{"cell_type":{"62a5f689":"code","8dd7e10f":"code","d2a4da6c":"code","d81f0f10":"code","04279b07":"code","8663268c":"code","e4901078":"code","98ad9de4":"code","39eb8366":"code","d75e3cc9":"code","d630ad05":"code","2fb55877":"code","b2df8c0c":"code","fe1c6cc3":"code","f3e208ac":"code","7d8fbc67":"code","5fd313e1":"code","1fac43f0":"code","7e3d015c":"code","78bc2f71":"code","f9c63ef2":"code","b668e4e8":"markdown","c885cf4a":"markdown","a527b9c4":"markdown","7e6de72b":"markdown","7bd25523":"markdown","afadd3a5":"markdown","85a34a04":"markdown","896d9e2d":"markdown","7f55aca4":"markdown","e4ffffc1":"markdown","21404bd7":"markdown"},"source":{"62a5f689":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\", color_codes=True)\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom itertools import combinations\nfrom numpy import array,array_equal\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom xgboost import plot_tree\nfrom matplotlib.pylab import rcParams","8dd7e10f":"train = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/test.csv\")","d2a4da6c":"test_id = test.ID","d81f0f10":"df = pd.DataFrame(train.TARGET.value_counts())\ndf['%'] = 100 * df['TARGET']\/train.shape[0]\ndf","04279b07":"train = train.loc[:, (train != train.iloc[0]).any()]\ntest = train.loc[:, (train != train.iloc[0]).any()]","8663268c":"def remove_ducplicated_column(dataset):\n    remove = []\n    cols = dataset.columns\n    for i in range(len(cols)-1):\n        v = dataset[cols[i]].values\n        for j in range(i+1,len(cols)):\n            if np.array_equal(v,dataset[cols[j]].values):\n                remove.append(cols[j])\n    dataset.drop(remove, axis=1, inplace=True)","e4901078":"remove_ducplicated_column(train) # delete duplicate columns for trains\nremove_ducplicated_column(test) # -- for test","98ad9de4":"X_train = train.iloc[:,:-1]\ny_train = train.TARGET\n\nX_test = test.iloc[:,:-1]\ny_test = test.TARGET","39eb8366":"# Create a random forest classifier\nclf = RandomForestClassifier(random_state=0, n_jobs=-1)\n\n# Train the classifier\nclf.fit(X_train, y_train)\n\n# Print the name and gini importance of each feature\nfor feature in zip(X_train.columns, clf.feature_importances_):\n    print(feature)","d75e3cc9":"# Create a selector object that will use the random forest classifier to identify\n# features that have an importance of more than 0.15\nsfm = SelectFromModel(clf, threshold=0.002)\n\n# Train the selector\nsfm.fit(X_train, y_train)\n\n# Print the names of the most important features\nprint(len(sfm.get_support(indices=True)), \"features selected\")\nfor feature_list_index in sfm.get_support(indices=True):\n    print(X_train.columns[feature_list_index], clf.feature_importances_[feature_list_index])","d630ad05":"X_important_train = sfm.transform(X_train)\nX_important_test = sfm.transform(X_test)","2fb55877":"def confusio_matrix(y_test, y_predicted):\n  cm = confusion_matrix(y_test, y_predicted)\n  plt.figure(figsize=(15,10))\n  plt.clf()\n  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n  classNames = ['Negative','Positive']\n  plt.title('Matrice de confusion')\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  tick_marks = np.arange(len(classNames))\n  plt.xticks(tick_marks, classNames, rotation=45)\n  plt.yticks(tick_marks, classNames)\n  s = [['TN','FP'], ['FN', 'TP']]\n  \n  for i in range(2):\n      for j in range(2):\n          plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n  plt.show()","b2df8c0c":"m2_xgb = xgb.XGBClassifier(n_estimators=110, nthread=-1, max_depth = 4, seed=1729)\nm2_xgb.fit(X_important_train, y_train, eval_metric=\"auc\", verbose = False, eval_set=[(X_important_test, y_test)])","fe1c6cc3":"y_predicted = m2_xgb.predict(X_important_test)","f3e208ac":"y_predicted","7d8fbc67":"print(len(y_test))","5fd313e1":"confusio_matrix(y_test,y_predicted)","1fac43f0":"rcParams['figure.figsize'] = 50,20\nplot_tree(m2_xgb)\nplt.show()","7e3d015c":"from sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\nfrom inspect import signature\n\nprecision, recall, _ = precision_recall_curve(y_test, y_predicted)\nprint(precision, recall)\n# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\nstep_kwargs = ({'step': 'post'}\n               if 'step' in signature(plt.fill_between).parameters\n               else {})\nplt.step(recall, precision, color='b', alpha=0.2, where='post')\nplt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\n#plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))","78bc2f71":"# calculate the auc score\nprint(\"Roc AUC: \", roc_auc_score(y_test, m2_xgb.predict_proba(X_important_test)[:,1], average='macro'))","f9c63ef2":"## # Submission\nprobs = m2_xgb.predict_proba(X_test)\n\n#submission = pd.DataFrame({\"ID\":test_id, \"TARGET\": probs[:,1]})\n#submission.to_csv(\"submission.csv\", index=False)","b668e4e8":"Create A Data Subset With Only The Most Important Features","c885cf4a":" -> **Visualize Gradient Boosting Decision Trees**","a527b9c4":"**Deleted the columns that have a constant value**","7e6de72b":"Plot the Precision-Recall curve","7bd25523":"**Separation of features and TARGET**","afadd3a5":"Identify And Select Most Important Features","85a34a04":"**Classification avec XGBClassifier**","896d9e2d":"** Find duplicated columns in value and delete them **","7f55aca4":"View the percentage distribution of TARGET value (0 or 1) in trainset","e4ffffc1":"**Feature Selection Using Random Forest**","21404bd7":"**--> Confusion Matrix**"}}