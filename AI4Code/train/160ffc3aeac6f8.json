{"cell_type":{"0082d20b":"code","005622ea":"code","b03dbc99":"code","711ac6db":"code","416bd0d5":"code","4dc149b4":"code","fa8d05ed":"code","4d5796fe":"code","92cdc7ec":"code","f9267666":"code","b0fac1b9":"code","62ce001b":"code","86ea3833":"code","a849bca0":"code","3b71abdc":"code","8d277711":"code","457c61c8":"code","1fb8ce2b":"code","90c14b5d":"code","3737adc6":"code","7f2dbaee":"code","89af54eb":"code","3d8db64b":"code","5422a4e3":"code","74f14148":"code","f9d14982":"code","d2a39fca":"code","aad572b0":"code","50db17be":"code","04fa0856":"code","918cb154":"code","065f7647":"code","63823ce3":"code","9fb4cee2":"code","6c1eff50":"code","07575852":"code","570b9159":"code","fa2a364c":"code","91c33b1f":"code","5b6c5fc8":"code","a292ef18":"code","afbf785f":"code","92cc8483":"code","a73f52b7":"code","af18cf7f":"code","9a591648":"code","fa216132":"code","1691c629":"code","61372e07":"code","62c000fb":"code","b1cb9f51":"code","ef57fc33":"code","a49ad5ad":"code","6617461a":"markdown","c7536c79":"markdown","7bbc9fbd":"markdown","bacd80c1":"markdown","a7b158e3":"markdown","2769a55b":"markdown","bd98c1db":"markdown","c3e07347":"markdown","06ead11b":"markdown","e4441c10":"markdown","c51b6c1a":"markdown","19aa8041":"markdown"},"source":{"0082d20b":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport gc\nimport os\nimport PIL\n\nfrom scipy import stats\nfrom multiprocessing import Pool\nfrom PIL import ImageOps, ImageFilter\nfrom tqdm import tqdm\npd.set_option(\"max_columns\",300)\npd.set_option(\"max_rows\",1103)\nfrom wordcloud import WordCloud\n\ntqdm.pandas()","005622ea":"df_train = pd.read_csv('..\/input\/imet-2019-fgvc6\/train.csv')\ntrain_path = '..\/input\/imet-2019-fgvc6\/train\/'\nlabel_df = pd.read_csv('..\/input\/imet-2019-fgvc6\/labels.csv')","b03dbc99":"label_names = label_df['attribute_name'].values\n\nnum_labels = np.zeros((df_train.shape[0],))\ntrain_labels = np.zeros((df_train.shape[0], len(label_names)))\n\nfor row_index, row in enumerate(df_train['attribute_ids']):\n    num_labels[row_index] = len(row.split())    \n    for label in row.split():\n        train_labels[row_index, int(label)] = 1","711ac6db":"culture, tag, unknown = 0, 0, 0\n\nfor l in label_names:\n    if l[:3] == 'cul':\n        culture += 1\n    elif l[:3] == 'tag':\n        tag += 1\n    else:\n        unknown += 1\n        \nprint(f'Culture : {culture}')\nprint(f'Tag     : {tag}')\nprint(f'Unknown : {unknown}')\nprint(f'Total   : {culture + tag + unknown}')","416bd0d5":"label_df['is_culture'] = label_df['attribute_name'].apply(lambda x: 1 if 'culture' in x else 0)\nattribute_count = label_df['is_culture'].value_counts()\n\nax = sns.barplot(['Tag', 'Culture'], attribute_count.values, alpha=0.8)\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height()}\\n{p.get_height() * 100 \/ label_df.shape[0]:.2f}%',\n                (p.get_x() + p.get_width()\/2., p.get_height()), \n                ha='center', \n                va='center', \n                fontsize=12, \n                color='black',\n                xytext=(2,-20), \n                textcoords='offset points')\nplt.title('Culture\/Tag')\nplt.xlabel('attribute type')\nplt.ylabel('Frequency')\n","4dc149b4":"label_sum = np.sum(train_labels, axis=0)\n\nculture_sequence = label_sum[:398].argsort()[::-1]\ntag_sequence = label_sum[398:].argsort()[::-1]\n\nculture_labels = [label_names[x][9:] for x in culture_sequence]\nculture_counts = [label_sum[x] for x in culture_sequence]\n\ntag_labels = [label_names[x + 398][5:] for x in tag_sequence]\ntag_counts = [label_sum[x + 398] for x in tag_sequence]","fa8d05ed":"for i in range(len(culture_labels)):\n    print(culture_labels[i],':',culture_counts[i])","4d5796fe":"df = pd.DataFrame({'Culture_label': culture_labels,'Culture_count': culture_counts})\ndf.to_csv('cutr_labe.csv',index=True)","92cdc7ec":"for i in range(len(tag_labels)):\n    print(tag_labels[i],':',tag_counts[i])","f9267666":"df = pd.DataFrame({'Tags_label': tag_labels,'Tags_count': tag_counts})\ndf.to_csv('tags_label.csv',index=True)","b0fac1b9":"plt.figure(figsize=(20,15))\n\nplt.subplot(1,2,1)\nax1 = sns.barplot(y=culture_labels[:20], x=culture_counts[:20], orient=\"h\")\nplt.title('Label Counts by Culture (Top 20)',fontsize=15)\nplt.xlim((0, max(culture_counts)*1.15))\nplt.yticks(fontsize=15)\n\nfor p in ax1.patches:\n    ax1.annotate(f'{int(p.get_width())}\\n{p.get_width() * 100 \/ df_train.shape[0]:.2f}%',\n                (p.get_width(), p.get_y() + p.get_height() \/ 2.), \n                ha='left', \n                va='center', \n                fontsize=12, \n                color='black',\n                xytext=(7,0), \n                textcoords='offset points')\n\nplt.subplot(1,2,2)    \nax2 = sns.barplot(y=tag_labels[:20], x=tag_counts[:20], orient=\"h\")\nplt.title('Label Counts by Tag (Top 20)',fontsize=15)\nplt.xlim((0, max(tag_counts)*1.15))\nplt.yticks(fontsize=15)\n\nfor p in ax2.patches:\n    ax2.annotate(f'{int(p.get_width())}\\n{p.get_width() * 100 \/ df_train.shape[0]:.2f}%',\n                (p.get_width(), p.get_y() + p.get_height() \/ 2.), \n                ha='left', \n                va='center', \n                fontsize=12, \n                color='black',\n                xytext=(7,0), \n                textcoords='offset points')\n\nplt.tight_layout()\nplt.show()","62ce001b":"plt.figure(figsize=(20,8))\n\nax = sns.countplot(num_labels)\nplt.xlabel('Number of Labels')\nplt.title('Number of Labels per Image', fontsize=20)\n\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height() * 100 \/ df_train.shape[0]:.3f}%',\n            (p.get_x() + p.get_width() \/ 2., p.get_height()), \n            ha='center', \n            va='center', \n            fontsize=11, \n            color='black',\n            xytext=(0,7), \n            textcoords='offset points')\n","86ea3833":"train_attr_ohot = np.zeros((len(df_train), len(label_df)), dtype=int)\n\nfor idx, attr_arr in enumerate(df_train.attribute_ids.str.split(\" \").apply(lambda l: list(map(int, l))).values):\n    train_attr_ohot[idx, attr_arr] = 1","a849bca0":"names_arr = label_df.attribute_name.values\ndf_train[\"attribute_names\"] = [\", \".join(names_arr[arr == 1]) for arr in train_attr_ohot]","3b71abdc":"df_train[\"attr_num\"] = train_attr_ohot.sum(axis=1)\ndf_train[\"culture_attr_num\"] = train_attr_ohot[:, :398].sum(axis=1)\ndf_train[\"tag_attr_num\"] = train_attr_ohot[:, 398:].sum(axis=1)","8d277711":"df_train.head()","457c61c8":"#for i in range(len(df_train[\"attribute_names\"])):\n#    print(df_train[\"attribute_names\"][i],':',df_train[\"culture_attr_num\"][i])","1fb8ce2b":"fig = plt.figure(figsize=(15, 10))\nfig.subplots_adjust(hspace=0.4)\nax2 = fig.add_subplot(3,1,2,)\nsns.countplot(df_train.culture_attr_num, ax=ax2)\nax2.set_title(\"number of 'culture' attributes each art has\")\nfor p in ax2.patches:\n    ax2.annotate(f'{p.get_height() * 100 \/ df_train.shape[0]:.3f}%',\n            (p.get_x() + p.get_width() \/ 2., p.get_height()), \n            ha='center', \n            va='center', \n            fontsize=11, \n            color='black',\n            xytext=(0,7), \n            textcoords='offset points')\nax3 = fig.add_subplot(3,1,3,)\nax3.set_title(\"number of 'tag' attributes each art has\")\nsns.countplot(df_train.tag_attr_num, ax=ax3)\nfor p in ax3.patches:\n    ax3.annotate(f'{p.get_height() * 100 \/ df_train.shape[0]:.3f}%',\n            (p.get_x() + p.get_width() \/ 2., p.get_height()), \n            ha='center', \n            va='center', \n            fontsize=11, \n            color='black',\n            xytext=(0,7), \n            textcoords='offset points')","90c14b5d":"from cv2 import cv2\ni = 1\ndf_train[\"attribute_ids\"]=df_train[\"attribute_ids\"].apply(lambda x:x.split(\" \"))\ndf_train[\"id\"]=df_train[\"id\"].apply(lambda x:x+\".png\")\nplt.figure(figsize=[30,30])\nfor img_name in os.listdir(\"..\/input\/imet-2019-fgvc6\/train\/\")[5:10]:   \n    img = cv2.imread(\"..\/input\/imet-2019-fgvc6\/train\/%s\" % img_name)[...,[2, 1, 0]]\n    plt.subplot(5, 1, i)\n    plt.imshow(img)\n    ids = df_train[df_train[\"id\"] == img_name][\"attribute_ids\"]\n    print(ids)\n    title_val = []\n    for tag_id in ids.values[0]:\n        att_name = label_df[label_df['attribute_id'].astype(str) == tag_id]['attribute_name'].values[0]\n        title_val.append(att_name)\n    plt.title(title_val)\n    i += 1\n    \nplt.show()","3737adc6":"import os\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nimport hashlib","7f2dbaee":"def check_md5(fname):\n    hash_md5 = hashlib.md5()\n    with open(fname, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            hash_md5.update(chunk)\n    return hash_md5.hexdigest()","89af54eb":"file_names = []\npath_root = '..\/input\/imet-2019-fgvc6\/train\/'\nfor filename in os.listdir(path_root)[0:20]:\n    file_names.append(check_md5(path_root+filename))\nprint(len(file_names))","3d8db64b":"unit = np.unique(file_names,return_counts=True)\ncount = 0\nfor i in range(len(unit[1])):\n    if unit[1][i]>1:\n        count += 1\n        print('Duplicated Images')\nif count == 0:\n    print('NOT Duplicated Images')","5422a4e3":"def padding_image(path_img):\n    image_old = Image.open(path_img)\n    width, height = image_old.size\n\n    if width > height:\n        distance_max = width\n        array = np.zeros([distance_max, distance_max, 3], dtype=np.uint8)\n        array.fill(0)\n        image_new = Image.fromarray(array)\n\n        xmin = 0\n        ymin = int((distance_max \/ 2) - (height \/ 2))\n        xmax = distance_max\n        ymax = int((distance_max \/ 2) + (height \/ 2))\n\n        image_new.paste(image_old, (xmin, ymin, xmax, ymax))\n        return image_new\n\n    elif width < height:\n        distance_max = height\n        array = np.zeros([distance_max, distance_max, 3], dtype=np.uint8)\n        array.fill(0)\n        image_new = Image.fromarray(array)\n\n        xmin = int((distance_max \/ 2) - (width \/ 2))\n        ymin = 0\n        xmax = int((distance_max \/ 2) + (width \/ 2))\n        ymax = distance_max\n\n        image_new.paste(image_old, (xmin, ymin, xmax, ymax))\n        return image_new\n\n    else:\n        return image_old","74f14148":"import random\nrandom_filenames = random.choices(os.listdir(path_root), k=5)\nfor filename in random_filenames:\n    plt.imshow(np.array(Image.open(path_root+filename)))\n    plt.figure()\n    plt.imshow(padding_image(path_root+filename))\n    plt.figure()","f9d14982":"import fastai\nfrom fastai.vision import *\nfastai.__version__","d2a39fca":"BATCH  = 126\nSIZE   = 250\npath = Path('..\/input\/imet-2019-fgvc6\/') # iMet data path","aad572b0":"!ls ..\/input\/resnet50\/","50db17be":"# Making pretrained weights work without needing to find the default filename\nfrom torch.utils import model_zoo\nPath('models').mkdir(exist_ok=True)\n!cp '..\/input\/resnet50\/resnet50.pth' 'models\/'\ndef load_url(*args, **kwargs):\n    model_dir = Path('models')\n    filename  = 'resnet50.pth'\n    if not (model_dir\/filename).is_file(): raise FileNotFoundError\n    return torch.load(model_dir\/filename)\nmodel_zoo.load_url = load_url","04fa0856":"# Load train dataframe\ntrain_df = pd.read_csv(path\/'train.csv')\ntrain_df.head()","918cb154":"# Load labels dataframe\nlabels_df = pd.read_csv(path\/'labels.csv')\nlabels_df.head()","065f7647":"# Load sample submission\ntest_df = pd.read_csv(path\/'sample_submission.csv')\ntest_df.head()","63823ce3":"tfms = get_transforms(do_flip=True, flip_vert=False, max_rotate=0.10, max_zoom=1.5, max_warp=0.2, max_lighting=0.2,\n                     xtra_tfms=[(symmetric_warp(magnitude=(-0,0), p=0)),])","9fb4cee2":"train, test = [ImageList.from_df(df, path=path, cols='id', folder=folder, suffix='.png') \n               for df, folder in zip([train_df, test_df], ['train', 'test'])]\ndata = (train.split_by_rand_pct(0.05, seed=42)\n        .label_from_df(cols='attribute_ids', label_delim=' ')\n        .add_test(test)\n        .transform(tfms, size=SIZE, resize_method=ResizeMethod.PAD, padding_mode='border',)\n        .databunch(path=Path('.'), bs=BATCH).normalize(imagenet_stats))","6c1eff50":"data","07575852":"# Source: https:\/\/www.kaggle.com\/c\/human-protein-atlas-image-classification\/discussion\/78109\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n\n    def forward(self, logit, target):\n        target = target.float()\n        max_val = (-logit).clamp(min=0)\n        loss = logit - logit * target + max_val + \\\n               ((-max_val).exp() + (-logit - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-logit * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        if len(loss.size())==2:\n            loss = loss.sum(dim=1)\n        return loss.mean()","570b9159":"learn = cnn_learner(data, base_arch=models.resnet50, loss_func=FocalLoss(), metrics=fbeta)","fa2a364c":"ls ..\/input","91c33b1f":"!cp '..\/input\/models2\/stage-1.pth' 'models\/'","5b6c5fc8":"def find_best_fixed_threshold(preds, targs, do_plot=True):\n    score = []\n    thrs = np.arange(0, 0.5, 0.01)\n    for thr in progress_bar(thrs):\n        score.append(fbeta(valid_preds[0],valid_preds[1], thresh=thr))\n    score = np.array(score)\n    pm = score.argmax()\n    best_thr, best_score = thrs[pm], score[pm].item()\n    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n    if do_plot:\n        plt.plot(thrs, score)\n        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n        plt.show()\n    return best_thr\n\ni2c = np.array([[i, c] for c, i in learn.data.train_ds.y.c2i.items()]).astype(int) # indices to class number correspondence\n\ndef join_preds(preds, thr):\n    return [' '.join(i2c[np.where(t==1)[0],1].astype(str)) for t in (preds[0].sigmoid()>thr).long()]","a292ef18":"learn.load('stage-1')","afbf785f":"# Validation predictions\nvalid_preds = learn.get_preds(DatasetType.Valid)\nbest_thr = find_best_fixed_threshold(*valid_preds)","92cc8483":"# Find a good learning rate\nlearn.lr_find()\nlearn.recorder.plot()","a73f52b7":"learn.unfreeze()\nlearn.fit_one_cycle(16, slice(1e-4,1e-3))\nlearn.freeze()\nlearn.save('stage-2', return_path=True)","af18cf7f":"# Validation predictions\nvalid_preds = learn.get_preds(DatasetType.Valid)\nbest_thr = find_best_fixed_threshold(*valid_preds)","9a591648":"learn.recorder.plot()\nlearn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","fa216132":"learn.export()","1691c629":"# Test predictions\n#test_preds = learn.get_preds(DatasetType.Test)\n#test_df.attribute_ids = join_preds(test_preds, best_thr)\n#test_df.head()","61372e07":"#test_df.to_csv('submission.csv', index=False)","62c000fb":"# Validation predictions with TTA\n#valid_preds = learn.TTA(ds_type=DatasetType.Valid)\n#best_thr = find_best_fixed_threshold(*valid_preds)","b1cb9f51":"# Test predictions with TTA\ntest_preds = learn.TTA(ds_type=DatasetType.Test)\ntest_df.attribute_ids = join_preds(test_preds, best_thr)\ntest_df.head()","ef57fc33":"test_df.to_csv('submission.csv', index=False) ","a49ad5ad":"# Find a good learning rate\nlearn.lr_find()\nlearn.recorder.plot()","6617461a":"## TTA","c7536c79":"# Data","7bbc9fbd":"# Check duplicated images","bacd80c1":"# Setup","a7b158e3":"# Get predictions","2769a55b":"Example of images with tags","bd98c1db":"# EDA by Visualize Images","c3e07347":"# Train the model","06ead11b":"# Create data object using datablock API","e4441c10":"# Padding image","c51b6c1a":"# Create learner with pretrenet model and FocalLoss\nFor problems with high class imbalance Focal Loss is usually a better choice than the usual Cross Entropy Loss.","19aa8041":"# EDA CSV"}}