{"cell_type":{"2b2bf26f":"code","3acf8f28":"code","48c70dfa":"code","8b16096b":"code","884f7bd7":"code","5eaeeccf":"code","aa0dcc32":"code","4d701952":"code","5cd19736":"code","a87473ee":"code","3d0c03ea":"code","7815559c":"code","1ead461c":"code","08ae743a":"code","e9407c30":"code","e00be212":"code","cf107621":"code","b4228c87":"code","6ee27486":"code","e68032d8":"code","468a09fa":"code","3242d583":"code","7ba8ae3f":"code","e8405078":"code","be89fd86":"code","5e97d7c4":"code","b406a844":"code","1e86e882":"code","c87b94d2":"code","b64353b0":"code","cafb10e7":"code","8efdf06e":"code","08bd1cf7":"code","61c54c07":"code","74e1b6f3":"code","4f2e13ae":"code","0cb0bc9d":"code","b45d7a03":"code","bd882a8a":"code","6155bd88":"code","59c9965f":"code","ce8bdcee":"code","78ed3133":"code","0da2199b":"code","d80cb700":"code","528b1c2b":"code","fa64c5a9":"code","7217b9b6":"code","a2951b6b":"markdown","94e1e977":"markdown","d8c4e964":"markdown","2a774253":"markdown","488d10d4":"markdown","323e5151":"markdown","3ef072fa":"markdown"},"source":{"2b2bf26f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nnltk.download('stopwords')\n%matplotlib inline\nsns.set_style(\"darkgrid\")\nplt.style.use(\"fivethirtyeight\")\nprint(\"Necessary packages included successfully!\")","3acf8f28":"# example text for model training (SMS messages)\nsimple_train = ['call you tonight', 'Call me a cab', 'Please call me... PLEASE!']","48c70dfa":"# import and instantiate CountVectorizer (with the default parameters)\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer()\n# learn the 'vocabulary' of the training data (occurs in-place)\nvect.fit(simple_train)","8b16096b":"# examine the fitted vocabulary\nvect.get_feature_names()","884f7bd7":"# transform training data into a 'document-term matrix'\nsimple_train_dtm = vect.transform(simple_train)\nsimple_train_dtm","5eaeeccf":"# convert sparse matrix to a dense matrix\nsimple_train_dtm.toarray()","aa0dcc32":"# examine the vocabulary and document-term matrix together\npd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())","4d701952":"# check the type of the document-term matrix\ntype(simple_train_dtm)","5cd19736":"# examine the sparse matrix contents\nprint(simple_train_dtm)","a87473ee":"# example text for model testing\nsimple_test = [\"please don't call me\"]\n# transform testing data into a document-term matrix (using existing vocabulary)\nsimple_test_dtm = vect.transform(simple_test)\nsimple_test_dtm.toarray()","3d0c03ea":"# examine the vocabulary and document-term matrix together\npd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())","7815559c":"url = 'https:\/\/raw.githubusercontent.com\/MainakRepositor\/Datasets-\/master\/spam.csv'\nsms = pd.read_csv(url,encoding='latin-1')\nsms.dropna(how=\"any\", inplace=True, axis=1)\nsms.columns = ['label', 'message']\nsms.head()","1ead461c":"sms.describe()","08ae743a":"sms.groupby('label').describe()","e9407c30":"# convert label to a numerical variable\nsms['label_num'] = sms.label.map({'ham':0, 'spam':1})\nsms.head()","e00be212":"sms['message_len'] = sms.message.apply(len)\nsms.head()","cf107621":"plt.figure(figsize=(17, 8))\n\nsms[sms.label=='ham'].message_len.plot(bins=35, kind='hist', color='blue', \n                                       label='Ham messages', alpha=0.6)\nsms[sms.label=='spam'].message_len.plot(kind='hist', color='red', \n                                       label='Spam messages', alpha=0.6)\nplt.legend()\nplt.xlabel(\"Message Length\")","b4228c87":"sms[sms.label=='ham'].describe()","6ee27486":"sms[sms.label=='spam'].describe()","e68032d8":"sms[sms.message_len == 910].message.iloc[0]","468a09fa":"import string\nfrom nltk.corpus import stopwords\n\ndef text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    STOPWORDS = stopwords.words('english') + ['u', '\u00fc', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n    \n    # Now just remove any stopwords\n    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])\n    \nsms.head()","3242d583":"sms['clean_msg'] = sms.message.apply(text_process)\nsms.head()","7ba8ae3f":"type(stopwords.words('english'))","e8405078":"from collections import Counter\n\nwords = sms[sms.label=='ham'].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\nham_words = Counter()\n\nfor msg in words:\n    ham_words.update(msg)\n    \nprint(ham_words.most_common(50))","be89fd86":"words = sms[sms.label=='spam'].clean_msg.apply(lambda x: [word.lower() for word in x.split()])\nspam_words = Counter()\n\nfor msg in words:\n    spam_words.update(msg)\n    \nprint(spam_words.most_common(50))","5e97d7c4":"# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\nX = sms.clean_msg\ny = sms.label_num\nprint(X.shape)\nprint(y.shape)","b406a844":"# split X and y into training and testing sets \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","1e86e882":"from sklearn.feature_extraction.text import CountVectorizer\n\n# instantiate the vectorizer\nvect = CountVectorizer()\nvect.fit(X_train)","c87b94d2":"# learn training data vocabulary, then use it to create a document-term matrix\nX_train_dtm = vect.transform(X_train)\n# equivalently: combine fit and transform into a single step\nX_train_dtm = vect.fit_transform(X_train)\n# examine the document-term matrix\nX_train_dtm","b64353b0":"# transform testing data (using fitted vocabulary) into a document-term matrix\nX_test_dtm = vect.transform(X_test)\nX_test_dtm","cafb10e7":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer = TfidfTransformer()\ntfidf_transformer.fit(X_train_dtm)\ntfidf_transformer.transform(X_train_dtm)","8efdf06e":"# import and instantiate a Multinomial Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\n# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n%time nb.fit(X_train_dtm, y_train)","08bd1cf7":"# make class predictions for X_test_dtm\ny_pred_class = nb.predict(X_test_dtm)\n# calculate accuracy of class predictions\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test, y_pred_class)","61c54c07":"# print the confusion matrix\nmetrics.confusion_matrix(y_test, y_pred_class)","74e1b6f3":"X_test.shape","4f2e13ae":"X_test[y_pred_class > y_test]","0cb0bc9d":"# print message text for false negatives (spam incorrectly classifier)\nX_test[y_pred_class < y_test]","b45d7a03":"# example of false negative \nX_test[4949]","bd882a8a":"# calculate predicted probabilities for X_test_dtm (poorly calibrated)\ny_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\ny_pred_prob\n","6155bd88":"# calculate AUC\nmetrics.roc_auc_score(y_test, y_pred_prob)","59c9965f":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\n\npipe = Pipeline([('bow', CountVectorizer()), \n                 ('tfid', TfidfTransformer()),  \n                 ('model', MultinomialNB())])\npipe.fit(X_train, y_train)","ce8bdcee":"y_pred = pipe.predict(X_test)\nmetrics.accuracy_score(y_test, y_pred)","78ed3133":"metrics.confusion_matrix(y_test, y_pred)","0da2199b":"# import an instantiate a logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(solver='liblinear')\n# train the model using X_train_dtm\n%time logreg.fit(X_train_dtm, y_train)","d80cb700":"# make class predictions for X_test_dtm\ny_pred_class = logreg.predict(X_test_dtm)\n# calculate predicted probabilities for X_test_dtm (well calibrated)\ny_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\ny_pred_prob","528b1c2b":"# calculate accuracy\nmetrics.accuracy_score(y_test, y_pred_class)","fa64c5a9":"metrics.confusion_matrix(y_test, y_pred_class)","7217b9b6":"# calculate AUC\nmetrics.roc_auc_score(y_test, y_pred_prob)","a2951b6b":"## **1. Importing and preparing dataset**","94e1e977":"## **4. Testing and Evaluation**","d8c4e964":"**MADE BY MAINAK CHAUDHURI ON 02\/02\/2022**","2a774253":"## **2. Reading a text-based dataset into notebook**","488d10d4":"# **SMS Spam Detection using Natural Language Processing**\n**Approach :**\n***i. Representing text as numerical data***\n\n***ii. Reading a text-based dataset into pandas***\n\n***iii.Vectorizing our dataset***\n\n***iv. Building and evaluating a model***\n\n***v. Comparing models***\n\n***vi. Examining a model for further insight***","323e5151":"## **3. Applying NLP Algorithms**","3ef072fa":"## **Conclusion:**\nThus the model is 98% accurate and most spam messeages have been categorized accordingly. "}}