{"cell_type":{"86469dd0":"code","24fdeb91":"code","7652384d":"code","e1cb52a2":"code","d5a72a63":"code","c1bc15ba":"code","bde27532":"code","749844f2":"code","f86668ba":"code","919d4b23":"markdown","fa66daff":"markdown","db5b6346":"markdown"},"source":{"86469dd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24fdeb91":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.cluster import KMeans \nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import MinMaxScaler","7652384d":"df=pd.read_csv('..\/input\/iris-dataset\/Iris.csv')\ndf.drop(['Id'],axis=1,inplace=True)\n##\ndf['Species_id']=df['Species'].factorize()[0]\nflower_label=df['Species'].factorize()[1]\ndf.sample(2)","e1cb52a2":"from sklearn.cluster import KMeans\nX1=df.iloc[:,[0,1,2,3]]\n\nwcss= [];score=[]\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters = k, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n    kmeans.fit_transform(X1)\n    score.append(kmeans.score(X1))\n    wcss.append(kmeans.inertia_)\n\nplt.figure(figsize = (12, 7))\n\nplt.plot(range(1, 11), wcss, linewidth = 5, marker = 'o',color=\"green\", ms = 20, mfc = 'black')\nplt.title('Elbow Plot\\n', fontsize = 20)\nplt.xlabel('K')\nplt.ylabel('WCSS')\nplt.show()\n\ndata1={'k':range(1,11),'score':score,'Inertia':wcss}\ndf1=pd.DataFrame(data1)\ndf1","d5a72a63":"x=df.iloc[:,[0,1,2,3]]\nkmeans = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit(x)\n# print(y_kmeans.labels_)\nplt.figure(figsize = (14, 8))\n##\nSepalLengthCm=df.iloc[:,[0]]\nSepalWidthCm=df.iloc[:,[1]]\npredict_labels=kmeans.labels_\ncluster_centers_x=kmeans.cluster_centers_[:, 0]\ncluster_centers_y=kmeans.cluster_centers_[:, 1]\n##\nplt.scatter(SepalLengthCm,SepalWidthCm, c = predict_labels, s = 105)\nplt.scatter(cluster_centers_x, cluster_centers_y, color = 'red', s = 250)\nplt.title('Clusters of Sepal\\n', fontsize = 20)\nplt.xlabel('SepalLengthCm', fontsize = 20)\nplt.ylabel('SepalWidthCm', fontsize = 20)\nplt.show()","c1bc15ba":"kmeans = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit(x)\n# print(y_kmeans.labels_)\nplt.figure(figsize = (14, 8))\n##\nPetalLengthCm=df.iloc[:,[2]]\nPetalWidthCm=df.iloc[:,[3]]\npredict_labels=kmeans.labels_\ncluster_centers_x=kmeans.cluster_centers_[:, 0]\ncluster_centers_y=kmeans.cluster_centers_[:, 1]\n##\nplt.scatter(SepalLengthCm,SepalWidthCm, c = predict_labels, s = 105)\nplt.scatter(cluster_centers_x, cluster_centers_y, color = 'red', s = 250)\nplt.title('Clusters of Petal\\n', fontsize = 20)\nplt.xlabel('PetalLengthCm', fontsize = 20)\nplt.ylabel('PetalWidthCm', fontsize = 20)\nplt.show()","bde27532":"import scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(x, method  = \"ward\"))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()","749844f2":"from scipy.cluster.hierarchy import dendrogram,linkage\n\nplt.figure(figsize = (17, 8))\n\ndendo = dendrogram(linkage(x, method = 'ward'))\nplt.title('Dendrogram', fontsize = 15)\nplt.show()","f86668ba":"x=df.drop(['Species','Species_id'],axis=1)\nfrom sklearn.cluster import AgglomerativeClustering \nhc = AgglomerativeClustering(n_clusters = 4, affinity = 'euclidean', linkage ='ward')\n# Lets try to fit the hierarchical clustering algorithm  to dataset X while creating the \n# clusters vector that tells for each customer which cluster the customer belongs to.\ny_hc=hc.fit_predict(x)\ny_hc","919d4b23":"# Kmean\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html","fa66daff":"# Dendrogram\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2021\/08\/hierarchical-clustering-algorithm-python\/\n\n![](https:\/\/editor.analyticsvidhya.com\/uploads\/388381_cpm-bNYkvgCE9sxvF6pGNQ.gif)","db5b6346":"# Reference\n\nhttps:\/\/www.kaggle.com\/khotijahs1\/k-means-clustering-of-iris-dataset"}}