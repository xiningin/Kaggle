{"cell_type":{"1c2503cb":"code","63061632":"code","d590a0c9":"code","e6afd783":"code","3baf2039":"code","3b57589c":"code","1dfe5ccf":"code","b44f7660":"code","e1e9bc3f":"code","19a3f950":"code","181145cb":"code","e0424b46":"code","0fc969f1":"code","d15088dc":"code","a2c4c583":"code","a2af4408":"code","6c8ff747":"code","89f5435b":"code","c8b5d287":"code","3f76d5a0":"code","9164a0a2":"code","425e9548":"code","94063893":"code","44429486":"code","fbec6306":"code","3818f340":"code","81c2addd":"code","46f21e90":"code","ee4b50c0":"markdown","b006840f":"markdown","c2cf2781":"markdown","e6736fe2":"markdown","604135bf":"markdown","b0c9cfde":"markdown","ea31c4db":"markdown","1c5aa845":"markdown","83c70751":"markdown","db0b343d":"markdown","f7458e8e":"markdown","0c7a6044":"markdown","e60d25a3":"markdown","9489bfbc":"markdown","7c6a3ef9":"markdown","a8f3c413":"markdown"},"source":{"1c2503cb":"%%capture\n# install tensorflow 2.0 alpha\n!pip install -q tensorflow-gpu==2.0.0-alpha0\n\n#install GapCV\n!pip install -q gapcv","63061632":"import os\nimport time\nimport cv2\nimport gc\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import callbacks\n\nimport gapcv\nfrom gapcv.vision import Images\n\nfrom sklearn.utils import class_weight\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint('tensorflow version: ', tf.__version__)\nprint('keras version: ', tf.keras.__version__)\nprint('gapcv version: ', gapcv.__version__)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nos.makedirs('model', exist_ok=True)\nprint(os.listdir('..\/input'))\nprint(os.listdir('.\/'))","d590a0c9":"def elapsed(start):\n    \"\"\"\n    Returns elapsed time in hh:mm:ss format from start time in unix format\n    \"\"\"\n    elapsed = time.time()-start\n    return time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))","e6afd783":"def plot_sample(imgs_set, labels_set, img_size=(12,12), columns=4, rows=4, random=False):\n    \"\"\"\n    Plot a sample of images\n    \"\"\"\n    \n    fig=plt.figure(figsize=img_size)\n    \n    for i in range(1, columns*rows + 1):\n        \n        if random:\n            img_x = np.random.randint(0, len(imgs_set))\n        else:\n            img_x = i-1\n        \n        img = imgs_set[img_x]\n        ax = fig.add_subplot(rows, columns, i)\n        ax.set_title(str(labels_set[img_x]))\n        plt.axis('off')\n        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.show()","3baf2039":"dataset_name = 'wildlife224'\nminibatch_size = 32\nwildlife_filter = ['black_bear', 'bald_eagle', 'cougar', 'elk', 'gray_wolf']\n\nif not os.path.isfile('{}.h5'.format(dataset_name)):\n    ## create two list to use as paramaters in GapCV\n    print('{} preprocessing started'.format(dataset_name))\n    images_list = []\n    classes_list = []\n    for folder in os.scandir('..\/input\/oregon_wildlife\/oregon_wildlife'):\n        if folder.name in wildlife_filter:\n            for image in os.scandir(folder.path):\n                images_list.append(image.path)\n                classes_list.append(image.path.split('\/')[-2])\n\n    ## GapCV\n    images = Images(\n        dataset_name,\n        images_list,\n        classes_list,\n        config=[\n            'resize=(224,224)',\n            'store',\n            'stream'\n        ]\n    )","3b57589c":"del images\nimages = Images(\n    config=['stream'],\n    augment=[\n        'flip=horizontal',\n        'edge',\n        'zoom=0.3',\n        'denoise'\n    ]\n)\nimages.load(dataset_name)\nprint('{} dataset ready for streaming'.format(dataset_name))","1dfe5ccf":"images.split = 0.2\nX_test, Y_test = images.test\nimages.minibatch = 32\ngap_generator = images.minibatch","b44f7660":"print('content:', os.listdir(\".\/\"))\nprint('time to load data set:', images.elapsed)\nprint('number of images in data set:', images.count)\nprint('classes:', images.classes)\nprint('data type:', images.dtype)","e1e9bc3f":"Y_int = [y.argmax() for y in Y_test]\nclass_weights = class_weight.compute_class_weight(\n    'balanced',\n    np.unique(Y_int),\n    Y_int\n)\n\ntotal_train_images = images.count - len(X_test)\nn_classes = len(images.classes)","19a3f950":"!free -m","181145cb":"base_model = VGG16(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=None,\n    input_shape=(224, 224, 3),\n    pooling=None,\n    classes=1000\n)","e0424b46":"#vgg16_model.summary()\n#type(vgg16_model)","0fc969f1":"### use just in case include_top=True\n# model = Sequential()\n# for layer in vgg16_model.layers[:-3]:\n#     model.add(layer)\n\n### use loop to enable or disable trainable layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(layers.Flatten()) # comment it out if include_top=False\nmodel.add(layers.Dense(4096, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(4096, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(n_classes, activation='softmax'))\n\nmodel = Model(inputs=base_model.input, outputs=model(base_model.output)) # comment it out if include_top=False","d15088dc":"model.summary()","a2c4c583":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","a2af4408":"model_file = '.\/model\/model.h5'\n\n# # Clear any logs from previous runs\n# !rm -rf .\/logs\/fit\/*\n# !rm -rf .\/model\/*\n\n# log_dir=\".\/logs\/fit\/{}\".format(time.strftime(\"%Y%m%d-%H%M%S\", time.gmtime()))\n\n# get_ipython().system_raw(\n#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n#     .format(log_dir)\n# )","6c8ff747":"## commented out if you want to check the localhost\n# !curl http:\/\/localhost:6006","89f5435b":"# !wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip > \/dev\/null 2>&1\n# !unzip ngrok-stable-linux-amd64.zip > \/dev\/null 2>&1\n    \n# get_ipython().system_raw('.\/ngrok http 6006 &')","c8b5d287":"# !curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","3f76d5a0":"# tensorboard = callbacks.TensorBoard(\n#     log_dir=log_dir,\n#     histogram_freq=1\n# )\n\nearlystopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5\n)\n\nmodel_checkpoint = callbacks.ModelCheckpoint(\n    model_file,\n    monitor='val_accuracy',\n    save_best_only=True,\n    save_weights_only=False,\n    mode='max'\n)","9164a0a2":"start = time.time()\n\nmodel.fit_generator(\n    generator=gap_generator,\n    validation_data=(X_test, Y_test),\n    epochs=50,\n    steps_per_epoch=int(total_train_images \/ minibatch_size),\n    initial_epoch=0,\n    verbose=1,\n    class_weight=class_weights,\n    callbacks=[\n        # tensorboard,\n        model_checkpoint\n    ]\n)\n\nprint('\\nElapsed time: {}'.format(elapsed(start)))","425e9548":"#### Keras Bug!! :(\n# del model\n# model = load_model(model_file)","94063893":"scores = model.evaluate(X_test, Y_test, batch_size=32)\n\nfor score, metric_name in zip(scores, model.metrics_names):\n    print(\"{} : {}\".format(metric_name, score))","44429486":"!curl https:\/\/d36tnp772eyphs.cloudfront.net\/blogs\/1\/2016\/11\/17268317326_2c1525b418_k.jpg > test_image.jpg","fbec6306":"labels = {val:key for key, val in images.classes.items()}\nlabels","3818f340":"%pwd\n%ls","81c2addd":"image2 = Images('foo', ['test_image.jpg'], [0], config=['resize=(224,224)'])\nimg = image2._data[0]","46f21e90":"# prediction = model.predict_classes(img)  # un-comment it out if include_top=False\nprediction = model.predict(img)   # comment it out if include_top=False\nprediction = np.argmax(prediction,axis=1)   # comment it out if include_top=False\nprediction = labels[prediction[0]]\n\nplot_sample(img, ['predicted image: {}'.format(prediction)], img_size=(8, 8), columns=1, rows=1)","ee4b50c0":"### class_weights","b006840f":"## GapCV image preprocessing","c2cf2781":"# OREGON WILDLIFE - TENSORFLOW 2.0 + KERAS + GAPCV","e6736fe2":"## training","604135bf":"## install tensorboard and gapcv","b0c9cfde":"## Tensorboard + Callbacks\n\nTo run tensorboard un-comment lines","ea31c4db":"## utils functions","1c5aa845":"## Keras model definition","83c70751":"## get a random image and get a prediction!","db0b343d":"### download VGG16","f7458e8e":"### info","0c7a6044":"### split data set and start generator","e60d25a3":"## callbacks","9489bfbc":"### use GapCV in stream mode","7c6a3ef9":"### trainable layers","a8f3c413":"## import libraries"}}