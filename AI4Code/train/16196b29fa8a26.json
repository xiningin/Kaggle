{"cell_type":{"17739aee":"code","68ea3cb0":"code","5462b5b7":"code","4a82f376":"code","f821d6e6":"code","75c8fac4":"code","3bf02869":"code","7534583b":"code","cc27003e":"code","84a3dcc9":"code","ca648d8a":"code","327fc16e":"code","a4dfcd62":"code","ff85396d":"code","1cc90a46":"code","29ff4090":"code","92bcfe44":"code","984c77fd":"code","96008b56":"code","ce394323":"code","0dfd3284":"code","69cca5ce":"code","a98af0f5":"code","322c9acd":"code","b54e04da":"code","e1a22586":"markdown","7c8687be":"markdown","32259635":"markdown","6dc27f1b":"markdown"},"source":{"17739aee":"import gc\nimport json\nimport torch\nimport itertools\nimport time\nimport datetime\nimport random\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport numpy.ma as ma\n\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler, random_split\n\n#from transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom transformers import AdamW \nfrom transformers import get_linear_schedule_with_warmup\n\nfrom sklearn.model_selection import train_test_split\n#from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\n","68ea3cb0":"train_file = '..\/input\/cs39aa-yelp-reviews\/train_val_test.csv'\n\nMAX_LENGTH = 300","5462b5b7":"train_data = pd.read_csv(train_file)\nprint(f'train data shape: {train_data.shape}')","4a82f376":"train_data.describe()","f821d6e6":"labels_in_index_order = ['negative', 'positive']\ntrain_data['label'] = train_data['rating'].apply(labels_in_index_order.index)\ntrain_data.describe()","75c8fac4":"train_data.head()","3bf02869":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n                                                           #num_labels=2,\n                                                           #max_position_embeddings=785,\n                                                           output_attentions=False,\n                                                           output_hidden_states=False)","7534583b":"X = train_data.review.values # X and y are both numpy arrays\ny = train_data.label.values\nprint(X.shape)\nprint(y.shape)","cc27003e":"print('original: \\n', X[0])\n\nprint('\\n\\ntokenized: \\n', tokenizer.tokenize(X[0]))\nprint('len(tokenized(X[0])): \\n', len(tokenizer.tokenize(X[0])))\n\nprint('\\n\\ntoken IDs: \\n', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[0])))","84a3dcc9":"observed_max_len = 0\n\n# For every sentence...\nfor exc in X:\n\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n    input_ids = tokenizer.encode(exc, add_special_tokens=True)\n    \n    # Update the maximum sentence length.\n    observed_max_len = max(observed_max_len, len(input_ids))\n\nprint('Max sentence length: ', observed_max_len) # max len in training data is 314, but 256 will fully cover most observations","ca648d8a":"# Tokenize all of excerpts and map their tokens to their word IDs\ninput_ids = []\nattention_masks = []\n\n# For every sentence...\nfor exc in X:\n    # `encode_plus` will:\n    #   (1) Tokenize the sentence.\n    #   (2) Prepend the `[CLS]` token to the start.\n    #   (3) Append the `[SEP]` token to the end.\n    #   (4) Map tokens to their IDs.\n    #   (5) Pad or truncate the sentence to `max_length`\n    #   (6) Create attention masks for [PAD] tokens.\n    encoded_dict = tokenizer.encode_plus(\n                        exc,                       # Sentence to encode\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                        truncation = True,\n                        padding = 'max_length',\n                        max_length = MAX_LENGTH,          # Pad & truncate all sentences        \n                        #pad_to_max_length = True,\n                        return_attention_mask = True,   # Construct attn. masks\n                        return_tensors = 'pt',     # Return pytorch tensors\n                   )\n    \n    # Add the encoded sentence to the list.    \n    input_ids.append(encoded_dict['input_ids'])\n    \n    # And its attention mask (simply differentiates padding from non-padding).\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Convert the lists into tensors.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(y).float()","327fc16e":"print('original X[0]: ', X[0])\nprint('\\n\\ntoken IDs for X[0]:', input_ids[0])","a4dfcd62":"labels2 = torch.tensor([(1,0) if x == 0 else (0,1) for x in labels])\nlabels2 = labels2.long()","ff85396d":"# Combine the training inputs into a TensorDataset.\ndataset = TensorDataset(input_ids, attention_masks, labels) #.long())\n\n# Create a 85-15 train-validation split and calc sizes of each.\ntrain_size = int(0.85 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Divide the dataset by randomly selecting samples.\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","1cc90a46":"BATCH_SIZE = 32\n\n# The DataLoader needs to know our batch size for training, so we specify it \n# here. Smaller batch sizes are generally recommended for fine-tuning BERT \n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = BATCH_SIZE # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = BATCH_SIZE # Evaluate with this batch size.\n        )","29ff4090":"model.cuda()\n\n# Get all of the model's parameters as a list of tuples.\nparams = list(model.named_parameters())\n\nprint('The DistilBERT model number of layers: {}.\\n'.format(len(params)))\n\nfor i, p in enumerate(params):\n    print(\"layer {:>3}: {:<55} {:>12}\".format(i, p[0], str(tuple(p[1].size()))))","92bcfe44":"# Create our own optimizer that sets a different (much lower) learning rate for the layers \n# that are already pre-trained, and then a larger learning rate for the two final linear\n# layers that have not been trained at all (but are instead initialized to random values).\ndef create_optimizer(model):\n    named_parameters = list(model.named_parameters())    \n    \n    bert_parameters = named_parameters[:100]\n    classifier_parameters = named_parameters[100:]\n        \n    bert_group = [params for (name, params) in bert_parameters]\n    classifier_group = [params for (name, params) in classifier_parameters]\n\n    parameters = []\n\n    #for layer_num, (name, params) in enumerate(bert_parameters):\n    for name, params in bert_parameters:        \n        lr = 1e-5\n        parameters.append({\"params\": params,\n                           \"lr\": lr})\n\n    #for layer_num, (name, params) in enumerate(regressor_parameters):\n    for name, params in classifier_parameters:\n        lr = 1e-3 \n        parameters.append({\"params\": params,\n                           \"lr\": lr})\n\n    return AdamW(parameters)","984c77fd":"criterion = nn.MSELoss()\n\n#optimizer = AdamW(model.parameters(),\n#                  lr = 1e-5, # args.learning_rate - default is 5e-5\n#                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n#                )\noptimizer = create_optimizer(model)","96008b56":"EPOCHS = 4\n\n# Number of training epochs does not need to be a lot for fine-tuning, \n# recommendations for BERT models are between 2-4\n\n# Total number of training steps is [number of batches] x [number of epochs]. \n# (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * EPOCHS\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","ce394323":"def format_time(elapsed):\n    ''' Convert time in seconds and returns a string hh:mm:ss '''\n    elapsed_rounded = int(round((elapsed)))\n    return str(datetime.timedelta(seconds=elapsed_rounded))","0dfd3284":"demo_inputs = tokenizer(\"this restaurant was okay\", return_tensors='pt')\ndemo_label = torch.tensor([1])\noutputs = model(**demo_inputs.to(device), labels=demo_label.to(device))\noutputs","69cca5ce":"# Set the seed value all over the place to make this reproducible.\nseed_val = 1\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\ntorch.set_default_dtype(torch.float64)\n\n# We'll store a number of quantities such as training and validation loss, \n# validation accuracy, and timings.\ntraining_stats = []\n\n# Measure the total training time for the whole run.\ntotal_t0 = time.time()\n\n# For each epoch...\nfor epoch_i in range(0, EPOCHS):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    \n    # Perform one full pass over the training set.\n\n    print(\"\")\n    print('======== Epoch {:} \/ {:} ========'.format(epoch_i + 1, EPOCHS))\n    print('Training...')\n\n    # Measure how long the training epoch takes.\n    t0 = time.time()\n\n    # Reset the total loss for this epoch.\n    total_train_loss = 0\n\n    # Put the model into training mode. Don't be mislead--the call to \n    # `train` just changes the *mode*, it doesn't *perform* the training.\n    # `dropout` and `batchnorm` layers behave differently during training\n    # vs. test (source: https:\/\/stackoverflow.com\/questions\/51433378\/what-does-model-train-do-in-pytorch)\n    model.train()\n\n    # For each batch of training data...\n    y_train = {'actual':[], 'predicted':[]}\n    for step, batch in enumerate(train_dataloader):\n\n        # Progress update every 40 batches.\n        if step % 25 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n        # `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks, not needed for DistilBERT\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_labels = batch[2].long().to(device)\n\n        # Always clear any previously calculated gradients before performing a\n        # backward pass. PyTorch doesn't do this automatically because \n        # accumulating the gradients is sometimes desired \n        model.zero_grad()        \n\n        # Perform a forward pass (evaluate the model on this training batch).        \n        outputs = model(b_input_ids, \n                        labels=b_labels)\n\n        # Accumulate the training loss over all of the batches so that we can\n        # calculate the average loss at the end. `loss` is a Tensor containing a\n        # single value; the `.item()` function just returns the Python value \n        # from the tensor.\n        total_train_loss += outputs[0].item()\n\n        # Perform a backward pass to calculate the gradients.\n        #loss = criterion(outputs[1].flatten(), b_labels.float())#.sqrt()\n        loss = criterion(outputs[1].softmax(dim=-1)[:,1], b_labels.float())#.sqrt()\n        \n        # backpropagation\n        loss.backward()\n        \n        # for plotting results later on\n        y_train['actual'] += b_labels.float().cpu().numpy().flatten().tolist()\n        y_train['predicted'] += outputs[1].softmax(dim=-1)[:,1].detach().cpu().numpy().flatten().tolist()\n\n        # Clip the norm of the gradients to 1.0.\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters and take a step using the computed gradient.\n        # The optimizer dictates the \"update rule\"--how the parameters are\n        # modified based on their gradients, the learning rate, etc.\n        optimizer.step()\n\n        # Update the learning rate.\n        scheduler.step()\n        \n    # Calculate the average loss over all of the batches.\n    avg_train_loss = total_train_loss \/ len(train_dataloader)            \n    \n    # Measure how long this epoch took.\n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epoch took: {:}\".format(training_time))\n        \n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n    # Put model in evaluation mode (don't calculate gradients, no dropout, etc.)\n    model.eval()\n\n    # Tracking variables \n    total_eval_loss = 0\n\n    # Evaluate data for one epoch\n    y_val = {'actual':[], 'predicted':[]}\n    for step, batch in enumerate(validation_dataloader):\n                \n        # Progress update every 40 batches.\n        if step % 5 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n        \n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using \n        # the `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks, not needed for DistilBERT\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_labels = batch[2].long().to(device)\n        \n        # Tell pytorch not to bother with constructing the compute graph during\n        # the forward pass, since this is only needed for backprop (training).\n        with torch.no_grad():        \n\n            # Forward pass, calculate predictions\n            outputs = model(b_input_ids, \n                            labels=b_labels)\n\n        # Accumulate the validation loss.\n        loss = outputs[0]\n        total_eval_loss += loss.item()\n        \n        # Move labels\/targets and predictions to CPU\n        preds = outputs[1].softmax(dim=-1)[:,1].detach().cpu().numpy()\n        targets = b_labels.to('cpu').numpy()\n        \n        # for plotting results later on\n        y_val['actual'] += targets.flatten().tolist()\n        y_val['predicted'] += preds.flatten().tolist()\n\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss \/ len(validation_dataloader)\n    \n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n    \n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","a98af0f5":"#outputs[1][:,1].unsqueeze(0)\n#b_labels\noutputs[1].softmax(dim=-1)[:,1]\n\nlen(y_val['actual'])","322c9acd":"train_acc = accuracy_score(y_train['actual'], [1 if y > 0.5 else 0 for y in y_train['predicted']])\nvalid_acc = accuracy_score(y_val['actual'], [1 if y > 0.5 else 0 for y in y_val['predicted']])\nprint(f\"DistilBERT model training MSE = {train_acc:.6f}\")\nprint(f\"DistilBERT model validation MSE = {valid_acc:.6f}\")","b54e04da":"training_losses = [epoch_stats['Training Loss'] for epoch_stats in training_stats]\nvalidation_losses = [epoch_stats['Valid. Loss'] for epoch_stats in training_stats]\nplt.plot(range(1,len(training_losses)+1), training_losses, c='r')\nplt.plot(range(1,len(validation_losses)+1), validation_losses, c='b')\nplt.xticks(range(1, len(training_losses)+1))\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()","e1a22586":"## Imports\n\nNearly identical to the CommonLit Deep Learning Model. However, now that we are doing classification (instead of regression), we will imort accuracy_score instead of mean_squared_error. ","7c8687be":"Accuracy close to 96%, so a bit better than what we saw with the other models. This is still with the smaller dataset too, which could improve accuracy further (as well as for the other models too). ","32259635":"Instantiate the tokenizer and model. Note that the CommonLit Deep Learning model also used DistilBERT, except that it was regression, so we used 'num_labels = 1' for a single numerical output from the final layer. \n\nNow, however, we are doing classification, so we use 'num_labels=2'. This means that the final layer in the model will have two outputs, which we'll then run manually through softmax ourselves to get two probabilities (the first probability is the model's predicted probability that the label should be negative, and the second probability is the model's predicted probability that the label should be positive). ","6dc27f1b":"# CS 39AA: Classifying Yelp Reviews w\/ a Pre-trained Model\n\n"}}