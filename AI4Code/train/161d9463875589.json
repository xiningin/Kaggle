{"cell_type":{"ae7ea9e8":"code","13d2bd44":"code","a67015ae":"code","41c0dee3":"code","30624d6f":"code","3c443810":"code","f4aa1f47":"code","5987b7cc":"code","99d4c75d":"code","b07cc116":"code","8662825a":"code","ac3ca364":"code","c762b0da":"code","ab513ab4":"code","f0a5639b":"code","1ca3f510":"code","5a24e6a1":"code","984687b8":"code","93878720":"code","c365fb11":"code","346d6206":"code","77f456f1":"code","ec37b500":"code","001f9224":"markdown"},"source":{"ae7ea9e8":"#!kaggle competitions download -c 2020-ai-exam-fashionmnist-4","13d2bd44":"#!unzip 2020-ai-exam-fashionmnist-4.zip","a67015ae":"import torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nimport pandas as pd\nimport numpy as np\n","41c0dee3":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","30624d6f":"learning_rate = 0.001\ntraining_epochs = 15\nbatch_size = 100","3c443810":"train_data = pd.read_csv('..\/input\/2020-ai-exam-fashionmnist-4\/mnist_train_label.csv', header = None)\ntest_data = pd.read_csv('..\/input\/2020-ai-exam-fashionmnist-4\/mnist_test.csv', header = None, usecols=range(1, 785))","f4aa1f47":"test_data","5987b7cc":"train_data","99d4c75d":"x_train_data = train_data.loc[:, 1:784]\ny_train_data = train_data.loc[:, 0]\n\n#\ub370\uc774\ud130 \uc815\uaddc\ud654\nx_train_data = x_train_data\/255\nx_train_data","b07cc116":"  \nx_train_data = np.array(x_train_data)\ny_train_data = np.array(y_train_data)\nx_train_data = torch.FloatTensor(x_train_data)\ny_train_data = torch.LongTensor(y_train_data)","8662825a":"train_dataset =  torch.utils.data.TensorDataset(x_train_data, y_train_data)","ac3ca364":"data_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                          batch_size=batch_size, \n                                          shuffle = True, \n                                          drop_last = True)","c762b0da":"linear1 = torch.nn.Linear(784,256, bias = True)\nlinear2 = torch.nn.Linear(256,256, bias = True)\nlinear3 = torch.nn.Linear(256,128, bias = True)\nlinear4 = torch.nn.Linear(128,128, bias = True)\nlinear5 = torch.nn.Linear(128,10, bias = True)\nReLU = torch.nn.ReLU()\ndropout = torch.nn.Dropout(p=0.3)","ab513ab4":"torch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)\ntorch.nn.init.xavier_normal_(linear4.weight)\ntorch.nn.init.xavier_normal_(linear5.weight)","f0a5639b":"model = torch.nn.Sequential(linear1, ReLU,dropout,\n                            linear2, ReLU,dropout,\n                            linear3, ReLU,dropout,\n                            linear4, ReLU,dropout,\n                            linear5).to(device)","1ca3f510":"loss = torch.nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)","5a24e6a1":"total_batch = len(data_loader)\nfor epoch in range(training_epochs):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n\n    avg_cost += cost\/total_batch\n  print(epoch+1)\n  print(avg_cost)\nprint(\"f\")","984687b8":"with torch.no_grad():\n  test_data.loc[:, 783] = 0\n  x_test = test_data.loc[:,:]\n  x_test = x_test\/255\n  x_test = np.array(x_test)\n  x_test = torch.from_numpy(x_test).float().to(device)\n  prediction = model(x_test)\n  correct = torch.argmax(prediction, 1)\ncorrect","93878720":"correct = correct.cpu().numpy().reshape(-1, 1)\ncorrect","c365fb11":"submit = pd.read_csv('..\/input\/2020-ai-exam-fashionmnist-4\/submission.csv')\nsubmit","346d6206":"for i in range(len(correct)):\n  submit['Category'][i] = correct[i].item()\nsubmit","77f456f1":"submit.to_csv('submission.csv', index = False, header = True)","ec37b500":"#!kaggle competitions submit -c 2020-ai-exam-fashionmnist-4 -f submit.csv -m \"result\"","001f9224":"!pip uninstall kaggle<br>\n!pip install --upgrade pip<br>\n!pip install kaggle==1.5.6<br>\n!mkdir -p ~\/.kaggle<br>\n!cp kaggle.json ~\/.kaggle<br>\n!ls -lha kaggle.json<br>\n!chmood 600 ~\/.kaggle\/kaggle.json<br>"}}