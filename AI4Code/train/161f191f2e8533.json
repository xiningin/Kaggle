{"cell_type":{"68e942f6":"code","ff625e57":"code","0baf3504":"code","14a4f928":"code","7749aaf1":"code","cad4893b":"code","e562eda4":"code","bd3e7ddb":"code","5f7a9a23":"code","fe0b6a56":"code","da1b727e":"code","e64374ce":"code","44715cf3":"code","6455d563":"code","5a927b75":"code","72f9d729":"code","3ba7257c":"code","14e0e649":"code","4b667f9f":"code","c7b3e208":"code","ed32ab29":"code","53372e84":"code","2cc6d245":"code","f283a9d2":"code","bed8a007":"code","e7b37f63":"code","b4af81c1":"code","2ca1222f":"code","742c31a1":"code","a514653e":"code","fd7d401a":"code","384b3e7e":"code","bf683fd9":"code","c3d3a693":"code","d66544a0":"code","098c70ca":"code","1f80daa4":"code","1543b608":"code","1b97cc3c":"code","6a558127":"code","5daccceb":"code","84f6282f":"code","a3823e0c":"code","5b8b42e3":"markdown","82f79e7a":"markdown","27801469":"markdown","88c0452c":"markdown"},"source":{"68e942f6":"import time\nimport numpy as np\nimport pandas as pd\nimport pandas_datareader as pdr\n\nfrom keras.layers import LSTM\nfrom keras.models import Sequential\nfrom keras.layers.wrappers import TimeDistributed\nfrom keras.layers.core import Dense, Activation, Dropout\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","ff625e57":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import *\n\n\nimport xgboost as xgb\n\n\nfrom sklearn.preprocessing import PowerTransformer\n\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels import tsa\nfrom scipy import stats\n\nimport sys, os\nimport random \n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\n    \nfrom IPython import display, utils\n\n\ndef set_seed(seed=2020):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\nset_seed()","0baf3504":"import pandas_datareader as pdr\ndef get_raw_data(index_name,retry_attempts = 3):   \n    if index_name:\n        while retry_attempts > 0 :\n            try:\n                df = pdr.get_data_yahoo(index_name)\n                new_df = df.reindex(index=pd.date_range(df.index.min(), \n                                          df.index.max(), \n                                          freq='D')).fillna(method='ffill')\n                retry_attempts = 0\n                return new_df\n            except:\n                print(\"Data pull failed. {} retry attempts remaining\".\\\n                      format(retry_attempts))\n                retry_attempts = retry_attempts - 1\n    else:\n        print(\"Invalid usage. Parameter index_name is required\")\n    return None","14a4f928":"sp_df = get_raw_data('^GSPC')\nsp_close_series = sp_df.Close\nsp_close_series.plot(figsize=(15, 7), color = 'teal')\nsp_df.head()","7749aaf1":"sp_df.info()","cad4893b":"sp_df.reset_index(inplace=True)\nsp_df","e562eda4":"sp_df.columns","bd3e7ddb":"sp_df.columns = ['Date', 'High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close']\n\nsp_df.head()","5f7a9a23":"sp_df.Date.min(), sp_df.Date.max()","fe0b6a56":"feats = ['Date', 'Close', 'Volume']\ntrain= sp_df[feats].copy()\ntrain.head()","da1b727e":"ts_series = train.Close","e64374ce":"from pylab import rcParams\nrcParams['figure.figsize'] = 17,15\nrcParams['lines.color'] = 'teal'\n\n\nresult = seasonal_decompose(ts_series, model='additive', period=30)\nsns.set()\n\nplt.style.use('bmh')\nresult.plot()\n\nplt.show()","44715cf3":"train.Date.dtypes","6455d563":"train['year'] = train.Date.dt.year\ntrain['month'] = train.Date.dt.month\ntrain['day'] = train.Date.dt.day\ntrain['week']=train.Date.dt.week\ntrain['quarter']=train.Date.dt.quarter\ntrain.head()","5a927b75":"train['month_block'] = train['year'].astype(str) + train['month'].astype(str)\ntrain.head(20)","72f9d729":"train['week_block'] = train['year'].astype(str) + train['month'].astype(str) + train['week'].astype(str)\ntrain.head(20)","3ba7257c":"train['month_block'].unique().size","14e0e649":"train['week_block'].unique().size","4b667f9f":"x = train.groupby(['week_block'])['Close'].mean().rename('mean_Close').reset_index()\n#x.sort_values(['month','cinema_code'], inplace = True)\nx.head()","c7b3e208":"x.shape","ed32ab29":"x.week_block.min(), x.week_block.max()","53372e84":"def build_lagandroll(df,target,  width = [2, 3]):\n    \n\n    for c in width:\n        shifted = target.shift(c)\n        df['lag_'+str(c)] = shifted\n        window = target.rolling(window=c)\n        dataframe = pd.concat([window.min(), window.mean(), window.max(), window.std()], axis=1)\n        dataframe.columns = ['roll'+str(c)+'_min', 'roll'+str(c)+'_mean', 'roll'+str(c)+'_max', 'roll'+str(c)+'_var']\n        df = pd.concat([df, dataframe], axis=1)\n    return df\n\ntarget = x.pop('mean_Close')\n\ndf = build_lagandroll(x, target, width=[1, 2,3, 5])\n\ndf.shape, df.week_block.unique().size, ","2cc6d245":"sns.set()\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 7))\nsns.distplot(target,bins=50, fit=norm, kde=True, color='teal')","f283a9d2":"sns.set()\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 7))\nsns.distplot(np.sqrt(target),bins=50, fit=norm, kde=True, color='m')","bed8a007":"(df.head(10))","e7b37f63":"df.shape","b4af81c1":"le = LabelEncoder()\ndf['week_block'] = le.fit_transform(df.week_block.astype(str))\ndf.week_block.head()","2ca1222f":"df.week_block.describe()","742c31a1":"df = pd.concat([df, target], axis=1)\ntrain = df.copy()\ntrain = train[train.week_block < 300]\ny_train = train.pop('mean_Close')\n\nval = df.copy()\nval =  val[val.week_block >= 300 ]\ny_val = val.pop('mean_Close')\n\ntrain.shape, y_train.shape, val.shape, y_val.shape","a514653e":"del train['week_block']\ndel val['week_block']","fd7d401a":"import xgboost as xgb\n\n\ndxtrain = xgb.DMatrix(train, label=y_train)\ndxtest = xgb.DMatrix(val, label=y_val)\n\nxgb_params = {\n    'objective': 'reg:linear',  # error evaluation for multiclass training\n    'booster':'gbtree',\n    'max_depth':5,\n    \n    'eta':0.01, \n    'subsample':0.7,\n    'colsample_bytree':0.7,\n    #'lambda':2, \n    'alpha':2,\n    'gamma':1\n}\nxgb_params['eval_metric'] = ['rmse']\nnum_rounds = 2000\nwatchlist  = [(dxtrain,'train'), (dxtest,'test')]\nmodel = xgb.train(xgb_params, dxtrain, num_rounds, watchlist, verbose_eval=100, early_stopping_rounds=150)","384b3e7e":"print(model.best_ntree_limit)\nxgb_pred = model.predict(dxtest,ntree_limit=model.best_ntree_limit)","bf683fd9":"xgb_pred","c3d3a693":"y_val","d66544a0":"plt.style.use('fivethirtyeight')\n\nplt.figure(figsize=(20, 6))\nplt.plot(val.index, y_val, 'k', label = 'Actuals', linewidth=7)\nplt.plot(val.index, xgb_pred, 'darkred', label = 'Predicted', linewidth=7)","098c70ca":"TRAIN_PERCENT = 0.9\ndef get_seq_train_test(time_series, scaling=True,train_size=0.9):\n    scaler = None\n    if scaling:\n        scaler = MinMaxScaler(feature_range=(0, 1))\n        time_series = np.array(time_series).reshape(-1,1)\n        scaled_stock_series = scaler.fit_transform(time_series)\n    else:\n        scaled_stock_series = time_series\n        \n    train_size = int(len(scaled_stock_series) * train_size)\n\n    train = scaled_stock_series[0:train_size]\n    test = scaled_stock_series[train_size:len(scaled_stock_series)]\n    \n    return train,test,scaler \n\n\ntrain,test,scaler = get_seq_train_test(sp_close_series,\n                                   scaling=True,\n                                   train_size=TRAIN_PERCENT)\n\ntrain = np.reshape(train,(1,train.shape[0],1))\ntest = np.reshape(test,(1,test.shape[0],1))\n\ntrain_x = train[:,:-1,:]\ntrain_y = train[:,1:,:]\n\ntest_x = test[:,:-1,:]\ntest_y = test[:,1:,:]\n\nprint(\"Data Split Complete\")\n\nprint(\"train_x shape={}\".format(train_x.shape))\nprint(\"train_y shape={}\".format(train_y.shape))\nprint(\"test_x shape={}\".format(test_x.shape))\nprint(\"test_y shape={}\".format(test_y.shape))","1f80daa4":"VERBOSE = True\ndef get_seq_model(hidden_units=7,input_shape=(1,1),verbose=False):\n    # create and fit the LSTM network\n    model = Sequential()\n    # samples*timesteps*featuress\n\n    model.add(LSTM(input_shape=input_shape, \n                   units = hidden_units, \n                   return_sequences=True\n    ))\n    \n    # readout layer. TimeDistributedDense uses the same weights for all\n    # time steps.\n    model.add(TimeDistributed(Dense(1)))\n    start = time.time()\n    \n    model.compile(loss=\"mse\", optimizer=\"adam\")\n    \n    if verbose:\n        print(\"> Compilation Time : \", time.time() - start)\n        print(model.summary())\n        \n    return model\n\n\n\n\nseq_lstm_model=None\ntry:\n    seq_lstm_model = get_seq_model(input_shape=(train_x.shape[1],1),\n                                                verbose=VERBOSE)   \nexcept:\n    print(\"Model Build Failed. Trying Again\")\n    seq_lstm_model = get_seq_model(input_shape=(train_x.shape[1],1),\n                                                verbose=VERBOSE)\n","1543b608":"seq_lstm_model.fit(train_x, train_y, \n               epochs=150, batch_size=8, \n               verbose=1)\nprint(\"Model Fit Complete\")","1b97cc3c":"import math\nfrom sklearn.metrics import mean_squared_error\ntrainPredict = seq_lstm_model.predict(train_x)\ntrainScore = math.sqrt(mean_squared_error(train_y[0], trainPredict[0]))\nprint('Train Score: %.2f RMSE' % (trainScore))","6a558127":"from keras.preprocessing.sequence import pad_sequences\n\ntestPredict = pad_sequences(test_x,\n                                maxlen=train_x.shape[1],\n                                padding='post',\n                                dtype='float64')\n","5daccceb":"testPredict = seq_lstm_model.predict(testPredict)\n\n# evaluate performances\ntestScore = math.sqrt(mean_squared_error(test_y[0], \n                                         testPredict[0][:test_x.shape[1]]))\nprint('Test Score: %.2f RMSE' % (testScore))","84f6282f":"trainPredict = scaler.inverse_transform(trainPredict.reshape(-1, 1))#trainPredict.shape[1]))\ntestPredict = scaler.inverse_transform(testPredict.reshape(-1, 1))#testPredict.shape[1]))","a3823e0c":"train_size = len(trainPredict)+1\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(20, 10))\nplt.plot(sp_close_series.index,\n         sp_close_series.values,c='grey',\n         alpha=0.5,label='True Data')\nplt.plot(sp_close_series.index[1:train_size],\n         trainPredict,label='Training Fit', c='k')\nplt.plot(sp_close_series.index[train_size+1:],\n         testPredict[:test_x.shape[1]],label='Testing Forecast', c='darkred', linewidth=4)\nplt.title('Forecast Plot')\nplt.legend()\nplt.show()","5b8b42e3":"## **Frequency: Week**","82f79e7a":"### Building blocks for downsampling","27801469":"# **sTOCK pRICE**","88c0452c":"## **Sequence Modeling**"}}