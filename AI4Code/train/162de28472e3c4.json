{"cell_type":{"075e8a30":"code","da35ccce":"code","31bceaf7":"code","6182dd8f":"code","c40fd418":"code","cf633a69":"code","b004604d":"code","991e8ee2":"code","b36c29a2":"code","e701cdc4":"code","82a3d238":"code","7ffc7380":"code","9ffee4dd":"code","a08f1a75":"code","43387b3f":"code","f1efff4a":"code","6e0785af":"code","45846254":"code","35ffe3e3":"code","44d4fa0f":"markdown","1ac7cbe5":"markdown","2464a70b":"markdown","111c0d5d":"markdown"},"source":{"075e8a30":"######################################################################################\n# Lets see what people have to say about zomato's IPO by Applying some nlp skills    #\n######################################################################################\n\n# making neccessary import \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')","da35ccce":"# lets load and inspect the data\ndataFrame = pd.read_csv('\/kaggle\/input\/tweets-about-zomatoipo\/zomato-ipo.csv')\ndataFrame.info()","31bceaf7":"cleanFrame = dataFrame[['date', 'username', 'tweet', 'language', 'likes_count', 'retweets_count', 'hashtags']]\ncleanFrame.info()","6182dd8f":"cleanFrame","c40fd418":"print('A little summary is as follow:')\nprint('* There are {} unique users who tweeted '.format(len (set (cleanFrame['username']))))\nprint('* This means {} % tweets are unique'.format( 100 *len (set (cleanFrame['username'])) \/ len(cleanFrame)))\nprint('* of these tweets {} % were in English'.format( 100 *len ((cleanFrame[cleanFrame['language'] == 'en'])) \/ len(cleanFrame)))\n\nmaxLiked = max(dataFrame['likes_count'])\nprint()\nprint( '* The most like tweet was like {} times'.format(maxLiked))\nprint('The most liked tweet is as follows ahem:')\nprint(dataFrame[dataFrame['likes_count'] == maxLiked]['tweet'].values[0])\nprint()\n\nmaxRetweeted = max(dataFrame['retweets_count'])\nprint('* The most retweeted tweet was tweeted {} times'.format(maxRetweeted))\nprint('which read as follows: ')\nprint(dataFrame[dataFrame['retweets_count'] == maxRetweeted]['tweet'].values[0])","cf633a69":"# de-emojify \nimport re\ndef deEmojify(text):\n    regrex_pattern = re.compile(pattern = \"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           \"]+\", flags = re.UNICODE)\n    return regrex_pattern.sub(r'',text)","b004604d":"## Assumption to keep this analysis simple we will only be analyzing englis tweets\ncleanFrame = cleanFrame[cleanFrame['language'] == 'en']\n\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : a.replace('[', ''))\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : a.replace(']', ''))\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : a.replace('\\'', ''))\n# Functions for deEmojifying\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : deEmojify(a))\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : re.sub(\"[^a-zA-Z0-9]+\", ' ', a))\n\n# removes hyperlinks\ncleanFrame['hashtags'] = cleanFrame['hashtags'].apply(lambda a : re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', a, flags=re.MULTILINE))","991e8ee2":"hashTags = []\nfor mem in cleanFrame['hashtags']:\n    mems = mem.split(',')\n    for member in mems:\n        hashTags.append(member)\n\nhashTags = list(set(hashTags))","b36c29a2":"# lets start visualizations by plotting word clouds\n# World Cloud Plotter\nfrom wordcloud import WordCloud, STOPWORDS \nstopwords = set(STOPWORDS) \n\ndef WordCloudForSentiments (corpus, title):\n    wordcloud = WordCloud(width = 800, height = 800,background_color ='grey',\n                          stopwords = stopwords,  min_font_size = 10).generate(corpus)\n    \n    plt.figure(figsize = (12, 12), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.rcParams.update({'font.size': 25})\n    plt.axis(\"off\") \n    plt.title('Word Cloud:  ' + title)\n    plt.tight_layout(pad = 0) \n  \n    plt.show() ","e701cdc4":"WordCloudForSentiments( ''.join(hashTags),'WordCloud:hashtags' )","82a3d238":"# lets clean the tweets using the same functions above:\ncleanFrame['tweet'] = cleanFrame['tweet'].apply(lambda a : deEmojify(a))\ncleanFrame['tweet'] = cleanFrame['tweet'].apply(lambda a : re.sub(\"[^a-zA-Z0-9]+\", ' ', a))\ncleanFrame['tweet'] = cleanFrame['tweet'].apply(lambda a : re.sub(r'^https?:\\\/\\\/.*[\\r\\n]*', '', a, flags=re.MULTILINE))","7ffc7380":"# with the tweets data cleaned lets build a corpus\ntweetCorpus = ''\nfor tweet in cleanFrame['tweet']:\n    tweetCorpus +=  (tweet + ' ')    # adding a space to seperate tweets","9ffee4dd":"#Plotting tweet corpus\nWordCloudForSentiments( ''.join(tweetCorpus),'WordCloud:tweets' )","a08f1a75":"#  A Function for Sentiment Analysis\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\ndef SentimentAnlysis(sentence):\n    sentAnalyzer = SentimentIntensityAnalyzer() \n    sentDict = sentAnalyzer.polarity_scores(sentence)\n    \n    if sentDict['compound'] >= 0.05:\n        return \"positive\"\n    elif sentDict['compound'] <= -0.05 :\n        return \"negative\"\n    else:\n        return \"neutral\"","43387b3f":"# lets do sentiment analyis now\nfrom tqdm import tqdm\nsentiment = []\n\nfor tweet in  tqdm (cleanFrame['tweet']):\n    sentiment.append(SentimentAnlysis(tweet))","f1efff4a":"# lets append this to our dataFrame and continue our analysis\ncleanFrame['sentiments'] = sentiment\n\n# A pie chart for understanding postive, negatives and neutral tweets\n\nnumPostives = len(cleanFrame[cleanFrame['sentiments'] == 'positive'])\nnumNegatives = len(cleanFrame[cleanFrame['sentiments'] == 'negative'])\nnumNeutrals  = len(cleanFrame[cleanFrame['sentiments'] == 'neutral'])\n\nplt.figure(figsize = (7, 7))\nplt.pie([numPostives, numNegatives, numNeutrals], labels = ['positives', 'negatives', 'neutrals'], autopct='%1.2f%%')\nplt.title('Twitter Sentiments on Zomato IPO')","6e0785af":"# lets do one thing more and try to see who the sentiment in changing with time\ncleanFrame['date']= pd.to_datetime(cleanFrame['date'])","45846254":"# Now each unique date collect Positive, negative, and neutral tweets\ndates = set(cleanFrame['date'])\npositivesOndate = []\nnegativesOndate = []\nneutralsOndate  = []\nda              = []\n\nfor date in dates:\n    pos = len (cleanFrame[(cleanFrame['date'] == date) & (cleanFrame['sentiments'] == 'positive')])\n    neg = len (cleanFrame[(cleanFrame['date'] == date) & (cleanFrame['sentiments'] == 'negative')])\n    neu = len (cleanFrame[(cleanFrame['date'] == date) & (cleanFrame['sentiments'] == 'neutral')])\n    \n    positivesOndate.append(pos)\n    negativesOndate.append(neg)\n    neutralsOndate.append(neu)\n    da.append( str(date))","35ffe3e3":"# let plot this info\nplt.figure(figsize=(10, 7))\nplt.plot( positivesOndate, label = 'Postive Sentiments' )\nplt.plot( negativesOndate, label = 'Negative Sentiments')\nplt.plot( neutralsOndate, label = 'Neutral Sentiments ')\nplt.ylabel('Number of tweets on that day')\nplt.xlabel('Days passed')\nplt.title('Zomato IPO Sentiment timeSeries')\nplt.legend()\nplt.show()\n","44d4fa0f":"It seems folks have a pretty postive outlook for Zomato IPO, although I believe more neutrals should in be either postive\nor negatives, but this essentially catches the sentiment.","1ac7cbe5":"Let's first make sure that the data is not baised anyhow by checking the unique usernames.","2464a70b":"Lets perform some data cleaning to have a better insight!!\nThe parameters the seems relevant for our analysis are date, username (because lets be sure no one is creating hype, by tweeting a particular sentiment message), tweet, language, like_count, retweet count, hashtags(lets take these as well)","111c0d5d":"Before we proceed to word clouds and data clean lets go through the hashtags firts."}}