{"cell_type":{"f2947cd2":"code","a07bdecc":"code","65d194e4":"code","b08af785":"code","9a590ed2":"code","082bc50b":"code","15724b0f":"code","2d03d1ff":"code","68495f50":"code","d3d030b0":"code","d69c5644":"code","506d9679":"code","f1ba9382":"code","b51c3c78":"code","7178a55d":"code","fe2af8a5":"code","be946101":"code","db32e8f2":"code","00f8f72e":"code","bd4accff":"code","109df17f":"code","6f4a5b85":"code","fcb3cbfc":"code","76d8735d":"code","0e0944ed":"code","72359b66":"code","522a6767":"code","d0c30e39":"code","9f1e4396":"code","b69dd903":"code","d42f934b":"markdown","08ab32b0":"markdown","d6e0c339":"markdown","63fee1f7":"markdown","da91c271":"markdown","50b05b83":"markdown","30a3b030":"markdown","2341b072":"markdown","9932f975":"markdown","352aeb2b":"markdown","88a1f006":"markdown","0cc47678":"markdown","a53a7082":"markdown","a88e965d":"markdown","d1f8d4e0":"markdown"},"source":{"f2947cd2":"import findspark\nfindspark.init()","a07bdecc":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, count, udf\nfrom pyspark.ml.feature import RegexTokenizer, CountVectorizer, \\\n    IDF, StopWordsRemover, StringIndexer\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.sql.types import IntegerType\n\nimport re","65d194e4":"spark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"Sentiment Analysis\") \\\n    .getOrCreate()","b08af785":"path = 'data\/amazon-alexa-reviews.tsv'","9a590ed2":"df = spark.read.option(\"sep\", \"\\t\") \\\n    .option(\"header\", \"true\") \\\n    .csv(path)","082bc50b":"df.show(3)","15724b0f":"df.toPandas().info()","2d03d1ff":"df.groupBy('rating').agg(count('rating')).orderBy('rating').show()","68495f50":"label_col = udf(lambda x: int((x =='5')|(x=='4')), IntegerType())  \ndf = df.withColumn('classe', label_col(df.rating))\ndf.show(1)","d3d030b0":"dfn = df.drop(*['date', 'variation', 'feedback'])","d69c5644":"dfn.show(3)","506d9679":"def preprocessor(text):\n    text = re.sub('<[^>]*>', '', str(text))\n    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n        ' '.join(emoticons).replace('-', '')\n    return text","f1ba9382":"preprocessor_udf = udf(preprocessor)","b51c3c78":"dfn = dfn.withColumn('prepared_reviews', preprocessor_udf(col('verified_reviews')))","7178a55d":"dfn.show(3)","fe2af8a5":"# diviser le texte en mots s\u00e9par\u00e9s\nregexTokenizer = RegexTokenizer(inputCol=\"prepared_reviews\", outputCol=\"mots\", pattern=\"\\\\W\")\ndfn = regexTokenizer.transform(dfn)","be946101":"dfn.show(1)","db32e8f2":"# supprimer les mots vides\nremover = StopWordsRemover(inputCol='mots', outputCol='mots_clean')\ndfn = remover.transform(dfn).select('rating', 'mots_clean')","00f8f72e":"dfn.show(2)","bd4accff":"# trouver le terme fr\u00e9quences des mots\ncv = CountVectorizer(inputCol=\"mots_clean\", outputCol=\"TF\")\ncvmodel = cv.fit(dfn)\ndfn = cvmodel.transform(dfn)\ndfn.take(1)","109df17f":"# trouver le Inter-document Frequency\nidf = IDF(inputCol=\"TF\", outputCol=\"features\")\nidfModel = idf.fit(dfn)\ndfn = idfModel.transform(dfn)\ndfn.head()","6f4a5b85":"# cr\u00e9er la colonne d'\u00e9tiquette\nindexer = StringIndexer(inputCol=\"classe\", outputCol=\"label\")","fcb3cbfc":"data = df.drop(*['date', 'variation', 'feedback'])\ndata = data.withColumn('prepared_reviews', preprocessor_udf(col('verified_reviews')))","76d8735d":"# Divisez le jeu de donn\u00e9es au hasard en ensembles de formation et de test\n(trainingData, testData) = data.randomSplit([0.7, 0.3], seed = 100)","0e0944ed":"# cr\u00e9er le pipeline\nnb = NaiveBayes(smoothing=1.0)\npipeline = Pipeline(stages=[regexTokenizer, remover, cv, idf, indexer, nb])","72359b66":"# \u00e9xecuter les \u00e9tapes du pipeline et former le modele\nmodel = pipeline.fit(trainingData)","522a6767":"# Faire des pr\u00e9dictions sur testData \n#afin que nous puissions mesurer la pr\u00e9cision de notre mod\u00e8le sur de nouvelles donn\u00e9es\npredictions = model.transform(testData)","d0c30e39":"evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\\\n            metricName=\"accuracy\")","9f1e4396":"accuracy = evaluator.evaluate(predictions)\nprint(\"Model Accuracy: \", accuracy)","b69dd903":"spark.stop()","d42f934b":"Ce qui nous int\u00e9resse sont les deux colonnes `rating` et `verified_reviews`.  Donc nous allons v\u00e9rifier si ces deux colonnes contient d\u00e9ja des valeurs null.","08ab32b0":"## 1. Introduction:","d6e0c339":"Pour \u00e9valuer notre modele nous allons utiliser `Evaluator` de `MulticlassClassification`.","63fee1f7":"On remarque que les rating du 5 \u00e9toiles domine le dataset.  \nMaintenant nous pouvons nous d\u00e9barrasser des colonnes inutiles:","da91c271":"Perfecto! aucune valeur null.  \nPour comparer le nombre des `rating`:","50b05b83":"Maintenant nous allons cr\u00e9er les 2 classes des sentiment:\n0. => Sentiment N\u00e9gatif (1-3 \u00e9toiles)\n1. => Sentiment Positif (4-5 \u00e9toiles)","30a3b030":"Dans ce cahier, nous utiliserons le framework Spark pour construire un mod\u00e8le d'analyse des sentiments bas\u00e9 sur l'algorithme Naive Bayes.","2341b072":"Dans cette partie, nous allons extraire les features n\u00e9cessaires pour l'apprentisage de notre model \u00e0 partir de la colonne `verified_reviews`.  \nMais avant \u00e7a nous allons pr\u00e9parer nos donn\u00e9es, en supprimant les tags HTML, les mots vides (et, dans ..), d\u00e9placer les emojis \u00e0 la fin du texte, et transformer le texte en miniscule.","9932f975":"## 1. Chargement des donn\u00e9es","352aeb2b":"## 4. Cr\u00e9er le ML Pipeline","88a1f006":"# TP: Sentiment Analyst -  Naive Bayes","0cc47678":"Bon, une pr\u00e9cision de `90%` sur ce simple dataset n'est pas mauvais. ","a53a7082":"## 3. Extraction des features","a88e965d":"L'ensemble de donn\u00e9es est un avis de plusieurs utilisateurs sur le bot Amazon Alexa, o\u00f9 chaque ligne a un `review` et un `rating` (de 1 \u00e0 5 \u00e9toiles) et d'autres colonnes.  \nLien pour t\u00e9l\u00e9charger les donn\u00e9es: [Data Source](https:\/\/www.kaggle.com\/sid321axn\/amazon-alexa-reviews#amazon_alexa.tsv)","d1f8d4e0":"Apr\u00e9s d\u00e9finir tout les fonctions n\u00e9caissaires pour traiter notre dataset, nous allons les enchainer dans un pipeline pour construire notre modele."}}