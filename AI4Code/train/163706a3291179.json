{"cell_type":{"0164e829":"code","186c7e1a":"code","c2293a22":"code","e616bfeb":"code","d39ac1a1":"code","d3a92db0":"code","8fdf2339":"code","fefa5f57":"code","649728f5":"code","79a15bd1":"code","3b335433":"code","2b162566":"code","cb626d0e":"code","1fb2d808":"markdown"},"source":{"0164e829":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","186c7e1a":"df=pd.read_csv('\/kaggle\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv')\ndf.drop(['education'],axis=1,inplace=True)\ndf.head()","c2293a22":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(),annot=True,cmap=plt.cm.plasma)","e616bfeb":"df.info()","d39ac1a1":"df = df.apply(lambda x: x.fillna(x.mean()),axis=0)\ndf.isnull().sum(axis = 0)","d3a92db0":"sns.pairplot(df)","8fdf2339":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(df.drop(['TenYearCHD'],axis=1),df['TenYearCHD'],test_size=0.2,random_state=4)","fefa5f57":"from sklearn.linear_model import LogisticRegression\nLR=LogisticRegression(max_iter=1650)\nLR.fit(X_train,y_train)\nyhat=LR.predict(X_test)","649728f5":"from sklearn.metrics import accuracy_score,confusion_matrix\naccuracy_score(yhat,y_test)","79a15bd1":"ax=confusion_matrix(yhat,y_test)\nsns.heatmap(ax,annot=True,cmap=plt.cm.plasma)","3b335433":"from sklearn.neighbors import KNeighborsClassifier","2b162566":"def KNeigh(X_train,X_test,y_train,y_test):\n    score=[]\n    \n    for i in range(1,10):\n        KN=KNeighborsClassifier(n_neighbors=i)\n        KN.fit(X_train,y_train)\n        yhat=KN.predict(X_test)\n        score.append(accuracy_score(yhat,y_test))\n    max_score=max(score)\n    max_score_index=score.index(max_score)+1\n    print(f\"Max accuracy of the model is: {max_score} when n_neighbors: {max_score_index}\")","cb626d0e":"KNeigh(X_train,X_test,y_train,y_test)","1fb2d808":"# Conclusion:\n\n**Both model shows acuuracy of around 0.85. Hence both models are best suited for this problem.**"}}