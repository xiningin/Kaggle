{"cell_type":{"d82cdd23":"code","a82c54bc":"code","14157058":"code","a45cf468":"code","29189ca7":"code","128cfb4d":"code","8ff90074":"code","b3d32755":"code","7dc310cf":"code","b062e5b6":"code","e5febbdb":"code","b62dfe98":"code","a440e563":"code","0cea9976":"code","2a8fbd60":"code","fa7c6105":"code","944906bd":"code","bdbfbab5":"code","491e6adb":"code","b57f92a3":"code","05c08e67":"code","06177b27":"code","fd7eda1b":"code","6f492190":"code","035634c5":"code","059081ca":"code","db774c9c":"code","e0311fad":"code","f8242cf7":"code","1fb9ae05":"code","814818a3":"markdown","498edbf6":"markdown","520678c3":"markdown","cc9131a0":"markdown","0955ace7":"markdown"},"source":{"d82cdd23":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a82c54bc":"data = pd.read_csv('..\/input\/california-housing-prices\/housing.csv')\ndata.head()","14157058":"data.shape","a45cf468":"data.info()","29189ca7":"data.ocean_proximity.value_counts()","128cfb4d":"data.ocean_proximity.hist()","8ff90074":"data.describe()","b3d32755":"import matplotlib.pyplot as plt\ndata.hist(bins=20, figsize=(20,15))\nplt.show()","7dc310cf":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(data, test_size=0.2,\nrandom_state=21)","b062e5b6":"data[\"income_cat\"] = pd.cut(data[\"median_income\"],bins=[0., 1.5, 3.0, 4.5, 6., np.inf],labels=[1, 2, 3, 4, 5])","e5febbdb":"data.income_cat.hist()","b62dfe98":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(data, data[\"income_cat\"]):\n    strat_train_set = data.loc[train_index]\n    strat_test_set = data.loc[test_index]","a440e563":"strat_test_set[\"income_cat\"].value_counts() \/ len(strat_test_set)","0cea9976":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)","2a8fbd60":"housing = strat_train_set.copy()\ncorrelation = housing.corr()","fa7c6105":"import seaborn as sns\n# uncommment below code to check heatmap before applying any operation on dataframe\n# plt.figure(figsize=(10,10))\n# sns.heatmap(correlation,cbar=True, square=True, fmt='1.4f', annot=True, annot_kws={'size':10})","944906bd":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"]\/housing[\"households\"]\nhousing[\"bedrooms_per_room\"] =housing[\"total_bedrooms\"]\/housing[\"total_rooms\"]\nhousing[\"population_per_household\"]=housing[\"population\"]\/housing[\"households\"]","bdbfbab5":"correlation2 = housing.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(correlation2,cbar=True, square=True, fmt='1.4f', annot=True, annot_kws={'size':10})","491e6adb":"housing = strat_train_set.drop(\"median_house_value\", axis=1)\nhousing_labels = strat_train_set[\"median_house_value\"].copy()","b57f92a3":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\nhousing_num = housing.drop(\"ocean_proximity\", axis=1)","05c08e67":"from sklearn.base import BaseEstimator, TransformerMixin\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, households_ix]\n        population_per_household = X[:, population_ix] \/ X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)","06177b27":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nnum_pipeline = Pipeline([\n                        ('imputer', SimpleImputer(strategy=\"median\")),\n                        ('attribs_adder', CombinedAttributesAdder()),\n                        ('std_scaler', StandardScaler()),])\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","fd7eda1b":"housing_num_df = pd.DataFrame(data=housing_num_tr)\nhousing_num_df.head()","6f492190":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\nfull_pipeline = ColumnTransformer([\n(\"num\", num_pipeline, num_attribs),\n(\"cat\", OneHotEncoder(), cat_attribs),\n])\nhousing_prepared = full_pipeline.fit_transform(housing)","035634c5":"temp = pd.DataFrame(data= housing_prepared)","059081ca":"temp.shape","db774c9c":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","e0311fad":"# housing.iloc[2,3:6]","f8242cf7":"some_data = housing.iloc[:5]\nsome_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions:\", lin_reg.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))\n","1fb9ae05":"from sklearn.metrics import mean_squared_error\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","814818a3":"Below cell will plot 9 numerical data in the form of histogram","498edbf6":"data.info() gives information about data set like number of values it contain and data type\nhere all column contain 20640 values **except** *total_bedrooms* column which contain 20433 values (it contain null values).\nAll values contain float64 datatypes except *ocean_proximity* that is object type","520678c3":"Let dig more into this data set and try to retrieve more information by excuting describe() function","cc9131a0":"We have 20640 data points and 10 features in the form of column","0955ace7":"Counting the categorical values"}}