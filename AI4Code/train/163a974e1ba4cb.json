{"cell_type":{"da1797d4":"code","3e5c5f85":"code","9a496d6f":"code","4ebec229":"code","7ff4581b":"code","5ca5dca7":"code","1d858a44":"code","f13d1402":"code","a8b04844":"code","f5405365":"code","b7ba4ae8":"code","f2621fc3":"code","cfb9350c":"code","1bc5a572":"code","368e3546":"code","d8a70f42":"code","2c685c67":"code","2b5d873a":"code","bf526cd3":"code","89226d3b":"markdown","570015f5":"markdown","e7b2764e":"markdown","5d733043":"markdown","656b8498":"markdown","37fbda3f":"markdown","bab26655":"markdown","97aba36a":"markdown","0e29a6d7":"markdown","2ea962e3":"markdown","6e7124ae":"markdown","07b6cb27":"markdown","eb07cb77":"markdown","6632650d":"markdown","ea28583e":"markdown","19cf43f3":"markdown","729ee9d1":"markdown","e9d2597f":"markdown","8c80fc92":"markdown","e4ca86b7":"markdown","93eaa9e3":"markdown"},"source":{"da1797d4":"import pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.optimizers as O\nimport tensorflow.keras.losses as Loss\n\nfrom tqdm import tqdm\n\nfrom PIL import Image\nimport cv2\n\nimport matplotlib.pyplot as plt","3e5c5f85":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n  try:\n    tf.config.experimental.set_virtual_device_configuration(\n        gpus[0],\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=15240)])\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)","9a496d6f":"BATCH_SIZE = 800\nEPOCHS = 1\nDIM =(100,100)\nMAX_LENGTH = 20","4ebec229":"sampl = pd.read_csv('..\/input\/bms-molecular-translation\/sample_submission.csv')","7ff4581b":"test_path = '..\/input\/bms-molecular-translation\/test'\nfor i in tqdm(range(len(sampl))):\n    image_id = sampl.image_id.values[i]\n    sampl.image_id.values[i] = test_path+'\/'+image_id[0]+'\/'+image_id[1]+'\/'+image_id[2]+'\/'+image_id+'.png'\nsampl.head()","5ca5dca7":"detokens = {0: 'S', 1: 'B', 2: 'N', 3: 'I', 4: 'F', 5: 'P', 6: '3', 7: '6', 8: 'i', 9: '5', 10: '8', 11: 'C', 12: '7', 13: '4', 14: 'r', 15: '0', 16: '2', 17: 'O', 18: '9', 19: 'H', 20: 'l', 21: '$', 22: '1'} \nprint(detokens)","1d858a44":"def preprocess_test_image(image_id):\n    image = tf.io.read_file(image_id)    \n    image = tf.image.decode_png(image,channels=1)\n    def f1(): return tf.image.rot90(image,k=3)\n    def f2(): return image\n    image = tf.cond(tf.less(tf.shape(image)[1],tf.shape(image)[0]),f1,f2)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize_with_pad(image, DIM[0],DIM[1])\n    return image","f13d1402":"#     image = tf.io.read_file('..\/input\/bms-molecular-translation\/train\/0\/0\/0\/000011a64c74.png')\n#     image = tf.image.decode_png(image,channels=1)\n#     print(tf.shape(image))","a8b04844":"test_data = tf.data.Dataset.from_tensor_slices(sampl.image_id.values).map(preprocess_test_image,num_parallel_calls=tf.data.AUTOTUNE).batch(2048).prefetch(tf.data.AUTOTUNE)","f5405365":"model = M.load_model('..\/input\/trained-model-for-bmsmolecular\/phase1_base_model_v1.4.h5')","b7ba4ae8":"def detokenize(pred):\n    string_d = []\n    for i in range(len(pred)):\n        a = []\n        for j in range(len(pred[i])):\n            if pred[i][j] in detokens.keys():\n                a.append(detokens[pred[i][j]])\n            else:\n                a.append(str(pred[i][j]-47))\n        a = \"\".join(a)\n        string_d.append(a)\n    return string_d","f2621fc3":"pred = model.predict(test_data,verbose=1)\n","cfb9350c":"pred = np.argmax(pred,axis=-1)","1bc5a572":"pred = detokenize(pred)\npred = np.char.strip(pred,chars='$')","368e3546":"sampl.InChI = pred","d8a70f42":"for i in tqdm(range(len(sampl.image_id.values))):\n    sampl.image_id.values[i] = sampl.image_id.values[i][46:58]","2c685c67":"text = '\/c1-18(2,3)24-17(22)21-10-6-8-14(21)15-11-13(20-25-15)12-7-5-9-19-16(12)23-4\/h5,7,9,11,14H,6,8,10H2,1-4H3'\nsampl.InChI = sampl.InChI.values+text","2b5d873a":"sampl.head()","bf526cd3":"sampl.to_csv('submission.csv',index=False)","89226d3b":"### Batch Size, Epochs, input image dimensions and max length of the target sequence is defined here.","570015f5":"# Loading test data","e7b2764e":"Removing the file path from the image id column of the data","5d733043":"This function is utilized to detokenize the prediction using the detokens dictionary","656b8498":"## Setting global variables","37fbda3f":"This function preprocesses the data before loading the image to the GPU for predictions. In this function the image is loaded directly during prediction reducing the use of the available RAM as it would be nearly impossible to load that much data in the current provided RAM size before prerdiction. This function is utilized during prediction to preprocess the data when fetched.","bab26655":"Here tf.data.Dataset is utlized to fetch the data on the go instead of preloading the data in the RAM which would be nearly impossible given the current available RAM size. This function only loads the batch size amount of data in the memory and preprocesses the data on the go using the above function. Also, prefetch is used here that prefetches some data before hand to minimize bottleneck and improves spped.","97aba36a":"# Inference ","0e29a6d7":"Since the predictions are in range between 0 and 1 and the output activation was sigmoid so we are using argmax function to find the index of the maximum value in the axis, then the data is detokenized using the detokenize function and then the padded token is removed from the detokenized predicted sequences","2ea962e3":"**This code is an Inference code to find the training details check out this kaggle notebook** <a href=\"https:\/\/www.kaggle.com\/sambhavsg\/bms-baseline-inchi-first-layer-train-tf-keras?scriptVersionId=62450249\">BMS Baseline InChI first layer Train TF Keras<\/a> \n","6e7124ae":"# Import Modules","07b6cb27":"## Post Processing","eb07cb77":"## Prediction","6632650d":"InChI or International Chemical Identifier is a textual identifier for chemical substances, designed to provide a standard way to encode molecular information and to facilitate the search for such information in databases and on the web.","ea28583e":"# Loading Pretrained Model","19cf43f3":"<h1><center>Bristol-Myers Squibb - Molecular Translation<\/center><\/h1>","729ee9d1":"This is baseline for the first layer of the InChI notation so the other layers are set the same for all values.","e9d2597f":"## Importing and preprcocessing train data","8c80fc92":"# Loading and Preprocessing Data","e4ca86b7":"### Image path is added to the image id column of the data to load the image for inference","93eaa9e3":"During training tokens were defined to tokenize the input data labels. Now, in order to detokenize the data a detokens dictionary is created. This dictionary will be sued later in this code to interpret the predictions and detokenize the predicted values."}}