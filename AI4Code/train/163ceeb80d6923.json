{"cell_type":{"62fe1e87":"code","3edd4040":"code","dcaf508b":"code","899b1843":"code","a12892fc":"code","aebfc199":"code","324f2ef2":"code","3a6efb73":"code","489b62e8":"code","c9113f03":"code","0bb2a9c6":"code","424890dd":"code","70a4dad7":"code","2692b098":"code","fee69309":"code","a4196d76":"code","5e602588":"code","f6593645":"code","507f0344":"code","450f97ab":"code","a4c46b68":"code","7ae54bc9":"code","ed98abd3":"code","8945599e":"code","641bdf74":"code","34967c98":"code","e8ad6591":"code","3552d87b":"code","4ac64b7f":"code","385d211c":"code","970bcc94":"code","6aad7991":"code","914cf4d4":"code","4e52edbd":"code","8f0a7abd":"code","8e3fb30e":"code","fb885d0d":"code","f8f92b7b":"code","58dbb48f":"code","5b9421b7":"code","50d8c807":"code","a4dcf6b5":"code","baa11fff":"code","638a4ea9":"code","0bb90463":"code","c3f0c897":"code","63658be9":"code","0c24700a":"code","15759b4b":"code","2e250b27":"code","58ac3ba7":"code","90eebc85":"code","241faa5b":"code","650e8ce5":"code","be290eaa":"code","b801364e":"code","6f5fc6d7":"code","8fa59bae":"code","c9ee88f2":"code","afd90ad9":"code","b6288f56":"code","19e3d41c":"code","ba23d333":"code","bc780738":"code","b35f1f6b":"code","83c9163f":"code","a88e3e02":"code","12e8d82a":"code","8bd6e86b":"code","a77a617e":"markdown","a42be40e":"markdown","141d9439":"markdown","9ec1b92e":"markdown","9fb00ddf":"markdown","56f20135":"markdown","aa503fb4":"markdown","255cfcac":"markdown","1280f21f":"markdown"},"source":{"62fe1e87":"# Evaluating Student Writing \n# The classes being predicted are 'Claim','Counterclaim','Evidence','Position','Rebuttal','Concluding Statement' \n#and 'Lead'\n\n# Built this model using BERT. Starting with the 'bert-base-cased' model \n# I had also build a simple BOW model and TFIDF but the model was struggling with identifying certain classes \n# especially CounterClaims and Rebuttals (understandable given the types of words in them). \n# Initial testing with BERT has looked better.\n# I had also trained a BERT based model with just 5 classes - removed 'Concluding Statement' and 'Lead' from the train set\n# with a minor improvement in accuracy. The accuracy improvement was  not enough to justify a separate model.\n# This one uses all seven classes in one model\n\n# One area I am struggling with is classifying text as \"Evidence\". \"Evidence\" texts tend to be large bodies of text \n# with  Positions and Claims in the body. Often times, individual sentences get classified as Claims. \n# The prediction model returns a list of Probabilities and, in a lot of the cases, for text which is Evidence,\n# the second highest Probability has the correct one. Perhaps the output would be more accurate if I could provide \n# a couple of predictions for each piece of text. (That is against the rules of the Competition though)\n\n# Noticing a similar issue with \"Lead\" text though not as severe\n\n# Running this on Kaggle GPU and starting with the 'bert-base-cased' model","3edd4040":"# !pip install transformers --upgrade --quiet","dcaf508b":"import transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n#from transformers import AutoModel, AutoTokenizer\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader","899b1843":"%matplotlib inline","a12892fc":"RANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","aebfc199":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","324f2ef2":"#load training data\ndf = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv')\ndf[\"text_length\"] = df[\"discourse_text\"].str.len()","3a6efb73":"codes = {'Claim':0, 'Counterclaim':1, 'Evidence':2, 'Position':3, 'Rebuttal':4, 'Concluding Statement':5, 'Lead':6 }\ndf['discourse_type_num'] = df['discourse_type'].map(codes)\ndf.head()","489b62e8":"df.info()","c9113f03":"df.groupby(\"discourse_type\").text_length.mean().plot.bar(ylim=0, title=\"Average text Length by type\")","0bb2a9c6":"df.groupby(\"discourse_type\").discourse_type.count().plot.bar(ylim=0, title=\"Count of data points by Class\")","424890dd":"# see one essay\ndf_DBF7EB6A9E02 = df.loc[df.id.isin(['DBF7EB6A9E02'])]\ndf_DBF7EB6A9E02","70a4dad7":"fn = '\/kaggle\/input\/feedback-prize-2021\/train\/DBF7EB6A9E02.txt'\nwith open(fn) as f:\n    contents = f.read()\n    print(contents)","2692b098":"df_Conclusion = df.loc[df.discourse_type.isin(['Concluding Statement'])]\ndf_Conclusion.head(15)","fee69309":"max(df.text_length)","a4196d76":"plt.hist(df.text_length,  bins=500)  \nplt.ylabel('Count')\nplt.xlabel('Length of text');","5e602588":"# max length is 4099 but most are <100.\n#I'm a bit torn about what length to choose. Leads seem to be very long strings of text. So does Evidence\n# I might have trouble identifying Leads. Looking at some samples, Leads can be anything from a \n# couple of paragraphs up front to no Lead at all with the writer jumping straight into a Position.\n# I tried an initial model droping Leads and Conclusions from the corpus. This includes all the classes in one model\n#Pad to 100 words (tokens) and truncate ","f6593645":"MAX_LEN = 100\nBATCH_SIZE = 16","507f0344":"df_final = df\ndf.shape, df_final.shape","450f97ab":"# keeping case helps keep some info.\nPRE_TRAINED_MODEL_NAME = 'bert-base-cased'","a4c46b68":"tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","7ae54bc9":"#create a Dataset\nclass MyDataset(Dataset):\n\n  def __init__(self, inputtext, targets, tokenizer, max_len):\n    self.inputtext = inputtext\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_len = max_len\n\n  def __len__(self):\n    return len(self.inputtext)\n\n  def __getitem__(self, item):\n    inputtext = str(self.inputtext[item])\n    target = self.targets[item]\n    encoding = self.tokenizer.encode_plus(\n      inputtext,\n      add_special_tokens=True,\n      max_length=self.max_len,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      truncation=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n\n    return {\n      'input_text': inputtext,\n      'input_ids': encoding['input_ids'].flatten(),\n      'attention_mask': encoding['attention_mask'].flatten(),\n      'targets': torch.tensor(target, dtype=torch.long)\n    }","ed98abd3":"df_train, df_test = train_test_split(\n  df_final,\n  test_size=0.1,\n  random_state=42,\n  stratify=df_final.discourse_type.values\n)\n\ndf_val, df_test = train_test_split(\n  df_test,\n  test_size=0.5,\n  random_state=42,\n  stratify=df_test.discourse_type.values\n)","8945599e":"df_train.groupby(\"discourse_type\").discourse_type.count().plot.bar(ylim=0, title=\"Count of data points by Class\")","641bdf74":"df_train.shape, df_val.shape, df_test.shape","34967c98":"def create_data_loader(df, tokenizer, max_len, batch_size):\n\n  ds = MyDataset(\n    inputtext=df.discourse_text.to_numpy(),\n    targets=df.discourse_type_num.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )","e8ad6591":"train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)","3552d87b":"class TheClassifier(nn.Module):\n\n  def __init__(self, n_classes):\n    super(TheClassifier, self).__init__()\n    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n\n  def forward(self, input_ids, attention_mask):\n    returned = self.bert(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n    )\n    pooled_output = returned[\"pooler_output\"]\n    output = self.drop(pooled_output)\n    return self.out(output)","4ac64b7f":"device","385d211c":"model = TheClassifier(7) # classifying to one of Claim, CounterClaim, Evidence, Position, Rebuttal, Concluding Statement, Lead\nmodel = model.to(device)","970bcc94":"EPOCHS = 10\n\noptimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss().to(device)","6aad7991":"def train_epoch(\n  model,\n  data_loader,\n  loss_fn,\n  optimizer,\n  device,\n  scheduler,\n  n_examples\n):\n\n  model = model.train()\n  losses = []\n\n  correct_predictions = 0\n\n  for d in data_loader:\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    _, preds = torch.max(outputs, dim=1)\n    loss = loss_fn(outputs, targets)\n    correct_predictions += torch.sum(preds == targets)\n    losses.append(loss.item())\n    loss.backward()\n\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    \n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n\n  return correct_predictions.double() \/ n_examples, np.mean(losses)","914cf4d4":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n  losses = []\n  correct_predictions = 0\n\n  with torch.no_grad():\n    for d in data_loader:\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      _, preds = torch.max(outputs, dim=1)\n\n      loss = loss_fn(outputs, targets)\n\n      correct_predictions += torch.sum(preds == targets)\n\n      losses.append(loss.item())\n\n  return correct_predictions.double() \/ n_examples, np.mean(losses)","4e52edbd":"%%time\nhistory = defaultdict(list)\n\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n  print(f'Epoch {epoch + 1}\/{EPOCHS}')\n  print('-' * 10)\n  train_acc, train_loss = train_epoch(\n    model,\n    train_data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    len(df_train)\n  )\n\n  print(f'Train loss {train_loss} accuracy {train_acc}')\n\n  val_acc, val_loss = eval_model(\n    model,\n    val_data_loader,\n    loss_fn,\n    device,\n    len(df_val)\n  )\n\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\n  print()\n\n  history['train_acc'].append(train_acc)\n  history['train_loss'].append(train_loss)\n  history['val_acc'].append(val_acc)\n  history['val_loss'].append(val_loss)\n\n  if val_acc > best_accuracy:\n    torch.save(model.state_dict(), '\/kaggle\/working\/best_model_state.bin')\n    best_accuracy = val_acc","8f0a7abd":"print('Done')","8e3fb30e":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.ylim([0, 1]);","fb885d0d":"#lead best model\nmodel_best = TheClassifier(7)","f8f92b7b":"m = torch.load('\/kaggle\/working\/best_model_state.bin')","58dbb48f":"model_best.load_state_dict(m)","5b9421b7":"tokenizer.save_pretrained('\/kaggle\/working\/saved_model\/')","50d8c807":"# Specify a path\nPATH = \"\/kaggle\/working\/saved_model\/whole_model.pt\"\n\n# Save\ntorch.save(model_best, PATH)","a4dcf6b5":"model_best = model_best.to(device)","baa11fff":"test_acc, _ = eval_model(\n  model_best,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\ntest_acc.item()","638a4ea9":"def get_predictions(model, data_loader):\n  model = model.eval()\n  input_texts = []\n  predictions = []\n  prediction_probs = []\n  real_values = []\n\n  with torch.no_grad():\n    for d in data_loader:\n      texts = d[\"input_text\"]\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      _, preds = torch.max(outputs, dim=1)\n      input_texts.extend(texts)\n      predictions.extend(preds)\n      prediction_probs.extend(outputs)\n      real_values.extend(targets)\n\n  predictions = torch.stack(predictions).cpu()\n  prediction_probs = torch.stack(prediction_probs).cpu()\n  real_values = torch.stack(real_values).cpu()\n  return input_texts, predictions, prediction_probs, real_values","0bb90463":"y_input_texts, y_pred, y_pred_probs, y_test = get_predictions(\n  model_best,\n  test_data_loader\n)","c3f0c897":"class_names = ['Claim','Counterclaim','Evidence','Position','Rebuttal','Concluding Statement','Lead']\nprint(classification_report(y_test, y_pred, target_names=class_names))","63658be9":"input_text = \"The most detrimental outcome is death.\" #Claim\n#input_text = \"In conclusion, drivers should not be able to use\"","0c24700a":"encoded_text = tokenizer.encode_plus(\n  input_text,\n  max_length=MAX_LEN,\n  add_special_tokens=True,\n  return_token_type_ids=False,\n  pad_to_max_length=True,\n  truncation=True,\n  return_attention_mask=True,\n  return_tensors='pt',\n)","15759b4b":"input_ids = encoded_text['input_ids'].to(device)\nattention_mask = encoded_text['attention_mask'].to(device)\noutput = model_best(input_ids, attention_mask)\n\n_, prediction = torch.max(output, dim=1)\n\nprint(f'Review text: {input_text}')\nprint(f'Class  : {class_names[prediction]}')","2e250b27":"_, preds = torch.topk(output, 2)","58ac3ba7":"print(f'Predicted Class  : {class_names[preds[0,0].tolist()]}')\nprint(f'Second Predicted Class  : {class_names[preds[0,1].tolist()]}')\n\n#class_names[preds[0,0].tolist()], class_names[preds[0,1].tolist()]","90eebc85":"output.shape","241faa5b":"print(output)","650e8ce5":"def file_split_train(fname):\n    df_file = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\n    #print(fname)\n    fn = '\/kaggle\/input\/feedback-prize-2021\/train\/' + fname +'.txt'\n    #print(fn)\n    with open(fn) as f:\n        contents = f.read()\n        #print(contents)\n    #print(contents)\n    curr_index = 0\n    after_split_by_newline = contents.split('\\n')\n    for para in after_split_by_newline:\n        if (len(para) > 0):\n            after_split_by_period = para.split(\". \")\n            #print(after_split_by_period)\n            #print(len(s))\n            for sent in  after_split_by_period:\n                if (len(sent) > 0):\n                    sent_with_period = sent + '. '\n                    index_list = ''\n                    split_by_space = sent.split(' ')\n                    for wrd in split_by_space:\n                        index_list = index_list + str(curr_index) + ' '\n                        curr_index = curr_index + 1\n                    #print(index_list)\n                    #print(len(phr))\n                    df_file.loc[len(df_file.index)] = [fname, \"\", index_list, sent_with_period] \n    return(df_file)","be290eaa":"def file_split(fname):\n    df_file = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\n    #print(fname)\n    fn = '\/kaggle\/input\/feedback-prize-2021\/test\/' + fname +'.txt'\n    #print(fn)\n    with open(fn) as f:\n        contents = f.read()\n        #print(contents)\n    #print(contents)\n    curr_index = 0\n    after_split_by_newline = contents.split('\\n')\n    for para in after_split_by_newline:\n        if (len(para) > 0):\n            after_split_by_period = para.split(\". \")\n            #print(after_split_by_period)\n            #print(len(s))\n            for sent in  after_split_by_period:\n                if (len(sent) > 0):\n                    sent_with_period = sent + '. '\n                    index_list = ''\n                    split_by_space = sent.split(' ')\n                    for wrd in split_by_space:\n                        index_list = index_list + str(curr_index) + ' '\n                        curr_index = curr_index + 1\n                    #print(index_list)\n                    #print(len(phr))\n                    df_file.loc[len(df_file.index)] = [fname, \"\", index_list, sent_with_period] \n    return(df_file)","b801364e":"df_submission_train = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\ndf_submission_train = df_submission_train.append(file_split_train('A97DE0D49AEA'))\ndf_submission_train = df_submission_train.append(file_split_train('DBF7EB6A9E02'))\ndf_submission_train","6f5fc6d7":"class_names = ['Claim','Counterclaim','Evidence','Position','Rebuttal','Concluding Statement','Lead']","8fa59bae":"file_names = []\nfile_names.append('A97DE0D49AEA')\nfile_names.append('DBF7EB6A9E02')","c9ee88f2":"file_names ","afd90ad9":"# Make Predictions From Train\ndf_out = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\",\"raw_output\",\"seondaryclass\"])\n\nfor fnm in file_names:\n    df_split = df_submission_train.loc[(df_submission_train.id == fnm)].reset_index()\n    o_index_list = ''\n    o_input_text = ''\n    reached_conc = False\n    ctr = 0\n    for index, row in df_split.iterrows():\n        input_text = row['phrase']\n        prev_index_list = row['predictionstring']\n        ctr = ctr + 1\n        #call model\n        #output = torch.randn(1, 7)\n        \n        encoded_text = tokenizer.encode_plus(\n              input_text,\n              max_length=MAX_LEN,\n              add_special_tokens=True,\n              return_token_type_ids=False,\n              pad_to_max_length=True,\n              truncation=True,\n              return_attention_mask=True,\n              return_tensors='pt',\n        )\n        input_ids = encoded_text['input_ids'].to(device)\n        attention_mask = encoded_text['attention_mask'].to(device)\n        output = model(input_ids, attention_mask)\n        _, preds = torch.topk(output, 2)\n        curr_pred = class_names[preds[0,0].tolist()]  #\"Claim\"\n        sec_pred = class_names[preds[0,1].tolist()] #\"Evidence\"\n        if (curr_pred == \"Concluding Statement\"):\n            reached_conc = True\n        if(reached_conc):\n            curr_pred = \"Concluding Statement\"\n            o_index_list = o_index_list + prev_index_list \n            o_input_text = o_input_text + input_text\n        else:\n            df_out.loc[len(df_out.index)] = [fnm, curr_pred, prev_index_list , input_text, output, sec_pred] \n        #if (ctr == 10):\n            #curr_pred = \"Concluding Statement\"\n            #print(curr_pred)\n    if(reached_conc):\n        df_out.loc[len(df_out.index)] = [fnm, \"Concluding Statement\", o_index_list , o_input_text, \"\", \"\"] ","b6288f56":"df_out","19e3d41c":"df_out.to_csv('\/kaggle\/working\/out-tain_set.csv', index=False)","ba23d333":"df_submission = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\"])\n#df_submission = df_submission.append(file_split('A97DE0D49AEA'))\n#df_submission = df_submission.append(file_split('DBF7EB6A9E02'))\n\nfile_names = []\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/feedback-prize-2021\/test'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        #print(filename.split(\".\")[0])\n        DOC_ID = filename.split(\".\")[0]\n        fn = '\/kaggle\/input\/feedback-prize-2021\/test\/' + DOC_ID +'.txt'\n        file_names.append(DOC_ID)\n        #file_split(DOC_ID)\n        df_submission = df_submission.append(file_split(DOC_ID))\n        #with open(fn) as f:\n            #contents = f.read()\n            #print(contents)","bc780738":"df_submission","b35f1f6b":"file_names","83c9163f":"df_submission.to_csv('\/kaggle\/working\/test_sub_only_split_by_period.csv', index=False)","a88e3e02":"# Make Predictions From Test\ndf_out = pd.DataFrame(columns=[\"id\",\"class\",\"predictionstring\",\"phrase\",\"raw_output\",\"seondaryclass\"])\n\nfor fnm in file_names:\n    df_split = df_submission.loc[(df_submission.id == fnm)].reset_index()\n    o_index_list = ''\n    o_input_text = ''\n    reached_conc = False\n    ctr = 0\n    for index, row in df_split.iterrows():\n        input_text = row['phrase']\n        prev_index_list = row['predictionstring']\n        ctr = ctr + 1\n        #call model\n        #output = torch.randn(1, 7)\n        \n        encoded_text = tokenizer.encode_plus(\n              input_text,\n              max_length=MAX_LEN,\n              add_special_tokens=True,\n              return_token_type_ids=False,\n              pad_to_max_length=True,\n              truncation=True,\n              return_attention_mask=True,\n              return_tensors='pt',\n        )\n        input_ids = encoded_text['input_ids'].to(device)\n        attention_mask = encoded_text['attention_mask'].to(device)\n        output = model(input_ids, attention_mask)\n        _, preds = torch.topk(output, 2)\n        curr_pred = class_names[preds[0,0].tolist()]  #\"Claim\"\n        sec_pred = class_names[preds[0,1].tolist()] #\"Evidence\"\n        if (curr_pred == \"Concluding Statement\"):\n            reached_conc = True\n        if(reached_conc):\n            curr_pred = \"Concluding Statement\"\n            o_index_list = o_index_list + prev_index_list \n            o_input_text = o_input_text + input_text\n        else:\n            df_out.loc[len(df_out.index)] = [fnm, curr_pred, prev_index_list , input_text, output, sec_pred] \n        #if (ctr == 10):\n            #curr_pred = \"Concluding Statement\"\n            #print(curr_pred)\n    if(reached_conc):\n        df_out.loc[len(df_out.index)] = [fnm, \"Concluding Statement\", o_index_list , o_input_text, \"\", \"\"] ","12e8d82a":" df_out.to_csv('\/kaggle\/working\/submission.csv', index=False)","8bd6e86b":"df_out","a77a617e":"## Choosing MAX Sequence Length","a42be40e":"## Evaluation","141d9439":"## Run on Test Set","9ec1b92e":"## Load Train Data and EDA","9fb00ddf":"## Train","56f20135":"## Retrieve Preds for 1 piece of text","aa503fb4":"## Create a Model","255cfcac":"## Classify a piece of text","1280f21f":"## Define Datasets"}}