{"cell_type":{"a4362510":"code","6cf1e429":"code","d9f045ff":"code","ea289210":"code","4e1971a1":"code","d841cb82":"code","0eea6996":"code","9bdd731e":"code","0b9a83e3":"code","c1d14023":"code","ac5662e2":"code","88a144ca":"code","d83e02e8":"code","36a12335":"code","b205ee65":"code","369a793e":"code","ee03aacd":"code","7b6ba191":"code","91d12edc":"code","c40f501d":"code","78bd090e":"code","9568ac8b":"code","7e41075e":"code","e345c83e":"code","3d02dfa2":"code","35c512f7":"code","a0ddbcf4":"code","4bfd236b":"code","905c0b56":"code","3f1ddef7":"code","d6e1bee1":"code","95a10c44":"code","0d707159":"code","3a03f0a8":"code","25139d85":"code","612babf6":"code","6b2bd548":"code","29b0a795":"code","fab943dd":"code","11cf4fa5":"code","d8e1b2fe":"code","7c09b07c":"code","705722cf":"code","ec7cf829":"code","d43eb83c":"code","a570075e":"code","f018bd35":"code","216bd6d2":"code","210d8620":"code","9e02a8f5":"code","ff4c1fdb":"code","982bd43f":"markdown","c21ef936":"markdown","20a20e87":"markdown","07d082e5":"markdown","3e14ec1f":"markdown","a02558f1":"markdown","7a66dfb2":"markdown","6d5c5e2f":"markdown","783c93a2":"markdown","f625f15f":"markdown","4628b8f7":"markdown","fc2922a1":"markdown","69fcfed8":"markdown","f97bb2c1":"markdown"},"source":{"a4362510":"pip install -U scikit-learn","6cf1e429":"from sklearn.metrics import confusion_matrix ,classification_report,precision_score, recall_score ,f1_score, roc_curve, roc_auc_score \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","d9f045ff":"data = pd.read_csv('\/kaggle\/input\/ckdisease\/kidney_disease.csv')","ea289210":"data.head()","4e1971a1":"data.tail()","d841cb82":"data.info()","0eea6996":"data.describe()","9bdd731e":"data_num = data[['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo']]\ndata_cat = data[['rbc','pc','pcc','ba','pcv','wc','rc','htn','dm','cad','appet','pe','ane']]","0b9a83e3":"filna = data[['id', 'age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr',\n       'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n       'appet', 'pe', 'ane', 'classification']]\n","c1d14023":"for i in data_num.columns:\n    plt.hist(data_num[i])\n    plt.title(i)\n    plt.show()","ac5662e2":"print(data_num.corr())\nsns.heatmap(data_num.corr())","88a144ca":"pd.pivot_table(data, index='classification', values=['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo'])","d83e02e8":"for i in data_cat.columns:\n    sns.barplot(data_cat[i].value_counts().index,data_cat[i].value_counts()).set_title(i)\n    plt.show()","36a12335":"data_cat = data[['rbc','pc','pcc','ba','pcv','wc','rc','htn','dm','cad','appet','pe','ane']]","b205ee65":"print(data.classification.value_counts())\ndata.classification.replace(\"ckd\\t\",\"ckd\",inplace=True)\nprint(data.classification.value_counts())\nprint(\"===\"*20)\nprint(data.dm.value_counts())\ndata.dm.replace([\"\\tno\",\"\\tyes\",\" yes\"],[\"no\",\"yes\",\"yes\"],inplace=True)\nprint(data.dm.value_counts())\nprint(\"===\"*20)\nprint(data.cad.value_counts())\ndata.cad.replace([\"\\tno\"],[\"no\"],inplace=True)\nprint(data.cad.value_counts())","369a793e":"for i in data_cat:\n    print(pd.pivot_table(data,index='classification',columns=i, values='age'))\n    print(\"==\"*20)","ee03aacd":"data.rc.replace(\"\\t?\",data.rc.mode()[0], inplace=True)\ndata.rc = data.rc.apply(lambda x: float(x))\n\ndata.wc.replace(\"\\t?\",data.wc.mode()[0], inplace=True)\ndata.wc = data.wc.apply(lambda x: float(x))\n\n\ndata.pcv.replace([\"\\t?\",\"\\t43\"],data.pcv.mode()[0], inplace=True)\ndata.pcv = data.pcv.apply(lambda x: float(x))\n\ndata.classification.replace([\"ckd\",\"notckd\"],[1,0], inplace=True)","7b6ba191":"data_final_num = data[['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo','pcv','wc','rc']]\ndata_fincal_cat = data[['rbc','pc','pcc','ba','htn','dm','cad','appet','pe','ane']]","91d12edc":"for i in data_final_num.columns:\n    plt.hist(data_final_num[i])\n    plt.title(i)\n    plt.show()","c40f501d":"sns.heatmap(data_final_num.corr())","78bd090e":"pd.pivot_table(data, index='classification', values=['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo','pcv','wc','rc'])","9568ac8b":"for i in data_fincal_cat:\n    print(pd.pivot_table(data,index='classification',columns=i, values='age'))\n    print(\"==\"*20)","7e41075e":"# dealing with missing values\nfor i in filna.columns:\n    if data[i].isna().sum() > 0 :\n        if data[i].dtype == 'float64':\n            data[i].fillna(data[i].median(), inplace=True)\n        else:\n            data[i].fillna(data[i].mode()[0], inplace=True)\n","e345c83e":"# dealing with outliers values\nfor i in data_final_num.columns:\n    sns.boxplot(data_final_num[i])\n    plt.title(i)\n    plt.show()\n","3d02dfa2":"def outlinefree(dataCol):    \n    sorted(dataCol)\n    Q1,Q3 = np.percentile(dataCol,[25,75])   \n    IQR = Q3-Q1   \n    LowerRange = Q1-(1.5 * IQR)   \n    UpperRange = Q3+(1.5 * IQR)   \n    return LowerRange,UpperRange","35c512f7":"Lowage,Upage = outlinefree(data.age)\nLowbp,Upbp = outlinefree(data.bp)\nLowsg,Upsg = outlinefree(data.sg)\nLowal,Upal = outlinefree(data.al)\nLowsu,Upsu = outlinefree(data.su)\nLowbgr,Upbgr = outlinefree(data.bgr)\nLowbu,Upbu = outlinefree(data.bu)\nLowsc,Upsc = outlinefree(data.sc)\nLowsod,Upsod = outlinefree(data.sod)\nLowpot,Uppot = outlinefree(data.pot)\nLowhemo,Uphemo = outlinefree(data.hemo)\nLowpcv,Uppcv = outlinefree(data.pcv)\nLowwc,Upwc = outlinefree(data.wc)\nLowrc,Uprc = outlinefree(data.rc)","a0ddbcf4":"data.age.replace(list(data[(data.age < Lowage)].age),Lowage , inplace=True)\ndata.age.replace(list(data[(data.age > Upage)].age),Upage , inplace=True)\n\ndata.bp.replace(list(data[(data.bp < Lowbp)].bp),Lowbp , inplace=True)\ndata.bp.replace(list(data[(data.bp > Upbp)].bp),Upbp , inplace=True)\n\ndata.sg.replace(list(data[(data.sg < Lowsg)].sg),Lowsg , inplace=True)\ndata.sg.replace(list(data[(data.sg > Upsg)].sg),Upsg , inplace=True)\n\ndata.al.replace(list(data[(data.al < Lowal)].al),Lowal , inplace=True)\ndata.al.replace(list(data[(data.al > Upal)].al),Upal , inplace=True)\n\ndata.su.replace(list(data[(data.su < Lowsu)].su),Lowsu , inplace=True)\ndata.su.replace(list(data[(data.su > Upsu)].su),Upsu , inplace=True)\n\ndata.bgr.replace(list(data[(data.bgr < Lowbgr)].bgr),Lowbgr , inplace=True)\ndata.bgr.replace(list(data[(data.bgr > Upbgr)].bgr),Upbgr , inplace=True)\n\ndata.bu.replace(list(data[(data.bu < Lowbu)].bu),Lowbu , inplace=True)\ndata.bu.replace(list(data[(data.bu > Upbu)].bu),Upbu , inplace=True)\n\ndata.sc.replace(list(data[(data.sc < Lowsc)].sc),Lowbu , inplace=True)\ndata.sc.replace(list(data[(data.sc > Upsc)].sc),Upbu , inplace=True)\n\ndata.sod.replace(list(data[(data.sod < Lowsod)].sod),Lowsod , inplace=True)\ndata.sod.replace(list(data[(data.sod > Upsod)].sod),Upsod , inplace=True)\n\ndata.pot.replace(list(data[(data.pot < Lowpot)].pot),Lowpot , inplace=True)\ndata.pot.replace(list(data[(data.pot > Uppot)].pot),Uppot , inplace=True)\n\ndata.hemo.replace(list(data[(data.hemo < Lowhemo)].hemo),Lowhemo , inplace=True)\ndata.hemo.replace(list(data[(data.hemo > Uphemo)].hemo),Uphemo , inplace=True)\n\ndata.pcv.replace(list(data[(data.pcv < Lowpcv)].pcv),Lowpcv , inplace=True)\ndata.pcv.replace(list(data[(data.pcv > Uppcv)].pcv),Uppcv , inplace=True)\n\ndata.wc.replace(list(data[(data.wc < Lowwc)].wc),Lowwc , inplace=True)\ndata.wc.replace(list(data[(data.wc > Upwc)].wc),Upwc , inplace=True)\n\ndata.rc.replace(list(data[(data.rc < Lowrc)].rc),Lowrc , inplace=True)\ndata.rc.replace(list(data[(data.rc > Uprc)].rc),Uprc , inplace=True)","4bfd236b":"data_final_num2 = data[['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo','pcv','wc','rc']]","905c0b56":"for i in data_final_num2.columns:\n    sns.boxplot(data_final_num2[i])\n    plt.title(i)\n    plt.show()","3f1ddef7":"sns.pairplot(data, hue=\"classification\",corner=True)","d6e1bee1":"finaldata = data.loc[:,['classification','age','bp','sg','al','rbc','pc','pcc','ba','bgr','bu','sc','sod','pot','hemo','pcv','wc','rc','htn','dm','cad','appet','pe','ane']]","95a10c44":"final_dataset = pd.get_dummies(finaldata)","0d707159":"features = final_dataset.iloc[:,1:].values\nlabel = final_dataset.iloc[:,0].values","3a03f0a8":"#------------------------LogisticRegression-----------------------\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=112)\n\nclassimodel= LogisticRegression()  \nclassimodel.fit(X_train,y_train)\ntrainscore =  classimodel.score(X_train,y_train)\ntestscore =  classimodel.score(X_test,y_test)  \n\ny_pred =  classimodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","25139d85":"print(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\nprint(classification_report(y_test, y_pred))","612babf6":"#------------------------k-nearest neighbors (K-nn)-----------------------\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=43)\n\nKnnmodel= KNeighborsClassifier()  \nKnnmodel.fit(X_train, y_train)\ntrainscore =  Knnmodel.score(X_train,y_train)\ntestscore =  Knnmodel.score(X_test,y_test)  \n\ny_pred =  Knnmodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred),'\\n')\nprint(confusion_matrix(y_test, y_pred))","6b2bd548":"print(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\nprint(classification_report(y_test, y_pred))","29b0a795":"#------------------------naive bayes-----------------------\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=82)\n\nNBmodel=  GaussianNB()  \nNBmodel.fit(X_train, y_train)\ntrainscore =  NBmodel.score(X_train,y_train)\ntestscore =  NBmodel.score(X_test,y_test)  \n\ny_pred =  NBmodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred),'\\n')\nprint(confusion_matrix(y_test, y_pred))","fab943dd":"print(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\nprint(classification_report(y_test, y_pred))","11cf4fa5":"#------------------------support vector classification-----------------------\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=187)\n\nSVCmodel=  SVC(probability=True)  \nSVCmodel.fit(X_train, y_train)\ntrainscore =  SVCmodel.score(X_train,y_train)\ntestscore =  SVCmodel.score(X_test,y_test)  \n\ny_pred =  SVCmodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred),'\\n')\nprint(confusion_matrix(y_test, y_pred))","d8e1b2fe":"print(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\nprint(classification_report(y_test, y_pred))","7c09b07c":"#------------------------Decision Tree-----------------------\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=78)\n\nDTmodel=  DecisionTreeClassifier(max_depth=3)  \nDTmodel.fit(X_train, y_train)\ntrainscore =  DTmodel.score(X_train,y_train)\ntestscore =  DTmodel.score(X_test,y_test)  \n\ny_pred =  DTmodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred),'\\n')\nprint(confusion_matrix(y_test, y_pred))","705722cf":"print(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\nprint(classification_report(y_test, y_pred))","ec7cf829":"#------------------------Random Forest-----------------------\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=110)\n\nRFmodel=  RandomForestClassifier(criterion='entropy',max_depth=3) \nRFmodel.fit(X_train, y_train)\ntrainscore =  RFmodel.score(X_train,y_train)\ntestscore =  RFmodel.score(X_test,y_test)  \n\ny_pred =  RFmodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred),'\\n')\nprint(confusion_matrix(y_test, y_pred))","d43eb83c":"print(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\nprint(classification_report(y_test, y_pred))","a570075e":"#-------------------------------------- LogisticRegression -------------------------------------\nprobabilityValues = classimodel.predict_proba(features)[:,1]\n#Calculate AUC\nauc = roc_auc_score(label,probabilityValues)\nprint(auc)\n#Calculate roc_curve\nfpr,tpr, threshold =  roc_curve(label,probabilityValues)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.plot(fpr,tpr)","f018bd35":"#------------------------k-nearest neighbors (K-nn)-----------------------\nprobabilityValues = Knnmodel.predict_proba(features)[:,1]\n#Calculate AUC\nauc = roc_auc_score(label,probabilityValues)\nprint(auc)\n#Calculate roc_curve\nfpr,tpr, threshold =  roc_curve(label,probabilityValues)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.plot(fpr,tpr)","216bd6d2":"#-------------------------------------- naive bayes -------------------------------------\nprobabilityValues = NBmodel.predict_proba(features)[:,1]\n#Calculate AUC\nauc = roc_auc_score(label,probabilityValues)\nprint(auc)\n#Calculate roc_curve\nfpr,tpr, threshold =  roc_curve(label,probabilityValues)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.plot(fpr,tpr)","210d8620":"#-------------------------------------- support vector classification -------------------------------------\nprobabilityValues = SVCmodel.predict_proba(features)[:,1]\n#Calculate AUC\nauc = roc_auc_score(label,probabilityValues)\nprint(auc)\n#Calculate roc_curve\nfpr,tpr, threshold =  roc_curve(label,probabilityValues)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.plot(fpr,tpr)","9e02a8f5":"#-------------------------------------- Decision Tree -------------------------------------\nprobabilityValues = DTmodel.predict_proba(features)[:,1]\n#Calculate AUC\nauc = roc_auc_score(label,probabilityValues)\nprint(auc)\n#Calculate roc_curve\nfpr,tpr, threshold =  roc_curve(label,probabilityValues)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.plot(fpr,tpr)","ff4c1fdb":"#-------------------------------------- Random Forest -------------------------------------\nprobabilityValues = RFmodel.predict_proba(features)[:,1]\n#Calculate AUC\nauc = roc_auc_score(label,probabilityValues)\nprint(auc)\n#Calculate roc_curve\nfpr,tpr, threshold =  roc_curve(label,probabilityValues)\nplt.plot([0,1],[0,1], linestyle = '--')\nplt.plot(fpr,tpr)","982bd43f":"## Receiver Operating Characteristic Curve (ROC AUC)\n\nhere we will be using many algorithms and compare all of them. which algorithm will be giving us a Better result. The following algorithms are below.\n\n1. Logistic Regression (auc: 0.9997333333333333)\n2. k-nearest neighbors (auc: 0.8948933333333333)\n3. **naive bayes (auc: 1.0)**\n4. support vector classification (auc: 0.7623200000000001)\n5. DecisionTreeClassifier (auc: 0.99892)\n6. RandomForestClassifier (auc: 0.9998933333333333)","c21ef936":"## Conclusion\nI will choose a **naive bayes algorithm** for this dataset.\n\n**naive bayes score**\n\n1. **f1_score: 1.0**\n2. **auc: 1.0**","20a20e87":"## Data Normalization\n\n1. percentile(interquartile range)\n2. boxplot     ","07d082e5":"## Data Preprocessing\n1. deal with unwanted text.\n2. deal with missing values\n3. histogram\n4. heatmap\n5. pivot_table","3e14ec1f":"## Used Python Libraries","a02558f1":"## Exploratory data analysis (EDA)\n\n1) For numeric data\n\n       Made histograms to understand distributions\n       Corrplot\n       Pivot table comparing survival rate across numeric variables\n2) For Categorical Data\n\n       Made bar charts to understand balance of classes\n       Made pivot tables to understand relationship with survival","7a66dfb2":"\n![](https:\/\/i.pinimg.com\/564x\/d8\/ad\/c5\/d8adc5543f0f47ebb4e7da821f428937.jpg)","6d5c5e2f":"## Feature Engineering\n\n1. get_dummies()","783c93a2":"## Know Dataset Nature","f625f15f":"## Feature Selection\n\n1. seaborn.pairplot()","4628b8f7":"## Index\n\n1. Data Description\n2. Used Python Libraries\n3. Know Dataset Nature\n4. Exploratory data analysis (EDA)\n5. Data Preprocessing\n6. Data Normalization\n7. Feature Selection\n8. Feature engineering\n9. Model Buliding\n10. Receiver Operating Characteristic Curve (ROC AUC)\n11. conclusion","fc2922a1":"## Model Buliding\nhere we will be using many algorithms and compare all of them. which algorithm will be giving us a Better result. The following algorithms are below.\n\n1. Logistic Regression (f1 score: 0.9827586206896551 )\n2. k-nearest neighbors (f1 score: 0.8571428571428571 )\n3. **naive bayes (f1 score: 1.0)**\n4. support vector classification (f1 score: 0.7730061349693252 )\n5. **DecisionTreeClassifier (f1 score: 1.0)**\n6. **RandomForestClassifier (f1 score: 1.0)**","69fcfed8":"## Data Description:\n\nWe use the following representation to collect the dataset\n\n1. age - age\n2. bp - blood pressure\n3. sg - specific gravity\n4. al - albumin\n5. su - sugar\n6. rbc - red blood cells\n7. pc - pus cell\n8. pcc - pus cell clumps\n9. ba - bacteria\n10. bgr - blood glucose random\n11. bu - blood urea\n12. sc - serum creatinine\n13. sod - sodium\n14. pot - potassium\n15. hemo - hemoglobin\n16. pcv - packed cell volume\n17. wc - white blood cell count\n18. rc - red blood cell count\n19. htn - hypertension\n20. dm - diabetes mellitus\n21. cad - coronary artery disease\n22. appet - appetite\n23. pe - pedal edema\n24. ane - anemia\n25. class - class","f97bb2c1":"# Chronic Kidney Disease\nData has 25 feattures which may predict a patient with chronic kidney disease"}}