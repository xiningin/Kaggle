{"cell_type":{"4d86f2bc":"code","6dd4f32b":"code","8d7ebbbf":"code","62b448e1":"code","c8fa0aa9":"code","321537e0":"code","579410be":"code","79614272":"code","20cb508d":"code","c7f0698c":"code","7dc61320":"code","e321fc7d":"code","4b39432d":"code","65aeb63c":"code","5ddc51e0":"code","aa1ce50b":"code","0e7c46a8":"code","061e571c":"code","5c586f39":"code","94855b6d":"code","0b3ad207":"code","74c5d0f9":"code","e6c0921b":"code","c8a3b701":"code","3c29fd72":"code","a0752f44":"code","15332ba1":"code","ca7d7b7e":"code","8b545233":"code","f9db9483":"code","4dcfe80c":"code","87608f30":"code","82c7e0b1":"code","d76513bc":"code","b32a34d1":"markdown"},"source":{"4d86f2bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","6dd4f32b":"# Input data files are available in the \"..\/input\/\" directory.\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8d7ebbbf":"pd.set_option('display.max_columns', 200)","62b448e1":"### Load Train and Test Data\n\nprefix = '\/kaggle\/input\/home-data-for-ml-course'\n\nX = pd.read_csv(prefix + '\/train.csv', index_col='Id') \nX_test = pd.read_csv(prefix + '\/test.csv', index_col='Id')\n\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice\n\nX.drop(['SalePrice'], axis=1, inplace=True)\ntest_ids = X_test.index","c8fa0aa9":"X.info()","321537e0":"X.describe()","579410be":"X.head()","79614272":"X_test.head()","20cb508d":"### Handle Missing Values\n\ncols_with_missing = list(\n  set([col for col in X.columns if X[col].isnull().any()]) |\n  set([col for col in X_test.columns if X_test[col].isnull().any()]))\nprint('\\nColumns with missing values:\\n', cols_with_missing)\n\nmissing_val_count_by_column = X.isnull().sum()\nprint('\\nMissing values per column:\\n', missing_val_count_by_column[missing_val_count_by_column > 0])\n\ntotal_rows_count = X.shape[0] + X_test.shape[0]\nthreshold = 0.9 # 90%\ncols_missing_drop = (missing_val_count_by_column[\n    missing_val_count_by_column > total_rows_count * (1 - threshold)]).index.values\ncols_missing_impute = list(set(cols_with_missing) - set(cols_missing_drop))\nprint('\\nColumns to be dropped:\\n', cols_missing_drop)\nprint('\\nColumns to be imputed:\\n', cols_missing_impute)","c7f0698c":"X[cols_missing_drop].head()","7dc61320":"X[cols_missing_impute].head()","e321fc7d":"X.drop(cols_missing_drop, axis=1, inplace=True)\nX_test.drop(cols_missing_drop, axis=1, inplace=True)","4b39432d":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='most_frequent')\nimputed_X = pd.DataFrame(imputer.fit_transform(X))\nimputed_X_test = pd.DataFrame(imputer.transform(X_test))\n\nimputed_X.columns = X.columns\nimputed_X_test.columns = X_test.columns","65aeb63c":"#missing_val_count_by_column = (imputed_X_test.isnull().sum())\n#print('\\nNumber of missing values per column:\\n', missing_val_count_by_column[missing_val_count_by_column > 0])\n\nX = imputed_X\nX_test = imputed_X_test","5ddc51e0":"### Handle Categorical Variables\n\nobject_cols = [col for col in X.columns if X[col].dtype == \"object\"]\ngood_label_cols = [col for col in object_cols if set(X[col]) == set(X_test[col])]\nbad_label_cols = list(set(object_cols) - set(good_label_cols))\n\nprint('\\nAll categorical columns in the dataset:\\n', object_cols)\nprint('\\nCategorical columns that will be label encoded:\\n', good_label_cols)\nprint('\\nCategorical columns that will be dropped from the dataset:\\n', bad_label_cols)","aa1ce50b":"X[bad_label_cols].head()","0e7c46a8":"X[good_label_cols].head()","061e571c":"X[good_label_cols].info()","5c586f39":"from sklearn.preprocessing import LabelEncoder\n\nlabel_X = X.drop(bad_label_cols, axis=1)\nlabel_X_test = X_test.drop(bad_label_cols, axis=1)\n\nlabel_encoder = LabelEncoder()\nfor col in good_label_cols:\n    label_X[col] = label_encoder.fit_transform(X[col])\n    label_X_test[col] = label_encoder.transform(X_test[col])","94855b6d":"X = label_X\nX_test = label_X_test\n\nobject_cols = good_label_cols","0b3ad207":"X.head()","74c5d0f9":"object_nunique = list(map(lambda col: X[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n\nnunique = sorted(d.items(), key=lambda x: x[1])\nprint('Number of unique entries in each column with categorical data:', nunique)","e6c0921b":"low_cardinality_cols = [col for col in object_cols if X[col].nunique() < 10]\nhigh_cardinality_cols = list(set(object_cols) - set(low_cardinality_cols))\n#high_cardinality_cols = [k for k, v in d.items() if v > 10]\n\nprint('\\nCategorical columns that will be one-hot encoded:\\n', low_cardinality_cols)\nprint('\\nCategorical columns that will be dropped from the dataset:\\n', high_cardinality_cols)","c8a3b701":"X[low_cardinality_cols].head()","3c29fd72":"X[high_cardinality_cols].head()","a0752f44":"from sklearn.preprocessing import OneHotEncoder\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols = pd.DataFrame(OH_encoder.fit_transform(X[low_cardinality_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n\nOH_cols.index = X.index\nOH_cols_test.index = X_test.index\n\nnum_X = X.drop(object_cols, axis=1)\nnum_X_test = X_test.drop(object_cols, axis=1)\n\nOH_X = pd.concat([num_X, OH_cols], axis=1)\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)","15332ba1":"X = OH_X\nX_test = OH_X_test","ca7d7b7e":"X.head()","8b545233":"X_test.head()","f9db9483":"X.columns","4dcfe80c":"final_X = X\nfinal_y = y\nfinal_X_test = X_test","87608f30":"#model = RandomForestRegressor(n_estimators=200, random_state=0)\nfrom xgboost import XGBRegressor\nmodel = XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\n\nmodel.fit(final_X, final_y)\npreds_test = model.predict(final_X_test)","82c7e0b1":"output = pd.DataFrame({'Id': test_ids,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","d76513bc":"output.head()","b32a34d1":"for col in ['YearBuilt', 'YearRemodAdd']:#, 'GarageYrBlt', 'MoSold', 'YrSold']:\n    X[col] = X[col].astype(int)\n    X_test[col] = X_test[col].astype(int)\n\nfor col in ['LotFrontage', 'LotArea', 'MasVnrArea', 'GrLivArea', 'GarageArea', 'PoolArea']:\n    X[col] = X[col].astype(float)\n    X_test[col] = X_test[col].astype(float)"}}