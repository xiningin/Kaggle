{"cell_type":{"37e36e28":"code","f39808ce":"code","3c2cb2e2":"code","813c9b87":"code","b280c3a5":"code","f13806d6":"code","3da0e780":"code","dcac04ab":"code","ccde844b":"code","47655eb1":"code","adb68f1b":"code","837561ed":"code","66162538":"code","c627ac38":"code","521cfdb6":"code","b816a777":"code","7fc1a79b":"code","0ce6abf8":"code","c6c97efe":"code","c97108d5":"code","983c655c":"code","9593aab8":"code","cda6fedd":"code","6f32a5cd":"code","6f6c9a40":"code","bf63defa":"code","13112050":"code","af373c81":"code","90de7a8c":"code","4ead4691":"code","aa4d923e":"code","facce0ec":"code","e6dce7f9":"code","6e90c28b":"code","617fa58e":"code","1971969d":"code","a6e37c39":"code","d541be45":"code","3918777d":"code","37b12949":"code","4878b4a2":"markdown","6b3536ec":"markdown","e15cf1e0":"markdown","11bbdcc1":"markdown","f48b3891":"markdown"},"source":{"37e36e28":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Scalers\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n# Models\nfrom sklearn.linear_model import LogisticRegression #logistic regression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn import svm #support vector Machine\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.naive_bayes import GaussianNB #Naive bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.model_selection import train_test_split #training and testing data split\nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix #for confusion matrix\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Cross-validation\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.model_selection import cross_validate\n\n# GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n","f39808ce":"import pydicom\nimport random\nimport matplotlib.pyplot as plt\nimport glob\n","3c2cb2e2":"# directory setting\nINPUT = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'","813c9b87":"train_lab = pd.read_csv(INPUT + '\/' + 'train_labels.csv')\nsample_sub = pd.read_csv(INPUT + '\/' + 'sample_submission.csv')\n","b280c3a5":"print('Train labels')\ntrain_lab","f13806d6":"temp = train_lab['BraTS21ID'] + 100000\nitem_id = []\nfor i in range(len(train_lab)):\n    item_id = item_id + [str(temp[i])[-5:]]\nprint('Number of samples in training data')\nlen(item_id)   # 585","3da0e780":"def GenerateD(df, fol, Itype): # fol: 'train'; Itype: 'FLAIR'\n    print('number, number of images, image_count, intensity, volume, average, Gmin, Gmax, Gmax-average, CmaxName')\n    for i in range(len(item_id[:])):\n        item_fol = os.listdir(INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Itype)\n        item_fol2 = []\n        for j in item_fol:\n            k = 1000 + int(j[6:len(j)-4])\n            item_fol2 = item_fol2 + [k]\n        item_fols = sorted(item_fol2)\n        volume = 0\n        intensity = 0\n        image_count = 0\n        vac = 0\n        Gmax = 0\n        Gmin = 0\n        Amax = 0\n        Imax = 0\n        area_prev = 0\n        sumN_prev = 0\n        changeMax = 0\n        maxName ='none'\n        AmaxName ='none'\n        ImaxName ='none'\n        CmaxName ='00000'\n        for j in item_fols:\n            l = str(j-1000)\n            path = INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Itype + '\/Image-' + l + '.dcm'\n            dicom = pydicom.read_file(path)\n            data = dicom.pixel_array\n            sumN = np.sum(data)\n            sumN_plus = sumN - sumN_prev\n            sumN_prev = sumN\n            if sumN > Imax:\n                Imax = sumN\n                ImaxName = j\n            maxN = np.max(data)\n            if maxN > Gmax:\n                Gmax = maxN\n                maxName = j\n            minN = np.min(data)\n            if minN < Gmin:\n                Gmin = minN\n            zerocount = np.count_nonzero(data == 0)\n            area = np.count_nonzero(data != 0)\n            if area >0:\n                image_count = image_count +1\n            area_plus = area - area_prev\n            area_prev = area\n            if area > Amax:\n                Amax = area\n                AmaxName = j\n            change = -(sumN_plus\/(area_plus+1))\n            if change > changeMax:\n                changeMax = change\n                CmaxName = j\n            intensity = intensity + sumN\n            volume = volume + area\n            vac = vac + zerocount\n        average = intensity\/(volume+1)\n        df.loc[i,'c0'] = len(item_fol)\n        df.loc[i,'c1'] = image_count\n        df.loc[i,'c2'] = int(intensity)\n        df.loc[i,'c3'] = volume\n        df.loc[i,'c4'] = vac\n        df.loc[i,'c5'] = volume+vac\n        df.loc[i,'c6'] = average\n        df.loc[i,'c7'] = Gmin\n        df.loc[i,'c8'] = Gmax\n        df.loc[i,'c9'] = Gmax-average\n        df.loc[i,'c10'] = 'Image-' + str(int(CmaxName) -1000) + '.dcm'\n        print(i, len(item_fol), image_count, intensity, volume, average, Gmin, Gmax, Gmax-average, 'Image-' + str(int(CmaxName) -1000) + '.dcm')\n    return df\n\ntrain_lab = GenerateD(train_lab, 'train', 'FLAIR') # fol: 'train'; Itype: 'FLAIR'\n\ntrain_lab.head(10)","dcac04ab":"fol_num = '00000'\nfil_num = 70\npathA = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/'+fol_num+'\/FLAIR\/Image-'+str(fil_num)+'.dcm'\ndicom = pydicom.read_file(pathA)\ndata = dicom.pixel_array\n# print(i+1, np.min(data), np.average(data), np.max(data), np.sum(data), np.max(data)\/np.average(data))\nprint('An example image')\nplt.figure(figsize=(16, 5))\nplt.imshow(data, cmap=\"gray\")\nplt.show()\n\n# for i in range(129):\n#     fil_num = i+1\n#     pathA = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/'+fol_num+'\/FLAIR\/Image-'+str(fil_num)+'.dcm'\n#     dicom = pydicom.read_file(pathA)\n#     data = dicom.pixel_array\n#     print(i+1, np.min(data), np.average(data), np.max(data), np.sum(data), np.max(data)\/np.average(data))\n#     plt.figure(figsize=(16, 5))\n#     plt.imshow(data, cmap=\"gray\")\n#     plt.show()\n","ccde844b":"print(i, 'number of images', 'intensity', 'volume', 'average', 'Gmin', 'Gmax', 'Gmax-average', 'CmaxName')# for i in range(len(item_id[:10])):\n# for i in range(len(item_id[:1])):\nfor i in range(len(item_id[:])):\n    item_fol = os.listdir(INPUT + '\/train\/' + item_id[i] + '\/FLAIR')\n    item_fol2 = []\n    for j in item_fol:\n#         k = 'A' + j[6:len(j)-4]\n        k = 1000 + int(j[6:len(j)-4])\n        item_fol2 = item_fol2 + [k]\n    item_fols = sorted(item_fol2)\n#     volume = 0\n#     intensity = 0\n#     vac = 0\n#     Gmax = 0\n#     Gmin = 0\n#     Amax = 0\n#     Imax = 0\n#     area_prev = 0\n#     sumN_prev = 0\n#     changeMax = 0\n#     maxName ='none'\n#     AmaxName ='none'\n#     ImaxName ='none'\n#     CmaxName ='00000'\n    P50 = 0\n    P60 = 0\n    P70 = 0\n    P80 = 0\n    P90 = 0\n    P95 = 0\n    F2 = 0\n    F3 = 0\n    F4 = 0\n    F5 = 0\n    F6 = 0\n    val50 = train_lab['c9'][i] * 0.5 + train_lab['c6'][i]\n    val60 = train_lab['c9'][i] * 0.6 + train_lab['c6'][i]\n    val70 = train_lab['c9'][i] * 0.7 + train_lab['c6'][i]\n    val80 = train_lab['c9'][i] * 0.8 + train_lab['c6'][i]\n    val90 = train_lab['c9'][i] * 0.9 + train_lab['c6'][i]\n    val95 = train_lab['c9'][i] * 0.95 + train_lab['c6'][i]\n    F2val = train_lab['c6'][i] * 2\n    F3val = train_lab['c6'][i] * 3\n    F4val = train_lab['c6'][i] * 4\n    F5val = train_lab['c6'][i] * 5\n    F6val = train_lab['c6'][i] * 6\n    for j in item_fols:\n        l = str(j-1000)\n        path = INPUT + '\/train\/' + item_id[i] + '\/FLAIR\/Image-' + l + '.dcm'\n        dicom = pydicom.read_file(path)\n        data = dicom.pixel_array\n#         sumN = np.sum(data)\n#         sumN_plus = sumN - sumN_prev\n#         sumN_prev = sumN\n#         if sumN > Imax:\n#             Imax = sumN\n#             ImaxName = j\n#         maxN = np.max(data)\n#         if maxN > Gmax:\n#             Gmax = maxN\n#             maxName = j\n#         minN = np.min(data)\n#         if minN < Gmin:\n#             Gmin = minN\n        count50 = np.count_nonzero(data > val50)\n        count60 = np.count_nonzero(data > val60)\n        count70 = np.count_nonzero(data > val70)\n        count80 = np.count_nonzero(data > val80)\n        count90 = np.count_nonzero(data > val90)\n        count95 = np.count_nonzero(data > val95)\n        countF2 = np.count_nonzero(data > F2val)\n        countF3 = np.count_nonzero(data > F3val)\n        countF4 = np.count_nonzero(data > F4val)\n        countF5 = np.count_nonzero(data > F5val)\n        countF6 = np.count_nonzero(data > F6val)\n#         area = np.count_nonzero(data != 0)\n#         area_plus = area - area_prev\n#         area_prev = area\n#         if area > Amax:\n#             Amax = area\n#             AmaxName = j\n#         change = -(sumN_plus\/area_plus)\n#         if change > changeMax:\n#             changeMax = change\n#             CmaxName = j\n#         intensity = intensity + sumN\n#         volume = volume + area\n        P50 = P50 + count50\n        P60 = P60 + count60\n        P70 = P70 + count70\n        P80 = P80 + count80\n        P90 = P90 + count90\n        P95 = P95 + count95\n        F2 = F2 + countF2\n        F3 = F3 + countF3\n        F4 = F4 + countF4\n        F5 = F5 + countF5\n        F6 = F6 + countF6\n#         print(i, j, sumN, maxN, minN, zerocount, area, area_plus, sumN_plus, change)\n#     average = intensity\/volume\n#     train_lab.loc[i,'c1'] = len(item_fol)\n#     train_lab.loc[i,'c2'] = int(intensity)\n#     train_lab.loc[i,'c3'] = volume\n#     train_lab.loc[i,'c4'] = vac\n#     train_lab.loc[i,'c5'] = volume+vac\n#     train_lab.loc[i,'c6'] = int(average)\n#     train_lab.loc[i,'c7'] = Gmin\n#     train_lab.loc[i,'c8'] = Gmax\n#     train_lab.loc[i,'c9'] = int(Gmax-average)\n#     train_lab.loc[i,'c10'] = 'Image-' + str(int(CmaxName) -1000) + '.dcm'\n    c3val = train_lab['c3'][i]\n    train_lab.loc[i,'c11'] = P50 * 1e7 \/ c3val\n    train_lab.loc[i,'c12'] = P60 * 1e7 \/ c3val\n    train_lab.loc[i,'c13'] = P70 * 1e7 \/ c3val\n    train_lab.loc[i,'c14'] = P80 * 1e7 \/ c3val\n    train_lab.loc[i,'c15'] = P90 * 1e7 \/ c3val\n    train_lab.loc[i,'c16'] = P95 * 1e7 \/ c3val\n    train_lab.loc[i,'c17'] = F2 *  1e7 \/ c3val\n    train_lab.loc[i,'c18'] = F3 *  1e7 \/ c3val\n    train_lab.loc[i,'c19'] = F4 * 1e7 \/ c3val\n    train_lab.loc[i,'c20'] = F5 * 1e7 \/ c3val\n    train_lab.loc[i,'c21'] = F6 * 1e7 \/ c3val\n#     train_lab.loc[i,['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']] = (len(item_fol), intensity, volume, vac, volume+vac, average, Gmin, Gmax, int(Gmax-average))\n#     train_lab.loc[i,['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']] = (len(item_fol), intensity, volume, vac, volume+vac, average, Gmin, Gmax, int(Gmax-average))\n#     print(i, (P50, P60, P70, P80, P90, P95, \n#     print(i, (F2, F3, F4, F5, F6)*1e7\/train_lab['c3'][i])\n\n#     train_lab.c1[i] = len(item_fol)\n\n# print(item_id[:1], maxName, AmaxName, ImaxName)\ntrain_lab.head(10)","47655eb1":"train_lab","adb68f1b":"train_lab.to_csv('Table_trainA.csv')\ntrain_lab2 = train_lab[train_lab['c2'] != 0]\ntrain_data = train_lab2.reset_index()\ntrain_data","837561ed":"def AddDif1(df):\n    df2 = df\n    df2['d1'] = df['c11'] - df['c12']\n    df2['d2'] = df['c12'] - df['c13']\n    df2['d3'] = df['c13'] - df['c14']\n    df2['d4'] = df['c14'] - df['c15']\n    df2['d5'] = df['c15'] - df['c16']\n    return df2\n    \ntrain_data = AddDif1(train_data)\ntrain_data","66162538":"sample_sub","c627ac38":"temp = sample_sub['BraTS21ID'] + 100000\nitem_id = []\nfor i in range(len(sample_sub)):\n    item_id = item_id + [str(temp[i])[-5:]]\nprint('Number of samples in test data')\nlen(item_id)   # 87","521cfdb6":"train_lab = sample_sub\n\n# Note: change 'train' path to 'test'","b816a777":"train_lab = GenerateD(train_lab, 'test', 'FLAIR') # fol: 'train'; Itype: 'FLAIR'\n\ntrain_lab.head(10)","7fc1a79b":"print(i, 'number of images', 'intensity', 'volume', 'average', 'Gmin', 'Gmax', 'Gmax-average', 'CmaxName')# for i in range(len(item_id[:10])):\n# for i in range(len(item_id[:1])):\nfor i in range(len(item_id[:])):\n    item_fol = os.listdir(INPUT + '\/test\/' + item_id[i] + '\/FLAIR')\n    item_fol2 = []\n    for j in item_fol:\n#         k = 'A' + j[6:len(j)-4]\n        k = 1000 + int(j[6:len(j)-4])\n        item_fol2 = item_fol2 + [k]\n    item_fols = sorted(item_fol2)\n#     volume = 0\n#     intensity = 0\n#     vac = 0\n#     Gmax = 0\n#     Gmin = 0\n#     Amax = 0\n#     Imax = 0\n#     area_prev = 0\n#     sumN_prev = 0\n#     changeMax = 0\n#     maxName ='none'\n#     AmaxName ='none'\n#     ImaxName ='none'\n#     CmaxName ='00000'\n    P50 = 0\n    P60 = 0\n    P70 = 0\n    P80 = 0\n    P90 = 0\n    P95 = 0\n    F2 = 0\n    F3 = 0\n    F4 = 0\n    F5 = 0\n    F6 = 0\n    val50 = train_lab['c9'][i] * 0.5 + train_lab['c6'][i]\n    val60 = train_lab['c9'][i] * 0.6 + train_lab['c6'][i]\n    val70 = train_lab['c9'][i] * 0.7 + train_lab['c6'][i]\n    val80 = train_lab['c9'][i] * 0.8 + train_lab['c6'][i]\n    val90 = train_lab['c9'][i] * 0.9 + train_lab['c6'][i]\n    val95 = train_lab['c9'][i] * 0.95 + train_lab['c6'][i]\n    F2val = train_lab['c6'][i] * 2\n    F3val = train_lab['c6'][i] * 3\n    F4val = train_lab['c6'][i] * 4\n    F5val = train_lab['c6'][i] * 5\n    F6val = train_lab['c6'][i] * 6\n    for j in item_fols:\n        l = str(j-1000)\n        path = INPUT + '\/test\/' + item_id[i] + '\/FLAIR\/Image-' + l + '.dcm'\n        dicom = pydicom.read_file(path)\n        data = dicom.pixel_array\n#         sumN = np.sum(data)\n#         sumN_plus = sumN - sumN_prev\n#         sumN_prev = sumN\n#         if sumN > Imax:\n#             Imax = sumN\n#             ImaxName = j\n#         maxN = np.max(data)\n#         if maxN > Gmax:\n#             Gmax = maxN\n#             maxName = j\n#         minN = np.min(data)\n#         if minN < Gmin:\n#             Gmin = minN\n        count50 = np.count_nonzero(data > val50)\n        count60 = np.count_nonzero(data > val60)\n        count70 = np.count_nonzero(data > val70)\n        count80 = np.count_nonzero(data > val80)\n        count90 = np.count_nonzero(data > val90)\n        count95 = np.count_nonzero(data > val95)\n        countF2 = np.count_nonzero(data > F2val)\n        countF3 = np.count_nonzero(data > F3val)\n        countF4 = np.count_nonzero(data > F4val)\n        countF5 = np.count_nonzero(data > F5val)\n        countF6 = np.count_nonzero(data > F6val)\n#         area = np.count_nonzero(data != 0)\n#         area_plus = area - area_prev\n#         area_prev = area\n#         if area > Amax:\n#             Amax = area\n#             AmaxName = j\n#         change = -(sumN_plus\/area_plus)\n#         if change > changeMax:\n#             changeMax = change\n#             CmaxName = j\n#         intensity = intensity + sumN\n#         volume = volume + area\n        P50 = P50 + count50\n        P60 = P60 + count60\n        P70 = P70 + count70\n        P80 = P80 + count80\n        P90 = P90 + count90\n        P95 = P95 + count95\n        F2 = F2 + countF2\n        F3 = F3 + countF3\n        F4 = F4 + countF4\n        F5 = F5 + countF5\n        F6 = F6 + countF6\n#         print(i, j, sumN, maxN, minN, zerocount, area, area_plus, sumN_plus, change)\n#     average = intensity\/volume\n#     train_lab.loc[i,'c1'] = len(item_fol)\n#     train_lab.loc[i,'c2'] = int(intensity)\n#     train_lab.loc[i,'c3'] = volume\n#     train_lab.loc[i,'c4'] = vac\n#     train_lab.loc[i,'c5'] = volume+vac\n#     train_lab.loc[i,'c6'] = int(average)\n#     train_lab.loc[i,'c7'] = Gmin\n#     train_lab.loc[i,'c8'] = Gmax\n#     train_lab.loc[i,'c9'] = int(Gmax-average)\n#     train_lab.loc[i,'c10'] = 'Image-' + str(int(CmaxName) -1000) + '.dcm'\n    c3val = train_lab['c3'][i]\n    train_lab.loc[i,'c11'] = P50 * 1e7 \/ c3val\n    train_lab.loc[i,'c12'] = P60 * 1e7 \/ c3val\n    train_lab.loc[i,'c13'] = P70 * 1e7 \/ c3val\n    train_lab.loc[i,'c14'] = P80 * 1e7 \/ c3val\n    train_lab.loc[i,'c15'] = P90 * 1e7 \/ c3val\n    train_lab.loc[i,'c16'] = P95 * 1e7 \/ c3val\n    train_lab.loc[i,'c17'] = F2 *  1e7 \/ c3val\n    train_lab.loc[i,'c18'] = F3 *  1e7 \/ c3val\n    train_lab.loc[i,'c19'] = F4 * 1e7 \/ c3val\n    train_lab.loc[i,'c20'] = F5 * 1e7 \/ c3val\n    train_lab.loc[i,'c21'] = F6 * 1e7 \/ c3val\n#     train_lab.loc[i,['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']] = (len(item_fol), intensity, volume, vac, volume+vac, average, Gmin, Gmax, int(Gmax-average))\n#     train_lab.loc[i,['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']] = (len(item_fol), intensity, volume, vac, volume+vac, average, Gmin, Gmax, int(Gmax-average))\n#     print(i, (P50, P60, P70, P80, P90, P95, \n#     print(i, (F2, F3, F4, F5, F6)*1e7\/train_lab['c3'][i])\n\n#     train_lab.c1[i] = len(item_fol)\n\n# print(item_id[:1], maxName, AmaxName, ImaxName)\ntrain_lab.head(10)","0ce6abf8":"sample_sub = train_lab     # <=== Caution!","c6c97efe":"sample_sub.to_csv('Table_testA.csv')\ntest_data = sample_sub\ntest_data","c97108d5":"test_data = AddDif1(test_data)\ntest_data","983c655c":"output = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\noutput","9593aab8":"features = [\"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c8\", \"c9\", \n#             \"c11\", \"c12\", \"c13\", \"c14\", \"c15\", \"c16\",\n            \"d1\", \"d2\", \"d3\", \"d4\", \"d5\"]\ny = train_data[\"MGMT_value\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])","cda6fedd":"std_scaler = StandardScaler()\nX = std_scaler.fit_transform(X)\nX_test = std_scaler.transform(X_test)","6f32a5cd":"# # KNN\n# n_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22,24,26]\n# algorithm = ['auto']\n# weights = ['uniform', 'distance']\n# leaf_size = list(range(1,50,5))\n# hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n#                'n_neighbors': n_neighbors}\n# gd=GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n#                 cv=9, scoring = \"roc_auc\")\n# gd.fit(X, y)\n# print(gd.best_score_)\n# print(gd.best_estimator_)\n\n# gd.best_estimator_.fit(X, y)\n# y_pred = gd.best_estimator_.predict_proba(X_test)[:,1]\n# y_pred\n\n# y_score1 = gd.best_estimator_.predict_proba(X)[:,1]\n# predictions = gd.best_estimator_.predict_proba(X_test)[:,1]\n","6f6c9a40":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"MGMT_value\"]\n\nfeatures = [\"c2\", \"c3\", \"c4\", \"c5\", \"c6\", \"c8\", \"c9\", \n#             \"c11\", \"c12\", \"c13\", \"c14\", \"c15\", \"c16\",\n            \"d1\", \"d2\", \"d3\", \"d4\", \"d5\"]\n#             \"c17\", \"c18\", \"c19\", \"c20\", \"c21\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=1)\nmodel.fit(X, y)\n\ny_score1 = model.predict_proba(X)[:,1]\npredictions = model.predict_proba(X_test)[:,1]\n","bf63defa":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\ny_true1 = y\n# # y_score1 = model.predict_proba(X)[:,1]\n# y_score1 = gd.best_estimator_.predict_proba(X)[:,1]\n\nroc1 = roc_curve(y_true1, y_score1)\n\nfpr1, tpr1, thresholds1 = roc_curve(y_true1, y_score1)\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\ny_pred = np.round(y_score1, decimals = 0)\ntn1, fp1, fn1, tp1 = confusion_matrix(y_true1, y_pred).ravel()\nac1 = accuracy_score(y_true1, y_pred)\npr1 = precision_score(y_true1, y_pred)\nrc1 = recall_score(y_true1, y_pred)\nsp1 = tn1\/(fp1+tn1)\nf11 = f1_score(y_true1, y_pred)\nphi1 = (tp1*tn1-fp1*fn1)\/np.sqrt((tp1+fn1)*(tp1+fp1)*(tn1+fn1)*(tn1+fp1))\n\n# y_true2 = y_vali\n# y_score2 = p_vali\n\n# roc2 = roc_curve(y_true2, y_score2)\n\n# fpr2, tpr2, thresholds2 = roc_curve(y_true2, y_score2)\n# y_pred = np.round(p_vali, decimals = 0)\n# tn2, fp2, fn2, tp2 = confusion_matrix(y_true2, y_pred).ravel()\n# ac2 = accuracy_score(y_true2, y_pred)\n# pr2 = precision_score(y_true2, y_pred)\n# rc2 = recall_score(y_true2, y_pred)\n# sp2 = tn2\/(fp2+tn2)\n# f12 = f1_score(y_true2, y_pred)\n# phi2 = (tp2*tn2-fp2*fn2)\/np.sqrt((tp2+fn2)*(tp2+fp2)*(tn2+fn2)*(tn2+fp2))\n\n# y_true3 = y_test\n# y_score3 = p_test\n\n# roc3 = roc_curve(y_true3, y_score3)\n\n# fpr3, tpr3, thresholds3 = roc_curve(y_true3, y_score3)\n# y_pred = np.round(p_test, decimals = 0)\n# tn3, fp3, fn3, tp3 = confusion_matrix(y_true3, y_pred).ravel()\n# ac3 = accuracy_score(y_true3, y_pred)\n# pr3 = precision_score(y_true3, y_pred)\n# rc3 = recall_score(y_true3, y_pred)\n# sp3 = tn3\/(fp3+tn3)\n# f13 = f1_score(y_true3, y_pred)\n# phi3 = (tp3*tn3-fp3*fn3)\/np.sqrt((tp3+fn3)*(tp3+fp3)*(tn3+fn3)*(tn3+fp3))\n\nplt.figure(figsize=(6,6))\nplt.plot((0,1), (0,1), color=\"black\", linestyle=\"--\")\nplt.plot(fpr1, tpr1, linewidth=3)#, marker='o')\n# plt.plot(fpr2, tpr2, linewidth=3)#, marker='o')\n# plt.plot(fpr3, tpr3, linewidth=3)#, marker='o')\nplt.tick_params(direction='in')\nplt.xlabel('FPR: False positive rate')\nplt.ylabel('TPR: True positive rate')\n# plt.legend(['train', 'valid', 'test'], loc='lower right')\nplt.grid()\nROC1=roc_auc_score(y_true1, y_score1)\n# ROC2=roc_auc_score(y_true2, y_score2)\n# ROC3=roc_auc_score(y_true3, y_score3)\nprint(ROC1)#,ROC2,ROC3)","13112050":"# for i in range(len(X)):\n#     print(i, y[i], model.predict_proba(X)[:,1][i])","af373c81":"# predictions = model.predict_proba(X_test)[:,1]\n# predictions = gd.best_estimator_.predict_proba(X_test)[:,1]\noutput['MGMT_value'] = predictions\noutput","90de7a8c":"temp = output['BraTS21ID'] + 100000\nitem_id = []\nfor i in range(len(temp)):\n    item_id = item_id + [str(temp[i])[-5:]]\noutput['BraTS21ID'] = item_id\n\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","4ead4691":"output","aa4d923e":"feature_importance = model.feature_importances_\nprint('Feature importances')\nfor i in range(len(features)):\n    print(features[i], feature_importance[i])","facce0ec":"import matplotlib.pyplot as plt\nindices = np.argsort(feature_importance)[::1]\nplt.figure(figsize = (6, 6))\nplt.barh(np.array(features)[indices], feature_importance[indices], height = 0.5)\nplt.yticks(fontsize = 20)\nplt.xlabel(\"Feature importances\", fontsize = 25)\nplt.show()","e6dce7f9":"# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Resulting_train = pd.read_csv('..\/input\/rf-brain-tumor-flair\/Table_trainA.csv')\n# # len(Resulting_train)\n\n# def AddDif1(df):\n#     df2 = df\n#     df2['d1'] = df['c11'] - df['c12']\n#     df2['d2'] = df['c12'] - df['c13']\n#     df2['d3'] = df['c13'] - df['c14']\n#     df2['d4'] = df['c14'] - df['c15']\n#     df2['d5'] = df['c15'] - df['c16']\n#     return df2\n    \n# Resulting_train = AddDif1(Resulting_train)\nResulting_train = train_data\nResulting_train.head(2)","6e90c28b":"Positive_train = Resulting_train[Resulting_train.MGMT_value == 1]\nNegative_train = Resulting_train[Resulting_train.MGMT_value == 0]\n(len(Positive_train), len(Negative_train), len(Positive_train) + len(Negative_train))","617fa58e":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfig, ax = plt.subplots(4, 3, figsize=(12, 9))\nsns.set_palette(sns.color_palette(\"icefire\"))\n\nsns.kdeplot(data=Positive_train['c2'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[0][0])\nsns.kdeplot(data=Negative_train['c2'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[0][0])\nax[0][0].set_title('c2', fontsize=15, fontweight='bold')\nax[0][0].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['c3'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[0][1])\nsns.kdeplot(data=Negative_train['c3'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[0][1])\nax[0][1].set_title('c3', fontsize=15, fontweight='bold')\nax[0][1].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['c4'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[0][2])\nsns.kdeplot(data=Negative_train['c4'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[0][2])\nax[0][2].set_title('c4', fontsize=15, fontweight='bold')\nax[0][2].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['c6'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[1][0])\nsns.kdeplot(data=Negative_train['c6'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[1][0])\nax[1][0].set_title('c6', fontsize=15, fontweight='bold')\nax[1][0].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['c8'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[1][1])\nsns.kdeplot(data=Negative_train['c8'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[1][1])\nax[1][1].set_title('c8', fontsize=15, fontweight='bold')\nax[1][1].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['c9'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[1][2])\nsns.kdeplot(data=Negative_train['c9'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[1][2])\nax[1][2].set_title('c9', fontsize=15, fontweight='bold')\nax[1][2].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['d1'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[2][0])\nsns.kdeplot(data=Negative_train['d1'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[2][0])\nax[2][0].set_title('d1', fontsize=15, fontweight='bold')\nax[2][0].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['d2'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[2][1])\nsns.kdeplot(data=Negative_train['d2'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[2][1])\nax[2][1].set_title('d2', fontsize=15, fontweight='bold')\nax[2][1].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['d3'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[2][2])\nsns.kdeplot(data=Negative_train['d3'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[2][2])\nax[2][2].set_title('d3', fontsize=15, fontweight='bold')\nax[2][2].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['d4'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[3][0])\nsns.kdeplot(data=Negative_train['d4'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[3][0])\nax[3][0].set_title('d4', fontsize=15, fontweight='bold')\nax[3][0].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['d5'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[3][1])\nsns.kdeplot(data=Negative_train['d5'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[3][1])\nax[3][1].set_title('d4', fontsize=15, fontweight='bold')\nax[3][1].tick_params(direction='in')\n\nsns.kdeplot(data=Positive_train['c1'], label=\"positive\", color=\"#9999ff\", shade=True, ax=ax[3][2])\nsns.kdeplot(data=Negative_train['c1'], label=\"negative\", color=\"#ffaaaa\", shade=True, ax=ax[3][2])\nax[3][2].set_title('c1', fontsize=15, fontweight='bold')\nax[3][2].tick_params(direction='in')\n\n\nfig.suptitle('Distribution: positive (blue) and nagative (red)', fontsize=20, fontweight='bold')\n\nfig.tight_layout(rect=[0, 0.03, 1, 0.90]);","1971969d":"Debug_mode = False","a6e37c39":"# directory setting\nINPUT = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\ntrain_lab = pd.read_csv(INPUT + '\/' + 'train_labels.csv')\nsample_sub = pd.read_csv(INPUT + '\/' + 'sample_submission.csv')\n\nif Debug_mode == True:\n    train_lab = train_lab.iloc[:5,:] ###########################################\n    \ntemp = train_lab['BraTS21ID'] + 100000\nitem_id = []\nfor i in range(len(train_lab)):\n    item_id = item_id + [str(temp[i])[-5:]]\n","d541be45":"'''\n\u5404\u753b\u50cf\u306e\u5e73\u5747\u5024\u3068\u6a19\u6e96\u504f\u5dee\u3092\u53d6\u5f97\u3057\u3001\u307e\u3068\u3081\u308b\n'''\ndef GenerateH(df, fol, Itype): # fol: 'train'; Itype: 'FLAIR'\n    Types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n#     print('Start 1')\n    for i in range(len(item_id[:])):\n        item_fol = os.listdir(INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Types[Itype])\n        item_fol2 = []\n        for j in item_fol:\n            k = 1000 + int(j[6:len(j)-4])\n            item_fol2 = item_fol2 + [k]\n        item_fols = sorted(item_fol2)\n\n        heikin = []\n        hensa = []\n        saidai = []\n        for j in item_fols:\n            l = str(j-1000)\n            path = INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Types[Itype] + '\/Image-' + l + '.dcm'\n            dicom = pydicom.read_file(path)\n            data = dicom.pixel_array\n            dataF = data.flatten()\n            dataB = np.setdiff1d(dataF, [0])\n            if len(dataB) > 0:\n                heikin = heikin + [np.nanmean(dataB)]\n                hensa = hensa + [np.nanstd(dataB, ddof=1)]\n                saidai = saidai + [np.nanmax(dataB)]\n#         print(i, np.mean(heikin), np.std(heikin, ddof=1), np.mean(hensa), np.std(hensa, ddof=1))           \n#         print(i, np.mean(saidai), np.std(saidai, ddof=1))           \n            \n        df.loc[i, str(Itype)+'h1'] = np.nanmean(heikin)\n        df.loc[i, str(Itype)+'h2'] = np.nanstd(heikin, ddof=1)\n        df.loc[i, str(Itype)+'h3'] = np.nanmean(hensa)\n        df.loc[i, str(Itype)+'h4'] = np.nanstd(hensa, ddof=1)\n        df.loc[i, str(Itype)+'h5'] = np.nanmean(saidai)\n        df.loc[i, str(Itype)+'h6'] = np.nanstd(saidai, ddof=1)\n    return df\n\ndef GenerateD(df, fol, Itype): # fol: 'train'; Itype: 'FLAIR'\n    Types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n#     print('Start 1')\n    for i in range(len(item_id[:])):\n        item_fol = os.listdir(INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Types[Itype])\n        item_fol2 = []\n        for j in item_fol:\n            k = 1000 + int(j[6:len(j)-4])\n            item_fol2 = item_fol2 + [k]\n        item_fols = sorted(item_fol2)\n        volume = 0\n        intensity = 0\n        image_count = 0\n        vac = 0\n        Gmax = 0\n        Gmin = 0\n#         Amax = 0\n#         Imax = 0\n#         area_prev = 0\n#         sumN_prev = 0\n#         changeMax = 0\n#         maxName ='none'\n#         AmaxName ='none'\n#         ImaxName ='none'\n#         CmaxName ='00000'\n        for j in item_fols:\n            l = str(j-1000)\n            path = INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Types[Itype] + '\/Image-' + l + '.dcm'\n            dicom = pydicom.read_file(path)\n            data = dicom.pixel_array\n            sumN = np.sum(data)\n#             sumN_plus = sumN - sumN_prev\n#             sumN_prev = sumN\n#             if sumN > Imax:\n#                 Imax = sumN\n#                 ImaxName = j\n            maxN = np.max(data)\n            if maxN > Gmax:\n                Gmax = maxN\n#                 maxName = j\n            minN = np.min(data)\n            if minN < Gmin:\n                Gmin = minN\n            zerocount = np.count_nonzero(data == 0)\n            area = np.count_nonzero(data != 0)\n            if area >0:\n                image_count = image_count +1\n#             area_plus = area - area_prev\n#             area_prev = area\n#             if area > Amax:\n#                 Amax = area\n#                 AmaxName = j\n#             change = -(sumN_plus\/(area_plus+1))\n#             if change > changeMax:\n#                 changeMax = change\n#                 CmaxName = j\n            intensity = intensity + sumN\n            volume = volume + area\n            vac = vac + zerocount\n        average = intensity\/(volume+1)\n        df.loc[i, str(Itype)+'c0'] = len(item_fol)\n        df.loc[i, str(Itype)+'c1'] = image_count\n        df.loc[i, str(Itype)+'c2'] = intensity\n        df.loc[i, str(Itype)+'c3'] = volume\n        df.loc[i, str(Itype)+'c4'] = vac\n        df.loc[i, str(Itype)+'c5'] = volume+vac\n        df.loc[i, str(Itype)+'c6'] = average\n        df.loc[i, str(Itype)+'c7'] = Gmin\n        df.loc[i, str(Itype)+'c8'] = Gmax\n        df.loc[i, str(Itype)+'c9'] = Gmax-average\n#         df.loc[i,'c10'] = 'Image-' + str(int(CmaxName) -1000) + '.dcm'\n#         print(i, len(item_fol), image_count, intensity, volume, average, Gmin, Gmax, Gmax-average)#, 'Image-' + str(int(CmaxName) -1000) + '.dcm')\n    return df\n\ndef GenerateD2(df, fol, Itype): # fol: 'train'; Itype: 'FLAIR'\n    Types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n    for i in range(len(item_id[:])):\n        item_fol = os.listdir(INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Types[Itype])\n        item_fol2 = []\n        for j in item_fol:\n            k = 1000 + int(j[6:len(j)-4])\n            item_fol2 = item_fol2 + [k]\n        item_fols = sorted(item_fol2)\n        Gmean = df[str(Itype)+'c6'][i] # Gmean\n        B10 = Gmean * 0.2\n        B20 = Gmean * 0.4\n        B30 = Gmean * 0.6\n        B40 = Gmean * 0.8\n        B50 = Gmean\n        B60 = Gmean * 1.2\n        B70 = Gmean * 1.4\n        B80 = Gmean * 1.6\n        B90 = Gmean * 1.8\n        B100 = Gmean * 2\n        B110 = Gmean * 2.2\n        B120 = Gmean * 2.4\n        B130 = Gmean * 2.6\n        B140 = Gmean * 2.8\n        B150 = Gmean * 3\n        B160 = Gmean * 3.2\n        B170 = Gmean * 3.4\n        B180 = Gmean * 3.6\n        B190 = Gmean * 3.8\n        B200 = Gmean * 4\n        B210 = Gmean * 4.2\n        B220 = Gmean * 4.4\n        B230 = Gmean * 4.6\n        B240 = Gmean * 4.8\n        B250 = Gmean * 5\n        B260 = Gmean * 5.2\n        B270 = Gmean * 5.4\n        B280 = Gmean * 5.6\n        B290 = Gmean * 5.8\n        B300 = Gmean * 6\n        \n        count10 = 0\n        count20 = 0\n        count30 = 0\n        count40 = 0\n        count50 = 0\n        count60 = 0\n        count70 = 0\n        count80 = 0\n        count90 = 0\n        count100 = 0\n        count110 = 0\n        count120 = 0\n        count130 = 0\n        count140 = 0\n        count150 = 0\n        count160 = 0\n        count170 = 0\n        count180 = 0\n        count190 = 0\n        count200 = 0\n        count210 = 0\n        count220 = 0\n        count230 = 0\n        count240 = 0\n        count250 = 0\n        count260 = 0\n        count270 = 0\n        count280 = 0\n        count290 = 0\n        count300 = 0\n        \n        for j in item_fols:\n            l = str(j-1000)\n            path = INPUT + '\/' + fol + '\/' + item_id[i] + '\/' + Types[Itype] + '\/Image-' + l + '.dcm'\n            dicom = pydicom.read_file(path)\n            data = dicom.pixel_array\n            cou10 = np.count_nonzero(data < B10)\n            cou20 = np.count_nonzero(data < B20)\n            cou30 = np.count_nonzero(data < B30)\n            cou40 = np.count_nonzero(data < B40)\n            cou50 = np.count_nonzero(data < B50)\n            cou60 = np.count_nonzero(data < B60)\n            cou70 = np.count_nonzero(data < B70)\n            cou80 = np.count_nonzero(data < B80)\n            cou90 = np.count_nonzero(data < B90)\n            cou100 = np.count_nonzero(data < B100)\n            cou110 = np.count_nonzero(data < B110)\n            cou120 = np.count_nonzero(data < B120)\n            cou130 = np.count_nonzero(data < B130)\n            cou140 = np.count_nonzero(data < B140)\n            cou150 = np.count_nonzero(data < B150)\n            cou160 = np.count_nonzero(data < B160)\n            cou170 = np.count_nonzero(data < B170)\n            cou180 = np.count_nonzero(data < B180)\n            cou190 = np.count_nonzero(data < B190)\n            cou200 = np.count_nonzero(data < B200)\n            cou210 = np.count_nonzero(data < B210)\n            cou220 = np.count_nonzero(data < B220)\n            cou230 = np.count_nonzero(data < B230)\n            cou240 = np.count_nonzero(data < B240)\n            cou250 = np.count_nonzero(data < B250)\n            cou260 = np.count_nonzero(data < B260)\n            cou270 = np.count_nonzero(data < B270)\n            cou280 = np.count_nonzero(data < B280)\n            cou290 = np.count_nonzero(data < B290)\n            cou300 = np.count_nonzero(data < B300)\n\n            count10 = count10 + cou10\n            count20 = count20 + cou20\n            count30 = count30 + cou30\n            count40 = count40 + cou40\n            count50 = count50 + cou50\n            count60 = count60 + cou60\n            count70 = count70 + cou70\n            count80 = count80 + cou80\n            count90 = count90 + cou90\n            count100 = count100 + cou100\n            count110 = count110 + cou110\n            count120 = count120 + cou120\n            count130 = count130 + cou130\n            count140 = count140 + cou140\n            count150 = count150 + cou150\n            count160 = count160 + cou160\n            count170 = count170 + cou170\n            count180 = count180 + cou180\n            count190 = count190 + cou190\n            count200 = count200 + cou200\n            count210 = count210 + cou210\n            count220 = count220 + cou220\n            count230 = count230 + cou230\n            count240 = count240 + cou240\n            count250 = count250 + cou250\n            count260 = count260 + cou260\n            count270 = count270 + cou270\n            count280 = count280 + cou280\n            count290 = count290 + cou290\n            count300 = count300 + cou300\n\n        Volume1 = (df[str(Itype)+'c3'][i] + 1) \/ 100\n        vac = df[str(Itype)+'c4'][i]\n\n        df.loc[i, str(Itype)+'B1'] = (count10 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B2'] = (count20 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B3'] = (count30 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B4'] = (count40 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B5'] = (count50 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B6'] = (count60 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B7'] = (count70 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B8'] = (count80 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B9'] = (count90 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B10'] = (count100 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B11'] = (count110 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B12'] = (count120 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B13'] = (count130 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B14'] = (count140 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B15'] = (count150 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B16'] = (count160 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B17'] = (count170 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B18'] = (count180 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B19'] = (count190 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B20'] = (count200 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B21'] = (count210 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B22'] = (count220 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B23'] = (count230 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B24'] = (count240 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B25'] = (count250 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B26'] = (count260 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B27'] = (count270 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B28'] = (count280 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B29'] = (count290 - vac) \/ Volume1\n        df.loc[i, str(Itype)+'B30'] = (count300 - vac) \/ Volume1\n\n        \n        \n#         df.loc[i,'c12'] = P60 * 1e7 \/ c3val\n#         df.loc[i,'c13'] = P70 * 1e7 \/ c3val\n#         df.loc[i,'c14'] = P80 * 1e7 \/ c3val\n#         df.loc[i,'c15'] = P90 * 1e7 \/ c3val\n#         df.loc[i,'c16'] = P95 * 1e7 \/ c3val\n#         df.loc[i,'b1'] = (B10 - c4val) * 1e7 \/ c3val\n#         df.loc[i,'b2'] = (B20 - c4val) * 1e7 \/ c3val\n#         df.loc[i,'b3'] = (B30 - c4val) * 1e7 \/ c3val\n#         df.loc[i,'b4'] = (B40 - c4val) * 1e7 \/ c3val\n#         df.loc[i,'b5'] = (B50 - c4val) * 1e7 \/ c3val\n#         df.loc[i,'c17'] = F2 *  1e7 \/ c3val\n#         df.loc[i,'c18'] = F3 *  1e7 \/ c3val\n#         df.loc[i,'c19'] = F4 * 1e7 \/ c3val\n#         df.loc[i,'c20'] = F5 * 1e7 \/ c3val\n#         df.loc[i,'c21'] = F6 * 1e7 \/ c3val\n    return df\n\ndef AddDif1(df):\n    df2 = df\n    for i in range(4):\n        df2[str(i)+'d1'] = df[str(i)+'B1']\n        df2[str(i)+'d2'] = df[str(i)+'B2'] - df[str(i)+'B1']\n        df2[str(i)+'d3'] = df[str(i)+'B3'] - df[str(i)+'B2']\n        df2[str(i)+'d4'] = df[str(i)+'B4'] - df[str(i)+'B3']\n        df2[str(i)+'d5'] = df[str(i)+'B5'] - df[str(i)+'B4']\n        df2[str(i)+'d6'] = df[str(i)+'B6'] - df[str(i)+'B5']\n        df2[str(i)+'d7'] = df[str(i)+'B7'] - df[str(i)+'B6']\n        df2[str(i)+'d8'] = df[str(i)+'B8'] - df[str(i)+'B7']\n        df2[str(i)+'d9'] = df[str(i)+'B9'] - df[str(i)+'B8']\n        df2[str(i)+'d10'] = df[str(i)+'B10'] - df[str(i)+'B9']\n        df2[str(i)+'d11'] = df[str(i)+'B11'] - df[str(i)+'B10']\n        df2[str(i)+'d12'] = df[str(i)+'B12'] - df[str(i)+'B11']\n        df2[str(i)+'d13'] = df[str(i)+'B13'] - df[str(i)+'B12']\n        df2[str(i)+'d14'] = df[str(i)+'B14'] - df[str(i)+'B13']\n        df2[str(i)+'d15'] = df[str(i)+'B15'] - df[str(i)+'B14']\n        df2[str(i)+'d16'] = df[str(i)+'B16'] - df[str(i)+'B15']\n        df2[str(i)+'d17'] = df[str(i)+'B17'] - df[str(i)+'B16']\n        df2[str(i)+'d18'] = df[str(i)+'B18'] - df[str(i)+'B17']\n        df2[str(i)+'d19'] = df[str(i)+'B19'] - df[str(i)+'B18']\n        df2[str(i)+'d20'] = df[str(i)+'B20'] - df[str(i)+'B19']\n        df2[str(i)+'d21'] = df[str(i)+'B21'] - df[str(i)+'B20']\n        df2[str(i)+'d22'] = df[str(i)+'B22'] - df[str(i)+'B21']\n        df2[str(i)+'d23'] = df[str(i)+'B23'] - df[str(i)+'B22']\n        df2[str(i)+'d24'] = df[str(i)+'B24'] - df[str(i)+'B23']\n        df2[str(i)+'d25'] = df[str(i)+'B25'] - df[str(i)+'B24']\n        df2[str(i)+'d26'] = df[str(i)+'B26'] - df[str(i)+'B25']\n        df2[str(i)+'d27'] = df[str(i)+'B27'] - df[str(i)+'B26']\n        df2[str(i)+'d28'] = df[str(i)+'B28'] - df[str(i)+'B27']\n        df2[str(i)+'d29'] = df[str(i)+'B29'] - df[str(i)+'B28']\n        df2[str(i)+'d30'] = df[str(i)+'B30'] - df[str(i)+'B29']\n        df2[str(i)+'d31'] = df[str(i)+'c3']\/((df[str(i)+'c3']+1)\/100) - df[str(i)+'B30']\n        df2[str(i)+'d32'] = df[str(i)+'d1'] + df[str(i)+'d2'] + df[str(i)+'d3'] + df[str(i)+'d4'] + df[str(i)+'d5'] + df[str(i)+'d6'] + df[str(i)+'d7'] + df[str(i)+'d8'] + df[str(i)+'d9'] + df[str(i)+'d10'] + df[str(i)+'d11'] + df[str(i)+'d12'] + df[str(i)+'d13'] + df[str(i)+'d14'] + df[str(i)+'d15'] + df[str(i)+'d16'] + df[str(i)+'d17'] + df[str(i)+'d18'] + df[str(i)+'d19'] + df[str(i)+'d20'] + df[str(i)+'d21'] + df[str(i)+'d22'] + df[str(i)+'d23'] + df[str(i)+'d24'] + df[str(i)+'d25'] + df[str(i)+'d26'] + df[str(i)+'d27'] + df[str(i)+'d28'] + df[str(i)+'d29'] + df[str(i)+'d30'] + df[str(i)+'d31']\n\n    return df2\n","3918777d":"for i in range(4):\n    train_lab = GenerateH(train_lab, 'train', i) # fol: 'train'; Itype: 'FLAIR', 'T1w', 'T2w', 'T2w'\n\nfor i in range(4):\n    train_lab = GenerateD(train_lab, 'train', i) # fol: 'train'; Itype: 'FLAIR', 'T1w', 'T2w', 'T2w'\n\nfor i in range(4):\n    train_lab = GenerateD2(train_lab, 'train', i) # fol: 'train'; Itype: 'FLAIR'\n\ntrain_lab.to_csv('Table_trainAx.csv', index=False)\ntrain_lab2 = train_lab[train_lab['0c2'] != 0]\ntrain_lab2 = train_lab2[train_lab['1c2'] != 0]\ntrain_lab2 = train_lab2[train_lab['2c2'] != 0]\ntrain_lab2 = train_lab2[train_lab['3c2'] != 0]\ntrain_lab2 = train_lab2.reset_index()\ntrain_data = train_lab2.drop('index', axis=1)\n\ntrain_data = AddDif1(train_data)\n\ntrain_data.to_csv('Table_trainBx.csv', index=False)\n\ntrain_data.head(5)","37b12949":"if Debug_mode == True:\n    sample_sub = sample_sub.iloc[:5,:] ###########################################\n\ntemp = sample_sub['BraTS21ID'] + 100000\nitem_id = []\nfor i in range(len(sample_sub)):\n    item_id = item_id + [str(temp[i])[-5:]]\n# print('Number of samples in test data')\nlen(item_id)   # 87\n\nfor i in range(4):\n    sample_sub = GenerateH(sample_sub, 'test', i) # fol: 'train'; Itype: 'FLAIR'\n\nfor i in range(4):\n    sample_sub = GenerateD(sample_sub, 'test', i) # fol: 'train'; Itype: 'FLAIR'\n\nfor i in range(4):\n    sample_sub = GenerateD2(sample_sub, 'test', i) # fol: 'train'; Itype: 'FLAIR'\n\nsample_sub.to_csv('Table_testAx.csv', index=False)\ntest_data = sample_sub\n\ntest_data = AddDif1(test_data)\ntest_data.to_csv('Table_testBx.csv', index=False)\ntest_data.head(5)","4878b4a2":"The purpose is to find brain tumors on MRI images.\n* Random forest model was used.\n* Image recognition technique has not been used yet.","6b3536ec":"* References\n1. k-NN method: https:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83\n2. RF and file handling: https:\/\/www.kaggle.com\/alexisbcook\/titanic-tutorial","e15cf1e0":"# **Find Brain Tumor**","11bbdcc1":"![image.png](attachment:04016f4f-ca29-4267-b6c0-9dbb843836a0.png)","f48b3891":"# k-Nearest neighbor or Random forest"}}