{"cell_type":{"62369a24":"code","5fdb3578":"code","dd150934":"code","5184a4d1":"code","3aff3188":"code","7499a919":"code","cc747565":"code","43c4c9cf":"code","1d85d4d0":"code","adce99b7":"code","7f4f681c":"code","37ecd52e":"code","cf49d62d":"code","7ff7d4ba":"code","d7de930d":"code","b71e5706":"code","c7c5fff0":"code","bb8073f8":"code","281af661":"code","c07d58e1":"code","89e9bf76":"code","0a65c823":"code","a8141ea5":"code","1c4d35c7":"code","e601a351":"code","e288a066":"code","025f6ec9":"code","117dd15e":"code","d7098d82":"code","47649aa0":"markdown","b5f2f5b7":"markdown","3e431e74":"markdown","f4d8ec0d":"markdown","ea9e21d3":"markdown","280ef7bd":"markdown","9e8fd764":"markdown","c7c642c9":"markdown"},"source":{"62369a24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5fdb3578":"# import the modules\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","dd150934":"train = pd.read_csv('\/kaggle\/input\/flight-fare\/Data_Train.csv')\ntrain.head()","5184a4d1":"# Check the NaN\ntrain.isnull().sum()","3aff3188":"train['Date_of_Journey'].astype(str).str[-4:].value_counts()","7499a919":"# Dropping column\ntrain.drop(['Date_of_Journey'], axis=1, inplace=True)","cc747565":"airline_price_rank = {k:i for i,k in enumerate(train.groupby(['Airline'])['Price'].mean().sort_values(ascending = False).index)}\ntrain['Airline'] = train['Airline'].map(airline_price_rank)","43c4c9cf":"train[train['Route'].isnull()]","1d85d4d0":"num_stops_df = train[(train['Source']=='Delhi') & (train['Destination']=='Cochin')]\nnum_stops = num_stops_df['Total_Stops'].value_counts().sort_values(ascending=False).head(1).index.values[0]\nnum_stops","adce99b7":"# Replacing the NaN \ntrain['Total_Stops'].fillna(num_stops, inplace = True)","7f4f681c":"train['Total_Stops'] = np.where(train['Total_Stops']=='non-stop',0,train['Total_Stops'])\ntrain['Total_Stops'] = train['Total_Stops'].astype(str).str[0]\ntrain['Total_Stops'].unique()","37ecd52e":"# Dropping the route column\ntrain.drop(['Route'], axis=1, inplace=True)","cf49d62d":"# Taking the Hours and Minutes part from Duration column and calculate the duration in minutes\nduration_list = list(train['Duration'])\nhours_list = []\nminutes_list = []\nfor ele in duration_list:\n  h_idx = ele.find('h')\n  hours_list.append(ele[:h_idx])\n\n  m_idx = ele.find('m')\n  if m_idx==-1:\n    minutes_list.append(0)\n  elif m_idx!=-1:\n    minutes_list.append(ele[h_idx+2:m_idx])\n  \ntrain['Hour'] = pd.Series(hours_list)\ntrain['Minutes'] = pd.Series(minutes_list)\ntrain['Minutes'] = np.where(train['Minutes']=='',0,train['Minutes'])\ntrain['Hour'] = train['Hour'].astype(int)\ntrain['Minutes'] = train['Minutes'].astype(int)\ntrain['Duration'] = train['Hour']*60 + train['Minutes']\ntrain.head()","7ff7d4ba":"# Dropping the Hours and Minutes column\ntrain.drop(['Hour','Minutes'], axis=1, inplace=True)","d7de930d":"train['Additional_Info'].unique()","b71e5706":"train.groupby(['Additional_Info'])['Price'].mean().sort_values(ascending=False)","c7c5fff0":"train['Additional_Info'] = np.where(train['Additional_Info']=='Business class','Business class','Non-Business Class')\n\nencoded_df = pd.get_dummies(train['Additional_Info'], drop_first=False)\ntrain = pd.concat([train,encoded_df], axis=1)\ntrain.drop(['Additional_Info','Non-Business Class'], axis=1, inplace=True)\ntrain.head()","bb8073f8":"# Extracting the hour and minutes value from Dep_Time and Arrival_Time column\ntrain['Dep_Hour'] = pd.to_datetime(train['Dep_Time']).dt.hour\ntrain['Dep_Minutes'] = pd.to_datetime(train['Dep_Time']).dt.minute\n\ntrain['Arr_Hour'] = pd.to_datetime(train['Arrival_Time']).dt.hour\ntrain['Arr_Minutes'] = pd.to_datetime(train['Arrival_Time']).dt.minute\ntrain.head()","281af661":"# Dropping the Dep_Time and Arrival_Time columns\ntrain.drop(['Dep_Time','Arrival_Time'],axis=1, inplace=True)","c07d58e1":"print(train['Destination'].unique(),train['Source'].unique())","89e9bf76":"destination_dict = {'Banglore': 0,\n 'Cochin': 1,\n 'Delhi': 2,\n 'Hyderabad': 3,\n 'Kolkata': 4,\n 'New Delhi': 5,\n 'Chennai':6,\n 'Mumbai':7}\ntrain['Source'] = train['Source'].map(destination_dict)\ntrain['Destination'] = train['Destination'].map(destination_dict)\ntrain.head()","0a65c823":"# Extracting the dependent (y) and Independent (X) features\ny = train['Price']\nX = train.drop(['Price'], axis=1)","a8141ea5":"from sklearn.ensemble import ExtraTreesRegressor\nextraTreesRegressor = ExtraTreesRegressor()\nextraTreesRegressor.fit(X,y)\n\nscore_df = pd.DataFrame(extraTreesRegressor.feature_importances_, index=X.columns, columns = ['Score'])\nscore_df = pd.DataFrame(score_df['Score'].sort_values(ascending=False))\n\nscore_df.Score.plot(kind='bar', color='green')","1c4d35c7":"from sklearn.feature_selection import mutual_info_regression\nmutual_info_model = mutual_info_regression(X,y)\n\nmutual_score_df = pd.DataFrame(mutual_info_model, index=X.columns, columns=['Score'])\nmutual_score_df = pd.DataFrame(mutual_score_df['Score'].sort_values(ascending=False))\nmutual_score_df.Score.plot(kind='bar', color='red')","e601a351":"X.drop(['Business class'], axis=1, inplace=True)","e288a066":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nscalar = StandardScaler()\nX_scaled = scalar.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size=0.7)","025f6ec9":"from sklearn.ensemble import RandomForestRegressor\n\nrnforest = RandomForestRegressor()\nrnforest.fit(X_train,y_train)\npredictions = rnforest.predict(X_test)\nprint(\"The Training accuracy is {}\".format(round(rnforest.score(X_train, y_train),2)))\nprint(\"The Testing accuracy is {}\".format(round(rnforest.score(X_test, y_test),2)))","117dd15e":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nprint(\"Mean Absolute Error is {}\".format(mean_absolute_error(y_test, predictions)))\nprint(\"Root Mean Squared Error is {}\".format(np.sqrt(mean_squared_error(y_test, predictions))))","d7098d82":"fig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(111)\nplt.xlim((-20000,70000))\ny_test.plot(kind='kde', color='green')\npredictions.plot(kind='kde', color='red')\nlines, labels = ax.get_legend_handles_labels()\nlabels = ['Actual Price', 'Predicted Price']\nplt.legend(lines, labels)\nplt.show()","47649aa0":"Using ExtraTreesRegressor technique as well as Mutual Information Gain Technique, we see that Business Class column is not that significant towards the Price of the ticket. So, we can drop that and keep the remaining columns for model creation.","b5f2f5b7":"**The dataset contains data of year 2019 only. So, it doesnot add special significance towards the output. Its better to drop this column as of now.**","3e431e74":"# Feature Engineering","f4d8ec0d":"There is a null value in Total_Stops where Route is also null. The Source is Delhi and destination is Cochin in that row.","ea9e21d3":"# Model Building ","280ef7bd":"To encode the Source and Destination, we will be using Ordinal Number encoding, where we will assign a unique number to each place and then will encode them.","9e8fd764":"# Feature Selection","c7c642c9":"From the plot, it is seen that the Airline, Total_Stops and Duration are the most significant columns. Lets use the Mutual Information Gain technique to be more sue about the columns to be used for modelling."}}