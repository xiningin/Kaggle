{"cell_type":{"2a72c76f":"code","512f6acf":"code","a0173e8f":"code","726d9d33":"code","b38942dd":"code","f6a4d2b3":"code","f76fe870":"code","f4169f41":"code","d7f7d0ba":"code","e5d4971f":"code","4f19744e":"code","aa348d77":"code","3987327b":"code","34b00df0":"code","154e663b":"code","d7e83415":"code","4bb85c1e":"code","ab2aeb56":"code","d6aca901":"code","391b11b9":"code","3aeb6d83":"code","015cd298":"code","280b801d":"code","541b7b21":"code","26d6747b":"code","7ad71478":"markdown"},"source":{"2a72c76f":"pip install mtcnn","512f6acf":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport matplotlib.patches as patches\nimport tensorflow as tf\nfrom keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential\nfrom mtcnn.mtcnn import MTCNN\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.layers import LSTM","a0173e8f":"images=os.path.join(\"..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\")\ntrain_df=pd.read_csv(os.path.join(\"..\/input\/face-mask-detection-dataset\/train.csv\"))","726d9d33":"train_df.head()","b38942dd":"submission_df=pd.read_csv(os.path.join(\"..\/input\/face-mask-detection-dataset\/submission.csv\"))\nsubmission_df.head()","f6a4d2b3":"annotation=os.path.join(\"..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/annotations\")\nimg=os.listdir(images)\nann=os.listdir(annotation)\nimg.sort()\nprint(len(img),len(ann))","f76fe870":"train_images = img[1698:]\ntest_images = img[:1698]","f4169f41":"#Train Image\nimage=plt.imread(os.path.join(images,train_images[1]))\nplt.imshow(image)","d7f7d0ba":"#Test Image\nimg=plt.imread(os.path.join(images,test_images[1]))\nplt.imshow(img)","e5d4971f":"classes=['face_with_mask','face_no_mask']\ntrain_df= train_df[train_df['classname'].isin(classes)]\ntrain_df.sort_values('name',axis=0,inplace=True)","4f19744e":"box=[]\nfor i in range(len(train_df)):\n    a=[]\n    for j in train_df.iloc[i][[\"x1\",'x2','y1','y2']]:\n        a.append(j)\n    box.append(a)\ntrain_df[\"box\"]=box \ntrain_df.head()","aa348d77":"size=50\ndata=[]\npath = '..\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\/'\ndef create_data():\n       for i in range(len(train_df)):\n            b=[]\n            for j in train_df.iloc[i][['name','box','classname']]:\n                b.append(j)\n            img=cv2.imread(os.path.join(images,b[0]),cv2.IMREAD_GRAYSCALE)\n            crop = img[b[1][1]:b[1][3],b[1][0]:b[1][2]]\n            new_img=cv2.resize(crop,(size,size))\n            data.append([new_img,b[2]])\n            \ncreate_data() \n","3987327b":"plt.imshow(data[1][0])","34b00df0":"features=[]\nlabels=[]\nfor i,j in data:\n    features.append(i)\n    labels.append(j)\nlbl=LabelEncoder()\nlabels=lbl.fit_transform(labels)","154e663b":"features=np.array(features).reshape(-1,50,50,1)\nfeatures=tf.keras.utils.normalize(features,axis=1)\nlabels = to_categorical(labels)","d7e83415":"model=Sequential()\nmodel.add(Conv2D(100,(3,3),input_shape=features.shape[1:],activation='relu',strides=2))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, activation='softmax'))","4bb85c1e":"opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy']) \nmodel.fit(features,labels,epochs=35,batch_size=5)","ab2aeb56":"detector=MTCNN()\nimg=plt.imread(os.path.join(images,test_images[0]))\nfaces=detector.detect_faces(img)\nfor face in faces:\n        box=face['box']\n        im=cv2.rectangle(img,(box[0], box[1]),(box[0]+box[2], box[1] + box[3]),(0,155,255),10)\n        plt.imshow(im)","d6aca901":"test_df=[]\ntest_df1=[]\nt=[]\ns=[]\nr=[]\nfor image in test_images:\n    img=plt.imread(os.path.join(images,image))\n    faces=detector.detect_faces(img)\n    test=[]\n    for face in faces:\n        box=face['box']\n        test.append([image,box])\n    test_df.append(test)\n\nfor i in test_df:\n    if len(i)>0:\n        if len(i)==1:\n            t.append(i[0])\n        else:\n            for j in i:\n                t.append(j)  \nfor i in test:\n    s.append(i[0])\n\nfor image in test_images:\n    if image not in s:\n        r.append(image) \ndetector=MTCNN()\n\nfor image in r:\n    img=cv2.imread(os.path.join(images,image))\n    faces=detector.detect_faces(img)\n    t1=[]\n    for face in faces:\n        box=face['box']\n        t1.append([image,box])\n    test_df1.append(t1) \n\nfor i in test_df1:\n    if len(i)>0:\n        if len(i)==1:\n            t.append(i[0])\n        else:\n            for j in i:\n                t.append(j)","391b11b9":"x=[]\nfor i in t:\n    for j in i[1]:\n        if j<0:\n            x.append(i)","3aeb6d83":"testd=[]\ndef prepare_test():\n    for j in t:\n        if j not in x:\n            img=cv2.imread(os.path.join(images,j[0]),cv2.IMREAD_GRAYSCALE)\n            img=img[j[1][1]:j[1][1]+j[1][3],j[1][0]:j[1][0]+j[1][2]]\n            new_img=cv2.resize(img,(50,50))\n            new_img=new_img.reshape(-1,50,50,1)\n            predict=model.predict(new_img)\n            testd.append([j,predict])\n\nprepare_test()  ","015cd298":"image=[]\nclassname=[]\nx1=[]\nx2=[]\ny1=[]\ny2=[]\nfor i,j in testd:\n    classname.append(np.argmax(j))\n    image.append(i)\ndf=pd.DataFrame(columns=['image'])\ndf['image']=image\n\nimage=[]\n\nfor i in df['image']:\n    image.append(i[0])\n    x1.append(i[1][0])\n    x2.append(i[1][1])\n    y1.append(i[1][2])\n    y2.append(i[1][3])\ndf['name']=image\ndf['x1']=x1\ndf['x2']=x2\ndf['y1']=y1\ndf['y2']=y2    \ndf['classname']=classname\ndf['classname']=lbl.inverse_transform(df['classname'])\ndf.drop(['image'],axis=1,inplace=True)","280b801d":"df.sort_values('name',axis=0,inplace=True,ascending=False)\ndf.to_csv('sub.csv')\nsubmission=pd.read_csv(os.path.join(\"sub.csv\"))\nsubmission.head()","541b7b21":"submission.drop(['Unnamed: 0'],axis=1,inplace=True)\nsubmission.head(20)","26d6747b":"submission.to_csv('submission.csv')","7ad71478":"The dataset contains 6024 images and the annotations are 4326. Hence the dataset can be split as follows"}}