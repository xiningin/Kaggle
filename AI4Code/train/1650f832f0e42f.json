{"cell_type":{"5e64d87f":"code","3b6e2fac":"code","f274fd37":"code","338b2fff":"code","b5f9012f":"code","38aae88e":"code","6dfe417a":"code","f7d544cf":"code","66b27acb":"code","9a7c0bc1":"code","e689750b":"code","77cd77aa":"code","40fcc562":"code","dab57f91":"code","65131c03":"code","d79a6e6c":"code","d1d742f7":"code","8677d3bb":"code","ca0f2e9e":"code","33e49a6c":"code","e06c6d28":"code","2506b7f8":"code","9ab811ad":"code","125dedd9":"code","0deddb45":"code","06623016":"code","465cfaf4":"code","b0a201c8":"markdown"},"source":{"5e64d87f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3b6e2fac":"import matplotlib.pyplot as plt\nfrom collections import Counter","f274fd37":"fg_unet = pd.read_csv(\"\/kaggle\/input\/mnist-w-fgunet-output\/submission.csv\")\nvgg = pd.read_csv(\"\/kaggle\/input\/mnist-w-vgg16-output\/submission.csv\")\nresnet = pd.read_csv(\"\/kaggle\/input\/mnist-w-resnet-output\/submission.csv\")","338b2fff":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nsub = pd.read_csv(\"\/kaggle\/input\/mnist-w-resnet-output\/submission.csv\")","b5f9012f":"# Ensemble 1: majority vote\nmajority = sub.copy()\n\nno_maj = []\nunequal = []\nfor i in range(len(vgg)):\n    lst = [fg_unet.iloc[i].Label, vgg.iloc[i].Label, resnet.iloc[i].Label]\n    if not all(ele == lst[0] for ele in lst):\n        unequal.append(i)\n        count = Counter(lst).most_common()\n        if len(count)==len(lst):\n            no_maj.append(i)\n            majority.iloc[i].Label = lst[-1] # resnet had the highest standalone accuracy\n            img = test.iloc[i,:].values\n            img = img.reshape(28, 28)\n            print(i, lst)\n            plt.imshow(img)\n            plt.show()\n        else:\n            majority.iloc[i].Label = count[0][0]\n    else:\n        majority.iloc[i].Label = lst[0]\nprint(\"Number of rows not all equal: \", len(unequal))\nprint(\"Number of rows with no majority: \", len(no_maj))\n\nmajority.to_csv(\"submission_maj.csv\", index=False)","38aae88e":"from keras.models import load_model\nfrom keras.utils import to_categorical","6dfe417a":"fg_unet = load_model(\"\/kaggle\/input\/mnist-w-fgunet-output\/best_model.h5\")\nvgg = load_model(\"\/kaggle\/input\/mnist-w-vgg16-output\/best_model.h5\")\nresnet = load_model(\"\/kaggle\/input\/mnist-w-resnet-output\/best_model.h5\")","f7d544cf":"X = [train.iloc[i,1:].values for i in range(len(train))]\nX = [x.reshape(28,28) for x in X]\nX_28 = [x.reshape(28,28,1,1) for x in X]\nX_28 = np.array(X_28)\nX = [np.pad(x, 2) for x in X]\nX = np.array(X)\nX = X.reshape(X.shape[0],X.shape[1], X.shape[2],1)\nX = np.repeat(X, 3, axis=-1)","66b27acb":"X_test = [test.iloc[i,:].values for i in range(len(test))]\nX_test = [x.reshape(28,28) for x in X_test]\nX_test_28 = [x.reshape(28,28,1,1) for x in X_test]\nX_test_28 = np.array(X_test_28)\nX_test = [np.pad(x, 2) for x in X_test]\nX_test = np.array(X_test)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1], X_test.shape[2],1)\nX_test = np.repeat(X_test, 3, axis=-1)","9a7c0bc1":"X.shape, X_28.shape, X_test.shape, X_test_28.shape","e689750b":"f_y_train = fg_unet.predict(X_28, verbose=1)\nv_y_train = vgg.predict(X, verbose=1)\nr_y_train = resnet.predict(X, verbose=1)","77cd77aa":"f_y_test = fg_unet.predict(X_test_28, verbose=1)\nv_y_test = vgg.predict(X_test, verbose=1)\nr_y_test = resnet.predict(X_test, verbose=1)","40fcc562":"n_classes = 10\ny = [train.iloc[i,0] for i in range(len(train))]\ny = np.array(y)\nprint(np.unique(y, return_counts=True))\ny = to_categorical(y, num_classes=n_classes)\ny.shape","dab57f91":"# Ensemble 2: Ridge Regression\n\nfrom sklearn.linear_model import Ridge\nX = np.hstack([f_y_train, v_y_train, r_y_train])\nrid = Ridge()\nrid.fit(X, y)","65131c03":"X_pred = np.hstack([f_y_test, v_y_test, r_y_test])","d79a6e6c":"y_pred = rid.predict(X_pred)\ny_pred = np.argmax(y_pred, axis=-1)\nprint(y_pred.shape)","d1d742f7":"ridge = sub.copy()\nfor i in range(len(y_pred)):\n    ridge.iloc[i].Label = y_pred[i]\nridge.to_csv(\"submission_ridge.csv\", index=False)","8677d3bb":"# Ensemble 3: Generic Weighted Average\nfrom keras import Input, Model\nfrom keras.layers import Conv1D, Softmax, Flatten\nfrom keras.initializers import Constant\n\ninit = Constant(.333)\n\nX = Input(shape=(10,3))\nout = Conv1D(1, 1, use_bias=False, kernel_initializer=init, kernel_regularizer='l2')(X)\nout = Flatten()(out)\nout = Softmax()(out)\nmodel = Model(X, out)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\nmodel.summary()","ca0f2e9e":"X = np.stack([f_y_train, v_y_train, r_y_train], axis=-1)\nX_pred = np.stack([f_y_test, v_y_test, r_y_test], axis=-1)\nX.shape, X_pred.shape","33e49a6c":"model.fit(X, y, epochs=10)","e06c6d28":"y_pred = model.predict(X_pred)\nprint(y_pred[0])\ny_pred = np.argmax(y_pred, axis=-1)\nprint(y_pred.shape)","2506b7f8":"weighted = sub.copy()\nfor i in range(len(y_pred)):\n    weighted.iloc[i].Label = y_pred[i]\nweighted.to_csv(\"submission_weighted.csv\", index=False)","9ab811ad":"weights = model.layers[1].get_weights()\nweights = weights\/np.sum(weights)\nweights","125dedd9":"# Ensemble 4 & 5: single transferable vote & runoff\n!pip install pyrankvote","0deddb45":"import pyrankvote\nfrom pyrankvote import Candidate, Ballot","06623016":"candidates = [Candidate(i) for i in range(10)]","465cfaf4":"single = sub.copy()\nrunoff = sub.copy()\nfor i in range(len(X_pred)):\n    ballots = []\n    for j in range(3):\n        ballot = np.argsort(X_pred[i,:,j])\n        ballot = np.flip(ballot)\n        \n        ballots.append(Ballot(ranked_candidates=[candidates[i] for i in ballot]))\n    \n    election_result = pyrankvote.single_transferable_vote(candidates, ballots, number_of_seats=1)\n    winners = election_result.get_winners()\n    \n    single.iloc[i].Label = winners[0].name\n    \n    election_result = pyrankvote.instant_runoff_voting(candidates, ballots)\n    winners = election_result.get_winners()\n    \n    runoff.iloc[i].Label = winners[0].name\n\nsingle.to_csv(\"submission_single.csv\", index=False)\nrunoff.to_csv(\"submission_runoff.csv\", index=False)","b0a201c8":"The output files used in this notebook are from previous models I have built for this competition:\n* [MNIST w\/ FG-UNET](https:\/\/www.kaggle.com\/socathie\/mnist-w-fg-unet\/)\n* [MNIST w\/ ResNet and Data Augmentation](https:\/\/www.kaggle.com\/socathie\/mnist-w-resnet-and-data-augmentation\/)\n* [MNIST w\/ VGG16 and Data Augmentation](https:\/\/www.kaggle.com\/socathie\/mnist-w-vgg16\/)"}}