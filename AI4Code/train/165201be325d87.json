{"cell_type":{"3acd41f3":"code","7885261f":"code","adcc1bb6":"code","9b8993bc":"code","34d9c448":"code","46d1ac8d":"code","cff362c8":"code","bbc939cc":"code","47ff6b40":"code","0ffeb3f0":"code","0a088f8c":"code","237c542d":"code","a3eed02f":"markdown","e115c987":"markdown","5cce3667":"markdown","6194b40a":"markdown","da9ef564":"markdown","965f15e8":"markdown","f378906c":"markdown","d8658eb0":"markdown","fbc599e7":"markdown","adc8fdc9":"markdown","64cb0ac7":"markdown"},"source":{"3acd41f3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils","7885261f":"# Load the data\ntrain = pd.read_csv(\"train.csv\") #42000 rows, 784 pixel columns + 1 label column\ntest = pd.read_csv(\"test.csv\")   #28000 rows, 784 pixel columns","adcc1bb6":"# Split train into X and Y\nY = train['label']\nX = train.drop(columns=['label'])","9b8993bc":"print(X.shape)\nprint(test.shape)\nprint(Y.shape)","34d9c448":"X = X.values.reshape(-1, 28, 28, 1).astype('float32')\ntest = test.values.reshape(-1, 28, 28, 1).astype('float32')","46d1ac8d":"# normalize inputs from 0-255 to 0-1\nX = X \/ 255\ntest = test \/ 255","cff362c8":"num_classes = 10\nY = to_categorical(Y, num_classes)","bbc939cc":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 2)","47ff6b40":"def baseline_model():\n    # create model\n\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n    \n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","0ffeb3f0":"# Build the model\nmodel = baseline_model()\n\n# Fit the model\nmodel.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=86)\n\n# Final evaluation of the model\nscores = model.evaluate(X_test, Y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","0a088f8c":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","237c542d":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"results.csv\",index=False)","a3eed02f":"### 2. Load the given dataset","e115c987":"#### 3.1. Reshape\nWe need to reshape the dataset so that it is suitable for use training a CNN. In Keras, the layers used for two-dimensional convolutions expect pixel values with the dimensions [pixels][width][height][channels]. width = 28, height = 28, and channels = 1 (RGB would be 3 channels, but here it is black\/white)","5cce3667":"### 5. Predictions","6194b40a":"#### 3.4. Split the train and the validation set for the fitting","da9ef564":"#### 3.2. Normalize\nWe perform a grayscale normalization to reduce the effect of illumination's differences. Moreover the CNN converg faster on [0..1] data than on [0..255].","965f15e8":"### 4. CNN model\n\n   * Layer 1: Convolutional layer - 32 filters, size 5x5, relu activation, same padding\n   * Layer 2: Convolutional layer - 32 filters, size 5x5, relu activation, same padding\n   * Layer 3: Max pooling - 2x2\n   * Layer 4: Dropout 25%\n\n\n   * Layer 5: Convolutional layer - 64 filters, size 3x3, relu activation, same padding\n   * Layer 6: Convolutional layer - 64 filters, size 3x3, relu activation, same padding\n   * Layer 7: Max pooling - 2x2, stride 2x2\n   * Layer 8: Dropout 25% \n   \n   \n   * Layer 9: Flatten layer\n   * Layer 10: Dense layer, relu activation\n   * Layer 11: Dropout 50% \n   * Layer 12: Dense layer, softmax activation\n    \nP.S.: A \u201crelu\u201d activation stands for \u201cRectified Linear Units\u201d, which takes the max of a value or zero.","f378906c":"#### 3.3. Encode labels to one hot vectors","d8658eb0":"### 1. Import classes and functions","fbc599e7":"### 3. Pre-process data","adc8fdc9":"#### 4.1. Compile the model\n\nIn the model design process, we\u2019ve created an empty model without an objective function. We need to compile the model and specify:\n\n* a loss function,\n* an optimizer function, and\n* a metric to assess model performance.\n\n#### 4.2 Train the model\n\nThe model is trained using logarithmic loss and the ADAM gradient descent algorithm.","64cb0ac7":"# Convolutional Neural Network for MNIST\n_Gabriella Mansur_\n\nSources: \n* https:\/\/machinelearningmastery.com\/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras\/\n* https:\/\/www.sitepoint.com\/keras-digit-recognition-tutorial\/\n* https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\/notebook#3.-CNN\n\n"}}