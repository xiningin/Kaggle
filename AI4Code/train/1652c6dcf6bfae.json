{"cell_type":{"ad47fde4":"code","9c46b805":"code","789bf196":"code","231da1ce":"code","e039de3c":"code","def6b085":"code","17c941e3":"code","eb07f29e":"code","18a0ec73":"code","d3e76a9d":"code","9f8ae04d":"code","18e81dae":"code","ef6f8988":"code","326565db":"code","c203d270":"code","83784342":"code","d4c8327b":"code","ea3a8c8b":"code","7ab58a8b":"code","08953b2f":"code","b27d495c":"markdown","8a40bfc7":"markdown","aa88c1ea":"markdown","efe28852":"markdown","608ab5d1":"markdown","4f0973f9":"markdown","b97ab3c5":"markdown","eab26fc4":"markdown","4df80a82":"markdown","56ed8584":"markdown","0a413bdd":"markdown","f63dac15":"markdown","4fa5b5b2":"markdown"},"source":{"ad47fde4":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torchvision.transforms as transforms","9c46b805":"device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\ndevice","789bf196":"dataframe_train_combined = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndataframe_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","231da1ce":"dataframe_train, dataframe_validation  = train_test_split(dataframe_train_combined,test_size=0.2, shuffle=True)","e039de3c":"x_train_combined = (dataframe_train_combined.drop('label',axis=1).to_numpy().astype(np.float32)\/255.0).reshape(-1,28,28)  #ALL X data for final train\ny_train_combined = dataframe_train_combined['label'].to_numpy()                                                           #ALL Y data for final train\n\nx_train = (dataframe_train.drop('label',axis=1).to_numpy().astype(np.float32)\/255.0).reshape(-1,28,28)                    #split X data for prelemenary train\ny_train = dataframe_train['label'].to_numpy()                                                                             #split y data for prelemenary train\n    \n                                                                                                                          #x validation to calculate accuracy\nx_validation = torch.from_numpy((dataframe_validation.drop('label',axis=1).to_numpy().astype(np.float32)\/255.0).reshape(-1,28,28)).to(device)\ny_validation = dataframe_validation['label'].to_numpy()                                                                   #y validation to calculate accuracy","def6b085":"my_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(degrees=20),\n    transforms.RandomAffine(degrees=20),\n    transforms.RandomPerspective(),\n    transforms.ToTensor()\n])","17c941e3":"class DigitDataset(Dataset):\n    def __init__(self,x,y):\n        self.x=torch.tensor(x.tolist())\n        self.y=torch.from_numpy(y)\n        self.len=len(y)\n    def __getitem__(self,index):\n        sample = my_transform(self.x[index]).reshape(28,28) , self.y[index]\n            \n        return sample\n    \n    def __len__(self):\n        return self.len\n\ndataset_train = DigitDataset(x_train,y_train)                             #Split data\ndataset_train_combined = DigitDataset(x_train_combined,y_train_combined)  # All data","eb07f29e":"first_x , first_y = dataset_train[0]\nprint(first_y.item())","18a0ec73":"plt.imshow(first_x)","d3e76a9d":"batch_size = 1024\nnum_epochs = 90\nlearning_rate = 0.003\n","9f8ae04d":"train_loader = DataLoader(dataset=dataset_train,batch_size = batch_size, shuffle = True)\ntrain_loader_combined = DataLoader(dataset=dataset_train_combined,batch_size = batch_size, shuffle = True)","18e81dae":"def get_accuracy():\n    with torch.no_grad():\n        y_pred =  model(x_validation)\n        y_pred = y_pred.argmax(dim=1).to('cpu').numpy()\n        return (y_pred == y_validation).sum()\/len(y_validation)","ef6f8988":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        \n        self.drop = nn.Dropout(p=0.5)\n        self.relu = nn.ReLU()\n        \n        self.rnnH = nn.GRU(28,28,batch_first=True,bidirectional=True,num_layers=2,dropout=.5)\n        self.rnnV = nn.GRU(28,28,batch_first=True,bidirectional=True,num_layers=2,dropout=.5)\n        \n        self.fc1H = nn.Linear(56,28)\n        self.fc1V = nn.Linear(56,28)\n        \n        \n        self.cnn1H = nn.Conv2d(1,16,5)\n        self.pool1H = nn.MaxPool2d(2,2)\n        self.cnn2H = nn.Conv2d(16,32,3)\n        self.pool2H = nn.MaxPool2d(2,2)\n        \n        self.cnn1V = nn.Conv2d(1,16,5)\n        self.pool1V = nn.MaxPool2d(2,2)\n        self.cnn2V = nn.Conv2d(16,32,3)\n        self.pool2V = nn.MaxPool2d(2,2)\n        \n        self.combine = nn.Linear(32*5*5*2,512)\n        self.fc2 = nn.Linear(512,512)\n        self.fc3 = nn.Linear(512,10)\n        \n    def forward(self,x):\n        \n        xH = x\n        xV = x.permute(0,2,1)\n        \n        xH,_ = self.rnnH(xH)\n        xV, _= self.rnnV(xV)\n        \n        \n        xH = self.relu(self.fc1H(xH))\n        xV = self.relu(self.fc1V(xV))\n        \n        xH= xH.reshape(-1,1,28,28)\n        xV= xV.reshape(-1,1,28,28)\n        \n        xH = self.pool1H(self.relu(self.cnn1H(xH)))\n        xH = self.pool2H(self.relu(self.cnn2H(xH)))\n        xV = self.pool1V(self.relu(self.cnn1V(xV)))\n        xV = self.pool2V(self.relu(self.cnn2V(xV)))\n        \n        #xH = self.pool2H(self.relu(self.cnn4H(self.relu(self.cnn3H(self.pool1H(self.relu(self.cnn2H(self.relu(self.cnn1H(xH))))))))))\n        #xV = self.pool2H(self.relu(self.cnn4V(self.relu(self.cnn3V(self.pool1V(self.relu(self.cnn2V(self.relu(self.cnn1V(xV))))))))))\n        \n        x = self.drop(torch.cat((xH.reshape(-1,32*5*5), xV.reshape(-1,32*5*5)), dim=1))\n        x = self.drop(self.relu(self.combine(x)))\n\n        x = self.fc3(self.relu(self.fc2(x)))\n        return x\nmodel = Model().to(device)","326565db":"criterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size =10, gamma=0.6)","c203d270":"all_loss =[]\nall_accuracy=[]\n\n\nfor epoch in range(num_epochs):\n    running_loss=0.0\n    loops=0\n    for  x, y in train_loader:\n\n        x , y = x.to(device) , y.to(device)\n\n        pred = model(x)\n        loss= criterion(pred,y)\n        \n        running_loss+=loss.item()\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loops+=1\n    \n    model.eval()\n    all_loss.append(running_loss\/loops)\n    all_accuracy.append(get_accuracy())\n    model.train()\n    scheduler.step()\n    \n    print('Epoch:',epoch+1,'Train_Loss:',all_loss[-1],'VAL_Accuracy',all_accuracy[-1])\n    \n        \n","83784342":"plt.figure(figsize=(12,6))\nplt.plot(all_loss)\nplt.plot(all_accuracy)","d4c8327b":"model = Model().to(device)\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size =10, gamma=0.6)","ea3a8c8b":"all_loss =[]\n\nfor epoch in range(num_epochs):\n    running_loss=0.0\n    loops=0\n    for  x, y in train_loader_combined:\n\n        x , y = x.to(device) , y.to(device)\n\n        pred = model(x)\n        loss= criterion(pred,y)\n        \n        running_loss+=loss.item()\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loops+=1\n\n    all_loss.append(running_loss\/loops)\n    scheduler.step()\n    \n    print('Epoch:',epoch+1,'Train_Loss:',all_loss[-1])","7ab58a8b":"model.eval()\ntest_data = torch.from_numpy((dataframe_test.to_numpy().astype(np.float32())\/255.0).reshape(-1,28,28)).to(device)\npredicted = model(test_data)\npredicted = predicted.argmax(dim=1).to('cpu').numpy().reshape(-1,1)\n\nseq = (np.arange(28000)+1).reshape(-1,1)\nout =  np.append(seq,predicted,axis=1)\nout = pd.DataFrame(out,columns=['ImageId','Label'])\nout.to_csv('out.csv',index=False)\nout.head()","08953b2f":"out.to_csv('out.csv',index=False)","b27d495c":"### Transforms\nThis is used for image augmentation. Basically we will randomly alter the image a bit every time.","8a40bfc7":"# Check first element","aa88c1ea":"# DataLoader","efe28852":"# Predict Test Data and Save","608ab5d1":"# Load and Process Data","4f0973f9":"# Now time to train using all data","b97ab3c5":"# Model Optimizer and Loss","eab26fc4":"### Train_Validation_Split","4df80a82":"# Training Loop (Split data)","56ed8584":"### converting data to appropriate format and dimentions\nx datas are reshaped to 28*28 because thats the image dimentions, and that is what the model expects","0a413bdd":"# Testing Hyperparameters","f63dac15":"### Dataset Class","4fa5b5b2":"### Model Description\nImageShape=28*28 <br>\nThe image is modeled as having 28 sequences with 28 features for each sequence <br>\nThere are 2 bidirectional rnn's. One assumes rows as sequences and columns as features, the other one assumes columns as sequences and rows as features <br>\nSince the rnn's are bidirectional, there will be 2 times the output, so we use a linear layer to combine the outputs of both directions<br>\nThen we treat the rnn outputs as 2 seperate images, and do conv->maxpool->conv->maxpool. <br>\nThen we flatten both and concatenate them. <br>\nThen we pass them through some fully connected layers to get out final output <br>"}}