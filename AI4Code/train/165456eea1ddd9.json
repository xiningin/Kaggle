{"cell_type":{"d8d3533b":"code","202e49c1":"code","5729a239":"code","81203ba9":"code","fdfe6f9a":"code","f38357bc":"code","c5d5c9cb":"markdown","5e024be6":"markdown"},"source":{"d8d3533b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","202e49c1":"import torch\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.nn as nn\n\nimport numpy as np\nimport sys\n\nimport pandas as pd\n\nimport random\n\nfrom sklearn.preprocessing import StandardScaler\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(1)\ntorch.manual_seed(1)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(1)","5729a239":"train = pd.read_csv('\/kaggle\/input\/defense-project\/train_data.csv')\ntrain","81203ba9":"pd.concat((x_train_data, test))","fdfe6f9a":"scaler = StandardScaler()\ntest = pd.read_csv('\/kaggle\/input\/defense-project\/test_data.csv')\n\nx_train_data = train.loc[:,'# mean_0_a':'fft_749_b']\ny_train_data = train.loc[:,'label']\n\nxs_data = scaler.fit_transform(pd.concat((x_train_data, test)).values)\n\n# train\nx_train = torch.FloatTensor(xs_data[:1300])\ny_train = torch.LongTensor(y_train_data.values)\n\nepochs = 10001\n\nW = torch.zeros((2548, 3), requires_grad=True)\nb = torch.zeros(3, requires_grad=True)\n\noptimizer = optim.SGD([W, b], lr=0.01)\n\nfor ep in range(epochs):\n    hypothesis = x_train.matmul(W) + b\n    cost = F.cross_entropy(hypothesis, y_train)\n\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n\n    if ep%1000 == 0:\n        print('{:4}: loss: {:2.8f}'.format(ep, cost.item()))","f38357bc":"test = pd.read_csv('\/kaggle\/input\/defense-project\/test_data.csv')\nwith torch.no_grad():\n    x_test = torch.FloatTensor(xs_data[1300:])\n    \n    hypothesis = x_test.matmul(W) + b\n    \n    real_test_df = pd.DataFrame([[i, r] for i, r in enumerate(torch.argmax(hypothesis, dim=1).numpy())], columns=['Id',  'Category'])\n    real_test_df.to_csv('result.csv', mode='w', index=False)","c5d5c9cb":"# Baseline code","5e024be6":"# \uc804\ucc98\ub9ac (Scaler)\nscaler\ub97c \uc0ac\uc6a9\ud560\ub54c\ub294 train\uacfc test\ub97c \ubb36\uc5b4\uc11c \ud574\uc8fc\ub294\uac8c \uc88b\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4. \uc65c\ub0d0\ud558\uba74 \ud639\uc2dc\ub098 \uc788\uc744 train\uacfc test\uc758 \uac12 \ubd84\ud3ec\uac00 \ub2ec\ub77c \ud288\uc218\uac00 \uc788\uae30\uc5d0 \uac19\uc774 \ubb36\uc5b4\uc11c \ucd5c\ub300\ud55c \uac19\uc740\ud658\uacbd\uc744\ub9cc\ub4e4\uc5b4 \uc90d\uc2dc\ub2e4."}}