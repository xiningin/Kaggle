{"cell_type":{"e0d6977d":"code","17a2b17c":"code","45077dc5":"code","8f602b26":"code","0788a936":"code","091b4141":"code","824cad7c":"code","21bc262a":"code","e272aa90":"code","648600ba":"code","ccce2d8a":"code","450a92df":"code","dc28128f":"code","3dcf1b5e":"code","30d90fca":"code","1d1cbe4e":"code","f8bac045":"code","07965799":"code","82149d0a":"code","5271ff23":"code","d56e4177":"code","6d4668b1":"code","f9bdd628":"code","ba69518e":"code","d3eceb54":"code","8822cbed":"code","7a7270aa":"code","9687f63c":"code","c461ff12":"code","d88e4980":"code","728be61c":"code","0c92f19e":"code","f31ac86b":"code","506079de":"code","1c2b1972":"code","c492a625":"code","f1d0a1cc":"code","ac3236ed":"code","fb9b5430":"code","a1b361dc":"code","65d24da6":"code","af19bc4c":"code","06c542f3":"code","12aa5fe7":"code","a9239f03":"code","9646a841":"code","ae54f598":"code","c35e2419":"code","900495eb":"code","3177e852":"code","0ec20726":"markdown","73f27edb":"markdown","e2f3d752":"markdown","ad75df72":"markdown","0899983c":"markdown","86918be0":"markdown","5451ece6":"markdown","1b16b026":"markdown","96908760":"markdown","962304e6":"markdown","30a63da6":"markdown","6dd08a82":"markdown","f1363862":"markdown","e4efbbf4":"markdown","4e6f83d6":"markdown","6bc640a5":"markdown","d2bd1aab":"markdown","7b4f62b0":"markdown","f1d62e01":"markdown","25ea518c":"markdown","cebfd5c6":"markdown","ea55aa2c":"markdown","8bd44f55":"markdown","f59562aa":"markdown","6c94644b":"markdown","30050d42":"markdown","0e7fa6b9":"markdown","e462b941":"markdown","12fecdab":"markdown","41c8f08f":"markdown"},"source":{"e0d6977d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom scipy.stats import norm\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import preprocessing\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor","17a2b17c":"train = pd.read_csv(\"..\/input\/massp-housing-prices-in-melbourne\/train.csv\", index_col='id')\ntest = pd.read_csv(\"..\/input\/massp-housing-prices-in-melbourne\/test.csv\", index_col='id')","45077dc5":"train.head(5)","8f602b26":"print(f'K\u00edch th\u01b0\u1edbc t\u1eadp train: {train.shape}')\nprint(f'K\u00edch th\u01b0\u1edbc t\u1eadp test: {test.shape}')","0788a936":"duplicate_row = train[train.duplicated()]\nprint(duplicate_row)","091b4141":"train.info()","824cad7c":"train.dtypes.value_counts()","21bc262a":"train.describe()","e272aa90":"test.describe()","648600ba":"train.select_dtypes(exclude=[np.number]).describe()","ccce2d8a":"test.select_dtypes(exclude=[np.number]).describe()","450a92df":"display(train[train.BuildingArea == 0].head(5))\ndisplay(train[train.BuildingArea == 0].shape)","dc28128f":"def missing_values_table(df):\n    # Total missing values\n    mis_val = df.isnull().sum()       \n    # Percentage of missing values\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)       \n    # Make a table with the results\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)        \n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})        \n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n    return mis_val_table_ren_columns\n\nmissing_values_table(train)","3dcf1b5e":"missing_values_table(test)","30d90fca":"train.Price.describe()","1d1cbe4e":"sns.distplot(train['Price'])","f8bac045":"train.Price.describe()","07965799":"sns.distplot(train['Price'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['Price'], plot=plt)\nprint (\"Skew is:\", train.Price.skew())","82149d0a":"sns.boxplot(train['Price'], orient='v' )","5271ff23":"sns.distplot(np.log1p(train['Price']), fit=norm);\nfig = plt.figure()\nres = stats.probplot(np.log1p(train['Price']), plot=plt)\nprint (\"Skew is:\", np.log1p(train.Price).skew())","d56e4177":"def plot_feature(feature, axes):\n    sns.boxplot(data=train.dropna(), x=feature, y='Price',ax=axes[0])\n    axes[0].set_xlabel(feature)\n    #axes[1,0].set_ylabel('Price')\n    axes[0].set_title(f'{feature} v Price')\n    sns.countplot(train[feature].dropna(), ax=axes[1])","6d4668b1":"train['Regionname'] = train['Regionname'].map({'Northern Metropolitan':'N Metro',\n                                            'Western Metropolitan':'W Metro', \n                                            'Southern Metropolitan':'S Metro', \n                                            'Eastern Metropolitan':'E Metro', \n                                            'South-Eastern Metropolitan':'SE Metro', \n                                            'Northern Victoria':'N Vic',\n                                            'Eastern Victoria':'E Vic',\n                                            'Western Victoria':'W Vic'})","f9bdd628":"feature = 'Regionname'\nfig , axes = plt.subplots(1,2, figsize=(14,7), sharex=True)\nplot_feature(feature, axes)","ba69518e":"for feature in ['Type', 'Method', 'CouncilArea']:\n    fig , axes = plt.subplots(1,2, figsize=(14,7), sharex=True)\n    plot_feature(feature, axes)","d3eceb54":"ntrain = train.shape[0]\ntarget = train.Price.values\ndf = pd.concat((train, test)).reset_index(drop=True)\ndf.drop(['Price'], axis=1, inplace=True)","8822cbed":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Day'] = df['Date'].dt.day\ndf['Month'] = df['Date'].dt.month\ndf['Year'] = df['Date'].dt.year\ndf.drop('Date', axis='columns', inplace=True)","7a7270aa":"df.head()","9687f63c":"train = df[:ntrain]\ntest = df[ntrain:]","c461ff12":"numeric_features = train.select_dtypes(include=[np.number])","d88e4980":"numeric_features.describe().transpose()","728be61c":"corr = train.corr()  # Compute the correlation matrix\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]= True # Generate a mask for the upper triangle\nf, ax = plt.subplots(figsize=(12, 9))# Set up the matplotlib figure\nsns.heatmap(corr, mask=mask, cmap='coolwarm',\n            vmin = -1,vmax = 1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot= True, annot_kws={\"size\": 9})# Draw the heatmap with the mask and correct aspect ratio","0c92f19e":"# Suplots of numeric features v price\nsns.set_style('darkgrid')\nf, axes = plt.subplots(5,2, figsize = (20,30))\n\n# Plot [0,0]\nsns.regplot(x = 'Rooms', y = target, data = train, ax=axes[0,0])\naxes[0,0].set_xlabel('Rooms')\naxes[0,0].set_ylabel('Price')\naxes[0,0].set_title('Rooms v Price')\n\n# Plot [0,1]\nsns.regplot(x = 'Distance', y = target, data = train, ax=axes[0,1])\naxes[0,1].set_xlabel('Distance')\naxes[0,1].set_title('Distance v Price')\n\n# Plot [1,0]\nsns.regplot(x = 'Bathroom', y = target, data = train, ax=axes[1,0])\naxes[1,0].set_xlabel('Bathroom')\naxes[1,0].set_ylabel('Price')\naxes[1,0].set_title('Bathroom v Price')\n\n# Plot [1,1]\nsns.regplot(x = 'Car', y = target, data = train, ax=axes[1,1])\naxes[1,0].set_xlabel('Car')\naxes[1,1].set_title('Car v Price')\n\n# Plot [2,0]\nsns.regplot(x = 'Landsize', y = target, data = train, ax=axes[2,0])\naxes[2,0].set_xlabel('Landsize')\naxes[2,0].set_ylabel('Price')\naxes[2,0].set_title('Landsize v  Price')\n\n# Plot [2,1]\nsns.regplot(x = 'BuildingArea', y = target, data = train, ax=axes[2,1])\naxes[2,1].set_xlabel('BuildingArea')\naxes[2,1].set_title('BuildingArea v Price')\n\n# Plot [3,0]\nsns.regplot(x = 'Propertycount', y = target, data = train, ax=axes[3,0])\naxes[3,0].set_xlabel('Propertycount')\naxes[3,0].set_ylabel('Price')\naxes[3,0].set_title('Property Count v Price')\n\n# Plot [3,1]\nsns.regplot(x = 'Day', y = target, data = train, ax=axes[3,1])\naxes[3,1].set_xlabel('Day')\naxes[3,1].set_title('Day v Price')\n\n# Plot [4,0]\nsns.regplot(x = 'Month', y = target, data = train, ax=axes[4,0])\naxes[4,0].set_xlabel('Month')\naxes[4,0].set_ylabel('Price')\naxes[4,0].set_title('Month v  Price')\n\n# Plot [4,1]\nsns.regplot(x = 'Year', y = target, data = train, ax=axes[4,1])\naxes[4,1].set_xlabel('Year')\naxes[4,1].set_title('Year v Price')\n\nplt.show()","f31ac86b":"class DataFrameCleaner(TransformerMixin):\n    \n    def __init__(self):\n        '''\n        Fix errors in the process of collecting data:\n        - \"BuildingArea\" = 0 -> median value\n        - Create a 'Error' column to indicate if the value has been changed\n        '''\n        \n    def fit(self, X, y=None):\n        \n        try:\n            self.error = pd.Series([1 if c == 0 else 0 for c in X.BuildingArea], index=X.index)\n            self.fixed = pd.Series([X.BuildingArea.median() if c == 0 else c for c in X.BuildingArea], index=X.index)\n        except AttributeError:\n            pass\n        \n        return self\n    \n    def transform(self, X, y=None):\n        \n        try:\n            X.BuildingArea = self.fixed\n            X['Error'] = self.error\n        except AttributeError:\n            pass\n        \n        return X","506079de":"class DataFrameImputer(TransformerMixin):\n\n    def __init__(self):\n        \"\"\"\n        Impute missing values:\n        - Columns of dtype object are imputed with the most frequent value in column.\n        - Columns of other types are imputed with mean of column.\n        - Create '{column_name}+_nan' columns to indicate if the value is imputed\n        \"\"\"\n        self.fill_median = ['BuildingArea', 'Landsize', 'YearBuilt']\n        self.fill_min = ['Car', 'Bedroom2', 'Bathroom', 'Rooms']\n        self.fill_freq = ['CouncilArea', 'Regionname', 'Propertycount', 'Distance', 'Postcode', 'Lattitude', 'Longtitude']\n        \n    def fit(self, X, y=None):\n\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if c in self.fill_freq else X[c].median()\n            if c in self.fill_median else X[c].min() for c in X],\n            index=X.columns)\n\n        return self\n\n    def transform(self, X, y=None):\n        \n        for c in X:\n            if c in self.fill_median + self.fill_min + self.fill_freq:\n                X[c+'_nan'] = X[c].isnull()*1\n                \n        return X.fillna(self.fill)","1c2b1972":"train.columns.values","c492a625":"encoder = preprocessing.OneHotEncoder(handle_unknown='ignore')","f1d0a1cc":"class FeatureSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        return X[self.columns]","ac3236ed":"baseline_features = ['Suburb', 'Rooms', 'Type', 'Method', 'SellerG',\n       'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize',\n       'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n       'Longtitude', 'Regionname', 'Propertycount','Day', 'Month',\n       'Year']","fb9b5430":"baseline_preprocessor = Pipeline([\n    ('selector', FeatureSelector(baseline_features)),\n    ('cleaner', DataFrameCleaner()),\n    ('imputer', DataFrameImputer()),\n    ('encoder', encoder),\n])\n\nbaseline_model = Pipeline([\n    ('preprocessor', baseline_preprocessor),\n    ('estimator', XGBRegressor())\n])","a1b361dc":"def score_dataset(X, y, model=baseline_model):\n\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    log_y = np.log(y)\n    score = cross_val_score(\n        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\",\n    )\n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    return score","65d24da6":"score_dataset(train, target)","af19bc4c":"def encode_address(c):\n    try:\n        if 'Avenue' in c or 'Av' in c:\n            return 'Av'\n    except TypeError:\n        print(c)\n    if 'St' in c:\n        return 'St'\n    if 'Rd' in c:\n        return 'Rd'\n    if 'Pde' in c:\n        return 'Pde'\n    if 'Pl' in c:\n        return 'Pl'\n    if 'Esplanade' in c or 'Esp' in c:\n        return 'Esp'\n    s = c.split()[-1]\n    if s == 'Outlook':\n        return 'Out'\n    if s == 'Loop':\n        return 'Lp'\n    if s == 'Nook':\n        return 'Nk'\n    if s == 'Circuit':\n        return 'Cct'\n    if s == 'Terrace':\n        return 'Tce'\n    if s in ['Grove', 'Gve']:\n        return 'Gr'\n    if s == 'Greenway':\n        return 'Gwy'\n    if s in['Avenue', 'Aveue', 'Ave']:\n        return 'Av'\n    if s == 'Boulevard':\n        return 'Bvd'\n    if s in ['Street', 'street']:\n        return 'St'\n    if s == 'Crescent': # Crossway\n        return 'Cr'\n    if s == 'Wy':\n        return 'Wky'\n    if s == 'Highway':\n        return 'Hwy'\n    if s in ['Ridge', 'Ri', 'Ridgeway']:\n        return 'Rdg'\n    if s == 'Esplanade':\n        return 'Esp'\n    if s == 'Mews':\n        return 'Mw'\n    if s == 'Grange':\n        return 'Gra'\n    if s == 'Views':\n        return 'Vw'\n    if s == 'Parkway':\n        return 'Pky'\n    if s == 'Glade':\n        return 'Gld'\n    if 'The' in c:\n        return 'The'\n    return s\n\ndef to_season(month):\n    if month in range(1, 4):\n        return 'Spring'\n    if month in range(4, 7):\n        return 'Summer'\n    if month in range(7, 10):\n        return 'Fall'\n    if month in range(10, 13):\n        return 'Winter'","06c542f3":"class FeatureTransformer(TransformerMixin):\n    \n    def __init__(self):\n        '''\n        Feature Transformer:\n        - Encode 'Address' using the fuction 'encode_address' above.\n        - Encode 'Month' using the fuction 'to_season' above.\n        '''\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X['Address'] = np.vectorize(encode_address)(X['Address'])\n        # X['Season'] = np.vectorize(to_season)(X.Month)\n        X['Age'] = np.where(2019 - X.YearBuilt > 50, \"Historic\", \"Contemporary\")\n        return X\n        ","12aa5fe7":"features = ['Suburb', 'Address', 'Rooms', 'Type', 'Method', 'SellerG',\n       'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize',\n       'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n       'Longtitude', 'Regionname', 'Propertycount', 'Day', 'Month',\n       'Year']","a9239f03":"preprocessor = Pipeline([\n    ('selector', FeatureSelector(features)),\n    ('cleaner', DataFrameCleaner()),\n    ('imputer', DataFrameImputer()),\n    ('transformer', FeatureTransformer()),\n    ('encoder', encoder),\n])\n\nmodel = Pipeline([\n    ('preprocessor', preprocessor),\n    ('estimator', XGBRegressor())\n])\n\nscore_dataset(train, target, model=model)","9646a841":"import optuna\n\ndef objective(trial):\n    xgb_params = dict(\n        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n        n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n    )\n    xgb = XGBRegressor(**xgb_params)\n    tuning_model = Pipeline([\n        ('preprocessor', preprocessor),\n        ('estimator', xgb),\n    ])\n    return score_dataset(train, target, model=tuning_model)\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(objective, n_trials=20)\n# xgb_params = study.best_params","ae54f598":"xgb_params = {\n    'max_depth': 8, \n    'learning_rate': 0.04804510345985137, \n    'n_estimators': 1067, \n    'min_child_weight': 7, \n    'colsample_bytree': 0.243721007657978, \n    'subsample': 0.72095739604202, \n    'reg_alpha': 0.026338688165939338, \n    'reg_lambda': 8.312149146542485\n}","c35e2419":"tuned_model = Pipeline([\n        ('preprocessor', preprocessor),\n        ('estimator', XGBRegressor(**xgb_params)),\n    ])","900495eb":"tuned_model.fit(train, np.log(target))\npredictions = np.exp(tuned_model.predict(test))\n\noutput = pd.DataFrame({'id': test.index, 'Price': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","3177e852":"output","0ec20726":"### T\u00ecm hi\u1ec3u v\u1ec1 c\u00e1c tr\u01b0\u1eddng d\u1eef li\u1ec7u","73f27edb":"# 2. Khai ph\u00e1 d\u1eef li\u1ec7u (EDA)","e2f3d752":"T\u1eeb 3 \u0111\u1ed3 th\u1ecb tr\u00ean:\n- Bi\u1ebfn gi\u00e1 nh\u00e0 (Price) kh\u00f4ng theo ph\u00e2n ph\u1ed1i chu\u1ea9n.\n- Bi\u1ebfn gi\u00e1 nh\u00e0 b\u1ecb l\u1ec7ch tr\u00e1i.\n- C\u00f3 nhi\u1ec1u kho\u1ea3ng gi\u00e1 tr\u1ecb b\u1ea5t th\u01b0\u1eddng (outlier).","ad75df72":"## 2.3. Ph\u00e2n t\u00edch d\u1eef li\u1ec7u ph\u00e2n lo\u1ea1i (Categorical)","0899983c":"**Nh\u1eadn x\u00e9t:**\n- C\u00e1c 8 tr\u01b0\u1eddng b\u1ecb thi\u1ebfu tr\u00ean 23% d\u1eef li\u1ec7u, nguy\u00ean nh\u00e2n c\u00f3 th\u1ec3 do qu\u00e1 tr\u00ecnh thu th\u1eadp t\u1eeb nhi\u1ec1u ngu\u1ed3n kh\u00e1c nhau.","86918be0":"**Nh\u1eadn x\u00e9t:**\n- C\u00f3 nhi\u1ec1u tr\u01b0\u1eddng b\u1ecb thi\u1ebfu d\u1eef li\u1ec7u nh\u01b0 `Bedroom2`, `Bathroom`, `Car`, `Landsize`, `BuildingArea`, `YearBuilt`, ...\n- C\u00e1c tr\u01b0\u1eddng `Bedroom2`, `Bathroom`, `Car`, `Landsize` v\u00e0 `BuildingArea` c\u00f3 min l\u00e0 0 c\u00f3 th\u1ec3 do l\u1ed7i trong thu th\u1eadp d\u1eef li\u1ec7u.\n- Th\u1ed1ng k\u00ea c\u00e1c features c\u1ee7a 2 t\u1eadp `train` v\u00e0 `test` t\u01b0\u01a1ng \u0111\u1ed1i nh\u1ea5t qu\u00e1n, tr\u1eeb tr\u01b0\u1eddng `Landsize` v\u00e0 `BuildingArea` c\u00f3 s\u1ef1 kh\u00e1c nhau trong ph\u00e2n b\u1ed1 \u1edf 2 t\u1eadp do c\u00f3 c\u00e1c gi\u00e1 tr\u1ecb l\u1edbn (max c\u1ee7a `Landsize` \u1edf t\u1eadp `train` v\u00e0 max c\u1ee7a `BuildingArea` \u1edf t\u1eadp `test`).\n- Ph\u00e2n b\u1ed1 c\u1ee7a c\u00e1c h\u1ea7u h\u1ebft tr\u01b0\u1eddng (tr\u1eeb `Lattitude` v\u00e0 `Longtitude`) \u0111\u1ec1u b\u1ecb l\u1ec7ch.\n- Tr\u01b0\u1eddng `Type` v\u00e0 `Method` th\u1ef1c t\u1ebf c\u00f3 \u00edt lo\u1ea1i h\u01a1n trong Data Description.\n- T\u1eadp test c\u00f3 nh\u1eefng lo\u1ea1i kh\u00f4ng c\u00f3 t\u1eadp Train nh\u01b0 \u1edf tr\u01b0\u1eddng `Suburb`, `SellerG`.","5451ece6":"### Label Encoding c\u00e1c tr\u01b0\u1eddng ph\u00e2n lo\u1ea1i","1b16b026":"### Xem x\u00e9t d\u1eef li\u1ec7u thi\u1ebfu","96908760":"# 4. Thi\u1ebft l\u1eadp Baseline","962304e6":"## 2.4.2. T\u1ed5ng quan d\u1eef li\u1ec7u","30a63da6":"# 2.4. Ph\u00e2n t\u00edch d\u1eef li\u1ec7u s\u1ed1\n\n## 2.4.1. Bi\u1ebfn \u0111\u1ed5i tr\u01b0\u1eddng `Date`","6dd08a82":"# 3. Ti\u1ec1n x\u1eed l\u00fd d\u1eef li\u1ec7u\n\n## 3.1. Data cleansing","f1363862":"### Ph\u00e2n b\u1ed1 tr\u01b0\u1eddng target","e4efbbf4":"### Feature Selector v\u00e0 Baseline Model","4e6f83d6":"R\u00fat g\u1ecdn t\u00ean c\u1ee7a c\u00e1c v\u00f9ng trong tr\u01b0\u1eddng `Region` \u0111\u1ec3 d\u1ec5 theo d\u00f5i h\u01a1n.","6bc640a5":"### Import c\u00e1c th\u01b0 vi\u1ec7n","d2bd1aab":"## 3.2. X\u1eed l\u00fd d\u1eef li\u1ec7u thi\u1ebfu","7b4f62b0":"### S\u1eed d\u1ee5ng transform log(1+x) cho tr\u01b0\u1eddng target","f1d62e01":"### Quan s\u00e1t c\u00e1c th\u1ed1ng k\u00ea","25ea518c":"## 2.1 Ph\u00e2n t\u00edch target","cebfd5c6":"# 1. Data validation","ea55aa2c":"### Ph\u00e2n lo\u1ea1i c\u00e1c c\u1ed9t d\u1eef li\u1ec7u","8bd44f55":"### Load data","f59562aa":"## 1.2. Th\u00f4ng tin t\u1ed5ng quan target","6c94644b":"### Ki\u1ec3m tra xem c\u00e1c h\u00e0ng c\u00f3 tr\u00f9ng nhau kh\u00f4ng?","30050d42":"# 5. Feature Engineering","0e7fa6b9":"# Melbourne Housing Prediction - Team 4\n\n---\n\n### M\u00f4 t\u1ea3: \n\nT\u00ecm hi\u1ec3u v\u1ec1 d\u1eef li\u1ec7u v\u00e0 x\u00e2y d\u1ef1ng m\u00f4 h\u00ecnh d\u1ef1 \u0111o\u00e1n gi\u00e1 nh\u00e0 \u1edf Melbourne b\u1eb1ng m\u00f4 h\u00ecnh h\u1ed3i quy.","e462b941":"## 6. Hyperparameter Tuning","12fecdab":"Kh\u00f4ng c\u00f3 h\u00e0ng tr\u00f9ng trong t\u1eadp Train.","41c8f08f":"## 1.1. Th\u00f4ng tin t\u1ed5ng quan data"}}