{"cell_type":{"e4ffb861":"code","46fe40fa":"code","12929829":"code","cc26e1a1":"code","d0f03a89":"code","717ee68c":"code","355c843d":"code","d0f6e80f":"code","b371f9ba":"code","a4495585":"code","1a0b1bcb":"code","fec4efdf":"code","d30e9e39":"code","3c0e2abf":"code","10605a62":"code","8798b38c":"code","46cf21ed":"markdown","3deddbb7":"markdown","9cd79cf9":"markdown","099d1da8":"markdown","7681593c":"markdown","c63cb532":"markdown","e28e3d96":"markdown","ea70298b":"markdown","27fe0f34":"markdown","51d6982e":"markdown","855f78c7":"markdown","8918c2cc":"markdown","ec2b144d":"markdown","1881cbb2":"markdown"},"source":{"e4ffb861":"import pandas as pd\nimport os\nimport datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OrdinalEncoder\nimport xml.etree.ElementTree as ETree\n%matplotlib inline\nfrom sklearn.preprocessing import OrdinalEncoder","46fe40fa":"from re import search\n\ndataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'\n#read weather data\nweather = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))\n#create a list of datetime format from (hour, month,year,day)in weather dataset\nlst=[]\nfor index, row in weather.iterrows():   \n    lst.append(datetime.datetime(row['Year'],row['Month'],row['Day'],row['Hour']))\nweather['timestamp']=lst\n\n#assign the most frequent weather_condition to the nullable weather_condition\nweather[\"Weather_Condition\"]=weather[\"Weather_Condition\"].fillna('Partly Cloudy')\n#assign the highest frequent Wind_Chill(F) to the nullable Wind_Chill(F)\nweather['Wind_Chill(F)']=weather['Wind_Chill(F)'].fillna(60.0)\n#Drop duplicates and extract an encoded version from weather_condition as \"Condition Encoded\"\nweather.drop_duplicates(subset =\"timestamp\",keep = 'first', inplace = True)\nweather[\"Weather_Condition\"] =weather[\"Weather_Condition\"].astype('category')\nweather[\"Condition Encoded\"] = weather[\"Weather_Condition\"].cat.codes\n#set nulls to mean per column\nweather=weather.fillna(weather.mean())","12929829":"weather.info()","cc26e1a1":"#Read holidays data\nxmldata = os.path.join(dataset_path, 'holidays.xml')\nprstree = ETree.parse(xmldata)\nroot = prstree.getroot()\nrows = []\nfor rowno in root:\n    date = rowno.find('date').text\n    description = rowno.find('description').text\n\n    rows.append({\"timestamp\": date,\n                 \"Descriptions\": description})\n#Create a dataframe from\nxmlDf = pd.DataFrame(rows, columns=['timestamp', 'Descriptions'])\nxmlDf[\"timestamp\"] =xmlDf[\"timestamp\"].astype('datetime64')","d0f03a89":"# Function to return a dataframe of joined data from a csv_data at path ,holidays.xml and weather.csv \ndef prepare_data(path):\n    #read dataframe from the csv at given path\n    df = pd.read_csv(os.path.join(dataset_path, path))\n    #cast timestamp column to datetime\n    df['timestamp'] = pd.to_datetime(df['timestamp']).dt.floor('H')\n    #encode Side column into 0\/1 numerical values\n    ord_enc = OrdinalEncoder()\n    df[\"Side\"] = ord_enc.fit_transform(df[[\"Side\"]])\n    #merge the main df with weather\n    combined_df = pd.merge(df, weather, how=\"inner\", on=\"timestamp\")\n    \n    #combine with holidays data\n    combined_df['timestamp']=[row['timestamp'].date() for index, row in combined_df.iterrows()]\n    combined_df['timestamp'] = combined_df['timestamp'].astype('datetime64')\n    combined_df2 = pd.merge(combined_df, xmlDf, how=\"left\", on=\"timestamp\")\n    combined_df2['Is_holiday']  = combined_df2['Descriptions'].notnull().astype('int')\n    combined_df2=combined_df2.drop(columns=['Descriptions'])\n    return combined_df2","717ee68c":"#read train data and merge with weathe and holidays\ndf = prepare_data('train.csv')\n#Used Spearman for more correlation accuarcy\nplt.figure(figsize=(20,10))\ncor = df.drop(columns='ID').corr(method='spearman')\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","355c843d":"#create a scatter plot of column2 vs 'Severity' column\nimport seaborn as sns\ndef plot_VS_Severity(column2 ):\n    fig = plt.figure(figsize=(15,10))\n    #plt.scatter(df['Severity'] ,df[column2])\n    sns.set_theme(style=\"ticks\", color_codes=True)\n    sns.catplot(x=df['Severity'], y=df[column2], data=df)\n    plt.title(column2+' VS Severity Scatter Plot')\n    plt.show()\n\n#plot_VS_Severity('Weather_Condition' )\nplot_VS_Severity('Lat' )\nplot_VS_Severity('Lng' )\nplot_VS_Severity('Wind_Chill(F)' )\n#plot_VS_Severity('Month' )\n#plot_VS_Severity('Day' )\nplot_VS_Severity('Distance(mi)' )\n#plot_VS_Severity('Visibility(mi)' )\n#plot_VS_Severity('Wind_Speed(mph)' )\n#plot_VS_Severity('Humidity(%)' )\n#plot_VS_Severity('Temperature(F)' )\n","d0f6e80f":"df.drop(columns='ID').describe()","b371f9ba":"df.info()","a4495585":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42) # Try adding `stratify` here\n\nX_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']\ntrain_df.head()","1a0b1bcb":"# This cell is used to select the numerical features. IT SHOULD BE REMOVED AS YOU DO YOUR WORK.\nX_train = X_train[['Condition Encoded','Lat', 'Lng','Month','Day','Stop','Is_holiday','Wind_Chill(F)','Crossing', 'Distance(mi)','Side']]\nX_val = X_val[['Condition Encoded','Lat', 'Lng','Month','Day','Stop','Is_holiday','Wind_Chill(F)','Crossing', 'Distance(mi)','Side']]\n","fec4efdf":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)","d30e9e39":"print(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","3c0e2abf":"test_df =prepare_data('test.csv')\ntest_df.head()","10605a62":"X_test = test_df.drop(columns=['ID'])\n\n# You should update\/remove the next line once you change the features used for training\nX_test = X_test[['Condition Encoded','Lat', 'Lng','Month','Day','Stop','Is_holiday','Wind_Chill(F)','Crossing', 'Distance(mi)','Side']]\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted\n\ntest_df.head()","8798b38c":"test_df[['ID', 'Severity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","46cf21ed":"## Model Training\n\nLet's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. ","3deddbb7":"## Exploratory Data Analysis\nIn this step, one should load the data and analyze it. However, I'll load the data and do minimal analysis. You are encouraged to do thorough analysis!\n\nLet's load the data using `pandas` and have a look at the generated `DataFrame`.","9cd79cf9":"## Data Splitting\n\nNow it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n\n*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* ","099d1da8":"## Import the libraries\n\nWe'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections.","7681593c":"Well. That's a good start, right? A classifier that predicts all examples' `Severity` as 2 will get around 0.63. You should get better score as you add more features and do better data preprocessing.","c63cb532":"Now let's test our classifier on the validation dataset and see the accuracy.","e28e3d96":"## Submission File Generation\n\nWe have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n\nFirst, we'll load the data.","ea70298b":"## Conclusion\n\nIn this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. We chose not to go into details in each step to keep the welcoming notebook simple and make a room for improvement.\n\nYou're encourged to `Fork` the notebook, edit it, add your insights and use it to create your submission.","27fe0f34":"The output shows desciptive statistics for the numerical features, `Lat`, `Lng`, `Distance(mi)`, and `Severity`. I'll use the numerical features to demonstrate how to train the model and make submissions. **However you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.**","51d6982e":"The remaining steps is to submit the generated file and are as follows. \n\n1. Press `Save Version` on the upper right corner of this notebook.\n2. Write a `Version Name` of your choice and choose `Save & Run All (Commit)` then click `Save`.\n3. Wait for the saved notebook to finish running the go to the saved notebook.\n4. Scroll down until you see the output files then select the `submission.csv` file and click `Submit`.\n\nNow your submission will be evaluated and your score will be updated on the leaderboard! CONGRATULATIONS!!","855f78c7":"We've got 6407 examples in the dataset with 14 featues, 1 ID, and the `Severity` of the crash.\n\nBy looking at the features and a sample from the data, the features look of numerical and catogerical types. What about some descriptive statistics?","8918c2cc":"As pointed out eariler, I'll use the numerical features to train the classifier. **However, you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.** ","ec2b144d":"Note that the test set has the same features and doesn't have the `Severity` column.\nAt this stage one must **NOT** forget to apply the same processing done on the training set on the features of the test set.\n\nNow we'll add `Severity` column to the test `DataFrame` and add the values of the predicted class to it.\n\n**I'll select the numerical features here as I did in the training set. DO NOT forget to change this step as you change the preprocessing of the training data.**","1881cbb2":"Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only."}}