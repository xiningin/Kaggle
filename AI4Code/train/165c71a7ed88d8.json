{"cell_type":{"e84250fe":"code","05409c4b":"code","9bee3aa4":"code","9fc3e08c":"code","68980091":"code","01fce1b8":"code","6ed90a22":"code","24c0e19b":"code","51fe0159":"code","bad342b7":"code","5a04ab33":"code","5d001b23":"code","c39c4112":"code","367312dd":"code","3f9ed317":"code","c22ad493":"code","597ed00e":"code","fa38ea4a":"code","f315e678":"code","6a86ccd3":"code","31bffd58":"code","56bb14dd":"code","f32b459e":"code","d6b4741b":"code","b6f60cb9":"code","338b59a9":"code","dc13c826":"code","82a8c4ca":"code","a6a471ea":"code","79e798e0":"code","e7e2334d":"code","d8bfe8a7":"markdown","71b9ffbf":"markdown","9c7a1a32":"markdown","b463bbc6":"markdown","3a3da347":"markdown","a9a96407":"markdown","54532315":"markdown","f985ac80":"markdown","70bdfcab":"markdown","7f5e1d64":"markdown","b9534c03":"markdown","d0fadea8":"markdown","175c6880":"markdown"},"source":{"e84250fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","05409c4b":"df = pd.read_excel('\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\ndf.head()","9bee3aa4":"df.isnull().sum()","9fc3e08c":"na_percent = (df.isnull().sum()\/len(df))[(df.isnull().sum()\/len(df))>0].sort_values(ascending=False)\n\nmissing_data = pd.DataFrame({'Missing Percentage':na_percent*100})\nmissing_data","68980091":"na = (df.isnull().sum() \/ len(df)) * 100\nna = na.drop(na[na == 0].index).sort_values(ascending=False)\n\nf, ax = plt.subplots(figsize=(12,8))\nsns.barplot(x=na.index, y=na)\nplt.xticks(rotation='90')\nplt.xlabel('Features', fontsize=15)\nplt.title('Percentage Missing', fontsize=15)","01fce1b8":"# Lets first handle numerical features with nan value\nnumerical_nan = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes!='O']\nnumerical_nan","6ed90a22":"df[numerical_nan].isna().sum()","24c0e19b":"## Replacing the numerical Missing Values\n\nfor feature in numerical_nan:\n    ## We will replace by using median since there are outliers\n    median_value=df[feature].median()\n    \n    df[feature].fillna(median_value,inplace=True)\n    \ndf[numerical_nan].isnull().sum()","51fe0159":"# categorical features\ncategorical_feat = [feature for feature in df.columns if df[feature].dtypes=='O']\nprint('Total categorical features: ', len(categorical_feat))\nprint('\\n',categorical_feat)","bad342b7":"# categorical features with missing values\ncategorical_nan = [feature for feature in df.columns if df[feature].isna().sum()>1 and df[feature].dtypes=='O']\nprint(categorical_nan)","5a04ab33":"from sklearn.preprocessing import LabelEncoder\ncategorical_col = ('AGE_PERCENTIL', 'WINDOW')\n        \n        \nfor col in categorical_col:\n    label = LabelEncoder() \n    label.fit(list(df[col].values)) \n    df[col] = label.transform(list(df[col].values))\n\nprint('Shape all_data: {}'.format(df.shape))","5d001b23":"from scipy.stats import norm, skew\nnum_features = df.dtypes[df.dtypes != 'object'].index\nskewed_features = df[num_features].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_features})\nskewness.head(15)","c39c4112":"numerical_df = df.select_dtypes(exclude='object')\n\nfor i in range(len(numerical_df.columns)):\n    f, ax = plt.subplots(figsize=(7, 4))\n    fig = sns.distplot(numerical_df.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n    plt.xlabel(numerical_df.columns[i])","367312dd":"from sklearn.model_selection import train_test_split\n# Hot-Encode Categorical features\ndf = pd.get_dummies(df) \n\n# Splitting dataset back into X and test data\nX = df[:len(df)]\ntest = df[len(df):]\n\nX.shape","3f9ed317":"# Save target value for later\ny = df.HEMATOCRITE_MAX.values\n\n# In order to make imputing easier, we combine train and test data\ndf.drop(['HEMATOCRITE_MAX'], axis=1, inplace=True)\ndf = pd.concat((df, test)).reset_index(drop=True)","c22ad493":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=0)","597ed00e":"from sklearn.model_selection import KFold\n# Indicate number of folds for cross validation\nkfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Parameters for models\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [0.00005, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]","fa38ea4a":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LassoCV\n# Lasso Model\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas = alphas2, random_state = 42, cv=kfolds))\n\n# Printing Lasso Score with Cross-Validation\nlasso_score = cross_val_score(lasso, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlasso_rmse = np.sqrt(-lasso_score.mean())\nprint(\"LASSO RMSE: \", lasso_rmse)\nprint(\"LASSO STD: \", lasso_score.std())","f315e678":"# Training Model for later\nlasso.fit(X_train, y_train)","6a86ccd3":"from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas = alphas_alt, cv=kfolds))\nridge_score = cross_val_score(ridge, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nridge_rmse =  np.sqrt(-ridge_score.mean())\n# Printing out Ridge Score and STD\nprint(\"RIDGE RMSE: \", ridge_rmse)\nprint(\"RIDGE STD: \", ridge_score.std())","31bffd58":"# Training Model for later\nridge.fit(X_train, y_train)","56bb14dd":"elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\nelastic_score = cross_val_score(elasticnet, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nelastic_rmse =  np.sqrt(-elastic_score.mean())\n\n# Printing out ElasticNet Score and STD\nprint(\"ELASTICNET RMSE: \", elastic_rmse)\nprint(\"ELASTICNET STD: \", elastic_score.std())","f32b459e":"# Training Model for later\nelasticnet.fit(X_train, y_train)","d6b4741b":"from lightgbm import LGBMRegressor\nlightgbm = make_pipeline(RobustScaler(),\n                        LGBMRegressor(objective='regression',num_leaves=5,\n                                      learning_rate=0.05, n_estimators=720,\n                                      max_bin = 55, bagging_fraction = 0.8,\n                                      bagging_freq = 5, feature_fraction = 0.2319,\n                                      feature_fraction_seed=9, bagging_seed=9,\n                                      min_data_in_leaf =6, \n                                      min_sum_hessian_in_leaf = 11))\n\n# Printing out LightGBM Score and STD\nlightgbm_score = cross_val_score(lightgbm, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nlightgbm_rmse = np.sqrt(-lightgbm_score.mean())\nprint(\"LIGHTGBM RMSE: \", lightgbm_rmse)\nprint(\"LIGHTGBM STD: \", lightgbm_score.std())","b6f60cb9":"# Training Model for later\nlightgbm.fit(X_train, y_train)","338b59a9":"from xgboost import XGBRegressor\nxgboost = make_pipeline(RobustScaler(),\n                        XGBRegressor(learning_rate =0.01, n_estimators=3460, \n                                     max_depth=3,min_child_weight=0 ,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,nthread=4,\n                                     scale_pos_weight=1,seed=27, \n                                     reg_alpha=0.00006))\n\n# Printing out XGBOOST Score and STD\nxgboost_score = cross_val_score(xgboost, X, y, cv=kfolds, scoring='neg_mean_squared_error')\nxgboost_rmse = np.sqrt(-xgboost_score.mean())\nprint(\"XGBOOST RMSE: \", xgboost_rmse)\nprint(\"XGBOOST STD: \", xgboost_score.std())","dc13c826":"# Training Model for later\nxgboost.fit(X_train, y_train)","82a8c4ca":"results = pd.DataFrame({\n    'Model':['Lasso',\n            'Ridge',\n            'ElasticNet',\n            'LightGBM',\n            'XGBOOST',\n            ],\n    'Score':[lasso_rmse,\n             ridge_rmse,\n             elastic_rmse,\n             lightgbm_rmse,\n             xgboost_rmse,\n             \n            ]})\n\nsorted_result = results.sort_values(by='Score', ascending=True).reset_index(drop=True)\nsorted_result","a6a471ea":"f, ax = plt.subplots(figsize=(14,8))\nplt.xticks(rotation='90')\nsns.barplot(x=sorted_result['Model'], y=sorted_result['Score'])\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Performance', fontsize=15)\nplt.ylim(0.10, 0.12)\nplt.title('RMSE', fontsize=15)","79e798e0":"# Predict every model. Since we don't have test, that part of the script desn't make any sense.   \n#lasso_pred = lasso.predict(test)\n#ridge_pred = ridge.predict(test)\n#elasticnet_pred = elasticnet.predict(test)\n#lightgbm_pred = lightgbm.predict(test)\n#xgboost_pred = xgboost.predict(test)","e7e2334d":"#No test file, no predictions\n#elasticnet_pred = elasticnet.predict(test)\n# Combine predictions into final predictions\n#final_predictions = np.expm1((0.3*elasticnet_pred) + (0.3*lasso_pred) + (0.2*ridge_pred) + \n              # (0.1*xgboost_pred) + (0.1*lightgbm_pred))","d8bfe8a7":"#Syrian-Lebanese - Socializing and sharing \n\nThe Syrian-Lebanese is an international reference center for health. Through its service units, and also through its social responsibility, teaching and research efforts, it helps an increasing number of Brazilians to have a better and healthier life. This includes more than 120,000 patients annually treated at its facilities and also citizens who benefit from  public-p cooperation Rivada , projects in support of the Unified Health System (SUS) and medical knowledge disseminated in their programs formation.\n\nThe humanization of service, pioneering spirit and excellence are the bases of the operations of the S\u00edrio-Liban\u00eas and are part of its origin. The institution emerged in 1921, when a group of immigrants from the Syrian-Lebanese community in Brazil met with the objective of creating a project that would return the warm welcome they received in the country. The Ladies' Beneficent Society was created, a philanthropic entity that maintains the institution until today.https:\/\/translate.google.com.br\/translate?hl=en&sl=pt&u=https:\/\/www.hospitalsiriolibanes.org.br\/&prev=search&pto=aue","71b9ffbf":"#Creating a Visualization of every feature with missing values","9c7a1a32":"#Checking Skew - Create a new variable containing the dataset of only numerical features","b463bbc6":"#Viewing Model Performance - View Model Performance through a DataFrame and a barplot","3a3da347":"#Categorical features(handling missing data)","a9a96407":"#Dealing with Numerical features(handling missing data)","54532315":"It was suppose to have bars on the figure above. There is none and I don't know how to fix it.","f985ac80":"#Codes from Pratik Barua https:\/\/www.kaggle.com\/pratikbarua\/house-pricing-predictions","70bdfcab":"Das War's, Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","7f5e1d64":"#Lasso","b9534c03":"#Skew Visualization - Visualize each numerical feature with distplot","d0fadea8":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQHI1lvD6LtujKDpxxNCWSuZTK5fRjhOd-Slg&usqp=CAU)\nbrasiliaempresas.com.br","175c6880":"#Label Encoding.\n\nOur dataset cannot run with categorical columns so we must Label Encode these columns in order to make them numerical"}}