{"cell_type":{"5db9346d":"code","1c9fa197":"code","5ab9190f":"code","08be2ac2":"code","69601fd3":"code","01ca1291":"code","5c45664b":"code","2080b445":"code","210bbf2a":"code","f78b484d":"markdown","2b9edcda":"markdown","b983f8b7":"markdown","5f355063":"markdown","899dfee0":"markdown","75054bdb":"markdown","654dc80e":"markdown"},"source":{"5db9346d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom numpy.random import seed\nimport tensorflow as tf","1c9fa197":"dftrain = pd.read_csv('..\/input\/instagram-fake-spammer-genuine-accounts\/train.csv')\ndftest = pd.read_csv('..\/input\/instagram-fake-spammer-genuine-accounts\/test.csv')\n\ndf = pd.concat([dftrain, dftest], axis=0, sort=True)\ndf.head()","5ab9190f":"sns.countplot(x='profile pic', data=df, palette='hls', hue='fake')\nplt.xticks(rotation=45)\nplt.show()","08be2ac2":"sns.countplot(x='private', data=df, palette='hls', hue='fake')\nplt.xticks(rotation=45)\nplt.show()","69601fd3":"# Scale Continuous Features\ncontinuous_features = ['nums\/length username', 'description length', '#posts', '#followers', '#follows']\n\nscaler = StandardScaler()\nfor feature in continuous_features:\n    df[feature] = df[feature].astype('float64')\n    df[feature] = scaler.fit_transform(df[feature].values.reshape(-1, 1))\n\ndftrain.head()","01ca1291":"# Let's create our train test split\nX_train = df[pd.notnull(df['fake'])].drop(['fake'], axis=1)\ny_train = df[pd.notnull(df['fake'])]['fake']\nX_test = df[pd.isnull(df['fake'])].drop(['fake'], axis=1)","5c45664b":"model = Sequential()\nmodel.add(Dense(11, input_dim=X_train.shape[1], activation='linear', name='input_layer'))\nmodel.add(Dense(22, activation='linear', name='hidden_layer'))\nmodel.add(Dropout(0.0))\nmodel.add(Dense(1, activation='sigmoid', name='output_layer'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","2080b445":"training = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\nval_acc = np.mean(training.history['accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('accuracy', val_acc*100))","210bbf2a":"# summarize history for accuracy\nplt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","f78b484d":"## Data\n\nThe dataset contains accounts features such as: # of followers, # of following, presence of profile picture etc.\nThe label 'fake' is a value 0 (real profile) or 1 (fake profile).\n\nThe data is available for download here: `kaggle datasets download -d free4ever1\/instagram-fake-spammer-genuine-accounts`.","2b9edcda":"# Tensorflow instagram fake accounts detector\n\nFor this classification problem, I decided to use Tensorflow and built a neural network with 3 dense layers (1 input, 1 hidden, 1 output). The result is a model with an accuracy of ~80%","b983f8b7":"## Results","5f355063":"The model has been tested at several epochs number, and it seems to peek its performance at ~10 epochs with an accuracy oscillating around 80%.\nSome factors that can increase the overall accuracy are random seeding, which also helps with reproducibility. ","899dfee0":"## Data pre processing and overview","75054bdb":"There are 11 features in total and 1 categorical label. \nSome of them are categorical and some of them continuous, so we can scale the continous feature to prevent them from messing up with the prediction.\n","654dc80e":"## Neural Network Model\n\nThe model consists of 3 layers. The input layer contains 11 perceptrons, one for each feature of the dataset.\nThe hidden layer is densely connected and has 22 neurons.\nFinally the output layer only contains 1 output neuron for the final prediction."}}