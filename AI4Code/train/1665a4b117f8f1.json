{"cell_type":{"b9d7c4d1":"code","5604eb14":"code","61ec9c32":"code","14640cff":"code","d57328f1":"code","74b57542":"code","11e67e3d":"code","4fb22834":"code","abe830ec":"code","82e5ea39":"code","e4f36d8e":"markdown","4a4b23e0":"markdown","aabe10b2":"markdown","b1a933ba":"markdown"},"source":{"b9d7c4d1":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, utils, callbacks\nimport tensorflow as tf\n\nimport os","5604eb14":"nbr_of_clases = 10#10\u5206\u7c7b\nvalidation_percentage = 0.2#\u9a8c\u8bc1\u96c6\u6bd4\u4f8b\nresnet_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'#\u9884\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\n\ntraining_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')#\u8bfb\u53d6\u6570\u636e","61ec9c32":"def prepare_data(data_to_transform):\n    data = data_to_transform.copy()\n    data = data.reshape(-1, 28, 28, 1) \/ 255\n    return data","14640cff":"y = training_data['label'].values\nX = training_data.drop('label',axis = 1).values\n\ny = keras.utils.to_categorical(y, nbr_of_clases)#\u6807\u79f0\u578b\u7c7b\u522b\u8f6c\u72ec\u70ed\u7801\nX_rgb = prepare_data(X)#\u53d8\u4e3a28*28\uff0c\u6570\u503c\u8303\u56f40-1\n\nX_train, X_val, y_train, y_val = train_test_split(X_rgb, y, test_size=validation_percentage)","d57328f1":"from keras import layers,models\n\nmodel = models.Sequential([\n    layers.Conv2D(32, 3, activation='relu', input_shape=(128,128,1), padding='same'),\n    layers.Conv2D(32, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(padding='same'),\n    layers.Dropout(0.5),\n    layers.Conv2D(64, 3, activation='relu', padding='same'),\n    layers.Conv2D(64, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(padding='same'),\n    layers.Dropout(0.25),\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(nbr_of_clases, activation='softmax'),\n])\n#\u4e24\u4e2a\u5377\u79ef\u5355\u5143\uff08\u6bcf\u4e2a\u5305\u542b\u4e24\u4e2a\u5377\u79ef\u5c42\u548c\u4e00\u4e2a\u6700\u5927\u6c60\u5316\u5c42\uff09\uff0c\u901a\u8fc7\u4e00\u4e2adropout\u5c42\u540e\u8fdb\u884c\u5747\u503c\u6c60\u5316\uff0c\u7136\u540e\u7528\u5168\u8fde\u63a5\u5c42\u8f93\u51fa\n\nmodel.summary()\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'],)","74b57542":"def get_fitted_data_generator(data): #\u6570\u636e\u589e\u5f3a\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # channel\u5747\u503c\u5f52\u4e00\u5316\n        samplewise_center=False,  # \u6bcf\u4e2aX\u5168\u5c40\u5747\u503c\u5f52\u4e00\u5316\n        featurewise_std_normalization=False,  # channel\u6807\u51c6\u5dee\u5f52\u4e00\u5316\n        samplewise_std_normalization=False,  # \u6bcf\u4e2aX\u5168\u5c40\u6807\u51c6\u5dee\u5f52\u4e00\u5316\n        zca_whitening=False,  # ZCA\u767d\u5316\uff08PCA\u964d\u7ef4\u540e\u518d\u53d8\u6362\u4e3a\u539f\u6765\u7684\u7ebf\u6027\u7a7a\u95f4\uff09\n        zoom_range = 0.1, # \u968f\u673a\u7f29\u653e\n        height_shift_range=0.1,  # \u968f\u673a\u5e73\u79fb\n)\n    datagen.fit(data)\n    return datagen\n    \ndef fit_model_generator(model, X_train, y_train, epochs=1, batch=32, X_val=None, y_val=None):#batchsize\u4e3a32\n    image_nbr = np.size(X_train, 0)\n    training_data_generator = get_fitted_data_generator(X_train)\n    es = callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)#\u65e9\u505c\n    rlp = callbacks.ReduceLROnPlateau(    monitor='val_loss', factor=0.1, patience=2, min_lr=1e-10, mode='min', verbose=1)#\u5b66\u4e60\u7387\u8870\u51cf\n    return model.fit_generator(training_data_generator.flow(X_train, y_train, batch_size=batch), steps_per_epoch=(image_nbr\/\/batch),callbacks=[es, rlp],epochs=epochs, validation_data=(X_val, y_val), verbose=1)#fit_generator\u4f20\u9012\u7684\u662fsteps_per_epoch\u800c\u4e0d\u662fbatchsize","11e67e3d":"full_data_model = fit_model_generator(model, X_train, y_train, epochs=150,X_val=X_val,y_val=y_val)","4fb22834":"testing_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv').values#\u8bfb\u53d6\u6d4b\u8bd5\u6570\u636e\ntesting_data = prepare_data(testing_data)#\u53d8\u4e3a28*28\u76843\u901a\u9053\u56fe\u7247\uff0c\u6570\u503c\u8303\u56f40-1\n\ndef get_predictions(model, data):\n    return np.array([np.argmax(prediction) for prediction in model.predict(data)])\n\nfinal_predictions = get_predictions(model, testing_data)#\u9884\u6d4b","abe830ec":"submission_filename = 'submission.csv'\nanswers = pd.DataFrame({'ImageId':range(1, final_predictions.size + 1),'Label':final_predictions})\nanswers.to_csv(submission_filename, index=False)","82e5ea39":"submission_filename = '\/kaggle\/working\/submission.csv'\nanswers.to_csv(submission_filename, index=False)","e4f36d8e":"# \u6570\u636e\u9884\u5904\u7406","4a4b23e0":"# \u8bad\u7ec3","aabe10b2":"# \u521b\u5efa\u6a21\u578b","b1a933ba":"# \u9884\u6d4b\u5e76\u8f93\u51fa\u7ed3\u679c"}}