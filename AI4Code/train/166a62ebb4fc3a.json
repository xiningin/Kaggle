{"cell_type":{"af098be4":"code","74bad566":"code","9b58e01f":"code","dc47424c":"code","da7b10b3":"code","646b260c":"code","30e7194e":"code","7795b2b4":"code","61158242":"code","2dc65e00":"code","532a32cb":"code","8ea45cfd":"code","7ad4db84":"code","f5c329a0":"code","a659da36":"code","cc3fc482":"code","029c7b96":"code","4e6c6b70":"code","fa002743":"code","17be99af":"code","4dfeda0a":"code","ef620718":"code","8fa1d96e":"code","bfc49f72":"code","124c11a6":"code","8bd53f1c":"code","bbc7937b":"code","cdeea561":"code","cfe583e1":"code","2e7a5b21":"code","1fcbd941":"code","783e0a98":"code","e7901506":"code","aa29c91b":"code","35c9b5f2":"code","379f310f":"code","962eb1eb":"code","faf80067":"code","f03f41c1":"code","5aae6c6b":"code","06a6ca48":"code","c1e0474b":"markdown","c60e70b7":"markdown","fbf60d10":"markdown","e96a51db":"markdown","ba4c5c72":"markdown","08e91296":"markdown","169ce192":"markdown","f28fe92c":"markdown","0e175327":"markdown","6562c6c8":"markdown","e024fdbb":"markdown","f5a54cce":"markdown","54ff873b":"markdown","a30d78b3":"markdown","42af4a89":"markdown","e663c678":"markdown","f105aaf3":"markdown","42c8c074":"markdown","9cfebd14":"markdown","7fed9bf0":"markdown","2824b290":"markdown","bc2f1df6":"markdown","ff56fc58":"markdown","ee3b421a":"markdown","5ceece39":"markdown","871cfaec":"markdown","8556f5b8":"markdown","56232f84":"markdown","470bded6":"markdown","04ea0d2f":"markdown","ab8a16c8":"markdown"},"source":{"af098be4":"import pandas as pd\nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","74bad566":"cancer_df= pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","9b58e01f":"cancer_df.head()","dc47424c":"cancer_df.tail()","da7b10b3":"cancer_df.info()","646b260c":"cancer_df = cancer_df.drop('Unnamed: 32', axis=1)","30e7194e":"cancer_df.info()","7795b2b4":"cancer_df.shape","61158242":"cancer_df.dtypes","2dc65e00":"cancer_df[\"diagnosis\"].unique()","532a32cb":"cancer_df[\"diagnosis\"].value_counts()","8ea45cfd":"cancer_df['diagnosis'] = cancer_df['diagnosis'].map({'M':1,'B':0})\ncancer_df.head()","7ad4db84":"cancer_df.info()","f5c329a0":"cancer_df.describe()","a659da36":"plt.figure(figsize=(8, 4))\nsns.countplot(cancer_df['diagnosis'], palette=('Orange','DarkBlue'))","cc3fc482":"cols = ['diagnosis',\n        'radius_mean', \n        'texture_mean', \n        'perimeter_mean', \n        'area_mean', \n        'smoothness_mean', \n        'compactness_mean', \n        'concavity_mean',\n        'concave points_mean', \n        'symmetry_mean', \n        'fractal_dimension_mean']\n\nsns.pairplot(data=cancer_df[cols], hue='diagnosis', palette=('Orange','DarkBlue'))","029c7b96":"cols = ['diagnosis',\n        'radius_se', \n        'texture_se', \n        'perimeter_se', \n        'area_se', \n        'smoothness_se', \n        'compactness_se', \n        'concavity_se',\n        'concave points_se', \n        'symmetry_se', \n        'fractal_dimension_se']\n\nsns.pairplot(data=cancer_df[cols], hue='diagnosis', palette=('Orange','DarkBlue'))","4e6c6b70":"cols = ['diagnosis',\n        'radius_worst', \n        'texture_worst', \n        'perimeter_worst', \n        'area_worst', \n        'smoothness_worst', \n        'compactness_worst', \n        'concavity_worst',\n        'concave points_worst', \n        'symmetry_worst', \n        'fractal_dimension_worst']\n\nsns.pairplot(data=cancer_df[cols], hue='diagnosis', palette=('Orange','DarkBlue'))","fa002743":"corr=cancer_df.corr().round(2)\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, annot = True)","17be99af":"mask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, mask=mask, annot = True)","4dfeda0a":"cancer_df1=cancer_df\ncancer_df1.head()","ef620718":"cols = ['radius_worst', \n        'texture_worst', \n        'perimeter_worst', \n        'area_worst', \n        'smoothness_worst', \n        'compactness_worst', \n        'concavity_worst',\n        'concave points_worst', \n        'symmetry_worst', \n        'fractal_dimension_worst']\ncancer_df = cancer_df.drop(cols, axis=1)","8fa1d96e":"cols = ['perimeter_mean',\n        'perimeter_se', \n        'area_mean', \n        'area_se']\ncancer_df = cancer_df.drop(cols, axis=1)","bfc49f72":"cols = ['concavity_mean',\n        'concavity_se', \n        'concave points_mean', \n        'concave points_se']\ncancer_df = cancer_df.drop(cols, axis=1)","124c11a6":"cancer_df.columns","8bd53f1c":"cancer_df = cancer_df.drop('id', axis=1)","bbc7937b":"cancer_df.columns","cdeea561":"corr=cancer_df.corr().round(2)\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nplt.figure(figsize=(20,20))\nsns.heatmap(corr, mask=mask, annot = True)","cfe583e1":"cancer_df.describe()","2e7a5b21":"x= cancer_df.drop('diagnosis', axis=1)\ny= cancer_df['diagnosis']","1fcbd941":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 0)","783e0a98":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)","e7901506":"x_train.shape, x_test.shape","aa29c91b":"y_train.shape, y_test.shape","35c9b5f2":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)","379f310f":"y_pred = logreg.predict(x_test)","962eb1eb":"from sklearn.metrics import confusion_matrix, accuracy_score","faf80067":"confmat = confusion_matrix(y_pred, y_test)\nconfmat","f03f41c1":"accuracy_score(y_pred, y_test)\n","5aae6c6b":"from sklearn.ensemble import RandomForestClassifier\n","06a6ca48":"random_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 10,   \n                                       n_estimators=100, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\n\nrandom_forest.fit(x_train, y_train)\ny_pred = random_forest.predict(x_test)\nrandom_forest.score(x_train, y_train)\nprint(\"Score: \", round(random_forest.oob_score_, 4)*100, \"%\")","c1e0474b":"The prediction accuracy for the test data set using the above Random Forest is **92.71%**","c60e70b7":"Now, let's build logistic model on our data set","fbf60d10":"So here we have successfully converted data type of \"diagnosis\" column into numeric.\n\nFor our instance now, \nMalignant = 'M' = 1 & Benign = 'B' = 0","e96a51db":"Drop all columns related to the \"concavity\" and \"concave points\" attributes","ba4c5c72":"# Breast Cancer Prediction\n\nBreast cancer is a type of cancer that starts in the breast. Cancer starts when cells begin to grow out of control. Breast cancer cells usually form a tumor that can often be seen on an x-ray or felt as a lump. \n\nDepending on the types of cells in a tumor, it can be:\n\n1. **Benign** - The tumor doesn\u2019t contain cancerous cells.\n2. **Malignant** - The tumor contains cancerous cells.\n\n![](https:\/\/gotalktogetherdotcom.files.wordpress.com\/2016\/05\/cancerbenignmalig1.jpg)","08e91296":"Looking at the above plaot, we can verify the presence of **multicollinearity** between some of our variables. For instance, the **radius_mean column** has a correlation of **1** and **0.99** with **perimeter_mean** and **area_mean** columns, respectively. This is probably because the three columns essentially contain the same information, which is the physical size of the observation. Therefore we should only pick one of the three columns when we go into further analysis.\n\nAnother place where **multicollienartiy** is apparent is between the **\"mean\"** columns and the **\"worst\"** column. For instance, the **radius_mean** column has a correlation of **0.97** with the **radius_worst** column. In fact, each of the 10 key attributes display very high (from 0.7 up to 0.97) correlations between its **\"mean\"** and **\"worst\"** columns. \n\nThis is somewhat inevitable, because the **\"worst\"** columns are essentially just a subset of the **\"mean\"** columns; the **\"worst\"** columns are also the **\"mean\"** of some values. Therefore, I think we should discard the **\"worst\"** columns from our analysis and only focus on the **\"mean\"** columns.\n\nIn short, we will drop all **\"worst\"** columns from our dataset, then pick only one of the three attributes that describe the size of cells.\n\nSimilarly, it seems like there is **multicollinearity** between the attributes **compactness**, **concavity**, and **concave points**. Just like what we did with the size attributes, we should pick only one of these three attributes that contain information on the shape of the cell. I think **compactness** is an attribute name that is straightforward, so we will remove the other two attributes.\n\nWe will now go head and drop all unnecessary columns.","169ce192":"First, drop all \"worst\" columns","f28fe92c":"Predict on the top of test data","0e175327":"The last column looks somthing fishy, bunch of NaN values. Let's get ride over it.","6562c6c8":"Here, we have analyzed the relationship between the 10 key attributes and the diagnosis variable by only choosing the \"mean\" columns.","e024fdbb":"Then, drop all columns related to the \"perimeter\" and \"area\" attributes","f5a54cce":"Storing main data set in to another vairiable for our record.","54ff873b":"Loading the initial libraries","a30d78b3":"Let's take a look at the correlation matrix once again, this time created with our trimmed-down set of variables.","42af4a89":"In this notebook, we are going to predict whether a breast tumor is benign or malignant based on 30 features in the dataset. This prediction can be useful in diagnosing patients with suspected breast cancer.","e663c678":"And here is the accuracy","f105aaf3":"# Breast Cancer Dataset Attributes Information:\n\n1st column - ID number,\n2nd column -  Diagnosis (M = malignant, B = benign),\n3rd to 32nd column -  10 real-valued features are computed for each cell nucleus:\n\n1. radius (mean of distances from center to points on the perimeter)\n2. texture (standard deviation of gray-scale values)\n3. perimeter\n4. area\n5. smoothness (local variation in radius lengths)\n6. compactness (perimeter\u00b2 \/ area \u2014 1.0)\n7. concavity (severity of concave portions of the contour)\n8. concave points (number of concave portions of the contour)\n9. symmetry\n10. fractal dimension (\u201ccoastline approximation\u201d \u2014 1)\n\nThe **\"mean\"**, **\"standard error(se)\"** and **\u201cworst\u201d** or largest (mean of the three largest values) of these features were computed for each, resulting in 30 features. \n\nFor instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.","42c8c074":"Lets Apply Random Forest model","9cfebd14":"Here, we have analyzed the relationship between the 10 key attributes and the diagnosis variable by only choosing the \"se\" columns.","7fed9bf0":"Lastly, also drop the id column","2824b290":"The prediction accuracy for the test data set using the above Logistic Regression Model is **91.22%**","bc2f1df6":"Looks great! Now let's move on to our model.\n\nLet's describe data once more","ff56fc58":"All columns are having numeric data types except \"diagnosis\". Let's quickly analyze \"diagnosis\" column.","ee3b421a":"Here we have successfully dropped last column named as \"Unnamed 32\". Now after getting shape of the data, there are 569 rows and 32 columns.","5ceece39":"Let us load the data set","871cfaec":"Now,let's explore the data","8556f5b8":"Let's assign x and y, and accordingly split the data.","56232f84":"Finding shape of split data","470bded6":"Now, lets quickly go through the data types of each columns","04ea0d2f":"Creating confusion matrix","ab8a16c8":"From above sample of code, we can understand that, \"diagnosis\" column is having 2 unique categorical fields. Where 'B' stands for Benign and 'M' stands for Malignant. Let's quickly convert them into values."}}