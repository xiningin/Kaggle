{"cell_type":{"2a38604a":"code","7c372fb3":"code","b49ad1aa":"code","8fb4344b":"code","576d55b6":"code","17a5be19":"code","d5be085b":"code","13000314":"code","604c60f7":"code","a3ccd459":"code","53779989":"code","10a9a17a":"code","5bf862e1":"code","df92f526":"code","84913378":"code","aa09e5c9":"code","97ed06e4":"code","38b83da8":"code","bbd2d95d":"code","104efc4b":"code","44882df1":"code","cc38b966":"code","3f86ae77":"code","ffcf4c49":"code","a362b280":"code","dd5be248":"code","5eb5623a":"code","558dd270":"code","49f77647":"code","4247e172":"code","85673880":"code","ed19bd60":"code","44351d05":"code","bcacef39":"markdown","638fa077":"markdown","e55f27e0":"markdown","0ce7c8bf":"markdown","f423d376":"markdown","9fbc81bd":"markdown","4d399879":"markdown","a9d4047b":"markdown","3f57f371":"markdown","d1e75c14":"markdown","77ec9665":"markdown","58659425":"markdown","167334cf":"markdown","e58d3e49":"markdown","7dbcd0d5":"markdown","d0be4fc9":"markdown","2a861950":"markdown","07502dab":"markdown","83e8fae8":"markdown","c52767f0":"markdown","43661331":"markdown","46b2f162":"markdown","fed7154d":"markdown","6a8ea18c":"markdown","1727c650":"markdown"},"source":{"2a38604a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split,learning_curve,ShuffleSplit\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn import metrics\n\nimport warnings\nwarnings.filterwarnings('ignore')","7c372fb3":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain.tail(5)","b49ad1aa":"train.info()","8fb4344b":"# EDA\n# SalePrice\n\nsns.kdeplot(x = \"SalePrice\",data = train,shade=True,color = \"Green\")\nplt.show()","576d55b6":"train[\"SalePrice\"].describe()","17a5be19":"#scatter plot grlivarea\/saleprice\n\nsns.scatterplot(y = \"SalePrice\", x = \"GrLivArea\",data = train,color = \"purple\")\nplt.show()","d5be085b":"#scatter plot TotalBsmtSF\/saleprice\n\nsns.scatterplot(y = \"SalePrice\", x = \"TotalBsmtSF\",data = train,color = \"purple\")\nplt.show()","13000314":"fig = plt.figure(figsize=(20,9))\nsns.barplot(x = \"Neighborhood\",y = \"SalePrice\", data = train,)\nplt.xticks(rotation=90)\nplt.show()","604c60f7":"fig = plt.figure(figsize=(25,9))\nsns.barplot(x = \"YearBuilt\",y = \"SalePrice\", data = train,)\nplt.xticks(rotation=90)\nplt.show()","a3ccd459":"corr_metrics = train.corr()\ncorr_metrics['SalePrice'].sort_values(ascending=False)","53779989":"#correlation matrix\ncorrmat = train.corr()\nfig = plt.figure(figsize=(12,12))\nsns.heatmap(corrmat, square=True);","10a9a17a":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\nfig = plt.figure(figsize=(12,12))\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","5bf862e1":"cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols],diag_kind='kde',height=2.5)\nplt.show()","df92f526":"def draw_missing_data_table(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent = (data.isnull().sum()\/data.isnull().count() * 100).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\n\ndraw_missing_data_table(train).head(20)","84913378":"train.drop([\"Id\",\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\",\"FireplaceQu\",\"LotFrontage\",\"GarageCond\",\"GarageType\",\"GarageQual\",\n            \"GarageYrBlt\",\"GarageFinish\",\"BsmtExposure\",\"BsmtFinType2\",\"BsmtFinType1\",\"BsmtCond\",\n            \"BsmtQual\"],axis = 1,inplace=True)\n","aa09e5c9":"train = train.drop(train.loc[train['Electrical'].isnull()].index)\ntrain = train.drop(train.loc[train['MasVnrArea'].isnull()].index)\ntrain = train.drop(train.loc[train['MasVnrType'].isnull()].index)\ntrain.isnull().sum().max() #just checking that there's no missing data missing..","97ed06e4":"\n\nCategorical_columns = []\nNumerical_columns = []\nfor column in train.columns:\n    if np.dtype(train[column]) == object:\n        Categorical_columns.append(column)\n    else:\n        Numerical_columns.append(column)\n","38b83da8":"#High skewed attributes\n\ns_k=[]\nfor i in Numerical_columns:\n    if train[i].skew() > 1 or train[i].skew() < -1:\n        s_k.append([i,train[i].skew()])\n        skew=pd.DataFrame(s_k,columns=['Columns','Skewness'])\n        \nskew","bbd2d95d":"#applying log transformation\n\nfor i in skew[\"Columns\"]:\n    train[i] = train[i].apply(lambda x: np.log(x + 1))","104efc4b":"train.head()","44882df1":"\nscaler = MinMaxScaler()\ntrain[Numerical_columns] = scaler.fit_transform(train[Numerical_columns])","cc38b966":"Features = pd.get_dummies(train)","3f86ae77":"y = Features[\"SalePrice\"]\nX = Features.drop(\"SalePrice\",axis = 1)","ffcf4c49":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25, random_state = 42)","a362b280":"cl1 = DecisionTreeRegressor()\ncl2 = AdaBoostRegressor()\ncl3 = XGBRegressor()\n\nclfs = [cl1,cl2,cl3]","dd5be248":"\nAcc = pd.DataFrame(index=None, columns=['model','Root Mean Squared Error','Accuracy on Traing set',\n                                        'Accuracy on Testing set','r2-score'])\nfor clf in clfs:\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    \n    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n    ATrS =  clf.score(X_train,y_train)\n    ATeS = clf.score(X_test,y_test)\n    R2 = r2_score(y_test,y_pred)\n    \n    Acc = Acc.append(pd.Series({'model':clf.__class__.__name__, \n                                'Root Mean Squared Error': RMSE,\n                                'Accuracy on Traing set':ATrS * 100,\n                                'Accuracy on Testing set':ATeS * 100,\n                                'r2-score' : R2}),ignore_index=True )","5eb5623a":"Acc","558dd270":"from sklearn.model_selection import GridSearchCV\nparameters = {'nthread':[4,5,8,10], \n              'objective':['reg:linear'],\n              'learning_rate': [0.03, 0.05, 0.07, 0.1], #so called `eta` value\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [4],\n              'subsample': [0.7],\n              'colsample_bytree': [0.7],\n              'n_estimators': [5,10,15,50,500]}\n\nxgb_grid = GridSearchCV(cl3,\n                        parameters,\n                        cv = 5,\n                        n_jobs = 5,\n                        verbose=True)\n\nxgb_grid.fit(X_train,y_train)\n","49f77647":"xgb_grid.best_estimator_","4247e172":"\nAcc = pd.DataFrame(index=None, columns=['model','Root Mean Squared Error','Accuracy on Traing set',\n                                        'Accuracy on Testing set','r2-score'])\nfor clf in [cl3]:\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    \n    RMSE = np.sqrt(metrics.mean_squared_error(y_test, xgb_grid.predict(X_test)))\n    ATrS =  clf.score(X_train,y_train)\n    ATeS = clf.score(X_test,y_test)\n    R2 = r2_score(y_test,y_pred)\n    \n    Acc = Acc.append(pd.Series({'model':clf.__class__.__name__, \n                                'Root Mean Squared Error': RMSE,\n                                'Accuracy on Traing set':ATrS * 100,\n                                'Accuracy on Testing set':ATeS * 100,\n                                'r2-score' : R2}),ignore_index=True )","85673880":"Acc","ed19bd60":"RMSE = np.sqrt(metrics.mean_squared_error(y_test,xgb_grid.predict(X_test)))","44351d05":"RMSE","bcacef39":"----","638fa077":"### Relationsheep between Categorical Data","e55f27e0":"#### Do upvote it if you find it helpful \ud83d\ude0a","0ce7c8bf":"**Observation**\n* Highest Value of House is 755000.\n* Average value of hoouse is 180920.","f423d376":" We can see our well-known 'GrLivArea', 'TotalBsmtSF', and 'OverallQual' saying a big 'Hi!'.","9fbc81bd":"we can see that 'GarageX' variables have the same number of missing data. Since the most important information regarding garages is expressed by 'GarageCars' and considering that we are just talking about 5% of missing data, I'll delete the mentioned 'GarageX' variables.\n\nThe same logic applies to 'BsmtX' variables.","4d399879":"* `OverallQual`, `GrLivArea` and `TotalBsmtSF` are strongly correlated with `SalePrice`.\n\n* `FullBath`,`TotRmsAbvGrd`and `YearBuilt` are slightly correlated with `SalePrice`.","a9d4047b":"**We just analysed four variables, but there are many other that we should analyse.**","3f57f371":" PairPlot for highest correlated attributes","d1e75c14":"### Normalizing Numerical Features\n\nIn addition to performing transformations on features that are highly skewed, it is often good practice to perform some type of scaling on numerical features. Applying a scaling to the data does not change the shape of each feature's distribution. however, normalization ensures that each feature is treated equally when applying supervised learners. Note that once scaling is applied, observing the data in its raw form will no longer have the same original meaning.","77ec9665":"**10 Highest correlated variables**","58659425":"**Neighborhood: Physical locations within Ames city limits**\n* For a good `Neighborhood`, one would expect to observe a higher `SalePrice`.","167334cf":"**Root Mean Squared Error**\n\n* Before Tuning parameters : 0.044237\n* After Tuning parameters : 0.038944\n","e58d3e49":"For highly-skewed feature distributions, it is common practice to apply a <a href=\"https:\/\/en.wikipedia.org\/wiki\/Data_transformation_(statistics)\">logarithmic transformation<\/a> on the data so that the very large and very small values do not negatively affect the performance of a learning algorithm. Using a logarithmic transformation significantly reduces the range of values caused by outliers. Care must be taken when applying this transformation however: The logarithm of `0` is undefined, so we must translate the values by a small amount above `0` to apply the the logarithm successfully.\n","7dbcd0d5":"## Skewness\n\nIf skewness is less than -1 or greater than 1, the distribution is highly skewed. If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed. If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.","d0be4fc9":"**Observations:**\n    \n* Total number of raws : 1460  **(Will change after deal with missing data)**\n* There are lots of missing values presrent in Dataset.\n\n\n----","2a861950":"Finally, we have Three missing observation in `Electrical`,`MasVnrArea` and `MasVnrType`. Since it is just 8 observation, we'll delete those observation and keep the variables.","07502dab":"## Handling Missing values\n\n**To take care of missing attributes, You have many options:**\n   * Get rid of the missing data points.\n   * Get rid of the whole attributes\n   * set the value to some value(0, Mean or Median)\n   * Impute `bfill` or `ffill` in categorical missing data.\n   \n   \nWe'll consider that when more than 15% of the data is missing, we should delete the corresponding variable and pretend it never existed. This means that we will not try any trick to fill the missing data in these cases.","83e8fae8":"**Data fields**\n\nHere's a brief version of what you'll find in the data file.\n\n* **SalePrice** - the property's sale price in dollars. This is the target variable that you're trying to predict.\n* **MSSubClass:** The building class\n* **MSZoning:** The general zoning classification\n* **LotFrontage:** Linear feet of street connected to property\n* **LotArea:** Lot size in square feet\n* **Street:** Type of road access\n* **Alley:** Type of alley access\n* **LotShape:** General shape of property\n* **LandContour:** Flatness of the property\n* **Utilities:** Type of utilities available\n* **LotConfig:** Lot configuration\n* **LandSlope:** Slope of property\n* **Neighborhood:** Physical locations within Ames city limits\n* **Condition1:** Proximity to main road or railroad\n* **Condition2:** Proximity to main road or railroad (if a second is present)\n* **BldgType:** Type of dwelling\n* **HouseStyle:** Style of dwelling\n* **OverallQual:** Overall material and finish quality\n* **OverallCond:** Overall condition rating\n* **YearBuilt:** Original construction date\n* **YearRemodAdd:** Remodel date\n* **RoofStyle:** Type of roof\n* **RoofMatl:** Roof material\n* **Exterior1st:** Exterior covering on house\n* **Exterior2nd:** Exterior covering on house (if more than one material)\n* **MasVnrType:** Masonry veneer type\n* **MasVnrArea:** Masonry veneer area in square feet\n* **ExterQual:** Exterior material quality\n* **ExterCond:** Present condition of the material on the exterior\n* **Foundation:** Type of foundation\n* **BsmtQual:** Height of the basement\n* **BsmtCond:** General condition of the basement\n* **BsmtExposure:** Walkout or garden level basement walls\n* **BsmtFinType1:** Quality of basement finished area\n* **BsmtFinSF1:** Type 1 finished square feet\n* **BsmtFinType2:** Quality of second finished area (if present)\n* **BsmtFinSF2:** Type 2 finished square feet\n* **BsmtUnfSF:** Unfinished square feet of basement area\n* **TotalBsmtSF:** Total square feet of basement area\n* **Heating:** Type of heating\n* **HeatingQC:** Heating quality and condition\n* **CentralAir:** Central air conditioning\n* **Electrical:** Electrical system\n* **1stFlrSF:** First Floor square feet\n* **2ndFlrSF:** Second floor square feet\n* **LowQualFinSF:** Low quality finished square feet (all floors)\n* **GrLivArea:** Above grade (ground) living area square feet\n* **BsmtFullBath:** Basement full bathrooms\n* **BsmtHalfBath:** Basement half bathrooms\n* **FullBath:** Full bathrooms above grade\n* **HalfBath:** Half baths above grade\n* **Bedroom:** Number of bedrooms above basement level\n* **Kitchen:** Number of kitchens\n* **KitchenQual:** Kitchen quality\n* **TotRmsAbvGrd:** Total rooms above grade (does not include bathrooms)\n* **Functional:** Home functionality rating\n* **Fireplaces:** Number of fireplaces\n* **FireplaceQu:** Fireplace quality\n* **GarageType:** Garage location\n* **GarageYrBlt:** Year garage was built\n* **GarageFinish:** Interior finish of the garage\n* **GarageCars:** Size of garage in car capacity\n* **GarageArea:** Size of garage in square feet\n* **GarageQual:** Garage quality\n* **GarageCond:** Garage condition\n* **PavedDrive:** Paved driveway\n* **WoodDeckSF:** Wood deck area in square feet\n* **OpenPorchSF:** Open porch area in square feet\n* **EnclosedPorch:** Enclosed porch area in square feet\n* **3SsnPorch:** Three season porch area in square feet\n* **ScreenPorch:** Screen porch area in square feet\n* **PoolArea:** Pool area in square feet\n* **PoolQC:** Pool quality\n* **Fence:** Fence quality\n* **MiscFeature:** Miscellaneous feature not covered in other categories\n* **MiscVal:** Value of miscellaneous feature\n* **MoSold:** Month Sold\n* **YrSold:** Year Sold\n* **SaleType:** Type of sale\n* **SaleCondition:** Condition of sale","c52767f0":"### Loading Data and Packages","43661331":"## House Prices - Advanced Regression Techniques","46b2f162":"* `GrLivArea` and `TotalBsmtSF` seem to be linearly related with `SalePrice`. Both relationships are positive, which means that as one variable increases, the other also increases. \n* `OverallQual` and `YearBuilt` also seem to be related with `SalePrice`. The relationship seems to be stronger in the case of 'OverallQual', where the bar plot shows how sales prices increase with the overall quality.","fed7154d":"### Hyperparameters tuning","6a8ea18c":"**Strong Positive (Linear) Correlation between `SalePrice` and `GrLivArea`**","1727c650":"**Correlation merics (Heatmap)**"}}