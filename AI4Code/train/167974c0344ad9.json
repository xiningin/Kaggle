{"cell_type":{"e9cb73d5":"code","7c5774b2":"code","c6f6cdab":"code","6048e53a":"code","841c5a3a":"code","93506cd2":"code","bd371a79":"code","99bf3242":"code","f4a0f1ba":"code","46b9895a":"code","d9c8983c":"code","f587dd72":"code","f4986e57":"code","07e5402a":"code","8e9ee974":"code","d05bd93b":"code","7e409c7d":"code","08088346":"code","2198c629":"code","5e74cfd4":"code","33857936":"code","6a7a0be4":"code","4d9e45d3":"code","bb836c54":"code","f478f46a":"code","f0a5ff2c":"code","45ac665d":"code","664d9e45":"code","662adba1":"code","2910fec0":"code","fed0241c":"code","7fe3996a":"code","b71f5f51":"code","b75a0efd":"code","3f21051c":"code","2c7fd7b2":"code","eca5d484":"code","e1da14c6":"code","def68c3c":"code","11bbe7cf":"code","bb44bfe1":"code","8cfa87b6":"code","22a1b029":"code","0a346144":"code","81f59507":"code","f9219879":"code","d016fe13":"code","7a5832ea":"code","6fcb06c6":"code","c51605b5":"code","144d6454":"code","7abd5709":"markdown","cae64e54":"markdown","899787fc":"markdown","6723d974":"markdown","77a42cef":"markdown","5f15cae9":"markdown","833b0923":"markdown","64d4fc49":"markdown","47753692":"markdown","a949bd16":"markdown","590fbab2":"markdown","34e867b1":"markdown","eff3cc0a":"markdown","d203ea50":"markdown","eb8a1adb":"markdown","bb18bb8c":"markdown","281c6334":"markdown","5331b639":"markdown","a750f016":"markdown","eb7a0aae":"markdown","fd45ee76":"markdown","f17e8c9d":"markdown","10af575a":"markdown","5877e34b":"markdown","6c3c1a4b":"markdown","3c184f76":"markdown","dfcc6a11":"markdown","f543ee82":"markdown","2e4e4159":"markdown","d3a17e43":"markdown","083bec9a":"markdown","a7bfb49e":"markdown","a0deaf0f":"markdown","ae5c8948":"markdown","94717286":"markdown","b097ab7c":"markdown","1958c56d":"markdown","405e78a7":"markdown","5f0c3f4c":"markdown","6e67044e":"markdown","a3a155d9":"markdown","c084bade":"markdown","930449ea":"markdown","6cc1dfe0":"markdown","2913d547":"markdown","262da195":"markdown","7fc0be78":"markdown","92375f5e":"markdown","157ca7b0":"markdown","0db3f3af":"markdown","8fdccad6":"markdown","d17959a6":"markdown","623e645c":"markdown","026c79dc":"markdown","72f2ea19":"markdown","76175d1c":"markdown","d2ff3e88":"markdown","1cd027ee":"markdown"},"source":{"e9cb73d5":"# Importing neccesary libraries.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nsns.set(style=\"darkgrid\")","7c5774b2":"#Reading train and test files from the Titanic Data Set\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()\n","c6f6cdab":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","6048e53a":"#Determining the number of rows and columns in train and test dataframe\nprint('Train data: ', train_data.shape)\nprint('Test data: ', test_data.shape)","841c5a3a":"#Lets combine both the test and train data\ntitanic=pd.concat([train_data, test_data], sort=False).reset_index(drop=True)\ntitanic.shape","93506cd2":"# let's look at the statistical aspects of the dataframes\ntrain_data.describe()","bd371a79":"test_data.describe()","99bf3242":"# Let's see the type of each column\nprint('Train Data')\nprint('-'*50)\ntrain_data.info()\nprint('-'*50)\nprint('*'*75)\nprint('Test Data')\nprint('-'*50)\ntest_data.info()\n","f4a0f1ba":"#Checking missing values in train data\n\nprint('Missing values in Train Data')\nprint('-'*50)\nprint(train_data.isnull().sum())\nprint('-'*50)\nprint('*'*75)\nprint('Missing Percentage in Train Data ')\nprint('-'*50)\nprint(round(100*(train_data.isnull().sum()\/len(train_data.index)),2))\n","46b9895a":"#Checking missing values in test data\n\nprint('Missing values in Test Data')\nprint('-'*50)\nprint(test_data.isnull().sum())\nprint('-'*50)\nprint('*'*75)\nprint('Missing Percentage in Test Data ')\nprint('-'*50)\nprint(round(100*(test_data.isnull().sum()\/len(test_data.index)),2))\n","d9c8983c":"plt.figure(figsize=(14, 6))\nplt.subplot(1,2,1)\ncols = ['r','c']\n\n\n\ntrain_data['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',shadow=True, colors=cols)\nplt.title('Survived')\nplt.subplot(1,2,2)\nsns.countplot('Survived',data=train_data,palette='PuRd')\nplt.title('Survived')\nplt.show()\n","f587dd72":"plt.figure(figsize=(14, 6))\nplt.subplot(1,2,1)\ncols = ['yellowgreen', 'lightcoral']\ntrain_data['Sex'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',shadow=True, colors=cols)\nplt.title('Total Male\/Female onboard')\nplt.subplot(1,2,2)\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_data,palette='magma')\nplt.title('Sex vs Survived')\nplt.ylabel(\"Survival Rate\")\nplt.show()","f4986e57":"plt.figure(figsize=(14, 6))\nplt.subplot(1,2,1)\ncols = ['gold', 'lightcoral', 'lightblue']\ntrain_data['Pclass'].value_counts().plot.pie(autopct='%1.1f%%',shadow=True, colors=cols)\nplt.title('Number of Passengers by Class')\nplt.subplot(1,2,2)\nsns.barplot(x='Pclass', y='Survived',data=train_data, palette='cool')\nplt.title('Pclass:Survived vs Dead')\nplt.ylabel(\"Survival Rate\")\nplt.show()\n","07e5402a":"plt.figure(figsize=(14, 8))\nplt.subplot(1,2,1)\nsns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_data)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\",fontweight=\"bold\", size=20)\n\nplt.subplot(1,2,2)\nsns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=train_data)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\",fontweight=\"bold\", size=20)\nplt.subplots_adjust(right=1.7)\n\nplt.show()\n","8e9ee974":"plt.figure(figsize=(14, 8))\n\nplt.subplot(1, 2, 1)\ntrain_data[train_data['Survived']==0].Age.plot.hist(bins=20,cmap='Set3')\nplt.title(\"Survived\",fontweight=\"bold\", size=20)\nplt.ylabel(\"Proportion\")\nplt.xlabel(\"Age\")\n\n\nplt.subplot(1, 2, 2)\ntrain_data[train_data['Survived']==1].Age.plot.hist(bins=20, cmap='Pastel1')\nplt.title(\"Didn't Survive\",fontweight=\"bold\", size=20)\nx2=list(range(0,85,5))\nplt.subplots_adjust(right=1.7)\nplt.ylabel(\"Proportion\")\nplt.xlabel(\"Age\")\n\n\nplt.show()","d05bd93b":"#lets see these two plots together\nplt.figure(figsize=(12,6))\nsns.distplot(train_data[train_data['Survived']==0].Age,bins=20, kde=False, color='b', label='Died')\nsns.distplot(train_data[train_data['Survived']==1].Age,bins=20, kde=False, color='r',label='Survived')\nplt.title(\" Age vs Survived\/Died\",fontweight=\"bold\", size=20)\nplt.legend()\nplt.show()","7e409c7d":"plt.figure(figsize=(14, 8))\n\nplt.subplot(1, 2, 1)\nsns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=train_data,palette='husl')\nplt.title(\"Pclass and Age vs Survived\",fontweight=\"bold\", size=20)\nplt.subplot(1, 2, 2)\nsns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=train_data,palette='Set2')\nplt.title('Sex and Age vs Survived',fontweight=\"bold\", size=20)\nplt.subplots_adjust(right=1.7)\nplt.show()\n\n","08088346":"plt.figure(figsize=(14, 8))\n\nplt.subplot(1, 2, 1)\nsns.barplot(x='Parch',y=\"Survived\", data=train_data,palette='husl')\nplt.title(\"Parent\/Children vs Survival\",fontweight=\"bold\", size=20)\nplt.subplot(1, 2, 2)\nsns.barplot(x='Parch',y=\"Survived\",hue='Pclass' ,data=train_data,palette='Set2')\nplt.title('Parent\/Children & Pclass vs Survival',fontweight=\"bold\", size=20)\nplt.subplots_adjust(right=1.7)\n\nplt.show()\n\n","2198c629":"plt.figure(figsize=(14, 8))\n\nplt.subplot(1, 2, 1)\nsns.barplot(x='SibSp',y=\"Survived\", data=train_data,palette='rocket')\nplt.title(\"Sibling\/Spouse vs Survival\",fontweight=\"bold\", size=20)\nplt.subplot(1, 2, 2)\nsns.barplot(x='SibSp',y=\"Survived\",hue='Pclass' ,data=train_data,palette='rocket_r')\nplt.title('Sibling\/Spouse & Pclass vs Survival',fontweight=\"bold\", size=20)\nplt.subplots_adjust(right=1.7)\n\nplt.show()\n\n","5e74cfd4":"plt.figure(figsize=(15, 20))\n\nplt.subplot(2, 2, 1)\nsns.countplot('Embarked',data=train_data, palette='husl')\nplt.title('Number of Passengers Boarded',fontweight=\"bold\", size=20)\nplt.subplot(2, 2, 2)\nsns.countplot(x='Embarked',hue='Sex' ,data=train_data,palette='cool')\nplt.title('Embarked: Female-Male',fontweight=\"bold\", size=20)\nplt.subplots_adjust(right=1.7)\nplt.subplot(2, 2, 3)\nsns.countplot(x='Embarked',hue='Pclass' ,data=train_data,palette='deep')\nplt.title('Embarked vs Pclass',fontweight=\"bold\", size=20)\nplt.subplot(2, 2, 4)\nsns.countplot(x='Embarked',hue='Survived' ,data=train_data,palette='rocket_r')\nplt.title('Embarked vs Survived', fontweight=\"bold\", size=20)\nplt.subplots_adjust(right=1.7)\nplt.show()\n\n","33857936":"plt.figure(figsize=(15, 4))\nplt.subplot(1,3,1)\n\nsns.distplot(train_data[train_data['Pclass']==1].Fare, kde=False)\nplt.title('Fares in Class 1')\nplt.subplot(1,3,2)\nsns.distplot(train_data[train_data['Pclass']==2].Fare, kde=False,color='y')\nplt.title('Fares in Class 2')\nplt.subplot(1,3,3)\nsns.distplot(train_data[train_data['Pclass']==3].Fare, kde=False, color='g')\nplt.title('Fares in Class 3')\nplt.show()","6a7a0be4":"plt.figure(figsize=(12,8))\nsns.heatmap(train_data.corr(),annot=True,cmap='RdYlGn')","4d9e45d3":"titanic.head()","bb836c54":"fare=titanic.sort_values(by=['Fare'],ascending=False)\nfare[0:10]\n","f478f46a":"age=titanic.sort_values(by=['Age'],ascending=False)\nage[0:5]\n","f0a5ff2c":"sibsp=titanic.sort_values(by=['SibSp'],ascending=False)\nsibsp[0:10]\n","45ac665d":"parch=titanic.sort_values(by=['Parch'],ascending=False)\nparch[0:10]\n","664d9e45":"train_data.drop(\"Cabin\", axis = 1, inplace = True)\ntest_data.drop(\"Cabin\", axis = 1, inplace = True)","662adba1":"#the median will be an acceptable value to place in the NaN cells\ntrain_data[\"Age\"].fillna(train_data[\"Age\"].median(), inplace = True)\ntest_data[\"Age\"].fillna(test_data[\"Age\"].median(), inplace = True) ","2910fec0":"train_data['Embarked'].value_counts(normalize=True)","fed0241c":"Embarked_mode=train_data['Embarked'].mode()[0]\nEmbarked_mode","7fe3996a":"#impute with mode\ntrain_data[\"Embarked\"].fillna(\"S\", inplace = True)","b71f5f51":"test_data[\"Fare\"].fillna(test_data[\"Fare\"].median(), inplace = True)\n","b75a0efd":"#Checking missing values in train data\n\nprint('Missing values in Train Data')\nprint('-'*50)\nprint(train_data.isnull().sum())\nprint('-'*50)\nprint('*'*75)\nprint('Missing values in Test Data ')\nprint('-'*50)\nprint(test_data.isnull().sum())\n","3f21051c":"train_data['Sex'] = train_data['Sex'].map({'female': 0, 'male': 1})\ntest_data['Sex']= test_data['Sex'].map({'female': 0, 'male': 1})\n\ntrain_data['Embarked'] = train_data['Embarked'].map({'S': 0, 'C': 1,'Q': 2})\ntest_data['Embarked']= test_data['Embarked'].map({'S': 0, 'C': 1,'Q': 2})","2c7fd7b2":"train_data.head()","eca5d484":"train_data.drop([\"Name\",\"Ticket\"], axis = 1, inplace = True)\ntest_data.drop([\"Name\",\"Ticket\"], axis = 1, inplace = True)","e1da14c6":"train_data[\"Family\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\ntest_data[\"Family\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","def68c3c":"train_data.head(5)","11bbe7cf":"scaler = StandardScaler()\n\ntrain_data[['Age','Fare']] = scaler.fit_transform(train_data[['Age','Fare']])\ntest_data[['Age','Fare']] = scaler.transform(test_data[['Age','Fare']])\n\ntrain_data.head()","bb44bfe1":"test_data.head()","8cfa87b6":"X_train = train_data.drop(['Survived','PassengerId'], axis=1)\ny_train = train_data[\"Survived\"]\nX_test  = test_data.drop(\"PassengerId\", axis=1)\nX_train.shape, y_train.shape, X_test.shape","22a1b029":"print(X_train.columns)\nprint(X_test.columns)","0a346144":" Features=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Family']","81f59507":"# Logistic Regression\n\nLR = LogisticRegression()\nLR.fit(X_train, y_train)\n\n# Making Predictions\ny_pred = LR.predict(X_test)\n","f9219879":"# Calculating the Accuracy of the model.\n\nprint(\"Accuracy:\",round(LR.score(X_train, y_train)*100,2))","d016fe13":"coefs=LR.coef_[0]\ncoefs","7a5832ea":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\nY_pred = random_forest.predict(X_test)\n","6fcb06c6":"#Checking accuracy\nrandom_forest.score(X_train, y_train)\n\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nacc_random_forest","c51605b5":"feature_importance = pd.Series(random_forest.feature_importances_,index=Features).sort_values(ascending=False)\nfeature_importance","144d6454":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': Y_pred})\n\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","7abd5709":"*  <font color=red>Age: We can fill in the null values with the median for the most accuracy.<\/font>","cae64e54":"### <font color=green>Age, Cabin,Fare features has missing  in test data<\/font>","899787fc":"* > ### <font color=green>These plots shows that not many passengers survived the accident. Out of 891 passengers in training set, only around 350 (38.4% ) people survived of the total training set. <\/font>","6723d974":"* > ## <font color=blue>Handling missing values<\/font>","77a42cef":"### We can drop Name and Ticket column ","5f15cae9":"### Lets explore some real data on the combined data \"titanic'","833b0923":"### <font color=blue>Visualise the data on the training data<\/font>","64d4fc49":"# <font color=blue>5. Output<\/font>","47753692":"###  <font color=blue>Lets convert our categorical data to numeric<\/font>","a949bd16":"# <font color=blue>1. Reading and Inspection<\/font>","590fbab2":"### <font color=blue>Random Forest<\/font>","34e867b1":"* > ### <font color=green>We can see the highest fare was 512.39. And were in ticket class 1.<\/font>\n* > ### <font color=green>Highest Fare was for the people who boarded from Cherbourg<\/font>\n* > ### <font color=green>People who gave high fare were alone and not accompanied by siblings\/Spouses and were of middle age<\/font>\n","eff3cc0a":"# <font color=blue>4. Feature Scaling<\/font>","d203ea50":"# <font color=blue>Problem Statement<\/font>","eb8a1adb":"* <font color=red>Cabin: Cabin has a lot of missing values. We can drop it<\/font>","bb18bb8c":"* > ### <font color=green>Children less than 5 years old were saved in large numbers<\/font>\n* > ### <font color=green>More passengers died between age 15 to 30<\/font>\n* > ### <font color=green>The oldest survived persen was 80.<\/font>","281c6334":"# <font color=blue>3. Exploring some Real Data<\/font>","5331b639":"# <font color=blue>2. Data Visualisation<\/font>","a750f016":"*  <font color=red>Embarked: Embarked is a categorical variable, So here we can impute the missing values with the most popular category<\/font>","eb7a0aae":"* > ### <font color=green>Higher chance to survive with 1 or 2 SibSp<\/font>\n* > ### <font color=green>SibSp with 1,2 3 in number were in class 1 and 2<\/font>\n* > ### <font color=green>Class 3 has low survival rate for Siblings and spouses together<\/font>   \n\n","fd45ee76":"# <font color=blue>Domain Knowledge<\/font>","f17e8c9d":"* > ## <font color=blue>Heatmap <\/font>","10af575a":"* > ### <font color=green>Most of the passengers boarded form S and most of them were male<\/font>\n* > ### <font color=green>Most of the Pclass 3 boarded form S, It could be reason S has lot of died person.<\/font>\n\n\n","5877e34b":"### <font color=green>Age,Cabin, Embarked features has missing  in the train data<\/font>","6c3c1a4b":"### We can combine SibSp and Parch into one Family, which indicates the total number of family members on board for each member.","3c184f76":"* > ### <font color=green>Females between age 20 to 50 had high chance to survive in class 1<\/font>\n* > ### <font color=green>Third class young children and old aged people had less probability to survive <\/font>\n* > ### <font color=green>Probability of Survival is almost same for male and females between age 20 to 40<\/font>\n* > ### <font color=green>Females had greater chances to survive<\/font>","dfcc6a11":"### <font color=Darkblue>6.SibSp : Siblings\/ Spouses   <\/font>","f543ee82":"### <font color=Darkblue>2. Pclass: <\/font>","2e4e4159":"> ### <font color=green>In the first plot we can see, The number of men onboard are more than that of women. In the second plot we can make out that the number of women survived are more<\/font>\n\n* ### Gender appears to be a very good feature to use to predict survival, as shown by the large difference in propotion survived.","d3a17e43":"### <font color=green>There were total 1309 passengers onboard<\/font>","083bec9a":"### <font color=Darkblue>1. Survival: <\/font>","a7bfb49e":"![image.png](attachment:image.png)","a0deaf0f":"* > ### <font color=green>There looks to be a large distribution in the fares of Passengers in Pclass1 and this distribution goes on decreasing as the standards reduces.","ae5c8948":"### <font color=Darkblue>3. Age:   <\/font>","94717286":"> ### <font color=green>The training-set has 891 passengers and 11 features + the target variable (survived). Whereas, the test-set has 418 passengers<\/font>","b097ab7c":"* > ### <font color=green>Highest number of Siblings\/Spouses were 8 in number, boarded from Southampton<\/font>\n* > ### <font color=green>None of them seems to be survived as they were in class 3.As we saw in visualisation class 3 has very less survivors<\/font>\n* > ### <font color=green>We can also see all 8 people were from same Sage Family<\/font>\n","1958c56d":"* > ### <font color=green>Parents  with their children together who are one to three in number onboard have greater chance of survival. It however reduces as the number goes up<\/font>\n* > ### <font color=green>We can see that Parents with children together who were 1- 2 in number were in class 1 and 2 and who were three in number were in class 2<\/font>\n* > ### <font color=green>Class 3 has low survival rates for all the family members<\/font>   \n\n","405e78a7":"### <font color=blue>Logistic Regression<\/font>","5f0c3f4c":"### <font color=Darkblue>Survival Rates Based on Gender and Class<\/font>","6e67044e":"* > ### <font color=green>Oldest passenger Survived was 80 year old boarded from Southampton who was in class 1<\/font>\n","a3a155d9":"* > ### <font color=green>High parent children count were 9 in number<\/font>\n* > ### <font color=green>We can also see class Passengers having Family(SibSp, Parch were in class 3<\/font>\n","c084bade":"\nTitanic was a British passenger liner operated by the White Star Line. Titanic was on its way from Southampton to New York City when it sank in the North Atlantic Ocean in the early morning hours of 15 April 1912 after Titanic collided with an iceberg. The ship carried 2224 people, considering passengers and crew aboard,1514 of them died.\n\nTitanic carried 16 wooden lifeboats and four collapsibles, which could accommodate 1,178 people, only one-third of Titanic's total capacity (and 53% of real number of passengers). At the time, lifeboats were intended to ferry survivors from a sinking ship to a rescuing ship\u2014not keep afloat the whole population or power them to shore. If the SS Californian would responded to Titanic's distress calls, the lifeboats may have been adequate to ferry the passengers to safety as planned, but it didn't happen and the only way to survive were to get on the lifeboat.\n\nThe main question of the competition is \u201cwhat sorts of people were more likely to survive?\u201d","930449ea":"### <font color=Darkblue>8. Fare  <\/font>","6cc1dfe0":"* ### <font color=green>We can see survival rates for females is more in all the three classes compared to men<\/font>\n* ### <font color=green>People in Pclass 1 were more likely to survive than people in the other 2 Pclasses.<\/font>\n\n","2913d547":"### <font color=green>Now lets check the missing values again<\/font>","262da195":"### <font color=green>No more missing values in our dataset<\/font>","7fc0be78":"### <font color=Darkblue>7. Embarked  <\/font>","92375f5e":"# <font color=blue>4. Model Building<\/font>","157ca7b0":"### <font color=Darkblue>5. Parch- Parents & Children:   <\/font>","0db3f3af":"### <font color=Darkblue>2. Gender: <\/font>","8fdccad6":"We are given the train and test data. The training set is used to build our machine learning models. For the training set, we are provided the outcome  for each passenger. Our model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. \n\nThe test set is used to see how well our model performs on unseen data. For the test set, we are not provided the ground truth for each passenger. It is our job to predict these outcomes. For each passenger in the test set, use the model we trained to predict whether or not they survived the sinking of the Titanic.","d17959a6":"# <font color=blue>2. Data Preparation<\/font>","623e645c":"### <font color=green>We can see Random Forest is providing the high accuracy of 98%<\/font>\n### <font color=green>The features along with coefficients are listed above<\/font>","026c79dc":"*   <font color=red>Fare: Fare in test data is a numerical variable, lets impute with median<\/font>","72f2ea19":"### <font color=green>We can see that 38% out of the training-set survived the Titanic.<\/font>","76175d1c":"* >### <font color=green>We can see survival is in good relation with Fare variable<\/font>\n* > ### <font color=green>Survival also has strong negative correlation with sex and p-class<\/font>\n","d2ff3e88":"* ### <font color=green> First plot shows, there were more passengers in Pclass 3, compared to Pclass 1 and 2<\/font>\n* ### <font color=green>Passenegers of Pclass 1 had a very high chances to survive.<\/font>\n* ### <font color=green>The number of survival from pclass 3 is low compare to Pclass 1 and 2.<\/font>\n","1cd027ee":"### <font color=green>Numeric variables : PassengerId,Age,Fare,SibSp,Parch<\/font>\n### <font color=green>Categorical variables : Pclass,Name,Sex,Embarked<\/font>"}}