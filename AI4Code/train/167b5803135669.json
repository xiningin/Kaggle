{"cell_type":{"0e78b846":"code","10e746e7":"code","f3d66605":"code","c6ecb9f2":"code","51ad52b5":"code","beeb7ddd":"code","766390e5":"code","ec336b90":"code","4d9815f4":"code","98c819b1":"code","eec6e57b":"code","b5f4d124":"code","7371cb10":"code","1e316228":"code","0e8a08b8":"code","55298153":"code","5b299d71":"code","5af63ddb":"code","2e1831ff":"code","b53387aa":"code","05d87a4a":"code","8f36a547":"code","df66d7e4":"code","b147d9eb":"code","c217c92f":"code","ea10dc65":"code","80e885e6":"code","dd8a7193":"code","fb8c4783":"markdown","919188cf":"markdown","dc562a69":"markdown","c08124fb":"markdown","cef7d1f4":"markdown","d44cba50":"markdown","9534c6cd":"markdown","ce362eb4":"markdown","e00b2805":"markdown","23b564ab":"markdown","5e957020":"markdown","bdf945ac":"markdown","a7447e29":"markdown","c1adbecb":"markdown","5c7af80f":"markdown","6889cbf4":"markdown","4e897ef6":"markdown","e0de5344":"markdown","23786b90":"markdown","d6ef05b4":"markdown","2d864c87":"markdown"},"source":{"0e78b846":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","10e746e7":"X_full = pd.read_csv('..\/input\/train.csv')\nX_full.columns","f3d66605":"ID = X_full.PassengerId \nNAME = X_full.Name #Maybe we could use this in the future, so let's store this here.\nX_full.drop(['PassengerId','Name'], inplace=True, axis=1)\nX_full.head()","c6ecb9f2":"X_full.describe(include='all')","51ad52b5":"X_full.isnull().sum()","beeb7ddd":"plt.figure(figsize=(15,8))\nsns.heatmap(X_full.isnull(), cbar=False)","766390e5":"X_full.drop(['Cabin','Ticket'], inplace=True, axis=1)\nX_full.columns","ec336b90":"X_full.drop(X_full[X_full.Embarked.isnull() == True].index, inplace=True)\nplt.figure(figsize=(15,8))\nsns.heatmap(X_full.isnull(), cbar=False)","4d9815f4":"plt.figure(figsize=(15,8))\nsns.heatmap(X_full.corr(), cmap='magma', annot=True)","98c819b1":"s = X_full['Age'].isnull()\nX_full_age = X_full.copy() #Do this on a copy to see the distributions comparison\n\n\n\nX_full_age.Age[s] = X_full_age.Age[s].map(lambda x: random.randrange(X_full_age.Age.median() - (X_full_age.Age.median()*0.25),\n                                                       X_full_age.Age.median() + (X_full_age.Age.median()*0.25)))\n\n\nplt.figure(figsize=(20,6))\nsns.distplot(X_full_age.Age, ax=plt.subplot(1,2,1))\nsns.distplot(X_full.Age.dropna(), ax=plt.subplot(1,2,2))\n","eec6e57b":"X_full_age['Age'] = pd.Series(pd.cut(X_full_age.Age,[0,10,20,30,40,50,60,70,80,90], labels= False, right=True))\nX_full_age.head()","b5f4d124":"X_full_age.dtypes","7371cb10":"X_full_age.Pclass = pd.Categorical(X_full_age.Pclass)\nX_full_age = pd.get_dummies(X_full_age)\nX_full_age.head()","1e316228":"X_full_age.isnull().sum()","0e8a08b8":"X_full_age['Family'] = X_full_age.SibSp + X_full_age.Parch\nX_full_age.drop(['SibSp','Parch'], axis=1, inplace=True)\nX_full_age.head()","55298153":"plt.figure(figsize=(15,8))\nsns.heatmap(X_full_age.corr(), annot=True, cmap='magma')","5b299d71":"ytrain = X_full_age.Survived\nXtrain = X_full_age.drop(['Survived'], axis=1)","5af63ddb":"from sklearn.model_selection import cross_val_score, RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\nPGrid = {\"C\":[1,10,100],\n        \"gamma\":[.01, 0.1],\n        \"kernel\":['rbf'],\n        \"cache_size\":[200,500,1000]}\n\nmodel = SVC(random_state=1)\nXtrainsvm = StandardScaler().fit_transform(Xtrain)\n\ngsearch = GridSearchCV(estimator=model, param_grid=PGrid, cv=5, iid=False)\n\nscore = cross_val_score(gsearch, X=Xtrainsvm, y=ytrain, cv=5)\n\nscore.mean()","2e1831ff":"Xtest = pd.read_csv('..\/input\/test.csv')\nID = Xtest['PassengerId']\nXtest.drop(['PassengerId','Name','Cabin','Ticket'], inplace=True, axis=1)\nplt.figure(figsize=(15,8))\nsns.heatmap(Xtest.isnull(), cbar=False)","b53387aa":"s = Xtest['Age'].isnull()\n\nXtest.Age[s] = Xtest.Age[s].map(lambda x: random.randrange(round(Xtest.Age.median() - (Xtest.Age.median()*0.25)),\n                                                           round(Xtest.Age.median() + (Xtest.Age.median()*0.25))))\n\nXtest.isnull().sum()","05d87a4a":"s = Xtest['Fare'].isnull()\n\nXtest.Fare[s] = Xtest.Fare.mean()\n\nXtest.isnull().sum()","8f36a547":"Xtest['Age'] = pd.Series(pd.cut(Xtest.Age,[0,10,20,30,40,50,60,70,80,90], labels= False, right=True))\nXtest.head()","df66d7e4":"Xtest.Pclass = pd.Categorical(Xtest.Pclass)\nXtest = pd.get_dummies(Xtest)\nXtest.head()","b147d9eb":"Xtest['Family'] = Xtest.SibSp + Xtest.Parch\nXtest.drop(['SibSp','Parch'], axis=1, inplace=True)\nXtest.head()","c217c92f":"Xtest = StandardScaler().fit_transform(Xtest)","ea10dc65":"gsearch.fit(Xtrain, ytrain)\n\nsvmpredict = gsearch.predict(Xtest)","80e885e6":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\nxgb = XGBClassifier(n_estimators=1000, learning_rate=0.1, random_state=0)\nxgbscore = cross_val_score(xgb, Xtrainsvm, ytrain, cv=5)\nprint(xgbscore.mean())\nxgb.fit(Xtrainsvm, ytrain)\npredictions = xgb.predict(Xtest)","dd8a7193":"submission = pd.concat([ID,pd.Series(predictions.tolist())], axis=1)\nsubmission.columns = ['PassengerId','Survived']\nsubmission.to_csv('predictions.csv', index=False)\nsubmission.head()","fb8c4783":"# Nested Cross Validation","919188cf":"# XGBoost\n","dc562a69":"###### First of all, i want to thank you all that are viewing this kernel, this is my first kernel, and hopefully it helps me and more beginners in a significant way!","c08124fb":"# Preprocessing and feature engineering.\n\nWe have some NaN values in our dataset, let's visualize it.","cef7d1f4":"* Pclass has an obvious negative correlation with Fare. Passengers who payed more were in better classes.\n* Fare and Pclass has significant correlations with Survival rates. Meaning that passengers who payed more had a better chance at surviving.\n* Parch and SibSp has great correlation for obvious reasons too.\n* Age and Pclass has a negative correlation, meaning that older the passenger, more likely he's paying for a better class.\n* As for SibSp and Parch correlations with Age, greater the Age, less likely the passenger to be with family.","d44cba50":"# Filling nan values in age","9534c6cd":"# Categorical variables","ce362eb4":"There are only two rows that are missing the embarked column. Let's drop it too.","e00b2805":"# Saving submissions","23b564ab":"#### Now it becomes a little harder to interpret this correlation heatmap, but let's start\n    \n* Sex_female has a significant correlation with Survived, so females are more likely to survive. While males are not (Sex_male has negative correlation with survived)\n* People who embarked at Cherboug had more survivability than people who embarked at Queenstown, Southampton is the place with less survivability, this is because people who embarked at Cherbough were more rich, paid larger fares and got better classes.\n*  Women were more likely to be travelling with family than men.","5e957020":"Well, i think this distribution comparison is pretty good!\nNow let's bin our ages.","bdf945ac":"Sex and Embarked already are Categorical, let's set Pclass to categorical too.","a7447e29":"Cabin and Ticket are not good predictors of survival rate and Cabin has too many Nan values, so let's drop it out.","c1adbecb":"Now that we have no NaN values, lets combine SibSp and Parch to make a new feature named Family and drop the original values.","5c7af80f":" Now let's take care of our categorical variables. Those are Sex, Embarked and Pclass.","6889cbf4":"###### Could you all comment and tell me what could i do to improve my model accuracy, and if i did something wrong? I'm a real beginner, so your comments will be of great interest to me!","4e897ef6":"Let's take a first look at our dataset to see how it looks.","e0de5344":"# Preprocessing the test data","23786b90":"# A first look in our data.","d6ef05b4":"Right, now we need to do something with the age. But first let's check a heatmap of correlations of our numeric variables.","2d864c87":"Name and PassengerID are really not useful features."}}