{"cell_type":{"9989c629":"code","38cb8c38":"code","053e1ee4":"code","4d785785":"code","e204ca78":"code","3bb8fbe4":"code","3434954f":"code","e2d147b3":"code","df7e20f0":"code","8c556bb1":"code","d28502b3":"code","a1b6d07d":"code","a21a290f":"code","846da3b4":"code","e8e02b16":"code","a3561297":"code","f3c51e05":"code","439053f8":"code","2678dcc0":"code","bad94f76":"code","acc99889":"code","bca7eec4":"code","216d7431":"code","7c601604":"code","55192546":"code","384c65d5":"code","a5154ef5":"code","8b06030d":"markdown","53ea085d":"markdown","730031c2":"markdown","fa8ce505":"markdown","bac66815":"markdown","b3b499e6":"markdown","02fc1f85":"markdown"},"source":{"9989c629":"import h5py\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, KFold\nimport scipy as sp\nimport random\nimport nilearn as nl\nfrom nilearn import datasets\nfrom nilearn import plotting\nfrom nilearn import image\nimport nibabel as nib\nimport nilearn.plotting as nlplt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom functools import partial\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn import preprocessing\nimport category_encoders as ce\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\n\nimport lightgbm as lgb\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","38cb8c38":"train = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/train_scores.csv').sort_values(by='Id')\n\nloadings = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/loading.csv')\n\nfnc = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/fnc.csv')\n\nsample = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv')\n\nreveal = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/reveal_ID_site2.csv')\n\nICN = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/ICN_numbers.csv')\n\n","053e1ee4":"!wget https:\/\/github.com\/Chaogan-Yan\/DPABI\/raw\/master\/Templates\/ch2better.nii","4d785785":"mat = h5py.File('\/kaggle\/input\/trends-assessment-prediction\/fMRI_train\/10031.mat','r')\nmat.keys()","e204ca78":"sample = mat['SM_feature']\n","3bb8fbe4":"array = sample[()]\narray.shape","3434954f":"print(array.min(),array.max(),array.mean())","e2d147b3":"mat, ax = plt.subplots(1,4)\nmat.set_size_inches(25, 10)\nfor i in range(4):\n    Temp = array[i*10, :, 10, :] !=0  \n    ax[i].imshow(Temp)\nplt.show()","df7e20f0":"motor_images = datasets.fetch_neurovault_motor_task()\nimg = motor_images.images[0]","8c556bb1":"nii_loc = \"\/kaggle\/input\/trends-assessment-prediction\/fMRI_mask.nii\"\nnii_loc2 = \"\/kaggle\/input\/trends-assessment-prediction\/fMRI_train\/10031.mat\"\nniiplot = plotting.plot_glass_brain(img)\nniiplot","d28502b3":"\nmaskni = nl.image.load_img(nii_loc)\nsubjectimage = nl.image.new_img_like(nii_loc, array, affine=maskni.affine, copy_header=True)\n","a1b6d07d":"smri = 'ch2better.nii'\nnum_components = subjectimage.shape[-1]","a21a290f":"grid_size = int(np.ceil(np.sqrt(num_components)))\nfig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*10, grid_size*10))\n[axi.set_axis_off() for axi in axes.ravel()]\nrow = -1\nfor i, cur_img in enumerate(nl.image.iter_img(subjectimage)):\n    col = i % grid_size\n    if col == 0:\n        row += 1\n    nlplt.plot_stat_map(cur_img, bg_img=smri, title=\"IC %d\" % i, axes=axes[row, col], threshold=3, colorbar=False)","846da3b4":"train.isnull().sum()","e8e02b16":"reveal.head","a3561297":"ICN.head()","f3c51e05":"fnc.head()","439053f8":"train.head()","2678dcc0":"train_ids = sorted(loadings[loadings['Id'].isin(train.Id)]['Id'].values)\ntest_ids = sorted(loadings[~loadings['Id'].isin(train.Id)]['Id'].values)\npredictions = pd.DataFrame(test_ids, columns=['Id'], dtype=str)\nfeatures = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')","bad94f76":"data = pd.merge(loadings, train, on='Id').dropna()\nX_train = data.drop(list(features), axis=1).drop('Id', axis=1)\ny_train = data[list(features)]\nX_test = loadings[loadings.Id.isin(test_ids)].drop('Id', axis=1)","acc99889":"model = RandomForestRegressor(\n    max_depth=10,\n    min_samples_split=10,\n    min_samples_leaf=5\n)\ncv = KFold(n_splits = 5, shuffle=True, random_state=29)\ngrid = {\n    'n_estimators':[5,10,20,100]\n}\ngs = GridSearchCV(model, grid, n_jobs=-1, cv=cv, verbose=1, scoring='neg_mean_absolute_error')","bca7eec4":"best_models = {}\nfor col in features:\n    gs.fit(X_train, y_train[col])\n    best_models[col] = gs.best_estimator_\n    print(gs.best_score_)","216d7431":"for col in features:\n    predictions[col] = best_models[col].predict(X_test)","7c601604":"def make_sub(predictions):\n    features = ('age', 'domain1_var1', 'domain1_var2','domain2_var1','domain2_var2')\n    _columns = (0,1,2,3,4)\n    tests = predictions.rename(columns=dict(zip(features, _columns)))\n    tests = tests.melt(id_vars='Id',value_vars=_columns,value_name='Predicted')\n    tests['target'] = tests.variable.map(dict(zip(_columns, features)))\n    tests['Id_'] = tests[['Id', 'target']].apply(lambda x: '_'.join((str(x[0]), str(x[1]))), axis=1)\n  \n    return tests.sort_values(by=['Id', 'variable'])\\\n              .drop(['Id', 'variable', 'target'],axis=1)\\\n              .rename(columns={'Id_':'Id'})\\\n              .reset_index(drop=True)\\\n              [['Id', 'Predicted']]","55192546":"sub = make_sub(predictions)","384c65d5":"sub.head()","a5154ef5":"sub.to_csv('firsttry.csv', index=False)","8b06030d":"# Reading data","53ea085d":"# *THANK YOU.Its just the beginning,I will try my best to improve it and provide better notebook for other. Please upvote if you guys liked it,It would give a  motivation to continue on my work.*","730031c2":"# *IMPORTANT VISUALS OF BRAIN*","fa8ce505":"# IMPORTING MODULES","bac66815":"# I am sharing my notebook as It is a research competition, I would love if someone would be able to achieve great with the help of my simple notebook.\n\nI want to give credits to this [notebook](https:\/\/www.kaggle.com\/soham1024\/visualization-using-nilearn) for helping me out in some visuals. \nFeel free to use my notebook and please I request all of you to share your notebooks too.","b3b499e6":"# USING MODEL FOR PREDICTIONS","02fc1f85":"# Data Cleansing  "}}