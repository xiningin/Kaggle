{"cell_type":{"92d916b0":"code","411507f8":"code","b53074c2":"code","c61745dd":"code","8e0e66bf":"code","933c001e":"code","d9b6f6ac":"code","5184e1f8":"code","3e96986f":"code","c0838cba":"code","035d9602":"code","79f992c2":"code","98174cce":"code","026fd065":"code","4a817c22":"code","0ad40dba":"code","811095a6":"code","ba92193e":"code","ac8c56f0":"code","cc5471db":"code","09868ffc":"code","3701e92d":"code","a2c3a6d6":"code","5867570c":"code","6a2338a6":"code","b56a6afd":"code","7d5dfbef":"code","dd9efa65":"code","5c0542c0":"code","6343b206":"code","1c70561a":"code","3f90bf03":"code","227ee80f":"code","b3ae5d9c":"code","26d84eb6":"code","ae3dcdb4":"code","00b91e4a":"code","316ebd17":"code","ee9e8bf2":"code","c6f7e22d":"code","b8c24ab5":"code","b4fc9a70":"code","1ea0f23e":"code","423f2f27":"code","005dee96":"code","4d6a7586":"code","6df36262":"code","793adfc1":"code","81148b47":"code","ab3e840b":"code","aae65c56":"code","58db42a3":"code","f7d7c42a":"code","a9c4e4bf":"code","cfb88aa9":"code","f266310f":"code","c5439d60":"code","8e900305":"code","0d951b04":"code","bac6fbad":"code","068f321b":"code","babaf608":"code","584afa14":"code","8eb38cd4":"code","fea308f1":"code","2bc9f099":"code","e227f0d5":"code","9202e68e":"code","4b8222b0":"code","2a286538":"code","70112fa2":"code","54b7bf95":"code","b9df7980":"code","925db346":"code","3d2f0f35":"code","69560d16":"markdown","52478fff":"markdown","e94a6a50":"markdown","e01ca67a":"markdown","0cccf674":"markdown","3eea0d76":"markdown","8a81143e":"markdown","f32ada38":"markdown","ff3cc583":"markdown","96b148d0":"markdown","a3f108f5":"markdown","28062d38":"markdown","2206e683":"markdown","84a9dffe":"markdown","98b829ed":"markdown","8bb94965":"markdown","967fcb52":"markdown","6ae92c81":"markdown","33b067e1":"markdown","db5c1158":"markdown","3b36fbd2":"markdown","46cab88f":"markdown","86a5a8ea":"markdown","919acf40":"markdown","04785640":"markdown","9d0952a1":"markdown","88fcc8a0":"markdown","60c81ddd":"markdown","28d568a2":"markdown","940586ba":"markdown","ad27b703":"markdown","38f0ecab":"markdown","7173a9f4":"markdown","671609a3":"markdown","a7a0357a":"markdown","728e2411":"markdown","0f29f710":"markdown","1deac749":"markdown","ae30a358":"markdown","bcffde24":"markdown","3cac475e":"markdown","f279eb87":"markdown","a32a2c0c":"markdown","6f596ae8":"markdown","5b047277":"markdown","512a729a":"markdown","04e3bc14":"markdown","3ce2028c":"markdown","c180567b":"markdown","e429c242":"markdown","4fb83ad6":"markdown","a8f4fa71":"markdown","28788cb8":"markdown","86efb81c":"markdown","bcbf253d":"markdown","92892381":"markdown","2bf20363":"markdown","a389179d":"markdown","2db3319a":"markdown","8440ba5a":"markdown","8f86ac20":"markdown","96f8ac9d":"markdown","b16a7f29":"markdown","7eaae133":"markdown","415bf053":"markdown","8586b704":"markdown","870a8f49":"markdown","d02dd5bf":"markdown","9b571f86":"markdown","4e3705a0":"markdown","53654412":"markdown","ae1be64d":"markdown","0cc9749b":"markdown","e3738ce6":"markdown","a31dbfa3":"markdown","4243ced9":"markdown","95ca26f0":"markdown","12d6390e":"markdown","435580b9":"markdown","4dcab2ee":"markdown","bebff88e":"markdown"},"source":{"92d916b0":"%matplotlib inline","411507f8":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\n\nimport pickle\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dense, Dropout, ReLU, Softmax\n\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import SparseCategoricalAccuracy\nfrom tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler","b53074c2":"# CONSTANTS\nEPOCHS = 15\nBATCH_SIZE = 32\nSTEPS_PER_EPOCH = 86989 \/ BATCH_SIZE\n#MODEL_SELECTION_VALIDATION_STEPS = 86989 \/ BATCH_SIZE","c61745dd":"with open(\"..\/input\/traffic-signs-preprocessed\/data2.pickle\", \"rb\") as f:\n    data = pickle.load(f, encoding=\"latin1\")\n\n# Preparing y_train and y_validation for using in Keras\ndata[\"y_train\"] = to_categorical(data[\"y_train\"], num_classes=43)\ndata[\"y_validation\"] = to_categorical(data[\"y_validation\"], num_classes=43)\n\n# Making channels come at the end\ndata[\"x_train\"] = data[\"x_train\"].transpose(0, 2, 3, 1)\ndata[\"x_validation\"] = data[\"x_validation\"].transpose(0, 2, 3, 1)\ndata[\"x_test\"] = data[\"x_test\"].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == \"labels\":\n        print(F\"{i}:\", len(j))\n    else: \n        print(F\"{i}:\", j.shape)","8e0e66bf":"data[\"y_validation\"][0]","933c001e":"data[\"y_validation\"] = np.argmax(data[\"y_validation\"], axis=1)\ndata[\"y_train\"] = np.argmax(data[\"y_train\"], axis=1)","d9b6f6ac":"data[\"y_train\"].shape","5184e1f8":"data[\"y_train\"][0]","3e96986f":"data[\"y_validation\"].shape","c0838cba":"data[\"y_validation\"][0]","035d9602":"# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) \/ (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid","79f992c2":"# Visualizing some examples of training data\nexamples = data[\"x_train\"][100:200, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting some examples\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype(\"uint8\"), cmap=\"gray\")\nplt.axis(\"off\")\nplt.gcf().set_size_inches(15, 15)\nplt.title(\"Some examples of training data\", fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig(\"training_examples.png\")\nplt.close()","98174cce":"models_architectures_results = list()\nfinal_models = list()\nall_models = list()","026fd065":"def plot_hist(hist,\n              first_param,\n              second_param,\n              name_of_plot,\n              first_legend_label,\n              second_legend_label,\n              x_label,\n              y_label,\n              save_plot_img = False):\n    \n    plt.rcParams[\"figure.figsize\"] = (15.0, 5.0)\n    plt.rcParams[\"image.interpolation\"] = \"nearest\"\n    plt.rcParams[\"font.family\"] = \"Consolas\"\n    \n    fig = plt.figure()\n    plt.plot(hist.history[first_param], \"-o\", linewidth=3.0)\n    plt.plot(hist.history[second_param], \"-o\", linewidth=3.0)\n    \n    plt.plot(range(hist.params[\"epochs\"]),\n             hist.history[first_param],\n             c = \"g\",\n             label = first_legend_label)\n    plt.plot(range(hist.params[\"epochs\"]),\n             hist.history[second_param],\n             c = \"r\",\n             label = second_legend_label)\n    plt.legend(fontsize=\"xx-large\")\n    \n    plt.xticks(list(range(0, hist.params[\"epochs\"])), range(1, hist.params[\"epochs\"] + 1))\n    max_ylim = max(max(hist.history[first_param]), max(hist.history[second_param])) + 0.02\n    min_ylim = 0\n    if \"accuracy\" in first_param:\n        min_ylim = min(min(hist.history[first_param]), min(hist.history[second_param])) - 0.02\n    plt.ylim(min_ylim, max_ylim)\n    \n    plt.title(name_of_plot, fontsize=22)\n    plt.xlabel(x_label, fontsize = 18)\n    plt.ylabel(y_label, fontsize = 18)\n    plt.tick_params(labelsize=18)\n    \n    plt.show()\n    \n    if save_plot_img:\n        fig.savefig(F\"{hist.model.name}_{name_of_plot}.png\")\n        plt.close()","4a817c22":"def train_and_plot_results(model, callbacks = []):\n    model_hist = model.fit(data[\"x_train\"],\n                           data[\"y_train\"],\n                           batch_size=BATCH_SIZE,\n                           epochs = EPOCHS,\n                           steps_per_epoch = STEPS_PER_EPOCH,\n                           validation_data = (data[\"x_validation\"], data[\"y_validation\"]),\n                           callbacks = [TensorBoard(log_dir = F\"TensorBoardLogs\/{model.name}\/\", profile_batch = 100000000), \n                                        ModelCheckpoint(filepath = F\"ModelsCheckpoints\/{model.name}\/\")] + callbacks,\n                           verbose = 0)\n    plot_hist(model_hist,\n          \"loss\",\n          \"val_loss\",\n          \"Loss plot\",\n          \"train loss\",\n          \"validation loss\",\n          \"Epoch\",\n          \"Loss\",\n          True)\n    plot_hist(model_hist,\n          \"sparse_categorical_accuracy\",\n          \"val_sparse_categorical_accuracy\",\n          \"Accuracy plot\",\n          \"train accuracy\",\n          \"validation accuracy\",\n          \"Epoch\",\n          \"Accuracy\",\n          True)\n    train_loss, train_accuracy = model.evaluate(data[\"x_train\"],\n                                               data[\"y_train\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n    val_loss, val_accuracy = model.evaluate(data[\"x_validation\"],\n                                               data[\"y_validation\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n    print(F\"Loss - Train: {train_loss:.3f}, Validation: {val_loss:.3f}\")\n    print(F\"Accuracy - Train: {train_accuracy:.3f}, Validation: {val_accuracy:.3f}\")\n    print(F\"Variance %: {((train_accuracy - val_accuracy) * 100):.3f}\")\n    return (model.name, train_loss, val_loss, train_accuracy, val_accuracy)","0ad40dba":"def evaluate_architectures_models(models):\n    for model in models:\n        train_loss, train_accuracy = model.evaluate(data[\"x_train\"],\n                                               data[\"y_train\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n        val_loss, val_accuracy = model.evaluate(data[\"x_validation\"],\n                                               data[\"y_validation\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n        print(model.name)\n        print(F\"Train        Loss: {train_loss:.3f}, Accuracy: {train_accuracy:.3f}\")\n        print(F\"Validation   Loss: {val_loss:.3f}, Accuracy: {val_accuracy:.3f}\")\n        print(F\"Variance %         {((train_accuracy - val_accuracy) * 100):.3f}\")\n        print()","811095a6":"n1_model = Sequential(\n    name = \"n1_model\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 32, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    Dense(30, activation = ReLU()),\n    Dense(43, activation = Softmax())\n])","ba92193e":"n1_model.summary()","ac8c56f0":"n1_model.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","cc5471db":"models_architectures_results.append(train_and_plot_results(n1_model))","09868ffc":"all_models.append(n1_model)","3701e92d":"n2_model = Sequential(\n    name = \"n2_model\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 32, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    Dense(100, activation = ReLU()),\n    Dropout(0.1),\n    Dense(50, activation = ReLU()),\n    Dropout(0.1),\n    Dense(43, activation = Softmax())\n])","a2c3a6d6":"n2_model.summary()","5867570c":"n2_model.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","6a2338a6":"models_architectures_results.append(train_and_plot_results(n2_model))","b56a6afd":"all_models.append(n2_model)","7d5dfbef":"n3_model = Sequential(\n    name = \"n3_model\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 32, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(30, activation = ReLU()),\n    Dense(43, activation = Softmax())\n])","dd9efa65":"n3_model.summary()","5c0542c0":"n3_model.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","6343b206":"models_architectures_results.append(train_and_plot_results(n3_model))","1c70561a":"all_models.append(n3_model)","3f90bf03":"n4_model = Sequential(\n    name = \"n4_model\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 32, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(100, activation = ReLU()),\n    Dropout(0.1),\n    Dense(50, activation = ReLU()),\n    Dropout(0.1),\n    Dense(43, activation = Softmax())\n])","227ee80f":"n4_model.summary()","b3ae5d9c":"n4_model.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","26d84eb6":"models_architectures_results.append(train_and_plot_results(n4_model))","ae3dcdb4":"all_models.append(n4_model)","00b91e4a":"n5_model = Sequential(\n    name = \"n5_model\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(200, activation = ReLU()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU()),\n    BatchNormalization(),\n    Dropout(0.1),\n    Dense(100, activation = ReLU()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax())\n])","316ebd17":"n5_model.summary()","ee9e8bf2":"n5_model.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","c6f7e22d":"models_architectures_results.append(train_and_plot_results(n5_model))","b8c24ab5":"all_models.append(n5_model)","b4fc9a70":"evaluate_architectures_models(all_models)","1ea0f23e":"final_model_1 = Sequential(\n    name = \"final_model_1\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(200, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.1),\n    Dense(100, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax(), kernel_regularizer = l2())\n])","423f2f27":"final_model_1.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","005dee96":"train_and_plot_results(final_model_1)","4d6a7586":"all_models.append(final_model_1)\nfinal_models.append(final_model_1)","6df36262":"final_model_2 = Sequential(\n    name = \"final_model_2\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(200, activation = ReLU()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU()),\n    Dropout(0.1),\n    Dense(100, activation = ReLU()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax())\n])","793adfc1":"final_model_2.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","81148b47":"train_and_plot_results(final_model_2)","ab3e840b":"all_models.append(final_model_2)\nfinal_models.append(final_model_2)","aae65c56":"final_model_3 = Sequential(\n    name = \"final_model_3\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2()),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(200, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.1),\n    Dense(100, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax(), kernel_regularizer = l2())\n])","58db42a3":"final_model_3.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","f7d7c42a":"train_and_plot_results(final_model_3)","a9c4e4bf":"all_models.append(final_model_3)\nfinal_models.append(final_model_3)","cfb88aa9":"final_model_4 = Sequential(\n    name = \"final_model_4\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    BatchNormalization(),\n    Dense(200, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.1),\n    Dense(100, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax(), kernel_regularizer = l2())\n])","f266310f":"final_model_4.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","c5439d60":"train_and_plot_results(final_model_4)","8e900305":"all_models.append(final_model_4)\nfinal_models.append(final_model_4)","0d951b04":"final_model_5 = Sequential(\n    name = \"final_model_5\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-3)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    Dense(200, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU(), kernel_regularizer = l2()),\n    BatchNormalization(),\n    Dropout(0.1),\n    Dense(100, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax(), kernel_regularizer = l2())\n])","bac6fbad":"final_model_5.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","068f321b":"train_and_plot_results(final_model_5)","babaf608":"all_models.append(final_model_5)\nfinal_models.append(final_model_5)","584afa14":"final_model_6 = Sequential(\n    name = \"final_model_6\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 7e-4)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 7e-4)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 7e-4)),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 7e-4)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 7e-4)),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 7e-4)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    Dense(200, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.2),\n    Dense(150, activation = ReLU(), kernel_regularizer = l2()),\n    BatchNormalization(),\n    Dropout(0.1),\n    Dense(100, activation = ReLU(), kernel_regularizer = l2()),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax(), kernel_regularizer = l2())\n])","8eb38cd4":"final_model_6.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","fea308f1":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + EPOCHS))","2bc9f099":"train_and_plot_results(final_model_6, [annealer])","e227f0d5":"all_models.append(final_model_6)\nfinal_models.append(final_model_6)","9202e68e":"final_model_7 = Sequential(\n    name = \"final_model_7\",\n    layers = [\n    Input(shape = (32, 32, 3)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-4)),\n    Conv2D(filters = 64, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-4)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-4)),\n    Conv2D(filters = 128, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-4)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-4)),\n    Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = ReLU(), kernel_regularizer = l2(l = 1e-4)),\n    BatchNormalization(),\n    MaxPool2D(pool_size = 2),\n    Flatten(),\n    Dense(200, activation = ReLU(), kernel_regularizer = l2(0.5)),\n    Dropout(0.2),\n    Dense(150, activation = ReLU(), kernel_regularizer = l2(0.5)),\n    BatchNormalization(),\n    Dropout(0.1),\n    Dense(100, activation = ReLU(), kernel_regularizer = l2(0.5)),\n    Dropout(0.05),  \n    Dense(43, activation = Softmax(), kernel_regularizer = l2(0.5))\n])","4b8222b0":"final_model_7.compile(\n    optimizer = Adam(learning_rate = 0.001),\n    loss = SparseCategoricalCrossentropy(),\n    metrics = [SparseCategoricalAccuracy()])","2a286538":"train_and_plot_results(final_model_7, [annealer])","70112fa2":"all_models.append(final_model_7)\nfinal_models.append(final_model_7)","54b7bf95":"evaluate_architectures_models(final_models)","b9df7980":"test_loss, test_accuracy = final_model_1.evaluate(data[\"x_test\"],\n                                               data[\"y_test\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\nprint(F\"Test - Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}\")","925db346":"def evaluate_all_models(models):\n    for model in models:\n        train_loss, train_accuracy = model.evaluate(data[\"x_train\"],\n                                               data[\"y_train\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n        val_loss, val_accuracy = model.evaluate(data[\"x_validation\"],\n                                               data[\"y_validation\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n        test_loss, test_accuracy = model.evaluate(data[\"x_test\"],\n                                               data[\"y_test\"],\n                                               batch_size = BATCH_SIZE,\n                                               verbose = 0)\n        print(model.name)\n        print(F\"Train        Loss: {train_loss:.3f}, Accuracy: {train_accuracy:.3f}\")\n        print(F\"Validation   Loss: {val_loss:.3f}, Accuracy: {val_accuracy:.3f}\")\n        print(F\"Test         Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}\")\n        print()","3d2f0f35":"evaluate_all_models(all_models)","69560d16":"Enough, let's move on to the choice of model and tests.","52478fff":"Looks better, but we lost accuracy.","e94a6a50":"##### Train & Results","e01ca67a":"We see that the model has a high variance.<br>\nIf we look at the loss plot we can see that our model is gone and it is not working!","0cccf674":"##### Train & Results","3eea0d76":"## Practical application of model","8a81143e":"##### Model\nWhat if we applied regulation to both types of layers?","f32ada38":"Okay, we have a model, how can it be useful to us? How can we use it?<br>\nHere is an example:\nA car device that shows the last seen speed limit sign - this is actually a speed we should not exceed :)<br><br>\nWhat do we need:\n1. Raspberry Pi with camera and lcd display\n2. Detected Sign model that uses the camera data and finds the coordinates of the sign in the image(frame from video).\n3. Cut the image by given coordinates and submit it to our classification model.\n4. If the result indicates that the sign is of the speed limit type, we will display it on the display.\n\nHere's a high level description of how to use our model :)","ff3cc583":"We can see that the regulation of the convolution layers only, does not have a good effect on the model.","96b148d0":"## Conclusion","a3f108f5":"Well, we see that the labels are represented as an array of size 43, which represents the probability for the particular class. Because our classes are mutually exclusive (eg when each sample belongs exactly to one class), there are no probabilities of two or more classes, these are road signs :). For this reason, we will use as a loss and accuracy - sparse categorical crossentropy, a single number representing the class. For example, when one sample can have multiple classes or labels are soft probabilities (like [0.5, 0.3, 0.2]) we may use categorical crossentropy. We need to convert labels.","28062d38":"I think the best model is the final_model_1","2206e683":"##### Model\nLet's reduce the regulation in the convolutional layers a little and see if it will work.<br>\nWe can also add a callback function that minimizes the learning rate step with each passing epoch. So we should prevent wandering of loss functions around the minimum.","84a9dffe":"#### Final model \u21165","98b829ed":"##### Model\nLet's try to regulate the convolutional layers.","8bb94965":"In convolution layers we will use filters with 3x3 dimmension and same padding.<br>\nNow let's try a different type and complexity architectures.","967fcb52":"##### Model\nWe will now make a more complex model. 6 convolutional layers with 3 max pool layers that will reduce the size of training parameters. After that, we will add 3 fully connected layers, with dropout layers with different percentages and 2 batch normalization layers between them.","6ae92c81":"##### Train & Results","33b067e1":"#### Model architecture \u21161\n","db5c1158":"##### Train & Results","3b36fbd2":"##### Train & Results","46cab88f":"#### Final model \u21163","86a5a8ea":"Our model now looks like a model :)<br>Maybe we have an architecture to improve!","919acf40":"## Introduction\nIn the present article we will use Traffic Signs Preprocessed dataset<sup id=\"fnref:1\"><a href=\"#fn:1\" class=\"footnote\">[1]<\/a><\/sup>. Set is ready to use preprocessed data for Traffic Signs, witch initial data is German Traffic Sign Recognition Benchmarks (GTSRB)<sup id=\"fnref:2\"><a href=\"#fn:2\" class=\"footnote\">[2]<\/a><\/sup>, saved into the nine pickle files. We will use the data in the file data2.pickle - Shuffling, \/255.0 + Mean Normalization. First, we will load the data from the file, then we will preview some of the data. The next step will be to create some architectures and choose the best ones, which we will then try to improve with different techniques. Finally, we will see how well it can handle image class prediction.","04785640":"## Future work","9d0952a1":"## Visualize set of examples <sup id=\"fnref:4\"><a href=\"#fn:4\" class=\"footnote\">[4]<\/a><\/sup>\nWe will now create a function that will convert input 4D tensor to a grid.","88fcc8a0":"#### Model architecture \u21162","60c81ddd":"##### Train & Results","28d568a2":"The following 3 functions will save us a lot of code, help us train,save and show results, save and visualize charts with training history, and evaluate the models.","940586ba":"#### Compare & select best model architecture","ad27b703":"We obviously have a winner - Model architecture \u21165","38f0ecab":"#### Model architecture \u21163","7173a9f4":"The variance has dropped.\nBut the model is still not ok! Let return dropout layers.","671609a3":"We will now try to improve our best architecture. I guess our model overfitting the train data. Let's see if that's the case.","a7a0357a":"# Did you see the sign?\n### Author: Georgi Stoyanov\n#### January 2020","728e2411":"##### Train & Results","0f29f710":"##### Model\n1 convolution layer + 2 fully connected layers.<br>\nIn addition to adding another fully connected layer, we also add dropout layers to reduce variance and make the neurons less dependent on each other.","1deac749":"## Model Architectures\nThe next task is to test different convolution network architectures and choose the best one for future improvement.<br><br>\nIn order to compare the models used in this article, we create 3 collections, one for the models with which we test the architecture, second to final models and third for all the models we have used.","ae30a358":"It looks much better.","bcffde24":"#### Evaluate & select best model","3cac475e":"##### Model\nThe chosen architecture of the model is the deepest of all, so we can add a bach normalization layers that, perhaps, will improve the model by eliminating problems like vanishing (0) and exploding (\u221e) weights.","f279eb87":"## Domain Knowledge<sup id=\"fnref:3\"><a href=\"#fn:3\" class=\"footnote\">[3]<\/a><\/sup>\n<b>Traffic signs<\/b> or <b>road signs<\/b> are signs erected at the side of or above roads to give instructions or provide information to road users. The earliest signs were simple wooden or stone milestones. Later, signs with directional arms were introduced, for example, the fingerposts in the United Kingdom and their wooden counterparts in Saxony.\n\nWith traffic volumes increasing since the 1930s, many countries have adopted pictorial signs or otherwise simplified and standardized their signs to overcome language barriers, and enhance traffic safety. Such pictorial signs use symbols (often silhouettes) in place of words and are usually based on international protocols. Such signs were first developed in Europe, and have been adopted by most countries to varying degrees.\n\n### International conventions\nVarious international conventions have helped to achieve a degree of uniformity in Traffic Signing in various countries.","a32a2c0c":"After repeated training of the models, I have found that the results obtained can be described as unstable and difficult to reproduce, the deviation can be in the range 1-5%. In the future work section there are ideas that would change this and stabilize the results of the models. However, we can determine that the achievable results on this data set are about 96-98%. As I was unable to find information on the optimum accuracy value of this set, any higher value I would classify as unrealistic (overfitting).","6f596ae8":"##### Model\n\u0422he simplest.<br>\n1 convolution layer + 1 fully connected layers.<br>\nIn models present standard layers like: Input, MaxPool2D, Flatten, BatchNormalization, Dropout etc. Some of them will be explained when we need to change them.","5b047277":"Function <b>train_and_plot_results<\/b> - train,save and show results","512a729a":"##### Train & Results","04e3bc14":"## Read and prepare  dataset<sup id=\"fnref:4\"><a href=\"#fn:4\" class=\"footnote\">[4]<\/a><\/sup>\nLet's read and prepare the data and see if we read it correctly - size, structure, types, etc.","3ce2028c":"##### Train & Results","c180567b":"##### Train & Results","e429c242":"## Abstract\nIn this article, I have shown an example way to create a convolutional network - architecture selection, optimization, visualization of model information and its layers, measuring model accuracy, how to save our model, history and statistics about it, etc. Finally, we will see how well it will handle the task, what can be done as additional work for the future, and last but not least what an exemplary practical application we can find for the model.","4fb83ad6":"There is definitely an improvement.","a8f4fa71":"#### Final model \u21167","28788cb8":"## Test best model","86efb81c":"Function <b>evaluate_architectures_models<\/b> - evaluate the models","bcbf253d":"##### Model\n3 convolution layer with increasing number of filters + 1 fully connected layers.<br>\nAs the first model, but with more convolutional layers and one batch normalization layer between them and fully connected layers. This layer serves to normalize the weights so that we do not have cases of vanishing (0) and exploding (\u221e) weights.","92892381":"## Improve best model architecture","2bf20363":"#### Final model \u21166","a389179d":"#### Model architecture \u21164","2db3319a":"#### Model architecture \u21165","8440ba5a":"##### Model\nWe reduce the regulation in the convolutional layers a little further and increase the regulation in the convolutional layers a little.","8f86ac20":"The variance has dropped slightly.<br>\nBut the model is still not ok!","96f8ac9d":"We use the function to show 100 examples of data in the grid.","b16a7f29":"##### Model\nWe can see that the regulation with a default value in the convolution layers does not have a good effect on the model. Obviously, we need to reduce regulation to have more accurate filters.","7eaae133":"Lets test final_model_1.","415bf053":"##### Model\n3 convolution layer with increasing number of filters + 2 fully connected layers.<br>\nCombination of second and third models.","8586b704":"The following things can be done as future actions:\n* Different filter sizes 5x5 7x7\n* Different batch size\n* Selection of other architectures, optimization of other parameters or of the same but with other approaches.\n* Detailed study of the data - wrongly predicted and finding some connection between them.\n* Finding more data or shuffling all data and splitting training, validation and test sets again.\n* Visualization and examination of filter heatmaps and Feature Maps\n\nOr whatever you think will be helpful - Welcome to Deep Learning :)","870a8f49":"##### Train & Results","d02dd5bf":"## Test all models","9b571f86":"<div class=\"footnotes\">\n  <ol>\n      <li id=\"fn:1\">\n       <p><a href=\"https:\/\/www.kaggle.com\/valentynsichkar\/traffic-signs-preprocessed\" rel=\"noopener\" target=\"_blank\"> Traffic Signs Preprocessed<\/a><a href=\"#fnref:1\" class=\"reversefootnote\">&#8617;<\/a><\/p>\n    <\/li>\n      <br\/>\n    <li id=\"fn:2\">\n       <p><a href=\"https:\/\/www.kaggle.com\/meowmeowmeowmeowmeow\/gtsrb-german-traffic-sign\">GTSRB - German Traffic Sign Recognition Benchmark<\/a><a href=\"#fnref:2\" class=\"reversefootnote\">&#8617;<\/a><\/p>\n    <\/li>\n      <br\/>\n      <li id=\"fn:3\">\n       <p><a href=\"https:\/\/en.wikipedia.org\/wiki\/Traffic_sign\" rel=\"noopener\" target=\"_blank\">Wikipedia \u2013 Traffic sign<\/a><a href=\"#fnref:3\" class=\"reversefootnote\">&#8617;<\/a><\/p>\n    <\/li>\n      <br\/>\n      <li id=\"fn:4\">\n       <p><a href=\"https:\/\/www.kaggle.com\/valentynsichkar\/traffic-signs-classification-with-cnn\" rel=\"noopener\" target=\"_blank\">Traffic Signs Classification with CNN<\/a> by <a href=\"https:\/\/www.kaggle.com\/valentynsichkar\" rel=\"noopener\" target=\"_blank\">Valentyn Sichkar<\/a><a href=\"#fnref:4\" class=\"reversefootnote\">&#8617;<\/a><\/p>\n    <\/li>\n  <\/ol>\n<\/div>","4e3705a0":"Function <b>plot_hist<\/b> - save and visualize charts with training history","53654412":"<img src=\"https:\/\/ehhnkw.am.files.1drv.com\/y4mN1WYhHx5QRWJtliWHht6niSnYdS1_nUvQE4YWRX6kehKQ_L6oqijE8c-P9eaetFFUQXYrl7Of5XZpoNrJHQFAjvz90r2F2mHM1KhKtYlmyiwto1BwesdpS3UrJrURUK4l4lhFLh28bZR2G9L6MSPfuAUSr3oGU5GFao85JzFtuFogGerE6Tgn0u0z6qrTQR8R6n1u83B1EOv07NNvi5NHQ?width=1809&height=576&cropmode=none\">","ae1be64d":"The variance has dropped. \u0422he model is starting to look better.","0cc9749b":"#### Final model \u21162","e3738ce6":"##### Model\nTo reduce variance, we can use regularization in layers, let's start with the fully conected layers.","a31dbfa3":"##### Train & Results","4243ced9":"#### Final model \u21164","95ca26f0":"#### Final model \u21161","12d6390e":"We achieved accuracy with the test data 0.978. Now we test all models.","435580b9":"The following function makes it easier for us to test models.","4dcab2ee":"Hmm...","bebff88e":"## Refferences"}}