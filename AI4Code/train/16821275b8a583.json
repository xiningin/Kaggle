{"cell_type":{"25dbdda1":"code","6df0862a":"code","63f6da5d":"code","094327c9":"code","3ccb06eb":"code","af0c0b72":"code","f7f1eef8":"code","054041e6":"code","5528b643":"code","c480154f":"code","94034be0":"code","dcd992bd":"code","a30a83fd":"code","231854dc":"code","a4519852":"code","0ffaa771":"code","11c25003":"code","1e878a21":"markdown","8ee1d167":"markdown","1a78380e":"markdown","33fd12a5":"markdown","33ef8bcb":"markdown","d0a2c220":"markdown"},"source":{"25dbdda1":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold","6df0862a":"df_train = pd.read_csv('..\/input\/bengaliai-cv19\/train.csv')","63f6da5d":"df_train.head(2)","094327c9":"grapheme2idx = {grapheme: idx for idx, grapheme in enumerate(df_train.grapheme.unique())}\ndf_train['grapheme_id'] = df_train['grapheme'].map(grapheme2idx)","3ccb06eb":"df_train.head(2)","af0c0b72":"n_fold = 5\nskf = StratifiedKFold(n_fold, random_state=42)\nfor i_fold, (train_idx, val_idx) in enumerate(skf.split(df_train, df_train.grapheme)):\n    df_train.loc[val_idx, 'fold'] = i_fold\ndf_train['fold'] = df_train['fold'].astype(int)","f7f1eef8":"df_train.head(2)","054041e6":"df_train['unseen'] = 0\ndf_train.loc[df_train.grapheme_id >= 1245, 'unseen'] = 1","5528b643":"df_train.unseen.value_counts()","c480154f":"df_train.loc[df_train['unseen'] == 1, 'fold'] = -1","94034be0":"df_train['fold'].value_counts()","dcd992bd":"df_train.head(2)","a30a83fd":"df_train.to_csv('train_v2.csv', index=False)","231854dc":"n_fold = 5\nfor fold in range(n_fold):\n    train_idx = np.where((df_train['fold'] != fold) & (df_train['unseen'] == 0))[0]\n    valid_idx = np.where((df_train['fold'] == fold) | (df_train['unseen'] != 0))[0]\n\n    df_this_train = df_train.loc[train_idx].reset_index(drop=True)\n    df_this_valid = df_train.loc[valid_idx].reset_index(drop=True)\n    \n    #################################\n    # Do training and validating here\n    #################################\n    \n    break","a4519852":"n_uniq_grapheme = df_this_train.grapheme_id.nunique()\nn_uniq_root = df_this_train.grapheme_root.nunique()\nn_uniq_vowel = df_this_train.vowel_diacritic.nunique()\nn_uniq_diacritic = df_this_train.consonant_diacritic.nunique()\n\nprint(f'We have only {n_uniq_grapheme} grapheme in training data, but all {n_uniq_root} roots, {n_uniq_vowel} vowels, {n_uniq_diacritic} diacritics are remains')","0ffaa771":"n_uniq_grapheme = df_this_valid.grapheme_id.nunique()\nn_uniq_root = df_this_valid.grapheme_root.nunique()\nn_uniq_vowel = df_this_valid.vowel_diacritic.nunique()\nn_uniq_diacritic = df_this_valid.consonant_diacritic.nunique()\n\nprint(f'While we have all {n_uniq_grapheme} grapheme in validation, and all {n_uniq_root} roots, {n_uniq_vowel} vowels, {n_uniq_diacritic} diacritics as well')","11c25003":"# We have 7578 unseen samples in validation set, which is approximately 16.4%\ndf_this_valid['unseen'].value_counts()","1e878a21":"# Map grapheme to id","8ee1d167":"# StratifiedKFold On Grapheme","1a78380e":"Hi every one. I've made you guys a validation split, which considered unseen graphemes.\n\nIt have only 1245 graphemes in training set, while all components are remains. All unseen graphemes are used in every fold while training.\n\nUsing my split, we will have approximately **38k SEEN** samples, and exacly **7578 UNSEEN** samples for validation in each fold.\n\nDownload the file `train_v2.csv` generated by this script and have a try on yourself!\n\nUsage Example:\n```\ndf_train = pd.read_csv('path\/to\/train_v2.csv')\nn_fold = 5\nfor fold in range(n_fold):\n    train_idx = np.where((df_train['fold'] != fold) & (df_train['unseen'] == 0))[0]\n    valid_idx = np.where((df_train['fold'] == fold) | (df_train['unseen'] != 0))[0]  # all unseen graphemes are in each fold\n```","33fd12a5":"# Usage Example","33ef8bcb":"# Analysis","d0a2c220":"# Add Unseen Flag"}}