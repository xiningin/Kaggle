{"cell_type":{"94dad3f5":"code","5f5b9598":"code","7dd2824e":"code","0aab173f":"code","d0eaf277":"code","90439851":"code","4e8ddf67":"code","384c2ef2":"code","953b0fb3":"markdown","71990672":"markdown","afa2002b":"markdown","9d61fa91":"markdown"},"source":{"94dad3f5":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import random_split, DataLoader\n\nimport os\nimport glob\nimport re\nfrom random import shuffle\nfrom PIL import Image\n\nfrom tqdm import tqdm\n\n%matplotlib inline\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device: {}'.format(device))","5f5b9598":"image_dir = \"..\/input\/images\/Images\"\nimage_paths = [path for path in glob.iglob(image_dir + '\/*\/*.jpg', recursive=True)]\npattern = re.compile(\"(?<=-)\\w+(?=\/n)\")\nbreeds = [pattern.findall(image)[0] for image in image_paths]\ndogs = [(image_paths[i], breeds[i]) for i in range(len(image_paths))]\nshuffle(dogs)\n\nnum_sample_dogs = 6\n\ntest_ims = [Image.open(dogs[i][0]) for i in range(num_sample_dogs)]\ntest_ims_arrays = [np.array(test_im) for test_im in test_ims]\n\nfig, ax = plt.subplots(ncols=num_sample_dogs, figsize=(18,12))\nfor dog in range(num_sample_dogs):\n    ax[dog].imshow(test_ims_arrays[dog])\n    ax[dog].get_xaxis().set_visible(False)\n    ax[dog].get_yaxis().set_visible(False)\n    ax[dog].set_title(dogs[dog][1]);","7dd2824e":"data_transforms = transforms.Compose([\n    transforms.Resize(140),\n    transforms.CenterCrop(128),\n    transforms.ToTensor()\n])\n\ndataset = datasets.ImageFolder(image_dir, transform=data_transforms)\ntrain_dataset, test_dataset = random_split(dataset, \n                                           (int(0.9*len(dataset)), \n                                            len(dataset)-int(0.9*len(dataset))))\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\nprint(\"Training set size: {}\".format(len(train_dataset)))\nprint(\"Testing set size: {}\".format(len(test_dataset)))","0aab173f":"class ConvNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(6)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(12)\n        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 128 -> 64\n        \n        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(24)\n        self.conv4 = nn.Conv2d(in_channels=24, out_channels=48, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn4 = nn.BatchNorm2d(48)\n        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 64 -> 32\n        \n        self.conv5 = nn.Conv2d(in_channels=48, out_channels=96, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn5 = nn.BatchNorm2d(96)\n        self.conv6 = nn.Conv2d(in_channels=96, out_channels=182, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn6 = nn.BatchNorm2d(182)\n        self.mp3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 32 -> 16\n        \n        self.conv7 = nn.Conv2d(in_channels=182, out_channels=182, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn7 = nn.BatchNorm2d(182)\n        self.conv8 = nn.Conv2d(in_channels=182, out_channels=256, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn8 = nn.BatchNorm2d(256)\n        self.mp4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) # 16 -> 8\n        \n        self.conv9 = nn.Conv2d(in_channels=256, out_channels=256, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn9 = nn.BatchNorm2d(256)\n        self.conv10 = nn.Conv2d(in_channels=256, out_channels=256, \n                               kernel_size=3, stride=1, padding=1)\n        self.bn10 = nn.BatchNorm2d(256)\n        \n        self.fc1 = nn.Linear(256*8*8, 10000)\n        self.fc2 = nn.Linear(10000, 5000)\n        self.fc3 = nn.Linear(5000, 1000)\n        self.fc4 = nn.Linear(1000, 120)\n\n    def forward(self, x):\n        x = self.mp1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x)))))))\n        x = self.mp2(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))\n        x = self.mp3(F.relu(self.bn6(self.conv6(F.relu(self.bn5(self.conv5(x)))))))\n        x = self.mp4(F.relu(self.bn8(self.conv8(F.relu(self.bn7(self.conv7(x)))))))\n        x = F.relu(self.bn10(self.conv10(F.relu(self.bn9(self.conv9(x))))))\n        \n        x = x.view(x.shape[0], -1)\n        \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        \n        return x","d0eaf277":"convnet = ConvNet()","90439851":"convnet.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(convnet.parameters(), lr=0.03)\n\nepochs = 70\ntrain_losses, test_losses = [], []\ntest_accuracies = []\n\nfor e in tqdm(range(epochs)):\n    convnet.train()\n    for ii, (images, labels) in enumerate(train_dataloader):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        logits = convnet(images)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_losses.append(loss.item() \/ images.shape[0])\n    \n    test_loss = 0\n    accuracy = 0\n    convnet.eval()\n    for ii, (images, labels) in enumerate(test_dataloader):\n        images, labels = images.to(device), labels.to(device)\n        \n        with torch.no_grad():\n            logits = convnet(images)\n            loss = criterion(logits, labels)\n            test_loss += loss.item() \/ images.shape[0]\n            \n            preds = logits.argmax(dim=1)\n            accuracy += torch.mean((preds == labels).type(torch.FloatTensor))\n            \n    test_losses.append(test_loss \/ len(test_dataloader))\n    test_accuracies.append(accuracy \/ len(test_dataloader))","4e8ddf67":"train_losses_averaged = []\ninterval = 250\nfor i in range(0,len(train_losses),interval):\n        try:\n            train_losses_averaged.append(np.mean(train_losses[i:i+interval]))\n        except IndexError:\n            train_losses_averaged.append(np.mean(train_losses[i:]))","384c2ef2":"fig = plt.figure(figsize=(18, 12))\ngrid = plt.GridSpec(2, 2, hspace=0.4, wspace=0.2)\ntrain_loss_ax = fig.add_subplot(grid[0,:])\ntest_loss_ax = fig.add_subplot(grid[1, 0])\ntest_acc_ax = fig.add_subplot(grid[1, 1])\n\ntrain_loss_ax.plot(train_losses_averaged)\ntrain_loss_ax.set_title('Training loss (average per 250 batches)')\ntrain_loss_ax.set_xlabel('Batch')\ntest_loss_ax.plot(test_losses)\ntest_loss_ax.set_title('Test loss (average per epoch)')\ntest_loss_ax.set_xlabel('Epoch')\ntest_acc_ax.plot(test_accuracies, color='red')\ntest_acc_ax.set_title('Test accuracy (average per epoch)')\ntest_acc_ax.set_xlabel('Epoch')\n\nplt.show()","953b0fb3":"## A Simple Convolutional Neural Network\nWe now define a simple convolutional neural network, after first processing the image data.","71990672":"# How Much is That Doggie in the Window?\nFine-grained prediction of dog breeds using a ConvNet trained from scratch.","afa2002b":"Not such a good result...perhaps transfer learning can help!","9d61fa91":"## Data Exploration\nLet's first inspect some of the dog images. As we will see, there is a large amount of variety in how the images are framed, suggesting already that this will be a difficult problem."}}