{"cell_type":{"e81c2a27":"code","2f21542d":"code","37818b88":"code","0fb8ee91":"code","3fdd4060":"code","e391a0f3":"code","b71a0ac4":"code","c2240094":"code","94fe5bb5":"code","90f0c212":"code","0795e302":"code","155ab376":"code","43865f5e":"code","cbe8bb6b":"code","2bd4c939":"code","00fc4013":"code","60b82b22":"code","0be96164":"code","42024c7c":"code","3fd159de":"code","44dec375":"code","a8cfd628":"code","6915a374":"code","03036db8":"code","91a18574":"code","108c820c":"code","1a4170b9":"code","baeff735":"code","d18072b7":"code","a97892b7":"code","872b117d":"code","f87dbd06":"code","d5eb05a0":"code","902237b1":"code","4fb191e8":"code","454ddb66":"code","961bf93c":"code","7618de4c":"code","85f7fb8c":"code","f0731851":"code","e41fae97":"code","72f7a97c":"code","9a61cfd8":"code","bad3beaf":"code","5f28463c":"code","42c1900e":"code","5021b942":"code","58403c6a":"code","f9badcfb":"code","bad7a1ff":"code","39797600":"code","67b29a0e":"code","31b6f423":"code","e80cc767":"code","6713bba4":"code","91af0565":"code","fcdfadea":"code","952829cd":"code","c6c71d1a":"code","7f029dff":"code","3434b604":"code","72a9f86b":"code","84e47476":"code","781f6b41":"code","9dd82cd4":"code","c96c4aff":"code","9c61255d":"code","53f93498":"code","105e0e05":"markdown","33c665b0":"markdown","cdd76b4c":"markdown","6f08a2cc":"markdown","bc6aa9c3":"markdown","d4017c0f":"markdown","fba2acb7":"markdown","6c305ae6":"markdown","26c17035":"markdown","d479839b":"markdown","a4e2a3b4":"markdown","1d437b9c":"markdown","8ef19d37":"markdown","c82a222d":"markdown","87f09712":"markdown","5b99ee45":"markdown","a9023da5":"markdown","dd13c0e1":"markdown","bd38cea1":"markdown","8e6c9390":"markdown","9a814954":"markdown","61a8de86":"markdown","b2569681":"markdown","439c0a5f":"markdown","d9653f62":"markdown","8a800fe5":"markdown","cb47d46f":"markdown"},"source":{"e81c2a27":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","2f21542d":"train_data=pd.read_csv('..\/input\/titanic\/train.csv')#mudar o path para o que est\u00e1 em seu computador\ntest_data=pd.read_csv('..\/input\/titanic\/test.csv')\n#Dados_test[\"Age\"]=Dados_test.Age.fillna(Dados.Age.mean())\n#Dados_test[\"Fare\"]=Dados_test.Age.fillna(Dados.Fare.mean())\n#Dados_test.isnull().sum()\ntrain_data","37818b88":"train_data.info()","0fb8ee91":"train_data.describe()","3fdd4060":"full_dataset=[train_data,test_data]","e391a0f3":"for data in full_dataset:\n    data['Pronouns']=data.Name.str.findall(r'[A-Z]+[a-z]*\\.').str[0].str[:-1]\n\ntrain_data['Pronouns'].value_counts()","b71a0ac4":"pronouns_list=['Mr','Miss','Mrs','Master','Others']\npronouns_map=dict(zip(pronouns_list,range(len(pronouns_list))))#{'Mr':0,'Miss':1,'Mrs':2,'Master':3}\nfor data in full_dataset:\n    data.loc[False==data['Pronouns'].isin(pronouns_list),'Pronouns']='Others'\n    data['Pronouns']=data['Pronouns'].map(pronouns_map)","c2240094":"map_sex={'male':0,'female':1}\nfor data in full_dataset:\n    data['Sex']=data['Sex'].map(map_sex)","94fe5bb5":"sns.catplot(x='Pronouns',y='Age',data=train_data)","90f0c212":"train_data.groupby('Pronouns')['Age'].median()","0795e302":"for data in full_dataset:\n    data['Age'].fillna(data.groupby('Pronouns')['Age'].transform('median'),inplace=True)\n    #train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","155ab376":"train_data.Pclass.value_counts()","43865f5e":"Pclass1 = train_data.loc[train_data['Pclass']==1,'Embarked'].value_counts()\nPclass2 = train_data.loc[train_data['Pclass']==2,'Embarked'].value_counts()\nPclass3 = train_data.loc[train_data['Pclass']==3,'Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3],index=['Pclass1','Pclass2','Pclass3'])\ndf.plot(kind='bar')","cbe8bb6b":"for data in full_dataset:\n    data['Embarked']=data['Embarked'].fillna('S')","2bd4c939":"train_data.Pclass.value_counts()","00fc4013":"train_data.head()","60b82b22":"train_data.Pclass.value_counts()","0be96164":"for data in full_dataset:\n    data['Cabin']=data.Cabin.str[0]\n","42024c7c":"data.Cabin.value_counts()","3fd159de":"sns.catplot(data=train_data,x='Cabin',y='Pclass',hue='Survived',kind='bar')\n#sns.displot(data=train_data,x='Age',hue='Survived',kind='kde',multiple='stack')","44dec375":"sns.displot(x='Pclass',hue='Cabin',multiple='stack',data=train_data)","a8cfd628":"train_data.groupby('Cabin').Pclass.mean()","6915a374":"def feature_map(data,feature):\n    feature_val=data[feature].dropna().unique()\n    feature_map=dict(zip(feature_val,range(len(feature_val))))\n    data[feature]=data[feature].map(feature_map)\n    return feature_map\n\nfor data in full_dataset:\n    feature_map(data,'Cabin')\n    data[\"Cabin\"].fillna(data.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","03036db8":"train_data.Cabin","91a18574":"for data in full_dataset:\n    data['Family_size']=data['SibSp']+data['Parch']+1","108c820c":"train_data.info()","1a4170b9":"sns.displot(hue='Survived',x='Family_size',kind='kde',fill=True,data=train_data)","baeff735":"features_drop=['Name','SibSp','Parch']\nfor data in full_dataset:\n    data.drop(features_drop,axis=1,inplace=True)","d18072b7":"dados=train_data.copy()\ndados['Ticket_Pref']=dados[False==dados['Ticket'].str.split().str[0].str.isnumeric()].Ticket.str.split().str[0]\ndados['Ticket_Pref']=dados['Ticket_Pref'].fillna('Nothing')\n#comPref=dados.loc[False==dados['Ticket_Pref'].str.match('Nothing')]#.Pclass.value_counts()\n#semPref=dados.loc[True==dados['Ticket_Pref'].str.match('Nothing')]\n\ndados.loc[False==dados['Ticket_Pref'].str.match('Nothing'),'Pref']=1\ndados.loc[True==dados['Ticket_Pref'].str.match('Nothing'),'Pref']=0\ndados.loc[dados['Ticket_Pref'].str.match('PC'),'Pref']=2\ndados.loc[dados['Ticket_Pref'].str.match('A.*'),'Pref']=3\n\n#dados.Ticket_Pref.value_counts()\nsns.displot(data=dados,x='Pref',hue='Pclass',multiple='stack')","a97892b7":"dados.Ticket_Pref.value_counts()","872b117d":"for data in full_dataset:\n    data['Ticket_Pref']=data[False==data['Ticket'].str.split().str[0].str.isnumeric()].Ticket.str.split().str[0]\n    data['Ticket_Pref']=data['Ticket_Pref'].fillna('Nothing')\n\n    data.loc[dados['Ticket_Pref'].str.match('Nothing'),'Pref']=0\n    data.loc[False==dados['Ticket_Pref'].str.match('Nothing'),'Pref']=1\n    data.loc[dados['Ticket_Pref'].str.match('PC'),'Pref']=2\n    data.loc[dados['Ticket_Pref'].str.match('A.*'),'Pref']=3\n    \n    data.drop(['Ticket','Ticket_Pref'],axis=1,inplace=True)\n    ","f87dbd06":"train_data","d5eb05a0":"test_data.info()","902237b1":"#Preenchemos com a m\u00e9dia das classes\nfor data in full_dataset:\n    data['Fare'].fillna(train_data.groupby('Pclass')['Fare'].transform('median'),inplace=True)\n    ","4fb191e8":"test_data.info()","454ddb66":"from sklearn.feature_selection import mutual_info_classif\n\ndef mutual_info(Dados,target='Survived'):\n    X = Dados.copy().dropna()\n    y = X.pop(target)\n\n    # Label encoding for categoricals\n    for colname in X.select_dtypes(\"object\"):\n        X[colname], _ = X[colname].factorize()\n\n    # All discrete features should now have integer dtypes (double-check this before using MI!)\n    discrete_features = X.dtypes == 'int64'\n    mi=mutual_info_classif(X,y,discrete_features=discrete_features)#para regress\u00e3o usamos mutual_info_regression\n    mi=pd.Series(mi,index=X.columns)\n    mi=mi.sort_values(ascending=False)\n    serie=mi.sort_values()\n    labels=serie.index\n    plt.barh(labels,serie)\n    plt.xlabel('mutual information')\n    print(mi)\n    return mi\n\n#Dados_eng_prep=Dados_eng.dropna().drop('Age_cat',axis=1)\nmi_scores = mutual_info(train_data.drop('PassengerId',axis=1))  \n","961bf93c":"train_data.head()","7618de4c":"X=train_data.drop('Survived',axis=1)\nY=train_data['Survived']\nX_test=test_data","85f7fb8c":"X.shape","f0731851":"from sklearn.preprocessing import OneHotEncoder,MinMaxScaler,PolynomialFeatures\nfrom sklearn.compose import ColumnTransformer\n\ncat_features=['Sex','Embarked']\nnum_features=['Pclass','Age','Fare','Cabin','Pronouns','Family_size','Pref']\n\ncolumns=X.columns\n\npipeline=ColumnTransformer([\n\n    ('cat',OneHotEncoder(handle_unknown = 'ignore'),cat_features),\n    ('num',MinMaxScaler(),num_features),\n\n])\n\nX=pipeline.fit_transform(X)\nX_test=pipeline.transform(X_test)\n\nX.shape","e41fae97":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n","72f7a97c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\n\nmodels=[\n    \n    RandomForestClassifier(),\n    SVC(kernel='rbf',probability=True),\n    KNeighborsClassifier(),\n    LogisticRegression(),\n    SGDClassifier(loss=\"modified_huber\")\n]\n\nfor model in models:\n    scores=cross_val_score(model,X,Y,cv=k_fold,scoring='accuracy')\n    print('Model:\\t',model)\n    print('Mean score:\\t',round(np.mean(scores)*100, 2))\n    print(60*'-')\n    print('\\n')","9a61cfd8":"from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n\nparams=[\n    {'max_depth':[9,12,13,15,20,22,23],'max_leaf_nodes':[58,60,65,70,80,90,100,110,120,150]}\n]\n\nforest=RandomForestClassifier(random_state=0)\ngrid_search=GridSearchCV(forest,params,cv=k_fold,scoring='accuracy',refit=True)\ngrid_search.fit(X,Y)\nprint('Best Params:\\t',grid_search.best_params_)\nprint('Best Score:\\t',round(grid_search.best_score_*100,2))","bad3beaf":"forest.get_params()","5f28463c":"grid_search.best_estimator_","42c1900e":"forest_params=[\n    {'max_depth':[9,12,13,15,20,25],'max_leaf_nodes':[50,60,65,70,80,85,90,95,100]}\n]\n\nsvm_params=[\n    {'C':[20,30,40,45,50,60]}\n]\n\nneighbours_params=[\n    {'n_neighbors':[2,3,4,6]}\n]\n\nlogistic_params=[\n    {'C':[5,8,10,12,15,20,50]}\n]\n\nsgd_params=[\n    {'alpha':[0.0008,0.001,0.0015]}\n]\n\nparams=[forest_params,svm_params,neighbours_params,logistic_params,sgd_params]\n\n\nmodels=[\n    \n    RandomForestClassifier(random_state=0),\n    SVC(kernel='rbf',probability=True),\n    KNeighborsClassifier(),\n    LogisticRegression(max_iter=500000,solver='lbfgs'),\n    SGDClassifier(loss=\"modified_huber\")\n]","5021b942":"best_models=[]\nfor param,model in zip(params,models):\n    grid_search=GridSearchCV(model,param,cv=k_fold,scoring='accuracy',refit=True)\n    grid_search.fit(X,Y)\n    best_models.append(grid_search.best_estimator_)\n    print('Best model:\\t',grid_search.best_estimator_)\n    print('Best Score:\\t',round(grid_search.best_score_*100,2))\n    print(60*'-')\n    print('\\n')    ","58403c6a":"#!pip install -U tensorflow==2.7\n#!pip install -U scikeras","f9badcfb":"from sklearn.model_selection import train_test_split\n\nX_train,X_val,Y_train,Y_val=train_test_split(X,Y,test_size=0.15,random_state=1)\nprint('Train shape:\\t\\t',X_train.shape)\nprint('Validation shape:\\t',X_val.shape)","bad7a1ff":"import tensorflow as tf\nfrom tensorflow import keras\nprint(tf.__version__)\nprint(keras.__version__)","39797600":"early_stopping=keras.callbacks.EarlyStopping(monitor='val_binary_accuracy' ,patience=100,restore_best_weights=True)\ncheck_point=keras.callbacks.ModelCheckpoint('..\/input\/titanic\/Model_CheckPoint.h5',save_best_only=True)","67b29a0e":"from functools import partial\nfrom scikeras.wrappers import KerasClassifier\n\nMyDense=partial(keras.layers.Dense,activation='elu',\n                kernel_initializer='he_normal')\n\ndef build_model(n_hidden,n_neurons,penalty_rate,learning_rate):\n    reg=keras.regularizers.l2(penalty_rate)\n    model=keras.models.Sequential()\n    model.add(keras.layers.InputLayer(input_shape=X_train.shape[-1],))\n              \n    for _ in range(n_hidden):\n              model.add(MyDense(n_neurons,kernel_regularizer=reg))\n              \n    model.add(keras.layers.Dense(1,activation='sigmoid',kernel_initializer='glorot_uniform',kernel_regularizer=reg))\n    model.compile(loss=keras.losses.binary_crossentropy,\n             optimizer=keras.optimizers.SGD(learning_rate=learning_rate),\n             metrics=keras.metrics.binary_accuracy)\n    return model\n\ndnn_model=KerasClassifier(model=build_model,n_hidden=1,n_neurons=5,penalty_rate=0.001,learning_rate=0,\n                 callbacks=[early_stopping,check_point])","31b6f423":"X_train.shape","e80cc767":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import reciprocal\n\ndnn_params={\n    'n_hidden': np.arange(1,10),\n    'n_neurons': np.arange(1,70),\n    'learning_rate': reciprocal(3e-3,3e-2),\n    'penalty_rate': reciprocal(3e-5,3e-2),\n}\n\n\nrand_search=RandomizedSearchCV(dnn_model,dnn_params,cv=k_fold,scoring='accuracy',refit=True)\nrand_search.fit(X_train,Y_train,epochs=100,\n                 validation_data=(X_val,Y_val))","6713bba4":"print('Best model:\\t',rand_search.best_estimator_)\nprint('Best params:\\t',rand_search.best_params_)\nprint('Best Score:\\t',round(rand_search.best_score_*100,2))","91af0565":"model=keras.models.load_model('..\/input\/titanic\/model_CheckPoint.h5')\n\naccuracy_train=model.evaluate(X_train,Y_train)\nprint('Accuracy in training data:\\t %.2f %%' %(accuracy_train[-1]*100))\naccuracy_val=model.evaluate(X_val,Y_val)\nprint('Accuracy in validation data:\\t %.2f %%' %(accuracy_val[-1]*100))","fcdfadea":"X.shape","952829cd":"    model=rand_search.best_estimator_\n    scores=cross_val_score(model,X,Y,cv=k_fold,scoring='accuracy')\n    print('Model:\\t',model)\n    print('Mean score:\\t',round(np.mean(scores)*100, 2))\n    print(60*'-')\n    print('\\n')","c6c71d1a":"rand_search.best_estimator_","7f029dff":"model=keras.models.load_model('model_CheckPoint.h5')\nmodel.summary()","3434b604":"def evaluate(model,X_train,Y_train,X_val,Y_val):\n    \n    from sklearn.metrics import accuracy_score\n    print(model)\n    model.fit(X_train,Y_train)\n    pred_train=model.predict(X_train)\n    accuracy_train=accuracy_score(pred_train,Y_train)\n    print('Accuracy in training data:\\t %.2f %%' %(accuracy_train*100))\n    pred_val=model.predict(X_val)\n    accuracy_val=accuracy_score(pred_val,Y_val)\n    print('Accuracy in validation data:\\t %.2f %%' %(accuracy_val*100))\n    return model","72a9f86b":"best_models","84e47476":"dnn=KerasClassifier(model=keras.models.load_model('model_CheckPoint.h5'))","781f6b41":"#best_models.append(dnn)\nnames=[str(n).split('(')[0] for n in ((best_models[:6]))]\nestimators=list(zip(names,best_models))","9dd82cd4":"estimators","c96c4aff":"from sklearn.ensemble import VotingClassifier\n\nvoting_clf=VotingClassifier(estimators=estimators[:6],voting='soft')#,weights=weights)\nevaluate(voting_clf,X_train,Y_train,X_val,Y_val)\n#voting_clf.fit(X,Y)","9c61255d":"cross_val_score(voting_clf,X,Y,cv=k_fold,scoring='accuracy')","53f93498":"def submission(model,name):\n    preds=(model.predict(X_test)>0.5).astype('int64').reshape(X_test.shape[0],)#.reshape(-1,1)\n    preds_dict={\"PassengerId\":test_data[\"PassengerId\"].values,\n               \"Survived\":preds}\n    output = pd.DataFrame(preds_dict,index=test_data.index)\n    output.to_csv(name+'_submission.csv', index=False)\n    \nsubmission(voting_clf,'FeaturePrep')","105e0e05":"<h2><b>Sex:<\/b><\/h2>\n<ul>\n    <li> male : 0<\/li>\n    <li> female : 1<\/li>\n<\/ul>","33c665b0":"<h3><b>Mutual Information","cdd76b4c":"<h2><b>Hyperparameter tuning","6f08a2cc":"<h1> Projeto da Casa de IA - Competi\u00e7\u00e3o do Titanic\n    <p>","bc6aa9c3":"<h3><b>Deep Learning","d4017c0f":"<p>preenche os dados faltantes das idades ","fba2acb7":"<p> Foram escolhidas os seguintes par\u00e2metros para a constru\u00e7\u00e3o dos modelos iniciais:\n   <p> 'Pclass','Sex','Age','SibSp','Parch','Fare', 'Embarked'","6c305ae6":"<h3><b>Cabin","26c17035":"![image.png](attachment:image.png)","d479839b":"<h2><b>Feature Engeneering","a4e2a3b4":"<p>Separar o conjunto de dados em treino e valida\u00e7\u00e3o para avaliarmos os modelos.<p>\n<p>Treinar no conjunto de treinamento e avaliar no conjunto de valida\u00e7\u00e3o usando 'accuracy'<p>","1d437b9c":"<h3><b>Ensemble","8ef19d37":"<h3><b>Embarked","c82a222d":"<h2><b>Family Size","87f09712":"<h3><b>Age","5b99ee45":"Vemos que dependendo do pronome de tratamento utilizado as idades variam","a9023da5":"<h3><b>RandomForest","dd13c0e1":"Labels=['Crian\u00e7a(0-10)','Pr\u00e9Adolescente(10-15)','Adolescente(15-20)','JovemAdulto(20-30)','Adulto(30-40)','Adulto(40-50)','Adulto(50-60)','Idoso(60-90)']\nAge_cat=pd.cut(Dados_eng.Age,[0,10,15,20,30,40,50,60,90],labels=Labels)\nprint(Age_cat.value_counts())\nDados_eng['Age_cat']=Age_cat.astype('object')\n#encoder=OneHotEncoder()\n#Age_hot=encoder.fit_transform([Age_cat])\n#Dados_eng","bd38cea1":"<h2><b>Fare","8e6c9390":"<h1><b>Modelling","9a814954":"#best_models.append(rand_search.best_estimator_)\n\nfor model in best_models:\n    scores=cross_val_score(model,X,Y,cv=k_fold,scoring='accuracy')\n    print('Model:\\t',model)\n    print('Mean score:\\t',round(np.mean(scores)*100, 2))\n    print(60*'-')\n    print('\\n')","61a8de86":"<ul><b>Ideias para melhorar nosso c\u00f3digo:<\/b>\n    <li>Organizar os diferentes modelos e acur\u00e1cias em um DF para ser mais f\u00e1cil compar\u00e1-los<\/li>\n    <li>Categorizar as idades<\/li>\n    <li>Usar os pronomes de tratatamento <\/li>\n    <li>N\u00famero de pessoas por fam\u00edlia <\/li>\n    <li>Adicionar a cabine <\/li>\n    <li><\/li>\n    <\/ul>\n    \n     http:\/\/www.balmoralsoftware.com\/titanic\/titanic.htmsite>","b2569681":"<ul><b>Pronouns:<\/b>\n    <li> Mr : 0<\/li>\n    <li> Miss : 1<\/li>\n    <li> Mrs : 2<\/li>\n    <li> Master : 3<\/li>\n    <li> Others : 4<\/li>\n<\/ul>","439c0a5f":"<h3><b>Data Preparation for modeling","d9653f62":"https:\/\/www.encyclopedia-titanica.org\/titanic-victim\/andrew-emslie-johnston.html","8a800fe5":"<p> Refer\u00eancias:<\/p>\nhttps:\/\/github.com\/minsuk-heo\/kaggle-titanic\/blob\/master\/titanic-solution.ipynb","cb47d46f":"<p> substituir faltantes com S que representa mais de 50% dos dados em todas as classes"}}