{"cell_type":{"8af60b39":"code","5f88112c":"code","98199fc6":"code","bc28fa18":"code","595582f1":"code","9ca23ed3":"code","bc7732f1":"code","aaf67ea0":"code","60b9e05b":"code","7beadf34":"code","8e6ba856":"code","18932140":"code","fb13d87d":"code","7cd9502d":"code","746045f2":"code","6c53117f":"code","ffacd295":"code","e071c04d":"code","a3a0b3ed":"code","39cab8d7":"code","39737a0b":"code","91acebf5":"code","37607357":"code","59d5c7df":"code","a1aa297a":"code","85b14725":"code","637e395b":"markdown","19397c5f":"markdown","d0a9fb5b":"markdown"},"source":{"8af60b39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n #       print(os.path.join(dirname, filename))\n\n    \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f88112c":"import tensorflow as tf\nimport tensorflow_hub as hub","98199fc6":"labels_files = pd.read_csv('..\/input\/animal-images-dataset\/animal_data_img.csv')\nlabels_files","bc28fa18":"# Count of different animals\nlen(labels_files.Label.value_counts())","595582f1":"# Count of different animals types\nlen(labels_files.Animal_Type.value_counts())","9ca23ed3":"labels_files.drop(\"Label\", axis = 1, inplace = True)\nlabels_files","bc7732f1":"types = labels_files.Animal_Type.unique()\ntypes","aaf67ea0":"def preprocess_image(image_path, img_size = 224):\n  \"\"\"\n  Takes an image path and turns the image into a tensor\n  \"\"\"\n  # read the image \n  image = tf.io.read_file(image_path)\n  \n  # turn the jpg into a numerical Tensor with 3 color channels (RGB)\n  image = tf.image.decode_jpeg(image, channels = 3)\n\n  # Convert the color channel values from 0-255 to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n\n  # resize the image to our desired value: 224, 224\n  image = tf.image.resize(image, size = [img_size, img_size])\n\n  return image","60b9e05b":"def get_image_and_label(image_path, label):\n  \"\"\"\n  Takes an image filepath and the asociated label, preprocess the image and return a tuple of (image, label)\n  \"\"\"\n  image = preprocess_image(image_path)\n  return image, label","7beadf34":"\ndef create_databatches(X, y = None, batch_size = 32, valid_data = False, test_data = False):\n  \"\"\"\n  Create batches of data out of image (X) and label (y) pairs.\n  Shuffles the data if it's training data and doesn't shuffle it if it is validation data,\n  also accepts test data as input (no labels) \n  \"\"\"\n\n  # if the data is the test dataset, we dont have labels\n  if test_data:\n    print('Creating test data batches...')\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) #filepaths \n    data_batch = data.map(preprocess_image).batch(batch_size)\n    print('Done t!')\n    return data_batch\n  \n  # if the data is a valid dataset, we dont need to shuffle it \n  elif valid_data:\n    print('Creating validation data batches...')\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_and_label).batch(batch_size)\n    print('Done! v')\n    return data_batch\n  \n  else: \n    print('Creating training data batches...')\n    # turn filepaths and labels into tensors \n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n                                               tf.constant(y))) # labels\n    # shuffle pathnames and labels before maping image processing function is faster than shuffeling images \n    data = data.shuffle(buffer_size = len(X))\n\n    # create (image, labels) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_and_label)\n\n    # turn the training data into batches \n    data_batch = data.batch(batch_size)\n    print('Done! tr')\n    return data_batch ","8e6ba856":"bool_labels = [label == types for label in labels_files.Animal_Type]","18932140":"filepaths = ['..\/input\/animal-images-dataset\/animal_images\/' + path for path in labels_files.Image_File]","fb13d87d":"from sklearn.model_selection import train_test_split\n\nslice_sice = 100000\n\nX = filepaths[:slice_sice]\ny = bool_labels[:slice_sice]\n\n# split into training and validation \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 42)\n\nlen(X_train), len(X_test), len(y_train), len(y_test)","7cd9502d":"train_data = create_databatches(X_train, y_train)\nvalid_data = create_databatches(X_test, y_test, valid_data = True) ","746045f2":"early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 3)","6c53117f":"model_url = 'https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_130_224\/classification\/5'\ninput_shape = [None, 224, 224, 3] # [batch, height, width, color channels]\n\n# setup the output shape \noutput_shape = len(types)","ffacd295":"# setup the layers\nmodel = tf.keras.Sequential([\n  hub.KerasLayer(model_url), # layer 1\n  tf.keras.layers.Dense(units = output_shape, activation = 'softmax') # layer 2\n])\n\n# compile the model\nmodel.compile(\n  loss = tf.keras.losses.CategoricalCrossentropy(),\n  optimizer = tf.keras.optimizers.Adam(),\n  metrics = ['accuracy']\n)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 3)\n\n# Build the model\nmodel.build(input_shape)","e071c04d":"  model.fit(\n      x = train_data,\n      epochs = 100,\n      validation_data = valid_data,\n      validation_freq = 1,\n      callbacks = [early_stop]\n  )","a3a0b3ed":"def get_predicted_label(predictions_probabilities):\n  \"\"\"\n  Turns an array of predictions probabilities into a label\n  \"\"\"\n  return types[predictions_probabilities.argmax()]\n\ndef plot_prediction(prediction_probabilities, labels, images, n = 0, test_data = False):\n  \"\"\"\n  View the prediction, ground truth and image for a sample n\n  \"\"\"\n  if test_data: \n    labels = ['']\n  pred_prob, true_label, img = prediction_probabilities[n], labels[n], images[n]\n\n  # get the predicted label\n  pred_label = get_predicted_label(pred_prob)\n\n  # plot the image\n  plt.imshow(img)\n  plt.axis('off')\n  \n  # Change the color of the title depending on if the prediction is right or wrong  \n  \n  if pred_label == true_label:\n    color = 'green' \n  elif test_data:\n    color = 'black'\n  else:\n    color = 'red'\n\n\n  if not test_data:\n    # Change plot title to be: 'predicted label (predict_proba) true: true_label'\n    plt.title('{} {:2.0f}%, true: {}'.format(pred_label, np.max(pred_prob) * 100, true_label), color = color)\n  else: \n    plt.title('{} {:2.0f}%'.format(pred_label, np.max(pred_prob) * 100), color = color)","39cab8d7":"y_preds = model.predict(valid_data)","39737a0b":"true_test_labels = [get_predicted_label(l) for l in y_test]\ntest_images = [preprocess_image(img) for img in X_test]\n\nplot_prediction(y_preds, true_test_labels, test_images, n = 0, test_data = False)","91acebf5":"plot_prediction(y_preds, true_test_labels, test_images, n = 9, test_data = False)","37607357":"plot_prediction(y_preds, true_test_labels, test_images, n = 52, test_data = False)","59d5c7df":"predicted_classes = [pred.argmax() for pred in y_preds]\ntrue_classes = [true_label.argmax() for true_label in y_test]","a1aa297a":"from sklearn.metrics import classification_report\nprint(classification_report(true_classes, predicted_classes, target_names=types))","85b14725":"labels_files.Animal_Type.value_counts().plot(kind = 'bar')","637e395b":"### We have mostly images of Dogs, Birsd and fishes, so is expected to have a higer accuraccy on this classes","19397c5f":"## Animal type Classifier with Tensorflow and Tensorflow hub ","d0a9fb5b":"### Since there are 2483 different animals and just 7220 images, the model will classify animal types"}}