{"cell_type":{"27832ba7":"code","b60cb6d1":"code","09929bd4":"code","77b57023":"code","248a6163":"code","3c2cbea6":"code","3fabd080":"code","86456349":"markdown","269f5938":"markdown","a1cf28ac":"markdown","f527a47f":"markdown","adc7333d":"markdown","75cb9aae":"markdown","9fa5baf3":"markdown","752e7470":"markdown"},"source":{"27832ba7":"train_csv_path = '..\/input\/toy-dataset-for-regression-and-uq\/Data10_Train.csv'\ntest_csv_path = '..\/input\/toy-dataset-for-regression-and-uq\/Data10_Test.csv'\nval_csv_path = '..\/input\/toy-dataset-for-regression-and-uq\/Data10_Val.csv'\n\n\nimport pandas as pd\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport torch.utils.data as Data\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\nimport imageio\nimport math\n\n\ntrain_df = pd.read_csv(train_csv_path)\nval_df = pd.read_csv(val_csv_path)\ntrain_df.head()","b60cb6d1":"input_=[]\noutput_=[]\nfor row in train_df.iloc:\n    input_.append((row[0:len(row)-1]).astype(float))\n    output_.append(row[-1])\n    \ni_val=[]\no_val=[]\nfor row in val_df.iloc:\n    i_val.append((row[0:len(row)-1]).astype(float))\n    o_val.append(row[-1])\n    \nnum_input = len(row)-1;\nprint(num_input)\n\n\ntorch.manual_seed(1)    # reproducible\n\nx = torch.tensor(input_).float()  \ny = torch.tensor(output_).float()   \nnew_shape = (len(y), 1)\ny = y.view(new_shape)\n\n\ni_val = torch.tensor(i_val).float()  \no_val = torch.tensor(o_val).float()   \nnew_shape = (len(o_val), 1)\no_val = o_val.view(new_shape)\n\n\n\nmax_y = torch.max(y[:,0])\nmin_y =torch.min(y[:,0])\n\nmax_x = torch.max(x,dim=0)\nmin_x = torch.min(x,dim=0)\n\nprint(max_y, min_y, max_x.values, min_x.values)\n\nrange_y = max_y - min_y\nrange_x = max_x.values - min_x.values\n\nprint(range_x, range_y)\n\n    #Normalizing\nx = (x - min_x.values)\/range_x\ny = (y - min_y)\/range_y\n\n    #Normalizing\ni_val = (i_val - min_x.values)\/range_x\no_val = (o_val - min_y)\/range_y","09929bd4":"# torch can only train on Variable, so convert them to Variable\nx, y = Variable(x), Variable(y)\n\n# Make RVFL code Here\nnum_RVFL_HL = 1000\n# num_input by num_RVFL_HL sized weight matrix\nConst_Weight_RVFL = torch.rand((num_input,num_RVFL_HL))-.5\nprint(Const_Weight_RVFL.shape)\n# num_RVFL_HL by 1 sized hidden bias\nConst_bias_RVFL = torch.rand((1,num_RVFL_HL))-.5\n\nprint(x.shape)\nx2=F.relu(torch.matmul(x,Const_Weight_RVFL) + Const_bias_RVFL)\nprint(x2.shape)\nx_RVFL = torch.cat([x,x2],1)\nprint(x_RVFL.shape)\n\n\ni_val2 = F.relu(torch.matmul(i_val,Const_Weight_RVFL) + Const_bias_RVFL)\ni_val_RVFL = torch.cat([i_val,i_val2],1)\n\n\n#Connection to output layer\nNN_out = torch.nn.Linear(num_input+num_RVFL_HL, 1)\n\n\n# use the same net as before      \nnet = NN_out     # define the network\nprint(net)  # net architecture\noptimizer = torch.optim.Adam(net.parameters(), lr=0.05)\nloss_func = torch.nn.MSELoss()  # this is for regression mean squared loss","77b57023":"#initial values. These values will be replaced with smaller values\nminimum_train_loss = 1e5\nminimum_val_loss = 1e5\nEPOCH = 2000\n\n# start training\nfor epoch in range(EPOCH):\n  \n    prediction = net(x_RVFL)     # input x and predict based on x\n\n    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n\n    optimizer.zero_grad()   # clear gradients for next train\n    loss.backward()         # backpropagation, compute gradients\n    optimizer.step()        # apply gradients\n    \n    if loss<minimum_train_loss:\n        minimum_train_loss =loss\n        net_opt = net\n    \n    if epoch%200 == 199:\n      prediction = net_opt(i_val_RVFL)\n      loss_val = loss_func(prediction, o_val)\n      if loss_val<minimum_val_loss:\n        minimum_val_loss = loss_val\n        net_opt_val = net_opt\n      print (\"Epoch [{}\/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))","248a6163":"test_df = pd.read_csv(test_csv_path)\n\ni_test=[]\no_test=[]\nfor row in val_df.iloc:\n    i_test.append((row[0:len(row)-1]).astype(float))\n    o_test.append(row[-1])\n\n\n   \ni_test, o_test = Variable(torch.tensor(i_test)).float(), Variable(torch.tensor(o_test).float())\nnew_shape = (len(o_test), 1)\no_test = o_test.view(new_shape)\n\n    #Normalizing\ni_test = (i_test - min_x.values)\/range_x\no_test = (o_test - min_y)\/range_y\n\ni_test2 = F.relu(torch.matmul(i_test,Const_Weight_RVFL) + Const_bias_RVFL)\ni_test_RVFL = torch.cat([i_test,i_test2],1)\nprediction = net_opt_val(i_test_RVFL)\n\nloss_test = loss_func(prediction, o_test)\n\nprint(\"Normalized Test Loss\",loss_test.detach().numpy())\n\nloss_test = loss_test*range_y*range_y # As the loss function returns MSE\n\nprint(\"Test Loss\",loss_test.detach().numpy())","3c2cbea6":"standard_deviation = math.sqrt(minimum_val_loss)\nz_95 = 1.96*standard_deviation\nLB = prediction.detach().numpy() - z_95\nUB = prediction.detach().numpy() + z_95\no_test = o_test.detach().numpy()\n\n\n#Denormalization\ni_test = i_test*range_x + min_x.values\no_test = o_test*range_y.detach().numpy() + min_y.detach().numpy()\nLB = LB*range_y.detach().numpy() + min_y.detach().numpy()\nUB = UB*range_y.detach().numpy() + min_y.detach().numpy()\nprediction = prediction*range_y + min_y","3fabd080":"fig, (ax1) = plt.subplots(1, 1)\n\nax1.set(xlabel=\"Input (X1, Arbitrary Unit)\", ylabel=\"Target and Predictions (Arbitrary Unit)\" , ylim = (-1.5, 2), xlim = (-1,1))\nplt.rcParams[\"figure.figsize\"] = (6,5)\n\nax1.plot(i_test[:,0], prediction.detach().numpy(), color='r', linewidth=2, label='Point Prediction')\nax1.plot(i_test[:,0], LB, color='g', linewidth=2, label='Prediction Interval')\nax1.scatter(i_test[:,0], o_test, color='b',s=.5, label='Target')\nax1.plot(i_test[:,0], UB, linewidth=2, color='g')\n\nleg = ax1.legend(frameon=False, loc='lower left', bbox_to_anchor=(0.50,0.7));\n\nfig.show()\n\n\n\n\nPINAW = np.sum(UB-LB)\/len(UB)\/(np.max(o_test)-np.min(o_test)) \n# here PINAW= 2*z_95\n\n\nPINC = 0\nPINAFD =0\nfor iter1 in range(len(UB)):\n    if UB[iter1]>=o_test[iter1] and LB[iter1]<=o_test[iter1]:\n        PINC = PINC+1\n    else:\n        PINAFD = PINAFD + np.min([np.abs(UB[iter1]-o_test[iter1]), np.abs(LB[iter1]<o_test[iter1])]) \n        # PINAFD distance from the nearest interval\n\n\nif PINAFD>0:\n    PINAFD = PINAFD\/(len(UB) - PINC)\/(np.max(o_test)-np.min(o_test))         \n\nPINC = PINC\/len(UB)\n\nprint(\"PINAW:\",PINAW, \"  PINC:\", PINC, \"  PINAFD: \", PINAFD) ","86456349":"## Plotting","269f5938":"## Loading CSV files","a1cf28ac":"## Denormalization","f527a47f":"## Network on Test Data","adc7333d":"# Random Vector Functional Link (RVFL)\n\nThe dataset is also available at: https:\/\/github.com\/dipuk0506\/UQ-Data","75cb9aae":"## RVFL Network","9fa5baf3":"## Network Training","752e7470":"## Normalizing training and validation data"}}