{"cell_type":{"fe943de1":"code","f0f70325":"code","435534d7":"code","cd8f312f":"code","19bfb55a":"code","ec91666f":"code","7662f5b6":"code","261901a9":"code","ddbf145f":"code","ae8f589a":"code","4ab13533":"code","43cd0e6c":"code","670546c7":"code","3c3a4097":"code","e8cdf69d":"code","15420e0c":"code","174d23be":"code","3fb39c0f":"code","d5ee3205":"code","e1aa3ada":"code","c195a1b1":"code","24cafdc2":"code","d13d64bf":"code","2bf08aa1":"code","1a84e74b":"code","6c8cb9a4":"code","3f968988":"code","9fabcbdc":"code","09e4db31":"code","19c1f5a7":"code","c3b1ec72":"code","8da3f761":"code","ba57eee6":"code","4842175b":"code","a4d7fafd":"code","e14aaf0f":"code","05b37ff6":"code","fa9d35b1":"code","aca2e28a":"code","8d14be96":"code","f5454464":"code","ab3a7120":"code","394de669":"code","7450c956":"code","aaacfdb2":"code","495992aa":"markdown","5818616c":"markdown","952a8039":"markdown","f2e85cdc":"markdown","9ce22927":"markdown","675b82cc":"markdown","e652d8fd":"markdown","c5d4ce6e":"markdown","7342f6fa":"markdown","c78007cf":"markdown","bf08912f":"markdown","9c589866":"markdown","82018052":"markdown","b12e5d7f":"markdown","228be9bb":"markdown","de11d78c":"markdown","2f9933ba":"markdown","fd52e297":"markdown","c34d0788":"markdown","071e71fb":"markdown"},"source":{"fe943de1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0f70325":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\nopen_aq = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                   dataset_name=\"openaq\")\n\nprint(\"Setup Complete\")\n\n# print list of tables in this dataset (there's only one!)\nprint('Tables list: {}'.format(open_aq.list_tables()))\n\nopen_aq.table_schema('global_air_quality')\n","435534d7":"open_aq.head('global_air_quality')","cd8f312f":"def run_query(query , client):\n    if (client.estimate_query_size(query) >= 1):\n        return \"Query too big!\"\n    else:\n        return client.query_to_pandas_safe(query)\n\n","19bfb55a":"query = \"\"\"\n        SELECT COUNTRY , COUNT(1) AS TOTAL_ENTRIES\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        GROUP BY COUNTRY\n        ORDER BY TOTAL_ENTRIES DESC;\n\"\"\"\nrun_query(query,open_aq)","ec91666f":"query = \"\"\"\n        SELECT CITY, COUNT(1) AS TOTAL_ENTRIES\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'US'\n        GROUP BY CITY\n        ORDER BY TOTAL_ENTRIES DESC\n\"\"\"\nrun_query(query,open_aq)","7662f5b6":"query = \"\"\"\n        SELECT CITY, COUNT(1) AS TOTAL_ENTRIES\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE country = 'IN'\n        GROUP BY CITY\n        ORDER BY TOTAL_ENTRIES DESC\n\"\"\"\nrun_query(query,open_aq)","261901a9":"query = \"\"\"\n        SELECT CITY, COUNT(1) AS TOTAL_ENTRIES\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE CITY LIKE '%Delhi%'\n        GROUP BY CITY\n        ORDER BY TOTAL_ENTRIES DESC;\n\"\"\"\nrun_query(query,open_aq)","ddbf145f":"query = \"\"\"\n        SELECT CITY , MAX(EXTRACT(YEAR FROM TIMESTAMP)) AS LAST_RECORDED_YEAR , MIN(EXTRACT(YEAR FROM TIMESTAMP)) AS FIRST_RECORDED_YEAR\n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE CITY LIKE '%Delhi%'\n        GROUP BY CITY\n\"\"\"\nrun_query(query,open_aq)","ae8f589a":"query = \"\"\"\n        SELECT LOCATION , COUNT(1) AS TOTAL_ENTRIES \n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE CITY LIKE '%Delhi%'\n        GROUP BY LOCATION\n\n\"\"\"\nrun_query(query,open_aq)","4ab13533":"query = \"\"\"\n        SELECT DISTINCT LOCATION , LATITUDE , LONGITUDE \n        FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE CITY LIKE '%Delhi%'\n\"\"\"\naq_stations_delhi = run_query(query,open_aq)\naq_stations_delhi.head()","43cd0e6c":"import folium \nmap_delhi_stations = folium.Map(location= [28.7041,77.1025] , zoom_start = 10)\nlatlong = [(row['LATITUDE'],row['LONGITUDE'],row['LOCATION']) for _,row in aq_stations_delhi.iterrows()]\nfor coord in latlong:\n    folium.Marker( location=[ coord[0], coord[1] ],tooltip=coord[2], fill_color='red', radius=8 ).add_to( map_delhi_stations )\nmap_delhi_stations","670546c7":"query = \"\"\"\n        SELECT * FROM `bigquery-public-data.openaq.global_air_quality`\n        WHERE CITY LIKE '%Delhi%'\n        ORDER BY EXTRACT(YEAR FROM TIMESTAMP);\n        \"\"\"\ndelhi_data = run_query(query , open_aq)","3c3a4097":"delhi_data.head()","e8cdf69d":"for i in delhi_data.columns:\n    print(i,\":\",delhi_data[str(i)].isnull().sum())","15420e0c":"delhi_data.describe()","174d23be":"delhi_data[delhi_data['averaged_over_in_hours'].isnull()].index.to_list()","3fb39c0f":"delhi_data.iloc[12]","d5ee3205":"delhi_data[delhi_data['location'] == 'Anand Vihar']","e1aa3ada":"delhi_data['averaged_over_in_hours'] = delhi_data['averaged_over_in_hours'].replace(np.nan, delhi_data[delhi_data['location'] == 'Anand Vihar']['averaged_over_in_hours'].mean())","c195a1b1":"for i in delhi_data.columns:\n    print(i,\":\",delhi_data[str(i)].isnull().sum())","24cafdc2":"delhi_data[delhi_data['city'] == 'New Delhi']","d13d64bf":"delhi_data[delhi_data['location'] == 'Dwarka-Sector 8, Delhi - DPCC ']","2bf08aa1":"print(\"Number of Unique Values\")\ncols_to_drop = []\nfor i in delhi_data.columns:\n    if(len(delhi_data[str(i)].unique()) <= 2):\n        cols_to_drop.append(str(i))\n    print(i,\":\",len(delhi_data[str(i)].unique()))\n","1a84e74b":"cols_to_drop","6c8cb9a4":"delhi_data['averaged_over_in_hours'].value_counts()","3f968988":"delhi_data[delhi_data['averaged_over_in_hours'] == 1.00]","9fabcbdc":"delhi_data.drop(columns = cols_to_drop[:-1],axis = 1, inplace = True)","09e4db31":"delhi_data.drop(columns = ['latitude','longitude'] , inplace = True)\ndelhi_data.head()","19c1f5a7":"delhi_data['timestamp'].dtype","c3b1ec72":"year_2015 = delhi_data[delhi_data['timestamp'].dt.year == 2015].sort_values(by = 'timestamp')\nyear_2015.head()","8da3f761":"import seaborn as sns\nsns.set_theme(style='whitegrid')\nsns.lineplot(x = delhi_data['timestamp'].dt.year, y = delhi_data[delhi_data['pollutant'] == 'co']['value'])","ba57eee6":"sns.lineplot(x = delhi_data['timestamp'].dt.month, y = delhi_data[delhi_data['pollutant'] == 'co']['value'])","4842175b":"year_2018 = delhi_data[delhi_data['timestamp'].dt.year == 2018]\nco_values = year_2018[year_2018['pollutant'] == 'co']\nco_values","a4d7fafd":"sns.lineplot(x = delhi_data['timestamp'].dt.year, y = delhi_data[delhi_data['pollutant'] == 'no2']['value'])","e14aaf0f":"sns.lineplot(x = delhi_data['timestamp'].dt.month, y = delhi_data[delhi_data['pollutant'] == 'no2']['value'])","05b37ff6":"delhi_data['pollutant'].unique()","fa9d35b1":"sns.lineplot(x = delhi_data['timestamp'].dt.year, y = delhi_data[delhi_data['pollutant'] == 'o3']['value'])","aca2e28a":"sns.lineplot(x = delhi_data['timestamp'].dt.month, y = delhi_data[delhi_data['pollutant'] == 'o3']['value'])","8d14be96":"sns.lineplot(x = delhi_data['timestamp'].dt.year, y = delhi_data[delhi_data['pollutant'] == 'pm10']['value'])","f5454464":"sns.lineplot(x = delhi_data['timestamp'].dt.month, y = delhi_data[delhi_data['pollutant'] == 'pm10']['value'])","ab3a7120":"sns.lineplot(x = delhi_data['timestamp'].dt.year, y = delhi_data[delhi_data['pollutant'] == 'pm25']['value'])","394de669":"sns.lineplot(x = delhi_data['timestamp'].dt.month, y = delhi_data[delhi_data['pollutant'] == 'pm25']['value'])","7450c956":"sns.lineplot(x = delhi_data['timestamp'].dt.year, y = delhi_data[delhi_data['pollutant'] == 'so2']['value'])","aaacfdb2":"sns.lineplot(x = delhi_data['timestamp'].dt.month, y = delhi_data[delhi_data['pollutant'] == 'so2']['value'])","495992aa":"From the above cells , we can see that the location Dwarka-Sector 8, Delhi - DPCC is responsible for entering records as New Delhi. This station must be newly established or new to the record publication \/ collection list because it has never reported data prior to 2020.","5818616c":"From this we can see that we have a total record of 5 years. This is more than sufficient for our analysis.","952a8039":"# **Pollutants Trends and Analysis**","f2e85cdc":"We will not be dropping averaged over in hours for now. Seems this variable can contribute somehow.\n\nWe will also drop latitude and longitude as we already have the value saved for our reference should we need it.","9ce22927":"# pm10","675b82cc":"# Analysis Conclusion\n\n\nFrom the above analyis we can conclude the following\n* Carbon Monoxide \n    \n   **Year in which it peaked**: 2018\n    \n    **Months in which CO peaks (as per records for prev 5 yrs)**: Feb to April\n    \n* Nitrogen Dioxide \n\n     **Year in which it dropped** : 2018\n     \n     **Peak Months**: July - November\n     \n* Ozone Gas\n\n    **Peaked in Year** : 2016 - 2017\n    \n    **Peak Months** : January - March , June - November\n    \n* PM 10 \n    \n    **Peaked in Year** : 2015\n    \n    **Peak Months** : June - July\n    \n* PM 25\n\n    **Peaked in Years** : 2018\n    \n    **Peak Month** : February - April\n    \n* Sulphur Dioxide\n\n    **Peaked after 2018**\n    \n    \n","e652d8fd":"# so2 ","c5d4ce6e":"For the purpose of this project , we are focusing only on Delhi.","7342f6fa":"# CO","c78007cf":"# No2","bf08912f":"# pm25","9c589866":"New Delhi and Delhi are the same city hence we will need to change new delhi to delhi in the final dataset we obtain.","82018052":"# o3","b12e5d7f":"Is it just me or is that an outlier in the Dataset ?","228be9bb":"We can clearly see from this that the locations are scattered all over Delhi. Let's obtain a dataframe with all the coordinates of the given stations.","de11d78c":"Liked what I did here ? Do press the upvote button !\n\nHave some doubt or a suggestion ? Leave a comment and I'll get back to you ASAP.","2f9933ba":"Okay , we have fixed the missing value issue. Let's move ahead to check out the difference in records having city as Delhi and New Delhi","fd52e297":"We might add to this dataset in future. For now , let's plot all the stations on a map, shall we?","c34d0788":"Let's obtain the complete dataset now!","071e71fb":"We will replace this with a mean value for Anand Vihar"}}