{"cell_type":{"3a8ac284":"code","1f2a3689":"code","69c5486f":"code","36f8d295":"markdown","51dcd14a":"markdown"},"source":{"3a8ac284":"!pip install transformers\n!pip install sentencepiece","1f2a3689":"txt_path = \"\/kaggle\/input\/feedback-prize-2021\/train\/0000D23A521A.txt\"\n\nwith open(txt_path, \"rt\") as f:\n    txt = f.read()\n    \ntxt","69c5486f":"from transformers import PegasusForConditionalGeneration, AutoTokenizer\nimport torch\n\n# You can chose models from following list\n# https:\/\/huggingface.co\/models?sort=downloads&search=google%2Fpegasus\nmodel_name = 'google\/pegasus-cnn_dailymail'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\nbatch = tokenizer(txt, truncation=True, padding='longest', return_tensors=\"pt\").to(device)\ntranslated = model.generate(**batch)\ntgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n\ntgt_text","36f8d295":"![](https:\/\/ai2-s2-public.s3.amazonaws.com\/figures\/2017-08-08\/f4061bd225b3be5b3f5b18eb1a229ce991efefeb\/2-Figure1-1.png)","51dcd14a":"### Text summarization using PEGASUS\nIntroducing text summarization technique using PEGASUS which is powerful model for abstractive summarization. In PEGASUS, important sentences are removed\/masked from an input txt such as BERT and are generated together as one output sequence from the remaining sentences, similar to an extractive summary.\n\nArXiv: https:\/\/arxiv.org\/abs\/1912.08777"}}