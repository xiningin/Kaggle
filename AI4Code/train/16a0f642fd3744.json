{"cell_type":{"4ffa11d1":"code","b340cbd8":"code","b3a71553":"code","476adada":"code","e8bfb400":"code","7731154e":"code","c0013750":"code","c8e1abd1":"code","2c90ee26":"code","ed56200f":"code","166440f2":"code","77128b0e":"code","d4c15db3":"code","22528dc6":"code","363ced23":"code","730e9299":"code","391098f2":"code","d7956fec":"code","8f9c2b08":"code","44d33bea":"code","49e52abc":"code","a8192283":"code","bca25bd8":"code","b7122f37":"code","7496e95b":"code","521aa378":"code","ce07e44b":"code","04642f45":"code","1bfceee5":"code","0ec0cd48":"code","f4d115be":"code","1945cec7":"code","299c50cd":"code","53d56164":"code","1b8b9d90":"code","7ed97b14":"code","3a8721b9":"code","592d3f19":"code","68748e18":"markdown","4e6d5229":"markdown","9c8dccff":"markdown","46c307fd":"markdown","7abc11ca":"markdown","e1702d30":"markdown","13c900c8":"markdown","89d592fe":"markdown","4d3931fd":"markdown","abd3abe0":"markdown","cd09ed53":"markdown"},"source":{"4ffa11d1":"import os\nprint(os.listdir(\"..\/input\"))","b340cbd8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport gc\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport warnings\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\n\n# I don't like SettingWithCopyWarnings ...\nwarnings.simplefilter('error', SettingWithCopyWarning)\ngc.enable()\n%matplotlib inline","b3a71553":"train = pd.read_csv('..\/input\/train.csv', \n                    dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\ntest = pd.read_csv('..\/input\/test.csv', \n                   dtype={'date': str, 'fullVisitorId': str, 'sessionId':str}, nrows=None)\ntrain.shape, test.shape","476adada":"def get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['fullVisitorId'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['fullVisitorId'].isin(unique_vis[trn_vis])],\n                ids[df['fullVisitorId'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids","e8bfb400":"train['page_hit'] = train['totals.pageviews']\/(train['totals.hits']+1)\ntrain.loc[(train['page_hit'] > 0.35), 'is.page_hit'] = 1\ntrain.loc[(train['page_hit'] <= 0.35), 'is.page_hit'] = 0\ndel train['page_hit']\n\ntest['page_hit'] = test['totals.pageviews']\/(test['totals.hits']+1)\ntest.loc[(test['page_hit'] > 0.35), 'is.page_hit'] = 1\ntest.loc[(test['page_hit'] <= 0.35), 'is.page_hit'] = 0\ndel test['page_hit']","7731154e":"for df in [train, test]:\n    df['vis_date'] = pd.to_datetime(df['visitStartTime'], unit='s')\n    df['sess_date_dow'] = df['vis_date'].dt.dayofweek\n    df['sess_date_hours'] = df['vis_date'].dt.hour\n    df['sess_date_dom'] = df['vis_date'].dt.day\n    df.sort_values(['fullVisitorId', 'vis_date'], ascending=True, inplace=True)\n    df['next_session_1'] = (\n        df['vis_date'] - df[['fullVisitorId', 'vis_date']].groupby('fullVisitorId')['vis_date'].shift(1)\n    ).astype(np.int64) \/\/ 1e9 \/\/ 60 \/\/ 60\n    \n    df['next_session_2'] = (\n        df['vis_date'] - df[['fullVisitorId', 'vis_date']].groupby('fullVisitorId')['vis_date'].shift(-1)\n    ).astype(np.int64) \/\/ 1e9 \/\/ 60 \/\/ 60\n    \n    df['max_visits'] = df['fullVisitorId'].map(\n         df[['fullVisitorId', 'visitNumber']].groupby('fullVisitorId')['visitNumber'].max()\n     )\n    \n    df['nb_pageviews'] = df['date'].map(\n        df[['date', 'totals.pageviews']].groupby('date')['totals.pageviews'].sum()\n    )\n    \n    df['ratio_pageviews'] = df['totals.pageviews'] \/ df['nb_pageviews']","c0013750":"excluded_features = [\n    'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', \n    'visitId', 'visitStartTime'\n]\n\ncategorical_features = [\n    _f for _f in train.columns\n    if (_f not in excluded_features) & (train[_f].dtype == 'object')\n]","c8e1abd1":"from sklearn.model_selection import KFold\n\ndef mean_k_fold_encoding(col, alpha):\n    target_name = 'totals.transactionRevenue'\n    target_mean_global = train[target_name].mean()\n    \n    nrows_cat = train.groupby(col)[target_name].count()\n    target_means_cats = train.groupby(col)[target_name].mean()\n    target_means_cats_adj = (target_means_cats*nrows_cat + \n                             target_mean_global*alpha)\/(nrows_cat+alpha)\n    # Mapping means to test data\n    encoded_col_test = test[col].map(target_means_cats_adj)\n    #\uc784\uc758\ub85c \ucd94\uac00 \ud55c \ubd80\ubd84\n    encoded_col_test.fillna(target_mean_global, inplace=True)\n    encoded_col_test.sort_index(inplace=True)\n\n    kfold = KFold(n_splits=5, shuffle=True, random_state=1989)\n    parts = []\n    for trn_inx, val_idx in kfold.split(train):\n        df_for_estimation, df_estimated = train.iloc[trn_inx], train.iloc[val_idx]\n        nrows_cat = df_for_estimation.groupby(col)[target_name].count()\n        target_means_cats = df_for_estimation.groupby(col)[target_name].mean()\n\n        target_means_cats_adj = (target_means_cats * nrows_cat + \n                                target_mean_global * alpha) \/ (nrows_cat + alpha)\n\n        encoded_col_train_part = df_estimated[col].map(target_means_cats_adj)\n        parts.append(encoded_col_train_part)\n        \n    encoded_col_train = pd.concat(parts, axis=0)\n    encoded_col_train.fillna(target_mean_global, inplace=True)\n    encoded_col_train.sort_index(inplace=True)\n    \n    return encoded_col_train, encoded_col_test","2c90ee26":"train['totals.transactionRevenue'] = train['totals.transactionRevenue'].fillna(0)\n\nfor col in categorical_features:\n    temp_encoded_tr, temp_encoded_te = mean_k_fold_encoding(col, 5)\n    new_feat_name = 'mean_k_fold_{}'.format(col)\n    train[new_feat_name] = temp_encoded_tr.values\n    test[new_feat_name] = temp_encoded_te.values\ngc.collect()","ed56200f":"def frequency_encoding(frame, col):\n    freq_encoding = frame.groupby([col]).size()\/frame.shape[0] \n    freq_encoding = freq_encoding.reset_index().rename(columns={0:'{}_Frequency'.format(col)})\n    return frame.merge(freq_encoding, on=col, how='left')\n\nlen_train = train.shape[0]\ndf_all = pd.concat([train, test])\n\nfor col in categorical_features:\n    df_all = frequency_encoding(df_all, col)","166440f2":"del df_all['geoNetwork.subContinent_Frequency']\ndel df_all['geoNetwork.country_Frequency']\ndel df_all['geoNetwork.region_Frequency']; del df_all['geoNetwork.city_Frequency']\ndel df_all['device.deviceCategory_Frequency']; del df_all['geoNetwork.continent_Frequency']\ndel df_all['trafficSource.adContent_Frequency']; \n\ndf_all['sub_net_mm'] = df_all['mean_k_fold_geoNetwork.subContinent'] * df_all['mean_k_fold_geoNetwork.networkDomain']\ndf_all['region_city_metro_mmm'] = - (df_all['mean_k_fold_geoNetwork.region'] \/ df_all['mean_k_fold_geoNetwork.city'] * df_all['mean_k_fold_geoNetwork.metro'])\ndf_all['metro_source_mm'] = df_all['mean_k_fold_geoNetwork.metro'] * df_all['mean_k_fold_trafficSource.source']\ndf_all['channel_device_mm'] = df_all['mean_k_fold_channelGrouping'] * df_all['mean_k_fold_device.deviceCategory']\n\ndel df_all['mean_k_fold_geoNetwork.subContinent']; del df_all['mean_k_fold_geoNetwork.networkDomain'];\ndel df_all['mean_k_fold_geoNetwork.region']; del df_all['mean_k_fold_geoNetwork.city']; del df_all['mean_k_fold_geoNetwork.metro']\ndel df_all['mean_k_fold_trafficSource.source']; del df_all['mean_k_fold_channelGrouping']; del df_all['mean_k_fold_device.deviceCategory']","77128b0e":"# https:\/\/www.kaggle.com\/prashantkikani\/teach-lightgbm-to-sum-predictions-fe\ndef browser_mapping(x):\n    browsers = ['chrome','safari','firefox','internet explorer','edge','opera','coc coc','maxthon','iron']\n    if x in browsers:\n        return x.lower()\n    elif  ('android' in x) or ('samsung' in x) or ('mini' in x) or ('iphone' in x) or ('in-app' in x) or ('playstation' in x):\n        return 'mobile browser'\n    elif  ('mozilla' in x) or ('chrome' in x) or ('blackberry' in x) or ('nokia' in x) or ('browser' in x) or ('amazon' in x):\n        return 'mobile browser'\n    elif  ('lunascape' in x) or ('netscape' in x) or ('blackberry' in x) or ('konqueror' in x) or ('puffin' in x) or ('amazon' in x):\n        return 'mobile browser'\n    elif '(not set)' in x:\n        return x\n    else:\n        return 'others'\n    \n    \ndef adcontents_mapping(x):\n    if  ('google' in x):\n        return 'google'\n    elif  ('placement' in x) | ('placememnt' in x):\n        return 'placement'\n    elif '(not set)' in x or 'nan' in x:\n        return x\n    elif 'ad' in x:\n        return 'ad'\n    else:\n        return 'others'\n    \ndef source_mapping(x):\n    if  ('google' in x):\n        return 'google'\n    elif  ('youtube' in x):\n        return 'youtube'\n    elif '(not set)' in x or 'nan' in x:\n        return x\n    elif 'yahoo' in x:\n        return 'yahoo'\n    elif 'facebook' in x:\n        return 'facebook'\n    elif 'reddit' in x:\n        return 'reddit'\n    elif 'bing' in x:\n        return 'bing'\n    elif 'quora' in x:\n        return 'quora'\n    elif 'outlook' in x:\n        return 'outlook'\n    elif 'linkedin' in x:\n        return 'linkedin'\n    elif 'pinterest' in x:\n        return 'pinterest'\n    elif 'ask' in x:\n        return 'ask'\n    elif 'siliconvalley' in x:\n        return 'siliconvalley'\n    elif 'lunametrics' in x:\n        return 'lunametrics'\n    elif 'amazon' in x:\n        return 'amazon'\n    elif 'mysearch' in x:\n        return 'mysearch'\n    elif 'qiita' in x:\n        return 'qiita'\n    elif 'messenger' in x:\n        return 'messenger'\n    elif 'twitter' in x:\n        return 'twitter'\n    elif 't.co' in x:\n        return 't.co'\n    elif 'vk.com' in x:\n        return 'vk.com'\n    elif 'search' in x:\n        return 'search'\n    elif 'edu' in x:\n        return 'edu'\n    elif 'mail' in x:\n        return 'mail'\n    elif 'ad' in x:\n        return 'ad'\n    elif 'golang' in x:\n        return 'golang'\n    elif 'direct' in x:\n        return 'direct'\n    elif 'dealspotr' in x:\n        return 'dealspotr'\n    elif 'sashihara' in x:\n        return 'sashihara'\n    elif 'phandroid' in x:\n        return 'phandroid'\n    elif 'baidu' in x:\n        return 'baidu'\n    elif 'mdn' in x:\n        return 'mdn'\n    elif 'duckduckgo' in x:\n        return 'duckduckgo'\n    elif 'seroundtable' in x:\n        return 'seroundtable'\n    elif 'metrics' in x:\n        return 'metrics'\n    elif 'sogou' in x:\n        return 'sogou'\n    elif 'businessinsider' in x:\n        return 'businessinsider'\n    elif 'github' in x:\n        return 'github'\n    elif 'gophergala' in x:\n        return 'gophergala'\n    elif 'yandex' in x:\n        return 'yandex'\n    elif 'msn' in x:\n        return 'msn'\n    elif 'dfa' in x:\n        return 'dfa'\n    elif '(not set)' in x:\n        return '(not set)'\n    elif 'feedly' in x:\n        return 'feedly'\n    elif 'arstechnica' in x:\n        return 'arstechnica'\n    elif 'squishable' in x:\n        return 'squishable'\n    elif 'flipboard' in x:\n        return 'flipboard'\n    elif 't-online.de' in x:\n        return 't-online.de'\n    elif 'sm.cn' in x:\n        return 'sm.cn'\n    elif 'wow' in x:\n        return 'wow'\n    elif 'baidu' in x:\n        return 'baidu'\n    elif 'partners' in x:\n        return 'partners'\n    else:\n        return 'others'\n\ndf_all['device.browser'] = df_all['device.browser'].map(lambda x:browser_mapping(str(x).lower())).astype('str')\ndf_all['trafficSource.adContent'] = df_all['trafficSource.adContent'].map(lambda x:adcontents_mapping(str(x).lower())).astype('str')\ndf_all['trafficSource.source'] = df_all['trafficSource.source'].map(lambda x:source_mapping(str(x).lower())).astype('str')\n\ndef process_device(data_df):\n    print(\"process device ...\")\n    data_df['source.country'] = data_df['trafficSource.source'] + '_' + data_df['geoNetwork.country']\n    data_df['campaign.medium'] = data_df['trafficSource.campaign'] + '_' + data_df['trafficSource.medium']\n    data_df['browser.category'] = data_df['device.browser'] + '_' + data_df['device.deviceCategory']\n    data_df['browser.os'] = data_df['device.browser'] + \"_\" + data_df['device.operatingSystem']\n    return data_df\n\ndf_all = process_device(df_all)\n\ndef custom(data):\n    print('custom..')\n    data['device_deviceCategory_channelGrouping'] = data['device.deviceCategory'] + \"_\" + data['channelGrouping']\n    data['channelGrouping_browser'] = data['device.browser'] + \"_\" + data['channelGrouping']\n    data['channelGrouping_OS'] = data['device.operatingSystem'] + \"_\" + data['channelGrouping']\n    data['contry_sess_date_hours'] = data['geoNetwork.country'] + \"_\" +data['sess_date_hours'].astype(str)\n    data['contry_sess_date_dom'] = data['geoNetwork.country'] + \"_\" +data['sess_date_dom'].astype(str)\n    \n    for i in ['geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country','geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region','geoNetwork.subContinent']:\n        for j in ['device.browser','device.deviceCategory', 'device.operatingSystem', 'trafficSource.source']:\n            data[i + \"_\" + j] = data[i] + \"_\" + data[j]\n    \n    data['content.source'] = data['trafficSource.adContent'] + \"_\" + data['source.country']\n    data['medium.source'] = data['trafficSource.medium'] + \"_\" + data['source.country']\n    return data\n\ndf_all = custom(df_all)","d4c15db3":"df_all = df_all.drop(categorical_features, axis=1, inplace=False)","22528dc6":"excluded_features = [\n    'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', \n    'visitId', 'visitStartTime', 'vis_date', 'nb_sessions'\n]\n\ncat_cols = [\n    _f for _f in df_all.columns\n    if (_f not in excluded_features) & (df_all[_f].dtype == 'object')\n]","363ced23":"for f in cat_cols:\n    df_all[f], indexer = pd.factorize(df_all[f])\n    \ndel cat_cols\ngc.collect();","730e9299":"train = df_all[:len_train]\ntest = df_all[len_train:]\ndel df_all","391098f2":"gc.collect()","d7956fec":"y_reg = train['totals.transactionRevenue'].fillna(0)\ndel train['totals.transactionRevenue']\n\nif 'totals.transactionRevenue' in test.columns:\n    del test['totals.transactionRevenue']","8f9c2b08":"excluded_features = [\n    'date', 'fullVisitorId', 'sessionId', 'totals.transactionRevenue', \n    'visitId', 'visitStartTime', 'vis_date', 'nb_sessions',\n    'geoNetwork.subContinent','trafficSource.campaign','device.browser',\n    'totals.bounces','contry_sess_date_hours','contry_sess_date_dom',\n    'trafficSource.keyword'\n]\n\ncategorical_features = [\n    _f for _f in train.columns\n    if (_f not in excluded_features) & (train[_f].dtype == 'object')\n]","44d33bea":"y_clf = (y_reg > 0).astype(np.uint8)","49e52abc":"from sklearn.metrics import mean_squared_error, roc_auc_score, log_loss\n\nfolds = GroupKFold(n_splits=5)\n\ntrain_features = [_f for _f in train.columns if _f not in excluded_features]\noof_clf_preds = np.zeros(train.shape[0])\nsub_clf_preds = np.zeros(test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds.split(y_clf, y_clf, groups=train['fullVisitorId'])):\n    trn_x, trn_y = train[train_features].iloc[trn_], y_clf.iloc[trn_]\n    val_x, val_y = train[train_features].iloc[val_], y_clf.iloc[val_]\n    \n    clf = lgb.LGBMClassifier(\n        num_leaves=31,\n        learning_rate=0.03,\n        n_estimators=1000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    clf.fit(\n        trn_x, trn_y,\n        eval_set=[(val_x, val_y)],\n        early_stopping_rounds=50,\n        verbose=50\n    )\n    \n    oof_clf_preds[val_] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n    print(roc_auc_score(val_y, oof_clf_preds[val_]))\n    sub_clf_preds += clf.predict_proba(test[train_features], num_iteration=clf.best_iteration_)[:, 1] \/ folds.n_splits\n    \nroc_auc_score(y_clf, oof_clf_preds)","a8192283":"train['non_zero_proba'] = oof_clf_preds\ntest['non_zero_proba'] = sub_clf_preds","bca25bd8":"gc.collect()","b7122f37":"from sklearn.model_selection import StratifiedKFold, KFold\nimport lightgbm as lgb\n\ny_categorized = pd.cut(y_reg, bins=range(0,25,3), include_lowest=True,right=False, labels=range(0,24,3)) \n\n#folds = get_folds(df=df_train, n_splits=5)\nFOLDs = KFold(n_splits=5, shuffle=True, random_state=7)\ntrain_features = [_f for _f in train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(train.shape[0])\nsub_reg_preds = np.zeros(test.shape[0])\nfor fold_, (trn_, val_) in enumerate(FOLDs.split(train, y_categorized)):\n    trn_x, trn_y = train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.03,\n        n_estimators=1000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ FOLDs.n_splits #len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","7496e95b":"import warnings\nwarnings.simplefilter('ignore', FutureWarning)\n\nimportances['gain_log'] = np.log1p(importances['gain'])\nmean_gain = importances[['gain', 'feature']].groupby('feature').mean()\nimportances['mean_gain'] = importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 12))\nsns.barplot(x='gain_log', y='feature', data=importances.sort_values('mean_gain', ascending=False))","521aa378":"gc.collect()","ce07e44b":"train['predictions'] = np.expm1(oof_reg_preds)\ntest['predictions'] = sub_reg_preds","04642f45":"# Aggregate data at User level\ntrn_data = train[train_features + ['fullVisitorId']].groupby('fullVisitorId').mean()","1bfceee5":"%%time\n# Create a list of predictions for each Visitor\ntrn_pred_list = train[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n    .apply(lambda df: list(df.predictions))\\\n    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})","0ec0cd48":"# Create a DataFrame with VisitorId as index\n# trn_pred_list contains dict \n# so creating a dataframe from it will expand dict values into columns\ntrn_all_predictions = pd.DataFrame(list(trn_pred_list.values), index=trn_data.index)\ntrn_feats = trn_all_predictions.columns\ntrn_all_predictions['t_mean'] = np.log1p(trn_all_predictions[trn_feats].mean(axis=1))\ntrn_all_predictions['t_median'] = np.log1p(trn_all_predictions[trn_feats].median(axis=1))\ntrn_all_predictions['t_sum_log'] = np.log1p(trn_all_predictions[trn_feats]).sum(axis=1)\ntrn_all_predictions['t_sum_act'] = np.log1p(trn_all_predictions[trn_feats].fillna(0).sum(axis=1))\ntrn_all_predictions['t_nb_sess'] = trn_all_predictions[trn_feats].isnull().sum(axis=1)\nfull_data = pd.concat([trn_data, trn_all_predictions], axis=1)\ndel trn_data, trn_all_predictions\ngc.collect()\nfull_data.shape","f4d115be":"%%time\nsub_pred_list = test[['fullVisitorId', 'predictions']].groupby('fullVisitorId')\\\n    .apply(lambda df: list(df.predictions))\\\n    .apply(lambda x: {'pred_'+str(i): pred for i, pred in enumerate(x)})","1945cec7":"sub_data = test[train_features + ['fullVisitorId']].groupby('fullVisitorId').mean()\nsub_all_predictions = pd.DataFrame(list(sub_pred_list.values), index=sub_data.index)\nfor f in trn_feats:\n    if f not in sub_all_predictions.columns:\n        sub_all_predictions[f] = np.nan\nsub_all_predictions['t_mean'] = np.log1p(sub_all_predictions[trn_feats].mean(axis=1))\nsub_all_predictions['t_median'] = np.log1p(sub_all_predictions[trn_feats].median(axis=1))\nsub_all_predictions['t_sum_log'] = np.log1p(sub_all_predictions[trn_feats]).sum(axis=1)\nsub_all_predictions['t_sum_act'] = np.log1p(sub_all_predictions[trn_feats].fillna(0).sum(axis=1))\nsub_all_predictions['t_nb_sess'] = sub_all_predictions[trn_feats].isnull().sum(axis=1)\nsub_full_data = pd.concat([sub_data, sub_all_predictions], axis=1)\ndel sub_data, sub_all_predictions\ngc.collect()\nsub_full_data.shape","299c50cd":"train['target'] = y_reg\ntrn_user_target = train[['fullVisitorId', 'target']].groupby('fullVisitorId').sum()","53d56164":"del train; del test;\ngc.collect()","1b8b9d90":"xgb_params = {\n        'objective': 'reg:linear',\n        'booster': 'gbtree',\n        'learning_rate': 0.02,\n        'max_depth': 22,\n        'min_child_weight': 57,\n        'gamma' : 1.45,\n        'alpha': 0.0,\n        'lambda': 0.0,\n        'subsample': 0.67,\n        'colsample_bytree': 0.054,\n        'colsample_bylevel': 0.50,\n        'n_jobs': -1,\n        'random_state': 456\n    }","7ed97b14":"from xgboost import XGBRegressor\nfolds = get_folds(df=full_data[['totals.pageviews']].reset_index(), n_splits=5)\n\noof_preds = np.zeros(full_data.shape[0])\noof_preds1 = np.zeros(full_data.shape[0])\nboth_oof = np.zeros(full_data.shape[0])\nsub_preds = np.zeros(sub_full_data.shape[0])\nvis_importances = pd.DataFrame()\n\nfor fold_, (trn_, val_) in enumerate(folds):\n    print(\"-\"* 20 + \"Fold :\"+str(fold_) + \"-\"* 20)\n    trn_x, trn_y = full_data.iloc[trn_], trn_user_target['target'].iloc[trn_]\n    val_x, val_y = full_data.iloc[val_], trn_user_target['target'].iloc[val_]\n    xg = XGBRegressor(**xgb_params, n_estimators=1000)\n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.03,\n        n_estimators=1000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    print(\"-\"* 20 + \"LightGBM Training\" + \"-\"* 20)\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(trn_x, np.log1p(trn_y)), (val_x, np.log1p(val_y))],\n        eval_names=['TRAIN', 'VALID'],\n        early_stopping_rounds=50,\n        eval_metric='rmse',\n        verbose=100\n    )\n    print(\"-\"* 20 + \"Xgboost Training\" + \"-\"* 20)\n    xg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(trn_x, np.log1p(trn_y)), (val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        eval_metric='rmse',\n        verbose=100\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = trn_x.columns\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n\n    imp_df['fold'] = fold_ + 1\n    vis_importances = pd.concat([vis_importances, imp_df], axis=0, sort=False)\n\n    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_preds1[val_] = xg.predict(val_x)\n\n    oof_preds[oof_preds < 0] = 0\n    oof_preds1[oof_preds1 < 0] = 0\n\n    both_oof[val_] = oof_preds[val_] * 0.6 + oof_preds1[val_] * 0.4\n\n    # Make sure features are in the same order\n    _preds = reg.predict(sub_full_data[full_data.columns], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n\n    pre = xg.predict(sub_full_data[full_data.columns])\n    pre[pre<0]=0\n\n    sub_preds += (_preds \/ len(folds)) * 0.6 + (pre \/ len(folds)) * 0.4\n    gc.collect()\nprint(\"LGB  \", mean_squared_error(np.log1p(trn_user_target['target']), oof_preds) ** .5)\nprint(\"XGB  \", mean_squared_error(np.log1p(trn_user_target['target']), oof_preds1) ** .5)\nprint(\"Combine  \", mean_squared_error(np.log1p(trn_user_target['target']), both_oof) ** .5)","3a8721b9":"vis_importances['gain_log'] = np.log1p(vis_importances['gain'])\nmean_gain = vis_importances[['gain', 'feature']].groupby('feature').mean()\nvis_importances['mean_gain'] = vis_importances['feature'].map(mean_gain['gain'])\n\nplt.figure(figsize=(8, 25))\nsns.barplot(x='gain_log', y='feature', data=vis_importances.sort_values('mean_gain', ascending=False).iloc[:300])","592d3f19":"sub_full_data['PredictedLogRevenue'] = sub_preds\nsub_full_data[['PredictedLogRevenue']].to_csv('xgboost_lightgbm.csv', index=True)","68748e18":"### Feature Engineering #3","4e6d5229":"### Frequency Encoding","9c8dccff":"### Save Predictions","46c307fd":"### Mean encoding","7abc11ca":"### Modeling #3 : Create user level predictions","e1702d30":"### Modeling #1 : Classify noe-zero Revenues","13c900c8":"### Define folding strategy","89d592fe":"### Label Encoding","4d3931fd":"### Feature engineering : page_hit","abd3abe0":"### Modeling #2 : Predict revenues at session level","cd09ed53":"### Feature Engineering : Session and time features"}}