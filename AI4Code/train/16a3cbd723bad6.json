{"cell_type":{"7e8f871b":"code","549ad8cf":"code","628be154":"code","5e32ca08":"code","319f4063":"code","f275cf34":"code","351dd8f2":"code","639345ae":"code","a45b8932":"code","49e68686":"code","3b7ad36c":"code","2516e730":"code","fdbd9a52":"code","b5fb8ee1":"code","7899efc4":"code","05a9f4f9":"code","f36d0a9b":"code","b9731033":"code","2dfaa162":"code","349b2b42":"code","7b941600":"code","9647b020":"code","9c1e04f6":"code","8eaca41f":"code","019a51d6":"code","67714f56":"code","09a96566":"code","74d63728":"code","1bbe4223":"code","7ef79b7f":"code","e725dd94":"code","9914fba9":"code","9ce7a1c6":"code","db50da2c":"code","7ddc1074":"code","4f8c9298":"code","a08027f3":"code","6ee5f056":"code","d3f25238":"code","9e63095b":"code","cc21e0cf":"code","2d3e22f2":"code","cc465c2e":"code","29587af8":"code","92c57f1c":"code","5eb1264f":"code","250b7049":"code","834daeb0":"code","e0b4b7ea":"code","4f8abf14":"code","3fc0e8d9":"code","42b857f5":"code","19c259cd":"code","088f9f61":"code","647a0dbb":"code","765517d5":"code","2c64dcb6":"code","2fd6925c":"code","e85ee0b5":"code","bbbd0f12":"code","adfa13c6":"code","9f11e835":"markdown","07b60610":"markdown","1f1e79d9":"markdown","aa72d5e3":"markdown","d933ec4b":"markdown","5523cfb8":"markdown","43a2ffdf":"markdown","27dc0cbc":"markdown","6d1dca43":"markdown","dfb5519d":"markdown","7416b899":"markdown","e8dbaff6":"markdown","723db1b6":"markdown","254b9326":"markdown","097251f0":"markdown","ffef8a48":"markdown","e5060cb8":"markdown","686077fb":"markdown","67de92f8":"markdown","ffe455ba":"markdown","e5e57057":"markdown","9b3d3be6":"markdown","1fb1aebf":"markdown","46082648":"markdown","499bde67":"markdown","1ddb3f1c":"markdown","d06928f3":"markdown","ca37c70d":"markdown","fb289f59":"markdown","093c93be":"markdown","c723723e":"markdown","fa5d8af6":"markdown","74398597":"markdown","c6ba958e":"markdown","2e76b2d0":"markdown","ee32f339":"markdown","b3d48c3d":"markdown","5984dc38":"markdown","6afc29a1":"markdown","592a0082":"markdown","5358d806":"markdown","02a4b203":"markdown","e3df9143":"markdown"},"source":{"7e8f871b":"# Data Processing\nimport pandas as pd\n\n# Data Scraping\nimport requests\nfrom bs4 import BeautifulSoup","549ad8cf":"# Define the URL of the site\nbase_site = \"https:\/\/editorial.rottentomatoes.com\/guide\/140-essential-action-movies-to-watch-now\/2\/\"","628be154":"# sending a request to the webpage\nresponse = requests.get(base_site)\nresponse.status_code","5e32ca08":"# get the HTML from the webpage\nhtml = response.content","319f4063":"# convert the HTML to a Beautiful Soup object\nsoup = BeautifulSoup(html, 'html.parser')\n\n# Exporting the HTML to a file\nwith open('Rotten_tomatoes_page_2_HTML_Parser.html', 'wb') as file:\n    file.write(soup.prettify('utf-8'))","f275cf34":"# convert the HTML to a BeatifulSoup object\nsoup = BeautifulSoup(html, 'lxml')\n\n# Exporting the HTML to a file\nwith open('Rotten_tomatoes_page_2_LXML_Parser.html', 'wb') as file:\n    file.write(soup.prettify('utf-8'))","351dd8f2":"# Find all div tags on the webpage containing the information we want to scrape\ndivs = soup.find_all(\"div\", {\"class\": \"col-sm-18 col-full-xs countdown-item-content\"})\ndivs[:2]","639345ae":"# for instance, let's explore the first div\ndivs[0].find(\"h2\")","a45b8932":"# Extracting all 'h2' tags\nheadings = [div.find(\"h2\") for div in divs]\nheadings[:5]","49e68686":"# Inspecting the text inside the headings\n[heading.text for heading in headings][:5]","3b7ad36c":"headings[0]","2516e730":"# Let's check all heading links\n[heading.find('a') for heading in headings][:5]","fdbd9a52":"# Obtaining the movie titles from the links\nmovie_names = [heading.find('a').string for heading in headings]\nmovie_names[:5]","b5fb8ee1":"# Filtering only the spans containing the year\n[heading.find(\"span\", class_ = 'start-year') for heading in headings] [:5]","7899efc4":"# Extracting the year string\nyears = [heading.find(\"span\", class_ = 'start-year').string for heading in headings]\nyears [:5]","05a9f4f9":"years[0]","f36d0a9b":"years[0][1:-1]","b9731033":"# Removing '('\nprint(years[0].strip('('))\n\n# Removing ')'\nprint(years[0].strip(')'))\n\n# Combining both\nprint(years[0].strip('()'))","2dfaa162":"# Updating years with stripped values\nyears = [year.strip('()') for year in years]\nyears [:5]","349b2b42":"# Converting all the strings to integers\nyears = [int(year) for year in years]\nyears [:5]","7b941600":"# Filtering only the spans containing the score\n[heading.find(\"span\", class_ = 'tMeterScore') for heading in headings] [:5]","9647b020":"# Extracting the score string\nscores = [heading.find(\"span\", class_ = 'tMeterScore').string for heading in headings]\nscores [:5]","9c1e04f6":"# Removing the '%' sign\nscores = [s.strip('%') for s in scores]\nscores [:5]","8eaca41f":"# Converting each score to an integer\nscores = [int(s) for s in scores]\nscores [:5]","019a51d6":"# The critics consensus is located inside a 'div' tag with the class 'info critics-consensus'\n# This can be found inside the original 'div's we scraped\ndivs [:1]","67714f56":"# Getting the 'div' tags containing the critics consensus\nconsensus = [div.find(\"div\", {\"class\": \"info critics-consensus\"}) for div in divs]\nconsensus [:5]","09a96566":"# Inspecting the text inside these tags\n[con.text for con in consensus] [:5]","74d63728":"# The simplest (but not necessarily the best) way of achieving it is by taking the substring after the common phrase\n\n# Defining the phrase to be removed (note the space at the end)\ncommon_phrase = 'Critics Consensus: '\n\n# Finding how long is the common phrase\nlen(common_phrase)","1bbe4223":"consensus[0].text","7ef79b7f":"# Taking only the part of the text after the common phrase\nconsensus[0].text[19:]","e725dd94":"# Define a variable to store the length\ncommon_len = len(common_phrase)\n\n# Cleaning the list of the common phrase\nconsensus_text = [con.text[common_len:] for con in consensus]\nconsensus_text [:5]","9914fba9":"# We can add if-else logic to only truncate the string in case it starts with the common phrase\nconsensus_text = [con.text[common_len:] if con.text.startswith(common_phrase) else con.text for con in consensus ]\nconsensus_text [:5]","9ce7a1c6":"consensus[0]","db50da2c":"# We can use .contents to obtain a list of all children of the tag\nconsensus[0].contents","7ddc1074":"# The second element of that list is the text we want\nconsensus[0].contents[1]","4f8c9298":"# We can remove the extra whitespace (space at the beginning) with the .strip() method\nconsensus[0].contents[1].strip()","a08027f3":"# Processing all texts\nconsensus_text = [con.contents[1].strip() for con in consensus]\nconsensus_text [:5]","6ee5f056":"# Extracting all director divs\ndirectors = [div.find(\"div\", class_ = 'director') for div in divs]\ndirectors [:5]","d3f25238":"# Inspecting a div\ndirectors[0]","9e63095b":"# The director's name can be found as the string of a link\n\n# Obtaining all director links\n[director.find(\"a\") for director in directors] [40:45]","cc21e0cf":"# We can use if-else to deal with the None value\n\nfinal_directors = [None if director.find(\"a\") is None else director.find(\"a\").string for director in directors]\nfinal_directors [:5]","2d3e22f2":"cast_info = [div.find(\"div\", class_ = 'cast') for div in divs]\ncast_info [:5]","cc465c2e":"cast_info[0]","29587af8":"# Let's first practice with a single movie\n\n# Obtain all the links to different cast members\ncast_links = cast_info[0].find_all('a')\ncast_links","92c57f1c":"cast_names = [link.string for link in cast_links]\ncast_names","5eb1264f":"# OPTIONALLY: We can stitch all names together as one string\n\n# This can be done using the join method\n# To use join, pick a string to use as a separator (in our case a comma, followed with a space) and\n# pass the list of strings you want to merge to the join method\n\ncast = \", \".join(cast_names)\ncast","250b7049":"# Initialize the list of all cast memners\ncast = []\n\n# Just put all previous operations inside a for loop\nfor c in cast_info:\n    cast_links = c.find_all('a')\n    cast_names = [link.string for link in cast_links]\n    \n    cast.append(\", \".join(cast_names)) # Joining is optional\n\ncast [:5]","834daeb0":"# As you can see this can be done in just one line using nested list comprehension\n# However, the code is harded to understand\n\ncast = [\", \".join([link.string for link in c.find_all(\"a\")]) for c in cast_info]\ncast [:5]","e0b4b7ea":"# The adjusted scores can be found in a div with class 'info countdown-adjusted-score'\nadj_scores = [div.find(\"div\", {\"class\": \"info countdown-adjusted-score\"}) for div in divs]\nadj_scores [:5]","4f8abf14":"# Inspecting an element\nadj_scores[0]","3fc0e8d9":"# By inspection we see that the string we are looking for is the second child of the 'div' tag\nadj_scores[0].contents[1]  # Note the extra whitespace at the end","42b857f5":"# Extracting the string (without '%' sign and extra space)\nadj_scores_clean = [score.contents[1].strip('% ') for score in adj_scores]\nadj_scores_clean [:5]","19c259cd":"# Converting the strings to numbers\nfinal_adj = [float(score) for score in adj_scores_clean] # Note that this time the scores are float, not int!\nfinal_adj [:5]","088f9f61":"# The synopsis is located inside a 'div' tag with the class 'info synopsis'\nsynopsis = [div.find('div', class_='synopsis') for div in divs]\nsynopsis [:5]","647a0dbb":"# Inspecting the element\nsynopsis[0]","765517d5":"# The text is the second child\nsynopsis[0].contents[1]","2c64dcb6":"# Extracting the text\nsynopsis_text = [syn.contents[1] for syn in synopsis]\nsynopsis_text [:5]","2fd6925c":"# A dataframe is a tabular data type, frequently used in data science\n\nmovies_info = pd.DataFrame()\nmovies_info  # The dataframe is still empty, we need to fill it with the info we gathered","e85ee0b5":"movies_info[\"Movie Title\"] = movie_names\nmovies_info[\"Year\"] = years\nmovies_info[\"Score\"] = scores\nmovies_info[\"Adjusted Score\"] = final_adj\nmovies_info[\"Director\"] = final_directors\nmovies_info[\"Synopsis\"] = synopsis_text\nmovies_info[\"Cast\"] = cast\nmovies_info[\"Consensus\"] = consensus_text\nmovies_info.head()","bbbd0f12":"# By default pandas abbreviates any text beyond a certain length (as seen in the Cast and Consensus columns)\n\n# We can change that by setting the maximum column width to -1,\n# which means the column would be as wide as to display the whole text\npd.set_option('display.max_colwidth', -1)\nmovies_info.head()","adfa13c6":"# Write data to CSV file\nmovies_info.to_csv(\"movies_info.csv\", index = False, header = True)\n\n# Write data to excel file\n#movies_info.to_excel(\"movies_info.xlsx\", index = False, header = True)","9f11e835":"#### Observation\n- Alternativelly, we can do it with the help of the strip() method (this is robust)\n- It removes leading and trailing symbols from a string\n- By default, it removes whitespace, but we can specify other symbols to strip","07b60610":"### Removing '%' and extra space ' '","1f1e79d9":"## 4. Critics Consensus\n- inside a div with class 'critics-consensus'","aa72d5e3":"## Exporting the data to CSV (comma-separated values) and excel files\n- Index is set to False so that the index (0,1,2...) of each movie is not saved to the file (the index is purely internal)\n- The header is set to True, so that the names of the columns are saved","d933ec4b":"### Filtering Title","5523cfb8":"# Representing the data in structured form\n- We will take advantage of pandas and its dataframe for data storage","43a2ffdf":"#### For Loop","27dc0cbc":"# WEB SCRAPING FROM ROTTENTOMATOES MOVIE WEBSITE\n## Author: Vu Duong\n### Date: July, 2020\n\n# CREDITS\nThis work is inspired by a great source done before:\n- https:\/\/www.udemy.com\/course\/web-scraping-and-api-fundamentals-in-python\/\n\n# INTRODUCTION\nAre you tired of manually copying and pasting values in a spreadsheet? Do you want to learn how to obtain interesting, real-time and even rare information from the internet with a simple script?\n\nWeb Scraping is a technique for obtaining information from web pages or other sources of data, such as webpages, downloadable files, and APIs, through the use of intelligent automated programs. Web Scraping allows us to gather data from potentially hundreds or thousands of pages with a few lines of code. When it comes to data science \u2013 more and more data comes from external sources, thus knowing how to extract and structure that data quickly is an essential skill that will set you apart in the job market.","6d1dca43":"#### Way #2: Inspecting the HTML","dfb5519d":"## 8. Synopsis","7416b899":"## 5. Directors","e8dbaff6":"### Filtering Score","723db1b6":"### Filtering the names from 1 link","254b9326":"- It does contain the info we want to extract\n- However, we need to obtain the title, year and score separately\n- Let's inspect one heading to see if there is a way to distinguish between them\n\n### Observation:\n- The movie title is in the 'a' tag\n- The year is in a 'span' with class 'start-year'\n- The score is in a 'span' with class 'tMeterScore'","097251f0":"### Removing the % Sign","ffef8a48":"#### Observation\n- One way to remove the brackets is to drop the first and last symbol of the string\n- However, this will break, if the format of the year is changed","e5060cb8":"## lxml\n- By first accounts of inspecting the file everything seems fine","686077fb":"#### Way 1: Text processing","67de92f8":"## 3. Score","ffe455ba":"# FINDING AN ELEMENT CONTAINING ALL THE DATA","e5e57057":"### Filtering Adjusted Score","9b3d3be6":"### Removing the Brackets from Year","1fb1aebf":"#### Nested list comprehension","46082648":"## Creating a Data Frame","499bde67":"## 1. Title","1ddb3f1c":"## Populating the dataframe","d06928f3":"# CHOOSING A PARSER\n- 3 Options: lxml (best), html5lib (second), html.parser (worst)","ca37c70d":"# Target URL","fb289f59":"## 7. Adjusted Score","093c93be":"### Removing common phrase: 'Critics Consensus: '","c723723e":"# LIBRARY","fa5d8af6":"### Filtering Synopsis","74398597":"## A word of caution\n- Beautiful Soup ranks the lxml parser as the best one.\n- If a parser is not explicitly stated in the Beautiful Soup constructor,\n- the best one available on the current machine is chosen.\n- This means that the same piece of code can give different results on different computers.","c6ba958e":"### Filtering Critics Consensus","2e76b2d0":"### Filtering Directors\n- Notice that one link is None - the director of Iron Man is missing!\n- This means we can't simply use .string,\n- Because None has no string attribute\n- Running the line below will raise an error if uncommented\n- #[director.find(\"a\").string for director in directors]","ee32f339":"### Cleaning Missing Values","b3d48c3d":"#### Observation\n- When inspecting the HTML we see that the common phrase (\"Critics Consensus: \")\n- is located inside a span element\n- The string we want to obtain follows that\n- In my opinion, this method is closer to the BeautifulSoup approach","5984dc38":"## html.parser\n-  When inspecting the file we see that HTML element is closed at the begining -- it parsed incorrectly!\n-  Let's check another parser","6afc29a1":"# EXTRACTION OF ALL ELEMENTS FOR EACH MOVIE\n- The title, year and score of each movie are contained in the 'h2' tags","592a0082":"## 2. Year","5358d806":"## 6. Cast info\n- Each cast member's name is the string of a link\n- There are multiple cast members for a movie","02a4b203":"### Filtering Year","e3df9143":"### Filtering names from multiple links\n- We can either use a for loop (clearer), or\n- use a nested list compehension (more concise)"}}