{"cell_type":{"6de68b73":"code","16fbaf7e":"code","4d34c0e5":"code","2e7539d6":"code","48ab5f08":"code","cdad76ec":"code","90ed9c81":"code","44c1de75":"code","ed1d1720":"code","93b1b742":"code","180144c7":"code","ee3689f4":"code","3c6e6019":"code","d95f91c9":"code","43f51bfb":"code","e9a4cd3d":"code","8289d3eb":"code","cd5bc826":"code","33fb8117":"markdown","a4032f90":"markdown","4bbe47e2":"markdown","d454d26b":"markdown","63aec1ee":"markdown","ab40633e":"markdown","d44562ab":"markdown","187a56e2":"markdown","e2f12b02":"markdown","7bd6a617":"markdown"},"source":{"6de68b73":"pip install -q -U scikit-learn","16fbaf7e":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\nsns.set_context(\"talk\", font_scale=1.2)\nimport plotly.express as px\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nimport sklearn\nsklearn.__version__\n\nfrom sklearn.linear_model import ElasticNet, Lasso\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import make_scorer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_log_error,  mean_squared_error \npd.options.mode.chained_assignment = None  # default='warn'\n","4d34c0e5":"import sys, os\nsys.path.append(os.path.dirname(\"..\/usr\/lib\/\"))\nfrom housepricesadv_pipe import BasicePrepro, Imputer, Transforms, Encoder\nfrom housepricesadv_pipe import Scaler\nfrom housepricesadv_utils import root_mean_squared_log_error, get_cv_indices\nfrom housepricesadv_utils import save_results","2e7539d6":"train = pd.read_csv(\"..\/input\/housepricesadv-folds\/train_folds.csv\", \n                    keep_default_na=False, na_values=[\"\"])\ntrain.shape","48ab5f08":"test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\", \n                    keep_default_na=False, na_values=[\"\"])\ntest.shape","cdad76ec":"pipe = Pipeline([\n    ('BasicePrepro', BasicePrepro()),\n    ('Imputer', Imputer()),\n    ('Transforms', Transforms()),\n    ('Encoder', Encoder(cat_method=None)), # do not include nominal vars as one-hot, exclude them\n    ('Scaler', Scaler(MinMaxScaler())),\n    (\"Model\", ElasticNet(max_iter=8000, tol=1e-1, random_state=42))\n])#, memory=memory)\npipe\n","90ed9c81":"param_grid = dict(Model__alpha=np.logspace(-5, 2, 50),\n                  Model__l1_ratio=np.arange(0.1, 1.1, 0.5))\n\nsearch = GridSearchCV(pipe, param_grid, \n                   cv = get_cv_indices(train),\n                  verbose=10, scoring=make_scorer( root_mean_squared_log_error,\n                                                   greater_is_better=False))\nparam_grid","44c1de75":"# sklearn: To avoid unnecessary memory duplication the X argument of the fit method should be directly passed as a Fortran-contiguous numpy array.\nsearch_results = search.fit(train.copy().drop(columns=['Id', 'SalePrice', 'kfold']), train['SalePrice'])","ed1d1720":"search_results.best_estimator_","93b1b742":"search_results.best_estimator_.get_params()","180144c7":"search_results.best_score_","ee3689f4":"best_estimator = search_results.best_estimator_","3c6e6019":"best_estimator","d95f91c9":"weights = pd.DataFrame(zip(best_estimator.named_steps['Scaler'].columns,  \n                           best_estimator.named_steps['Model'].coef_), \n             columns=['feature', 'weight'])\nweights_sorted = weights.iloc[weights['weight'].abs().sort_values().index]\nweights_sorted.head(20)","43f51bfb":"weights_sorted.tail(10)","e9a4cd3d":"train.columns","8289d3eb":"test.columns","cd5bc826":"save_results(best_estimator, train, test, \n                        train.drop(columns=['Id', 'SalePrice', 'kfold']).columns, \n                        \"SalePrice\", \"Id\")","33fb8117":"# I. Extract and Prepro Data","a4032f90":"> This result is not good compared to my simple baselines..","4bbe47e2":"# III. Submission","d454d26b":"# II. Data Prepro\n\nFeature engineering is done in separate state and not tuned together iwth the algo here.","63aec1ee":"> Model chose L1 penalty with lasso","ab40633e":"# Modeling with ElasticNet 1\n\n### Goals\n\n* Build and Optimize Linear ElasticNet Regression Model\n\n\n\n### comments\n\n","d44562ab":"# II. Modeling","187a56e2":"Oftentimes I encounter convergence error hence I increased the tolerance for ElasticNet","e2f12b02":"get best model (which was fitted on whole train data):","7bd6a617":"> no feature was shrunk to zero."}}