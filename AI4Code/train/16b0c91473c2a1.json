{"cell_type":{"c149be18":"code","7c2df6a0":"code","37cf98e0":"code","534bead1":"code","4c4685d9":"code","bb7eda88":"code","5d285ccb":"code","e396ebab":"code","92ffc8cd":"code","01ff61e3":"code","5ce11e1a":"code","e97266d4":"code","7cd08fe3":"code","f60d89d1":"code","addfe02b":"code","81a2092d":"code","871d1cdc":"code","2fe66b6f":"code","94344636":"code","56f26aa3":"code","b4d14203":"code","2f50951c":"code","43d1ddb5":"code","a5afb354":"code","cea425f6":"code","b21955f0":"code","18f19840":"code","e2c4d6d9":"code","e5897036":"code","7b33166e":"markdown","ad562b06":"markdown","8bc80fe5":"markdown","e3fc2204":"markdown"},"source":{"c149be18":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","7c2df6a0":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","37cf98e0":"from fastai import *\nfrom fastai.vision import *\nimport imageio","534bead1":"path = Path('..\/input\/Kannada-MNIST')\ntrain = pd.read_csv('..\/input\/Kannada-MNIST\/train.csv')\ntest  =pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')","4c4685d9":"train.head()","bb7eda88":"def to_img_shape(data_X, data_y=[]):\n    data_X = np.array(data_X).reshape(-1,28,28)\n    data_X = np.stack((data_X,)*3, axis=-1)\n    data_y = np.array(data_y)\n    return data_X,data_y","5d285ccb":"data_X, data_y = train.loc[:,'pixel0':'pixel783'], train['label']\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(data_X, data_y, test_size=0.01,random_state=7,stratify=data_y)","e396ebab":"train_X,train_y = to_img_shape(train_X, train_y)\nval_X,val_y = to_img_shape(val_X,val_y)","92ffc8cd":"def save_imgs(path:Path, data, labels):\n    path.mkdir(parents=True,exist_ok=True)\n    for label in np.unique(labels):\n        (path\/str(label)).mkdir(parents=True,exist_ok=True)\n    for i in range(len(data)):\n        if(len(labels)!=0):\n            imageio.imsave( str( path\/str(labels[i])\/(str(i)+'.jpg') ), data[i] )\n        else:\n            imageio.imsave( str( path\/(str(i)+'.jpg') ), data[i] )\n\nsave_imgs(Path('\/data\/train'),train_X,train_y)\nsave_imgs(Path('\/data\/valid'),val_X,val_y)","01ff61e3":"tfms = get_transforms(do_flip=False )\n\ndata = (ImageList.from_folder('\/data\/') \n        .split_by_folder()          \n        .label_from_folder()        \n        .add_test_folder()          \n        .transform(tfms, size=64)   \n        .databunch())","5ce11e1a":"data.show_batch(3,figsize=(6,6))","e97266d4":"!mkdir -p \/tmp\/.cache\/torch\/checkpoints\n!cp \/kaggle\/input\/fastai-pretrained-models\/resnet50-19c8e357.pth \/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth\n\nlearn = cnn_learner(data, models.resnet50, metrics=[error_rate, accuracy], model_dir = Path('..\/kaggle\/working'),path = Path(\".\"))","7cd08fe3":"learn.fit_one_cycle(4)","f60d89d1":"learn.lr_find()","addfe02b":"learn.recorder.plot()","81a2092d":"lr = slice(2e-05)","871d1cdc":"learn.save('stage-1')","2fe66b6f":"learn.unfreeze()","94344636":"learn.fit_one_cycle(5,lr)","56f26aa3":"learn.save('stage-2')","b4d14203":"learn.fit_one_cycle(10,lr)","2f50951c":"learn.save('stage-3')","43d1ddb5":"learn.load('stage-3')","a5afb354":"test_csv = pd.read_csv('..\/input\/Kannada-MNIST\/test.csv')\ntest_csv.drop('id',axis = 'columns',inplace = True)\nsub_df = pd.DataFrame(columns=['id','label'])","cea425f6":"test_data = np.array(test_csv)","b21955f0":"def get_img(data):\n    t1 = data.reshape(28,28)\/255\n    t1 = np.stack([t1]*3,axis=0)\n    img = Image(FloatTensor(t1))\n    return img","18f19840":"from fastprogress import progress_bar","e2c4d6d9":"mb=progress_bar(range(test_data.shape[0]))\nfor i in mb:\n    timg=test_data[i]\n    img = get_img(timg)\n    sub_df.loc[i]=[i+1,int(learn.predict(img)[1])]","e5897036":"def decr(ido):\n    return ido-1\nsub_df['id'] = sub_df['id'].map(decr)\nsub_df.to_csv('submission.csv',index=False)","7b33166e":"**Fitting the model**","ad562b06":"**Making the Learner**","8bc80fe5":"**Getting the Predictions**","e3fc2204":"**Preprocessing**"}}