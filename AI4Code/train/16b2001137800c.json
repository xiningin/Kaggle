{"cell_type":{"eea1afcb":"code","5f763d9c":"code","f665cacd":"code","0bffa41e":"code","e5a03bf1":"code","e77efddf":"code","89e87d3a":"code","bae5596a":"code","7c15f1ed":"code","d8430584":"code","c26c64d9":"code","e2f91a58":"code","1c8b99d1":"code","3cded824":"code","25c68675":"code","a59a0a22":"code","7737e331":"code","35cd7eec":"code","8ccd4900":"code","e26114e8":"code","e64f38b7":"code","5763e670":"code","e8ca0c1a":"code","58d2a430":"code","33d19978":"code","b2423604":"code","069922f9":"code","cf8169ad":"code","071ad87c":"code","d34ece5d":"code","27b8d610":"code","101e2047":"code","c7f0fa69":"code","ec32b9a8":"code","16a637e7":"code","11cb4903":"code","3e2b9ec9":"code","ab3a41bd":"code","d6778b44":"code","2b147e18":"code","b2b37589":"code","ec1f9e41":"code","b0d40e34":"code","9dabbb55":"code","89bdf3fd":"code","14886c80":"code","baa2c299":"code","981e72f0":"code","b18739e8":"code","ee322ae2":"code","41a9c3b0":"code","f6e4b57c":"code","ed885c0a":"markdown","41d1f4b2":"markdown","279f65b9":"markdown","13190b10":"markdown","e6586a9f":"markdown","12e7d95d":"markdown","ebea17ef":"markdown","39ee37b8":"markdown","a7dbd8dd":"markdown","a283a9af":"markdown","12d55638":"markdown","50b1cab8":"markdown","c41028c2":"markdown","e841c7ad":"markdown","0ec1ca1a":"markdown","47ce2ca8":"markdown"},"source":{"eea1afcb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f763d9c":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport pandas_profiling\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import metrics\n\npd.pandas.set_option('display.max_columns',None)\npd.pandas.set_option('display.max_rows',None)","f665cacd":"dataset = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')","0bffa41e":"dataset.dtypes","e5a03bf1":"dataset.count()","e77efddf":"dataset.shape","89e87d3a":"## Here we will check the percentage of nan values present in each feature\n## 1 -step make the list of features which has missing values\nfeatures_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n## 2- step print the feature name and the percentage of missing values\n\nfor feature in features_with_na:\n    print(feature, np.round(dataset[feature].isnull().mean(), 4),  ' % missing values')","bae5596a":"for feature in features_with_na:\n    data = dataset.copy()\n    \n    # let's make a variable that indicates 1 if the observation was missing or zero otherwise\n    data[feature] = np.where(data[feature].isnull(), 1, 0)\n    \n    # let's calculate the mean SalePrice where the information is missing or present\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","7c15f1ed":"print(\"Id of Houses {}\".format(len(dataset.Id)))","d8430584":"# list of numerical variables\nnumerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'O']\n\nprint('Number of numerical variables: ', len(numerical_features))\n\n# visualise the numerical variables\ndataset[numerical_features].head()","c26c64d9":"# list of variables that contain year information\nyear_feature = [feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","e2f91a58":"# let's explore the content of these year variables\nfor feature in year_feature:\n    print(feature, dataset[feature].unique())","1c8b99d1":"## Lets analyze the Temporal Datetime Variables\n## We will check whether there is a relation between year the house is sold and the sales price\n\ndataset.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","3cded824":"## Here we will compare the difference between All years feature with SalePrice\n\nfor feature in year_feature:\n    if feature!='YrSold':\n        data=dataset.copy()\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","25c68675":"discrete_feature=[feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","a59a0a22":"dataset[discrete_feature].head()","7737e331":"## Lets Find the realtionship between them and Sale Price\n\nfor feature in discrete_feature:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","35cd7eec":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","8ccd4900":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","e26114e8":"## We will be using logarithmic transformation\n\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data['SalePrice']=np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalesPrice')\n        plt.title(feature)\n        plt.show()","e64f38b7":"for feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","5763e670":"categorical_features=[feature for feature in dataset.columns if data[feature].dtypes=='O']\ncategorical_features","e8ca0c1a":"dataset[categorical_features].head()","58d2a430":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(dataset[feature].unique())))","33d19978":"for feature in categorical_features:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","b2423604":"## Let us capture all the nan values\n## First lets handle Categorical features which are missing\nfeatures_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\n\nfor feature in features_nan:\n    print(\"{}: {}% missing values\".format(feature,np.round(dataset[feature].isnull().mean(),4)))","069922f9":"## Replace missing value with a new label\ndef replace_cat_feature(dataset,features_nan):\n    data=dataset.copy()\n    data[features_nan]=data[features_nan].fillna('Missing')\n    return data\n\ndataset=replace_cat_feature(dataset,features_nan)\n\ndataset[features_nan].isnull().sum()","cf8169ad":"## Now lets check for numerical variables the contains missing values\nnumerical_with_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes!='O']\n\n## We will print the numerical nan variables and percentage of missing values\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing value\".format(feature,np.around(dataset[feature].isnull().mean(),4)))","071ad87c":"## Replacing the numerical Missing Values\n\nfor feature in numerical_with_nan:\n    ## We will replace by using median since there are outliers\n    median_value=dataset[feature].median()\n    \n    ## create a new feature to capture nan values\n    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value,inplace=True)\n    \ndataset[numerical_with_nan].isnull().sum()","d34ece5d":"## Temporal Variables (Date Time Variables)\n\nfor feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    dataset[feature]=dataset['YrSold']-dataset[feature]","27b8d610":"num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n\nfor feature in num_features:\n    dataset[feature]=np.log(dataset[feature])","101e2047":"categorical_features=[feature for feature in dataset.columns if dataset[feature].dtype=='O']","c7f0fa69":"for feature in categorical_features:\n    temp=dataset.groupby(feature)['SalePrice'].count()\/len(dataset)\n    temp_df=temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')","ec32b9a8":"for feature in categorical_features:\n    labels_ordered=dataset.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    dataset[feature]=dataset[feature].map(labels_ordered)","16a637e7":"dataset.head()","11cb4903":"#feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n#scaler=MinMaxScaler()\n#scaler.fit(dataset[feature_scale])\n#scaler.transform(dataset[feature_scale])","3e2b9ec9":"# transform the train and test set, and add on the Id and SalePrice variables\n#data = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n                    #pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n                    #axis=1)","ab3a41bd":"data.head()","d6778b44":"features = dataset[dataset.columns.difference(['SalePrice'])]\ny = dataset['SalePrice']\nlm = LinearRegression()\nrfe = RFE(lm, n_features_to_select=20)\nrfe = rfe.fit(features, y)\nimp_RFE = features.columns[rfe.get_support()]\nimp_features = list(imp_RFE)\nimp_features","2b147e18":"X = dataset[imp_features]\nX","b2b37589":"#train and Test split \ntrain_X,test_X, train_y, test_y= train_test_split(X,y,test_size=0.3,random_state=1234)\n\nprint(train_X. shape)\nprint(test_X.shape)\nprint(train_y. shape)\nprint(test_y.shape)","ec1f9e41":"lm = lm.fit(train_X,train_y)","b0d40e34":"#Checking Accuracy for train and Test data\nprint(lm.score(train_X,train_y))\nprint(lm.score(test_X,test_y))","9dabbb55":"#Checking Mean Square Error  for Train and Test Data\nprint(\"Mean Square Error :\\n\")\nprint(metrics.mean_squared_error(train_y,lm.predict(train_X)))\nprint(metrics.mean_squared_error(test_y, lm.predict(test_X)))\n\n#Checking Root Mean Square Error\nprint(\"\\nRoot Mean Square Error :\\n\")\nprint(np.sqrt(metrics.mean_squared_error(train_y,lm.predict(train_X))))\nprint(np.sqrt(metrics.mean_squared_error(test_y,lm.predict(test_X))))","89bdf3fd":"train_X['pred'] = lm.predict(train_X)","14886c80":"train_y = np.exp(train_y)\ntrain_y = pd.Series(train_y)\ntrain_pred = np.exp(train_X.pred)\ntrain_pred = pd.concat([train_y, train_pred], axis = 1)\ntrain_pred.columns = ['SalePrice', 'Prediction']\ntrain_pred","baa2c299":"test_X['pred'] = lm.predict(test_X)\ntest_X.head()","981e72f0":"test_y = np.exp(test_y)\ntest_y = pd.Series(test_y)\ntest_pred = np.exp(test_X.pred)\ntest_pred = pd.concat([test_y, test_pred], axis = 1)\ntest_pred.columns = ['SalePrice', 'Prediction']\ntest_pred","b18739e8":"train_pred['Deciles']=pd.qcut(train_pred['Prediction'],10, labels=False)\navg_actual = train_pred[['Deciles','SalePrice']].groupby(train_pred.Deciles).mean().sort_index(ascending=False)['SalePrice']\navg_pred = train_pred[['Deciles','Prediction']].groupby(train_pred.Deciles).mean().sort_index(ascending=False)['Prediction']\nDecile_analysis_train = pd.concat([avg_actual, avg_pred], axis=1)\nDecile_analysis_train = Decile_analysis_train.reset_index()\nDecile_analysis_train","ee322ae2":"sns.regplot(x=\"SalePrice\", y=\"Prediction\", data=train_pred)","41a9c3b0":"test_pred['Deciles']=pd.qcut(test_pred['Prediction'],10, labels=False)\navg_actual = test_pred[['Deciles','SalePrice']].groupby(test_pred.Deciles).mean().sort_index(ascending=False)['SalePrice']\navg_pred = test_pred[['Deciles','Prediction']].groupby(test_pred.Deciles).mean().sort_index(ascending=False)['Prediction']\nDecile_analysis_test = pd.concat([avg_actual, avg_pred], axis=1)\nDecile_analysis_test = Decile_analysis_test.reset_index()\nDecile_analysis_test","f6e4b57c":"sns.regplot(x=\"SalePrice\", y=\"Prediction\", data=train_pred)","ed885c0a":"### Continuos Variable\n- The opposite of a discrete variable is a continuous variable, which can take on all possible values between the extremes. Thus this variable can vary in a continuous manner.\n- For example, consider the length of a stretched rubber band. Its length can be any value from its initial size to the maximum possible stretched size before it breaks. The length variable can be 10.0 cm or 15.435 cm. The variation is continuous in nature.","41d1f4b2":"- Checking for the data types in the dataset","279f65b9":"### Categorical Variables","13190b10":"##### In Data Analysis We will Analyze To Find out the below stuff\u00b6\n- Missing Values\n- All The Numerical Variables\n- Distribution of the Numerical Variables\n- Categorical Variables\n- Cardinality of Categorical Variables\n- Outliers\n- Relationship between independent and dependent feature(SalePrice)","e6586a9f":"### Numerical Variable","12e7d95d":"### Missing Value","ebea17ef":"- Here With the relation between the missing values and the dependent variable is clearly visible.So We need to replace these nan values with something meaningful which we will do in the Feature Engineering section\n\n- From the above dataset some of the features like Id is not required","39ee37b8":"### Discrete Variables\n- A discrete variable is a kind of statistics variable that can only take on discrete specific values. The variable is not continuous, which means there are infinitely many values between the maximum and minimum that just cannot be attained, no matter what.\n- For example, a coin toss can either be a heads or tails. If you want to quantify this data, you can assign 1 for heads and 0 for tails and compute the total score of a random coin tossing experiment. In this case, the variable that keeps track of the outcome is a discrete variable.","a7dbd8dd":"- END --------------------------","a283a9af":"### Outliers","12d55638":"### Numerical variables are usually of 2 type\n- Continous variable and Discrete Variables","50b1cab8":"##### Find out the relationship between categorical variable and dependent feature SalesPrice","c41028c2":"### Handling Rare Categorical Feature\n- We will remove categorical variables that are present less than 1% of the observations","e841c7ad":"#### There is a relationship between variable number and SalePrice","0ec1ca1a":"#### Temporal Variables(Eg: Datetime Variables)\n - From the Dataset we have 4 year variables. We have extract information from the datetime variables like no of years or no of days. One example in this specific scenario can be difference in years between the year the house was built and the year the house was sold. We will be performing this analysis in the Feature Engineering which is the next video.","47ce2ca8":"\n##### Since they are many missing values, we need to find the relationship between missing values and Sales Price\u00b6\n- Let's plot some diagram for this relationship"}}