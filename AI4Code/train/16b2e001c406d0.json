{"cell_type":{"d874698d":"code","520f1882":"code","9f985656":"code","5666b90e":"code","96ac345e":"code","b7a9da4d":"code","0378596c":"code","6bbd69d1":"code","dc135fb3":"code","70025a99":"code","69eaf864":"code","1806f346":"code","ec980dc9":"code","2879377b":"code","cb4947e6":"code","ca7694b9":"code","2ea3551e":"code","89db6238":"code","8cd06eef":"code","a2fea2de":"code","3cfc9d36":"code","0875f070":"code","df5510e3":"code","f8b52340":"code","090efdab":"code","c8a2e4eb":"code","f1e01592":"code","5d8bc10c":"code","7515f6d3":"code","ccf92fd7":"code","7f4b8f11":"code","e4274503":"code","10930eba":"code","080ea014":"code","c3963930":"code","5ed98ef2":"code","e56143e4":"code","42acb4db":"code","d10af3fc":"code","14302771":"code","f1baed98":"code","b048d1cc":"code","5fa06c13":"code","b71bf6cd":"code","afd40ce8":"code","5a7dc9c4":"code","94a40889":"markdown","7e20397d":"markdown","77bb0dec":"markdown","fd2e4327":"markdown","207bb05c":"markdown","89e97473":"markdown","ad24533e":"markdown","2d2c7568":"markdown","bb44725b":"markdown","c53c6341":"markdown"},"source":{"d874698d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","520f1882":"import pandas as pd\nimport seaborn as sns\nimport plotly.express as xp\nimport plotly.graph_objects as go\nimport numpy as np\nfrom datetime import datetime\nimport missingno\nimport yaml\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV,ShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import RidgeClassifier\nfrom catboost import CatBoostClassifier\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\npalette = ['#3aa833',\"#6b856a\",\"#354014\"]\nsns.palplot(palette)","9f985656":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which present only in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique ganres values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimentionality of the dataset\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    return embedded\n\ndef plot_commulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=palette[i])))\n    fig.show()","5666b90e":"#\u52a0\u8f7d\u6570\u636e\nPATH = \"..\/input\/mymusicalprefrences\/\" \ntrain = pd.read_csv(f\"{PATH}train.csv\")\ntest = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\ndf = pd.concat([train,test]).reset_index(drop=True)\ntr_mask = ~df.Category.isna()","96ac345e":"#\u53bb\u9664columns\u7a7a\u683c\u7b26\ndf.columns = [i.strip() for i in df.columns]\ndf.columns","b7a9da4d":"df.describe()","0378596c":"df.info()","6bbd69d1":"# \u7a7a\u503c\nmissingno.bar(df, color=palette, figsize=(30,2))","dc135fb3":"#\u5b57\u7b26\u4e32\u5b57\u6bb5\u548c\u6570\u5b57\u5b57\u6bb5columns\nstr_features = {\"Artists\",\"Track\",\"Version\",\"Artists_Genres\",\"Album\",\"Album_type\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\nnum_features = {\"Duration\",\"Release_year\",\"BPM\",\"Energy\",\"Dancebility\",\"Happiness\"}\ndisplay(df[str_features].head())\ndisplay(df[num_features].head())","70025a99":"sns.pairplot(df[list(num_features)+[\"Category\"]],palette=palette[:2], hue=\"Category\")","69eaf864":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})","1806f346":"def binary(x):\n    if x == 'M':\n        return 0\n    elif x == 'F':\n        return 1\n    else:\n        return 2\n\ndf['Vocal'] = df['Vocal'].apply(binary)\ntrain.head()","ec980dc9":"def tone(x):\n    x = x.split()\n    if x[1] == 'Minor':\n        return 0\n    else:\n        return 1\n\ndf['Tone'] =  list(map(lambda x: tone(x), df['Key']))\ntrain.head()","2879377b":"train['Key'].unique()\ndf[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\ndf.head()","cb4947e6":"df[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)","ca7694b9":"df.head()","2ea3551e":"ganres_onehot = split_to_onehot(df, \"Artists_Genres\")","89db6238":"genres_embedded = onehot_to_tsne2(ganres_onehot, \"Genres\")\n_df = genres_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists_Genres\"]] = df[[\"Category\",\"Artists_Genres\"]]","8cd06eef":"df = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"Artists_Genres\", axis=1)\n","a2fea2de":"df.head()","3cfc9d36":"def year(x):\n    if x < 1990: \n        return 1980\n    elif x < 2000:\n        return 1990\n    elif x < 2010:\n        return 2000\n    elif x < 2020:\n        return 2010\n    elif x < 2030:\n        return 2020\n    else:\n        return '1970 or older'","0875f070":"df['Release_year'] =  df['Release_year'].apply(year)","df5510e3":"df.head()","f8b52340":"df = pd.get_dummies(df, columns = ['Version', 'Album_type', 'Country','Album'])","090efdab":"df.head()","c8a2e4eb":"df.Artists = df.Artists.fillna(\"NA\")\nallstars = []\nfor i in df.index:\n    allstars.extend(df.loc[i, \"Artists\"].split(\"|\"))\n# We will put some threshold, not to put some rare artists into one-hot vector.\nthreshold = 3\nothers = Counter(allstars)\nothers = [k for k in others if others[k]<=threshold]","f1e01592":"# Drop all artists who are just in test set or just in train set\nin_train, in_test = [], []\nfor i in df.loc[tr_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~tr_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\n","5d8bc10c":"allstars = list(set(allstars) - set(others) - only_test - only_train)\nothers = set(others) | only_test | only_train\nres = []\ndef prune(x):\n    vector = np.zeros(len(allstars)+1) #for others\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(allstars)):\n        vector[i]=1 if allstars[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    res.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(res, columns = allstars+[\"Others\"], index=df.index)","7515f6d3":"df[\"Other_Artists\"] = onehot_artists[\"Others\"]\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\nonehot_artists[\"Category\"] = df[\"Category\"]","ccf92fd7":"artists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\n_df = artists_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists\"]] = df[[\"Category\",\"Artists\"]]\ndf = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)","7f4b8f11":"df = df.drop(columns='Artists')","e4274503":"df.head()","10930eba":"df.Labels = df.Labels.fillna('NA')\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_commulative_onehot(labels_onehot)","080ea014":"labels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\n_df = labels_embedded.copy(deep=True)\n_df[[\"Category\",\"Labels\"]] = df[[\"Category\",\"Labels\"]]\n","c3963930":"df = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)","5ed98ef2":"df = df.drop(columns='Track')","e56143e4":"df.head()","42acb4db":"Energy_mean = df.Energy.mean() \nDancebility_mean = df.Dancebility.mean()\nHappiness_mean = df.Happiness.mean()\n\ndf['Energy'] = df['Energy'].fillna(Energy_mean)\ndf['Dancebility'] = df['Dancebility'].fillna(Dancebility_mean)\ndf['Happiness'] = df['Happiness'].fillna(Happiness_mean)","d10af3fc":"df.isnull().sum()>0","14302771":"df.head()","f1baed98":"X_train, y_train = df.loc[tr_mask].iloc[:,2:], df.loc[tr_mask,\"Category\"]\nX_test = df.loc[~tr_mask].iloc[:,2:]\ndf.isnull().sum()>0","b048d1cc":"X_test.head()","5fa06c13":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)\ny_predSVC = svclassifier.predict(X_test)\ntest['Like_SVC'] = y_predSVC","b71bf6cd":"test[['Id', 'Like_SVC']]","afd40ce8":"sample = pd.read_csv(f\"{PATH}sample_submition.csv\")\nsample[\"Category\"] = svclassifier.predict(X_test)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)","5a7dc9c4":"sample.to_csv(\"submission.csv\", index=False)","94a40889":"## Genres","7e20397d":"## year","77bb0dec":"# Explorational Data Analysis ","fd2e4327":"## Key","207bb05c":"## label\\track\n","89e97473":"## 2.4 Energy,Happiness,Dancebility, BPM","ad24533e":"## Vocals ","2d2c7568":"## Version\\Album_type\\Country\\Album","bb44725b":"## Artists","c53c6341":"## \u7279\u5f81\u6570\u636e\u51c6\u5907\u5904\u7406"}}