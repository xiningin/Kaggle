{"cell_type":{"b089795c":"code","ff5a589b":"code","f5bbaf5a":"code","448b63ce":"code","e335425d":"code","5c122838":"code","742a219d":"code","07f0cbff":"code","75f84ec9":"code","04317ead":"code","2652f8a7":"code","181e8514":"code","3a9278e1":"code","a8118023":"code","0f39d6f4":"code","7578b226":"code","543974a5":"code","ad23d2ac":"code","530e7671":"code","748d0ab1":"code","463f578f":"code","e319c98e":"code","59913299":"code","a5f1febf":"code","4d56c7a9":"code","b3574c7b":"code","2d3b6c94":"code","786be3f3":"code","f5e5c684":"code","69553a38":"code","41b6f107":"code","7679bc7d":"code","97d1cb0f":"code","a9986706":"code","69e5f21b":"code","033f5788":"code","67c9455f":"code","86d1abf4":"code","50addff9":"code","1d3c7eaa":"code","e53fe2cf":"code","c5da07ab":"code","93696477":"code","b60a181d":"code","c4bd1e12":"code","7fd361d7":"code","52609a4a":"code","e0e44df7":"code","6e30b56a":"code","aa614508":"code","e6841e30":"code","91c9b216":"code","aac03012":"code","8fa334ec":"code","25a80a43":"code","2786ead0":"code","340ac6a3":"code","9479a1cd":"code","bf3b81a0":"code","dbb98702":"code","76aa7e6e":"code","b009cd7d":"code","4f53c112":"code","2a02b935":"code","cec44ff4":"code","83c3c69a":"code","c7dd12ac":"code","f68b0e2d":"code","fa2a928b":"code","de612ee5":"code","3c7d7e22":"code","f2b8e59c":"code","25b68671":"markdown","224ab611":"markdown","23608ff6":"markdown","34ca0022":"markdown","7e117fde":"markdown","093333ab":"markdown","2691e96e":"markdown","44a9f3b4":"markdown","95bee6e9":"markdown","ec5eedac":"markdown","d62ea7e7":"markdown","7bd35adc":"markdown","618b1934":"markdown","8c870dda":"markdown","4cb9cff3":"markdown","496e9476":"markdown","97c52e63":"markdown","dab4ac14":"markdown","7102b8cd":"markdown"},"source":{"b089795c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff5a589b":"%matplotlib inline\n#libraries for mathematical computation \nimport pandas as pd \nimport numpy as np \n#libraries for data training and cleaning and modeling\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import BayesianRidge\n#libraries for data visualization \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom matplotlib.pyplot import figure \n","f5bbaf5a":"train_data= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntrain_data.head(10)","448b63ce":"test_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest_data.head(10)","e335425d":"print(train_data.shape)","5c122838":"print(train_data.columns)","742a219d":"print(train_data.info())","07f0cbff":"print(train_data.describe)","75f84ec9":"train_data.dtypes","04317ead":"#select numeric columns \ntrain_data_numeric=train_data.select_dtypes(include=[np.number])\nnumeric_cols=train_data_numeric.columns.values\nprint(numeric_cols)\n","2652f8a7":"#select non numeric columns\ntrain_data_non_numeric = train_data.select_dtypes(exclude=[np.number])\nnon_numeric_cols=train_data_non_numeric.columns.values\nprint(non_numeric_cols)","181e8514":"cols_hm = train_data.columns[:30]\ncolours=['#000099', '#ffff00']\nsns.heatmap(train_data[cols_hm].isnull(),cmap=sns.color_palette(colours))","3a9278e1":"#missing data in heatmap for test_data\ncols_hm = test_data.columns[:30]\ncolours=['#000099', '#ffff00']\nsns.heatmap(test_data[cols_hm].isnull(),cmap=sns.color_palette(colours))","a8118023":"for col in train_data.columns:\n    pct_missing=np.mean(train_data[col].isnull())\n    print('{} - {}%'.format(col,round(pct_missing*100)))","0f39d6f4":"#for testdata\nfor col in test_data.columns:\n    pct_missing=np.mean(train_data[col].isnull())\n    print('{} - {}%'.format(col,round(pct_missing*100)))","7578b226":"for col in train_data.columns:\n    missing=train_data[col].isnull()\n    num_missing= np.sum(missing)\n    \n    if num_missing >0:\n        print('created missing indicator for:{}'.format(col))\n        train_data['{}_ismissing'.format(col)]=missing\n        \n#then based on the indicator , plot the histogram of missing values \nismissing_cols=[col for col in train_data.columns if 'ismissing' in col]\ntrain_data['num_missing']= train_data[ismissing_cols].sum(axis=1)\n\ntrain_data['num_missing'].value_counts().reset_index().sort_values(by='index').plot.bar(x='index',y='num_missing')","543974a5":"#droping rows with alot of missing values \nind_missing=train_data[train_data['num_missing']>35].index\ntrain_data_missing_rows=train_data.drop(ind_missing,axis=0)","ad23d2ac":"#as we know the Alley has most of the missing values from whole dataset so we will drop the whole feature \ncols_to_drop=['Alley']\ntrain_data_Alley=train_data.drop(cols_to_drop,axis=1)","530e7671":"#lets drop the column alley in test_data as well since we have droped it in train_data too\ncols_to_drop=['Alley']\ntest_data_Alley=test_data.drop(cols_to_drop,axis=1)","748d0ab1":"#now we will apply imputation on all the numeric features at once for all\ntrain_data_numeric =train_data.select_dtypes(include=[np.number])\nnumeric_cols=train_data_numeric.columns.values\n\nfor col in numeric_cols:\n    missing=train_data[col].isnull()\n    num_missing=np.sum(missing)\n    \n    if num_missing > 0:\n        print('Imputing missing values for:{}'.format(col))\n        train_data['{}_ismissing'.format(col)]=missing\n        med= train_data[col].median()\n        train_data[col]=train_data[col].fillna(med)","463f578f":"#histogram of Alley \ntrain_data['Alley'].hist(bins=100)\n","e319c98e":"#histogram for alley for test_data\ntest_data['Alley'].hist(bins=100)","59913299":"train_data['Alley'].describe()","a5f1febf":"\n#finding oyt duplicate rows\nprint(train_data.shape)","4d56c7a9":"key=['MSSubClass','LotFrontage','LotArea','Street','LotShape','LandContour','Utilities']\ntrain_data.fillna(-999).groupby(key)['Id'].count().sort_values(ascending=False).head(20)","b3574c7b":"#droping duplicates based on the subset of variables\nkey=['MSSubClass','LotFrontage','LotArea','Street','LotShape','LandContour','Utilities']\ntrain_data_dedupped2=train_data.drop_duplicates(subset=key)\nprint(train_data.shape)\nprint(train_data_dedupped2.shape)","2d3b6c94":"#dropping columns for test dataset \n#droping duplicates based on the subset of variables\nkey=['MSSubClass','LotFrontage','LotArea','Street','LotShape','LandContour','Utilities']\ntest_data_dedupped2=test_data.drop_duplicates(subset=key)\nprint(test_data.shape)\nprint(test_data_dedupped2.shape)","786be3f3":"train_data.drop(['Alley'],axis=1)","f5e5c684":"#dropping column for test data \ntest_data.drop(['Alley'],axis=1)","69553a38":"#checking the fireplace column\ntrain_data['FireplaceQu'].unique()","41b6f107":"#lets replace the null values of fireplace with none \ntrain_data['FireplaceQu']=train_data['FireplaceQu'].fillna('None')","7679bc7d":"#checking LotFrontage column \ntrain_data['LotFrontage'].unique()","97d1cb0f":"#lets replace the null values of LotFrontage with its median \ntrain_data['LotFrontage']=train_data['LotFrontage'].fillna(train_data['LotFrontage'].median())","a9986706":"#checking GarageCond column\ntrain_data['GarageCond'].unique()","69e5f21b":"#lets replace the GarageCond null values to none\ntrain_data['GarageCond']=train_data['GarageCond'].fillna('None')","033f5788":"#checking GarageQual column \ntrain_data['GarageQual'].unique()","67c9455f":"#lets replace the GarageQual null values to none\ntrain_data['GarageQual']=train_data['GarageQual'].fillna('None')","86d1abf4":"#checking GarageFinish column \ntrain_data['GarageFinish'].unique()","50addff9":"#lets replace the null values of GarageFinish with none \ntrain_data['GarageFinish']=train_data['GarageFinish'].fillna('None')","1d3c7eaa":"#checking GarageYrBlt column \ntrain_data['GarageYrBlt'].unique()","e53fe2cf":"#lets replace the missing values of GarageYrBlt with its median \ntrain_data['GarageYrBlt']=train_data['GarageYrBlt'].fillna(train_data['GarageYrBlt'].median())","c5da07ab":"#checking GarageType column \ntrain_data['GarageType'].unique()","93696477":"#replace the missing value in GarageType with None \ntrain_data['GarageType']=train_data['GarageType'].fillna('None')","b60a181d":"#checking BsmtFinType2 column \ntrain_data['BsmtFinType2'].unique()","c4bd1e12":"#replace the missing value in BsmtFinType2 with None \ntrain_data['BsmtFinType2']=train_data['BsmtFinType2'].fillna('None')","7fd361d7":"#checking BsmtExposure column \ntrain_data['BsmtExposure'].unique()","52609a4a":"#replace the missing value in BsmtExposure with none \ntrain_data['BsmtExposure']=train_data['BsmtExposure'].fillna('None')","e0e44df7":"#checking BsmtCond column\ntrain_data['BsmtCond'].unique()","6e30b56a":"#replace the missing value in BsmtCond to None \ntrain_data['BsmtCond']=train_data['BsmtCond'].fillna('BsmtCond')","aa614508":"#checking BsmtQual column \ntrain_data['BsmtQual'].unique()","e6841e30":"#replace the missing value in BsmtQual to None \ntrain_data['BsmtQual']=train_data['BsmtQual'].fillna('None')","91c9b216":"#checking MasVnrArea column \ntrain_data['MasVnrArea'].unique()","aac03012":"#replace the missing value with its median \ntrain_data['MasVnrArea']=train_data['MasVnrArea'].fillna(train_data['MasVnrArea'].median())","8fa334ec":"#checking column MasVnrType \ntrain_data['MasVnrType'].unique()","25a80a43":"#replace missing values in MasVnrType with None \ntrain_data['MasVnrType']=train_data['MasVnrType'].fillna('None')","2786ead0":"#checking electrical column \ntrain_data['Electrical'].unique()","340ac6a3":"#replace missing vanlue in Electrical with None \ntrain_data['Electrical']=train_data['Electrical'].fillna('None')","9479a1cd":"train_data.drop(['PoolQC_ismissing','MiscFeature_ismissing','Fence_ismissing'], axis=1)","bf3b81a0":"test_data.drop(['Alley','PoolQC','MiscFeature','Fence'],axis=1)","dbb98702":"#Converting String into Number\nnew_train_data=train_data.apply(lambda x:pd.factorize(x)[0])\ntest_data=test_data.apply(lambda x:pd.factorize(x)[0])\n\n#droping columns \nX_test = test_data.drop(['Id'], axis=1).values","76aa7e6e":"#feature selection and spliting of data \nfrom sklearn.model_selection import train_test_split\nx_var=train_data[['LotArea','MasVnrArea','BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF']].values\ny_var=train_data['SalePrice'].values\n\nX_train, X_test,y_train,y_test= train_test_split(x_var,y_var,test_size=0.4,random_state=1301)\n\nprint('X_train samples : ', X_train[0:5])\nprint('X_test samples : ', X_test[0:5])\nprint('y_train samples : ', y_train[0:5])\nprint('y_test samples : ', y_test[0:5])\n","b009cd7d":"#modeling \nfrom statistics import variance\nfrom fractions import Fraction as fr\nimport statistics\n\ntest_id=test_data['Id']\n\n\n#.RandomForest\nRandomForest=RandomForestRegressor(n_estimators=50)\nRandomForest.fit(X_train,y_train)\nRandomForest_predict=RandomForest.predict(X_test)\nprint(\"Random Forest Model Score: \",RandomForest.score(X_train,y_train))\n\n#.LinearRegression\nols=LinearRegression()\nols.fit(X_train,y_train)\nols_predict=ols.predict(X_test)\nprint(\"Linear Model score: \", ols.score(X_train,y_train))\n\n#.Ridge\nridge=Ridge(alpha=0.5)\nridge.fit(X_train,y_train)\nridge_predict=ridge.predict(X_test)\nprint(\"Ridge Model Score: \", ridge.score(X_train,y_train))\n\n#.lasso\nlasso=Lasso(alpha=0.01)\nlasso.fit(X_train,y_train)\nlasso_predict=lasso.predict(X_test)\nprint(\"Lasso Model Score: \", lasso.score(X_train,y_train))\n\n\n#Elasticnet\nen = ElasticNet(alpha = 0.01)\nen.fit(X_train, y_train)\nen_predict = en.predict(X_test)\nprint(\"Elastic Net Model Score: \",en.score(X_train,y_train))","4f53c112":"x_reshape=X_test.flatten()","2a02b935":"x_reshape.shape, X_test.shape","cec44ff4":"print(x_reshape[:20])\nprint(X_test[:20])","83c3c69a":"en_output= pd.DataFrame({'Id':X_test[:,0],'SalePrice':en_predict})\nprint(en_output)","c7dd12ac":"lasso_output= pd.DataFrame({'Id':X_test[:,0], 'SalePrice': lasso_predict})\nprint(lasso_output)","f68b0e2d":"ridge_output= pd.DataFrame({'Id':X_test[:,0], 'SalePrice':ridge_predict})\nprint(ridge_output)","fa2a928b":"linear_output= pd.DataFrame({'Id':X_test[:,0], 'SalePrice':ols_predict})\nprint(linear_output)","de612ee5":"RandomForest_output = pd.DataFrame({'Id':X_test[:,0], 'SalePrice': RandomForest_predict})\nprint(RandomForest_output)","3c7d7e22":"Y_predict=RandomForest.predict(X_test)","f2b8e59c":"sample_sub= pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsample_sub.head()","25b68671":"**Missing Data Histogram ****","224ab611":"**Dataframe to store Id and prediction using RandomForest Regression****","23608ff6":"**Dataframe to store Id and prediction using Linear Regression****","34ca0022":"> **Cleaning of data inorder to sort and replace the missing values in data ****","7e117fde":"now we have droped all the duplicates ","093333ab":"Now lets find the missing value of data through percentage list method ","2691e96e":"The very first step of training of data is data cleaning , we find many of data sets with blank and empty values for those datasets we need to clean the data inorder to place a categorical values in those empty spaces depending upon the numerical data for that ","44a9f3b4":"the above chart shows the missing values of first 30 features of train data set. where the horizontal access shows the feature name and vertical access shows the number of rows\/columns. Here the yellow color shows missing data and blue colour otherwise.\nThe above heatmap shows that Alley has most missing values and uncleaned data and MsZoning have missing values but comparitively less Uncleaned data than Alley","95bee6e9":"some datasets have uninformative\/repetative information which needs to be removed. lets find out how many features have repetitive data. now lets find out how many rows have duplicate features","ec5eedac":"**Missing Data Percentage List**** ","d62ea7e7":"**Dataframe to store Id and prediction using Lasso Regression********","7bd35adc":"**Irregular Data outliers****","618b1934":"> **Missing data in heat map ****","8c870dda":"importing libraries ","4cb9cff3":"**Dataframe to store Id and prediction using Ridge Regression****","496e9476":"> ***Training Data***","97c52e63":"**DataFrame to store Id with predition of Elastic Net****","dab4ac14":"> **Modelling of data****","7102b8cd":"lets drop the duplicate based on its key feature "}}