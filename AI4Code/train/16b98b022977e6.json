{"cell_type":{"76b9d21b":"code","a7703219":"code","d3f8f3d5":"code","5c0f9699":"code","0ad0f36b":"code","5ace6594":"code","1dab439f":"code","3c4a00de":"code","1e5d248e":"code","e094da78":"code","9f359fd0":"code","b6b4b529":"code","80245e3c":"code","1ea1138f":"code","37634a30":"code","76c46c88":"code","00baf1f0":"code","f27ebfb2":"code","d9e4dc8f":"code","a7d68716":"code","780c621c":"code","a3924969":"markdown"},"source":{"76b9d21b":"import tensorflow as tf\ntf.__version__","a7703219":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import mobilenet, resnet_v2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\ndataset_path = Path(\"..\/input\/common-mobile-web-app-icons\/\")","d3f8f3d5":"# include in svg file\nimage_paths = [path for path in dataset_path.glob(\"*\/*.jpg\")]","5c0f9699":"len(image_paths)","0ad0f36b":"[path for path in dataset_path.glob(\"*\/*.svg\")]","5ace6594":"x_col_name = \"image_path\"\ny_col_name = \"class\"\ndf = pd.DataFrame({x_col_name: image_paths})\ndf[y_col_name] = df[x_col_name].map(lambda x: x.parent.stem)\ndf[x_col_name] = df[x_col_name].map(lambda x: str(x))","1dab439f":"df.head()","3c4a00de":"# common using mobile app UI labels\nUSE_LABELS = ['arrow_left', 'notifications', 'play', 'info', 'mail',\n              'globe', 'upload', 'music', 'close', 'user', 'settings', 'home',\n              'fast_forward', 'trash', 'question', 'map', 'eye', 'check_mark',\n              'sort', 'overflow_menu', 'minimize', 'save', 'delete',\n              'maximize', 'download', 'share', 'external_link', 'thumbs_up',\n              'search', 'arrow_right', 'crop', 'camera', 'refresh', 'add',\n              'volume', 'favorite', 'menu', 'edit', 'fab', 'link', 'arrow_up',\n              'arrow_down', 'tag', 'warning', 'bookmark', 'cart', 'cloud',\n              'filter', '_negative']","1e5d248e":"labels = set(df[y_col_name].unique()).difference(set(USE_LABELS))\ndrop_indexes = pd.Index([])\nfor label in labels:\n    drop_index = df[df[y_col_name] == label].index\n    drop_indexes = drop_indexes.union(drop_index)","e094da78":"df.drop(index=drop_indexes, inplace=True)","9f359fd0":"df.shape","b6b4b529":"test_size = 0.2\nrandom_state = 1234\nx_train, x_val, y_train, y_val = train_test_split(df[x_col_name], df[y_col_name],\n                                                      test_size=test_size,\n                                                      shuffle=True,\n                                                      random_state=random_state,\n                                                      stratify=df[y_col_name])","80245e3c":"num_classes = len(df[y_col_name].unique())\nnum_classes","1ea1138f":"def plot_history(history):\n    # Plot training & validation accuracy values\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()","37634a30":"def build_model(base_model, n_classes):\n#     base_model.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.25)(x)\n    x = Dense(512, activation=\"relu\")(x)\n    x = Dropout(0.25)(x)\n    y = Dense(n_classes, activation=\"softmax\")(x)\n\n    model = Model(inputs=base_model.input,\n                  outputs=y)\n    return model","76c46c88":"width, height = 224, 224\ntarget_size = (height, width)\nnum_channels = 3\ninput_shapes = (height, width, num_channels)\nepochs = 10\nlr = 0.0001\nbatch_size = 64\nopt = optimizers.Adam(lr=lr)","00baf1f0":"base_model = resnet_v2.ResNet101V2(include_top=False,\n                                   weights='imagenet',\n                                   input_shape=input_shapes)","f27ebfb2":"model = build_model(base_model, num_classes)\nmodel.summary()","d9e4dc8f":"filepath = \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\ncallbacks = [ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)]","a7d68716":"train_gen = ImageDataGenerator(rotation_range=45,\n                               width_shift_range=.15,\n                               height_shift_range=.15,\n                               horizontal_flip=True,\n                               zoom_range=0.5,\n                               preprocessing_function=resnet_v2.preprocess_input)\ntrain_generator = train_gen.flow_from_dataframe(\n        pd.concat([x_train, y_train],\n                  axis=1),\n        x_col=x_col_name,\n        y_col=y_col_name,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='training')\nvalid_gen = ImageDataGenerator(preprocessing_function=resnet_v2.preprocess_input)\nvalid_generator = valid_gen.flow_from_dataframe(pd.concat([x_val, y_val],\n                                                              axis=1),\n                                                    x_col=x_col_name,\n                                                    y_col=y_col_name,\n                                                    target_size=target_size,\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical',\n                                                    subset='training')\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nSTEP_SIZE_TRAIN = train_generator.n \/\/ train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n \/\/ valid_generator.batch_size\n\nhistory = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=STEP_SIZE_TRAIN,\n                              validation_data=valid_generator,\n                              validation_steps=STEP_SIZE_VALID,\n                              epochs=epochs,\n                              callbacks=callbacks)","780c621c":"plot_history(history)","a3924969":"EDA is this [Link](https:\/\/www.kaggle.com\/wakamezake\/mobile-web-app-icons-eda)\n\n## References\n- [Github - testdotai\/classifier-builder](https:\/\/github.com\/testdotai\/classifier-builder)\n- [Kaggle - mobile-web-app-icons-eda](https:\/\/www.kaggle.com\/wakamezake\/mobile-web-app-icons-eda)\n- Keras\n  - [Github keras_applications\/mobilenet.py](https:\/\/github.com\/keras-team\/keras-applications\/blob\/master\/keras_applications\/mobilenet.py)"}}