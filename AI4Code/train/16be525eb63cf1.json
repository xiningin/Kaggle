{"cell_type":{"77abdf24":"code","f75296fc":"code","7486170c":"code","ec25d4ed":"code","d3ecbe78":"code","12848992":"code","d77914d8":"code","2d90d22c":"code","12aad2f7":"code","9bdb7284":"code","785d9066":"code","4ed59957":"code","16fe96e7":"code","8959290e":"code","1bcb64cd":"code","c1532db8":"code","c2e0968f":"code","9a9684bd":"code","c9c373b0":"code","e6939fea":"code","ba28e649":"code","4abcde09":"code","f24f320c":"code","425351f9":"code","32d7a148":"code","e5710aae":"code","eed2954d":"code","a0313960":"code","f6001636":"code","404a0d58":"code","a13c097a":"code","2d5a8f30":"markdown","7e09552e":"markdown","3a59293e":"markdown","fd0b7e21":"markdown","5fae262e":"markdown","deecc13b":"markdown","1343e7d5":"markdown","b8653534":"markdown","4a02c669":"markdown","03a83d57":"markdown"},"source":{"77abdf24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f75296fc":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom scipy.sparse import vstack\nimport datetime\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom scipy.sparse import hstack\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7486170c":"data_file = pd.read_csv('\/kaggle\/input\/phishing-data\/combined_dataset.csv')","ec25d4ed":"data_file.head(5)","d3ecbe78":"#Checking for null values\ndata_file.isna().any()","12848992":"#Checking the distribution of data\nprint(data_file['label'].value_counts())\nprint(data_file.shape)","d77914d8":"\ndef remove_characters(row):\n    chars = re.escape(string.punctuation)\n    return re.sub(r'['+chars+']', ' ',row)\n\ndata_file['domain'] = data_file['domain'].apply(remove_characters)","2d90d22c":"data_file.head(5)","12aad2f7":"#Creating string for Wordcloud of 'domain' tokens\ncomment_words = '' \nstopwords = set(STOPWORDS) \nfor val in data_file['domain']: \n      \n    # typecaste each val to string \n    val = str(val) \n  \n    # split the value \n    tokens = val.split() \n      \n    # Converts each token into lowercase \n    for i in range(len(tokens)): \n        tokens[i] = tokens[i].lower() \n      \n    comment_words += \" \".join(tokens)+\" \"\n  \nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords=stopwords,\n                min_font_size = 10).generate(comment_words)","9bdb7284":"# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)\nplt.show() ","785d9066":"data_file.shape","4ed59957":"data_file_x = data_file.drop(['label'], axis=1)\ndata_file_y = data_file['label']","16fe96e7":"#Dividing the dataset into train, val and test datasets\ntrain_df_x = data_file_x[:60000]\ntrain_df_y = data_file_y[:60000]\nval_df_x = data_file_x[60000:78000]\nval_df_y = data_file_y[60000:78000]\ntest_df_x = data_file_x[78000:]\ntest_df_y = data_file_y[78000:]","8959290e":"train_domain = train_df_x['domain']\nval_domain = val_df_x['domain']\ntest_domain = test_df_x['domain']","1bcb64cd":"#Drop 'domain' from dataset since we are converting it into bag of words\ntrain_df_x = train_df_x.drop(['domain'], axis=1)\nval_df_x = val_df_x.drop(['domain'], axis=1)\ntest_df_x = test_df_x.drop(['domain'], axis=1)","c1532db8":"print(train_df_x.shape, val_df_x.shape, test_df_x.shape)\nprint(train_df_y.shape, val_df_y.shape, test_df_y.shape)","c2e0968f":"count_vect = CountVectorizer()\nX_train_bow = count_vect.fit_transform(train_domain)\nX_val_bow = count_vect.transform(val_domain)\nX_test_bow = count_vect.transform(test_domain)\nfeature_names_bow = count_vect.get_feature_names()\nprint(X_train_bow.shape)\nprint(X_val_bow.shape)\nprint(X_test_bow.shape)","9a9684bd":"#Stacking the BoW features and other features from dataset\nbow_final_train_x = hstack((X_train_bow, train_df_x))\nbow_final_val_x = hstack((X_val_bow, val_df_x))\nbow_final_test_x = hstack((X_test_bow, test_df_x))","c9c373b0":"#Final shape of dataset will be 75926 features of domain plus 10 features of dataset. Therefore 75936 features\nbow_final_train_x.shape\nbow_final_val_x.shape\nbow_final_test_x.shape","e6939fea":"X_train_val = vstack((bow_final_train_x, bow_final_val_x))\nY_train_val = pd.concat([train_df_y, val_df_y], axis= 0)","ba28e649":"param_grid = {\n 'max_depth': [4, 8, 16, 32],\n 'n_estimators': [1, 2, 5, 10, 50, 100, 200]\n}\nt1 = datetime.datetime.now()\nrf = RandomForestClassifier(n_jobs=-1)\nclf = GridSearchCV(estimator = rf, param_grid = param_grid, scoring = 'roc_auc')\nclf.fit(X_train_val,Y_train_val)\nprint(\"time required = \", datetime.datetime.now() - t1)","4abcde09":"clf.best_params_","f24f320c":"rf_clf = RandomForestClassifier(max_depth = clf.best_params_['max_depth'], \n                                n_estimators=clf.best_params_['n_estimators'])\nrf_clf.fit(X_train_val,Y_train_val)\nbow_test_proba = rf_clf.predict_proba(bow_final_test_x)\nbow_train_proba = rf_clf.predict_proba(X_train_val)\nprint(\"Train proba\", bow_train_proba)\nprint(\"Test proba\", bow_test_proba)","425351f9":"print(\"Top 20 Important Features\")\nd = sorted(list(zip(count_vect.get_feature_names(), rf_clf.feature_importances_ )), key=lambda x: x[1], reverse=True)[:20]\nfeatures_list = []\nfor (i,j) in d:\n    features_list.append(i)\nprint(features_list)","32d7a148":"#calculatinf the AUC\nbow_fpr_train, bow_tpr_train, _ = roc_curve(Y_train_val, bow_train_proba[:, 1])\nbow_fpr_test, bow_tpr_test, _ = roc_curve(test_df_y, bow_test_proba[:, 1])\nbow_test_auc = auc(bow_fpr_test, bow_tpr_test)\nbow_train_auc = auc(bow_fpr_train, bow_tpr_train)\nprint(\"Train AUC\", bow_train_auc)\nprint(\"Test AUC\", bow_test_auc)","e5710aae":"import pylab\nplt.figure(figsize=(13, 10))\nplt.plot([0,1], [0,1], color='black', lw=2, linestyle='--')\nplt.plot(bow_fpr_test, bow_tpr_test, label=\"Test, auc=\"+str(bow_test_auc), color = 'red')\nplt.plot(bow_fpr_train, bow_tpr_train, label=\"Train, auc=\"+str(bow_train_auc), color = 'green')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\n\nplt.show()","eed2954d":"#Making predictions\nbow_test_conf = rf_clf.predict(bow_final_test_x)\nbow_train_conf = rf_clf.predict(X_train_val)","a0313960":"#Confusion Matrix and classification report\nbow_train_conf_matrix = confusion_matrix(Y_train_val, bow_train_conf)\nbow_test_conf_matrix = confusion_matrix(test_df_y, bow_test_conf)\nclass_report = classification_report(test_df_y, bow_test_conf)\nprint(bow_test_conf_matrix)\nprint(class_report)","f6001636":"ax= plt.subplot()\nsns.heatmap(bow_train_conf_matrix, annot=True, ax = ax, fmt='g')\nax.set_ylabel('Predicted labels')\nax.set_xlabel('True labels')\nax.set_title('Train Confusion Matrix') \nax.xaxis.set_ticklabels(['negative', 'positive']) \nax.yaxis.set_ticklabels(['negative', 'positive'])","404a0d58":"ax= plt.subplot()\nsns.heatmap(bow_test_conf_matrix, annot=True, ax = ax, fmt='g')\nax.set_ylabel('Predicted labels')\nax.set_xlabel('True labels')\nax.set_title('Train Confusion Matrix') \nax.xaxis.set_ticklabels(['negative', 'positive']) \nax.yaxis.set_ticklabels(['negative', 'positive'])","a13c097a":"from prettytable import PrettyTable\n    \nx = PrettyTable()\nx.field_names = [\"Algorithm\", \"Max_depth\", \"n_estimators\",  \"Vectorizer\", \"Train\", \"Test\"]\n\nx.add_row([\"Random Forest\", 32, 200, \"BoW\", 0.98914, 0.9875])\nprint(x)","2d5a8f30":"# Cleaning and preprocessing of Questions","7e09552e":"### Random Forest on Bag Of Words dataset","3a59293e":"1. Remove Spcial characters from domain and space in between them\n2. Convert all the characters into small letters","fd0b7e21":"Please Upvote if you like my work.","5fae262e":"### Preprocessing","deecc13b":"# Dataset","1343e7d5":"# Dataset\n\n1. Domain: The URL itself.\n2. Ranking: Page Ranking\n3. isIp: Is there an IP address in the weblink\n4. valid: This data is fetched from google's whois API that tells us more about the current\nstatus of the URL's registration.\n5. activeDuration: Also from whois API. Gives the duration of the time since the\nregistration up until now.\n6. urlLen: It is simply the length of the URL\n7. is@: If the link has a '@' character then it's value = 1\n8. isredirect: If the link has double dashes, there is a chance that it is a redirect. 1-> multiple\ndashes present together.\n9. haveDash: If there are any dashes in the domain name.\n10. domainLen: The length of just the domain name.\n11. noOfSubdomain: The number of subdomains preset in the URL.\n12. Labels: 0 -> Legitimate website , 1 -> Phishing Link\/ Spam Link","b8653534":"### Test Confusion Matrix","4a02c669":"### Train Confusion Matrix","03a83d57":"### Bag Of Words"}}