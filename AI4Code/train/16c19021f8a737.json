{"cell_type":{"13ba996c":"code","d29b5e52":"code","4c1861ba":"code","6fdae9ef":"code","43cc37db":"code","7ac712cb":"code","40849c25":"code","f53a6d38":"code","ac27a27d":"code","f625feb9":"code","0c3dae47":"code","ebdf0274":"code","30ed82c4":"code","c2896e89":"code","f108238e":"code","85283c76":"code","799f6406":"code","4d76fae1":"code","fbfffdc8":"code","831173b2":"code","a10c79cb":"code","8b4ae4a5":"code","7befb2cf":"code","55b30079":"code","45a177cb":"code","11347153":"code","e22a6fcc":"code","64015c3c":"code","ce723944":"code","dd5bc8a1":"code","2f10d981":"code","20a6f264":"code","f77a9701":"code","267163e7":"code","c77c0c4a":"code","413ac37b":"code","ad228e0c":"code","a9e27e02":"code","582a9110":"code","f254d126":"code","b5accb0c":"code","b3303bd1":"code","0e5a14d3":"code","a32de578":"code","771afb71":"code","c176a6c9":"code","ece7cb36":"code","6bbadfe1":"code","5be728ca":"code","fdf4ec18":"code","b3f34dc2":"code","cad06097":"code","d5d1c049":"code","97cfd646":"code","73da5cea":"code","628ecd6e":"code","f1ec4353":"code","e53bdbb7":"code","2b4d2efb":"code","70064de5":"code","ebae549b":"code","587a6185":"code","bf4466ba":"code","8d694d08":"code","0e843b93":"code","c6fd772d":"code","24962e55":"code","2c4b445d":"code","c83a590e":"code","1e50869e":"code","20497dd9":"code","84678973":"code","b4d572a9":"code","3f4f73db":"code","3762d4e2":"code","7c831a67":"code","17ca6361":"code","9a8726f3":"code","bc722525":"code","f67238e8":"code","cf83a9b0":"code","0f03dcf3":"code","d6cc81d8":"code","269a16e8":"code","4dbb8c6a":"code","b8d063e3":"code","22726cc8":"code","940549da":"code","2a810e59":"code","0431f906":"code","077f54f9":"code","0005a16b":"code","e9ea5c30":"code","e5eff471":"code","ed4546e8":"code","56ec4c34":"code","3a652c00":"code","dfa22ccb":"code","21bda7f1":"code","d4ef3c01":"code","a39d0101":"code","9352b26f":"code","78d9e67e":"code","5c64e6b7":"code","dd050a7f":"code","7e6c37c6":"code","c5fb7627":"code","d18c74cc":"code","4139b989":"code","219eff06":"code","c61a8489":"code","40228950":"code","e5a3eeb8":"code","344f417c":"markdown","37b940bd":"markdown","f164a021":"markdown","d43e2365":"markdown","d54503ea":"markdown","1cd54604":"markdown","b6fae13b":"markdown","a7598ba1":"markdown","0a38af27":"markdown","792ddb41":"markdown","e5f3dc95":"markdown","84347a5e":"markdown","1ecb9f39":"markdown","4fdf4571":"markdown","b8663ca1":"markdown","a741fdcf":"markdown","bd07deb8":"markdown","d5f21230":"markdown","c46d638d":"markdown","1882e7b2":"markdown","ed8bcd48":"markdown","3aff45d3":"markdown","eac1367f":"markdown","f1c6f229":"markdown","1d83f2ea":"markdown","5b0fb168":"markdown","f05e19ba":"markdown","364f5d47":"markdown","e82b1d13":"markdown","1ab455a4":"markdown","21dea2dd":"markdown","94f15806":"markdown","c31041ff":"markdown","9185daf6":"markdown","2f7c2332":"markdown","9d0eb060":"markdown","57333032":"markdown","25542a15":"markdown","7eb8f788":"markdown","86e22591":"markdown","df68338a":"markdown","de3cfdaf":"markdown","23485921":"markdown","7f7b90c9":"markdown","a47c2d42":"markdown","13962266":"markdown","4123518a":"markdown","240a0074":"markdown","59f372df":"markdown","77a1298c":"markdown","5a857863":"markdown","433a63be":"markdown","afdb9438":"markdown","3ebe76c2":"markdown","099dfff6":"markdown","18cff7b8":"markdown","fc96931c":"markdown","c52707bb":"markdown","6789e455":"markdown","ab462235":"markdown","b9c71b75":"markdown","89a7a960":"markdown","9994e0b4":"markdown","10ae8da7":"markdown","c2ea1ecb":"markdown","fc6005f2":"markdown","7ed795de":"markdown","b23600a4":"markdown","4d1f884d":"markdown","a386c922":"markdown","466b629b":"markdown","2e423c3d":"markdown","166e3c97":"markdown","f625bb79":"markdown","2ee694f0":"markdown","9e30a714":"markdown","bf581131":"markdown","085f7938":"markdown","fbf3519c":"markdown","32bd471b":"markdown","db0e2567":"markdown","75479047":"markdown","7accaee2":"markdown","a2a0b382":"markdown","15d45f7e":"markdown","d2e0094b":"markdown","ff91ee1d":"markdown","3a988572":"markdown","65b3ba29":"markdown","fea935ce":"markdown","9328cfbd":"markdown","2a2771b0":"markdown","1f936ac6":"markdown","86d935c3":"markdown","da63eb22":"markdown","257ac4db":"markdown","3bbf895a":"markdown","83ca7e0f":"markdown","28b13e4e":"markdown","ef2a58d0":"markdown","68b895f2":"markdown","c584ee5c":"markdown","915e280c":"markdown","4fb25447":"markdown","23c71ca6":"markdown","05622ab4":"markdown","977a71fe":"markdown","c35bbe82":"markdown","1d7fbda2":"markdown","369dceb0":"markdown"},"source":{"13ba996c":"from IPython.display import Image\nImage(\"..\/input\/images\/flatten-the-curve.png\")","d29b5e52":"### Load packages\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport numpy\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn import metrics\nfrom sklearn import svm\n%matplotlib inline\n\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.set_palette(\"husl\")\n\n\n#Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\n#metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, make_scorer\n\n#feature selection\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn import model_selection\n\n#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestRegressor\n\n#Regression\nfrom sklearn.linear_model import LogisticRegression, BayesianRidge, LinearRegression\nfrom sklearn import metrics\nimport statsmodels.api as sm\n\n#logistic curve\nfrom scipy.optimize import curve_fit\n\n#LDA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\n#seed\nimport random\n\n# Normalizing continuous variables\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n# Visualization\n\n## Bokeh\nfrom bokeh.plotting import output_notebook, figure, show\nfrom bokeh.models import ColumnDataSource, Div, Select, Button, ColorBar, CustomJS\nfrom bokeh.layouts import row, column, layout\nfrom bokeh.transform import cumsum, linear_cmap\nfrom bokeh.palettes import Blues8, Spectral3\nfrom bokeh.plotting import figure, output_file, show\n\n## Plotly\nfrom plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\n\nfrom matplotlib import dates\nimport plotly.graph_objects as go\n\n# Time series\nfrom fbprophet import Prophet\nimport datetime\nfrom datetime import datetime\n\n# Google BigQuery\nfrom google.cloud import bigquery\n\n#import cdist\nfrom scipy.spatial.distance import cdist\n\n# to solve SEIR\nfrom scipy.integrate import solve_ivp\n\n#others\nfrom pathlib import Path\nimport os\nfrom tqdm.notebook import tqdm\nfrom scipy.optimize import minimize\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error\nfrom matplotlib import dates\nimport plotly.graph_objects as go\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\n\n","4c1861ba":"### Load in the data from Kaggle Week 2\n\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/train.csv\",parse_dates=['Date'])\n                    \ntrain.tail()","6fdae9ef":"train.info()","43cc37db":"# Test dataset from Kaggle\n\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/test.csv\",parse_dates=['Date'])\n                    \ntest.tail()\n","7ac712cb":"submit = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/submission.csv\")\n                     \nsubmit.head()","40849c25":"#read the complete data set\n\ncomplete_data = pd.read_csv('..\/input\/corona-virus-report\/covid_19_clean_complete.csv', parse_dates=['Date'])\n\ncomplete_data = complete_data.rename(columns = {'Province\/State': 'Province_State', 'Country\/Region': 'Country_Region'})\n\ncomplete_data['Active'] = complete_data['Confirmed'] - complete_data['Deaths'] - complete_data['Recovered']\n\ncomplete_data.sort_values(by=['Date','Confirmed'], ascending=False).head()\n","f53a6d38":"complete_data.info()","ac27a27d":"#read the demographic data\n\ndemo_data = pd.read_csv('..\/input\/countryinfo\/covid19countryinfo.csv')\n\ndemo_data['pop']=demo_data['pop'].str.replace(',', '').astype('float')\n\ndemo_data['healthexp']=demo_data['healthexp'].str.replace(',', '').astype('float')\n\n\ndemo_data.head()","f625feb9":"pop_info = pd.read_csv('..\/input\/covid19-population-data\/population_data.csv')\n\npop_info.head()","0c3dae47":"# Weather data\nweather_data = pd.read_csv(\"..\/input\/weatherweek4\/training_data_with_weather_info_week_4.csv\", parse_dates=['Date'])\nweather_test = pd.read_csv(\"..\/input\/weatherweek4\/testing_data_with_weather_info_week_4.csv\", parse_dates=['Date'])\n","ebdf0274":"weather_data.info()","30ed82c4":"\nweather_data.head()\n","c2896e89":"\nweather_data = weather_data.replace(9999.9,np.NaN)\n\nweather_data = weather_data.replace(999.9,np.NaN)\n\nweather_data = weather_data.replace(99.99,np.NaN)\n\nweather_data.head()\n","f108238e":"#interpolate missing value with linear method\n\nweather_data['stp'] = weather_data['stp'].interpolate(method ='linear', limit_direction ='both') \nweather_data['wdsp'] = weather_data['wdsp'].interpolate(method ='linear', limit_direction ='both') \nweather_data['prcp'] = weather_data['prcp'].interpolate(method ='linear', limit_direction ='both') \n\nweather_data.sort_values(['Date']).tail()\n","85283c76":"## From @winterpierre source\n\nweather_addition = pd.read_csv(\"..\/input\/covid19-global-weather-data\/temperature_dataframe.csv\", parse_dates=['date'])\n\n#rename column\nweather_addition.columns = ['Unnamed: 0', 'Id', 'Province_State', 'Country_Region', 'lat', 'long', 'Date',\n       'ConfirmedCases', 'Fatalities', 'capital', 'humidity', 'sunHour', 'tempC',\n       'windspeedKmph']\n\n#fix the name US for consistency\nweather_addition = weather_addition.replace('USA','US')\n\nweather_addition.head()\n","799f6406":"\nlockdown = pd.read_csv('..\/input\/covid19-lockdown-dates-by-country\/countryLockdowndates.csv', parse_dates=['Date'])\n\nlockdown = lockdown.replace(pd.to_datetime('2020-11-03'),pd.to_datetime('2020-03-11'))\n\n\nlockdown.head()\n","4d76fae1":"\nhigh_risk_eu = ['Germany','Spain','Italy','France']\n\nlockdown1 = lockdown.loc[lockdown['Country\/Region'].isin(high_risk_eu)==True]\n\nlockdown1.sort_values(['Date'])\n","fbfffdc8":"high_risk_us = ['US']\n\nlockdown2 = lockdown.loc[lockdown['Country\/Region'].isin(high_risk_us)==True]\n\nlockdown2.sort_values(['Date'])\n","831173b2":"high_risk_us = ['Iran','Turkey','Russia','India','Korea, South']\n\nlockdown3 = lockdown.loc[lockdown['Country\/Region'].isin(high_risk_us)==True]\n\nlockdown3\n","a10c79cb":"test_conduct = pd.read_csv('..\/input\/covid19-tests-conducted-by-country\/Tests_Conducted_31Mar2020.csv')\n\ntest_conduct.head()","8b4ae4a5":"# case \ncase = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Formula: Active Case = Confirmed - Deaths - Recovered\ncomplete_data['Active'] = complete_data['Confirmed'] - complete_data['Deaths'] - complete_data['Recovered']\n\n# impute missing values \ncomplete_data[['Province_State']] = complete_data[['Province_State']].fillna('')\ncomplete_data[case] = complete_data[case].fillna(0)\n\ncomplete_data.sort_values(by=['Date','Confirmed'], ascending=False).head()\n","7befb2cf":"complete_data.sort_values(by=['Date'], ascending=False).tail()","55b30079":"map_covid = train.groupby(['Date', 'Country_Region'])['ConfirmedCases'].sum().reset_index()\nmap_covid['Date'] = map_covid['Date'].dt.strftime('%m\/%d\/%Y')\nmap_covid['size'] = map_covid['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(map_covid, locations=\"Country_Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Confirmed Cases Around the Globe', color_continuous_scale=\"tealrose\")\nfig.show()\n","45a177cb":"regions =pd.DataFrame()\n\nregions['Country'] = map_covid[\"Country_Region\"]\nregions['Confirmed Cases'] = map_covid[\"ConfirmedCases\"]\n\nfig = px.choropleth(regions, locations='Country',\n                    locationmode='country names',\n                    color=\"Confirmed Cases\",color_continuous_scale=\"tealrose\")\n\nfig.update_layout(title=\"COVID19 Confirmed Cases Globally\")\n\nfig.show()\n","11347153":"# sum of all Confirmed cases by country as of March 26\nsum_confirm = pd.DataFrame(complete_data.loc[complete_data['Date']==complete_data['Date'].max()].groupby(\n    ['Country_Region'])['Confirmed'].sum()).reset_index()\n\n# sum of all Death cases by country as of March 26\nsum_death = pd.DataFrame(complete_data.loc[complete_data['Date']==complete_data['Date'].max()].groupby(\n    ['Country_Region'])['Deaths'].sum()).reset_index()\n\n# sum of all Recovered cases by country as of March 26\nsum_recover = pd.DataFrame(complete_data.loc[complete_data['Date']==complete_data['Date'].max()].groupby(\n    ['Country_Region'])['Recovered'].sum()).reset_index()\n\n# sum of all Active cases by country as of March 26\nsum_active = pd.DataFrame(complete_data.loc[complete_data['Date']==complete_data['Date'].max()].groupby(\n    ['Country_Region'])['Active'].sum()).reset_index()\n","e22a6fcc":"sns.set(rc={'figure.figsize':(15, 7)})\n\ntop20_confirm = sum_confirm.sort_values(by=['Confirmed'], ascending=False).head(20)\n\nplot1 = sns.barplot(x=\"Confirmed\",y=\"Country_Region\", data=top20_confirm)\n\nplt.title(\"Total Numbers of Confirmed Cases\",fontsize=20)\n\nfor p in plot1.patches:\n    width = p.get_width()\n    plot1.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")","64015c3c":"top20_confirm['Country_Region'].unique()","ce723944":"\ntop20_death = sum_death.sort_values(by=['Deaths'], ascending=False).head(20)\n\nplot2 = sns.barplot(x=\"Deaths\",y=\"Country_Region\", data=top20_death)\n\nplt.title(\"Total Numbers of Fatal Cases\",fontsize=20)\n\nfor p in plot2.patches:\n    width = p.get_width()\n    plot2.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")","dd5bc8a1":"top20_recover = sum_recover.sort_values(by=['Recovered'], ascending=False).head(20)\n\nplot3 = sns.barplot(x=\"Recovered\",y=\"Country_Region\", data=top20_recover)\n\nplt.title(\"Total Numbers of Recovered Cases\",fontsize=20)\n\nfor p in plot3.patches:\n    width = p.get_width()\n    plot3.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")","2f10d981":"top20_active = sum_active.sort_values(by=['Active'], ascending=False).head(20)\n\nplot4 = sns.barplot(x=\"Active\",y=\"Country_Region\", data=top20_active)\n\nplt.title(\"Total Numbers of Active Cases\",fontsize=20)\n\nfor p in plot4.patches:\n    width = p.get_width()\n    plot4.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")","20a6f264":"### Compute day first outbreak for each country\ncomplete_data_first = train.copy()\n\ncountries_array = complete_data_first['Country_Region'].unique()\n\ncomplete_data_first_outbreak = pd.DataFrame()\n\nfor i in countries_array:\n    # get relevant data \n    day_first_outbreak = complete_data_first.loc[complete_data_first['Country_Region']==i]\n    \n    date_outbreak = day_first_outbreak.loc[day_first_outbreak['ConfirmedCases']>0]['Date'].min()\n    \n    #Calculate days since first outbreak happened\n    day_first_outbreak['days_since_first_outbreak'] = (day_first_outbreak['Date'] \n                                                       - date_outbreak).astype('timedelta64[D]')\n    \n    #impute the negative days with 0\n    day_first_outbreak['days_since_first_outbreak'][day_first_outbreak['days_since_first_outbreak']<0] = 0 \n   \n    complete_data_first_outbreak = complete_data_first_outbreak.append(day_first_outbreak,ignore_index=True)\n    \n","f77a9701":"\ncomplete_data_first_outbreak.head()\n","267163e7":"top20_confirm_first = complete_data_first_outbreak.loc[\n    complete_data_first_outbreak['Country_Region'].isin(\n        ['US', 'China', 'Italy', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Korea, South'])==True]\n\ntop20_confirm_first = top20_confirm_first.groupby(['Country_Region','days_since_first_outbreak'])['ConfirmedCases'].sum().reset_index()\n\ntop20_confirm_first['days_since_first_outbreak'] = pd.to_timedelta(\n    top20_confirm_first['days_since_first_outbreak'], unit='D')\n\nsns.lineplot(data=top20_confirm_first, x=\"days_since_first_outbreak\", y=\"ConfirmedCases\", hue=\"Country_Region\")\n\nplt.ylabel(\"Total cases in top 10 countries\")\n\nplt.xlabel(\"Number of days since first outbreak\")\n\n\nplt.title(\"Total numbers of cases since first outbreak in top 10 countries\",fontsize=20)\n\n","c77c0c4a":"\ntime_sum = complete_data.groupby('Date')['Date', 'Confirmed', 'Deaths'].sum().reset_index()\n\ntime_sum = pd.melt(time_sum, id_vars=['Date'], value_vars=['Confirmed','Deaths'])\n\ntime_sum = time_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=time_sum, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total cases\")\n\nplt.title(\"Total numbers of Cases\",fontsize=20)\n","413ac37b":"sns.set(rc={'figure.figsize':(15, 7)})\n\ntime_log = complete_data.groupby('Date')['Date', 'Confirmed', 'Deaths'].sum().reset_index()\n\ntime_log[\"Confirmed\"] = np.log(time_log[\"Confirmed\"])\n\ntime_log[\"Deaths\"] = np.log(time_log[\"Deaths\"])\n\ntime_log = pd.melt(time_log, id_vars=['Date'], value_vars=['Confirmed','Deaths'])\n\ntime_log = time_log.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=time_log, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total Confirmed cases on log scale\")\n\nplt.title(\"Total numbers of Confirmed on log scale\",fontsize=20)\n","ad228e0c":"china_sum = complete_data.loc[complete_data['Country_Region']==\"China\"].groupby('Date')['Date', 'Confirmed','Deaths','Active','Recovered'].sum().reset_index()\n\nchina_sum = pd.melt(china_sum, id_vars=['Date'], value_vars=['Confirmed','Deaths','Active','Recovered'])\n\nchina_sum = china_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=china_sum, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total cases in China\")\n\nplt.title(\"Total numbers of Cases in China\",fontsize=20)\n","a9e27e02":"italy_sum = complete_data.loc[complete_data['Country_Region']==\"Italy\"].groupby('Date')['Date', 'Confirmed','Deaths','Active','Recovered'].sum().reset_index()\n\nitaly_sum = pd.melt(italy_sum, id_vars=['Date'], value_vars=['Confirmed','Deaths','Active','Recovered'])\n\nitaly_sum = italy_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=italy_sum, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total cases in Italy\")\n\nplt.title(\"Total numbers of Cases in Italy\",fontsize=20)\n","582a9110":"spain_sum = complete_data.loc[complete_data['Country_Region']==\"Spain\"].groupby('Date')['Date', 'Confirmed','Deaths','Active','Recovered'].sum().reset_index()\n\nspain_sum = pd.melt(spain_sum, id_vars=['Date'], value_vars=['Confirmed','Deaths','Active','Recovered'])\n\nspain_sum = spain_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=spain_sum, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total cases in Spain\")\n\nplt.title(\"Total numbers of Cases in Spain\",fontsize=20)\n","f254d126":"us_sum = complete_data.loc[complete_data['Country_Region']==\"US\"].groupby('Date')['Date', 'Confirmed','Deaths','Active','Recovered'].sum().reset_index()\n\nus_sum = pd.melt(us_sum, id_vars=['Date'], value_vars=['Confirmed','Deaths','Active','Recovered'])\n\nus_sum = us_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=us_sum, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total cases in the U.S.\")\n\nplt.title(\"Total numbers of Cases in the U.S.\",fontsize=20)\n","b5accb0c":"#Other countries\n\nother_sum = complete_data.loc[complete_data['Country_Region'].isin([\"Italy\",\"China\",\"US\"])==False]\n\nother_sum = other_sum.groupby('Date')['Date', 'Confirmed','Deaths','Active','Recovered'].sum().reset_index()\n\nother_sum = pd.melt(other_sum, id_vars=['Date'], value_vars=['Confirmed','Deaths','Active','Recovered'])\n\nother_sum = other_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nsns.lineplot(data=other_sum, x=\"Date\", y=\"total\", hue=\"Cases\")\n\nplt.ylabel(\"Total cases in other countries\")\n\nplt.title(\"Total numbers of Cases in other countries\",fontsize=20)\n","b3303bd1":"# Countries that are in Europe\n\neurope = ['Austria','Italy','Belgium','Latvia','Bulgaria','Lithuania','Croatia','Luxembourg',\n          'Cyprus','Malta','Czechia','Netherlands','Denmark','Poland','Estonia','Portugal',\n          'Finland','Romania','France','Slovakia','Germany','Slovenia','Greece','Spain',\n          'Hungary','Sweden','Ireland','Switzerland','United Kingdom']\n\neurope_sum = complete_data.loc[complete_data['Country_Region'].isin(europe)==True]\n\neurope_sum.loc[europe_sum['Confirmed']>0].sort_values('Date').head(1)\n","0e5a14d3":"#Plot out the total cases by each country\neurope_sum = europe_sum.loc[complete_data['Date']==complete_data['Date'].max()].groupby(\n    'Country_Region')['Country_Region', 'Confirmed'].sum().reset_index().sort_values('Confirmed',ascending=False)\n\nplot5 = sns.barplot(x=\"Confirmed\",y=\"Country_Region\", data=europe_sum)\n\nplt.title(\"Total Numbers of Confirmed Cases\")\n\nfor p in plot1.patches:\n    width = p.get_width()\n    plot1.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")\n","a32de578":"top10_eu_sum = complete_data.loc[complete_data['Country_Region'].isin(['Italy','Spain','Germany',\n                                                                      'France','United Kingdom',\n                                                                      'Switzerland','Netherlands','Austria',\n                                                                      'Belgium','Portugal'])==True]\n\ntop10_eu_sum1 = top10_eu_sum.groupby(['Country_Region','Date'])['Confirmed'].sum().reset_index()\n\nsns.lineplot(data=top10_eu_sum1, x=\"Date\", y=\"Confirmed\", hue=\"Country_Region\")\n\nplt.ylabel(\"Total cases in Europe countries\")\n\nplt.title(\"Total numbers of Cases in Europe countries\",fontsize=20)\n","771afb71":"top10_eu_sum2 = top10_eu_sum.groupby(['Country_Region','Date'])['Confirmed','Deaths'].sum().reset_index()\n\ntop10_eu_sum2['Fatal_Rate'] = round((top10_eu_sum2['Deaths']\/top10_eu_sum2['Confirmed'])*100,2)\n\nsns.lineplot(data=top10_eu_sum2, x=\"Date\", y=\"Fatal_Rate\", hue=\"Country_Region\")\n\nplt.ylabel(\"Fatality Rate in Europe countries in Percentage\")\n\nplt.title(\"Fatality Rate  in Europe countries\",fontsize=20)","c176a6c9":"top10_eu_sum3 = top10_eu_sum.groupby(['Country_Region','Date'])['Confirmed','Recovered'].sum().reset_index()\n\ntop10_eu_sum3['Recover_Rate'] = round((top10_eu_sum3['Recovered']\/top10_eu_sum3['Confirmed'])*100,2)\n\nsns.lineplot(data=top10_eu_sum3, x=\"Date\", y=\"Recover_Rate\", hue=\"Country_Region\")\n\nplt.ylabel(\"Recovery Rate in Europe countries in Percentage\")\n\nplt.title(\"Recovery Rate  in Europe countries\",fontsize=20)","ece7cb36":"north_america = ['Antigua and Barbuda','Bahamas','Barbados','Belize','Canada','Costa Rica','Cuba','El Salvador',\n                 'Grenada','Guatemala','Hait\u00ed','Honduras','Jamaica','Mexico','Nicaragua','Panama',\n                 'Saint Kitts and Nevis','Saint Lucia','Saint Vincent and the Grenadines','Trinidad and Tobago','US']\n\nna_region_sum = complete_data.loc[complete_data['Country_Region'].isin(north_america)==True]\n\nna_region_sum.loc[na_region_sum['Confirmed']>0].sort_values('Date').head(1)\n","6bbadfe1":"# plot the total of US\nus_region_sum = train.loc[train['Country_Region'] == \"US\"]\n\nus_region_sum1 = us_region_sum.loc[us_region_sum['Date']==train['Date'].max()].groupby(\n    ['Province_State'])['ConfirmedCases'].sum().reset_index().sort_values('ConfirmedCases',ascending=False).head(20)\n\nplot6 = sns.barplot(x=\"ConfirmedCases\",y=\"Province_State\", data=us_region_sum1)\n\nplt.ylabel(\"Total confirmed cases by US states\")\n\nplt.title(\"Total Numbers of Confirmed Cases by U.S top 20 states\",fontsize=20)\n\nfor p in plot6.patches:\n    width = p.get_width()\n    plot6.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")\n    \n\n\n","5be728ca":"top10_us_sum = us_region_sum.loc[us_region_sum['Province_State'].isin(['New York','New Jersey','Washington',\n                                                                      'California','Michigan',\n                                                                      'Illinois','Florida','Louisiana',\n                                                                      'Pennsylvania','Texas'])==True]\n\n\ntop10_us_sum1 = top10_us_sum.groupby(\n    ['Province_State','Date'])['ConfirmedCases'].sum().reset_index()\n    \nsns.lineplot(data=top10_us_sum1, x=\"Date\", y=\"ConfirmedCases\", hue=\"Province_State\")\n\nplt.ylabel(\"Total confirmed cases by US states\")\n\nplt.title(\"Total numbers of Confirmed Cases in by top 10 states\",fontsize=20)\n","fdf4ec18":"top10_us_sum2 = top10_us_sum.groupby(['Province_State','Date'])['ConfirmedCases','Fatalities'].sum().reset_index()\n\ntop10_us_sum2['Fatal_Rate'] = round((top10_us_sum2['Fatalities']\/top10_us_sum2['ConfirmedCases'])*100,2)\n\nsns.lineplot(data=top10_us_sum2, x=\"Date\", y=\"Fatal_Rate\", hue=\"Province_State\")\n\nplt.ylabel(\"Fatality Rate in the U.S. states in Percentage\")\n\nplt.title(\"Fatality Rate by top 10 states\",fontsize=20)","b3f34dc2":"top10_us_sum3 = complete_data.loc[complete_data['Country_Region']=='US'].groupby(\n    'Date')['Confirmed','Recovered'].sum().reset_index()\n\ntop10_us_sum3['Recover_Rate'] = round((top10_us_sum3['Recovered']\/top10_us_sum3['Confirmed'])*100,2)\n\nsns.lineplot(data=top10_us_sum3, x=\"Date\", y=\"Recover_Rate\")\n\nplt.ylabel(\"Recovery Rate in the U.S. states in Percentage\")\n\nplt.title(\"Recovery Rate by top 10 states\",fontsize=20)","cad06097":"round(top10_us_sum3['Recover_Rate'].mean(),2)","d5d1c049":"\nasia = ['Afghanistan', 'Armenia', 'Azerbaijan', 'Bahrain', 'Bangladesh', 'Bhutan', 'Brunei', \n        'Cambodia', 'China', 'Timor-Leste', 'Georgia', 'India', 'Indonesia', 'Iran', 'Iraq', \n        'Israel', 'Japan', 'Jordan', 'Kazakhstan', 'Kuwait', 'Kyrgyzstan', 'Laos', 'Lebanon', \n        'Malaysia', 'Maldives', 'Mongolia', 'Myanmar', 'Nepal', 'Oman', 'Pakistan', \n        'Philippines', 'Qatar', 'Russia', 'Saudi Arabia', 'Singapore', 'Korea, South', 'Sri Lanka', \n        'Syria', 'Taiwan', 'Tajikistan', 'Thailand', 'Turkey', 'Turkmenistan', 'United Arab Emirates', \n        'Uzbekistan', 'Vietnam', 'Yemen']\n\nasia_sum = train.loc[train['Country_Region'].isin(asia)==True]\n\nasia_sum1 = asia_sum.loc[asia_sum['Date']==train['Date'].max()].groupby(\n    'Country_Region')['Country_Region', 'ConfirmedCases'].sum().reset_index().sort_values(\n    'ConfirmedCases',ascending=False).head(20)\n\nplot7 = sns.barplot(x=\"ConfirmedCases\",y=\"Country_Region\", data=asia_sum1)\n\nplt.title(\"Total Numbers of Confirmed Cases\",fontsize=20)\n\nfor p in plot7.patches:\n    width = p.get_width()\n    plot7.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")\n\n\n","97cfd646":"#Let's plot them in a timeline but excluding China\n\ntop10_asia_sum1 = asia_sum.loc[asia_sum['Country_Region'].isin(['Korea, South','Iran','Turkey','Israel',\n                                                               'Malaysia','Japan','Pakistan',\n                                                               'Thailand','Saudi Arabia','Indonesia',\n                                                              'Russia','India'])==True]\n\n\ntop10_asia_sum1 = top10_asia_sum1.groupby(\n    ['Country_Region','Date'])['ConfirmedCases'].sum().reset_index()\n    \nsns.lineplot(data=top10_asia_sum1, x=\"Date\", y=\"ConfirmedCases\", hue=\"Country_Region\")\n\nplt.ylabel(\"Total confirmed cases by Asia countries\")\n\nplt.title(\"Total numbers of Confirmed Cases in by Asia countries - excluding China\",fontsize=20)\n","73da5cea":"#excluding Iran, Korea and China\n\ntop10_asia_sum2 = asia_sum.loc[asia_sum['Country_Region'].isin(['Turkey','Israel',\n                                                               'Malaysia','Japan','Pakistan',\n                                                               'Thailand','Saudi Arabia','Indonesia',\n                                                              'Russia','India','Philippines'])==True]\n\n\ntop10_asia_sum2 = top10_asia_sum2.groupby(\n    ['Country_Region','Date'])['ConfirmedCases'].sum().reset_index()\n    \nsns.lineplot(data=top10_asia_sum2, x=\"Date\", y=\"ConfirmedCases\", hue=\"Country_Region\")\n\nplt.ylabel(\"Total confirmed cases by Asia countries\")\n\nplt.title(\"Total numbers of Confirmed Cases in by Asia countries - excluding China, Korea and Iran\",fontsize=20)","628ecd6e":"\ntop10_asia_sum3 = asia_sum.loc[asia_sum['Country_Region'].isin(['Korea, South','Turkey','Israel',\n                                                               'Malaysia','Japan','Pakistan',\n                                                               'Thailand','Saudi Arabia','Indonesia',\n                                                              'Russia','India'])==True]\n\n\ntop10_asia_sum3 = top10_asia_sum3.groupby(\n    ['Country_Region','Date'])['ConfirmedCases','Fatalities'].sum().reset_index()\n\ntop10_asia_sum3['Fatal_Rate'] = round((top10_asia_sum3['Fatalities']\/top10_asia_sum3['ConfirmedCases'])*100,2)\n    \nsns.lineplot(data=top10_asia_sum3, x=\"Date\", y=\"Fatal_Rate\", hue=\"Country_Region\")\n\nplt.ylabel(\"Fatality Rate in Asia countries in Percentage\")\n\nplt.title(\"Fatality Rate in Asia countries - excluding China and Iran\",fontsize=20)","f1ec4353":"\ntop10_asia_sum4 = complete_data.loc[complete_data['Country_Region'].isin(['Korea, South','Iran','Turkey','Israel',\n                                                               'Malaysia','Japan','Pakistan',\n                                                               'Thailand','Saudi Arabia','Indonesia',\n                                                              'Russia','India','Philippines'])==True]\n\ntop10_asia_sum4 = top10_asia_sum4.groupby(['Country_Region','Date'])['Confirmed','Recovered'].sum().reset_index()\n\ntop10_asia_sum4['Recover_Rate'] = round((top10_asia_sum4['Recovered']\/top10_asia_sum4['Confirmed'])*100,2)\n\nsns.lineplot(data=top10_asia_sum4, x=\"Date\", y=\"Recover_Rate\", hue=\"Country_Region\")\n\nplt.ylabel(\"Recovery Rate in Europe countries in Percentage\")\n\nplt.title(\"Recovery Rate  in Europe countries\",fontsize=20)","e53bdbb7":"\ntemp_covid = weather_data.groupby(['Date', 'Country_Region'])['temp'].mean().reset_index()\ntemp_covid['Date'] = pd.to_datetime(temp_covid['Date'])\nmap_covid['Date'] = pd.to_datetime(map_covid['Date'])\n\n#merge with the confirmed cases for size changing\ntemp_covid = pd.merge(temp_covid, map_covid, on=['Date','Country_Region'],how='left')\n\ntemp_covid['Date'] = temp_covid['Date'].dt.strftime('%m\/%d\/%Y')\n\nfig = px.scatter_geo(temp_covid, locations=\"Country_Region\", locationmode='country names', \n                     color=\"temp\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Temperature according to the number of Confirmed Cases Around the Globe', \n                     color_continuous_scale=\"tealrose\")\nfig.show()\n","2b4d2efb":"wdsp_covid = weather_data.groupby(['Date', 'Country_Region'])['wdsp'].max().reset_index()\nwdsp_covid['Date'] = pd.to_datetime(wdsp_covid['Date'])\n\n#merge with the confirmed cases for size changing\nwdsp_covid = pd.merge(wdsp_covid, map_covid, on=['Date','Country_Region'],how='left')\n\nwdsp_covid['Date'] = wdsp_covid['Date'].dt.strftime('%m\/%d\/%Y')\n\nfig = px.scatter_geo(wdsp_covid, locations=\"Country_Region\", locationmode='country names', \n                     color=\"wdsp\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Windspeed according to the number of Confirmed Cases Around the Globe', \n                     color_continuous_scale=\"tealrose\")\nfig.show()\n","70064de5":"prcp_covid = weather_data.groupby(['Date', 'Country_Region'])['prcp'].max().reset_index()\nprcp_covid['Date'] = pd.to_datetime(prcp_covid['Date'])\n\n#merge with the confirmed cases for size changing\nprcp_covid = pd.merge(prcp_covid, map_covid, on=['Date','Country_Region'],how='left')\n\nprcp_covid['Date'] = prcp_covid['Date'].dt.strftime('%m\/%d\/%Y')\n\nfig = px.scatter_geo(prcp_covid, locations=\"Country_Region\", locationmode='country names', \n                     color=\"prcp\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Precipitation according to the number of Confirmed Cases Around the Globe', \n                     color_continuous_scale=\"tealrose\")\nfig.show()\n","ebae549b":"humid_covid = weather_addition.groupby(['Date', 'Country_Region'])['humidity'].mean().reset_index()\nhumid_covid['Date'] = pd.to_datetime(humid_covid['Date'])\n\n#merge with the confirmed cases for size changing\nhumid_covid = pd.merge(humid_covid, map_covid, on=['Date','Country_Region'],how='left')\nhumid_covid = humid_covid.dropna()\n\nhumid_covid['Date'] = humid_covid['Date'].dt.strftime('%m\/%d\/%Y')\n\nfig = px.scatter_geo(humid_covid, locations=\"Country_Region\", locationmode='country names', \n                     color=\"humidity\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Humidity according to the number of Confirmed Cases Around the Globe', \n                     color_continuous_scale=\"tealrose\")\nfig.show()\n","587a6185":"sun_covid = weather_addition.groupby(['Date', 'Country_Region'])['sunHour'].mean().reset_index()\nsun_covid['Date'] = pd.to_datetime(sun_covid['Date'])\n\n#merge with the confirmed cases for size changing\nsun_covid = pd.merge(sun_covid, map_covid, on=['Date','Country_Region'],how='left')\nsun_covid = sun_covid.dropna()\n\nsun_covid['Date'] = sun_covid['Date'].dt.strftime('%m\/%d\/%Y')\n\nfig = px.scatter_geo(sun_covid, locations=\"Country_Region\", locationmode='country names', \n                     color=\"sunHour\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Humidity according to the number of Confirmed Cases Around the Globe', \n                     color_continuous_scale=\"tealrose\")\nfig.show()\n","bf4466ba":"#join the dataframe\n\ntemp_covid1 = pd.merge(temp_covid, wdsp_covid[['Date','Country_Region','wdsp']], \n                             on=['Date','Country_Region'],how='left')\ntemp_covid1 = pd.merge(temp_covid1, prcp_covid[['Date','Country_Region','prcp']], \n                             on=['Date','Country_Region'],how='left')\ntemp_covid1 = pd.merge(temp_covid1, humid_covid[['Date','Country_Region','humidity']], \n                             on=['Date','Country_Region'],how='left')\ntemp_covid1 = pd.merge(temp_covid1, sun_covid[['Date','Country_Region','sunHour']], \n                             on=['Date','Country_Region'],how='left')\n\ntemp_covid1 = temp_covid1.dropna()\n\ntemp_covid1.tail()","8d694d08":"temp_covid2 = temp_covid1[['temp','wdsp','prcp','humidity','sunHour']]\n\ncorr = temp_covid2.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\nsns.set(style=\"white\")\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\n","0e843b93":"#construct the Multilinear regression model\nX =  temp_covid1[['temp','wdsp','humidity']]\ny = temp_covid1['ConfirmedCases']\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit()\n\n#model summary\nmodel.summary()\n","c6fd772d":"china_temp = temp_covid1.loc[temp_covid1['Country_Region']=='China']\n\n#construct the OLS model\nX =  china_temp[['temp', 'wdsp', 'humidity']]\ny = china_temp['ConfirmedCases']\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit()\n\n#predictions = model.predict(X) # make the predictions by the model\n\nmodel.summary()\n","24962e55":"italy_temp = temp_covid1.loc[temp_covid1['Country_Region']=='Italy']\n\n#construct the OLS model\nX =  italy_temp[['temp', 'wdsp', 'humidity']]\ny = italy_temp['ConfirmedCases']\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit()\n\n#predictions = model.predict(X) # make the predictions by the model\n\nmodel.summary()","2c4b445d":"spain_temp = temp_covid1.loc[temp_covid1['Country_Region']=='Spain']\n\n#construct the OLS model\nX =  spain_temp[['temp', 'wdsp', 'humidity']]\ny = spain_temp['ConfirmedCases']\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit()\n\n#predictions = model.predict(X) # make the predictions by the model\n\nmodel.summary()","c83a590e":"\nus_temp = temp_covid1.loc[temp_covid1['Country_Region']=='US']\n\n#construct the OLS model\nX =  us_temp[['temp','wdsp', 'humidity']]\ny = us_temp['ConfirmedCases']\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit()\n\n#predictions = model.predict(X) # make the predictions by the model\n\nmodel.summary()\n","1e50869e":"#Combine US states to only US \ndemo_data1 = demo_data.replace(['Alabama', 'Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware',\n             'Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana',\n             'Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska',\n             'Nevada','New Hampshire','New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota',\n             'Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota', 'Tennessee',\n             'Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming','San Franciso',\n             'GeorgiaUS', 'Atlanta', 'Honolulu', 'Washington DC'], 'US')\n\ndemo_data1.head()\n","20497dd9":"\ndemo_data_pop = demo_data1.groupby(['country'])['country','pop'].sum().reset_index().sort_values('pop',ascending=False)\n\ndemo_data_pop = demo_data_pop.loc[demo_data_pop['country'].isin(['US', 'Italy', 'China', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Netherlands', 'Belgium',\n       'Korea, South', 'Turkey', 'Austria', 'Canada', 'Portugal', 'Norway',\n       'Brazil', 'Israel', 'Australia'])==True]\n\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\nsns.set(rc={'figure.figsize':(15, 7)})\n\nplot_pop=sns.barplot(x=\"pop\",y=\"country\", data=demo_data_pop)\n\nplt.xlabel(\"Population\")\n\nplt.title(\"Population\",fontsize=20)\n\nfor p in plot_pop.patches:\n    width = p.get_width()\n    plot_pop.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")\n    ","84678973":"\ndemo_data2 = demo_data1.sort_values('tests',ascending=False).head(20)\n\nplot10 = sns.barplot(x=\"tests\",y=\"country\", data=demo_data2)\n\nplt.xlabel(\"Total number of COVID-19 test\")\n\nplt.title(\"Total number of COVID-19 test\",fontsize=20)\n\nfor p in plot10.patches:\n    width = p.get_width()\n    plot10.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")","b4d572a9":"\ndemo_data3 = demo_data1.groupby(['country'])['country',\n                                           'hospibed'].mean().reset_index().sort_values('hospibed',ascending=False)\n\ndemo_data3 = demo_data3.loc[demo_data3['country'].isin(['US', 'Italy', 'China', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Netherlands', 'Belgium',\n       'Korea, South', 'Turkey', 'Austria', 'Canada', 'Portugal', 'Norway',\n       'Brazil', 'Israel', 'Australia'])==True]\n\nplot11 = sns.barplot(x=\"hospibed\",y=\"country\", data=demo_data3)\n\nplt.xlabel(\"Hospital bed per 1,000 people\")\n\nplt.title(\"Amount of hospital bed per 1,000 people\",fontsize=20)\n","3f4f73db":"demo_data9 = demo_data1.groupby(['country'])['country',\n                                           'medianage'].median().reset_index().sort_values('medianage',ascending=False)\n\ndemo_data9 = demo_data9.loc[demo_data9['country'].isin(['US', 'Italy', 'China', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Netherlands', 'Belgium',\n       'Korea, South', 'Turkey', 'Austria', 'Canada', 'Portugal', 'Norway',\n       'Brazil', 'Israel', 'Australia'])==True]\n\nplot13 = sns.barplot(x=\"medianage\",y=\"country\", data=demo_data9)\n\nplt.xlabel(\"Median Age\")\n\nplt.title(\"Median Age by Country\",fontsize=20)","3762d4e2":"demo_data4 = demo_data1.groupby(['country'])['country',\n                                           'density'].sum().reset_index().sort_values('density',ascending=False)\n\ndemo_data4 = demo_data4.loc[demo_data4['country'].isin(['US', 'Italy', 'China', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Netherlands', 'Belgium',\n       'Korea, South', 'Turkey', 'Austria', 'Canada', 'Portugal', 'Norway',\n       'Brazil', 'Israel', 'Australia'])==True]\n\nplot12 = sns.barplot(x=\"density\",y=\"country\", data=demo_data4)\n\nplt.xlabel(\"denisity\")\n\nplt.title(\"Population Density by Country\",fontsize=20)\n\nfor p in plot12.patches:\n    width = p.get_width()\n    plot12.text(width + 1.5  ,\n            p.get_y()+p.get_height()\/2. + 0.2,\n            '{:1.0f}'.format(width),\n            ha=\"left\")\n    ","7c831a67":"demo_data7 = demo_data1.groupby(['country'])['country',\n                                           'lung'].mean().reset_index().sort_values('lung',ascending=False)\n\ndemo_data7 = demo_data7.loc[demo_data7['country'].isin(['US', 'Italy', 'China', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Netherlands', 'Belgium',\n       'Korea, South', 'Turkey', 'Austria', 'Canada', 'Portugal', 'Norway',\n       'Brazil', 'Israel', 'Australia'])==True]\n\nplot14 = sns.barplot(x=\"lung\",y=\"country\", data=demo_data7)\n\nplt.xlabel(\"Death rate from lung diseases per 100k people\")\n\nplt.title(\"Death rate from lung diseases per 100k people by Country\",fontsize=20)\n","17ca6361":"demo_data11 = demo_data1.groupby(['country'])['country',\n                                           'smokers'].sum().reset_index().sort_values('smokers',ascending=False)\n\ndemo_data11 = demo_data11.loc[demo_data11['country'].isin(['US', 'Italy', 'China', 'Spain', 'Germany', 'France', 'Iran',\n       'United Kingdom', 'Switzerland', 'Netherlands', 'Belgium',\n       'Korea, South', 'Turkey', 'Austria', 'Canada', 'Portugal', 'Norway',\n       'Brazil', 'Israel', 'Australia'])==True]\n\nplot111 = sns.barplot(x=\"smokers\",y=\"country\", data=demo_data11)\n\nplt.xlabel(\"Number of smokers\")\n\nplt.title(\"Number of smokers by Country\",fontsize=20)","9a8726f3":"Image(\"..\/input\/images\/log-curve.png\")","bc722525":"china_sum = complete_data.loc[complete_data['Country_Region']==\"China\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\nchina_sum = pd.melt(china_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\nchina_sum = china_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=china_sum, x=\"Date\", y=\"total\", color=\"dodgerblue\")\n\nax.axvline(pd.to_datetime('2020-01-23'), color=\"red\", linestyle=\"--\")\n\nax.axvline(pd.to_datetime('2020-02-12'), color=\"gray\", linestyle=\"--\")\n\nax.annotate(\"Date first quarantine\", xy=(pd.to_datetime('2020-01-24'), 50000))\n\nax.annotate(\"Inflection Point\", xy=(pd.to_datetime('2020-02-13'), 50000))\n\nplt.ylabel(\"Total cases in China\")\n\nplt.title(\"Total numbers of Cases in China\",fontsize=20)\n","f67238e8":"korea_sum = complete_data.loc[complete_data['Country_Region']==\"South Korea\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\nkorea_sum = pd.melt(korea_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\nkorea_sum = korea_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=korea_sum, x=\"Date\", y=\"total\", color=\"violet\")\n\nax.axvline(pd.to_datetime('2020-02-23'), color=\"black\", linestyle=\"--\")\n\nax.axvline(pd.to_datetime('2020-03-01'), color=\"gray\", linestyle=\"--\")\n\nax.axvline(pd.to_datetime('2020-02-01'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"First roll out \\n widespread testing\", xy=(pd.to_datetime('2020-02-02'), 5000))\n\nax.annotate(\"Date First \\nQuarantine\", xy=(pd.to_datetime('2020-02-15'), 7000))\n\nax.annotate(\"Inflection Point\", xy=(pd.to_datetime('2020-03-03'), 4000))\n\nplt.ylabel(\"Total confirmed cases in South Korea\")\n\nplt.title(\"Total numbers of Cases in South Korea\",fontsize=20)\n","cf83a9b0":"italy_sum = complete_data.loc[complete_data['Country_Region']==\"Italy\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\nitaly_sum = pd.melt(italy_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\nitaly_sum = italy_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=italy_sum, x=\"Date\", y=\"total\", color=\"palevioletred\")\n\nax.axvline(pd.to_datetime('2020-03-11'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"Date First Quarantine\", xy=(pd.to_datetime('2020-03-12'), 125000))\n\nplt.ylabel(\"Total confirmed cases in Italy\")\n\nplt.title(\"Total numbers of Cases in Italy\",fontsize=20)\n","0f03dcf3":"spain_sum = complete_data.loc[complete_data['Country_Region']==\"Spain\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\nspain_sum = pd.melt(spain_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\nspain_sum = spain_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=spain_sum, x=\"Date\", y=\"total\", color=\"green\")\n\nax.axvline(pd.to_datetime('2020-03-14'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"Date First Quarantine\", xy=(pd.to_datetime('2020-03-15'), 125000))\n\nplt.ylabel(\"Total confirmed cases in Spain\")\n\nplt.title(\"Total numbers of Cases in Spain\",fontsize=20)\n","d6cc81d8":"france_sum = complete_data.loc[complete_data['Country_Region']==\"France\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\nfrance_sum = pd.melt(france_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\nfrance_sum = france_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=france_sum, x=\"Date\", y=\"total\", color=\"salmon\")\n\nax.axvline(pd.to_datetime('2020-03-16'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"Date First Quarantine\", xy=(pd.to_datetime('2020-03-17'), 110000))\n\nplt.ylabel(\"Total confirmed cases in France\")\n\nplt.title(\"Total numbers of Cases in France\",fontsize=20)\n","269a16e8":"germany_sum = complete_data.loc[complete_data['Country_Region']==\"Germany\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\ngermany_sum = pd.melt(germany_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\ngermany_sum = france_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=germany_sum, x=\"Date\", y=\"total\", color=\"orange\")\n\nax.axvline(pd.to_datetime('2020-03-20'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"Date First Quarantine\", xy=(pd.to_datetime('2020-03-21'), 125000))\n\nplt.ylabel(\"Total confirmed cases in Germany\")\n\nplt.title(\"Total numbers of Cases in Germany\",fontsize=20)\n","4dbb8c6a":"iran_sum = complete_data.loc[complete_data['Country_Region']==\"Iran\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\niran_sum = pd.melt(iran_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\niran_sum = iran_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=iran_sum, x=\"Date\", y=\"total\", color=\"cornflowerblue\")\n\nax.axvline(pd.to_datetime('2020-03-15'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"Date First Quarantine\", xy=(pd.to_datetime('2020-03-16'), 60000))\n\nplt.ylabel(\"Total confirmed cases in Iran\")\n\nplt.title(\"Total numbers of Cases in Iran\",fontsize=20)\n","b8d063e3":"us_sum = complete_data.loc[complete_data['Country_Region']==\"US\"].groupby('Date')['Date', 'Confirmed'].sum().reset_index()\n\nus_sum = pd.melt(us_sum, id_vars=['Date'], value_vars=['Confirmed'])\n\nus_sum = us_sum.rename(columns={\"value\": \"total\", \"variable\": \"Cases\"})\n\nax=sns.lineplot(data=us_sum, x=\"Date\", y=\"total\", color=\"orchid\")\n\nax.axvline(pd.to_datetime('2020-03-22'), color=\"red\", linestyle=\"--\")\n\nax.annotate(\"Date First Quarantine \\nin New York\", xy=(pd.to_datetime('2020-03-23'), 600000))\n\nplt.ylabel(\"Total confirmed cases in the U.S.\")\n\nplt.title(\"Total numbers of Cases in the U.S.\",fontsize=20)\n","22726cc8":"Image(\"..\/input\/images\/SEIR-math.png\")\n","940549da":"# This functions smooths data, thanks to Dan Pearson. We will use it to smooth the data for growth factor.\ndef smoother(inputdata,w,imax):\n    data = 1.0*inputdata\n    data = data.replace(np.nan,1)\n    data = data.replace(np.inf,1)\n    #print(data)\n    smoothed = 1.0*data\n    normalization = 1\n    for i in range(-imax,imax+1):\n        if i==0:\n            continue\n        smoothed += (w**abs(i))*data.shift(i,axis=0)\n        normalization += w**abs(i)\n    smoothed \/= normalization\n    return smoothed\n\ndef growth_factor(confirmed):\n    confirmed_iminus1 = confirmed.shift(1, axis=0)\n    confirmed_iminus2 = confirmed.shift(2, axis=0)\n    return (confirmed-confirmed_iminus1)\/(confirmed_iminus1-confirmed_iminus2)\n\ndef growth_ratio(confirmed):\n    confirmed_iminus1 = confirmed.shift(1, axis=0)\n    return (confirmed\/confirmed_iminus1)\n\n# This is a function which plots (for in input country) the active, confirmed, and recovered cases, deaths, and the growth factor.\ndef plot_country_active_confirmed_recovered(country):\n    \n    # Plots Active, Confirmed, and Recovered Cases. Also plots deaths.\n    country_data = train[train['Country_Region']==country]\n    table = country_data.drop(['Id','Province_State'], axis=1)\n\n    table2 = pd.pivot_table(table, values=['ConfirmedCases','Fatalities'], index=['Date'], aggfunc=np.sum)\n    table3 = table2.drop(['Fatalities'], axis=1)\n   \n    # Growth Factor\n    w = 0.5\n    table2['GrowthFactor'] = growth_factor(table2['ConfirmedCases'])\n    table2['GrowthFactor'] = smoother(table2['GrowthFactor'],w,5)\n\n    # 2nd Derivative\n    table2['2nd_Derivative'] = np.gradient(np.gradient(table2['ConfirmedCases'])) #2nd derivative\n    table2['2nd_Derivative'] = smoother(table2['2nd_Derivative'],w,7)\n\n\n    #Plot confirmed[i]\/confirmed[i-1], this is called the growth ratio\n    table2['GrowthRatio'] = growth_ratio(table2['ConfirmedCases'])\n    table2['GrowthRatio'] = smoother(table2['GrowthRatio'],w,5)\n    \n        #Plot the growth rate, we will define this as k in the logistic function presented at the beginning of this notebook.\n    table2['GrowthRate']=np.gradient(np.log(table2['ConfirmedCases']))\n    table2['GrowthRate'] = smoother(table2['GrowthRate'],0.5,3)\n    \n    # horizontal line at growth rate 1.0 for reference\n    x_coordinates = [1, 100]\n    y_coordinates = [1, 1]\n    \n    sns.set(rc={'figure.figsize':(10, 5)})\n\n    \n    pd.plotting.register_matplotlib_converters()\n\n    #plots\n    table2['Fatalities'].plot(title='Fatalities')\n    plt.show()\n    table3.plot() \n    plt.show()\n    table2['GrowthFactor'].plot(title='Growth Factor')\n    plt.plot(x_coordinates, y_coordinates) \n    plt.show()\n    table2['2nd_Derivative'].plot(title='2nd_Derivative')\n    plt.show()\n    table2['GrowthRatio'].plot(title='Growth Ratio')\n    plt.plot(x_coordinates, y_coordinates)\n    plt.show()\n    table2['GrowthRate'].plot(title='Growth Rate')\n    plt.show()\n\n\n    return \n","2a810e59":"plot_country_active_confirmed_recovered('China')","0431f906":"plot_country_active_confirmed_recovered('Korea, South')","077f54f9":"plot_country_active_confirmed_recovered('US')","0005a16b":"plot_country_active_confirmed_recovered('Italy')","e9ea5c30":"plot_country_active_confirmed_recovered('Spain')","e5eff471":"plot_country_active_confirmed_recovered('Vietnam')","ed4546e8":"# Function code refernece from https:\/\/www.kaggle.com\/anjum48\/seir-model-with-intervention\n\n# Susceptible equation\ndef dS_dt(S, I, R_t, T_inf):\n    return -(R_t \/ T_inf) * I * S\n\n# Exposed equation\ndef dE_dt(S, E, I, R_t, T_inf, T_inc):\n    return (R_t \/ T_inf) * I * S - (T_inc**-1) * E\n\n# Infected equation\ndef dI_dt(I, E, T_inc, T_inf):\n    return (T_inc**-1) * E - (T_inf**-1) * I\n\n# Recovered\/Remove\/deceased equation\ndef dR_dt(I, T_inf):\n    return (T_inf**-1) * I\n\ndef SEIR_model(t, y, R_t, T_inf, T_inc):\n    \n    if callable(R_t):\n        reproduction = R_t(t)\n    else:\n        reproduction = R_t\n        \n    S, E, I, R = y\n    \n    S_out = dS_dt(S, I, reproduction, T_inf)\n    E_out = dE_dt(S, E, I, reproduction, T_inf, T_inc)\n    I_out = dI_dt(I, E, T_inc, T_inf)\n    R_out = dR_dt(I, T_inf)\n    \n    return [S_out, E_out, I_out, R_out]","56ec4c34":"## Thanks @funkyboy for the plotting function\n\ndef plot_model_and_predict(data, pop, solution, title='SEIR model'):\n    sus, exp, inf, rec = solution.y\n    \n    f = plt.figure(figsize=(16,5))\n    ax = f.add_subplot(1,2,1)\n    #ax.plot(sus, 'b', label='Susceptible');\n    ax.plot(exp, 'y', label='Exposed');\n    ax.plot(inf, 'r', label='Infected');\n    ax.plot(rec, 'c', label='Recovered\/deceased');\n    plt.title(title)\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.ylabel(\"Fraction of population\", fontsize=10);\n    plt.legend(loc='best');\n    \n    ax2 = f.add_subplot(1,2,2)\n    preds = np.clip((inf + rec) * pop ,0,np.inf)\n    ax2.plot(range(len(data)),preds[:len(data)],label = 'Predict ConfirmedCases')\n    ax2.plot(range(len(data)),data['ConfirmedCases'])\n    plt.title('Model predict and data')\n    plt.ylabel(\"Population\", fontsize=10);\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.legend(loc='best');","3a652c00":"Country = 'New York'\nN = pop_info[pop_info['Name']==Country]['Population'].tolist()[0] # Hubei Population \n\n# Load dataset of Hubei\ntrain_loc = train[train['Country_Region']==Country].query('ConfirmedCases > 0')\nif len(train_loc)==0:\n    train_loc = train[train['Province_State']==Country].query('ConfirmedCases > 0')\n\nn_infected = train_loc['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\nmax_days = len(train_loc)# how many days want to predict\n\n# Initial stat for SEIR model\ns = (N - n_infected)\/ N\ne = 0.\ni = n_infected \/ N\nr = 0.\n\n# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9 # average infectious period\nR_0 = 3.954 # reproduction number\n\n## Solve the SEIR model \nsol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(R_0, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\n## Plot result\nplot_model_and_predict(train_loc, N, sol, title = 'SEIR Model (without intervention)')","dfa22ccb":"# Define all variable of SEIR model \nT_inc = 5.2  # average incubation period\nT_inf = 2.9  # average infectious period\n\n# Define the intervention parameters (fit result, latter will show how to fit)\nR_0, cfr, k, L=[ 3.95469597 , 0.04593316 , 3.      ,   15.32328881]\n\ndef time_varying_reproduction(t): \n    return R_0 \/ (1 + (t\/L)**k)\n\nsol2 = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc), \n                t_eval=np.arange(max_days))\n\nplot_model_and_predict(train_loc, N, sol2, title = 'SEIR Model (with intervention)')","21bda7f1":"def cumsum_signal(vec):\n    temp_val = 0\n    vec_new = []\n    for i in vec:\n        if i > temp_val:\n            vec_new.append(i)\n            temp_val = i\n        else:\n            vec_new.append(temp_val)\n    return vec_new","d4ef3c01":"# Use a constant reproduction number\ndef eval_model_const(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # R0 become half after intervention days\n    def time_varying_reproduction(t):\n        if t > 60: # we set intervention days = 60\n            return R_0 * 0.5\n        else:\n            return R_0\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","a39d0101":"# Use a Hill decayed reproduction number\ndef eval_model_decay(params, data, population, return_solution=False, forecast_days=0):\n    R_0, cfr, k, L = params # Paramaters, R0 and cfr \n    N = population # Population of each country\n    n_infected = data['ConfirmedCases'].iloc[0] # start from first comfirmedcase on dataset first date\n    max_days = len(data) + forecast_days # How many days want to predict\n    s, e, i, r = (N - n_infected)\/ N, 0, n_infected \/ N, 0 #Initial stat for SEIR model\n    \n    # https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions   \n    # Hill decay. Initial values: R_0=2.2, k=2, L=50\n    def time_varying_reproduction(t): \n        return R_0 \/ (1 + (t\/L)**k)\n    \n    # Solve the SEIR differential equation.\n    sol = solve_ivp(SEIR_model, [0, max_days], [s, e, i, r], args=(time_varying_reproduction, T_inf, T_inc),\n                    t_eval=np.arange(0, max_days))\n    \n    sus, exp, inf, rec = sol.y\n    # Predict confirmedcase\n    y_pred_cases = np.clip((inf + rec) * N ,0,np.inf)\n    y_true_cases = data['ConfirmedCases'].values\n    \n    # Predict Fatalities by remove * fatality rate(cfr)\n    y_pred_fat = np.clip(rec*N* cfr, 0, np.inf)\n    y_true_fat = data['Fatalities'].values\n    \n    optim_days = min(20, len(data))  # Days to optimise for\n    weights = 1 \/ np.arange(1, optim_days+1)[::-1]  # Recent data is more heavily weighted\n    \n    # using mean squre log error to evaluate\n    msle_cases = mean_squared_log_error(y_true_cases[-optim_days:], y_pred_cases[-optim_days:], weights)\n    msle_fat = mean_squared_log_error(y_true_fat[-optim_days:], y_pred_fat[-optim_days:], weights)\n    msle_final = np.mean([msle_cases, msle_fat])\n    \n    if return_solution:\n        return msle_final, sol\n    else:\n        return msle_final","9352b26f":"def fit_model_new(data, area_name, initial_guess=[2.2, 0.02, 2, 50], \n              bounds=((1, 20), (0, 0.15), (1, 3), (1, 100)), make_plot=True, decay_mode = None):\n    \n    if area_name in ['France']:# France last data looks weird, remove it\n        train = data.query('ConfirmedCases > 0').copy()[:-1]\n    else:\n        train = data.query('ConfirmedCases > 0').copy()\n    \n    ####### Split Train & Valid #######\n    valid_data = train[-7:].copy()\n    train_data = train[:-7].copy()\n    \n    ####### If this country have no ConfirmedCase, return 0 #######\n    if len(train_data) == 0:\n        result_zero = np.zeros((43))\n        return pd.DataFrame({'ConfirmedCases':result_zero,'Fatalities':result_zero}), 0 \n    \n    ####### Load the population of area #######\n    try:\n        #population = province_lookup[area_name]\n        population = pop_info[pop_info['Name']==area_name]['Population'].tolist()[0]\n    except IndexError:\n        print ('country not in population set, '+str(area_name))\n        population = 1000000 \n    \n    \n    if area_name == 'US':\n        population = 327200000\n        \n    if area_name == 'Global':\n        population = 7744240900\n        \n    cases_per_million = train_data['ConfirmedCases'].max() * 10**6 \/ population\n    n_infected = train_data['ConfirmedCases'].iloc[0]\n    \n    ####### Total case\/popuplation below 1, reduce country population #######\n    if cases_per_million < 1:\n        #print ('reduce pop divide by 100')\n        population = population\/100\n        \n    ####### Fit the real data by minimize the MSLE #######\n    res_const = minimize(eval_model_const, [2.2, 0.02], bounds=((1, 20), (0, 0.15)),\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n\n    res_decay = minimize(eval_model_decay, initial_guess, bounds=bounds,\n                         args=(train_data, population, False),\n                         method='L-BFGS-B')\n    \n    ####### Align the date information #######\n    test_end = datetime.strptime('2020-05-14','%Y-%m-%d')\n    test_start = datetime.strptime('2020-04-02','%Y-%m-%d')\n    test_period = (test_end - test_start).days\n    train_max = train_data.Date.max()\n    train_all_max = train.Date.max()\n    train_min = train_data.Date.min()\n    add_date = 0\n    delta_days =(test_end - train_max).days\n    train_add_time=[]\n\n    if train_min > test_start:\n        add_date = (train_min-test_start).days\n        last = train_min-pd.Timedelta(days=add_date)\n        train_add_time = np.arange(last, train_min, dtype='datetime64[D]').tolist()\n        train_add_time = pd.to_datetime(train_add_time)\n        dates_all = train_add_time.append(pd.to_datetime(np.arange(train_min, test_end+pd.Timedelta(days=1), dtype='datetime64[D]')))\n    else:\n        dates_all = pd.to_datetime(np.arange(train_min, test_end+pd.Timedelta(days=1), dtype='datetime64[D]'))\n\n\n    ####### Auto find the best decay function ####### \n    if decay_mode is None:\n        if res_const.fun < res_decay.fun :\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n    else:\n        if decay_mode =='day_decay':\n            msle, sol = eval_model_const(res_const.x, train_data, population, True, delta_days+add_date)\n            res = res_const\n        else:\n            msle, sol = eval_model_decay(res_decay.x, train_data, population, True, delta_days+add_date)\n            res = res_decay\n            R_0, cfr, k, L = res.x\n\n    ####### Predict the result by using best fit paramater of SEIR model ####### \n    sus, exp, inf, rec = sol.y\n    \n    y_pred = pd.DataFrame({\n        'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n       # 'ConfirmedCases': [inf[0]*population for i in range(add_date)]+(np.clip((inf + rec) * population,0,np.inf)).tolist(),\n       # 'Fatalities': [rec[0]*population for i in range(add_date)]+(np.clip(rec, 0, np.inf) * population * res.x[1]).tolist()\n        'Fatalities': cumsum_signal((np.clip(rec * population * res.x[1], 0, np.inf)).tolist())\n    })\n\n    y_pred_valid = y_pred.iloc[len(train_data):len(train_data)+len(valid_data)]\n    #y_pred_valid = y_pred.iloc[:len(train_data)]\n    y_pred_test = y_pred.iloc[-(test_period+1):]\n    #y_true_valid = train_data[['ConfirmedCases', 'Fatalities']]\n    y_true_valid = valid_data[['ConfirmedCases', 'Fatalities']]\n    #print (len(y_pred),train_min)\n    #print (y_true_valid['ConfirmedCases'])\n    #print (y_pred_valid['ConfirmedCases'])\n    ####### Calculate MSLE ####### \n    valid_msle_cases = mean_squared_log_error(y_true_valid['ConfirmedCases'], y_pred_valid['ConfirmedCases'])\n    valid_msle_fat = mean_squared_log_error(y_true_valid['Fatalities'], y_pred_valid['Fatalities'])\n    valid_msle = np.mean([valid_msle_cases, valid_msle_fat])\n    \n    ####### Plot the fit result of train data and forecast after 300 days ####### \n    if make_plot:\n        if len(res.x)<=2:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using intervention days decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}')\n        else:\n            print(f'Validation MSLE: {valid_msle:0.5f}, using Hill decay, Reproduction number(R0) : {res.x[0]:0.5f}, Fatal rate : {res.x[1]:0.5f}, K : {res.x[2]:0.5f}, L: {res.x[3]:0.5f}')\n        \n        ####### Plot the fit result of train data dna SEIR model trends #######\n\n        f = plt.figure(figsize=(16,5))\n        ax = f.add_subplot(1,2,1)\n        ax.plot(exp, 'y', label='Exposed');\n        ax.plot(inf, 'r', label='Infected');\n        ax.plot(rec, 'c', label='Recovered\/deceased');\n        plt.title('SEIR Model Trends')\n        plt.xlabel(\"Days\", fontsize=10);\n        plt.ylabel(\"Fraction of population\", fontsize=10);\n        plt.legend(loc='best');\n        #train_date_remove_year = train_data['Date'].apply(lambda date:'{:%m-%d}'.format(date))\n        ax2 = f.add_subplot(1,2,2)\n        xaxis = train_data['Date'].tolist()\n        xaxis = dates.date2num(xaxis)\n        hfmt = dates.DateFormatter('%m\\n%d')\n        ax2.xaxis.set_major_formatter(hfmt)\n        ax2.plot(np.array(train_data['Date'], dtype='datetime64[D]'),train_data['ConfirmedCases'],label='Confirmed Cases (train)', c='g')\n        ax2.plot(np.array(train_data['Date'], dtype='datetime64[D]'), y_pred['ConfirmedCases'][:len(train_data)],label='Cumulative modeled infections', c='r')\n        ax2.plot(np.array(valid_data['Date'], dtype='datetime64[D]'), y_true_valid['ConfirmedCases'],label='Confirmed Cases (valid)', c='b')\n        ax2.plot(np.array(valid_data['Date'], dtype='datetime64[D]'),y_pred_valid['ConfirmedCases'],label='Cumulative modeled infections (valid)', c='y')\n        plt.title('Real ConfirmedCase and Predict ConfirmedCase')\n        plt.legend(loc='best');\n        plt.show()\n            \n        ####### Forecast 300 days after by using the best paramater of train data #######\n        if len(res.x)>2:\n            msle, sol = eval_model_decay(res.x, train_data, population, True, 300)\n        else:\n            msle, sol = eval_model_const(res.x, train_data, population, True, 300)\n        \n        sus, exp, inf, rec = sol.y\n        \n        y_pred = pd.DataFrame({\n            'ConfirmedCases': cumsum_signal(np.diff((inf + rec) * population, prepend=n_infected).cumsum()),\n            'Fatalities': cumsum_signal(np.clip(rec, 0, np.inf) * population * res.x[1])\n        })\n        \n        ####### Plot 300 days after of each country #######\n        start = train_min\n        end = start + pd.Timedelta(days=len(y_pred))\n        time_array = np.arange(start, end, dtype='datetime64[D]')\n\n        max_day = numpy.where(inf == numpy.amax(inf))[0][0]\n        where_time = time_array[max_day]\n        pred_max_day = y_pred['ConfirmedCases'][max_day]\n        xy_show_max_estimation = (where_time, max_day)\n        \n        con = y_pred['ConfirmedCases']\n        max_day_con = numpy.where(con == numpy.amax(con))[0][0] # Find the max confimed case of each country\n        max_con = numpy.amax(con)\n        where_time_con = time_array[len(time_array)-50]\n        xy_show_max_estimation_confirmed = (where_time_con, max_con)\n        \n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=time_array, y=y_pred['ConfirmedCases'].astype(int),\n                            mode='lines',\n                            line = dict(color='red'),\n                            name='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date())))\n        \n        fig.add_trace(go.Scatter(x=time_array[:len(train)], y=train['ConfirmedCases'],\n                            mode='lines',\n                            name='Confirmed case until '+ str(train_all_max.date()),line = dict(color='green', width=4)))\n        fig.add_annotation(\n            x=where_time_con,\n            y=max_con-(max_con\/30),\n            showarrow=False,\n            text=\"Estimate Max Case around:\" +str(int(max_con)),\n            font=dict(\n                color=\"Blue\",\n                size=15\n            ))\n        fig.add_annotation(\n            x=time_array[len(train)-1],\n            y=train['ConfirmedCases'].tolist()[-1],\n            showarrow=True,\n            text=f\"Real Max ConfirmedCase: \" +str(int(train['ConfirmedCases'].tolist()[-1]))) \n        \n        fig.add_annotation(\n            x=where_time,\n            y=pred_max_day,\n            text='Infect start decrease from: ' + str(where_time))   \n        fig.update_layout(title='Estimate Confirmed Case ,'+area_name+' Total population ='+ str(int(population)), legend_orientation=\"h\")\n        fig.show()\n        \n        #df = pd.DataFrame({'Values': train_data['ConfirmedCases'].tolist()+y_pred['ConfirmedCases'].tolist(),'Date_datatime':time_array[:len(train_data)].tolist()+time_array.tolist(),\n        #           'Real\/Predict': ['ConfirmedCase' for i in range(len(train_data))]+['PredictCase' for i in range(len(y_pred))]})\n        #fig = px.line(df, x=\"Date_datatime\", y=\"Values\",color = 'Real\/Predict')\n        #fig.show()\n        #plt.figure(figsize = (16,7))\n        #plt.plot(time_array[:len(train_data)],train_data['ConfirmedCases'],label='Confirmed case until '+ str(train_max.date()),color='g', linewidth=3.0)\n        #plt.plot(time_array,y_pred['ConfirmedCases'],label='Estimation Confirmed Case Start from '+ str(start.date())+ ' to ' +str(end.date()),color='r', linewidth=1.0)\n        #plt.annotate('Infect start decrease from: ' + str(where_time), xy=xy_show_max_estimation, size=15, color=\"black\")\n        #plt.annotate('max Confirmedcase: ' + str(int(max_con)), xy=xy_show_max_estimation_confirmed, size=15, color=\"black\")\n        #plt.title('Estimate Confirmed Case '+area_name+' Total population ='+ str(int(population)))\n        #plt.legend(loc='lower right')\n        #plt.show()\n\n\n    return y_pred_test, valid_msle","78d9e67e":"country = 'US'\ncountry_pd_train = train[train['Country_Region']==country]\ncountry_pd_train2 = country_pd_train.groupby(['Date']).sum().reset_index()\ncountry_pd_train2['Date'] = pd.to_datetime(country_pd_train2['Date'], format='%Y-%m-%d')\na,b = fit_model_new(country_pd_train2,country,make_plot=True)\n","5c64e6b7":"country = 'New York'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","dd050a7f":"country = 'Italy'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","7e6c37c6":"country = 'Spain'\nif country not in train['Country_Region'].unique():\n    country_pd_train = train[train['Province_State']==country]\nelse:\n    country_pd_train = train[train['Country_Region']==country]\n\na,b = fit_model_new(country_pd_train,country,make_plot=True)","c5fb7627":"validation_scores = []\nvalidation_county = []\nvalidation_country = []\n\ntest_seir = test.copy()\n\nfor country in tqdm(train['Country_Region'].unique()):\n    country_pd_train = train[train['Country_Region']==country]\n    #if country_pd_train['Province_State'].isna().unique()==True:\n    if len(country_pd_train['Province_State'].unique())<2:\n        predict_test, score = fit_model_new(country_pd_train,country,make_plot=False)\n        if score ==0:\n            print(f'{country} no case')\n        validation_scores.append(score)\n        validation_county.append(country)\n        validation_country.append(country)\n        test_seir.loc[test_seir['Country_Region']==country,'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n        test_seir.loc[test_seir['Country_Region']==country,'Fatalities'] = predict_test['Fatalities'].tolist()\n    else:\n        for state in country_pd_train['Province_State'].unique():\n            if state != state: # check nan\n                state_pd = country_pd_train[country_pd_train['Province_State'].isna()]\n                predict_test, score = fit_model_new(state_pd,state,make_plot=False)\n                if score ==0:\n                    print(f'{country} \/ {state} no case')\n                validation_scores.append(score)\n                validation_county.append(state)\n                validation_country.append(country)\n                test_seir.loc[(test_seir['Country_Region']==country)&(test_seir['Province_State'].isna()),'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n                test_seir.loc[(test_seir['Country_Region']==country)&(test_seir['Province_State'].isna()),'Fatalities'] = predict_test['Fatalities'].tolist()\n            else:\n                state_pd = country_pd_train[country_pd_train['Province_State']==state]\n                predict_test, score = fit_model_new(state_pd,state,make_plot=False)\n                if score ==0:\n                    print(f'{country} \/ {state} no case')\n                validation_scores.append(score)\n                validation_county.append(state)\n                validation_country.append(country)\n                test_seir.loc[(test_seir['Country_Region']==country)&(test_seir['Province_State']==state),'ConfirmedCases'] = predict_test['ConfirmedCases'].tolist()\n                test_seir.loc[(test_seir['Country_Region']==country)&(test_seir['Province_State']==state),'Fatalities'] = predict_test['Fatalities'].tolist()\n         #   print(f'{country} {state} {score:0.5f}')\n            \nprint(f'Mean validation score: {np.average(validation_scores):0.5f}')","d18c74cc":"validation_scores = pd.DataFrame({'country\/state':validation_country,'country':validation_county,'MSLE':validation_scores})\nvalidation_scores.sort_values(by=['MSLE'], ascending=False).head(20)","4139b989":"large_msle = validation_scores[validation_scores['MSLE']>1]","219eff06":"for country in large_msle['country'].unique():\n    if (country!= country)==False: # check None\n        #print ('training model for country ==>'+country)\n        country_pd_train = train[train['Country_Region']==country]\n        country_pd_test = test[test['Country_Region']==country]\n        if len(country_pd_train)==0:\n            country_pd_train = train[train['Province_State']==country]\n            country_pd_test = test[test['Province_State']==country]\n\n            x = np.array(range(len(country_pd_train))).reshape((-1,1))[:-7]\n            valid_x = np.array(range(len(country_pd_train))).reshape((-1,1))[-7:]\n            y = country_pd_train['ConfirmedCases'][:-7]\n            valid_y = country_pd_train['ConfirmedCases'][-7:]\n            y_fat = country_pd_train['Fatalities'][:-7]\n            valid_y_fat = country_pd_train['Fatalities'][-7:]\n            \n            model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model = model.fit(x, y)\n\n            model_fat = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model_fat = model_fat.fit(x, y_fat)\n            \n            predict_y = model.predict(valid_x)\n            predict_yfat = model_fat.predict(valid_x)\n            score = mean_squared_log_error(np.clip(valid_y,0,np.inf), np.clip(predict_y,0,np.inf))\n            score_fat = mean_squared_log_error(np.clip(valid_y_fat,0,np.inf), np.clip(predict_yfat,0,np.inf))\n            score = (score+score_fat)\/2\n\n            print(f'{country} {score:0.5f}')\n            if score < large_msle[large_msle['country']==country]['MSLE'].tolist()[0]:\n                validation_scores.loc[validation_scores['country']==country,'MSLE'] = score\n                predict_x = (np.array(range(len(country_pd_test)))+50).reshape((-1,1))\n                test_seir.loc[test_seir['Province_State']==country,'ConfirmedCases'] = model.predict(predict_x)\n                test_seir.loc[test_seir['Province_State']==country,'Fatalities'] = model_fat.predict(predict_x)\n        else:\n            x = np.array(range(len(country_pd_train))).reshape((-1,1))[:-7]\n            valid_x = np.array(range(len(country_pd_train))).reshape((-1,1))[-7:]\n            y = country_pd_train['ConfirmedCases'][:-7]\n            valid_y = country_pd_train['ConfirmedCases'][-7:]\n            y_fat = country_pd_train['Fatalities'][:-7]\n            valid_y_fat = country_pd_train['Fatalities'][-7:]\n            \n            model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model = model.fit(x, y)\n\n            model_fat = Pipeline([('poly', PolynomialFeatures(degree=2)),\n                             ('linear', LinearRegression(fit_intercept=False))])\n            model_fat = model_fat.fit(x, y_fat)\n            \n            predict_y = model.predict(valid_x)\n            predict_yfat = model_fat.predict(valid_x)\n            score = mean_squared_log_error(np.clip(valid_y,0,np.inf), np.clip(predict_y,0,np.inf))\n            score_fat = mean_squared_log_error(np.clip(valid_y_fat,0,np.inf), np.clip(predict_yfat,0,np.inf))\n            score = (score+score_fat)\/2\n\n            print(f'{country} {score:0.5f}')\n            if score < large_msle[large_msle['country']==country]['MSLE'].tolist()[0]:\n                validation_scores.loc[validation_scores['country']==country,'MSLE'] = score\n                predict_x = (np.array(range(len(country_pd_test)))+50).reshape((-1,1))\n                test_seir.loc[test_seir['Country_Region']==country,'ConfirmedCases'] = model.predict(predict_x)\n                test_seir.loc[test_seir['Country_Region']==country,'Fatalities'] = model_fat.predict(predict_x)\n                ","c61a8489":"val_soces = validation_scores['MSLE'].tolist()\nprint(f'Mean validation score: {np.average(val_soces):0.5f}')","40228950":"\nsubmit['Fatalities'] = round(test_seir['Fatalities'].astype('float'),0)\nsubmit['ConfirmedCases'] = round(test_seir['ConfirmedCases'].astype('float'),0)\nsubmit.tail()\n","e5a3eeb8":"submit.to_csv('submission.csv',index=False)","344f417c":"## Table of content\n\n### 1) [Data Exploratory Analysis](#eda)\n  - [Number of cases around the world](#world)\n  - [Days since first outbreak](#first_outbreak)\n  - [Deep dive into confirmed, fatal and recover cases](#confirm_fatal)\n  - [Statistics of top 3 COVID19 Infected Countries](#top3_countries)\n  - [Statistics for each 3 continents - Europe, Asia, North America](#continents)\n  - [Understand the affect of weather on COVID19 transmission and fatalities](#temp)\n  - [Understand the affect of demographic on COVID19 transmission and fatalities](#demo)\n  - [What's happened after the first quarantine of top 3 impacted countries by Covid-19?](#quarantine)\n  \n### 2) [SEIR Model](#SEIR) \nWhat's logistic curve or SEIR model and how they are related to predicting the pandemic?\n\n- [Logistic Curve](#logistic_curve)\n- [SEIR Model break-down](#SEIR_model)\n\n\n### 3) [Prediction](#prediction)\n\nFor prediciton purpose, I will try mainly 3 predictive models (Random Forest, Multilinear Regression and Bayesian Ridge Regression) for each type of data, which I eventually assembled all different variables together to feed in the prediction models as well. \n\nSo far, the Random Forest Model with Weather Variables is having the best Public Score on Kaggle. However, I will continue to improve on the model performance in the next couple of days.\n\n- [Forecast with Original Dataset](#original)\n - [Random Forest Model](#original_rf)\n - [Multilinear Regression](#original_lin)\n - [Bayesian Ridge Regression](#original_br)\n- [Forecast with Weather features](#weather_predict)\n - [Random Forest Model](#weather_rf)\n - [Multilinear Regression](#weather_lin)\n - [Bayesian Ridge Regression](#weather_br)\n- [Forecast with additional feature - distance from the first outbreak of the continent](#distance)\n - [Random Forest Model](#distance_rf)\n - [Multilinear Regression](#distance_lin)\n - [Bayesian Ridge Regression](#distance_br)\n- [Forecast with Demographic features](#demo_predict)\n - [Random Forest Model](#demo_rf)\n - [Multilinear Regression](#demo_lin)\n - [Bayesian Ridge Regression](#demo_br)\n- [Forecast with all additional features above](#all_predict)\n - [Random Forest Model](#all_rf)\n - [Multilinear Regression](#all_lin)\n - [Bayesian Ridge Regression](#all_br)\n \n### 4 ) [Conclusion](#conclusion)\n","37b940bd":"- **Note**: The color represents the humidity level and the size of the circle shows the number of Covid-19 Cases\n\n#### It seems that higher humidity implies higher number of outbreak.","f164a021":"#### Top 20 countries with the amount of hospital bed per 1,000 people","d43e2365":"- **Note**: The color represents the hours of the sun and the size of the circle displays the number of Covid-19 Cases\n\n#### The hours of the sun seem to not correlate with the number of outbreak since they are around 20 hours for almost every country.\n","d54503ea":"#### In later [section](#demo_understand), I found that the high number of smokers relates with the number of confirmed cases for Covid-19. However, more scientific research is needed to be conducted in order to draw the final conclusion.\n","1cd54604":"## Logistic Curve\n\n<a id='logistic_curve'><\/a>\n","b6fae13b":"#### Among the top severe country by Covid-19, South Korea and Germany are among their counterparts to mitigate the death rate. This becomes clear when they are the top 2 countries with amount of ICU beds per 1K patients to effectively support healthcare workers save thousand of patients' lives.","a7598ba1":"#### Spain","0a38af27":"### Let's look at all Europe countries\n","792ddb41":"### What's the current situation?","e5f3dc95":"####  In Asia, China is the first case of the outbreak","84347a5e":"### Model without intervention\n\nWe will first try the model on New York. \n\nWe can see that without any intervention, the number confirmed cases will continue to increase.\n","1ecb9f39":"### Function of Fit the SEIR model to real data\n* Auto choose the best decay function of $R_t$ (intervention days decay or Hill decay)\n* Total case\/country population is below 1, reduce country population\n* If datset still no case, return 0 \n* Plot the fit result and forecast trends (Infect smooth decrease by what date)\n* Function being hide, there are describe in code.","4fdf4571":"### China","b8663ca1":"#### In contrast with China and Italy, strong wind speed shows statistically significant impact on the confirmed cases. In essence, the number of cases decrease by nearly 535 people when the wind speed increases by 1 mile\/hour. High humidity also decreases the number of transmission by 41 cases.\n\n#### However, the high temperature in the US seems to make it worse for covid-19 transmission.\n\n#### This is only approximate estimate of the linear coefficients, since the U.S. has 50 states and the weather conditions may vary for different areas.","a741fdcf":"### Precipitation by Country over time","bd07deb8":"**Additional Source: Humidity and Sun Hours**\n\nSpecial thanks to [@winterpierre](https:\/\/www.kaggle.com\/winterpierre91\/covid19-global-weather-data#temperature_dataframe.csv) for the additional weather data.\n\nThe data contains average temperature, hours of sunlight, percent humidity, and wind speed in the capital city of 156 countries. The date ranges from 22\/1\/2020 to 21\/3\/2020","d5f21230":"#### Even though that China and South Korea Growth Factor has approximated 1.00, U.S., Italy and Spain are growing fast in the number of infected cases (the 2nd Derivative curve is increasing). Vietnam - my country, even though it has no death case so far and still on a very small amount of infected cases, there's potential that it will widespread if we do not act now.\n","c46d638d":"### Linear Regression Model","1882e7b2":"## SEIR Model \n\n<a id='SEIR_model'><\/a>\n\n* Function was taken from the [Epidemic Calculator](http:\/\/gabgoh.github.io\/COVID\/index.html)\n![image.png](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/3\/3d\/SEIR.PNG)\n- **S**usceptible : number of susceptible\n- **E**xpose : number of expose\n- **I**nfectious : number of infectious\n- **R**ecovered or Removed : number recovered (or immune) individuals\n\n### S + E + I + R = N\n- N is country total population\n\nDifferential Equations are as below (Source: [Epidemic Calculator](http:\/\/gabgoh.github.io\/COVID\/index.html)): \n","ed8bcd48":"#### Fatality Rate","3aff45d3":"<img src=\"Epidemic Curve of the Confirmed Cases of Coronavirus Disease 2019 (COVID-19).png\">\n\nSource: [Journal of the American Medical Association](https:\/\/jamanetwork.com\/journals\/jama\/fullarticle\/2762130)\n\n\n#### Nearly after 20 days, the number of actual outbreak decreased signifcantly.\n\n\n#### However, after approximately 15 days of quarantine, school shutdowns, and travel bans, the number of cases in Italy and U.S. continue to rise exponentially. This may due to the fact that China had acted fast as soon as a few cases were detected, but this was not the case for Italy and the U.S.","eac1367f":"#### China","f1c6f229":"### Plot SEIR model and predict","1d83f2ea":"We won't go into details about the math, but a general understanding would be sufficient:\n\n### Logistic Function\n\nA **logistic function** or **logistic curve** is an equation of the form: \n\n$f(x) = \\frac{N}{1 + e^{-k(x-x_0)}}$\n\n#### where\n\n- N = the curve's maximum value\n- x_0 = the inflection point\n- k = growth rate of the curve\n\nReference: https:\/\/en.wikipedia.org\/wiki\/Logistic_function","5b0fb168":"#### Even though Korea has flattened the curve, Iran continues to be the rise.","f05e19ba":"#### Same with China, given everything constant, the high level of humidity significantly impact on the decrease of infected cases.","364f5d47":"## 1) Exploratory Data Analysis\n\n<a id='eda'><\/a>\n\n#### In this section, I will present some interactive visualizations for us to understand the big picture of our current situation in COVID-19 pandemic. ","e82b1d13":"#### Population with higher density can also relate to the transmission rate of Covid-19. As we can see, China, France, US and South Korea are the top country with high population density.\n","1ab455a4":"**Disclaimer:** The model is currently based on the current data that we have, the prediction will be more accurate as new data coming in and with further tuning.","21dea2dd":"#### Weather Data\n\nData was retrievied following the amazing work by [Davide Bonin](https:\/\/www.kaggle.com\/davidbnn92\/weather-data\/#data)\n\nI created my own version and the data can be found [here](https:\/\/www.kaggle.com\/giginghn\/weather-features)\n\n**Dictionary**\n\n- **temp**: temperature for the day in degrees Fahrenheit to tenths. Missing = 9999.9\n- **max**: Maximum temperature reported during the day in Fahrenheit to tenths--time of max temp report varies by country and region, so this will sometimes not be the max for the calendar day. Missing = 9999.9\n- **min**: Minimum temperature reported during the day in Fahrenheit to tenths--time of min temp report varies by country and region, so this will sometimes not be the min for the calendar day. Missing = 9999.9\n- **stp**: Mean station pressure for the day in millibars to tenths. Missing = 9999.9\n- **wdsp**: Mean wind speed for the day in knots to tenths. Missing = 999.9\n- **prcp**: Total precipitation (rain and\/or melted snow) reported during the day in inches and hundredths; will usually not end with the midnight observation--i.e., may include latter part of previous day. .00 indicates no measurable precipitation (includes a trace). Missing = 99.9\n- **fog**: Indicators (1 = yes, 0 = no\/not reported) for the occurrence during the day","94f15806":"#### The rest of the World combined is also seeing a steady increase in confirmed cases over time.","c31041ff":"#### We can see the total number of active casses in China has gone down in mid-Feb, so the spike that we saw earlier has to be from other regions.","9185daf6":"As the number of infected cases rise, the number of recovery cases began to drop, this means that we need to supress the cases below the healthcare capacity so that we can prepare, stock enough supplies and have sufficient numbers of healthcare workers to serve the patients.","2f7c2332":"#### Density by top 20 countries with COVID19 outbreak","9d0eb060":"## Weather\n\n<a id='temp'><\/a>\n\n#### In this section, I will break down by temperature (in Fahranheit), wind speed, humidity and sun hours to analyze and find their impact on the transmission rate accordingly.\n","57333032":"## Let's fit SEIR model on each country and region\n\n- I want to examine on U.S., New York, California (where I'm based), Italy and Spain.\n","25542a15":"- **Note**: The color represents the volume of precipitation and the size of the circle represents the number of Covid-19 Cases\n\n\n#### According to the graph, the outbreak does not differ much by precipitation.\n","7eb8f788":"### Windspeed by Country over time","86e22591":"#### Similar to the cases we saw earlier in European countries, as the number of infected cases rise, the number of recovery cases began to drop. This means that we need to supress the cases below the healthcare capacity so that we can prepare, stock enough supplies and have sufficient numbers of healthcare workers to serve the patients.","df68338a":"### Other countries","de3cfdaf":"### Which country has the first infected case?\n\n<a id='continents'><\/a>\n","23485921":"### Number of confirmed, fatal and recovered cases over time\n\n<a id='confirm_fatal'><\/a>\n","7f7b90c9":"#### Top 20 countries with number of COVID19 tests\n","a47c2d42":"#### Spain is different from other countries' pattern that we observe before. The number of infected cases in Spain are negatively impacted asw windspeed and humidity increase. \n\n#### While temperature increase, it significantly decreases the number of infected cases in Spain.\n","13962266":"#### In later [section](#demo_understand), I will examine the relationship between the death rate by lung diseases with fatal and infected rate by Covid-19.\n\n#### Even though that lung diseases may not directly impact on the number of confirmed and death cases, we need more investigation to understand if it correlate to worsening the health condition with people who are positive with Covid-19 in any possible ways.","4123518a":"#### Recovery Rate","240a0074":"#### According to the multilinear regression model, temperature, windspeed and humiditiy have statistically significant impact on the number of Covid-19 transmissions overall.\n\n#### Particular,\n- When temperature increase by 1 degree, the number of infected cases will decrease approximately 7 cases. \n- Similarly, when windspeed increase by 1 mile\/hour, the number of confirmed cases will increase by 178.\n- Finally, if the humidity level goes up by 1 unit, there will be nearly a decrease in 17 Covid cases.","59f372df":"#### Similar to the general pattern, the high humidity level also significantly decrease the number of Covid-19 infected cases. However, for the case in China, the windspeed does not have significant effect on transmission.\n","77a1298c":"#### Breakdown by Confirm and Fatal cases","5a857863":"#### Submission File from Kaggle","433a63be":"### Let's look at the North America countries and the U.S.","afdb9438":"# Covid19 Data Analysis\n\n## Background\nThe White House Office of Science and Technology Policy (OSTP) pulled together a coalition research groups and companies (including Kaggle) to prepare the COVID-19 Open Research Dataset (CORD-19) to attempt to address key open scientific questions on COVID-19. Those questions are drawn from National Academies of Sciences, Engineering, and Medicine\u2019s (NASEM) and the World Health Organization (WHO).\n\n## The Challenge\nKaggle is launching a companion COVID-19 forecasting challenges to help answer a subset of the NASEM\/WHO questions. We are currently on week 2.\n\nWhile the challenge involves forecasting confirmed cases and fatalities between April 2 and May 14 by region, the primary goal isn't only to produce accurate forecasts. It\u2019s also to identify factors that appear to impact the transmission rate of COVID-19.\n\nAs the data becomes available, Kaggle will update the leaderboard with live results based on data made available from the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE).\n\n## Analysis\nIn this challenge, I will be analyzing the open-source data from different contributors on Kaggle to answer these critical questions:\n\n- **What do we know about non-pharmaceutical interventions?** Ex: quarantine, cancelling large gatherings, widespread testing, etc.)\n\n- **What is known about transmission, incubation, and environmental stability?** Ex: Data on temperature, humidity and wind speed by region.\n\n- **What do we know about COVID-19 risk factors?** Ex: Percentage of the population that smokes, numbers of death by lung diseses or numbers of ICU for the patients in a country.\n\n- **When should we expect the number of infected cases will start to stabilize and decrease?** \n\n- **What would be the maximum number of cases in N days?**\n\nIn addition, I will predict the cumulative number of confirmed COVID19 cases as well as fatal cases in **173 countries** across the world for future dates **(ranging from April 1 - April 30)**.\n\n**Disclaimer from Kaggle:** We understand this is a serious situation, and in no way want to trivialize the human impact this crisis is causing by predicting fatalities. Our goal is to provide better methods for estimates that can assist medical and governmental institutions to prepare and adjust as pandemics unfold.\n","3ebe76c2":"#### US","099dfff6":"#### We can see that the curve was about to flatten out during mid-February, however, the cases continued to rised abruptly on Feb 10. \n\n### Let's break down in top 3 countries to see where the spike happened\n\n<a id='top3_countries'><\/a>\n","18cff7b8":"#### The first case began from the **U.S.**","fc96931c":"### Load Data\n\n#### Train dataset from Kaggle","c52707bb":"#### Test set from Kaggle","6789e455":"#### Complete dataset that include Geographic Data","ab462235":"#### We can see that the outbreak started from Washington state on March 9th and the strike leveled up from there.","b9c71b75":"### Demographic Data\n\n<a id='demo'><\/a>\n","89a7a960":"### Number of tests conducted","9994e0b4":"## 2) SEIR Model\n\n<a id='SEIR'><\/a>\n","10ae8da7":"### US","c2ea1ecb":"### Let's look into Asia countries","fc6005f2":"### We can already see China and Korea epidemic follwed this curve","7ed795de":"### Growth Equation\n\n**Growth factor**:\n\n$G_n = \\frac{G_n - G_{n-1}}{G_{n-1} - G_{n-2}}$\n\n**Growth ratio**:\n\n$G_n = \\frac{G_n }{G_{n-1}}$\n\n- $G_n$ : Number of cases on **n** day\n\nSpecial thanks to Daner Ferhadi for the functions.","b23600a4":"#### Death rate from lung diseases per 100k people by top 20 countries with COVID19 outbreak","4d1f884d":"#### Populations by top 20 countries with COVID19 outbreak","a386c922":"### Humidity by Country over time","466b629b":"### Load Packages","2e423c3d":"#### Fatality Rate","166e3c97":"### Sun Hour by Country over time\n","f625bb79":"- **Note**: The color represents the temperature levels and the size of the circle stands for the number of Covid-19 Cases\n\n#### This looks like the outbreak mostly widespreads in the region where the average temperature in Fahranheit is around 40 to 60 degrees.","2ee694f0":"### Italy","9e30a714":"#### Fatality Rate","bf581131":"### Model with intervention\n* There are different way to reduce $R_t$, [Different decay function](https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions) \n\nThis could be modified to take any function of $R_t(t)$ values to model the reproduction number as a time varying variable\n\nWhen we introduce intervention, we can curb the spread of the Covid-19 cases.\n","085f7938":"#### Recovery Rate","fbf3519c":"### Intervention by after days for SEIR model\n* after days, start interverntion, $ R_0 = R_0 * 0.5$","32bd471b":"Special thanks to: [funkyboy](https:\/\/www.kaggle.com\/super13579\/covid-19-global-forecast-seir-visualize) and [Daner Ferhadi](https:\/\/www.kaggle.com\/dferhadi\/logistic-curve-fitting-global-covid-19-confirmed)\n\n#### Reference:\n\n- [Exponential Growth - 3Blue1Brown](https:\/\/www.youtube.com\/watch?v=Kas0tIxDvrg&t=3s)\n- [Compartmental Model in Epidemiology](https:\/\/en.wikipedia.org\/wiki\/Compartmental_models_in_epidemiology#The_SEIR_model)\n- [Epidemic Calculator](http:\/\/gabgoh.github.io\/COVID\/index.html)\n\n## What's logistic curve or SEIR model and how they are related to predicting the pandemic?","db0e2567":"#### We can see that both China and Korea have hit the inflection point and flattened their curve for epidemic outbreak.\n\n#### If we look closely at Italy, U.S. and Spain, they are increasing the infected cases with an exponential growth.","75479047":"### Cleaning Data","7accaee2":"Source: [3Blue1Brown](https:\/\/www.youtube.com\/watch?v=Kas0tIxDvrg&t=3s)\n","a2a0b382":"#### People whose ages are above 65 are the most vulnerable towards coronavirus. Italy and Spain are among the top 5 countries with highest median age (above 40 years old) and, at the same time, with the highest number of fatal rate by Covid-19.","15d45f7e":"## About\n\n### COVID-19 (Corona Virus Disease 2019)\n- Caused by a SARS-COV-2 corona virus.\n- First identified in Wuhan, Hubei, China. The earliest reported symptoms was detected in November 2019.\n- On 30 January the WHO declared the outbreak to be a Public Health Emergency of International Concern\n- Until today, nearly 1 million people around the world are confirmed to be positive with Covid-19 by [Worldometer live tracking](https:\/\/www.worldometers.info\/coronavirus\/)\n\n\n### Data:\n\n- [Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE](https:\/\/github.com\/CSSEGISandData\/COVID-19)\n\n- [COVID19 Global Forecasting (Week 2)](https:\/\/www.kaggle.com\/c\/covid19-global-forecasting-week-2\/data)\n\n- [COVID-19 Complete Dataset (Updated every 24hrs)](https:\/\/www.kaggle.com\/imdevskp\/corona-virus-report)\n\n- [COVID19 Demographic Data](https:\/\/www.kaggle.com\/koryto\/countryinfo#covid19countryinfo.csv)\n\n- [World Population Data](https:\/\/www.kaggle.com\/anjum48\/covid19-population-data)\n\n- [Weather Data](https:\/\/www.kaggle.com\/noaa\/gsod)\n\n- [Additiional Weather Data](https:\/\/www.kaggle.com\/winterpierre91\/covid19-global-weather-data#temperature_dataframe.csv)","d2e0094b":"- The spread of an epidemic can be modeled using a logistic curve rather than an exponential curve. \n\n- The growth can start exponentially, however, it must slow down after some point called the **inflection point**.  The inflection point is essentially the midpoint of the spread. \n\nIn the next few sections, we will model the number of Covid-19 cases using a logistic curve. But first, let's briefly walk through the equation for the curve and the plot of the curve.\n\n\n\n","ff91ee1d":"- **Note**: The color represents the strength of the wind and the size of the circle represents the number of Covid-19 Cases\n\n\n#### According to the graph, the outbreak mostly widespreads in the region where the windspeed is around 40-50 miles\/hour ","3a988572":"#### Demographic Data\n\nSpecial thanks to [My Koryto](https:\/\/www.kaggle.com\/koryto) for the contribution of the data.\n\n**Dictionary**\n\n- Population (2020)\n- Density: The number of people who lives per square meter. (2020)\n- Median age (2020)\n- Urban population: the % of the population who lives in urban areas. (2020)\n- Hospital beds per 1,000 people\n- Forced quarantine policy initial date: I believe that a couple of weeks after this specific date, we can assume there would be a reduction of the infection rate. (updated on a daily basis)\n- School closure policy initial date: Same as (6). (updated on a daily basis)\n- Public places (bars, restaurants, movie theatres, etc.) closure policy initial date (updated on a daily basis)\n- The maximum amount of people allowed in gatherings and the initial date of the policy (updated on a daily basis)\n- Non-essential house leaving - initial date of the restriction (updated on a daily basis)\n- Sex ratio grouped by age groups (amount of males per female). (2020)\n- Lung disease death rate per 100k people, separated by sex. (2020)\n- % of smokers within the population: The higher this number is, the higher the fatalities number would be. (2019)\n- Amount of COVID detection test made per day: for about 50 countries\n- GDP-nominal (2019)\n- Health expenses in international USD (2019, 2017, 2015)\n- Health expenses divided by population (2020 - population), (2019, 2017, 2015 - health expenses)\n- Average amount of children per woman (2017)\n- First patient detection date\n- Total confirmed cases (updated on a daily basis)\n- Total active cases (updated on a daily basis)\n- New confirmed cases (updated on a daily basis)\n- Total deaths (updated on a daily basis)\n- New deaths (updated on a daily basis)\n- Total recovered (updated on a daily basis)\n- Amount of patients in critical situation (updated on a daily basis)\n- Total cases \/ 1 million population (updated on a daily basis)\n- Total deaths \/ 1 million population (updated on a daily basis)\n","65b3ba29":"#### Italy","fea935ce":"### How long since the first outbreak?\n\n<a id='first_outbreak'><\/a>\n\n","9328cfbd":"### Put the function in the current pandemic\n\nThere are 4 important factors in our model:\n- Growth Factor\n- Growth Ratio\n- Growth Rate\n- 2nd Derivative\n\nWe will use these growth metrics to gain insight into which countries may have already hit their inflection points. For example, **if a country's growth factor has stabilized around 1.0 then this can be a sign that that country has reached it's inflection point**. \n\nWe will then fit the logistic curve to the number of confirmed cases for each country. This will help us predict whether a country has hit their inflection point, and when they will reach a possible maximum number of confirmed cases.\n\nFurthermore, if we take the **2nd derivative**, it is telling us **how fast the case is growing**.\n\nThe bigger picture will be to correlate this with preventative efforts such as quarantines, widespread testing, etc.\n","2a2771b0":"#### Recovery Rate","1f936ac6":"## Fit the SEIR model to real data and predict\n\nFind the best variables of SEIR model to fit the real data\n* **T_inf** --> Using average value 2.9 \n* **T_inc** --> Using average value 5.2\n* **R_t** --> find the best reproduction number by fitting the real data (if have decay function, find the paramater of decay function)\n* **cfr** --> find the best Case fatality rate, this parater is for predict Fatalities","86d935c3":"#### On a positive side, even though New York is the most contagious state, the fatality rate is still considered small compared to Washington and Lousiana states.","da63eb22":"#### Median Age by top 20 countries with COVID19 outbreak","257ac4db":"Sun hour have high correlation with temperature (positive) and humidity (negative). Therefore, we will not include sunHour in the linear regression model.","3bbf895a":"#### The outbreak started in Italy in mid-Feb and in the U.S. from beginning of March.","83ca7e0f":"#### Beside China, South Korea is the top 2 country that have the highest number of COVID tests per day. Introducing widespread testing and contact tracing before quarantine or 'shelter in place' ban, the country has curb the COVID-19 spread signficantly by widespread testing only within a month.\n\nFurther reading: https:\/\/www.sciencemag.org\/news\/2020\/03\/coronavirus-cases-have-dropped-sharply-south-korea-whats-secret-its-success","28b13e4e":"While Iran, Japan and Malaysia are having the good sign of recovery, Thailand's recovery rate is decreasing.","ef2a58d0":"### Shelter In Place information","68b895f2":"#### It's clear that the outbreak began in **France**.","c584ee5c":"\n### Temperature by Country over time","915e280c":"## Predict all Country\/Region and Province\/States\n* Counting all Country\/Region MSLE & predict\n* If MSLE is lower than 1 , using PR model to retrain and check the performance","4fb25447":"### Let's look at the top 10 Europe countries with outbreaks in a timeline\n\n#### Confirmed Cases","23c71ca6":"### Intervention by Hill function for SEIR model\n- [Decay Function](https:\/\/github.com\/SwissTPH\/openmalaria\/wiki\/ModelDecayFunctions)","05622ab4":"### Cumsum signal\n* to prevent fluctuation","977a71fe":"### Number of cases around the world\n\n<a id='world'><\/a>\n","c35bbe82":"### Spain","1d7fbda2":"### Correlation Matrix","369dceb0":"Special thanks to [Datasaurus](https:\/\/www.kaggle.com\/anjum48\/covid19-population-data) for the Population data source."}}