{"cell_type":{"63618d69":"code","37c27df8":"code","b1805df3":"code","347b297d":"code","68d74e92":"code","2c45700e":"code","319a4843":"code","4c547cd0":"code","a0a5db75":"code","6a0f3aed":"code","74183a13":"code","3d3ca198":"code","09dddc41":"code","8b378adf":"code","ef6e6e85":"code","8481ae6d":"markdown","20cc4c45":"markdown","a0e5def5":"markdown","e7c48f41":"markdown","48a12937":"markdown"},"source":{"63618d69":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nprint(os.listdir(\"..\/input\"))\n\n","37c27df8":"train_df =  pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/train.csv', nrows = 1000000, parse_dates=[\"pickup_datetime\"])\ntest_df =  pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/test.csv',  parse_dates=[\"pickup_datetime\"])\n#only the first 1000000 rows are used to reduce running time\ntrain_df.dtypes","b1805df3":"#data cleaning part1\n# Find null values\n#Identify null values\nprint(train_df.isnull().sum())","347b297d":"#Drop rows with null values\nprint('Old size: %d' % len(train_df))\ntrain_df = train_df.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(train_df))","68d74e92":"#data cleaning part2\n#drop off data with extremely long distance between departure and arrival\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\nadd_travel_vector_features(train_df)\nplot = train_df.iloc[:20000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')\nprint('Old size: %d' % len(train_df))\ntrain_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(train_df))\nplot = train_df.iloc[:20000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","2c45700e":"#data cleaning part3\n#drop off data with strange longitude and latitude\nprint('Old size: %d' % len(train_df))\nplot = train_df.iloc[:20000].plot.scatter('dropoff_longitude', 'dropoff_latitude')\nplot = train_df.iloc[:20000].plot.scatter('pickup_longitude', 'pickup_latitude')\ntrain_df = train_df[(train_df.dropoff_longitude < -70) & (train_df.dropoff_latitude > 35) & (train_df.pickup_longitude < -70) & (train_df.pickup_latitude > 35)]\ntrain_df = train_df[(train_df.dropoff_longitude > -80) & (train_df.dropoff_latitude < 45) & (train_df.pickup_longitude > -80) & (train_df.pickup_latitude < 45)]\nplot = train_df.iloc[:20000].plot.scatter('dropoff_longitude', 'dropoff_latitude')\nplot = train_df.iloc[:20000].plot.scatter('pickup_longitude', 'pickup_latitude')\nprint('New size: %d' % len(train_df))\n","319a4843":"#Visualisation part1\n# plot histogram of fare\ntrain_df.fare_amount.hist(bins=100, figsize=(14,3))\nplt.xlabel('fare $USD')\nplt.title('Histogram');","4c547cd0":"#data cleaning part4\n#drop off data with fare below the smallest possible fare\nprint('Old size: %d' % len(train_df))\nplot = train_df.iloc[:20000].plot.scatter('fare_amount', 'fare_amount')\ntrain_df = train_df[(train_df.fare_amount > 3)]\nprint('New size: %d' % len(train_df))\nplot = train_df.iloc[:20000].plot.scatter('fare_amount', 'fare_amount')","a0a5db75":"#Visualisation part2\n# plot amount of records each day in train and test set\ntrain_df['pickup_datetime'] = pd.to_datetime(train_df.pickup_datetime)\ntest_df['pickup_datetime'] = pd.to_datetime(test_df.pickup_datetime)\ntrain_df.loc[:, 'pickup_date'] = train_df['pickup_datetime'].dt.date\ntest_df.loc[:, 'pickup_date'] = test_df['pickup_datetime'].dt.date\nplt.plot(train_df.groupby('pickup_date').count()[['key']], 'o-', label='train')\nplt.plot(test_df.groupby('pickup_date').count()[['key']], 'o-', label='test')\nplt.title('Train and test period complete overlap.')\nplt.legend(loc=0)\nplt.ylabel('number of records')\nplt.show()","6a0f3aed":"#Visualisation part3\n# plot amount of records each weakday in train and test set\ntrain_df['pickup_datetime'] = pd.to_datetime(train_df.pickup_datetime)\ntest_df['pickup_datetime'] = pd.to_datetime(test_df.pickup_datetime)\ntrain_df.loc[:, 'pickup_weekday'] = train_df['pickup_datetime'].dt.weekday\ntest_df.loc[:, 'pickup_weekday'] = test_df['pickup_datetime'].dt.weekday\nplt.plot(train_df.groupby('pickup_weekday').count()[['key']], 'o-', label='train')\nplt.plot(test_df.groupby('pickup_weekday').count()[['key']], 'o-', label='test')\nplt.title('Train and test period complete overlap.')\nplt.legend(loc=0)\nplt.ylabel('number of records')\nplt.show()\n#We found that the need of taxi on weekdays is higher than that on weekends.\n#While in test dataset, the chosen records are balanced according to the day of the week.","74183a13":"#Visualisation part4\n# plot amount of records each hour in train and test set\ntrain_df['pickup_datetime'] = pd.to_datetime(train_df.pickup_datetime)\ntest_df['pickup_datetime'] = pd.to_datetime(test_df.pickup_datetime)\ntrain_df.loc[:, 'pickup_hour'] = train_df['pickup_datetime'].dt.hour\ntest_df.loc[:, 'pickup_hour'] = test_df['pickup_datetime'].dt.hour\nplt.plot(train_df.groupby('pickup_hour').count()[['key']], 'o-', label='train')\nplt.plot(test_df.groupby('pickup_hour').count()[['key']], 'o-', label='test')\nplt.title('Train and test period complete overlap.')\nplt.legend(loc=0)\nplt.ylabel('number of records')\nplt.show()\n#From the plot we found that in train set the record of taxi rides reach the peak at around 19:00 while there are not much need of taxi at around 5:00 everyday,\n#At the same tiem the chosen of test set based on the time period is balanced.","3d3ca198":"import lightgbm as lgb\ntest_test = pd.read_csv('..\/input\/dataafterclean\/testAfterClean.csv')\ntrain = pd.read_csv('..\/input\/dataafterclean\/trainAfterClean.csv')\nval= pd.read_csv('..\/input\/dataafterclean\/validationAfterClean.csv')\ntest= pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/test.csv')\n","09dddc41":"def bearing_array(lat1, lng1, lat2, lng2):\n    AVG_EARTH_RADIUS = 6371  # in km\n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))\n\ntrain.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values,\n                                          train['pickup_longitude'].values, \n                                          train['dropoff_latitude'].values, \n                                          train['dropoff_longitude'].values)\ntest_test.loc[:, 'direction'] = bearing_array(test_test['pickup_latitude'].values,\n                                         test_test['pickup_longitude'].values, \n                                         test_test['dropoff_latitude'].values, \n                                         test_test['dropoff_longitude'].values)\nval.loc[:, 'direction'] = bearing_array(val['pickup_latitude'].values,\n                                         val['pickup_longitude'].values, \n                                         val['dropoff_latitude'].values, \n                                         val['dropoff_longitude'].values)\n\n\nfrom sklearn.decomposition import PCA\ncoords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n                    train[['dropoff_latitude', 'dropoff_longitude']].values,\n                    val[['pickup_latitude', 'pickup_longitude']].values,\n                    val[['dropoff_latitude', 'dropoff_longitude']].values,\n                    test_test[['pickup_latitude', 'pickup_longitude']].values,\n                    test_test[['dropoff_latitude', 'dropoff_longitude']].values))\n\npca = PCA().fit(coords)\ntrain['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntrain['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntrain['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntrain['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\nval['pickup_pca0'] = pca.transform(val[['pickup_latitude', 'pickup_longitude']])[:, 0]\nval['pickup_pca1'] = pca.transform(val[['pickup_latitude', 'pickup_longitude']])[:, 1]\nval['dropoff_pca0'] = pca.transform(val[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\nval['dropoff_pca1'] = pca.transform(val[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\ntest_test['pickup_pca0'] = pca.transform(test_test[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntest_test['pickup_pca1'] = pca.transform(test_test[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntest_test['dropoff_pca0'] = pca.transform(test_test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntest_test['dropoff_pca1'] = pca.transform(test_test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]","8b378adf":"X_train = train.drop(['fare_amount','pickup_latitude', 'pickup_longitude','dropoff_latitude', 'dropoff_longitude'], axis=1)\nY_train = train[\"fare_amount\"]\nX_test = val.drop(['fare_amount','pickup_latitude', 'pickup_longitude','dropoff_latitude', 'dropoff_longitude'], axis=1)\nY_test = val[\"fare_amount\"]\ntest_test = test_test.drop(['pickup_latitude', 'pickup_longitude','dropoff_latitude', 'dropoff_longitude'], axis=1)\n\nY_test = Y_test.reset_index().drop('index',axis = 1)\nY_train = Y_train.reset_index().drop('index',axis = 1)","ef6e6e85":"import xgboost as xgb\ndtrain = xgb.DMatrix(X_train, label=Y_train)\ndvalid = xgb.DMatrix(X_test, label=Y_test)\ndtest = xgb.DMatrix(test_test)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\nxgb_pars = {'min_child_weight': 1, 'eta': 0.1, 'colsample_bytree': 0.9, \n            'max_depth': 10,\n'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n'eval_metric': 'rmse', 'objective': 'reg:linear'}\nmodel = xgb.train(xgb_pars, dtrain, 1000, watchlist, early_stopping_rounds=40,\n      maximize=False, verbose_eval=1)\nprint('Modeling RMSLE %.5f' % model.best_score)\nxgb.plot_importance(model, max_num_features=10, height=0.7)\n\n\npred = model.predict(dtest)\nsubmission = pd.concat([test['key'], pd.DataFrame(pred)], axis=1)\nsubmission.columns = ['key','fare_amount']\nsubmission.to_csv(\"sub_xgb.csv\", index=False)","8481ae6d":"**New York City Taxi Fare Prediction**","20cc4c45":"**Data Visualization**","a0e5def5":"**Data Exploring**","e7c48f41":"**Building Model**","48a12937":"**Data Loading**"}}