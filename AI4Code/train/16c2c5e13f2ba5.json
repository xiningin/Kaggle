{"cell_type":{"901ac83b":"code","9a81a2a0":"code","5e99e7f4":"code","b94bcc34":"code","ccc086c9":"code","a3c9e14c":"code","39a1d90a":"code","be375374":"code","0624105b":"code","e102f69e":"code","ed92ffd2":"code","79608907":"code","25ab52ed":"code","b144d25f":"code","782c2b2a":"code","91e492ee":"code","e6bb1d8e":"code","ef9fb5fb":"code","c3bc512e":"markdown","d249103a":"markdown","42549c81":"markdown","f5c06ee4":"markdown","666ba4f2":"markdown","f5859600":"markdown","60692749":"markdown","1240d9d0":"markdown","f82e5e75":"markdown","d9e5a111":"markdown","fa675f45":"markdown","bf6c7ed1":"markdown","07a695d6":"markdown","13619ee2":"markdown"},"source":{"901ac83b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a81a2a0":"import numpy as np \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n#import seaborn as sns\n\nnp.random.seed(2)\nnum_classes=10\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport keras\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator","5e99e7f4":"train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","b94bcc34":"train_images=[]\nfor i in range(0,len(train)):\n    x=np.array(train.iloc[i][1:].values)\n    x=x.reshape(28,28)\n    train_images.append(x)\ntrain_images = np.asarray(train_images) \n\n\ntest_images = []\nfor i in range(0,len(test)):\n    x = np.array(test.iloc[i].values)\n    x = x.reshape(28,28)\n    test_images.append(x)\ntest_images = np.asarray(test_images)\n\nplt.imshow(train_images[7],cmap='gray')\nplt.show()","ccc086c9":"print(train.shape)\nprint(test.shape)","a3c9e14c":"X_train = train.drop(labels=[\"label\"],axis=1)\nY_train = train['label']","39a1d90a":"# normalising the data values\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n#images converted to grayscale ","be375374":"# reshape which will convert to a 28x28x1 array. height = width = 28. Gray scale so 1. RGB => 3\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","0624105b":"print(X_train.shape)\nprint(test.shape)","e102f69e":"# onehot encoding for label \nY_train_cat = to_categorical(Y_train, num_classes = 10)","ed92ffd2":"model = Sequential()\nmodel.add(Conv2D(64,(5,5),padding=\"valid\",strides=1,name=\"Conv1\",activation=\"relu\",input_shape=(28,28,1)))\n#practice model.add(Conv2D(8,(2,2),padding=\"valid\",strides=1,name=\"Conv2\"))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(8,(5,5),padding=\"valid\",strides=1,name=\"Conv2\",activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(64,activation =\"relu\"))\nmodel.add(Dense(32,activation=\"relu\"))\nmodel.add(Dense(10,activation =\"softmax\"))","79608907":"model.summary()","25ab52ed":"model.compile(loss = keras.losses.categorical_crossentropy,optimizer = RMSprop(),metrics =['accuracy'])","b144d25f":"History=model.fit(X_train,Y_train_cat,batch_size = 32,epochs =5,verbose= 1,validation_split = 0.2)","782c2b2a":"model.evaluate(X_train,Y_train_cat)","91e492ee":"predict=model.predict_classes(test)","e6bb1d8e":"results = pd.Series(predict,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,len(predict)+1),name = \"ImageId\"),results],axis = 1)","ef9fb5fb":"submission.to_csv(\"submission1.csv\", index = False)","c3bc512e":"# Import Libraries","d249103a":"# Model Prediction","42549c81":"# Submission","f5c06ee4":"## One Hot Encoading","666ba4f2":"## Normalisation","f5859600":"# Model Evaluation","60692749":"If you found this notebook helpful or you just liked it , some upvotes,Comments would be very much appreciated - That will keep me motivated to update it on a regular basis :-)","1240d9d0":"## ImageData Visullization","f82e5e75":"## Model Compile","d9e5a111":"## Reshape","fa675f45":"# Data Modelling","bf6c7ed1":"# Data Processing","07a695d6":"## Model Fit","13619ee2":"# Data Reading"}}