{"cell_type":{"d1e97b6d":"code","4dcfc902":"code","b2611fb6":"code","465c0600":"code","e1bdde0e":"code","5252034b":"code","b317f3cf":"code","d7750434":"code","a292394c":"code","83fc1ed2":"code","b307f295":"code","1ffe83f4":"code","58df856b":"code","b579f584":"code","5a1844f7":"code","ff47b2e3":"code","ff0ac2ae":"code","65b0db1b":"code","759fed8f":"code","58e09af9":"code","9df308b9":"code","a408e14f":"code","66db302c":"code","f48d6a82":"code","447aabe5":"code","0b3f047d":"code","0b026dca":"code","bc8ba6cb":"code","e730467a":"code","7aa3aa2b":"code","f21304c5":"code","568236d3":"code","5db65173":"code","02ddc20c":"code","8e414dea":"code","aa74f7b1":"code","e7b1bf6b":"code","0fbd882a":"code","dc6e969c":"code","100cacea":"code","a56ac5a2":"code","489ef37e":"code","44c5a871":"code","bc5b8dff":"code","ba78a799":"code","c5687e8f":"code","ec8f8532":"code","e07f9e7e":"code","2b2dd0d9":"code","14ff87eb":"code","7075ecca":"code","94b8ae2a":"code","844a7167":"code","302c248c":"code","11d1259d":"code","79d95dc1":"code","acd8111d":"code","a8c1d91b":"code","47adddd5":"code","5ff8eca6":"code","f6b8aa2f":"code","563f7af8":"markdown","fe50a87e":"markdown","49718ee9":"markdown","63901929":"markdown","06c9664a":"markdown"},"source":{"d1e97b6d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","4dcfc902":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b2611fb6":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport statsmodels.api as sm","465c0600":"# df = pd.read_csv('train.csv')\ndf = pd.read_csv('\/kaggle\/input\/iba-ml2-mid-project\/train.csv')","e1bdde0e":"df.head(5)","5252034b":"df.sample(5)","b317f3cf":"df.columns","d7750434":"df.info()","a292394c":"df['credit_line_utilization'] = df['credit_line_utilization'].str.replace(',', '.').astype('float')","83fc1ed2":"df.isnull().sum()","b307f295":"df.isnull().sum() \/ len(df)","1ffe83f4":"df.shape","58df856b":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5)\ndf2 = imputer.fit_transform(df.drop('Id', axis=1))","b579f584":"df2 = pd.DataFrame(df2, columns=df.drop('Id', axis=1).columns)","5a1844f7":"df2.number_dependent_family_members = round(df2.number_dependent_family_members)","ff47b2e3":"df2.columns","ff0ac2ae":"df2 = df2.rename(columns=\n                 {\n                     'number_dependent_family_members': 'fam_mem',\n                     'monthly_income': 'income',\n                     'number_of_credit_lines': 'ncl',\n                     'credit_line_utilization': 'clu',\n                     'number_of_previous_late_payments_up_to_59_days': 'late59',\n                     'number_of_previous_late_payments_up_to_89_days': 'late89',\n                     'number_of_previous_late_payments_90_days_or_more': 'late90',\n                     'real_estate_loans': 'loans',\n                     'ratio_debt_payment_to_income': 'ratio',\n                     'defaulted_on_loan': 'default'\n                 }\n                )\n\ndf2.head(3)","65b0db1b":"fig, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(df2.corr(), annot=True)","759fed8f":"df2.max() - df2.min()","58e09af9":"sns.boxplot(np.log(df2['income']))","9df308b9":"sns.pairplot(df2, hue='default')","a408e14f":"df2.default.value_counts()","66db302c":"n_rows = 3\nn_cols = 4\n\n# creating subplots\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(17, 10))\n\nfor i, column in enumerate(df2.columns):\n    sns.distplot(df2[column], ax=axes[i\/\/n_cols, i%n_cols])","f48d6a82":"df3 = np.log(df2.drop(['age', 'default'], axis=1) + 1)","447aabe5":"n_rows = 3\nn_cols = 4\n\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(17, 10))\n\nfor i, column in enumerate(df3.columns):\n    sns.distplot(df3[column], ax=axes[i\/\/n_cols, i%n_cols])","0b3f047d":"sns.distplot(np.log(df3.clu+1))","0b026dca":"df2.nunique()","bc8ba6cb":"df2.max() - df2.min()","e730467a":"df3.max() - df3.min()","7aa3aa2b":"sns.heatmap(pd.concat([df2, df3], axis=1).corr())","f21304c5":"df4 = pd.concat([df2, df3], axis=1)","568236d3":"lst = []\n\nfor i in df3.columns:\n    lst.append(i + \"_log\")","5db65173":"lst","02ddc20c":"df4.columns = list(df2.columns) + lst","8e414dea":"df4.head(5)","aa74f7b1":"df2","e7b1bf6b":"df2.drop_duplicates(inplace=True)","0fbd882a":"from imblearn.under_sampling import NearMiss\n\n# defining dataset\nX = df2.drop('default', axis=1)\ny = df2['default']\n\n# summarizing class distribution\nundersample = NearMiss(version=3, n_neighbors_ver3=3)\n\n# transforming the dataset\nX, y = undersample.fit_resample(X, y)","dc6e969c":"und = pd.concat([X, y], axis=1)","100cacea":"fig, ax = plt.subplots(figsize=(12, 8))\n\nsns.heatmap(und.corr(), annot=True)","a56ac5a2":"n_rows = 3\nn_cols = 4\n\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(18, 12))\n\nfor i, column in enumerate(und.columns):\n    sns.distplot(und[column], ax=axes[i\/\/n_cols, i%n_cols])","489ef37e":"und2 = und.drop(['age', 'default'], axis=1)\nund2 = np.log(und2 + 1)","44c5a871":"n_rows = 3\nn_cols = 4\n\nfig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(18, 12))\n\nfor i, column in enumerate(und2.columns):\n    sns.distplot(und2[column], ax=axes[i\/\/n_cols, i%n_cols])","bc5b8dff":"lst = []\n\nfor i in und2.columns:\n    lst.append(i + '_log')","ba78a799":"und2.columns = lst","c5687e8f":"und3 = pd.concat([und, und2], axis=1)","ec8f8532":"def vif_cal(input_data, dependent_col):\n    \n    vif_df = pd.DataFrame(columns=['Var', 'Vif'])\n    x_vars = input_data.drop([dependent_col], axis=1)\n    xvar_names = x_vars.columns\n    \n    for i in range(0, xvar_names.shape[0]):\n        y = x_vars[xvar_names[i]] \n        x = x_vars[xvar_names.drop(xvar_names[i])]\n        rsq = sm.OLS(y,x).fit().rsquared  \n        vif = round(1 \/ (1-rsq), 2)\n        vif_df.loc[i] = [xvar_names[i], vif]\n        \n    return vif_df.sort_values(by='Vif', axis=0, ascending=False, inplace=False)","e07f9e7e":"vif_cal(und3.drop(['ncl_log', 'late90', 'fam_mem_log', 'late59', 'income_log', 'loans_log'], axis=1), 'default')","2b2dd0d9":"und4 = und3.drop(['ncl_log', 'late90', 'fam_mem_log', 'late59', 'income_log', 'loans_log'], axis=1)","14ff87eb":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.heatmap(und4.corr(), annot=True)","7075ecca":"und4.drop(['fam_mem', 'late90_log', 'late89'], axis=1, inplace=True)","94b8ae2a":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.heatmap(und4.corr(), annot=True)","844a7167":"from sklearn.linear_model import LogisticRegression","302c248c":"model = LogisticRegression(solver='liblinear')","11d1259d":"from sklearn.model_selection import train_test_split\n\nX = und4.drop('default', axis=1)\ny = und4['default']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","79d95dc1":"model.fit(X_train, y_train)","acd8111d":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score as ras\nfrom sklearn.metrics import confusion_matrix as cm","a8c1d91b":"# checking model's accuracy\n\nprint('Report for Train set: \\n')\nprint(classification_report(y_train, model.predict(X_train)))\n\nprint('Report for Test set: \\n')\nprint(classification_report(y_test, model.predict(X_test)))\n\nprint('\\n')\nprint('ROC\/AUC score for Train: ')\nprint(ras(y_train, model.predict_proba(X_train)[:,1]))\n\nprint('\\n')\nprint('ROC\/AUC score for Test: ')\nprint(ras(y_test, model.predict_proba(X_test)[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix for Train: ')\nprint(cm(y_train, model.predict(X_train)))\n\nprint('\\n')\nprint('Confusion Matrix for Test: ')\nprint(cm(y_test, model.predict(X_test)))","47adddd5":"df4[X.columns]","5ff8eca6":"print('Report for whole data: \\n')\nprint(classification_report(df4['default'], model.predict(df4[X.columns])))\n\nprint('\\n')\nprint('ROC\/AUC score: ')\nprint(ras(df4['default'], model.predict_proba(df4[X.columns])[:,1]))\n\nprint('\\n')\nprint('Confusion Matrix: ')\nprint(cm(df4['default'], model.predict(df4[X.columns])))","f6b8aa2f":"df4.default.value_counts()","563f7af8":"### ABB Tech Academy - Machine Learning\n\n#### Step Project: EDA (Exploratory Data Analysis) notebook\n-------------------------------\nDate: 07.01.2022","fe50a87e":"Undersampling the data for building better model:\n<br>\n* less than 10% of data is defaulted, most algorithms just easily give all the value of 0 and gets higher (more than ~90%) accuracy\n<br>\n* by this method, we select relevant data points in majority class (default=0) and keep all the minority class (default=1) ","49718ee9":"VIF (Variance Inflation Factor) is used for detecting multicollinearity which is a problem for linear models","63901929":"VIF value higher than 10 (sometimes 4) means higher degree of multicollinearity, this variable should be excluded","06c9664a":"Some variables have lognormal distribution, better to have their log"}}