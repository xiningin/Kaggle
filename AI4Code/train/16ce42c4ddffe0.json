{"cell_type":{"18c6fa6f":"code","8fb2b197":"code","55798354":"code","3d388d79":"code","b4ee66dc":"code","4d21d411":"code","4e2ea621":"code","b45449f8":"code","3a4492eb":"code","564fa3de":"code","087e9cb0":"code","2cce7c11":"code","4962f024":"code","f811103a":"code","072df0e9":"code","96946eef":"code","a535eaca":"code","6752c831":"code","f29d5f25":"code","90134d9e":"code","f180d9d3":"code","c018a8c8":"code","fd5ba0ae":"code","056c16e7":"code","6b34ab2b":"code","6a1b81bd":"code","c56ee052":"code","6ed69a91":"code","d12afd3a":"code","c956bdf9":"code","04c2fecb":"code","78274d0d":"code","2da415f4":"code","22890176":"code","dd694c9a":"code","2b623b65":"code","c279b9be":"code","c56cdacc":"code","2cb2c354":"code","658451c6":"code","7cf76fd6":"code","6a2aeecc":"markdown","eea605f7":"markdown","ff3d2066":"markdown","184efd92":"markdown","d33b65a0":"markdown","e3dd8442":"markdown","b14a0b5a":"markdown","5540f479":"markdown","26a715a7":"markdown","8de35fef":"markdown","49abf073":"markdown","0cd36b90":"markdown","db482cb6":"markdown","7b550054":"markdown","a5c3b921":"markdown","c53d0d2d":"markdown","ebf6b785":"markdown","b519da8e":"markdown","d450b33f":"markdown","9d359ef2":"markdown","ca183682":"markdown","2c1242db":"markdown","7f44e16f":"markdown","4c61d3db":"markdown","da7df429":"markdown","75246e50":"markdown","b7baaf5f":"markdown","5d08abc3":"markdown","beb27258":"markdown","6822d385":"markdown","ca793a9d":"markdown","ba422245":"markdown","f2996d68":"markdown","2a1d447b":"markdown","a2ac331f":"markdown","ffb0aeb3":"markdown","272e9629":"markdown","0c4a4cd9":"markdown","aaed1f6e":"markdown","cf471508":"markdown","fe7f0b36":"markdown"},"source":{"18c6fa6f":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\nfrom pprint import pprint\n\n# Text processing\nimport nltk\n\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\n\n# spacy for lemmatization\nimport spacy\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn')\nimport seaborn as sns","8fb2b197":"def plot_categories( df , cat , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , row = row , col = col )\n    facet.map( sns.barplot , cat , target  )\n    facet.add_legend()\n    \n# NLTK Stop words\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","55798354":"# get CFPB complaints csv file as a DataFrame\ndf = pd.read_csv(\"\/kaggle\/input\/Consumer_Complaints.csv\", \n                 usecols=('Issue', 'Consumer complaint narrative'), \n                 nrows=100000)\n\nprint('Training Set Dataframe Shape: ', df.shape)\n\n#lets see the data\ndf.head(5)","3d388d79":"cnt_pro = df['Issue'].value_counts()\n\n# Plot 'Product' by frequency\nplt.figure(figsize=(24,6))\nsns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Issue', fontsize=1)\nplt.xticks(rotation=90)\nplt.show();","b4ee66dc":"# let's see how many Null values we have:\ndf.isnull().sum()","4d21d411":"# drop row if have Null in any column\ndf = df.dropna()\nprint('Dataset after removing Null values: ', df.shape)\n\ndf.head(10)","4e2ea621":"# rename column to 'narrative'\ndf.rename(columns = {'Consumer complaint narrative':'narrative'}, inplace = True)\n\n# Convert to list\nnarrative = df.narrative.values.tolist()\n\n# Let's see how our narrative text looks like before cleaning\npprint(narrative[:1])","b45449f8":"from wordcloud import WordCloud\n\ndef plot_wordcloud(wordcloud):\n    plt.figure(figsize=(12, 10))\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.axis(\"off\")\n    plt.show()","3a4492eb":"wordcloud = WordCloud(max_font_size=None, max_words=200, background_color=\"white\", \n                      width=5000, height=4000, stopwords=stop_words).generate(str(narrative))\n\nplot_wordcloud(wordcloud)","564fa3de":"# We will clean text using regex\nimport re \n\n# Remove spacial characters\nnarrative = [re.sub(r'[^\\w\\s]','',str(item)) for item in narrative]\n\n# Remove distracting single quotes\nnarrative = [re.sub(\"\\'\", \"\", str(item)) for item in narrative]\n\n# Remove masked data 'XXXX'\nnarrative = [re.sub(\"XXXX\", \"\", str(item)) for item in narrative]","087e9cb0":"# Let's see how our narrative text looks after cleaning\npprint(narrative[:1])","2cce7c11":"def sent_to_words(sentences):\n    for sentence in sentences:\n        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n\nnarrative_words = list(sent_to_words(narrative))\n\npprint(narrative_words[:1])","4962f024":"# Build the bigram and trigram models\nbigram = gensim.models.Phrases(narrative_words, min_count=5, threshold=100) # higher threshold fewer phrases.\ntrigram = gensim.models.Phrases(bigram[narrative_words], threshold=100)  \n\n# Faster way to get a sentence clubbed as a trigram\/bigram\nbigram_mod = gensim.models.phrases.Phraser(bigram)\ntrigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# See trigram example\nprint(trigram_mod[bigram_mod[narrative_words[0]]])","f811103a":"# Define functions for stopwords, bigrams, trigrams and lemmatization\ndef remove_stopwords(texts):\n    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n\ndef make_bigrams(texts):\n    return [bigram_mod[doc] for doc in texts]\n\ndef make_trigrams(texts):\n    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n\ndef lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \"\"\"https:\/\/spacy.io\/api\/annotation\"\"\"\n    texts_out = []\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    return texts_out","072df0e9":"# Remove Stop Words\nnarrative_words_nostops = remove_stopwords(narrative_words)\n\n# Form Bigrams\nnarrative_words_bigrams = make_bigrams(narrative_words_nostops)\n\n# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\nnlp = spacy.load('en', disable=['parser', 'ner'])\n\n# Do lemmatization keeping only noun, adj, vb, adv\nnarrative_lemmatized = lemmatization(narrative_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n\nprint(narrative_lemmatized[:1])","96946eef":"# Create Dictionary\nid2word = corpora.Dictionary(narrative_lemmatized)\n\n# Create Corpus\ntexts = narrative_lemmatized\n\n# Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in texts]\n\n# View\nprint(corpus[:1])","a535eaca":"# Human readable format of corpus (term-frequency)\n[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]","6752c831":"# Build LDA model\nlda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=10, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=100,\n                                           passes=10,\n                                           alpha='auto',\n                                           per_word_topics=True)","f29d5f25":"# Print the Keyword in the 10 topics\npprint(lda_model.print_topics())\ndoc_lda = lda_model[corpus]","90134d9e":"# Compute Perplexity\nprint('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda_model, texts=narrative_lemmatized, dictionary=id2word, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","f180d9d3":"def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values","c018a8c8":"# Can take a long time to run...\nmodel_list, coherence_values = compute_coherence_values(dictionary=id2word, \n                                                        corpus=corpus, \n                                                        texts=narrative_lemmatized, \n                                                        start=4, \n                                                        limit=30, \n                                                        step=2)","fd5ba0ae":"## Show graph\nlimit=30; start=4; step=2;\nx = range(start, limit, step)\nplt.plot(x, coherence_values)\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.show()","056c16e7":"# Print the coherence scores\nfor m, cv in zip(x, coherence_values):\n    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))","6b34ab2b":"# Select the model and print the topics\noptimal_model = model_list[1]\nmodel_topics = optimal_model.show_topics(formatted=False)\npprint(optimal_model.print_topics(num_words=10))","6a1b81bd":"# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(optimal_model, corpus, id2word)\nvis","c56ee052":"#nltk.download('vader_lexicon')\n\n# load the SentimentIntensityAnalyser object in\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# assign it to another name to make it easier to use\nanalyzer = SentimentIntensityAnalyzer()","6ed69a91":"# use the polarity_scores() method to get the sentiment metrics\ndef print_sentiment_scores(sentence):\n    snt = analyzer.polarity_scores(sentence)\n    print(\"{:-<40} {}\".format(sentence, str(snt)))","d12afd3a":"print_sentiment_scores(\"Women in Tech is a great event.\")","c956bdf9":"print_sentiment_scores(\"Women in Tech is a GREAT event.\")","04c2fecb":"print_sentiment_scores(\"Women in Tech is a GREAT event. :)\")","78274d0d":"print_sentiment_scores(\"Women in Tech is a GREAT event!!! :)\")","2da415f4":"# getting only the negative score\ndef negative_score(text):\n    negative_value = analyzer.polarity_scores(text)['neg']\n    return negative_value\n\n# getting only the neutral score\ndef neutral_score(text):\n    neutral_value = analyzer.polarity_scores(text)['neu']\n    return neutral_value\n\n# getting only the positive score\ndef positive_score(text):\n    positive_value = analyzer.polarity_scores(text)['pos']\n    return positive_value\n\n# getting only the compound score\ndef compound_score(text):\n    compound_value = analyzer.polarity_scores(text)['compound']\n    return compound_value","22890176":"df['sentiment_neg'] = df['narrative'].apply(negative_score)\ndf['sentiment_neu'] = df['narrative'].apply(neutral_score)\ndf['sentiment_pos'] = df['narrative'].apply(positive_score)\ndf['sentiment_compound'] = df['narrative'].apply(compound_score)","dd694c9a":"df.head(10)","2b623b65":"# all scores in 4 histograms\nfig, axes = plt.subplots(2, 2, figsize=(10,8))\n\n# plot all 4 histograms\ndf.hist('sentiment_neg', bins=25, ax=axes[0,0], color='lightcoral', alpha=0.6)\naxes[0,0].set_title('Negative Sentiment Score')\ndf.hist('sentiment_neu', bins=25, ax=axes[0,1], color='lightsteelblue', alpha=0.6)\naxes[0,1].set_title('Neutral Sentiment Score')\ndf.hist('sentiment_pos', bins=25, ax=axes[1,0], color='chartreuse', alpha=0.6)\naxes[1,0].set_title('Positive Sentiment Score')\ndf.hist('sentiment_compound', bins=25, ax=axes[1,1], color='navajowhite', alpha=0.6)\naxes[1,1].set_title('Compound')\n\n# plot common x- and y-label\nfig.text(0.5, 0.04, 'Sentiment Scores',  fontweight='bold', ha='center')\nfig.text(0.04, 0.5, 'Number of Complaints', fontweight='bold', va='center', rotation='vertical')\n\n# plot title\nplt.suptitle('Sentiment Analysis of CFPB Complaints\\n\\n', fontsize=12, fontweight='bold');","c279b9be":"# full dataframe with POSITIVE comments\ndf_pos = df.loc[df.sentiment_compound >= 0.9]\n\n# only corpus of POSITIVE comments\npos_comments = df_pos['narrative'].tolist()\n\n# full dataframe with NEGATIVE comments\ndf_neg = df.loc[df.sentiment_compound < 0.0]\n\n# only corpus of NEGATIVE comments\nneg_comments = df_neg['narrative'].tolist()","c56cdacc":"# read some positive comments\npos_comments[2:3]","2cb2c354":"# read some positive comments\nneg_comments[2:3]","658451c6":"df_pos['text_length'] = df_pos['narrative'].apply(len)\ndf_neg['text_length'] = df_neg['narrative'].apply(len)","7cf76fd6":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(8,5))\n\nsns.distplot(df_pos['text_length'], kde=True, bins=50, color='chartreuse')\nsns.distplot(df_neg['text_length'], kde=True, bins=50, color='lightcoral')\n\nplt.title('\\nDistribution Plot for Length of Complaint\\n')\nplt.legend(['Positive Narratives', 'Negative Narratives'])\nplt.xlabel('\\nText Length')\nplt.ylabel('Percentage of Comments\\n');","6a2aeecc":"### Let's compare the length of both positive and negative comments:","eea605f7":"### Setup helper Functions","ff3d2066":"### Import Libraries\n\nThe core packages used are:\n- re\n- nltk\n- gensim\n- spacy\n- pyLDAvis\n\nBesides this we will also using:\n- matplotlib\/seaborn\n- numpy\n- pandas \n\nfor data handling and visualization. Let\u2019s import them.","184efd92":"### Cleaning complaints narratives","d33b65a0":"### View the topics in LDA model\n\nThe above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n\nYou can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics() as shown next.","e3dd8442":"### Tokenize words\n\nLet\u2019s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n\nGensim\u2019s simple_preprocess() is great for this. Additionally I have set deacc=True to remove the punctuations.","b14a0b5a":"## CFPB Complaints Database\n\n<b>Consumer Financial Protection Bureau<\/b>: CFPB works to hold financial institutions accountable in matters related to financial products. CFPB contacts the relevant party on the behalf of consumer after a consumer files a complaint with it against the party. Also, it analyzes the database of complaints and takes relevant actions to deter financial institutions from indulging in abusive, misinformed and fraudulent practices.","5540f479":"### What makes VADER great for social media text?\n\nFour Heuristics of VADER:\n\n1. Emoticons (e.g. ! has value)\n2. Capitalization (AMAZING vs Amazing)\n3. Degree modifiers ('effing cute' vs 'sort of cute')\n4. Shift in polarity due to but (e.g. I love you, but I don't want to be with you anymore)\n","26a715a7":"# Case Study #1: Topic Modeling (CFPB Complaints Database)","8de35fef":"## NLP Process Flow:\n\n#### A typical NLP process flow has the following steps:\n\n<img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/419786\/801852\/NLP3.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1574372331&Signature=QXVrlf8uVov%2FWpXkyZ2QAmF188hrW6QdtPAxXo6qPlGphsg2SiRnF%2Fp7idm1P5DzDRqJfksqhcneT9b32x9mpia53pmuyKEw6HPKxzIGeIaLJvVc7%2FSsFytYZcTobF21bcJgDy198ogoKuzz1CwT8KVvgbYf3VobNo1DoXxf13tGBzM2w%2FGr7iYJd6DrhKERA8jv%2B%2BR8P0xIUaZ3sw3g9hOyd%2Fop54nwKoD%2B45ezGNBdezZVDdg7BUTenJzqWk5q3U6ts5gtPUmHYoicHUlg5F%2Fz95WjZNXMcPfY1rD8DgTXXDu%2BTuUCtGiZcY3lsaokcDsa1IvkgYxNoZHuU%2Bnglw%3D%3D\" alt=\"Drawing\"  align=\"center\">\n\n#### 1) Data Collection: \n- <b>Data mining or ETL<\/b> (extract-transform-load) process to collect a corpus of unstructured data.\n\n#### 2) Data Preprocessing:\n- <b>Tokenization:<\/b> Segmentation of running text into words.\n- <b>Lemmatization:<\/b> Removal of inflectional endings to return the base form.\n- <b>Parts-of-speech tagging:<\/b> Identification of words as nouns, verbs, adjectives etc.\n\n#### 3) Feature Engineering:\n- <b>Word Embeddings:<\/b> Transforming text into a meaningful vector or array of numbers.\n- <b>N-grams<\/b> : An unigram is a set of individual words within a document; bi-gram is a set of 2 adjacent words within a document.\n- <b>TF-IDF values:<\/b> Term-Frequency-Inverse-Document-Frequency is a numerical statistic representing how important a word is to a document within a collection of documents.\n\n#### 4) Application of NLP Algorithms:\n- <b>Latent Dirichlet Allocation:<\/b> Topic modeling algorithm for detecting abstract themes from a collection of documents.\n- <b>Support Vector Machine:<\/b> Classification algorithm for detection of underlying consumer sentiment.\n- <b>Long Short-Term Memory Network:<\/b> Type of recurrent neural networks for machine translation used in Google Translate.\n\nNow let\u2019s look at a couple of real-life case studies on actual customer complaints.","49abf073":"# Case Study #2: Sentiment Analysis using Valence Aware Dictionary and sEntiment Reasoner.\n","0cd36b90":"### Compute Model Perplexity and Coherence Score\n<b>Perplexity metric<\/b> is measuring how well does the model represent or reproduce the statistics of the held-out data.\nHowever, recent studies have shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated. <b>Optimizing for perplexity may not yield human interpretable topics<\/b>\n\n<b>Topic Coherence<\/b> measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.","db482cb6":"### Creating Bigram and Trigram Models\n\nBigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring.\n\nSome examples in our example are: \u2018front_bumper\u2019, \u2018oil_leak\u2019, \u2018maryland_college_park\u2019 etc.\n\nGensim\u2019s Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold. The higher the values of these param, the harder it is for words to be combined to bigrams.","7b550054":"### Wordcloud","a5c3b921":"## Agenda:\n\n - What is Natural Language Processing?\n\n - NLP Process Flow\n\n - Case Study 1: Topic Modelling\n    \n - Case Study 2: Sentiment Analysis\n\n - Wrap-up\n\n - Q&A","c53d0d2d":"### Let's investigate the distribution of all scores","ebf6b785":"## How does VADER work?\n\nVADER belongs to a type of sentiment analysis that is based on lexicons of sentiment-related words. In this approach, each of the words in the lexicon is rated as to whether it is positive or negative, and in many cases, how positive or negative. Below you can see an excerpt from VADER\u2019s lexicon, where more positive words have higher positive ratings and more negative words have lower negative ratings.\n\n<img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/419786\/801852\/vader1.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1574372745&Signature=DBxG6f6G5oz3D%2Bn8koFZrKBWl1QX8Hcjj5%2BxRCUSVQ0i07eY78tar8EI%2BtSeI6%2FyAomz%2FID5cRpnlhBAgfXM2QLlbR0Co%2F9tLUrn%2BUNQJFjPxggEEA4%2B9hz09f7%2FOi5gwtUSTzu08KnwWlRTu%2Ble%2FLmKveKDDqY6yx4AB8ZXcuWhF5EX2Xst2DUrVbkd6uxiJCb%2BDqx9hhNFt0gAf8dZRM%2Fhga51h03yTz%2Bfj8pTryQ6UiUYMN7vS69YFpsEAK7emcRVBLbBav%2F%2BUn1z8idfuyHmUv74Qc8AZXyiEuysI3uwm7aJ%2B7ZHeFPlLENGtnS0d%2BVOhnQlLMBlF0owJmQitw%3D%3D\" alt=\"Drawing\"  align=\"center\">\n\nLet's see how it works in practice...\n","b519da8e":"## Topic Modeling with Gensim\n\n<b>Topic Modeling<\/b> is a technique to extract the hidden topics from large volumes of text. \n<b>Latent Dirichlet Allocation(LDA)<\/b> is a popular algorithm for topic modeling with excellent implementations in the Python\u2019s Gensim package. \n\n### What does LDA do?\n\nLDA\u2019s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. \nAnd each topic as a collection of keywords, again, in a certain proportion.\n\nOnce you provide the algorithm with the number of topics, \nall it does it to rearrange the topics distribution within the documents \nand keywords distribution within the topics to obtain a good composition of topic-keywords distribution.\n\nWhen I say topic, what is it actually and how it is represented?\n\nA topic is nothing but a collection of dominant keywords that are typical representatives. \nJust by looking at the keywords, you can identify what the topic is all about.\n\nThe following are key factors to obtaining good segregation topics:\n\nThe quality of text processing.\nThe variety of topics the text talks about.\nThe choice of topic modeling algorithm.\nThe number of topics fed to the algorithm.\nThe algorithms tuning parameters.","d450b33f":"<table style=\"width:100%\">\n<tr>\n    <td style=\"font-size:26px\"><p align=\"left\"><b>Piotr Zalewski<\/b> <br><br> Head of CPB Finance Analytics <br><br> Natwest Poland<\/td>\n<td><p align=\"right\"><img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/419786\/801852\/NW_LOGO_ST_POS_CMYK.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1574370800&Signature=kc64Z5tMkiRKmcxlMabmNcWPLsmU32ZdNtOUOqFnfOwi0VzP2gtIk9FFHX%2FeGx%2BZ%2Fs%2BAgTc9%2F9rs1twh0MsFFJ0A9a6qXpqjzKWaesD4XSFe4olSsz%2Ftxf9NPN0YjRCKViqxJ2G%2FxQZOaqaKjpekaVLSGg6Pny%2BIjgrRWyP5XuqxiSvudCDPRhv6qEZcY73%2BV%2FGRHr5DQWMErxYpvz4LajrYcnKY1XTfLyhXuHgk2tbn1dy0QPDd%2BISPRcd4a7oPVHAE6uAEY2o4hsbVPNsJvKzcCBkPac3nLTiU7ECf4dmxckEvn8uWWd6BRGUQAXlvA2tD%2FPg%2FRFF2yuOAEg2zSw%3D%3D\" alt=\"Drawing\" width=\"150\" height=\"150\" align=\"right\"><\/td>\n<\/tr>\n<\/table>","9d359ef2":"After removing the masked data and spacial characters, the text still looks messy. \nIt is not ready for the LDA to consume. \nWe need to break down each sentence into a list of words through tokenization, while clearing up all the messy text in the process.\n\nGensim\u2019s simple_preprocess is great for this.","ca183682":"## Calculating Sentiment Score for our Complaints example","2c1242db":"<img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/419786\/801852\/Vader.jpg?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1574372662&Signature=U0jRCpym2SQ4xbm%2F8eFeYtMuYmGZ%2BnenpS4IpYS62GEoI7io5RVb83wUx%2Bu8yBtImykXTdSb26NEWpJkyICq6rUyEM7Q3SLmDEGlesg3rMIcwLQOqgELOPzibJoJHCTxxvJix0TZ6T3J2IJGbd85XUz1ViZFj2FdbNqsp%2FsWYK9F49mxMlRyf8FYjjNV6ypjweYaS6jCbmBDKkOIO66D4nGw3RzkCJuRKDin61Wf5DD5j%2FGSeYBJtwlohGWFp5meutG2nT9WyXgAqov%2FGccte2V1F5zssXXRc7iOhe%2FDn6dts2n8WLU86%2BtfX2C1Ca0VHXKgPuD3ZLRSb0DlRODmEQ%3D%3D\" alt=\"Drawing\"  align=\"center\">","7f44e16f":"So how to infer pyLDAvis\u2019s output?\n\nEach bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n\nA good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n\nA model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n\nAlright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.","4c61d3db":"## What is sentiment analysis?\n\n<b>Sentiment analysis<\/b> is simply the process of working out (statistically) whether a piece of text is positive, negative or neutral. The majority of sentiment analysis approaches take one of two forms: polarity-based, where pieces of texts are classified as either positive or negative, or valence-based, where the intensity of the sentiment is taken into account. For example, the words \u2018good\u2019 and \u2018excellent\u2019 would be treated the same in a polarity-based approach, whereas \u2018excellent\u2019 would be treated as more positive than \u2018good\u2019 in a valence-based approach.","da7df429":"### Load data","75246e50":"### Building the Topic Model\nWe have everything required to train the LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well.\n\nApart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0\/num_topics prior.\n\nchunksize is the number of documents to be used in each training chunk. update_every determines how often the model parameters should be updated and passes is the total number of training passes.\n","b7baaf5f":"## Data Preprocessing","5d08abc3":"VADER produces four sentiment metrics from these word ratings, which you can see below. The first three, positive, neutral and negative, represent the proportion of the text that falls into those categories. As you can see, our example sentence was rated as 50,6% positive, 49,4% neutral and 0% negative. \nThe final metric, the compound score, is the sum of all of the lexicon ratings which have been standardised to range between -1 and 1. In this case, our example sentence has a rating of 0.6249, which is pretty good.","beb27258":"# Wrap-up and Q&A","6822d385":"## Preparation","ca793a9d":"\n##### However, natural languages are extremely complex systems. \n##### Think of a human body; it consists of 11 separate systems (e.g., nervous, digestive etc.) working in tandem with each other. \n##### Similarly, a human language has several sub-systems such as phonology, morphology, and semantics working seamlessly with each other.\n\n\n<img src='https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/419786\/801852\/NLP2.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1574372308&Signature=cYbDCTH%2BdN2Ivr8DQab2bQXzUgYFn7I5Smv%2FsllqEDpxmA14PfAMXM9qKEHp6Ruofbg%2Br2WxpE46%2BkS7eEyWi73jS68BVSUZYDK8TviyoaJ9MIc%2Fz2YTD2RnDE4JfZZzievs676GpC5nEqfXx9xRzlUM9jdKM%2B1nC%2FlrwAFL9TZTxL9ab0%2Bh6hOAHvtJWq41PFypkeLjPGOFZDCflOrTmpWZkqUlVrCaOY6jQhJxYAnfsgOXtr1O%2Bp%2Bg5H%2FfBpLhvsgY3TmDTYgztLtcn8RXtUlx8An6MmYgGzJpuuJrA0YRcqglU4ORy0FoB%2B5yvfhE8dM2DaLoytFY8dGkx91UgA%3D%3D' alt=\"Drawing\"  align=\"center\">\n\n##### This complex interplay of different sub-systems makes learning a new language a difficult proposition. \n##### If you are a native English speaker it will probably take you 2,000+ class hours to be fluent in Mandarin. \n##### That\u2019s several years\u2019 worth of studying! \n##### This is the reason why the progress in NLP has been slow as compared with other areas within Machine Learning and AI.\n","ba422245":"## Visualize the topics-keywords\nNow that the LDA model is built, the next step is to examine the produced topics and the associated keywords. \nThere is no better tool than pyLDAvis package\u2019s interactive chart and is designed to work well with jupyter notebooks.","f2996d68":"### Remove Null Values","2a1d447b":"\n\n\n\n### Natural Language Processing (NLP)\n\n##### NLP is the ability of machines to understand and analyze human language. \n##### It is a part of the Artificial Intelligence (AI) domain with a significant overlap with Linguistics.\n\n\n<img src=\"https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/419786\/801852\/NLP.png?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1574370895&Signature=dNAyQKMGWI87C1CZ2xZq88kxJPLXamYGmBYILOI18ebByaPyX%2FoLwF%2Fv61MMDuA%2BqUzD%2BXg7UsYM9q7hlHWBDc7pMdCO8ROAyKAkCgzFU8uI5epvf1hZLwa7U5OunSg5gPCbr%2BPcoxYvu9XmiByC5glRN40b8M12s5EqYhPSIOef%2Fe1u9FsQuxOLA0b2q2OnzniawmJ7albVdEjoK1koAwG2lVFsFwNITiTEyJhMt3ZMKjWArO9pvYCD3j6x1b%2B4BnKvI1IDjO%2FDAvG1bBE2zTAyi9jNut%2FmxY12HV9p5pKbRxTxbUubG2Hq0ZDDlK59SZrju9r24OYyl%2FoF6hkjrw%3D%3D\" alt=\"Drawing\"  align=\"center\">","a2ac331f":"### Let's review some positive and negative comments:","ffb0aeb3":"# Natural Language Processing in Python","272e9629":"### Removing Stop Words, Making Bigrams and Lemmatize\n\nThe bigrams model is ready. \nLet\u2019s define the functions to remove the stopwords, make bigrams and lemmatization and call them sequentially.\n\n<b>Stop words:<\/b> Stop Words are words which do not contain important significance to be used in Search Queries. Usually, these words are filtered out from search queries because they return a vast amount of unnecessary information. Each programming language will give its own list of stop words to use. Mostly they are words that are commonly used in the English language such as 'as, the, be, are' etc.\n\n<b>Lemmatization<\/b>, reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words.\nFor example, runs, running, ran are all forms of the word run, therefore run is the lemma of all these words. Because lemmatization returns an actual word of the language, it is used where it is necessary to get valid words.","0c4a4cd9":"Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n\nFor example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n\nThis is used as the input by the LDA model.","aaed1f6e":"### Create the Dictionary and Corpus needed for Topic Modeling\n\nThe two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let\u2019s create them.","cf471508":"### How to find the optimal number of topics for LDA?\n\nMy approach to finding the optimal number of topics is to build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value.\n\nChoosing a \u2018k\u2019 that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics.\n\nIf you see the same keywords being repeated in multiple topics, it\u2019s probably a sign that the \u2018k\u2019 is too large.\n\nThe compute_coherence_values() (see below) trains multiple LDA models and provides the models and their corresponding coherence scores.","fe7f0b36":"### Explore Variable - 'Issue'"}}