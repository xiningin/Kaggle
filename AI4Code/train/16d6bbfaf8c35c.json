{"cell_type":{"7e13f904":"code","775e8422":"code","d347a1fc":"code","0a786db4":"code","f158faad":"code","e488ce90":"code","b042b9eb":"code","97be5017":"code","4b4980d2":"code","7895d38f":"code","d7ae432b":"code","dfab5621":"code","ee458d56":"code","ea9c473c":"code","3ea1d0f6":"code","0259c89e":"code","89b85d73":"code","19523cc5":"code","999a226d":"code","12b7dc79":"code","56f756df":"code","2e44bbb6":"code","a13a0b8b":"code","10be2744":"code","b836cc77":"code","7772e5b1":"code","c68127cf":"code","4472604d":"code","e80d0a70":"code","b77c0b3a":"code","441dc0c1":"code","ba45b109":"code","65d36cef":"code","2de4920b":"code","a1800abd":"code","33143e98":"code","469cc0c2":"markdown","cab1fbd3":"markdown"},"source":{"7e13f904":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","775e8422":"import seaborn as sns\nimport matplotlib.pyplot as plt","d347a1fc":"from sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.utils import resample","0a786db4":"from keras.utils.np_utils import to_categorical\nfrom keras.layers import Convolution1D, MaxPool1D, Dense, Input, Flatten\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model","f158faad":"root = '\/kaggle\/input\/heartbeat\/'","e488ce90":"train_df = pd.read_csv(root+'mitbih_train.csv', header=None)\ntest_df = pd.read_csv(root+'mitbih_test.csv', header=None)","b042b9eb":"train_df.head()","97be5017":"train_df.info()","4b4980d2":"class_dist = train_df[187].astype(int).value_counts()\nclass_dist","7895d38f":"class_dist.mean()","d7ae432b":"plt.figure(figsize=(10, 7))\np = class_dist.plot(kind='pie',\n                    labels=['N','S','V','F','Q'],\n                    autopct='%1.1f%%')\np.add_artist(plt.Circle((0,0), 0.7, color='white'))\nplt.title('Class Distribution')\nplt.legend()\nplt.show()\nplt.savefig('Origial Class Distribution.PNG')","dfab5621":"#train_df_new\ndf_0 = train_df[train_df[187]==0].sample(n=20000, random_state=8)\ndf_1 = resample(train_df[train_df[187]==1], n_samples=20000,replace=True,\n                                           random_state=8)\ndf_2 = resample(train_df[train_df[187]==2], n_samples=20000,replace=True,\n                                           random_state=8)\ndf_3 = resample(train_df[train_df[187]==3], n_samples=20000,replace=True,\n                                           random_state=8)\ndf_4 = resample(train_df[train_df[187]==4], n_samples=20000,replace=True,\n                                           random_state=8)","ee458d56":"train_df_new = pd.concat([df_0, df_1, df_2, df_3, df_4])","ea9c473c":"plt.figure(figsize=(10, 7))\np = train_df_new[187].value_counts().plot(kind='pie',\n                    labels=['N','S','V','F','Q'],\n                    autopct='%1.1f%%')\np.add_artist(plt.Circle((0,0), 0.7, color='white'))\nplt.title('Class Distribution: Post Random-Sampling')\nplt.legend()\nplt.show()\nplt.savefig('post random sampling class dist.PNG')","3ea1d0f6":"c = train_df_new.groupby(187, group_keys=False)\\\n        .apply(lambda train_df_new: train_df_new.sample(1))\nc","0259c89e":"fig, axes = plt.subplots(5, 1, figsize=(16, 11))\n\nleg = iter(['N', 'S', 'V', 'F', 'U'])\ncolors = iter(['skyblue', 'red', 'lightgreen', 'orange', 'black'])\nfor i, ax in enumerate(axes.flatten()):\n    ax.plot(c.iloc[i, :186].T, color=next(colors))\n    ax.legend(next(leg))\nplt.title('Sample of different heart-beat types')\nplt.show()\nplt.savefig('heart beat sample.PNG')","89b85d73":"def plot_hist(class_num, min_val = 5, size = 70, title=''):\n    img = train_df_new.loc[train_df_new[187]==class_num].values\n    img = img[:, min_val: size]\n    img_flatten = img.flatten()\n\n    final1 = np.arange(min_val, size)\n    for _ in range(img.shape[0]-1):\n        tempo1 = np.arange(min_val, size)\n        final1 = np.concatenate((final1, tempo1))\n    print(len(final1))\n    print(len(img_flatten))\n    plt.hist2d(final1, img_flatten, bins=(80, 80), cmap=plt.cm.jet)\n    plt.title('2D Histogram- '+title)\n\n    plt.show()\n    plt.savefig('2D Histogram- '+title+'.PNG')","19523cc5":"plot_hist(0, title='Normal Heart Beat')","999a226d":"plot_hist(1, 5, 50, title='Supraventricular ectopic beats')","12b7dc79":"plot_hist(2, 30, 70, title='Ventricular ectopic beats')","56f756df":"plot_hist(3, 20, 58, title='Fusion beats')","2e44bbb6":"plot_hist(4, 15, 70, title='Unknown beats')","a13a0b8b":"def add_gaussian_noise(signal):\n    noise = np.random.normal(0, 0.05, 186)\n    return signal+noise","10be2744":"plt.figure(figsize=(14, 7))\ntempo = c.iloc[0, :186]\nbruiter = add_gaussian_noise(tempo)\n\n# tempo\nplt.subplot(2,1,1)\nplt.plot(tempo)\n\nplt.title('ECG: BEFORE Gaussion noise additon')\n\n#bruiter\nplt.subplot(2,1,2)\nplt.plot(bruiter)\n\nplt.title('ECG: AFTER Gaussion noise additon')\n\n\nplt.show()\nplt.savefig('ECG Gaussian noise transformation.PNG')","b836cc77":"# data prepapration : Labels\ntarget_train = train_df_new[187]\ntarget_test = test_df[187]\n\ny_train = to_categorical(target_train)\ny_test = to_categorical(target_test)","7772e5b1":"# data prepapration : Features\nX_train = train_df_new.iloc[:,:186].values[:,:, np.newaxis]\nX_test = test_df.iloc[:,:186].values[:,:, np.newaxis]","c68127cf":"def train_model(X_train, y_train, X_test, y_test):\n    \n    # input signal image shape\n    im_shape = (X_train.shape[1], 1)\n    \n    # Input layer\n    inputs_cnn = Input(shape = (im_shape),\n                       name='inputs_cnn')\n    \n    # Block 1\n    conv1_1 = Convolution1D(64, (6), activation='relu',\n                            input_shape=im_shape)(inputs_cnn)\n    conv1_1 = BatchNormalization()(conv1_1)\n    \n    pool1 = MaxPool1D(pool_size=(3), strides=(2),\n                            padding='same')(conv1_1)\n    \n    # Block 2\n    conv2_1 = Convolution1D(64, (3), activation='relu',\n                            input_shape=im_shape)(pool1)\n    conv2_1 = BatchNormalization()(conv2_1)\n    \n    pool2 = MaxPool1D(pool_size=(3), strides=(2),\n                    padding='same')(conv2_1)\n\n    # Block 3\n    conv3_1 = Convolution1D(64, (3), activation='relu',\n                            input_shape=im_shape)(pool2)\n    conv3_1 = BatchNormalization()(conv3_1)\n    \n    pool3 = MaxPool1D(pool_size=(3), strides=(2),\n                            padding='same')(conv3_1)\n    # Flatten\n    flatten = Flatten()(pool3)\n    \n    # Dense Block\n    dense1 = Dense(64, activation='relu')(flatten)\n    dense2 = Dense(32, activation='relu')(dense1)\n    \n    # Output Block\n    output = Dense(5, activation='softmax', name='output')(dense2)\n    \n    # compile model\n    model = Model(inputs= inputs_cnn, outputs= output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy',\n                 metrics=['accuracy'])\n    \n    callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n                ModelCheckpoint(filepath='best_model.h5',\n                                monitor='val_loss',\n                                save_best_only=True)]\n    # training\n    print('Training...')\n    history=model.fit(X_train, y_train, epochs=40, batch_size=32,\n                      validation_data=(X_test, y_test),\n                      callbacks=callbacks)\n    \n    model.load_weights('best_model.h5')\n    \n    return (model, history)","4472604d":"def evaluate_model(history, X_test, y_test, model):\n    scores = model.evaluate((X_test), y_test, verbose=0)\n    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n    \n    print(history)\n    fig1, ax_acc = plt.subplots()\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Model - Accuracy')\n    plt.legend(['Training', 'Validation'], loc='lower right')\n    plt.show()\n    \n    fig2, ax_loss = plt.subplots()\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Model - Loss')\n    plt.legend(['Training', 'Validation'], loc='upper right')\n    plt.show()\n    plt.savefig('step evalutaion.PNG')\n    target_names = [str(i) for i in range(5)]\n    \n    y_true = []\n    for element in y_test:\n        y_true.append(np.argmax(element))\n    prediction_proba = model.predict(X_test)\n    prediction = np.argmax(prediction_proba, axis=1)\n    cnf_matrix = confusion_matrix(y_true, prediction)\n        ","e80d0a70":"model, history = train_model(X_train, y_train, X_test, y_test)","b77c0b3a":"evaluate_model(history, X_test, y_test, model)\ny_pred = model.predict(X_test)","441dc0c1":"y_test","ba45b109":"np.arange(len(y_pred))","65d36cef":"y_pred_clean = np.zeros_like(y_pred)\nfor idx, i in enumerate(np.argmax(y_pred,axis=1)):\n    y_pred_clean[idx][i] = 1","2de4920b":"print(classification_report(y_test, y_pred_clean))","a1800abd":"conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred_clean, axis=1))\nprint(conf_matrix)","33143e98":"plt.figure(figsize=(10, 7))\nsns.heatmap(np.corrcoef(conf_matrix))\nplt.title('Confusion Matrix Corrleation-Coefficient')\nplt.savefig('Confusion Matrix Correlation Coefficient.png')","469cc0c2":"### ['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4]\n\n-N : Non-ecotic beats (normal beat) -S : Supraventricular ectopic beats -V : Ventricular ectopic beats -F : Fusion Beats -Q : Unknown Beats","cab1fbd3":"### Model"}}