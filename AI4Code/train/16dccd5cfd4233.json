{"cell_type":{"39bfc86a":"code","5b5c9c30":"code","4361eaef":"code","a1379985":"code","ba524931":"code","b6c983ba":"code","b24ec07a":"code","da2debbf":"code","3e9139ee":"code","5b51e349":"code","2ba07b12":"code","811bd29c":"code","e6899d9a":"code","b1777050":"code","b1a4c103":"code","6c68fdd4":"code","649c510c":"code","de3f8516":"code","c172893c":"code","19f0a636":"markdown","64daa294":"markdown","a541ec3b":"markdown","24ef06a2":"markdown","22c885a6":"markdown","fd61de31":"markdown","d830aa12":"markdown"},"source":{"39bfc86a":"# Bibliotecas necess\u00e1rias\n\n# manipula\u00e7\u00e3o de dados\nimport os\nimport re\nimport cv2\nimport random\nimport numpy as np\n\n# redes neurais\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\n\nfrom sklearn.model_selection import train_test_split\n\n# plot\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n%matplotlib inline ","5b5c9c30":"labels = []\nimages = []\nasanas_name = []\nimages_path = []\nimages_pixels = []\n\ndataset_path ='..\/input\/yoga-pose-image-classification-dataset\/dataset'\n\nclasses_20 = os.listdir(dataset_path)[:20]\n\nfor i, directory in enumerate(classes_20):\n    asanas_name.append(directory)\n    for img in os.listdir(os.path.join(dataset_path,directory)):  \n        if len(re.findall('.png',img.lower())) != 0 or len(re.findall('.jpg',img.lower())) != 0 or len(re.findall('.jpeg',img.lower())) != 0:\n            img_path = os.path.join(os.path.join(dataset_path,directory),img)\n            images.append(img)\n            images_path.append(img_path)\n            img_pix = cv2.imread(img_path,3)\n            images_pixels.append(cv2.resize(img_pix, (100,100)))\n            labels.append(i)\n    \nprint(\"Total labels: \", len(labels))\nprint(\"Total images: \", len(images))\nprint(\"Total images path: \", len(images_path))\nprint(\"Total grupos poses de Yoga: \", len(asanas_name))\n\nprint(\"Total images_pixels: \", len(images_pixels))","4361eaef":"print('Total de grupos poses de Yoga:', len(classes_20), '\\n')\n\nclasses = []\nfor class_ in classes_20:\n    classes.append(class_)\n    print(class_)","a1379985":"fig = plt.gcf()\nfig.set_size_inches(16, 16)\n\nnext_pix = images_path\nrandom.shuffle(next_pix)\n\nfor i, img_path in enumerate(next_pix[0:12]):\n    \n    sp = plt.subplot(4, 4, i + 1)\n    sp.axis('Off')\n\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n\nplt.show()","ba524931":"# Analisando o dataset\nshuf = list(zip(images_pixels,labels))\nrandom.shuffle(shuf)\n\ntrain_data, labels_data = zip(*shuf)","b6c983ba":"# Separando x_train e y_train | # Transformando a imagem 2d em um numpy array | #Normalizando para valores entre 0 e 1\nX_data = np.array(train_data) \/ 255 \nY_data =  to_categorical(labels_data, num_classes = 20) # vetor de saida com 20 dimensoes\nY_data[0]","b24ec07a":"print(\"Quantidade de elementos de conjunto de dados: {}\". format(len(train_data)))\n\n\nprint(\"X total: \", X_data.shape)\nprint(\"Y total: \", Y_data.shape)","da2debbf":"# Separando uma parte para treino (70%) e outra para valida\u00e7\u00e3o (30%)\nX_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size = 0.3, random_state=101)\n\nprint(\"X treino : \", len(X_train))\nprint(\"X Qtde de valida\u00e7\u00e3o : \", len(X_val))\nprint(\"Y teste : \", len(Y_train))\nprint(\"Y Qtde de valida\u00e7\u00e3o : \", len(Y_val))","3e9139ee":"im_shape = (100,100)\nnum_classes = 20\nseed = 10\nBATCH_SIZE = 16\n\nim_shape[0], im_shape[1]","5b51e349":"# Criando e treinando o modelo Sequential\n# Sequential: Modelo Keras de ir adicionando camadas (como um lego)\n# Conv2D: Camada com kernels (filtros) que percorrem a imagem extraindo caracter\u00edsitcas (mapas de caracte\u00edsticas)\n# MaxPooling2D: Camada que reduz a dimensionalidade dos mapas de caracter\u00edsticas 2D\n# Flatten: Camada que transforma um mapa de caracter\u00edsticas 2D num vetor para classficador final\n# Dense: Camada onde todas as entradas est\u00e3o conectadas em cada neur\u00f4nio (totalmente conectada)\n# Dropout: Camada usa durante treino que descarta aleatoriamente um percentual de conex\u00f5es (reduz overfitting)\n\nmodel = Sequential()\nmodel.add(Conv2D(35, kernel_size=(10, 10), activation='relu', input_shape=(100,100,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(60, kernel_size=(3,3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(40, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","2ba07b12":"# Compilando o modelo\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(),\n              metrics=['accuracy'])","811bd29c":"# Treina com os parte dos dados\nbatch_size = 32\nepochs = 50\n\n\n\n#Salvar o melhor modelo\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=2),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=2)\n]\n\nhistory = model.fit(X_train, Y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    callbacks = callbacks_list,\n                    verbose=1,\n                    validation_data=(X_val, Y_val))","e6899d9a":"#Vamos ver como foi o treino?\n# X_train, X_val, Y_train, Y_val\n\nfig, ax = plt.subplots(1,2, figsize=(16,8))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","b1777050":"from tensorflow.keras.models import load_model\n# Load the best saved model\nmodel = load_model('model.h5')\n\n# Test\nscore = model.evaluate(X_val, Y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","b1a4c103":"#from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam","6c68fdd4":"base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(im_shape[0], im_shape[1], 3))\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(100, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n    \noptimizer = Adam()\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","649c510c":"epochs = 80\n\n#Retorno de chamada para salvar o melhor modelo\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\n#Training\nhistory = model.fit(X_train, Y_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    callbacks = callbacks_list,\n                    verbose=1,\n                    validation_data=(X_val, Y_val))","de3f8516":"from tensorflow.keras.models import load_model\n# Load the best saved model\nmodel = load_model('model.h5')\n\n# Test\nscore = model.evaluate(X_val, Y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","c172893c":"# Training curves\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","19f0a636":"Observa\u00e7\u00e3o: Um fluxo de trabalho de depura\u00e7\u00e3o comum: [add() + summary()](https:\/\/keras.io\/guides\/sequential_model\/)\n\nAo construir uma nova arquitetura sequencial, \u00e9 \u00fatil empilhar camadas de forma incremental add() e imprimir resumos de modelos com frequ\u00eancia. Por exemplo, isso permite que voc\u00ea monitore como uma pilha de camadas Conv2D e MaxPooling2D est\u00e1 reduzindo a resolu\u00e7\u00e3o de mapas de recursos de imagem.","64daa294":"No caso do nosso dataset, n\u00e3o precisa criar o Generator por termos uma amostra significativa.","a541ec3b":"# Modelo 1: Convolutional Neural Networks","24ef06a2":"# Pr\u00e9-processamento do conjunto de dados","22c885a6":"# Classifica\u00e7\u00e3o de imagens\n\n### Alunas: Paula Samanta e Giovana de Lucca\n\n- Nesse notebook ser\u00e1 implementado modelos de deep learning para classifica\u00e7\u00e3o considerando a melhor avalia\u00e7\u00e3o de acur\u00e1cia poss\u00edvel.\n- Comparando um modelo totalmente desenvolvido manualmente e um modelo baseado em arquiteturas cl\u00e1ssicas e transfer learning.","fd61de31":"# Modelo 2: Convolutional Neural Networks + Transfer Learning","d830aa12":"# Conjunto de dados: [Yoga Pose Image classification](https:\/\/www.kaggle.com\/shrutisaxena\/yoga-pose-image-classification-dataset)"}}