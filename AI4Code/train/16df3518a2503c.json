{"cell_type":{"63214d29":"code","d632b437":"code","76b1a3cf":"code","b9afa198":"code","25674e17":"code","6d9c25e0":"code","e67f4d0d":"code","39ed177b":"code","73018614":"code","bff6910f":"code","b1c03af3":"code","f70e3771":"code","214abfea":"code","e6960078":"code","f56771e6":"code","138c83d4":"code","73b7946d":"code","be0eb407":"code","a7fadf70":"code","8030a4ca":"code","40b030e7":"code","0038a1ab":"code","7de4a937":"code","84cf57c8":"code","bd73701c":"code","9b202244":"markdown","2ebdbd12":"markdown","6b780391":"markdown"},"source":{"63214d29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d632b437":"data = pd.read_csv(\"..\/input\/boston-housing-dataset\/HousingData.csv\")\ndata.head(5)","76b1a3cf":"len(data)","b9afa198":"data.info()","25674e17":"data.isnull()","6d9c25e0":"data.isnull().sum","e67f4d0d":"data.dropna(how=\"all\" , inplace=True)\n","39ed177b":"data.shape","73018614":"print(np.shape(data))","bff6910f":"data.describe()","b1c03af3":"prices = data['MEDV']\nprices","f70e3771":"# data exploration\n# Minimum price of the data\nminimum_price = np.amin(prices)\n\n# Maximum price of the data\nmaximum_price = np.amax(prices)\n\n# Mean price of the data\nmean_price = np.mean(prices)\n\n# Median price of the data\nmedian_price = np.median(prices)\n\n# Standard deviation of prices of the data\nstd_price = np.std(prices)\n\n# Show the calculated statistics\nprint(\"Statistics for Boston housing dataset:\\n\")\nprint(\"Minimum price: ${}\".format(minimum_price)) \nprint(\"Maximum price: ${}\".format(maximum_price))\nprint(\"Mean price: ${}\".format(mean_price))\nprint(\"Median price ${}\".format(median_price))\nprint(\"Standard deviation of prices: ${}\".format(std_price))","214abfea":"fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor a,b in data.items():\n    sns.boxplot(y=a, data=data, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","e6960078":"#find outliers\nfor a, b in data.items():\n        q1 = b.quantile(0.25)\n        q3 = b.quantile(0.75)\n        irq = q3 - q1\n        b_col = b[(b <= q1 - 1.5 * irq) | (b >= q3 + 1.5 * irq)]\n        perc = np.shape(b_col)[0] * 100.0 \/ np.shape(data)[0]\n        print(\"Column %s outliers = %.2f%%\" % (a, perc))","f56771e6":"sns.pairplot(data, size=2.5)\nplt.tight_layout()","138c83d4":"for i in data.columns:\n    sns.boxplot(data[i])\n    plt.title(i)\n    plt.show()","73b7946d":"for i in data.columns:\n    value_z=(data[i]-data[i].mean())\/(data[i].std())\n    sns.distplot(value_z)\n    plt.show()","be0eb407":"var_ind = np.arange(0, 14)\nplot = plt.figure(figsize = (20, 10))\nplot.subplots_adjust(hspace = 0.5, wspace = 0.5)\nfor i in range(1, 15):\n    a = plot.add_subplot(4, 4, i)\n    a.hist(data.iloc[:, var_ind[i - 1]], alpha = 0.7, bins = 30)\n    a.title.set_text(data.columns[i - 1])","a7fadf70":"fig, axs = plt.subplots(ncols=7, nrows=2, figsize=(20, 10))\nindex = 0\naxs = axs.flatten()\nfor a,b in data.items():\n    sns.distplot(b, ax=axs[index])\n    index += 1\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)","8030a4ca":"sns.pairplot(data)\nplt.show()","40b030e7":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.distplot(data['MEDV'], bins=30)\nplt.show()","0038a1ab":"plt.figure(figsize=(20, 10))\nsns.heatmap(data.corr().abs(),  annot=True)","7de4a937":"corr = data.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 10))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='RdBu', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","84cf57c8":"plt.figure(figsize=(20, 5))\n\nfeatures = ['LSTAT', 'RM']\ntarget = data['MEDV']\n\nfor i, col in enumerate(features):\n    plt.subplot(1, len(features) , i+1)\n    x = data[col]\n    y = target\n    plt.scatter(x, y, marker='o')\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('MEDV')","bd73701c":"data.corr()","9b202244":"This is supervised learning regression problem","2ebdbd12":"visualisation","6b780391":"CRIM:\nThis is the per capita crime rate by town\n\nZN: \nThis is the proportion of residential land zoned for lots larger than 25,000 sq.ft.\n\nINDUS:\nThis is the proportion of non-retail business acres per town.\n\nCHAS: \nThis is the Charles River dummy variable (this is equal to 1 if tract bounds river; 0 otherwise)\n\nNOX: \nThis is the nitric oxides concentration (parts per 10 million)\n\nRM:\nThis is the average number of rooms per dwelling\n\nAGE: \nThis is the proportion of owner-occupied units built prior to 1940\n\nDIS:\nThis is the weighted distances to five Boston employment centers\n\nRAD: \nThis is the index of accessibility to radial highways\n\nTAX:\nThis is the full-value property-tax rate per $10,000\n\nPTRATIO: \nThis is the pupil-teacher ratio by town\n\nB: \nThis is calculated as 1000(Bk \u2014 0.63)\u00b2, where Bk is the proportion of people of African American descent by town\n\nLSTAT: \nThis is the percentage lower status of the population\n\nMEDV: This is the median value of owner-occupied homes in $1000s"}}