{"cell_type":{"12ef9b56":"code","9a855a2e":"code","5a5f97ce":"code","e5c2cd71":"code","26263266":"code","0d6bcb7d":"code","4b1365e6":"code","f5d9a923":"code","72c65f4e":"code","56e44bbd":"code","acc51e9d":"code","1a5e9a10":"code","e8190fb0":"code","086db008":"code","951a7a73":"code","5a4e3cd2":"code","1943e483":"code","f50ac187":"code","b7dc10a6":"code","c723b610":"code","60259232":"code","c7447d35":"code","e2779159":"code","8d0f86e9":"code","3c825f5f":"code","660dda26":"code","45a59687":"code","9b95c3d6":"code","451d86ff":"code","96643346":"code","510e26ad":"code","3abaf1a4":"code","d4e85c56":"code","64126f65":"code","89171635":"code","31492371":"code","3267d06e":"code","0bd2b852":"code","c17d58d7":"code","c73103e7":"markdown","13c73f28":"markdown","5cbf4d46":"markdown","a6df47df":"markdown","e5ba7dd0":"markdown","ad6f097e":"markdown","dab251a1":"markdown","f617b465":"markdown","fc08d92f":"markdown","43fd9534":"markdown","450717b5":"markdown","1c9e26c6":"markdown","29ff0068":"markdown","353a1ea5":"markdown","f4e9a764":"markdown","64fae5c4":"markdown","0d1f664c":"markdown"},"source":{"12ef9b56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a855a2e":"# Essentials\nimport numpy as np\nimport pandas as pd\nimport datetime\nimport random\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","5a5f97ce":"import os\nimport gc\nimport copy\nimport random\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold ,RepeatedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\n\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 18})\nplt.style.use('ggplot')\nimport seaborn as sns\nfrom scipy import stats\n\nimport shap\n\nfrom sklearn.preprocessing import StandardScaler\n\nimport optuna.integration.lightgbm as lgbm\nimport optuna\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","e5c2cd71":"df_train = pd.read_csv('..\/input\/widsdatathon2022\/train.csv')\ndf_test = pd.read_csv('..\/input\/widsdatathon2022\/test.csv')","26263266":"submission = pd.read_csv('..\/input\/widsdatathon2022\/sample_solution.csv')\n","0d6bcb7d":"print(f'\\033[92mNumber of rows in train data: {df_train.shape[0]}')\nprint(f'\\033[94mNumber of columns in train data: {df_train.shape[1]}')\nprint(f'\\033[91mNumber of values in train data: {df_train.count().sum()}')\nprint(f'\\033[91mNumber missing values in train data: {sum(df_train.isna().sum())}')","4b1365e6":"df_train.head()","f5d9a923":"df_train.columns","72c65f4e":"df_train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","56e44bbd":"df_train.columns","acc51e9d":"cols_with_missing = [col for col in df_train.columns \n                                 if df_train[col].isnull().any()]\nmiss_count =df_train.isna().sum()\nmiss_df = (pd.concat([miss_count.rename('Missing count'),miss_count.div(len(df_train)).rename('Missing value')],axis = 1).loc[miss_count.ne(0)])\nmiss_df.style.background_gradient(cmap=\"YlGn\")","1a5e9a10":"categorical_features = [c for c in df_train.columns if (1<df_train[c].nunique()) \n                  & (df_train[c].dtype != np.number)\n                  & (df_train[c].dtype != int)]\ncategorical_features","e8190fb0":"for col in categorical_features:\n    df_train[col]=df_train[col].astype('category')\ndata_binary_col = df_train.select_dtypes('category').columns\ndata_binary_col ","086db008":"num_col=df_train.select_dtypes('number').columns\nnum_col","951a7a73":"target_variable = \"site_eui\"","5a4e3cd2":"sns.distplot(df_train['site_eui'], color = \"#8FBC8B\")","1943e483":"def kdeplot_features(df_train,df_test, feature, title):\n    '''Takes a column from the dataframe and plots the distribution (after count).'''\n    \n    values_train = df_train[feature].to_numpy()\n    values_test = df_test[feature].to_numpy()  \n     \n    plt.figure(figsize = (18, 3))\n    \n    sns.kdeplot(values_train, color = '#006400')\n    sns.kdeplot(values_test, color = '#9ACD32')\n    \n    plt.title(title, fontsize=15)\n    plt.legend()\n    plt.show();\n    \n    del values_train , values_test\n    gc.collect()\n    \ndef countplot_features(df_train, feature, title):\n    '''Takes a column from the dataframe and plots the distribution (after count).'''\n    \n           \n    plt.figure(figsize = (10, 5))\n    \n    sns.countplot(df_train[feature], color = '#006400')\n        \n    plt.title(title, fontsize=15)    \n    plt.show();\n    \n        \ndef create_wandb_hist(x_data=None, x_name=None, title=None, log=None):\n    '''Create and save histogram in W&B Environment.\n    x_data: Pandas Series containing x values\n    x_name: strings containing axis name\n    title: title of the graph\n    log: string containing name of log'''\n    \n    data = [[x] for x in x_data]\n    table = wandb.Table(data=data, columns=[x_name])\n    wandb.log({log : wandb.plot.histogram(table, x_name, title=title)})","f50ac187":"numerical_features=df_train.select_dtypes('number').columns","b7dc10a6":"numerical_features","c723b610":"# plot distributions of features\nfor feature in numerical_features:\n    if feature != \"site_eui\":\n        kdeplot_features(df_train,df_test, feature=feature, title = feature + \" distribution\")","60259232":"# plot distributions of categorical features\nfor feature in categorical_features:\n    fig = countplot_features(df_train, feature=feature, title = \"Frequency of \"+ feature)","c7447d35":"plt.figure(figsize=(15, 5))\nmin_temp=['january_min_temp', 'february_min_temp','march_min_temp','april_min_temp','may_min_temp','june_min_temp','july_min_temp','august_min_temp','september_min_temp', 'october_min_temp','november_min_temp', 'december_min_temp']\nfor col in min_temp:\n   \n   sns.kdeplot(\n   data=df_train[col],\n   fill=True, common_norm=False, palette=\"mako\",\n   alpha=.5, linewidth=0,\n)\nplt.title(\"Monthly distribution of min temp\")\n\nplt.figure(figsize=(15, 5))\nmax_temp=['january_max_temp', 'february_max_temp','march_max_temp','april_max_temp','may_max_temp','june_max_temp','july_max_temp','august_max_temp','september_max_temp', 'october_max_temp','november_max_temp', 'december_max_temp']\nfor col in max_temp:\n   \n  sns.kdeplot(\n   data=df_train[col], \n   fill=True, common_norm=False, palette=\"mako\",\n   alpha=.5, linewidth=0,\n)\nplt.title(\"Monthly distribution of max temp\")\n\nplt.figure(figsize=(15, 5))\navg_temp=['january_avg_temp', 'february_avg_temp','march_avg_temp','april_avg_temp','may_avg_temp','june_avg_temp','july_avg_temp','august_avg_temp','september_avg_temp', 'october_avg_temp','november_avg_temp', 'december_avg_temp']\nfor col in avg_temp:\n    \n    sns.kdeplot(\n   data=df_train[col], \n   fill=True, common_norm=False, palette=\"mako\",\n   alpha=.5, linewidth=0,\n)\nplt.title(\"Monthly distribution of avg temp\")","e2779159":"# year_built: replace with current year.\ndf_train['year_built'] = df_train['year_built'].replace(np.nan, 2022)\n#replacing rest of the values with mean\n#data['energy_star_rating']=data['energy_star_rating'].replace(np.nan,data['energy_star_rating'].mean())\n#data['direction_max_wind_speed']= data['direction_max_wind_speed'].replace(np.nan,data['direction_max_wind_speed'].mean())\n#data['direction_peak_wind_speed']= data['direction_peak_wind_speed'].replace(np.nan,data['direction_peak_wind_speed'].mean())\n#data['max_wind_speed']=data['max_wind_speed'].replace(np.nan,data['max_wind_speed'].mean())\n#data['days_with_fog']=data['days_with_fog'].replace(np.nan,data['days_with_fog'].mean())\n\n##for testdata\n\n# year_built: replace with current year.\ndf_test['year_built'] = df_test['year_built'].replace(np.nan, 2022)","8d0f86e9":"from sklearn.impute import SimpleImputer\nnull_col=['energy_star_rating','direction_max_wind_speed','direction_peak_wind_speed','max_wind_speed','days_with_fog']\nimputer = SimpleImputer()\nimputer.fit(df_train[null_col])\ndata_transformed = imputer.transform(df_train[null_col])\ndf_train[null_col] = pd.DataFrame(data_transformed)\ntest_data_transformed = imputer.transform(df_test[null_col])\ndf_test[null_col] = pd.DataFrame(test_data_transformed)","3c825f5f":"#rechecking null values\ncols_with_missing = [col for col in df_train.columns \n                                 if df_train[col].isnull().any()]\ncols_with_missing","660dda26":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor col in categorical_features:\n    df_train[col] = le.fit_transform(df_train[col])\n    df_test[col] = le.fit_transform(df_test[col])","45a59687":"df_train.head()","9b95c3d6":"#data_binary_col1 = data[data_binary_col]\ndummy_col = pd.get_dummies(df_train[data_binary_col], drop_first=True)\ndf_train = pd.concat([df_train,dummy_col], axis=1)\ndf_train = df_train.drop(columns=data_binary_col )","451d86ff":"dummy_test = pd.get_dummies(df_test[data_binary_col], drop_first=True)\ndf_test = pd.concat([df_test,dummy_test], axis=1)\ndf_test = df_test.drop(columns=data_binary_col )","96643346":"y = df_train['site_eui']\nX = df_train.drop(['site_eui'], axis = 1)","510e26ad":"X.head()","3abaf1a4":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain = scaler.fit_transform(X)\ntest = scaler.transform(df_test)","d4e85c56":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)","64126f65":"import xgboost\n\nxgboost_model = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.03, gamma=0, subsample=0.75,\n                           colsample_bytree=0.4, max_depth=3)\nxgboost_model.fit(X_train,y_train)","89171635":"from sklearn.metrics import explained_variance_score\npredictions = xgboost_model.predict(X_test)\nprint(explained_variance_score(predictions,y_test))","31492371":"from sklearn.model_selection import GridSearchCV\nxgb = xgboost.XGBRegressor()\nparameters = {'objective':['reg:linear'],\n              'learning_rate': [.02, .05, 0.01], #so called `eta` value\n              'max_depth': [3,5],\n              'min_child_weight': [4],\n              'subsample': [0.7],\n              'colsample_bytree': [0.4],\n              'n_estimators': [1000],\n              'reg_alpha': [0.4],\n              'reg_lambda': [2e-08]\n}\nxgb_grid = GridSearchCV(xgb,\n                        parameters,\n                        cv = 5,\n                        verbose=True)\n\nxgb_grid.fit(X_train,y_train)\n\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)","3267d06e":"#testdata prediction\nprediction = xgb_grid.best_estimator_.predict(df_test)\nprediction","0bd2b852":"submission= pd.read_csv('\/kaggle\/input\/widsdatathon2022\/sample_solution.csv')\nsubmission['site_eui'] = prediction\nsubmission.to_csv(\"submission.csv\",index=False)","c17d58d7":"submission.head()","c73103e7":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nWiDS Datathon 2022 \n     <\/p>","13c73f28":"Model achieved the 97 % accuary and model seems to be overfitted. Next step is using the gridsearch to find the optimal parameters","5cbf4d46":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nOverview of Data\n     <\/p>","a6df47df":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nEvalution Metric\n     <\/p>","e5ba7dd0":"<b>Problem Statement:<\/b> <p> Climate change is a globally relevant, urgent, and multi-faceted issue heavily impacted by energy policy and infrastructure. Addressing climate change involves mitigation (i.e. mitigating greenhouse gas emissions) and adaptation (i.e. preparing for unavoidable consequences). Mitigation of GHG emissions requires changes to electricity systems, transportation, buildings, industry, and land use. <\/p>\n\n<p>According to a report issued by the International Energy Agency (IEA), the lifecycle of buildings from construction to demolition were responsible for 37% of global energy-related and process-related CO2 emissions in 2020. Yet it is possible to drastically reduce the energy consumption of buildings by a combination of easy-to-implement fixes and state-of-the-art strategies. For example, retrofitted buildings can reduce heating and cooling energy requirements by 50-90 percent. Many of these energy efficiency measures also result in overall cost savings and yield other benefits, such as cleaner air for occupants. This potential can be achieved while maintaining the services that buildings provide.<\/p>\n\n<b>Goal: <\/b><p>\n**<span style=\"color:#008000;\">The goal of this competition is to predict the energy consumption using building characteristics and climate and weather variables.<\/span>**<\/p>","ad6f097e":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nModel\n     <\/p>","dab251a1":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nThank You \n     <\/p>","f617b465":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nExploratory Data Analysis\n     <\/p>","fc08d92f":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nLoading Data\n     <\/p>","43fd9534":"<p style=\"padding: 10px;\n          color:#000000;\n          font-weight: bold;\n          text-align: center;\n          background-color:#FFFFFF;\n          font-size:150%;\">\nChecking Null values\n     <\/p>","450717b5":"The evaluation metric for this competition is Root Mean Squared Error (RMSE). The RMSE is commonly used measure of the differences between predicted values provided by a model and the actual observed values.","1c9e26c6":"<p style=\"padding: 10px;\n          color:#FFFFFF;\n          font-weight: bold;\n          text-align: center;\n          background-color:#006400;\n          font-size:260%;\">\nImporting Libraries\n     <\/p>","29ff0068":"**<span style=\"color:#008000;\">site_eui: Site Energy Usage Intensity is the amount of heat and electricity consumed by a building as reflected in utility bills<\/span>**<\/p>","353a1ea5":"Graph is positively skewed (right-skewed Distribution).","f4e9a764":"![Screenshot 2022-01-20 135703.png](attachment:7aa1cd07-39ec-4a28-a988-a749f7b7875d.png)","64fae5c4":"<p style=\"padding: 10px;\n          color:#000000;\n          font-weight: bold;\n          text-align: center;\n          background-color:#FFFFFF;\n          font-size:150%;\">\nTarget Variable\n     <\/p>","0d1f664c":"References:\n\nhttps:\/\/www.kaggle.com\/shrutisaxena\/wids2022-starter-code\n\nhttps:\/\/www.kaggle.com\/usharengaraju\/wids2022-lgbm-starter-w-b#notebook-container"}}