{"cell_type":{"1c4e78f6":"code","5a8bb7be":"code","e17652bd":"code","80e51451":"code","033256bf":"code","f5a67156":"code","2b9e1b16":"code","dd5ad418":"markdown","21077482":"markdown","5fb06fb0":"markdown","31d5cb94":"markdown","35a3e9a9":"markdown"},"source":{"1c4e78f6":"!pip install mtcnn","5a8bb7be":"import cv2\nimport mtcnn\nfrom mtcnn.mtcnn import MTCNN\nimport matplotlib.pyplot as plt\n\nimage_path = \"..\/input\/lfw-dataset\/lfw-deepfunneled\/lfw-deepfunneled\/Chip_Knight\/Chip_Knight_0001.jpg\"\nprint(mtcnn.__version__)","e17652bd":"def detect_face(image):\n    detector = MTCNN()\n    bounding_boxes = detector.detect_faces(image)\n    return bounding_boxes","80e51451":"def draw_bounding_boxes(image, bboxes):\n    for box in bboxes:\n        x1, y1, w, h = box['box']\n        cv2.rectangle(image, (x1, y1), (x1+w,y1+h), (0,255,0), 2)","033256bf":"def mark_key_point(image, keypoint):\n    cv2.circle(image, (keypoint), 1, (0,255,0), 2)","f5a67156":"image = cv2.imread(image_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nbboxes = detect_face(image)\nprint(\"Output of MTCNN detector is...\\n\",bboxes)","2b9e1b16":"# draw bounding box around the detected face and mark facial keypoints\ndraw_bounding_boxes(image, bboxes)\nmark_key_point(image, bboxes[0]['keypoints']['left_eye'])\nmark_key_point(image, bboxes[0]['keypoints']['right_eye'])\nmark_key_point(image, bboxes[0]['keypoints']['nose'])\nmark_key_point(image, bboxes[0]['keypoints']['mouth_left'])\nmark_key_point(image, bboxes[0]['keypoints']['mouth_right'])\n\n# display the image\nplt.figure(figsize=(10,10))\nplt.imshow(image)\nplt.xticks([])\nplt.yticks([])\nplt.show()","dd5ad418":"## 1. Some basic steps","21077482":"## 5. Test with an image to detect a face","5fb06fb0":"## 2. Define method to detect face in an image using MTCNN","31d5cb94":"## 4. Define method to mark keypoints on face","35a3e9a9":"## 3. Define method to draw bounding box around the face in an image"}}