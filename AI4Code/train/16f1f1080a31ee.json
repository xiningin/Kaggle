{"cell_type":{"c73f452e":"code","3db29ed9":"code","0e880433":"code","3035207b":"code","1d0a35a4":"code","0648b981":"code","d7a43bca":"code","dd1ae93b":"code","26ad4856":"code","96cb8a1e":"code","932e6f6e":"markdown","3769f254":"markdown","76d52b09":"markdown","57a00dac":"markdown","43266f60":"markdown","130e49e7":"markdown","3f47a313":"markdown","ab8c7373":"markdown","7998421b":"markdown","847f8b04":"markdown","93cf51a0":"markdown","c6e1b8e0":"markdown","16039cbf":"markdown","482b5c45":"markdown","050d293a":"markdown","ddcacc6a":"markdown","acbc0f0e":"markdown","6c0b2240":"markdown","7b53f7a5":"markdown","2a060658":"markdown","7503dd5b":"markdown","51a27472":"markdown","3dc8844f":"markdown","e90dc60c":"markdown","9d484e23":"markdown","c1e0a2ec":"markdown","d103ea03":"markdown","c64edc07":"markdown","4fa5a771":"markdown","067daa9f":"markdown","390090cd":"markdown","e5e24e6f":"markdown","499da901":"markdown","f8eca3c2":"markdown","09f69e35":"markdown","36c7817f":"markdown"},"source":{"c73f452e":"import glob\nimport os\n\nimport numpy as np\nimport pandas as pd\n\nfrom IPython.display import Image\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n","3db29ed9":"df_sub = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\n\ndf_sub.head()","0e880433":"id_ = '0007de18844b0dbbb5e1f607da0606e0'\nfilename = '..\/input\/petfinder-pawpularity-score\/train\/' + id_ + '.jpg'\n\nImage(filename) ","3035207b":"no_of_images = len(os.listdir('..\/input\/petfinder-pawpularity-score\/train'))\n\nprint(no_of_images)","1d0a35a4":"def plot_images(file,threshold = 20):\n    count = 1\n    images = []\n    \n    for img_path in glob.glob(file):\n        images.append(mpimg.imread(img_path))\n        if count == threshold:\n            break\n        count+=1\n        \n    plt.figure(figsize=(20,10))\n    columns = 5\n    for i, image in enumerate(images):\n        plt.subplot(len(images) \/ columns + 1, columns, i + 1)\n        plt.imshow(image)\n    ","0648b981":"file = '..\/input\/petfinder-pawpularity-score\/train\/*.jpg'\nplot_images(file)","d7a43bca":"simple_train_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv',usecols=['Id','Pawpularity'])\nsimple_train_df.head()","dd1ae93b":"complete_train_df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ncomplete_train_df.head()","26ad4856":"plt.figure(figsize = (25, 25))\nsns.heatmap(complete_train_df.corr(), annot = True)","96cb8a1e":"#end","932e6f6e":"<center style=\"font-family:verdana;\"><h1 style=\"background: #ADD8E6 ;\">_<\/h1><\/center>","3769f254":"#### In this section, we will only be discussing the data that is sufficient to start making the predictions. \n\n#### Well the problem is cleared that we need to predict some numbers from an image, and we also have the data needed for such models.\n\n#### Let's see the data \n","76d52b09":"<center style=\"font-family:verdana;\"><h1 style=\"background: #ADD8E6 ;\">_<\/h1><\/center>","57a00dac":"#### Let's see the csv files ","43266f60":"### 1. Using simple CNN \n\n\n#### \u25d8 develop a simple Convolutional neural network model that takes the image as an input and gives the score as an output \n#### \u25d8 Simple and we can experiment with this model easily \n","130e49e7":"### let's import the necessary modules ","3f47a313":"#### As we can see that the first column is the id of the image and its corresponding pawpularity-score.\n\n#### The id of the image is simply the name of the image in the dataset and used as a unique identifier of an image ","ab8c7373":"#### We have seen the problem and it looks like there are several approaches\/techniques that can be adapted for this problem.\n","7998421b":"#### There are 9912 images in this folder, let\u2019s see a few.","847f8b04":"<center><h1>Discussion on the possible approaches <\/h1><\/center>","93cf51a0":"#### well there are several columns, the following is the discription  \n\n#### Each pet photo is labeled with the value of 1 (Yes) or 0 (No) for each of the following features:\n\n* Focus - Pet stands out against uncluttered background, not too close \/ far.\n* Eyes - Both eyes are facing front or near-front, with at least 1 eye \/ pupil decently clear.\n* Face - Decently clear face, facing front or near-front.\n* Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n* Action - Pet in the middle of an action (e.g., jumping).\n* Accessory - Accompanying physical or digital accessory \/ prop (i.e. toy, digital sticker), excluding collar and leash.\n* Group - More than 1 pet in the photo.\n* Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n* Human - Human in the photo.\n* Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n* Info - Custom-added text or labels (i.e. pet name, description).\n* Blur - Noticeably out of focus or noisy, especially for the pet\u2019s eyes and face. For Blur entries, \u201cEyes\u201d column is always set to 0.","c6e1b8e0":"## Simple problem statement ","16039cbf":"### now Let's see the correlation in the metadata","482b5c45":"### 2. Using the pre-trained image model   \n\n#### \u25d8 We can use the pre-trained model (eg. resnet ) to extract the information in the image ( i.e image to vec )\n\n#### \u25d8 And a simple Feedforward network on top of that for predicting the score \n","050d293a":"<center style=\"font-family:verdana;\"><h1 style=\"background: #ADD8E6 ;\">_<\/h1><\/center>","ddcacc6a":"#### Many more .. ","acbc0f0e":"### train\/test folder \n\n#### In this folder, we will find all the images that are available to us for the training of the model.\n","6c0b2240":"### Let's have a look at the first image from the train folder ","7b53f7a5":"### Let's have a look at summition.csv to know more ","2a060658":"<center style=\"font-family:verdana;\"><h1 style=\"background: #ADD8E6 ;\">_<\/h1><\/center>","7503dd5b":"#### in this notebook we have discussed many important points and I hope that this analysis helps \n\n### Thank you for the readings, happy to hear your thoughts\/suggestions.","51a27472":"### 4. Adding Metadata\n\n#### \u25d8 We can simply use this data by converting the information in the vector and appending the final vector to the image vector and using this for the prediction.\n\n#### Well there are several ways of using this meta data\n","3dc8844f":"# staters \n\n#### Hello readers in this notebook we will look over the problem statement and understand the data given in this competition\n\n#### Following are the points covered in this notebook \n\n* A dive in problem statement \n* Understanding given data : part 1 \n* Understanding given data : part 2 (metadata)\n* Discussion on the possible approaches  \n\n#### Now we can start the notebook, hope it helps \n\n\n","e90dc60c":"#### To put the problem in simple words, we can say the following: \n\n#### Given an image predict the score of that image\n\n#### In other words, we need to train a model that takes the image( photo of street animal ) and predict the number ( pawpularity-score ), and to do that we are given with the dataset ( image and its corresponding score) as well as metadata about the image, which can be used in the model.\n","9d484e23":"#### He sure does looks cute to me :)\n\n#### As of now we have cleared the basic understanding of the problem statement and we will get to know more about the given problem once we go through the data provided in the next section.  \n","c1e0a2ec":"#### In this section, we will discuss the metadata provided to us \n\n\n#### While it's clear that we have all we need to create the model and start experimenting, but there are some we should consider before we begin \n\n#### Metadata is the extra information about the image, that is labeled by the humans. ( We know that machine learning models try to mimic the human behavior and given information(metadata) is interpreted by the humans, all the more reason to find good use of metadata )\n\n#### As we discussed before, there are several factors affecting the Pawpularity, and we can find such factors in the metadata\n\n#### let's start exploring the metadata\n","d103ea03":"#### from the above simple description we can say that we have all the data we need to train a model for predicting the Pawpularity score of a pet's image ","c64edc07":"#### looks like Metadata has no direct significant impact on Pawpularity-score, And that's the reason we need to do research to find out more about the data provided and get the best from it. ","4fa5a771":"#### similarly we have some images in the test folder, that are used as a test set.\n","067daa9f":"#### We know that PetFinder.my is an organization that helps the street animals to find a loving home using their Butifuell photos, well it just happens to be human nature that we tend to pick the most beautiful\/cute one out of all the photos. \n\n#### Every living organism is beautiful, we just need to show the users its beauty. Petfinder.my uses images of street animals, But some images are more attractive than others. This attractiveness is measured through the profile's page view statistics at the listing pages, Duplicate click, and many more.\n\n#### pawpularity-score for a pet\u2019s photo is calculated through the above means. In this competition, Our task is to train a machine learning model that can predict the pawpularity-score of the pet's photo.\n\n#### One may argue that there are several factors affecting the pawpularity-score and to support that( in some sense ) we are also provided with the metadata that can be used to make the predictions better.\n","390090cd":"#### So far we have explored all the data there is and hope that must have given you some good understanding of the problem statement, in the next section we will discuss the possible approaches.","e5e24e6f":"### 3. Using Transformers \n\n\n#### \u25d8 Transformers are changing the world of NLP and the transformers can also be used for visual tasks, have a look here: https:\/\/towardsdatascience.com\/transformers-in-computer-vision-farewell-convolutions-f083da6ef8ab\n","499da901":"<center><h1>Understanding given data : part 2 ( Metadata )<\/h1><\/center>","f8eca3c2":"#### As we discussed before, simply put train.csv contains the associative mapping from image to its respective Pawpularity score \n\n#### well there is more to this CSV file that we will discuss in the next section ","09f69e35":"<center><h1>A dive in the problem statement <\/h1><\/center>","36c7817f":"<center><h1>Understanding given data : part 1<\/h1><\/center>"}}