{"cell_type":{"e977cc91":"code","cdac0c06":"code","8b4f3bc8":"code","703f08d2":"code","dfa5db15":"code","f8f06ef2":"code","8d62df52":"code","1d7865d3":"code","4b27460f":"code","140709a8":"code","8803dae8":"code","f958108d":"code","b43a7c28":"code","c77e774a":"code","a50c6cbf":"code","7965d9a4":"code","ee75fc06":"code","4c68147d":"code","c1fad31f":"code","12279ff6":"code","a2560beb":"code","7662fc74":"code","e3a93423":"markdown","04527451":"markdown","340471db":"markdown","07e236c3":"markdown","63b34c20":"markdown","4372fc33":"markdown","0f041f56":"markdown","b51d4459":"markdown"},"source":{"e977cc91":"# Imports\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Flatten, Dropout, Dense, UpSampling2D, Reshape\nfrom keras.layers import Conv2DTranspose, Activation, BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import RMSprop\nfrom keras.datasets import cifar10","cdac0c06":"%matplotlib inline\nimport matplotlib.pylab as plt\n\nfrom tqdm import tnrange\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder","8b4f3bc8":"# Informa\u00e7\u00f5es dos dados de entrada\nimg_rows = 32\nimg_cols = 32\nchannel = 3\nclasses = 10","703f08d2":"# Hiperpar\u00e2metros\ndepth = 64\ndropout = 0.4","dfa5db15":"discriminator = Sequential()\n\ninput_shape = (img_rows, img_cols, channel)\n\ndiscriminator.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape, padding='same'))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(dropout))\n\ndiscriminator.add(Conv2D(depth*2, 5, strides=2, padding='same'))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(dropout))\n\ndiscriminator.add(Conv2D(depth*4, 5, strides=2, padding='same'))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(dropout))\n\ndiscriminator.add(Conv2D(depth*8, 5, strides=1, padding='same'))\ndiscriminator.add(LeakyReLU(alpha=0.2))\ndiscriminator.add(Dropout(dropout))\n\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(classes + 1))\ndiscriminator.add(Activation('softmax'))\n\ndiscriminator.summary()","f8f06ef2":"# Otimizador\noptimizer = RMSprop(lr=0.0001, decay=6e-8)\n\n# Cria\u00e7\u00e3o do Modelo\ndiscriminator_model = Sequential()\ndiscriminator_model.add(discriminator)\n\n# Compila\u00e7\u00e3o\ndiscriminator_model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])","8d62df52":"# Hiperpar\u00e2metros\ndropout = 0.4\ndepth = 64+64+64+64\ndim = 8","1d7865d3":"generator = Sequential()\n\ngenerator.add(Dense(dim*dim*depth, input_dim=100 + classes))\ngenerator.add(BatchNormalization(momentum=0.9))\ngenerator.add(Activation('relu'))\ngenerator.add(Reshape((dim, dim, depth)))\ngenerator.add(Dropout(dropout))\n\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2DTranspose(int(depth\/2), 5, padding='same'))\ngenerator.add(BatchNormalization(momentum=0.9))\ngenerator.add(Activation('relu'))\n\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2DTranspose(int(depth\/4), 5, padding='same'))\ngenerator.add(BatchNormalization(momentum=0.9))\ngenerator.add(Activation('relu'))\n\ngenerator.add(Conv2DTranspose(3, 5, padding='same'))\ngenerator.add(Activation('sigmoid'))\n\ngenerator.summary()","4b27460f":"# Otimizador\noptimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n\n# Cria\u00e7\u00e3o do Modelo\nadversarial_model = Sequential()\nadversarial_model.add(generator)\ndiscriminator.trainable = False\nadversarial_model.add(discriminator)\n\n# Compila\u00e7\u00e3o do Modelo\nadversarial_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nadversarial_model.summary()","140709a8":"# Carregando os dados\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train = np.concatenate((x_train, x_test))\ny_train = np.concatenate((y_train, y_test))","8803dae8":"# Normaliza\u00e7\u00e3o\ndef normalize(images):\n    images=images.astype('float32')\n    if images.max() > 1.0:\n        images\/=255.0\n    return images","f958108d":"# One-Hot Encoding\ndef one_hot(labels):\n    enc = OneHotEncoder()\n    return enc.fit_transform(y_train).toarray()","b43a7c28":"x_train = normalize(x_train)\ny_train = one_hot(y_train)","c77e774a":"# Gerando noise rand\u00f4mico para os dados de entrada\ndef create_generator_noise(batch_size):\n    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n    sampling = np.random.randint(classes, size=batch_size)\n    noise_labels = np.zeros((batch_size, classes))\n    noise_labels[np.arange(batch_size), sampling] = 1\n    noise_input = np.concatenate((noise, noise_labels), axis=1)\n    \n    return noise_input, noise_labels","a50c6cbf":"# Gerando noise rand\u00f4mico para os labels\ndef create_generator_noise_by_label(labels):\n    noise = np.random.uniform(-1.0, 1.0, size=[len(labels), 100])\n\n    noise_labels = np.zeros((len(labels), classes))\n    noise_labels[np.arange(len(labels)), labels] = 1\n    noise_input = np.concatenate((noise, noise_labels), axis=1)\n    \n    return noise_input","7965d9a4":"def train(batch_size=256, train_steps=2000):\n    discriminator_losses = []\n    adversarial_losses = []\n    sample_images = []\n    \n    for i in tnrange(train_steps):\n        # Seleciona uma amostra aleat\u00f3ria dos dados de treinamento e os r\u00f3tulos\n        sample_idx = np.random.randint(0, x_train.shape[0], size=batch_size)\n        images_train = x_train[sample_idx, :, :, :]\n        labels_train = y_train[sample_idx]\n        labels_train = np.concatenate((labels_train, np.zeros(shape=(batch_size, 1))), axis=1)\n        \n        # Cria ru\u00eddo no intervalo -1 a 1 e r\u00f3tulos aleat\u00f3rios como entrada para o gerador para gerar as imagens falsas\n        noise_input, _ = create_generator_noise(batch_size)\n        images_fake = generator.predict(noise_input)\n        \n        # Cria entrada por concatenar imagens reais e falsas e atribuindo os respectivos r\u00f3tulos\n        labels_fake = np.zeros(shape=(batch_size, classes+1))\n        labels_fake[:,-1] = 1\n        \n        input_data   = np.concatenate((images_train, images_fake))\n        input_labels = np.concatenate((labels_train, labels_fake))\n\n        discriminator_loss = discriminator_model.train_on_batch(input_data, input_labels)\n        \n        # Treina o modelo adversarial para gerar melhores imagens\n        noise_input, noise_labels = create_generator_noise(batch_size)\n        noise_labels = np.concatenate((noise_labels, np.zeros(shape=(batch_size, 1))), axis=1)\n        \n        adversarial_loss = adversarial_model.train_on_batch(noise_input, noise_labels)\n        \n        discriminator_losses.append(discriminator_loss)\n        adversarial_losses.append(adversarial_loss)\n        \n        if i % 100 == 0:\n            labels = [1]\n            noise = create_generator_noise_by_label(labels)\n            fake_images = generator.predict(noise)\n            sample_images.append(fake_images[0])\n    \n    return discriminator_losses, adversarial_losses, sample_images","ee75fc06":"# Treinamento\ndiscriminator_losses, adversarial_losses, sample_images  = train(train_steps=20000)","4c68147d":"# Print do resultado\nplt.figure(figsize=(20,40))\nfor i, fake_image in enumerate(sample_images, 0):\n    plt.subplot(20, 10, i+1)\n    plt.imshow(np.reshape(fake_image, (img_cols, img_rows, channel)), cmap='gray')\n    plt.title(\"Itera\u00e7\u00e3o %d\" % (i * 100))\n    plt.axis('off')","c1fad31f":"# Print do treinamento\nplt.figure(figsize=(20,10))\n\nplt.subplot(2,2,1)\nplt.plot(np.array(discriminator_losses)[:, 0])\nplt.title(\"Discriminator Losses\")\n\nplt.subplot(2,2,2)\nplt.plot(np.array(discriminator_losses)[:, 1])\nplt.title(\"Acur\u00e1cia do Discriminator\")\n\nplt.subplot(2,2,3)\nplt.plot(np.array(adversarial_losses)[:, 0], color='darkorange')\nplt.title(\"Generator Losses\")\n\nplt.subplot(2,2,4)\nplt.plot(np.array(adversarial_losses)[:, 1], color='darkorange')\nplt.title(\"Acur\u00e1cia do Generator\")","12279ff6":"label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]","a2560beb":"def sample_labels(size):\n    labels = []\n    for label, _ in enumerate(label_names):\n        for sample_size in range(size):\n            labels.append(label)\n    return labels","7662fc74":"fig, big_axes = plt.subplots(figsize=(20, 20) , nrows=len(label_names), ncols=1, sharey=True) \n\nfor row, big_ax in enumerate(big_axes, start=1):\n    big_ax.set_title(label_names[row-1], fontsize=16)\n    big_ax.tick_params(labelcolor=(1.,1.,1., 0.0), top='off', bottom='off', left='off', right='off')\n    big_ax._frameon = False\n\nlabels = sample_labels(15)\nnoise = create_generator_noise_by_label(labels)\n\nfake_images = generator.predict(noise)\n\nplt.figure(figsize=(20,20))\nfor i, fake_image in enumerate(fake_images, 1):\n    ax = fig.add_subplot(len(label_names), 15, i)\n    ax.imshow(np.reshape(fake_image, (img_cols, img_rows, channel)), cmap='gray')\n    ax.axis('off')","e3a93423":"Leaky ReLUs s\u00e3o uma tentativa de consertar o problema do \u201cdying ReLU\u201d. Ao inv\u00e9s da fun\u00e7\u00e3o ser zero quando x < 0, a leaky ReLU ter\u00e1 uma pequena inclina\u00e7\u00e3o negativa (de 0.01, por exemplo). Ou seja, a fun\u00e7\u00e3o calcula f(x)=\ud835\udfd9(x<0)(\u03b1x)+\ud835\udfd9(x>=0)(x) onde \u03b1 \u00e9 uma constante.","04527451":"## Treinamento","340471db":"## Generator Network","07e236c3":"## Discriminator Network","63b34c20":"## Perda e Otimiza\u00e7\u00e3o do Discriminator","4372fc33":"## Perda e Otimiza\u00e7\u00e3o do Generator e Cria\u00e7\u00e3o do Modelo","0f041f56":"## Gerando Imagens com Etiquetas de Classe Dadas","b51d4459":"# Deep Convolutional Generative Adversarial Networks "}}