{"cell_type":{"43e03534":"code","54f2322e":"code","72a600df":"code","c0383da4":"code","9f4872ed":"code","252ccaaa":"code","031188ce":"code","e0f40629":"code","b768fc17":"code","10d0678b":"code","11e7560b":"code","83e6d05a":"code","0ca5b749":"code","7ec9d37e":"code","4daef0e3":"code","30f194f2":"code","d862ef57":"code","58d94afc":"code","6b9ee786":"code","20934979":"code","3ccee059":"code","16d7550a":"code","38f58096":"code","3db8dd83":"code","7e3d52f3":"code","9435c36b":"code","dad08de9":"code","26fb12a0":"code","4e3b221e":"code","ed7f5e81":"code","828390be":"code","ac3d9b10":"code","bb1ecb30":"code","d106fb01":"code","79dc9a2e":"code","ce62e1f9":"code","b91f6758":"markdown","f96e4119":"markdown","d7af10b4":"markdown","94b344db":"markdown","2df2e041":"markdown"},"source":{"43e03534":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport PIL \nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models","54f2322e":"dataset_url = \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file(\"flower_photos\", origin=dataset_url, cache_dir='.', untar=True)\n# cache_dir indicates where to download data. I specified . which means current directory\n# untar true will unzip it","72a600df":"import pathlib\ndata_dir = pathlib.Path(data_dir)\ndata_dir","c0383da4":"list(data_dir.glob('*\/*.jpg')) #This line shows all the files that ends with .jpg\nimage_count = len(list(data_dir.glob('*\/*.jpg'))) # and now we can know the length of the pictures we have\nimage_count","9f4872ed":"roses = list(data_dir.glob('roses\/*')) #This will display on the roses\nlen(roses)","252ccaaa":"PIL.Image.open(roses[96])","031188ce":"flowers_image_dict = {\n    'roses': list(data_dir.glob('roses\/*')),\n    'daisy': list(data_dir.glob('daisy\/*')),\n    'dandelion': list(data_dir.glob('dandelion\/*')),\n    'sunflowers': list(data_dir.glob('sunflowers\/*')),\n    'tulips': list(data_dir.glob('tulips\/*')),\n}","e0f40629":"flowers_labels_dict = {\n    'roses': 0,\n    'daisy': 1,\n    'dandelion': 2,\n    'sunflowers': 3,\n    'tulips': 4,\n}","b768fc17":"# so to read the first 5 roses files we can do it like that\nflowers_image_dict['roses'][:5]","10d0678b":"# Soooo to transform it to a numpy array we use cv2.imread() (OpenCV) but this actually requires a \"String\" not WindowsPath\nstr(flowers_image_dict['roses'][0])\nimg = cv2.imread(str(flowers_image_dict['roses'][0]))","11e7560b":"print(\"Image Shape: \", img.shape)","83e6d05a":"img1 = cv2.imread(str(flowers_image_dict['roses'][11]))\nimg1.shape","0ca5b749":"# Soooo here we notice that two roses pictures has way different shapes and we need to resize that by using \nprint(\"Image One: \", cv2.resize(img, (180,180)).shape)\nprint(\"Image Two: \", cv2.resize(img1, (180,180)).shape)","7ec9d37e":"# Sooooo we want do that to all the pictures and we achieve that by:\nX, y = [], []\n\nfor flower_name, images in flowers_image_dict.items(): # This iterates through each folder (key) in the dict\n    for image in images: # This loops through all the files (images path) in each key\n        img = cv2.imread(str(image)) # This reads the image file to an array\n        resized_img = cv2.resize(img, (180, 180)) # Here we resize the image tp 180*180\n        X.append(resized_img) # We add the images to X array \n        y.append(flowers_labels_dict[flower_name]) # We add the label from the labels dict we created so roses can be index 0 and so on","4daef0e3":"plt.imshow(X[0])","30f194f2":"X[0]","d862ef57":"X = np.array(X)\ny = np.array(y)","58d94afc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","6b9ee786":"# Now we should normalize our data \nX_train_scaled = X_train \/ 255\nX_test_scaled = X_test \/ 255","20934979":"ANN = models.Sequential([\n    layers.Conv2D(16, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(16, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(16, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(5, activation='softmax')\n])","3ccee059":"ANN.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.sparse_categorical_crossentropy,\n    metrics=['accuracy']\n)","16d7550a":"ANN.fit(X_train_scaled, y_train, epochs=10)","38f58096":"ANN.evaluate(X_test_scaled, y_test)","3db8dd83":"y_preds = ANN.predict(X_test_scaled)","7e3d52f3":"y_labels = [np.argmax(elem) for elem in y_preds]","9435c36b":"num = 200\nprint(\"Predicted: \", y_labels[num])\nprint(\"Label: \", y_test[num])","dad08de9":"data_augmentation = models.Sequential([\n    layers.experimental.preprocessing.RandomContrast(.3),\n    layers.experimental.preprocessing.RandomRotation(.1),\n    layers.experimental.preprocessing.RandomZoom(.2),\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\")\n])","26fb12a0":"plt.imshow(X[0]) #The image before applying data augmentation","4e3b221e":"plt.imshow(data_augmentation(X)[0].numpy().astype(\"uint8\")) #The image after applying data augmentation","ed7f5e81":"CNN_with_data_augmentation = models.Sequential([\n    data_augmentation,\n    layers.Conv2D(16, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, activation='relu', padding='same'),\n    layers.MaxPooling2D(),\n    layers.Dropout(.3),\n    \n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(5, activation='softmax')\n])","828390be":"CNN_with_data_augmentation.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.sparse_categorical_crossentropy,\n    metrics=['accuracy']\n)","ac3d9b10":"CNN_with_data_augmentation.fit(X_train_scaled, y_train, epochs=50)","bb1ecb30":"CNN_with_data_augmentation.evaluate(X_test_scaled, y_test)","d106fb01":"y_preds = CNN_with_data_augmentation.predict(X_test_scaled)","79dc9a2e":"y_labels = [np.argmax(elem) for elem in y_preds]","ce62e1f9":"num = 201\nprint(\"Predicted: \", y_labels[num])\nprint(\"Label: \", y_test[num])","b91f6758":"Now using `Pathlib` we can convert that path to `WindowsPath` and from it we can classify the pictures and put them in variables ","f96e4119":"### We notice that this model is overfitting even tho we scaled our data so we're trying some Data Augmentation techniques now","d7af10b4":"We Notice that with only 19 epochs after applying augmentation our model got really good with the training and with the test dataset so if we trained it more that can lead to much more better results","94b344db":"We notice that every picture is in different resolution so we need to actually change all of them to just one resolution \n<br><br><b>But first let's read the images from our disk into numpy array<\/b>","2df2e041":"### Now that we have our data in an array format we can start training the model"}}