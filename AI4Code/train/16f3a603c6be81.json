{"cell_type":{"0901f12b":"code","49c744ef":"code","ee04b24d":"code","025019f2":"code","ba9b0c53":"code","e3fdd33b":"code","250aa4b9":"code","65139f67":"code","7142fdcc":"code","55aa627a":"code","5a4be2c4":"code","4ca31442":"code","038cdd57":"code","399aecfc":"code","db946a25":"code","bf5e6845":"code","1b65a490":"code","409c6020":"code","37c8f33e":"code","85536e14":"code","fd0c697d":"code","72e548c6":"code","9e187299":"code","40445f26":"code","61cc01dc":"markdown","b9bbae78":"markdown","ab8bc8af":"markdown","b521f074":"markdown","e6bd51fd":"markdown","f6f0b01a":"markdown","bcd430d5":"markdown","15f6529f":"markdown","238744b8":"markdown","3a167d70":"markdown","0186b9b0":"markdown","8fa7326d":"markdown","06867f09":"markdown"},"source":{"0901f12b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","49c744ef":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split","ee04b24d":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost.sklearn import XGBClassifier","025019f2":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import auc, roc_curve\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_recall_fscore_support","ba9b0c53":"import os\nos.listdir('.\/..\/input')","e3fdd33b":"df = pd.read_csv(\"..\/input\/data.csv\")","250aa4b9":"print(df.shape)","65139f67":"print(df.info())","7142fdcc":"df.head()","55aa627a":"df.isna().any()","5a4be2c4":"del df['id']\ndel df['Unnamed: 32']","4ca31442":"x = df.loc[:, 'radius_mean': 'fractal_dimension_worst']\ny = df['diagnosis']","038cdd57":"di = {'M': 1, 'B': 0}\ny = y.map(di)\nprint(y)","399aecfc":"scale = StandardScaler()\nX = scale.fit_transform(x)","db946a25":"pca = PCA(n_components = 2)\nX = pca.fit_transform(X)","bf5e6845":"X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)","1b65a490":"dt = DecisionTreeClassifier()\ndt1 = dt.fit(X_train,y_train)\ny_pred_dt = dt1.predict(X_test)\ny_pred_dt_prob = dt1.predict_proba(X_test)\n\n\nrf = RandomForestClassifier(n_estimators=100)\nrf1 = rf.fit(X_train,y_train)\ny_pred_rf = rf1.predict(X_test)\ny_pred_rf_prob = rf1.predict_proba(X_test)\n\n\netc = ExtraTreesClassifier(n_estimators=100)\netc1 = etc.fit(X_train,y_train)\ny_pred_etc= etc1.predict(X_test)\ny_pred_etc_prob = etc1.predict_proba(X_test)\n\n\nknc = KNeighborsClassifier()\nknc1 = knc.fit(X_train,y_train)\ny_pred_knc= knc1.predict(X_test)\ny_pred_knc_prob = knc1.predict_proba(X_test)\n\n\nxg = XGBClassifier(learning_rate=0.5, reg_alpha= 5, reg_lambda= 0.1)\nxg1 = xg.fit(X_train,y_train)\ny_pred_xg= xg1.predict(X_test)\ny_pred_xg_prob = xg1.predict_proba(X_test)\n\n\ngbm = GradientBoostingClassifier()\ngbm1 = gbm.fit(X_train,y_train)\ny_pred_gbm= gbm1.predict(X_test)\ny_pred_gbm_prob= gbm1.predict_proba(X_test)","409c6020":"print(\"DecisionTreeClassifier: {0}\".format(accuracy_score(y_test,y_pred_dt)))\nprint(\"RandomForestClassifier: {0}\".format(accuracy_score(y_test,y_pred_rf)))\nprint(\"ExtraTreesClassifier: {0}\".format(accuracy_score(y_test,y_pred_etc)))\nprint(\"KNeighborsClassifier: {0}\".format(accuracy_score(y_test,y_pred_knc)))\nprint(\"XGBClassifier: {0}\".format(accuracy_score(y_test,y_pred_xg)))\nprint(\"GradientBoostingClassifier: {0}\".format(accuracy_score(y_test,y_pred_gbm)))\n","37c8f33e":"print(\"DecisionTreeClassifier: \", confusion_matrix(y_test,y_pred_dt))\nprint(\"RandomForestClassifier: \", confusion_matrix(y_test,y_pred_rf))\nprint(\"ExtraTreesClassifier: \", confusion_matrix(y_test,y_pred_etc))\nprint(\"GradientBoostingClassifier: \", confusion_matrix(y_test,y_pred_gbm))\nprint(\"KNeighborsClassifier: \", confusion_matrix(y_test,y_pred_knc))\nprint(\"XGBClassifier: \", confusion_matrix(y_test,y_pred_xg))","85536e14":"print(\"No. of elements in y_test:\", len(y_test))","fd0c697d":"fpr_dt, tpr_dt, thresholds = roc_curve(y_test, y_pred_dt_prob[: , 1], pos_label= 1)\nfpr_rf, tpr_rf, thresholds = roc_curve(y_test, y_pred_rf_prob[: , 1], pos_label= 1)\nfpr_etc, tpr_etc, thresholds = roc_curve(y_test, y_pred_rf_prob[: , 1], pos_label= 1)\nfpr_knc, tpr_knc, thresholds = roc_curve(y_test, y_pred_rf_prob[: , 1], pos_label= 1)\nfpr_xg, tpr_xg, thresholds = roc_curve(y_test, y_pred_xg_prob[: , 1], pos_label= 1)\nfpr_gbm, tpr_gbm, thresholds = roc_curve(y_test, y_pred_gbm_prob[: , 1], pos_label= 1)","72e548c6":"print(\"DecisionTreeClassifier: {0}\".format(auc(fpr_dt,tpr_dt)))\nprint(\"RandomForestClassifier: {0}\".format(auc(fpr_rf,tpr_rf)))\nprint(\"ExtraTreesClassifier: {0}\".format(auc(fpr_etc,tpr_etc)))\nprint(\"GradientBoostingClassifier: {0}\".format(auc(fpr_gbm,tpr_gbm)))\nprint(\"KNeighborsClassifier: {0}\".format(auc(fpr_knc,tpr_knc)))\nprint(\"XGBClassifier: {0}\".format(auc(fpr_xg,tpr_xg)))","9e187299":"print(\"DecisionTreeClassifier: \")\nprint(precision_recall_fscore_support(y_test,y_pred_dt))\nprint(\"RandomForestClassifier: \")\nprint(precision_recall_fscore_support(y_test,y_pred_rf))\nprint(\"ExtraTreesClassifier: \")\nprint(precision_recall_fscore_support(y_test,y_pred_etc))\nprint(\"GradientBoostingClassifier: \")\nprint(precision_recall_fscore_support(y_test,y_pred_gbm))\nprint(\"KNeighborsClassifier: \")\nprint(precision_recall_fscore_support(y_test,y_pred_knc))\nprint(\"XGBClassifier: \")\nprint(precision_recall_fscore_support(y_test,y_pred_xg))","40445f26":"# Plot ROC curve now\nfig = plt.figure(figsize=(12,10))\nax = fig.add_subplot(111)\n\n# Connect diagonals\nax.plot([0, 1], [0, 1], ls=\"--\")\n\n# Labels etc\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('ROC curve')\n\n# Set graph limits\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.0])\n\n# Plot each graph now\nax.plot(fpr_dt, tpr_dt, label = \"dt\")\nax.plot(fpr_rf, tpr_rf, label = \"rf\")\nax.plot(fpr_etc, tpr_etc, label = \"etc\")\nax.plot(fpr_knc, tpr_knc, label = \"knc\")\nax.plot(fpr_xg, tpr_xg, label = \"xg\")\nax.plot(fpr_gbm, tpr_gbm, label = \"gbm\")\n\n# Set legend and show plot\nax.legend(loc=\"lower right\")\nplt.show()","61cc01dc":"### From graph, we see algorithms xg and knc give us best results.","b9bbae78":"### AUC Values","ab8bc8af":"ROC Graph","b521f074":"## Basic Imports","e6bd51fd":"## Analyze data ","f6f0b01a":"### Classifiers\n\nCreate different classifiers and get predictions and prediction probabilities from them.","bcd430d5":"### Precision\/Recall\/F-score for each label (0,1)","15f6529f":"Deleting unneeded columns","238744b8":"Create our x (input data) and y (output data)","3a167d70":"Confusion Matrix","0186b9b0":"## Read data from file","8fa7326d":"## Sklearn Imports","06867f09":"#### Comparing the output of predictions with actual results"}}