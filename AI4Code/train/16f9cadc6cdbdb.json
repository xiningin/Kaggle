{"cell_type":{"38cfc0b0":"code","d1295db0":"code","8c140bfd":"code","a50b360b":"code","a9625d7c":"code","64b98297":"code","4c41c892":"code","74f0cdb2":"code","9e7f805c":"code","916762fd":"code","93645a34":"code","693236d9":"code","182b0a02":"code","f95d1872":"code","487242f6":"code","ae2a21cf":"code","b1608191":"code","9a49a013":"code","32dd0a06":"markdown","98223f01":"markdown","42bda4e1":"markdown","b12da700":"markdown","b4bd79e6":"markdown","f250d55b":"markdown","5a7dfb04":"markdown","369857c4":"markdown"},"source":{"38cfc0b0":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import pairwise\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom IPython.display import display","d1295db0":"from google.cloud import bigquery\nclient = bigquery.Client()","8c140bfd":"# All of the standard patent data is available in bigquery such as publication\/\n# grant\/filing\/priority date, inventors, assignees, cpc\/ipc\/etc codes, citations\n\ndf = client.query(\"\"\"\nSELECT\n  publication_number, country_code, publication_date, filing_date, \n  priority_date, grant_date, inventor, assignee, cpc, citation, priority_claim\nFROM\n  `patents-public-data.patents.publications` \nWHERE\n  RAND() < 0.01 \nLIMIT\n  5\"\"\").to_dataframe()","a50b360b":"df","a9625d7c":"# Some of the fields are nested and can be either unnested in bigquery or\n# python. Here we unnest all of the cpc and citation data. The unnesting of two\n# fields creates a cross join between them, so even for a single patent a lot\n# of rows are created.\n\ndf = client.query(\"\"\"\n\nSELECT \n  pubs.publication_number, \n  pubs.filing_date,\n  cpc.code as cpc_code, \n  cpc.first as cpc_first,\n  cpc.inventive as cpc_inventive,\n  cite.publication_number AS cite_pub,\n  cite.filing_date AS cite_filing_date\nFROM \n  `patents-public-data.patents.publications` AS pubs,\n  UNNEST(citation) AS cite,\n  UNNEST(cpc) AS cpc\nWHERE \n  pubs.publication_number = \"US-8000000-B2\"\n  \"\"\").to_dataframe()\n","64b98297":"df.head(20)","4c41c892":" # There is a lot of more detailed patent data that can be obtained,\n # such as the full text of the patent (title, abstract, claims, description),\n # its top terms and a 64 dimension embedding representation.\n \ndf = client.query(\"\"\"\n\nSELECT \n  pubs.publication_number,\n  abstract.text AS abstract,\n  claims.text AS claim,\n  top_terms,\n  embedding_v1 AS embedding\nFROM \n  `patents-public-data.patents.publications` AS pubs\n    INNER JOIN `patents-public-data.google_patents_research.publications` AS res ON \n      pubs.publication_number = res.publication_number,\n    UNNEST(abstract_localized) AS abstract,\n    UNNEST(claims_localized) AS claims\nWHERE \n  pubs.publication_number = \"US-8000000-B2\"\n  \"\"\").to_dataframe()","74f0cdb2":"df","9e7f805c":"# Get Embeddings for a random set of patents\n\ndf = client.query(\"\"\"\nSELECT \n  publication_number,\n  embedding_v1 as embedding\nFROM \n  `patents-public-data.google_patents_research.publications`\nWHERE \n  country = \"United States\"\n  AND RAND() < 0.1\nLIMIT\n  100\"\"\").to_dataframe()","916762fd":"# Compute similarity between the patents.\nemb = df.embedding.to_list()\npairwise.cosine_similarity(emb, emb)","93645a34":"# We can cluster the embeddings too\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=5, random_state=0).fit(emb)\nkmeans.labels_","693236d9":"# We fetch the embeddings for 10000 random US patents and use the first\n# letter of the cpc code as the classification for a patent.\n\ndf = client.query(\"\"\"\n\nSELECT \n  publication_number,\n  embedding_v1,\n  SUBSTR(cpc.code, 0, 1) AS cpc_class\nFROM \n  `patents-public-data.google_patents_research.publications`,\n  UNNEST(cpc) AS cpc\nWHERE \n  country = \"United States\"\n  AND RAND() < 0.1\nLIMIT\n  10000\"\"\").to_dataframe()","182b0a02":"cpc_classes = {\n    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'Y': 8}\nclasses = tf.convert_to_tensor([cpc_classes[x] for x in df.cpc_class.tolist()])\n\ninputs = tf.convert_to_tensor(df.embedding_v1.tolist())","f95d1872":"model = tf.keras.Sequential([\n  tf.keras.layers.Dense(32, activation='relu'),\n  tf.keras.layers.Dense(len(cpc_classes))\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\n\nhistory = model.fit(x=inputs,  y=classes, epochs=10, validation_split=0.1)","487242f6":"# For another set of 10000 random US patents we fetch the abstract text and\n# use the first letter of the cpc code for the classification.\n\ndf = client.query(\"\"\"\n\nSELECT \n  publication_number,\n  abstract,\n  SUBSTR(cpc.code, 0, 1) AS cpc_class\nFROM \n  `patents-public-data.google_patents_research.publications`,\n  UNNEST(cpc) AS cpc\nWHERE \n  country = \"United States\"\n  AND RAND() < 0.1\nLIMIT\n  100000\"\"\").to_dataframe()","ae2a21cf":"cpc_classes = {\n    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'Y': 8}\nclasses = tf.convert_to_tensor([cpc_classes[x] for x in df.cpc_class.tolist()])\n\nvocab_size = 1000\nemb_size = 16\ntokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n    df.abstract.tolist(), vocab_size)","b1608191":"msl = 100  # max sequence length\ninputs = [tokenizer.encode(x) for x in df.abstract.tolist()]\ninputs = [x[:msl] if len(x) > msl else x + [0]*(msl-len(x)) for x in inputs]\ninputs = tf.convert_to_tensor(inputs)","9a49a013":"model = tf.keras.Sequential([\n  tf.keras.layers.Embedding(vocab_size, emb_size),\n  tf.keras.layers.Conv1D(16, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling1D(),\n  tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.GlobalAveragePooling1D(),\n  tf.keras.layers.Dense(32, activation='relu'),\n  tf.keras.layers.Dense(len(cpc_classes))\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)\n\nhistory = model.fit(x=inputs, y=classes, epochs=10, validation_split=0.1)","32dd0a06":"# Build More Advanced Models","98223f01":"### Cluster Patents","42bda4e1":"### Similarity Between Patents","b12da700":"# Simple Patent Data","b4bd79e6":"### CPC Classifier With Embeddings","f250d55b":"**Copyright 2020 Google LLC**\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n\nhttp:\/\/www.apache.org\/licenses\/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","5a7dfb04":"# Gathering Some Unique Text, Top Terms, Embeddings Data","369857c4":"### CPC Classifier With Abstract Text"}}