{"cell_type":{"8bf89e48":"code","e20722f6":"code","23d4255a":"code","d422bf63":"code","7be70b2d":"code","c07b7739":"code","b4bdb1de":"code","513cc3ee":"code","cbf75da6":"code","971ca213":"code","7db7b459":"code","8d8e2746":"code","dd75f74d":"code","c37c1b81":"code","30504207":"code","1c876e27":"code","81d98ce1":"code","5660962b":"code","d32a75fe":"code","9c30c299":"code","4f53588f":"code","9b6fe633":"code","e684ee25":"code","36e91f54":"code","50192110":"markdown","f2ca68b4":"markdown","4dd8693f":"markdown","6829fac1":"markdown","70413266":"markdown","204c8425":"markdown","0e7bc433":"markdown","68fe8ef4":"markdown","f6bd9c27":"markdown","9b893cbc":"markdown","8ba65d9e":"markdown","78d43441":"markdown","8ec48cff":"markdown","fa8ffa89":"markdown","08df851f":"markdown","100a3d56":"markdown","ed44e0af":"markdown","e2a9bbc5":"markdown","01be2465":"markdown","bbeab146":"markdown","be727c93":"markdown","8432214d":"markdown","5b62ebb7":"markdown","2291ff3d":"markdown","71627773":"markdown","b1f875da":"markdown"},"source":{"8bf89e48":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e20722f6":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE","23d4255a":"df  = pd.read_csv('\/kaggle\/input\/asian-and-indian-cuisines\/asian_indian_recipes.csv')\ndf.head()","d422bf63":"df.info()","7be70b2d":"df.cuisine.value_counts().plot.barh()\nplt.show()","c07b7739":"thai_df = df[(df.cuisine == \"thai\")]\njapanese_df = df[(df.cuisine == \"japanese\")]\nchinese_df = df[(df.cuisine == \"chinese\")]\nindian_df = df[(df.cuisine == \"indian\")]\nkorean_df = df[(df.cuisine == \"korean\")]\n\nprint(f'thai df: {thai_df.shape}')\nprint(f'japanese df: {japanese_df.shape}')\nprint(f'chinese df: {chinese_df.shape}')\nprint(f'indian df: {indian_df.shape}')\nprint(f'korean df: {korean_df.shape}')","b4bdb1de":"# Create a function create_ingredient() in Python to create an \n# ingredient dataframe. This function will start by dropping an \n# unhelpful column and sort through ingredients by their count:\ndef create_ingredient_df(df):\n    ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')\n    ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]\n    ingredient_df = ingredient_df.sort_values(by='value', ascending=False,\n    inplace=False)\n    return ingredient_df","513cc3ee":"thai_ingredient_df = create_ingredient_df(thai_df)\nthai_ingredient_df.head(10).plot.barh()\nplt.show()","cbf75da6":"japanese_ingredient_df = create_ingredient_df(japanese_df)\njapanese_ingredient_df.head(10).plot.barh()\nplt.show()","971ca213":"chinese_ingredient_df = create_ingredient_df(chinese_df)\nchinese_ingredient_df.head(10).plot.barh()\nplt.show()","7db7b459":"indian_ingredient_df = create_ingredient_df(indian_df)\nindian_ingredient_df.head(10).plot.barh()\nplt.show()","8d8e2746":"feature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)\nlabels_df = df.cuisine #.unique()\nfeature_df.head()","dd75f74d":"oversample = SMOTE()\ntransformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)","c37c1b81":"print(f'new label count: {transformed_label_df.value_counts()}')\nprint(f'old label count: {df.cuisine.value_counts()}')","30504207":"cuisines_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')","1c876e27":"cuisines_df .head()","81d98ce1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\nfrom sklearn.svm import SVC","5660962b":"cuisines_label_df = cuisines_df['cuisine']\ncuisines_label_df.head()","d32a75fe":"cuisines_feature_df = cuisines_df.drop(['cuisine'], axis=1)\ncuisines_feature_df.head()","9c30c299":"X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)","4f53588f":"lr = LogisticRegression(multi_class='ovr',solver='liblinear')\nmodel = lr.fit(X_train, np.ravel(y_train))\n\naccuracy = model.score(X_test, y_test)\nprint (\"Accuracy is {}\".format(accuracy))","9b6fe633":"print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')\nprint(f'cuisine: {y_test.iloc[50]}')","e684ee25":"test= X_test.iloc[50].values.reshape(-1, 1).T\nproba = model.predict_proba(test)\nclasses = model.classes_\nresultdf = pd.DataFrame(data=proba, columns=classes)\n\ntopPrediction = resultdf.T.sort_values(by=[0], ascending = [False])\ntopPrediction.head()","36e91f54":"y_pred = model.predict(X_test)\nprint(classification_report(y_test,y_pred))","50192110":"We can see this model in action by testing one row of data (#50):","f2ca68b4":"Now we are ready to train the model!\n\n- We will use logistic regression to classify our data","4dd8693f":"- The next task will be to import the data:","6829fac1":"Divide the X and y coordinates into two dataframes for training. cuisine can be the labels dataframe:","70413266":"## Learning about cuisines","204c8425":"Now we can use that function to get an idea of top ten most popular ingredients by cuisine.\n\n- Call create_ingredient() and plot it calling barh():","0e7bc433":"## Apply logistic regression\nSince we are using the multiclass case, we need to choose what scheme to use and what solver to set. Use LogisticRegression with a multiclass setting and the liblinear solver to train.\n\n- Create a logistic regression with multi_class set to ovr and the solver set to liblinear:","68fe8ef4":"Get more detail by printing a classification report","f6bd9c27":"The data is nice and clean, balanced, and very delicious!\n\nThe last step is to save our balanced data, including labels and features, into a new dataframe that can be exported into a file:","9b893cbc":"## Discovering ingredients\nNow we can dig deeper into the data and learn what are the typical ingredients per cuisine. We should clean out recurrent data that creates confusion between cuisines, so let's learn about this problem.\n","8ba65d9e":"## Clean and balance the data","78d43441":"## Split the data\nSplit the data into training and testing groups by calling train_test_split():","8ec48cff":"- Get info about this data by calling info():","fa8ffa89":"Digging deeper, we can check for the accuracy of this prediction:","08df851f":"## Balance the dataset\nNow that we have cleaned the data, use SMOTE - \"Synthetic Minority Over-sampling Technique\" - to balance it.\n\n- Call fit_resample(), this strategy generates new samples by interpolation.","100a3d56":"The first task at hand, before starting this project, is to clean and balance our data to get better results. \n\n'imblearn' is a Scikit-learn package that will allow we to better balance the data.","ed44e0af":"Drop that the cuisine column, calling drop(). Save the rest of the data as trainable features:","e2a9bbc5":"Now we are set up to read import the data next.","01be2465":"Find out how much data is available per cuisine and print it out: ","bbeab146":"* Import the packages we need to import our data and visualize it, also import SMOTE from imblearn.","be727c93":"## Hello 'classifier'\n\nThe question we want to ask of this cuisine dataset is actually a multiclass question, as we have several potential national cuisines to work with. Given a batch of ingredients, which of these many classes will the data fit?\n\nScikit-learn offers several different algorithms to use to classify data, depending on the kind of problem we want to solve.","8432214d":"Now, import several more libraries:","5b62ebb7":"Now the work starts to become more interesting. Let's discover the distribution of data, per cuisine\n\n- Plot the data as bars by calling barh():","2291ff3d":"**The accuracy is good!**","71627773":"By balancing our data, we'll have better results when classifying it. Think about a binary classification. If most of our data is one class, a ML model is going to predict that class more frequently, just because there is more data for it. Balancing the data takes any skewed data and helps remove this imbalance.\n\n- Now we can check the numbers of labels per ingredient:","b1f875da":"Now, drop the most common ingredients that create confusion between distinct cuisines, by calling drop():\n\n- Everyone loves rice, garlic and ginger!"}}