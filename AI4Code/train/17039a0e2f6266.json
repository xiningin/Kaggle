{"cell_type":{"4fa77a7d":"code","ee27bf5d":"code","b2b1ac86":"code","51b48b99":"code","b8ddf9da":"code","1583ee82":"code","6ed75a3d":"code","179ab152":"code","f0d9f70a":"code","14f5120d":"code","7d20ed0f":"code","48b10a83":"code","c64f58bc":"code","a2fc62c3":"code","48845e16":"code","910ed73f":"code","bd896ee4":"code","b91b2895":"code","2d779bdd":"code","a078ca06":"code","208da37b":"code","aac547d9":"code","20c8ec73":"code","d0d7557c":"code","a9e60611":"code","296b92b5":"code","767cb889":"code","4e9c9c89":"code","9f22b37a":"code","3423c4ba":"code","89c862df":"code","dec46112":"code","bf59a913":"code","5a129e5b":"code","5cf51743":"code","70e94cf6":"code","e4732212":"code","1b0b95d1":"code","2c144758":"markdown","d243963f":"markdown","e5ed2a8b":"markdown","de7895a5":"markdown","3207b463":"markdown","6b169e83":"markdown","0fe85bf3":"markdown","ce6024cb":"markdown","233637e7":"markdown","3b38f52c":"markdown","b69343c4":"markdown","ad3e968f":"markdown","dff2ce41":"markdown","a69e56f2":"markdown","fa2c7d9e":"markdown","28de4c3e":"markdown","f6d2be77":"markdown","747208c8":"markdown","a50f7e23":"markdown","b65b7f3d":"markdown","59e15b00":"markdown","d097f460":"markdown","fb52bbcd":"markdown"},"source":{"4fa77a7d":"from math import sqrt\n\nimport pandas as pd","ee27bf5d":"# Pandas config\ndef pandas_config():\n    # display 10 rows and all the columns\n    pd.set_option('display.max_rows', 20)\n    pd.set_option('display.max_columns', None)\n\n    \npandas_config()","b2b1ac86":"# Global path variables\nRATINGS_PATH = '\/kaggle\/input\/movielens-20m-dataset\/rating.csv'\nLINK_PATH = '\/kaggle\/input\/movielens-20m-dataset\/link.csv'\nGENOME_PATH = '\/kaggle\/input\/movielens-20m-dataset\/genome_tags.csv'\nGENOME_SCORES_PATH = '\/kaggle\/input\/movielens-20m-dataset\/genome_scores.csv'\nTAGS_PATH = '\/kaggle\/input\/movielens-20m-dataset\/tag.csv'\nMOVIE_PATH = '\/kaggle\/input\/movielens-20m-dataset\/movie.csv'","51b48b99":"movies_df = pd.read_csv(MOVIE_PATH)\nratings_df = pd.read_csv(RATINGS_PATH)","b8ddf9da":"movies_df.sample(5)","1583ee82":"ratings_df.sample(5)","6ed75a3d":"# Remove the years from the title of `movies_df`\ndef rm_dates_from_title(df: pd.DataFrame):\n    # Using regular expressions to find a year stored between parentheses\n\n    # We specify the parantheses so we don't conflict with movies that have years in their titles\n    df['year'] = df.title.str.extract('(\\(\\d\\d\\d\\d\\))', expand=False)\n\n    # Removing the parentheses\n    df['year'] = df.year.str.extract('(\\d\\d\\d\\d)', expand=False)\n\n    # Removing the years from the 'title' column\n    df['title'] = df.title.str.replace('(\\(\\d\\d\\d\\d\\))', '', regex=True)\n\n    # Applying the strip function to get rid of any ending whitespace characters that may have appeared\n    df['title'] = df.title.apply(lambda x: x.strip())\n\n    \nrm_dates_from_title(movies_df)\nmovies_df.sample(5)","179ab152":"# Every genre is separated by a | so we simply have to call the split function on |\nmovies_df.genres = movies_df.genres.str.split('|')\nmovies_df.sample(5)","f0d9f70a":"# one-hot-encode movies_df's genres column\ndef one_hot_encode_genres(df: pd.DataFrame):\n    # Copying the movie dataframe into a new one since we won't need to use\n    # the genre information in our content-based recommendation system.\n    movies_with_genres_df = df.copy()\n\n    # For every row in the dataframe, iterate through the list of genres and place\n    # a 1 into the corresponding column\n    for index, row in df.iterrows():\n        for genre in row.genres:\n            movies_with_genres_df.at[index, genre] = 1\n\n    # Filling in the NaN values with 0 to show that a movie doesn't have that column's genre\n    movies_with_genres_df.fillna(0, inplace=True)\n\n    return movies_with_genres_df\n\n\nmovies_with_genres_df = one_hot_encode_genres(movies_df)\nmovies_with_genres_df.sample(5)","14f5120d":"ratings_df.sample(5)","7d20ed0f":"# Drop removes a specified row or column from a dataframe\nratings_df.drop('timestamp', axis='columns', inplace=True)\nratings_df.sample(5)","48b10a83":"# Creating an input user to recommend movies to\ndef get_dummy_user():\n    '''This will the user to whome we will recommend movies. This user has his own list \n      of favourite movies which we will use to recommend him movies related to those \n      movies which he has highly rated.\n      \n      Notice: To add more movies, simply increase the amount of elements in the userInput. \n      Feel free to add more in! Just be sure to write it in with capital letters and if a \n      movie starts with a \"The\", like \"The Matrix\" then write it in like this: 'Matrix, The'. '''\n\n    user_input = [\n        {\n            'title': 'Breakfast Club, The',\n            'rating': 5\n        }, {\n            'title': 'Toy Story',\n            'rating': 3.5\n        }, {\n            'title': 'Jumanji',\n            'rating': 2\n        }, {\n            'title': \"Pulp Fiction\",\n            'rating': 5\n        }, {\n            'title': 'Akira',\n            'rating': 4.5\n        }\n    ]\n\n    input_movies = pd.DataFrame(user_input)\n    return input_movies\n\n\ninput_movies = get_dummy_user()\ninput_movies.sample(5)","c64f58bc":"# Add movieId to input user\ndef add_movies_ids(movies_df, input_movies):\n    # Filtering out the movies by title\n    input_id = movies_df[movies_df.title.isin(input_movies.title.tolist())]\n\n    # Then merging it so we can get the movie_id. It's implicitly merging it by title.\n    input_movies = pd.merge(input_movies, input_id)\n\n    # Dropping movies information that we won't use from the input dataframe\n    input_movies.drop(['genres', 'year'], axis='columns', inplace=True)\n\n    return input_movies\n\n\ninput_movies = add_movies_ids(movies_df, input_movies)\ninput_movies.sample(5)","a2fc62c3":"# Filtering out the movies from movies_with_genres_df\nuser_movies = movies_with_genres_df[movies_with_genres_df['movieId'].isin(\n    input_movies['movieId'].tolist()\n)]\n\nuser_movies.sample(5)","48845e16":"# We'll only need the actual genre table, so let's clean this up a bit by resetting the\n# index and dropping the movieId, title, genres and year columns.\n\n# Resetting the index to avoid future issues\nuser_movies = user_movies.reset_index(drop=True)\n\n# Dropping unnecessary issues due to memory and to avoid issues\nuser_genre_df = user_movies.drop(['movieId', 'title', 'genres', 'year'], axis='columns')\n\nprint(user_genre_df.shape)\nuser_genre_df","910ed73f":"input_movies['rating']","bd896ee4":"# Dot product to get weights\nuser_profile = user_genre_df.T.dot(input_movies['rating'])\n\nprint(user_profile.shape)\nuser_profile.head(len(user_profile))","b91b2895":"# Now let's get the genres of every movie in our original dataframe\ngenre_df = movies_with_genres_df.set_index(movies_with_genres_df['movieId'])\n\n# Droping the unnecessary information\ngenre_df.drop(['movieId', 'title', 'genres', 'year'], axis='columns', inplace=True)\n\nprint(genre_df.shape)\ngenre_df.sample(5)","2d779bdd":"print(genre_df.shape)\nprint(user_profile.shape)","a078ca06":"user_profile","208da37b":"genre_df.head(2)","aac547d9":"genre_df.head(2) * user_profile","20c8ec73":"(genre_df.head(2) * user_profile).sum(axis='columns')","d0d7557c":"# Multiplying each row in genre_df with the user_profile and summing that row values\n# to get wieght to recommend the movies\ndef get_recommendation_df(genre_df, user_profile):\n    # Also normalizing the values by dividing by user_profile.sum()\n    df = ((genre_df * user_profile).sum(axis='columns')) \/ user_profile.sum()\n    return df\n\n\nrecommendation_df = get_recommendation_df(genre_df, user_profile)\n\nprint(recommendation_df.shape)\nrecommendation_df.head()","a9e60611":"# Sort our recommendations in descending order\nrecommendation_df = recommendation_df.sort_values(ascending=False)\nrecommendation_df.head()","296b92b5":"# Final recommedation table\n# Getting only top 20 movies to recommend to user\nmovies_df.loc[movies_df['movieId'].isin(recommendation_df.head(20).keys())]","767cb889":"user_subset = ratings_df[ratings_df['movieId'].isin(input_movies['movieId'].tolist())]\n\nprint(user_subset.shape)\nuser_subset.head()","4e9c9c89":"# We now group up the rows by user ID.\nuser_subset_group = user_subset.groupby(['userId'])\n\n# let's look at one of the users, e.g. the one with userID=1130\nuser_subset_group.get_group(1130)","9f22b37a":"# Sorting users with movie most in common with the input will have priority\nuser_subset_group = sorted(user_subset_group, key=lambda x: len(x[1]), reverse=True)\n\n# Top 3 users in user_subset_group\nuser_subset_group[0:3]","3423c4ba":"user_subset_group = user_subset_group[0:100]","89c862df":"def calculate_persona_corr(user_subset_group, input_movies):\n    # Store the Pearson Correlation in a dictionary, where the key is the user Id and the\n    # value is the coefficient\n    pearson_corr_dict = {}\n\n    # For every user group in our subset\n    for name, group in user_subset_group:\n        # Let's start by sorting the input and current user group so the values aren't mixed up later on\n        group = group.sort_values(by='movieId')\n        input_movies = input_movies.sort_values(by='movieId')\n\n        # Get the N for the formula\n        n_ratings = len(group)\n\n        # Get the review scores for the movies that they both have in common\n        temp_df = input_movies[input_movies['movieId'].isin(group['movieId'].tolist())]\n\n        # And then store them in a temporary buffer variable in a list format to facilitate future calculations\n        temp_rating_list = temp_df['rating'].tolist()\n\n        # Let's also put the current user group reviews in a list format\n        temp_group_list = group['rating'].tolist()\n\n        # Now let's calculate the pearson correlation between two users, so called, x and y\n        Sxx = sum([i**2 for i in temp_rating_list]) - pow(sum(temp_rating_list), 2) \/ float(n_ratings)\n        Syy = sum([i**2 for i in temp_group_list]) - pow(sum(temp_group_list), 2) \/ float(n_ratings)\n        Sxy = sum(i * j for i, j in zip(temp_rating_list, temp_group_list)) - sum(temp_rating_list) * sum(temp_group_list) \/ float(n_ratings)\n\n        # If the denominator is different than zero, then divide, else, 0 correlation.\n        if Sxx != 0 and Syy != 0:\n            pearson_corr_dict[name] = Sxy \/ sqrt(Sxx * Syy)\n        else:\n            pearson_corr_dict[name] = 0\n\n    return pearson_corr_dict\n\n\npearson_corr_dict = calculate_persona_corr(user_subset_group, input_movies)\npearson_corr_dict.items()","dec46112":"def create_pearson_df(pearson_corr_dict):\n    pearson_df = pd.DataFrame.from_dict(pearson_corr_dict, orient='index')\n    pearson_df.columns = ['similarityIndex']\n    pearson_df['userId'] = pearson_df.index\n    pearson_df.index = range(len(pearson_df))\n    return pearson_df\n\n\npearson_df = create_pearson_df(pearson_corr_dict)\npearson_df.sample(5)","bf59a913":"# Now let's get the top 50 users that are most similar to the input.\ntop_users = pearson_df.sort_values(by='similarityIndex', ascending=False)[0:50]\ntop_users.head()","5a129e5b":"top_users_rating = top_users.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\ntop_users_rating.head()","5cf51743":"# Multiplies the similarity by the user's ratings\ntop_users_rating['weightedRating'] = top_users_rating['similarityIndex'] * top_users_rating['rating']\ntop_users_rating.head()","70e94cf6":"# Applies a sum to the top_users after grouping it up by userId\ntemp_top_users_rating = top_users_rating.groupby('movieId').sum()[['similarityIndex', 'weightedRating']]\ntemp_top_users_rating.columns = ['sum_similarityIndex', 'sum_weightedRating']\ntemp_top_users_rating.head()","e4732212":"# Creates an empty dataframe\nrecommendation_df = pd.DataFrame()\n\n# Now we take the weighted average\nrecommendation_df['weighted average recommendation score'] = temp_top_users_rating['sum_weightedRating'] \/ temp_top_users_rating['sum_similarityIndex']\nrecommendation_df['movieId'] = temp_top_users_rating.index\nrecommendation_df.head()","1b0b95d1":"# Now let's sort it and see the top 20 movies that the algorithm recommended!\nrecommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\nrecommendation_df.head(10)\n\nmovies_df.loc[movies_df['movieId'].isin(recommendation_df.head(10)['movieId'].tolist())]","2c144758":"The top x similar users to input user","d243963f":"#### Top 20 recommendations","e5ed2a8b":"Now, let's start `recommending movies` to the input user.\n\nRating of selected users to all movies\n\nWe're going to do this by taking the `weighted average` of the ratings of the movies using the `Pearson Correlation` as the weight. But to do this, we first need to get the movies watched by the users in our pearson_df from the ratings dataframe and then store their correlation in a new column called `similarityIndex`. This is achieved below by merging of these two tables.","de7895a5":"Below are the few info about `genre_df` and `user_profile` to understand the recommendation code logic ","3207b463":"The above gives how much the `input user` will like movie with `movieId` 1 & 2. We can say that user might like movie with movieId 1 more than 2.\n\nBelow is `get_recommendation_df` applys the above recommendation logic over the entire `genre_df` dataset.","6b169e83":"# Movie Recommendation System\n\nHere [MovieLens 20M Dataset](https:\/\/www.kaggle.com\/grouplens\/movielens-20m-dataset) by `GroupLens` is used to build `content based` and `collaborative filtering` recommendation systems.\n\n![](https:\/\/media.giphy.com\/media\/l3vR2SwA3hfH4NtVC\/giphy.gif)","0fe85bf3":"Now we're ready to start learning the input's preferences!\n\nTo do this, we're going to `turn each genre into weights`. We can do this by using the input's reviews and multiplying them into the input's genre table and then summing up the resulting table by column. This operation is actually a `dot product between a matrix and a vector`.","ce6024cb":"### Cleaning the `rating_df`","233637e7":"Let's also sort these groups so the users that share the `most movies in common` with the input have higher priority. This provides a richer recommendation since `we won't go through every single user`.","3b38f52c":"`input_movies`, `rating_df` and `movie_df` are not altered in either recommendation systems","b69343c4":"`Similarity of users to input user`\n\nNext, we are going to compare all users (not really all !!!) to our specified user and find the one that is `most similar`. We're going to find out how similar each user is to the input through the `Pearson Correlation Coefficient`. It is used to measure the strength of a linear association between two variables.\n\nPearson correlation is `invariant to scaling`, i.e. multiplying all elements by a nonzero constant or adding any constant to all elements. For example, if you have two vectors X and Y,then, `pearson(X, Y) == pearson(X, 2 * Y + 3)`. This is a pretty `important property` in recommendation systems because for example two users might rate two series of items totally different in terms of absolute rates, but they would be similar users (i.e. with similar ideas) with similar rates in various scales.\n\n![Pearson Correlation](https:\/\/cdn-5a6cb102f911c811e474f1cd.closte.com\/wp-content\/uploads\/2020\/08\/Pearson-Correlation-Coefficient-Formula.png)\n\nThe values given by the pearson correlation formula vary from r = -1 to r = 1, where 1 forms a direct correlation between the two entities (it means a perfect positive correlation) and -1 forms a perfect negative correlation. In our case, a 1 means that the two users have similar tastes while a -1 means the opposite.\n\nWe will select a subset of users to iterate through. This limit is imposed because we don't want to waste too much time going through every single user.","ad3e968f":"With the `input's profile` and the `complete list of movies and their genres` in hand, we're going to take the `weighted average of every movie based on the input profile` and recommend the top twenty movies that most satisfy it.","dff2ce41":"Now, we calculate the Pearson Correlation between input user and subset group, and store it in a dictionary, where the key is the user Id and the value is the coefficient","a69e56f2":"Getting the users who has `seen the same movies` as our input user. With the movie ID's in our input, we can now get the subset of users that have watched and reviewed the movies in our input.","fa2c7d9e":"Since keeping genres in a list format isn't optimal for the content-based recommendation system technique, we will use the `One Hot Encoding` technique to convert the list of genres to a vector where each column corresponds to one possible value of the feature. \n\nThis encoding is needed for feeding categorical data. In this case, we store every different genre in columns that contain either 1 or 0. `1 shows that a movie has that genre and 0 shows that it doesn't`. Let's also store this dataframe in another variable since genres won't be important for our first recommendation system","28de4c3e":"---\n\nI'll wrap things up there. If you want to find some other answers then go ahead `edit` this kernel. If you have any `questions` then do let me know.\n\nIf this kernel helped you then don't forget to \ud83d\udd3c `upvote` and share your \ud83c\udf99 `feedback` on improvements of the kernel.\n\n![](https:\/\/media.giphy.com\/media\/N2fDcOGHsEEA8\/giphy.gif)\n\n---","f6d2be77":"## \ud83e\udd41 Building content based recommendation system\n\n![](https:\/\/media.giphy.com\/media\/mdzHqtdkwdeZG\/giphy.gif)\n\n`Content-Based` or `Item-Item recommendation systems`, this technique attempts to figure out what a user's favourite aspects of an item is and then recommends items that present those aspects.\n\nHere we're going to try to figure out the input's `favourite genres` from the `movies` and `ratings` given.\n\nWe're going to start by learning the `input's preferences`, so let's get the subset of movies that the input has watched from the Dataframe containing genres defined with binary values.","747208c8":"Every row in the ratings dataframe has a user id associated with at least one movie, a rating and a timestamp showing when they reviewed it. We won't be needing the `timestamp column`, so let's drop it to save on memory.","a50f7e23":"## \ud83c\udfbb Data Preparation","b65b7f3d":"In this dot product we understand that what user likes, so we see what is the `combined adventure, romance, etc...` does users rated movies have & from there we understand that the user likes adventure movies alot, the user's second preference is romantic movies and so on... This is what the weights tells us.\n\nNow, we have the `weights for every genre of the user's preferences`. This is known as the `User Profile`. Using this, we can recommend movies that satisfy the user's preferences.","59e15b00":"Now all we need to do is simply multiply the movie rating by its weight (The similarity index), then sum up the new ratings and divide it by the sum of the weights.\n\nWe can easily do this by simply multiplying two columns, then grouping up the dataframe by movieId and then dividing two columns.\n\nIt shows the idea of all similar users to candidate movies for the input user","d097f460":"## \ud83c\udfb7 Building collaborative filtering recommendation system\n\n![](https:\/\/media.giphy.com\/media\/Jbv9LhPjpiI5W\/giphy.gif)\n\n`Collaborative Filtering`, which is also known as `User-User Filtering`.\n\nAs hinted by its alternate name, this technique uses other users to recommend items to the input user. It attempts to find users that have similar preferences and opinions as the input and then recommends items that they have liked to the input. There are several methods of finding `similar users` (Even some making use of Machine Learning), and the one used here is based on the `Pearson Correlation Function`.\n\nThe process for creating a `User Based recommendation` system is as follows:\n\n- Select a user with the movies the user has watched\n- Based on his rating to movies, find the top X neighbours\n- Get the watched movie record of the user for each neighbour.\n- Calculate a similarity score using some formula\n- Recommend the items with the highest score","fb52bbcd":"### Cleaning the `movie_df`"}}