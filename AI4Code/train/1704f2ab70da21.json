{"cell_type":{"c9d64d90":"code","1672c3c8":"code","86f3a9bc":"code","79f427f5":"code","55987ab1":"code","cad5218a":"code","9e8dc226":"code","4fd09f1d":"code","7d24e135":"code","3acf8d97":"code","46106056":"code","457b4d01":"code","5d1e930f":"code","497cb288":"code","1260cc34":"code","1b1542dd":"markdown","57f44ef2":"markdown","367d3400":"markdown","f5d64169":"markdown","497d1951":"markdown"},"source":{"c9d64d90":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1672c3c8":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\n\nIMG_SIZE = (96, 96)\nIN_SHAPE = (*IMG_SIZE, 3)\nBATCH_SIZE = 64","86f3a9bc":"# CROP_TEST = 36\n# IN_SHAPE_TEST = (CROP_TEST,CROP_TEST,3)\n","79f427f5":"df_data = pd.read_csv('..\/input\/train_labels.csv')\ntrain_dir = \"..\/input\/train\/\"\ntest_dir = \"..\/input\/test\"\n    ","55987ab1":"#Taken from https:\/\/www.kaggle.com\/byrachonok\/cancer-detection-show-data\nfig, ax = plt.subplots(1,3, figsize=(20,5))\nfor i, idx in enumerate(df_data[df_data['label'] == 0]['id'][:3]):\n    path = os.path.join('\/kaggle\/input\/train\/', idx)\n    ax[i].imshow(Image.open(path+'.tif'))\n    pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n            fc=(0.0, 0.0, 0.0, 0.0), \n            ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n    ax[i].add_patch(pf)","cad5218a":"fig, ax = plt.subplots(1,3, figsize=(20,5))\nfor i, idx in enumerate(df_data[df_data['label'] == 1]['id'][:3]):\n    path = os.path.join('\/kaggle\/input\/train\/', idx)\n    ax[i].imshow(Image.open(path+'.tif'))\n    pt = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n            fc=(0.0, 0.0, 0.0, 0.0), \n            ec=(0.9, 0.0, 0.0 ,0.9), lw=4, linestyle='--')\n    ax[i].add_patch(pt)","9e8dc226":"train, valid = train_test_split(df_data,test_size=0.15)\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) \/ x.std() if x.std() > 0 else x,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rotation_range=90, shear_range=0.05, zoom_range=0.1 )\n\ntest_datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) \/ x.std() if x.std() > 0 else x)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = train,\n    directory='..\/input\/train\/',\n    x_col='id',\n    y_col='label',\n    has_ext=False,\n    batch_size=BATCH_SIZE,\n    seed=2018,\n    shuffle=True,\n    class_mode='binary',\n    target_size=IMG_SIZE)\n\nvalid_generator = test_datagen.flow_from_dataframe(\n    dataframe = valid,\n    directory='..\/input\/train\/',\n    x_col='id',\n    y_col='label',\n    has_ext=False,\n    batch_size=BATCH_SIZE,\n    seed=2018,\n    shuffle=False,\n    class_mode='binary',\n    target_size=IMG_SIZE\n)","4fd09f1d":"# conv_base = ResNet50(\n#     weights='imagenet',\n#     include_top=False,\n#     input_shape=IN_SHAPE\n# )\n\n# VGG model without the last classifier layers (include_top = False)\nconv_base = VGG16(include_top = False,\n                    input_shape = IN_SHAPE,\n                    weights='imagenet')\n    \n# Freeze the layers \nfor layer in conv_base.layers[:-12]:\n    layer.trainable = False\n    \n# Check the trainable status of the individual layers\nfor layer in conv_base.layers:\n    print(layer, layer.trainable)","7d24e135":"model = Sequential()\n# model.add(Cropping2D(cropping=((CROP_TEST,CROP_TEST), (48,48)), input_shape=IN_SHAPE))\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation=\"relu\"))\nmodel.add(Dropout(0.6))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.6))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nconv_base.summary()","3acf8d97":"# conv_base.Trainable=True\n\n# set_trainable=False\n# for layer in conv_base.layers:\n#     if layer.name == 'res5a_branch2a':\n#         set_trainable = True\n#     if set_trainable:\n#         layer.trainable = True\n#     else:\n#         layer.trainable = False","46106056":"model.compile(optimizers.Adam(0.001), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","457b4d01":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\n\nearlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\nlearning_rate_decay = ReduceLROnPlateau(monitor='acc', patience=2, verbose=1, factor=0.3, min_lr=1e-5)\n\nhistory = model.fit_generator(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=50,\n                   callbacks=[learning_rate_decay, earlystopper])","5d1e930f":"from glob import glob\nfrom skimage.io import imread\n\nbase_test_dir = '..\/input\/test\/'\ntest_files = glob(os.path.join(base_test_dir,'*.tif'))\nsubmission = pd.DataFrame()\nfile_batch = 5000\nmax_idx = len(test_files)\nfor idx in range(0, max_idx, file_batch):\n    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n    test_df['id'] = test_df.path.map(lambda x: x.split('\/')[3].split(\".\")[0])\n    test_df['image'] = test_df['path'].map(imread)\n    K_test = np.stack(test_df[\"image\"].values)\n    K_test = (K_test - K_test.mean()) \/ K_test.std()\n    predictions = model.predict(K_test)\n    test_df['label'] = predictions\n    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\nsubmission.head()","497cb288":"submission.to_csv(\"submission.csv\", index = False, header = True)","1260cc34":"# Save the last model\n#model.save('..\/input\/model.h5')","1b1542dd":"Positive examples","57f44ef2":"Negative examples.\n\nCredit: https:\/\/www.kaggle.com\/byrachonok\/cancer-detection-show-data","367d3400":"Model using VGG16 as base","f5d64169":"Credit: https:\/\/www.kaggle.com\/fadhli\/starter-code-keras-resnet50-0-9275-lb","497d1951":"Submission"}}