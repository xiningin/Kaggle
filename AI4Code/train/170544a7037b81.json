{"cell_type":{"50bde970":"code","feddb54e":"code","5282189b":"code","67669f53":"code","f8f55d71":"code","d90b531a":"code","7e344b7a":"code","36036580":"code","166be7d7":"code","43727758":"code","a6838d24":"code","dee2eead":"code","622d4bdd":"code","43533a55":"code","3faaed82":"code","fb57bfc2":"code","6f8bed62":"code","01af616d":"code","d4a26dfd":"code","cd02a20c":"code","d3e7e118":"code","72d96093":"code","74695a77":"code","d84c94f7":"code","511d24f7":"code","a0e2253b":"code","485ec677":"code","a4a22e6b":"code","cfdcbc69":"code","be1dc96b":"code","eb61080d":"code","e574eb6f":"code","0c927acc":"code","9ba53078":"code","7a6e5bc7":"code","69b27d0e":"code","2e412b7a":"code","0fd24a5e":"code","1b135341":"code","9df5f60a":"code","730d77bf":"code","f545ae9c":"code","7787e691":"code","67ef9581":"code","18812bc1":"code","1cbef70b":"code","afd0801d":"code","1ac4f0ac":"code","cc1bad81":"code","741a16d9":"code","7b0d4721":"code","06b97d05":"code","9f966aef":"code","2b3a8bfd":"code","47a5c130":"code","c2f6aa32":"code","9560392a":"code","15551fb5":"code","a0faff71":"code","e2163161":"code","6aaa029a":"code","728d1427":"code","b352a520":"code","eee04532":"code","682f8b8e":"code","408ad8fc":"code","57e591a9":"code","d0ab6b60":"code","25b911f3":"code","2177b380":"code","c5d3bb77":"code","2cf74fdc":"code","a85afdb4":"code","d3eae6bd":"code","9430dded":"code","48573d43":"code","40701ccc":"code","67b1c773":"code","7597eee7":"code","9fac2a74":"code","0080acf0":"code","bb1d7029":"code","ccba210f":"code","e189db54":"markdown","96a7d003":"markdown","b39932a1":"markdown"},"source":{"50bde970":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","feddb54e":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n","5282189b":"train.isnull().sum()","67669f53":"train.describe()","f8f55d71":"train = train.drop([\"Name\",\"PassengerId\",\"Ticket\"], axis =1)\n\ntest = test.drop([\"Name\",\"Ticket\"],axis =1)","d90b531a":"train","7e344b7a":"#one-hot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","36036580":"train.nunique()","166be7d7":"train.columns","43727758":"categorical = ['Pclass','Sex', 'SibSp', 'Parch', 'Embarked']","a6838d24":"for i in categorical:\n    sns.barplot(x=i,y=\"Survived\", data = train)\n    plt.show()","dee2eead":"sns.histplot(data = train[train[\"Survived\"]==1], x=\"Age\", kde=True,stat =\"probability\", bins = 10)","622d4bdd":"#sns.histplot(data = train[train[\"Survived\"]==1], x=\"Fare\", kde=True,stat =\"probability\", bins = 10)","43533a55":"train.value_counts(train.Embarked)","3faaed82":"train.Parch.isnull().sum()\ntrain = train.dropna(subset = [\"Parch\"], axis = 0)\ntest =  test.dropna(subset = [\"Parch\"], axis = 0)","fb57bfc2":"test.isnull().sum()","6f8bed62":"train.Parch.isnull().sum()","01af616d":"train= train.dropna(subset=[\"Embarked\"])","d4a26dfd":"train[\"Sex\"].isnull().sum()","cd02a20c":"train[\"Age\"].isnull().sum()","d3e7e118":"train[\"Age\"].fillna(train[\"Age\"].median(),inplace = True)\ntest[\"Age\"].fillna(test[\"Age\"].median(),inplace = True)","72d96093":"train[\"Age\"].isnull().sum()","74695a77":"sns.histplot(data = train[train[\"Survived\"]==1], x=\"Age\", kde=True,stat =\"probability\", bins = 10)\n#this is not indivdual class prob","d84c94f7":"train=train.drop(columns =[\"Cabin\"])\ntest=test.drop(columns =[\"Cabin\"])\n","511d24f7":"train","a0e2253b":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder","485ec677":"#Label Encoding the necessary\nle =LabelEncoder()\nlabel = le.fit_transform(train['Embarked'])\nl2= le.fit_transform(train['Sex'])\nlabel_test = le.fit_transform(test['Embarked'])\nl2_test= le.fit_transform(test['Sex'])","a4a22e6b":"#train =train.drop(['Embarked'], axis =1)","cfdcbc69":"train['Embarked'] = label\ntest['Embarked'] = label_test\n","be1dc96b":"train['Sex'] = l2\ntest['Sex'] = l2_test\n","eb61080d":"train","e574eb6f":"ohe = OneHotEncoder()\nX = ohe.fit_transform(train.Embarked.values.reshape(-1,1)).toarray()\n'''dfOneHot = pd.DataFrame(X) \ntrain =pd.concat([train,dfOneHot], axis =1)'''\nX_test = ohe.fit_transform(train.Embarked.values.reshape(-1,1)).toarray()","0c927acc":"X.shape","9ba53078":"dfOneHot = pd.DataFrame(X, columns = [\"Embarked_\"+str(int(i)) for i in range(X.shape[1])])\ntrain = pd.concat([train,dfOneHot], axis =1)\ntrain = train.drop(\"Embarked\", axis =1)\n\ndfOneHot_test = pd.DataFrame(X_test, columns = [\"Embarked_\"+str(int(i)) for i in range(X_test.shape[1])])\ntest = pd.concat([test,dfOneHot_test], axis =1)\ntest = test.drop(\"Embarked\", axis =1)","7a6e5bc7":"train.nunique()","69b27d0e":"train.Parch.isnull().sum()","2e412b7a":"train[train[\"Parch\"]==0]","0fd24a5e":"train.dropna(subset = [\"Parch\"], axis =0,inplace =True)\ntest.dropna(subset = [\"Parch\"], axis =0,inplace =True)\n","1b135341":"train[\"Parch\"].isnull().sum()","9df5f60a":"X= ohe.fit_transform(train.Parch.values.reshape(-1,1)).toarray()\nX_test = ohe.fit_transform(test.Parch.values.reshape(-1,1)).toarray()","730d77bf":"train.isnull().sum()","f545ae9c":"\"\"\"dfOneHot = pd.DataFrame(X, columns = [\"Parch_\"+str(int(i)) for i in range(X.shape[1])])\ntrain = pd.concat([train,dfOneHot], axis =1)\ntrain = train.drop(\"Parch\", axis =1)\n\ndfOneHot_test = pd.DataFrame(X_test, columns = [\"Parch_\"+str(int(i)) for i in range(X_test.shape[1])])\ntest = pd.concat([test,dfOneHot_test], axis =1)\ntest = test.drop(\"Parch\", axis =1)\"\"\"","7787e691":"train","67ef9581":"train[\"SibSp\"].unique()","18812bc1":"train[\"SibSp\"].isnull().sum()","1cbef70b":"train.dropna(subset = [\"SibSp\"], axis =0,inplace =True)\ntest.dropna(subset = [\"SibSp\"], axis =0,inplace =True)","afd0801d":"\"\"\"X= ohe.fit_transform(train.SibSp.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"SibSp_\"+str(int(i)) for i in range(X.shape[1])])\ntrain = pd.concat([train,dfOneHot], axis =1)\ntrain = train.drop(\"SibSp\", axis =1)\n\nX_test= ohe.fit_transform(test.SibSp.values.reshape(-1,1)).toarray()\ndfOneHot_test = pd.DataFrame(X_test, columns = [\"SibSp_\"+str(int(i)) for i in range(X_test.shape[1])])\ntest = pd.concat([test,dfOneHot_test], axis =1)\ntest = test.drop(\"SibSp\", axis =1)\"\"\"","1ac4f0ac":"train[\"Pclass\"].isnull().sum()\ntrain.dropna(subset = [\"Pclass\"], axis =0,inplace =True)\nX= ohe.fit_transform(train.Pclass.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"Pclass_\"+str(int(i)) for i in range(X.shape[1])])\ntrain = pd.concat([train,dfOneHot], axis =1)\ntrain = train.drop(\"Pclass\", axis =1)\n\nX_test= ohe.fit_transform(test.Pclass.values.reshape(-1,1)).toarray()\ndfOneHot_test = pd.DataFrame(X_test, columns = [\"Pclass_\"+str(int(i)) for i in range(X_test.shape[1])])\ntest = pd.concat([test,dfOneHot_test], axis =1)\ntest = test.drop(\"Pclass\", axis =1)","cc1bad81":"train = train.dropna(axis=0)","741a16d9":"train.isnull().sum()","7b0d4721":"train.shape","06b97d05":"\"\"\"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain= scaler.fit_transform(X_train)\"\"\"","9f966aef":"print(test.columns)\nprint(train.columns)","2b3a8bfd":"train","47a5c130":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(train.drop(columns=['Survived'], axis=1),\n    train['Survived'],\n    test_size=0.3,\n    random_state=0)","c2f6aa32":"print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)","9560392a":"from sklearn.feature_selection import mutual_info_classif\n\nmutual_info = mutual_info_classif(X_train, y_train)\nmutual_info","15551fb5":"#convert to series and then label them\nmutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","a0faff71":"cols = mutual_info.sort_values(ascending=False).index[15:]\ncols","e2163161":"\"\"\"X_train = X_train.drop(cols,axis =1)\nX_test = X_test.drop(cols,axis =1)\"\"\"","6aaa029a":"X_train","728d1427":"X_train.shape","b352a520":"y_train.dtypes","eee04532":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train= scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n\"\"\"test_s = scaler.fit_transform(test)\"\"\"","682f8b8e":"y_test.shape","408ad8fc":"from sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score\nsvm_model= LinearSVC()\nsvm_model.fit(X_train,y_train)\ny_pred = svm_model.predict(X_test)\ny_pred.shape\nacc = accuracy_score(y_pred,y_test)\nprint(acc*100)","57e591a9":"from sklearn.tree import DecisionTreeClassifier\nlt_model = DecisionTreeClassifier()\nlt_model.fit(X_train,y_train)\ny_pred = lt_model.predict(X_test)\nacc = accuracy_score(y_pred,y_test)\nprint(acc*100)","d0ab6b60":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier()\nrf_model.fit(X_train,y_train)\ny_pred = rf_model.predict(X_test)\nacc = accuracy_score(y_pred,y_test)\nprint(acc*100)","25b911f3":"from sklearn.ensemble import GradientBoostingClassifier\ngb_model = GradientBoostingClassifier()\ngb_model.fit(X_train,y_train)\ny_pred = gb_model.predict(X_test)\nacc = accuracy_score(y_pred,y_test)\nprint(acc*100)","2177b380":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nlog_model = LogisticRegression()\nlog_model.fit(X_train,y_train)\ny_pred = log_model.predict(X_test)\nacc = accuracy_score(y_pred,y_test)\nprint(acc*100)","c5d3bb77":"test.columns","2cf74fdc":"X_train.shape","a85afdb4":"test.shape","d3eae6bd":"train.columns","9430dded":"test.isnull().sum()","48573d43":"test[\"Fare\"].fillna(test[\"Fare\"].median(),inplace = True)","40701ccc":"ids= test[\"PassengerId\"]\ntest = test.drop([\"PassengerId\"], axis=1)","67b1c773":"test_s = scaler.fit_transform(test)","7597eee7":"predictions = rf_model.predict(test_s)","9fac2a74":"predictions","0080acf0":"predictions.shape","bb1d7029":"op = pd.DataFrame({\"PassengerId\":ids.astype(int),\"Survived\":predictions.astype(int)})\nop.to_csv('submission.csv',index=False)","ccba210f":"op","e189db54":"**Mutual Info**","96a7d003":"# Dealing with Missing Data","b39932a1":"X"}}