{"cell_type":{"eef745fb":"code","a04e7ac3":"code","26d80e14":"code","81da47d8":"code","34d7a625":"code","5bae4a5f":"code","345a065c":"code","c0ea6994":"code","de3601f4":"code","ba636dc3":"code","0abb5ba2":"code","f31a5ca8":"code","7aea9f18":"code","7b5a3c71":"code","d7e2ebd9":"code","a2226f7c":"code","4793a8f5":"code","9f013f6e":"code","742ad827":"code","6e0f096d":"code","006e2d8e":"code","339ac818":"code","ad62f174":"code","df47e265":"markdown","5a064a8d":"markdown","0e2ba2c4":"markdown"},"source":{"eef745fb":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\nimport seaborn as sns","a04e7ac3":"train_stft = pd.read_csv(\"..\/input\/volcano-20201231-feature-engineering\/train_features.csv\")\ntest_stft = pd.read_csv(\"..\/input\/volcano-20201231-feature-engineering\/test_features.csv\")\n\ntrain_fft = pd.read_csv(\"..\/input\/volcano-2020-10-19\/train_features.csv\")\ntest_fft = pd.read_csv(\"..\/input\/volcano-2020-10-19\/test_features.csv\")\n\ntrain_features = pd.concat([train_stft, train_fft], axis=1)\ntest_features = pd.concat([test_stft, test_fft], axis=1)\n\nfeatures = pd.concat([train_features, test_features], axis=0)\nfeatures.fillna(0, inplace=True)\nfeatures","26d80e14":"tmp = features.sample(n=40, axis=1, random_state=91)\ntmp","81da47d8":"fig, axes = plt.subplots(8, 5, figsize=(25, 20))\n\nfor i, col in enumerate(tmp.columns):\n    axes.ravel()[i].hist(tmp[col], bins=50, color=\"teal\")\n    \nplt.show()","34d7a625":"from scipy.special import erfinv\n\n# \u30e9\u30f3\u30af\u30ac\u30a6\u30b9\u5909\u63db\u3059\u308b\u95a2\u6570\u3092\u5b9a\u7fa9\u3059\u308b\ndef rank_gauss(x):\n    n = x.shape[0]    # \u30b5\u30f3\u30d7\u30eb\u6570\n    temp = x.argsort()\n    rank_x = temp.argsort() \/ n\n    rank_x -= rank_x.mean()\n    rank_x *= 2\n    efi_x = erfinv(rank_x)\n    efi_x -= efi_x.mean()\n    return efi_x","5bae4a5f":"fig, axes = plt.subplots(8, 5, figsize=(25, 20))\n\nfor i, col in enumerate(tmp.columns):\n    rg = rank_gauss(tmp[col])\n    axes.ravel()[i].hist(rg, bins=50, color=\"teal\")\n    \nplt.show()","345a065c":"X_rg = pd.DataFrame()\n\nfor col in features.columns:\n    rg = rank_gauss(features[col])\n    X_rg = pd.concat([X_rg, rg], axis=1)\n    \nX_rg","c0ea6994":"X = X_rg.iloc[:len(train_features), :]\nX_test = X_rg.iloc[len(train_features):, :]\n\nX = np.array(X)\nX_test = np.array(X_test)","de3601f4":"train = pd.read_csv(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv\")\ny = train[\"time_to_eruption\"]\ny","ba636dc3":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials","0abb5ba2":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=34)\n\nprint(X_train.shape)\nprint(X_val.shape)","f31a5ca8":"kf1 = KFold(n_splits=10, shuffle=True, random_state=95)\nkf2 = KFold(n_splits=10, shuffle=True, random_state=43)","7aea9f18":"lgb_train = lgb.Dataset(X_train, label=y_train)\nlgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)","7b5a3c71":"def lgb_score(params):\n\n    params[\"num_leaves\"] = int(params[\"num_leaves\"])\n    params[\"min_data_in_leaf\"] = int(params[\"min_data_in_leaf\"])\n\n    model = lgb.train(params=lgb_params,\n                      train_set=lgb_train,\n                      valid_sets=(lgb_train, lgb_val),\n                      num_boost_round=10000,\n                      early_stopping_rounds=20,\n                      verbose_eval=0)\n    \n    pred = model.predict(X_val, num_iteration=model.best_iteration)    \n    score = mae(pred, y_val)\n    \n    history.append((params, score))\n    \n    return {\"loss\": score, \"status\": STATUS_OK}","d7e2ebd9":"lgb_params = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"regression\",\n    \"eval_metric\": \"mae\",\n    \"num_leaves\": 31,\n    \"learning_rate\": 0.08,\n    \"bagging_fraction\": 0.8,\n    \"feature_fraction\": 0.8,\n    \"min_data_in_leaf\": 20,\n    \"random_state\": 93\n}\n\n# \u63a2\u7d22\u3059\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u7a7a\u9593\u3092\u6307\u5b9a\nparams_space = {\n    \"num_leaves\": hp.quniform(\"num_leaves\", 25, 50, 1),\n    \"min_data_in_leaf\": hp.quniform(\"min_data_in_leaf\", 10, 70, 1),\n    \"bagging_fraction\": hp.quniform(\"bagging_fraction\", 0.6, 0.95, 0.025),\n    \"feature_fraction\": hp.quniform(\"feature_fraction\", 0.6, 0.95, 0.025)\n}\n\ntrials = Trials()\nhistory = []\n\nfmin(lgb_score, params_space, algo=tpe.suggest, trials=trials, max_evals=100)\n\nhistory = sorted(history, key=lambda tpl: tpl[1])\nbest = history[0]\n\nprint(f\"best_params: {best[0]}, mae: {best[1]:.10f}\")","a2226f7c":"lgb_params = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"regression\",\n    \"eval_metric\": \"mae\",\n    \"num_leaves\": best[0][\"num_leaves\"],\n    \"learning_rate\": 0.05,\n    \"bagging_fraction\": best[0][\"bagging_fraction\"],\n    \"feature_fraction\": best[0][\"feature_fraction\"],\n    \"min_data_in_leaf\": best[0][\"min_data_in_leaf\"],\n    \"random_state\": 93\n}","4793a8f5":"pred_lgb1 = pd.DataFrame()\n\nfor k, (tr_id, vl_id) in enumerate(kf1.split(X, y)):\n    \n    X_train, X_val = X[tr_id, :], X[vl_id, :]\n    y_train, y_val = y[tr_id], y[vl_id]\n    \n    lgb_train = lgb.Dataset(X_train, label=y_train)\n    lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n    \n    model = lgb.train(params=lgb_params,\n                      train_set=lgb_train,\n                      valid_sets=(lgb_train, lgb_val),\n                      num_boost_round=20000,\n                      early_stopping_rounds=100,\n                      verbose_eval=0)\n    \n    pred = model.predict(X_val, num_iteration=model.best_iteration)\n    print(f\"k={k+1}, mae: {mae(pred, y_val)}\")\n    \n    pred = model.predict(X_test, num_iteration=model.best_iteration)\n    pred = pd.Series(pred)\n    pred_lgb1 = pd.concat([pred_lgb1, pred], axis=1)","9f013f6e":"pred_lgb1","742ad827":"pred_lgb2 = pd.DataFrame()\n\nfor k, (tr_id, vl_id) in enumerate(kf2.split(X, y)):\n    \n    X_train, X_val = X[tr_id, :], X[vl_id, :]\n    y_train, y_val = y[tr_id], y[vl_id]\n    \n    lgb_train = lgb.Dataset(X_train, label=y_train)\n    lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n    \n    model = lgb.train(params=lgb_params,\n                      train_set=lgb_train,\n                      valid_sets=(lgb_train, lgb_val),\n                      num_boost_round=20000,\n                      early_stopping_rounds=100,\n                      verbose_eval=0)\n    \n    pred = model.predict(X_val, num_iteration=model.best_iteration)\n    print(f\"k={k+1}, mae: {mae(pred, y_val)}\")\n    \n    pred = model.predict(X_test, num_iteration=model.best_iteration)\n    pred = pd.Series(pred)\n    pred_lgb2 = pd.concat([pred_lgb2, pred], axis=1)","6e0f096d":"pred_lgb2","006e2d8e":"pred = pd.concat([pred_lgb1, pred_lgb2], axis=1)\npred = pred.mean(axis=1)\npred","339ac818":"sample_sub = pd.read_csv(\"..\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv\")\nsub = sample_sub.copy()\nsub[\"time_to_eruption\"] = pred\n\nsub","ad62f174":"sub.to_csv(\"submission.csv\", index=False)","df47e265":"## lgb","5a064a8d":"## Prediction","0e2ba2c4":"# Submission"}}