{"cell_type":{"8de22a4d":"code","d65f5aee":"code","19dd612e":"code","7e6381d9":"code","cea05f5a":"code","7b34f326":"code","b81d74f0":"code","ea06c9e6":"code","89175bd2":"code","131f7606":"code","1151d683":"code","91f66524":"code","a08b611c":"code","39acb862":"code","cb60a123":"code","9b6609d2":"code","b7e0e37d":"code","83416eb0":"code","f30bab48":"markdown","45046382":"markdown","8fb6d2ee":"markdown","62213caa":"markdown","d920a1dc":"markdown","1b65ba21":"markdown","29cc3ba6":"markdown","35062a41":"markdown","664f3a23":"markdown","1344ccef":"markdown","52861b0c":"markdown","153cf349":"markdown","06d0d78c":"markdown","832f5262":"markdown","15fe6c35":"markdown"},"source":{"8de22a4d":"import pandas as pd\n\n#Gr\u00e1fico\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# ML\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import  DecisionTreeRegressor\nfrom sklearn.metrics import r2_score #m\u00e9todo para o c\u00e1lculo do R2\nfrom sklearn.metrics import mean_squared_error #erro absoluto","d65f5aee":"pnad = pd.read_csv('..\/input\/testes\/dados.csv')\npnad.head()","19dd612e":"pnad.describe()","7e6381d9":"pnad.isnull().sum()","cea05f5a":"#removendo valores n\u00e3o significativos para an\u00e1lise \npnad.drop(columns= ['UF', 'Sexo', 'Cor', 'Altura'], inplace= True)\npnad.head()","7b34f326":"pnad.boxplot(['Renda'])","b81d74f0":"plt.bar( pnad['Idade'], pnad['Renda'])\nplt.xlabel('Idade')\nplt.ylabel('Renda')\nplt.title('Idade x Renda')\nplt.show()","ea06c9e6":"plt.bar( pnad['Anos de Estudo'], pnad['Renda'])\nplt.xlabel('Anos de Estudo')\nplt.ylabel('Renda')\nplt.title('Anos de Estudo x Renda')\nplt.show()","89175bd2":"#Correla\u00e7\u00e3o \ncorr = pnad.corr()\ncorr.style.background_gradient()","131f7606":"x = pnad.iloc[:,:-1].values\n#x_res = x.reshape((-1,1))\ny = pnad.iloc[:,-1].values\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)","1151d683":"#treinamento\nreg_lg = LinearRegression()\nreg_lg.fit(x_train,y_train)","91f66524":"#previs\u00e3o\npred_lg = reg_lg.predict(x_test)\nprint('Y = {}X {}'.format(reg_lg.coef_,reg_lg.intercept_))","a08b611c":"#m\u00e9tricas para dados de TEST \nR2_reg = r2_score(y_test, pred_lg)  #realiza o c\u00e1lculo do R2\n\nprint(\"Coeficiente de Determina\u00e7\u00e3o (R2):\", R2_reg)\n\nMSE_reg = mean_squared_error(y_test,pred_lg) # encontra o MSE atrav\u00e9s do sklearn\nprint('MSE: ', MSE_reg) ","39acb862":"#m\u00e9tricas para dados de TREINAMENTO \n\npred_lg2 = reg_lg.predict(x_train)\nR2_reg2 = r2_score(y_train, pred_lg2)  #realiza o c\u00e1lculo do R2\n\nprint(\"Coeficiente de Determina\u00e7\u00e3o (R2):\", R2_reg2)\n\nMSE_reg2 = mean_squared_error(y_train,pred_lg2) # encontra o MSE atrav\u00e9s do sklearn\nprint('MSE: ', MSE_reg2) ","cb60a123":"#treinando \nreg_dt = DecisionTreeRegressor() # Cria objeto DecisionTreeRegressor\nreg_dt.fit(x_train,y_train)\n","9b6609d2":"#previs\u00e3o\npred_dt= reg_dt.predict(x_test)\nprint(pred_dt)","b7e0e37d":"#m\u00e9tricas para dados de TESTE\nR2_dt= r2_score(y_test,pred_dt)\nprint(\"Coeficiente de Determina\u00e7\u00e3o (R2):\", R2_dt)\n\nMSE_dt = mean_squared_error(y_test,pred_dt) # encontra o MSE atrav\u00e9s do sklearn\nprint('MSE: ', MSE_dt)","83416eb0":"#m\u00e9tricas para dados de TREINAMENTO \n\npred_dt2 = reg_dt.predict(x_train)\nR2_dt2 = r2_score(y_train, pred_dt2)  #realiza o c\u00e1lculo do R2\nprint(\"Coeficiente de Determina\u00e7\u00e3o (R2):\", R2_dt2)\n\nMSE_dt2 = mean_squared_error(y_train,pred_dt2) # encontra o MSE atrav\u00e9s do sklearn\nprint('MSE: ', MSE_reg2) ","f30bab48":"O maior grau de correla\u00e7\u00e3o est\u00e1 associado ao Anos de Estudo.\n\nOBS: como esperado a Idade e o Anos de Estudos s\u00e3o inversamente proporcionais ","45046382":"#An\u00e1lise da base","8fb6d2ee":"**Analisando correla\u00e7\u00e3o entre vari\u00e1veis**","62213caa":"# Modelos de Regress\u00e3o Linear Multipla ","d920a1dc":"**Gr\u00e1fico Anos de Estudo x Renda**","1b65ba21":"**DecisionTreeRegressor**","29cc3ba6":"Os valores de renda est\u00e3o muitos disperos. De forma que \u00e9 dificil determinar o que de fato \u00e9 outlier. Por este motivo a exist\u00eancia de outliers ser\u00e1 desconsiderada \n","35062a41":"Valores ausentes ","664f3a23":"**Gr\u00e1fico Idade x Renda**","1344ccef":"Separando os dados em treino e teste para a valida\u00e7\u00e3o cruzada 70\/30","52861b0c":"**LinearRegression**","153cf349":"A renda do brasileiro ser\u00e1 analisada a partir da vari\u00e1veis Idade e Anos de Estudo. O objetivo \u00e9 mensurar o grau de correla\u00e7\u00e3o entre essas vari\u00e1veis e a renda","06d0d78c":"**Poss\u00edveis outliers**","832f5262":"# An\u00e1lise da vari\u00e1vel renda ","15fe6c35":"# Conclus\u00e3o:\nAmbos os modelos de regress\u00e3o linear simples apresentam desempenhos parecidos. Nenhum dos dois explica bem a vari\u00e1vel Renda, pois n\u00e3o possuem **R2** (poder explicativo) satisfat\u00f3rios e apresentam **MSE** (erro m\u00e9dio quadr\u00e1tico) elevados. \n  Como as m\u00e9tricas est\u00e3o est\u00e3o t\u00e3o ruins para os dados de teste quanto para os de treinamento, pode se concluir que n\u00e3o estamos diantes de um problema de **overfitting** e sim de **underfitting**. As principais poss\u00edveis causas est\u00e3o abaixo:  \n\n1.   Pode ser que outras vari\u00e1veis n\u00e3o presentes no dataset influenciem mais a renda do brasileiro ou complementem a an\u00e1lise. \n2.   Os dados podem n\u00e3o serem bem modelados um modelo linear, tal como foi utilizado. \n3.   Os outliers podem estar atrapalhando o desempenho dos modelos \n\nPor fim, podemos concluir que an\u00e1lise da renda do brasileiro requer uma modelagem mais complexa e\/ou um melhor escolha de v\u00e1riaveis preditoras.  "}}