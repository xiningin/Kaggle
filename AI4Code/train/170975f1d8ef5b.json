{"cell_type":{"af55ca59":"code","93ea67c5":"code","96478504":"code","7b2a5c25":"code","c49507a7":"code","920eb4a9":"code","af97f712":"code","e38639e3":"code","28cdff8f":"code","9afe2a3f":"code","dfd4d617":"code","fb408e39":"code","510236b9":"code","5a7b9ca2":"code","72285575":"code","a5d05f7b":"code","665a583e":"code","5835ff96":"code","eaa8ea0c":"code","6a72dfff":"code","cdf1b974":"code","617438fe":"code","165cfaf6":"code","c9fdda62":"code","7b25de90":"code","b7966d38":"code","1150611c":"code","7de5fa3f":"code","d6e56852":"code","d1df342f":"code","72735fe2":"markdown","a6b6b727":"markdown","84a746b4":"markdown","4f7401ce":"markdown","3d6515af":"markdown"},"source":{"af55ca59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93ea67c5":"uk_retail=pd.read_csv('..\/input\/twentysev\/twentyeleven.csv')","96478504":"uk_retail.info()","7b2a5c25":"uk_retail['InvoiceDate']=pd.to_datetime(uk_retail['InvoiceDate'])","c49507a7":"uk_retail['dayofweek']=uk_retail['InvoiceDate'].dt.dayofweek","920eb4a9":"uk_retail['dayofweek'].value_counts()","af97f712":"uk_retail['date']=uk_retail['InvoiceDate'].dt.strftime('%Y-%m-%d')","e38639e3":"uk_retail['date']=pd.to_datetime(uk_retail['date'])","28cdff8f":"## Grouping retail sku's to identify datewise sales\n\nretail_grouped= uk_retail.groupby(['Description','date']).agg(total_sale=('Quantity','sum')).reset_index()","9afe2a3f":"# Calulating average and standard deviation\n\ncv_data = retail_grouped.groupby('Description').agg(average=('total_sale','mean'),\n                                                    sd=('total_sale','std')).reset_index()","dfd4d617":"## Calculating CV_squared\n\ncv_data['cv_sqr'] = (cv_data['sd']\/cv_data['average'])**2\ncv_data","fb408e39":"prod_by_date= uk_retail.groupby(['Description','date']).agg(count=('Description','count')).reset_index()","510236b9":"skus=prod_by_date.Description.value_counts()","5a7b9ca2":"## Product sku's list\n\nskus","72285575":"new_df= pd.DataFrame()","a5d05f7b":"for i in range(len(skus.index)):\n    a= prod_by_date[prod_by_date['Description']==skus.index[i]]\n    a['previous_date']=a['date'].shift(1)\n    new_df=pd.concat([new_df,a],axis=0)","665a583e":"new_df.info()","5835ff96":"new_df['duration']=new_df['date']- new_df['previous_date']","eaa8ea0c":"new_df['Duration']=new_df['duration'].astype(str).str.replace('days','')","6a72dfff":"new_df['Duration']=pd.to_numeric(new_df['Duration'],errors='coerce')","cdf1b974":"## Calculating ADI\n\nADI = new_df.groupby('Description').agg(ADI = ('Duration','mean')).reset_index()","617438fe":"ADI","165cfaf6":"## Cross validation\n\nadi_cv=pd.merge(ADI,cv_data)","c9fdda62":"adi_cv","7b25de90":"## Defining a fuction for categorization\n\ndef category(df):\n    a=0\n    \n    if((df['ADI']<=1.34) & (df['cv_sqr']<=0.49)):\n        a='Smooth'\n    if((df['ADI']>=1.34) & (df['cv_sqr']>=0.49)):  \n        a='Lumpy'\n    if((df['ADI']<1.34) & (df['cv_sqr']>0.49)):\n        a='Erratic'\n    if((df['ADI']>1.34) & (df['cv_sqr']<0.49)):\n        a='Intermittent'\n    return a","b7966d38":"## Categorizing products based on their forcastability\n\nadi_cv['category']=adi_cv.apply(category,axis=1)","1150611c":"## Categorized list\n\nadi_cv.head","7de5fa3f":"import seaborn as sns","d6e56852":"## Visualizing the categories\n\nsns.scatterplot(x='cv_sqr',y='ADI',hue='category',data=adi_cv)","d1df342f":"## Final category counts\n\nadi_cv.category.value_counts()","72735fe2":"### Forecast accuracy strongly depends upon the product forcastability. To determine this,we apply two coefficients:\n\n* Average Demand Interval (ADI)- it measures the demand regularity in time by computing the average inerval between two demands.\n* Square of Coefficient of variation(CV^2)- it measures the variation in quantities.\n\nBased on these 2 dimensions, we can classify demand profiles into 4 categories:\n\na) Smooth demand (ADI < 1.32 and CV\u00b2 < 0.49)- The demand is regular in time and in quantity. It is therefore easy to forecast with a low forecasting error level. \n\nb) Intermittent demand (ADI >= 1.32 and CV\u00b2 < 0.49)- The demand history shows very little variation in demand quantity but a high variation in the interval between two demands. Though specific forecasting methods tackle intermittent demands, the forecast error margin is higher.\n\nc) Erratic demand (ADI < 1.32 and CV\u00b2 >= 0.49)-The demand has regular occurrences in time with high quantity variations. The forecast accuracy remains shaky.\n\nd) Lumpy demand (ADI >= 1.32 and CV\u00b2 >= 0.49). The demand is characterized by a large variation both in quantity and time. It is actually impossible to produce a reliable forecast, no matter which forecasting tools we use.\n","a6b6b727":"## Demand Classification based on forcastability of products","84a746b4":"## Conclusion: Final list of sku's categorized based on their forcastability.","4f7401ce":"## Average Demand Interval (ADI) per Product","3d6515af":"## Coefficient of Variance Squared (CV2)"}}