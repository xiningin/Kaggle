{"cell_type":{"7f4864eb":"code","bc8575fb":"code","4c7bb38e":"code","3913229e":"code","e43be997":"code","b9595843":"code","3a10f392":"code","f2114b9b":"code","038bb372":"code","84e14529":"code","46b90504":"code","69a9720b":"code","f256f0ed":"code","4f9f666f":"code","5d2fcb9d":"code","61efe715":"code","0298c0ee":"code","22f80b5a":"code","5066eed3":"code","b28a8b1f":"code","2c367acb":"code","ee82a609":"code","beaba2f8":"code","0eac053b":"code","29d659ec":"code","b5457b7c":"code","b5d52a52":"code","dd39cbca":"code","481f4ac9":"code","bf2ba4a2":"code","3368b181":"markdown","ee28c603":"markdown","a7ddf88f":"markdown","8d5b70f9":"markdown","15696270":"markdown","6e09ebef":"markdown","364300a2":"markdown","b7f14681":"markdown","15f74a5d":"markdown","a15ae1f7":"markdown","86fa1492":"markdown","06eb2f6f":"markdown","f73106bf":"markdown","d59fcfc0":"markdown","33c76e69":"markdown","90cc7848":"markdown","50efe83a":"markdown","4c17261e":"markdown","1c8fba78":"markdown","aeb4fec1":"markdown","baca599d":"markdown","a810ee76":"markdown","a84f2896":"markdown","fd8dfe9c":"markdown","fa29b7da":"markdown","dddb4fb9":"markdown","b186ad37":"markdown","553ff8d1":"markdown","0ae5efc5":"markdown","1cf9ccef":"markdown","f36dd553":"markdown"},"source":{"7f4864eb":"# Importing all libraries required in this notebook\nimport pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","bc8575fb":"# Reading data from remote link\nurl = \"http:\/\/bit.ly\/w-data\"\ndf = pd.read_csv(url)\ndf.head()","4c7bb38e":"df.shape","3913229e":"df.isnull().sum()","e43be997":"df.Hours.mean()","b9595843":"df.describe()","3a10f392":"# Plotting the distribution of scores\ndf.plot(x='Hours', y='Scores', style='gx')  \nplt.title('Hours vs Percentage')  \nplt.xlabel('Hours Studied')  \nplt.ylabel('Percentage')  \nplt.show() ","f2114b9b":"from pandas_profiling import ProfileReport","038bb372":"profile = ProfileReport(df, title=\"EDA Report\")\nprofile","84e14529":"profile.to_file(\"Report.html\")","46b90504":"X = df.iloc[:, :-1].values  #Independent variable\ny = df.iloc[:, 1].values  #Target variable","69a9720b":"X.shape","f256f0ed":"y.shape","4f9f666f":"from sklearn.model_selection import train_test_split  \nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                            test_size=0.2, random_state=0) ","5d2fcb9d":"print(X_test)\nprint(y_test)","61efe715":"from sklearn.linear_model import LinearRegression  \nregressor = LinearRegression()  \nregressor.fit(X_train, y_train) \n\nprint(\"Training complete.\")","0298c0ee":"# Plotting the regression line\nline = regressor.coef_*X+regressor.intercept_\nprint(\"Regression Equation =\", regressor.coef_,\"X\",\"+\",regressor.intercept_)\n# Plotting for the test data\nplt.scatter(X,y)\nplt.plot(X,line)","22f80b5a":"# Testing data\npred = regressor.predict(X_test) # Predicting the scores\npred","5066eed3":"# Comparing Actual vs Predicted\ndf2 = pd.DataFrame({'Actual': y_test, 'Predicted': pred})  \ndf2","b28a8b1f":"# We can also test with our own data\nhours = [[9.25]]\nown_pred = regressor.predict(hours)\nprint(\"No of Hours = {}\".format(hours))\n\nif own_pred>=100:\n    print(\"You are Perfect! You have scored 100%\")\nelse:\n    print(\"Predicted Percentage Score = {}\".format(own_pred[0]))","2c367acb":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import explained_variance_score\n\nmse = mean_absolute_error(y_test,pred) \nmae = mean_absolute_error(y_test,pred)\nr2 = r2_score(y_test,pred)\nevs = explained_variance_score(y_test,pred)\n\nprint(mse)\nprint(mae)\nprint(r2)\nprint(evs)","ee82a609":"import statsmodels.api as sm\nX_train2 = sm.add_constant(X_train)\nmodel = sm.OLS(y_train,X_train2)\nresult = model.fit()\nresult.params\n\nresult.summary()","beaba2f8":"X_test2 = sm.add_constant(X_test)","0eac053b":"pred2 = result.predict(X_test2) ","29d659ec":"Residual = pred2 - y_test","b5457b7c":"sns.distplot(Residual)","b5d52a52":"df.plot(x='Hours', y='Scores', style='go')","dd39cbca":"import statsmodels.tsa.api as smt\nacf = smt.graphics.plot_acf(Residual)","481f4ac9":"df.plot(x='Hours', y='Scores', style='o')","bf2ba4a2":"#Saving model to disk\nimport pickle\nmodel = pickle.dump(regressor,open('model.pkl','wb'))\n\n# loading model\n\nmodel = pickle.load(open('model.pkl','rb'))\nprint(model.predict([[9.25]]))","3368b181":"Now, the next step is to split this data into training and test sets. We'll do this by using Scikit-Learn's built-in train_test_split() method:","ee28c603":"**Data has 25 rows and 2 columns**","a7ddf88f":"**2. Normality of Residuals and Homoscedasticity**","8d5b70f9":"### **2. Training the Model**\nWe have split our data into training and testing sets, and now is finally the time to train our algorithm. ","15696270":"As there is only one feature, there is NO multicollinearity.","6e09ebef":"From the above two plots, we can see that the residuals approximate a normal distribution and the variance is almost constant.","364300a2":"We have already seen that there is a linear relationship between the target variable and the independent variable.","b7f14681":"**1. No MultiCollinearity**","15f74a5d":"### 6. Checking for Assumptions of Linear Regression","a15ae1f7":"**3. No Auto-correlation of Residuals**","86fa1492":"**Predicting for our Own Data:**","06eb2f6f":"The Goal is to Understand how a Machine Learning Algorithm works. In this notebook, we will explore the Given Data set consisting of two columns. We will build a Simple linear Regression Model to predict the Percentage score obtained by a student aaccording to the number of hours they study.","f73106bf":"https:\/\/drive.google.com\/file\/d\/1UQLw61R3B2u3Z8sCNO-mh_NhCWH4Hqqk\/view?usp=sharing","d59fcfc0":"We don't see any Omitted variable Bias in this Model.","33c76e69":"### **1. Preparing the data**\n\nThe next step is to divide the data into Dependent Variable (Target) and Independent variable.","90cc7848":"From the ACF plot it's clear that apart from the first Lag, we don't have any signification autocorrelation between the Residuals.","50efe83a":"### Saving model to Disk","4c17261e":"**Automatic EDA using Pandas Profiling**","1c8fba78":"From the graph above, we can clearly see that there is a positive linear relation between the number of hours studied and percentage scored. In other words, the two variables are highly correlated and the correlation coefficient is Positive.","aeb4fec1":"**5. No endoneity of Residual**","baca599d":"### 5. Using Stats Model to summarize the regression","a810ee76":"**Now, Let's plot our data points on 2-D graph**","a84f2896":"**There are no missing values in the Data**","fd8dfe9c":"### **4. Evaluating the model**\n\nThe final step is to evaluate the performance of algorithm. This step is particularly important to compare how well different algorithms perform on a particular dataset. For simplicity here, we have chosen the mean square error. There are many such metrics.","fa29b7da":"### Author: Rohan Kamble\n","dddb4fb9":"**4. Linear Relationship**","b186ad37":"## **Task 2: To Explore Supervised Machine Learning**","553ff8d1":"**The EDA report can also be found on the following Link:**","0ae5efc5":"### Building the Model : Simple Linear Regression\nIn this regression task we will predict the percentage of marks that a student is expected to score based upon the number of hours they studied. ","1cf9ccef":"**Average study hours is 5.012**","f36dd553":"### **3. Making Predictions**\nNow that we have trained our model, it's time to make some predictions."}}