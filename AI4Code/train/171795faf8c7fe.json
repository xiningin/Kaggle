{"cell_type":{"91e0ecf2":"code","2361986b":"code","83757305":"code","cde4cb01":"code","49a9e439":"code","2a785b28":"code","827deaaf":"code","e6876d89":"code","5e3f5233":"code","ce372a6f":"code","2d211149":"code","bd708357":"code","f843950d":"code","cf2efe97":"code","93019b92":"code","4eb0c3b0":"code","743ed899":"code","50c7d883":"code","e0bf2d7f":"code","422d6b8a":"code","244a7a45":"code","5bd35c13":"code","327f1b8c":"code","2bfd67e3":"code","00f12ae4":"code","78dd1b65":"code","84c524ae":"code","62433a1a":"code","fc7a60a9":"code","823d1f1b":"code","07d34d58":"code","45c1c0f5":"code","a57cf3db":"code","8d427002":"code","871b9139":"code","1b4754f1":"code","702d6478":"code","98d0d8f0":"code","825b1d9d":"code","9cb31e74":"code","f2321620":"code","70625677":"code","3b17d23a":"code","32093f52":"markdown","71fcbe0c":"markdown","6656d34d":"markdown","9ce8ce5b":"markdown","0556410e":"markdown","c72379f7":"markdown","925d827f":"markdown","04e41695":"markdown","4a9d5ea1":"markdown","2ac51736":"markdown","09b84192":"markdown","db17f769":"markdown","9738723a":"markdown","71eb7245":"markdown","e5057e68":"markdown","80543ffb":"markdown","5bdbc842":"markdown","69d2507b":"markdown","30017b5c":"markdown","ee061c82":"markdown","34669736":"markdown","ebac3899":"markdown","ab23ea62":"markdown","0d309e48":"markdown","16051f0e":"markdown","a96020ce":"markdown","b96c345f":"markdown","6ebe5393":"markdown","b956fc0b":"markdown","1a623af1":"markdown"},"source":{"91e0ecf2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt","2361986b":"img = cv2.imread('\/kaggle\/input\/opencv-samples-images\/data\/home.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.figure()\nplt.title(\"Original\")\nplt.imshow(img)","83757305":"print(\"Original photo size:\",img.shape)","cde4cb01":"#Resize\n\nimg_resized = cv2.resize(img,(200,200))\nprint(\"Resized :\",img_resized.shape)\n\nplt.figure()\nplt.title(\"Resized\")\nplt.imshow(img_resized)","49a9e439":"#Crop\n\nimg_cropped = img[:200,:300] # width height -> height width \n\nplt.figure()\nplt.title(\"Cropped\")\nplt.imshow(img_cropped)","2a785b28":"img_empty = np.zeros((512,512,3), np.uint8) # black pic\nprint(img_empty.shape)\nplt.figure()\nplt.title(\"Black Picture\")\nplt.imshow(img_empty)","827deaaf":"#Line\ncv2.line(img_empty, (100,100), (100,300), (0,255,0), 3) # BGR = (0,255,0)\nplt.figure()\nplt.title(\"Line\")\nplt.imshow(img_empty)","e6876d89":"#Rectangle\ncv2.rectangle(img_empty, (0,0), (256,256), (255,0,0), cv2.FILLED)\nplt.figure()\nplt.title(\"Rectangle\")\nplt.imshow(img_empty)","5e3f5233":"#Circle\ncv2.circle(img_empty,(300,300),45,(0,0,255),cv2.FILLED)\nplt.figure()\nplt.title(\"Circle\")\nplt.imshow(img_empty)","ce372a6f":"#Text\ncv2.putText(img_empty,\"HERE\",(350,350),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255))\nplt.figure()\nplt.title(\"Text\")\nplt.imshow(img_empty)","2d211149":"#Horizantal Merge\nimg1 = cv2.imread('\/kaggle\/input\/opencv-samples-images\/data\/messi5.jpg')\nimg1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n\n#They have not same shape therefore we have to resize one of them\nimg1 = cv2.resize(img1,(512,384))\n\nprint(img1.shape)\n\nhor = np.hstack((img,img1))\nplt.figure()\nplt.title(\"Merged\")\nplt.imshow(hor)","bd708357":"#Vertical Merge\nimg1 = cv2.imread('\/kaggle\/input\/opencv-samples-images\/data\/messi5.jpg')\nimg1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n\n#They have not same shape therefore we have to resize one of them\nimg1 = cv2.resize(img1,(512,384))\n\nprint(img1.shape)\n\nhor = np.vstack((img,img1))\nplt.figure()\nplt.title(\"Merged\")\nplt.imshow(hor)","f843950d":"image = cv2.imread('\/kaggle\/input\/opencv-samples-images\/scan.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n \n# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\n \nwarped = cv2.warpPerspective(image, M, (420,594))\n\nplt.subplot(1, 2, 2)\nplt.title(\"warpPerspective\")\nplt.imshow(warped)","cf2efe97":"# Blended Picture = alpha*img1 + beta*img2\nblended = cv2.addWeighted(src1 = img, alpha =0.5, src2= img1, beta = 0.5, gamma = 0)\n\nplt.figure()\nplt.title(\"Blended\")\nplt.imshow(blended)\n","93019b92":"_,thresh_img = cv2.threshold(img,thresh=60,maxval = 255,type = cv2.THRESH_BINARY)\nplt.figure()\nplt.imshow(thresh_img, cmap = \"gray\")\nplt.title(\"Threshold\")\nplt.axis(\"off\")","4eb0c3b0":"\"\"\"thresh_img2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\nplt.figure()\nplt.imshow(thresh_img2, cmap = \"gray\")\nplt.title(\"Adaptive Threshold\")\nplt.axis(\"off\")\"\"\"","743ed899":"img3 = cv2.imread('\/kaggle\/input\/opencv-samples-images\/Background_Subtraction_Tutorial_frame_1.png')\nimg3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\nplt.figure()\nplt.imshow(img3, cmap = \"gray\")\nplt.title(\"Original\")\nplt.axis(\"off\")","50c7d883":"dst2 = cv2.blur(img3,ksize = (3,3))\nplt.figure()\nplt.imshow(dst2, cmap = \"gray\")\nplt.title(\"Average Blur\")\nplt.axis(\"off\")","e0bf2d7f":"gb = cv2.GaussianBlur(img3,ksize=(3,3),sigmaX=7)\nplt.figure()\nplt.imshow(gb, cmap = \"gray\")\nplt.title(\"Gaussian Blur\")\nplt.axis(\"off\")","422d6b8a":"mb = cv2.medianBlur(img3, ksize = 3)\nplt.figure()\nplt.imshow(mb, cmap = \"gray\")\nplt.title(\"Median Blur\")\nplt.axis(\"off\")","244a7a45":"def gaussianNoise(image):\n    row, col, ch = image.shape\n    mean = 0\n    var = 0.05\n    sigma = var**0.5\n    \n    gauss = np.random.normal(mean, sigma, (row,col,ch))\n    gauss = gauss.reshape(row,col,ch)\n    noisy = image + gauss\n    \n    return noisy","5bd35c13":"img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\/255","327f1b8c":"gaussianNoisyImage = gaussianNoise(img3)\ngb2 = cv2.GaussianBlur(gaussianNoisyImage, ksize = (3,3), sigmaX = 7)\n\nhor = np.hstack((gaussianNoisyImage,gb2))\nplt.figure()\nplt.imshow(hor)","2bfd67e3":"def saltPepperNoise(image):\n    row, col, ch = image.shape\n    s_vs_p = 0.5\n    \n    amount = 0.004\n    \n    noisy = np.copy(image)\n    \n    # salt white\n    num_salt = np.ceil(amount * image.size * s_vs_p)\n    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n    noisy[coords] = 1\n    \n    # pepper black\n    num_pepper = np.ceil(amount * image.size * (1 - s_vs_p))\n    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n    noisy[coords] = 0\n    \n    return noisy","00f12ae4":"spImage = saltPepperNoise(img3) \nmb2 = cv2.medianBlur(spImage.astype(np.float32), ksize = 3)\n\nhor = np.hstack((spImage,mb2))\nplt.figure()\nplt.imshow(hor)","78dd1b65":"img4 = cv2.imread('\/kaggle\/input\/opencv-samples-images\/data\/LinuxLogo.jpg',0)\nplt.imshow(img4, cmap = \"gray\")\nplt.title(\"Original\")\nplt.axis(\"off\")","84c524ae":"kernel = np.ones((5,5),dtype = np.uint8)\nresult = cv2.erode(img4,kernel,iterations=1)\nplt.imshow(result, cmap = \"gray\")\nplt.title(\"Erosion\")\nplt.axis(\"off\")","62433a1a":"result2 = cv2.dilate(img4,kernel,iterations=1)\nplt.imshow(result2, cmap = \"gray\")\nplt.title(\"Dilation\")\nplt.axis(\"off\")","fc7a60a9":"white_noise = np.random.randint(0,2,size=img4.shape[:2])\nwhite_noise *= 255\nplt.imshow(white_noise, cmap = \"gray\")\nplt.title(\"White Noise\")\nplt.axis(\"off\")","823d1f1b":"noise_img = img4 + white_noise\nplt.imshow(noise_img, cmap = \"gray\")\nplt.title(\"White Noise Image\")\nplt.axis(\"off\")","07d34d58":"opening = cv2.morphologyEx(noise_img.astype(np.float32),cv2.MORPH_OPEN,kernel)\nplt.imshow(opening, cmap = \"gray\")\nplt.title(\"Opening\")\nplt.axis(\"off\")","45c1c0f5":"black_noise = np.random.randint(0,2,size=img4.shape[:2])\nblack_noise *= -255\nplt.imshow(black_noise, cmap = \"gray\")\nplt.title(\"Black Noise\")\nplt.axis(\"off\")","a57cf3db":"black_noise_img = black_noise + img4\nblack_noise_img[black_noise_img <= -245] = 0\nplt.imshow(black_noise_img, cmap = \"gray\")\nplt.title(\"Black Noise Image\")\nplt.axis(\"off\")","8d427002":"closing = cv2.morphologyEx(black_noise_img.astype(np.float32),cv2.MORPH_CLOSE,kernel)\nplt.imshow(closing, cmap = \"gray\")\nplt.title(\"Closing Image\")\nplt.axis(\"off\")","871b9139":"gradient = cv2.morphologyEx(img4,cv2.MORPH_GRADIENT,kernel)\nplt.imshow(gradient, cmap = \"gray\")\nplt.title(\"Gradient Image\")\nplt.axis(\"off\")","1b4754f1":"img5 = cv2.imread('\/kaggle\/input\/opencv-samples-images\/data\/sudoku.png',0)\nplt.imshow(img5, cmap = \"gray\")\nplt.title(\"Original\")\nplt.axis(\"off\")","702d6478":"sobelx = cv2.Sobel(img5,ddepth=cv2.CV_16S,dx=1,dy=0,ksize=5)\nplt.imshow(sobelx, cmap = \"gray\")\nplt.title(\"Sobel X\")\nplt.axis(\"off\")","98d0d8f0":"sobely = cv2.Sobel(img5,ddepth=cv2.CV_16S,dx=0,dy=1,ksize=5)\nplt.imshow(sobely, cmap = \"gray\")\nplt.title(\"Sobel Y\")\nplt.axis(\"off\")","825b1d9d":"laplacian = cv2.Laplacian(img5, ddepth = cv2.CV_16S)\nplt.imshow(laplacian, cmap = \"gray\")\nplt.axis(\"off\")","9cb31e74":"img6 = cv2.imread('\/kaggle\/input\/opencv-samples-images\/data\/WindowsLogo.jpg')\nimg6 = cv2.cvtColor(img6,cv2.COLOR_BGR2RGB)\nplt.imshow(img6, cmap = \"gray\")\nplt.title(\"Original\")\nplt.axis(\"off\")\nprint(\"Shape:\",img6.shape)","f2321620":"mask = np.zeros(img6.shape[:2],np.uint8)\nmask[50:185,81:241] = 255\nplt.imshow(mask, cmap = \"gray\")\nplt.title(\"Mask\")\nplt.axis(\"off\")","70625677":"masked_img = cv2.bitwise_and(img6,img6,mask=mask)\nplt.imshow(masked_img, cmap = \"gray\")\nplt.title(\"Masked Image\")\nplt.axis(\"off\")","3b17d23a":"masked_img_his = cv2.calcHist([img6],channels=[2],mask = mask,histSize=[256],ranges=[0,256]) # for green\nplt.figure()\nplt.plot(masked_img_his)","32093f52":"* Add Gaussian Noise","71fcbe0c":"# SHAPE AND TEXT","6656d34d":"* Let's add some black noise as the booting is effective on black noise","9ce8ce5b":"3. Opening","0556410e":"* Median Blur","c72379f7":"* Average Blur","925d827f":"* Adaptive Threshold","04e41695":"# BLENDING","4a9d5ea1":"5. Morphological Gradient","2ac51736":"* X Gradient","09b84192":"* Both Of Them","db17f769":"* Now we destroy noises with opening","9738723a":"# MERGE P\u0130CS","71eb7245":"# RES\u0130ZE CROP\n","e5057e68":"* Let's Create a Mask","80543ffb":"* Add Salt Pepper Noise","5bdbc842":"* Y Gradient","69d2507b":"# MORPHOLOG\u0130CAL OPERATIONS","30017b5c":"* We can not see much changes.Because we have not noise\n* Let's create some noise","ee061c82":"# GRADIENTS","34669736":"**1. Erosion**","ebac3899":"4. CLose","ab23ea62":"# HISTOGRAMS","0d309e48":"# BLURR\u0130NG","16051f0e":"* Let's add some white noise as the booting is effective on white noise","a96020ce":"* Threshold","b96c345f":"2. Dilation","6ebe5393":"* For accuracy ,Normalization","b956fc0b":"* Gaussian Blur","1a623af1":"# WARP PERSPECT\u0130VE"}}