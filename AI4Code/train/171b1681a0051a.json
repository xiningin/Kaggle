{"cell_type":{"2b79f48c":"code","bdff58a1":"code","8b74334e":"code","cabc64b6":"code","fd24ea32":"code","b0884204":"code","e57e4198":"code","21125c5b":"code","76af9f4b":"code","b49b7090":"code","b408b4f1":"code","2d3b5e49":"code","03f982c3":"code","311c5ec5":"code","d20f54a4":"code","aff43c1e":"code","f6e1e25b":"code","dd81d00d":"code","e2eda3df":"code","656ebf2a":"code","81bab07e":"code","38bebd06":"code","2e29dc25":"code","c28ed47b":"code","410171e4":"code","9db29fbd":"code","45922044":"code","9f3be67d":"code","b8950849":"code","09f77250":"code","1ec235ae":"code","fa0719e2":"code","c1941736":"code","b55d4f77":"markdown","699cdfd0":"markdown","385e89e3":"markdown","8813e121":"markdown","1954c8fa":"markdown","eccf01c9":"markdown","298c0c4a":"markdown"},"source":{"2b79f48c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sb\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score\nimport seaborn as sns\nimport tensorflow as tf","bdff58a1":"# Reading data\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","8b74334e":"train.head()","cabc64b6":"test.head()","fd24ea32":"print('Train data size',train.shape)\nprint('Test data size',test.shape)\n\nprint(train['Survived'].value_counts(),'\\n')\nprint(Counter(train['Sex']),'\\n')\nprint(train['SibSp'].value_counts(),'\\n')\nprint(train['Parch'].value_counts(),'\\n')\nprint(train['Embarked'].value_counts(),'\\n')","b0884204":"rcParams['figure.figsize'] = 10,5\nsb.barplot(x = train['Survived'].value_counts().index, y = train['Survived'].value_counts().values)\nplt.title('Survival counts')\nplt.xlabel('Survived')\nplt.ylabel('No of passengers')\nplt.show()","e57e4198":"gender = pd.crosstab(train['Survived'],train['Sex'])\ngender.plot(kind=\"bar\",title='No of passengers survived')\nplt.show()","21125c5b":"rcParams['figure.figsize'] = 10,5\nax = train['Age'].hist(bins = 15,alpha = 0.9, color = 'green')\nax.set(xlabel = 'Age',ylabel = 'Count',title = 'Visualization of Ages')\nplt.show()","76af9f4b":"rcParams['figure.figsize'] = 10,10\nsb.heatmap(train.corr(),annot = True,square = True,linewidths = 2,linecolor = 'black')","b49b7090":"y = train[\"Survived\"]\n\n# getting dummy variables column\n\nenc = LabelEncoder()\n\ntrain['Sex'] = enc.fit_transform(train['Sex'])\ntest['Sex'] = enc.fit_transform(test['Sex'])\n\ntrain['Name'] = enc.fit_transform(train['Name'])\ntest['Name'] = enc.fit_transform(test['Name'])\n\ntrain['Cabin'] = enc.fit_transform(train['Cabin'].astype('str'))\ntest['Cabin'] = enc.fit_transform(test['Cabin'].astype('str'))\n\ntrain['Embarked'] = enc.fit_transform(train['Embarked'].astype('str'))\ntest['Embarked'] = enc.fit_transform(test['Embarked'].astype('str'))\n\ntrain['Ticket'] = enc.fit_transform(train['Ticket'].astype('category'))\ntest['Ticket'] = enc.fit_transform(test['Ticket'].astype('category'))\n \nX = train\ntest_X = test","b408b4f1":"X.set_index(['PassengerId'],inplace = True)\ntest_X.set_index(['PassengerId'],inplace = True)\nX = X.drop(['Survived'], axis=1)","2d3b5e49":"X.tail()","03f982c3":"test_X.head()","311c5ec5":"print(X.isnull().sum(),'\\n')\nprint(test_X.isnull().sum())","d20f54a4":"X.fillna(X.median(), inplace=True)\ntest_X.fillna(test_X.mean(), inplace=True)\nprint(X.isnull().sum(),'\\n')\nprint(test_X.isnull().sum())","aff43c1e":"#Normalizing\n\nfrom sklearn.preprocessing import normalize\n\nX = normalize(X)\ntest_X = normalize(test_X)","f6e1e25b":"print(\"Logistic Regression:\", cross_val_score(LogisticRegression(), X, y).mean())\n\nprint(\"SVC:\", cross_val_score(SVC(), X, y).mean())\n\nprint(\"Random Forest:\", cross_val_score(RandomForestClassifier(), X, y).mean())\n\nprint(\"GaussianNB:\", cross_val_score(GaussianNB(), X, y).mean())\n\nprint(\"Decision Tree:\", cross_val_score(DecisionTreeClassifier(), X, y).mean())\n\nprint(\"KNeighbors:\", cross_val_score(KNeighborsClassifier(), X, y).mean())\n\nprint(\"MLP:\", cross_val_score(MLPClassifier(), X, y).mean())\n\nprint(\"XGB-TREE:\", cross_val_score(XGBClassifier(booster='gbtree'), X, y).mean())\n\nprint(\"XGB-DART:\", cross_val_score(XGBClassifier(booster='dart'), X, y).mean())","dd81d00d":"# fit the model on the whole dataset\nmodel_RF = RandomForestClassifier()\n\nmodel_RF.fit(X, y)","e2eda3df":"y_pred = model_RF.predict(test_X)","656ebf2a":"test_X","81bab07e":"# #K Fold Cross Validation\n\n# from sklearn.model_selection import KFold\n\n\n# kf = KFold(n_splits=5, random_state=42, shuffle=True)\n\n# for train_index, val_index in kf.split(X):\n#     print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n#     X_train, X_val = X[train_index], X[val_index]\n#     y_train, y_val = y[train_index], y[val_index]","38bebd06":"# print(X_train.shape)\n# print(y_train.shape)\n# print(X_val.shape)\n# print(y_val.shape)\n\n# #reshape for rnn\n\n# X_train = X_train.reshape(-1, 1, 10)\n# X_val  = X_val.reshape(-1, 1, 10)\n# y_train = y_train.values #convert pd to array\n# y_train = y_train.reshape(-1, 1,)\n# y_val = y_val.values #convert pd to array\n# y_val = y_val.reshape(-1, 1,)\n\n# print(X_train.shape)\n# print(y_train.shape)\n# print(X_val.shape)\n# print(y_val.shape)","2e29dc25":"# from tensorflow.keras.layers import Conv2D,LSTM,LeakyReLU, MaxPooling2D,Concatenate,Input, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\n# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n# from tensorflow.keras.models import Model\n\n\n# # create model\n    \n\n# #input \n# input_layer = Input(shape=(1,10))\n# main_rnn_layer = LSTM(1024, return_sequences=True, recurrent_dropout=0.9)(input_layer)\n\n    \n# #output\n# rnn = LSTM(1024)(main_rnn_layer)\n# dense = Dense(512)(rnn)\n# dropout_c = Dropout(0.8)(dense)\n# dense = Dense(265)(dropout_c)\n# dropout_c = Dropout(0.5)(dense)\n# dense = Dense(128)(dropout_c)\n# dropout_c = Dropout(0.3)(dense)\n\n# classes = Dense(1, activation= LeakyReLU(alpha=0.1),name=\"class\")(dropout_c)\n\n# model = Model(input_layer, classes)\n\n# # Compile model\n# callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n#              EarlyStopping(monitor='val_loss', patience=20),\n#              ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n# model.compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")\n\n# model.summary()\n# # Fit the model\n# history = model.fit(X_train, y_train, \n#           epochs = 1000, \n#           batch_size = 128, \n#           validation_data=(X_val,  y_val), \n#           callbacks=callbacks)","c28ed47b":"# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('Loss over epochs')\n# plt.ylabel('Loss')\n# plt.xlabel('Epoch')\n# plt.legend(['Train', 'Validation'], loc='best')\n# plt.show()","410171e4":"# test_X.shape\n\n# test_X = test_X.reshape(-1, 1,10)","9db29fbd":"# test_predict = np.where(test_predict > 0.5, 1, 0)","45922044":"test_predict = pd.Series(y_pred)","9f3be67d":"test.reset_index(inplace = True)\ntest.head()","b8950849":"predict = test['PassengerId']","09f77250":"predict = pd.concat([predict,test_predict], axis=1)","1ec235ae":"predict.rename(columns={0: \"Survived\"},inplace=True)","fa0719e2":"predict.to_csv(\"submission.csv\",index=False)","c1941736":"predict","b55d4f77":"Read Data","699cdfd0":"2- RNN model","385e89e3":"Data Preparation","8813e121":"1- basic models:","1954c8fa":"Modeling","eccf01c9":"![](http:\/\/)I will use Random Forest","298c0c4a":"there is missing data in age"}}