{"cell_type":{"24d5a676":"code","c779b2dc":"code","a242afc0":"code","c511f481":"code","9baff746":"code","8ffc09f1":"code","81e9ba25":"code","dbd86b4a":"code","e7b08f86":"code","2363ecd7":"code","9cfddc99":"code","7cdd8126":"code","b83ea4a9":"code","29ca5ae1":"code","7199d07e":"code","fda7a881":"code","b407418d":"code","1d76f75f":"code","bddfb99c":"code","2715720b":"code","9acfb4f2":"code","f26d29d5":"code","5b838a95":"code","3595b3e5":"code","fcee15ad":"code","732e2e97":"code","f0e232de":"code","7299e1ca":"code","105e1f06":"code","0710670a":"code","f507d983":"code","6a7f7d37":"code","fc5b10de":"code","a76c0f28":"code","43c3df9c":"code","c18ca207":"code","f810a0cb":"code","7e1b6e75":"code","8d65bddd":"code","cc38baeb":"code","fd05e61f":"code","01f45362":"code","3ad7586c":"code","bfe61f4a":"code","de26a6f3":"code","12d5f596":"code","3f73e836":"code","4bcf1c8b":"code","d8890265":"code","85d1fe66":"code","76f8ce33":"code","13a41d62":"code","b604f38f":"code","f4f2b2ed":"code","5e3b7928":"code","75be2be1":"code","26f368a0":"code","c141ad58":"code","9606784b":"code","fbb1a19f":"markdown","6d8d0930":"markdown","61da7260":"markdown","ca945f54":"markdown","348bef9f":"markdown","bfc203e8":"markdown","43b8dee1":"markdown","e527a278":"markdown","ad8227fd":"markdown","6275ef77":"markdown","b7b3faa5":"markdown","7a8d5df0":"markdown","067b1386":"markdown","d5e0fd3a":"markdown","2d72a50c":"markdown","307caf13":"markdown","64c2095e":"markdown","665beba5":"markdown","16f08617":"markdown","d625adb8":"markdown","457d4015":"markdown","7881e117":"markdown","569ad59b":"markdown","b9259c5b":"markdown","dfa2f83b":"markdown","f0efba74":"markdown","1bc731b6":"markdown","61b23a0e":"markdown","b81cd8e8":"markdown","735855d3":"markdown","ac789340":"markdown","1178743a":"markdown","59be0b5e":"markdown","68e1ade9":"markdown","1209bee1":"markdown","43fd5b1c":"markdown","acdb63e4":"markdown","0851efcd":"markdown","8b78f971":"markdown","619a85ae":"markdown","05d46ab9":"markdown","d664e1df":"markdown","4ec44c51":"markdown","f1705dc4":"markdown","414b8f48":"markdown","68ac0a3f":"markdown","c8568bb8":"markdown","26f9b3b4":"markdown"},"source":{"24d5a676":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c779b2dc":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn import metrics   #Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt","a242afc0":"train = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/test.csv')","c511f481":"train.head()","9baff746":"df = train.copy()","8ffc09f1":"df.info()","81e9ba25":"df.describe()","dbd86b4a":"df.isnull().sum()","e7b08f86":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,8))\nsns.countplot(x = 'Gender', hue = 'Vehicle_Damage', data=df)","2363ecd7":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Vehicle_Age', hue = 'Vehicle_Damage', data=df)","9cfddc99":"plt.figure(figsize=(12,8))\nprint(df['Age'].value_counts()[:5])\nsns.distplot(df.Age, color='darkred')","7cdd8126":"print(f\"Youngest Customer's age : {df['Age'].min()}\")\nprint(f\"Oldest Customer's age : {df['Age'].max()}\")","b83ea4a9":"pd.set_option('display.max_rows', None)\nage_range = pd.DataFrame(df['Age'].value_counts())\nage_range","29ca5ae1":"bins = [18, 30, 40, 50, 60, 70, 120]\nlabels = ['18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ndf['Age_Range'] = pd.cut(df.Age, bins, labels = labels,include_lowest = True)","7199d07e":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Age_Range', hue = 'Vehicle_Damage', data=df)","fda7a881":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Gender', hue = 'Response', data=df)","b407418d":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Gender', hue = 'Previously_Insured', data=df)","1d76f75f":"df['Driving_License'].value_counts()","bddfb99c":"plt.figure(figsize=(24,8))\nsns.countplot(x = 'Region_Code', hue = 'Vehicle_Damage', data=df)","2715720b":"plt.figure(figsize=(24,8))\nsns.countplot(x = 'Region_Code', hue = 'Response', data=df)","9acfb4f2":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Previously_Insured', hue = 'Response', data=df)","f26d29d5":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Age_Range', hue = 'Response', data=df)","5b838a95":"print(df['Annual_Premium'].value_counts().head(15))\nplt.figure(figsize=(12,8))\nsns.distplot(df['Annual_Premium'])","3595b3e5":"plt.figure(figsize=(12,8))\nsns.countplot(x = 'Vehicle_Age',data=df)","fcee15ad":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(), annot=True)","732e2e97":"df.corr()['Response']","f0e232de":"df.info()","7299e1ca":"df['Vehicle_Age'].value_counts()","105e1f06":"df=pd.concat([df,pd.get_dummies(df['Vehicle_Damage'],prefix='Vehicle_Damage')],axis=1).drop(['Vehicle_Damage'],axis=1)","0710670a":"df.head()","f507d983":"df=pd.concat([df,pd.get_dummies(df['Gender'],prefix='Gender')],axis=1).drop(['Gender'],axis=1)","6a7f7d37":"df.head()","fc5b10de":"df.drop(['Vehicle_Damage_No','Gender_Female'], axis=1, inplace=True)\ndf.head()","a76c0f28":"df['Vehicle_Age'] = pd.Categorical(df['Vehicle_Age'].values).codes\ndf['Age_Range'] = pd.Categorical(df['Age_Range'].values).codes\ndf.head()","43c3df9c":"df.info()","c18ca207":"df.shape","f810a0cb":"X = df.drop(['Response','id', 'Age_Range'], axis=1)\ny = df['Response']","7e1b6e75":"scaler = MinMaxScaler()\nscaled_X = scaler.fit_transform(X)\nscaled_X = pd.DataFrame(scaled_X)\nscaled_X.columns = X.columns\nscaled_X.head()","8d65bddd":"print(y.value_counts())\ny.value_counts().plot(kind='bar')","cc38baeb":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\nprint('Original dataset shape %s' % Counter(y))\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(scaled_X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","fd05e61f":"X_res = pd.DataFrame(X_res)\ny_res = pd.Series(y_res)\nX_res.columns = scaled_X.columns\nX_res.head()","01f45362":"print(y_res.value_counts())\ny_res.value_counts().plot(kind='bar')","3ad7586c":"X_res.shape","bfe61f4a":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.3, random_state = 42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","de26a6f3":"np.random.seed(42)\nxgb1 = XGBClassifier(learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1,\ngamma=0,subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic',nthread=4,\nscale_pos_weight=1,seed=27)\nxgb1.fit(X_train, y_train)","12d5f596":"np.random.seed(42)\netc = ExtraTreesClassifier(n_estimators=200).fit(X_train, y_train)\nprint(etc.score(X_test, y_test))\netc_pred = etc.predict(X_test)\nprint(classification_report(etc_pred, y_test))","3f73e836":"np.random.seed(42)\nrf = RandomForestClassifier(n_estimators=200).fit(X_train, y_train)\nprint(rf.score(X_test, y_test))\nrf_pred = rf.predict(X_test)\nprint(classification_report(rf_pred, y_test))","4bcf1c8b":"print(f\"ROC_AUC Score of XGBoost Classifier is : {metrics.roc_auc_score(xgb1.predict(X_test), y_test)}\")\nprint(f\"ROC_AUC Score of RandomForestClassifier is : {metrics.roc_auc_score(rf.predict(X_test), y_test)}\")\nprint(f\"ROC_AUC Score of ExtraTreesClassifier is : {metrics.roc_auc_score(etc.predict(X_test), y_test)}\")","d8890265":"test.head()","85d1fe66":"t_copy = test.copy()","76f8ce33":"t_copy.head()","13a41d62":"t_copy=pd.concat([t_copy,pd.get_dummies(t_copy['Gender'],prefix='Gender')],axis=1).drop(['Gender'],axis=1)\nt_copy=pd.concat([t_copy,pd.get_dummies(t_copy['Vehicle_Damage'],prefix='Vehicle_Damage')],axis=1).drop(['Vehicle_Damage'],axis=1)","b604f38f":"t_copy.head()","f4f2b2ed":"t_copy['Vehicle_Age'] = pd.Categorical(t_copy['Vehicle_Age'].values).codes\nt_copy.head()","5e3b7928":"X_train.columns","75be2be1":"t_copy.columns","26f368a0":"t_copy.drop(['id','Vehicle_Damage_No','Gender_Female'], axis=1, inplace=True)","c141ad58":"scaled_test = scaler.transform(t_copy)\nscaled_test = pd.DataFrame(scaled_test)\nscaled_test.columns = t_copy.columns\nscaled_test.head()","9606784b":"pred = etc.predict(scaled_test)\nf_pred = pd.concat([pd.DataFrame(test['id']),pd.DataFrame(pred)], axis=1)\nf_pred.columns = ['id','Response'] \nf_pred.head()\nf_pred.to_csv('Submission.csv')","fbb1a19f":"Now lets take a look at the data.","6d8d0930":"It looks like more men don't have insurance.","61da7260":"It looks like area with region code 28.0 has the most vehicle damage cases.\n\nNow lets compare `Region_Code` with `Response`.","ca945f54":"Now implementing SMOTE results in significant increase in the data points.\nLets check the shape of the data.","348bef9f":"1-2 years old vehicles are prone to damage more than vehicles that are <1 year and >2 years old.","bfc203e8":"## Modelling\n\nNow that all the features are numerical, lets build some ML models.","43b8dee1":"Lets now take a look at `Driving_License` column","e527a278":"As we can see that now the datapoints are 668798, almost double the size of our original number of datapoints.\n\nAnyway, lets now build models on this data.\n\nWe also don't need the feature `Age_Range`, as it gives the same information as `Age`, so lets drop it.","ad8227fd":"Looking at the `Region_Code`...","6275ef77":"Lets first deal with the categorical data..","b7b3faa5":"You can play around with different parameters, or tune them as you wish.\nI've used them because they seemed to work for me.","7a8d5df0":"While 380297 customers have driving license, 812 don't.","067b1386":"Now that we've created dummy variable for `Vehicle_Damage` feature, lets do the same for `Gender` feature.","d5e0fd3a":"It seems like males are more interested in insurance than females.","2d72a50c":"Of all the models, ExtraTreesClassifier has better `roc_auc_score`. So lets consider that as our final model.\n\nBut before making predictions on the test set, we must remember that we created an additional feature called `Age_Range` using `Age` column.\n\nWe have to drop one of them, so that the model is more robust.\n\nThis may result in the drop of ROC_AUC_score, but it makes our model robust.","307caf13":"Creating dummy variables.","64c2095e":"Dropping `id,Vehicle_Damage_No,Gender_Female`, to avoid dummy variable trap.","665beba5":"It doesn't seem like any features are highly correlated.\n\nLets look for columns that correlated to the target variable.","16f08617":"Interesting, looks like the probability of `Vehicle_Damage` was more with the customers of 40-49 age group.","d625adb8":"Now lets compare `Gender` and `Response` variable.","457d4015":"Target variable is highly imbalanced. This will definitely result in poor results in the class with lower value counts.\nLets balance it using `SMOTE`.","7881e117":"Before start building models, lets check if the target variable is balanced.","569ad59b":"Most vehicles are 1-2 years old.","b9259c5b":"`Age` is somewhat correlated to the target feature, but the correlation is not much.","dfa2f83b":"Can you notice what's wrong here?.\n\nYes!, while creating dummy variables, we created extra features which represent the same thing. This is called dummy variable trap.\n\nSo lets drop any 2 of the 4 dummy variables created. ","f0efba74":"Now lets check if there are missing values.","1bc731b6":"## Predictions\nNow lets make predictions on the test data.","61b23a0e":"It looks like most common age is 24, with around 25,960 customers lying in that age.\n\nLets also look at the age range.","b81cd8e8":"Lets now look at correlation of features.","735855d3":"Before we go further and perform EDA, data wrangling lets make a copy of the original data and then look at the stats of the data.","ac789340":"Lets see how many customers are the oldest (85 years old) and youngest(20 years old)","1178743a":"Now lets compare `Age_Range` and `Vehicle_Damage` and see how they correlate.","59be0b5e":"There are about 3 `objects`, which have to converted into numerical format. \nSo lets do that.\nBut before that lets take a look at those 3 features.\n\n`Gender` - Has 2 classes, `Male, Female`. Here we can use `pd.get_dummies()`.\n\n`Vehicle_Age` - Has 3 classes, `1-2 Year, < 1 Year, > 2 Years`. Now this is ordinal data, so the best way to convert this feature into number would be to use `Label Encoding'.\n\n`Vehicle_Damage` - Has 2 classes, `Yes, No`. Similar to `Gender`, we can use `pd.get_dummies()`.\n\nLets do that.\n\nNote - We only use `Label Encoding` when the feature is ordinal. We can also use Label Encoder. But in case the feature isn't ordinal and is instead nominal, go ahead and use either `pd.get_dummies()` or `OneHotEncoder`.","68e1ade9":"It seems that, customers in the age group 40-49 are the ones that are most interested in getting the insurance.","1209bee1":"Now lets take a look at the `Age` column.","43fd5b1c":"If you look carefully, some customers who are not insured, are still not interested in getting the insurance.","acdb63e4":"Before we build models, lets first normalize the data.","0851efcd":"There are 6232 customers, who are 20 years old, whereas there 11 customers who are 85 years old.\n\nLets now create a new column which is binned version of the `Age` column, which helps us understand the data more.","8b78f971":"Now we still have to convert feature `Vehicle_Age`, and since it's a ordinal feature,lets use `pd.categorical()`.","619a85ae":"## Importing other necessary libraries.\n","05d46ab9":"Interesting, looks like vehicles owned by `Male`, tend to have more damage, compared to `Female`.","d664e1df":"## EDA and Feature Engineering.\n","4ec44c51":"Our target variable is now balanced.","f1705dc4":"And obviously, that is the region where the most customers are interested in getting the insurance.","414b8f48":"Now lets look at different data types we're dealing with in this case..","68ac0a3f":"Scaling the test data..","c8568bb8":"## Loading the datasets.","26f9b3b4":"It seems that most common annual premium is 2630.0 with 64877 customers opting out for it."}}