{"cell_type":{"758d953f":"code","b767e266":"code","e2408f7d":"code","b60350ce":"code","e0349379":"code","cbd3c52a":"code","35227004":"code","237725f5":"code","efebfc8c":"code","e75cc9df":"markdown","b6febfac":"markdown","55557137":"markdown","52a9ac7d":"markdown","28ecd1c5":"markdown","fcfbf48d":"markdown"},"source":{"758d953f":"# importing all necessary libraries to run the code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk import NaiveBayesClassifier\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem import PorterStemmer\nimport re\n# using the variable sw to hold all stopwords that are in English\nsw = stopwords.words('english')","b767e266":"# reading csv file with the data for analyse\nds = pd.read_csv('..\/input\/googleplaystore_user_reviews.csv')","e2408f7d":"# checking to see how the data are formatted\nds.head()","b60350ce":"# the method info of a dataframe shows us the number of null coluns of our data\nds.info()","e0349379":"# Number of elements before removing the NaN values\nprint('Size before removing Nan: %s'% len(ds))\n\n# Number of elements after removing the NaN values\nds.dropna(axis=0, inplace=True)\nprint('Size before removing Nan: %s'% len(ds))","cbd3c52a":"def cleaning_data(data):\n    aux_list = []\n    flag = False\n    for phase_word in data:\n        word_list = []\n        for word in phase_word.split():\n            word = word.lower()\n            if flag and not word in sw:\n                flag = False\n                word_list.append('not_'+word)\n                continue\n            if re.search('(n\\'t)$|(not)|(no)|(never)', word):\n                flag = True\n                continue\n            if not word in sw:\n                word = re.sub('[\\W_0-9]', ' ', word)\n                word_list.append(word)\n        aux_list.append(' '.join(word_list))\n    return aux_list","35227004":"X = cleaning_data(ds['Translated_Review'])\ny = ds['Sentiment']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","237725f5":"# This CountVectorizer is used to represent the words as a list of values, instead of text\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\n\nvectorizer.fit(X)\nX_train = vectorizer.transform(X_train)\nX_test = vectorizer.transform(X_test)\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(y)\ny_train = le.transform(y_train)\ny_test = le.transform(y_test)","efebfc8c":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(units=100, activation='relu', input_dim=len(vectorizer.get_feature_names())))\nmodel.add(Dense(units=3, activation='sigmoid'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, \n          epochs=2, verbose=1)\nscores = model.evaluate(X_test, y_test, verbose=1)\nprint(\"Accuracy:\", scores[1])","e75cc9df":"The keras library was used to create a NN. The NN uses the relu as activation function in the hidden layer and the sigmoid in the output layer. ","b6febfac":"This function was used to clean the data. The stopwords were removed from the data since it also does not add too much to the analysis. To detect the words that have negative meaning was used a regex. This regex find the words ends in \"n't\" or is the word \"not\" or \"no\" or \"never\". More words can be add later and it may increase the result. When this words are found, the next word will have a \"not_\" before the word. <br>\nI.E: <lo> <li><b>Input:<\/b> 'This app is not good' <br> <\/li>\n     <li><b>Output:<\/b> ['app', 'not_good'] <\/li> <\/lo> <br>\nThis is the return of the cleaning_data function to the input given above","55557137":"The result of the analysis can be seen above, the NN created was capable of predict correctly about 92% of the test cases.","52a9ac7d":"After removing the null values, let's split the data in, training and test case, so we can train our model and test to check the model accuracy.","28ecd1c5":"It is possible to realize that the data have NaN values, so we need to remove them, since this data will not add anything to our analysis. We are trying to predict the Sentiment of a person, based on their app review. So, the columns 'Translated_Review' and 'Sentiment' will be used to get our result.","fcfbf48d":"To use a NN is necessary to apply an label encode in the output. Since the output is 'Positive','Neutral' or 'Negative' with the enconder applied the result is 0,1 or 2"}}