{"cell_type":{"b1f7cac5":"code","659a190e":"code","68fb642c":"code","980d7009":"code","08a0363c":"code","878d6eae":"code","44767fa7":"code","47a2861a":"code","4b4a6dfa":"code","5efb6236":"code","8227f5ab":"code","3779aca0":"code","ca2000ec":"code","d4bbc9b5":"code","5b343b9c":"code","608c88b8":"code","17ba8e7c":"code","c95a92f5":"code","3105d22c":"code","53fe3eae":"code","aa5a9881":"code","e772b1c0":"code","31c4c38a":"code","04b46614":"code","fb2295ae":"code","5ea854b5":"code","0e157677":"code","dd17453c":"code","7e586c93":"code","ad715a1c":"code","5d0e4b14":"code","5bf5daa5":"markdown","4ffd287e":"markdown","2d42fd7d":"markdown","46ce9522":"markdown","4bc0305f":"markdown","b012f20c":"markdown","5d5ebaf1":"markdown","b99f6b30":"markdown","41930d89":"markdown","0c3c8d10":"markdown","953a5be3":"markdown","ae20603c":"markdown","9501bb08":"markdown","f95abc1f":"markdown","cbd7c3e1":"markdown","2be04b59":"markdown","89a5b8ea":"markdown","576a700b":"markdown","c2bc6bfe":"markdown","159f93dd":"markdown","7d5b4fb0":"markdown","39377d18":"markdown","73ed2862":"markdown","23f45da8":"markdown","75d7748f":"markdown","8c3d3540":"markdown","5ad0c823":"markdown","f0a79283":"markdown","54e11512":"markdown","a20d212c":"markdown","66af0927":"markdown","4db4779d":"markdown","8f35ec43":"markdown","641bec42":"markdown","120e037f":"markdown"},"source":{"b1f7cac5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.impute import KNNImputer\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# displays all the columns\npd.set_option('display.max_columns', None)\nplt.rcParams[\"figure.figsize\"] = (18, 8);","659a190e":"df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf.head()","68fb642c":"df.shape","980d7009":"df.info()","08a0363c":"feature_cols = [col for col in df.columns if col not in ['SalePrice']]\ntarget_cols = ['SalePrice']\n\ncat_cols = [col for col in feature_cols if df[col].dtype == 'O']\ncont_cols = [col for col in feature_cols if col not in cat_cols]","878d6eae":"sns.heatmap(df.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","44767fa7":"def encode_missing_columns(df, col):\n    le = LabelEncoder()\n    \n    # gets unique values w\/o NaN\n    unique_without_nan = pd.Series([i for i in df[col].unique() if type(i) == str])\n    le.fit(unique_without_nan) # Fit on unique values\n    \n    # Set transformed col leaving np.NaN as they are\n    df[col] = df[col].apply(lambda x: le.transform([x])[0] if type(x) == str else x)","47a2861a":"demo_col = pd.Series(['apple', 'mango', 'banana', 'apple', 'banana', np.NaN])\nprint(f'Unique Values in the Column: {demo_col.unique()}')\nprint(f'Unique Values of type string: {[i for i in demo_col.unique() if type(i) == str]}')","4b4a6dfa":"le = LabelEncoder()\nunique_without_nan = pd.Series([i for i in demo_col.unique() if type(i) == str])\nle.fit(unique_without_nan)\ndemo_col.apply(lambda x: le.transform([x])[0] if type(x) == str else x)","5efb6236":"sum(df.isna().sum(axis=1) > 0)","8227f5ab":"sum(df.isna().sum(axis=0) > 0)","3779aca0":"df_simple_imputer = df.copy()","ca2000ec":"imputer = SimpleImputer(strategy='mean')\n\ndf_simple_imputer[cont_cols] = imputer.fit_transform(df_simple_imputer[cont_cols])","d4bbc9b5":"imputer = SimpleImputer(strategy='most_frequent')\n\ndf_simple_imputer[cat_cols] = imputer.fit_transform(df_simple_imputer[cat_cols])","5b343b9c":"sns.heatmap(df_simple_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","608c88b8":"df_knn_imputer = df.copy()","17ba8e7c":"for col in cat_cols:\n    encode_missing_columns(df_knn_imputer, col)","c95a92f5":"knn_imputer = KNNImputer(n_neighbors=5)\n\ndf_knn_imputer[feature_cols] = knn_imputer.fit_transform(df_knn_imputer[feature_cols])","3105d22c":"sns.heatmap(df_knn_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","53fe3eae":"df_iterative_imputer = df.copy()","aa5a9881":"for col in cat_cols:\n    encode_missing_columns(df_iterative_imputer, col)","e772b1c0":"itr_imputer = IterativeImputer()\n\ndf_iterative_imputer[feature_cols] = itr_imputer.fit_transform(df_iterative_imputer[feature_cols])","31c4c38a":"sns.heatmap(df_iterative_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=df.columns);","04b46614":"from sklearn.impute import MissingIndicator","fb2295ae":"df_miss = df.copy()","5ea854b5":"miss_indicator = MissingIndicator()\n\nX_miss = miss_indicator.fit_transform(df_miss[feature_cols])","0e157677":"X_miss.shape","dd17453c":"df_miss_itr = df.copy()","7e586c93":"for col in cat_cols:\n    encode_missing_columns(df_miss_itr, col)","ad715a1c":"# setting add_indicator=True returns missing indicators alongwith the imputed dataframe\nitr_imputer = IterativeImputer(add_indicator=True) \n\nX = itr_imputer.fit_transform(df_miss_itr[feature_cols])","5d0e4b14":"X.shape","5bf5daa5":"<a id = '2.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">2.1 Dropping Rows with Missing Values<\/h2>","4ffd287e":"<a id = '3.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.1 Univariate Imputation<\/h2>","2d42fd7d":"Let's take an example to understand what this function is doing <br>\nSuppose we have a column `['apple', 'mango', 'banana', 'apple', 'banana', NaN]`","46ce9522":"<a id = '5'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 5. Missing Indicator + Iterative Imputer <\/h2>","4bc0305f":"<a id = '4'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 4. Missing Indicator <\/h2>","b012f20c":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We have 99 feature columns now (80 original features + 19 missing indicator features) and 1 target column<\/span>","5d5ebaf1":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">This isn't an imputation technique, but this might be the first thing that comes in mind to deal with missing values<\/span>","b99f6b30":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Like KNNImputer, Iterative Imputer also doesn't work on strings<\/span>","41930d89":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Recall that in <a href=\"#2.2\">Section 2.2<\/a> we had seen that if we drop all columns with missing values we lose 19 columns<\/span>","0c3c8d10":"<a id = '6'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 6. Further Readings <\/h2>","953a5be3":"<a id = '3.2.2'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 28px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.2.2 Iterative Imputer<\/h2>","ae20603c":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Most of the times the missing values are not randomly distributed across observations but are distributed within one or more sub-samples. Therefore, missingness itself might be a good indicator to classify the labels<\/span>","9501bb08":"<a id = '1'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 1. Introduction <\/h2>","f95abc1f":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\"> Handling Missing Values<\/h1>\n<br>\n\n![](https:\/\/fintechprofessor.com\/wp-content\/uploads\/2019\/12\/close-up-texture-of-a-white-jigsaw-puzzle-in-assembled-state-with-missing-elements-forming-a-blue-pad_t20_WxKR61.jpg)","cbd7c3e1":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We can impute missing values with a provided constant value, or using the statistics (mean, median or most frequent) of each column.<\/span>","2be04b59":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Imputing Continuous Variables<\/span>","89a5b8ea":"<a id = '1.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">1.1 Import Required Libraries<\/h2>","576a700b":"<div class = 'alert alert-info' style = 'color:blue'> \ud83d\udca1 This notebook is part of the <a href=\"http:\/\/iitg.ac.in\/sa\/caciitg\/course\" style=\"color: #002d5e\">Summer Analytics 2021<\/a> course curated by <a href=\"https:\/\/www.linkedin.com\/company\/caciitg\/mycompany\/\" style=\"color: black\">Consulting & Analytics Club, IIT Guwahati<\/a>. This notebook intends to introduce the readers to various different Imputaion techniques and How to deal with missing values in general with the help of <i>pandas<\/i> and <i>sklearn<\/i><\/div>","c2bc6bfe":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">If we drop all the rows with any missing value we aren't left with any row<\/span>","159f93dd":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Imputing Categorical Variables<\/span>","7d5b4fb0":"<h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center \" >Table of Contents<\/h1>\n\n\n* [1. Introduction](#1)\n    * [1.1 Import Required Libraries](#1.1)\n    * [1.2 Exploring the Data](#1.2)\n    * [1.3 Helper Function](#1.3)\n* [2. Dropping Rows and Columns](#2)\n    * [2.1 Dropping Rows with Missing Values](#2.1)\n    * [2.2 Dropping Columns with Missing Values](#2.2)\n* [3. Univariate vs Multivariate Imputation](#3)\n    * [3.1 Univariate Imputation](#3.1)\n        * [3.1.1 Simple Imputer](#3.1.1)\n    * [3.2 Multivariate Imputation](#3.2)\n        * [3.2.1 KNN Imputer](#3.2.1)\n        * [3.2.2 Iterative Imputer](#3.2.2)\n* [4. Missing Indicator](#4)\n* [5. Missing Indicator + Iterative Imputer](#5)\n* [6. Further Readings](#6)","39377d18":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">We have 81 columns in total, 80 of them are feature columns and <code>SalePrice<\/code> is the target column<\/span>","73ed2862":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">KNNImputer doesn't work on strings so we need to encode the strings into float or int keeping the <code>NaN<\/code> values<\/span> <br>\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">This is where we will use the helper function we defined earlier<\/span>","23f45da8":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">If we drop all columns with missing values we lose 19 columns<\/span>","75d7748f":"<a id = '3.2.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 28px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.2.1 KNN Imputer<\/h2>","8c3d3540":"1. [KNN Imputer Algorithm](https:\/\/www.youtube.com\/watch?v=AHBHMQyD75U&list=PLlg4M31xJeYa7XcJZWypot8l7R-0E65Ls)\n2. [Iterative Imputer Algorithm](https:\/\/www.youtube.com\/watch?v=WPiYOS3qK70&list=PLlg4M31xJeYa7XcJZWypot8l7R-0E65Ls)","5ad0c823":"<a id = '3.2'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.2 Multivariate Imputation<\/h2>","f0a79283":"<a id = '1.3'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">1.3 Helper Function<\/h2>","54e11512":"<a id = '3.1.1'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 28px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">3.1.1 Simple Imputer<\/h2>","a20d212c":"<a id = '2.2'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight: normal; border-radius: 100px 100px; text-align: center\">2.2 Dropping Columns with Missing Values<\/h2>","66af0927":"<a id = '1.2'><\/a>\n\n<h2 style = \"background-color: #f6f5f5; color : #fe346e; font-size: 35px; font-family:garamond; font-weight:normal; border-radius: 100px 100px; text-align: center\">1.2 Exploring the Data <\/h2>","4db4779d":"<a id = '3'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 3. Univariate vs Multivariate Imputation <\/h2>","8f35ec43":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">A strategy for imputing missing values by modeling each feature with missing values as a function of other features<\/span>","641bec42":"<a id = '2'><\/a>\n<h2 style = \"font-family:garamond; font-size:50px; background-color: #f6f6f6; color : #fe346e; border-radius: 100px 100px; text-align:center\"> 2. Dropping Rows and Columns <\/h2>","120e037f":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. <code>SimpleImputer<\/code>). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. <code>IterativeImputer<\/code>).<\/span>"}}