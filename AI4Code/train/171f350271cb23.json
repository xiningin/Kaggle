{"cell_type":{"8aea6d39":"code","5f307bec":"code","c35b621a":"code","cf917f63":"code","06af60f7":"code","cd262778":"code","2a9e1e70":"code","bb803c47":"code","69be3e97":"code","6d8d9cfc":"code","4c2f60b9":"code","999734f3":"code","2f1b73eb":"code","86ff4d0f":"markdown","6fc94da2":"markdown","508fc280":"markdown","d4913c15":"markdown","601962c5":"markdown","11ea177d":"markdown","51f06e99":"markdown","d8b9d3ba":"markdown","0b3c1487":"markdown","feb9217e":"markdown","b2098931":"markdown","6a146a64":"markdown","b38d9e5c":"markdown","05a3cdce":"markdown","92b88065":"markdown","8b36f5f9":"markdown"},"source":{"8aea6d39":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools","5f307bec":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","c35b621a":"# divide training data into features and labels\nX_train = train.iloc[:,1:]\ny_train = train.iloc[:,0]","cf917f63":"# Reshape and normalize image\nX_train = X_train.values.reshape(-1, 28, 28, 1)\/255.\ntest = test.values.reshape(-1, 28, 28, 1)\/255.\n# One Hot encoding the label\ny_train = to_categorical(y_train, 10)","06af60f7":"random_seed = 0\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_seed)","cd262778":"datagen = ImageDataGenerator(\n            rotation_range=10,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            zoom_range=0.1\n            )","2a9e1e70":"model = Sequential()\n\nmodel.add(Conv2D(32, (5,5), padding='same', input_shape=X_train.shape[1:], activation='relu'))\nmodel.add(Conv2D(32, (5,5), padding='same', activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","bb803c47":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","69be3e97":"EPOCHS = 30\nBATCH_SIZE = 20\ncallback_list = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1),\n    EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=4)\n]\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                   epochs=EPOCHS,\n                   callbacks=callback_list,\n                   validation_data=(X_val, y_val),\n                   steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE)","6d8d9cfc":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nfig, ax = plt.subplots(figsize=(12,4))\nax.plot(loss, 'b', label='Training loss')\nax.plot(val_loss, 'r', label='Validation loss')\nax.legend()","4c2f60b9":"def plot_confustion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Oranges):\n    plt.figure(figsize=(10,7))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i , cm[i,j],\n                horizontalalignment='center',\n                color='white' if cm[i, j] > thresh else 'black')\n    plt.tight_layout()\n    plt.xlabel('True label')\n    plt.ylabel('Predicted label')","999734f3":"y_pred = model.predict(X_val)\ny_pred_classes = np.argmax(y_pred, axis=1)\ny_real_classes = np.argmax(y_val, axis=1)\ncm = confusion_matrix(y_pred_classes, y_real_classes)\nplot_confustion_matrix(cm, classes=range(10))","2f1b73eb":"results = model.predict(test)\nresults = np.argmax(results, axis=1)\nresults = pd.Series(results, name='Label')\nsubmission = pd.concat([pd.Series(range(1,28001), name='ImageID'), results], axis=1)\nsubmission.to_csv('submission.csv', index=False)","86ff4d0f":"### 2.4 Data Augmentation","6fc94da2":"# Digit Recognizer with keras CNN","508fc280":"### 3.2 Compile","d4913c15":"### 2.3 split training and validation set","601962c5":"<a id=\"1\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>1. Import required libraries<\/center><\/h1>","11ea177d":"<a id=\"4\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>4. Training<\/center><\/h1>","51f06e99":"### 2.2 Optimize the data","d8b9d3ba":"### 5.1 Training and validation curves","0b3c1487":"### 3.1 Define model","feb9217e":"* [1. Import required libraries](#1)\n* [2. Data preparation](#2)\n* [3. Build CNN](#3)\n* [4. Training](#4)\n* [5. Evaluate the model](#5)\n* [6. Create submission](#6)","b2098931":"<a id=\"2\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>2. Data preparation<\/center><\/h1>","6a146a64":"### 2.1 load dataset","b38d9e5c":"<a id=\"6\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>6. Create submission<\/center><\/h1>","05a3cdce":"<a id=\"3\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>3. Build CNN<\/center><\/h1>","92b88065":"### 5.2 Confusion matrix","8b36f5f9":"<a id=\"5\"><\/a>\n<h1 style='background:dimgray; border:0; color:white'><center>5. Evaluate the model<\/center><\/h1>"}}