{"cell_type":{"96dd2adb":"code","51c53405":"code","be76fe6d":"code","38c82e27":"code","60c14067":"code","d85dc0ce":"code","c887bfd8":"code","55662386":"code","ba883406":"code","24bd0dfb":"code","0bcf6ae3":"code","1ea141c2":"code","0a074caa":"code","6d8d0ad9":"code","3c1b1b1a":"code","2a51eb55":"code","260151a3":"code","1d31c581":"code","207631b5":"code","9df651b6":"code","d6d2e4d5":"code","f3fa2c71":"code","ea943d8e":"code","dbcdda32":"code","95184cc8":"code","1b16a436":"code","76e05927":"code","a783305f":"code","facc7f12":"code","055bb7b1":"code","fdd3935e":"code","cca2bbc9":"code","63d0dd09":"code","b709aef9":"markdown","6f268070":"markdown","7fe92567":"markdown","993cfb3c":"markdown","65b15a90":"markdown","968a6f67":"markdown","cec6dd0a":"markdown","c14031bc":"markdown","76827f6f":"markdown"},"source":{"96dd2adb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n!pip install imutils\nimport os\nimport keras.backend as K\nimport imutils\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51c53405":"import glob\nfiles=[]\nfiles=[]\nfor file in glob.glob(\"..\/input\/brain-tumor\/Brain Tumor\/Brain Tumor\/*.jpg\"):\n    files.append(file)\n        ","be76fe6d":"def crop_brain_contour(image, plot=False):\n    \n    # Convert the image to grayscale, and blur it slightly\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n    \n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # Find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n    # extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    \n    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n\n    if plot:\n        plt.figure()\n        plt.subplot(1, 2, 1)\n        plt.imshow(image)\n        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        plt.title('Original Image')\n        plt.subplot(1, 2, 2)\n        plt.imshow(new_image)\n        plt.tick_params(axis='both', which='both',top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        plt.title('Cropped Image')\n        plt.show()\n    \n    return new_image","38c82e27":"import os\ntry:\n    os.rmdir('.\/crop\/')\n   \nexcept:\n    pass\n","60c14067":"\n#os.mkdir('.\/crop\/')\n\n\nfor file in files:\n    #print(file)\n    ex_img = cv2.imread(file)\n    ex_crop_img = crop_brain_contour(ex_img, False)\n    filename='.\/crop\/'+os.path.basename(file)\n    #print(filename)\n    cv2.imwrite(filename,ex_crop_img)\n    ","d85dc0ce":"import pandas as pd\ndf_train=pd.read_csv('..\/input\/brain-tumor\/Brain Tumor.csv')\ndf_train\ndf_train_=df_train[['Image','Class']]\ndf_train_.columns=['filename','class']","c887bfd8":"np.unique(df_train_['class'])\ndf_train_.filename=[filename+'.jpg' for filename in df_train_.filename.values ]\n\ndf_train_=df_train_.sample(frac=1)","55662386":"print(len(df_train_[df_train_['class']==0]))\nprint(len(df_train_[df_train_['class']==1]))\n\n","ba883406":"from sklearn.model_selection import train_test_split\n\nX_train,X_=train_test_split(df_train_,test_size=0.2,random_state=0)\n\nX_test,X_val=train_test_split(X_,test_size=0.2,random_state=0)","24bd0dfb":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimg_generator=ImageDataGenerator(rescale=1\/255)\n\ntrain_it = img_generator.flow_from_dataframe(X_train,directory='.\/crop\/', class_mode='raw',\n                                             featurewise_std_normalization=True,\n                                             image_size=(256, 256))\ntest_it = img_generator.flow_from_dataframe(X_test,directory='.\/crop\/', class_mode='raw',image_size=(256, 256),featurewise_std_normalization=True,batch_size=602)\nval_it = img_generator.flow_from_dataframe(X_val,directory='.\/crop\/', class_mode='raw',image_size=(256, 256),featurewise_std_normalization=True)","0bcf6ae3":"import matplotlib.pyplot as plt\n\nfig,ax=plt.subplots(2,2,figsize=(6,6))\n\nimages,labels = train_it.next()\nx=0\ny=0\nfor i in range(0,16):\n    image = images[i]\n    if y<2 and x<2:\n        ax[y][x].imshow(image)\n    if x>2:\n        y=y+1\n        x=0\n    x=x+1\nplt.show()","1ea141c2":"\n# example of tending the vgg16 model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\n\n# load model without classifier layers\nvgg = VGG16(include_top=False, input_shape=(256, 256, 3))\n# add new classifier layers\nflat1 = Flatten()(vgg.output)\ndropout = Dropout(0.5)(flat1)\ndense1 = Dense(1024, activation='relu')(flat1)\nbatch =  BatchNormalization()(dense1)\ndense2 = Dense(1024, activation='relu')(batch)\ndropout = Dropout(0.5)(dense2)\noutput = Dense(1, activation='sigmoid')(dropout)\n# define new model\nmodel = Model(inputs=vgg.inputs, outputs=output)\n# summarize\nmodel.summary()\n\nfor layer in vgg.layers:\n    layer.trainable=False\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","0a074caa":"import tensorflow\nes=tensorflow.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=8,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True,\n)\n","6d8d0ad9":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2)\ncallbacks=[reduce_lr,es]","3c1b1b1a":"model.fit_generator(train_it, epochs=30,steps_per_epoch=5, \n                    validation_data=val_it, validation_steps=3,callbacks=callbacks)","2a51eb55":"if os.path.isfile('\/kaggle\/working\/model.h5'):\n    model.load_weights(\"\/kaggle\/working\/model.h5\")\nelse:\n    model.fit_generator(train_it, epochs=180,steps_per_epoch=5, \n                    validation_data=val_it, validation_steps=3,callbacks=callbacks)","260151a3":"model.save_weights('\/kaggle\/working\/model.h5')","1d31c581":"scores=model.evaluate_generator(generator=test_it,steps=10)","207631b5":"print(\"Accuracy = \", scores[1])","9df651b6":"df_shuffle=X_test\ndf_shuffle.filename=['.\/crop\/'+filename for filename in df_shuffle.filename]","d6d2e4d5":"df_yes=df_shuffle[df_shuffle['class']==1]\ndf_yes","f3fa2c71":"df_yes=df_shuffle[df_shuffle['class']==1]\nname=list(df_yes.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\n\nfrom tensorflow.keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nx_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\nimage = preprocess_input(x_reshape)\n\nmodel.predict(image)","ea943d8e":"df_no=df_shuffle[df_shuffle['class']==0]\nname=list(df_no.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\n\nfrom tensorflow.keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nx_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\nimage = preprocess_input(x_reshape)\n\nmodel.predict(image)","dbcdda32":"y_pred=[]\ny_true=[]\nimages,y_true=test_it.next()\n\nfor image in images:\n    \n    pred=model.predict(np.array([image]))\n    \n\n    \n\n    \n \n    y_pred.extend(pred[0])\n   ","95184cc8":"y_pred_=[int(y>0.5) for y in y_pred]","1b16a436":"y_true","76e05927":"y_test=y_true","a783305f":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred_))","facc7f12":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_pred_)","055bb7b1":"def get_xai(x):\n    \n    \n    x=x\/255\n    x_ = np.expand_dims(x, axis=0)\n        \n\n    y_pred = model.predict(x_)\n    \n    print('pred',y_pred)\n    last_conv_layer = model.get_layer('block5_conv3')\n    argmax = np.argmax(y_pred[0])\n    print(argmax)\n    output = model.output[:, argmax]\n    print(output)\n    print(last_conv_layer.output)\n    grads = K.gradients(output, last_conv_layer.output)[0]\n\n    #tf.print(grads)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n\n\n\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n\n\n\n    from keras.applications.vgg16 import preprocess_input\n    #x = preprocess_input(x)\n    #print( pooled_grads_value[pooled_grads_value>0])\n\n    pooled_grads_value, conv_layer_output_value = iterate([x_])\n\n\n    for i in range(512):\n        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n    heatmap = np.mean(conv_layer_output_value, axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    heatmap \/= np.max(heatmap)\n    #plt.matshow(heatmap)\n    #plt.show()\n    import cv2\n    heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    hif = .05\n    superimposed_img = heatmap * hif + x\n    from matplotlib.pyplot import figure\n    plt.figure(figsize=(5, 5))\n    #fig, ax =figure(figsize=(10, 2))\n    #ax.imshow(random.rand(8, 90), interpolation='nearest')\n    plt.imshow(superimposed_img)\n    #plt.axis('off')\n    plt.show()\n    \ndef get_heatmap(x):\n    \n    \n    x=x\/255\n    x_ = np.expand_dims(x, axis=0)\n        \n\n    y_pred = model.predict(x_)\n    \n   \n    last_conv_layer = model.get_layer('block5_conv3')\n    argmax = np.argmax(y_pred[0])\n    \n    output = model.output[:, argmax]\n   \n    grads = K.gradients(output, last_conv_layer.output)[0]\n\n    #tf.print(grads)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n\n\n\n    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n\n\n\n    from keras.applications.vgg16 import preprocess_input\n    #x = preprocess_input(x)\n    #print( pooled_grads_value[pooled_grads_value>0])\n\n    pooled_grads_value, conv_layer_output_value = iterate([x_])\n\n\n    for i in range(512):\n        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n    heatmap = np.mean(conv_layer_output_value, axis=-1)\n    heatmap = np.maximum(heatmap, 0)\n    heatmap \/= np.max(heatmap)\n    #plt.matshow(heatmap)\n    #plt.show()\n    import cv2\n    heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    return heatmap","fdd3935e":"df_yes=df_shuffle[df_shuffle['class']=='yes']\nname=list(df_yes.iloc[1:2,:]['filename'])[0]\nprint(name)\nex_img = cv2.imread(name)\nex_img = cv2.resize(ex_img,(256,256))\nplt.imshow(ex_img)\nget_xai(ex_img)","cca2bbc9":"###from tqdm import tqdm\n\n###images=[]\n###predictions=[]\n\n\n###for i,r in tqdm(df_shuffle.iterrows()):\n###    ex_img = cv2.imread(r['filename'])\n###    ex_img = cv2.resize(ex_img,(256,256))\n###    plt.imshow(ex_img)\n\n###    from tensorflow.keras.preprocessing import image\n###    from keras.applications.vgg16 import preprocess_input\n\n###    x_reshape = ex_img.reshape((1, ex_img.shape[0],ex_img.shape[1], ex_img.shape[2]))\n\n###    image = preprocess_input(x_reshape)\n    \n###    pred=model.predict(image)\n###    images.append(get_heatmap(ex_img).flatten())\n###    predictions.extend(pred[0])","63d0dd09":"### import csv\n\n### df_shuffle.to_csv('\/kaggle\/working\/df.csv')\n\n### with open('\/kaggle\/working\/maps.csv', 'wb') as images:\n###    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n###    wr.writerow(mylist)","b709aef9":"### Reading Files","6f268070":"## Test Accuracy","7fe92567":"## Machine Learning Explainable","993cfb3c":"## Saving maps","65b15a90":"## Class Balance","968a6f67":"## Show images","cec6dd0a":"## Crop Image","c14031bc":"## Train model","76827f6f":"## Test Predictions"}}