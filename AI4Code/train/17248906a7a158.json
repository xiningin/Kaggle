{"cell_type":{"c1b8692a":"code","048d78e6":"code","7be357c3":"code","eb175a24":"code","aac8e294":"code","5a54d569":"code","5b42cba8":"code","f497324a":"code","542ef9e5":"code","d8869df5":"code","c80e3f45":"markdown","805f52f1":"markdown"},"source":{"c1b8692a":"'''\nImports\n'''\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers.experimental.preprocessing import TextVectorization","048d78e6":"DIR = '..\/input\/original-flickr8k-dataset\/'\nTRAIN = os.listdir(DIR + 'Flickr8k_Dataset\/Flicker8k_Dataset')\nprint(f'Training Images => {len(TRAIN)}')\n\nCAPTIONS = open(DIR + 'Flickr8k.token.txt').readlines()  ","7be357c3":"'''\nStore image paths and captions in seperate list to create a dataframe.\n'''\nimages = []\ncap_data = []\n\nfor line in CAPTIONS:\n    line = line.rstrip(\"\\n\")\n    img_name, cap_text = line.split(\"\\t\")\n    img_name = img_name.split('#')[0]\n    if img_name.endswith(\"jpg\"):\n        images.append(DIR + 'Flickr8k_Dataset\/Flicker8k_Dataset\/'+img_name)\n        cap_data.append(cap_text)\nprint(f'Total images (include repetitions ) = {len(images)}\\n# Captions = {len(cap_data)}')\n\n\ndf = pd.DataFrame(list(zip(images,cap_data)),columns=['Image_path','Captions'])\ndf = df.sample(frac=1).reset_index(drop=True)\ndf.head()","eb175a24":"def _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() \n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))","aac8e294":"def serialize_example(img, name, caption):\n    '''\n    Define how to serialze each sample.\n    '''\n    feature = {\n      'image': _bytes_feature(img),\n      'name' : _bytes_feature(name),\n      'caption': _bytes_feature(caption),\n\n    }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","5a54d569":"NUM_TFRECORDS =  140\nIMG_SIZE = 299\nFILE_PER_RECORD = len(df)\/\/NUM_TFRECORDS\n\nos.makedirs('.\/tfrec_files\/',exist_ok=True)\n\nfor idx in tqdm(range(NUM_TFRECORDS)):\n    with tf.io.TFRecordWriter(f'.\/tfrec_files\/File_{idx+1}_{FILE_PER_RECORD}.tfrec') as writer:\n        for k in range(FILE_PER_RECORD*idx, FILE_PER_RECORD*(idx+1)):\n            img = cv2.imread(df['Image_path'].iloc[k])\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tobytes()\n            name = df['Image_path'].iloc[k].split('\/')[-1]\n            caption = df['Captions'].iloc[k]\n            example = serialize_example(\n              img,\n              str.encode(name),\n              str.encode(caption)\n            )\n            writer.write(example)","5b42cba8":"BATCH_SIZE = 16\nOP_IMG_SIZE = 256\nAUTO = tf.data.experimental.AUTOTUNE\nTRAINING_FILENAMES = tf.io.gfile.glob('.\/tfrec_files\/*.tfrec')\nprint(f'# Tfrecord files = {len(TRAINING_FILENAMES)}')","f497324a":"import math\nnp.set_printoptions(threshold=15, linewidth=80)\nCLASSES = [0,1]\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    labels = [i.decode() for i in  numpy_labels]\n    return numpy_images, labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize\/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize\/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)\/\/rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE\/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE\/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = label\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING\/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        # image = cv2.imdecode(image,cv2.IMREA)\n        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)","542ef9e5":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    channels = tf.unstack(image, axis=-1)\n    image    = tf.stack([channels[2], channels[1], channels[0]], axis=-1)\n    image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    image = tf.image.resize(image,[OP_IMG_SIZE,OP_IMG_SIZE])\n    image = tf.reshape(image, [OP_IMG_SIZE,OP_IMG_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"name\":tf.io.FixedLenFeature([],tf.string),\n        \"caption\": tf.io.FixedLenFeature([],tf.string),\n\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = example['caption']\n    return image, label\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord)\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset","d8869df5":"training_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(16)\ntrain_batch = iter(training_dataset)\n\ndisplay_batch_of_images(next(train_batch))","c80e3f45":" ## *Visualizing Some tfrecord files*","805f52f1":"## Steps: \n#### *1. Created a dataframe with all the image paths and corresponding captions for easy use.*\n#### *2. Serialized a group of samples together in a .tfrec file.*\n#### *3. Visualized decoded samples .*"}}