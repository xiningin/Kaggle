{"cell_type":{"388d240c":"code","d0712560":"code","6e4c4c85":"code","28ba01de":"code","522c1d1a":"code","b9c59758":"code","2ad53405":"code","edfb82ed":"code","8dee2203":"code","b675bc7c":"code","00eab9b7":"code","ae969a3b":"code","dfaa3c91":"code","98f209ad":"code","aea33c29":"code","7170eaf0":"code","858c9508":"code","655ed398":"code","1fd156b3":"code","8a720b78":"code","1134b33c":"code","57b3bf8e":"code","e3d1b342":"code","9e2f48fc":"code","a7be95a9":"code","45134129":"code","c2b89d2c":"code","889c3a23":"code","4b884cb7":"code","1dd03b38":"code","dc3b610f":"code","f1f45c99":"code","8804cb39":"code","eb18b443":"code","2ffd4d40":"markdown"},"source":{"388d240c":"# This notebook helps to understand how to use ML tools in real world data sets. Particularly i used Titanic data \n#to help predict survived unsurvived families\n# As you go down you will see following steps of my work;\n#>>importing necessary libraries\n#>>reading file\n#>>generating and description about data contents\n#>>visualization\n#>>filling and replacing operations\n#>>training and prediction","d0712560":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import misc\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KDTree, BallTree, KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns\nsns.set_style('whitegrid')","6e4c4c85":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntrain.head()","28ba01de":"train.head()","522c1d1a":"train.sample(n=10)","b9c59758":"train.describe(include='all')\n","2ad53405":"train.isnull().sum()","edfb82ed":"plt.hist(train['Survived'], bins = 3)\nplt.show()","8dee2203":"print(\"Not Survived {} out of {} passengers.\".format(len(train[train['Survived'] == 0]), len(train['Survived'])))\nprint(\"Survived {} out of {} passengers.\".format(len(train[train['Survived'] == 1]), len(train['Survived'])))","b675bc7c":"#the most frequent letter in Embarked feature\ntrain['Embarked'].mode()","00eab9b7":"#replacing missing cells with S\ntrain['Embarked'].fillna('S', inplace = True)\ntrain.isnull().any()","ae969a3b":"train['Age'].interpolate(inplace = True)\ntrain.isnull().any()","dfaa3c91":"train['Sex'].replace('male', 1, inplace = True)\ntrain['Sex'].replace('female', 0, inplace = True)\ntrain['Embarked'].replace('S', 2, inplace = True)\ntrain['Embarked'].replace('C', 1, inplace = True)\ntrain['Embarked'].replace('Q', 0, inplace = True)\ntrain.head()","98f209ad":"age = train['Age'].values.reshape(-1,1)\nmin_max_scaler = preprocessing.MinMaxScaler()\nage_scaled = min_max_scaler.fit_transform(age)\ntrain['Age'] = pd.DataFrame(age_scaled)\n\nfare = train['Fare'].values.reshape(-1,1)\nmin_max_scaler2 = preprocessing.MinMaxScaler()\nfare_scaled = min_max_scaler2.fit_transform(fare)\ntrain['Fare'] = pd.DataFrame(fare_scaled)\n\npclass = train['Pclass'].values.reshape(-1,1)\nmin_max_scaler3 = preprocessing.MinMaxScaler()\npclass_scaled = min_max_scaler3.fit_transform(pclass)\ntrain['Pclass'] = pd.DataFrame(pclass_scaled)\n\nemb = train['Embarked'].values.reshape(-1,1)\nmin_max_scaler4 = preprocessing.MinMaxScaler()\nemb_scaled = min_max_scaler4.fit_transform(emb)\ntrain['Embarked'] = pd.DataFrame(emb_scaled)\n\nsib = train['SibSp'].values.reshape(-1,1)\nmin_max_scaler5 = preprocessing.MinMaxScaler()\nsib_scaled = min_max_scaler5.fit_transform(sib)\ntrain['SibSp'] = pd.DataFrame(sib_scaled)\n\nparch = train['Parch'].values.reshape(-1,1)\nmin_max_scaler6 = preprocessing.MinMaxScaler()\nparch_scaled = min_max_scaler6.fit_transform(parch)\ntrain['Parch'] = pd.DataFrame(parch_scaled)\n\n\ntrain.head()","aea33c29":"# corr matrix\ncorr = train.corr()\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","7170eaf0":"sns.factorplot('Age','Survived', data=train,size=10,aspect=2)","858c9508":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()","655ed398":"trainX, testX, trainY, testY = train_test_split(train[['Pclass', 'Sex', 'Age','SibSp','Parch','Fare', 'Embarked']], train['Survived'], test_size = 0.25)","1fd156b3":"#Decision tree classifier\na=np.arange(2,10,1)\nfor i in a:\n    clf1 = DecisionTreeClassifier(max_depth=i)\n    clf1.fit(trainX, trainY)\n    accuracy = clf1.score(testX, testY)\n    print(i,accuracy)","8a720b78":"#Support Vector Classifier\nclf2 = svm.SVC()\nclf2.fit(trainX, trainY)\naccuracy = clf2.score(testX, testY)\nprint(accuracy)","1134b33c":"#LRC\nclf3 = LogisticRegressionCV(Cs=1000, penalty='l2')\nclf3.fit(trainX, trainY)\naccuracy = clf3.score(testX, testY)\nprint(accuracy)","57b3bf8e":"#KNN\nclf4 = KNeighborsClassifier()\nclf4.fit(trainX, trainY)\naccuracy = clf4.score(testX, testY)\nprint(accuracy)","e3d1b342":"#Multilayer perceptron\n\nclf5 = MLPClassifier()\nclf5.fit(trainX, trainY)\naccuracy = clf5.score(testX, testY)\nprint(accuracy)","9e2f48fc":"#Random Forest Classifier\nclf6 = RandomForestClassifier()\nclf6.fit(trainX, trainY)\naccuracy = clf6.score(testX, testY)\nprint(accuracy)","a7be95a9":"test.head()","45134129":"test = test[['PassengerId','Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\ntest.isnull().any() #passengerId, Name, Ticket, Cabin delete","c2b89d2c":"test['Age'].interpolate(inplace = True)\ntest.isnull().any()\n","889c3a23":"test['Embarked'].fillna('S', inplace = True)\ntest.isnull().any()","4b884cb7":"test['Fare'].interpolate(inplace = True)\ntest.isnull().any()","1dd03b38":"test['Sex'].replace('male', 1, inplace = True)\ntest['Sex'].replace('female', 0, inplace = True)\ntest['Embarked'].replace('S', 2, inplace = True)\ntest['Embarked'].replace('C', 1, inplace = True)\ntest['Embarked'].replace('Q', 0, inplace = True)\ntest.head()","dc3b610f":"from sklearn import preprocessing\nage = test['Age'].values.reshape(-1,1)\nmin_max_scaler = preprocessing.MinMaxScaler()\nage_scaled = min_max_scaler.fit_transform(age)\ntest['Age'] = pd.DataFrame(age_scaled)\n\nfare = test['Fare'].values.reshape(-1,1)\nmin_max_scaler2 = preprocessing.MinMaxScaler()\nfare_scaled = min_max_scaler2.fit_transform(fare)\ntest['Fare'] = pd.DataFrame(fare_scaled)\n\npclass = test['Pclass'].values.reshape(-1,1)\nmin_max_scaler3 = preprocessing.MinMaxScaler()\npclass_scaled = min_max_scaler3.fit_transform(pclass)\ntest['Pclass'] = pd.DataFrame(pclass_scaled)\n\nemb = test['Embarked'].values.reshape(-1,1)\nmin_max_scaler4 = preprocessing.MinMaxScaler()\nemb_scaled = min_max_scaler4.fit_transform(emb)\ntest['Embarked'] = pd.DataFrame(emb_scaled)\ntest.head()","f1f45c99":"test.head()","8804cb39":"trainX = train[['Pclass', 'Sex','Age','SibSp','Parch', 'Fare', 'Embarked']]\ntrainY = train['Survived']\ntestX = test[['Pclass', 'Sex','Age','SibSp','Parch', 'Fare', 'Embarked']]","eb18b443":"result = pd.DataFrame(test['PassengerId'])\nclf = DecisionTreeClassifier()\nclf.fit(trainX, trainY)\npredictDTC = clf.predict(testX)\nresult['Survived'] = predictDTC\n","2ffd4d40":"#Applying on a Test Set"}}