{"cell_type":{"83aa0785":"code","a8d48865":"code","b312f7a4":"code","9e367bbc":"code","55722cdf":"code","7fdb7c04":"code","229e36c7":"code","d5ed81a5":"code","d18b4839":"code","e497347e":"code","b57923f3":"code","0147da81":"code","e36eb1ac":"code","7c21769b":"markdown","d641152d":"markdown","d04fb84b":"markdown","543691db":"markdown","f8577aaa":"markdown","ec7693b6":"markdown","01033c1b":"markdown","7b2c28dc":"markdown","6c864948":"markdown","70645119":"markdown","6efb466c":"markdown"},"source":{"83aa0785":"import os\nimport tensorflow\nos.environ['KERAS_BACKEND'] = 'tensorflow'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator","a8d48865":"dataset = pd.read_csv('..\/input\/driver_imgs_list.csv')\ndataset.head(5)","b312f7a4":"import os\nfrom IPython.display import display, Image\nimport matplotlib.image as mpimg\n\nactivity_map = {'c0': 'Safe driving', \n                'c1': 'Texting - right', \n                'c2': 'Talking on the phone - right', \n                'c3': 'Texting - left', \n                'c4': 'Talking on the phone - left', \n                'c5': 'Operating the radio', \n                'c6': 'Drinking', \n                'c7': 'Reaching behind', \n                'c8': 'Hair and makeup', \n                'c9': 'Talking to passenger'}\n\nplt.figure(figsize = (12, 20))\nimage_count = 1\nBASE_URL = '..\/input\/imgs\/train\/'\nfor directory in os.listdir(BASE_URL):\n    if directory[0] != '.':\n        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n            if i == 1:\n                break\n            else:\n                fig = plt.subplot(5, 2, image_count)\n                image_count += 1\n                image = mpimg.imread(BASE_URL + directory + '\/' + file)\n                plt.imshow(image)\n                plt.title(activity_map[directory])","9e367bbc":"classifier = Sequential()\nclassifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (240, 240, 3), data_format = 'channels_last'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Flatten())\nclassifier.add(Dense(units = 1024, activation = 'relu'))\nclassifier.add(Dense(units = 256, activation = 'relu'))\nclassifier.add(Dense(units = 10, activation = 'sigmoid'))\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nclassifier.summary()","55722cdf":"train_datagen = ImageDataGenerator(rescale = 1.0\/255, \n                                   shear_range = 0.2, \n                                   zoom_range = 0.2, \n                                   horizontal_flip = True, \n                                   validation_split = 0.2)\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/imgs\/train', \n                                                 target_size = (240, 240), \n                                                 batch_size = 32,\n                                                 subset = 'training')\n\nvalidation_set = train_datagen.flow_from_directory('..\/input\/imgs\/train', \n                                                   target_size = (240, 240), \n                                                   batch_size = 32,\n                                                   subset = 'validation')","7fdb7c04":"classifier.fit_generator(training_set,\n                         steps_per_epoch = 17943\/32,\n                         epochs = 10,\n                         validation_data = validation_set,\n                         validation_steps = 4481\/32)","229e36c7":"classifier.save_weights(\"model.h5\")","d5ed81a5":"# serialize model to JSON\nmodel_json = classifier.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","d18b4839":"# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")","e497347e":"from PIL import Image\n\ndef get_data(image_path):\n    img = Image.open(image_path)\n    img = img.resize((240, 240), Image.ANTIALIAS) # resizes image in-place\n    return np.asarray(img)\/255","b57923f3":"test_file = pd.read_csv('..\/input\/sample_submission.csv')\ntest_file.head(5)","0147da81":"for i, file in enumerate(test_file['img']):\n    image = get_data('..\/input\/imgs\/test\/' + file)\n    image = np.reshape(image, (1, image.shape[0], image.shape[1], image.shape[2]))\n    result = classifier.predict(image)\n    test_file.iloc[i, 1:] = result[0]","e36eb1ac":"test_file.to_csv('results.csv', index = False)","7c21769b":"Saving model","d641152d":"loading saved model","d04fb84b":"# Import libraries\n\nI'll use Keras and Tensorflow libraries to create a **Convolutional Neural Network**. So, I'll import the necessary libraries to do the same.","543691db":"# Identifying distracted drivers\n\nIn this notebook, I'll use the dataset which includes images of drivers while performing a number of tasks including .... The aim is to correctly identify if the driver is distracted from driving. We might also like to check what activity is the person performing.","f8577aaa":"# Building the model\n\nI'll develop the model with a total of 3 Convolutional layers, then a Flatten layer and then 3 Dense layers. I'll use the optimizer as `adam`, and loss as `categorical_crossentropy`.","ec7693b6":"# Images overview\n\nLet's take a look at the various images in the dataset. I'll plot an image for each of the 10 classes. As the directory names are not descriptive, I'll use a map to define the title for each image that is more descriptive.","01033c1b":"# Import the dataset\n\nI'll import the .csv file to read the labels.","7b2c28dc":"# Creating training data\n\nOnce the model is ready, I'll use the data on which I want to train the model. The folder `train` includes the images I need. I'll generate more images using **ImageDataGenerator** and split the training data into 80% train and 20% validation split.","6c864948":"From the csv file, I'll use the `classname` as the labels for the images and use the image names to match the labels with the correct images.","70645119":"# Train the model\n\nUsing `fit_generator`, I'll train the model. I'll also save the model to the file, `safeDriving.h5`.","6efb466c":"# Predicting on test data"}}