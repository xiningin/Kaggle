{"cell_type":{"819c96e8":"code","92cc505f":"code","b5584c53":"code","14d89de1":"code","9c7ec066":"code","78419024":"code","757f9af1":"code","1421d191":"code","0eb4faa7":"code","07e24df6":"code","bac13430":"code","5d89db72":"code","e977fbe5":"code","2644dee9":"code","d6f06f52":"code","5c881cef":"code","f375b568":"code","7a02f66c":"code","e24aa019":"code","72fa5d93":"code","e82dfeef":"code","22fc6f7e":"code","bcd9cda6":"code","893400f2":"code","fd822c2a":"code","680468da":"markdown","eb3a7ae1":"markdown","a39346d6":"markdown","5a37bac1":"markdown","6142455d":"markdown","bad0e761":"markdown","bd8a7bb4":"markdown","8bfed3b4":"markdown"},"source":{"819c96e8":"!pip3 install -q tensorflow_decision_forests","92cc505f":"# Import packages and modules\nimport numpy  as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow_decision_forests as tfdf\n\nfrom sklearn.model_selection import train_test_split","b5584c53":"# Check the version of TensorFlow Decision Forests\nprint(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)","14d89de1":"# Read in the data\ntrain = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv',index_col=0)\ntest  = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv', index_col=0)\n\ntrain.head()","9c7ec066":"train.shape","78419024":"# Understand the variable types\ntrain.dtypes.value_counts()","757f9af1":"# Understand if there are any missing values present\ntrain.isnull().sum()","1421d191":"# The Neural Network does not work well with Numerical missing values. Set to 0. This initial adjustment boosted the score of the model.\n# Lets try using an alternative measure\n# 1st option - replace with zero value\n# 2nd option - replace with mean value\ndef replace_missing(df):\n    for col in df.columns:\n        if df[col].dtype not in [str, object] and method == 'zero':\n            df[col] = df[col].fillna(0)\n\n# Default method of using a zero value\n# replace_missing(train)\n# replace_missing(test)\n# Second option of using mean value\ntrain.fillna(value=train.mean(), inplace=True)\ntest.fillna(value=test.mean(), inplace=True)","0eb4faa7":"# Check for missing\ntrain.isnull().sum()\n# test.isnull().sum()","07e24df6":"train.head(5)","bac13430":"# Use only 25% of the training data in this example - original method\ntrain_data      = train.sample(frac=0.25, random_state=42)\nvalidation_data = train.drop(train_data.index).sample(frac=0.05, random_state=42)","5d89db72":"# Split the dataset into a training and a testing dataset.\n# def split_dataset(dataset, test_ratio=0.30):\n#     \"\"\"Splits a panda dataframe in two.\"\"\"\n#     test_indices = np.random.rand(len(dataset)) < test_ratio\n#     return dataset[~test_indices], dataset[test_indices]\n\n\n# train_ds_pd, val_ds_pd = split_dataset(train)\n# print(\"{} examples in training, {} examples for testing.\".format(\n#     len(train_ds_pd), len(val_ds_pd)))","e977fbe5":"train_data['claim'].value_counts().to_frame().T","2644dee9":"validation_data['claim'].value_counts().to_frame().T","d6f06f52":"# Convert the dataset into a TensorFlow dataset.\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    train_data, label=\"claim\"\n)                                          \nval_ds = tfdf.keras.pd_dataframe_to_tf_dataset(\n    validation_data, label=\"claim\"\n)                                 \ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test)","5c881cef":"%%time\n\n# Train a Random Forest model.\nmodel = tfdf.keras.RandomForestModel()\n\n# Add evaluation metrics\nmodel.compile(\n    metrics=[\"accuracy\"]\n)\nmodel.fit(x=train_ds)\n\n# # Train a Gradient Boosted Trees model.\n# model = tfdf.keras.GradientBoostedTreesModel(num_trees=1500)\n# model.fit(train_ds)","f375b568":"# Evaluate the model\nevaluate = model.evaluate(val_ds, return_dict=True)\nprint()\n\nfor name, value in evaluate.items():\n    print(f\"{name}: {value:.4f}\")","7a02f66c":"# Model Summary\nmodel.summary()","e24aa019":"# Model features\nmodel.make_inspector().features()","72fa5d93":"# Feature importance\nmodel.make_inspector().variable_importances()","e82dfeef":"# Model self evaluation\nmodel.make_inspector().evaluation()","22fc6f7e":"logs = model.make_inspector().training_logs()\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Accuracy (out-of-bag)\")\nplt.subplot(1, 2, 2)\nplt.plot([log.num_trees for log in logs], [log.evaluation.loss for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Logloss (out-of-bag)\")\nplt.show()","bcd9cda6":"predictions = model.predict(val_ds)\ny_true      = validation_data[\"claim\"]\n\nfrom sklearn.metrics import roc_auc_score\nROC_AUC = roc_auc_score(y_true, predictions)\nprint(\"The ROC AUC score is %.5f\" % ROC_AUC )","893400f2":"sample          = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\nsample['claim'] = model.predict(test_ds)\nsample.to_csv('submission_mean_miss.csv',index=False)","fd822c2a":"# Re-train the model with a different learning algorithm\ntfdf.keras.get_all_models()","680468da":"### Future work\nPerform hyperparameter testing on the Random Forest and the Decision Forest","eb3a7ae1":"# Related reading\n* [Introducing TensorFlow Decision Forests](https:\/\/blog.tensorflow.org\/2021\/05\/introducing-tensorflow-decision-forests.html)\n* [TensorFlow Decision Forests](https:\/\/github.com\/tensorflow\/decision-forests) GitHub\n* [Yggdrasil Decision Forests](https:\/\/github.com\/google\/yggdrasil-decision-forests) GitHub\n\n**Related kaggle notebooks**\n\n* [\"*Decision Forest for dummies*\"](https:\/\/www.kaggle.com\/kritidoneria\/decision-forest-for-dummies) written by [KritiDoneria](https:\/\/www.kaggle.com\/kritidoneria) and [Laurent Pourchot](https:\/\/www.kaggle.com\/pourchot)\n* [\"*Decision Forest fed by Neural Network*\"](https:\/\/www.kaggle.com\/pourchot\/decision-forest-fed-by-neural-network) written by [Laurent Pourchot](https:\/\/www.kaggle.com\/pourchot)","a39346d6":"Calculate the score of our hold-out validation dataset","5a37bac1":"Lets try out the [`tfdf.keras.RandomForestModel`](https:\/\/www.tensorflow.org\/decision_forests\/api_docs\/python\/tfdf\/keras\/RandomForestModel)\nThe previous notebook used the [`tfdf.keras.GradientBoostedTreesModel`](https:\/\/www.tensorflow.org\/decision_forests\/api_docs\/python\/tfdf\/keras\/GradientBoostedTreesModel). Lets try to Hyperparameter tune this later.\n\n***\nOther model [`tfdf.keras.CartModel`](https:\/\/www.tensorflow.org\/decision_forests\/api_docs\/python\/tfdf\/keras\/CartModel)","6142455d":"## Notebook Aim\nExtend the analysis performed using the TensorFlow Decision Forests to understand what elements of the model can be tuned. \n***\nInitial aim is to review the [minimal](https:\/\/github.com\/tensorflow\/decision-forests\/blob\/main\/examples\/minimal.py) baseline model","bad0e761":"# [TensorFlow Decision Forests](https:\/\/www.tensorflow.org\/decision_forests): Classification example\n> \"*TensorFlow Decision Forests (TF-DF) is a collection of state-of-the-art algorithms for the training, serving and interpretation of Decision Forest models. The library is a collection of Keras models and supports classification, regression and ranking.*\"\n\nThis notebook is heavily based on the official tutorial [\"*Build, train and evaluate models with TensorFlow Decision Forests*\"](https:\/\/www.tensorflow.org\/decision_forests\/tutorials\/beginner_colab).\n\nFirst we shall install the `tensorflow_decision_forests` package","bd8a7bb4":"Now write out a `submission.csv`","8bfed3b4":"## Forked Notebook\n[Classification using TensorFlow Decision Forests](https:\/\/www.kaggle.com\/carlmcbrideellis\/classification-using-tensorflow-decision-forests) written by [Carl McBride Ellis](https:\/\/www.kaggle.com\/carlmcbrideellis)"}}