{"cell_type":{"75328438":"code","b63c2f7d":"code","0ff953b5":"code","7737bab8":"code","814433b7":"code","1e287dc0":"code","8bd1da0f":"code","e3be8c13":"code","281cfeda":"code","136e7c74":"code","ca44b356":"code","7e6600d0":"code","beb4efa1":"code","53178297":"code","237c5a4f":"code","88aa58c8":"code","3a39c0c0":"code","034493bd":"code","e5093c39":"code","9b07c0d9":"code","cb11354a":"code","0f57663a":"code","71de1b06":"code","647bc988":"code","28283806":"code","26e7008d":"code","fd13f287":"markdown"},"source":{"75328438":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b63c2f7d":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/train.csv\", index_col ='id')\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\", index_col ='id')","0ff953b5":"train.head()","7737bab8":"test.head()","814433b7":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission.head()","1e287dc0":"import matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport matplotlib.pyplot as plt","8bd1da0f":"train.target.value_counts()","e3be8c13":"train.shape","281cfeda":"test.shape","136e7c74":"\ntrain['target'] = train['target'].replace({'Class_1': 0, 'Class_2' : 1, 'Class_3' : 2, 'Class_4' : 3,\n                                      'Class_5' : 4, 'Class_6' : 5, 'Class_7' : 6, 'Class_8' : 7,\n                                      'Class_9' : 8})\ntrain['target'] = train['target'].astype(int)","ca44b356":"train.target.value_counts()","7e6600d0":"X = train.drop(['target'], axis = 1)\ny = train['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75)","beb4efa1":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","53178297":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks \n    \nmodel = keras.Sequential([\n        layers.BatchNormalization(input_shape = [75]),\n        layers.Dense(units = 128, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Dense(units = 64, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Dense(units = 32, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),    \n        layers.Dense(9, activation = 'softmax'),\n    ])\nmodel.summary()","237c5a4f":"model.compile(loss='sparse_categorical_crossentropy', \n              optimizer = keras.optimizers.Adam(learning_rate=0.001), metrics='accuracy')\n\nearly_stopping = callbacks.EarlyStopping(\n    patience=20,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\nplateau = callbacks.ReduceLROnPlateau(\n    factor = 0.5,                                     \n    patience = 2,                                   \n    min_delt = 0.000001,                                \n    cooldown = 0,                               \n    verbose = 1)\n\nhistory = model.fit(X_train, y_train,\n          batch_size = 128, epochs = 100,\n          validation_data=(X_test, y_test),\n          callbacks=[early_stopping, plateau]);\n","88aa58c8":"score = model.evaluate(X_test, y_test)\nprint('Test loss: {}'.format(score[0]))\nprint('Test accuracy: {}%'.format(score[1] * 100))","3a39c0c0":"pred = np.argmax(model.predict(X_test), axis=-1)\npred[:10]","034493bd":"from sklearn.metrics import log_loss\npred_prob = model.predict_proba(X_test)\nlogloss = log_loss(y_test, pred_prob)\nlogloss","e5093c39":"test_pred= model.predict_proba(X_test)\ntest_pred","9b07c0d9":"test_pred=pd.DataFrame(test_pred)\ntest_pred","cb11354a":"test_pred.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']","0f57663a":"test_pred.head()","71de1b06":"test_df = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\nid_col= test_df['id']","647bc988":"final_test= pd.concat([id_col,test_pred],\n                      axis=1)\nfinal_test.to_csv('submission.csv',index=False)","28283806":"submission.head()","26e7008d":"final_test.head()","fd13f287":"# Please upvote if you like it, this gives us inspiration to work more."}}