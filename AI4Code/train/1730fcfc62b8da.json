{"cell_type":{"4e0ef8a5":"code","6dd8e6c7":"code","2e836e5d":"code","844a7fa8":"code","58546588":"code","9fe18b50":"code","ed0e34a1":"code","d7884b5a":"code","39779e1c":"code","eea3f889":"code","5efc4c7a":"code","ae9e0b1d":"code","e1c373b0":"code","ddf355b0":"code","ecd40ae9":"code","ad48be95":"code","f407c58c":"markdown","d8ad837a":"markdown","479d1d97":"markdown"},"source":{"4e0ef8a5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nprint(\"Done\")","6dd8e6c7":"import torch\nimport torch.nn as nn","2e836e5d":"class Discriminator(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            # input: N x channels_img x 64 x 64\n            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            # _block(in_channels, out_channels, kernel_size, stride, padding)\n            self._block(features_d, features_d * 2, 4, 2, 1),\n            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n            ),\n            nn.InstanceNorm2d(out_channels, affine=True),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.disc(x)\n    \n\nprint(\"Discriminator declaration done\")","844a7fa8":"class Generator(nn.Module):\n    def __init__(self, channels_noise, channels_img, features_g):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(\n            # Input: N x channels_noise x 1 x 1\n            self._block(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n            self._block(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n            nn.ConvTranspose2d(\n                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n            ),\n            # Output: N x channels_img x 64 x 64\n            nn.Tanh(),\n        )\n\n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nprint(\"Generator declaration done\")","58546588":"# weight initialization function \ndef initialize_weights(model):\n    # Initializes weights according to the DCGAN paper\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n            nn.init.normal_(m.weight.data, 0.0, 0.02)\n\nprint(\"Done\")","9fe18b50":"import torch\nimport torch.nn as nn\nimport string\n\n\ndef gradient_penalty(critic, real, fake, device=\"cpu\"):\n    BATCH_SIZE, C, H, W = real.shape\n    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n    interpolated_images = real * alpha + fake * (1 - alpha)\n\n    # Calculate critic scores\n    mixed_scores = critic(interpolated_images)\n\n    # Take the gradient of the scores with respect to the images\n    gradient = torch.autograd.grad(\n        inputs=interpolated_images,\n        outputs=mixed_scores,\n        grad_outputs=torch.ones_like(mixed_scores),\n        create_graph=True,\n        retain_graph=True,\n    )[0]\n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n    return gradient_penalty\n\n\ndef save_checkpoint(gen_state, disc_state, gen_opt, disc_opt,epoch: int = 0,  filename: string = f'\/checkpoint.pth.tar'):\n    print(\"=> Saving checkpoint\")\n    state = {\n        'epoch': epoch,\n        'gen_state': gen_state,\n        'disc_state': disc_state,\n        'gen_opt': gen_opt,\n        'disc_opt': disc_opt\n    }\n    torch.save(state, filename)\n\n\ndef load_checkpoint(checkpoint, gen, disc, gen_opt, disc_opt, ) -> int:\n    print(\"=> Loading checkpoint\")\n\n    gen.load_state_dict(checkpoint['gen_state'])\n    disc.load_state_dict(checkpoint['disc_state'])\n    \n    if gen_opt and disc_opt:\n        gen_opt.load_state_dict(checkpoint['gen_opt'])\n        disc_opt.load_state_dict(checkpoint['disc_opt'])\n\n    return checkpoint['epoch']\n    \nprint(\"Utils declaration done\")","ed0e34a1":"# Clear output folder\n!rm -rf \/\n!mkdir logs\/\n\nprint(\"Logs cleaning done\")","d7884b5a":"import os\n\n# Download Ngrok to tunnel the tensorboard port to an external port\n!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport multiprocessing\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir .\/logs\/ --host 0.0.0.0 --port 6006 &\",\n                        \".\/ngrok http 6006 &\"\n                        ]]\n\nprint(\"Ngrok tunnel setup done\")","39779e1c":"! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n        \nprint(\"Ngrok tunneling done\")","eea3f889":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\nfrom torch.utils.tensorboard import SummaryWriter\n\nprint(\"Loading of libraries done\")","5efc4c7a":"# Hyperparameters etc.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nLEARNING_RATE = 1e-4\nBATCH_SIZE = 64\nIMAGE_SIZE = 64\nCHANNELS_IMG = 3\nZ_DIM = 100\n\nNUM_EPOCHS = 200\n\nFEATURES_CRITIC = 64\nFEATURES_GEN = 64\n\nCRITIC_ITERATIONS = 5\nLAMBDA_GP = 10\n\ntransforms = transforms.Compose(\n    [\n        transforms.Resize(IMAGE_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]),\n    ]\n)\n\nprint(\"Hyperparameter set up done\")","ae9e0b1d":"# load pretrained models?\nLOAD_PRETRAINED = False\nCHECKPOINT_PATH = \"..\/input\/start_checkpoint.pth.tar\"\nSTARTING_EPOCH = 0","e1c373b0":"# Initializing the models, loss functions, the dataset and the tensorboard\ndataset_grapes = datasets.ImageFolder(\n    root='..\/input\/wgisd-grapescutout-64x64\/grapes_64x64_as_jpg',\n    transform=transforms\n)\ndata_loader_grapes = DataLoader(\n    dataset=dataset_grapes,\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\n# initialize gen and disc, note: discriminator should be called critic,\n# according to WGAN paper (since it no longer outputs between [0, 1])\ngen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\ncritic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n\n#initializing weights\ninitialize_weights(gen)\ninitialize_weights(critic)\n\n# initializate optimizer\nopt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\nopt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n\n# for tensorboard plotting\nfixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n\nwriter_real = SummaryWriter(f\"logs\/real\")\nwriter_fake = SummaryWriter(f\"logs\/fake\")\nstep = 0\n\ngen.train()\ncritic.train()\n\nprint(\"Model initialization done\")","ddf355b0":"# load pretrained models\nif LOAD_PRETRAINED:\n    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n    STARTING_EPOCH=load_checkpoint(\n                        checkpoint=checkpoint,\n                        gen=gen,\n                        disc=critic,\n                        gen_opt=opt_gen,\n                        disc_opt=opt_gen\n                    )\nNUM_EPOCHS += STARTING_EPOCH","ecd40ae9":"print(f'Starting training for epochs: {NUM_EPOCHS} batch_size: {BATCH_SIZE} batch_per_epoch: {len(data_loader_grapes)}')\n\nfor epoch in range(NUM_EPOCHS):\n    epoch +=STARTING_EPOCH\n    \n    print(f\"Epoch [{epoch}\/{NUM_EPOCHS}]\")\n    \n    # Target labels not needed\n    for batch_idx, (real, _) in enumerate(data_loader_grapes):\n        real = real.to(device)\n        cur_batch_size = real.shape[0]\n        \n        # Train Critic: max E[critic(real)] - E[critic(fake)]\n        # equivalent to minimizing the negative of that\n        for _ in range(CRITIC_ITERATIONS):\n            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n            fake = gen(noise)\n            critic_real = critic(real).reshape(-1)\n            critic_fake = critic(fake).reshape(-1)\n            gp = gradient_penalty(critic, real, fake, device=device)\n            loss_critic = (\n                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n            )\n            critic.zero_grad()\n            loss_critic.backward(retain_graph=True)\n            opt_critic.step()\n\n        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n        gen_fake = critic(fake).reshape(-1)\n        loss_gen = -torch.mean(gen_fake)\n        gen.zero_grad()\n        loss_gen.backward()\n        opt_gen.step()\n\n        # Print losses occasionally and print to tensorboard\n#         if batch_idx % 10 == 0:\n#             print(\n#                 f\"Epoch [{epoch}\/{NUM_EPOCHS}] Batch {batch_idx}\/{len(data_loader_grapes)} \\\n#                   Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n#             )\n\n        if batch_idx == 0:\n            with torch.no_grad():\n                fake = gen(fixed_noise)\n                # take out (up to) 32 examples\n                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n\n                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n                writer_fake.add_image(f\"fakes\", img_grid_fake, global_step=step)\n\n            step += 1\n            \n    if epoch % 50 == 0 and epoch > 0:\n        checkpoint = {'gen': gen.state_dict(), 'crit': critic.state_dict()}\n        filename = f'checkpoint_wgangp_64x64_{epoch}epochs.pth.tar'\n        save_checkpoint(\n            gen_state=gen.state_dict(),\n            disc_state=critic.state_dict(),\n            gen_opt=opt_gen.state_dict(),\n            disc_opt=opt_critic.state_dict(),\n            filename=filename,\n            epoch=NUM_EPOCHS\n        )\n            \nprint(\"Training done\")","ad48be95":"filename = f'checkpoint_wgangp_64x64_{NUM_EPOCHS}epochs.pth.tar'\nsave_checkpoint(\n    gen_state=gen.state_dict(),\n    disc_state=critic.state_dict(),\n    gen_opt=opt_gen.state_dict(),\n    disc_opt=opt_critic.state_dict(),\n    filename=filename,\n    epoch=NUM_EPOCHS\n)","f407c58c":"# **Training**","d8ad837a":"# **Implementing the Critic (Discriminator) and the Generator**","479d1d97":"# **Declaring utils functions**"}}