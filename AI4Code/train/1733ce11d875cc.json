{"cell_type":{"ed4c1843":"code","432c0e98":"code","1e8f87fd":"code","253cb31e":"code","ce3931b8":"code","701a0479":"code","80a48025":"code","e1781e10":"code","84d7bc89":"code","02b2f77a":"code","2a9078fe":"code","31053e2a":"code","38ef3691":"code","5f35c545":"code","70444624":"code","5098c742":"code","85099354":"code","0fb0d401":"code","64b56228":"code","12faac89":"code","24d6fe92":"markdown","db5444d9":"markdown","e442365a":"markdown","cbd29d1b":"markdown","b4cd26dc":"markdown","246787d3":"markdown","a2ad6ccb":"markdown","03cceeb1":"markdown","1e1a3b07":"markdown","a5b62002":"markdown","180a6ff6":"markdown","802ed3af":"markdown","18504afc":"markdown","fdb7f65e":"markdown","6b9df52f":"markdown","f801d9cd":"markdown","43aa2202":"markdown","6f9e8f8c":"markdown","5e8b311d":"markdown","0b2fd49f":"markdown","279e09e0":"markdown","9c5e418b":"markdown","567331b4":"markdown","a563fca7":"markdown","2004140a":"markdown","07e59fec":"markdown","0676b529":"markdown","31e8b749":"markdown","eee1803e":"markdown","5f5a774c":"markdown","5aa490c5":"markdown","e79d35f9":"markdown","3e5acc79":"markdown","bec7244f":"markdown","444d43a1":"markdown","3c4a4e12":"markdown","777ab287":"markdown","adcab987":"markdown","35d50a23":"markdown","245ac4be":"markdown"},"source":{"ed4c1843":"import pandas as pd\nimport numpy as np\n\npd.read_csv('\/kaggle\/input\/monthly-robberies.csv',header=0,index_col=0,parse_dates=True,squeeze=True).head()","432c0e98":"#split into a training and validation dataset\nseries= pd.read_csv('\/kaggle\/input\/monthly-robberies.csv', header=0,index_col=0, parse_dates=True, squeeze=True)\nsplit_point= len(series) -12\ndataset, validation = series[0:split_point],series[split_point:]\nprint('Dataset %d, Validation %d' % (len(dataset),len(validation)))\ndataset.to_csv('dataset.csv')\nvalidation.to_csv('validation.csv')","1e8f87fd":"#prepare data\nX = series.values\nX = X.astype('float32')\ntrain_size = int(len(X)*0.50)\ntrain,test = X[0:train_size], X[train_size:]","253cb31e":"#evaluate a persistence model\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n#load data\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=0,index_col=0,parse_dates=True,squeeze=True)\n\n#prepare data\nX = series.values\nX = X.astype('float32')\ntrain_size = int(len(X)* 0.50)\ntrain, test = X[0:train_size],X[train_size:]\n\n#walk forward validation\nhistory = [x for x in train]\npredictions = list()\n\nfor i in range(len(test)):\n    #predict\n    yhat = history[-1]\n    predictions.append(yhat)\n    #observation\n    obs= test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n#report performance\nrmse = sqrt(mean_squared_error(test,predictions))\nprint('RMSE: %.3f' % rmse)","ce3931b8":"print(series.describe())","701a0479":"#line plots of time series\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,8))\nseries.plot()\nplt.show()","80a48025":"# density plots of time series\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\nplt.figure(1,figsize=(10,8))\nplt.subplot(211)\nseries.hist()\nplt.subplot(212)\nseries.plot(kind='kde')\nplt.show()\n","e1781e10":"series = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\nprint(series)\ngroups = series['1966':'1973'].groupby(pd.Grouper(freq='A'))\nyears = pd.DataFrame()\nfor name, group in groups:\n    years[name.year] = group.values\nplt.figure(figsize=(10,8))\nyears.boxplot()\nplt.show()","84d7bc89":"#statistical test for the stationarity fof the timeseries\nfrom statsmodels.tsa.stattools import adfuller\n\n#create a differenced time series\ndef difference(dataset):\n    diff = list()\n    for i in range(1,len(dataset)):\n        value = dataset[i] - dataset[i-1]\n        diff.append(value)\n    return pd.Series(diff)\n\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\nX = series.values\n# difference datra\nstationary = difference(X)\nstationary.index = series.index[1:]\n\n#check if stationary\nresult = adfuller(stationary)\nprint('ADF statistic: %f' % result[0] )\nprint('p-value: %f' % result[1])\nprint('Critical values:')\nfor key,value in result[4].items():\n    print('\\t%s: %.3f' % (key,value))\n\n#save\nstationary.to_csv('stationary.csv')","02b2f77a":"# ACF and PACF plots of the time series\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\nplt.figure(figsize=(10,8))\nplt.subplot(211)\nplot_acf(series,lags=50,ax=plt.gca())\nplt.subplot(212)\nplot_pacf(series,lags=50,ax=plt.gca())\nplt.show()","2a9078fe":"#evaluate manually configured ARIMA model\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom math import sqrt\n\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\n\nX = series.values\nX = X.astype('float32')\ntrain_size = int(len(X)*0.50)\ntrain, test = X[0: train_size],X[train_size:]\n#walkforward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    #predict\n    model = ARIMA(history, order=(0,1,2))\n    model_fit= model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    #observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%3.f'% (yhat, obs))\n#report performance\nrmse = sqrt(mean_squared_error(test,predictions))\nprint('RMSE: %.3f' % rmse)","31053e2a":"import warnings\nimport pandas as pd\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n#evaluate an ARIMA model for a given order (p,d,q) and return RMSE\ndef evaluate_arima_model(X, arima_order):\n    #prepare training dataset\n    X = X.astype('float32')\n    train_size = int(len(X) * 0.50)\n    train, test = X[0:train_size],X[train_size:]\n    history = [x for x in train]\n    #make predictions\n    predictions = list()\n    for t in range(len(test)):\n        model = ARIMA(history,order=arima_order)\n        model_fit = model.fit(disp=0)\n        yhat= model_fit.forecast()[0]\n        predictions.append(yhat)\n        history.append(test[t])\n    #calculate out of sample error\n    rmse = sqrt(mean_squared_error(test,predictions))\n    return rmse\n\ndef evaluate_models(dataset,p_values, d_values, q_values):\n    data = dataset.astype('float32')\n    best_score, best_cfg = float('inf'), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    rmse = evaluate_arima_model(dataset, order)\n                    if rmse < best_score:\n                        best_score, best_cfg = rmse,order\n                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n                except:\n                    continue\n    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n    \n# load dataset\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None, index_col=0,parse_dates=True,squeeze=True)\n#evaluate parameters\np_values = range(0,13)\nd_values = range(0,4)\nq_values = range(0,13)\nwarnings.filterwarnings('ignore')\n# evaluate_models(series.values,p_values,d_values,q_values)\n        ","38ef3691":"series = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\n#prepare data\nX = series.values\nX = X.astype('float32')\ntrain_size= int(len(X)*0.5)\ntrain,test = X[:train_size],X[train_size:]\n#walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    #predict\n    model = ARIMA(history, order=(0,1,2))\n    model_fit=model.fit(disp=0)\n    yhat=model_fit.forecast()[0]\n    predictions.append(yhat)\n    #observation\n    obs = test[i]\n    history.append(obs)\n# errors\nresiduals = [test[i] - predictions[i] for i in range(len(test))]\nresiduals = pd.DataFrame(residuals)\nplt.figure(figsize=(10,8))\nplt.subplot(211)\nresiduals.hist(ax=plt.gca())\nplt.subplot(212)\nresiduals.plot(kind='kde',ax=plt.gca())\nplt.show()","5f35c545":"series = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None, index_col=0,parse_dates=True,squeeze=True)\nX = series.values\nX = X.astype('float32')\ntrain_size = int(len(X) * 0.5)\ntrain, test = X[:train_size],X[train_size:]\n#walk forward validation\nhistory = [x for x in train]\npredictions=list()\nfor i in range(len(test)):\n    model = ARIMA(history, order=(0,1,2))\n    model_fit= model.fit(disp=0)\n    yhat=model_fit.forecast()[0]\n    predictions.append(yhat)\n    obs= test[i]\n    history.append(obs)\n#errors\nresiduals = [test[i]-predictions[i] for i in range(len(test))]\nresiduals = pd.DataFrame(residuals)\nplt.figure(figsize=(10,8))\nplt.subplot(211)\nplot_acf(residuals,lags=25,ax=plt.gca())\nplt.subplot(212)\nplot_pacf(residuals,lags=25,ax=plt.gca())\nplt.show()","70444624":"from scipy.stats import boxcox\nfrom statsmodels.graphics.gofplots import qqplot\n\nX = series.values\ntransformed, lam =boxcox(X)\nprint(\"Lambda: %f\" % lam)\nplt.figure(1,figsize=(10,8))\nplt.subplot(311)\nplt.plot(transformed)\n#histogram\nplt.subplot(312)\nplt.hist(transformed)\nplt.subplot(313)\nqqplot(transformed, line='r',ax=plt.gca())\nplt.show()","5098c742":"#invert Box-Cox transform\nfrom math import log,exp\ndef boxcox_inverse(value,lam):\n    if lam == 0:\n        return exp(value)\n    return exp(log(lam * value + 1)\/ lam)","85099354":"#evaluate ARIMA models with box-cox transformed time series\n\nseries = pd.read_csv('\/kaggle\/working\/dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\n#prepare data\nX = series.values\nX - X.astype('float32')\ntrain_size = int(len(X)*0.5)\ntrain, test= X[:train_size],X[train_size:]\n#walk-forward validation\nhistory=[x for x in train]\npredictions= list()\nfor i in range(len(test)):\n    #transform\n    transformed, lam = boxcox(history)\n    if lam < -5:\n        transformed, lam= history, 1\n    # predict\n    model = ARIMA( transformed, order=(0,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    #invert transformed prediction\n    yhat = boxcox_inverse(yhat,lam)\n    predictions.append(yhat)\n    \n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n#report performance\nrmse = sqrt(mean_squared_error(test,predictions))\nprint('RMSE: %.3f' % rmse)","0fb0d401":"# finalize model and save to file\nimport numpy as np\n\n#monkey patch around bug in ARIMA class\ndef __getnewargs__(self):\n    return ((self.endog),(self.k_lags, self.k_diff, self.k_ma))\n\nARIMA.__getnewargs__  = __getnewargs__\n\n#load data\nseries = pd.read_csv('dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\n#prepare data\nX = series.values\nX = X.astype('float32')\n\ntransformed, lam = boxcox(X)\n\nmodel = ARIMA(transformed, order=(0,1,2))\nmodel_fit= model.fit(disp=0)\n\nmodel_fit.save('model.pkl')\nnp.save('model_lambda.npy',[lam])","64b56228":"#load the finalized model and make a prediction\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom math import exp,log\n\nmodel_fit= ARIMAResults.load('model.pkl')\nlam = np.load('model_lambda.npy')\nyhat = model_fit.forecast()[0]\nyhat = boxcox_inverse(yhat,lam)\nprint('Predicted: %.3f' % yhat)","12faac89":"#load and prepare datasets\ndataset = pd.read_csv('dataset.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\nX = dataset.values.astype('float32')\nhistory = [x for x in X]\nvalidation = pd.read_csv('validation.csv',header=None,index_col=0,parse_dates=True,squeeze=True)\ny = validation.values.astype('float32')\n#load model\nmodel_fit = ARIMAResults.load('model.pkl')\nlam = np.load('model_lambda.npy')\n#make first prediction\npredictions = list()\nyhat = model_fit.forecast()[0]\nyhat = boxcox_inverse(yhat,lam)\npredictions.append(yhat)\nhistory.append(y[0])\nprint('>Predicted=%.3f, Expected=%.3f' % (yhat,y[0]))\n#rolling forecasts\nfor i in range(1,len(y)):\n    transformed,lam = boxcox(history)\n    if lam < -5:\n        transformed, lam = history, 1\n    #predict\n    model = ARIMA(transformed, order=(0,1,2))\n    model_fit= model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    #invert transformed prediction\n    yhat = boxcox_inverse(yhat,lam)\n    predictions.append(yhat)\n    #observation\n    obs = y[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%3.f' % (yhat,obs))\n#report performance\nrmse = sqrt(mean_squared_error(y,predictions))\nprint('RMSE: %.3f' %rmse)\nplt.plot(y)\nplt.plot(predictions,color='red')\nplt.show()","24d6fe92":"### Test Strategy\n\nCandidate models will be evaluated using walk-forward validation. This is because a rolling forecast type model is required from the problem definition. This is where one-stemp forecasts are needed given all available data. The walk-forward validation will work as follows:\n\n1. The first 50% of the dataset will be held back to train the model.\n2. The remaining 50% of the dataset will be iterated and test the model\n3. For each step in the test dataset:\n    a. A model will be trained.\n    b. A one-step prediction made and the prediction stored for later evaluation.\n    c. The actual observation from the test dataset will be added to the training dataset for the next iteration.\n4. The predictions made during the iteration of the test dataset will evaluated and an RMSE score reported.\n\nGiven the small size of the data, we will allow the model to be retrained given all available data prior to each prediction. We can write the code for the test harness using simple NumP and Python code. Firstly, we can split the dataset into train and test sets directly. We are careful to always convert the loaded dataset to `float32` in case the loaded data still has some String or Integer data types.","db5444d9":"### 1.5.2 Line Plot\n\nA line plot of a time series can provide a lot of insight into the problem. The example below creates and shows a line plot of the dataset.","e442365a":"### Density Plot\n\nReviewing plots of the density of observations can provide further insight into the structure of the data. The example below cretes a histogram and density plot of the observations without any temporal structure.","cbd29d1b":"### 1.6.1 Manually Configured ARIMA\nNonseasonal ARIMA(p,d,q) requires three parameters and is traditionally configured manually. Analysis of the time series data assumes that we are working with a stationary time series. The time series is almost certainly non-stationary. We can make it stationary by first differencing the series and using a statistical test to confirm that the result is stationary. The example below creates a stationary version of the series and saves it to file stationary.csv","b4cd26dc":"The final RMSE of the model on the transformed data was 49.102. This is a smaller error than the ARIMA model untransformed data, but only slightly, and may or may not be statistically different.","246787d3":"Observation: \n* The median values for each year(green line) show a trend that may not be linear.\n* The spread, or middle 50% of the data (blue boxes), differ, but perhaps not consistently over time.\n* The earlier years, perhaps first 2, are quite different from the rest of the dataset.","a2ad6ccb":"### 1.6.2 Grid Search ARIMA Hyperparameters\n\nMany ARIMA configurations are unstable on this dataset, but there may be other hyperparameters that result in a well-performing model. In this section, we will search values of p, d, and q for combinations that do not result in error, and find the combination that results in the best performance. We will use a grid search to explore all combinations in a subset of integer values. Specifically, we will search all combinations of the following parameters:\n* p: 0 to 12\n* d: 0 to 3\n* q: 0 to 12\n\nThis is (13 * 4 * 13) of 676 runs of the test harness and will take some time to execute. The complete worked example with the grid search version of the test harness is:","03cceeb1":"Observations:\n* The large fluctuations have been removed from the line plot of the time series.\n* The histogram shows a flatter or more uniform distribution of values.\n* The Q-Q plot is reasonable, but still not a perfect fit for a Gaussian distribution","1e1a3b07":"# 1.2 Problem Description\nThe problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, or just under 10 years of data. The values are a count and there are 118 observations. The dataset is credited to McCleary and Hay(1980). Below is a sample of the first few rows of the dataset.","a5b62002":"# 1.3 Test Harness\n\nWe must develop a test harness to investigate the data and evaluate candidate models. This involves two steps:\n1. Defining a Validation Dataset.\n2. Developing a Method for Model Evaluation","180a6ff6":"The first step before getting bogged down in data analysis and modelling is to establish a baseline performance. This will provide both a template for evaluating models using the proposed test harness and a performance measure by which all more elaborate predictive models can be compared. The baseline prediction for time series forecasting is called the naive forecast, or persistence. This is where the observation from the previous time step is used as the prediction for the observation at the next time step. We can plug this directly into the test harness defined in the previous section. The complete code listing is provided below.","802ed3af":"Running the code outputs the result of a statistical significance test of whether the 1-lag differenced series is stationary. Specifically, the augumented Dickey-Fuller test. The results show that the test statistic value -3.980946 is smaller than the critical value at 5% of -2.893. This suggests that we can reject the null hypothesis with a significace level of less that 5%. Rejecting the null hypothesis means that the process has no unit root and in turn that the 1-lag differenced time series is stationary or does not have time dependent structure.\n\nThis suggests that atleast one level of differencing is required. The d parameter in our ARIMA model should at least be a value of 1. The next step is to select the lag values for the Autoregression(AR) and Moving Average(MA) parameters, p and q respectively. We can do this by reviewing Autocorrelation Function and Partial Autocorrelation Function plots . ","18504afc":"We get a RMSE of 49.821, which is lower than the persistence model.\nThis is a good start, but we may be able to get improved results with a better configured ARIMA model","fdb7f65e":"### 1.5.1 Summary Statistics\nSummary statistics provides a quick look at the limits of the observed values. It can help to get a quick idea of what we are working with. The example below calculates and prints summary statistics for the time series.","6b9df52f":"# 1.4 Persistence","f801d9cd":"# 1.3.2 Model Evaluation","43aa2202":"### 1.5.4 Box and Whisker Plots\nWe can group the monthly data by year and get an idea of the spread of observations for each year and how this may be changing. We do expect to see some trend (increasing mean or median), but ir may be interesting to see how the rest of the distribution may be changing . Lets group the observations by year and create one box and whisker plot for each year of observations. The last year(1974) only contains 10 months and may not be a useful comparison with the other 12 months of observations in the other years. Therefore only data between 1966 and 1973 is plotted","6f9e8f8c":"# 1.6 ARIMA Models\nIn this section, we will develop Autoregressive Integrated Moving Average models for the problem. We will approach this is four steps:\n1. Developing a manually configured ARIMA model.\n2. Using a grid search of ARIMA to find an optimized model.\n3. Analysis of forecast residual errors to evaluate any bias in the model.\n4. Explore improvements to the model using power transforms.","5e8b311d":"The results suggest that what little autocorrelation is present in the time series has been captured by the model","0b2fd49f":"Observations from the plots;\n* The ACF shows a significant lag for 10-11 months\n* The PACF shows a significant lag for perhaps 2 months\n* Both ACF and PACF show a drop-off at the same point, perhaps suggesting a mis of AR and MA.\n\nA good starting point for p and q values is 1 or 2\n\nThis quick analysis suggests an ARIMA(11,1,2) on the raw data may be a good starting point. Experimentation shows that this configuration of ARIMA does not converge and results in errors by the underlying library as do similarly large AR values. Some experimentation shows that the model does not appear to be stable, with non-zero AR and MA orders defined at the same time. The model can be simplified to ARIMA(0,1,2). The example below demonstrates the performance of this ARIMA model on the test harness.","279e09e0":"### 1.7.2 Make Prediction\n\nA natural case may be to load the model and make a single forecast. This is relatively straightforward and involves restoring the saved model and the lambda and calling the forecast() function. ","9c5e418b":"# 1.5 Data Analysis\n\nWe can use the summary statistics and plots of the data to quickly learn more about the structure of the prediction problem. In this section, we will look at the data from four perspectives:\n1. Summary Statistics.\n2. Line Plot.\n3. Density Plots.\n4. Box and Whisker Plot.","567331b4":"### 1.6.4 Box-Cox Transformed Dataset","a563fca7":"Running the grid search through all combinations reports the results on those that converge without error. The example takes a little less than 2 hours to run on modern hardware.\nTher results show that the best configuration discovered was AARIMA(0,1,2). coincidently that was demonstrated in the previous section.","2004140a":"# 1.1 Introduction\n\nIn this tutorial, we will work through a time series forecasting project from end-to-end, from defining the problem to training a final model and making predictions. This notebook is not exhaustive but shows how you can get good results quickly by working through a time series forecasting problem systematically. The steps of this project that we will work through are as follows:\n1. Problem Description.\n2. Test Harness.\n3. Persistence.\n4. Data Analysis.\n5. ARIMA Models.\n6. Model Validation.\n\nThis will provide a template for working through a time series prediction problem that you can use on your own dataset.","07e59fec":"# 1.7 Model Validation\nAfter Models have been developed and a final model selected, it must be validated and finalized. Validation is an optional part of the process, but one that provides a last check to ensure we have not fooled or lied to ourselves. This section includes the following steps:\n* **Finalize Model** : Train and save the final model.\n* **Make Prediction** : Load the finalized model and make a prediction.\n* **Validate Model** : Load and validate the final model.","0676b529":"This creates two plots. The graphs suggest a Gaussian-like distribution with a longer right tail. This is perhaps a sign that the predictions are biased and in this case that perhaps a power-based transform of the raw data before modeling might be useful.","31e8b749":"Some observations from the statistics include:\n* The number of observations (count) matches our expectation, meaning we are handling the data correctly.\n* The mean is about 173, which we might consider our level in this series.\n* The standard deviation is relatively large at 112 robberies.\n* The percentiles along with the standard deviation do suggest a large spread to the data.\n\nThe Large spread in this series will like make highly accurate predictions difficuly if it is caused by random fluctuation","eee1803e":"Observations include:\n* There is an increasing trend of robberies over time.\n* There do not appear to be any obvious outliers.\n* There are relatively large fluctuations from year to year, up and down.\n* The fluctuations at later yaer appear larger than fluctuations at earlier years.\n* The trend means the dataset is almost certainly non-stationary and the apparent change in fluctuation may also contribute.\n","5f5a774c":"### 1.6.3 Review Residual Errors\n\nA good final check of a model is to review residual forecast errors. Ideally, the distribution of residual errors should be a Gaussian with a zero mean. We can check this by plotting residuals with a histogram and density plots. The example below calculates the residual errors for predictions on the test set and creates these density plots.","5aa490c5":"# 1.3.1 Validation Dataset","e79d35f9":"It is also a good idea to check the time series of the residual errors for any type of autocorrelation. If present, it would suggest that the model has more opportunity to model the temporal structure in the data. The example below recalculates the residual errors and creates ACF and PACF plots to check for any significant autocorrelation.","3e5acc79":"### 1.7.1 Finalize Model\nFinalizing the model involves fitting an ARIMA model on the entire dataset, in this case, on a transformed version of the entire dataset. Once fit, the model can be saved to file for later use.\nBecause a Box-Cox transform is also performed on the data, we need to know the chosen lambda so that any predictions from the model can be converted back to the original, untransformed scale.","bec7244f":"Observations; \n* The distribution is not Gaussian\n* The distribution is left shifted and may be exponential or a double Gaussian","444d43a1":"### 1.7.3 Validate Model\n\nWe can load the model and use it in a pretend operational manner. In the test harness setcion, we saved the final 12 months of the original dataset in a separate file to validate the final model. We can load this validation.csv file now and use it to see how well our model really is on unseen data. There are two ways we might proceed:\n* Load the model and use it to forecast the next 12 months. The forecast beyond the firest one or two months will quickly start to degrade in skill.\n* Load the model and use it in a rolling-forecast manner updating the transform and model for each time step. This is the preferred method as it is how one would use this model in practice as it wouls achieve the best performance.","3c4a4e12":"A plot of the predictions compared to the validation dataset is also provided. The forecasrt does have the charateristic of a persistence forecast. This does suggest that although this time series does have an obvious trend, it is still a reasonably difficult problem","777ab287":"The dataset is not current. This means that we cannot easily collect updated data to validate the model. Therefore we will pretend that it is October 1974 and withhold the last one year of data from analysis and model selection. This final year of data will be used to validate the final model. The code below will load the dataset as a Pandas Series and split it into two, one for model development (dataset.csv) and the other for validation (validation.csv).","adcab987":"Model evaluation will only be performed on the data in dataset.csv prepared in the previous section. Model evaluation involves two elements:\n\n1. Performance Measure.\n2. Test Strategy.\n\n### Performance Measure \nThe observations are a count of robberies. We will evaluate the performance of predictions using the root mean squared error(RMSE). This will give more weight to predictions that are grossly wrong and will have the same units as the original data. Any transforms to the data must be reversed before the RMSE is calculated and reported to make the performance between different methods directly comparable.\n\nWe can calculate the RMSE using the helper function from the scikit-learn library mean_squared_error() that calculates the mean squared error between a list of expected values and the predictions. We can then take the square root of this value to give us a RMSE score.","35d50a23":"Running the test harness prints the prediction and observation for each iteration of the test dataset. The RMSE of the persistence model here is `51.844`. This means on average, the model was wrong by about 51 robberies for each prediction made.","245ac4be":"The specific contents of these files are:\n* dataset.csv : Observations from January 1966 to October 1974 (106 observations)\n* validation.csv : Observations from November 1974 to Octover 1975 (12 observations)\n\nThe validation set is 10 % of the original dataset."}}