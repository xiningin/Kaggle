{"cell_type":{"df5ea38e":"code","a83fcfc4":"code","4f0a6424":"code","87cd9b95":"code","10d5bacd":"code","ba721861":"code","ef965743":"code","3f04ea49":"code","3e60d2a7":"code","5ddde77f":"code","9946895f":"code","1aceaa73":"code","ea8b319d":"code","adf1db0a":"code","71263bd9":"code","c214ef73":"code","4e5ea624":"code","ea5ac1ea":"code","01c71766":"code","2a40abe8":"code","72e88b20":"code","a3e02d30":"code","7270ce93":"code","ec682678":"code","82b77f74":"code","4def283b":"code","f88b2fdd":"markdown","c36affdb":"markdown","222359d6":"markdown","cdc72d72":"markdown","417ba9e5":"markdown","5719c178":"markdown","99422acf":"markdown","96e3e74e":"markdown","06430f6d":"markdown","3a2b9af0":"markdown","522f48d0":"markdown","696fda8e":"markdown","52cf4065":"markdown","88ef6cb9":"markdown","0929a555":"markdown","901cf6e4":"markdown","b0f50699":"markdown","e7ab3687":"markdown"},"source":{"df5ea38e":"from sklearn import datasets\n\niris = datasets.load_iris()","a83fcfc4":"print(dir(iris))","4f0a6424":"print(iris.target_names)","87cd9b95":"print(iris.target)","10d5bacd":"import numpy as np\n\nnp.bincount(iris.target)","ba721861":"import pandas as pd\n\nx = pd.DataFrame(iris.data)\nx.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']\nx['Target'] = iris.target\nx['Target_Names'] = [iris.target_names[i] for i in iris.target]","ef965743":"x","3f04ea49":"import matplotlib.pyplot as plt\n\nfig = plt.subplot()\n\ncol_1 = 'Petal_Width'\ncol_2 = 'Sepal_Length'\n\ncolors = ['blue', 'red', 'green']\n\nfor label, color in zip(range(len(iris.target_names)), colors):\n    fig.scatter(x[col_1][x.Target==label], \n                x[col_2][x.Target==label],\n                label=iris.target_names[label],\n                c=color)\n\nfig.set_xlabel(col_1)\nfig.set_ylabel(col_2)\nfig.legend(loc='upper left')\nplt.show()","3e60d2a7":"import matplotlib.pyplot as plt\n\nfig = plt.subplot()\n\nindex_sepal_length = 0\nindex_sepal_width = 1\nindex_petal_lentgh = 2\nindex_petal_width = 3\n\ncolors = ['blue', 'red', 'green']\n\nfor label, color in zip(range(len(iris.target_names)), colors):\n    fig.scatter(iris.data[iris.target==label, index_petal_width], \n                iris.data[iris.target==label, index_sepal_length],\n                label=iris.target_names[label],\n                c=color)\n\nfig.set_xlabel(iris.feature_names[index_petal_width])\nfig.set_ylabel(iris.feature_names[index_sepal_length])\nfig.legend(loc='upper left')\nplt.show()","5ddde77f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\niris_dtrain, iris_dtest, iris_ttrain, iris_ttest = train_test_split(iris.data, iris.target, test_size=0.2, random_state=4)\n","9946895f":"print(iris_dtrain.shape)\nprint(iris_dtest.shape)","1aceaa73":"print(iris_ttrain.shape)\nprint(iris_ttest.shape)","ea8b319d":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(iris_dtrain, iris_ttrain)\niris_tpred = knn.predict(iris_dtest)\nscore = metrics.accuracy_score(iris_ttest, iris_tpred)","adf1db0a":"score","71263bd9":"!pip install rake_nltk","c214ef73":"import json\n\nwith open('..\/input\/articles\/articles\/article1.json') as json_data:\n    data_dict = json.load(json_data)\n","4e5ea624":"data_dict","ea5ac1ea":"from rake_nltk import Rake\n\nr = Rake(language='french', max_length=3)\nr.extract_keywords_from_text(data_dict['contenuArticle'])\nr.get_ranked_phrases()","01c71766":"!python -m spacy download fr\n!python -m spacy download fr_core_news_md","2a40abe8":"import spacy\nimport json\n\nfrom spacy import displacy\nnlp = spacy.load('fr')\n\nwith open('..\/input\/articles\/articles\/article1.json') as json_data:\n    data_dict = json.load(json_data)\n\ndoc = nlp(data_dict['contenuArticle'])\ntokens = [x.text for x in doc]\nprint(tokens)","72e88b20":"import string\nfrom nltk.corpus import stopwords\n\nstopWords = stopwords.words('french')\nstopWords.extend(list(string.punctuation))","a3e02d30":"filtered_tokens = [tok for tok in tokens if tok not in stopWords]\nprint(filtered_tokens)","7270ce93":"token_sent = [x.text for x in doc.sents]\nprint(token_sent)","ec682678":"for token in nlp(token_sent[0]):\n    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\\t{8}\".format(\n        token.text,\n        token.idx,\n        token.lemma_,\n        token.is_punct,\n        token.is_space,\n        token.shape_,\n        token.pos_,\n        token.tag_,\n        token.ent_type_\n    ))","82b77f74":"[(x.text, x.label_) for x in doc.ents]","4def283b":"from spacy import displacy\n\ndisplacy.render(doc, style=\"ent\", jupyter=True)","f88b2fdd":"## **2. L'algorithme des k plus proches voisins (knn)**","c36affdb":"**Visualisation des donn\u00e9es**","222359d6":"[Autres m\u00e9thodes d'extraction de mots cl\u00e9s](https:\/\/towardsdatascience.com\/keyword-extraction-process-in-python-with-natural-language-processing-nlp-d769a9069d5c)","cdc72d72":"### Tokenisation par phrases","417ba9e5":"# **Introduction \u00e0 scikit-learn**\n\nScikit-learn est une biblioth\u00e8que Python d\u00e9di\u00e9e \u00e0 l'apprentissage automatique. Elle donne acc\u00e8s \u00e0 un grand nombre d'algorithmes courants. Elle int\u00e9gre plusieurs ensembles de donn\u00e9es, par exemple les de donn\u00e9es iris, diabetes.\n\nNous allons commencer les donn\u00e9es.\n\n## **1. Le jeu de donn\u00e9es Iris**\n\nIris est ensemble de donn\u00e9es bien connu qui d\u00e9crit 50 exemples de chacune des 3 esp\u00e8ces de fleurs d'iris (Iris setosa, Iris virginica et Iris versicolor).\n\nLes caract\u00e9ristiques des donn\u00e9es iris sont:\n\n* longueur des s\u00e9pales en cm\n* largeur des s\u00e9pales en cm\n* longueur des p\u00e9tales en cm\n* largeur des p\u00e9tales en cm\n\nLes classes sont les suivantes:\n\n* Iris Setosa\n* Iris Versicolor\n* Iris Virginie\n\n\n![bbb](https:\/\/user.oc-static.com\/upload\/2017\/10\/24\/15088528667743_iris.png)","5719c178":"### **Tracer la courbe pour k=5 \u00e0 50**","99422acf":"### Reconnaissance d'entit\u00e9s nomm\u00e9es","96e3e74e":"# **Projet**\n\n","06430f6d":"[TP \u00e0 faire](https:\/\/www.labri.fr\/perso\/zemmari\/ia_data\/pdfs\/td03.pdf)(\n[T\u00e9l\u00e9charger les donn\u00e9es](https:\/\/www.labri.fr\/perso\/zemmari\/datasets\/fruits.csv))","3a2b9af0":"**Nombre d'exemples pour chaque esp\u00e8ce**","522f48d0":"### Lien Traitement automatique des langues\n\n[https:\/\/maelfabien.github.io\/machinelearning\/NLPfr\/#5-reconnaissance-dentit%C3%A9s-nomm%C3%A9es-ner](https:\/\/maelfabien.github.io\/machinelearning\/NLPfr\/#5-reconnaissance-dentit%C3%A9s-nomm%C3%A9es-ner)","696fda8e":"### **1.1 Chargement des donn\u00e9es**","52cf4065":"### Enlever les mots les plus fr\u00e9quents","88ef6cb9":"### **1.2 Mettre le donn\u00e9es dans un DataFrame**","0929a555":"## **3. Traitement automatique de la langue (TAL)**\n\n\n### **3.1 Extraction de mots cl\u00e9s**","901cf6e4":"**Liste des classes (esp\u00e8ces)**","b0f50699":"### Tokenisation","e7ab3687":"## **3.2 Spacy**\n\n### T\u00e9l\u00e9charger les mod\u00e8les fran\u00e7ais"}}