{"cell_type":{"dfdeb4a2":"code","1e366d6b":"code","a5ebd975":"code","3cec1a2f":"code","de1b6613":"code","553a6fc4":"code","158fdf98":"code","95192063":"code","0b3a5250":"code","a9930c42":"code","fef5853a":"code","31901cbc":"markdown"},"source":{"dfdeb4a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1e366d6b":"# we must import data after import libraries\n#lets do it\nmovie=pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\nrating = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")","a5ebd975":"#now it's time we get the know our data\nmovie.head(10)","3cec1a2f":"#we don't need \"genres\" feature so we drop that column\nmovie=movie.drop([\"genres\"],axis=1)","de1b6613":"rating = rating.loc[:,[\"userId\",\"movieId\",\"rating\"]]\nrating.head(10)\n","553a6fc4":"# now we have an idea about the data\n# lets processing a little more\ndata = pd.merge(movie,rating)","158fdf98":"# now lets look at our data \ndata.head(10)","95192063":"#its looking ready to process almost.\n#but we have so important problem.\n#data is too big.\ndata.shape","0b3a5250":"#data has 20 milions row\n#we can't not use all and already we don't need it\n#this kernel was written for learning purposes \ndata = data.iloc[:1000000,:]\n#one millions sample is enough for we \n","a9930c42":"#lets make a pivot table in order to make rows are users and columns are movies.\npivot_table = data.pivot_table(index = [\"userId\"],columns = [\"title\"],values = \"rating\")\npivot_table.head(10)","fef5853a":"# now it's time to get our results\n# I want to try for \"Toy Story\"\nmovie_watched = pivot_table[\"Toy Story (1995)\"]\nsimilarity_with_other_movies = pivot_table.corrwith(movie_watched) \nsimilarity_with_other_movies = similarity_with_other_movies.sort_values(ascending=False)\nsimilarity_with_other_movies.head()","31901cbc":"This system recommended the \"Gospa\" to us according to 1 million data.\nAs someone who loves \"Toy Story\" I will watch \"Gospa\"."}}