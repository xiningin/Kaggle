{"cell_type":{"5025e7a1":"code","9d8b1bcb":"code","983ef98f":"code","7cfbfbf8":"code","2a1aae9b":"code","dbc2f718":"code","0335086d":"code","0f272c83":"code","c9603ba4":"code","8ec4f4a8":"code","00f963ec":"code","83388fa1":"code","3d38a5ab":"code","48c24216":"code","2ce3f952":"code","774f9a62":"code","19254517":"code","c8325636":"code","a1411733":"code","0590938d":"code","343cc7f8":"code","a974b47a":"code","7e30b866":"markdown","a70c1b76":"markdown","fdc7bcac":"markdown","b06c227b":"markdown","f2053f76":"markdown"},"source":{"5025e7a1":"import numpy as np \nimport pandas as pd \nimport json\nimport bq_helper\nfrom pandas.io.json import json_normalize\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\nimport lightgbm as lgb\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dropout, Dense, Embedding, SpatialDropout1D, concatenate, BatchNormalization, Flatten\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import Callback\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.losses import mean_squared_error as mse_loss\n\nfrom keras import optimizers\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","9d8b1bcb":"# https:\/\/www.kaggle.com\/julian3833\/1-quick-start-read-csv-and-flatten-json-fields\n\ndef load_df(csv_path='..\/input\/train.csv', JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']):\n\n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'})\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n\n    return df","983ef98f":"%%time\ntrain = load_df(\"..\/input\/train.csv\")","7cfbfbf8":"%%time\ntest = load_df(\"..\/input\/test.csv\")","2a1aae9b":"train['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True)\ntest['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True)\ntrain['trafficSource.isTrueDirect'].fillna(False, inplace=True)\ntest['trafficSource.isTrueDirect'].fillna(False, inplace=True)\n\ntrain['date'] = pd.to_datetime(train['date'].apply(lambda x: str(x)[:4] + '-' + str(x)[4:6] + '-' + str(x)[6:]))\ntest['date'] = pd.to_datetime(test['date'].apply(lambda x: str(x)[:4] + '-' + str(x)[4:6] + '-' + str(x)[6:]))","dbc2f718":"cols_to_drop = [col for col in train.columns if train[col].nunique(dropna=False) == 1]\ntrain.drop(cols_to_drop, axis=1, inplace=True)\ntest.drop([col for col in cols_to_drop if col in test.columns], axis=1, inplace=True)\n\n#only one not null value\ntrain.drop(['trafficSource.campaignCode'], axis=1, inplace=True)\n\nfor col in ['visitNumber', 'totals.hits', 'totals.pageviews', 'totals.transactionRevenue']:\n    train[col] = train[col].astype(float)\n    \ntrain['totals.transactionRevenue'] = train['totals.transactionRevenue'].fillna(0)\ntrain['totals.transactionRevenue'] = np.log1p(train['totals.transactionRevenue'])","0335086d":"train['totals.bounces'] = train['totals.bounces'].fillna(0)\ntrain['totals.newVisits'] = train['totals.newVisits'].fillna(0)\ntrain['totals.pageviews'] = train['totals.pageviews'].fillna(0)\ntrain['totals.transactionRevenue'] = train['totals.transactionRevenue'].fillna(0)\ntrain['trafficSource.adContent'] = train['trafficSource.adContent'].fillna(0)\ntrain['trafficSource.keyword'] = train['trafficSource.keyword'].fillna(0)\ntrain['trafficSource.adwordsClickInfo.adNetworkType'] = train['trafficSource.adwordsClickInfo.adNetworkType'].fillna(0)\ntrain['trafficSource.adwordsClickInfo.gclId'] = train['trafficSource.adwordsClickInfo.gclId'].fillna(0)\ntrain['trafficSource.adwordsClickInfo.page'] = train['trafficSource.adwordsClickInfo.page'].fillna(0)\ntrain['trafficSource.adwordsClickInfo.slot'] = train['trafficSource.adwordsClickInfo.slot'].fillna(0)\n\ntest['totals.bounces'] = test['totals.bounces'].fillna(0)\ntest['totals.newVisits'] = test['totals.newVisits'].fillna(0)\ntest['totals.pageviews'] = test['totals.pageviews'].fillna(0)\ntest['trafficSource.adContent'] = test['trafficSource.adContent'].fillna(0)\ntest['trafficSource.keyword'] = test['trafficSource.keyword'].fillna(0)\ntest['trafficSource.adwordsClickInfo.adNetworkType'] = test['trafficSource.adwordsClickInfo.adNetworkType'].fillna(0)\ntest['trafficSource.adwordsClickInfo.gclId'] = test['trafficSource.adwordsClickInfo.gclId'].fillna(0)\ntest['trafficSource.adwordsClickInfo.page'] = test['trafficSource.adwordsClickInfo.page'].fillna(0)\ntest['trafficSource.adwordsClickInfo.slot'] = test['trafficSource.adwordsClickInfo.slot'].fillna(0)","0f272c83":"train['month'] = train['date'].dt.month\ntrain['day'] = train['date'].dt.day\ntrain['weekday'] = train['date'].dt.weekday\ntrain['weekofyear'] = train['date'].dt.weekofyear\n\ntest['month'] = test['date'].dt.month\ntest['day'] = test['date'].dt.day\ntest['weekday'] = test['date'].dt.weekday\ntest['weekofyear'] = test['date'].dt.weekofyear\n\ntrain['browser_category'] = train['device.browser'] + '_' + train['device.deviceCategory']\ntrain['browser_operatingSystem'] = train['device.browser'] + '_' + train['device.operatingSystem']\n\ntest['browser_category'] = test['device.browser'] + '_' + test['device.deviceCategory']\ntest['browser_operatingSystem'] = test['device.browser'] + '_' + test['device.operatingSystem']\n\ntrain['source_country'] = train['trafficSource.source'] + '_' + train['geoNetwork.country']\ntest['source_country'] = test['trafficSource.source'] + '_' + test['geoNetwork.country']\n                                                                   \ntrain['visitNumber'] = np.log1p(train['visitNumber'])\ntest['visitNumber'] = np.log1p(test['visitNumber'])\n\ntrain['totals.hits'] = np.log1p(train['totals.hits'])\ntest['totals.hits'] = np.log1p(test['totals.hits'].astype(int))\n\ntrain['totals.pageviews'] = np.log1p(train['totals.pageviews'].fillna(0))\ntest['totals.pageviews'] = np.log1p(test['totals.pageviews'].astype(float).fillna(0))","c9603ba4":"num_cols = ['visitNumber', 'totals.hits', 'totals.pageviews', 'month_unique_user_count', 'day_unique_user_count', 'mean_hits_per_day'\n           'sum_pageviews_per_network_domain', 'sum_hits_per_network_domain', 'count_hits_per_network_domain', 'sum_hits_per_region',\n           'sum_hits_per_day', 'count_pageviews_per_network_domain', 'mean_pageviews_per_network_domain', 'weekday_unique_user_count',\n           'sum_pageviews_per_region', 'count_pageviews_per_region', 'mean_pageviews_per_region', 'user_pageviews_count', 'user_hits_count',\n           'count_hits_per_region', 'mean_hits_per_region', 'user_pageviews_sum', 'user_hits_sum', 'user_pageviews_sum_to_mean',\n            'user_hits_sum_to_mean', 'user_pageviews_to_region', 'user_hits_to_region', 'mean_pageviews_per_network_domain',\n           'mean_hits_per_network_domain','totals.bounces', 'totals.newVisits']\nnum_cols = [col for col in num_cols if col in train.columns]","8ec4f4a8":"no_use = [\"date\", \"fullVisitorId\", \"sessionId\", \"visitId\", \"visitStartTime\", 'totals.transactionRevenue', 'trafficSource.referralPath']\ncat_cols = [col for col in train.columns if col not in num_cols and col not in no_use]","00f963ec":"max_values = {}\nfor col in cat_cols:\n    print(col)\n    lbl = LabelEncoder()\n    lbl.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n    train[col] = lbl.transform(list(train[col].values.astype('str')))\n    test[col] = lbl.transform(list(test[col].values.astype('str')))\n    max_values[col] = max(train[col].max(), test[col].max())  + 2","83388fa1":"# printing because I'm too lazy to write everything by hand. Open output to see.\nfor col in cat_cols:\n    n = col.replace('.', '_')\n    print(f'{n} = Input(shape=[1], name=\"{col}\")')\n    print(f'emb_{n} = Embedding({max_values[col]}, {(np.min(max_values[col]+1)\/\/2, 50)})({col})')\n    print(',', n)","3d38a5ab":"def model(dense_dim_1=128, dense_dim_2=64, dense_dim_3=32, dense_dim_4=16, \ndropout1=0.2, dropout2=0.1, dropout3=0.1, dropout4=0.1, lr=0.0001):\n\n    #Inputs\n    channelGrouping = Input(shape=[1], name=\"channelGrouping\")\n    device_browser = Input(shape=[1], name=\"device.browser\")\n    device_deviceCategory = Input(shape=[1], name=\"device.deviceCategory\")\n    device_operatingSystem = Input(shape=[1], name=\"device.operatingSystem\")\n    day = Input(shape=[1], name=\"day\")\n    geoNetwork_city = Input(shape=[1], name=\"geoNetwork.city\")\n    geoNetwork_continent = Input(shape=[1], name=\"geoNetwork.continent\")\n    geoNetwork_country = Input(shape=[1], name=\"geoNetwork.country\")\n    geoNetwork_metro = Input(shape=[1], name=\"geoNetwork.metro\")\n    geoNetwork_networkDomain = Input(shape=[1], name=\"geoNetwork.networkDomain\")\n    geoNetwork_region = Input(shape=[1], name=\"geoNetwork.region\")\n    geoNetwork_subContinent = Input(shape=[1], name=\"geoNetwork.subContinent\")\n    trafficSource_adContent = Input(shape=[1], name=\"trafficSource.adContent\")\n    trafficSource_adwordsClickInfo_adNetworkType = Input(shape=[1], name=\"trafficSource.adwordsClickInfo.adNetworkType\")\n    trafficSource_adwordsClickInfo_gclId = Input(shape=[1], name=\"trafficSource.adwordsClickInfo.gclId\")\n    trafficSource_adwordsClickInfo_isVideoAd = Input(shape=[1], name=\"trafficSource.adwordsClickInfo.isVideoAd\")\n    trafficSource_adwordsClickInfo_page = Input(shape=[1], name=\"trafficSource.adwordsClickInfo.page\")\n    trafficSource_adwordsClickInfo_slot = Input(shape=[1], name=\"trafficSource.adwordsClickInfo.slot\")\n    trafficSource_campaign = Input(shape=[1], name=\"trafficSource.campaign\")\n    trafficSource_keyword = Input(shape=[1], name=\"trafficSource.keyword\")\n    trafficSource_medium = Input(shape=[1], name=\"trafficSource.medium\")\n    trafficSource_source = Input(shape=[1], name=\"trafficSource.source\")\n    month = Input(shape=[1], name=\"month\")\n    weekday = Input(shape=[1], name=\"weekday\")\n    weekofyear = Input(shape=[1], name=\"weekofyear\")\n    browser_category = Input(shape=[1], name=\"browser_category\")\n    browser_operatingSystem = Input(shape=[1], name=\"browser_operatingSystem\")\n    source_country = Input(shape=[1], name=\"source_country\")\n\n    totals_pageviews = Input(shape=[1], name=\"totals.pageviews\")\n    totals_hits = Input(shape=[1], name=\"totals.hits\")\n    visitNumber = Input(shape=[1], name=\"visitNumber\")\n    \n    \n    #Embeddings layers\n\n    emb_channelGrouping = Embedding(9, 5)(channelGrouping)\n    emb_device_browser = Embedding(130, 50)(device_browser)\n    emb_device_deviceCategory = Embedding(4, 3)(device_deviceCategory)\n    emb_device_operatingSystem = Embedding(25, 13)(device_operatingSystem)\n    emb_day = Embedding(32, 16)(day)\n    emb_geoNetwork_city = Embedding(957, 50)(geoNetwork_city)\n    emb_geoNetwork_continent = Embedding(7, 4)(geoNetwork_continent)\n    emb_geoNetwork_country = Embedding(229, 50)(geoNetwork_country)\n    emb_geoNetwork_metro = Embedding(124, 50)(geoNetwork_metro)\n    emb_geoNetwork_networkDomain = Embedding(41983, 50)(geoNetwork_networkDomain)\n    emb_geoNetwork_region = Embedding(484, 50)(geoNetwork_region)\n    emb_geoNetwork_subContinent = Embedding(24, 12)(geoNetwork_subContinent)\n    emb_trafficSource_adContent = Embedding(78, 39)(trafficSource_adContent)\n    emb_trafficSource_adwordsClickInfo_adNetworkType = Embedding(5, 3)(trafficSource_adwordsClickInfo_adNetworkType)\n    emb_trafficSource_adwordsClickInfo_gclId = Embedding(59010, 50)(trafficSource_adwordsClickInfo_gclId)\n    emb_trafficSource_adwordsClickInfo_isVideoAd = Embedding(3, 3)(trafficSource_adwordsClickInfo_isVideoAd)\n    emb_trafficSource_adwordsClickInfo_page = Embedding(13, 7)(trafficSource_adwordsClickInfo_page)\n    emb_trafficSource_adwordsClickInfo_slot = Embedding(5, 3)(trafficSource_adwordsClickInfo_slot)\n    emb_trafficSource_campaign = Embedding(36, 18)(trafficSource_campaign)\n    emb_trafficSource_keyword = Embedding(5394, 50)(trafficSource_keyword)\n    emb_trafficSource_medium = Embedding(8, 4)(trafficSource_medium)\n    emb_trafficSource_source = Embedding(501, 50)(trafficSource_source)\n    emb_month = Embedding(13, 7)(month)\n    emb_weekday = Embedding(8, 4)(weekday)\n    emb_weekofyear = Embedding(53, 27)(weekofyear)\n    emb_browser_category = Embedding(175, 50)(browser_category)\n    emb_browser_operatingSystem = Embedding(215, 50)(browser_operatingSystem)\n    emb_source_country = Embedding(4480, 50)(source_country)\n\n    concat_emb1 = concatenate([\n           Flatten() (emb_channelGrouping),\n            Flatten() (emb_device_deviceCategory),\n            Flatten() (emb_device_operatingSystem),\n            Flatten() (emb_day),\n            Flatten() (emb_geoNetwork_continent),\n            Flatten() (emb_geoNetwork_subContinent),\n            Flatten() (emb_trafficSource_adContent),\n            Flatten() (emb_trafficSource_adwordsClickInfo_adNetworkType),\n            Flatten() (emb_trafficSource_adwordsClickInfo_isVideoAd),\n            Flatten() (emb_trafficSource_adwordsClickInfo_page),\n            Flatten() (emb_trafficSource_adwordsClickInfo_slot),\n            Flatten() (emb_trafficSource_campaign),\n            Flatten() (emb_trafficSource_medium),\n            Flatten() (emb_month),\n            Flatten() (emb_weekday),\n            Flatten() (emb_weekofyear),\n            Flatten() (emb_geoNetwork_region)\n    ])\n    \n    categ = Dropout(dropout1)(Dense(dense_dim_1,activation='relu') (concat_emb1))\n    categ = BatchNormalization()(categ)\n    categ = Dropout(dropout2)(Dense(dense_dim_2,activation='relu') (categ))\n    \n    concat_emb2 = concatenate([\n           Flatten() (emb_browser_category), \n            Flatten() (emb_browser_operatingSystem), \n            Flatten() (emb_source_country), \n            Flatten() (emb_device_browser), \n            Flatten() (emb_geoNetwork_city), \n            Flatten() (emb_trafficSource_source), \n            Flatten() (emb_trafficSource_keyword), \n            Flatten() (emb_trafficSource_adwordsClickInfo_gclId), \n            Flatten() (emb_geoNetwork_networkDomain), \n            Flatten() (emb_geoNetwork_country), \n            Flatten() (emb_geoNetwork_metro), \n            Flatten() (emb_geoNetwork_region)\n    ])\n    categ2 = Dropout(dropout1)(Dense(dense_dim_1* 2,activation='relu') (concat_emb2))\n    categ2 = BatchNormalization()(categ2)\n    categ2 = Dropout(dropout2)(Dense(dense_dim_2* 2,activation='relu') (categ2))\n    \n    #main layer\n    main_l = concatenate([\n          categ\n        , categ2\n        , totals_pageviews\n        , totals_hits\n        , visitNumber\n    ])\n    \n    main_l = Dropout(dropout3)(Dense(dense_dim_3,activation='relu') (main_l))\n    main_l = BatchNormalization()(main_l)\n    main_l = Dropout(dropout4)(Dense(dense_dim_4,activation='relu') (main_l))\n    \n    #output\n    output = Dense(1) (main_l)\n\n    model = Model([channelGrouping,\n                   device_browser,\n                   device_deviceCategory,\n                   device_operatingSystem,\n                   geoNetwork_city,\n                   geoNetwork_continent,\n                   geoNetwork_country,\n                   geoNetwork_metro,\n                   geoNetwork_networkDomain,\n                   geoNetwork_region,\n                   geoNetwork_subContinent,\n                   trafficSource_adContent,\n                   trafficSource_adwordsClickInfo_adNetworkType,\n                   trafficSource_adwordsClickInfo_gclId,\n                   trafficSource_adwordsClickInfo_isVideoAd,\n                   trafficSource_adwordsClickInfo_page,\n                   trafficSource_adwordsClickInfo_slot,\n                   trafficSource_campaign,\n                   trafficSource_keyword,\n                   trafficSource_medium,\n                   trafficSource_source,\n                   month,\n                   day,\n                   weekday,\n                   weekofyear,\n                   browser_category,\n                   browser_operatingSystem,\n                   source_country,\n                   totals_pageviews, totals_hits, visitNumber], output)\n    #model = Model([**params], output)\n    model.compile(optimizer = Adam(lr=lr),\n                  loss= mse_loss,\n                  metrics=[root_mean_squared_error])\n    return model\n\ndef root_mean_squared_error(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))\n#model=model()","48c24216":"train = train.sort_values('date')\nX = train.drop(no_use, axis=1)\ny = train['totals.transactionRevenue']\nX_test = test.drop([col for col in no_use if col in test.columns], axis=1)\nn_fold = 10\nfolds = KFold(n_splits=n_fold, shuffle=False, random_state=42)","2ce3f952":"# converting data to format which can be used by Keras\ndef get_keras_data(df, num_cols, cat_cols):\n    cols = num_cols + cat_cols\n\n    X = {col: np.array(df[col]) for col in cols}\n    # print(\"Data ready for Vectorization\")\n    \n    return X","774f9a62":"X_test_keras = get_keras_data(X_test, num_cols, cat_cols)","19254517":"def train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, reduce_lr=False, patience=3):\n    \"\"\"\n    Helper function to train model. Also I noticed that ReduceLROnPlateau is rarely\n    useful, so added an option to turn it off.\n    \"\"\"\n    \n    early_stopping = EarlyStopping(patience=patience, verbose=1)\n    model_checkpoint = ModelCheckpoint(\"model.hdf5\",\n                                       save_best_only=True, verbose=1, monitor='val_root_mean_squared_error', mode='min')\n    if reduce_lr:\n        reduce_lr = ReduceLROnPlateau(factor=0.1, patience=2, min_lr=0.000005, verbose=1)\n        hist = keras_model.fit(X_t, y_train, batch_size=batch_size, epochs=epochs,\n                            validation_data=(X_v, y_valid), verbose=False,\n                            callbacks=[early_stopping, model_checkpoint, reduce_lr])\n    \n    else:\n        hist = keras_model.fit(X_t, y_train, batch_size=batch_size, epochs=epochs,\n                            validation_data=(X_v, y_valid), verbose=False,\n                            callbacks=[early_stopping, model_checkpoint])\n\n    keras_model = load_model(\"model.hdf5\", custom_objects={'root_mean_squared_error': root_mean_squared_error})\n    \n    return keras_model","c8325636":"def root_mean_squared_error(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=0))","a1411733":"oof = np.zeros(len(train))\npredictions = np.zeros(len(test))\nbatch_size = 2 ** 10\nepochs = 100\nscores = []\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n    print('Fold:', fold_n)\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    X_t = get_keras_data(X_train, num_cols, cat_cols)\n    X_v = get_keras_data(X_valid, num_cols, cat_cols)\n    \n    keras_model = model(dense_dim_1=64, dense_dim_2=64, dense_dim_3=32, dense_dim_4=8, \n                        dropout1=0.05, dropout2=0.1, dropout3=0.1, dropout4=0.05, lr=0.0001)\n    mod = train_model(keras_model, X_t, y_train, batch_size, epochs, X_v, y_valid, reduce_lr=False, patience=3)\n    oof[valid_index] = mod.predict(X_v).reshape(-1,)\n    \n    y_pred = mod.predict(X_test_keras).reshape(-1,)\n    predictions += y_pred\n    \n    y_pred_valid = mod.predict(X_v)\n    scores.append(mean_squared_error(y_valid, y_pred_valid) ** 0.5)\n    print('Validation score: {}.'.format(scores[-1]))\n    print('*'* 50)\n\npredictions \/= n_fold","0590938d":"3.7187107900597733 ** 0.5","343cc7f8":"print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","a974b47a":"submission = test[['fullVisitorId']].copy()\nsubmission.loc[:, 'PredictedLogRevenue'] = predictions\nsubmission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].apply(lambda x : 0.0 if x < 0 else x)\nsubmission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].fillna(0.0)\ngrouped_test = submission[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()\ngrouped_test.to_csv(f'nn_cv{np.mean(scores):.4f}_std_{np.std(scores):.4f}_prediction.csv', index=False)\noof_df = pd.DataFrame({\"fullVisitorId\": train[\"fullVisitorId\"], \"PredictedLogRevenue\": oof})\noof_df.to_csv(f'nn_cv{np.mean(scores):.4f}_std_{np.std(scores):.4f}_oof.csv', index=False)","7e30b866":"### Neural net\n\nThe main idea which allows us to efficiently use neural nets for tabular data is categorical embeddings. Basically this means using encodings for categorical features like we do it for text data.\n\nYou can read more in this fastai [article](http:\/\/www.fast.ai\/2018\/04\/29\/categorical-embeddings\/) or in this [one](https:\/\/medium.com\/@satnalikamayank12\/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9) with an example of Keras implentation.\n\nTo encode variables we need two numbers:\n- length - it will be equal to cardinality + 2 (to be slightly higher than it);\n- dimensionality - it is usually calculated as `(cardinality + 1) \/\/ 2` and usually is capped at 50 or we could have huge values;","a70c1b76":"## Keras NN baseline\n\nIn this kernel I show a simple NN with categorical embeddings in Keras. If you want to read more about feature processing, please refer to my previous [kernel](https:\/\/www.kaggle.com\/artgor\/eda-on-basic-data-and-lgb-in-progress).","fdc7bcac":"#### Model definition","b06c227b":"### Processing data\n\nThere is a lot of processing, so I hide it by default, you can see it by opening the cells below.","f2053f76":"### Loading data"}}