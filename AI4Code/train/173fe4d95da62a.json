{"cell_type":{"a213d10d":"code","919e8d00":"code","36c660fb":"code","86baa59c":"code","137d688c":"code","3d7b541d":"code","e8163512":"code","a5d5eaee":"code","b0df6fe0":"code","25717840":"code","04f5526b":"code","7fc8d7d2":"code","f0a4cf9e":"code","f8bba3ce":"code","67c8ac4a":"code","16a9356b":"code","2d0c0338":"code","1cc2627d":"code","7c6949a8":"code","507d2fc0":"code","a160ba0c":"code","496253ce":"code","8b2a4e14":"code","9a496f39":"code","1d19b982":"code","638252b1":"code","57d98357":"code","f00259f8":"markdown"},"source":{"a213d10d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","919e8d00":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\ntrain['both'] = 1\ntest['both'] = 0\ntest['Survived'] = np.nan\n\ndata = pd.concat([train, test])\ndata.columns","36c660fb":"train.info()\ntrain.describe()","86baa59c":"df_num = train[['Age', 'SibSp', 'Parch', 'Fare']]\ndf_cat = train[['Survived', 'Pclass', 'Sex', 'Ticket', 'Embarked', 'Cabin']]","137d688c":"for col in df_num.columns:\n    plt.hist(df_num[col])\n    plt.title(col)\n    plt.show()","3d7b541d":"\nsns.heatmap(df_num.corr())\nprint(df_num.corr())","e8163512":"def pivoting(cols,values='Ticket', data=train, index='Survived', func='count'):\n    print(pd.pivot_table(data, index=index, columns=cols, values=values, aggfunc=func))\n    print()","a5d5eaee":"pd.pivot_table(train, index='Survived', values=['Age', 'SibSp', 'Parch', 'Fare'])","b0df6fe0":"for col in df_cat.columns:\n    sns.barplot(df_cat[col].value_counts().index, df_cat[col].value_counts())\n    plt.title(col)\n    plt.show()","25717840":"pivoting('Pclass')\npivoting('Sex')\npivoting('Embarked')\npivoting('Cabin')","04f5526b":"train['cabin_multiple'] = train['Cabin'].apply(lambda x: 0 if pd.isna(x)\n                                              else len(x.split()))\n\ntrain['cabin_multiple'].value_counts()","7fc8d7d2":"pivoting('cabin_multiple')","f0a4cf9e":"train['Name'].head()","f8bba3ce":"train['title'] = train['Name'].apply(lambda x: x.split(', ')[1].split('.')[0].strip())\n\ntrain['title'].value_counts()","67c8ac4a":"data['cabin_multiple'] = data['Cabin'].apply(lambda x: 0 if pd.isna(x)\n                                              else len(x.split()))\ndata['title'] = data['Name'].apply(lambda x: x.split(', ')[1].split('.')[0].strip())\n\n\ndata['Age'].fillna(train['Age'].median(), inplace=True)\ndata['Fare'].fillna(train['Fare'].mean(), inplace=True)\ndata.dropna(subset=['Embarked'], inplace=True)\ndata['gauss_sibsp'] = np.log(data['SibSp'] + 1)\ndata['gauss_fare'] = np.log(data['Fare'] + 1)\n\ndata['gauss_sibsp'].hist()\ndata['gauss_fare'].hist()","16a9356b":"dummies = pd.get_dummies(data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n                              'gauss_fare', 'Embarked', 'cabin_multiple', 'title',\n                              'both']])\n\nX_train = dummies[dummies['both'] == 1].drop(['both'], axis=1)\nX_test = dummies[dummies['both'] == 0].drop(['both'], axis=1)\n\ny_train = data[data['both'] == 1]['Survived']","2d0c0338":"# Scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ndummies_copied = dummies.copy()\n\ndummies_copied[['Age','SibSp','Parch','gauss_fare']] = scaler.fit_transform(dummies[[\n    'Age','SibSp','Parch','gauss_fare']])\n\nX_train_scaled = dummies_copied[dummies_copied['both'] == 1].drop(['both'], axis=1)\nX_test_scaled = dummies_copied[dummies_copied['both'] == 0].drop(['both'], axis=1)","1cc2627d":"from sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier","7c6949a8":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","507d2fc0":"# use tuned performance, without checking baseline\ndef performance(clf, model):\n    print(model)\n    print('best score:', clf.best_score_)\n    print('best parameters:', clf.best_params_)","a160ba0c":"gnb = GaussianNB()\n\ncross_val = cross_val_score(gnb, X_train_scaled, y_train, cv=5)\nprint(cross_val.mean())\nprint(cross_val)","496253ce":"logistic = LogisticRegression()\n\nparam_grid = {'max_iter': [2000], 'penalty': ['l1', 'l2'], 'C': np.logspace(-4, 4, 20),\n        'solver': ['liblinear']}\n\nclf_logistic = GridSearchCV(logistic, param_grid=param_grid, cv=5, verbose=True,\n                           n_jobs=-1)\n\nclf_logistic.fit(X_train_scaled, y_train)\nperformance(clf_logistic, 'Logistic Regression')","8b2a4e14":"knn = KNeighborsClassifier()\n\nparam_grid = {'n_neighbors': [3, 4, 5, 7, 9, 17], 'weights': ['distance', 'uniform'],\n             'algorithm': ['auto', 'ball_tree', 'kd_tree'], 'p': [1, 2, 3]}\n\nclf_knn = GridSearchCV(knn, param_grid=param_grid, cv=5, verbose=True, n_jobs=-1)\nclf_knn.fit(X_train_scaled, y_train)\nperformance(clf_knn, 'k nearest neighbors')","9a496f39":"rf = RandomForestClassifier(random_state=42)\n\nparam_grid = {'n_estimators': [100, 250, 500, 1000],\n             'max_depth': [3, 5, 10, 20, 50, 100, None],\n             'max_features': ['auto', 'sqrt'],\n             'min_samples_leaf': [1, 2, 5, 10],\n             'min_samples_split': [1, 2, 5, 10]}\n\nclf_rf = RandomizedSearchCV(rf, param_distributions=param_grid, verbose=True, n_jobs=-1, cv=5)\nclf_rf.fit(X_train_scaled, y_train)\n\nperformance(clf_rf, 'random forest')","1d19b982":"svc = SVC(probability=True)\n\nsvc.fit(X_train_scaled, y_train)\n\nsvc.score(X_train_scaled, y_train)","638252b1":"xgb = XGBClassifier(random_state=1)\n\nparam_grid = {'n_estimators': [100, 250, 500, 550],\n            'colsample_bytree': [.75, .8, .9],\n            'max_depth': [None],\n            'reg_alpha': [1],\n            'reg_lambda': [2, 5, 7, 10],\n            'subsample': [.5, .6, .7],\n            'learning_rate': [.5],\n            'gamma': [.5, 1, 2],\n            'min_child_weight': [0.01],\n            'sampling_method': ['uniform']}\n\nclf_xgb = GridSearchCV(xgb, param_grid=param_grid, cv=5, verbose=True, n_jobs=-1)\nclf_xgb.fit(X_train_scaled, y_train)\nperformance(clf_xgb, 'XGB Classifier')","57d98357":"predicted = clf_xgb.best_estimator_.predict(X_test_scaled).astype(int)\n\noutput = {'PassengerId': test['PassengerId'], 'Survived': predicted}\nsubmission = pd.DataFrame(data=output)\nsubmission.to_csv('output.csv', index=False)","f00259f8":"# Model building\n\n1. Naive Bayes - 69%\n2. Logistic Regression - 82%  \n3. K Nearest Neighbors - 83%\n4. Random Forest - 83%\n5. Support Vector Classifier - 83%\n6. XGB Classifier - 85%"}}