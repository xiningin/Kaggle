{"cell_type":{"d22c0754":"code","41f38049":"code","f2508e37":"code","ecc6198e":"code","54c6a064":"code","625d5a17":"code","f5c9deca":"code","27c00afa":"code","fa31f303":"code","38e40cc5":"code","26c4014e":"code","e5ec0df5":"code","2d83b967":"code","8a9c34fa":"code","ae10f7a4":"code","26226d3c":"code","3dde6fad":"code","ee81c36f":"code","7960e7ab":"code","24558809":"code","ac7d614d":"code","b923063b":"code","58be3fcf":"code","8cf1cc2b":"code","f51adba7":"code","da08d950":"code","ef320ba8":"code","e3edf2d9":"code","5e5632b9":"code","1ef977d1":"code","d20a67f1":"code","2a0bd13e":"code","b65762b9":"code","dc6df3ea":"code","3a7ec4c9":"code","da30b61f":"code","fd8894fa":"code","09a6f454":"code","2411088b":"code","04b01886":"code","485e6f76":"code","ecb6e4ef":"code","7eaa0486":"code","bacf9cb8":"code","b1c8cbf7":"code","efe2c885":"code","78ef225e":"code","ff49d548":"code","a1f06c9c":"code","3757c6b7":"code","64aaed6b":"code","256599a7":"code","cf268250":"code","3f5713d2":"code","278757a2":"code","35535d61":"code","18b49900":"code","a07eae05":"code","9f7340aa":"code","36f15e5c":"markdown","10972e35":"markdown","a1e98655":"markdown","b60ce047":"markdown","245bcdb3":"markdown","c2e5b756":"markdown","46225a4b":"markdown","12ecb233":"markdown","50a01c9f":"markdown","24f8da16":"markdown","fa1537d0":"markdown","d87af8fb":"markdown","f48a20bd":"markdown","249a03f9":"markdown","b8f076ab":"markdown","c89b94cc":"markdown","f9e829c9":"markdown","51e109d0":"markdown","22e958b8":"markdown","4d349128":"markdown","4280b480":"markdown","1cf2605b":"markdown","5c478b46":"markdown","4f9104e2":"markdown","3aeb2764":"markdown","fff44501":"markdown","b471f55a":"markdown","c5f4891e":"markdown","de0fc1c7":"markdown","586daabc":"markdown","9ea29d2f":"markdown","ef0e46a7":"markdown","8629ab9a":"markdown"},"source":{"d22c0754":"!pip install dabl","41f38049":"# for some basic operations\nimport numpy as np\nimport pandas as pd\n\n# for visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport dabl\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f2508e37":"# reading the data\ndata = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\");  \n\n# getting the shape of the data\nprint(data.shape)","ecc6198e":"# looking at the head of the data\n\ndata.head()","54c6a064":"data.describe()","625d5a17":"sns.pairplot(data[['math score', 'reading score', 'writing score']], height = 4)","f5c9deca":"# lets check the no. of unique items present in the categorical column\n\ndata.select_dtypes('object').nunique()","27c00afa":"# lets check the percentage of missing data in each columns present in the data\n\nno_of_columns = data.shape[0]\npercentage_of_missing_data = data.isnull().sum()\/no_of_columns\nprint(percentage_of_missing_data)","fa31f303":"# comparison of all other attributes with respect to Math Marks\n\nplt.rcParams['figure.figsize'] = (18, 6)\nplt.style.use('fivethirtyeight')\ndabl.plot(data, target_col = 'math score')","38e40cc5":"# comparison of all other attributes with respect to Reading Marks\n\nplt.rcParams['figure.figsize'] = (18, 6)\nplt.style.use('fivethirtyeight')\ndabl.plot(data, target_col = 'reading score')","26c4014e":"# comparison of all other attributes with respect to Writing Marks\n\nplt.rcParams['figure.figsize'] = (18, 6)\nplt.style.use('fivethirtyeight')\ndabl.plot(data, target_col = 'writing score')","e5ec0df5":"# comparison of all other attributes with respect to Writing Marks\n\nplt.rcParams['figure.figsize'] = (18, 6)\nplt.style.use('fivethirtyeight')\ndabl.plot(data, target_col = 'writing score')","2d83b967":"total_students = data.shape[0]\nstudents_score_more_than_50 = data[data['math score'] > 50].shape[0]\n\nprobability_of_students_scoring_more_than_50_in_maths = (students_score_more_than_50\/total_students)*100\nprint(\"Probability of Students Scoring more than 50 marks in Maths :\", probability_of_students_scoring_more_than_50_in_maths)","8a9c34fa":"total_students = data.shape[0]\nstudents_score_more_than_50 = data[data['reading score'] > 50].shape[0]\n\nprobability_of_students_scoring_more_than_50_in_reading = (students_score_more_than_50\/total_students)*100\nprint(\"Probability of Students Scoring more than 50 marks in Reading :\", probability_of_students_scoring_more_than_50_in_reading)","ae10f7a4":"total_students = data.shape[0]\nstudents_score_more_than_50 = data[data['writing score'] > 50].shape[0]\n\nprobability_of_students_scoring_more_than_50_in_writing = (students_score_more_than_50\/total_students)*100\nprint(\"Probability of Students Scoring more than 50 marks in Writing :\", probability_of_students_scoring_more_than_50_in_writing)","26226d3c":"total_students = data.shape[0]\nnumber_of_students_passing_in_all_subjects = data[(data['math score'] > 40) &\n                                                  (data['writing score'] > 40) & \n                                                  (data['reading score'] > 40)].shape[0]\nprobability_of_students_passing_in_all_the_subjects = (number_of_students_passing_in_all_subjects\/total_students)*100\nprint(\"The Probability of Students Passing in all the Subjects is {0:.2f} %\".format(probability_of_students_passing_in_all_the_subjects))","3dde6fad":"total_students = data.shape[0]\nnumber_of_students_scoring_more_than_90 = data[(data['math score'] > 90) &\n                                                  (data['writing score'] > 90) & \n                                                  (data['reading score'] > 90)].shape[0]\n\nprobability_of_students_scoring_more_than_90_in_all_subjects = (number_of_students_scoring_more_than_90\/total_students)*100\nprint(\"The Probability of Students Passing in all the Subjects is {0:.2f} %\".\n      format(probability_of_students_scoring_more_than_90_in_all_subjects))","ee81c36f":"plt.subplot(1, 3, 1)\nsns.distplot(data['math score'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(data['reading score'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(data['writing score'])\n\nplt.suptitle('Checking for Skewness', fontsize = 18)\nplt.show()","7960e7ab":"# lets take seed so that everytime the random values come out to be constant\nnp.random.seed(6)\n\n# lets take 100 sample values from the dataset of 1000 values\nsample_math_marks = np.random.choice(a= data['math score'], size=100)\n\n# getting the sample mean\nprint (\"Sample mean for Math Scores:\", sample_math_marks.mean() )          \n\n# getting the population mean\nprint(\"Population mean for Math Scores:\", data['math score'].mean())\n\n# lets take 100 sample values from the dataset of 1000 values\nsample_reading_marks = np.random.choice(a= data['reading score'], size=100)\n\n# getting the sample mean\nprint (\"\\nSample mean for Reading Scores:\", sample_reading_marks.mean() )          \n\n# getting the population mean\nprint(\"Population mean for Reading Scores:\", data['reading score'].mean())\n\n# lets take 100 sample values from the dataset of 1000 values\nsample_writing_marks = np.random.choice(a= data['writing score'], size=100)\n\n# getting the sample mean\nprint (\"\\nSample mean for Writing Scores:\", sample_math_marks.mean() )          \n\n# getting the population mean\nprint(\"Population mean for Writing Scores:\", data['writing score'].mean())","24558809":"# lets import the scipy package\nimport scipy.stats as stats\nimport math\n\n# lets seed the random values\nnp.random.seed(10)\n\n# lets take a sample size\nsample_size = 1000\nsample = np.random.choice(a= data['math score'],\n                          size = sample_size)\nsample_mean = sample.mean()\n\n# Get the z-critical value*\nz_critical = stats.norm.ppf(q = 0.95)  \n\n # Check the z-critical value  \nprint(\"z-critical value: \",z_critical)                                \n\n# Get the population standard deviation\npop_stdev = data['math score'].std()  \n\n# checking the margin of error\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(sample_size)) \n\n# defining our confidence interval\nconfidence_interval = (sample_mean - margin_of_error,\n                       sample_mean + margin_of_error)  \n\n# lets print the results\nprint(\"Confidence interval:\",end=\" \")\nprint(confidence_interval)\nprint(\"True mean: {}\".format(data['math score'].mean()))","ac7d614d":"# lets import the scipy package\nimport scipy.stats as stats\nimport math\n\n# lets seed the random values\nnp.random.seed(10)\n\n# lets take a sample size\nsample_size = 1000\nsample = np.random.choice(a= data['reading score'],\n                          size = sample_size)\nsample_mean = sample.mean()\n\n# Get the z-critical value*\nz_critical = stats.norm.ppf(q = 0.95)  \n\n # Check the z-critical value  \nprint(\"z-critical value: \",z_critical)                                \n\n# Get the population standard deviation\npop_stdev = data['reading score'].std()  \n\n# checking the margin of error\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(sample_size)) \n\n# defining our confidence interval\nconfidence_interval = (sample_mean - margin_of_error,\n                       sample_mean + margin_of_error)  \n\n# lets print the results\nprint(\"Confidence interval:\",end=\" \")\nprint(confidence_interval)\nprint(\"True mean: {}\".format(data['reading score'].mean()))","b923063b":"# lets seed the random values\nnp.random.seed(10)\n\n# lets take a sample size\nsample_size = 1000\nsample = np.random.choice(a= data['writing score'],\n                          size = sample_size)\nsample_mean = sample.mean()\n\n# Get the z-critical value*\nz_critical = stats.norm.ppf(q = 0.95)  \n\n # Check the z-critical value  \nprint(\"z-critical value: \",z_critical)                                \n\n# Get the population standard deviation\npop_stdev = data['writing score'].std()  \n\n# checking the margin of error\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(sample_size)) \n\n# defining our confidence interval\nconfidence_interval = (sample_mean - margin_of_error,\n                       sample_mean + margin_of_error)  \n\n# lets print the results\nprint(\"Confidence interval:\",end=\" \")\nprint(confidence_interval)\nprint(\"True mean: {}\".format(data['writing score'].mean()))","58be3fcf":"data[(data['gender'] == 'female') &\n     (data['math score'] > 90) & \n     (data['writing score'] > 90) &\n     (data['reading score'] > 90)]","8cf1cc2b":"data.groupby(['gender']).agg(['min','median','max'])","f51adba7":"data[['lunch','gender','math score','writing score','reading score']].groupby(['lunch','gender']).agg('median')","da08d950":"data[['test preparation course',\n      'gender',\n      'math score',\n      'writing score',\n      'reading score']].groupby(['test preparation course','gender']).agg('median')","ef320ba8":"data[['race\/ethnicity',\n      'math score',\n      'writing score',\n      'reading score']].groupby(['race\/ethnicity']).agg('median')","e3edf2d9":"# visualising the number of male and female in the dataset\n\nplt.rcParams['figure.figsize'] = (15, 5)\n\nsns.countplot(data['gender'], palette = 'bone')\nplt.title('Comparison of Males and Females', fontweight = 30)\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.show()","5e5632b9":"# visualizing the different groups in the dataset\n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('ggplot')\n\nsns.countplot(data['race\/ethnicity'], palette = 'pink')\nplt.title('Comparison of various groups', fontweight = 30, fontsize = 20)\nplt.xlabel('Groups')\nplt.ylabel('count')\nplt.show()","1ef977d1":"# visualizing the differnt parental education levels\n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('fivethirtyeight')\n\nsns.countplot(data['parental level of education'], palette = 'Blues')\nplt.title('Comparison of Parental Education', fontweight = 30, fontsize = 20)\nplt.xlabel('Degree')\nplt.ylabel('count')\nplt.show()","d20a67f1":"# visualizing different types of lunch \n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('seaborn-talk')\n\nsns.countplot(data['lunch'], palette = 'PuBu')\nplt.title('Comparison of different types of lunch', fontweight = 30, fontsize = 20)\nplt.xlabel('types of lunch')\nplt.ylabel('count')\nplt.show()","2a0bd13e":"# visualizing maths score\n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('tableau-colorblind10')\n\nsns.countplot(data['math score'], palette = 'BuPu')\nplt.title('Comparison of math scores', fontweight = 30, fontsize = 20)\nplt.xlabel('score')\nplt.ylabel('count')\nplt.xticks(rotation = 90)\nplt.show()","b65762b9":"# visualizing reading score\n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('tableau-colorblind10')\n\nsns.countplot(data['reading score'], palette = 'RdPu')\nplt.title('Comparison of Reading scores', fontweight = 30, fontsize = 20)\nplt.xlabel('score')\nplt.ylabel('count')\nplt.xticks(rotation = 90)\nplt.show()","dc6df3ea":"# visualizing writing score\n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('tableau-colorblind10')\n\nsns.countplot(data['writing score'], palette = 'prism')\nplt.title('Comparison of Writing scores', fontweight = 30, fontsize = 20)\nplt.xlabel('score')\nplt.ylabel('count')\nplt.xticks(rotation = 90)\nplt.show()","3a7ec4c9":"# gender vs race\/etnicity \n\nplt.rcParams['figure.figsize'] = (15, 9)\nx = pd.crosstab(data['gender'], data['race\/ethnicity'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = False)\nplt.title('Gender vs Race', fontweight = 30, fontsize = 20)\nplt.show()","da30b61f":"# comparison of race\/ethnicity and parental level of education\n\nplt.rcParams['figure.figsize'] = (15, 9)\nx = pd.crosstab(data['race\/ethnicity'], data['parental level of education'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = 'True')\nplt.title('Race vs Parental Education', fontweight = 30, fontsize = 20)\nplt.show()","fd8894fa":"# comparison of parental degree and test course\n\nplt.rcParams['figure.figsize'] = (15, 9)\nsns.countplot(x = 'parental level of education', data = data, hue = 'test preparation course', palette = 'dark')\nplt.title('Parental Education vs Test Preparation Course', fontweight = 30, fontsize = 20)\nplt.show()","09a6f454":"# comparison of race\/ethnicity and test preparation course\n\nsns.countplot(x = 'race\/ethnicity', data = data,  hue = 'test preparation course', palette = 'bright')\nplt.title('Race vs Test Preparion', fontweight = 30, fontsize = 20)\nplt.show()","2411088b":"# feature engineering on the data to visualize and solve the dataset more accurately\n\n# setting a passing mark for the students to pass on the three subjects individually\npassmarks = 40\n\n# creating a new column pass_math, this column will tell us whether the students are pass or fail\ndata['pass_math'] = np.where(data['math score']< passmarks, 'Fail', 'Pass')\ndata['pass_math'].value_counts().plot.pie(colors = ['lightblue', 'lightgreen'])\n\nplt.title('Pass\/Fail in Maths', fontweight = 30, fontsize = 20)\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()\n","04b01886":"# creating a new column pass_reading, this column will tell us whether the students are pass or fail\n\ndata['pass_reading'] = np.where(data['reading score']< passmarks, 'Fail', 'Pass')\ndata['pass_reading'].value_counts(dropna = False).plot.pie(colors = ['pink', 'yellow'])\n\nplt.title('Pass\/Fail in Reading', fontweight = 30, fontsize = 20)\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()","485e6f76":"# creating a new column pass_writing, this column will tell us whether the students are pass or fail\n\ndata['pass_writing'] = np.where(data['writing score']< passmarks, 'Fail', 'Pass')\ndata['pass_writing'].value_counts(dropna = False).plot.pie(colors = ['orange', 'gray'])\n\nplt.title('Pass\/Fail in Writing', fontweight = 30, fontsize = 20)\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()","ecb6e4ef":"# computing the total score for each student\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata['total_score'] = data['math score'] + data['reading score'] + data['writing score']\n\nsns.distplot(data['total_score'], color = 'magenta')\n\nplt.title('comparison of total score of all the students', fontweight = 30, fontsize = 20)\nplt.xlabel('total score scored by the students')\nplt.ylabel('count')\nplt.show()","7eaa0486":"# computing percentage for each of the students\n# importing math library to use ceil\nfrom math import * \nimport warnings\nwarnings.filterwarnings('ignore')\n\ndata['percentage'] = data['total_score']\/3\n\nfor i in range(0, 1000):\n    data['percentage'][i] = ceil(data['percentage'][i])\n\nplt.rcParams['figure.figsize'] = (15, 9)\nsns.distplot(data['percentage'], color = 'orange')\n\nplt.title('Comparison of percentage scored by all the students', fontweight = 30, fontsize = 20)\nplt.xlabel('Percentage scored')\nplt.ylabel('Count')\nplt.show()","bacf9cb8":"# checking which student is fail overall\n\ndata['status'] = data.apply(lambda x : 'Fail' if x['pass_math'] == 'Fail' or \n                           x['pass_reading'] == 'Fail' or x['pass_writing'] == 'Fail'\n                           else 'pass', axis = 1)\n\ndata['status'].value_counts(dropna = False).plot.pie(colors = ['grey', 'crimson'])\nplt.title('overall results', fontweight = 30, fontsize = 20)\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()","b1c8cbf7":"# Assigning grades to the grades according to the following criteria :\n# 0  - 40 marks : grade E\n# 41 - 60 marks : grade D\n# 60 - 70 marks : grade C\n# 70 - 80 marks : grade B\n# 80 - 90 marks : grade A\n# 90 - 100 marks : grade O\n\ndef getgrade(percentage, status):\n  if status == 'Fail':\n    return 'E'\n  if(percentage >= 90):\n    return 'O'\n  if(percentage >= 80):\n    return 'A'\n  if(percentage >= 70):\n    return 'B'\n  if(percentage >= 60):\n    return 'C'\n  if(percentage >= 40):\n    return 'D'\n  else :\n    return 'E'\n\ndata['grades'] = data.apply(lambda x: getgrade(x['percentage'], x['status']), axis = 1 )\n\ndata['grades'].value_counts()","efe2c885":"# plotting a pie chart for the distribution of various grades amongst the students\n\nlabels = ['Grade 0', 'Grade A', 'Grade B', 'Grade C', 'Grade D', 'Grade E']\nsizes = [58, 156, 260, 252, 223, 51]\ncolors = ['yellow', 'gold', 'lightskyblue', 'lightcoral', 'pink', 'cyan']\nexplode = (0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001)\n\npatches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90)\nplt.legend(patches, labels)\nplt.title('Distribution of Grades among Students', fontweight = 30, fontsize = 20)\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n","78ef225e":"# comparison parent's degree and their corresponding grades\n\nplt.rcParams['figure.figsize'] = (15, 9)\n\nx = pd.crosstab(data['parental level of education'], data['grades'])\ncolor = plt.cm.copper(np.linspace(0, 1, 8))\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, color = color)\nplt.title(\"Parental Education vs Student's Grades\", fontweight = 30, fontsize = 20)\nplt.show()","ff49d548":"# for better visualization we will plot it again using seaborn\n\nsns.countplot(x = data['parental level of education'], data = data, hue = data['grades'], palette = 'pastel')\nplt.title('Parental Education vs Grades of Students', fontsize = 20, fontweight = 30)\nplt.show()","a1f06c9c":"# comparing the distribution of grades among males and females\n\nsns.countplot(x = data['grades'], data = data, hue = data['gender'], palette = 'cubehelix')\n#sns.palplot(sns.dark_palette('purple'))\nplt.title('Grades vs Gender', fontweight = 30, fontsize = 20)\nplt.show()","3757c6b7":"from sklearn.preprocessing import LabelEncoder\n\n# creating an encoder\nle = LabelEncoder()\n\n# label encoding for test preparation course\ndata['test preparation course'] = le.fit_transform(data['test preparation course'])\n\n# label encoding for lunch\ndata['lunch'] = le.fit_transform(data['lunch'])\n\n# label encoding for race\/ethnicity\n# we have to map values to each of the categories\ndata['race\/ethnicity'] = data['race\/ethnicity'].replace('group A', 1)\ndata['race\/ethnicity'] = data['race\/ethnicity'].replace('group B', 2)\ndata['race\/ethnicity'] = data['race\/ethnicity'].replace('group C', 3)\ndata['race\/ethnicity'] = data['race\/ethnicity'].replace('group D', 4)\ndata['race\/ethnicity'] = data['race\/ethnicity'].replace('group E', 5)\n\n# label encoding for parental level of education\ndata['parental level of education'] = le.fit_transform(data['parental level of education'])\n\n#label encoding for gender\ndata['gender'] = le.fit_transform(data['gender'])\n\n# label encoding for pass_math\ndata['pass_math'] = le.fit_transform(data['pass_math'])\n\n# label encoding for pass_reading\ndata['pass_reading'] = le.fit_transform(data['pass_reading'])\n\n# label encoding for pass_writing\ndata['pass_writing'] = le.fit_transform(data['pass_writing'])\n\n# label encoding for status\ndata['status'] = le.fit_transform(data['status'])","64aaed6b":"# splitting the dependent and independent variables\n\nx = data.iloc[:,:14]\ny = data.iloc[:,14]\n\nprint(x.shape)\nprint(y.shape)","256599a7":"# splitting the dataset into training and test sets\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 45)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","cf268250":"# importing the MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# creating a scaler\nmm = MinMaxScaler()\n\n# feeding the independent variable into the scaler\nx_train = mm.fit_transform(x_train)\nx_test = mm.transform(x_test)","3f5713d2":"# applying principal components analysis\n\nfrom sklearn.decomposition import PCA\n\n# creating a principal component analysis model\n#pca = PCA(n_components = None)\n\n# feeding the independent variables to the PCA model\n#x_train = pca.fit_transform(x_train)\n#x_test = pca.transform(x_test)\n\n# visualising the principal components that will explain the highest share of variance\n#explained_variance = pca.explained_variance_ratio_\n#print(explained_variance)\n\n# creating a principal component analysis model\n#pca = PCA(n_components = 2)\n\n# feeding the independent variables to the PCA model\n#x_train = pca.fit_transform(x_train)\n#x_test = pca.transform(x_test)","278757a2":"from sklearn.linear_model import  LogisticRegression\n\n# creating a model\nmodel = LogisticRegression()\n\n# feeding the training data to the model\nmodel.fit(x_train, y_train)\n\n# predicting the test set results\ny_pred = model.predict(x_test)\n\n# calculating the classification accuracies\nprint(\"Training Accuracy :\", model.score(x_train, y_train))\nprint(\"Testing Accuracy :\", model.score(x_test, y_test))","35535d61":"# printing the confusion matrix\n\nfrom sklearn.metrics import confusion_matrix\n\n# creating a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# printing the confusion matrix\nplt.rcParams['figure.figsize'] = (8, 8)\nsns.heatmap(cm, annot = True, cmap = 'Greens')\nplt.title('Confusion Matrix for Logistic Regression', fontweight = 30, fontsize = 20)\nplt.show()","18b49900":"from sklearn.ensemble import RandomForestClassifier\n\n# creating a model\nmodel = RandomForestClassifier()\n\n# feeding the training data to the model\nmodel.fit(x_train, y_train)\n\n# predicting the x-test results\ny_pred = model.predict(x_test)\n\n# calculating the accuracies\nprint(\"Training Accuracy :\", model.score(x_train, y_train))\nprint(\"Testing Accuracy :\", model.score(x_test, y_test))","a07eae05":"# printing the confusion matrix\n\nfrom sklearn.metrics import confusion_matrix\n\n# creating a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# printing the confusion matrix\nplt.rcParams['figure.figsize'] = (8, 8)\nsns.heatmap(cm, annot = True, cmap = 'Reds')\nplt.title('Confusion Matrix for Random Forest', fontweight = 30, fontsize = 20)\nplt.show()","9f7340aa":"from pandas.plotting import radviz\nfig, ax = plt.subplots(figsize=(12, 12))\nnew_df = x.copy()\nnew_df[\"status\"] = y\nradviz(new_df, \"status\", ax=ax, colormap=\"rocket\")\nplt.title('Radial Visualization for Target', fontsize = 20)\nplt.show()","36f15e5c":"<img src = \"https:\/\/media.giphy.com\/media\/3orieMyfgezWc93UOc\/giphy.gif\" >","10972e35":"*5. Lets check the Effect of Race and Ethnicity on Student's Performance*","a1e98655":"***3. Lets also check the Probability of Students Scoring more than 90 in all the three Subjects***","b60ce047":"**Student Performance Analysis**","245bcdb3":"4. Lets check the Effect of Test Preparation Course on Scores","c2e5b756":"*The first step is to import all the necessary libraries needed for performing the analysis*","46225a4b":"**Random Forest**","12ecb233":"***4. Checking for Skewness for the Maths, Reading and Writing Scores***","50a01c9f":"*3. Lets check the Effect of Lunch on Student's Performnce*","24f8da16":"*As can be seen from the first five rows of the dataset, the dataset contains columns like 'gender', 'race\/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score'*","fa1537d0":"**Label Encoding**","d87af8fb":"***6. Let check the Confidence Interval for Math Score***","f48a20bd":"**Objective**\n\n- To draw inference about whether factors like gender of the student, the race\/ethnicity of the student, the level of education of their parents, the type of lunch they ate and whether the completition of test preparation course has any impact on the scores obtained by the student in the tests.","249a03f9":"**5. Lets check the Inference**","b8f076ab":"***7. Let check the Confidence Interval for Reading Score***","c89b94cc":"- Notice that the true mean is contained in our interval.\n- A confidence interval of 95% would mean that if we take many samples and create confidence intervals for each of them, 95% of our samples' confidence intervals will contain the true population mean.\n- Now, let's create several confidence intervals and plot them to get a better sense of what it means to \"capture\" the true mean","f9e829c9":"*It gives a clear Idea that Students getting very low grades have high correlation on Lunch and Parental Education*","51e109d0":"**Modelling**","22e958b8":"*Exploring the 'StudentPerformance' dataset.*","4d349128":"**Data Visualizations**","4280b480":"*2. Lets compare the scores secured by Boys and Girls*","1cf2605b":"<img src = \"https:\/\/i.ytimg.com\/vi\/XVg251UOnzk\/maxresdefault.jpg\" >","5c478b46":"**8. Let check the Confidence Interval for Writing Score**","4f9104e2":"**2. Lets also check the Probability of Students Passing in all the three Subjects**","3aeb2764":"**1. Lets check the Probability of Students Scoring More than 50 Marks in Maths**","fff44501":"**Data Preparation**","b471f55a":"<img src = \"https:\/\/www.rvcj.com\/wp-content\/uploads\/2014\/12\/Exam.png\" >","c5f4891e":"***Questions that this analysis***\n\n1. Does the gender of student plays a role in how they perform in various courses...\n\n2. Does the educational background of the parents impact the students performance...\n\n3. Does the ethnicity of the student has an impact on their performance...\n\n4. Is completing the Test Preparation course help the students in performing better...\n\n5. Does the quality of lunch the students consume leaves an impact on how they perform... \n\nFinally, a model will be trained to predict how the students will perform given the factors influencing their performance and will also evaluate the performance of the model.","de0fc1c7":"**Descriptive Statistics**","586daabc":"**Inferential Statistics**","9ea29d2f":"**Grouping Operations**","ef0e46a7":"*It is very much clear, that there is no skewness in the Target Columns*","8629ab9a":"*1. Number of Girl Students Scoring 90 in all the Subjects*"}}