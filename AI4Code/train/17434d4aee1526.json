{"cell_type":{"81930e06":"code","7739e16f":"code","47ca494b":"code","4e8d7f5f":"code","581065b0":"code","a85da4f3":"code","f2258183":"code","b420f5da":"code","550d17df":"code","9700f1de":"code","1b4aa16d":"code","8b68fcd5":"code","da85018e":"code","51eedfe2":"code","ecb1ae7f":"code","d06111f9":"code","da34f73a":"code","4b381db9":"code","13a904ee":"code","36f26326":"code","269cdb92":"code","76b77985":"code","daded8fa":"code","060c5663":"code","143b586d":"code","3d4b1361":"code","24a24a1b":"code","f91d0e41":"code","3c570c2e":"markdown","40091b97":"markdown","5eefb99b":"markdown","d1ddf81b":"markdown"},"source":{"81930e06":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7739e16f":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport keras.backend as K\nfrom zipfile import ZipFile\nfrom IPython.display import clear_output\nfrom pathlib import Path\nimport zipfile","47ca494b":"train_zip_path = \"\/kaggle\/input\/carvana-image-masking-challenge\/train.zip\"\nwith zipfile.ZipFile(train_zip_path, \"r\") as z_:\n    z_.extractall(\"\/kaggle\/working\")","4e8d7f5f":"masks_zip_path = \"\/kaggle\/input\/carvana-image-masking-challenge\/train_masks.zip\"\nwith zipfile.ZipFile(masks_zip_path, \"r\") as z_:\n    z_.extractall(\"\/kaggle\/working\")\n","581065b0":"print(len(os.listdir(\"\/kaggle\/working\/train\")))\nprint(len(os.listdir(\"\/kaggle\/working\/train_masks\")))","a85da4f3":"#Train dataframe\n\ncar_ids = []\npaths = []\n\nfor dirname, _, filenames in os.walk(\"\/kaggle\/working\/train\"):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        paths.append(path)\n        \n        car_id = filename.split(\".\")[0]\n        car_ids.append(car_id)\n        \ndf = pd.DataFrame({\"id\": car_ids, \"car_path\": paths})\ndf = df.set_index(\"id\")\ndf","f2258183":"#Train_mask dataframe\n\ncar_ids = []\nmask_path = []\n\nfor dirname, _,filenames in os.walk(\"\/kaggle\/working\/train_masks\"):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        mask_path.append(path)\n        \n        car_id = filename.split(\".\")[0]\n        car_id = car_id.split(\"_mask\")[0]\n        car_ids.append(car_id)\n        \n        \nmask_df = pd.DataFrame({\"id\": car_ids, \"mask_path\": mask_path})\nmask_df = mask_df.set_index(\"id\")\nmask_df","b420f5da":"df[\"mask_path\"] = mask_df[\"mask_path\"]\ndf = df.reset_index(drop=True)\ndf","550d17df":"#data augmentation function\n\nimage_size = [256, 256]\nOUTPUT_CHANNELS = 3\n\ndef augmentation(input_image, mask_image):\n    \n    \n    if tf.random.uniform(()) > 0.5:\n        input_image = tf.image.flip_left_right(input_image)\n        mask_image = tf.image.flip_left_right(mask_image)\n    \n    return input_image, mask_image","9700f1de":"#Preprocessing function\n\ndef preprocess(car_path, mask_path):\n    input_image = tf.io.read_file(car_path)\n    input_image = tf.image.decode_jpeg(input_image, channels=OUTPUT_CHANNELS)\n    input_image = tf.image.resize(input_image, image_size)\n    input_image = tf.cast(input_image, tf.float32) \/ 255.0\n\n    \n    mask_image = tf.io.read_file(mask_path)\n    mask_image = tf.image.decode_jpeg(mask_image, channels=OUTPUT_CHANNELS)\n    mask_image = tf.image.resize(mask_image, image_size)\n    mask_image = mask_image[:, :, :1]\n    mask_image = tf.math.sign(mask_image)\n    \n    input_image, mask_image = augmentation(input_image, mask_image)\n    \n    return input_image, mask_image","1b4aa16d":"#create_dataset function\n\ndef create_dataset(df, train = False):\n    if not train:\n        ds = tf.data.Dataset.from_tensor_slices((df[\"car_path\"].values, df[\"mask_path\"].values))\n        ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n        \n    else:\n        ds = tf.data.Dataset.from_tensor_slices((df[\"car_path\"].values, df[\"mask_path\"].values))\n        ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n        ds = ds.map(augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n        \n    return ds","8b68fcd5":"#Data split\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(df, random_state=42, test_size=0.25)\ntrain = create_dataset(train_df, train=True)\nvalid = create_dataset(valid_df)","da85018e":"TRAIN_LENGTH = len(train_df)\nBATCH_SIZE = 16\nBUFFER_SIZE = 1000","51eedfe2":"#train and validation dataset\n\ntrain_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\ntrain_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\nvalid_dataset = valid.batch(BATCH_SIZE)","ecb1ae7f":"#Take a look before data training\n\ndef display(display_list):\n    plt.figure(figsize=(15,15))\n    \n    title = [\"Input image\", \"True mask\", \"Predicted_mask\"]\n    \n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i + 1)\n        plt.title(title[i])           \n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis(\"off\")\n                   \n    plt.show()","d06111f9":"for image, mask in train.take(1):\n    sample_image, sample_mask = image, mask\n    display([sample_image, sample_mask])","da34f73a":"#Base model\n\nbase_model = tf.keras.applications.MobileNetV2(input_shape=[256, 256, 3], include_top=False)\n\nlayer_names = [\n    \"block_1_expand_relu\",\n    \"block_3_expand_relu\",\n    \"block_6_expand_relu\",\n    \"block_13_expand_relu\",\n    \"block_16_project\",\n]","4b381db9":"#Encoder\n\nmodel_base_output = [base_model.get_layer(name).output for name in layer_names]\n\ndown_stack = tf.keras.Model(inputs=base_model.input, outputs=model_base_output)\n\ndown_stack.trainable = False","13a904ee":"#Decoder function\n\ndef upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    \n    result = tf.keras.Sequential()\n    result.add(\n    tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding=\"same\", kernel_initializer=initializer, use_bias=False))\n    \n    result.add(tf.keras.layers.BatchNormalization())\n    \n    if apply_dropout:\n        result.add(tf.keras.layers.Dropout(0.5))\n        \n    result.add(tf.keras.layers.ReLU())\n\n    return result","36f26326":"#Decoder\n\nup_stack = [\n    upsample(512, 3),\n    upsample(256, 3),\n    upsample(128, 3),\n    upsample(64, 3)\n] ","269cdb92":"#unet_model function\n\ndef unet_model(output_channels):\n    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n    \n    skips = down_stack(inputs)\n    x = skips[-1]\n    skips = reversed(skips[:-1])\n    \n    for up, skip, in zip(up_stack, skips):\n        x = up(x)\n        concat = tf.keras.layers.Concatenate()\n        x = concat([x, skip])\n        \n    last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2, padding=\"same\")\n    x = last(x)\n    \n    return tf.keras.Model(inputs=inputs, outputs=x)","76b77985":"#Create model\n\nmodel = unet_model(OUTPUT_CHANNELS)\n\nmodel.compile(optimizer=\"adam\",\n             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n             metrics=[\"accuracy\"])","daded8fa":"#Model architecture\n\ntf.keras.utils.plot_model(model, show_shapes=True)","060c5663":"#Let's test the model to see what it predicts before training\n\ndef create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","143b586d":"def show_predictions(train_dataset=None, num=1):\n    if train_dataset:\n        for image, mask in train_dataset.take(num):\n            pred_mask = model.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n            \n    else:\n        display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n            \nshow_predictions()","3d4b1361":"model.summary()","24a24a1b":"#Calllback function\n\nfrom IPython.display import clear_output\n\nclass DisplayCallback(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        clear_output(wait=True)\n        show_predictions()\n        print(\"\\nSample Predictions after epoch {}\\n\".format(epoch+1))","f91d0e41":"EPOCHS = 5\nSTEPS_PER_EPOCH= TRAIN_LENGTH \/\/ BATCH_SIZE\n\nmodel_history = model.fit(train_dataset, epochs=EPOCHS,\n                          steps_per_epoch=STEPS_PER_EPOCH,\n                          validation_data=valid_dataset,\n                          callbacks=[DisplayCallback()])","3c570c2e":"# Model building","40091b97":"# Data loading and preprocessing","5eefb99b":"# Training","d1ddf81b":"# Import libraries"}}