{"cell_type":{"7eb3b81d":"code","0e3d35f5":"code","177ac615":"code","ccad25e1":"code","cc5a12c5":"code","bb30371e":"code","1ec67553":"code","2c96d5cb":"code","53eca58f":"code","871c2a20":"code","d36337ef":"code","5f05f34e":"code","31b127be":"code","401b7068":"code","a554bd19":"code","b13d19b7":"code","005b44e1":"code","d38615fb":"code","847a367e":"code","91f0893d":"code","5bc71216":"code","5b8d15b2":"code","76a9eacd":"code","ee66775b":"code","3d2a89fa":"code","30beb03b":"code","fd5e2ae9":"code","186bab9a":"code","7afc72fd":"code","5569cac4":"code","371d51dc":"code","94db41e6":"markdown","a1365b30":"markdown","04792839":"markdown","ea55105c":"markdown","135fd371":"markdown","42f7549a":"markdown","e027dd7f":"markdown","a5457997":"markdown","da5982cb":"markdown","31bea984":"markdown","3906b880":"markdown","14dca164":"markdown","a2239a8f":"markdown","f8d24911":"markdown","30e3f167":"markdown","64a6e470":"markdown","2e4bbd36":"markdown","e87a21b5":"markdown","2582cf99":"markdown","3092f9ab":"markdown","510acb0a":"markdown","361eb10d":"markdown","eda4b3cd":"markdown","16452f48":"markdown","63848845":"markdown","af3b9816":"markdown","a7e32dd1":"markdown","49d40748":"markdown","ec51bd3c":"markdown","f4484de0":"markdown","ffd6e10c":"markdown","e01d4974":"markdown","3946fc81":"markdown","be1c55c3":"markdown","7463ffe5":"markdown","42410768":"markdown","f9e50648":"markdown","166c8357":"markdown","9c578c2a":"markdown","d927f595":"markdown","f8657462":"markdown","d91f7952":"markdown","cad13020":"markdown","60772ad6":"markdown"},"source":{"7eb3b81d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e3d35f5":"# Matplotlib forms basis for visualization in python\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# we will use the seaborn library\nimport seaborn as sns\n\nsns.set()\n\n# Graphics in SVG format are more sharp and legible\n%config InlineBackend.figure_format = 'svg'","177ac615":"DATA_URL = \"https:\/\/raw.githubusercontent.com\/Yorko\/mlcourse.ai\/master\/data\/\"\n\ndf = pd.read_csv(DATA_URL + \"telecom_churn.csv\")","ccad25e1":"df.head()","cc5a12c5":"features = [\"Total day minutes\", \"Total intl calls\"]\ndf[features].hist(figsize=(10,4));","bb30371e":"df[features].plot(\n    kind=\"density\", subplots=True, layout=(1,2), sharex=False, figsize=(10,4)\n);","1ec67553":"sns.distplot(df[\"Total intl calls\"]);","2c96d5cb":"sns.boxplot(x=\"Total intl calls\", data=df);","53eca58f":"_, axes = plt.subplots(1, 2, sharey=True, figsize=(6,4))\nsns.boxplot(data=df[\"Total intl calls\"], ax=axes[0])\nsns.violinplot(data=df[\"Total intl calls\"], ax=axes[1])","871c2a20":"df[features].describe()","d36337ef":"df[\"Churn\"].value_counts()","5f05f34e":"_, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n\nsns.countplot(x=\"Churn\", data=df, ax=axes[0])\nsns.countplot(x=\"Customer service calls\", data=df, ax=axes[1]);","31b127be":"#Drop non-numerical varaibles\n\nnumerical = list(\n    set(df.columns)\n    - set(\n        [\n            \"State\",\n            \"International plan\",\n            \"Voice mail plan\",\n            \"Area code\",\n            \"Churn\",\n            \"Customer service calls\",\n        ]\n    )\n)\n\n# calculate and plot\ncorr_matrix = df[numerical].corr()\nsns.heatmap(corr_matrix);","401b7068":"numerical = list(\n    set(numerical)\n    - set(\n        [\n            \"Total day charge\",\n            \"Total eve charge\",\n            \"Total night charge\",\n            \"Total intl charge\",\n        ]\n    )\n)","a554bd19":"plt.scatter(df[\"Total day minutes\"], df[\"Total night minutes\"]);","b13d19b7":"sns.jointplot(x=\"Total day minutes\", y=\"Total night minutes\", data=df)","005b44e1":"sns.jointplot(\n    \"Total day minutes\", \"Total night minutes\", data=df, kind=\"kde\",\n);","d38615fb":"# `pairplot()1 may become very slow wit the SVG format\n%config InlineBackend.figure_format = 'png'\nsns.pairplot(df[numerical]);","847a367e":"%config InlineBackend.figure_format = 'svg'","91f0893d":"sns.lmplot(\n    \"Total day minutes\", \"Total night minutes\", data=df, hue=\"Churn\", fit_reg=False\n);","5bc71216":"# Sometimes you cna analyze an ordinal variable just as numerical one\nnumerical.append(\"Customer service calls\")\n\nfig, axes = plt.subplots(nrows=3, ncols=4, figsize=(10, 7))\nfor idx, feat in enumerate(numerical):\n    ax = axes[int(idx \/ 4), idx % 4]\n    sns.boxplot(x=\"Churn\", y=feat, data=df, ax=ax)\n    ax.set_xlabel(\"\")\n    ax.set_ylabel(feat)\nfig.tight_layout();","5b8d15b2":"sns.countplot(x=\"Customer service calls\", hue=\"Churn\", data=df);","76a9eacd":"_, axes = plt.subplots(1, 2, sharey=True, figsize=(10,4))\n\nsns.countplot(x=\"International plan\", hue=\"Churn\", data=df, ax=axes[0])\nsns.countplot(x=\"Voice mail plan\", hue=\"Churn\", data=df, ax=axes[1]);","ee66775b":"pd.crosstab(df[\"State\"], df[\"Churn\"]).T","3d2a89fa":"df.groupby([\"State\"])[\"Churn\"].agg([np.mean]).sort_values(by=\"mean\", ascending=False).T","30beb03b":"from sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler","fd5e2ae9":"X = df.drop([\"Churn\", \"State\"], axis=1)\nX[\"International plan\"] = X[\"International plan\"].map({\"Yes\": 1, \"No\": 0})\nX[\"Voice mail plan\"] = X[\"Voice mail plan\"].map({\"Yes\": 1, \"No\": 0})","186bab9a":"scaler = StandardScaler()\n\nX_scaled = scaler.fit_transform(X)","7afc72fd":"%%time\ntsne = TSNE(random_state=18)\ntsne_repr = tsne.fit_transform(X_scaled)","5569cac4":"plt.scatter(tsne_repr[:, 0], tsne_repr[:, 1], alpha=0.5);","371d51dc":"plt.scatter(\ntsne_repr[:, 0],\ntsne_repr[:, 1],\n    c=df[\"Churn\"].map({False: \"Blue\", True: \"orange\"}),\n    alpha=0.5,\n);","94db41e6":"<h2> 2.1 Quantitative features <\/h2>\n\nQuantitative features take on ordered numerical values. Those values can be discrete, like integers, or continuous, like real numbers, and usually express a count or a measurement.","a1365b30":"Sometimes, such a visualization may help draw conclusions about data; but, in this case, everything is pretty clear with no surprises.","04792839":"The function `jointplot()` plots two histograms that may be useful in some cases.\n\nUsing the same function, we can also get a smoothed version fo our bivariate distribution:","ea55105c":"Now it is clear that, for example, many dissatisfied customers who canceled their subscription are crowded together in one cluster representing the people with the international plan but no voice mail.\n\nFinally, let's note some disadvantages of t-SNE:\n* High computational complexity. The implementation in `scikit-learn` is unlikely to be feasible in a real task. If you have a large number of samples, you should try `Multicore-TNSE` instead.\n* The plot can change a great deal of depending on the random seed, which complicates interpreation. In general, you shouldn't make any far-reaching conclusions based on such graphs because it can equate to plain guessing. Of course, some findings in t-SNE pictures can inspire an idea and be confirmed through more thorough research down the line, but that does not happend very often.\n\n\nOccasionally, using t-SNE, you can get a really good intuition for the data.","135fd371":"By default, the entries in the output are sorted from the most to the least frequently-occurring values.\n\nIn our case, the data is not balanced; that is our two target classes, loyal and disloyal customers, are not represented equally in the dataset. Only a small part of the clients canceled their subscription to the telecom service. As we will see in the following articles, this fact may imply some restrictions on measuring the classification performance, and in the future, we may want to additionally penalize our model errors in predicting the minority \"Churn\" class.","42f7549a":"The last data column, `Churn`, is our target variable. It's binary: True indicates that the company eventually lost this customer, and False indicates that the customer was retained. Later, we will build models that predict this feature based on the remaining features. This is why we call it a target.","e027dd7f":"From the colored correlation matrix generated above, we can see that there are 4 varaibles such as Total day charge that have been calculated directly from the number of minutes spent on phone calls (Total day minutes). These are called dependednt variables and can therefore be left out since they do not contribute any additiona information. Let's get rid of them:","a5457997":"This is basically a bivariate version of the `Kernel Density Plot` discussed eariler.","da5982cb":"<h3> Scatterplot matrix <\/h3>\n\nIn some cases, we may want to plot a scatterplot matrix such as the one shown below. Its diagonal contains the distributions of the corresponding variables, and the scatter plots for each pair of variables fill the rest of the matrix.","31bea984":"We also need to normalize the data. For this, we will subtract the mean from each varaible and divid it by its standard devaition. All of the can be done with `StandardScaler`.","3906b880":"The difference between the box and violin plots is that the former illustrates certain statistics concerning individual examples in a dataset while the volin plot concentrates more on the smoothed distribution as a whole.\n\nIn our case, the violin plot does not contribute any additional information about the data as everything is clear from the box plot alone.","14dca164":"<b> An observation: <\/b> When International Plan is enabled, the churn rate is much higher;  the usage of the international plan by the customer is a strong feature. We do not observe the same effect with Voice mail plan.","a2239a8f":"We get an uninteresting picture of two normally idstributed variables. Also, it seems that these features are uncorrelated because the ellipse-like shapre is aligned with the axes.\n\nThere is a slightly fancier option to create a scatter plot witht the `seaborn` library:","f8d24911":"# 2. Univariate visualization\n\nUnivariate analysis looks at one feature at a time. When we analyze a feature independently, we are usually mostly interested in the distribution of its values and ignore other features in the dataset.\n\nBelow, we will consider different statistical types of features and the corresponding tools for their individual visual analysis.","30e3f167":"In the case of State, the number of distinct values is rather high: 51. We see that there are only a few data points available for each individual state - only 3 to 17 customers in each state abandoned the operator. Let's ignore that for a second and calculate the churn rate for each state, sorting it from high to low:","64a6e470":"At first glance, it seems that the churn rate in New Jersey and California are above 25% and less than 6% for Hawaii and Alaska. However, these conclusions are based on too few examples, and our observation could be a mere property of our particular dataset. We can confirm this with the `Matthews` and `Cramer` correlation hypotheses, but this would be beyond the scope of this article.","2e4bbd36":"Let's sight on our dataset","e87a21b5":"# 4. Whole dataset visualizations\n\n<h2> 4.1 A naive approach <\/h2>\n    \nWe have been looking at different facets of our dataset by guessing interesting features and selecting a small number of them at a time for visualization. We have only dealt with two to three variables at once and were easily able to observe the structure and relationships in data. But, what if we want to display all the features and still be able to interpret the resulting visualization?\n    \nWe could use `hist()` or create a scatterplot matrix with `pairplot()` for the whole dataset to look at all of our features simultaneously. But, when the number of features is high enough, this kind of visual analysis quickly becomes slow and inefficient. Besides, we would still be analyzing our variables in a pairwise fahsion, not all at once.\n\n<h2> 4.2 Dimensionality reduction <\/h2>\n\nMost real-world datasets have many features, sometimes, many thousands of them. Each of them can be considered as a dimension in the space of data points. Consequently, more often than not, we deal with high-dimensional datasets, where entire visualization is quite hard.\n\n\nTo look at a dataset as a whole, we need decrease the number of dimensions used in visualization without losing much information about the data. This task is called `dimensionality reduction` and is an example of an unsupervised learning problem because we need to derive new, low-dimensional features from the data itself, without any supervised input.\n\nOne of the well-known dimensionality reduction methods is `Principal Component Analysis` (PCA), which we will study later in this couse. Its limitation is that it is a linear algorithm that implies certain restrictions on the data.\n\nThere are also many non-linear methods, collectively called Manifold Learning. One of the best-know of them is t-SNE.\n\n\n<h2> 4.3 t-SNE <\/h2>\n\nLet's cretae a `t-SNE` representation of the same churn data we have been using.\n\nThe name of the method looks complex and a bit intimidating: t-distributed `Stochastic Nieghbor Embedding`. Its math is also impressive (we will not delve into it here, but, if you feel brave, here is the original article by Lauren var der Maarten and Geoffrey Hinton from JMLR). Its basic idea is simple: find a projection for a high-dimensional feature space onto a plane (or a 3D hyperplane, but it is almost always 2D) such that those point that were far apart in the initial n-dimensional space will end up far apart on the plane. Those that were originally close would remain close to each other.\n\nEssentially, neighbor embedding is a search for a new and less-dimensiona data representation that preserves neighborships of examples.\n\nNow, let's do some practice. First, we need to import some additional clases:","2582cf99":"While the histograms, discussed above, and bar plots may look similar, there are several differences between them:\n\n1. Histograms are best suited for looking at the distribution of numerical variables while bar plots are used for categorical features.\n\n2. The values on the X-axis in the histogram are numerical; a bar plot can have any type of values on the X-axis: numbersl, strings, booleans.\n\n3. The histogram's X-axis is a Cartisian coordinate axis along which values cannot be changed; the ordering of the vars is not predefined. Still, it is useful to note that the bars are often sorted by height, that is, the frequency of the values. Also, when we consider ordinal variables (like Customer service calls in our data), the bars are sually ordered by variable value.\n\n\nThe left chart above vividly illustrates the imbalance in our target variable. The bar plot for Customer service calls on the right gives a hint that the majority of customers resolve their problems in maximum 2-3 calls. But, as we want to be able to predict the minority class, we may be more interested in how the fewer dissatisfied cutomers behave. It may well be that the tail of that bar plot contains most of our churn. These are just hypotheses for now, so let's move on to some more interesting and powerful visual techniques.","3092f9ab":"We will load the dataset:","510acb0a":"Let's see how to interpret a box plot. Its components are a box (obviously, this is why it is called a box plot), the so-called whiskers, and a number of individual points (outliers).\n\n\nThe box by itself illustrates the interquartile spread of the distribution; its length is determined by the 25th (Q1) and 75th(Q3) precentiles. THe vertical line inside the box marks the median (50%) of the distribution.\n\nThe whiskers are the linears extending from the box. They represent the entire scatter of data points, specifically the points that fall within the interval `(Q1 - 1.5 * IQR, Q3 + 1.5 * IQR), where IQR = Q3 - Q1` is the interquartile range.\n\nOutliers that fall outside of the range bounded by the whiskers are plotted individually as black points along the central axis.\n\nWe can see that a large number of international calls is quite rare in our data.","361eb10d":"It seems that our small proportion of diloyal customer lean towards the top-right corner; that is, such customers tend to spend more time on the phone during both day and night. But this is not absolutely clear, and we won't make any definitive conclusions form thsi chart.\n\nNow, let's create box plots to visualize the distribution statistics of the numerical variables in two disjoint groups: the loyal customers `(Churn=False)` and those who left `(Churn=True)`.","eda4b3cd":"Now, let's build a t-SNE representation:","16452f48":"A histogram groups values into bins of equal value range. The shape of the histogram may contain clues about the underlying distribution type: Gaussian, exponential, etc. You can also spot any skewness in its shape when the distribution is nearly regular but has some anomalies. Knowing the distribution of the feature values becomes important when you use Machine Learning methods that assume a particular type (most often Gaussian).\n\n\nIn the above plot, we see that the variable Total day minutes is normally distributed, while Total intl calls is prominently skewed right (its tail is longer on the right).\n\nThere is also another, often clearer, way to grasp the distribution: density plots or more formally, Kernel Density Plots. They can be considered a smoothed version of the histogram. Their main advantage over the latter is that they do not depends on the size of the bins. Let's create density plots for the same two variables:","63848845":"and plot it:","af3b9816":"# 3. Multivariate visualization\n\nMultivariate plots allow us to see relationships between two and more different variables, all the one figure. Just as in the case of univariate plots, the specific type of visualization will depends on the type variables being analzed.\n\n<h2> 3.1 Quantitative vs. Quantitative <\/h2>\n\n<h3> Correlation matrix <\/h3>\n\nLet's look at the correlations among the numerical varaibles in our dataset. This information is important to know as there are Machine Learning algorithms (for example, linear and lgistic regresion) that do not handle highly correlated input variables well.\n\nFirst, we will use the method `corr()` on a DataFrame that calculates the correlation between each pair of features. Then, we pass the resulting correlation matrix to `heatmap()` from `seaborn`, which renders a color-coded matrix for the provided values:","a7e32dd1":"<h2> 3.2 Quantitative vs. Categorical <\/h2>\n\nIn this section, we will make our simple quantitative plots a little more exciting. We will try to gain new insights for churn prediction from the interactions between the numerical and categorical features.\n\nMore specifically, let's see how the input variables are related to the target variable Churn.\n\nPreviously, you learned about scatter plots. Additionally, their points can be color or size coded so that the values of a third categorical variable are also presented in the same figure. We can achieve this with the `scatter()` function seen above, but, let's try a new function called `lmplot()` and use the paramter `hue` to indicate our categorical feature of interest:","49d40748":"<h3> Scatter plot <\/h3>\n\nThe scatter plot displays values of two numerical variables as Cartesian coordinates in 2D space. Scatter plots in 3D are also possible.\n\nLet's try out the function `scatter()` from the `matplotlib` library:","ec51bd3c":"<h2> 2.2 Categorical and binary features <\/h2>\n\nCategorical features take on a fixed number of values. Each of these values assigns an observation to a corresponding group, known as a category, which reflects some quanlitative property of the example. Binary variables are an important special case of categorical variables when the number of possible values is exactly 2. If the values of a categorical variable are ordered, it is called ordinal.\n\n\n<h3> Frequency table <\/h3>\n\nLet's check the class balance in our dataset by looking at the distribution of the target variable: the churn rate. First, we will get a frequency table, which shows how frequent each value of the categorical variable is. For this, we will use the `value_counts()` method:","f4484de0":"# 1. DasetSet\n\nBefore we get to the data, lets' initialize our environment:","ffd6e10c":"<h3> Histograms and density plots <\/h3>\n\nThe easiest way to look at the distribution of a numerical variable is to plot its histpgram using the DataFrame's Method `hist()`.","e01d4974":"From this chart, we can see that the greatest discrepancy in distrubution between the two groups is for three variables: Total day minutes, Customer service calls, and Numer vmail messages.\n\nLet's look at the distribution of day minutes spoken for the loyal and disloyal customers separately. We will create box and violin plots for Total day minutes grouped by the target variable.","3946fc81":"<h3> Violin plot <\/h3>\n\nThe last type of distribution plots that we will consider is a violin plot.\n\nLook at the figures below. On the left, we see the already familiar box plot. To the right, there is violin plot with the kernel density estimate on both sides.","be1c55c3":"It is also possible to plot a distribution of observations with `seabron's` `distplot()`. For example, let's look at the distribution of Total day minutes. By default, the plot displays the histogram with the `kernel density estumate` (KDE) on top.","7463ffe5":"<h3> Box plot <\/h3>\n\nAnother useful tpe of visualization is a box plot. `seaborn` does a greate job here:","42410768":"Its output is mostly self-explanatory. 25%, 50%, 75% are the corresponding `percentiles`.","f9e50648":"The height of the histogram bars here is normed and shows the density rather than the number of examples in each bin.","166c8357":"<h3> describe() <\/h3>\n\nIn addition to graphical tools, in order to get the exact numerical statistics of the distribution, we can use the method `describe()` of a DataFrame:","9c578c2a":"<h3> Bar plot <\/h3>\n\nThe bar plot is a graphical representation of the frequency table. The easiest way to create it is to use the `seborn's` function `countplot()`. There is another function in seabron that is somewhat confusingly called `barplot()` and is mostly used for representation of some basic statistics of a numerical variable grouped by a categorical feature.\n\nLet's plot the distributions for two categorical variables:","d927f595":"<b> An observation: <\/b> the churn rate increases significantly after 4 or more calls to customer service.\n\nNow, let's look at the relationship between Churn adn the binary features, international plan and Voice mail plan.","f8657462":"We will leave out the State and CHurn features and convert the values `\"Yes\"`\/`\"NO\"` of the binary features into numerical values using `pandas.Series.map():`","d91f7952":"Let's color this t-SNE representation according to the churn (blue for loyal customer, and orange for those who churned).","cad13020":"<h3> Contingency table <\/h3>\n\nIn addition to using graphical means for categrical analysis, there is a traditional tool from statistics: a contingency table, also called a cross tabulation. It shows a multivariate frequency distribution of categorical variables in tabular form. In particular, it allows us to see the distribution of one variable conditional on the other by looking along a column or row.\n\nLet's try to see how Churn is related to the categorical variable State by creating a cross tabulation:","60772ad6":"<h2> 3.3 Categorical vs. Categorical <\/h2>\n\nAs we saw earlier in this article, the variable Customer service calls has few unique values and, thus, can be considered either numerical or ordinal. We have already seen its distribution with a count plot. Now, we are interested in the relationship between this ordinal feature and the target variable Churn.\n\nLet's look at the distruibution of the numer of calls to customer service, again using a count plot. This time, let's also pass the parameter `hue=Churn` that adds a categorical dimension to the plot:"}}