{"cell_type":{"b8cca9c1":"code","39b29a37":"code","3e4e495e":"code","423cac83":"code","c8e30731":"code","8a6e59a6":"code","7237ee91":"code","59ad17b0":"code","c242230a":"code","bb165b29":"code","579e8a1b":"code","67ac097c":"code","1e4ff984":"code","e661c4c1":"code","3ff87404":"code","58013c15":"code","3d02b57e":"code","f866a2fe":"code","7663b671":"code","f0489ff8":"code","9d2930d4":"code","60109dda":"code","2c0daff2":"code","14ec46e6":"code","8393fa76":"code","6c23c682":"code","37321955":"code","f2bcd722":"code","6131e92a":"code","edd66766":"code","3405da01":"code","66042751":"code","c7acd085":"code","7822b54d":"code","de7e7cc8":"code","ec74e814":"code","e0d57331":"code","66604017":"code","c3beb927":"code","90e1262f":"code","f820b257":"code","e5139efb":"code","3e62894c":"code","129bd1c5":"code","fb2a571b":"code","6b241623":"code","a53dbaf3":"code","5779d47b":"code","b6367af1":"code","9a5ee742":"code","c1534966":"code","2033da83":"code","3a21c0b2":"code","f23a5617":"code","c516f8eb":"code","ba019252":"code","8105d707":"code","237dc2c7":"code","32318536":"code","5797217a":"code","62b6eee3":"code","3b8bb27c":"code","a75d338e":"code","5438999d":"code","cde88cbc":"markdown","a36e6a19":"markdown","252e8bc6":"markdown","323dd41c":"markdown","871162d0":"markdown","0e2f6624":"markdown","d5643c91":"markdown","ca5158b7":"markdown","b8e28970":"markdown","6fbe3c0d":"markdown","bd7eee33":"markdown","139c4cd6":"markdown","250d3c04":"markdown","7a3c3b9d":"markdown","95f7d3b1":"markdown","dff3ed81":"markdown","01e4e2ad":"markdown"},"source":{"b8cca9c1":"# import the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nsns.set_style('darkgrid')\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n\nfrom sklearn.ensemble import ExtraTreesClassifier, VotingClassifier, GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgbm\nfrom xgboost import XGBClassifier, XGBRegressor\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')","39b29a37":"# Import the data\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")","3e4e495e":"train.describe()","423cac83":"train.info()","c8e30731":"# Check for null values\ntrain.isna().sum()","8a6e59a6":"sns.countplot(data=train, x=\"Survived\");","7237ee91":"sns.countplot(data=train, x='Sex');","59ad17b0":"plt.figure(figsize=(14, 6))\nsns.lineplot(data=train, y='Survived', x='Age');","c242230a":"train_male = train[train[\"Sex\"]=='male']\ntrain_female = train[train[\"Sex\"]=='female']","bb165b29":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\nsns.lineplot(data=train_male, y='Survived', x='Age', ax=ax[0])\nsns.lineplot(data=train_female, y='Survived', x='Age', ax=ax[1]);","579e8a1b":"sns.countplot(data=train, x='Pclass')","67ac097c":"plt.figure(figsize=(8, 5))\nsns.countplot(data=train, x='Pclass', hue='Survived');","1e4ff984":"train.groupby('Pclass').Fare.median()","e661c4c1":"plt.figure(figsize=(8, 5))\nsns.countplot(data=train, x='Parch', hue='Survived')","3ff87404":"sns.countplot(data=train, x='Embarked', hue='Survived')","58013c15":"sns.countplot(data=train, x='SibSp');","3d02b57e":"fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\nsns.histplot(data=train, x='Fare', ax=ax[0])\nsns.histplot(data=train, x='Age', ax=ax[1])","f866a2fe":"train.groupby('Pclass').Fare.median()","7663b671":"train","f0489ff8":"def fill_nan(df):\n    \n    # Fill Age\n    df[\"Age\"] = df[\"Age\"].fillna(np.mean(train[\"Age\"]))\n    \n    # Fill Fare\n    median_fare = df['Fare'].median()\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    \n    # Fill cabin\n    df[\"Cabin\"] = df[\"Cabin\"].fillna('X')\n    \n    # Fill embarked\n    df[\"Embarked\"] = df['Embarked'].fillna('X')\n    \n    # Fill ticket\n    df['Ticket'] = df['Ticket'].fillna(\"X\")\n    \n    return df","9d2930d4":"train = fill_nan(train)","60109dda":"def encode(df):\n    le = LabelEncoder()\n    \n    # Encode cabin\n    df['Cabin'] = le.fit_transform(df['Cabin'])\n    \n    # Encode Sex\n    df[\"Sex\"] = le.fit_transform(df[\"Sex\"])\n    \n    # Encode Ticket\n    df['Ticket'] = le.fit_transform(df[\"Ticket\"])\n    \n    # Encode Embarked\n    df_embarked = pd.get_dummies(df[\"Embarked\"])\n    \n    # Concat one-hot encoded vectors into dataframe\n    df = pd.concat([df, df_embarked], axis=1)\n    \n    return df","2c0daff2":"train_encoded = encode(train)","14ec46e6":"train_encoded","8393fa76":"def add_features(df):\n    \n    # Add family size\n    df['family_size'] = df['SibSp'] + df['Parch']\n    \n    # See if the person is alone or not\n    df['Is_alone'] = 0\n    df.loc[df['family_size'] == 0, 'Is_alone'] = 1\n    \n    # Binning age\n    ## From the visualization of age we can divide the age into 4 groups\n    df['Binned_Age'] = pd.qcut(df['Age'], q=4)\n    \n    ## Encode binned age\n    le = LabelEncoder()\n    df['Binned_Age'] = le.fit_transform(df['Binned_Age'])\n    \n    # Bin fare\n    df['Binned_fare'] = pd.qcut(df['Fare'], q=4)\n    \n    # Encode fare\n    df['Binned_fare'] = le.fit_transform(df['Binned_fare'])\n    \n    return df","6c23c682":"train = add_features(train_encoded)","37321955":"corr = train.corr()","f2bcd722":"sns.heatmap(corr);","6131e92a":"umap_df = train.drop(['Name', 'Survived', 'PassengerId', 'Embarked'], axis=1)","edd66766":"from umap import UMAP","3405da01":"umap_2d = UMAP(n_components=2, init='random')\nprojections = umap_2d.fit_transform(umap_df)","66042751":"# Visualize UMAP\nfig = px.scatter(projections, x=0, y=1, color=train.Survived, labels={'color':'Survived', '0':'x_component', '1':'y_component'})\nfig.show()","c7acd085":"X = train.drop([\"Name\", 'Survived', 'PassengerId', 'Embarked'], axis=1)\ny = train[\"Survived\"]","7822b54d":"def cross_validate(X, y, model, params, folds=5, display_clf_report=False):\n\n    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n    for fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n        print(f\"Fold: {fold}\")\n        x_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n        x_ts, y_ts = X.iloc[ts_idx], y.iloc[ts_idx]\n\n        clf = model(**params)\n        clf.fit(x_tr, y_tr,\n                eval_set=[(x_ts, y_ts)],\n                early_stopping_rounds=100,\n                verbose=False)\n\n        pred = clf.predict(x_ts)\n        score = accuracy_score(y_ts, pred)\n        loss = log_loss(y_ts, pred)\n        print(f\" Log loss: {loss}\")\n        print(f\" Accuracy: {score}\")\n        print()\n        \n        if display_clf_report:\n            print(classification_report(y_ts, pred))\n        \n        print(\"-\"*50)\n    \n    return clf","de7e7cc8":"lgbm_params = {\n    'objective':'binary',\n    'boosting':'gbdt',\n    'metric': 'binary_logloss',\n    'n_estimators': 1000,\n    'objective': 'binary',\n    'random_state': 42,\n    'learning_rate': 0.002,\n    'min_child_samples': 150,\n    'reg_alpha': 0.003,\n    'reg_lambda': 8.97,\n    'num_leaves': 20,\n    'max_depth': 45,\n    #'colsample_bytree': 0.18,\n    #'subsample': 0.013,\n    'subsample_freq': 2,\n    \"bagging_fraction\":0.65,\n    \"feature_fraction\":0.65,\n    'max_bin': 33\n}","ec74e814":"lgbm_model = cross_validate(X, y, LGBMClassifier, lgbm_params, folds=5, display_clf_report=False)","e0d57331":"cb_params = {\n    'loss_function': 'Logloss',\n    'eval_metric': 'Logloss',\n    'random_seed': 42,\n    'max_depth': 8,\n    'learning_rate': 0.01,\n    'n_estimators': 2000,\n    'max_bin': 280,\n    'min_data_in_leaf': 64,\n    'l2_leaf_reg': 0.01,\n    'subsample': 0.8\n}","66604017":"cbr_model = cross_validate(X, y, CatBoostClassifier, cb_params, folds=5)","c3beb927":"import gc\ngc.collect()","90e1262f":"xgb_params = {\n    'eval_metric':'logloss',\n    \"seed\":42,\n    \"n_estimators\":1000\n}","f820b257":"xgb_clf = cross_validate_boosting(X, y, XGBClassifier, xgb_params, folds=5)","e5139efb":"param_xgbr = {\n    'eval_metric':'logloss',\n    'n_estimators':1000,\n    'seed':42\n}","3e62894c":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","129bd1c5":"xgbr = XGBRegressor(**param_xgbr)\nmodel_xgbr = xgbr.fit(x_train, y_train)","fb2a571b":"pred = model_xgbr.predict(x_test)","6b241623":"test_pseudo = test.copy()","a53dbaf3":"test_pseudo = fill_nan(test_pseudo)\ntest_encoded = encode(test_pseudo)\ntest_pseudo = add_features(test_encoded)","5779d47b":"preds = model_xgbr.predict(test_pseudo[X.columns])\ntest_pseudo[\"target\"] = preds","b6367af1":"test_pseudo = test_pseudo[ (test_pseudo['target']<=0.01) | (test_pseudo['target']>=0.99) ].copy()\ntest_pseudo.loc[ test_pseudo['target']>=0.5, 'target' ] = 1\ntest_pseudo.loc[ test_pseudo['target']<0.5, 'target' ] = 0","9a5ee742":"test_pseudo['target'] = test_pseudo['target'].astype('int')","c1534966":"test_pseudo['Survived'] = test_pseudo['target']","2033da83":"test_pseudo.drop('target', axis=1, inplace=True)","3a21c0b2":"train_pseudo = pd.concat([train, test_pseudo],axis=0)","f23a5617":"X_pseudo = train_pseudo.drop([\"Name\", 'Survived', 'PassengerId', 'Embarked'], axis=1)\ny_pseudo = train_pseudo[\"Survived\"]","c516f8eb":"xgb_clf_pseudo = cross_validate_boosting(X_pseudo, y_pseudo, XGBClassifier, xgb_params, folds=5)","ba019252":"lgbm.plot_importance(lgbm_model);","8105d707":"xgb.plot_importance(xgb_clf_pseudo)","237dc2c7":"test_nan = fill_nan(test)","32318536":"test_encode = encode(test_nan)","5797217a":"test = add_features(test_encode)","62b6eee3":"pred_lgbm = lgbm_model.predict(test_encode[X.columns])\npred_cb = cbr_model.predict(test_encode[X.columns])\npred_xgb = xgb_clf.predict(test_encode[X.columns])\npred_pseudo = xgb_clf_pseudo.predict(test_encode[X.columns])","3b8bb27c":"blend1 = 0.6 * pred_xgb + 0.4 * pred_lgbm\nblend2 = 0.4 * pred_xgb + 0.3 * pred_lgbm + 0.3 * pred_cb\nblend3 = 0.5 * pred_xgb + 0.5 * pred_pseudo","a75d338e":"blend1 = blend1.astype('int')\nblend2 = blend2.astype('int')\nblend3 = blend3.astype('int')","5438999d":"# LGBM \nsubmission[\"Survived\"] =  pred_lgbm\nsubmission.to_csv(\"LGBM Predictions.csv\", index=False)\n\n# Catboost\nsubmission[\"Survived\"] = pred_cb\nsubmission.to_csv(\"Catboost predictions.csv\", index=False)\n\n# XGBoost\nsubmission['Survived'] = pred_xgb\nsubmission.to_csv(\"XGBoost predictions.csv\", index=False)\n\n# XGB Pseudo\nsubmission['Survived'] = pred_pseudo\nsubmission.to_csv(\"XGBoost(Pseudo) predictions.csv\", index=False)\n\n# Blend 1\nsubmission['Survived'] = blend1\nsubmission.to_csv(\"Blending 1.csv\", index=False)\n\n# Blend 2\nsubmission['Survived'] = blend2\nsubmission.to_csv(\"Blending 2.csv\", index=False)\n\n# Blend 3\nsubmission['Survived'] = blend3\nsubmission.to_csv(\"Blending 3.csv\", index=False)","cde88cbc":"## LGBM Classifier","a36e6a19":"* Umap is dimensionality reduction technique. It is faster than TSNE.\n* UMAP is fast and preserves the global structure i.e. the distance between data points within clusters and between clusters are preserved.","252e8bc6":"## Pseudo Labelling","323dd41c":"# Titanic Dataset","871162d0":"## Submission","0e2f6624":"## XGB Regressor","d5643c91":"## XGBoost","ca5158b7":"## Visualization","b8e28970":"## Feature Importance","6fbe3c0d":"* #Females survived more than #males.","bd7eee33":"## Baseline Model","139c4cd6":"## Catboost","250d3c04":"## Umap","7a3c3b9d":"## Coorelation matrix","95f7d3b1":"* #People from Pclass 1 and 2 survived more than class 3","dff3ed81":"## Feature Engineering","01e4e2ad":"## Preprocessing"}}