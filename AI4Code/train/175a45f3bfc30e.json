{"cell_type":{"1b48547a":"code","0db1b64e":"code","ef6e4a6a":"code","cc923af2":"code","dac4670a":"code","876952d0":"code","2dc2bef6":"code","479a08da":"code","98ce09fd":"code","15533a5e":"code","97e6c3d8":"code","e48e23d9":"code","59e16963":"code","1025b70b":"code","6c2af8d8":"code","43196cfa":"code","225d615d":"code","8f5fd020":"code","4ef1800b":"code","08328cab":"code","b35115f0":"code","3bc2b92b":"code","eea78fcf":"code","64d38288":"code","deb9badc":"code","c046ab67":"code","d8cbacaf":"code","f412c6de":"markdown","fe9e8ef3":"markdown","23ca0bdc":"markdown","ba461ff2":"markdown","0daab7cd":"markdown","e2aa7eb2":"markdown","e2747606":"markdown","4c350cdf":"markdown","faa694d1":"markdown","c3b3d39c":"markdown","833a2a19":"markdown","118c0cfc":"markdown","13686cb1":"markdown","ee8549cd":"markdown","6bfd06b1":"markdown","f121e8fd":"markdown","05196f0a":"markdown"},"source":{"1b48547a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\npd.set_option('max_columns', 50)\nplt.style.use('bmh')\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","0db1b64e":"calendar = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")","ef6e4a6a":"sales_train_validation = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")","cc923af2":"sample_submission = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sample_submission.csv\")","dac4670a":"sell_prices = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")","876952d0":"calendar.head(8)","2dc2bef6":"sales_train_validation.head(4)","479a08da":"sell_prices.head(4)","98ce09fd":"sample_submission.head(4)","15533a5e":"d_cols = [c for c in sales_train_validation.columns if 'd_' in c] # sales data columns\n\n# Below we are chaining the following steps in pandas:\n# 1. Select the item.\n# 2. Set the id as the index, Keep only sales data columns\n# 3. Transform so it's a column\n# 4. Plot the data\nsales_train_validation.loc[sales_train_validation['id'] == 'FOODS_3_090_CA_3_validation'] \\\n    .set_index('id')[d_cols] \\\n    .T \\\n    .plot(figsize=(15, 5),\n          title='FOODS_3_090_CA_3 sales by \"d\" number',\n          color=next(color_cycle))\nplt.legend('')\nplt.show()","97e6c3d8":"# Calendar data looks like this (only showing columns we care about for now)\ncalendar[['d','date','event_name_1','event_name_2',\n     'event_type_1','event_type_2', 'snap_CA']].head()","e48e23d9":"# Merge calendar on our items' data\nexample = sales_train_validation.loc[sales_train_validation['id'] == 'FOODS_3_090_CA_3_validation'][d_cols].T\nexample = example.rename(columns={8412:'FOODS_3_090_CA_3'}) # Name it correctly\nexample = example.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\nexample = example.merge(calendar, how='left', validate='1:1')\nexample.set_index('date')['FOODS_3_090_CA_3'] \\\n    .plot(figsize=(15, 5),\n          color=next(color_cycle),\n          title='FOODS_3_090_CA_3 sales by actual sale dates')\nplt.show()\n\n# Select more top selling examples\nexample2 = sales_train_validation.loc[sales_train_validation['id'] == 'HOBBIES_1_234_CA_3_validation'][d_cols].T\nexample2 = example2.rename(columns={6324:'HOBBIES_1_234_CA_3'}) # Name it correctly\nexample2 = example2.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\nexample2 = example2.merge(calendar, how='left', validate='1:1')\n\nexample3 = sales_train_validation.loc[sales_train_validation['id'] == 'HOUSEHOLD_1_118_CA_3_validation'][d_cols].T\nexample3 = example3.rename(columns={6776:'HOUSEHOLD_1_118_CA_3'}) # Name it correctly\nexample3 = example3.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\nexample3 = example3.merge(calendar, how='left', validate='1:1')","59e16963":"examples = ['FOODS_3_090_CA_3','HOBBIES_1_234_CA_3','HOUSEHOLD_1_118_CA_3']\nexample_df = [example, example2, example3]\nfor i in [0, 1, 2]:\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 3))\n    example_df[i].groupby('wday').mean()[examples[i]] \\\n        .plot(kind='line',\n              title='average sale: day of week',\n              lw=5,\n              color=color_pal[0],\n              ax=ax1)\n    example_df[i].groupby('month').mean()[examples[i]] \\\n        .plot(kind='line',\n              title='average sale: month',\n              lw=5,\n              color=color_pal[4],\n\n              ax=ax2)\n    example_df[i].groupby('year').mean()[examples[i]] \\\n        .plot(kind='line',\n              lw=5,\n              title='average sale: year',\n              color=color_pal[2],\n\n              ax=ax3)\n    fig.suptitle(f'Trends for item: {examples[i]}',\n                 size=20,\n                 y=1.1)\n    plt.tight_layout()\n    plt.show()","1025b70b":"twenty_examples = sales_train_validation.sample(20, random_state=529) \\\n        .set_index('id')[d_cols] \\\n    .T \\\n    .merge(calendar.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')","6c2af8d8":"fig, axs = plt.subplots(10, 2, figsize=(15, 20))\naxs = axs.flatten()\nax_idx = 0\nfor item in twenty_examples.columns:\n    twenty_examples[item].plot(title=item,\n                              color=next(color_cycle),\n                              ax=axs[ax_idx])\n    ax_idx += 1\nplt.tight_layout()\nplt.show()","43196cfa":"sales_train_validation['cat_id'].unique()","225d615d":"sales_train_validation.groupby('cat_id').count()['id'] \\\n    .sort_values() \\\n    .plot(kind='barh', figsize=(15, 5), title='Count of Items by Category')\nplt.show()","8f5fd020":"past_sales = sales_train_validation.set_index('id')[d_cols] \\\n    .T \\\n    .merge(calendar.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')\n\n\nfor i in sales_train_validation['cat_id'].unique():\n    items_col = [c for c in past_sales.columns if i in c]\n    past_sales[items_col] \\\n        .sum(axis=1) \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Total Sales by Item Type')\nplt.legend(sales_train_validation['cat_id'].unique())\nplt.show()","4ef1800b":"past_sales_clipped = past_sales.clip(0, 1)\nfor i in sales_train_validation['cat_id'].unique():\n    items_col = [c for c in past_sales.columns if i in c]\n    (past_sales_clipped[items_col] \\\n        .mean(axis=1) * 100) \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Inventory Sale Percentage by Date',\n              style='.')\nplt.ylabel('% of Inventory with at least 1 sale')\nplt.legend(sales_train_validation['cat_id'].unique())\nplt.show()","08328cab":"store_list = sell_prices['store_id'].unique()\nfor s in store_list:\n    store_items = [c for c in past_sales.columns if s in c]\n    past_sales[store_items] \\\n        .sum(axis=1) \\\n        .rolling(90).mean() \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Rolling 90 Day Average Total Sales (10 stores)')\nplt.legend(store_list)\nplt.show()","b35115f0":"fig, axes = plt.subplots(5, 2, figsize=(15, 10), sharex=True)\naxes = axes.flatten()\nax_idx = 0\nfor s in store_list:\n    store_items = [c for c in past_sales.columns if s in c]\n    past_sales[store_items] \\\n        .sum(axis=1) \\\n        .rolling(7).mean() \\\n        .plot(alpha=1,\n              ax=axes[ax_idx],\n              title=s,\n              lw=3,\n              color=next(color_cycle))\n    ax_idx += 1\n# plt.legend(store_list)\nplt.suptitle('Weekly Sale Trends by Store ID')\nplt.tight_layout()\nplt.show()","3bc2b92b":"# ----------------------------------------------------------------------------\n# Author:  Nicolas P. Rougier\n# License: BSD\n# ----------------------------------------------------------------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\n\n\ndef calmap(ax, year, data):\n    ax.tick_params('x', length=0, labelsize=\"medium\", which='major')\n    ax.tick_params('y', length=0, labelsize=\"x-small\", which='major')\n\n    # Month borders\n    xticks, labels = [], []\n    start = datetime(year,1,1).weekday()\n    for month in range(1,13):\n        first = datetime(year, month, 1)\n        last = first + relativedelta(months=1, days=-1)\n\n        y0 = first.weekday()\n        y1 = last.weekday()\n        x0 = (int(first.strftime(\"%j\"))+start-1)\/\/7\n        x1 = (int(last.strftime(\"%j\"))+start-1)\/\/7\n\n        P = [ (x0,   y0), (x0,    7),  (x1,   7),\n              (x1,   y1+1), (x1+1,  y1+1), (x1+1, 0),\n              (x0+1,  0), (x0+1,  y0) ]\n        xticks.append(x0 +(x1-x0+1)\/2)\n        labels.append(first.strftime(\"%b\"))\n        poly = Polygon(P, edgecolor=\"black\", facecolor=\"None\",\n                       linewidth=1, zorder=20, clip_on=False)\n        ax.add_artist(poly)\n    \n    ax.set_xticks(xticks)\n    ax.set_xticklabels(labels)\n    ax.set_yticks(0.5 + np.arange(7))\n    ax.set_yticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n    ax.set_title(\"{}\".format(year), weight=\"semibold\")\n    \n    # Clearing first and last day from the data\n    valid = datetime(year, 1, 1).weekday()\n    data[:valid,0] = np.nan\n    valid = datetime(year, 12, 31).weekday()\n    # data[:,x1+1:] = np.nan\n    data[valid+1:,x1] = np.nan\n\n    # Showing data\n    ax.imshow(data, extent=[0,53,0,7], zorder=10, vmin=-1, vmax=1,\n              cmap=\"RdYlBu_r\", origin=\"lower\", alpha=.75)","eea78fcf":"print('The lowest sale date was:', past_sales.sum(axis=1).sort_values().index[0],\n     'with', past_sales.sum(axis=1).sort_values().values[0], 'sales')\nprint('The lowest sale date was:', past_sales.sum(axis=1).sort_values(ascending=False).index[0],\n     'with', past_sales.sum(axis=1).sort_values(ascending=False).values[0], 'sales')","64d38288":"from sklearn.preprocessing import StandardScaler\nsscale = StandardScaler()\npast_sales.index = pd.to_datetime(past_sales.index)\nfor i in sales_train_validation['cat_id'].unique():\n    fig, axes = plt.subplots(3, 1, figsize=(20, 8))\n    items_col = [c for c in past_sales.columns if i in c]\n    sales2013 = past_sales.loc[past_sales.index.isin(pd.date_range('31-Dec-2012',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2013.values.reshape(-1, 1)))\n    calmap(axes[0], 2013, vals.reshape(53,7).T)\n    sales2014 = past_sales.loc[past_sales.index.isin(pd.date_range('30-Dec-2013',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2014.values.reshape(-1, 1)))\n    calmap(axes[1], 2014, vals.reshape(53,7).T)\n    sales2015 = past_sales.loc[past_sales.index.isin(pd.date_range('29-Dec-2014',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2015.values.reshape(-1, 1)))\n    calmap(axes[2], 2015, vals.reshape(53,7).T)\n    plt.suptitle(i, fontsize=30, x=0.4, y=1.01)\n    plt.tight_layout()\n    plt.show()","deb9badc":"fig, ax = plt.subplots(figsize=(15, 5))\nstores = []\nfor store, d in sell_prices.query('item_id == \"FOODS_3_090\"').groupby('store_id'):\n    d.plot(x='wm_yr_wk',\n          y='sell_price',\n          style='.',\n          color=next(color_cycle),\n          figsize=(15, 5),\n          title='FOODS_3_090 sale price over time',\n         ax=ax,\n          legend=store)\n    stores.append(store)\n    plt.legend()\nplt.legend(stores)\nplt.show()","c046ab67":"sell_prices['Category'] = sell_prices['item_id'].str.split('_', expand=True)[0]\nfig, axs = plt.subplots(1, 3, figsize=(15, 4))\ni = 0\nfor cat, d in sell_prices.groupby('Category'):\n    ax = d['sell_price'].apply(np.log1p) \\\n        .plot(kind='hist',\n                         bins=20,\n                         title=f'Distribution of {cat} prices',\n                         ax=axs[i],\n                                         color=next(color_cycle))\n    ax.set_xlabel('Log(price)')\n    i += 1\nplt.tight_layout()","d8cbacaf":"thirty_day_avg_map = sales_train_validation.set_index('id')[d_cols[-30:]].mean(axis=1).to_dict()\nfcols = [f for f in sample_submission.columns if 'F' in f]\nfor f in fcols:\n    sample_submission[f] = sample_submission['id'].map(thirty_day_avg_map).fillna(0)\n    \nsample_submission.to_csv('..\/submission.csv', index=False)","f412c6de":"# M5 Forecasting Challenge\n- This competition will use the metric: **Weighted Root Mean Squared Scaled Error** (RMSSE) <br\/>\n- We are tasked with forecasting hierarchical sales data from Wal-Mart.<br\/>\n- The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details.<br\/>\n- In addition, it has explanatory variables such as price, promotions, day of the week, and special events.","fe9e8ef3":"# Sale Prices\nWe are given historical sale prices of each item. Lets take a look at our example item from before.\n- It looks to me like the price of this item is growing.\n- Different stores have different selling prices.","23ca0bdc":"# What exactly are we trying to predict?\nWe are trying for forecast sales for 28 forecast days. The sample submission has the following format:\n- The columns represent 28 forecast days. We will fill these forecast days with our predictions.\n- The rows each represent a specific item. This id tells us the item type, state, and store. We don't know what these items are exactly.","ba461ff2":"Looking at the same data a different way, we can plot a rolling 7 day total demand count by store. Note clearly that some stores have abrupt changes in their demand, it could be that the store expanded or a new competitor was built near by. Either way this is imporant to note when creating predictive models about demand pattern. ","0daab7cd":"# Sales broken down by time variables\n- Now that we have our example item lets see how it sells by:\n    - Day of the week\n    - Month\n    - Year","e2aa7eb2":"# Sales by Store\nWe are provided data for 10 unique stores. What are the total sales by stores?\n- Note that some stores are more steady than others.\n- CA_2 seems to have a big change occur in 2015","e2747606":"Some interesting things to note from these heatmaps:\n- Food tends to have lower number of purchases as the month goes on. Could this be because people get their paychecks early in the month?\n- Household and Hobby items sell much less in January - after the Holiday season is over.\n- Cleary weekends are more popular shopping days regardless of the item category.","4c350cdf":"## TODO\n- Simple prediction based on historical average sale by day of week\n- Facebook prophet model\n- lgbm\/xgb model based on day features","faa694d1":"# A submission\n- Submit the average value from the past 30 days","c3b3d39c":"# Data Files\n- `calendar.csv` - Contains information about the dates on which the products are sold.\n- `sales_train_validation.csv` - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\n- `sample_submission.csv` - The correct format for submissions. Reference the Evaluation tab for more info.\n- `sell_prices.csv` - Contains information about the price of the products sold per store and date.\n\nNot available yet:\n- `sales_train_evaluation.csv` - Available one month before competition deadline. Will include sales [d_1 - d_1941]","833a2a19":"# Combined Sales over Time by Type\n- We have several item types:\n    - Hobbies\n    - Household\n    - Foods\n- Lets plot the total demand over time for each type","118c0cfc":"# Visualizing the data for a single item\n- Lets take a random item that sell a lot and see how it's sales look across the training data.\n- `FOODS_3_090_CA_3_validation` sells a lot\n- Note there are days where it appears the item is unavailable and sales flatline","13686cb1":"# Lets look at a lot of different items!\n- Lets put it all together to plot 20 different items and their sales\n- Some observations from these plots:\n    - It is common to see an item unavailable for a period of time.\n    - Some items only sell 1 or less in a day, making it very hard to predict.\n    - Other items show spikes in their demand (super bowl sunday?) possibly the \"events\" provided to us could help with these.","ee8549cd":"## Merging the data with real dates\n- We are given a calendar with additional information about past and future dates.\n- The calendar data can be merged with our days data\n- From this we can find weekly and annual trends","6bfd06b1":"# Sales Heatmap Calendar","f121e8fd":"# Rollout of items being sold.\n- We can see the some items come into supply that previously didn't exist. Similarly some items stop being sold completely.\n- Lets plot the sales, but only count if item is selling or not selling (0 -> not selling, >0 -> selling)\n- This plot shows us that many items are being slowly introduced into inventory, so many of them will not register a sale at the beginning of the provided data.","05196f0a":"We are given historic sales data in the `sales_train_validation` dataset.\n- rows exist in this dataset for days d_1 to d_1913. We are given the department, category, state, and store id of the item.\n- d_1914 - d_1941 represents the `validation` rows which we will predict in stage 1\n- d_1942 - d_1969 represents the `evaluation` rows which we will predict for the final competition standings."}}