{"cell_type":{"0aed4459":"code","d61ae979":"code","7a1699ef":"code","0c59553e":"code","063cbe08":"code","2446f2aa":"code","e5429280":"code","eeac2e32":"code","6b5dc282":"code","61b8f753":"code","ac364846":"code","896a2ae7":"code","d167bec6":"code","f70cd685":"code","b63505e5":"code","949db77a":"code","d7d86e14":"code","86469d40":"code","dcf81573":"code","f1c97843":"code","19ef9c80":"code","51798e81":"code","156192d2":"code","f53909c0":"code","200937aa":"code","86426b4f":"code","dee51252":"code","1fd844ac":"code","35e4ad65":"code","ccfad89d":"code","8ab5e9a9":"code","07e14e89":"code","d753fe77":"code","8d6daf89":"code","7bc71c3a":"code","961ceeb2":"code","3a1a3259":"code","2384add7":"code","3f50b6b6":"code","68ebffb4":"code","7eaa9070":"code","a5a77b67":"code","453a94c1":"code","cc15864d":"code","fc1ff5a7":"code","3076d510":"code","3cedafe0":"code","6ec92329":"code","9d5c93ef":"code","56a9eeb3":"code","3b3a0dd8":"code","11ceabc1":"markdown","7b30475a":"markdown","1306c0ce":"markdown","50866b03":"markdown","2ce63a86":"markdown","ca6bb407":"markdown","22fe4eaa":"markdown","326f0714":"markdown","b4628f0b":"markdown","91dee02f":"markdown","14cbcf3f":"markdown","29438fb2":"markdown","e191f7f2":"markdown","75d11e06":"markdown","e23d5445":"markdown","86ec70bf":"markdown","7ab3241b":"markdown","59d489df":"markdown","3c837b03":"markdown","ffabaf2e":"markdown","8a514b4f":"markdown","a9ba4f1d":"markdown","0a1bf891":"markdown","dc142ba5":"markdown","537f31e4":"markdown","db8cb40d":"markdown","c14c0b06":"markdown","35db7543":"markdown","02ae78dd":"markdown","44fdfd47":"markdown","1633dc4d":"markdown"},"source":{"0aed4459":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\n\nimport string\nimport warnings\nfrom pprint import PrettyPrinter\n\nwarnings.filterwarnings('ignore')\npprint = PrettyPrinter().pprint\n\nSEED = 42","d61ae979":"def concat_df(train_data, test_data):\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\ndef divide_df(all_data):\n    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_all = concat_df(df_train, df_test)\n\ndf_train.name = 'Training Set'\ndf_test.name = 'Test Set'\ndf_all.name = 'All Set'\n\ndfs = [df_train, df_test]\n\nprint('Number of Training Examples = {}'.format(df_train.shape[0]))\nprint('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\nprint('Training X Shape = {}'.format(df_train.shape))\nprint('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0]))\nprint('Test X Shape = {}'.format(df_test.shape))\nprint('Test y Shape = {}\\n'.format(df_test.shape[0]))\nprint(df_train.columns)\nprint(df_test.columns)","7a1699ef":"print(df_train.info())\ndf_train.sample(3)","0c59553e":"print(df_test.info())\ndf_test.sample(3)","063cbe08":"def display_missing(df):\n    for col in df.columns.tolist():\n        print('{:>11} column missing values: {:>3}'.format(col, df[col].isnull().sum()))\n    print('\\n')\n    \nfor df in dfs:\n    print('{}'.format(df.name))\n    display_missing(df)","2446f2aa":"# corr(): Compute pairwise correlation of columns, excluding NA\/null values\n# abs(): Return a Series\/DataFrame with absolute numeric value of each element\n# unstack(): Pivot a level of the (necessarily hierarchical) index labels\ndf_all_corr = df_all.corr() \\\n    .abs() \\\n    .unstack() \\\n    .sort_values(kind='quicksort', ascending=False) \\\n    .reset_index()\n\ndf_all_corr.rename(columns={\n    'level_0': 'Feature 1',\n    'level_1': 'Feature 2',\n    0: 'Correlation Coefficient'\n}, inplace=True)\n\ndf_all_corr[df_all_corr['Feature 1'] == 'Age']","e5429280":"age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\nage_by_pclass_sex\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {:>6}s: {}'.format(\n            pclass,\n            sex,\n            age_by_pclass_sex[sex][pclass]\n        ))\nprint('Median age of all: {}'.format(df_all['Age'].median()))\n\n# Filling the missing value in Age with the medians of Sex and Pclass groups\ndf_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'] \\\n    .apply(lambda x: x.fillna(x.median()))","eeac2e32":"df_all[df_all['Embarked'].isnull()]","6b5dc282":"#  When I googled Stone, Mrs. George Nelson (Martha Evelyn),\n# I found that she embarked from S (Southampton) with her maid Amelie Icard,\n# in this page Martha Evelyn Stone: Titanic Survivor.  \n#  \"Mrs Stone boarded the Titanic in Southampton on 10 April 1912\n# and was travelling in first class with her maid Amelie Icard.\n# She occupied cabin B-28.\"\n#  Missing values in Embarked are filled with S with this information.\n\ndf_all['Embarked'] = df_all['Embarked'].fillna('S')","61b8f753":"df_all[df_all['Fare'].isnull()]","ac364846":"med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp'])['Fare'].median()\nmed_fare = med_fare[3][0][0]\ndf_all['Fare'] = df_all['Fare'].fillna(med_fare)","896a2ae7":"# M stands for Missing\ndf_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\ndrop_columns = [\n    'Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin',\n    'PassengerId', 'Ticket'\n]\n# transpose(): Transpose index and columns\ndf_all_decks = df_all.groupby(['Deck', 'Pclass']) \\\n    .count() \\\n    .drop(columns=drop_columns) \\\n    .rename(columns={'Name': 'Count'}) \\\n    .transpose()\n\ndef get_pclass_dist(df):\n    deck_counts = {\n        'A': {}, 'B': {}, 'C': {},\n        'D': {}, 'E': {}, 'F': {},\n        'G': {}, 'M': {}, 'T': {}\n    }\n    decks = df.columns.levels[0]\n    \n    for deck in decks:\n        for pclass in range(1, 4):\n            try:\n                count = df[deck][pclass][0]\n                deck_counts[deck][pclass] = count\n            except KeyError:\n                deck_counts[deck][pclass] = 0\n                \n    df_decks = pd.DataFrame(deck_counts)\n    deck_percentages = {}\n    \n    for col in df_decks.columns:\n        deck_percentages[col] = [\n            (count \/ df_decks[col].sum()) * 100 for count in df_decks[col]\n        ]\n        \n    return deck_counts, deck_percentages\n\ndef display_pclass_dist(percentages):\n    df_percentage = pd.DataFrame(percentages).transpose()\n    deck_names = (\n        'A', 'B', 'C',\n        'D', 'E', 'F',\n        'G', 'M', 'T'\n    )\n    bar_count = np.arange(len(deck_names))\n    bar_width = 0.85\n    \n    pclass1 = df_percentage[0]\n    pclass2 = df_percentage[1]\n    pclass3 = df_percentage[2]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n    \n    plt.show()\n    \nall_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\npprint(all_deck_count)\npprint(all_deck_per)\ndisplay_pclass_dist(all_deck_per)","d167bec6":"#  There is one person on the boat deck in T cabin\n# and he is a 1st class passenger.\n#  T cabin passenger has the closest resemblance to A deck passengers\n# so he is grouped with A deck\nidx = df_all[df_all['Deck'] == 'T'].index\ndf_all.loc[idx, 'Deck'] = 'A'","f70cd685":"drop_columns_all_decks_survived = [\n    'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Pclass',\n    'Cabin', 'PassengerId', 'Ticket'\n]\ndf_all_decks_survived = df_all \\\n    .groupby(['Deck', 'Survived']) \\\n    .count() \\\n    .drop(columns=drop_columns_all_decks_survived) \\\n    .rename(columns={'Name': 'Count'}) \\\n    .transpose()\n\ndef get_survived_dist(df):\n    surv_counts = {\n        'A': {}, 'B': {}, 'C': {},\n        'D': {}, 'E': {}, 'F': {},\n        'G': {}, 'M': {}\n    }\n    decks = df.columns.levels[0]\n    \n    for deck in decks:\n        for survive in range(0, 2):\n            surv_counts[deck][survive] = df[deck][survive][0]\n            \n    df_surv = pd.DataFrame(surv_counts)\n    surv_percentages = {}\n    \n    for col in df_surv.columns:\n        surv_percentages[col] = [\n            (count \/ df_surv[col].sum()) * 100 for count in df_surv[col]\n        ]\n        \n    return surv_counts, surv_percentages\n\ndef display_surv_dist(percentages):\n    \n    df_survived_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85    \n\n    not_survived = df_survived_percentages[0]\n    survived = df_survived_percentages[1]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n \n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n    \n    plt.show()\n    \nall_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\npprint(all_surv_count)\npprint(all_surv_per)\ndisplay_surv_dist(all_surv_per)","b63505e5":"df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\ndf_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\ndf_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n\ndf_all['Deck'].value_counts()","949db77a":"df_all.drop(['Cabin'], inplace=True, axis=1)\n\ndf_train, df_test = divide_df(df_all)\ndfs = [df_train, df_test]\n\nfor df in dfs:\n    display_missing(df)","d7d86e14":"survived = df_train['Survived'].value_counts()[1]\nnot_survived = df_train['Survived'].value_counts()[0]\nsurvived_per = survived \/ df_train.shape[0]\nnot_survived_per = not_survived \/ df_train.shape[0]\n\nprint(\n    '{} of {} passengers survived and it is the {:.2f}% of the training set.'.format(\n        survived,\n        df_train.shape[0],\n        survived_per\n    )\n)\nprint(\n    '{} of {} passengers didnt survive and it is the {:.2f}% of the training set.'.format(\n        not_survived,\n        df_train.shape[0],\n        not_survived_per\n    )\n)\n\nplt.figure(figsize=(10, 8))\nsns.countplot(df_train['Survived'])\n\nplt.xlabel('Survival', size=15, labelpad=15)\nplt.ylabel('Passenger Count', size=15, labelpad=15)\nplt.xticks((0, 1), [\n    'Not Survived ({0:.2f}%)'.format(not_survived_per),\n    'Survived ({0:.2f}%)'.format(survived_per)\n])\nplt.tick_params(axis='x', labelsize=13)\nplt.tick_params(axis='y', labelsize=13)\n\nplt.title('Training Set Survival Distribution', size=15, y=1.05)\n\nplt.show()","86469d40":"df_train_corr = df_train \\\n    .drop(['PassengerId'], axis=1) \\\n    .corr() \\\n    .abs() \\\n    .unstack() \\\n    .sort_values(kind='quicksort', ascending=False) \\\n    .reset_index()\n\ndf_train_corr.rename(columns={\n    'level_0': 'Feature 1',\n    'level_1': 'Feature 2',\n    0: 'Correlation Coefficient'\n}, inplace=True)\n\ndf_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)\ndf_train_corr_nd = df_train_corr.drop(\n    df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index\n)\n\ndf_test_corr = df_test \\\n    .drop(['PassengerId'], axis=1) \\\n    .corr() \\\n    .abs() \\\n    .unstack() \\\n    .sort_values(kind='quicksort', ascending=False) \\\n    .reset_index()\n\ndf_test_corr.rename(columns={\n    'level_0': 'Feature 1',\n    'level_1': 'Feature 2',\n    0: 'Correlation Coefficient'\n}, inplace=True)\n\ndf_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\ndf_test_corr_nd = df_test_corr.drop(\n    df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index\n)\ndf_test_corr_nd","dcf81573":"corr = df_train_corr_nd['Correlation Coefficient'] > 0.1\ndf_train_corr_nd[corr]","f1c97843":"corr = df_test_corr_nd['Correlation Coefficient'] > 0.1\ndf_test_corr_nd[corr]","19ef9c80":"fig, axs = plt.subplots(nrows=2, figsize=(15, 15))\n\nsns.heatmap(\n    df_train.drop(['PassengerId'], axis=1).corr(),\n    ax=axs[0],\n    annot=True,\n    square=True,\n    cmap='coolwarm',\n    annot_kws={'size': 14}\n)\nsns.heatmap(\n    df_test.drop(['PassengerId'], axis=1).corr(),\n    ax=axs[1],\n    annot=True,\n    square=True,\n    cmap='coolwarm',\n    annot_kws={'size': 14}\n)\n\nfor i in range(1):    \n    axs[i].tick_params(axis='x', labelsize=14)\n    axs[i].tick_params(axis='y', labelsize=14)\n    \naxs[0].set_title('Training Set Correlations', size=15)\naxs[1].set_title('Test Set Correlations', size=15)\n\nplt.show()","51798e81":"cont_features = ['Age', 'Fare']\nsurv = df_train['Survived'] == 1\n\nfig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\nplt.subplots_adjust(right=1.5)\n\nfor i, feature in enumerate(cont_features):    \n    # Distribution of survival in feature\n    sns.distplot(df_train[~surv][feature], label='Not Survived', hist=True, color='#e74c3c', ax=axs[0][i])\n    sns.distplot(df_train[surv][feature], label='Survived', hist=True, color='#2ecc71', ax=axs[0][i])\n    \n    # Distribution of feature in dataset\n    sns.distplot(df_train[feature], label='Training Set', hist=False, color='#e74c3c', ax=axs[1][i])\n    sns.distplot(df_test[feature], label='Test Set', hist=False, color='#2ecc71', ax=axs[1][i])\n    \n    axs[0][i].set_xlabel('')\n    axs[1][i].set_xlabel('')\n    \n    for j in range(2):        \n        axs[i][j].tick_params(axis='x', labelsize=20)\n        axs[i][j].tick_params(axis='y', labelsize=20)\n    \n    axs[0][i].legend(loc='upper right', prop={'size': 20})\n    axs[1][i].legend(loc='upper right', prop={'size': 20})\n    axs[0][i].set_title('Distribution of Survival in {}'.format(feature), size=20, y=1.05)\n\naxs[1][0].set_title('Distribution of {} Feature'.format('Age'), size=20, y=1.05)\naxs[1][1].set_title('Distribution of {} Feature'.format('Fare'), size=20, y=1.05)\n        \nplt.show()","156192d2":"cat_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n\nfig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\nplt.subplots_adjust(right=1.5, top=1.25)\n\nfor i, feature in enumerate(cat_features, 1):    \n    plt.subplot(2, 3, i)\n    sns.countplot(x=feature, hue='Survived', data=df_train)\n    \n    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n    plt.ylabel('Passenger Count', size=20, labelpad=15)    \n    plt.tick_params(axis='x', labelsize=20)\n    plt.tick_params(axis='y', labelsize=20)\n    \n    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 18})\n    plt.title('Count of Survival in {} Feature'.format(feature), size=20, y=1.05)\n\nplt.show()","f53909c0":"df_all['Fare'] = pd.qcut(df_all['Fare'], 13)","200937aa":"fig, axs = plt.subplots(figsize=(22, 9))\nsns.countplot(x='Fare', hue='Survived', data=df_all)\n\nplt.xlabel('Fare', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=10)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n\nplt.show()","86426b4f":"df_all['Age'] = pd.qcut(df_all['Age'], 10)","dee51252":"fig, axs = plt.subplots(figsize=(22, 9))\nsns.countplot(x='Age', hue='Survived', data=df_all)\n\nplt.xlabel('Age', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Survival Counts in {} Feature'.format('Age'), size=15, y=1.05)\n\nplt.show()","1fd844ac":"df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1","35e4ad65":"family_map = {\n    1: 'Alone',\n    2: 'Small',\n    3: 'Small',\n    4: 'Small',\n    5: 'Medium',\n    6: 'Medium',\n    7: 'Large',\n    8: 'Large',\n    11: 'Large'\n}\ndf_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)","ccfad89d":"fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\nplt.subplots_adjust(right=1.5)\n\nsns.barplot(x=df_all['Family_Size'].value_counts().index, y=df_all['Family_Size'].value_counts().values, ax=axs[0][0])\nsns.countplot(x='Family_Size', hue='Survived', data=df_all, ax=axs[0][1])\n\naxs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\naxs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n\nsns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\nsns.countplot(x='Family_Size_Grouped', hue='Survived', data=df_all, ax=axs[1][1])\n\naxs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\naxs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n\nfor i in range(2):\n    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n    for j in range(2):\n        axs[i][j].tick_params(axis='x', labelsize=20)\n        axs[i][j].tick_params(axis='y', labelsize=20)\n        axs[i][j].set_xlabel('')\n        axs[i][j].set_ylabel('')\n\nplt.show()","8ab5e9a9":"df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')","07e14e89":"fig, axs = plt.subplots(figsize=(12, 9))\nsns.countplot(x='Ticket_Frequency', hue='Survived', data=df_all)\n\nplt.xlabel('Ticket Frequency', size=15, labelpad=20)\nplt.ylabel('Passenger Count', size=15, labelpad=20)\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\n\nplt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\nplt.title('Count of Survival in {} Feature'.format('Ticket Frequency'), size=15, y=1.05)\n\nplt.show()","d753fe77":"df_all['Title_Original'] = df_all['Name'] \\\n    .str.split(', ', expand=True)[1] \\\n    .str.split('.', expand=True)[0]\ndf_all['Title'] = df_all['Name'] \\\n    .str.split(', ', expand=True)[1] \\\n    .str.split('.', expand=True)[0]\n\ndf_all['Title'] = df_all['Title'].replace(\n    ['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'],\n    'Miss\/Mrs\/Ms'\n)\ndf_all['Title'] = df_all['Title'].replace(\n    ['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'],\n    'Dr\/Military\/Noble\/Clergy'\n)\n\ndf_all['Is_Married'] = 0\ndf_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1","8d6daf89":"fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\nsns.barplot(\n    x=df_all['Title_Original'].value_counts().index,\n    y=df_all['Title_Original'].value_counts().values,\n    ax=axs[0]\n)\n\naxs[0].tick_params(axis='x', labelsize=10)\naxs[1].tick_params(axis='x', labelsize=15)\n\nfor i in range(2):    \n    axs[i].tick_params(axis='y', labelsize=15)\n\naxs[0].set_title('Title Feature Value Counts', size=20, y=1.05)\n\nsns.barplot(\n    x=df_all['Title'].value_counts().index,\n    y=df_all['Title'].value_counts().values,\n    ax=axs[1]\n)\naxs[1].set_title('Title Feature Value Counts After Grouping', size=20, y=1.05)\n\nplt.show()\ndf_all.drop('Title_Original', axis=1, inplace=True)","7bc71c3a":"def extract_surname(data):    \n    \n    families = []\n    \n    for i in range(len(data)):        \n        name = data.iloc[i]\n\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n            \n        families.append(family)\n            \n    return families\n\ndf_all['Family'] = extract_surname(df_all['Name'])\ndf_train = df_all.loc[:890]\ndf_test = df_all.loc[891:]\ndfs = [df_train, df_test]","961ceeb2":"non_unique_families = [\n    x for x in df_train['Family'].unique() if x in df_test['Family'].unique()\n]\nnon_unique_tickets = [\n    x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()\n]\n\ndf_family_survival_rate = df_train \\\n    .groupby('Family')['Survived', 'Family', 'Family_Size'] \\\n    .median()\ndf_ticket_survival_rate = df_train \\\n    .groupby('Ticket')['Survived', 'Ticket', 'Ticket_Frequency'] \\\n    .median()\n    \nfamily_rates = {}\nticket_rates = {}\n\nfor i in range(len(df_family_survival_rate)):\n    if df_family_survival_rate.index[i] in non_unique_families \\\n        and df_family_survival_rate.iloc[i, 1] > 1:\n        family_rates[df_family_survival_rate.index[i]] = \\\n            df_family_survival_rate.iloc[i, 0]\n\nfor i in range(len(df_ticket_survival_rate)):\n    if df_ticket_survival_rate.index[i] in non_unique_tickets \\\n        and df_ticket_survival_rate.iloc[i, 1] > 1:\n        ticket_rates[df_ticket_survival_rate.index[i]] = \\\n            df_ticket_survival_rate.iloc[i, 0]","3a1a3259":"mean_survival_rate = np.mean(df_train['Survived'])\n\ntrain_family_survival_rate = []\ntrain_family_survival_rate_NA = []\ntest_family_survival_rate = []\ntest_family_survival_rate_NA = []\n\nfor i in range(len(df_train)):\n    if df_train['Family'][i] in family_rates:\n        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n        train_family_survival_rate_NA.append(1)\n    else:\n        train_family_survival_rate.append(mean_survival_rate)\n        train_family_survival_rate_NA.append(0)\n        \nfor i in range(len(df_test)):\n    if df_test['Family'].iloc[i] in family_rates:\n        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n        test_family_survival_rate_NA.append(1)\n    else:\n        test_family_survival_rate.append(mean_survival_rate)\n        test_family_survival_rate_NA.append(0)\n\ndf_train['Family_Survival_Rate'] = train_family_survival_rate\ndf_train['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\ndf_test['Family_Survival_Rate'] = test_family_survival_rate\ndf_test['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n\ntrain_ticket_survival_rate = []\ntrain_ticket_survival_rate_NA = []\ntest_ticket_survival_rate = []\ntest_ticket_survival_rate_NA = []\n\nfor i in range(len(df_train)):\n    if df_train['Ticket'][i] in ticket_rates:\n        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n        train_ticket_survival_rate_NA.append(1)\n    else:\n        train_ticket_survival_rate.append(mean_survival_rate)\n        train_ticket_survival_rate_NA.append(0)\n        \nfor i in range(len(df_test)):\n    if df_test['Ticket'].iloc[i] in ticket_rates:\n        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n        test_ticket_survival_rate_NA.append(1)\n    else:\n        test_ticket_survival_rate.append(mean_survival_rate)\n        test_ticket_survival_rate_NA.append(0)\n        \ndf_train['Ticket_Survival_Rate'] = train_ticket_survival_rate\ndf_train['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\ndf_test['Ticket_Survival_Rate'] = test_ticket_survival_rate\ndf_test['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA","2384add7":"for df in [df_train, df_test]:\n    df['Survival_Rate'] = \\\n        (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) \/ 2\n    df['Survival_Rate_NA'] = \\\n        (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) \/ 2","3f50b6b6":"non_numeric_features = [\n    'Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare'\n]\n\nfor df in dfs:\n    for feature in non_numeric_features:\n        df[feature] = LabelEncoder().fit_transform(df[feature])","68ebffb4":"cat_features = [\n    'Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped'\n]\nencoded_features = []\n\nfor df in dfs:\n    for feature in cat_features:\n        encoded_feature = OneHotEncoder() \\\n            .fit_transform(df[feature].values.reshape(-1, 1)) \\\n            .toarray()\n        n = df[feature].nunique()\n        cols = ['{}_{}'.format(feature, n) for n in range(1, n+1)]\n        encoded_df = pd.DataFrame(encoded_feature, columns=cols)\n        encoded_df.index = df.index\n        encoded_features.append(encoded_df)\n\ndf_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\ndf_test = pd.concat([df_test, *encoded_features[6:]], axis=1)","7eaa9070":"df_all = concat_df(df_train, df_test)\ndrop_cols = [\n    'Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped',\n    'Survived', 'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp',\n    'Ticket', 'Title', 'Ticket_Survival_Rate', 'Family_Survival_Rate',\n    'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA'\n]\ndf_all.drop(columns=drop_cols, inplace=True)\ndf_all.columns","a5a77b67":"X_train = StandardScaler() \\\n    .fit_transform(df_train.drop(columns=drop_cols))\ny_train = df_train['Survived'].values\nX_test = StandardScaler() \\\n    .fit_transform(df_test.drop(columns=drop_cols))\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(df_test.shape))","453a94c1":"#  single_best_model is a good model to start experimenting\n# and learning about decision trees.\n\nsingle_best_model = RandomForestClassifier(\n    criterion='gini',\n    n_estimators=1100,\n    max_depth=5,\n    min_samples_split=4,\n    min_samples_leaf=5,\n    max_features='auto',\n    oob_score=True,\n    random_state=SEED,\n    n_jobs=-1,\n    verbose=1\n)\n\n#  leaderboard_model overfits to test set\n# so it's not suggested to use models like this in real life projects.\n\nleaderboard_model = RandomForestClassifier(\n    criterion='gini',\n    n_estimators=1750,\n    max_depth=7,\n    min_samples_split=6,\n    min_samples_leaf=6,\n    max_features='auto',\n    oob_score=True,\n    random_state=SEED,\n    n_jobs=-1,\n    verbose=1\n)","cc15864d":"N = 5\noob = 0\nprobs = pd.DataFrame(\n    np.zeros((len(X_test), N*2)),\n    columns=[\n        'Fold_{}_Prob_{}'.format(i, j) for i in range(1, N+1) for j in range(2)\n    ]\n)\nimportances = pd.DataFrame(\n    np.zeros((X_train.shape[1], N)),\n    columns=[\n        'Fold_{}'.format(i) for i in range(1, N+1)\n    ],\n    index=df_all.columns\n)\nfprs = []\ntprs = []\nscores = []\n\nskf = StratifiedKFold(\n    n_splits=N,\n    random_state=N,\n    shuffle=True\n)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n    print('Fold {}\\n'.format(fold))\n    \n    leaderboard_model.fit(\n        X_train[trn_idx],\n        y_train[trn_idx]\n    )\n    \n    trn_fpr, trn_tpr, trn_thresholds = \\\n        roc_curve(\n            y_train[trn_idx],\n            leaderboard_model.predict_proba(X_train[trn_idx])[:, 1]\n        )\n    trn_auc_score = auc(trn_fpr, trn_tpr)\n    \n    val_fpr, val_tpr, val_thresholds = \\\n        roc_curve(\n            y_train[val_idx],\n            leaderboard_model.predict_proba(X_train[val_idx])[:, 1]\n        )\n    val_auc_score = auc(val_fpr, val_tpr)\n    \n    scores.append((trn_auc_score, val_auc_score))\n    fprs.append(val_fpr)\n    tprs.append(val_tpr)\n    \n    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = \\\n        leaderboard_model.predict_proba(X_test)[:, 0]\n    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = \\\n        leaderboard_model.predict_proba(X_test)[:, 1]\n    importances.iloc[:, fold-1] = leaderboard_model.feature_importances_\n    \n    oob += leaderboard_model.oob_score_ \/ N\n    print('Fold {} OOB Score: {}\\n'.format(fold, leaderboard_model.oob_score_))   \n    \nprint('Average OOB Score: {}'.format(oob))","fc1ff5a7":"importances['Mean_Importance'] = importances.mean(axis=1)\nimportances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\nimportances\n\nplt.figure(figsize=(15, 20))\nsns.barplot(\n    x='Mean_Importance',\n    y=importances.index,\n    data=importances\n)\n\nplt.xlabel('')\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Random Forest Classifier Mean Feature Importance Between Folds', size=15)\n\nplt.show()","3076d510":"def plot_roc_curve(fprs, tprs):\n    \n    tprs_interp = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n    f, ax = plt.subplots(figsize=(15, 15))\n    \n    # Plotting ROC for each fold and computing AUC scores\n    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n        tprs_interp[-1][0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n        \n    # Plotting ROC for random guessing\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n    \n    mean_tpr = np.mean(tprs_interp, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n    \n    # Plotting the mean ROC\n    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n    \n    # Plotting the standard deviation around the mean ROC Curve\n    std_tpr = np.std(tprs_interp, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n    \n    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n    ax.tick_params(axis='x', labelsize=15)\n    ax.tick_params(axis='y', labelsize=15)\n    ax.set_xlim([-0.05, 1.05])\n    ax.set_ylim([-0.05, 1.05])\n\n    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n    ax.legend(loc='lower right', prop={'size': 13})\n    \n    plt.show()\n\nplot_roc_curve(fprs, tprs)","3cedafe0":"probs","6ec92329":"class_survived = [col for col in probs.columns if col.endswith('Prob_1')]\nclass_survived","9d5c93ef":"probs['1'] = probs[class_survived].sum(axis=1) \/ N\nprobs['0'] = probs.drop(columns=class_survived).sum(axis=1) \/ N","56a9eeb3":"probs['pred'] = 0\npos = probs[probs['1'] >= 0.5].index\nprobs.loc[pos, 'pred'] = 1\nprobs[['1','0','pred']].head(10)","3b3a0dd8":"y_pred = probs['pred'].astype(int)\n\nsubmission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\nsubmission_df['PassengerId'] = df_test['PassengerId']\nsubmission_df['Survived'] = y_pred.values\nsubmission_df.to_csv('submissions.csv', header=True, index=False)\nsubmission_df.head()","11ceabc1":"## 2.4. Target Encoding\n\n - Name \uc73c\ub85c Family \uc0dd\uc131 (family name)\n - Family, Family_Size \uac12\uc744 \uc0ac\uc6a9\ud574 \uac00\uc871 \ub2f9 \uc0dd\uc874 \ud655\ub960 \uad6c\ud568\n - Ticket, Ticket_Frequency \uac12\uc744 \uc0ac\uc6a9\ud574 \ud2f0\ucf13 \ub2f9 \uc0dd\uc874 \ud655\ub960 \uad6c\ud568\n - Family_Survival_Rate\n    - \ud6c8\ub828 \ub370\uc774\ud130 \/ \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ubaa8\ub450 \uc788\ub294 Family \ub77c\uba74 \uac00\uc871 \ub2f9 \uc0dd\uc874 \ud655\ub960\uc744 \uc800\uc7a5\n    - \uc5b4\ub290 \ud55c \ucabd\uc5d0\ub77c\ub3c4 \uc5c6\ub294 \ub370\uc774\ud130\ub77c\uba74 \ud6c8\ub828 \ub370\uc774\ud130 \uc804\uccb4\uc758 \ud3c9\uade0 \uc0dd\uc874 \ud655\ub960\uc744 \uc800\uc7a5\n - Family_Survival_Rate_NA\n    - \ud6c8\ub828 \ub370\uc774\ud130 \/ \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ubaa8\ub450 \uc788\ub294 Family \uc778\uc9c0 \uc800\uc7a5 (1, 0)\n - Ticket_Survival_Rate\n    - \ud6c8\ub828 \ub370\uc774\ud130 \/ \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ubaa8\ub450 \uc788\ub294 Ticket \uc774\ub77c\uba74 \ud2f0\ucf13 \ub2f9 \uc0dd\uc874 \ud655\ub960\uc744 \uc800\uc7a5\n    - \uc5b4\ub290 \ud55c \ucabd\uc5d0\ub77c\ub3c4 \uc5c6\ub294 \ub370\uc774\ud130\ub77c\uba74 \ud6c8\ub828 \ub370\uc774\ud130 \uc804\uccb4\uc758 \ud3c9\uade0 \uc0dd\uc874 \ud655\ub960\uc744 \uc800\uc7a5\n - Ticket_Survival_Rate_NA\n    - \ud6c8\ub828 \ub370\uc774\ud130 \/ \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc5d0 \ubaa8\ub450 \uc788\ub294 Ticket \uc778\uc9c0 \uc800\uc7a5 (1, 0)\n - Survaival_Rate = (Ticket_Survival_Rate + Family_Survival_Rate) \/ 2\n - Survaival_Rate_NA = (Ticket_Survival_Rate_NA + Family_Survival_Rate_NA) \/ 2\n \n#### get family name","7b30475a":"# 2. Feature Engineering\n## 2.1. Binning Continuous Features\n### 2.1.1. Fare column","1306c0ce":"### 1.2.2. Embarked column","50866b03":"#### survival percentage in decks","2ce63a86":"## 0.3. Table of contents\n\n1. Exploratory Data Analysis\n    1. Overview\n    2. Missing Values\n        1. Age column\n        2. Embarked column\n        3. Fare column\n        4. Cabin column\n        5. Result of filling the missing values\n    3. Target Distribution\n    4. Correlations\n    5. Target Distribution in Feature\n        1. Continuous Features\n        2. Categorical Features\n2. Feature Engineering\n    1. Binding Continous Features\n        1. Fare column\n        2. Age column\n    2. Frequency Encoding\n    3. Title & is Married\n    4. Target Encoding\n    5. Feature Transformation\n        1. Label Encoding Non-Numerical Features\n        2. One-Hot Encoding the Categorical Features\n    6. Conclusion\n3. Model\n    1. Random Forest with StratifiedKFold\n    2. Feature Importance\n    3. ROC Curve\n    4. Submission","ca6bb407":"### 1.2.4. Cabin column\n#### passenger class distribution in decks","22fe4eaa":"### 1.2.1. Age column\n\n#### display correlation for Age column","326f0714":"## 3.1. Random Forest with StratifiedKFold","b4628f0b":"## 1.3. Target Distribution","91dee02f":"## 0.1. References\nhttps:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\n## 0.2. Import libraries and data","14cbcf3f":"### 2.1.2. Age column","29438fb2":"#### fill na with median value for Age column","e191f7f2":"## 2.2. Frequency Encoding\n - SibSp \uc640 Parch \ub97c \uc0ac\uc6a9\ud574 Family_Size \uc0dd\uc131\n - Family_Size \ub97c \uac00\uc9c0\uace0 Family_Size_Grouped \uc0dd\uc131\n - Ticket \uc744 \uac00\uc9c0\uace0 Ticket_Frequency \uc0dd\uc131","75d11e06":"- Passenger Class Distribution \uacfc Survival Percentage \ub370\uc774\ud130\ub97c \ud1b5\ud574 \uc5f0\uad00\uc774 \uc788\ub294 \uac78\ub85c \ud310\ub2e8\ub418\ub294 `Cabin` \ub370\uc774\ud130\ub4e4\uc744 `Deck` \uceec\ub7fc\uc73c\ub85c \uadf8\ub8f9\ud654\ud55c\ub2e4.","e23d5445":"### 1.5.2. Categorical Features","86ec70bf":"## 2.3. Title & is Married\n\n - Name \uc73c\ub85c Title \uc0dd\uc131\n - Title \ub85c Is_Married \uc0dd\uc131","7ab3241b":"#### add survlval rate columns","59d489df":"## 2.6. Conclusion","3c837b03":"## 3.3. ROC Curve","ffabaf2e":"#### get survival rate by family, family size, tickt and ticket frequency","8a514b4f":"## 2.5. Feature Transformation\n\n### 2.5.1. Label Encoding Non-Numerical Features","a9ba4f1d":"# 3. Model","0a1bf891":"## 1.2. Missing Values","dc142ba5":"### 2.5.2. One-Hot Encoding the Categorical Features","537f31e4":"### 1.2.3. Fare column","db8cb40d":"## 1.5. Target Distribution In Feature\n\n### 1.5.1. Continuous Features","c14c0b06":"## 3.2. Feature Importance","35db7543":"# 1. Exploratory Data Analysis\n\n## 1.1. Overview","02ae78dd":"### 1.2.5. Result of filling the missing values","44fdfd47":"## 3.4. Submission","1633dc4d":"## 1.4. Correlations"}}