{"cell_type":{"7dd8ff18":"code","22e62093":"code","11e3a263":"code","ec38b0ca":"code","d433bdf3":"code","1c9f8216":"code","b4c07125":"code","d66b85f3":"code","4da615d9":"code","f613a5f3":"code","38ae7e40":"code","f7211fc3":"code","15c6a5e0":"code","e32c2ee4":"code","bb179d41":"code","d62f3763":"code","f47f72ab":"code","e34ec8a4":"code","dd219a9c":"code","834b1aab":"code","bd26c187":"code","b4a75bcd":"markdown","9a43ec24":"markdown","878f2f0c":"markdown","0065b1b6":"markdown","b4bb1dbd":"markdown","6321f37d":"markdown","50171a8f":"markdown","3bdcd4a1":"markdown","e4652f96":"markdown","c44cc7b3":"markdown","7abe454d":"markdown","02aa76cd":"markdown","550aa178":"markdown"},"source":{"7dd8ff18":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer","22e62093":"train_df=pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\ntest_df=pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')","11e3a263":"train_df.head()","ec38b0ca":"train_df.info()","d433bdf3":"train_df.describe()","1c9f8216":"test_df.head()","b4c07125":"test_df.info()","d66b85f3":"test_df.describe()","4da615d9":"#replace the commas with dots and converting to float in credit_line_utilization column\ntest_df['credit_line_utilization'].replace(',','.',regex=True, inplace=True)\ntest_df[\"credit_line_utilization\"] = pd.to_numeric(test_df[\"credit_line_utilization\"])\ntrain_df['credit_line_utilization'].replace(',','.',regex=True, inplace=True)\ntrain_df[\"credit_line_utilization\"] = pd.to_numeric(train_df[\"credit_line_utilization\"])","f613a5f3":"#checking the column\ntrain_df.info()\ntest_df.info()","38ae7e40":"#Now it is float","f7211fc3":"test_df.columns","15c6a5e0":"#drop ID column\ntrain_df.drop(labels='Id', axis=1, inplace=True)\ntest_df.drop(labels='Id', axis=1, inplace=True)","e32c2ee4":"train_df.head()","bb179d41":"train_df.hist(train_df.columns.values.tolist(), figsize=(18,10))","d62f3763":"pd.value_counts(train_df['defaulted_on_loan']).plot.bar()\nplt.title('Frequency of Defaulted on Loan column')\nplt.xlabel('Defaulted on loan')\nplt.ylabel('Frequency')","f47f72ab":"#Checking the correlation before removing ooutiers\ncorr_matrix = train_df.corr()\nprint(corr_matrix[\"defaulted_on_loan\"].sort_values(ascending=False))\n(corr_matrix[\"defaulted_on_loan\"]).plot.bar()","e34ec8a4":"train_df.drop(train_df.index[train_df['number_of_previous_late_payments_up_to_59_days'] >8], inplace = True)\ntrain_df.drop(train_df.index[train_df['number_of_previous_late_payments_up_to_89_days'] >4], inplace = True)\ntrain_df.drop(train_df.index[train_df['number_of_previous_late_payments_90_days_or_more'] >5], inplace = True)\ntrain_df.drop(train_df.index[train_df['credit_line_utilization'] >4], inplace = True)\ntrain_df.drop(train_df.index[train_df['monthly_income'] >30000], inplace = True)\ntrain_df.drop(train_df.index[train_df['real_estate_loans'] >8], inplace = True)\ntrain_df.drop(train_df.index[train_df['ratio_debt_payment_to_income'] >2], inplace = True)","dd219a9c":"#checking distribution after removing outliers\ntrain_df.hist(train_df.columns.values.tolist(), figsize=(18,10))","834b1aab":"corr_matrix = train_df.corr()\nprint(corr_matrix[\"defaulted_on_loan\"].sort_values(ascending=False))\n(corr_matrix[\"defaulted_on_loan\"]).plot.bar()","bd26c187":"test_df.hist(test_df.columns.values.tolist(), figsize=(18,10))","b4a75bcd":"The correlation between columns and target variable is very low for now, we will recheck it after removing outliers.","9a43ec24":"### Removing outliers ","878f2f0c":"We can see that our correlation values increases significantly. I also chekced IsolationForest method to remove outliers however, the correlation values were less than manual removing technique. So I prefer manual removig for train data.","0065b1b6":"### Visualize distribution of numerical values for test data. ","b4bb1dbd":"## Visualize train data","6321f37d":"### Visualize distribution of numerical values for train data. ","50171a8f":"As we can see that now our data is more distributed. Let's recheck the correlation.","3bdcd4a1":"## Visualize test data","e4652f96":"From this graph we can visualize that, none of the graph look like bell curve, meaning it is not normally distributed. The reason of that is outliers in our data.For train model we will get rid of outliers by removing them.","c44cc7b3":"We can visualize that there is imbalancing in our 'defaulted_on_loan' column in train data, so we need to use balancing technique as well.","7abe454d":"## Reading the data","02aa76cd":"We can see the same scenario in our test data as well. The values are not distributed well. We can't remove outliers for this data. We can replace them to normalize our distribution.","550aa178":"We can see that credit_line_utilization column is shown as object although it is float. It  happened because of the commas in values. So we need to change commas to dots, and convert the values to float"}}