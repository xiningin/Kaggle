{"cell_type":{"8364f1f8":"code","734689d9":"code","ddb4c9a4":"code","5ae2bd1d":"code","ef4678c7":"code","4e5a2075":"code","26519859":"code","17578885":"code","b9cafd89":"code","b3bf8c52":"code","3f235fb5":"code","6a94b613":"code","e9babc06":"code","a1214ae5":"code","4be8979a":"code","19912582":"code","a88964b8":"code","523f501c":"code","51d163bd":"code","06305bfc":"code","b515a60a":"code","23e1c60e":"code","dd16e51b":"code","afcfb946":"code","58c6e65b":"code","729e8cdb":"code","97968ea1":"code","9aa001f1":"code","c9389106":"code","e8d04a2c":"code","66580c21":"code","3a5e23d6":"code","fc4cb858":"code","3f6eebed":"code","e4363e2c":"code","b22eb14f":"code","af2046b2":"code","34d7fc41":"code","52a54656":"code","3d279bf9":"code","4adbf61c":"code","f6ee7337":"code","6dd852bf":"code","86f49273":"code","bf16eef7":"markdown","cd5ad4fa":"markdown","903f258d":"markdown","0714fd53":"markdown","e10eeab2":"markdown","e6074dc5":"markdown","6ed1a8b3":"markdown","3c28f22b":"markdown","31836cf7":"markdown","2d3c9886":"markdown","d513f24f":"markdown","b749abb5":"markdown"},"source":{"8364f1f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","734689d9":"df=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")    ## Train dataset\n\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')  ## Test dataset","ddb4c9a4":"df.head()","5ae2bd1d":"df_test.head()","ef4678c7":"df.shape, df_test.shape","4e5a2075":"df.isnull().sum()","26519859":"df_test.isnull().sum()","17578885":"mean_val = df['Age'].mean()\nmean_val","b9cafd89":"df['Age'] = df['Age'].fillna(value=mean_val)","b3bf8c52":"mode_val = df['Embarked'].mode()\nmode_val","3f235fb5":"df['Embarked'] = df['Embarked'].fillna(value='S')  ","6a94b613":"df['Cabin'] = df['Cabin'].fillna(value='NaN')","e9babc06":"df.isnull().sum()","a1214ae5":"df_test.isnull().sum()","4be8979a":"df_test['Age'].mean()","19912582":"df_test['Age'] = df_test['Age'].fillna(value=(df_test['Age'].mean()))","a88964b8":"df_test['Cabin'].mode()","523f501c":"df_test['Cabin'] = df_test['Cabin'].fillna(value=(df_test['Cabin'].mode()[0]))","51d163bd":"df_test['Fare'] = df_test['Fare'].fillna(value=(df_test['Fare'].mean()))","06305bfc":"df_test.isnull().sum()","b515a60a":"df = df.astype({'SibSp':'object','Parch':'object','Pclass':'object'})","23e1c60e":"df_test = df_test.astype({'SibSp':'object','Parch':'object','Pclass':'object'})","dd16e51b":"df = pd.get_dummies(df.drop(['PassengerId','Name','Ticket','Cabin','Parch'],axis=1))","afcfb946":"df.head()","58c6e65b":"df.shape","729e8cdb":"df_test.head()","97968ea1":"df_test['Parch'].value_counts()  ## train Data does notcontain Parch_9\n## But test_X data contains Parch_9 its shape when we create dummies will (418,25), but we want it to be (418,24)\n## It is very much imp that the no. of columns train_X and test_X match\n## Now when we split the data to be trained we get shape of train_X with 24 columns \n## And so as test_X will be having 24 columns when we put Parch_9 into Parch_0","9aa001f1":"df_test['Parch'].replace({9:0},inplace=True)\ndf_test['Parch'].value_counts()","c9389106":"df_test = df_test.astype({'Parch':'object'})","e8d04a2c":"test_X = pd.get_dummies(df_test.drop(['PassengerId','Name','Ticket','Cabin','Parch'],axis=1))\ntest_X.head()","66580c21":"test_X.shape","3a5e23d6":"train_X = df.drop(['Survived'], axis=1)    ## X has the feature variables(Independent Var) which help in prediction of target\ntrain_y = df['Survived']                  ## Y has the Dependent var\n\ntrain_X.shape, train_y.shape","fc4cb858":"## MinMaxScaler scales down values in the range 0 to 1\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_scaled = scaler.fit_transform(train_X)","3f6eebed":"## X_scaled is an array O\/P, convert it into Panda DataFrame\n## X earlier contained the Features therefore it shld only now hold the scaled features\n\ntrain_X = pd.DataFrame(X_scaled, columns=train_X.columns)","e4363e2c":"train_X.head()   ## Range = 0 to 1","b22eb14f":"testx_scaled = scaler.fit_transform(test_X)\n\ntest_X = pd.DataFrame(testx_scaled, columns=test_X.columns)\ntest_X.head()","af2046b2":"from sklearn.ensemble import RandomForestClassifier","34d7fc41":"rf = RandomForestClassifier(n_estimators=100, max_depth=12)","52a54656":"rf.fit(train_X, train_y)","3d279bf9":"rf.score(train_X, train_y)","4adbf61c":"train_predict = rf.predict(train_X)","f6ee7337":"test_pred = rf.predict(test_X)","6dd852bf":"test_pred","86f49273":"output = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': test_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","bf16eef7":"# Convert categ. variables into binary valued ","cd5ad4fa":"# Remember we always need to SCALE our data bcoz sometimes the parameters have different units (Distance Based Algo. eg. KNN)","903f258d":"# Descision Tree","0714fd53":"# Random Forest algo\n","e10eeab2":"For Test","e6074dc5":"For Test","6ed1a8b3":"For test","3c28f22b":"# Data Types","31836cf7":"For Train","2d3c9886":"#  Imputing the missing values","d513f24f":"For train","b749abb5":"For Train"}}