{"cell_type":{"3b58e756":"code","061cf42f":"code","a84f8773":"code","4e310a5d":"code","198bb2be":"code","4195f379":"code","b0af6be2":"code","0bfdf973":"code","b6b3414f":"code","b5d3b950":"code","959e720e":"code","a091f6c5":"code","04119d9c":"markdown","e133aaef":"markdown","b7edfba2":"markdown","8dd459f5":"markdown","21dff98b":"markdown","e4268ffa":"markdown","ca6e21ff":"markdown","7fff4c88":"markdown","4d137711":"markdown","70539747":"markdown","b5a4e107":"markdown","205ecc65":"markdown","6ac0bbe6":"markdown"},"source":{"3b58e756":"# Import the libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","061cf42f":"# Load the data\ncifar = keras.datasets.cifar10\n\n(train_images, train_labels), (test_images, test_labels) = cifar.load_data()","a84f8773":"class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck']","4e310a5d":"# Divide the values by 255\ntrain_images, test_images = train_images \/ 255, test_images \/ 255","198bb2be":"# Plot the first 25 images in the training set\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i])\n    plt.xlabel(class_names[train_labels[i][0]])\nplt.show()","4195f379":"# Configure the layers\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\nmodel.add(keras.layers.MaxPooling2D((2, 2)))\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((2, 2)))\nmodel.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(64, activation='relu'))\nmodel.add(keras.layers.Dense(10, activation='softmax'))","b0af6be2":"# Display the model's architecture\nmodel.summary()","0bfdf973":"# Compile the model\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","b6b3414f":"# Fit the model\nhistory = model.fit(train_images, train_labels, epochs=10,\n                    validation_data=(test_images, test_labels))","b5d3b950":"# Create the accuracy plot\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\nplt.show()","959e720e":"# Make predictions\npredictions = model.predict(test_images)","a091f6c5":"# Plot the images for the first 25 predictions\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.gca().set_title(f'Predicted: {class_names[np.argmax(predictions[i])]}')\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_images[i])\n    plt.xlabel(f'Actual: {class_names[test_labels[i][0]]}')\n    plt.tight_layout()\nplt.show()","04119d9c":"Let's display the architecture of our model.","e133aaef":"Let's plot several images along with their predictions.","b7edfba2":"## Evaluating the Model\nNext, we can create a plot to compare how the model performs on the training and test sets","8dd459f5":"### Compiling the Model\nBefore training the model, we need to compile the model with the following settings:\n- Loss function: This measures how accurate the model is during training. For the loss function, we are going to use the sparse categorical cross entropy.\n- Optimizer: This is how the model is updated based on the data it sees and its loss function. We are going to use Adam, which is an optimization algorithm based on adaptive estimation of first-order and second-order moments.\n- Metrics: Used to monitor the training and testing steps. Here we will use accuracy, the fraction of the images that are correctly classified.","21dff98b":"## Loading the Data\nWe can import and load the CIFAR10 dataset directly from TensorFlow. Loading the dataset returns four NumPy arrays:\n- The train_images and train_labels arrays are the training set, which is the data the model uses to learn.\n- The model is tested against the test set, the test_images, and test_labels arrays.","e4268ffa":"### Fitting the Model\nNow, we can use the `model.fit` method to fits the model to the training data.","ca6e21ff":"To verify that the data is in the correct format, let's display the first 25 images from the training set along with the class name below each image.","7fff4c88":"## Making Predictions\nWith the model trained, we can now use it to make predictions on some images.","4d137711":"## Building the Model\nNow, we can build the neural network by configuring the layers of the model and compiling the model.","70539747":"## Preprocessing the Data\nSince the pixel values of the images fall in the range of 0 to 255, we need to normalize the pixel values to be between 0 and 1.","b5a4e107":"#  Convolutional Neural Network on CIFAR10 Dataset\nThis project is one of my Deep Learning projects. For this project, we have the [CIFAR10](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset that contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images.\n\nThe goal of this project is to create a Convolutional Neural Network (CNN) to classify CIFAR images.","205ecc65":"Each image is mapped to a single label. Since the class names are not included with the dataset, we will create a list to store these class names.","6ac0bbe6":"### Configuring the Layers\nThe CNN will mainly consist of a stack of `keras.layers.Conv2D` and `keras.layers.MaxPooling2D` layers. To complete our model, we will use `keras.layers.Flatten` to transform the 3D output to 1D, then add a `keras.layers.Dense` layer on top. Since CIFAR has 10 output classes, we will use a final `keras.layers.Dense` layer with 10 outputs and a softmax activation."}}