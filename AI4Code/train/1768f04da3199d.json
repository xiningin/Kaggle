{"cell_type":{"cb5cddd2":"code","c0197f3a":"code","4cb6d36b":"code","fd715fbb":"code","d5e86f07":"code","cf13b87c":"code","119c339c":"code","7833c194":"code","83d858d8":"code","07e8f4aa":"code","e8532bc3":"code","e353710b":"code","bd1e6c6c":"code","f01896e6":"code","18686559":"code","cd480cbd":"code","38f2b09e":"code","e873e349":"code","2b17ed29":"code","0b74e363":"code","3fef531a":"code","bb188391":"code","6210c607":"code","547a8d6e":"code","d9eb7b09":"code","ac54b58e":"code","ced28f7e":"code","71d7cbab":"code","5305777c":"code","505b67e8":"code","74911a81":"code","04e6f744":"code","67440eae":"code","7af4d37a":"code","a5b2246c":"markdown","fc90eb69":"markdown","251896fb":"markdown","3a205bd7":"markdown","581517d9":"markdown","b0253edd":"markdown","d38b75bd":"markdown","85821ccb":"markdown","1bb649f4":"markdown","4edaa068":"markdown","0dc87d46":"markdown","577d5365":"markdown","a81c055f":"markdown","602ad54d":"markdown","ac5015ab":"markdown","caa4e5b1":"markdown","2799be45":"markdown","cda47440":"markdown","7e41b8db":"markdown","c9664be8":"markdown","e53197a4":"markdown","a7ed8ab6":"markdown","06c94e63":"markdown","e12f820a":"markdown","2bbf3f23":"markdown","50953c9e":"markdown","050268af":"markdown","19c90f54":"markdown"},"source":{"cb5cddd2":"#Import Libraries\n#Pandas\nimport pandas as pd\n\n#Numpy\nimport numpy as np\n\n#Matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Seaborn\nimport seaborn as sns\n\n#Plotly\nimport plotly.figure_factory as ff\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objects as go\nimport plotly.express as px","c0197f3a":"# Read the first dataset\ntrain = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')","4cb6d36b":"# Let us look at the data\ntrain.head() ","fd715fbb":"# This includes the list of all columns\ntrain.columns","d5e86f07":"#Exploring the categorical variables in the dataset\ntrain.select_dtypes(include = \"object\").columns","cf13b87c":"#Exploring the numerical variables in the dataset\ntrain.select_dtypes(exclude =\"object\").columns","119c339c":"#Let's look at the info for the non.null count and data type of each column\ntrain.info()","7833c194":"#By default, describe shows only numerical attributes. \n#top shows the most occured instance in that column\ntrain.describe(include = \"object\").transpose()","83d858d8":"# Let us take the unique values from MSZoning\nlabel = train[\"MSZoning\"].unique()\nsizes = train[\"MSZoning\"].value_counts().values\n\n# Now we could define the Pie chart\n# pull is given as a fraction of the pie radius. This serves the same purpose as explode \nfig_pie1 = go.Figure(data=[go.Pie(labels=label, values=sizes, pull=[0.1, 0, 0, 0])])\n# Defining the layout\nfig_pie1.update_layout(title=\"Zone propotion\",    \n        font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#7f7f7f\"\n    ))\nfig_pie1.show()\n\n# Plotting multiple violinplots, including a box and scatter diagram\nfig_vio1 = px.violin(x = train['MSZoning'], y = train[\"SalePrice\"], box=True, points=\"all\")\n# Defining the layout\nfig_vio1.update_layout(\n    title=\"MS Zone-SalePrice\",\n    xaxis_title=\"MS Zone\",\n    yaxis_title=\"SalePrice\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18\n    ))\nfig_vio1.show()","07e8f4aa":"# getting the first 5 largest saleprice values\ntrain['SalePrice'].nlargest(5)","e8532bc3":"#identifying the expensive neighborhood after slicing the indexes\nHP_Index = [691,1182,1169,898,803]\ntrain['Neighborhood'].iloc[HP_Index]","e353710b":"# Plotting split boxplot, including a box and scatter diagram\nfig_box1 = px.box(x = train['Neighborhood'], y = train[\"SalePrice\"])\n\nfig_box1.update_layout(\n    title=\"Neighborhood - SalePrice\",\n    xaxis_title=\"Neighborhood\",\n    yaxis_title=\"SalePrice\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18\n    ))\nfig_box1.show()","bd1e6c6c":"#descriptive statistics summary\ntrain['SalePrice'].describe()","f01896e6":"#Plot histogram\nfig_hist1 = train['SalePrice'].iplot(kind='hist', opacity=0.75, color='#007959', title='SalePrice distribution', \n                                yTitle='Count', xTitle='SalePrice', bargap = 0.20)","18686559":"#jointplot - TotalBsmtSF vs SalePrice\n\nsns.jointplot(x='TotalBsmtSF',y='SalePrice',data=train, kind='reg', color= 'orange',height = 5, ratio = 2, space=0.01)\nsns.set(rc={'figure.figsize':(15,12)})","cd480cbd":"#jointplot - GrLivArea vs SalePrice\n\nsns.jointplot(x='GrLivArea',y='SalePrice',data=train, kind='reg', color= 'green',height = 5, ratio = 2, space=0.01)\nsns.set(rc={'figure.figsize':(15,12)})","38f2b09e":"# boxplot - YearBuilt - SalePrice\nfig_box2 = px.box(x = train['YearBuilt'], y = train[\"SalePrice\"])\n\nfig_box2.update_layout(\n    title=\"YearBuilt - SalePrice\",\n    xaxis_title=\"YearBuilt\",\n    yaxis_title=\"SalePrice\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18)\n    )\nfig_box2.show()","e873e349":"# swarmplot - OverallQual - SalePrice\nsns.swarmplot(x=\"OverallQual\", y=\"SalePrice\", data=train)","2b17ed29":"# Heatmap\n\n# Lets consider the correlation matrix\nCorrMat = train.corr() \n\n# using seaborn to create the heatmap\nfig, ax = plt.subplots(figsize=(20,15)) \nsns.heatmap(CorrMat,linecolor='white',linewidths=1, ax=ax)","0b74e363":"# Clustermap\n\nsns.clustermap(CorrMat,linecolor='white',linewidths=1)","3fef531a":"# creating pairplot using seaborn\n# let us first create a list of columns which are to be studied\n\nclmn1 = ['SalePrice', 'GarageArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF',  'OverallQual', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'LotFrontage', 'OverallCond']\n\nsns.pairplot(train[clmn1],palette='rainbow', height = 2.5)\nplt.show();","bb188391":"# Heatmap\n\n# Lets consider the correlation matrix\nCorrMat2 = train[clmn1].corr() \n\n# using seaborn to create the heatmap\nfig, ax = plt.subplots(figsize=(20,15)) \nsns.heatmap(CorrMat2,linecolor='white',linewidths=1, ax=ax, annot = True)","6210c607":"# Comparing SalePrice and FullBath\nfig, ax = plt.subplots(figsize=(15,10)) \nsns.boxplot(x=\"FullBath\", y=\"SalePrice\", data=train, palette='deep')\n\nplt.title(\"Sale Price - Full Bathrooms\")","547a8d6e":"# Comparing SalePrice and HalfBath\nfig, ax = plt.subplots(figsize=(10,10)) \nsns.boxplot(x=\"HalfBath\", y=\"SalePrice\", data=train, palette='muted')\n\nplt.title(\"Sale Price - Half Bathrooms\")","d9eb7b09":"# Comparing Overall Condition and HalfBath\n\nfig, ax = plt.subplots(figsize=(15,10)) \nsns.swarmplot(x=train['OverallCond'], y=train[\"SalePrice\"], data=train)\n\nplt.title(\"Sale Price - OverallCond\")","ac54b58e":"fig, ax = plt.subplots(figsize=(15,10)) \nsns.swarmplot(x=train['Electrical'], y=train[\"SalePrice\"], data=train)\n\nplt.title(\"Sale Price - Electrical\")","ced28f7e":"fig, ax = plt.subplots(figsize=(15,10)) \nsns.violinplot(x=\"GarageCars\", y=\"SalePrice\", data=train, palette='rainbow')\n\nplt.title(\"Sale Price - GarageCars\")","71d7cbab":"#Plot stripplot\nfig, ax = plt.subplots(figsize=(12,10)) \nsns.stripplot(x=\"Heating\", y=\"SalePrice\", data=train,jitter=True)","5305777c":"# Violin plot with hue\nfig, ax = plt.subplots(figsize=(12,10)) \nsns.violinplot(x=\"HeatingQC\", y=\"SalePrice\", data=train, hue='CentralAir',split=True,palette='Set1')","505b67e8":"# First of all the data type (object) related to kitchen quality is mapped to an integer value\nKitqua_map = {'Po': 0, 'Fa': 1,'TA': 2, 'Gd': 3,'Ex': 4}\ntrain['KitchenQual'] = train['KitchenQual'].map(Kitqua_map) \n\ntrain['KitchenQual']","74911a81":"# KitchenQuality - SalePrice\nfig, ax = plt.subplots(figsize=(15,10)) \nsns.violinplot(x=\"KitchenQual\", y=\"SalePrice\", data=train, palette='deep')\n\nplt.title(\"Sale Price - KitchenQual\")","04e6f744":"# Let us look at the total missing values in the data set\n# Lokking for any missing values in the dataframe column\nmiss_val = train.columns[train.isnull().any()]\n\n# printing out the columns and the total number of missing values of all the column\nfor column in miss_val:\n    print(column, train[column].isnull().sum())","67440eae":"# defining two empty lists for columns and its values\nnan_columns = []\nnan_values = []\n\nfor column in miss_val:\n    nan_columns.append(column)\n    nan_values.append(train[column].isnull().sum())\n\n# plotting the graph\nfig, ax = plt.subplots(figsize=(30,12))\nplt.bar(nan_columns, nan_values, color = 'orange', width = 0.5)\nax.set_xlabel(\"Count of missing values\")\nax.set_ylabel(\"Column Names\")\nax.set_title(\"Variables with missing values\");","7af4d37a":"#Exploring the numerical variables in the dataset\nnum_data = train.select_dtypes(exclude =\"object\").columns\n\n# now let us fill the missing values with the mean of the respective column\ntrain[num_data].apply(lambda x: x.fillna(x.mean()),axis=0)","a5b2246c":"# More Visualization of variables.","fc90eb69":"# Inference on a selected variable comparison to SalePrice\n\nThe main take away from the one to one comparison comprises of a set of details, namely:\n\n1. 'GrLivArea' and 'TotalBsmtSF' seem to be linearly related with 'SalePrice'. Both relationships are positive, which means that as one variable increases, the other also increases. In the case of 'TotalBsmtSF', we can see that the slope of the linear relationship is particularly high.\n\n2. 'YearBuilt' and 'OverallQual' also seem to be heavily related to 'SalePrice'. This says the better the house quality, higher the price.","251896fb":"So, it is clear from the plot that the highly expensive houses are in Northridge, followed by Northridge heights. On the contrary, the lowest price location in Iowa is at Rail Road (IDOTRR), followed by Old Town (OldTown)","3a205bd7":"Lets analyse it using a heatmap again. ","581517d9":"From the above data, there are few variables of some particular interest. It would be, as default, a very important factor to consider the area\/zone before building or buying a house. In this case when considering the same, so many choose to stay at Residential Low Density (RL) zone. Now let us look at the price range of the top 5 highly expensive houses.\n\nNow we could look into the MSZoning as a whole by plotting a pie chart. This gives us the percentage comparison of different MSZoning in the price estimation. Meanwhile it is also interesting to compare MSZoning with the SalePrice. This is plotted using a multiple violin plot, containing a box and scatter depiction. For a better data visualisation, I am using plotly. For self-exploring, I am happy to share the link with you https:\/\/plotly.com\/python\/","b0253edd":"# Correlation of variables\n\nAs we just looked at the comparison of a selected number of variables to the SalePrice, it is time to look at the correlation of variables to each other. For this comparison, I would be using the following plots\n1. Heatmap\n2. Clustermap - It uses hierarchal clustering to produce a clustered version of the heatmap\n3. Pairplot","d38b75bd":"**Bathroom size - SalePrice**","85821ccb":"**GarageCars - SalePrice**","1bb649f4":"**Heating variable**\n\nLet's look at the type of \"Heating\" at various houses, to see which is most commonly used heating type in houses.\nIt is also interesting to look at the heating quality and condition (\"HeatingQC\"), along with the central Air conditioning (\"CentralAir\"). ","4edaa068":"Few topics of this kernel, especially which is mentioned above has been collected from: https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\/notebook. Please take a look on his findings as well. ","0dc87d46":"**Electrical - SalePrice**","577d5365":"In this kernel a major session deals with the reason of our pursuit, \"SalePrice\". Before comparing the numerical and categorical relationship with the SalesPrice, let's look at the SalesPrice and look at its behaviour.","a81c055f":"# Plotting SalePrice vs Categorical variable","602ad54d":"Let us set the null values of all numerical variables to mean value of the respective column","ac5015ab":"From the visualization, it is quite evident that Gas forced air warm furnace ('GasA') is used at a majority of houses, followed by Gas hot water or steam Heat ('GasW').","caa4e5b1":"# Types of Data Analytics\n\nData analytics could be explained as an extensive usage of data to manipulate the data using a statistical and quantitative approach. This uses explanatory and predictive models and fact-based management to come to a conclusion.  It would be quite a nice idea to explore the different data analytics that data scientists use of a daily basis. These could be defined as the basic and key forms of data analytics. \n\n![image.png](attachment:image.png)\n\n**1. Descriptive analytics: What is happening?**\n\nThis is an interpretation of the historical data to understand changes of a data under study. It uses range of data to draw comparisons in a business. Few examples include monthly profit and loss statement, month over month sales growth. The clarity of the information that is been deducted depends on the use of data visualisation. \n\n**2. Regression or Diagnostic analytics: Why is it happening?**\n\nAs the process hints, it empowers an analyst to dig deep and find out the root cause of the problem. In this example of house price estimation, we deal with a regression analytics and compare and study different variables and find out how and why are the house prices high or low. \n\n**3. Predictive analytics: What is likely to happen?**\n\nThis is all about forecasting. To name few contents, this looks for the likelihood of an event happening in the future, estimating a time in which an event might happen. An example of this would include the prediction of a major health condition based on the age of a person. Let\u2019s say the older a person, the more vulnerable the person to a health weakness. \n\n**4. Prescriptive analytics: What do I need to do?**\n\nThis deals with a better course of action from the user side. It uses the complex techniques used in the above analytics in knowing what happened, why has it even occurred, what might happen to determine the best course of action to take. Traffic application could be considered as a best example of this. It chooses the best route for us, considering the distance of each route, speed at which one travel and the current traffic conditions. \n\n**Reference** : https:\/\/www.kdnuggets.com\/2017\/07\/4-types-data-analytics.html","2799be45":"From the above heatmap and cluster map, we could infer variables which are very much correlated and few variables which are not even correlated. \nTo name a few, let us consider the following variables.\n\n1. 'GarageCars' and 'GarageArea', these 2 varibales are strongly correlated.\n2. 'TotalBsmtSF' and '1stFlrSF', these 2 variables are strongly correlated too.\n3. 'OverallCond' and 'YearBuilt' are those variables which are negatively correlated.\n\nNow let us look at the pairplot connecting the dots. ","cda47440":"# Comparing SalePrice and variables\n\nThe SalePrice graph seems to deviate from the normal distribution. The highest frequency of SalePrice is in the range between 130k to 150k. From the dataset, it is almost impossible to select the key parameters that control the SalePrice. However, it would be in this case our own wisdom to choose a few variables (choosing both categorical and numerical variables) for the purpose of this study. \n\nFrom the set of variables, I have selected the following variables, which can play an important role in estimating the Price up to a greater extend:\n1. OverallQual - this is basically the overall quality of the house. I don't know how this value is calculated but looking at the dependencies, it seems worth to take a look. \n2. YearBuilt - the year the house was built\n3. TotalBsmtSF - Total area of the basement in square feet\n4. GrLivArea - Above ground living area in square feet\n\nAfter selection, we could just split up the variables on two grounds:\n* Categorical variables - OverallQual and YearBuilt. This could be considered as the building variables as it describes the construction of the house. \n* Numerical variables - TotalBsmtSF and GrLivArea. This describes the space of the house. ","7e41b8db":"**Overall Condition - Salesprice**","c9664be8":"# Missing Values\n\nOn the contrary to all the available values we have within the list, it is important to know about variables that don't have a valid value as well. This is sometimes important while teaching a data set to finally check whether the trained and test datasets are working as expected. But at the same time, it is difficult to train using an invalid or no value. This might be either completely removed or should be filled either with the mean or median or mode value. Another way is to use Decision trees or Random forest models. This way we could handle the missing values in a much better way. \n\nFor a better insight, you could refer the Book \"**Decision Trees - A visual Introduction got Beginners**\" from Chris Smith. Here is the amazon link: https:\/\/www.amazon.com\/Decision-Trees-Random-Forests-Introduction-ebook\/dp\/B078J8GFGC","e53197a4":"On the data description there are certain variables which are too valuable to look at, while considering the price. To me 'neighborhood' speaks first when and stands out as an important parameter while looking for a house. It would be a similar situation here and so let us look at the expensive location, based on the top 5 sale price.","a7ed8ab6":"**KitchenQuality - SalePrice**","06c94e63":"Since the datasets are already available for us, we could skip the process of data mining or data scraping. However, it is important to study the data and to prepare it before analysis. This is a process consisting of two important techniques, namely Data cleansing or cleaning and Data wrangling. These techniques would identify the data quality and set it for further analysing. To name a few contents, these techniques would deal with validating accuracy, reformatting values, threshold checking, understanding the columns and data types; which would finally convert the data into an actionable form. ","e12f820a":"From this information, it is quite clear that the most expensive houses are in the Northridge location followed by the Northridge Heights. Based on a latest survey by www.bestplaces.net, it is quite clear that in 2020 a Median Home in Ames, Iowa cost around $183,400. At the same time the other expenses like Food & Groceries, Housing, Utilities, Transportation and Miscellaneous expenses are below the normal US Average. \n\nTo know the real estate value of each neighborhood in the best possible way, I would like to create a box plot here with the Neighborhood as \"x axis\" and SalePrice at \"y axis\".","2bbf3f23":"To start with, it is important to know the categorical and numerical variables that estimates the price of the houses.  ","50953c9e":"From the graph it is evident that the 2 variables are less related to each other. As in the description OverallCond rates the overall condition of the house. This seems to look strange for the relation with SalePrice","050268af":"# Plotting SalePrice vs Numerical Variables","19c90f54":"# Introduction\n\nIn this Kernel I would like to explain few methods for analysing, cleaning and visualizing a dataset. Moreover, as this is one of the best examples of a beginner project in the data science, I would be more than happy to explain the various tributaries of data science as well."}}