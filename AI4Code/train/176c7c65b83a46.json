{"cell_type":{"f9829838":"code","9e7e652f":"code","8efca312":"code","18451336":"code","b1fbc86d":"code","607b08eb":"code","e5fc62e8":"code","41f52726":"code","9fd2844c":"code","54e0672e":"code","0e214c3d":"code","ebec435d":"code","b760d70f":"code","8655ed02":"code","03c4d5d0":"code","40879667":"code","d295ab0e":"code","c0077643":"code","3408ddba":"code","d404e562":"code","b86d670c":"code","f39b4eb1":"code","dbd7f6bf":"code","1eca9381":"code","a881b0cb":"code","c4f9aa19":"code","419bd8aa":"code","f022ac93":"code","d831c3a4":"code","31277aa1":"code","198a9d4f":"code","fb1f437f":"code","ca845fa4":"code","7cd47fb2":"code","8e65c519":"code","823daea5":"code","6104d8c9":"code","f1c3db48":"markdown","627c1f70":"markdown","0d82f26a":"markdown","288df092":"markdown","76ef3dd5":"markdown"},"source":{"f9829838":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e7e652f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nsns.set(style=\"whitegrid\")\n\nplt.style.use('fivethirtyeight')\n","8efca312":"df=pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\ndf.head()","18451336":"df.shape","b1fbc86d":"df.isnull().sum()","607b08eb":"df.info()","e5fc62e8":"df['price_range'].value_counts()","41f52726":"price_range={0:0,1:0, 2:1, 3:1}\ndf['price_range']=[price_range[x] for x in df['price_range']]","9fd2844c":"df['price_range'].value_counts()\n","54e0672e":"corr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","0e214c3d":"from statsmodels.stats.outliers_influence import variance_inflation_factor\ncols=['price_range']\nX=df.drop(cols, axis=1)","ebec435d":"X.columns","b760d70f":"vif_data = pd.DataFrame()\nvif_data[\"feature\"] = X.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                          for i in range(len(X.columns))]\nprint(vif_data)","8655ed02":"X=df.drop('price_range', axis=1)\ny=df['price_range']\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","03c4d5d0":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","40879667":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","d295ab0e":"lr=LogisticRegression(solver='liblinear')\nlr.fit(X_train, y_train)","c0077643":"y_pred=lr.predict(X_train)","3408ddba":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","d404e562":"y_test_pred=lr.predict(X_test)","b86d670c":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","f39b4eb1":"cfm=confusion_matrix(y_test, y_test_pred)","dbd7f6bf":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot() ","1eca9381":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot() ","a881b0cb":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot() ","c4f9aa19":"y_test_pred_prob=lr.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","419bd8aa":"metrics.roc_auc_score(y_test, y_test_pred_prob)","f022ac93":"metrics.roc_auc_score(y_test, y_test_pred_prob)","d831c3a4":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","31277aa1":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","198a9d4f":"from sklearn.linear_model import LogisticRegression\nmodel= LogisticRegression(solver='liblinear')\nmodel.fit(X_train, y_train)","fb1f437f":"threshold = []\naccuracy = []\n\nfor p in np.unique(model.predict_proba(X_train)[:,1]):\n    threshold.append(p)\n    y_pred = (model.predict_proba(X_train)[:,1] >= p).astype(int)\n    accuracy.append(balanced_accuracy_score(y_train,y_pred))","ca845fa4":"plt.figure(figsize=(10,6))\nplt.scatter(threshold,accuracy)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Balanced accuracy\")\nplt.show()","7cd47fb2":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    d=[acc_train, acc_test,  roc, correct, incorrect,  cm]\n    index=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\n    output=pd.DataFrame(data=d, index=index)\n    \n    d=sns.heatmap(cm, annot=True)\n    dd=plot_roc_curve(clf, X_train, y_train)\n    ddd=plot_precision_recall_curve(clf, X_train, y_train)\n\n    return output,d, dd, ddd","8e65c519":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression(solver='liblinear')\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","823daea5":"# 2 Random Forest\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf_rf = RandomForestClassifier()\nclf_rf.fit(X_train, y_train)\n\nY_pred_rf = clf_rf.predict(X_test)\nprint(clf_scores(clf_rf, Y_pred_rf))","6104d8c9":"# 3 XGboost\nfrom sklearn.ensemble import GradientBoostingClassifier\nclf_xg = GradientBoostingClassifier()\nclf_xg.fit(X_train, y_train)\n\nY_pred_xg = clf_xg.predict(X_test)\nprint(clf_scores(clf_xg, Y_pred_xg))","f1c3db48":"# Logistic Regresion","627c1f70":"# Correlation","0d82f26a":"# Multicollinearity ","288df092":"# Threshold","76ef3dd5":"# Other Models"}}