{"cell_type":{"882fe6df":"code","ed7e385a":"code","1727de1e":"code","8f0bf0e2":"code","15db55d8":"code","1a720444":"code","202825bc":"code","ab90d1b7":"code","a4065e9c":"code","396ea27d":"code","22c1bf9f":"code","75ab0211":"code","da45a862":"code","c89bf320":"code","6f5e5687":"code","79a2ecfd":"code","6b476ce9":"code","489c5e26":"code","477c9339":"code","04bc139d":"code","977d292c":"code","f49cd545":"code","15065974":"code","5680f945":"code","6cd4b5ab":"code","81473790":"code","ae3259c6":"code","dad9e6d1":"code","9a9827d1":"markdown","a4e00058":"markdown","8d621a02":"markdown","d2e52f26":"markdown","69e764e4":"markdown","ed320cf0":"markdown","b72aae74":"markdown","79d2b8ef":"markdown","fd5087e0":"markdown","d7d4c207":"markdown","3bdfc5af":"markdown","ce7cbc5c":"markdown","566b36ad":"markdown","b4f78050":"markdown","01b7ecf2":"markdown","d6d345e8":"markdown","a37a198a":"markdown","6e398669":"markdown","e62ccc16":"markdown","c9b08199":"markdown","9683d662":"markdown","98697b9c":"markdown"},"source":{"882fe6df":"pip install pymorphy2","ed7e385a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import plot_roc_curve\n\nimport re\nimport pymorphy2\nfrom collections import Counter\nfrom wordcloud import WordCloud\nfrom tqdm import tqdm\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nimport warnings\nwarnings.filterwarnings('ignore')","1727de1e":"toxic_comments = pd.read_csv('..\/input\/russian-language-toxic-comments\/labeled.csv')\ntoxic_comments.head()","8f0bf0e2":"toxic_comments.info()","15db55d8":"toxic_comments['toxic'].value_counts().plot(kind='pie', title='Class distribution  \"toxic\"', autopct='%1.1f%%')\nplt.axis('off')\nplt.show()","1a720444":"TOKEN_RE = re.compile(r'[\u0430-\u044f\u0451]+')\nrussian_stopwords = stopwords.words(\"russian\")\nlemmatizer = pymorphy2.MorphAnalyzer()\n\ndef tokenize_text(txt, min_lenght_token=2):\n    txt = txt.lower()\n    all_tokens = TOKEN_RE.findall(txt)\n    return [token for token in all_tokens if len(token) >= min_lenght_token]\n\ndef remove_stopwords(tokens):\n    return list(filter(lambda token: token not in russian_stopwords, tokens))\n\ndef lemmatizing(tokens):\n    return [lemmatizer.parse(token)[0].normal_form for token in tokens]\n\ndef text_cleaning(txt):\n    tokens = tokenize_text(txt)\n    tokens  = lemmatizing(tokens)\n    tokens = remove_stopwords(tokens)\n    return ' '.join(tokens)\n   ","202825bc":"tqdm.pandas()\n\ndf_token = toxic_comments.copy()\ndf_token['comment'] = df_token['comment'].progress_apply(text_cleaning)\ndf_token.head()","ab90d1b7":"df = df_token.copy()\nempty = df[df['comment'] == '']\nprint('Number of empty texts: ', len(empty))\ndf = df.drop(empty.index)","a4065e9c":"print('Number of duplicates:', df.duplicated().sum())","396ea27d":"df = df.drop_duplicates()","22c1bf9f":"print('Number of duplicate comments: ', df['comment'].duplicated().sum())","75ab0211":"df[df['comment'] == '\u043c\u0430\u0441\u043a\u0430 \u043b\u0438\u0446\u043e \u0436\u0430\u0442\u044c']","da45a862":"# original text\ntoxic_comments.loc[[1084, 5487]]","c89bf320":"df[df['comment'] == '\u0433\u043e\u0434']","6f5e5687":"# original text\ntoxic_comments.loc[[6044, 9803]]","79a2ecfd":"comment_duplicated = df[df['comment'].duplicated('last')]\ncomment_duplicated","6b476ce9":"# remove duplicate comments \ndf = df.drop_duplicates(subset='comment')\n\n# Labeling examples\nzero_labels = [1084, 1198, 1250, 1394, 1456, 1586, 1631, 1637, 1659, \n               1693, 1703, 1739, 1781, 1814, 1820, 1877, 4256, 6044]\nfor row in comment_duplicated.iterrows():\n    comment = row[1]['comment']\n    idx = df[df['comment'] == comment].index\n    if idx in zero_labels:\n        label = 0.\n    else:\n        label = 1.\n    df.loc[idx, 'toxic'] = label\n    \nprint('Number of duplicates:', df.duplicated('comment').sum())    ","489c5e26":"clean_text = df.copy()\nclean_text.head()","477c9339":"# Counting the occurrence of each word in the corpus \ncorpus = clean_text['comment'].values\n\ntext = ' '.join(corpus)\ncounter = Counter(text.split())\nsorted_counter = counter.most_common()\nsorted_counter[:5]","04bc139d":"# Drawing a graph of the frequency of words \nwords = [pair[0] for pair in sorted_counter]\nwords_count = [pair[1] for pair in sorted_counter]\n\nplt.figure(figsize=(10, 5))\nplt.plot(words[:40], words_count[:40])\nplt.xticks(rotation=90)\nplt.title('Frequency distribution of words', fontsize=14)\nplt.show()","977d292c":"only_toxic = clean_text[clean_text['toxic'] == 1]\ntext_toxic = ' '.join(only_toxic['comment'].values)\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_toxic)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title('The most frequent words in toxic texts', fontsize=14)\nplt.show()","f49cd545":"notoxic = clean_text[clean_text['toxic'] == 0]\nnorm_text = ' '.join(notoxic['comment'].values)\n\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(norm_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title('The most frequent words in non-toxic texts ', fontsize=14)\nplt.show()","15065974":"df_train, df_test = train_test_split(clean_text, \n                                     random_state=311, \n                                     test_size=0.33, \n                                     stratify=clean_text['toxic']\n                                    )\n\ntrain_corpus = df_train['comment'].values\ntest_corpus = df_test['comment'].values\n\ny_train = df_train['toxic']\ny_test = df_test['toxic']","5680f945":"vectorizer = TfidfVectorizer(ngram_range=(2,4), analyzer='char_wb', max_df=0.8, min_df=10)\nX_train = vectorizer.fit_transform(train_corpus)\nX_test = vectorizer.transform(test_corpus)\n\nprint('Total features: ', len(vectorizer.get_feature_names()))","6cd4b5ab":"Logregres = LogisticRegression(max_iter=10000, C=3, solver='liblinear')\nLogregres.fit(X_train, y_train)\ny_pred = Logregres.predict(X_test)\nprint(classification_report(y_test, y_pred))","81473790":"plot_confusion_matrix(Logregres, X_test, y_test, cmap='binary')\nplt.show()","ae3259c6":"plot_roc_curve(Logregres, X_test, y_test)\nplt.show()","dad9e6d1":"message = \"\u041f\u0440\u0435\u043a\u0440\u0441\u043d\u044b\u0439 \u043f\u0440\u0438\u043c\u0435\u0440 \u043f\u043e\u043b\u043d\u043e\u0433\u043e \u043e\u0442\u0441\u0443\u0442\u0441\u0432\u0438\u044f \u043c\u043e\u0437\u0433\u0430\"\nclean_message = text_cleaning(message)\nX_example = vectorizer.transform([clean_message])\ntoxic_propabality = Logregres.predict_proba(X_example)[0,1]\nprint(f'Probability of toxicity: {toxic_propabality:.2f}')","9a9827d1":"## 3. Text preprocessing ","a4e00058":"After a little analysis, it turned out that after cleaning the text, one of the reasons for the appearance of duplicates was the presence of examples in the source data that differ only in the `\\n` character. Such duplicates can be easily removed ","8d621a02":"### 3.1 Tokenization","d2e52f26":"## 2. Loading data ","69e764e4":"## 5. Vectorization ","ed320cf0":"## 1. Loading Libraries ","b72aae74":"Check comments for duplicates ","79d2b8ef":"### 3.2 Duplicates ","fd5087e0":"# Russian Toxic Comments (preprocessing+baseline)","d7d4c207":"Example 2 case ","3bdfc5af":"There are no gaps in the data of 14412 examples. The target variable `toxic` has an imbalance of classes, therefore, when evaluating the model, we will focus on the metrics *F1*, *precision* and *recall*. ","ce7cbc5c":"Check data for duplicates ","566b36ad":"Russian-language toxic comments [dataset](https:\/\/www.kaggle.com\/blackmoon\/russian-language-toxic-comments) from Kaggle platform. \n\nThe aim of the work was to create a basic model of text classification, along the way including elements of text analysis.\n\nContent:\n+ [1. Loading Libraries](#1.-Loading-Libraries)\n+ [2. Loading data](#2.-Loading-data)\n+ [3. Text preprocessing](#3.-Text-preprocessing)\n  + [3.1 Tokenization](#3.1-Tokenization)\n  + [3.2 Duplicates](#3.2-Duplicates)\n+ [4. Frequency analysis](#4.-Frequency-analysis)\n+ [5. Vectorization](#5.-Vectorization)\n+ [6. Baseline. LogisticRegression](#6.-Baseline.-LogisticRegression)","b4f78050":"This fact indicates the ambiguity of the toxicity label.\n\nCases of ambiguity:\n1. Original comments are the same, but labels are different\n2. The original comments are different, but after tokenization they became the same, while the labels are different ","01b7ecf2":"For each toxicity class, we will create a \"word cloud\" ","d6d345e8":"Check if empty texts appeared after tokenization and delete them if they exist ","a37a198a":"Example 1 case ","6e398669":"Text cleaning includes word tokenization, lemmatization, and stopword removal","e62ccc16":"The words \"\u044d\u0442\u043e\" and \"\u0432\u0441\u0451\" are the most common words in both classes. When classified, they will not carry meaningful information to determine the correct class. Next, in `TfidfVectorizer` set the limit `max_df`.","c9b08199":"## 4. Frequency analysis ","9683d662":"Let's see all the duplicates in the comments ","98697b9c":"## 6. Baseline. LogisticRegression"}}