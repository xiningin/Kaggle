{"cell_type":{"3f65e8c7":"code","ce954b42":"code","26ecef83":"code","822ede3e":"code","697871d9":"code","6131b5ce":"code","00843919":"code","44fa8ec4":"code","0c76f6ba":"code","5ad91e4b":"code","e0aa06a2":"code","d19b7fd8":"code","92323f49":"code","921e03dc":"code","7efe023a":"code","d86a7ef9":"code","9a1054be":"code","32f69a64":"code","3360c364":"code","17f65fd4":"code","2505f023":"code","f3ee7bd6":"code","69b824c0":"code","f5dbbeaf":"code","574ee850":"code","f23caa8a":"code","d32f49db":"code","9c56fa9f":"code","5d3ae1c0":"code","8e0c65e8":"code","c8a82ab4":"markdown","ca65162f":"markdown","49c42b5d":"markdown","87c65a5e":"markdown"},"source":{"3f65e8c7":"import IPython.display\nimport librosa\nimport librosa.display\nimport pandas as pd\nimport os\nimport struct\nimport glob\nimport soundfile as sf\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import specgram\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint \nfrom datetime import datetime\nfrom sklearn import metrics \nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)","ce954b42":"# Audio files and CSV file containing metadata\nfile_path = '..\/input\/urbansound8k'\nurbansound8k = pd.read_csv('..\/input\/urbansound8k\/UrbanSound8K.csv')\nfile_viz = glob.glob('..\/input\/urbansound8k\/fold1\/*')","26ecef83":"#pd.set_option('display.max_rows', None)\nurbansound8k.head()","822ede3e":"class_map = {'0' : 'air_conditioner', '1' : 'car_horn', '2' : 'children_playing', '3' : 'dog_bark', '4' : 'drilling', \n                 '5' : 'engine_idling', '6' : 'gun_shot', '7' : 'jackhammer', '8' : 'siren', '9' : 'street_music'}\npd.DataFrame(sorted(list(class_map.items())))","697871d9":"samples = [(class_map[label], [f for f in file_viz if f.split('-')[1] == label][0]) \n           for label in class_map.keys()]","6131b5ce":"def get_sound_data(path, sr=22050):\n    data, fsr = sf.read(path)\n    data_22k = librosa.resample(data.T, fsr, sr)\n    if len(data_22k.shape) > 1:\n        data_22k = np.average(data_22k, axis=0)\n    return data_22k, sr\nsample_data = [(sample[0], get_sound_data(sample[1])) for sample in samples]\n[(sample[0], sample[1][0].shape) for sample in sample_data]","00843919":"for data in sample_data:\n    print(data[0], ':')\n    IPython.display.display(IPython.display.Audio(data=data[1][0], rate=data[1][1]))","44fa8ec4":"i = 1\nfig = plt.figure(figsize=(15, 6))\nfor item in sample_data:\n    plt.subplot(2, 5, i)\n    librosa.display.waveplot(item[1][0], sr=item[1][1], color='r', alpha=0.7)\n    plt.title(item[0])\n    i += 1\nplt.tight_layout()","0c76f6ba":"i = 1\nfig = plt.figure(figsize=(15, 6))\nfor item in sample_data:\n    plt.subplot(2, 5, i)\n    specgram(item[1][0], Fs=item[1][1])\n    plt.title(item[0])\n    i += 1\nplt.tight_layout()","5ad91e4b":"class WavFileHelper():\n    \n    def read_file_properties(self, filename):\n\n        wave_file = open(filename,\"rb\")\n        \n        riff = wave_file.read(12)\n        fmt = wave_file.read(36)\n        \n        num_channels_string = fmt[10:12]\n        num_channels = struct.unpack('<H', num_channels_string)[0]\n\n        sample_rate_string = fmt[12:16]\n        sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n        \n        bit_depth_string = fmt[22:24]\n        bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n\n        return (num_channels, sample_rate, bit_depth)","e0aa06a2":"wavfilehelper = WavFileHelper()\n\naudiodata = []\nfor index, row in urbansound8k.iterrows():\n    \n    file_name = os.path.join(os.path.abspath(file_path),'fold'+str(row[\"fold\"])+'\/',str(row[\"slice_file_name\"]))\n    data = wavfilehelper.read_file_properties(file_name)\n    audiodata.append(data)\n\n# Convert into a Panda dataframe\naudiodf = pd.DataFrame(audiodata, columns=['num_channels','sample_rate','bit_depth'])","d19b7fd8":"max_pad_len = 174\n\ndef extract_features(file_name):\n   \n    try:\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        pad_width = max_pad_len - mfccs.shape[1]\n        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n        return None \n     \n    return mfccs","92323f49":"features = []\n\n# Iterate through each sound file and extract the features \nfor index, row in urbansound8k.iterrows():\n    \n    file_name = os.path.join(os.path.abspath(file_path),'fold'+str(row[\"fold\"])+'\/',str(row[\"slice_file_name\"]))\n    \n    class_label = row[\"classID\"]\n    data = extract_features(file_name)\n    \n    features.append([data, class_label])\n\n# Convert into a Panda dataframe \nfeaturesdf = pd.DataFrame(features, columns=['feature','class_label'])","921e03dc":"X = np.array(featuresdf.feature.tolist())\ny = np.array(featuresdf.class_label.tolist())\n\n# Encode the classification labels\nle = LabelEncoder()\nyy = to_categorical(le.fit_transform(y)) \n\n# split the dataset \nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 3)","7efe023a":"x_train1 = x_train \nx_test1 = x_test\ny_train1 = y_train\ny_test1 = y_test","d86a7ef9":"num_rows = 40\nnum_columns = 174\nnum_channels = 1\n\nx_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\nx_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\nprint(x_train.shape)\n\nnum_labels = yy.shape[1]\nfilter_size = 3","9a1054be":"# Constructing model with RELu and SoftMax activation functions:\nmodel_relu = Sequential()\nmodel_relu.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\nmodel_relu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_relu.add(Dropout(0.2))\n\nmodel_relu.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\nmodel_relu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_relu.add(Dropout(0.2))\n\nmodel_relu.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\nmodel_relu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_relu.add(Dropout(0.2))\n\nmodel_relu.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\nmodel_relu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_relu.add(Dropout(0.2))\nmodel_relu.add(GlobalAveragePooling2D())\nmodel_relu.add(Flatten())\nmodel_relu.add(Dense(num_labels, activation='softmax'))","32f69a64":"model_relu.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","3360c364":"model_relu.summary()\n\n# Calculate pre-training accuracy \nscore = model_relu.evaluate(x_test, y_test, verbose=1)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)","17f65fd4":"num_epochs = 100\nnum_batch_size = 256\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.basic_cnn.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\n\nhistory_relu = model_relu.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data = (x_test, y_test), callbacks=[checkpointer], verbose=1)\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","2505f023":"# Evaluating the model on the training and testing set\n\nscore = model_relu.evaluate(x_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model_relu.evaluate(x_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","f3ee7bd6":"# Plotting Loss of CNN 2D - ReLu Model\n\nmetrics = history_relu.history\nplt.plot(history_relu.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['train_loss', 'test_loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","69b824c0":"# Plotting Accuracy of CNN 2D - ReLu Model\n\nplt.plot(history_relu.history['accuracy'], label='train_accuracy')\nplt.plot(history_relu.history['val_accuracy'], label='test_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)","f5dbbeaf":"# Construct model with ELU and Sigmoid activation functions:\nmodel_elu = Sequential()\nmodel_elu.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='elu'))\nmodel_elu.add(BatchNormalization())\nmodel_elu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_elu.add(Dropout(0.2))\n\n\nmodel_elu.add(Conv2D(filters=32, kernel_size=2, activation='elu'))\nmodel_elu.add(BatchNormalization())\nmodel_elu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_elu.add(Dropout(0.2))\n\n\nmodel_elu.add(Conv2D(filters=64, kernel_size=2, activation='elu'))\nmodel_elu.add(BatchNormalization())\nmodel_elu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_elu.add(Dropout(0.2))\n\n\nmodel_elu.add(Conv2D(filters=128, kernel_size=2, activation='elu'))\nmodel_elu.add(MaxPooling2D(pool_size=(2,2)))\nmodel_elu.add(Dropout(0.2))\nmodel_elu.add(GlobalAveragePooling2D())\nmodel_elu.add(Flatten())\nmodel_elu.add(Dense(num_labels, activation='softmax'))","574ee850":"model_elu.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","f23caa8a":"model_elu.summary()\n\n# Calculate pre-training accuracy \nscore = model_elu.evaluate(x_test, y_test, verbose=1)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)","d32f49db":"num_epochs = 100\nnum_batch_size = 256\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.basic_cnn.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\n\nhistory_elu = model_elu.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data = (x_test, y_test), callbacks=[checkpointer], verbose=1)\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","9c56fa9f":"# Evaluating the model on the training and testing set\nscore = model_elu.evaluate(x_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model_elu.evaluate(x_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","5d3ae1c0":"# Plotting Loss of CNN 2D - ELU model\n\nmetrics = history_elu.history\nplt.plot(history_elu.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['train_loss', 'test_loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","8e0c65e8":"# Plotting Accuracy of CNN 2D - ELU Model\n\nplt.plot(history_elu.history['accuracy'], label='train_accuracy')\nplt.plot(history_elu.history['val_accuracy'], label='test_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)","c8a82ab4":"### Please read 'Project Report.pdf' for detailed explanations -> https:\/\/github.com\/SanketSonu\/UrbanSound8K\/blob\/main\/Project%20Report.pdf","ca65162f":"### Extracting features using Librosa","49c42b5d":"# CNN 2D - ELU Model","87c65a5e":"# CNN 2D - RELU Model"}}