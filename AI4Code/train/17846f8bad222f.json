{"cell_type":{"d373b532":"code","34c00c47":"code","2036d724":"code","8373e613":"code","4e6dfaa6":"code","92e09061":"code","0e7ddcb7":"code","0bdea4f8":"code","b9673e7e":"code","36c75815":"code","94e842e7":"code","2ec7c36c":"code","456d7dce":"code","19812231":"code","421a6ab3":"code","3ba5161b":"code","1b728298":"code","448dee8c":"code","ab6dafda":"code","f445f06c":"code","40ca9108":"code","c8a2e766":"code","6cea3a65":"code","105e7286":"code","7417d2e0":"code","bf18f96e":"code","aa18e456":"code","4a08e886":"markdown","90eaaf1e":"markdown","6c5bf32c":"markdown","97ef82c1":"markdown","13d1d1da":"markdown"},"source":{"d373b532":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","34c00c47":"#import the Data\ndf_train=pd.read_csv(\"train.csv\")\ndf_test=pd.read_csv(\"test.csv\")\ndf_train['TrainData'] = 1\ndf_test['TrainData'] =0","2036d724":"#Lets remove the outliers in the sale Price and then build the model.\n# df_train['SalePrice'].plot(kind='box')\nq25 = df_train['SalePrice'].quantile(0.25)\nq75 = df_train['SalePrice'].quantile(0.75)\nIQR = q75 - q25\nLowerValue = q25 - (1.5 * IQR)\nUpperValue = q75 + (1.5 * IQR)\ndf_train = df_train[df_train['SalePrice'] <=  UpperValue]","8373e613":"#Merging the test and train Data set\ndf = pd.concat([df_train, df_test])\nprint(df.shape)\nprint(df_train.shape)\nprint(df_test.shape)","4e6dfaa6":"df.head()","92e09061":"plt.plot(df['SalePrice'])","0e7ddcb7":"## CHECK THE NULL COLUMNS\ndf_nulls =df.isnull().mean()\ndf_nulls [df_nulls >  0.8]","0bdea4f8":"##droping the columns which have too many null values.\ndf.drop(columns=['Alley','PoolQC','Fence','MiscFeature'] , inplace=True)","b9673e7e":"# CHECK THE VARIANCE CATEGORICAL FEATURES SPREAD.\ncat_features=df.select_dtypes(include=['object']).columns\nlen(cat_features)","36c75815":"n_col = 3\nn_rows = int(len(cat_features) \/ n_col) + 1\nfig , ax = plt.subplots(n_rows, n_col)\nfig.set_figheight(5*n_rows)\nfig.set_figwidth(10)\ni=0\nfor feature in cat_features:\n    df_cnt = df[feature].value_counts()\n    ax[int(i\/n_col) , np.mod(i,n_col) ].bar(df_cnt.index , \n                                            df_cnt.values \/ df_cnt.sum()\n                                            )\n    ax[int(i\/n_col), np.mod(i,n_col)].set_title(feature)\n    i=i+1\n","94e842e7":"# It is seen that for some of the features the 95% or  more values are concentrated \n# to a single category. We can consider these features are constant and drop them.\n# We check only for top 5 values\ndf_cnt =pd.DataFrame(columns=['Value1','Value2','Value3','Value4','Value5']\n                     , index = cat_features)\nfor c in cat_features:\n    i=1\n    for rec in df[c].value_counts() \/ df[c].value_counts().sum():\n       df_cnt.loc[c]['Value' + str(i) ]  = round(rec,4)\n       i = i + 1\n\ncol_with_constant_values=df_cnt[df_cnt['Value1'] >= 0.95].index\ndf.drop(columns=col_with_constant_values,inplace=True)","2ec7c36c":"# col_with_constant_values\ncat_features=df.select_dtypes(include=['object']).columns\nlen(cat_features)","456d7dce":"df_null_cnt= df[cat_features].isnull().sum()\ndf_null_cnt[df_null_cnt>0].index","19812231":"# From Data Description we replace \n# Exterior2nd --> None\n# MasVnrType --> None\n# BsmtQual --> NA\n# BsmtCond --> NA\n# BsmtExposure --> NA\n# BsmtFinType1 --> NA\n# BsmtFinType2 --> NA\n# FireplaceQu --> NA\n# GarageType --> NA\n# GarageFinish --> NA\n# GarageQual --> NA\n# SaleType --> Oth\ndf['Exterior2nd'] = df['Exterior2nd'].fillna('None')\ndf['MasVnrType'] = df['MasVnrType'].fillna('None')\ndf['BsmtQual'] = df['BsmtQual'].fillna('NA')\ndf['BsmtCond'] = df['BsmtCond'].fillna('NA')\ndf['BsmtExposure'] = df['BsmtExposure'].fillna('NA')\ndf['BsmtFinType1'] = df['BsmtFinType1'].fillna('NA')\ndf['BsmtFinType2'] = df['BsmtFinType2'].fillna('NA')\ndf['FireplaceQu'] = df['FireplaceQu'].fillna('NA')\ndf['GarageType'] = df['GarageType'].fillna('NA')\ndf['GarageFinish'] = df['GarageFinish'].fillna('NA')\ndf['GarageQual'] = df['GarageQual'].fillna('NA')\ndf['SaleType'] = df['SaleType'].fillna('Oth')\n\n#Refresh the list\ndf_null_cnt= df[cat_features].isnull().sum()\ndf_null_cnt[df_null_cnt>0].index","421a6ab3":"# For the remaining features we impute them with most occuring value\ndf['MSZoning']=df['MSZoning'].fillna(df['MSZoning'].mode()[0])\ndf['Exterior1st']=df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\ndf['Electrical']=df['Electrical'].fillna(df['Electrical'].mode()[0])\ndf['KitchenQual']=df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\ndf['Functional']=df['Functional'].fillna(df['Functional'].mode()[0])","3ba5161b":"number_features = df.select_dtypes(exclude=['object']).columns\n# len(number_features)\nnumber_features","1b728298":"df_null_cnt= df[number_features].isnull().sum()\ndf_null_cnt[df_null_cnt>0].index","448dee8c":"df_null_cnt.sort_values()","ab6dafda":"## Replace BsmtFinSF1, BsmtFinSF2, GarageArea, BsmtUnfSF, TotalBsmtSF, GarageCars,\n## BsmtHalfBath, BsmtFullBath as zero.\ndf['BsmtFinSF1'] = df['BsmtFinSF1'].fillna(0)\ndf['BsmtFinSF2'] = df['BsmtFinSF2'].fillna(0)\ndf['GarageArea'] = df['GarageArea'].fillna(0)\ndf['BsmtUnfSF'] = df['BsmtUnfSF'].fillna(0)\ndf['TotalBsmtSF'] = df['TotalBsmtSF'].fillna(0)\ndf['GarageCars'] = df['GarageCars'].fillna(0)\ndf['BsmtHalfBath'] = df['BsmtHalfBath'].fillna(0)\ndf['BsmtFullBath'] = df['BsmtFullBath'].fillna(0)\ndf_null_cnt= df[number_features].isnull().sum()\ndf_null_cnt[df_null_cnt>0].index","f445f06c":"## Replacing others with average value\ndf['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\ndf['MasVnrArea'] = df['MasVnrArea'].fillna(df['MasVnrArea'].mean())\ndf['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].mean())\n","40ca9108":"cat_features = df.select_dtypes(include=['object']).columns\ncat_features","c8a2e766":"# Based on the data description we understand that Following features have the ordinal \n# values. We can replace them with the ordinal values.\n# LotShape , ExterQual, ExterCond, BsmtQual, BsmtCond, BsmtExposure, HeatingQC, \n# CentralAir, KitchenQual, FireplaceQu, GarageFinish, GarageQual\nmap_dict={'Reg':3 ,'IR1':2 ,'IR2':1 ,'IR3':0 ,'Ex':4 ,'Gd':3 ,'TA':2 ,'Fa':1 ,\n'Po':0 ,'NA': 0 ,'Av':2,'Mn':1 ,'No':0 ,'NA':0 ,'N':0 ,'Y':1 ,'Fin':3 ,\n'RFn':2 ,'Unf':1 ,'NA':0}\nordinal_cols =['LotShape' , 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n                'HeatingQC', 'CentralAir', 'KitchenQual', 'FireplaceQu', 'GarageFinish', \n                 'GarageQual']\nfor c in ordinal_cols:\n    df[c] = df[c].map(map_dict)","6cea3a65":"# For the remaining categorical variable we generate the dummy values\ncat_features = df.select_dtypes(include=['object']).columns\ndf=pd.get_dummies(df, columns= cat_features , prefix = cat_features) ","105e7286":"X=df[df['TrainData'] ==1]\nX=X.drop(columns=['TrainData','SalePrice','Id'])\nX_test=df[df['TrainData'] ==0]\nX_test=X_test.drop(columns=['TrainData','SalePrice','Id'])\ny=df[df['TrainData'] ==1]['SalePrice']\nX.index = df[df['TrainData'] ==1]['Id']\nX_test.index = df[df['TrainData'] ==0]['Id']\ny.index = df[df['TrainData'] ==1]['Id']","7417d2e0":"# Now we do the sclalling of the variable with standar scaller\nfrom sklearn.preprocessing import StandardScaler\nsclr = StandardScaler()\nsclr_fit = sclr.fit(X)\nX= pd.DataFrame(sclr_fit.transform(X), columns=X.columns , index= X.index)\nX_test= pd.DataFrame(sclr_fit.transform(X_test), columns=X_test.columns, index = X_test.index )","bf18f96e":"#Lets build the model with XGboost\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3)\n# model = RandomForestRegressor(max_depth=20)\nmodel=xgb.XGBRegressor(max_depth=15,n_estimators=200)\nmodel = model.fit(xtrain,ytrain)\nprint(f'Scoring for Train Data {round(mean_squared_error (y_pred =model.predict(xtrain),y_true= ytrain))}  against min of {ytrain.mean()}')\nprint(f'Scoring for Test Data {round(mean_squared_error (y_pred =model.predict(xtest),y_true= ytest))}  against min of {ytest.mean()}')","aa18e456":"y_predicted= model.predict(X_test)\ndf_test['SalePrice'] = y_predicted\ndf_test['SalePrice'].to_csv('Submission.csv')","4a08e886":"### All Null values have been imputed. Now convert the categorical features to numeric.","90eaaf1e":"If you liked the Notebook, pls upvote...","6c5bf32c":"### House Prices: Advanced Regression Techniques\nPredict sales prices and practice feature engineering, RFs, and gradient boosting","97ef82c1":"### Now we have removed the features having null values and constant values. Now we impute the null values for categorical variables.","13d1d1da":"#### Now we are done with categorical features. Lets work on the numerical features to remove null values."}}