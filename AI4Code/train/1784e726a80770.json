{"cell_type":{"37b1c760":"code","e0d4a801":"code","ebb2b372":"code","916d443e":"code","39fe0cf9":"code","c63388ba":"code","531d2899":"code","8e383ae1":"markdown","1af952ff":"markdown","4fb5cfd9":"markdown","8b3dce65":"markdown","3c6090be":"markdown"},"source":{"37b1c760":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e0d4a801":"train_path = '..\/input\/learn-together\/train.csv'\ntest_path = '..\/input\/learn-together\/test.csv'\n\ntrain_data = pd.read_csv(train_path, index_col='Id')\ntest_data = pd.read_csv(test_path, index_col='Id')\n\ntrain_data.head()","ebb2b372":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\ny = train_data['Cover_Type']\nX = train_data.drop(['Cover_Type'], axis=1)\n\n# split the dataset in train\/validation\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# create and train the classifier\nclf = RandomForestClassifier(n_estimators=100, \n                             random_state=0)\nclf.fit(X_train, y_train)\n\n# get predictions for validation data\ny_preds = clf.predict(X_valid)","916d443e":"from sklearn.metrics import accuracy_score\n\n# get accuracy\naccuracy = accuracy_score(y_valid, y_preds)\nprint('Accuracy: ', accuracy)","39fe0cf9":"# get feature importance\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\n\nfeature_imp.head()","c63388ba":"# create a new model, just using the most important features\nn_features = 25\ntop_features = feature_imp.head(n_features).keys()\nX2 = X[top_features]\n\n# split the dataset in train\/validation\nX_train, X_valid, y_train, y_valid = train_test_split(X2, y, test_size=0.2, random_state=0)\n\n# create and train the classifier\nclf2 = RandomForestClassifier(n_estimators=100, \n                             random_state=0)\nclf2.fit(X_train, y_train)\n\n# get predictions for validation data\ny_preds2 = clf2.predict(X_valid)\n\n# get accuracy\naccuracy = accuracy_score(y_valid, y_preds2)\nprint('Accuracy: ', accuracy)","531d2899":"# get the predictions for the test data\nfinal_preds = clf.predict(test_data)\n\n# create output file\noutput = pd.DataFrame({'Id': test_data.index,\n                       'Cover_Type': final_preds})\noutput.to_csv('submission.csv', index=False)","8e383ae1":"I will make a very simple script, just to run and make a first submission.\nNo fancy algorithms or feature engineering, just a very simple Random Forest Classifier.","1af952ff":"Accuracy is around 85%... not bad for so few lines of code.\n\nLet's create a new model, choosing only the most important features.","4fb5cfd9":"From the competition's data description it looks like the data is already one-hot encoded, which will make things much easier.","8b3dce65":"Let's evaluate the accuracy of the model:","3c6090be":"Preparing the file for submision"}}