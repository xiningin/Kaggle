{"cell_type":{"1c972c2f":"code","90fa9202":"code","eab68229":"code","4086e38d":"code","06588964":"code","d96c4b20":"code","011d531f":"code","a4d451e4":"code","2b53c377":"code","3ee715ff":"code","bcb7d9af":"code","6f7f6a3f":"code","347a73f6":"code","b469fdd3":"code","1d23ccfb":"code","8739ff3c":"code","9c73838b":"code","f9c97883":"code","2f5d0d1c":"code","6d318a07":"code","a3ffc1cc":"code","81b49bd9":"code","c0e5067f":"code","e2aef207":"code","ede7ce0f":"code","2dd7862a":"code","8d13d6ad":"code","3628266c":"code","fc1fdeab":"code","76cb842a":"code","64a99f05":"code","602cd7a9":"code","7daafc07":"code","76ddf93c":"code","f62e9f01":"code","0e5d7fc1":"code","473c3a4c":"code","2b8259e0":"code","0ba3302b":"code","c83e76b6":"code","41dae3e5":"code","4ab762a3":"code","abf75096":"code","0375c5a7":"code","5e2ef31a":"code","a81719f9":"code","fdfebaf3":"code","5a209107":"code","91e02e77":"code","cb973c55":"code","63aa97df":"code","54a7e248":"code","0c056bb0":"code","43e1ca88":"code","b9ebea29":"code","d52e6867":"code","dff9771b":"code","4785802b":"code","480426ad":"code","3409948b":"code","491c926d":"code","5ac75d64":"code","b31b740a":"code","6248ac91":"code","827ecda4":"code","aa8dcad4":"code","81238f67":"code","916ae461":"code","93d5633d":"code","bf2811a9":"code","52e356c0":"code","c1681382":"code","5f43b494":"code","2123cd62":"code","3af30d5e":"code","59b46568":"code","1c5eedfe":"code","aaf5a947":"code","7a1aedd8":"code","b9368030":"code","c8dcda01":"code","bc9c83a1":"code","a93c28d2":"code","d02d0fa1":"code","b0c4ffa9":"code","01e9149f":"code","dbc16cac":"code","7c78f5be":"code","532a8cde":"code","8258d852":"code","d383a0d5":"code","5de95243":"code","d14bff2d":"code","e75bbf29":"code","06d661d7":"code","6d63bcc4":"code","47507ea2":"markdown","39b1f2cf":"markdown","a534e181":"markdown","5a4928d1":"markdown","3150aced":"markdown","fd5a2b4d":"markdown","cf23980d":"markdown","5ccc2da6":"markdown","2b006b83":"markdown","e6d40127":"markdown","cc58ed47":"markdown","2a1e994a":"markdown","b80fea93":"markdown","5ed8b106":"markdown","686d81c1":"markdown","4520f011":"markdown","ce237c5a":"markdown","edee022b":"markdown","dcd2b781":"markdown","5c53b3b7":"markdown","94542fdc":"markdown","6cac929e":"markdown","6ad4b9c2":"markdown","ef636af7":"markdown","7d84d2f9":"markdown","99955f9c":"markdown","77fad9f7":"markdown","5fdf55ac":"markdown","d3e58972":"markdown","24d49da1":"markdown","3d9f55a2":"markdown","7eea847c":"markdown","27e5f10b":"markdown","ee1e514b":"markdown","e148574c":"markdown","811af038":"markdown","1ced88c2":"markdown","690138bf":"markdown","b72cc62a":"markdown","57e0e777":"markdown","cc9c6143":"markdown","5975b57a":"markdown","499796cd":"markdown","cc7cb15a":"markdown","7de0ede2":"markdown","0a346f01":"markdown","5ccb1492":"markdown","91ce8d8c":"markdown","ba19aeec":"markdown","8c6daa88":"markdown","1cdfa734":"markdown","afc5369b":"markdown","783f66d5":"markdown","2ee85a4c":"markdown","2d4f57fb":"markdown","fdb25812":"markdown","35a88cc8":"markdown","9bb3ae1c":"markdown","2c0de543":"markdown","ae9fc6e7":"markdown","919a63db":"markdown","853adfda":"markdown","6f5f653e":"markdown","1363588d":"markdown","8cd7bd81":"markdown","08c4f207":"markdown","e6fa61e6":"markdown","7ca9da94":"markdown","d0edea58":"markdown","a9f3974a":"markdown","c269868c":"markdown","e247abf6":"markdown","7e7c1163":"markdown","43347c70":"markdown","8839db9f":"markdown","04129eb0":"markdown"},"source":{"1c972c2f":"Image(url= \"https:\/\/i.imgur.com\/iLNlNfs.jpg\")","90fa9202":"Image(url= \"https:\/\/i.imgur.com\/BX0QYJh.jpg\")","eab68229":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\n# Visualization\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\nimport seaborn as sns\nsns.set_style('whitegrid', {'grid.linestyle': '--'})\nfrom IPython.display import Image\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport colorlover as cl\n\n# Others\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\ninit_notebook_mode(connected=True)","4086e38d":"mql = pd.read_csv('..\/input\/marketing-funnel\/marketing funnel by olist\/olist_marketing_qualified_leads_dataset.csv', \n                  parse_dates=['first_contact_date'])\ncd = pd.read_csv('..\/input\/marketing-funnel\/marketing funnel by olist\/olist_closed_deals_dataset.csv',\n                parse_dates=['won_date'])\nsellers = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv')\norder_items = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv')\n\nproducts = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_products_dataset.csv\")\npayments = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\norders = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")\nreviews = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")\ngeo = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv\")\ncustomers = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\nproduct_translation = pd.read_csv('..\/input\/brazilian-ecommerce\/product_category_name_translation.csv')","06588964":"#helper function\ndef pichart_with_table(main_df,column_name,title,top_n,filename):\n    fig = plt.figure(figsize=(10,6))\n\n    summary = main_df.groupby(column_name)[\"mql_id\"].nunique().sort_values(ascending=False)\n    df = pd.DataFrame({'source':summary.index, 'counts':summary.values})\n    labels = df['source']\n    counts = df['counts']\n\n    ax1 = fig.add_subplot(121)\n    if top_n > 0:\n        ax1.pie(counts[0:top_n], labels=labels[0:top_n], autopct='%1.1f%%', startangle=180)\n    else:\n        ax1.pie(counts, labels=labels, autopct='%1.1f%%', startangle=180)\n    ax1.set_title(title)\n    ax1.axis('equal')\n\n    ax2 = fig.add_subplot(122)\n    font_size=10\n    ax2.axis('off')\n    if top_n > 0:\n        df_table = ax2.table(cellText=df.values[0:top_n], colLabels=df.columns, loc='center',colWidths=[0.8,0.2])\n    else:\n        df_table = ax2.table(cellText=df.values, colLabels=df.columns, loc='center',colWidths=[0.8,0.2])\n\n    df_table.auto_set_font_size(False)\n    df_table.set_fontsize(font_size)\n\n    fig.tight_layout()\n    plt.savefig(filename)\n    plt.show()","d96c4b20":"mql.describe()","011d531f":"cd.describe(include=\"all\")","a4d451e4":"zero_count = (mql.isnull()).sum() # (df1 == 0).sum()\nzero_count_df = pd.DataFrame(zero_count)\n#zero_count_df.drop('Survived', axis=0, inplace=True)\nzero_count_df.columns = ['Missing Value Count']\n\n# https:\/\/stackoverflow.com\/questions\/31859285\/rotate-tick-labels-for-seaborn-barplot\/60530167#60530167\nsns.set(style='whitegrid')\nplt.figure(figsize=(13,4))\nsns.barplot(x=zero_count_df.index, y=zero_count_df['Missing Value Count'])\nplt.title('Marketing Qualified Lead')\nplt.xticks(rotation=30)\n\n\nzero_count = (cd.isnull()).sum() # (df1 == 0).sum()\nzero_count_df = pd.DataFrame(zero_count)\n#zero_count_df.drop('Survived', axis=0, inplace=True)\nzero_count_df.columns = ['Missing Value Count']\n\nsns.set(style='whitegrid')\nplt.figure(figsize=(13,5))\nsns.barplot(x=zero_count_df.index, y=zero_count_df['Missing Value Count'])\nplt.title('Closed Deals')\nplt.xticks(rotation=90)","2b53c377":"# Remove unnecessary columns\ncd = cd.drop(['has_company','has_gtin','average_stock','declared_product_catalog_size'], axis = 1) \n\n#filling the rest NAs\nrest_cols = ['lead_behaviour_profile','business_segment','lead_type','business_type']\ncd[rest_cols] = cd[rest_cols].fillna('unknown')\nmql['origin'].fillna('unknown')\n\n#checking if any null is remaining or not\ncd[cd.isnull().any(axis=1)]","3ee715ff":"geo =  geo.drop_duplicates(subset=['geolocation_zip_code_prefix'], keep='first')\n\n# Check duplicated value\ngeo[geo['geolocation_zip_code_prefix'] == 1037]\n\n#geo['geolocation_zip_code_prefix'].duplicated().sum()","bcb7d9af":"data = pd.merge(products,order_items,\n                how='inner', on='product_id')\ndata = pd.merge(data, orders,\n                how='inner', on='order_id')\ndata = pd.merge(data, payments,\n                how='inner', on='order_id')\ndata = pd.merge(data, reviews,\n                how='inner', on='order_id')\ndata = pd.merge(data, customers,\n                how='inner', on='customer_id')\ndata = pd.merge(data, sellers,\n                how='inner', on='seller_id')\ndata = pd.merge(data, geo, \n                how='inner', \n                left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix')\ndata = pd.merge(data, product_translation,\n                how='left', on='product_category_name') # There are some data without english names\ndata.shape","6f7f6a3f":"# Add a 'year-month' column\nmql['first_contact_date(y-m)'] = mql['first_contact_date'].dt.to_period('M')\nmql[['first_contact_date', 'first_contact_date(y-m)']].head(3)","347a73f6":"# Create time series table\nmonthly_mql = mql.groupby(by='first_contact_date(y-m)').mql_id.count()\nmonthly_mql.to_frame().T","b469fdd3":"a = monthly_mql.to_frame()\n\na.plot.line(figsize=(12, 6))\n\n\"\"\"\na['first_contact_date(y-m)'] = a['first_contact_date(y-m)'].astype('str')\n\nplt.figure(figsize = (15, 6))\n\nsns.lineplot(x = a['first_contact_date(y-m)'], y = a['mql_id'])\n\"\"\" ","1d23ccfb":"pichart_with_table(mql,\"origin\",\"Origin Sources\",-1,\"origin_mql.png\")","8739ff3c":"mql_origin = pd.pivot_table(mql,\n                            index='origin',\n                            columns='first_contact_date(y-m)',\n                            values='mql_id',                            \n                            aggfunc='count',\n                            fill_value=0)","9c73838b":"mql.groupby('origin')['mql_id'].count().sort_values(ascending=False)","f9c97883":"# Sort index from largest to smallest in volume\n# == origin_list = mql['origin'].value_counts()\norigin_list = mql.groupby('origin')['mql_id'] \\\n                                   .count().sort_values(ascending=False).index\nmql_origin = mql_origin.reindex(origin_list)\nmql_origin","2f5d0d1c":"# Plot the monthly volume by channel\nplt.figure(figsize=(20,8))\nsns.heatmap(mql_origin, annot=True, fmt='g');","6d318a07":"landing_page_origin = mql['landing_page_id'].value_counts()","a3ffc1cc":"landing_page_origin[:10].plot.bar()","81b49bd9":"# Merge 'MQL' with 'closed deals'\n# Merge by 'left' in order to evaluate conversion rate\nmql_cd = pd.merge(mql,\n                  cd,\n                  how='left',\n                  on='mql_id')","c0e5067f":"# Add a column to distinguish signed MOLs from MQLs who left without signing up\nmql_cd['seller_id(bool)'] = mql_cd['seller_id'].notna()","e2aef207":"mql_cd.head()","ede7ce0f":"# alternative: mql_cd.groupby('first_contact_date(y-m)')['seller_id'].count()\n# Compute monthly closed deals\nmonthly_cd = mql_cd.groupby('first_contact_date(y-m)')['seller_id(bool)'].sum()\nmonthly_cd","2dd7862a":"# Plot the monthly volume of closed deals\nmonthly_cd.plot.line(figsize=(12, 6))\nplt.title('Closed Deal Volume (Jun 2017 - May 2018)', fontsize=14);","8d13d6ad":"monthly_conversion = mql_cd.groupby(by='first_contact_date(y-m)')['seller_id(bool)'].agg(['count', 'sum'])\n\nmonthly_conversion['conversion_rate(%)'] = ((monthly_conversion['sum'] \/ monthly_conversion['count']) * 100).round(1)\nmonthly_conversion","3628266c":"# Plot the monthly conversion rate\nmonthly_conversion['conversion_rate(%)'].plot.line(figsize=(12, 6))\nplt.ylabel('In Percentage Terms')\nplt.title('Conversion Rate (Jun 2017 - May 2018)', fontsize=14);","fc1fdeab":"mql_cd.head(3)","76cb842a":"# .dt.days -> work for  TimedeltaProperties\n\n# Calculate sales length in days\nmql_cd['sales_length(day)'] = (mql_cd['won_date'] - mql_cd['first_contact_date']).dt.days\nmql_cd[['first_contact_date', 'won_date', 'sales_length(day)']].head()","64a99f05":"# won_date always occur after first_contact_date, thus sales_length(day) must be > 0\n# remove the outliers\nmql_cd = mql_cd[mql_cd['sales_length(day)'] > 0]","602cd7a9":"sns.distplot(mql_cd['sales_length(day)'])","7daafc07":"# Separate sales length for each year\nclosed_deal = (mql_cd['seller_id'].notna())\nlead_2017 = (mql_cd['first_contact_date'].dt.year.astype('str') == '2017')\nlead_2018 = (mql_cd['first_contact_date'].dt.year.astype('str') == '2018')\n\nsales_length_2017 = mql_cd[closed_deal & lead_2017]['sales_length(day)']\nsales_length_2018 = mql_cd[closed_deal & lead_2018]['sales_length(day)']","76ddf93c":"figure, ax = plt.subplots(figsize=(12,6))\n\nsns.kdeplot(sales_length_2017,\n            cumulative=True,\n            label='2017 (Jun-Dec)',\n            ax=ax)\nsns.kdeplot(sales_length_2018,\n            cumulative=True,\n            label='2018 (Jan-May)',\n            ax=ax)\n\nax.set_title('Sales Length in Days', fontsize=14)\nax.xaxis.set_major_locator(plt.MaxNLocator(10))\nplt.xlim(0,500);","f62e9f01":"print('There are',len(cd[cd.declared_monthly_revenue>0]), 'MQLs in profit') #total count\nprint('Only around',round(len(cd[cd.declared_monthly_revenue>0])\/len(cd)*100, 2), '% in total') #total percent of data","0e5d7fc1":"fig = plt.figure(figsize=(8,5))\ncd[cd['declared_monthly_revenue']>0]['declared_monthly_revenue'].value_counts().plot.bar()\nplt.title(\"Revenue of closed deals ($)\")\nplt.xlabel(\"Amount\")\nplt.ylabel(\"Total number of sellers\")\nfig.tight_layout()\n#plt.savefig(\"revenue_disclosed.png\")\nplt.show()","473c3a4c":"# Bring 'closed deals' data\ncd_profile = cd[cd['lead_behaviour_profile'].notna()].copy()\n\ncd_profile['lead_behaviour_profile'].value_counts()","2b8259e0":"# Combine four types of mixed profiles(2.4%) into 'others'\nprofile_list = ['cat', 'eagle', 'wolf', 'shark']\n\ncd_profile['lead_behaviour_profile(upd)'] = cd_profile['lead_behaviour_profile'].map(lambda profile: profile \n                                                                                     if profile in profile_list else 'others')\ncd_profile['lead_behaviour_profile(upd)'].value_counts()","0ba3302b":"cd_profile[['lead_type', 'lead_behaviour_profile(upd)']].head()","c83e76b6":"# Create 'profile - lead type' table\ncols = cd_profile['lead_type'].value_counts().index\nindex = cd_profile['lead_behaviour_profile(upd)'].value_counts().index\nindex = index.rename('lead_behaviour_profile(upd)')\n\nprofile_leadType = pd.pivot_table(cd_profile,\n                                  index='lead_behaviour_profile(upd)',\n                                  columns='lead_type',\n                                  values='seller_id',\n                                  aggfunc='count',\n                                  fill_value=0)","41dae3e5":"profile_leadType = profile_leadType.reindex(index)[cols]\nprofile_leadType","4ab762a3":"# Create 'profile - business type' table\ncols = cd_profile['business_type'].value_counts().index\nindex = cd_profile['lead_behaviour_profile(upd)'].value_counts().index\n\nprofile_businessType = pd.pivot_table(cd_profile,\n                                      index='lead_behaviour_profile(upd)',\n                                      columns='business_type',\n                                      values='seller_id',\n                                      aggfunc='count',\n                                      fill_value=0)\n\nprofile_businessType = profile_businessType.reindex(index)[cols]\nprofile_businessType","abf75096":"# Create 'profile - business segment' table\ncols = cd_profile['business_segment'].value_counts().index\nindex = cd_profile['lead_behaviour_profile(upd)'].value_counts().index\n\nprofile_segment = pd.pivot_table(cd_profile,\n                                 index='lead_behaviour_profile(upd)',\n                                 columns='business_segment',\n                                 values='seller_id',\n                                 aggfunc='count',\n                                 fill_value=0)\n\nprofile_segment = profile_segment.reindex(index)[cols]\nprofile_segment","0375c5a7":"Image(url= \"https:\/\/i.imgur.com\/hujp7Hc.jpg\")","5e2ef31a":"# Plot the above three tables\nfigure, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(20,20))\nfigure.subplots_adjust(hspace=0.3)\n\nsns.heatmap(profile_leadType,\n            annot=True,\n            fmt='g',\n            ax=ax1)\nsns.heatmap(profile_businessType,\n            annot=True,\n            fmt='g',\n            ax=ax2)\nsns.heatmap(profile_segment,\n            annot=True,\n            fmt='g',\n            ax=ax3)\n\nax1.set_title('Behaviour Profile - Lead Type', fontsize=14)\nax2.set_title('Behaviour Profile - Business Type', fontsize=14)\nax3.set_title('Behaviour Profile - Business Segement', fontsize=14);","a81719f9":"# Create 'profile-SDR' table\ncols = cd_profile['sdr_id'].value_counts().index\nindex = cd_profile['lead_behaviour_profile(upd)'].value_counts().index\n\nprofile_sdr = pd.pivot_table(cd_profile,\n                             index='lead_behaviour_profile(upd)',\n                             columns='sdr_id',\n                             values='seller_id',\n                             aggfunc='count',\n                             fill_value=0)\n\nprofile_sdr = profile_sdr.reindex(index)[cols] # Sort SDR in descending order of volume \nprofile_sdr","fdfebaf3":"# Create 'profile-SR' table\ncols = cd_profile['sr_id'].value_counts().index\nindex = cd_profile['lead_behaviour_profile(upd)'].value_counts().index\n\nprofile_sr = pd.pivot_table(cd_profile,\n                            index='lead_behaviour_profile(upd)',\n                            columns='sr_id',\n                            values='seller_id',\n                            aggfunc='count',\n                            fill_value=0)\n\nprofile_sr = profile_sr.reindex(index)[cols] # Sort SR in descending order of volume\nprofile_sr","5a209107":"# Plot the two tables\nfigure, (ax1,ax2) = plt.subplots(2, 1, figsize=(20,14))\nfigure.subplots_adjust(hspace=0.2)\n\nsns.heatmap(profile_sdr,\n            annot=True,\n            fmt='g',\n            ax=ax1)\nsns.heatmap(profile_sr,\n            annot=True,\n            fmt='g',\n            ax=ax2)\n\nax1.set_title('SDR Performance in Descending Volume', fontsize=14)\nax2.set_title('SR Performance in Descending Volume', fontsize=14)\nax1.set_xticks([])\nax2.set_xticks([]);","91e02e77":"all_data = pd.merge(cd,order_items,\n                how='inner', on='seller_id')\nall_data = pd.merge(all_data, orders,\n                how='inner', on='order_id')\nall_data = pd.merge(all_data, products,\n                how='inner', on='product_id')\nall_data = pd.merge(all_data, product_translation,\n                how='left', on='product_category_name') # There are some data without english names\nall_data.shape","cb973c55":"all_data['order_purchase_timestamp'] = pd.to_datetime(all_data['order_purchase_timestamp'])","63aa97df":"# Sort out orders not devliered to customers\nall_data = all_data[all_data['order_status'] == 'delivered']\n\n# Add a 'year-month' column\nall_data['order_purchase_timestamp(y-m)'] = all_data['order_purchase_timestamp'].dt.to_period('M')\n\nprint(all_data.shape)\nall_data.head(3)","54a7e248":"cols = all_data.groupby(by='business_segment') \\\n           .price \\\n           .sum() \\\n           .sort_values(ascending=False) \\\n           .index\n\nmonthly_segment_revenue = all_data.groupby(['order_purchase_timestamp(y-m)', 'business_segment']) \\\n                              .price \\\n                              .sum() \\\n                              .unstack(level=1, fill_value=0)\n\nmonthly_segment_revenue = monthly_segment_revenue[cols]\nmonthly_segment_revenue","0c056bb0":"# Plot the monthly revenues by segment\nmonthly_segment_revenue.plot.area(figsize=(20,15))\n\nplt.title('Monthly Revenues by Business Segment', fontsize=14)\nplt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5));","43e1ca88":"# Create watches segment dataframe\nwatches = all_data[all_data['business_segment'] == 'watches']\nwatches.shape","b9ebea29":"# Create monthly revenues by product category\ncols = watches.groupby('product_category_name_english')['price'].sum().sort_values(ascending=False).index\n\n# monthly_revenue_category = pd.pivot_table(watches,\n#                                  index='order_purchase_timestamp(y-m)',\n#                                  columns='product_category_name_english',\n#                                  values='price',\n#                                  aggfunc='sum',\n#                                  fill_value=0)\n\nmonthly_revenue_category = watches.groupby(['order_purchase_timestamp(y-m)', 'product_category_name_english']) \\\n                                  .price \\\n                                  .sum() \\\n                                  .unstack(level=1, fill_value=0)\n\nmonthly_revenue_category = monthly_revenue_category[cols]\nmonthly_revenue_category","d52e6867":"# Plot the monthly revenues by category\nmonthly_revenue_category.plot.area(figsize=(15,6))\nplt.title('Monthly Revenues by Product Category of Watches', fontsize=14);","dff9771b":"# Create 'seller - product category' table\ncols = watches.groupby('product_category_name_english')['price'].sum().sort_values(ascending=False).index\n\nwatches_seller_revenue = watches.groupby(['seller_id', 'product_category_name_english']) \\\n                                ['price'].sum().unstack(level=1, fill_value=0)\n\nwatches_seller_revenue = watches_seller_revenue[cols]\nwatches_seller_revenue['total'] = watches_seller_revenue.sum(axis=1)\n\nwatches_seller_revenue","4785802b":"watches_seller_revenue.T","480426ad":"# Plot the above table\nwatches_seller_revenue.T.plot.barh(stacked=True, figsize=(12,6))\n\nplt.title('Watches Revenue by Seller', fontsize=14)\nplt.legend(loc='lower right');\n","3409948b":"index = watches[watches['product_category_name_english'] == 'watches_gifts'].groupby('product_id') \\\n                ['price'].sum().sort_values(ascending=False).index\nproduct_seller_revenue = watches[watches['product_category_name_english'] == 'watches_gifts'] \\\n                                  .groupby(['seller_id', 'product_id']) \\\n                                  ['price'].sum().unstack(level=0, fill_value=0)\n\nproduct_seller_revenue = product_seller_revenue.reindex(index)\nproduct_seller_revenue.head()","491c926d":"product_seller_revenue.plot.bar(stacked=True, figsize=(20, 6))\nplt.title('Product Revenues in Watches_gifts Category', fontsize=14);","5ac75d64":"a = product_seller_revenue.copy()\ntotal = a['7d13fca15225358621be4086e1eb0964'].sum()\na['Percentage'] = round(a['7d13fca15225358621be4086e1eb0964'] \/ total * 100, 2)\n\nt = 0\ndef sum_percentage(data):\n    global t\n    t = t + data\n    return t\n\na['sum_percentage'] = a['Percentage'].apply(sum_percentage)\n\na['sum_percentage'].plot.bar(figsize=(20, 6))","b31b740a":"payments.describe(include=\"all\")","6248ac91":"def plot_dist(values, log_values, title, color=\"#D84E30\"):\n    fig, axis = plt.subplots(1, 2, figsize=(12,4))\n    axis[0].set_title(\"{} - linear scale\".format(title))\n    axis[1].set_title(\"{} - logn scale\".format(title))\n    ax1 = sns.distplot(values, color=color, ax=axis[0])\n    ax2 = sns.distplot(log_values, color=color, ax=axis[1])","827ecda4":"payments['payment_value_log'] = payments['payment_value'].apply(lambda x: np.log(x) if x > 0 else 0)\n\nplot_dist(payments['payment_value'], payments['payment_value_log'], 'Payment Value distribution')","aa8dcad4":"method_count = payments['payment_type'].value_counts().to_frame().reset_index()\nmethod_value = payments.groupby('payment_type')['payment_value'].sum().to_frame().reset_index()\n\n# Plotly piechart\ncolors = None\ntrace1 = go.Pie(labels=method_count['index'], values=method_count['payment_type'],\n                domain= {'x': [0, .48]}, marker=dict(colors=colors))\ntrace2 = go.Pie(labels=method_value['payment_type'], values=method_value['payment_value'],\n                domain= {'x': [0.52, 1]}, marker=dict(colors=colors))\n\nlayout = dict(title= \"Number of payments (left) and Total payments value (right)\", \n              height=400, width=800)\nfig = dict(data=[trace1, trace2], layout=layout)\niplot(fig)","81238f67":"sns.catplot(x=\"payment_type\", y=\"payment_value\",data=payments, aspect=2, height=3.8)","916ae461":"gr = payments.groupby('payment_type')['payment_value_log']\nplt.figure(figsize=(10,4))\nfor label, arr in gr:\n    sns.kdeplot(arr, label=label)","93d5633d":"payments[payments['payment_installments'] == 1]['payment_type'].value_counts().to_frame()","bf2811a9":"payments[payments['payment_installments'] > 1]['payment_type'].value_counts().to_frame()","52e356c0":"payments.groupby('payment_installments')['payment_value'].mean()","c1681382":"ins_count = payments.groupby('payment_installments').size()\nsns.barplot(x=ins_count.index, y=ins_count)","5f43b494":"pay_one_inst = payments[payments['payment_installments'] == 1]\nmethod_count = pay_one_inst['payment_type'].value_counts().to_frame().reset_index()\nmethod_value = pay_one_inst.groupby('payment_type')['payment_value'].sum().to_frame().reset_index()\n# Plotly piechart\ncolors = None\ntrace1 = go.Pie(labels=method_count['index'], values=method_count['payment_type'],\n                domain= {'x': [0, .48]}, marker=dict(colors=colors))\ntrace2 = go.Pie(labels=method_value['payment_type'], values=method_value['payment_value'],\n                domain= {'x': [0.52, 1]}, marker=dict(colors=colors))\nlayout = dict(title= \"Orders and value for a single installment\", \n              height=400, width=800,)\nfig = dict(data=[trace1, trace2], layout=layout)\niplot(fig)","2123cd62":"data.groupby('order_id').size().value_counts().to_frame().plot.bar(figsize=(12, 6))","3af30d5e":"# Products value\nsum_value = data.groupby('order_id')['price'].sum()\nplot_dist(sum_value, np.log1p(sum_value), 'Products value')\n\n# Freights value\nsum_value = data.groupby('order_id')['freight_value'].sum()\nplot_dist(sum_value, np.log1p(sum_value), 'Freight value', color=\"#122aa5\")","59b46568":"data['order_purchase_timestamp'] = pd.to_datetime(data['order_purchase_timestamp'])","1c5eedfe":"value_month = data[['order_purchase_timestamp', 'price']].copy()\nvalue_month['year-month'] = value_month['order_purchase_timestamp'].dt.to_period('M')\nvalue_month.set_index('year-month', inplace=True)\nvalue_month.groupby(pd.Grouper(freq=\"M\"))['price'].sum().plot.bar()","aaf5a947":"orders_count = data.groupby('product_category_name_english').size()\norders_count['others'] = orders_count[orders_count < 1000].sum()\norders_count = orders_count[orders_count >= 1000].sort_values(ascending=True)\n\norders_value = data.groupby('product_category_name_english')['price'].sum()\norders_value = orders_value[orders_count.index]\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\naxes = axes.flatten()\nsns.barplot(x=orders_count.values[:-1], y=orders_count.index[:-1], ax=axes[0])\nplt.ylabel('');\nsns.barplot(x=orders_value.values[:-1], y=orders_value.index[:-1], ax=axes[1])\nplt.ylabel('');","7a1aedd8":"review_qty = data.groupby('review_score').size()\nreview_value = data.groupby('review_score')['price'].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\naxes = axes.flatten()\nsns.barplot(x=review_qty.index, y=review_qty.values, ax=axes[0])\nplt.xlabel('');\nsns.barplot(x=review_value.index, y=review_value.values, ax=axes[1])\nplt.xlabel('review_score for mean price');","b9368030":"# Convert columns to datetime\ndata['order_purchase_timestamp'] = pd.to_datetime(data['order_purchase_timestamp'])\ndata['order_estimated_delivery_date'] = pd.to_datetime(data['order_estimated_delivery_date'])\ndata['order_delivered_customer_date'] = pd.to_datetime(data['order_delivered_customer_date'])\n\ndata['delivery_time'] = (data['order_delivered_customer_date'] - data['order_purchase_timestamp']).dt.days\ndata['estimated_delivery_time'] = (data['order_estimated_delivery_date'] - data['order_purchase_timestamp']).dt.days","c8dcda01":"plt.figure(figsize=(10,4))\nplt.title(\"Delivery time in days\")\nax1 = sns.kdeplot(data['delivery_time'].dropna(), color=\"#D84E30\", label='Delivery time')\nax2 = sns.kdeplot(data['estimated_delivery_time'].dropna(), color=\"#7E7270\", label='Estimated delivery time')","bc9c83a1":"sns.boxplot(x=\"review_score\", y=\"delivery_time\",\n            data=data[data['delivery_time'] < 60])","a93c28d2":"geo_state = data.groupby('geolocation_state')['geolocation_lat','geolocation_lng'].mean().reset_index()\ngeo_city = data.groupby('geolocation_city')['geolocation_lat','geolocation_lng'].mean().reset_index()","d02d0fa1":"geo = [go.Scattermapbox(lon = geo_state['geolocation_lng'],\n                        lat = geo_state['geolocation_lat'],\n                        text = geo_state['geolocation_state'],\n                        marker = dict(size = 18,\n                                      color = 'tomato',))]\n\nlayout = dict(title = 'Brazil State',\n              mapbox = dict(accesstoken = 'pk.eyJ1IjoiaG9vbmtlbmc5MyIsImEiOiJjam43cGhpNng2ZmpxM3JxY3Z4ODl2NWo3In0.SGRvJlToMtgRxw9ZWzPFrA',\n                            center= dict(lat=-22,lon=-43),\n                            bearing=10,\n                            pitch=0,\n                            zoom=2,))\n\nfig = dict(data=geo, layout=layout)\niplot(fig, validate=False)","b0c4ffa9":"customer_by_location = data.copy()\n\ngeo_city.columns = ['geolocation_city', 'geolocation_city_lat', 'geolocation_city_lng']\ngeo_state.columns = ['geolocation_state', 'geolocation_state_lat', 'geolocation_state_lng']\n\ncustomer_by_location = pd.merge(customer_by_location, geo_city,\n                how='inner', on='geolocation_city')\ncustomer_by_location = pd.merge(customer_by_location, geo_state,\n                how='inner', on='geolocation_state')\n\ncity_spend = customer_by_location.groupby(['customer_city','geolocation_city_lng','geolocation_city_lat'])['price'].sum().to_frame().reset_index()\ncity_freight = customer_by_location.groupby(['customer_city','geolocation_city_lng','geolocation_city_lat'])['freight_value'].mean().reset_index()\nstate_spend = customer_by_location.groupby(['customer_state','geolocation_state_lng','geolocation_state_lat'])['price'].sum().to_frame().reset_index()\nstate_freight = customer_by_location.groupby(['customer_state','geolocation_state_lng','geolocation_state_lat'])['freight_value'].mean().reset_index()\nstate_freight['text'] = 'state: ' + state_freight['customer_state'] + ' | freight: ' + round(state_freight['freight_value'],1).astype(str)","01e9149f":"state_order = [go.Scattergeo(lon = state_spend['geolocation_state_lng'],\n                      lat = state_spend['geolocation_state_lat'],\n                      text = state_freight['text'],\n                      marker = dict(size = state_spend['price']\/2000,\n                                    sizemin = 5,\n                                    color= state_freight['freight_value'],\n                                    colorscale= 'balance',\n                                    cmin = 20,\n                                    cmax = 50,\n                                    line = dict(width=0.1, color='rgb(40,40,40)'),\n                                    sizemode = 'area'\n                                   ),\n                      name = 'State'),]\nlayout = dict(\n        title = 'Brazilian E-commerce Order by States',\n        showlegend = True,\n        autosize=True,\n        width = 900,\n        height = 600,\n        geo = dict(\n            scope = \"south america\",\n            projection = dict(type='winkel tripel', scale = 1),\n            center = dict(lon=-47,lat=-22),\n            showland = True,\n            showcountries= True,\n            showsubunits=True,\n            landcolor = 'rgb(155, 155, 155)',\n            subunitwidth=1,\n            countrywidth=1,\n            subunitcolor=\"rgb(255, 255, 255)\",\n            countrycolor=\"rgb(255, 255, 255)\"\n        )\n    )\n\nfig = dict( data=state_order, layout=layout )\niplot( fig, validate=False)","dbc16cac":"count_state = data['geolocation_state'].value_counts()\ncount_state['others'] = count_state[count_state < 5000].sum()\ncount_state = count_state[count_state > 5000]\n\nsns.barplot(x=count_state.index, y=count_state.values)","7c78f5be":"freigh_value = [go.Scattergeo(lon = state_freight['geolocation_state_lng'],\n                      lat = state_freight['geolocation_state_lat'],\n                      text = state_freight['text'],\n                      marker = dict(size = (state_freight['freight_value']-10)**2,\n                                    sizemin = 5,\n                                    color= state_freight['freight_value'],\n                                    colorscale= 'balance',\n                                    cmin = 20,\n                                    cmax = 50,\n                                    line = dict(width=0.1, color='rgb(40,40,40)'),\n                                    sizemode = 'area'\n                                   ),\n                      name = 'State'),]\nlayout = dict(\n        title = 'Freight Values',\n        showlegend = True,\n        autosize=True,\n        width = 900,\n        height = 600,\n        geo = dict(\n            scope = \"south america\",\n            projection = dict(type='winkel tripel', scale = 1.0),\n            center = dict(lon=-47,lat=-22),\n            showland = True,\n            showcountries= True,\n            showsubunits=True,\n            landcolor = 'rgb(155, 155, 155)',\n            subunitwidth=1,\n            countrywidth=1,\n            subunitcolor=\"rgb(255, 255, 255)\",\n            countrycolor=\"rgb(255, 255, 255)\"\n        )\n    )\n\nfig = dict( data=freigh_value, layout=layout)\niplot( fig, validate=False)","532a8cde":"state_delivery_time = data.groupby('customer_state')['delivery_time'].mean().to_frame()\n\nstate_delivery_time.columns = ['avg_state_delivery_time']\nstate_delivery_time = state_delivery_time.reset_index()\n\nstate_delivery_time = pd.merge(state_delivery_time,state_spend,\n                how='inner', on='customer_state')\n\n# Clean delivery time\nstate_delivery_time = state_delivery_time[state_delivery_time['avg_state_delivery_time'] > 0]\n\n# Show text on the graph\nstate_delivery_time['text'] = 'state: ' + state_delivery_time['customer_state'].astype('str') + ' ' + \\\n                            (state_delivery_time['avg_state_delivery_time'].apply(np.ceil)).astype('str') + ' days'","8258d852":"State_Delivery_Days = [go.Scattergeo(lon = state_delivery_time['geolocation_state_lng'],\n                      lat = state_delivery_time['geolocation_state_lat'],\n                      text = state_delivery_time['text'],\n                      marker = dict(size = 20,\n                                    sizemin = 5,\n                                    color= ((state_delivery_time['avg_state_delivery_time'])**2),\n                                    colorscale= 'agsunset',\n                                    cmin = 10,\n                                    cmax = 255,\n                                    line = dict(width=0.1, color='rgb(40,40,40)'),\n                                    sizemode = 'area'\n                                   ),\n                      name = 'State'),]\nlayout = dict(\n        title = 'State Delivery Days',\n        showlegend = True,\n        autosize=True,\n        width = 900,\n        height = 600,\n        geo = dict(\n            scope = \"south america\",\n            projection = dict(type='winkel tripel', scale = 1.6),\n            center = dict(lon=-47,lat=-22),\n            showland = True,\n            showcountries= True,\n            showsubunits=True,\n            landcolor = 'rgb(155, 155, 155)',\n            subunitwidth=1,\n            countrywidth=1,\n            subunitcolor=\"rgb(255, 255, 255)\",\n            countrycolor=\"rgb(255, 255, 255)\"\n        )\n    )\n\nfig = dict( data=State_Delivery_Days, layout=layout)\niplot( fig, validate=False)","d383a0d5":"geo = [go.Scattermapbox(lon = geo_city['geolocation_city_lng'],\n                        lat = geo_city['geolocation_city_lat'],\n                        text = geo_city['geolocation_city'],\n                        marker = dict(size = 3,\n                                      color = 'tomato',))]\n\nlayout = dict(title = 'Brazil City',\n              mapbox = dict(accesstoken = 'pk.eyJ1IjoiaG9vbmtlbmc5MyIsImEiOiJjam43cGhpNng2ZmpxM3JxY3Z4ODl2NWo3In0.SGRvJlToMtgRxw9ZWzPFrA',\n                            center= dict(lat=-22,lon=-43),\n                            bearing=10,\n                            pitch=0,\n                            zoom=2,))\n\nfig = dict(data=geo, layout=layout)\niplot(fig, validate=False)","5de95243":"count_city = data['geolocation_city'].value_counts()\n\nplt.figure(figsize=(13,4))\nsns.barplot(x=count_city.index[:10], y=count_city.values[:10])","d14bff2d":"city_delivery_time = data.groupby('customer_city')['delivery_time'].mean().to_frame()\n\ncity_delivery_time.columns = ['avg_city_delivery_time']\ncity_delivery_time = city_delivery_time.reset_index()\n\ncity_delivery_time = pd.merge(city_delivery_time,city_spend,\n                how='inner', on='customer_city')\n\n# Clean delivery time\ncity_delivery_time = city_delivery_time[city_delivery_time['avg_city_delivery_time'] > 0]\n\n# Show text on the graph\ncity_delivery_time['text'] = 'city: ' + city_delivery_time['customer_city'].astype('str') + ' ' + city_delivery_time['avg_city_delivery_time'].astype('str') + ' days'","e75bbf29":"City_Delivery_Days = [go.Scattergeo(lon = city_delivery_time['geolocation_city_lng'],\n                      lat = city_delivery_time['geolocation_city_lat'],\n                      text = city_delivery_time['text'],\n                      marker = dict(size = 3,\n                                    sizemin = 5,\n                                    color= ((city_delivery_time['avg_city_delivery_time'])**2),\n                                    colorscale= 'agsunset',\n                                    cmin = 10,\n                                    cmax = 255,\n                                    line = dict(width=0.1, color='rgb(40,40,40)'),\n                                    sizemode = 'area'\n                                   ),\n                      name = 'City'),]\nlayout = dict(\n        title = 'City Delivery Days',\n        showlegend = True,\n        autosize=True,\n        width = 900,\n        height = 600,\n        geo = dict(\n            scope = \"south america\",\n            projection = dict(type='winkel tripel', scale = 1.6),\n            center = dict(lon=-47,lat=-22),\n            showland = True,\n            showcountries= True,\n            showsubunits=True,\n            landcolor = 'rgb(155, 155, 155)',\n            subunitwidth=1,\n            countrywidth=1,\n            subunitcolor=\"rgb(255, 255, 255)\",\n            countrycolor=\"rgb(255, 255, 255)\"\n        )\n    )\n\nfig = dict( data=City_Delivery_Days, layout=layout)\niplot( fig, validate=False)","06d661d7":"delivery_time_city = city_delivery_time['customer_city'].value_counts()\n\nplt.figure(figsize=(13,4))\nsns.barplot(x=delivery_time_city.index[:10], y=delivery_time_city.values[:10])","6d63bcc4":"print(customers['customer_id'].duplicated().sum())\nprint(customers['customer_unique_id'].duplicated().sum())","47507ea2":"## 0.2 Closed Deads","39b1f2cf":"#### Observation\n- Most delivery time is less than 50 days.\n- Review score is lower for longer delivery time.\n- Customer really giving better review score as they get their order in advanced!","a534e181":"## 3.1 Monthly Revenues by Business Segment","5a4928d1":"### 3.1.1 Watches Revenue by Product Category","3150aced":"## 2.1 Time Series Volume of Closed Deals","fd5a2b4d":"#### Observation\n- 8000 rows\n- 8000 unique mql_id\n- 336 unique first contact date\n- 495 separate landing page\n- 10 unique origin marketing channel, denoted by 'origin'","cf23980d":"## 2.2 Conversion Rate\nConversion rate means the percentage of MQLs who finally signed up for sellers (closed deals).","5ccc2da6":"#### Observation\n- 60 missing value appears in 'Origin' feature\n- has_company, has_gtin, average_stock, declared_product_catalog_size contains lots of missing values, thus we safely remove them from the analysis.","2b006b83":"#### Observation:\n- Likewise, monthly volume of closed deals sharply increased after 2018.","e6d40127":"#### Observation\n- Though 'watches' segment is the largest part of revenue, it has only two sellers.\n- Furthermore, the leading seller generated 97.0% of segment revenue.","cc58ed47":"### 6.2.1 City Delivery Days","2a1e994a":"## 6.2 Cities","b80fea93":"Most payments are done with credit card (almost 75%) and another 20% with boleto.","5ed8b106":"There is a huge spike in Nov 24 due to Black Friday\n\nSales are weak after Dec 20 (end-year holidays)","686d81c1":"## 5.4 Quantity - Revenue by products\n- The 2 chart below pretty much speak for themselves","4520f011":"# 2. SALES PERFORMANCE OVERVIEW\nAfter a MQL,who finally signed up for seller is called a closed deal, filled a form on landing page to sign up for seller, a Sales Development Representative(SDR) contacted the MQL and gathered more information about the lead. Then a Sales Representative(SR) consulted the MQL. So interaction between SDRs\/SRs and MQLs can affect conversion from MQLs to sellers.\n\nAt this section I will deal with three aspects of sales result such as Closed deal volumne, Conversion rate and Sales length.","ce237c5a":"# BRAZILIAN E-COMMERCE DATA\n## Author: Vu Duong\n### Date: July, 2020\n\n# CREDITS:\nThis work is inspired by multiple greate sources done before:\n- https:\/\/www.kaggle.com\/htrap94\/eda-mql-and-closed-deals-dataset\n- https:\/\/www.kaggle.com\/jungjoonlee\/eda-with-ecommerce-marketplace-seller-side\n- https:\/\/www.kaggle.com\/jsaguiar\/e-commerce-exploratory-analysis\n- https:\/\/www.kaggle.com\/andresionek\/joining-marketing-funnel-with-brazilian-e-commerce\n- https:\/\/www.kaggle.com\/andresionek\/geospatial-analysis-of-brazilian-e-commerce\n- https:\/\/www.kaggle.com\/gsdeepakkumar\/e-commerce-dataset-analysis\n- https:\/\/www.kaggle.com\/hoonkeng\/eda-understand-brazil-e-commerce-geographically\n\n# INTRODUCTION\nThe dataset has information of 100k orders from 2016 to 2018 made at multiple marketplaces in Brazil. Its features allows viewing an order from multiple dimensions: from order status, price, payment and freight value to customer location, product attributes and finally reviews written by customers.\n\nThis is real commercial data provided by Olist, it has been anonymised.Olist connects small businesses from all over Brazil to channels where merchants are able to sell their products and ship them directly to the customers using Olist logistics partners. After a customer purchases the product from Olist Store a seller gets notified to fulfill that order. Once the customer receives the product, or the estimated delivery date is due, the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments.","edee022b":"# 5 Order - Order Items - Products","dcd2b781":"## 2.3 Sales Length\n- Sales length means period from first contact to signing up for seller.","5c53b3b7":"## 5.5 Review Score","94542fdc":"### 2.5.2 SDR\/SR Performance by Behaviour Profile","6cac929e":"## 4.3 Installment","6ad4b9c2":"### 0.4.2 Geography","ef636af7":"#### Observation\n- The review score of 5 is leading the chart\n\n- The second chart show that the product's price doesn't impact on how customers' score","7d84d2f9":"#### Observation\n- Sales length was dramatically shortened as well. While 13.1% of deals were closed within 50 days in 2017, 78.9% was closed in 2018. \n- In a nutshell, both conversion rate and sales length were improved in 2018 against 2017.","99955f9c":"- Total revenues across 29 segments came in at 664,858 in the first eight months of 2018.\n- The biggest segment was 'watches', which generated 17.4% of total revenues (115,901).","77fad9f7":"## 4.1 Payment Distribution","5fdf55ac":"## 5.3 Purchase timestamp","d3e58972":"Customers can pay with more than one payment method and therefore we have duplicate order ids in this frame. The sequential feature is used to indicate the payment method order.","24d49da1":"#### Observation","3d9f55a2":"#### Observation\n- Organic search, paid search, and social platform are 3 leading marketing channels that drive people to website\n- Nearly 5k customers come from online platforms: organic and paid search, direct traffic, email, while the rest are sources like referral, display, other.","7eea847c":"## 1.3 Landing Page","27e5f10b":"### 0.4.1 Closed deals, Marketing qualified leads","ee1e514b":"#### Observation\n- Actual delivery time is usually earlier than estimated delivery time, resulting good customers' experience.","e148574c":"# 3. CLOSED DEAL PERFORMANCE OVERVIEW","811af038":"### 2.5.1 Characteristics of Closed Deal","1ced88c2":"# LIBRARY","690138bf":"## 5.6 Delivery Time","b72cc62a":"## 0.4 Cleaning","57e0e777":"Conversion rate also increased with volume.","cc9c6143":"## 0.1 Marketing Qualified Leads","5975b57a":"## 1.1 Time Series Analysis of Marketing Qualified Lead (MQL) Volume","499796cd":"#### Observation\n- 'watches_gifts' may be a relatively homogeneous market so securing popular items is more important than pursuing a broad range of products. It implies that a category leader should be acquired to boost category revenue.\n- Six best-selling items form 60% of category revenue.","cc7cb15a":"#### Observation:\n- Paid search is the second biggest contributor to lead generation after 'organic search'.\n- The third one is 'social' which acquired MQLs more than or similar to 'paid search' since April 2018.\n- If the marginal cost of paid search increases, it would be possible to examine effectiveness of 'social' as an alternative.","7de0ede2":"#### Observation\n- Top 10 landing page","0a346f01":"# 6 GEOLOCATION","5ccb1492":"### 6.1.1 Orders by State","91ce8d8c":"### 0.4.3 Join all tables","ba19aeec":"'lead_behaviour profile' is related to DISC personality test. Each type has the meaning as follows: https:\/\/www.discprofile.com\/what-is-disc\/overview\/\n\n- Closed deals are won in order of cat, eagle, wolf and shark based on descending volume in all three dimensions.\n- In consideration of business context, it might make sense that conversion rate of wolf (accuracy-focused) or shark (result-focused) was lower than cat (cooperation-focused) or eagle (relationship-focused).\n\nIf so, sales performance could be improved by matching SDRs\/SRs with MQLs properly.","8c6daa88":"# 0. MARKETING FUNNEL SUMMARIES ","1cdfa734":"## Customer Data Schema\nThe data is divided in multiple datasets for better understanding and organization. Please refer to the following data schema when working with it:","afc5369b":"### 1.2.2 MQL Volume by Marketing Channel between 06\/2017 - 07\/2018","783f66d5":"## 2.5 Digging into Closed Deal\nI will explore closed deals in more depth to see whether there is room for improvement in sales process. \n\nSpecifically I'm looking into three dimensions of closed deals('lead type', 'business segment', 'business type') with 'lead behaviour profile' as an axis.","2ee85a4c":"### 6.1.2 Freigh Value by State","2d4f57fb":"## 2.4 Monthly Revenue by MQL ","fdb25812":"#### Obsevation\nLet's uncover information about two sellers.\n- The leading seller is 'online big', perhaps a large internet-based company with high market share or strong brand awareness.\n- And its business type is 'reseller'. That explains why there are irrelevant product categories in 'watches' segment. The fact that a business segment may have unrelated product categories means revenue analysis should be conducted based on 'product category' rather than 'business segment'.","35a88cc8":"## 5.2 Product Price - Freigh Value\n- Product unit price is mostly less than \\$1000.\n- Freight value revolves around \\$150. ","9bb3ae1c":"##### Observation\n\n1. SDR\n    - 1st and 3rd SDRs are eminent in handling cat.\n    - 2nd and 10th SDRs are specialized in eagle.\n    - 1st SDR is also unparalleled in dealing with wolf.\n    - As to shark 1st SDR is better than the others, but not enough to claim to be an expert.\n    - SDR is the first contact point of MQL so they do not know the lead's behaviour profile yet. Therefore sharing top performers' -expertise in cat, eagle or wolf can enhance team performance.\n    - In regard to shark, external resources may be helpful in building capability.\n\n2. SR\n    - 1st SR has matchless skills in managing both cat and eagle.\n    - SRs on the first four places are good at handling wolf, but not as much as their highest performing fields.\n    - 2nd and 5th are the best performers in regard to shark, but hard to say 'proficient'.\n    - Eagle can be assigned to 2nd SR. Further, spreading knowledge among the team can improve team performance.\n    - Like SDR, external knowledge sources can be a way to boost performance.","2c0de543":"#### Observation\n- Most conversion length is from 0 to 70 days","ae9fc6e7":"### 3.1.2 Watches Revenue by Seller","919a63db":"#### Observation\n- Top 5 cities experience the worst delivey time are: Brazilia, Jaguariuna, Mogi-guacu, Camacari, Uba","853adfda":"## 1.2 Marketing Channel\n- Marketing channel is recorded in 'origin' field.","6f5f653e":"# 1. MARKETING CHANNEL EFFECTIVENESS\nOlist acquired sellers through diverse marketing channels. Let's find out which channel was the most effective in lead generation.","1363588d":"## 6.1 States","8cd7bd81":"## 4.2 Payment Method","08c4f207":"# 4. PAYMENTS","e6fa61e6":"### 6.1.3 State Delivery Days","7ca9da94":"# 7 CUSTOMERS","d0edea58":"Only credit cards can have more than one installment:","a9f3974a":"#### Observation\n- 842 rows\n- 842 unique mql id\n- 842 unique seller id\n- 32 unique sdr id\n- 22 sr id\n- 33 separate business segments\n- 8 lead types\n- 9 different lead behavior profile","c269868c":"#### Observation:\nSince 2018, monthly MQL volume soared to above 1,000. ","e247abf6":"# TOP 10 PRODUCTS\n# TOP 10 SELLERS\n# ORDER TREND: YEAR, MONTH, WEEKDAY, HOUR\n# TRANSACTION VALUE BY CITY, STATE","7e7c1163":"## Seller (Merchants) Data Schema\nThe data is divided in multiple datasets for better understanding and organization. Please refer to the following data schema when working with it:","43347c70":"### 1.2.1 Marketing Channel Overall","8839db9f":"## 0.3 Checking for Missing Values","04129eb0":"### 5.1 The Number of Products in each order \n- 1 order mostly includes 1 or 2 products"}}