{"cell_type":{"e43b6ff3":"code","51e577b7":"code","c70b1318":"code","97582aa4":"code","973caec3":"code","9a182f33":"code","bdd6ac36":"code","53a174ce":"code","ee351d89":"code","ed9e9711":"code","7afd8ce3":"code","d41b957a":"code","f62f0adf":"code","f6362520":"code","b45b1285":"code","b3b77677":"code","99322afd":"code","4d92d158":"code","1d986558":"code","c93cd9bb":"code","524d14c7":"code","060b2278":"code","c132346a":"code","533202fd":"code","633a720c":"code","93ee1404":"markdown"},"source":{"e43b6ff3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport nltk \nfrom nltk.corpus import stopwords\n#to remove HTML tags from the doc\nfrom bs4 import BeautifulSoup \n#removing numbers,punctuations,i.e regular expressions from the doc\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","51e577b7":"train_data = pd.read_csv(\"..\/input\/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\ntrain_data.shape","c70b1318":"train_data.head(5)","97582aa4":"# view the first review\ntrain_data.review[0]","973caec3":"# html tags and comments are removed and stored in sample1\n\nsample1 = BeautifulSoup(train_data.review[0],\"html.parser\")\n\n# using get_text() we can see only text in html doc\n\nprint(sample1.get_text())","9a182f33":"# a '^' within square brackets searches anything other than the one on it\n# hence here it matches everything from numbers and punctuations etc , leaving only the words\n\nletters_only = re.sub(\"[^a-zA-Z]\",\" \",sample1.get_text())\nprint(letters_only)","bdd6ac36":"# changing all the words to lowercase to create a bag of words later\n\nlower_case = letters_only.lower()\n\n# the whole doc is now split to create an array from which most common words called \"stop words\" will be removed\n\nwords = lower_case.split()","53a174ce":"import nltk\nnltk.download('stopwords')\n\n# most common stopwords used in english language\n\nprint(stopwords.words(\"english\"))","ee351d89":"# removing  stopwords from sample1 so that relevant words can be filtered out and stored in words\n\nwords = [w for w in words if w not in stopwords.words(\"english\")]\nprint(words)","ed9e9711":"# the above code cleans only one review , let's make a function to clean all the reviews\ndef review_to_words(raw_review):\n    #remove html using BeautifulSoup\n    review_text = BeautifulSoup(raw_review,\"html.parser\").get_text()\n    #removing raw letters,numbers,punctuations\n    letters_only = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n    #creating an array , resolving whitespaces\n    words = letters_only.lower().split()\n    #create an array of stopwords so that we don't have to access corpus to search for a stopword\n    stop = set(stopwords.words(\"english\"))\n    #removing stopwords from the raw_review\n    meaningful_words = [w for w in words if w not in stop]\n    #return a string with only the words that are important\n    return(\" \".join(meaningful_words))","7afd8ce3":"# finding the number of reviews\nnum_rev = train_data.review.size\nprint(num_rev)","d41b957a":"# storing all cleaned reviews in one place\n\ncleaned_rev = []\nfor i in range(num_rev):\n    cleaned_rev.append(review_to_words(train_data.review[i]))","f62f0adf":"# creating a function, vectorizer to convert the words into vectors\n\nvectorizer = CountVectorizer(analyzer=\"word\",\n                            preprocessor=None,\n                            stop_words=\"english\",\n                            max_features=5000)","f6362520":"# converting reviews from text into features\n\ntrain_data_features = vectorizer.fit_transform(cleaned_rev)\n\n#change the classifier into array\n\ntrain_data_features = train_data_features.toarray()","b45b1285":"X = train_data_features\n\n#dependent variable,y will be 1 for positive and 0 for negative review\n\ny = train_data.sentiment ","b3b77677":"# 25000 rows and 5000 features\n\nprint (X.shape) \nprint (y.shape) ","99322afd":"# splitting the training data into test and train\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=123)","4d92d158":"# Applying MultinomialNaiveBayes for classification \n\nnaive = MultinomialNB()\nclassifier = naive.fit(X_train,y_train)\npredict = classifier.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(predict,y_test)\ncm","1d986558":"accuracy = cm.trace()\/cm.sum()\nprint(accuracy)","c93cd9bb":"# loading test data for prediction\n\ntest_data = pd.read_csv(\"..\/input\/testData.tsv\",header=0, delimiter=\"\\t\", quoting=3)\ntest_data.head(2)","524d14c7":"# preprocessing of test data\n\nnumber_of_review = len(test_data[\"review\"])\nprint(number_of_review)\n\n# removing all punctuations,numbers, etc from test data\n\nclean_review =[]\nfor i in range(number_of_review):\n    clean_review.append(review_to_words(test_data[\"review\"][i]))\n    ","060b2278":"# converting text into features and features to array\n\ntest_data_features = vectorizer.fit_transform(clean_review)\ntest_data_features = test_data_features.toarray()\n","c132346a":"# predicting test data by the classifier\n\ny_pred_M = classifier.predict(test_data_features)\n\n# accuracy and f1 score\n\nprint(accuracy_score(y,y_pred_M))\nprint(f1_score(y,y_pred_M))","533202fd":"# Applying BernolliNaiveBayes Classifier to training data \n\nBernNB = BernoulliNB(binarize = 0.01)\nBernNB.fit(X_train,y_train)\nprint(BernNB)\n\n# applying classifier to the test data\n\ny_pred_B = BernNB.predict(test_data_features)\nprint (accuracy_score(y,y_pred_B))\nprint (f1_score(y,y_pred_B))\n","633a720c":"# since accuracy and f1_score are slightly higher in MultinomialNaiveBayes, \n# predicted value of that model is used for the submission.\n\n# Copy the results to a pandas dataframe with an \"id\" column and\n# a \"sentiment\" column\n\noutput = pd.DataFrame( data={\"id\":test_data[\"id\"], \"sentiment\": y_pred_M} )\n\n# Use pandas to write the comma-separated output file\n\noutput.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )","93ee1404":"creating bag of words model"}}