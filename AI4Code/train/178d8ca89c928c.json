{"cell_type":{"779d5c21":"code","103485db":"code","ccc4d611":"code","b76cabfd":"code","a736dfae":"code","8e96c16c":"code","b497463b":"code","94ac73e0":"code","ded3f31a":"code","e25a6ee8":"code","ea79882f":"code","2b29281a":"code","e4554cf1":"code","c811476c":"code","1377ca4b":"code","8c1d5465":"code","4cac31a7":"code","8c706c6b":"markdown","15df58a8":"markdown","05fd248f":"markdown","6851f1f2":"markdown"},"source":{"779d5c21":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","103485db":"import os\nlabels = os.listdir('..\/input\/indian-coins-dataset\/indian_coins_dataset')\nprint(labels)","ccc4d611":"num = []\nfor label in labels:\n    path = '..\/input\/indian-coins-dataset\/indian_coins_dataset\/{0}\/'.format(label)\n    folder_data = os.listdir(path)\n    k = 0\n    print('\\n', label.upper())\n    for image_path in folder_data:\n        k = k+1\n    num.append(k)\n    print('there are ', k,' images in ', label, 'class')","b76cabfd":"import matplotlib.pyplot as plt\nplt.figure(figsize = (8,8))\nplt.bar(labels, num)\nplt.title('NUMBER OF IMAGES CONTAINED IN EACH CLASS')\nplt.xlabel('classes')\nplt.ylabel('count')\nplt.show()","a736dfae":"x_data =[]\ny_data = []\nimport cv2\nfor label in labels:\n    path = '..\/input\/indian-coins-dataset\/indian_coins_dataset\/{0}\/'.format(label)\n    folder_data = os.listdir(path)\n    for image_path in folder_data:\n        image = cv2.imread(path+image_path)\n        image_resized = cv2.resize(image, (150,150))\n        x_data.append(np.array(image_resized))\n        y_data.append(label)","8e96c16c":"x_data = np.array(x_data)\ny_data = np.array(y_data)\nprint('the shape of X is: ', x_data.shape, 'and that of Y is: ', y_data.shape)","b497463b":"#stadardizing the input data\nx_data = x_data.astype('float32')\/255","94ac73e0":"y_cls = np.array(y_data)","ded3f31a":"coins_ids = {\n    'rupee_1': 0,\n    'rupee_2': 1,\n    'rupee_5': 2,\n    'rupee_10': 3,\n    }\n\ny = np.array([coins_ids[coin] for coin in y_cls])\n","e25a6ee8":"X_train = x_data\nY_train = y","ea79882f":"from keras.layers import Conv2D, MaxPool2D, Flatten, GlobalAvgPool2D, GlobalMaxPool2D, Dense\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\nmodel = Sequential()\n\n# CNN network\nmodel.add( Conv2D(16, 3, activation='relu', padding='same', input_shape=(150, 150, 3)) )\nmodel.add( MaxPool2D(2) )\n\nmodel.add( Conv2D(32, 3, activation='relu', padding='same') )\nmodel.add( MaxPool2D(2) )\n\nmodel.add( Conv2D(64, 3, activation='relu', padding='same') )\nmodel.add( MaxPool2D(2) )\n\nmodel.add( Conv2D(128, 3, activation='relu', padding='same') )\nmodel.add( MaxPool2D(2) )\n\nmodel.add( Conv2D(256, 3, activation='relu', padding='same') )\n\n# Transition between CNN and MLP\nmodel.add( GlobalAvgPool2D() )\n\n# MLP network\nmodel.add( Dense(256, activation='relu') )\n\nmodel.add( Dense(4, activation='softmax') )\n\nmodel.summary()\n","2b29281a":"optim = Adam(lr=1e-3)\nmodel.compile(optim, 'sparse_categorical_crossentropy', metrics=['acc'])","e4554cf1":"X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=33)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=33)\nprint(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))","c811476c":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        rotation_range=90,\n        featurewise_center=True,\n        featurewise_std_normalization=True,\n        shear_range=0.2,\n        zoom_range=0.2,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\ndatagen.fit(X_train)\n\nval_datagen = ImageDataGenerator(\n        rotation_range=90,\n        featurewise_center=True,\n        featurewise_std_normalization=True,\n         width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nval_datagen.fit(X_val)","1377ca4b":"early_stop = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n\n\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size=32), \n                    samples_per_epoch=len(X_train),  \n                    nb_epoch=100, \n                    validation_data=val_datagen.flow(X_val, y_val, batch_size=32),\n                    nb_val_samples=len(X_val),\n                    verbose=1,\n                    callbacks=[early_stop])","8c1d5465":"ax = df_history[['acc', 'val_acc']].plot()\nax.set_ylim(0.9, 1)","4cac31a7":"model.save('coins_model_2.h5')","8c706c6b":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Convolution2D, MaxPooling2D,GlobalAveragePooling2D, AveragePooling2D\n\nx = model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128,activation='relu')(x)\nx = Dropout(0.2)(x)\n\nmodel.summary()","15df58a8":"from keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\nmodel = ResNet50(include_top=False,weights='imagenet',input_shape=(150,150,3))\nmodel.summary()\n\n","05fd248f":"from keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense, Activation\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras import callbacks\n\nimg_width, img_height = 150, 150\nbatch_size = 32\nsamples_per_epoch = 1000\nvalidation_steps = 300\nnb_filters1 = 32\nnb_filters2 = 64\nconv1_size = 3\nconv2_size = 2\npool_size = 2\nclasses_num = 4\nlr = 0.0004\n\nmodel = Sequential()\nmodel.add(Convolution2D(nb_filters1, conv1_size, conv1_size, border_mode =\"same\", input_shape=(img_width, img_height, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n\nmodel.add(Convolution2D(nb_filters2, conv2_size, conv2_size, border_mode =\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(pool_size, pool_size), dim_ordering='th'))\n\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(classes_num, activation='softmax'))","6851f1f2":"from tensorflow.keras import regularizers\n\npredictions = Dense(4,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n\nmodel = Model(inputs=model.input, outputs=predictions)\n"}}