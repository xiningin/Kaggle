{"cell_type":{"f74796b3":"code","799b158d":"code","7eb9320b":"code","f986e892":"code","8bb82ad3":"code","67eaec29":"code","71a224ff":"code","4a697e42":"code","742672cd":"code","d2f6c6e1":"code","e473319b":"code","d7f54320":"code","9853076d":"code","bce7f25d":"code","374e06e5":"code","62be904b":"code","2f3b7947":"code","265c36ea":"code","7df8e905":"code","4f170253":"code","bd86bbbf":"code","88adb053":"code","40892d9f":"code","946a0c9e":"markdown","9e252991":"markdown","8daed2b9":"markdown","3f8d191b":"markdown","85eaf97d":"markdown","c0819f1d":"markdown","d8127902":"markdown","371fbf9b":"markdown","2deaba42":"markdown","3159ee50":"markdown","f4adf392":"markdown","97c209e8":"markdown","1e75ee66":"markdown","65c38961":"markdown"},"source":{"f74796b3":"#load necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport matplotlib as mpl\nimport matplotlib.patches as mpatches\n\n","799b158d":"#load data files\n\n    \ndf7_1=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare-ridership-2017\/2017 Data\/Bikeshare Ridership (2017 Q1).csv\",encoding=\"ISO 8859-1\")\ndf7_2=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare-ridership-2017\/2017 Data\/Bikeshare Ridership (2017 Q2).csv\",encoding=\"ISO 8859-1\")\ndf7_3=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare-ridership-2017\/2017 Data\/Bikeshare Ridership (2017 Q3).csv\",encoding=\"ISO 8859-1\")\ndf7_4=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare-ridership-2017\/2017 Data\/Bikeshare Ridership (2017 Q4).csv\",encoding=\"ISO 8859-1\")\n\ndf8_1=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare2018\/bikeshare2018\/Bike Share Toronto Ridership_Q1 2018.csv\",encoding=\"ISO 8859-1\")\ndf8_2=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare2018\/bikeshare2018\/Bike Share Toronto Ridership_Q2 2018.csv\",encoding=\"ISO 8859-1\")\ndf8_3=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare2018\/bikeshare2018\/Bike Share Toronto Ridership_Q3 2018.csv\",encoding=\"ISO 8859-1\")\ndf8_4=pd.read_csv(\"..\/input\/toronto-bikeshare-data\/bikeshare2018\/bikeshare2018\/Bike Share Toronto Ridership_Q4 2018.csv\",encoding=\"ISO 8859-1\")\n\n#add datafiles together to create one big file\ndf_list=[df7_1,df7_2,df7_3,df7_4,df8_1,df8_2,df8_3,df8_4]\n\ndf=pd.concat(df_list,sort=False)\n#reset index and remove the old index column\ndf.reset_index(inplace=True)\ndf.drop('index',axis=1, inplace=True)","7eb9320b":"#to disable python warnings\npd.options.mode.chained_assignment = None \n","f986e892":"#split trip_start_time column into start_time and start_date\ndf['start_date'],df['start_time']=[x.split(' ')[0] for x in df['trip_start_time']],[x.split(' ')[1] for x in df['trip_start_time']]\n\n#trip_stop_time requires some more transformation\n#looks like some of the rows do not let to split them; let's find those rows and delete them\nno_date=[x for x in df['trip_stop_time'] if not ' ' in x]\n\ndf.drop(df[df['trip_stop_time']==no_date[0]].index, axis=0, inplace=True)\ndf.reset_index(inplace=True)\ndf['stop_date'],df['stop_time']=[x.split(' ')[0] for x in df['trip_stop_time']],[x.split(' ')[1] for x in df['trip_stop_time']]\n\n#since there are some dates which are formated by european style and all the others are formated by the USA style\n#it is easy to find the dates where month is bigger than 12, however how to figure out which dates where the first and the second number is lower than 12\n#let's assume that these numbers belong to one dataset part; max index value is 453082; rows in the first df7_1 of the dataset is 132123 and the second part of the dataset df7_2 is 333353 rows long\n#in total it is 465476 rows; it is slightly higher than the max value. so, let's transform the first two datasets\n\n#find the final index value for transformation\nmargin=df7_1.shape[0]+df7_2.shape[0]\n#create a list of properly transformed dates\nDate = ['{}\/{}\/{}'.format(m,d,y) for d, m, y in map(lambda x: x.split('\/'), df['start_date'])]\n\n#substitute old mixed values with the new saved to Data list\ndf['start_date'][:margin]=Date[:margin]\n#some of the year values are two digit and not 4 digit as the rest\n\ndate_to_fix=[]\nfor i,val in enumerate(df['start_date'].unique()):\n    if len(val.split('\/')[2])<4:\n        date_to_fix.append(val)\n#find index of the rows with short year\nbad_date_index=df[df['start_date'].isin(date_to_fix)].index\n#fix the problem\ndf['start_date'][bad_date_index]=[x[:6]+'20'+x[-2:] for x in df['start_date'][bad_date_index]]\n\n#create list of unique date not transformed to datetime for further need in the future\nstart=df['start_date'].unique()\n#transform the column to datetime\ndf['start_date']=[datetime.datetime.strptime(x,'%m\/%d\/%Y') for x in df['start_date']]\n\n#the same for the stop_date column\nmargin=df7_1.shape[0]+df7_2.shape[0]\nDate = ['{}\/{}\/{}'.format(m,d,y) for d, m, y in map(lambda x: x.split('\/'), df['stop_date'])]\ndf['stop_date'][:margin]=Date[:margin]\n\ndate_to_fix=[]\nfor i,val in enumerate(df['stop_date'].unique()):\n    if len(val.split('\/')[2])<4:\n        date_to_fix.append(val)\nlen(date_to_fix)\n\nbad_date_index=df[df['stop_date'].isin(date_to_fix)].index\ndf['stop_date'][bad_date_index]=[x[:6]+'20'+x[-2:] for x in df['stop_date'][bad_date_index]]\n\nstop=df['stop_date'].unique()\n#still stop_date does not let to convert to datetime; let's look for mistakes\n#this is going to help me to see which values do not let to convert it to datetime format\nstart_not=[x for x in start if x not in stop]\nstop_not=[x for x in stop if x not in start]\n\n#it turned out that stop_date has incorrect date; let's delete it\ndf.drop(df[df['stop_date']=='1\/01\/12018'].index, axis=0, inplace=True)\ndf.reset_index(inplace=True)\ndf.drop('index',axis=1, inplace=True)\n\ndf['stop_date']=[datetime.datetime.strptime(x,'%m\/%d\/%Y') for x in df['stop_date']]\n\n#now we need to make time columns of datetime format\n\ndf['start_day_week']=[x.weekday() for x in df['start_date']]\ndf['stop_day_week']=[x.weekday() for x in df['stop_date']]\n\n#create weekday vocabulary\nday_voc={0:'Sunday',1:'Monday',2:'Tuesday', 3:'Wednesday', 4:'Thursday', 5:'Friday',6:'Saturday' }\n\n#create columns with weekdays full names\ndf['start_day_week']=df['start_day_week'].map(day_voc)\ndf['stop_day_week']=df['stop_day_week'].map(day_voc)\n\n#some of the time rows consist of minutes and hours and some of them consist of minutes, hours and seconds\nlong_time_start=[]\nfor i,val in enumerate(df['start_time'].unique()):\n    if len(val.split(':'))>2:\n        long_time_start.append(val)\n\nlong_time_stop=[]\nfor i,val in enumerate(df['stop_time'].unique()):\n    if len(val.split(':'))>2:\n        long_time_stop.append(val)\n\n\nlong_time_start_index=df[df['start_time'].isin(long_time_start)].index\nlong_time_stop_index=df[df['stop_time'].isin(long_time_stop)].index\n\ndf['start_time'][long_time_start_index]=['{}:{}'.format(h, m) for h,m,s in map(lambda x: x.split(':') ,df['start_time'][long_time_start_index])]\ndf['stop_time'][long_time_stop_index]=['{}:{}'.format(h, m) for h,m,s in map(lambda x: x.split(':') ,df['stop_time'][long_time_stop_index])]\n\ndf['start_time']=[datetime.datetime.strptime(x,'%H:%M').time() for x in df['start_time']]\ndf['stop_time']=[datetime.datetime.strptime(x,'%H:%M').time() for x in df['stop_time']]","8bb82ad3":"#let's create columns month and year for better visualisation and filtering\ndf['month_start']=[x.month for x in df['start_date']]\ndf['month_stop']=[x.month for x in df['stop_date']]\n\nmonth_dict={1:'January', 2:'February', 3:'March', 4:'April',5:'May', 6:'June', 7:'July', 8:'August',9:'September', 10:'October', 11:'November', 12:'December'}\ndf['month_start']=df['month_start'].map(month_dict)\ndf['month_stop']=df['month_stop'].map(month_dict)\n\n#year columns\ndf['month_start'].unique()\nindex_2017=[x.year==2017 for x in df['start_date']]\ndf['year']=df['month_start']\ndf['year'][index_2017]= '2017'\nindex_2018=[x.year==2018 for x in df['start_date']]\ndf['year'][index_2018]= '2018'\n\n#divide dataset to 2017 and 2018 to use later for visualisations\ndf['month_start'].unique()\nindex_2017=[x.year==2017 for x in df['start_date']]\ndf_2017 = df[index_2017]\nindex_2018=[x.year==2018 for x in df['start_date']]\ndf_2018=df[index_2018]\n","67eaec29":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\nsns.set_style( {'axes.spines.left': False,\n 'axes.spines.bottom': False,\n 'axes.spines.right': False,\n 'axes.spines.top': False})\n\n\nsns.countplot(df_2017['month_start'], ax=ax[0], palette=\"ch:.25\")\nax[0].set_title('Count of Bike Rides per Month in 2017', fontsize=14)\nax[0].set_xticklabels(df_2017['month_start'].unique(),rotation=45)\nax[0].set_xlabel('Months')\nax[0].set_ylabel('Number of Rides')\nax[0].set_ylim(0, 300000) \n\n\nsns.countplot(df_2018['month_start'], ax=ax[1], palette=\"Blues\")\nax[1].set_title('Count of Bike Rides per Month in 2018', fontsize=14)\nax[1].set_xticklabels(df_2018['month_start'].unique(),rotation=45)\nax[1].set_xlabel('Months')\nax[1].set_ylabel('Number of Rides')\n\n\nplt.show()","71a224ff":"plt.figure(figsize=(12,6))\nred_patch = mpatches.Patch(color='b',label='2017')\nblue_patch = mpatches.Patch( color='aliceblue',label='2018')\n\ng=sns.countplot(df_2017['month_start'], palette=\"GnBu\")\nsns.countplot(df_2018['month_start'],palette=\"Blues\",alpha=0.25)\ng.set_title('Count of Bike Rides per Month in 2017 and 2018', fontsize=14)\ng.set_xticklabels(df_2017['month_start'].unique(),rotation=45)\ng.set_xlabel('Months')\ng.set_ylabel('Count')\ng.legend(handles=[blue_patch, red_patch])\n\n\nplt.show()\n","4a697e42":"\nplt.figure(figsize=(12,6))\nred_patch = mpatches.Patch(color='r', label='2017')\nblue_patch = mpatches.Patch(color='b', label='2018')\n\ng=sns.countplot(df_2017['start_day_week'], palette=\"BrBG\")\nsns.countplot(df_2018['start_day_week'],color='r',alpha=0.25)\ng.set_title('Count of Bike Rides by Weekday in 2017 and 2018', fontsize=14)\ng.set_xticklabels(df_2017['start_day_week'].unique())\ng.set_xlabel('Weekday')\ng.set_ylabel('Count')\ng.legend(handles=[blue_patch, red_patch])\n\n\nplt.show()","742672cd":"trip_long=pd.pivot_table(df,index=['start_date'],values='trip_duration_seconds', aggfunc=np.mean )\ntrip_long.reset_index(inplace=True)\ntrip_long['start_day_week']=[x.weekday() for x in trip_long['start_date']]\ntrip_long['month_start']=[x.month for x in trip_long['start_date']]\nmonth_dict={1:'January', 2:'February', 3:'March', 4:'April',5:'May', 6:'June', 7:'July', 8:'August',9:'September', 10:'October', 11:'November', 12:'December'}\ntrip_long['month_start']=trip_long['month_start'].map(month_dict)\nday_voc={0:'Monday',1:'Tuesday',2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday',6:'Sunday' }\n\ntrip_long['start_day_week']=trip_long['start_day_week'].map(day_voc)\ntrip_long['month_start'].unique()\nindex_2017=[x.year==2017 for x in trip_long['start_date']]\ntrip_long['year']=trip_long['month_start']\ntrip_long['year'][index_2017]= '2017'\nindex_2018=[x.year==2018 for x in trip_long['start_date']]\ntrip_long['year'][index_2018]= '2018'\n\n\ntrip_long_17=trip_long[trip_long['year']=='2017']\ntrip_long_18=trip_long[trip_long['year']=='2018']","d2f6c6e1":"trip_long_17.rename(columns={'start_day_week':'Weekday'},inplace=True)\n\nsns.set_style( {'axes.spines.left': False,\n 'axes.spines.bottom': False,\n 'axes.spines.right': False,\n 'axes.spines.top': False})\nplt.figure(figsize=(18,8))\ng=sns.barplot(trip_long_17['month_start'],trip_long_17['trip_duration_seconds'], hue=trip_long_17['Weekday'],palette='BuGn',hue_order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n#sns.lineplot(trip_long_18['month_start'],trip_long_18['trip_duration_seconds'], hue=trip_long_18['start_day_week'])\ng.set_title('Duration of Bikerides in Seconds', fontsize=16)\ng.set(xlabel='Months', ylabel='Total Average Ride Duration')\n","e473319b":"print(df_2017.user_type.unique())\nprint(df_2018.user_type.unique())","d7f54320":"#create dictionary of values to apply to the column\ndict_type={'Member':'Annual Member', 'Casual':'Casual Member'}\ndf_2017.user_type=df_2017.user_type.apply(lambda x:dict_type[x] )","9853076d":"sns.set_style( {'axes.spines.left': False,\n 'axes.spines.bottom': True,\n 'axes.spines.right': False,\n 'axes.spines.top': False})\nfig, ax = plt.subplots(2,1, figsize=(10,6))\nfig.tight_layout(pad=6.0)\nsns.countplot(df_2017['month_start'], ax=ax[0],hue=df_2017['user_type'], palette=\"PiYG\")\nax[0].set_title('Count of Bikerides in 2017 among Members and Casual Riders', fontsize=14)\nax[0].set_xticklabels(df_2017['month_start'].unique(), rotation=30)\nax[0].set_xlabel('')\nax[0].set_ylabel('Number of Rides')\nax[0].set_ylim(0, 200000) \nax[0].legend(loc='upper left', frameon=False)\n\n\n\nsns.countplot(df_2018['month_start'], ax=ax[1],hue=df_2018['user_type'], palette=\"BrBG\")\nax[1].set_title('Count of Bikerides in 2018 among Members and Casual Riders', fontsize=14)\nax[1].set_xticklabels(df_2018['month_start'].unique(), rotation=30)\nax[1].set_xlabel('')\nax[1].set_ylabel('Number of Rides')\nax[1].legend(loc='upper left', frameon=False)\n","bce7f25d":"df['start_hour']=[int(str(x)[:2]) for x in df['start_time']]# to create a column just with the hour value without minutes\n#groupby start hour and day to get the count of rides per hour each day\nn=df[['start_hour','start_date','month_start']].groupby(['start_hour','start_date']).count()\n\nn.reset_index(inplace=True)\nn['start_day_week']=[x.weekday() for x in n['start_date']] #create column of weekdays in numbers\nday_voc={0:'Monday',1:'Tuesday',2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday',6:'Sunday' }\n#create column of word weekdays\nn['start_day_week']=n['start_day_week'].map(day_voc)\n#create column of year value\nn['year']=[x.year for x in n['start_date']]\nn['month']=[x.month for x in n['start_date']] #column with month in numbers\nmonth_dict={1:'January', 2:'February', 3:'March', 4:'April',5:'May', 6:'June', 7:'July', 8:'August',9:'September', 10:'October', 11:'November', 12:'December'}\nn['month_word']=n['month'].map(month_dict) #months in words\n\n","374e06e5":"#rename columns to get better visual\nn.rename(columns={'month_start':'count', 'start_day_week':'weekday', 'start_hour':'hour'}, inplace=True)","62be904b":"g = sns.FacetGrid(n, col=\"weekday\", hue=\"month\",\n                  subplot_kws=dict(projection='polar'), height=4.5,\n                  sharex=False, sharey=False, despine=False,col_order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n\n# Draw a scatterplot onto each axes in the grid\ng.map(sns.lineplot, \"hour\", \"count\",palette=\"PiYG\")\ng.set_titles(\"{col_name}\") \n","2f3b7947":"for i,v in enumerate(n['month_word'].unique()):\n    sns.set_style('white')\n    g=sns.FacetGrid(n[n['month']==(i+1)], col='weekday', col_wrap=7, height=1.5, aspect=2, col_order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n    g=g.map(sns.lineplot, 'hour','count','year', palette=\"PiYG\")\n    g.set(xlim=(0,24))\n    g.set_xlabels('Time')\n    g.set_ylabels('{}'.format(v))\n    g.set_titles(\"{col_name}\") \n    g.add_legend()\n    g.despine(left=True)\n    ","265c36ea":"n1=df[['start_day_week','month_start','year','user_type']].groupby(['start_day_week','month_start','year']).count()\nn1.reset_index(inplace=True)\nn1.rename(columns={'month_start':'month', 'start_day_week':'weekday', 'user_type':'count'}, inplace=True)\nmonth_to_num={'January':0, 'February':1, 'March':2,'April':3,'May':4,'June':5,'July':6,'August':7,'September':8,'October':9,'November':10,'December':11}\nweekday_to_num={'Monday':0, 'Tuesday':1, 'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}\nn1['month1']=n1['month'].apply(lambda x: month_to_num[x])\nn1['weekday1']=n1['weekday'].apply(lambda x: weekday_to_num[x])\n\nnum_to_month=['January', 'February','March','April','May','June','July','August','September','October','November','December']\nnum_to_weekday={0:'Monday', 1:'Tuesday', 2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\nn17=n1[n1['year']=='2017']\nn18=n1[n1['year']=='2018']\nn17p=n17.pivot(index='month1', columns='weekday1', values='count')\nn18p=n18.pivot(index='month1', columns='weekday1', values='count')\n\ncols=['Monday','Tuesday','Wednesday', 'Thursday', 'Friday', 'Saturday','Sunday']\nn17p['month']=num_to_month\nn17p.set_index('month',inplace=True)\nn18p['month']=num_to_month\nn18p.set_index('month',inplace=True)\nn17p.columns=cols\nn18p.columns=cols\nsum17=np.sum(n17p,axis=1).tolist()\nyearpermonth17=pd.DataFrame({'total_sum':sum17}).set_index(n17p.index)\nsum18=np.sum(n18p,axis=1).tolist()\nyearpermonth18=pd.DataFrame({'total_sum':sum18}).set_index(n18p.index)","7df8e905":"percentagediff=np.round((n18p-n17p)\/n18p,2)\n","4f170253":"percentagediff","bd86bbbf":"g=sns.clustermap(percentagediff, cmap='mako', annot=percentagediff)\n","88adb053":"plt.figure(figsize=(12,6))\ng=sns.heatmap(percentagediff,annot=True)\ng.set_title('Count of Bike Rides per Month in 2018\/2017', fontsize=14)\ng.set_xticklabels(df_2017['month_start'].unique(),rotation=45)\n#g.set_xlabel('')\ng.set_ylabel('')\n\n","40892d9f":"\nplt.figure(figsize=(12,6))\nsns.set(style=\"whitegrid\")\ng=sns.scatterplot(yearpermonth17['total_sum'],yearpermonth17.index,palette=\"RdYlGn\", marker='D',s=120)\nsns.scatterplot(yearpermonth18['total_sum'],yearpermonth18.index,palette=\"PRGn\",s=120)\ng.set_title('Total Bike Rides per Month in 2017 and 2018', fontsize=14)\ng.set_xlabel('')\ng.set_ylabel('')\ng.legend(loc='lower right', frameon=False)\n\n","946a0c9e":"The code below transforms dataset to calculate the average trip duration per weekday.","9e252991":"Below we can see a general distribution of rides per weekday and per month. This visualisation was created just to get the general understanding as it is not detailed.","8daed2b9":"The table below shows percentage difference of number of rides in 2018 in comparison with 2017. Most of the moths weekdays show significant rise in the number of rides. Only few days have lower number of rides.","3f8d191b":"Let's look at the rides per user type. Firstly, we need to unify the titles of members and nonmembers. In 2017 it was marked as Member and Casual. In 2018, usertype was differentiated as Annual Member and Casual Member","85eaf97d":"Data transformation below will help to get better understanding of ride number and distribution depending on the hour of the day,weekday and month.","c0819f1d":"The charts below show us the different pick hours of bike rides. There is significant change in pick hours in 2017 and 2018. Weekends show clear tendency of afternoon and evening bikerides. On the days from Monday till Friday we can see the pick hours are in the morning and evening. Most likely people use bikes for commute to and from work.","d8127902":"When we check duration of rides, we can see the longest trips were taken on the weekends. Which means that weekends are also profitable days for bikeshare despite the fact that number of rides in total is significantly lower on weekends than on work days.","371fbf9b":"Now we can see the distribution of bikerides per month in 2017 and 2018. There were much more rides in 2018 than in 2017. In 2018 5 months show rides volume over 200 000 rides, whereas in 2017 only 3 months have high intensity. ","2deaba42":"The dataset is very big. Let's transform some of it's columns. First of all, we need seperate date and time columns.","3159ee50":"Let's check out the most popular days in 2017 and 2018. Looks like Saturday and Sunday are less popular days for bike rides. We can assume that working days contribute more to the bikeride numbers. ","f4adf392":"Let's combine these two plots to get a better visualisation. As we can see, almost all of the months in 2018 have higher number of rides. Only October and Novemebr of 2017 are higher than the same months in 2017.","97c209e8":"In 2017, there were slightly more non-members then in 2018. Peak month of non member rides was in July. In 2018, almost the same high number of rides was done in May, June, July and August.","1e75ee66":"Now let's look at the total number of rides per each month.","65c38961":"<H1>BikeshareRidership Data Transformation, Research and Visualisation<\/H1>\n\nIn this notebook we will research BikeshareRidership data in python.\n\nThe dataset consists of 8 seperate csv files. It contains bikeshare trips information starting from January 1, 2017 and ending in December 31, 2018.\n"}}