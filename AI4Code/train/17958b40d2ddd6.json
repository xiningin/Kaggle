{"cell_type":{"832e2564":"code","af9bde9c":"code","91a51863":"code","22fd84f4":"code","abcf4daf":"code","fc6134f2":"code","6e39cadd":"code","0edd4600":"code","85f551ae":"code","88a468b9":"code","90d22333":"code","a88bbf85":"code","6ea942b3":"code","ddb04b58":"code","09023861":"code","287f496a":"code","1b82c28c":"code","455d73e9":"code","48bd9b55":"code","590e693c":"code","7cf530fd":"code","1dd66f78":"code","9e89c248":"code","12e01bab":"code","c9548ca8":"code","ecc9a080":"code","3f5062ed":"code","b06a7a9a":"code","ab7469f0":"code","f951469c":"code","f1e7a868":"code","4dc5aa31":"code","0d3a7bf5":"code","de9c01ab":"code","b0f7fcf8":"code","f5edbb86":"code","fb64cb62":"code","c3108234":"code","82212fa2":"code","1d46c36d":"code","c1ab8b40":"code","1023ef49":"code","e34be900":"code","bd959d5a":"code","70abd188":"code","b3a7db87":"code","6f3e6e4f":"code","597adf00":"code","7a4e7163":"code","3af7b4a7":"code","74eace8e":"code","494f84ed":"code","307e717a":"code","b72e6baa":"code","da2ffea1":"code","4d64733a":"code","cbb873d4":"code","05bebea2":"code","b7cba4b3":"code","58d19c16":"code","a10398f4":"code","9f49c544":"code","0301bf8f":"code","82e4e477":"code","cf689492":"code","a0077a54":"code","cae1b6bf":"code","525ca54b":"code","8d490a8c":"code","1c5873df":"code","29e832df":"code","6ac8ea9f":"code","ec3f8c3d":"code","20288f8f":"code","9c25560c":"code","3d5252d3":"code","85534523":"code","4af260e3":"code","ae49e8d8":"code","43e580be":"code","f2ba3c4e":"code","34e32e49":"code","f0ebb01a":"code","8e5d59f2":"code","6fb43f26":"code","734060ac":"code","679df440":"code","0285a9bc":"code","d6181779":"markdown","d1c4d301":"markdown","7d428051":"markdown","3eeae3b0":"markdown","ab3e7b44":"markdown","d89888ff":"markdown","31c62cfd":"markdown","612ea32e":"markdown","bde0138b":"markdown","7ddc303c":"markdown","c7239aa6":"markdown","096e6adb":"markdown","ea5fd701":"markdown","2f11c38d":"markdown","81b24f3a":"markdown","3edb6595":"markdown","a9f4d080":"markdown","2a2b9255":"markdown","b02fa67d":"markdown","5af137c5":"markdown","899e05b4":"markdown","036ec2d3":"markdown","bb1231ff":"markdown","299a6c38":"markdown","ad96bcf6":"markdown","a2b86698":"markdown"},"source":{"832e2564":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af9bde9c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","91a51863":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/train.csv')\ntrain.head(5)","22fd84f4":"test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/test.csv')\ntest.head(2)","abcf4daf":"sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/sample_submission.csv')\nsub.head(2)","fc6134f2":"train.shape","6e39cadd":"train.describe()","0edd4600":"train.info()","85f551ae":"train.isnull().sum()","88a468b9":"train['target'] = train['target'].map({'Class_1':1,'Class_2':2,'Class_3':3,'Class_4':4})","90d22333":"train.head(2)","a88bbf85":"train.drop(['id'],axis=1, inplace=True)\ntest.drop(['id'],axis=1, inplace=True)","6ea942b3":"# let's see how data is distributed for every column\nplt.figure(figsize=(20,25), facecolor='white')\nplotnumber = 1\n\nfor column in train:\n    if plotnumber<= 52:\n        ax = plt.subplot(8,7,plotnumber)\n        sns.distplot(train[column])\n        plt.xlabel(column,fontsize=20)\n    plotnumber+=1\nplt.tight_layout()","ddb04b58":"X = train.drop(['target'], axis=1)\ny = train['target']","09023861":"X.head(2)","287f496a":"y.value_counts()","1b82c28c":"from imblearn.combine import SMOTETomek\nfrom imblearn.under_sampling import NearMiss","455d73e9":"# Implementing Oversampling for Handling Imbalanced \nsmk = SMOTETomek(random_state=42)\nX_res,y_res=smk.fit_resample(X,y)","48bd9b55":"y_res.value_counts()","590e693c":"X_ros.drop(['feature_19','feature_30','feature_31','feature_32','feature_35','feature_38','feature_39','feature_42'], axis=1, inplace=True)","7cf530fd":"test.drop(['feature_19','feature_30','feature_31','feature_32','feature_35','feature_38','feature_39','feature_42'], axis=1, inplace=True)","1dd66f78":"X_res.shape","9e89c248":"y.shape","12e01bab":"from imblearn.over_sampling import RandomOverSampler","c9548ca8":"os =  RandomOverSampler()\nX_ros, y_ros = os.fit_resample(X, y)","ecc9a080":"y_ros.value_counts()","3f5062ed":"from imblearn.under_sampling import NearMiss\nns=NearMiss()\nX_ns,y_ns=ns.fit_resample(X,y)","b06a7a9a":"y_ns.value_counts()","ab7469f0":"X_res.head(2)","f951469c":"col = X_res.columns","f1e7a868":"X_res.nunique()","4dc5aa31":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel=ExtraTreesClassifier()\nmodel.fit(X,y)","0d3a7bf5":"print(model.feature_importances_)","de9c01ab":"ranked_features=pd.Series(model.feature_importances_,index=X.columns)\nranked_features.nlargest(10).plot(kind='barh')\nplt.show()","b0f7fcf8":"ranked_features.sort_values(ascending=False)","f5edbb86":"temp = []\nfor i in ranked_features.index:\n  if ranked_features[i] > 0.02:\n    temp.append(i)","fb64cb62":"df = X[temp]\ndf.head(2)","c3108234":"df_test = test[temp]\ndf_test.head(2)","82212fa2":"from sklearn.feature_selection import mutual_info_classif","1d46c36d":"mutual_info=mutual_info_classif(X,y)","c1ab8b40":"mutual_data=pd.Series(mutual_info,index=X.columns)\nmutual_data.sort_values(ascending=False)","1023ef49":"temp = []\nfor i in mutual_data.index:\n  if mutual_data[i] != 0:\n    temp.append(i)","e34be900":"df = X[temp]","bd959d5a":"df.head(2)","70abd188":"from sklearn.decomposition import PCA\npca = PCA()\nprincipalComponents = pca.fit_transform(X_ros)\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('Explained Variance')\nplt.show()","b3a7db87":"pca = PCA(n_components=30)\nnew_data = pca.fit_transform(X_ros)\n# This will be the new data fed to the algorithm.\nprincipal_Df = pd.DataFrame(data = new_data)","6f3e6e4f":"principal_Df.head(2)","597adf00":"test_data = pca.transform(test)\n# This will be the new data fed to the algorithm.\nprincipal_Df_test = pd.DataFrame(data = test_data)","7a4e7163":"principal_Df_test.head()","3af7b4a7":"### Only for ANN training\nY = pd.get_dummies(y)\nY.shape","74eace8e":"# Create Train & Test Data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(principal_Df, y_ros, test_size=0.2, random_state=1)  ### Change y with \"Y\" while ANN training","494f84ed":"# Standard Scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)","307e717a":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)","b72e6baa":"from sklearn.preprocessing import QuantileTransformer\nscaler = QuantileTransformer()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)","da2ffea1":"test_scaled = scaler.transform(principal_Df_test)","4d64733a":"!pip install catboost","cbb873d4":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\nfrom sklearn.model_selection import GridSearchCV\nfrom lightgbm import LGBMClassifier\nfrom imblearn.ensemble import EasyEnsembleClassifier","05bebea2":"classifiers = [['DecisionTree :',DecisionTreeClassifier()],\n               ['RandomForest :',RandomForestClassifier()], \n               ['Naive Bayes :', GaussianNB()],\n               ['KNeighbours :', KNeighborsClassifier()],\n#                ['SVM :', SVC()],\n#                ['Neural Network :', MLPClassifier()],\n               ['LogisticRegression :', LogisticRegression()],\n               ['ExtraTreesClassifier :', ExtraTreesClassifier()],\n               ['AdaBoostClassifier :', AdaBoostClassifier()],\n               ['GradientBoostingClassifier: ', GradientBoostingClassifier()],\n               ['XGB :', XGBClassifier()],\n               ['LGBM :',LGBMClassifier(objective='multiclass', random_state=5)],\n               ['Easy :',EasyEnsembleClassifier()],\n               ['CatBoost :', CatBoostClassifier(logging_level='Silent')]]\n\npredictions_df = pd.DataFrame()\npredictions_df['actual_labels'] = y_val\n\nfor name,classifier in classifiers:\n    classifier = classifier\n    classifier.fit(X_train_scaled, y_train)\n    predictions = classifier.predict(X_val_scaled)\n    predictions_df[name.strip(\" :\")] = predictions\n    print(name, accuracy_score(y_val, predictions))","b7cba4b3":"ETC = XGBClassifier(tree_method = 'gpu_hist')\nETC.fit(X_train_scaled, y_train)\npredictions = ETC.predict(X_val_scaled)\nprint(\"Accuracy :\", accuracy_score(y_val, predictions))\nprint(\"Confusion Matrix :\", confusion_matrix(y_val, predictions))\nprint(\"Classification :\", classification_report(y_val, predictions))","58d19c16":"from sklearn.metrics import log_loss\ny_pred = sclf.predict_proba(X_val_scaled)\nlog_loss(y_val, y_pred)","a10398f4":"y_pred = sclf.predict_proba(test_scaled)","9f49c544":"grid = {'max_depth': [3,4,5,7,9],'n_estimators':[100, 200, 300,400, 500],'learning_rate':[0.001,0.01,0.1]}","0301bf8f":"gscv = GridSearchCV (estimator = Cat, param_grid = grid, scoring ='accuracy', cv = 5)\ngscv.fit(X_train_scaled, y_train)","82e4e477":"print(gscv.best_params_)","cf689492":"tuned_model = CatBoostClassifier(learning_rate= 0.1, max_depth= 5, n_estimators= 300, task_type = \"GPU\",verbose=True)\ntuned_model.fit(X_train_scaled, y_train)\npredictions = tuned_model.predict(X_val_scaled)\naccuracy_score(y_val, predictions)","a0077a54":"ADB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\nXGB = XGBClassifier()\n# ADB.fit(X_train_scaled, y_train)\n# predictions = ADB.predict(X_val_scaled)\n# accuracy_score(y_val, predictions)","cae1b6bf":"# stacking\nfrom mlxtend.classifier import StackingClassifier\nXGB = XGBClassifier(tree_method = 'gpu_hist')\nRFC = RandomForestClassifier()\nETC = ExtraTreesClassifier()","525ca54b":"sclf=StackingClassifier(classifiers=[RFC,ETC], use_probas=True, meta_classifier=XGB)\nsclf.fit(X_train_scaled, y_train)\npredictions = sclf.predict(X_val_scaled)\naccuracy_score(y_val, predictions)","8d490a8c":"from sklearn.ensemble import BaggingClassifier\nCat = CatBoostClassifier(verbose=False, task_type = \"GPU\")","1c5873df":"bag_xgb = BaggingClassifier(Cat,\n                            n_estimators=200, max_samples=0.5,\n                            bootstrap=True, random_state=0,oob_score=True, n_jobs=-1)\nbag_xgb.fit(X_train_scaled, y_train)\npredictions = bag_xgb.predict(X_val_scaled)\naccuracy_score(y_val, predictions)","29e832df":"from sklearn.metrics import log_loss\ny_pred = bag_xgb.predict_proba(X_val_scaled)\nlog_loss(y_val, y_pred)","6ac8ea9f":"y_pred = bag_xgb.predict_proba(test_scaled)","ec3f8c3d":"submission_cat = pd.DataFrame(y_pred, columns=['Class_1','Class_2','Class_3','Class_4'])\nsubmission_cat['id'] = sub['id']","20288f8f":"submission_cat.to_csv('.\/result.csv', index=None)","9c25560c":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam","3d5252d3":"X_train_scaled.shape","85534523":"y_train.shape","4af260e3":"y_val.shape","ae49e8d8":"model = keras.models.Sequential([ \n    keras.layers.Dense(activation=\"relu\", input_dim=50, units=32, kernel_initializer=\"uniform\"),\n    keras.layers.Dense(activation=\"relu\", units=64, kernel_initializer=\"uniform\"),    \n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(activation=\"relu\", units=128, kernel_initializer=\"uniform\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(activation=\"relu\", units=256, kernel_initializer=\"uniform\"),\n    keras.layers.Dense(activation=\"softmax\", units=4, kernel_initializer=\"uniform\")\n])","43e580be":"model.summary()","f2ba3c4e":"epochs = 50\nopt = Adam()\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","34e32e49":"history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_scaled,y_val))","f0ebb01a":"# summarizing historical accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","8e5d59f2":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","6fb43f26":"y_pred = model.predict(test)","734060ac":"sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","679df440":"sub[['Class_1','Class_2','Class_3','Class_4']] = y_pred\nsub.head(10)","0285a9bc":"sub.to_csv('.\/result.csv', index=None)","d6181779":"**Loading Dataset**","d1c4d301":"**Applying PCA**","7d428051":"**Standard Scaling**","3eeae3b0":"**Shape of Dataset**","ab3e7b44":"**Bagging**","d89888ff":"**Robust Scaling**","31c62cfd":"**Handling Categorical fetures**","612ea32e":"**Checking Missing Values**","bde0138b":"**Handling Imbalanced Data**","7ddc303c":"**Stacking**","c7239aa6":"**Importing Libraries**","096e6adb":"**Under Sampling**","ea5fd701":"**Feature Selection Using ExtraTreesClassifier**","2f11c38d":"**Model training using ANN**","81b24f3a":"**Quantile Transformer**","3edb6595":"**Importing all Classification Model**","a9f4d080":"**Summary of DataFrame**","2a2b9255":"**RandomOverSampler to handle imbalanced data**","b02fa67d":"**Hyperparameter Tuning**","5af137c5":"**Checking Distribution of Dataset**","899e05b4":"**Drop Unnecessary Column**","036ec2d3":"**Separting Dependent and Independent column**","bb1231ff":"**Looking on some stastical data**","299a6c38":"**Feature Selection using mutual_info_classif**","ad96bcf6":"**Some Other Feature Engineering**","a2b86698":"**Splitting Dataset into Train and Validation set**"}}