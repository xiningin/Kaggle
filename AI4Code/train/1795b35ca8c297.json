{"cell_type":{"a5884767":"code","5d21fed8":"code","0d7371b1":"code","d32ed5c2":"code","2928e0a4":"code","4016f6b2":"code","0afc5eca":"code","516043c5":"code","76ce5772":"code","686df84c":"code","9c20ce9e":"code","5a12e29a":"code","4742ba19":"code","5025b2ea":"code","fbae77c3":"code","bf48fa38":"code","d51018c2":"code","85bad469":"code","0e5c83ae":"code","a512eba1":"code","48e6d6b9":"code","b47a6547":"code","c1bc1dc1":"code","2ff999ec":"code","5a3a057c":"code","d043d01e":"code","3fe5d67a":"code","4ad4398d":"code","01417429":"code","9fa6be2b":"code","ae6cc874":"code","c5bbe556":"code","12a2a672":"code","c6cc259a":"code","0fdc745c":"code","b1bef829":"markdown","a646447c":"markdown","fa2ad8a3":"markdown","43f69aea":"markdown","5a8eff8d":"markdown","ed04739a":"markdown","ec79a913":"markdown"},"source":{"a5884767":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport shutil\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d21fed8":"import zipfile\nwith zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/train.zip',mode='r') as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile('\/kaggle\/input\/dogs-vs-cats\/test1.zip',mode='r') as z:\n    z.extractall(\".\")","0d7371b1":"cats,dogs = [],[]\nfile_names = os.listdir(\".\/train\/\")\nfor i in file_names:\n    if i.split(\".\")[0]=='cat':\n        cats.append(i)\n    else:\n        dogs.append(i)","d32ed5c2":"len(cats),len(dogs)","2928e0a4":"!mkdir my_dataset\n!mkdir my_dataset\/training_data\n!mkdir my_dataset\/training_data\/cats\n!mkdir my_dataset\/training_data\/dogs\n!mkdir my_dataset\/validation_data\n!mkdir my_dataset\/validation_data\/cats\n!mkdir my_dataset\/validation_data\/dogs","4016f6b2":"train_size = int(len(cats)*.8) #80 percentage\n\n\nfor f in cats[:train_size]:\n    shutil.move(\".\/train\/\"+f, '.\/my_dataset\/training_data\/cats\/')\n\nfor f in cats[train_size:]:\n    shutil.move(\".\/train\/\"+f, '.\/my_dataset\/validation_data\/cats\/')\n    \nfor f in dogs[:train_size]:\n    shutil.move(\".\/train\/\"+f, '.\/my_dataset\/training_data\/dogs\/')\n\nfor f in dogs[train_size:]:\n    shutil.move(\".\/train\/\"+f, '.\/my_dataset\/validation_data\/dogs\/')","0afc5eca":"base_dir = '.\/my_dataset\/'\n\ntrain_dir = os.path.join(base_dir, 'training_data')\nvalidation_dir = os.path.join(base_dir, 'validation_data')\n\n# Directory with our training cat\/dog pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with our validation cat\/dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')","516043c5":"train_cat_fnames = os.listdir( train_cats_dir )\ntrain_dog_fnames = os.listdir( train_dogs_dir )\n\nvalidation_cat_fnames = os.listdir( validation_cats_dir )\nvalidation_dog_fnames = os.listdir( validation_dogs_dir )\n\nprint(train_cat_fnames[:10])\nprint(train_dog_fnames[:10])","76ce5772":"print('total training cat images :', len(os.listdir(      train_cats_dir ) ))\nprint('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n\nprint('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\nprint('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))","686df84c":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images","9c20ce9e":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_fnames[ pic_index-8:pic_index] \n               ]\n\nnext_dog_pix = [os.path.join(train_dogs_dir, fname) \n                for fname in train_dog_fnames[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_cat_pix+next_dog_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","5a12e29a":"import tensorflow as tf\nprint(tf.__version__)","4742ba19":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","5025b2ea":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","fbae77c3":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale= 1.0\/255)\nvalid_datagen = ImageDataGenerator(rescale= 1.0\/255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                   batch_size=20,\n                                                   class_mode='binary',\n                                                   target_size=(150,150))\n\nvalidation_generator = valid_datagen.flow_from_directory(validation_dir,\n                                                   batch_size=20,\n                                                   class_mode='binary',\n                                                   target_size=(150,150))","bf48fa38":"history = model.fit(train_generator,\n                   validation_data=validation_generator,\n                   steps_per_epoch=100,\n                   epochs=15,\n                   validation_steps=50,\n                   verbose=2)","d51018c2":"def plot_model_history(history):\n    #-----------------------------------------------------------\n    # Retrieve a list of list results on training and test data\n    # sets for each training epoch\n    #-----------------------------------------------------------\n    acc      = history.history[     'accuracy' ]\n    val_acc  = history.history[ 'val_accuracy' ]\n    loss     = history.history[    'loss' ]\n    val_loss = history.history['val_loss' ]\n\n    epochs   = range(len(acc)) # Get number of epochs\n\n    #------------------------------------------------\n    # Plot training and validation accuracy per epoch\n    #------------------------------------------------\n    plt.plot  ( epochs,     acc )\n    plt.plot  ( epochs, val_acc )\n    plt.title ('Training and validation accuracy')\n    plt.figure()\n\n    #------------------------------------------------\n    # Plot training and validation loss per epoch\n    #------------------------------------------------\n    plt.plot  ( epochs,     loss )\n    plt.plot  ( epochs, val_loss )\n    plt.title ('Training and validation loss'   )\n    \n    plt.show()","85bad469":"plot_model_history(history)","0e5c83ae":"model2 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel2.compile(optimizer=RMSprop(lr=0.001),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\nmodel2.summary()","a512eba1":"train_datagen_aug = ImageDataGenerator(rescale=1\/255,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\n# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n# TRAIN GENERATOR.\ntrain_generator_aug = train_datagen_aug.flow_from_directory(train_dir,\n                                                   batch_size=10,\n                                                   class_mode='binary',\n                                                   target_size=(150,150))\n\nvalidation_datagen_aug = ImageDataGenerator(rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\n# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n# VALIDATION GENERATOR.\nvalidation_generator_aug = validation_datagen_aug.flow_from_directory(validation_dir,\n                                                              batch_size=100,\n                                                              class_mode='binary',\n                                                              target_size=(150, 150))","48e6d6b9":"history2 = model2.fit(train_generator_aug,\n                   validation_data=validation_generator_aug,\n                   steps_per_epoch=100,\n                   epochs=15,\n                   validation_steps=50,\n                   verbose=2)","b47a6547":"plot_model_history(history2)","c1bc1dc1":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","2ff999ec":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape=(150,150,3),\n                               include_top=False,\n                               weights=None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n    layer.trainable=False\n    \n# pre_trained_model.summary()","5a3a057c":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('Last layer output shape: ',last_layer.output_shape)\nlast_output = last_layer.output","d043d01e":"x = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel3 = tf.keras.Model(pre_trained_model.input,x)\nmodel3.compile(optimizer=RMSprop(lr=0.0001),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n","3fe5d67a":"history3 = model.fit(\n                train_generator_aug,\n                validation_data = validation_generator_aug,\n                steps_per_epoch=100,\n                epochs=15,\n                validation_steps=50,\n                verbose=2)","4ad4398d":"plot_model_history(history_3)","01417429":"test_path='.\/test1'\ntest_file=os.listdir('.\/test1')","9fa6be2b":"test_df=pd.DataFrame({'file':test_file})\ntest_df.head()","ae6cc874":"test_generator = valid_datagen.flow_from_dataframe(test_df,directory=test_path,\n                                                 x_col='file',\n                                                 y_col=None,\n                                                 class_mode=None,\n                                                 target_size=(150,150),\n                                                 batch_size=32,\n                                                 shuffle=False)","c5bbe556":"predict=model.predict(test_generator)\nsub = np.around(predict).astype(int)","12a2a672":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nmy_random_list = [random.randint(0, len(test_file)) for i in range(8)]\nrandom_list = [os.path.join(test_path,test_file[i]) for i in my_random_list]\n\n\nfor i, img_path in enumerate(next_cat_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n  label = \"Dog\" if sub[my_random_list[i]]==1 else \"Cat\"\n  plt.title('Predicted: '+str(label)+'\\nScore: '+str(predict[my_random_list[i]]))\n\nplt.show()\n","c6cc259a":"submission = test_df.copy()\nsubmission['id'] = submission['file'].str.split(\".\").str[0]\nsubmission['label'] = sub\nsubmission.drop(['file'], axis=1, inplace=True)\nsubmission['id'] = submission['id'].astype('int')\nsubmission = submission.sort_values(by=['id'])\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0fdc745c":"submission.head()","b1bef829":"With Augmentation and Dropout","a646447c":"Test and Submission","fa2ad8a3":"Tensorflow Model","43f69aea":"MODEL hISTORY Plotting","5a8eff8d":"Transfer learning","ed04739a":"From above model we pick transfer learning as best model","ec79a913":"To do:\n\n* Callbacks\n* Tensorboard\n* Augmentation\n* Transfer Learning"}}