{"cell_type":{"6b0b2a96":"code","26dd7f1d":"code","c67ef1e4":"code","4cb1bdd1":"code","268f1497":"code","fddc1fed":"code","5f9e32c6":"code","4c9ead4b":"code","1753dfc8":"code","933ec53d":"code","27ca0d76":"code","a33a1baa":"code","eed35736":"code","70d58fd2":"code","563d09cf":"code","b785f00e":"code","0cb39b93":"code","aaec104a":"code","546ea4ae":"markdown","374669d9":"markdown","ff29bb5b":"markdown","f61148d1":"markdown","155a1fcf":"markdown"},"source":{"6b0b2a96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","26dd7f1d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.decomposition import PCA\n#from sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import KFold\nfrom sklearn import linear_model\nfrom sklearn.metrics import make_scorer\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import svm\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler","c67ef1e4":"root_dir = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/'","4cb1bdd1":"train = pd.read_csv(root_dir + 'train.csv')\ntest = pd.read_csv(root_dir + 'test.csv')","268f1497":"## remove na columns\nlarge_na = train.isna().sum() > 0\nlarge_na_test = test.isna().sum() > 0\n\nna_rm_col = large_na[large_na==True].index.tolist() + large_na_test[large_na_test==True].index.tolist()\n\ntrain.drop(na_rm_col, axis=1, inplace=True)\n\ntest.drop(na_rm_col, axis=1, inplace=True)\n\n## select columns\ncat_cols = train.select_dtypes('object').columns\n\nnum_cols = [i for i in train.columns if i not in cat_cols and i not in ['SalePrice']]","fddc1fed":"## one hot and feature reduction\nenc = OneHotEncoder(handle_unknown='ignore')\nmerge_df = pd.concat([train[cat_cols], test[cat_cols].fillna('0')], axis=0)\nenc.fit(merge_df)\n\nohe_train = enc.transform(train[cat_cols]).toarray()\nohe_test = enc.transform(test[cat_cols]).toarray()","5f9e32c6":"## scaling\nsc = StandardScaler()\ntrain_num_scale = pd.DataFrame(sc.fit_transform(train[num_cols]))\ntest_num_scale = pd.DataFrame(sc.transform(test[num_cols]))\n\ntrain_feature = pd.concat([train_num_scale, pd.DataFrame(ohe_train)], axis=1)\ntest_feature = pd.concat([test_num_scale, pd.DataFrame(ohe_test)], axis=1)","4c9ead4b":"pca = PCA(whiten=True)\npca.fit(train_feature)","1753dfc8":"var_pd = pd.DataFrame(pca.explained_variance_ratio_)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('N')\nplt.ylabel('variance explained');","933ec53d":"pca = PCA(n_components=100)\npca.fit(train_feature)\n\ntrain_feature_pca = pca.transform(train_feature)\ntest_feature_pca = pca.transform(test_feature)\n\nlinear_reg = linear_model.LinearRegression()\n\nlinear_reg.fit(train_feature_pca,train['SalePrice'])\n\ny_pred = linear_reg.predict(test_feature_pca)\n\nlinear_reg.get_params()","27ca0d76":"cv = KFold(n_splits=4, shuffle=True, random_state=20)\n\nr2_scorer = make_scorer(r2_score)\n\nr2_val_score = cross_val_score(estimator=linear_reg, cv=cv, scoring=r2_scorer, X=train_feature_pca, y=train['SalePrice'])\nr2_val_score.mean()","a33a1baa":"from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n\nselector = SelectKBest(mutual_info_regression, k=40)\n\ntrain_select = selector.fit_transform(train_feature, train['SalePrice'])\n\nlinear_reg.fit(train_select, train['SalePrice'])\n\n## cv\ncv = KFold(n_splits=4, shuffle=True, random_state=22)\nscorer = make_scorer(r2_score)\nr2_scores = cross_val_score(estimator=linear_reg, cv=cv, scoring=scorer, X = train_select, y=train['SalePrice'])\n\n\nnp.mean(r2_scores)","eed35736":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = train_feature.columns\n\nvif_data['VIF'] = [variance_inflation_factor(train_feature.values, i) for i in range(len(train_feature.columns))]\n\nsum(vif_data.VIF < 10)","70d58fd2":"vif_data.feature[vif_data.VIF < 20].index","563d09cf":"train_select = train_feature.iloc[:,[0, 2, 3, 4, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n            24, 25]]\n## cv\n\nlinear_reg.fit(train_select, train['SalePrice'])\n\n## cv\ncv = KFold(n_splits=4, shuffle=True, random_state=22)\nscorer = make_scorer(r2_score)\nr2_scores = cross_val_score(estimator=linear_reg, cv=cv, scoring=scorer, X = train_select, y=train['SalePrice'])\nnp.mean(r2_scores)","b785f00e":"from sklearn.linear_model import Lasso\n\nmodel = Lasso(max_iter=3000)\nmodel.fit(train_feature, train['SalePrice'])","0cb39b93":"lasso_coef = pd.Series(model.coef_, index = train_feature.columns)\nprint('lasso picked ', sum(lasso_coef!=0), ' features, out of ',len(train_feature.columns))","aaec104a":"## cv\ncv = KFold(n_splits=4, shuffle=True, random_state=22)\nscorer = make_scorer(r2_score)\nr2_scores = cross_val_score(estimator=model, cv=cv, scoring=scorer, X = train_select, y=train['SalePrice'])\nnp.mean(r2_scores)","546ea4ae":"## PCA","374669d9":"## Variance Inflation Factor","ff29bb5b":"## SelectKbest","f61148d1":"## L1 Lasso regression","155a1fcf":"## Preprocessing"}}