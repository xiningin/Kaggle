{"cell_type":{"9c167e4e":"code","b0e03c8d":"code","604cd903":"code","99a3c7a6":"markdown"},"source":{"9c167e4e":"\n!pip install arabic_reshaper\n!pip install imagedegrade\n","b0e03c8d":"#Example of image generated\nimport cv2\nfrom matplotlib import pyplot as plt\n\n#Import image\nimg = cv2.imread(\"..\/input\/image-generated\/1056a62.jpg\")\n\n#Show the image with matplotlib\nplt.imshow(img)\nplt.show()","604cd903":"\n\nfrom enum import Enum\nimport enum\nimport numpy as np\nimport random\nfrom PIL import ImageFont, ImageDraw, Image\nimport arabic_reshaper\nfrom bidi.algorithm import get_display\nfrom skimage import data, transform\nimport matplotlib.pyplot as plt\nfrom imagedegrade import np as degrade\nfrom math import pi\nimport cv2\n\n\"\"\" Utility Functions \"\"\"\n\ndef load_image(img_path, shape=None):\n    img = cv2.imread(img_path)\n    if shape is not None:\n        img = cv2.resize(img, shape)\n    \n    return img\n\ndef save_image(img_path, img):\n    cv2.imwrite(img_path, img)\n\ndef get_rad(theta, phi, gamma):\n    return (deg_to_rad(theta),\n            deg_to_rad(phi),\n            deg_to_rad(gamma))\n\ndef get_deg(rtheta, rphi, rgamma):\n    return (rad_to_deg(rtheta),\n            rad_to_deg(rphi),\n            rad_to_deg(rgamma))\n\ndef deg_to_rad(deg):\n    return deg * pi \/ 180.0\n\ndef rad_to_deg(rad):\n    return deg * 180.0 \/ pi\n\n\nfontpath = \"arial.ttf\"\n\nclass ImageTransformer(object):\n    \"\"\" Perspective transformation class for image\n        with shape (height, width, #channels) \"\"\"\n\n    def __init__(self, image_path, shape):\n        self.image_path = image_path\n        self.image = load_image(image_path, shape)\n \n        self.height = self.image.shape[0]\n        self.width = self.image.shape[1]\n        self.num_channels = self.image.shape[2]\n\n\n    \"\"\" Wrapper of Rotating a Image \"\"\"\n    def rotate_along_axis(self, theta=0, phi=0, gamma=0, dx=0, dy=0, dz=0):\n        \n        # Get radius of rotation along 3 axes\n        rtheta, rphi, rgamma = get_rad(theta, phi, gamma)\n        \n        # Get ideal focal length on z axis\n        # NOTE: Change this section to other axis if needed\n        d = np.sqrt(self.height**2 + self.width**2)\n        self.focal = d \/ (2 * np.sin(rgamma) if np.sin(rgamma) != 0 else 1)\n        dz = self.focal\n\n        # Get projection matrix\n        mat = self.get_M(rtheta, rphi, rgamma, dx, dy, dz)\n        \n        return cv2.warpPerspective(self.image.copy(), mat, (self.width, self.height), borderMode = cv2.BORDER_CONSTANT, borderValue=(255,192,203))\n\n\n    \"\"\" Get Perspective Projection Matrix \"\"\"\n    def get_M(self, theta, phi, gamma, dx, dy, dz):\n        \n        w = self.width\n        h = self.height\n        f = self.focal\n\n        # Projection 2D -> 3D matrix\n        A1 = np.array([ [1, 0, -w\/2],\n                        [0, 1, -h\/2],\n                        [0, 0, 1],\n                        [0, 0, 1]])\n        \n        # Rotation matrices around the X, Y, and Z axis\n        RX = np.array([ [1, 0, 0, 0],\n                        [0, np.cos(theta), -np.sin(theta), 0],\n                        [0, np.sin(theta), np.cos(theta), 0],\n                        [0, 0, 0, 1]])\n        \n        RY = np.array([ [np.cos(phi), 0, -np.sin(phi), 0],\n                        [0, 1, 0, 0],\n                        [np.sin(phi), 0, np.cos(phi), 0],\n                        [0, 0, 0, 1]])\n        \n        RZ = np.array([ [np.cos(gamma), -np.sin(gamma), 0, 0],\n                        [np.sin(gamma), np.cos(gamma), 0, 0],\n                        [0, 0, 1, 0],\n                        [0, 0, 0, 1]])\n\n        # Composed rotation matrix with (RX, RY, RZ)\n        R = np.dot(np.dot(RX, RY), RZ)\n\n        # Translation matrix\n        T = np.array([  [1, 0, 0, dx],\n                        [0, 1, 0, dy],\n                        [0, 0, 1, dz],\n                        [0, 0, 0, 1]])\n\n        # Projection 3D -> 2D matrix\n        A2 = np.array([ [f, 0, w\/2, 0],\n                        [0, f, h\/2, 0],\n                        [0, 0, 1, 0]])\n\n        # Final transformation matrix\n        return np.dot(A2, np.dot(T, np.dot(R, A1)))\n\narabic_letters_normal = [\"\u0623\", \"\u0628\", \"\u062f\", \"\u0647\u0640\", \"\u0648\", \"\u0637\"]\narabic_letters_alph = {\n    \"\u0623\" : \"a\",\n    \"\u0628\" : \"b\",\n    \"\u062c\" : \"j\",\n    \"\u062f\" : \"d\",\n    \"\u0647\u0640\" : \"h\",\n    \"\u0648\" : \"w\",\n    \"\u0637\" : \"t\"\n}\narabic_state_owned = \"\u062c\"\n\nclass Template(Enum):\n    T1_520_110 = [1,\"typical\", [520, 110]]\n    T2_300_150 =  [2, \"typical\", [300, 150]]\n    M2_180_120 =  [2, \"typical\", [200, 120]]\n    TP_WW = [1,  \"temporary\", [520, 110]]\n    ST1_520_110 =  [1, \"state_owned\",[520, 110]]\n    ST2_300_150 = [2, \"state_owned\",[300, 150]]\n    CT1_520_110 =  [1, \"civil_protection\", [520, 110]]\n    CT2_300_150 =  [2,  \"civil_protection\", [300, 150]]\n    PT1_520_110 =  [1, \"police\",[520, 110]]\n    PT2_300_150 =  [2, \"police\",[520, 110]]\n\n    \n#Select the type of license plate [template1,template2,template3] == 3types of license plate \n\navailable_templates = [ Template.T1_520_110, Template.T2_300_150, Template.M2_180_120]# , Template.T1_520_110, Template.T2_300_150, Template.M2_180_120]\n\n\nres_up = 4\nspace_border_T1_520_110_range = [0.1, 0.2]\nspace_numeric_T1_520_110_range = [0.1, 0.2]\nspace_bar_T1_520_110_range = [0.1,0.2]\nnumeric_thickness_range = [12,16,20,24,28]\nbar_thickness_range = [0,4,8,12,16,20]\nspace_border_ratio_range = [0.01, 0.08]\ncolor_max_gray = 50\nmin_white_background = 75\nprobability_of_bars = 0.75\n\ndef get_image(template):\n    img_size = template.value[2]\n    x, y = img_size[1]*res_up,img_size[0]*res_up\n    img = np.zeros((x,y,3), dtype=np.uint8)\n    img.fill( 255- random.randint(0, min_white_background))\n\n    #for i in range(x):\n    #    for j in range(y):\n    #        img[i,j,0] = 255 - random.randint(0, min_white_background)\n    #        img[i,j,1] = 255 - random.randint(0, min_white_background)\n    #        img[i,j,2] = 255 - random.randint(0, min_white_background)\n \n    return img\n\narabic_font = ImageFont.truetype(fontpath, 256)\n\ndef draw_arabic(img, pos, color, letter):\n    img_pil = Image.fromarray(img)\n    draw = ImageDraw.Draw(img_pil)\n    draw.text((int(pos[0]), int(pos[1])),letter, font = arabic_font, fill=color )\n    return img_pil\n\n\n\ndef generate_plate(template):\n    background = get_image(template)\n\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    fontScale = 8\n    color_gray = random.randint(0, color_max_gray)\n    color = (color_gray,color_gray,color_gray)\n    numeric_thickness = numeric_thickness_range[random.randint(0, len(numeric_thickness_range) - 1)]\n    with_bars = random.random() < probability_of_bars\n    bar_thickness = bar_thickness_range[random.randint(0, len(bar_thickness_range) - 1)]\n    random_arabic_translate = random.randint(0,20)\n\n        \n    if template.value[1] == \"typical\":\n        a = random.randint(0, 99999)\n        b = random.randint(0, 89)\n        letter = arabic_letters_normal[random.randint(0, len(arabic_letters_normal) - 1)]\n        label = str(a) + arabic_letters_alph[letter] + str(b)\n\n        text_space = bool(random.getrandbits(1))\n        \n        wim, him = template.value[2]\n\n        if [wim, him] == [520, 110]:\n\n            wim = wim if with_bars else 420\n\n            him *= res_up\n            wim *= res_up\n\n            w, h = cv2.getTextSize(str(a) if text_space else \"00000\", font, fontScale,numeric_thickness)[0]\n            w2, h2 = cv2.getTextSize(str(b) if text_space else \"00\", font, fontScale,numeric_thickness)[0]\n        \n            space_border = int(random.uniform(space_border_ratio_range[0], space_border_ratio_range[1]) * wim)\n            \n            org = (space_border, int(him\/2 + h\/2))\n\n            image = cv2.putText(background, str(a) , org, font, fontScale, color, numeric_thickness, cv2.LINE_AA)\n\n            \n\n            second_text_x = wim - int(space_border + w2)\n            image = cv2.putText(image, str(b), (second_text_x, org[1]), font, fontScale, color, numeric_thickness, cv2.LINE_AA)\n\n            if with_bars:\n\n                space_bar = int(0.05 * wim)\n                first_bar_x = space_border + w + space_bar\n                image = cv2.putText(image, \"|\", (first_bar_x, org[1]), font, fontScale, color, bar_thickness, cv2.LINE_AA)\n                \n                second_bar_x = int(wim - (space_border + w2 + space_bar)) \n                width, height = arabic_font.getsize(letter)\n                letter_x = int((second_bar_x + first_bar_x) \/ 2 - (width \/ 2))\n                center_im = him\/2 - height\/2 - random_arabic_translate\n\n                image = cv2.putText(image, \"|\", (second_bar_x, org[1]), font, fontScale, color, bar_thickness, cv2.LINE_AA)\n\n                img = draw_arabic(image, (letter_x, center_im), color, letter)\n                img = np.array(img)\n            else:\n\n                arabic_x = int(((space_border + w) + (wim - space_border - w2))\/2)\n                width, height = arabic_font.getsize(letter)\n                letter_x = arabic_x - (width \/ 2)\n                center_im = him\/2 - height\/2 - random_arabic_translate\n\n                img = draw_arabic(image, (letter_x, center_im), color, letter)\n                \n                img = np.array(img)[0:him, 0:wim]\n        \n            random_crop_y = random.randint(0, 100)\n            img = img[random_crop_y:(him-random_crop_y), 0:wim]\n            img = np.array(img)\n        \n        elif [wim, him] == [300, 150] or [wim, him] == [200, 120]:\n            him *= res_up\n            wim *= res_up\n\n\n\n            w, h = cv2.getTextSize(str(a) if text_space else \"00000\", font, fontScale,numeric_thickness)[0]\n            w2, h2 = cv2.getTextSize(str(b) if text_space else \"00\", font, fontScale,numeric_thickness)[0]\n        \n            space_border = int(random.uniform(space_border_ratio_range[0], space_border_ratio_range[1]) * wim) \n            \n            img = cv2.putText(background, str(a), (int(wim\/2 -w\/2), int((3\/4) * him +  h\/2)), font, fontScale, color, numeric_thickness, cv2.LINE_AA)\n\n            img = cv2.putText(img, str(b), (wim - space_border- w2, int((1\/4) * him + h2\/2)), font, fontScale, color, numeric_thickness, cv2.LINE_AA)\n\n\n\n            if with_bars:\n                wb, hb = cv2.getTextSize('|', font, fontScale,numeric_thickness)[0]\n                img = cv2.putText(img, \"|\", (int(wim\/2 - wb \/2) , int((1\/4) * him + hb\/2 - 10) ), font, fontScale, color, bar_thickness, cv2.LINE_AA)\n                img = cv2.line(img, (space_border, int(him\/2)), (int(wim - space_border), int(him\/2)), color, bar_thickness + 1,cv2.LINE_AA)\n  \n\n            width, height = arabic_font.getsize(letter)\n            arabic_x =  space_border + random.randint(0,50)\n            img = draw_arabic(img, (arabic_x,  int((1\/4) * him - height\/2)), color, letter)\n            img = np.array(img)\n\n\n\n\n    return [img, label]\n\n# https:\/\/github.com\/eborboihuc\/rotate_3d\n\n#theta = height\nmin_theta = -10\nmax_theta = 25 \n#phi = left\/right\nmax_phi = 20\n#gamma plate rotation\nmax_gamma = 2\n\n\ndef rotate_random(img):\n    it = ImageTransformer(img, (500,200))\n    theta = random.uniform(min_theta, max_theta)\n    phi =random.uniform(-max_phi, max_phi)\n    gamma =random.uniform(-max_gamma, max_gamma) \n\n    return it.rotate_along_axis(theta=theta, phi=phi, gamma=gamma, dx=0, dy=0, dz=100)\n\n# https:\/\/github.com\/mastnk\/imagedegrade\n\ndegrade_prob = 0.6\ndegrade_seq_prob = 0.1\nprob_noise = 0.5\nprob_blur = 0.5\nprob_saltpepper = 0.5\nprob_jpegcom = 0.5\nblur_max = 25\nnoise_max = 30\njpegmin= 50\n\ndef degrade_image(img):\n    if random.random() < degrade_prob:\n        degradations = []\n        if random.random() < prob_blur:\n            degradations.append(\"blur\")\n        if random.random() < prob_noise:\n            degradations.append(\"noise\")\n        if random.random() < prob_saltpepper:\n            degradations.append(\"salt\")\n        if random.random() < prob_jpegcom:\n            degradations.append(\"jpeg\")\n        random.shuffle(degradations)\n        for deg in degradations:\n            if deg == \"blur\":\n                img = degrade.blur( img, random.randint(10, blur_max))\n            if deg == \"noise\":\n                img = degrade.noise(img , random.randint(10, noise_max) )\n            if deg == \"salt\":\n                img = degrade.saltpepper(img , random.random() \/ 2)\n            #if deg == \"jpeg\":\n            #    img = degrade.jpeg(img , random.randint(jpegmin, 95))\n    elif random.random() < degrade_seq_prob:\n        img = degrade.blur_noise_jpeg( img, random.randint(10, blur_max), random.randint(10, noise_max) , random.randint(jpegmin, 95), intensity_range = (0,1) )\n    return img\n\n# stretch image\n\nprob_stretch = 0.8\nmax_stretch_w = 0.01\nmax_stretch_h = 0.01\n\ndef stretch(img):\n    (h,w,c) = img.shape\n    if random.random() < prob_stretch:\n        if random.random() < prob_stretch:\n            h *= (1 - random.uniform(-max_stretch_h, max_stretch_h))\n        if random.random() < prob_stretch:\n            w *=  (1 - random.uniform(-max_stretch_w, max_stretch_w))\n        img = cv2.resize(img, (int(w), int(h)))\n    \n    return img\n\nprob_resize = 0.9\nresize_ratio_max = 4\n\ndef random_resize(img):\n    if random.random() < prob_resize:\n        (h,w,c) = img.shape\n        print(h, w)\n        ratio = random.randint(1,resize_ratio_max)\n        new_h, new_w = int(w \/ ratio), int(h \/ ratio)\n        img = cv2.resize(np.array(img).astype('uint8'), (new_h, new_w))\n\n    return img\n\nimport glob\n# add backgrounds\nbackgrounds = glob.glob(\".\/backgrounds\/*.jpg\")\nimport numpy as np\ndef add_to_random_background_image(img):\n    \n    if len(backgrounds)>0:\n        background_path= random.choice(backgrounds)\n        back = cv2.imread(background_path)\n        back = cv2.resize(back, (2500,1200))\n        (h,w,c) = img.shape\n        (h2,w2,c2) = back.shape\n        if w2 > w and h2 > h:\n            x0 = random.randint(0, h2 - h)\n            y0 = random.randint(0, w2 - w)\n            crop_img = back[x0:x0+h, y0:y0+w]\n\n            \n            #img.fill( 255- random.randint(0, min_white_background))\n\n            for x in range(h):\n                for y in range(w):\n                    pixel = img[x,y]\n                    if not (pixel[1] == 192 and pixel[2] == 203):\n                        crop_img[x][y][0] = pixel[0]\n                        crop_img[x][y][1] = pixel[1]\n                        crop_img[x][y][2] = pixel[2]\n                    #img[x,y] = crop_img[x,y] if img[x,y].all() == [255,192,203] else img[x,y]\n            #img = np.array(img)\n            #img = img[np.where((img==[255,192,203]).all(axis=2))] = [255,255,255]\n            #return cv2.bitwise_and(img, crop_img)\n            return crop_img\n\n    return img\n\ndef create_plate():\n    template = random.choice(available_templates)\n    img, label = generate_plate(template)\n    img = stretch(img)\n    img = degrade_image(img)\n    cv2.imwrite(\"temp.png\", img)\n    img = rotate_random(\"temp.png\")\n    img = random_resize(img)\n    img = add_to_random_background_image(img)\n    \n    return [img, label]\n\n#generat 100 images with 4 augmentations\n\nfor k in range(500):\n    img, label = create_plate()\n    cv2.imwrite(f\"augmented2\/{label}.jpg\", img)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    cv2.imwrite(f\"augmented2\/{label}$.jpg\", gray)\n    blur = cv2.GaussianBlur(gray,(7,7),0)\n    cv2.imwrite(f\"augmented2\/{label}$$.jpg\", blur)\n    binary = cv2.threshold(blur, 180, 255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n    cv2.imwrite(f\"augmented2\/{label}$$$.jpg\", binary)\n    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n    cv2.imwrite(f\"augmented2\/{label}$$$$.jpg\", thre_mor)\n    \n    \n\n\n\n\n\n","99a3c7a6":"# **Code For Generating Synthetic Morrocan license Plate**\n\nReferences : \n\nhttps:\/\/github.com\/eborboihuc\/rotate_3d \n\n\nhttps:\/\/github.com\/mastnk\/imagedegrade\n\n"}}