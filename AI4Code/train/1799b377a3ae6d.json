{"cell_type":{"ec88f6c7":"code","c407fc3b":"code","98f3bdc8":"code","cdd6be95":"code","00d80e75":"code","c1bbc394":"code","8c71c789":"code","40d6c56b":"code","b56199f9":"code","473dd239":"code","bfd3f742":"code","d1b60069":"code","53a90460":"code","47f40fd1":"code","617b2df6":"markdown","06b2a83d":"markdown","bbc71453":"markdown"},"source":{"ec88f6c7":"import tensorflow as tf\nimport pandas as pd\nfrom sklearn import preprocessing","c407fc3b":"anime = pd.read_csv('..\/input\/anime-recommendation-database-2020\/anime.csv')\nanimelist = pd.read_csv('..\/input\/anime-recommendation-database-2020\/animelist.csv')\nwatching_status = pd.read_csv('..\/input\/anime-recommendation-database-2020\/watching_status.csv')","98f3bdc8":"animelist_sample = animelist.sample(n=10000)\nanime_df = pd.merge(animelist_sample,anime,how='left',left_on='anime_id',right_on='MAL_ID')\nanime_df['watching_status'] = anime_df['watching_status'].replace(list(watching_status['status']),list(watching_status[' description']))","cdd6be95":"anime_df=anime_df[['user_id', 'anime_id', 'rating', 'watching_status', 'watched_episodes','Score', 'Genres', 'Type', 'Episodes', 'Premiered', 'Producers', 'Licensors',\n       'Studios', 'Source', 'Duration', 'Rating', 'Ranked', 'Popularity','Members', 'Favorites', 'Watching', 'Completed', 'On-Hold', 'Dropped','Plan to Watch']]\n#anime_df[['Score','Ranked']] = anime_df[['Score','Ranked']].apply(pd.to_numeric)\n\nanime_df['Score']=anime_df['Score'].replace('Unknown',0.0)\nanime_df['Ranked']=anime_df['Ranked'].replace('Unknown',0.0)\nanime_df[['Score','Ranked']] = anime_df[['Score','Ranked']].apply(pd.to_numeric)","00d80e75":"# continuous feature\ncon = ['watched_episodes','Score','Ranked','Popularity','Members', 'Favorites', 'Watching', 'Completed', 'On-Hold','Dropped','Plan to Watch']\ncat = ['user_id', 'anime_id','watching_status','Genres','Type','Episodes','Premiered','Producers', 'Licensors','Studios',\n      'Source','Duration','Rating',]","c1bbc394":"# preprocess continuous features\nanime_df[con]= preprocessing.StandardScaler().fit_transform(anime_df[con])","8c71c789":"# preprocess categorical features\nanime_df[cat]= preprocessing.OrdinalEncoder().fit_transform(anime_df[cat])","40d6c56b":"emb_counts = [len(anime_df[c].unique()) for c in cat]","b56199f9":"ds = tf.data.Dataset.zip((\n    tf.data.Dataset.from_tensor_slices((\n        tf.cast(anime_df[con].values, tf.float32),\n        tf.cast(anime_df[cat].values, tf.int32),\n    )),\n    tf.data.Dataset.from_tensor_slices((\n        tf.cast(anime_df['rating'].values, tf.int32)\n    ))\n)).shuffle(buffer_size=2048)\n\n\nds_test = ds.take(int(len(ds) * 0.2))\nds_train = ds.skip(len(ds_test))\nds_valid = ds_test.take(int(len(ds_test) * 0.5))\nds_test = ds_test.skip(len(ds_valid))","473dd239":"for features_batch, labels_batch in ds.take(1):\n    print(features_batch)\n    print(labels_batch)","bfd3f742":"def MLP(arch, activation='relu', out_activation=None):\n    mlp = tf.keras.Sequential()\n\n    for units in arch[:-1]:\n        mlp.add(tf.keras.layers.Dense(units, activation=activation))\n\n    mlp.add(tf.keras.layers.Dense(arch[-1], activation=out_activation))\n\n    return mlp\n\n\nclass SecondOrderFeatureInteraction(tf.keras.layers.Layer):\n    def __init__(self, self_interaction=False):\n        super(SecondOrderFeatureInteraction, self).__init__()\n        self.self_interaction = self_interaction\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs[0])[0]\n        concat_features = tf.stack(inputs, axis=1)\n\n        dot_products = tf.matmul(concat_features, concat_features, transpose_b=True)\n\n        ones = tf.ones_like(dot_products)\n        mask = tf.linalg.band_part(ones, 0, -1)\n        out_dim = int(len(inputs) * (len(inputs) + 1) \/ 2)\n\n        if not self.self_interaction:\n            mask = mask - tf.linalg.band_part(ones, 0, 0)\n            out_dim = int(len(inputs) * (len(inputs) - 1) \/ 2)\n\n        flat_interactions = tf.reshape(tf.boolean_mask(dot_products, mask), (batch_size, out_dim))\n        return flat_interactions\n\n\nclass DLRM(tf.keras.Model):\n    def __init__(\n            self,\n            embedding_sizes,\n            embedding_dim,\n            arch_bot,\n            arch_top,\n            self_interaction,\n    ):\n        super(DLRM, self).__init__()\n        self.emb = [tf.keras.layers.Embedding(size, embedding_dim) for size in embedding_sizes]\n        self.bot_nn = MLP(arch_bot, out_activation='relu')\n        self.top_nn = MLP(arch_top, out_activation='relu')\n        self.interaction_op = SecondOrderFeatureInteraction(self_interaction)\n\n    def call(self, input):\n        input_dense, input_cat = input\n        emb_x = [E(x) for E, x in zip(self.emb, tf.unstack(input_cat, axis=1))]\n        dense_x = self.bot_nn(input_dense)\n\n        Z = self.interaction_op(emb_x + [dense_x])\n        z = tf.concat([dense_x, Z], axis=1)\n        p = self.top_nn(z)\n\n        p = tf.clip_by_value(p, 0.0, 10.0)\n        return p","d1b60069":"model = DLRM(\n    embedding_sizes=emb_counts,\n    embedding_dim=4,\n    arch_bot=[8,4],\n    arch_top=[1],\n    self_interaction=False\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.MeanSquaredError(),\n    metrics=[\"mae\"]\n)","53a90460":"BATCH_SIZE = 64\n\nhistory =model.fit(\n    ds_train.batch(BATCH_SIZE),\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n    ],\n    epochs=10,\n    verbose=2\n)","47f40fd1":"results = model.evaluate(ds_test.batch(BATCH_SIZE))\nprint(f'Loss {results[0]}, Accuracy {results[1]}')","617b2df6":"**preprocessing**","06b2a83d":"**build and train the model**","bbc71453":"**Download the dataset**"}}