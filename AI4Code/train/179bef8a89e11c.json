{"cell_type":{"3e4e2013":"code","15dde07d":"code","70d4d8f2":"code","2b8e3960":"code","47e85108":"code","c3fd3e98":"code","04f6ac8b":"code","c7a03108":"code","fb80b912":"code","98e24f63":"code","4fd04b7c":"code","90ee5a8e":"code","e6274a77":"code","bb900313":"code","891ced97":"code","6422d9a8":"code","1d93b850":"code","43a55c55":"code","50c7bb31":"code","6a6a05e7":"code","8c0820d4":"code","924b321a":"markdown","f9f7b8a0":"markdown","26b41469":"markdown","8dd0fd36":"markdown","e19386a3":"markdown","47c5f113":"markdown","9e192c02":"markdown","03cdf343":"markdown","4a0d5b9e":"markdown","48b355b5":"markdown","96c94117":"markdown","3e540de3":"markdown","8f6b9b1e":"markdown"},"source":{"3e4e2013":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15dde07d":"!rm -rf waymo-od > \/dev\/null\n!git clone https:\/\/github.com\/waymo-research\/waymo-open-dataset.git waymo-od\n!cd waymo-od && git branch -a\n!cd waymo-od && git checkout remotes\/origin\/master\n# !pip3 install --upgrade pip","70d4d8f2":"!pip3 install waymo-open-dataset-tf-2-1-0==1.2.0","2b8e3960":"import os\nimport tensorflow.compat.v1 as tf\nimport math\nimport numpy as np\nimport itertools\n\ntf.enable_eager_execution()\n\nfrom waymo_open_dataset.utils import range_image_utils\nfrom waymo_open_dataset.utils import transform_utils\nfrom waymo_open_dataset.utils import  frame_utils\nfrom waymo_open_dataset import dataset_pb2 as open_dataset","47e85108":"!ls -lrt","c3fd3e98":"FILENAME = 'waymo-od\/tutorial\/frames'\ndataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\nfor data in dataset:\n    frame = open_dataset.Frame()\n    frame.ParseFromString(bytearray(data.numpy()))\n    break","04f6ac8b":"(range_images, camera_projections,range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(frame)\n","c7a03108":"print(frame.context)","fb80b912":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\ndef show_camera_image(camera_image, camera_labels, layout, cmap=None):\n  \"\"\"Show a camera image and the given camera labels.\"\"\"\n\n  ax = plt.subplot(*layout)\n\n  # Draw the camera labels.\n  for camera_labels in frame.camera_labels:\n    # Ignore camera labels that do not correspond to this camera.\n    if camera_labels.name != camera_image.name:\n      continue\n\n    # Iterate over the individual labels.\n    for label in camera_labels.labels:\n      # Draw the object bounding box.\n      ax.add_patch(patches.Rectangle(\n        xy=(label.box.center_x - 0.5 * label.box.length,\n            label.box.center_y - 0.5 * label.box.width),\n        width=label.box.length,\n        height=label.box.width,\n        linewidth=1,\n        edgecolor='red',\n        facecolor='none'))\n\n  # Show the camera image.\n  plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n  plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n  plt.grid(False)\n  plt.axis('off')\n\nplt.figure(figsize=(25, 20))\n\nfor index, image in enumerate(frame.images):\n  show_camera_image(image, frame.camera_labels, [3, 3, index+1])","98e24f63":"plt.figure(figsize=(64, 20))\ndef plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n  \"\"\"Plots range image.\n\n  Args:\n    data: range image data\n    name: the image title\n    layout: plt layout\n    vmin: minimum value of the passed data\n    vmax: maximum value of the passed data\n    cmap: color map\n  \"\"\"\n  plt.subplot(*layout)\n  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n  plt.title(name)\n  plt.grid(False)\n  plt.axis('off')\n\ndef get_range_image(laser_name, return_index):\n  \"\"\"Returns range image given a laser name and its return index.\"\"\"\n  return range_images[laser_name][return_index]\n\ndef show_range_image(range_image, layout_index_start = 1):\n  \"\"\"Shows range image.\n\n  Args:\n    range_image: the range image data from a given lidar of type MatrixFloat.\n    layout_index_start: layout offset\n  \"\"\"\n  range_image_tensor = tf.convert_to_tensor(range_image.data)\n  range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)\n  lidar_image_mask = tf.greater_equal(range_image_tensor, 0)\n  range_image_tensor = tf.where(lidar_image_mask, range_image_tensor,\n                                tf.ones_like(range_image_tensor) * 1e10)\n  range_image_range = range_image_tensor[...,0] \n  range_image_intensity = range_image_tensor[...,1]\n  range_image_elongation = range_image_tensor[...,2]\n  plot_range_image_helper(range_image_range.numpy(), 'range',\n                   [8, 1, layout_index_start], vmax=75, cmap='gray')\n  plot_range_image_helper(range_image_intensity.numpy(), 'intensity',\n                   [8, 1, layout_index_start + 1], vmax=1.5, cmap='gray')\n  plot_range_image_helper(range_image_elongation.numpy(), 'elongation',\n                   [8, 1, layout_index_start + 2], vmax=1.5, cmap='gray')\nframe.lasers.sort(key=lambda laser: laser.name)\nshow_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)\nshow_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)","4fd04b7c":"points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n    frame,\n    range_images,\n    camera_projections,\n    range_image_top_pose)\npoints_ri2, cp_points_ri2 = frame_utils.convert_range_image_to_point_cloud(\n    frame,\n    range_images,\n    camera_projections,\n    range_image_top_pose,\n    ri_index=1)\n\n# 3d points in vehicle frame.\npoints_all = np.concatenate(points, axis=0)\npoints_all_ri2 = np.concatenate(points_ri2, axis=0)\n# camera projection corresponding to each point.\ncp_points_all = np.concatenate(cp_points, axis=0)\ncp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)","90ee5a8e":"print(points_all.shape)\nprint(cp_points_all.shape)\nprint(points_all[0:2])\nfor i in range(5):\n  print(points[i].shape)\n  print(cp_points[i].shape)","e6274a77":"print(points_all_ri2.shape)\nprint(cp_points_all_ri2.shape)\nprint(points_all_ri2[0:2])\nfor i in range(5):\n  print(points_ri2[i].shape)\n  print(cp_points_ri2[i].shape)","bb900313":"from IPython.display import Image, display\ndisplay(Image('waymo-od\/tutorial\/3d_point_cloud.png'))","891ced97":"images = sorted(frame.images, key=lambda i:i.name)\ncp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)\ncp_points_all_concat_tensor = tf.constant(cp_points_all_concat)\n\n# The distance between lidar points and vehicle frame origin.\npoints_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)\ncp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)\n\nmask = tf.equal(cp_points_all_tensor[..., 0], images[0].name)\n\ncp_points_all_tensor = tf.cast(tf.gather_nd(\n    cp_points_all_tensor, tf.where(mask)), dtype=tf.float32)\npoints_all_tensor = tf.gather_nd(points_all_tensor, tf.where(mask))\n\nprojected_points_all_from_raw_data = tf.concat(\n    [cp_points_all_tensor[..., 1:3], points_all_tensor], axis=-1).numpy()","6422d9a8":"def rgba(r):\n  \"\"\"Generates a color based on range.\n\n  Args:\n    r: the range value of a given point.\n  Returns:\n    The color for a given range\n  \"\"\"\n  c = plt.get_cmap('jet')((r % 20.0) \/ 20.0)\n  c = list(c)\n  c[-1] = 0.5  # alpha\n  return c\n\ndef plot_image(camera_image):\n  \"\"\"Plot a cmaera image.\"\"\"\n  plt.figure(figsize=(20, 12))\n  plt.imshow(tf.image.decode_jpeg(camera_image.image))\n  plt.grid(\"off\")\n\ndef plot_points_on_image(projected_points, camera_image, rgba_func,\n                         point_size=5.0):\n  \"\"\"Plots points on a camera image.\n\n  Args:\n    projected_points: [N, 3] numpy array. The inner dims are\n      [camera_x, camera_y, range].\n    camera_image: jpeg encoded camera image.\n    rgba_func: a function that generates a color from a range value.\n    point_size: the point size.\n\n  \"\"\"\n  plot_image(camera_image)\n\n  xs = []\n  ys = []\n  colors = []\n\n  for point in projected_points:\n    xs.append(point[0])  # width, col\n    ys.append(point[1])  # height, row\n    colors.append(rgba_func(point[2]))\n\n  plt.scatter(xs, ys, c=colors, s=point_size, edgecolors=\"none\")","1d93b850":"plot_points_on_image(projected_points_all_from_raw_data,\n                     images[0], rgba, point_size=5.0)","43a55c55":"!sudo apt install build-essential\n!sudo apt-get install --assume-yes pkg-config zip g++ zlib1g-dev unzip python3 python3-pip\n!wget https:\/\/github.com\/bazelbuild\/bazel\/releases\/download\/0.28.0\/bazel-0.28.0-installer-linux-x86_64.sh\n!sudo bash .\/bazel-0.28.0-installer-linux-x86_64.sh","50c7bb31":"!cd waymo-od && .\/configure.sh && cat .bazelrc && bazel clean","6a6a05e7":"!cd waymo-od && bazel build ... --show_progress_rate_limit=10.0","8c0820d4":"!cd waymo-od && bazel-bin\/waymo_open_dataset\/metrics\/tools\/compute_detection_metrics_main waymo_open_dataset\/metrics\/tools\/fake_predictions.bin  waymo_open_dataset\/metrics\/tools\/fake_ground_truths.bin","924b321a":"# Build and Test","f9f7b8a0":"# Visualize Camera Images and Camera Labels","26b41469":"# Visualize Range Images","8dd0fd36":"Second rerun","e19386a3":"# Read One Frame\nEach file in the dataset is a sequence of frames ordered by frame start timestamps. We have extracted two frames from the dataset to demonstrate the dataset format.","47c5f113":"# Command line detection metrics computation","9e192c02":"# Show point Cloud\n\n3D point clouds are rendered using an internal tool, which is unfortunately not publicly available yet. Here is an example of what they look like.","03cdf343":"# Examine number of points in each lidar sensor.","4a0d5b9e":"# Install waymo_open_dataset package","48b355b5":"# Point Cloud Conversation and Visualization","96c94117":"# Examine frame context","3e540de3":"# Visualize Camera Position","8f6b9b1e":"# Install from source code\n## Install dependencies"}}