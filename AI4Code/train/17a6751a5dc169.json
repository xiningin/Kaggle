{"cell_type":{"ef1eca16":"code","b772de92":"code","0af3083a":"code","64d8e830":"code","0d9411df":"code","019dbade":"code","5a60b863":"code","49068b63":"code","842fa75d":"code","6ad99340":"code","fbe4cf96":"code","e4f21ad7":"code","2236e780":"code","55f7d005":"code","8b8463d9":"code","20f3afd6":"code","71c72a5b":"code","ce150382":"code","1df3619e":"code","edb2fcda":"code","f6ee8914":"code","ab14e488":"code","5488eb62":"code","7731e4f1":"code","2aeffe4b":"code","3e42e330":"code","a19016b5":"code","895ce070":"code","05ec2ebb":"code","3c88381f":"code","b76dccd7":"code","27bd9a8b":"code","66a9c8dc":"code","1d109c8c":"code","cf2ab61f":"markdown","b26a5a8f":"markdown","fcf6bc6a":"markdown","4efc0660":"markdown","1a0591f2":"markdown","3bf7e81a":"markdown","f566658b":"markdown","f8fd0f87":"markdown","1b7e4f1b":"markdown","e29deeab":"markdown","04e2e5f0":"markdown","778df0c9":"markdown","37196226":"markdown","d25587a9":"markdown","5a4d14c6":"markdown","4c9f8cd7":"markdown","158f2e93":"markdown","b1adda71":"markdown","17fd7b58":"markdown","ade5785c":"markdown","5481c1d8":"markdown","159ef21e":"markdown","47b3f9d2":"markdown","e9a54222":"markdown","682d070c":"markdown","bc7d158e":"markdown","487c6284":"markdown","01291f55":"markdown","d8b6e59c":"markdown","630c89d3":"markdown"},"source":{"ef1eca16":"!pip install '..\/input\/timm034\/timm-0.4.12-py3-none-any.whl' -qq","b772de92":"!cp -r ..\/input\/fmipackage\/fmi-master\/* .\/","0af3083a":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning) ","64d8e830":"import sys\nfrom fastai.vision.all import *\nimport timm\nfrom timm import create_model\nfrom fmi.explore import *\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","0d9411df":"pd.options.mode.chained_assignment = None","019dbade":"system_info()","5a60b863":"source = Path('..\/input\/petfinder-pawpularity-score')\ntrain_csv = pd.read_csv(f'{source}\/train.csv')\ntrain_csv","49068b63":"meta = train_csv[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group',\n       'Collage', 'Human', 'Occlusion', 'Info', 'Blur']]\n\nmeta['multi'] = meta.apply(lambda x: x.index[x == 1].tolist(), axis=1)\nmeta['multi'] = meta['multi'].astype('string')\n\nspec_chars = [\"[\", \"]\", \"'\", \",\", \";\"]\n\nfor char in spec_chars:\n    meta['multi'] = meta['multi'].str.replace(char, '')","842fa75d":"meta_class = meta[['multi']]\n\ntrain_csv['Id'] = train_csv['Id'].map(lambda x:str(source\/'train'\/x)+'.jpg')\n\npath_df = train_csv[['Id']]\n\ndf = pd.concat([path_df, meta_class], axis=1)\ndf","6ad99340":"item_tfms = [Resize(224, method=ResizeMethod.Crop),\n             Resize(224, method=ResizeMethod.Squish),\n             Resize(224, method=ResizeMethod.Pad),\n             RandomCrop(224)]\nbatch_tfms = [RandomResizedCrop(196), *aug_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)]","fbe4cf96":"for item in item_tfms:\n    set_seed(7)\n    paws = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   get_x=ColReader(0),\n                   splitter=RandomSplitter(),\n                   get_y=ColReader(1, label_delim=' '),\n                   item_tfms = item,\n                   batch_tfms = batch_tfms)\n    \n    val = str(item); val_split = val.split(' ')\n    title = (val_split[0], val_split[5], val_split[6])    \n    print(title)\n    dls = paws.dataloaders(df, bs=8)\n    dls.show_batch(max_n=8, nrows=1)","e4f21ad7":"paws = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   get_x=ColReader(0),\n                   splitter=RandomSplitter(),\n                   get_y=ColReader(1, label_delim=' '),\n                   item_tfms = Resize(224, method=ResizeMethod.Squish),\n                   #batch_tfms = [RandomResizedCrop(196), *aug_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)])\n                   batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()]))\n\ndls = paws.dataloaders(df, bs=32)\ndls.show_batch(max_n=7, nrows=1)","2236e780":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n#!cp '..\/input\/timm034\/efficientnetv2_rw_m_agc-3d90cb1e.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/efficientnetv2_rw_m_agc-3d90cb1e.pth'\n!cp '..\/input\/timm034\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'","55f7d005":"def create_timm_body(arch:str, pretrained=True, cut=None):\n    model = create_model(arch, pretrained=pretrained)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n    elif callable(cut): return cut(model)\n    else: raise NamedError(\"cut must be either integer or function\")","8b8463d9":"#body = create_timm_body('efficientnetv2_rw_m', pretrained=True)\n#nf = num_features_model(body); nf\n#head = create_head(nf, dls.c, concat_pool=True, first_bn=True, bn_final=True)\n#model = nn.Sequential(body, head)\nmodel = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=dls.c)","20f3afd6":"#model[1]","71c72a5b":"learn = Learner(dls, \n                model, \n                metrics=[accuracy_multi],\n                cbs = [ShowGraphCallback,\\\n                       SaveModelCallback(monitor='accuracy_multi',fname='best_acc',comp=np.greater, with_opt=True)]).to_fp16()","ce150382":"print(learn.loss_func, learn.opt_func)","1df3619e":"from fastai.metrics import rmse","edb2fcda":"learn = Learner(dls, \n                model, \n                #opt_func = ranger,\n                metrics=[accuracy_multi, rmse],\n                cbs = [ShowGraphCallback,\\\n                       SaveModelCallback(monitor='accuracy_multi',fname='best_acc',comp=np.greater, with_opt=True)],\n                 wd = 4e-3,\n                 wd_bn_bias=False).to_fp16()","f6ee8914":"learn.fine_tune(17, 1e-3)","ab14e488":"X = train_csv[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity']]\ny = X.pop('Pawpularity')\nX","5488eb62":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n\nss = StandardScaler()\nx_train_scaled = ss.fit_transform(x_train)\nx_test_scaled = ss.transform(x_test)","7731e4f1":"model = LogisticRegression()\nmodel.fit(x_train_scaled, y_train)\nattribute_importance = pd.DataFrame(data={\n    'Attribute': x_train.columns,\n    'Importance': model.coef_[0]*100\n})\nattribute_importance = attribute_importance.sort_values(by='Importance', ascending=False)\n\nplt.figure(figsize=(10,5))\nax = sns.barplot(x=attribute_importance['Attribute'], y=attribute_importance['Importance'], palette='rainbow_r')\nplt.xlabel('Attribute', fontsize='x-large')\nplt.ylabel('Importance', fontsize='x-large')\nplt.yticks(fontweight='light', fontsize='x-large')\nplt.xticks(rotation=45, fontweight='light', fontsize='x-large');","2aeffe4b":"attribute_importance","3e42e330":"test_imgs_path = f'{source}\/test'\ntest_fns = get_image_files(test_imgs_path)","a19016b5":"learn.load('best_acc')","895ce070":"learn.predict(test_fns[0])","05ec2ebb":"dls.valid_ds[2][0]","3c88381f":"dls.valid_ds[2][1]","b76dccd7":"learn.predict(dls.valid_ds[2][0])","27bd9a8b":"pred_list = []\nfor file in test_fns:\n    p = learn.predict(file)\n    pos_vals = int(sum(p[1]))\n    if pos_vals == 0:\n        pos_vals = 1\n    else:\n        pos_vals = pos_vals\n           \n    if 'Subject Focus' in p[0]: val = 5.4\n    else: val = 0\n    if 'Eyes' in p[0]: val1 = -17\n    else: val1 = 0\n    if 'Face' in p[0]: val2 = 8.7\n    else: val2 = 0\n    if 'Near' in p[0]: val3 = 10.1\n    else: val3 = 0\n    if 'Action' in p[0]: val4 = 8.5\n    else: val4 = 0\n    if 'Accessory' in p[0]: val5 = -21\n    else: val5 = 0\n    if 'Group' in p[0]: val6 = 14.9\n    else: val6 = 0\n    if 'Collage' in p[0]: val7 = -4.9\n    else: val7 = 0\n    if 'Human' in p[0]: val8 = 8.6\n    else: val8 = 0\n    if 'Occlusion' in p[0]: val9 = -5.3\n    else: val9 = 0\n    if 'Info' in p[0]: val10 = 4\n    else: val10 = 0\n    if 'Blur' in p[0]: val11 = -7.7\n    else: val11 = 0\n        \n    final_one = val + val1 + val2 + val3 + val4 + val5 + val6 + val7 + val8 + val9 + val10 + val11    \n    print(final_one)\n    \n    if final_one < 0:\n        final_one = 0\n    else: final_one = final_one\n    \n    final = float(final_one\/pos_vals)\n    print(final)\n    pred_list.append(final)","66a9c8dc":"test_data = pd.DataFrame()\ntest_data['Id'] = [img[:-4]for img in os.listdir(test_imgs_path)]\n\ntest_data['Pawpularity'] = pred_list\ntest_data","1d109c8c":"test_data.to_csv('submission.csv' , index=False)","cf2ab61f":"This notebook specifically uses the Photo Metadata (and not the Pawpularity score) with the aim of building a supplementary model as stated in the competition Data Description.\n\n- **'You may use these labels as you see fit, and optionally build an intermediate \/ supplementary model to predict the labels from the photos. If your supplementary model is good, we may integrate it into our AI tools as well.**\n\n- **In our production system, new photos that are dynamically scored will not contain any photo labels. If the Pawpularity prediction model requires photo label scores, we will use an intermediary model to derive such parameters, before feeding them to the final model.'**\n\nSo this will be treated as a 'multi-label' classification problem where each test image will be used to predict the labels and then from the labels predict the **pawpularity** score.\n\n![image.png](attachment:6f7298fc-6cd3-4a46-ba55-8bc6d36e4367.png)","b26a5a8f":"- Load Dependancies\n- Load & Extract\/Clean Data\n- DataBlock\n- Training\n- Determine how to score the predicted labels\n- Submission","fcf6bc6a":"When creating the **Learner** if the loss function and optimization function are not specified **fastai** will try to use the most appropriate functions","4efc0660":"Suppress pandas **SettingWithCopyWarning** which potential indicates issues with chained assignments","1a0591f2":"**fastai** allows for alot of customization. The concept of **presizing** is explained in detail [here](https:\/\/github.com\/fastai\/fastbook\/blob\/master\/05_pet_breeds.ipynb)\n\nBy default **fastai** uses the **Crop** method when resizing images but depending on the dataset that might not always be the best method to use.  We can compare the default (Crop) with Squish and Pad to see how they look within a batch.","3bf7e81a":"Now to get the predictions","f566658b":"Disable any **FutureWarning**s","f8fd0f87":"### Submission","1b7e4f1b":"Create the updated training database","e29deeab":"Note on using **create_head**:\n- by default it uses the pooling trick(**concat_pool = True**) where both adaptative average pooling and adaptive max pooling are used, switching this to **False** results in only adaptive average pooling being used.\n- **first_bn** is also by default set to **True** - this creates a **BatchNorm** layer after Pooling + Flatten\n- **bn_final** is also by default set to **True** - this creates a **BatchNorm** layer after Dropout + Linear\n\nThe **fastai** tutorials and various posts have mentioned how these all improve training","04e2e5f0":"You can view them like so:","778df0c9":"We will use the above values to get the **Pawpularity** predictions","37196226":"The predictions will all be 0 because we do not have access to the images but we can see that the prediction is a 13 long vector.\n\nWe can test this by using one of the images from the validation dataset","d25587a9":"### Determine how to score the predicted labels","5a4d14c6":"Load the pre-trained weights from **timm**","4c9f8cd7":"As this is a classification problem we use Logistic Regression","158f2e93":"Extract the metadata and get rid of any special characters","b1adda71":"This notebook uses **[fastai](https:\/\/github.com\/fastai)** and **[timm](https:\/\/github.com\/rwightman\/pytorch-image-models\/tree\/master\/timm)**","17fd7b58":"Scale the inputs","ade5785c":"We can see differences between the various methods and in this case using **Squish** displays the best results","5481c1d8":"So in this case by default the loss function chosen is BCEWithLogitsLoss and the optimization function is Adam. In this case we will choose a different optimization function.\n\nBy default:\n\n- **weight decay** is not added by default\n- **weight decay** if specified is only applied to the BatchNorm layers and not the bias\n- the **BatchNorm** layers are trained even when they are supposed to be frozen.\n\nIn this case we add weight decay(a L2 regularization technique and use Leslie 's value of wd=4e-3) and apply it to both the BatchNorm layers and the bias","159ef21e":"## Contents","47b3f9d2":"And creating the submission file","e9a54222":"### Load Dependancies","682d070c":"### Create DataBlock","bc7d158e":"Compare how **Crop**, **Squish** and **Pad** resized images look within a batch and **set_seed** as a means of reproducibility","487c6284":"In this experiment we will obtain importances from coefficients.  In this simple logic case we examine feature importances by examining the model\u2019s coefficients. If the assigned coefficient is a large positive or negative number it has a positive or negative influence on the prediction.  And if the coefficient is zero, it does not have an impact on the prediction.","01291f55":"### Training","d8b6e59c":"### Load & Extract\/Clean Data","630c89d3":"Check the loaded versions"}}