{"cell_type":{"c93b190e":"code","504977f7":"code","1e8579b1":"code","bf34a181":"code","3bc5af7d":"code","bb22ff7f":"code","219e51b6":"code","fd426a34":"code","0959f60c":"code","629ac268":"code","a8e6f900":"code","bbdb029d":"code","d2c873a3":"code","64c566ef":"code","8832ac23":"code","41a1509c":"code","75688a13":"code","28ae36d1":"code","ef9f9aef":"code","069a1d89":"code","ff4ac232":"code","850b91ba":"code","67bbb2e0":"code","98a9da1a":"code","1c4b888f":"code","79479797":"code","9aa00a88":"code","4fbd4cbc":"code","0aafeb90":"code","4d823741":"markdown","8f6e3ea4":"markdown","ed66264c":"markdown","c2fd4cb4":"markdown","1a6d26bb":"markdown"},"source":{"c93b190e":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport os\nimport pathlib\n\nimport PIL\nimport glob\n\nimport tensorflow as tf","504977f7":"base_dir = '..\/input\/fruits\/fruits-360'\ntrain_dir = os.path.join(base_dir, 'Training\/')","1e8579b1":"train_dir ","bf34a181":"tarin_dir_pathlib = pathlib.Path(\"..\/input\/fruits\/fruits-360\/Training\/\")\ntarin_dir_pathlib","3bc5af7d":"# Total COunt of Images in Training set\nlen(list(tarin_dir_pathlib.glob(\"*\/*.jpg\")))","bb22ff7f":"fruits = list(tarin_dir_pathlib.glob(\"Apple Red Delicious\/*.jpg\"))\nfruits[:2]","219e51b6":"plt.figure(figsize = (10,10))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img = PIL.Image.open(str(fruits[i]))\n    plt.imshow(img)\n    plt.axis('off')\n    \nplt.show()","fd426a34":"batch_size = 32\nimg_height = 100\nimg_width = 100","0959f60c":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    tarin_dir_pathlib,\n    validation_split = 0.2,\n    subset = 'training',\n    seed = 99,\n    image_size = (img_height, img_width),\n    batch_size = batch_size\n)","629ac268":"validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    tarin_dir_pathlib,\n    validation_split = 0.2,\n    subset = 'validation',\n    seed = 99,\n    image_size = (img_height, img_width),\n    batch_size = batch_size\n)","a8e6f900":"class_names = train_ds.class_names\nnum_class = len(class_names)","bbdb029d":"class_names","d2c873a3":"num_class","64c566ef":"for images, labels in train_ds.take(1):\n    plt.figure(figsize = (10,10))\n    for i in range(9):\n        plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy().astype('uint8'))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")\nplt.show()        ","8832ac23":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\nvalidation_ds = validation_ds.cache().prefetch(buffer_size = AUTOTUNE)","41a1509c":"data_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n    ]\n)","75688a13":"preprocess_input = tf.keras.applications.resnet.preprocess_input","28ae36d1":"base_model = tf.keras.applications.resnet.ResNet50(\n    input_shape = (img_height, img_width, 3),\n    include_top = False,\n    weights = 'imagenet'\n)","ef9f9aef":"base_model.trainable = False","069a1d89":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nprediction_layer = tf.keras.layers.Dense(num_class)","ff4ac232":"inputs = tf.keras.Input(shape = (100,100,3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training = False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\n\nmodel = tf.keras.Model(inputs = inputs, outputs = outputs)","850b91ba":"optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)","67bbb2e0":"model.compile(\n    optimizer = optimizer,\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n    metrics = ['accuracy']\n)","98a9da1a":"model.summary()","1c4b888f":"model.evaluate(validation_ds)","79479797":"epochs = 10\nhistory = model.fit(\n    train_ds,\n    epochs = epochs,\n    validation_data = validation_ds\n)","9aa00a88":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize = (12,10))\n\nplt.plot(epochs_range, train_loss, label = 'Training Loss')\nplt.plot(epochs_range, val_loss, label = 'Validation Loss')\n\nplt.legend(loc = 'upper left')\nplt.title('Training and Validation Loss')\n\nplt.show()\n","4fbd4cbc":"np.argmin(val_loss)","0aafeb90":"model.save(\"tf_resnet_model_v1.h5\") #using h5 extension\nprint(\"model saved!!!\")","4d823741":"# train the Model","8f6e3ea4":"# Building the Model","ed66264c":"# Pre-Processing","c2fd4cb4":"# Fruits Classification\n\nhttps:\/\/www.kaggle.com\/moltean\/fruits\n","1a6d26bb":"# Visualization"}}