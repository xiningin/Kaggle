{"cell_type":{"f7ae0fbf":"code","255e7069":"code","870b4868":"code","6a141d0e":"code","5910d66f":"code","151fcf2e":"code","ac370249":"code","e956949b":"code","28215548":"code","f9d860cb":"code","e2c90b44":"code","0335a5cc":"code","8ade40a6":"code","6d8bf609":"code","e955f837":"code","4a8d4540":"code","c354a983":"code","5daff1f1":"code","98dd0a59":"code","e66f2bcc":"code","b0e1d788":"code","68fb89aa":"code","eb82f49f":"code","4e359d62":"code","9678aca8":"markdown","8e501cf0":"markdown","c80588b6":"markdown","e411d681":"markdown","ce112dd6":"markdown","f6c9b9c3":"markdown","5faaac56":"markdown"},"source":{"f7ae0fbf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nltk\nimport seaborn as sns\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split, cross_val_score","255e7069":"df = pd.read_csv('\/kaggle\/input\/us-state-of-the-union-addresses-1790-2019\/state_ofthe_union_texts.csv')","870b4868":"df.head()","6a141d0e":"df.info()","5910d66f":"df.describe()","151fcf2e":"len(df['President'].unique())","ac370249":"df['President'].unique()","e956949b":"df['Text Length'] = df['Text'].apply(len)\ndf['Word Count'] = df['Text'].apply (lambda t: len(nltk.tokenize.wordpunct_tokenize(t)))","28215548":"df.head()","f9d860cb":"sns.distplot(df['Text Length'], bins=10)\nplt.title(\"Speeches's Text Length Frequency Distribution\")","e2c90b44":"pd.cut(df['Text Length'], bins=10).value_counts()","0335a5cc":"sns.distplot(df['Word Count'], bins=10)\nplt.title(\"Speeches's Word Count Frequency Distribution\")","8ade40a6":"pd.cut (df['Word Count'], bins=10).value_counts()","6d8bf609":"sns.distplot(df['Year'], bins=10)\nplt.title(\"Speeches's Year Frequency Distribution\")","e955f837":"pd.cut (df['Year'], bins=10).value_counts()","4a8d4540":"plt.figure(figsize=(15,10))\nax = sns.boxplot(x='President', y='Text Length', data=df, palette='inferno')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nplt.title('Text Length Plot by President')","c354a983":"g = sns.factorplot('President', data=df, kind='count', aspect=3, palette='inferno')\ng.set_xticklabels(rotation=90)\nplt.title('Number of Speeches by President')","5daff1f1":"df = df[(df['President'] != 'Zachary Taylor') & (df['President'] != 'Warren G. Harding') & (df['President'] != 'Ronald Reagan')]","98dd0a59":"pipeline = Pipeline([\n    ('cv', CountVectorizer(stop_words='english', strip_accents='ascii')),\n    ('lsvm', SGDClassifier(loss='hinge', verbose=0, penalty='l1'))\n])","e66f2bcc":"data_train= []\nfor p in df['President'].unique():\n    text1 = df[df['President'] == p].sample(1)['Text'].values[0]\n    data_train.append([p, text1])\n    text2 = ''\n    while True:\n        text2 = df[df['President'] == p].sample(1)['Text'].values[0]\n        if text2 != text1:\n            break\n    data_train.append([p, text2])\ndf_train= pd.DataFrame(data_train, columns=['President', 'Text'])","b0e1d788":"%time pipeline.fit(df_train['Text'], df_train['President'])","68fb89aa":"%time preds = pipeline.predict(df['Text'])","eb82f49f":"confusion_matrix(df['President'], preds)","4e359d62":"print (classification_report(df['President'], preds))","9678aca8":"## Model creation\n\nIn this step, it was tried with CountVectorizer and TfidfVectorizer. Besides that, these vectorizer was tested with and without stemmer. For machine learning model, it was tested with naive bayes, random forests, adaboost, and linear SVM.\n\nThe chosen model uses the CountVectorizer without stemming, and dropping stopwords and accents, and using linear SVM with penalty l1.","8e501cf0":"### Drop the labels that have less than 2 speeches","c80588b6":"In the begining, the classification report had some zero precision labels. With the random selection of speeches to generate the train set, there's no more zero precision labels.","e411d681":"Here I will create a train dataset with 2 different randomly selected speeches for each label. This is necessary because the train_test_split function create train dataset that doesn't have some label samples, reducing the prediction performance.","ce112dd6":"# Classifying U.S. Presidents Speeches\nThe goal of this notebook is to evaluate a ML model that predicts which U.S. president read the speech.","f6c9b9c3":"## Data load and exploratory data analysis","5faaac56":"### Calculating text length and word count\nMaybe has some interesting information"}}