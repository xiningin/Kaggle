{"cell_type":{"a5aae733":"code","a252c3e0":"code","eb0f8eac":"code","ad458cea":"code","a2374e38":"code","7797fa8a":"code","e08d711f":"code","38330df5":"code","b985299f":"code","541d7929":"code","1825fe3a":"code","b96d304d":"code","7cf1dc4b":"code","24b68760":"code","4b8f39f2":"code","5404c3e7":"code","50df0593":"code","0c2c3fde":"code","3c24e370":"code","955599b3":"code","f81f1f0c":"code","d779b858":"code","d24cb5eb":"code","9d81ca20":"code","0d0e5870":"code","3318b6aa":"code","e62d0ce0":"code","82923be8":"code","c7b204d1":"code","f032c9cb":"code","9a41629c":"code","014c8b1f":"code","9ce1bdd5":"code","3ab54a32":"code","806976da":"code","883c2bba":"code","c4425b85":"code","b1afa41f":"code","2a22a178":"code","670574d8":"code","f4410636":"code","481f46a7":"code","6aabed1c":"code","b2ad2ca8":"markdown","40664bdb":"markdown","54a637c8":"markdown","9e06b2a7":"markdown","489f57e7":"markdown","b49f9441":"markdown","719f34af":"markdown"},"source":{"a5aae733":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm\n\nclass_names = ['unknown', 'widhi']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\nnb_classes = len(class_names)\nIMAGE_SIZE = (150, 150)","a252c3e0":"pip install mtcnn","eb0f8eac":"pip install opencv-python","ad458cea":"def load_data():\n\n    datasets = ['..\/input\/wajahtes\/train',\n                '..\/input\/wajahtes\/train']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","a2374e38":"(train_images, train_labels), (test_images, test_labels) = load_data()","7797fa8a":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)\ntrain_images.shape, train_labels.shape","e08d711f":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(train_images, train_labels,test_size=0.2)\n\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","38330df5":"n_train = x_train.shape[0]\nn_test = x_test.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","b985299f":"import pandas as pd\n\n_, train_counts = np.unique(y_train, return_counts=True)\n_, test_counts = np.unique(y_test, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'test': test_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()\n","541d7929":"plt.pie(train_counts,\n        explode=(0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","1825fe3a":"'''\n\nx_train = train_images \/ 255.0 \nx_test_images = test_images \/ 255.0\nx_train.shape,x_test_images.shape\n'''\nx_train = x_train \/ 255.0 \nx_test = x_test \/ 255.0\nx_train.shape,x_test.shape\n","b96d304d":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","7cf1dc4b":"display_random_image(class_names, x_train, y_train)","24b68760":"def display_examples(class_names, images, labels):\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","4b8f39f2":"display_examples(class_names, x_train, y_train)","5404c3e7":"import tensorflow as tf\nimport keras\n\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Conv2D ,LSTM, MaxPooling2D , Flatten , Dropout \nfrom keras.layers import BatchNormalization,TimeDistributed\n\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (15,5)\nimport seaborn as sns\nimport pandas as pd\nimport os\nimport random\nimport time\nimport os\n\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom scipy import signal\nfrom scipy.fft import fftshift\n","50df0593":"def cnn_model():    \n\n    model = Sequential()\n    \n    model.add(Conv2D(filters = 64, kernel_size = (8,8), \n                     padding = \"same\", activation = \"relu\", \n                     input_shape=(150,150,3)))\n    model.add(MaxPooling2D(pool_size = (4,4)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    \n    model.add(Conv2D(filters = 64, kernel_size = (4,4), \n                     padding = \"same\", activation = \"relu\",\n                     input_shape=(150,150,3)))\n    model.add(MaxPooling2D(pool_size = (2,2)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(filters = 64, kernel_size = (2,2), \n                     padding = \"same\", activation = \"relu\",\n                     input_shape=(150,150,3)))\n\n    model.add(MaxPooling2D(pool_size = (1,1)))\n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    \n\n    model.add(Flatten())\n    \n    model.add(Dense(32, activation = \"relu\"))\n    model.add(Dense(1, activation = \"sigmoid\"))  \n   \n    model.compile(optimizer =\"adam\", loss = \"binary_crossentropy\", \n                  metrics = ['accuracy'])      \n    \n    return model\n\n#jika multiclass softmax dense 2 atau lebih\n#jika multiclass \"sparse_categorical_crossentropy\"","0c2c3fde":"model = cnn_model()\nmodel.summary()","3c24e370":"pat = 5\nn_folds=5\nepochs=100\nbatch_size=32\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 5, verbose=1,factor=0.5, min_lr=0.0001)\nearly_stopping = EarlyStopping(monitor='loss', patience=pat, verbose=1)\nmodel_checkpoint = ModelCheckpoint('subjek1CNN.h5', verbose=1,save_best_only=True)\n\ndef fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS=epochs, BATCH_SIZE=batch_size):\n    model = None\n    model = cnn_model() \n    results = model.fit(t_x, t_y, epochs=EPOCHS, batch_size=BATCH_SIZE, \n                        callbacks=[learning_rate_reduction,\n                                   early_stopping,\n                                   model_checkpoint], verbose=1, validation_split=0.1)  \n    \n    print(\"Val Score: \", model.evaluate(val_x, val_y))\n        \n    predictions = model.predict_classes(val_x, batch_size=32, verbose=1)\n    print(classification_report(val_y, predictions ))\n    \n    predictions = model.predict_classes(t_x, batch_size=32, verbose=1)\n    cm = confusion_matrix(t_y,predictions)\n    \n    plt.figure(figsize = (5,5))\n    sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' ,\n                linewidth = 1 , annot = True, fmt='')\n    \n    return results","955599b3":"model_history = [] \nfor i in range(n_folds):\n    print(\"Training on Fold: \",i+1)\n    t_x, val_x, t_y, val_y = train_test_split(test_images, test_labels, \n                                              test_size=0.2, \n                                              random_state = np.random.randint(1,1000, 1)[0]\n                                             )\n    model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n   \n    print(\"=======\"*12, end=\"\\n\\n\\n\")\n","f81f1f0c":"keras.utils.plot_model(model, show_shapes=True)","d779b858":"\nmodel = load_model('subjek1CNN.h5')\nmodel.evaluate(val_x, val_y)\npredictions = model.predict_classes(val_x, batch_size=32, verbose=1)\nprint(classification_report(val_y, predictions ))\n    ","d24cb5eb":"from keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder","9d81ca20":"t_x, val_x, t_y, val_y = train_test_split(test_images, test_labels, test_size=0.2, )\nt_x.shape, val_x.shape, t_y.shape, val_y.shape","0d0e5870":"model = load_model('subjek1CNN.h5')\nclass_names = ['unknown', 'widhi']\nencoder = LabelEncoder()\nencoder_y = encoder.fit_transform(labels)\ntrain_labels = to_categorical(encoder_y,num_classes=None)\n    \n#predictions = model.predict_classes(t_x)\n\npredictions = model.predict_classes(t_x, batch_size=32, verbose=1)\ncm = confusion_matrix(t_y,predictions)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"Blues\",xticklabels=class_names, yticklabels=class_names, linecolor = 'black' ,\n                linewidth = 1 , annot = True, fmt='')","3318b6aa":"import matplotlib.pyplot as plt \nfig, (ax1, ax2) =  plt.subplots( ncols=2, sharex=True)\nax1.plot(model_history[0].history['accuracy'], label='Training Fold 1 accuration')\nax1.plot(model_history[1].history['accuracy'], label='Training Fold 2 accuration')\nax1.plot(model_history[2].history['accuracy'], label='Training Fold 3 accuration')\nax1.plot(model_history[3].history['accuracy'], label='Training Fold 4 accuration')\nax1.plot(model_history[4].history['accuracy'], label='Training Fold 5 accuration')\nax1.legend()\nax2.plot(model_history[1].history['loss'], label='Training Fold 1 loss')\nax2.plot(model_history[1].history['loss'], label='Training Fold 2 loss')\nax2.plot(model_history[2].history['loss'], label='Training Fold 3 loss')\nax2.plot(model_history[3].history['loss'], label='Training Fold 4 loss ')\nax2.plot(model_history[4].history['loss'], label='Training Fold 5 loss')\nax2.legend()\nplt.show()","e62d0ce0":"import matplotlib.pyplot as plt \nfig, (plt1, plt2)  =  plt.subplots( ncols=2, sharex=True)\nfig = plt.figure(figsize=(5,5))\nplt1.plot(model_history[0].history['accuracy'], label='Train Accuracy Fold 1', color='black')\nplt1.plot(model_history[0].history['val_accuracy'], label='Val Accuracy Fold 1', color='orange', linestyle = \"dashdot\")\nplt1.legend()\nplt2.plot(model_history[0].history['loss'], label='Train Loss Fold 1', color='black')\nplt2.plot(model_history[0].history['val_loss'], label='Val Loss Fold 1', color='orange', linestyle = \"dashdot\")\nplt2.legend()\nplt.show()\n\nfig, (plt1, plt2)  =  plt.subplots( ncols=2, sharex=True)\nfig = plt.figure(figsize=(5,5))\nplt1.plot(model_history[1].history['accuracy'], label='Train Accuracy Fold 2', color='red')\nplt1.plot(model_history[1].history['val_accuracy'], label='Val Accuracy Fold 2', color='orange', linestyle = \"dashdot\")\nplt1.legend()\nplt2.plot(model_history[1].history['loss'], label='Train Loss Fold 2', color='red')\nplt2.plot(model_history[1].history['val_loss'], label='Val Loss Fold 2', color='orange', linestyle = \"dashdot\")\nplt2.legend()\nplt.show()\n\n\nfig, (plt1, plt2)  =  plt.subplots( ncols=2, sharex=True)\nfig = plt.figure(figsize=(5,5))\nplt1.plot(model_history[2].history['accuracy'], label='Train Accuracy Fold 3', color='green')\nplt1.plot(model_history[2].history['val_accuracy'], label='Val Accuracy Fold 3', color='orange', linestyle = \"dashdot\")\nplt1.legend()\nplt2.plot(model_history[2].history['loss'], label='Train Loss Fold 3', color='green')\nplt2.plot(model_history[2].history['val_loss'], label='Val Loss Fold 3', color='orange', linestyle = \"dashdot\")\nplt2.legend()\nplt.show()\n\n\nfig, (plt1, plt2)  =  plt.subplots( ncols=2, sharex=True)\nfig = plt.figure(figsize=(5,5))\nplt1.plot(model_history[3].history['accuracy'], label='Train Accuracy Fold 4', color='blue')\nplt1.plot(model_history[3].history['val_accuracy'], label='Val Accuracy Fold 4', color='orange', linestyle = \"dashdot\")\nplt1.legend()\nplt2.plot(model_history[3].history['loss'], label='Train Loss Fold 4', color='blue')\nplt2.plot(model_history[3].history['val_loss'], label='Val Loss Fold 4', color='orange', linestyle = \"dashdot\")\nplt2.legend()\nplt.show()\n\n\nfig, (plt1, plt2)  =  plt.subplots( ncols=2, sharex=True)\nfig = plt.figure(figsize=(5,5))\nplt1.plot(model_history[4].history['accuracy'], label='Train Accuracy Fold 5', color='purple')\nplt1.plot(model_history[4].history['val_accuracy'], label='Val Accuracy Fold 5', color='orange', linestyle = \"dashdot\")\nplt1.legend()\nplt2.plot(model_history[4].history['loss'], label='Train Loss Fold 4', color='purple')\nplt2.plot(model_history[4].history['val_loss'], label='Val Loss Fold 4', color='orange', linestyle = \"dashdot\")\nplt2.legend()\nplt.show()","82923be8":"model = load_model('subjek1CNN.h5')\npredictions = model.predict_classes(x_test, batch_size=32, verbose=1)   # Vector of probabilities\n\npred_labels = np.argmax(predictions, axis =1) # We take the highest probability\ndisplay_random_image(class_names, x_test, pred_labels)","c7b204d1":"import cv2\nimport mtcnn\nimport matplotlib.pyplot as plt","f032c9cb":"face_detector = mtcnn.MTCNN()\nimg = cv2.imread('..\/input\/wajahtes\/train\/widhi\/19575410_10209196992471098_6504103582793799056_o.jpg')\nmodel_path = '.\/subjek1CNN.h5'\nmodel = load_model(model_path)\n\nconf_t = 0.99\nimg = cv2.resize(img, (150, 150))\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nresults = face_detector.detect_faces(img)\n\nnormalized_img= np.expand_dims(img, axis=0) #cnn pure\ndata_for_model= normalized_img\nprediction = model.predict(data_for_model)\n\nprint(prediction)\n#a = float(prediction[0][0])*10\n#b = float(prediction[0][1])*10\n#print(a,b)\n\na = float(prediction[0])\nif a <9 :\n    \n    pred = \"widhi\"\nelse :\n    \n    pred = \"unknown\"\n    \n#img2 = cv2.resize(img, (480, 480))\n    \nfor res in results:\n    x1, y1, width, height = res['box']\n    x1, y1 = abs(x1), abs(y1)\n    x2, y2 = x1 + width, y1 + height\n\n    confidence = res['confidence']\n    if confidence < conf_t:\n        continue\n    key_points = res['keypoints'].values()\n\n    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), thickness=1)\n    cv2.putText(img, pred, (x1, y1), cv2.FONT_ITALIC, 1, (0, 255, 0), 1)\n    '''\n    for point in key_points:\n    cv2.circle(img, point, 1, (0, 255, 0), thickness=-1)\n    '''\n\nplt.figure(figsize=(5, 5))\nplt.imshow(img)\nplt.show()","9a41629c":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","014c8b1f":"path=\"..\/input\/face-detection\/train_data\"\n!ls ..\/input\/wajahtes\/train","9ce1bdd5":"image_size = (180, 180)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/wajahtes\/train\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/wajahtes\/train\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n","3ab54a32":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","806976da":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.1),\n    ]\n)","883c2bba":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","c4425b85":"augmented_train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n","b1afa41f":"train_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)\n","2a22a178":"def make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=2)\nkeras.utils.plot_model(model, show_shapes=True)","670574d8":"epochs = 50\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),]\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],)\n\nmodel.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,)\nprint(\"Val Score: \", model.evaluate(val_ds))\n","f4410636":"img = keras.preprocessing.image.load_img(\n    \"..\/input\/wajahtes\/train\/unknown\/0 (1).jpg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\n\nscore = predictions[0]\n\nprint(\"This image is %.2f percent me  and %.2f percent not me.\"\n    % (100 * (1 - score), 100 * score))\n","481f46a7":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm","6aabed1c":"\nimport cv2\nimport mtcnn\nimport matplotlib.pyplot as plt\n\nmodel_path = '.\/save_at_50.h5'\nmodel = load_model(model_path)\n\nface_detector = mtcnn.MTCNN()\n\n\nimg = cv2.imread('..\/input\/wajahtes\/train\/widhi\/18595373_10208842824337116_7422078812770027_o (1).jpg')\n\n\nimg = cv2.resize(img, (180, 180))\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nresults = face_detector.detect_faces(img)\n\nnormalized_img= np.expand_dims(img, axis=0) #cnn pure\ndata_for_model= normalized_img\nprediction = model.predict(data_for_model)\nprint(prediction[0])\n\n\nx = float(prediction[0])\n#a = float(prediction[0][1])\nif x >0.001 :\n    #print(\"bukan\")\n    pred = \"widhi\"\nelse :\n    #print(\"aku\")\n    pred = \"unknown\"\n    \n#img2 = cv2.resize(img, (480, 480))\n    \nfor res in results:\n    x1, y1, width, height = res['box']\n    x1, y1 = abs(x1), abs(y1)\n    x2, y2 = x1 + width, y1 + height\n\n    confidence = res['confidence']\n    if confidence < conf_t:\n        continue\n    key_points = res['keypoints'].values()\n\n    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), thickness=1)\n    #cv2.putText(img, 'S: {confidence:.3f}', (x1+20, y1), cv2.FONT_ITALIC, 1, (0, 0, 255), 1)\n    cv2.putText(img, pred, (x1, y1), cv2.FONT_ITALIC, 1, (0, 255, 0), 1)\n    #for point in key_points:\n        #cv2.circle(img2, point, 5, (0, 255, 0), thickness=-1)\nplt.figure(figsize=(10, 10))\nplt.imshow(img)\nplt.show()","b2ad2ca8":"# Split Data","40664bdb":"#PERBANDIINGAN AKURASI DATA","54a637c8":"#Model CNN usulan","9e06b2a7":"#Conf Matrix","489f57e7":"#Akurasi","b49f9441":"#CNN SOTA","719f34af":"#TES oNLINE"}}