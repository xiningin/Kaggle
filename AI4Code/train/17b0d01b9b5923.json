{"cell_type":{"92571244":"code","b0b3ea71":"code","c772faef":"code","401e1933":"code","c3b19114":"code","9d2e66f0":"code","1784c9e3":"code","fdbc95d1":"code","976305da":"code","3ee209a8":"code","0aed36e0":"markdown","c735088e":"markdown"},"source":{"92571244":"# import data and libraries\n\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport networkx as nx\nimport math\nfrom matplotlib.pyplot import figure\nimport itertools\n\ninput_file = \"\/kaggle\/input\/scl-2021-da\/contacts.json\"\ndf = pd.read_json(input_file)\n\n# replace all ' ' strings with NaN value\ndf = df.replace(r'^\\s*$', np.NaN, regex=True)","b0b3ea71":"# Create graphs\nG1 = nx.from_pandas_edgelist(df,'Email','OrderId') # create edges from Email to OrderId\nG2 = nx.from_pandas_edgelist(df,'Email','Phone')   # create edges from Email to Phone\nG3 = nx.from_pandas_edgelist(df,'Phone','Email')   # and so on...\nG4 = nx.from_pandas_edgelist(df,'Phone','OrderId')\nG5 = nx.from_pandas_edgelist(df,'OrderId','Email')\nG6 = nx.from_pandas_edgelist(df,'OrderId','Phone')\n\nGA = nx.compose(G1, G2)  # combine G1 and G2\nGB = nx.compose(G3, G4)  # combine G3 and G4\nGC = nx.compose(G5, G6)  # and so on...\nGI = nx.compose(GA, GB)  \n\nGT = nx.compose(GI, GC)  # final combined graph\n\n# remove nan values from the graph - else, almost all nodes are connected to one another via the nan nodes\nnan_nodes = []\n\nfor node in GT.nodes():\n    if str(node) == \"nan\":\n        nan_nodes.append(node)\nGT.remove_nodes_from(nan_nodes)","c772faef":"# visualisation on a subset of the data\ncount = 0\nlimit = 100\nsubset_nodes = []\nfor i in GT.nodes():\n    subset_nodes.append(i)\n    if count > limit:\n        break\n    count+=1\n    \nsubgraph = GT.subgraph(subset_nodes)\nfigure(figsize=(10, 8))\nnx.draw_shell(subgraph, with_labels=True)","401e1933":"def fetch_connected_nodes(G, node, seen = None):\n    '''\n    This function uses depth-first search to \n    return a set of connected nodes to an input node\n    \n    G:      graph to check\n    node:   node for which to return a set of connected nodes\n    seen:   initial set of visited nodes, None by default\n    '''\n    \n    if seen == None:\n        seen = set([node])\n    for neighbor in G.neighbors(node):\n        if neighbor not in seen:\n            seen.add(neighbor)\n            fetch_connected_nodes(G, neighbor, seen)\n    return seen\n\ndef getConnectionsIds(row,dict):\n    '''\n    Get list of indices of all the connected rows\n    \n    row:    row to check for\n    dict:   input dictionary with nodes and respective sets of connected nodes\n    '''\n    return dict[row['all'][0]]","c3b19114":"# create a dictionary of nodes and their connected nodes\ng_dict = {}\n\nfor x in GT.nodes:\n    \n    # find connections if the node is not null\n    if not pd.isnull(x):\n        connected = fetch_connected_nodes(GT, x)\n        connected = [x for x in connected if str(x) != 'nan']\n        g_dict[x] = connected  # add to the dictionary of {node : node's connections}\n\n# check first 5 items in g_dict\n{k: '{0} related user contact information - {1}'.format(len(g_dict[k]),g_dict[k]) for k in list(g_dict)[:5]}","9d2e66f0":"# combine all non-NaN user contacts in a single list \ndf['all'] = df.apply(lambda x: [x['Email'],x['Phone'],x['OrderId']],axis=1)\ndf[\"all\"] = df[\"all\"].apply(lambda x: [i for i in x if str(i) != \"nan\"])\n\n# create new column containing a list of connected user contact information\ndf['connections'] = df.apply(lambda x: getConnectionsIds(x,g_dict),axis=1)\ndf['connections'] = df['connections'].apply(sorted)\ndf['connections'] = df.connections.apply(lambda x: ', '.join([str(i) for i in x]))\n\ndf.head()","1784c9e3":"# use groupby to sum the 'Contacts' column\ngroup_sum = df.groupby('connections').sum()\ngroup_idx = df.groupby('connections').apply(lambda x: x.index.tolist())\ngroup_sum['ticket_trace'] = pd.Series(group_idx)\ngroup_sum['ticket_trace'] = group_sum['ticket_trace'].apply(lambda x: \"-\".join([str(y) for y in x]))\n\ngroup_sum.head()","fdbc95d1":"# merge the two dfs to obtain final csv\nsubmission = df.merge(group_sum,left_on='connections',right_on='connections')\n\nsubmission.head()","976305da":"# formatting\nsubmission = submission[['Id_x','ticket_trace','Contacts_y']]\nsubmission['ticket_trace\/contact'] = submission[\"ticket_trace\"].astype(str) + \", \" + submission[\"Contacts_y\"].astype(str)\nsubmission = submission[['Id_x','ticket_trace\/contact']]\nsubmission = submission.rename(columns={\"Id_x\": \"ticket_id\"})\nsubmission = submission.sort_values(by=['ticket_id'])\nsubmission = submission.set_index('ticket_id')\n\nsubmission.head()","3ee209a8":"# export to csv\nsubmission.to_csv(\".\/submission.csv\")","0aed36e0":"This solution uses graph theory to find all connected components to determine if the contact information can be linked to a single individual.\n\nHappy to get any suggestions to improve the code below!","c735088e":"We will define some functions that will be useful to our program later.\n1. First, we define a function \"fetch_connected_nodes\" to help us find a list of user contact information related to a given piece of user contact information.\ni.e. given an email address \"johndoe@hotmail.com\", we return a set of email address, telephone numbers and order ids related to \"johndoe@hotmail.com\".\n2. Next, we define a function to return the corresponding ID numbers of the connected rows, given an input row"}}