{"cell_type":{"1eaeb01a":"code","357feeeb":"code","5a009ff1":"code","f248f562":"code","ca04ea99":"code","9e559619":"code","637d42f5":"code","ea0f1daf":"code","f6b41e93":"code","9c6a2483":"code","db5b4a99":"code","09e7ee24":"code","066c7efc":"code","f2ec518e":"markdown","7aed0b64":"markdown","a3ad9f39":"markdown","577aeccf":"markdown"},"source":{"1eaeb01a":"import pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","357feeeb":"input_files = ['\/kaggle\/input\/us-election-2020-presidential-debates\/us_election_2020_1st_presidential_debate.csv',\n               '\/kaggle\/input\/us-election-2020-presidential-debates\/us_election_2020_2nd_presidential_debate.csv',\n               '\/kaggle\/input\/us-election-2020-presidential-debates\/us_election_2020_biden_town_hall.csv',\n               '\/kaggle\/input\/us-election-2020-presidential-debates\/us_election_2020_trump_town_hall.csv']\ndfs = [pd.read_csv(file) for file in input_files]\ndata_frame = pd.concat(dfs)\nprint(data_frame.shape)\ndata_frame.head()","5a009ff1":"from itertools import chain\n\nprint(data_frame.speaker.unique())\ntrump_df = data_frame[(data_frame.speaker.str.contains('Trump'))]\nbiden_df = data_frame[(data_frame.speaker.str.contains('Biden'))]\n\n# Drop speaker and minute columns\ntrump_text_df = trump_df.drop(['speaker', 'minute'], axis=1)\nbiden_text_df = biden_df.drop(['speaker', 'minute'], axis=1)\n\ntrump_text = list(chain(*trump_text_df.astype(str).values.tolist()))\nbiden_text = list(chain(*biden_text_df.astype(str).values.tolist()))\n\nprint('DONALD TRUMP')\nprint(trump_text[::100])\nprint('-----------------------------------------------------------------------------')\nprint('JOE BIDEN')\nprint(biden_text[::50])","f248f562":"from keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(trump_text+biden_text)\nvocab_size = len(tokenizer.word_index) + 1\nprint('Vocabulary size : ', vocab_size)","ca04ea99":"from nltk import sent_tokenize\nimport numpy as np\nfrom keras.utils import to_categorical\nmax_sequence_length = 4\n\ndef get_sequences(text):\n    input_sequences = list()\n    output_sequences = list()\n    slice_size = max_sequence_length + 1\n    for s in text:\n        s = s.lower()\n        sentences = sent_tokenize(s)\n        seq = tokenizer.texts_to_sequences(sentences)\n        for s in seq:\n            tokens = [s[i:i+slice_size] for i in range(len(s) - slice_size + 1)]\n            for t in tokens:\n                if t:\n                    input_sequences.append(t[:-1])\n                    output_sequences.append(t[-1])\n    return np.array(input_sequences), to_categorical(output_sequences, num_classes=vocab_size)\n            \n        \n            ","9e559619":"trump_input, trump_output = get_sequences(trump_text)\nbiden_input, biden_output = get_sequences(biden_text)","637d42f5":"len(trump_input), len(biden_input)","ea0f1daf":"from keras import Sequential\nfrom keras.layers import LSTM, Dense, Embedding\n\ndef get_model():\n    model = Sequential()\n    model.add(Embedding(vocab_size, 50, input_length=max_sequence_length))\n    model.add(LSTM(100, return_sequences=True))\n    model.add(LSTM(100))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(vocab_size, activation='softmax'))\n    print(model.summary())\n    return model","f6b41e93":"from keras import Sequential\nfrom keras.layers import LSTM, Dense, Embedding\n\ndef get_model():\n    model = Sequential()\n    model.add(Embedding(vocab_size, 50, input_length=max_sequence_length))\n    model.add(LSTM(100, return_sequences=True))\n    model.add(LSTM(100))\n    model.add(Dense(100, activation='relu'))\n    model.add(Dense(vocab_size, activation='softmax'))\n    print(model.summary())\n    return model","9c6a2483":"def train_model(text_input, text_output, epochs):\n    model = get_model()\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.fit(text_input, text_output, batch_size=128, epochs=epochs)\n    return model","db5b4a99":"def predict(model, seed):\n    words = seed.split(' ')\n    for i in range(10):\n        input_vectors = tokenizer.texts_to_sequences([' '.join(words)])\n        y =  model.predict_classes(input_vectors)\n        for key, value in tokenizer.word_index.items():\n            if value == y:\n                word = key\n                break\n        print(word, end =\" \"),\n        words = words[1:]\n        words.append(word)","09e7ee24":"trump_model = train_model(trump_input, trump_output, 200)\n# combined_model = train_model(np.concatenate([trump_input, biden_input]), \n#                              np.concatenate([trump_output, biden_output]), 200)\n","066c7efc":"predict(trump_model, 'believe in law and')","f2ec518e":"Get text from the two speakers","7aed0b64":"Model","a3ad9f39":"Transform text to sequences","577aeccf":"Make a prediction"}}