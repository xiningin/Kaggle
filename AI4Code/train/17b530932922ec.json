{"cell_type":{"a88e27a9":"code","1bbd3742":"code","87b301a2":"code","b6905c85":"code","d878e1cd":"code","074c891e":"code","0c4c9928":"code","7f8eb83e":"code","ecf92437":"code","29c5ee3c":"code","bc24d483":"code","2174091b":"code","8fed902d":"code","f59b56b7":"code","d4456c63":"code","6afe8298":"code","0dc0d6e2":"code","73345801":"code","9b7ed588":"code","4d195835":"code","82732729":"code","c28b6054":"code","acc43a0c":"code","21c312b6":"code","5e4d6c80":"code","8c8e8740":"code","7b837866":"code","dc24c9a8":"code","6822babf":"code","9ee73276":"code","29375e67":"code","a460d23a":"code","0c3551f9":"code","fca34a77":"code","1e87c694":"code","17c39855":"code","1159c510":"code","f2cc3884":"code","2aef16ed":"code","2f8e5ce5":"code","1a77b908":"code","1ab10498":"code","16365fcd":"code","613a4db2":"code","821a9922":"code","d0984238":"code","e38ebc1e":"code","ff039060":"code","2cd4b5a1":"code","4728378e":"code","cfc00667":"code","f13539c9":"code","8b40694e":"code","850762aa":"code","21c5d520":"code","749abd2c":"code","5dd67aca":"code","32d7ef29":"code","d7429370":"code","1db493c2":"code","775e9ccf":"code","212fe33b":"code","4325bbee":"code","5288a377":"code","e86937bf":"code","5b6c3e49":"code","2e9311c5":"code","15da272a":"code","3e7f587d":"code","eb068480":"code","168468b2":"code","81e7638a":"markdown","85ff36a1":"markdown","4201a223":"markdown","039340ed":"markdown"},"source":{"a88e27a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1bbd3742":"import seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE\n\n# pd.set_option('display.max_rows',None)\n# pd.set_option('display.max_columns',None)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.metrics import roc_auc_score","87b301a2":"train=pd.read_csv('\/kaggle\/input\/jobathon-analytics-vidhya-health-insurance\/Train.csv')\ntest=pd.read_csv('\/kaggle\/input\/jobathon-analytics-vidhya-health-insurance\/Test.csv')\nsub=pd.read_csv('\/kaggle\/input\/jobathon-analytics-vidhya-health-insurance\/sample_submission.csv')","b6905c85":"sub.head()","d878e1cd":"train.head()","074c891e":"train['Diff']=train['Upper_Age']-train['Lower_Age']\ntest['Diff']=test['Upper_Age']-test['Lower_Age']\n\ndef set_range_age(x):\n    if(x<15):\n        return 1\n    elif((x>=15) and (x<30)):\n        return 2\n    elif(x>=30 and x<45):\n        return 3\n    elif(x>=45):\n        return 4\n    \ntrain['New']=train['Diff'].apply(set_range_age)\ntest['New']=test['Diff'].apply(set_range_age)","0c4c9928":"train['New'].value_counts()","7f8eb83e":"train.isnull().sum()","ecf92437":"len(train)","29c5ee3c":"a = train.isnull().sum()\/len(train)*100\na[a>0]","bc24d483":"a = test.isnull().sum()\/len(test)*100\na[a>0]","2174091b":"train.describe()","8fed902d":"train.info()","f59b56b7":"train.columns","d4456c63":"print(len(train))","6afe8298":"for i in train.columns:\n    print(f'Column :{i} Number of unique columns:{train[i].nunique()}')  ","0dc0d6e2":"plt.figure(figsize=(12,7))\nsns.countplot(train['City_Code'])","73345801":"train['City_Code'].nunique()","9b7ed588":"train['City_Code'].value_counts()","4d195835":"# train['Region_Code'].value_counts()","82732729":"plt.figure(figsize=(10,7))\nsns.distplot(train['Upper_Age'])","c28b6054":"plt.figure(figsize=(10,7))\nsns.distplot(train['Lower_Age'])","acc43a0c":"train['Health Indicator'].value_counts()","21c312b6":"train.groupby('City_Code')['Health Indicator'].value_counts()","5e4d6c80":"def set_health_indicator(x):\n    city=x[0]\n    health=x[1]\n    if pd.isnull(health):\n        if (city=='C28') | (city=='C31') | (city=='C36'):\n            return 'X2'\n        elif city=='C35':\n            return 'X3'\n        else:\n            return 'X1'\n    else:\n        return health\ntrain['Health Indicator']=train[['City_Code','Health Indicator']].apply(set_health_indicator,axis=1)\ntest['Health Indicator']=test[['City_Code','Health Indicator']].apply(set_health_indicator,axis=1)","8c8e8740":"train.isnull().sum()","7b837866":"train['Holding_Policy_Duration'].value_counts()","dc24c9a8":"train.isnull().sum()","6822babf":"train['Holding_Policy_Duration']=train['Holding_Policy_Duration'].apply(lambda x:15.0 if x =='14+' else float(x))\ntest['Holding_Policy_Duration']=test['Holding_Policy_Duration'].apply(lambda x:15.0 if x =='14+' else float(x))","9ee73276":"train['Holding_Policy_Duration'].value_counts()","29375e67":"train['Holding_Policy_Duration'].describe()","a460d23a":"# train['Holding_Policy_Duration'].fillna(5.0,inplace=)","0c3551f9":"train['Holding_Policy_Duration'].fillna(5.0,inplace=True)\ntest['Holding_Policy_Duration'].fillna(5.0,inplace=True)","fca34a77":"train.isnull().sum()","1e87c694":"train['Holding_Policy_Type'].value_counts()","17c39855":"train.groupby('City_Code')['Holding_Policy_Type'].value_counts().head()","1159c510":"list_city=['c12','c15','c17','c18','c19','c24']\ndef set_Holding_Policy(x):\n    city=x[0]\n    policy=x[1]\n    if pd.isnull(policy):\n        if (city in list_city):\n            return 1\n        else:\n            return 3\n    return policy\ntrain['Holding_Policy_Type']=train[['City_Code','Holding_Policy_Type']].apply(set_Holding_Policy,axis=1)\ntest['Holding_Policy_Type']=test[['City_Code','Holding_Policy_Type']].apply(set_Holding_Policy,axis=1)","f2cc3884":"train.info()","2aef16ed":"train['Response'].value_counts()","2f8e5ce5":"for i in train.columns:\n    print(f'Column :{i} Number of unique columns:{train[i].nunique()}')  ","1a77b908":"train.head()","1ab10498":"plt.figure(figsize=(10,6))\nsns.heatmap(train.corr(),cmap='coolwarm')","16365fcd":"columns_to_drop=['ID','Region_Code','Reco_Policy_Premium','Diff','Upper_Age','Lower_Age']\ndummies_columns=['City_Code','Accomodation_Type','Reco_Insurance_Type','Is_Spouse'\n                 ,'Holding_Policy_Type','Reco_Policy_Cat']\nlabel_encode=['Health Indicator']","613a4db2":"# train[(train['Is_Spouse']=='Yes')&(train['Reco_Insurance_Type']=='Individual')]","821a9922":"# a=train[(train['Is_Spouse']=='No')&(train['Reco_Insurance_Type']=='Joint')].index\n# train.drop(a,inplace=True)","d0984238":"train.drop(columns=columns_to_drop,inplace=True)\ntest.drop(columns=columns_to_drop,inplace=True)","e38ebc1e":"train_1=train.copy()\ntrain_1=pd.get_dummies(train_1,drop_first=True,columns=dummies_columns)\ntest_1=test.copy()\ntest_1=pd.get_dummies(test_1,drop_first=True,columns=dummies_columns)\n\nle=LabelEncoder()\nfor col in label_encode:\n    train_1[col]=le.fit_transform(train_1[col])\n    test_1[col]=le.transform(test_1[col])","ff039060":"train_1.shape","2cd4b5a1":"X=train_1.drop(columns=['Response'])\ny=train_1['Response']","4728378e":" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","cfc00667":"scaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\ntest_1=scaler.transform(test_1)","f13539c9":"# cvs_random=cross_val_score(RandomForestClassifier(),X=X_train,y=y_train,cv=5,scoring='accuracy')\n# print(cvs_random.mean())\n# print(cvs_random.std())","8b40694e":"# cvs_random=cross_val_score(DecisionTreeClassifier(),X=X_train,y=y_train,cv=5,scoring='accuracy')\n# print(cvs_random.mean())\n# print(cvs_random.std())","850762aa":"# cvs_random=cross_val_score(LogisticRegression(),X=X_train,y=y_train,cv=5,scoring='accuracy')\n# print(cvs_random.mean())\n# print(cvs_random.std())","21c5d520":"# cvs_random=cross_val_score(XGBClassifier(),X=X_train,y=y_train,cv=5)\n# print(cvs_random.mean())\n# print(cvs_random.std())","749abd2c":"# sm = SMOTE(random_state = 2) \n# X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel()) \n\n# model=LogisticRegression(solver=\"liblinear\")\n\n# model.fit(X_train_res,y_train_res)\n# pred_logistic=model.predict_proba(X_test)[:, 1]\n\n# roc_auc_score(y_test,pred_logistic)","5dd67aca":"# model=LogisticRegression(solver=\"liblinear\")\n\n# model.fit(X_train,y_train)\n# pred_logistic=model.predict_proba(X_test)[:, 1]\n\n# roc_auc_score(y_test,pred_logistic)","32d7ef29":"# model=RandomForestClassifier()\n\n# model.fit(X_train,y_train)\n# pred_random=model.predict_proba(X_test)[:, 1]\n\n# roc_auc_score(y_test,pred_random)","d7429370":"# model=DecisionTreeClassifier()\n\n# model.fit(X_train,y_train)\n# pred_decision=model.predict_proba(X_test)[:, 1]\n\n# roc_auc_score(y_test,pred_decision)","1db493c2":"# test_predictions=model.predict_proba(test_1)[:, 1]\n\n# sub['Response']=test_predictions\n\n# sub.to_csv('JOB-A-THON-LOGISTICS(PREDICTIONS)-1.csv',index=False)","775e9ccf":"# from sklearn.model_selection import GridSearchCV\n# param_test1 = {'n_estimators':range(20,81,10)}\n# gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n# param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n# gsearch1.fit(X_train,y_train)","212fe33b":"# gsearch1.get_params, gsearch1.best_params_, gsearch1.best_score_","4325bbee":"# from sklearn.model_selection import RandomizedSearchCV\n# from sklearn.model_selection import StratifiedKFold\n# params = {\n#         'min_child_weight': [1, 5, 10],\n#         'gamma': [0.5, 1, 1.5, 2, 5],\n#         'subsample': [0.6, 0.8, 1.0],\n#         'colsample_bytree': [0.6, 0.8, 1.0],\n#         'max_depth': [3, 4, 5]\n#         }\n# xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n#                     silent=True, nthread=1)\n# folds = 3\n# param_comb = 5\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\n# random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n\n# # Here we go\n# # start_time = timer(None) # timing starts from this point for \"start_time\" variable\n# random_search.fit(X_train, y_train)\n# # timer(start_time) # timing ends here for \"start_time\" variable\n\n# random_search.best_params_","5288a377":"xgb1 = XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=5,\n min_child_weight=1,\n gamma=1.5,\n subsample=0.6,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\nxgb1.fit(X_train,y_train)\n\n# model=XGBClassifier()\n\nxgb1.fit(X_train,y_train)\npred_xgb=xgb1.predict_proba(X_test)[:, 1]\n\nroc_auc_score(y_test,pred_xgb)","e86937bf":"# train[train['Diff']>0]['Diff'].describe()","5b6c3e49":"# train['Diff']=train['Upper_Age']-train['Lower_Age']\n# pd.cut(train['Diff'],bins=4)","2e9311c5":"# param_test1 = {\n#  'max_depth':range(3,10,2),\n#  'min_child_weight':range(1,6,2)\n# }\n# gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n#  min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n#  objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n#  param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n# gsearch1.fit(X_train,y_train)\n# gsearch1.best_estimator_, gsearch1.best_params_, gsearch1.best_score_","15da272a":"# sm = SMOTE(random_state = 2) \n# X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel()) \n# from imblearn.under_sampling import NearMiss \n# nr = NearMiss() \n  \n# X_train_res, y_train_res = nr.fit_resample(X_train, y_train.ravel())\n\n# model=XGBClassifier()\n\n# model.fit(X_train_res,y_train_res)\n# pred_xgb=model.predict_proba(X_test)[:, 1]\n\n# roc_auc_score(y_test,pred_xgb)","3e7f587d":"# model.predict_proba(test_1)[:,1]","eb068480":"test_predictions=xgb1.predict_proba(test_1)[:, 1]\n\nsub['Response']=test_predictions\n\nsub.to_csv('JOB-A-THON-XGB(PREDICTIONS)-1.csv',index=False)","168468b2":"sub","81e7638a":"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX","85ff36a1":"# **Rank in top 15% on Private Leader Board**","4201a223":"c28=x2\nc31=x2\nc35=x3\nc36=x2","039340ed":"### Hope This Notebook Helps others prepare for the same "}}