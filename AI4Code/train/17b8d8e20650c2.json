{"cell_type":{"e4dbcd42":"code","f48ba968":"code","94d7a9b7":"code","219ef508":"code","693170d7":"code","630c59b0":"code","c7de7d36":"code","2c610dc6":"code","d137e1e1":"code","27889aa8":"markdown","6bb0b385":"markdown","cb8d7767":"markdown","011c3cd3":"markdown","313332cf":"markdown"},"source":{"e4dbcd42":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f48ba968":"import pandas as pd\nimport numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n%matplotlib inline ","94d7a9b7":"def get_lag_time(df,col,n_back):\n    for i in range(n_back):\n        df[col+'-'+str(i+1)] = df[col].shift(i+1)\n    return df","219ef508":"def get_lead_time(df,col,n_back):\n    for i in range(n_back):\n        df[col+'+'+str(i+1)] = df[col].shift(-(i+1))\n    return df","693170d7":"def read_edit(path):    \n        df = pd.read_csv(path)\n        # renaming columns\n        names = {'Date':'date','Hour':'hour','Temperature(\ufffdC)':'temp',\n                'Humidity(%)':'humidity','Visibility (10m)':'vis_10',\n                'Dew point temperature(\ufffdC)':'dew_pt_temp','Solar Radiation (MJ\/m2)':'solar_rad',\n                'Rainfall(mm)':'rainfall_mm','Snowfall (cm)':'snowfall_cm','Seasons':'seasons','Holiday':'holiday',\n                'Functioning Day':'functioning_day','Wind speed (m\/s)':'windspeed'}\n\n        df.rename(columns=names,inplace=True)\n\n        # converting date to date time\n        df['date']=pd.to_datetime(df['date'],format=\"%d\/%m\/%Y\")\n        # making date and night out of hours\n        df['label_day_night']=df['hour'].apply(lambda x : 'Night' if (x >20 or x<5) else( 'Day'))\n        # getting day names\n        df['week_day']=df[\"date\"].dt.day_name()\n        # getting months\n        df['month']=df['date'].dt.month\n        # Encoding days of the week\n        mapping_dictDay={'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}\n        df['week_day_encoding']=df['week_day'].map(mapping_dictDay)\n\n        # getting dummies for seasons,holiday,functioning_day\n        df = pd.get_dummies(df, columns = ['holiday','functioning_day','seasons'],drop_first=True)\n\n        df['date'], Categorical= pd.factorize(df['date'])\n        df['week_day'], Categorical= pd.factorize(df['week_day'])\n\n        # applying lag_time & lead_time\n        df = get_lag_time(df,'windspeed',2)\n        df = get_lag_time(df,'rainfall_mm',2)\n        df = get_lead_time(df,'rainfall_mm',4)\n        df = get_lead_time(df,'temp',1)\n        \n\n        return df","630c59b0":"# reading train and test data\ndataset_path = '\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/'\ntrain = read_edit(os.path.join(dataset_path, 'train.csv'))\ntest = read_edit(os.path.join(dataset_path,'test.csv'))\n\ntest = test.drop(['date','dew_pt_temp','label_day_night','week_day','snowfall_cm'],axis =1)\nX=train.drop(['ID','y','date','dew_pt_temp','label_day_night','week_day','snowfall_cm'],axis =1)\ny=train['y'] #the target\n\nX.head()","c7de7d36":"# train - test split\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1, random_state=42)\n# xgboost model\nxg_reg = xgb.XGBRegressor(objective='count:poisson',random_state=42,colsample_bytree = 0.6, learning_rate = 0.1,max_depth=5\n                 ,alpha = 10, n_estimators = 1000)","2c610dc6":"from sklearn.metrics import mean_squared_log_error\n# fit the model\nxg_reg=xg_reg.fit(X_train,y_train)\n#==========================================================\n#========================train=============================\ny_pred=xg_reg.predict(X_train)\nrmsle_train = np.sqrt(mean_squared_log_error(y_train, y_pred))\nprint(\"RMSE-train: %f\" % (rmsle_train))\n\n\n#==========================================================\n#======================validation==========================\n\ny_pred1=xg_reg.predict(X_val)\nrmsle = np.sqrt(mean_squared_log_error(y_val, y_pred1))\nprint(\"RMSE-val: %f\" % (rmsle))\n#==========================================================\n#====================cross-val=============================\nscores = cross_val_score(xg_reg, X_train, y_train, cv=5,scoring='neg_mean_squared_log_error')\nprint(\"RMSE-Crossval %0.2f \" % (np.sqrt(np.abs(scores.mean()))))\n\n\n","d137e1e1":"y_pred2 = xg_reg.predict(test.drop(['ID'],axis=1))\ntest['y'] = y_pred2\ntest[['ID', 'y']].to_csv('sub_x.csv', index=False)\nf = pd.read_csv('sub_x.csv')\nf","27889aa8":"## Converting time series proplem to regression proplem\nby getting previous time points for some features","6bb0b385":"## fit and evaluate","cb8d7767":"## submission","011c3cd3":"## Train test split and mmodel","313332cf":"## Reading and editing df and test sets"}}