{"cell_type":{"85353c17":"code","9c112df1":"code","1dda0a7b":"code","30b54118":"code","48bf188b":"code","8e84c98b":"code","1e46d668":"code","f8b33cb2":"code","e9322380":"code","bccb1dd3":"code","0c4a4622":"code","dae92b45":"code","ed6901f0":"code","e4b9f37d":"code","9cf93900":"code","4d57d546":"code","5f7f69a8":"code","db3cfd68":"code","973b8c7f":"code","504917dd":"code","67bc95d5":"code","d558bc29":"code","10e777e2":"code","97a0a37f":"markdown","2eb7a4d3":"markdown","b9f29c9c":"markdown","024b49e3":"markdown","d997dae5":"markdown","86d4fa54":"markdown","934ef429":"markdown","ac6310fd":"markdown","b360376f":"markdown","a6e7d6f3":"markdown","ddc9c1f1":"markdown","f919df47":"markdown","04f66b4c":"markdown","9e9bdb61":"markdown","4fbfe32d":"markdown","766906af":"markdown","9e20cea0":"markdown","51579df2":"markdown","7a438c8a":"markdown","a6695976":"markdown","601d1c21":"markdown","b0ec83d3":"markdown","5d3bef11":"markdown","648ce509":"markdown","779559b0":"markdown","9a905665":"markdown"},"source":{"85353c17":"import numpy as np\nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nfrom sklearn.mixture import GaussianMixture \n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import RobustScaler\n\nfrom scipy.spatial.distance import cdist\nfrom matplotlib.patches import Ellipse\n\nsns.set()","9c112df1":"df = pd.read_csv('\/kaggle\/input\/ccdata\/CC GENERAL.csv')\ndf.head(3)","1dda0a7b":"df.set_index('CUST_ID', inplace=True)\ndf.head(3)","30b54118":"nan_sample = df.isnull().sum().sort_values(ascending=False)\nnan_sample = nan_sample[nan_sample > 0]\nnan_sample","48bf188b":"for i in nan_sample.index:\n    df.loc[df[i].isnull(), i] = df[i].mean()","8e84c98b":"df.isnull().sum().sort_values(ascending=False)","1e46d668":"df.duplicated().value_counts()","f8b33cb2":"plt.subplots(figsize=(14, 10))\ndf.boxplot()\nplt.yscale('log')\nplt.xticks(rotation=50)\nplt.show()","e9322380":"df.describe()","bccb1dd3":"scaler = RobustScaler() \nscaled = scaler.fit_transform(df.values)\nscaled","0c4a4622":"pca = PCA(n_components=0.95, svd_solver='full')\npca_values = pca.fit_transform(scaled)\n\npca.n_components_, np.sum(pca.explained_variance_ratio_)","dae92b45":"pca_values = PCA(n_components=2).fit_transform(scaled)","ed6901f0":"sse = dict((k, KMeans(n_clusters=k, max_iter=10000).fit(pca_values).inertia_) for k in range(1, 20))\n    \nplt.bar(x=sse.keys(), height=sse.values(), width=1, edgecolor='k', facecolor='orange')\nplt.plot(list(sse.keys()), list(sse.values()), 'ro-')\nplt.xlabel(\"Number of cluster\")\nplt.ylabel(\"SSE\")\nplt.show()","e4b9f37d":"def graph_clusters(method_name, array2d, nmin=2, nmax=9, style=plt.cm.plasma):\n    \n    count_axis_x = 3\n    count_axis_y = (nmax - nmin + 1) \/\/ 3 + 1\n    \n    f = plt.figure(figsize=(count_axis_x  * 6, count_axis_y * 5))\n\n    for i in range(nmin, nmax + 1):\n        model = method_name(n_clusters=i).fit(array2d)\n        f.add_subplot(count_axis_y, count_axis_x, i - 1)\n        plt.scatter(array2d[:, 0], array2d[:, 1], s=10, cmap=style, c=model.labels_, label=\"number of\\nclusters = \" + str(i))\n        plt.legend()\n\n    plt.show()\n\n\ngraph_clusters(KMeans, pca_values, 2, 10, plt.cm.viridis)","9cf93900":"kmeans = KMeans(n_clusters=4, max_iter=1000).fit(pca_values)\n\nplt.subplots(figsize=(10, 8))\nsns.scatterplot(x=\"Pca1\", y=\"Pca2\", hue=\"Cluster\", \n                     data=pd.DataFrame({'Pca1': pca_values[:, 0],\n                                        'Pca2': pca_values[:, 1],\n                                        'Cluster': kmeans.labels_}), palette=plt.cm.tab20, s=100, \n                     alpha=1, edgecolor='k', linewidth=1.2)\n\ncenters = kmeans.cluster_centers_\n\nr = [cdist(pca_values[kmeans.labels_ == i], [center]).max() for i, center in enumerate(kmeans.cluster_centers_)]\n\nplt.scatter(centers[:, 0], centers[:, 1], facecolor='green', marker='H', s=120, edgecolor='k')\nfor c, rad in zip(centers, r):\n    plt.gcf().gca().add_artist(plt.Circle(c, rad, facecolor='darkgreen', lw=3, alpha=0.25, zorder=10))\n\nplt.axis('equal')\nplt.show()","4d57d546":"# kmeans = KMeans(n_clusters=4, max_iter=1000).fit(scaled)\ndata = pd.concat([df, pd.DataFrame(kmeans.labels_, columns=['Cluster'], index=df.index)], axis=1)\ndata = data[['Cluster'] + [col for col in data.columns if col != 'Cluster']]\n\nfor c in data.columns[1:]:\n    grid = sns.FacetGrid(data, col='Cluster', height=3, aspect=1.3)\n    grid.map(plt.hist, c, bins=20, edgecolor='k')\n    grid.set_xticklabels(rotation=40)\n    \npd.DataFrame(data['Cluster'].value_counts())","5f7f69a8":"graph_clusters(AgglomerativeClustering, pca_values, 2, 10)","db3cfd68":"ag = AgglomerativeClustering(n_clusters=4, \n                             affinity='euclidean', \n                             linkage='ward').fit(pca_values)\n\nplt.subplots(figsize=(10, 8))\nsns.scatterplot(x=\"Pca1\", y=\"Pca2\", hue=\"Cluster\", \n                     data=pd.DataFrame({'Pca1': pca_values[:, 0],\n                                        'Pca2': pca_values[:, 1],\n                                        'Cluster': ag.labels_}), palette=plt.cm.tab20, s=100, \n                     alpha=1, edgecolor='k', linewidth=1.2)\n\nplt.show()","973b8c7f":"data = pd.concat([df, pd.DataFrame(ag.labels_, columns=['Cluster_ag'], index=df.index)], axis=1)\ndata = data[['Cluster_ag'] + [col for col in data.columns if col != 'Cluster_ag']]\n\nfor c in data.columns[1:]:\n    grid = sns.FacetGrid(data, col='Cluster_ag', height=3, aspect=1.3)\n    grid.map(plt.hist, c, bins=20, edgecolor='k')\n    grid.set_xticklabels(rotation=40)\n\npd.DataFrame(data['Cluster_ag'].value_counts())","504917dd":"f = plt.figure(figsize=(18, 15))\n\nfor i in range(2, 10):\n    model = GaussianMixture(n_components=i).fit(pca_values)\n    f.add_subplot(3, 3, i - 1)\n    plt.scatter(pca_values[:, 0], pca_values[:, 1], s=10, cmap=plt.cm.magma_r, c=model.predict(pca_values), \n                label=\"number of\\nclusters = \" + str(i))\n    plt.legend()\n\nplt.show()","67bc95d5":"def draw_ellipse(position, covariance, ax=None, **kwargs):\n    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n    ax = ax or plt.gca()\n    \n    # Convert covariance to principal axes\n    if covariance.shape == (2, 2):\n        U, s, Vt = np.linalg.svd(covariance)\n        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n        width, height = 2 * np.sqrt(s)\n    else:\n        angle = 0\n        width, height = 2 * np.sqrt(covariance)\n    \n    # Draw the Ellipse\n    for nsig in range(1, 4):\n        v = np.random.randint(255, size=3)\n        rgb = plt.cm.viridis.colors\n        \n        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n                             angle, facecolor=rgb[v[nsig - 1]], edgecolor='k', **kwargs))","d558bc29":"gmm = GaussianMixture(n_components=4, init_params='kmeans', covariance_type='full').fit(pca_values)\n\nf, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12, 18))\n\nsns.scatterplot(x=\"Pca1\", y=\"Pca2\", hue=\"Cluster\", \n                     data=pd.DataFrame({'Pca1': pca_values[:, 0],\n                                        'Pca2': pca_values[:, 1],\n                                        'Cluster': gmm.predict(pca_values)}), palette=plt.cm.Spectral, s=100, \n                     alpha=1, edgecolor='k', linewidth=1.2, ax=ax1)\n\n\nax2.set_yticks(ax1.get_yticks())\nax2.set_ylabel(ax1.get_ylabel())\n\nfor pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n    draw_ellipse(pos, covar, alpha=0.2, ax=ax2)\n\n# ax1.axis('equal')\n# ax2.axis('equal')\nf.show()","10e777e2":"data = pd.concat([df, pd.DataFrame(ag.labels_, columns=['Cluster_gmm'], index=df.index)], axis=1)\ndata = data[['Cluster_gmm'] + [col for col in data.columns if col != 'Cluster_gmm']]\n\nfor c in data.columns[1:]:\n    grid = sns.FacetGrid(data, col='Cluster_gmm', height=3, aspect=1.3)\n    grid.map(plt.hist, c, bins=20, edgecolor='k')\n    grid.set_xticklabels(rotation=40)\n\npd.DataFrame(data['Cluster_gmm'].value_counts())","97a0a37f":"Vizualize KMeans, number of clusters $\\overline{2, 9}$","2eb7a4d3":"Draw ellipse from: https:\/\/jakevdp.github.io\/PythonDataScienceHandbook\/05.12-gaussian-mixtures.html","b9f29c9c":"Add cluster number and grouping by features","024b49e3":"Optimal components PCA","d997dae5":"Add cluster number and grouping by features","86d4fa54":"Vizualize GaussianMixture, number of clusters $\\overline{2, 9}$ ","934ef429":"Read","ac6310fd":"## Reading and preprocessing","b360376f":"Add cluster number and grouping by features","a6e7d6f3":"## AgglomerativeClustering","ddc9c1f1":"Vizualize, numbers of clusters = 4","f919df47":"As a result, we can say that all three methods differ slightly from each other. Replacing the PCA is more likely to improve results.","04f66b4c":"Duplicated","9e9bdb61":"There are Outliers $\\rightarrow$ Robust","4fbfe32d":"Vizualize AgglomerativeClustering, number of clusters $\\overline{2, 9}$ ","766906af":"## GaussianMixture","9e20cea0":"Unbalanced and indistinguishable features $\\uparrow$. Sadly","51579df2":"## KMeans","7a438c8a":"## PCA","a6695976":"The result ~ was repeated","601d1c21":"Nans","b0ec83d3":"Error","5d3bef11":"PCA $\\leftarrow$ 2 components (for vizualize)","648ce509":"Vizualize, numbers of clusters = 4","779559b0":"## Libraries","9a905665":"Outliers in data (log scale)"}}