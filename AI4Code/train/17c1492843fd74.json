{"cell_type":{"54e4af6b":"code","d2de5005":"code","e7f4f313":"code","88672691":"code","678aa457":"code","d089123f":"code","565a8355":"code","2606323e":"code","430c4858":"code","e179c3c6":"code","cb72ccdd":"code","5eb84cb4":"code","8891a767":"code","5744b9d7":"code","6de82e5a":"code","e5d0e816":"code","3bf3d122":"code","34d18f90":"code","b8cc0d65":"code","45948ecb":"code","0366354e":"markdown","f41432ed":"markdown","20515b3c":"markdown","cd00e2a4":"markdown","e50da298":"markdown","e529c5f0":"markdown","a8c0f822":"markdown","bc9dea63":"markdown","9198ae2c":"markdown"},"source":{"54e4af6b":"\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","d2de5005":"train_dir = Path('..\/input\/famous-iconic-women\/output\/train')\ntest_dir = Path('..\/input\/famous-iconic-women\/output\/valid')\n\n# Get filepaths and labels\nfilepaths_train = list(train_dir.glob(r'**\/*.jpg'))\nfilepaths_test = list(test_dir.glob(r'**\/*.jpg'))","e7f4f313":"def proc_img(filepath):\n    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepath))\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df\n\ntrain_df = proc_img(filepaths_train)\ntest_df = proc_img(filepaths_test)\n\n\n# Show the result\ntrain_df.head(5)","88672691":"print(f'Number of training pictures: {train_df.shape[0]}')\nprint(f'Number of test pictures: {test_df.shape[0]}')","678aa457":"# Display 15 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(train_df.Filepath[i]))\n    ax.set_title(train_df.Label[i])\nplt.tight_layout()\nplt.show()","d089123f":"# This code fix an error, which would occur during the training otherwise\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True","565a8355":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","2606323e":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='training',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='validation',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","430c4858":"# Load the pretained model\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","e179c3c6":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(64, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=50,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","cb72ccdd":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","5eb84cb4":"pd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()","8891a767":"results = model.evaluate(test_images, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","5744b9d7":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","6de82e5a":"from sklearn.metrics import classification_report\ny_test = list(test_df.Label)\nprint(classification_report(y_test, pred))","e5d0e816":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (20,15))\nsns.heatmap(cf_matrix, annot=False, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix')\nplt.show()","3bf3d122":"# Display 15 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\nplt.tight_layout()\nplt.show()","34d18f90":"def show_by_label(label):\n    \"\"\"Display some pictures of the dataset by label    \n    \"\"\"\n    fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                            subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        tmp = train_df[train_df.Label == label]['Filepath'].iloc[i]\n        ax.imshow(plt.imread(tmp))\n    plt.tight_layout()\n    plt.show()\n","b8cc0d65":"# The label \"Estee Lauder\" doesn't show the woman behind the brand but her products\nshow_by_label('Estee Lauder')","45948ecb":"# It seems that Data Augmentation has been used\n# some pictures are duplicated by changing the zoom or the colours\nshow_by_label('Bessie Coleman')","0366354e":"\n<img src=\"https:\/\/i.imgur.com\/2WynUUt.png\"\/> ","f41432ed":"# Table of contents\n\n[<h3>1. Loading and preprocessing<\/h3>](#1)\n\n[<h3>2. Load the Images with a generator and Data Augmentation<\/h3>](#2)\n\n[<h3>3. Train the model<\/h3>](#3)\n\n[<h3>4. Visualize the result<\/h3>](#4)\n\n[<h3>5. Visualization of some pictures<\/h3>](#5)","20515b3c":"# Examples of prediction","cd00e2a4":"# 5. Visualization of some pictures<a class=\"anchor\" id=\"5\"><\/a>","e50da298":"# 1. Loading and preprocessing<a class=\"anchor\" id=\"1\"><\/a>","e529c5f0":"# 2. Load the Images with a generator and Data Augmentation<a class=\"anchor\" id=\"2\"><\/a>\n\nHaving in total around 3000 pictures with 64 different women, this makes around 50 pictures\/woman. Taking in consideration that the pictures are from very different perspectives and backrounds, 50 isn't a lot. The Data Augmentation on the fly, will generate new pictures by changing a bit each picture.","a8c0f822":"# 3. Train the model<a class=\"anchor\" id=\"3\"><\/a>","bc9dea63":"# 4. Visualize the result<a class=\"anchor\" id=\"4\"><\/a>","9198ae2c":"# Person Recognition with Deep Learning\n\nSimple algorithm for person recognition"}}