{"cell_type":{"8407da8b":"code","d1eb2c88":"code","965a7000":"code","00caf4d5":"code","07c9d94a":"code","241f6aea":"code","6166ec80":"code","767d5e43":"code","1d4d5496":"code","82a15199":"code","079fa187":"code","5295d4d7":"code","fda9e2fb":"code","ed12211e":"code","f634d3ea":"code","c815a630":"code","b63c8519":"code","2fb3a357":"code","28f5a59e":"code","5fc9bb63":"code","bbccc5c4":"code","9b260464":"code","d7cc0978":"code","f65fe4fa":"code","a0d6520a":"code","f47d7701":"code","45a5727c":"markdown","5138a308":"markdown","6f329f94":"markdown","5bf27f3d":"markdown","71610073":"markdown","67693db8":"markdown","2058de40":"markdown","32e44080":"markdown","6e4db912":"markdown","c4ba5847":"markdown","84f08dbf":"markdown","769ae49f":"markdown","1096e257":"markdown","1d11f54d":"markdown","4971f77a":"markdown"},"source":{"8407da8b":"import numpy as np       # linear algebra\nimport pandas as pd      # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf  # lib AI and numerical computing with tensores\n\n# keras\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, ZeroPadding2D\nfrom keras.models import Sequential\nfrom keras.optimizers import RMSprop\n\nfrom matplotlib import pyplot as plt\n\nfrom keras.utils.np_utils import to_categorical # data processing - convert to one-hot-encoding\n\nimport matplotlib.pyplot as plt # visualization\n%matplotlib inline\n\nimport os # comunication with operational system\nprint(os.listdir(\"..\/input\"))","d1eb2c88":"# lendo o dataset \ndata = pd.read_csv('..\/input\/train.csv')\n\n# labels\nx = data.drop(labels=[\"label\"], axis=1) \n\n# features\ny = data['label']\n\n# liberando mais espaco\ndel data\nprint(x.shape, y.shape)","965a7000":"# redimensiomado o array 784 em matrix de 28 x 28 em uma canal, imagem em tons de cinza\nx = x.values.reshape(-1,28,28,1)\nx.shape","00caf4d5":"fig,ax = plt.subplots(1,4, figsize=(12,5))\n\nfor i in range(4):\n    ax[i].imshow(x[i][:,:,0], cmap=\"gray\")","07c9d94a":"# as imagens s\u00e3o formadas de valores de 0 a 255, com essa rapida normaliza\u00e7\u00e3o, elas ficam na escala entre 0 e 1\nx = x \/ 255.0\n\n# \u00e9 melhor para o modelo de aprendizado de m\u00e1quina convergir valores de 0 a 1, do que 1 a 10, o aprendizado se torna mais r\u00e1pido\ny = to_categorical(y, num_classes=10)\nprint(x.shape, y.shape)","241f6aea":"from sklearn.model_selection import train_test_split\n# divide os dados de treino e validacao para setar no treinamento\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\ndel x\ndel y","6166ec80":"def simpleCNN(entrada, weights_path=None):\n    \n    model = Sequential()\n\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=entrada))\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(256, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation=\"softmax\"))\n\n    if weights_path:\n        model.load_weights(weights_path)\n\n    return model","767d5e43":"\n# definindo o model\nmodel = simpleCNN(x_train[1].shape)","1d4d5496":"\nmodel.compile(RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","82a15199":"print('-'*30)\nprint('treinando o modelo')\nlog = model.fit(x_train, y_train, batch_size=10, epochs=3)\n","079fa187":"log.history.keys()","5295d4d7":"# summarize history for loss\nplt.plot(log.history['acc'], '--go')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')","fda9e2fb":"# summarize history for loss\nplt.plot(log.history['loss'], '--ro')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')","ed12211e":"test_loss, test_acc = model.evaluate(x_test, y_test)","f634d3ea":"print('Accuracy: %.2f ' %(test_acc*100))\nprint('Loss: %.2f '  %(test_loss*100))","c815a630":"# imagens utilizadas para teste\n\nimagens_selecionadas = x_test[0:20,:,:,]\n\nfig,ax = plt.subplots(1,imagens_selecionadas.shape[0], figsize=(12,5))\n\nfor i in range(imagens_selecionadas.shape[0]):\n    ax[i].imshow(imagens_selecionadas[i,:,:,0], cmap=\"gray\")","b63c8519":"# fazendo a predi\u00e7\u00e3o sobre os dados de teste\npredicao = model.predict(imagens_selecionadas)","2fb3a357":"from sklearn.metrics import confusion_matrix\nimport itertools","28f5a59e":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt =  'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","5fc9bb63":"np.argmax(imagens_selecionadas)\n\ny_pred = []\ncorretas = []\n\nfor i in range(len(imagens_selecionadas)):\n    y_pred.append(np.argmax(predicao[i]))\n    corretas.append(np.argmax(y_test[i]))\n    \ncnf_matrix = confusion_matrix(corretas, y_pred)\ncnf_matrix","bbccc5c4":"plot_confusion_matrix(cnf_matrix, classes=['1','2','3','4','5','6','7','8','9'])","9b260464":"# lendo o dataset \ndata = pd.read_csv('..\/input\/test.csv')\ndata.head()","d7cc0978":"# tranformando o vetor em imagem\ntest = data.values.reshape(-1,28,28,1)\ntest.shape","f65fe4fa":"# normalizando os dados de teste\ntest = test \/  255.0\n\n# fazendo a predia\u00e7\u00e3o\nprevisoes_test = model.predict(test)","a0d6520a":"previsoes_test_label = []\n\nfor i in range(len(previsoes_test)):\n    previsoes_test_label.append(np.argmax(previsoes_test[i]))","f47d7701":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(previsoes_test_label)+1)),\n                         \"Label\": previsoes_test_label})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)","45a5727c":"## Avaliando o Modelo com os Dados de Teste","5138a308":"## Fazendo a prvis\u00e3o e submetendo o aquivo de submiss\u00e3o","6f329f94":"## Fazendo a classifica\u00e7\u00e3o","5bf27f3d":"## Conjunto de Dados\n\nMeu conjunto de dados se escontra na seguinte estrutura:\n   *  _train.csv_: possui os dados de treinamento, com a primeira coluna possuindo as classes, ou r\u00f3tulos, e as demais colunas possuem os valores dos pixeis da imagem, as caracter\u00edsticas.\n   * _test.csv_ : possui somente os valores dos pixeis, os labels ser\u00e3o previstos ap\u00f3s a classifica\u00e7\u00e3o do modelo de aprendizado de m\u00e1quina definido.\n   \n   \n","71610073":"## Normaliza\u00e7\u00e3o dos Dados \n","67693db8":"## Visualizando as imagens","2058de40":"Acontece que a precis\u00e3o no conjunto de dados de teste \u00e9 um pouco menor que a precis\u00e3o no conjunto de dados de treinamento. Essa lacuna entre a precis\u00e3o do treinamento e a precis\u00e3o do teste \u00e9 um exemplo de overfitting. O overfitting \u00e9 quando um modelo de aprendizado de m\u00e1quina apresenta um desempenho pior em novos dados do que em seus dados de treinamento.","32e44080":"##  Separa\u00e7\u00e3o dos Dados para Treinamento e Teste\n\nPara treinar e testar o modelo de aprendizado de m\u00e1quina, ser\u00e3o definido 4 vari\u00e1veis:\n   * **y_train**:  Cont\u00e9m os valores das classes, respons\u00e1vel para ser a sa\u00edda desejada do conjunto _x_train_. \n   * **x_train**: Cont\u00e9m somente os valores do pixeis, \u00e9 o conjunto de caracter\u00edsticas que ensina ao modelo o que aquela classe \u00e9 composta, a rede n\u00e3o aprende os valores do pixeis, mas um padr\u00e3o em comum nesses dados.  _x_train_ e _y_train_ s\u00e3o usados somente na etapa de treinamento.\n   * **x_test**: semelhate a _x_train_, mas se difere por serem imagens distintas das usadas pra treinamento e s\u00e3o usadas somente na etapa de teste.  o Intuito em usar dados diferentes aos treinados \u00e9 avaliar a capacidade de generaliza\u00e7\u00e3o da rede, ou seja, ver o qu\u00e3o bom meu modelo \u00e9 preciso em classificar dados com representa\u00e7\u00f5es distintas da mesma classe.\n   * **y_test**: semelhate a _y_train_, mas se difere por ser usado somente na etapa de teste e \u00e9 utilizado para comparar com a sa\u00edda da classifica\u00e7\u00e3o do modelo, e validar quais predi\u00e7\u00f5es ele classificou corretamente.\n   \n Na biblioteca _sklearn_ tem um fun\u00e7\u00e3o que realiza essa serapa\u00e7\u00e3o informando  a porcentagem opcional dos dados de teste e treino.\n \n\n","6e4db912":"## Visualizando a matriz de confus\u00e3o","c4ba5847":"## Definindo o modelo de aprendizado de m\u00e1quina\n\nO bloco de constru\u00e7\u00e3o b\u00e1sico de uma rede neural \u00e9 a camada. As camadas extraem representa\u00e7\u00f5es dos dados alimentados nelas. E, esperan\u00e7osamente, essas representa\u00e7\u00f5es s\u00e3o mais significativas para o problema em quest\u00e3o. O modelo foi contru\u00eddo com as sequintes camadas: \n\n * A primeira camada **Flatten**, transforma o formato das imagens de uma matriz 2d (de 28 por 28 pixels), para uma matriz 1d de 28 * 28 = 784 pixels. Essa camada n\u00e3o tem par\u00e2metros para aprender; s\u00f3 reformata os dados.\n\n * A camada **Dense** \u00e9 a camda oculta totalmente conectadas. A primeira camada Densa possui 128 n\u00f3s (ou neur\u00f4nios). A segunda (e \u00faltima) camada \u00e9 uma camada softmax de 10 n\u00f3s - isso retorna uma matriz de 10 pontua\u00e7\u00f5es de probabilidade que somam 1. Cada n\u00f3 cont\u00e9m uma pontua\u00e7\u00e3o que indica a probabilidade de a imagem atual pertencer a uma das 10 classes.\n \n * **Dropout** consiste em configurar aleatoriamente uma taxa de fra\u00e7\u00e3o de unidades de entrada para 0 a cada atualiza\u00e7\u00e3o durante o tempo de treinamento, o que ajuda a evitar o overfitting. \n\n","84f08dbf":"## Visualizado Acur\u00e1cia e Perda no Treinamento","769ae49f":"Em busca de aumentar, seus conhecimentos de aprendizado de m\u00e1quina ? Vote no **kernel** para incentivar o desenvolvimento de mais problemas.\n\n## Refer\u00eancias\n * [Get Started with TensorFlow](https:\/\/www.tensorflow.org\/tutorials\/)\n * [Matrix de confus\u00e3o](http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html)\n * [NN Beginners](https:\/\/medium.com\/@judyshih318\/use-keras-to-build-the-first-simple-neural-network-as-a-beginner-8f0f2f6427e0)","1096e257":"As imagens est\u00e3o em uma dimens\u00e3o, um vetor de tamanho N. Para tranfomar em uma imagem o vetor ser\u00e1 redimensionado para  uma matrix 28 x 28.","1d11f54d":"## Compilando o  modelo\n\nAntes de o modelo estar pronto para o treinamento, ele precisa de mais algumas configura\u00e7\u00f5es. Estes s\u00e3o adicionados durante a etapa de compila\u00e7\u00e3o do modelo:\n * **Loss Function**: Isso mede a precis\u00e3o do modelo durante o treinamento. Queremos minimizar essa fun\u00e7\u00e3o para \"guiar\" o modelo na dire\u00e7\u00e3o certa.\n * **Optimizer** - \u00e9 assim que o modelo \u00e9 atualizado com base nos dados que ele v\u00ea e na sua fun\u00e7\u00e3o de perda.\n * **Metrics**: Usado para monitorar as etapas de treinamento e teste. O exemplo a seguir usa _accuracy_, a fra\u00e7\u00e3o das imagens que s\u00e3o classificadas corretamente.\n","4971f77a":"## Treinando o modelo\nPara come\u00e7ar o treinamento, chame o m\u00e9todo _model.fit_ - o modelo \u00e9 \"adequado\" aos dados de treinamento passando **x_train** e **y_train**. "}}