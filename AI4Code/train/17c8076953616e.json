{"cell_type":{"29c6906c":"code","d4c5c6dd":"code","64a1b465":"code","f88935fa":"code","ffdd6231":"code","415cdc8b":"code","f2d018e9":"code","c66d83c6":"code","334efa61":"code","99dd6dd9":"code","37dfa59a":"code","405f9cfe":"code","cad107fb":"code","16efe6c4":"code","4d3c41aa":"code","b13b4b75":"code","3a76398f":"code","193dd1a6":"code","5964ffa1":"code","1370cd79":"code","3b9f0ca1":"code","d6d104db":"code","642e0818":"code","4c239e73":"code","dc18e966":"code","1882e7b3":"code","a3c6d9a0":"code","2570d09b":"code","f6994b6c":"code","a93fde76":"code","19b151c6":"code","309e24af":"code","a2ad7b98":"code","531e8d40":"code","6cd1eea4":"code","a59c7a6d":"code","eb7364ad":"code","fab81551":"markdown","0c806c0f":"markdown","8adbcb4c":"markdown","5ac0cdd2":"markdown","c2673776":"markdown","f7809415":"markdown","8cd8277f":"markdown","75da68a3":"markdown"},"source":{"29c6906c":"import numpy as np # matrix tools\nimport matplotlib.pyplot as plt # for basic plots\nimport seaborn as sns # for nicer plots\nimport pandas as pd\nfrom glob import glob\nimport re\nfrom skimage.io import imread\n\nimport keras","d4c5c6dd":"%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname,\"______\")\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","64a1b465":"BASE_IMG_PATH=os.path.join('..','kaggle\/input')\npath= os.path.join(BASE_IMG_PATH,'overview.csv')\noverview = pd.read_csv(path)\noverview.head()","f88935fa":"len(overview)","ffdd6231":"overview['Contrast'] = overview['Contrast'].map(lambda x: 1 if x else 0)","415cdc8b":"plt.figure(figsize=(10,5))\nsns.distplot(overview['Age'])","f2d018e9":"g = sns.FacetGrid(overview, col=\"Contrast\", size=8)\ng = g.map(sns.distplot, \"Age\")","c66d83c6":"g = sns.FacetGrid(overview, hue=\"Contrast\",size=6, legend_out=True)\ng = g.map(sns.distplot, \"Age\").add_legend()","334efa61":"BASE_IMG_PATH=os.path.join('..','kaggle\/input')\nprint(os.path.join(BASE_IMG_PATH,'tiff_images','*.tif'))\nall_images_list = glob(os.path.join(BASE_IMG_PATH,'tiff_images','*.tif'))\nall_images_list[:5]\nprint(all_images_list)","99dd6dd9":"imread(all_images_list[0]).shape","37dfa59a":"np.array(np.arange(81)).reshape(9,9)","405f9cfe":"np.array(np.arange(81)).reshape(9,9)[::3,::3]","cad107fb":"np.expand_dims(imread(all_images_list[0])[::4,::4],0).shape","16efe6c4":"jimread = lambda x: np.expand_dims(imread(x)[::2,::2],0)","4d3c41aa":"test_image = jimread(all_images_list[0])\nplt.imshow(test_image[0])","b13b4b75":"check_contrast = re.compile(r'data\\\\tiff_images\\\\ID_([\\d]+)_AGE_[\\d]+_CONTRAST_([\\d]+)_CT.tif')\nlabel = []\nid_list = []\nfor image in all_images_list:\n    id_list.append(check_contrast.findall(image)[0][0])\n    label.append(check_contrast.findall(image)[0][1])","3a76398f":"label_list = pd.DataFrame(label,id_list)","193dd1a6":"label_list.head()","5964ffa1":"images = np.stack([jimread(i) for i in all_images_list],0)","1370cd79":"len(images)","3b9f0ca1":"from sklearn.model_selection import train_test_split","d6d104db":"X_train, X_test, y_train, y_test = train_test_split(images, label_list, test_size=0.1, random_state=0)","642e0818":"n_train, depth, width, height = X_train.shape\nn_test,_,_,_ = X_test.shape","4c239e73":"n_train,depth, width, height","dc18e966":"input_shape = (width,height,depth)","1882e7b3":"input_shape","a3c6d9a0":"input_train = X_train.reshape((n_train, width,height,depth))\ninput_train.shape\ninput_train.astype('float32')\ninput_train = input_train \/ np.max(input_train)\ninput_train.max()","2570d09b":"input_test = X_test.reshape(n_test, *input_shape)\ninput_test.astype('float32')\ninput_test = input_test \/ np.max(input_test)","f6994b6c":"output_train = keras.utils.to_categorical(y_train, 2)\noutput_test = keras.utils.to_categorical(y_test, 2)\noutput_train[5]","a93fde76":"input_train.shape","19b151c6":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.layers import Conv2D, MaxPooling2D","309e24af":"batch_size = 20\nepochs = 40","a2ad7b98":"model2 = Sequential()\nmodel2.add(Conv2D(50, (5, 5), activation='relu', input_shape=input_shape))\n # 32\uac1c\uc758 4x4 Filter \ub97c \uc774\uc6a9\ud558\uc5ec Convolutional Network\uc0dd\uc131\nmodel2.add(MaxPooling2D(pool_size=(3, 3))) # 3x3 Maxpooling \nmodel2.add(Conv2D(30, (4, 4), activation='relu', input_shape=input_shape))\nmodel2.add(MaxPooling2D(pool_size=(2, 2))) # 2x2 Maxpooling \nmodel2.add(Flatten()) # \ucb49\ud480\uc5b4\uc11c Fully Connected Neural Network\ub97c \ub9cc\ub4e0\ub2e4. \nmodel2.add(Dense(2, activation='softmax'))","531e8d40":"model2.summary()","6cd1eea4":"model2.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","a59c7a6d":"history = model2.fit(input_train, output_train,\n                    batch_size=batch_size,\n                    epochs=epochs,\n                    verbose=1,\n                    validation_data=(input_test, output_test))","eb7364ad":"score = model2.evaluate(input_test, output_test, verbose=0)\nscore","fab81551":"## Split Data to Train, Test","0c806c0f":"## Reshape image Data ","8adbcb4c":"## Network","5ac0cdd2":"## Exploratory data analysis","c2673776":" - np.expand_dims -> Expand the shape of an array.\n  - Insert a new axis, corresponding to a given position in the array shape.","f7809415":"# Constrast Cancer Classification","8cd8277f":"## Read Image Files ","75da68a3":"## Model 2"}}