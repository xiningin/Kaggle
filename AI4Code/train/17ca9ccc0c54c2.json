{"cell_type":{"a64b9dc0":"code","7ed1b3e9":"code","126c2cf7":"code","278af0a6":"code","aea8e50c":"code","4c656b68":"code","3358c142":"code","63f6a0c3":"code","520684b5":"code","de1d0390":"code","5dcbafd5":"code","5fe4149c":"code","87ce07a4":"code","4d34cf96":"code","b854af0d":"code","b46dc71d":"code","3cfd378d":"code","10fef151":"code","7eea3d4a":"code","10781b5f":"code","113b39aa":"code","0b30532d":"markdown","25b57393":"markdown","3baf3d72":"markdown","79d4dda5":"markdown","c080d3b0":"markdown","e434869c":"markdown","7fea92ad":"markdown","a135bf28":"markdown","97293386":"markdown","6bc7db95":"markdown","fc7d42e3":"markdown","592d7dbe":"markdown","a3ac4196":"markdown","a7f06172":"markdown","7177d402":"markdown","9015d0b4":"markdown","642e2480":"markdown","4a3278ac":"markdown","c18f3380":"markdown","b72ad68f":"markdown","acb5079d":"markdown","1f6fb343":"markdown","7adefdde":"markdown"},"source":{"a64b9dc0":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","7ed1b3e9":"tf.__version__","126c2cf7":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv('\/kaggle\/input\/churn-modeling-dataset\/Churn_Modelling.csv') \ndata.head()","278af0a6":"x=data.iloc[:,3:-1].values #excluding the first 3 rows because they are not so important\ny=data.iloc[:,-1].values","aea8e50c":"x","4c656b68":"y","3358c142":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nx[:,2]=le.fit_transform(x[:,2])","63f6a0c3":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct=ColumnTransformer(transformers=[(\"encoder\", OneHotEncoder(), [1])], remainder=\"passthrough\")\nx=np.array(ct.fit_transform(x))","520684b5":"print(x)","de1d0390":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=9)","5dcbafd5":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nx_train=ss.fit_transform(x_train)\nx_test=ss.transform(x_test)","5fe4149c":"ann=tf.keras.models.Sequential() \n# this creates  a ANN variable,which represents our artificial neural network,\n#created as an instance of that sequential class which initializes artificial neural network","87ce07a4":"ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\")) ## to know what is the number, just needs an experimentation\n#in this dense function now,  we can specify,  how many hidden neurons we want to have.","4d34cf96":"ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\")) ","b854af0d":" ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\")) ## to know what is the number, just needs an experimentation\n# having a sigmoid activation function allows to get not only ultimately the predictions,\n#but the probabilities that the binary outcome is one.","b46dc71d":"ann.compile(optimizer= \"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n#what's the Cassey gradient descent allows to do?\n# it is what will update the weights in order to reduce the loss error between your predictions and the real results.","3cfd378d":"ann.fit(x_train, y_train, batch_size=32,epochs=100)","10fef151":"ann.predict(ss.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]])) > 0.5\n# the probability the the customer will leave the bank\n#2d array\n#2% of leaving the bank","7eea3d4a":"y_pred=ann.predict(x_test)\ny_pred=(y_pred>0.5)\n\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","10781b5f":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm=confusion_matrix(y_test, y_pred)\ncm","113b39aa":"accuracy_score(y_test, y_pred)","0b30532d":"## Feature Scalling \nvery fundamental for deep learning... so we apply feature scalling for everything","25b57393":"First, we create a variable that will be nothing else than the artificial neural network itself.This artificial neural network viable will be created as an object of a certain class. And that certain class is the sequential class, which allows exactly to build an artificial neural network.","3baf3d72":"## Compiling the ANN\n","79d4dda5":"which means... that the customer will not exit the bank","c080d3b0":"## Predicting the test set results\n","e434869c":"## Splitting the dataset for Training and Tes set","7fea92ad":"-- batch_size\nThe batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters. (https:\/\/machinelearningmastery.com\/difference-between-a-batch-and-an-epoch\/)\nbatch size, because indeed batch learning is always more efficient and more performant when training in artificial new network.\n\n\n\nThe batch size parameter gives exactly the number of predictions you want to have in the batch to be compared to that same number of real results. Classic value is 32\n\n-- epochs\n\n a neural network has to be trained over a certain amount of Epochs\n\nSo as to improve the accuracy over time.\nThe number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n\nOne epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches - The number of epochs is traditionally large, often hundreds or thousands, allowing the learning algorithm to run until the error from the model has been sufficiently minimized.(https:\/\/machinelearningmastery.com\/difference-between-a-batch-and-an-epoch\/)","a135bf28":"# Building the ANN","97293386":"## Importing the Dataset","6bc7db95":"# Part 3 - Traiing the ANN","fc7d42e3":"### Label Encoding the Gender Column","592d7dbe":"## Initializing the ANN\n","a3ac4196":"### One Hot Encoding for the Geography Column","a7f06172":"## Adding the input layer and the first hidden layer\n","7177d402":"-- metrics--\nwe can actually choose several metrics at the same time.","9015d0b4":"## Homework\nUse our ANN model to predict if the customer with the following informations will leave the bank:\n\nGeography: France\n\nCredit Score: 600\n\nGender: Male\n\nAge: 40 years old\n\nTenure: 3 years\n\nBalance: $ 60000\n\nNumber of Products: 2\n\nDoes this customer have a credit card? Yes\n\nIs this customer an Active Member: Yes\n\nEstimated Salary: $ 50000\n\nSo, should we say goodbye to that customer?","642e2480":"## Training the ANN on the Training Set","4a3278ac":"-- loss-- \nWhen you are doing binary classification, you know, classification, when you have to predict a binary outcome.\n\nWell, the lost function must always be \"binary_crossentropy\"\n\nif you were doing non binary classification. (You know, like, for example, predicting three different categories.) here you would have to enter a \"category_crossentropy\" loss.\n","c18f3380":"-- optimizer--- when we trained in and on the training set, we will at each iteration.\n\nCompare the predictions in a batch to the real results in the same batch.\n\nAnd that optimizer here will update the weights through stochastic gradient descent ","b72ad68f":"## Adding the output layer\n","acb5079d":"# Data Preprocessing","1f6fb343":"## Adding the second hidden layer\n","7adefdde":"## Encoding Categorical Data"}}