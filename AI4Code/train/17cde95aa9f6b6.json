{"cell_type":{"c27605ec":"code","38d094c4":"code","653728ab":"code","a161a313":"code","364238bc":"code","0f88d4d0":"code","1a690ce2":"code","6ab22d01":"code","da6b227f":"code","76dccde4":"code","970dd442":"code","ac37e00d":"code","07c54d74":"code","ce492520":"code","d92618e7":"code","f8026f36":"code","94ff2982":"code","892d7db9":"markdown","7d6a9f34":"markdown","cb06b3a9":"markdown","b3c73fac":"markdown","725a0030":"markdown","05edd7c1":"markdown","5db57f0a":"markdown","9f0b1845":"markdown","469ccb28":"markdown"},"source":{"c27605ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38d094c4":"%matplotlib ipympl\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom matplotlib.animation import FuncAnimation\nfrom matplotlib.lines import Line2D\nfrom IPython.display import HTML\n\n# from matplotlib import animation, rc","653728ab":"survey_2021 = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv', dtype='string')\nsurvey_2020 = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv', dtype='string')\nsurvey_2019 = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv', dtype='string')\nsurvey_2018 = pd.read_csv('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv', dtype='string')\n\nlist_surveys = [survey_2018, survey_2019, survey_2020, survey_2021]","a161a313":"# list in order of 2017 ~ 2021\ngroups = {\n    'Age': ['Q2', 'Q1', 'Q1', 'Q1'],\n    'Gender': ['Q1', 'Q2', 'Q2', 'Q2'],\n    'Job Title': ['Q6', 'Q5', 'Q5', 'Q5'],\n    'Programming Experience': [np.nan, np.nan, 'Q6', 'Q6'],\n    'ML Experience': ['Q25', 'Q23', 'Q15', 'Q15'],\n    'Compensation': ['Q9', 'Q10', 'Q25', 'Q25'],\n    'Industry': ['Q7', np.nan, 'Q4', 'Q4'],\n    \n    'Programming Language': ['Q16_', 'Q18_', 'Q7_', 'Q7_'],\n    'IDE': ['Q13_', 'Q16_', 'Q9_', 'Q9_'],\n    'Notebook': ['Q14_', 'Q17_', 'Q10_', 'Q10_'],\n    'Specialized Hardware': [np.nan, 'Q21_', 'Q12_', 'Q12_'],\n    'Visualization Libraries\/Tools': ['Q21_', 'Q20_', 'Q14_', 'Q14_'],\n    'ML Frameworks': ['Q19_', 'Q28_', 'Q16_', 'Q16_'],\n    'ML Algorithms': [np.nan, 'Q24_', 'Q17_', 'Q17_'],\n    'CV Algorithms': [np.nan, 'Q26_', 'Q18_', 'Q18_'],\n    'NLP Methods': [np.nan, 'Q27_', 'Q19_', 'Q19_'],\n    'Important Part of Work': ['Q11_', 'Q24_', 'Q24_', 'Q24_'],\n    'Computing Platform': ['Q15_', 'Q29_', 'Q26_', 'Q27_'],\n    \n# Cloud platforms: GCP, AWS, Microsoft Azure, IBM\n#     'Daily Cloud Platforms': 'Q27_A_',\n#     'Cloud Products': 'Q27_A_'\n#     'Data Storage Products': 'Q30_A_',\n#     'Big Data Products': 'Q32_A_',\n#     'Data Analysis Tools': 'Q41'\n\n    'Language Recommendation': ['Q18', 'Q19', 'Q8', 'Q8'],\n    'Courses': ['Q36_', 'Q13_', 'Q40_', 'Q40_'],\n    'Favorite Media Source': ['Q38_', 'Q12_', 'Q42_', 'Q42_'],\n    'Tools to Share Projects': ['Q49_', np.nan, 'Q39_', 'Q39']\n}\n\nyear_df = {\n    0: '2018',\n    1: '2019',\n    2: '2020',\n    3: '2021'\n}","364238bc":"# Cleaning Functions\n\n# Get df for using and rec without questions by given Q: 'Q6_' or 'Q7'\ndef get_df(df, Q):\n    if pd.isna(Q):\n        return None\n    elif Q[-1] == '_':\n        result = df.loc[1:, df.columns.str.startswith(Q)]\n    else:\n        result = df.loc[1:, [Q]]\n    return result\n\n# 2018, 2019\n# change -1 to np.nan and others to 'Other'\ndef change_other(x):\n    if x != -1 and x != '-1':\n        return 'Other'\n    else:\n        return np.nan\n    \n# For Using df with multiple columns\ndef change_columns(df): \n    columns = []\n    for col in df.columns:\n        val = df[col].unique()\n        val = [x for x in val if not pd.isna(x)][0]\n        columns.append(val)\n    df.columns = columns\n    return df\n\n# For Rec df with single column\ndef format_values(df): \n    vals = df.values.flatten().tolist()\n    columns = np.unique([x for x in vals if not pd.isna(x)])\n    results = pd.DataFrame(index=df.index, columns=columns)\n\n    for col in columns:\n        idx = df[df.iloc[:, 0] == col].index\n        results.loc[idx, col] = col\n\n    return results\n\n# Groupby given group G: 'Age'\ndef group_by(survey, groups, i, group_name, df):\n    if groups[group_name] is None:\n        return None\n    col = groups[group_name][i]\n    group_col = survey.loc[1:, col]\n    group_col.name = group_name\n    grouped = (pd.concat([group_col, df], axis=1).groupby(group_name)).count()\n    return grouped\n\n\ndef get_df_by_group(group_name, variable_name):\n    # Combined responses of all surveys and groups.\n    combined = []\n    for i in range(len(list_surveys)):\n        df = get_df(list_surveys[i], groups[variable_name][i])\n        if df is None:\n            combined.append(None)\n        else:\n            if df.shape[1] == 1:\n                df = format_values(df)\n            else:\n                # if -1 exists in other (2018-2019), apply (change_other)\n                if i in [0, 1]:\n                    df.iloc[:, -1] = df.iloc[:, -1].apply(change_other)\n                df = change_columns(df)\n            grouped = group_by(list_surveys[i], groups, i, group_name, df)\n            combined.append(grouped)\n    return combined","0f88d4d0":"temp = get_df_by_group('Compensation', 'Computing Platform')\n\ntemp[3].empty","1a690ce2":"def animate_X_by_Group(fig, axes, G, X):\n#     plt.close('all')\n    fig.suptitle(f'Trend of {X} Grouped by {G} for each Year')\n    datas = get_df_by_group(G, X)\n    \n    \n    max_values = []\n    # max_value\n    for df in datas:\n        if not df.empty:\n            max_values.append(max(df.values.flatten()) + 200)\n        else:\n            max_values.append(None)\n    \n    def animate(frame):\n        for i, ax in enumerate(axes.flatten()):\n            if max_values[i]:\n                data = datas[i].sort_values(by=datas[i].index[0], axis=1)\n\n                ax.clear()\n                ax.set_ylim([0, max_values[i]])\n\n                group = data.iloc[frame, :]\n\n                rects = ax.bar(group.index, group.values, color=None)\n                ax.bar_label(rects, labels=group.values)\n\n                title = ax.set_title(f'Year {str(year_df[i])}: {G} {group.name}')\n                plt.setp(ax.get_xticklabels(), rotation=-45, horizontalalignment='left')\n\n                top_5 = group.sort_values(ascending=False).iloc[:5]\n                top_5 = [i + ': ' + str(j) for i, j in zip(top_5.index, top_5.values)]\n                custom_lines = [Line2D([0], [0],  lw=4),\n                                Line2D([0], [0],  lw=4),\n                                Line2D([0], [0],  lw=4),\n                               Line2D([0], [0], lw=4),\n                                Line2D([0], [0], lw=4)]\n                legs = ax.legend(custom_lines, top_5, title=f'Top 5 {X}',\n                               title_fontsize='large', fontsize='medium',\n                               loc=2)\n            else:\n                pass\n        return axes, rects\n\n    ani = FuncAnimation(fig, animate, frames=len(datas), repeat=True, interval=2000, blit=False)\n        \n    return ani","6ab22d01":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'Compensation', 'Programming Language')\nplt.close()","da6b227f":"HTML(result.to_jshtml())","76dccde4":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'ML Experience', 'Visualization Libraries\/Tools')\nplt.close()","970dd442":"HTML(result.to_jshtml())","ac37e00d":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'ML Experience', 'ML Frameworks')\nplt.close()","07c54d74":"HTML(result.to_jshtml())","ce492520":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'Compensation', 'Computing Platform')\nplt.close()","d92618e7":"HTML(result.to_jshtml())","f8026f36":"fig, axes = plt.subplots(2, 2, figsize=(12, 12))\nplt.subplots_adjust(top = 0.9, bottom=0.1, right=0.9, left=0.1, hspace=0.3, wspace=0.3)\nresult = animate_X_by_Group(fig, axes, 'Compensation', 'Courses')\nplt.close()","94ff2982":"HTML(result.to_jshtml())","892d7db9":"# 1) Language Used Grouped by Compensation\n\n### Python came in first in all groups and all years.\n### SQL came in strong second.\n<br>\n<br>\n\n### And other languages such as Javascript, C++, R, and Bash appeared in the top 5 languages.\n\n#### My intuition is that Python is the primary language of data science and artificial intelligence\n#### And Javascript, SQL, C++, R, and Bash are used to create and manipulate website interactions, embedded systems, and operating systems.","7d6a9f34":"# Wrapping Things Up...\n\n<br>\n<br \/>\n\n### What I am excited about:\n### - Expanding data science community. (Stack Overflow, Kaggle, Youtube...). I had so many people help me create these visualizations and I can't thank them enough.\n### - Improving documentations (Matplotlib, Seaborn, Tensorflow, PyTorch, Keras) that accelerate data science projects.\n### - Powerful technologies that are being developed by big companies that give immense computing powers to individuals like me.\n### - Learning more about data visualizations and artificial intelligence. There are lots of room for improvement (speed, accuracy, publications, revisions).\n\n<br \/>\n\n### Improvements I could have made: \n### - I could have cleaned the data a lot more to allow for more robust data analysis.\n### - I could have tried different kinds of plots such as scatter plot and 3d animations.\n### - I could have came up with more intereseting subsets.","cb06b3a9":"### The first thing I want to know is \n####    - Group by expertise\n####       - Ex. Age, job title, ML experience, compensation.\n####    - Why? Qualify each responses by their expected expertise.\n   ","b3c73fac":"## Let's See What We Got!","725a0030":"# Courses Completed or Started Grouped by Compensation for each Year\n\n\n### - Data scientists have been using courses such as,\n### - Coursera, Kaggle, Universities, Udemy, DataCamp, and edX.\n\n<br\/>\n** Kaggle did not ask this question in the year 2020\n<br\/> \n\n### Most of these courses are free or sold at an affordable price, so it's a great idea to start studying them.\n### My intuition is that AI education and consulting will play as a huge catalyst to the AI revolution.","05edd7c1":"# Computing Platform Grouped by Compensation for each Year\n\n## The plot reveals a clear trend:\n### - Data scientists began ramping up Cloud Services usage.\n### - AWS, Google Cloud Platform, Microsoft Azure are same big names out there currently.\n\n<br\/> \n\n### Like other categories, we expect the usage in the top 5 platforms to increase.\n### Cloud computing platforms allow data scientists to leverage the power of data centers to analyze data and train machine learning models.","5db57f0a":"# ML Frameworks Grouped by ML Experience\n\n## The plot reveals a popularity in\n### - Scikit-Learn,\n### - Then TensorFlow, Keras, and PyTorch,\n### - and Xgboost and RandomForest.\n\n<br\/> \n\n### Similar to programming languages, machine learning frameworks and tools seem to be growing in users.\n### This may be due to rapid developments and advances in machine learning communities.\n### It's quiet awesome to see the numbers at the beginning of an exponential growth of the data science community!\n","9f0b1845":"# 2) Visualization Libraries\/Tools grouped by ML Experience\n\n### - Matplotlib seems to be the go-to choice for visualizations.\n### - Seaborn, which is built on top of Matplotlib, came in second.\n### - Ggplot2, Plotly, Shiny (for R), and Geoplotlib (geo-data) came in the top 5.\n\n\n<br>\n<br>\n\n\n#### I used Matplotlib to create data visualizations and animations.\n#### It allows flexibility and versatility, which, combined with other visualization tools, can help data scientists tremendously.","469ccb28":"# Kaggle 2021 Survey Data Visualization\n\n<br>\n<br>\n\n\n## Let's find out trends in relevant ML-related tools and algorithms.\n### - This can be helpful for students and beginners who want to learn practical ML.\n### - We can also use data to see what \"the world\" is doing."}}