{"cell_type":{"8afcc7f8":"code","dd421f43":"code","7cb58a31":"code","ce23866f":"code","bd876780":"code","885f74d0":"code","5b5cad1e":"code","ec616172":"code","bf8170c6":"code","59b3694c":"code","5f167d06":"code","bbd8f7c6":"code","97bd0eae":"code","acc11408":"code","adafeb77":"code","05277a8d":"code","58c7a6b7":"code","e2405a60":"code","f54ae66b":"code","32ba68ff":"code","da22402d":"markdown","a089b2e3":"markdown","bf133d7e":"markdown","8e7ee38f":"markdown","da5c4b8e":"markdown","8d07f893":"markdown","0d3596a1":"markdown","7eb465b1":"markdown"},"source":{"8afcc7f8":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nimport pydicom\nimport cv2","dd421f43":"train_image = pd.read_csv('..\/input\/siim-covid19-detection\/train_image_level.csv')\ntrain_study = pd.read_csv('..\/input\/siim-covid19-detection\/train_study_level.csv')\nprint('shape of train_image:', train_image.shape)\ntrain_image.head()","7cb58a31":"print('shape of train_study:', train_study.shape)\ntrain_study.head()","ce23866f":"TRAIN_DIR = '..\/input\/siim-covid19-detection\/train'\nTEST_DIR = '..\/input\/siim-covid19-detection\/test'","bd876780":"# take first example and get path to it\nfrom os import walk, listdir\nimage_dir = train_image['StudyInstanceUID'][0]\npath_to_img = TRAIN_DIR + '\/' + image_dir \npath_to_img = path_to_img +'\/' + listdir(path_to_img)[0] \npath_to_img = path_to_img + '\/' + next(walk(path_to_img))[2][0]","885f74d0":"data = pydicom.dcmread(path_to_img)\n# get the pixel information into a numpy array\nimg = data.pixel_array\nprint('The image has {} x {} voxels'.format(img.shape[0],\n                                            img.shape[1]))","5b5cad1e":"print(img, img.shape)","ec616172":"import matplotlib.pyplot as plt\nplt.imshow(img, cmap='gray')\nplt.show()","bf8170c6":"# this can help with increasing the contrast\nfrom skimage import exposure\nequ_img = exposure.equalize_hist(img)\nplt.imshow(equ_img, cmap='gray')\nplt.show()","59b3694c":"equ_img","5f167d06":"box1 = train_image.label[0].split()[:6]\nbox2 = train_image.label[0].split()[6:]\nimg = cv2.rectangle(img,(int(float(box1[2])), int(float(box1[3]))), \n                    (int(float(box1[4])), int(float(box1[5]))),\n                    color=(0, 0, 0), thickness=15)\n\nimg = cv2.rectangle(img,(int(float(box2[2])), int(float(box2[3]))), \n                    (int(float(box2[4])), int(float(box2[5]))),\n                    color=(0, 0, 0), thickness=15)\nplt.imshow(img, cmap='gray')\nplt.show()","bbd8f7c6":"# now on image with equalize_hist\nequ_img = cv2.rectangle(equ_img,(int(float(box1[2])), int(float(box1[3]))), \n                    (int(float(box1[4])), int(float(box1[5]))),\n                    color=(0, 0, 0), thickness=15)\n\nequ_img = cv2.rectangle(equ_img,(int(float(box2[2])), int(float(box2[3]))), \n                    (int(float(box2[4])), int(float(box2[5]))),\n                    color=(0, 0, 0), thickness=15)\nplt.imshow(equ_img, cmap='gray')\nplt.show()","97bd0eae":"shape1, shape2, ratios = [], [], []\nfor study_id in set(train_image.StudyInstanceUID):\n    path1 = TRAIN_DIR + '\/' + study_id \n    for p in listdir(path1):\n        path_to_img = path1 +'\/' + p\n        path_to_img = path_to_img + '\/' + next(walk(path_to_img))[2][0]\n        data = pydicom.dcmread(path_to_img)\n        sh1 = data.Rows\n        sh2 = data.Columns\n        shape1.append(sh1)\n        shape2.append(sh2)\n        ratios.append(sh1\/sh2)","acc11408":"plt.hist(shape1, bins=20)\nplt.title('Height of the images')\nplt.show()\nplt.hist(shape2, bins=20)\nplt.title('Width of the images')\nplt.show()\nplt.hist(ratios, bins=20)\nplt.title('Height to width ratio of the images')\nplt.show()","adafeb77":"# the studies in train_study_level.csv file aren't multilabeled:\nlabels_sum = train_study.iloc[:,1:].sum(axis=1)\nprint('Min number of labels:', min(labels_sum))\nprint('Max number of labels:', max(labels_sum))","05277a8d":"train_study.iloc[:,1:].sum().plot(kind='bar', figsize=(10,6), grid=True, rot=0,\n                                  title='Frequency of the labels', width=2\/3)\nplt.show()","58c7a6b7":"train_image.StudyInstanceUID.value_counts().plot(kind='hist', logy=True, bins=np.arange(1,11)-0.5,\n                                           xticks=range(1,10), title='Number of images per study',\n                                           figsize=(10,6), rwidth=0.9)\nplt.show()\nprint(train_image.StudyInstanceUID.value_counts().value_counts())","e2405a60":"n_nan = train_image.boxes.isna().sum()\nn_boxes = len(train_image.boxes) - n_nan\nprint(f'There are {n_boxes} images with boxes and {n_nan} images without any boxes.')","f54ae66b":"print('Labels of images with no boxes')\ntrain_study[train_study.id.str.split('_').str[0].isin(set(train_image[train_image.boxes.isna()].StudyInstanceUID))].iloc[:,1:].sum()","32ba68ff":"print('Labels of images with boxes')\ntrain_study[train_study.id.str.split('_').str[0].isin(set(train_image[~train_image.boxes.isna()].StudyInstanceUID))].iloc[:,1:].sum()","da22402d":"# IMAGE DATA\n\nThis is how you can get to an image:","a089b2e3":"For most of the studies (5822 out of 6334) there is only 1 image but for some there are more (up to 9 images).  \nHere is an explanation from Competition Host:\n> Most of the studies only have 1 image.  \nIn some cases, however, there are studies with more than 1 image. In these cases, patients were imaged more than once on the same date\/time (same StudyInstanceUID). In some cases, there is motion artifact, so the tech re-took the image. In other cases, different image processing is applied (the images look almost identical, but there is subtle change in contrast). In other cases, there are coverage, image penetration, or other technique issues, presumably resulting in the technologist needing to retake radiographs.  \n(...) We are addressing this issue currently regarding the duplicates and test set. We'll let you know when this process is completed.\n\n[source](https:\/\/www.kaggle.com\/c\/siim-covid19-detection\/discussion\/240250#1322940)","bf133d7e":"### Let's see the boxes...","8e7ee38f":"The image files are in DICOM (.dcm) format. This format is often used in the medical images since it contains information about the patient (to avoid mismatching the patients' data). DICOM format can be handled using pydicom package (see more: https:\/\/pydicom.github.io\/pydicom\/stable\/index.html )","da5c4b8e":"## Boxes\nAll of the images marked as \"Negative for Pneumonia\" don't have any boxes. But there are also some images from other categories with no boxes.","8d07f893":"## Let's look at the data!","0d3596a1":"## Explaining some confusing aspects of the data\nEvery image in train_image data is assigned to one study in train_study data (StudyInstanceUID column). But one study can contain multiple images (more info in the **STUDY DATA** section).  \n\nColumns 'boxes' and 'label' in train_image are somewhat redundant:\n* boxes contains location and size of the boxes\n* label contains location (xmin, ymin, xmax, ymax) of the boxes and confidence (which for the training data is always 1)\n\nSo we don't need 'boxes' column, we can just use the info from 'label' column.\n\n### The 'label' column in train_image data\nlabel column has a structure:  \na) for image with no boxes: `none 1 0 0 1 1`  \nb) for image with boxes: `opacity 1 <xmin> <ymin> <xmax> <ymax>`\n* if there is more than one box, there are multiple labels like this in a row, for example:  \n`opacity 1 789.29 582.43 1815.94 2499.73 opacity 1 2245.91 591.21 3340.57 2352.75`\n  \n\n### How should the submission file look like?\nFor images it is consistent with the label column!<br\/>\na) for image with no boxes: `id_image,none 1 0 0 1 1`  \nb) for image with boxes: `id_image,opacity <confidence> <xmin> <ymin> <xmax> <ymax>`  \nAnd for studies: `id_study,<class> <confidence> 0 0 1 1`\n\nExample from the Kaggle Evaluation tab:\n```\nId,PredictionString\n2b95d54e4be65_study,negative 1 0 0 1 1\n2b95d54e4be66_study,typical 1 0 0 1 1\n2b95d54e4be67_study,indeterminate 1 0 0 1 1 atypical 1 0 0 1 1\n2b95d54e4be68_image,none 1 0 0 1 1\n2b95d54e4be69_image,opacity 0.5 100 100 200 200 opacity 0.7 10 10 20 20\n```\n\nAlso, if I understand correctly, every study in train and test data is assigned to exactly one class (the classes are mutually exclusive) and it's best if you predict that class. But if you are not sure about your prediction, you can also try multilabel classification, for example: `2b95d54e4be65_study,negative 0.7 0 0 1 1 indeterminate 0.6 0 0 1 1`.","7eb465b1":"# STUDY DATA"}}