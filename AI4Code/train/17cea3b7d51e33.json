{"cell_type":{"d72a9264":"code","7caf6749":"code","6ad7d980":"code","3215da2b":"code","4a077a12":"code","86207a38":"code","90403a87":"code","541d0e73":"code","99c0b3e3":"code","77b48bf2":"code","ed82f269":"code","f5800265":"code","7c5d3ae9":"code","acb84361":"code","5ece5019":"code","98a37ed2":"code","25397901":"code","e4019f0a":"code","082c813c":"code","1daa44f0":"code","19142c4e":"code","28af6ad3":"code","324b3383":"code","0ed61a93":"code","abf68ab5":"code","8f1256f1":"code","dd52cbbb":"code","c92d5a67":"code","a20a3136":"markdown"},"source":{"d72a9264":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7caf6749":"#import the csv file\noilPrices = pd.read_csv('\/kaggle\/input\/brent-oil-prices\/BrentOilPrices.csv')\n#change column names to more comfortable names\noilPrices.columns=['date', 'price']\n\nprint(\"Data Set:\"% oilPrices.columns, oilPrices.shape)\nprint(\"Data Types:\", oilPrices.dtypes)\n#Check the top five records\noilPrices.head()","6ad7d980":"#Cast Date Column to type date\noilPrices['date'] = pd.to_datetime(oilPrices['date'])","3215da2b":"#As you may noticed the time series data does not contain the values for Saturday and Sunday. Hence missing values have to be filled. \n#Fill in Weekends - First make date as index (for resample method), then use forward fill ffill(),\n#which will assign the weekend values with Friday value. Resample method for frequency conversion and resampling of time series. Object must have a datetime-like index (DatetimeIndex, PeriodIndex, or TimedeltaIndex), \n#or pass datetime-like values to the on or level keyword\noilPrices.set_index('date', inplace=True)\noilPrices = oilPrices.resample('D').ffill().reset_index()","4a077a12":"#Make sure we have no null values\noilPrices.isnull().values.any()","86207a38":"#Let us split the date into year, month and week to explore trend in oil prices\noilPrices['year']=oilPrices['date'].dt.year\noilPrices['month']=oilPrices['date'].dt.month\noilPrices['week']=oilPrices['date'].dt.week","90403a87":"#Let us read the data until the 1st of January 2019 to split the data and predict prices in 2019\ntrain = oilPrices[(oilPrices['date' ] > '2001-01-01') & (oilPrices['date' ] <= '2019-12-31')]\ntest = oilPrices[oilPrices['date' ] >= '2020-01-01']","541d0e73":"#Yearly price visualization\nyearlyPrice=train.groupby([\"year\"])['price'].mean()\nplt.figure(figsize=(16,4))\nplt.title('Oil Prices')\nplt.xlabel('Year')\nplt.ylabel('Price')\nyearlyPrice.plot()\nplt.show();","99c0b3e3":"#time-series to decompose our time series into three distinct components: trend, seasonality, and noise.\nmonthlyPrice=oilPrices.groupby([\"month\"])['price'].mean()\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 18, 8\ndecomposition = sm.tsa.seasonal_decompose(yearlyPrice, freq=1, model='additive')\nfig = decomposition.plot()\nplt.show()","77b48bf2":"from fbprophet import Prophet\nd={'ds':train['date'],'y':train['price']}\ndf_pred=pd.DataFrame(data=d)\n# I took off Seasonality as Oil prices on weekends remain same as Friday until next opening on Monday\nmodel = Prophet(daily_seasonality=False)\nmodel.fit(df_pred)\nfuture = model.make_future_dataframe(periods=273)\nforecast = model.predict(future)\nforecast2020 = forecast[(forecast['ds' ] >= '2020-01-01') & (forecast['ds' ] <= '2020-04-21')]","ed82f269":"plt.figure(figsize=(18, 6))\nmodel.plot(forecast, xlabel = 'Date', ylabel = 'Price')\nplt.title('Brent Oil Price Prediction');","f5800265":"from fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(model, forecast2020)  # This returns a plotly Figure\npy.iplot(fig)","7c5d3ae9":"# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(forecast2020['ds'], forecast2020['yhat'], label='Predicted Prices')\nax.plot(test['date'], test['price'], label='Original Prices')\nplt.ylim([0,100])\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.title('Prophet Model Brent Oil Prices Forecast 2020')\nplt.xlabel('Month')\nplt.ylabel('Price')\nplt.show()","acb84361":"import statistics\n#Create a series of predicted values and observed ones\nobserved=test['price'].iloc[1:]\npredicted=forecast2020['yhat'].iloc[1:]\n#Reset the index of the series\npredicted.reset_index(drop=True, inplace=True)\nobserved.reset_index(drop=True, inplace=True)\n# loop over the set and find the difference between observed and predicted values then save them in a set\npred_err=[]\nfor count in range(len(observed)):\n    err = predicted[count] - observed[count]\n    pred_err.append(err)\n#Take the Absolute value and find the mean\nmae = statistics.mean(map(abs,pred_err))\nprint('Mean Absolute Error = {}'.format(round(mae, 2)))","5ece5019":"#Convert to Time Series For ARIMA Estimator\nseries=pd.Series(data=train['price'].to_numpy(), index=train['date'])\n#check if the Index is Datetime format\nseries.index","98a37ed2":"#The Augmented Dickey-Fuller test can be used to test for a unit root in a univariate process in the presence of serial correlation.\nfrom statsmodels.tsa.stattools import adfuller\nfrom numpy import log\nresult = adfuller(series)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])","25397901":"#Look if there is a stationary data, which looks non stationary\n#We need stationary data to make time series forecasting\nplt.plot(series[0:100])\nplt.show()","e4019f0a":"#find the order of differencing (d) in ARIMA model; hence the purpose of differencing it to make the time series stationary\ndaily_series_diff1 = series.diff(periods=1).dropna()\ndaily_series_diff2 = daily_series_diff1.diff(periods=1).dropna()\nfig, ax = plt.subplots()\nax.plot(daily_series_diff1[0:100], label='1st Order Differencing')\nax.plot(daily_series_diff2[0:100], label='2nd Order Differencing')\nplt.ylim([-3,3])\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.title('Time Series')\nplt.xlabel('Date')\nplt.ylabel('Diff')\nplt.show()","082c813c":"plt.rcParams.update({'figure.figsize':(12,3), 'figure.dpi':120})\nfrom statsmodels.graphics.tsaplots import plot_acf\nfig, axes = plt.subplots(1, 2, sharex=True)\nplot_acf(daily_series_diff1, lags=20, ax=axes[0], title=\"Autocorrelation 1st Order Differencing\")\nplot_acf(daily_series_diff2, lags=20, ax=axes[1], title=\"Autocorrelation 2nd Order Differencing\")\nplt.xlabel('Lag')\nplt.ylabel('ACF')\nplt.show()","1daa44f0":"#Determine the number of the moving average by looking at the Partial Autocorrelation : p value should be one based on the Partial Autocorrelation \nplt.rcParams.update({'figure.figsize':(12,3), 'figure.dpi':120})\n#Partial Auto-Correlation\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfig, axes = plt.subplots(1, 2, sharex=True)\nplot_pacf(daily_series_diff1, lags=10, ax=axes[0], title=\"Partial Autocorrelation 1st Order Differencing\")\nplot_pacf(daily_series_diff2, lags=10, ax=axes[1], title=\"Partial Autocorrelation 2nd Order Differencing\")\nplt.xlabel('Lag')\nplt.ylabel('PACF')\nplt.show()","19142c4e":"!pip install pmdarima\n#Number of differences required for a stationary series\nfrom pmdarima.arima.utils import ndiffs\ny=series\n# augmented Dickey\u2013Fuller test (adf test)\nprint(\"ADF Test: \",ndiffs(y, test='adf'))\n# Kwiatkowski\u2013Phillips\u2013Schmidt\u2013Shin (KPSS) test\nprint(\"KPSS Test: \",ndiffs(y, test='kpss'))\n# Phillips\u2013Perron (PP) test:\nprint(\"PP Test: \",ndiffs(y, test='pp'))","28af6ad3":"import pmdarima as pm\nmodel = pm.auto_arima(series, start_p=1, start_q=1,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\n\nprint(model.summary())","324b3383":"from statsmodels.tsa.arima_model import ARIMA\n# fit model\nmodel = ARIMA(series, order=(1, 0, 1)).fit(transparams=False)\nprint(model.summary())","0ed61a93":"#Forecast the oil prices for the period start='1\/1\/2019', end='9\/30\/2019'\n#typ='levels' if d is not set to zero (d = the number of nonseasonal differences)\nARIMA_Predict = model.predict(start='1\/1\/2019', end='9\/30\/2019')","abf68ab5":"#Standard deviation of residuals or Root-mean-square error (RMSD) https:\/\/www.youtube.com\/watch?v=zMFdb__sUpw\nmseProphet = mean_squared_error(test['price'],forecast2020['yhat'])\nmseARIMA = mean_squared_error(test['price'],ARIMA_Predict)\nrmseProphet = sqrt(mseProphet)\nrmseARIMA = sqrt(mseARIMA)\nprint('The Mean Squared Error of ARIMA forecasts is {}'.format(round(mseARIMA, 2)))\nprint('The Root Mean Squared Error of ARIMA forecasts is {}'.format(round(rmseARIMA, 2)))\nprint('The Mean Squared Error of Prophet forecasts is {}'.format(round(mseProphet, 2)))\nprint('The Root Mean Squared Error of Prophet forecasts is {}'.format(round(rmseProphet, 2)))","8f1256f1":"#OR you may replace all the above with sklearn simple mae function:\nfrom sklearn.metrics import mean_absolute_error\nmaeARIMA=mean_absolute_error(test['price'],ARIMA_Predict)\nmaeProphet=mean_absolute_error(test['price'],forecast2020['yhat'])\nprint('Mean Absolute Error ARIMA = {}'.format(round(maeARIMA, 2)))\nprint('Mean Absolute Error Prophet = {}'.format(round(maeProphet, 2)))","dd52cbbb":"# Create plots with pre-defined labels.\nfig, ax = plt.subplots()\nax.plot(forecast2020['ds'], ARIMA_Predict, label='Predicted Prices')\nax.plot(test['date'], test['price'], label='Original Prices')\nplt.ylim([0,100])\nlegend = ax.legend(loc='upper center', shadow=True)\nplt.title('ARIMA Model Brent Oil Prices Forecast 2019')\nplt.xlabel('Month')\nplt.ylabel('Price')\nplt.show()","c92d5a67":"mae=mean_absolute_error(test['price'],ARIMA_Predict)\nprint('Mean Absolute Error = {}'.format(round(mae, 2)))","a20a3136":"**Brent Oil Prices Prediction using Prophet & ARIMA**.\nArticle explaining the code is [available here](https:\/\/medium.com\/analytics-vidhya\/brent-oil-prices-forecast-with-prophet-and-arima-50f5f177da5b)."}}