{"cell_type":{"2fa1102d":"code","f4908761":"code","ffb123b9":"code","48376979":"code","fe60be9f":"code","8c22881b":"code","27e8f6cf":"code","94c17b48":"code","618e4f70":"code","79b17ee9":"code","c8ebb7e5":"markdown","35c7a24f":"markdown","137c6635":"markdown","a81f4ff8":"markdown","6fff45f8":"markdown","e81e0c7b":"markdown","b4db33bf":"markdown","7eb894ca":"markdown","7b5b083f":"markdown","15e3cc22":"markdown","7bdc1cc2":"markdown","ccf9fca7":"markdown","c671cbbf":"markdown","158269cf":"markdown","317ab162":"markdown","d1f83e47":"markdown"},"source":{"2fa1102d":"#import deep learning libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as L\n\nimport numpy as np\nimport pandas as pd","f4908761":"encoder = keras.Sequential()\n\nencoder.add(L.InputLayer([784]))\nencoder.add(L.Dense(500, activation='selu'))\nencoder.add(L.Dense(300, activation='selu'))\nencoder.add(L.Dense(2, activation='selu', name='latent'))\n\nencoder.summary()","ffb123b9":"decoder = keras.Sequential()\n\ndecoder.add(L.InputLayer([2]))\ndecoder.add(L.Dense(300, activation='selu'))\ndecoder.add(L.Dense(500, activation='selu'))\ndecoder.add(L.Dense(784, activation='sigmoid', name='reconstruction'))\n\ndecoder.summary()","48376979":"autoencoder = keras.Sequential([encoder, decoder])\nautoencoder.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1.5))","fe60be9f":"from tensorflow.keras.datasets.mnist import load_data\n\n(X_train, y_train), (X_val, y_val) = load_data()\nX_train = (np.array(X_train)\/255.).reshape(-1, 784)\nX_val = (np.array(X_val)\/255.).reshape(-1, 784)","8c22881b":"history = autoencoder.fit(X_train, X_train, validation_data=(X_val, X_val), epochs=10)","27e8f6cf":"import matplotlib.pyplot as plt\n\nimg_num = 546 #experiment with values from [0, 9999]\n\nimg = X_val[img_num].reshape(28, 28)\nimg_recon = autoencoder.predict(X_val[img_num].reshape(1, 784))\n\nplt.imshow(img, cmap='binary')\nplt.show()\nplt.imshow(img_recon.reshape(28, 28), cmap='binary')","94c17b48":"X_val_latent = encoder.predict(X_val)","618e4f70":"plt.figure(figsize=(30, 20))\nplt.scatter(X_val_latent[:, 0], X_val_latent[:, 1], c=y_val, s=15, cmap='tab10')\nplt.axis('off')","79b17ee9":"import matplotlib as mpl\n\nplt.figure(figsize=(30, 20))\ncmap = plt.cm.tab10\nplt.scatter(X_val_latent[:, 0], X_val_latent[:, 1], c=y_val, s=15, cmap=cmap)\nimage_positions = np.array([[1., 1.]])\nfor index, position in enumerate(X_val_latent):\n    dist = np.sum((position - image_positions) ** 2, axis=1)\n    if np.min(dist) > 0.02: # if far enough from other images\n        image_positions = np.r_[image_positions, [position]]\n        imagebox = mpl.offsetbox.AnnotationBbox(\n            mpl.offsetbox.OffsetImage(X_val[index].reshape(28, 28), cmap=\"binary\"),\n            position, bboxprops={\"edgecolor\": cmap(y_val[index]), \"lw\": 2})\n        plt.gca().add_artist(imagebox)\nplt.axis(\"off\")\nplt.show()","c8ebb7e5":"As you can see, each image has its own section\/cluster. Some pairs of numbers overlap more than others. For example, 3 and 5 overlap along with 4 and 9. If you think about it, these numbers are very similar in real life. \n\nAnother interesting thing is visualizing the borders of sections. If you look at the border of the orange cluster (number 1), you can see that the number starts to get slanted as it gets closer and closer to other sections. A slanted 1, can sometimes look like the middle part of a 2 or an elongated 5. ","35c7a24f":"### Implementation\n\nAs with any neural network, we need to have a loss function to minimize. The purpose of an autoencoder is to make the reconstruction as close to the original image as possible. Therefore, we can take the **Mean Squared Error** of each pixel in the image and use it as our loss function. To code the encoder, we will create a Sequential TensorFlow model. These are the number of neurons in each layer ```784, 500, 300, 2```. If you look back at Figure [1], we are using the same layers. ","137c6635":"It is pretty clear from the above image that each number has a pretty distinct section. However, we can't see which color represents which number. We also don't know what types of images are outliers (located outside of their general cluster). The next picture gives us the most amazing results!","a81f4ff8":"Now let's write the code for the decoder. It is the same thing except the weights will go in the reverse order ```300, 500, 784```. We will use sigmoid activation function in the last layer since each pixel has a value between 0 and 1.","6fff45f8":"## What are Autoencoders?\n\nAutoencoders are a type of neural network that can be used to represent complex features (such as images) with a small vector known as the **latent representation**. \n\n<img src=\"https:\/\/miro.medium.com\/max\/3110\/0*uq2_ZipB9TqI9G_k\" alt=\"autoencoder\" width=\"500\"\/>\n\n[1]\n\nIn the image above, you can see the structure of a simple autoencoder. The input is a image, and the output is a reconstruction of the same image. Right now, this seems pretty useless! Actually, the reconstruction isn't very helpful in most scenarios. However, the latent vector (2 neurons) can be very helpful to implement techniques such as dimensionality reduction and PCA. ","e81e0c7b":"Lets visualize an image along with its reconstruction from the validation set. ","b4db33bf":"## Dimensionality Reduction\n\nIf we pass an image into the encoder, it will give a representation of the image with just 2 numbers. We can use this to our advantage and try to visualize this. It is now possible since we can easily visualize in 2 dimensions. Visualizing 784 dimensions is extremely difficult. This is the benefit of **Dimensionality Reduction**. ","7eb894ca":"Now we can create the full autoencoder by simply stacking the two models on top of each other. Then, we will compile the model using the mean squared error as the loss function.","7b5b083f":"Now we can create a scatter plot by treating one number from the latent representation as the $x$ value, and the other as the $y$ value. Each color represents a different number.","15e3cc22":"## Overview\n\n* What are autoencoders\n* Autoencoder Structure\n* Autoencoder Inplementation\n* MNIST Dimensionality Reduction with Autoencoder\n* Really cool Visualization!","7bdc1cc2":"Note that we don't acutally need ```y_train``` and ```y_val```. The inputs are also the labels. This is completely unsupervised. \n\nLets start training!","ccf9fca7":"I hope you found this tutorial as a good intro into Autoencoders. In addition, I hope you found the fact that you can visualize 10,000 784 pixel images in just 2 dimensions as a cool and fascinating application. \n\nIn the next tutorial, I plan to dive into the more popular application of autoencoders --> variational autoencoders! \n\nPlease upvote this notebook only if you found it helpful. Thank you!\n\nThis book helped me a lot while making this notebook: \n> G\u00e9ron, A. (2017). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow concepts, tools, and techniques to build intelligentsystems O'Reilly Media Paperback .","c671cbbf":"In the next code cell, we will just load in the data from tensorflow and reshape the data from ```(n, 28, 28)``` to ```(n, 784)```. We will also normalize the values by dividing everything by 255. ","158269cf":"As you can see, the model does a descent job of reconstructing the image. It may not seem that impressive at first. However, it creates the reconstruction out of just 2 numbers (since the latent dimension was 2) which store information about the original image. ","317ab162":"### Autoencoder Structure\n\nThere are two parts to an autoencoder --> Encoder & Decoder\n\n**Encoder**\n\nThe goal of the encoder is to get the image\/input from its original state to the latent representation. The number of neurons in each layer decreases as you get deeper into the encoder with the latent layer having the least neurons. \n\n**Decoder**\n\nThe decoder is essentially the reflection of the encoder across the latent layer. Each layer has the same number of nuerons. The output layer represents the reconstruction. ","d1f83e47":"## Conclusion"}}