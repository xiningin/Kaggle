{"cell_type":{"47293fd2":"code","758946af":"code","a29e81ff":"code","58b1e13c":"code","14652d9a":"code","0dcf28d5":"code","7d992e1f":"code","3a0b6266":"code","e1e916c7":"code","54d9c862":"code","e1b21b80":"code","cef246ad":"code","7f1bbe2f":"code","aa9d38f7":"code","1d124d97":"code","6e82d914":"code","04287940":"code","6cc77e73":"code","bca0da77":"code","98f3a6b5":"code","5b52bce9":"code","d2bf1419":"code","7a7d1971":"code","8792128a":"code","81bf56cf":"code","517c46f6":"code","ef84b2bb":"code","444700f2":"code","d677d37c":"code","796e8cdf":"code","f6b50557":"code","146bc170":"code","dcc8e1e8":"code","c7bfac37":"code","26acbed5":"code","51019c7d":"code","02667487":"code","0a6e55d1":"code","581a49e3":"markdown","44515a2f":"markdown","12b034ac":"markdown","055d62c0":"markdown","15fd7ddd":"markdown","52502b37":"markdown","ae9c253a":"markdown","b8dda51b":"markdown","cb1ccc58":"markdown","e476014b":"markdown","e458889d":"markdown","13e9e7f8":"markdown","5fcbf610":"markdown","d346b305":"markdown","b1949c8a":"markdown","c67beadc":"markdown","1a95e2a7":"markdown","8b37f378":"markdown","9175633e":"markdown","918be5df":"markdown","3c291801":"markdown","6c32972c":"markdown","9a3c6e75":"markdown","b1a4870f":"markdown","c0143b5b":"markdown","c4482567":"markdown","fbd346fc":"markdown"},"source":{"47293fd2":"#importing the required packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","758946af":"#Load the train data in dataframe\ndf_train = pd.read_csv('..\/input\/train.csv')","a29e81ff":"#Display the columns in training set\ndf_train.columns","58b1e13c":"df_train.head()","14652d9a":"df_train.describe()","0dcf28d5":"df_train.info()","7d992e1f":"#Analysing Missing Values (NA)\ntotal_na = df_train.isnull().sum().sort_values(ascending=False)\npercent_na = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nna_df = pd.concat([total_na, percent_na], axis=1, keys=['No of Missing Values', '% of Missing Values']).sort_values(by= '% of Missing Values', ascending = False)\nna_df.head(20)","3a0b6266":"na_df[na_df['% of Missing Values'] > 0.4]","e1e916c7":"na_df.loc[['MasVnrType', 'MasVnrArea','Electrical']]","54d9c862":"#dealing with missing data\ndf_train = df_train.drop((na_df[na_df['% of Missing Values'] > 0.4]).index,1)\ndf_train = df_train.drop((na_df.loc[['MasVnrType', 'MasVnrArea','Electrical']]).index,1)","e1b21b80":"na_df.isnull().sum().max() #Checking for any missed out NAs\n# na_df.head(20)","cef246ad":"#Filling NA for other Missing Values with Mean values\ndf_train['LotFrontage'].fillna(value = df_train['LotFrontage'].mean, inplace = True)\ndf_train['GarageCond'].fillna(value = df_train['GarageCond'].mean, inplace = True)\ndf_train['GarageType'].fillna(value = df_train['GarageType'].mean, inplace = True)\ndf_train['GarageFinish'].fillna(value = df_train['GarageFinish'].mean, inplace = True)\ndf_train['GarageQual'].fillna(value = df_train['GarageQual'].mean, inplace = True)\ndf_train['GarageYrBlt'].fillna(value = df_train['GarageYrBlt'].mean, inplace = True)\ndf_train['BsmtExposure'].fillna(value = df_train['BsmtExposure'].mean, inplace = True)\ndf_train['BsmtFinType2'].fillna(value = df_train['BsmtFinType2'].mean, inplace = True)\ndf_train['BsmtFinType1'].fillna(value = df_train['BsmtFinType1'].mean, inplace = True)\ndf_train['BsmtCond'].fillna(value = df_train['BsmtCond'].mean, inplace = True)\ndf_train['BsmtQual'].fillna(value = df_train['BsmtQual'].mean, inplace = True)","7f1bbe2f":"sns.boxplot(x = df_train['SalePrice'])","aa9d38f7":"#standardizing data\nlow_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\nhigh_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\nprint('outer range (low) of the distribution:')\nprint(low_range)\nprint('\\nouter range (high) of the distribution:')\nprint(high_range)","1d124d97":"#bivariate analysis saleprice\/grlivarea\nsns.jointplot(x = 'GrLivArea', y = 'SalePrice', data = df_train, kind = 'reg');","6e82d914":"#deleting points\ndf_train.sort_values(by = 'GrLivArea', ascending = False)[:2]\ndf_train = df_train.drop(df_train[df_train['Id'] == 1299].index)\ndf_train = df_train.drop(df_train[df_train['Id'] == 524].index)","04287940":"#bivariate analysis saleprice\/grlivarea\nsns.jointplot(x = 'TotalBsmtSF', y = 'SalePrice', data = df_train, kind = 'reg');","6cc77e73":"#descriptive statistics summary\ndf_train['SalePrice'].describe()","bca0da77":"#histogram\nsns.distplot(df_train['SalePrice'], fit = norm);\n","98f3a6b5":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())","5b52bce9":"#Normal probability plot\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)","d2bf1419":"#histogram and normal probability plot\nsns.distplot(df_train['TotalBsmtSF'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","7a7d1971":"#Creating a new column for category variable\n#if area>0 then 1, else if area==0 then 0\ndf_train['HasBsmt'] = pd.Series(len(df_train['TotalBsmtSF']), index=df_train.index)\ndf_train['HasBsmt'] = 0 \ndf_train.loc[df_train['TotalBsmtSF']>0,'HasBsmt'] = 1","8792128a":"#scatter plot grlivarea\/saleprice\nvar = 'GrLivArea'\nsns.lmplot(x=var, y='SalePrice', markers = 'x', data = df_train)","81bf56cf":"#scatter plot totalbsmtsf\/saleprice\nvar = 'TotalBsmtSF'\nsns.lmplot(x=var, y='SalePrice', markers = 'x', fit_reg = True, data = df_train)","517c46f6":"\n#box plot overallqual\/saleprice\nvar = 'OverallQual'\nf, ax = plt.subplots(figsize=(10, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=df_train)\nfig.axis(ymin=0, ymax=800000);","ef84b2bb":"var = 'YearBuilt'\nf, ax = plt.subplots(figsize=(18, 8))\nfig = sns.boxplot(x=var, y=\"SalePrice\", data=df_train)\nfig.axis(ymin=0, ymax=800000);\nplt.xticks(rotation=90);","444700f2":"#Heatmap from Correlation Matrix for all the variables in dataset\ncorr_mat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr_mat, vmax=.8, square=True);","d677d37c":"#STRONG POSITIVELY CORRELATED\ncorr_mat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr_mat[corr_mat > 0.7], vmax=.8, annot = True, square=True);","796e8cdf":"#STRONG NEGATIVELY CORRELATED\ncorr_mat = df_train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corr_mat[corr_mat < -0.3], vmax=.8, annot = True, square=True);\n# sns.heatmap(corr_mat, mask = corr_mat < -0.4, vmax=.8, annot = True, square=True);","f6b50557":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corr_mat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nmask = np.zeros_like(cm)\nmask[np.triu_indices_from(mask)] = True\nhm = sns.heatmap(cm, cbar=True, mask = mask, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","146bc170":"#scatterplot\nsns.set(palette = 'deep')\ncols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols], size = 2.5)\nplt.show();","dcc8e1e8":"#standardizing data\nsaleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);","c7bfac37":"#applying log transformation\ndf_train['SalePrice_Log'] = np.log(df_train['SalePrice'])","26acbed5":"sns.distplot(df_train['SalePrice_Log'], fit = norm);\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice_Log'], plot=plt)","51019c7d":"#standardizing data\ntotalBsmtSF_scaled = StandardScaler().fit_transform(df_train['TotalBsmtSF'][:,np.newaxis]);","02667487":"#transform data\ndf_train.loc[df_train['HasBsmt']==1,'TotalBsmtSF'] = np.log(df_train['TotalBsmtSF'])","0a6e55d1":"sns.distplot(df_train['TotalBsmtSF'], fit = norm);\nfig = plt.figure()\nres = stats.probplot(df_train['TotalBsmtSF'], plot=plt)","581a49e3":"'SalePrice' has positive skew and is not following the shape of normal distribution. In the last part, let us convert it into logarathamic scale and recheck.","44515a2f":"### Relationship with numerical variables","12b034ac":"TO BE CONTINUED....","055d62c0":"Following fields are observed to be vs having a strong correlation:\n1. 'TotalBsmtSF'vs '1stFlrSF'. \n2. 'YearBlt'vs 'GarageYrBlt'. \n(This is obvious isn't it! Not an useful observation but it shows that these variables are multi-collinear in nature. ","15fd7ddd":"Now let us delve deep into the study of relationships among variables in combinations. We will be using the regression scatter plots, correlation matrix, heatmap etc for this section.","52502b37":"## Detecting Outliers\nOutliers can be detected with the help of Univariate and Bivariate analysis","ae9c253a":"# 3. Study of variables (features) in isolation: 'SalePrice' variable","b8dda51b":"SalePrice and TotalBsmtSF are even more positively correlated with much stronger linear correlation. ","cb1ccc58":"Deleting the outliers identified from boxplot, StandardScaler and Jointplot...","e476014b":"Not a clear relationship established here. However, we can still say that the recently built houses has an higher sale price. \nAlso, year 2009 is an anomaly here due to the sub-prime crisis - all the asset classes went south. ","e458889d":"SalePrice and GrLivArea are positive + linearly correlated. ","13e9e7f8":"#### 'SalePrice' correlation matrix (zoomed heatmap style)","5fcbf610":"### Univariate analysis","d346b305":"### Bivariate analysis","b1949c8a":"We can observe that the distribution is showing peakedness with a kurtosis of 6.5362 and positively skewed with Skewness at 1.8828.","c67beadc":"Below set of variables 'PoolQC', 'MiscFeature' and 'FireplaceQu' looks like probable outliers. Similarly, 'Electrical'and 'PavedDrive' also looks like probable outliers with fewest occurences. Let us drop them from our dataframe.\n\nRemaining missing values will be handled by replacing them with mean values.","1a95e2a7":"# 1. Initiation","8b37f378":"**Index**\n1. Initiation\n2. Data cleaning and preprocessing\n3. Study of variables (features) in isolation\n4. Study of variables in groups and combinations\n5. To be continued...","9175633e":"# 2. Data cleaning and preprocessing\nFirst step in any project - to clean and preprocess the data for further analysis and model building. Here the focus is on missing values (NA) and the corresponding patterns. ","918be5df":"We can see that as OverallQual improves, SalePrice also improves with significant linear increase in terms of IQR.","3c291801":"# 4. Study of variables in groups and combinations","6c32972c":"## Now let us try to apply StandardScaler and log transformations and recheck some of the variable plots","9a3c6e75":"Not much outliers in this plot. Moving on to study of SalePrice variable...","b1a4870f":"# BEGINNER EXPLORATORY DATA ANALYSIS WITH PYTHON","c0143b5b":"### Relationship with categorical features","c4482567":"#### Scatter plots : 'SalePrice' vs Correlated Variables","fbd346fc":"#### Correlation matrix (heatmap style)"}}