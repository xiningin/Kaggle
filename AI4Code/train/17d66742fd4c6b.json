{"cell_type":{"0b08742e":"code","ec132bb0":"code","136e22bc":"code","181735c9":"code","201c3130":"code","2b6e17b2":"code","7ec750ac":"code","8c603721":"code","d0fc8e48":"code","45c8175b":"code","f7d45cef":"code","cf9860ef":"code","955c3099":"code","66b0b9b6":"code","93a5bc88":"code","e2d0cf19":"code","52fcf826":"code","713d0ba2":"code","00818d4f":"code","cc0ca083":"code","1d06ba3e":"code","2e981e78":"code","35ca7c95":"code","b12b15f9":"code","75815596":"code","e4f5ba8d":"code","5059d9c9":"code","9b95cdbb":"code","3fcb587b":"code","61cb6554":"code","91bb929d":"code","915dc69b":"code","673b0056":"code","bf3e8fd8":"code","8d214452":"code","5833bbce":"code","aba054eb":"code","5d8c5074":"code","74c47034":"code","d25d0ac5":"code","25eca7ae":"code","0a3be20f":"code","36769497":"code","da8ee4fc":"code","2a3de7ae":"code","fa8e874e":"code","ca756cd2":"code","600e2bfd":"code","e6c72179":"code","3b9d6f80":"markdown","792d480c":"markdown","598f14e1":"markdown"},"source":{"0b08742e":"!pip install pyforest","ec132bb0":"from pyforest import *  # By importing pyforest, we don't need to include the package of pandas and numpy.\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom sklearn import metrics\nfrom imblearn.over_sampling import SMOTE","136e22bc":"churn = pd.read_csv('..\/input\/employee-attrition\/Employee_Churn.csv')\nchurn.head()","181735c9":"churn.describe()    # describe() gives us the information of the numerical features. ","201c3130":"churn.info()   # info() gives us the information of all the attributes' datatypes.","2b6e17b2":"churn.isnull().sum()       # isnull() let's us know if there is any null values in any particular feature.","7ec750ac":"churn.memory_usage(deep=True)    # memory_usage gives us the clear idea of which attribute consumes more memory in bytes.","8c603721":"churn.BusinessTravel.value_counts()   # value_counts() let's us know the particular data appears how many times in a particular column.","d0fc8e48":"churn.Department.value_counts()","45c8175b":"churn.EducationField.value_counts()","f7d45cef":"churn.JobRole.value_counts()","cf9860ef":"from sklearn.preprocessing import LabelEncoder       # helps us to convert categorical into numerical.\nle=LabelEncoder()\nchurn['Attrition'] = le.fit_transform(churn['Attrition'])\nchurn['BusinessTravel'] = le.fit_transform(churn['BusinessTravel'])\nchurn['Department'] = le.fit_transform(churn['Department'])\nchurn['Gender'] = le.fit_transform(churn['Gender'])\nchurn['MaritalStatus'] = le.fit_transform(churn['MaritalStatus'])\nchurn['OverTime'] = le.fit_transform(churn['OverTime'])\nchurn['EducationField'] = le.fit_transform(churn['EducationField'])\nchurn['JobRole'] = le.fit_transform(churn['JobRole'])","955c3099":"churn.head()","66b0b9b6":"churn.memory_usage(deep=True)   # by converting all the categorical columns into numerical, the memory usage decreases.","93a5bc88":"# let's drop the attributes that are not required for implementation.\n\nchurn.drop(columns=['YearsWithCurrManager', 'WorkLifeBalance', 'TrainingTimesLastYear', 'StockOptionLevel', 'NumCompaniesWorked', 'MaritalStatus', 'EnvironmentSatisfaction', 'EmployeeNumber','StandardHours', 'Over18'], inplace=True, axis=1)\nchurn.info()","e2d0cf19":"churn.shape  #shape let's us know the number of rows and columns in dataset.","52fcf826":"print(churn.Age.max())  # we can get the data of a person who is of max age\nprint(churn.Age.min())  # we can get the data of a person who is of min age","713d0ba2":"print(churn.loc[churn.Age == 60])\nprint('-------------------------------------------------------------------------------------------------------')\nprint(churn.loc[churn.Age == 18])","00818d4f":"churn.loc[(churn.Age == 18) & (churn.Attrition == 1)]   # Gives us the data of a person who is 18 years and who left the company.","cc0ca083":"churn.loc[(churn.Attrition == 1) & (churn.Gender == 1)]  #Male","1d06ba3e":"print(churn.DailyRate.max())\nprint(churn.DailyRate.min())","2e981e78":"print(churn.MonthlyIncome.max())   #employee who has max monthly income\nprint(churn.MonthlyIncome.min())   #employee who has min monthly income","35ca7c95":"churn.loc[(churn.MonthlyIncome == 19999) & (churn.Attrition == 0)]  ","b12b15f9":"churn.loc[churn.MonthlyIncome == 1009]  # We can get an idea behind this employee's attrition that the monthly income is low, distance from home is also more, he is also doing overtime so it is obvious that the employee will definitely churn (leave the company)","75815596":"print(churn.DistanceFromHome.max())\nprint(churn.DistanceFromHome.min())","e4f5ba8d":"churn.loc[(churn.DistanceFromHome >= 10) & (churn.Attrition == 1)]","5059d9c9":"churn.loc[(churn.Department == 0) & (churn.Attrition == 1)] #Human Resources","9b95cdbb":"churn.loc[(churn.Department == 1) & (churn.Attrition == 1)] #Research & Development","3fcb587b":"churn.loc[(churn.Department == 2) & (churn.Attrition == 1)] #Sales","61cb6554":"print(churn.PerformanceRating.max())\nprint(churn.PerformanceRating.min())","91bb929d":"churn[(churn.PerformanceRating == 4) & (churn.Attrition == 1)]","915dc69b":"churn.loc[churn.YearsSinceLastPromotion == 15]","673b0056":"numerical = [u'Age', u'DailyRate', u'DistanceFromHome', \n             u'Education',\n             u'HourlyRate',\n             u'MonthlyIncome', u'MonthlyRate',\n             u'PercentSalaryHike', u'PerformanceRating',\n             'TotalWorkingYears',\n             'YearsAtCompany',\n             'YearsSinceLastPromotion']\ndata = [\n    go.Heatmap(\n        z= churn[numerical].astype(float).corr().values, # Generating the Pearson correlation\n        x=churn[numerical].columns.values,\n        y=churn[numerical].columns.values,\n        colorscale='Viridis',\n        reversescale = False,\n#         text = True ,\n        opacity = 1.0\n        \n    )\n]\n\n\nlayout = go.Layout(\n    title='Pearson Correlation of numerical features',\n    xaxis = dict(ticks='', nticks=36),\n    yaxis = dict(ticks='' ),\n    width = 900, height = 700,\n    \n)\n\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='labelled-heatmap')","bf3e8fd8":"churn.Attrition.sum() # Total 237 employees have churned (left the company).","8d214452":"churn.MonthlyIncome.plot(kind='hist')","5833bbce":"churn.DailyRate.plot(kind='hist')","aba054eb":"churn.TotalWorkingYears.plot(kind='hist')","5d8c5074":"churn.Attrition.plot(kind='hist')","74c47034":"ax = sns.boxplot(x='Attrition', y='Department', data=churn)\nax = sns.stripplot(x='Attrition', y='Department', data=churn, jitter=True, edgecolor='gray')","d25d0ac5":"sns.violinplot(x='Attrition',y='Department',data=churn,size=6)","25eca7ae":"# Now, let's split our data into training and testing.\n\ntrain, test = train_test_split(churn, test_size=0.2)\nprint(train.shape)\nprint(test.shape)","0a3be20f":"#Pie chart will give the percentage of attrition and non-attrition\n\nimport plotly.offline as ply\nvalues = pd.Series(churn[\"Attrition\"]).value_counts()\ntrace = go.Pie(values=values)\nply.iplot([trace])","36769497":"X=churn.loc[:, churn.columns != 'Attrition']\ny=churn.loc[:, churn.columns == 'Attrition']","da8ee4fc":"print(\"Shape of X is: {}\".format(X.shape))\nprint(\"Shape of y is: {}\".format(y.shape))","2a3de7ae":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","fa8e874e":"from sklearn.metrics import (accuracy_score, log_loss, classification_report)\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprint('Accuracy',metrics.accuracy_score(prediction, y_test))\nprint(classification_report(prediction, y_test))","ca756cd2":"import xgboost as xgb\nmodel = xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprint('Accuracy',metrics.accuracy_score(prediction, y_test))\nprint(classification_report(prediction, y_test))","600e2bfd":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprint(classification_report(prediction, y_test))","e6c72179":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprint(classification_report(prediction, y_test))","3b9d6f80":"Now, we will generate the Pearson matrix to know the correlation between each and every attributes.","792d480c":"Now we will implement some of machine learning algorithms to know the accuracy, precision and recall.","598f14e1":"From the above analysis we can come to know that, most of the employees who churned are of Research and Development department"}}