{"cell_type":{"59d39a8d":"code","7b557bf2":"code","d0d3c8f1":"code","cca6d58c":"code","4e7ffa71":"code","49109996":"code","24522d26":"code","39860403":"code","46b1b376":"code","0d1081c9":"code","7a24e3d4":"code","c238bded":"code","e40c789e":"code","f436c3e8":"code","90e1998c":"code","df4a42b7":"code","7dc4f456":"code","78eb653d":"code","77ea81a9":"code","4dd1d736":"code","20d27aef":"code","b27512e5":"markdown","136f75df":"markdown","c37922ee":"markdown","dda210e0":"markdown","35574cd3":"markdown","1f0da7df":"markdown","f745abf7":"markdown","821fad9b":"markdown","58bf8281":"markdown","92065b57":"markdown","4af7d2a6":"markdown","cac083db":"markdown","00013858":"markdown","eec05566":"markdown","56a2729c":"markdown","a41ca67d":"markdown","49f7c2d9":"markdown","586ab99f":"markdown","3f8bd765":"markdown","7f07fd36":"markdown","12552d17":"markdown","f5d43f77":"markdown","503f5df8":"markdown"},"source":{"59d39a8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7b557bf2":"train  = pd.read_csv('\/kaggle\/input\/mobile-price-classification\/train.csv')","d0d3c8f1":"!pip install pycaret","cca6d58c":"from pandas_profiling import ProfileReport\nfrom pycaret.classification import *","4e7ffa71":"train_report = ProfileReport(train)","49109996":"train_report","24522d26":"train_setup = setup(train,target ='price_range')","39860403":"setup_data = setup(data = train,target = 'price_range',train_size =0.8,categorical_features =['blue','dual_sim','four_g','three_g','touch_screen','wifi'],normalize = True,normalize_method = 'zscore',remove_multicollinearity = True,multicollinearity_threshold = 0.8,pca =True, pca_method ='linear',pca_components = 0.90,ignore_low_variance = True)","46b1b376":"setup_data = setup(data = train,target = 'price_range',train_size =0.8,categorical_features =['blue','dual_sim','four_g','three_g','touch_screen','wifi'],normalize = True,normalize_method = 'zscore',remove_multicollinearity = True,multicollinearity_threshold = 0.8,pca =True, pca_method ='linear',pca_components = 0.90,ignore_low_variance = True,numeric_features =['talk_time','fc','n_cores','sc_h','sc_w'])","0d1081c9":"compare_models()","7a24e3d4":"final_model = create_model('qda')","c238bded":"plot_model(final_model,plot='auc')","e40c789e":"plot_model(final_model,plot='pr')","f436c3e8":"plot_model(final_model,plot='class_report')","90e1998c":"plot_model(final_model,plot='learning')","df4a42b7":"plot_model(final_model,plot='parameter')","7dc4f456":"evaluate_model(final_model)","78eb653d":"final_predictions = predict_model(final_model)","77ea81a9":"final_predictions","4dd1d736":"finalize_model(final_model)","20d27aef":"save_model(final_model,'final_model')","b27512e5":"**<center>That's the end, thanks for your patience and curiousity to learn new stuffs....<br\/>See you later in future notebooks<\/center>**","136f75df":"**Ignoring Low Varience**<br\/>\nSometimes a dataset may have a categorical feature with multiple levels, where distribution of such levels are skewed and one level may dominate over other levels. This means there is not much variation in the information provided by such feature.  For a ML model, such feature may not add a lot of information and thus can be ignored for modeling.\n\n**Parameter in setup method**<br\/>\n\nignore_low_variance: bool, default = False\nWhen set to True, all categorical features with statistically insignificant variances are removed from the dataset.\n","c37922ee":"**One hot encoding**\n\nMachine learning algorithms cannot work directly with categorical data and they must be transformed into numeric values before training a model. Most common type of categorical encoding is One Hot Encoding (also known as dummy encoding) where each categorical level becomes a separate feature in the dataset containing binary values (1 or 0).PyCaret will transform all categorical features in dataset using one hot encoding.One Hot Encoding works on all features that are either inferred as categorical or are forced as categorical using categorical_features parameter within setup.\n\n**Parameters in setup method:**<br\/>\n\ncategorical_features: string, default = None\nIf the inferred data types are not correct, categorical_features can be used to overwrite the inferred type. If when running setup the type of \u2018column1\u2019 is inferred as numeric instead of categorical, then this parameter can be used to overwrite the type by passing categorical_features = ['column1']\n\n\n\n\n","dda210e0":"# Area Under the Curve","35574cd3":"**Train Test Split<br\/>**\n\nGoal in machine learning is to build a model that generalizes well to the new data. Hence the dataset is split into the Train dataset and the Test dataset during supervised machine learning experiment. Test dataset serves as a proxy for new data.Test dataset (also known as hold-out set) is not used in training of models and hence can be used to evaluate metrics and determine if the model has over-fitted the data.\n\n**Parameters in setup method:**\n\ntrain_size: float, default = 0.7\nSize of the training set. By default, 70% of the data will be used for training and validation. The remaining data will be used for a test \/ hold-out set.","1f0da7df":"# Saving the model for future use","f745abf7":"# Finalizing the model","821fad9b":"# Model HyperParameter","58bf8281":"**PREPROCESSING STEPS:**<br\/>\n1)Train Test Split<br\/>\n2)One Hot Encoding<br\/>\n3)Normalization<br\/>\n4)Removing Multicolinearity<br\/>\n5)Principal Component Analysis<br\/>\n6)Ignoring Low Variance<br\/>","92065b57":"# Learning Curve","4af7d2a6":"**Normalization<br\/>**\nNormalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to rescale the values of numeric columns in the dataset without distorting differences in the ranges of values or losing information. \n\n**Parameters in setup**<br\/>\n\nnormalize: bool, default = False\nWhen set to True, the feature space is transformed using the normalized_method param. \n\n<u>Various normalize methods<\/u>:\n* z-score : The standard zscore is calculated as z = (x \u2013 u) \/ s\n* minmax : scales and translates each feature individually such that it is in the range of 0 \u2013 1.\n* maxabs : scales and translates each feature individually such that the maximal absolute value of each feature will be 1.0. It does not shift\/center the data, and thus does not destroy any sparsity.\n* robust : scales and translates each feature according to the Interquartile range. When the dataset contains outliers, robust scaler often gives better results.\n\n","cac083db":"PyCaret is an open source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within seconds in your choice of notebook environment.\n\nIn this notebook I'm going to surf around various methods available in pycaret library. As I'm a newbie to this library this notebook will serve as a tutorial for all the people who want to learn this new uber cool library.\n\nThe Agenda is very simple:\n1. Report Creation<br\/>\n2. Preprocessing<br\/>\n3. Checking different models\n4. Fixing final models\n5. Different model plots\n6. Prediction with the final model\n7. Saving the model\n\nIf you like this notebook consider upvoting it.....\n\n**<center>Let's Start<\/center>**","00013858":"**Removing Multi-Collinearity**<br\/>\nMulticollinearity (also called collinearity) is a phenomenon in which one feature variable in the dataset is highly linearly correlated with another feature variable in the same dataset. Multicollinearity increases the variance of the coefficients, thus making them unstable and noisy for linear models. One such way to deal with Multicollinearity is to drop one of the two features that are highly correlated with each other.\n\n**Parameters in setup method**<br\/>\n\nremove_multicollinearity: bool, default = False\nWhen set to True, the variables with inter-correlations higher than the threshold defined under the multicollinearity_threshold param are dropped. When two features are highly correlated with each other, the feature that is less correlated with the target variable is dropped.","eec05566":"# Precision Recall Curve","56a2729c":"# Choosing the model with high accuracy as final model","a41ca67d":"# Classification Report","49f7c2d9":"# Comparing Different ML models","586ab99f":"# BEFORE PREPROCESSING","3f8bd765":"![image.png](attachment:image.png)","7f07fd36":"**Principal Component Analysis**<br\/>\nPrincipal Component Analysis (PCA) is an unsupervised technique used in machine learning to reduce the dimensionality of a data. It does so by compressing the feature space by identifying a subspace that captures most of the information in the complete feature matrix. It projects the original feature space into lower dimensionality. \n\n**Parameters in setup method**<br\/>\n\n\npca: bool, default = False\nWhen set to True, dimensionality reduction is applied to project the data into a lower dimensional space using the method defined in pca_method param. ","12552d17":"<h5>**Some Numeric features are inferred as categorical features so we have mention those in numeric_features parameter to make them numerical features**<\/h5>","f5d43f77":"# Predicting the test set using final model","503f5df8":"# Evaluating the final model"}}