{"cell_type":{"82c31f3a":"code","2436961a":"code","bfd1c541":"code","52e0ce33":"code","f8b4d075":"code","14d4c4d4":"code","b106ca61":"code","8f5f059b":"code","d12193fb":"code","f4fe8e87":"code","c5d5c4e8":"code","c138dfed":"code","069001ef":"code","1030c8a2":"code","4870b9b0":"markdown","d01e740a":"markdown","161a5af3":"markdown","18612690":"markdown","7688f6be":"markdown"},"source":{"82c31f3a":"import numpy as np\nimport tensorflow as tf\nfrom skimage import measure\nimport keras.backend as K","2436961a":"# helper function to calculate IoU\ndef iou_bbox(box1, box2):\n    x11, y11, w1, h1 = box1\n    x21, y21, w2, h2 = box2\n    assert w1 * h1 > 0\n    assert w2 * h2 > 0\n    x12, y12 = x11 + w1, y11 + h1\n    x22, y22 = x21 + w2, y21 + h2\n\n    area1, area2 = w1 * h1, w2 * h2\n    xi1, yi1, xi2, yi2 = max([x11, x21]), max([y11, y21]), min([x12, x22]), min([y12, y22])\n    \n    if xi2 <= xi1 or yi2 <= yi1:\n        return 0\n    else:\n        intersect = (xi2-xi1) * (yi2-yi1)\n        union = area1 + area2 - intersect\n        return intersect \/ union\n    \n# simple test\nbox1 = [100, 100, 200, 200]\nbox2 = [100, 100, 300, 200]\nprint(iou_bbox(box1, box2))","bfd1c541":"def map_iou(boxes_true, boxes_pred, thresholds=(0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75)):\n    \"\"\"\n    Mean average precision at differnet intersection over union (IoU) threshold\n\n    input:\n        boxes_true: Mx4 numpy array of ground true bounding boxes of one image.\n                    bbox format: (x1, y1, w, h)\n        boxes_pred: Nx4 numpy array of predicted bounding boxes of one image.\n                    bbox format: (x1, y1, w, h)\n        thresholds: IoU shresholds to evaluate mean average precision on\n    output:\n        map: mean average precision of the image\n    \"\"\"\n\n    # According to the introduction, images with no ground truth bboxes will not be\n    # included in the map score unless there is a false positive detection (?)\n\n    # return 0 if both are empty, don't count the image in final evaluation (?)\n    if len(boxes_true) == 0 and len(boxes_pred) == 0:\n        return 0\n\n    map_total = 0\n\n    # loop over thresholds\n    for t in thresholds:\n        matched_bt = set()\n        tp, fn = 0, 0\n        for i, bt in enumerate(boxes_true):\n            matched = False\n            for j, bp in enumerate(boxes_pred):\n                miou = iou_bbox(bt, bp)\n                if miou >= t and not matched and j not in matched_bt:\n                    matched = True\n                    tp += 1 # bt is matched for the first time, count as TP\n                    matched_bt.add(j)\n            if not matched:\n                fn += 1 # bt has no match, count as FN\n\n        fp = len(boxes_pred) - len(matched_bt) # FP is the bp that not matched to any bt\n        m = tp \/ (tp + fn + fp)\n        map_total += m\n\n    return map_total \/ len(thresholds)","52e0ce33":"def unet_mask_to_bbox_coords(mask, threshold=0.5, do_resize=False):\n    '''\n    :param mask: predicted mask, numpy array of shape (widht, height, 1) or (width, height)\n    :param threshold: threshold for binarization of mask\n    :return: bbox coordinates, in form [x, y, width, height] for each bbox coordinate\n    :rtype: numpy array\n    '''\n    if mask.ndim == 3:\n        mask = mask[:, :, 0]\n    # resize predicted mask\n    if do_resize:\n        mask = resize(mask, (1024, 1024), mode='constant')\n    # threshold predicted mask, multiply by 255, since predictions were upscaled for memory performance\n    comp = mask > threshold\n    # apply connected components\n    comp = measure.label(comp)\n\n    bboxes = np.array([]).reshape((0, 4))\n\n    for region in measure.regionprops(comp):\n        # retrieve x, y, height and width\n        y, x, y2, x2 = region.bbox\n        height = y2 - y\n        width = x2 - x\n        bboxes = np.concatenate([bboxes, np.array([[x, y, width, height]])], axis=0)\n\n    return bboxes","f8b4d075":"def competitionMetric(y_true, y_pred):\n    '''\n    Implementation of rsna pneumonia competition metric\n    '''\n    def np_competitionMetric(np_true, np_pred):\n        '''\n        Compute the mean map_iou for each sample of the batch\n        '''\n        return np.mean([map_iou(unet_mask_to_bbox_coords(true), unet_mask_to_bbox_coords(pred))\n                               for true, pred in zip(np_true, np_pred)]).astype(np.float32)\n\n    return tf.py_func(np_competitionMetric,\n                      inp=[y_true, y_pred],\n                      Tout=tf.float32,\n                      stateful=False,\n                      name='competitionMetric'\n                      )","14d4c4d4":"y_true_array = np.zeros((1, 128, 128, 1))\ny_true_array[:, 20: 41, 23:45, :] = 1\ny_true = tf.Variable(y_true_array, dtype='float32', name='y_true')\n\ny_pred_array = np.zeros((1, 128, 128, 1))\ny_pred_array[:, 20: 37, 18:37, :] = 1\ny_pred = tf.Variable(y_pred_array, dtype='float32', name='y_pred')","b106ca61":"sess = K.get_session()\nsess.run(tf.global_variables_initializer())","8f5f059b":"sess.run(competitionMetric(y_true, y_pred))","d12193fb":"box_true = [[20, 23, 21, 22]] #x, y, width, height\nbox_pred = [[20, 18, 17, 19]]\nmap_iou(box_true, box_pred)","f4fe8e87":"sess = K.get_session()\n\ny_true_array = np.zeros((24, 128, 128, 1))\ny_true_array[:, 20: 35, 10:40, :] = 1\ny_true = tf.Variable(y_true_array, dtype='float32', name='y_true')\n\ny_pred_array = np.zeros((24, 128, 128, 1))\ny_pred_array[5:, 20: 37, 19:37, :] = 1\ny_pred_array[:10, 100:115, 105:115, :] = 1\ny_pred = tf.Variable(y_pred_array, dtype='float32', name='y_pred')","c5d5c4e8":"sess.run(tf.global_variables_initializer())","c138dfed":"sess.run(competitionMetric(y_true, y_pred))","069001ef":"batch_box_true = [ [[20, 10, 15, 30]] for _ in range(24)]\nbatch_box_pred = [ [[100, 105, 15, 10]] for _ in range(5)] +\\\n                 [ [[100, 105, 15, 10], [20, 19, 17, 18]] for _ in range(5)] +\\\n                 [ [[20, 19, 17, 18]] for _ in range(14)]","1030c8a2":"np.mean([map_iou(box_true, box_pred) for box_true, box_pred in zip(batch_box_true, batch_box_pred)])","4870b9b0":"**Implementation of the competition metric in keras for image segmentation models\n**\n\nCode is partly from these great kernels:\n\nUnet segmentation: https:\/\/www.kaggle.com\/jonnedtc\/cnn-segmentation-connected-components\n\nNumpy implementation of the bbox https:\/\/www.kaggle.com\/chenyc15\/mean-average-precision-metric\n\nIdea borrowed from: https:\/\/www.kaggle.com\/raresbarbantan\/f2-metric and is modified for this competition.","d01e740a":"**In contrast to the competition metric, the confidence level is not taken into account for computing the map_iou. **","161a5af3":"**> Let's do a simple test**","18612690":"Create the corresponding batch of bboxes","7688f6be":"Now, let's compute the metric on a batch example"}}