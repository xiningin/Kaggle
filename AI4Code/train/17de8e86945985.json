{"cell_type":{"cb5a9d19":"code","5f21f6c4":"code","1caf6a2c":"code","f33c502b":"code","593d288c":"code","38dd5cc1":"code","af5cd2e1":"code","0c7ed0e8":"code","13de93c4":"code","ccb263d6":"code","e79f751a":"code","6df4cd85":"code","07c63ea5":"code","7e927f40":"code","94a63a6d":"code","fbdd3099":"code","17589650":"code","d29730cc":"code","aaa87729":"code","ad2fddb9":"code","19e0db01":"code","8ac55cf4":"code","fe64e7df":"code","4b6d836d":"code","d54dd11b":"code","4d32a849":"code","88db62eb":"code","eeaf2788":"code","7f5180af":"code","a06121c0":"code","8829af26":"code","7a9ada34":"code","9b6444a8":"code","436e53ff":"code","d1662068":"code","d8de8113":"code","b3a7ead0":"code","31844468":"code","371b2496":"code","eb8c1e33":"code","d586b066":"code","6145f3eb":"code","8f042335":"code","27ba0278":"code","df610e57":"code","dce2f748":"code","33fcedec":"code","d20d0bc0":"code","556bed22":"code","14426587":"code","4dc064cf":"code","70b3e248":"code","0c4226d5":"code","048fe71a":"code","27ca5bd1":"code","8dc771aa":"code","06216155":"code","9b8dac8f":"code","a3640492":"code","a616b8c7":"code","c6ba917f":"code","70c81878":"code","03cb879c":"code","91e823b0":"code","6852fa5f":"code","dc2723a6":"code","238cd71e":"code","0b3b142b":"code","258d2ed5":"code","d89f0efa":"code","86fdd297":"code","6f8c666e":"code","0830e074":"code","09126b69":"code","504b728e":"code","45360140":"code","5aec8089":"code","9593894d":"code","188ff0b0":"code","d26947f0":"code","c6eb4a14":"code","96ae9f3e":"code","a75aa7ae":"markdown","5b23c121":"markdown","ae80ef6d":"markdown","7435c650":"markdown","cd74885b":"markdown","ea649845":"markdown","796530d3":"markdown","46ee9fe6":"markdown","e5417558":"markdown","59396ca6":"markdown","120ca7da":"markdown","5950a373":"markdown","8e6a87d1":"markdown","bd84635a":"markdown","a34ef1c1":"markdown","ae77baf8":"markdown","1bb04b71":"markdown","97cf6a49":"markdown","50956428":"markdown","18b53712":"markdown","e388471b":"markdown","d62e4446":"markdown","60210059":"markdown","da4ceda0":"markdown","95f02e6e":"markdown","e727dfa0":"markdown","20ee2548":"markdown","1d6e6519":"markdown","896cf31b":"markdown","8f285f2d":"markdown","01637f56":"markdown","5a97cc6b":"markdown","37b6baad":"markdown","a9497824":"markdown","bdd1d9c9":"markdown","47f5bc52":"markdown"},"source":{"cb5a9d19":"# EDA: \nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# MOdel selection\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.linear_model import LogisticRegression\n\n# Model hyper parameter tuning\nfrom sklearn import metrics\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport os\n\nimport warnings  \nwarnings.filterwarnings('ignore')","5f21f6c4":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntelecom_data = pd.read_csv(os.path.join(dirname, 'telecom_churn_data.csv'))\ntelecom_data.head()       ","1caf6a2c":"\npd.read_excel('\/kaggle\/input\/telecom-churn-data-directory\/DataDictionary-TelecomChurnCaseStudy(1).xlsx')","f33c502b":"telecom_data.info(verbose=True)","593d288c":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(telecom_data.describe())","38dd5cc1":"telecom_data.shape","af5cd2e1":"def get_null_percentage(_data):\n    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n        return (_data.isnull().sum(axis=0)\/_data.shape[0]).sort_values(ascending= False)","0c7ed0e8":"get_null_percentage(telecom_data)","13de93c4":"telecom_data['good_phase_recharge'] = telecom_data['total_rech_amt_6'] + telecom_data['total_rech_amt_7']","ccb263d6":"seventy_percentile = int(telecom_data['good_phase_recharge'].quantile(.70))\ntelecom_data = telecom_data[(telecom_data.good_phase_recharge > seventy_percentile)]\ntelecom_data.shape","e79f751a":"null_values_per = get_null_percentage(telecom_data)\nfiltered_columns = list(null_values_per[null_values_per < 0.6].index)\nfiltered_data = telecom_data[filtered_columns]\nfiltered_data.head()","6df4cd85":"get_null_percentage(filtered_data)","07c63ea5":"# std_og_t2c_mou_6\n# std_ic_t2o_mou_6\n# std_ic_t2o_mou_8\n# std_og_t2c_mou_8\n# std_og_t2c_mou_9\n# std_ic_t2o_mou_9\n\n# ===> Drop these columns as there is no change in the data overall\ndropping_columns = [\n    'std_og_t2c_mou_6', 'std_ic_t2o_mou_6', 'std_ic_t2o_mou_8',\n    'std_og_t2c_mou_8', 'std_og_t2c_mou_9', 'std_ic_t2o_mou_9',\n    'std_og_t2c_mou_7', 'std_ic_t2o_mou_7', 'loc_og_t2o_mou', 'std_og_t2o_mou',\n    'loc_ic_t2o_mou', 'circle_id', 'mobile_number'\n]\nfiltered_data = filtered_data.drop(columns=dropping_columns, axis=1)","7e927f40":"filtered_data.roam_og_mou_9.fillna(0, inplace=True)","94a63a6d":"def is_churned(_x):\n    if ((_x.total_ic_mou_9 == 0) & (_x.total_og_mou_9 == 0) & (_x.vol_2g_mb_9 == 0) & (_x.vol_3g_mb_9 == 0)):\n        return 1\n    else:\n        return 0\nfiltered_data['churn'] = filtered_data.apply(is_churned, axis=1)","fbdd3099":"filtered_data.head()","17589650":"filtered_data.churn.value_counts()","d29730cc":"# ===> Drop columns 'last_date_of_month_6', 'last_date_of_month_7' as it's same across all columns\nfiltered_data.drop(columns=['last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8', 'last_date_of_month_9'], axis=1, inplace=True)","aaa87729":"def convert_to_datetime(_x, _columns):\n    _x[_columns] = _x[_columns].apply(pd.to_datetime, format='%m\/%d\/%Y')\n    return _x\n\n\n_columns = [\n     'date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_9', 'date_of_last_rech_8'\n]\nfiltered_data[_columns] = convert_to_datetime(filtered_data[_columns], _columns)","ad2fddb9":"without9_columns = filtered_data.columns.drop(list(filtered_data.filter(regex='_9')))\nfiltered_data = filtered_data[without9_columns] \nfiltered_columns = filtered_data.columns","19e0db01":"filtered_data[(filtered_data.arpu_7 <= 0) & (filtered_data.arpu_8 <= 0)].churn.value_counts() ","8ac55cf4":"for _column in filtered_columns:\n    plt.figure()\n    sns.boxplot(y=_column, x='churn', data=filtered_data, orient='v')\n    plt.show()","fe64e7df":"filtered_data.date_of_last_rech_7.dtype","4b6d836d":"def filter_date_and_day(_data):\n    for _column in _data.select_dtypes(include=['datetime64']).columns:\n        _data[_column + '_year'] = _data[_column].dt.year \n        _data[_column + '_month'] = _data[_column].dt.month \n        _data[_column + '_day'] = _data[_column].dt.day\n        _data.drop(columns=[_column], axis=1, inplace=True)\n    return _data\n\nfiltered_data = filter_date_and_day(filtered_data)\nfiltered_data.info(verbose=True)","d54dd11b":"filtered_data.select_dtypes(include=['datetime64']).columns","4d32a849":"filtered_data = filtered_data[~(filtered_data.apply(lambda x: sum(x.isnull().values), axis = 1)> 80)]","88db62eb":"filtered_data.shape","eeaf2788":"filtered_data.dropna(inplace=True)","7f5180af":"filtered_data.shape","a06121c0":"qar = filtered_data['loc_og_t2m_mou_6'].quantile(1.0)\nfiltered_data[ filtered_data['onnet_mou_8'] < qar].shape","8829af26":"def quantile_percentage(data):  \n    quantile = pd.DataFrame(columns=['col', '10','50','85','90','95','99','100','max'])\n    for col in data.columns:\n        _tmp = data[col].quantile([0.1,0.5,0.85,0.9,0.95,0.99,1.0])\n        quantile = quantile.append({'col': col, \n                                    '10': str(round(_tmp[0.1],2)), \n                                    '50': str(round(_tmp[0.5],2)),\n                                    '85': str(round(_tmp[0.85],2)),\n                                    '90': str(round(_tmp[0.9],2)),\n                                    '95': str(round(_tmp[0.95],2)),\n                                    '99': str(round(_tmp[0.99],2)),\n                                    '100': str(round(_tmp[1.0],2)),\n                                   'max':max(data[col])}, ignore_index=True)\n    return quantile\n\npd.set_option('display.max_rows', 500)\nquantile_percentage(filtered_data.select_dtypes([np.number]))","7a9ada34":"Q1 = filtered_data.quantile(0.05)\nQ3 = filtered_data.quantile(0.99)\nIQR = Q3 - Q1\n\nfiltered_data = filtered_data[~((filtered_data < (Q1 - 1.5 * IQR)) |(filtered_data > (Q3 + 1.5 * IQR))).any(axis=1)]\nfiltered_data.shape","9b6444a8":"X = filtered_data.drop(columns=['churn'], axis=1)\nY = filtered_data[['churn']]\n\nscaler = StandardScaler()\n_columns = X.columns\nX[_columns] = scaler.fit_transform(X)\nX.head()\n","436e53ff":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)","d1662068":"x_train.head()","d8de8113":"pca = PCA(random_state=100, svd_solver='randomized')\npca.fit_transform(x_train)","b3a7ead0":"pca.components_.round(3)","31844468":"colnames = list(x_train.columns)\npcs_df = pd.DataFrame({'PC1':pca.components_[0],'PC2':pca.components_[1], 'Feature':colnames})\npcs_df.head(10)","371b2496":"pca.explained_variance_ratio_.round(4)","eb8c1e33":"fig = plt.figure(figsize=(12, 8))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')\nplt.show()","d586b066":"pca_final = IncrementalPCA(n_components=85)\ndf_train_pca = pca_final.fit_transform(x_train)\ndf_train_pca.shape","6145f3eb":"corrmat = np.corrcoef(df_train_pca.transpose())\nplt.figure(figsize=(40, 40))\nsns.heatmap(corrmat, annot=True)","8f042335":"pca_test_data = pca_final.transform(x_test)\npca_test_data.shape","27ba0278":"logistic_regression = LogisticRegression()\nlogistic_model = logistic_regression.fit(df_train_pca, y_train)\npredicted_proba = logistic_model.predict_proba(pca_test_data)[:, 1]\n\"{:2.2}\".format(metrics.roc_auc_score(y_test, predicted_proba))","df610e57":"plt.figure(figsize=(8, 8))\nplt.scatter(df_train_pca[:, 0], df_train_pca[:, 1], c= y_train['churn'].map({0: 'red', 1: 'green'}))\nplt.xlabel('Principle component 1')\nplt.ylabel('Principle component 2')\nplt.show()","dce2f748":"fig = plt.figure(figsize=(8,8))\nax = Axes3D(fig)\n# ax = plt.axes(projection='3d')\nax.scatter(df_train_pca[:,2], df_train_pca[:,0], df_train_pca[:,1], c=y_train['churn'].map({0:'green',1:'red'}))","33fcedec":"pca_column_frame = pcs_df.head(85)\npca_column_frame.head()","d20d0bc0":"pca_column_frame['coeff'] = logistic_model.coef_[0]\npca_column_frame.sort_values(by=['coeff'])","556bed22":"rfc = RandomForestClassifier(n_jobs=-1, bootstrap=True,\n                             max_depth=4,\n                             min_samples_leaf=50, \n                             min_samples_split=50,\n                             max_features=8,\n                             n_estimators=60)\nrfc.fit(df_train_pca,y_train)","14426587":"predictions = rfc.predict(pca_test_data)","4dc064cf":"print(classification_report(y_test, predictions))","70b3e248":"accuracy_score(y_true=y_test, y_pred=predictions).round(2)","0c4226d5":"print(confusion_matrix(y_test, predictions))","048fe71a":"metrics.roc_auc_score(y_test, predicted_proba)","27ca5bd1":"import imblearn\nfrom imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(return_indices=True)\nx_rus, y_run, ind = rus.fit_sample(x_train, y_train)","8dc771aa":"x_rus.shape","06216155":"y_run.shape","9b8dac8f":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(return_indices=True)\n\n# x_ros, y_ros, ind = ros.fit_sample(x_train, y_train)\n# x_test_ros, y_test_ros, ind = ros.fit_sample(x_test, y_test)\n\nx_ros, y_ros, ind = ros.fit_sample(df_train_pca, y_train)\nx_test_ros, y_test_ros, ind = ros.fit_sample(pca_test_data, y_test)\nx_ros.shape","a3640492":"y_ros.sum()","a616b8c7":"def fit_random_forest(x_train_data, x_test_data, y_train_data, y_test_data):\n    rf = RandomForestClassifier(n_jobs=-1,\n                                bootstrap=True,\n                                max_depth=4,\n                                min_samples_leaf=50,\n                                min_samples_split=50,\n                                n_estimators=60)\n    rf.fit(x_train_data, y_train_data)\n    predictions = rf.predict(x_test_data)\n    print(classification_report(y_test_data, predictions))\n    print(accuracy_score(y_true=y_test_data, y_pred=predictions))\n    print(confusion_matrix(y_test_data, predictions))\n    return rf","c6ba917f":"rfe_algo = fit_random_forest(x_ros, x_test_ros, y_ros, y_test_ros)","70c81878":"from imblearn.combine import SMOTETomek\nsmt = SMOTETomek(ratio='auto')\nx_smt_train, y_smt_train = smt.fit_sample(df_train_pca, y_train)\nx_smt_test, y_smt_test = smt.fit_sample(pca_test_data, y_test)","03cb879c":"rfe_algo = fit_random_forest(x_smt_train, x_smt_test, y_smt_train, y_smt_test)","91e823b0":"rfe_algo.feature_importances_.round(3)","6852fa5f":"def fit_logistic_regression(x_train_data, x_test_data, y_train_data, y_test_data):\n    log = LogisticRegression(random_state=True)\n    log.fit(x_train_data, y_train_data)\n    predicted_proba = log.predict_proba(x_test_data)[:,1]\n    print(metrics.roc_auc_score(y_test_data, predicted_proba).round(3)*100)\n    return log","dc2723a6":"log_alg = fit_logistic_regression(x_smt_train, x_smt_test, y_smt_train, y_smt_test)","238cd71e":"_percentage = log_alg.predict_proba(x_smt_train)[:,1]","0b3b142b":"churn_predicted = pd.DataFrame({})\nchurn_predicted['ChurnProbability'] = _percentage\nchurn_predicted['y_train'] = y_smt_train\nchurn_predicted.head(10)","258d2ed5":"probabilities = [i\/10 for i in range(10) ]\ncutoff = pd.DataFrame(columns=['prob', 'accuracy', 'sensitivity', 'specificity'])\nfor _prob in probabilities:\n    churn_predicted[_prob] = churn_predicted.ChurnProbability.map(lambda x: 1 if x > _prob else 0)\n    cm = metrics.confusion_matrix(churn_predicted.y_train, churn_predicted[_prob])\n    total = sum(sum(cm))\n    _accuracy = round((cm[0, 0] + cm[1, 1])\/total, 3)\n    _sensitivity = round(cm[1,1] \/ (cm[1,0] + cm[1,1]), 3)\n    _specificity = round(cm[0,0] \/ (cm[0,0] + cm[0,1]), 3)\n    cutoff.loc[_prob] = [ _prob, _accuracy, _sensitivity,  _specificity ]\n    \ncutoff","d89f0efa":"cutoff.plot.line(x='prob', y=['accuracy', 'sensitivity', 'specificity'])","86fdd297":"_test_percentage = log_alg.predict_proba(x_smt_test)[:,1]\ntest_churn_predicted = pd.DataFrame({'ChurnProbability': log_alg.predict_proba(x_smt_test)[:,1]})\ntest_churn_predicted['y_test'] = y_smt_test\ntest_churn_predicted['0.55_predict'] = test_churn_predicted.ChurnProbability.map(lambda x: 1 if x > 0.55 else 0)\ntest_churn_predicted['0.65_predict'] = test_churn_predicted.ChurnProbability.map(lambda x: 1 if x > 0.65 else 0)\ntest_churn_predicted['0.60_predict'] = test_churn_predicted.ChurnProbability.map(lambda x: 1 if x > 0.6 else 0)\ntest_churn_predicted.head(10)","6f8c666e":"print(metrics.confusion_matrix(test_churn_predicted.y_test, test_churn_predicted['0.65_predict'])) \nprint(metrics.confusion_matrix(test_churn_predicted.y_test, test_churn_predicted['0.60_predict'])) \nprint(metrics.confusion_matrix(test_churn_predicted.y_test, test_churn_predicted['0.55_predict'])) ","0830e074":"_percentage = log_alg.predict_proba(x_smt_test)[:,1]","09126b69":"def draw_roc(actual, probability):\n    fpr, tpr, thershoulds = metrics.roc_curve(actual, probability, drop_intermediate=False)\n    auc = metrics.roc_auc_score(actual, probability)\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc)\n    plt.plot([0,1], [0,1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    return None\n\ndraw_roc(y_smt_test, _percentage)\n","504b728e":"pca_column_frame['sampling_coeff'] = log_alg.coef_[0]\npca_column_frame.iloc[(-np.abs(pca_column_frame['sampling_coeff'].values)).argsort()]","45360140":"model_rf = RandomForestClassifier(bootstrap=True,\n                                  max_depth=10,\n                                  min_samples_leaf=100, \n                                  min_samples_split=200,\n                                  n_estimators=1000,\n                                  oob_score = True, n_jobs = -1,\n                                  random_state =50,\n                                  max_features = 15,\n                                  max_leaf_nodes = 30)\nmodel_rf.fit(x_smt_train, y_smt_train)\n\n# Make predictions\nprediction_test = model_rf.predict(x_smt_test)\n\nprint(classification_report(y_smt_test,prediction_test))\nprint(confusion_matrix(y_smt_test,prediction_test))\n","5aec8089":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV","9593894d":"r_model = RandomForestClassifier()\nparams = {\n    'max_features': range(30, 40, 5),\n    'n_estimators': [40],\n    'min_samples_leaf': range(100, 150, 25),\n    'min_samples_split': range(100, 150, 25),\n    'max_depth': [7, 8, 9]\n}\n\nfolds = KFold(n_splits=2, shuffle=True, random_state=101)\ngrid_cv1 = GridSearchCV(r_model,\n                        param_grid=params,\n                        scoring='accuracy',\n                        n_jobs=-1,\n                        cv=folds,\n                        verbose=1,\n                        return_train_score=True)\ngrid_cv1.fit(x_smt_train, y_smt_train)","188ff0b0":"results = pd.DataFrame(grid_cv1.cv_results_)\nresults","d26947f0":"grid_cv1.best_params_","c6eb4a14":"best_estimator = grid_cv1.best_estimator_\nbest_estimator.fit(x_smt_train, y_smt_train)\n\n# Make predictions\nprediction_test = best_estimator.predict(x_smt_test)\n\nprint(classification_report(y_smt_test,prediction_test))\nprint(confusion_matrix(y_smt_test,prediction_test))","96ae9f3e":"pca_column_frame\n\nplt.figure(figsize=(20, 10))\ntop_10_features = pca_column_frame.iloc[(-np.abs(pca_column_frame['sampling_coeff'].values)).argsort()].head(10)\nsns.barplot(x='Feature', y='sampling_coeff', data=top_10_features)\nplt.xlabel('Features', size=20)\nplt.ylabel('Coefficient', size=20)\nplt.xticks(size = 14, rotation='vertical')\nplt.show()","a75aa7ae":"### Import Data: ","5b23c121":"##### Drop these columns as there is no change in the data overall","ae80ef6d":"### Logistic regression with PCA:","7435c650":"### Feature engineering:","cd74885b":"##### **Has an accuracy of 91.5**","ea649845":"### Problem Statement\n\nIn the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n\n \n\nFor many incumbent operators, retaining high profitable customers is the number one business goal.\n\n \n\nTo reduce customer churn, **telecom companies need to predict which customers are at high risk of churn.**","796530d3":"Note: There may be a chance of loosing the data with under sampling","46ee9fe6":"# Telecom chrun case study","e5417558":"### Over sampling with under sampling with logistic regression: ","59396ca6":"#### Remove rows with more than 80% null values:","120ca7da":"#### we try to make 85 components to describe 95% of the components","5950a373":"### Random Forest:","8e6a87d1":"#### Check correlation: ","bd84635a":"### Data preparation, Cleaning & Feature engineering:","a34ef1c1":"### Remove columns with more than 60% null values","ae77baf8":"#### Observation:\n\n**Though there is a accurasy of 94% it's not able to identify the churned users.**\n**it's because of class imbalance**\n**We will try to reduce the class imbalance using imblearn different techniques**","1bb04b71":"### Sampling: \n    * Use different sampling techniques to solve class imbalance problem.","97cf6a49":"**Observation: There is a overfit in the data set from the result we can see**","50956428":"## Random forest classifier with PCA:","18b53712":"### Import necessery libraries:","e388471b":"### EDA:","d62e4446":"#### Features list with variance explanation:","60210059":"### Over sampling: ","da4ceda0":"#### There is no co-relation b\/w the variables:","95f02e6e":"### Data understanding:","e727dfa0":"#### Correlation:","20ee2548":"### Outlier Treatment: \n    * Consider the columns with different quartile and apply the quartile \n    * Consdier the quartiles of 100, 99, 95, 90 for upper limit\n    * Consider the quartiles of 0, 10, 50 for lower limit","1d6e6519":"### Oversampling followed by under sampling:","896cf31b":"#### Dimentionality reduction: ","8f285f2d":"### Observation: \n\n### **From the observation we can see that PCA with Logistic regression has balanced specificity and recall**","01637f56":"##### Note: By observing the data we can say that it's better to do outlier treatment with 99% and 0.5% QUARTILES","5a97cc6b":"#### Remove columns with suffic _9 as those are once which decided to be a chrun customer. ","37b6baad":"### Model building and tuning:","a9497824":"##### Convert DateTime to numeric for model to consume:","bdd1d9c9":"#### Standardise the data: ","47f5bc52":"#### From the below observations we can derive the top features that can impact the churn: \n    * Outgoing others\n    * Roaming outgoing minutes of usage\n    * local outgoing minutes of usage\n    * STD outgoing Operator T to fixed lines of T\n    * STD incoming Operator T to fixed lines of T"}}