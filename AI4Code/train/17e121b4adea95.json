{"cell_type":{"3f261287":"code","d63e02ae":"code","d78cdbd4":"code","9966d45c":"code","6d5e9bc5":"code","78d77179":"code","42873ddb":"code","5f321363":"code","5c264c56":"code","a7f5fd4b":"code","4b2f3efe":"code","e59f57f6":"code","59c4a6af":"code","9a56560b":"code","0b160d0b":"code","2eeae4d9":"code","c948b55a":"code","a8dfa4d9":"code","5857c248":"code","f7ff8c4b":"code","e1ac680b":"code","8a50d91e":"code","57f0fa82":"code","c63c5ba1":"code","5a085e15":"code","30a0e98e":"code","582cb7cb":"code","443d2bc8":"code","615dd993":"code","5ad4ab1a":"code","434e2763":"code","8289668d":"code","0f7373d1":"code","fa69e1d9":"code","bd042b0c":"code","41e904ad":"code","923c5160":"code","4c9e3321":"code","5520163b":"code","4b5aa911":"code","b420f43c":"code","bce67a60":"code","e228d723":"code","f51a70aa":"code","efc761cc":"code","7a8a67b2":"code","d619d958":"code","71a92e6a":"code","b97ba958":"code","f5c20cc5":"code","67221e02":"code","f66a4b53":"code","a9e965ef":"code","0a95fa21":"code","e51961ac":"code","9da4c73f":"code","e2cbf812":"code","44a24d5e":"code","4af6df3b":"code","0cf9fea8":"code","74636d74":"code","19bdf21b":"code","384b3483":"code","6182c2e9":"code","94d4a1a4":"code","d1dbfb50":"code","5f8cbe9b":"code","b2c2a65c":"code","7a10b434":"code","ebcead33":"code","799aa11b":"code","8e03fb24":"code","f0bf61ed":"code","985c8bb9":"code","77b12136":"markdown","d3c7ead4":"markdown","0d041db7":"markdown","2876aeca":"markdown","8a093ccf":"markdown","0ea4865e":"markdown","cc26260c":"markdown","c718833f":"markdown","a8838283":"markdown","735e1907":"markdown","c35439d1":"markdown","b6b7a720":"markdown","1809ee1e":"markdown","130ec2e1":"markdown","f09fe242":"markdown","8c3e6ca8":"markdown","15981ec8":"markdown","87537725":"markdown","b5fd7c1f":"markdown","0e9c44f4":"markdown","2963052c":"markdown","bde5ca83":"markdown","5f8dc3f5":"markdown","7e3f3ae8":"markdown","bcec13b5":"markdown","23a5564b":"markdown","482cb676":"markdown","1687dc9c":"markdown","bba3dae5":"markdown","7608e8cb":"markdown","e0413fb7":"markdown","02b1e81b":"markdown","3fcdf93b":"markdown","11ab2e2e":"markdown","c1db61ba":"markdown","0517db44":"markdown","7009e0b9":"markdown","ab93dbea":"markdown","b6785b42":"markdown","b0bdee57":"markdown","26c871b3":"markdown","042e30bb":"markdown","d0d3a87c":"markdown","7a79472d":"markdown","29cfd604":"markdown"},"source":{"3f261287":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization\nplt.style.use(\"bmh\")\nimport seaborn as sns #Visualisation also \nfrom collections import Counter\nimport warnings \nwarnings.filterwarnings(\"ignore\")  #To ignore mistakes on the code (not necessary)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n#To see different kind of visualisation styles \n#plt.style.available","d63e02ae":"#To see different kind of visualisation styles \n#plt.style.available","d78cdbd4":"train_df=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_df=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_Id=test_df[\"PassengerId\"]","9966d45c":"#Lets see how many columns and attributes are there\ntrain_df.columns","6d5e9bc5":"#We can see the first rows of the columns with head .Just to see what information they contain\ntrain_df.head()","78d77179":"#For more specific info we use describe to obtain statistical information such as mean ,std,max etc...\ntrain_df.describe()","42873ddb":"# info about columns data category (types )is important for further applications\ntrain_df.info()","5f321363":"def bar_plot(variable):\n\n    \"\"\"\n    input:variable \n    output:bar plot & value count \n    \n    \"\"\"\n    #get the feature\n    var = train_df[variable]\n    #count number of categorical variable (value\/sample)\n    varValue =var.value_counts()\n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))\n\n\n   \n      ","5c264c56":"category1 = ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',   'Embarked']\n\nfor c in category1:\n    bar_plot(c)","a7f5fd4b":"category2 =[\"Cabin\",\"Name\",\"Ticket\"]\n\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","4b2f3efe":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable],bins =50) #Frekans\u0131 de\u011fi\u015ftirir (bins)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","e59f57f6":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","59c4a6af":"#Is there any correlation about class and survived ratio \n# Pclass vs Survived\n#sort ascending\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","9a56560b":"##Is there any correlation about sex and survived ratio\n#Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","0b160d0b":"##Is there any correlation about sibling and survived ratio\n#Sib vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","2eeae4d9":"##Is there any correlation about parch and survived ratio\n#Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"],as_index = False).mean().sort_values(by=\"Survived\",ascending = False)","c948b55a":"def detect_outliers(df,features):\n    outlier_indices=[]\n    for c in features:\n        #1st quartile\n        Q1 =np.percentile(df[c],25)\n        #3rd quartile\n        Q3 =np.percentile(df[c],75)\n        #IQR\n        IQR =Q3-Q1\n        #Outlier step\n        outlier_step =IQR * 1.5\n        #Detecting outliers index\n        outlier_list_col =df[(df[c] < Q1 -outlier_step) | (df[c] > Q3  + outlier_step)].index\n        #store indeces\n        outlier_indices.extend(outlier_list_col)\n\n        \n    outlier_indices=Counter(outlier_indices)\n    multiple_outliers = list(i for i,v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","a8dfa4d9":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","5857c248":"#drop outliers\ntrain_df =train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","f7ff8c4b":"#For control about running it over once\ntrain_df_len =len(train_df)\n\ntrain_df = pd.concat([train_df,test_df],axis= 0).reset_index(drop=True)\n","e1ac680b":"train_df.columns[train_df.isnull().any()]","8a50d91e":"train_df.isnull().sum()","57f0fa82":"train_df[train_df[\"Embarked\"].isnull()]","c63c5ba1":"train_df.boxplot(column = \"Fare\",by =\"Embarked\")\nplt.show()","5a085e15":"train_df[\"Embarked\"] =train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","30a0e98e":"train_df[train_df[\"Fare\"].isnull()]","582cb7cb":"train_df[\"Fare\"]=train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","443d2bc8":"list1 =[ \"SibSp\",\"Parch\",\"Age\",\"Fare\",\"Survived\"]\nsns.heatmap(train_df[list1].corr(),annot = True ,fmt= \".2f\")\nplt.show()\n","615dd993":"g = sns.factorplot(x = \"SibSp\", y= \"Survived\",data =train_df,kind =\"bar\",size = 9)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","5ad4ab1a":"g = sns.factorplot(x = \"Parch\", y= \"Survived\",data =train_df,kind =\"bar\",size = 9)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","434e2763":"g = sns.factorplot(x = \"Pclass\", y= \"Survived\",data =train_df,kind =\"bar\",size = 9)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","8289668d":"g = sns.FacetGrid(train_df, col=\"Survived\")\ng.map(sns.distplot, \"Age\" , bins = 25)\nplt.show()","0f7373d1":"g= sns.FacetGrid(train_df,col = \"Survived\" ,row =\"Pclass\")\ng.map(plt.hist,\"Age\",bins = 25)\ng.add_legend()\nplt.show()","fa69e1d9":"g = sns.FacetGrid(train_df , row = \"Embarked\", size = 3)\ng.map(sns.pointplot,\"Pclass\",\"Survived\" ,\"Sex\")\ng.add_legend()\nplt.show()","bd042b0c":"g = sns.FacetGrid(train_df, row = \"Embarked\",col = \"Survived\")\ng.map(sns.barplot,\"Sex\",\"Fare\")\ng.add_legend()\nplt.show()","41e904ad":"train_df[train_df[\"Age\"].isnull()]","923c5160":"sns.factorplot( x=\"Sex\",y=\"Age\",data=train_df, kind =\"box\")\nplt.show()","4c9e3321":"sns.factorplot( x=\"Sex\",y=\"Age\",hue =\"Pclass\",data=train_df, kind =\"box\")\nplt.show()","5520163b":"sns.factorplot( x=\"Parch\",y=\"Age\",data=train_df, kind =\"box\")\nsns.factorplot( x=\"SibSp\",y=\"Age\",data=train_df, kind =\"box\")\nplt.show()","4b5aa911":"#We need to use heatmap for correlation but in order to see the gender feature in heatmap.\n#Need to make sex  the feature numerical.","b420f43c":"train_df[\"Sex\"]=[1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]\nsns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),annot =True)\nplt.show()","bce67a60":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"])&(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])&(train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if  not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i]=age_med","e228d723":"train_df[train_df[\"Age\"].isnull()]","f51a70aa":"train_df[\"Name\"].head(10)","efc761cc":"#noktaya g\u00f6re ay\u0131r \nname =train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","7a8a67b2":"sns.countplot(x=\"Title\",data = train_df)\nplt.xticks(rotation =60)\nplt.show()","d619d958":"# convert to categorical \ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] =[0 if i== \"Master\" else 1 if i ==\"Miss\" or i ==\"Ms\" or i== \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]","71a92e6a":"g = sns.factorplot(x = \"Title\",y= \"Survived\",data= train_df,kind=\"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","b97ba958":"train_df.drop(labels = [\"Name\"],axis = 1,inplace=True)\ntrain_df.head()","f5c20cc5":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","67221e02":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df [\"Parch\"] +1","f66a4b53":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\" ,data =train_df, kind =\"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","a9e965ef":"train_df[\"family_size\"] = [1 if i<5 else 0 for i in train_df [\"Fsize\"]]","0a95fa21":"sns.countplot(x=\"family_size\",data=train_df)\nplt.show()","e51961ac":"g = sns.factorplot(x = \"family_size\", y = \"Survived\" ,data =train_df, kind =\"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","9da4c73f":"train_df = pd.get_dummies(train_df, columns = [\"family_size\"])\ntrain_df.head()","e2cbf812":"train_df[\"Embarked\"].head()","44a24d5e":"sns.countplot(x=\"Embarked\",data =train_df)","4af6df3b":"train_df = pd.get_dummies(train_df, columns =[\"Embarked\"])\ntrain_df.head()","0cf9fea8":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","74636d74":"#Prefix T changes the dummies colons from ticket to T\ntrain_df = pd.get_dummies(train_df, columns = [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","19bdf21b":"sns.countplot(x=\"Pclass\",data=train_df)\nplt.show()","384b3483":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])\ntrain_df.head()","6182c2e9":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Sex\"])\ntrain_df.head()","94d4a1a4":"train_df.drop(labels = [\"PassengerId\",\"Cabin\"], axis = 1,inplace = True)","d1dbfb50":"from sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","5f8cbe9b":"\ntest = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis=1 ,inplace=True)","b2c2a65c":"train = train_df[:train_df_len]\nX_train = train.drop(labels =\"Survived\",axis =1)\ny_train = train[\"Survived\"]\nX_train,X_test,y_train,y_test =train_test_split(X_train,y_train,test_size =0.33,random_state =42)\nprint(\"x_train\",len(X_train))\nprint(\"y_train\",len(y_train))\nprint(\"x_test\",len(X_test))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","7a10b434":"logreg =LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train =round(logreg.score(X_train,y_train)*100,2)\nacc_log_test =round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy : % {}\".format(acc_log_train))\nprint(\"Test Accuracy : % {}\".format(acc_log_test))","ebcead33":"random_state=42\nclassifier= [DecisionTreeClassifier(random_state = random_state),\n            SVC(random_state = random_state),\n            RandomForestClassifier( random_state = random_state),\n            LogisticRegression(random_state = random_state),\n            KNeighborsClassifier()]\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                    \"max_depth\" : range(1,20,2)}\nsvm_param_grid = {\"kernel\":[\"rbf\"],\n                 \"gamma\":[0.001,0.01,0.1,1],\n                 \"C\" :[1,10,50,100,200,300,1000]}\nrf_param_grid ={\"max_features\":[1,3,10],\n               \"min_samples_split\":[2,3,10],\n               \"min_samples_leaf\":[1,3,10],\n               \"bootstrap\":[False],\n               \"n_estimators\":[100,300],\n               \"criterion\":[\"gini\"]}\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\":[\"l1\",\"l2\"]}\nknn_param_grid ={\"n_neighbors\":np.linspace(1,19,10,dtype=int).tolist(),\n                \"weights\":[\"uniform\",\"distance\"],\n                \"metric\":[\"eucledian\",\"manhattan\"]}\nclassifier_param =[dt_param_grid,\n                   svm_param_grid,\n                   rf_param_grid ,\n                   logreg_param_grid,\n                   knn_param_grid]","799aa11b":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","8e03fb24":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\",\n                                                                            \"SVM\",\n                                                                            \"RandomForestClassifier\",\n                                                                            \"LogisticRegression\",\n                                                                            \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","f0bf61ed":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))\n\n","985c8bb9":"test_survived =pd.Series(votingC.predict(test),name=\"Survived\").astype(int)\nresults = pd.concat([test_Id,test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","77b12136":"<a id=\"20\"><\/a><br>\n### Fill Missing ; Age Feature","d3c7ead4":"<a id=\"26\"><\/a><br>\n## Pclass","0d041db7":"dtypes: float64(2): Fare and Age\n\nint64(5):PClass,Sipsp,parch,ID,Survived\n\nobject(5):Cabin,embarked,ticket,name ,Sex\n","2876aeca":"<a id=\"30\"><\/a><br>\n## Logistic Regression ","8a093ccf":"<a id=\"2\"><\/a><br>\n\n# Variable Description\n\n1. PassengerId:Id number of each passenger .It doesnt hold any specific info rather than numers\n1. Survived : Survived(1) or died(0)\n1. Pclass : High class (paid more ) or low class(paid less) .Correlates with Fare .\n1. Name \n1. Sex\n1. Age\n1. SibSp :Number of siblings and spouses\n1. Parch : Parents\/childern\n1. Ticket : no of ticket\n1. Fare :Ticket money\n1. Cabin : category of cabin\n1. Embarked : Where the passengers get on the ship ","0ea4865e":"* Graph shows us that a  persons who have a lot sib\/sp couldnt survive.\n* To get a better model we could Divide the Sib into two.","cc26260c":"<a id=\"27\"><\/a><br>\n## Gender","c718833f":"sng#Introduction\nTitanic was one of the biggest ship catastrophy of the 20th century.Out of 2224 passengers and crew members 1502 of them died .\nWe will try to anaylse this famous accident step by step with data analysis.\n\n<fond color= \"green\">\n\nContent:\n\n1. [Load and Check Data](#1)\n    \n2. [Variable Description](#2)\n * [Variable Anaylsis](#3) \n    * [Categorical Variable Analysis](#4)\n    * [Numerical Variable Analysis](#5)\n    \n3.[Basic Data Analysis](#6) \n    \n4.[Outlier Detection](#7)\n    \n5.[Missing Value](#8)\n  * [Finding Miss Val](#9)\n  * [Filling Miss Val](#10)\n    \n   \n6.[Visualisation](#11)\n  * [ Correlation between sibsp--parch--age--fare--survived](#12)\n  * [ Correlation between sibsp-survived](#13) \n  * [Fill Missing ; Age Feature](#20)\n    \n7.[Feature Engineering](#21)\n * [Name -- Title](#22)\n * [Family Size](#23)\n * [Embarked](#24)\n * [Ticket](#25)   \n * [Pclass](#26)  \n * [Sex](#27)\n * [Dropping Features:ID and Cabin](#28)\n    \n8.[Modeling: Train Test Split](#29)\n   * [Logistic Regression](#30)\n   * [Hyperparamater Tuning -- Grid Search -- Cross Validation](#31)","a8838283":"To guess where they get hey boat we need to use features that gives us hint about it for example  price can be a good measurement where they land . Lets check","735e1907":"<a id=\"31\"><\/a><br>\nHyperparamater Tuning -- Grid Search -- Cross Validation\n\n* We will compare different models in this section\n* Evaluating each model of time by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","c35439d1":"\n<a id=\"24\"><\/a><br>\n## Embarked","b6b7a720":"<a id=\"14\"><\/a><br>\n## Parch--Survived","1809ee1e":"In order to find this persons fare wee should check class 3's average payment","130ec2e1":"<a id=\"1\"><\/a><br>\n# Load and check Data","f09fe242":"<a id=\"33\"><\/a><br>\n## Ensemble Modelling","8c3e6ca8":"## Age -- Survived ","15981ec8":"## Embarked -- Sex -- Fare  -- Survived","87537725":"##  Embarked -- Sex -- Pclass -- Survived","b5fd7c1f":"Class gives us good info:\n-1 st class passengers are older than 2nd and the 3rd class is the youngest","0e9c44f4":"<a id=\"4\"><\/a><br>\n## Categorical Variable Analysis","2963052c":"## PClass - Survived - Age ","bde5ca83":"Small families have more chance to survive","5f8dc3f5":"<a id=\"8\"><\/a><br>\n# Missing Value\n* Finding and Filling","7e3f3ae8":"<a id=\"29\"><\/a><br>\n# Modeling: Train Test Split","bcec13b5":"<a id=\"5\"><\/a><br>\n## Numerical Variable Analysis","23a5564b":"## PClass -- Survived ","482cb676":"<a id=\"11\"><\/a><br>\n# [Visualisation]\n    \n   * [ Correlation between sibsp--parch--age--fare--survived]","1687dc9c":"<a id=\"22\"><\/a><br>\n## Name -- Title ","bba3dae5":"<a id=\"9\"><\/a><br>\n## Finding Missing Value","7608e8cb":"* The probabaility of them getting the ship on C is highly ","e0413fb7":"Smaller families  have  a bigger probability to survive\nSibso and parch can be used for new feature extraction with th = 3","02b1e81b":"<a id=\"13\"><\/a><br>\n## SibSp--Survived","3fcdf93b":"<a id=\"10\"><\/a><br>\n## Filling Mising Value\n* 2 missing value at embarked\n* 1 missing value at fare","11ab2e2e":"<a id=\"34\"><\/a><br>\n## Prediction and Submission","c1db61ba":"<a id=\"28\"><\/a><br>\n## Dropping Features \n### ID and Cabin","0517db44":"<a id=\"3\"><\/a><br>\n# Variable Anaylsis \n  * Categorical Variable Analysis:PClass,Sipsp,parch,Survived,ticket,name ,Sex\n  * Numerical Variable Analysis:ID,Fare and Age","7009e0b9":"<a id=\"21\"><\/a><br>\n# Feature Engineering","ab93dbea":"This heatmap  shows us that age is correlated with sibsp,parch and pclass","b6785b42":"* Female have much better survive rate .\n* Men have better survive rate  in C port ","b0bdee57":"<a id=\"7\"><\/a><br>\n# Outlier Detection\n\nIt is a method to eliminate the extreme values and find the average of the data.","26c871b3":"Does the title of the people affects the survival rate ? Lets see","042e30bb":"<a id=\"6\"><\/a><br>\n\n# Basic Data Analysis\n\n* Pclass-Survived\n* Sex-Survived\n* SibSp-Survived\n* Parch-Survived","d0d3a87c":"<a id=\"25\"><\/a><br>\n## Ticket Feature","7a79472d":"Gender is not gives us specific info about age.","29cfd604":"<a id=\"23\"><\/a><br>\n## Family Size "}}