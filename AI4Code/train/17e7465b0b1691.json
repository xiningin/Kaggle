{"cell_type":{"61d73140":"code","529baeb5":"code","6a961251":"code","41a8df58":"code","eb35c218":"code","6cb8c86c":"code","477be3eb":"code","050faf1b":"code","09abb600":"code","330dd245":"code","a6544558":"code","f9b1e0a8":"code","7adb80c6":"code","e6b0e75b":"code","1c6fdf89":"code","e6673542":"code","04046a6d":"code","8bc8efaf":"code","ae7edcb2":"code","3a92a49c":"code","75e23201":"code","a88fe8d4":"code","5718003e":"code","751dbd7c":"code","528cc723":"code","89c7fab2":"code","30120cf4":"code","dbc219a3":"code","f5f79205":"code","585dd752":"code","f8a0cbe9":"code","0a04a5c6":"code","ef69440c":"markdown","7f0cb9c9":"markdown","61fe5298":"markdown","a33fb934":"markdown","cabf358a":"markdown","9d1d3e3b":"markdown","82966959":"markdown","d19e87db":"markdown","cf306b0e":"markdown","daa84002":"markdown","c786c5c5":"markdown","b46f29e3":"markdown","16bfce8b":"markdown","3f43e928":"markdown","50f5cdcd":"markdown","49a4253b":"markdown","cfcd3163":"markdown","fea27805":"markdown","45f93472":"markdown"},"source":{"61d73140":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\n%matplotlib inline","529baeb5":"train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","6a961251":"print(\"The Shape of Training Set : {}\".format(train.shape))\nprint(\"The Shape of Testing Set : {}\".format(test.shape))\nprint(\"The Shape of Submission Set : {}\".format(submission.shape))\ntrain.head()","41a8df58":"train.loss.value_counts().plot(figsize=(16, 8), kind='bar')","eb35c218":"print(\"Total number of missing values: \", train.isna().sum().sum())","6cb8c86c":"# from sklearn.feature_selection import mutual_info_classif\n\n# importances = mutual_info_classif(X,Y)\n# feat_importances = pd.Series(importances, X.columns)\n# feat_importances.plot(kind='barh', color='teal')\n# plt.show()","477be3eb":"# np.where(importances == importances.max())\n# print(\"Column with max information gain: \", X.columns[82])","050faf1b":"# no correlation\n# corr_train=train.corr()\n# fig = plt.figure(figsize=(15,12))\n# sns.heatmap(corr_train)\n# corr.style.background_gradient(cmap='coolwarm')","09abb600":"# corr_train = corr_train['loss'].sort_values(ascending=False).round(2)\n# corr_train","330dd245":"# corr_train[corr_train >0]\n","a6544558":"#  Remove `id` column,no Relevant for the Work\nX = train.drop('id', axis = 1)\nX_test = test.drop('id', axis = 1)\n\n# target and labels\nX = X.drop(columns='loss')\ny = train['loss']\n\n# split dataset\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size = 0.3, random_state = 1)","f9b1e0a8":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline","7adb80c6":"#The best 50 Features\npca = Pipeline([('scale', MinMaxScaler()), ('pca', PCA(49, random_state=0))\n]).fit(X_train)\nX_train_pca = pca.transform(X_train)\nX_val_pca = pca.transform(X_val)\nX_test =pca.transform(X_test)","e6b0e75b":"# check gpu \nimport tensorflow as tf\nprint(\"is_built_with_cuda: \", tf.test.is_built_with_cuda())\ntf.config.list_physical_devices()","1c6fdf89":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\npca_xgb_model = XGBRegressor(max_depth=7,                     \n                      n_estimators=2500,\n                      learning_rate=0.008,\n                      subsample=0.84,\n                      booster= 'gbtree',\n                      tree_method= 'gpu_hist',\n                      colsample_bytree= 0.70,\n                      reg_lambda= 5,\n                      reg_alpha= 32,\n                      n_jobs= 4,            \n                      alpha=0.5,\n                      random_state=123).fit(X_train_pca, y_train, verbose = 200)","e6673542":"# prediction\npca_xgb_model_pred = pca_xgb_model.predict(X_val_pca)\npca_xgb_model_pred = np.clip(pca_xgb_model_pred, y.min(), y.max())\n\nprint(44 * '=')\nprint(f'XgBoost PCA - Mean Error: {mean_squared_error(y_val,pca_xgb_model_pred, squared = False)}')\nprint(44 * '=')","04046a6d":"pca_xgb_model_test_pred = pca_xgb_model.predict(X_test)\npca_xgb_model_test_pred = np.clip(pca_xgb_model_test_pred, y.min(), y.max())\n\n# save submission in csv file\npca_xgb_model_sub = submission.copy()\npca_xgb_model_sub.iloc[:,1] = pca_xgb_model_test_pred.data\npca_xgb_model_sub.to_csv(\"submission_pca_xgb.csv\",index=False)\nprint(\"submission_pca_xgb.csv file saved !!!\")","8bc8efaf":"from catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error\n\npca_catb_model = CatBoostRegressor(depth=6,\n                            iterations=1600,\n                            learning_rate=0.024,\n                            l2_leaf_reg=20,\n                            random_strength=1.5,\n                            grow_policy='Depthwise',\n                            leaf_estimation_method='Newton', \n                            bootstrap_type='Bernoulli',\n                            thread_count=4,\n                            verbose=False,\n                            loss_function='RMSE',\n                            eval_metric='RMSE',\n                            od_type='Iter',\n                            task_type='GPU',\n                            devices='0:1',\n                            early_stopping_rounds=500,\n                            random_state=123).fit(X_train_pca, y_train, verbose = 200)","ae7edcb2":"pca_catb_model_pred = pca_catb_model.predict(X_val_pca)\npca_catb_model_pred = np.clip(pca_catb_model_pred, y.min(), y.max())\n\nprint(44 * '=')\nprint(f'CatBoost PCA - Mean Error: {mean_squared_error(y_val,pca_catb_model_pred, squared = False)}')\nprint(44 * '=')","3a92a49c":"pca_catb_model_test_pred = pca_catb_model.predict(X_test)\npca_catb_model_test_pred = np.clip(pca_catb_model_test_pred, y.min(), y.max())\n\n# save submission in csv file\npca_catb_model_sub = submission.copy()\npca_catb_model_sub.iloc[:,1] = pca_catb_model_test_pred.data\npca_catb_model_sub.to_csv(\"submission_pca_catb.csv\",index=False)\nprint(\"submission_pca_catb.csv file saved !!!\")","75e23201":"from sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(random_state=123).fit(X_train, y_train)\nFeatures_importance = pd.DataFrame([(col,coef) for col , coef in zip(X.columns,dt.feature_importances_)], \n             columns = ['feature', 'importance']).set_index('feature').sort_values('importance',ascending = False)\nFeatures_importance","a88fe8d4":"Features_importance = Features_importance[Features_importance.values > 0.01]\nFeatures_importance.shape","5718003e":"Features_importance.index","751dbd7c":"# filter columns according to above features\nX_RF = X[Features_importance.index]\nX_test_RF = test.drop (columns = ['id'])\nX_test_RF = X_test_RF[Features_importance.index]\nX_RF.shape,X_test_RF.shape","528cc723":"## Scaling data\nscaler = StandardScaler()\nscaler.fit(X_RF)\nX_RF = scaler.transform(X_RF)\nX_test_RF = scaler.transform(X_test_RF)\nX_train_RF,X_val_RF,y_train_RF,y_val_RF=train_test_split(X_RF,y,test_size = 0.3, random_state = 1)","89c7fab2":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\nrf_xgb_model = XGBRegressor(max_depth=7,                     \n                      n_estimators=2500,\n                      learning_rate=0.008,\n                      subsample=0.84,\n                      booster= 'gbtree',\n                      tree_method= 'gpu_hist',\n                      colsample_bytree= 0.70,\n                      reg_lambda= 5,\n                      reg_alpha= 32,\n                      n_jobs= 4,            \n                      alpha=0.5,\n                      random_state=123).fit(X_train_RF, y_train_RF)","30120cf4":"rf_xgb_model_pred = rf_xgb_model.predict(X_val_RF)\nrf_xgb_model_pred = np.clip(rf_xgb_model_pred, y.min(), y.max())\n\nprint(44 * '=')\nprint(f'XgBoost RF - Mean Error: {mean_squared_error(y_val_RF,rf_xgb_model_pred, squared = False)}')\nprint(44 * '=')","dbc219a3":"rf_xgb_model_test_pred = rf_xgb_model.predict(X_test_RF)\nrf_xgb_model_test_pred = np.clip(rf_xgb_model_test_pred, y.min(), y.max())\n\n# save submission in csv file\nrf_xgb_model_sub = submission.copy()\nrf_xgb_model_sub.iloc[:,1] = rf_xgb_model_test_pred.data\nrf_xgb_model_sub.to_csv(\"submission_rf_xgb.csv\",index=False)\nprint(\"submission_rf_xgb.csv file saved !!!\")","f5f79205":"from catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_squared_error\n\nrf_catb_model = CatBoostRegressor(depth=6,\n                            iterations=1600,\n                            learning_rate=0.024,\n                            l2_leaf_reg=20,\n                            random_strength=1.5,\n                            grow_policy='Depthwise',\n                            leaf_estimation_method='Newton', \n                            bootstrap_type='Bernoulli',\n                            thread_count=4,\n                            verbose=False,\n                            loss_function='RMSE',\n                            eval_metric='RMSE',\n                            od_type='Iter',\n                            task_type='GPU',\n                            devices='0:1',\n                            early_stopping_rounds=500,\n                            random_state=123).fit(X_train_RF, y_train_RF, verbose = 200)","585dd752":"rf_catb_model_pred = rf_catb_model.predict(X_val_RF)\nrf_catb_model_pred = np.clip(rf_catb_model_pred, y.min(), y.max())\n\nprint(44 * '=')\nprint(f'catBoost RF - Mean Error: {mean_squared_error(y_val_RF,rf_catb_model_pred, squared = False)}')\nprint(44 * '=')","f8a0cbe9":"rf_catb_model_test_pred = rf_catb_model.predict(X_test_RF)\nrf_catb_model_test_pred = np.clip(rf_catb_model_test_pred, y.min(), y.max())\n\n# save submission in csv file\nrf_catb_model_sub = submission.copy()\nrf_catb_model_sub.iloc[:,1] = rf_catb_model_test_pred.data\nrf_catb_model_sub.to_csv(\"submission_rf_catb.csv\",index=False)\nprint(\"submission_rf_catb.csv file saved !!!\")","0a04a5c6":"print(f'XgBoost PCA - Mean Error : {mean_squared_error(y_val,pca_xgb_model_pred, squared = False)}')\nprint(f'CatBoost PCA - Mean Error: {mean_squared_error(y_val,pca_catb_model_pred, squared = False)}')\nprint(f'XgBoost RF - Mean Error  : {mean_squared_error(y_val_RF,rf_xgb_model_pred, squared = False)}')\nprint(f'CatBoost RF - Mean Error : {mean_squared_error(y_val_RF,rf_catb_model_pred, squared = False)}')","ef69440c":"### 9.3 RF Model II - CatBoostRegressor","7f0cb9c9":"### The most correlated Features (Above 0)","61fe5298":"### 9.2 RF Model I - XGBRegressor","a33fb934":"### 5.1. Information Gain - filter method","cabf358a":"## 4. Checking Missvalues","9d1d3e3b":"## 10. Final result","82966959":"## 2. Read dataset","d19e87db":"## 3. Plot the Target Distribution","cf306b0e":"Perform 2 different approaches dimensionality reduction(using PCA) and feature selection(using random forest) to reduce features, and derive which is better approach for given dataset.","daa84002":"### 8.1 PCA Model I - XGBRegressor","c786c5c5":"## 7. Split dataset","b46f29e3":"<div>\n<h1 align=\"center\">Dimensionality Reduction Vs. Feature Selection<\/h3>\n<h3 align=\"center\">Tabular Playground Series - Aug 2021<\/h3>\n<h4 align=\"center\">By: Saurabh Zinjad<\/h3>\n<h3 align=\"center\">If you find this work useful, please don't forget upvoting :)<\/h3>\n<\/div>","16bfce8b":"## 5. Feature selection","3f43e928":"### 8.2 PCA Model II - CatBoostRegressor","50f5cdcd":"## 9. Feature Selection using DecisionTree","49a4253b":"## 8. Dimensionality reduction With PCA","cfcd3163":"## 6. Analysis Correlation","fea27805":"## 1. Libraries and packages setup","45f93472":"### 9.1 Get best 50 features using `DecisionTreeRegressor`"}}