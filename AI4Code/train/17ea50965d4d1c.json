{"cell_type":{"b8c823e9":"code","c29e5bcf":"code","8b02dbe9":"code","dc76f683":"code","9c04ae28":"code","c0692a75":"code","562c9365":"code","d96c9bf9":"code","4a44a6ef":"code","c4485d47":"code","89738654":"code","3f7e1fa9":"code","ea9b8f32":"code","e134beaf":"code","1d1c1d6c":"code","55293ee2":"code","f8bda394":"code","f63cb676":"code","2370c403":"code","254194f3":"code","3a36e40b":"code","d0679fdb":"code","b2cc3b1d":"code","3ea59a7a":"code","d4a59f0c":"code","8e75adcd":"code","f253b226":"code","a2040601":"code","f78a38a8":"code","a8d8677e":"code","9e977dde":"code","1aaff014":"code","c0284699":"code","e84e385a":"code","ed716b00":"code","f9e19b21":"code","6cf341da":"code","8f5da796":"code","f79552bf":"code","6caf7bd1":"code","1f6848b0":"code","2ec3a79c":"code","4993ea98":"code","0c472826":"code","63cad32e":"code","b4c40777":"code","c95c0739":"code","57b00796":"code","94fcfec7":"code","a88a1633":"code","9f104760":"code","ce3ad2c1":"code","b071f653":"code","6fe4bf6b":"code","6b406f9f":"code","3dcba2d7":"code","e9e51c52":"code","56742979":"code","ab80f33b":"code","26ad98bf":"code","8d23cc40":"code","a4f6478f":"code","3f29fca3":"code","4749c4fd":"code","5df5e6d5":"code","20cce90d":"code","2f12b896":"code","48ba5c78":"code","cd37b55e":"code","fdbc9a6a":"code","017a0a13":"code","12eff1c0":"code","6412e892":"code","0d6e8a33":"code","92bed20b":"code","ddd51be0":"code","14308f7c":"code","cb583202":"code","20c8d2ec":"markdown","b7427e77":"markdown","ef5eac93":"markdown","052b6b37":"markdown","2b81aafb":"markdown"},"source":{"b8c823e9":"import pandas as pd\nimport platform\nfrom sklearn.model_selection import train_test_split\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom nltk.corpus import words\n#nltk.download('punkt')\nfrom sklearn.pipeline import Pipeline\n#from sklearn.linear_model import LogisticRegression\nimport sklearn.linear_model as lm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import precision_score, recall_score, precision_recall_curve, f1_score\nfrom sklearn import metrics\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import plot_precision_recall_curve\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV","c29e5bcf":"pd.set_option('display.max_colwidth', None)","8b02dbe9":"df = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\", sep=\",\")","dc76f683":"df.shape","9c04ae28":"df.head(20)","c0692a75":"df.head(20)","562c9365":"df.tail(20)","d96c9bf9":"df[\"target\"].value_counts()","4a44a6ef":"count_class_0, count_class_1 = df[\"target\"].value_counts()","c4485d47":"print(count_class_0, count_class_1)","89738654":"class_ratio = count_class_0 \/ count_class_1","3f7e1fa9":"print(\"{0:.3f}\".format(class_ratio))","ea9b8f32":"df.head(20)","e134beaf":"df.loc[df[\"target\"] == 1].head(10)","1d1c1d6c":"df.loc[df[\"target\"] == 0].head(10)","55293ee2":"for c in df[df[\"target\"] == 1][\"text\"].head(10):\n    print(c)","f8bda394":"for c in df[df[\"target\"] == 0][\"text\"].head(10):\n    print(c)","f63cb676":"# Since classes are imbalanced, we need to resample the dataframe\n# First divide by class\ndf_class_0 = df[df[\"target\"] == 0]\ndf_class_1 = df[df[\"target\"] == 1]","2370c403":"df_class_0","254194f3":"df_class_1","3a36e40b":"# Second resample - try both under- and over-sampling\ndf_class_0_under = df_class_0.sample(count_class_1) # undersampling by loosing objects\ndf_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\ndf_class_1_over = df_class_1.sample(count_class_0, replace=True) # oversampling by duplicaitng objects\ndf_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n\n#df = df_under\n#df = df_over\n\n# Looks like oversampling works better since we use more objects - more training cases","d0679fdb":"df[\"target\"].value_counts()","b2cc3b1d":"train_df, test_df = train_test_split(df, train_size=0.9)","3ea59a7a":"test_df.shape","d4a59f0c":"train_df[\"target\"].value_counts()","8e75adcd":"test_df[\"target\"].value_counts()","f253b226":"#eng_words = words.words(\"en\")","a2040601":"#print(\"wort\" in eng_words)","f78a38a8":"snowball = SnowballStemmer(language=\"english\")","a8d8677e":"def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n    '''Tokenize sentences with nltk dropping non-english words and punctuation and optionally stop words'''\n    tokens = word_tokenize(sentence, language=\"english\")\n    #tokens = [i for i in tokens if i in eng_words and i not in string.punctuation]\n    tokens = [i for i in tokens if i not in string.punctuation]\n    if remove_stop_words:\n        tokens = [i for i in tokens if i not in stopwords.words(\"english\")]\n    tokens = [snowball.stem(i) for i in tokens]\n    return tokens","9e977dde":"tokenize_sentence(\"the sentence and asdf fy krkr\", False)","1aaff014":"vectorizer_params = {\n    #\"max_features\": 500,\n    #\"max_features\": None,\n    #\"tokenizer\": lambda x: tokenize_sentence(x, remove_stop_words=False),\n    #\"tokenizer\": None,\n    #\"ngram_range\": (1, 100),\n    #\"min_df\": 0,\n    #\"max_df\": 100,\n    #\"use_idf\": False,\n    #\"decode_error\": \"replace\",\n    #\"sublinear_tf\": True,\n    #\"analyzer\": \"char\"\n}","c0284699":"vectorizer = TfidfVectorizer(**vectorizer_params)","e84e385a":"vectorizer","ed716b00":"features = vectorizer.fit_transform(train_df[\"text\"])","f9e19b21":"print(features.shape)","6cf341da":"feature_names = vectorizer.get_feature_names()","8f5da796":"print(\"Feature names (unique tokens): {0}.\\nFeature count: {1}\".format(feature_names, len(feature_names)))","f79552bf":"print('fire' in feature_names)","6caf7bd1":"X_train = train_df[\"text\"]","1f6848b0":"X_train","2ec3a79c":"y_train = train_df[\"target\"]","4993ea98":"y_train","0c472826":"lr_model_params = {\n    #\"class_weight\": \"balanced\",\n    #\"class_weight\": None,\n    #\"class_weight\": {1: 1, 0: 1\/class_ratio},\n    #\"random_state\": 0,\n    #\"Cs\": 5,\n    #\"penalty\": \"none\",\n    #\"penalty\": \"elasticnet\",\n    \"solver\": \"liblinear\",\n    #\"l1_ratio\": 0.5,\n    #\"max_iter\": 10000,\n    #\"cv\": 10\n}","63cad32e":"model = lm.LogisticRegressionCV(**lr_model_params)\n#features = features[:,-2000:]\nmodel.fit(features, y_train)","b4c40777":"model.n_features_in_","c95c0739":"text_n = 10\nfeatures[text_n]","57b00796":"test_model_y = model.predict(features[text_n])","94fcfec7":"test_model_y[0]","a88a1633":"train_df[\"text\"].iloc[text_n]","9f104760":"model_pipeline = Pipeline([\n    (\"vectorizer\", vectorizer),\n    (\"model\", model)\n]\n)","ce3ad2c1":"model_pipeline.fit(X_train, y_train)","b071f653":"model_pipeline.classes_","6fe4bf6b":"len(model.coef_[0])","6b406f9f":"model.C_","3dcba2d7":"model_pipeline.named_steps","e9e51c52":"#model_pipeline.predict([\"Attention: bush fire reported!\"])","56742979":"#model_pipeline.predict([\"Kids were playing in the park.\"])","ab80f33b":"#model_pipeline.get_params()","26ad98bf":"#y_test = y_train\ny_test = test_df[\"target\"]","8d23cc40":"#y_pred = model_pipeline.predict(X_train)\ny_pred = model_pipeline.predict(test_df[\"text\"])","a4f6478f":"#print(precision_score(y_true=y_test, y_pred=y_pred))","3f29fca3":"#print(recall_score(y_true=y_test, y_pred=y_pred))","4749c4fd":"#print(f1_score(y_true=y_test, y_pred=y_pred))","5df5e6d5":"print(metrics.classification_report(y_test, y_pred, labels = [1, 0], digits=5))","20cce90d":"f1_1 = metrics.classification_report(y_test, y_pred, output_dict=True)[\"1\"][\"f1-score\"]\nf1_0 = metrics.classification_report(y_test, y_pred, output_dict=True)[\"0\"][\"f1-score\"]\nprint(\"Mean f1 score: {0:.5f}\".format((f1_1 + f1_0)\/2))","2f12b896":"plot_precision_recall_curve(estimator=model_pipeline, X=test_df[\"text\"], y=y_test)","48ba5c78":"model_pipeline.score(test_df[\"text\"], y_test)","cd37b55e":"pred_df = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\", sep=\",\")","fdbc9a6a":"pred_df.shape","017a0a13":"pred_df.head()","12eff1c0":"pred_df[\"target\"] = model_pipeline.predict(pred_df[\"text\"])","6412e892":"pred_df.shape","0d6e8a33":"pred_df.head(20)","92bed20b":"pred_df.tail(20)","ddd51be0":"pred_df.drop(columns=[\"keyword\", \"location\", \"text\"], inplace=True)","14308f7c":"pred_df.head()","cb583202":"pred_df.to_csv(\"\/kaggle\/working\/nlp_disaster_tweets_tfidf_lr_submission.csv\", index=False)","20c8d2ec":"#### Create and train our Logistic Regression model","b7427e77":"#### Denote train sample (train_df) as y_train","ef5eac93":"#### Denote features as X_train","052b6b37":"#### Convert a collection of raw documents to a matrix of TF-IDF features.","2b81aafb":"#### Learn vocabulary and idf, return Tf-idf-weighted document-term matrix."}}