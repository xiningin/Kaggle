{"cell_type":{"6753fb5f":"code","6367c3bf":"code","2689606e":"code","eca896c3":"code","c3ba9246":"code","0c0e9510":"code","d8c2a843":"code","f7f174b9":"code","153ba26c":"code","5c37c9d6":"code","5d7edbd0":"code","50aec3a7":"code","4fd4182c":"code","27fbd186":"code","2ffcb11b":"code","6b302023":"code","3dab9478":"code","bf780106":"code","9c36cd91":"code","a1bc152f":"code","55491817":"code","b691bc0d":"code","f6ad1508":"code","6cbe7074":"code","f5a5c889":"code","17f315a1":"code","57e14f49":"code","24c42778":"code","4b09a158":"code","7f0ae4fd":"code","bd6d6a98":"code","8470b396":"code","d99bbcda":"code","ecd199db":"code","666ad9fd":"code","51fe3a37":"code","fa45b5c0":"markdown","2d45878a":"markdown","a8e233ad":"markdown","744c2a5c":"markdown","363b12db":"markdown","b1778e2b":"markdown","b84e09af":"markdown","5e171c9b":"markdown","56414299":"markdown","a6c99909":"markdown","738d5ab9":"markdown","07d15915":"markdown","a6b6d03e":"markdown","53f2b9a5":"markdown","cb62d5db":"markdown","464e742c":"markdown","551ebcb8":"markdown","9bcd116c":"markdown","2d512c21":"markdown","23ac6f17":"markdown","76f4b6ea":"markdown","e2d4fa32":"markdown","c26320f6":"markdown","03000980":"markdown"},"source":{"6753fb5f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\n\n# for interactive visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\n#import plotly.figure_factory as ff","6367c3bf":"# importing the dataset\ndf = pd.read_csv('\/kaggle\/input\/123qweasd\/Mall_Customers.csv')\ndf.head()","2689606e":"df.info()","eca896c3":"df.shape","c3ba9246":" df.isnull().sum()","0c0e9510":"#df.iloc[:,[3,4]]","d8c2a843":"df.describe().T","f7f174b9":"df.Gender.value_counts()","153ba26c":"#distribution of age\n\nf, ax = plt.subplots(figsize=(10,8))\nax = sns.histplot(df['Age'],bins=10,color = 'orange')\nax.set_title(\"Distribution of age variable\")\n#ax.set_xticklabels(df.Age.value_counts().index, rotation = 30)\n\nplt.show()","5c37c9d6":"#Mean Age by gender \n\nf, ax = plt.subplots(figsize=(6,4))\nax = sns.boxenplot(x = 'Gender',y = 'Age', data = df)\nax.set_title(\"Age by Gender\")\nplt.show()","5d7edbd0":"#distribution of income\n\nf, ax = plt.subplots(figsize=(10,8))\nax = sns.histplot(df['Annual Income (k$)'],bins=10,color = 'orange')\nax.set_title(\"Distribution of income variable\")\n#ax.set_xticklabels(df.Age.value_counts().index, rotation = 30)\n\nplt.show()","50aec3a7":"#Mean Income by gender \n\nf, ax = plt.subplots(figsize=(6,4))\nax = sns.boxplot(x = 'Gender',y = 'Annual Income (k$)', data = df)\nax.set_title(\"Income by Gender\")\nplt.show()","4fd4182c":"#distribution of spending\n\nf, ax = plt.subplots(figsize=(10,8))\nax = sns.histplot(df['Spending Score (1-100)'],bins=10,color = 'orange')\nax.set_title(\"Distribution of spending variable\")\n#ax.set_xticklabels(df.Age.value_counts().index, rotation = 30)\n\nplt.show()","27fbd186":"#Mean spending by gender \n\nf, ax = plt.subplots(figsize=(6,4))\nax = sns.boxplot(x = 'Gender',y = 'Spending Score (1-100)', data = df)\nax.set_title(\"Spending by gender\")\nplt.show()","2ffcb11b":"df.corr()","6b302023":"# Draw a scatter plot while assigning point colors and sizes to different\n# variables in the dataset\nf, ax = plt.subplots(figsize=(6.5, 6.5))\n#sns.despine(df, left=True, bottom=True)\n#clarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(x=\"Age\", y=\"Annual Income (k$)\",\n                hue=\"Gender\",\n                palette=\"ch:r=-.2,d=.3_r\",\n                #hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=df, ax=ax)\nax.set_title(\"Age vs Annual Income\")\nplt.show()","3dab9478":"# Draw a scatter plot while assigning point colors and sizes to different\n# variables in the dataset\nf, ax = plt.subplots(figsize=(6.5, 6.5))\n#sns.despine(df, left=True, bottom=True)\n#clarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(x=\"Age\", y=\"Spending Score (1-100)\",\n                hue=\"Gender\",\n                palette=\"ch:r=-.2,d=.3_r\",\n                #hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=df, ax=ax)\nax.set_title(\"Age vs Spending Score\")\nplt.show()","bf780106":"# Draw a scatter plot while assigning point colors and sizes to different\n# variables in the dataset\nf, ax = plt.subplots(figsize=(6.5, 6.5))\n#sns.despine(df, left=True, bottom=True)\n#clarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(y=\"Spending Score (1-100)\", x=\"Annual Income (k$)\",\n                hue=\"Gender\",\n                palette=\"ch:r=-.2,d=.3_r\",\n                #hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=df, ax=ax)\nax.set_title(\"Annual Income vs Spending Score\")\nplt.show()","9c36cd91":"cdataincomess = df.iloc[:,[3,4]]\ncdataincomess","a1bc152f":"wcss1 = []\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i,init = 'k-means++',random_state = 0)\n    kmeans.fit(cdataincomess) \n    wcss1.append(kmeans.inertia_)\n","55491817":"#plot the elblow graph to plot the clusters vs wcss values\n\n#sns.set_style(\"darkgrid\")\nplt.style.use(\"dark_background\")\nplt.plot(range(1,11),wcss1)\nplt.title(\"Eblow graph\")\nplt.xlabel(\"Clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()\n","b691bc0d":"kmeans = KMeans(n_clusters = 5,init = 'k-means++',random_state = 0)\npredictedclusters = kmeans.fit_predict(cdataincomess)\n\nprint(predictedclusters)","f6ad1508":"# variables in the dataset\nf, ax = plt.subplots(figsize=(10, 8))\nplt.style.use(\"dark_background\")\n#sns.set_style(\"darkgrid\")\n#sns.despine(df, left=True, bottom=True)\nsns.scatterplot(x=cdataincomess['Annual Income (k$)'], y=cdataincomess['Spending Score (1-100)'],\n                hue=predictedclusters,\n                palette=\"deep\",\n                #hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=cdataincomess, ax=ax)\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],c='cyan')\nax.set_title(\"Customer Groups in Clusters\")\nplt.show()","6cbe7074":"# Measures the separation distance between the Clusters , Closer to 1 is a good score\nfrom sklearn.metrics import silhouette_score\nScore = silhouette_score(cdataincomess, kmeans.labels_, metric='euclidean', sample_size=None, random_state=None)\n\nprint(\"Silhoutte Score\", Score)","f5a5c889":"cdataagess = df.iloc[:,[2,4]]\ncdataagess","17f315a1":"wcss2 = []\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i,init = 'k-means++',random_state = 0)\n    kmeans.fit(cdataagess) \n    wcss2.append(kmeans.inertia_)","57e14f49":"plt.style.use(\"dark_background\")\nplt.plot(range(1,11),wcss2)\nplt.title(\"Eblow graph\")\nplt.xlabel(\"Clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()","24c42778":"kmeans = KMeans(n_clusters = 4,init = 'k-means++',random_state = 0)\npredictedclusters2 = kmeans.fit_predict(cdataagess)\n\nprint(predictedclusters2)","4b09a158":"# variables in the dataset\nf, ax = plt.subplots(figsize=(10, 8))\nplt.style.use(\"dark_background\")\n#sns.set_style(\"darkgrid\")\n#sns.despine(df, left=True, bottom=True)\n#clarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(x=cdataagess['Age'], y=cdataagess['Spending Score (1-100)'],\n                hue=predictedclusters2,\n                palette=\"deep\",\n                #hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=cdataagess, ax=ax)\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],c='cyan')\nax.set_title(\"Customer Age Groups in Clusters\")\nplt.show()","7f0ae4fd":"# Measures the separation distance between the Clusters , Closer to 1 is a good score\nfrom sklearn.metrics import silhouette_score\nScore2 = silhouette_score(cdataagess, kmeans.labels_, metric='euclidean', sample_size=None, random_state=None)\n\nprint(\"Silhoutte Score\", Score2)","bd6d6a98":"cdataagein = df.iloc[:,[2,3]]\ncdataagein","8470b396":"wcss3 = []\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i,init = 'random',random_state = 0,max_iter = 300)\n    kmeans.fit(cdataagein) \n    wcss3.append(kmeans.inertia_)","d99bbcda":"plt.style.use(\"dark_background\")\nplt.plot(range(1,11),wcss3)\nplt.title(\"Eblow graph\")\nplt.xlabel(\"Clusters\")\nplt.ylabel(\"WCSS3\")\nplt.show()","ecd199db":"kmeans = KMeans(n_clusters = 4,init = 'random',random_state = 0,max_iter = 300)\npredictedclusters3 = kmeans.fit_predict(cdataagein)\n\nprint(predictedclusters3)","666ad9fd":"# variables in the dataset\nf, ax = plt.subplots(figsize=(10, 8))\nplt.style.use(\"dark_background\")\n#sns.set_style(\"darkgrid\")\n#sns.despine(df, left=True, bottom=True)\n#clarity_ranking = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]\nsns.scatterplot(x=cdataagein['Age'], y=cdataagein['Annual Income (k$)'],\n                hue=predictedclusters3,\n                palette=\"deep\",\n                #hue_order=clarity_ranking,\n                sizes=(1, 8), linewidth=0,\n                data=cdataagein, ax=ax)\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],c='cyan')\nax.set_title(\"Customer Age Groups in Clusters\")\nplt.show()","51fe3a37":"# Measures the separation distance between the Clusters , Closer to 1 is a good score\nfrom sklearn.metrics import silhouette_score\nScore3 = silhouette_score(cdataagein, kmeans.labels_, metric='euclidean', sample_size=None, random_state=None)\n\nprint(\"Silhoutte Score\", Score3)","fa45b5c0":"# Optimum number of Clusters is 5\n\n# Now lets train the K-Means Clustering Model with 5 clusters","2d45878a":"# Now lets Cluster the Spending Score by Age group","a8e233ad":"# Lets Cluster this time by Age and Income","744c2a5c":"# Plot the predicted Clusters against the data","363b12db":"# Choosing the number of Clusters using elbow method to get the minimum WCSS value","b1778e2b":"# As age increases the spending score tends to decrease with more customers in the age group of 20's to 40's","b84e09af":"# Looking at Annual income vs Spending score, we tend to have different customer segments for each income\/spending category","5e171c9b":"# Optimum number of Clusters is 4\n\n# Now lets train the K-Means Clustering Model with 4 clusters","56414299":"# There is no strong correlation among any of the continuous variables except for Age and Spending score which seems to have a negative correlation.","a6c99909":"# Based on our finding above, lets select Annual Income and Spending Score for Clustering to see any strong clusters in the population","738d5ab9":"# From the above plot we can see that there are more clusters in the early age groups compared to the older age group as the spending reduces or gets more conservative with aging","07d15915":"# From the age distribution, we can see that the customers in the age group of late 20's and early 30's are more likely to shop followed by teens","a6b6d03e":"# The Silhoutte score is lower than the first cluster suggesting that this model is not as better than the above model","53f2b9a5":"# There are more males in the age group of 30 to 50 than females","cb62d5db":"# Import the Dataset and Analyze","464e742c":"# Optimum number of Clusters is 4\n\n# Now lets train the K-Means Clustering Model with 6 clusters","551ebcb8":"# From the above plot we can see that the customers can be categorized into 5 groups preferably and can be marketed as listed below\n\n# 0 = Average spenders with average income (Could be targeted with more ads to encourage the ongoing engagement)\n# 1 = High spending low income customers (Could be targeted with more ads)\n# 2 = High Income High Spending customers (Could be targeted with more exclusive and VIP offers)\n# 3 = Low Income Low Spending (Could be targeted with more promotional offers and higher discounts)\n# 4 = High Income Low Spending (Could be targeted with VIP introductory credit card offers)\n","9bcd116c":"Choose the number of Clusters based on elbow method","2d512c21":"# There are more females than males in the Customers list","23ac6f17":"# Most of the people have an income in the range of 40k-80k","76f4b6ea":"# Looks like the spending score for most people is around 40 to 60 with less people who over spend and underspend","e2d4fa32":"# Females have slightly less median income compared to males and also there are more females with little lower salaries in comparision to males","c26320f6":"# The Silhoutte score is lowest for this clustering model\n\n# Based on the above three scenarios and considering the silhoutte score, we can market the customers based on the first clustering model (Score vs Income)","03000980":"# Interstingly the spending score of males vs females is in sharp contrast to the pay scale. Females spend more than males even though the income is little lesser in comparision"}}