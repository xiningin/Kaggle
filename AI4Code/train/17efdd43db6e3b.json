{"cell_type":{"d63a770a":"code","ffbbe56b":"code","8f8281dc":"code","4627aac3":"code","a8c809fd":"code","f630d06a":"code","c90a1de1":"code","505a2ab8":"code","98987e74":"code","1edf2987":"code","2cd1fe5c":"code","b3ab6c6c":"code","38ad8431":"code","494731dc":"code","ab785192":"code","ad45eeb1":"code","dbe4d73a":"code","27616b53":"code","83b237b7":"markdown","4fc1a1a2":"markdown","8fcf490a":"markdown","27829fd5":"markdown","459df675":"markdown","41fd4175":"markdown","4f9b3125":"markdown","f87e0149":"markdown","9d9a9c2b":"markdown","3c378de1":"markdown","dee76ce8":"markdown","867dd8b6":"markdown","2c2cc710":"markdown","ed9e3fb7":"markdown","f84f430c":"markdown","87c4a991":"markdown","1f646619":"markdown","b5c9f97f":"markdown","4dfbed93":"markdown","44a47ff0":"markdown","e60bcb25":"markdown","7dddfbd6":"markdown","8f5802be":"markdown","eea9624f":"markdown","bf5f8a85":"markdown","0cbec30e":"markdown","6364ad0f":"markdown","9727142c":"markdown","d22cc8b1":"markdown"},"source":{"d63a770a":"!pip install textstat\n!pip install pyicu\n!pip install pycld2","ffbbe56b":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport math\nimport string\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom transformers import pipeline\nimport textstat\nfrom polyglot.detect import Detector\n\nplt.style.use('ggplot')","8f8281dc":"test_df = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')\nvalidation_df = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')\nprint(f'Validation Data is of shape: {validation_df.shape}')\nprint(f'Comments to score (test) is of shape: {test_df.shape}')","4627aac3":"test_df.head()","a8c809fd":"validation_df.head(5)","f630d06a":"print(f'Total workers involved in validation are => {len(validation_df.worker.unique())}')","c90a1de1":"print(f'Less toxic unique comments => {len(validation_df.less_toxic.unique())}')\nprint(f'More toxic unique comments => {len(validation_df.more_toxic.unique())}')\nprint(f'Toal unique comments in both columns => {len(validation_df.more_toxic.append(validation_df.less_toxic).unique())}')","505a2ab8":"def detect_language(text):\n    return Detector(\"\".join(x for x in text if x.isprintable()), quiet=True).languages[0].name\n\nall_comments = validation_df.less_toxic.append(validation_df.more_toxic).value_counts().index.values\nlanguages = [detect_language(comment) for comment in all_comments]\nlanguage_df = pd.DataFrame({\n    'text': all_comments,\n    'language': languages\n})\n\nlanguage_df['language'].value_counts().to_frame().head(15)","98987e74":"less_toxic_wc = validation_df.less_toxic.apply(lambda comment: textstat.lexicon_count(str(comment)))\nmore_toxic_wc = validation_df.more_toxic.apply(lambda comment: textstat.lexicon_count(str(comment)))\n\nless_toxic_sc = validation_df.less_toxic.apply(lambda comment: textstat.sentence_count(str(comment)))\nmore_toxic_sc = validation_df.more_toxic.apply(lambda comment: textstat.sentence_count(str(comment)))\n\nfig = plt.figure(figsize=(12,6))\n\nax1 = fig.add_subplot(121)\nbins = np.linspace(0, 500, 50)\nax1.hist(less_toxic_wc, bins, alpha=0.9, label='less toxic wc', color = \"skyblue\")\nax1.hist(more_toxic_wc, bins, alpha=0.5, label='more toxic wc', color = \"red\")\nax1.set_title('Word count distribution')\n\nax2 = fig.add_subplot(122)\nbins = np.linspace(0, 60, 40)\nax2.hist(less_toxic_sc, bins, alpha=0.9, label='less toxic wc', color = \"skyblue\")\nax2.hist(more_toxic_sc, bins, alpha=0.5, label='more toxic wc', color = \"red\")\nax2.set_title('Sentence count distribution')\n\nplt.show()","1edf2987":"wc_diff = validation_df.apply(lambda row: len(row.less_toxic.split()) - len(row.more_toxic.split()), axis=1)\n\nplt.figure(figsize=(8, 6))\nbins = np.linspace(-200, 200, 30)\nplt.hist(wc_diff, bins, alpha=0.5, label='wc difference', color = \"green\", ec=\"black\")\nplt.legend(loc='upper right')\nplt.title('Word count difference [less toxic -  more toxic]')\nplt.show()","2cd1fe5c":"worker_freq_df = validation_df.worker.value_counts()\n\nplt.figure(figsize=(8, 6))\nbins = math.ceil((worker_freq_df.max() - worker_freq_df.min())\/10)\nplt.hist(worker_freq_df, bins, alpha=0.3, label='wc difference', color = \"blue\", ec=\"black\")\nplt.legend(loc='upper right')\nplt.title('Worker WORK load')\nplt.show()","b3ab6c6c":"pair_occ_df = validation_df[['less_toxic','more_toxic']].apply(lambda row: ' ~ '.join(np.sort(list(row))), axis=1).value_counts().value_counts()\n\nplt.figure(figsize=(8, 6))\nplt.bar(pair_occ_df.index, pair_occ_df.values, alpha=0.5, label='', color = \"blue\", ec=\"black\")\nplt.xticks(pair_occ_df.index)\n# plt.legend(loc='upper left')\nplt.title('Occurance count of comment pairs')\nplt.show()","38ad8431":"validation_df['comment_pair_ordered'] = validation_df['less_toxic'] + ' : ' + validation_df['more_toxic']\nval_order_dict = validation_df['comment_pair_ordered'].value_counts().to_dict()\nvalidation_df['n_agreements'] = validation_df['comment_pair_ordered'].map(val_order_dict)\n\nvalidation_df['agreement'] = validation_df['n_agreements'].map({1: 'Reviewer Disagreed',\n                                                                2: 'Agreed with One Reviwer',\n                                                                3: 'All Three Reviewers Agreed'})\n\nax = validation_df['agreement'].value_counts().plot(kind='bar',  alpha=0.7, figsize=(12, 5))\n\nax.tick_params(axis='x', rotation=0)\nax.set_title('Worker Agreement', fontsize=16)\nplt.show()","494731dc":"# all punctutaion count\npunctuation_count = lambda l1,l2: sum([1 for x in l1 if x in l2])\nvalidation_df['less_toxic_punctuation_count'] = validation_df.less_toxic.apply(lambda comment: punctuation_count(comment,set(string.punctuation)))\nvalidation_df['more_toxic_punctuation_count'] = validation_df.more_toxic.apply(lambda comment: punctuation_count(comment,set(string.punctuation)))\n\n# exclamation mark count\nexclmataion_count = lambda l1: sum([1 for x in l1 if x =='!'])\nvalidation_df['less_toxic_exclmataion_count'] = validation_df.less_toxic.apply(lambda comment: exclmataion_count(comment))\nvalidation_df['more_toxic_exclmataion_count'] = validation_df.more_toxic.apply(lambda comment: exclmataion_count(comment))\n\npunctuation_value_counts = validation_df.apply(lambda row: 1 if row.more_toxic_punctuation_count > row.less_toxic_punctuation_count else 0, axis=1).value_counts()\nexclamation_value_counts = validation_df.apply(lambda row: 1 if row.more_toxic_exclmataion_count >= row.less_toxic_exclmataion_count else 0, axis=1).value_counts()\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(121)\nax1.pie(punctuation_value_counts, labels = ['Less toxic', 'More toxic'], colors = ['skyblue', '#ff6666'])\nax1.set_title('Puncutaion count')\n\nax2 = fig.add_subplot(122)\nax2.pie(exclamation_value_counts, labels = ['Less toxic', 'More toxic'], colors = ['skyblue', '#ff6666'])\nax2.set_title('Exclamation count')\n\nplt.show()","ab785192":"less_toxic_reading_score = validation_df.less_toxic.apply(lambda comment: textstat.flesch_reading_ease(comment)).mean()\nmore_toxic_reading_score = validation_df.more_toxic.apply(lambda comment: textstat.flesch_reading_ease(comment)).mean()\n\nplt.figure(figsize=(8, 6))\nplt.bar(['Less toxic', 'More toxic'], [less_toxic_reading_score, more_toxic_reading_score], alpha=0.5, width=0.6)\nplt.ylabel('Readability score')\nplt.title('Flesch Readability score')\nplt.show()","ad45eeb1":"validation_df.less_toxic.value_counts().to_frame().head(5)","dbe4d73a":"validation_df.more_toxic.value_counts().to_frame().head(5)","27616b53":"less_toxic_comments = validation_df['less_toxic'].value_counts().to_frame().head(1000)\nless_toxic_text = ' '.join(less_toxic_comments.index.tolist())\n\nmore_toxic_comments = validation_df['more_toxic'].value_counts().to_frame().head(1000)\nmore_toxic_text = ' '.join(more_toxic_comments.index.tolist())\n\n\nless_toxic_wordcloud = WordCloud(max_font_size=50, max_words=100,\n                      width=500, height=500,background_color=\"white\").generate(less_toxic_text)\n\n\nmore_toxic_wordcloud = WordCloud(max_font_size=50, max_words=100,\n                       width=500, height=500, background_color=\"black\").generate(more_toxic_text)\n\n\nfig, (ax1,ax2) = plt.subplots(1, 2, figsize=(15,15))\nax1.imshow(less_toxic_wordcloud, interpolation=\"bilinear\")\nax1.axis(\"off\")\nax2.imshow(more_toxic_wordcloud, interpolation=\"bilinear\")\nax2.axis(\"off\")\nax1.set_title('Less Toxic Comments', fontsize=15)\nax2.set_title('More Toxic Comments', fontsize=15)\nplt.tight_layout(pad = 5)\nplt.show()","83b237b7":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> \nAgreement among workers\n<\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nNow that we know there are 10K pairs score thrice, let's checkout the number of times workers agree and the times that they disagree.\n<\/p>\n","4fc1a1a2":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> Unique comments and workers<\/span>","8fcf490a":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> \nWord Cloud\n<\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nFinally, everyone's favourite Word clouds!!!\n<\/p>\n","27829fd5":"<p id=\"eda\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 10px 10px; background-color: #f2843a; border-radius: 5px;\">\n    <b> Exploratory data analysis<\/b>\n<\/p> \n\n<p style=\"font-size: 110%;font-style: italic;\" > Now that we have everything we need in the dataframes let's try to explore the details! \n","459df675":"\n<p style=\"font-size: 110%; font-style: italic;\" > \nSo basically, each comment pair either occurs once or thrice in the dataset.\n<\/p>","41fd4175":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> Worker work load <\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nHow many pairs of comments did workers score? Let's plot the distribition\n<\/p>\n","4f9b3125":"<p id=\"load_data\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 10px 10px; background-color: #f2843a; border-radius: 5px;\">\n    <b> Load data<\/b>\n<\/p> \n\n<p style=\"font-size: 110%;font-style: italic;\" > There are three files in the input folder. Let's load the data in and look at it some sample from the data.<\/p>\n","f87e0149":"<p style=\"font-size: 110%; font-style: italic;\" > \nWell, it turns out that less toxic comments usually have more punctuation count. The same is indicated by exclamation count as well which wasn't expected as usually the ones that are more toxic use more exclamation!  \nAnyway, it is what it is.\n<\/p>\n","9d9a9c2b":"<div style=\"background-color:#dee3e3; padding: 25px 50px 25px 50px;\">\n<h1 style=\"font-family: Arial, Helvetica, sans-serif;text-shadow: grey 0px 0px 3px; font-weight: bold; font-size: 230%;\"><center>Jiggsaw Toxic Severity Rating<\/center><\/h1>\n\n<p style=\"font-size: 110%;font-style: italic;\" >This notebook attempts to perform EDA on the Jiggsaw Toxic Severity Rating dataset. The focus in this competition is on ranking the severity of comment toxicity from innocuous to outrageous. <\/p>\n<\/div>","3c378de1":"<p style=\"font-size: 110%; font-style: italic;\" > \nTotal unique comments are around 14K which were looked at by 753 workers!\n<\/p>\n","dee76ce8":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> Words and Sentences <\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nDo word and sentence count in a comment indcate something? Let's plot the distributions to find out.\n<\/p>\n","867dd8b6":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 10px 10px; background-color: #f2843a; border-radius: 5px;\">\n    <b> Libraries<\/b>\n<\/p> \n\n<p style=\"font-size: 110%;font-style: italic;\" >Install dependencies and import libraries<\/p>\n<\/div>","2c2cc710":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> \nLanguage readability\n<\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nThe premise behind checking readability is that less toxic words are easier to read that more toxic ones. <br\/>\nWe will user Textstat to achieve this. Textstat is an easy to use library to calculate statistics from text. It helps determine readability, complexity, and grade level. It offeres various but the one that will be checked in this notebook is called the Flesch Reading Ease Score which is the score of readability which indicates how difficult a passage in English is to understand. \n<\/p>\n","ed9e3fb7":"<p style=\"font-size: 110%; font-style: italic;\" > \nOk, then let's compare the word count between in each pair and see distributions to find if there's a clue\n<\/p>","f84f430c":"<p style=\"font-size: 110%; font-style: italic;\" > \nSo, more toxic comments tend to be short whereas less toxic comments are usually longer. That being said, there's also quite a lot of overlapp! <br>\nFurther, most comments have 1 or 2 sentences and there's very little to differentiate both classes here as well.\n<\/p>\n\n","87c4a991":"<p style=\"font-size: 110%; font-style: italic;\" > \nVoil\u00e0! You made it till the end!!  <br \/><br \/>\nThanks a lot for sticking along and taking your time to read this. Do let know if something needs to be corrected and also feel free to drop a comment. <br \/>\nHave a good one! Stay safe\n<\/p>","1f646619":"<p style=\"font-size: 110%; font-style: italic;\" > \nAlthough the distribution is slight right skewed which means less toxic were longer than more toxic comments there isn't much separating them.\n<\/p>","b5c9f97f":"\n<p style=\"font-size: 110%; font-style: italic;\" > \nAs expected, the less toxic comments have a better readability score than the more toxic ones. It would also be a good idea to try out other features from textstat library but we not going to do that in this notebook.\n<\/p>","4dfbed93":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> Languges in validation comments<\/span>","44a47ff0":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> \nPunctuation marks\n<\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nOften there are several punctuation marks in a toxic comment. Looking at the correlation should give us some idea.\n<\/p>\n","e60bcb25":"<p style=\"font-size: 110%;font-style: italic;\" > \nThe validation data has the worker id who classified a pair of comments into less or more toxic. There are more than 30K rows in the dataset.\n<\/p>\n\n\n","7dddfbd6":"> - [jiggsaw-toxic-comments-eda-twitch-stream](https:\/\/www.kaggle.com\/robikscube\/jiggsaw-toxic-comments-eda-twitch-stream\/notebook)\n>---","8f5802be":"<p style=\"font-size: 110%; font-style: italic;\" > \nComments marked MORE TOXIC the most number of times are as below\n<\/p>","eea9624f":"<p style=\"font-size: 110%; font-style: italic;\" > \nSo, 99.16% of the comments are in English with other languages having very low occurance in comparision.\n<\/p>\n","bf5f8a85":"<p style=\"font-size: 110%;font-style: italic;\" > \n    The test file has comment_id and and text associated to each comment. Next, let's look at the validation data.\n<\/p>\n\n","0cbec30e":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> \nMost repeated less toxic comment\n<\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nComments marked LESS TOXIC the most number of times are as below\n<\/p>\n","6364ad0f":"<p id=\"ref\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 10px 10px; background-color: #f2843a; border-radius: 5px;\">\n    <b>Refrences<\/b>\n<\/p> \n\n<p style=\"font-size: 110%;\" >Thank you! <\/p>\n","9727142c":"<p style=\"font-size: 110%; font-style: italic;\" > \nSo, the distribution tells us that most workers scored some 1-20 comment pairs but there were also some workers who did upwards of 200 pairs! Hope they detoxed themselves.\n\n<\/p>","d22cc8b1":"* <span style=\"color:#f2843a;font-size: 150%; font-weight: bold;\"> \nComment pair frequency\n<\/span>\n<p style=\"font-size: 110%; font-style: italic;\" > \nWe saw earlier that there were around 14K unique comment pairs but the dataset has around 30K comment pairs. There must be a lot of repetation of pairs and to check this we plot the frequency distribution.\n<\/p>\n"}}