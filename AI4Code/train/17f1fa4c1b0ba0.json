{"cell_type":{"4e413596":"code","4c8103ac":"code","40c873c6":"code","b9726356":"code","429bb0c5":"code","89f89c45":"code","1a7c3aaf":"code","11460604":"code","894d2260":"code","53a1d07e":"code","03156c0d":"code","1152c0c8":"code","ffbbced4":"code","16eb65a5":"code","a1e53131":"code","7e9fe342":"code","0c5bb534":"code","2edfe2b0":"code","c616a2ab":"code","16ce42ae":"code","d4bdc45a":"markdown","1db78d80":"markdown","e809b81e":"markdown","f77c5992":"markdown","650d8a71":"markdown","72ed8994":"markdown","3524b071":"markdown","469fa64a":"markdown","11297bb5":"markdown","f559d823":"markdown","12b52652":"markdown"},"source":{"4e413596":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c8103ac":"import re\nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer","40c873c6":"nltk.download(['stopwords','punkt','wordnet'])","b9726356":"df=pd.read_csv('..\/input\/predict-stock-price-based-on-news-headline\/Data.csv', encoding = \"ISO-8859-1\")\ndf.head()","429bb0c5":"df.shape","89f89c45":"df['Headlines']=(df.iloc[:,2:]+' ').astype(str).values.sum(axis=1)\ndf=df[['Date','Label','Headlines']]\ndf.head()","1a7c3aaf":"df['Date'].min(),df['Date'].max()","11460604":"train=df[df['Date']<'2015-01-01']\ntest=df[df['Date']>='2015-01-01']\ntrain.shape,test.shape","894d2260":"stemmer=PorterStemmer()\nlemmatizer=WordNetLemmatizer()\nstopwords_en=set(stopwords.words('english'))","53a1d07e":"# Function of text preprocessing or clean-up\ndef preprocess(msg):\n  msg=msg.lower()\n  msg=re.sub('[^a-zA-Z]',' ',msg)\n  msg=[w for w in msg.split() if w not in stopwords_en]\n  return ' '.join(msg)","03156c0d":"# Function: preprocessing with stemming\ndef stemmatize(msg):\n  msg=msg.lower()\n  msg=re.sub('[^a-zA-Z]',' ',msg)\n  msg=[stemmer.stem(w) for w in msg.split() if w not in stopwords_en]\n  return ' '.join(msg)","1152c0c8":"# Function: preprocessing with lemmatization\ndef lemmatize(msg):\n  msg=msg.lower()\n  msg=re.sub('[^a-zA-Z]',' ',msg)\n  msg=[lemmatizer.lemmatize(w) for w in msg.split() if w not in stopwords_en]\n  return ' '.join(msg)","ffbbced4":" # Stemmatize, lemmatize or just pre-process\n train['Wordlist']=train['Headlines'].apply(preprocess)\n train.head()","16eb65a5":"X_train=train['Wordlist']\ny_train=train['Label']","a1e53131":"# Bag of words\nbow=CountVectorizer(ngram_range=(2,2))\nX_train=bow.fit_transform(X_train)","7e9fe342":"rf_clf=RandomForestClassifier(n_estimators=200,criterion='entropy')\nrf_clf.fit(X_train,y_train)","0c5bb534":"# Pre-processing test data\ntest['Wordlist']=test['Headlines'].apply(preprocess)\nX_test =test['Wordlist']\nX_test=bow.transform(X_test)\ny_test=test['Label']","2edfe2b0":"# Predictions\ny_pred=rf_clf.predict(X_test)","c616a2ab":"accuracy_score(y_test,y_pred)","16ce42ae":"print(confusion_matrix(y_test,y_pred))","d4bdc45a":"Importing required libraries","1db78d80":"Download NLTK packages\n- stopwords: for stopwords\n- punkt: for stemmatization\n- wordnet: for lemmatization","e809b81e":"# Training the model (sklean)\n- Random Forest Classifier","f77c5992":"Read data","650d8a71":"50% accuracy has no utility. Too many false positives.","72ed8994":"# NLP using NLTK\n\n### Text preprocessing\n- text preprocessing or clean-up\n- stemmatization\n- lemmatization","3524b071":"### Train test split","469fa64a":"Get date range and split data based on dates.","11297bb5":"# Data pre-processing\n1. Join headlines colums Top1 through Top 25 into a single column called 'Headlines'\n2. Keep only required columns (Date, Label, Headlines)","f559d823":"# Testing the model","12b52652":"### Vectorization\n- Bag of words\n- TF-IDF"}}