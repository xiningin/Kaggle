{"cell_type":{"a0185917":"code","ec24a434":"code","9d6f787e":"code","396370b3":"code","82d0e484":"code","d5bb601f":"code","54cd9559":"code","f92dbeb2":"code","cdfcf4ed":"code","4e9759f5":"code","c404db40":"code","afcb249d":"code","aa5f2eca":"code","7de9bb8f":"code","157d85f3":"code","98810606":"code","7cba1cd0":"code","68d7915b":"code","085c1e55":"code","684e2f43":"code","1e73ba37":"code","9fcae4f0":"code","249886eb":"code","edb77205":"code","2dc5e511":"code","5577f5f4":"code","78a3b349":"code","860347f8":"code","63b2278d":"code","7377a7c5":"code","a0018281":"code","5d7cd424":"code","085c2d56":"code","9b43183a":"code","51e90dec":"code","4bafc21c":"code","e458ce2e":"code","5c82412b":"code","f2504a61":"code","e7682ec2":"code","68a21c9b":"code","4600ddec":"code","6936aa60":"code","497d33c5":"code","046fb1b9":"code","729881d5":"code","414b643d":"code","6ed5e032":"code","ada60651":"code","7beba4ba":"code","7785fcdf":"code","d7cf225e":"code","4d2d1f9d":"code","b9de66ca":"code","fb11fdbf":"code","77ee63b9":"markdown","89990e60":"markdown","f50247fd":"markdown","9adfef2a":"markdown","3637200f":"markdown","0eea486c":"markdown","95ec920b":"markdown","bc11e2cc":"markdown","0d61a033":"markdown","1f0792d8":"markdown","2112676c":"markdown","ce6f4b38":"markdown","92030782":"markdown","34c4cc30":"markdown","b6d9d571":"markdown","f2b153b1":"markdown","61dada83":"markdown","ca5d86f4":"markdown","1e91368d":"markdown","d437ca39":"markdown","9788ff34":"markdown","2cdb7fe1":"markdown","0c61b1e1":"markdown","d5929e8a":"markdown","4e692512":"markdown","cec57f5d":"markdown","1c533d1c":"markdown","3ec605c2":"markdown","b501ed1e":"markdown","4bfd85b5":"markdown","ae2256bc":"markdown","3fe383df":"markdown","f94f61f7":"markdown","769bf3f3":"markdown","cf2d897f":"markdown","c0e57918":"markdown","64157b65":"markdown","2c0d3c4a":"markdown"},"source":{"a0185917":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","ec24a434":"dataset = pd.read_csv(r\"..\/input\/car-sales\/Car_sales.csv\")\ndataset","9d6f787e":"### Describe the dataset\ndataset.describe()","396370b3":"### Checking if there are null values in the dataset\ndataset.info()","82d0e484":"### Plotting a histogram for the variable - 'Sales_in_thousands'\n\nplt.hist(list(dataset['Sales_in_thousands']), bins = 20)\nplt.xlabel(\"Sales in thousands\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Understanding the distribution of the variable - Sales_in_thousands\")\nplt.show()","d5bb601f":"### Plotting a bar graph for the top 10 manufacturers with most models manufactured\n\nmanufacturer_count = dict()\nfor each_manufacturer in list(dataset['Manufacturer']):\n    if each_manufacturer not in manufacturer_count:\n        manufacturer_count[each_manufacturer] = 1\n    else:\n        manufacturer_count[each_manufacturer] += 1\n\nsorted_manufacturers = dict(sorted(manufacturer_count.items(), key = lambda item : item[1], reverse = True))\n\ntop_10_manufacturers = []\ntop_10_counts = []\nfor each_manufacturer in sorted_manufacturers:\n    top_10_manufacturers.append(each_manufacturer)\n    top_10_counts.append(sorted_manufacturers[each_manufacturer])\n    if len(top_10_counts) == 10:\n        break\n\nfig = plt.figure(figsize = (10, 7))\nplt.bar(top_10_manufacturers, top_10_counts, color = 'red', width = 0.4)\nplt.xlabel(\"Top 10 Manufacturers\")\nplt.ylabel(\"Models manufactured\")\nplt.title(\"Top 10 manufacturers with most models manufactured\")\nplt.show()","54cd9559":"### Plotting a bar graph between various types of vehicles used in the dataset\n\nvehicle_type_dict = dict()\nfor each_vehicle in dataset['Vehicle_type']:\n    if each_vehicle not in vehicle_type_dict:\n        vehicle_type_dict[each_vehicle] = 1\n    else:\n        vehicle_type_dict[each_vehicle] += 1\n\nvehicle_type = list(vehicle_type_dict.keys())\nvehicle_count = list(vehicle_type_dict.values())\n\nplt.bar(vehicle_type, vehicle_count, color = 'red', width = 0.5)\nplt.xlabel(\"Various Vehicle Types\")\nplt.ylabel(\"Count of each vehicle type\")\nplt.title(\"Bar graph showing the count of various vehicle types used in the dataset\")\nplt.show()","f92dbeb2":"### Plotting a histogram to understand the distribution of the variable - 'Price_in_thousands'\n\nplt.hist(list(dataset['Price_in_thousands']), bins = 20)\nplt.xlabel(\"Price in thousands\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram showing the distribution of the variable - 'Price_in_thousands'\")\nplt.show()","cdfcf4ed":"### Plotting a scatter plot between 'Engine_size' and 'Horsepower' for the top 5 manufacturers with most models manufactured\n\ntop_5_manufacturers = [manufacturer for manufacturer in top_10_manufacturers[: 5]]\ncolors = ['green', 'blue', 'red', 'yellow', 'pink']\n\nfor index in range(5):\n    plt.scatter(list(dataset[dataset['Manufacturer'] == top_5_manufacturers[index]]['Engine_size']), \n               list(dataset[dataset['Manufacturer'] == top_5_manufacturers[index]]['Horsepower']),\n               color = colors[index], label = top_5_manufacturers[index])\n\nplt.xlabel(\"Engine Size\")\nplt.ylabel(\"Horsepower\")\nplt.title(\"Scatterplot between Engine size and Horsepower for the top 5 manufacturers with most models manufactured\")\nplt.legend()\nplt.show()","4e9759f5":"### Plotting a scatter plot between 'Fuel_capacity' and 'Fuel_efficiency' for the top 5 manufacturers with the most models manufactured\n\nfor index in range(5):\n    plt.scatter(list(dataset[dataset['Manufacturer'] == top_5_manufacturers[index]]['Fuel_capacity']), \n               list(dataset[dataset['Manufacturer'] == top_5_manufacturers[index]]['Fuel_efficiency']),\n               color = colors[index], label = top_5_manufacturers[index])\n\nplt.xlabel(\"Fuel capacity\")\nplt.ylabel(\"Fuel efficiency\")\nplt.title(\"Scatterplot between Fuel capacity and Fuel efficiency for the top 5 manufacturers with most models manufactured\")\nplt.legend()\nplt.show()","c404db40":"### Plotting a bar graph showing the number of vehicles launched every year\n\nyear = [str(each_date) for each_date in dataset['Latest_Launch']]\nnew_year = [each_year[-1:-5:-1][::-1] for each_year in year]\n\nyear_count_dict = dict()\nfor each_year in new_year:\n    if each_year not in year_count_dict:\n        year_count_dict[each_year] = 1\n    else:\n        year_count_dict[each_year] += 1\n\nyears = list(year_count_dict.keys())\nyear_count = list(year_count_dict.values())\n\nplt.bar(years, year_count, color = 'green', width = 0.4)\nplt.xlabel(\"Years\")\nplt.ylabel(\"Number of launches in the year\")\nplt.title(\"Bar graph showing the number of launches per year\")\nplt.show()","afcb249d":"### Plotting a histogram for the variable - 'Power_perf_factor'\n\nplt.xlabel(\"Distribution of Power performance factor\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram to show the distribution of the variable - Power_perf_factor\")\nplt.hist(list(dataset['Power_perf_factor']), bins = 20)\nplt.show()","aa5f2eca":"### Plotting the histogram for the average sales values\n\naverage_sales_dict = dict()\nmanufacturers = set(dataset['Manufacturer'])\nfor each_manufacturer in manufacturers:\n    manufacturer_sales_data = list(dataset[dataset['Manufacturer'] == each_manufacturer]['Sales_in_thousands'])\n    average_sales_dict[each_manufacturer] = np.mean(manufacturer_sales_data)\n\nsorted_manufacturers = dict(sorted(average_sales_dict.items(), key = lambda item : item[1], reverse = True))\nprint(sorted_manufacturers)\n\nplt.hist(list(sorted_manufacturers.values()), bins = 20)\nplt.xlabel(\"Average sales\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram for the average sales values\")\nplt.show()","7de9bb8f":"### Plotting a bar graph to find out the top 5 manufacturers with the highest average sales\n\ntop_5_manufacturers = list(sorted_manufacturers.keys())[:5]\ntop_5_manufacturers_sales = list(sorted_manufacturers.values())[:5]\n\nplt.bar(top_5_manufacturers, top_5_manufacturers_sales, color = 'red', width = 0.4)\nplt.xlabel(\"Manufacturers\")\nplt.ylabel(\"Average sales of each manufacturer\")\nplt.title(\"Top 5 manufacturers with highest average sales\")\nplt.show()","157d85f3":"### Plotting the correlation between various columns\n\nplt.figure(figsize=(10, 10))\nheatmap = sns.heatmap(dataset.corr(), vmin=-1, vmax=1, annot=True)\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)","98810606":"### Data preprocessing packages\n\nimport statsmodels.api as sm\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","7cba1cd0":"### Dropping the columns - Model, Latest_Launch\n\nmodified_dataset = dataset.drop(['Model', 'Latest_Launch'], axis = 1)\nmodified_dataset","68d7915b":"### Dropping all the rows which have na in the column - Price_in_thousands\n\n#modified_dataset = dataset.dropna(axis = 0)\nnew_dataset = modified_dataset[modified_dataset['Price_in_thousands'].notna()]\nnew_dataset","085c1e55":"### Replacing the na's in the columns - __year_resale_value, Fuel_efficiency, Power_perf_factor with median\n\nnew_dataset['__year_resale_value'].fillna(value = new_dataset['__year_resale_value'].median(), inplace = True)\nnew_dataset['Fuel_efficiency'].fillna(value = new_dataset['Fuel_efficiency'].median(), inplace = True)\nnew_dataset['Power_perf_factor'].fillna(value = new_dataset['Power_perf_factor'].median(), inplace = True)\nnew_dataset","684e2f43":"### Checking if the dataset has NA\n\nnew_dataset.info()","1e73ba37":"### Replacing the na's in the columns - Curb_weight with mean\n\nnew_dataset['Curb_weight'].fillna(value = new_dataset['Curb_weight'].mean(), inplace = True)\nnew_dataset","9fcae4f0":"### Checking if the dataset has NA\n\nnew_dataset.info()","249886eb":"### Observing the multi collinearity - Variance Inflation Factor\n\n'''On observing the correlation matrix, it was evident that almost all the variables are pairwise correlated. \nHence, we use the Variance Inflation Factor (VIF) to identify those columns which cause the problem of multicollinearity\nin the dataset.'''\n\nsample_dataset = new_dataset.drop(['Sales_in_thousands','Manufacturer', 'Vehicle_type'], axis = 1) ### Removing categorical data for calculating VIF\ncolumn_names = list(sample_dataset.columns)\n\nfor name in column_names:\n    if len(column_names) >= 2:\n        Y = sample_dataset.loc[:, sample_dataset.columns == name]\n        X = sample_dataset.loc[:, sample_dataset.columns != name]\n        linear_model = sm.OLS(Y, X)\n        results = linear_model.fit()\n        r_squared = results.rsquared\n        vif_value = round(1\/(1 - r_squared), 2)\n        print(\"Column: {} and VIF: {}\".format(name, vif_value))\n        if vif_value > 10:\n            sample_dataset = sample_dataset.drop([name], axis = 1)\n            column_names.remove(name)\n    ","edb77205":"### Drop the columns - _year_resale_value, Engine_size, Wheelbase, Length, Fuel_capacity, Power_perf_factor\n\nfinal_dataset = new_dataset.drop(['__year_resale_value', 'Engine_size', 'Wheelbase', 'Length', \n                                     'Fuel_capacity', 'Power_perf_factor'], axis = 1)\nfinal_dataset","2dc5e511":"### Encoding the categorical variable - Manufacturer\n\n'''Encoding the variable - Manufacturer such that if the average sales of a manufacturer are greater than 75, they belong \nto class 2, else class 1'''\n\nmanufacturers = []\nfor each_manufacturer in final_dataset['Manufacturer']:\n    if sorted_manufacturers[each_manufacturer] > 75:\n        manufacturers.append(2)\n    else:\n        manufacturers.append(1)\nfinal_dataset['Manufacturer'] = manufacturers\nfinal_dataset","5577f5f4":"### Dividing the dataset into dependent and independent variables\n\nX = final_dataset.iloc[:, [0, 1, 2, 4, 5, 6, 7]].values\nY = final_dataset.iloc[:, 3:4].values","78a3b349":"print(X[0])","860347f8":"print(Y)","63b2278d":"### Encoding the caategorical variable - Vehicle_type using OneHotEncoding\n\ncolumnTransformer = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [2])], \n                                     remainder ='passthrough')\nX = np.array(columnTransformer.fit_transform(X))\nprint(X[0])","7377a7c5":"### Splitting the data into Training and Test sets\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)","a0018281":"### Feature Scaling the data using StandardScaler\n\nstandardScaler = StandardScaler()\nX_train[:, 3:] = standardScaler.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = standardScaler.transform(X_test[:, 3:])","5d7cd424":"print(X_train[0])","085c2d56":"print(X_test[0])","9b43183a":"#### Importing required libraries\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV","51e90dec":"### Training the linear regression model on the Training set\n\nlinear_regressor = LinearRegression()\nlinear_regressor.fit(X_train, Y_train)","4bafc21c":"### Predicting the Test set results\n\nY_pred = linear_regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), axis = 1))","e458ce2e":"### Calculating the R-squared value of the model\n\nr2_linear_regression = r2_score(Y_test, Y_pred)\nr2_linear_regression","5c82412b":"### Training the Support Vector Regression on the dataset\n\nsupport_vector_regressor = SVR(kernel = 'rbf')\nsupport_vector_regressor.fit(X_train, Y_train)","f2504a61":"### Predicting the Test set results\n\nY_pred = support_vector_regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), axis = 1))","e7682ec2":"### Calculating the R-squared value of the model\n\nr2_support_vector_regression = r2_score(Y_test, Y_pred)\nr2_support_vector_regression","68a21c9b":"### Training the Decision Tree Regression on the dataset\n\ndecision_tree_regressor = DecisionTreeRegressor(random_state = 0)\ndecision_tree_regressor.fit(X_train, Y_train)","4600ddec":"### Predicting the Test set results\n\nY_pred = decision_tree_regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), axis = 1))","6936aa60":"### Calculating the R-squared value of the model\n\nr2_decision_tree_regression = r2_score(Y_test, Y_pred)\nr2_decision_tree_regression","497d33c5":"### Training the Random Forest Regression on the Training set\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\nrandom_forest_regressor.fit(X_train, Y_train)","046fb1b9":"### Predicting the Test set results\n\nY_pred = random_forest_regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), axis = 1))","729881d5":"### Calculating the R-squared value of the model\n\nr2_random_forest_regression = r2_score(Y_test, Y_pred)\nr2_random_forest_regression","414b643d":"### Training the Ridge Regression on the Training set\n\nridge = Ridge()\nparameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\nridge_regressor = GridSearchCV(ridge, parameters, scoring = 'neg_mean_squared_error', cv = 5)\nridge_regressor.fit(X_train, Y_train)","6ed5e032":"# Finding out best alpha for Ridge Regression\n\nprint(ridge_regressor.best_params_)","ada60651":"### Predicting the Test set results\n\nY_pred = ridge_regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), axis = 1))","7beba4ba":"### Calculating the R-squared value of the model\n\nr2_ridge_regression = r2_score(Y_test, Y_pred)\nr2_ridge_regression","7785fcdf":"### Training the Lasso Regression on the dataset\n\nlasso = Lasso()\nparameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\nlasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv = 5)\nlasso_regressor.fit(X_train, Y_train)","d7cf225e":"# Finding out best alpha for Lasso Regression\n\nprint(lasso_regressor.best_params_)","4d2d1f9d":"### Predicting the Test set results\n\nY_pred = lasso_regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), axis = 1))","b9de66ca":"### Calculating the R-squared value of the model\n\nr2_lasso_regression = r2_score(Y_test, Y_pred)\nr2_lasso_regression","fb11fdbf":"### Tabulating the performance of various regression models\n\nfrom tabulate import tabulate\n\ntable = []\ntable.append(['S.No.', 'Regression Model', 'R-squared value'])\ntable.append(['1', 'Linear Regression', r2_linear_regression])\ntable.append(['2', 'Support Vector Regression', r2_support_vector_regression])\ntable.append(['3', 'Decision Tree Regression', r2_decision_tree_regression])\ntable.append(['4', 'Random Forest Regression', r2_random_forest_regression])\ntable.append(['5', 'Ridge Regression (alpha = 5)', r2_ridge_regression])\ntable.append(['6', 'Lasso Regression (alpha = 0.01)', r2_lasso_regression])\n\nprint(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))","77ee63b9":"#### Model Building","89990e60":"#### Applying Random Forest Regression on the dataset","f50247fd":"#### Applying Linear Regression on the dataset ","9adfef2a":"On observing the above graph, we can say that the count of passenger vehicle type is almost three times than car vehicle type.","3637200f":"#### 1. How is the variable 'Sales_in_thousands' distributed?","0eea486c":"On observing the above correlation matrix, we can say that the pair of the variables (_year_resale_value, Price_in_thousands), (horsepower, Price_in_thousands), (horsepower, engine_size), (length, wheel_base), (curb_weight, engine_size), (fuel_capacity, curb_weight), (power_perf_factor, _year_resale_value), (power_perf_factor, price_in_thousands), (power_perf_factor, engine_size), (power_perf_factor, horsepower) have a strong positive association that means if the value of one variable increases, then the value of the other variable also increases. Similarly, the pair of variables (fuel_efficiency, engine_size), (fuel_efficiency, curb_weight), (fuel_efficiency, fuel_capacity) have a strong negative association that means as the value of one variable increases the value of other variable decreases.","95ec920b":"Here, we are removing the 2 records which have NA in them.","bc11e2cc":"On observing the above graph, we can say that the manufacturers 'Dodge' and 'Ford' manufactured most models than any other manufacturer.","0d61a033":"#### Applying Decision Tree Regression on the dataset","1f0792d8":"#### 2. Top 10 'Manufacturers' with most 'Models' manufactured?","2112676c":"#### 7. How many vehicles are launched every year?","ce6f4b38":"#### 9. Top 5 manufacturers with the highest average sales.","92030782":"#### Applying Support Vector Regression on the dataset","34c4cc30":"On observing the above graph, we can say that the graph is normally distributed with slightly right skewed.","b6d9d571":"On observing the above data, we can say that the columns _year_resale_value, Engine_size, Wheelbase, Length, Fuel_capacity, Power_perf_factor cause multi collinearity in the dataset. Hence we drop these columns from the dataset.","f2b153b1":"On observing the above graph, we can say that Mercedes-B provides vehicles with greater horse power for small engine sizes. Dodge has the biggest engine with the maximum horse power among the top 5 manufacturers. Similarly, Chevrolet has the smallest engine with the least horse power. Also, the variables 'Engine_size' and 'Horsepower' has a positive association.","61dada83":"Here, we are going to answer the following questions:\n1. How is the variable 'Sales_in_thousands' distributed?\n2. Top 10 manufacturers with most models manufactured? \n3. What are the different types of vehicles used in this dataset?\n4. How is the variable 'Price_in_thousands' distributed?\n5. Understanding the variables 'Engine_size' and 'Horsepower' for each manufacturer.\n6. Understanding the variables 'Fuel_capacity' and 'Fuel_efficiency' for each manufacturer.\n7. How many vehicles are launched every year?\n8. How is the variable 'Power_performance_factor' distributed?\n9. Manufacturer with the highest average sales.\n10. Correlation between all the variables.","ca5d86f4":"#### Exploratory Data Analysis","1e91368d":"#### Data preprocessing","d437ca39":"#### 10. Correlation between all the variables","9788ff34":"#### Importing the libraries","2cdb7fe1":"#### Conclusion","0c61b1e1":"On observing the above table, we can say that Random Forest Regression works best on this dataset, as it has an R-squared value of 82 percent which is significantly better than other regression models.","d5929e8a":"#### Applying Ridge Regression on the dataset","4e692512":"#### 5. Understanding the variables 'Engine_size' and 'Horsepower' for the top 5 manufacturers with most models manufactured.","cec57f5d":"#### Applying Lasso Regression on the dataset","1c533d1c":"On observing the above graph, we can say that the years 2011 and 2012 have the maximum launches. We will use the same data to encode these values during the Data preprocessing.","3ec605c2":"#### 6. Understanding the varibles 'Fuel_capacity' and 'Fuel_efficiency' for the top 5 manufacturers with most models manufactured.","b501ed1e":"## Analysis on Car sales dataset","4bfd85b5":"#### 3. What are the different types of vehicles used in the dataset?","ae2256bc":"On observing the above graph, we can say that the graph is right skewed with the majority of the values lying between 10 and 25, and has outliers at the far right end of the graph.","3fe383df":"On observing the above data, we can see that there are missing values in the columns - _year_resale_value, Price_in_thousands, Engine_size, Horse_power, Wheelbase, Width, Length, Curb_weight, Fuel_capacity, Fuel_efficiency, Power_perf_factor","f94f61f7":"#### 4. How is the variable 'Price_in_thousands' distributed?","769bf3f3":"#### Importing the dataset","cf2d897f":"On observing the above graph, we can say that the variables 'Fuel capacity' and 'Fuel efficiency' has a negative association between them.","c0e57918":"#### 8. How is the variable 'Power_performance_factor' distributed?","64157b65":"On observing the above data, we can say that the distribution of the variable 'Sales_in_thousands' is right skewed with most of the values between 0 and 25 thousand, and outlier at the far end in the right.","2c0d3c4a":"On observing the above graph, we can see that the average sales for the manufacturer Ford is very high than compared to any other manufacturer."}}