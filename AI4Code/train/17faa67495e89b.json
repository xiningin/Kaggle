{"cell_type":{"74da990b":"code","4208fec5":"code","e07e8b12":"code","9096f203":"code","399f3d14":"code","40438861":"code","d203cbd5":"code","f0523cc7":"code","a709dfdf":"code","b1a8d9dd":"code","72b4680f":"code","4df8b4bc":"code","2ea57392":"code","c5df55d1":"code","3ecb6bb8":"code","6f6da07c":"code","85d688dc":"code","54085412":"code","620ed852":"markdown","3ddf4596":"markdown","98c6d383":"markdown","16a02e15":"markdown","1859b364":"markdown","ddd01d77":"markdown","d503c8c1":"markdown","b4a65358":"markdown","d295e52e":"markdown","9be6143b":"markdown"},"source":{"74da990b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom keras.models import Model, load_model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nimport os\nimport shutil\nfrom sklearn.metrics import confusion_matrix","4208fec5":"# This cell is responsible for preparing the test set\nold_folder = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\nnew_folder = '.\/asl_alphabet_test1'\n\nos.mkdir(new_folder)\n\n# The Paths of both the training set and the Test Set\ntest_dir = new_folder\ntrain_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\n\n\nfor file in os.listdir(old_folder):\n  shutil.copy(os.path.join(old_folder, file), new_folder)\n\n# Because the Test dataset contains only 28 images, this will cause problems when trying to calculate and plot the confusion matrix\n# For this I am going to copy an image of the lost class from the training set to the test set\nshutil.copy(os.path.join(train_dir, 'del\/del1.jpg'), new_folder)\nos.rename(os.path.join(new_folder, 'del1.jpg'), os.path.join(new_folder, 'del_test.jpg'))","e07e8b12":"input_shape = (128, 128, 3)                                           # Shape of the resized input Image\nsplit_ratio = 0.1                                                     # Ratio of splitting the data set into training and validation sets\nm = 87000                                                             # Number of training examples\nbatch_size = 64                                                      # Size of the Batch of data we feed the learning Algorithm\nnum_classes = 29                                                      # Number of Classes in the data\ntarget_size = (128, 128)                                              # Shape of the resized input Image\nepochs = 50                                                            # Number of Epochs for the training process\nsteps_per_epoch = int(m * (1 - split_ratio) \/ batch_size)             # Number of steps for each epoch\nvalidation_steps = int(m * split_ratio \/ batch_size)                  # Number of validation steps for each epoch\nclasses = os.listdir(train_dir)                                       # List of the classes\nclasses.sort()","9096f203":"# Now that I have prepared the test data and defined the hyperparameters, I will use the ImageDataGenerator to load the data\n# The ImageDataGenerator will be also used for Data Augmentation\ntrain_gen = ImageDataGenerator(rescale=1.\/255,\n                               samplewise_center=True, \n                               samplewise_std_normalization=True,\n                               rotation_range = 10,\n                               validation_split = split_ratio)","399f3d14":"# Loading the DataSets\n\ntrain_generator = train_gen.flow_from_directory(train_dir, target_size=target_size,\n                                                shuffle=True, seed=13,\n                                                class_mode='categorical',\n                                                batch_size=batch_size, subset=\"training\")\n\nval_generator = train_gen.flow_from_directory(train_dir, target_size=target_size,\n                                              shuffle=True, seed=13,\n                                              class_mode='categorical',\n                                              batch_size=batch_size, subset=\"validation\")","40438861":"# I will use transfer learning and I will use MobileNet architecture as the backbone.\nbase_model = MobileNetV2(include_top=False, input_shape = input_shape)\n\n# Now, I will Define my Classifier \/ Decoder\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.4)(x)\nx = Dense(29, activation='softmax')(x)\n\n# Integrate the whole Model\nmodel = Model(base_model.input, x)","d203cbd5":"# Printing the Summary of the Model\nmodel.summary()","f0523cc7":"# Plotting the Model to visualize the tensorboard graph\nplot_model(model, to_file='model.png', show_shapes=True)","a709dfdf":"# I will use the following callbacks\n\n# To save the best Model\nmodelcheckpoint = ModelCheckpoint(monitor='val_loss',\n                                  filepath='.\/best_model.hdf5',\n                                  save_best_only=True)\n\n# To avoid overfitting, Stop early when the validation loss saturates \nearlystopping = EarlyStopping(monitor='val_loss', patience=5)\n\n# To reduce the Learning rate during training. This will reduce the probability of overshooting the minimum\nreduce_LR = ReduceLROnPlateau(monitor='val_loss',\n                              factor=1e-1,\n                              patience=10,\n                              verbose=1,\n                              min_lr = 2e-6)","b1a8d9dd":"# Compiling the Model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","72b4680f":"# Fitting the Model\nhistory = model.fit_generator(train_generator, validation_data=val_generator,\n                                        callbacks=[earlystopping, reduce_LR, modelcheckpoint],\n                                        epochs=epochs, steps_per_epoch=steps_per_epoch,\n                                        validation_steps=validation_steps, verbose=2)","4df8b4bc":"# Getting the Training and Validation Accuracies\ntraining_accuracy = history.history['accuracy']\nvalidation_accuracy = history.history['val_accuracy']\n\n# Getting the Training and Validation Losses\ntraining_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n\n# Plotting the Learning Curves\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(training_accuracy, label='Training Accuracy')\nplt.plot(validation_accuracy, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.xlabel('epoch')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(training_loss, label='Training Loss')\nplt.plot(validation_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","2ea57392":"# I will test my model through three Different Methods:\n#  1- I will loop through the test set and check the predictions of each individual Image\n#  2- I will plot the Confusion Matrix\n#  3- I will calculate the test Accuracy\n# Here is the first proposed approach \nY_actual = [file_name.split('_')[0] for file_name in os.listdir(new_folder)]\nY_predicted = []\nfor i, test_image in enumerate(os.listdir(new_folder)):\n    image_location = new_folder + '\/' + test_image\n    img = tf.io.read_file(image_location)\n    img = tf.image.decode_png(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, target_size, method='nearest')\n\n    plt.figure()\n    plt.axis('Off')\n    plt.imshow(img)\n    img = np.array(img) \/ 255.\n    img = img.reshape((1, input_shape[0], input_shape[1], input_shape[2]))\n    img = train_gen.standardize(img)\n    prediction = np.array(model.predict(img))\n    actual = test_image.split('_')[0]\n    predicted = classes[prediction.argmax()]\n    Y_predicted.append(predicted)\n    print('Actual class: {} \\n Predicted class: {}'.format(actual, predicted))\n    plt.show()","c5df55d1":"# Calulating the Confusion Matrix\nconfusion_matrix1 = confusion_matrix(Y_actual, Y_predicted)\nprint(confusion_matrix1)","3ecb6bb8":"# Plotting the Confusion Matrix\n# Citation >> 'https:\/\/www.kaggle.com\/shivam2811\/asl-alphabet-classification-99-68'\ndef plot_confusion_matrix(confusion_matrix):\n    cm = confusion_matrix\n    plt.figure(figsize = (24, 20))\n    ax = plt.subplot()\n    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n    plt.colorbar()\n    plt.title(\"Confusion Matrix\")\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    ax.title.set_fontsize(20)\n    ax.xaxis.label.set_fontsize(16)\n    ax.yaxis.label.set_fontsize(16)\n    limit = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n    plt.show()","6f6da07c":"plot_confusion_matrix(confusion_matrix1)","85d688dc":"# Calculating the Test Accuracy\nCorrect_answers = 0\nfor i in range(len(Y_actual)):\n    if Y_actual[i] == Y_predicted[i]:\n        Correct_answers += 1\n\nprint('The Testing Accuracy is {}'.format(Correct_answers \/ len(Y_actual)))","54085412":"# This is the Images that I have captured using the camera of my own Laptop\nfor image in os.listdir('..\/input\/asl-detection'):\n  img = tf.io.read_file(os.path.join('..\/input\/asl-detection', image))\n  img = tf.image.decode_png(img, channels=3)\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  img = tf.image.resize(img, target_size, method='nearest')\n\n  plt.figure()\n  plt.axis('Off')\n  plt.imshow(img)\n  img = np.array(img) \/ 255.\n  img = img.reshape((1, input_shape[0], input_shape[1], input_shape[2]))\n  img = train_gen.standardize(img)\n  prediction = np.array(model.predict(img))\n  predicted = classes[prediction.argmax()]\n  print('Predicted class: {}'.format(predicted))\n  plt.show()","620ed852":"# > ***Loading and Preprocessing the Data***","3ddf4596":"# > ***First of all, I will import the Packages I will use through the Notebook***","98c6d383":"# > ***Plotting the Learning Curves***","16a02e15":"# > ***Testing the Model***","1859b364":"# > ***Now, I will define the hyperparameters***","ddd01d77":"# > ***My Test Case***","d503c8c1":"# > ***Training the Model***","b4a65358":"# > ***Defining the Model***","d295e52e":"# > ***Compiling the Model***","9be6143b":"# > ***Printing and Plotting the Confusion Matrix***"}}