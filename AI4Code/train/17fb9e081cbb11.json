{"cell_type":{"1d07f05c":"code","1552f9c5":"code","01fb83ba":"code","ed1c1725":"code","723a5967":"code","6ece06d9":"code","ed817313":"code","d96db0ad":"code","7fc05743":"code","5e715b21":"code","d02cec10":"code","7c6d4718":"code","a13e22ad":"code","884a3466":"code","11356211":"code","a1f2f63c":"code","f3b85afd":"code","87f4c527":"code","e6ecd4b7":"code","9eaf87d9":"code","a4319b8f":"code","9059677d":"code","b2717fae":"code","123971fb":"code","8df745fd":"markdown","025884e4":"markdown","0066c905":"markdown","29507d55":"markdown","d4de4d2e":"markdown","06d34cfa":"markdown","0265d502":"markdown","6262bb76":"markdown","44b1029a":"markdown","4bc855f1":"markdown","f19c3311":"markdown","495990fe":"markdown","4d3475bd":"markdown","095c019e":"markdown","5d778da6":"markdown","8649d7e6":"markdown","3a05fa16":"markdown","e196b11a":"markdown","9c9f7de5":"markdown","4e6e4e57":"markdown","600ecd97":"markdown","96db51d0":"markdown","29a9fb2e":"markdown","1dd007ea":"markdown","dc382a1f":"markdown","9be67d5d":"markdown","2bf5ca2b":"markdown","a3554fb3":"markdown"},"source":{"1d07f05c":"# importing libraries\nfrom keras.models import Sequential     # initialize NN as a sequnce of layers\nfrom keras.layers import Convolution2D  # 2D coz it is an image not a video(3D) which has time stamp as well\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense          # to add fully connected layers\n# import warnings  \n# warnings.filterwarnings('ignore')       # to ignore the warnings","1552f9c5":"cnn_classifier = Sequential()","01fb83ba":"cnn_classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))","ed1c1725":"cnn_classifier.add(MaxPooling2D(pool_size=(2, 2)))","723a5967":"# adding 2d layer for better accuracy\ncnn_classifier.add(Convolution2D(32, 3, 3, activation='relu'))\ncnn_classifier.add(MaxPooling2D(pool_size=(2, 2)))","6ece06d9":"cnn_classifier.add(Flatten())  # to create a vector of pooling image having a unique feature","ed817313":"cnn_classifier.add(Dense(units=128, activation='relu'))   # input layer\ncnn_classifier.add(Dense(units=1, activation='sigmoid'))  # output layer (1 coz we need to predict a dog or a cat)","d96db0ad":"cnn_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","7fc05743":"from keras.preprocessing.image import ImageDataGenerator","5e715b21":"# creating the function\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,                      \n    shear_range=0.2,                       \n    zoom_range=0.2,                         \n    horizontal_flip=True)                   ","d02cec10":"test_datagen = ImageDataGenerator(rescale=1. \/ 255)     ","7c6d4718":"training_set = train_datagen.flow_from_directory('..\/input\/dog-cat2\/training_set',\n                                              target_size=(64, 64), batch_size=32, class_mode='binary')","a13e22ad":"test_set = test_datagen.flow_from_directory('..\/input\/dog-cat2\/test_set',\n                                            target_size=(64, 64), batch_size=32, class_mode='binary')","884a3466":"cnn_classifier.fit(training_set, epochs=25, validation_data=test_set, validation_steps=2000 )","11356211":"import numpy as np    # to pre-process the image so that it gets accepted by predict method we are going to use\nfrom keras.preprocessing import image   # to load the image\n\n# the loaded image goes here\ntest_image = image.load_img('..\/input\/dog-cat2\/single_prediction\/dog.jpg',\n                            target_size=(64, 64))   # target size same as that of the testing data","a1f2f63c":"test_image","f3b85afd":"test_image = image.img_to_array(test_image)","87f4c527":"test_image = np.expand_dims(test_image, axis=0)\ntest_image.shape","e6ecd4b7":"result = cnn_classifier.predict(test_image)\nprint(result) # to check the result","9eaf87d9":"training_set.class_indices","a4319b8f":"result.shape","9059677d":"if result[0][0] == 1:\n    prediction = 'Dog'\nelse:\n    prediction = 'Cat'\n    \n# printing the result\nprint(f\"The CNN identified the newly loaded image as {prediction}\")","b2717fae":"test_image2 = image.load_img('..\/input\/dog-cat2\/single_prediction\/cat.jpg',\n                            target_size=(64, 64))\ntest_image2","123971fb":"test_image2 = image.img_to_array(test_image2)\ntest_image2 = np.expand_dims(test_image2, axis=0)\nresult2 = cnn_classifier.predict(test_image2)\n\nif result2[0][0] == 1:\n    prediction2 = 'Dog'\nelse:\n    prediction2 = 'Cat'\n\nprint(f\"The CNN identified the newly loaded image as {prediction2}\")","8df745fd":"**Arguments used -**\n* `target_size` size of images expected in the cnn model, same as the input shape\n* `batch_size` size of the batches where random samples of image will be included \nor after how many inputs the weights will be updated\n* `class_mode` = 'binary' as this is a classification problem (2 classes)","025884e4":"**Step 1.1 :** Intializing the CNN","0066c905":"**Step 1.2 :** Convolution","29507d55":"## Step - 2 : Fitting CNN to images","d4de4d2e":"**Step 2.4 :** Applying image augmentation on testing set","06d34cfa":"**Step 2.5 :** Fitting the model\n\n**Arguments used -** \n* `training set` - as our training set has 8000 images and the batch size is 32, so the CNN will make 250 batches of these images and run the epochs\n* `epochs` are nothing but how many times you want to run through the network, the more the better\n* `validation_steps` - no. of images in testing set","0265d502":"**Note -**\nFollowing is a template taken from Keras Documentation for Image preprocessing and fitting the model by taking the data from a directory\n\n**Step 2.1 :** Image Augmentation\n* Rescaling the Training data\n* This step is necessary as it generates many transformations so that we don't find same image in different batches","6262bb76":"**Step 3.1 :** Pre-processing the image which we are going to load","44b1029a":"**Argument used -**\n* `pool_size` represents the size of pooling image, usually kept 2x2 to not lose info and be precise as well","4bc855f1":"**Step 3.6 :** Additional step **(Making result more explanatory)**\n* We extract the 1st element from `result` as it is a 2d array to identify whether the image is of a cat or a dog\n* Then we assign them with their respective class","f19c3311":"**Step 3.3 :** Changing the above image to 4 dimension\n* The predict method expects 4 dimensions and we have only 3\n* It can't take a single input i.e image\n* It only accepts inputs in a batch\n* Hence the 4th dimension is the batch, even if the batch has 1 input, the inputs must be in a batch","495990fe":"Hence as you can see we got 67% validation accuracy. Now let's check how well it performs on the new data","4d3475bd":"## Step - 3 : Making New Prediction\n\n* Here we will pass an image of a dog to see if our CNN identifies it correctly","095c019e":"**Step 3.4 :** Prediction","5d778da6":"**Step 1.4 :** Flatten","8649d7e6":"This result tells us that it identified the **dog** correctly","3a05fa16":"**Step 1.5 :** Compile(fit)","e196b11a":"## **Step - 1 :** Pre-processing","9c9f7de5":"**Step 1.3 :** Max Pooling","4e6e4e57":"**Arguments used -**\n\n* `optimizer` = name of the algorithm we want to apply, usually SGD algorithm known by 'adam'\n* `loss` = it is a loss function within SGD algorithm, or the function we need to optimize to find optimal weights usually based on the activation function used for the o\/p layer, or the type of dependent variable\n* `metrics` parameter has [ ] coz it expects a list of values as the weights have been calculated after each observation or each batch of observations. Hence the algorithm uses this parameter to calculate the accuracy to improve the model performance","600ecd97":"# **Dog\/Cat Recognition using Convolutional Neural Network**\n\n## **Goals of the project -**\n* To understand the basic implemetation of the CNN\n* To build the CNN layer by layer and understanding the significance of each layer and the arguments used\n* Performing operations like Convolutional, MaxPooling, Flatten, etc\n* Understanding the concepts of vector in Flattening and Full Connection\n* Implementing Image Augmentation operations like rescaling, horizontal flip on training and testing images \n* Using Image Data Generator for Pre-processing","96db51d0":"**Step 3.2 :** Changing the dimensions of the test image from 64x64(2D) to 64x64x3(3D)","29a9fb2e":"**Step 2.3 :** Applying image augmentation on training set","1dd007ea":"**Arguments used -**\n* `arg1` = no. of feature detectors or filters \n* `arg2` = no. of rows of each feature detector \n* `arg3` = no. of cols of each feature detector \n* `arg4` = input_shape, i.e the shape of the image. The goal is to force the shape of all images into the same format as the input images may be of different shape \n* `input_shape=(64, 64, 3)` says that the dim. will be 64x64 and 3 represents the 3 channel of RGB as it is a colored image \n* `activation='relu'` as classifying the image is a non-linear problem, we use rectifier to have non-linearity in our model\n","dc382a1f":"**Arguments used -**\n* `rescale` rescales all pixel values between 0 and 1\n* `shear_range` performs random transvection (0.2) suggested by keras i.e. A kind of linear mapping which leaves all points on one axis fixed, while other points are shifted parallel to the axis by a distance proportional to their perpendicular distance from the axis\n* `zoom_range` is random zoom (0.2) suggested by keras\n* `horizontal_flip=True` images will be flipped horizontally\n\n**Step 2.2 :** Rescaling the test data","9be67d5d":"**Step 3.5 :** Checking the indices\n* We don't know from the result obtained above whether 1 stands for cat or a dog\n* Hence we use the attribute called `class_indices`, which gives us the info about the index assigned to each class","2bf5ca2b":"Checking whether it identifies the **cat** as well","a3554fb3":"**Step 1.5 :** Full Connection"}}