{"cell_type":{"f9324fd9":"code","9a8b21c5":"code","509b3cc8":"code","9659d9bb":"code","98871e3b":"code","9f0addc7":"code","c2dcf693":"code","a9d47231":"code","93f2104e":"code","d0b7d1d6":"code","f06fbbd4":"code","be2924e1":"code","8c8b2365":"code","19cda4c7":"code","56ffd50a":"code","9bc287f9":"code","a56c870d":"code","e1688d52":"code","2e365ef5":"markdown","38c13a3b":"markdown","2f2436eb":"markdown","7cd00a9e":"markdown","21064451":"markdown","555a6b30":"markdown","59171c3e":"markdown","fc6fc25e":"markdown","7e615460":"markdown","d537720e":"markdown","dde243ee":"markdown","8abefd9c":"markdown","fc6bd5f6":"markdown","46ddecdc":"markdown","f9451ba2":"markdown","2ac0828a":"markdown","7366525d":"markdown","9257637b":"markdown","bff6e01d":"markdown","6ffff784":"markdown"},"source":{"f9324fd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a8b21c5":"# Import the train and test data\n\npd.set_option('max_columns', None) #to display all the columns\ntrain_df = pd.read_csv(\"..\/input\/datasets-attrition-rate\/train.csv\")\nX_test = pd.read_csv(\"..\/input\/datasets-attrition-rate\/test.csv\")\ntrain_df.head()","509b3cc8":"X = train_df.drop(['Attrition','Id','EmployeeNumber','Behaviour'],axis = 1)\nY = train_df['Attrition']\nX_test_N = X_test.drop(['Id','EmployeeNumber','Behaviour'],axis = 1)","9659d9bb":"s = (X.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","98871e3b":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y,\n                                                      train_size=0.8, test_size=0.2,\n                                                      random_state=0)","9f0addc7":"from sklearn.preprocessing import LabelEncoder\n\n# Make copy to avoid changing original data \nlabel_X_train = X_train.copy()\nlabel_X_valid = X_valid.copy()\nlabel_X_test = X_test_N.copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n    label_X_valid[col] = label_encoder.transform(X_valid[col])\n    label_X_test[col] = label_encoder.transform(X_test_N[col])  ","c2dcf693":"from sklearn import preprocessing\n\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\nX_train_minmax = min_max_scaler.fit_transform(label_X_train)\nX_valid_minmax = min_max_scaler.transform(label_X_valid)\nX_test_minmax = min_max_scaler.transform(label_X_test)","a9d47231":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nn_estimators = [100, 200, 300, 500]\nmax_depth = [1, 5, 8, 15, 20, 25]\nmin_samples_split = [1, 1.5, 2, 5, 8]\n\nhyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split)\n\nforest = RandomForestClassifier(random_state = 0)\ngridF = GridSearchCV(forest, hyperF, cv = 5, verbose = 3, \n                      n_jobs = -1)\n\nbestF = gridF.fit(X_train_minmax, y_train)\nprint(bestF.best_params_)","93f2104e":"from xgboost import XGBClassifier\n\ngamma = [0.01, 0.1, 0.5, 1]\nmax_depth = [1, 2, 5, 8, 10,12]\nlearning_rate = [0.1, 1, 2, 5, 10]\n\nhyperF_XGB = dict(gamma = gamma, max_depth = max_depth,  \n              learning_rate = learning_rate)\n\nXGB = XGBClassifier(random_state = 0)\ngridF_XGB = GridSearchCV(XGB, hyperF_XGB, cv = 5, verbose = 1, \n                      n_jobs = -1)\n\nbestF_XGB = gridF_XGB.fit(X_train_minmax, y_train)\nprint(bestF_XGB.best_params_)","d0b7d1d6":"from sklearn.ensemble import GradientBoostingClassifier\n\nn_estimators = [100, 200, 300, 500, 700, 1000]\nmax_depth = [1, 2, 5, 6, 8]\nlearning_rate = [0.01, 0.05, 0.1, 1, 2,]\n\nhyperF_gb = dict(n_estimators = n_estimators, max_depth = max_depth,\n             learning_rate = learning_rate)\n\ngb = GradientBoostingClassifier(random_state = 0)\ngridF_gb = GridSearchCV(gb, hyperF_gb, cv = 5, verbose = 1, \n                      n_jobs = -1)\n\nbestF_gb = gridF_gb.fit(X_train_minmax, y_train)\nprint(bestF_gb.best_params_)","f06fbbd4":"from sklearn import svm\n\nC = [1, 2, 3, 4, 5, 6, 6.5, 7]\nkernel = [ 'poly', 'rbf', 'sigmoid']\ngamma = ['scale', 'auto']\n\nhyperF_svm = dict(C = C, kernel = kernel,  \n              gamma=gamma)\n\nmodel_svm = svm.SVC(random_state=0)\ngridF_svm = GridSearchCV(model_svm, hyperF_svm, cv = 5, verbose = 1, \n                      n_jobs = -1)\n\nbestF_svm = gridF_svm.fit(X_train_minmax, y_train)\nprint(bestF_svm.best_params_)","be2924e1":"RF_reg = RandomForestClassifier(max_depth= 20, min_samples_split= 2, n_estimators= 300, random_state=0)\nRF_reg.fit(X_train_minmax,y_train)\n\nfrom sklearn import metrics\ny_pred_class_train = RF_reg.predict(X_train_minmax)\n\ny_pred_class = RF_reg.predict(X_valid_minmax)\nprint('Validation Accuracy: ')\nprint(metrics.accuracy_score(y_valid, y_pred_class))\n\nprint('\\n Confusion Matrix:')\nconfusion = metrics.confusion_matrix(y_valid, y_pred_class)\nprint(confusion)\n\n# calculate the fpr and tpr for all thresholds of the classification\nfpr, tpr, threshold = metrics.roc_curve(y_valid, y_pred_class)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","8c8b2365":"Gradient_reg = GradientBoostingClassifier(learning_rate= 0.05, max_depth= 5, n_estimators= 500, random_state=0)\nGradient_reg.fit(X_train_minmax,y_train)\n\ny_pred_class = Gradient_reg.predict(X_valid_minmax)\n\nfrom sklearn import metrics\n\nprint('Confusion Matrix: \\n')\nconfusion = metrics.confusion_matrix(y_valid, y_pred_class)\nprint(confusion)\n\n# calculate the fpr and tpr for all thresholds of the classification\nfpr, tpr, threshold = metrics.roc_curve(y_valid, y_pred_class)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","19cda4c7":"XGB_reg = XGBClassifier(gamma= 0.1,learning_rate= 0.1, max_depth=12)\nXGB_reg.fit(X_train_minmax,y_train)\n\ny_pred_class = XGB_reg.predict(X_valid_minmax)\n\nfrom sklearn import metrics\n\nprint('Confusion Matrix: \\n')\nconfusion = metrics.confusion_matrix(y_valid, y_pred_class)\nprint(confusion)\n\n# calculate the fpr and tpr for all thresholds of the classification\nfpr, tpr, threshold = metrics.roc_curve(y_valid, y_pred_class)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","56ffd50a":"model_svm = svm.SVC(C= 7, gamma= 'scale', kernel= 'rbf',random_state=0,probability=True)\nmodel_svm.fit(X_train_minmax,y_train)\n\ny_pred_class = model_svm.predict(X_valid_minmax)\n\nfrom sklearn import metrics\n\nprint('Confusion Matrix: \\n')\nconfusion = metrics.confusion_matrix(y_valid, y_pred_class)\nprint(confusion)\n\n# method I: plt\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","9bc287f9":"f_impt= pd.DataFrame(RF_reg.feature_importances_,index=X_train.columns)\nf_impt = f_impt.sort_values(by=0,ascending=False)\nf_impt.columns = ['feature importance']\nf_impt","a56c870d":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\n\ndef get_score(n_estimators):\n    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n    \n    Keyword argument:\n    n_estimators -- the number of trees in the forest\n    \"\"\"\n    # Replace this body with your own code\n    my_pipeline = Pipeline(steps=[('model', RandomForestClassifier(n_estimators, random_state=0))])\n    scores = -1 * cross_val_score(my_pipeline, X_train_minmax, y_train,\n                              cv=10,\n                              scoring='accuracy')\n\n    return scores.mean()\n\nresults = {}\nfor i in range(1,8):\n    results[50*i] = get_score(50*i)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(list(results.keys()), list(results.values()))\nplt.show()","e1688d52":"attrition_percent = Gradient_reg.predict_proba(X_test_minmax)\ndataset = pd.DataFrame({'Attrition': attrition_percent[:, 1]})\n\nId_col = train_df['Id']\nId_col.head()\ndataset.insert(0, \"Id\",Id_col , True)\n\ndataset.set_index('Id', inplace=True)\nprint (dataset)","2e365ef5":"Import Data and libraries","38c13a3b":"For svm","2f2436eb":"For XGBClassifier","7cd00a9e":"For GradientBoostingClassifier","21064451":"Apply Label Encoding to the categorical variables (Text Form) so as to convert it into numeric form.\n\nIn Label Encoding, remember to always fit_transform the training dataset and then transform the test\/validation dataset.","555a6b30":"Applying first model 'GradientBoostingClassifier' to the given dataset and trying to find the best parameters to better tune the model\n","59171c3e":"Now that we have found the best fit parameters using GridSearchCV Method. We can use the respective parameters in running the ML Models. We will try to find the validation accuracy, Confusion Matrix and AUC score to evaluate the Fitness of the given model with dataset. At Last we will select the model with highest accuracy or AUC score to predict the attrition rate on test data.","fc6fc25e":"####### FEATURE IMPORTANCE #### ####\n\nRank the importance of features. We can decide which parameters to drop based on these statistics.","7e615460":"Applying first model 'svm' to the given dataset and trying to find the best parameters to better tune the model\n","d537720e":"Drop the columns using Feature Engineering which we will see in later steps\n","dde243ee":"Find object columns so as to transform or encode them in order to apply ML models on the data","8abefd9c":"For Feature Engineering we can plot many graphs showing distribution of individual variables against attrition rate, If the distribution is not normal or if it is skewed then we can use SQRT or LOG functions to fine tune them.\n\nAlso we can find the correlation graphs of pairs of varibales to find dependencies and if some of them are highly dependent on each other then we can drop or modify them to avoide repeated results.\n\nPlotting these graphs are very easy and will take much space to this notebook hence I havent shown them to keep it simple.\n\n# Please do Upvote if you find it useful. I am happy for any comments or suggestions for this notebook","fc6bd5f6":"First for RandomForestClassifier","46ddecdc":"Applying first model 'RandomForestClassifier' to the given dataset and trying to find the best parameters to better tune the model using 'GridSearchCV' method.\n\nUse CV value as per your consideration (It will decide the number of cross validation datasets considered for evaluation)","f9451ba2":"Based on the accuracy and AUC score we have decided to use GradientBoostingClassifier as the final model to predict attrition rate on test dataset","2ac0828a":"Break off validation set from training data","7366525d":"# Employee Attrition Prediction\n\nTo predict Employee Attrition by the given data about his\/her past history.\n\nI would like to thank Consultancy and Analytics Club of IIT Guwahati, for conducting such a wonderful hackathon. https:\/\/www.kaggle.com\/c\/summeranalytics2020. It was really fun in applying what we learned in the course, it started my journey to kaggle.\n\nAs the COVID-19 keeps unleashing its havoc, the world continues to get pushed into the crisis of the great economic recession, more and more companies start to cut down their underperforming employees. Companies firing hundreds and thousands of Employees is a typical headline today. Cutting down employees or reducing an employee salary is a tough decision to take. Here in this project we look at various parameters responsible for attrition of employee and at the end will build a model to predict Employee Attrition.\n\nI tried to keep the code simple without sharing the visualization graphs which are easy to plot and helps in Feature Engineering. \n\nHere I share my first kernel, please do upvote it if you find it helpful.","9257637b":"Applying first model 'XGBClassifier' to the given dataset and trying to find the best parameters to better tune the model\n","bff6e01d":"Apply MinMax Scalar to all features so as to tune the variables in similar scale. This step helps in improving the model results and better fit model to the data given","6ffff784":"Cross Validation can be useful in finding the average low MAPE score and to get the best parameters for our chosen ML model\n\n"}}