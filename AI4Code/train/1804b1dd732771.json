{"cell_type":{"8784cfa6":"code","0f7d9b51":"code","37930153":"code","0979ffd7":"code","26ba38d4":"code","bed747de":"code","76fdf551":"code","3e3a0ff7":"code","7336dd02":"code","40632d6f":"code","9f7d9804":"code","e483db09":"code","8f997a44":"code","e27c5f31":"code","7fe6eee9":"code","75e56f7e":"code","6f5c5e8a":"markdown","ff55b443":"markdown","1d19e533":"markdown","00176b47":"markdown","c92ca001":"markdown","80f76db7":"markdown"},"source":{"8784cfa6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport copy \nimport cv2\n\nfrom tqdm import tqdm\nfrom pathlib import Path, PosixPath\nfrom PIL import Image, ImageDraw\nfrom pydantic import BaseModel\nfrom typing import Optional \n\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"bmh\")\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0f7d9b51":"root = Path(\"\/kaggle\/input\/tensorflow-great-barrier-reef\/\")\nroot","37930153":"list(root.iterdir())","0979ffd7":"df = pd.read_csv(root\/\"train.csv\")\ndf.head()","26ba38d4":"total_images = {i.name:len(list(i.glob(\"*.jpg\"))) for i in list((root \/ \"train_images\").glob(\"*\"))}\nprint(total_images)\ndf[\"video_id\"].value_counts()","bed747de":"class Annot(BaseModel):\n    bbox: np.ndarray\n    dtype: str\n    \n    class Config:\n        arbitrary_types_allowed = True        \n        \n\nclass ImageStore(BaseModel):\n    img_loc: PosixPath\n    video_id: str\n    frame_id: str \n    annot: Annot\n    img: np.ndarray\n    vis_img: Optional[np.ndarray]\n    \n    class Config:\n        arbitrary_types_allowed = True","76fdf551":"class GBR:\n    def __init__(self, root, df_loc, only_annots=True):\n        self.df = pd.read_csv(df_loc) if isinstance(df_loc, (str, PosixPath)) else df_loc\n        self.root = root \n        self.df = self.df[self.df[\"annotations\"] != \"[]\"].reset_index(drop=True) if only_annots else self.df \n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        meta = self.df.iloc[idx]\n        video_id = f\"video_{meta['video_id']}\"\n        loc = self.root \/ \"train_images\" \/ video_id \/ (str(meta[\"video_frame\"])+\".jpg\")\n        if loc.exists():\n            img = np.asarray(Image.open(loc))\n            annot = Annot(bbox=np.asarray([[i[\"x\"], i[\"y\"], i[\"width\"], i[\"height\"]] for i in eval(meta[\"annotations\"]) if i != \"[]\"]), dtype=\"xywh\")\n            data = ImageStore(img= img, annot=annot, img_loc=loc, video_id=loc.parent.name, frame_id=loc.name)\n            return data\n        else:\n            print(\"Image not present\")\n    \n    @staticmethod\n    def draw_bboxes(img, bboxes, line_width=5, color=(255, 0, 0)):\n        img = Image.fromarray(copy.deepcopy(img))\n        draw = ImageDraw.Draw(img)\n        lw = line_width or max(round(sum(img.shape) \/ 2 * 0.003), 2)\n        for annot in bboxes:\n            x, y, w, h = annot\n            draw.rectangle([x, y, x+w, y+h], width=lw, outline=\"red\")\n        return img\n    \n    def vis_random(self):\n        idx = np.random.randint(len(self))\n        data = self[idx]\n        if data is not None:\n            vis_img = self.draw_bboxes(data.img, data.annot.bbox) if len(data.annot.bbox) > 0 else data.img \n            print(f\"visualizing: video_id: {data.video_id}, frame: {data.frame_id}\")\n            fig, ax = plt.subplots(figsize=(12, 7.5), nrows=1, ncols=1)\n            ax.imshow(vis_img)\n            ax.axis(\"off\")","3e3a0ff7":"gbr = GBR(root, df, only_annots=True)","7336dd02":"## visualizing a random frame. Can u recognize a object (starfish) just looking at the frame. \ngbr.vis_random()","40632d6f":"df[\"contains_star_fish\"] = df[\"annotations\"].apply(lambda x: len(eval(x)))\ndf.head()","9f7d9804":"fps = 30\ntime_per_sequence = (df.groupby([\"video_id\", \"sequence\"])[\"video_frame\"].count()\/fps).reset_index()\ntime_per_sequence.columns = [\"video_id\", \"sequence\", \"time (sec)\"]\ntime_per_sequence.head()","e483db09":"time_per_sequence[\"time (sec)\"].hist(figsize=(8, 3.5), bins=20)\nplt.title(\"time (sec)\")\nplt.show()","8f997a44":"fig, ax = plt.subplots(figsize=(8*3, 3.5), nrows=1, ncols=3)\nfor i in range(df[\"video_id\"].unique().shape[0]):\n    df_ = df[df[\"video_id\"] == i]\n    ax.flat[i].grid(False)\n    pcm = ax.flat[i].scatter(df_[\"sequence_frame\"].values, df_[\"video_frame\"].values, c=df_[\"contains_star_fish\"].values, cmap='RdBu_r')\n    ax.flat[i].set_title(f\"video_id: {i}\")\n    #ax.flat[i].legend(loc=\"upper right\")\nfig.colorbar(pcm, shrink=1)\nplt.show()","e27c5f31":"def frames2video_gbr(df, save_folder, vis_bbox=False, fps:int=30):\n    ## convert a sequence to video using video_id and sequence as folder name. \n    video_id = df[\"video_id\"].unique()[0]\n    out = None \n    d_ = GBR(root, df_, only_annots=False)\n    for i in tqdm(range(len(d_))):\n        data = d_[i]\n        if data is None:\n            continue\n        height, width, layers = data.img.shape\n        size = (width, height)\n        if out is None:\n            out = cv2.VideoWriter((save_folder\/f\"video_{video_id}-{sequence}.mp4\").as_posix(), cv2.VideoWriter_fourcc(*'MP4V'), fps, size)\n        \n        if vis_bbox:\n            img = GBR.draw_bboxes(data.img, data.annot.bbox) if len(data.annot.bbox) > 0 else data.img \n            img = img if isinstance(img, np.ndarray) else np.asarray(img)\n        else:\n            img = data.img\n        \n        out.write(img[:, :, ::-1])\n    out.release()","7fe6eee9":"save_path=Path(\"\/kaggle\/working\/\") \/ \"raw\"\nsave_path_bbox=Path(\"\/kaggle\/working\/\") \/ \"bbox\"\nsave_path.mkdir(exist_ok=True)\nsave_path_bbox.mkdir(exist_ok=True)\nfps = 24\n## select a video \nsequence = df[\"sequence\"].unique()[3]\ndf_ = df[df[\"sequence\"] == sequence].reset_index(drop=True)\nprint(df_.shape)\nframes2video_gbr(df_, save_path, vis_bbox=False, fps=fps)\nframes2video_gbr(df_, save_path_bbox, vis_bbox=True, fps=fps)","75e56f7e":"# from IPython.display import Video\n# Video(list(Path(\"\/kaggle\/working\/raw\").glob(\"*\"))[0].as_posix())","6f5c5e8a":"This tutorial is used to understand the data. \n## List of topics. \n- [x] visualize the images.  \n- [x] visualize the image with annot boxes.  \n- [x] understand video_id and create a video and visualize them.  \n- [x] video's with bboxes (vis and data)  \n- [ ] bbox stats  ","ff55b443":"## Save a video\n- one raw video \n- same video with bboxes on the image.","1d19e533":"## Convert frame to videos ","00176b47":"## How many videos are present in the dataset ?\n- `sequence` column gives individual video snippets unique_ids. \n- `sequence_frame` gives the frame number within the video. \n- The below plot also tells where star fishes are located within the video along with their count. ","c92ca001":"- Visualizing the appearance of star fish within a video_sequence. \n- Colors represent the count of star fish within the video. On x-axis we have where the star fish is see within the `sequence`.\n- y_axis we have the video_frame number. From this we can make that a single video is stripped into several small video chunks. ","80f76db7":"## Underwater stuff "}}