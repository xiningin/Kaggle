{"cell_type":{"0c03d09c":"code","930c4012":"code","c2573e37":"code","04d558dd":"code","5d49db84":"code","258067b3":"code","6ddda28a":"code","1bd2d84d":"code","2c4bbc00":"code","4b16f33d":"code","10b1cc93":"code","a42aa8c3":"code","13fbfff3":"code","231fc5af":"code","89db8c2a":"code","b97def2f":"code","c605b0ef":"code","874a02ae":"code","43417ed3":"code","4c0a02c8":"code","6aa298ba":"code","a6d363e6":"code","31309bab":"code","2399a63e":"code","0869fb59":"code","420f078d":"code","fa51c0e9":"code","65cdb4c8":"code","24447274":"code","2cac839f":"code","276b4d70":"code","bc1d5516":"code","9f7ffda6":"code","d64d605c":"code","57620c66":"markdown","3d20939f":"markdown","d8b33a8f":"markdown","28393b50":"markdown","af6e5607":"markdown","0ee3bb65":"markdown","d1657218":"markdown","2946aeb2":"markdown","a42a9ae8":"markdown","3de26c7d":"markdown","270ed880":"markdown","9bf1f243":"markdown","3ee3161c":"markdown","27871889":"markdown","41dcded7":"markdown","58a83c10":"markdown","f2181513":"markdown","421ae462":"markdown","ba0c8844":"markdown","053fee78":"markdown","a3046935":"markdown","7b7cacce":"markdown","1fee63e9":"markdown","46c1eeff":"markdown","4c090183":"markdown","d84343ee":"markdown","252e24c7":"markdown","32f3d1d1":"markdown"},"source":{"0c03d09c":"import pandas as pd\nimport os \n\nbean_data = pd.read_excel(os.getcwd() + \"\/..\/input\/Dry_Bean_Dataset.xls\")\nbean_data.head()","930c4012":"bean_data.describe()","c2573e37":"bean_data.isnull().any().sum()","04d558dd":"# This line tells the notebook to show plots inside of the notebook\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n# sb.pairplot(bean_data.sample(100), hue='Class')\n# ;","5d49db84":"plt.figure(figsize = (8, 5))\n\nsb.countplot(x = bean_data[\"Class\"])\nplt.title(\"Number of beans per type\")\nplt.show()","258067b3":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(bean_data['Class'])\nbean_data['Class'] = le.transform(bean_data['Class'])","6ddda28a":"corr_matrix = bean_data.corr()\n\nplt.figure(figsize=(15,15))\nplt.title('Correlation Heatmap of Beans Dataset')\na = sb.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\na.set_xticklabels(a.get_xticklabels(), rotation=30)\na.set_yticklabels(a.get_yticklabels(), rotation=30)\nplt.show()","1bd2d84d":"original_bean_data = bean_data\n\noriginal_bean_data.head()","2c4bbc00":"bean_data = bean_data.drop(['ShapeFactor3', \n                            'Compactness',\n                            'AspectRation',\n                            'Area',\n                            'MajorAxisLength',\n                            'MinorAxisLength',\n                            'ConvexArea',\n                            'EquivDiameter',\n                            'ShapeFactor1'], axis = 1)\n\nbean_data.head()","4b16f33d":"def get_X_y(dataset, scaler=None):\n    X = dataset.drop('Class', axis=1)\n    y = dataset['Class']\n    \n    if scaler != None:\n        scaler = scaler.fit(X)\n        X = scaler.transform(X)\n\n    return X, y\n        \nX, y = get_X_y(bean_data)\n\nX.head()","10b1cc93":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\n\ndef tune_model(dataset, model_instance, parameter_grid, cross_validation=StratifiedKFold(n_splits=10), scaler=None, oversample=False): \n    X, y = get_X_y(dataset, scaler)\n    \n    if oversample:\n        steps = [('sampling', SMOTE()), ('model', model_instance)]\n        model_instance = Pipeline(steps=steps)\n\n\n    grid_search = GridSearchCV(\n        model_instance,\n        param_grid=parameter_grid,\n        cv=cross_validation,\n        scoring=\"f1_weighted\"\n    )\n\n    grid_search.fit(X, y)\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\n\n    grid_search.best_estimator_\n    return grid_search","a42aa8c3":"from sklearn.model_selection import train_test_split\nimport time\n\ndef measure_time(dataset, model_instance, params, scaler=None, oversample=False):\n    X, y = get_X_y(dataset, scaler)\n\n    if oversample:\n        steps = [('sampling', SMOTE()), ('model', model_instance)]\n        model_instance = Pipeline(steps=steps)\n    model_instance.set_params(**params)\n\n    (X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.25, random_state=1)\n    \n    start = time.time()\n    model_instance.fit(X_train, y_train)\n    end = time.time()\n    return end - start","13fbfff3":"from sklearn.tree import DecisionTreeClassifier\n\nparameter_grid = {\n    'criterion': ['gini', 'entropy'],\n    'splitter': ['best', 'random'],\n    'max_depth': range(1, 7),\n    'max_features': range(1, 7)\n}\n\n# No oversampling \/ No feature selection\ndt_original = tune_model(original_bean_data, DecisionTreeClassifier(), parameter_grid)","231fc5af":"# No oversampling \/ Feature selection\ndt = tune_model(bean_data, DecisionTreeClassifier(), parameter_grid)","89db8c2a":"parameter_grid = {\n    'model__criterion': ['gini', 'entropy'],\n    'model__splitter': ['best', 'random'],\n    'model__max_depth': range(1, 7),\n    'model__max_features': range(1, 7)\n}\n\n# Oversampling \/ Feature Selection\ndt_os_fs = tune_model(bean_data, DecisionTreeClassifier(), parameter_grid, oversample=True)","b97def2f":"# Importing necessary libraries\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport numpy as np","c605b0ef":"X, y = get_X_y(bean_data)\n\n# Without standardizing the data:\nsvc = SVC()\n\n# cross_val_score returns a list of the scores, which we can visualize\n# to get a reasonable estimate of our classifier's performance\ncv_scores = cross_val_score(svc, X, y, cv=10)\n\nplt.hist(cv_scores)\nplt.title('Average score: {}'.format(np.mean(cv_scores)))","874a02ae":"# Standardizing the data:\nstandardized_X, y = get_X_y(bean_data, scaler = StandardScaler())\n\nsvc = SVC()\n\n# cross_val_score returns a list of the scores, which we can visualize\n# to get a reasonable estimate of our classifier's performance\ncv_scores = cross_val_score(svc, standardized_X, y, cv=10)\nplt.hist(cv_scores)\nplt.title('Average score: {}'.format(np.mean(cv_scores)))","43417ed3":"parameter_grid = {\n    'C': [1, 10, 50], \n    'gamma': [0.001, 0.0001],\n    # 'kernel': ['linear', 'poly', 'rbf']\n    'kernel': ['linear', 'rbf', 'sigmoid']\n}\n\n# No oversampling \/ No feature selection\nsvc_original = tune_model(original_bean_data, SVC(), parameter_grid, scaler=StandardScaler())","4c0a02c8":"# No oversampling \/ Feature selection\nsvc = tune_model(bean_data, SVC(), parameter_grid, scaler=StandardScaler())","6aa298ba":"parameter_grid = {\n    'model__C': [1, 10, 50], \n    'model__gamma': [0.001, 0.0001],\n    # 'kernel': ['linear', 'poly', 'rbf']\n    'model__kernel': ['linear', 'rbf', 'sigmoid']\n}\n\n# Oversampling \/ Feature Selection\nsvc_os_fs = tune_model(bean_data, SVC(), parameter_grid, scaler=StandardScaler(), oversample=True)","a6d363e6":"# Without standardizing the data\nfrom sklearn import neighbors\n\nX, y = get_X_y(bean_data)\n\nknn = neighbors.KNeighborsClassifier()\n\n# cross_val_score returns a list of the scores, which we can visualize\n# to get a reasonable estimate of our classifier's performance\ncv_scores = cross_val_score(knn, X, y, cv=10)\nplt.hist(cv_scores)\nplt.title('Average score: {}'.format(np.mean(cv_scores)))\n;","31309bab":"# Standardizing the data\nstandardized_X, y = get_X_y(bean_data, scaler=StandardScaler())\n\nknn = neighbors.KNeighborsClassifier()\n\ncv_scores = cross_val_score(knn, standardized_X, y, cv=10)\nplt.hist(cv_scores)\nplt.title('Average score: {}'.format(np.mean(cv_scores)))\n;","2399a63e":"parameter_grid =  {\n    'n_neighbors':[4,5,6,7,10,15],\n    'leaf_size':[5, 10, 15, 20, 50, 100],\n    'n_jobs':[-1],\n    'algorithm':['auto']\n}\n\n# No oversampling \/ No feature selection\nknn = neighbors.KNeighborsClassifier()\nknn_original = tune_model(original_bean_data, knn, parameter_grid, scaler=StandardScaler())","0869fb59":"# No oversampling \/ Feature selection\nknn = neighbors.KNeighborsClassifier()\nknn = tune_model(bean_data, knn, parameter_grid, scaler=StandardScaler())","420f078d":"parameter_grid = {\n    'model__n_neighbors':[4,5,6,7,10,15],\n    'model__leaf_size':[5, 10, 15, 20, 50, 100],\n    'model__n_jobs':[-1],\n    'model__algorithm':['auto']\n}\n\n# Oversampling \/ Feature Selection\nknn_os_fs = tune_model(bean_data, neighbors.KNeighborsClassifier(), parameter_grid, scaler=StandardScaler(), oversample=True)","fa51c0e9":"from sklearn.naive_bayes import GaussianNB\n\nparameter_grid = {}\n\n# No oversampling \/ No feature selection\nnb_original = tune_model(original_bean_data, GaussianNB(), parameter_grid, scaler=StandardScaler())","65cdb4c8":"# No oversampling \/ Feature selection\nnb = tune_model(bean_data, GaussianNB(), parameter_grid, scaler=StandardScaler())","24447274":"parameter_grid = {}\n\n# Oversampling \/ Feature Selection\nnb_os_fs = tune_model(bean_data, GaussianNB(), parameter_grid, scaler=StandardScaler(), oversample=True)","2cac839f":"from sklearn.ensemble import RandomForestClassifier\n\n# parameter_grid = {\n#     'n_estimators': [100,200],\n#     'max_depth': [8, 9, 10],\n#     'n_jobs': [-1], #Use all cores\n#     'max_features': ['auto', 'sqrt'],\n#     'criterion': ['gini', 'entropy']\n# }\n\nparameter_grid = {\n    'n_estimators': [10, 50, 100, 200],\n    'max_depth': [5, 10, 15],\n    'n_jobs': [-1], #Use all cores\n    'max_features': ['auto'],\n    'criterion': ['gini', 'entropy']\n}\n\n# No oversampling \/ No feature selection\nrfc_original = tune_model(original_bean_data, RandomForestClassifier(), parameter_grid)","276b4d70":"# No oversampling \/ Feature selection\nrfc = tune_model(bean_data, RandomForestClassifier(), parameter_grid)","bc1d5516":"parameter_grid = {\n    'model__n_estimators': [10, 50, 100, 200],\n    'model__max_depth': [5, 10, 15],\n    'model__n_jobs': [-1], #Use all cores\n    'model__max_features': ['auto'],\n    'model__criterion': ['gini', 'entropy']\n}\n\n# Oversampling \/ Feature Selection\nrfc_os_fs = tune_model(bean_data, RandomForestClassifier(), parameter_grid, oversample=True)","9f7ffda6":"scores = {\n    \"Decision Tree\" : [dt_original, dt, dt_os_fs],\n    \"SVC\" : [svc_original, svc, svc_os_fs],\n    \"K-nearest Neighbours\" : [knn_original, knn, knn_os_fs],\n    \"Naive Bayes\" : [nb_original, nb, nb_os_fs],\n    \"Random Forest\" : [rfc_original, rfc, rfc_os_fs]\n}\n\nlabels = [\"No oversampling\/No feature selection\",\"No oversampling\/Feature selection\", \"Oversampling\/Feature selection\"]\n\nind = np.arange(5)\n\nplt.figure(figsize=(10,9))\nplt.bar(ind, [i[0].best_score_ for i in scores.values()], 0.2)\nax = plt.bar(ind + 0.2, [i[1].best_score_ for i in scores.values()], 0.2)\nax = plt.bar(ind + 0.4, [i[2].best_score_ for i in scores.values()], 0.2)\nplt.xticks(ind, scores.keys())\nplt.legend(labels,loc=1)\nplt.ylim(0.7, 1)\nplt.show()","d64d605c":"times = {\n    \"Decision Tree\" : [\n        measure_time(original_bean_data, DecisionTreeClassifier(), dt_original.best_params_),\n        measure_time(bean_data, DecisionTreeClassifier(), dt.best_params_),\n        measure_time(bean_data, DecisionTreeClassifier(), dt_os_fs.best_params_, oversample=True)\n    ],\n    \"SVC\" : [\n        measure_time(original_bean_data, SVC(), svc_original.best_params_, scaler=StandardScaler()),\n        measure_time(bean_data, SVC(), svc.best_params_, scaler=StandardScaler()),\n        measure_time(bean_data, SVC(), svc_os_fs.best_params_, oversample=True, scaler=StandardScaler())\n    ],\n    \"K-nearest Neighbours\" : [\n        measure_time(original_bean_data, neighbors.KNeighborsClassifier(), knn_original.best_params_, scaler=StandardScaler()),\n        measure_time(bean_data, neighbors.KNeighborsClassifier(), knn.best_params_, scaler=StandardScaler()),\n        measure_time(bean_data, neighbors.KNeighborsClassifier(), knn_os_fs.best_params_, oversample=True, scaler=StandardScaler())\n    ],\n    \"Naive Bayes\" : [\n        measure_time(original_bean_data, GaussianNB(), nb_original.best_params_, scaler=StandardScaler()),\n        measure_time(bean_data, GaussianNB(), nb.best_params_, scaler=StandardScaler()),\n        measure_time(bean_data, GaussianNB(), nb_os_fs.best_params_, oversample=True, scaler=StandardScaler())\n    ],\n    \"Random Forest\" : [\n        measure_time(original_bean_data, RandomForestClassifier(), rfc_original.best_params_),\n        measure_time(bean_data, RandomForestClassifier(), rfc.best_params_),\n        measure_time(bean_data, RandomForestClassifier(), rfc_os_fs.best_params_, oversample=True)\n    ]\n}\n\nlabels = [\"No oversampling\/No feature selection\",\"No oversampling\/Feature selection\", \"Oversampling\/Feature selection\"]\n\nind = np.arange(5)\n\nplt.figure(figsize=(10,9))\nplt.bar(ind, [i[0] for i in times.values()], 0.2)\nax = plt.bar(ind + 0.2, [i[1] for i in times.values()], 0.2)\nax = plt.bar(ind + 0.4, [i[2] for i in times.values()], 0.2)\nplt.xticks(ind, times.keys())\nplt.legend(labels,loc=1)\n\n# plt.ylim(0.7, 1)\nplt.show()","57620c66":"Now we can run the model some times to see its efficiency with the default parameters:","3d20939f":"# K-nearest neighbours (KNN)\nJust like the SVM model, the KNN model also requires the data to be standardised.","d8b33a8f":"Without standardizing the data the results are simply bad.","28393b50":"# Analysing times to train\n\nBelow we present a plot with the times to train each model one time","af6e5607":"# Random Forest Classifier","0ee3bb65":"By comparing both histograms, it can be easily concluded that the standardization is really necessary and produces better and more consistent results.\n\nStill the cross validation scores vary a lot based on the training data chosen. Therefore we should do some parameter tuning to see what the best parameters are for our dataset that don't overfit the data. This can be achieved by a GridSearch. This will be addressed below. \n","d1657218":"# Dry Bean Dataset Analysis","2946aeb2":"# Importing the dataset","a42a9ae8":"# Naive Bayes","3de26c7d":"## Work specification\n\nThe main purpose of this project is to test and compare **Supervised Learning** models.\n\nWe are given a dataset which contains various features regarding dry beans. Our goal is to develop a model which will take in features of data beans and in turn will preidct whether a given bean's species type.","270ed880":"# SVM\n\nThe SVM algorithm expects the data to be standardized, so we use the *Sklearn StandardScaler* to standardize our data. If this is not performed prior to training the model, the efficiency will be all over the place.","9bf1f243":"The function below is used to retrieve the inputs and outputs from the dataset provided:","3ee3161c":"### Attribute Information\n\n1) **Area (A):** The area of a bean zone and the number of pixels within its boundaries.  \n2) **Perimeter (P):** Bean circumference is defined as the length of its border.  \n3) **Major axis length (L):** The distance between the ends of the longest line that can be drawn from a bean.  \n4) **Minor axis length (l):** The longest line that can be drawn from the bean while standing perpendicular to the main axis.  \n5) **Aspect ratio (K):** Defines the relationship between L and l.  \n6) **Eccentricity (Ec):** Eccentricity of the ellipse having the same moments as the region.  \n7) **Convex area (C):** Number of pixels in the smallest convex polygon that can contain the area of a bean seed.  \n8) **Equivalent diameter (Ed):** The diameter of a circle having the same area as a bean seed area.  \n9) **Extent (Ex):** The ratio of the pixels in the bounding box to the bean area.  \n10) **Solidity (S):** Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.  \n11) **Roundness (R):** Calculated with the following formula: (4piA)\/(P^2)  \n12) **Compactness (CO):** Measures the roundness of an object: Ed\/L  \n13) **ShapeFactor1 (SF1)**  \n14) **ShapeFactor2 (SF2)**  \n15) **ShapeFactor3 (SF3)**  \n16) **ShapeFactor4 (SF4)**   \n17) **Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira**  ","27871889":"# Decision Tree Classifier","41dcded7":"## Group\n\n- Eduardo Correia - up201806433\n- Jo\u00e3o Cardoso - up201806531\n- Ricardo Font\u00e3o - up201806317","58a83c10":"## Removing outliers\n\nAs can be seen in the graph above, there are clearly some outliers in our dataset.\n\nSince it's not mentioned in the initial problem's statement if these outliers are to be expected or not, we decided not to remove them.","f2181513":"# Comparing Models","421ae462":"First we check for missing data:","ba0c8844":"# Feature Selection\n\nOur next step is to create a correlation matrix to compare how each feautre correlates to eachother and to the Class label. For that we need to encode the Class label so that the correlation can be calculated. ","053fee78":"# Conclusion\n\nThe proposed work was to test and compare different Supervised Machine Learning models for classification of the Dry beans dataset. The tested models were **Decision Tree**, **Support Vector Machines**, **K-nearest Neighbours**, **Naive Bayes** and **Random Forest**. \n\nAfter some exploratory data analysis we decided to drop some features based on their correlation with each other. This proved to be only effective in the **Naive Bayes** and **Random Forest Classifiers**. \n\nTo evaluate each model and choose the best parameters for each one, we used SKLearn's GridSearchCV to test different set of parameters. To score the models we used **f1 wighted score**. We also tried combining oversampling with and without feature selection. Looking at the benchmarks we can conclude that oversampling does not improve the scores on our models while increasing significantly the training time. \n\nIn terms of scoring, it can be concluded that the best models for our classification problem is the **Support Vector Machine**, followed closely by the **K-nearest Neighbors**. However when we take a look at the time needed to train each model, the **Support Vector Machine** takes much longer than **K-nearest Neighbours**, making **K-nearest neighbours** the best model overall. This appears to be related to the fact that **K-nearest Neighbours** can be trained with the flag n_jobs=-1 which makes it use all the cores in the CPU while **Support Vector Machine** does not support this option.","a3046935":"# Time measuring\n","7b7cacce":"# Cross validation and parameter tuning\n## Auxiliary function to perform parameter tuning with cross validation\n\nFor parameter selection we use GridSearchCV and for oversampling we use imblearn's SMOTE.","1fee63e9":"## Checking for the amount of each bean in the dataset","46c1eeff":"No missing values were found. Next we create a plot of the dataset with a color for each class:","4c090183":"![Big plot](out.png)","d84343ee":"As it is noticeable, there's a huge discrepancy between the least (Bombay) and most (Dermason) common bean species, with a difference of a factor of 6. We will take this into account when choosing the scoring function used to compare the models. ","252e24c7":"# Used libraries\n\n* [scikit-learn](https:\/\/scikit-learn.org\/)\n* [pandas](https:\/\/pandas.pydata.org\/)\n* [seaborn](https:\/\/seaborn.pydata.org\/)\n* [matplotlib](https:\/\/matplotlib.org\/)\n* [imblearn](https:\/\/imbalanced-learn.org\/stable\/)","32f3d1d1":"From this correlation matrix we can exctract features that are strongly correlated with eachother. Since we have a mirrored matrix the analysis can be done by just exctracting the upper matrix triangle and searching for values with an absolute value of more than 0.9 which is our criteria for correlated features.   \n\nThe first set of features correlated are:\n* Area\n* Perimeter\n* MajorAxisLength\n* MinorAxisLength\n* ConvexArea\n* EquivDiameter\n* ShapeFactor1 -> even though this feature only has high correlation(>0.9) with MinorAxisLength it presents >0.85 correlation with all other features here presented so we'll include it here\n\n\nThe feature to remove is the one that presents the highest correlation with the Class label which in this case is the **Perimeter**.\n\nThe second set of correlated features are:\n* ShapeFactor3\n* Compactness\n* Eccentricity\n* AspectRation\n\nFrom this set of features the retained one is **Eccentricity**.\n\nSo the following features will be dropped:\n* ShapeFactor3\n* Compactness\n* AspectRation\n* Area\n* MajorAxisLength\n* MinorAxisLength\n* ConvexArea\n* EquivDiameter\n* ShapeFactor1"}}