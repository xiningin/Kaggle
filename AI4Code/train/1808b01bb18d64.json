{"cell_type":{"47f3421d":"code","4c477cef":"code","a10049c8":"code","170e033b":"code","7f7835a0":"code","a8b23e12":"code","57920ad7":"code","44dbe5ed":"code","4790cfa1":"code","66f4e098":"code","79aef306":"code","4d8f6b72":"code","c917e95f":"code","429c2c35":"code","45c94965":"code","980bc7da":"markdown","0a10f664":"markdown","863bdf9a":"markdown","e2be4498":"markdown","ad192c11":"markdown"},"source":{"47f3421d":"from functools import partial\n\nimport numpy as np\nimport pandas as pd\n\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\nfrom matplotlib import pyplot as plt\n\nimport optuna","4c477cef":"train_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\ntrain_df.head()","a10049c8":"# Reference: https:\/\/www.kaggle.com\/tolgadincer\/continuous-target-stratification\n\nN_FOLDS = 5\ntrain_df[\"kfold\"] = -1\nskf = StratifiedKFold(n_splits=N_FOLDS)\ntrain_df[\"groups\"] = pd.cut(train_df[\"Pawpularity\"], bins=10, labels=False)\ntarget = train_df[\"groups\"]\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(target, target)):\n    train_df.loc[val_idx, 'kfold'] = fold\ntrain_df = train_df.drop([\"groups\"], axis=1)\ntrain_df.head()","170e033b":"plt.hist(train_df[\"Pawpularity\"], bins=100, density=True)\nplt.xlabel('Target')\nplt.ylabel('Frequency')\nplt.show()","7f7835a0":"fig, axs = plt.subplots(1, 5, sharex=True, sharey=True, figsize=(15, 4))\nfor i, ax in enumerate(axs):\n    ax.hist(train_df[train_df[\"kfold\"] == i][\"Pawpularity\"], bins=100, density=True, label=f\"Fold-{i}\")\n    if i == 0:\n        ax.set_ylabel(\"Frequency\")\n    if i == 2:\n        ax.set_xlabel(\"Target\")\n    ax.legend(frameon=False, handlelength=0)\nplt.tight_layout()\nplt.show()","a8b23e12":"features = [\n    \"Subject Focus\", \"Eyes\", \"Face\", \"Near\", \"Action\",\n    \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\",\n    \"Info\", \"Blur\"\n]\ntarget = [\"Pawpularity\"]","57920ad7":"def oof_score(models, train_df):\n    preds, targets = [], []\n    for idx, model in enumerate(models):\n        preds.append(model.predict(train_df[train_df[\"kfold\"] == idx][features]))\n        targets.append(train_df[train_df[\"kfold\"] == idx][target])\n    preds, targets = np.hstack(preds), np.vstack(np.array(targets, dtype=\"object\")).reshape(-1, )\n    return np.sqrt(mean_squared_error(targets, preds))","44dbe5ed":"def objective(trial, train_df, features, target):\n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'n_estimators': trial.suggest_int(\"n_estimators\", 64, 8192),\n        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-3, 0.25, log=True),\n        'num_leaves': trial.suggest_int(\"num_leaves\", 4, 16),\n        'max_depth': trial.suggest_int(\"max_depth\", 4, 16),\n        'feature_fraction': trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n        'lambda_l1': trial.suggest_loguniform(\"lambda_l1\", 1e-8, 100.0),\n        'lambda_l2': trial.suggest_loguniform(\"lambda_l2\", 1e-8, 100.0),\n        'seed': 42,\n        'deterministic': True,\n        'verbose':-1\n    }\n\n    models = []\n    for fold in range(N_FOLDS):\n        train = train_df[train_df[\"kfold\"] != fold]\n        val = train_df[train_df[\"kfold\"] == fold]\n\n        x_train, y_train = train[features], train[target]\n        x_val, y_val = val[features], val[target]\n\n        lgb_train = lgb.Dataset(x_train, y_train)\n        lgb_val = lgb.Dataset(x_val, y_val)\n\n        model = lgb.train(\n            params,\n            lgb_train,\n            num_boost_round=5000,\n            valid_sets=(lgb_train, lgb_val),\n            early_stopping_rounds=100,\n            verbose_eval=False\n        )\n        models.append(model)\n    return oof_score(models, train_df)","4790cfa1":"opt_fun = partial(\n    objective,\n    train_df=train_df,\n    features=features,\n    target=target\n)\n\nstudy = optuna.create_study(direction=\"minimize\")\nstudy.optimize(opt_fun, n_trials=500)\nprint(study.best_params)","66f4e098":"study.best_value, study.best_params","79aef306":"params = study.best_params.copy()\nparams.update({\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': {'rmse'}\n})\nparams","4d8f6b72":"models = []\nfor fold in range(N_FOLDS):\n    train = train_df[train_df[\"kfold\"] != fold]\n    val = train_df[train_df[\"kfold\"] == fold]\n\n    x_train, y_train = train[features], train[target]\n    x_val, y_val = val[features], val[target]\n\n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_val = lgb.Dataset(x_val, y_val)\n\n    model = lgb.train(\n        params,\n        lgb_train,\n        num_boost_round=5000,\n        valid_sets=(lgb_train, lgb_val),\n        early_stopping_rounds=100,\n        verbose_eval=100\n    )\n    models.append(model)","c917e95f":"test_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\ntest_df.head()","429c2c35":"sample_sub_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/sample_submission.csv\")\nsample_sub_df.head()","45c94965":"preds = sum([model.predict(test_df[features]) for model in models])\/N_FOLDS\nsample_sub_df[\"Pawpularity\"] = preds\nsample_sub_df.to_csv('submission.csv', index=False)","980bc7da":"### Distribution of each split","0a10f664":"## Stratified Split","863bdf9a":"## Verifying Stratified Split","e2be4498":"### Target distribution","ad192c11":"## Regression using Light GBM"}}