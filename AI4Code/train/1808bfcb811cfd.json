{"cell_type":{"71b0a7d2":"code","021facf7":"code","7f3666ad":"code","9038c1d2":"code","d73f2161":"code","615d1904":"code","52d42cb3":"code","da7e4fca":"code","bbd3dcf5":"code","5b8d730f":"code","2c6e78b0":"code","ab4d4d7e":"code","3594d300":"code","b9285a7b":"code","5af8c19a":"code","a5475d1a":"code","68bf3ca7":"code","3aaaf1d1":"markdown","634022d3":"markdown","aa35653f":"markdown"},"source":{"71b0a7d2":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport warnings\nwarnings.filterwarnings('ignore')","021facf7":"import os\nos.listdir('..\/input\/')","7f3666ad":"train_df = pd.read_csv('..\/input\/santander-customer-transaction-prediction\/train.csv') \ntest_df = pd.read_csv('..\/input\/santander-customer-transaction-prediction\/test.csv') ","9038c1d2":"# train_stat = pd.read_csv('..\/input\/stats-features\/train_stat.csv') \n# test_stat = pd.read_csv('..\/input\/stats-features\/test_stat.csv') ","d73f2161":"# train_stat['ID_code'] = train_df.ID_code\n# test_stat['ID_code'] = test_df.ID_code","615d1904":"# train = pd.merge(train_df, train_stat,on='ID_code')\n# test = pd.merge(test_df, test_stat,on='ID_code')","52d42cb3":"train = train_df.copy()\ntest = test_df.copy()","da7e4fca":"del train_df\n# del train_stat\ndel test_df\n# del test_stat","bbd3dcf5":"train.shape, test.shape","5b8d730f":"def augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t\/\/2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y\n","2c6e78b0":"train.head()","ab4d4d7e":"test.head()","3594d300":"features = [c for c in train.columns if c not in ['ID_code', 'target']]\ntarget = train['target']\nX_test = test[features].values","b9285a7b":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.335,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.041,\n    'learning_rate': 0.0083,\n    'max_depth': -1,\n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary',\n    'verbosity': 1}","5af8c19a":"num_folds = 9\nfeatures = [c for c in train.columns if c not in ['ID_code', 'target']]\n\nfolds = KFold(n_splits=num_folds, random_state=2319)\noof = np.zeros(len(train))\ngetVal = np.zeros(len(train))\npredictions = np.zeros(len(target))\nfeature_importance_df = pd.DataFrame()\n\nprint('Light GBM Model')\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n    \n    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n    \n    X_tr, y_tr = augment(X_train.values, y_train.values)\n    X_tr = pd.DataFrame(X_tr)\n    \n    print(\"Fold:{}\".format(fold_ + 1))\n    trn_data = lgb.Dataset(X_tr, label=y_tr)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n    \n    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) \/ folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","a5475d1a":"predictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\nsub = pd.DataFrame({\"ID_code\": test.ID_code.values})\nsub[\"target\"] = predictions['target']\nsub.to_csv('submission_oof.csv', index=False)","68bf3ca7":"sub.head(2)","3aaaf1d1":"## Data Augmentation\n\nThanks to @Jiwei Liu Kernel\nhttps:\/\/www.kaggle.com\/jiweiliu\/lgb-2-leaves-augment\/output\n","634022d3":"### Feature engineering ----- Continued","aa35653f":"## Stats Feature"}}