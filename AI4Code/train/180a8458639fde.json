{"cell_type":{"4db0c3fa":"code","79e0662f":"code","d866b1f6":"code","de06462a":"code","5f90b033":"code","f1c7cc0b":"code","fe2d0dc7":"code","12941cf8":"code","aed8595f":"code","3f1bd766":"code","1194ac76":"code","9d360d6c":"code","b7b41202":"code","1d6c4240":"code","ea1a104b":"code","8ae9681e":"code","15d058f5":"code","ed7435b2":"code","503f0c8d":"code","defb3d82":"code","4b9d6f04":"code","8c6a45f5":"code","c403b386":"code","6abe167f":"code","af6e6693":"code","97aed7d2":"code","72adfadb":"code","e32c3e54":"code","ca99307f":"code","cf78d84d":"code","2ea50b9d":"code","6765dd4a":"code","6183c143":"code","6f894fd5":"code","04b2bb1d":"code","35e9939f":"code","8bc85e20":"code","85af0f14":"code","b318a59e":"code","55394917":"code","150effee":"markdown","2fc657d2":"markdown","48f620fc":"markdown","6f849ef0":"markdown","15dee8d6":"markdown","b3fd2099":"markdown","2749c07a":"markdown","d4cc5a80":"markdown","e563c814":"markdown","5eff977c":"markdown","59aae55a":"markdown","fdb32391":"markdown","e00c0c5b":"markdown","ab7beabd":"markdown","41348319":"markdown","060e9f6e":"markdown","20550110":"markdown","d51d3b17":"markdown","3f264659":"markdown"},"source":{"4db0c3fa":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_log_error as msle\nfrom math import sqrt\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","79e0662f":"df = pd.read_csv(\"\/kaggle\/input\/dataset\/Excavator Health Parameters.csv\")\ndf.columns","d866b1f6":"df.info()","de06462a":"df.head()","5f90b033":"#removing the first row as it contains all the units of each column\ndf.drop([0], axis = 0, inplace = True)","f1c7cc0b":"#removing SMR and Calendar column as it wont be helpful while making model\ndf.drop([\"SMR\", \"Calendar\"], axis = 1, inplace = True)","fe2d0dc7":"df.head()","12941cf8":"df.describe()","aed8595f":"df.shape","3f1bd766":"def missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","1194ac76":"missing_table=missing_values_table(df)\nmissing_table","9d360d6c":"df[\"ENGINE OIL PRESS @HI IDLE MIN\"].describe()","b7b41202":"df[\"ENGINE OIL PRESS@LO IDLE MIN\"].describe()","1d6c4240":"df[\"ENGINE OIL TEMP MAX\"].describe()","ea1a104b":"df[\"AMBIENT TEMP MAX\"].describe()","8ae9681e":"df[\"AMBIENT TEMP MIN\"].describe()","15d058f5":"df[\"EXHAUST TEMP MAX (CYL.4-6)\"].describe()","ed7435b2":"df[\"EXHAUST TEMP MAX (CYL.1-3)\"].describe()","503f0c8d":"#All these columns have more than 95% data missing\ndf.drop([\"ENGINE OIL PRESS @HI IDLE MIN\", \"ENGINE OIL PRESS@LO IDLE MIN\"], axis = 1, inplace = True) ","defb3d82":"!pip install dataprep","4b9d6f04":"from dataprep.eda import plot, plot_correlation, create_report, plot_missing","8c6a45f5":"plot(df)","c403b386":"create_report(df)","6abe167f":"#replacing NAN with mean of each their column\nmean_val1 = pd.to_numeric(df[\"ENGINE OIL TEMP MAX\"], errors='coerce').mean()\nmean_val2 = pd.to_numeric(df[\"AMBIENT TEMP MAX\"], errors='coerce').mean()\nmean_val3 = pd.to_numeric(df[\"AMBIENT TEMP MIN\"], errors='coerce').mean()\nmean_val4 = pd.to_numeric(df[\"EXHAUST TEMP MAX (CYL.4-6)\"], errors='coerce').mean()\nmean_val5 = pd.to_numeric(df[\"EXHAUST TEMP MAX (CYL.1-3)\"], errors='coerce').mean()\nmean_val6 = pd.to_numeric(df[\"BLOWBY PRESS MAX\"], errors='coerce').mean()\nvalues = {\"ENGINE OIL TEMP MAX\":mean_val1, \"AMBIENT TEMP MAX\":mean_val2, \"AMBIENT TEMP MIN\":mean_val3, \"EXHAUST TEMP MAX (CYL.4-6)\":mean_val4, \"EXHAUST TEMP MAX (CYL.1-3)\":mean_val5, \"BLOWBY PRESS MAX\":mean_val6}\ndf.fillna(value=values, inplace = True)","af6e6693":"#hecking if there are any more missing values\nmissing_table=missing_values_table(df)\nmissing_table","97aed7d2":"df = df.astype(float)","72adfadb":"y = df[\"FUEL RATE\"].values\ndf.drop(\"FUEL RATE\", axis = 1, inplace = True)\nx = df.values","e32c3e54":"sc = StandardScaler()\nx = sc.fit_transform(x)","ca99307f":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)","cf78d84d":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","2ea50b9d":"def rmsle(true_val, pred_val):\n    return sqrt(msle(true_val, pred_val))","6765dd4a":"def run_cv_model(train, test, target, model_fn, eval_fn= None, params = {}, label = 'model'):\n    kf = KFold(n_splits = 5)\n    fold_splits = kf.split(train, target)\n    cv_scores = []\n    pred_full_test = 0\n    pred_train = np.zeros((train.shape[0]))\n    i = 1\n    for whole_index, part_index in fold_splits:\n        print('Started '+label+' fold '+str(i)+'\/5')\n        print('Train '+label)\n        whole_train, part_train = train[whole_index], train[part_index]\n        whole_target, part_target = target[whole_index], target[part_index]\n        pred_train_part, pred_test_y = model_fn(whole_train, whole_target, part_train, part_target, test, params)\n        pred_train[part_index] = pred_train_part\n        pred_full_test = pred_full_test + pred_test_y\n        if eval_fn is not None:\n            cv_score = eval_fn(part_target, pred_train_part)\n            cv_scores.append(cv_score)\n            print(label + ' cv score {}: {}'.format(i, cv_score))\n        i+=1\n    print('{} cv score: {}'.format(label, cv_scores))\n    print('{} cv mean score : {}'.format(label, np.mean(cv_scores)))\n    print('{} cv std score : {}'.format(label, np.std(cv_scores)))\n    pred_full_test = pred_full_test \/ 5\n    results = {'train': pred_train,\n               'test': pred_full_test,\n               'cv scores': cv_scores,\n               'cv mean score':np.mean(cv_scores),\n               'label': label}\n    return results","6183c143":"def runRF(train_X, train_y, test_X, test_y, test, params):\n    model = RandomForestRegressor(**params)\n    model.fit(train_X, train_y)\n    print('Predict 1\/2')\n    pred_test_y = model.predict(test_X)\n    print('Predict 2\/2')\n    pred_test_y2 = model.predict(test)\n    return pred_test_y, pred_test_y2","6f894fd5":"def runDT(train_X, train_y, test_X, test_y, test, params):\n    model = DecisionTreeRegressor(**params)\n    model.fit(train_X, train_y)\n    print('Predict 1\/2')\n    pred_test_y = model.predict(test_X)\n    print('Predict 2\/2')\n    pred_test_y2 = model.predict(test)\n    return pred_test_y, pred_test_y2","04b2bb1d":"def runSVM(train_X, train_y, test_X, test_y, test, params):\n    model = SVR(**params)\n    model.fit(train_X, train_y)\n    print('Predict 1\/2')\n    pred_test_y = model.predict(test_X)\n    print('Predict 2\/2')\n    pred_test_y2 = model.predict(test)\n    return pred_test_y, pred_test_y2","35e9939f":"def runXGB(train_X, train_y, test_X, test_y, test, params):\n    model = XGBRegressor(**params)\n    model.fit(train_X, train_y)\n    print('Predict 1\/2')\n    pred_test_y = model.predict(test_X)\n    print('Predict 2\/2')\n    pred_test_y2 = model.predict(test)\n    return pred_test_y, pred_test_y2","8bc85e20":"def switch(x):\n    if x == 'RF':\n        rf_params = {'n_estimators': 200, 'random_state': 100}\n        results = run_cv_model(x_train, x_test, y_train, runRF, rmsle, rf_params, 'RF')            \n    if x == 'SVM':\n        svm_params = {'kernel':'rbf'}\n        results = run_cv_model(x_train, x_test, y_train, runSVM, rmsle, svm_params, 'SVM')\n    if x == 'DT':\n        dt_params = {'random_state':0}\n        results = run_cv_model(x_train, x_test, y_train, runDT, rmsle, dt_params, 'DT')\n    if x == 'XGB':\n        xgb_params = {'booster':'gbtree', 'random_state':0}\n        results = run_cv_model(x_train, x_test, y_train, runXGB, rmsle, xgb_params, 'XGB')\n    return results","85af0f14":"model = ['RF', 'SVM', 'DT','XGB']\nresults = []\n\nfor i in model:\n    r = switch(i)\n    results.append(r)","b318a59e":"##result from Random Forest model (as it gives us the best accuracy using root mean square log error)\nresults[0]","55394917":"final_model = RandomForestRegressor(n_estimators = 200, random_state = 200)\nfinal_model.fit(x, y)","150effee":"# **Excavator Model** (Prediction of excavator health using **Fuel rate**)","2fc657d2":"# **Outcome** : \n**we used 4 models for prediction of fuel rate from the given dataset. Later on these fuel rates can be used to make a statement about health of excavators. We are using Root Mean Squared Log error metric for calculating the accuracy of our models. The accuracy we got after applying models are as follows.**\n1. Random Forest Regression - 0.0524996990601583\n2. SVR - 0.06862913514666771\n3. Decision Tree Regression - 0.0756092241372757\n4. XGBoost Regression - 0.054675096895347844\n\n**as we can see the two best models we have are Random Forest Regression and XGBoost Rgeression. For any regression problem these two model give the best results in most of the cases.**","48f620fc":"# **Predicitve Analysis of Excavator Health**\n**Objective :- Analysis of the given dataset and making a machine learning model to predict fuel rate, later on fuel rate will be used to predict health od excavators.** \n\n*Predictive analytics* is the use of data, statistical algorithms and *machine learning techniques* to identify the likelihood of future outcomes based on historical data. The goal is to go beyond knowing what has happened to providing a best assessment of what will happen in the future.\nThough predictive analytics has been around for decades, it's a technology whose time has come. More and more organizations are turning to predictive analytics to increase their bottom line and competitive advantage. Why now?\n* Growing volumes and types of data, and more interest in using data to produce valuable insights.\n* Faster, cheaper computers.\n* Easier-to-use software.\n* Tougher economic conditions and a need for competitive differentiation.\n \nWith interactive and easy-to-use software becoming more prevalent, predictive analytics is no longer just the domain of mathematicians and statisticians. Business analysts and line-of-business experts are using these technologies as well.","6f849ef0":"**Challenges**\n\nWhile the scope of data analytics in mining looks promising, the industry is facing a few challenges.\n\nIt is rather difficult to figure out which data should be collected and analysed. Rummaging through the vast amounts of data collected along the mining chain and identifying and selecting the appropriate data to help make informed decisions to positively affect the bottom line is the biggest challenge.\n\nAnother challenge is consolidating data across different systems, platforms and vendors, for it makes it difficult to create a cohesive data system approach.\n\nThe mining industry has only scratched the surface of what data analytics have to offer. With technology companies understanding the growing need, they are offering solutions to help companies make the most of the huge piles of data collected. With data analytics promising lower costs, better safety procedures, increased efficiency and productivity, every company will make the most of it soon.","15dee8d6":"RMSLE metrics\n![image.png](attachment:acc5659a-c2dd-445e-b1bf-8be10a246c6c.png)","b3fd2099":"# **Importing Libraries**","2749c07a":"# Why is predictive analytics important?\nOrganizations are turning to predictive analytics to help solve difficult problems and uncover new opportunities. Common uses include:\n* **Detecting fraud**  - Combining multiple analytics methods can improve pattern detection and prevent criminal behavior. As cybersecurity becomes a growing concern, high-performance behavioral analytics examines all actions on a network in real time to spot abnormalities that may indicate fraud, zero-day vulnerabilities and advanced persistent threats.\n* **Optimizing marketing campaigns** - Predictive analytics are used to determine customer responses or purchases, as well as promote cross-sell opportunities. Predictive models help businesses attract, retain and grow their most profitable customers. \n* **Improving operations** - Many companies use predictive models to forecast inventory and manage resources. Airlines use predictive analytics to set ticket prices. Hotels try to predict the number of guests for any given night to maximize occupancy and increase revenue. Predictive analytics enables organizations to function more efficiently.\n* **Reducing risk** - Credit scores are used to assess a buyer\u2019s likelihood of default for purchases and are a well-known example of predictive analytics. A credit score is a number generated by a predictive model that incorporates all data relevant to a person\u2019s creditworthiness. Other risk-related uses include insurance claims and collections.","d4cc5a80":"# **Model Building**","e563c814":"# Checking for missing data","5eff977c":"# **Process**","59aae55a":"![image.png](attachment:9ed1998e-6579-495b-85da-1478adb0b0af.png)","fdb32391":"**Data Source** : Data was collected from HEMM Operator for the past 5 years\n\n**Data Requirement** : For making our predicitve analysis the current dataset is enough to make a preliminary model. But to make a detailed model lots of different data will be required such as heat sensors from the engine, hydrolic pressure sensors can be used from the coolant of engine.","e00c0c5b":"![image.png](attachment:e90de991-9df6-44ee-a098-26f82f2bb3aa.png)","ab7beabd":"# **Data Preparation**","41348319":"1. Define Project : Define the project outcomes, dilverables, scoping of effort, buisness objectives, identify the datasets which are going to be used.\n2. Data Collection : Data Mining for predicitve analysis prepares data from multiple sources for analysis. This provides a complete view of customer interactions.\n3. Data Analysis : Data Analysis is the process of inspecting, cleaning, transforming, and modeling data with objective of discovering useful information, arriving at conclusions.\n4. Statistical Analysis : Statistical Analysis enables to validate the assumptions, hypothesis and test them with using standard statistical models.\n5. Modeling : Predictive Modeling provides the ability to automatically create accurate predicitve models about future. There is also options to choose the best solution with multi model evaluation.\n6. Deployment : Predictive model Deployment provides the option to deploy the analytical results in to the every day decision making process to get results, reports and output by automating the decision based on the modeling.\n7. Model Monitoring : Models are manages and monitored to review the model performance to ensure that it is providing the results expected.","060e9f6e":"# Analysing missing value columns","20550110":"**Scope** \n\nUsing data, intelligent systems can predict when an equipment or machinery could fail. In fact, IBM can predict, with real-time analytics derived from a whole bunch of operational data, when a piece of equipment or machinery could fail.\n\nData analytics can be used in practically every stage of the mining process \u2013 from extracting the ore and processing, to separating and concentrating all that is usable. As of now, logistics seems to be the most inefficient part of the mining process. Most of the transportation happens by rail, and a lot of deficiencies reported by companies revolve around the automated process of loading railway cars. With data analytics, it will be possible to point out the inefficiencies and business leaders will be able to make informed decisions for improvement.\n\nData analytics can also be used to ensure the safety of miners. Automated ground control systems, installed by many mining companies across the globe, are primarily used underground or for pit mining. These systems capture data from the vibrations in the ground and can determine whether the mine is strong enough. Whenever miners face real danger (like a ground slide or a tunnel collapse), the monitoring system can send out warning signals for miners to evacuate to safety. Data generated by this ground monitoring system can be used to create safer and cost effective procedures for drilling and blasting.","d51d3b17":"# Exploratory Data Analysis","3f264659":"# Handling Missing values"}}