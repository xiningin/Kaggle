{"cell_type":{"1066ac34":"code","ea467275":"code","2364ec7c":"code","a5864cdf":"code","eb6861be":"code","53c0d044":"code","3f0403cb":"code","959d0118":"code","6eed85a9":"code","cfd1c678":"code","7f7fed96":"code","788a1529":"code","2669ac86":"code","c469debc":"code","26a72f47":"code","ac0fa2a4":"code","0bad21b7":"code","b46c2016":"code","086b164c":"code","c4a517f1":"code","d7ee56df":"code","7b4ee7a5":"code","a31c3f28":"code","fe5219ba":"code","c814c20e":"code","fa85bbf0":"code","169a2cb1":"markdown","66e0f839":"markdown","b762de33":"markdown","66ae6079":"markdown","0481fba8":"markdown","278dbc6d":"markdown","15aa8f65":"markdown","b8a31bff":"markdown","fd5ac184":"markdown","60125711":"markdown","9fe18eee":"markdown","098069c1":"markdown","14b11d1c":"markdown","a3178753":"markdown","226e01e7":"markdown","a47227b8":"markdown","b3cab60c":"markdown","9b8b3d50":"markdown","889f7761":"markdown","4eeabd3f":"markdown","bfacd56f":"markdown","4d68282f":"markdown"},"source":{"1066ac34":"import numpy as np \nimport pandas as pd \nfrom sklearn.preprocessing import StandardScaler\nfrom yellowbrick.cluster import KElbowVisualizer\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\nfrom scipy.stats import mannwhitneyu, spearmanr, pearsonr\npd.options.mode.chained_assignment = None","ea467275":"survey = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv', low_memory=False)\nsurvey['Q6'].iloc[survey['Q6'] == 'I have never written code'] = '0 years'\nsurvey['Q15'].iloc[survey['Q15'] == 'I do not use machine learning methods'] = '0 years' \n# removing the question\ndata = survey.iloc[1:]","2364ec7c":"# Creating the features for clustering\nprofiles = pd.DataFrame(index = data.index)\n\n# Number of programming languages used\ndata['Q7_Part_12'] = np.nan\nprofiles['num_langs'] = data.filter(regex='Q7').notna().sum(axis=1)\n\n# Number of ml-algorithms used\ndata['Q17_Part_11'] = np.nan\nprofiles['num_algs'] = data.filter(regex='Q17').notna().sum(axis=1)\n\n# Number of sources\ndata['Q42_Part_11'] = np.nan\nprofiles['num_sources'] = data.filter(regex='Q42').notna().sum(axis=1)\n\n# Age class\nprofiles['age_class'] = data['Q1']\nage_classes = ['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-69', '70+']\ni = 0\nfor a in age_classes:\n    profiles['age_class'].iloc[profiles['age_class'] == a] = i\n    i += 1\n\n# Users degree    \nprofiles['degree'] = data['Q4']\ndegrees = ['I prefer not to answer', 'No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree',\n          'Bachelor\u2019s degree', 'Master\u2019s degree', 'Professional doctorate', 'Doctoral degree']\ni = 0\nfor d in degrees:\n    profiles['degree'].iloc[profiles['degree'] == d] = i\n    if d != 'Professional doctorate': i += 1 # assign same rank to doctoral degree and professional doctorate \n        \n# How long has the user been writing code\nprofiles['years_coding_class'] = data['Q6']\ncode = ['0 years', '< 1 years', '1-3 years', '3-5 years', '5-10 years', '10-20 years', '20+ years']\ni = 0\nfor c in code:\n    profiles['years_coding_class'].iloc[profiles['years_coding_class'] == c] = i\n    i += 1\n\n# How long has the user been using ml-methods\nprofiles['years_ml_class'] = data['Q15']\nml = ['0 years', 'Under 1 year', '1-2 years', '2-3 years', '3-4 years',  '4-5 years', '5-10 years', '10-20 years', '20 or more years']\ni = 0\nfor m in ml:\n    profiles['years_ml_class'].iloc[profiles['years_ml_class'] == m] = i\n    i += 1\nprofiles['years_ml_class'] = profiles['years_ml_class'].fillna(profiles['years_ml_class'].median())\n\n# Is the user a student?\nprofiles['student'] = data['Q5'].str.contains('Student')\n\n# does the employer use ml\nprofiles['ml_used_at_job'] = data['Q23'].fillna('I do not know')\nprofiles['ml_used_at_job'].iloc[profiles['ml_used_at_job'] == 'I do not know'] = 0\nprofiles['ml_used_at_job'].iloc[profiles['ml_used_at_job'] == 'No (we do not use ML methods)'] = 0\nprofiles['ml_used_at_job'].iloc[profiles['ml_used_at_job'] == 'We are exploring ML methods (and may one day put a model into production)'] = 1\nprofiles['ml_used_at_job'].iloc[profiles['ml_used_at_job'] == 'We recently started using ML methods (i.e., models in production for less than 2 years)'] = 1\nprofiles['ml_used_at_job'].iloc[profiles['ml_used_at_job'] == 'We use ML methods for generating insights (but do not put working models into production)'] = 1\nprofiles['ml_used_at_job'].iloc[profiles['ml_used_at_job'] == 'We have well established ML methods (i.e., models in production for more than 2 years)'] = 2","a5864cdf":"profiles","eb6861be":"palette = ['#016E78', '#02ABB7', '#00F3D7', \"#94167F\", '#E672E0', \"#F62E97\"]\npal5 = ['#02ABB7', '#00F3D7', \"#F62E97\", '#E672E0', '#674076']\npal3 = ['#00F3D7', \"#94167F\", \"#F62E97\"]\npal2 = ['#00F3D7', \"#F62E97\"]\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n\nsns.countplot(ax=ax1, x=\"num_langs\", palette=palette, data=profiles)\nsns.countplot(ax=ax2, x=\"num_algs\", palette=palette, data=profiles)\nsns.countplot(ax=ax3, x=\"num_sources\", palette=palette, data=profiles)\nplt.show()","53c0d044":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n\nsns.countplot(ax=ax1, x=\"age_class\", palette=palette, data=profiles)\nsns.countplot(ax=ax2, x=\"years_coding_class\", palette=palette, data=profiles)\nsns.countplot(ax=ax3, x=\"years_ml_class\", palette=palette, data=profiles)\nplt.show()","3f0403cb":"pal = pal2\nfig = plt.subplots(figsize=(10,10))\n\ndata1 = [profiles['student'].mean(), 1-profiles['student'].mean()]\nlabels = ['student', 'not a student']\nplt.pie(data1, labels = labels, colors = pal, autopct='%.0f%%')\nplt.show()","959d0118":"pal = pal3\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n\nsns.countplot(ax=ax1, x=\"Q4\", palette=pal, data=survey[1:])\nax1.tick_params(labelrotation=45)\nsns.countplot(ax=ax2, x=\"ml_used_at_job\", palette=pal, data=profiles)\nplt.show()","6eed85a9":"# scaling the data improves the performance of kmeans-clustering\nscl = StandardScaler()\ns_profiles = pd.DataFrame(scl.fit_transform(profiles), index=profiles.index, columns=profiles.columns)\n# using the elbow-method to find a suitable number of clusters\nmodel = KMeans(random_state=69)\nvisualizer = KElbowVisualizer(model, k=(2,10))\nvisualizer.fit(s_profiles)  \nvisualizer.show()\nplt.show()","cfd1c678":"# fit and predict\nkmeans = KMeans(n_clusters=5,random_state=69)\nprofiles['cluster'] = kmeans.fit_predict(s_profiles)","7f7fed96":"#pal = [\"palegreen\", \"paleturquoise\", \"lightpink\",\"salmon\",\"plum\"]\npal = pal5\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30,10))\n\nsns.boxplot(ax=ax1, x=\"cluster\", y=\"num_algs\", palette=pal, data=profiles)\nsns.boxplot(ax=ax2, x=\"cluster\", y=\"num_langs\", palette=pal, data=profiles)\nsns.boxplot(ax=ax3, x=\"cluster\", y=\"num_sources\", palette=pal, data=profiles)\nplt.show()","788a1529":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30,10))\n\nsns.countplot(ax=ax1, x=\"age_class\", hue='cluster', palette=pal, data=profiles)\nsns.countplot(ax=ax2, x=\"years_coding_class\", hue='cluster', palette=pal, data=profiles)\nsns.countplot(ax=ax3, x=\"years_ml_class\", hue='cluster', palette=pal, data=profiles)\nplt.show()","2669ac86":"# function getting the data for the pie-chart\ndef get_data(df, cluster, key):\n    out = []\n    labl = []\n    dft = df[df['cluster'] == cluster]\n    for i in sorted(dft[key].unique()):\n        out.append(len(dft[key][dft[key] == i]))\n        labl.append(str(i))\n    return out, labl","c469debc":"fig, axs = plt.subplots(figsize=(18,15))\n\nfig.suptitle('Student')\n\npal = pal2\n\ndata0, label0 = get_data(profiles, 0, 'student')\ndata1, label1 = get_data(profiles, 1, 'student')\ndata2, label2 = get_data(profiles, 2, 'student')\ndata3, label3 = get_data(profiles, 3, 'student')\ndata4, label4 = get_data(profiles, 4, 'student')\n\nax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\nax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\nax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\nax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\nax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n\nax1.pie(data0, labels = label0, colors = pal, autopct='%.0f%%')\nax1.set_title('Cluster 0')\nax2.pie(data1, labels = label1, colors = pal, autopct='%.0f%%')\nax2.set_title('Cluster 1')\nax3.pie(data2, labels = label2, colors = pal, autopct='%.0f%%')\nax3.set_title('Cluster 2')\nax4.pie(data3, labels = label3, colors = pal, autopct='%.0f%%')\nax4.set_title('Cluster 3')\nax5.pie(data4, labels = label4, colors = pal, autopct='%.0f%%')\nax5.set_title('Cluster 4')\nplt.show()","26a72f47":"fig, axs = plt.subplots(figsize=(18,15))\n\nfig.suptitle('Highest Degree')\n\npal = palette\n\ndata0, label0 = get_data(profiles, 0, 'degree')\ndata1, label1 = get_data(profiles, 1, 'degree')\ndata2, label2 = get_data(profiles, 2, 'degree')\ndata3, label3 = get_data(profiles, 3, 'degree')\ndata4, label4 = get_data(profiles, 4, 'degree')\n\nlabels = ['Not Disclosed', 'No Degree p. HS.', 'College no Degree', 'Bachelor', 'Master', 'Doctor']\n\nax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\nax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\nax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\nax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\nax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n\nax1.pie(data0, labels = labels, colors = pal, autopct='%.0f%%')\nax1.set_title('Cluster 0')\nax2.pie(data1, labels = labels, colors = pal, autopct='%.0f%%')\nax2.set_title('Cluster 1')\nax3.pie(data2, labels = labels, colors = pal, autopct='%.0f%%')\nax3.set_title('Cluster 2')\nax4.pie(data3, labels = labels, colors = pal, autopct='%.0f%%')\nax4.set_title('Cluster 3')\nax5.pie(data4, labels = labels, colors = pal, autopct='%.0f%%')\nax5.set_title('Cluster 4')\nplt.show()","ac0fa2a4":"fig, axs = plt.subplots(figsize=(18,15))\n\nfig.suptitle('Usage of ML-Algorithms at the Workplace')\n\npal = pal3\n\ndata0, label0 = get_data(profiles, 0, \"ml_used_at_job\")\ndata1, label1 = get_data(profiles, 1, \"ml_used_at_job\")\ndata2, label2 = get_data(profiles, 2, \"ml_used_at_job\")\ndata3, label3 = get_data(profiles, 3, \"ml_used_at_job\")\ndata4, label4 = get_data(profiles, 4, \"ml_used_at_job\")\n\nlabels = ['No Usage\/Unknown', 'Moderate Usage', 'Extensive Usage']\n\nax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\nax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\nax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\nax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\nax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n\nax1.pie(data0, labels = labels, colors = pal, autopct='%.0f%%')\nax1.set_title('Cluster 0')\nax2.pie(data1, labels = labels, colors = pal, autopct='%.0f%%')\nax2.set_title('Cluster 1')\nax3.pie(data2, labels = labels, colors = pal, autopct='%.0f%%')\nax3.set_title('Cluster 2')\nax4.pie(data3, labels = labels, colors = pal, autopct='%.0f%%')\nax4.set_title('Cluster 3')\nax5.pie(data4, labels = ['No Usage\/Unknown'], colors = pal, autopct='%.0f%%')\nax5.set_title('Cluster 4')\nplt.show()","0bad21b7":"fig = plt.subplots(figsize=(10,10))\npal = pal5\ndata1 = [len(profiles[profiles['cluster'] == 0]), len(profiles[profiles['cluster'] == 1]), \n        len(profiles[profiles['cluster'] == 2]), len(profiles[profiles['cluster'] == 3]),\n       len(profiles[profiles['cluster'] == 4])]\nlabels = ['0', '1', '2', '3', '4']\nplt.pie(data1, labels = labels, colors = pal, autopct='%.0f%%')\nplt.show()","b46c2016":"# preparing the dataframes for the exploration concerning further questions\ndata['cluster'] = profiles['cluster']\nprofiles['gender'] = data['Q2']\nprofiles['country'] = data['Q3']\nprofiles['occupation'] = data['Q5']","086b164c":"fig, axs = plt.subplots(2, 2, figsize=(19,15))\n\n# top ten professions by cluster\naxs[0, 0].set_title('Seasoned ML-Professionals')\naxs[0, 0].bar(data[profiles['cluster'] == 0].value_counts('Q5')[:10].index, data[profiles['cluster'] == 0].value_counts('Q5')[:10], color = palette)\naxs[0, 0].tick_params(labelrotation=45)\naxs[0, 0].grid(False)\n\naxs[0, 1].set_title('Seasoned Coders')\naxs[0, 1].bar(data[profiles['cluster'] == 1].value_counts('Q5')[:10].index, data[profiles['cluster'] == 1].value_counts('Q5')[:10], color = palette)\naxs[0, 1].tick_params(labelrotation=45)\naxs[0, 1].grid(False)\n\naxs[1, 0].set_title('Inexperienced with ML-Methods')\naxs[1, 0].bar(data[profiles['cluster'] == 2].value_counts('Q5')[:10].index, data[profiles['cluster'] == 2].value_counts('Q5')[:10], color = palette)\naxs[1, 0].tick_params(labelrotation=45)\naxs[1, 0].grid(False)\n\naxs[1, 1].set_title('Young Professionals')\naxs[1, 1].bar(data[profiles['cluster'] == 3].value_counts('Q5')[:10].index, data[profiles['cluster'] == 3].value_counts('Q5')[:10], color = palette)\naxs[1, 1].tick_params(labelrotation=45)\naxs[1, 1].grid(False)\n\nplt.tight_layout()","c4a517f1":"data['Q20'] = data['Q20'].fillna('No Answer')\n\nfig, axs = plt.subplots(2, 2, figsize=(19,15))\n\n# top ten industries by cluster\naxs[0, 0].set_title('Seasoned ML-Professionals')\naxs[0, 0].bar(data[profiles['cluster'] == 0].value_counts('Q20')[:10].index, data[profiles['cluster'] == 0].value_counts('Q20')[:10], color = palette)\naxs[0, 0].tick_params(labelrotation=45)\naxs[0, 0].grid(False)\n\naxs[0, 1].set_title('Seasoned Coders')\naxs[0, 1].bar(data[profiles['cluster'] == 1].value_counts('Q20')[:10].index, data[profiles['cluster'] == 1].value_counts('Q20')[:10], color = palette)\naxs[0, 1].tick_params(labelrotation=45)\naxs[0, 1].grid(False)\n\naxs[1, 0].set_title('Inexperienced with ML-Methods')\naxs[1, 0].bar(data[profiles['cluster'] == 2].value_counts('Q20')[:10].index, data[profiles['cluster'] == 2].value_counts('Q20')[:10], color = palette)\naxs[1, 0].tick_params(labelrotation=45)\naxs[1, 0].grid(False)\n\naxs[1, 1].set_title('Young Professionals')\naxs[1, 1].bar(data[profiles['cluster'] == 3].value_counts('Q20')[:10].index, data[profiles['cluster'] == 3].value_counts('Q20')[:10], color = palette)\naxs[1, 1].tick_params(labelrotation=45)\naxs[1, 1].grid(False)\n\nplt.tight_layout()","d7ee56df":"fig, axs = plt.subplots(figsize=(18,15))\n\nfig.suptitle('USD spent on ml-\/cloud computing services in the past 5 years by the team or the individual')\n\npal = palette\n\ndata0, label0 = data['Q26'][profiles['cluster'] == 0].value_counts().sort_index(), sorted(data['Q26'][profiles['cluster'] == 0].value_counts().index)\ndata1, label1 = data['Q26'][profiles['cluster'] == 1].value_counts().sort_index(), sorted(data['Q26'][profiles['cluster'] == 1].value_counts().index)\ndata2, label2 = data['Q26'][profiles['cluster'] == 2].value_counts().sort_index(), sorted(data['Q26'][profiles['cluster'] == 2].value_counts().index)\ndata3, label3 = data['Q26'][profiles['cluster'] == 3].value_counts().sort_index(), sorted(data['Q26'][profiles['cluster'] == 3].value_counts().index)\ndata4, label4 = data['Q26'][profiles['cluster'] == 4].value_counts().sort_index(), sorted(data['Q26'][profiles['cluster'] == 4].value_counts().index)\n\nax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\nax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\nax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\nax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\nax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n\nax1.pie(data0, labels = label0, colors = pal, autopct='%.0f%%')\nax1.set_title('Seasoned ML-Professionals')\nax2.pie(data1, labels = label1, colors = pal, autopct='%.0f%%')\nax2.set_title('Seasoned Coders')\nax3.pie(data2, labels = label2, colors = pal, autopct='%.0f%%')\nax3.set_title('Inexperienced with ML-Methods')\nax4.pie(data3, labels = label3, colors = pal, autopct='%.0f%%')\nax4.set_title('Young Professionals')\nax5.pie(data4, labels = label4, colors = pal, autopct='%.0f%%')\nax5.set_title('Students')\nplt.show()","7b4ee7a5":"profiles['gender'].iloc[profiles['gender'] == 'Nonbinary'] = 'NB'\nprofiles['gender'].iloc[profiles['gender'] == 'Prefer to self-describe'] = 'Self-described'\nprofiles['gender'].iloc[profiles['gender'] == 'Prefer not to say'] = 'Not disclosed'\n\nfig, axs = plt.subplots(figsize=(18,15))\n\nfig.suptitle('Gender')\n\npal = palette\nex = (0, 0.05, 0.2, 0.1, 0)\n\ndata0, label0 = profiles['gender'][profiles['cluster'] == 0].value_counts().sort_index(), sorted(profiles['gender'][profiles['cluster'] == 0].value_counts().index)\ndata1, label1 = profiles['gender'][profiles['cluster'] == 1].value_counts().sort_index(), sorted(profiles['gender'][profiles['cluster'] == 1].value_counts().index)\ndata2, label2 = profiles['gender'][profiles['cluster'] == 2].value_counts().sort_index(), sorted(profiles['gender'][profiles['cluster'] == 2].value_counts().index)\ndata3, label3 = profiles['gender'][profiles['cluster'] == 3].value_counts().sort_index(), sorted(profiles['gender'][profiles['cluster'] == 3].value_counts().index)\ndata4, label4 = profiles['gender'][profiles['cluster'] == 4].value_counts().sort_index(), sorted(profiles['gender'][profiles['cluster'] == 4].value_counts().index)\n\nax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\nax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\nax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\nax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\nax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n\nax1.pie(data0, labels = label0, explode = ex, colors = pal, autopct='%.0f%%')\nax1.set_title('Seasoned ML-Professionals')\nax2.pie(data1, labels = label1,explode = ex, colors = pal, autopct='%.0f%%')\nax2.set_title('Seasoned Coders')\nax3.pie(data2, labels = label2, explode = ex, colors = pal, autopct='%.0f%%')\nax3.set_title('Inexperienced with ML-Methods')\nax4.pie(data3, labels = label3, explode = ex, colors = pal, autopct='%.0f%%')\nax4.set_title('Young Professionals')\nax5.pie(data4, labels = label4, explode = ex, colors = pal, autopct='%.0f%%')\nax5.set_title('Students')\nplt.show()","a31c3f28":"fig, axs = plt.subplots(5, 3, figsize=(20,20))\n\npal = pal5\n\naxs[0, 0].set_title('India')\naxs[0, 0].pie(profiles['cluster'][profiles['country'] == 'India'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'India'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[0, 1].set_title('United States of America')\naxs[0, 1].pie(profiles['cluster'][profiles['country'] == 'United States of America'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'United States of America'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[0, 2].set_title('Japan')\naxs[0, 2].pie(profiles['cluster'][profiles['country'] == 'Japan'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Japan'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[1, 0].set_title('China')\naxs[1, 0].pie(profiles['cluster'][profiles['country'] == 'China'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'China'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[1, 1].set_title('Brazil')\naxs[1, 1].pie(profiles['cluster'][profiles['country'] == 'Brazil'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Brazil'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[1, 2].set_title('Russia')\naxs[1, 2].pie(profiles['cluster'][profiles['country'] == 'Russia'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Russia'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[2, 0].set_title('Nigeria')\naxs[2, 0].pie(profiles['cluster'][profiles['country'] == 'Nigeria'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Nigeria'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[2, 1].set_title('UK') \naxs[2, 1].pie(profiles['cluster'][profiles['country'] == 'United Kingdom of Great Britain and Northern Ireland'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'United Kingdom of Great Britain and Northern Ireland'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[2, 2].set_title('Pakistan')\naxs[2, 2].pie(profiles['cluster'][profiles['country'] == 'Pakistan'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Pakistan'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[3, 0].set_title('Egypt')\naxs[3, 0].pie(profiles['cluster'][profiles['country'] == 'Egypt'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Egypt'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[3, 1].set_title('Germany')\naxs[3, 1].pie(profiles['cluster'][profiles['country'] == 'Germany'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Germany'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[3, 2].set_title('Spain')\naxs[3, 2].pie(profiles['cluster'][profiles['country'] == 'Spain'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Spain'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[4, 0].set_title('Indonesia')\naxs[4, 0].pie(profiles['cluster'][profiles['country'] == 'Indonesia'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Indonesia'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[4, 1].set_title('Turkey')\naxs[4, 1].pie(profiles['cluster'][profiles['country'] == 'Turkey'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'Turkey'].value_counts().index), colors = pal, autopct='%.0f%%')\naxs[4, 2].set_title('France')\naxs[4, 2].pie(profiles['cluster'][profiles['country'] == 'France'].value_counts().sort_index(), labels = sorted(profiles['cluster'][profiles['country'] == 'France'].value_counts().index), colors = pal, autopct='%.0f%%')\nplt.show()","fe5219ba":"# loading data GDP per capita, ppp in 2018\ngdp_per_capita = pd.read_csv('..\/input\/gdp-per-capita-all-countries\/GDP.csv')\n\n# Making the country names compatible\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'Russian Federation'] = 'Russia'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'Egypt, Arab Rep.'] = 'Egypt'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'Iran, Islamic Rep.'] = 'Iran, Islamic Republic of...'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'United States'] = 'United States of America'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'Vietnam'] = 'Viet Nam'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'United Kingdom'] = 'United Kingdom of Great Britain and Northern Ireland'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'Hong Kong SAR, China'] = 'Hong Kong (S.A.R.)'\ngdp_per_capita['Country '].iloc[gdp_per_capita['Country '] == 'Korea, Rep.'] = 'South Korea'\n# ['Other', 'I do not wish to disclose my location', 'Taiwan'] were not included\n\np_country = pd.get_dummies(profiles, columns = ['cluster'])\np_country = p_country.groupby('country').mean()\ngdp_per_capita = gdp_per_capita.set_index('Country ')\ngdp_per_capita = gdp_per_capita[gdp_per_capita.index.isin(p_country.index)]\np_country['gdp_pc'] = np.nan\np_country['gdp_pc'] = gdp_per_capita ['2018']\np_country = p_country.dropna()","c814c20e":"fig, axs = plt.subplots(figsize=(20,15))\n\nfig.suptitle('GDP per capita, ppp in 2018 to the share of each cluster')\n\nax1 = plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\nax2 = plt.subplot2grid((2,6), (0,2), colspan=2)\nax3 = plt.subplot2grid((2,6), (0,4), colspan=2)\nax4 = plt.subplot2grid((2,6), (1,1), colspan=2)\nax5 = plt.subplot2grid((2,6), (1,3), colspan=2)\n\nax1.scatter(p_country['gdp_pc'], p_country['cluster_0'], color = \"#F62E97\")\nax1.set_title('Seasoned ML-Professionals')\nax2.scatter(p_country['gdp_pc'], p_country['cluster_1'], color = \"#F62E97\")\nax2.set_title('Seasoned Coders')\nax3.scatter(p_country['gdp_pc'], p_country['cluster_2'], color = \"#F62E97\")\nax3.set_title('Inexperienced with ML-Methods')\nax4.scatter(p_country['gdp_pc'], p_country['cluster_3'], color = \"#F62E97\")\nax4.set_title('Young Professionals')\nax5.scatter(p_country['gdp_pc'], p_country['cluster_4'], color = \"#F62E97\")\nax5.set_title('Students')\nplt.show()","fa85bbf0":"print('r and p-value')\nprint('Seasoned ML-Professionals: ' + str(pearsonr(p_country['gdp_pc'], p_country['cluster_0'])))\nprint('Seasoned Coders: ' + str(pearsonr(p_country['gdp_pc'], p_country['cluster_1'])))\nprint('Inexperienced with ML-Methods: ' + str(pearsonr(p_country['gdp_pc'], p_country['cluster_2'])))\nprint('Young Professionals: ' + str(pearsonr(p_country['gdp_pc'], p_country['cluster_3'])))\nprint('Students: ' + str(pearsonr(p_country['gdp_pc'], p_country['cluster_4'])))","169a2cb1":"Kaggle is a formidable platform with a great community, but who are the people who make up this platform? That's the question I wanted to answer with this notebook. I grouped the participants of this survey into 5 clusters by utilizing kmeans-clustering. The five types of Kagglers I found are the following:\n\n* Seasoned ML-Professionals\n* Seasoned Coders\n* Inexperienced with ML-Methods\n* Young ML-Professionals\n* Students\n\nThe clusters are based on a selection of discrete, ordinal and binary features. I further explored the clusters with regards to the occupation of Kagglers from the clusters, how much they or their team spends on ml- or cloud computing services, their gender and which type of Kagglers makes up which share of the respondents from the 15 countries with the most respondents. ","66e0f839":"**Seasoned ML-Professionals**\n\nThe most people belonging to this cluster are data scientists with 1074 individuals which is followed by research scientists with 549. This cluster has the largest share of research scientists with 16.67%.\n\n**Seasoned Coders**\n\nMost Kagglers from this cluster are software engineers. 482 of the participants belonging to this cluster answered with other.\n\n**Inexperienced with ML-Methods**\n\nThe largest group from this cluster is currently not employed with 1291 individuals 1226 answered with other. However there is a large group of data analysts and data scientist with 1106 and 850 respondents respectively. \n\n**Young Professionals**\n\nThe four largest groups in this cluster are data scientists with 1458, data analyst with 758, software engineer with 717 and machine learning engineer with 668.","b762de33":"**Usage of ML-Algorithms at the Workplace** \n\nThere isn't any usage of ML-Algorithms at the workplaces of people from cluster 4. Which is unsurprising as this cluster only contains students. Cluster 0 has the largest share of extensive use, which corresponds to the answer 'We have well established ML methods (i.e., models in production for more than 2 years)'. The Clusters 1 and 2 are both mostly made up of people who either don't know whether their company uses ml-methods or the company doesn't use any ml-algorithms. This share is 61% for cluster 1 and 79%. Cluster 3's share of people who report a moderate usage of m-methods at their company is 58%.","66ae6079":"**Cluster 0: Seasoned ML-Professionals**\n\nKagglers from cluster 0 are among the most experienced in coding and have the most experience in using ml-methods. They are highly educated with the largest share of doctors in their ranks. Their workplace uses ml-methods to the highest extend with a share of 38% of well-established ml-models. This Cluster account for 13% of the participants.\n\n**Cluster 1: Seasoned Coders**\n\nCluster 1 is the oldest. They're equally as experienced in coding as Kagglers from cluster 0 however they have generally less experience in using ml-methods. The workplace of 61% of these Kagglers either doesn't use ml-methods or the Kagglers don't know whether the workplace makes use of them. 13% of the participants belong to this cluster.\n\n**Cluster 2: Inexperienced with ML-Methods**\n\nA majority from this cluster doesn't work in a company where ml-methods are used, as 79% either don't know whether or not ml-methods are used at their company, or they reported that they aren't used. 983 out of 1032 participants who've never written code belong to this cluster. Those who work in data science are generally less experienced when it comes to the usage of ml-methods. \n\n**Cluster 3: Young ML-Professionals**\n\nCluster 3 consists of young adults who mostly work at companies, with a moderate usage of ml-methods. Kagglers of this type use a wide variety of ml-algorithms but have less experience than the 'Seasoned ML-Professionals'.\n\n**Cluster 4: Students**\n\nWe're students. There isn't much else to say.","0481fba8":"# Expenses for ML and Cloud Computing Services","278dbc6d":"**The Features:**\n* num_langs: The number of languages a Kaggler uses on a regular basis *(discrete)*\n* num_algs: The number of ml-algorithms an individual uses on a regular basis *(discrete)*\n* num_sources: The variety of sources a Kaggler uses *(discrete)*\n* age_class: The class corresponding to a Kagglers age *(ordinal)*\n* degree: Highest degree of a Kaggler or the highest degree the Kaggler will obtain in the next 2 years *(ordinal)*\n* years_coding_class: Variable describing how many years an individual has been coding *(ordinal)*\n* years_ml_class: Variable describing how many years an individual has been using ml-methods *(ordinal)*\n* student: Variable describing whether an individual is a student  *(binary)*\n* ml_used_at_job: How intensively does the workplace use ml-methods *(ordinal)*","15aa8f65":"**Number of Algorithms**\n\nKagglers from cluster 2 use the fewest ml-algorithms. 57% of users from cluster 2 use no ml-algorithm on a regular basis, another 15.84% use one ml-algorithm. The boxplots for clusters 1 and 4 generally follow the same shape with a 25th percentile of 0, a median of 1 and a 50th percentile of 3. Kagglers from these two clusters use a lower variety of algorithms than Kagglers from the clusters 0 and 3 but a larger variety than kagglers from cluster 2. Clusters 0 and 3 use the most algorithms and are in general very similar. 57.75% from cluster 3 and 58.26% from cluster 0 reported that they use between 3 and 5 different algorithms on a regular basis.\n\n**Number of Languages**\n\nThe median for the number of languages used on a regular basis by Kagglers from Cluster 2 is 2. 1186 Kagglers from this cluster don't use any programming language on a regular basis. This number was 1351 for all participants. Kagglers from the clusters 0 and 1 use the most programming languages on a regular basis. The median for cluster 0 is 3 languages, so is the mode and the arithmetic mean is 3.1938. The median for cluster 1 is also 3, the mode is 2 and the arithmetic mean is 2.9310.\n\n**Number of Sources**\n\nIndividuals from the clusters 0 and 3 use the largest variety of sources. The median for both clusters is 3 and the 25th percentile and 75th percentile are at 2 and 4 respectively.","b8a31bff":"**Gender by cluster**\n\nThe community is still predominantly male. The cluster with the lowest share of women are the seasoned ml-professionals, only 11% of this cluster are women. The situation when it comes to the seasoned coders isn't much different, since only 14% of this group are women. Young ml-professionals are also for the largest part male. The clusters for students and people who are inexperienced with ml-methods quite similar as both have a share of women of 23%.","fd5ac184":"**Relationship between GDP per capita, ppp in 2018 and a cluster's share of the respondents from this country**\n\nThere is a significant linear relationship between the share of each cluster and a country's GDP per capita. It's strong and positive for seasoned ml-professionals. It's moderately positive for seasoned coders. The shares for students, young professionals and inexperienced people are negatively correlated. There are two possible reason I can think of for the relationships. The first one is the negative relationship between birthrates and a country's wealth. The above observed relationships could be representative for a lack of young people who could become data analysts and data scientists in wealthy countries. The second reason I can think of is that this may represent different levels of maturity in each country's tech-sector. Nevertheless, this is still an interesting observation, despite my inability to properly explain it.","60125711":"# Introduction","9fe18eee":"**USD spent on ml-\/cloud computing services in the past 5 years by the team or the individual**\n\nSeasoned ML-Professionals have spent the most money with staggering 17% answering that they\/their team has spent at least 100,000 USD. 59% have spent at least 1000 USD. The contrary is true for the group that's inexperienced with ml-methods. 58% have reported that they or their team didn't spend money on ml-\/cloud computing services and overall 85% of them have spent less than 1000 USD.","098069c1":"# Getting the Features for KMeans-Clustering","14b11d1c":"# Conclusion\n\nI identified 5 distinct types of Kagglers. The first group are the Seasoned ML-Professionals. They are among the oldest Kagglers and have the most experience in machine learning. The most common occupation is 'Data Scientist' and the second most common is 'Research Scientist'. 17% of this type reported that they or their team have spent at least 100,000 USD on ml- and cloud computing services in the past 5 years. This cluster has the smallest share of women with only 11%. The group of Seasoned Coders is the oldest one and has similar experience in coding as the Seasoned ML-Professionals, yet they have little experience in machine learning. Most Kagglers belonging to this group are software engineers. They for a large part don't use ml-methods at their workplace as 61% reported that their company doesn't use ml-methods or they are unaware if their company does. The share of women is also very low with only 14%. The cluster for people who are inexperienced with ml-methods is rather heterogenous as the four most common answers regarding their occupation were that they're currently not employed, that their job can't be described by any of the options, that they work as data analysts or data scientist. Data analysts and data scientists from this group are generally less experienced in using ml-methods. This group is at the younger end of the spectrum. A relatively large share of this cluster is female with 23%. Young ML-Professionals are young adults who mostly work at companies, with a moderate usage of ml-methods. By far the most common job is data scientist, followed by data analyst, software engineer and machine learning engineer. The students are the youngest and fairly inexperienced. The share of women is 23%. It might be reasonable to have a look at accessibility of well-paid data science jobs for women. Another interesting observation is that the relative frequency of each type differs a lot across countries. This is correlated with a country's PPP adjusted GDP per capita. ","a3178753":"**Share of Students**\n\nCluster 4 only consists of students, whilst the other clusters almost exclusively consist of non-students. ","226e01e7":"**Age**\n\nCluster 0 and 1 are the oldest. Cluster 0's median age class is '40-44' and the mode is '30-34'. Cluster one is older with a median age class of '45-49' and a mode of '40-44'. Whilst Cluster 4 is the youngest both the median and the mode are at '18-21'. 66.95% of Cluster 3 are at max 29 years old and 84.57% are under 35.\n\n**Years a Kaggler has been Coding**\n\nKagglers from cluster 0 have been mostly coding for '10-20 years', as that's both the median and mode. The same applies to cluster 1. Both the median and mode for cluster 2 are '< 1 year'. Cluster 2 also includes almost all of the users who've never written any code, 983 out of 1032 Kagglers who've never written code. Kagglers from Cluster 4 have a little bit more experience as their mode and median is '1-3 years'. The mode and median for cluster 3 are the same as for cluster 4, however the classes 'I've never written code', '< 1 years' and '1-3 years' make up 55.30% of cluster 3 and 78.92% of cluster 4. So, it can be said that cluster 4 is generally more experienced in writing code.\n\n**Years a Kaggler has been using ML-Methods**\n\nThe biggest difference between cluster 0 and 1 can be found when we look at their experience with machine learning methods. 53.40% of Kagglers from cluster 1 have less than one year of experience with ml-methods. The median for cluster 0 is '4-5 years' and the mode is '5-10 years'. In fact, 48% from this cluster belong to the classes '5-10 years' and upwards.","a47227b8":"**Highest Degree**\n\nCluster 0 is highly educated with 46% master\u2019s degrees and 41% doctorates making for a combined share of 87%. Cluster 1 has the second largest share of doctorates with 20%. It's share of bachelor\u2019s degrees is with 24% larger than the share for cluster 0 but it's smaller than in all the other clusters. Clusters 2 and three mostly consist of people with bachelor's and master\u2019s degrees. The share of master\u2019s degrees is larger in cluster 3 with 48% and the share of bachelor degrees is larger in cluster 2 with 44%. Cluster 4 has the largest share of people who've had\/will have some form of college\/uni education without a degree with 12%. Cluster 4 bachelor\u2019s degrees make up the majority of this cluster with 53%.","b3cab60c":"# KMeans","9b8b3d50":"# Exploring the Clusters","889f7761":"# Occupation and Industry","4eeabd3f":"# Gender","bfacd56f":"# Naming the Clusters","4d68282f":"# Clusters by Country"}}