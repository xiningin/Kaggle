{"cell_type":{"d26ecf49":"code","6c2a5b71":"code","0f6599bd":"code","cc2dd216":"code","3b430fab":"code","ec789ddc":"code","8ccc7222":"code","779ce259":"code","d569ed78":"code","d3d364bd":"code","55ed20de":"code","99a93085":"code","a0f55259":"code","9f29cf98":"code","850ecef1":"code","2f28c66b":"code","1b1b1692":"markdown","17812612":"markdown","b2f75c38":"markdown"},"source":{"d26ecf49":"#import libraries files\nimport pandas as pd\nimport numpy as np","6c2a5b71":"data = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv',encoding= 'latin-1')\ndata.head()","0f6599bd":"#Drop NAN Value\n\ndata.dropna(inplace=True, axis=1)","cc2dd216":"#Change Columns Name\n\ndata.columns = ['label', 'message']\ndata.head()","3b430fab":"data.describe().transpose()","ec789ddc":"#Let's make a new column to detect how long the text messages are:\ndata['length'] = data['message'].apply(len)\ndata.head()","8ccc7222":"import matplotlib.pyplot as plt\n\nbins = 1.15**(np.arange(0,50))\nplt.hist(data[data['label']=='ham']['length'],bins=bins,alpha=0.8)\nplt.hist(data[data['label']=='spam']['length'],bins=bins,alpha=0.8)\nplt.legend(('ham','spam'))\nplt.show()","779ce259":"from sklearn.model_selection import train_test_split\n\nX = data['message']\ny= data['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30, random_state=11)\nX_train.shape","d569ed78":"\n#Data Preprocessing for tokinezer and Stopwords data filtering\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nCount_Vec = CountVectorizer()\n\nX_train_counts = Count_Vec.fit_transform(X_train)","d3d364bd":"X_train_counts.shape","55ed20de":"#TF-IDF\n\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\ntfv = TfidfTransformer()\n\nX_train_tfidf = tfv.fit_transform(X_train_counts)\n","99a93085":"# If you not use CountVectorizer and TfidfTransformer the Use TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer()\n\nX_train_Vect = tfidf.fit_transform(X_train)","a0f55259":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\n\ntext_clf = Pipeline([('tfidf',TfidfVectorizer()), ('clf', SVC()),])\ntext_clf.fit(X_train, y_train)","9f29cf98":"pred = text_clf.predict(X_test)","850ecef1":"from sklearn import metrics\nprint(metrics.confusion_matrix(y_test,pred))","2f28c66b":"print(metrics.classification_report(y_test, pred))","1b1b1692":"**Ham Spam Classification Using Classic NLP**","17812612":"**Data Preprocessing**","b2f75c38":"**If you not use CountVectorizer and TfidfTransformer then you can use TfidfVectorizer**"}}