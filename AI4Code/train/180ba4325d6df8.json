{"cell_type":{"a7db76f2":"code","5d09689d":"code","d8059180":"code","63d12d19":"code","62a9ce4a":"code","7f963657":"code","e5ad749d":"code","ba458f4b":"code","9a5e3e9d":"code","c3263c9e":"code","d180a9ad":"code","2a3d1754":"code","54d19423":"code","16108a28":"code","f10831b1":"code","a5d66515":"code","5a46de3b":"code","42f35cf1":"code","aac39dda":"markdown","0fcd334c":"markdown","6297af88":"markdown","d1bddcde":"markdown","49a0b050":"markdown","97cbfb2c":"markdown","eb4aa292":"markdown","ed5ed813":"markdown","420004f4":"markdown","58e9e103":"markdown","1802067f":"markdown","f1e05896":"markdown","fa674296":"markdown","324dfa21":"markdown","72f3fadd":"markdown","f1066bda":"markdown","c0745622":"markdown","4295d5c6":"markdown","baa8027a":"markdown","1df330a1":"markdown"},"source":{"a7db76f2":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras import layers\nimport time","5d09689d":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n\nprint(train_images.shape)","d8059180":"fig = plt.figure(figsize=(6,6))\n\nfor i in range(9):\n    fig.add_subplot(3,3,i+1)\n    plt.imshow(train_images[312*i],cmap=\"gray\")\n    plt.axis(\"off\")\n\nplt.show()","63d12d19":"# 1x784 to 28x28 \ntrain_images = train_images.reshape(-1,28,28,1).astype(\"float32\")\n\n# scaling between -1 and 1\ntrain_images = (train_images-127.5) \/ 127.5\n\ntrain_images.shape","62a9ce4a":"BUFFER_SIZE = 60000\nBATCH_SIZE = 128\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n","7f963657":"# Generator Model\n\ndef make_generator():\n    \"\"\"\n    This function returns generator model\n    \"\"\"\n    model = tf.keras.models.Sequential()\n    # This model will take 100x1 random noise (seed) as input\n    model.add(layers.Dense(7*7*256,use_bias=False,input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    # Reshaping \n    model.add(layers.Reshape((7,7,256)))\n    assert model.output_shape == (None,7,7,256) # None is batch size\n    \n    model.add(layers.Conv2DTranspose(128,(5,5),strides=(1,1),padding=\"same\",use_bias=False))\n    assert model.output_shape == (None,7,7,128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding=\"same\",use_bias=False))\n    assert model.output_shape == (None,14,14,64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(1,(5,5),strides=(2,2),padding=\"same\",use_bias=False))\n    # We've used 1 as channel size because our digits are grayscale.\n    # You can use 3 channel size in your RGB projects.\n    assert model.output_shape == (None,28,28,1)\n    \n    return model","e5ad749d":"generator = make_generator()\n# Let's use this untrained generator\n\nnoise = tf.random.normal([1,100])\nbullshit_image = generator(noise,training=False)\nplt.imshow(bullshit_image[0,:,:,0],cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()\n","ba458f4b":"def make_discriminator():\n    \n    model = tf.keras.models.Sequential()\n    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding=\"same\",input_shape=(28,28,1)))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding=\"same\"))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Flatten())\n    \n    # Real or fake\n    model.add(layers.Dense(1))\n    \n    return model","9a5e3e9d":"discriminator = make_discriminator()\n","c3263c9e":"decision = discriminator(bullshit_image)\nprint(decision)","d180a9ad":"# we'll use cross entropy loss \ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output,fake_output):\n    # ones_like => Creates a tensor of all ones that has the same shape as the input.\n    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n    # zeros_like => Creates a tensor of all zeros that has same shape as the input\n    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","2a3d1754":"def generator_loss(fake_output):\n    # We've labeled fake outputs as one because generator will try to fool discriminator\n    return cross_entropy(tf.ones_like(fake_output),fake_output)","54d19423":"# Learning rate ==> 1e-4 ===> 0.0001\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","16108a28":"import os\ncheckpoint_dir = \".\/\"\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator\n                                )","f10831b1":"EPOCHS = 50\nnoise_dim = 100\n\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE,noise_dim])\n    \n    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:\n        \n        generated_images = generator(noise,training=True)\n        \n        real_output = discriminator(images,training=True)\n        fake_output = discriminator(generated_images,training=True)\n        \n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output,fake_output)\n        \n    gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n    \n    generator_optimizer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))","a5d66515":"def train(dataset,epochs):\n    \n    for epoch in range(epochs):\n        start = time.time()\n        \n        for image_batch in dataset:\n            train_step(image_batch)\n            \n        # save model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n        \n        print(\"\"\"Epoch {}\/{} is finished, process time {} seconds.\n        =============================================================\"\"\".format(epoch+1,epochs,(time.time()-start)))\n            \n            ","5a46de3b":"train(train_dataset,EPOCHS)","42f35cf1":"test_noise = tf.random.normal([9,100])\nnew_images = generator(test_noise,training=False)\n\nfig = plt.figure(figsize=(6,6))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.axis(\"off\")\n    plt.imshow(new_images[i,:,:,0] * 127.5 + 127.5,cmap=\"gray\")\n\n    ","aac39dda":"These digist are not in the dataset, we generated it !!!!","0fcd334c":"# The Generator and The Discriminator\nIn this section I am going to create generator and discriminator. I will start with generator.","6297af88":"* Let's create a generator using this function.","d1bddcde":"* Now we'll scale images between -1 and 1, like tanh function.","49a0b050":"* Our losses are ready, let's create optimizer. \n* As optimizer, we will use Adam.","97cbfb2c":"## Saving checkpoints","eb4aa292":"# Generating Digits \nIn this section we'll generate some digits.","ed5ed813":"Discriminator loss is ready, let's create generator loss.","420004f4":"# Importing Libraries and Load The Data\nIn this section I am going to import the libraries that we need and load the data. \n\nIn this kernel I will use Keras (Tensorflow backend)","58e9e103":"* First, I'll define train_step function.","1802067f":"* Everything is ready, now we can train our GANs. I feel very excited, what about you?","f1e05896":"* Looks like random noise :))\n\nOur generator is ready, but still we need a discriminator, discriminator is easier than generator, it is a CNN based classifier. Let's create it.","fa674296":"* Let's use this untrained discriminator in order to detect whether generated image real or not.","324dfa21":"# Conclusion\nThanks for your attention, if you have any question in your mind, please ask, I will definetely return.\n\nTutorial from tensorflow docs: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan\n","72f3fadd":"* Our data is ready, last step is shuffling and batching the data.","f1066bda":"# Training Model\nIn this section I am going to train our GANs model. ","c0745622":"* There are 60K images in MNIST dataset's train set.\n* Let's check some random sample","4295d5c6":"# Loss Functions and Optimizers\nIn this section I am going to define loss functions and optimizers of the networks.","baa8027a":"* I know, it looks a bit confusing but I will explain as much as I can.\n\n1. This function takes one batch image\n1. First we've created a random noise, we'll use this random noise when we generate image using generator.\n1. Then, we've generated images using random noise.\n1. We've sent real images to discriminator and took decisions of discriminator\n1. We've sent fake images (generated images) to discriminator as well and took decisions of discriminator.\n\n1. Using this decisions, we've computed gen_loss and disc_loss.\n1. And thanks to this lossess we've computed gradients of generator and discriminator, now we can update our model using these gradients\n1. Finally we've updated our generator and optimizer.\n\nI hope I can explain everything clear. Let's move on.","1df330a1":"# Introduction\nHello people, welcome to this kernel. In this kernel I am going to generate digits using MNIST dataset and DCGANs (Deep Convolutional Generative Adverserial Networks) structure.\n\nBefore starting, let's take a look at the content of this kernel\n\n# Notebook Content\n1. What is GANs\n1. Importing Libraries and Loading Data\n1. The Generator and The Discriminator\n1. Loss Functions and Optimizers\n1. Training Model\n1. Generating Digits\n1. Conclusion\n\n\n# What is GANs\nGANs is a structure that generates data similar to the dataset. In general, GANs are to be used with image dataset and texts. As you can understand from the name of GANs, it includes more than one networks.\n\nFirst network's name is Generator, it generates images using a random noise (random numbers with shape 100,) \n\nSecond network's name is Discriminator, it tries to understand whether picture that came to it real or fake.\n\nIn Generator model, we'll use Convolutional 2D Transpose layers, thanks to this layers we can upsample the data. And in Discriminator, we will use classic Convolutional 2D Layer.\n\nIn both, we will use LeakyReLU as activation function and binary crossentropy as loss function. We will use LeakyReLU because it solves vanishing gradient problem.\n\nI've explained everything, now let's take a look at the diagram below\n\n![image.png](attachment:image.png)\n"}}