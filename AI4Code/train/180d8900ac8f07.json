{"cell_type":{"3122de93":"code","3549e70b":"code","b8684e05":"code","a885aae0":"code","d7b7b2e4":"code","4c591ce3":"code","6c83288b":"code","70f5b28c":"code","69736669":"code","4dc4c359":"code","4f1ff03d":"code","7ca70b12":"code","feadb8c7":"code","bdc18ac4":"code","aff7d54b":"code","282866fb":"code","b267c6a5":"code","7837a94f":"code","1fb96618":"code","b317ca3c":"code","eab90094":"code","67a3f8e1":"code","a1bfacf6":"code","82d8382a":"code","a6dcbc1c":"code","1a7c018a":"code","3c3cacbe":"code","3dd1d241":"code","124bdc83":"code","30d9c59a":"code","1b94f865":"code","86a17e77":"code","90bda7d9":"code","0839718c":"code","313fdb50":"code","7cafff72":"code","35ab78e3":"code","40aabd16":"code","9886b6ca":"code","18f00b05":"code","eebd814d":"code","dbf8c713":"code","e2beeaf8":"code","2193eaa2":"code","5e43d2d7":"markdown","3c465116":"markdown","49447d36":"markdown","313450c4":"markdown","08327218":"markdown","df7697f3":"markdown","5befd613":"markdown","86ba2736":"markdown","9c1d9c53":"markdown","71f3d14a":"markdown","79e2b2f0":"markdown","23a2006d":"markdown"},"source":{"3122de93":"#importing required libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# import plotly.express as px ## gives weired result during model.fit() hence not used\n\nimport tensorflow as tf\n\nfrom keras import Sequential #to create the model arcitecture\nfrom keras.applications import VGG16,VGG19,ResNet50,ResNet101,Xception,InceptionV3,MobileNet,MobileNetV2 #all pretrained models \n#                                     Follow : https:\/\/keras.io\/api\/applications\/ for all documentation\nfrom keras.layers import Dense, Input, Dropout, Flatten \nfrom keras.optimizers import Adam,SGD #optimizers\nfrom keras.callbacks import ReduceLROnPlateau #to reduce learning rate\nfrom keras.preprocessing.image import ImageDataGenerator #Image data generator to generate data of various specification to del with overfitting\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3549e70b":"#to check if gpu is available or not\nprint('GPU is available !!!' if tf.config.list_physical_devices('GPU') else 'GPU is not available')\n\n#GPU \ntf.config.list_physical_devices('GPU')","b8684e05":"#https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator\n\ndatagen_train = ImageDataGenerator(rescale = 1.0\/255,  # Ar RGB colors are presented in 0-155 range (1 pixel = 8 bits, since each bit can be 1 or 0, 8 bits info 2^8 = 256 , 0-255 , total 256)\n                            horizontal_flip = True,\n                            vertical_flip = True,\n                             zoom_range = 0.2,\n                             shear_range = 0.2,\n                             width_shift_range = 0.2,\n                             height_shift_range = 0.2,\n                             fill_mode = 'nearest'\n                             \n                            ) \n\ndatagen_val = ImageDataGenerator(rescale = 1.0\/255 ) # we dont have other parameters as the model will predict on these images during vaidation\n\ndatagen_pred = ImageDataGenerator(rescale = 1.0\/255 ) # we dont have other parameters as the model will predict on these images during prediction\n\ntrain_DIR = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/\"\nval_DIR = \"\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/\"\npred_DIR = \"\/kaggle\/input\/intel-image-classification\/seg_pred\/\" \n\n\"\"\" we are not using seg_pred\/seg_pred\/ as datagen requires images to be present inside a folder of certain label.\nBut in target folder we have all images inside a single folder 'seg_pred'. hence we are using seg_pred instead of seg_pred\/seg_pred\/\n\n\"\"\"\n# Follow this link : https:\/\/studymachinelearning.com\/keras-imagedatagenerator-with-flow_from_directory\/\n# Follow this link : https:\/\/medium.com\/@vijayabhaskar96\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n                                                            \n\nbatch_size = 32\nimage_size = (150,150) #we are converting all images from the directory to this shape as our models need input of constant shape\n\ntrain_datagen = datagen_train.flow_from_directory(train_DIR,\n                                                 batch_size = batch_size,\n                                                 target_size = image_size,\n                                                  class_mode = 'categorical',\n                                                  color_mode = 'rgb',\n#                                                   seed = 101\n                                                 )\nval_datagen = datagen_val.flow_from_directory(val_DIR,\n                                             batch_size = batch_size,\n                                             target_size = image_size,\n                                             class_mode = 'categorical',\n                                             color_mode ='rgb',\n#                                              seed = 110\n                                             )\npred_datagen = datagen_pred.flow_from_directory(pred_DIR,\n                                               batch_size = 1, # as we want all images in one batch during prediction\n                                               target_size = image_size,\n                                                class_mode = None, # to return only image\n                                               color_mode ='rgb',\n#                                                seed = 150\n                                               ) \n","a885aae0":"#class lables in train dataset\ntrain_datagen.class_indices\n","d7b7b2e4":"# validation classes\nval_datagen.class_indices","4c591ce3":"#mapping encoded values to class labels\nlabels = train_datagen.class_indices\nlabels = dict((v,k) for k,v in labels.items())\nlabels # now we have encoded values as keys and class name as valaues. This helps during decoding the predicition","6c83288b":"#plotting some images from image generator https:\/\/www.analyticsvidhya.com\/blog\/2020\/08\/image-augmentation-on-the-fly-using-keras-imagedatagenerator\/\n\nfig,ax = plt.subplots(nrows=1,ncols=5,figsize=(16,16))\n\n\nfor i in range (5):\n    \n    image = next(train_datagen)[0][0] # getting images\n    \n    image = np.squeeze(image) # changing size from (1, 200, 200, 3) to (200, 200, 3) for plotting the image\n    \n    ax[i].imshow(image)\n    ax[i].axis('off')","70f5b28c":"# Hyperparameters:\n\n\ninput_shape = (150,150,3)\nbatch_size = 32\nlr = 0.001\nn_class = 6\nepochs =20\nadam = Adam(lr = lr, beta_1 = 0.9, beta_2 =0.999,amsgrad =False,epsilon =1e-7)\n\n","69736669":"#ReduceLROnPlateau to reduce LR : https:\/\/keras.io\/api\/callbacks\/reduce_lr_on_plateau\/\n\nlrr = ReduceLROnPlateau(monitor = 'val_acc',\n                       patience = 1,\n                       factor =0.25,\n                        min_lr = 0.000003,\n                        verbose =1\n                       )","4dc4c359":"#Creating early stopping callback\nfrom  keras.callbacks import EarlyStopping\nearly_stopping =EarlyStopping(monitor = 'val_accuracy', patience=3) #stop the training process if there is no change in val_accuracy for 3 rounds","4f1ff03d":"#instatiating the model\nvgg16 = VGG16(include_top = False,input_shape = input_shape,\n                  weights='imagenet',\n                  classes = n_class)\n\n# #we are freezing all layers and training only fully connected layers\n# for layer in vgg16.layers:\n#     layer.trainable =False","7ca70b12":"#creating a function to build the FC by taking the base model and return the final model\n\ndef build_model(base_modelx):\n    \n    for layer in base_modelx.layers:\n        layer.trainable = False\n    \n    model = Sequential(base_modelx)\n    model.add(Flatten())\n    model.add(Dense(1024,activation ='relu'))\n#     model.add(Dropout(0.3))\n    model.add(Dense(512,activation = 'relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(256,activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(128,activation = 'relu'))\n    model.add(Dropout(0.15))\n    model.add(Dense(n_class,activation='softmax'))\n    \n    print(model.summary())\n    \n    model.compile(loss = 'categorical_crossentropy',optimizer = adam,metrics =['acc'])\n    \n    return model\n    \n    ","feadb8c7":"model = build_model(vgg16)\n","bdc18ac4":"#itting the model\nmodel.fit(train_datagen,\n          epochs = epochs,\n          validation_data = val_datagen,\n          verbose =1,\n          callbacks =[lrr,early_stopping]\n         )","aff7d54b":"# model.history.history","282866fb":"# len(model.history.history['acc'])","b267c6a5":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","7837a94f":"vgg19 = VGG19(include_top = False, weights ='imagenet', input_shape = input_shape,\n                   classes =n_class)\n\n  \nmodel = build_model(vgg19)","1fb96618":"#itting the model\nmodel.fit(train_datagen,\n          epochs = epochs,\n          validation_data = val_datagen,\n          verbose =1,\n          callbacks =[lrr,early_stopping]\n         )","b317ca3c":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","eab90094":"resnet50 = ResNet50(include_top = False, weights ='imagenet',\n                   input_shape = input_shape,\n                   classes = n_class)\nmodel = build_model(resnet50)","67a3f8e1":"model.fit(train_datagen, epochs = epochs,\n         validation_data = val_datagen,\n         verbose =1,\n         callbacks =[lrr,early_stopping])","a1bfacf6":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","82d8382a":"resnet101 = ResNet101(include_top = False, weights = 'imagenet',\n                      input_shape = input_shape,\n                     classes =n_class)\nmodel = build_model(resnet101)","a6dcbc1c":"model.fit(train_datagen,epochs = epochs,\n         validation_data = val_datagen,\n         verbose =1,\n         callbacks = [lrr,early_stopping])","1a7c018a":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","3c3cacbe":"xception = Xception(include_top = False, weights = 'imagenet',\n                    input_shape = input_shape,\n                    classes = n_class)\n\nmodel = build_model(xception)","3dd1d241":"model.fit(train_datagen, epochs = epochs,\n         validation_data = val_datagen,\n         verbose =1,\n         callbacks = [lrr,early_stopping])","124bdc83":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","30d9c59a":"inception = InceptionV3(include_top= False, weights = 'imagenet',\n                       input_shape = input_shape,\n                       classes = n_class) \nmodel = build_model(inception)","1b94f865":"model.fit(train_datagen, epochs = epochs,\n           validation_data = val_datagen,\n           verbose = 1,\n           callbacks = [lrr,early_stopping])","86a17e77":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","90bda7d9":"mobilenetv2 = MobileNetV2(include_top= False, weights = 'imagenet',\n                       input_shape = input_shape,\n                       classes = n_class) \nmodel = build_model(mobilenetv2)","0839718c":"model.fit(train_datagen, epochs = epochs,\n           validation_data = val_datagen,\n           verbose = 1,\n           callbacks = [lrr,early_stopping])","313fdb50":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","7cafff72":"mobilenet = MobileNet(include_top= False, weights = 'imagenet',\n                       input_shape = input_shape,\n                       classes = n_class) \nmodel = build_model(mobilenet)","35ab78e3":"model.fit(train_datagen, epochs = epochs,\n           validation_data = val_datagen,\n           verbose = 1,\n           callbacks = [lrr,early_stopping])","40aabd16":"#Ploting acc and loss\nresults = pd.DataFrame({'epochs':list(range(1,epochs+1)),'Training_acc':model.history.history['acc'],'Validation_acc':model.history.history['val_acc'],\n                      'Training_loss':model.history.history['loss'],'Validation_loss':model.history.history['val_loss']})\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_acc', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_acc', data = results, color='blue' )\nplt.title('Training Accuracy vs Validation Accuracy')\nplt.show()\n\nplt.figure(figsize=(12,5))\nsns.lineplot(x = 'epochs', y ='Training_loss', data = results, color='r' )\nsns.lineplot(x = 'epochs', y ='Validation_loss', data = results, color='blue' )\nplt.title('Training Loss vs Validation Loss')\nplt.show()","9886b6ca":"#Prediction:\npreds = model.predict(pred_datagen)\npreds[0:5,:]","18f00b05":"# preds[1]","eebd814d":"#get the indices\npred_class_indices = np.argmax(preds,axis=1)\npred_class_indices[0:26]","dbf8c713":"#get the name of the label\nlabel_names = [labels[k] for k in pred_class_indices]\nlabel_names[0:26]","e2beeaf8":"# plt.imshow(np.squeeze(pred_datagen[19]))","2193eaa2":"# lets check those images\nn=25\n\n# setup the figure \nplt.figure(figsize=(20,20))\n\nfor i in range(n):\n#     print(i)\n    ax = plt.subplot(5, 5, i+1)\n    plt.imshow(np.squeeze(pred_datagen[i]))","5e43d2d7":"This is image data of Natural Scenes around the world.\n\nContent\n* This Data contains around 25k images of size 150x150 distributed under 6 categories.\n* {'buildings' -> 0,\n'forest' -> 1,\n'glacier' -> 2,\n'mountain' -> 3,\n'sea' -> 4,\n'street' -> 5 }\n\n* The Train, Test and Prediction data is separated in each zip files. There are around 14k images in Train, 3k in Test and 7k in Prediction.\n\n* If you check the directory under input (check the top right portion of this notebook), you can see that images are placed inside their respective classes. Separate class label csv file is not given.\n* So we have two choices \n        1. Load images directly from ImageDataGenerator.flow_from_directory\n        2. Create a function to load images from directory and create a list for class lables \n        \nWe are going with option 1 in this notebook.","3c465116":"### VGG19","49447d36":"## Model Building:\n\n* We are creating different models VGG16,VGG19,ResNet50,ResNet101,Xception,InceptionV3 \n* The arcitecture for fully connceted layer will be same for all these model (easy comparison)\n* I have run these models using different arcitectures and this arcitecture gave good result (You can try with different arcitecures also)","313450c4":"### Resnet50","08327218":"### MobileNet:","df7697f3":"### Our model has failed to classify some images correctly. We need to tune our model to get better classification. \n\n## I hope that you like my work.Please upvote this notebook. \n# Happy Learning :)","5befd613":"### InceptionV3","86ba2736":"### Resnet101\n","9c1d9c53":"### Xception","71f3d14a":"### MobileNetV2:","79e2b2f0":"### Special Thanks to:\n1. Aditya Naresh : https:\/\/www.kaggle.com\/recursion17\/intel-image-classification-92-accuracy\n2. Vijayabhaskar J: https:\/\/medium.com\/@vijayabhaskar96\/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n3. Bhavika Kanani : https:\/\/studymachinelearning.com\/keras-imagedatagenerator-with-flow_from_directory\/","23a2006d":"### Prediction:\n* I am using mobilenet to predict. Here we have to select te best model to do the prediction. The whole method of predicting on the test data will be same.\n* Please name model_vgg16 or model_resnet for each models, so that finally we can indentify the model with best score easily."}}