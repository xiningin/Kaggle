{"cell_type":{"5e1da987":"code","60d333a8":"code","d0a8f6cb":"code","4bcbbfb5":"code","11e1f412":"code","1808f18a":"code","3bba06eb":"code","40490634":"code","09a2ea44":"code","ed90d72e":"code","3b63f229":"code","a10b0d93":"code","4fb7bbde":"code","02f236b4":"code","65fc6ae6":"code","8ba53867":"code","c2583c65":"code","3993e42f":"code","d980b913":"code","90a04797":"code","42ac66c0":"code","74335d96":"code","c5342073":"code","a46c9a22":"code","c3ef29f3":"code","e4d0dd39":"code","a80ce98d":"code","ef0c26be":"code","6edb65c8":"code","fd62ec1c":"code","d5280180":"code","4fa4170c":"code","db3233e1":"code","758e43ec":"code","744fdd97":"code","baf16854":"code","659d9906":"code","6c540073":"code","51aee847":"code","93a6241c":"code","7286232d":"code","fb6930f7":"code","db7852ea":"code","fa267abc":"code","7161a17b":"code","a09e663f":"code","9aa473ca":"code","57d8a203":"code","0dfc1d29":"code","d2368bb4":"code","ce054d4a":"code","eaa1c119":"code","045d63a1":"code","934ac08d":"code","0bbb6c63":"markdown","27d83e68":"markdown","e84133db":"markdown","bb2bd628":"markdown","bd6ab579":"markdown","7434bfd8":"markdown","e9bab8d3":"markdown","740253f6":"markdown","fd8cd235":"markdown","4e922961":"markdown","8ed14a59":"markdown","6a9e581b":"markdown","afaeeaa7":"markdown"},"source":{"5e1da987":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_rows', 30)","60d333a8":"raw_data = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\nraw_data.head()","d0a8f6cb":"print ('Rows:', raw_data.shape[0])\nprint ('Columns:', raw_data.shape[1])\nprint ('Missing Values:',raw_data.isnull().sum().values.sum())\nprint ('Numerical Columns:', raw_data.describe().columns.values.shape[0])\nprint ('Categorical Columns:', raw_data.shape[1] - raw_data.describe().columns.values.shape[0])\nprint ('Unique Values:\\n', raw_data.nunique())","4bcbbfb5":"\n#Display all columns\n##Type of Total Charges is String, Converting to int after converting null values from TotalCharges to numpy null\n\ntype(raw_data['TotalCharges'][0])\nraw_data['TotalCharges'] = raw_data['TotalCharges'].replace(' ', np.NaN)\nraw_data['TotalCharges'] = raw_data['TotalCharges'].astype(float)\n\n#Dropping null rows from total charges\nraw_data = raw_data.dropna()\n\nraw_data = raw_data.reset_index(drop=True)\n","11e1f412":"\ncategorical_columns_with_2_categories = [ 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n        'PhoneService','PaperlessBilling']\n\ncategorical_columns_with_3_categories = [  'MultipleLines', 'InternetService',\n       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract']\n\ncategorical_columns_with_4_categories=['PaymentMethod']\n\n###Below code used to  check what are the categories, and whether we need to modify some of them or not\nprint('2 categories:')\nfor i in categorical_columns_with_2_categories:\n    print( i , raw_data[i].unique(),'\\n')\n\nprint('\\n3 categories:')\nfor i in categorical_columns_with_3_categories:\n    print( i , raw_data[i].unique(),'\\n')   \n\nprint('\\n4 categories:')\nfor i in categorical_columns_with_4_categories:\n    print( i , raw_data[i].unique(),'\\n')     \n\n","1808f18a":"print('Checking if there are any null rows in Categorical columns\\nActual rows:', raw_data.shape[0])\nfor i in categorical_columns_with_2_categories:\n    print('Not null rows in ', i ,':',raw_data[i][raw_data[i]==raw_data[i].unique()[0]].count() + raw_data[i][raw_data[i]==raw_data[i].unique()[1]].count())\n\nfor i in categorical_columns_with_3_categories:\n    print('Not null rows in ', i ,':',raw_data[i][raw_data[i]==raw_data[i].unique()[0]].count() + raw_data[i][raw_data[i]==raw_data[i].unique()[1]].count() + raw_data[i][raw_data[i]==raw_data[i].unique()[2]].count())\n\nfor i in categorical_columns_with_4_categories:\n    print('Not null rows in ', i ,':',raw_data[i][raw_data[i]==raw_data[i].unique()[0]].count() + raw_data[i][raw_data[i]==raw_data[i].unique()[1]].count() + raw_data[i][raw_data[i]==raw_data[i].unique()[2]].count() + raw_data[i][raw_data[i]==raw_data[i].unique()[3]].count())\n    ","3bba06eb":"raw_data_1 = raw_data.copy()","40490634":"raw_data_1 = raw_data.drop('customerID',axis =1)","09a2ea44":"#Replacing 'No internet service' with 'No'\ncolumns_1 = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies']\n\nfor i in columns_1:\n       raw_data_1[i]=raw_data_1[i].replace('No internet service','No')\n\ncolumns_2 = ['MultipleLines']\nfor i in columns_2:\n       raw_data_1[i]=raw_data_1[i].replace('No phone service','No')\n        \ncolumns_3 = ['Churn']\nfor i in columns_3:\n    raw_data_1[i]=raw_data_1[i].replace('Yes',1)\n    raw_data_1[i]=raw_data_1[i].replace('No',0)","ed90d72e":"\n\n##Confirming whether replacement was successfull or not\nfor i in categorical_columns_with_3_categories:\n    print( i , raw_data_1[i].unique(),'\\n') ","3b63f229":"##When we look at tenure, total unique values are 72 in record of 7032, so it is a categorical number hidden under numbers, if taken as quantitatively it will distrub our model\n##As there are 72 unique values in tenure, so we can not create each column of OHE for tenure, so we will create groups based on tenure and later create OHE based on those groups.\n##using Sorted function to check whether there are any missing values\n#sorted(raw_data_1['tenure'].unique())","a10b0d93":"temp_c = ['SeniorCitizen']\n##Creating Categories for Senior Citizen under YES and NO it will make extraction of dummies easier later on\nfor i in temp_c:\n    raw_data_1[i]=raw_data_1[i].replace(1,'Yes')\n    raw_data_1[i]=raw_data_1[i].replace(0,'No')","4fb7bbde":"raw_data_1.head()\nnumerical_features=['MonthlyCharges','TotalCharges','tenure']\ncategorical_features = [\n 'gender',\n 'SeniorCitizen',\n 'Partner',\n 'Dependents',\n 'PhoneService',\n 'MultipleLines',\n 'InternetService',\n 'OnlineSecurity',\n 'OnlineBackup',\n 'DeviceProtection',\n 'TechSupport',\n 'StreamingTV',\n 'StreamingMovies',\n 'Contract',\n 'PaperlessBilling',\n 'PaymentMethod',\n]\n","02f236b4":"#Creating Checkpoint\nraw_data_2 = raw_data_1.copy()","65fc6ae6":"temp =raw_data_2.groupby(['Churn']).count()['gender']\np2 = raw_data_2['Churn'].value_counts().values","8ba53867":"fig1, ax1= plt.subplots(1)\nexplode = (0.2,0)\n\nlabels = ['No','Yes']\n\n#p2 = [temp[0],temp[1]]\nax1.set_title('Customer Churn in Data ')\nax1.pie(p2, explode=explode, autopct='%1.1f%%',\n        shadow=True,labels=labels, startangle=90)\n\n\nplt.tight_layout()\nplt.show()\n","c2583c65":"def non_churn(cat_col):\n    temp = raw_data_2.groupby(['Churn',cat_col])['Churn'].count()\n    return temp[0]\ndef churn(cat_col):\n    temp = raw_data_2.groupby(['Churn',cat_col])['Churn'].count()\n    return temp[1]\n\ndef pie_cat(cat_col,explode=(0.2,0)):\n    p2= non_churn(cat_col)\n    p3 = churn(cat_col)\n    fig1,(ax2,ax3) = plt.subplots(1,2,figsize=(10,10))\n\n    labels = raw_data_2[cat_col].unique()\n    ax3.pie(p3, explode=explode, autopct='%1.1f%%',\n        shadow=True,labels=labels, startangle=90)\n    ax2.pie(p2,  autopct='%1.1f%%',\n        shadow=True,labels=labels, startangle=90)\n    ax2.set_title('Non Churn customers')\n    ax3.set_title(' Churn customers')\n    plt.suptitle('Churn Distribution in '+ cat_col,fontsize='15')\n    plt.tight_layout()\n    plt.show()\n","3993e42f":"#for i in range(16):\n#    pie_cat(categorical_features[i])\nex = (0.1,0.1,0.1)\n\npie_cat(categorical_features[0])\n#pie_cat(categorical_features[1])\n#pie_cat(categorical_features[2])","d980b913":"#pie_cat(categorical_features[3])\n#pie_cat(categorical_features[4])\n#pie_cat(categorical_features[5])","90a04797":"ex = (0.1,0.1,0.1)\n\npie_cat(categorical_features[6],ex)\n#pie_cat(categorical_features[7])\n#pie_cat(categorical_features[8])","42ac66c0":"pie_cat(categorical_features[9])\n#pie_cat(categorical_features[10])\n#pie_cat(categorical_features[11])\n","74335d96":"ex = (0.1,0.1,0.1)\n#pie_cat(categorical_features[12])\npie_cat(categorical_features[13],ex)\n#pie_cat(categorical_features[14])","c5342073":"ex = (0.1,0.1,0.1,0.1)\npie_cat(categorical_features[15],ex)","a46c9a22":"raw_data_3 = raw_data_2.copy()\ndef tenure_lab(raw_data_3) :\n    \n    if raw_data_3[\"tenure\"] <= 12 :\n        return \"Tenure_0-12\"\n    elif (raw_data_3[\"tenure\"] > 12) & (raw_data_3[\"tenure\"] <= 24 ):\n        return \"Tenure_12-24\"\n    elif (raw_data_3[\"tenure\"] > 24) & (raw_data_3[\"tenure\"] <= 48) :\n        return \"Tenure_24-48\"\n    elif (raw_data_3[\"tenure\"] > 48) & (raw_data_3[\"tenure\"] <= 60) :\n        return \"Tenure_48-60\"\n    elif raw_data_3[\"tenure\"] > 60 :\n        return \"Tenure_gt_60\"\n    \nraw_data_3['tenure'] = raw_data_2.apply(lambda raw_data_2:tenure_lab(raw_data_2),axis = 1)\n","c3ef29f3":"def tenure_non_churn(cat_col):\n    temp = raw_data_3.groupby(['Churn',cat_col])['Churn'].count()\n    return temp[0]\ndef tenure_churn(cat_col):\n    temp = raw_data_3.groupby(['Churn',cat_col])['Churn'].count()\n    return temp[1]\n\ndef tenure_pie_cat(cat_col,explode=(0.1,0.1,0.1,0.1,0.1)):\n    p2= tenure_non_churn(cat_col)\n    p3 = tenure_churn(cat_col)\n    fig1,(ax2,ax3) = plt.subplots(1,2,figsize=(10,10))\n\n    labels = raw_data_3[cat_col].unique()\n    ax3.pie(p3, autopct='%1.1f%%',\n        shadow=True,explode=explode,labels=labels, startangle=90)\n    ax2.pie(p2,  autopct='%1.1f%%',\n        shadow=True,labels=labels,startangle=90)\n    ax2.set_title('Non Churn customers')\n    ax3.set_title(' Churn customers')\n    plt.suptitle('Churn Distribution in '+ cat_col,fontsize='15')\n    plt.tight_layout()\n    plt.show()\n","e4d0dd39":"tenure_pie_cat('tenure')\n","a80ce98d":"fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,7))\n\nsns.distplot(raw_data_2[raw_data_2.Churn==0]['TotalCharges']\n             ,bins=30,kde=False,color='Green',ax=ax1,label=['Not Churn'])\nsns.distplot(raw_data_2[raw_data_2.Churn==1]['TotalCharges']\n             ,bins=30,kde=False,color='Black',ax=ax1,label=['Churned'])\n\nsns.distplot(raw_data_2[raw_data_2.Churn==0]['MonthlyCharges']\n             ,bins=30,kde=False,color='Green',ax=ax2,label=['Not Churn'])\nsns.distplot(raw_data_2[raw_data_2.Churn==1]['MonthlyCharges']\n             ,bins=30,kde=False,color='Black',ax=ax2,label=['Churned'])\n\nsns.distplot(raw_data_2[raw_data_2.Churn==0]['tenure']\n             ,bins=30,kde=False,color='Green',ax=ax3,label=['Not Churn'])\nsns.distplot(raw_data_2[raw_data_2.Churn==1]['tenure']\n             ,bins=30,kde=False,color='Black',ax=ax3,label=['Churned'])\nplt.legend()","ef0c26be":"fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,7))\nsns.scatterplot(raw_data_2['TotalCharges'],\n                raw_data_2['tenure'],color='Black',ax=ax1,hue=raw_data_2['Churn'])\nsns.scatterplot(raw_data_2['MonthlyCharges'],\n                raw_data_2['tenure'],color='Black',ax=ax2,hue=raw_data_2['Churn'])\nsns.scatterplot(raw_data_2['MonthlyCharges'],\n                raw_data_2['TotalCharges'],color='Black',ax=ax3,hue=raw_data_2['Churn'])","6edb65c8":"#fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,7))\n#sns.scatterplot(raw_data_2[raw_data_2.Churn==1]['TotalCharges'],\n#                raw_data_2[raw_data_2.Churn==1]['tenure'],color='Black',ax=ax1)\n#sns.scatterplot(raw_data_2[raw_data_2.Churn==1]['MonthlyCharges'],\n#                raw_data_2[raw_data_2.Churn==1]['tenure'],color='Black',ax=ax2)\n#sns.scatterplot(raw_data_2[raw_data_2.Churn==1]['MonthlyCharges'],\n#                raw_data_2[raw_data_2.Churn==1]['TotalCharges'],color='Black',ax=ax3)","fd62ec1c":"plt.figsize=(200,10)\nplt.xticks(rotation=90)\nsns.countplot(raw_data_3['tenure'],hue=raw_data_3['Churn'])\nplt.show()\n","d5280180":"#sns.scatterplot(raw_data_3[raw_data_3.Churn==1]['MonthlyCharges'],\n #               raw_data_3[raw_data_3.Churn==1]['TotalCharges'],color='Black',hue=raw_data_3['tenure'])","4fa4170c":"plt.xticks(rotation=90)\nsns.boxplot( raw_data_3['tenure'],raw_data_3['TotalCharges'],color='Orange',hue=raw_data_3['Churn'])","db3233e1":"plt.xticks(rotation=90)\nsns.boxplot( raw_data_3['tenure'],raw_data_3['MonthlyCharges'],color='Orange',hue=raw_data_3['Churn'])","758e43ec":"plt.xticks(rotation=90)\nsns.barplot(raw_data_3['tenure'],\n            raw_data_3['MonthlyCharges'],hue=raw_data_3['Churn'],\n            estimator=np.mean).set_title('Average Distribution of Monthly Charges According to Tenure')\nplt.show()","744fdd97":"plt.xticks(rotation=90)\nsns.barplot(raw_data_3['tenure']\n            ,raw_data_3['TotalCharges'],hue=raw_data_3['Churn'],\n            estimator=np.median).set_title('Average Distribution of Total Charges According to Tenure')\nplt.show()","baf16854":"import plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization\n\n\n\ntrace1 = go.Scatter3d(x = raw_data_2[raw_data_2.Churn==1][\"MonthlyCharges\"],\n                      y = raw_data_2[raw_data_2.Churn==1][\"TotalCharges\"],\n                      z = raw_data_2[raw_data_2.Churn==1][\"tenure\"],\n                      mode = \"markers\",\n                      name = \"Churn customers\",\n                      \n                      marker = dict(size = 1,color = \"red\")\n                     )\n\n\nlayout = go.Layout(dict(title = \"Monthly charges,total charges & tenure in customer attrition\",\n                        scene = dict(camera = dict(up=dict(x= 0 , y=0, z=0),\n                                                   center=dict(x=0, y=0, z=0),\n                                                   eye=dict(x=1.25, y=1.25, z=1.25)),\n                                     xaxis  = dict(title = \"monthly charges(x)\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'),\n                                     yaxis  = dict(title = \"total charges(y)\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  ),\n                                     zaxis  = dict(title = \"tenure(z)\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  )\n                                    ),\n                        height = 700,\n                       )\n                  )\n                  \n\ndata = trace1\nfig  = go.Figure(data = data,layout = layout)\npy.iplot(fig)","659d9906":"#Creating Checkpoint\nraw_data_4 = raw_data_2.copy()","6c540073":"input = raw_data_4.drop('Churn',axis=1)\ntarget = raw_data_4['Churn']\ninput = pd.get_dummies(input,drop_first=True)","51aee847":"fig,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(input.corr(),cmap='coolwarm').set_title('Correlatiion Matrix')\nplt.show()","93a6241c":"from sklearn.preprocessing import StandardScaler\nnum_cols=['MonthlyCharges','TotalCharges','tenure']\nstd = StandardScaler()\nscaled = std.fit_transform(input[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\ninput_2 = input.drop('MonthlyCharges',axis =1)\ninput_2 = input_2.drop('TotalCharges',axis =1)\ninput_2 = input_2.drop('tenure',axis =1)\nscaled_input = pd.merge(scaled, input_2, left_index=True, right_index=True)\n","7286232d":"scaled_input.head()","fb6930f7":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\n#from yellowbrick.classifier import DiscriminationThreshold\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.feature_selection import chi2","db7852ea":"score, pvalue = chi2(input,target)","fa267abc":"#pvalue.round(3)","7161a17b":"#reg_summary['P Values'] = pvalue.round(3)","a09e663f":"x_train,x_test,y_train,y_test = train_test_split(scaled_input,target,test_size = .25 ,random_state = 111)\nx_train.head()\n","9aa473ca":"#Function attributes\n#dataframe     - processed dataframe\n#Algorithm     - Algorithm used \n#training_x    - predictor variables dataframe(training)\n#testing_x     - predictor variables dataframe(testing)\n#training_y    - target variable(training)\n#training_y    - target variable(testing)\n#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n                                 #regression,features for tree based models)\n\n#threshold_plot - if True returns threshold plot for model\nsns.set()\n\nlogit  = LogisticRegression(class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=1000, n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nlogit.fit(x_train,y_train)\npredictions = logit.predict(x_test)\nprobabilities = logit.predict_proba(x_test)\npredictions_train = logit.predict(x_train)\n\nreg_summary = pd.DataFrame(data = input.columns.values, columns=['Features'])\nreg_summary['Coefficients'] = logit.coef_.ravel()\n\nreg_summary_2=reg_summary.sort_values(by = \"Coefficients\",ascending = False)\nlog_test = accuracy_score(y_test,predictions)\nlog_train = accuracy_score(y_train,predictions_train)\nprint (\"\\n Classification report : \\n\",classification_report(y_test,predictions))\n\nprint (\"Test Accuracy   Score : \",accuracy_score(y_test,predictions))\nprint (\"Train Accuracy   Score : \",accuracy_score(y_train,predictions_train))\n\nconf_matrix = confusion_matrix(y_test,predictions)\nmodel_roc_auc = roc_auc_score(y_test,predictions)\n\nprint (\"Area under curve : \",model_roc_auc,\"\\n\")\nfpr,tpr,thresholds = roc_curve(y_test,probabilities[:,1])\nfig,ax1=plt.subplots(1,figsize=(20,20))\nsns.set(font_scale=1.4)\nsns.barplot(reg_summary_2['Features'],reg_summary_2['Coefficients'],ax=ax1,orient='v')\nplt.xticks(rotation=90)\nplt.xticks(fontsize=20)\nplt.show()\n","57d8a203":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(fpr,tpr)\nax.plot([0,1],[0,1])\nax.set_title('Reciever Operating Charecteristics Curve for Simple Logistic')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nplt.show()","0dfc1d29":"\nsns.set()\nfrom sklearn.feature_selection import RFE\n\nlogit_rfe = LogisticRegression(solver='liblinear')\n\nrfe = RFE(logit_rfe,10)\nrfe = rfe.fit(x_train,y_train)\n\ndata = pd.DataFrame(data = x_train.columns.values, columns=['Features'])\ndata['Support']=rfe.support_\ndata['Rank']=rfe.ranking_\n\ncols = data[data.Support==True]['Features'].values\ndata\n\ndata_2 = data.drop('Support',axis=1)\nfig,ax = plt.subplots(figsize=(10,10))\ndata_2= data_2.set_index('Features').sort_values(by = \"Rank\",ascending = True)\nsns.heatmap(data_2,cmap='coolwarm',annot=True,fmt='g',linewidths=.5,ax=ax).set_title('Feature Ranking')\nb,t = plt.ylim()\nb +=0.5\nt -=0.5\nplt.ylim(b,t)\nplt.yticks(fontsize=15)\nplt.show()\n","d2368bb4":"\nlogit  = LogisticRegression(class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=1000, n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\nlogit.fit(x_train[cols],y_train)\npredictions = logit.predict(x_test[cols])\nprobabilities = logit.predict_proba(x_test[cols])\npredictions_train = logit.predict(x_train[cols])\nreg_summary_3 = pd.DataFrame(data = x_train[cols].columns.values, columns=['Features'])\nreg_summary_3['Coefficients'] = logit.coef_.ravel()\nreg_summary_4=reg_summary_3.sort_values(by = \"Coefficients\",ascending = False)\nlog_rfe_test= accuracy_score(y_test,predictions)\nlog_rfe_train=accuracy_score(y_train,predictions_train)\nprint (\"\\n Classification report : \\n\",classification_report(y_test,predictions))\n\nprint (\"Test Accuracy   Score : \",accuracy_score(y_test,predictions))\nprint (\"Train Accuracy   Score : \",accuracy_score(y_train,predictions_train))\n\nconf_matrix_2 = confusion_matrix(y_test,predictions)\nmodel_roc_auc_2 = roc_auc_score(y_test,predictions)\nprint (\"Area under curve : \",model_roc_auc_2,\"\\n\")\n\nfpr_1,tpr_1,thresholds = roc_curve(y_test,probabilities[:,1])\n\nfig,ax1=plt.subplots(1,figsize=(20,20))\nsns.set(font_scale=1.4)\nsns.barplot(reg_summary_4['Features'],reg_summary_4['Coefficients'],ax=ax1,orient='v')\nplt.xticks(rotation=90)\nplt.xticks(fontsize=20)\nplt.show()\n\n","ce054d4a":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(fpr_1,tpr_1)\nax.plot([0,1],[0,1])\nax.set_title('Reciever Operating Charecteristics Curve for RFE Logistic')\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nplt.show()","eaa1c119":"\n\ndf = pd.DataFrame(data = ['True Positive:','True Negative','False Negative:','False Positive:','AUC Score:','Train Accuracy','Test Accurcacy','Train Samples','Test Samples'], columns=['Features'])\ndf['Simple Log'] = conf_matrix[1][1],conf_matrix[0][0],conf_matrix[1][0],conf_matrix[0][1],model_roc_auc*100,log_train*100,log_test*100,5274,1758\n\n\ndf['RFE Log'] = conf_matrix_2[1][1],conf_matrix_2[0][0],conf_matrix_2[1][0], conf_matrix_2[0][1],model_roc_auc_2*100,log_rfe_train*100,log_rfe_test*100,5274,1758\nprint(df)","045d63a1":"df =df.set_index('Features')\n","934ac08d":"\nsns.heatmap(df,cmap='coolwarm',annot=True,fmt='g',linewidths=.5).set_title('Comparitive Measures b\/w Simple Log and RFE log')\nb,t = plt.ylim()\nb +=0.5\nt -=0.5\nplt.ylim(b,t)\nplt.show()","0bbb6c63":"# Customer Attrition According to Charges and tenure","27d83e68":"#Creating Checkpoint","e84133db":"# Relation between Numerical Variables","bb2bd628":"# Data Cleaning","bd6ab579":"# Data Pre-processing","7434bfd8":"###Creating Categories for Tenure, code is courtesy of Pavan Raj\n","e9bab8d3":"# Comparision Between Simple Logistic and RFE Logsitic","740253f6":"#Customer Attrition","fd8cd235":"Building a Model","4e922961":"#Customer Attrition According to Different categories","8ed14a59":"#Information about Data\nCustomer attrition, also known as customer churn, customer turnover, or customer defection, is the loss of clients or customers.\n\nTelephone service companies, Internet service providers, pay TV companies, insurance firms, and alarm monitoring services, often use customer attrition analysis and customer attrition rates as one of their key business metrics because the cost of retaining an existing customer is far less than acquiring a new one. Companies from these sectors often have customer service branches which attempt to win back defecting clients, because recovered long-term customers can be worth much more to a company than newly recruited clients.\n\nCompanies usually make a distinction between voluntary churn and involuntary churn. Voluntary churn occurs due to a decision by the customer to switch to another company or service provider, involuntary churn occurs due to circumstances such as a customer's relocation to a long-term care facility, death, or the relocation to a distant location. In most applications, involuntary reasons for churn are excluded from the analytical models. Analysts tend to concentrate on voluntary churn, because it typically occurs due to factors of the company-customer relationship which companies control, such as how billing interactions are handled or how after-sales help is provided.\n\npredictive analytics use churn prediction models that predict customer churn by assessing their propensity of risk to churn. Since these models generate a small prioritized list of potential defectors, they are effective at focusing customer retention marketing programs on the subset of the customer base who are most vulnerable to churn.\n\nOnly 7043 rows\nThere are 21 columns with 19 features\nOnly 11 missing values.","6a9e581b":"#  Exploration of Data","afaeeaa7":"# Recursive Feature Logistic Regression"}}