{"cell_type":{"237b1f4e":"code","449038b5":"code","c4098c30":"code","ee1a5f11":"code","875bc315":"code","30868b55":"code","2d8f5d72":"code","0951d897":"code","ba2e4e28":"code","50323401":"code","d6501080":"code","01f5e243":"code","3be071fa":"code","ed39a3cf":"code","af7f22ab":"code","9728eeb9":"code","759d0e0e":"code","cfc998ca":"code","d6993b6b":"code","d54ff1f5":"code","93c23058":"code","9d78a66f":"code","a1ac2ac2":"code","12e0c4ea":"code","1b649ac6":"code","5c5c24bb":"code","120c1dc1":"code","6a87e20b":"code","1edd9bf1":"markdown","f097a531":"markdown","6447ea72":"markdown","5c77c265":"markdown"},"source":{"237b1f4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","449038b5":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier","c4098c30":"titanic_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","ee1a5f11":"titanic_data","875bc315":"titanic_data.isnull().sum()","30868b55":"X = titanic_data.drop(['Survived','Name','Ticket','Cabin','Embarked'], axis = 1)\ny = titanic_data.Survived","2d8f5d72":"X","0951d897":"X['Sex'] = X['Sex'].replace('male', 1)\nX['Sex'] = X['Sex'].replace('female', 0)","ba2e4e28":"male_mean_age = round(X.groupby(['Sex']).median()['Age'][1],1)\nfemale_mean_age = round(X.groupby(['Sex']).median()['Age'][0],1)","50323401":"X.loc[(X['Age'].isnull()) & (X['Sex'] == 1), 'Age'] = male_mean_age\nX.loc[(X['Age'].isnull()) & (X['Sex'] == 0), 'Age'] = female_mean_age","d6501080":"X","01f5e243":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","3be071fa":"clf_rf = RandomForestClassifier()","ed39a3cf":"parametrs = {'n_estimators': [10,20], \n             'max_depth': range(10,15),\n             'min_samples_split': range(11,16),\n             'min_samples_leaf':range(9,12)\n            }\n\ngrid_search_cv_clf = GridSearchCV(clf_rf, parametrs, cv=5)\n\n# {'max_depth': 12,\n#  'min_samples_leaf': 10,\n#  'min_samples_split': 15,\n#  'n_estimators': 20}","af7f22ab":"grid_search_cv_clf.fit(X_train, y_train)","9728eeb9":"grid_search_cv_clf.best_params_","759d0e0e":"best_clf_rf = grid_search_cv_clf.best_estimator_","cfc998ca":"best_clf_rf.score(X_test,y_test)","d6993b6b":"test_data","d54ff1f5":"y_test_data = test_data.drop(['Name','Ticket','Cabin','Embarked'], axis = 1)","93c23058":"y_test_data.isnull().sum()","9d78a66f":"y_test_data['Sex'] = y_test_data['Sex'].replace('male', 1)\ny_test_data['Sex'] = y_test_data['Sex'].replace('female', 0)\n\nmale_mean_age = round(y_test_data.groupby(['Sex']).median()['Age'][1],1)\nfemale_mean_age = round(y_test_data.groupby(['Sex']).median()['Age'][0],1)\n\ny_test_data.loc[(y_test_data['Age'].isnull()) & (y_test_data['Sex'] == 1), 'Age'] = male_mean_age\ny_test_data.loc[(y_test_data['Age'].isnull()) & (y_test_data['Sex'] == 0), 'Age'] = female_mean_age\n\ny_test_data = y_test_data.fillna(y_test_data['Fare'].median())","a1ac2ac2":"best_clf_rf.predict(y_test_data)","12e0c4ea":"predicts = pd.Series(best_clf_rf.predict(y_test_data), name='Survived')","1b649ac6":"PassId = test_data['PassengerId']","5c5c24bb":"result = pd.concat([PassId, predicts], axis=1)","120c1dc1":"result","6a87e20b":"result.to_csv('MySubmission.csv', index=False)","1edd9bf1":"# Test data preprocessing","f097a531":"# Train data preprocessing","6447ea72":"# Making a prediction","5c77c265":"# Model fitting"}}