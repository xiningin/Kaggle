{"cell_type":{"d85f5bd0":"code","51065628":"code","a1a2f5bc":"code","8dbec097":"code","5b3eda2c":"code","42193e5d":"code","db1d5f9c":"code","59ff3b6e":"code","1ebe0b6d":"code","c00c9d6f":"code","b403023d":"code","2f9bcf5b":"code","71e0e4b9":"code","d1c58e5d":"code","13ac05e8":"code","8fe6cb95":"code","48a40f4e":"code","402723f5":"markdown","e391f37d":"markdown","98e920de":"markdown","6e608d24":"markdown","de85fcb8":"markdown","5ec1b37d":"markdown","67bd45ca":"markdown","bb520cf8":"markdown","d4c32c43":"markdown","c8ef0ed4":"markdown","baf13fc3":"markdown","c3a473cc":"markdown"},"source":{"d85f5bd0":"#\u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\nimport numpy as np \nimport pandas as pd \nfrom pandas import Series\n\nimport re\nimport datetime\n\nfrom sklearn.feature_selection import mutual_info_classif, f_classif\nfrom sklearn.model_selection import train_test_split, train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import clone\n\nfrom tqdm.notebook import tqdm\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor","51065628":"#\u0418\u043c\u043f\u043e\u0440\u0442 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438\u0437 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u044f\ndata_sample = pd.read_csv('..\/input\/sf-dst-car-price-prediction\/sample_submission.csv')\n\n#\u0418\u043c\u043f\u043e\u0440\u0442 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\ndata_full = pd.read_csv('..\/input\/sf-dst-car-price-prediction-super-parser-eda\/data_full_EDA.csv') \n\n#\u0412\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 EDA\ndata_columns = pd.read_csv('..\/input\/sf-dst-car-price-prediction-super-parser-eda\/data_full_columns.csv') \n\ncat_cols = data_columns[data_columns.column_type == 'cat'].column_name.values\nbin_cols = data_columns[data_columns.column_type == 'bin'].column_name.values\nnum_cols = data_columns[data_columns.column_type == 'num'].column_name.values\n\nprint(len(data_full))","a1a2f5bc":"data_train = data_full[data_full.sample_ == 0]\ndata_test = data_full[data_full.sample_ == 1].drop(['price', 'sample_'], axis=1).values","8dbec097":"X = data_train.drop(['price', 'sample_'], axis=1).values\nY = data_train['price'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)","5b3eda2c":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)\/y_true))\n\ndef learn_model(model):        \n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)    \n    print (f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, y_pred))*100:0.2f}%\")\n    \ndef learn_model_log(model):\n    model.fit(X_train,np.log(y_train+1))\n    y_pred = np.exp(model.predict(X_test))\n    print (f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, y_pred))*100:0.2f}%\")","42193e5d":"RANDOM_SEED = 42","db1d5f9c":"#learn_model(LinearRegression())\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 87.83%","59ff3b6e":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u043c \u043b\u0438\u043d\u0435\u0439\u043d\u0443\u044e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e \u0441 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\n\"\"\"\nlr = LinearRegression().fit(X_train, np.log(y_train+1))\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, np.exp(lr.predict(X_test))))*100:0.2f}%\")\nVERSION = 1\npredict_test = np.exp(lr.predict(X_test))\npredict_submission = np.exp(lr.predict(data_test))\n\"\"\"\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 20.95%","1ebe0b6d":"# Random forest\n\"\"\"\nrf = RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1).fit(X_train, np.log(y_train+1))\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, np.exp(rf.predict(X_test))))*100:0.2f}%\")\nVERSION = 2\npredict_test = np.exp(rf.predict(X_test))\npredict_submission = np.exp(rf.predict(data_test))\n\"\"\"\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 13.95%","c00c9d6f":"# \u041f\u043e\u0434\u0431\u043e\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0434\u043b\u044f Random forest\n\"\"\"\nrandom_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n               'max_features': ['auto', 'sqrt'],\n               'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n               'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4],\n               'bootstrap': [True, False]}\n\nrf = RandomForestRegressor(random_state=RANDOM_SEED)\nrf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, \n                               cv=3, verbose=2, random_state=RANDOM_SEED, n_jobs=-1)\nrf_random.fit(X_train, np.log(y_train+1))\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, np.exp(rf_random.predict(X_test))))*100:0.2f}%\")\nVERSION = 8\npredict_test = np.exp(rf.predict(X_test))\npredict_submission = np.exp(rf.predict(data_test))\n\"\"\"","b403023d":"#\u0435\u0449\u0435 \u043f\u0430\u0440\u043e\u0447\u043a\u0430 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432\n\n#learn_model_log(KNeighborsRegressor(algorithm = 'ball_tree', weights = 'distance', p=1))\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 66.25% \u043f\u043e-\u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 59.54% p=1\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 66.24% algorithm = 'ball_tree'\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 63.98% weights = 'distance'\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 66.25% leaf_size = 5\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 57.66% algorithm = 'ball_tree', weights = 'distance', p=1\n\n#learn_model_log(KNeighborsRegressor(algorithm = 'ball_tree', weights = 'distance', p=1))\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 50.23%\n\n#learn_model(DecisionTreeRegressor(random_state = 42))\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 110.55% max_depth=3, max_features=20\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 45.65% max_depth=15, max_features=5\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 22.29% max_depth=10\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 19.79% \u043f\u043e-\u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 17.50% max_depth=15\n\n#learn_model_log(DecisionTreeRegressor(max_depth=15, random_state = 42))\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 19.46% \u043f\u043e-\u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 60.92% max_depth=3, max_features=20\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 38.89% max_depth=15, max_features=5\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 19.26% max_depth=10\n#\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 16.56% max_depth=15","2f9bcf5b":"# CatBoostRegressor\n\"\"\"\ncb = CatBoostRegressor(iterations = 5000, random_seed = RANDOM_SEED, eval_metric='MAPE', \\\n                            custom_metric=['R2', 'MAE'], silent=True,)\ncb.fit(X_train, np.log(y_train+1), eval_set=(X_test, np.log(y_test+1)), verbose_eval=0, use_best_model=True)\ncb.save_model('catboost_single_model_2_baseline.model')\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, np.exp(cb.predict(X_test))))*100:0.2f}%\")\nVERSION = 3\npredict_test = np.exp(cb.predict(X_test))\npredict_submission = np.exp(cb.predict(data_test))\n\"\"\"\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 13.51%\n# Kaggle 19.66459","71e0e4b9":"# GradientBoostingRegressor\n\"\"\"\ngb = GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=300)\ngb.fit(X_train, np.log(y_train+1))\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, np.exp(gb.predict(X_test))))*100:0.2f}%\")\nVERSION = 4\npredict_test = np.exp(gb.predict(X_test))\npredict_submission = np.exp(gb.predict(data_test))\"\"\"\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 13.68%\n# Kaggle 18.86542","d1c58e5d":"# xgboost\nxb = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.5, learning_rate=0.03, \\\n                      max_depth=12, alpha=1, n_jobs=-1, n_estimators=1000)\nxb.fit(X_train, np.log(y_train+1))\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {(mape(y_test, np.exp(xb.predict(X_test))))*100:0.2f}%\")\nVERSION = 5\npredict_test = np.exp(xb.predict(X_test))\npredict_submission = np.exp(xb.predict(data_test))\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 13.31%\n# Kaggle 18.84844","13ac05e8":"\"\"\"\nscaler = StandardScaler() \nX_train = scaler.fit_transform(X_train) \nX_test = scaler.transform(X_test) \ndata_test = scaler.transform(data_test)\n\ny_train = y_train \ny_test = y_test\n\ncv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n\ndef compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test):\n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \n\n    splits = cv.split(X_train)\n    for train_fold_index, predict_fold_index in splits:\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n\n        folded_regr = clone(regr)\n        folded_regr.fit(X_fold_train, y_fold_train)\n\n        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\n\n    meta_regr = clone(regr)\n    meta_regr.fit(X_train, y_train)\n\n    X_meta_test = meta_regr.predict(X_test)\n    X_meta_pred = meta_regr.predict(data_test)\n\n    return X_meta_train, X_meta_test, X_meta_pred\n\ndef generate_meta_features(regr, X_train, X_test, y_train, cv, data_test):\n    features = [compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test) for regr in tqdm(regr)]    \n    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\n    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\n    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\n    return stacked_features_train, stacked_features_test, stacked_features_pred\n\nregr = RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \n                             max_features=3, max_depth=19, bootstrap=True, random_state=RANDOM_SEED)\n\nstacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features([\n                            regr,\n                            RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1, max_depth=5, n_estimators=200),\n                            ExtraTreesRegressor(random_state=RANDOM_SEED), \n                            RandomForestRegressor(random_state=RANDOM_SEED, max_depth=15) \\\n], X_train, X_test, y_train, cv, data_test)\n\ndef compute_metric(regr, X_train, y_train, X_test, y_test): \n    regr.fit(X_train, y_train) \n    y_test_pred = regr.predict(X_test) \n    return np.round(mape(y_test, y_test_pred)*100, 4)\n\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {compute_metric(regr, stacked_features_train, y_train, stacked_features_test, y_test)}%\")\nVERSION = 6\npredict_test = regr.predict(stacked_features_test)\npredict_submission = regr.predict(stacked_features_pred)\n\"\"\"\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 15.2942%\n# Kaggle 22.59028","8fe6cb95":"\"\"\"\nscaler = StandardScaler() \nX_train = scaler.fit_transform(X_train) \nX_test = scaler.transform(X_test) \ndata_test = scaler.transform(data_test)\n\ny_train = y_train\ny_test = y_test\n\ncv = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n\ndef compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test):\n    X_meta_train = np.zeros_like(y_train, dtype=np.float32)    \n\n    splits = cv.split(X_train)\n    for train_fold_index, predict_fold_index in splits:\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n\n        folded_regr = clone(regr)\n        folded_regr.fit(X_fold_train, y_fold_train)\n\n        X_meta_train[predict_fold_index] = folded_regr.predict(X_fold_predict)\n\n    meta_regr = clone(regr)\n    meta_regr.fit(X_train, y_train)\n\n    X_meta_test = meta_regr.predict(X_test)\n    X_meta_pred = meta_regr.predict(data_test)\n\n    return X_meta_train, X_meta_test, X_meta_pred\n\ndef generate_meta_features(regr, X_train, X_test, y_train, cv, data_test):\n    features = [compute_meta_feature(regr, X_train, X_test, y_train, cv, data_test) for regr in tqdm(regr)]    \n    stacked_features_train = np.vstack([features_train for features_train, features_test, features_pred in features]).T\n    stacked_features_test = np.vstack([features_test for features_train, features_test, features_pred in features]).T\n    stacked_features_pred = np.vstack([features_pred for features_train, features_test, features_pred in features]).T\n    return stacked_features_train, stacked_features_test, stacked_features_pred\n\nregr = RandomForestRegressor(n_estimators=300, min_samples_split=2, min_samples_leaf=1, \n                             max_features=3, max_depth=25, bootstrap=True, random_state=RANDOM_SEED)\n\nstacked_features_train, stacked_features_test, stacked_features_pred = generate_meta_features([\n                            regr,\n                            RandomForestRegressor(random_state = RANDOM_SEED, n_jobs = -1, verbose = 1, max_depth=5, n_estimators=200),\n                            ExtraTreesRegressor(random_state=RANDOM_SEED),\n                            GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=300),\n                            RandomForestRegressor(random_state=RANDOM_SEED, n_jobs = -1, max_depth=15) \\\n], X_train, X_test, y_train, cv, data_test)\n\ndef compute_metric(regr, X_train, y_train, X_test, y_test): \n    regr.fit(X_train, np.log(y_train+1))\n    y_test_pred = np.exp(regr.predict(X_test))\n    return np.round(mape(y_test, y_test_pred)*100, 4)\n\nprint(f\"\u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: {compute_metric(regr, stacked_features_train, y_train, stacked_features_test, y_test)}%\")\nVERSION = 7\npredict_test = np.exp(regr.predict(stacked_features_test))\npredict_submission = np.exp(regr.predict(stacked_features_pred))\n\"\"\"\n# \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0435 MAPE: 13.8579%\n# Kaggle 20.63917","48a40f4e":"#predict_test = np.exp(model.predict(X_test))\n#predict_submission = np.exp(model.predict(data_test))\n\ndata_sample['price'] = predict_submission\ndata_sample.to_csv(f'submission_2_v{VERSION}.csv', index=False)\ndata_sample.head(10)","402723f5":"# \u041d\u0430\u0438\u0432\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c","e391f37d":"# \u0417\u0430\u0434\u0430\u0447\u0430\n\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f \u043f\u043e \u0435\u0433\u043e \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0430\u043c. \u0414\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043c\u0435\u0442\u0440\u0438\u043a\u0443 MAPE\n\n\u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0435 \u043c\u044b \u0432\u044b\u0431\u0438\u0440\u0430\u043b\u0438 \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f.\n\n\u0422\u0430\u043a\u0436\u0435 \u0432 \u044d\u0442\u043e\u043c \u043f\u0440\u043e\u0435\u043a\u0442\u0435 \u043c\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0438:\n* \u041d\u043e\u0443\u0442\u0431\u0443\u043a, \u0447\u0435\u0440\u0435\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u0430\u0440\u0441\u0438\u043b\u0438 https:\/\/www.kaggle.com\/juliadeinego\/sf-dst-car-price-prediction-super-parsers-data\n* \u0421\u043f\u0430\u0440\u0441\u0435\u043d\u043d\u044b\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 https:\/\/www.kaggle.com\/juliadeinego\/data-car-sales\n* \u041d\u043e\u0443\u0442\u0431\u0443\u043a, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043f\u0440\u043e\u0432\u0435\u043b\u0438 EDA https:\/\/www.kaggle.com\/juliadeinego\/sf-dst-car-price-prediction-super-parser-eda\n* \u041d\u043e\u0443\u0442\u0431\u0443\u043a, \u0432 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043f\u0440\u043e\u0432\u0435\u043b\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 https:\/\/www.kaggle.com\/juliadeinego\/sf-dst-car-price-prediction-super-parsers-ml\n","98e920de":"# Submission","6e608d24":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","de85fcb8":"## \u0427\u0442\u043e \u0431\u044b \u043c\u044b \u0441\u0434\u0435\u043b\u0430\u043b\u0438 \u0435\u0449\u0435, \u043d\u043e \u0438\u0437-\u0437\u0430 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u043f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0432 \u0442\u0430\u043a\u043e\u043c \u0432\u0438\u0434\u0435:\n1. \u0418\u0437\u043c\u0435\u043d\u0438\u0442\u044c \u0441\u043f\u043e\u0441\u043e\u0431 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n2. \u041f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0441 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438 \u0430\u0432\u0442\u043e, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u044b \u0443\u0434\u0430\u043b\u0438\u043b\u0438\n3. \u041f\u0440\u043e\u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432\u0441\u0435 \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438\n4. \u0421\u0434\u0435\u043b\u0430\u0442\u044c \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u043e\u0439 (\u0432 \u0434\u0438\u0430\u043f\u0430\u0437\u043e\u043d\u0435 +-2\u0441\u0438\u0433\u043c\u0430 \u0441 \u0448\u0430\u0433\u043e\u043c 10\u043a) \u0438 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\n5. \u041f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0441\u0442\u0435\u043a\u0438\u043d\u0433 \u043b\u0443\u0447\u0448\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432 GradientBoostingRegressor, XGBRegressor \u0438 Catboost","5ec1b37d":"\u0414\u0430\u043b\u0435\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0440\u0430\u0437\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0438\u0445 \u043c\u0435\u0442\u0440\u0438\u043a\u0438. \u0412\u0441\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0437\u0430\u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u0433\u0440\u0443\u0437\u0438\u0442\u044c \u043d\u043e\u0443\u0442\u0431\u0443\u043a. \u0412 \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u044f\u0445 \u043f\u0440\u043e\u043f\u0438\u0448\u0435\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0438. \u041e\u0441\u0442\u0430\u0432\u0438\u043c \u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c","67bd45ca":"\u0421\u043d\u0430\u0447\u0430\u043b\u0430 \u0432\u044b\u0434\u0435\u043b\u0438\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e \u0447\u0430\u0441\u0442\u0438.","bb520cf8":"## \u0412\u044b\u0432\u043e\u0434\u044b \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435:\n1. Catboost \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0445\u043e\u0440\u043e\u0448\u0438\u0439 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c, \u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0434\u0430\u0436\u0435 \u0441 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438.\n2. \u041f\u0440\u0435\u0432\u0437\u043e\u0439\u0442\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 Catboost \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u0441 xgboost. \u0415\u0433\u043e \u0438 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0432 \u0441\u043e\u0440\u0435\u0432\u043e\u0432\u0430\u043d\u0438\u0438\n3. \u041c\u0435\u0442\u0440\u0438\u043a\u0443 \u0441\u0438\u043b\u044c\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\n4. \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u0432 (250\u043a \u043e\u0431\u044c\u0435\u043a\u0442\u043e\u0432 \u0438 20+ \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432) \u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u0445\u043e\u0440\u043e\u0448\u0438\u0445 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432. \u041d\u0435 \u0432\u0441\u0435 \u043c\u043e\u0436\u043d\u043e \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c \u043d\u0430 \u043a\u0430\u0433\u043b\u0435 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0433\u043b\u0443\u0431\u0438\u043d\u0430 \u0434\u0435\u0440\u0435\u0432\u0430, \u043f\u043e\u0438\u0441\u043a \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u043f\u043e\u0434\u043e\u0431\u043d\u043e\u0435 \u0432\u044b\u043b\u0435\u0442\u0430\u044e\u0442 \u0441 \u043e\u0448\u0438\u0431\u043a\u043e\u0439 \u043d\u0435\u0445\u0432\u0430\u0442\u043a\u0438 \u043f\u0430\u043c\u044f\u0442\u0438...)","d4c32c43":"\u0414\u0435\u043b\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0435\u0449\u0435 \u043e\u0434\u0438\u043d \u0442\u0435\u0441\u0442 \u0438 \u0442\u0440\u0435\u0439\u043d, \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438,\n\u0447\u0442\u043e\u0431\u044b \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c, \u043a\u0430\u043a \u0445\u043e\u0440\u043e\u0448\u043e \u043c\u043e\u0434\u0435\u043b\u044c \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442, \u0434\u043e \u043e\u0442\u043f\u0440\u0430\u0432\u043a\u0438 submission \u043d\u0430 kaggle.","c8ef0ed4":"# \u0421\u0442\u0435\u043a\u0438\u043d\u0433","baf13fc3":"# \u041f\u0440\u043e\u0441\u0442\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","c3a473cc":"# \u0411\u0443\u0441\u0442\u0438\u043d\u0433"}}