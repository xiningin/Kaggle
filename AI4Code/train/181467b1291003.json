{"cell_type":{"a18ca2d4":"code","0c833e14":"code","6870bb9e":"code","65bb6692":"code","a0cf4d5f":"code","83fcfede":"code","4c533dcf":"code","f27662cc":"code","d95fc23d":"code","68a072e4":"code","72b774a1":"code","b3317f5f":"code","b2d07858":"code","5abd81d4":"code","b58acda4":"code","8d3e11b9":"code","b73ded8e":"code","23c7dc2b":"code","d6ec1b0c":"code","82c13545":"code","d2c72309":"code","9174cf5a":"code","015bfeb9":"markdown","36c0f9f3":"markdown","cf165d32":"markdown","ab3203aa":"markdown","7480e18b":"markdown","5685e43d":"markdown","ec97ebc4":"markdown","ba44701b":"markdown","60b0129e":"markdown","87861f85":"markdown","5fe8bebf":"markdown","0e5e76ca":"markdown"},"source":{"a18ca2d4":"! pip install distance #Make sure you have Internet(ON) in the Kaggle notebook settings","0c833e14":"import pandas as pd\nimport numpy as np\nimport json\nimport os.path\nimport re\nimport distance\nimport matplotlib.pyplot as plt","6870bb9e":"metadata=pd.read_csv(\"\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv\")\nmetadata=metadata[metadata[\"sha\"]==metadata[\"sha\"]] #filters out entries having sha=NaN\nmetadata=metadata[metadata[\"has_full_text\"]] #filters out entries for which the full text is not available","65bb6692":"def path(shaid): #returns path of .json file\n    for dirname, _, files in os.walk('\/kaggle\/input'):\n        if shaid+'.json' in files:\n            return os.path.join(dirname,shaid+\".json\")","a0cf4d5f":"def get_year_month_day(x,k):\n    s = str(x)\n    s = s.split('-')\n    try:\n        return int(s[k])\n    except:\n        return 0","83fcfede":"metadata[\"year\"]=metadata.apply(lambda x: get_year_month_day(x[\"publish_time\"],0),axis=1)\nmetadata[\"month\"]=metadata.apply(lambda x: get_year_month_day(x[\"publish_time\"],1),axis=1)\nmetadata[\"day\"]=metadata.apply(lambda x: get_year_month_day(x[\"publish_time\"],2),axis=1)\n","4c533dcf":"# metadata = metadata[metadata[\"year\"]>2019]","f27662cc":"metadata[\"Path\"]=metadata.apply(lambda x: path(x[\"sha\"]),axis=1) #this takes a while unfotunately\nmetadata=metadata[metadata[\"Path\"]==metadata[\"Path\"]]\nmetadata.shape","d95fc23d":"STRING='vir ' #note the space at the end","68a072e4":"Texts={} #dictionary: {id: \"Text\"}; adapted from cristian's notebook (https:\/\/www.kaggle.com\/crprpr\/vaccine-data-filter)\nvalid_id=[]\nfor shaid,file in zip(metadata[\"sha\"],metadata[\"Path\"]):\n    with open(file, 'r') as f:\n        doc=json.load(f)\n    MainText=''\n    for item in doc[\"body_text\"]:\n        MainText=MainText+(re.sub('[^a-zA-Z0-9]', ' ', item[\"text\"].lower()))\n    if STRING in MainText:\n        Texts[shaid]=MainText\n        valid_id.append(shaid)","72b774a1":"metadata_old = metadata.copy()","b3317f5f":"metadata  = metadata_old.copy()\nsha_selected=[]\nmetadata['selected']=False\nfor a in Texts.keys():\n    t = Texts[a]\n    s = t.split(' ')\n    # f = s.find(\"table\")\n    # key_words = [ 'ratio','recovered','death','covid-19','covid19'  ]\n    key_words = [ 'covid-19','covid19', 'covid 19'  ]\n    for k in key_words:\n        indexes = [index for index in range(len(s)) if s[index] == k]\n        if len(indexes) > 0:\n            idx = metadata[metadata['sha']==a].index  \n            metadata.at[idx,'selected'] = True \n            \n            \n    key_words = [ ['result','in', 'death'] ]\n    for k in key_words:\n        indexes = [index for index in range(len(s)) if s[index] == k[0]]\n        if len(indexes) > 0:\n            for i in indexes:\n                if s[i+1]==k[1] and s[i+2] == k[2]:\n                    idx = metadata[metadata['sha']==a].index  \n                    metadata.at[idx,'selected'] = True \n             \n\nx = metadata[metadata['selected']==True]\nx.shape\nmetadata_old = metadata.copy()\n#metadata = x","b2d07858":"metadata=metadata[metadata[\"sha\"].isin(valid_id)] #filter only articles that contain names of antivirals\n\nmetadata.shape","5abd81d4":"MIN_LENGTH=6 #most likely names of antivirals are longer than 4 letters + 2 spaces; shorter words are probably acronyms \ndrugs=[]\ndrugs_data = {}\nfor shaid in valid_id:\n    iterator=re.finditer(STRING,Texts[shaid])\n    for m in iterator:\n        d = Texts[shaid][Texts[shaid].rfind(' ',0, m.end()-2):m.end()]\n        drugs.append(d)        \n        meta = metadata[metadata['sha']==shaid]\n        \n        info = [int(meta.year),int(meta.month),int(meta.day),shaid,meta.publish_time]\n        try:\n            drugs_data[d].append(info)\n        except:\n            drugs_data[d] = []\n            drugs_data[d].append(info)\n            \ndrugs=[i for i in drugs if len(i)>MIN_LENGTH]\ndrugs_set=list(set(drugs))\ndrugs_set=sorted(drugs_set)","b58acda4":"THRESH=2 #Threshold for the Levenshtein distance\nincorrects=[]\ncorrects=[]\nfrom itertools import combinations\nfor str1,str2 in combinations(drugs_set,2):\n    if (distance.levenshtein(str1, str2)<THRESH) and (drugs.count(str1)>10 or drugs.count(str2)>10):\n            if drugs.count(str1)>drugs.count(str2):\n                incorrect=str2\n                correct=str1\n            else:\n                incorrect=str1\n                correct=str2\n            print(str1, \"(\",drugs.count(str1),\")\", \"and\", str2, \"(\",drugs.count(str2),\")\", \"look very similar. I will substitute\", incorrect, \"with\", correct)\n            if incorrect not in incorrects:\n                incorrects.append(incorrect)\n                corrects.append(correct)\nfor item in incorrects:\n    drugs_set.remove(item)","8d3e11b9":"len(drugs_set)","b73ded8e":"for shaid in valid_id:\n    for inc in range(0,len(incorrects)):\n        re.sub(incorrects[inc],corrects[inc], Texts[shaid])","23c7dc2b":"MAXPLOT=20 #plot the MAXPLOT most mentioned antivirals\ncs=[]\nfor item in drugs_set:\n    cs.append(drugs.count(item))\ncs=np.array(cs)\nplt.figure(figsize=(20,5))\nplt.bar(np.array(drugs_set)[(-cs).argsort()[:MAXPLOT]], cs[(-cs).argsort()[:MAXPLOT]])\nplt.xticks(rotation=90,fontsize=15)\nplt.yticks(fontsize=15)\nplt.ylabel(\"Counts\", fontsize=15)\nplt.show()","d6ec1b0c":"def plot_drug(a,sx):\n    dd = drugs_data[a]\n\n    df = pd.DataFrame.from_dict(dd)\n    df.columns=[\"year\", \"month\", \"day\", \"sha\",\"publish_time\"]\n    x = (df[\"year\"]).astype(str)+\"-\"+(df[\"month\"]).astype(str)+\"-\"+(df[\"day\"]).astype(str)\n    try:\n        df['date']=pd.to_datetime(x)\n\n        k = df.groupby(['sha','date']).size().reset_index(name='Size')\n         \n        kk = k[['date','Size']] \n        #plt.scatter(kk['date'], kk['Size'] ,s=250,label=a)\n        # plt.plot(kk['date'], kk['Size'],'o--',linewidth=.1, markersize=10+sx ,label=a)\n        plt.plot(kk['date'], [sx+1]*len(kk['date']),'o--',linewidth=.1, markersize=33 ,label=a)\n    except:        \n        pass\n ","82c13545":"MAXPLOT=20 #plot the MAXPLOT most mentioned antivirals\ncs = []\nfor item in drugs_set:\n    cs.append(drugs.count(item))\ncs = np.array(cs)\n\na = np.array(drugs_set)[(-cs).argsort()[:MAXPLOT]]\n\nplt.figure(figsize=(50,15))\n\ncnt=0\nfor a_itr in a:\n    cnt+=1\n    plot_drug(a_itr,(MAXPLOT-cnt))\nplt.xticks(rotation=90,fontsize=25)\nplt.yticks(fontsize=25)\nplt.legend()\nplt.legend(loc=1, prop={'size': 25})\nplt.grid(True)\nplt.show()\n","d2c72309":"metadata[metadata['sha']==shaid]","9174cf5a":"Texts[shaid]","015bfeb9":"At least 127 different antivirals are mentioned in the CORD-19 database. It would be interesting to have an automated way to assess which of these therapies are successful and which are not. If you know an efficient way to do that, let me know in the comments!","36c0f9f3":"# Data preparation","cf165d32":"According to the standard drug nomenclature (https:\/\/en.wikipedia.org\/wiki\/Drug_nomenclature), the names for antivirals have the suffix *-vir*. ","ab3203aa":"# Looking for misspellings","7480e18b":"There is an issue with the date. Using the publish_time is not the date we should use to understand when the data\/information was collected. **Does someone have any idea how to overcome this problem? **","5685e43d":"# Conclusions","ec97ebc4":"# Looking for antivirals","ba44701b":"As medical doctors are busy saving lives, data scientists can help them navigate through the mole of recent literature on COVID-19 to access quickly and efficiently new approaches and new therapies. This simple notebook searches for the most mentioned names of antivirals in the CORD-19 database.","60b0129e":"Curiously, some names look very similar to each other, and are most likely typos or different spellings. Here I look for the \"similarity\" between pairs of words via the Levenshtein distance (https:\/\/en.wikipedia.org\/wiki\/Levenshtein_distance). If the distance is smaller than THRESH, I regard the names as equivalent and retain the spelling with most entries.","87861f85":"Now drugs_set contains the set of antiviral names.","5fe8bebf":"This substitues the correct spellings in the bodies of text:","0e5e76ca":"# Results"}}