{"cell_type":{"e6f76662":"code","ca4452e3":"code","cf26c001":"code","d1607f6f":"code","cd1909d1":"code","3b1ec786":"code","252cf00e":"code","e18918d3":"code","03a7daf3":"code","4e2bc0e0":"code","eb052e75":"code","4ffe3f3e":"code","ee82ffa7":"code","47f25312":"code","f8f57278":"code","fb2d3e60":"code","befb16e0":"code","67970588":"code","32cb4bfb":"code","b5e6a4ed":"code","86d7ab56":"code","8596d65b":"code","7a64ad7b":"code","125d2b38":"code","a788caef":"code","0d9ae1fd":"code","bc8552a2":"code","55c4fbff":"code","f4138bab":"markdown"},"source":{"e6f76662":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca4452e3":"path_to_data = '\/kaggle\/input\/doom-crossing\/'\npath_to_doom = '\/kaggle\/input\/doom-crossing\/doom\/'\npath_to_animal = '\/kaggle\/input\/doom-crossing\/animal_crossing\/'\n\nimg_dirs = []\nfor entry in os.scandir(path_to_data):\n    if entry.is_dir():\n        img_dirs.append(entry.path)\nimg_dirs","cf26c001":"import matplotlib.pyplot as plt","d1607f6f":"image = plt.imread('\/kaggle\/input\/doom-crossing\/animal_crossing\/5fqz3vkvw8q41.jpg')\nplt.imshow(image)","cd1909d1":"doom_dict = {}\nfor img_dir in img_dirs:\n    doom_name = img_dir.split('\/')[-1]\n    file_list = []\n    for entry in os.scandir(img_dir):\n        file_list.append(entry.path)\n    doom_dict[doom_name] = file_list\ndoom_dict","3b1ec786":"class_dict = {}\ncount = 0\nfor doom_name in doom_dict.keys():\n    class_dict[doom_name] = count\n    count = count + 1\nclass_dict","252cf00e":"import cv2\nimport pywt","e18918d3":"img = cv2.imread('\/kaggle\/input\/doom-crossing\/animal_crossing\/3xfc3u4woq051.jpg')\nscalled_img = cv2.resize(img, (200, 200))\nplt.imshow(scalled_img)","03a7daf3":"def w2d(img, mode=None, level=1):\n    imArray = img\n    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n    imArray =  np.float32(imArray)   \n    imArray \/= 255;\n\n    coeffs=pywt.wavedec2(imArray, mode, level=level)\n\n    coeffs_H=list(coeffs)  \n    coeffs_H[0] *= 0;  \n    \n    imArray_H=pywt.waverec2(coeffs_H, mode);\n    imArray_H *= 255;\n    imArray_H =  np.uint8(imArray_H)\n\n    return imArray_H","4e2bc0e0":"X, y = [], []\nfor doom_name, training_files in doom_dict.items():\n    for training_image in training_files:\n        img = cv2.imread(training_image)\n        scalled_raw_img = cv2.resize(img, (200, 200))\n        img_har = w2d(img,'db1',5)\n        scalled_img_har = cv2.resize(img_har, (200, 200))\n        combined_img = np.vstack((scalled_raw_img.reshape(200*200*3,1),scalled_img_har.reshape(200*200,1)))\n        X.append(combined_img)\n        y.append(class_dict[doom_name])","eb052e75":"len(X[0])","4ffe3f3e":"X = np.array(X).reshape(len(X),len(X[0])).astype(float)\nX.shape","ee82ffa7":"from sklearn.model_selection import train_test_split","47f25312":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","f8f57278":"X_train.shape","fb2d3e60":"X_train = X_train.reshape(len(X_train), 200, 200, 4)\nX_test = X_test.reshape(len(X_test), 200, 200, 4)\ny_train = np.asarray(y_train)\ny_test = np.asarray(y_test)","befb16e0":"X_train.shape","67970588":"X_test.shape","32cb4bfb":"X_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","b5e6a4ed":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport keras","86d7ab56":"model = Sequential()\n\n#-- 1 layer -- \nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=(200, 200, 4)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n#-- 2 layer -- \nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n#-- 3 layer -- \nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n#-- 4 layer -- \nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","8596d65b":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","7a64ad7b":"model.fit(X_train, y_train, batch_size=32, epochs=5, shuffle=True)","125d2b38":"X_test","a788caef":"model.evaluate(X_test, y_test)","0d9ae1fd":"from sklearn.linear_model import LogisticRegression","bc8552a2":"X_train = X_train.reshape(len(X_train), 200*200*4)\nX_test = X_test.reshape(len(X_test), 200*200*4)","55c4fbff":"lr = LogisticRegression(max_iter=1000)\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","f4138bab":"For further optimization you can tune hyperparameters "}}