{"cell_type":{"49f806fe":"code","d1017966":"code","ceb643f5":"code","a3a03aca":"code","6ce3bb20":"code","a3369cf8":"code","5f6e770f":"code","827ab427":"code","e03cc8ea":"code","9e1d6b18":"code","93760f94":"code","7ce49da7":"code","e6b9fc2a":"code","fdca089e":"code","b7c99277":"code","13629396":"code","7e8f15de":"code","9d8c9f40":"code","3ecaacae":"code","72923899":"code","b3017be5":"code","d8690109":"code","e2534447":"code","ab6712e5":"code","586364f5":"code","738a5738":"code","d9ecc6f5":"code","0e511540":"code","70cd8541":"code","d8d1d425":"code","a8e79aee":"code","4f189af0":"code","2472276e":"code","10cfa201":"code","7164a6a5":"code","b46d866b":"code","f6b2d261":"code","0f496574":"code","9618ea24":"code","05db647d":"code","096cf97b":"code","e25867c6":"code","4864c714":"code","1c44f349":"code","9af17767":"code","83ae1304":"code","a95754dd":"code","4457759f":"code","fd96ce0a":"code","53a1d066":"code","fc92a385":"code","d5f8abff":"code","6caeebd9":"code","442ab67c":"code","bfe41e75":"code","1811d3be":"code","5d58f572":"code","75dc83e4":"markdown","6eb010c5":"markdown","e8bdac41":"markdown","5338c476":"markdown","a9beb776":"markdown","63842d06":"markdown","c1eb44a1":"markdown","a825df52":"markdown","af0df607":"markdown","68352890":"markdown","4208005d":"markdown","4a7a17dc":"markdown"},"source":{"49f806fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1017966":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import VotingRegressor\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 10000)\npd.set_option('display.max_rows', 10000)","ceb643f5":"df_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","a3a03aca":"df_train.info()","6ce3bb20":"y     = df_train[['Id','SalePrice']]\ndf_train = df_train.drop('SalePrice',axis=1)","a3369cf8":"concat_df = [df_train,df_test]\ndf_all = pd.concat(concat_df).reset_index(drop=True)","5f6e770f":"df_all.info()","827ab427":"df_dummy = pd.get_dummies(df_all['MSZoning'],prefix='MSZoning',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['MSZoning']","e03cc8ea":"df_all['LotFrontage'] = df_all['LotFrontage'].fillna(df_all['LotFrontage'].mean())","9e1d6b18":"def LotFrontage(n):\n    if (n > 21) & (n < 50):\n        return 1\n    elif (n > 50) & (n <= 70):\n        return 2\n    elif (n > 70) & (n <= 75):\n        return 3\n    elif (n > 75) & (n <= 80):\n        return 4\n    elif (n > 80) & (n <= 90):\n        return 5\n    elif (n > 100) & (n <= 120):\n        return 6\n    elif (n > 120) & (n <= 140):\n        return 7\n    elif (n > 140) & (n <= 160):\n        return 8\n    elif (n > 160) & (n <= 180):\n        return 9\n    elif (n > 180) & (n <= 200):\n        return 9\n    else:\n        return 10","93760f94":"df_all['LotFrontage'] = df_all['LotFrontage'].apply(LotFrontage)","7ce49da7":"df_dummy = pd.get_dummies(df_all['Neighborhood'],prefix='Neighborhood',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['Neighborhood']","e6b9fc2a":"df_all['Exterior2nd'] = df_all['Exterior2nd'].fillna('Other')\ndf_dummy = pd.get_dummies(df_all['Exterior2nd'],prefix='Exterior2nd',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['Exterior2nd']","fdca089e":"df_dummy = pd.get_dummies(df_all['Utilities'],prefix='Utilities',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['Utilities']","b7c99277":"df_dummy = pd.get_dummies(df_all['LandContour'],prefix='LandContour',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['LandContour']","13629396":"df_dummy = pd.get_dummies(df_all['Condition1'],prefix='Condition1',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['Condition1']","7e8f15de":"def Condition2(c):\n    if c == 'Norm':\n        return 1\n    elif c == 'Feedr':\n        return 2\n    elif c == 'PosA':\n        return 3\n    elif c == 'PosN':\n        return 4\n    elif c == 'Artery':\n        return 5\n    else:\n        return 0","9d8c9f40":"df_all['Condition2'] = df_all['Condition2'].apply(Condition2).astype(int)","3ecaacae":"df_dummy = pd.get_dummies(df_all['BldgType'],prefix='BldgType',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['BldgType']","72923899":"df_dummy = pd.get_dummies(df_all['HouseStyle'],prefix='HouseStyle',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['HouseStyle']","b3017be5":"df_dummy = pd.get_dummies(df_all['RoofMatl'],prefix='RoofMatl',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['RoofMatl']","d8690109":"df_all['Exterior1st']= df_all['Exterior1st'].fillna('Other')","e2534447":"def Exterior1st(c):\n    if c == 'VinylSd':\n        return 1\n    elif c == 'Wd Sdng':\n        return 2\n    elif c == 'HdBoard':\n        return 3\n    elif c == 'Plywood':\n        return 4\n    elif c == 'MetalSd':\n        return 5\n    elif c == 'CemntBd':\n        return 6\n    elif c == 'WdShing':\n        return 7\n    elif c == 'BrkFace':\n        return 8\n    elif c == 'AsbShng':\n        return 9\n    else:\n        return 0","ab6712e5":"df_all['Exterior1st'] = df_all['Exterior1st'].apply(Exterior1st).astype(int)","586364f5":"def BsmtFinSF1(n):\n    if (n > -1) & (n <= 150):\n        return 1\n    elif (n > 150) & (n <= 300):\n        return 2\n    elif (n > 300) & (n <= 450):\n        return 3\n    elif (n > 450) & (n <= 600):\n        return 4\n    elif (n > 600) & (n <= 750):\n        return 5\n    else:\n        return 10","738a5738":"df_all['BsmtFinSF1'] = df_all['BsmtFinSF1'].apply(BsmtFinSF1).astype(int)","d9ecc6f5":"def MasVnrArea(n):\n    if (n > -1) & (n <= 150):\n        return 1\n    elif (n > 150) & (n <= 200):\n        return 2\n    elif (n > 200) & (n <= 300):\n        return 3\n    else:\n        return 0","0e511540":"df_all['MasVnrArea'] = df_all['MasVnrArea'].apply(MasVnrArea).astype(int)","70cd8541":"df_dummy = pd.get_dummies(df_all['ExterQual'],prefix='ExterQual',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['ExterQual']","d8d1d425":"df_dummy = pd.get_dummies(df_all['ExterCond'],prefix='ExterCond',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['ExterCond']","a8e79aee":"df_all['BsmtQual'] = df_all['BsmtQual'].fillna('TA')\ndf_dummy = pd.get_dummies(df_all['BsmtQual'],prefix='BsmtQual',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['BsmtQual']","4f189af0":"df_all['BsmtCond'] = df_all['BsmtCond'].fillna('TA')\ndf_dummy = pd.get_dummies(df_all['BsmtCond'],prefix='BsmtCond',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['BsmtCond']","2472276e":"df_all['BsmtExposure'] = df_all['BsmtExposure'].fillna('TA')\ndf_dummy = pd.get_dummies(df_all['BsmtExposure'],prefix='BsmtExposure',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['BsmtExposure']","10cfa201":"def Functional(f):\n    if f == 'Typ':\n        return 1\n    elif f == 'Min1':\n        return 2\n    elif f == 'Min2':\n        return 3\n    elif f == 'Mod':\n        return 4\n    elif f == 'Maj1':\n        return 5\n    elif f == 'Maj2':\n        return 6\n    elif f == 'Sev':\n        return 7\n    elif f == 'Sal':\n        return 8\n    else:\n        return 0","7164a6a5":"df_all['Functional'] = df_all['Functional'].apply(Functional).astype(int)","b46d866b":"df_dummy = pd.get_dummies(df_all['GarageType'],prefix='GarageType',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['GarageType']","f6b2d261":"df_dummy = pd.get_dummies(df_all['SaleType'],prefix='SaleType',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['SaleType']","0f496574":"df_dummy = pd.get_dummies(df_all['SaleCondition'],prefix='SaleCondition',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['SaleCondition']","9618ea24":"df_dummy = pd.get_dummies(df_all['Heating'],prefix='Heating',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['Heating']","05db647d":"df_dummy = pd.get_dummies(df_all['KitchenQual'],prefix='KitchenQual',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['KitchenQual']","096cf97b":"df_all['GarageQual'] = df_all['GarageQual'].fillna('TA')\ndf_dummy = pd.get_dummies(df_all['GarageQual'],prefix='GarageQual',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['GarageQual']","e25867c6":"df_dummy = pd.get_dummies(df_all['Foundation'],prefix='Foundation',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['Foundation']","4864c714":"df_dummy = pd.get_dummies(df_all['GarageCond'],prefix='GarageCond',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['GarageCond']","1c44f349":"df_dummy = pd.get_dummies(df_all['PavedDrive'],prefix='PavedDrive',dummy_na=True)\ndf_all = pd.concat([df_all,df_dummy],axis=1)\ndel df_all['PavedDrive']","9af17767":"df_all['GarageYrBlt']= df_all['GarageYrBlt'].fillna('2003').astype(int)\ndf_all['TotalBsmtSF'] = df_all['TotalBsmtSF'].fillna('1305').astype(int)\ndf_all['BsmtFullBath'] = df_all['BsmtFullBath'].fillna('0').astype(int)\ndf_all['BsmtHalfBath'] = df_all['BsmtHalfBath'].fillna('0').astype(int)\ndf_all['GarageCars'] = df_all['GarageCars'].fillna('2').astype(int)\ndf_all['GarageArea'] = df_all['GarageArea'].fillna('420').astype(int)\ndf_all['PoolArea']=df_all['PoolArea'].astype(int)","83ae1304":"df_all =df_all.drop(['YrSold','MoSold','MiscVal','PoolQC','ScreenPorch','3SsnPorch','EnclosedPorch',\n                     'KitchenAbvGr','CentralAir','Alley','LotConfig','LotShape','LandSlope','RoofStyle',\n                     'BsmtFinSF2','BsmtUnfSF','HeatingQC','Electrical','BsmtFinType2','BsmtFinType1',\n                     'GarageFinish','MiscFeature','FireplaceQu','Fence','Alley','Street','MasVnrType'], axis = 1)","a95754dd":"Scaler = StandardScaler()\nall_scaled = pd.DataFrame(Scaler.fit_transform(df_all))\n\ntrain_scaled = pd.DataFrame(all_scaled[:1460])\ntest_scaled = pd.DataFrame(all_scaled[1460:2920])","4457759f":"X_train = train_scaled\ny_train = y['SalePrice']\nX_train, X_test, y_train, y_test = train_test_split(\n    X_train, y_train, test_size=0.15, random_state=0)","fd96ce0a":"XGBoost\nparam_xgb = {\"max_depth\": [1,3,5,10,100],\n             \"learning_rate\" : [0.0001,0.001,0.01],\n             \"min_child_weight\" : [1, 3, 5, 10],\n             \"n_estimators\": [1, 10, 100, 1000],\n             \"subsample\": [0.5,0.75,0.9],\n             \"gamma\":[0,0.1,0.2],\n             \"eta\": [0.3,0.15,0.10]}\n\ngs_xgb = GridSearchCV(XGBRegressor(),\n                      param_xgb,\n                      cv=4,#cross validation\n                      verbose=True,#Display Logs\n                      n_jobs=-1)#Multi Tasking\ngs_xgb.fit(X_train, y_train)\n \nprint(gs_xgb.best_estimator_)","53a1d066":"LightGBM\nparam_lgb = {\"max_depth\": [1, 3, 5, 10, 25, 50, 75],\n             \"learning_rate\" : [0.001,0.01,0.05,0.1],\n             \"num_leaves\": [1, 10, 100,1000],\n             \"n_estimators\": [1, 3, 10, 100, 1000]}\n\ngs_lgb = GridSearchCV(LGBMRegressor(),\n                      param_lgb,\n                      cv=4,#cross validation\n                      verbose=True,#Display Logs\n                      n_jobs=-1)#Multi Tasking\ngs_lgb.fit(X_train, y_train)\n\nprint(gs_lgb.best_estimator_)","fc92a385":"XGB = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                   colsample_bynode=1, colsample_bytree=1, eta=0.3, gamma=0,\n                   gpu_id=-1, importance_type='gain', interaction_constraints='',\n                   learning_rate=0.01, max_delta_step=0, max_depth=5,\n                   min_child_weight=1,monotone_constraints='()',n_estimators=1000,\n                   n_jobs=0, num_parallel_tree=1, random_state=0,\n                   reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.5,\n                   tree_method='exact', validate_parameters=1, verbosity=None)\nXGB.fit(X_train,y_train)","d5f8abff":"model_lgb = LGBMRegressor(learning_rate=0.05, max_depth=3, n_estimators=1000, num_leaves=10)\nmodel_lgb.fit(X_train , y_train)","6caeebd9":"votingC = VotingRegressor(estimators=[('xgb_r', XGB),('lgb_r', model_lgb)],n_jobs=4)\n\nvotingC = votingC.fit(X_train, y_train)","442ab67c":"print (\"Training score:\",XGB.score(X_train,y_train),\"Test Score:\",XGB.score(X_test,y_test))\nprint (\"Training score:\",model_lgb.score(X_train,y_train),\"Test Score:\",model_lgb.score(X_test,y_test))\nprint (\"Training score:\",votingC.score(X_train,y_train),\"Test Score:\",votingC.score(X_test,y_test))","bfe41e75":"y_pred_voting = pd.DataFrame(votingC.predict(test_scaled))","1811d3be":"y_pred=pd.DataFrame()\ny_pred['SalePrice'] = y_pred_voting[0]\ny_pred['Id'] = df_test['Id']","5d58f572":"y_pred.to_csv('submission.csv',index=False)","75dc83e4":"Import modules. Please install pip.\n>pip install lightgbm<br>\n>pip install xgboost<br>\n>pip install scikit-learn","6eb010c5":"<h2>Concat train-test data<\/h2><br>\nIt makes easy to data clearning.<br>\nWhile coding, there are much errors.<br>\nIt is not match demension between train and test.<br>\n\"Thinking demension\" is very important keys to code and fix.<br>\nPlease be careful.","e8bdac41":"<h2>Hi, Kagglers<\/h2>\n\nThank you for your upvotes(previous notebook is here([Titanic's](https:\/\/www.kaggle.com\/vet516lec\/titanic-lgbm-xgboost-parameter-tuning\/comments))). I'm really happy.<br>\n\n<h3>If you like, Please upvote!<\/h3>","5338c476":"<h2>Grid Search<\/h2><br>\nI did GridSearch but it haste time about 14hours!! Here is GridSearch code.","a9beb776":"<h2>Check data<\/h2>","63842d06":"<h2>Submit result<\/h2>","c1eb44a1":"<h2>If you like, please upvote!<\/h2>","a825df52":"<h2>Ensemble<\/h2>\nVoting = (XGBoost + LightGBM)\n","af0df607":"<h2>Prepare to submit labels<\/h2>","68352890":"<h2>Separate Train Test data.<\/h2>","4208005d":"<h2>Data Clearning<\/h2>\nUsing dummy function.<br>\nSome are using label encoder(Handmade!)\n","4a7a17dc":"<h2>Check Score<\/h2>"}}