{"cell_type":{"d0e50057":"code","d978d070":"code","41dd7bea":"code","b51294ca":"code","fbb12a0b":"code","53a4e1f8":"code","8c60b650":"code","c57b3597":"code","4fdf87fb":"code","12e35fb2":"code","c12558fe":"code","beecf6ea":"code","7063ff76":"code","d32ebb8e":"code","91b53a46":"code","194c57a8":"code","dfc370b7":"code","84b8cb07":"code","bd179397":"code","2993cadb":"code","6b82fe9b":"code","b9a164a2":"code","01ece13f":"code","a59d5e67":"code","37b3a190":"code","6eb44418":"code","3c2f6793":"code","b8e8f0d7":"code","0abaa510":"code","ab7ae456":"code","17f96c04":"code","817d3d50":"code","4db6ef56":"code","7db4a2b3":"code","f59e1f6a":"code","bd0d2a20":"code","fa5b4811":"markdown","5118bcef":"markdown","a0c6b2e2":"markdown","8c27db7e":"markdown","1413dc50":"markdown","6e448d83":"markdown","cb92a98c":"markdown","c4267726":"markdown","72e1d0a1":"markdown","2c18afcd":"markdown","a8386078":"markdown"},"source":{"d0e50057":"import warnings\nwarnings.filterwarnings('ignore')\n\n%load_ext autoreload\n%autoreload 2\n\nimport sys\nsys.path.append('..')\n\nimport sys\n\nIN_COLAB = 'google.colab' in sys.modules\nREPO_DIR = '..' if IN_COLAB  else '..'","d978d070":"!git clone https:\/\/github.com\/google-research\/graph-attribution.git --quiet\n    \nimport sys\nsys.path.insert(1, '\/kaggle\/working\/graph-attribution')","41dd7bea":"!pip install tensorflow tensorflow-probability -q\n!pip install dm-sonnet -q\n!pip install graph_nets \"tensorflow>=2.1.0-rc1\" \"dm-sonnet>=2.0.0b0\" tensorflow_probability\n!pip install git+https:\/\/github.com\/google-research\/graph-attribution -quiet","b51294ca":"!pip install git+https:\/\/github.com\/google-research\/graph-attribution","fbb12a0b":"import os\nimport itertools\nimport collections\nimport tqdm.auto as tqdm\n\nfrom IPython.display import display\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\nimport tensorflow as tf\nimport sonnet as snt\nimport graph_nets\nfrom graph_nets.graphs import GraphsTuple\nimport graph_attribution as gatt\n\nfrom tqdm import tqdm\n\nimport time\n\nimport networkx as nx\n\n# Ignore tf\/graph_nets UserWarning:\n# Converting sparse IndexedSlices to a dense Tensor of unknown shape\nimport warnings\nwarnings.simplefilter(\"ignore\", UserWarning)\n\nfor mod in [tf, snt, gatt]:\n    print(f'{mod.__name__:20s} = {mod.__version__}')","53a4e1f8":"from graph_attribution import tasks\nfrom graph_attribution import graphnet_models as gnn_models\nfrom graph_attribution import graphnet_techniques as techniques\nfrom graph_attribution import datasets\nfrom graph_attribution import experiments\nfrom graph_attribution import templates\nfrom graph_attribution import graphs as graph_utils\n\n#datasets.DATA_DIR = os.path.join(REPO_DIR, 'data')\n#print(f'Reading data from: {datasets.DATA_DIR}')\n\ndatasets.DATA_DIR = '.\/graph-attribution\/data'","8c60b650":"print(f'Available tasks: {[t.name for t in tasks.Task]}')\nprint(f'Available model types: {[m.name for m in gnn_models.BlockType]}')\nprint(f'Available ATT techniques: {list(techniques.get_techniques_dict(None,None).keys())}')","c57b3597":"task_type = 'logic7'\nblock_type = 'gcn'\n\n#task_dir = datasets.get_task_dir(task_type)\ntask_dir = '.\/graph-attribution\/data\/logic7'\nexp, task, methods = experiments.get_experiment_setup(task_type, block_type)\ntask_act, task_loss = task.get_nn_activation_fn(), task.get_nn_loss_fn()\ngraph_utils.print_graphs_tuple(exp.x_train)\nprint(f'Experiment data fields:{list(exp.__dict__.keys())}')","4fdf87fb":"hp = gatt.hparams.get_hparams({'block_type':block_type, 'task_type':task_type})\nhp","12e35fb2":"model = experiments.GNN(node_size = hp.node_size,\n               edge_size = hp.edge_size,\n               global_size = hp.global_size,\n               y_output_size = task.n_outputs,\n               block_type = gnn_models.BlockType(hp.block_type),\n               activation = task_act,\n               target_type = task.target_type,\n               n_layers = hp.n_layers)\nmodel(exp.x_train)\ngnn_models.print_model(model)","c12558fe":"optimizer = snt.optimizers.Adam(hp.learning_rate)\n\nopt_one_epoch = gatt.training.make_tf_opt_epoch_fn(exp.x_train, exp.y_train, hp.batch_size, model,\n                                      optimizer, task_loss)\n\npbar = tqdm(range(hp.epochs))\nlosses = collections.defaultdict(list)\nstart_time = time.time()\nfor _ in pbar:\n    train_loss = opt_one_epoch(exp.x_train, exp.y_train).numpy()\n    losses['train'].append(train_loss)\n    losses['test'].append(task_loss(exp.y_test, model(exp.x_test)).numpy())\n    #pbar.set_postfix({key: values[-1] for key, values in losses.items()})\n\nlosses = {key: np.array(values) for key, values in losses.items()}","beecf6ea":"# Plot losses\nfor key, values in losses.items():\n    plt.plot(values, label=key)\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend()\nplt.show()","7063ff76":"y_pred = model(exp.x_test).numpy()\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred <= 0.5] = 0\n#y_pred\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nprint(accuracy_score(exp.y_test, y_pred))\n\nprint(confusion_matrix(exp.y_test, y_pred))\n\nprint(classification_report(exp.y_test, y_pred))","d32ebb8e":"# Evaluate predictions and attributions\nresults = []\nfor method in tqdm(methods.values(), total=len(methods)):\n    results.append(experiments.generate_result(model, method, task, exp.x_test, exp.y_test, exp.att_test))\npd.DataFrame(results)","91b53a46":"# Source: https:\/\/notebook.community\/deepmind\/graph_nets\/graph_nets\/demos\/graph_nets_basics\ngraphs_nx = graph_nets.utils_np.graphs_tuple_to_networkxs(exp.x_test)\n\ndef nx_g_plotter(graphs_nx, ColNum=8, node_clr='#ff8080'):\n    _, axs = plt.subplots(ncols=ColNum, nrows = 1, figsize=(30, 5))\n    for iax, (graph_nx2, ax) in enumerate(zip(graphs_nx, axs)):\n        nx.draw(graph_nx2, ax=ax, node_color=node_clr)\n        ax.set_title(\"Graph {}\".format(iax))","194c57a8":"graphs_nx_1 = []\ngraphs_nx_0 = []\n\nfor ii, g_net_ii in enumerate(graphs_nx):\n    if exp.y_test[ii] == 1:\n        graphs_nx_1.append(g_net_ii)\n    else:\n        graphs_nx_0.append(g_net_ii)\n        \nnx_g_plotter(graphs_nx_1, ColNum=8, node_clr='#ff8080')\nnx_g_plotter(graphs_nx_0, ColNum=8, node_clr='#00bfff')","dfc370b7":"graphs_nx_wrong0 = []\ngraphs_nx_wrong1 = []\ngraphs_nx_correct0 = []\ngraphs_nx_correct1 = []\n\ny_pred2 = model(exp.x_test).numpy()\n\ny_wrong0 = []\ny_wrong1 = []\ny_correct0 = []\ny_correct1 = []\n\nfor ii, g_net_ii in enumerate(graphs_nx):\n    if exp.y_test[ii] != y_pred[ii] and exp.y_test[ii] == 0:\n        graphs_nx_wrong0.append(g_net_ii)\n        y_wrong0.append(y_pred2[ii])\n    elif exp.y_test[ii] != y_pred[ii] and exp.y_test[ii] == 1:\n        graphs_nx_wrong1.append(g_net_ii)\n        y_wrong1.append(y_pred2[ii])\n    elif exp.y_test[ii] == y_pred[ii] and exp.y_test[ii] == 0:\n        graphs_nx_correct0.append(g_net_ii)\n        y_correct0.append(y_pred2[ii])\n    elif exp.y_test[ii] == y_pred[ii] and exp.y_test[ii] == 1:\n        graphs_nx_correct1.append(g_net_ii)\n        y_correct1.append(y_pred2[ii])\n        \nprint(len(graphs_nx_wrong0), len(graphs_nx_wrong1), len(graphs_nx_correct0), len(graphs_nx_correct1))\n\nnx_g_plotter(graphs_nx_wrong0, ColNum=8, node_clr='#ff8080')\nnx_g_plotter(graphs_nx_wrong1, ColNum=8, node_clr='#00bfff')\nnx_g_plotter(graphs_nx_correct0, ColNum=8, node_clr='#00e600')\nnx_g_plotter(graphs_nx_correct1, ColNum=8, node_clr='#e600ac')","84b8cb07":"y_yes = exp.y_test[exp.y_test == 1]\ny_no = exp.y_test[exp.y_test != 1]\ny_yes.shape, y_no.shape","bd179397":"recovered_data_dict_list = graph_nets.utils_np.graphs_tuple_to_data_dicts(exp.x_test)\n\ngraphs_tuple_1 = graph_nets.utils_np.data_dicts_to_graphs_tuple(recovered_data_dict_list)","2993cadb":"!git clone https:\/\/github.com\/msarrias\/graph-distance-for-complex-networks --quiet\n\nimport sys\nsys.path.insert(1, '\/kaggle\/working\/graph-distance-for-complex-networks')","6b82fe9b":"import numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.ticker import MultipleLocator\nimport scipy.linalg as la\nimport networkx as nx\nimport random, time, math\nfrom collections import Counter\n\nimport fun as f\nfrom Graph import Graph\nfrom Watts_Strogatz import watts_strogatz_graph\nfrom Erdos_Renyi import erdos_renyi_graph\n\ndef Wasserstein_Dist(cdfX, cdfY):\n  \n    Res = 0\n    power = 1\n    n = len(cdfX)\n\n    for ii in range(0, n-2):\n        height = abs(cdfX[ii]-cdfY[ii])\n        width = cdfX[ii+1] - cdfX[ii]\n        Res = Res + (height ** power) * width \n \n    return Res\n\n\ndef r_eigenv(G_i, G_j):\n    #Eigen-decomposition of G_j\n    A_Gi = (nx.adjacency_matrix(G_i)).todense()\n    D_i = np.diag(np.asarray(sum(A_Gi))[0])\n    eigenvalues_Gi, eigenvectors_Gi = la.eig(D_i - A_Gi)\n    r_eigenv_Gi = sorted(zip(eigenvalues_Gi.real, eigenvectors_Gi.T), key=lambda x: x[0])\n\n    #Eigen-decomposition of G_j\n    A_Gj = (nx.adjacency_matrix(G_j)).todense()\n    D_j = np.diag(np.asarray(sum(A_Gj))[0])\n    eigenvalues_Gj, eigenvectors_Gj = la.eig(D_j - A_Gj)\n    r_eigenv_Gj = sorted(zip(eigenvalues_Gj.real, eigenvectors_Gj.T), key=lambda x: x[0])\n    \n    r = 4\n    signs =[-1,1]\n    temp = []\n    for  sign_s in signs:\n        for sign_l in signs:\n            vri = sorted(f.normalize_eigenv(sign_s * r_eigenv_Gi[r][1]))\n            vrj = sorted(f.normalize_eigenv(sign_l * r_eigenv_Gj[r][1]))\n            cdf_dist = f.cdf_dist(vri, vrj)\n            temp.append(cdf_dist)\n    \n    #Compute empirical CDF\n    step = 0.005\n    x=np.arange(0, 1, step)\n    cdf_grid_Gip = f.cdf(len(r_eigenv_Gi[r][1]),x,\n                   f.normalize_eigenv(sorted(r_eigenv_Gi[r][1], key=lambda x: x)))\n    cdf_grid_Gin = f.cdf(len(r_eigenv_Gi[r][1]),x,\n                   f.normalize_eigenv(sorted(-r_eigenv_Gi[r][1], key=lambda x: x)))\n\n    cdf_grid_Gjp = f.cdf(len(r_eigenv_Gj[r][1]),x,\n                   f.normalize_eigenv(sorted(r_eigenv_Gj[r][1], key=lambda x: x)))\n    cdf_grid_Gjn = f.cdf(len(r_eigenv_Gj[r][1]),x,\n                   f.normalize_eigenv(sorted(-r_eigenv_Gj[r][1], key=lambda x: x)))\n    \n    WD1 = Wasserstein_Dist(cdf_grid_Gip, cdf_grid_Gjp)\n    WD2 = Wasserstein_Dist(cdf_grid_Gip, cdf_grid_Gjn)\n    WD3 = Wasserstein_Dist(cdf_grid_Gin, cdf_grid_Gjp)\n    WD4 = Wasserstein_Dist(cdf_grid_Gin, cdf_grid_Gjn)\n\n    WD = [WD1, WD2, WD3, WD4]\n    \n    return max(temp), max(WD)\n\ndistt_wrong1_correct1 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_correct1)))\nWDist_wrong1_correct1 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_correct1)))\nConf_W1_C1 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_correct1)))\n\nfor ii, g_net_ii in enumerate(graphs_nx_wrong1):\n    for jj, g_net_jj in enumerate(graphs_nx_correct1):\n        distt_wrong1_correct1[ii,jj], WDist_wrong1_correct1[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n        Conf_W1_C1[ii,jj] = y_correct1[jj] - y_wrong1[ii]\n\n\nimport seaborn as sns; sns.set_theme()\n\n#ax = sns.heatmap(distt)\n#ax = sns.displot(distt_wrong1_correct1.flatten())","b9a164a2":"df = pd.DataFrame()\ndf['WDist_W1_C1'] = WDist_wrong1_correct1.flatten()\ndf['Conf_W1_C1'] = Conf_W1_C1.flatten()\n\nsns.scatterplot(data=df, x=\"Conf_W1_C1\", y=\"WDist_W1_C1\")","01ece13f":"graphs_nx_train = graph_nets.utils_np.graphs_tuple_to_networkxs(exp.x_train)\n\ngraphs_nx_train_1 = []\ngraphs_nx_train_0 = []\n\nfor ii, g_net_ii in enumerate(graphs_nx_train):\n    if exp.y_train[ii] == 1:\n        graphs_nx_train_1.append(g_net_ii)\n    else:\n        graphs_nx_train_0.append(g_net_ii)\n\n\ndistt_wrong1_train1 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_train_1)))\nWDist_wrong1_train1 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_train_1)))\n\nfor ii, g_net_ii in enumerate(graphs_nx_wrong1):\n    for jj, g_net_jj in enumerate(graphs_nx_train_1):\n        distt_wrong1_train1[ii,jj], WDist_wrong1_train1[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n        \ndistt_wrong1_train0 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_train_0)))\nWDist_wrong1_train0 = np.zeros((len(graphs_nx_wrong1),len(graphs_nx_train_0)))\n\nfor ii, g_net_ii in enumerate(graphs_nx_wrong1):\n    for jj, g_net_jj in enumerate(graphs_nx_train_0):\n        distt_wrong1_train0[ii,jj], WDist_wrong1_train0[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n        \n#ax = sns.displot(distt_wrong1_train1.flatten())","a59d5e67":"ax2 = sns.displot(WDist_wrong1_correct1.flatten(), kind = 'kde')","37b3a190":"ax2 = sns.displot(WDist_wrong1_train1.flatten(), kind = 'kde')","6eb44418":"ax2 = sns.displot(WDist_wrong1_train0.flatten(), kind = 'kde')","3c2f6793":"distt_wrong0_correct0 = np.zeros((len(graphs_nx_wrong0),len(graphs_nx_correct0)))\nWDist_wrong0_correct0 = np.zeros((len(graphs_nx_wrong0),len(graphs_nx_correct0)))\n\nfor ii, g_net_ii in enumerate(graphs_nx_wrong0):\n    for jj, g_net_jj in enumerate(graphs_nx_correct0):\n        distt_wrong0_correct0[ii,jj], WDist_wrong0_correct0[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n\ndistt_wrong0_train0 = np.zeros((len(graphs_nx_wrong0),len(graphs_nx_train_0)))\nWDist_wrong0_train0 = np.zeros((len(graphs_nx_wrong0),len(graphs_nx_train_0)))\n\nfor ii, g_net_ii in enumerate(graphs_nx_wrong0):\n    for jj, g_net_jj in enumerate(graphs_nx_train_0):\n        distt_wrong0_train0[ii,jj], WDist_wrong0_train0[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n        \ndistt_wrong0_train1 = np.zeros((len(graphs_nx_wrong0),len(graphs_nx_train_1)))\nWDist_wrong0_train1 = np.zeros((len(graphs_nx_wrong0),len(graphs_nx_train_1)))\n\nfor ii, g_net_ii in enumerate(graphs_nx_wrong0):\n    for jj, g_net_jj in enumerate(graphs_nx_train_1):\n        distt_wrong0_train1[ii,jj], WDist_wrong0_train1[ii,jj] = r_eigenv(g_net_ii, g_net_jj)","b8e8f0d7":"ax2 = sns.displot(WDist_wrong0_correct0.flatten(), kind = 'kde')","0abaa510":"ax2 = sns.displot(WDist_wrong0_train0.flatten(), kind = 'kde')","ab7ae456":"ax2 = sns.displot(WDist_wrong0_train1.flatten(), kind = 'kde')","17f96c04":"if 0:\n    distt_correct0_train0 = np.zeros((len(graphs_nx_correct0),len(graphs_nx_train_0)))\n    WDist_correct0_train0 = np.zeros((len(graphs_nx_correct0),len(graphs_nx_train_0)))\n\n    for ii, g_net_ii in enumerate(graphs_nx_correct0):\n        for jj, g_net_jj in enumerate(graphs_nx_train_0):\n            distt_correct0_train0[ii,jj], WDist_correct0_train0[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n        \n    distt_correct0_train1 = np.zeros((len(graphs_nx_correct0),len(graphs_nx_train_1)))\n    WDist_correct0_train1 = np.zeros((len(graphs_nx_correct0),len(graphs_nx_train_1)))\n\n    for ii, g_net_ii in enumerate(graphs_nx_correct0):\n        for jj, g_net_jj in enumerate(graphs_nx_train_1):\n            distt_correct0_train1[ii,jj], WDist_correct0_train1[ii,jj] = r_eigenv(g_net_ii, g_net_jj)","817d3d50":"if 0:\n    distt_correct1_train0 = np.zeros((len(graphs_nx_correct1),len(graphs_nx_train_0)))\n    WDist_correct1_train0 = np.zeros((len(graphs_nx_correct1),len(graphs_nx_train_0)))\n\n    for ii, g_net_ii in enumerate(graphs_nx_correct1):\n        for jj, g_net_jj in enumerate(graphs_nx_train_0):\n            distt_correct1_train0[ii,jj], WDist_correct1_train0[ii,jj] = r_eigenv(g_net_ii, g_net_jj)\n        \n    distt_correct1_train1 = np.zeros((len(graphs_nx_correct1),len(graphs_nx_train_1)))\n    WDist_correct1_train1 = np.zeros((len(graphs_nx_correct1),len(graphs_nx_train_1)))\n\n    for ii, g_net_ii in enumerate(graphs_nx_correct1):\n        for jj, g_net_jj in enumerate(graphs_nx_train_1):\n            distt_correct1_train1[ii,jj], WDist_correct1_train1[ii,jj] = r_eigenv(g_net_ii, g_net_jj)","4db6ef56":"def Wasserstein_Dist(XX, YY):\n  \n    import numpy as np\n    nx = len(XX)\n    ny = len(YY)\n    n = nx + ny\n\n    XY = np.concatenate([XX,YY])\n    X2 = np.concatenate([np.repeat(1\/nx, nx), np.repeat(0, ny)])\n    Y2 = np.concatenate([np.repeat(0, nx), np.repeat(1\/ny, ny)])\n\n    S_Ind = np.argsort(XY)\n    XY_Sorted = XY[S_Ind]\n    X2_Sorted = X2[S_Ind]\n    Y2_Sorted = Y2[S_Ind]\n\n    Res = 0\n    E_CDF = 0\n    F_CDF = 0\n    power = 1\n\n    for ii in range(0, n-2):\n        E_CDF = E_CDF + X2_Sorted[ii]\n        F_CDF = F_CDF + Y2_Sorted[ii]\n        height = abs(F_CDF-E_CDF)\n        width = XY_Sorted[ii+1] - XY_Sorted[ii]\n        Res = Res + (height ** power) * width;  \n \n    return Res\n\ndef  Wasserstein_Dist_PVal(XX, YY):\n    # Information about Bootstrap: https:\/\/towardsdatascience.com\/an-introduction-to-the-bootstrap-method-58bcb51b4d60\n    import random\n    nboots = 10\n    WD = Wasserstein_Dist(XX,YY)\n    na = len(XX)\n    nb = len(YY)\n    n = na + nb\n    comb = np.concatenate([XX,YY])\n    reps = 0\n    bigger = 0\n    for ii in range(1, nboots):\n        e = random.sample(range(n), na)\n        f = random.sample(range(n), nb)\n        boost_WD = Wasserstein_Dist(comb[e],comb[f]);\n        if (boost_WD > WD):\n            bigger = 1 + bigger\n            \n    pVal = bigger\/nboots;\n\n    return pVal, WD","7db4a2b3":"#pVal, WD = Wasserstein_Dist_PVal(WDist_wrong0_train0.flatten(), WDist_wrong0_train1.flatten())\n#print(pVal, WD)","f59e1f6a":"#pVal, WD = Wasserstein_Dist_PVal(WDist_correct0_train0.flatten(), WDist_correct0_train1.flatten())\n#print(pVal, WD)","bd0d2a20":"#pVal, WD = Wasserstein_Dist_PVal(WDist_wrong1_train1.flatten(), WDist_wrong1_train0.flatten())\n#print(pVal, WD)","fa5b4811":"<a id = \"glib\"><\/a>\n## Graph Attribution specific imports","5118bcef":"<a id = \"lib\"><\/a>\n## Importing Required Libraries","a0c6b2e2":"<a id = \"init\"><\/a>\n## Initialization and Installations","8c27db7e":"<a id = \"load\"><\/a>\n# Load Experiment Data, Task and Attribution Techniques","1413dc50":"<a id = \"model\"><\/a>\n## Creating a GNN Model\n\n### Defining Hyperparams of the Experiment","6e448d83":"<a id = \"SafeML\"><\/a>\n## Graph Distance Measures and SafeML Idea","cb92a98c":"### Instantiate model","c4267726":"<a id = \"dis\"><\/a>\n## Discussion\nIt seems that the current idea is not successful and we should do more investigation. We can also consider about model-specific SafeML.","72e1d0a1":"<a id = \"gviz\"><\/a>\n## Graph Vizualization","2c18afcd":"<a id =\"train\"><\/a>\n## Training the GNN Model","a8386078":"# Graph Neural Network (GCN)-based Synthetic Binding Logic Classification plus Graph-SafeML\nThe eisting example of GNN-based Synthetic Binding Logic Classification from google research team is used to test the idea of SafeML for Graph-based classifiers. You can find the source code [here](https:\/\/github.com\/google-research\/graph-attribution) and the related paper for the code is available [here](https:\/\/papers.nips.cc\/paper\/2020\/file\/417fbbf2e9d5a28a855a11894b2e795a-Paper.pdf) [[1]](https:\/\/papers.nips.cc\/paper\/2020\/file\/417fbbf2e9d5a28a855a11894b2e795a-Paper.pdf).\nRegarding the Graph-based distance measure, the theory of \"Graph distance for complex networks\" provided by of Yutaka Shimada et al. is used [[2]](https:\/\/www.nature.com\/articles\/srep34944). The code related to this paper is avaialble [here](https:\/\/github.com\/msarrias\/graph-distance-for-complex-networks).\nYou can read more about the idea of SafeML in [[3]](https:\/\/github.com\/ISorokos\/SafeML). To read more about \"Synthetic Binding Logic Classification\" and the related dataset that is used in this notebook, please check [[4]](https:\/\/www.pnas.org\/content\/pnas\/116\/24\/11624.full.pdf).\n\n![SafeML logo from: https:\/\/github.com\/ISorokos\/SafeML](https:\/\/miro.medium.com\/max\/700\/1*H0lN2Q9lmSRgfaGj9VqqGA.png)\n\nThe SafeML project takes place at the University of Hull in collaboration with Fraunhofer IESE and Nuremberg Institute of Technology\n\n\n## Table of Content\n* [Initialization and Installations](#init)\n* [Importing Required Libraries](#lib)\n* [Graph Attribution Specific Imports](#glib)\n* [Load Experiment Data, Task and Attribution Techniques](#load)\n* [Creating a GNN Model](#model)\n* [Graph Vizualization](#gviz)\n* [Graph Distance Measures and SafeML Idea](#SafeML)\n* [Discussion](#dis)\n\n### References:\n[[1]. Wiltschko, A. B., Sanchez-Lengeling, B., Lee, B., Reif, E., Wei, J., McCloskey, K. J., & Wang, Y. (2020). Evaluating Attribution for Graph Neural Networks.](https:\/\/papers.nips.cc\/paper\/2020\/file\/417fbbf2e9d5a28a855a11894b2e795a-Paper.pdf)\n\n[[2]. Shimada, Y., Hirata, Y., Ikeguchi, T., & Aihara, K. (2016). Graph distance for complex networks. Scientific reports, 6(1), 1-6.](https:\/\/www.nature.com\/articles\/srep34944)\n\n[[3]. Aslansefat, K., Sorokos, I., Whiting, D., Kolagari, R. T., & Papadopoulos, Y. (2020, September). SafeML: Safety Monitoring of Machine Learning Classifiers Through Statistical Difference Measures. In International Symposium on Model-Based Safety and Assessment (pp. 197-211). Springer, Cham.](https:\/\/arxiv.org\/pdf\/2005.13166.pdf)\n\n[[4]. McCloskey, K., Taly, A., Monti, F., Brenner, M. P., & Colwell, L. J. (2019). Using attribution to decode binding mechanism in neural network models for chemistry. Proceedings of the National Academy of Sciences, 116(24), 11624-11629.](https:\/\/www.pnas.org\/content\/pnas\/116\/24\/11624.full.pdf)"}}