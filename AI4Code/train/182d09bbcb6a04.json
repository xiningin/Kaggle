{"cell_type":{"0f9d99d5":"code","81868f63":"code","8f9ca632":"code","3455f2ed":"code","5431155a":"code","1c67d736":"code","fd790cb4":"markdown","ce9b6ad2":"markdown","a472c87a":"markdown","f66003ed":"markdown","d5ddfacb":"markdown","3006401d":"markdown","b3df6392":"markdown"},"source":{"0f9d99d5":"!pip install pygam","81868f63":"import pandas  as pd\nimport matplotlib.pyplot as plt\n\n#===========================================================================\n# read in the data\n#===========================================================================\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data  = pd.read_csv('..\/input\/titanic\/test.csv')\n\n#===========================================================================\n# select some features of interest (\"ay, there's the rub\", Shakespeare)\n#===========================================================================\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n\n#===========================================================================\n# for the features that are categorical we use pd.get_dummies:\n# \"Convert categorical variable into dummy\/indicator variables.\"\n#===========================================================================\nX_train       = pd.get_dummies(train_data[features])\ny_train       = train_data[\"Survived\"]\nfinal_X_test  = pd.get_dummies(test_data[features])","8f9ca632":"from pygam import LogisticGAM, s, f\n\nclassifier = LogisticGAM(s(0) + s(1) + s(2) + s(3))\n\nclassifier.fit(X_train, y_train)\n\n#===========================================================================\n# use the model to predict 'Survived' for the test data\n#===========================================================================\npredictions = classifier.predict(final_X_test)\n\n# convert from True\/False to 1\/0\npredictions = (predictions)*1","3455f2ed":"classifier.summary()","5431155a":"plt.figure(figsize=(15, 4))\nfor i, term in enumerate(classifier.terms):\n    if term.isintercept:\n        continue\n    plt.plot(classifier.partial_dependence(term=i), label=\"s({})\".format(i))\n    plt.legend()","1c67d736":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)","fd790cb4":"### finally write out a `submission.csv` file","ce9b6ad2":"### visualize each individual feature function\nHere each of the four spline functions:","a472c87a":"### produce a summary","f66003ed":"# A classification example using Generalized Additive Models with pyGAM\n\n[Generalized additive models](https:\/\/en.wikipedia.org\/wiki\/Generalized_additive_model) combine [generalized linear models](https:\/\/en.wikipedia.org\/wiki\/Generalized_linear_model) with [additive models](https:\/\/en.wikipedia.org\/wiki\/Additive_model). For an excellent introduction see [\"A Tour of pyGAM\"](https:\/\/pygam.readthedocs.io\/en\/latest\/notebooks\/tour_of_pygam.html).\n\n### Install `pyGAM`","d5ddfacb":"### set up some simple Titanic competition data\nNo feature engineering or anything; just enough to get us going...","3006401d":"### perform the classification\nHere we use `LogisticGAM`, which uses a logit link function and binomial distribution, with four spline terms, `s(0)...s(3)`, for each of the four features:","b3df6392":"# Links\n* [pyGAM](https:\/\/github.com\/dswah\/pyGAM) on GitHub\n* [pyGAM documentation](https:\/\/pygam.readthedocs.io\/en\/latest\/index.html)\n* [Daniel Serv\u00e9n and Charlie Brummitt \"pyGAM: Generalized Additive Models in Python\", Zenodo (2018)](http:\/\/dx.doi.org\/10.5281\/zenodo.1208723)\n\n# Further reading\n* [Trevor Hastie and Robert Tibshirani \"Generalized Additive Models\", Statistical Science Vol. 1 pp. 297-310 (1986)](https:\/\/projecteuclid.org\/download\/pdf_1\/euclid.ss\/1177013604)\n* [\"Generalized Additive Models\" by Michael Clark](https:\/\/m-clark.github.io\/generalized-additive-models\/)"}}