{"cell_type":{"cf976a4a":"code","3b959643":"code","9ac569af":"code","fa9a4d59":"code","73fbce2c":"code","f75baa2e":"code","ba1e642a":"code","76c99ac9":"code","a1a582c3":"code","d6da071d":"code","39110b17":"code","0b05f71f":"code","bd2323b7":"code","fc248b4d":"code","57fbb409":"markdown","0be4a07f":"markdown","625bd3dc":"markdown","6c5e5450":"markdown","eae960aa":"markdown","5b51a0b6":"markdown","2564cb41":"markdown","0318b3f8":"markdown"},"source":{"cf976a4a":"# Import necessary libraries\nimport math\nimport pickle\nimport os\nimport pandas as pd\nimport folium \nimport numpy as np\nimport matplotlib\nmatplotlib.use('nbagg')\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\nimport plotly as py\nimport cufflinks\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom tqdm import tqdm_notebook as tqdm\nimport warnings\nimport tensorflow as tf\nfrom numpy import array\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import BatchNormalization\nfrom dateutil.relativedelta import relativedelta\nimport datetime\nfrom xgboost import XGBRegressor\nwarnings.filterwarnings(\"ignore\")\n","3b959643":"# Reading COVID-19 Raw data\n# Reading COVID-19 Raw data\ntrain = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-3\/train.csv\")\n#covid_master=pd.read_csv('covid_19_data.csv')\nsubmission = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-3\/submission.csv\")\n#covid_open=pd.read_csv('COVID19_open_line_list.csv')\ntest = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-3\/test.csv\")\n#train = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-1\/train.csv\")","9ac569af":"# We will fill the missing states with a value 'NoState'\ntrain=train.fillna('NoState')\ntest=test.fillna('NoState')\n# changing the data type\ntrain=train.rename(columns={'ConfirmedCases':'Confirmed','Fatalities':'Deaths','Country_Region':'Country\/Region',\n                     'Province_State':'Province\/State','Date':'ObservationDate'})\ntest=test.rename(columns={'ConfirmedCases':'Confirmed','Fatalities':'Deaths','Country_Region':'Country\/Region',\n                     'Province_State':'Province\/State','Date':'ObservationDate'})\nnum_cols=['Confirmed', 'Deaths']\nfor col in num_cols:\n    temp=[int(i) for i in train[col]]\n    train[col]=temp \ntrain.head(2)","fa9a4d59":"from sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgbm\nlb = LabelEncoder()\ntrain_xgb=train.copy()\ntest_xgb=test.copy()\n#lb.fit(train_xgb['Country\/Region'])\ntrain_xgb['Country\/Region']=lb.fit_transform(train_xgb['Country\/Region'])\ntrain_xgb['Province\/State']=lb.fit_transform(train_xgb['Province\/State'])\ntest_xgb['Country\/Region']=lb.fit_transform(test_xgb['Country\/Region'])\ntest_xgb['Province\/State']=lb.fit_transform(test_xgb['Province\/State'])\n\ntrain_dt=[int(datetime.datetime.strptime(train_xgb.iloc[i].ObservationDate, \"%Y-%m-%d\").strftime(\"%m%d\")) \n          for i in range(len(train_xgb)) ]\ntrain_xgb['ObservationDate']=train_dt\ntest_dt=[int(datetime.datetime.strptime(test_xgb.iloc[i].ObservationDate, \"%Y-%m-%d\").strftime(\"%m%d\")) \n          for i in range(len(test_xgb)) ]\ntest_xgb['ObservationDate']=test_dt\ntrain_xgb.head()","73fbce2c":"# Creating list of all regions of all counntries\nunique_regions=train_xgb['Country\/Region'].unique()\nstates_per_regions=[]\nfor reg in tqdm(unique_regions):\n    states_per_regions.append(train_xgb[train_xgb['Country\/Region']==reg]['Province\/State'].unique()) \nprint('No of unique regions:',len(unique_regions))    ","f75baa2e":"train_xgb.head()","ba1e642a":"# Method for prediction\nimport math\ndef pred(model,data):\n    y_pred=model.predict(data)\n    #y_pred=[math.ceil(i) for i in y_pred]\n    return y_pred","76c99ac9":"# Method for Hyperparameter Tuning\nfrom sklearn.metrics import mean_squared_log_error\ndef get_best_xgb_model(X_c,y_c):\n    X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(X_c, y_c, test_size=0.30, random_state=42)\n    print('XGBoost Hyper Parameter Tunning')\n    min_child_samples=[5,10,20,50,70]\n    loss=[]\n    loss1=[]\n    loss2=[]\n    loss3=[]\n    loss4=[]\n    for n in min_child_samples:\n        xgb_c=XGBRegressor(n_iterators=1000,min_child_samples=n)\n        xgb_c.fit(X_train_c,y_train_c)\n        y_pred=pred(xgb_c,X_val_c)\n        if ((y_val_c >= 0).all() and (y_pred >= 0).all()):\n            loss.append(mean_squared_log_error(y_pred,y_val_c))\n            #print('min_child_samples:',n,'msle:',mean_squared_log_error(y_pred,y_val_c))\n    print('Best min_child_samples:',min_child_samples[np.argmin(loss)])   \n\n    learning_rate=[0.0001,0.001,0.01,0.1,0.2,0.5]  \n    for n in learning_rate:\n        xgb_c=XGBRegressor(n_iterators=1000,min_child_samples=min_child_samples[np.argmin(loss)],learning_rate=n)\n        xgb_c.fit(X_train_c,y_train_c)\n        y_pred=pred(xgb_c,X_val_c)\n        if ((y_val_c >= 0).all() and (y_pred >= 0).all()):\n            loss1.append(mean_squared_log_error(y_pred,y_val_c))\n        #print('learning_rate:',n,'msle:',mean_squared_log_error(y_pred,y_val_c))\n    print('Best learning_rate:',learning_rate[np.argmin(loss1)])   \n\n    num_leaves=[5,10,30,50,100]\n    for n in num_leaves:\n        xgb_c=XGBRegressor(n_iterators=1000,min_child_samples=min_child_samples[np.argmin(loss)],learning_rate=learning_rate[np.argmin(loss1)]\n                                ,num_leaves=n)\n        xgb_c.fit(X_train_c,y_train_c)\n        y_pred=pred(xgb_c,X_val_c)\n        if ((y_val_c >= 0).all() and (y_pred >= 0).all()):\n            loss2.append(mean_squared_log_error(y_pred,y_val_c))\n        #print('num_leaves:',n,'msle:',mean_squared_log_error(y_pred,y_val_c))\n    print('Best lnum_leaves:',num_leaves[np.argmin(loss2)])  \n\n    reg_alpha=[0.0,0.01,0.05,0.1,0.5]\n    for n in reg_alpha:\n        xgb_c=XGBRegressor(n_iterators=1000,min_child_samples=min_child_samples[np.argmin(loss)],learning_rate=learning_rate[np.argmin(loss1)]\n                      ,reg_alpha=n,num_leaves=num_leaves[np.argmin(loss2)])\n        xgb_c.fit(X_train_c,y_train_c)\n        y_pred=pred(xgb_c,X_val_c)\n        if ((y_val_c >= 0).all() and (y_pred >= 0).all()):\n            loss3.append(mean_squared_log_error(y_pred,y_val_c))\n        #print('reg_alpha:',n,'msle:',mean_squared_log_error(y_pred,y_val_c))\n    print('Best reg_alpha:',reg_alpha[np.argmin(loss3)]) \n\n    n_estimators=[50,100,200,500,1000]\n    for n in n_estimators:\n        xgb_c=XGBRegressor(n_iterators=1000,min_child_samples=min_child_samples[np.argmin(loss)],learning_rate=learning_rate[np.argmin(loss1)]\n                      ,reg_alpha=reg_alpha[np.argmin(loss3)],num_leaves=num_leaves[np.argmin(loss2)],n_estimators=n)\n        xgb_c.fit(X_train_c,y_train_c)\n        y_pred=pred(xgb_c,X_val_c)\n        if ((y_val_c >= 0).all() and (y_pred >= 0).all()):\n            loss4.append(mean_squared_log_error(y_pred,y_val_c))\n        #print('n_estimators:',n,'msle:',mean_squared_log_error(y_pred,y_val_c))\n    print('Best n_estimators:',n_estimators[np.argmin(loss4)])   \n    xgb_c=XGBRegressor(n_iterators=1000,min_child_samples=min_child_samples[np.argmin(loss)],learning_rate=learning_rate[np.argmin(loss1)]\n                      ,reg_alpha=reg_alpha[np.argmin(loss3)],num_leaves=num_leaves[np.argmin(loss2)],n_estimators=n_estimators[np.argmin(loss4)])\n    xgb_c.fit(X_train_c,y_train_c)\n    return xgb_c","a1a582c3":"# Utility method to run Decision Tree model\nfrom sklearn.tree import DecisionTreeClassifier\ndef run_model_DT(train,test):\n    res=pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n    for k in tqdm(range(len(unique_regions))):\n        for state in states_per_regions[k]:\n            #print(unique_regions[k],state)\n            temp_train=train[(train['Country\/Region']==unique_regions[k]) &(train['Province\/State']==state)]\n            temp_test=test[(test['Country\/Region']==unique_regions[k]) &(test['Province\/State']==state)]\n            X_train=temp_train.loc[:, ['Province\/State', 'Country\/Region','ObservationDate']]\n            X_test=temp_test.loc[:, ['Province\/State', 'Country\/Region','ObservationDate']]\n            y_c=temp_train.loc[:,'Confirmed']\n            y_d=temp_train.loc[:,'Deaths']\n            Forecast_Id=[int(i) for i in temp_test.ForecastId]\n            # Model for Confirmed Cases\n            #print(X_train.shape,len(y_c))\n            model_c= DecisionTreeClassifier()\n            model_c.fit(X_train, y_c)\n            y_c_pred = model_c.predict(X_test)\n            # Model for Confirmed Cases\n            model_d= DecisionTreeClassifier()\n            model_d.fit(X_train, y_d)\n            y_d_pred = model_d.predict(X_test)\n            res_temp=pd.DataFrame({'ForecastId': Forecast_Id, 'ConfirmedCases': y_c_pred, 'Fatalities': y_d_pred})\n            res = pd.concat([res, res_temp], axis=0)\n    return res\n\n# Utility method to run XGBoost\ndef run_model_XGB(train,test,n_estimators):\n    res=pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n    for k in tqdm(range(len(unique_regions))):\n        for state in states_per_regions[k]:\n            #print(unique_regions[k],state)\n            temp_train=train[(train['Country\/Region']==unique_regions[k]) &(train['Province\/State']==state)]\n            temp_test=test[(test['Country\/Region']==unique_regions[k]) &(test['Province\/State']==state)]\n            X_train=temp_train.loc[:, ['Province\/State', 'Country\/Region','ObservationDate']]\n            X_test=temp_test.loc[:, ['Province\/State', 'Country\/Region','ObservationDate']]\n            y_c=temp_train.loc[:,'Confirmed']\n            y_d=temp_train.loc[:,'Deaths']\n            Forecast_Id=[int(i) for i in temp_test.ForecastId]\n            # Model for Confirmed Cases\n            #print(X_train.shape,len(y_c))\n            model_c=XGBRegressor(n_estimators=n_estimators)\n            model_c.fit(X_train, y_c)\n            y_c_pred = model_c.predict(X_test)\n            # Model for Death Cases\n            model_d= XGBRegressor(n_estimators=n_estimators)\n            model_d.fit(X_train, y_d)\n            y_d_pred = model_d.predict(X_test)\n            res_temp=pd.DataFrame({'ForecastId': Forecast_Id, 'ConfirmedCases': y_c_pred, 'Fatalities': y_d_pred})\n            res = pd.concat([res, res_temp], axis=0)\n    return res","d6da071d":"# Run Model\nres_DT=run_model_DT(train_xgb,test_xgb)\nres_XGB=run_model_XGB(train_xgb,test_xgb,1500)","39110b17":"def get_mse(res,target):\n    res=res.rename(columns={'ConfirmedCases':'Confirmed','Fatalities':'Deaths','Country_Region':'Country\/Region',\n                     'Province_State':'Province\/State','Date':'ObservationDate'})\n    Id=[int(i) for i in res.ForecastId]\n    res['ForecastId']=Id\n    temp=pd.merge(res,test,on='ForecastId',how='inner')\n    y_pred=list(temp.query(\"ObservationDate>='2020-03-26' and ObservationDate<'2020-04-07'\")[target])\n    y_true=list(train.query(\"ObservationDate>='2020-03-26' and ObservationDate<'2020-04-07'\")[target])\n    print('mse:',mean_squared_error(y_true,y_pred))","0b05f71f":"res_DT.head()","bd2323b7":"res_final=res_XGB\n#res_final['ConfirmedCases']=0.35*res_XGB['ConfirmedCases']+0.65*res_DT['ConfirmedCases']\n#res_final['Fatalities']=0.35*res_XGB['Fatalities']+0.65*res_DT['Fatalities']\nres_final.head()","fc248b4d":"\nId=[int(i) for i in res_final.ForecastId]\nres_final['ForecastId']=Id\nres_final.to_csv('submission.csv',index=None)\nres_final.head(20)","57fbb409":"## Projection using LSTM\n\nPlease find the notebook that comes with N days projection of cases using LSTM\nhttps:\/\/www.kaggle.com\/arpandas65\/covid-19-projection-using-lstm?scriptVersionId=31704316","0be4a07f":"## Preparing the Model","625bd3dc":"## Reading Data","6c5e5450":"## What's there in this Notebook?\nThis notebook mainly explores the forcasting of COVID_19 (Week 3) using DecisionTree and XGBoost","eae960aa":"### A Brief Description\nCoronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS coronavirus 2, or SARS-CoV-2),a virus closely related to the SARS virus.The disease was discovered and named during the 2019\u201320 coronavirus outbreak.Those affected may develop a fever, dry cough, fatigue, and shortness of breath. A sore throat,runny nose or sneezing is less common. While the majority of cases result in mild symptoms,some can progress to pneumonia and multi-organ failure.","5b51a0b6":"### Exploratory Data Analysis and Visualization\n\nPlease visit the following notebook for a detailed regional and timeseries Exploratory Data Analysis\nhttps:\/\/www.kaggle.com\/arpandas65\/covid-19-regional-and-time-series-data-analysis?scriptVersionId=31484857","2564cb41":"## Data Preprocessing","0318b3f8":"## Submission"}}