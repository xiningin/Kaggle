{"cell_type":{"0efcbca7":"code","9cb71783":"code","1264cdff":"code","06733088":"code","221cadfc":"code","33934dbc":"code","fa9abd56":"code","9d363271":"code","0295b50d":"code","8924d9cc":"code","41d19b39":"code","05bd027e":"code","e427ff1f":"code","79af11af":"code","28e92a57":"code","3ce140b1":"code","438fa702":"code","c05cd6dc":"code","818d6738":"code","a5255147":"code","a9ecccce":"code","d6500f92":"code","19bd895c":"code","65495cbb":"code","ede4aad6":"code","b058f138":"code","dd97323b":"code","7cc5b91c":"code","6519a3fd":"code","42c73b7e":"code","86d87169":"code","06bd5415":"code","9cc9cdea":"code","33ebe207":"code","a29bfac0":"code","50a0e5fc":"code","6f9480e9":"code","4e289347":"code","b373a46f":"code","3c681a20":"code","c7ff99ac":"code","f5b9d15c":"code","d300601a":"code","b1f453cd":"code","cb6883e4":"code","7fe64d0c":"code","9f490227":"code","ffc3612e":"code","e9e4a07d":"code","7a774a05":"code","2c2ee4ef":"code","dde96619":"code","2e6c85a7":"code","e2efdd93":"code","1c824961":"code","674069d6":"code","df87acd0":"code","9b8ff410":"code","d1349b2b":"markdown","b6015345":"markdown","fb443eba":"markdown","7aa8d537":"markdown","24127810":"markdown","a8c7c3a0":"markdown","2665938d":"markdown","61b30441":"markdown"},"source":{"0efcbca7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cb71783":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport random\nimport os\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, pyll\nimport time\nimport colorama  # https:\/\/pypi.python.org\/pypi\/colorama\nimport pickle\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom catboost import CatBoostClassifier, Pool\nfrom scipy import stats\nfrom dateutil import parser","1264cdff":"\n\nSEED = 2021\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\nos.environ['PYTHONHASHSEED']=str(SEED)\n\n","06733088":"train_df = pd.read_csv('\/kaggle\/input\/exhibit-art-ml-challenge\/dataset\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/exhibit-art-ml-challenge\/dataset\/test.csv')\nsub_df = pd.read_csv('\/kaggle\/input\/exhibit-art-ml-challenge\/dataset\/sample_submission.csv')","221cadfc":"train_df.head()","33934dbc":"sns.boxplot(x=train_df[\"Cost\"])","fa9abd56":"train_df.shape, test_df.shape","9d363271":"train_df.info()","0295b50d":"for col in train_df.select_dtypes('object').columns:\n    print(col, train_df[col].nunique())","8924d9cc":"#train_df = train_df[(np.abs(stats.zscore(train_df[\"Cost\"])) < 3)]","41d19b39":"sns.boxplot(x=train_df[\"Cost\"])","05bd027e":"print(train_df['Cost'].quantile(0.10))\nprint(train_df['Cost'].quantile(0.90))","e427ff1f":"train_df['Cost'] = np.where(train_df['Cost'] <163.55, 163.55,train_df['Cost'])\ntrain_df['Cost'] = np.where(train_df['Cost'] >6239.74, 6239.74,train_df['Cost'])\nprint(train_df['Cost'].skew())","79af11af":"train_df.isna().sum()","28e92a57":"test_df.isna().sum()","3ce140b1":"train_df['Artist Reputation'].fillna(0.0, inplace=True)\ntrain_df['Height'].fillna(train_df['Height'].value_counts().idxmax(), inplace=True)\ntrain_df['Width'].fillna(train_df['Width'].value_counts().idxmax(), inplace=True)\ntrain_df['Weight'].fillna(train_df['Weight'].value_counts().idxmax(), inplace=True)\ntrain_df['Transport'].fillna(train_df['Transport'].value_counts().idxmax(), inplace=True)\ntrain_df['Material'].fillna(train_df['Material'].value_counts().idxmax(), inplace=True)\ntrain_df['Remote Location'].fillna(train_df['Remote Location'].value_counts().idxmax(), inplace=True)\n\n\ntest_df['Artist Reputation'].fillna(0.0, inplace=True)\ntest_df['Height'].fillna(test_df['Height'].value_counts().idxmax(), inplace=True)\ntest_df['Width'].fillna(test_df['Width'].value_counts().idxmax(), inplace=True)\ntest_df['Weight'].fillna(test_df['Weight'].value_counts().idxmax(), inplace=True)\ntest_df['Transport'].fillna(test_df['Transport'].value_counts().idxmax(), inplace=True)\n","438fa702":"train_df.head()","c05cd6dc":"train_df = train_df.drop([\"Artist Name\"], axis=1)\ntest_df = test_df.drop([\"Artist Name\"], axis=1)","818d6738":"train_df.isna().sum()","a5255147":"correlations = train_df.corr()['Cost']\ncorrelations*100","a9ecccce":"train_df[\"Scheduled Date\"] = [parser.parse(row_date) for row_date in train_df[\"Scheduled Date\"]]\ntrain_df[\"Delivery Date\"] = [parser.parse(row_date) if isinstance(row_date, str) else row_date for row_date in train_df[\"Delivery Date\"]]\n\n\ntest_df[\"Scheduled Date\"] = [parser.parse(row_date) for row_date in test_df[\"Scheduled Date\"]]\ntest_df[\"Delivery Date\"] = [parser.parse(row_date) if isinstance(row_date, str) else row_date for row_date in test_df[\"Delivery Date\"]]\n\n","d6500f92":"train_df[[\"Scheduled Date\",\"Delivery Date\"]].head()","19bd895c":"train_df[\"difference\"] = (train_df[\"Scheduled Date\"]-train_df[\"Delivery Date\"]).astype('timedelta64[D]').astype('int')\n\ntest_df[\"difference\"] = (test_df[\"Scheduled Date\"]-test_df[\"Delivery Date\"]).astype('timedelta64[D]').astype('int')","65495cbb":"train_df[\"difference\"].head()","ede4aad6":"train_df = train_df.drop([\"Delivery Date\",\"Scheduled Date\"], axis=1)\ntest_df = test_df.drop([\"Delivery Date\",\"Scheduled Date\"], axis=1)","b058f138":"train_df.head()","dd97323b":"train_df.groupby([\"Customer Location\"]).head()","7cc5b91c":"train_df[\"Customer Location\"].head()","6519a3fd":"temp = train_df[\"Customer Location\"].apply(lambda x: x.split(\",\"))\nregion_code = []\ncity_code = []\nfor i in temp:\n    if(len(i)==1):\n        temp_region_code = i[0].split(\" \")[2]\n        temp_city_code = i[0].split(\" \")[1]\n        region_code.append(temp_region_code)\n        city_code.append(temp_city_code)\n    else:\n        temp_region_code = i[1].split(\" \")[2]\n        temp_city_code = i[1].split(\" \")[1]\n        region_code.append(temp_region_code)\n        city_code.append(temp_city_code)\nregion_code = pd.DataFrame(region_code, columns =['Region code'])\ncity_code = pd.DataFrame(city_code, columns =['City code'])\ntrain_df= pd.concat([train_df,region_code,city_code], axis=1)\ntrain_df","42c73b7e":"temp = test_df[\"Customer Location\"].apply(lambda x: x.split(\",\"))\nregion_code = []\ncity_code = []\nfor i in temp:\n    if(len(i)==1):\n        temp_region_code = i[0].split(\" \")[2]\n        temp_city_code = i[0].split(\" \")[1]\n        region_code.append(temp_region_code)\n        city_code.append(temp_city_code)\n    else:\n        temp_region_code = i[1].split(\" \")[2]\n        temp_city_code = i[1].split(\" \")[1]\n        region_code.append(temp_region_code)\n        city_code.append(temp_city_code)\nregion_code = pd.DataFrame(region_code, columns =['Region code'])\ncity_code = pd.DataFrame(city_code, columns =['City code'])\ntest_df= pd.concat([test_df,region_code,city_code], axis=1)\ntest_df","86d87169":"train_df = train_df.drop([\"Customer Location\"], axis=1)\ntest_df = test_df.drop([\"Customer Location\"], axis=1)","06bd5415":"cols_to_remove = ['Customer Id']\ntarget = 'Cost'\n\nXtestIdentifier = test_df['Customer Id']\n\n_X = train_df.drop(cols_to_remove + [target], axis=1)\ny = train_df[target]\n\n_XTEST = test_df.drop(cols_to_remove , axis=1)\nX_all = pd.concat([_X, _XTEST]).reset_index(drop=True)\nX_all.shape","9cc9cdea":"y","33ebe207":"y.skew()","a29bfac0":"#y=np.log1p(y)\ny.skew()","50a0e5fc":"for col in train_df.select_dtypes('object').columns:\n    print(col)","6f9480e9":"cat_columns = []\nfor col in X_all.select_dtypes('object').columns:\n    print(col)\n    cat_columns.append(col)\n    le = LabelEncoder()\n    X_all[col] = le.fit_transform(X_all[col])","4e289347":"X_all.head()","b373a46f":"#datatdummies = pd.get_dummies(train_df[['Material','International','Express Shipment','Installation Included','Transport','Fragile','Customer Information','Remote Location',\"Region code\",\"City code\"]],drop_first=True)\n#train_df = pd.concat([train_df, datatdummies], axis=1)\n#train_df = train_df.drop(columns = ['Material','International','Express Shipment','Installation Included','Transport','Fragile','Customer Information','Remote Location',\"Region code\",\"City code\"])\n\n#datatdummies = pd.get_dummies(test_df[['Material','International','Express Shipment','Installation Included','Transport','Fragile','Customer Information','Remote Location',\"Region code\",\"City code\"]],drop_first=True)\n#test_df = pd.concat([test_df, datatdummies], axis=1)\n#test_df = test_df.drop(columns = ['Material','International','Express Shipment','Installation Included','Transport','Fragile','Customer Information','Remote Location',\"Region code\",\"City code\"])","3c681a20":"X = X_all[:len(y)]\nXTEST = X_all[len(y):]\nX.shape, XTEST.shape","c7ff99ac":"y = y.values.reshape(-1,1)\ny.shape","f5b9d15c":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_y = StandardScaler()\nX = sc_X.fit_transform(X)\ny = sc_y.fit_transform(y)\nXTEST = sc_X.fit_transform(XTEST)\n","d300601a":"from sklearn import metrics","b1f453cd":"X_train , X_test, y_train, y_test= train_test_split(X,y,test_size=0.2)","cb6883e4":"# Very bad model\nfrom sklearn.linear_model  import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n#lr.score(X_test, y_test)\ny_predlr = lr.predict(X_test)\nscores_regr = metrics.mean_squared_error(y_test, y_predlr)\nscores_regr","7fe64d0c":"y_predlr-y_test","9f490227":"from sklearn.svm import SVR\n\n\nregressor = SVR(kernel='rbf')\nregressor.fit(X_train,y_train)\nregressor.score(X_test,y_test)\ny_predsvr = regressor.predict(X_test)\nscores_regr = metrics.mean_squared_error(y_test, y_predsvr)\nscores_regr","ffc3612e":"y_predsvr-y_test","e9e4a07d":"XTEST","7a774a05":"y_predsubsvr = regressor.predict(XTEST)\ny_predsubsvr","2c2ee4ef":"from sklearn.ensemble import RandomForestRegressor\nrfmodel = RandomForestRegressor(n_estimators=100, max_features='sqrt')\nrfmodel.fit(X_train, y_train)\n\ny_predrf = rfmodel.predict(X_test)\nscores_regr = metrics.mean_squared_error(y_test, y_predrf)\nscores_regr","dde96619":"y_predsubrf = rfmodel.predict(XTEST)\ny_predsubrf","2e6c85a7":"subrf = pd.DataFrame({'Customer Id': XtestIdentifier,'Cost': y_predsubrf})","e2efdd93":"subrf.to_csv('rfsubmission.csv',index=False)","1c824961":"import xgboost as xgb\n\nxgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n\nxgb_model.fit(X, y)\n\ny_pred = xgb_model.predict(X)\n\nmse=mean_squared_error(y, y_pred)\n\nprint(np.sqrt(mse))","674069d6":"XTEST","df87acd0":"y_predsubxgb = xgb_model.predict(XTEST)\ny_predsubxgb = np.where(y_predsubxgb>0,y_predsubxgb,0)\n","9b8ff410":"subxgb = pd.DataFrame({'Customer Id': XtestIdentifier,'Cost': y_predsubxgb})\nsubxgb.to_csv('xgbsubmission.csv',index=False)","d1349b2b":"# Handling Dates","b6015345":"# Feature Scaling","fb443eba":"# Label Encoding\n","7aa8d537":"# Handling Null Values\n","24127810":"# Handling Customer Location\n","a8c7c3a0":"# Model Building","2665938d":"# Checking Correlations","61b30441":"# Handling Outliers"}}