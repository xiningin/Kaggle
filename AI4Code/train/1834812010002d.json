{"cell_type":{"99682ddf":"code","5d6ca96c":"code","a05f205e":"code","4d17a1b8":"code","0fac3a99":"code","76d31ee9":"code","00ecc032":"code","571b2594":"code","8d351fee":"code","bc516d06":"code","f81248c0":"code","0787febd":"code","b1fc2074":"code","28dbe921":"code","b69bce92":"code","102ec4be":"code","f458d346":"code","51dc4819":"code","5eb49337":"code","27155c6d":"code","b19e7d21":"code","3f898e2d":"code","514283a5":"code","ef986833":"code","9cc4a1e1":"code","e28c702c":"code","585c07fd":"code","0eb7b967":"code","49f1059c":"code","c3d7b6d3":"code","388196d3":"code","368ef4ee":"code","c7302d5d":"code","4846fc59":"code","580c7112":"code","87f8b1d7":"code","0ea93289":"code","2d6d9616":"code","bf7b55d8":"code","6de0e787":"code","2e22af15":"code","5630c1a0":"code","8710c941":"code","fdd0fac4":"code","16b728b3":"code","1848f46a":"code","d07fa80c":"code","49d2f728":"code","5444640a":"code","8eabe781":"code","05a57126":"code","3f108f2e":"code","647b7162":"code","0551ce7d":"code","0be07a64":"code","af18c696":"code","f0fb5541":"code","bc8672c1":"code","a4325685":"code","21669cc8":"code","c277cb6d":"code","2c4a33bb":"code","36c340dc":"code","75e7cb1c":"code","a9287468":"code","d4c5f279":"code","b208e490":"code","11fa5e5c":"code","eed9d054":"markdown","6b64c70a":"markdown","60cd7a5f":"markdown","4306d009":"markdown","524cf472":"markdown","99546a62":"markdown","692aa56f":"markdown","e66e6321":"markdown","76346e47":"markdown","6a0b3fd9":"markdown","ebdadaf0":"markdown","a341b908":"markdown","1ec32a24":"markdown","54675e32":"markdown","d27cc896":"markdown","6ab4d300":"markdown","1add0315":"markdown","0696e754":"markdown","6440523a":"markdown","01daea49":"markdown","d3e847b0":"markdown","ad3e4fc3":"markdown","0fbe23fb":"markdown","67c8a1a0":"markdown","bda8c71c":"markdown","eacab25a":"markdown","5b710432":"markdown","a1f32fdf":"markdown","0c355a1a":"markdown","1d0d4ed7":"markdown","8f079f42":"markdown","b85f2446":"markdown","7637189a":"markdown","f94947cd":"markdown","a623fb24":"markdown","f5cab2a4":"markdown","32388dd3":"markdown","d8d790f0":"markdown","bb99388a":"markdown","039ec0d4":"markdown","d56326aa":"markdown","bdc520ee":"markdown","250464b3":"markdown","2b9aa913":"markdown","582e2fdc":"markdown","2fc35ca3":"markdown","b2d401bf":"markdown","8a85f27d":"markdown","f9d23265":"markdown","9325d303":"markdown","3fa9dd93":"markdown","6ba07fe4":"markdown","919098e8":"markdown"},"source":{"99682ddf":"isimler = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\ndireks_sag =  [True, False, False, False, True, True, True]\narac_sayisi = [809, 731, 588, 18, 200, 70, 45]   # 10bin kisi basina dusen arac sayisi\n\n# pandas kutuphanesini import ediniz\nimport pandas as pd\n\n# verilen listeleri kullanarak sozlugum adli bir sozluk olusturunuz. \n# degisken adlari:  ulkeler,  direksiyon_sag,  arac_sayisi\nsozlugum = {\"ulkeler\":isimler, \"direks_sag\":direks_sag, \"arac_sayisi\":arac_sayisi}\n\n# 'sozlugum' adli sozluk u Dataframe e ceviriniz: 'araclar' ismi ile kaydediniz\naraclar = pd.DataFrame(sozlugum)\n\n# bu dataframe i yazdiriniz\naraclar","5d6ca96c":"satir_indeksleri = ['US', 'AUS', 'JAP', 'IN', 'RU', 'MOR', 'EG']\n\n# verilen diziyi araclar dataframe inin indeksi icin kullaniniz (atayiniz)\naraclar.index = satir_indeksleri\n\n# araclar dataframe ini tekrar yazdiriniz\naraclar","a05f205e":"\n\n# cars.csv  dosyasini cars adi ile kaydediniz\ncars = pd.read_csv(\"..\/input\/carsdataset\/cars.csv\")\n\n# cars verisinin ilk 5 gozlemini yazdiriniz\n\ncars.head()\n","4d17a1b8":"# Kolon ismi de\u011fi\u015ftirme (\"Unnamed:0 -> kisa_ad\" \u015feklinde de\u011fi\u015ftirilebilir.)\ncars.rename(columns = {\"Unnamed: 0\":\"kisa_ad\"}, inplace = True)","0fac3a99":"cars","76d31ee9":"# ilk sutun gozlemlerin indeksi olarak belirlenmis olarak csv dosyasini okuyunuz:\ncars = pd.read_csv(\"..\/input\/carsdataset\/cars.csv\", index_col = 0)\n\n\n# cars verisini tekrar yazdiriniz\ncars","00ecc032":"# country degiskenini bir Pandas Series olarak yazdiriniz\ncars[\"country\"]","571b2594":"# country degiskenini bir  Pandas DataFrame olarak yazdiriniz\ncars[[\"country\"]]","8d351fee":"# dataframe in sadece country ve drives_right degiskenlerini secerek yazdiriniz\ncars[[\"country\",\"drives_right\"]]","bc516d06":"# cars verisinin ilk 3 gozlemi yazdiriniz\ncars[:3]","f81248c0":"cars","0787febd":"# 4. 5. ve 6. gozlemleri yazdiriniz\ncars[3:6]","b1fc2074":"cars","28dbe921":"# sadece Japonya ya ait bilgileri yazdiriniz\ncars.loc[\"JAP\"]","b69bce92":"# Avusturya ve Misira ait bilgileri yazdiriiniz\ncars.loc[[\"AUS\",\"EG\"], \"cars_per_cap\" : \"drives_right\" ]","102ec4be":"# Morocco a ait drives_right bilgisini yazdiriniz\ncars.loc[\"MOR\", \"drives_right\"]","f458d346":"# rusya ve morocco nun country ve drives_right bilgilerini yazdiriniz:\ncars.loc[[\"RU\",\"MOR\"], [\"country\",\"drives_right\"] ]","51dc4819":"# ABD'den Rusyaya (ikisi de dahil), cars_per_cap tan drives_right'a(ikisi de dahil) loc kullanarak g\u00f6zlemleri yazd\u0131r\u0131n\u0131z\ncars.loc[\"US\":\"RU\", \"cars_per_cap\":\"drives_right\"]","5eb49337":"# drives_right kolonunu(degiskenini) bir Series olarak yazdiriniz (loc ile):\ncars.loc[: , \"drives_right\"]","27155c6d":"# drives_right kolonunu(degiskenini) bir DataFrame olarak yazdiriniz (loc ile):\ncars.loc[: , [\"drives_right\"]]","b19e7d21":"# cars_per_cap ve drives_right kolonlarini(degiskenlerini) bir DataFrame olarak yazdiriniz (loc ile):\ncars.loc[:,[\"cars_per_cap\", \"drives_right\"]]","3f898e2d":"# cars_per_cap degeri 500 den buyuk olan degerleri True olarak g\u00f6nderiniz. bu veriyi  car_maniac  adiyla kaydediniz \ncar_maniac = cars[\"cars_per_cap\"] > 500\n\n\n\n#  car_maniac  verisini yazdiriniz\ncar_maniac","514283a5":"import numpy as np\n\n# cars_per_cap degeri 500 den k\u00fc\u00e7\u00fck ve 100 den b\u00fcy\u00fck olan degerleri True d\u00f6nd\u00fcr\u00fcn\u00fcz. bu veriyi  medium  adiyla kaydediniz\nmedium = (cars[\"cars_per_cap\"] < 500) & (cars[\"cars_per_cap\"] > 100)\n\n# medium u yazdiriniz\nmedium","ef986833":"med = cars[(cars[\"cars_per_cap\"] < 500) & (cars[\"cars_per_cap\"] > 100)]\n\nmed","9cc4a1e1":"\"saltuk\" + str(5)","e28c702c":"# bir ustteki hucrede yazilan ciktiyi veren kodlari yaziniz. (cars dataframe'inin uzerinde dongu kullanarak)\nfor index, row in cars.iterrows():\n    print(index + \": \" + str(row[\"cars_per_cap\"]))","585c07fd":"cars","0eb7b967":"# Cars verisi uzerinde goruldugu gibi country adli bir degisken(kolon) var. df uzerinde for dongusu ile bu degiskeni kullanip \n# ayni ulke isimlerinin buyuk harfli halini barindiran yeni bir degisken olusturup bu veriye ekleyiniz.\n# yeni degiskenin adi: COUNTRY seklinde olsun\n\nfor index, row in cars.iterrows():\n    cars.loc[index, \"COUNTRY\"] = row[\"country\"].upper()\n    \n# df i yazdiriniz\ncars","49f1059c":"\n# cars verisinin ilk halini tekrar cagiralim:\ncars = pd.read_csv(\"..\/input\/carsdataset\/cars.csv\", index_col = 0)\n\n# 16. adimda yapilan ayni seyi .apply(str.upper)  yontemi ile yapiniz. (Bilgiye dikkat!)\ncars[\"COUNTRY\"] = cars[\"country\"].apply(str.upper)\n\n# cars df sini yazdiriniz\ncars","c3d7b6d3":"#girilen de\u011ferin karesini alan fonksiyon yaz\u0131n.\ndef square(x):\n    return x**2","388196d3":"#\u00fcstte yaz\u0131lan fonksiyonu apply ile cars_per_cap columnuna uygulay\u0131n. Bu de\u011ferleri \"kare\" isimli yeni bir columna yazd\u0131r\u0131n.\ncars[\"kare\"] = cars[\"cars_per_cap\"].apply(square)","368ef4ee":"cars","c7302d5d":"# cars_per_cap de\u011ferlerinin lambda kullanarak k\u00fcp\u00fcn\u00fc al\u0131n. Bu de\u011ferleri \"k\u00fcp\" isimli yeni bir columna yazd\u0131r\u0131n.\ncars[\"k\u00fcp\"] = cars[\"cars_per_cap\"].apply(lambda x: x**3)","4846fc59":"# cars df yazd\u0131r\u0131n.\ncars","580c7112":"# homeless pkl dosyas\u0131n\u0131 okutun\ndf = pd.read_pickle(\"..\/input\/homelessdata\/homeless_data.pkl\")","87f8b1d7":"df.head()","0ea93289":"df.info()","2d6d9616":"df.shape","bf7b55d8":"# descriptive statistic\ndf.describe().T","6de0e787":"df.values","2e22af15":"df.columns","5630c1a0":"df.index","8710c941":"# df i  individual degiskenine gore siralayiniz.  df_ind ile kaydediniz\ndf_ind = df.sort_values(\"individuals\")\n\n# df_ind  in ilk 5 gozlemini yazdiriniz\ndf_ind.head()","fdd0fac4":"# df i family members degiskenine gore tersten (buyukten kucuge) siralayiniz.    df_fam adi ile kaydediniz \n# (ascending=duz=kucukten buyuge)\n\ndf_fam = df.sort_values(\"family_members\", ascending = False)\n\n\n# df_fam in ilk 5 gozlemini yazdiriniz\ndf_fam.head()","16b728b3":"# df i region degiskenine gore duz ve bu siralamanin uzerine ayni zamanda family members degiskenine gore tersten siralayiniz.    \n# df_reg_fam adi ile kaydediniz \ndf_reg_fam = df.sort_values([\"region\", \"family_members\"], ascending = [True, False])\n\n\n# df_reg_fam in ilk 5 gozlemini yazdiriniz\ndf_reg_fam.head()","1848f46a":"# individuals degerinin  10000  den fazla oldugu gozlemleri seciniz:  ind_buyuk_10k ad\u0131 ile kaydediniz\nind_buyuk_10k = df[df[\"individuals\"] > 10000]\n\n# ind_buyuk_10k in ilk 5 gozlemini yazdiriniz\nind_buyuk_10k.head()","d07fa80c":"#  region degiskeni  Mountain  olan gozlemleri deciniz:  mountain_reg ad\u0131 ile kaydediniz\nmountain_reg = df[df[\"region\"] == \"Mountain\"]\n\n#mountain_reg in ilk 5 gozlemini yazdiriniz\nmountain_reg.head()","49d2f728":"# family_members degeri 1000 den kucuk olan ve region i Pacific  olan gozlemleri seciniz: fam_buyuk_1k_pac ad\u0131 ile kaydediniz\nfam_buyuk_1k_pac = df[(df[\"family_members\"] < 1000) & (df[\"region\"] == \"Pacific\")]\n\n#fam_buyuk_1k_pac in ilk 5 gozlemini yazdiriniz\nfam_buyuk_1k_pac","5444640a":"# region degiskeni   South Atlantic  veya  Mid-Atlantic  olan gozlemleri seciniz:  south_mid_atlantic ad\u0131 ile kaydediniz\nsouth_mid_atlantic = df[df[\"region\"].isin([\"South Atlantic\",\"Mid-Atlantic\"])][[\"state\"]]\n\n# print\nsouth_mid_atlantic","8eabe781":"cities = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n\n# state degiskeni  cities  listesinin icinde olan gozlemleri seciniz\/filtreleyiniz:  cities_df ad\u0131 ile kaydediniz\ncities_df = df[df[\"state\"].isin(cities)]\n\n# print\ncities_df","05a57126":"# individuals  ve  family_members  degiskenlerinin toplamini belirten  total  adli bir degisken ekleyiniz\ndf[\"total\"] = df[\"individuals\"] + df[\"family_members\"]\n\n\n# tek yasayan evsizlerin tum evsizlere olan oranini belirten bir degisken ekleyiniz: o_individuals\n# bunu  individuals \/ total ile bulabiliriz:\ndf[\"o_individuals\"] = df[\"individuals\"] \/ df[\"total\"]\n\n# df.head() in son hali:\ndf","3f108f2e":"\n# walmart_sales veri setini satislar ad\u0131yla kaydedelim.\nsatislar = pd.read_pickle(\"..\/input\/walmartsalesdataset\/walmart_sales.pkl\")","647b7162":"satislar.head()","0551ce7d":"satislar[\"weekly_sales\"].mean()","0be07a64":"satislar.weekly_sales.mean()","af18c696":"satislar.weekly_sales.median()","f0fb5541":"satislar[\"date\"].max()","bc8672c1":"satislar.date.min()","a4325685":"satislar.head()","21669cc8":"satislar.agg({\"weekly_sales\":[\"min\",\"max\",\"median\"],\"temperature_c\":\"mean\"}).T","c277cb6d":"# Tipine(type de\u011fi\u015fkeni) gore magaza sayilarini bulunuz (value_counts): \nsatislar[\"type\"].value_counts()","2c4a33bb":"# Tipine gore magaza oranlarini bulunuz (value_counts):\nsatislar[\"type\"].value_counts(normalize = True)","36c340dc":"# Tipine gore magazalarin departman sayilari, sirali olarak yazdiriniz:\nsatislar[[\"type\",\"department\"]].value_counts()","75e7cb1c":"# yukaridaki sonucun oransal degerleri ve siralanmis hali berabear yazdiralim:\nsatislar[[\"type\",\"department\"]].value_counts(normalize = True, sort = True)","a9287468":"# type a gore guruplayiniz, magaza tiplerinin haftalik satis toplamlarini bulunuz: satislar_tipe_gore ad\u0131yla kaydedin\nsatislar_tipe_gore = satislar.groupby(\"type\")[\"weekly_sales\"].sum()\n\n\n# satis miktarlarini (uc tipin miktarlari) toplamlarina bolerek oranlarini bulunuz\nsatislar_orani = satislar_tipe_gore\/sum(satislar_tipe_gore)\nsatislar_orani","d4c5f279":"# haftalik satislari type ve is_holiday durumuna a gore guruplayiniz, \n# (cift guruplama: ornegin tipi A olan magazada tatil olma durumuna gore satis sayilari ... gibi)\n","b208e490":"satislar_type_isholiday = satislar.groupby([\"type\",\"is_holiday\"])[\"weekly_sales\"].sum()","11fa5e5c":"satislar_type_isholiday","eed9d054":"20. df'i iki boyutlu numpy arrayi olarak yazdirin","6b64c70a":"df.column.agg(function)","60cd7a5f":"## Aggregating","4306d009":"## homeless_data verisi uzerinde calisalim:","524cf472":"4. ilk kolonu satirlarin indeksi olarak acmak icin kulanilan arguman:  index_col = 0","99546a62":"30. df[df['column'].isin(a_list)]","692aa56f":"37. satislar['variable'].agg(a_function)","e66e6321":"11. Filtreleme-Secme 2:","76346e47":"33. weekly_sales degiskeninin ortalamasini yazdiriniz:","6a0b3fd9":"12. Filtreleme-Secme 3:","ebdadaf0":"41. groupby","a341b908":"10. tek satirda ayni islem:","1ec32a24":"18. df 'nin boyutunu yazdirin","54675e32":"US: 809\nAUS: 731\nJAP: 588\nIN: 18\nRU: 200\nMOR: 70\nEG: 45","d27cc896":"5. Koseli parantezle degisken secme :","6ab4d300":"19. df'in degiskenlerinin istatistiklerini yazdirin","1add0315":"28. df[(df[\"variable1\"] < 100) & (df[\"variable2\"] == \"example\")]","0696e754":"13. DataFrame uzerinde dongu-2","6440523a":"9. loc ve iloc 3:","01daea49":"27. df[ df['variable']=='example' ]","d3e847b0":"17. df hakkinda yapisal bilgileri yazdirin","ad3e4fc3":"8. loc ve iloc 2:","0fbe23fb":"39. df['variable'].value_counts(normalize=True)","67c8a1a0":"22. df'in gozlem(satir) indekslerini yazdirin","bda8c71c":"25. df.sort_values(['variable_name1','variable_name2'], ascending=[False,False] )","eacab25a":"32. satislar dataframe'inin ilk bes gozlemini yazdiriniz","5b710432":"23. df.sort_values('variable_name')","a1f32fdf":"38. df['variable'].value_counts()","0c355a1a":"7. loc ve iloc:","1d0d4ed7":"16. df nin ilk bes gozlemini yazdirin","8f079f42":"3. csv dosyasi okuma:","b85f2446":"21. df'in degisken(kolon) isimlerini bir baska degisle kolon index isimlerini yazdirin","7637189a":"# Veri Manipulasyonu 201: Pandas","f94947cd":"# Extra about apply","a623fb24":"36. Ilk satilan urun hangi tarihte satilmistir","f5cab2a4":"29. df[\"variable\"] .isin([a,b,c,d])","32388dd3":"1. sozlukten Dataframe olusturma:  pd.DataFrame()","d8d790f0":"15. dongu yerine .apply() methodu:","bb99388a":"6. Koseli parantezle gozlem secme :","039ec0d4":"2. gozlem indeksleri atama: df.index =","d56326aa":"BILGI:\n\ncolors = [\"brown\", \"black\", \"tan\"]\ncondition = dogs[\"color\"].isin(colors)\ndogs[condition]\n\nveya\n\ncolors = [\"brown\", \"black\", \"tan\"]\ndogs[ dogs[\"color\"].isin(colors) ]","bdc520ee":"31. Simple Feature Engineering","250464b3":"### ozet istatistikler","2b9aa913":"df['column1','column2','column3'].agg(['function1','function2'])","582e2fdc":"BILGI:\ncpc = cars['cars_per_cap']\ncars[ (cpc > 10) & (cpc < 80) ]\n\nveya \n\ncpc = cars['cars_per_cap']\ncars[ np.logical_and(cpc > 10, cpc < 80) ]","2fc35ca3":"35. Son satilan urun hangi tarihte satilmistir","b2d401bf":"26. df[ df['variable'] > 100 ]","8a85f27d":"14. Dongu ile dataframe'e ait olan bir degiskeni alip, bir islem yapip baska bir degisken olarak dataframe'e ekleme","f9d23265":"40. df['variable'].value_counts(sort=True)","9325d303":"24. df.sort_values('variable_name', ascending=False )","3fa9dd93":"BILGI: Asagida verilen iki kod parcacigi ayni isi yapar:\n\nfor degisken, gozlem in df.iterrows() :\n    df.loc[degisken, \"name_length\"] = len(gozlem[\"country\"])\n\ndf[\"name_length\"] = df[\"country\"].apply(len)","6ba07fe4":"\n#\u00a0AGGREGAT\u0130ON \u0130LE \u0130LG\u0130L\u0130 EKSTRA G\u00d6STER\u0130LEB\u0130L\u0130R. DATAFRAME AGGREGAT\u0130ON YAZIP ARANAB\u0130L\u0130R GOOGLE DA","919098e8":"34. weekly_sales degiskeninin ortanca degerini yazdiriniz: "}}