{"cell_type":{"2fba80ae":"code","5f8879d2":"code","d6330c3a":"code","63d922ec":"code","8e545093":"code","c6d779cf":"code","825275c3":"code","309df4af":"code","229fe017":"code","8d598e75":"code","6cd1403e":"code","cd71b7a9":"code","0dd3e4ee":"code","54f2a719":"markdown"},"source":{"2fba80ae":"# https:\/\/www.kaggle.com\/artgor\/dcgan-baseline\nfrom __future__ import print_function\n#%matplotlib inline\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom torchvision.utils import save_image\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","5f8879d2":"len(os.listdir('..\/input\/daqian-oracle'))","d6330c3a":"# Setting parameters\ndataroot = \"..\/input\"\nworkers = 2\n\nbatch_size = 128\nimage_size = 64\n\n# Number of channels\nnc = 3\n# Latent vector (i.e. size of generator input)\nnz = 100\n# Size of feature maps in generator\nngf = 64\n# Size of feature maps in discriminator\nndf = 64\n\n# Number of training epochs\nepochs = 1000\n# Learning rate for optimizers\nlr_gen = 0.001\nlr_dis = 0.00001\n# Beta1 hyperparam for Adam optimizers\nbeta1 = 0.3\nngpu = 1","63d922ec":"dataset = dset.ImageFolder(root=dataroot,\n                           transform=transforms.Compose([\n                               transforms.Resize((image_size+30, image_size+30)),\n                               transforms.RandomCrop((image_size, image_size), padding=None, pad_if_needed=False, fill=1, padding_mode='constant'),\n                               transforms.RandomHorizontalFlip(p=0.5), # could be improved\n                               transforms.RandomVerticalFlip(p=0.5),\n#                                transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3),\n#                                transforms.RandomRotation((-20, +20), resample=False, expand=False, center=None, fill=1),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\n# Create the dataloader\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=workers)\n\n# Decide which device we want to run on\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")","8e545093":"real_batch = next(iter(dataloader))\nplt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.title(\"Training Images\");\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)));","c6d779cf":"# def weights_init(m):\n#     classname = m.__class__.__name__\n#     if classname.find('Conv') != -1:\n#         nn.init.normal_(m.weight.data, 0.0, 0.02)\n#     elif classname.find('BatchNorm') != -1:\n#         nn.init.normal_(m.weight.data, 1.0, 0.02)\n#         nn.init.constant_(m.bias.data, 0)\n\n# ----------------------------------------------------------------------------\n# Pixelwise feature vector normalization.\n# reference: https:\/\/github.com\/tkarras\/progressive_growing_of_gans\/blob\/master\/networks.py#L120\n# ----------------------------------------------------------------------------\nclass PixelwiseNorm(nn.Module):\n    def __init__(self):\n        super(PixelwiseNorm, self).__init__()\n\n    def forward(self, x, alpha=1e-8):\n        \"\"\"\n        forward pass of the module\n        :param x: input activations volume\n        :param alpha: small number for numerical stability\n        :return: y => pixel normalized activations\n        \"\"\"\n        y = x.pow(2.).mean(dim=1, keepdim=True).add(alpha).sqrt()  # [N1HW]\n        y = x \/ y  # normalize the input x volume\n        return y","825275c3":"# https:\/\/www.kaggle.com\/phoenix9032\/gan-dogs-starter-24-jul-custom-layers\ndef show_generated_img_all():\n    gen_z = torch.randn(32, nz, 1, 1, device=device)\n    gen_images = netG(gen_z).to(\"cpu\").clone().detach()\n    gen_images = gen_images.numpy().transpose(0, 2, 3, 1)\n    gen_images = (gen_images+1.0)\/2.0\n    fig = plt.figure(figsize=(25, 16))\n    for ii, img in enumerate(gen_images):\n        ax = fig.add_subplot(4, 8, ii + 1, xticks=[], yticks=[])\n        plt.imshow(img)\n    #plt.savefig(filename)  \n    \n### This is to show one sample image for iteration of chosing\ndef show_generated_img():\n    noise = torch.randn(1, nz, 1, 1, device=device)\n    gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n    gen_image = gen_image.numpy().transpose(1, 2, 0)\n    gen_image = ((gen_image+1.0)\/2.0)\n    plt.imshow(gen_image)\n    plt.show()\n\nclass MinibatchStdDev(torch.nn.Module):\n    \"\"\"\n    Minibatch standard deviation layer for the discriminator\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        derived class constructor\n        \"\"\"\n        super(MinibatchStdDev, self).__init__()\n\n    def forward(self, x, alpha=1e-8):\n        \"\"\"\n        forward pass of the layer\n        :param x: input activation volume\n        :param alpha: small number for numerical stability\n        :return: y => x appended with standard deviation constant map\n        \"\"\"\n        batch_size, _, height, width = x.shape\n        # [B x C x H x W] Subtract mean over batch.\n        y = x - x.mean(dim=0, keepdim=True)\n        # [1 x C x H x W]  Calc standard deviation over batch\n        y = torch.sqrt(y.pow(2.).mean(dim=0, keepdim=False) + alpha)\n\n        # [1]  Take average over feature_maps and pixels.\n        y = y.mean().view(1, 1, 1, 1)\n\n        # [B x 1 x H x W]  Replicate over group and pixels.\n        y = y.repeat(batch_size,1, height, width)\n\n        # [B x C x H x W]  Append as new feature_map.\n        y = torch.cat([x, y], 1)\n        # return the computed values:\n        return y","309df4af":"from torch.nn.utils import spectral_norm\nfrom torch.optim import lr_scheduler\n\nclass Generator(nn.Module):\n    def __init__(self, nz, nfeats, nchannels):\n        super(Generator, self).__init__()\n\n        # input is Z, going into a convolution\n        self.conv1 = spectral_norm(nn.ConvTranspose2d(nz, nfeats * 8, 4, 1, 0, bias=False))\n        #self.bn1 = nn.BatchNorm2d(nfeats * 8)\n        # state size. (nfeats*8) x 4 x 4\n        \n        self.conv2 = spectral_norm(nn.ConvTranspose2d(nfeats * 8, nfeats * 8, 4, 2, 1, bias=False))\n        #self.bn2 = nn.BatchNorm2d(nfeats * 8)\n        # state size. (nfeats*8) x 8 x 8\n        \n        self.conv3 = spectral_norm(nn.ConvTranspose2d(nfeats * 8, nfeats * 4, 4, 2, 1, bias=False))\n        #self.bn3 = nn.BatchNorm2d(nfeats * 4)\n        # state size. (nfeats*4) x 16 x 16\n        \n        self.conv4 = spectral_norm(nn.ConvTranspose2d(nfeats * 4, nfeats * 2, 4, 2, 1, bias=False))\n        #self.bn4 = nn.BatchNorm2d(nfeats * 2)\n        # state size. (nfeats * 2) x 32 x 32\n        \n        self.conv5 = spectral_norm(nn.ConvTranspose2d(nfeats * 2, nfeats, 4, 2, 1, bias=False))\n        #self.bn5 = nn.BatchNorm2d(nfeats)\n        # state size. (nfeats) x 64 x 64\n        \n        self.conv6 = spectral_norm(nn.ConvTranspose2d(nfeats, nchannels, 3, 1, 1, bias=False))\n        # state size. (nchannels) x 64 x 64\n        self.pixnorm = PixelwiseNorm()\n    def forward(self, x):\n        #x = F.leaky_relu(self.bn1(self.conv1(x)))\n        #x = F.leaky_relu(self.bn2(self.conv2(x)))\n        #x = F.leaky_relu(self.bn3(self.conv3(x)))\n        #x = F.leaky_relu(self.bn4(self.conv4(x)))\n        #x = F.leaky_relu(self.bn5(self.conv5(x)))\n        x = F.leaky_relu(self.conv1(x))\n        x = F.leaky_relu(self.conv2(x))\n        x = self.pixnorm(x)\n        x = F.leaky_relu(self.conv3(x))\n        x = self.pixnorm(x)\n        x = F.leaky_relu(self.conv4(x))\n        x = self.pixnorm(x)\n        x = F.leaky_relu(self.conv5(x))\n        x = self.pixnorm(x)\n        x = torch.tanh(self.conv6(x))\n        \n        return x\n\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, nchannels, nfeats):\n        super(Discriminator, self).__init__()\n\n        # input is (nchannels) x 64 x 64\n        self.conv1 = nn.Conv2d(nchannels, nfeats, 4, 2, 1, bias=False)\n        # state size. (nfeats) x 32 x 32\n        \n        self.conv2 = spectral_norm(nn.Conv2d(nfeats, nfeats * 2, 4, 2, 1, bias=False))\n        self.bn2 = nn.BatchNorm2d(nfeats * 2)\n        # state size. (nfeats*2) x 16 x 16\n        \n        self.conv3 = spectral_norm(nn.Conv2d(nfeats * 2, nfeats * 4, 4, 2, 1, bias=False))\n        self.bn3 = nn.BatchNorm2d(nfeats * 4)\n        # state size. (nfeats*4) x 8 x 8\n       \n        self.conv4 = spectral_norm(nn.Conv2d(nfeats * 4, nfeats * 8, 4, 2, 1, bias=False))\n        self.bn4 = nn.MaxPool2d(2)\n        # state size. (nfeats*8) x 4 x 4\n        self.batch_discriminator = MinibatchStdDev()\n        self.pixnorm = PixelwiseNorm()\n        self.conv5 = spectral_norm(nn.Conv2d(nfeats * 8 +1, 1, 2, 1, 0, bias=False))\n        # state size. 1 x 1 x 1\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x), 0.2)\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)\n       # x = self.pixnorm(x)\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)\n       # x = self.pixnorm(x)\n        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)\n       # x = self.pixnorm(x)\n        x = self.batch_discriminator(x)\n        x = torch.sigmoid(self.conv5(x))\n        #x= self.conv5(x)\n        return x.view(-1, 1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nlr = 0.0002\nlr_d = 0.0002\nbeta1 = 0.5\nepochs = 1600\nnetG = Generator(100, 32, 3).to(device)\nnetD = Discriminator(3, 48).to(device)\n\ncriterion = nn.BCELoss()\n#criterion = nn.MSELoss()\n\noptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=lr_d, betas=(beta1, 0.999))\n# lr_schedulerG = lr_scheduler.CosineAnnealingWarmRestarts(optimizerG, T_0=epochs\/\/200, eta_min=0.00005)\n# lr_schedulerD = lr_scheduler.CosineAnnealingWarmRestarts(optimizerD, T_0=epochs\/\/200, eta_min=0.00005)\nlr_schedulerG = lr_scheduler.MultiStepLR(optimizerG, milestones=[150, 200], gamma=0.1)\nlr_schedulerD = lr_scheduler.MultiStepLR(optimizerD, milestones=[150, 200], gamma=0.1)\n\nnz = 100\nfixed_noise = torch.randn(25, nz, 1, 1, device=device)\n\nreal_label = 0.7\nfake_label = 0.0","229fe017":"from tqdm import tqdm_notebook as tqdm\nfrom time import time\nimport torch.nn.functional as F\nfrom scipy.stats import truncnorm\nstart = time()\n\nG_losses = []\nD_losses = []\n\nreal_chance = []\nfake_chance = []\n\nstep = 0\nfor epoch in range(epochs):\n    for ii, (real_images) in enumerate(dataloader):\n        end = time()\n        if (end -start) > 25000 :\n            break\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        real_images = real_images[0] ############################################ CAREFUL\n        \n        \n        netD.zero_grad()\n        real_images = real_images.to(device)\n        batch_size = real_images.size(0)\n        labels = torch.full((batch_size, 1), real_label, device=device) +  np.random.uniform(-0.1, 0.1)\n\n        output = netD(real_images)\n        errD_real = criterion(output, labels)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        # train with fake\n        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        labels.fill_(fake_label) + np.random.uniform(0, 0.2)\n        output = netD(fake.detach())\n        errD_fake = criterion(output, labels)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        labels.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake)\n        errG = criterion(output, labels)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n        \n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n        \n        real_chance.append(errD_real.item())\n        fake_chance.append(errD_fake.item())\n        \n        if step % 2 == 0:\n            print('[%d\/%d][%d\/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f \/ %.4f'\n                  % (epoch + 1, epochs, ii, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n            \n            valid_image = netG(fixed_noise)\n        step += 1\n        lr_schedulerG.step(epoch)\n        lr_schedulerD.step(epoch)\n\n    if epoch % 200 == 0:\n        show_generated_img()","8d598e75":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses,label=\"G\")\nplt.plot(D_losses,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","6cd1403e":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(real_chance,label=\"Real\")\nplt.plot(fake_chance,label=\"Fake\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","cd71b7a9":"# torch.save(netG.state_dict(), 'generator.pth')\n# torch.save(netD.state_dict(), 'discriminator.pth')\n\ndef truncated_normal(size, threshold=1):\n    values = truncnorm.rvs(-threshold, threshold, size=size)\n    return values\n\nif not os.path.exists('..\/output_images'):\n    os.mkdir('..\/output_images')\nim_batch_size = 100\nn_images=10000\nfor i_batch in range(0, n_images, im_batch_size):\n    z = truncated_normal((im_batch_size, 100, 1, 1), threshold=1)\n    gen_z = torch.from_numpy(z).float().to(device)    \n    #gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n    gen_images = netG(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)): save_image((gen_images[i_image, :, :, :] +1.0)\/2.0, os.path.join('..\/output_images', f'image_{i_batch+i_image:05d}.png'))\n\n\nimport shutil\nshutil.make_archive('images', 'zip', '..\/output_images')","0dd3e4ee":"# https:\/\/www.kaggle.com\/artgor\/dcgan-baseline\nfig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor i, j in enumerate(images[:32]):\n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    plt.imshow(j)","54f2a719":"# Meiling Han's Words from Heaven"}}