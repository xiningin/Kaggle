{"cell_type":{"b28155ff":"code","7b162313":"code","c7361ba1":"code","6e68efda":"code","ef971285":"code","bcb92afb":"code","8ceacefa":"code","6c8cb714":"code","ff99b843":"code","34985ecf":"code","ddd29a37":"code","f86e9fa4":"code","8fe44aeb":"code","775316a7":"code","5c3c1454":"code","137636ac":"code","da8ef1a2":"code","b1586923":"code","116ac0b7":"code","21b4674a":"code","eebdcfb1":"code","c3711900":"code","8947a62f":"code","09302d2d":"code","50554a87":"code","fcaab3e1":"code","43069b3b":"code","116aaeb0":"code","2c7a6578":"code","77584009":"code","42f4ac8d":"markdown"},"source":{"b28155ff":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline","7b162313":"train_data=pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_data.head()","c7361ba1":"\ntest_data=pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data.head()\n\n","6e68efda":"train_data.describe()","ef971285":"sns.heatmap(train_data.isnull(),yticklabels=False) # check missing values","bcb92afb":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","8ceacefa":"print(\"males survived:\", train_data[\"Survived\"][train_data[\"Sex\"] == 'male'].value_counts(normalize=True))","6c8cb714":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data) #survived by class","ff99b843":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train_data,hue='Sex')","34985ecf":"# dropping missing values coulumn\ntrain_data = train_data.drop(['Cabin'], axis = 1)\ntest_data = test_data.drop(['Cabin'], axis = 1)","ddd29a37":"# cleaning and processing data \nsns.boxplot(x='Pclass',y='Age',data=train_data)\n# first class people have higher age","f86e9fa4":"\n\n# age column has missing values \n#applying function to set age according to class \n# for example class 1 people might be having average age 40 \n\ndef set_age(cols):\n    age=cols[0]\n    pclass=cols[1]\n    \n    if pd.isnull(age):\n        \n        if pclass==1:\n            return 40\n        elif pclass == 2:\n            return 30\n        else:\n            return 25\n    \n    else: \n        return age\n    \n    \ntrain_data['Age']=train_data[['Age','Pclass']].apply(set_age,axis=1)\ntest_data['Age']=test_data[['Age','Pclass']].apply(set_age,axis=1)\n\n","8fe44aeb":"sns.heatmap(train_data.isnull(),yticklabels=False)  #no missing values now","775316a7":"train_sex_new=pd.get_dummies(train_data['Sex'],drop_first=True) #replacing categorcial data with numerical value\ntrain_embark_new=pd.get_dummies(train_data['Embarked'],drop_first=True)\n\ntest_sex_new=pd.get_dummies(test_data['Sex'],drop_first=True) #replacing categorcial data with numerical value\ntest_embark_new=pd.get_dummies(test_data['Embarked'],drop_first=True)","5c3c1454":"train_data=pd.concat([train_data,train_sex_new,train_embark_new],axis=1)\ntest_data=pd.concat([test_data,test_sex_new,test_embark_new],axis=1)","137636ac":"train_data.drop(['Sex','Embarked'],axis=1,inplace=True)\ntest_data.drop(['Sex','Embarked'],axis=1,inplace=True)","da8ef1a2":"\n\ntrain_data.head()\n\n","b1586923":"# dropping unnecessary columns \n\ntrain_data = train_data.drop(['Ticket','Name'], axis = 1)\ntest_data = test_data.drop(['Ticket','Name'], axis = 1)","116ac0b7":"train_data.head() #all numerical values","21b4674a":"test_data.head()  # all numericals","eebdcfb1":"# final check on missing data\nprint(pd.isnull(train_data).sum())\nprint(pd.isnull(test_data).sum()) #one fare value missing in test data","c3711900":"# filling missing fare value based on mean fare value for respective clas s\nfor i in range(len(test_data[\"Fare\"])):\n    if pd.isnull(test_data[\"Fare\"][i]):\n        pc = test_data[\"Pclass\"][i] # respective Pclass \n        test_data[\"Fare\"][i] = round(train_data[train_data[\"Pclass\"] == pc][\"Fare\"].mean(), 4)","8947a62f":"print(pd.isnull(test_data).sum())","09302d2d":"# train test split \nfrom sklearn.model_selection import train_test_split\n\nX = train_data.drop(['Survived', 'PassengerId'], axis=1)\ny = train_data[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","50554a87":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=10000)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)","fcaab3e1":"from sklearn.metrics import classification_report","43069b3b":"print(classification_report(y_pred,y_test))\n\nfrom sklearn.metrics import accuracy_score\na = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(a) \n # 79 percent accuracy","116aaeb0":"# Support Vector Machines\n\nfrom sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\na = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(a)","2c7a6578":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\na = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(a)","77584009":"'''\nTo submit to kaggle first predict on test_data given by kaggle as: \n\n# predicting on given test data\n\n#set ids as PassengerId and prediction \npid = test_data['PassengerId']\npredictions = rf.predict(test_data.drop('PassengerId', axis=1))\n\n#sconvert to csv file named submission.csv\n\nsubmit = pd.DataFrame({ 'PassengerId' : pid, 'Survived': predictions })\nsubmit.to_csv('titanic_submission2.csv', index=False)\n\n\n'''","42f4ac8d":"**Random Forest** fits better"}}