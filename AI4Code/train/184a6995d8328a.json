{"cell_type":{"3334942e":"code","2224d9e3":"code","3fb13dfe":"code","e748aefd":"code","31a1cfe4":"code","edbfc26e":"code","609da7ad":"code","6fc1bd1e":"code","0a6c87a3":"code","78e72768":"code","bb70186d":"code","ae8463bb":"code","c71afd08":"code","a775107b":"code","9c11c466":"markdown","b2b728b4":"markdown","b739b832":"markdown","8983aaa2":"markdown","dce57111":"markdown","fa905730":"markdown"},"source":{"3334942e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load  \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn import preprocessing, model_selection, tree, metrics\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport urllib.request\nimport zipfile\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2224d9e3":"train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","3fb13dfe":"X = train.drop('label', axis = 1)\ny = train['label']\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n                                        test_size = .2, shuffle = False)\n\nX_train = X_train \/ 255\nX_test = X_test \/ 255\ntest = test \/ 255","e748aefd":"input_ = keras.layers.Input(shape = (784,))\nx = keras.layers.Dense(units = 128, activation = 'relu')(input_)\nx = keras.layers.Dense(units = 128, activation = 'relu')(x)\noutput = keras.layers.Dense(units = 10, activation = 'softmax')(x)\nmodel = keras.models.Model(inputs = input_, outputs = output)\n\nprint(model.summary())\n\nmodel.compile(loss = 'sparse_categorical_crossentropy', \n              optimizer = 'rmsprop', metrics = ['accuracy'])\nhistory = model.fit(X_train, y_train, validation_data = (X_test, y_test), \n                    batch_size = 128, epochs = 10)","31a1cfe4":"# Test model\nmodel.evaluate(X_test, y_test)","edbfc26e":"# Visualize Validation Data Loss. We expect this to decrease with the number of epochs trained on\nplt.plot(history.history['val_loss'])","609da7ad":"x_train = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\nx_test = X_test.values.reshape(X_test.shape[0], 28, 28, 1)","6fc1bd1e":"inputs = keras.layers.Input(shape = (28, 28, 1))\nx = keras.layers.Conv2D(32, (3, 3), activation = 'relu')(inputs)\nx = keras.layers.MaxPooling2D(pool_size = (2, 2))(x)\nx = keras.layers.Conv2D(32, (3, 3), activation = 'relu')(x)\nx = keras.layers.MaxPooling2D(pool_size = (2, 2))(x)\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(128, activation = 'relu')(x)\noutput = keras.layers.Dense(10, activation = 'softmax')(x)\n\nmodel = keras.models.Model(inputs = inputs, outputs = output)\nmodel.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\nprint(model.summary())\n\nmodel.fit(x_train, y_train, validation_data  =  (x_test, y_test), batch_size = 128, epochs = 10)","0a6c87a3":"train_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train'\nvalidation_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation'\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  rotation_range = 40,\n                                  width_shift_range = .2,\n                                  height_shift_range = .2, \n                                   shear_range = 0.2,\n                                  zoom_range = 0.2,\n                                  horizontal_flip = True,\n                                  fill_mode = 'nearest')\ntrain_generator = train_datagen.flow_from_directory(train_path, \n                                                   target_size = (300, 300),\n                                                   class_mode = 'binary')\n\nval_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  rotation_range = 40,\n                                  width_shift_range = .2,\n                                  height_shift_range = .2, \n                                   shear_range = 0.2,\n                                  zoom_range = 0.2,\n                                  horizontal_flip = True,\n                                  fill_mode = 'nearest')\nval_generator = val_datagen.flow_from_directory(validation_path, \n                                                   target_size = (300, 300),\n                                                   class_mode = 'binary')\n\n","78e72768":"model = tf.keras.models.Sequential([\n tf.keras.layers.Conv2D(16, (3,3), activation='relu' ,\n input_shape=(300, 300, 3)),\n tf.keras.layers.MaxPooling2D(2, 2),\n tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n tf.keras.layers.MaxPooling2D(2,2),\n tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n tf.keras.layers.MaxPooling2D(2,2),\n tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n tf.keras.layers.MaxPooling2D(2,2),\n tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n tf.keras.layers.MaxPooling2D(2,2),\n tf.keras.layers.Flatten(),\n tf.keras.layers.Dense(512, activation='relu'),\n tf.keras.layers.Dense(1, activation='sigmoid')\n])\nprint(model.summary())\nmodel.compile(loss='binary_crossentropy',\n optimizer=keras.optimizers.RMSprop(lr=0.001),\n metrics=['accuracy'])\n","bb70186d":"history = model.fit_generator(train_generator,\n epochs=15, validation_data=val_generator)\n","ae8463bb":"from tensorflow.keras.applications.inception_v3 import InceptionV3\n\n# Load InceptionV3 Model; The Image dimensions must be consistent.\npre_trained_model = InceptionV3(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(150, 150, 3))\n\ntrain_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train'\nvalidation_path = '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation'\n\n# Since we are loading Images from disk, we use ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,)\ntrain_generator = train_datagen.flow_from_directory(train_path, \n                                                   target_size = (150, 150),\n                                                   class_mode = 'binary')\n\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\nval_generator = val_datagen.flow_from_directory(validation_path, \n                                                   target_size = (150, 150),\n                                                   class_mode = 'binary')","c71afd08":"# Print Summary - the model summary is large hence not printing here.\n#print(pre_trained_model.summary())\n\n# Set trainable and last layer\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n    \nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\n# Feed into another network\nx = keras.layers.Flatten()(last_output)\nx = keras.layers.Dense(1024, activation='relu')(x)\nx = keras.layers.Dense(1, activation='sigmoid')(x)\nmodel = keras.models.Model(pre_trained_model.input, x)\nmodel.compile(optimizer=keras.optimizers.RMSprop(lr=0.0001),\n                 loss='binary_crossentropy', metrics=['acc'])\n","a775107b":"model.fit_generator(train_generator, epochs = 10, validation_data=val_generator)","9c11c466":"## Train Neural Networks with Dense Units. \nWe dont expect excellent performance. CNNs are Expected to do much better.","b2b728b4":"## Perform Transfer Learning - Load InceptionV3","b739b832":"## Using CNN\n1. Use a Simple CNN with Max Pooling Layers.\n2. Use Data Augmentation to classify Horses vs Humans. Use ImageDataGenerator for the same.\n3. Perform Transfer Learning - load inceptionV3 model to classify Horses vs Humans. This gave much better performance. ","8983aaa2":"Transfer Learning gave best results with the least effort. The same model can also be finely tweaked to classify other kinds of Images. ","dce57111":"## Train to distinguish horses from humans\nThis Data was created by Lawrence Moroney. Here are some details about it:\nhttp:\/\/www.laurencemoroney.com\/horses-or-humans-dataset\/","fa905730":"## Contents:\n* Train Dense Neural Network to classify on the Fashion MNIST Data\n* Train CNN to classify Fashion MNIST Data\n* Use Data Augmentation to classify Horses vs Humans. Use ImageDataGenerator for the same.\n* Perform **Transfer Learning** - load **InceptionV3** model to classify Horses vs Humans. This gave much better performance."}}