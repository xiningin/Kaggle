{"cell_type":{"33308ddd":"code","797b1777":"code","976af678":"code","3ba5e552":"code","7e441517":"code","b303b989":"code","3531b8d6":"code","119e4f56":"code","4d2070c9":"code","d466e167":"code","f2374b09":"code","3b135a56":"code","34b3ef5e":"code","f31b0e5e":"code","6d5d0da1":"code","8324246a":"code","5591d46b":"code","808fabbc":"code","df884c1d":"code","27bca5a4":"code","4ce0cc9a":"code","a7e1451a":"code","3d8375bb":"code","e41ed741":"code","3b18ebab":"code","5fa62b0d":"code","7777b8e1":"code","637b1787":"code","bbc54c08":"markdown"},"source":{"33308ddd":"#------------------------------------------------------------------------------------------\n# 1.Imports\n#------------------------------------------------------------------------------------------\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom prettytable import PrettyTable","797b1777":"#------------------------------------------------------------------------------------------\n# 2.Datasets\n#------------------------------------------------------------------------------------------\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\neval_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntrain_data_raw = train_data\neval_data_raw = eval_data","976af678":"#------------------------------------------------------------------------------------------\n# 3.Visualize the datasets\n#------------------------------------------------------------------------------------------\n\n#train_data to train model\ntrain_data.head()","3ba5e552":"#------------------------------------------------------------------------------------------\n# 4.Statistics of train data\n#------------------------------------------------------------------------------------------\ntrain_data.describe()","7e441517":"#------------------------------------------------------------------------------------------\n# 5.Eval_data to submit kaggle\n#------------------------------------------------------------------------------------------\neval_data.head()","b303b989":"#------------------------------------------------------------------------------------------\n# 6.Statistics eval_data\n#------------------------------------------------------------------------------------------\neval_data.describe()","3531b8d6":"#------------------------------------------------------------------------------------------\n# 7.Feature analysis\n#------------------------------------------------------------------------------------------\n\n#NaN Count\ndft = pd.DataFrame(train_data.isnull().sum(),columns=[\"Train NaN\"])\ndfe = pd.DataFrame(eval_data.isna().sum(),columns=[\"Eval NaN\"])\ndf = pd.concat([dft,dfe],axis=1)\ndf","119e4f56":"#------------------------------------------------------------------------------------------\n# 8.Ticket Class, Pclass, Sex and Embarked\n#------------------------------------------------------------------------------------------\ntrain_data['Embarked'].fillna(value='S', inplace=True)\neval_data['Fare'].fillna(value=train_data.Fare.mean(), inplace=True)\n\nfig,axx= plt.subplots(1, 3, figsize=(20,5))\naxx[0].set_title('Ticket Class Train')\nsns.countplot(x='Pclass', data=train_data, ax=axx[0])\naxx[1].set_title('Sex Train')\nsns.countplot(x='Sex', data=train_data, ax=axx[1])\naxx[2].set_title('Embarked(C - Cherbourg, Q - Queenstown, S - Southampton) Train')\nsns.countplot(x='Embarked', data=train_data, ax=axx[2])\nplt.tight_layout()\n\nfig,axx= plt.subplots(1, 3, figsize=(20,5))\naxx[0].set_title('Ticket Class Eval')\nsns.countplot(x='Pclass', data=eval_data, ax=axx[0])\naxx[1].set_title('Sex Eval')\nsns.countplot(x='Sex', data=eval_data, ax=axx[1])\naxx[2].set_title('Embarked(C - Cherbourg, Q - Queenstown, S - Southampton) Eval')\nsns.countplot(x='Embarked', data=eval_data, ax=axx[2])\nplt.tight_layout()","4d2070c9":"#------------------------------------------------------------------------------------------\n# 9.Pclass vs Fare\n#------------------------------------------------------------------------------------------\nfig,axx= plt.subplots(1, 2, figsize=(20,5))\naxx[0].set_title('Pclass vs Fare Train')\nsns.boxplot(x='Pclass',y='Fare',data=train_data, palette='Set2', ax = axx[0])\naxx[1].set_title('Pclass vs Fare Eval')\nsns.boxplot(x='Pclass',y='Fare',data=eval_data, palette='Set2',ax = axx[1])\nplt.tight_layout()","d466e167":"#------------------------------------------------------------------------------------------\n# 10.Age\n#------------------------------------------------------------------------------------------\n\nmean_age_miss = round(train_data[train_data[\"Name\"].str.contains('Miss.', na=False)]['Age'].mean())\nmean_age_mrs = round(train_data[train_data[\"Name\"].str.contains('Mrs.', na=False)]['Age'].mean())\nmean_age_mr = round(train_data[train_data[\"Name\"].str.contains('Mr.', na=False)]['Age'].mean())\nmean_age_master = round(train_data[train_data[\"Name\"].str.contains('Master.', na=False)]['Age'].mean())\n\nprint('Mean age of Miss. title {}'.format(mean_age_miss))\nprint('Mean age of Mrs. title {}'.format(mean_age_mrs))\nprint('Mean age of Mr. title {}'.format(mean_age_mr))\nprint('Mean age of Master. title {}'.format(mean_age_master))\n","f2374b09":"def fill_age(name_age):\n    \n    name = name_age[0]\n    age = name_age[1]\n    \n    if pd.isnull(age):\n        if 'Mr.' in name:\n            return mean_age_mr\n        if 'Mrs.' in name:\n            return mean_age_mrs\n        if 'Miss.' in name:\n            return mean_age_miss\n        if 'Master.' in name:\n            return mean_age_master\n        if 'Dr.' in name:\n            return mean_age_master\n        if 'Ms.' in name:\n            return mean_age_miss\n    else:\n        return age\n\ntrain_data['Age'] = train_data[['Name', 'Age']].apply(fill_age,axis=1)\neval_data['Age'] = eval_data[['Name', 'Age']].apply(fill_age,axis=1)\n\ndf=train_data.sort_values(by=[\"Age\"])\nplt.figure(figsize=(20, 5))\nax = sns.countplot(x='Age', data=df)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90 ,fontsize=8)\nplt.xlabel = \"Age\"\nplt.ylabel = \"Count\"\nplt.title(\"Age Train Data\")\nplt.tight_layout()\n\ndf=eval_data.sort_values(by=[\"Age\"])\nplt.figure(figsize=(20, 5))\nax = sns.countplot(x='Age', data=df)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90 ,fontsize=8)\nplt.xlabel = \"Age\"\nplt.ylabel = \"Count\"\nplt.title(\"Age Eval Data\")\nplt.tight_layout()\n","3b135a56":"#------------------------------------------------------------------------------------------\n# 11.Deck and Room\n#------------------------------------------------------------------------------------------\ntrain_data[\"Cabin_Data\"] = train_data[\"Cabin\"].isnull().apply(lambda x: not x)\ntrain_data[\"Deck\"] = train_data[\"Cabin\"].str.slice(0,1)\ntrain_data[\"Room\"] = train_data[\"Cabin\"].str.slice(1,5).str.extract(\"([0-9]+)\", expand=False).astype(\"float\")\n\neval_data[\"Cabin_Data\"] = eval_data[\"Cabin\"].isnull().apply(lambda x: not x)\neval_data[\"Deck\"] = eval_data[\"Cabin\"].str.slice(0,1)\neval_data[\"Room\"] = eval_data[\"Cabin\"].str.slice(1,5).str.extract(\"([0-9]+)\", expand=False).astype(\"float\")\n\ntrain_data[\"Deck\"] = train_data[\"Deck\"].fillna(\"N\")\ntrain_data[\"Room\"] = train_data[\"Room\"].fillna(train_data[\"Room\"].mean())\n\neval_data[\"Deck\"] = eval_data[\"Deck\"].fillna(\"N\")\neval_data[\"Room\"] = eval_data[\"Room\"].fillna(eval_data[\"Room\"].mean())","34b3ef5e":"train_data","f31b0e5e":"eval_data","6d5d0da1":"#------------------------------------------------------------------------------------------\n# 12.Deck vs Fare\n#------------------------------------------------------------------------------------------\nplt.figure(figsize=(12,5))\nplt.title('Deck vs Fare')\nsns.boxplot(x='Deck',y='Fare',data=train_data, palette='Set2')\nplt.tight_layout()","8324246a":"\nprint('Median Deck A {}'.format(train_data[train_data['Deck']=='A']['Fare'].median()))\nprint('Median Deck B {}'.format(train_data[train_data['Deck']=='B']['Fare'].median()))\nprint('Median Deck C {}'.format(train_data[train_data['Deck']=='C']['Fare'].median()))\nprint('Median Deck D {}'.format(train_data[train_data['Deck']=='D']['Fare'].median()))\nprint('Median Deck E {}'.format(train_data[train_data['Deck']=='E']['Fare'].median()))","5591d46b":"\nprint('Median Class 1 {}'.format(train_data[train_data['Pclass']==1]['Fare'].median()))\nprint('Median Class 2 {}'.format(train_data[train_data['Pclass']==2]['Fare'].median()))\nprint('Median Class 3 {}'.format(train_data[train_data['Pclass']==3]['Fare'].median()))","808fabbc":"#------------------------------------------------------------------------------------------\n# 13.Deck Analysis\n#------------------------------------------------------------------------------------------\nfig,axx= plt.subplots(1, 2, figsize=(20,5))\naxx[0].set_title('Deck Train')\nsns.countplot(x='Deck', data=train_data, ax=axx[0])\naxx[1].set_title('Deck Eval')\nsns.countplot(x='Deck', data=eval_data, ax=axx[1])\nplt.tight_layout()","df884c1d":"#------------------------------------------------------------------------------------------\n# 14.Deck vs Pclass Class\n#------------------------------------------------------------------------------------------\n\nplt.figure(figsize=(20, 5))\nax = sns.countplot(x='Deck', hue= \"Pclass\", data=train_data)\nax.set_xticklabels(ax.get_xticklabels())\nplt.xlabel = \"Deck\"\nplt.ylabel = \"Count\"\nplt.title(\"Deck Class\")\nplt.tight_layout()\n","27bca5a4":"#------------------------------------------------------------------------------------------\n# 15.New Features\n#------------------------------------------------------------------------------------------\ntrain_data['Family_size'] = train_data['SibSp'] + train_data['Parch'] + 1\neval_data['Family_size'] = eval_data['SibSp'] + eval_data['Parch'] + 1\n\ndef create_alone_feature(SibSp_Parch):\n    if (SibSp_Parch[0]+SibSp_Parch[1])==0:\n        return 1\n    else:\n        return 0\n \ntrain_data['Alone'] = train_data[['SibSp','Parch']].apply(create_alone_feature, axis=1)\neval_data['Alone'] = eval_data[['SibSp','Parch']].apply(create_alone_feature, axis=1)","4ce0cc9a":"#------------------------------------------------------------------------------------------\n# 16.Coorelation\n#------------------------------------------------------------------------------------------\ndf = train_data\nf = plt.figure(figsize=(19, 15))\nplt.matshow(df.corr(), fignum=f.number)\nplt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14, rotation=45)\nplt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);","a7e1451a":"#------------------------------------------------------------------------------------------\n# 17.Features to train\n#------------------------------------------------------------------------------------------\nfeatures = [\"Pclass\", \"Sex\",  \"Family_size\", \"Embarked\", \"Fare\", \"Age\"]\nlabel = \"Survived\"\n","3d8375bb":"#------------------------------------------------------------------------------------------\n# 18.Get dummies\n#------------------------------------------------------------------------------------------\n\ntrain_data= pd.get_dummies(train_data_raw[features])\neval_data = pd.get_dummies(eval_data_raw[features])\n\n#categorize for Sex\n#train_data['Sex']= train_data['Sex'].map({\"female\": 1, \"male\": 2})\n#eval_data['Sex']= eval_data['Sex'].map({\"female\": 1, \"male\": 2})\n\n#categorize for Embarked\n#categories = {\"S\": 1, \"C\": 2, \"Q\": 3}\n#train_data['Embarked']= train_data['Embarked'].map(categories)\n#eval_data['Embarked']= eval_data['Embarked'].map(categories)\n\n#categories = {'C': 1, 'B': 2, 'D':3, 'E': 4, 'A': 5}\n#train_data['Deck'] = train_data[\"Deck\"].map(categories)\n#eval_data['Deck'] = eval_data[\"Deck\"].map(categories)","e41ed741":"#------------------------------------------------------------------------------------------\n# 19.Train Data\n#------------------------------------------------------------------------------------------\ntrain_data.head()","3b18ebab":"#------------------------------------------------------------------------------------------\n# 20.Eval Data\n#------------------------------------------------------------------------------------------\neval_data.head()","5fa62b0d":"#------------------------------------------------------------------------------------------\n# 21.X and y Split\n#------------------------------------------------------------------------------------------\nfrom sklearn.model_selection import train_test_split\n\nX, y = train_data, train_data_raw[label].values\n\n# Split data 70%-30% into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 0)\n\n# Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","7777b8e1":"#------------------------------------------------------------------------------------------\n# 22.Parameter Estimator --> model\n#------------------------------------------------------------------------------------------\nfrom sklearn.model_selection import  GridSearchCV\n\nrf = RandomForestClassifier()\nclf = GridSearchCV(estimator=rf, param_grid={'max_depth':[4, 5, 6, 7, 10], \n                                          'criterion':['gini','entropy'],\n                                          'min_samples_split':[2, 3, 10, 20], \n                                          'min_samples_leaf':[1, 2, 3, 10, 20], \n                                          'n_estimators':[50, 100, 200, 300, 400]}\n                                          #,cv=5 #crossvalidation 5 folds\n                                          )\n\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\n\nprint(clf.best_params_)\nprint(clf.best_score_)\ndf = pd.DataFrame(clf.cv_results_)\nsorted_df = df.sort_values(by = \"rank_test_score\",ascending = True).head(10)\nsorted_df[['param_criterion','param_max_depth','param_min_samples_split','param_min_samples_leaf','param_n_estimators','mean_test_score','rank_test_score']]\n\n#{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n#0.8283096774193549","637b1787":"#------------------------------------------------------------------------------------------\n# 23.Best Model estimated\n#------------------------------------------------------------------------------------------\nmodel = clf.estimator\n\n#------------------------------------------------------------------------------------------\n# 24.Fit model\n#------------------------------------------------------------------------------------------\n\n#model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n#model = RandomForestClassifier(criterion = 'gini',n_estimators = 50, max_depth = 5,min_samples_leaf = 2,min_samples_split = 10,random_state=1)\nmodel.fit(X_train, y_train)\n\n#------------------------------------------------------------------------------------------\n# 25.Analyse the results\n#------------------------------------------------------------------------------------------\npredictions = model.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy: ', accuracy_score(y_test, predictions))\n\n#features importance\nlist1 = features\nlist2 = model.feature_importances_\nlist2, list1 = zip(*sorted(zip(list2, list1),reverse=True)) #sort\n\ntable = PrettyTable(['Features','Importance'])\nfor x in range(0,len(list1)):\n    table.add_row([list1[x],list2[x]])\n\nprint(table)\n\n#------------------------------------------------------------------------------------------\n# 26.Output to submit\n#------------------------------------------------------------------------------------------\n\npredictions = model.predict(eval_data)\n\noutput = pd.DataFrame({'PassengerId': eval_data_raw.PassengerId, 'Survived': predictions})\noutput.to_csv(\"submission.csv\", index=False)\n\nprint(datetime.datetime.now() , \"Your submissions was successfully saved!\")","bbc54c08":"# Titanic Survival Model\n![Titanic](https:\/\/imgc.allpostersimages.com\/img\/print\/u-g-PGF0TC0.jpg?w=200&h=300)"}}