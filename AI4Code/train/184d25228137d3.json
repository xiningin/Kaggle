{"cell_type":{"741560d9":"code","df1d7726":"code","71d8eb62":"code","6910fc62":"code","13b9c6eb":"code","90fcc1d4":"code","2f4e983b":"code","687fbd3f":"code","9fecd841":"code","06b97556":"code","e5b5b8c6":"code","ccf26a64":"code","1174f0b5":"code","488b46b4":"code","b1ee9b80":"code","e133951e":"code","e28a46c7":"code","c66e49d7":"code","95f2ad32":"code","ddea6446":"code","c776f04f":"code","8da1b219":"code","1e44fce5":"code","8c46e418":"code","3b66b21c":"code","c254e5f8":"markdown","ade01af2":"markdown","7e64dc62":"markdown","30bbcead":"markdown","bca3bedf":"markdown"},"source":{"741560d9":"# install missing packages\n!pip -q install torchsummary","df1d7726":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport os\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nfrom torchsummary import summary\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom pathlib import Path\n\n\n# set background color to white\nmatplotlib.rcParams['figure.facecolor'] = '#ffffff'\n\n# set default figure size\nmatplotlib.rcParams['figure.figsize'] = (15, 7)","71d8eb62":"DATA_DIR = r'..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset'","6910fc62":"# Get filepaths and labels\nimage_dir = Path(DATA_DIR)\nfilepaths = list(image_dir.glob(r'**\/*.png'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\n# Concatenate filepaths and labels\nimage_df = pd.concat([filepaths, labels], axis=1)\n\n# remove GT from some label names\nimage_df['Label'] = image_df['Label'].apply(lambda x: x.replace(\" GT\", \"\"))","13b9c6eb":"image_df","90fcc1d4":"# count plot for each class\nsns.countplot(x='Label', data=image_df).set(title='Count of different image classes')\nplt.show()","2f4e983b":"# the images are already augumented so no need to do any transforms\ntrans = transforms.Compose([transforms.Resize([128, 128]), # resize to a smaller size to avoid CUDA running out of memory\n                            transforms.ToTensor()\n                           ])\n\nimages = ImageFolder(root=DATA_DIR, transform=trans)","687fbd3f":"# split data to train, test\nsize = len(images)\ntest_size = int(0.2 * size)\ntrain_size = int(size - test_size)\nprint(f\"number of classes: {len(images.classes)}\")\nprint(f\"total number of images: {size}\")\nprint(f\"total number of train images: {train_size}\")\nprint(f\"total number of test images: {test_size}\")\n# random_split\ntrain_set, test_set = random_split(images, (train_size, test_size))","9fecd841":"# show a single image\ndef show_image(img, label, dataset):\n    plt.imshow(img.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(dataset.classes[label])","06b97556":"show_image(*train_set[7], train_set.dataset)","e5b5b8c6":"show_image(*train_set[101], train_set.dataset)","ccf26a64":"# create data loaders\nbatch_size = 64 # larger numbers lead to CUDA running out of memory\ntrain_dl = DataLoader(train_set, batch_size=batch_size)\ntest_dl = DataLoader(test_set, batch_size=batch_size)","1174f0b5":"# visualize a batch of images\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(20, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break","488b46b4":"show_batch(train_dl)","b1ee9b80":"# convlutional block with batchnorm and max pooling\ndef conv_block(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n              nn.BatchNorm2d(out_channels), \n              nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n    \n\n# CNN with residual connections\nclass FishResNet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 64)\n        self.conv2 = conv_block(64, 128, pool=True)\n        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n        \n        self.conv3 = conv_block(128, 256, pool=True)\n        self.conv4 = conv_block(256, 512, pool=True)\n        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                        nn.Flatten(),\n                                        nn.Dropout(0.2),\n                                        nn.Linear(512 * 4 * 4, num_classes))\n        \n    def forward(self, xb):\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out # add residual\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out # add residual\n        out = self.classifier(out)\n        return out\n        ","e133951e":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # choose device accordingly\nmodel = FishResNet(3, 9).to(device) # 3 color channels and 9 output classes\ncriterion = nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n# model summary (helps in understanding the output shapes)\nsummary(model, (3, 128, 128))","e28a46c7":"# multiclass accuracy\ndef multi_acc(y_pred, y_test):\n    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() \/ len(correct_pred)\n    acc = torch.round(acc * 100)\n    return acc","c66e49d7":"# training loop\nepochs = 10\nlosses = []\nfor epoch in range(epochs):\n    # for custom progress bar\n    with tqdm(train_dl, unit=\"batch\") as tepoch:\n        epoch_loss = 0\n        for data, target in tepoch:\n            tepoch.set_description(f\"Epoch {epoch + 1}\")\n            data, target = data.to(device), target.to(device) # move input to GPU\n            out = model(data)\n            loss = criterion(out, target)\n            acc = multi_acc(out, target)\n            epoch_loss += loss.item()\n            loss.backward()\n            optim.step()\n            optim.zero_grad()\n            tepoch.set_postfix(loss = loss.item(), accuracy = acc.item()) # show loss and accuracy per batch of data\n    losses.append(epoch_loss)","95f2ad32":"# plot losses\nsns.set_style(\"dark\")\nsns.lineplot(data=losses).set(title=\"loss change during training\", xlabel=\"epoch\", ylabel=\"loss\")\nplt.show()","ddea6446":"# predict on testing data samples (the accuracy here is batch accuracy)\ny_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    with tqdm(test_dl, unit=\"batch\") as tepoch:\n        for inp, labels in tepoch:\n            inp, labels = inp.to(device), labels.to(device)\n            y_test_pred = model(inp)\n            acc = multi_acc(y_test_pred, labels)\n            _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n            tepoch.set_postfix(accuracy = acc.item())\n            y_pred_list.append(y_pred_tag.cpu().numpy())\n            y_true_list.append(labels.cpu().numpy())","c776f04f":"# flatten prediction and true lists\nflat_pred = []\nflat_true = []\nfor i in range(len(y_pred_list)):\n    for j in range(len(y_pred_list[i])):\n        flat_pred.append(y_pred_list[i][j])\n        flat_true.append(y_true_list[i][j])\n        \nprint(f\"number of testing samples results: {len(flat_pred)}\")","8da1b219":"# calculate total testing accuracy\nprint(f\"Testing accuracy is: {accuracy_score(flat_true, flat_pred) * 100:.2f}%\")","1e44fce5":"# Display 15 random picture of the dataset with their labels\ninds = np.random.randint(len(test_set), size=15)\nfig, axes = plt.subplots(nrows=3, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in zip(inds, axes.flat):\n    img, label = test_set[i]\n    ax.imshow(img.permute(1, 2, 0))\n    ax.set_title(f\"True: {test_set.dataset.classes[label]}\\nPredicted: {test_set.dataset.classes[flat_pred[i]]}\")\nplt.tight_layout()\nplt.show()","8c46e418":"# classification report\nprint(classification_report(flat_true, flat_pred, target_names=images.classes))","3b66b21c":"# plot confusion matrix\nidx2class = {v: k for k, v in images.class_to_idx.items()}\nconfusion_matrix_df = pd.DataFrame(confusion_matrix(flat_true, flat_pred)).rename(columns=idx2class, index=idx2class)\nsns.heatmap(confusion_matrix_df, annot=True, fmt='').set(title=\"confusion matrix\", xlabel=\"Predicted Label\", ylabel=\"True Label\")\nplt.show()","c254e5f8":"exploring the images and their classes before modeling","ade01af2":"# Fish Classification with PyTorch ResNet\nthis project makes use of a residual network to classify different classes of fish based on images.\n\n### dataset classes\n- Black Sea Sprat\n- Gilt-Head Bream\n- Hourse Mackerel\n- Red Mullet\n- Red Sea Bream\n- Sea Bass\n- Shrimp\n- Striped Red Mullet\n- Trout","7e64dc62":"we can see that the batch loss is decreasing on each epoch meaning the model is learning effectively, the accuracy also keeps raising the longer we train, to make the loss easier to understand lets plot it","30bbcead":"there are 2000 images of each class, which means our model won't be biased towereds a particular class because it has a larger sample size","bca3bedf":"## Conclusion\nin this project we classified 9 different classes of fish at an decent accuracy of 87% with most of the classes having good percision and recall, however the model can be improved further by employing some techniques such as:\n\n- Transfer learning: using pre-trained models.\n- Learning rate scheduling: chaging the learning rate throughout the training process.\n- Gradient clipping: setting threshold for gradient values.\n- using Dropout layers."}}