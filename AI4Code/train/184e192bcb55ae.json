{"cell_type":{"c4697f70":"code","3d506806":"code","215dbd8e":"code","225e448a":"code","963f443e":"code","2c3201df":"code","88fc3b2a":"code","449dd89f":"code","2d73598d":"code","f67302a4":"code","44eb8412":"code","90be8e65":"code","b5664c34":"code","b51d3a50":"code","a2fc3999":"code","c7cd3513":"code","11942f5f":"code","d4077bd8":"code","c737fd7e":"markdown","25e2a300":"markdown","cf5c9f4f":"markdown","6808a1a2":"markdown","68252bdd":"markdown","ba869148":"markdown","9ddd3261":"markdown","e8f26ba5":"markdown"},"source":{"c4697f70":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d506806":"import gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","215dbd8e":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')","225e448a":"print(train.isna().sum(), test.isna().sum())","963f443e":"train.info()","2c3201df":"test.info()","88fc3b2a":"train['std'] = train.std(axis=1)\ntrain['min'] = train.min(axis=1)\ntrain['max'] = train.max(axis=1)\n\ntest['std'] = test.std(axis=1)\ntest['min'] = test.min(axis=1)\ntest['max'] = test.max(axis=1)","449dd89f":"y = train['target']\ntrain.drop(columns = ['id', 'target'], inplace = True)\ntest.drop(columns = 'id', inplace = True)","2d73598d":"def Stacking_Data_Loader(model, model_name, train, y, test, fold):\n    '''\n    Put your train, test datasets and fold value!\n    This function returns train, test datasets for stacking ensemble :)\n    '''\n\n    stk = StratifiedKFold(n_splits = fold, random_state = 42, shuffle = True)\n    \n    # Declaration Pred Datasets\n    train_fold_pred = np.zeros((train.shape[0], 1))\n    test_pred = np.zeros((test.shape[0], fold))\n    \n    for counter, (train_index, valid_index) in enumerate(stk.split(train, y)):\n        x_train, y_train = train.iloc[train_index], y[train_index]\n        x_valid, y_valid = train.iloc[valid_index], y[valid_index]\n\n        print('------------ Fold', counter+1, 'Start! ------------')\n        if model_name == 'cat':\n            print('------------ Fold', counter+1, '----Model: cat -----')\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n        elif model_name == 'xgb':\n            print('------------ Fold', counter+1, '----Model: xgb -----')\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric = 'auc', verbose = 500, early_stopping_rounds = 200)\n        else:\n            print('------------ Fold', counter+1, '----Model: lightBGM -----')\n            model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], eval_metric = 'auc', verbose = 500, early_stopping_rounds = 200)\n            \n        print('------------ Fold', counter+1, 'Done! ------------')\n        \n        train_fold_pred[valid_index, :] = model.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n        test_pred[:, counter] = model.predict_proba(test)[:, 1]\n        \n        del x_train, y_train, x_valid, y_valid\n        gc.collect()\n        \n    test_pred_mean = np.mean(test_pred, axis = 1).reshape(-1, 1)\n    \n    del test_pred\n    gc.collect()\n    \n    print('Done!')\n    \n    return train_fold_pred, test_pred_mean","f67302a4":"lgb_params={'n_estimators': 4000, 'learning_rate': 0.011642724475955537, 'max_depth': 10, 'colsample_bytree': 0.21541052979897893, 'subsample': 0.4744107712695383, 'eval_metric': 'auc', 'use_label_encoder': False, 'gamma': 0.25, 'reg_lambda': 100.0, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor', 'random_state': 42}","44eb8412":"xgb_params={'n_estimators': 4000, 'learning_rate': 0.04450779920391389, 'max_depth': 8, 'colsample_bytree': 0.3694058712030688, 'subsample': 0.7424217717367224, 'eval_metric': 'auc', 'use_label_encoder': False, 'gamma': 1.0, 'reg_lambda': 10.0, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor', 'random_state': 42}","90be8e65":"cat_params = {'iterations': 17298,\n              'learning_rate': 0.03429054860458741,\n              'reg_lambda': 0.3242286463210283,\n              'subsample': 0.9433911589913944,\n              'random_strength': 22.4849972385133,\n              'depth': 8,\n              'min_data_in_leaf': 4,\n              'leaf_estimation_iterations': 8,\n              'task_type':\"GPU\",\n              'bootstrap_type':'Poisson',\n              'verbose' : 500,\n              'early_stopping_rounds' : 200,\n              'eval_metric' : 'AUC'}","b5664c34":"lgbm = LGBMClassifier(**lgb_params)\n\nxgb = XGBClassifier(**xgb_params)\n\ncat = CatBoostClassifier(**cat_params)","b51d3a50":"cat_train, cat_test = Stacking_Data_Loader(cat, 'cat', train, y, test, 5)\ndel cat\ngc.collect()\n\nlgbm_train, lgbm_test = Stacking_Data_Loader(lgbm, 'lgbm', train, y, test, 5)\ndel lgbm\ngc.collect()\n\nxgb_train, xgb_test = Stacking_Data_Loader(xgb, 'xgb', train, y, test, 5)\ndel xgb\ngc.collect()","a2fc3999":"stack_x_train = np.concatenate((cat_train, lgbm_train, xgb_train), axis = 1)\nstack_x_test = np.concatenate((cat_test, lgbm_test, xgb_test), axis = 1)\n","c7cd3513":"del cat_train, lgbm_train, xgb_train, cat_test, lgbm_test, xgb_test\ngc.collect()","11942f5f":"stk = StratifiedKFold(n_splits = 5)\n\ntest_pred_lo = 0\nfold = 1\ntotal_auc = 0\n\nfor train_index, valid_index in stk.split(stack_x_train, y):\n    x_train, y_train = stack_x_train[train_index], y[train_index]\n    x_valid, y_valid = stack_x_train[valid_index], y[valid_index]\n    \n    lr = LogisticRegression(n_jobs = -1, random_state = 42, C = 5, max_iter = 2000)\n    lr.fit(x_train, y_train)\n    \n    valid_pred_lo = lr.predict_proba(x_valid)[:, 1]\n    test_pred_lo += lr.predict_proba(stack_x_test)[:, 1]\n    auc = roc_auc_score(y_valid, valid_pred_lo)\n    total_auc += auc \/ 5\n    print('Fold', fold, 'AUC :', auc)\n    fold += 1\n    \nprint('Total AUC score :', total_auc)","d4077bd8":"# submit!\n\nsub = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nsub['target'] = test_pred_lo\nsub.to_csv('sub.csv', index = 0)\nsub","c737fd7e":"# Level 2 training","25e2a300":"# Feature Generation","cf5c9f4f":"# Load Data","6808a1a2":"## stacking data loader","68252bdd":"## lightBGM: https:\/\/www.kaggle.com\/yuyougnchan\/tps-nov-lightgbm-baseline\n## catboost: https:\/\/www.kaggle.com\/aayush26\/tps-nov-2021-catboost-301-w-oof","ba869148":"# Check Missing Value","9ddd3261":"# Stacking","e8f26ba5":"# Modeling"}}