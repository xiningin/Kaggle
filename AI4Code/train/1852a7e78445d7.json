{"cell_type":{"77408828":"code","d2eeb2fb":"code","5fe9abbd":"code","8fb3991d":"code","349704ed":"code","d2d83782":"code","58063993":"markdown","b47cf678":"markdown","0b09407d":"markdown","68e95b4a":"markdown","37c1fb52":"markdown","a6465f0c":"markdown","be883f10":"markdown"},"source":{"77408828":"import keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Activation, Dropout, add, Flatten, MaxPooling2D, Conv2D, Dense, AveragePooling2D","d2eeb2fb":"#Loading the Data\ndf = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nX = np.c_[df.iloc[:, 1:]].reshape(len(df), 28, 28, 1)\ny = np.c_[df.iloc[:, 0]]\n\n#Transforming the labels to OneHotVectors (e.g, Label = 2 Becomes after OneHotting => [0, 0, 1, 0, 0, 0, 0 ,0, 0, 0] ,Label = 0 Becomes after OneHotting => [1, 0, 0, 0, 0, 0, 0 ,0, 0, 0] )\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nenc_label = OneHotEncoder()\ny = enc_label.fit_transform(y).toarray()\n#Splitting the Dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.15)\n","5fe9abbd":"\nmodel = Sequential()\n#INPUT LAYER\nmodel.add(Conv2D(32, (4, 4), input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\nmodel.add(AveragePooling2D((2, 2)))\n#HIDDEN LAYER 1\nmodel.add(Conv2D(32, (4, 4), padding='same'))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\n#HIDDEN LAYER 2\nmodel.add(Conv2D(32, (4, 4)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((4, 4)))\n#HIDDEN LAYER 3\nmodel.add(Conv2D(32, (2, 2)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))\n#FULLY CNNECTED LAYER\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Dropout(0.5))\nmodel.add(Activation('relu'))\n#OUTPUT LAYER\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))\n#CHOOSING our MODEL's loss, optimizer, metrics\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","8fb3991d":"#Building the Flow of Images\nfrom keras.preprocessing.image import ImageDataGenerator\ntrain_gen = ImageDataGenerator()\ntrain_gen = train_gen.flow(X, y, batch_size=1000)","349704ed":"#Training the model\nmodel.fit_generator(train_gen, epochs=10, steps_per_epoch=10000)","d2d83782":"loss, acc = model.evaluate(X_test, y_test)\nprint('Loss : {}, Accuracy : {}'.format(loss, acc))","58063993":"<h1><font color='#50474F'> 3] Building Our Model! <\/font><\/h1>","b47cf678":"<h1><center><font color='#F21212'>An investement in knowledge pays the best interest :))<\/font><\/center><\/h1>","0b09407d":"<h3><font color='#50474F'> Hello and welcome to this notebook where YOU are going to discover how to build CNN model :))<\/font><\/h3>\n<h1><font color='#50474F'> 1] Loading Modules that we're going to need <\/font><\/h1>","68e95b4a":"<h1><font color='#50474F'> 3] Building The Flow of Images THEN Training our Model <\/font><\/h1>","37c1fb52":"<h1><font color='#50474F'> 2] Loading & Spliting the Data <\/font><\/h1>","a6465f0c":"<h1><font color='#50474F'> Let's see how well our model Generalizes :D <\/font><\/h1>","be883f10":"<h3><font color='#50474F'>Good Enough!, but i would suggest training this model on the whole given dataset and this well produce a better result! :)), See you in the next notebook!<font><\/h3>"}}