{"cell_type":{"6ca2f553":"code","928a07e2":"code","e7bc9893":"code","80663634":"code","978ef87e":"code","439e0a14":"code","e1c73982":"code","6bc9a324":"code","1d0cd4ae":"code","680d7fbc":"markdown","ccf232cb":"markdown","419ff00f":"markdown","5db0630c":"markdown","76482a88":"markdown","b5610ecc":"markdown","b9dd7f08":"markdown","acb98176":"markdown"},"source":{"6ca2f553":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport numpy as np\n","928a07e2":"# Define your network ( Simple Example )\nclass FashionClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        input_size = 784\n        self.fc1 = nn.Linear(input_size, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 128)\n        self.fc4 = nn.Linear(128, 64)\n        self.fc5 = nn.Linear(64,10)\n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        x = self.dropout(F.relu(self.fc4(x)))\n        x = F.log_softmax(self.fc5(x), dim=1)\n        return x","e7bc9893":"# Define a transform to normalize the data\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n# Download and load the training data\ntrainset = datasets.FashionMNIST('F_MNIST_data\/', download=True, train=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n\n# Download and load the test data\ntestset = datasets.FashionMNIST('F_MNIST_data\/', download=True, train=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)","80663634":"# Create the network, define the criterion and optimizer\nmodel = FashionClassifier()\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","978ef87e":"## Train for few epochs\nepochs = 3\ntrain_losses = []\ntest_losses = []\nmin_loss = np.Inf\n\nfor i in range(epochs):\n    train_loss = 0\n    train_acc = 0 \n    test_loss = 0 \n    test_acc = 0 \n    \n    # Training step\n    model.train()\n    for images, labels in trainloader:\n        optimizer.zero_grad()\n        log_ps = model.forward(images)\n        loss = criterion(log_ps, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        ps = torch.exp(log_ps)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == labels.view(top_class.shape)\n        acc = torch.mean(equals.type(torch.FloatTensor))\n        train_acc += acc.item()\n        \n    # Validation Step\n    with torch.no_grad():\n        model.eval()\n        \n        for images, labels in testloader:\n            log_ps = model.forward(images)\n            test_loss += criterion(log_ps, labels).item()\n            ps = torch.exp(log_ps)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(top_class.shape)\n            test_acc += torch.mean(equals.type(torch.FloatTensor)).item()\n    \n    train_losses.append(train_loss\/len(trainloader))\n    test_losses.append(test_loss\/len(testloader))\n    \n    print(\"Epoch:\",i+1,\n          \"Train loss:\",train_loss\/len(trainloader),\n          \"TrainAcc:\",100*train_acc\/len(trainloader),\n          \"Test loss:\",test_loss\/len(testloader),\n          \"Test Acc:\",100*test_acc\/len(testloader))\n\n    \n        \n    \n        \n        ","439e0a14":"print(\"The state dict keys: \\n\\n\", model.state_dict().keys())","e1c73982":"checkpoint = {'model': FashionClassifier(),\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint.pth')","6bc9a324":"def load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n    \n    model.eval()\n    \n    return model","1d0cd4ae":"model = load_checkpoint('checkpoint.pth')\nprint(model)","680d7fbc":"# Train the network","ccf232cb":"# Define your model","419ff00f":"---\n# Loading the model","5db0630c":"# Saving and Loading Models in PyTorch\n\nIn this notebook, I'll show you how to save and load models with PyTorch.\nWorking on a Deep Learning project usually takes time, and there are many things to tweak and change over time.\u00a0\nWhether you \"babysit\" your model while training or you leave it and go do something else, It's always a good practice to save checkpoints of your model for many reasons.\n\n* You need to save the best model to be used for prediction \n\n* You may want to save the latest state of a model to be able to continue training and fine tune later","76482a88":"---\n## Saving the model\nThe parameters for PyTorch networks are stored in a model's `state_dict`. It includes the parameters matrices for each of the layers.","b5610ecc":"Loading is as simple as Saving.\n* Reconstruct the model\n* Load the state dict to the model\n* Freeze the parameters and enter evaluation mode if you're loading for inference\n","b9dd7f08":"We will need to reconstruct the model exactly as it was when trained at loading time, So we need to store information about the model architecture in the checkpoint, along with the state dict.\n\nIf you are planning to continue training of the model you'll need to store the optimizer state too.\n\nTo do this, you build a dictionary with all the information you need to compeletely rebuild the model.","acb98176":"# Prepare the dataset "}}