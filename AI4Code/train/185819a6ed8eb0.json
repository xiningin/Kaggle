{"cell_type":{"4b76189c":"code","cfb5c765":"code","78f40028":"code","d03ef9fc":"code","da83a4aa":"code","82e33d6b":"code","ac605fd3":"code","532cad94":"code","52983c57":"code","da4f7c83":"code","7ca91d74":"code","b86aca31":"code","b9b49233":"code","23469efd":"code","1707649c":"code","6153cd5a":"code","569cf7cb":"code","0ae9b21c":"code","0eddf857":"code","077ca79b":"code","fe3adcbf":"code","45529fa1":"code","b888a168":"code","3285fa22":"code","6e4174a0":"code","9310f7dc":"code","4415fb40":"code","fba6c56f":"code","5a3867ff":"code","893ff34a":"code","0bcff67c":"code","1fbe540c":"code","5e359e63":"code","06374e9c":"code","e4d1cf7b":"code","0a8b7673":"markdown","69c3237f":"markdown","d1ec14b7":"markdown","64596f94":"markdown","917a27a9":"markdown","d9465297":"markdown","0b091555":"markdown","5a640d6f":"markdown","a7c45a9b":"markdown","f317270d":"markdown","c3e4f0a1":"markdown","65114844":"markdown","ac637ee1":"markdown","2c2da35e":"markdown","561c68a1":"markdown","3c1d5cbb":"markdown","02bbfd24":"markdown","7fb71d6a":"markdown","72372ded":"markdown","fee0eef7":"markdown","b91e159b":"markdown","3953928f":"markdown","e6727793":"markdown","dab2fd78":"markdown","b4e6690b":"markdown","3c707e23":"markdown","be647366":"markdown","9a15381f":"markdown","a13d9d91":"markdown","fa4eb1f3":"markdown","a3b451c2":"markdown","2e4fdf1a":"markdown","b7535af7":"markdown","02d2daba":"markdown","07e41449":"markdown","6c704b2b":"markdown","d33a5593":"markdown","1373db62":"markdown","07efa5da":"markdown","19ee1d1d":"markdown","af600975":"markdown","0c25b2bc":"markdown","6ddbb934":"markdown"},"source":{"4b76189c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport seaborn as sn\nimport plotly.figure_factory as ff\nimport math\nimport plotly.graph_objects as go","cfb5c765":"#Importing all data\n\ndata_18 = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv\", )\ndata_19 = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\", )\ndata_20 = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\", )\ndata_21 = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\", )","78f40028":"# Gets all information from a single question for a single term\ndef get_all_from_sq(q, term, data = data_21):\n    return data[data[q].isin([term])]\n\n# Gets all information from a single question with multiple parts for terms in term_list\ndef get_all_from_mcq(q, term_list, data = data_21):\n    df = data\n    for i in range(len(term_list)):\n        df = df[df[q + \"Part_\" + str(i + 1)].isin(term_list)]\n    return df\n\n# Gets all information that is = term1 in q1 and term2 in q1 (Extra)\ndef get_and(q1, q2, term1, term2, data = data_21):\n    return (data[data[q1].isin([term1])])[data[q2].isin([term2])]\n\n# Counts the data after checking data type\ndef data_count(q1 = 1, cross_ref = None, qt = \"sq\", cross_ref_t = None, term = 1, term2 = None, data = data_21):\n    if(cross_ref == None):\n        # for single questions it'll return total number of terms\n        if(qt == \"sq\"):\n            return len(get_all_from_sq(q1, term).count(axis = 1))\n        else:\n            # for multiple answer questions it'll return total number of terms in all parts\n            return len(get_all_from_mcq(q1, term).count(axis = 1))\n    else:\n        return len(get_and(q1, cross_ref, term, term2).count(axis = 1))\n\n# Builds a dataset based on 2 questions by corelating them. q1_terms and q2_terms are the terms you want\n# to relate\ndef build_2_var_sq(q1, q2, q1_terms, q2_terms, data = data_21):\n    len_opt = len(q1_terms)\n    df = {}\n    for i in range(len_opt):\n        n1 = q1 + str(i + 1)\n        df[n1] = data_count(q1 = q1, cross_ref = q2, term = q1_terms[i], term2 = q2_terms, cross_ref_t = \"sq\", data = data_21)\n    df = pd.DataFrame(df.items(), columns = ['VarX', 'VarY'])\n    return df\n\n# Instead of using the logical AND operation we use the OR operation, so it's checking other possibilities\ndef build_2_var_sq_or(q1, q2, q1_terms, q2_terms, data = data_21):\n    len_opt = len(q1_terms)\n    df = {}\n    for i in range(len_opt):\n        n1 = q1 + str(i + 1)\n        s1 = 0\n        for j in range(len(q2_terms)):\n            s1 += data_count(q1 = q1, cross_ref = q2, term = q1_terms[i], term2 = q2_terms[j], cross_ref_t = \"sq\",\n                            data = data)\n        df[n1] = s1\n    df = pd.DataFrame(df.items(), columns = ['VarX', 'VarY'])\n    return df\n\n# From a question it gets all the names of the options\ndef get_question_index(q1, data = data_21):\n    return list(data[q1].value_counts().index)\n\n# If we have 2 data counts for 2 variables, it formats the data\n# It also converts it to relative data if rel = true\n# Output = [VarX, Mid, VarY]\ndef relate_data_counts(lab, counts, indexes, rel):\n    d = []\n    tot = 0\n    if(counts.size == 0 and not rel):\n        return [lab, 0]\n    for i in range(min(len(indexes), len(counts))):\n        d.append([lab, indexes[i], counts[i]])\n        tot += counts[i]\n    if(rel):\n        d.append(tot)\n    return d\n# Get the value_counts as an array\ndef get_question_counts(q1, data = data_21):\n    return np.array(data[q1].value_counts())\n\n# A remade and more efficient version that applies the and operation between 2 questions.\ndef get_question_and(q1, q2, data = data_21, rel = False):\n    q1_names = get_question_index(q1, data)\n    q2_names = get_question_index(q2, data)\n    d = []\n    for name in q1_names:\n        if(not rel):\n            d1 = relate_data_counts(name,\n                                     get_question_counts(q2, data[data[q1].isin([name])])[:-1],\n                                     q2_names[:-1], rel)\n            for j in d1:\n                d.append(j)\n        else:\n            d1 = relate_data_counts(name,\n                                     get_question_counts(q2, data[data[q1].isin([name])])[:-1],\n                                     q2_names[:-1], rel)\n            tot = d1[-1]\n            for j in range(len(d1) - 1):\n                d.append([d1[j][0], d1[j][1], float(d1[j][2])\/float(tot + 1)])\n    return d\n# Renames a certain dataframe - helpful to fix data with large names\ndef rename_frame(array, naming_1, naming_2):\n    d = pd.DataFrame(np.array(array), columns = ['VarX', 'Mid', 'VarY'])\n    for i in range(len(naming_1)):\n        d = d.replace(naming_1[i], value= naming_2[i])\n    return d\n\n# For a single variable, it compiles all data from all years. Input the list of question numbers\n# If you have \"Q1_Part_n\", then just put \"Q1_\"\n# Then enter the variable you are searching for.\ndef multi_Y_data_SV(q1_list, q1_var, get_var = False, data_list = [data_21], year_list = [\"2021\"], rel = False):\n    d = []\n    if(get_var):\n        for i in range(len(q1_list)):\n            co = get_question_counts(q1_list[i], data = data_list[i])[0]\n            d.append([year_list[i], q1_var, co])\n    else:\n        for i in range(len(q1_list)):\n            co = get_question_counts(q1_list[i], data = data_list[i])\n            names = get_question_index(q1_list[i], data = data_list[i])\n            n1 = \"\"\n            for j in range(len(names)):\n                if(q1_var[i] == names[j]):\n                    n1 = j\n                    break\n            d.append([year_list[i], q1_var, co[j]])\n    return d\n\n# Formats the above data for making into a line graph\ndef line_graph_SV(q1_list, q1_var, get_var = False, data_list = [data_21], year_list = [\"2021\"], rel = False, \n                  alternate_name = None, naming = None):\n    if(alternate_name == None):\n        d = multi_Y_data_SV(q1_list, q1_var, get_var, data_list, year_list, \n                                     rel)\n        d = pd.DataFrame(np.array(d), columns = ['VarX', 'Mid', 'VarY'])\n    else:\n        d = rename_frame(multi_Y_data_SV(q1_list, q1_var, get_var, data_list, year_list, \n                                     rel),\n                     naming, \n                     alternate_name)\n    d['VarY'] = d['VarY'].astype(str).astype(float)\n    return d\n\n# Helps relate multiple variables in multiple questions.\ndef multi_Y_data_MV(q1_list, q1_var, get_var = False, data_list = [data_21], year_list = [\"2021\"], year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = False, cut_off = 1, reformat = False):\n    d = []\n    for i in range(len(q1_var)):\n        q_nums = []\n        i1 = 0\n        for n in q1_list:\n            if(has_other and i == len(q1_var) - 1):\n                if(i1 <= cut_off):\n                    q_nums.append(n + \"OTHER_TEXT\")\n                else:\n                    q_nums.append(n + \"OTHER\")\n            elif(year_wise_skip != None):\n                if(i1 in year_wise_skip[i]):\n                    i1 += 1\n            else:\n                q_nums.append(n + \"Part_\" + str(i + 1))\n            \n            i1 += 1\n        d1 = multi_Y_data_SV(q_nums, q1_var[i], get_var = True, data_list = data_list, \n                             year_list = year_list)\n        d.append(pd.DataFrame(d1, columns = ['VarX', 'Mid', 'VarY']))\n    return pd.concat(d)\n\n# Helps rescale according to what year we are looking at\n# the ident is what we are using as base year\ndef reformat_yearwise(data, year_dict, ident):\n    d = []\n    for index, row in data.iterrows():\n        d.append([row['VarX'][:-3], row['Mid'], \n                  round(row['VarY'] \/ (1 + year_dict[row['VarX']]) * year_dict[ident])])\n    return d\n\n# Convert data into relative data\n# Ident is just there for convinience\ndef reformat_yearwise_rel(data, year_dict, ident):\n    d = []\n    for index, row in data.iterrows():\n        d.append([row['VarX'][:-3], row['Mid'], \n                  row['VarY'] \/ (1 + year_dict[row['VarX']])])\n    return d\n\n# Maps the salary into different numeric categories depending on maping (Extra)\ndef salary_map(data, qnum, maping):\n    d = data\n    for key in maping:\n        d[qnum] = d[qnum].replace(key, maping[key])\n    return d\n\n# A salary map\nchange_dict_1 = {\n    '25,000-29,999':27500, '60,000-69,999':65000, '$0-999':500, '30,000-39,999': 35000,\n       '15,000-19,999':17500, '70,000-79,999':75000, '2,000-2,999':2500, '10,000-14,999':12500,\n       '5,000-7,499':6250, '20,000-24,999':22500, '1,000-1,999':1500, '100,000-124,999':112500,\n       '7,500-9,999':8750, '4,000-4,999':4500, '40,000-49,999':45000, '50,000-59,999':55000,\n       '3,000-3,999':3500, '300,000-499,999':400000, '200,000-249,999':225000,\n       '125,000-149,999':137500, '250,000-299,999':275000, '80,000-89,999':85000,\n       '90,000-99,999':95000, '150,000-199,999':175000, '>$1,000,000': 1100000,\n       '$500,000-999,999':750000\n}\n\n# convert the data to log. (Extra)\ndef to_log(data):\n    d = []\n    for i in range(len(data)):\n        d.append(math.log(data[i] + 1))\n    return d\n\n# Reconvert the numeric salary to smaller ranges (Extra)\ndef compile_salary(data, ranges):\n    d = []\n    for point in data:\n        flag = True\n        for j in ranges:\n            if(isinstance(point, int) or isinstance(point, float)):\n                if(ranges[j][0] <= point and point <= ranges[j][1]):\n                    d.append(j)\n                    flag = False\n                    break\n            else:\n                d.append(\"nan\")\n        if(flag):\n            d.append(\"nan\")\n    return d\n\n# Another function to convert the data into relative values\n# This is less generalized\ndef conv_rel(cat_list, data):\n    d = []\n    for cat in cat_list:\n        d_temp = data[data[\"VarX\"].isin([cat])]\n        s_t = d_temp[\"VarY\"].sum()\n        d_temp[\"VarY\"] = d_temp[\"VarY\"] \/ s_t\n        d.append(d_temp)\n    return pd.concat(d)\n\n# Formats data for making into a line graph with multiple variables.\ndef year_relator(q_list, y_list, q_points, data_list, q_py):\n    d = []\n    j = 0\n    qs = 0\n    for i in range(len(q_list)):\n        if(qs == q_py):\n            j += 1\n            qs = 0\n        count = get_question_counts(q_list[i], data_list[j])\n        d.append([y_list[j], q_points[qs], count[0]])\n        qs += 1\n    return d\n\n\"\"\"\ntest_1 = year_relator([\"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\", \"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\",\n              \"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\", \"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\",\n              \"Q18_Part_1\", \"Q18_Part_2\", \"Q18_Part_10\", \"Q18_Part_1\", \"Q18_Part_2\", \"Q18_Part_10\",\n             \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_9\", \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_9\"\n             ], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             [\"Python\", \"R\", \"MATLAB\"], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 3)\n\"\"\"\n\n# Splits data into old and new users\ndef bifurcate_data(dat):\n    old = []\n    ne = []\n    for val in dat:\n        name = val[0]\n        if(name[-3:] == \"Old\"):\n            old.append(val)\n        else:\n            ne.append(val)\n    return pd.DataFrame(old, columns = [\"VarX\", \"Mid\", \"VarY\"]), pd.DataFrame(ne, columns = [\"VarX\", \"Mid\", \"VarY\"])\n\n# Combines elements according to the middle values\ndef comb_mids1(dat, mid_vals, rem_vals, years):\n    d = dat\n    for i in range(len(years)):\n        n1 = years[i]\n        for mid in mid_vals:\n            #if(d.loc[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[1]), 'VarY'] != np.nan and d.loc[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[0]), 'VarY'] != np.nan):\n            # d.loc[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[0]), 'VarY'] += d.loc[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[0]), 'VarY'] + d.loc[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[1]), 'VarY']\n            d.loc[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[0]), 'VarY'] += d.loc[[(d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[0]), (d[\"VarX\"] == n1) & (d[\"Mid\"] == mid[1])], 'VarY'].sum()\n    \n    d = d.loc[~d[\"Mid\"].isin(rem_vals)]\n    \n    return d\n\n# A better version of comb_mids1\ndef comb_mids(dat, mid_vals, rem_vals, years):\n    d = []\n    for i in range(len(years)):\n        for j in range(len(mid_vals)):\n            for k in range(len(dat)):\n                if(dat[k][0] == years[i] and dat[k][1] == mid_vals[j][0]):\n                    flag = False\n                    for l in range(len(dat)):\n                        if(dat[l][0] == years[i] and dat[l][1] == mid_vals[j][1]):\n                            d.append([dat[k][0], dat[k][1], dat[k][2] + dat[l][2]])\n                            flag = True\n                            break\n                    if(flag):\n                        break\n    for i in range(len(dat)):\n        flag = True\n        for j in range(len(mid_vals)):\n            if((dat[i][1] == mid_vals[j][0] and dat[i][0] in years) or (dat[i][0] in years and dat[i][1] == mid_vals[j][1])):\n                flag = False\n                break\n        if(flag):\n            d.append(dat[i])\n    return d\n\n# Makes a line graph for single choice question with multiple variables\ndef Line_SV_2(q_list, q_to_find, naming, year_list, per_year, data):\n    count = 0\n    y_no = 0\n    d = []\n    for i in range(len(q_list)):\n        if(count == per_year):\n            count = 0\n            y_no += 1\n        valY = data[y_no][q_list[i]].value_counts()[q_to_find[i]]\n        d.append([year_list[y_no], naming[count], valY])\n        count += 1\n    d = pd.DataFrame(d, columns = [\"VarX\", \"Mid\", \"VarY\"])\n    d['VarY'] = d['VarY'].astype(str).astype(float)\n    return d\n\n# Another way to convert to relative values\ndef conv_rel_2(data, mapping):\n    d = []\n    for i in range(len(data)):\n        d.append([data[i][0], data[i][1], data[i][2] \/ mapping[data[i][0]]])\n    d = pd.DataFrame(d, columns = [\"VarX\", \"Mid\", \"VarY\"])\n    d['VarY'] = d['VarY'].astype(str).astype(float)\n    return d\n\n# Change names of data\ndef re_name_2(data, naming):\n    d = []\n    for i in range(len(data)):\n        d.append([data[i][0], naming[data[i][1]], data[i][2]])\n    return pd.DataFrame(d, columns = ['VarX', 'Mid', 'VarY'])\n\n# Helps make graphs in ploty.go\ndef add_many_traces(fig, data, trace_list, color_list):\n    for i in range(len(trace_list)):\n        fig.add_trace(go.Scatter(x = data[data['Mid'].isin([trace_list[i]])]['VarX'],\n                                y = data[data['Mid'].isin([trace_list[i]])]['VarY'],\n                                 hovertemplate = trace_list[i] + ': %{y:.2f}<extra><\/extra>',\n                                 name = trace_list[i],\n                                 marker_color = color_list[i]\n                                ))","d03ef9fc":"# Segregating the data according to the decided metrics\n\nd21_o = data_21[data_21[\"Q15\"].isin([\"10-20 years\", \"20 or more years\"])]\nd21_y = data_21[data_21[\"Q15\"].isin([\"Under 1 year\", \"1-2 years\"])]\nd20_y = data_20[data_20[\"Q15\"].isin([\"Under 1 year\", \"1-2 years\"])]\nd20_o = data_20[data_20[\"Q15\"].isin([\"10-20 years\", \"20 or more years\"])]\nd18_y = data_18[data_18[\"Q25\"].isin([\"< 1 year\", \"1-2 years\"])]\nd18_o = data_18[data_18[\"Q25\"].isin([\"10-15 years\", \"20+ years\"])]\nd19_y = data_19[data_19[\"Q23\"].isin([\"< 1 years\", \"1-2 years\"])]\nd19_o = data_19[data_19[\"Q23\"].isin([\"10-20 years\", \"20+ years\"])]","da83a4aa":"print(\"2021 - Experienced:\", len(d21_o), \"New Users:\", len(d21_y))\nprint(\"2020 - Experienced:\", len(d20_o), \"New Users:\", len(d20_y))\nprint(\"2019 - Experienced:\", len(d19_o), \"New Users:\", len(d19_y))\nprint(\"2018 - Experienced:\", len(d18_o), \"New Users:\", len(d18_y))","82e33d6b":"# Primary Analysis Tool\n\n# Get the question names\nnames_old_Analysis = get_question_index(\"Q41\", d21_o)\nnames_y_Analysis = get_question_index(\"Q41\", d21_y)\nnames_old_Analysis_18 = get_question_index(\"Q12_MULTIPLE_CHOICE\", d18_o)\nnames_y_Analysis_18 = get_question_index(\"Q12_MULTIPLE_CHOICE\", d18_y)\n\n# Get all data from the single choice questions\nAnalysis_old_2021 = Line_SV_2([\"Q41\",\"Q41\",\"Q41\",\"Q41\",\"Q41\",\"Q41\"],\n            names_old_Analysis,\n          names_old_Analysis, \n          [\"2021 Old\", \"2021 New\"], 6, \n          [d21_o[~d21_o[\"Q41\"].isin([np.nan])],d21_y[~d21_y[\"Q41\"].isin([np.nan])]])\n\nAnalysis_new_2021 = Line_SV_2([\"Q41\",\"Q41\",\"Q41\",\"Q41\",\"Q41\",\"Q41\"],\n            names_y_Analysis,\n          names_y_Analysis, \n          [\"2021 New\"], 6, \n          [d21_y[~d21_y[\"Q41\"].isin([np.nan])]])\n\nAnalysis_2021 = pd.concat([Analysis_old_2021, Analysis_new_2021])\n\n# Rescale to be on par with 2021 data\nAnalysis_2021 = conv_rel_2(Analysis_2021.to_numpy(), {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n                         #ident = ['2021 Old', '2021 New'])\n# Rename the long names\nAnalysis_2021 = re_name_2(Analysis_2021.to_numpy(), {'Local or hosted development environments (RStudio, JupyterLab, etc.)': 'Development Environments',\n                                     'Local development environments (RStudio, JupyterLab, etc.)': 'Development Environments',\n                                     'Basic statistical software (Microsoft Excel, Google Sheets, etc.)': 'Basic Stat Software',\n                                     'Business intelligence software (Salesforce, Tableau, Spotfire, etc.)': 'Business Intelligence',\n                                     'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)': 'Cloud',\n                                      'Other': 'Other',\n                                      'Advanced statistical software (SPSS, SAS, etc.)': 'Advanced Stat Soft'\n                                     })\n# Make a graph\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Analysis_2021[Analysis_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Analysis_2021[Analysis_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Analysis_2021[Analysis_2021['VarX'].isin(['2021 New'])]['Mid'],\n                     y = Analysis_2021[Analysis_2021['VarX'].isin(['2021 New'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Primary Data Analysis Tool for Users in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Data Analysis Tool',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","ac605fd3":"Analysis_old_2020 = Line_SV_2([\"Q38\",\"Q38\",\"Q38\",\"Q38\",\"Q38\",\"Q38\"],\n            names_old_Analysis,\n          names_old_Analysis, \n          [\"2020 Old\", \"2020 New\"], 6, \n          [d20_o[~d20_o[\"Q38\"].isin([np.nan])],d20_y[~d20_y[\"Q38\"].isin([np.nan])]])\n\nAnalysis_new_2020 = Line_SV_2([\"Q38\",\"Q38\",\"Q38\",\"Q38\",\"Q38\",\"Q38\"],\n            names_y_Analysis,\n          names_y_Analysis, \n          [\"2020 New\"], 6, \n          [d20_y[~d20_y[\"Q38\"].isin([np.nan])]])\n\nAnalysis_old_2019 = Line_SV_2([\"Q14\",\"Q14\",\"Q14\",\"Q14\",\"Q14\",\"Q14\"],\n            names_old_Analysis,\n          names_old_Analysis, \n          [\"2019 Old\", \"2019 New\"], 6, \n          [d19_o[~d19_o[\"Q14\"].isin([np.nan])],d19_y[~d19_y[\"Q14\"].isin([np.nan])]])\n\nAnalysis_new_2019 = Line_SV_2([\"Q14\",\"Q14\",\"Q14\",\"Q14\",\"Q14\",\"Q14\"],\n            names_y_Analysis,\n          names_y_Analysis, \n          [\"2019 New\"], 6, \n          [d19_y[~d19_y[\"Q14\"].isin([np.nan])]])\n\nAnalysis_old_2018 = Line_SV_2([\"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\",\n                              \"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\"],\n            names_old_Analysis_18,\n          names_old_Analysis_18, \n          [\"2018 Old\", \"2018 New\"], 6, \n          [d18_o[~d18_o[\"Q12_MULTIPLE_CHOICE\"].isin([np.nan])],d18_y[~d18_y[\"Q12_MULTIPLE_CHOICE\"].isin([np.nan])]])\n\nAnalysis_new_2018 = Line_SV_2([\"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\",\n                              \"Q12_MULTIPLE_CHOICE\",\"Q12_MULTIPLE_CHOICE\"],\n            names_y_Analysis_18,\n          names_y_Analysis_18, \n          [\"2018 New\"], 6, \n          [d18_y[~d18_y[\"Q12_MULTIPLE_CHOICE\"].isin([np.nan])]])\n\nAnalysis_2021 = pd.concat([Analysis_old_2021, Analysis_new_2021])\nAnalysisVsYear = pd.concat([Analysis_2021, Analysis_old_2020, Analysis_new_2020,Analysis_old_2019, Analysis_new_2019,\n                           Analysis_old_2018, Analysis_new_2018])\n\n\nAnalysisVsYear[AnalysisVsYear['Mid'].isin(['Local or hosted development environments (RStudio, JupyterLab, etc.)'])]['Mid'] = 'Local development environments (RStudio, JupyterLab, etc.)'\n\n\n#AnalysisVsYear.loc(AnalysisVsYear['Mid'] == 'Local or hosted development environments (RStudio, JupyterLab, etc.)')['Mid'] = 'Local development environments (RStudio, JupyterLab, etc.)'\n\n\nAnalysisVsYear = conv_rel_2(AnalysisVsYear.to_numpy(), {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n\nAnalysisVsYear = re_name_2(AnalysisVsYear.to_numpy(), {'Local or hosted development environments (RStudio, JupyterLab, etc.)': 'Development Environments',\n                                     'Local development environments (RStudio, JupyterLab, etc.)': 'Development Environments',\n                                     'Basic statistical software (Microsoft Excel, Google Sheets, etc.)': 'Basic Stat Software',\n                                     'Business intelligence software (Salesforce, Tableau, Spotfire, etc.)': 'Business Intelligence',\n                                     'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)': 'Cloud',\n                                      'Other': 'Other',\n                                      'Advanced statistical software (SPSS, SAS, etc.)': 'Advanced Stat Soft'\n                                     })\n\nAnalysisVsYear_o, AnalysisVsYear_y = bifurcate_data(AnalysisVsYear.to_numpy())\n\nfig = go.Figure()\nadd_many_traces(fig, AnalysisVsYear_o.reindex(index=AnalysisVsYear_o.index[::-1]), ['Development Environments', \n                                                                                    'Basic Stat Software', 'Business Intelligence', 'Cloud',\n                                                                                    'Other', 'Advanced Stat Soft'],\n                ['red', 'green', 'blue', 'black', 'yellow', 'grey', 'purple', 'brown', 'dark green'])\nfig.update_layout(title_text = \"Preferred Data Analysis Tool for Users vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, AnalysisVsYear_y.reindex(index=AnalysisVsYear_y.index[::-1]),['Development Environments', \n                                                                                    'Basic Stat Software', 'Business Intelligence', 'Cloud',\n                                                                                    'Other', 'Advanced Stat Soft'], \n                ['red', 'green', 'blue', 'black', 'yellow', 'grey', 'purple', 'brown', 'dark green'])\nfig.update_layout(title_text = \"Preferred Data Analysis Tool for Users vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\n","532cad94":"Expenditure = Line_SV_2([\"Q26\",\"Q26\", \"Q26\",\"Q26\", \"Q26\",\"Q26\",\n          \"Q25\",\"Q25\", \"Q25\",\"Q25\", \"Q25\",\"Q25\",\n          \"Q11\",\"Q11\",\"Q11\",\"Q11\",\"Q11\",\"Q11\",\n           \"Q26\",\"Q26\", \"Q26\",\"Q26\", \"Q26\",\"Q26\",\n          \"Q25\",\"Q25\", \"Q25\",\"Q25\", \"Q25\",\"Q25\",\n          \"Q11\",\"Q11\",\"Q11\",\"Q11\",\"Q11\",\"Q11\"], \n          [\"$0 ($USD)\", '$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)',\n           \"$0 ($USD)\", '$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)',\n           \"$0 (USD)\", '$1-$99', '$100-$999','$1000-$9,999', '$10,000-$99,999', '> $100,000 ($USD)',\n           \"$0 ($USD)\", '$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)',\n           \"$0 ($USD)\", '$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)',\n           \"$0 (USD)\", '$1-$99', '$100-$999','$1000-$9,999', '$10,000-$99,999', '> $100,000 ($USD)'],\n          ['0', '<100', '<1000', '<10000', '<100000', '>100000'], [\"2021 Old\", \"2020 Old\", \"2019 Old\",\n                                                                  \"2021 New\", \"2020 New\", \"2019 New\"], 6, \n          [d21_o, d20_o, d19_o, d21_y, d20_y, d19_y])\n\nExpenditure = conv_rel_2(Expenditure.to_numpy(), {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n                         #ident = ['2021 Old', '2021 New'])\n\n\nfig = px.bar(Expenditure, x = 'Mid', y = 'VarY', color = 'VarX', barmode = \"group\", labels = {\n    '2021 Old': '2021 Experienced', '2020 Old': '2020 Experienced', '2019 Old': '2019 Experienced',\n    '2021 New': '2021 New', '2020 New': '2020 New', '2019 New': '2019 New'\n})\nfig.show()","52983c57":"# Education Platforms 2021\n\nEd_2021 = multi_Y_data_MV([\"Q40_\", \"Q40_\"], ['Coursera',\n'edX',\n'Kaggle Learn Courses',\n'DataCamp',\n'Fast.ai',\n'Udacity',\n'Udemy',\n'LinkedIn Learning',\n'Cloud-certification programs',\n'University Courses',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\n#num_old_Deploy_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\n#num_young_Deploy_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nEd_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Ed_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Ed_2021[Ed_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Ed_2021[Ed_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Ed_2021[Ed_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Ed_2021[Ed_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Education Platforms Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Education Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()\n\n\n","da4f7c83":"# Graph all except linkedin and cloud because of lack of data\n\nEdVsYear = year_relator([\"Q40_Part_1\", \"Q40_Part_2\", \"Q40_Part_3\", \"Q40_Part_4\", \"Q40_Part_5\", \"Q40_Part_6\", \n                         \"Q40_Part_7\", \"Q40_Part_8\", \"Q40_Part_9\", \"Q40_Part_10\", \"Q40_Part_11\",\n                         \"Q40_Part_1\", \"Q40_Part_2\", \"Q40_Part_3\", \"Q40_Part_4\", \"Q40_Part_5\", \"Q40_Part_6\", \n                         \"Q40_Part_7\", \"Q40_Part_8\", \"Q40_Part_9\", \"Q40_Part_10\", \"Q40_Part_11\",\n              \"Q37_Part_1\", \"Q37_Part_2\", \"Q37_Part_3\", \"Q37_Part_4\", \"Q37_Part_5\", \"Q37_Part_6\", \n                         \"Q37_Part_7\", \"Q37_Part_8\", \"Q37_Part_9\", \"Q37_Part_10\", \"Q37_Part_11\",\n              \"Q37_Part_1\", \"Q37_Part_2\", \"Q37_Part_3\", \"Q37_Part_4\", \"Q37_Part_5\", \"Q37_Part_6\", \n                         \"Q37_Part_7\", \"Q37_Part_8\", \"Q37_Part_9\", \"Q37_Part_10\", \"Q37_Part_11\",\n               \"Q13_Part_2\", \"Q13_Part_3\", \"Q13_Part_6\", \"Q13_Part_4\", \"Q13_Part_7\", \"Q13_Part_1\", \n                         \"Q13_Part_8\", \"Q13_Part_9\", \"Q13_Part_12\", \"Q13_Part_10\", \"Q13_Part_11\",\n               \"Q13_Part_2\", \"Q13_Part_3\", \"Q13_Part_6\", \"Q13_Part_4\", \"Q13_Part_7\", \"Q13_Part_1\", \n                         \"Q13_Part_8\", \"Q13_Part_9\", \"Q13_Part_12\", \"Q13_Part_10\", \"Q13_Part_11\",\n                \"Q36_Part_2\", \"Q36_Part_3\", \"Q36_Part_6\", \"Q36_Part_4\", \"Q36_Part_7\", \"Q36_Part_1\", \n                         \"Q36_Part_9\", \"Q36_Part_13\", \"Q36_Part_13\", \"Q36_Part_11\", \"Q36_Part_12\",\n                \"Q36_Part_2\", \"Q36_Part_3\", \"Q36_Part_6\", \"Q36_Part_4\", \"Q36_Part_7\", \"Q36_Part_1\", \n                         \"Q36_Part_9\", \"Q36_Part_13\", \"Q36_Part_13\", \"Q36_Part_11\", \"Q36_Part_12\"], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             ['Coursera', 'EdX', 'Kaggle', 'DataCamp', 'Fast.ai', 'Udacity', 'Udemy', 'Linkedin', 'Cloud',\n             'University', 'None'], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 11)\n\nEdVsYear_o, EdVsYear_y = bifurcate_data(EdVsYear)\n\n\nEdVsYear_o = pd.DataFrame(reformat_yearwise_rel(EdVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nEdVsYear_y = pd.DataFrame(reformat_yearwise_rel(EdVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\nEdVsYear_o = EdVsYear_o.loc[EdVsYear_o['Mid'] != 'Linkedin']\nEdVsYear_o = EdVsYear_o.loc[EdVsYear_o['Mid'] != 'Cloud']\nEdVsYear_y = EdVsYear_y.loc[EdVsYear_y['Mid'] != 'Linkedin']\nEdVsYear_y = EdVsYear_y.loc[EdVsYear_y['Mid'] != 'Cloud']\n\nfig = go.Figure()\nadd_many_traces(fig, EdVsYear_o.reindex(index=EdVsYear_o.index[::-1]), ['Coursera', 'EdX', 'Kaggle', 'DataCamp', 'Fast.ai', 'Udacity', 'Udemy',\n             'University', 'None'],\n                ['red', 'grey', 'blue', 'grey', 'grey', 'grey', 'lightgreen', 'yellow', 'grey'])\nfig.update_layout(title_text = \"Education Platform vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, EdVsYear_y.reindex(index=EdVsYear_y.index[::-1]),['Coursera', 'EdX', 'Kaggle', 'DataCamp', 'Fast.ai', 'Udacity', 'Udemy',\n             'University', 'None'], \n                ['red', 'grey', 'blue', 'grey', 'grey', 'grey', 'lightgreen', 'yellow', 'grey'])\nfig.update_layout(title_text = \"Education Platform vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n","7ca91d74":"Lang2021 = multi_Y_data_MV([\"Q7_\", \"Q7_\"], [\"Python\", \"R\", \"SQL\", \"C\", \"C++\", \"Java\", \"Javascript\", \"TypeScript\", \"Bash\", \"MATLAB\", \"None\", \n                 \"Other\"], get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = False, cut_off = 1, reformat = False)\n\nLang2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Lang2021)\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Lang2021[Lang2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Lang2021[Lang2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Lang2021[Lang2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Lang2021[Lang2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Programming Language Usage for Experienced and New Users\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Programming Language',\n                 yaxis_title = 'Share of Users',\n                 )\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","b86aca31":"LangVsYear = year_relator([\"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\", \"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\",\n              \"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\", \"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_11\",\n              \"Q18_Part_1\", \"Q18_Part_2\", \"Q18_Part_10\", \"Q18_Part_1\", \"Q18_Part_2\", \"Q18_Part_10\",\n             \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_9\", \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_9\"\n             ], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             [\"Python\", \"R\", \"MATLAB\"], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 3)\n\nLangVsYear_o, LangVsYear_y = bifurcate_data(LangVsYear)\n\nLangVsYear_o = pd.DataFrame(reformat_yearwise_rel(LangVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nLangVsYear_y = pd.DataFrame(reformat_yearwise_rel(LangVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\n\nfig = go.Figure()\nadd_many_traces(fig, LangVsYear_o.reindex(index=LangVsYear_o.index[::-1]), [\"Python\", \"R\", \"MATLAB\"], ['red', 'green', 'blue'])\nfig.update_layout(title_text = \"Programming Language Usage vs Time for Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, LangVsYear_y.reindex(index=LangVsYear_y.index[::-1]), [\"Python\", \"R\", \"MATLAB\"], ['red', 'green', 'blue'])\nfig.update_layout(title_text = \"Programming Language Usage vs Time for New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n","b9b49233":"# IDE Vs Time\n\nIDE2021 = multi_Y_data_MV([\"Q9_\", \"Q9_\"], [\"JupyterLab\", \"RStudio\", \"Visual Studio\", \n                                           \"VS Code\", \"PyCharm\", \"Spyder\", \"Notepad++\", \n                                           \"Sublime Text\", \"Vim\", \"MATLAB\", \"Jupyter Notebook\", \"None\",\n                                           \"Other\"], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nIDE2021 = conv_rel([\"2021 Old\", \"2021 Young\"], IDE2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = IDE2021[IDE2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = IDE2021[IDE2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = IDE2021[IDE2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = IDE2021[IDE2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"IDE Usage for Experienced and New Users\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'IDE Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","23469efd":"# Focus on Jupyter, RStudio, Visual Studio, Vim\n\nIDEvsYear_2120 = year_relator([\"Q9_Part_1\", \"Q9_Part_2\", \"Q9_Part_3\", \"Q9_Part_4\", \"Q9_Part_9\", \"Q9_Part_11\", \"Q9_Part_1\", \"Q9_Part_2\", \"Q9_Part_3\", \"Q9_Part_4\", \"Q9_Part_9\",\"Q9_Part_11\",\n              \"Q9_Part_1\", \"Q9_Part_2\", \"Q9_Part_3\", \"Q9_Part_4\", \"Q9_Part_9\", \"Q9_Part_11\", \"Q9_Part_1\", \"Q9_Part_2\", \"Q9_Part_3\", \"Q9_Part_4\", \"Q9_Part_9\",\"Q9_Part_11\"],\n             #\"Q13_Part_1\", \"Q13_Part_2\", \"Q13_Part_4\", \"Q13_Part_8\", \"Q13_Part_11\", \"Q13_Part_1\", \"Q13_Part_2\", \"Q13_Part_4\", \"Q13_Part_8\",\"Q13_Part_11\"\n             #], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\"], \n                         # \"2018 Old\", \"2018 New\"], \n             [\"Jupyter Lab\", \"Jupyter Notebooks\", \"RStudio\", \"Visual Studio\", \"Visual Studio Code\", \"Vim\"], \n             [d21_o, d21_y, d20_o, d20_y], \n              # d19_o, d19_y, d18_o, d18_y], \n              6)\n\nIDEvsYear_18 = year_relator([\"Q13_Part_1\", \"Q13_Part_2\", \"Q13_Part_4\", \"Q13_Part_8\", \"Q13_Part_11\", \"Q13_Part_1\", \"Q13_Part_2\", \"Q13_Part_4\", \"Q13_Part_8\", \"Q13_Part_11\"],\n                         [\"2018 Old\", \"2018 New\"], \n             [\"Jupyter Lab\", \"RStudio\", \"Visual Studio Code\", \"Visual Studio\", \"Vim\"], \n              [d18_o, d18_y], \n              5)\n\nIDEvsYear_19 = year_relator([\"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_6\", \"Q16_Part_8\",\"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_6\", \"Q16_Part_8\",],\n                         [\"2019 Old\", \"2019 New\"], \n             [\"Jupyter Lab\", \"RStudio\", \"Visual Studio\", \"Vim\"], \n              [d19_o, d19_y], \n              4)\n\nIDEvsYear = pd.concat([pd.DataFrame(IDEvsYear_2120, columns = [\"VarX\", 'Mid', 'VarY']), \n                       pd.DataFrame(IDEvsYear_19, columns = [\"VarX\", 'Mid', 'VarY']),\n                       pd.DataFrame(IDEvsYear_18, columns = [\"VarX\", 'Mid', 'VarY'])])\nIDEvsYear = comb_mids(IDEvsYear.to_numpy(), [[\"Visual Studio\",\"Visual Studio Code\"], [\"Jupyter Lab\", \"Jupyter Notebooks\"]],\n                     [\"Visual Studio Code\", \"Jupyter Notebooks\"], [\"2021 Old\", \"2020 Old\",\"2021 New\", \"2020 New\"])\nIDEvsYear = comb_mids(IDEvsYear, [[\"Visual Studio\",\"Visual Studio Code\"]],\n                     [\"Visual Studio Code\"], [\"2018 Old\", \"2018 New\"])\n\n\nIDEVsYear_o, IDEVsYear_y = bifurcate_data(IDEvsYear)\nIDEVsYear_o[\"VarY\"] = IDEVsYear_o[\"VarY\"].astype(str).astype(float)\nIDEVsYear_y[\"VarY\"] = IDEVsYear_y[\"VarY\"].astype(str).astype(float)\n\nIDEVsYear_o = pd.DataFrame(reformat_yearwise_rel(IDEVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\n\nIDEVsYear_o = IDEVsYear_o.sort_values('VarX', ascending = False)\n\nIDEVsYear_y = pd.DataFrame(reformat_yearwise_rel(IDEVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\nIDEVsYear_y = IDEVsYear_y.sort_values('VarX', ascending = False)\n\nfig = go.Figure()\nadd_many_traces(fig, IDEVsYear_o.reindex(index=IDEVsYear_o.index[::-1]), [\"Jupyter Lab\", \"RStudio\", \"Visual Studio\", \"Vim\"], ['red', 'green', 'blue', 'black'])\nfig.update_layout(title_text = \"IDE Used vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, IDEVsYear_y.reindex(index=IDEVsYear_y.index[::-1]), [\"Jupyter Lab\", \"RStudio\", \"Visual Studio\", \"Vim\"], ['red', 'green', 'blue', 'black'])\nfig.update_layout(title_text = \"IDE Used vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n","1707649c":"# Notebook Usage in 2021\n\nNotebooks2021 = multi_Y_data_MV([\"Q10_\", \"Q10_\"], ['Kaggle Notebooks',\n'Colab Notebooks',\n'Azure Notebooks',\n'Paperspace\/Gradient',\n'Binder\/JupyterHub',\n'Code Ocean',\n'IBM Watson Studio',\n'Amazon Sagemaker Notebooks',\n'Amazon EMR Notebooks',\n'Google Cloud Notebooks',\n'Google Cloud Datalab',\n'Databricks Colab Notebooks',\n'Zeppelin \/ Zepl Notebooks',\n'Deepnote Notebooks',\n'Observable Notebooks',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nNotebooks2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Notebooks2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Notebooks2021[Notebooks2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Notebooks2021[Notebooks2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Notebooks2021[Notebooks2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Notebooks2021[Notebooks2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Notebooks Usage in 2021 for Experienced and New Users\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Notebook',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","6153cd5a":"# Focus on Kaggle, Colab, Azure, None\n\nNbVsYear = year_relator([\"Q10_Part_1\", \"Q10_Part_2\", \"Q10_Part_3\", \"Q10_Part_16\", \"Q10_Part_1\", \"Q10_Part_2\", \"Q10_Part_3\", \"Q10_Part_16\",\n              \"Q10_Part_1\", \"Q10_Part_2\", \"Q10_Part_3\", \"Q10_Part_13\", \"Q10_Part_1\", \"Q10_Part_2\", \"Q10_Part_3\", \"Q10_Part_13\",\n              \"Q17_Part_1\", \"Q17_Part_2\", \"Q17_Part_3\", \"Q17_Part_11\", \"Q17_Part_1\", \"Q17_Part_2\", \"Q17_Part_3\", \"Q17_Part_11\",\n             \"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\", \"Q14_Part_10\", \"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\", \"Q14_Part_10\"\n             ], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             [\"Kaggle\", \"Colab\", \"Azure\", \"None\"], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 4)\n\nNbVsYear_o, NbVsYear_y = bifurcate_data(NbVsYear)\n\n\nNbVsYear_o = pd.DataFrame(reformat_yearwise_rel(NbVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nNbVsYear_y = pd.DataFrame(reformat_yearwise_rel(NbVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\n\nfig = go.Figure()\nadd_many_traces(fig, NbVsYear_o.reindex(index=NbVsYear_o.index[::-1]), [\"Kaggle\", \"Colab\", \"Azure\", \"None\"], ['red', 'green', 'blue', 'black'])\nfig.update_layout(title_text = \"Notebooks Used vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, NbVsYear_y.reindex(index=NbVsYear_y.index[::-1]), [\"Kaggle\", \"Colab\", \"Azure\", \"None\"], ['red', 'green', 'blue', 'black'])\nfig.update_layout(title_text = \"Notebooks Used vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n","569cf7cb":"# TPU Usage\n\nTPUVsYear = Line_SV_2([\"Q13\",\"Q13\",\"Q13\",\"Q13\",\"Q13\",\n            \"Q13\",\"Q13\",\"Q13\",\"Q13\",\"Q13\",\n            \"Q22\",\"Q22\",\"Q22\",\"Q22\",\"Q22\",\n            \"Q13\",\"Q13\",\"Q13\",\"Q13\",\"Q13\",\n            \"Q13\",\"Q13\",\"Q13\",\"Q13\",\"Q13\",\n            \"Q22\",\"Q22\",\"Q22\",\"Q22\",\"Q22\"],\n            ['Never', 'Once', '2-5 times', '6-25 times', 'More than 25 times',\n           'Never', 'Once', '2-5 times', '6-25 times', 'More than 25 times',\n           'Never', 'Once', '2-5 times', '6-24 times', '> 25 times',\n           'Never', 'Once', '2-5 times', '6-25 times', 'More than 25 times',\n           'Never', 'Once', '2-5 times', '6-25 times', 'More than 25 times',\n           'Never', 'Once', '2-5 times', '6-24 times', '> 25 times'],\n          ['Never', 'Once', '2-5 times', '6-25 Times', '> 25 Times'], \n          [\"2021 Old\", \"2020 Old\", \"2019 Old\", \"2021 New\", \"2020 New\", \"2019 New\"], 5, \n          [d21_o[~d21_o[\"Q13\"].isin([np.nan])], d20_o[~d20_o[\"Q13\"].isin([np.nan])], d19_o[~d19_o[\"Q22\"].isin([np.nan])], \n           d21_y[~d21_y[\"Q13\"].isin([np.nan])], d20_y[~d20_y[\"Q13\"].isin([np.nan])], d19_y[~d19_y[\"Q22\"].isin([np.nan])]])\n\nTPUVsYear = conv_rel_2(TPUVsYear.to_numpy(), {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n                         #ident = ['2021 Old', '2021 New'])\nTPUVsYear_o, TPUVsYear_y = bifurcate_data(TPUVsYear.to_numpy())\n\nTPUVsYear_2021 = TPUVsYear[TPUVsYear[\"VarX\"].isin(['2021 Old', '2021 New'])]\nfig = go.Figure()\nfig.add_trace(go.Bar(x = TPUVsYear_2021[TPUVsYear_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = TPUVsYear_2021[TPUVsYear_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = TPUVsYear_2021[TPUVsYear_2021['VarX'].isin(['2021 New'])]['Mid'],\n                     y = TPUVsYear_2021[TPUVsYear_2021['VarX'].isin(['2021 New'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"TPU Usage in 2021 for Experienced and New Users\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Frequency of TPU Usage',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","0ae9b21c":"# TPU Line Graphs\n\nfig = go.Figure()\nadd_many_traces(fig, TPUVsYear_o.reindex(index=TPUVsYear_o.index[::-1]), ['Never', 'Once', '2-5 times', '6-25 Times', '> 25 Times'],\n                ['red', 'grey', 'blue', 'grey', 'green'])\nfig.update_layout(title_text = \"TPU Usage Frequency vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, TPUVsYear_y.reindex(index=TPUVsYear_y.index[::-1]), ['Never', 'Once', '2-5 times', '6-25 Times', '> 25 Times'], \n                ['red', 'grey', 'blue', 'grey', 'green'])\nfig.update_layout(title_text = \"TPU Usage Frequency vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n","0eddf857":"# ML Frameworks 2021\n\nFrame_2021 = multi_Y_data_MV([\"Q16_\", \"Q16_\"], ['Scikit-learn',\n'TensorFlow',\n'Keras',\n'PyTorch',\n'Fast.ai',\n'MXNet',\n'Xgboost',\n'LightGBM',\n'CatBoost',\n'Prophet',\n'H2O 3',\n'Caret',\n'Tidymodels',\n'JAX',\n'PyTorch Lightning',\n'Huggingface',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nFrame_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Frame_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Frame_2021[Frame_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Frame_2021[Frame_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Frame_2021[Frame_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Frame_2021[Frame_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Machine Learning Frameworks Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Machine Learning Framework',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","077ca79b":"# Focus on scikit-learn TensorFlow, Keras, PyTorch, Xgboost, LightGBM, None\n\n# Not taking hugging face because lack of data\n\nFrameVsYear = year_relator([\"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_3\", \"Q16_Part_4\", \"Q16_Part_7\", \"Q16_Part_8\", 'Q16_Part_17', \n                           \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_3\", \"Q16_Part_4\", \"Q16_Part_7\", \"Q16_Part_8\", 'Q16_Part_17',\n              \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_3\", \"Q16_Part_4\", \"Q16_Part_7\", \"Q16_Part_8\", 'Q16_Part_15',\n              \"Q16_Part_1\", \"Q16_Part_2\", \"Q16_Part_3\", \"Q16_Part_4\", \"Q16_Part_7\", \"Q16_Part_8\", 'Q16_Part_15',\n              \"Q28_Part_1\",\"Q28_Part_2\", \"Q28_Part_3\", \"Q28_Part_6\", \"Q28_Part_5\", \"Q28_Part_8\", \"Q28_Part_11\",\n              \"Q28_Part_1\",\"Q28_Part_2\", \"Q28_Part_3\", \"Q28_Part_6\", \"Q28_Part_5\", \"Q28_Part_8\", \"Q28_Part_11\",\n             \"Q19_Part_1\",\"Q19_Part_2\", \"Q19_Part_3\", \"Q19_Part_4\", \"Q19_Part_10\", \"Q19_Part_14\", \"Q19_Part_14\",\n             \"Q19_Part_1\",\"Q19_Part_2\", \"Q19_Part_3\", \"Q19_Part_4\", \"Q19_Part_10\", \"Q19_Part_14\", \"Q19_Part_14\",\n             ], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             [\"Scikit-learn\", \"TensorFlow\", \"Keras\", 'PyTorch', 'Xgboost', 'LightGBM', \"None\"], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 7)\n\nFrameVsYear_o, FrameVsYear_y = bifurcate_data(FrameVsYear)\n\n\nFrameVsYear_o = pd.DataFrame(reformat_yearwise_rel(FrameVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nFrameVsYear_y = pd.DataFrame(reformat_yearwise_rel(FrameVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\n\nfig = go.Figure()\nadd_many_traces(fig, FrameVsYear_o.reindex(index=FrameVsYear_o.index[::-1]), [\"Scikit-learn\", \"TensorFlow\", \"Keras\", 'PyTorch', 'Xgboost', 'LightGBM', \"None\"],\n                ['red', 'green', 'blue', 'black', 'yellow', 'purple', 'grey'])\nfig.update_layout(title_text = \"ML Frameworks Used vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, FrameVsYear_y.reindex(index=FrameVsYear_y.index[::-1]), [\"Scikit-learn\", \"TensorFlow\", \"Keras\", 'PyTorch', 'Xgboost', 'LightGBM', \"None\"], \n                ['red', 'green', 'blue', 'black', 'yellow', 'purple', 'grey'])\nfig.update_layout(title_text = \"ML Frameworks Used vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\n\n\n","fe3adcbf":"# AutoML\n\nAuto_2021 = multi_Y_data_MV([\"Q36_A_\", \"Q36_A_\"], ['Data augmentation (imgaug, albumentations)',\n'Feature engineering\/selection (tpot, boruta_py)',\n'Model selection (auto-sklearn, xcessiv)',\n'Model architecture searches (darts, enas)',\n'Hyperparameter tuning (hyperopt, ray.tune, Vizier)',\n'Full ML pipelines (Google AutoML, H20 Driverless AI)',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nnum_old_Auto_ans = Auto_2021[Auto_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_Auto_ans = Auto_2021[Auto_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nAuto_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Auto_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Auto_2021[Auto_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Auto_2021[Auto_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Auto_2021[Auto_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Auto_2021[Auto_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"AutoML (or Partial) Usage in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'AutoML Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","45529fa1":"# Graph all and test\n\nAutoVsYear = year_relator([\"Q36_A_Part_1\", \"Q36_A_Part_2\",\"Q36_A_Part_3\", \"Q36_A_Part_4\", \"Q36_A_Part_5\", \"Q36_A_Part_6\", \"Q36_A_Part_7\",\n                           \"Q36_A_Part_1\", \"Q36_A_Part_2\",\"Q36_A_Part_3\", \"Q36_A_Part_4\", \"Q36_A_Part_5\", \"Q36_A_Part_6\", \"Q36_A_Part_7\",\n              \"Q33_A_Part_1\", \"Q33_A_Part_2\", \"Q33_A_Part_3\", \"Q33_A_Part_4\", \"Q33_A_Part_5\", \"Q33_A_Part_6\", \"Q33_A_Part_7\",\n              \"Q33_A_Part_1\", \"Q33_A_Part_2\", \"Q33_A_Part_3\", \"Q33_A_Part_4\", \"Q33_A_Part_5\", \"Q33_A_Part_6\", \"Q33_A_Part_7\",\n              \"Q25_Part_1\", \"Q25_Part_2\", \"Q25_Part_3\", \"Q25_Part_4\", \"Q25_Part_5\", \"Q25_Part_6\", \"Q25_Part_7\",\n              \"Q25_Part_1\", \"Q25_Part_2\", \"Q25_Part_3\", \"Q25_Part_4\", \"Q25_Part_5\", \"Q25_Part_6\", \"Q25_Part_7\"], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\"], \n             ['Augmentation', 'Feature Engineering', 'Model Selection', 'Architechture Searches',\n              'Hyperparameter', 'Full Pipelines', 'None'], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y], 7)\n\nAutoVsYear_o, AutoVsYear_y = bifurcate_data(AutoVsYear)\n\nAutoVsYear_o = pd.DataFrame(AutoVsYear_o, columns = ['VarX', 'Mid', 'VarY'])\nAutoVsYear_y = pd.DataFrame(AutoVsYear_y, columns = ['VarX', 'Mid', 'VarY'])\n\nnum_old_Auto_ans_21 = AutoVsYear_o[AutoVsYear_o['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_Auto_ans_21 = AutoVsYear_y[AutoVsYear_y['VarX'].isin([\"2021 New\"])]['VarY'].sum()\nnum_old_Auto_ans_20 = AutoVsYear_o[AutoVsYear_o['VarX'].isin([\"2020 Old\"])]['VarY'].sum()\nnum_young_Auto_ans_20 = AutoVsYear_y[AutoVsYear_y['VarX'].isin([\"2020 New\"])]['VarY'].sum()\nnum_old_Auto_ans_19 = AutoVsYear_o[AutoVsYear_o['VarX'].isin([\"2019 Old\"])]['VarY'].sum()\nnum_young_Auto_ans_19 = AutoVsYear_y[AutoVsYear_y['VarX'].isin([\"2019 New\"])]['VarY'].sum()\n\n\nAutoVsYear_o = pd.DataFrame(reformat_yearwise_rel(AutoVsYear_o, {'2021 Old' : num_old_Auto_ans_21, '2020 Old' : num_old_Auto_ans_20,\n                                                             '2019 Old' : num_old_Auto_ans_19, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nAutoVsYear_y = pd.DataFrame(reformat_yearwise_rel(AutoVsYear_y, {'2021 New' : num_young_Auto_ans_21, '2020 New' : num_young_Auto_ans_20, \n                                                             '2019 New' : num_young_Auto_ans_19, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\nfig = go.Figure()\nadd_many_traces(fig, AutoVsYear_o.reindex(index=AutoVsYear_o.index[::-1]), ['Augmentation', 'Feature Engineering', 'Model Selection', 'Architechture Searches',\n              'Hyperparameter', 'Full Pipelines', 'None'],\n                ['red', 'green', 'blue', 'black', 'yellow', 'grey', 'purple'])\nfig.update_layout(title_text = \"AutoML (or Partial) Usage vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, AutoVsYear_y.reindex(index=AutoVsYear_y.index[::-1]),['Augmentation', 'Feature Engineering', 'Model Selection', 'Architechture Searches',\n              'Hyperparameter', 'Full Pipelines', 'None'], \n                ['red', 'green', 'blue', 'black', 'yellow', 'grey', 'purple'])\nfig.update_layout(title_text = \"AutoML (or Partial) Usage vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()","b888a168":"# AutoML Specific Tools\n\nAutoP_2021 = multi_Y_data_MV([\"Q37_A_\", \"Q37_A_\"], ['Google Cloud AutoML',\n'H20 Driverless AI',\n'Databricks AutoML',\n'DataRobot AutoML',\n'Amazon Sagemaker Autopilot',\n'Azure Automated Machine Learning',\n'No \/ None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nnum_old_AutoP_ans = AutoP_2021[AutoP_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_AutoP_ans = AutoP_2021[AutoP_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nAutoP_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], AutoP_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = AutoP_2021[AutoP_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = AutoP_2021[AutoP_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = AutoP_2021[AutoP_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = AutoP_2021[AutoP_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Usage of Specific AutoML tools in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Auto ML Tool',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","3285fa22":"# Experiments\n\nExperiments_2021 = multi_Y_data_MV([\"Q38_A_\", \"Q38_A_\"], ['Neptune.ai',\n'Weights & Biases',\n'Comet.ml',\n'Sacred + Omniboard',\n'TensorBoard',\n'Guild.ai',\n'Polyaxon',\n'Trains',\n'Domino Model Monitor',\n'MLflow',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nnum_old_Experiments_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_Experiments_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nExperiments_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Experiments_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Experiments_2021[Experiments_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Experiments_2021[Experiments_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Experiments_2021[Experiments_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Experiments_2021[Experiments_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Experiment Management Tools Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Experiment Management Tools',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","6e4174a0":"# Social Media Platforms 2021\n\nReport_2021 = multi_Y_data_MV([\"Q42_\", \"Q42_\"], ['Twitter',\n\"Email newsletters\",\n'Reddit',\n'Kaggle',\n'Course Forums',\n'YouTube',\n'Podcasts',\n'Blogs',\n'Journal Publications',\n'Slack Communities',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\n#num_old_Deploy_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\n#num_young_Deploy_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nReport_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Report_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Report_2021[Report_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Report_2021[Report_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Report_2021[Report_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Report_2021[Report_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Media Platform for Data Science Reporting Referred to in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Reporting Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()\n","9310f7dc":"ReportVsYear = year_relator([\"Q42_Part_1\", \"Q42_Part_2\", \"Q42_Part_3\", \"Q42_Part_4\", \"Q42_Part_5\", \"Q42_Part_6\", \n                         \"Q42_Part_7\", \"Q42_Part_8\", \"Q42_Part_9\", \"Q42_Part_10\", \"Q42_Part_11\",\n                         \"Q42_Part_1\", \"Q42_Part_2\", \"Q42_Part_3\", \"Q42_Part_4\", \"Q42_Part_5\", \"Q42_Part_6\", \n                         \"Q42_Part_7\", \"Q42_Part_8\", \"Q42_Part_9\", \"Q42_Part_10\", \"Q42_Part_11\",\n              \"Q39_Part_1\", \"Q39_Part_2\", \"Q39_Part_3\", \"Q39_Part_4\", \"Q39_Part_5\", \"Q39_Part_6\", \n                         \"Q39_Part_7\", \"Q39_Part_8\", \"Q39_Part_9\", \"Q39_Part_10\", \"Q39_Part_11\",\n              \"Q39_Part_1\", \"Q39_Part_2\", \"Q39_Part_3\", \"Q39_Part_4\", \"Q39_Part_5\", \"Q39_Part_6\", \n                         \"Q39_Part_7\", \"Q39_Part_8\", \"Q39_Part_9\", \"Q39_Part_10\", \"Q39_Part_11\",\n              \"Q12_Part_1\", \"Q12_Part_2\", \"Q12_Part_3\", \"Q12_Part_4\", \"Q12_Part_5\", \"Q12_Part_6\", \n                         \"Q12_Part_7\", \"Q12_Part_8\", \"Q12_Part_9\", \"Q12_Part_10\", \"Q12_Part_11\",\n               \"Q12_Part_1\", \"Q12_Part_2\", \"Q12_Part_3\", \"Q12_Part_4\", \"Q12_Part_5\", \"Q12_Part_6\", \n                         \"Q12_Part_7\", \"Q12_Part_8\", \"Q12_Part_9\", \"Q12_Part_10\", \"Q12_Part_11\"], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\"], \n             ['Twitter', 'Newsletters', 'Reddit', 'Kaggle', 'Course Forums', 'Youtube', 'Podcasts', \n              'Blogs', 'Journals', 'Slack', 'None'], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y], 11)\n\n\"\"\"\nReportVsYear_2018 = year_relator(['Q38_Part_1', 'Q38_Part_2', 'Q38_Part_3','Q38_Part_4','Q38_Part_5',\n                              'Q38_Part_6','Q38_Part_7','Q38_Part_8','Q38_Part_9','Q38_Part_10','Q38_Part_11',\n                              'Q38_Part_12','Q38_Part_13','Q38_Part_14','Q38_Part_15','Q38_Part_16','Q38_Part_17',\n                              'Q38_Part_18','Q38_Part_19','Q38_Part_20','Q38_Part_21','Q38_Part_22',\n                              'Q38_Part_1', 'Q38_Part_2', 'Q38_Part_3','Q38_Part_4','Q38_Part_5',\n                              'Q38_Part_6','Q38_Part_7','Q38_Part_8','Q38_Part_9','Q38_Part_10','Q38_Part_11',\n                              'Q38_Part_12','Q38_Part_13','Q38_Part_14','Q38_Part_15','Q38_Part_16','Q38_Part_17',\n                              'Q38_Part_18','Q38_Part_19','Q38_Part_20','Q38_Part_21','Q38_Part_22'],\n                             ['2018 Old', '2018 New'],\n                             [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n                             [d18_o, d18_y]\n                            )\n\nReportvsYear = comb_mids(ReportVsYear.to_numpy(), [[6, ], [\"Jupyter Lab\", \"Jupyter Notebooks\"]],\n                     [\"Visual Studio Code\", \"Jupyter Notebooks\"], [\"2021 Old\", \"2020 Old\",\"2021 New\", \"2020 New\"])\n\n\"\"\"\n\nReportVsYear_o, ReportVsYear_y = bifurcate_data(ReportVsYear)\n\n\nReportVsYear_o = pd.DataFrame(reformat_yearwise_rel(ReportVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nReportVsYear_y = pd.DataFrame(reformat_yearwise_rel(ReportVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\nReportVsYear_o = ReportVsYear_o.loc[ReportVsYear_o['Mid'] != 'Newsletters']\nReportVsYear_y = ReportVsYear_y.loc[ReportVsYear_y['Mid'] != 'Newsletters']\n\nfig = go.Figure()\nadd_many_traces(fig, ReportVsYear_o.reindex(index=ReportVsYear_o.index[::-1]), ['Twitter', 'Newsletters', 'Reddit', 'Kaggle', 'Course Forums', 'Youtube', 'Podcasts', \n              'Blogs', 'Journals', 'Slack', 'None'],\n                ['grey', 'grey', 'grey', 'blue', 'yellow', 'red', 'grey', 'green', 'orange', 'grey',\n                'grey'])\nfig.update_layout(title_text = \"Media Reporting Platform vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, ReportVsYear_y.reindex(index=ReportVsYear_y.index[::-1]),['Twitter', 'Newsletters', 'Reddit', 'Kaggle', 'Course Forums', 'Youtube', 'Podcasts', \n              'Blogs', 'Journals', 'Slack', 'None'], \n                ['grey', 'grey', 'grey', 'blue', 'yellow', 'red', 'grey', 'green', 'orange', 'grey',\n                'grey'])\nfig.update_layout(title_text = \"Media Reporting Platform vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n","4415fb40":"# Visualization Libraries\n\nVisL_2021 = multi_Y_data_MV([\"Q14_\", \"Q14_\"], ['Matplotlib',\n'Seaborn',\n'Plotly \/ Plotly Express',\n'Ggplot \/ ggplot2',\n'Shiny',\n'D3 js',\n'Altair',\n'Bokeh',\n'Geoplotlib',\n'Leaflet \/ Folium',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nVisL_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], VisL_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = VisL_2021[VisL_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = VisL_2021[VisL_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = VisL_2021[VisL_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = VisL_2021[VisL_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Visualization Libraries Used in 2021 for Experienced and New Users\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Visualization Library',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","fba6c56f":"# Focus on Matplotlib, Seaborn, Ploty, Ggplot, Shiny, None\n\nVisLVsYear = year_relator([\"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\", \"Q14_Part_4\", \"Q14_Part_5\", \"Q14_Part_11\", \n                           \"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\", \"Q14_Part_4\", \"Q14_Part_5\",\"Q14_Part_11\",\n              \"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\", \"Q14_Part_4\", \"Q14_Part_5\", \"Q14_Part_11\", \n              \"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\", \"Q14_Part_4\", \"Q14_Part_5\",\"Q14_Part_11\",\n              \"Q20_Part_2\", \"Q20_Part_8\", \"Q20_Part_6\", \"Q20_Part_1\", \"Q20_Part_4\", \"Q20_Part_11\",\n              \"Q20_Part_2\", \"Q20_Part_8\", \"Q20_Part_6\", \"Q20_Part_1\", \"Q20_Part_4\", \"Q20_Part_11\",\n             \"Q21_Part_2\", \"Q21_Part_8\", \"Q21_Part_6\", \"Q21_Part_1\", \"Q21_Part_4\", \"Q21_Part_12\",\n             \"Q21_Part_2\", \"Q21_Part_8\", \"Q21_Part_6\", \"Q21_Part_1\", \"Q21_Part_4\", \"Q21_Part_12\",\n             ], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             [\"Matplotlib\", \"Seaborn\", \"Ploty\", 'GGPlot2', 'Shiny', \"None\"], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 6)\n\nVisLVsYear_o, VisLVsYear_y = bifurcate_data(VisLVsYear)\n\n\nVisLVsYear_o = pd.DataFrame(reformat_yearwise_rel(VisLVsYear_o, {'2021 Old' : 573, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nVisLVsYear_y = pd.DataFrame(reformat_yearwise_rel(VisLVsYear_y, {'2021 New' : 13838, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\n\nfig = go.Figure()\nadd_many_traces(fig, VisLVsYear_o.reindex(index=VisLVsYear_o.index[::-1]), [\"Matplotlib\", \"Seaborn\", \"Ploty\", 'GGPlot2', 'Shiny', \"None\"],\n                ['red', 'green', 'blue', 'black', 'yellow', 'purple'])\nfig.update_layout(title_text = \"Visualization Libraries Used vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, VisLVsYear_y.reindex(index=VisLVsYear_y.index[::-1]), [\"Matplotlib\", \"Seaborn\", \"Ploty\", 'GGPlot2', 'Shiny', \"None\"], \n                ['red', 'green', 'blue', 'black', 'yellow', 'purple'])\nfig.update_layout(title_text = \"Visualization Libraries Used vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()","5a3867ff":"# Cloud Computing 2021\n\nCC_2021 = multi_Y_data_MV([\"Q27_A_\", \"Q27_A_\"], ['Amazon Web Services (AWS)',\n'Microsoft Azure',\n'Google Cloud Platform',\n'IBM Cloud \/ Red Hat',\n'Oracle Cloud',\n'SAP Cloud',\n'Salesforce Cloud',\n'VMware Cloud',\n'Alibaba Cloud',\n'Tencent Cloud',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nnum_old_CC_ans = CC_2021[CC_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_CC_ans = CC_2021[CC_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nCC_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], CC_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = CC_2021[CC_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = CC_2021[CC_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = CC_2021[CC_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = CC_2021[CC_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Cloud Computing Platforms Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Cloud Computing Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()\nnames_old_CC = get_question_index(\"Q28\", d21_o)\nnames_y_CC = get_question_index(\"Q28\", d21_y)\n\nCC_2021_Fav_old = Line_SV_2([\"Q28\",\"Q28\", \"Q28\", \"Q28\", \"Q28\", \"Q28\", \"Q28\",\"Q28\", \"Q28\"],\n            names_old_CC,\n          names_old_CC, \n          [\"2021 Old\", \"2021 New\"], 9, \n          [d21_o[~d21_o[\"Q28\"].isin([np.nan])],d21_y[~d21_y[\"Q28\"].isin([np.nan])]])\n\nCC_2021_Fav_new = Line_SV_2([\"Q28\",\"Q28\", \"Q28\", \"Q28\", \"Q28\", \"Q28\", \"Q28\",\"Q28\", \"Q28\",\"Q28\",\"Q28\", \"Q28\"],\n            names_y_CC,\n          names_y_CC, \n          [\"2021 New\"], 12, \n          [d21_y[~d21_y[\"Q28\"].isin([np.nan])]])\n\nCC_2021_Fav = pd.concat([CC_2021_Fav_old,CC_2021_Fav_new])\n\nCC_2021_Fav = conv_rel_2(CC_2021_Fav.to_numpy(), {'2021 Old' : num_old_CC_ans, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : num_young_CC_ans, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n                         #ident = ['2021 Old', '2021 New'])\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = CC_2021_Fav[CC_2021_Fav['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = CC_2021_Fav[CC_2021_Fav['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = CC_2021_Fav[CC_2021_Fav['VarX'].isin(['2021 New'])]['Mid'],\n                     y = CC_2021_Fav[CC_2021_Fav['VarX'].isin(['2021 New'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Preferred Cloud Computing Platform Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Cloud Computing Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","893ff34a":"# Focus on AWS, Azure, Google, None\n\nCCVsYear = year_relator([\"Q27_A_Part_1\", \"Q27_A_Part_2\", \"Q27_A_Part_3\", \"Q27_A_Part_11\",\"Q27_A_Part_1\", \"Q27_A_Part_2\", \"Q27_A_Part_3\", \"Q27_A_Part_11\",\n              \"Q26_A_Part_1\", \"Q26_A_Part_2\", \"Q26_A_Part_3\", \"Q26_A_Part_11\",\"Q26_A_Part_1\", \"Q26_A_Part_2\", \"Q26_A_Part_3\", \"Q26_A_Part_11\",\n              \"Q29_Part_2\", \"Q29_Part_3\", \"Q29_Part_1\", \"Q29_Part_11\",\"Q29_Part_2\", \"Q29_Part_3\", \"Q29_Part_1\", \"Q29_Part_11\",\n              \"Q15_Part_2\", \"Q15_Part_3\", \"Q15_Part_1\", \"Q15_Part_6\",\"Q15_Part_2\", \"Q15_Part_3\", \"Q15_Part_1\", \"Q15_Part_6\"\n             ], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             [\"AWS\", \"Azure\", \"Google\", \"None\"], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 4)\n\nCCVsYear_o, CCVsYear_y = bifurcate_data(CCVsYear)\n\nnum_old_CC_ans_21 = CCVsYear_o[CCVsYear_o['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_CC_ans_21 = CCVsYear_y[CCVsYear_y['VarX'].isin([\"2021 New\"])]['VarY'].sum()\nnum_old_CC_ans_20 = CCVsYear_o[CCVsYear_o['VarX'].isin([\"2020 Old\"])]['VarY'].sum()\nnum_young_CC_ans_20 = CCVsYear_y[CCVsYear_y['VarX'].isin([\"2020 New\"])]['VarY'].sum()\nnum_old_CC_ans_19 = CCVsYear_o[CCVsYear_o['VarX'].isin([\"2019 Old\"])]['VarY'].sum()\nnum_young_CC_ans_19 = CCVsYear_y[CCVsYear_y['VarX'].isin([\"2019 New\"])]['VarY'].sum()\nnum_old_CC_ans_18 = CCVsYear_o[CCVsYear_o['VarX'].isin([\"2018 Old\"])]['VarY'].sum()\nnum_young_CC_ans_18 = CCVsYear_y[CCVsYear_y['VarX'].isin([\"2018 New\"])]['VarY'].sum()\n\nCCVsYear_o = pd.DataFrame(reformat_yearwise_rel(CCVsYear_o, {'2021 Old' : num_old_CC_ans_21, '2020 Old' : num_old_CC_ans_20,\n                                                             '2019 Old' : num_old_CC_ans_19, '2018 Old': num_old_CC_ans_18},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nCCVsYear_y = pd.DataFrame(reformat_yearwise_rel(CCVsYear_y, {'2021 New' : num_young_CC_ans_21, '2020 New' : num_young_CC_ans_20,\n                                                             '2019 New' : num_young_CC_ans_19, '2018 New': num_young_CC_ans_18},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\n\n\nfig = go.Figure()\nadd_many_traces(fig, CCVsYear_o.reindex(index=CCVsYear_o.index[::-1]), [\"AWS\", \"Azure\", \"Google\", \"None\"],\n                ['red', 'green', 'blue', 'black'])\nfig.update_layout(title_text = \"Cloud Computing Platform Usage vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, CCVsYear_y.reindex(index=CCVsYear_y.index[::-1]),[\"AWS\", \"Azure\", \"Google\", \"None\"], \n                ['red', 'green', 'blue', 'black'])\nfig.update_layout(title_text = \"Cloud Computing Platform Usage vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\n\n\n","0bcff67c":"# Managed ML\n\nMML_2021 = multi_Y_data_MV([\"Q31_A_\", \"Q31_A_\"], ['Amazon SageMaker',\n'Azure Machine Learning Studio',\n'Google Cloud Vertex AI',\n'DataRobot',\n'Databricks',\n'Dataiku',\n'Alteryx',\n'Rapidminer',\n'No \/ None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\n#num_old_MML_ans = CC_2021[CC_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\n#num_young_MML_ans = CC_2021[CC_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nMML_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], MML_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = MML_2021[MML_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = MML_2021[MML_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = MML_2021[MML_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = MML_2021[MML_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Managed ML Platforms Usage in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Managed ML Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","1fbe540c":"# Big Data\n\nBD_2021 = multi_Y_data_MV([\"Q32_A_\", \"Q32_A_\"], ['MySQL',\n'PostgreSQL',\n'SQLite',\n'Oracle Database',\n'MongoDB',\n'Snowflake',\n'IBM Db2',\n'Microsoft SQL Server',\n'Microsoft Azure SQL Database',\n'Microsoft Azure Cosmos DB',\n'Amazon Redshift',\n'Amazon Aurora',\n'Amazon RDS',\n'Amazon DynamoDB',\n'Google Cloud BigQuery',\n'Google Cloud SQL',\n'Google Cloud Firestore',\n'Google Cloud BigTable',\n'Google Cloud Spanner',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nnum_old_BD_ans = BD_2021[BD_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_BD_ans = BD_2021[BD_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nBD_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], BD_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = BD_2021[BD_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = BD_2021[BD_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = BD_2021[BD_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = BD_2021[BD_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Big Data Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Big Data Tool',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()\nnames_old_BD = get_question_index(\"Q33\", d21_o)\nnames_y_BD = get_question_index(\"Q33\", d21_y)\n\nBD_2021_Fav_old = Line_SV_2([\"Q33\", \"Q33\", \"Q33\", \"Q33\", \"Q33\",\n                            \"Q33\", \"Q33\", \"Q33\", \"Q33\", \"Q33\",\n                            \"Q33\", \"Q33\", \"Q33\", \"Q33\", \"Q33\",\n                            \"Q33\", \"Q33\", \"Q33\", \"Q33\"],\n            names_old_BD,\n          names_old_BD, \n          [\"2021 Old\", \"2021 New\"], 19, \n          [d21_o[~d21_o[\"Q33\"].isin([np.nan])],d21_y[~d21_y[\"Q33\"].isin([np.nan])]])\n\nBD_2021_Fav_new = Line_SV_2([\"Q33\", \"Q33\", \"Q33\", \"Q33\", \"Q33\",\n                            \"Q33\", \"Q33\", \"Q33\", \"Q33\", \"Q33\",\n                            \"Q33\", \"Q33\", \"Q33\", \"Q33\", \"Q33\",\n                            \"Q33\", \"Q33\", \"Q33\", \"Q33\", 'Q33'],\n            names_y_BD,\n          names_y_BD, \n          [\"2021 New\"], 20, \n          [d21_y[~d21_y[\"Q33\"].isin([np.nan])]])\n\nBD_2021_Fav = pd.concat([BD_2021_Fav_old,BD_2021_Fav_new])\n\nBD_2021_Fav = conv_rel_2(BD_2021_Fav.to_numpy(), {'2021 Old' : num_old_BD_ans, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : num_young_BD_ans, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n                         #ident = ['2021 Old', '2021 New'])\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = BD_2021_Fav[BD_2021_Fav['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = BD_2021_Fav[BD_2021_Fav['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = BD_2021_Fav[BD_2021_Fav['VarX'].isin(['2021 New'])]['Mid'],\n                     y = BD_2021_Fav[BD_2021_Fav['VarX'].isin(['2021 New'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Preferred Big Data Tools Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Big Data Tool',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","5e359e63":"# Focus on MySQL, PostgreSQL, SQLite, MS SQL, Snowflake, None\n\nBDVsYear = year_relator([\"Q32_A_Part_1\", \"Q32_A_Part_2\",\"Q32_A_Part_3\", \"Q32_A_Part_5\", \"Q32_A_Part_6\", \"Q32_A_Part_8\", \"Q32_A_Part_20\",\n              \"Q32_A_Part_1\", \"Q32_A_Part_2\",\"Q32_A_Part_3\", \"Q32_A_Part_5\", \"Q32_A_Part_6\", \"Q32_A_Part_8\", \"Q32_A_Part_20\",\n              \"Q29_A_Part_1\", \"Q29_A_Part_2\",\"Q29_A_Part_3\", \"Q29_A_Part_5\", \"Q29_A_Part_6\", \"Q29_A_Part_8\", \"Q29_A_Part_17\",\n              \"Q29_A_Part_1\", \"Q29_A_Part_2\",\"Q29_A_Part_3\", \"Q29_A_Part_5\", \"Q29_A_Part_6\", \"Q29_A_Part_8\", \"Q29_A_Part_17\",\n              \"Q34_Part_1\", \"Q34_Part_2\",\"Q34_Part_3\", \"Q32_Part_12\", \"Q34_Part_4\", \"Q32_Part_12\", \"Q32_Part_11\",\n              \"Q34_Part_1\", \"Q34_Part_2\",\"Q34_Part_3\", \"Q32_Part_12\", \"Q34_Part_4\",  \"Q32_Part_12\", \"Q32_Part_11\",\n              \"Q29_Part_10\", \"Q29_Part_11\",\"Q29_Part_12\", \"Q29_Part_12\", \"Q29_Part_9\", \"Q30_Part_16\", \"Q30_Part_24\",\n                        \"Q29_Part_10\", \"Q29_Part_11\",\"Q29_Part_12\", \"Q29_Part_12\", \"Q29_Part_9\", \"Q30_Part_16\", \"Q30_Part_24\"], \n             [\"2021 Old\", \"2021 New\", \"2020 Old\", \"2020 New\", \"2019 Old\", \"2019 New\", \"2018 Old\", \"2018 New\"], \n             ['MySQL', 'PostgreSQL', 'SQLite', 'MongoDB', 'MS SQL', 'Snowflake', 'None'], \n             [d21_o, d21_y, d20_o, d20_y, d19_o, d19_y, d18_o, d18_y], 7)\n\nBDVsYear_o, BDVsYear_y = bifurcate_data(BDVsYear)\n\nnum_old_BD_ans_21 = BDVsYear_o[BDVsYear_o['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_BD_ans_21 = BDVsYear_y[BDVsYear_y['VarX'].isin([\"2021 New\"])]['VarY'].sum()\nnum_old_BD_ans_20 = BDVsYear_o[BDVsYear_o['VarX'].isin([\"2020 Old\"])]['VarY'].sum()\nnum_young_BD_ans_20 = BDVsYear_y[BDVsYear_y['VarX'].isin([\"2020 New\"])]['VarY'].sum()\nnum_old_BD_ans_19 = BDVsYear_o[BDVsYear_o['VarX'].isin([\"2019 Old\"])]['VarY'].sum()\nnum_young_BD_ans_19 = BDVsYear_y[BDVsYear_y['VarX'].isin([\"2019 New\"])]['VarY'].sum()\nnum_old_BD_ans_18 = BDVsYear_o[BDVsYear_o['VarX'].isin([\"2018 Old\"])]['VarY'].sum()\nnum_young_BD_ans_18 = BDVsYear_y[BDVsYear_y['VarX'].isin([\"2018 New\"])]['VarY'].sum()\n\nBDVsYear_o = pd.DataFrame(reformat_yearwise_rel(BDVsYear_o, {'2021 Old' : num_old_BD_ans_21, '2020 Old' : num_old_BD_ans_20, \n                                                             '2019 Old' : num_old_BD_ans_19, '2018 Old': num_old_BD_ans_18},\n                              '2021 Old') , columns = ['VarX', 'Mid', 'VarY'])\nBDVsYear_y = pd.DataFrame(reformat_yearwise_rel(BDVsYear_y, {'2021 New' : num_young_BD_ans_21, '2020 New' : num_young_BD_ans_20, \n                                                             '2019 New' : num_young_BD_ans_19, '2018 New': num_young_BD_ans_18},\n                              '2021 New'), columns = ['VarX', 'Mid', 'VarY'])\n\nBDVsYear_o = BDVsYear_o.loc[BDVsYear_o['Mid'] != 'MongoDB']\nBDVsYear_o = BDVsYear_o.loc[BDVsYear_o['Mid'] != 'Snowflake']\nBDVsYear_y = BDVsYear_y.loc[BDVsYear_y['Mid'] != 'MongoDB']\nBDVsYear_y = BDVsYear_y.loc[BDVsYear_y['Mid'] != 'Snowflake']\n\nfig = go.Figure()\nadd_many_traces(fig, BDVsYear_o.reindex(index=BDVsYear_o.index[::-1]), ['MySQL', 'PostgreSQL', 'SQLite', 'MS SQL', 'None'],\n                ['red', 'green', 'blue', 'black', 'yellow', 'grey', 'purple'])\nfig.update_layout(title_text = \"Big Data Tools Usage vs Time by Experienced Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\nfig = go.Figure()\nadd_many_traces(fig, BDVsYear_y.reindex(index=BDVsYear_y.index[::-1]),['MySQL', 'PostgreSQL', 'SQLite', 'MS SQL', 'None'], \n                ['red', 'green', 'blue', 'black', 'yellow', 'grey', 'purple'])\nfig.update_layout(title_text = \"Big Data Tools Usage vs Time by New Users\", legend = dict(x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Time (Years)',\n                 yaxis_title = 'Proportion of Users',)\nfig.show()\n\n\n\n\n","06374e9c":"# Business Intelligence Tools\n\nBI_2021 = multi_Y_data_MV([\"Q34_A_\", \"Q34_A_\"], ['Amazon QuickSight',\n'Microsoft Power BI',\n'Google Data Studio',\n'Looker',\n'Tableau',\n'Salesforce',\n'Einstein Analytics',\n'Qlik',\n'Domo',\n'TIBCO Spotfire',\n'Alteryx',\n'Sisense',\n'SAP Analytics Cloud',\n'Microsoft Azure Synapse',\n'Thoughtspot',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\nnum_old_BI_ans = BI_2021[BI_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\nnum_young_BI_ans = BI_2021[BI_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nBI_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], BI_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = BI_2021[BI_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = BI_2021[BI_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = BI_2021[BI_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = BI_2021[BI_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Business Intelligence Tools Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Business Intelligence Tools',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()\nnames_old_BI = get_question_index(\"Q35\", d21_o)\nnames_y_BI = get_question_index(\"Q35\", d21_y)\n\nBI_2021_Fav_old = Line_SV_2([\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\n                            \"Q35\",\"Q35\",\"Q35\",\"Q35\"],\n            names_old_BI,\n          names_old_BI, \n          [\"2021 Old\", \"2021 New\"], 11, \n          [d21_o[~d21_o[\"Q35\"].isin([np.nan])]])\n\nBI_2021_Fav_new = Line_SV_2([\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\n                            \"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\"Q35\",\n                            \"Q35\"],\n            names_y_BI,\n          names_y_BI, \n          [\"2021 New\"], 15, \n          [d21_y[~d21_y[\"Q35\"].isin([np.nan])]])\n\nBI_2021_Fav = pd.concat([BI_2021_Fav_old,BI_2021_Fav_new])\n\nBI_2021_Fav = conv_rel_2(BI_2021_Fav.to_numpy(), {'2021 Old' : num_old_BI_ans, '2020 Old' : 419, '2019 Old' : 183, '2018 Old': 465, \n                                       '2021 New' : num_young_BI_ans, '2020 New' : 9771, '2019 New' : 8947, '2018 New': 11179})\n                         #ident = ['2021 Old', '2021 New'])\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x = BI_2021_Fav[BI_2021_Fav['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = BI_2021_Fav[BI_2021_Fav['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = BI_2021_Fav[BI_2021_Fav['VarX'].isin(['2021 New'])]['Mid'],\n                     y = BI_2021_Fav[BI_2021_Fav['VarX'].isin(['2021 New'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Preferred Business Intelligence Tools in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Business Intelligence Tools',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()","e4d1cf7b":"# Deployment 2021\n\nDeploy_2021 = multi_Y_data_MV([\"Q39_\", \"Q39_\"], ['Plotly Dash',\n'Streamlit',\n'NBViewer',\n'GitHub',\n'Personal blog',\n'Kaggle',\n'Colab',\n'Shiny',\n'None',\n'Other'], \n                          get_var = False, data_list = [d21_o, d21_y], year_list = [\"2021 Old\", \"2021 Young\"], \n                       year_wise_skip = None,\n                  alternate_name = None, naming = None, has_other = True, cut_off = -1, reformat = False)\n\n#num_old_Deploy_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Old\"])]['VarY'].sum()\n#num_young_Deploy_ans = Experiments_2021[Experiments_2021['VarX'].isin([\"2021 Young\"])]['VarY'].sum()\n\n\nDeploy_2021 = conv_rel([\"2021 Old\", \"2021 Young\"], Deploy_2021)\nfig = go.Figure()\nfig.add_trace(go.Bar(x = Deploy_2021[Deploy_2021['VarX'].isin(['2021 Old'])]['Mid'],\n                     y = Deploy_2021[Deploy_2021['VarX'].isin(['2021 Old'])]['VarY'],\n                     hovertemplate = 'Old: %{y:.2f}<extra><\/extra>',\n                    name = 'Experienced'))\nfig.add_trace(go.Bar(x = Deploy_2021[Deploy_2021['VarX'].isin(['2021 Young'])]['Mid'],\n                     y = Deploy_2021[Deploy_2021['VarX'].isin(['2021 Young'])]['VarY'],\n                     hovertemplate = 'New: %{y:.2f}<extra><\/extra>',\n                     name = 'New',\n                    marker_color = 'red'))\n\n#fig = go.Figure(data = [go.bar(x = Lang2021['Mid'], y = Lang2021['VarY'], color = Lang2021['VarX'])])\nfig.update_layout(title_text = \"Deployment Platforms Used in 2021\", legend = dict(x=0.8,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n), paper_bgcolor='rgba(0,0,0,0)',\n    plot_bgcolor='rgba(0,0,0,0)',\n                 xaxis_title = 'Deployment Platform',\n                 yaxis_title = 'Proportion of Users')\nfig.update_layout(barmode='group', xaxis={'categoryorder':'total descending'})\n\n\nfig.show()\n","0a8b7673":"As in AutoML, we notice that significantly many new and experienced users both don't actually use this technology. However, it is clear that experienced users use this technology much more than new users:\n1. Tensorboard and MLflow are the favorites for experienced users. They are also very commonly used by new users, but experienced users use it proportionately much more.\n2. A reverse trend is seen here since the least common ML products are actually being used by new users more than experienced users. We were seeing the opposite before.\n3. This isn't a comprehensive list, since both groups use a few other tools (as indicated by the \"other\" bar)\n\nThis means that experiment management overall used more by experienced users. This may be because it is a more advanced topic.\n****\n\n**Look here buddy, you talked about so many software. Where do I learn about them when they come out?**\n\nMost people use specific sources to learn about the advancements in the Data Science field. Be it about algorithms, software tools, or even cool products.\n\nLet's take a peek into these sources","69c3237f":"The graph above shows very diverse sources. Let's start with the experienced users:\n1. Experienced users prefer to look at Kaggle, Blogs and Journals the most.\n2. They also look at YouTube but not as much. They also look at Email and Twitter\n3. This is not a comprehensive list because there are quite a few other sources not listed here for this group.\n\nOn the other hand for new users:\n4. Their main source for getting updates is Kaggle. This is proportionately much higher than for experienced group.\n5. This is closely followed by YouTube (higher than experienced) and then Blogs\n6. In stark contrast to veterans, they refer to very few journal publications\n\nThe 5,6th points is not surprising, but concerning. This shows a large difference between the two groups. The experienced group is able to learn more, and get to know about new developments in the field much quicker than new users. Why this is not surprising is because new users don't have the appropriate guidance to know how to read research papers quickly. On the other hand, YouTube is really easy to digest and watch. \nWhy this is concerning is because they are instead relying on sources such as YouTube that are completely unregulated. Although there are good sources maintained by trusted organizations, there are several channels that don't present accurate or complete information","d1ec14b7":"Wow... There are so many, where do I even start? Let's go from left to right\n\n1. MySQL is the most popular tool for new users, and experienced users. In fact, the usage of mySQL by new users is much higher than any other tool.\n2. PostgreSQL is another popular tool. It is slightly more popular for experienced users.\n3. In the graph there aren't any large disparities between experienced and new users except for in MySQL\n4. Surprisingly, many people don't actually use any Big Data Tools - This is moreso for new users.\n5. MS SQL, MongoDB, and SQLite are popular and hold approximately equal market share.\n\nIn terms of preferences:\n6. MYSQL ranks in first for both groups. There is a large margin here for the new users in fact.\n7. PostgreSQL is also prefered by experienced users, and is almost the same as the preference level of MySQL.\n\nThis tells us that other than MySQL, the market is pretty evenly shared. Despite PostgreSQL having a smaller market share, it has an approximately equal liking as MySQL. This means it may be better to try PostgreSQL than MySQL.\n\nAlthough MongoDB has a lot of market share, I will not analyze it due to the lack of past data","64596f94":"In the two graphs above we see the same alarming trend repeat itself:\n\n1. YouTube is remaining constant for both groups\n2. Journals and Blogs are greatly decreasing in usage.\n3. Course Forums and Kaggle are also losing users\n\nThis means that at a relative scale, Youtube is becoming more popular. This is quite alarming because there can be a lot of misinformation on YouTube. Whereas, journals are accurate and peer reviewed.\n\nOn a more positive note, this means that to obtain more traction over time, YouTube may be a good solution.\n\n****","917a27a9":"Before you read further, it is important to understand how the proportions were taken specifically here. This question was asked to only \"Professionals\" which excluded a large segment of both groups. As a result, I re-normalized based on the number of people that were asked this question. This was done elsewhere, and has been clearly explained where.\n\nTo me, it was surprising that experienced people use AutoML much more than new users!\n1. Most new users do not use any AutoML techniques\n2. Many experienced users also don't use any AutoML techniques, but it is proportionately much less\n3. The most used feature by experienced users is Hyperparameter tuning\n4. As a whole, model selection is used the most by both groups (when we consider the groups overall)\n5. These actually constitute most of the tasks done in AutoML, as the other tasks are negligible in proportion.\n\nWe can ask ourselves, has the demand for these products increased over time?","d9465297":"We see that the number of people using absolutely no notebook is decreasing over time for both groups. I.e., we see that people are using Notebooks more often. \n1. The fastest rise in % of users is for Colab in both categories\n2. For experienced users, the % of them using Kaggle has remained almost constant\n3. For new users on the other hand, they are using Kaggle Notebooks a lot more as time progresses, although the rate of change is not too steep.\n4. I graphed MS Azure also to sample the other notebooks. I noticed that it's user % is decreasing over time for both groups, but at a very slow rate.\n\nThis tells us that Colab will rise in nuumbers in the next few years. Moreover, it may be a good decision to shift to Colab notebooks, as more experienced users are preferring to use it themselves. This is a positive trend that New users are following in their footsteps. Despite this competition, the fact that Kaggle books are almost constant for experienced users indicates that they may also be a good choice for new users. \n****\n**Notebooks often come with TPUs. What about those?**\n\nWell, let's actually take a look at how often TPUs are used in today's time. Note that TPUs are called Tensor Processing Units.\n\n\n","0b091555":"**How We will Analyze the Data**\n\nFirstly I will present a graph of how the users are using the chosen technology in 2021. I will bring attention to the main points of focus and explain them. Here, I will plot the market *share* of users.\nThe data plotted will be relative numbers, i.e., of all the people in the dataset in our groups, what percentage of them used this tool, etc.\n\nI will then focus on these tools\/products, and how they evolved over time. These are also relative.\n\nI took relative numbers to accomodate the different number of survey takers each year. Moreover, the number of Experienced users is far less than the New users. So this makes it easier to analyze between these classes. Additionally it helps us analyze the data from some questions that were not asked to certain groups (such as non-professionals)\n\n*Note: Certain tools and products were not available in the previous Surveys as Options. They may still be prominent features of the 2021 graph. I will unfortunately not analyze these in past years, but I will clearly indicate when they occur*\n\nCertainly, there will also be some rare exceptions.","5a640d6f":"This is a very untapped market. It's clear that most users in both groups don't use any Managed ML.\n\n1. For each platform, more experienced users use them.\n2. There are many more new users that don't use any platform that nexperienced users\n3. Of the platforms used, Amazon SageMaker, Azure, Databricks and Google are in a large lead.\n4. Proportionately, there is a large gap between experienced and new users for Rapidminer and Dataiku - meaning that new users may have not discovered them yet.\n\n****\n**Sadly, Managed ML isn't too hot right now. You know what is? Big Data!**\n\nYes, for the past few years, Data Science, ML and Big Data have been synonymous. Let's study the progress in Big Data Tools over time. But first, what is its current state in 2021?","a7c45a9b":"In the graph above, we definitely see that the space is dominated by: Scikit-learn, TensorFlow, Keras, Xgboost and Pytorch.\nSo, there is a large variety of options, each holding a substantial share of the market in ML Frameworks. Moreover:\n\n1. More new members use Scikit-learn, Tensorflow and Keras than Experienced users proportionately. Although, the disparity for Scikit-learn is the quite large and is the largest of the 3. But note that this is market share, this difference is most likely because experienced users use multiple frameworks as seen above.\n2. On the other hand, Xgboost and PyTorch are preferred by Veteran users very slightly more.\n3. It is more common for Experienced users to use relatively uncommon frameworks, which means that they are more likely to learn and use multiple frameworks as compared to new users\n4. New Users are more likely to not use any framework than veterans.\n\nPoint 3 tells us that almost all the popular frameworks gain considerable traction from experienced users. It is hence likely to continue this way, meaning that as the new users gain experience, they will look at more frameworks.\n\nLet's now plot some trends for the most popular frameworks and identify patterns. This time, I will highlight all the frameworks as there is a pattern in each one, and they are easy to distinguish.","f317270d":"Surprisingly, we notice that the usage of advanced statistics software has declined for both groups. \nMoreover:\n1. The use of basic statistics software has risen greatly for both pools.\n2. For experienced users, development environments have slightly decreased, but for new users, it has decreased over time significantly.\n3. For experienced users, the use of cloud and other software have also declined a little bit.\n\nBecause experienced users are moving towards basic statistics software, it may be possible that these software are actually more useful in the long run, and provide more applications in daily life. This can be infered because the experienced users are likely to have used most of the types of software, before deciding to use this software most frequenctly. If that is the case, then it is a good trend that new users are also following the old users by also using basic software more often (but it's more likely to be that it's easier to use)","c3e4f0a1":"We see that the % of users using Python has been increasing over time for new practitioners, whereas it is more or less constant for experienced practioners. Moreover, the % of users using Python is very high. On the other hand, the % of users using MATLAB and R has slightly decreased over time for both groups. Particularly, R has had the largest decrease in users for the new practitioners.\n\nSince Experienced users are also stopping to use R, it may be that they find the features of Python more attractive (such as the powerful ML libraries). (Sorry for the tough love R!). The same situation is being seen for MATLAB.\n\nUnless R and MATLAB get such libraries for ML, Python will only increase it's share over time as the trend indicates.\n\n\n\n*Hopefully, you are now accustomed to the analysis style. Let's dive deeper*","65114844":"Notice that most people have still not used TPUs ever in both groups. But we see that:\n1. The % of people that never used TPUs is decreasing every year for both groups. The rate of decrease is also approximately the same\n2. The % of people that have just started using TPUs (2-5 times) is increasing for both groups at similar rates.\n3. The rate of increase of usage of at the highest level (> 25) is very slow for both new and experienced users. In fact, it is pretty negligible.\n\nThe 2nd point, indicates that people are exploring TPUs quite openly, as they do try it more than once. However, there are 2 possibilities for the 3rd point for experienced users -\nFirstly, they may not find it particularly useful, so they stop using it after their initial experimentation.\nAlternatively, they may not be doint enough projects per year using TPUs so that they go from the 2-5 category to >25 category.\n\nThe second explanation certainly holds for the New users, because after 3 years (even if they do enough projects) they move into the group of 3-10 year experienced users. This is certainly a drawback of the grouping used in the analysis. Nevertheless, we learn 2 possible things from this:\n - The frequency with which TPUs are used by either group is not very high in projects (or that the projects themselves are long)\n OR\n - Both groups do not find practical use for TPUs after some tries.\n \n Although, the second possibility is less likely, because TPUs are said to increase performance by 100 times as compared to CPU.","ac637ee1":"I have plotted 2 graphs above - One about the market share, and 1 about the preferences in products\n\n1. AWS, GCP and Azure have the most share.\n2. For almost all Cloud Computing platforms, we see that experienced users use them much more than new users.\n3. A significant amount of users from both groups don't use cloud computing at all. But, the new users mostly don't use any cloud computing platform at all.\n\nBefore I talk about the preferences, note that most people didn't actually even answer this question. Hence, the proportions may not add up to 1.\n\n4. Unsurprisingly, most people prefer AWS and GCP, but shockingly, a significant amount of people said that they had a similar dev experience. This amount was in fact larger than the popularity for MS Azure.\n5. A considerable amount of experienced users stated that none of them were satisfactory.","2c2da35e":"Of the tools in the survey, we see that Google Cloud AutoML is used the most by both groups, with a significant increase for new users. For these specific tools, it seems as though experienced users don't use them. It means that the experienced users use alternative tools, as also indicated by the relatively large \"other\" bar. Nevertheless, for experienced users, the market share for all the tools is approximately the same.\n\n**Ok, I've made something. I want to experiment with it to improve it - Experimentation**\n\nTo manage our experiments, there have been many tools in the market. Let's look at some of them:","561c68a1":"The most common platform is Coursera overall. For new users, Kaggle Learn is the most popular platform.\n\n1. Experienced users had used coursera in the past.\n2. They also relied heavily on university courses.\n3. On the other hand new users rely on Kaggle Learn, Coursera, and Udemy the most.\n4. Many more old users have \"no\" education as compared to the new users\n","3c1d5cbb":"From the graph, we see that the proportion (here it is simply % because the classes are mutually exclusive) of users that have never used TPUs is pretty high. This may be because of 2 reasons - TPUs are an advanced technology that most people don't have access to in person, and TPUs are specialized for Tensorflow - Google's special ML Framework. Not everyone uses Tensorflow, and so may not use TPUs either (we'll see this later :)). But, we also observe the following:\n\n1. The proportion of people that have never used TPUs is more for new users than experienced users.\n2. The number of experienced users that have used TPUs more than 6 times is proportionately higher than that of new users","02bbfd24":"We notice that Development Environments are the most popular tool overall. For experienced users it is largely the most used type of platform. On the other hand, for new users, Basic Statistics Software such as MS Excel are the most popular.\n\n1. Development environments are still very common among new users, but much less than for experienced users\n2. Advanced statistics software and cloud tools are more popular among experienced users than for new users\n\nThis allows us to infer that new users use ML applications for relatively simple tasks, since they use basic statistics software. On the other hand, experienced users use similar tools, but they focus more on development of software since they use development environments the most.","7fb71d6a":"Over time, we see that the number of people not using AutoML in new users has increased, whereas it has remained approximately constant for experienced users.\n\n1. For experienced users, between 2019 and 2021, we see that the uses of AutoML have remained approximately constant. Hyperparameter tuning applications have increased, but at the same time, use of feature engineering and model selection have slightly decreased (basically offsetting the increase).\n2. For new users, all the uses have decreased in demand.\n\nThis is a negative trend for AutoML, as it indicates, that newer users aren't using this technology, and it's demand is decreasing over time. For experienced users, we only see a shift in their type of demands, but the overall usage is constant.\n\n**Let's now check the Specific Software**","72372ded":"****\n**First Things First - Programming Languages**\n\nHow can we start without looking at how the usage of Programming Languages has evolved over time?\n\nIn 2021, the following graph illustrates the *share* of users of ML.","fee0eef7":"**It's Aliveee!!! - Deployment**\n\nHuff... We've come so far... You're probably tired of just Window shopping and now want to actually get stuff. Don't worry, we're almost there :D\n\nEven if you made an amazing product. If you want to share it with the world, or set up your own shop in the market, you'll need to deploy this.\n\nLet's check Deployment:","b91e159b":"****\n**To Summarize**\n\n- We have gone through the entire market, and looked at its various shops and owners\n- Some shops were niche, like Business Intelligence, while others were used by everyone such as Education\n- Most places had 1-2 guys with monopoly, but some places where much more open and had much more competition!\n- By the time we reached the end of the market, we have a good idea about how the market is today, and how it came about to be. We even have a small idea about the future\n\n:D\n\nIf you enjoyed this notebook, please upvote it!\n\nAnd if you want to have fun, feel free to guess my category (new\/experienced) in the comment section!","3953928f":"****\n**Who are Experienced and New Practitioners?**\n\nBefore proceeding, it is important to note, what I constituted \"Experienced\" and \"New\" practitioners to be. I chose \"New\" Practitioners to be coders who have less than 3 years of *Machine Learning Experience* and the *Experienced Group* are the set of people with more than 10 years of experience.\n\nWhy did I choose this metric? Well, I had narrowed down two other options - Salary, Coding. \n\nLet me explain why I didn't choose these for my analysis (they may be good for others). First of all, Salary is not well suited to our purpose. We wish to analuze the previous and current generation of ML practioners. However, in some rare instances, we do have younger practitioners earning a high salary, which would club them in the same group as older practitioners. This certainly would not be helpful to our analysis.\nCoding experience is another invalid metric because a coder with 20 years of Full Stack Experience who has just transitioned to Machine Learning is *still in the new generation of ML coders* but will be counted in the older generation. \nClearly, these metrics will present discrepancies.\n\nNow, why 3 and 10? Well, I didn't want to choose an extremely small group. Besides, in the world of computing, even 10 years is a large number!","e6727793":"But, as before, we do want to know how the usage of TPUs is changing over time in the 2 different categories. Let's plot this. However, I noticed that it is a bit difficult to read the graph, so I only highlighted the key features in color. To read about the other lines, please hover over them to see more.","dab2fd78":"****\n**What about the IDEs?**\n\nWe know how the programming languages have changed over time, but what about the IDEs on which they are coded in?\n\nLet's plot their share of users in 2021","b4e6690b":"Year on year, the most striking development is that the number of people using NO cloud computing platform has significantly decreased over time.\n\n1. The user base for AWS has slightly decreased in the experienced pool, and has remaind about constant for the new group.\n2. Google and Azure platforms have increased significantly in both groups.\n\nThis tells us that the market share of GCP and Azure is increasing quite a bit. We can infer that the people that previously did not use any cloud computing might be shifting to these platforms.\n****\n\n**Speaking of Cloud Computing, what about Managed Machine Learning?**\n\nUnfortunately, there wasn't enough data to do a trend analysis of this over time, but let's look at this in 2021:","3c707e23":"Now that we have a bit of an overview, we should try to get a bit more information about the 2 groups that will help us in our ensuing analysis.\n****\n**Expenditure On ML**\n\nWe already looked at how data analysis tools are used by each group at a high level. Before moving ahead, we should analyze how the different groups spend money on different products. This will tell us if we made a good decision in forming our categories as well...","be647366":"# The Market - The Story of Data Science Products\nBy Aaryam Sharma\n\nThe Market is a metaphor for the collection of sites on the internet that provide us tools, data and knowledge to conduct our Data Science jobs! The Market is marvelous for sure - because this notebook is practically in this same Market because it's providing data and knowledge!!!\n\nThis notebook is a journey into this market (that sometimes gives free stuff like Kaggle :D) of technological tools and innovations that surrounds the world of Data Science through the lens of experienced and new machine learning practitioners.\n\nTogether, we will analyze how the market is shaped today, and how it has come to this point by looking at some past years data.\n****\n\n**Why I Should I Read This Notebook?**\n\nFirstly, if you are new to ML, then this Notebook is very helpful for you. You will learn about the several different tools available at your disposal, and also learn about who uses what. This can help you choose which tool to learn about and add to your own repertoire.\n\nEven if you are experienced and know about ML tools, this notebook will be very helpful for you. Here, you will be able to look at how the market has changed over time - something developers will find especially useful. Moreover, you will get to know about how other people are using ML tools across the globe - so you understand about a more global market!\n****\n\n**Motivation Of This Topic**\n\nThe objective of this data science competition is to identify and present several insights into the data provided by this survey. I noticed that how sparingly the market of products surrounding machine learning has been analyzed. Moreover, these analyses seldom relate the present and past data in conjunction to generate information about the potential changes in the future market. I decided to present insights into this topic, to help programmers understand the direction the user-base has taken in terms of using Data Science based tools and software.\n\nAdditionally, I decided to compare 2 distict groups - Experienced and New practitioners, because they reflect the market in the previous and current generation respectively. Furthermore, in this notebook, I will use these statistics to explain whether these trends are beneficial or are harmful to the Data Science world.\n\n****","9a15381f":"We see that Matplotlib and Seaborn have most of the market share.\nHowever, Plotly and Ggplot are not too far behind.\n\n1. We see that experienced users often use plotly and ggplot more often.\n2. New users use Matplotlib and Seaborn much more than older users\n3. Experienced users have many more visualization library knowledge, because hey use more uncommon libraries proportionately more than new users.","a13d9d91":"Observe that in each graph Scikit-learn has the most number of users. We also see that:\n1. The % of users of sk-learn has remained approximately constant in both groups.\n2. On the other hadn % of tensorflow, keras has been slowly decreasing in both groups.\n3. In the experienced pool, the % of pytorch and xgboost users has increased rapidly. On the other hand, for new users, Xgboost has very slightly declined and PyTorch has increased but not as much as for experienced users\n4. LightBGM has remained approximately constant for new users, but has increased significantly for veterans.\n5. The number of people using no framework has slightly increased for new members, but has decreased for older members -significantly\n\nPoint 3 is a positive trend for PyTorch, since it shows that experienced users are liking it more and more, and this news has reached new members. This is good because new members are learning from the experienced members, showing development in the field.\n\nOn the other hand, 4 is negative because new users are not realizing the same advantages of LightGBM that advanced users are. Similarly, 5 shows that ML frameworks must be useful because veterans are shifting towards them, but new users are drifting away slowly. However, this increase is very slight, and may not be indicative of a lack of future market.\n\n****\n**Let's go one step further - Let's not help, let's automate - AutoML**\n\nAutoML tools help completely automate certain aspects of ML programming. These tools may only partially automate, or they may fully automate. \n\nLet us first understand what tasks AutoML helps us with the most\n","fa4eb1f3":"Over time, the number of people not using Big Data tools has decreased. We also see that:\n1. For experienced users, MySQL has been approximately constant, whereas for new users it has increased significantly.\n2. Microsoft SQL has been losing users very sharply.\n3. PostgreSQL has increased very slightly in both groups\n\nSince we see that the people using Big Data has been increasing sharply (seen from the 'none' line), but MySQL, PostgreSQL, etc. as graphed above have either decreased, remained constant or only slightly increased, we can infer that other Big Data Tools are gaining more traction in recent times. I.e., the market share is equalizing.\n\n****\n**What rhymes with Big? Bi-...-Business! (It Really Doesn't)**\n\nNow that we've explored Big Data, let's look at Business intelligence platforms\n","a3b451c2":"**You discussed so much about ML. I even know where to get information. What about me, I like graphing?**\n\nSeeing is Believing!\n\nWe looked at notebooks, frameworks, AutoML and so on, but another key item that most data scientists use is visualization. In fact, I'm using it right now!\n\nLet's check the current visualization libraries","2e4fdf1a":"****\n**Hold On! Did you say Tensorflow?**\n\nIn the field of Data Science, ML Frameworks have expanded greatly, and many people are using them quite often - even those people with little experience with ML. This has widened access to the field. It is natural to check the market share of the several ML Frameworks out there\n","b7535af7":"Business intelligence is one of those tools that most people don't use unless they are actually in a Business. The survey takers have come from a wide variety of industries, so it is unlikely that they use these tools.\n\nNevertheless, we observe the following:\n1. The largest proportion of people in both groups don't actually use Business Intelligence Tools.\n2. Surprisingly, experienced users use these tools less than new users.\n3. Tableau and MS Power BI have the largest market share for both groups. Other than this, we notice that the other platforms have approximately equal market share.\n4. New users use Tableau, MS Power BI and Google Data Studio proportionately more than veterans.\n5. Veterans on the other hand use more uncommon tools. This is a very common trend we have been seeing.\n\n6. Microsoft Power BI is the most preferred tool in both groups. It surpasse Tableau despite having slightly less market share for new users. This may mean that it is a better tool as its users are more satisfied with it.\n\n****\n\n\n","02d2daba":"We notice that there is a sudden spike in the number of Vim Users in both categories in recent times. \nOn average, Visual Studio and Jupyter Lab have been constant in % of users.\nRStudio has been steadily declining in recent years\n\nFor new users, there has been a large fall in Jupyter Lab usage. This is most likely a statistical discrepancy, as it is certainly an outlier.\n\n****\n\n**Seeing that Notebooks are Very Popular, which Notebook is the most common?**\n\nLet's now see how the notebook platforms have changed their number of users.","07e41449":"Firstly, notice that the experienced users denoted by \"Old\", for \"Old users\" have proportionately spent more money on ML products than the new users. This is best illustrated where we see that the first 3 bars of the last 3 categories are much higher than those for the other 3 bars (new users). This means that new users don't spend as much on ML than their experienced counter-parts.\n\nThis implies that Experienced users will most likely have experimented with different products, implying that the tools they currently use, are most likely the optimal tools as per their knowledge and practice.\nThis reinforces the choice of using ML Experience as our differentiating metric.\n****\n**Education**\n\nLastly, before looking at the market, let's look at what education platforms our buyers and sellers have used. This will help us get a full backdrop on why they use the products they do.","6c704b2b":"In the data above, we see that most of the grey lines are actually decreasing in usage over time.\nOn the other hand:\n1. University education has increased significantly for both groups.\n2. For new users, kaggle has had the largest increase as an education platform.\n3. Coursera has remained almost constant for experienced users, but has declined significantly for new users\n4. Udemy has remained almost constant for both groups and maintained a significant share of the education market","d33a5593":"Unsurprisingly, we notice that Jupyter Notebook is the most used platform by both groups, but unsurprisingly, the newer generation uses it more often. We also notice some other features:\n\n1. VS Code and PyCharm are much more popular in newer users than they are for the older generation.\n2. RStudio is more popular for the Experienced users. But, this is in accordance with what we fould out for the language R. It only makes sense that it's IDE is less used if the language is less used by newer users. (But I used RStudio :O)\n3. Vim is much more popular among Experienced users. It's because it was released during the time they started out, so they are more used to it.\n4. There are very few people that actually don't use an IDE.\n\nLet's focus on Jupyter lab Products, RStudio, Visual Studio and Vim have changed over time as these are the prominent distinctions","1373db62":"The graphs above reflect very similar data as the bar chart did. However, notice that:\n1. The % of experienced users using Matplotlib and Seaborn has increased significantly over time. These libraries have also increased for new users, but at a much smaller level\n2. % Users of shiny, ggplot has been declining quite a bit for both groups\n3. On average, plotly and no library users have been constant for both groups\n\nThis tells us that Matplotlib and Seaborn's market share will increase greatly for experienced users in the future, and slightly for new users. On the other hand, libraries such as ggplot and shiny are declining in popularity.\n\nThe fact that both groups show similar trends means that new users are learning from experienced users, implying that the field is progressing, as there is communication between the two types, and they are discovering the same benefits in each software.\n\n****\n\n**Ok ok, we get it. But I've heard that people also use Cloud Services**\n\nAnother emerging market is cloud computing in machine learning. \nBut here, it get's a bit tricky. Firstly, not all people were asked this question. From analyzing the spending, we saw that mostly new members weren't asked this question. So, because we're analyzing market share, let's only focus on the people that were considered professionals by the survey.\n\nLet's check this out:","07efa5da":"By far, GitHub is everyone's favorite platform to deploy their products on. But a large subset of people don't deploy their application anywhere. \n\n1. More experienced users don't upload their products anywhere. But this gap is only a slight gap.\n2. Kaggle is the next most common deployment platform for both groups. It is twice as popular for new users than it is for experienced users.\n3. Google Colab is also quite popular with both.\n4. The other options such as Personal blogs, Shiny, Plotyl Dash, etc. are very popular with the veterans.\n\nWe can guess that veterans code some cool stuff. Maybe they already have the recognition they deserve, which is why they post it on more private sources such as blogs. On the other hand, new users are just starting out, so they want as much recognition as possible and the ability to transmit their products quickly. Hence, their choice for kaggle and github.","19ee1d1d":"**An Overview**\n\nLet's use the data about the type of tools that are used by the survey responders to understand what categories our two groups are at a superficial level. In particular, we'll look at the primary tool they use to analyze data","af600975":"**Let The Numbers Rain Down**\n\nLet's start by counting how many people each group has per year. You may check the above cell to notice that the number of users in each group from 2018 to 2021 are:\n\n2021 - Experienced: 573 New Users: 13838\n\n2020 - Experienced: 419 New Users: 9771\n\n2019 - Experienced: 183 New Users: 8947\n\n2018 - Experienced: 465 New Users: 11179\n\n****","0c25b2bc":"The space of notebooks has been dominated by Google Colab and Kaggle for both categories. We also however, see that many people don't use any notebooks (this was seen because we already saw in the previous data, that there are many people that don't use notebooks). Other features we observe:\n\n1. Kaggle Notebooks are much more common for newer users.\n2. Colab Notebooks are more common for newer users, but the difference is much smaller than Kaggle Notebooks\n3. Many more experienced users use NO notebook at all, than inexperienced users.\n4. All Other notebooks are used much less than Kaggle and Colab.\n\nBut, how has this composition changed over time? Is Colab gaining pace or is Kaggle?","6ddbb934":"In this graph, there are 5 key observations:\n\n1. Python has the most number of users in both classes. We notice that the Newer users are using Python Proportionately more than they are using other languages. This is most likely because Experienced users also know many other languages which most likely decreases the relative proportion of Python Users.\n2. There are Proportionately more users using R that are more experienced than the present users. In fact proportionatley, twice the number of users know R that are Experienced than are New\n3. Experienced users are proportionately more profficient in MATLAB than the newer users. We can infer this because the bar for MATLAB is 3.5 times taller for Experienced users than it is for new users.\n4. The highlighted languages represent the majority of languages that ML practicitioners use for Experienced and Inexperienced users, since the bar for \"Other\" languages is negligible (shows 0.00 here, but it's non zero)\n5. There are some people on both sides that do not use any Programming Language. It may be because they are using Statistics software such as Excel. More shockingly, there are more experienced users in this category than new users. It is a positive trend because it shows us that more programmers are learning coding languages.\n\nLet's now plot the trend in programming languages for MATLAB, Python and R over time:"}}