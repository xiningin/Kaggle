{"cell_type":{"e182a13c":"code","5f41cec5":"code","67c534c3":"code","7a6a557f":"code","bf8ad020":"code","168f3b10":"code","29164c89":"code","7442af93":"code","3b2486b7":"code","99f942f7":"code","fc3db1e1":"code","8af5cb79":"code","741f1878":"code","a90cf788":"code","5a74f4d5":"code","b4147fa7":"code","4f1dd736":"code","7f526e36":"code","f3017d81":"code","953bcf47":"markdown","bec60669":"markdown","02875e33":"markdown","3e29c989":"markdown","dcc15cb8":"markdown","37a316f6":"markdown","6dfb7afc":"markdown","13a24147":"markdown","44ab9704":"markdown","5cb2a558":"markdown","ef417c6a":"markdown","df99adde":"markdown","7264d8bc":"markdown","bb3039c0":"markdown","d9696a8d":"markdown","a31583d4":"markdown","5e53a1a9":"markdown","108aaf8e":"markdown"},"source":{"e182a13c":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom scipy import spatial\nfrom random import randint\nfrom IPython.display import SVG\nimport matplotlib.pyplot as plot\nfrom sklearn.utils import shuffle\nimport matplotlib.gridspec as gridspec\nimport tensorflow.keras.utils as Utils\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.metrics as Metrics\nfrom sklearn.neighbors import NearestNeighbors\nfrom keras.utils.vis_utils import model_to_dot\nimport tensorflow.keras.optimizers as Optimizer\nfrom sklearn.metrics import confusion_matrix as CM\nimport tensorflow.keras.activations as Actications\nfrom sklearn.metrics import classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","5f41cec5":"def get_images(directory):\n    Images = []\n    Labels = []\n    label = 0\n    \n    for labels in os.listdir(directory):\n        if labels == 'cats':\n            label = 0\n        elif labels == 'dogs':\n            label = 1\n        \n        for image_file in os.listdir(directory+labels):\n            image = cv2.imread(directory+labels+r'\/'+image_file)\n            image = cv2.resize(image,(150,150)) \n            Images.append(image)\n            Labels.append(label)\n    \n    return shuffle(Images,Labels,random_state=123)\n\ndef get_classlabel(class_code):\n    labels = {0:'cats', 1:'dogs'}\n    return labels[class_code]","67c534c3":"Images, Labels = get_images('..\/input\/dogs-cats-images\/dataset\/training_set\/')\n\nImages = np.array(Images)\nLabels = np.array(Labels)\n\nImages.shape, Labels.shape","7a6a557f":"f,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(5):\n    for j in range(5):\n        rnd_number = randint(0,len(Images))\n        ax[i,j].imshow(Images[rnd_number])\n        ax[i,j].set_title(get_classlabel(Labels[rnd_number]))\n        ax[i,j].axis('off')","bf8ad020":"inp = tf.keras.layers.Input(shape = (150, 150, 3), name = 'inp')\nx = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top = False)(inp)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\noutput = tf.keras.layers.Softmax(dtype='float32')(x)\nmodel = tf.keras.models.Model(inputs = [inp], outputs = [output])","168f3b10":"embeddings = model.predict(Images)\nembeddings = pd.DataFrame(embeddings)\n\nembeddings.shape","29164c89":"ref_index = 5\nplot.imshow(Images[ref_index])","7442af93":"filetered_indexes = []\nthreshold = 0.91\n\nfor i in range(len(embeddings)):\n    if i==ref_index:\n        continue\n    cosine_similarity = 1-spatial.distance.cosine(embeddings.iloc[i,:].values.reshape(1,-1), embeddings.iloc[ref_index,:].values.reshape(1,-1))\n    if cosine_similarity <= threshold:\n        filetered_indexes.append(i)\n        \nlen(filetered_indexes), len(embeddings)","3b2486b7":"embeddings['label'] = Labels\nfiltered_embeddings = embeddings.iloc[filetered_indexes, :]","99f942f7":"cols = list(embeddings.columns)\ncols.remove('label')","fc3db1e1":"X_train, X_test, y_train, y_test = train_test_split(embeddings[cols], embeddings['label'], test_size=0.2, stratify=embeddings['label'], random_state=42)\n\nclassifier = LogisticRegression()\nclassifier.fit(X_train,y_train)\npreds = classifier.predict(X_test)\nprint(classification_report(y_test,preds))","8af5cb79":"X_train, X_test, y_train, y_test = train_test_split(filtered_embeddings[cols], filtered_embeddings['label'], test_size=0.2, stratify=filtered_embeddings['label'], random_state=42)\n\nclassifier = LogisticRegression()\nclassifier.fit(X_train,y_train)\npreds = classifier.predict(X_test)\nprint(classification_report(y_test,preds))","741f1878":"del embeddings['label']\nmodel_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\nmodel_knn.fit(embeddings)\ndistances, indices = model_knn.kneighbors(embeddings.iloc[ref_index,:].values.reshape(1,-1), n_neighbors = 25)","a90cf788":"image = [ref_index]\ndistance = [0]\n\nfor i in range(0, len(distances.flatten())):\n    if i != 0:\n        image.append(embeddings.index[indices.flatten()[i]])\n        distance.append(distances.flatten()[i])","5a74f4d5":"initial_dist = []\nfinal_dist = []","b4147fa7":"index = 0\nf,ax = plot.subplots(5,5) \nf.subplots_adjust(0,0,3,3)\nfor i in range(5):\n    for j in range(5):\n        rnd_number = randint(0,len(Images))\n        ax[i,j].imshow(Images[image[index]])\n        initial_dist.append(1 - distance[index])\n        ax[i,j].set_title(1 - distance[index])\n        ax[i,j].axis('off')\n        index+=1","4f1dd736":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rotation_range=45,\n                            zoom_range=0.15,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.15,\n                            horizontal_flip=True,\n                            fill_mode=\"nearest\")\n\ndatagen.fit(Images)","7f526e36":"index = 0\nf,ax = plot.subplots(5,5)\nf.subplots_adjust(0,0,3,3)\n\nfor i in range(5):\n    for j in range(5):\n        it = datagen.flow(Images[image[index]].reshape((1,) + Images[image[index]].shape), batch_size=1)\n        augm = model.predict(it.next())\n        cosine_similarity = spatial.distance.cosine(augm, embeddings.iloc[ref_index,:].values.reshape(1,-1))\n        ax[i,j].imshow(it.next()[0].astype('uint8'))\n        final_dist.append(1 - cosine_similarity)\n        ax[i,j].set_title(1 - cosine_similarity)\n        ax[i,j].axis('off')\n        index+=1","f3017d81":"initial_dist = np.reshape(np.array(initial_dist), (5, 5))\nfinal_dist = np.reshape(np.array(final_dist), (5, 5))\n\nfig, ((ax1, ax2)) = plot.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\nax1.imshow(initial_dist, cmap='hot', interpolation='nearest')\nax1.set_title('Initial Correlation')\nax2.imshow(final_dist, cmap='hot', interpolation='nearest')\nax2.set_title('Correlation after Augmentation')\nplot.show()","953bcf47":"## Initial Image Correlations","bec60669":"## Finding similar images based on Cosine Distances","02875e33":"Here, I have used cosine similarity to compare image embeddings. Instead of filtering all the images, I have filtered only the images that are similar to the reference image.","3e29c989":"# My Suggestions","dcc15cb8":"## Observation\nIn the above shown tests, We removed 84 images similar to the reference image of a cat. On training the resulting dataset, We observe that the overall accuracy of the model decreases from 95 to 91 by removing these images, But the precision of the cat class has increased from 96 to 99. Precision of dog class also decreases from 94 to 86 (that is most likely due to removal some dog images).","37a316f6":"## Visualize Images in the Dataset","6dfb7afc":"## Observations\nAfter applying some basic image augmentations, We observe that the cosine similarity between images decrease which suggests us that the correlation between images can also be decreased by applying augmentations.","13a24147":"## Comparing Correlations","44ab9704":"## Generating Image Embeddings (Using pretrained EffnetB0)","5cb2a558":"## Importing Dataset","ef417c6a":"## Results on Filtered Embeddings","df99adde":"## Reference Image","7264d8bc":"## Results on Original Embeddings","bb3039c0":"## Proposed Approach\nThe given paper considers a bias reduction algorithm AFLITE. This algorithm filters out the dataset while retaining the identical train-test distribution. This not only helps the model generalize better but also reduces the training time. Although theoretically, this seems a great approach as it helps the model learn the less dominant features better, the results show that there is a decrease in the performance on various datasets. I think that is most likely because the distribution of the data in the training and testing dataset is quite similar. This means that the features that are dominant in the training dataset were also dominant in the testing dataset, So if the priority of these features is decreased, the performance degrades as well. But I think this approach will work well for the datasets which have different distributions in the training and testing which is common in real-life datasets. Also, the model trained using this approach will most likely be able to perform better on data that do not have the dominant features. This approach also helps in maintaining the bias-variance tradeoff as it makes the dataset more challenging to learn and forces the model to develop an understanding of complex features. According to the paper, this filtering method was able to remove synthetic data as well. They tested this approach with various datasets including image classification and NLP datasets and it resets the benchmark scores for these datasets as it filters out spurious biases in these datasets.","d9696a8d":"# Implementing Paper's Approach\n\nName: Adversarial Filters of Dataset Biases\n\nLink: https:\/\/arxiv.org\/abs\/2002.04108","a31583d4":"Here, We can see that the filtered embeddings has 98.9% size of original embeddings.","5e53a1a9":"## Creating Filtered dataset of Embeddings","108aaf8e":"## Image Correlations after applying Basic Augmentations"}}