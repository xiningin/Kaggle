{"cell_type":{"8db56543":"code","024e8e94":"code","e85fcbe8":"code","811e2206":"code","e98d6057":"code","27a151e7":"code","80762630":"code","6c85b9ee":"code","9abdf2f3":"code","1971bf2c":"code","13ca80e4":"code","931d583d":"code","b90b730d":"code","898393b8":"markdown","78461237":"markdown"},"source":{"8db56543":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","024e8e94":"df = pd.read_excel('\/kaggle\/input\/convid\/Mpro full XChem screen - experiment summary - ver-2020-03-25-annotated.xlsx')\ndf = df[df[\"RefinementOutcome\"].isin([\"7 - Analysed & Rejected\",\"6 - Deposited\"])]\ndf = df[df['CompoundSMILES'].notnull()]\ndf.RefinementOutcome.replace(\"7 - Analysed & Rejected\",False,inplace=True)\ndf.RefinementOutcome.replace(\"6 - Deposited\",True,inplace=True)\ndf.RefinementOutcome.value_counts()","e85fcbe8":"!conda install -y -c rdkit rdkit;\n# !pip install pandas==0.23.0","811e2206":"#Importing Chem module\nfrom rdkit import Chem \n\n#Method transforms smiles strings to mol rdkit object\ndf['mol'] = df['CompoundSMILES'].apply(lambda x: Chem.MolFromSmiles(x)) \ndf['mol'] = df['mol'].apply(lambda x: Chem.AddHs(x))\ndf['num_of_atoms'] = df['mol'].apply(lambda x: x.GetNumAtoms())\ndf['num_of_heavy_atoms'] = df['mol'].apply(lambda x: x.GetNumHeavyAtoms())\n\ndef number_of_atoms(atom_list, df):\n    for i in atom_list:\n        df['num_of_{}_atoms'.format(i)] = df['mol'].apply(lambda x: len(x.GetSubstructMatches(Chem.MolFromSmiles(i))))\n\nnumber_of_atoms(['C','O', 'N', 'Cl'], df)        \n\nfrom rdkit.Chem import Descriptors\ndf['tpsa'] = df['mol'].apply(lambda x: Descriptors.TPSA(x))\ndf['mol_w'] = df['mol'].apply(lambda x: Descriptors.ExactMolWt(x))\ndf['num_valence_electrons'] = df['mol'].apply(lambda x: Descriptors.NumValenceElectrons(x))\ndf['num_heteroatoms'] = df['mol'].apply(lambda x: Descriptors.NumHeteroatoms(x))","e98d6057":"df.head()","27a151e7":"df.columns.values","80762630":"%%time\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold,StratifiedKFold,GroupKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n\ndef lgb_kfold(train_df,test_df, train_target,  test_target,features,target,cat_features,folds,params,classification=False):\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n\n    cv_list = []\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, train_target)):\n        print ('FOLD:' + str(n_fold+1))\n        \n        train_x, train_y = train_df.iloc[train_idx], train_target.iloc[train_idx]\n        valid_x, valid_y = train_df.iloc[valid_idx], train_target.iloc[valid_idx]\n        \n        print ('train_x shape:',train_x.shape)\n        print ('valid_x shape:',valid_x.shape)\n        \n        dtrain = lgb.Dataset(train_x, label=train_y,categorical_feature=cat_features)\n        dval = lgb.Dataset(valid_x, label=valid_y, reference=dtrain,categorical_feature=cat_features) \n        bst = lgb.train(params, dtrain, num_boost_round=10000,\n            valid_sets=[dval,dtrain], verbose_eval=100,early_stopping_rounds=100, ) #feval = evalerror\n        new_list = sorted(zip(features, bst.feature_importance('gain')),key=lambda x: x[1], reverse=True)[:]\n        for item in new_list:\n            print (item) \n              \n        oof_preds[valid_idx] = bst.predict(valid_x, num_iteration=bst.best_iteration)\n        sub_preds += bst.predict(test_df[features], num_iteration=bst.best_iteration) \/ folds.n_splits\n        \n        oof_cv = roc_auc_score(valid_y,  oof_preds[valid_idx])\n        cv_list.append(oof_cv)\n        print (cv_list)\n \n    auc = roc_auc_score(train_target,  oof_preds)\n    print('Full OOF AUC %.6f' % auc)  \n    auc = roc_auc_score(test_target,  sub_preds)\n    print('Holdout OOF AUC %.6f' % auc) \n    train_df['prediction'] = oof_preds\n    test_df['prediction'] = sub_preds\n    \n    return train_df,test_df,auc\n\nparams = {\n        \"nthread\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"objective\": \"binary\",\n        \"metric\": \"auc\",\n        \"min_data_in_leaf\": 70, \n        \"min_gain_to_split\": 0.1,\n        \"min_child_weight\": 0.001,\n        \"reg_alpha\": 0.1, \n        \"reg_lambda\": 1, \n        \"max_depth\" : -1,\n        \"num_leaves\" : 31, \n        \"max_bin\" : 256, \n        \"is_unbalanced\" : True, \n        \"learning_rate\" :0.01,\n        \"bagging_fraction\" : 0.9,\n        \"bagging_freq\" : 1,\n        \"bagging_seed\" : 4590,\n        \"feature_fraction\" : 0.9,\n        \"verbosity\": -1,\n        \"boost_from_average\": False,\n}\n\n    \ndrop_features = ['CrystalName', 'CompoundCode', 'CompoundSMILES', 'MountingResult',\n       'DataCollectionOutcome', 'DataProcessingResolutionHigh',\n       'RefinementOutcome', 'Deposition_PDB_ID', 'mol', \n                 ]\ntarget = 'RefinementOutcome'\ncat_features = []\nfeatures = [f for f in df.columns if f not in drop_features]\nprint ('features:', len(features), features)\n\ntrain_x,test_x, train_y,  test_y  = train_test_split(df[features], df[target], test_size=0.2, random_state=223,stratify=df[target]) \n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=223)\ntrain_lgb,test_lgb,auc = lgb_kfold(train_x,test_x, train_y,  test_y,features,target,cat_features,folds,params,classification=True)\n","6c85b9ee":"!pip install git+https:\/\/github.com\/samoturk\/mol2vec;","9abdf2f3":"df.shape","1971bf2c":"from gensim.models import word2vec\nfrom mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\nmodel = word2vec.Word2Vec.load('\/kaggle\/input\/mol2vec\/model_300dim.pkl')\n\n#Constructing sentences\ndf['sentence'] = df.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)\n\n#Extracting embeddings to a numpy.array\n#Note that we always should mark unseen='UNK' in sentence2vec() so that model is taught how to handle unknown substructures\ndf['mol2vec'] = [DfVec(x) for x in sentences2vec(df['sentence'], model, unseen='UNK')]\nX = np.array([x.vec for x in df['mol2vec']])\nX.shape","13ca80e4":"df = df.reset_index(drop=True)\nmdf = pd.DataFrame(X)\nnew_df = pd.concat([mdf, df], axis=1)","931d583d":"new_df.head()","b90b730d":"drop_features = ['CrystalName', 'CompoundCode', 'CompoundSMILES', 'MountingResult',\n       'DataCollectionOutcome', 'DataProcessingResolutionHigh',\n       'RefinementOutcome', 'Deposition_PDB_ID', 'mol', 'sentence', 'mol2vec'\n                 ]\ntarget = 'RefinementOutcome'\ncat_features = []\nfeatures = [f for f in new_df.columns if f not in drop_features]\nprint ('features:', len(features), features)\ntrain_x,test_x, train_y,  test_y  = train_test_split(new_df[features], new_df[target], test_size=0.2, random_state=223,stratify=new_df[target]) \n\ntrain_lgb,test_lgb,auc = lgb_kfold(train_x,test_x, train_y,  test_y,features,target,cat_features,folds,params,classification=True)\n","898393b8":"# Mol2vec","78461237":"# Mol Feature Engineering"}}