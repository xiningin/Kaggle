{"cell_type":{"3b62f061":"code","5d34753a":"code","b6059429":"code","a2abfc7a":"code","7ff43d01":"code","2b997c20":"code","07c317ca":"code","faae622b":"code","198d98d4":"code","895240a4":"code","b6731bc8":"code","86eee325":"code","b44d5136":"code","3ae50881":"code","6b18199f":"code","76311c82":"code","09f5e31d":"code","9a8a10fc":"code","74826a71":"code","3db7f6da":"code","2823cb9d":"markdown","104314be":"markdown","9a9546be":"markdown","4301a0c8":"markdown","a9827c84":"markdown","a18f6d8d":"markdown","a0a96e29":"markdown","41ce0513":"markdown","179189ed":"markdown","81e964b4":"markdown","5319bd9b":"markdown","1826a82d":"markdown","f55beaf3":"markdown","06504dda":"markdown","7b44b1f9":"markdown","d36e160e":"markdown","72ac0369":"markdown","4059aee1":"markdown","1cedf870":"markdown","22a76de8":"markdown","b832a93e":"markdown","e5288fca":"markdown","9efc8fcb":"markdown","d7cde3f2":"markdown","e2950f10":"markdown","3a803575":"markdown","2a2f08c4":"markdown","2dbd00e8":"markdown","661b44a8":"markdown"},"source":{"3b62f061":"%matplotlib inline\n\nimport tensorflow as tf\n\nfrom matplotlib import pyplot as plt","5d34753a":"image_path = '..\/input\/catimage\/images\/train\/cat\/cat.jpg'\n\nplt.imshow(plt.imread(image_path));","b6059429":"directory_path = \"..\/input\/catimage\/images\"","a2abfc7a":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=40\n)","7ff43d01":"x, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","2b997c20":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    width_shift_range=[-40, -20, 0, 20, 40],\n    height_shift_range=[-50,50]\n)","07c317ca":"x, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","faae622b":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    brightness_range=(0., 2.)\n)\n\nx, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","198d98d4":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    shear_range=45\n)\n\nx, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","895240a4":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    zoom_range=0.5\n)\n\nx, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","b6731bc8":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    channel_shift_range=100\n)\n\nx, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","86eee325":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    horizontal_flip=True,\n    vertical_flip=True\n)\n\nx, y = next(generator.flow_from_directory(directory_path, batch_size=1))\nplt.imshow(x[0].astype('uint8'));","b44d5136":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\ngenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True\n)\n\ngenerator.fit(x_train)","3ae50881":"x, y = next(generator.flow(x_train, y_train, batch_size=1))\nprint(x.mean(), x.std(), y)\nprint(x_train.mean())","6b18199f":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    samplewise_center=True,\n    samplewise_std_normalization=True\n)\n\nx, y = next(generator.flow(x_train, y_train, batch_size=1))\nprint(x.mean(), x.std(), y)","76311c82":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    rescale=1.\n)","09f5e31d":"x, y = next(generator.flow(x_train, y_train, batch_size=1))","9a8a10fc":"print(x.mean(), x.std(), y)","74826a71":"model = tf.keras.models.Sequential([\n    tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, input_shape=(32, 32, 3), pooling='avg'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","3db7f6da":"_ = model.fit(\n    generator.flow(x_train, y_train, batch_size=32),\n    steps_per_epoch=10, epochs=1\n)","2823cb9d":"The brightness of the image can be augmented by either randomly darkening images, brightening images, or both.\n\nThe intent is to allow a model to generalize across images trained on different lighting levels.","104314be":"<img src=\"https:\/\/stepup.ai\/content\/images\/2020\/07\/figures_augmentation.zoom-1.png\" align=\"center\"  alt=\"Zoom Range\" style=\"height: 250px; width:400px;\"\/>","9a9546be":"Shear Intensity (Shear angle in counter-clockwise direction in degrees)","4301a0c8":"<img src=\"https:\/\/stepup.ai\/content\/images\/2020\/07\/figures_augmentation.shift-4.png\" align=\"center\"  alt=\"Height and Width Shifts\" style=\"height: 250px; width:600px;\"\/>","a9827c84":"# Task 2: Width and Height Shifts","a18f6d8d":"# Task 4: Shear Transformation","a0a96e29":"# Task 5: Zoom","41ce0513":"# Task 1: Rotation\n","179189ed":" ```featurewise_center``` : It sets the input mean to 0 over the dataset, feature-wise.\n \n ```featurewise_std_normalization``` : It divides the inputs by standard deviation of the dataset, feature-wise.","81e964b4":"# Task 8: Normalization\n\n### Featurewise","5319bd9b":"Range for random channel shifts.","1826a82d":"A shift to an image means moving all pixels of the image in one direction, such as horizontally or vertically, while keeping the image dimensions the same.\n\nThe ```width_shift_range``` and ```height_shift_range``` arguments to the ImageDataGenerator constructor control the amount of horizontal and vertical shift respectively.\n\n","f55beaf3":"\n<img src=\"https:\/\/stepup.ai\/content\/images\/2020\/07\/figures_augmentation.rotation-1.png\" align=\"center\"  alt=\"Rotation\" style=\"height: 200px; width:400px;\"\/>","06504dda":"A zoom augmentation randomly zooms the image in and either adds new pixel values around the image or interpolates pixel values respectively.\n\nImage zooming can be configured by the ```zoom_range``` argument to the ImageDataGenerator constructor. You can specify the percentage of the zoom as a single float or a range as an array or tuple.","7b44b1f9":"```samplewise_center``` :  Set each sample mean to 0.\n\n```samplewise_std_normalization``` : Divide each input by its standard deviation","d36e160e":"# Model Training","72ac0369":"<img src=\"https:\/\/stepup.ai\/content\/images\/2020\/07\/figures_augmentation.flip-1.png\" align=\"center\"  alt=\"Horizontal and Vertical Flips\" style=\"height: 250px; width:400px;\"\/>","4059aee1":"# Task 9: Rescale and Preprocessing Function","1cedf870":"\n<img src=\"https:\/\/stepup.ai\/content\/images\/2020\/07\/figures_augmentation.shear-2.png\" align=\"center\"  alt=\"Shear Range\" style=\"height: 200; width:500px;\"\/>","22a76de8":"# Task 6: Channel Shift","b832a93e":"### Samplewise","e5288fca":"```rotation_range ``` : Degree range for random rotations.\n\n\n- A rotation augmentation randomly rotates the image clockwise by a given number of degrees from 0 to 360.\n\n- The rotation will likely rotate pixels out of the image frame and leave areas of the frame with no pixel data that must be filled in.","9efc8fcb":"# Task 7: Flips","d7cde3f2":"Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images from the existing images in the dataset.\n\nTraining deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.It is a good practice to use Data Augmentation if we want to prevent overfitting, or initial dataset is too small to train on , or even if we want to squeeze better performance from our model. \n\nThe Keras deep learning neural network library provides the capability to fit models using image data augmentation via the ```ImageDataGenerator``` class.\n\nStill, you should keep in mind that you can augment the data for the ML problems as well.\n\nWe can use Data Augmentation for various types of data such as:\n\n- Audio\n- Text\n- Images\n- Any other types of data\n\nIn this notebook, you will discover how to use image data augmentation when training deep learning neural networks.","e2950f10":"# Import Libraries","3a803575":"```rescale``` : Rescaling factor. \n- Defaults to None. \n- If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (after applying all other transformations).","2a2f08c4":"An image flip means reversing the rows or columns of pixels in the case of a vertical or horizontal flip respectively.\n\nThe flip augmentation is specified by a boolean ```horizontal_flip``` or ```vertical_flip argument``` to the ImageDataGenerator class constructor. ","2dbd00e8":"# Image Data Augmentation with Keras\n","661b44a8":"# Task 3 : Brightness"}}