{"cell_type":{"5d3af625":"code","aed029c4":"code","82713acd":"code","a2c9a202":"code","01fdff78":"code","004d5d68":"code","13919542":"code","3ecf87c2":"code","6d6959bd":"code","5d548031":"code","8cbdfdda":"code","7d8eaa14":"code","df038d4a":"code","50d28397":"code","05f5f9a8":"code","6825eefa":"code","5797a7e5":"code","f9d6c35a":"code","7b2190ca":"code","451fc781":"code","e3c6fad6":"code","e1b15d1e":"code","65ac7d11":"code","22978df8":"code","1db036b9":"code","d75bc66f":"code","7a8333ed":"code","4ec64ffa":"code","d34b25d9":"code","6724d002":"code","a29d1f5d":"code","186fa7ed":"code","8369b81c":"code","c0a806d0":"code","16cce899":"code","d504cb13":"code","054b34f6":"markdown","192d88d2":"markdown","24d6c04f":"markdown","6e84e3f5":"markdown","b53d7b38":"markdown","6543e71d":"markdown","9efc7499":"markdown","38aeb9bc":"markdown","a01485c6":"markdown","cf29717f":"markdown","8bea04d3":"markdown","f2f1b03f":"markdown","e4bf9990":"markdown","1025436c":"markdown","18dc610e":"markdown","4bfcc01b":"markdown","feb6adbf":"markdown"},"source":{"5d3af625":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport joblib\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import ElasticNet, Ridge, Lasso\nfrom sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.utils import estimator_html_repr\nfrom sklearn import set_config\nset_config(display='diagram')","aed029c4":"## reading the csv file\ndf = pd.read_csv('\/kaggle\/input\/fish-market\/Fish.csv')","82713acd":"## understanding the basic info about the data\n\ndf.info()","a2c9a202":"## Checking the first five rows of the dataframe\ndf.head()","01fdff78":"## Number of rows and columns in the dataset\ndf.shape","004d5d68":"## Number of unique values present in each feature\ndf.nunique()","13919542":"## Checking the correlation between the features of the dataframe\nsns.heatmap(df.corr(),annot=True)","3ecf87c2":"## Checking for missing values in the data\n\ndf.isnull().sum() ","6d6959bd":"## Separating independent and dependent features\n\nY = pd.DataFrame(df['Weight'],columns=['Weight'])\n\nX = df.drop(columns=['Weight'])\n","5d548031":"## getting the names of the numerical and categorical features\n\ncat_feat = [feature for feature in X.columns if X[feature].dtypes == 'O']\n\nnum_feat = [feature for feature in X.columns if feature not in cat_feat]","8cbdfdda":"## splitting the dataset into training and test set\n\nx_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=1232)","7d8eaa14":"## we are creating this as the SimpleImputer method doesn't have get_feature_names_out method\nSimpleImputer.get_feature_names_out = (lambda self, names=None:\n                                       self.feature_names_in_)","df038d4a":"cat_pipe = Pipeline([\n            \n            ('cat_imputer',SimpleImputer(strategy=\"most_frequent\")),\n            ('one_hot_encoder',OneHotEncoder())\n    \n        ])\n \nnum_pipe = Pipeline([\n     \n             ('num_imputer',SimpleImputer(strategy=\"median\")),\n             ('std_scalar',StandardScaler())\n        ])\n","50d28397":"preprocessing_pipe = ColumnTransformer([\n            \n            ('cat',cat_pipe,cat_feat),\n            ('num',num_pipe,num_feat)\n    \n        ],remainder=\"passthrough\")","05f5f9a8":"## Creating a pipeline for model training \n\nmodel_pipe1 = Pipeline([\n\n        ('model1',Ridge(random_state=123))\n])\n\nmodel_pipe2 = Pipeline([\n\n        ('model2',Lasso(random_state=124))\n])\n\nmodel_pipe3 = Pipeline([\n    \n            (\"model3\",ElasticNet(random_state=243))    \n    \n])","6825eefa":"## Combining the pipelines for preprocessing and model training\nfull_pipeline1 = Pipeline([\n            \n            ('preprocessing',preprocessing_pipe),\n            ('model_training1',model_pipe1)\n    \n    ])\n\nfull_pipeline2 = Pipeline([\n            \n            ('preprocessing',preprocessing_pipe),\n            ('model_training2',model_pipe2)\n    \n    ])\n\nfull_pipeline3 = Pipeline([\n            \n            ('preprocessing',preprocessing_pipe),\n            ('model_training3',model_pipe3)\n    \n    ])","5797a7e5":"full_pipeline1","f9d6c35a":"## saving the full_pipeline1 diagram as a html file\n\nwith open('\/kaggle\/working\/Ridge_regression_pipeline.html','w',encoding=\"utf-8\") as f:\n    f.write(estimator_html_repr(full_pipeline1))","7b2190ca":"full_pipeline2","451fc781":"## saving the full_pipeline2 diagram as a html file\n\nwith open('\/kaggle\/working\/Lasso_regression_pipeline.html','w',encoding=\"utf-8\") as f:\n    f.write(estimator_html_repr(full_pipeline2))","e3c6fad6":"full_pipeline3","e1b15d1e":"## saving the full_pipeline3 diagram as a html file\n\nwith open('\/kaggle\/working\/ElasticNet_regression_pipeline.html','w',encoding=\"utf-8\") as f:\n    f.write(estimator_html_repr(full_pipeline3))","65ac7d11":"## Using cross validation to find the best model out of three \n\nkf = KFold(n_splits=5,shuffle=True,random_state=987)\nscore1 = cross_val_score(full_pipeline1,x_train,y_train,cv=kf,scoring='r2').mean()\nscore2 = cross_val_score(full_pipeline2,x_train,y_train,cv=kf,scoring='r2').mean()\nscore3 = cross_val_score(full_pipeline3,x_train,y_train,cv=kf,scoring='r2').mean()\n\nprint(f\"R squared score for the ridge regression on training set is {np.round(score1,3)}\")\nprint(f\"R squared score for the lasso regression on training set is {np.round(score2,3)}\")\nprint(f\"R squared score for the elasticnet regression on training set is {np.round(score3,3)}\")","22978df8":"## getting the parameters that can be tuned for full_pipeline2\n\nfull_pipeline2.get_params().keys()","1db036b9":"tuning_parameters = {}\ntuning_parameters['model_training2__model2__alpha'] = np.arange(1,10,0.5)\ntuning_parameters['model_training2__model2__selection'] = ['cyclic','random']","d75bc66f":"hyperparameter_tuning_results = RandomizedSearchCV(full_pipeline2,tuning_parameters,scoring='r2',random_state=764)","7a8333ed":"tuning_results = hyperparameter_tuning_results.fit(x_train,y_train)","4ec64ffa":"tuning_results_df = pd.DataFrame(tuning_results.cv_results_)","d34b25d9":"tuning_results_df[['param_model_training2__model2__alpha','param_model_training2__model2__selection','mean_test_score','rank_test_score']]","6724d002":"tuning_results.best_params_","a29d1f5d":"full_pipeline2['model_training2'].named_steps['model2'].set_params(selection='random',alpha=1.5)","186fa7ed":"## Training the model using the new parameters\nlasso_model = full_pipeline2.fit(x_train,y_train)","8369b81c":"y_predict = lasso_model.predict(x_test)","c0a806d0":"y_predict","16cce899":"### Calculating the accuracy of the model using r2_score\n\nr2_score(y_test,y_predict)","d504cb13":"joblib.dump(lasso_model,\"\/kaggle\/working\/lasso_model.pkl\")","054b34f6":"##### Combining the preprocessing pipeline with three model pipelines to get three full pipeline (one for each model)","192d88d2":"#### Importing the required libraries","24d6c04f":"##### Saving the full pipeline for lasso regression as a html file","6e84e3f5":"##### Creating a separate pipeline for numerical and categorical features","b53d7b38":"##### Since SimpleImputer class doesn't have method to get the feature names after transformation, creating one","6543e71d":"Saving the created model into the python pickle file","9efc7499":"#### Tuning the hyperparameters of the lasso regression full pipeline","38aeb9bc":"##### Saving the full pipeline for elastic net regression as a html file","a01485c6":"##### Performing K-fold cross validation on three full pipelines","cf29717f":"##### Creating different pipelines for three models","8bea04d3":"##### Even if there are no missing values in this data, we are going to implement imputers.This is because the new or future data that we might use for retraining the model can have missing values","f2f1b03f":"##### Combining the created pipelines for numerical and categorical features to create a single preprocessing pipeline","e4bf9990":"#### creating a pipeline for preprocessing of data","1025436c":"#### Reading the dataset","18dc610e":"##### Saving the full pipeline for ridge regression as a html file","4bfcc01b":"###### Since the lasso regression is giving the highest score, we will use that to train our model","feb6adbf":"#### Understanding the data"}}