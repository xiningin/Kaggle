{"cell_type":{"d46b42c7":"code","53a454ef":"code","bc173b6b":"code","2e538f52":"code","8be94ecd":"code","32cba995":"code","08b4ce96":"code","74385cd8":"code","01c8d6ac":"code","c2197a10":"code","05f523a0":"code","772fcde6":"code","e918f2fd":"code","f3334cf0":"code","e1186f76":"code","d6a43e51":"code","4551a270":"code","ab0549d8":"code","99e253a8":"code","928abdb9":"code","c88f3845":"code","a4550bc0":"code","67f160a2":"code","a4d11f01":"code","da882f2e":"code","a44d016f":"code","8898bfd3":"code","f4ba2baa":"code","d949eeb2":"markdown","1836c7d3":"markdown","4aff90f1":"markdown","bc6c6dea":"markdown","cc3e67c7":"markdown","5c1c0e19":"markdown","f196ba70":"markdown","c5faee17":"markdown","5e833757":"markdown","6ac0e464":"markdown","a832a36b":"markdown","f025921b":"markdown","0652d24c":"markdown","ea3ced62":"markdown","b99dd610":"markdown","5bcdf77f":"markdown"},"source":{"d46b42c7":"\n\n# linear algebra.\nimport numpy as np \n# data processing, CSV file I\/O (e.g. pd.read_csv).\nimport pandas as pd \n\n\nfrom sklearn.model_selection import train_test_split  # Train-Test Split \nfrom sklearn.feature_extraction.text import CountVectorizer # Bag of Words \nfrom sklearn.linear_model import LogisticRegression # Model Creation \nfrom sklearn.metrics import confusion_matrix  # Metrics Evaluation \n\n#For Data Viz.\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\n#For Warning Messages. \nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","53a454ef":"df = pd.read_csv('\/kaggle\/input\/clothing-shoes-and-jewellery-reviews\/balanced_review.csv')\ndf.head()","bc173b6b":"print(f'Dataset has {df.shape[0]} rows and {df.shape[1]} columns.')","2e538f52":"df.info()","8be94ecd":"df.describe()","32cba995":"df.isnull().any(axis = 0)","08b4ce96":"df.isnull().sum()","74385cd8":"df1 = df.copy()\n\ndf1.dropna(inplace = True)","01c8d6ac":"df1.isnull().sum()","c2197a10":"df1['overall'].value_counts()","05f523a0":"df1['overall'].value_counts().plot(kind = 'pie' , autopct = '%1.1f%%' , shadow = True ,explode=[0.1,0,0,0,0] )\nplt.title(\"Distribution of Overall Rating.\")\nfig = plt.gcf()\nfig.set_size_inches(7,7)\nplt.show()","772fcde6":"df2 = df1[df1['overall'] != 3]","e918f2fd":"df2.shape","f3334cf0":"df2['overall'].value_counts()","e1186f76":"df2['positivity'] = np.where(df2['overall'] > 3 , 1,0)\n","d6a43e51":"df2['positivity'].value_counts()","4551a270":"x_train,x_test,y_train,y_test = train_test_split(df2['reviewText'] , df2['positivity'] , test_size = 0.2 , random_state = 42)\nprint(f'Shape of x_train : {x_train.shape} ')\nprint(f'Shape of x_test : {x_test.shape}')\nprint(f'Shape of y_train : {y_train.shape}')\nprint(f'Shape of y_test : {y_test.shape}')","ab0549d8":"vect = CountVectorizer().fit(x_train)","99e253a8":"len(vect.get_feature_names())","928abdb9":"x_train_vectorized = vect.transform(x_train)","c88f3845":"x_train_vectorized","a4550bc0":"model = LogisticRegression(solver='liblinear')","67f160a2":"model.fit(x_train_vectorized , y_train)","a4d11f01":"predictions = model.predict(vect.transform(x_test))","da882f2e":"from sklearn.metrics import accuracy_score \n\nscore = accuracy_score(y_test,predictions)\nscore_percentage = score * 100 \nprint(f'Accuracy Score : {score_percentage:.2f} %')","a44d016f":"from sklearn.metrics import roc_auc_score \n\nroc_auc = roc_auc_score(y_test,predictions)\nroc_percentage = roc_auc * 100 \nprint(f'ROC AUC Score : {roc_percentage:.2f} %')","8898bfd3":"cm = confusion_matrix(y_test,predictions)\n#mask = np.triu(np.ones_like(cm , dtype = bool))\nsns.heatmap(cm  , annot = True ,linewidth = 1 )","f4ba2baa":"from sklearn.metrics import classification_report\n\nprint(f'Classification Report: \\n {classification_report(y_test,predictions)}')\n","d949eeb2":"<b>Now,Let's Perform Predictions on test set.<\/b>","1836c7d3":"<b style = 'font-size:20px'>Let's Investigate target Variable.<\/b>","4aff90f1":"<b>Let's make target variable two class classification problem.<\/b>","bc6c6dea":"<b style = 'font-size:20px'>Let's Check for Missing Values or NaN Values.<\/b>","cc3e67c7":"<b>Context<\/b>\n<br>\nTo know the customer's behaviour this dataset was created .\nInitially , the complete dataset was nearly about 14 GBs, So I pre-processed that dataset and created smaller chuck sizes of that dataset, and created a separate dataset out of it with summary,overall,reviewText columns.\n<br>\n\n<b>Content<\/b>\n<br>\n<b>Overall<\/b> - This is a label column , which depicts the no of ratings given out of 5.\n<br>\n<b>reviewText<\/b> - This column has the customer review in categorical format.\n<br>\n<b>Summary<\/b> - Summary has abstract of the reviewText column\n<br>\n\n<b>Inspiration<\/b>\n<br>\nTo Create a Machine Learning model using NLP techniques that will tell which review is positive and which one is a negative review.\n<br>","5c1c0e19":"<b>Let's drop the missing values and clean the data.<\/b>","f196ba70":"<b style = 'font-size:20px'>Let's Create our final Classification ML model.<\/b>","c5faee17":"<b style = 'font-size:20px'>Let's Evaluate our model using some metrics.<\/b>","5e833757":"<b style = 'font-size:20px'>Let's Seperate Train and Test sets.<\/b>","6ac0e464":"<b style = 'font-size:20px'>Reading the dataset and Understading it.<\/b>","a832a36b":"<b>Accessing the Statistical Information of the dataset.<\/b>","f025921b":"<b>Now is the time we should apply bag of words classifier.<\/b>","0652d24c":"<b>We got missing values in reviewText and Summary columns.<\/b>","ea3ced62":"<b style = 'font-size:20px'>Import all the required Libraries<\/b> ","b99dd610":"<b>Accessing the Information of the dataset. <\/b>","5bcdf77f":"<b>So seperate out postive and negative reviews,the rating 3 won't help us because it would be baised,So let's make a seperate dataframe with 1,2 as negative ratings and 4,5 as positive ratings.<\/b>"}}