{"cell_type":{"7c6b167c":"code","41c1a5a7":"code","431fd92c":"code","822fe2fb":"code","160485a8":"code","4927298a":"markdown","63db69c8":"markdown","f11d8178":"markdown","c8d8f37e":"markdown","75ed8626":"markdown","62ae6720":"markdown","933fcdf0":"markdown","8bb5803f":"markdown"},"source":{"7c6b167c":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\n#import seaborn as sns\n#import matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nfrom sklearn.model_selection import StratifiedKFold","41c1a5a7":"class ImageDataset(Dataset):\n    def __init__(self, csv_file, img_path, transform=None):\n\n        self.csv_file = csv_file\n        self.img_path = img_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.csv_file)\n\n    def __getitem__(self, idx):\n        #csv_file=train_labels\n        #img_path=\"D:\/Human Protein Atlas Image Classification\/train\/\"\n        #idx=0\n        #path= img_path+csv_file.iloc[idx, 0]\n        \n        path = self.img_path+self.csv_file.iloc[idx, 0]\n        \n        R = Image.open(path + '_red.png')\n        G = Image.open(path + '_green.png')\n        B = Image.open(path + '_blue.png')\n        Y = Image.open(path + '_yellow.png')\n\n        im = np.stack((\n            np.array(R)\/255, \n            np.array(G)\/255, \n            np.array(B)\/255,\n            np.array(Y)\/255))\n        \n        im=torch.Tensor(im)\n        label = torch.from_numpy(np.array(list(self.csv_file.iloc[idx,1:]))).float()\n        \n        return im, label","431fd92c":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.C1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3,padding=1)\n        self.C2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3,padding=1)\n        \n        self.C3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3,padding=1)\n        self.C4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3,padding=1)\n        \n        self.C5 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,padding=1)\n        self.C6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n        self.C7 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n        self.C8 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n        \n        self.C9 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,padding=1)\n        self.C10 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n        self.C11 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n        self.C12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n\n        self.L1 = nn.Linear(32*32*64, 512)\n        self.L2 = nn.Linear(512, 28)\n\n    def forward(self, x):\n        x=self.C1(x)\n        x=self.C2(x)\n        x=F.max_pool2d(F.relu(x),2)\n\n        x=self.C3(x)\n        x=self.C4(x)\n        x=F.max_pool2d(F.relu(x),2)\n        \n        x=self.C5(x)\n        x=self.C6(x)\n        x=self.C7(x)\n        x=self.C8(x)\n        x=F.max_pool2d(F.relu(x),2)\n        \n        x=self.C9(x)\n        x=self.C10(x)\n        x=self.C11(x)\n        x=self.C12(x)\n        x=F.max_pool2d(F.relu(x),2)\n        \n        x = x.view(-1, self.num_flat_features(x))\n\n        x = F.relu(self.L1(x))\n        x = F.relu(self.L2(x))\n        \n        x=F.sigmoid(x)\n\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","822fe2fb":"def FocalLoss(output, target):\n    gamma=2\n    if not (target.size() == output.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), output.size()))\n\n    max_val = (-output).clamp(min=0)\n    loss = output - output * target + max_val + ((-max_val).exp() + (-output - max_val).exp()).log()\n\n    invprobs = F.logsigmoid(-output * (target * 2.0 - 1.0))\n    loss = (invprobs * gamma).exp() * loss\n        \n    return loss.sum(dim=1).mean()","160485a8":"\nif __name__ == \"__main__\":\n    train_labels = pd.read_csv(\"D:\/Human Protein Atlas Image Classification\/train.csv\")\n    \n    train_labels.head()\n    train_labels.shape[0]\n\n    label_names = {\n        0:  \"Nucleoplasm\",  \n        1:  \"Nuclear membrane\",   \n        2:  \"Nucleoli\",   \n        3:  \"Nucleoli fibrillar center\",   \n        4:  \"Nuclear speckles\",\n        5:  \"Nuclear bodies\",   \n        6:  \"Endoplasmic reticulum\",   \n        7:  \"Golgi apparatus\",   \n        8:  \"Peroxisomes\",   \n        9:  \"Endosomes\",   \n        10:  \"Lysosomes\",   \n        11:  \"Intermediate filaments\",   \n        12:  \"Actin filaments\",   \n        13:  \"Focal adhesion sites\",   \n        14:  \"Microtubules\",   \n        15:  \"Microtubule ends\",   \n        16:  \"Cytokinetic bridge\",   \n        17:  \"Mitotic spindle\",   \n        18:  \"Microtubule organizing center\",   \n        19:  \"Centrosome\",   \n        20:  \"Lipid droplets\",   \n        21:  \"Plasma membrane\",   \n        22:  \"Cell junctions\",   \n        23:  \"Mitochondria\",   \n        24:  \"Aggresome\",   \n        25:  \"Cytosol\",   \n        26:  \"Cytoplasmic bodies\",   \n        27:  \"Rods & rings\"\n    }\n\n    reverse_train_labels = dict((v,k) for k,v in label_names.items())\n\n    for key in label_names.keys():\n        train_labels[label_names[key]] = 0\n        \n    train_labels = train_labels.apply(fill_targets, axis=1)\n    train_labels.head()\n    del train_labels['Target']\n    \n#check sample is ok\n#000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_blue\n\n    transformations = transforms.Compose([transforms.ToTensor()])\n    \n    model = Net()\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.99))\n\n    for k in train_labels.columns:\n        if k!='Id':\n            folds = StratifiedKFold(n_splits=10, shuffle=True)\n            for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_labels.values,train_labels[k].values)):\n                \n                temp=train_labels.iloc[val_idx].reset_index(drop=True)\n\n                dataset = ImageDataset(csv_file=temp,img_path=\"D:\/Human Protein Atlas Image Classification\/train\/\",transform=transformations )\n                \n                dataloader = DataLoader(dataset, batch_size=64,shuffle=True)\n                for batch_idx, (data, target) in enumerate(dataloader):\n                    print('1')\n\n                    data, target = Variable(data), Variable(target)\n                    optimizer.zero_grad()\n                    output = model(data)\n                    loss = FocalLoss(output, target)\n                    loss.backward()\n                    optimizer.step()\n                    print('Train Epoch: [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(batch_idx * len(data), len(dataloader.dataset),100. * batch_idx \/ len(dataloader), loss.data[0]))\n","4927298a":"**Loding image data**","63db69c8":"**Loss function**","f11d8178":"**CNN model**","c8d8f37e":"**Thank you for your reading**\n\nThe model above is very poor ,each batch trainning error is  ~10.05  :-) \n\nThere is a lot of work I can do and learn.  :-) ","75ed8626":"**PyTorch Practice -CNN**\n\nHello everyone!! \n\nThis is my first kernel, I'm very new to image classification and deep learnning. \n\nAny comment is very welcome!!","62ae6720":"**Reference**\n\n\n[Starting kit for PyTorch Deep Learning](https:\/\/www.kaggle.com\/mratsim\/starting-kit-for-pytorch-deep-learning?fbclid=IwAR0ukfUlQjN1LBWJ974ugnFlwvnJ3Q5KfuWLOqRKaKngtVg6anvNBsbZgqg)\n\n[CNN 128x128x4, Keras from scratch [LB 0.328]](https:\/\/www.kaggle.com\/rejpalcz\/cnn-128x128x4-keras-from-scratch-lb-0-328)\n\n[Protein Atlas - Exploration and Baseline](https:\/\/www.kaggle.com\/allunia\/protein-atlas-exploration-and-baseline)","933fcdf0":"**Import libraries**","8bb5803f":"**Trainnig**"}}