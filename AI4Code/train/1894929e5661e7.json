{"cell_type":{"6f2da6eb":"code","af78f2fa":"code","2a59182e":"code","6cee306c":"code","762b8edc":"code","7a590408":"code","30304aba":"code","717452e2":"code","c5b9193e":"code","02025508":"code","21d4ccda":"code","28ec1141":"code","92ddee8e":"code","33fa59cc":"code","028eebfa":"code","3e647148":"code","6f23a36c":"code","9445c023":"code","bd228480":"code","259e4dea":"code","5059c9e8":"code","dd3e6d3f":"code","aec38efb":"code","c5ebf830":"code","c0b072f2":"code","fb6aba7f":"code","1168bbb1":"code","3474785d":"code","e9238c52":"code","5c94e5c1":"code","a219fc2e":"code","16c35877":"code","fb5b9449":"code","b8bbd9ff":"code","0f17fef0":"code","bad1ec78":"code","5bf8087c":"code","ceba31f1":"markdown","a266a057":"markdown","37d9c82f":"markdown","18dd1e21":"markdown","8cc6d3ae":"markdown","8d710e8b":"markdown","e926072d":"markdown","7b3eeab9":"markdown","d26398f5":"markdown","a10e8f24":"markdown"},"source":{"6f2da6eb":"import pickle, nltk, os, json, re\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\nnltk.download('stopwords')","af78f2fa":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 40)\npd.set_option('display.max_rows', None)","2a59182e":"def load_metadata(metadata_file):\n    df = pd.read_csv(metadata_file,\n                 dtype={'Microsoft Academic Paper ID': str,\n                        'pubmed_id': str, \n                        \"title\":str,\n                        \"absract\":str,\n                        \"WHO #Covidence\": str})\n    print(f'Loaded metadata with {len(df)} records')\n    return df","6cee306c":"def isNaN(string):\n    return string != string\nprint('hello', isNaN('hello'))\nprint(np.nan,isNaN(np.nan))","762b8edc":"METADATA_FILE = '\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv'\n\nmetadata = load_metadata(METADATA_FILE)","7a590408":"def add_calculated_columns(df):\n    df['has_title'] = df.title.apply(lambda x: not isNaN(x) and x != 'TOC')\n    df['has_abstract'] = df.abstract.apply(lambda x: not isNaN(x) and x != 'TOC')\n    return df","30304aba":"metadata = add_calculated_columns(metadata)\nmetadata.head()","717452e2":"df = metadata[metadata['has_title'] | metadata['has_abstract']].copy()\ndf.shape","c5b9193e":"def join_text(title, abstract, empty_text = \"\"):\n    try:\n        str_abstract = '' if (isNaN(abstract)) else abstract\n        str_title = '' if (isNaN(title)) else title\n        return (str_title + ' ' + str_abstract).strip()\n    except: \n        return empty_text\n    \nprint(join_text(df.iloc[0].title, 'Hola'))\nprint(join_text(df.iloc[0].title, df.iloc[0].abstract))\nprint(join_text(df.iloc[0].title, np.nan))\nprint(join_text(np.nan, df.iloc[0].title))\nprint(join_text(np.nan, np.nan))\n","02025508":"df['text'] = df.apply(lambda x: join_text(x.title,x.abstract,\"\"), axis = 1)","21d4ccda":"N_VOCAB = 20000","28ec1141":"%time \nvectorizer = CountVectorizer(max_features=N_VOCAB, \n                        lowercase=True,\n                        stop_words=nltk.corpus.stopwords.words('english'))\nX_doc_terms = vectorizer.fit_transform(df.text)","92ddee8e":"def showFreqTerms(X_train_counts, vectorizer, ):\n    sum_words = X_train_counts.sum(axis = 0)\n\n    term_freq = [(word,sum_words[0,idx]) for word,idx in vectorizer.vocabulary_.items()]\n    return sorted(term_freq, key = lambda x:x[1], reverse = True)","33fa59cc":"terms = showFreqTerms(X_doc_terms, vectorizer)\nterms_df = pd.DataFrame(terms, columns = [\"term\", \"frequency\"])","028eebfa":"terms_df","3e647148":"terms_df.shape","6f23a36c":"plt.rcParams[\"figure.figsize\"] = (6,10)\n\nterms_df[0:50].set_index(\"term\").sort_values(\"frequency\").plot(kind=\"barh\")","9445c023":"vectorizer.vocabulary_","bd228480":"feature_names = vectorizer.get_feature_names()\nfeature_names[120:140]","259e4dea":"feature_names[-30:]","5059c9e8":"def get_keywords(X, vectorizer):\n    feature_names = vectorizer.get_feature_names()\n    keywords = []\n    for i in range(X.shape[0]):\n        pos_list = X[i]\n        doc_keywords = []\n        for pos in pos_list.indices:\n            token = feature_names[pos]\n            doc_keywords.append(token)\n        keywords.append(doc_keywords)\n        \n    return keywords","dd3e6d3f":"keywords = get_keywords(X_doc_terms,vectorizer)\n\n#adding the new column\ndf['keywords'] = keywords\n\ndf.head()","aec38efb":"df.head()","c5ebf830":"def find(query_set,keyword_list):\n    return len(query_set.intersection(set(keyword_list))) > 0","c0b072f2":"%time\n\nquery_set = set(['induced','vaccines'])\n\ndf_induced = df[df.keywords.apply(lambda x:  find(query_set, x))]","fb6aba7f":"def find_sub_dataframe(df, query_set):\n    df_result = df[df.keywords.apply(lambda x:  find(query_set, x))]\n    return df_result","1168bbb1":"def extract_term_df(df):\n    c = Counter()\n    for d in df.keywords:\n        c.update(d)\n \n    return pd.DataFrame.from_dict(data=c, orient='index', columns=['doc_freq'])","3474785d":"def plot_df_terms(df_terms, k = 50 ):\n    df_terms.sort_values('doc_freq')[-k:].plot(kind='barh')","e9238c52":"def show_results(df,query_set):\n    show_cols = ['title','journal','url','abstract','keywords']\n\n    df_results = find_sub_dataframe(df, query_set)\n    df_terms = extract_term_df(df_results)\n    \n    print(f\"Query terms: {query_set}\")\n    print(f\"Number of results: {df_results.shape[0]}\")\n    print(f\"Number of terms: {df_terms.shape[0]}\")\n    \n    print(\"Results\")\n    display(df_results[show_cols].head())\n    \n    print(\"Co-occurence terms\")\n    plot_df_terms(df_terms)","5c94e5c1":"pd.set_option('display.max_colwidth', -1)","a219fc2e":"query_set = set(['induced','vaccines'])\nshow_cols = ['title','journal','url','keywords']\n\nshow_results(df,query_set)","16c35877":"questions = [\n \"Range of incubation periods for the disease in humans (and how this varies across age and health status) and how long individuals are contagious, even after recovery.\",\n \"Prevalence of asymptomatic shedding and transmission (e.g., particularly children).\",\n \"Seasonality of transmission.\",\n \"Physical science of the coronavirus (e.g., charge distribution, adhesion to hydrophilic\/phobic surfaces, environmental survival to inform decontamination efforts for affected areas and provide information about viral shedding).\",\n \"Persistence and stability on a multitude of substrates and sources (e.g., nasal discharge, sputum, urine, fecal matter, blood).\",\n \"Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).\",\n \"Natural history of the virus and shedding of it from an infected person\",\n \"Implementation of diagnostics and products to improve clinical processes\",\n \"Disease models, including animal models for infection, disease and transmission\",\n \"Tools and studies to monitor phenotypic change and potential adaptation of the virus\",\n \"Immune response and immunity\",\n \"Effectiveness of movement control strategies to prevent secondary transmission in health care and community settings\",\n \"Effectiveness of personal protective equipment (PPE) and its usefulness to reduce risk of transmission in health care and community settings\",\n \"Role of the environment in transmission\"   \n]","fb5b9449":"df_queries = pd.DataFrame(data=questions, columns = ['question'])","b8bbd9ff":"question_X = vectorizer.transform(df_queries.question)","0f17fef0":"df_queries['keywords'] = get_keywords(question_X,vectorizer)","bad1ec78":"df_queries","5bf8087c":"import matplotlib.pyplot as plt\n\nfor i in range(df_queries.shape[0]):\n    print(df_queries.loc[i].question)\n    show_results(df,set(df_queries.loc[i].keywords)) \n    plt.show()","ceba31f1":"## 7. CORD-19 Questions\n\nRange of incubation periods for the disease in humans (and how this varies across age and health status) and how long individuals are contagious, even after recovery.","a266a057":"## Build a document - term matrix","37d9c82f":"## 2. Preprocessing\n\n- Clean articles that do not have metadata\n- Use title and abstract for extracting keywords ","18dd1e21":"## 1. Loading metadata","8cc6d3ae":"## 6. Build a toy search-engine","8d710e8b":"**TODO**: \n   - Some preprocessing to remove numbers may help\n   - Removing non unicode\n   - Perform smarter keyword extraction","e926072d":"## 4. Visualize common terms in the collection","7b3eeab9":"## 5. Extracting the keywords from each text","d26398f5":"- Common terms are what you could expect from a bio\/health collection based on COVID-19 keyword selection: \n     - Generic medical terms: virus, diseases, simptoms, proteins, expression, etc\n     - Specific aliases to COVID-19 and other related virus\n     - Some broad health terms: health\n     - Some common terms that maybe could be added to a stopword list (in a search engine): new, old, one, two ","a10e8f24":"# Exploratory - Keyword extraction\n\n## Objective \nGet an overview of the document content, at what extent a keyword based search engine may help to find relevant articles. \n\nThis is a first step to provide an exploratory interface. So far, only metadata is used.\n\n## Process \n- Use sklearn to explore common keywords\n- Visualize keywords\n\n\n## Conclusions "}}