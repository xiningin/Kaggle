{"cell_type":{"c9feb6e5":"code","6a41451d":"code","a0084cdc":"code","ed1ba39e":"code","f28fab9a":"code","acc05bf5":"code","1148652e":"code","3e08f3fe":"code","bb831196":"code","a5914b3b":"code","6db7cdc6":"code","55c585da":"code","00550d09":"code","5273667b":"code","be31a12a":"code","fdefaf17":"code","9ed8d31d":"code","9b71027b":"code","4b1e75ed":"code","60915881":"code","5fec8ec7":"code","1d2d6961":"code","30da69e3":"code","11f0f340":"code","8860abdd":"code","b7f8c2d3":"markdown","e3793d5b":"markdown","23ee0094":"markdown","efccd4bd":"markdown","1f9b3699":"markdown","ba288df6":"markdown","3961a60f":"markdown","c801b1b1":"markdown","f1248955":"markdown","59040e86":"markdown","ceca960a":"markdown","ea115a24":"markdown"},"source":{"c9feb6e5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Additional packages for data preprocessing, model building, data visualisation\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6a41451d":"# Import data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ncombined = pd.concat([train,test],axis = 0)","a0084cdc":"# Basic properties of data\ntrain.info()\ntrain.describe()","ed1ba39e":"test.info()\ntest.describe()","f28fab9a":"# Investigating NA values in each column\n#train.loc[train['Fare'] == 0]\n#train.loc[train['Age'].isna()]\n#train.loc[train['Cabin'].notna()]\ntrain.loc[train['Embarked'].isna()]","acc05bf5":"# Removing NA values from data\ntrain_pre = train.dropna(subset = [\"Age\"],inplace = False)\ntrain_pre.info()","1148652e":"sns.swarmplot(x = \"Pclass\",y=\"Age\",hue = \"Survived\",data = train_pre)","3e08f3fe":"sns.swarmplot(x = \"Survived\",y=\"Age\",hue = \"Sex\",data = train_pre)","bb831196":"sns.heatmap(data = train_pre.corr(),cmap = \"Spectral\",center = 0)","a5914b3b":"train_pre.dropna(subset = ['Cabin','Embarked'],inplace = True)\ntrain_pre.info()\ntrain_pre.describe()","6db7cdc6":"# Filling NA values for Age\nmeanAge = round(combined[\"Age\"].mean(skipna = True))\ntrain['Age'].fillna(meanAge,inplace = True)\ntest['Age'].fillna(meanAge,inplace = True)","55c585da":"proxyCabin = \"Unknown\"\ntrain['Cabin'].fillna(proxyCabin,inplace = True)\ntest['Cabin'].fillna(proxyCabin,inplace = True)","00550d09":"modeEmbark = combined[\"Embarked\"].mode()[0]\ntrain['Embarked'].fillna(modeEmbark,inplace = True)\ntest['Embarked'].fillna(modeEmbark,inplace = True)","5273667b":"meanFare = round(combined[\"Fare\"].mean(skipna = True))\ntest['Fare'].fillna(meanFare,inplace = True)","be31a12a":"train.info()\ntrain.head()","fdefaf17":"# Dropping columns\ntrain.drop(['Name','PassengerId','Ticket','Cabin'],axis = 1,inplace = True)\ntest.drop(['Name','Ticket','Cabin'],axis = 1,inplace = True)","9ed8d31d":"train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n\ntrain.drop(['SibSp','Parch'],axis = 1,inplace = True)\ntest.drop(['SibSp','Parch'],axis = 1,inplace = True)","9b71027b":"train.info()\ntrain.head()","4b1e75ed":"# Encoding categorical columns \ntrainPclassAdd = pd.get_dummies(train['Pclass'].reset_index(drop = True),prefix = 'Pclass',dtype = int)\ntrainEmbarkedAdd = pd.get_dummies(train['Embarked'].reset_index(drop = True).astype(str),prefix = 'Embarked',dtype = int)\n\ntestPclassAdd = pd.get_dummies(test['Pclass'].reset_index(drop = True),prefix = 'Pclass',dtype = int)\ntestEmbarkedAdd = pd.get_dummies(test['Embarked'].reset_index(drop = True).astype(str),prefix = 'Embarked',dtype = int)\n\ntrain['Sex'] = train['Sex'].apply(lambda x: 1 if x == 'male' else 0)\ntest['Sex'] = test['Sex'].apply(lambda x: 1 if x == 'male' else 0)","60915881":"train = pd.concat([train.reset_index(drop = True),trainPclassAdd,trainEmbarkedAdd],axis = 1)\ntest = pd.concat([test.reset_index(drop = True),testPclassAdd,testEmbarkedAdd],axis = 1)\n\ntrain.drop([\"Embarked\",\"Pclass\"],axis = 1, inplace = True)\ntest.drop([\"Embarked\",\"Pclass\"],axis = 1, inplace = True)\ntrain.head()","5fec8ec7":"test.head()","1d2d6961":"X_train = train.drop(['Survived'],axis = 1)\ny_train = train['Survived']\n\nX_test = test.drop(['PassengerId'],axis = 1)\nX_train.shape, y_train.shape, X_test.shape","30da69e3":"# Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\nprint(\"Training accuracy is \" + str(logreg.score(X_train,y_train)* 100))\nlogreg.coef_[0]","11f0f340":"# Support Vector Machine\nsvm = SVC()\nsvm.fit(X_train,y_train)\nprint(\"Training accuracy is \" + str(svm.score(X_train,y_train)* 100))","8860abdd":"# Decision tree classifier\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\nprint(\"Training accuracy is \" + str(dtc.score(X_train,y_train)* 100))","b7f8c2d3":"## 1. Data preparation\nWe import the data and investigate some basic properties of the data.","e3793d5b":"# 4. Model building\nWe will test the following models for the prediction\n1. Logistic regression\n2. Support Vector Machine\n3. Decision Tree Classifier ","23ee0094":"We will now fill the NA values in the Age, Cabin and Embarked columns. The following will be performed:\n1. Fill NA values in Age with the mean age.\n2. Fill NA values in Cabin with the proxy value \"Unknown\"\n3. Fill NA values in Embarked with the mode port of embarkation.","efccd4bd":"It appears that many of the labelled cabins are ones from the 1st class cabins. We will not use the Cabin column in further analysis.","1f9b3699":"We can observe a few things here.\n1. Some people has a recorded fare of 0, distributed among all class. It is possible that they were awarded the ticket, or there was an error with the data record.\n2. Many people with a record of Cabin is also a 1st class passenger","ba288df6":"## 2. Dealing with NA values\n\nThere are a few choices to deal with the missing values in the Age, Cabin and Embarked columns.\n1. Filling in the missing values with some proxy value (e.g. mean, median)\n2. Dropping the entries with missing values entirely\n\nWe will try out the second method for some exploratory data analysis with Age","3961a60f":"It looks as if being a female also greatly increases your chances of surviving the Titanic!","c801b1b1":"It appears that most factors have a weak correlation with each other, with the exception of fare and parch. However, this weak correlation can also be because we did not normalise the data before plotting the heatmap. ","f1248955":"From the swarmplot (made with the data visualization package Seaborn), we can determine a few properites who survived the Titanic:\n1. Most survivors seem to come from 1st class\n2. Survivors have their age evenly distributed","59040e86":"## 3. Preprocessing data","ceca960a":"We will now convert the categorical columns we want to use to binary variables.","ea115a24":"We will start off by dropping columns (Name, PassengerID, Ticket and Cabin) we are not using from the dataframe, and combining the SibSp and Parch columns."}}