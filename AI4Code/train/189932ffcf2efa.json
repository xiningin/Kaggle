{"cell_type":{"5077db16":"code","12be0eea":"code","6fd76dac":"code","05a4a1c3":"code","a80a586d":"code","5cccbe97":"code","b052dc3b":"code","5a9688c4":"code","c7595ea0":"code","30f204c4":"code","4eb6d8d8":"code","7c9a055a":"code","de9b7b29":"code","9e390d16":"code","b477af8b":"code","c5b90ff8":"code","cb3f5b55":"code","658518d6":"code","373dca93":"code","e0ce66ed":"code","1f3c5f3d":"code","dbff9c3c":"markdown"},"source":{"5077db16":"!pip install feature-engine\n!pip install -U imbalanced-learn","12be0eea":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sklearn as sk\nimport imblearn as imb \nfrom feature_engine import categorical_encoders as ce\nfrom feature_engine import missing_data_imputers as mdi\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom imblearn.pipeline import Pipeline as pl\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom matplotlib import pyplot as plt\n","6fd76dac":"trainset = pd.read_csv('..\/input\/it-405-dm-and-bi-2020\/train.csv')\ntestset = pd.read_csv('..\/input\/it-405-dm-and-bi-2020\/test.csv')\nsubmission_df = pd.read_csv('..\/input\/it-405-dm-and-bi-2020\/sample_submission.csv')\n","05a4a1c3":"#Reading csv files\ntarget = trainset[\"Target\"]\ntrainset.drop([\"Id\", \"Target\"], axis=1, inplace=True) \ntestset.drop([\"Id\"], axis=1, inplace=True)","a80a586d":"trainset\n","5cccbe97":"missing_perc = trainset.isna().mean()\n","b052dc3b":"missing_perc","5a9688c4":"trainset = trainset.loc[:, missing_perc < 0.7]\ntestset = testset.loc[:, missing_perc < 0.7]","c7595ea0":"trainset.head()","30f204c4":"testset.head()","4eb6d8d8":"categorical_cols = [var for var in trainset.columns if trainset[var].dtype == 'O']\nnumerical_cols = [var for var in trainset.columns if trainset[var].dtype != 'O']","7c9a055a":"print(\"Categorical Columns: \", categorical_cols)\nprint(\"Numerical Columns: \", numerical_cols)\n","de9b7b29":"corr_data = trainset.copy()\ncorr_data['Target'] = target\ncorr = corr_data.corr()\nf, ax = plt.subplots(figsize=(15, 9))\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(200, 10, as_cmap=True),\n            square=True, ax=ax)","9e390d16":"ppipeline = Pipeline([\n     ('numeric_col_median_imp', mdi.MeanMedianImputer(\n            imputation_method=\"mean\", variables = numerical_cols)),\n    \n     ('categorical_col_imp', mdi.CategoricalVariableImputer(imputation_method = 'frequent', variables = categorical_cols)),\n    \n     (\"cardinality_reduce\", ce.RareLabelCategoricalEncoder(variables = categorical_cols)),\n    \n     ('categorical_to_ohe', ce.OneHotCategoricalEncoder(variables = categorical_cols)),\n    \n     ('normalizer', StandardScaler()),\n    \n     ('classifier', GradientBoostingClassifier()),\n    \n    ])\n\n    ","b477af8b":"cv = sk.model_selection.StratifiedKFold(n_splits=5, random_state=0)\ncross_val_scores = sk.model_selection.cross_val_score(ppipeline, trainset, target, cv=cv, scoring='roc_auc')","c5b90ff8":"cross_val_scores","cb3f5b55":"print('Mean of Stratified Cross Validation Score: ', np.mean(cross_val_scores))","658518d6":"ppipeline.fit(trainset, target)\nsubmission_df['Target'] = ppipeline.predict_proba(testset)[:, 1]","373dca93":"submission_df['Target']","e0ce66ed":"submission_df.head()","1f3c5f3d":"submission_df.to_csv(\"can_berk_kilic_final_submission.csv\", index = False)","dbff9c3c":"#Can Berk K\u0131l\u0131\u00e7\n#20161701044"}}