{"cell_type":{"2b77b857":"code","2da35fdd":"code","337e7cee":"code","b35fbef2":"code","59693e70":"code","f0ed84cf":"code","4477f516":"code","a66f44e8":"code","fe2e7710":"code","c712a5c0":"code","4d730abe":"code","55bb871f":"code","7783495f":"code","7870f305":"code","a1d186a0":"code","c2b1530c":"code","55a97bcd":"code","ee4c95b0":"code","c78f9188":"code","7d8b402e":"code","c51ef317":"code","09ad3545":"code","330f9ef3":"code","9189586a":"code","383285a9":"code","597fc726":"code","aa30752b":"code","07389906":"code","05557d43":"code","d99d555a":"code","22573ff0":"code","9aec6ae8":"code","2e252d6a":"code","39060827":"code","c8e7624c":"code","e690f89e":"code","78ad6ca1":"code","19a83c3d":"code","e03c249c":"code","cddca666":"code","f13667ad":"code","de145713":"code","bdc1a440":"code","4037a6db":"code","ca07d56f":"code","97894c8e":"code","7c36e6d9":"code","947a3dcf":"code","c2f6cc7c":"code","4cf23d06":"code","4a903bd5":"code","0412793d":"code","915b8b94":"code","ca4995ad":"code","67bbdd14":"code","900e114d":"code","ac26b2f1":"code","306ea13d":"code","60880d6a":"code","3bdedd7b":"code","0fe27299":"code","56e17872":"code","10fb96b8":"code","0a78a9f2":"code","370bb356":"code","1548c58d":"code","0a06aa1c":"code","d423e554":"code","ab4d598f":"code","e45f9a02":"code","9881000c":"code","0cb130ac":"code","fa31fd3e":"code","794cad41":"code","42308ebd":"code","5fbcb50f":"code","70978295":"code","bdc41472":"code","0c265620":"code","5343907b":"code","70043b03":"code","10ecdcb4":"code","dbfe773c":"code","1ad8db71":"code","798f8031":"code","e8753616":"code","39280dc1":"code","89c8afda":"code","e5221eca":"code","c0487856":"code","60a01f67":"code","7085eefa":"code","a4563929":"code","5fc6c615":"code","ca66c38c":"code","38974280":"code","839015f9":"code","21b88971":"code","cfb7811f":"code","54aee809":"code","fbebb231":"code","bdf1cdd8":"code","6cc690b6":"code","5bc64ab3":"code","b5c51962":"code","cfb7a402":"code","e6320eb7":"code","9e04c74f":"code","ed61be9c":"code","5e4f950f":"code","da7236a4":"code","dc3535b0":"code","4364733b":"code","962e0f4b":"code","95f31fec":"code","e3f4b929":"code","fabcbede":"code","b781f231":"code","25b9d41f":"code","91fabba4":"code","9e2a4501":"code","6b3e33b3":"code","6e004c88":"code","e5fcfcee":"code","247646cf":"code","7e0b0517":"code","ec46c6de":"code","9eb00332":"code","68eff00d":"code","0e7a6948":"code","63db5a84":"code","0d2aed36":"code","a13921e1":"code","be1dc47c":"code","294cd58e":"code","258ae711":"code","e63cf549":"code","acd911bb":"code","fcef35c5":"code","cc73b363":"code","ade34a62":"code","23dd7a27":"code","39e676c0":"code","41d4992c":"code","75f92caf":"code","8a82d01b":"code","5e541663":"code","4ed5be92":"code","684815fc":"code","af32a34c":"code","d862840c":"code","850f7a40":"code","11693cdb":"code","ff73e053":"code","4931c29e":"code","2a5ee88e":"code","8e062c35":"code","fb5c55a2":"code","f5597f14":"code","f003eefe":"code","10cd55f3":"code","414d062d":"code","ce49e464":"code","4bad2085":"code","7139aceb":"code","6cf9fcfb":"code","9fccc805":"code","d470d6fa":"code","44d5a85d":"code","a2eadc5a":"code","6dc86eab":"code","63374b9f":"code","a059737b":"code","4050a908":"code","731489c6":"code","ba32b177":"code","1c888b04":"code","f7af4eb9":"code","6ddb29aa":"code","4a59c879":"code","099a1999":"code","41fc8bf5":"code","32a19713":"code","897e3a17":"code","acb7fa8b":"code","2bec9604":"code","f38bb4e0":"code","b099eaf1":"code","98cb1420":"code","695ae8bf":"code","b3451e93":"code","1a87d870":"code","06b9ec39":"code","1ee9808e":"code","3123c4a8":"code","e8790977":"code","58ccf38d":"code","1eb728b1":"code","489e171a":"code","bb262cde":"code","0a227232":"code","32562d41":"code","abed4079":"code","3853c3f7":"code","6116b641":"code","e7e5c753":"code","0536e7bf":"code","00fab995":"code","d1bb8d99":"code","1cd79eb7":"code","d20aeefa":"code","1308472e":"code","e4b334d5":"code","f4a438cf":"code","f15df892":"code","d104dff1":"markdown","fde3f88b":"markdown","5494b1a8":"markdown","f800e4ad":"markdown","1934eadb":"markdown","7c3b9c9e":"markdown","3cf5f3f7":"markdown","6f061310":"markdown","44d61d49":"markdown","8668f216":"markdown","998035dc":"markdown","3f2af622":"markdown","73263b1a":"markdown","c088a03c":"markdown","391345bd":"markdown","f67eaad8":"markdown"},"source":{"2b77b857":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2da35fdd":"multi_response_path = '\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv'\ntext_response_path = '\/kaggle\/input\/kaggle-survey-2019\/other_text_responses.csv'\nquestion_path = '\/kaggle\/input\/kaggle-survey-2019\/questions_only.csv'\nsurvey_schema_path = '\/kaggle\/input\/kaggle-survey-2019\/survey_schema.csv'","337e7cee":"# reading csv file  \nmulti_response = pd.read_csv(multi_response_path)\ntext_response = pd.read_csv(text_response_path)\nquestion = pd.read_csv(question_path)\nsurvey = pd.read_csv(survey_schema_path)","b35fbef2":"# basic function of python\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sb\n%matplotlib inline\nimport numpy as np\nfrom pandas import ExcelWriter\nfrom pandas import ExcelFile\nimport xlrd\nfrom scipy import stats\nfrom datetime import datetime\n\n# feature selection\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import feature_selection\n\n# oversampling\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\n\n# building the models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# import tensorflow\n# from tensorflow.contrib.keras import models, layers\n# from tensorflow.contrib.keras import activations, optimizers, losses\n\n# standardize the vaiable\nfrom sklearn.preprocessing import StandardScaler\n\n# from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# validation\nfrom sklearn.metrics import confusion_matrix,classification_report","59693e70":"multi_response.dtypes","f0ed84cf":"print (f'Shape of multiple choice responses: {multi_response.shape}')\nprint (f'Shape of questions only: {question.shape}')\nprint (f'Shape of survey schema: {survey.shape}')\nprint (f'Shape of text responses: {text_response.shape}')","4477f516":"multi_response.head()","a66f44e8":"text_response.head()","fe2e7710":"question.head()","c712a5c0":"survey['2019 Kaggle Machine Learning and Data Science Survey']","4d730abe":"multi_response = multi_response.drop([0])\nmulti_response = multi_response.reset_index(drop=True)\nmulti_response.head()","55bb871f":"X_enc = multi_response.copy()","7783495f":"X_enc = pd.get_dummies(X_enc, columns=['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8',\\\n                                       'Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8',\\\n                                       'Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12',\\\n                                       'Q13_Part_1','Q13_Part_2','Q13_Part_3','Q13_Part_4','Q13_Part_5','Q13_Part_6','Q13_Part_7','Q13_Part_8',\\\n                                       'Q13_Part_9','Q13_Part_10','Q13_Part_11','Q13_Part_12',\\\n                                       'Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_5','Q16_Part_6','Q16_Part_7','Q16_Part_8',\\\n                                       'Q16_Part_9','Q16_Part_10','Q16_Part_11','Q16_Part_12',\\\n                                       'Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_4','Q17_Part_5','Q17_Part_6','Q17_Part_7','Q17_Part_8',\\\n                                       'Q17_Part_9','Q17_Part_10','Q17_Part_11','Q17_Part_12',\\\n                                       'Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_Part_7','Q18_Part_8',\\\n                                       'Q18_Part_9','Q18_Part_10','Q18_Part_11','Q18_Part_12',\\\n                                       'Q20_Part_1','Q20_Part_2','Q20_Part_3','Q20_Part_4','Q20_Part_5','Q20_Part_6','Q20_Part_7','Q20_Part_8',\\\n                                       'Q20_Part_9','Q20_Part_10','Q20_Part_11','Q20_Part_12',\\\n                                       'Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5',\\\n                                       'Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8',\\\n                                       'Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12',\\\n                                       'Q25_Part_1','Q25_Part_2','Q25_Part_3','Q25_Part_4','Q25_Part_5','Q25_Part_6','Q25_Part_7','Q25_Part_8',\\\n                                       'Q26_Part_1','Q26_Part_2','Q26_Part_3','Q26_Part_4','Q26_Part_5','Q26_Part_6','Q26_Part_7',\\\n                                       'Q27_Part_1','Q27_Part_2','Q27_Part_3','Q27_Part_4','Q27_Part_5','Q27_Part_6',\\\n                                       'Q28_Part_1','Q28_Part_2','Q28_Part_3','Q28_Part_4','Q28_Part_5','Q28_Part_6','Q28_Part_7','Q28_Part_8',\\\n                                       'Q28_Part_9','Q28_Part_10','Q28_Part_11','Q28_Part_12',\\\n                                       'Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7','Q29_Part_8',\\\n                                       'Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12',\\\n                                       'Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8',\\\n                                       'Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_Part_12',\\\n                                       'Q31_Part_1','Q31_Part_2','Q31_Part_3','Q31_Part_4','Q31_Part_5','Q31_Part_6','Q31_Part_7','Q31_Part_8',\\\n                                       'Q31_Part_9','Q31_Part_10','Q31_Part_11','Q31_Part_12',\\\n                                       'Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8',\\\n                                       'Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12',\\\n                                       'Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8',\\\n                                       'Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12',\\\n                                       'Q34_Part_1','Q34_Part_2','Q34_Part_3','Q34_Part_4','Q34_Part_5','Q34_Part_6','Q34_Part_7','Q34_Part_8',\\\n                                       'Q34_Part_9','Q34_Part_10','Q34_Part_11','Q34_Part_12'])","7870f305":"X_enc.head()","a1d186a0":"# X_enc = X_enc.drop(['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8',\\\n#                                        'Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8',\\\n#                                        'Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12',\\\n#                                        'Q13_Part_1','Q13_Part_2','Q13_Part_3','Q13_Part_4','Q13_Part_5','Q13_Part_6','Q13_Part_7','Q13_Part_8',\\\n#                                        'Q13_Part_9','Q13_Part_10','Q13_Part_11','Q13_Part_12',\\\n#                                        'Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_5','Q16_Part_6','Q16_Part_7','Q16_Part_8',\\\n#                                        'Q16_Part_9','Q16_Part_10','Q16_Part_11','Q16_Part_12',\\\n#                                        'Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_4','Q17_Part_5','Q17_Part_6','Q17_Part_7','Q17_Part_8',\\\n#                                        'Q17_Part_9','Q17_Part_10','Q17_Part_11','Q17_Part_12',\\\n#                                        'Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_Part_7','Q18_Part_8',\\\n#                                        'Q18_Part_9','Q18_Part_10','Q18_Part_11','Q18_Part_12',\\\n#                                        'Q20_Part_1','Q20_Part_2','Q20_Part_3','Q20_Part_4','Q20_Part_5','Q20_Part_6','Q20_Part_7','Q20_Part_8',\\\n#                                        'Q20_Part_9','Q20_Part_10','Q20_Part_11','Q20_Part_12',\\\n#                                        'Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5',\\\n#                                        'Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_Part_8',\\\n#                                        'Q24_Part_9','Q24_Part_10','Q24_Part_11','Q24_Part_12',\\\n#                                        'Q25_Part_1','Q25_Part_2','Q25_Part_3','Q25_Part_4','Q25_Part_5','Q25_Part_6','Q25_Part_7','Q25_Part_8',\\\n#                                        'Q26_Part_1','Q26_Part_2','Q26_Part_3','Q26_Part_4','Q26_Part_5','Q26_Part_6','Q26_Part_7',\\\n#                                        'Q27_Part_1','Q27_Part_2','Q27_Part_3','Q27_Part_4','Q27_Part_5','Q27_Part_6',\\\n#                                        'Q28_Part_1','Q28_Part_2','Q28_Part_3','Q28_Part_4','Q28_Part_5','Q28_Part_6','Q28_Part_7','Q28_Part_8',\\\n#                                        'Q28_Part_9','Q28_Part_10','Q28_Part_11','Q28_Part_12',\\\n#                                        'Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7','Q29_Part_8',\\\n#                                        'Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12',\\\n#                                        'Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8',\\\n#                                        'Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_Part_12',\\\n#                                        'Q31_Part_1','Q31_Part_2','Q31_Part_3','Q31_Part_4','Q31_Part_5','Q31_Part_6','Q31_Part_7','Q31_Part_8',\\\n#                                        'Q31_Part_9','Q31_Part_10','Q31_Part_11','Q31_Part_12',\\\n#                                        'Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8',\\\n#                                        'Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12',\\\n#                                        'Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8',\\\n#                                        'Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12',\\\n#                                        'Q34_Part_1','Q34_Part_2','Q34_Part_3','Q34_Part_4','Q34_Part_5','Q34_Part_6','Q34_Part_7','Q34_Part_8',\\\n#                                        'Q34_Part_9','Q34_Part_10','Q34_Part_11','Q34_Part_12'],axis=1)","c2b1530c":"#FinalData = pd.concat([multi_response,X_enc], axis=1)","55a97bcd":"X_enc = X_enc.drop(['Q2_OTHER_TEXT','Q5_OTHER_TEXT','Q9_OTHER_TEXT','Q12_OTHER_TEXT','Q13_OTHER_TEXT','Q14_Part_1_TEXT','Q14_Part_2_TEXT','Q14_Part_3_TEXT',\\\n                            'Q14_Part_4_TEXT','Q14_Part_5_TEXT','Q14_OTHER_TEXT','Q16_OTHER_TEXT','Q17_OTHER_TEXT','Q18_OTHER_TEXT','Q19_OTHER_TEXT',\\\n                            'Q20_OTHER_TEXT','Q21_OTHER_TEXT','Q24_OTHER_TEXT','Q25_OTHER_TEXT','Q26_OTHER_TEXT','Q27_OTHER_TEXT','Q28_OTHER_TEXT',\\\n                            'Q29_OTHER_TEXT','Q30_OTHER_TEXT','Q31_OTHER_TEXT','Q32_OTHER_TEXT','Q33_OTHER_TEXT','Q34_OTHER_TEXT'],axis=1)","ee4c95b0":"X_enc.dtypes","c78f9188":"X_enc.head()","7d8b402e":"plt.figure(figsize=(10,5))\nsb.countplot(x = 'Q2',data = X_enc)\nplt.show()","c51ef317":"plt.figure(figsize=(10,5))\nsb.countplot(x = 'Q3',data = X_enc)\nplt.xticks(rotation=90)\nplt.show()","09ad3545":"# Let's see top10 countries more detailed.\nX_enc['Q3'].value_counts()[:10].reset_index()","330f9ef3":"top_10_country = X_enc['Q3'].value_counts()[:10].reset_index()","9189586a":"#Pie Chart\ntop_10_country['Q3'] = top_10_country['Q3']*100\/top_10_country['Q3'].sum()\n#explode=(0.1,0,0,0,0,0,0,0,0,0)\ncolors=['g','b','r','c','m','y','r','k','m','b']\nfig, ax=plt.subplots(figsize=(10,5))\nax.pie(top_10_country['Q3'],labels = top_10_country['index'],colors=colors)\nplt.tight_layout()\nplt.show()","383285a9":"plt.figure(figsize=(12,5))\nsb.countplot(x = 'Q1',hue = 'Q2',data = X_enc)\nplt.show()","597fc726":"job = pd.DataFrame(X_enc.iloc[1:]['Q5'].value_counts().sort_values(ascending=False)).reset_index().head(25)\njob","aa30752b":"plt.figure(figsize=(12,5))\nsb.barplot(x=job['Q5'],y=job['index'], palette='viridis')\nplt.xlabel('Count')\nplt.ylabel('', fontsize=10)\nplt.xticks(rotation=0)\nplt.yticks(rotation=0)\nplt.title('Job title')","07389906":"job = X_enc['Q5'].value_counts()\njob","05557d43":"#total = int(X_enc.iloc[1]['Q19'])\nplt.figure(figsize=(12,5))\nax = sb.barplot(X_enc.groupby(['Q19']).size().reset_index(name='counts')['Q19'][:-1], X_enc.groupby(['Q19']).size().reset_index(name='counts')['counts'][:-1])","d99d555a":"# checking the imbalance\nsb.countplot(x='Q10',data=X_enc,palette='RdBu_r') # Barplot for the dependent variable","22573ff0":"X_enc['Q10'].value_counts()","9aec6ae8":"# # Category variables -> Numerical variables\nlist_feat=['Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q10','Q11','Q14','Q15','Q19','Q22','Q23']","2e252d6a":"for feature in list_feat:\n    labels = X_enc[feature].astype('category').cat.categories.tolist()\n    replace_map_comp = {feature : {k: v for k,v in zip(labels,list(range(0,len(labels)+1)))}}\n\n    X_enc.replace(replace_map_comp, inplace=True)","39060827":"X_enc.head()","c8e7624c":"#Rename the columns for better understanding\ndata = X_enc.rename(columns={\n             'Time from Start to Finish (seconds)':'Time duration',\n             'Q1':'Age',\n             'Q2':'Gender',\n             'Q3':'Country',\n             'Q4':'Education level',\n             'Q5':'Job title',\n             'Q6':'Company size',\n             'Q7':'The number of data scientist in company',\n             'Q8':'ML implementaion in company',\n             #Q9: Activities that make up an important part of your role at work(Multiple choices)\n            'Q10':'Yearly compensation',\n            'Q11':'Investment on ML',\n            #Q12: Favorite media sources that report on data science topics(Multiple choices)\n            #Q13: Which platforms for studying data science(Multiple choices)\n            'Q14':'Primary tool used for ML',\n            'Q15':'Coding experience',\n            #Q16: Integrated development environments (IDE's) you use on a regular basis(Multiple choices)\n            #Q17: Hosted notebook products you use on a regular basis(Multiple choices)\n            #Q18: Programming languages you use on a regular basis(Multiple choices)\n            'Q19': 'Programming language to learn first',\n            #Q20: Data visualization libraries or tools you use on a regular basis(Multiple choices)\n            #Q21: Specialized hardware you use on a regular basis(Multiple choices)\n            'Q22':'Experience in TPU',\n            'Q23': 'Years in using machine learning methods'\n            #Q24: ML algorithms you use on a regular basis(Multiple choices)\n            #Q25: Categories of ML tools you use on a regular basis(Multiple choices)\n            #Q26: Categories of computer vision methods you use on a regular basis(Multiple choices)\n            #Q27: Natural language processing (NLP) methods you use on a regular basis(Multiple choices)\n            #Q28: Machine learning frameworks you use on a regular basis(Multiple choices)\n            #Q29: Cloud computing platforms you use on a regular basis(Multiple choices)\n            #Q30: Specific cloud computing products you use on a regular basis(Multiple choices)\n            #Q31: Specific big data \/ analytics products you use on a regular basis(Multiple choices)\n            #Q32: Machine learning products you use on a regular basis(Multiple choices)\n            #Q33: Automated machine learning tools (or partial AutoML tools) you use on a regular basis(Multiple choices)\n            #Q34: Relational database products do you use on a regular basis(Multiple choices)\n\n})","e690f89e":"data.head()","78ad6ca1":"data.shape","19a83c3d":"data['Time duration'] = data['Time duration'].apply(pd.to_numeric)\n#data['Time duration'] = data['Time duration'].astype('int')","e03c249c":"data.isnull() # Checking missing values","cddca666":"# There are too many variables so heatmap is not useful\nsb.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","f13667ad":"missing_data = data.isnull()\nmissing_data.head(5)","de145713":"for column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")","bdc1a440":"data.shape","4037a6db":"final_data = data.dropna()","ca07d56f":"final_data.shape","97894c8e":"final_data.head()","7c36e6d9":"# Import the random forest model.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX = final_data.iloc[:, np.r_[:,0:9,10:218]]  #independent columns\ny = final_data.iloc[:, np.r_[:,9]]   #target column: salary\n\n# This line instantiates the model. \nmodel3 = RandomForestClassifier() \n# Fit the model on your training data.\nmodel3.fit(X, y)\nfeature_importances = pd.DataFrame(model3.feature_importances_,\n                                   index = X.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nfeature_importances","947a3dcf":"(pd.Series(model3.feature_importances_, index=X.columns).nlargest(20).plot(kind='barh'))","c2f6cc7c":"from xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\nX = final_data.iloc[:, np.r_[:,0:9,10:218]]  #independent columns\ny = final_data.iloc[:, np.r_[:,9]]   #target column: salary\n# fit model no training data\nmodel2 = XGBClassifier()\nmodel2.fit(X,y)\n# feature importance\nprint(model2.feature_importances_)\n# plot feature importance\n\nplt.figure(figsize=(3,6))\nplot_importance(model2,max_num_features=20)\nplt.show()","4cf23d06":"X = final_data.iloc[:, np.r_[:,0:9,10:218]]  #independent columns\ny = final_data.iloc[:, np.r_[:,9]]   #target column: salary\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel1 = ExtraTreesClassifier()\nmodel1.fit(X,y)\nprint(model1.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model1.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","4a903bd5":"# X = final_data.iloc[:, np.r_[:,0:9,10:218]]  #independent columns\n# y = final_data.iloc[:, np.r_[:,9]]   #target column: Salary\n# #get correlations of each features in dataset\n# corrmat = final_data.corr()\n# top_corr_features = corrmat.index\n# plt.figure(figsize=(20,20))\n# #plot heat map\n# g=sb.heatmap(final_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","0412793d":"multi_response.head()","915b8b94":"req = multi_response[1:]","ca4995ad":"req['Q7']","67bbdd14":"####Checking the proportion of survey takers ----> large interest shown by 25-29 year old age group ----> find the distribtuion ohis population by country\nage_group = req.groupby(['Q1'],as_index=False).count().reset_index().loc[:,'Q1':'Time from Start to Finish (seconds)']","900e114d":"age_group.sort_values('Time from Start to Finish (seconds)', inplace=True)","ac26b2f1":"# import seaborn as sns\n# sns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\n# ax = sns.barplot(x=\"Q1\", y=\"Time from Start to Finish (seconds)\", data=age_group)\n# ax.set(xlabel='Age Group Participating In The Survey', ylabel='Number of people participating in the survey')","306ea13d":"#Age group 25-29\nage_25 = req[req.Q1 == \"25-29\"]","60880d6a":"age_25_educ = age_25.groupby(['Q4'],as_index=False)[['Q1']].count()","3bdedd7b":"age_25_educ","0fe27299":"age_25_educ.sort_values('Q1',inplace=True)","56e17872":"#Preliminary visualization ---> most people in this age group are pursuing a Master's degree,followed by Bachelor's, Master's and phD\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(1, 1, figsize=(35,15))\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q4\", y=\"Q1\", data=age_25_educ)\nax.set_title(\"Proportion of participants between 25-29 years pursuing different professions\",fontsize=20)\nax.set(xlabel='Professional Degree being pursued by age_group 25-29', ylabel='Number of people participating in the survey')","10fb96b8":"#AGE GROUP DISRTRIBUTION BY GENDER --->\ngender_age_25 = age_25.groupby(['Q2'],as_index=False)[['Q1']].count()","0a78a9f2":"gender_age_25.sort_values('Q1',inplace=True)","370bb356":"gender_age_25.reset_index(drop=True)","1548c58d":"#Preliminary visualization ---> most people in this age group are pursuing a Master's degree,followed by Bachelor's, Master's and phD\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(1, 1, figsize=(20,10))\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q2\", y=\"Q1\", data=gender_age_25)\nax.set_title(\"Gender Proportion of participants between 25-29 years \",fontsize=20)\nax.set(xlabel='Gender of participant in the age_group 25-29', ylabel='Number of people participating in the survey')","0a06aa1c":"#between ages 25-29 by country\ncountry_age_25 = age_25.groupby(['Q3'],as_index=False)[['Q1']].count()","d423e554":"country_age_25.reset_index(drop=True)","ab4d598f":"# Prepare Data\ncountry_age_25.sort_values('Q1',inplace=True)\n#country.reset_index(inplace=True)\n\n# Draw plot\nimport matplotlib.patches as patches\n\nfig, ax = plt.subplots(figsize=(16,10), facecolor='white', dpi= 80)\nax.vlines(x=country_age_25.index, ymin=0, ymax=country_age_25.Q1, color='firebrick', alpha=0.7, linewidth=20)\n\n# Annotate Text\nfor i, q1 in enumerate(country_age_25.Q1):\n    ax.text(i, q1+0.5, round(q1, 1), horizontalalignment='center')\n\n\n# Title, Label, Ticks and Ylim\nax.set_title('Bar Chart for Proportion of Survey Attempts by participants between 25-29 by Country distribution', fontdict={'size':22})\nax.set(ylabel='Number of 25-29 year old people participated in survey', ylim=(0, 1500))\nax.set(xlabel='Country participating in Survey')\nplt.xticks(country_age_25.index, country_age_25.Q3.str.upper(), rotation=60, horizontalalignment='right', fontsize=12)\n\n# Add patches to color the X axis labels\np1 = patches.Rectangle((.57, -0.005), width=.33, height=.13, alpha=.1, facecolor='green', transform=fig.transFigure)\np2 = patches.Rectangle((.124, -0.005), width=.446, height=.13, alpha=.1, facecolor='red', transform=fig.transFigure)\nfig.add_artist(p1)\nfig.add_artist(p2)\nplt.show()","e45f9a02":"########25-29 year olds different professions\nprofession_age_25 = age_25.groupby(['Q5'],as_index=False)[['Q1']].count()","9881000c":"profession_age_25.sort_values('Q1',inplace=True)","0cb130ac":"profession_age_25.reset_index(drop=True)","fa31fd3e":"profession_age_25['Q5'] = profession_age_25[profession_age_25['Q5']!=0]","794cad41":"#Preliminary visualization ---> most people in this age group are pursuing a Master's degree,followed by Bachelor's, Master's and phD\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(1, 1, figsize=(25,10))\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q5\", y=\"Q1\", data=profession_age_25)\nax.set_title(\"Work Profession of participants between 25-29 years \",fontsize=20)\nax.set(xlabel='Profession of participant in the age_group 25-29', ylabel='Number of people participating in the survey')","42308ebd":"#LARGE NOT EMPLOYED CROWD INTERESTED....OTHER <----> proportion of unemployed people interested by country\n#increase number of unemployed people in specific country <----> look at growth of machine learning in these countries\nunemployed = req[req['Q5']=='Not employed']","5fbcb50f":"unemployed.reset_index(drop=True)","70978295":"#CHECK PROPORTION OF UNEMPLOYED PEOPLE BY EDUCATION...AND GENDER...AND COUNTRY...AND AGE GROUPS\nunemployed_by_country = unemployed.groupby(['Q3','Q1']).count().reset_index().loc[:,'Q3':'Time from Start to Finish (seconds)']","bdc41472":"unemployed_by_country.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","0c265620":"unemployed_by_country","5343907b":"import pandas as pd\n\npivot = pd.pivot_table(unemployed_by_country, index='Q3', columns='Q1', values='Frequency')","70043b03":"ax = pivot.plot(kind='bar', figsize=(40,20),fontsize=20)\nylab = ax.set_ylabel('Number of paticipants Unemployed',fontsize=20)\nxlab = ax.set_xlabel('Country',fontsize=20)\n#stacked=True,","10ecdcb4":"###AREAS OF INTERESTED UNEMPLOYED NUMBER IN THE AGE-GROUPS 25-29,30-34,35-39,40-44,45-49,\nunemployed.groupby(['Q3', 'Q1']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))","dbfe773c":"####Check unemployed rates by highest level of education attained of participants\nax = unemployed.groupby(['Q4', 'Q1']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\nax.set_xlabel(\"Professional degree attained by participant\",fontsize=15)\nax.set_ylabel(\"Number of Unemployed Participants by Age\",fontsize=15)\nax.legend(title=\"Age-Groups of participants\")","1ad8db71":"#Number of unemployed people giving the survey by country\nax = unemployed.groupby(['Q3', 'Q4']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\nax.set_xlabel(\"Country of participant\",fontsize=15)\nax.set_ylabel(\"Number of unemployed participants by acquired level of education\",fontsize=15)\nax.set_title(\"Proportion of acquired levels of education by unemployed participants across different countries\")\nax.legend(title = \"List of levels of education of participants\")","798f8031":"#Distribution of various levels of education across different countries\nax = req.groupby(['Q3', 'Q4']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\nax.set_xlabel(\"Countries\",fontsize=15)\nax.set_ylabel(\"Number of People posessing a certain level of education\",fontsize=15)\nax.set_title(\"Proportion of level of education of different participants across the countries\",fontsize=20)\nax.legend(title=\"Professional degree attained by participant\")","e8753616":"#Gender<--->Education Level proportions\nr = req[(req['Q2']==\"Male\")|(req['Q2']==\"Female\")]","39280dc1":"re = r[r['Q4'] != 0]","89c8afda":"re.groupby(['Q4', 'Q2']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\nax.set_xlabel(\"Level of education attained\",fontsize=15)\nax.set_ylabel(\"Number of People posessing a certain level of education distributed by gender\",fontsize=15)\nax.set_title(\"Gender distribution of Highest level of education attained\",fontsize=20)\nax.legend(title=\"Gender of participant\")","e5221eca":"#Distribution of gender and profession\nax = req.groupby(['Q5', 'Q2']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\nax.set_xlabel(\"Current Role of Participant\",fontsize=15)\nax.set_ylabel(\"Number of People distributed by Gender\",fontsize=15)\nax.set_title(\"Gender distribution of Work Roles of Participants\",fontsize=20)\nax.legend(title=\"Gender of participant\")","c0487856":"##############ABOVE PLOTS CAN BE GENERATED FOR EACH COUNTRY ???\nl = req.Q3.unique()\nfor num in l:\n    if num in ['India','']:\n        m = req[req['Q3']==num]\n        ax = m.groupby(['Q5', 'Q2']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\n        ax.set_xlabel(\"Current Role of Participant\",fontsize=15)\n        ax.set_ylabel(\"Number of People distributed by Gender\",fontsize=15)\n        ax.set_title(\"Gender distribution of Work Roles of Participants in {}\".format(num),fontsize=20)\n        ax.legend(title=\"Gender of participant\")","60a01f67":"l = req.Q3.unique()\nfor num in l:\n    m = req[req['Q3']==num]\n    ax = m.groupby(['Q4', 'Q2']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\n    ax.set_xlabel(\"Current Role of Participant\",fontsize=15)\n    ax.set_ylabel(\"Number of People distributed by Gender\",fontsize=15)\n    ax.set_title(\"Gender distribution of Work Roles of Participants in {}\".format(num),fontsize=20)\n    ax.legend(title=\"Gender of participant\")","7085eefa":"################GENDER IMBALANCED CATEGORY <----> DEVELOP INSIGHTS BASED ON BALANCED FEATURE <---> DISTRIBUTION OF WORK PROFESSIONS AND SIZE OF COMPANY\nl = req.Q3.unique()\nfor num in l:\n    m = req[(req['Q3']==num)&(req['Q6']!=0)&(req['Q5']!=0)]\n    ax = m.groupby(['Q6', 'Q5']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\n    ax.set_xlabel(\"Current Size of Company Employed In\",fontsize=15)\n    ax.set_ylabel(\"Number of People distributed by work position\",fontsize=15)\n    ax.set_title(\"Work Roles of Participants in {} distributed by Size Company\".format(num),fontsize=20)\n    ax.legend(title=\"Work Role of participant\")","a4563929":"###########HAVE TO ANALYZE OTHER RESPONSES FOR ROLES <---> what profession exists more with a particular company size<---> focus on what softwares\/ technologies are used\n#******compare the level of work experience and the advancement in technologies and softwares used across different countries*********#","5fc6c615":"#####Compare the tools and softwares used by data scientists, \n##############ABOVE PLOTS CAN BE GENERATED FOR EACH COUNTRY ???\nl = req.Q3.unique()\nfor num in l:\n    m = req[req['Q3']==num]\n    ax = m.groupby(['Q4', 'Q2']).size().unstack().plot(kind='bar', stacked=True,figsize=(20,10))\n    ax.set_xlabel(\"Highest Education Attained By Participant\",fontsize=15)\n    ax.set_ylabel(\"Number of People distributed by Gender\",fontsize=15)\n    ax.set_title(\"Gender distribution of Education of Participants in {}\".format(num),fontsize=20)\n    ax.legend(title=\"Gender of participant\")","ca66c38c":"s = ['Q12_Part_1','Q12_Part_2','Q12_Part_3']\nsources = ['Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8','Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12']\nl = list()\nfor i in sources:\n    df = req.groupby([i]).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Source_for_learning'}, inplace = True)\n    l.append(df)","38974280":"fav_sources_to_learn_from = pd.concat(l)","839015f9":"fav_sources_to_learn_from = fav_sources_to_learn_from[fav_sources_to_learn_from['Source_for_learning']!=0]","21b88971":"fstlf = fav_sources_to_learn_from.sort_values('Frequency',ascending=False)","cfb7811f":"f = fstlf.reset_index(drop=True)\nf","54aee809":"import seaborn as sns\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(1, 1, figsize=(90,20))\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Source_for_learning\", y=\"Frequency\", data=f)\nax.set_title(\"Distribution of different sources of learning used by our participants \".format(i))\nax.set(xlabel='Source for learning used', ylabel='Frequency')\nax.tick_params(axis = 'both', which = 'major', labelsize = 15)\nax.tick_params(axis = 'both', which = 'minor', labelsize = 15)","fbebb231":"l = req.Q3.unique()\nsources = ['Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8','Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12']\nl = list()\nfor i in sources:\n    df = req.groupby([i,'Q3']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Source_for_learning'}, inplace = True)\n    l.append(df)","bdf1cdd8":"sources_to_learn_by_country = pd.concat(l)","6cc690b6":"sources_to_learn_by_country = sources_to_learn_by_country[sources_to_learn_by_country.Source_for_learning!=0]","5bc64ab3":"stl = sources_to_learn_by_country.reset_index(drop=True)\nstl","b5c51962":"#####REQUIRED COUNTRY LIST TO ANALYZE COMPARISON OF PREFERENCE OF DIFFERENT SOURCES OF LEARNING\ncountries = req.Q3.unique()\nfor i in countries:\n    d = stl[stl['Q3']==i]\n    dr = d.reset_index(drop=True)\n    sns.set(style=\"whitegrid\")\n    fig, ax = plt.subplots(1, 1, figsize=(90,20))\n#     tips = sns.load_dataset(\"tips\")\n    ax = sns.barplot(x=\"Source_for_learning\", y=\"Frequency\", data=dr)\n    ax.set_title(\"Distribution of different sources of learning preferred by participants in {}\".format(i),fontsize=30)\n    ax.set(xlabel='Source for learning used', ylabel='Frequency')\n    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)\n    ax.tick_params(axis = 'both', which = 'minor', labelsize = 15)\n\n#IRELAND --> Increased Youtube\n#SLACK Communities ---> Russia\n#SAUDI, ALGERIA--> Youtube over kaggle","cfb7a402":"########REQUIRED SOURCE FOR LEARNING LIST TO ANALYZE THE USAGE OF EACH SOURCE ACROSS DIFFERENT COUNTRIES\nsources = stl.Source_for_learning.unique()\nfor i in sources:\n    d = stl[stl['Source_for_learning']==i]\n    dr = d.reset_index(drop=True)\n    sns.set(style=\"whitegrid\")\n    fig, ax = plt.subplots(1, 1, figsize=(110,30))\n#     tips = sns.load_dataset(\"tips\")\n    ax = sns.barplot(x=\"Q3\", y=\"Frequency\", data=dr)\n    ax.set_title(\"Distribution of different participants from different countries using {}\".format(i),fontsize=30)\n    ax.set(xlabel='Source for learning used', ylabel='Frequency')\n    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)\n    ax.tick_params(axis = 'both', which = 'minor', labelsize = 15)","e6320eb7":"#Find distribution of main source of learning by age group --> see which audience is better target audience\nl = req.Q3.unique()\nsources = ['Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8','Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12']\nl = list()\nfor i in sources:\n    df = req.groupby([i,'Q1']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Source_for_learning'}, inplace = True)\n    l.append(df)","9e04c74f":"sources_to_learn_by_age = pd.concat(l)","ed61be9c":"sources_to_learn_by_age = sources_to_learn_by_age[sources_to_learn_by_age.Source_for_learning!=0]","5e4f950f":"stla = sources_to_learn_by_age.reset_index(drop=True)\nstla","da7236a4":"####\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(stla.index, stla.Q1.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q1\", y=\"Frequency\", hue=\"Source_for_learning\", data=stla)\nax.legend(fontsize=20)\nax.set_title('Distribution of preferred source reporting data science by age group',fontsize=20)\nax.set(xlabel='Age Group', ylabel='Distribution of age groups of people participating in the survey')\n\n\n##############Older people tend to stick to paper version of information... might explain why there is a higher proportion of 70plus people dependng on journal publications\n############18-29 reddit increases and then steady decline; same for kaggle\n############","dc3535b0":"###age distribution by country ...\n##########more visual analysis required\nl = req.Q3.unique()\nsources = ['Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_Part_6','Q12_Part_7','Q12_Part_8','Q12_Part_9','Q12_Part_10','Q12_Part_11','Q12_Part_12']\nl = list()\nfor i in sources:\n    df = req.groupby([i,'Q1','Q3']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Source_for_learning'}, inplace = True)\n    l.append(df)\ncountries = req.Q3.unique()\nsources_to_learn_by_age = pd.concat(l)\nsources_to_learn_by_age = sources_to_learn_by_age[sources_to_learn_by_age.Source_for_learning!=0]\nstla = sources_to_learn_by_age.reset_index(drop=True)\nfor i in countries:\n    d = stla[stla['Q3']==i]\n    dr = d.reset_index(drop=True)\n    sns.set(style=\"whitegrid\")\n    fig, ax = plt.subplots(1, 1, figsize=(90,20))\n#     tips = sns.load_dataset(\"tips\")\n    ax = sns.barplot(x=\"Q1\", y=\"Frequency\", hue=\"Source_for_learning\", data=dr)\n    ax.legend(fontsize=20)\n    ax.set_title('Distribution of preferred source reporting data science by age group in country {}'.format(i),fontsize=20)\n    ax.set(xlabel='Age Group', ylabel='Distribution of age groups of people participating in the survey')\n    ax.legend(loc='best')","4364733b":"########Just a fun dive at q9 <----> category -> \"None of these activites are an important part of my role at work\"\n###########See the popuplations where the curiosity to learn the language exists <----> age group grouping, country grouping\n#Q9 ---> Has 8 parts\nl = req.Q3.unique()\nrole_at_work = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8']\nl = list()\nfor i in role_at_work:\n    df = req.groupby([i,'Q1']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Role_at_Work'}, inplace = True)\n    l.append(df)","962e0f4b":"role_at_work = pd.concat(l)","95f31fec":"role_at_work","e3f4b929":"role_at_work = role_at_work[role_at_work.Role_at_Work != 0]","fabcbede":"####\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(role_at_work.index, role_at_work.Q1.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q1\", y=\"Frequency\", hue=\"Role_at_Work\", data=role_at_work)\nax.legend(fontsize=20)\nax.set_title('Distribution of Role at work by age group',fontsize=20)\nax.set(xlabel='Age Group', ylabel='Distribution of role at work of people participating in the survey')\n\n\n##############Older people tend to stick to paper version of information... might explain why there is a higher proportion of 70plus people dependng on journal publications\n############18-29 reddit increases and then steady decline; same for kaggle\n############","b781f231":"###NOT MUCH INSIGHT BY GENDER DISTRIBUTION\n\nrole_at_work = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8']\nl = list()\nfor i in role_at_work:\n    df = req.groupby([i,'Q2']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Role_at_Work'}, inplace = True)\n    l.append(df)","25b9d41f":"role_at_work_gender = pd.concat(l)","91fabba4":"role_at_work_gender = role_at_work_gender[role_at_work_gender.Role_at_Work != 0]\nrole_at_work_gender","9e2a4501":"import seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(role_at_work_gender.index, role_at_work_gender.Q2.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q2\", y=\"Frequency\", hue=\"Role_at_Work\", data=role_at_work_gender)\nax.legend(fontsize=20)\nax.set_title('Distribution of Role at work by gender',fontsize=20)\nax.set(xlabel='Gender', ylabel='Distribution of gender of people participating in the survey')","6b3e33b3":"role_at_work = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8']\nl = list()\nfor i in role_at_work:\n    df = req.groupby([i,'Q6']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Role_at_Work'}, inplace = True)\n    l.append(df)","6e004c88":"role_at_work_size = pd.concat(l)","e5fcfcee":"role_at_work_size = role_at_work_size[role_at_work_size.Role_at_Work != 0]","247646cf":"import seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(role_at_work_size.index, role_at_work_size.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Role_at_Work\", data=role_at_work_size)\nax.legend(fontsize=20)\nax.set_title('Distribution of Role at work by size of company',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Distribution of role at work of participants participating in the survey')\n\n\n\n\n#is ML finding more tendency for application in smaller scaled companies ?????","7e0b0517":"import seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(role_at_work_size.index, role_at_work_size.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Role_at_Work\", data=role_at_work_size)\nax.legend(fontsize=20)\nax.set_title('Distribution of Role at work by size of company',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Distribution of role at work of participants participating in the survey')\n\n\n\n\n#is ML finding more tendency for application in smaller scaled companies ?????","ec46c6de":"##########Distribution of people involved in \nrole_at_work = ['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8']\nl = list()\nfor i in role_at_work:\n    df = req.groupby([i,'Q6','Q3']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\n    df.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\n    df.rename(columns = {i:'Role_at_Work'}, inplace = True)\n    l.append(df)\ncountries = req.Q3.unique()\nrole_at_work_size = pd.concat(l)\nrole_at_work_size = role_at_work_size[role_at_work_size.Role_at_Work != 0]\nstla = role_at_work_size.reset_index(drop=True)\ncountries = req.Q3.unique()\nfor i in countries:\n    d = stla[stla['Q3']==i]\n    dr = d.reset_index(drop=True)\n    #plt.xticks(role_at_work_size.index, role_at_work_size.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\n    sns.set(style=\"whitegrid\")\n    fig, ax = plt.subplots(1, 1, figsize=(90,20))\n#     tips = sns.load_dataset(\"tips\")\n    ax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Role_at_Work\", data=dr)\n    ax.legend(fontsize=20)\n    ax.set_title('Distribution of Role at work by size of company in {}'.format(i),fontsize=20)\n    ax.set(xlabel='Size of company', ylabel='Distribution of role at work of people participating in the survey')","9eb00332":"########Amount spent by company v\/s size of company employed \ndf = req.groupby(['Q6','Q11']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\ndf.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)","68eff00d":"d = df[df.Q6 != 0]","0e7a6948":"dr = d[d.Q11 != 0]","63db5a84":"y = dr","0d2aed36":"y","a13921e1":"import seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Q11\", data=dr)\nax.legend(fontsize=20)\nax.set_title('Distribution of Money invested in ML and Cloud Products by size of company',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Distribution of amount invested by companies of participants participating in the survey')\n\n\n\n\n#is ML finding more tendency for application in smaller scaled companies ?????","be1dc47c":"###########Amount invested in companies in the field of machine learning and cloud computing products by country\ndf = req.groupby(['Q6','Q11','Q3']).count().loc[:,:'Time from Start to Finish (seconds)'].reset_index()\ndf.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True)\nd = df[df.Q6 != 0]\ndr = d[d.Q11 != 0]\ncountries = req.Q3.unique()\nfor i in countries:\n    d = dr[dr['Q3']==i]\n    drr = d.reset_index(drop=True)\n    #plt.xticks(role_at_work_size.index, role_at_work_size.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\n    import seaborn as sns\n    fig, ax = plt.subplots(1, 1, figsize=(20,20))\n\n    sns.set(style=\"whitegrid\")\n#     tips = sns.load_dataset(\"tips\")\n    ax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Q11\", data=drr)\n    ax.legend(fontsize=20)\n    ax.set_title('Distribution of Money invested in ML and Cloud Products by size of company in {}'.format(i),fontsize=20)\n    ax.set(xlabel='Size of company', ylabel='Distribution of amount invested by companies of participants participating in the survey')","294cd58e":"#Analysis within each gender\n##########GENDER DISTRIBUTION ATTEMPTING SURVEY\ngender = req.groupby(['Q2'],as_index=False).count().reset_index().loc[:,'Q2':'Time from Start to Finish (seconds)']","258ae711":"gender.sort_values('Time from Start to Finish (seconds)', inplace=True)","e63cf549":"import seaborn as sns\nsns.set(style=\"whitegrid\")\nfig, ax = plt.subplots(1, 1, figsize=(15,15))\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q2\", y=\"Time from Start to Finish (seconds)\", data=gender)\nax.set(xlabel='Gender Participating In The Survey', ylabel='Number of people participating in the survey')","acd911bb":"#####DISTRIBUTION BY COUNTRY \ncountry = req.groupby(['Q3'],as_index=False).count().reset_index().loc[:,'Q3':'Time from Start to Finish (seconds)']","fcef35c5":"country.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","cc73b363":"# Prepare Data\ncountry.sort_values('Frequency', inplace=True)\n#country.reset_index(inplace=True)\n\n# Draw plot\nimport matplotlib.patches as patches\n\nfig, ax = plt.subplots(figsize=(16,10), facecolor='white', dpi= 80)\nax.vlines(x=country.index, ymin=0, ymax=country.Frequency, color='firebrick', alpha=0.7, linewidth=20)\n\n# Annotate Text\nfor i, Frequency in enumerate(country.Frequency):\n    ax.text(i, Frequency+0.5, round(Frequency, 1), horizontalalignment='center')\n\n\n# Title, Label, Ticks and Ylim\nax.set_title('Bar Chart for Proportion of Survey Attempts by Country distribution', fontdict={'size':22})\nax.set(ylabel='Number of people participated in survey', ylim=(0, 5000))\nax.set(xlabel='Country participating in Survey')\nplt.xticks(country.index, country.Q3.str.upper(), rotation=60, horizontalalignment='right', fontsize=12)\n\n# Add patches to color the X axis labels\np1 = patches.Rectangle((.57, -0.005), width=.33, height=.13, alpha=.1, facecolor='green', transform=fig.transFigure)\np2 = patches.Rectangle((.124, -0.005), width=.446, height=.13, alpha=.1, facecolor='red', transform=fig.transFigure)\nfig.add_artist(p1)\nfig.add_artist(p2)\nplt.show()","ade34a62":"#####DISTRIBUTION BY EDUCATION -----> missing values present\neducation = req.groupby(['Q4'],as_index=False).count().reset_index().loc[:,'Q4':'Time from Start to Finish (seconds)']","23dd7a27":"education.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","39e676c0":"education.sort_values('Frequency', inplace=True)","41d4992c":"education = education[education['Q4'] != 0]","75f92caf":"education = education[education['Q4'] != \"I prefer not to answer\"]","8a82d01b":"import seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(education.index, education.Q4.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q4\", y=\"Frequency\", data=education)\nax.set_title('Proportion of different levels of education attained by the participants',fontsize=20)\nax.set(xlabel='Highest Level of Education Attained By Person Participating In The Survey', ylabel='Number of people participating in the survey')","5e541663":"#####DISTRIBUTION BY profession of participant\nprofession = req.groupby(['Q5'],as_index=False).count().reset_index().loc[:,'Q5':'Time from Start to Finish (seconds)']","4ed5be92":"profession.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","684815fc":"profession.sort_values('Frequency', inplace=True)","af32a34c":"profession.reset_index(drop=True)","d862840c":"profession = profession[profession['Q5'] != 0]","850f7a40":"####SIGNIFICANT NUMBER OF OTHER RESPONSE ---> NEED MORE ANALYSIS INTO OTHER RESPONSE OF Q5\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(profession.index, profession.Q5.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q5\", y=\"Frequency\", data=profession)\nax.set_title('Proportion of different levels of education attained by the participants',fontsize=20)\nax.set(xlabel='Highest Level of Education Attained By Person Participating In The Survey', ylabel='Number of people participating in the survey')","11693cdb":"#####DISTRIBUTION BY size of establishment\nsize = req.groupby(['Q6'],as_index=False).count().reset_index().loc[:,'Q6':'Time from Start to Finish (seconds)']","ff73e053":"size.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","4931c29e":"size.sort_values('Frequency', inplace=True)","2a5ee88e":"size.reset_index(drop=True)","8e062c35":"size = size[size['Q6'] != 0]","fb5c55a2":"####INTERESTING OBSERVATION: survey undertaken by a large population working in a smaller scale industry\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(size.index, size.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", data=size)\nax.set_title('Proportion of sizes of companies the participants are employed in',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Number of people participating in the survey')","f5597f14":"####taking a deeper dive into the small scale establishment employees\n#size_by_profession = \nsize_by_profession = req.groupby(['Q6','Q5'],as_index=False).count().reset_index().loc[:,'Q6':'Time from Start to Finish (seconds)']","f003eefe":"size_by_profession = size_by_profession[size_by_profession['Q6'] != 0]","10cd55f3":"size_by_profession = size_by_profession[size_by_profession['Q5'] != 0]","414d062d":"####\ns1 = size_by_profession[size_by_profession['Q6'] == '0-49 employees']\ns2 = size_by_profession[size_by_profession['Q6'] == '1000-9,999 employees']\ns3 = size_by_profession[size_by_profession['Q6'] == '250-999 employees']\ns4 = size_by_profession[size_by_profession['Q6'] == '50-249 employees']\ns5 = size_by_profession[size_by_profession['Q6'] == '> 10,000 employees']\n","ce49e464":"# s1.sort_values('Frequency', inplace=True)\n# s2.sort_values('Frequency', inplace=True)\n# s3.sort_values('Frequency', inplace=True)\n# s4.sort_values('Frequency', inplace=True)\n# s5.sort_values('Frequency', inplace=True)","4bad2085":"size_by_profession = pd.concat([s1,s2,s3,s4,s5])","7139aceb":"size_by_profession.reset_index(drop=True)","6cf9fcfb":"size_by_profession.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","9fccc805":"####\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(size_by_profession.index, size_by_profession.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Q5\", data=size_by_profession)\nax.legend(fontsize=20)\nax.set_title('Distribution of Profession of the participant taking the survey by company size',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Number of people participating in the survey')","d470d6fa":"####\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(size_by_profession.index, size_by_profession.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Q5\", data=size_by_profession)\nax.legend(fontsize=20)\nax.set_title('Distribution of Profession of the participant taking the survey by company size',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Number of people participating in the survey')","44d5a85d":"req['Q10']","a2eadc5a":"num_inv_in_datascience = req.groupby(['Q7'],as_index=False).count().reset_index().loc[:,'Q7':'Time from Start to Finish (seconds)']","6dc86eab":"def func(line):\n    l = line\n    if line == '14-Oct':\n        l = '10-14'\n    elif line == '2-Jan':\n        l = '1-2'\n    elif line == '4-Mar':\n        l = '3-4'\n    elif line == '9-May':\n        l = '5-9'\n    return l\nnum_inv_in_datascience['Q7']=num_inv_in_datascience['Q7'].apply(func)","63374b9f":"num_inv_in_datascience.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","a059737b":"num_inv_in_datascience.sort_values('Frequency',inplace = True)","4050a908":"#############LARGE NUMBER OF MISSING VALUES...\nnum_inv_in_datascience = num_inv_in_datascience[num_inv_in_datascience['Q7']!=0]","731489c6":"num_inv_in_datascience","ba32b177":"####INTERESTING OBSERVATION: survey undertaken by a large population working in a smaller scale industry\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(num_inv_in_datascience.index, num_inv_in_datascience.Q7.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q7\", y=\"Frequency\", data=num_inv_in_datascience)\nax.set_title('Proportion of number of individuals involved in Datascience in the company the participant is employed in',fontsize=20)\nax.set(xlabel='Number of people involved in data-science ', ylabel='Number of people participating in the survey')","1c888b04":"#GROUP BY SIZE OF COMPANY AND NUMBER OF DATA SCIENCE PEOPLE INVOLVED ...ADD A COUNTRY COMPARISON TOO\nreq['Q7']","f7af4eb9":"#size_by_profession \nsize_by_ds = req.groupby(['Q6','Q7'],as_index=False).count().reset_index().loc[:,'Q6':'Time from Start to Finish (seconds)']","6ddb29aa":"size_by_ds.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","4a59c879":"size_by_ds = size_by_ds[size_by_ds.Q6 != 0]\nsize_by_ds = size_by_ds[size_by_ds.Q7 != 0]\nsize_by_ds['Q7'] = size_by_ds['Q7'].apply(func)","099a1999":"size_by_ds['Q7'].value_counts()\n","41fc8bf5":"####\ns1 = size_by_ds[size_by_ds['Q6'] == '0-49 employees']\ns2 = size_by_ds[size_by_ds['Q6'] == '50-249 employees']\ns3 = size_by_ds[size_by_ds['Q6'] == '250-999 employees']\ns4 = size_by_ds[size_by_ds['Q6'] == '1000-9,999 employees']\ns5 = size_by_ds[size_by_ds['Q6'] == '> 10,000 employees']\n","32a19713":"s1","897e3a17":"# s1.sort_values('Frequency', inplace=True)\n# s2.sort_values('Frequency', inplace=True)\n# s3.sort_values('Frequency', inplace=True)\n# s4.sort_values('Frequency', inplace=True)\n# s5.sort_values('Frequency', inplace=True)\n# s6.sort_values('Frequency', inplace=True)\n# s7.sort_values('Frequency', inplace=True)","acb7fa8b":"size_by_ds = pd.concat([s1,s2,s3,s4,s5])","2bec9604":"size_by_ds","f38bb4e0":"####\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(30,30))\n\nplt.xticks(size_by_profession.index, size_by_ds.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q6\", y=\"Frequency\", hue=\"Q7\", data=size_by_ds)\nax.legend(fontsize=20)\nax.set_title('Distribution of number of data science individuals by company size',fontsize=20)\nax.set(xlabel='Size of company', ylabel='Number of data science individuals in the company')\nchartBox = ax.get_position()\nax.set_position([chartBox.x0, chartBox.y0, chartBox.width*0.6, chartBox.height])\nax.legend(loc='upper center', bbox_to_anchor=(0.5,1), shadow=True, ncol=1)\nplt.show()","b099eaf1":"#country,company size and distribution of individual involved\n#Let's consider the top 5 countries from where maximum survey participants\n\nsize_by_ds_country = req.groupby(['Q3','Q6','Q7'],as_index=False).count().reset_index().loc[:,'Q3':'Time from Start to Finish (seconds)']","98cb1420":"size_by_ds_country.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) \nsize_by_ds_country","695ae8bf":"size_by_ds_country = size_by_ds_country[size_by_ds_country.Q6 != 0]\nsize_by_ds_country = size_by_ds_country[size_by_ds_country.Q7 != 0]\nsize_by_ds_country['Q7'] = size_by_ds_country['Q7'].apply(func)","b3451e93":"size_by_ds_country.reset_index(drop=True)","1a87d870":"#Taking mean of each category to get effective number of data science individuals\ndef func2(line):\n    if line == '0':\n        line = float(0)\n    elif line == '1-2':\n        line = float(1.5)\n    elif line == '3-4':\n        line = float(3.5)\n    else:\n        line = 12\n    return line\n\nsize_by_ds_country['Q7'] = size_by_ds_country['Q7'].apply(func2)","06b9ec39":"size_by_ds_country['Q7']","1ee9808e":"size_by_ds_country['Effective_Frequency'] = size_by_ds_country.Q7*size_by_ds_country.Frequency","3123c4a8":"sdc = size_by_ds_country.groupby(['Q3','Q6'],as_index=False)[['Effective_Frequency']].sum()","e8790977":"sdc['Q3'].value_counts()","58ccf38d":"##TOP 5 COUNTRIES ----> INDIA, UNITED STATES OF AMERICA, OTHER, BRAZIL, JAPAN, RUSSIA, CHINA, GERMANY\n##India \nindia = sdc[(sdc.Q3 == 'India') | (sdc.Q3 == 'United States of America')| (sdc.Q3 == 'China')| (sdc.Q3 == 'Brazil')| (sdc.Q3 == 'Japan')| (sdc.Q3 == 'Russia')|(sdc.Q3 == 'Germany')]","1eb728b1":"india","489e171a":"####\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(20,10))\n\nplt.xticks(india.index, india.Q6.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n#tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q3\", y=\"Effective_Frequency\", hue=\"Q6\", data=india)\nax.legend(fontsize=20)\nax.set_title('Distribution of number of data science individuals by company size in India',fontsize=20)\nax.set(xlabel='COUNTRY', ylabel='Number of DATA SCIENCE individuals in the company')\nchartBox = ax.get_position()\nax.set_position([chartBox.x0, chartBox.y0, chartBox.width*0.6, chartBox.height])\nax.legend(loc='upper center', bbox_to_anchor=(0.5,1), shadow=True, ncol=1)\nplt.show()","bb262cde":"####DISTRIBUTION OF SURVEY TAKEN BY PROFESSION OF THE INDIVIDUALS AND COUNTRY\n#########DISTRIBUTION OF SURVEY TAKEN BY AGE GROUP, GENDER, COUNTRY, PROFESSION(INTERMIX THESE 4 AND TRY TO FIND TRENDS)\ngender_by_country = req.groupby(['Q2','Q3'],as_index=False).count().reset_index().loc[:,'Q2':'Time from Start to Finish (seconds)']","0a227232":"gender_by_country.rename(columns = {'Time from Start to Finish (seconds)':'Frequency'}, inplace = True) ","32562d41":"gender_by_country = gender_by_country[(gender_by_country.Q2 == 'Female') | (gender_by_country.Q2 == 'Male')]","abed4079":"####from pre-liminary visual analysis of the plot, higher proportion of female participants in Brazil, Canada, China, Germany\nimport seaborn as sns\nfig, ax = plt.subplots(1, 1, figsize=(40,60))\n\nplt.xticks(gender_by_country.index, gender_by_country.Q3.str.upper(), rotation=60, horizontalalignment='right', fontsize=20)\nsns.set(style=\"whitegrid\")\n# tips = sns.load_dataset(\"tips\")\nax = sns.barplot(x=\"Q3\", y=\"Frequency\", hue=\"Q2\", data=gender_by_country)\nax.legend(fontsize=20)\nax.set_title('Distribution of gender of participant by country',fontsize=20)\nax.set(xlabel='COUNTRY', ylabel='Number of DATA SCIENCE individuals in the company')\nchartBox = ax.get_position()\nax.set_position([chartBox.x0, chartBox.y0, chartBox.width*0.6, chartBox.height])\nax.legend(loc='upper center', bbox_to_anchor=(0.5,1), shadow=True, ncol=1)\nplt.show()","3853c3f7":"#Calculate percentage of male and female participants in survey from each country...\ngender_by_country","6116b641":"##groupby gender and profession....profession and country.... gender, profession and country\ngender_by_profession = req.groupby(['Q2','Q3'],as_index=False).count().reset_index().loc[:,'Q2':'Time from Start to Finish (seconds)']","e7e5c753":"gender_by_profession","0536e7bf":"question.head()","00fab995":"question.transpose().head()","d1bb8d99":"q = question.transpose()\nq.columns =['Content'] \nq.head()","1cd79eb7":"import nltk\nstopwords = nltk.corpus.stopwords.words('english')\nnew_words=('selected','select','basic','follow','current','highest','formal','choice','follow', 'use', 'regular')\nfor i in new_words:\n    stopwords.append(i)\nprint(stopwords)\na = list(stopwords)","d20aeefa":"def create_Word_Corpus(df):\n    words_corpus = ''\n    for val in df[\"Content\"]:\n        text = val.lower()\n        tokens = nltk.word_tokenize(text)\n        tokens = [word for word in tokens if word not in string.punctuation]\n        tokens = [word for word in tokens if word not in a]\n        tokens = stemming(tokens)\n        for words in tokens:\n            words_corpus = words_corpus + words + ' '\n    return words_corpus","1308472e":"def plot_Cloud(wordCloud):\n    plt.figure( figsize=(20,10), facecolor='k')\n    plt.imshow(wordCloud)\n    plt.axis(\"off\")\n    plt.tight_layout(pad=0)\n    plt.show()\n#     plt.savefig('wordclouds.png', facecolor='k', bbox_inches='tight')","e4b334d5":"def stemming(tokens):\n    ps=PorterStemmer()\n    stem_words=[]\n    for x in tokens:\n        stem_words.append(ps.stem(x))\n    return stem_words","f4a438cf":"# importing all the required Libraries\nimport glob\nimport json\nimport csv\nimport pandas as pd\nimport numpy as np\nfrom wordcloud import WordCloud\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom textblob import TextBlob\nfrom textblob.sentiments import NaiveBayesAnalyzer\nimport string\nimport matplotlib.pyplot as plt\nfrom nltk.stem import PorterStemmer\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nquestion_wordcloud = WordCloud(width=900, height=500).generate(create_Word_Corpus(q))","f15df892":"plot_Cloud(question_wordcloud)","d104dff1":"# Converting Categorical Features\nWe'll need to convert categorical features to numerical features. Otherwise our machine learning algorithm won't be able to directly take in those features as inputs.","fde3f88b":"# Handling the missing data\n<h4>Evaluating for Missing Data<\/h4> The missing values are converted to Python's default. We use Python's built-in functions to identify these missing values. There are two methods to detect missing data:<ol>    <li><b>.isnull()<\/b><\/li>    <li><b>.notnull()<\/b><\/li><\/ol>The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n\nEvaluating for Missing Data\n\nThe missing values are converted to Python's default. We use Python's built-in functions to identify these missing values. There are two methods to detect missing data:\n.isnull()\n.notnull()\nThe output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.","5494b1a8":"We can check that questioner is interested in data science and machine learning.","f800e4ad":"<h3 id=\"deal_missing_values\">Deal with missing data<\/h3>\n<b>How to deal with missing data?<\/b>\n\n<ol>\n    <li>drop data<br>\n        a. drop the whole row<br>\n        b. drop the whole column\n    <\/li>\n    <li>replace data<br>\n        a. replace it by mean<br>\n        b. replace it by frequency<br>\n        c. replace it based on other functions\n    <\/li>\n<\/ol>","1934eadb":"Most of respondents are from India and USA.","7c3b9c9e":"# Feature Importance\nWe can get the feature importance of each feature of our dataset by using the feature importance property of the model.\nFeature importance gives you a score for each feature of our data, the higher the score more important or relevant is the feature towards our output variable.\nFeature importance is an inbuilt class that comes with Tree Based Classifiers, we will be using Extra Tree Classifier for extracting the top 10 features for the dataset.\n\nThe target is the salaries of respondent and this feature importance is to check which factors contribute to the higher salaries.","3cf5f3f7":"# Data visualization\nLet's make some data visualizations and find out interesting points in each question!!!","6f061310":" # Checking missing values\n In this section, we deal with the data cleaning and check out some missing data or imbalance data.","44d61d49":"Most of respondents are males.\n\n","8668f216":"# Correlation Matrix with Heatmap\n\nCorrelation states how the features are related to each other or the target variable. Correlation can be positive (increase in one value of feature increases the value of the target variable) or negative (increase in one value of feature decreases the value of the target variable) Heatmap makes it easy to identify which features are most related to the target variable, we will plot heatmap of correlated features using the seaborn library.","998035dc":"\"True\" stands for missing value, while \"False\" stands for not missing value.","3f2af622":"Let's play with Kaggle ML & DS survey data:)","73263b1a":"Natural Language Processing","c088a03c":"<h4>Count missing values in each column<\/h4>\n<p>\nUsing a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value, \"False\"  means the value is present in the dataset.  In the body of the for loop the method  \".value_counts()\"  counts the number of \"True\" values. \n<\/p>","391345bd":"# Exploratory Data Analysis\n\nIn this section, we deal with the data cleaning and check out some missing data or imbalance data.","f67eaad8":"After feature importance, it can concluded that country, age, job title, coding experience contribute the salaries a lot. And, we can find out that the higher salary, the longer time duration. This is a very interesting point. In this project, I didn't try to build a classification model but the classification models such as Logistic regression, decision tree (Random forest), SVM, etc can be built to predict the target such as salaries."}}