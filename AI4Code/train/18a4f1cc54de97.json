{"cell_type":{"f41c0f83":"code","60dfc0f3":"code","a1da3b67":"code","d6249c19":"code","361df622":"code","a107bd5e":"code","379f44eb":"code","ee889f86":"code","91a4a5d9":"code","6d1ba4ba":"code","c97990b3":"code","ac77c403":"code","6fecd9d0":"code","69d43b47":"code","c40cfd19":"code","9910952e":"code","7676cc5b":"code","e964e3b2":"code","81571778":"code","d1ef6513":"code","dfdb2286":"code","76f68c47":"code","230090a8":"code","ff6ce5d2":"code","7af2931a":"code","5b9b7fb7":"code","e7dd033a":"code","ff54509d":"code","80008c16":"code","fbbadde9":"code","5ada3dd8":"code","a1e75f48":"code","bcc6d5b1":"code","0e2ae662":"code","b2c3ccc0":"code","eab21727":"markdown","467ea381":"markdown","c2519696":"markdown","738e142f":"markdown","1be2abb5":"markdown","381b7a51":"markdown","e4ac2681":"markdown","0ccbff87":"markdown","df7314bf":"markdown","fc938db0":"markdown","cbea6355":"markdown","8c3050d1":"markdown","9e9a5c93":"markdown","3d9610de":"markdown","87350da9":"markdown","26b86ec0":"markdown","546a0aa9":"markdown","f0d9bd16":"markdown","fe935fc3":"markdown","e0ea4b40":"markdown","cddd1c24":"markdown","2bce0a2a":"markdown","20591afa":"markdown","606fce72":"markdown"},"source":{"f41c0f83":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","60dfc0f3":"from pathlib import Path as path\nimport os","a1da3b67":"train_data = path(r'..\/input\/10-monkey-species\/training')\nvalid_data = path(r\"..\/input\/10-monkey-species\/validation\")","d6249c19":"# Monkey Labels \ndata_labels = pd.read_csv(r\"..\/input\/10-monkey-species\/monkey_labels.txt\")","361df622":"data_labels","a107bd5e":"def show_images(num_images, label):\n    \"\"\"\n    We pass the number of images, and the monkey label form 0:9 \n    , and then show an n random images.\n    \"\"\"\n    \n    for i in range(num_images):\n        imgdir = path('..\/input\/10-monkey-species\/training\/training\/' + label)\n        imgfile = np.random.choice(os.listdir(imgdir))\n        img = cv2.imread('..\/input\/10-monkey-species\/training\/training\/' + label + '\/' + imgfile)\n        plt.figure(i)\n        plt.imshow(img)\n        plt.title(imgfile)\n        plt.show()","379f44eb":"show_images(2, 'n1')","ee889f86":"show_images(2, 'n5')","91a4a5d9":"show_images(2, 'n9')","6d1ba4ba":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input","c97990b3":"train_filepaths = list(train_data.glob(r'**\/*.jpg'))\ntest_filepaths = list(valid_data.glob(r'**\/*.jpg'))","ac77c403":"from skimage import color","6fecd9d0":"def proc_img(filepath):\n    \"\"\" \n    Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepath))\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df","69d43b47":"# Create a DataFrame with the filepaths and the labels of the picture\ntrain_df = proc_img(train_filepaths)\ntest_df = proc_img(test_filepaths)","c40cfd19":"train_generator = ImageDataGenerator(\n    preprocessing_function= preprocess_input\n)\n\n\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,  # << Train_Data >>\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='training',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","9910952e":"# Test generator\ntest_generator = ImageDataGenerator(\n    preprocessing_function= preprocess_input\n)\n\nval_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,  # << Test Data >>\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0, \n    subset='training',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","7676cc5b":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,MaxPool2D, Flatten, Dropout","e964e3b2":"model = Sequential()\n\n# add the CNN layers\n\n\n\nmodel.add(Conv2D (filters = 32, kernel_size = (3,3), input_shape = (224, 224, 3), activation='relu') )\n\nmodel.add(MaxPool2D(pool_size = (4,4)))\n\nmodel.add(Conv2D (filters = 64, kernel_size = (3,3), input_shape = (224, 224, 3), activation='relu') )\n\nmodel.add(MaxPool2D(pool_size = (4,4)))\n\nmodel.add(Conv2D (filters = 128, kernel_size = (3,3), input_shape = (224, 224, 3), activation='relu') )\n\nmodel.add(MaxPool2D(pool_size = (4,4)))\n\nmodel.add(Flatten())\n\n# Dense Layers\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(10,activation='softmax'))","81571778":"model.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","d1ef6513":"model.summary()","dfdb2286":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","76f68c47":"model.fit(train_images, epochs = 30, validation_data = val_images, callbacks = early_stop)","230090a8":"pd.DataFrame(model.history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Loss\")\nplt.show()","ff6ce5d2":"# Predict the label of the test_images\npred_labels = model.predict(val_images)\n#print(pred_labels)\n\npred_labels = np.argmax(pred_labels,axis=1)\n#print(pred_labels)\n\n# Map label\nlabels = (val_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())  # Maping 0: n0, 1:n1 and, so on ...\npred_labels = [labels[k] for k in pred_labels]   # >> K's the labels \n\n# print(labels)\n# print(pred_labels)","7af2931a":"plt.imshow(plt.imread(test_df.Filepath.iloc[2]))\nplt.title(f\"True: {test_df.Label.iloc[2]} , {pred_labels[2]}\")\nplt.show()","5b9b7fb7":"from tensorflow.keras.layers import AveragePooling2D","e7dd033a":"model = Sequential()\n\n# add the CNN layers\nmodel.add(Conv2D (filters = 32, kernel_size = (3,3), input_shape = (224, 224, 3), activation='relu') )\nmodel.add(AveragePooling2D(pool_size = (4,4)))\n\nmodel.add(Conv2D (filters = 64, kernel_size = (3,3), input_shape = (224, 224, 3), activation='relu') )\nmodel.add(AveragePooling2D(pool_size = (4,4)))\n\nmodel.add(Conv2D (filters = 128, kernel_size = (3,3), input_shape = (224, 224, 3), activation='relu') )\nmodel.add(AveragePooling2D(pool_size = (4,4)))\n\nmodel.add(Flatten())\n\n# Dense Layers\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(10,activation='softmax'))","ff54509d":"model.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","80008c16":"model.fit(train_images, epochs = 30, validation_data = val_images, callbacks = early_stop) ","fbbadde9":"pd.DataFrame(model.history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Loss\")\nplt.show()","5ada3dd8":"plt.plot(df)","a1e75f48":"import tensorflow\nimport keras ","bcc6d5b1":"# Simple NN\nmodel = tensorflow.keras.Sequential([\n    keras.layers.Reshape(target_shape=(672 * 224, ),input_shape=(224, 224, 3)),\n    keras.layers.Dense(units=256, activation='relu'),\n    keras.layers.Dense(units=128, activation='relu'),\n    keras.layers.Dense(units=10, activation='softmax')\n])","0e2ae662":"model.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","b2c3ccc0":"model.fit(train_images, epochs = 10 , validation_data = val_images, verbose=1)","eab21727":"> **Model Complie**","467ea381":"__Label #9__","c2519696":"**Model_Structure**","738e142f":"*Test Generator*","1be2abb5":"# > **\u0650Another MODEL**","381b7a51":"> **Avg Pooling**","e4ac2681":"*Load The Data*","0ccbff87":"**Convert The Pathes to data frame**","df7314bf":"> **Model Fitting**","fc938db0":"# About The Project:\n__The dataset consists of two files, training and validation. Each folder contains 10 subforders labeled as n0~n9__\\\n__Images are 400x300 px or larger and JPEG format (almost 1400 images)__\n","cbea6355":"**Remove Text**","8c3050d1":"> **Predict**","9e9a5c93":"# Show the Monkey Images","3d9610de":"> **Early Stop**","87350da9":"__Explore The Data__","26b86ec0":"# > Modeling","546a0aa9":"# Simple NN","f0d9bd16":"# Images Pre-Processing","fe935fc3":"__Label #1__","e0ea4b40":"__Label #5__","cddd1c24":"*Import the main modules*","2bce0a2a":"*Import The Main Modules*","20591afa":"> **Model Summary**","606fce72":"__*Training Generator*__"}}