{"cell_type":{"fe84891c":"code","cbcfa9bd":"code","23695787":"code","d14011b1":"code","0419d729":"code","51679639":"code","c2896e48":"code","cd417bc5":"code","771afaf8":"code","2f590f23":"code","2424d1e8":"code","4ace1bbf":"code","286870f7":"code","c8c0e896":"code","fefa0f08":"code","d020a096":"code","aa96ddde":"code","a7a787fe":"code","7b07bf43":"code","5b2a882d":"code","3ea71428":"code","3e072cc0":"code","cab43038":"code","3bfac6db":"code","b3eda301":"code","3b43b537":"code","ba29691b":"code","d5b5fd5c":"code","7b4c9503":"code","ec63a0d3":"code","3eb62774":"code","ca15e0c6":"code","fff5b4bb":"code","d80164ea":"code","725d4b31":"code","bb47c2db":"code","87f9f171":"code","23853116":"code","340b6470":"code","a2e546b7":"code","06f30e4d":"code","fc0e4080":"code","1703bb03":"code","535fd3c0":"code","02d48dc3":"code","4ad13bc3":"code","dbd2d1c0":"code","b5fb0d63":"code","802be6f3":"code","de1b0614":"code","6692cf1d":"code","811ea662":"code","05eb93e7":"code","c1813d67":"code","2a37d022":"code","283ec523":"code","196e68b7":"code","8b9aacde":"code","dd705d04":"code","04ac80c1":"code","d559317c":"markdown","5e0b8256":"markdown","62e1f21e":"markdown","4b5ccfa1":"markdown","a8a50a4a":"markdown","4533dfce":"markdown","122776d6":"markdown","c609702a":"markdown","9a1673e8":"markdown","e452bbde":"markdown","6e04efae":"markdown","9026becc":"markdown","8e56cbaa":"markdown","805a7293":"markdown","f9202a11":"markdown","7d5b173d":"markdown","ca42a61d":"markdown","045ed65e":"markdown","f1860321":"markdown","e967068e":"markdown","3d440bd9":"markdown","bf43ca32":"markdown"},"source":{"fe84891c":"# Import Libraries\nimport numpy as np\nimport pandas as pd","cbcfa9bd":"# Read the dataset\nweather1 = pd.read_csv(\"\/kaggle\/input\/weather-data-for-linear-regression\/weather.csv\")","23695787":"#check the head of the data set\nweather1.head()","d14011b1":"# Inspection code to understand the data\nweather1.shape","0419d729":"weather1.info()","51679639":"weather1.describe()","c2896e48":"# Import visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Pair plot between numerical columns\nsns.pairplot(weather1)\nplt.show()","cd417bc5":"# Box plot for Categorical columns\nplt.figure(figsize=(20,12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'Rain', y = 'Temperature_c' , data = weather1)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'Description' , y = 'Temperature_c' , data = weather1)\n\nplt.show()","771afaf8":"# get the dummy variable for the feature 'Description' and store it in a new variable -'status'\nstatus = pd.get_dummies(weather1['Description'])\n","2f590f23":"#Check what the dataset 'status' looks like \nstatus.head()","2424d1e8":"#lets drop the first column from status dataframe using 'drop_first = True'\nstatus = pd.get_dummies(weather1['Description'],drop_first = True)","4ace1bbf":"# Add the result to the original data frame weather1\nweather1 = pd.concat([weather1,status],axis = 1)","286870f7":"#Drop 'Description' as we have created the dummies for it\nweather1.drop(['Description'],axis=1, inplace= True )","c8c0e896":"weather1.head()","fefa0f08":"# Import Library\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset in 70:30\nnp.random.seed(0)\ndf_train, df_test = train_test_split(weather1, train_size = 0.7 , test_size = 0.3 , random_state = 100)\nprint(df_train.shape)\nprint(df_test.shape)\n","d020a096":"# Normalization : (x-xmin)\/(xmax - xmin)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nnum_vars1 = ['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees','Visibility_km','Pressure_millibars']\ndf_train[num_vars1] = scaler.fit_transform(df_train[num_vars1])","aa96ddde":"df_train.describe()","a7a787fe":"df_train.head()","7b07bf43":"plt.figure(figsize = (16,10))\nsns.heatmap(df_train.corr(), annot = True , cmap=\"GnBu\")\nplt.show()","5b2a882d":"#Dividing into X and y set for model building\n\ny_train = df_train.pop('Temperature_c')\nX_train = df_train","3ea71428":"# Building the Model\n\nimport statsmodels.api as sm\n\n#Add a constant\n\nX_train_lm = sm.add_constant(X_train[['Humidity']])\n# Create a first fitted model\nlr  = sm.OLS(y_train, X_train_lm).fit()","3e072cc0":"lr.params","cab43038":"print(lr.summary())\n# Print the summary of the linear regression model obtained\n","3bfac6db":"# Assign all the feature variables to X\nX_train_lm = X_train[['Humidity','Wind_Speed_kmh'] ]\n","b3eda301":"#Build a linear Model\n\nimport statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params\n\n\n","3b43b537":"print(lr.summary())\n# Check the summary","ba29691b":"X_train_lm = X_train[['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees'] ]\n","d5b5fd5c":"import statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params","7b4c9503":"print(lr.summary())\n","ec63a0d3":"X_train_lm = X_train[['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees','Visibility_km'] ]\n","3eb62774":"import statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params","ca15e0c6":"print(lr.summary())\n","fff5b4bb":"X_train_lm = X_train[['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees','Visibility_km','Pressure_millibars'] ]\n","d80164ea":"import statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params","725d4b31":"print(lr.summary())\n","bb47c2db":"X_train_lm = X_train[['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees','Visibility_km','Pressure_millibars','Rain'] ]\n","87f9f171":"import statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params","23853116":"print(lr.summary())\n","340b6470":"X_train_lm = X_train[['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees','Visibility_km','Pressure_millibars','Rain','Normal'] ]\n","a2e546b7":"import statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params","06f30e4d":"print(lr.summary())\n","fc0e4080":"X_train_lm = X_train[['Humidity','Wind_Speed_kmh','Wind_Bearing_degrees','Visibility_km','Pressure_millibars','Rain','Normal','Warm'] ]\n","1703bb03":"import statsmodels.api as sm\nX_train_lm = sm.add_constant(X_train_lm)\nlr  = sm.OLS(y_train, X_train_lm).fit()\nlr.params","535fd3c0":"print(lr.summary())\n","02d48dc3":"#Check for the VIF values of the feature variable\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor ","4ad13bc3":"#Create a data frame that will contains all the names of the all the feature variables and their respective VIFs\n\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = \"VIF\", ascending = False )\nvif","dbd2d1c0":"# We generally want a VIF with less than 5 hence we need to drop some variables and consider p also should not be higher than 0.5\n\n#Dropping the variable Pressure_millibars as p is 0.861 as well as VIF very large as compared to 5\n\nX = X_train.drop('Pressure_millibars',1,)","b5fb0d63":"#Build a fitted model again\nX_train_lm = sm.add_constant(X)\nlr_2  = sm.OLS(y_train, X_train_lm).fit()\nlr.params\n\n","802be6f3":"print(lr.summary())\n","de1b0614":"#Calculate the VIFs again for the new model\nvif = pd.DataFrame()\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = \"VIF\", ascending = False )\nvif","6692cf1d":"#High VIF is rain variable with 14.19 large value\nX=X.drop('Rain',1)\n","811ea662":"X_train_lm = sm.add_constant(X)\nlr2  = sm.OLS(y_train, X_train_lm).fit()\n","05eb93e7":"print(lr2.summary())","c1813d67":"#calculate again VIF for new model\n\n#Calculate the VIFs again for the new model\nvif = pd.DataFrame()\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = \"VIF\", ascending = False )\nvif","2a37d022":"#High VIF value hence dropping Visibility_km 7.23\n\nX=X.drop('Visibility_km',1)\n","283ec523":"X_train_lm = sm.add_constant(X)\nlr3  = sm.OLS(y_train, X_train_lm).fit()\n","196e68b7":"print(lr3.summary())","8b9aacde":"\n\n#Calculate the VIFs again for the new model\nvif = pd.DataFrame()\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'],2)\nvif = vif.sort_values(by = \"VIF\", ascending = False )\nvif","dd705d04":"y_train_temp = lr3.predict(X_train_lm)\n","04ac80c1":"#Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_temp), bins = 20)\nfig.suptitle('Error Terms' , fontsize = 20)\nplt.xlabel('Errors',fontsize = 18)                  #X-label  #Plot Heading\n","d559317c":"# Weather Case Study \n\nWe will analyse the weather data and find the linear relationship between Temperature and other factors of weather.\n\n### Read and Understand the dataset","5e0b8256":"#### Model - 10","62e1f21e":"Hence we can see that error distribution is centered around zero and qualitatively normal  , which looks good and make sense","4b5ccfa1":"### Data Preparation\nCreate Dummy variables for categorical columns","a8a50a4a":"### Conclusion \n\nLinear relation between temperature and other variable is as follows :\n\n$ Temperature_c = 0.4797 - (0.1508 * Humidity ) - ( 0.0582 * WindSpeedkmh ) + (0.0078 * WindBearingdegrees) +  (0.1847 * Normal ) + ( 0.3630 * Warm) $","4533dfce":"#### Model - 8","122776d6":"#### Model - 3","c609702a":"#### Model - 6","9a1673e8":"#### Model - 4 ","e452bbde":"#### Model - 2","6e04efae":"#### Check correlation between dummy variables and original dataset","9026becc":"Hence now we can se that the VIfs  and P  values both are within an acceptable Range , hence we will stop dropping variables.\nPerfect Model Obtained.\n","8e56cbaa":"#### Final Model ","805a7293":"### Residual Analysis","f9202a11":"### Model Building","7d5b173d":"#### Model - 7","ca42a61d":"### EDA\n#### Bivariate Analysis","045ed65e":"### Train-Test split\nSplit the data in train and test in ratio 70:30","f1860321":"#### Model - 5","e967068e":"#### Model - 9","3d440bd9":"#### Model -1","bf43ca32":"#### Normalization Scaling\nTo remove data redundancy we perform scaling"}}