{"cell_type":{"d9d995b8":"code","a4e630bf":"code","8189f3c8":"code","58f227bb":"code","c8143a2e":"code","68cc6b91":"code","631539ac":"code","6773dd6e":"code","b5d035c1":"code","60091cb4":"code","721cb300":"code","181a1d72":"code","f1142aa9":"code","eafe94ad":"code","32e022ff":"code","574d2fa0":"code","01dc2cf3":"code","ac9a9900":"code","1f34fdba":"code","81747a4a":"code","4f33ca96":"code","65516b82":"code","ed320696":"code","f733bd91":"code","77cec0ad":"code","bb3b11f0":"code","3cf2014e":"code","97023823":"code","4741f79a":"code","6f01cd8e":"code","756809bd":"code","52afdf42":"markdown","3ba52f65":"markdown","bf45ec49":"markdown","b2c64673":"markdown","5d08c531":"markdown"},"source":{"d9d995b8":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a4e630bf":"from fastai import *\nfrom fastai.vision import *","8189f3c8":"img = open_image(Path('\/kaggle\/input\/br-coins\/classification_dataset\/all\/25_1477287102.jpg'))\nprint(img.size)\nimg","58f227bb":"train_path = Path('\/kaggle\/input\/br-coins\/classification_dataset\/all\/')\nfnames = get_image_files(train_path)\npat = r'\/([^\/]+)_\\d+.jpg$'","c8143a2e":"data = ImageDataBunch.from_name_re(train_path,\n                                   fnames,\n                                   pat,\n                                   ds_tfms=get_transforms(flip_vert=True, max_zoom=1.0,max_rotate=25, max_lighting=0.1, max_warp=0.1, p_affine=0.75, p_lighting=0.75),# A small portion of the images have the coin near the corner of the image so zooming in can remove alot of signal\n                                   size=64,#224,#480\n                                   bs=64\n                                  ).normalize(imagenet_stats)","68cc6b91":"data.show_batch(row=3, figsize=(12,12))","631539ac":"learn = cnn_learner(data, models.resnet34, pretrained=False, metrics=error_rate)","6773dd6e":"Model_Path = Path('\/kaggle\/input\/brazillian-coin-fastai-classifier\/')\nlearn.model_dir = Model_Path\nlearn.load('stage-1');","b5d035c1":"learn.load('stage-1')\nlearn.unfreeze()","60091cb4":"learn.fit_one_cycle(2)","721cb300":"Model_Path = Path('\/kaggle\/working')\nlearn.model_dir = Model_Path\nlearn.save('stage-2')","181a1d72":"learn.lr_find()\nlearn.recorder.plot()","f1142aa9":"learn.unfreeze()","eafe94ad":"#looking at the curve, we don't have much we can use for a learning rate\nlearn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))","32e022ff":"learn.save('stage-3')","574d2fa0":"learn.destroy()","01dc2cf3":"data = ImageDataBunch.from_name_re(train_path,\n                                   fnames,\n                                   pat,\n                                   ds_tfms=get_transforms(flip_vert=True, max_zoom=1.0,max_rotate=25, max_lighting=0.1, max_warp=0.1, p_affine=0.75, p_lighting=0.75),\n                                   size=224,\n                                   bs=64,\n                                  ).normalize(imagenet_stats)","ac9a9900":"learn = cnn_learner(data, models.resnet34, pretrained=False, metrics=error_rate)","1f34fdba":"Model_Path = Path('\/kaggle\/working')\nlearn.model_dir = Model_Path\nlearn.load('stage-3');","81747a4a":"learn.fit_one_cycle(2)","4f33ca96":"learn.unfreeze()\nlr_find(learn)\nlearn.recorder.plot()","65516b82":"learn.fit_one_cycle(5, slice(1e-6,1e-4))","ed320696":"learn.save('stage-4')","f733bd91":"learn.destroy()","77cec0ad":"data = ImageDataBunch.from_name_re(train_path,\n                                   fnames,\n                                   pat,\n                                   ds_tfms=get_transforms(flip_vert=True, max_zoom=1.0,max_rotate=25, max_lighting=0.1, max_warp=0.1, p_affine=0.75, p_lighting=0.75),\n                                   size=480,\n                                   bs=64\n                                  ).normalize(imagenet_stats)","bb3b11f0":"learn = cnn_learner(data, models.resnet34, pretrained=False, metrics=error_rate)\nModel_Path = Path('\/kaggle\/working')\nlearn.model_dir = Model_Path\nlearn.load('stage-4');","3cf2014e":"learn.fit_one_cycle(6, 1e-4)#","97023823":"lr_find(learn)\nlearn.recorder.plot()","4741f79a":"learn.save('stage-5')","6f01cd8e":"learn.unfreeze()\nlearn.fit_one_cycle(1, slice(1e-6,1e-5))","756809bd":"learn.save('final')","52afdf42":"# Final Thoughts:\n\nThe model didn't exactly hit my goal. Managed to get about a 96% accuracy, which isn't bad, but not ahead of similiar models.\n\nI did not expect to get so small a boost in performance when I finally used the almost full sized images. This is my first attempt at progressive resizing so I am still experimenting.\n\nThere is also one major flaw with this model, because I recreated the dataset for each iteration (twice for the images shrunk down to 64 by 64, once for the images at 224 by 224, and a fourth time with the images at size 480 by 480), each time I recreated the dataset the validation and training data was reshuffled. This means that the model is being tested on data that was likely already labeled for it in a previous iteration. The way around this would be to create a training and validation folder and feed those to the databunch object (I ran a little tight on time with this one so I didn't get around to that).\n\nThis year I've challenged myself to complete one task on Kaggle per week, in order to develop a larger Data Science portfolio. If you found this notebook useful or interesting please give it an upvote. I'm always open to constructive feedback. If you have any questions, comments, concerns, or if you would like to collaborate on a future task of the week feel free to leave a comment here or message me directly.","3ba52f65":"# Task: Classification task with NN\n\nThe goal of the task is to build a coin classifier using a neural network. In this notebook I will demonstrate progressive resizing to achieve the most accurate possible results. My goal for this models accuracy was 97% as the owner of the dataset had a model that achieved 96% accuracy.\n\nAs one quick note: I'm using Luis Moneda's original dataset, instead of VolodymyrGavrysh's copy (which is the dataset that has the task attached to it). For whatever reason I had greater difficulty getting the classifier to run well on the other dataset (my final accuracy was around 93% and this model did better), it might not be that I wasn't using the best method to untar the .jpg files.\n\nThanks to:\n* Luis Moneda for the dataset https:\/\/www.kaggle.com\/lgmoneda\/br-coins\n* VolodymyrGavrysh for the task https:\/\/www.kaggle.com\/volodymyrgavrysh\/brazilian-coins-dataset-classification25k-images\/tasks?taskId=395","bf45ec49":"# Once more with feeling!\n\nNotice that with just this step the error rate of the model is already well under 10%. Now to train the model on the images that are full size to create the final model","b2c64673":"# Quirk\n\nFor some silly reason if I run the cnn_learner with pretrained left in its default True state then I can't commit this notebook successfully. But if I train the model in one of these kernels, download it, then upload it to the notebook and then load it the notebook, then the notebook commits just fine. The code below generates the model that I will be updating in this notebook.\n\n`\nlearn = cnn_learner(data, models.resnet34, metrics=error_rate)\nlearn.fit_one_cycle(8)\nModel_Path = Path('\/kaggle\/working\/')\nlearn.model_dir = Model_Path\nlearn.save('stage-1')\n`","5d08c531":"# Second Verse same as the first!\n\nFor the first phase, we reached an accuracy of about 85%, but not to the goal yet, the images for this training set are less than a quarter of their original size. Now the model will be trained again, this time on the images that are about half size of the original images."}}