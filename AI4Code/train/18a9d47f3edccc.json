{"cell_type":{"e3fc0c87":"code","b349ab1a":"code","1b07f5c8":"code","86fe79ca":"code","4e79c1ca":"code","4f073dac":"code","13a1e13f":"code","ac130017":"code","5aba348e":"code","613e4edc":"code","6dc4f5fc":"code","c3cc03e9":"code","e91cdef2":"code","c079950e":"code","dc3db9f3":"code","941c4797":"code","6e8f3083":"code","7af5cb3d":"code","282c8f69":"code","99bdae97":"code","58daa7a1":"code","32a42648":"code","8402bed9":"code","07eefc41":"code","f836315e":"code","0edc4bcb":"code","940f6f2e":"code","d70d2dae":"code","0fff5a04":"code","1578196f":"code","709c849c":"code","8fa3a547":"code","db38a9bb":"code","b89dfd22":"code","0c9a40a2":"code","4517bd6a":"code","aab74c7b":"code","978f691f":"code","452a2dff":"code","1117847b":"code","faf40262":"code","6a2293ac":"code","8039c4a7":"code","2581d0ba":"code","95300e07":"code","d4f6df6c":"code","a1da56fb":"code","f2389ac8":"code","18bc25c3":"code","dcdbee8a":"code","6e7468df":"code","4ad5876d":"code","54d38008":"code","b89d746e":"code","599cd33d":"code","615831e8":"code","d16abd89":"markdown","24e79741":"markdown","ce3e2117":"markdown","056a0b2e":"markdown","b391355d":"markdown","65493497":"markdown","0e40a32a":"markdown","5df4666e":"markdown","b11c8340":"markdown","058f6418":"markdown","952845cf":"markdown","fb3d822d":"markdown","52d7f318":"markdown","0bd2cb13":"markdown","2c7f939f":"markdown","0f0f4e38":"markdown","d789cbf3":"markdown","43ffd09f":"markdown","97e7af62":"markdown","d66044bf":"markdown","a0618525":"markdown","6419247e":"markdown","ca7df122":"markdown"},"source":{"e3fc0c87":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nimport datetime\nimport gc\nimport pickle\nfrom tqdm import tqdm_notebook as tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')","b349ab1a":"%%time\ndf_train = pd.read_feather('..\/input\/ashrae-feather\/train.ft')\n\nbuilding = pd.read_feather('..\/input\/ashrae-feather\/building.ft')\nle = LabelEncoder()\nbuilding.primary_use = le.fit_transform(building.primary_use)\n\nDATA_PATH = \"..\/input\/ashrae-energy-prediction\/\"\nweather_train = pd.read_csv(DATA_PATH + 'weather_train.csv')\nweather_test = weather_df = pd.read_csv(DATA_PATH + 'weather_test.csv')\n# weather_train = pd.read_feather('..\/input\/ashrae-feather\/weather_train.ft')\n# weather_test = pd.read_feather('..\/input\/ashrae-feather\/weather_test.ft')","1b07f5c8":"%%time\ndf_train = df_train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20 18\")')\ndf_train = df_train.query('not (building_id == 681 & meter == 0 & timestamp <= \"2016-04-27\")')\ndf_train = df_train.query('not (building_id == 761 & meter == 0 & timestamp <= \"2016-09-02\")')\ndf_train = df_train.query('not (building_id == 799 & meter == 0 & timestamp <= \"2016-09-02\")')\ndf_train = df_train.query('not (building_id == 802 & meter == 0 & timestamp <= \"2016-08-24\")')\ndf_train = df_train.query('not (building_id == 1073 & meter == 0 & timestamp <= \"2016-10-26\")')\ndf_train = df_train.query('not (building_id == 1094 & meter == 0 & timestamp <= \"2016-09-08\")')\ndf_train = df_train.query('not (building_id == 29 & meter == 0 & timestamp <= \"2016-08-10\")')\ndf_train = df_train.query('not (building_id == 40 & meter == 0 & timestamp <= \"2016-06-04\")')\ndf_train = df_train.query('not (building_id == 45 & meter == 0 & timestamp <= \"2016-07\")')\ndf_train = df_train.query('not (building_id == 106 & meter == 0 & timestamp <= \"2016-11\")')\ndf_train = df_train.query('not (building_id == 107 & meter == 0 & timestamp >= \"2016-11-10\")')\ndf_train = df_train.query('not (building_id == 112 & meter == 0 & timestamp < \"2016-10-31 15\")')\ndf_train = df_train.query('not (building_id == 144 & meter == 0 & timestamp > \"2016-05-14\" & timestamp < \"2016-10-31\")')\ndf_train = df_train.query('not (building_id == 147 & meter == 0 & timestamp > \"2016-06-05 19\" & timestamp < \"2016-07-18 15\")')\ndf_train = df_train.query('not (building_id == 171 & meter == 0 & timestamp <= \"2016-07-05\")')\ndf_train = df_train.query('not (building_id == 177 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\ndf_train = df_train.query('not (building_id == 258 & meter == 0 & timestamp > \"2016-09-26\" & timestamp < \"2016-12-12\")')\ndf_train = df_train.query('not (building_id == 258 & meter == 0 & timestamp > \"2016-08-30\" & timestamp < \"2016-09-08\")')\ndf_train = df_train.query('not (building_id == 258 & meter == 0 & timestamp > \"2016-09-18\" & timestamp < \"2016-09-25\")')\ndf_train = df_train.query('not (building_id == 260 & meter == 0 & timestamp <= \"2016-05-11\")')\ndf_train = df_train.query('not (building_id == 269 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\ndf_train = df_train.query('not (building_id == 304 & meter == 0 & timestamp >= \"2016-11-20\")')\ndf_train = df_train.query('not (building_id == 545 & meter == 0 & timestamp > \"2016-01-17\" & timestamp < \"2016-02-10\")')\ndf_train = df_train.query('not (building_id == 604 & meter == 0 & timestamp < \"2016-11-21\")')\ndf_train = df_train.query('not (building_id == 693 & meter == 0 & timestamp > \"2016-09-07\" & timestamp < \"2016-11-23\")')\ndf_train = df_train.query('not (building_id == 693 & meter == 0 & timestamp > \"2016-07-12\" & timestamp < \"2016-05-29\")')\ndf_train = df_train.query('not (building_id == 723 & meter == 0 & timestamp > \"2016-10-06\" & timestamp < \"2016-11-22\")')\ndf_train = df_train.query('not (building_id == 733 & meter == 0 & timestamp > \"2016-05-29\" & timestamp < \"2016-06-22\")')\ndf_train = df_train.query('not (building_id == 733 & meter == 0 & timestamp > \"2016-05-19\" & timestamp < \"2016-05-20\")')\ndf_train = df_train.query('not (building_id == 803 & meter == 0 & timestamp > \"2016-9-25\")')\ndf_train = df_train.query('not (building_id == 815 & meter == 0 & timestamp > \"2016-05-17\" & timestamp < \"2016-11-17\")')\ndf_train = df_train.query('not (building_id == 848 & meter == 0 & timestamp > \"2016-01-15\" & timestamp < \"2016-03-20\")')\ndf_train = df_train.query('not (building_id == 857 & meter == 0 & timestamp > \"2016-04-13\")')\ndf_train = df_train.query('not (building_id == 909 & meter == 0 & timestamp < \"2016-02-02\")')\ndf_train = df_train.query('not (building_id == 909 & meter == 0 & timestamp < \"2016-06-23\")')\ndf_train = df_train.query('not (building_id == 1008 & meter == 0 & timestamp > \"2016-10-30\" & timestamp < \"2016-11-21\")')\ndf_train = df_train.query('not (building_id == 1113 & meter == 0 & timestamp < \"2016-07-27\")')\ndf_train = df_train.query('not (building_id == 1153 & meter == 0 & timestamp < \"2016-01-20\")')\ndf_train = df_train.query('not (building_id == 1169 & meter == 0 & timestamp < \"2016-08-03\")')\ndf_train = df_train.query('not (building_id == 1170 & meter == 0 & timestamp > \"2016-06-30\" & timestamp < \"2016-07-05\")')\ndf_train = df_train.query('not (building_id == 1221 & meter == 0 & timestamp < \"2016-11-04\")')\ndf_train = df_train.query('not (building_id == 1225 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-01-13 22\" & timestamp < \"2016-03-08 12\")')\ndf_train = df_train.query('not (building_id == 1241 & meter == 0 & timestamp > \"2016-07-14\" & timestamp < \"2016-11-19\")')\ndf_train = df_train.query('not (building_id == 1250 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1255 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1264 & meter == 0 & timestamp > \"2016-08-23\")')\ndf_train = df_train.query('not (building_id == 1265 & meter == 0 & timestamp > \"2016-05-06\" & timestamp < \"2016-05-26\")')\ndf_train = df_train.query('not (building_id == 1272 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1275 & building_id <= 1280 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1283 & meter == 0 & timestamp > \"2016-07-08\" & timestamp < \"2016-08-03\")')\ndf_train = df_train.query('not (building_id >= 1291 & building_id <= 1302 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1303 & meter == 0 & timestamp > \"2016-07-25 22\" & timestamp < \"2016-07-27 16\")')\ndf_train = df_train.query('not (building_id == 1303 & meter == 0 & timestamp > \"2016-01-26\" & timestamp < \"2016-06-02 12\")')\ndf_train = df_train.query('not (building_id == 1319 & meter == 0 & timestamp > \"2016-05-17 16\" & timestamp < \"2016-06-07 12\")')\ndf_train = df_train.query('not (building_id == 1319 & meter == 0 & timestamp > \"2016-08-18 14\" & timestamp < \"2016-09-02 14\")')\ndf_train = df_train.query('not (building_id == 1322 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n\n# 2nd cleaning\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\ndf_train = df_train.query('not (building_id == 1272 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1291 & building_id <= 1297 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1300 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1302 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1291 & building_id <= 1299 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1221 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1225 & building_id <= 1226 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1241 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1223 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1226 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1225 & building_id <= 1226 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1305 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1307 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1223 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1231 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1233 & building_id <= 1234 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1272 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id >= 1275 & building_id <= 1297 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1300 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1293 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\ndf_train = df_train.query('not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\ndf_train = df_train.query('not (building_id == 1223 & meter == 0 & timestamp > \"2016-9-28 07\" & timestamp < \"2016-10-11 18\")')\ndf_train = df_train.query('not (building_id == 1225 & meter == 1 & timestamp > \"2016-8-22 23\" & timestamp < \"2016-10-11 14\")')\ndf_train = df_train.query('not (building_id == 1230 & meter == 1 & timestamp > \"2016-8-22 08\" & timestamp < \"2016-10-05 18\")')\ndf_train = df_train.query('not (building_id == 904 & meter == 0 & timestamp < \"2016-02-17 08\")')\ndf_train = df_train.query('not (building_id == 986 & meter == 0 & timestamp < \"2016-02-17 08\")')\ndf_train = df_train.query('not (building_id == 954 & meter == 0 & timestamp < \"2016-08-08 11\")')\ndf_train = df_train.query('not (building_id == 954 & meter == 0 & timestamp < \"2016-06-23 08\")')\ndf_train = df_train.query('not (building_id >= 745 & building_id <= 770 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\ndf_train = df_train.query('not (building_id >= 774 & building_id <= 787 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\n\n# 3rd cleaning hourly spikes\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp == \"2016-02-26 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp == \"2016-02-26 01\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp == \"2016-02-26 01\")')\n\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\ndf_train = df_train.query('not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n\ndf_train = df_train.query('not (building_id != 1227 & building_id != 1281 & building_id != 1314 & building_id >=1223 & building_id < 1335 & meter==0 & meter_reading==0)')\n\n# 4th cleaning (using hindsight from leaks)\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & meter==1 & timestamp > \"2016-07-16 04\" & timestamp < \"2016-07-19 11\")')\ndf_train = df_train.query('not (building_id == 107 & meter == 0 & timestamp <= \"2016-07-06\")')\n# df_train = df_train.query('not (building_id == 53 & meter == 0)')\ndf_train = df_train.query('not (building_id == 180 & timestamp >= \"2016-02-17 12\")')\ndf_train = df_train.query('not (building_id == 182 & meter == 0)')\ndf_train = df_train.query('not (building_id == 191 & meter == 0 & timestamp >= \"2016-12-22 09\")')\ndf_train = df_train.query('not (building_id == 192 & meter == 1 & timestamp >= \"2016-05-09 18\")')\ndf_train = df_train.query('not (building_id == 192 & meter == 3 & timestamp >= \"2016-03-29 05\" & timestamp <= \"2016-04-04 08\")')\ndf_train = df_train.query('not (building_id == 207 & meter == 1 & timestamp > \"2016-07-02 20\" & timestamp < \"2016-08-25 12\")')\n# df_train = df_train.query('not (building_id == 218)')\ndf_train = df_train.query('not (building_id == 258 & timestamp > \"2016-09-18\" & timestamp < \"2016-12-12 13\")')\ndf_train = df_train.query('not (building_id == 258 & timestamp > \"2016-08-29 08\" & timestamp < \"2016-09-08 14\")')\ndf_train = df_train.query('not (building_id == 257 & meter == 1 & timestamp < \"2016-03-25 16\")')\ndf_train = df_train.query('not (building_id == 260 & meter == 1 & timestamp > \"2016-05-10 17\" & timestamp < \"2016-08-17 11\")')\ndf_train = df_train.query('not (building_id == 260 & meter == 1 & timestamp > \"2016-08-28 01\" & timestamp < \"2016-10-31 13\")')\n# df_train = df_train.query('not (building_id == 279 & meter == 3)')\n# df_train = df_train.query('not (building_id == 287 & meter == 1)')\n# df_train = df_train.query('not (building_id == 287 & meter == 3)')\ndf_train = df_train.query('not (building_id == 220 & meter == 1 & timestamp > \"2016-09-23 01\" & timestamp < \"2016-09-23 12\")')\ndf_train = df_train.query('not (building_id == 281 & meter == 1 & timestamp > \"2016-10-25 08\" & timestamp < \"2016-11-04 15\")')\ndf_train = df_train.query('not (building_id == 273 & meter == 1 & timestamp > \"2016-04-03 04\" & timestamp < \"2016-04-29 15\")')\ndf_train = df_train.query('not (building_id == 28 & meter == 0 & timestamp < \"2016-10-14 20\")')\ndf_train = df_train.query('not (building_id == 71 & meter == 0 & timestamp < \"2016-08-18 20\")')\ndf_train = df_train.query('not (building_id == 76 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 14\")')\ndf_train = df_train.query('not (building_id == 101 & meter == 0 & timestamp > \"2016-10-12 13\" & timestamp < \"2016-10-12 18\")')\ndf_train = df_train.query('not (building_id == 7 & meter == 1 & timestamp > \"2016-11-03 09\" & timestamp < \"2016-11-28 14\")')\ndf_train = df_train.query('not (building_id == 9 & meter == 1 & timestamp > \"2016-12-06 08\")')\ndf_train = df_train.query('not (building_id == 43 & meter == 1 & timestamp > \"2016-04-03 08\" & timestamp < \"2016-06-06 13\")')\ndf_train = df_train.query('not (building_id == 60 & meter == 1 & timestamp > \"2016-05-01 17\" & timestamp < \"2016-05-01 21\")')\ndf_train = df_train.query('not (building_id == 75 & meter == 1 & timestamp > \"2016-08-05 13\" & timestamp < \"2016-08-26 12\")')\ndf_train = df_train.query('not (building_id == 95 & meter == 1 & timestamp > \"2016-08-08 10\" & timestamp < \"2016-08-26 13\")')\ndf_train = df_train.query('not (building_id == 97 & meter == 1 & timestamp > \"2016-08-08 14\" & timestamp < \"2016-08-25 14\")')\ndf_train = df_train.query('not (building_id == 1232 & meter == 1 & timestamp > \"2016-06-23 16\" & timestamp < \"2016-08-31 20\")')\ndf_train = df_train.query('not (building_id == 1236 & meter == 1 & meter_reading >= 3000)')\ndf_train = df_train.query('not (building_id == 1239 & meter == 1 & timestamp > \"2016-03-11 16\" & timestamp < \"2016-03-27 17\")')\ndf_train = df_train.query('not (building_id == 1264 & meter == 1 & timestamp > \"2016-08-22 17\" & timestamp < \"2016-09-22 20\")')\ndf_train = df_train.query('not (building_id == 1264 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\ndf_train = df_train.query('not (building_id == 1269 & meter == 1 & meter_reading >= 2000)')\ndf_train = df_train.query('not (building_id == 1272 & meter == 1 & timestamp > \"2016-08-11 12\" & timestamp < \"2016-08-30 19\")')\ndf_train = df_train.query('not (building_id == 1273 & meter == 1 & timestamp > \"2016-05-31 14\" & timestamp < \"2016-06-17\")')\ndf_train = df_train.query('not (building_id == 1276 & meter == 1 & timestamp < \"2016-02-03 23\")')\ndf_train = df_train.query('not (building_id == 1280 & meter == 1 & timestamp > \"2016-05-18\" & timestamp < \"2016-05-26 09\")')\ndf_train = df_train.query('not (building_id == 1280 & meter == 1 & timestamp > \"2016-02-28 23\" & timestamp < \"2016-05-02 05\")')\ndf_train = df_train.query('not (building_id == 1280 & meter == 1 & timestamp > \"2016-06-12 01\" & timestamp < \"2016-7-07 06\")')\ndf_train = df_train.query('not (building_id == 1288 & meter == 1 & timestamp > \"2016-07-07 15\" & timestamp < \"2016-08-12 17\")')\ndf_train = df_train.query('not (building_id == 1311 & meter == 1 & timestamp > \"2016-04-25 18\" & timestamp < \"2016-05-13 14\")')\ndf_train = df_train.query('not (building_id == 1099 & meter == 2)')\n\ndf_train = df_train.query('not (building_id == 1329 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\ndf_train = df_train.query('not (building_id == 1331 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\ndf_train = df_train.query('not (building_id == 1427 & meter == 0 & timestamp > \"2016-04-11 10\" & timestamp < \"2016-04-11 14\")')\ndf_train = df_train.query('not (building_id == 1426 & meter == 2 & timestamp > \"2016-05-03 09\" & timestamp < \"2016-05-03 14\")')\ndf_train = df_train.query('not (building_id == 1345 & meter == 0 & timestamp < \"2016-03-01\")')\ndf_train = df_train.query('not (building_id == 1346 & timestamp < \"2016-03-01\")')\ndf_train = df_train.query('not (building_id == 1359 & meter == 0 & timestamp > \"2016-04-25 17\" & timestamp < \"2016-07-22 14\")')\ndf_train = df_train.query('not (building_id == 1365 & meter == 0 & timestamp > \"2016-08-19 00\" & timestamp < \"2016-08-19 07\")')\ndf_train = df_train.query('not (building_id == 1365 & meter == 0 & timestamp > \"2016-06-18 22\" & timestamp < \"2016-06-19 06\")')\n\ndf_train = df_train.query('not (building_id == 18 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 16\")')\ndf_train = df_train.query('not (building_id == 18 & meter == 0 & timestamp > \"2016-11-05 05\" & timestamp < \"2016-11-05 15\")')\ndf_train = df_train.query('not (building_id == 101 & meter == 0 & meter_reading > 800)')\n\ndf_train = df_train.query('not (building_id == 1384 & meter == 0 & meter_reading == 0 )')\ndf_train = df_train.query('not (building_id >= 1289 & building_id <= 1301 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1243 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1263 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1284 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1286 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1263 & meter == 0 & timestamp > \"2016-11-10 11\" & timestamp < \"2016-11-10 15\")')\n\ndf_train = df_train.query('not (building_id == 1238 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1329 & meter == 2 & timestamp > \"2016-11-21 12\" & timestamp < \"2016-11-29 12\")')\ndf_train = df_train.query('not (building_id == 1249 & meter == 2 & meter_reading == 0)')\n\ndf_train = df_train.query('not (building_id == 1250 & meter == 2 & meter_reading == 0)')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-05 18\" & timestamp < \"2016-03-05 22\")')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-27 00\" & timestamp < \"2016-03-27 23\")')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-11 09\" & timestamp < \"2016-04-13 03\")')\ndf_train = df_train.query('not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-29 00\" & timestamp < \"2016-04-30 15\")')\ndf_train = df_train.query('not (building_id == 1303 & meter == 2 & timestamp < \"2016-06-06 19\")')\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & meter == 1 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & building_id != 1296 & building_id != 129 & building_id != 1298 & building_id != 1299 & meter == 2 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\ndf_train = df_train.query('not (building_id >= 1223 & building_id <= 1324 & meter == 3 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n","86fe79ca":"# # Remove outliers\n# df_train = df_train [ df_train['building_id'] != 1099 ]\n# df_train = df_train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')","4e79c1ca":"# # building_meter map\n\n# bm_cols = ['bm', 'weekday', 'hour',]\n# df_train['hour'] = df_train['timestamp'].dt.hour\n# df_train['weekday'] = df_train['timestamp'].dt.weekday\n# df_train['bm'] = df_train['building_id'].apply(lambda x: str(x)) + '_' + df_train['meter'].apply(lambda x: str(x))\n# bm = df_train.groupby(bm_cols)['meter_reading'].mean().rename('bm_week_hour').to_frame()","4f073dac":"# df_train = df_train.merge(bm, right_index=True, left_on=bm_cols, how='left')\n# df_train.drop(['bm'], axis=1, inplace=True)\n# df_train.head()","13a1e13f":"# Original code from https:\/\/www.kaggle.com\/aitude\/ashrae-missing-weather-data-handling by @aitude\n\ndef fill_weather_dataset(weather_df):\n    \n    # Find Missing Dates\n    time_format = \"%Y-%m-%d %H:%M:%S\"\n    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n    total_hours = int(((end_date - start_date).total_seconds() + 3600) \/ 3600)\n    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n    \n    missing_hours = []\n    for site_id in range(16):\n        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n        new_rows['site_id'] = site_id\n        weather_df = pd.concat([weather_df,new_rows])\n\n        weather_df = weather_df.reset_index(drop=True)           \n\n    # Add new Features\n    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n    weather_df[\"day\"] = weather_df[\"timestamp\"].dt.day\n    weather_df[\"week\"] = weather_df[\"timestamp\"].dt.week\n    weather_df[\"month\"] = weather_df[\"timestamp\"].dt.month\n    \n    # Reset Index for Fast Update\n    weather_df = weather_df.set_index(['site_id','day','month'])\n\n    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n    weather_df.update(air_temperature_filler,overwrite=False)\n\n    # Step 1\n    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n    # Step 2\n    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n\n    weather_df.update(cloud_coverage_filler,overwrite=False)\n\n    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n    weather_df.update(due_temperature_filler,overwrite=False)\n\n    # Step 1\n    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n    # Step 2\n    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n\n    weather_df.update(sea_level_filler,overwrite=False)\n\n    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n    weather_df.update(wind_direction_filler,overwrite=False)\n\n    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n    weather_df.update(wind_speed_filler,overwrite=False)\n\n    # Step 1\n    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n    # Step 2\n    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n\n    weather_df.update(precip_depth_filler,overwrite=False)\n\n    weather_df = weather_df.reset_index()\n    weather_df = weather_df.drop(['day','week','month'],axis=1)\n        \n    return weather_df\n\n# Original code from https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage by @gemartin\n\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\"\n    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \"\"\"\n    \n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef features_engineering(df):\n    \n    # Sort by timestamp\n    df.sort_values(\"timestamp\")\n    df.reset_index(drop=True)\n    \n    # Add more features\n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n    df[\"weekday\"] = df[\"timestamp\"].dt.weekday\n    \n    df['square_feet'] =  np.log1p(df['square_feet'])\n    df['sm'] = df['site_id'].apply(lambda x: str(x)) + '_' + df['meter'].apply(lambda x: str(x))\n    \n    \n    # Remove Unused Columns\n    drop = [\"timestamp\",'site_id',\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n    df = df.drop(drop, axis=1)\n    gc.collect()\n    \n    # Encode Categorical Data\n    le = LabelEncoder()\n    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n    \n    # reduce memory\n    df = reduce_mem_usage(df, use_float16=True)\n    \n    return df","ac130017":"def rmse(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(ypred - ytrue), axis=0))\ndef rmsle(ytrue, ypred):\n    return np.sqrt(np.mean(np.square(np.log1p(ypred) - np.log1p(ytrue)), axis=0))","5aba348e":"weather_train = fill_weather_dataset(weather_train)","613e4edc":"df_train = reduce_mem_usage(df_train,use_float16=True)\nbuilding = reduce_mem_usage(building,use_float16=True)\nweather_train = reduce_mem_usage(weather_train,use_float16=True)","6dc4f5fc":"df_train = df_train.merge(building, left_on='building_id',right_on='building_id',how='left')\ndf_train = df_train.merge(weather_train,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\ndel weather_train\ngc.collect()","c3cc03e9":"%%time\ndf_train = features_engineering(df_train)","e91cdef2":"df_train.head()","c079950e":"y_train = np.log1p(df_train[\"meter_reading\"])\nX_train = df_train.drop('meter_reading', axis = 1)\ndel df_train\ngc.collect()","dc3db9f3":"%%time\ncategorical_features = ['sm', \"building_id\", \"meter\", \"primary_use\", \"weekday\"]\nparams = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 1280,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\",\n    \"num_threads\": 2\n}\n\npred_L1 = []\nvalid_L1 = []\nseed = None\nkf = KFold(n_splits=3, random_state=seed)\n\nmodels = []\nfor train_index,test_index in kf.split(X_train):\n    train_features = X_train.loc[train_index]\n    train_target = y_train.loc[train_index]\n    \n    test_features = X_train.loc[test_index]\n    test_target = y_train.loc[test_index]\n    \n    d_training = lgb.Dataset(train_features, label=train_target,categorical_feature=categorical_features, free_raw_data=False)\n    d_test = lgb.Dataset(test_features, label=test_target,categorical_feature=categorical_features, free_raw_data=False)\n    \n    model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n    models.append(model)\n    pred_L1.append(model.predict(test_features))\n    valid_L1.append(test_target)\n    \n    del train_features, train_target, test_features, test_target, d_training, d_test\n    gc.collect()","941c4797":"del X_train, y_train\ngc.collect()","6e8f3083":"for model in models:\n    lgb.plot_importance(model)\n    plt.show()","7af5cb3d":"df_test = pd.read_feather('..\/input\/ashrae-feather\/test.ft')\nrow_ids = df_test[\"row_id\"]\ndf_test.drop(\"row_id\", axis=1, inplace=True)\ndf_test = reduce_mem_usage(df_test)","282c8f69":"# df_test['hour'] = df_test['timestamp'].dt.hour\n# df_test['weekday'] = df_test['timestamp'].dt.weekday\n# df_test['bm'] = df_test['building_id'].apply(lambda x: str(x)) + '_' + df_test['meter'].apply(lambda x: str(x))\n# df_test = df_test.merge(bm, right_index=True, left_on=bm_cols, how='left')\n# df_test.drop('bm', axis=1, inplace=True)","99bdae97":"df_test = df_test.merge(building,left_on='building_id',right_on='building_id',how='left')\ndel building\ngc.collect()","58daa7a1":"weather_test = fill_weather_dataset(weather_test)\nweather_test = reduce_mem_usage(weather_test)","32a42648":"df_test = df_test.merge(weather_test,how='left',on=['timestamp','site_id'])\ndel weather_test\ngc.collect()","8402bed9":"df_test = features_engineering(df_test)","07eefc41":"df_test.info()","f836315e":"df_test.head()","0edc4bcb":"%%time\npred = []\nfor model in tqdm(models):\n    if  pred == []:\n        pred = np.expm1(model.predict(df_test, num_iteration=model.best_iteration)) \/ len(models)\n    else:\n        pred += np.expm1(model.predict(df_test, num_iteration=model.best_iteration)) \/ len(models)\n    del model\n    gc.collect()","940f6f2e":"# save model to file\npickle.dump(models, open(\"models.pkl\", \"wb\"))\npickle.dump(pred_L1, open(\"pred_L1.pkl\", \"wb\"))\npickle.dump(valid_L1, open(\"valid_L1.pkl\", \"wb\"))","d70d2dae":"del df_test, models\ngc.collect()","0fff5a04":"submission = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(pred, 0, a_max=None)})\ndel row_ids, pred\ngc.collect()\nsubmission['meter_reading'] = submission['meter_reading'].astype('float32')\nsubmission['row_id'] = submission['row_id'].astype('int32')\nsubmission.to_csv(\"submission.csv\", index=False, chunksize=25000)","1578196f":"submission.head()","709c849c":"print(f\"submission mean: {submission['meter_reading'].mean():.4f}\")\nprint(f\"submission std: {submission['meter_reading'].std():.4f}\")\nprint(f\"submission min: {submission['meter_reading'].min():.4f}\")\nprint(f\"submission max: {submission['meter_reading'].max():.4f}\")","8fa3a547":"sns.distplot(np.log1p(submission['meter_reading'].values), kde=False);\ngc.collect()","db38a9bb":"site0 = pd.read_feather('..\/input\/ucf-building-meter-reading\/site0.ft')\ndf_test = pd.read_feather('..\/input\/ashrae-feather\/test.ft')","b89dfd22":"merged = df_test.merge(site0, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","0c9a40a2":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","4517bd6a":"print(f'RMSLE of buildings 0-104: {rmsle(ytrue, pred):.4f}')","aab74c7b":"site1 = pd.read_feather('..\/input\/ucl-data-leakage-episode-2\/site1.ft')\nsite1 = site1.query('timestamp >= 2017')","978f691f":"merged = df_test.merge(site1, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","452a2dff":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","1117847b":"del site1, merged\nprint(f'RMSLE of buildings 105-155: {rmsle(ytrue, pred):.4f}')","faf40262":"site2 = pd.read_feather('..\/input\/asu-feather\/site2.ft')\nsite2 = site2.query('timestamp >= 2017')","6a2293ac":"merged = df_test.merge(site2, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","8039c4a7":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","2581d0ba":"del site2, merged\nprint(f'RMSLE of buildings 156-290: {rmsle(ytrue, pred):.4f}')","95300e07":"site4 = pd.read_feather('..\/input\/ucb-feather\/site4.ft')\nsite4 = site4.query('timestamp >= 2017')","d4f6df6c":"merged = df_test.merge(site4, left_on=['building_id', 'timestamp'], \n              right_on=['building_id', 'timestamp'], how='left')","a1da56fb":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","f2389ac8":"del site4, merged\nprint(f'RMSLE of 74\/91 buildings : {rmsle(ytrue, pred):.4f}')","18bc25c3":"site15 = pd.read_feather('..\/input\/cornell-feather\/site15.ft')\nsite15 = site15.query('timestamp >= 2017')\nsite15 = site15.drop_duplicates()","dcdbee8a":"merged = df_test.merge(site15, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","6e7468df":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","4ad5876d":"del site15, merged\nprint(f'RMSLE of buildings 1325-1448: {rmsle(ytrue, pred):.4f}')","54d38008":"site012 = pd.read_feather('..\/input\/comb-leaked-dataset\/site012.ft')\nsite012 = site012.query('timestamp >= 2017')","b89d746e":"merged = df_test.merge(site012, left_on=['building_id', 'meter', 'timestamp'], \n              right_on=['building_id', 'meter', 'timestamp'], how='left')","599cd33d":"ytrue = merged[~merged['meter_reading'].isna()]['meter_reading']\npred = submission[~merged['meter_reading'].isna()]['meter_reading']","615831e8":"del site012, merged\ngc.collect()\nprint(f'RMSLE of buildings 0-290: {rmsle(ytrue, pred):.4f}')","d16abd89":"## Merge Weather Data","24e79741":"## Load Test Data","ce3e2117":"# Submission Validation UCB Site4 (74 blds)","056a0b2e":"## Utility Functions","b391355d":"## Fill Weather Information","65493497":"## Fill Weather Information\n\nI'm using [this kernel](https:\/\/www.kaggle.com\/aitude\/ashrae-missing-weather-data-handling) to handle missing weather information.","0e40a32a":"# Submission Validation ASU Site2 (bld 156-290)","5df4666e":"## Features Engineering","b11c8340":"## Features & Target Variables","058f6418":"# Submission Validation UCL Site1 (bld 105-155)","952845cf":"##  KFOLD LIGHTGBM Model","fb3d822d":"## Important Features","52d7f318":"# Save Model","0bd2cb13":"## Submission","2c7f939f":"# Submission Validation Cornell Site15 (bld 1325-1448)","0f0f4e38":"credit to:\n@aitude for \nhttps:\/\/www.kaggle.com\/aitude\/ashrae-kfold-lightgbm-without-leak-1-08","d789cbf3":"## Memory Reduction","43ffd09f":"## Features Engineering","97e7af62":"# Submission Validation UCF Site0 (bld 0-104)","d66044bf":"## Prediction","a0618525":"## Merge Building Data","6419247e":"## Merge Data\n\nWe need to add building and weather information into training dataset.","ca7df122":"# Submission Validation Site0-2 (bld 0-290)"}}