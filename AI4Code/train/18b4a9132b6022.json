{"cell_type":{"a23f9579":"code","f32e2fe7":"code","8c13dd9a":"code","1739c76d":"code","fe1c900a":"code","3d242b1f":"code","5b06026c":"code","3fffab59":"code","0ba7269d":"code","93b5ca5d":"code","540e1c98":"code","f45ca928":"code","f3373dd0":"code","dcf98f69":"code","6c417f71":"markdown","3bc25cdd":"markdown","778da46d":"markdown","1c4279c3":"markdown","4a4aaa31":"markdown","697b4d97":"markdown","80fc63de":"markdown","d2e40fce":"markdown","4d447a2b":"markdown"},"source":{"a23f9579":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nimport plotly as py\nimport plotly.graph_objs as go\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn import preprocessing \nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering \n","f32e2fe7":"df = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndf.head()","8c13dd9a":"df.isnull().sum()","1739c76d":"df.describe()","fe1c900a":"plt.figure(1 , figsize = (15 , 6))\nn = 0 \nfor x in ['Age' , 'Annual Income (k$)' , 'Spending Score (1-100)']:\n    n += 1\n    plt.subplot(1 , 3 , n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n    sns.distplot(df[x] , bins = 15)\n    plt.title('Distplot of {}'.format(x))\nplt.show()","3d242b1f":"label_encoder = preprocessing.LabelEncoder() \n\ndf['Gender'] = label_encoder.fit_transform(df['Gender'])\ndf.head()","5b06026c":"plt.figure(1, figsize = (16 ,8))\nsns.heatmap(df)\nplt.show()","3fffab59":"plt.figure(1, figsize = (16 ,8))\ndendrogram = sch.dendrogram(sch.linkage(df, method  = \"ward\"))\n\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.show()","0ba7269d":"hc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage ='average')\n\ny_hc = hc.fit_predict(df)\ny_hc","93b5ca5d":"df['cluster'] = pd.DataFrame(y_hc)","540e1c98":"trace1 = go.Scatter3d(\n    x= df['Age'],\n    y= df['Spending Score (1-100)'],\n    z= df['Annual Income (k$)'],\n    mode='markers',\n     marker=dict(\n        color = df['cluster'], \n        size= 10,\n        line=dict(\n            color= df['cluster'],\n            width= 12\n        ),\n        opacity=0.8\n     )\n)\ndata = [trace1]\nlayout = go.Layout(\n    title= 'Clusters using Agglomerative Clustering',\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Spending Score'),\n            zaxis = dict(title  = 'Annual Income')\n        )\n)\nfig = go.Figure(data=data, layout=layout)\npy.offline.iplot(fig)","f45ca928":"X = df.iloc[:, [3,4]].values\nplt.scatter(X[y_hc==0, 0], X[y_hc==0, 1], s=100, c='red', label ='Cluster 1')\nplt.scatter(X[y_hc==1, 0], X[y_hc==1, 1], s=100, c='blue', label ='Cluster 2')\nplt.scatter(X[y_hc==2, 0], X[y_hc==2, 1], s=100, c='green', label ='Cluster 3')\nplt.scatter(X[y_hc==3, 0], X[y_hc==3, 1], s=100, c='purple', label ='Cluster 4')\nplt.scatter(X[y_hc==4, 0], X[y_hc==4, 1], s=100, c='orange', label ='Cluster 5')\nplt.title('Clusters of Customers (Hierarchical Clustering Model)')\nplt.xlabel('Annual Income(k$)')\nplt.ylabel('Spending Score(1-100)')\nplt.show()","f3373dd0":"df.head()","dcf98f69":"df.to_csv(\"segmented_customers.csv\", index = False)","6c417f71":"## Cluster Analysis\n\n1. Green - Low Income, Low Spending\n2. Yellow - Low Income, High Spending\n3. Red - Medium Income, Medium Spending\n4. Purple - High Income, Low Spending\n5. Blue - High Income, High Spending","3bc25cdd":"## Heatmap\n\nA heat map is a data visualization technique that shows magnitude of a phenomenon as color in two dimensions. The variation in color may be by hue or intensity, giving obvious visual cues to the reader about how the phenomenon is clustered or varies over space.","778da46d":"## Final Note\n\nThus, we have analysed Customer data and performed Hierarchical Clustering using Agglomerative Clustering Algorithm. This kind of cluster analysis helps design better customer acquisition strategies and helps in business growth. Let me know your feedback for this notebook, happy kaggling :)","1c4279c3":"## Agglomerative Clustering\n\nThis is a \"bottom-up\" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.","4a4aaa31":"## Hierarchical Clustering for Customer Data\n\n![clustering image](https:\/\/cdn.educba.com\/academy\/wp-content\/uploads\/2019\/11\/Hierarchical-Clustering-Analysis.png)\n\n### Clustering\nClustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group than those in other groups. In simple words, the aim is to segregate groups with similar traits and assign them into clusters.\n\n### Hierarchical Clustering \nHierarchical clustering, also known as hierarchical cluster analysis, is an algorithm that groups similar objects into groups called clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other.\n\n### About the dataset\nThis input file contains the basic information (ID, age, gender, income, spending score) about the customers of a mall. Spending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data.","697b4d97":"## Dendrogram\n\nA dendrogram is a diagram representing a tree. This diagrammatic representation is frequently used in different contexts: in hierarchical clustering, it illustrates the arrangement of the clusters produced by the corresponding analyses. ","80fc63de":"## Data Exploration","d2e40fce":"## Hierarchical Clustering for Customer Data","4d447a2b":"## Label Encoding\n\nLabel Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form. Machine learning algorithms can then decide in a better way on how those labels must be operated. \n"}}