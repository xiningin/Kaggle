{"cell_type":{"e28a9d7c":"code","2806e00b":"code","9b02222c":"code","a4375cbc":"code","4d7f6719":"code","ffbbd69a":"code","36db91a9":"code","0d4eb79f":"markdown","bb45412c":"markdown","fda8c24c":"markdown","bb9e603b":"markdown","6f95d583":"markdown","f6fb5576":"markdown","5360e3b0":"markdown"},"source":{"e28a9d7c":"# For testing, multiprocessing and chaining dictionaries\nimport numpy as np\nimport multiprocessing\nfrom collections import ChainMap","2806e00b":"# Default RLenc\ndef RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  # list of run lengths\n    r = 0  # the current run length\n    pos = 1  # count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n","9b02222c":"class Consumer(multiprocessing.Process):\n    \"\"\"Consumer for performing a specific task.\"\"\"\n\n    def __init__(self, task_queue, result_queue):\n        \"\"\"Initialize consumer, it has a task and result queues.\"\"\"\n        multiprocessing.Process.__init__(self)\n        self.task_queue = task_queue\n        self.result_queue = result_queue\n\n    def run(self):\n        \"\"\"Actual run of the consumer.\"\"\"\n        while True:\n            next_task = self.task_queue.get()\n            if next_task is None:\n                # Poison pill means shutdown\n                self.task_queue.task_done()\n                break\n            # Fetch answer from task\n            answer = next_task()\n            self.task_queue.task_done()\n            # Put into result queue\n            self.result_queue.put(answer)\n        return\n\n\nclass RleTask(object):\n    \"\"\"Wrap the RLE Encoder into a Task.\"\"\"\n\n    def __init__(self, idx, img):\n        \"\"\"Save image to self.\"\"\"\n        self.img = img\n        self.idx = idx\n\n    def __call__(self):\n        \"\"\"When object is called, encode.\"\"\"\n        return {self.idx: RLenc(self.img)}\n\n\nclass FastRle(object):\n    \"\"\"Perform RLE in paralell.\"\"\"\n\n    def __init__(self, num_consumers=2):\n        \"\"\"Initialize class.\"\"\"\n        self._tasks = multiprocessing.JoinableQueue()\n        self._results = multiprocessing.Queue()\n        self._n_consumers = num_consumers\n\n        # Initialize consumers\n        self._consumers = [Consumer(self._tasks, self._results) for i in range(self._n_consumers)]\n        for w in self._consumers:\n            w.start()\n\n    def add(self, img, idx):\n        \"\"\"Add a task to perform.\"\"\"\n        self._tasks.put(RleTask(img, idx))\n\n    def get_results(self):\n        \"\"\"Close all tasks.\"\"\"\n        # Provide poison pill\n        [self._tasks.put(None) for _ in range(self._n_consumers)]\n        # Wait for finish\n        self._tasks.join()\n        # Return results\n        singles = []\n        while not self._results.empty():\n            singles.append(self._results.get())\n        return dict(ChainMap({}, *singles))","a4375cbc":"#even faster RLE encoder\ndef toRunLength(x, firstDim = 2):\n    \n    if firstDim == 2:\n        x = np.swapaxes(x, 1,2)\n    \n    x = (x > 0.5).astype(int)\n    x = x.reshape((x.shape[0], -1))    \n    x = np.pad(x, ((0,0),(1,1)), 'constant')\n    \n    x = x[:,1:] - x[:,:-1]\n    starts = x > 0\n    ends = x < 0\n    \n    rang = np.arange(x.shape[1])\n    \n    results = []\n    \n    for image, imStarts, imEnds in zip(x, starts, ends):\n        st = rang[imStarts]\n        en = rang[imEnds]\n        \n#         counts = (en-st).astype(str)\n#         st = (st+1).astype(str)\n        \n#         res = np.stack([st,counts], axis=-1).reshape((-1,))\n#         res = np.core.defchararray.join(\" \", res)\n\n        res = \"\"\n        for s,e in zip(st,en):\n            res += str(s+1) + \" \" + str(e-s) + \" \"\n            \n        results.append(res[:-1])\n    #print(\"called\")\n        \n    return results","4d7f6719":"class FasterTask(object):\n    \"\"\"Wrap the RLE Encoder into a Task.\"\"\"\n\n    def __init__(self, array, startIndex):\n        \"\"\"Save array to self.\"\"\"\n        self.array = array\n        self.startIndex = startIndex\n\n    def __call__(self):\n        \"\"\"When object is called, encode.\"\"\"\n        return (toRunLength(self.array), self.startIndex)\n\n\nclass FasterRle(object):\n    \"\"\"Perform RLE in paralell.\"\"\"\n\n    def __init__(self, num_consumers=2):\n        \"\"\"Initialize class.\"\"\"\n        self._tasks = multiprocessing.JoinableQueue()\n        self._results = multiprocessing.Queue()\n        self._n_consumers = num_consumers\n\n        # Initialize consumers\n        self._consumers = [Consumer(self._tasks, self._results) for i in range(self._n_consumers)]\n        for w in self._consumers:\n            w.start()\n\n    def add(self, array, startIndex):\n        \"\"\"Add a task to perform.\"\"\"\n        self._tasks.put(FasterTask(array, startIndex))\n\n    def get_results(self):\n        \"\"\"Close all tasks.\"\"\"\n        # Provide poison pill\n        [self._tasks.put(None) for _ in range(self._n_consumers)]\n        # Wait for finish\n        self._tasks.join()\n        # Return results\n        singles = []\n        while not self._results.empty():\n            singles.append(self._results.get())\n            \n        resultDic = dict()\n        for rles, start in singles:\n            #print('start:', start)\n            for i,rle in enumerate(rles):\n                #print('i:', i)\n                resultDic[str(start+i)] = rle\n        return resultDic","ffbbd69a":"example_image = np.random.uniform(0, 1, size=(1000, 101, 101)) > 0.5\n\n# Wrap the FastRle class into a method so we measure the time\ndef original(array):\n    results = {}\n    for i, arr in enumerate(array):\n        results['%d' % i] = RLenc(arr)\n    return results\n\ndef faster(array):\n    rle = FastRle(4)\n    for i, arr in enumerate(array):\n        rle.add('%d' % i, arr)\n    return rle.get_results()\n\ndef pureNumpy(array):\n    rle = toRunLength(array)\n    rle = {'%d' % i: row for i,row in enumerate(rle)}\n    return rle\n\ndef evenFaster(array):\n    #make sure you treat this properly when len(array) % 4 != 0\n    rle = FasterRle(4)\n    subSize = len(array)\/\/4  \n    \n    for i in range(0,len(array),subSize):\n        rle.add(array[i:i+subSize], i)\n    return rle.get_results()\n\nprint(\"Measuring times: \\n\")\nprint(\"Original:\")\n%timeit original(example_image)\nprint(\"\\nParallel:\")\n%timeit faster(example_image)\nprint(\"\\nPure numpy:\")\n%timeit pureNumpy(example_image)\nprint(\"\\nEven faster:\")\n%timeit evenFaster(example_image)\n","36db91a9":"example_image = np.random.uniform(0, 1, size=(12, 101, 101)) > 0.5\nx = faster(example_image)\ny = original(example_image)\nz = pureNumpy(example_image)\nw = evenFaster(example_image)\n\n# Make sure they are the same\nprint(\"Comparing values:\\n\")\n\ncomparison = []\nfor key in x:\n    comparison.append(x[key] == y[key])\nprint('Original vs Parallel:', np.all(comparison))\n\ncomparison = []\nfor key in x:\n    comparison.append(x[key] == z[key])\nprint(\"Original vs pure numpy:\",np.all(comparison))\n\ncomparison = []\nfor key in x:\n    comparison.append(x[key] == w[key])\nprint(\"Original vs even faster:\",np.all(comparison))","0d4eb79f":"### Even faster RLE by using the proposed solution in parallel","bb45412c":"### RLE with parallel processing","fda8c24c":"# Validation\n\nJust to make sure all functions output the same for the same input images.","bb9e603b":"# Introduction\n\nThis kernel was forked from an older version from [Faster RLE](https:\/\/www.kaggle.com\/adamhart\/faster-rle) by @Adam Hart\n\n\"I don't really like waiting, so I wanted to speed up the submission process a little bit. So here is a class you can use to utilize multiprocessing in Python for creating the submission file.\"\n\n## Speed comparisons\n\nWe will compare four kinds of encoding functions, as defined below:\n\n- Original RLE (from the forked kernel)    \n- Multiprocessing with the original RLE (great improvement in time)     \n- **Proposed:** Pure numpy function (a little slower than the multiprocessed version)    \n- Multiprocessed pure numpy function\n\n## Warning\n\nFor some reason I can't figure out, sometimes the last section if this kernel fails when validating the multiprocessed numpy encoder.   \nIt's as if some of the 4 processes never got run.   \n\n## Function definitions\n\nThe functions are defined as follows.","6f95d583":"### Original RLE","f6fb5576":"> ### Proposed faster RLE using pure numpy","5360e3b0":"# Comparisons\n\nHere, we test the time it takes for each of the 4 functions to run. "}}