{"cell_type":{"065d620f":"code","ff9be62f":"code","bf3626be":"code","c2794295":"code","df7d87ad":"code","59822e30":"code","81b91da9":"code","266fade2":"code","a3a4661f":"code","0ca1fc18":"code","3e6e6b56":"code","6b232cc5":"code","c90ac043":"code","2d4d4c43":"code","cabe2f58":"code","248ab774":"code","b80c2d06":"code","cfc7b919":"code","408b8334":"code","326d6d80":"code","bd8d04b6":"code","e939f478":"code","d2495ab4":"code","13bdb259":"code","633e7650":"code","b9ddb5e1":"code","1ceabb3c":"code","7c8d26b1":"code","5a893bd5":"code","f598d153":"code","f3aaea72":"code","4959a528":"code","2fb3a074":"code","23b9c29e":"code","b41f1506":"code","250f2a3a":"code","512c966f":"code","e4ccf946":"code","f0d63022":"code","96a739b0":"code","f2549e35":"code","37863b44":"code","723c4012":"code","9d353fd8":"code","f9a0bc29":"code","a03c83f5":"code","cfe7d59b":"code","2276615b":"code","d7e00fe4":"code","487168df":"code","cc3bfe0d":"code","d3f3a527":"markdown","1eab18e9":"markdown","589f277d":"markdown","0b349b67":"markdown","8c31ec4d":"markdown","99b736a3":"markdown","162f2997":"markdown","fb32bb04":"markdown","e5778052":"markdown","6a7c8dda":"markdown","c33e0c15":"markdown","13848c1e":"markdown","8f47a0c3":"markdown","7d795bef":"markdown","87a4f7cd":"markdown","b61f2fa4":"markdown","a46fcfde":"markdown","07becfd2":"markdown","8a8c8c91":"markdown","4c92d06a":"markdown","de147379":"markdown","4d2d6cee":"markdown","e0db5919":"markdown","9b8d85ad":"markdown","270cd4de":"markdown","aeb12de7":"markdown","57ef2ee7":"markdown","87b876fc":"markdown","648a1ce8":"markdown","04005d6a":"markdown","96228ac0":"markdown","b92d47c8":"markdown","a82cc237":"markdown","44bf3761":"markdown","dfac0aa8":"markdown"},"source":{"065d620f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport warnings\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport json\nfrom sklearn.preprocessing import LabelEncoder\nwarnings.filterwarnings(\"ignore\")","ff9be62f":"train = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\ntrain.info()","bf3626be":"test = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')\ntest.info()","c2794295":"train.head()","df7d87ad":"test.head()","59822e30":"train.describe(include='all')","81b91da9":"test.describe(include='all')","266fade2":"train.isna().sum()","a3a4661f":"test.isna().sum()","0ca1fc18":"sns.jointplot(x=\"budget\", y=\"revenue\", data=train, height=11, ratio=4, color=\"g\")\nplt.show()","3e6e6b56":"sns.jointplot(x=\"popularity\", y=\"revenue\", data=train, height=11, ratio=4, color=\"g\")\nplt.show()","6b232cc5":"sns.jointplot(x=\"runtime\", y=\"revenue\", data=train, height=11, ratio=4, color=\"g\")\nplt.show()","c90ac043":"sns.distplot(train.revenue)","2d4d4c43":"train.revenue.describe()","cabe2f58":"train['logRevenue'] = np.log1p(train['revenue'])\nsns.distplot(train['logRevenue'] )","248ab774":"#Since only last two digits of year are provided, this is the correct way of getting the year.\ntrain[['release_month','release_day','release_year']]=train['release_date'].str.split('\/',expand=True).replace(np.nan, -1).astype(int)\n# Some rows have 4 digits of year instead of 2, that's why I am applying (train['release_year'] < 100) this condition\ntrain.loc[ (train['release_year'] <= 19) & (train['release_year'] < 100), \"release_year\"] += 2000\ntrain.loc[ (train['release_year'] > 19)  & (train['release_year'] < 100), \"release_year\"] += 1900\n\nreleaseDate = pd.to_datetime(train['release_date']) \ntrain['release_dayofweek'] = releaseDate.dt.dayofweek\ntrain['release_quarter'] = releaseDate.dt.quarter","b80c2d06":"plt.figure(figsize=(20,12))\nsns.countplot(train['release_year'].sort_values())\nplt.title(\"Movie Release count by Year\",fontsize=20)\nloc, labels = plt.xticks()\nplt.xticks(fontsize=12,rotation=90)\nplt.show()","cfc7b919":"plt.figure(figsize=(20,12))\nsns.countplot(train['release_month'].sort_values())\nplt.title(\"Release Month Count\",fontsize=20)\nloc, labels = plt.xticks()\nloc, labels = loc, [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\nplt.xticks(loc, labels,fontsize=20)\nplt.show()","408b8334":"plt.figure(figsize=(20,12))\nsns.countplot(train['release_day'].sort_values())\nplt.title(\"Release Day Count\",fontsize=20)\nplt.xticks(fontsize=20)\nplt.show()","326d6d80":"plt.figure(figsize=(20,12))\nsns.countplot(train['release_dayofweek'].sort_values())\nplt.title(\"Total movies released on Day Of Week\",fontsize=20)\nloc, labels = plt.xticks()\nloc, labels = loc, [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\nplt.xticks(loc, labels,fontsize=20)\nplt.show()","bd8d04b6":"plt.figure(figsize=(20,12))\nsns.countplot(train['release_quarter'].sort_values())\nplt.title(\"Total movies released in a quarter\",fontsize=20)\nplt.show()","e939f478":"train['meanRevenueByYear'] = train.groupby(\"release_year\")[\"revenue\"].aggregate('mean')\ntrain['meanRevenueByYear'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(1920,2018,4))\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue By Year\",fontsize=20)\nplt.show()","d2495ab4":"train['meanRevenueByMonth'] = train.groupby(\"release_month\")[\"revenue\"].aggregate('mean')\ntrain['meanRevenueByMonth'].plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Month\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue Release Month\",fontsize=20)\nplt.show()","13bdb259":"train['meanRevenueByDayOfWeek'] = train.groupby(\"release_dayofweek\")[\"revenue\"].aggregate('mean')\ntrain['meanRevenueByDayOfWeek'].plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Day of Week\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue by Day of Week\",fontsize=20)\nplt.show()","633e7650":"train['meanRevenueByQuarter'] = train.groupby(\"release_quarter\")[\"revenue\"].aggregate('mean')\ntrain['meanRevenueByQuarter'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(1,5,1))\nplt.xlabel(\"Quarter\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue by Quarter\",fontsize=20)\nplt.show()","b9ddb5e1":"train['meanruntimeByYear'] = train.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\ntrain['meanruntimeByYear'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(1920,2018,4))\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Runtime\")\nplt.title(\"Movie Mean Runtime by Year\",fontsize=20)\nplt.show()","1ceabb3c":"train['meanPopularityByYear'] = train.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\ntrain['meanPopularityByYear'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(1920,2018,4))\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Popularity\")\nplt.title(\"Movie Mean Popularity by Year\",fontsize=20)\nplt.show()","7c8d26b1":"train['meanBudgetByYear'] = train.groupby(\"release_year\")[\"budget\"].aggregate('mean')\ntrain['meanBudgetByYear'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(1920,2018,4))\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Budget\")\nplt.title(\"Movie Mean Budget by Year\",fontsize=20)\nplt.show()","5a893bd5":"def get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d\ntrain = train\ntrain['genres'] = train['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ngenres = train.genres.str.get_dummies(sep=',')\ntrain = pd.concat([train, genres], axis=1, sort=False)\nprint(\"Action Genres Movie           \", train[train.Action == 1].shape[0])\nprint(\"Adventure Genres Movie        \", train[train.Adventure == 1].shape[0])\nprint(\"Animation Genres Movie        \", train[train.Animation == 1].shape[0])\nprint(\"Comedy Genres Movie           \", train[train.Comedy == 1].shape[0])\nprint(\"Crime Genres Movie            \", train[train.Crime == 1].shape[0])\nprint(\"Documentary Genres Movie      \", train[train.Documentary == 1].shape[0])\nprint(\"Drama Genres Movie            \", train[train.Drama == 1].shape[0])\nprint(\"Family Genres Movie           \", train[train.Family == 1].shape[0])\nprint(\"Fantasy Genres Movie          \", train[train.Fantasy == 1].shape[0])\nprint(\"Foreign Genres Movie          \", train[train.Foreign == 1].shape[0])\nprint(\"History Genres Movie          \", train[train.History == 1].shape[0])\nprint(\"Music Genres Movie            \", train[train.Music == 1].shape[0])\nprint(\"Mystery Genres Movie          \", train[train.Mystery == 1].shape[0])\nprint(\"Romance Genres Movie          \", train[train.Romance == 1].shape[0])\nprint(\"Science Fiction Genres Movie  \", train[train['Science Fiction'] == 1].shape[0])\nprint(\"TV Movie Genres Movie         \", train[train['TV Movie'] == 1].shape[0])\nprint(\"Thriller Genres Movie         \", train[train.Thriller == 1].shape[0])\nprint(\"War Genres Movie              \", train[train.War == 1].shape[0])\nprint(\"Western Genres Movie          \", train[train.Western == 1].shape[0])","f598d153":"test = test\ntest['genres'] = test['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ngenres = test.genres.str.get_dummies(sep=',')\ntest = pd.concat([test, genres], axis=1, sort=False)\nprint(\"Action Genres Movie           \", test[test.Action == 1].shape[0])\nprint(\"Adventure Genres Movie        \", test[test.Adventure == 1].shape[0])\nprint(\"Animation Genres Movie        \", test[test.Animation == 1].shape[0])\nprint(\"Comedy Genres Movie           \", test[test.Comedy == 1].shape[0])\nprint(\"Crime Genres Movie            \", test[test.Crime == 1].shape[0])\nprint(\"Documentary Genres Movie      \", test[test.Documentary == 1].shape[0])\nprint(\"Drama Genres Movie            \", test[test.Drama == 1].shape[0])\nprint(\"Family Genres Movie           \", test[test.Family == 1].shape[0])\nprint(\"Fantasy Genres Movie          \", test[test.Fantasy == 1].shape[0])\nprint(\"Foreign Genres Movie          \", test[test.Foreign == 1].shape[0])\nprint(\"History Genres Movie          \", test[test.History == 1].shape[0])\nprint(\"Music Genres Movie            \", test[test.Music == 1].shape[0])\nprint(\"Mystery Genres Movie          \", test[test.Mystery == 1].shape[0])\nprint(\"Romance Genres Movie          \", test[test.Romance == 1].shape[0])\nprint(\"Science Fiction Genres Movie  \", test[test['Science Fiction'] == 1].shape[0])\nprint(\"TV Movie Genres Movie          0\")\nprint(\"Thriller Genres Movie         \", test[test.Thriller == 1].shape[0])\nprint(\"War Genres Movie              \", test[test.War == 1].shape[0])\nprint(\"Western Genres Movie          \", test[test.Western == 1].shape[0])","f3aaea72":"plt.figure(figsize=(20,15))\nsns.countplot(train['original_language'].sort_values())\nplt.title(\"Original Language Count\",fontsize=20)\nplt.show()","4959a528":"train['status'].value_counts()","2fb3a074":"train.loc[train['status'] == \"Rumored\"][['status','revenue']]","23b9c29e":"test['status'].value_counts()","b41f1506":"trainAdditionalFeatures = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TrainAdditionalFeatures.csv')\ntestAdditionalFeatures = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TestAdditionalFeatures.csv')\n\ntrain = pd.merge(train, trainAdditionalFeatures, how='left', on=['imdb_id'])\ntest = pd.merge(test, testAdditionalFeatures, how='left', on=['imdb_id'])","250f2a3a":"print(\"Missing rating in Train set\", train['rating'].isna().sum())\nprint(\"Missing total Votes in Train set\", train['totalVotes'].isna().sum())\nprint(\"\")\nprint(\"Missing rating in Test set\", test['rating'].isna().sum())\nprint(\"Missing total Votes in Test set\", test['totalVotes'].isna().sum())","512c966f":"train['rating'] = train['rating'].fillna(1.5)\ntrain['totalVotes'] = train['totalVotes'].fillna(6)\n\ntest['rating'] = test['rating'].fillna(1.5)\ntest['totalVotes'] = test['totalVotes'].fillna(6)","e4ccf946":"plt.figure(figsize=(20,12))\nsns.countplot(train['rating'].sort_values())\nplt.title(\"Train Rating Count\",fontsize=20)\nplt.show()","f0d63022":"plt.figure(figsize=(20,12))\nsns.countplot(test['rating'].sort_values())\nplt.title(\"Test set Rating Count\",fontsize=20)\nplt.show()","96a739b0":"train['meanRevenueByRating'] = train.groupby(\"rating\")[\"revenue\"].aggregate('mean')\ntrain['meanRevenueByRating'].plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue By Rating\",fontsize=20)\nplt.show()","f2549e35":"train['meanRevenueByTotalVotes'] = train.groupby(\"totalVotes\")[\"revenue\"].aggregate('mean')\ntrain['meanRevenueByTotalVotes'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(0,2500,500))\nplt.xlabel(\"Total Votes\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue By Total Votes\",fontsize=20)\nplt.show()","37863b44":"train['meantotalVotesByYear'] = train.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\ntrain['meantotalVotesByYear'].plot(figsize=(15,10),color=\"g\")\nplt.xticks(np.arange(1920,2018,4))\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Rating\")\nplt.title(\"Movie Mean Total Votes by Year\",fontsize=20)\nplt.show()","723c4012":"train['meanTotalVotesByRating'] = train.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\ntrain['meanTotalVotesByRating'].plot(figsize=(15,10),color=\"g\")\n#plt.xticks(np.arange(1920,2018,4))\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Total Votes\")\nplt.title(\"Movie Mean Total Votes by Rating\",fontsize=20)\nplt.show()","9d353fd8":"train = train[['budget','rating','totalVotes','popularity','runtime','release_year','release_month','release_dayofweek','revenue']]\nf,ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(train.corr(), annot=True)\nplt.show()","f9a0bc29":"def prepare(df):\n    global json_cols\n    global train_dict\n    df['rating'] = df['rating'].fillna(1.5)\n    df['totalVotes'] = df['totalVotes'].fillna(6)\n    df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) \/ ( df['totalVotes'] + 1000 )\n\n    df[['release_month','release_day','release_year']]=df['release_date'].str.split('\/',expand=True).replace(np.nan, 0).astype(int)\n    df['release_year'] = df['release_year']\n    df.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n    df.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n    \n    releaseDate = pd.to_datetime(df['release_date']) \n    df['release_dayofweek'] = releaseDate.dt.dayofweek \n    df['release_quarter'] = releaseDate.dt.quarter     \n\n    df['originalBudget'] = df['budget']\n    df['inflationBudget'] = df['budget'] + df['budget']*1.8\/100*(2018-df['release_year']) #Inflation simple formula\n    df['budget'] = np.log1p(df['budget']) \n    \n    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n    df['collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n    le = LabelEncoder()\n    le.fit(list(df['collection_name'].fillna('')))\n    df['collection_name'] = le.transform(df['collection_name'].fillna('').astype(str))\n    df['num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n    df['num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n\n    \n    \n    df['_popularity_mean_year'] = df['popularity'] \/ df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n    df['_budget_runtime_ratio'] = df['budget']\/df['runtime'] \n    df['_budget_popularity_ratio'] = df['budget']\/df['popularity']\n    df['_budget_year_ratio'] = df['budget']\/(df['release_year']*df['release_year'])\n    df['_releaseYear_popularity_ratio'] = df['release_year']\/df['popularity']\n    df['_releaseYear_popularity_ratio2'] = df['popularity']\/df['release_year']\n\n    df['_popularity_totalVotes_ratio'] = df['totalVotes']\/df['popularity']\n    df['_rating_popularity_ratio'] = df['rating']\/df['popularity']\n    df['_rating_totalVotes_ratio'] = df['totalVotes']\/df['rating']\n    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']\/df['release_year']\n    df['_budget_rating_ratio'] = df['budget']\/df['rating']\n    df['_runtime_rating_ratio'] = df['runtime']\/df['rating']\n    df['_budget_totalVotes_ratio'] = df['budget']\/df['totalVotes']\n    \n    df['has_homepage'] = 0\n    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 1\n    \n    df['isbelongs_to_collectionNA'] = 0\n    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n    \n    df['isTaglineNA'] = 0\n    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n\n    df['isOriginalLanguageEng'] = 0 \n    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n    \n    df['isTitleDifferent'] = 1\n    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n\n    df['isMovieReleased'] = 1\n    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n\n    # get collection id\n    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n    \n    df['original_title_letter_count'] = df['original_title'].str.len() \n    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n\n\n    df['title_word_count'] = df['title'].str.split().str.len()\n    df['overview_word_count'] = df['overview'].str.split().str.len()\n    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n    \n    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n    df['crew_count'] = df['cast'].apply(lambda x : len(x))\n\n    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\n    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n        temp = df[col].str.get_dummies(sep=',')\n        df = pd.concat([df, temp], axis=1, sort=False)\n    df.drop(['genres_etc'], axis = 1, inplace = True)\n    \n    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n    ],axis=1)\n    \n    df.fillna(value=0.0, inplace = True) \n\n    return df\ntrain = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\n\n#power_six = train.id[train.budget > 1000][train.revenue < 100]\n\n#for k in power_six :\n#    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000\n#Clean Datapower_six \ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n\n\n\ntest = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')\n\n#Clean Data\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6856,'budget'] = 10 \ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest['revenue'] = np.nan\n\n# features from https:\/\/www.kaggle.com\/kamalchhirang\/eda-simple-feature-engineering-external-data\ntrain = pd.merge(train, pd.read_csv('..\/input\/tmdb-competition-additional-features\/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\ntest = pd.merge(test, pd.read_csv('..\/input\/tmdb-competition-additional-features\/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n\nadditionalTrainData = pd.read_csv('..\/input\/tmdb-box-office-prediction-more-training-data\/additionalTrainData.csv')\nadditionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\nadditionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '\/')\ntrain = pd.concat([train, additionalTrainData])\n\n#train = pd.merge(train, additionalTrainData, how='left', on=['imdb_id'],axis=1)\nprint(train.columns)\nprint(train.shape)\ntrain['revenue'] = np.log1p(train['revenue'])\ny = train['revenue'].values\n\njson_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d\n\nfor col in tqdm(json_cols + ['belongs_to_collection']) :\n    train[col] = train[col].apply(lambda x : get_dictionary(x))\n    test[col] = test[col].apply(lambda x : get_dictionary(x))\n    \ndef get_json_dict(df) :\n    global json_cols\n    result = dict()\n    for e_col in json_cols :\n        d = dict()\n        rows = df[e_col].values\n        for row in rows :\n            if row is None : continue\n            for i in row :\n                if i['name'] not in d :\n                    d[i['name']] = 0\n                d[i['name']] += 1\n        result[e_col] = d\n    return result\n\ntrain_dict = get_json_dict(train)\ntest_dict = get_json_dict(test)\n\n# remove cateogry with bias and low frequency\nfor col in json_cols :\n    \n    remove = []\n    train_id = set(list(train_dict[col].keys()))\n    test_id = set(list(test_dict[col].keys()))   \n    \n    remove += list(train_id - test_id) + list(test_id - train_id)\n    for i in train_id.union(test_id) - set(remove) :\n        if train_dict[col][i] < 10 or i == '' :\n            remove += [i]\n            \n    for i in remove :\n        if i in train_dict[col] :\n            del train_dict[col][i]\n        if i in test_dict[col] :\n            del test_dict[col][i]\n            \nall_data = prepare(pd.concat([train, test]).reset_index(drop = True))\ntrain = all_data.loc[:train.shape[0] - 1,:]\ntest = all_data.loc[train.shape[0]:,:] ","a03c83f5":"from sklearn.model_selection import KFold\n\nrandom_seed = 2019\nk = 10\nfold = list(KFold(k, shuffle = True, random_state = random_seed).split(train))\nnp.random.seed(random_seed)","cfe7d59b":"import xgboost as xgb\n\ndef xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    params = {'objective': 'reg:linear', \n              'eta': 0.01, \n              'max_depth': 6, \n              'subsample': 0.6, \n              'colsample_bytree': 0.7,  \n              'eval_metric': 'rmse', \n              'seed': random_seed, \n              'silent': True,\n    }\n    \n    record = dict()\n    model = xgb.train(params\n                      , xgb.DMatrix(trn_x, trn_y)\n                      , 1000000\n                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n                      , verbose_eval=verbose\n                      , early_stopping_rounds=500\n                      , callbacks = [xgb.callback.record_evaluation(record)])\n    best_idx = np.argmin(np.array(record['valid']['rmse']))\n\n    val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n\n    return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}","2276615b":"import lightgbm as lgb\n\ndef lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n\n    params = {'objective':'regression',\n         'num_leaves' : 40,\n         'min_data_in_leaf' : 20,\n         'max_depth' : 4,\n         'learning_rate': 0.005,\n         \"feature_fraction\": 0.8,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.8,\n         \"bagging_seed\": random_seed,\n         \"metric\": 'rmse',\n         \"random_state\" : random_seed,\n         \"verbosity\": -1}\n\n    record = dict()\n    model = lgb.train(params\n                      , lgb.Dataset(trn_x, trn_y)\n                      , num_boost_round = 1000000\n                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n                      , verbose_eval = verbose\n                      , early_stopping_rounds = 500\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )\n    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\n    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n    test_pred = model.predict(test, num_iteration = model.best_iteration)\n    \n    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}","d7e00fe4":"from catboost import CatBoostRegressor\n\ndef cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    model = CatBoostRegressor(iterations=10000000,\n                                 learning_rate=0.005,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.7,\n                                 random_seed = random_seed,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=500\n                                )\n    model.fit(trn_x, trn_y,\n                 eval_set=(val_x, val_y),\n                 use_best_model=True,\n                 verbose=False)\n    \n    val_pred = model.predict(val_x)\n    test_pred = model.predict(test)\n    \n    return {'val':val_pred, 'test':test_pred, 'error':model.get_best_score()['validation_0']['RMSE'], 'importance':model.get_feature_importance()}","487168df":"result_dict = dict()\nval_pred = np.zeros(train.shape[0])\ntest_pred = np.zeros(test.shape[0])\nfinal_err = 0\nverbose = False\n\nfor i, (trn, val) in enumerate(fold) :\n    print(i+1, \"fold.    RMSE\")\n    \n    trn_x = train.loc[trn, :]\n    trn_y = y[trn]\n    val_x = train.loc[val, :]\n    val_y = y[val]\n    \n    fold_val_pred = []\n    fold_test_pred = []\n    fold_err = []\n    \n    #\"\"\" xgboost\n    start = datetime.now()\n    result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    fold_val_pred.append(result['val'])\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds\/60)) + 'm)')\n    #\"\"\"\n    \n    #\"\"\" lightgbm\n    start = datetime.now()\n    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    fold_val_pred.append(result['val'])\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds\/60)) + 'm)')\n    #\"\"\"\n    \n    #\"\"\" catboost model\n    start = datetime.now()\n    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    fold_val_pred.append(result['val'])\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds\/60)) + 'm)')\n    #\"\"\"\n    \n    # mix result of multiple models\n    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n    test_pred += np.mean(np.array(fold_test_pred), axis = 0) \/ k\n    final_err += (sum(fold_err) \/ len(fold_err)) \/ k\n    \n    print(\"---------------------------\")\n    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) \/ len(fold_err)))\n    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n    \n    print('')\n    \nprint(\"fianl avg   err.\", final_err)\nprint(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))","cc3bfe0d":"sub = pd.read_csv('..\/input\/tmdb-box-office-prediction\/sample_submission.csv')\ndf_sub = pd.DataFrame()\ndf_sub['id'] = sub['id']\ndf_sub['revenue'] = np.expm1(test_pred)\ndf_sub.to_csv(\"submission.csv\", index=False)","d3f3a527":"Release Month Vs Revenue Plot","1eab18e9":"Count Genres in Test set","589f277d":"Plot Budget vs Revenue.","0b349b67":"Plot Release Year Count","8c31ec4d":"Release day of week vs Revenue","99b736a3":"Plot Release Day of Week","162f2997":"Get Month, Day Year, Week day, quarter from release date","fb32bb04":"4389 movies released in test data, 7 are yet to release.","e5778052":"Fill  Missing Rating & Total Votes\n\n **Note**: Actually, I downloaded the data from my website's database: MoviesRE.com . Before few months, I deleted movies with less than 10 votes or 2.1 rating. So probably around 80% of the missing rows will have less than 10 votes or 2.1 rating. So let's fill them with 1.5 and 6","6a7c8dda":"**Revenue (Target Variable) Distribution**","c33e0c15":"2996 Movies released in Train and 4 Movies are yet to release. ","13848c1e":"**Thank you everyone**\n**More coming soon :)**","8f47a0c3":"# **EDA**","7d795bef":"**Let's Explore External Data**","87a4f7cd":"# Let's Get Started\n![Let's get started](https:\/\/i.giphy.com\/media\/DfSXiR60W9MVq\/giphy.webp)","b61f2fa4":"Count of missing values in each column in train:","a46fcfde":"Plot Release month count","07becfd2":"Plot Release Year vs Revenue. ","8a8c8c91":"Plot runtime vs revenue","4c92d06a":"Plot release day count","de147379":"Original Language Count","4d2d6cee":"Training with CatBoost","e0db5919":"Train set Rating Count","9b8d85ad":"Training using LightGBM","270cd4de":"This is strange, movie is yet to release and revenue is already given. ","aeb12de7":"Count Genres in Train set","57ef2ee7":"# **Feature Engineering & Prediction**\n\nI am using two external datasets.\n1. **TMDB Competition Additional Features:** This dataset contain rating & number of votes of a movie.\n2. **TMDB Competition Additional Training Data:** This dataset contain around 2,000 additional rows, which I am using for training the data. \n\nI am also manually fixing the budget & revenue of some rows below. Let me know, if any part is not clear.","87b876fc":"Submission","648a1ce8":"Plot release quater Count","04005d6a":"Count of missing values in each column in train:","96228ac0":"Missing Values","b92d47c8":"Plot popularity vs revenue","a82cc237":"\nTrain using XGBoost: ","44bf3761":"Because revenue variable is skewed, let's calculate log of it. ","dfac0aa8":"**Data Description**\n**id** - Integer unique id of each movie\n\n**belongs_to_collection** - Contains the TMDB Id, Name, Movie Poster and Backdrop URL  of a movie in JSON format. You can see the Poster and Backdrop Image like this: https:\/\/image.tmdb.org\/t\/p\/original\/<Poster_path_here>. Example: https:\/\/image.tmdb.org\/t\/p\/original\/\/iEhb00TGPucF0b4joM1ieyY026U.jpg\n\n**budget**:Budget of a movie in dollars. 0 values mean unknown. \n\n**genres** : Contains all the Genres Name & TMDB Id in JSON Format\n\n**homepage** - Contains the official homepage URL of a movie. Example: http:\/\/sonyclassics.com\/whiplash\/\t, this is the homepage of Whiplash movie.\n\n**imdb_id** - IMDB id of a movie (string). You can visit the IMDB Page like this: https:\/\/www.imdb.com\/title\/<imdb_id_here>\n\n**original_language** - Two digit code of the original language, in which the movie was made. Like: en = English, fr = french. \n\n**original_title** - The original title of a movie. Title & Original title may differ, if the original title is not in English. \n\n**overview** - Brief description of the movie.\n\n**popularity** -  Popularity of the movie in float. \n\n**poster_path** - Poster path of a movie. You can see the full image like this: https:\/\/image.tmdb.org\/t\/p\/original\/<Poster_path_here>\n\n**production_companies** - All production company name and TMDB id in JSON format of a movie.\n\n**production_countries** - Two digit code and full name of the production company in JSON format.\n\n**release_date** - Release date of a movie in mm\/dd\/yy format.\n\n**runtime** - Total runtime of a movie in minutes (Integer).\n\n**spoken_languages** - Two digit code and full name of the spoken language. \n\n**status** - Is the movie released or rumored? \n\n**tagline** - Tagline of a movie \n\n**title** - English title of a movie\n\n**Keywords** - TMDB Id and name of all the keywords in JSON format. \n\n**cast** - All cast TMDB id, name, character name, gender (1 = Female, 2 = Male) in JSON format\n\n**crew** - Name, TMDB id, profile path of various kind of crew members job like Director, Writer, Art, Sound etc. \n\n**revenue** - Total revenue earned by a movie in dollars. "}}