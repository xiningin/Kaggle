{"cell_type":{"237e97d3":"code","dae9af97":"code","cec8fa0e":"code","8c1fe34e":"code","113c884e":"code","56024a9c":"code","71a9c62d":"code","b4411244":"code","c5d745c6":"code","e8fc3f7e":"code","3720caa4":"code","0c6ad436":"code","70cc8e75":"code","8b91ac7c":"code","78e467cc":"code","b2d29b82":"code","b8a1cb6f":"code","64b97949":"code","64a68fd4":"code","2ad019ed":"code","18cf011b":"code","ee9938dd":"markdown","428bfa38":"markdown","0fb7f6d6":"markdown","6512ebae":"markdown","1d3cfcca":"markdown","bb095d32":"markdown","6adfb8f3":"markdown","a3e7a920":"markdown","2fa501ac":"markdown","720bf4d8":"markdown","c206f9ff":"markdown","6c495322":"markdown","5e1bc7a0":"markdown","b6377724":"markdown","799257ab":"markdown","54492ebd":"markdown","573c70cd":"markdown","5ea0cf48":"markdown","1790d723":"markdown"},"source":{"237e97d3":"#IMPORTING LIBRARIES\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt","dae9af97":"path='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/train'\nplt.figure(figsize=(70,70))\ncount=0\nplant_names=[]\ntotal_images=0\nfor i in os.listdir(path):\n  count+=1\n  plant_names.append(i)\n  plt.subplot(7,7,count)\n\n  images_path=os.listdir(path+\"\/\"+i)\n  print(\"Number of images of \"+i+\":\",len(images_path),\"||\",end=\" \")\n  total_images+=len(images_path)\n\n  image_show=plt.imread(path+\"\/\"+i+\"\/\"+images_path[0])\n  \n  plt.imshow(image_show)\n  plt.xlabel(i)\n  \n  plt.xticks([])\n  plt.yticks([])\n\n\nprint(\"Total number of images we have\",total_images)\n\n\n\n  ","cec8fa0e":"print(plant_names)\nprint(len(plant_names))","8c1fe34e":"import tensorflow\nfrom tensorflow import keras\nfrom keras.models import Sequential,load_model,Model\nfrom keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\nfrom keras.optimizers import SGD\nfrom keras.initializers import glorot_uniform\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n","113c884e":"\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input","56024a9c":"base_model_tf=ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),classes=38)\n","71a9c62d":"#Model building\nbase_model_tf.trainable=False\n\npt=Input(shape=(224,224,3))\nfunc=tensorflow.cast(pt,tensorflow.float32)\nx=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\nmodel_resnet=base_model_tf(x,training=False)\nmodel_resnet=GlobalAveragePooling2D()(model_resnet)\nmodel_resnet=Dense(128,activation='relu')(model_resnet)\nmodel_resnet=Dense(64,activation='relu')(model_resnet)\nmodel_resnet=Dense(38,activation='softmax')(model_resnet)\n\n\nmodel_main=Model(inputs=pt,outputs=model_resnet)\nmodel_main.summary()","b4411244":"#Image augmentation\ntrain_datagen= ImageDataGenerator(shear_range=0.2,zoom_range=0.2,horizontal_flip=False,vertical_flip=False\n                                  ,fill_mode='nearest',width_shift_range=0.2,height_shift_range=0.2)\n\nval_datagen=ImageDataGenerator()\n\npath_train='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/train'\n\npath_valid='\/kaggle\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/valid'\n\ntrain= train_datagen.flow_from_directory(directory=path_train,batch_size=32,target_size=(224,224),\n                                         color_mode='rgb',class_mode='categorical',seed=42)\n\nvalid=val_datagen.flow_from_directory(directory=path_valid,batch_size=32,target_size=(224,224),color_mode='rgb',class_mode='categorical')\n\n","c5d745c6":"#CallBacks\nes=EarlyStopping(monitor='val_accuracy',verbose=1,patience=7,mode='auto')\nmc=ModelCheckpoint(filepath='\/content',monitor='val_accuracy',verbose=1,save_best_only=True)\nlr=ReduceLROnPlateau(monitor='val_accuracy',verbose=1,patience=5,min_lr=0.001)","e8fc3f7e":"model_main.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])","3720caa4":"#Training\nmodel_main.fit(train,validation_data=valid,epochs=30,steps_per_epoch=200,verbose=1,callbacks=[mc,es,lr])","0c6ad436":"model_main.save(\"RESNET50_PLANT_DISEASE.h5\")","70cc8e75":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom PIL import Image","8b91ac7c":"plt.figure(figsize=(10,5))\nplt.plot(model_main.history.history['loss'],color='b',label='Training loss')\nplt.plot(model_main.history.history['val_loss'],color='r',label='Validation loss')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss_value\")\nplt.title(\"loss\")\n","78e467cc":"plt.figure(figsize=(10,5))\nplt.plot(model_main.history.history['accuracy'],color='b',label='Training accuracy')\nplt.plot(model_main.history.history['val_accuracy'],color='r',label='Validation accsuracy')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.title(\"accuracy graph\")\n","b2d29b82":"'''def indentity_block(X,f,stage,filters,block):\n\n    conv_base_name= 'res'+str(stage)+block+\"_branch\"\n    bn_name=\"bn\"+str(stage)+block+\"_branch\"\n  \n    F1,F2,F3=filters\n    X_shortcut=X\n\n    X=Conv2D(filters=F1, kernel_size=(1,1), padding='valid', strides=(1,1), name=conv_base_name+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2a\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F2, kernel_size=(f,f), padding='same', strides=(1,1), name=conv_base_name+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2b\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F3, kernel_size=(1,1), padding='valid', strides=(1,1), name=conv_base_name+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2c\")(X)\n    X=Add()([X,X_shortcut])\n\n    X=Activation('relu')(X)\n\n    return(X)'''\n","b8a1cb6f":"'''def convolution_block(X,f,stage,filters,block,s=2):\n    conv_base_name=\"res\"+str(stage)+block+\"_branch\"\n    bn_name=\"bn\"+str(stage)+block+\"_branch\"\n  \n    F1,F2,F3=filters\n    X_shortcut=X\n\n    X=Conv2D(filters=F1, kernel_size=(1,1), padding='valid', strides=(s,s), name=conv_base_name+\"2a\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2a\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F2, kernel_size=(f,f), padding='same', strides=(1,1), name=conv_base_name+\"2b\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2b\")(X)\n    X=Activation('relu')(X)\n\n    X=Conv2D(filters=F3, kernel_size=(1,1), padding='valid', strides=(1,1), name=conv_base_name+\"2c\",kernel_initializer=glorot_uniform(seed=0))(X)\n    X=BatchNormalization(axis=3,name=bn_name+\"2c\")(X)\n  \n    X_shortcut=Conv2D(filters=F3,kernel_size=(1,1),padding='valid',strides=(s,s),name=conv_base_name+\"1\",kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut=BatchNormalization(axis=3,name=bn_name+\"1\")(X_shortcut)\n\n    X=Add()([X,X_shortcut])\n\n    X=Activation('relu')(X)\n\n    return(X)'''\n\n","64b97949":"'''def resnet50(input_size=(224,224,3)):\n\n    X_input=Input(input_size)\n\n    X=ZeroPadding2D((3,3))(X_input)\n  \n    #STAGE 1\n    X=Conv2D(filters=64,kernel_size=(7,7),strides=(2,2),kernel_initializer=glorot_uniform(seed=0),name='conv1')(X)\n    X=BatchNormalization(axis=3,name='bn1')(X)\n    X=Activation('relu')(X)\n    X=MaxPool2D((3,3),strides=(2,2))(X)\n\n    #STAGE 2\n    X=convolution_block(X,f=3,filters=[64,64,256],block=\"a\",s=1,stage=2)\n    X=indentity_block(X,f=3,filters=[64,64,256],block='b',stage=2)\n    X=indentity_block(X,f=3,filters=[64,64,256],block='c',stage=2)\n\n    #STAGE 3\n    X=convolution_block(X,f=3,filters=[128,128,512],block=\"a\",s=2,stage=3)\n    X=indentity_block(X,f=3,filters=[128,128,512],block='b',stage=3)\n    X=indentity_block(X,f=3,filters=[128,128,512],block='c',stage=3)\n    X=indentity_block(X,f=3,filters=[128,128,512],block='d',stage=3)\n\n\n    #STAGE 4\n    X=convolution_block(X,f=3,filters=[256,256,1024],block=\"a\",s=2,stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='b',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='c',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='d',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='e',stage=4)\n    X=indentity_block(X,f=3,filters=[256,256,1024],block='f',stage=4)\n\n\n    #STAGE 5\n    X=convolution_block(X,f=3,filters=[512,512,2048],block=\"a\",s=2,stage=5)\n    X=indentity_block(X,f=3,filters=[512,512,2048],block='b',stage=5)\n    X=indentity_block(X,f=3,filters=[512,512,2048],block='c',stage=5)\n\n    X=AveragePooling2D(pool_size=(2,2),padding='same')(X)\n\n    model=Model(inputs=X_input,outputs=X,name=\"RESNET50\")\n\n    return(model)'''\n\n","64a68fd4":"\n'''base_model=resnet50(input_size=(224,224,3))\nbase_model.load_weights('\/content\/resnet50_weights_tf_dim_ordering_tf_kernels_notop(1).h5')'''","2ad019ed":"'''model1=base_model.output\nmodel1=Flatten()(model1)\nmodel1=Dense(256,activation='relu',name='Dense1')(model1)\nmodel1=Dropout(0.2)(model1)\nmodel1=Dense(128,activation='relu',name='Dense1.1')(model1)\nmodel1=Dropout(0.2)(model1)\n\nmodel1=Dense(38,activation='softmax',name='Dense3')(model1)\n\nmain_model=Model(inputs=base_model.input,outputs=model1)\nmain_model.summary()'''","18cf011b":"'''base_model.trainable=False\nfor layer in main_model.layers:\n  print(layer,layer.trainable)'''","ee9938dd":"1. **I Have used transfer learning here and also implemented Resnet50 from scratch below**\n\n2. **I hope you know below steps  , if you don't let me know I will edit this notebook again**","428bfa38":"![LEAF](http:\/\/www.mobindustry.net\/wp-content\/uploads\/1_IbJF_6mRTMsG9gL0j8uz5Q.jpeg)","0fb7f6d6":"**I will comment it out below code and you can take reference from here and can implement your own resnet architecture . Trust it will be fun :)**","6512ebae":"1. Here comes the question then why resnet? Yeah we have the answer to combat the problem of vanishing gradient problem , it has something called \"skip connections\" which solves the problem of vanishing gradient\n\n2. Before moving forward let me tell you about our over achiever boy resnet ;)\n     1. Won 1st place in the ILSVRC 2015 classification competition with a top-5 error rate of 3.57%\n     2. Won the 1st place in ILSVRC and COCO 2015 competition in ImageNet Detection,                          ImageNetlocalization, Coco detection and Coco segmentation.\n     3. Replacing VGG-16 layers in Faster R-CNN with ResNet-101. They observed relative improvements           of 28%\n     4. Efficiently trained networks with 100 layers and 1000 layers also.\n     \n","1d3cfcca":"**WHAT IS RENSET MODEL?**","bb095d32":"1. Over the last few years deep learning and machine learning are the most hottest topic in the tech industry because it has wide use in real life problems one of them is computer vision and prediction and many more and in this journey researchers( we should be very grateful to them) have created many deep learning architectures which can give us tremendous results in predicting the images \n\n2. Some of architectures which are widely known and used are Alexnet,VGG16,VGG19,Resnet and many more and due to observations and results researchers thought more we increase number of layers (I am talking about deep learning layers such as Conv2D,MaxPool2D,GlobalAveragePooling2D etc.) the model will learn more complex features from images , but but but;) they were absolutely wrong \n\n3. They got know that a 56 layer network is performing very bad than 20 layer network even on the training data , AS you can see from below image\n\n\n![Graph](http:\/\/d1m75rqqgidzqn.cloudfront.net\/wp-data\/2020\/09\/09193619\/11-696x235.png)\n\n4. As we can see 56 layer network has greater training error than 20 layer network \n\n5. What is the problem? Can we think of that , OK let me tell you this problem is called vanishing gradient problem in which weights are not updated while backward propagation , Oh you don't know abotu this let me help you with that . Visit here : https:\/\/youtu.be\/JIWXbzRXk1I (Krish Naik) , make sure you will go understand it properly","6adfb8f3":"# Last but not the least\n\n1. **Give it a upvote if you love it , your upvote may be can help me to get a job :)**\n2. **Will come up with more notebooks**\n3. **Have any doubt please comment and ask , don't get appreciate If you really like my work**\n4. **If you are beginner and won't able to understand the code , tell me I will edit this notebook or provide you resources to get better intuition**\n5. **Thanks will meet on the next :)**","a3e7a920":"**RESNET50 CODE IMPLEMENTATION**","2fa501ac":"# DATASET ","720bf4d8":"# RESNET50 IMPLEMENTATION USING KERAS API","c206f9ff":"\n*  **As farmers and agriculture field are the important part of our life , farmers are the root level building blocks in the economy of any country . They work really heard for a whole season to grow a specific crop for survival of his family**\n\n* **Sometimes these crops on which he dedicated his whole 3-6 months to nurture these crops got disease as result of which they can't sell their crops on the price he was expecting**\n\n*  **And He thinks if he knew these if he knew the plant disease before hand , he can use spefic pesticides and fertilizers to get over these disease**\n\n*  **What if we can use deep learning techniques to help famers to know about specific disease , so that they can be ready before harvestifying their crops**\n\n*  **Well I have implemented Resnet50 to detect the disease , but If we want model to be deploy inside a mobile app then mobilenet architecture will be suitable**","6c495322":"1. Resnet architecture have 2 important blocks , first is identity block and second is convolution block\n\n2. Let me first explain identity block: The identity block is the standard block used in ResNets and  corresponds to the case where the input activation has the same dimension as the output activation. You can see in below image\n\n![Identity_block](http:\/\/machinelearningknowledge.ai\/wp-content\/uploads\/2020\/12\/ResNet-Residual-Network-Keras-Implementation-Identity-Block.png)\n\n3. Convolution Block : We can use this type of block when the input and output dimensions don\u2019t match up. The difference with the identity block is that there is a CONV2D layer in the shortcut path.\n\n![Convolution_block](http:\/\/machinelearningknowledge.ai\/wp-content\/uploads\/2020\/12\/ResNet-Keras-Implementation-Convolutional-Block.png)\n\n4. For better understanding you can visit this LINK: https:\/\/machinelearningknowledge.ai\/keras-implementation-of-resnet-50-architecture-from-scratch\/\n\n5. Also visit here(this blog is legendary) : https:\/\/towardsdatascience.com\/understanding-and-visualizing-resnets-442284831be8#:~:text=ResNet%20Layers,layers%20remains%20the%20same%20%E2%80%94%204.","5e1bc7a0":"1. **Do you know why I have not run below cells to get results, actually i have tried to run it but I was not getting even 50% accuracy on training set**\n\n2. **You know why? Well I don't use preprocessing function , what is it ? This function is Preprocessed numpy.array or a tf.Tensor with type float32.**\n\n3. **The images are converted from RGB to BGR, then each color channel is zero-centered with respect to the ImageNet dataset, without scaling**\n\n4. **sometimes data is not zero-centered according to the imagenet dataset and we don't get good results , so tensoflow has provided us this preprocess input , you can see I have used it in above model**\n\n5. **Read it from here:https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/resnet\/preprocess_input**","b6377724":"**IMPORTING NECESSARY LIBRARIES FOR TRAINING OF MODEL**","799257ab":"**WHY RESNET?**","54492ebd":"**About resnet**","573c70cd":"# **MOTIVATION**","5ea0cf48":"**Well below is the implementation of Resnet50**\n\n1. **Resnet50 have 5 stages in which each stage contains both convolution block as well as identity block** \n\n![Resnet50](http:\/\/machinelearningknowledge.ai\/wp-content\/uploads\/2020\/12\/ResNet-Keras-Implementation-Architecture.png)\n\n\n\n2. **Also see from here(see 50 layer architecture) , I will suggest read blogs from above given links**\n\n![Layers](http:\/\/test.neurohive.io\/wp-content\/uploads\/2019\/01\/resnet-architectures-34-101.png)","1790d723":"1. **We have 38 classes of plant disease images which contains 70295 images in training set and 17572 in valid set**\n\n2. **Each class contains average of 1700-1800 number of images to work upon**\n\n3. **Each image is of size= (256,256,3)** \n"}}