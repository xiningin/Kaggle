{"cell_type":{"f81c9ffc":"code","e60308c6":"code","99549337":"code","f631b3d0":"code","ac8a8ef0":"code","6d8606f5":"code","4f6e0622":"code","cb89c50b":"code","0baff263":"code","51fe5ccf":"code","3b98f396":"code","7483be58":"code","864cdfe0":"code","b83df92d":"code","6ccc6afa":"code","55c1d9df":"code","e80205ac":"code","018f24e8":"code","9068f7e0":"code","df677527":"code","caed2973":"code","5ee43263":"code","81757543":"code","7091c21d":"code","7b7b0bf2":"code","c71877d6":"code","41a8683d":"code","de5aabef":"code","b64bbae4":"code","43e9570f":"code","46858118":"code","6024a0b4":"code","0bb571e5":"code","5656ef03":"code","5cf59441":"code","2500273c":"code","6ea072ef":"code","779a04c1":"code","fd3b470d":"code","71b4675a":"code","2f4f6e32":"code","cb6efeb1":"code","9abb7855":"code","74ffbda1":"code","125a6827":"code","deb2edd1":"code","4030344f":"code","3a362c15":"code","d27734d2":"code","634c17be":"code","a458c8f8":"code","0b6e334c":"code","2217637b":"code","dcc1c04e":"code","2b2f9889":"code","840d3cf3":"code","c5d546d2":"code","de457728":"code","0d2e4fe8":"code","03fcdf9e":"code","29098292":"code","3006ac7d":"code","5845af90":"code","b0530114":"code","d9a0537f":"code","2e12f043":"code","c93dfd37":"code","3e713550":"code","b70d4db7":"code","d9217a23":"code","43feaa92":"code","bc165503":"code","fff01f4c":"code","bba1094a":"code","69ea4335":"code","a1462a91":"code","2a4180b5":"code","861c82e9":"code","cd969e62":"code","0e99ce3b":"code","ce0b0d4d":"code","d1a6e673":"code","22c979ee":"markdown","5197bda1":"markdown","59b33036":"markdown","98c1a4a5":"markdown","ab4a4d44":"markdown","fe2fa656":"markdown","7ddee9d8":"markdown","992416ae":"markdown","61f20237":"markdown","6df0c74d":"markdown","9c81e9e2":"markdown","2146d4fc":"markdown","0818bba3":"markdown","dbf6a5dd":"markdown","8f4bea02":"markdown","1b16cf10":"markdown","78f47fab":"markdown","1fbb9f97":"markdown","1d87ceb6":"markdown","81d2f39b":"markdown","c3cd20a9":"markdown","6bd9e198":"markdown","70f84319":"markdown","1ab019da":"markdown","ef86d760":"markdown","31770740":"markdown","7426e3ee":"markdown","69cfe93f":"markdown","c40b0c09":"markdown","792fc1cf":"markdown"},"source":{"f81c9ffc":"#import the required libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport statsmodels.api as sm\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve\n\nimport warnings\nwarnings.filterwarnings('ignore')","e60308c6":"#Read the data file\nlead_df = pd.read_csv('\/kaggle\/input\/leads-dataset\/Leads.csv')","99549337":"# Top 5 rows\nlead_df.head()","f631b3d0":"# Check the shape the data frame\nlead_df.shape","ac8a8ef0":"# Summary of the numerical columns\nlead_df.describe()","6d8606f5":"# Null and Data type of the data\nlead_df.info()","4f6e0622":"# Null check against each columns\n#lead_df.isnull().sum()\/len(lead_df)*100\nlead_df.isnull().sum()","cb89c50b":"# Based on the whole data size, remove columns which have more than 3000 null rows (approx 32.5%)\nfor col in lead_df.columns:\n    if lead_df[col].isnull().sum()>3000:\n        print(col)\n        lead_df.drop(col, axis=1, inplace=True)","0baff263":"# Check for the columns where only one record exist\nfor col in lead_df.columns:\n    if lead_df[col].nunique() == 1:\n        print(col)","51fe5ccf":"# Based on the above results, there are several columns which have only 1 rows. We will drop these columns as it will not add any value\nlead_df.drop(['Magazine','Receive More Updates About Our Courses','Update me on Supply Chain Content','Get updates on DM Content','I agree to pay the amount through cheque'], axis=1, inplace=True)","3b98f396":"# Now check the data distribution in the columns, if there are not much variation then it will not be useful for our model\nfor col in lead_df.columns:\n    print(lead_df[col].astype('category').value_counts())\n    print('-------------------------------\\n')","7483be58":"# Based on above result, drop the columns which do not have much variation in the data. as they will not be usefull for the data.\nlead_df.drop(['Do Not Call','What matters most to you in choosing a course','Search','Newspaper Article','X Education Forums','Newspaper','Digital Advertisement','Through Recommendations'],\naxis=1, inplace=True)","864cdfe0":"col = ['Specialization','How did you hear about X Education','Lead Profile','City']\n\nfor i in col:\n    print(lead_df[i].value_counts(normalize=True))\n    print('------------------')","b83df92d":"# 'How did you hear about X Education' &  'Lead Profile' have 'Select' value as 71%, 63% respectively. we will drop them as well\nlead_df.drop(['How did you hear about X Education','Lead Profile'], axis=1, inplace=True)","6ccc6afa":"# Other than that 'Prospect ID' and 'Lead Number' are the unique value column, we will drop them as well along with 'Country' & 'City'\nlead_df.drop(['Prospect ID','Lead Number','Country','City'], axis=1, inplace=True)","55c1d9df":"# Now check the number of null values in the data frame\nlead_df.isnull().sum()","e80205ac":"# Checking null values in 'What is your current occupation'\nlead_df['What is your current occupation'].value_counts(dropna=False, normalize=True)","018f24e8":"# Checking null values in 'Specialization'\nlead_df['Specialization'].value_counts(dropna=False, normalize=True)","9068f7e0":"# As data is already skewed, we will Drop all the rows with null values as imputing them might skewed it further\nlead_df.dropna(axis=0, inplace=True)","df677527":"# As data is clean now, check the shape. we have lost 31% of total data due to the clean up\nlead_df.shape","caed2973":"# Extract numerical and categorical columns for EDA\nnumerical_columns = lead_df.select_dtypes(include=['int64','float64']).columns\ncategorical_columns = lead_df.select_dtypes(exclude=['int64','float64']).columns","5ee43263":"# Box plot for numerical variables\nplt.figure(figsize=(15,10))\nplt.style.use('ggplot')\n\nfor i in range(len(numerical_columns)):\n    plt.subplot(2,2,i+1)\n    sns.boxplot(lead_df[numerical_columns[i]], orient='h')\n\nplt.show()","81757543":"# As there seems to be some outliers in ('TotalVisits','Page Views Per Visit') columns, We will handle outliers through 1.5*iqr method\n\nb_rows = lead_df.shape[0]\n\nfor i in ['TotalVisits','Page Views Per Visit'] :\n    q75,q25 = np.percentile(lead_df.loc[:,i],[75,25])\n    iqr = q75-q25\n    \n    min = q25 - (iqr*1.5)\n    max = q75 + (iqr*1.5)\n    \n    lead_df = lead_df.drop(lead_df[lead_df.loc[:,i] < min].index)\n    lead_df = lead_df.drop(lead_df[lead_df.loc[:,i] > max].index)\na_rows = lead_df.shape[0]","7091c21d":"# # Bar plot for Numerical variables\nfig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,5))\nsns.barplot(x='Converted', y='TotalVisits', data=lead_df, ci=0, ax=ax1)\nsns.barplot(x='Converted', y='Total Time Spent on Website', data=lead_df, ci=0, ax=ax2)\nsns.barplot(x='Converted', y='Page Views Per Visit', data=lead_df, ci=0, ax=ax3)\nplt.show()","7b7b0bf2":"# plot for categorical variables\nplt.figure(figsize=(20,15))\nplt.style.use('ggplot')\n\nfor i in range(len(categorical_columns)):\n    plt.subplot(2,4,i+1)\n    sns.countplot(x=categorical_columns[i], data=lead_df, hue='Converted')\n    plt.xticks( rotation=40, ha=\"right\")\n\nplt.show()\n","c71877d6":"# we will create Dummy variables for all the categorical columns\ndummy_df = pd.get_dummies(lead_df[categorical_columns], drop_first=True)","41a8683d":"# Check the Dummy Data Frame\ndummy_df","de5aabef":"# Remove categorical columns from the original data frame as we already have created dummy columns for them.\nlead_df.drop(categorical_columns, axis=1, inplace=True)","b64bbae4":"# Merge Dummy dataframe to the original dataframe\nlead_df = pd.concat([lead_df, dummy_df], axis=1)","43e9570f":"# Removing the Specialization_Select column as it is a invalid class\nlead_df.drop('Specialization_Select', axis=1, inplace=True)","46858118":"correlation =  lead_df.corr()\nmask = np.array(correlation)\nmask[np.tril_indices_from(mask)] = False\n\nplt.figure(figsize=(15,15))\nsns.heatmap(correlation, mask=mask, cmap=\"RdYlGn\", annot=False)\nplt.show()","6024a0b4":"np.random.seed(0)\nlead_train, lead_test = train_test_split(lead_df, train_size=0.7, random_state=100)","0bb571e5":"# Scalling the numerical variables using the min max scaler\nnumerical_columns = ['Converted','TotalVisits', 'Total Time Spent on Website','Page Views Per Visit']\n\nmm = MinMaxScaler()\nlead_train[numerical_columns] = mm.fit_transform(lead_train[numerical_columns])\nlead_test[numerical_columns] = mm.transform(lead_test[numerical_columns])","5656ef03":"# Verify the train dataframe\nlead_train.shape","5cf59441":"# Prepartion of X an y variables from training dataframe\ny_train = lead_train.pop('Converted')\nX_train = lead_train","2500273c":"#Functions to build model and verify VIF\n\ndef build_model(X,y):\n    lr = LogisticRegression()\n    X = sm.add_constant(X) #Adding the constant\n    lr = sm.GLM(y, X, family = sm.families.Binomial()) \n    res = lr.fit() # fitting the model\n    print(res.summary()) # model summary\n    return res\n    \ndef checkVIF(X):\n    vif = pd.DataFrame() # New dataframe\n    vif['Features'] = X.columns # Added all columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])] # Calcuate VIF against each columns\n    vif['VIF'] = round(vif['VIF'], 2) \n    vif = vif.sort_values(by = \"VIF\", ascending = False) # Sorting based on VIF\n    return vif","6ea072ef":"# Function to get the list of RFE supported columns\n\ndef getRFECol (X, y, num):\n    logreg = LogisticRegression(solver='liblinear')\n    rfe = RFE(logreg, num) # configure required numbers of columns\n    rfe = rfe.fit(X, y) # fitting the model\n    col = X.columns[rfe.support_] # Columns based on RFE reccomendation\n    return col","779a04c1":"# Take help of RFE to identify 20 top variables for our model building\nRFE_cols = getRFECol(X_train, y_train, 20)\nRFE_cols","fd3b470d":"# BUILDING MODEL #1\n# Based on the RFE reccomended variables, lets fit the model on them and verify the model\n\nX_train_sm = sm.add_constant(X_train[RFE_cols])\nlr1 = build_model(X_train_sm, y_train)\ncheckVIF(X_train_sm)","71b4675a":"# We will reduce the number for variable in RFE and try our model with 17 top significant varibales\nRFE_cols = getRFECol(X_train, y_train, 17)\nRFE_cols","2f4f6e32":"#BUILDING MODEL #2\n# Based on the RFE reccomended variables, lets fit the model on them and verify the model\n\nX_train_sm = sm.add_constant(X_train[RFE_cols])\nlr2 = build_model(X_train_sm, y_train)\ncheckVIF(X_train_sm)","cb6efeb1":"# We will reduce the number for variable in RFE and try our model with 15 top significant varibales\nRFE_cols = getRFECol(X_train, y_train, 15)\nRFE_cols","9abb7855":"#BUILDING MODEL #3\n# Based on the RFE reccomended variables, lets fit the model on them and verify the model\nX_train_sm = sm.add_constant(X_train[RFE_cols])\nlr3 = build_model(X_train_sm, y_train)\ncheckVIF(X_train_sm)","74ffbda1":"# Drop the insignificant variable\nX_train_sm.drop('What is your current occupation_Housewife', axis=1, inplace=True)","125a6827":"#BUILDING MODEL #4\n\nlr4 = build_model(X_train_sm, y_train)\ncheckVIF(X_train_sm)","deb2edd1":"# Predict on the train data\ny_train_pred = lr4.predict(sm.add_constant(X_train_sm))\ny_train_pred","4030344f":"# Prepare actual vs predicated dataframe\ny_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred = pd.DataFrame({'Actual': y_train.values, 'Probability': y_train_pred})\ny_train_pred","3a362c15":"# Calculate Lead Score\ny_train_pred['Lead_Score'] = y_train_pred.Probability.map( lambda x: round(x*100))","d27734d2":"# Predict the value based on an arbitrary cut off probability(0.5)\ny_train_pred['Predicted'] = y_train_pred.Probability.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred","634c17be":"# Confusion Metrix\nconfusion = metrics.confusion_matrix(y_train_pred.Actual, y_train_pred.Predicted)\nconfusion","a458c8f8":"# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nTP = confusion[1,1]\nTN = confusion[0,0]\nFP = confusion[0,1]\nFN = confusion[1,0]","0b6e334c":"# Accuracy - Measures of Accuracy\n# Describes overall, how often the classifier correct.\n(TP+TN)\/(TP+TN+FP+FN)","2217637b":"# Sensitivity\/Recall - When it\u2019s actually yes, how often does it predict yes?\nTP\/(TP+FN)","dcc1c04e":"# Specificity - When it\u2019s actually no, how often does it predict no?\nTN\/(TN+FP)","2b2f9889":"# Precision - When it predicts yes, how often is it correct?\nTP\/(TP+FP)","840d3cf3":"def draw_roc(actual, probs):\n    fpr, tpr, thresholds = metrics.roc_curve(actual, probs, drop_intermediate = False)\n    auc_score = metrics.roc_auc_score(actual, probs)\n    plt.figure(figsize=(5,5))\n    plt.plot(fpr, tpr, label='ROC curve (area =  %0.2f)' % auc_score)\n    plt.plot([0,1], [0,1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc='lower right')\n    plt.show()","c5d546d2":"draw_roc(y_train_pred.Actual, y_train_pred.Probability)","de457728":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred[i]= y_train_pred.Probability.map(lambda x: 1 if x > i else 0)\ny_train_pred.head()","0d2e4fe8":"# Creating a dataframe to see the values of accuracy, sensitivity, and specificity at different values of probabiity cutoffs\ncutoff_df = pd.DataFrame(columns=['Probability', 'Accuracy', 'Sensivity', 'Specificity'])\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred.Actual, y_train_pred[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","03fcdf9e":"# Let's plot accuracy sensitivity and specificity for various probabilities.\nplt.style.use('ggplot')\ncutoff_df.plot.line(x='Probability', y=['Accuracy','Sensivity','Specificity'])\nplt.show()","29098292":"#y_train_pred.Actual, y_train_pred.Final_Predicted\np, r, thresholds = precision_recall_curve(y_train_pred.Actual, y_train_pred.Probability)","3006ac7d":"plt.style.use('ggplot')\nplt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.legend(['Precision','Recall'])\nplt.title('Precision-Recall Trade-off')\nplt.show()","5845af90":"# Lets derive the new prediction based on the new cut-off\ny_train_pred['Final_Predicted'] = y_train_pred.Probability.map( lambda x: 1 if x > 0.41 else 0)\ny_train_pred.head()","b0530114":"# Confusion Metrix based on the new predictions\nconfusion2 = metrics.confusion_matrix(y_train_pred.Actual, y_train_pred.Final_Predicted )\nconfusion2","d9a0537f":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","2e12f043":"# Accuracy - Measures of Accuracy\n# Describes overall, how often the classifier correct.\n(TP+TN)\/(TP+TN+FP+FN)","c93dfd37":"# Sensitivity\/Recall - When it\u2019s actually yes, how often does it predict yes?\nTP\/(TP+FN)","3e713550":"# Specificity - When it\u2019s actually no, how often does it predict no?\nTN\/(TN+FP)","b70d4db7":"# Precision - When it predicts yes, how often is it correct?\nTP\/(TP+FP)","d9217a23":"# Verify the test dataframe\nlead_test.shape","43feaa92":"# Prepartion of X an y variables from test dataframe\ny_test = lead_test.pop('Converted')\nX_test = lead_test","bc165503":"# Use only columns from the final model\nX_test_sm = sm.add_constant(X_test)\nX_test_sm = X_test_sm[X_train_sm.columns]","fff01f4c":"# Predict on test data\ny_test_pred = lr4.predict(X_test_sm)","bba1094a":"# Prepare actual vs predicated dataframe\ny_test_pred = pd.DataFrame({'Actual': y_test.values, 'Probability':y_test_pred})\ny_test_pred","69ea4335":"# Calculate Lead Score\ny_test_pred['Lead_Score'] = y_test_pred.Probability.map( lambda x: round(x*100))\ny_test_pred","a1462a91":"# Predict based on cut-off probability\ny_test_pred['Predicted'] = y_test_pred.Probability.map(lambda x: 1 if x > 0.41 else 0)\ny_test_pred","2a4180b5":"# Confusion Matrix for test data\nconfusion3 = metrics.confusion_matrix(y_test_pred.Actual, y_test_pred.Predicted )\nconfusion3","861c82e9":"TP = confusion3[1,1] # true positive \nTN = confusion3[0,0] # true negatives\nFP = confusion3[0,1] # false positives\nFN = confusion3[1,0] # false negatives","cd969e62":"# Accuracy - Measures of Accuracy\n# Describes overall, how often the classifier correct.\n(TP+TN)\/(TP+TN+FP+FN)","0e99ce3b":"# Sensitivity\/Recall - When it\u2019s actually yes, how often does it predict yes?\nTP\/(TP+FN)","ce0b0d4d":"# Specificity - When it\u2019s actually no, how often does it predict no?\nTN\/(TN+FP)","d1a6e673":"# Precision - When it predicts yes, how often is it correct?\nTP\/(TP+FP)","22c979ee":"# Business Goal\nX Education needs help in selecting the most promising leads, i.e. the leads that are most likely to convert into paying customers. The company needs a model wherein you a lead score is assigned to each of the leads such that the customers with higher lead score have a higher conversion chance and the customers with lower lead score have a lower conversion chance. The CEO, in particular, has given a ballpark of the target lead conversion rate to be around 80%.","5197bda1":"### Train - Test split","59b33036":"Based on the overall number of columns, we have decided to start with 20 columns to build our model. We will change our assumption based on the observation in further iterations.","98c1a4a5":"ROC curve\n\nA ROC(Receiver Operator Characteristic Curve) can help in deciding the best threshold value. It is generated by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis) as you vary the threshold for assigning observations to a given class.ROC curve will always end at (1,1). The threshold at this point will be 0. This means that we will always classify these observations falling into the class 1(Specificity will be 0. False positive rate is 1).\n\nOne should select the best threshold for the trade off you want to make. According to the criticality of the business, we need to compare the cost of failing to detect positives vs cost of raising false alarms.","ab4a4d44":"Now the p-values and VIF improved significantly, only variable 'What is your current occupation_Housewife' seems to be insignificant. we will drop and fit our model again. ","fe2fa656":"### Precision and recall tradeoff","7ddee9d8":"## Model Evaluation","992416ae":"at probibility 0.4, Accuracy, Sensivity, Specificity seems to be very close to be each other. Lets plot it to validate the same.","61f20237":"#### Below columns, data is too skewed. which would not be useful for our analysis\n- Do Not Call\n- What matters most to you in choosing a course\n- Search\n- Newspaper Article\n- X Education Forums\n- Newspaper\n- Digital Advertisement\n- Through Recommendations'","6df0c74d":"There are still a few variables which have high p-value greater and high VIF. we reduce the number of variable further to 15 and try another iteration. ","9c81e9e2":"Now all the variables seems to be in order now. we dont have any variable with high p-value and none of the variable have VIF greater than 5. we will proceed with this model and derive the Probabilities, Lead Score, Predictions also evaluate it with different methods. ","2146d4fc":"### Observations on Train data:\n\nSo as we can see above the model seems to be performing well. The ROC curve has a value of 0.87, which is very good. We have the following values for the Train Data:\n\n- Accuracy : 78.88% \n- Sensitivity : 79.87% \n- Specificity : 77.98% \n- Precision : 76.81% ","0818bba3":"## Exploratory Data Analysis","dbf6a5dd":"# Problem Statement\nX Education sells online courses to industry professionals. The company markets its courses on several websites and search engines like Google. Once these people land on the website, they might browse the courses or fill up a form for the course or watch some videos. When these people fill up a form providing their email address or phone number, they are classified to be a lead. Moreover, the company also gets leads through past referrals.\nOnce these leads are acquired, employees from the sales team start making calls, writing emails, etc. Through this process, some of the leads get converted while most do not. The typical lead conversion rate at X education is around 30%.","8f4bea02":"### Optimise Cut off - ROC (Receiver Operator Characteristic Curve)","1b16cf10":"### Data scalling","78f47fab":"**Inference**\n- Lead Add Form seem to have most conversion rate in Lead Origin\n- Reference and Wangingak website seem to have an influence on lead conversion\n- Do not Email seem to have a negative influence on lead conversion\n- Sms sent in last activity has maximum lead conversion rate\n- Marketing Management seem to have a positive influence on lead conversion \n- Working professional have the highest lead conversion rate\n- SMS sent in last Notable Activity has the highest conversion rate.\n- A free copy of Mastering the Interview do not seem to have a positive influence over conversion rate","1fbb9f97":"## Data cleaning and preparation","1d87ceb6":"As there are several variables which have p-value greater than 0.05 which means that they not significant for our model also VIF value is too high for few variable. Higher VIF means that there are multi collinearity between the variables. ","81d2f39b":"## Dummy variables creation","c3cd20a9":"### Observations on Test data:\n\nAfter running the model on the Test Data these are the figures we obtain:\n\n- Accuracy : 78.88% \n- Sensitivity : 78.78% \n- Specificity : 78.98% \n- Precision : 77.97% ","6bd9e198":"## Prediction on the Test data","70f84319":"## Build Model","1ab019da":"With above graph optimal cut-off seems to be at probability 0.41, lets validate it with precision-recall trade-off as well","ef86d760":"Above graph is also validating our assumption of optimul cut-off (4.1)","31770740":"The previous cut off was randomely selected (0.5). Now we will find the optimum one for our model","7426e3ee":"**Inference**\n- There seems to be several high correlated variables exist in the dataframe however we are not doing anything as of now\n- We will eliminate them if they appear during the model fitting","69cfe93f":"## Final Observation:\n\nLet us compare the values obtained for Train & Test:\n\n**Train Data:**\n\n- Accuracy : 78.88% \n- Sensitivity : 79.87% \n- Specificity : 77.98% \n- Precision : 76.81% \n\n**Test Data:**\n\n- Accuracy : 78.88% \n- Sensitivity : 78.78% \n- Specificity : 78.98% \n- Precision : 77.97% \n\n**Conclusion :**\n\n- While we have checked both Sensitivity-Specificity as well as Precision and Recall Metrics, we have considered the optimal cut off based on Sensitivity and Specificity for calculating the final prediction.\n- Accuracy, Sensitivity and Specificity values of test set are around 79%, 79% and 79% which are approximately closer to the respective values calculated using trained set.\n- Also the lead score calculated in the trained set of data shows the conversion rate on the final predicted model is around 80%\n- Hence overall this model seems to be good.","c40b0c09":"**Inference**\n- Total time spent on website has highest conversion rate\n- Total visits also have some influence over leads gets converted\n- Page view per visit does not seem to have much influence over conversion\n","792fc1cf":"## Data inspection"}}