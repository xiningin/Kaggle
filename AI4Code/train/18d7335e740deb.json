{"cell_type":{"dd0f378f":"code","4d17e98d":"code","1c6d17f6":"code","36b9ff9c":"code","703d7404":"code","a3ac67b2":"code","a176db05":"code","9a15c8e8":"code","6616332c":"code","50db2698":"code","e906d1f1":"code","3bb25c0d":"markdown","d68a0b33":"markdown","a42578be":"markdown","07ed5f6f":"markdown","02f46d28":"markdown"},"source":{"dd0f378f":"import numpy as np\nimport pandas as pd\nimport string\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4d17e98d":"train_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","1c6d17f6":"# Removing punctuation and numbers from the data\n\nprint(train_data.head()['text'])\nchars_to_remove = list(string.punctuation) + list((str(x) for x in range(10)))\n\ndef remove_punct_cap(string):\n    output = ''\n    for char in string:\n        if char not in chars_to_remove:\n            output += char.lower()\n    return output\n\ntrain_data['text'] = train_data['text'].apply(remove_punct_cap)\n\nprint('\\n After preprocessing: \\n')\nprint(train_data.head()['text'])","36b9ff9c":"train_data_arr = train_data.values\ntrain_X = train_data_arr[:,:4]\ntrain_X = np.nan_to_num(train_X)\ntrain_y = train_data_arr[:,4:]\n\ntest_data_arr = test_data.values\ntest_X = np.nan_to_num(test_data_arr)","703d7404":"from keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef encode(data):\n    data = [one_hot(data[i, 3], 1000) for i in range(len(data))]\n    data = pad_sequences(data, maxlen = 33, padding = 'post')\n    return data\n\ntrain_X_encoded = encode(train_X)\nprint(train_X_encoded.shape)\n\ntest_X_encoded = encode(test_X)\nprint(test_X_encoded.shape)","a3ac67b2":"from keras.models import Sequential\nfrom keras import layers\nfrom keras.layers.embeddings import Embedding\n\ndef build_model():\n    model = Sequential()\n    model.add(layers.Embedding(20000, 16, input_length=33))\n    model.add(layers.LSTM(12, dropout=0.2, recurrent_dropout=0.2))\n    model.add(layers.Dense(1, activation='sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n    return model\n   \nmodel = build_model()\nmodel.summary()","a176db05":"history = model.fit(train_X_encoded, train_y, epochs=20, batch_size=128, validation_split=0.2, verbose=0)","9a15c8e8":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nepochs = [i+1 for i in range(len(acc))]","6616332c":"plt.plot(epochs, acc, 'o', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","50db2698":"# Determining how many epochs to use\nprint(val_acc)\ntriple_average = [sum([val_acc[j] for j in [i, i+1, i+2]])\/3 for i in range(len(acc)-3)]\nprint(triple_average)\nepochs = [i+2 for i in range(len(acc)-3) if triple_average[i] == max(triple_average)]\nprint(epochs)\n\n# Building and fitting the model\n\nmodel = build_model()\nhistory = model.fit(train_X_encoded, train_y, epochs=epochs[0], batch_size=128, verbose=0)","e906d1f1":"predictions = model.predict(test_X_encoded)\npredictions = predictions.reshape(len(predictions))\npredictions = [int(x) for x in np.rint(predictions)]\noutput = pd.DataFrame({'id': test_data.id, 'target': predictions})\noutput.to_csv('submission.csv', index=False)\nprint('Complete')","3bb25c0d":"# Converting data into Numpy arrays","d68a0b33":"# Importing data","a42578be":"# Preprocessing the text data","07ed5f6f":"# Building and training the final model","02f46d28":"# Building and training a model "}}