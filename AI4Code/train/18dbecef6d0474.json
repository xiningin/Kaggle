{"cell_type":{"580473e0":"code","bd976da9":"code","5b54ef86":"code","4138f3a6":"code","752a4373":"code","d477f623":"code","c141386d":"code","1c02e035":"code","d8ca87d8":"code","d20d90c3":"code","13c304c2":"code","ad80b297":"code","f14c689e":"code","0622f466":"code","9118cf9c":"code","249920a9":"code","094af98d":"code","ce655f20":"code","88e3fcbc":"code","05c774c2":"code","ee45e55d":"code","8e322b34":"code","37a482a3":"code","671446fc":"code","b4a5ebdb":"code","970d7acc":"code","335c20b6":"code","5b05730f":"code","242a88f8":"code","95054fe3":"code","869d87cf":"code","2fe958e8":"code","001ce8f1":"code","9d671d0e":"code","3ba23b62":"code","945a512d":"code","3860d98f":"code","d3f136ed":"code","2e6f40e4":"code","2d16cac9":"markdown","3afe1bc7":"markdown","dced9fca":"markdown","9afa3a30":"markdown","e1304a6e":"markdown","c8405a85":"markdown","43a56f08":"markdown","716af648":"markdown","6493ca07":"markdown"},"source":{"580473e0":"# Octopus ML pakage - github.com\/gershonc\/octopus-ml\n!pip install octopus-ml ","bd976da9":"import warnings\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport time\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport tracemalloc\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nimport lightgbm as lgb\nfrom tqdm import tqdm\n#check out https:\/\/github.com\/gershonc\/octopus-ml\nimport octopus_ml as oc\n\npd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000\npd.set_option('display.max_colwidth', -1)  # or 199\n%matplotlib inline\nwarnings.simplefilter(\"ignore\")\n","5b54ef86":"train_df = pd.read_csv ( \"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","4138f3a6":"train_df.head(4)","752a4373":"# Data shape \nprint (\"Train set: \",train_df.shape)\nprint (\"Test set: \",test_df.shape)","d477f623":"# DataFrane Summary by pandas summary package (extension of pandas.describe method) \ndfs = DataFrameSummary(train_df)\ndfs.summary()","c141386d":"# Top 20 features with missing data\n\nsns.set_style(\"whitegrid\")\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(15,4))\ndf=pd.Series(1 - train_df.count() \/ len(train_df)).sort_values(ascending=False).head(20)\nsns.barplot(x=df.index, y=df,palette=\"Blues_d\")\nplt.xticks(rotation=90)\n","1c02e035":"train_df['YrSold'].value_counts()","d8ca87d8":"grp_year=train_df.groupby('YrSold')\nplt.figure(figsize=(5,3))\n\ndf_years=grp_year['SalePrice'].mean().reset_index()\nsns.barplot(x=df_years.YrSold, y=df_years['SalePrice'],palette=\"Blues_d\")\nplt.xticks(rotation=0)","d20d90c3":"from scipy.stats import norm, skew \nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(12,4))\n\nsns.distplot(train_df['SalePrice'] , fit=norm);\n(mu, sigma) = norm.fit(train_df['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='upper right')\n\nax = plt.axes()\nplt.ylabel('Frequency')\nplt.title('SalePrice distribution')","13c304c2":"# Categorical features\n\ncategorical_features=[]\nfor c in train_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        train_df[c] = train_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)","ad80b297":"import seaborn as sns\nimport scipy.stats as stats\nsns.set_style(\"whitegrid\")\n\n\nj = sns.jointplot(x=train_df['OverallQual'],y=train_df['SalePrice'],data=train_df, kind='reg', height=6)\n#j.annotate(stats.pearsonr)\nplt.show()\nprint (\"Pearson | P-value: \"+str(stats.pearsonr(train_df['OverallQual'], y=train_df['SalePrice'])))","f14c689e":"sns.set_style(\"whitegrid\")\nj = sns.jointplot(x=train_df['TotalBsmtSF'],y=train_df['SalePrice'],data=train_df, kind='reg', height=6)\n#j.annotate(stats.pearsonr)\nplt.show()\nprint (\"Pearson | P-value: \"+str(stats.pearsonr(train_df['TotalBsmtSF'], y=train_df['SalePrice'])))","0622f466":"sns.set_style(\"whitegrid\")\nj = sns.jointplot(x=train_df['GrLivArea'],y=train_df['SalePrice'],data=train_df, kind='reg', height=6)\n#j.annotate(stats.pearsonr)\nplt.show()\nprint (\"Pearson: \"+str(round(stats.pearsonr(train_df['GrLivArea'], y=train_df['SalePrice'])[0],4))+\"| P-value: \"+ str(stats.pearsonr(train_df['GrLivArea'], y=train_df['SalePrice'])[1]))","9118cf9c":"train_df['SalePrice'] = np.log1p(train_df[\"SalePrice\"])\ny = train_df['SalePrice']\ntest_id = test_df['Id']\ndata = pd.concat([train_df, test_df], axis=0, sort=False)\ndata = data.drop(['Id', 'SalePrice'], axis=1)","249920a9":"numerical_feat = ['BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFinSF1', 'GarageArea']\ncategorical_feat = ['MSZoning', 'Utilities', 'Functional', 'KitchenQual', 'Exterior2nd', 'Electrical', 'Exterior1st', 'SaleType']","094af98d":"for cat_feat in categorical_feat:\n    data[cat_feat] = data[cat_feat].fillna(str(data[cat_feat][:len(train_df)].value_counts().index[0]))","ce655f20":"for num_feet in numerical_feat:\n    data[num_feet] = data[num_feet].fillna(data[num_feet][:len(train_df)].mean())","88e3fcbc":"data['TotalSF'] = data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\ndata['SumOverAll'] = data['OverallQual'] + data['OverallCond']","05c774c2":"numeric_feats = data.dtypes[data.dtypes != 'object'].index\nskewed_feats = data[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skew = skewed_feats[abs(skewed_feats) > 0.5]\nhigh_skew","ee45e55d":"for feat in high_skew.index:\n    data[feat] = np.log1p(data[feat])","8e322b34":"train = data[:len(train_df)]\ntest = data[len(train_df):]","37a482a3":"features=train.columns.to_list()\nprint ('Number of features ', len(features))","671446fc":"\"\"\"from sklearn.impute import SimpleImputer\nnumerical_cols= train_df.select_dtypes(exclude='object')\nnumerical_cols\nimp_mean=SimpleImputer(strategy='median')\nimp_mean.fit(numerical_cols)\nimp_mean.transform(numerical_cols)\"\"\"","b4a5ebdb":"# Categorical features\n\ncategorical_features=[]\nfor c in train.columns:\n    col_type = train[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        train[c] = train[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)\nX=train","970d7acc":"params = {\n'boosting_type': 'gbdt',\n'objective': 'regression',\n'metric': 'rmse',\n#\"num_leaves\":9,\n#\"learning_rate\":0.05, \n#\"n_estimators\":100,\n#\"max_bin\":55, \n#\"bagging_fraction\":0.8,\n#\"bagging_freq\":5, \n#\"feature_fraction\":0.2319,\n#\"feature_fraction_seed\":9, \n#\"bagging_seed\":9,\n#\"min_data_in_leaf\":6, \n#\"min_sum_hessian_in_leaf\":11, \n#\"n_jobs\":-1\n}\n\nmetrics= oc.cv_adv(X,y,0.5,100,shuffle=True,params=params, mode=\"regression\") ","335c20b6":"preds_real = list(zip(np.expm1(metrics['predictions_proba'][0:1000]),np.expm1(metrics['y'][0:1000])))\ndf = pd.DataFrame(preds_real, columns=['Preds','Real'])\ndf.head(10)","5b05730f":"df.boxplot(column=['Preds', 'Real'])","242a88f8":"dfs = DataFrameSummary(df)\ndfs.summary()","95054fe3":"from sklearn import metrics as metric\n#print('Mean Squared Error:', metric.mean_squared_error(np.expm1(metrics['y']), np.expm1(metrics['predictions_proba'])))\nprint('Root Mean Squared Error:', np.sqrt(metric.mean_squared_error(np.expm1(metrics['y']), np.expm1(metrics['predictions_proba']))))","869d87cf":"# Categorical features\ntest_df=test\ncategorical_features=[]\nfor c in test_df.columns:\n    col_type = test_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        test_df[c] = test_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)\n\nresult = pd.DataFrame(test_id, columns = ['Id'])\ntest_pre = np.expm1(metrics['final_clf'].predict(test_df))\nresult['SalePrice'] = test_pre\n\nresult.to_csv(\"lgb_result_updated.csv\", index = False, header = True)\n#result.to_csv(\"lgb_result2.csv\")","2fe958e8":"result.head(10)","001ce8f1":"for i, s_clf in enumerate(metrics['stacked_models']):\n    test_pre = np.expm1(s_clf.predict(test_df))\n    result['clf_'+str(i)]=test_pre","9d671d0e":"result.head(5)","3ba23b62":"col = result.loc[: , \"clf_0\":\"clf_4\"]\nresult['sale_mean'] = col.mean(axis=1)","945a512d":"result.head(8)","3860d98f":"submit = pd.DataFrame(result['Id'], columns = ['Id'])\nsubmit['SalePrice']=result['sale_mean']\nsubmit.to_csv('stacked_submission.csv',index = False)\nsubmit.head(4)","d3f136ed":"feature_imp_list=oc.plot_imp(metrics['final_clf'],X,'LightGBM House prices Kaggle',num=30)","2e6f40e4":"top_features=feature_imp_list.sort_values(by='Value', ascending=False).head(20)\ntop_features","2d16cac9":"## Please upvote if you find this notebook interesting and useful","3afe1bc7":"## EDA","dced9fca":"## Octopus ML - regression model adjusments","9afa3a30":"## Stacked CV 5-folds models ","e1304a6e":"### Correlations to target (Sale price)","c8405a85":"## Data pre-processing\n","43a56f08":"### Feature importance ","716af648":"## Model Explainability","6493ca07":"## Models performance evaluation - preds vs real "}}