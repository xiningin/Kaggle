{"cell_type":{"7fa81dd0":"code","faf848fd":"code","1c25c43c":"code","3acb9b15":"code","cd090ed2":"code","e696a373":"code","e7519393":"code","dc0079af":"code","0344e918":"code","eff22e46":"code","8f063972":"code","c5ec703e":"code","c426427b":"code","85a0a675":"code","7fd8d947":"code","0dc562fe":"code","f90d1b6f":"code","373cf81e":"code","760f7c50":"code","3725ff35":"code","6d723973":"code","2ff0c991":"code","193d543d":"code","5f6a7d3a":"code","56eb4e41":"code","af9a39b7":"code","2683afbb":"code","3f3e577d":"code","318bb049":"code","cb83146e":"code","24d3b9f4":"code","651fbfd0":"code","0f7f5224":"code","0ceb4c05":"code","67d545d3":"code","91f47ef5":"code","1a801a5b":"code","bc356ed5":"code","4a6eaee1":"code","efb501d2":"code","3323a6f1":"code","f9d7411c":"markdown","18cb7e52":"markdown","14af0edc":"markdown","88771873":"markdown","51edb384":"markdown","8d92c93e":"markdown","6539aa6c":"markdown","59273668":"markdown","9c71af0e":"markdown","a3e8c8c6":"markdown","70e4ba98":"markdown","c8d28b70":"markdown","3d545793":"markdown","cc5d2136":"markdown","0cd4edd3":"markdown","e99a3ff2":"markdown"},"source":{"7fa81dd0":"#Import Packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport regex as re\nfrom plotly import tools\n\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\n","faf848fd":"#Import and take a look at the Data\ntrain=pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntrain.head()\n\n","1c25c43c":"train.describe()","3acb9b15":"#Draw up some visuals of survival correlations\nfig, axs = plt.subplots(ncols=3, nrows=2, figsize=(15,10))\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train, ax=axs[0,0])\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train, ax=axs[0,1])\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train, ax=axs[0,2])\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train, ax=axs[1,0])\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train, ax=axs[1,1])\nsns.countplot(x=\"Survived\", data=train, ax=axs[1,2])","cd090ed2":"#Lets check missing values\nprint(pd.isnull(train).sum())\nprint('Percent of missing \"Cabin\" records is %.2f%%' %((train['Cabin'].isnull().sum()\/train.shape[0])*100))\nprint('Percent of missing \"Age\" records is %.2f%%' %((train['Age'].isnull().sum()\/train.shape[0])*100))\nprint('Percent of missing \"Embarked\" records is %.2f%%' %((train['Embarked'].isnull().sum()\/train.shape[0])*100))","e696a373":"#Lets check missing values\nprint(pd.isnull(test).sum())\nprint('Percent of missing \"Cabin\" records is %.2f%%' %((test['Cabin'].isnull().sum()\/test.shape[0])*100))\nprint('Percent of missing \"Age\" records is %.2f%%' %((test['Age'].isnull().sum()\/test.shape[0])*100))\nprint('Percent of missing \"Embarked\" records is %.2f%%' %((test['Embarked'].isnull().sum()\/test.shape[0])*100))","e7519393":"for dataframe in [train, test]:\n    dataframe.set_index('PassengerId', inplace=True)\n    \ntrain.head()","dc0079af":"\n#Extracting first letter to determine cbin grade \ntrain['Cabin'] = train['Cabin'].apply(lambda x: \"other\" if pd.isna(x) else x[0])","0344e918":"\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n\nsns.countplot(data=train.loc[train['Cabin'] == 'other'], hue ='Cabin', x='Pclass', ax=ax[0,0]).set_title('Unknown Cabin')\nsns.countplot(data=train.loc[train['Cabin'] != 'other'], hue ='Cabin', x='Pclass', ax=ax[0,1]).set_title('Cabin')\nsns.countplot(data=train.loc[train['Cabin'] == 'other'], hue ='Survived', x='Pclass',  ax=ax[1,0])\nsns.countplot(data=train.loc[train['Cabin'] != 'other'], hue ='Survived', x='Pclass',  ax=ax[1,1])\n\n","eff22e46":"for dataframe in [train, test]:\n    dataframe['Cabin'] = dataframe['Cabin'].apply(lambda vector: 0 if vector == 'other' else 1)\n    \ntrain.head()","8f063972":"\nfig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n\nsns.countplot(data=train, hue ='Survived', x='Embarked', ax=ax[0]).set_title('Embarked Survived Ratio')\nsns.countplot(data=train, hue ='Pclass', x='Embarked', ax=ax[1]).set_title('Embarked Pclass')\n","c5ec703e":"#\"C\" includes mostly class 1 people and surive ratio seems to be correlated with class here, dropping this column.\n\nfor dataframe in [train, test]:\n    dataframe.drop('Embarked', inplace=True, axis=1)","c426427b":"#Exploring titles and social ranks omboard, as we know members of the english aristocracy joined the ship, is it possible to combine this and fare?.\n#Structure: Surname, title. name -\nfor dataframe in [train, test]:\n    dataframe['Title']= dataframe['Name'].apply(lambda name:re.search(r'\\,(.*?)\\.',name).group(0))\n    #dataframe.drop('Name', inplace=True, axis= 1)\n","85a0a675":"\n\nfig, ax = plt.subplots(ncols=2, figsize=(20, 5))\nsns.countplot(data=train, x='Title', hue='Survived', ax=ax[0])\nsns.countplot(data=train, x='Title', hue='Pclass', ax=ax[1])","7fd8d947":"train.head()\n\n#Keeping Title for now, these dropping Name + Ticket \nfor dataframe in [train, test]:\n    dataframe.drop(['Name', 'Ticket'], inplace=True, axis=1)","0dc562fe":"#transforming special Titles into something more usable\n\nfor dataframe in [train, test]:\n   dataframe['Title'] = dataframe['Title'].apply(lambda vector: vector if vector in [', Mr.', ', Mrs.' , ', Miss.', ', Master.'] else \"Special\" )\n\ntrain.head()","f90d1b6f":"#lets get a dist plot going for fare possibly we could use this either as a 0 - 1 delimer or bucketize \n\nfig, ax = plt.subplots(ncols=2, nrows=2, figsize=(20, 10))\n\nsns.distplot(train['Fare'], ax=ax[0,0]).set_title(\"Total\")\n\nsns.distplot(train.loc[train['Pclass']==1]['Fare'], ax=ax[0,1], color='Blue').set_title(\"Class 1\")\n             \nsns.distplot(train.loc[train['Pclass']==2]['Fare'], ax=ax[1,0], color='Orange').set_title(\"Class 2\")\n             \nsns.distplot(train.loc[train['Pclass']==3]['Fare'], ax=ax[1,1], color='Green').set_title(\"Class 3\")\n","373cf81e":"\n#Within class one, there is a clear corelation between higher survival ratio and fare. \n#On average the higher paying persons survied, most likely due to skewed stats (500 fare)\n\ntrain.loc[train['Pclass'] != 1]\n\nfig, ax = plt.subplots(ncols=2, figsize=(20, 10))\nsns.barplot(x=\"Pclass\", y=\"Fare\", hue=\"Survived\", data=train, ax=ax[0])\nsns.barplot(x=\"Sex\", y=\"Fare\",  hue=\"Survived\", data=train,  ax=ax[1]);\n\n","760f7c50":"#lets get binning,\nfor dataframe in [train, test]:\n    dataframe.loc[ dataframe['Fare'] <= 10, 'Fare']  = 0\n    dataframe.loc[(dataframe['Fare'] > 10) & (dataframe['Fare'] <= 15), 'Fare'] = 1\n    dataframe.loc[(dataframe['Fare'] > 15) & (dataframe['Fare'] <= 22), 'Fare'] = 2\n    dataframe.loc[(dataframe['Fare'] > 22) & (dataframe['Fare'] <= 30), 'Fare'] = 3\n    dataframe.loc[(dataframe['Fare'] > 30) & (dataframe['Fare'] <= 40), 'Fare'] = 4\n    dataframe.loc[(dataframe['Fare'] > 40) & (dataframe['Fare'] <= 60), 'Fare'] = 5\n    dataframe.loc[(dataframe['Fare'] > 60) & (dataframe['Fare'] <= 100), 'Fare'] = 6\n    dataframe.loc[(dataframe['Fare'] > 100) & (dataframe['Fare'] <= 200), 'Fare'] = 7\n    dataframe.loc[ dataframe['Fare'] > 200, 'Fare'] = 8 ;\n\n","3725ff35":"#fixing missing fare in test, set it to the avg (pclass 3 -)\ntest.loc[test['Fare'].isnull(), 'Fare'] = 0","6d723973":"sns.countplot(x='Fare', hue='Survived', data=train)\n#looks good lets continue.","2ff0c991":"train.head()","193d543d":"Families = train.loc[(train['SibSp']>0) | (train['Parch'] > 0)]\nSingles = train.loc[(train['SibSp']==0) & (train['Parch'] == 0)]\n\nprint('Percent of surving when part of a \"family\" is %.2f%%' %(Families.loc[Families['Survived']==1]['SibSp'].count() \/ Families['SibSp'].count()))\nprint('Percent of surving when single is %.2f%%' %(Singles.loc[Singles['Survived']==1]['SibSp'].count() \/ Singles['SibSp'].count()))\n \nprint(Families.shape)\nprint(Singles.shape)\n\nfig, ax =plt.subplots(1,2)\nsns.countplot(x='Survived', data = Families, ax=ax[0]).set_title('Families')\nsns.countplot(x='Survived', data = Singles, ax=ax[1]).set_title('Singles')\n\n","5f6a7d3a":"#Create another column with the number of famial ties and complete remove SibSp and Parch,\n\nfor dataframe in [train, test]:\n    dataframe['FamMemb'] = dataframe.apply(lambda column: column[['SibSp']] + column['Parch'], axis=1)\n    dataframe.drop(['Parch','SibSp'],axis = 1, inplace = True)\n    \ntrain.head()","56eb4e41":"sns.countplot(data=train, x='FamMemb', hue='Survived') ","af9a39b7":"#Lets get ready to bucketize the last data\n#overall Age distribution \n\ngroup_labels = ['distplot']\nfig = ff.create_distplot([train.loc[train['Age'].notnull()]['Age'].values], ['Age'])\npy.iplot(fig, filename='Basic Distplot')","2683afbb":"\nfig, ax = plt.subplots(ncols=3 ,  figsize=(20, 5))\n              \nsns.barplot(x=\"Sex\", y=\"Age\", hue=\"Title\", data=train, ax=ax[0])\nsns.barplot(x=\"Sex\", y=\"Age\", hue=\"Fare\", data=train,  ax=ax[1]);\nsns.barplot(x=\"Sex\", y=\"Age\", hue=\"Pclass\", data=train, ax=ax[2])","3f3e577d":"#Fixing Special case title in test.\ntest.loc[test.index == 980, 'Age'] = 22\n\n#Define function to return a random age number based on class, title and sex. \ndef f(row, dataframe):\n    return np.random.choice(dataframe.loc[(dataframe['Sex'] == row['Sex']) & (dataframe['Pclass'] == row['Pclass']) & (dataframe['Title'] == row['Title']) & (dataframe['Age'].notnull())]['Age'], 1)[0]\n\n\nfor dataframe in [train, test]:\n    dataframe.loc[dataframe['Age'].isnull(), 'Age'] = dataframe.loc[dataframe['Age'].isnull()].apply(f, args=(dataframe, ), axis = 1)\n   ","318bb049":"#Lets get ready to bucketize the last data\n#overall Age distribution \n\ngroup_labels = ['distplot']\nfig = ff.create_distplot([train['Age'].values], ['Age'])\npy.iplot(fig, filename='Basic Distplot')","cb83146e":"#last step lets bucketize Age:\n\nfor dataframe in [train, test]:\n    dataframe.loc[ dataframe['Age'] <= 10, 'Age']  = 0 #children\n    dataframe.loc[(dataframe['Age'] > 10) & (dataframe['Age'] <= 15), 'Age'] = 1\n    dataframe.loc[(dataframe['Age'] > 15) & (dataframe['Age'] <= 20), 'Age'] = 2\n    dataframe.loc[(dataframe['Age'] > 20) & (dataframe['Age'] <= 30), 'Age'] = 3\n    dataframe.loc[(dataframe['Age'] > 30) & (dataframe['Age'] <= 40), 'Age'] = 4\n    dataframe.loc[(dataframe['Age'] > 40) & (dataframe['Age'] <= 50), 'Age'] = 5\n    dataframe.loc[ dataframe['Age'] > 50, 'Age'] = 6 ;\n    \n\n","24d3b9f4":"\ngroup_labels = ['distplot']\nfig = ff.create_distplot([train['Age'].values], ['Age'])\npy.iplot(fig, filename='Basic Distplot')","651fbfd0":"#lets numerize the last values and plug this into some ML models\n#create new column\nfor dataframe in [train, test]:\n    dataframe['Female'] = dataframe.apply(lambda column: 1 if column['Sex'] == 'female' else 0, axis=1)\n    dataframe.drop('Sex', inplace=True, axis= 1)\n\n","0f7f5224":"#last step lets bucketize Age:\n\nfor dataframe in [train, test]:\n    dataframe.loc[ (dataframe['Title'] == \", Master.\"), 'Title']  = 0\n    dataframe.loc[(dataframe['Title'] == \", Miss.\") , 'Title'] = 1\n    dataframe.loc[(dataframe['Title'] == \", Mr.\") , 'Title'] = 2\n    dataframe.loc[(dataframe['Title'] == \", Mrs.\") , 'Title'] = 3\n    dataframe.loc[(dataframe['Title'] == \"Special\") , 'Title'] = 4\n    \n\n","0ceb4c05":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif\n","67d545d3":"#Split data into target feature and train data.\ntarget = train.iloc[:,0]\ntrain.drop('Survived', inplace=True, axis=1)\n\ncols = train.columns","91f47ef5":"#Using max min scaler as our outliers are fixed with binning.\nscaler = MinMaxScaler()\ntrain = scaler.fit_transform(train)\ntest = scaler.fit_transform(test)","1a801a5b":"\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n#K-Folds cross-validato\n#Provides train\/test indices to split data in train\/test sets. \n#Split dataset into k consecutive folds (5 is default).\nkf = KFold(n_splits = 5, random_state = 1)\n\n#Set hyperparameters, lets iterate over a large range.\nxgb_paramaters = {'max_depth' : [1, 2, 3, 4], 'learning_rate' : [0.05, 0.1, 0.15, 0.2], 'n_estimators' : [50, 100, 200, 300], 'n_jobs' : [-1], 'random_state' : [1]}\nxgb = XGBClassifier()","bc356ed5":"\nfrom sklearn.metrics import classification_report\n\n\nscores = ['precision', 'recall']\n\nfor score in scores:\n    print(\"# Tuning hyper-parameters for %s\" % score)\n    print()\n    \n    #using Gridsearch to estimate the best combination of hyperparameter values.\n    gs_xgb = GridSearchCV(xgb, xgb_paramaters, n_jobs = -1, cv = kf, scoring = 'roc_auc')\n    gs_xgb.fit(train, target)\n    \n\n    print(\"Best parameters set found on development set:\")\n    print(gs_xgb.best_score_)\n    print(gs_xgb.best_params_)\n    print()\n\n    print(\"Detailed classification report:\")\n    print()\n    print(\"The model is trained on the full development set.\")\n    print(\"The scores are computed on the full evaluation set.\")\n    print()\n    y_true, y_pred = target, gs_xgb.predict(train)\n    print(classification_report(y_true, y_pred))\n    print()\n","4a6eaee1":"prediction = gs_xgb.predict(test)\n","efb501d2":"index = pd.RangeIndex(start=892, stop=1310, step=1)","3323a6f1":"\ntest_index = pd.DataFrame(test)\nsubmission = pd.DataFrame({'Survived' : prediction}, index = index)\nsubmission.to_csv('submission.csv', index_label = ['PassengerId'])","f9d7411c":"## 2.8 Numeration of last variables.","18cb7e52":"### **Dealing with missing records.**\n","14af0edc":"## **3. Model selection and prediction**\n\nNormalization.","88771873":"# **Titanic dataset - Logistic Regression - SciKit Learn - XGBoost**","51edb384":"## 2.2 Embarked","8d92c93e":"## 2.1 - Cabin","6539aa6c":"### **4. Summary and data submission**","59273668":"## **2. Data exploration**","9c71af0e":"Quick notes:\n* We can see that surival correlates with Class, Sex, Famlilal ties, also port \"C\" (most likely lots of women or high class) seems to have a larger surival rate.\n* Average age is 29, class pop leans towards 3, Average familal tie is less than 1. Survival rate 0.38%","a3e8c8c6":"### 1. **Problem Statement: Predict if a person would live or die on the titanic**","70e4ba98":"**Alterations**\n* Cabin - Lets explore this a bit more. Could possibly be related to Pclass and survivability.\n* Age: -81% data should be enough to guess the remainders.\n* Ticket - There is a correlation with passenger class and possibly Cabin? \n* Embarked - Couldnt possible matter where you came from?\n\n","c8d28b70":"## 2.4 - Fare","3d545793":"## 2.6 Families","cc5d2136":" Seems that people with documented cabins mostly comes from Pclass 1, and overall has higher survivability rate than the average, we will make cabin into a known = 1 or not know = 0 type of column.","0cd4edd3":"## 2.7 - Age","e99a3ff2":"## 2.3 Name - Title - Social Rank"}}