{"cell_type":{"e04892c6":"code","a654364e":"code","18dae3bc":"code","7d660c29":"code","6ba86d23":"code","a308ea0a":"code","75315054":"code","05d16436":"code","177b01d0":"code","9de415cb":"code","8e2b9cd4":"code","c3ee95d5":"code","56cafa78":"code","31111c31":"code","2d50f8d8":"code","e1a6723b":"code","ff3ec15b":"code","b39a1451":"code","861c732c":"code","2aa8250d":"code","954f43af":"code","b817d283":"code","fd1bd93a":"code","19525ff1":"code","85ba5582":"code","6408b364":"code","11178ae0":"code","7c8a9d36":"code","ecdf73a8":"code","e1f35035":"code","61233488":"code","8ca9b301":"code","6cae814a":"code","75a55fd7":"code","66a7d4e5":"code","38102b57":"code","dc450eb3":"code","37bb20fc":"code","669884e3":"markdown","5fb77d47":"markdown","49ffaf76":"markdown","4eda5885":"markdown","a773fd94":"markdown","987c7f8e":"markdown","0aa2d382":"markdown","d5ecbcca":"markdown","02606567":"markdown","7f987624":"markdown","1578b920":"markdown","88558d74":"markdown","09196649":"markdown","61c5e22e":"markdown","21830148":"markdown","1f821f53":"markdown"},"source":{"e04892c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a654364e":"# Import useful libraries\n\nimport time\nimport re\nimport string\nfrom numpy import mean\nfrom numpy import set_printoptions\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold, KFold, GridSearchCV\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.utils.multiclass import type_of_target\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom collections import Counter\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n\nimport warnings\nwarnings.filterwarnings('ignore')","18dae3bc":"# Read dataset\n\ntrain_data = pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv')\ntrain_data.columns = train_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ntest_data.columns = test_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')","7d660c29":"print('Train Data Shape: ', train_data.shape)\nprint('Test Data Shape: ', test_data.shape)\ntrain_data.head()","6ba86d23":"train_data.isnull().sum()","a308ea0a":"train_data['response'].value_counts()","75315054":"train_data.nunique()","05d16436":"fig, axes = plt.subplots(ncols = 2, figsize = (13, 3), dpi = 100)\nplt.tight_layout()\n\ntrain_data.groupby('response').count()['id'].plot(kind = 'pie', ax = axes[0], labels = ['Interested (87.7%)', 'Not Interested (12.1%)'])\nsns.countplot(x = train_data['response'], hue = train_data['response'], ax = axes[1])\n\naxes[0].set_ylabel('')\naxes[1].set_ylabel('')\naxes[1].set_xticklabels(['Interested (87.7%)', 'Not Interested (12.1%)'])\naxes[0].tick_params(axis = 'x', labelsize = 8)\naxes[0].tick_params(axis = 'y', labelsize = 8)\naxes[1].tick_params(axis = 'x', labelsize = 8)\naxes[1].tick_params(axis = 'y', labelsize = 8)\n\naxes[0].set_title('Label Distribution in Training Set', fontsize = 8)\naxes[1].set_title('Label Count in Training Set', fontsize =8)\n\nplt.show()","177b01d0":"# looking at the frequency of records by age\n\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.copper(np.linspace(0, 1, 66))\ntrain_data['age'].value_counts().head(66).plot.bar(color = color)\nplt.title('Age distribution (Most policy holders are young. Age is highly skewed)', fontsize = 15)\nplt.xticks(rotation = 90)\nplt.show()","9de415cb":"train_data['type'] = 'train'\ntest_data['type'] = 'test'\n\nmaster_data = pd.concat([train_data, test_data])","8e2b9cd4":"plt.figure(figsize = (8, 5))\nsns.distplot(master_data['annual_premium'])\nplt.title('Annual Premium distribution (Highly skewed to the right)', fontsize = 15)\nplt.show()","c3ee95d5":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['gender'] == 'Male'), 'age'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Male\"})\nsns.distplot(master_data.loc[(master_data['gender'] == 'Female'), 'age'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Female\"})\nplt.title('Age distribution by Gender', fontsize = 15)\nplt.show()","56cafa78":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['gender'] == 'Male'), 'annual_premium'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Male\"})\nsns.distplot(master_data.loc[(master_data['gender'] == 'Female'), 'annual_premium'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Female\"})\nplt.title('Annual Premium distribution by Gender', fontsize = 15)\nplt.show()","31111c31":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['driving_license'] == 0), 'age'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Not Licensed for driving\"})\nsns.distplot(master_data.loc[(master_data['driving_license'] == 1), 'age'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Licensed for Driving\"})\nplt.title('Age distribution by Driving License', fontsize = 15)\nplt.show()","2d50f8d8":"plt.figure(figsize = (15, 6))\nsns.distplot(master_data.loc[(master_data['driving_license'] == 0), 'annual_premium'], kde_kws = {\"color\": \"b\", \"lw\": 1, \"label\": \"Not Licensed for driving\"})\nsns.distplot(master_data.loc[(master_data['driving_license'] == 1), 'annual_premium'], kde_kws = {\"color\": \"r\", \"lw\": 1, \"label\": \"Licensed for Driving\"})\nplt.title('Annual Premium distribution by Driving License', fontsize = 15)\nplt.show()","e1a6723b":"plt.figure(figsize = (18, 5))\nsns.boxplot(master_data['annual_premium'])\nplt.title('Annual Premium distribution (Highly skewed to the right)', fontsize = 15)\nplt.show()","ff3ec15b":"plt.figure(figsize = (8, 5))\nsns.distplot(master_data['vintage'])\nplt.title('No. of days customer was associated with the company', fontsize = 15)\nplt.show()","b39a1451":"# looking at the frequency of records by age\n\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.copper(np.linspace(0, 1, 50))\ntrain_data['policy_sales_channel'].value_counts().head(50).plot.bar(color = color)\nplt.title('Top Policy Sales Channels', fontsize = 15)\nplt.xticks(rotation = 90)\nplt.show()","861c732c":"# looking at the frequency of records by sales channel\n\nplt.rcParams['figure.figsize'] = (18, 7)\ncolor = plt.cm.copper(np.linspace(0, 1, 53))\ntrain_data['region_code'].value_counts().head(53).plot.bar(color = color)\nplt.title('Customers count by top regions', fontsize = 15)\nplt.xticks(rotation = 90)\nplt.show()","2aa8250d":"fig, axes = plt.subplots(ncols = 2, figsize = (13, 3), dpi = 100)\nplt.tight_layout()\n\ntrain_data.groupby('previously_insured').count()['id'].plot(kind = 'pie', ax = axes[0], labels = ['Insured Customers (54.1%)', 'Not Insured Customers (45.9%)'])\nsns.countplot(x = train_data['previously_insured'], hue = train_data['previously_insured'], ax = axes[1])\n\naxes[0].set_ylabel('')\naxes[1].set_ylabel('')\naxes[1].set_xticklabels(['Insured Customers (54.1%)', 'Not Insured Customers (45.9%)'])\naxes[0].tick_params(axis = 'x', labelsize = 8)\naxes[0].tick_params(axis = 'y', labelsize = 8)\naxes[1].tick_params(axis = 'x', labelsize = 8)\naxes[1].tick_params(axis = 'y', labelsize = 8)\n\naxes[0].set_title('Label Distribution in Training Set', fontsize = 8)\naxes[1].set_title('Label Count in Training Set', fontsize =8)\n\nplt.show()","954f43af":"sns.countplot(data = master_data, x = 'driving_license', hue = 'gender')\nplt.ylabel('Count')\nplt.show()","b817d283":"# Unique values for all the columns\nfor col in train_data.columns[~(train_data.columns.isin(['age', 'id', 'region_code', 'annual_premium', 'policy_sales_channel', 'vintage']))].tolist():\n    print(\" Unique Values --> \" + col, ':', len(train_data[col].unique()), ': ', train_data[col].unique())","fd1bd93a":"gender = {'Male': 0, 'Female': 1}\ndriving_license = {0: 0, 1: 1}\npreviously_insured = {0: 1, 1: 0}\nvehicle_age = {'> 2 Years': 2, '1-2 Year': 1, '< 1 Year': 0}\nvehicle_damage = {'Yes': 1, 'No': 0}\n\nmaster_data['gender'] = master_data['gender'].map(gender)\nmaster_data['driving_license'] = master_data['driving_license'].map(driving_license)\nmaster_data['previously_insured'] = master_data['previously_insured'].map(previously_insured)\nmaster_data['vehicle_age'] = master_data['vehicle_age'].map(vehicle_age)\nmaster_data['vehicle_damage'] = master_data['vehicle_damage'].map(vehicle_damage)\n\nmaster_data['policy_sales_channel'] = master_data['policy_sales_channel'].apply(lambda x: np.int(x))\nmaster_data['region_code'] = master_data['region_code'].apply(lambda x: np.int(x))\n\nmaster_data.head()","19525ff1":"corrMatrix = master_data.corr()\nsns.heatmap(corrMatrix, annot = True)\nplt.show()","85ba5582":"# Numerical columns\nnumerical_cols = ['age', 'vintage']\n\n# categorical column \ncat_col = ['gender', 'driving_license', 'region_code', 'previously_insured', 'vehicle_age', 'vehicle_damage', 'policy_sales_channel']\n\n#master_data['policy_sales_channel'] = master_data['policy_sales_channel'].map(master_data['policy_sales_channel'].value_counts())\n#master_data['region_code'] = master_data['region_code'].map(master_data['region_code'].value_counts())\n\nss = StandardScaler()\nmaster_data[numerical_cols] = ss.fit_transform(master_data[numerical_cols])\n\nmm = MinMaxScaler()\nmaster_data[['annual_premium']] = mm.fit_transform(master_data[['annual_premium']])\n\nmaster_data.head()","6408b364":"train_data = master_data.loc[(master_data['type'] == 'train')]\ntest_data = master_data.loc[(master_data['type'] == 'test')]\n\ntrain_data = train_data.drop(['id', 'type'], axis = 1)\ntrain_data['response'] = train_data['response'].apply(lambda x: np.int(x))\n\ntestIDs = test_data['id']\ntest_data = test_data.drop(['id', 'type', 'response'], axis = 1)\ntrain_data.head()","11178ae0":"for column in cat_col:\n    test_data[column] = test_data[column].astype('str')","7c8a9d36":"for column in cat_col:\n    train_data[column] = train_data[column].astype('str')\n\ntrain_data = train_data.drop(['vintage'], axis = 1)\ntest_data = test_data.drop(['vintage'], axis = 1)\n\nX = train_data.drop(['response'], axis = 1)#.values\ny = train_data['response']#.values\n\ncat_cols = [0, 2, 3, 4, 5, 6, 8]","ecdf73a8":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.22, random_state = 22, stratify = y, shuffle = True)\n\nmodelC = CatBoostClassifier()\nmodelC = modelC.fit(X_train, y_train, cat_features = cat_col, eval_set = (X_test, y_test), early_stopping_rounds = 10, verbose = 100)\n\npredictions = [pred[1] for pred in modelC.predict_proba(X_test)]\nprint('Validation ROC AUC Score:', roc_auc_score(y_test, predictions, average = 'weighted'))","e1f35035":"cat_pred = [pred[1] for pred in modelC.predict_proba(test_data)]\nsubmissionC = pd.DataFrame(data = {'id': testIDs, 'Response': cat_pred})\nsubmissionC.to_csv(\"catboost_v1.csv\", index = False)\nsubmissionC.head()","61233488":"X = train_data.drop(['response'], axis = 1).values\ny = train_data['response'].values","8ca9b301":"kfold, scores = KFold(n_splits = 5, shuffle = True, random_state = 22), list()\nfor train, test in kfold.split(X):\n    X_train, X_test = X[train], X[test]\n    y_train, y_test = y[train], y[test]\n\n    model = LGBMClassifier(random_state = 22, max_depth = 7, n_estimators = 110, reg_lambda = 1.2, reg_alpha = 1.2, min_child_weight = 1, \n                           learning_rate = 0.15, gamma = 0.3, colsample_bytree = 0.5, eval_metric = 'auc', is_higher_better = 1, plot = True)\n    model.fit(X_train, y_train)\n    preds = [pred[1] for pred in model.predict_proba(X_test)]\n    score = roc_auc_score(y_test, preds, average = 'weighted')\n    scores.append(score)\n    print('Validation ROC AUC:', score)\nprint(\"Average Validation ROC AUC: \", sum(scores)\/len(scores))","6cae814a":"yTest = model.predict(X_test)\n\nfpr, tpr, thresholds = roc_curve(yTest.ravel(), y_test)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label = 'AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.0])\nplt.ylim([-0.1,1.01])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","75a55fd7":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)","66a7d4e5":"\"\"\"\nmodel = LGBMClassifier(random_state = 22)\n\nparam_grid = {\"learning_rate\"    : [0.01, 0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40],\n              \"max_depth\"        : [4, 5, 6, 7, 8, 9, 10],\n              \"min_child_weight\" : [1, 3, 5, 7],\n              \"gamma\"            : [0.0, 0.1, 0.2 , 0.3, 0.4],\n              \"colsample_bytree\" : [0.3, 0.4, 0.5 , 0.7],\n              \"n_estimators\"     : [50, 70, 90, 100, 120, 150, 200, 250, 300, 350, 400, 450],\n              'reg_alpha'        : [1,1.2],\n              'reg_lambda'       : [1,1.2,1.4]\n              }\n\nkfold = KFold(n_splits = 6, shuffle = True, random_state = 22)\n\ngrid_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = \"accuracy\", n_jobs  = -1, cv = kfold, verbose = 1)\ngrid_result = grid_search.fit(X_train, y_train)\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n\"\"\"","38102b57":"bestLGB = LGBMClassifier(random_state = 22, max_depth = 7, n_estimators = 110, reg_lambda = 1.2, reg_alpha = 1.2, min_child_weight = 1,\n                         learning_rate = 0.15, gamma = 0.3, colsample_bytree = 0.5)\nbestLGB.fit(X_train, y_train)\ny_pred = bestLGB.predict_proba(X_test)","dc450eb3":"Preds = [predClass[1] for predClass in model.predict_proba(test_data.values)]","37bb20fc":"submission = pd.DataFrame(data = {'id': testIDs, 'Response': Preds})\nsubmission.to_csv('cross_sell_v8.csv', index = False)\nsubmission.head()","669884e3":"## CatBoost gave an ROC AUC score of 85.83 (0.3 improvement over LightGBM)","5fb77d47":"# Predictions","49ffaf76":"- It appears **policy sales channel** and **vintage** are more negatively correlated to the target variable **response**","4eda5885":"## Hyperparameter Tuning","a773fd94":"## Combine Training and Test Data for additional visualizations","987c7f8e":"# Exploratory Data Analysis","0aa2d382":"## 1. Catboost Model","d5ecbcca":"## ROC AUC Curve","02606567":"### Splitting the dataset","7f987624":"## Splitting bact to train\/test set","1578b920":"##### We should oversample the minority class to account for customers without a driving license","88558d74":"# Model Building","09196649":"# Feature Engineering","61c5e22e":"# Correlation of features with target variable","21830148":"# Submission","1f821f53":"## 2. LGBM Classifier with kFold"}}