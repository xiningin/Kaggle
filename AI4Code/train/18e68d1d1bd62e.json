{"cell_type":{"77685c31":"code","8728b79a":"code","4db65cd7":"code","3798e7ab":"code","144f2060":"code","719d9903":"code","bb5d0b35":"code","d957edb5":"code","89dab7f5":"code","e0917667":"code","16317363":"code","28f1b7ff":"code","4efebb77":"code","7d7eff16":"code","8417f047":"code","531b2a09":"code","fcef0fcc":"code","a4140f4c":"code","cbe2c7fd":"code","a09b2e2a":"code","5fb5574c":"markdown","45dd0310":"markdown","14d05f90":"markdown","6fba6c4f":"markdown","2637bb07":"markdown","804941ab":"markdown","a795ebc6":"markdown","1031a1bb":"markdown","e331d75c":"markdown","524cd571":"markdown","5c026b3a":"markdown","1ffa86fb":"markdown","99c5202d":"markdown","0944dee5":"markdown","54213dd4":"markdown","5e3a688a":"markdown","904097a2":"markdown","36eb86b9":"markdown","727a5761":"markdown","5dcf673d":"markdown"},"source":{"77685c31":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nnp.random.seed(2021)","8728b79a":"cp = \"\/kaggle\/input\/tabular-playground-series-sep-2021\/\"\ndf_train = pd.read_csv(cp + \"train.csv\")\ndf_test = pd.read_csv(cp + \"test.csv\")\nsubmission = pd.read_csv(cp + \"sample_solution.csv\")","4db65cd7":"# Labels extraction & redundant columns removal\nlabels = df_train['claim']\ndf_train.drop(['id', 'claim'], axis = 1, inplace = True)\ndf_test.drop(['id'], axis = 1, inplace = True)","3798e7ab":"df_train.head(3)","144f2060":"df_train.info()","719d9903":"plt.figure(figsize = (6, 6))\nplt.xticks(size = 12); plt.yticks(size = 12)\nax = sns.countplot(x = labels,linewidth = 5, palette=\"Set2\")\nax.set_title('Claim Countplot', fontsize = 20)\nax.set_xlabel('Claim', fontsize = 12); ax.set_ylabel('Count', fontsize = 12)\ntotal = labels.shape[0]\nfor p in ax.patches:\n    percent = 100 * p.get_height() \/ total\n    percent_t = f\"{percent:.2f}%\"\n    x, y = p.get_x() + p.get_width() \/ 2, p.get_y() + p.get_height() \/ 2\n    ax.annotate(percent_t, (x, y), fontsize = 12, ha = 'center')\n    p.set_width(p.get_width() * 0.5)\n    p.set_x(p.get_x() + p.get_width() * 0.5)\nplt.show()","bb5d0b35":"df_train.describe().T.style.background_gradient(cmap = 'Blues')\\\n                           .bar(subset = [\"mean\",], color = 'lightgreen')\\\n                           .bar(subset = [\"std\"], color = '#ee1f5f')\\\n                           .bar(subset = [\"max\"], color = '#FFA07A')","d957edb5":"emptyCols_train, emptyCols_test = df_train.columns[df_train.isnull().any()], df_test.columns[df_test.isnull().any()]\nmissing_cells_train, missing_cells_test = df_train.isnull().sum().sum(), df_test.isnull().sum().sum()\nmissing_percent_train = np.round(100 * missing_cells_train \/ np.product(df_train.shape), 4)\nmissing_percent_test = np.round(100 * missing_cells_test \/ np.product(df_test.shape), 4)\nprint(\"############ Null Values in df_train & df_test ############\\n\")\nprint(f\"df_train : {len(emptyCols_train)} \/ {len(df_train.columns)} columns contain Nan\")\nprint(f\"           {missing_cells_train:,} Nan \/ {np.product(df_train.shape):,} Cells : {missing_percent_train}%\\n\")\nprint(f\"df_test : {len(emptyCols_test)} \/ {len(df_test.columns)} columns contain Nan\")\nprint(f\"           {missing_cells_test:,} Nan \/ {np.product(df_test.shape):,} Cells : {missing_percent_test}%\")","89dab7f5":"df_null_train = pd.DataFrame(data = df_train.isnull().sum(), columns = ['train_nan'])\ndf_null_test = pd.DataFrame(data = df_test.isnull().sum(), columns = ['test_nan'])\ndf_null = pd.concat([df_null_train, df_null_test], axis = 1, join = 'inner')\ndf_null['train_nan'] \/= df_train.shape[0]; df_null['test_nan'] \/= df_test.shape[0]\ndf_null['average'] = (df_null['train_nan'] + df_null['test_nan']) \/ 2\ndf_null *= 100\ndf_null.sort_values(ascending = False, by = ['average'], inplace = True)\nfeatures = list(df_null.index)\nfig, ax = plt.subplots(figsize = (15, 6))\nplt.xticks(size = 12); plt.yticks(size = 12)\nax = sns.scatterplot(data = df_null)\nax.set_title('Proportion of Nan Values in Train & Test Data', fontsize = 20)\nax.set_xticks(features[::4]); ax.set_xticklabels(features[::4], rotation = 45)\nax.set_xlabel('feature', fontsize = 12); ax.set_ylabel('%', fontsize = 12)\nplt.show()","e0917667":"print(f\"All features in both df_train & df_test include Nan values with the proportion : {np.round(df_null.min().min(), 3)}% ~ {np.round(df_null.max().max(),3)}%\")","16317363":"lst1, lst0, totals = [], [], []\nmaxOneProp, minOneProp = float('-inf'), float('inf')\nfor col in df_train.columns:\n    nullIndex = df_train[col].isnull()\n    ones = labels[nullIndex].sum()\n    total = labels[nullIndex].count()\n    maxOneProp = max(maxOneProp, 100 * ones \/ total)\n    minOneProp = min(minOneProp, 100 * ones \/ total)\n    zeros = total - ones\n    lst1.append(ones); lst0.append(zeros); totals.append(total)\nfeature_missing_df = pd.concat([pd.Series(df_train.columns), pd.Series(lst0), pd.Series(lst1),pd.Series(totals)], axis = 1)\nfeature_missing_df.set_axis(['feature', 'claim_0', 'claim_1', 'total'], axis = 1, inplace = True)\nfeature_missing_df.sort_values('total', ascending = False, inplace = True)","28f1b7ff":"sns.set_context('paper')\nf, ax = plt.subplots(figsize = (13,20))\nsns.set_color_codes('pastel')\nsns.barplot(x = 'total', y = 'feature', data = feature_missing_df, label = 'Total', color = 'r', edgecolor = 'w')\nsns.barplot(x = 'claim_1', y = 'feature', data = feature_missing_df, label = 'Claim_1', color = 'b', edgecolor = 'w')\nsns.set_color_codes('muted')\nax.legend(ncol = 2, loc = 'lower right')\nax.set_title('Claim Distribution for Missing Cols', fontsize = 20)\nax.set_xlabel('Claim 1 vs 0', fontsize = 12); ax.set_ylabel('Feature', fontsize = 12)\nplt.xticks(size = 12); plt.yticks(size = 12)\nax.set_yticks(ax.get_yticks()[::4]);\nplt.show()\ndel feature_missing_df","4efebb77":"print(\"In terms of columns, for Nan value rows : \")\nprint(f\"Claim 0 Proportion : {np.round(100 - maxOneProp, 2)}% ~ {np.round(100 - minOneProp, 2)}%\")\nprint(f\"Claim 1 Proportion : {np.round(minOneProp, 2)}% ~ {np.round(maxOneProp, 2)}%\")","7d7eff16":"missing_cols_row = df_train.isnull().T.sum()\nmaxColMissing = missing_cols_row.max()\nfig, ax = plt.subplots(1,2,figsize = (16, 8))\nfig.suptitle(\"Missing Cols Count per Row in Train Data\", fontsize=18)\nplt.xticks(size=12); plt.yticks(size = 12)\nax = ax.flatten()\n\nsns.countplot(x=missing_cols_row, ax = ax[0])\nax[0].set_title('Row Count', fontsize = 15)\nax[0].set_xlabel('Missing Cols', fontsize = 12); ax[0].set_ylabel('Row Count', fontsize=12)\nfor p in ax[0].patches[8:]:\n    count = f\"{p.get_height():,}\"\n    x, y = p.get_x() + p.get_width() \/ 2, p.get_y() + p.get_height() * 10 + 10000\n    ax[0].annotate(count, (x, y), fontsize = 10, ha = 'center')\n    \nmissing_cols_row.rename(\"count\", inplace = True)\nconcat_df = pd.concat([missing_cols_row, labels], axis = 1)\nnew_counts = concat_df.groupby(['count'])['claim'].value_counts(normalize=True).rename('percentage').mul(100).reset_index().sort_values('percentage')\nsns.barplot(x = 'count', y = 'percentage', hue = 'claim',data = new_counts, ax = ax[1])\nfor p in ax[1].patches:\n    p.set_width(p.get_width() * 0.5)\n    p.set_x(p.get_x() + p.get_width() * 0.5)\nax[1].set_title('Claim Proportion (Normalized)', fontsize = 15)\nax[1].set_xlabel('Missing Cols', fontsize = 12); ax[1].set_ylabel('Percentage (%)', fontsize=12)\nplt.show()","8417f047":"train_max_missing_col, test_max_missing_col = missing_cols_row.max(), df_test.isnull().T.sum().max()\nprint(f\"Training data max # of missing cols in one row : {train_max_missing_col}\")\nprint(f\"Testing data max # of missing cols in one row : {test_max_missing_col}\")","531b2a09":"df_drop = df_train.copy()\ndf_drop.dropna(axis = 0, inplace=True) \nprint(f\"# of removed rows : {df_train.shape[0] - df_drop.shape[0]} out of {df_train.shape[0]} rows\")\nprint(f\"{np.round(100 * (df_train.shape[0] - df_drop.shape[0]) \/ df_train.shape[0], 4)}% rows gone\")\nprint(df_drop.shape)\ndel df_drop","fcef0fcc":"fig, axes = plt.subplots(12,10,figsize = (20, 15))\naxes = axes.flatten()[:-2]\nfor idx, ax in enumerate(axes):\n    sns.kdeplot(data = df_train.sample(n = 10000), x = f'f{idx + 1}', fill = True, ax = ax)\n    sns.kdeplot(data = df_test.sample(n = 10000), x = f'f{idx + 1}', fill = True, ax = ax)    \n    ax.set_xticks([]); ax.set_yticks([]); ax.set_xlabel(''); ax.set_ylabel('')\n    ax.set_title(f'f{idx + 1}', loc = 'right', fontsize = 12)\nfig.tight_layout()\nplt.show()","a4140f4c":"skewness_train = df_train.skew(axis = 0, skipna = True)\nkurtosis_train = df_train.kurtosis(axis = 0, skipna = True)","cbe2c7fd":"sns.set_theme(style=\"whitegrid\")\nfig, ax = plt.subplots(1,2,figsize = (18, 4))\nplt.xticks(size=12); plt.yticks(size = 12)\nax = ax.flatten()\nsns.boxplot(x=skewness_train, ax= ax[0]); sns.boxplot(x=kurtosis_train, ax= ax[1])\nax[0].set_title('Skewness', fontsize=20); ax[1].set_title('Kurtosis', fontsize=20)\nplt.show()","a09b2e2a":"corr = df_train.corr()\nf, ax = plt.subplots(figsize = (16, 16))\nax.set_title('Correlation on Train Data Features', fontsize = 24, y = 1.05)\nmask = np.triu(np.ones_like(corr, dtype = bool))\nsns.heatmap(corr, annot = False, mask = mask, center=0, linewidths = .5, cmap = \"coolwarm\")#, vmin=-0.05, vmax= 0.05)\nplt.show()","5fb5574c":"## Proportion of Missing Values","45dd0310":"# Import Libraries & Setup","14d05f90":"## Labels Overview","6fba6c4f":"# Missing Values\nAll columns contain null values.","2637bb07":"Let's look at the distribution of the number of missing columns for each row.","804941ab":"# Overview","a795ebc6":"# Feature Distribution","1031a1bb":"## Features Overview","e331d75c":"Labels are well-balanced.","524cd571":"dtypes of all 118 features are 'float64'.","5c026b3a":"Let's explore how claim distributions are formed for each column when the column has a missing value:","1ffa86fb":"Looking at each column separately, roughly 75% of the Nan values yield Claim 1","99c5202d":"## Dropping Rows with Any Missing Col","0944dee5":"Dropping all rows with any missing col won't work since it wipes out two-third of all the rows","54213dd4":"What happens if we drop all rows with any missing col?","5e3a688a":"# Feature Correlation","904097a2":"We observe a wide variety of ranges in the features, scaling would be necessary\/preferred.","36eb86b9":"# Feature Skewness & Kurtosis","727a5761":"# TPS - Sep 2021\n\n# Important Notes:\n- Binary Classification : Labels (Claim) are either 0 or 1\n- 118 features, 1 label\n- All 118 features : float64\n- All features include missing values, better find a good way to fill them in\n- Some features include numbers with enormous scale, so scaling is necessary\/preferred","5dcf673d":"## Labels Distribution on Missing Values"}}