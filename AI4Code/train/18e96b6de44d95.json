{"cell_type":{"c405e42d":"code","f9c71b67":"code","622f1bb9":"code","957fad7c":"code","da1745eb":"code","50772b4d":"code","bd14690f":"code","1e117db4":"code","233b54ee":"code","4eb31bcc":"code","cbc93ea7":"code","ef73bdbb":"code","986d9084":"code","9660a16e":"markdown"},"source":{"c405e42d":"import torch\nimport torch.nn as nn \nimport pandas as pd\nimport numpy as np \nimport glob \nimport os\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nimport albumentations\nfrom PIL import Image\nfrom PIL import ImageFile\nfrom torch.nn import functional as F\nfrom  tqdm import tqdm\nfrom sklearn import metrics\nImageFile.LOAD_TRUNCATED_IMAGES=True","f9c71b67":"DATA_DIR = '..\/input\/captcha-version-2-images\/samples'\nBATCH_SIZE = 8\nIMAGE_WIDTH = 200\nIMAGE_HEIGHT = 50\nNUM_WORKERS = 8\nEPOCHS = 200\nDEVICE = \"cpu\"","622f1bb9":"image_files = glob.glob(os.path.join(DATA_DIR,\"*.png\"))\n# ..\/input\/captcha-version-2-images\/samples\/2s22s.png","957fad7c":"targets_o = [x.split('\/')[-1].split('.')[0] for x in image_files]\ntargets = [[c for c in x] for x in targets_o]\ntargets_flatten = [c for clist in targets for c in clist]","da1745eb":"lbl_enc = preprocessing.LabelEncoder()\nlbl_enc.fit(targets_flatten)\ntargets_enc = [lbl_enc.transform(x) for x in targets]\ntargets_enc =np.array(targets_enc)\n","50772b4d":"targets_enc = targets_enc +1\n(train_img, test_img, train_targets,test_targets,_, test_targets_orig) = model_selection.train_test_split(image_files, targets_enc,targets_o, test_size = 0.1, random_state=42 )","bd14690f":"class CaptchaDataset():\n    def __init__(self,image_paths ,targets, resize=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize \n        mean = (0.485,0.456,0.406)\n        std = (0.229,0.224, 0.225)\n        \n        self.aug = albumentations.Compose( [albumentations.Normalize(mean,std, max_pixel_value=255.0,always_apply=True)])\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self,index):\n        image = Image.open(self.image_paths[index]).convert(\"RGB\")\n        targets = self.targets[index]\n        \n        if self.resize is not None:\n            image = image.resize((self.resize[1],self.resize[0]) ,resample=Image.BILINEAR)\n        \n        image =np.array(image)\n        augmented = self.aug(image=image)\n        image = augmented[\"image\"]\n        image= np.transpose(image,(2,0,1)).astype(np.float32)\n        \n        return { \"images\": torch.tensor(image,dtype =torch.float),\n               \"targets\": torch.tensor(targets,dtype=torch.long)}","1e117db4":"class CaptchaModel(nn.Module):\n    def __init__(self, num_chars):\n        super(CaptchaModel, self).__init__()\n        self.conv_1 = nn.Conv2d(3, 128, kernel_size=(3, 3), padding=(1, 1))\n        self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2))\n        self.conv_2 = nn.Conv2d(128, 64, kernel_size=(3, 3), padding=(1, 1))\n        self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2))\n        self.linear_1 = nn.Linear(768, 64)\n        self.drop_1 = nn.Dropout(0.2)\n        self.lstm = nn.GRU(64, 32, bidirectional=True, num_layers=2, dropout=0.25, batch_first=True)\n        self.output = nn.Linear(64, num_chars + 1)\n\n    def forward(self, images, targets=None):\n#         print(images.size())\n        bs, c, h, w = images.size() # 16,3,50,200\n        x = F.relu(self.conv_1(images)) # 16,128,50,200\n        print(x.size())\n        x = self.pool_1(x) # 16,64,25,100\n        print(x.size())\n        x = F.relu(self.conv_2(x)) # 16,64,25,100\n        print(x.size())\n        x = self.pool_2(x) # 16,64,12,50\n        print(x.size())\n        x = x.permute(0, 3, 1, 2) # 16,50,64,12\n        print(x.size()) \n        x = x.view(bs, x.size(1), -1) # 16,50,64*12\n        print(x.size())\n        x = F.relu(self.linear_1(x))\n        print(x.size())\n        x = self.drop_1(x)\n        x, _ = self.lstm(x)\n        print(x.size())\n        x = self.output(x)\n        print(x.size())\n        x = x.permute(1, 0, 2)\n\n        if targets is not None:\n            log_probs = F.log_softmax(x, 2)\n            input_lengths = torch.full(\n                size=(bs,), fill_value=log_probs.size(0), dtype=torch.int32\n            )\n            target_lengths = torch.full(\n                size=(bs,), fill_value=targets.size(1), dtype=torch.int32\n            )\n            loss = nn.CTCLoss(blank=0)(\n                log_probs, targets, input_lengths, target_lengths\n            )\n            return x, loss\n\n        return x, None","233b54ee":"if __name__ == \"__main__\":\n    cm = CaptchaModel(19)\n    img = torch.rand((1, 3, 50, 200))\n    x, _ = cm(img, torch.rand((1, 5)))","4eb31bcc":"\ndef train_fn(model, data_loader, optimizer):\n    model.train()\n    fin_loss = 0\n    tk0 = tqdm(data_loader, total=len(data_loader))\n    for data in tk0:\n        for key, value in data.items():\n            data[key] = value.to(DEVICE)\n        optimizer.zero_grad()\n        _, loss = model(**data)\n        loss.backward()\n        optimizer.step()\n        fin_loss += loss.item()\n    return fin_loss \/ len(data_loader)\n\n","cbc93ea7":"\ndef eval_fn(model, data_loader):\n    model.eval()\n    fin_loss = 0\n    fin_preds = []\n    tk0 = tqdm(data_loader, total=len(data_loader))\n    for data in tk0:\n        for key, value in data.items():\n            data[key] = value.to(DEVICE)\n        batch_preds, loss = model(**data)\n        fin_loss += loss.item()\n        fin_preds.append(batch_preds)\n    return fin_preds, fin_loss \/ len(data_loader)","ef73bdbb":"\ndef remove_duplicates(x):\n    if len(x) < 2:\n        return x\n    fin = \"\"\n    for j in x:\n        if fin == \"\":\n            fin = j\n        else:\n            if j == fin[-1]:\n                continue\n            else:\n                fin = fin + j\n    return fin\n\n\ndef decode_predictions(preds, encoder):\n    preds = preds.permute(1, 0, 2)\n    preds = torch.softmax(preds, 2)\n    preds = torch.argmax(preds, 2)\n    preds = preds.detach().cpu().numpy()\n    cap_preds = []\n    for j in range(preds.shape[0]):\n        temp = []\n        for k in preds[j, :]:\n            k = k - 1\n            if k == -1:\n                temp.append(\"\u00a7\")\n            else:\n                p = encoder.inverse_transform([k])[0]\n                temp.append(p)\n        tp = \"\".join(temp).replace(\"\u00a7\", \"\")\n        cap_preds.append(remove_duplicates(tp))\n    return cap_preds\n\n\n\n","986d9084":"image_files = glob.glob(os.path.join(DATA_DIR, \"*.png\"))\ntargets_orig = [x.split(\"\/\")[-1][:-4] for x in image_files]\ntargets = [[c for c in x] for x in targets_orig]\ntargets_flat = [c for clist in targets for c in clist]\n\nlbl_enc = preprocessing.LabelEncoder()\nlbl_enc.fit(targets_flat)\ntargets_enc = [lbl_enc.transform(x) for x in targets]\ntargets_enc = np.array(targets_enc)\ntargets_enc = targets_enc + 1\n\n(\n    train_imgs,\n    test_imgs,\n    train_targets,\n    test_targets,\n    _,\n    test_targets_orig,\n) = model_selection.train_test_split(\n    image_files, targets_enc, targets_orig, test_size=0.1, random_state=42\n)\n\ntrain_dataset = CaptchaDataset(\n    image_paths=train_imgs,\n    targets=train_targets,\n    resize=(IMAGE_HEIGHT, IMAGE_WIDTH),\n)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    shuffle=True,\n)\n\ntest_dataset = CaptchaDataset(\n    image_paths=test_imgs,\n    targets=test_targets,\n    resize=(IMAGE_HEIGHT, IMAGE_WIDTH),\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    shuffle=False,\n)\n\nmodel = CaptchaModel(num_chars=len(lbl_enc.classes_))\nmodel.to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, factor=0.8, patience=5, verbose=True\n)\nfor epoch in range(EPOCHS):\n    train_loss = train_fn(model, train_loader, optimizer)\n    valid_preds, test_loss = eval_fn(model, test_loader)\n    valid_captcha_preds = []\n    for vp in valid_preds:\n        current_preds = decode_predictions(vp, lbl_enc)\n        valid_captcha_preds.extend(current_preds)\n    combined = list(zip(test_targets_orig, valid_captcha_preds))\n    print(combined[:10])\n    test_dup_rem = [remove_duplicates(c) for c in test_targets_orig]\n    accuracy = metrics.accuracy_score(test_dup_rem, valid_captcha_preds)\n    print(\n        f\"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss} Accuracy={accuracy}\"\n    )\n    scheduler.step(test_loss)\n\n","9660a16e":"## Read the data \n####  GLOB: module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell"}}