{"cell_type":{"e8015a50":"code","5fe972ff":"code","dba7e9d2":"code","504d237a":"code","88f2a2a0":"code","c5d05ec4":"code","8a62377b":"code","ed8c763a":"code","9a106021":"code","d943e7bb":"code","9dbccabf":"code","8b8f6311":"code","95ae908f":"code","4a7583fc":"code","902abc77":"code","2e9e03fd":"code","150bae0c":"code","5d14ec38":"code","dd96a943":"code","648a84cf":"code","77f2e53d":"code","a1ae094b":"code","86e2e5bc":"code","54e49545":"code","0d913d9f":"code","ac91d228":"code","09937c45":"code","8458bbcb":"code","d18f1d0c":"code","996b580c":"code","cdb775b4":"code","19995ee0":"code","920ae374":"code","4bcb0bb7":"code","60fb4019":"code","e9216791":"code","e43550b4":"code","42b77921":"code","82155a93":"code","d8930790":"code","9dd348d4":"code","49687f54":"code","21f92218":"code","ea512f9d":"code","47a90081":"code","c26d098b":"code","ec879f1f":"code","38928d40":"markdown","b35ed870":"markdown","7da5b891":"markdown","d0dad075":"markdown","e45d1647":"markdown","d5dd15fe":"markdown"},"source":{"e8015a50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom imblearn.metrics import classification_report_imbalanced\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5fe972ff":"labels = pd.read_csv('\/kaggle\/input\/cancerdatasets\/labels.csv')\ndata = pd.read_csv('\/kaggle\/input\/cancerdatasets\/data.csv')","dba7e9d2":"plt.figure(figsize=(17,5))\nsns.barplot(x = pd.unique(labels.disease_type), y = labels.disease_type.value_counts());","504d237a":"plt.figure( figsize= (7,7))\nplt.pie((labels.disease_type.value_counts())\/100 , labels=pd.unique(labels.disease_type), startangle\n=180 , autopct='%1.1f%%' ,textprops={ 'fontsize': 11 , 'rotation':0}, shadow=True, radius=1.25)\nplt.show()","88f2a2a0":"X = data.drop(['Unnamed: 0'], axis=1)\ny = labels.disease_type","c5d05ec4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)","8a62377b":"from sklearn.ensemble import RandomForestClassifier","ed8c763a":"rf = RandomForestClassifier()","9a106021":"rf_params = {'n_estimators': [50, 100],\n'max_features': [7, 19, 21],\n'min_samples_split':[3,7,11],\n'max_depth':[3,7,11]}","d943e7bb":"rf_cv_model = GridSearchCV(rf, rf_params, cv=5, n_jobs=-1, verbose=2).fit(X_train, y_train)","9dbccabf":"best_params_rf =  rf_cv_model.best_params_\nbest_params_rf","8b8f6311":"rf = RandomForestClassifier(max_depth=best_params_rf['max_depth'], \n                            max_features=best_params_rf['max_features'], \n                            min_samples_split=best_params_rf['min_samples_split'], \n                            n_estimators=best_params_rf['n_estimators']).fit(X_train, y_train)","95ae908f":"y_pred = rf.predict(X_test)","4a7583fc":"accuracy_score(y_test, y_pred)","902abc77":"cross_val_score(rf, X_test, y_test, cv=3).mean()","2e9e03fd":"from imblearn.metrics import sensitivity_specificity_support\nsensitivity_specificity_support(y_test, y_pred, average='micro', labels=pd.unique(labels.disease_type))","150bae0c":"print(classification_report_imbalanced(y_test, y_pred, target_names=pd.unique(labels.disease_type)))","5d14ec38":"cm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(7,7))\nsns.heatmap(cm, annot=True, fmt=\"d\", linewidths=0.7 ,cbar=False, xticklabels=pd.unique(labels.disease_type),yticklabels=pd.unique(labels.disease_type))\nplt.show()","dd96a943":"from sklearn.ensemble import GradientBoostingClassifier","648a84cf":"gbm = GradientBoostingClassifier()","77f2e53d":"gbm_params = {'learning_rate': [0.1, 0.01, 0.05],\n            'n_estimators': [100,200],\n            'max_depth':[2,3,5,8]}","a1ae094b":"gbm_cv_model = GridSearchCV(gbm, gbm_params, cv=10, n_jobs=-1, verbose=2).fit(X_train, y_train)","86e2e5bc":"gbm_cv_model","54e49545":"best_params_gbm = gbm_cv_model.best_params_","0d913d9f":"gbm = GradientBoostingClassifier(\n    learning_rate=best_params_gbm['learning_rate'], \n    max_depth=best_params_gbm['max_depth'], \n    n_estimators=best_params_gbm['n_estimators']).fit(X_train, y_train)","ac91d228":"y_pred = gbm.predict(X_test)","09937c45":"accuracy_score(y_test, y_pred)","8458bbcb":"cross_val_score(gbm, X_test, y_test, cv=21).mean()","d18f1d0c":"from imblearn.metrics import sensitivity_specificity_support\nsensitivity_specificity_support(y_test, y_pred, average='micro', labels=pd.unique(labels.disease_type))","996b580c":"print(classification_report_imbalanced(y_test, y_pred, target_names=pd.unique(labels.disease_type)))","cdb775b4":"cm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(7,7))\nsns.heatmap(cm, annot=True, fmt=\"d\", linewidths=0.7 ,cbar=False, xticklabels=pd.unique(labels.disease_type),yticklabels=pd.unique(labels.disease_type))\nplt.show()","19995ee0":"from xgboost import XGBClassifier","920ae374":"xgboost = XGBClassifier()","4bcb0bb7":"xgboost_params = {'learning_rate': [0.1, 0.01, 0.001],\n            'subsample':[0.6, 0.8, 1],\n            'n_estimators': [100,500],\n            'max_depth':[3,5,7]}","60fb4019":"xgboost_cv_model = GridSearchCV(xgboost, xgboost_params, cv=10, n_jobs=-1, verbose=2).fit(X_train, y_train)","e9216791":"xgboost_cv_model","e43550b4":"best_params_xgb = xgboost_cv_model.best_params_","42b77921":"xgboost = XGBClassifier(\n    learning_rate=best_params_xgb['learning_rate'], \n    max_depth=best_params_xgb['max_depth'], \n    n_estimators=best_params_xgb['n_estimators'], \n    subsample=best_params_xgb['subsample']).fit(X_train, y_train)","82155a93":"y_pred = xgboost.predict(X_test)","d8930790":"accuracy_score(y_test, y_pred)","9dd348d4":"cross_val_score(xgboost, X_test, y_test, cv=21).mean()","49687f54":"from imblearn.metrics import sensitivity_specificity_support\nsensitivity_specificity_support(y_test, y_pred, average='micro', labels=pd.unique(labels.disease_type))","21f92218":"print(classification_report_imbalanced(y_test, y_pred, target_names=pd.unique(labels.disease_type)))","ea512f9d":"cm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(7,7))\nsns.heatmap(cm, annot=True, fmt=\"d\", linewidths=0.7 ,cbar=False, xticklabels=pd.unique(labels.disease_type),yticklabels=pd.unique(labels.disease_type))\nplt.show()","47a90081":"models = [rf, gbm, xgboost]\nresult = []\nresults = pd.DataFrame(columns=['Models', \"Accuracy\"])\n\nfor model in models:\n    names = model.__class__.__name__\n    print(names)\n    if names == 'MLPClassifier':\n        y_pred = model.predict(X_test_scaler)\n    else:\n        y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    result = pd.DataFrame([[names, acc*100]], columns=['Models', 'Accuracy'])\n    results = results.append(result)","c26d098b":"sns.barplot(x='Accuracy', y='Models', data=results, color='r')\nplt.xlabel('Accuracy %')\nplt.title('Modellerin Do\u011fruluk Oranlar\u0131');","ec879f1f":"results","38928d40":"### Conclusion","b35ed870":"### Preparing the data set for training\n\nDependent and independent variables are determined. The data set is divided into 30% training and testing.","7da5b891":"#### Gradient Boosting Machine(GBM)","d0dad075":"#### eXtreme Gradient Boosting (XGBoost)","e45d1647":"## Diagnosis of Cancer Using Blood Microbiome Data\n\n\nAbstract\n\nIt is known that cancer disease, which is common today, is learned in the early stages and a more effective treatment process is\nexperienced. It is aimed to establish a character support system that will provide early detection in the project. It is aimed to detect 4\ndifferent types of cancer, which are common using system microbiome blood data, by machine learning methods. The project was\ncarried out using classification methods.","d5dd15fe":"#### Random Forest"}}