{"cell_type":{"e735116f":"code","cd7e29b4":"code","9d0dcada":"code","1b4d2ef9":"code","333ff3b4":"code","acf983d4":"code","1e09e487":"code","4ed6ced0":"code","a284aa92":"code","18aad918":"code","5bac097d":"code","71af0a27":"code","2d03a5da":"code","372496b3":"code","cf1246a8":"code","22feebc9":"code","656e4d06":"code","8e27243e":"code","1b8358e2":"code","9ba5d75a":"code","e568e553":"code","840e5f00":"code","320fdaed":"code","827c39dd":"code","7e98ec00":"code","0e538ca7":"code","3da36cc7":"code","9db586fd":"code","3bd670c8":"code","30cc373d":"code","54862de9":"code","65e30812":"code","c4c34e36":"code","1d7c601d":"code","81f41b9c":"code","ae2b117b":"code","27cf6d6d":"code","2c933200":"code","ff1b0247":"code","af885348":"code","4416e6b8":"code","d78e55f1":"code","84be30c3":"code","9ecbb765":"code","46de4e03":"code","25ceb837":"code","f105e271":"code","a991b50f":"code","cbca9331":"code","79776e2b":"markdown","ba4362a0":"markdown","5caea35a":"markdown","e0192409":"markdown","12cab3a6":"markdown","d1b71ff4":"markdown","12546392":"markdown"},"source":{"e735116f":"import pandas as pd\nimport nltk\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer","cd7e29b4":"df = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\n\ndf.head(5)","9d0dcada":"df['Name'] = df['text'] + ('_' + df['keyword']).fillna('')","1b4d2ef9":"df = df.drop(['id','keyword','location','text'], axis = 1)","333ff3b4":"df.shape[0]","acf983d4":"df.head(5)","1e09e487":"X = df.Name\ny = df.target","4ed6ced0":"X","a284aa92":"model = []\nfor i in range(0, df.shape[0]):\n    data = re.sub(r'\\W', ' ', str(X[i]))\n    data = data.lower()\n    #data = re.sub(r'\\s*http.*', '', data)\n    data = re.sub(r'^br$', ' ', data)\n    data = re.sub(r\"\u00fb\u00aa\", \"\", data)\n    data = re.sub(r\"\u00fb\", \"\", data)\n    data = re.sub(r\"\u00fb\u00ef\", \"\", data)\n    data = re.sub(r\"\u00fb_\", \"\", data)\n    data = re.sub(r\"\u00fb\u00f3\", \"\", data)\n    data = re.sub(r'^br$', ' ', data)\n    data = re.sub(r'\\s+br\\s+',' ',data)\n    data = re.sub(r'\\s+[a-z]\\s+', ' ',data)\n    data = re.sub(r'^b\\s+', '', data)\n    data = re.sub(r'\\s+', ' ', data)\n    model.append(data)    \n    ","18aad918":"model","5bac097d":"vector = TfidfVectorizer(max_features = 4000, min_df = 3, max_df = 0.5, stop_words = stopwords.words('english'))\nX = vector.fit_transform(model).toarray()","71af0a27":"X","2d03a5da":"X.shape[1]","372496b3":"vector.get_feature_names()","cf1246a8":"from sklearn.model_selection import train_test_split\ntext_train, text_test, sent_train, sent_test = train_test_split(X, y, test_size = 0.20, random_state = 42)","22feebc9":"from keras.models import Sequential\nfrom keras import layers\n\ninput_dim = text_train.shape[1]  # Number of features\n\nmodel = Sequential()\nmodel.add(layers.Dense(128, input_dim=input_dim, activation='relu'))\nmodel.add(layers.Dropout(0.7))\nmodel.add(layers.Dense(1, activation='sigmoid'))","656e4d06":"model.compile(loss='binary_crossentropy', \n               optimizer='adadelta', \n               metrics=['accuracy'])\nmodel.summary()","8e27243e":"history = model.fit(text_train, sent_train,\n                    epochs=20,\n                    verbose=False,\n                    batch_size=50,\n                    validation_data=(text_test, sent_test))\n                ","1b8358e2":"loss, accuracy = model.evaluate(text_train, sent_train, verbose=False)\nprint(\"Training Accuracy: {:.4f}\".format(accuracy))\nloss, accuracy = model.evaluate(text_test, sent_test, verbose=False)\nprint(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n","9ba5d75a":"text_train = X\nsent_train = y","e568e553":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\n\nlr.fit(text_train, sent_train)","840e5f00":"pred = lr.predict(text_test)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(sent_test, pred)","320fdaed":"print (\"Accuracy of test set\",accuracy_score(sent_test, pred)*100,\"%\")","827c39dd":"cm","7e98ec00":"X.shape[1]","0e538ca7":"from sklearn.naive_bayes import MultinomialNB\nclf_m = MultinomialNB(alpha = 2.0)","3da36cc7":"clf_m.fit(text_train, sent_train)","9db586fd":"pred = lr.predict(text_test)\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(sent_test, pred)","3bd670c8":"print (\"Accuracy of test set\",accuracy_score(sent_test, pred)*100,\"%\")","30cc373d":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators = 200, max_features = 'log2',verbose = 0)","54862de9":"%%time\n\nclf.fit(text_train, sent_train)\n\npred_new = lr.predict(text_test)","65e30812":"pred_new = lr.predict(text_test)","c4c34e36":"print (\"Accuracy of test set\",accuracy_score(sent_test, pred_new)*100,\"%\")","1d7c601d":"pred_new","81f41b9c":"from sklearn.datasets import make_classification\nfrom sklearn.ensemble import RandomForestClassifier\n# Build a classification task using 3 informative features\nX, Y = make_classification(n_samples=1000,\n                           n_features=10,\n                           n_informative=3,\n                           n_redundant=0,\n                           n_repeated=0,\n                           n_classes=2,\n                           random_state=0,\n                           shuffle=False)\n\n\nrfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n\nparam_grid = { \n    'n_estimators': [200, 700],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\nCV_rfc.fit(X, Y)\nprint(CV_rfc.best_params_)","ae2b117b":"test = pd.read_csv(r\"C:\\Users\\Kushagra's PC\\Desktop\\test.csv\")\n\ntest.head(5)","27cf6d6d":"test['Name'] = test['text'] + ('_' + test['keyword']).fillna('')","2c933200":"test = test.drop(['id','keyword','location','text'], axis = 1)","ff1b0247":"test.head()","af885348":"X_t = test.Name","4416e6b8":"X_t.shape[0]","d78e55f1":"model_new = []\nfor i in range(0, 3263):\n    data = re.sub(r'\\W', ' ', str(X_t[i]))\n    data = data.lower()\n    data = re.sub(r'\\s*http.*', '', data)\n    data = re.sub(r'^br$', ' ', data)\n    data = re.sub(r\"\u00fb\u00aa\", \"\", data)\n    data = re.sub(r\"\u00fb\", \"\", data)\n    data = re.sub(r\"\u00fb\u00ef\", \"\", data)\n    data = re.sub(r\"\u00fb_\", \"\", data)\n    data = re.sub(r\"\u00fb\u00f3\", \"\", data)\n    data = re.sub(r'^br$', ' ', data)\n    data = re.sub(r'\\s+br\\s+',' ',data)\n    data = re.sub(r'\\s+[a-z]\\s+', ' ',data)\n    data = re.sub(r'^b\\s+', '', data)\n    data = re.sub(r'\\s+', ' ', data)\n    model_new.append(data)    \n    ","84be30c3":"model_new","9ecbb765":"X_t = vector.transform(model_new).toarray()","46de4e03":"X_t","25ceb837":"X_t.shape[1]","f105e271":"pred = lr.predict(X_t)","a991b50f":"prediction  = pd.DataFrame(pred)\nprediction","cbca9331":"prediction.to_csv('result.csv')","79776e2b":"## Using Random forest","ba4362a0":"# MNB","5caea35a":"## GridSearch CV","e0192409":"## Deep Learning","12cab3a6":"## Using Logistic regression","d1b71ff4":"# DATA PREPROCESSING","12546392":"# Fitting in on test data set"}}