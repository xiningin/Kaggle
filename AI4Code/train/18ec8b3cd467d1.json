{"cell_type":{"6cb207f9":"code","4222bbd1":"code","b21f9966":"code","a10c20fa":"code","b8fd98ef":"code","0ec02571":"code","d2ee9c1e":"code","600c51a5":"code","2eedf5ac":"code","c97f311c":"code","9005ad77":"code","300b94f2":"code","4fbba71c":"markdown","2b0c3302":"markdown","120141fa":"markdown","79308e44":"markdown","8886bf3a":"markdown","3e127d6b":"markdown"},"source":{"6cb207f9":"import tensorflow as tf\nimport math\nx = tf.linspace(0.0,2.0*math.pi,360)\ny = tf.sin(x)","4222bbd1":"with tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.sin(x)\ndy_dx = tape.gradient(y,x)","b21f9966":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_theme()\nsns.lineplot(x,y,label = 'sin(x)')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","a10c20fa":"x = tf.linspace(0.0,100.0,100)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.pow(x,2)\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '${x^2}$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","b8fd98ef":"x = tf.linspace(0.0,100.0,100)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.math.log(x)\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$log(x)$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","0ec02571":"x = tf.linspace(0.0,2*math.pi,360)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.math.atan(x)\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$tan^{-1}(x)}$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","d2ee9c1e":"x = tf.linspace(-2*math.pi,2*math.pi,360)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.math.sqrt(tf.math.asin(x))\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$\\sqrt{sin^{-1}(x)}$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","600c51a5":"x = tf.linspace(-100.0,100.0,201)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.pow(x,x)\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$x^x$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","2eedf5ac":"x = tf.linspace(-2*math.pi,2*math.pi,360)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.math.sqrt(tf.math.tan(x))\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$\\sqrt{tan(x)}$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","c97f311c":"x = tf.linspace(-2*math.pi,2*math.pi,360)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.math.sqrt(tf.math.sigmoid(x))\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$sigmoid(x)$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","9005ad77":"x = tf.linspace(-4*math.pi,4*math.pi,200)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = tf.sin(x)\/x\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$sinc(x)$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","300b94f2":"x = tf.linspace(-100,100,200)\nwith tf.GradientTape() as tape:\n    tape.watch(x)\n    y = 1- tf.maximum(0.0, tf.sign(-x))\ndy_dx = tape.gradient(y,x)\nsns.lineplot(x,y,label = '$unit(x)$')\nsns.lineplot(x,dy_dx,label = '$dy\/dx$')","4fbba71c":"## Auto Differentiation in tensorFlow\n---\n\nTensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.","2b0c3302":"Lets see how this works on a simple function like $\\sin(x)$\n\nWe know that the \n\n## $\\frac{d}{dx}sin(x) = cos(x)$\n\nLets test this graph out using our gradient tape API","120141fa":"# Auto Differentiation\n\nIn computers we deal with finite sequences and quantities. Any operation that is performed by a machine is a combination of the basic arithmetic operations addition,substraction, multiplication and division. So its easy for computers to perform differentiation on a wide range of mathematical operations with less computational cost using various techniques. This is termed as auto differentiation. For more deatils you can refer to [this](https:\/\/en.wikipedia.org\/wiki\/Automatic_differentiation#:~:text=In%20mathematics%20and%20computer%20algebra,specified%20by%20a%20computer%20program) article.\n\nTensorflow comes with a pre built api called Gradient Tape. This api records the sequence of operations in a **\"tape\"** one after the other. This lets the api calculate the gradient of the losses in the back propagation step in the exact reverse sequence. I will demonstrate the use of the Gradient Tape api in simple terms on few well known functions and their diffrentiations. ","79308e44":"So here I have demonstrated the power of the graidient tape api and how it is able to fetch accurate results. ","8886bf3a":"The above example clearly shows us the differentiation of $sin(x)$ which is $cos(x)$. Lets try some other examples.","3e127d6b":"## Examples of Auto Differentiation using tensor flow\n---\n\nThe following functions and their differentiations will be plotted :-\n* $f(x) = x^2$\n* $f(x) = ln(x)$\n* $f(x) = tan^{-1}(x)$\n* $f(x) = \\sqrt {sin^{-1}(x)}$\n* $f(x) = x^x$\n* $f(x) = \\sqrt{tan(x)}$\n* $f(x) = sinc(x)$\n* $f(x) = sign(x)$\n* $f(x) = unit(x)$"}}