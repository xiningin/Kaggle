{"cell_type":{"777a496c":"code","b7c50d4e":"code","a36252b9":"code","f8173ee2":"code","09bac9bf":"code","193f6e64":"code","5576e83f":"code","5e454b8c":"code","1f522eda":"code","4331642f":"code","3931efb2":"code","63cdcd96":"code","526af405":"code","56242886":"code","2d70ef44":"code","f2338b45":"code","01a3772f":"code","03a17411":"code","da380218":"code","53f14873":"code","d2f6b491":"code","86c58446":"code","a31d5706":"code","06c1cc3d":"code","5fb5558f":"code","8378364a":"code","fed3abcf":"code","2ad9276c":"code","19b9ad8d":"code","5567b311":"code","931fc361":"code","a1a83082":"code","caa12c92":"markdown","8d0f218e":"markdown","c3a2baf1":"markdown","cb069463":"markdown","bbbc6918":"markdown","e08babe5":"markdown","521f273a":"markdown","3bc4457b":"markdown","ee8613b7":"markdown","190ba08b":"markdown","06f43e0b":"markdown","3cc6bbc7":"markdown","f12d1159":"markdown","49f170b0":"markdown"},"source":{"777a496c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as ms\n\n%matplotlib inline","b7c50d4e":"data = pd.read_csv('..\/input\/train.csv')","a36252b9":"data.head()","f8173ee2":"data.info()","09bac9bf":"data.describe()","193f6e64":"ms.matrix(data)","5576e83f":"def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n    # Categorical \n    pclass = pd.get_dummies(df['Pclass'], prefix = 'Pclass')\n    embarked = pd.get_dummies(df['Embarked'], prefix = 'embarked')\n    sex = pd.get_dummies(df['Sex'], prefix = 'Sex')   \n    \n    # Syntetic\n    family = df[['SibSp', 'Parch']].copy()\n\n    # Family size of relative abourd including passanger\n    family['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n\n    # IsAlone indicates no relatives on board\n    family['IsAlone'] = 1  \n    family['IsAlone'].loc[family['FamilySize'] > 1] = 0 \n\n    family.drop(['SibSp','Parch'],axis=1,inplace=True)\n    \n    # concat\n    df = pd.concat([df, pclass, sex, embarked, family], axis=1)\n\n    return df","5e454b8c":"data = feature_engineering(data)","1f522eda":"ms.matrix(data)","4331642f":"sns.heatmap(data.corr(),cmap='coolwarm')\nplt.title('data.corr()')","3931efb2":"X = data.drop('Survived',axis=1)\nY = data['Survived']","63cdcd96":"from sklearn.model_selection import train_test_split","526af405":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20)","56242886":"def clean_for_logistic_regression(df_X: pd.DataFrame, df_Y: pd.DataFrame, drop_rows: bool = False):\n    '''\n    Keep only numerical features.\n    When the whole row is removed from df_X, than corresponded row is also removed from df_Y\n    Impute age based on median of corresponded Pclass (improvements possible based on title in the name)\n    Impute Fare as median of existing fares (improvements possible based on Pclass, title, Embark)\n    Impute Embarked based on the most common value - mode\n\n    Keep only these features:\n        Age\tSibSp\tParch \n        Fare\n        Pclass_1\tPclass_2\tPclass_3\tSex_female\tSex_male\t\n        embarked_C\tembarked_Q\tembarked_S\n        FamilySize\tIsAlone\n    '''\n    features = ['Age', \n                'Sex_female', \n                'Sex_male', \n                'SibSp', \n                'Parch', \n                'FamilySize', \n                'IsAlone',\n                'Fare', \n                'Pclass', \n                'Pclass_1', \n                'Pclass_2', \n                'Pclass_3',\n                'embarked_C', \n                'embarked_Q', \n                'embarked_S'\n               ]\n    \n    df_X = df_X.copy()\n    \n    pclass_1_median_age = df_X['Age'].loc[df_X['Pclass_1'] == 1].median()\n    pclass_2_median_age = df_X['Age'].loc[df_X['Pclass_2'] == 1].median()     \n    pclass_3_median_age = df_X['Age'].loc[df_X['Pclass_3'] == 1].median() \n        \n    def impute_age(cols):\n        Age = cols[0]\n        Pclass = cols[1]\n\n        if pd.isnull(Age):\n            if Pclass == 1:\n                return pclass_1_median_age\n            elif Pclass == 2:\n                return pclass_2_median_age\n            else:\n                return pclass_3_median_age\n        else:\n            return Age\n    \n    df_X['Age'] = df_X[['Age', 'Pclass']].apply(impute_age, axis=1)\n    \n    df_X['Embarked'].fillna(df_X['Embarked'].mode()[0], inplace = True)\n    df_X['Fare'].fillna(df_X['Fare'].median(), inplace = True)\n    \n    df_X['SibSp'].fillna(0, inplace = True)\n    df_X['Parch'].fillna(0, inplace = True)\n    \n    df_X = df_X[features]\n    \n    return df_X, df_Y    ","2d70ef44":"X_train_lr, Y_train_lr = clean_for_logistic_regression(X_train, Y_train)\nX_test_lr, Y_test_lr = clean_for_logistic_regression(X_test, Y_test)\n","f2338b45":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver='lbfgs', max_iter=1000)\nmodel.fit(X_train_lr,Y_train_lr)","01a3772f":"Y_hat_test_lr = model.predict(X_test_lr)","03a17411":"import operator\n\ncoef = list(zip(X_test_lr.columns.values, model.coef_[0]))\nsorted(coef, key=operator.itemgetter(1), reverse=True)","da380218":"## Confusion Matrix","53f14873":"from sklearn.metrics import confusion_matrix, classification_report","d2f6b491":"print(confusion_matrix(Y_test_lr, Y_hat_test_lr))","86c58446":"print(classification_report(Y_test_lr,Y_hat_test_lr))","a31d5706":"prediction_data = pd.read_csv('..\/input\/test.csv')","06c1cc3d":"prediction_data.head()","5fb5558f":"ms.matrix(prediction_data)","8378364a":"prediction_data = feature_engineering(prediction_data)","fed3abcf":"ms.matrix(prediction_data)","2ad9276c":"X_prediction_lr, Y_prediction_lr = clean_for_logistic_regression(prediction_data, None)\n","19b9ad8d":"ms.matrix(X_prediction_lr)","5567b311":"Y_prediction_lr = model.predict(X_prediction_lr)","931fc361":"prediction_data['Survived'] = Y_prediction_lr\nsubmit = prediction_data[['PassengerId','Survived']]\n\nsubmit.head()","a1a83082":"submit.to_csv(\"..\/working\/submit.csv\", index=False)","caa12c92":"## convert categorical values\n\n### Pclass \nPclass could be as one feature with a number of a class or it could be a different features for each distinct value\n\n### Sex\nSex need to be a boolean value female\n\n### Embarked\nEmbarked need to be a one feature for each embarked distinct value.\nNote: research impact of removing one particular of embarked value because it is calculable from all others\n\n## Syntetic features\nFamilySize of relative abourd including passanger.\nIsAlone indicates no relatives on board","8d0f218e":"# Step - 1 : Frame The Problem\n\n## TODO:\n* Try using PClass as a numerical and categorical feature within the same model\n* Three variable layers \n    * list of all features including synthetic like PClass as a separate features, \n    * list of different algos\n    * list of different voting schemas\n    * pick one which provides the best prediction for particular passenger\n\n\n","c3a2baf1":"# Step - 6 : Evaluation","cb069463":"# Step - 7 : Predict on New Cases","bbbc6918":"## Train Test Split","e08babe5":"# Step - 4 : Feature Engineering","521f273a":"## Coefficients \nThe most biggest impact for survival were being female, first class and embarked from Cherbourg ","3bc4457b":"## Display corelations between features","ee8613b7":"### LogisticRegression","190ba08b":"# Step - 2 : Obtain the Data","06f43e0b":"## Building a model","3cc6bbc7":"# Step - 3 : Analyse the Data","f12d1159":"# Step - 5 : Model Selection","49f170b0":"data contains features which could not be used with specific models (e.g. null values are not acceptable for LogisticRegression.\nDefining a function which cleans data for specific model"}}