{"cell_type":{"28d8204b":"code","9f80f02f":"code","533b7211":"code","7616d2f8":"code","6c0a93e9":"code","5e99667d":"code","7fc8dfcd":"code","adf493cb":"code","4df99d3f":"code","4c93df6d":"code","f69e06a2":"code","15dd1e12":"markdown","ec88c10b":"markdown","4833e8b1":"markdown","ce5e44e2":"markdown","163a707b":"markdown"},"source":{"28d8204b":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport bq_helper\n\npatents_helper = bq_helper.BigQueryHelper(\n    active_project=\"patents-public-data\",\n    dataset_name=\"patents\"\n)","9f80f02f":"# A list of patents we care about. In this case we're going to manually enter a set of patents related to codecs.\ninput_patents = [\n    'US-7292636-B2',\n    'US-6115503-A',\n    'US-6812873-B1',\n    'US-6825782-B2',\n    'US-6850175-B1',\n    'US-6934331-B2',\n    'US-6967601-B2',\n    'US-7068721-B2',\n    'US-7183951-B2',\n    'US-7190289-B2',\n    'US-7199836-B1',\n    'US-7298303-B2',\n    'US-7310372-B2',\n    'US-7339991-B2',\n    'US-7346216-B2',\n    'US-7474699-B2',\n]\n# Converts input list into a string for use in queries.\ninput_patents_str = '(' + str(input_patents)[1:-1] + ')'\ninput_patents_str","533b7211":"query = '''\n#standardSQL\nSELECT DISTINCT cpc_code \nFROM (\n    SELECT\n    publication_number,\n    c.code as cpc_code\n\n    FROM `patents-public-data.patents.publications`\n    ,UNNEST(cpc) as c\n\n    where publication_number in {}\n)\n'''.format(input_patents_str)\n\nall_cpcs = patents_helper.query_to_pandas(query=query)\n# Convert into helper string for limiting CPCs\nall_cpcs_str = '(' + str(list(all_cpcs.cpc_code.values))[1:-1] + ')'","7616d2f8":"# Get sample of patents not in our input set, but sharing at least 1 cpc.\nquery = '''\nSELECT DISTINCT publication_number\nFROM `patents-public-data.patents.publications`\n,UNNEST(cpc) as cpc\nwhere publication_number not in {}\nand cpc.code in {}\nand rand() < 0.2\nlimit 100\n'''.format(input_patents_str, all_cpcs_str)\nshared_cpc = patents_helper.query_to_pandas_safe(query, max_gb_scanned=5)\nshared_cpc.loc[:, 'source'] = 'shared_cpc'\nshared_cpc.head()","6c0a93e9":"# Get sample of 100 random patents not sharing any CPC's.\nquery = '''\nSELECT DISTINCT publication_number\nFROM `patents-public-data.patents.publications`\n,UNNEST(cpc) as cpc\nwhere publication_number not in {}\nand cpc.code not in {}\nand rand() < 0.2\nlimit 100\n'''.format(input_patents_str, all_cpcs_str)\nno_shared_cpc = patents_helper.query_to_pandas_safe(query, max_gb_scanned=5)\nno_shared_cpc.loc[:, 'source'] = 'no_shared_cpc'\nno_shared_cpc.head()","5e99667d":"# Pull all the \"similar patents\" from Patents Research dataset.\n# Each of our patents in the input list should have ~25 similar patents listed, so we get back 12*25 rows\nquery = '''\nSELECT distinct\ns.publication_number\n\nFROM `patents-public-data.patents.publications` p\nJOIN `patents-public-data:google_patents_research.publications` r\n  on p.publication_number = r.publication_number\n, UNNEST(similar) as s\nwhere p.publication_number in {}\n'''.format(input_patents_str)\nsimilar = patents_helper.query_to_pandas_safe(query, max_gb_scanned=36)\nsimilar.loc[:, 'source'] = 'similar_to_input'\nprint(len(similar))","7fc8dfcd":"# Lets constuct our dataframe by concatenating our input list, the close negatives and \n# the list of \"similar patents\" according to the patents research table.\ndf = pd.DataFrame(input_patents, columns=['publication_number'])\ndf.loc[:, 'source'] = 'input'\ndf = pd.concat(\n    [df, similar, shared_cpc, no_shared_cpc]).drop_duplicates('publication_number', keep='first')\ndf.source.value_counts()","adf493cb":"all_patents_str = '(' + str(list(df.publication_number.unique()))[1:-1] + ')'\nquery = r'''\nCREATE TEMPORARY FUNCTION convert_embedding_to_string(embedding ARRAY<FLOAT64>)\nRETURNS STRING\nLANGUAGE js AS \"\"\"\nlet embedding_str = ''\nfor (i = 0; i < embedding.length; i++) { \n  embedding_str += embedding[i].toFixed(6) + ',';\n} \nreturn embedding_str\n\"\"\"; \n\nSELECT \npublication_number,\nconvert_embedding_to_string(embedding_v1) embedding\nFROM `patents-public-data.google_patents_research.publications` \nwhere publication_number in %s\n''' % (all_patents_str)\n\nresults = patents_helper.query_to_pandas_safe(query, max_gb_scanned=50).drop_duplicates('publication_number')\n# Put the string embedding into 64 float cols.\nembeddings = pd.DataFrame(\n    data=[e for e in results.embedding.apply(lambda x: x.split(',')[:64]).values],\n    columns = ['x{}'.format(i) for i in range(64)],\n    index=results.publication_number\n)\nembeddings = embeddings.astype(float).reset_index()\nembeddings.head()","4df99d3f":"# Merge the embeddings into the dataframe.\ndf = df.merge(embeddings, on='publication_number').drop_duplicates('publication_number')\ndf.head()","4c93df6d":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(df.iloc[:, 2:].values)\npca_df = pd.DataFrame(\n    data = principal_components\n    ,columns = ['principal component 1', 'principal component 2']\n)\n\nplot_df = pd.concat([pca_df, df[['source']]], axis = 1)","f69e06a2":"fig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = plot_df.source.unique()\ncolors = ['r', 'g', 'b', 'y']\nfor source, color in zip(targets,colors):\n    indicesToKeep = plot_df['source'] == source\n    ax.scatter(plot_df.loc[indicesToKeep, 'principal component 1']\n               , plot_df.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 12)\nax.legend(targets)\nax.grid()","15dd1e12":"## Next, we'll run PCA on the 64 dimensional embeddings - converting them into a 2-D vector for ease of plotting. ","ec88c10b":"# Plotting Similar Patents with Google Patents Public Data\n- In this notebook, we'll walk through how to use publicly available patent embeddings, similar patents and other data to visualize patents near some set of input patents.\n\n## Overview\n- We'll set an input list of patents and use these to a few additional sets of patents including 1) The 25 most similar patents to each of those in our input list. 2) A set of 100 patents with shared CPC's and 3) A set of 100 patents which have no CPC overlap. \n- Next we'll pull a patent embedding from the Google Patents Research Dataset\n- Finally, we'll run PCA to convert the 64 digit embedding in a 2D vector for plotting.","4833e8b1":"Note on embeddings - the Patents research table has a repeated field which contains a patent embedding. To use this in python, we need to extract the repeated value as a joined string - hence the javascript UDF below.","ce5e44e2":"Copyright 2019 Google LLC.","163a707b":"## Dataset Construction\nHere we need to do some data wrangling. We could either write one big query, or do things step by step in python. Its easier to follow in python, so I'm going to do it iteratively as follows:\n1. First I'm going to pull the list of all CPC codes covered by our input list (including non-inventive). This will be used for getting a sample of other patents which are related but not exactly the same as our input set.\n2. Get the list of most similar patents for each of the patents in our input set. This comes from the table `patents-public-data.google_patents_research.publications`\n4. For all patents in our set, get the 64 digit patent embedding from the `patents-public-data.google_patents_research.publications` table.\n3. Run PCA to convert our 64 digit embedding into 2 dimensions and plot our similar patents against the larger random sample from shared CPC's. "}}