{"cell_type":{"b62c9400":"code","4851ecb3":"code","332b9e17":"code","41880531":"code","cc09a4ea":"code","b035126a":"code","c3f8617c":"code","da9cafec":"code","83f154b3":"code","734a7899":"code","a4600600":"code","8f588521":"code","e4eaf92b":"code","294a6590":"code","9e188cdc":"code","da1d614e":"code","46858b93":"code","714f402e":"code","d1317618":"code","b788b6fd":"markdown","b255f5ec":"markdown","1c0b0c77":"markdown","390d34ce":"markdown","28577192":"markdown","1f7ad8ff":"markdown","e0b71b0d":"markdown","8d82b8e0":"markdown","2e7db7e1":"markdown","cdfa588b":"markdown","a163779a":"markdown","bb066bff":"markdown","5e4ba1e5":"markdown","190bd26c":"markdown","22d0ddce":"markdown","899949ed":"markdown","e6ef7e10":"markdown"},"source":{"b62c9400":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4851ecb3":"building_df = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/building_metadata.csv\")\nprint(building_df.shape)\nbuilding_df.head()","332b9e17":"building_df.describe()","41880531":"building_df.dtypes","cc09a4ea":"building_df.isna().sum() \/ building_df.shape[0]","b035126a":"building_df['site_id'] = building_df['site_id'].astype(np.uint8)\nbuilding_df['building_id'] = building_df['building_id'].astype(np.uint16)\nbuilding_df['square_feet'] = building_df['square_feet'].astype(np.uint32)\nbuilding_df.dtypes","c3f8617c":"cat_columns = ['site_id', 'primary_use']\nplt.figure(figsize=(15, 5))\nfor ind, col in enumerate(cat_columns):\n    plt.subplot(1, len(cat_columns), ind+1)\n    plt.title(col)\n    building_df[col].value_counts(sort=False).plot(kind='bar')","da9cafec":"plt.figure(figsize=(10,5))\ny = building_df['year_built'].value_counts(sort=False)\nplt.title('year_built')\nplt.xticks(rotation=45)\ny.index = pd.to_datetime(y.index.astype(int), format='%Y')\ny = y.sort_index()\nplt.grid()\nplt.plot(y)\ndel y","83f154b3":"le = LabelEncoder()\nbuilding_df[\"primary_use_enc\"] = le.fit_transform(building_df[\"primary_use\"]).astype(np.uint8)","734a7899":"plt.figure(figsize=(6,6))\nsns.heatmap(building_df.corr(), square=True, annot=True)","a4600600":"plt.figure(figsize=(5, 5))\nplt.xlabel('square_feet')\nplt.ylabel('floor_count')\nX = building_df[pd.notnull(building_df['floor_count'])]\nplt.scatter(np.log1p(X['square_feet']), X['floor_count'])\ndel X","8f588521":"weather_train = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/weather_train.csv\")\nprint(weather_train.shape)\nweather_train.head()","e4eaf92b":"weather_train.describe()","294a6590":"weather_train.dtypes","9e188cdc":"weather_train.isna().sum() \/ weather_train.shape[0]","da1d614e":"float_cols = ['air_temperature', 'cloud_coverage', 'dew_temperature',\n        'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']","46858b93":"weather_train['site_id'] = weather_train['site_id'].astype(np.uint8)\nweather_train['timestamp'] = pd.to_datetime(weather_train['timestamp'])\nfor i in float_cols:\n    weather_train[i] = weather_train[i].astype(np.float32)\nweather_train.dtypes","714f402e":"plt.figure(figsize=(8, 8))\nsns.heatmap(weather_train.corr(), square=True, annot=True)","d1317618":"tmp = weather_train[weather_train['site_id'] == 0]\nplt.figure(figsize=(20, 15))\nfor ind, col in enumerate(float_cols):\n    plt.subplot(4, 2, ind + 1)\n    plt.xticks(rotation=30)\n    plt.grid()\n    plt.title(col)\n    plt.plot(tmp['timestamp'], tmp[col])","b788b6fd":"Load data and describe it a bit","b255f5ec":"For year_build we can use simple plot, and see how many building was build in each year","1c0b0c77":"Missed Data Percentage","390d34ce":"Check correlations between features ","28577192":"Let's look at the distribution of data on various features. For the site_id and primary_use, you can use the bar plot","1f7ad8ff":"# building_metadata.csv exploration","e0b71b0d":"Check data types of our columns. Many columns have a larger data type than they should:","8d82b8e0":"# Introduction\nHello  \nThis is my first attempt at exploratory data analysis. In this notebook, I would like to try to describe the data of the current competition, to find oddities and patterns in the data.  \nI will be glad to advice and comments!)","2e7db7e1":"Load data and describe it a bit","cdfa588b":"We set a smaller data type for columns that do not have missing values (we will work with the remaining columns later)","a163779a":"# weather_train.csv exploration","bb066bff":"Let's convert prinary_use column to the number:","5e4ba1e5":"And create correlation matrix for our data. As we can see squeree_feet and floor_count is correlate well. This fact may be useful in recovering missing values for the number of floors.","190bd26c":"Change dtypes of the columns","22d0ddce":"Let's see the dependence of the number of floors on the logarithm of the area","899949ed":"### more later...","e6ef7e10":"Missed data percentage"}}