{"cell_type":{"6c24e1e3":"code","7b5d9d0f":"code","4fdced5e":"code","ad0daf66":"code","f05bb68b":"code","6669f894":"code","6fd46439":"code","f99e9d0c":"code","48970e6b":"code","0f86658d":"code","7245b7ec":"code","8cdc9ea1":"code","e0c3428d":"code","5d2813cd":"code","1874795a":"code","519bf2a8":"code","7bbd40ac":"code","a0440f89":"code","2e115556":"code","d428c072":"code","69ac3323":"code","8d8b8e0a":"code","3fd2372e":"code","5de71ee1":"code","4b46cf5a":"code","2484518e":"code","d1e9f713":"code","e7b39cdc":"code","54a4d7b2":"code","41ed1abb":"markdown","5218ce82":"markdown","5fa21d2a":"markdown","e60a7402":"markdown","29dd10a6":"markdown","03627696":"markdown","d3e04d77":"markdown","d712a9a0":"markdown","845e395f":"markdown","4f789a5f":"markdown","63c1efba":"markdown","46e474cb":"markdown","dca29311":"markdown"},"source":{"6c24e1e3":"!pip install allennlp==1.0.0rc3 allennlp-models==1.0.0rc3","7b5d9d0f":"!pip install text2text","4fdced5e":"# --------------------------------------------------\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport re\nfrom typing import List\nfrom enum import Enum\nfrom pprint import pprint, pformat\nimport warnings\n# --------------------------------------------------\n# For Reproducibility - setting the random seed\nimport random\nimport IPython\nimport subprocess\n# --------------------------------------------------\n# For SRL and OpenIE\nfrom allennlp.predictors.predictor import Predictor\nimport allennlp_models.syntax.srl\n# --------------------------------------------------\n# GPU check & used by allennlp\nimport torch\n# --------------------------------------------------","ad0daf66":"MODALS = [\"will\", \"may\", \"can\", \"must\", \"shall\", \"might\", \"should\", \"could\", \"would\"]","f05bb68b":"class SRL_TAGS(Enum):\n    \"\"\"\n    > The Arg0 label is assigned to arguments which are understood as agents, causers, or experiencers. \n    > The Arg1 label is usually assigned to the patient argument, \n    > i.e. the argument which undergoes the change of state or is being affected by the action.  \n    \n    > Frameset leave.01 \"move away from\":\n    >     Arg0: entity leaving\n    >     Arg1: place left\n\n    > Frameset leave.02 \"give\":\n    >     Arg0: giver\n    >     Arg1: thing given \n    >     Arg2: beneficiary\n    \n    > In general, if an argument satisfies two roles, \n    > the highest ranked argument label should be selected, \n    > where Arg0 >> Arg1 >> Arg2>>... .\n    \n    > 1.4.13 Modals (MOD)\n    > Modals are: will, may, can, must, shall, might, should, could, would.\n    > These elements are consistently labeled in the TreeBank as \u2018MOD.\u2019\n    > These are one of the few elements that are selected and tagged directly on the modal word itself,\n    > as opposed to selecting a higher node that contains the lexical item.\n\n    References:\n    * https:\/\/github.com\/allenai\/allennlp-models\/blob\/d2b50dff8daa40afb577feea0a9778c3438fdbe2\/test_fixtures\/syntax\/srl\/serialization\/vocabulary\/labels.txt\n    * https:\/\/catalog.ldc.upenn.edu\/docs\/LDC2007T21\/propbank\/english-propbank.pdf\n    * https:\/\/www.aclweb.org\/anthology\/J05-1004\/\n    * https:\/\/www.aclweb.org\/anthology\/W12-4501\/\n    * https:\/\/www.aclweb.org\/anthology\/P15-4009\/    \n    \"\"\"\n    NO_TAG=\"O\"\n\n    BEGIN_VERB=\"B-V\"\n    VERB=\"V\"\n\n    BEGIN_AGENT=BEGIN_ARG0=\"B-ARG0\"\n    INTERM_AGENT=INTERM_ARG0=\"I-ARG0\"\n    AGENT=ARG0=\"ARG0\"\n\n    BEGIN_PATIENT=BEGIN_ARG1=\"B-ARG1\"\n    INTERM_PATIENT=INTERM_ARG1=\"I-ARG1\"\n    PATIENT=ARG1=\"ARG1\"\n\n    BEGIN_ARG2=\"B-ARG2\"\n    INTERM_ARG2=\"I-ARG2\"\n    ARG2=\"ARG2\"\n\n    BEGIN_ARG3=\"B-ARG3\"\n    INTERM_ARG3=\"I-ARG3\"\n    ARG3=\"ARG3\"\n\n\n    ARG4=\"ARG4\"\n\n    \n    ARGM_ADJ=\"ARGM-ADJ\"\n    \n    \n    ARGM_EXT=\"ARGM-EXT\"\n\n\n    C_ARG0=\"C-ARG0\"\n    C_ARG1=\"C-ARG1\"\n    C_ARG2=\"C-ARG2\"\n\n    ARGM_LOC=\"ARGM-LOC\"\n\n    ARGM_PNC=\"ARGM-PNC\"\n\n    ARGM_CAU=\"ARGM-CAU\"\n\n    ARGM_DIR=\"ARGM-DIR\"\n\n    ARGM_LVB=\"ARGM-LVB\"\n\n    ARGM_COM=\"ARGM-COM\"\n    R_ARG3=\"R-ARG3\"\n    ARGM_REC=\"ARGM-REC\"\n    ARG5=\"ARG5\"\n    C_ARGM_MNR=\"C-ARGM-MNR\"\n\n\n    R_ARGM_TMP=\"R-ARGM-TMP\"\n\n    R_ARGM_CAU=\"R-ARGM-CAU\"\n\n\n    BEGIN_TEMPORAL_MARKER=\"B-ARGM-TMP\"\n    INTERM_TEMPORAL_MARKER=\"I-ARGM-TMP\"\n    TEMPORAL=TEMPORAL_MARKER=ARG_TMP=\"ARGM-TMP\"\n\n    # Transition words like \"But\" or \"Also\" or \"However\"\n    # Could also be a name like \"Vince\" >> e.g. \"I aint kidding you, Vince.\"\n    BEGIN_DISCOURSE_MARKER=\"B-ARGM-DIS\"\n    INTERM_DISCOURSE_MARKER=\"I-ARGM-DIS\"\n    DISCOURSE=DISCOURSE_MARKER=ARGM_DIS=\"ARGM-DIS\"\n\n    BEGIN_NEGATION_MARKER=\"B-ARGM-NEG\"\n    NEGATION=NEGATION_MARKER=ARGM_NEG=\"ARGM-NEG\"\n\n    # Modals are: will, may, can, must, shall, might, should, could, would\n    # It may be useful to enforce this by `assert` statements in code\n    # sometimes the SRL Predictor tags \"can\" as \"VERB\" when it should be MOD\n    # but BE CAREFUL.. it is possible \"to can\" and \"to be canned\"\n    BEGIN_MODAL=\"B-ARGM-MOD\"\n    MODAL=MODAL_MARKER=ARGM_MOD=\"ARGM-MOD\"\n\n    BEGIN_MANNER_MARKER=\"B-ARGM-MNR\"\n    INTERM_MANNER_MARKER=\"I-ARGM-MNR\"\n    MANNER=MANNER_MARKER=ARGM_MNR=\"ARGM-MNR\"\n\n    BEGIN_ADVERBIAL_MARKER=\"B-ARGM-ADV\"\n    INTERM_ADVERBIAL_MARKER=\"I-ARGM-ADV\"\n    ADVERBIAL=ADVERBIAL_MARKER=ARGM_ADV=\"ARGM-ADV\"\n\n    BEGIN_PURPOSE_MARKER=\"B-ARGM-PRP\"\n    INTERM_PURPOSE_MARKER=\"I-ARGM-PRP\"\n    PURPOSE=PURPOSE_MARKER=ARGM_PRP=\"ARGM-PRP\"\n\n    BEGIN_GOAL_MARKER=BEGIN_ARGM_GOL=\"B-ARGM-GOL\"\n    INTERM_GOAL_MARKER=INTERM_ARGM_GOL=\"I-ARGM-GOL\"\n    GOAL=GOAL_MARKER=ARGM_GOL=\"ARGM-GOL\"\n\n    BEGIN_REFERENTIAL_AGENT=BEGIN_R_ARG0=\"B-R-ARG0\"\n    REF_AGENT=REFERENTIAL_AGENT=R_ARG0=\"R-ARG0\"\n\n    BEGIN_REFERENTIAL_PATIENT=BEGIN_R_ARG1=\"B-R-ARG1\"\n    REF_PATIENT=REFERENTIAL_PATIENT=R_ARG1=\"R-ARG1\"\n\n    BEGIN_REFERENTIAL_ARG2=BEGIN_R_ARG2=\"B-R-ARG2\"\n    R_ARG2=\"R-ARG2\"\n    \n    R_ARGM_MNR=\"R-ARGM-MNR\"\n\n\n    R_ARGM_LOC=\"R-ARGM-LOC\"\n\n\n    # > Pierre Vinken , 61 years old , \n    # > will join the board as a nonexecutive director Nov. 29 . \n    # ARG0: Pierre Vinken , 61 years old ,\n    # ARGM-MOD: will\n    # REL: join\n    # ARG1: the board\n    # ARGM-PRD: as a nonexecutive director\n    # ARGM-TMP: Nov. 29\n    PREDICATE_MODIFIER=ARGM_PRD=\"ARGM-PRD\"","6669f894":"!ls \/kaggle\/input\/syllabus-corpus","6fd46439":"MY_SEED = 42\nBERT_SRL_MODEL = \"https:\/\/storage.googleapis.com\/allennlp-public-models\/bert-base-srl-2020.03.24.tar.gz\"\nOPEN_IE_MODEL = \"https:\/\/storage.googleapis.com\/allennlp-public-models\/openie-model.2020.03.26.tar.gz\"\nCSV_FILE = \"\/kaggle\/input\/syllabus-corpus\/corpus_sents.csv\"\nSENTENCE_COL = \"nlp_data.sent_data.sent\"\nVERB_COL = \"nlp_data.sent_data.verb\"\nSUBJECT_COL = \"nlp_data.sent_data.subject\"\nOBJECT_COL = \"nlp_data.sent_data.object\"\nSRL_COL = \"srl\"\nSRL_VERBS_COL = f\"{SRL_COL}.verbs\"\nSRL_LIST_COL = f\"{SRL_COL}_list\"\nOPEN_IE_COL = \"openie\"\n# use torch to get GPU device\nif torch.cuda.is_available():\n    DEVICE = torch.cuda.current_device()\nelse:\n    DEVICE = -1  # https:\/\/docs.allennlp.org\/v1.0.0rc4\/api\/predictors\/predictor\/#from_path","f99e9d0c":"# --------------------------------------------------\n# set random seeds\ntorch.manual_seed(MY_SEED)\n# transformers.set_seed(MY_SEED)\nrandom.seed(MY_SEED)\nnp.random.seed(MY_SEED)\n# tf.random.set_seed(MY_SEED)\n# --------------------------------------------------\n\n# --------------------------------------------------\n# print system information (but not packages)\nprint(\"=====\"*10)\nprint(\"IPython.sys_info()\")\nprint(IPython.sys_info())\nprint(\"=====\"*10)\n\n# get module information\n!pip freeze > frozen-requirements.txt\n\n# append system information to file\nwith open(\"IPython.sys_info.txt\", \"w\") as file:\n    file.write(IPython.sys_info())\n# --------------------------------------------------\n\n# --------------------------------------------------\n# Check CPU\nprint(\"=====\"*10)\nprint(\"CPU\")\nprint((subprocess.check_output(\"lscpu\", shell=True).strip()).decode())\nprint(\"=====\"*10)\n# --------------------------------------------------\n\n# --------------------------------------------------\n# Check GPU\nprint(\"=====\"*10)\nprint(\"GPU\")\ngpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n      print('Settings >> Accelerator >> GPU')\nelse:\n      print(gpu_info)\nprint(\"=====\"*10)\n# --------------------------------------------------","48970e6b":"srl_predictor = Predictor.from_path(BERT_SRL_MODEL, cuda_device=DEVICE)","0f86658d":"srl_predictor.predict(\n  sentence=\"Did Uriah honestly think he could beat the game in under three hours?\"\n)","7245b7ec":"openie_predictor = Predictor.from_path(OPEN_IE_MODEL, cuda_device=DEVICE)","8cdc9ea1":"openie_predictor.predict(\n  sentence=\"John decided to run for office next month.\"\n)","e0c3428d":"df = pd.read_csv(CSV_FILE)","5d2813cd":"df.columns","1874795a":"mask = [\n    \"Position\",\n#     \"SERP Title\",\n    \"URL\",\n#     \"Hostname\",\n#     \"SERP Description\",\n#     \"Word Count\",\n    \"filename\",\n#     \"first_50_entities\",\n#     \"semistructured_statements\",\n#     \"first_50_bigrams_with_min_freq_2\",\n#     \"first_50_trigrams\",\n#     \"top_10_textrank_key_terms\",\n#     \"top_10_singlerank_key_terms\",\n#     \"top_10_positionrank_key_terms\",\n#     \"top_10_yake_key_terms\",\n#     \"top_10_scake_key_terms\",\n#     \"doc_n_sents\",\n#     \"doc_n_words\",\n#     \"doc_n_chars\",\n#     \"doc_n_syllables\",\n#     \"doc_n_unique_words\",\n#     \"doc_n_long_words\",\n#     \"doc_n_monosyllable_words\",\n#     \"doc_n_polysyllable_words\",\n#     \"doc_flesch_kincaid_grade_level\",\n#     \"doc_flesch_reading_ease\",\n#     \"doc_smog_index\",\n#     \"doc_gunning_fog_index\",\n#     \"doc_coleman_liau_index\",\n#     \"doc_automated_readability_index\",\n#     \"doc_lix\",\n#     \"doc_gulpease_index\",\n    \"nlp_data.id\",\n    \"nlp_data.sent_data.id\",\n    \"nlp_data.sent_data.sent\",\n    \"nlp_data.sent_data.subject\",\n    \"nlp_data.sent_data.verb\",\n    \"nlp_data.sent_data.object\",\n#     \"nlp_data.sent_data.n_chars\",\n#     \"nlp_data.sent_data.n_long_words\",\n#     \"nlp_data.sent_data.n_monosyllable_words\",\n#     \"nlp_data.sent_data.n_polysyllable_words\",\n#     \"nlp_data.sent_data.n_sents\",\n#     \"nlp_data.sent_data.n_syllables\",\n#     \"nlp_data.sent_data.n_unique_words\",\n#     \"nlp_data.sent_data.n_words\",\n#     \"nlp_data.sent_data.automated_readability_index\",\n#     \"nlp_data.sent_data.coleman_liau_index\",\n#     \"nlp_data.sent_data.flesch_kincaid_grade_level\",\n#     \"nlp_data.sent_data.flesch_reading_ease\",\n#     \"nlp_data.sent_data.gulpease_index\",\n#     \"nlp_data.sent_data.gunning_fog_index\",\n#     \"nlp_data.sent_data.lix\",\n#     \"nlp_data.sent_data.smog_index\",\n#     \"nlp_data.sent_data.wiener_sachtextformel\",\n]","519bf2a8":"df = df[mask]\ndf.head()","7bbd40ac":"def _get_srl_given_predictor(sentence, predictor):\n    return predictor.predict(\n        sentence=sentence\n    )\n\ndef _get_srl_with_global_predictor(sentence):\n    return _get_srl_given_predictor(sentence, srl_predictor)\n\n\ndef _get_openie_given_predictor(sentence, predictor):\n    return predictor.predict(\n        sentence=sentence\n    )\n\ndef _get_openie_with_global_predictor(sentence):\n    return _get_openie_given_predictor(sentence, openie_predictor)","a0440f89":"i = 0\ndef _with_count(fun, N=None):\n    def _fun(x): global i; i = i + 1; print(f\"{i}\/{N}\", end=\"\\r\"); return fun(x)\n    return _fun\n\nN=len(df)\ndf[SRL_COL] = df[SENTENCE_COL].apply(_with_count(_get_srl_with_global_predictor, N))","2e115556":"i = 0\ndef _with_count(fun, N=None):\n    def _fun(x): global i; i = i + 1; print(f\"{i}\/{N}\", end=\"\\r\"); return fun(x)\n    return _fun\n\nN=len(df)\ndf[OPEN_IE_COL] = df[SENTENCE_COL].apply(_with_count(_get_openie_with_global_predictor, N))","d428c072":"df.columns","69ac3323":"df.to_csv(\"facts.csv\", index=False)\ndf = pd.read_csv(\"facts.csv\")","8d8b8e0a":"df[df[VERB_COL].notna()].groupby(\"Position\").agg(tuple)","3fd2372e":"# need to run eval on the serialized dictionaries\n# to use them as dicts instttead of strings\n# after the read_csv\ndf[SRL_COL] = df[SRL_COL].apply(eval)","5de71ee1":"!ls -lah","4b46cf5a":"def make_srl_list(words: List[str], tags: List[str]) -> List[List[str]]:\n    \"\"\"\n    modifed from \n    https:\/\/github.com\/allenai\/allennlp-models\/blob\/d21af08f90dfbeb1df9410adeec8b1503cfb82d5\/allennlp_models\/syntax\/srl\/srl_predictor.py#L78\n    \"\"\"\n    frame = []\n    chunk = []\n\n    for (token, tag) in zip(words, tags):\n        if tag.startswith(\"I-\"):\n            chunk.append(token)\n        else:\n            if chunk:\n                # frame.append(\"[\" + \" \".join(chunk) + \"]\")\n                frame.append(chunk)\n                chunk = []\n\n            if tag.startswith(\"B-\"):\n                # chunk.append(tag[2:] + \": \" + token)\n                chunk.append(tag[2:])\n                chunk.append(token)\n            elif tag == \"O\":\n                frame.append(token)\n\n    if chunk:\n        # frame.append(\"[\" + \" \".join(chunk) + \"]\")\n        frame.append(chunk)\n\n    return frame\n\n\n\ndef make_custom_srl_dict(words: List[str], tags: List[str]) -> dict:\n    \"\"\"\n    modifed from \n    https:\/\/github.com\/allenai\/allennlp-models\/blob\/d21af08f90dfbeb1df9410adeec8b1503cfb82d5\/allennlp_models\/syntax\/srl\/srl_predictor.py#L78\n    \"\"\"\n    frame = []\n    chunk = []\n\n    verbs = SRL_TAGS.VERB.value\n    agents = SRL_TAGS.AGENT.value\n    patients = SRL_TAGS.PATIENT.value\n    temporals = SRL_TAGS.TEMPORAL.value\n    negations = SRL_TAGS.NEGATION.value\n\n    arg2 = SRL_TAGS.ARG2.value\n    arg3 = SRL_TAGS.ARG3.value\n    arg4 = SRL_TAGS.ARG4.value\n    arg5 = SRL_TAGS.ARG5.value\n    \n    argm_adj = SRL_TAGS.ARGM_ADJ.value\n    argm_ext = SRL_TAGS.ARGM_EXT.value\n    argm_loc = SRL_TAGS.ARGM_LOC.value\n    argm_pnc = SRL_TAGS.ARGM_PNC.value\n    argm_cau = SRL_TAGS.ARGM_CAU.value\n    argm_dir = SRL_TAGS.ARGM_DIR.value\n    argm_lvb = SRL_TAGS.ARGM_LVB.value\n    argm_com = SRL_TAGS.ARGM_COM.value\n    argm_rec = SRL_TAGS.ARGM_REC.value\n    \n    c_arg0 = SRL_TAGS.C_ARG0.value\n    c_arg1 = SRL_TAGS.C_ARG1.value\n    c_arg2 = SRL_TAGS.C_ARG2.value\n\n    c_argm_mnr = SRL_TAGS.C_ARGM_MNR.value\n\n    ref_agents = SRL_TAGS.REF_AGENT.value\n    ref_patients = SRL_TAGS.REF_PATIENT.value\n    ref_manners = SRL_TAGS.R_ARGM_MNR.value\n    \n    ref_arg2 = SRL_TAGS.R_ARG2.value\n    ref_arg3 = SRL_TAGS.R_ARG3.value\n\n    r_argm_loc = SRL_TAGS.R_ARGM_LOC.value\n    r_argm_tmp = SRL_TAGS.R_ARGM_TMP.value\n    r_argm_cau = SRL_TAGS.R_ARGM_CAU.value\n\n    verb_mod = SRL_TAGS.PREDICATE_MODIFIER.value\n\n    discourses = SRL_TAGS.DISCOURSE.value\n    modal = SRL_TAGS.MODAL.value\n    manners = SRL_TAGS.MANNER.value\n    adverbials = SRL_TAGS.ADVERBIAL.value\n    purposes = SRL_TAGS.PURPOSE.value\n    goals = SRL_TAGS.GOAL.value\n\n    tag_dict = {\n        verbs : [],           # who `DID WHAT` to whom, when and where\n        verb_mod : [],        # who did what `(AS A WHAT | TO WHAT | WHAT)?` to whom, when and where\n        agents : [],          # `WHO` did what to whom, when and where\n        patients : [],        # who did what `TO WHOM`, when and where\n        temporals : [],       # who did what to whom, `WHEN` and where\n        negations : [],       # who did `NOT WHAT` ...\n        arg2 : [],            # ??? TODO: read more papers\n        arg3 : [],            # ???\n        arg4 : [],            # ???\n        arg5 : [],            # ???\n        argm_adj : [],        # ???\n        argm_ext : [],        # ???\n        argm_loc : [],        # ???\n        argm_pnc : [],        # ???\n        argm_cau : [],        # ???\n        argm_dir : [],        # ???\n        argm_lvb : [],        # ???\n        argm_com : [],        # ???\n        argm_rec : [],        # ???\n        c_arg0 : [],          # ???\n        c_arg1 : [],          # ???\n        c_arg2 : [],          # ???\n        c_argm_mnr : [],      # ???\n        ref_agents : [],      # ???\n        ref_patients : [],    # ???\n        ref_arg2 : [],        # ???\n        ref_arg3 : [],        # ???\n        ref_manners : [],     # ???\n        r_argm_loc : [],      # ???\n        r_argm_tmp : [],      # ???\n        r_argm_cau : [],      # ???\n        discourses : [],      # ???\n        modal : [],           # will, may, can, must, shall, might, should, could, would.\n        manners : [],         # ???how???in what way???\n        adverbials : [],      # ???\n        purposes : [],        # ???why???\n        goals : [],           # ???why???        \n    }\n\n    last_tag = \"\"\n    \n    for (token, tag) in zip(words, tags):\n        last_tag = tag\n\n        if tag.startswith(\"I-\"):\n            t = tag[2:]\n            tag_dict[t].append(token)\n            chunk.append(token)\n        else:\n            if chunk:\n                frame.append(chunk)\n                chunk = []\n\n            if tag.startswith(\"B-\"):\n                t = tag[2:]\n                chunk.append(t)\n                tag_dict[t].append(token)\n                chunk.append(token)\n            elif tag == \"O\":\n                frame.append(token)\n\n    if chunk:\n        frame.append(chunk)\n\n    return frame, tag_dict\n\n\n\n# ============================\n# tags = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARGM-TMP', 'B-V', 'O', 'O', 'O', 'O', 'O']\n# tags = ['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']\n# words = ['Growth', 'and', 'Development', 'creates', 'varying', 'degrees', 'of', 'environmental', 'impacts', 'that', 'ultimately', 'can', 'cause', 'environments', 'to', 'change', '.']\n# ============================\n\n# ============================\n# tags = ['O', 'O', 'O', 'O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\ntags = ['B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'B-ARGM-MOD', 'O', 'B-V', 'B-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'I-ARGM-ADV', 'O']\n# tags = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']\n# tags = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG0', 'O', 'B-ARGM-TMP', 'I-ARGM-TMP', 'O', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']\nwords = ['Questions', 'about', 'a', 'site', 'can', 'be', 'answered', 'only', 'if', 'we', 'take', 'the', 'time', 'to', 'understand', 'the', 'land', \"'s\", 'complexities', '.']\n# ============================\n\n\npprint(make_srl_list(words, tags))\nframes, tag_dict = make_custom_srl_dict(words, tags)\npprint(frames)\npprint(tag_dict)","2484518e":"def _get_custom_srl_dict(srl):\n    words = srl[\"words\"]\n    for verb_dict in srl[\"verbs\"]:\n        tags = verb_dict[\"tags\"]\n        verb = verb_dict[\"verb\"]\n        if verb in MODALS:\n            # continue past all MODALS falsely labeled as verb\n            continue\n        else:\n            # get the first possible verb and return\n            # which means any other SRLs in the list are ignored\n            # TODO: find a better way to always pick the best SRL\n            try:\n                frames, tag_dict = make_custom_srl_dict(words, tags)\n            except:\n                warnings.warn( (\n                     \"\\n\\n\"\n                    \"found a tag that is not in SRL_TAGS enum.\"\n                    \"\\n\\n\"\n                    f\"{pformat(make_srl_list(words, tags))}\"\n                    \"\\n\\n\"\n                    \"will return empty dict\/list on tag_to_tokens\/frames\"\n                    \"\\n\\n\"\n                ) )\n                frames = []\n                tag_dict = dict()\n            return {\n                \"verb\": verb,\n                \"tags\": tags,\n                \"tag_to_tokens\": tag_dict,\n                \"frames\": frames,\n            }\n    warnings.warn(\"No srl found. returning default dict\")\n    return {\n        \"verb\": \"\",\n        \"tags\": [],\n        \"tag_to_tokens\": dict(),\n        \"frames\": [],\n    }\n    \n\n# foos = []\n\n# for i, srl  in enumerate( df[SRL_COL] ):\n#     words = srl[\"words\"]\n#     for verb in srl[\"verbs\"]:\n#         tags = verb[\"tags\"]\n#         try:\n#             _, tag_dict = make_custom_srl_dict(words, tags)\n#             foos.append(tag_dict)\n#         except:\n#             pprint(make_srl_list(words, tags))\n# print(\"DONE\")","d1e9f713":"# df[SRL_COL].apply(lambda x: [d[\"verb\"] for d in x[\"verbs\"]])\n# df[SRL_COL].apply(lambda x: [[d[\"verb\"] , make_srl_list(x[\"words\"], d[\"tags\"])] for d in x[\"verbs\"]])\ntagged_df = df.join(pd.json_normalize(df[SRL_COL].apply(_get_custom_srl_dict)))\ntagged_df.to_csv(\"facts_tagged.csv\")","e7b39cdc":"has_verb_df = tagged_df[tagged_df[VERB_COL].notna()]\nhas_verb_df.head()","54a4d7b2":"pprint(has_verb_df.values[4])","41ed1abb":"# Overview\n\nThere are facts in the text of each syllabus document. \n\nCan we extract them?\n\nAfter extracting the facts like:\n> who did what to whom, when and where?\n\nCan we then create frame-based meaning representations?\n* answer all `who` questions **>>>** `People DataFrame`\n* answer all `when` questions >>> `Timeline DataFrame`\n* answer all `to whom` questions >>> `People-join-People DataFrame`\n* answer all `where` questions >>> `Locations DataFrame`\n* answer all `did what` questions >>> `Actions DataFrame`\n\nNext, when anyone asks a question that matches the question we used to create a _frame_, can we answer those questions?\n* answer all `who` questions **<<<** `People DataFrame`\n* answer all `when` questions **<<<** `Timeline DataFrame`\n* etc...\n\nIn that way, can a system be said to have \"learned a fact\"... assuming it gets the answer right.\n\n\nSpecific to the syllabus corpus:\n* If we mine `when` (temporal) info to generate a `Timeline DataFrame` does that easily answer **\"when is this due\"** type of questions?\n* If we mine `who` info to generate a `People DataFrame` ... what can that answer?\n* If we mine `where` info to generate a `???` ... what can that answer?\n* If we mine `to whom` info to generate a `???` ... what can that answer?\n* If we mine `did what` info to generate a `???` ... what can that answer?\n\n\n--------------------\n**References**\n* [AllenNLP Open Information Extraction demo](https:\/\/demo.allennlp.org\/open-information-extraction)\n* [AllenNLP Semantic Role Labeling (SRL) demo](https:\/\/demo.allennlp.org\/semantic-role-labeling)\n* [Supervised Open Information Extraction (IE)](https:\/\/www.aclweb.org\/anthology\/N18-1081\/)\n* [Answering Complex Questions Using Open Information Extraction](https:\/\/www.aclweb.org\/anthology\/P17-2049\/)\n* [Simple BERT Models for Relation Extraction and Semantic Role Labeling](https:\/\/arxiv.org\/abs\/1904.05255)\n* [NLP Highlights podcast 96 -- QA as annotation format with Luke Zettlemoyer](https:\/\/soundcloud.com\/nlp-highlights\/96-question-answering-as-an-annotation-format-with-luke-zettlemoyer)\n* [Jurafsky SRL chapter](https:\/\/web.stanford.edu\/~jurafsky\/slp3\/20.pdf)\n* [Jurafsky SRL slides](https:\/\/web.stanford.edu\/~jurafsky\/slp3\/slides\/22_SRL.pdf)\n* [Jurafsky IE chapter](https:\/\/web.stanford.edu\/~jurafsky\/slp3\/18.pdf)\n* [NLP Progress on SRL](http:\/\/nlpprogress.com\/english\/semantic_role_labeling.html)\n* [NLP Progress on IE](http:\/\/nlpprogress.com\/english\/information_extraction.html)\n* [Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language](https:\/\/www.aclweb.org\/anthology\/D15-1076\/)\n* [QASRL.org](http:\/\/qasrl.org)\n* [QASRL](https:\/\/dada.cs.washington.edu\/qasrl)\n* [Large-Scale QA-SRL Parsing](https:\/\/www.aclweb.org\/anthology\/P18-1191\/)\n* [papers with code -- NLP](https:\/\/paperswithcode.com\/area\/natural-language-processing)\n* [Jointly Predicting Predicates and Arguments in Neural Semantic Role Labeling](https:\/\/www.aclweb.org\/anthology\/P18-2058\/)\n* [Jurafsky Logical Representations of Sentence Meaning chapter](https:\/\/web.stanford.edu\/~jurafsky\/slp3\/16.pdf)\n* [slides on SRL in Ling571 at washington.edu](http:\/\/courses.washington.edu\/ling571\/ling571_WIN2016\/slides\/ling571_class12_sem_srl_flat.pdf)\n* [propbank github](https:\/\/github.com\/propbank\/propbank-documentation)\n* [this one says r-arg is \"referential\" ](http:\/\/scottyih.org\/files\/necessity_punyakanok.pdf)\n* [also mentions referential](https:\/\/www.ijcai.org\/Proceedings\/05\/Papers\/1672.pdf)\n* [also mentions referential](https:\/\/www.mitpressjournals.org\/doi\/pdf\/10.1162\/coli.2008.34.2.257)\n* [also mentions referential](http:\/\/classes.ischool.syr.edu\/ist664\/NLPSpring2013\/SemanticRoleLabeling.2013.ppt.pdf)\n* [more slides](https:\/\/www.aclweb.org\/mirror\/hlt-naacl2013\/Documents\/semantic-role-labeling-part-2-naacl-2013-tutorial.pdf)\n* [mentioned \"continuation\" `C-` and \"referent\" `R-`](https:\/\/www.researchgate.net\/publication\/324941325_Optimization_of_Natural_Language_Processing_Components_for_Robustness_and_Scalability#pf105)","5218ce82":"# Save Facts","5fa21d2a":"## Consider the following\n\n\nA simple sentence:\n```\nThe quick brown fox jumped over the lazy dog\n```\n\nCan be parsed simply into a triple\n```\njumped: [ARG0: The quick brown fox] [V: jumped] [ARGM-DIR: over the lazy dog]\n```\n\n\nOther sentences are a bit more complex due to containing:\n* `conditionals` **(see below)**\n* `questions`\n* other things\n\n\nSo perhaps an algorithm to `find_conditional_phrases` or `identify_question_sentence` might be needed?\n* question sentences can be identified [by some heuristics used in Google's Natural Questions dataset](https:\/\/research.google\/pubs\/pub47761\/)\n* for conditionals..... [well google it](https:\/\/www.google.com\/search?q=nlp+conditional+phrases) also [try googling](https:\/\/www.google.com\/search?q=causal+site%3Aaclweb.org+-sentiment+-random+-field+-distribution&oq=causal+site%3Aaclweb.org+-sentiment+-random+-field+-distribution) and optionally [try this google](https:\/\/www.google.com\/search?q=nlp+conditional+phrases+sentences+acl+-sentiment+-random+-field+-distribution&oq=nlp+conditional+phrases+sentences+acl+-sentiment+-random+-field+-distribution)\n  * perhaps [this paper](https:\/\/publik.tuwien.ac.at\/files\/PubDat_223973.pdf)\n  * maybe [this paper](https:\/\/pdfs.semanticscholar.org\/4951\/7539055234e73bfa6140a7a84b74cfc12685.pdf)\n  * consider [this paper](https:\/\/link.springer.com\/chapter\/10.1007\/978-3-642-04957-6_41)\n  * also [this paper](https:\/\/www.aclweb.org\/anthology\/W03-1210)\n  * how about [this paper](https:\/\/www.aclweb.org\/anthology\/P18-1212\/)\n  * or even [this paper](https:\/\/www.aclweb.org\/anthology\/W17-0812\/)\n\n**But why even care??**\n* If a sentence contains a conditional... then the SRL output may not be easily transformed into an ontology. \n* Consequently, we might choose to simply disregard anything that contains `if` or `in the event that` or `conditionally upon` ... there could be many ways....\n* However, we know that the Syllabus Corpus has an average readability of \"high-school\" level... so that might help reduce the scope our conditional-phrase search. \n\n**But also**\n* notice the conditional phrase **(see below)** is wrapped within the `ARGM-ADV` tag\/annotation.\n* it's not a _patient_ nor an _agent_.... it's a _modifier_.\n* That is helpful! If the SRL consistently outputs conditionals within `ARGM-ADV` then the frame creation \/ factoid mining based on the _patient_ and _agent_ can maintain its integrity.\n  * i.e. if ARG0 is empty ... we do not know the `agent`\n  * i.e. if ARG1 is empty ... we do not know the `patient`\n  * vice versa...\n  * etc...\n\n\n```\n[['ARG1', 'Questions', 'about', 'a', 'site'],\n ['ARGM-MOD', 'can'],\n 'be',\n ['V', 'answered'],\n ['ARGM-ADV',\n  'only',\n  'if',\n  'we',\n  'take',\n  'the',\n  'time',\n  'to',\n  'understand',\n  'the',\n  'land',\n  \"'s\",\n  'complexities'],\n '.']\n{'ARG0': [],\n 'ARG1': ['Questions', 'about', 'a', 'site'],\n 'ARG2': [],\n 'ARG3': [],\n 'ARGM-ADV': ['only',\n              'if',\n              'we',\n              'take',\n              'the',\n              'time',\n              'to',\n              'understand',\n              'the',\n              'land',\n              \"'s\",\n              'complexities'],\n 'ARGM-DIS': [],\n 'ARGM-GOL': [],\n 'ARGM-MNR': [],\n 'ARGM-MOD': ['can'],\n 'ARGM-NEG': [],\n 'ARGM-PRP': [],\n 'ARGM-TMP': [],\n 'V': ['answered']}\n ```","e60a7402":"# --------------","29dd10a6":"## [Reproducibility](https:\/\/www.kaggle.com\/rtatman\/reproducible-research-best-practices-jupytercon)","03627696":"## Consider the following.\n\n\n**It is possible to not know \"who\" did the `verb`** (i.e. no `ARG0` i.e. no Subject\/Agent\/Experiencer\/Causer)\n```\nOn January 13, 2018, a false ballistic missile alert was issued via the Emergency Alert System and Commercial Mobile Alert System over television, radio, and cellphones in the U.S. state of Hawaii. \n```\n\n```\nissued: [ARGM-TMP: On January 13] , 2018 , [ARG1: a false ballistic missile alert] was [V: issued] [ARGM-MNR: via the Emergency Alert System and Commercial Mobile Alert System over television , radio , and cellphones in the U.S. state of Hawaii] .\n```\n\n\n\n**In an informative document the word `this` sometimes refers to the document itself.**\n\n\n```\n[['acknowledge',\n  [['ARG0', 'This'],\n   'is',\n   'to',\n   ['ARGM-MNR', 'formally'],\n   ['V', 'acknowledge'],\n   ['ARG1',\n    'receipt',\n    'and',\n    'approval',\n    'of',\n    'the',\n    'above',\n    '-',\n    'referenced',\n    'Academic',\n    'Senate',\n    'resolution'],\n   '.']],\n ['referenced',\n  ['This',\n   'is',\n   'to',\n   'formally',\n   'acknowledge',\n   'receipt',\n   'and',\n   'approval',\n   'of',\n   'the',\n   ['ARGM-LOC', 'above'],\n   '-',\n   ['V', 'referenced'],\n   ['ARG1', 'Academic', 'Senate', 'resolution'],\n   '.']]\n```","d3e04d77":"# Let's get Semantic Role Lables on OCR_TEXT","d712a9a0":"## Imports","845e395f":"## Some more to consider\n\n\nThe following contained _tags_ that I did not originally find documented, but in hindsight were in both Jurafsky textbook and other papers (e.g. `ARG4` and `ARGM-PRD`)\n\n```\n[['ARG1', 'Natural', 'and', 'introduced', 'elements'],\n ['ARGM-TMP', 'typically'],\n ['V', 'come'],\n ['ARGM-PRD', 'together'],\n ['ARG4', 'at', 'sites'],\n ['ARGM-PRP', 'to', 'create', 'complex', 'systems'],\n '.']\n```\n* notice the verb. \n* makes little sense alone, but rather concatenated the `come together` provides the full predicate\n\n* After reading the above sentence a **reader will know**\n  * What something does\n  * Where something does something\n  * Why something does something\n  * Where something does something\n  * How-often\/When something does something\n* Also, the **reader may still wonder** (if meaningful)\n  * Who causes something to do something\n  * How something does something\n  * ...\n* So you might consider that a good FAQ might provide a clean stuctured summary of\n  * what the **reader will know**\n  * and what the **reader may still wonder**\n  * after finishing the document. \n  \n  \n## Even more to consider\n\n```\n['These',\n 'systems',\n 'tell',\n 'us',\n 'stories',\n 'about',\n ['ARGM-MNR', 'the', 'ways'],\n ['R-ARGM-MNR', 'that'],\n ['ARG0', 'humans'],\n ['ARGM-MOD', 'might'],\n ['V', 'interact'],\n ['ARG1', 'there'],\n '.']\n```\n* `R-ARGM-MNR`\n\n--------------------\n\n```\n['\u00ab',\n 'Are',\n 'there',\n ['ARG1', 'opportunities', 'and\/or'],\n ['V', 'limitations'],\n ['ARGM-ADJ', 'that', 'might', 'restrict', 'some', 'activities'],\n '?']\n```\n* `ARGM-ADJ`\n\n--------------------\n\n```\n['Undesired',\n 'landscape',\n 'change',\n 'can',\n 'occur',\n 'when',\n ['ARG0', 'people'],\n 'do',\n 'not',\n 'take',\n ['ARGM-TMP', 'the', 'time'],\n 'to',\n ['ARGM-EXT', 'fully'],\n ['V', 'understand'],\n ['ARG1', 'the', 'interrelationships', 'of', 'the', 'various', 'systems'],\n '.']\n```\n* `ARGM-EXT`\n\n--------------------\n\n```\n['1',\n '.',\n 'study',\n 'a',\n 'landscape',\n 'analytically',\n 'and',\n 'holistically',\n 'so',\n 'as',\n 'to',\n 'better',\n 'understand',\n 'the',\n 'complex',\n 'web',\n 'of',\n 'relationships',\n ['R-ARG1', 'that'],\n ['V', 'exist'],\n ['ARGM-LOC', 'in', 'biophysical', 'systems'],\n ',']\n```\n\n* `ARGM-LOC`\n\n--------------------\n\n```\n['Lectures',\n 'will',\n 'be',\n 'followed',\n 'by',\n ['ARGM-LOC', 'a', 'studio', 'period'],\n ',',\n ['R-ARGM-LOC', 'where'],\n ['ARG1', 'exercises'],\n ['ARGM-MOD', 'can'],\n 'be',\n ['V', 'developed'],\n '.']\n```\n\n* `R-ARGM-LOC`\n\n--------------------\n\n```\n[['ARG1',\n  'Only',\n  'documented',\n  'illness',\n  'or',\n  'documented',\n  'compassionate',\n  'grounds'],\n ['ARGM-MOD', 'will'],\n 'be',\n ['V', 'accepted'],\n ['ARGM-PNC', 'to', 'excuse', 'late', 'submissions'],\n '.']\n```\n\n* `ARGM-PNC` (purpose not cause)\n> Purpose clauses are used to show the motivation for some action. \n> Clauses beginning with \"in order to\" are canonical purpose clauses\n> \n> https:\/\/verbs.colorado.edu\/~mpalmer\/projects\/ace\/PBguidelines.pdf\n  * More than a few CEOs say [0] the red-carpet treatment tempts them to return to a heartland city for future meetings . \n    * ARG1: them\n    * REL: return\n    * ARG4-to: to a heartland city\n    * ARGM-PNC: for future meetings\n  * In a disputed 1985 ruling , the Commerce Commission said [0] Commonwealth Edison could raise its electricity rates by 49 million to pay for the plant.\n    * ARG0: Commonwealth Edison\n    * ARGM-MOD: could\n    * REL: raise\n    * ARG1: its electricity rates\n    * ARG2-by: by 49 million\n    * ARGM-PNC: to pay for the plant\n\n\n--------------------\n\n```\n[['ARGM-TMP', 'Many', 'times'],\n ['ARGM-LOC', 'in', 'a', 'group', 'situation'],\n ['ARG0', 'we'],\n 'do',\n ['ARGM-NEG', 'not'],\n ['V', 'want'],\n ['ARG1', 'to', 'ask', 'questions'],\n ['ARGM-CAU',\n  'for',\n  'fear',\n  'that',\n  'our',\n  'classmates',\n  'will',\n  'think',\n  'that',\n  'we',\n  'are',\n  'not',\n  'intelligent'],\n '.']\n```\n* `ARGM-CAU`\n\n\n--------------------\n\n```\n[['ARGM-TMP', 'The', 'times'],\n ['R-ARGM-TMP', 'that'],\n ['ARG1', 'I'],\n 'am',\n ['V', 'guaranteed'],\n ['C-ARG1', 'to', 'be', 'in', 'my', 'office'],\n 'are',\n 'listed',\n 'above',\n '.']\n```\n\n* `R-ARGM-TMP` (referential temporal marker ??? )\n\n\n--------------------\n\n```\n['This',\n 'course',\n 'is',\n 'designed',\n 'to',\n ['ARGM-MNR', 'individually'],\n ['V', 'mentor'],\n ['ARG1', 'students'],\n ['ARGM-DIR', 'through', 'the', 'final', 'steps', 'required'],\n ['ARGM-PRP',\n  'to',\n  'complete',\n  'the',\n  'Cal',\n  'Poly',\n  'Lean',\n  'Six',\n  'Sigma',\n  'Green',\n  'Belt',\n  'Certification'],\n '.']\n```\n* `ARGM-DIR` (directionals)\n  * into a huge bin\n  * forward\n  * back\n  * home (as in \"Franklin, go home\" such that verb=\"go\")\n\n--------------------\n\n```\n[['ARG0', 'Green', 'Belt', 'projects'],\n ['ARGM-ADV', 'typically'],\n ['V', 'take'],\n ['ARG1', '3', '-', '9', 'months'],\n ['C-ARG0', 'to', 'complete'],\n '.']\n```\n\n* `C-ARG0`\n\n--------------------\n\n```\n[['ARG0', 'They'],\n ['ARGM-MOD', 'would'],\n 'also',\n ['ARGM-LVB', 'do'],\n 'some',\n ['ARGM-MNR', 'pre'],\n '-',\n ['V', 'work'],\n 'and',\n 'speak',\n 'to',\n 'the',\n 'instructor',\n '(',\n 'mentor',\n ')',\n 'about',\n 'the',\n 'feasibility',\n 'of',\n 'completing',\n 'the',\n 'projects',\n 'on',\n 'time',\n '.']\n```\n\n* `ARGM-LVB` (Light verb)\n>  \n> This  tag  is  used  to  label  the  light  verb  only  in  the  noun  pass  of  light  verb  annotation.\n> See Chapter 2 for more details.\n>\n> https:\/\/verbs.colorado.edu\/propbank\/EPB-Annotation-Guidelines.pdf\n>\n* Yesterday,  Mary  made  an  accusation  of  duplicity  against  John  because  she  was  enraged  withjealousy.\n  * ARGM-TMP: Yesterday\n  * ARG0:  Mary\n  * ARGM-LVB: made\n  * REL: accusation\n  * ARG2:  of duplicity\n  * ARG1:  against John\n  * ARGM-CAU: because she was enraged with jealousy.\n\n\n**This one is interesting** because if the `ARGM-MNR` is missing then you can ask:\n* **HOW** was the work done?\n* **HOW** was the acusation made?\n\nAnd those _how_ questions would be structured differently without the _light verb_.\n\n\n--------------------\n\n\n```\n[['ARGM-LOC', 'Collaborative'],\n ['V', 'Filtering'],\n ['ARG1', '1', 'Chapter', '11'],\n ',',\n ['C-ARG2', '12', '5'],\n '.']\n```\n* `C-ARG2` (coninuation of arg2?)\n  * hmm... this one is weird\n  * and there is no regular `ARG2` either\n  * if `C-*` exists but not corresponding `*` (e.g. `C-ARG2` with `ARG2`)\n    * then perhaps I can consider it bad grammar?\n    * honestly... this one isn't even a sentence..\n    * it was extracted from a table\n      * http:\/\/web.archive.org\/web\/20180714044332\/http:\/\/users.csc.calpoly.edu\/~dekhtyar\/466-Spring2018\/syllabus.466.pdf\n\n\n--------------------\n\n```\n['ooccasional',\n 'critical',\n 'absences',\n ',',\n ['ARG3', 'for'],\n ['R-ARGM-CAU', 'which'],\n ['ARG1', 'advance', 'notification'],\n 'is',\n ['V', 'required']]\n```\n\n* `R-ARGM-CAU` (referential cause)\n\n* this phrase came from a list\n  * http:\/\/web.archive.org\/web\/20200525134742\/http:\/\/users.csc.calpoly.edu\/~gfisher\/classes\/406\/handouts\/syllabus.html\n\n--------------------\n\n\n```\n[['ARG0', 'You'],\n 'are',\n 'also',\n 'required',\n 'to',\n ['V', 'bring'],\n ['ARG1', 'a', 'scientific', 'calculator'],\n ['ARGM-COM', 'with', 'you'],\n ['ARG2', 'to', 'each', 'class', 'session'],\n '.']\n```\n\n* `ARGM-COM` (commitatives)\n  * https:\/\/verbs.colorado.edu\/propbank\/EPB-Annotation-Guidelines.pdf\n  * \"with his friend\"\n  * \"with a police escort\"\n\n**conversationally, extract this by**\n* **`with whom`** did someone do something?\n\n--------------------\n\n```\n['Cheating',\n ':',\n 'If',\n 'your',\n 'work',\n 'or',\n 'parts',\n 'of',\n 'your',\n 'work',\n 'are',\n 'plagiarized',\n 'from',\n 'another',\n 'student',\n 'or',\n 'unapproved',\n 'source',\n ',',\n 'you',\n 'will',\n 'fail',\n 'the',\n 'course',\n 'and',\n ['ARG1', 'a', 'letter'],\n ['ARGM-MOD', 'will'],\n 'be',\n ['V', 'put'],\n ['ARG2', 'in', 'your', 'file'],\n ['ARGM-COM', 'with', 'Cal', 'Poly', 'Judicial', 'Affairs'],\n '.']\n```\n\n* `ARGM-COM`\n\n--------------------\n\n```\n['The',\n 'textbook',\n 'is',\n 'recommended',\n 'and',\n 'not',\n 'required',\n ',',\n 'but',\n 'it',\n 'contains',\n ['ARGM-MNR', 'clear', 'exposition', 'and', 'many', 'exercises'],\n ['R-ARG3', 'with', 'which'],\n 'to',\n ['V', 'develop'],\n 'and',\n 'assess',\n 'your',\n 'understanding',\n '.']\n```\n\n* `R-ARG3` (referential arg3)\n\n--------------------\n\n```\n[['ARG0', 'Your', 'instructor'],\n ['ARGM-MOD', 'will'],\n ['V', 'go'],\n ['ARG1', 'over', 'this', 'style', 'sheet'],\n ['ARGM-COM', 'with', 'you'],\n ['ARGM-LOC', 'in', 'class'],\n '.']\n```\n\n* `ARGM-COM`\n\n--------------------\n\n```\n[['ARG1', 'Programming', 'assignments'],\n ['ARGM-MOD', 'may'],\n 'be',\n ['V', 'submitted'],\n ['ARG5', 'up'],\n ['ARG2', 'to', 'one', 'class'],\n ['ARGM-TMP', 'day', 'late'],\n ['ARG3', 'for', 'up', 'to', '70', '%', 'credit'],\n '.']\n```\n\n* `ARG5`\n\n--------------------\n\n```\n['There',\n 'may',\n 'be',\n ['ARG3', 'some', 'assignments'],\n ['R-ARG3', 'for', 'which'],\n ['ARG1', 'the', 'use', 'of', 'late', 'days'],\n ['ARGM-MOD', 'will'],\n ['ARGM-NEG', 'not'],\n 'be',\n ['V', 'allowed'],\n '.']\n```\n\n* `R-ARG3`\n\n--------------------\n\n```\n[['ARG0', 'Your', 'instructor'],\n ['ARGM-MOD', 'will'],\n ['V', 'go'],\n ['ARG1', 'over', 'this', 'style', 'sheet'],\n ['ARGM-COM', 'with', 'you'],\n ['ARGM-LOC', 'in', 'class'],\n '.']\n```\n\n* `ARGM-COM`\n\n--------------------\n\n```\n[['ARG0', 'Your', 'instructor'],\n ['ARGM-MOD', 'will'],\n ['V', 'go'],\n ['ARG1', 'over', 'this', 'style', 'sheet'],\n ['ARGM-COM', 'with', 'you'],\n ['ARGM-LOC', 'in', 'class'],\n '.']\n```\n\n* `ARGM-COM`\n\n--------------------\n\n```\n[['ARGM-DIS', '\u2018'],\n ['ARG0', 'You'],\n ['ARGM-MOD', 'can'],\n ['V', 'work'],\n ['ARGM-REC', 'together'],\n ['ARG1', 'on', 'lab', 'exercises'],\n '.']\n```\n\n* ARGM-REC (Reciprocals)\n  * https:\/\/verbs.colorado.edu\/propbank\/EPB-Annotation-Guidelines.pdf\n\n> But voters decided that if the stadium was such a good idea someone would build it himself, andrejected it 59% to 41% .\n  * ARGM-ADV: if the stadium was such a good idea\n  * ARG0:  someone\n  * ARGM-MOD: would\n  * REL: build\n  * ARG1:  it\n  * ARGM-REC: himself\n\n\n--------------------\n\n```\n[['ARG0', 'You'],\n ['ARGM-MOD', 'may'],\n ['V', 'work'],\n ['ARGM-MNR', 'individually'],\n ['ARG1', 'on', 'this', 'project'],\n ['C-ARGM-MNR', 'or', 'with', 'a', 'partner'],\n ';',\n 'you',\n 'must',\n 'declare',\n 'which',\n 'during',\n 'the',\n 'first',\n 'week',\n '.']\n```\n\n* `C-ARGM-MNR` (continuation of argm-manner?)","4f789a5f":"## Try SRL","63c1efba":"## Try OpenIE","46e474cb":"## Globals \/ Config","dca29311":"## Installs"}}