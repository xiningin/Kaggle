{"cell_type":{"c286c79f":"code","264786b0":"code","24f521a3":"code","bee7699a":"code","f67181dd":"code","d5104569":"code","9b7d6d3f":"code","e65e5763":"code","62fe32ac":"code","e0c39be9":"code","7af3366e":"code","535e4fa4":"code","36b52480":"code","72006b73":"code","0ffedf3d":"code","b53471c9":"code","7c1ef281":"code","f5abdb01":"code","a6e4765e":"code","88d8ea3e":"code","03277cae":"code","63f7fe79":"code","623616f3":"code","d94139bf":"markdown","0f82e8f3":"markdown","aec2d50a":"markdown","cf6dcfd2":"markdown","ebd8638a":"markdown","3a733412":"markdown","90e832f6":"markdown","8e84d4b1":"markdown","bcf01868":"markdown","1371f40f":"markdown"},"source":{"c286c79f":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport torchvision.models as models\nimport torchvision.transforms as trns\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data import random_split, DataLoader, Dataset\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [8, 10]","264786b0":"file_map = dict()\nfor i in range(12):\n    path = '\/kaggle\/input\/data\/images_' + ('00' if i < 9 else '0') + str(i + 1) + '\/images\/'\n    for f in os.listdir(path):\n        if os.path.isfile(os.path.join(path, f)) and f[-4:] == '.png':\n            file_map[f] = os.path.join(path, f)","24f521a3":"df = pd.read_csv('\/kaggle\/input\/data\/Data_Entry_2017.csv')\ndf.head(10)","bee7699a":"df.info()","f67181dd":"def showImage(pil):\n    plt.imshow(np.array(pil) \/ 255)","d5104569":"def loadImage(path):\n    return Image.open(path).convert('RGB')","9b7d6d3f":"showImage(loadImage(file_map[list(file_map.keys())[100]]))","e65e5763":"classes = [\n    'Atelectasis', \n    'Consolidation', \n    'Infiltration', \n    'Pneumothorax', \n    'Edema', \n    'Emphysema', \n    'Fibrosis', \n    'Effusion', \n    'Pneumonia', \n    'Pleural_thickening', \n    'Cardiomegaly', \n    'Nodule', \n    'Mass', \n    'Hernia', \n    'No Finding'\n]","62fe32ac":"class ImageDataset(Dataset):\n    def __init__(self, data, transforms):\n        self.image_paths = [file_map[f] for f in data[0]]\n        self.labels = data[1]\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(data[0])\n    \n    def __getitem__(self, idx):\n        image = self.transforms(loadImage(self.image_paths[idx]))\n        target = torch.tensor([int(cls in self.labels[idx]) for cls in classes], dtype=torch.float32)\n        return (image, target)","e0c39be9":"data = (df.iloc[:5000, 0], [df.iloc[i, 1].split('|') for i in range(5000)])","7af3366e":"dataset = ImageDataset(data, trns.Compose([\n    trns.Resize((240, 240)),\n    trns.ToTensor(), \n    trns.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225],inplace=True)\n]))","535e4fa4":"print(dataset[1][1])\nplt.imshow(dataset[1][0].permute((1, 2, 0)))","36b52480":"train_dataset, validation_dataset = random_split(dataset, [int(len(dataset) * 0.85), \n            len(dataset) - int(len(dataset) * 0.85)])","72006b73":"train_dataset_size = len(train_dataset)\nvalidation_dataset_size = len(validation_dataset)\n\ntrain_dataset_size, validation_dataset_size","0ffedf3d":"num_classes = 15\ninput_shape = (3, 240, 240)","b53471c9":"num_clients = 3\nrounds = 10\nbatch_size = 64\nepochs_per_client = 6\nlearning_rate = 1e-1","7c1ef281":"resnet34 = models.resnet34(pretrained=True)\nresnet34","f5abdb01":"def get_device():\n    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader(DataLoader):\n        def __init__(self, dl, device):\n            self.dl = dl\n            self.device = device\n\n        def __iter__(self):\n            for batch in self.dl:\n                yield to_device(batch, self.device)\n\n        def __len__(self):\n            return len(self.dl)\n\ndevice = get_device()","a6e4765e":"class FederatedNet(torch.nn.Module):    \n    def __init__(self):\n        super().__init__()\n        self.network = models.resnet34(pretrained=True)\n        self.network.fc = torch.nn.Linear(self.network.fc.in_features, num_classes)\n        self.track_layers = {\n            'layer4':  self.network.layer4,\n            'linear': self.network.fc\n        }\n        self.freeze()\n\n    def freeze(self):\n        for param in self.network.parameters():\n            param.requires_grad = False\n        for layer_name in self.track_layers:\n            for param in self.track_layers[layer_name].parameters():\n                param.requires_grad = True\n    \n    def forward(self, x_batch):\n        out = torch.sigmoid(self.network(x_batch))\n        return out\n    \n    def get_track_layers(self):\n        return self.track_layers\n    \n    def apply_parameters(self, parameters_dict):\n        with torch.no_grad():\n            for layer_name in parameters_dict:\n                layer_params = list(self.track_layers[layer_name].parameters())\n                for i in range(len(layer_params)):\n                    layer_params[i].data = (layer_params[i].data + (parameters_dict[layer_name][i] - \n                                                layer_params[i].data))\n    \n    def get_parameters(self):\n        parameters_dict = dict()\n        for layer_name in self.track_layers:\n            parameters_dict[layer_name] = [param.data.clone().detach() for param in self.track_layers\n                                                [layer_name].parameters()]\n        return parameters_dict\n    \n    def batch_accuracy(self, outputs, labels):\n        with torch.no_grad():\n            return torch.tensor(torch.sum((outputs > 0.5) == labels).item() \/ len(outputs))\n    \n    def _process_batch(self, batch):\n        images, labels = batch\n        outputs = self(images)\n        loss = torch.nn.functional.binary_cross_entropy(outputs, labels)\n        accuracy = self.batch_accuracy(outputs, labels)\n        return (loss, accuracy)\n    \n    def fit(self, dataset, epochs, lr, batch_size=128, opt=torch.optim.SGD):\n        self.train()\n        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size, shuffle=True), device)\n        optimizer = opt(self.parameters(), lr)\n        history = []\n        for epoch in range(epochs):\n            losses = []\n            accs = []\n            for batch in dataloader:\n                loss, acc = self._process_batch(batch)\n                loss.backward()\n                optimizer.step()\n                optimizer.zero_grad()\n                loss.detach()\n                losses.append(loss)\n                accs.append(acc)\n            avg_loss = torch.stack(losses).mean().item()\n            avg_acc = torch.stack(accs).mean().item()\n            history.append((avg_loss, avg_acc))\n        return history\n    \n    def evaluate(self, dataset, batch_size=64):\n        self.eval()\n        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size), device)\n        losses = []\n        accs = []\n        with torch.no_grad():\n            for batch in dataloader:\n                loss, acc = self._process_batch(batch)\n                losses.append(loss)\n                accs.append(acc)\n        avg_loss = torch.stack(losses).mean().item()\n        avg_acc = torch.stack(accs).mean().item()\n        return (avg_loss, avg_acc)","88d8ea3e":"class Client:\n    def __init__(self, client_id, dataset):\n        self.client_id = client_id\n        self.dataset = dataset\n    \n    def get_dataset_size(self):\n        return len(self.dataset)\n    \n    def get_client_id(self):\n        return self.client_id\n    \n    def train(self, parameters_dict, return_model_dict=False):\n        net = to_device(FederatedNet(), device)\n        net.apply_parameters(parameters_dict)\n        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n        print(self.client_id + ':')\n        for i, res in enumerate(train_history):\n            print('Epoch [{}]: Loss = {}, Accuracy = {}'.format(i + 1, round(res[0], 4), round(res[1], 4)))\n        return net.get_parameters(), net.state_dict() if return_model_dict else None","03277cae":"examples_per_client = train_dataset_size \/\/ num_clients\nclient_datasets = random_split(train_dataset, [min(i + examples_per_client, \n           train_dataset_size) - i for i in range(0, train_dataset_size, examples_per_client)])\nclients = [Client('client_' + str(i), client_datasets[i]) for i in range(num_clients)]","63f7fe79":"global_net = to_device(FederatedNet(), device)\nhistory = []\n\nfor i in range(rounds):\n    print('Start Round {} ...'.format(i + 1))\n    curr_parameters = global_net.get_parameters()\n    new_parameters = dict([(layer_name, [0 for param in global_net.track_layers[layer_name].parameters()])\n                            for layer_name in curr_parameters])\n    for j, client in enumerate(clients):\n        client_parameters, state_dict = client.train(curr_parameters, (j == len(clients) - 1))\n        if j == len(clients) - 1:\n            global_net.load_state_dict(state_dict)\n            global_net.apply_parameters(client_parameters)\n            train_loss, train_acc = global_net.evaluate(train_dataset)\n            val_loss, val_acc = global_net.evaluate(validation_dataset)\n            print('After round {}, train_loss = {}, val_loss = {}, val_acc = {}\\n'.format(i + 1, round(train_loss, 4), \n                    round(val_loss, 4), round(val_acc, 4)))\n            history.append((train_loss, val_loss))\n\n        fraction = client.get_dataset_size() \/ train_dataset_size\n        for layer_name in client_parameters:\n            for j in range(len(client_parameters[layer_name])):\n                new_parameters[layer_name][j] += fraction * client_parameters[layer_name][j]\n\n    global_net.apply_parameters(new_parameters)","623616f3":"plt.plot([i + 1 for i in range(len(history))], [history[i][0] for i in range(len(history))], color='r', label='train loss')\nplt.plot([i + 1 for i in range(len(history))], [history[i][1] for i in range(len(history))], color='b', label='val loss')\nplt.title('Training history')\nplt.legend()\nplt.show()","d94139bf":"## Define Client class","0f82e8f3":"## Define notebook constants","aec2d50a":"## Start server","cf6dcfd2":"## Define GPU utilities","ebd8638a":"## Map images to their location","3a733412":"## Load dataset","90e832f6":"## Define FederatedNet class","8e84d4b1":"## Import Libraries","bcf01868":"## Setup clients","1371f40f":"## Define training and validation sets"}}