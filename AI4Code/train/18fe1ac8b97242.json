{"cell_type":{"2b3eac00":"code","60c7d8da":"code","4eee2d2e":"code","f2f967cb":"code","434b54f5":"code","0b1f64a9":"code","9002e3d7":"code","1af27392":"code","ccf7975e":"code","e3383bc8":"markdown","ba5d6f63":"markdown","2942d952":"markdown","d2c052cd":"markdown","33c68a0f":"markdown","58808cc5":"markdown","cb746e01":"markdown","1bfdc73f":"markdown","a87c1d2c":"markdown","6682e906":"markdown"},"source":{"2b3eac00":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\nfrom tensorflow.keras.metrics import MeanSquaredError\n\nimport os\n","60c7d8da":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4eee2d2e":"pd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\nRootDir = \"\/kaggle\/input\/cryptocurrencypricehistory\"\nHistory = 60\n\ndef read_data ():\n    coin_no = 0\n    for name in os.listdir(RootDir):\n        coin_no += 1\n    \n    max_length, min_length = 0, 1000000\n    for name in os.listdir(RootDir):\n        df = pd.read_csv(RootDir + \"\/\" + name, parse_dates=['Date'])\n        length = df.shape[0]\n        if max_length < length:\n            max_length = length\n        if min_length > length:\n            min_length = length\n    \n    data = np.zeros ((coin_no, max_length))\n    lengths = np.zeros(coin_no, dtype = int)\n    i = 0\n    for name in os.listdir(RootDir):\n        short_name = name[5:-4]\n        df = pd.read_csv(RootDir + \"\/\" + name, parse_dates=['Date'])\n        length = df.shape[0]\n        lengths[i] = length\n        print (i, short_name, length)\n        data[i, 0:length] = df['Close'].values  # We only keep the closing price as a sequence!\n        i += 1\n    \n    return coin_no, lengths, data\n\ncoin_no, lengths, data = read_data ()\nprint (\"Got\", coin_no, \"coins.\")","f2f967cb":"def scale_data (data, lengths):\n    coin_no = data.shape[0]\n    shift = np.zeros (coin_no)\n    factor = np.zeros (coin_no)\n    for i in range (coin_no):\n        max_val = data[i,:lengths[i]].max()\n        min_val = data[i, :lengths[i]].min()\n        shift[i] = min_val\n        factor[i] = max_val - min_val\n        data[i,0:lengths[i]] = (data[i,0:lengths[i]]-shift[i])\/factor[i]\n    return (shift, factor)\n    \nshift, factor = scale_data (data, lengths)","434b54f5":"def create_sequences (data, lengths, start, end):\n    x = []\n    y = []\n    for i in range (start, end):   # Go only over the specified coins\n        for j in range(History, lengths[i]):\n            x.append(data[i, j-History:j])\n            y.append(data[i, j])\n    return np.array(x)[:, :, np.newaxis], np.array(y)\n\nx_train, y_train = create_sequences(data, lengths, 0, 18)\nprint (\"Got\", y_train.shape[0], \"training sequenes.\")\nx_val, y_val = create_sequences(data, lengths, 18, 22)\nprint (\"Got\", y_val.shape[0], \"validation sequenes.\")\nx_test, y_test = create_sequences(data, lengths, 22, 23)\nprint (\"Got\", y_test.shape[0], \"test sequenes.\")","0b1f64a9":"def build_lstm ():\n    # Build an LSTM model\n    model = Sequential()\n    model.add(LSTM(128, return_sequences=True, input_shape= (History, 1)))\n    model.add(LSTM(64, return_sequences=False))\n    model.add(Dense(25))\n    model.add(Dense(1))\n    \n    # Compile the model\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[MeanSquaredError()])\n    model.summary()\n    \n    return model\n\nmodel = build_lstm()","9002e3d7":"hist = model.fit(x_train, y_train, validation_data = (x_val, y_val), \n              batch_size=32, epochs=5) ","1af27392":"def show_stats (hist):\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title(\"Model loss\")\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Training loss\",\"Validation loss\"])\n    plt.show()\n\nshow_stats (hist)","ccf7975e":"predictions = model.predict(x_test)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nprint (\"Root mean square error on test data:\", rmse)    \nplt.plot(predictions*factor[22] + shift[22])\nplt.plot(y_test*factor[22] + shift[22])    \nplt.legend([\"Predictions\",\"Real data\"])\nplt.show()","e3383bc8":"Now, let's train the model we just built using the training set:","ba5d6f63":"# Scaling and splitting:\nWe need to scale the data:","2942d952":"As always, let's start with a few imports:","d2c052cd":"Seems like the predictions are pretty accurate!","33c68a0f":"Let's write a function to show the training stats:","58808cc5":"Next, let's see what kind if data we have:","cb746e01":"# Read the data\nWe set some parameters and write a function to read the data","1bfdc73f":"Coins 0-18 will be our training set. We'll use the next 4 coins for validation, and we'll use the last coin (XRP) for testing ","a87c1d2c":"A bit of overfitting at the end, but it doesn't seem to be too bad. In retrospect, one or two epochs should be enough.\n\nNow that the model is trained, we can use it to predict the test data:","6682e906":"# LSTM model\nWe build a model based on the LSTM architecture to model the data"}}