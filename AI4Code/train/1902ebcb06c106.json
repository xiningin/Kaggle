{"cell_type":{"d90303e7":"code","aba8ba4f":"code","8ab450cc":"code","e35feb51":"code","c01897c9":"code","80f68e56":"code","6e720fc4":"code","14ce0379":"code","4304dfc2":"code","466713d3":"code","a767f3ef":"code","bfca835c":"code","bb892778":"code","ae6f9fb7":"code","898346fe":"code","25d844f1":"code","7ded7d77":"code","2d417d5e":"code","563dad51":"code","1a0fe0bf":"code","59b05a32":"code","55e76817":"code","b974fb9f":"code","ea4ac1e1":"code","dc71cee3":"code","d50a3cf3":"code","66ad0305":"code","c3a8078e":"code","26984927":"code","bb351a01":"code","29ba9b69":"code","6b13d80c":"code","ebf86f26":"code","a37bb01b":"code","e0b65953":"code","8c36f6a9":"markdown","c142a6f2":"markdown","811406a7":"markdown","5c76417a":"markdown","bc97daf7":"markdown","c3b3fc08":"markdown","846c7ae7":"markdown","1413b194":"markdown","73034698":"markdown","6fa84130":"markdown"},"source":{"d90303e7":"import shutil\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.random import set_seed\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","aba8ba4f":"with_mask_images = os.listdir(\"..\/input\/data\/with_mask\")\nwithout_mask_images = os.listdir(\"..\/input\/data\/without_mask\")","8ab450cc":"len(with_mask_images), len(without_mask_images)","e35feb51":"os.mkdir(\".\/train\")\nos.mkdir(\".\/train\/with_mask\")\nos.mkdir(\".\/val\")\nos.mkdir(\".\/val\/with_mask\")\nos.mkdir(\".\/test\")\nos.mkdir(\".\/test\/with_mask\")\n\n\nos.mkdir(\".\/train\/without_mask\")\nos.mkdir(\".\/val\/without_mask\")\nos.mkdir(\".\/test\/without_mask\")\n\nwith_mask_train_len = int(np.round(0.7 * len(with_mask_images),0))\nwith_mask_val_len = int(np.round(0.85 * len(with_mask_images),0))\n\nfor i in range(with_mask_train_len):\n    shutil.copy(os.path.join(\"..\/input\/data\/with_mask\",with_mask_images[i]),\".\/train\/with_mask\")\n    \nfor i in range(with_mask_train_len,with_mask_val_len):\n    shutil.copy(os.path.join(\"..\/input\/data\/with_mask\",with_mask_images[i]),\".\/val\/with_mask\")\n    \nfor i in range(with_mask_val_len,len(with_mask_images)):\n    shutil.copy(os.path.join(\"..\/input\/data\/with_mask\",with_mask_images[i]),\".\/test\/with_mask\")\n\nwithout_mask_train_len = int(np.round(0.7 * len(without_mask_images),0))\nwithout_mask_val_len = int(np.round(0.85 * len(without_mask_images),0))\n\nfor i in range(without_mask_train_len):\n    shutil.copy(os.path.join(\"..\/input\/data\/without_mask\",without_mask_images[i]),\".\/train\/without_mask\")\n    \nfor i in range(without_mask_train_len,without_mask_val_len):\n    shutil.copy(os.path.join(\"..\/input\/data\/without_mask\",without_mask_images[i]),\".\/val\/without_mask\")\n    \nfor i in range(without_mask_val_len,len(without_mask_images)):\n    shutil.copy(os.path.join(\"..\/input\/data\/without_mask\",without_mask_images[i]),\".\/test\/without_mask\")","c01897c9":"PATH_TRAIN_MASK = \".\/train\/with_mask\"\nPATH_VAL_MASK = \".\/val\/with_mask\"\nPATH_TEST_MASK = \".\/test\/with_mask\"\n\nPATH_TRAIN_NO_MASK = \".\/train\/without_mask\"\nPATH_VAL_NO_MASK = \".\/val\/without_mask\"\nPATH_TEST_NO_MASK = \".\/test\/without_mask\"\n\nPATH_TRAIN = \".\/train\"\nPATH_VAL = \".\/val\"\nPATH_TEST = \".\/test\"","80f68e56":"print(f'With Mask Train: {len(os.listdir(PATH_TRAIN_MASK))}\\n\\\nWith Mask Validation: {len(os.listdir(PATH_VAL_MASK))}\\n\\\nWith Mask Test: {len(os.listdir(PATH_TEST_MASK))}\\n\\\nWith Mask Total: {len(os.listdir(PATH_TRAIN_MASK))+len(os.listdir(PATH_VAL_MASK))+len(os.listdir(PATH_TEST_MASK))}')","6e720fc4":"print(f'Without Mask Train: {len(os.listdir(PATH_TRAIN_NO_MASK))}\\n\\\nWithout Mask Validation: {len(os.listdir(PATH_VAL_NO_MASK))}\\n\\\nWithout Mask Test: {len(os.listdir(PATH_TEST_NO_MASK))}\\n\\\nWithout Mask Total: {len(os.listdir(PATH_TRAIN_NO_MASK))+len(os.listdir(PATH_VAL_NO_MASK))+len(os.listdir(PATH_TEST_NO_MASK))}')","14ce0379":"(any(pd.Series(os.listdir(PATH_TRAIN_MASK)).str.contains(\"without\")), any(pd.Series(os.listdir(PATH_VAL_MASK)).str.contains(\"without\")),\nany(pd.Series(os.listdir(PATH_TEST_MASK)).str.contains(\"without\")))","4304dfc2":"(any(pd.Series(os.listdir(PATH_TRAIN_NO_MASK)).str.contains(\"with_\",regex=False)), any(pd.Series(os.listdir(PATH_VAL_NO_MASK)).str.contains(\"with_\",regex=False)),\nany(pd.Series(os.listdir(PATH_TEST_NO_MASK)).str.contains(\"with_\",regex=False)))","466713d3":"train_mask_files = os.listdir(PATH_TRAIN_MASK)\ntrain_no_mask_files = os.listdir(PATH_TRAIN_NO_MASK)","a767f3ef":"rows=20 #rows in subplots\ncols=5 #columns in subplots\n\nfig,ax = plt.subplots(rows,cols,figsize=(12,100))\nr = 0\nc = 0\nfor i in range(rows*cols):\n    aa = plt.imread(os.path.join(PATH_TRAIN_NO_MASK,train_no_mask_files[i]))\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa)\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\nplt.show()","bfca835c":"rows=20 #rows in subplots\ncols=5 #columns in subplots\n\nfig,ax = plt.subplots(rows,cols,figsize=(12,100))\nr = 0\nc = 0\nfor i in range(rows*cols):\n    aa = plt.imread(os.path.join(PATH_TRAIN_MASK,train_mask_files[i]))\n    ax[r,c].axis(\"off\")\n    ax[r,c].imshow(aa)\n    c+=1\n    if c == cols:\n        c=0\n        r+=1\nplt.show()","bb892778":"for i in range(len(train_mask_files)):\n    train_image_shape = plt.imread(os.path.join(PATH_TRAIN_MASK,train_mask_files[i])).shape\n    if i==0:\n        width = train_image_shape[0]\n        height = train_image_shape[1]\n    else:\n        width = np.append(width,train_image_shape[0])\n        height = np.append(height,train_image_shape[1])\n        \nfor i in range(len(train_no_mask_files)):\n    train_image_shape = plt.imread(os.path.join(PATH_TRAIN_NO_MASK,train_no_mask_files[i])).shape\n    width = np.append(width,train_image_shape[0])\n    height = np.append(height,train_image_shape[1])","ae6f9fb7":"sns.jointplot(width[width<400][:(min(len(width[width<400]),len(height[height<400])))],height[height<400][:(min(len(width[width<400]),len(height[height<400])))])\nplt.xlabel(\"Width\")\nplt.ylabel(\"Height\");","898346fe":"train_data_gen = ImageDataGenerator(rotation_range=30,\n                                    width_shift_range=0.02,\n                                    height_shift_range=0.02,\n                                    zoom_range=[0.8,1.2],\n                                    horizontal_flip=True,\n                                    rescale=1\/255\n                                   )\n\nval_data_gen = ImageDataGenerator(rescale=1\/255)\ntest_data_gen = ImageDataGenerator(rescale=1\/255)","25d844f1":"fig,ax = plt.subplots(1,5,figsize=(15,15))\nr = random.sample(range(len(train_mask_files)),1)[0]\nax[0].imshow(plt.imread(os.path.join(PATH_TRAIN_MASK,train_mask_files[r])))\nax[0].set_title(\"Original\")\nax[0].axis(\"off\")\nfor i in range(1,5):\n    ax[i].imshow(train_data_gen.random_transform(plt.imread(os.path.join(PATH_TRAIN_MASK,train_mask_files[r]))))\n    ax[i].set_title(\"Augmented\")\n    ax[i].axis(\"off\")\nplt.show()","7ded7d77":"fig,ax = plt.subplots(1,5,figsize=(15,15))\nr = random.sample(range(len(train_no_mask_files)),1)[0]\nax[0].imshow(plt.imread(os.path.join(PATH_TRAIN_NO_MASK,train_no_mask_files[r])))\nax[0].set_title(\"Original\")\nax[0].axis(\"off\")\nfor i in range(1,5):\n    ax[i].imshow(train_data_gen.random_transform(plt.imread(os.path.join(PATH_TRAIN_NO_MASK,train_no_mask_files[r]))))\n    ax[i].set_title(\"Augmented\")\n    ax[i].axis(\"off\")\nplt.show()","2d417d5e":"set_seed(11)\nrandom.seed(11)\nnp.random.seed(11)\nBATCH_SIZE = 32\ntraining_data = train_data_gen.flow_from_directory(PATH_TRAIN,\n                                                   target_size=(200,200),\n                                                   color_mode=\"rgb\",\n                                                   class_mode=\"binary\",\n                                                   batch_size=BATCH_SIZE,\n                                                   seed=11)\n\nval_data = val_data_gen.flow_from_directory(PATH_VAL,\n                             target_size=(200,200),\n                             color_mode=\"rgb\",\n                             class_mode=\"binary\",\n                             batch_size=BATCH_SIZE,\n                             seed=11,shuffle=False)\n\ntest_data = test_data_gen.flow_from_directory(PATH_TEST,\n                             target_size=(200,200),\n                             color_mode=\"rgb\",\n                             class_mode=\"binary\",\n                             batch_size=BATCH_SIZE,\n                             seed=11,shuffle=False)","563dad51":"training_data.class_indices","1a0fe0bf":"training_data.image_shape","59b05a32":"random.seed(11)\nset_seed(11)\nnp.random.seed(11)\n\nINPUT_SHAPE = training_data.image_shape\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64,kernel_size=3,strides=1,activation=\"relu\",input_shape=INPUT_SHAPE))\nmodel.add(Conv2D(filters=64,kernel_size=3,strides=1,activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n\nmodel.add(Conv2D(filters=128,kernel_size=3,strides=1,activation=\"relu\"))\nmodel.add(Conv2D(filters=128,kernel_size=3,strides=1,activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n\nmodel.add(Conv2D(filters=256,kernel_size=3,strides=1,activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n\nmodel.add(Conv2D(filters=512,kernel_size=3,strides=1,activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding=\"same\"))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units=512,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=1024,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=1,activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"binary_accuracy\"])","55e76817":"early_stop = EarlyStopping(monitor=\"val_loss\",patience=4,mode=\"min\") #Ensure the model doesn't overfit","b974fb9f":"random.seed(11)\nset_seed(11)\nnp.random.seed(11)\nhistory = model.fit(training_data,batch_size=32,epochs=500,callbacks=early_stop,validation_data=val_data)","ea4ac1e1":"#Dataframe capturing the accuracy and loss per epoch\nloss_df = pd.DataFrame(history.history)\nloss_df","dc71cee3":"loss_df.plot();","d50a3cf3":"test_data.class_indices","66ad0305":"model.evaluate(test_data)","c3a8078e":"prediction = model.predict(test_data).flatten()","26984927":"print(prediction)","bb351a01":"prediction = np.round(prediction) #rounding so that the prediction >0.5 becones 1 and everything else becomes 0","29ba9b69":"prediction","6b13d80c":"y_test = test_data.classes","ebf86f26":"sns.heatmap(confusion_matrix(y_test,prediction),annot=True,cbar=False,fmt=\"d\")\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Actual\");","a37bb01b":"print(classification_report(y_test,prediction))","e0b65953":"shutil.rmtree(PATH_TRAIN)\nshutil.rmtree(PATH_VAL)\nshutil.rmtree(PATH_TEST)","8c36f6a9":"The cell below creates 3 folders 'train', 'val' and 'test' and splits the images with and without masks in the ratio 0.7:0.15:0.15 respectively. ","c142a6f2":"Below is the number of images in train, validaton, and test set","811406a7":"Since the images have varied width and height, the below code stores the weight and height of all the images in an array","5c76417a":"Let's look at few images without masks. This helps us in image augmentation","bc97daf7":"<h1>0: With_mask<\/h1>\n<h1>1: Without_mask<\/h1>","c3b3fc08":"Ensuring that the folders having images with mask don't have any image having 'without' in their names.\n\nFalse indicates no image filename has without in it","846c7ae7":"<h1>FACE MASK DETECTION WITHOUT TRANSFER LEARNING","1413b194":"As we can see from the above plot, most of the images have a height between 170 and 230, while width between 180 and 270. Also there are good number of images of smaller size. Hence, we'll select an image size of 200x200","73034698":"Ensuring that the folders having images without mask don't have any image having 'with_' in their names","6fa84130":"Below we can see the results of the image augmentation"}}