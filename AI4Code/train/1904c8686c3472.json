{"cell_type":{"bfa8fbe3":"code","427ad2d9":"code","c5bb2d96":"code","7eacdaa3":"code","6efa10f7":"code","e7cb70ef":"code","939accb7":"code","66459701":"code","8254a2c8":"code","781a21e6":"code","e5af94e0":"code","3c6c3021":"code","8f220442":"code","7a5a682c":"code","c63a6b48":"code","e8db9732":"code","b2400bb5":"code","eb5bc671":"code","dca44570":"code","9acab399":"code","3236ec2a":"code","619f8729":"code","6f950994":"code","597cfef7":"code","d905bf83":"code","0121ff0d":"code","73bf596a":"code","a3a23d22":"code","b9c88971":"code","010305e3":"markdown","b30c2fb8":"markdown","fda91ab6":"markdown","8186e302":"markdown","b62a6ab3":"markdown","61934ff8":"markdown","8d7654cd":"markdown","b66f4f37":"markdown","4f22612f":"markdown","99a20972":"markdown","1065b353":"markdown","9d304a84":"markdown","f2d21d48":"markdown","28abe57e":"markdown","d930a13d":"markdown","b7366e21":"markdown","6c85fcf5":"markdown","db46bd9b":"markdown"},"source":{"bfa8fbe3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","427ad2d9":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport PIL\nimport cv2\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow_addons as tfadd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import InceptionResNetV2","c5bb2d96":"train_data = pd.read_csv('\/kaggle\/input\/plant-pathology-2021-fgvc8\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\nTRAIN_IMG_DIR = '..\/input\/plant-pathology-2021-fgvc8\/train_images\/'\nTEST_IMG_DIR = '..\/input\/plant-pathology-2021-fgvc8\/test_images\/'","7eacdaa3":"labels = train_data.labels.unique()\nvalue_counts = train_data['labels'].value_counts()","6efa10f7":"plt.figure(figsize=(10, 6))\nplt.xticks(rotation=90)\nplt.title(\"Comparison of Different Labels\")\nsns.barplot(x=labels, y=value_counts)","e7cb70ef":"IMG_SIZE = 250\n\nfor i in range(0, 100, 10):\n    img_array = cv2.imread(TRAIN_IMG_DIR + train_data['image'][i])\n    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    plt.imshow(new_array)\n    plt.title(train_data['labels'][i])\n    plt.show()","939accb7":"dummy_train_data = train_data\ndummy_train_data = dummy_train_data['labels'].str.split(\" \", expand=True).stack()\nlabel_dummies = pd.get_dummies(dummy_train_data).groupby(level=0).sum()","66459701":"label_dummies.head()","8254a2c8":"cols = label_dummies.columns\nlabel_counts = label_dummies[cols].sum()","781a21e6":"plt.figure(figsize=(10, 6))\nplt.title(\"Comparison of all unique Labels\")\nsns.barplot(x=cols, y=label_counts)","e5af94e0":"train_data['labels'] = train_data['labels'].str.split(\" \")\n\ndatagen = ImageDataGenerator(rescale=1.\/255, validation_split=0.1)\nfinal_train_data = datagen.flow_from_dataframe(train_data,\n    directory='\/kaggle\/input\/resized-plant2021\/img_sz_512',\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    subset=\"training\")","3c6c3021":"validation_data = datagen.flow_from_dataframe(train_data,\n    directory='\/kaggle\/input\/resized-plant2021\/img_sz_512',\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    subset=\"validation\")","8f220442":"weights = '..\/input\/keras-pretrained-models\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npretrained_weight_model = InceptionResNetV2(\n    include_top=False,\n    weights=weights,\n    input_shape=(256, 256, 3)\n)","7a5a682c":"pretrained_weight_model.input\npretrained_weight_model.output","c63a6b48":"final_model = Sequential([\n    pretrained_weight_model,\n    GlobalAveragePooling2D(),\n    Dense(units=6, activation = 'sigmoid')\n])\n\nfor layer in final_model.layers[:-1]:\n    layer.trainable=False\n\nfinal_model.summary()","e8db9732":"f1_score = tfadd.metrics.F1Score(num_classes=6, average='macro')\n\nearly_stopping = EarlyStopping(monitor=f1_score, patience=3, mode='max', restore_best_weights=True)\n\n\nfinal_model.compile(loss='binary_crossentropy', optimizer=Adam(epsilon=0.01), \n              metrics= [f1_score])\n\nhistory = final_model.fit(final_train_data, epochs=60, \n        callbacks=early_stopping, validation_data=validation_data)","b2400bb5":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()","eb5bc671":"history_frame.loc[:, ['f1_score', 'val_f1_score']].plot();","dca44570":"for i in range(test_data.shape[0]):\n    image_path = TEST_IMG_DIR+'\/'+test_data.image[i]\n    with PIL.Image.open(image_path) as image_data:\n        image_data = image_data.resize((256, 256))\n        image_data.save(f'.\/{test_data.image[i]}')","9acab399":"final_test_data = datagen.flow_from_dataframe(test_data,\n    directory='.\/',\n    x_col=\"image\",\n    y_col=None,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=None,\n    classes=None,\n)","3236ec2a":"pred_data = final_model.predict(final_test_data)\npred_data = pred_data.tolist()","619f8729":"pred_data","6f950994":"index_list = []\n\nfor pred in pred_data:\n    index = []\n    for value in pred:\n        if value >= 0.3:\n            index.append(pred.index(value))\n    if index != []:\n        index_list.append(index)\n    else:\n        index.append(np.argmax(pred))\n        index_list.append(index)","597cfef7":"index_list","d905bf83":"pred_labels = final_train_data.class_indices\npred_labels = dict((value, key) for key, value in pred_labels.items())\n\npred_label_names = []\n\nfor indices in index_list:\n    index = []\n    for i in indices:\n        index.append(str(pred_labels[i]))\n    pred_label_names.append(' '.join(index))","0121ff0d":"pred_label_names","73bf596a":"resized_test_images = tf.io.gfile.glob('.\/*.jpg')\n\nfor image in resized_test_images:\n    os.remove(image)\n\ntest_data['labels'] = pred_label_names\n# test_data.to_csv('submission.csv', index=False)","a3a23d22":"test_data","b9c88971":"final_model.save(\"plant_pathology_2021.h5\")","010305e3":"So far so good. Let's plot the labels and their occurrence in the training images","b30c2fb8":"We have converted the categorical data via dummy variable from pandas","fda91ab6":"Let's create a callback to prevent overfitting\/underfitting","8186e302":"Let's now predict on the test images that we have. Firstly, I will resize the images to 256X256 and then predict the values on it.","b62a6ab3":"## Analysis of scores\n\n1. loss vs f1 score\n2. validation loss vs validation f1 score","61934ff8":"### Take a look at the labels!\n\nAn image may belong to one class or multiple classes. So, in short we have 6 classes of labels. Out of these 6 classes, there are 5 diseases, namely:\n\n* scab\n* complex\n* rust\n* frog eye leaf spot\n* powdery mildew\n\nThe remaining one label is \"healthy\" which is pretty much self explanatory\n\nThis is a multi-label classification problem as one image can represent more than one class of diseases.\n\nLet's have a look at some of the images","8d7654cd":"We might as well look at the individual label comparison with each other. I will create a copy of my training data as I don't want to make changes to original training data","b66f4f37":"The below code is just for model saving purpose as the submission has some time constraints attached to it","4f22612f":"Here are the predicted labels:","99a20972":"# Plant Pathology 2021 - FGVC8\n\n### What is this competition about?\n\nApples are one of the most important temperate fruit crops in the world. Foliar (leaf) diseases pose a major threat to the overall productivity and quality of apple orchards. The current process for disease diagnosis in apple orchards is based on manual scouting by humans, which is time-consuming and expensive.\n\nAlthough computer vision-based models have shown promise for plant disease identification, there are some limitations that need to be addressed. Large variations in visual symptoms of a single disease across different apple cultivars, or new varieties that originated under cultivation, are major challenges for computer vision-based disease identification. These variations arise from differences in natural and image capturing environments, for example, leaf color and leaf morphology, the age of infected tissues, non-uniform image background, and different light illumination during imaging etc.","1065b353":"Now, we will set the data directories for images and datasets","9d304a84":"## Model Creation and Fitting\n\nI will be using InceptionResNetV2 pre-trained model. In addition to this, I will be adding a GlobalAveragePooling2D layer and one last Dense layer with 6 nodes, one for each class with 'sigmoid' as activation, one node for each label(this is a multilabel classification problem)","f2d21d48":"Converting the output values to the indices of labels","28abe57e":"## Problem with the original image size\n\nThe image sizes of all the training images is very high. I encountered two issues due to that:\n\n1. While the model was getting trained, most of the CPU time was used to load the images. Due to that, a single epoch took somewhere around 45 mins. GPU was getting used but the main lag was due to the CPU which was busy loading the images from the dataset\n\n2. When I tried downsizing the images to a lower resolution, my RAM got used fully and I was not able to continue ahead. Plus, it also took a lot of time to downsize 18632 images.\n\nTherefore, I will be using a resized images dataset ([link to the dataset](https:\/\/www.kaggle.com\/ankursingh12\/resized-plant2021))\n\nAlso, we need the labels of training data in a comma separated fashion","d930a13d":"##  F1 score as metrics\n\nSince it is a multilabel image classification, I will be going for F1 accuracy instead of binary accuracy in macro mode. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally)","b7366e21":"Mapping the labels back to the disease names","6c85fcf5":"### Let's import some libraries!","db46bd9b":"We have our predicted labels. Now the final step is the submission of our predicted labels"}}