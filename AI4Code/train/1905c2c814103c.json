{"cell_type":{"300fc58e":"code","76a3c9df":"code","b3772ad0":"code","530ece8a":"code","d424a40c":"code","936f03ff":"code","a4e6a96a":"code","2faaa672":"code","afc5ebf5":"code","35e01341":"code","f838a06f":"code","f941f8bc":"code","99b43627":"code","21a82651":"code","0540c517":"code","c8cf7773":"markdown","d8c34cd3":"markdown","00815d62":"markdown","75ead68f":"markdown","102f938c":"markdown","63912354":"markdown","b1b32bf5":"markdown","d0e4021e":"markdown","37095b3a":"markdown","97ace042":"markdown","258bd783":"markdown","76bf30a7":"markdown","e8aaae71":"markdown","35393d1d":"markdown","1c682d5c":"markdown","a8f7e45b":"markdown","bdeadb39":"markdown","43a7db45":"markdown","2328200a":"markdown","82a15932":"markdown"},"source":{"300fc58e":"#\u00a0Data loading and processing\nimport pandas as pd \n\n#\u00a0Plotting\nimport matplotlib.pylab as plt\nimport seaborn as sns","76a3c9df":"#\u00a0Some setup\nsns.set(font_scale=1.5)\nMETA_DATASETS_PATH = \"..\/input\/all_kaggle_datasets.csv\"","b3772ad0":"meta_datasets_df = pd.read_csv(META_DATASETS_PATH)","530ece8a":"_dfs = []\nfor datasetId, category_row in meta_datasets_df.set_index(\"datasetId\")[\"categories\"].iteritems():\n    #\u00a0Each category_dict has two keys: \"categories\" and \"type\". Notice that the \"type\" column is always equal to \"dataset\"\n    #\u00a0so will ignore it (doesn't add anything).\n    category_dict = eval(category_row)\n    #\u00a0A list of categories\n    categories = category_dict[\"categories\"]\n    _df = pd.DataFrame(categories)\n    _df[\"datasetId\"] = datasetId \n    if category_dict[\"type\"] != \"dataset\":\n        print(category_dict[\"type\"])\n    _dfs.append(_df)\ncategories_df = pd.concat(_dfs, sort=False)","d424a40c":"categories_df.head(1).T","936f03ff":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\ncategories_df.groupby(\"name\").size().nlargest(10).plot(kind='bar', ax=ax)\nax.set_ylabel(\"Number of datasets\")\nax.set_xlabel(\"Categories\")","a4e6a96a":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\ncategories_df.groupby(\"name\")[\"totalCount\"].sum().nlargest(10).plot(kind='bar', ax=ax)\nax.set_ylabel(\"Total count\")\nax.set_xlabel(\"Categories\")","2faaa672":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n(meta_datasets_df.assign(date=lambda df: pd.to_datetime(df[\"dateUpdated\"]))\n                 .set_index('date')\n                 .resample('1M')\n                 .size()\n                 .plot(ax=ax)\n)\n\nax.set_ylabel(\"Number of datasets per month\")\n\n","afc5ebf5":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n(meta_datasets_df.assign(date=lambda df: pd.to_datetime(df[\"dateUpdated\"]))\n                 .set_index('date')\n                 .resample('1M')\n                 .size()\n                 .cumsum()\n                 .plot(ax=ax)\n)","35e01341":"\"The number of unique datasets as of {} is {}\".format(meta_datasets_df.dateUpdated.max(), meta_datasets_df.datasetId.nunique())","f838a06f":"from scipy.optimize import curve_fit\nimport numpy as np\n\n\ndef exp_f(x, a, b, c):\n    return a*np.exp(b*x)+c\n\nto_fit_s = (meta_datasets_df.assign(date=lambda df: pd.to_datetime(df[\"dateUpdated\"]))\n                            .set_index('date')\n                            .resample('1M')\n                            .size()\n                            .cumsum())\n\nx = range(0, len(to_fit_s))\ny = to_fit_s.values\n\nfitted_params, covariance = curve_fit(exp_f, x, y, p0=(1, 1, 0))\nfitted_s = pd.Series(exp_f(x, *fitted_params), index=to_fit_s.index)","f941f8bc":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nfitted_s.plot(ax=ax, label='Fitted', style='o--')\nto_fit_s.plot(ax=ax, label='Original', style='o-')\nax.legend()\nax.set_ylabel(\"Cumulative number of datasets\")","99b43627":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nday_of_week_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n(meta_datasets_df.assign(date=lambda df: pd.to_datetime(df[\"dateUpdated\"]))\n                 .assign(day_of_week=lambda df: df.date.dt.day_name())\n                 .groupby(\"day_of_week\")\n                 .size()\n                 .loc[day_of_week_order]\n                 .plot(kind='bar', ax=ax))","21a82651":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n(meta_datasets_df.assign(date=lambda df: pd.to_datetime(df[\"dateUpdated\"]))\n                 .assign(month=lambda df: df.date.dt.month)\n                 .groupby(\"month\")\n                 .size()\n                 .plot(kind='bar', ax=ax))","0540c517":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n(meta_datasets_df.groupby(\"creatorName\")[\"datasetId\"]\n                 .count()\n                 .nlargest(10)\n                 .plot(kind='bar', ax=ax)\n)\nax.set_xlabel(\"Creator's name\")\nax.set_ylabel(\"Number of datasets\")","c8cf7773":"Alright. Is it possible to fit a \"line\" to the above curve? The answer is yes using \nthe [`curve_fit`](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.optimize.curve_fit.html) function from `scipy`.","d8c34cd3":"Here is the same time series as above but with the **cumulative** number of datasets over time.","00815d62":"From the above timeseries it seems that: \n\n1. there are more and more datasets each month.\n2. datasets as a Kaggle feature have started to gather momentum somewhere around August 2017.","75ead68f":"##\u00a0Top 10 categories (by number of datasets)","102f938c":"#\u00a0Load the data","63912354":"#\u00a0Parse the `categories` column","b1b32bf5":"## Number of datasets per month","d0e4021e":"More datasets during the week days than during the weekend it seems. Notice that for the above graph to be \ncorrect, I have assumed that the `dateUpdated` column is in the same timezone (UTC).","37095b3a":"As you have noticed, the `categories` column is a dictionnary. Let's flatten this column and store it in a separate DataFrame.\nThis new DataFrame could be easily merged with the original one using the `datasetId` column.","97ace042":"#\u00a0Top dataset creators","258bd783":"Let's display the 10 top dataset creators.","76bf30a7":"The above time series looks correct. :)","e8aaae71":"## Number of datasets per day of week","35393d1d":"In what follows, I will explore the evolution of the number of datasets over time. \nTo make things more readable, I have resampled (using Pandas' [resample](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.resample.html) method) the dates to \na frequency of one point per month. ","1c682d5c":"Not bad! \n\nFinally, is there a day of week or a month where datasets are the most uploaded? Let's find out!","a8f7e45b":"## Top 10 categories (by total count)","bdeadb39":"#\u00a0Cumulative number of datasets curve fitting","43a7db45":"So far it seems that July (month number 7) is the one with the biggest number of datasets. \nThis result might change once the August (and subsequent months) results are added.","2328200a":"#\u00a0Evolution of number of datasets per year and month","82a15932":"Welcome to the Kaggle's datasets EDA notebook! \n\nHere you will find some insights about Kaggle's datasets: from top categories to evolution of \ndatasets over time.\n\nDon't forget to leave comments and\/orsuggestions.\nEnjoy!"}}