{"cell_type":{"26e8421f":"code","536e5ef1":"code","276c9de9":"code","8f704946":"code","149d25ab":"code","10969d7e":"code","88f50e45":"code","dd561b74":"code","5c803e07":"code","38efe4fb":"code","4b46cc05":"code","0f2812e1":"code","8f41e670":"code","189cdb32":"code","5ca89cd4":"code","cf56edd2":"code","9bad7f3e":"code","65de383b":"code","21de4f9c":"markdown","050ba478":"markdown","166e152c":"markdown","538639da":"markdown","f910ff3f":"markdown","823985ad":"markdown","b04802d1":"markdown","02557357":"markdown","e44a7d41":"markdown","d0da9b6d":"markdown","bf57b83a":"markdown","2f63a812":"markdown","2f6e57ec":"markdown","8c866ef7":"markdown"},"source":{"26e8421f":"import pandas as pd\nimport numpy as np\nimport os.path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom PIL import Image\n\n%matplotlib inline\nfrom keras.applications import ResNet50,ResNet101\nimport cv2\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\nfrom keras import applications\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing import image","536e5ef1":"from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","276c9de9":"train = pd.read_csv('\/kaggle\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train.csv')\ntrain.head()","8f704946":"# As we are going to divide dataset\ndf = train.copy()","149d25ab":"# Increasing the size of dataset without disturbing their corresponding ratios \n\nMisce = train[train[\"Class\"]=='Miscellaneous']\nChris_tree = train[train[\"Class\"]=='Christmas_Tree']\nJacket = train[train[\"Class\"]=='Jacket']\nCandle = train[train[\"Class\"]=='Candle']\nAirplane = train[train[\"Class\"]=='Airplane']\nSnowman = train[train[\"Class\"]=='Snowman']\n\ndf = pd.concat([df,Misce])\ndf = pd.concat([df,Chris_tree])\ndf = pd.concat([df,Jacket])\ndf = pd.concat([df,Candle])\ndf = pd.concat([df,Airplane])\ndf = pd.concat([df,Snowman])","10969d7e":"TRAIN_PATH = '..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train'\nTEST_PATH = '..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/test'","88f50e45":"def get_model(IMG_SIZE):\n    base_model =applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    add_model = Sequential()\n    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n    add_model.add(Dropout(0.3))\n    add_model.add(Dense(64, activation='relu'))\n    add_model.add(Dropout(0.4))\n\n    add_model.add(Dense(6, activation='softmax'))\n\n    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n                  metrics=['accuracy'])\n    return model\n#     model.summary()","dd561b74":"# Storing the average of all predictions\n\nmain_pred = []\ndata_kfold = pd.DataFrame()","5c803e07":"# Creating X, Y for training \n\ntrain_y = df.Class\ntrain_x = df.drop(['Class'],axis=1)","38efe4fb":"IMG_SIZE = 128\nBATCH_SIZE = 16\nEPOCHS = 10\nN_SPLIT = 7","4b46cc05":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\nvalidation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\n\nkfold = StratifiedKFold(n_splits=N_SPLIT,shuffle=True,random_state=42)\nj = 0\nfor train_idx, val_idx in list(kfold.split(train_x,train_y)):\n    x_train_df = df.iloc[train_idx]\n    x_valid_df = df.iloc[val_idx]\n    j+=1\n\n\n    training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, directory=TRAIN_PATH,\n                                                 x_col=\"Image\", y_col=\"Class\",\n                                                 class_mode=\"categorical\",\n                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n    \n    validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df, directory=TRAIN_PATH,\n                                                 x_col=\"Image\", y_col=\"Class\",\n                                                 class_mode=\"categorical\",\n                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=BATCH_SIZE)\n    \n    model_test = get_model(IMG_SIZE)\n    \n    \n    history = model_test.fit_generator( training_set,\n                                        validation_data=validation_set,\n                                        epochs = EPOCHS,\n                                        steps_per_epoch=x_train_df.shape[0] \/\/ BATCH_SIZE\n                                        )\n    \n    y_pred = []\n    name = []                      \n    labels = (training_set.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    for i in os.listdir('..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/test\/'):\n        name.append(i)\n        i='..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/test\/'+i\n        img=image.load_img(i,target_size=(IMG_SIZE,IMG_SIZE,3))\n        img=image.img_to_array(img)\/255\n        pred=model_test.predict(img.reshape(1,IMG_SIZE,IMG_SIZE,3))\n        y_pred.append(labels[np.argmax(pred[0])])\n                                       \n    data_kfold[j] = y_pred\n    gc.collect()","0f2812e1":"data_kfold","8f41e670":"gc.collect()","189cdb32":"name = []\nfor i in os.listdir('..\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/test\/'):\n    name.append(i)\nans = pd.DataFrame(name,columns = ['Image'])","5ca89cd4":"ans[\"Class\"] = -1","cf56edd2":"# Taking The Label with Maximum Occurences\n\nimport collections \nfor i in range(len(data_kfold)):\n    co = collections.Counter(data_kfold.loc[i])\n    \n    co = sorted(co.items(),key=lambda x: x[1],reverse=True)\n    ans.Class.loc[i] = co[0][0]","9bad7f3e":"ans","65de383b":"ans.to_csv('Kfold_submission.csv',index=False)","21de4f9c":"## Submission","050ba478":"### **Might Take Too Much of GPU Quota but will give result with less overfitting**","166e152c":"Increase EPOCHS variable if you are going for competition","538639da":"# Please Upvote if it helped YOU ! \ud83d\udc4d\u270c","f910ff3f":"# Creating DataFrame","823985ad":"# Setting Path For Images Folder","b04802d1":"# Initializing Libraries","02557357":"**Used Resnet50.<br>\nAs competition is live. I have left many places to be worked.**","e44a7d41":"# Model","d0da9b6d":"# Training And Predition","bf57b83a":"# Preparation for kfolds","2f63a812":"**I took 7 splits as we have 6 labels and even for worst case at least 1 label will have 2 occurence**","2f6e57ec":"# Another dataset","8c866ef7":"# Getting the Data"}}