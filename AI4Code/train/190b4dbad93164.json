{"cell_type":{"1a7bee36":"code","6c52f224":"code","f4cd774b":"code","d6040a44":"code","624887f3":"code","50f7adfa":"code","fc116080":"code","a7b62a5b":"code","71c0facb":"code","739ab87a":"code","93592c6e":"code","aec7ac51":"code","76114158":"code","48299291":"code","1c6b82f0":"code","42643b19":"code","be8c6f4d":"code","2c36eed7":"code","1eb4ccc1":"code","88a5c174":"code","793ece08":"code","e2a1b58f":"code","8e6e1c8d":"code","39b70754":"code","4fb1b26b":"code","8e536aa7":"code","0b988e7e":"code","eba6ce05":"code","724c1e6d":"code","86cfa13d":"code","865da3cb":"code","248aed73":"code","b8742b94":"code","091f6fde":"code","c7a2a0eb":"code","022b1644":"code","bf4d7386":"code","bbac008b":"code","055af26e":"code","f79eedd4":"code","1d523bcc":"markdown","2006a0b5":"markdown","febfc924":"markdown","912280f8":"markdown","7411a026":"markdown","7666a3c3":"markdown","c0da64aa":"markdown","c259ccfe":"markdown","b2b67341":"markdown","9744f307":"markdown","c5eeaa54":"markdown"},"source":{"1a7bee36":"# import modules\nimport numpy as np \nimport pandas as pd \nimport os\nimport re \n\n# load datasets\ntraining_data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")","6c52f224":"# separate target from predictors in training set\nsurvived_labels = training_data['Survived'].copy()\ntrain = training_data.drop('Survived', axis=1)","f4cd774b":"# create Title\ndef extract_title(name):\n    \"\"\"Given a name from the Name column, extract the title. \n    If it is common return it, else return 'Rare'.\n    \"\"\"\n    try:\n        title = re.search(r',\\s(.+?)\\.', name).groups()[0]\n    except:\n        title = ''\n    \n    if title in [\"Mr\", \"Mrs\", \"Miss\"]:\n        return(title)\n    else:\n        return('Rare')\n        \ntrain['Title'] = train['Name'].map(lambda x: extract_title(x))","d6040a44":"# Create NameLength\ntrain['NameLength'] = train['Name'].map(lambda x: len(x))","624887f3":"# Create NumRelatives\ntrain['NumRelatives'] = train['SibSp'] + train['Parch']","50f7adfa":"# Create FarePerPerson\ntrain['count'] = 1\ngroup = train[['Ticket','Fare','count']].groupby('Ticket').sum()\ngroup['Fare'] = group['Fare']\/group['count']\ngroup['FarePerPerson'] = (group['Fare'])\/group['count']\n\ndef map_fare_perperson(ticket):\n    \"\"\"Counts people per tickets and divides the fare per number of people in a ticket.\n    Uses the group helper table with aggregated results.\n    \"\"\"\n\n    row_names=np.array(list(group.index.values))\n    loc=np.where(row_names == ticket)[0][0]\n    \n    return(group['FarePerPerson'][loc:loc+1][0])\n\ntrain['FarePerPerson'] = train['Ticket'].map(lambda x: map_fare_perperson(x))","fc116080":"# Create Deck \ndef clean_cabin(x):\n    \"\"\"Extract the Deck information, first letter only, \n    Limit to six groups, A through F, binning other decks to F.\n    \"\"\"\n    \n    letter=x[0]\n    \n    if letter not in 'ABCDEF':\n        letter='F'\n        \n    return(letter)\n    \ntrain['Deck']=train['Cabin'].map(lambda x: clean_cabin(x), na_action='ignore')","a7b62a5b":"# Embarked\n# impute two missing with majority class\ntrain['Embarked']=train['Embarked'].fillna('S')","71c0facb":"# Age\n# impute with group medians given gender, passenger class, and title\ntrain['Age'] = train.groupby(['Sex', 'Pclass','Title'])['Age'].\\\n                             transform(lambda x: x.fillna(x.median()))","739ab87a":"# Sex\ntrain['IsMale'] = pd.get_dummies(train['Sex'])['male']","93592c6e":"# Embarked\ntrain['Embarked_S']=pd.get_dummies(train['Embarked'])['S']\ntrain['Embarked_Q']=pd.get_dummies(train['Embarked'])['Q']","aec7ac51":"# Title\ntrain['Title_Mr']=pd.get_dummies(train['Title'])['Mr']\ntrain['Title_Mrs']=pd.get_dummies(train['Title'])['Mrs']\ntrain['Title_Miss']=pd.get_dummies(train['Title'])['Miss']","76114158":"# Pclass\ntrain['Pclass_1']=pd.get_dummies(train['Pclass'])[1]\ntrain['Pclass_2']=pd.get_dummies(train['Pclass'])[2]","48299291":"# Deck\ntrain['Deck'].fillna('None') # create a None category for NA values\ntrain['Deck_A']=pd.get_dummies(train['Deck'])['A']\ntrain['Deck_B']=pd.get_dummies(train['Deck'])['B']\ntrain['Deck_C']=pd.get_dummies(train['Deck'])['C']\ntrain['Deck_D']=pd.get_dummies(train['Deck'])['D']\ntrain['Deck_E']=pd.get_dummies(train['Deck'])['E']\ntrain['Deck_F']=pd.get_dummies(train['Deck'])['F']","1c6b82f0":"# drop unwanted, redundant columns\ntrain.drop(['PassengerId', 'Pclass','Name','Sex','SibSp','Parch','Ticket','Fare',\n            'Cabin','count','Embarked','Title','Deck'], axis=1, inplace=True)","42643b19":"# scale Age, NameLength, NumRelatives, FarePerPerson\ndef minmax_scale(X):\n    \n    def scale(X, x):\n        return((x - min(X)) \/ (max(X) - min(X)))\n        \n    return(X.map(lambda x: scale(X, x)))\n\ndef std_scale(X):\n\n    def scale(X, x):\n        return((x - np.mean(X)) \/ np.std(X))\n\n    return(X.map(lambda x: scale(X, x)))\n    \n    \ntrain['Age_minmax'] = minmax_scale(train['Age'])\ntrain['Age_std'] = std_scale(train['Age'])\ntrain['NameLength_minmax'] = minmax_scale(train['NameLength'])\ntrain['NameLength_std'] = std_scale(train['NameLength'])\ntrain['NumRelatives_minmax'] = minmax_scale(train['NumRelatives'])\ntrain['NumRelatives_std'] = std_scale(train['NumRelatives'])\ntrain['FarePerPerson_minmax'] = minmax_scale(train['FarePerPerson'])\ntrain['FarePerPerson_std'] = std_scale(train['FarePerPerson'])","be8c6f4d":"# comparing min-max and standard scaling\n%matplotlib inline\n\nfrom matplotlib import pyplot as plt\n\ndef plot_all(x, std_x, mm_x, y, std_y, mm_y, title):\n    \n    plt.figure(figsize=(14,8))\n    plt.scatter(x, y, \n                color='green', alpha=0.4,\n                label='original scale')\n    plt.scatter(std_x, std_y, \n                color='red', alpha=0.2,\n                label='standardized [$N(\\mu=0, \\; \\sigma=1)$]')\n    plt.scatter(mm_x, mm_y, \n                color='blue', alpha=0.2,\n                label='min-max scaled [min=0, max=1]')\n    plt.title(title, fontsize=16)\n    plt.xlabel(title.split('and')[0], fontsize=14) \n    plt.ylabel(title.split('and')[1], fontsize=14)\n    plt.legend(loc='upper right')\n    plt.tight_layout()\n\ndef plot_scaled(x, std_x, mm_x, y, std_y, mm_y, title):\n    \n    plt.figure(figsize=(5,5))\n    plt.scatter(std_x, std_y, \n                color='red', alpha=0.2,\n                label='standardized [$N(\\mu=0, \\; \\sigma=1)$]')\n    plt.scatter(mm_x, mm_y, \n                color='blue', alpha=0.2,\n                label='min-max scaled [min=0, max=1]')\n    plt.title('Scaled Features', fontsize=12)\n    plt.xlabel(title.split('and')[0])\n    plt.ylabel(title.split('and')[1])\n    plt.legend(loc='upper right')\n    plt.tight_layout()","2c36eed7":"plot_all(train['Age'],train['Age_std'],train['Age_minmax'],\n         train['NumRelatives'],train['NumRelatives_std'],train['NumRelatives_minmax'],\n        'Age and Number of Relatives')\n\nplt.show()\n\nplot_scaled(train['Age'],train['Age_std'],train['Age_minmax'],\n         train['NumRelatives'],train['NumRelatives_std'],train['NumRelatives_minmax'],\n        'Age and Number of Relatives')\n\nplt.show()","1eb4ccc1":"plot_all(train['NameLength'],train['NameLength_std'],train['NameLength_minmax'],\n         train['FarePerPerson'],train['FarePerPerson_std'],train['FarePerPerson_minmax'],\n        'Name Length and Fare Per Person')\n\nplt.show()\n\nplot_scaled(train['NameLength'],train['NameLength_std'],train['NameLength_minmax'],\n         train['FarePerPerson'],train['FarePerPerson_std'],train['FarePerPerson_minmax'],\n        'Name Length and Fare Per Person')\n\nplt.show()","88a5c174":"# drop unscaled and standard scaled features\ntrain.drop(['Age', 'NameLength','FarePerPerson','NumRelatives','Age_std',\n            'NameLength_std','FarePerPerson_std','NumRelatives_std'], axis=1, inplace=True)","793ece08":"train.head(10)","e2a1b58f":"# convert to numpy arrays\ntrain_processed = train.to_numpy()\ntrain_labels = survived_labels.to_numpy()","8e6e1c8d":"from sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state=42)\n\n# using first 80% of the training set\ntrain_subset = train_processed[:700]\nlabels_subset = train_labels[:700]\n\n# training first model\nsgd_clf.fit(train_subset, labels_subset)","39b70754":"def predict_SGD(data, labels):\n    \"\"\"Make predictions using our SGD classifier and print the accuracy\n    \"\"\"\n    \n    predictions = sgd_clf.predict(data)\n    results = pd.DataFrame({'preds': predictions,\n                            'labels':labels})\n\n    results['accurate'] = 0\n    for i in range(0, len(results)):\n        if results['labels'][i:i+1].values == results['preds'][i:i+1].values:\n            results['accurate'][i:i+1] = 1\n        else:\n            pass\n    \n    accuracy = round(sum(results['accurate'])\/results.shape[0],4)\n    \n    print('number of rows: ' +str(results.shape[0]))\n    print('number of accurate predictions: ' +str(sum(results['accurate'])))\n    print('accuracy: ' +str(accuracy))","4fb1b26b":"# predict on the validation subset (remaining 20%)\nvalidation_data = train_processed[700:]\nvalidation_labels = training_data[700:]['Survived']\n\npredict_SGD(validation_data, validation_labels)","8e536aa7":"# predict on original 80% of training for comparison\noriginal_data = train_processed[:700]\noriginal_labels = training_data[:700]['Survived']\n\npredict_SGD(original_data, original_labels)","0b988e7e":"# using random shuffling\nfrom sklearn.utils import shuffle\n\nX, y = train_processed, train_labels\n\nnp.random.seed(43)\nshuffled_data, shuffled_labels = shuffle(X, y)\n\nshuffled_data_80pct = shuffled_data[:700]\nshuffled_labels_80pct = shuffled_labels[:700]\n\n# train model on first 80 % of the data\nsgd_clf.fit(shuffled_data_80pct, shuffled_labels_80pct)","eba6ce05":"# predict on the validation subset (remaining 20%)\nshuffled_data_20pct = shuffled_data[700:]\nshuffled_labels_20pct = shuffled_labels[700:]\n\npredict_SGD(shuffled_data_20pct, shuffled_labels_20pct)","724c1e6d":"predict_SGD(shuffled_data_80pct, shuffled_labels_80pct)","86cfa13d":"def predict_SGD_val_train(data_v, labels_v, data_t, labels_t):\n    \"\"\"Make predictions for validation and training data using our SGD classifier.\n    Compute the difference between validation and training accuracies.\n    \"\"\"\n    \n    preds_v = sgd_clf.predict(data_v)\n    preds_t = sgd_clf.predict(data_t)\n    \n    v = pd.DataFrame({'preds': preds_v,\n                      'labels':labels_v})\n    t = pd.DataFrame({'preds': preds_t,\n                      'labels':labels_t})\n    v['accurate'] = 0\n    for i in range(0, len(v)):\n        if v['labels'][i:i+1].values == v['preds'][i:i+1].values:\n            v['accurate'][i:i+1] = 1\n        else:\n            pass\n    \n    t['accurate'] = 0\n    for i in range(0, len(t)):\n        if t['labels'][i:i+1].values == t['preds'][i:i+1].values:\n            t['accurate'][i:i+1] = 1\n        else:\n            pass\n        \n    accuracy_v = round(sum(v['accurate'])\/v.shape[0],4)\n    accuracy_t = round(sum(t['accurate'])\/t.shape[0],4)\n       \n    diff = accuracy_v - accuracy_t\n    \n    return(diff)  ","865da3cb":"# train SGD model on 100 randomly shuffled datasets\ndifferences = []\nfor i in range(0,100):\n    \n    # random shuffle\n    np.random.seed(i)\n    shuffled_data, shuffled_labels = shuffle(X, y)\n\n    # 80% for training\n    shuffled_data_80pct = shuffled_data[:700]\n    shuffled_labels_80pct = shuffled_labels[:700]\n    \n    # 20 % for validation\n    shuffled_data_20pct = shuffled_data[700:]\n    shuffled_labels_20pct = shuffled_labels[700:]\n\n    # train\n    sgd_clf.fit(shuffled_data_80pct, shuffled_labels_80pct)\n    \n    # predict\n    res = predict_SGD_val_train(shuffled_data_20pct, shuffled_labels_20pct, \n                                shuffled_data_80pct, shuffled_labels_80pct)\n    \n    differences.append(res)","248aed73":"def plot_diff(x):\n\n    plt.figure(figsize=(12,7))\n    plt.ylim(-.3,.3)\n    plt.axhline(y=0, linewidth=2, \n                label='No Difference: 0', color='blue')\n    plt.axhline(y=np.mean(differences), linewidth=2, \n                label='Mean Difference: -0.8%', color='green')\n    plt.title('100 SGD Models: Validation vs. Training Accuracy', fontsize=16)\n    plt.xlabel('100 Random Models', fontsize=14)\n    plt.ylabel('Validation Accuracy Minus Training Accuracy', fontsize=12)\n    plt.legend(loc='upper right')\n    plt.grid()\n    plt.plot(x, 'r--')\n    plt.tight_layout()\n\nplot_diff(differences)\nplt.show()","b8742b94":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ndef plot_learning_curves(model, X, y):\n    \"\"\"Plot the learning curves for train and validation sets, given a model,\n    a dataset X, and a target feature vector y.\n    \"\"\"\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=127)\n    train_acc, val_acc, train_mean, val_mean = [], [], [], []\n    \n    for m in range(5, len(X_train)):\n        model.fit(X_train[:m], y_train[:m])\n        y_train_predict = model.predict(X_train[:m])\n        y_val_predict = model.predict(X_val)\n        train_acc.append(accuracy_score(y_train[:m], y_train_predict))\n        val_acc.append(accuracy_score(y_val, y_val_predict))\n        train_mean.append(np.mean(train_acc))\n        val_mean.append(np.mean(val_acc))\n\n    plt.figure(figsize=(18,10))\n    plt.plot(np.sqrt(train_acc), 'r--', linewidth=.8, label=\"train accuracy\")\n    plt.plot(np.sqrt(val_acc), 'b--', linewidth=.8, label=\"validation accuracy\")\n    plt.plot(train_mean, 'r-', linewidth=1, label=\"mean train accuracy\")\n    plt.plot(val_mean, 'b-', linewidth=1, label=\"mean validation accuracy\")\n \n    plt.title(\"SGD Learning Rate During Training and Validation\", fontsize=16)\n    plt.axis([0, 710, 0.5, 1.1])\n    plt.legend(loc=\"upper right\", fontsize=14)\n    plt.xlabel(\"Training Set Size\", fontsize=14)\n    plt.ylabel(\"Accuracy\", fontsize=14)","091f6fde":"sgd_clf = SGDClassifier(random_state=42)\nplt.figure(figsize=(18,10))\nplot_learning_curves(sgd_clf, X, y)\nplt.show()","c7a2a0eb":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n\ny_prob_forest = cross_val_predict(forest_clf, X, y, cv=3, method=\"predict_proba\")\ny_scores_forest = y_prob_forest[:, 1]\n\ny_scores_sgd = cross_val_predict(sgd_clf, X, y, cv=3,method=\"decision_function\")","022b1644":"from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.title('ROC curve', fontsize=16)\n    plt.xlabel('False Positive Rate', fontsize=14)\n    plt.ylabel('True Positive Rate', fontsize=14)\n\n# calculating FPR and TPR for all Thresholds\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y, y_scores_forest)\nfpr_sgd, tpr_sgd, thresholds_sgd = roc_curve(y, y_scores_sgd)\n\n# plotting\nplt.figure(figsize=(9, 9))\nplt.plot(fpr_sgd, tpr_sgd, \"b:\", linewidth=2, label=\"SGD\")\nplot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\nplt.legend(loc=\"lower right\", fontsize=14)\nplt.show()","bf4d7386":"# calculating the Area Under the Curve (AUC)\nauc_sgd, auc_rf = np.array([roc_auc_score(y, y_scores_sgd), \n                            roc_auc_score(y, y_scores_forest)])\n\nprint('SGD          : ' +str(round(auc_sgd,4))\\\n   +'\\nRandom Forest: ' +str(round(auc_rf,4)))","bbac008b":"from sklearn.metrics import precision_recall_curve\n\nprecisions_sgd, recalls_sgd, thresholds_sgd = precision_recall_curve(y, y_scores_sgd)\nprecisions_rf, recalls_rf, thresholds_rf = precision_recall_curve(y, y_scores_forest)\n","055af26e":"def plot_precision_recall_per_thresh(precisions, recalls, thresholds, title):\n    plt.plot(thresholds, precisions[:-1], 'r--', label='Precision', linewidth=1)\n    plt.plot(thresholds, recalls[:-1], 'y-', label='Recall', linewidth=1)\n    plt.title(title +\" - Precision vs. Recall\")\n    plt.xlabel(\"Threshold\", fontsize=14)\n    plt.ylabel(\"Accuracy\", fontsize=14)\n    plt.legend(loc=\"lower left\", fontsize=14)\n    plt.ylim([0, 1])\n\nplt.figure(figsize=(12, 6))\nplot_precision_recall_per_thresh(precisions_sgd, recalls_sgd, thresholds_sgd, \"SGD\")\nplt.xlim([-6, 7.5])\nplt.ylim([-.1, 1.1])\nplt.show()","f79eedd4":"plt.figure(figsize=(12, 6))\nplot_precision_recall_per_thresh(precisions_rf, recalls_rf, thresholds_rf, \"Random Forest\")\nplt.xlim([-.1, 1.1])\nplt.ylim([-.1, 1.1])\nplt.show()","1d523bcc":"# Titanic Survival Part 2: Exploring Modeling in Python\n\nIn Part 1 of this project I conduct Exploratory Data Analysis (EDA) of the Titanic training data using R. This exploration can be found [here.](http:\/\/rpubs.com\/BigBangData\/512981)\n\nIn Part 2 (this notebook) I continue the exploration using Python and building a couple of basic models. This is not intended as the goal of the competition, just an exploration of modeling in Python.\n\nIn Part 3 I use a jupyter notebook to create a pre-processing pipeline and train several models in Python using the scikit-learn module, and submit my predictions to the competition.\n","2006a0b5":"The accuracy of the predictions on the original 80% of the training set, the data used to train the SGD classifier, seem slightly worse. One would expect the opposite. Let's run more predictions just to get a feel for the variance (instability of predictions) of this SGD model.","febfc924":"We see that on average the validation accuracy is very slightly lower than the training accuracy, so the difference is negligible, and the SGD model performs more or less equally on training and validation using the full training data.\n\nThis could be an indication that this algorithm is biased and there isn't enough flexibility in the model for it to learn, given our data. A look at learning curves will help determine what is going on.","912280f8":"In this section I explore a couple models just to familiarize myself with the modeling process in Python. This exploration goes beyond the primary goal of the Titanic competition (increased accuracy) by looking at ROC and precision-recall curves.\n\n\n### Stochastic Gradient Descent","7411a026":"This concludes the exploration of two basic models - in the next notebook I will build a pre-processing pipeline and train many models to improve accuracy, as the competition expects.","7666a3c3":"Without any tuning, the Random Forest model performs about the same as the SGD, yet it is more consistent and less prone to randomness. \n\nAnother way to visualize the performance of classifiers is through precision-recall curves, especially useful when there is a significant class imbalance (which is not our case). Without getting into details, here I explore visualizing the performance of the same two models by observing their precision and recall over all thresholds.","c0da64aa":"The Stochastic Gradient Descent algorithm, because of its random approach, behaves fairly inconsistently for most of the training set. The mean train accuracy decreases as the algorithm learns and the mean validation accuracy increases, as expected. \n\nThere is an early indication that the inconsistency (fluctuations) of this algorithm is settling down, but we need more data. Since we do not have more data, we need to find an algorithm that behaves more consistently. It also looks like the validation accuracy tops out at about 0.8.\n\n### Random Forests","c259ccfe":"## Scaling","b2b67341":"## Exploring Models","9744f307":"## Binary Indicators:","c5eeaa54":"This resulst makes even less sense, the data it was trained on was harder to predict by a 4% drop in accuracy. Will this be true more often than not? What if we trained and predicted on 100 random models."}}