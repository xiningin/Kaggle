{"cell_type":{"dbae3596":"code","0f2898b5":"code","65233978":"code","ecfd6ce4":"code","93977d2c":"code","6ea456b6":"code","37cdf254":"code","3ac1842a":"code","1a5a547f":"code","373030d4":"code","2282ff05":"code","82e29248":"code","a84a5133":"code","97a3e4ed":"code","b08e6ee4":"code","cf7c2bb7":"code","a22f897d":"code","e73c182d":"code","ed391094":"code","58f378fb":"code","4ebbca63":"code","036534c2":"code","89def265":"markdown","33917756":"markdown","a70ddf02":"markdown","dfa5a9bd":"markdown","e1686260":"markdown","ef10b45c":"markdown","e1eda11c":"markdown","183940a8":"markdown","cae53b6b":"markdown","be5b3900":"markdown","a117e375":"markdown","b44588b6":"markdown","badb31f4":"markdown","8a6c6543":"markdown","fececf76":"markdown","4d3ccb06":"markdown","5c520b56":"markdown","c228484b":"markdown","7881f04f":"markdown","c2747961":"markdown","8052061f":"markdown","6fbf55e8":"markdown","fe986238":"markdown","6e1af41e":"markdown","260ff890":"markdown","50ef8975":"markdown","7bf87957":"markdown"},"source":{"dbae3596":"import numpy as np \nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport timeit\nimport gc\nimport sys\n\nplt.rcParams[\"figure.figsize\"] = (10,6)\nstart_total = timeit.default_timer()","0f2898b5":"df = pd.read_csv('..\/input\/netflix-prize-data\/combined_data_1.txt', names = ['User_Id', 'Rating'], usecols = [0,1])\n#df_2 = pd.read_csv('..\/input\/netflix-prize-data\/combined_data_2.txt', names = ['User_Id', 'Rating'], usecols = [0,1])\n#df_3 = pd.read_csv('..\/input\/netflix-prize-data\/combined_data_3.txt', names = ['User_Id', 'Rating'], usecols = [0,1])\n#df_2 = pd.read_csv('..\/input\/netflix-prize-data\/combined_data_4.txt', names = ['User_Id', 'Rating'], usecols = [0,1])\n\n#df = df.append(df_2)\n#df = df.append(df_3)\n#df = df.append(df_4)\n\n\n#Bei mehr als einem Datenset:\n#df = df.reset_index(drop=True)\n\ndf.head()","65233978":"df_headers = df[df['Rating'].isnull()]\ndf_headers = df_headers['Rating'].reset_index()\ndf_headers.head()","ecfd6ce4":"start = timeit.default_timer()\nmovie_Id = np.array([])\n\n#Index des letzten Films\ni_max = len(df_headers['index']) - 1\n\nind_prev = 0\n\n#i=aktuelle Movie ID\n#ind=Index der Movie_header im originalen Datenset\nfor i,ind in enumerate(df_headers['index']):  \n    current_movie = np.full((1,ind-ind_prev), i)\n    movie_Id = np.append(movie_Id, current_movie)\n    ind_prev = ind\n    \n    #der Fortschritt des loops wird alle 50 Filme ausgegeben\n    if (i%50 == 0 or i == i_max):\n        print(f'Progress: {i\/i_max*100:.2f}%', end='\\r', flush=True)\n\n#der letzte Film muss separat behandelt werden\nlast_movie = np.full((1, len(df) - len(movie_Id)), df_headers['index'].size)\nmovie_Id = np.append(movie_Id, last_movie)\n\n#F\u00fcge das array movie_Id als Spalte zum Dataframe hinzu\ndf['Movie_Id'] = movie_Id\n\n#die Movie_header Zeilen werden gel\u00f6scht um nur Bewertungen zu behalten\ndf = df[pd.notnull(df['Rating'])]\n    \nprint(f\"\\n{timeit.default_timer()-start:.2f}s\")\n","93977d2c":"#Movie_Id und User_Id werden ab jetzt als int gespeichert\ndf['Movie_Id'] = df['Movie_Id'].astype(int)\ndf['User_Id'] = df['User_Id'].astype(int)\n\n#Beipiel der Daten mit Movie_Id als Spalte\ndf.sample(10)","6ea456b6":"#df = df.sample(frac=0.1).reset_index(drop=True)","37cdf254":"#Wie viele Bewertungen gibt es f\u00fcr jeden Film und f\u00fcr jeden Nutzer\nmovie_count = df['Movie_Id'].value_counts()\nuser_count = df['User_Id'].value_counts()","3ac1842a":"#Histogramm f\u00fcr Filme\nplt.hist(movie_count,bins=1000)\nplt.xlim(0,10000)\nplt.xlabel(\"Anzahl an Bewertungen\")\nplt.ylabel(\"Anzahl an Filmen\")\nplt.grid()\nplt.show()\n\n#Histogramm f\u00fcr Nutzer\nplt.hist(user_count,bins=1000)\nplt.xlim(0,200)\nplt.xlabel(\"Anzahl an Bewertungen\")\nplt.ylabel(\"Anzahl an Nutzern\")\nplt.grid()\nplt.show()","1a5a547f":"##### alpha ist der Anteil der Filme und Nutzer die gel\u00f6schte werden\n#alpha = 0.3  #F\u00fcr User_Id=12345678 (Leander)\n#alpha = 0.95 #F\u00fcr User_Id=1000079\nalpha = 0.99 #F\u00fcr Vergleich der verschiedenen Algorithmen\n\n\n#Alle Filme und Nutzer die unterhalb der alpha Quantile liegen werden gel\u00f6scht\nmovie_quant = movie_count.quantile(alpha)\nuser_quant = user_count.quantile(alpha)\n\nprint(f\"Filme mit weniger Bewertungen als die untersten {alpha*100:.0f}% werden gel\u00f6scht.\")\nprint(f\"Filme m\u00fcssen mindestens: {int(movie_quant)} Bewertungen haben\\n\")\nprint(f\"Nutzer mit weniger Bewertungen als die untersten {alpha*100:.0f}% werden gel\u00f6scht.\")\nprint(f\"Nutzer m\u00fcssen mindestens {int(user_quant)} Filme bewertet haben.\")\n","373030d4":"#Erstelle eine liste mit Filmen die behalten werden\nkeep_movies = (df['Movie_Id'].value_counts()>movie_quant)\nkeep_movies = keep_movies[keep_movies == True]\nkeep_movies = keep_movies[keep_movies].index.tolist()\n\n#Erstelle eine liste mit Nutzern die behalten werden\nkeep_users = (df['User_Id'].value_counts()>user_quant)\nkeep_users = keep_users[keep_users == True]\nkeep_users = keep_users[keep_users].index.tolist()\n\n#Erstelle eine liste mit Bewertungen die behalten werden\nkeep_rating = df['Movie_Id'].isin(keep_movies) & df['User_Id'].isin(keep_users)\n\n#df_new ist das Dataframe mit weniger bewertungen das ab jetzt benutzt wird\ndf_new = df[keep_rating]\n\n\n#Wie viele Filme wurden gel\u00f6scht?\nn_movies = df['Movie_Id'].nunique()\nprint(f\"Anzahl an Filmen die gel\u00f6scht wurden: {n_movies - len(keep_movies)}\")\nprint(f\"Anteil an Nutzern die gel\u00f6scht wurden: {1-len(keep_movies)\/n_movies:.4f}\\n\")\n\n#how many users were deleted?\nn_users = df['User_Id'].nunique()\nprint(f\"Anzahl an Nutzern die gel\u00f6scht wurden: {n_users - len(keep_users)}\")\nprint(f\"Anteil an Filmen die gel\u00f6scht wurden: {1-len(keep_users)\/n_users:.4f}\\n\\n\")\n\n\nprint('Anzahl an Bewertungen vor dem Filtern: {}'.format(df.shape[0]))\nprint('Anzahl an Bewertungen nach dem Filtern: {}'.format(df_new.shape[0]))\n","2282ff05":"##### plot a histogram of movie_count\nplt.hist(movie_count,bins=5000)\nplt.axvline(movie_quant,color=\"red\",linestyle='dashed',label='{} quantile'.format(alpha))\nplt.xlim(0,5000)\nplt.xlabel(\"Anzahl an Bewertungen\")\nplt.ylabel(\"Anzahl an Filmen\")\nplt.legend()\nplt.grid()\nplt.savefig(\".\/hist_30_movies.jpg\",dpi=400)\nplt.show()\n\n#plot a histogram of movie_count\nplt.hist(user_count,bins=1000)\nplt.axvline(user_quant,color=\"red\",linestyle='dashed',label='{} quantile'.format(alpha))\nplt.xlim(0,20*user_quant)\nplt.xlabel(\"Anzahl an Bewertungen\")\nplt.ylabel(\"Anzahl an Nutzern\")\nplt.legend()\nplt.grid()\nplt.savefig(\".\/hist_30_users.jpg\",dpi=400)\nplt.show()","82e29248":"movie_titles = pd.read_csv('..\/input\/netflix-prize-data\/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\nmovie_titles.set_index('Movie_Id', inplace = True)\nmovie_titles = movie_titles.reset_index()\nmovie_titles = movie_titles[movie_titles['Movie_Id'].isin(keep_movies)]\n\n#movie_titles.to_csv(r'.\/movie_titles_after_filter.txt', header=None, index=None, sep=' ', mode='a')\nmovie_titles.sample(10)\n","a84a5133":"if (alpha == 0.3):\n\n    df_leander = pd.read_csv('..\/input\/ratings\/ratings_leander.txt', names = ['User_Id', 'Rating','Movie_Id'], usecols = [0,1,2])\n    df_leander['Movie_Id'] = df_leander['Movie_Id'].astype(int)\n    df_leander['User_Id'] = df_leander['User_Id'].astype(int)\n    df_benji = pd.read_csv('..\/input\/ratings\/ratings_benji.txt', names = ['User_Id', 'Rating','Movie_Id'], usecols = [0,1,2])\n    df_benji['Movie_Id'] = df_benji['Movie_Id'].astype(int)\n    df_benji['User_Id'] = df_benji['User_Id'].astype(int)\n\n\n    df_new = df_new.append(df_leander)\n    df_new = df_new.reset_index(drop=True)\n    df_new = df_new.append(df_benji)\n    df_new = df_new.reset_index(drop=True)\n    df_leander.sample(10)","97a3e4ed":"from surprise import Dataset, Reader, accuracy\nfrom surprise import SVD, SVDpp,KNNBaseline, KNNBasic, BaselineOnly\nfrom surprise.model_selection import cross_validate,train_test_split","b08e6ee4":"data = Dataset.load_from_df(df_new[['User_Id', 'Movie_Id', 'Rating']], Reader())\n#data_train, data_test = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)","cf7c2bb7":"del df\ndel movie_Id\ndel df_headers\ndel keep_users\ngc.collect()","a22f897d":"#Modelle werden nur verglichen, wenn testing=True und der Datensatz ausreichend verkleinert wurde (Standard: alpha = 0.99)\ntesting = False\nif (testing == True and (alpha == 0.5 or alpha == 0.99)):\n\n    scores = []\n\n    models = [SVD(),SVDpp(),KNNBasic(),BaselineOnly()]\n    #[SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n\n    for model in models:\n        start = timeit.default_timer()\n\n        #using train and test sets:\n        #model.fit(data_train)\n        #data_pred = model.test(data_test)\n        #acc = accuracy.rmse(data_pred)\n        #scores.append(acc)\n\n        #using cross validation:\n        results = cross_validate(model, data, measures=['RMSE'], cv=3, verbose=True)\n        tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n        tmp = tmp.append(pd.Series([str(model).split(' ')[0].split('.')[-1]], index=['Model']))\n\n        # Store data\n        scores.append(tmp)\n        print(f\"{model}: {timeit.default_timer() - start:.2f}s\")","e73c182d":"print(\"Building trainset...\")\ntrainset = data.build_full_trainset()\nprint(\"Trainset completed...\")\n\nsvd = SVD()\nprint(\"Training SVD...\")\nsvd.fit(trainset)\nprint(\"Training completed...\")\n\n\n#Freigeben von nicht genutzem Speicher\ndel data\ndel trainset\ngc.collect()","ed391094":"def predict_for_user(user_id):\n    #Welche Filme hat der User sehr gut bewertet? \n    user = df_new[(df_new['User_Id'] == user_id) & (df_new['Rating'] == 5) ]\n    user = user.set_index('Movie_Id')\n    user = movie_titles['Name'][user.index-1]\n    print(f\"Filme die User {user_id} mit 5 Sternen bewertet hat:\\n\")\n    print(user.head(50))\n    \n    #Welche Filme empfielt das Modell\n    user = movie_titles.copy()\n    user = user.reset_index()\n    #user = user[user['Movie_Id'].isin(keep_movies)]\n    user['Estimate_Score'] = user['Movie_Id'].apply(lambda x: svd.predict(user_id, x).est)\n\n    user = user.drop('Movie_Id', axis = 1)\n    user = user.sort_values('Estimate_Score', ascending=False)\n    user = user.set_index('index')\n\n    return user","58f378fb":"if (alpha == 0.3):\n    #Benji\n    user_id = 123456789\n    result = predict_for_user(user_id)\n    print(f\"\\n\\n\\n Die Filme, die User {user_id} nach dem trainierten Modell am besten bewertet werden: \\n\")\n    print(result.head(20))\n    \n    #Leander\n    user_id = 12345678\n    result = predict_for_user(user_id)\n    print(f\"\\n\\n\\n Die Filme, die User {user_id} nach dem trainierten Modell am besten bewertet werden: \\n\")\n    print(result.head(20))\n    \nelif (alpha == 0.95):\n    user_id = 1000079\n    result = predict_for_user(user_id)\n    print(f\"\\n\\n\\n Die Filme, die User {user_id} nach dem trainierten Modell am besten bewertet werden: \\n\")\n    print(result.head(20))\n","4ebbca63":"if (alpha == 0.3):\n    ids = [12345678,123456789]\n    for user_id in ids:\n        user = df_new[(df_new['User_Id'] == user_id)]\n        user = user.set_index('Movie_Id')\n        print(user_id)\n        print(f\"Finale Empfehlungen f\u00fcr user {user_id}\")\n        print(result[~(result.index).isin(user.index-1)].head(20))\n\nif (alpha == 0.95):\n    user = df_new[(df_new['User_Id'] == user_id)]\n    user = user.set_index('Movie_Id')\n    print(user_id)\n    print(f\"Finale Empfehlungen f\u00fcr user {user_id}\")\n    print(result[~(result.index).isin(user.index-1)].head(20))\n","036534c2":"end_total = timeit.default_timer()\nprint(f\"Runtime of program: {end_total - start_total:.2f}s\")","89def265":"## 1e.) Hinzuf\u00fcgen meiner eigenen Ratings aus separater txt Datei (User_Id(Leander)='12345678')","33917756":"### Vergleich der Modelle bei alpha=0.99:\n\n**1. SVDpp:** RMSE=0.8810\n\n**2. SVD:** RMSE=0.8854\n\n**3. KNNBaseline:** RMSE=0.8892\n\n**4. KNNBasic:** RMSE=0.9003\n\n**5. BaselineOnly:** RMSE=0.9304\n\n### Ergebnisse bei alpha=0.5:\n\n**1. SVD:** RMSE=0.8770\n\n","a70ddf02":"Es kann ausge\u00e4hlt werden, welche der vier Datensets geladen werden. Mit mehr als einem Datenset kommt es allerdings schnell zu langen Laufzeiten und Memory Errors. Bei mehreren Datensets muss df.reset_index(drop=True) verwendet werden.","dfa5a9bd":"## Empfehlungen f\u00fcr User 123456789 (Benji) mit $\\alpha=0.3$ (Titel, Estimated Score)                                                             \n\n### 1.                                 **Lost: Season 1**        4.642074\n### 2.   **Lord of the Rings: The Fellowship of the Ring**        4.458469\n### 3.                                      **Braveheart**        4.360494\n### 4.                                      **The Chorus**        4.355074\n### 5.                        **The Silence of the Lambs**        4.287214\n### 6.                     **Ghosts of Rwanda: Frontline**        4.274848\n### 7.                                      **Local Hero**        4.267465\n### 8.                                            **FLCL**        4.243018\n### 9.                       **Finding Nemo (Widescreen)**        4.226555\n### 10.                                     **Get Backers**        4.183222\n### 11.                                **The Last Samurai**        4.180642\n### 12.                                             **Ray**        4.168621\n### 13.                      **King of the Hill: Season 1**        4.160325\n### 14.                                         **Charade**        4.157592\n### 15.     **GoodFellas: Special Edition: Bonus Material**        4.140778\n### 16.        **Thin Man Collection: Alias Nick and Nora**        4.134943\n### 17.                       **Six Feet Under: Season 4**        4.130170\n### 18.                                        **Firefly**        4.125661\n### 19.                                     **The Pianist**        4.121956\n### 20.                       **The Passion of the Christ**        4.117828","e1686260":"\n## 2b.) Die Modelle werden gefittet und verglichen","ef10b45c":"Die meisten Filme haben sehr wenig Bewertungen bekommen, genauso haben die meisten Nutzer sehr wenig Bewertungen abgegeben. Als n\u00e4chstes werden die am wenigsten bewerteten Filme und die am wenigsten bewertenden Nutzer aus dem Datenset gel\u00f6scht, um eine bessere Performance zu erreichen.","e1eda11c":"### Das Modell kann jetzt vorhersagen, welche Ratings ein User jedem beliebigen Film geben wird","183940a8":"## 1c.) Verkleinern des Datensets durch L\u00f6schen von weniger sinnvollen Filmen und Nutzern","cae53b6b":"## 1b.) 'Movie_Id' wird als Spalte hinzugef\u00fcgt\n\n\nDiese Gruppierung kann nicht direkt f\u00fcr das Trainieren eines Models verwendet werden. Deshalb ist der erste Schritt, im Dataframe eine neue Spalte \"Movie_Id\" zu erstellen, welche f\u00fcr jede Bewertung die korrekte ID des Films erh\u00e4lt.\n\nDaf\u00fcr werden zun\u00e4chst die Indizes der Zeilen extrahiert, welche den Beginn eines Films darstellen und deshalb als \"Rating\" den Eintrag \"NaN\" haben.","be5b3900":"### Wir k\u00f6nnen alle Filme aus den Empfehlungen entfernen, die der User bereits bewertet hat:","a117e375":"# 0. Imports","b44588b6":"### SVD:\n### Ein Film wird durch Vektor $x_j$ und ein Nutzer durch Vektor $y_i$ beschrieben.\n\n### Die erwartete Bewertung $r_{ij}$ von Nutzer $j$ zu Film $i$ wird ausgedr\u00fcckt durch  $\\hat r_{ij}=x_j^Ty_i$\n\n### $x_j$ und $y_i$ werden durch ein Minimierungsrpoblem berechnet: $\\min\\limits_{x,y}\\sum\\limits_{i,j}(r_{ij}-x_j^Ty_i)$","badb31f4":"Im Folgenden kann die Gr\u00f6\u00dfe des Datensets zum Debugging verkleinert werden. frac ist der Anteil an zuf\u00e4llig ausgew\u00e4hlten Bewertungen die behalten werden. Mit frac=1 wird das gesamte Datenset benutzt.","8a6c6543":"## 1a.) Loading the Dataset (from ..\/input\/netflix-prize-data\/)","fececf76":"\"User_Id\" ist eine eindeutige Identifikationszahl f\u00fcr jeden Benutzer und \"Rating\" ist eine Zahl zwischen 0 (sehr schlecht) und 5 (sehr gut), welche der entsprechende Nutzer abgegeben hat.\n\nDie Bewertungen sind nach den entsprechenden Filmen gruppiert, separiert durch eine Zeile, welche die ID des Films enth\u00e4lt auf den sich die nachfolgenden Bewertungen beziehen. Zum Beispiel sind die Zeilen 1 bis 547 Bewertungen f\u00fcr den Film mit ID=1, die Zeilen 549 bis 693 f\u00fcr den Film mit ID=2, usw. \n","4d3ccb06":"# 1. Loading and preprocessing the data","5c520b56":"### Wir benutzen ab jetzt das SVD() Modell, da der RMSE Fehler klein und die Laufzeit am geringsten ist.","c228484b":"#### Freigeben von Speicher...","7881f04f":"Durch die Gr\u00f6\u00dfe des Datensets kommt es leicht zu Speicherproblemen. Deshalb wird zu\u00e4chst ein numpy-Array erstellt, welches die korrekten Movie_IDs enth\u00e4lt und anschlie\u00dfend als Spalte an das Dataframe angef\u00fcgt wird.\n\nD.h. movie_Id = np.array([1,...,1,2,...,2,3,...,3,...]) ist ein array mit 528 Einsen, 144 Zweien, usw.\n\nDieser Schritt kann mehrere Minuten dauern.","c2747961":" ## Empfehlungen f\u00fcr User 1000079 mit $\\alpha=0.95$ (Titel, Estimated Score)  \nYear                              Name  Estimate_Score\n### 1.          **Finding Nemo (Widescreen)**       3.828139\n### 2.            **Sixteen Candles**       3.700875\n### 3.              **The Sting**       3.612089\n### 4.          **Aladdin: Platinum Edition**       3.598731\n### 5.            **The King and I**      3.565756\n### 6.       **Alien: Collector's Edition**      3.562768\n### 7.          **North by Northwest**     3.555763\n### 8.            **Friends: Season 2**      3.529245\n### 9.      **Sex and the City: Season 4**     3.514128\n### 10.                      **Batman Begins**        3.494697\n### 11.                       **Coach Carter**        3.470938\n### 12.                 **The Maltese Falcon**        3.464277\n### 13.       **Aliens: Collector's Edition**        3.460768\n### 14.   **Casino: 10th Anniversary Edition**        3.446077\n### 15.                    **Boyz N the Hood**        3.432111\n### 16.                         **Goldfinger**        3.402852\n### 17.              **Fried Green Tomatoes**        3.383141\n### 18.                     **Seven Samurai**        3.363454\n### 19.                       **Poltergeist**        3.355065\n### 20.                            **Shrek 2**        3.352589","8052061f":"## 1d.) Laden der Filmtitel aus \"movie_titles.csv\"\n\nDie Datei \"movie_titles.csv\" besteht aus drei Spalten: 1) die movie_ID wie sie bisher verwendet wurde, 2) das Jahr in dem der Film erschienen ist und 3) der Filmtitel als String. ","6fbf55e8":"# Project URL: https:\/\/www.kaggle.com\/leanderthiessen\/ml-project-netflix-leander-thiessen","fe986238":"Das $\\alpha$-Quantil kann graphisch dargestellt werden:","6e1af41e":"## Empfehlungen f\u00fcr User 12345678 (Leander) mit $\\alpha=0.3$ (Titel, Estimated Score)                                                             \n### **1.**                                      **Lost: Season 1**   4.515718\n### **2.**                  **Buffy the Vampire Slayer: Season 6**   4.310773\n### **3.**                           **As Time Goes By: Series 8**   4.310066\n### **4.**                                  **My Neighbor Totoro**   4.269945\n### **5.**                             **Queer as Folk: Season 1**   4.269096\n### **6.**                                         **Get Backers**   4.237437\n### **7.**       **Eric Clapton: Crossroads Guitar Festival 2004**   4.233429\n### **8.**                      **Cadfael: The Virgin in the Ice**   4.208023\n### **9.**                  **Tae Guk Gi: The Brotherhood of War**   4.204482\n### **10.**                                **ECW: One Night Stand**   4.198693\n### **11.**                                         **Invader Zim**   4.145655\n### **12.**   **Carlos Mencia: Not for the Easily Offended: Li...**   4.143262\n### **13.**                               **Six Feet Under: Season 4**   4.143182\n### **14.**                                     **Torch Song Trilogy**   4.139662\n### **15.**                                       **The Sixth Sense**   4.133574\n### **16.**                                       **Secondhand Lions**   4.129206\n### **17.**                **From Mao to Mozart: Isaac Stern in China**   4.122430\n### **18.**                                     **The O.C.: Season 1**   4.120281\n### **19.**                                      **Foyle's War: Set 2**   4.115954\n### **20.**                  **Joseph Campbell and The Power of Myth**   4.104715\n\n         \n","260ff890":"Das Netflix Datenset besteht aus vier Text-Datein (\"combined_data_*.txt\"), welche die Film Bewertungen der Benutzer enthalten. Au\u00dferdem enth\u00e4lt die Datei \"movie_titles.csv\" ein Mapping zwischen den Titeln der Filme und den IDs die in den txt Dateien verwendet werden.","50ef8975":"# 2.) Recommendation Model (Surprise)\n","7bf87957":"## 2a.) Erstelle ein Train and Test set\n\nHier gibt es die M\u00f6glichkeit, ein Train und Test set zu erstellen. Da wir sp\u00e4ter aber zum Vergleichen der Modelle Cross-Validation verwenden, ist es hier nicht notwendig."}}