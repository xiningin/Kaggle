{"cell_type":{"3fb21766":"code","aeb0cc7f":"code","e97d10a1":"code","44cad302":"code","a52369a9":"code","203ec534":"code","ebb29a91":"code","388c7535":"code","092359bf":"code","b06381c7":"code","75c47fb5":"code","9e1b7dd6":"code","f3e75886":"code","b97314f5":"code","d4cf7876":"code","8eeaea32":"code","97a3bf42":"code","7583cd6f":"code","f84a513a":"code","41539595":"code","3c3b93a1":"code","669e2435":"code","bd9da08e":"code","dcaea489":"code","dad4201b":"code","fcb903b4":"code","1eebe135":"code","e82b19ea":"code","4b0f20f0":"code","863b3fd3":"code","43181b74":"code","7412e840":"markdown","5c772746":"markdown","6864deb5":"markdown","51e3a589":"markdown","c86115c9":"markdown","188c51b2":"markdown","c1b28b47":"markdown","eb90fcb6":"markdown","68da33b7":"markdown","809e6664":"markdown","25ca81f3":"markdown","dc09f8e3":"markdown","6f44f9cf":"markdown","a286161b":"markdown","abdbdf3a":"markdown","c3798ee0":"markdown"},"source":{"3fb21766":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","aeb0cc7f":"df_train = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')\nprint(df_train.shape)\nprint(df_test.shape)","e97d10a1":"df_train.head()","44cad302":"df_train.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]).T","a52369a9":"null_train = df_train.isnull().sum()\nnull_train[null_train>0].sum()","203ec534":"null_test = df_train.isnull().sum()\nnull_test[null_test>0].sum()","ebb29a91":"from scipy import stats\nfrom scipy.stats import norm\n\nf=plt.figure(figsize=(8,5))\nsns.set_theme()\nsns.distplot(df_train['target'],fit=norm)\nf=plt.figure(figsize=(8,5))\nres=stats.probplot(df_train['target'],plot=plt)\nf=plt.figure(figsize=(8,5))\nsns.boxplot(x='target', data=df_train, orient='h')","388c7535":"df_train.dtypes\ncat_data = list(df_train.select_dtypes(['object']).columns)\ncont_data = list(df_train.select_dtypes(['float64']).columns)\nprint(cat_data)\nprint(cont_data)","092359bf":"columns = df_train.drop([\"id\",\"target\"], axis=1).columns.values\n\ncols = 4\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,20), sharex=False)\n\nplt.subplots_adjust(hspace = 0.3)\n\ni=0\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            scatter = axs[r, c].scatter(df_train[columns[i]].values,\n                                        df_train[\"target\"],\n                                        )\n            axs[r, c].set_title(columns[i], fontsize=14, pad=5)\n            axs[r, c].tick_params(axis=\"y\", labelsize=11)\n            axs[r, c].tick_params(axis=\"x\", labelsize=11)\n                                  \n        i+=1\n        \nplt.show();","b06381c7":"from sklearn.preprocessing import OrdinalEncoder\n\nord_enc = OrdinalEncoder()\n\ndf_train[cat_data] = ord_enc.fit_transform(df_train[cat_data])\ndf_test[cat_data] = ord_enc.transform(df_test[cat_data])","75c47fb5":"df_train[cat_data].head(),df_test[cat_data].head()","9e1b7dd6":"df_train.head()","f3e75886":"plt.figure(figsize=(10,8))\nsns.heatmap(data=df_train.corr(),cmap=\"YlGnBu\",linewidths=0.3,linecolor='black')\nplt.show()","b97314f5":"X = df_train.drop(['id','target'],axis=1)\ny = df_train.target\nprint(X.shape)\nprint(y.shape)","d4cf7876":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","8eeaea32":"X_train.head()","97a3bf42":"# from sklearn.tree import DecisionTreeRegressor\n# from sklearn.metrics import mean_squared_error\n\n# model_dtr = DecisionTreeRegressor(random_state=1)\n# model_dtr.fit(X_train,y_train)\n# ypred_dtr = model_dtr.predict(X_test)\n\n# print(\"MSE: \", mean_squared_error(y_test,ypred_dtr))","7583cd6f":"# from sklearn.ensemble import RandomForestRegressor\n\n# model_rfr = RandomForestRegressor(n_estimators=100,n_jobs=-1)\n# model_rfr.fit(X_train,y_train)\n# ypred_rfr = model_rfr.predict(X_test)\n\n# print(\"MSE: \", mean_squared_error(y_test,ypred_rfr))","f84a513a":"from datetime import datetime\n\ndef timer(start_time=None):\n    if not start_time:\n        return datetime.now()\n    elif start_time:\n        thr,tmp_sec = divmod((datetime.now()-start_time).total_seconds(),3600)\n        tmin,tsec = divmod(tmp_sec,60)\n        print('\\nTime taken: {} hours {} minutes and {} seconds.'.format(thr,tmin,round(tsec,2)))","41539595":"##Hyperparameter Optimization\nparams={\n    \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30,0.35],\n    \"max_depth\" : [3,4,5,6,7,8,10,12,15],\n    \"min_child_weight\" : [1,3,5,7],\n    \"gamma\" : [0.0,0.1,0.2,0.3,0.4],\n    \"colsample_bytree\" : [0.3,0.4,0.5,0.7]\n}","3c3b93a1":"import xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\n\nmodel_xgbreg = xgb.XGBRegressor(tree_method = 'gpu_hist')\n\nrandom_search=RandomizedSearchCV(estimator=model_xgbreg,param_distributions=params,scoring='neg_mean_absolute_error',n_iter=5,n_jobs=-1,cv=5,verbose=3)\n","669e2435":"start_time = timer(None)\nrandom_search.fit(X_train,y_train)\ntimer(start_time)","bd9da08e":"random_search.best_estimator_","dcaea489":"random_search.best_params_","dad4201b":"sgb_regressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, gamma=0.0, gpu_id=0,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.05, max_delta_step=0, max_depth=10,\n             min_child_weight=5,  monotone_constraints='()',\n             n_estimators=100, n_jobs=2, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n             tree_method='gpu_hist', validate_parameters=1, verbosity=None)","fcb903b4":"from sklearn.model_selection import cross_val_score\n\nscore = cross_val_score(sgb_regressor,X_train,y_train,cv=10)","1eebe135":"print(score.mean())\nprint(random_search.best_score_)\nscore","e82b19ea":"df_test.head(3)","4b0f20f0":"test = df_test.drop(['id'],axis=1)\n\nprint(test.shape)\ntest.head()","863b3fd3":"pred_final = random_search.predict(test)\n\noutput = pd.DataFrame({'id': df_test.id,\n                       'target': pred_final})\noutput.to_csv('submission_1.csv', index=False)","43181b74":"pred_final.shape","7412e840":"#### 5.Extracting catagorical and continuous data columns into seperate lists","5c772746":"# 30 Days of ML","6864deb5":"#### 6. Plot cols vs target variable","51e3a589":"#### 10. Model Creation","c86115c9":"#### 9. Splitting using train_test_split","188c51b2":"##### 10.2. Random Forest","c1b28b47":"#### 2. Read CSV into Pandas Dataframe","eb90fcb6":"#### 8. Setting features and target","68da33b7":"#### 12. Submission","809e6664":"#### 3. Descriptive Statistics with custom percentiles","25ca81f3":"#### 4. Distribution of target","dc09f8e3":"#### 4. Check for null values","6f44f9cf":"##### 10.1. Decision Tree","a286161b":"#### 7. Converting Categorical data into numerical (imp. before using ML model) ","abdbdf3a":"##### 10.3. XGBoost","c3798ee0":"#### 1. Import Libraries and find input file paths"}}