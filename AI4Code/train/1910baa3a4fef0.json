{"cell_type":{"80364b1e":"code","2a47b8ae":"code","f421ad4a":"code","7acd7eb5":"code","bd0aafe9":"code","edf8752d":"code","40e7df11":"code","0172fcf7":"code","5bb4d16c":"code","c9590bfe":"code","49b699f2":"code","7404ff45":"code","9279e323":"code","687edb57":"code","c2812ab5":"code","8a694bde":"code","70be3a22":"code","b77978ae":"code","5d6bcee1":"code","b401c718":"code","81fff5b9":"code","a9871198":"code","4dc4fa93":"code","5f78c68b":"code","c04c2fb6":"code","5d1c2976":"code","7d944ebb":"code","a90b526f":"code","3f4f3f40":"code","7892f72d":"code","336c5737":"code","d7a72052":"code","1578f83b":"code","08869981":"code","345cdf54":"code","f597e125":"code","ec45ba18":"code","382cb06e":"code","1d131a03":"code","1ad69e7b":"code","a1952671":"code","096fea4a":"code","2758c89d":"code","19b98b46":"code","1b16ce64":"code","3bd5d366":"code","add00f42":"code","23979a5e":"markdown","f50efedb":"markdown","9a13f039":"markdown","b85bb192":"markdown","e79b805f":"markdown","1aeb36bb":"markdown","6a4bdd18":"markdown","6ea5b130":"markdown","59508968":"markdown","a585d557":"markdown","308b29fa":"markdown","13c574a7":"markdown","173b0f2a":"markdown","ca5d7960":"markdown","dc0dfe7b":"markdown","429097bf":"markdown"},"source":{"80364b1e":"#Importing the Libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport scipy\nfrom scipy.stats import chi2_contingency\nfrom scipy import stats\nfrom datetime import datetime\n\nwarnings.filterwarnings('ignore')","2a47b8ae":"def \u0441hi_square(df,di):\n  dfm = df.copy()\n  l = []\n  i = 0\n  for i in df.columns:\n    l.append(df[i])\n    i += 1\n  obs = np.array([l])\n  ax1 = plt.axes()\n    \n  # Contingency table\n  print('Contingency table: ')\n  print(chi2_contingency(obs)[3][0])\n  sns.heatmap((chi2_contingency(obs)[3][0]),\n                   yticklabels=dfm.columns,\n                   xticklabels=di.values(),\n                   annot=True,\n                   cmap=\"YlGnBu\", \n                   ax = ax1)\n  ax1.set_title('Contingency table')\n  plt.show()\n  modif = dfm\n  modif = np.array(modif).T\n  ax1 = plt.axes()\n  for i in range(len(dfm.index)):\n    for j in range(len(dfm.columns)):\n      modif[j,i] -= chi2_contingency(obs)[3][0][j,i]\n  sns.heatmap(modif,\n                   yticklabels=dfm.columns,\n                   xticklabels=di.values(),\n                   annot=True,\n                   cmap=\"YlGnBu\", \n                   ax = ax1)\n  ax1.set_title('Contingency table')\n  plt.show()\n\n  # Final results\n  chi2, prob, deg, expected = scipy.stats.chi2_contingency(df)\n  output = \"Chi2: {}\\ndegrees of freedom: {}\\np-value: {}\\n\"\n  print(output.format(chi2, deg, prob))\n  plt.xlabel('chi2')\n  plt.ylabel('Value')\n  x = np.arange(0, 30, .05)\n  for i in range(deg-2,deg+1):\n    if (i != deg):\n      plt.plot(x, stats.chi2.pdf(x, df=i), color='r', lw=1)\n    else:\n      plt.plot(x, stats.chi2.pdf(x, df=i), color='b', lw=2)\n  plt.show()\n  if (prob < 0.5):\n    print('H0 theory was not confirmed')\n    print('There is no uniformity')\n  else:\n    print('H0 theory was confirmed')","f421ad4a":"df = pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv',sep='\\t')\ndf","7acd7eb5":"edu = df.Education\nans = df.Response","bd0aafe9":"labels, uniques = df.Education.factorize()\ndf.Education = labels\nun = []\nfor i in range(len(uniques)):\n    un.append((df.Education.unique()[i],uniques[i]))\nuniques_ = dict(un)\nuniques_","edf8752d":"dft = pd.DataFrame()\ndft['EDUCATION'] = df.Education\ndft.index = df.Response","40e7df11":"l = []\nfor i in dft.EDUCATION.unique():\n    l.append([sum((dft.EDUCATION == i) & (dft.index == 0)), sum((dft.EDUCATION == i) & (dft.index == 1))])\ndft = pd.DataFrame(l)","0172fcf7":"\u0441hi_square(dft,uniques_)","5bb4d16c":"ms = df.Marital_Status\nans = df.Response","c9590bfe":"labels, uniques = df.Marital_Status.factorize()\ndf.Marital_Status = labels\nun = []\nfor i in range(len(uniques)):\n    un.append((df.Marital_Status.unique()[i],uniques[i]))\nuniques_ = dict(un)\nuniques_","49b699f2":"dft = pd.DataFrame()\ndft['MS'] = df.Marital_Status\ndft.index = df.Response","7404ff45":"l = []\nfor i in dft.MS.unique():\n    l.append([sum((dft.MS == i) & (dft.index == 0)), sum((dft.MS == i) & (dft.index == 1))])\ndft = pd.DataFrame(l)","9279e323":"\u0441hi_square(dft,uniques_)","687edb57":"df.Kidhome.unique()","c2812ab5":"df.Teenhome.unique()","8a694bde":"df['Kid_Teen'] = 0\nfor i in range(2240):\n    if (0 <= df.Kidhome[i] < df.Teenhome[i]):\n        df['Kid_Teen'][i] = 'Teens dominate'\n    elif (0 <= df.Teenhome[i] < df.Kidhome[i]):\n        df['Kid_Teen'][i] = 'Kids dominate'\n    elif (0 < df.Teenhome[i] == df.Kidhome[i]):\n        df['Kid_Teen'][i] = 'No preponderance'\n    else:\n        df['Kid_Teen'][i] = 'No children'\ndf = df.drop(['Kidhome','Teenhome'],axis=1)\ndf","70be3a22":"kt = df.Kid_Teen\nans = df.Response","b77978ae":"labels, uniques = df.Kid_Teen.factorize()\ndf.Kid_Teen = labels\nun = []\nfor i in range(len(uniques)):\n    un.append((df.Kid_Teen.unique()[i],uniques[i]))\nuniques_ = dict(un)\nuniques_","5d6bcee1":"dft = pd.DataFrame()\ndft['KT'] = df.Kid_Teen\ndft.index = df.Response","b401c718":"l = []\nfor i in dft.KT.unique():\n    l.append([sum((dft.KT == i) & (dft.index == 0)), sum((dft.KT == i) & (dft.index == 1))])\ndft = pd.DataFrame(l)","81fff5b9":"\u0441hi_square(dft,uniques_)","a9871198":"df","4dc4fa93":"df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\ndf['Age'] = 0\nc = 0\nfor i,j in zip(df['Dt_Customer'],df['Year_Birth']):\n    if (i.year - j > 70):\n        df['Age'][c] = 70\n    else:\n        df['Age'][c] = i.year - j\n    c += 1\ndf = df.drop(['Dt_Customer','Year_Birth'],axis=1)","5f78c68b":"import matplotlib.ticker as ticker\nimport seaborn as sns\n\ndef barplot_data(listx,listy,sizex=18,sizey=6,stepx=6,stepy=6,numberx=True,ox=True):   \n    fig, ax = plt.subplots()\n    fig.set_figwidth(sizex)\n    fig.set_figheight(sizey)\n    b = ax.bar(listx, listy, color='orange')\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(round(sizey\/stepy)))\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(round(sizex\/stepx)))\n    if (numberx):\n        for rect in b:\n            height = rect.get_height()\n            plt.text(rect.get_x() + rect.get_width()\/2.0, height, '%d' % int(height), ha='center', va='bottom')\n\n    plt.show()","c04c2fb6":"barplot_data(list(df.Age.unique()),list(df.groupby('Age').count()['ID']),stepy=1,stepx=20)","5d1c2976":"df.isnull().sum()","7d944ebb":"df = df.fillna(0)","a90b526f":"df.Income = round(df.Income\/1000)","3f4f3f40":"df.Income = df.Income.astype(int)","7892f72d":"for i in range(2240):\n    if (df.Income[i] > 100):\n        df.Income[i] = 100","336c5737":"barplot_data(list(df.Income.unique()),list(df.groupby('Income').count()['ID']),stepy=1,stepx=5)","d7a72052":"from sklearn.preprocessing import StandardScaler","1578f83b":"df = df.drop(['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5'],axis=1)","08869981":"df['Consumption'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntMeatProducts'] + df['MntSweetProducts'] + df['MntGoldProds']","345cdf54":"df = df.drop(['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds'],axis=1)","f597e125":"df['Activity'] = df['NumDealsPurchases'] + df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumWebVisitsMonth']","ec45ba18":"df = df.drop(['NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth'],axis=1)","382cb06e":"df = df.drop(['Z_Revenue','Z_CostContact','ID'],axis=1)","1d131a03":"ds = df.copy()\n\nscaler = StandardScaler()\nscaler.fit(ds)\ndfs = pd.DataFrame(scaler.transform(ds),columns= ds.columns )","1ad69e7b":"dfs","a1952671":"from sklearn.cluster import KMeans\n\nwcss=[]\nfor i in range(1,11):\n    kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)\n    kmeans.fit(dfs)\n    wcss.append(kmeans.inertia_)\nplt.figure(figsize=(12,6))\nplt.plot(range(1,11),wcss, 'rx-')\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","096fea4a":"from sklearn.metrics import silhouette_score ","2758c89d":"silhouette_scores = []\nfor i in range(2,10):\n    m1=KMeans(n_clusters=i, random_state=42)\n    c = m1.fit_predict(dfs)\n    silhouette_scores.append(silhouette_score(dfs, m1.fit_predict(dfs))) \nplt.bar(range(2,10), silhouette_scores, color='gray') \nplt.xlabel('Number of clusters', fontsize = 10) \nplt.ylabel('S(i)', fontsize = 10) \nplt.show()","19b98b46":"kmeans=KMeans(n_clusters=2, random_state=42).fit(dfs)\npred=kmeans.predict(dfs)\ndf['cluster'] = pred","1b16ce64":"barplot_data(list(df.groupby('cluster').count()['Income'].index),list(df.groupby('cluster').count()['Income']),sizex=6,sizey=5,stepx=7,stepy=0.1)","3bd5d366":"def ClusteringEffect(df):\n    print('Class separation mapping process...')\n    sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n    for i in df:\n        diag = sns.FacetGrid(df, col = \"cluster\", hue = \"cluster\", palette = \"Set1\")\n        diag.map(plt.hist, i, bins=6, ec=\"w\") \n        diag.set_xticklabels(rotation=25, color = 'black')\n        diag.set_yticklabels(color = 'black')\n        diag.set_xlabels(size=12, color = 'black')\n        diag.set_titles(size=12, color = 'black')\n        diag.fig.set_figheight(6)\n\nClusteringEffect(df)","add00f42":"for i in df.columns:\n    if (i != 'cluster'):\n        print(df.groupby(df.cluster).mean()[i])","23979a5e":"---------------\n\nIt was decided to divide the data into two classes.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=72&leftFill=%23FF0000 \"progress\")\n\n---------------","f50efedb":"---------------\n\nThe number of children in a family has a very strong impact on the determining factor of the client. If there are no children in the client's family, then he often gives 1 as a result, the situation with **teen domenate** is the opposite.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=32&leftFill=%23FF0000 \"progress\") \n\n---------------","9a13f039":"### It is necessary to calculate the difference between the registration and the year of birth.\n\n---------------\n\nTo do this, simply take the difference from the upper border of 70.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=32&leftFill=%23FF0000 \"progress\") \n\n---------------","b85bb192":"# Let's introduce functions for calculating statistical indicators.","e79b805f":"![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=99&leftFill=%23FF0000 \"progress\")\n\nIf you like it, go to the kaggle profile. Thank you all for reading.","1aeb36bb":"# Output\n\n------------------------------\n1. Class 0. A class characterized by a small number of children, or mostly children are already adults. This class has a graduation or PhD. The class is characterized by loneliness in relationships. The average age of the client is more senior than class 1. The client spends a lot of money and is very active in the web space.\n\n------------------------------\n\n2. Class 1. It is characterized by family relationships at the mature age of 20-40 years. This class is well educated. This class increases internet activity and more requirements. This class does not spend much and tries to save money. The class has a large number of young children.\n\n------------------------------\n\n","6a4bdd18":"# Data loading and initial analysis","6ea5b130":"---------------\n\nWe connected all the necessary libraries.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=1&leftFill=%23FF0000 \"progress\") \n\n---------------","59508968":"# Application of deep statistical analysis\n### This is a parsing on transforming and changing the statistical indicators of a dataset.","a585d557":"---------------\n\nIt can be seen that the answer is more often 1 if the client is **PhD** and more often equal to 0 if **Graduation**. Which allows you to make a good judgment about the customer base.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=14&leftFill=%23FF0000 \"progress\") \n\n---------------","308b29fa":"# KMean Clustering","13c574a7":"---------------\n\nIt can be seen that the answer more often corresponds to 1 if the client is **Single** and more often to 0 if **Together** or **Married**. Which allows you to make a good judgment about the customer base.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=21&leftFill=%23FF0000 \"progress\") \n\n---------------","173b0f2a":"# Preprocessing","ca5d7960":"---------------\n\nWe performed preprocessing of the data. Made changes and deletions of some columns for better further data analysis.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=56&leftFill=%23FF0000 \"progress\") \n\n---------------","dc0dfe7b":"# Analysis of the resulting classes","429097bf":"---------------\n\nAdjust the normal distribution of Income. To do this, simply take the difference from the upper boundary of 100.\n\n![progress](http:\/\/www.yarntomato.com\/percentbarmaker\/button.php?barPosition=39&leftFill=%23FF0000 \"progress\") \n\n---------------"}}