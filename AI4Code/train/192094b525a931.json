{"cell_type":{"8ff52b89":"code","95432db0":"code","3f63d452":"code","df63fcb4":"code","09879e14":"code","ff0a84fc":"code","fe975476":"code","3e5dc02e":"code","fe79d9b6":"code","3a4a9253":"code","c40e524a":"code","490da438":"code","7dfc8663":"code","80526ed5":"code","de042f8a":"code","61ae2cff":"code","96a09fde":"code","57931e7e":"code","506e2f8e":"code","eef35e90":"code","049364ed":"code","831ce24c":"markdown","70bf658a":"markdown","b7e120a7":"markdown","314f79e2":"markdown","1131fc5c":"markdown","d122e2c4":"markdown","db84c401":"markdown","8d04c197":"markdown","451025de":"markdown","c5ade662":"markdown","0845733c":"markdown","3d56e2d0":"markdown","06113ca2":"markdown","0435221f":"markdown","05767652":"markdown","8e76a1ab":"markdown","c464a14e":"markdown","bfe41dde":"markdown","3a8e621e":"markdown"},"source":{"8ff52b89":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","95432db0":"training_data = pd.read_csv(\"..\/input\/udacity-mlcharity-competition\/census.csv\")\ntest_data = pd.read_csv(\"..\/input\/udacity-mlcharity-competition\/test_census.csv\", index_col=0)\n\nprint(\"Shape of Training Dataset:\", training_data.shape)\nprint(\"Shape of Testing Dataset:\", test_data.shape)\ntraining_data.head()","3f63d452":"print(training_data.income.value_counts(normalize=True))\nprint()\nprint(training_data.income.value_counts())","df63fcb4":"print(\"Null Values in training data:\", training_data.isna().sum().sum())\nprint(\"Null Values in Testing data:\", test_data.isna().sum().sum())","09879e14":"test_data.isna().sum()","ff0a84fc":"training_data.dtypes","fe975476":"X_test_fill_mean = test_data.fillna(test_data.mean())\nX_test_fill_mean.isna().sum()","3e5dc02e":"X_test_fill_mean.dtypes","fe79d9b6":"y_train_raw = training_data.income\nX_train_raw = training_data.drop('income', axis=1)","3a4a9253":"X_train_raw['capital-gain']","c40e524a":"plt.hist(X_train_raw['capital-gain'], bins=25)\nplt.title('capital-gain')\nplt.ylim([0, 2000])\nplt.show()\nplt.hist(X_train_raw['capital-loss'], bins=25)\nplt.title('capital-loss')\nplt.ylim([0, 2000])\nplt.show()","490da438":"skewed = ['capital-gain','capital-loss']\nX_train_log_transform = pd.DataFrame(X_train_raw)\nX_test_log_transform = pd.DataFrame(X_test_fill_mean)\n\nX_train_log_transform[skewed] = X_train_log_transform[skewed].apply(lambda x: np.log(x+1))\nX_test_log_transform[skewed] = X_test_log_transform[skewed].apply(lambda x: np.log(x+1))","7dfc8663":"plt.hist(X_train_log_transform['capital-gain'], bins=25)\nplt.title('capital-gain')\nplt.ylim([0, 2000])\nplt.show()\nplt.hist(X_train_log_transform['capital-loss'], bins=25)\nplt.title('capital-loss')\nplt.ylim([0, 2000])\nplt.show()","80526ed5":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnumerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n\nX_train_log_minmax_transform = pd.DataFrame(data = X_train_log_transform)\nX_train_log_minmax_transform[numerical] = scaler.fit_transform(X_train_log_transform[numerical])\n\nX_test_log_minmax_transform = pd.DataFrame(data = X_test_log_transform)\nX_test_log_minmax_transform[numerical] = scaler.transform(X_test_log_transform[numerical])\n","de042f8a":"X_train_log_minmax_transform.describe()","61ae2cff":"X_train = pd.get_dummies(X_train_log_minmax_transform)\nX_test = pd.get_dummies(X_test_log_minmax_transform)","96a09fde":"y_train = (y_train_raw=='>50K').map(int)","57931e7e":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, fbeta_score, accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\n\nclf = AdaBoostClassifier(random_state=42, n_estimators=100)\n\nparameters = {\n    'learning_rate': [0.001, 0.1, 1, 10]\n}\n\nscorer = make_scorer(fbeta_score, beta=0.5)\n\ngrid_obj = GridSearchCV(clf, param_grid=parameters, scoring=scorer)\n\ngrid_fit = grid_obj.fit(X_train, y_train)\n\nbest_clf = grid_fit.best_estimator_\n\nbest_predictions = best_clf.predict(X_train)\n\nprint(\"Final accuracy score on the training data: {:.4f}\".format(accuracy_score(y_train, best_predictions)))\nprint(\"Final F-score on the training data: {:.4f}\".format(fbeta_score(y_train, best_predictions, beta = 0.5)))","506e2f8e":"pred_test = best_clf.predict(X_test)","eef35e90":"pred_df = pd.DataFrame(pred_test, columns=['income'])\npred_df.index.names = [\"id\"]\npred_df","049364ed":"pred_df.to_csv(\"submission.csv\")","831ce24c":"## Splitting Training Features and Label","70bf658a":"### Filling Numberical Values with mean value","b7e120a7":"Normalize the Numerical Data","314f79e2":"It can be seen from above result that training data is highly biased. More than 75% of the data is for \"<=50K\"","1131fc5c":"## Checking null values in data","d122e2c4":"There are lots of null values in test data and so we need to fill in some values for these as we cannot delete these records as it is testing data.","db84c401":"## Finding Distribution of Numerical Data","8d04c197":"As it can be seen from above output, all the fields have null values, which we need to fill with some values","451025de":"## Log Transform the above data","c5ade662":"As we can see all numerical NA values are filled and only categoricals are remaining","0845733c":"### Convert Target Label to Numerical","3d56e2d0":"## One Hot Encoding","06113ca2":"From above output\n\n* **Numberical Features** : age, education-num, capital-gain, capital-loss, hours-per-week\n* **Categorical Features** : workclass, education_level, marital-status, occupation, relationship, race, sex, native-country\n* **Output label** : income (Categorical)","0435221f":"# Loading Datasets","05767652":"To fill in Null values,\n\n* **Numberical Features**: Need to be filled with relevant values, either mean or interpolled value\n* **Categorical Features**: Null values will be eliminated when converting the data to one-hot-encoding","8e76a1ab":"### Types of columns","c464a14e":"### Distribution of Null Values","bfe41dde":"# Training Model","3a8e621e":"## Distribution of Target Label"}}