{"cell_type":{"bb29f438":"code","c3e28f79":"code","7cec55e5":"code","9b3dc9f2":"code","64d2b8ca":"code","e06e1c38":"code","0c2af4c2":"code","ac471688":"code","fd7c42ce":"code","0ec063bb":"code","b9a5b07b":"code","b6cac779":"code","b0e8887c":"code","8b0597ce":"code","b290060f":"markdown"},"source":{"bb29f438":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c3e28f79":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt","7cec55e5":"train_dataset = pd.read_csv('..\/input\/fashion-mnist_train.csv')\ntest_dataset = pd.read_csv(\"..\/input\/fashion-mnist_test.csv\")\ntrain_dataset.head()","9b3dc9f2":"# now I have to split up the label column and pixels column\ny_train = train_dataset[\"label\"].values\nx_train = train_dataset.drop(\"label\", axis=1)\ny_test = test_dataset[\"label\"]\nx_test = test_dataset.drop(\"label\", axis=1)","64d2b8ca":"training_data = np.asarray(x_train).reshape(-1,28,28,1)\ntesting_data = np.asarray(x_test).reshape(-1,28,28,1)","e06e1c38":"import random\nplt.imshow(random.choice(training_data).reshape(28,28),cmap=\"gray\")","0c2af4c2":"# now lets add some deep learning","ac471688":"from tensorflow.keras.layers import Dense, Flatten, Activation,Dropout,Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom keras.utils import np_utils","fd7c42ce":"model = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n                        input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(30, activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","0ec063bb":"# compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])","b9a5b07b":"model.fit(training_data, y_train, batch_size=128, epochs=10,verbose=1)","b6cac779":"results = model.predict(testing_data)","b0e8887c":"labels = {0: \"T-shirt\/top\" ,1: \"Trouser\", 2: \"Pullover\",\n          3: \"Dress\", 4: \"Coat\", 5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\" }","8b0597ce":"fig = plt.figure(figsize=(20, 8))\nfor i, idx in enumerate(np.random.choice(testing_data.shape[0], size=24, replace=False)): \n    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(testing_data[idx]),cmap='gray')\n    pred_idx = np.argmax(results[idx])\n    ax.set_title(\"{}\".format(labels[pred_idx]))","b290060f":"0 T-shirt\/top ,1 Trouser, 2 Pullover,3 Dress, 4 Coat, 5 Sandal, 6 Shirt, 7 Sneaker, 8 Bag, 9 Ankle boot "}}