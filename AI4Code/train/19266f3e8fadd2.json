{"cell_type":{"1719c2ae":"code","6d37241a":"code","99837099":"code","15e9c8ed":"code","34f11f41":"code","b1867485":"code","b6dd6654":"code","5b570c88":"code","0c0d44fc":"code","d0a125db":"code","53e74551":"code","3ffd928c":"code","9707ae38":"code","f389c52b":"code","4c431ba7":"code","3dff5056":"code","6b4ea6f3":"code","1c8db53c":"code","799e3a1c":"code","64827ae7":"code","1acf5ed4":"code","52f83682":"markdown","03e92ae7":"markdown"},"source":{"1719c2ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d37241a":"from kaggle_environments import make","99837099":"seed=562124210\nenv = make(\"lux_ai_2021\", configuration={\"seed\": seed, \"loglevel\": 2, \"annotations\": True}, debug=True)","15e9c8ed":"steps = env.run([\"simple_agent\", \"simple_agent\"])\nenv.render(mode=\"ipython\", width=1200, height=800)","34f11f41":"seed=48\nenv = make(\"lux_ai_2021\", configuration={\"seed\": seed, \"loglevel\": 2, \"annotations\": True}, debug=True)","b1867485":"steps = env.run([\"simple_agent\", \"simple_agent\"])\nenv.render(mode=\"ipython\", width=1200, height=800)\n","b6dd6654":"!cp -r ..\/input\/lux-ai-2021\/* .","5b570c88":"from lux.game import Game\nfrom lux.game_map import Cell, RESOURCE_TYPES, Position\nfrom lux.constants import Constants\nfrom lux.game_constants import GAME_CONSTANTS\nfrom lux import annotate\nimport math\nimport sys\n\ngame_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n    \n    if game_state.turn == 0:\n        print(\"Agent is running!\", file=sys.stderr)\n        actions.append(annotate.circle(0, 0))\n    return actions","0c0d44fc":"steps = env.run([agent, \"simple_agent\"])","d0a125db":"env.render(mode=\"ipython\", width=800, height=800)\n","53e74551":"def find_resources(game_state):\n    resource_tiles: list[Cell] = []\n    width, height = game_state.map_width, game_state.map_height\n    for y in range(height):\n        for x in range(width):\n            cell = game_state.map.get_cell(x, y)\n            if cell.has_resource():\n                resource_tiles.append(cell)\n    return resource_tiles\n\ndef find_closest_resources(pos, player, resource_tiles):\n    closest_dist = math.inf\n    closest_resource_tile = None\n    for resource_tile in resource_tiles:\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.COAL and not player.researched_coal(): continue\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.URANIUM and not player.researched_uranium(): continue\n        dist = resource_tile.pos.distance_to(pos)\n        if dist < closest_dist:\n            closest_dist = dist\n            closest_resource_tile = resource_tile\n    return closest_resource_tile","3ffd928c":"resource_tiles = find_resources(game_state)\ncell = resource_tiles[0]\nprint(\"Cell at\", cell.pos, \"has\")\nprint(cell.resource.type, cell.resource.amount)","9707ae38":"cell = find_closest_resources(Position(1, 1), game_state.players[0], resource_tiles)\nprint(\"Closest resource at\", cell.pos, \"has\")\nprint(cell.resource.type, cell.resource.amount)","f389c52b":"game_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n    \n    if game_state.turn == 0:\n        print(\"Agent is running!\", file=sys.stderr)\n\n    resource_tiles = find_resources(game_state)\n    \n    for unit in player.units:\n        if unit.is_worker() and unit.can_act():\n            if unit.get_cargo_space_left() > 0:\n                closest_resource_tile = find_closest_resources(unit.pos, player, resource_tiles)\n                if closest_resource_tile is not None:\n                    action = unit.move(unit.pos.direction_to(closest_resource_tile.pos))\n                    actions.append(action)\n    \n    return actions","4c431ba7":"seed=42\nenv = make(\"lux_ai_2021\", configuration={\"seed\": seed, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run([agent, \"simple_agent\"])\nenv.render(mode=\"ipython\", width=800, height=800)","3dff5056":"def find_closest_city_tile(pos, player):\n    closest_city_tile = None\n    if len(player.cities) > 0:\n        closest_dist = math.inf\n        for k, city in player.cities.items():\n            for city_tile in city.citytiles:\n                dist = city_tile.pos.distance_to(pos)\n                if dist < closest_dist:\n                    closest_dist = dist\n                    closest_city_tile = city_tile\n    return closest_city_tile","6b4ea6f3":"game_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n    \n    if game_state.turn == 0:\n        print(\"Agent is running!\", file=sys.stderr)\n\n    resource_tiles = find_resources(game_state)\n    \n    for unit in player.units:\n        if unit.is_worker() and unit.can_act():\n            if unit.get_cargo_space_left() > 0:\n                closest_resource_tile = find_closest_resources(unit.pos, player, resource_tiles)\n                if closest_resource_tile is not None:\n                    action = unit.move(unit.pos.direction_to(closest_resource_tile.pos))\n                    actions.append(action)\n            else:\n                closest_city_tile = find_closest_city_tile(unit.pos, player)\n                if closest_city_tile is not None:\n                    action = unit.move(unit.pos.direction_to(closest_city_tile.pos))\n                    actions.append(action)\n    \n    return actions","1c8db53c":"seed=41\nenv = make(\"lux_ai_2021\", configuration={\"seed\": seed, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run([agent, \"simple_agent\"])\nenv.render(mode=\"ipython\", width=1200, height=800)","799e3a1c":"%%writefile agent.py\nfrom lux.game import Game\nfrom lux.game_map import Cell, RESOURCE_TYPES\nfrom lux.constants import Constants\nfrom lux.game_constants import GAME_CONSTANTS\nfrom lux import annotate\nimport math\nimport sys\n\ndef find_resources(game_state):\n    resource_tiles: list[Cell] = []\n    width, height = game_state.map_width, game_state.map_height\n    for y in range(height):\n        for x in range(width):\n            cell = game_state.map.get_cell(x, y)\n            if cell.has_resource():\n                resource_tiles.append(cell)\n    return resource_tiles\n\ndef find_closest_resources(pos, player, resource_tiles):\n    closest_dist = math.inf\n    closest_resource_tile = None\n    for resource_tile in resource_tiles:\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.COAL and not player.researched_coal(): continue\n        if resource_tile.resource.type == Constants.RESOURCE_TYPES.URANIUM and not player.researched_uranium(): continue\n        dist = resource_tile.pos.distance_to(pos)\n        if dist < closest_dist:\n            closest_dist = dist\n            closest_resource_tile = resource_tile\n    return closest_resource_tile\n\ndef find_closest_city_tile(pos, player):\n    closest_city_tile = None\n    if len(player.cities) > 0:\n        closest_dist = math.inf\n        for k, city in player.cities.items():\n            for city_tile in city.citytiles:\n                dist = city_tile.pos.distance_to(pos)\n                if dist < closest_dist:\n                    closest_dist = dist\n                    closest_city_tile = city_tile\n    return closest_city_tile\n\ngame_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    player = game_state.players[observation.player]\n    opponent = game_state.players[(observation.player + 1) % 2]\n    width, height = game_state.map.width, game_state.map.height\n\n    resource_tiles = find_resources(game_state)\n    \n    for unit in player.units:\n        if unit.is_worker() and unit.can_act():\n            if unit.get_cargo_space_left() > 0:\n                closest_resource_tile = find_closest_resources(unit.pos, player, resource_tiles)\n                if closest_resource_tile is not None:\n                    action = unit.move(unit.pos.direction_to(closest_resource_tile.pos))\n                    actions.append(action)\n            else:\n                closest_city_tile = find_closest_city_tile(unit.pos, player)\n                if closest_city_tile is not None:\n                    action = unit.move(unit.pos.direction_to(closest_city_tile.pos))\n                    actions.append(action)\n                    \n        \n    return actions\n","64827ae7":"!tar -czf submission.tar.gz *","1acf5ed4":"import json\nreplay = env.toJSON()\nwith open(\"replay.json\", \"w\") as f:\n    json.dump(replay, f)","52f83682":"### PLEASE UPVOTE if you like this notebook. It will keep me motivated to update my notebook. :)\n\n#### What are you trying to do in this notebook?\nThe Lux AI Challenge is a competition where I design agents to tackle a multi-variable optimization, resource gathering, and allocation problem in a 1v1 scenario against other competitors. Gather the most resources and survive the night!\n\nIn addition to optimization, successful agents must be capable of analyzing their opponents and developing appropriate policies to get the upper hand.\n\n#### Why are you trying it?\nI'm trying to the Lux AI Challenge centers itself on developing creative, accessible, inclusive, and engaging AI competitions.\nTo tackle a multi-variable optimization, resource gathering, and allocation problem in a 1v1 scenario against other competitors. In addition to optimization, successful agents must be capable of analyzing their opponents and developing appropriate policies to get the upper hand.\n","03e92ae7":"#### Did it work?\nYes, It works.\n\n#### What did you not understand about this process?\nWell, everything provides in the competition data page. I've no problem while working on it. If you guys don't understand the thing that I'll do in this notebook then please comment on this notebook.\n\n#### What else do you think you can try as part of this approach?\nWell, everything is in its place. If I feel like i need to add something to it then i'll definitely do this.\n\n"}}