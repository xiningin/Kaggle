{"cell_type":{"e964f020":"code","c8f068df":"code","2e26acf3":"code","aa18096a":"code","aed23b3a":"code","9deb49de":"code","87f5a6df":"code","1258996f":"code","6768bb22":"code","51469fa9":"code","2381c83b":"code","35cd4c17":"code","eca77a38":"code","bbba13b8":"code","4d66bb7c":"code","84911c45":"code","df8ead82":"code","3d021925":"code","c87a1be1":"code","35222e47":"code","fcc28808":"code","2a61a5a4":"code","7e09f59e":"code","83fd268d":"code","b6933a96":"code","a6f084a0":"markdown","db17194b":"markdown","03acb54d":"markdown","705ee074":"markdown","ca0e50cb":"markdown","6f151a5e":"markdown","fed5bfc5":"markdown","4c3e496a":"markdown","76f0ba6d":"markdown"},"source":{"e964f020":"# Importing all necessary Python libraries.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","c8f068df":"# Retrieving the data.\ndf = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","2e26acf3":"df.head()","aa18096a":"df.describe()","aed23b3a":"df.info()","9deb49de":"# Dropping the unnamed feature.\ndf2 = df.drop(columns=['Unnamed: 32', 'id'])","87f5a6df":"# Replacing the diagnosis of malignant or benign with 1s and 0s.\ndf2['diagnosis'].replace({'M':1, 'B':0}, inplace = True)","1258996f":"df2.info()","6768bb22":"X = df2.iloc[:, 1:].values\ny = df2['diagnosis']","51469fa9":"# Using standard scaler to receive values from +3 to -3.\nfrom sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","2381c83b":"# Applying PCA to reduce the dimensionality of the data.\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents1 = pca.fit_transform(X)","35cd4c17":"principalComponents1","eca77a38":"# Splitting the data into training and testing sets.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","bbba13b8":"# Implementing Logistic Regression.\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state = 0)\nlr.fit(X_train, y_train)","4d66bb7c":"y_pred = lr.predict(X_test)","84911c45":"# Visualizing the confusion matrix.\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","df8ead82":"# Implementing Support Vector Machine.\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'linear', random_state = 0)\nsvc.fit(X_train, y_train)","3d021925":"y_pred = svc.predict(X_test)","c87a1be1":"# Visualizing the confusion matrix.\ncm1 = confusion_matrix(y_test, y_pred)\nprint(cm1)\naccuracy_score(y_test, y_pred)","35222e47":"# Implementing Decision Tree.\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\ndt.fit(X_train, y_train)","fcc28808":"y_pred = dt.predict(X_test)","2a61a5a4":"# Visualizing the confusion matrix.\ncm2 = confusion_matrix(y_test, y_pred)\nprint(cm2)\naccuracy_score(y_test, y_pred)","7e09f59e":"# Implementing KNN.\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn.fit(X_train, y_train)","83fd268d":"y_pred = knn.predict(X_test)","b6933a96":"# Visualizing the confusion matrix.\ncm3 = confusion_matrix(y_test, y_pred)\nprint(cm3)\naccuracy_score(y_test, y_pred)","a6f084a0":"# Data","db17194b":"# Importing Libraries","03acb54d":"# KNN","705ee074":"# 4 Different Algorithms on Breast Cancer Dataset","ca0e50cb":"# SVM","6f151a5e":"# Feature Engineering with Standardization and PCA","fed5bfc5":"# Decision Tree","4c3e496a":"# Logistic Regression","76f0ba6d":"In this notebook I have used four different machine learning algorithms on the Wisconsin Diagnostic Breast Cancer Dataset. I have used Logistic Regression, SVM, Decision Tree, and KNN. This is a walkthrough of each of the 4 algorithms for anyone new to ML. Hope you enjoy!"}}