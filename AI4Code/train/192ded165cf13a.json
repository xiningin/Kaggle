{"cell_type":{"5914d778":"code","87db85b5":"code","83efdce7":"code","16f12e72":"code","82720579":"code","2d9a8d38":"code","25e76ff6":"code","18168076":"code","b55dec9a":"code","998689b1":"code","95e7d2b7":"code","e64cb88f":"code","e31c7b3b":"code","b6d4139a":"code","2695ce85":"code","c9f480e9":"code","9a1981bc":"code","353d74d5":"code","2bf2e8a2":"code","f8828f27":"code","756f4a44":"code","3ffa29b4":"code","9ba60bad":"code","4bf5b559":"code","81c49515":"code","1b4f0269":"markdown","fcdbeb37":"markdown","ce733b32":"markdown","b87d3e27":"markdown","89b37249":"markdown","e1b23db5":"markdown","2c11cd5a":"markdown","0c903f4d":"markdown","620e688f":"markdown","6e912771":"markdown","5ef404e0":"markdown"},"source":{"5914d778":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pathlib\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gc\nprint(os.listdir(\"..\/input\"))\n\nfrom sklearn.metrics import confusion_matrix\nfrom fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *\n\n# Any results you write to the current directory are saved as output.","87db85b5":"cache_dir = os.path.expanduser(os.path.join('~', '.torch'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","83efdce7":"!cp ..\/input\/resnet34\/resnet34.pth \/tmp\/.torch\/models\/resnet34-333f7ec4.pth","16f12e72":"PATH = '..\/input\/flowers-train-valid-split\/flowers_split\/flowers_split\/'\nsz=224","82720579":"os.listdir(f'{PATH}valid')","2d9a8d38":"torch.cuda.is_available()","25e76ff6":"sample = os.listdir(f'{PATH}valid\/daisy')[:5]\n#sample","18168076":"img = plt.imread(f'{PATH}valid\/daisy\/{sample[0]}')\nplt.imshow(img);\ndel sample","b55dec9a":"#img.shape\ndel img","998689b1":"arch = resnet34\ndata = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch,224))\ndata.path = pathlib.Path('.')  ## IMPORTANT for PyTORCH to create tmp directory which won't be otherwise allowed on Kaggle Kernel directory structure\nlearn = ConvLearner.pretrained(arch, data, precompute=False) #Precompute=True causes the Commit & run operation to fail\nlearn.fit(0.01, 2)","95e7d2b7":"gc.collect()\ndata.classes","e64cb88f":"log_preds = learn.predict()\nlog_preds.shape\npreds = np.argmax(log_preds, axis=1)\nprobs = np.exp(log_preds[:,1]) ","e31c7b3b":"def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\ndef rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)\n\ndef plot_val_with_title(idxs, title):\n    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n    title_probs = [probs[x] for x in idxs]\n    print(title)\n    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)\n\ndef plots(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)\/\/rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\n\ndef load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n\ndef plot_val_with_title(idxs, title):\n    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n    title_probs = [probs[x] for x in idxs]\n    print(title)\n    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))","b6d4139a":"plot_val_with_title(rand_by_correct(True), \"Correctly classified\")","2695ce85":"def most_by_mask(mask, mult):\n    idxs = np.where(mask)[0]\n    return idxs[np.argsort(mult * probs[idxs])[:4]]\n\ndef most_by_correct(y, is_correct): \n    mult = -1 if (y==1)==is_correct else 1\n    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)","c9f480e9":"plot_val_with_title(most_by_correct(2, True), \"Most correct Roses\")","9a1981bc":"lrf=learn.lr_find()","353d74d5":"learn.sched.plot()","2bf2e8a2":"del data\ndel learn","f8828f27":"tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\ndata = ImageClassifierData.from_paths(PATH, tfms=tfms)\ndata.path = pathlib.Path(\".\")\nlearn = ConvLearner.pretrained(arch, data, precompute=False)\nlearn.fit(1e-2, 1)\ngc.collect()","756f4a44":"learn.precompute = False\nlearn.unfreeze()\nlr=np.array([1e-4,1e-3,1e-2])\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n#learn.sched.plot_lr()","3ffa29b4":"log_preds,y = learn.TTA()\nprobs = np.mean(np.exp(log_preds),0)","9ba60bad":"accuracy_np(probs, y)","4bf5b559":"#plt.figure(figsize=(15,15))\npreds = np.argmax(probs, axis=1)\nprobs = probs[:,1]\ncm = confusion_matrix(y, preds)","81c49515":"plot_confusion_matrix(cm, data.classes, figsize=(10,10))","1b4f0269":"## Best Model (93% Accuracy)\n\n- **No precomputed activations.**\n- **Unfreezing all layers.**\n- **Use of SGDR with varying Learning Rates for each set of layers.**","fcdbeb37":"### Image Dimensions\n\nHere, we have got ourselves a standard **3 Channel** image so our pretrained models should work fine with added tricks of Data Augmentation.","ce733b32":"# Create a confusion matrix to visualize class-wise results!","b87d3e27":"## Baseline Model (88% Accuracy)\n\n- Resnet34 Architecture\n- Precomputed Activations\n- No Data Augmentation","89b37249":"## Confusion Matrix (Dev Set)","e1b23db5":"### Necessary Library Imports\n\nA directory containing pretrained **Resnet34** model was also required and was available on Kaggle as a public dataset.","2c11cd5a":"### Check status of GPU Availability","0c903f4d":"### Learning Rate ~ 0.01","620e688f":"The following are the two helper modules required to put Resnet34 weights in the apt directory for PyTorch to use directly. These were taken from Anshul Rai's [kernel here](https:\/\/www.kaggle.com\/anshulrai\/using-fastai-in-kaggle-kernel).","6e912771":"## Finding a Learning Rate\n\nUsing the `lr_find` (learning rate finder) from the FastAI library to get an optimum learning rate.","5ef404e0":"#### Flower Classification\n\nList of classes of Flowers given in the dataset-\n1. Daisy\n2. Rose\n3. Dandelion\n4. Tulip\n5. Sunflower\n\nIdea here is to fine-tune a pretrained model (**Resnet34**) using the FastAI Library to get the best possible (close to SOTA) result."}}