{"cell_type":{"163c9675":"code","bc3f053b":"code","40733dba":"code","5c863245":"code","aa81f50d":"code","ab298f0b":"code","5f326196":"markdown"},"source":{"163c9675":"#IMPORT FILE NECESSARY TO RUN THE CODE\n#dataset is imported in order to get the boston house dataset from sklearn \nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error","bc3f053b":"boston=datasets.load_boston()\nx=boston.data[:,:]\ny=boston.target\nprint(x.shape,y.shape)\nxtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20,random_state=42)","40733dba":"def dis(v,w):\n    return np.sqrt(np.sum((v-w)**2))","5c863245":"def knn_r(tr, tr_lab, te , k):\n    distances = []\n    \n    for i in range(tr.shape[0]):\n        distances.append(dis(tr[i], te))\n    \n    distances = np.array(distances)\n    inds = np.argsort(distances)\n    \n    distances = distances[inds]\n    tr_lab_2 = tr_lab[inds]\n    value = np.average(tr_lab_2[:k])\n    \n    return value","aa81f50d":"def knn_reg(tr , tr_lab, te , te_lab , k):\n    preds = []\n    for i in range(te.shape[0]):\n        value = knn_r(tr, tr_lab, te[i] , k)\n        preds.append(value)\n    \n    preds  = np.array(preds)\n    err = mean_squared_error(te_lab , preds)\n    return err","ab298f0b":"acc = knn_reg(xtrain , ytrain , xtest , ytest ,5)\nprint (\"MEAN SQUARED ERROR:\",acc)","5f326196":"**BOSTON HOUSE PRICING **\n\n*CONCEPT USED: KNN (k nearest neigbours)*\n\n\nthe program is just for understanding the most basic ML algorithm that is KNN \n\n\nDIFFICULTY LEVEL : **EASY** \n\n\nThe algorithm estimates the cost of the house.\n\n**KNN is not the right approch for this particular problem.**\n\nthats why the mean squared error is as high as 25%\n\nbut this is just an example showing how we can use KNN for regression problems. \n The main purpose of KNN is basically for classification problems.\n \n KNN is the easiest algorithm to start undderstanding the ML algo\n "}}