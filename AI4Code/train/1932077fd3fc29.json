{"cell_type":{"f5cfe75a":"code","95597c94":"code","9ae52333":"code","ee9e4ac0":"code","bb0e26f3":"code","4d23b53b":"code","4dd6e0d7":"code","0b309b73":"code","d3fe321b":"code","4ad69aff":"code","d0e943db":"code","d9a2e697":"code","2866cd01":"code","b5d715ce":"code","50a4dfe1":"code","6bc4d269":"code","7aec8c53":"code","7de8d349":"code","ef4b27da":"code","203d59a8":"code","af9bac75":"code","f35fc71f":"code","97d0b913":"code","3b2eea6a":"code","12b4355d":"markdown","9615620e":"markdown","1404d9c7":"markdown","c281f767":"markdown","d575711b":"markdown","3a9c988d":"markdown","47e6e15b":"markdown","7da533de":"markdown"},"source":{"f5cfe75a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95597c94":"from xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.filterwarnings('ignore')","9ae52333":"import warnings","ee9e4ac0":"train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')","bb0e26f3":"x_data = train.drop(['id', 'claim'], axis=1)\ny_data = train.claim\n\nx_test = test.drop('id', axis=1)","4d23b53b":"print('x_data shape {}'.format(x_data.shape))\nprint('x_test shape {}'.format(x_test.shape))","4dd6e0d7":"# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import roc_auc_score\n\n# model = LogisticRegression()","0b309b73":"# from sklearn.tree import DecisionTreeClassifier\n\n# model = DecisionTreeClassifier()\n\n# from sklearn.model_selection import train_test_split\n\n# x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.3, random_state=50)\n\n\n# model.fit(x_train, y_train)\n# y_pred = model.predict_proba(x_val)[:, 1]\n# roc_auc_score(y_val, y_pred)","d3fe321b":"x_data['n_missing'] = x_data.isna().sum(axis=1)\nx_test['n_missing'] = test.isna().sum(axis=1)","4ad69aff":"# from sklearn.impute import SimpleImputer\n\n# imputer = SimpleImputer(strategy=\"median\")\n# x_data = imputer.fit_transform(x_data)\n# x_test = imputer.transform(x_test)","d0e943db":"# pd.DataFrame(x_data).isna().sum()\n# pd.DataFrame(x_test).isna().sum()","d9a2e697":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nx_data_scaler = scaler.fit_transform(x_data)\nx_test_scaler = scaler.transform(x_test)","2866cd01":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_data_scaler, y_data, test_size=0.3, random_state=50)\n","b5d715ce":"# from sklearn.ensemble import AdaBoostClassifier\n# adaboost = AdaBoostClassifier()\n# adaboost.fit(x_train, y_train)\n# y_pred = adaboost.predict_proba(x_val)[:, 1]","50a4dfe1":"# from sklearn.metrics import roc_auc_score\n# roc_auc_score(y_val, y_pred)","6bc4d269":"def objective(trial):\n\n    param_grid = {'objective': 'binary:logistic',\n              'use_label_encoder': False,\n              'n_estimators': trial.suggest_int('n_estimators', 500, 5000),\n              'learning_rate': trial.suggest_discrete_uniform('learning_rate',0.01,0.1,0.01),\n              'subsample': trial.suggest_discrete_uniform('subsample', 0.3, 1.0, 0.1),\n              'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree',0.1,1.0, 0.1),\n              'max_depth': trial.suggest_int('max_depth', 2, 20),\n              'booster': 'gbtree',\n              'gamma': trial.suggest_uniform('gamma',1.0,10.0),\n              'reg_alpha': trial.suggest_int('reg_alpha',50,100),\n              'reg_lambda': trial.suggest_int('reg_lambda',50,100),\n              'random_state': 42,\n                 }\n\n\n    xgb_model = XGBClassifier(**param_grid, tree_method='gpu_hist', predictor='gpu_predictor',\n                            eval_metric=['logloss'])\n\n    xgb_model.fit(x_train, y_train, verbose=False)\n    y_pred = xgb_model.predict_proba(x_val)[:, 1]\n    return roc_auc_score(y_val, y_pred)\n","7aec8c53":"import optuna\nfrom optuna.samplers import TPESampler\n\ntrain_time = 1 * 30 * 60 # h * m * s\nstudy = optuna.create_study(direction='maximize', sampler=TPESampler(), study_name='XGBClassifier')\nstudy.optimize(objective, timeout=train_time)\n\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial:')\ntrial = study.best_trial\n\nprint('\\tValue: {}'.format(trial.value))\nprint('\\tParams: ')\nfor key, value in trial.params.items():\n    print('\\t\\t{}: {}'.format(key, value))","7de8d349":"xgb_params = trial.params\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['predictor'] = 'gpu_predictor'\n\n# xgb_params = {\n#     'objective': 'binary:logistic',\n#     'use_label_encoder': False,\n#     'n_estimators': 2299,\n#     'learning_rate': 0.05968414618557474,\n#     'subsample': 0.8,\n#     'colsample_bytree': 0.9,\n#     'max_depth': 5,\n#     'booster': 'gbtree',\n#     'gamma': 1.550895536131489,\n#     'reg_alpha': 84,\n#     'reg_lambda': 93,\n#     'tree_method': 'gpu_hist',\n#     'predictor': 'gpu_predictor',\n#     'n_jobs': 4\n# }\n\n# xgb_params = {'objective': 'binary:logistic',\n#               'use_label_encoder': False,\n#               'n_estimators': 5000,\n#               'learning_rate': 0.04,\n#               'subsample': 0.66,\n#               'colsample_bytree': 0.9,\n#               'max_depth': 4,\n#               'booster': 'gbtree',\n#               'gamma': 3.5,\n#               'reg_alpha': 81.8,\n#               'reg_lambda': 72.0,\n#               'random_state': 42,\n#               'tree_method': 'gpu_hist',\n#               'predictor': 'gpu_predictor',\n#               'n_jobs': 4}","ef4b27da":"from sklearn.model_selection import KFold\n\nn_split = 10\nkfold = KFold(n_split)\n\nval_pred = np.zeros(y_data.shape)\ny_test = np.zeros((x_test.shape[0],))\n\nfor i, (train_index, val_index) in enumerate(kfold.split(x_data_scaler)):\n    # train model\n    print(\"fold {} training\".format(i))\n    model = XGBClassifier(**xgb_params, eval_metric=['logloss'])\n    model.fit(x_data_scaler[train_index], y_data[train_index])\n    \n    # predict val and test\n    val_pred[val_index] = model.predict_proba(x_data_scaler[val_index])[:, 1]\n    vla_score = roc_auc_score(y_data[val_index], val_pred[val_index])\n    print(\"fold {} validation auc score {}\".format(i, vla_score))\n    \n    y_test += model.predict_proba(x_test_scaler)[:, 1] \/ n_split\n    \n# evaluate validation score    \nprint(\"val auc score :\", roc_auc_score(y_data, val_pred))","203d59a8":"# xgb_model = XGBClassifier(**xgb_params)\n\n# xgb_model.fit(x_train, y_train)\n# y_val_probe = xgb_model.predict_proba(x_val)","af9bac75":"# train_auc = roc_auc_score(y_train, xgb_model.predict_proba(x_train)[:, 1])\n# val_auc = roc_auc_score(y_val, y_val_probe[:, 1])\n\n# print(\"train auc {}\\nval auc {}\".format(train_auc, val_auc))","f35fc71f":"# y_test = xgb_model.predict_proba(x_test_scaler)[:, 1]","97d0b913":"sub_mission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')\nsub_mission.claim = y_test\nsub_mission.to_csv('submission.csv', index=False)","3b2eea6a":"import seaborn as sns\nsns.histplot(y_test)","12b4355d":"### submission","9615620e":"### best params","1404d9c7":"### KFold","c281f767":"train auc 0.8202678946011855\nval auc 0.8138542447335897","d575711b":"### data preprocessing","3a9c988d":"### optuna","47e6e15b":"\tValue: 0.8156367214564837\n\tParams: \n\t\tn_estimators: 2299\n\t\tlearning_rate: 0.05968414618557474\n\t\tsubsample: 0.8\n\t\tmax_depth: 5\n\t\tgamma: 1.550895536131489\n\t\treg_alpha: 50\n\t\treg_lambda: 100\n\t\ttree_method: gpu_hist\n\t\tpredictor: gpu_predictor","7da533de":"### adaboost"}}