{"cell_type":{"b0e6196c":"code","4aa90d99":"code","0e87d6e0":"code","2924e69d":"code","92c98aef":"code","581de3e2":"code","ec996940":"code","c12b2e84":"markdown","b2865ed5":"markdown","712ff432":"markdown","863a580b":"markdown","c6fcf29f":"markdown"},"source":{"b0e6196c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4aa90d99":"import tensorflow\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport pandas as pd\nimport shutil","0e87d6e0":"%mkdir -p data\/train\n%mkdir -p data\/valid\n%cd data\/\n%mkdir -p train\/daisy\n%mkdir -p train\/dandelion\n%mkdir -p train\/rose\n%mkdir -p train\/sunflower\n%mkdir -p train\/tulip\n\n%mkdir -p valid\/daisy\n%mkdir -p valid\/dandelion\n%mkdir -p valid\/rose\n%mkdir -p valid\/sunflower\n%mkdir -p valid\/tulip","2924e69d":"class Preprocessing:\n    \n    def __init__(self,base_path,categories,t_path,v_path):\n        self.categories = categories\n        self.path = base_path\n        self.train_path = t_path\n        self.validation_path = v_path\n        self.df_list = []\n        \n    def load_flowers_data(self):   \n        for flower in self.categories:\n            images = []  \n            images = os.listdir(self.path+\"\/\"+flower)\n            for image in images:\n                self.df_list.append((flower,self.path+\"\/\"+flower+\"\/\"+image))\n        flowers = pd.DataFrame(self.df_list,columns=['category','image_path'])\n        return flowers\n    \n    def copy_util(self,df,category,dest):\n        for idx,row in df.iterrows():\n            shutil.copy(row[\"image_path\"],dest+\"\/\"+category+\"\/\"+row[\"image_path\"].split(\"\/\")[-1])\n            \n    \n    def random_image_split(self,flowers):\n        for category in categories:\n            valid_data = flowers_data[flowers_data[\"category\"]==category].sample(frac=0.2).reset_index(drop=True)\n            self.copy_util(valid_data,category,self.validation_path)\n            val_idx = valid_data.index\n            train_data = flowers_data[(~flowers_data.index.isin(val_idx)) & (flowers_data[\"category\"] == category)]\n            self.copy_util(train_data,category,self.train_path)            \n            \n        ","92c98aef":"base_path = \"\/kaggle\/input\/flowers-recognition\/flowers\/flowers\"\ntrain_path = \"\/kaggle\/working\/data\/train\"\nvalidation_path = \"\/kaggle\/working\/data\/valid\"\ncategories = os.listdir(base_path)\nprep = Preprocessing(base_path,categories,train_path,validation_path)\nflowers_data = prep.load_flowers_data()\nprep.random_image_split(flowers_data)","581de3e2":"num_classes = 5\nresnet_weights_path = '\/kaggle\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nflowers_model = Sequential()\nflowers_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nflowers_model.add(Dense(num_classes, activation='softmax'))\n\nflowers_model.compile(optimizer='sgd', \n                     loss='categorical_crossentropy', \n                     metrics=['accuracy'])\n\n\nflowers_model.layers[0].trainable = False","ec996940":"image_size = 224\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                              horizontal_flip = True)\ntrain_generator = data_generator.flow_from_directory(\n                                        directory='\/kaggle\/working\/data\/train',\n                                        target_size=(image_size, image_size),\n                                        batch_size=100,\n                                        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n                                        directory='\/kaggle\/working\/data\/valid',\n                                        target_size=(image_size, image_size),\n                                        class_mode='categorical')\nfit_stats = flowers_model.fit_generator(train_generator,\n                                       steps_per_epoch=41,\n                                       validation_data=validation_generator,\n                                       validation_steps=1)","c12b2e84":"Load the pretrained Resnet50 weights and specify the output classes (five categories here). Specify the False to skip training the first layer,since we are using transfer learning here","b2865ed5":"Creating folders to split training and validion data, which can be later inferred directly using Keras image preprocessing API rather than creating lables manually","712ff432":"Download all necessary packages","863a580b":"Creating preprocessing class that will take care of loading and splitting the data between train and validation folders","c6fcf29f":"We need to create the data generator with data augumentation,i.e we will enable horizontal_flip, this helps us to include the horizontal flipped image for training.\n\n"}}