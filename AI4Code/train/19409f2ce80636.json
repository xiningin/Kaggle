{"cell_type":{"93ae5792":"code","d7ef8f9c":"code","ad81fb7d":"code","3fa6a53a":"code","d689aa1a":"code","b2e6a854":"code","d8a9c14f":"code","74cf7674":"code","a6973c77":"code","8e252665":"code","8fca24ff":"code","47a8dd5a":"code","62050157":"code","0980738c":"code","cd405fe6":"code","b08b2318":"code","60248fda":"code","ac50d3a0":"code","c42bead7":"code","251c20b2":"code","9b611bba":"code","06442920":"code","ae2d1d99":"markdown","e1bee157":"markdown","e55dc803":"markdown","c0a9f34b":"markdown","29630106":"markdown","176f5600":"markdown","1eafb520":"markdown","c08965a1":"markdown","d443fe1c":"markdown","538f5d27":"markdown","63424c7a":"markdown","f762d250":"markdown","609809b8":"markdown","d9768e8d":"markdown","15b6c2b7":"markdown"},"source":{"93ae5792":"#Importing required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom datetime import date \nimport holidays \nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#         break\n    ","d7ef8f9c":"# Reading dataset\nmarketing_spent = pd.read_csv('\/kaggle\/input\/google-store-ecommerce-data-fake-retail-data\/Marketing_Spend.csv')\nonline = pd.read_csv('\/kaggle\/input\/google-store-ecommerce-data-fake-retail-data\/Online.csv')","ad81fb7d":"marketing_spent.head(2)","3fa6a53a":"online.head(2)","d689aa1a":"marketing_spent.rename(columns = {'Unnamed: 0':'Date'}, inplace = True) \nmarketing_spent['Date']= pd.to_datetime(marketing_spent['Date'])\nonline['Date'] = pd.to_datetime(online['Date'], format='%Y%m%d')","b2e6a854":"# understanding marketing spent dataset\nprint(\"Total number of rows:\",online.shape[0])\nprint(\"Total number of colums:\",online.shape[1])\nprint(\"\\n\\nList of columns:\", online.columns.tolist())\nprint(\"\\n\\nDate Range:\", online['Date'].min(), \"to\", online['Date'].max())\nprint(\"\\n\\nDatatypes:\\n\",online.dtypes)\nprint(\"\\n\\nUnique values:\\n\",online.nunique())\nprint(\"\\n\\nMissing values:\\n\",online.isnull().sum())\nprint(\"\\n\\nQuantitative analysis\\n\", online.describe())","d8a9c14f":"# understanding marketing spent dataset\nprint(\"Total number of rows:\",marketing_spent.shape[0])\nprint(\"Total number of colums:\",marketing_spent.shape[1])\nprint(\"\\n\\nList of columns:\", marketing_spent.columns.tolist())\nprint(\"\\n\\nDate Range:\", marketing_spent['Date'].min(), \"to\", marketing_spent['Date'].max())\nprint(\"\\n\\nDatatypes:\\n\",marketing_spent.dtypes)\nprint(\"\\n\\nUnique values:\\n\",marketing_spent.nunique())\nprint(\"\\n\\nMissing values:\\n\",marketing_spent.isnull().sum())\nprint(\"\\n\\nQuantitative analysis\\n\", marketing_spent.describe())","74cf7674":"df = pd.merge(marketing_spent,online,left_on=['Date'],right_on=['Date'])\ndf.shape","a6973c77":"df.columns = df.columns.str.replace(' ', '_')\n# Missing values compution\ndf = df.fillna(axis=0, method='ffill')\ndf.head(2)","8e252665":"df2 = df.copy()\ndf2 = df2[['Date', 'Quantity']]\nprint(\"Shape:\",df2.shape,\"\\n\")\nprint(df2.info(),\"\\n\")\nprint(\"Missing values:\\n\",df2.isnull().sum())\nprint(\"\\nDescription:\\n\", df2.describe())","8fca24ff":"df2 = df2.groupby(['Date'])['Quantity'].sum().reset_index()\ndf2.head()","47a8dd5a":"# extracting more features from the train dataset\ndf2['Year'] = pd.to_datetime(df2['Date']).dt.year\ndf2['Week'] = pd.to_datetime(df2['Date']).dt.week\ndf2['Day'] = pd.to_datetime(df2['Date']).dt.day\ndf2['Weekday'] = pd.to_datetime(df2['Date']).dt.dayofweek\ndf2.head(8)","62050157":"sns.boxplot(x=df2['Quantity'])","0980738c":"# weekly trend\nsns.lineplot(df2['Week'], df2['Quantity'])","cd405fe6":"# removing outliers\ndf2 = df2[df2['Quantity']<3000]\nsns.boxplot(x=df2['Quantity'])","b08b2318":"#Breaking the data and selecting features , predictors\npredictors=df2.drop(['Quantity','Date'],axis=1)\ntarget=df2['Quantity']\nx_train,x_cv,y_train,y_cv=train_test_split(predictors,target,test_size=0.1,random_state=7)","60248fda":"def scores(i):\n    lin = i()\n    lin.fit(x_train, y_train)\n    y_pred=lin.predict(x_cv)\n    lin_r= r2_score(y_cv, y_pred)\n    s.append(lin_r)\n#Checking the scores by using our function\nalgos=[LinearRegression,KNeighborsRegressor,RandomForestRegressor,Lasso,ElasticNet,DecisionTreeRegressor]\ns=[]\nfor i in algos:\n    scores(i)","ac50d3a0":"models = pd.DataFrame({\n    'Models': ['Linear Regression', 'K-Neighbors Regressor', \n              'Random Forest Regressor', 'Lasso','Decision Tree Regressor'],\n    'R2-Score': [s[0],s[1],s[2],s[3],s[4]]})\nmodels.sort_values(by='R2-Score', ascending=False)","c42bead7":"#Hypertuned Model\nmodel = RandomForestRegressor(oob_score=True,\n                              n_jobs=1,\n                              random_state=7,\n                              max_features='auto',\n                              min_samples_leaf=4)\n# bootstrap=True, criterion='mse', max_depth=None,\n#                       max_features='auto', max_leaf_nodes=None,\n#                       min_impurity_decrease=0.0, min_impurity_split=None,\n#                       min_samples_leaf=4, min_samples_split=2,\n#                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=3,\n#                       oob_score=True, random_state=7, verbose=0,\n#                       warm_start=False\nmodel.fit(x_train,y_train)","251c20b2":"pred = model.predict(x_cv)\nr2_score(pred, y_cv)","9b611bba":"def mean_percentage_error(y_cv, pred): \n    y_cv, pred = np.array(y_cv), np.array(pred)\n    return np.mean(np.array((y_cv - pred) \/ y_cv)) * 100\nmean_percentage_error(y_cv, pred)","06442920":"# creating testing data for 2018 Jan month\ndate_2018 = \"2018-01-01\"\n# index = pd.date_range(date_2018, periods=30, freq='D')\n#creating Quantity column\n# columns = ['Quantity']\ntest = pd.DataFrame()\ntest['Date'] = pd.date_range(start=date_2018, periods=30, freq='D')\n# # extracting more features from the train dataset\ntest['Year'] = pd.to_datetime(test['Date']).dt.year\ntest['Week'] = pd.to_datetime(test['Date']).dt.week\ntest['Day'] = pd.to_datetime(test['Date']).dt.day\ntest['Weekday'] = pd.to_datetime(test['Date']).dt.dayofweek\n\ntest[\"Quantity\"] = \"\"\n\ntest1=test.drop(['Quantity', 'Date'],axis=1)\npred2=model.predict(test1)\ntest['Random_Forest_Quantity_pred']=pred2.round(0)\ntest.head()\n\nresult=test[['Date','Random_Forest_Quantity_pred']]\nresult.head(30)","ae2d1d99":"# Regression models implemented here are Linear Regression, Random forest, Decision tree, Lasso and K-Neighbors Regressor","e1bee157":"# Combining Marketing Spend and Online dataset","e55dc803":"# Splitting the dataset","c0a9f34b":"# Test predict quantities for Jan 2018","29630106":"* Renaming columns as the Date column in names as \"Unnamed\" in marketing_spent csv file.\n* Changing Date format in online csv file from YYYYMMDD to YYYY-MM-DD.","176f5600":"**Output:** Post running the below script, output resembles as shown in the below image.\n\n![Screenshot%20from%202020-08-06%2012-23-18.png](attachment:Screenshot%20from%202020-08-06%2012-23-18.png)\n","1eafb520":"We have 5 missing values for Quantity. Lets fill the same later.\n\nUnderstanding marketing spent dataset","c08965a1":"understanding Online dataset","d443fe1c":"As we can see Random Forest Regressor will give the best R squared score for our dataset. As we have evaluated, let's run for Random Forest Regressor and see how it performs.","538f5d27":"# Comparing Algorithms","63424c7a":"# R2 Score","f762d250":"Lets plot some weekly","609809b8":"# Checking the score","d9768e8d":"We group by \"Date\" and sum up the \"Quantities\"","15b6c2b7":"# Removing Outliers"}}