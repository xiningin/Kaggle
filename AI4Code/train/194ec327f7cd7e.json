{"cell_type":{"5a5e60e2":"code","8f38dc6a":"code","6b717e01":"code","a997a8e1":"code","02247f25":"code","b7c58d0f":"code","ea7cc387":"code","2b96f0c3":"code","c7f6fa2b":"code","48770078":"code","a8b96ac6":"code","294cdb82":"code","bebc02f0":"code","4a0c504f":"code","e875cbce":"code","ecab9138":"code","70126132":"markdown","f5a2da5c":"markdown","2644dddf":"markdown","d72c4726":"markdown","17f08109":"markdown","34f4ce34":"markdown","f141ba99":"markdown","8897fa60":"markdown","1dc619a0":"markdown","e8205e2c":"markdown","74359f47":"markdown","7b9944d9":"markdown","4ea45e06":"markdown","93a52aaa":"markdown","5f5503b2":"markdown"},"source":{"5a5e60e2":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","8f38dc6a":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [299, 299]\nEPOCHS = 50","6b717e01":"filenames = tf.io.gfile.glob(str(GCS_PATH + '\/COVID-19_Radiography_Dataset\/*\/*'))\n\ntrain_filenames, val_filenames = train_test_split(filenames, test_size=0.2)","a997a8e1":"COUNT_NORMAL = len([filename for filename in train_filenames if \"Normal\" in filename])\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n\nCOUNT_PNEUMONIA = len([filename for filename in train_filenames if \"Viral Pneumonia\" in filename])\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))\n\nCOUNT_COVID19 = len([filename for filename in train_filenames if \"\/COVID-19_Radiography_Dataset\/COVID\" in filename])\nprint(\"COVID19 images count in training set: \" + str(COUNT_COVID19))\n\nCOUNT_OPACITY = len([filename for filename in train_filenames if \"Lung_Opacity\" in filename])\nprint(\"COVID19 images count in training set: \" + str(COUNT_OPACITY))","02247f25":"train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n\nfor f in train_list_ds.take(5):\n    print(f.numpy())","b7c58d0f":"TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))","ea7cc387":"CLASS_NAMES = np.array(['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia'])\nCLASS_NAMES","2b96f0c3":"def get_label(file_path):\n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    print(type(parts))\n    if(parts[-2] == \"COVID\"):\n        return 0\n    elif(parts[-2] == 'Lung_Opacity'):\n        return 1\n    elif(parts[-2] == 'Normal'):\n        return 2\n    elif(parts[-2] == 'Viral Pneumonia'):\n        return 3\n    else:\n        return 4\n\ndef decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels=3)\n  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n  img = tf.image.convert_image_dtype(img, tf.float32)\n  # resize the image to the desired size.\n  return tf.image.resize(img, IMAGE_SIZE)\n\ndef process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label\n\ntrain_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\nval_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","c7f6fa2b":"def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n    # This is a small dataset, only load it once, and keep it in memory.\n    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n    # fit in memory.\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n    # Repeat forever\n    ds = ds.repeat()\n\n    ds = ds.batch(BATCH_SIZE)\n\n    # `prefetch` lets the dataset fetch batches in the background while the model\n    # is training.\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","48770078":"train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\n\nimage_batch, label_batch = next(iter(train_ds))","a8b96ac6":"def build_model():\n    dense169 = tf.keras.applications.DenseNet169(input_shape=(299, 299, 3), include_top= False, weights='imagenet')\n    dense169.trainable = False\n    model = tf.keras.Sequential([\n                                     dense169, \n                                     tf.keras.layers.Flatten(),\n                                     tf.keras.layers.Dense(units=256, activation='relu'),\n                                     tf.keras.layers.Dense(units=256, activation='relu'),\n                                     tf.keras.layers.Dense(units=4, activation='softmax')\n                                     ])\n    \n    return model","294cdb82":"weight_for_0 = (1 \/ COUNT_COVID19)*(TRAIN_IMG_COUNT)\/2.0 \nweight_for_1 = (1 \/ COUNT_OPACITY)*(TRAIN_IMG_COUNT)\/2.0\nweight_for_2 = (1 \/ COUNT_NORMAL)*(TRAIN_IMG_COUNT)\/2.0\nweight_for_3 = (1 \/ COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)\/2.0\n\nclassWeight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\nprint('Weight for class 2: {:.2f}'.format(weight_for_2))\nprint('Weight for class 3: {:.2f}'.format(weight_for_3))\n","bebc02f0":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [\n        'accuracy',\n        'mse'\n    ]\n    \n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=METRICS\n    )\nmodel.summary()","4a0c504f":"history = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    class_weight=classWeight\n)\n\nmodel.save('DenseNet169.h5')","e875cbce":"fig, ax = plt.subplots(1, 2, figsize=(22, 8))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","ecab9138":"loss, acc, mse = model.evaluate(val_ds, batch_size = BATCH_SIZE, steps = (VAL_IMG_COUNT \/\/ BATCH_SIZE))","70126132":"# Train the model","f5a2da5c":"Let's plot the model accuracy and loss for the training and the validating set. These plots show the accuracy and loss values of the training.","2644dddf":"# Predict and evaluate results","d72c4726":"# Visualize the dataset","17f08109":"Call the next batch iteration of the training data.","34f4ce34":"The below cell is optional. It's just assigning weights to the datasets as per the number of images in each class. You can skip this if you wish to.","f141ba99":"First, let's use buffered prefetching so we can yield data from disk without having I\/O become blocking.","8897fa60":"Currently our dataset is just a list of filenames. We want to map each filename to the corresponding (image, label) pair. The following methods will help us do that.","1dc619a0":"# Visualizing model performance","e8205e2c":"We need a Google Cloud link to our data to load the data using a TPU. While we're at it, we instantiate constant variables. It is generally better practice to use constant variables instead of hard-coding numbers.","74359f47":"# Load the data","7b9944d9":"Since there are four possible labels for the image, we will be using the sparse_categorical_crossentropy loss. When we fit the model, identify the class weights. Because we are using a TPU, training will be relatively quick.","4ea45e06":"Using Transfer learning with InceptionV3. Notice the softmax layer at the output.","93a52aaa":"Let's evaluate the model on our test data!","5f5503b2":"# Build the CNN"}}