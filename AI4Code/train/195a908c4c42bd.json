{"cell_type":{"c67c4420":"code","f3e1ae97":"code","74e51902":"code","94deb6ec":"code","cbf440b6":"code","a16a2706":"code","625f38c6":"code","d2c58503":"code","14305441":"code","97f103a5":"code","7e4bf9c6":"code","d2d31809":"code","6e74fa3f":"code","92c9d90c":"code","b7348c68":"code","059fddaa":"code","3533e4e7":"code","f911d9d8":"code","1cf9f1ca":"code","3ae4082c":"code","ecc2d2bf":"code","3947ceeb":"code","16784f71":"code","01fbd89b":"code","2cd519fd":"code","55132793":"code","a8a12eed":"code","afdc70dc":"code","b524e1bb":"code","c92ab39a":"code","4b55fc49":"code","41f1bb11":"code","4dfb58ad":"code","e2a6b4ca":"code","9177398f":"code","54e1d090":"code","abc07c00":"code","a463074c":"code","f0c28123":"code","d64b079e":"code","933b2720":"code","bdb3c9bf":"markdown","e1a3203f":"markdown","9ee2580c":"markdown","0ad2914b":"markdown","2bba3c2c":"markdown","3f3cad7b":"markdown","95db8a93":"markdown","cb7909e1":"markdown","787e9532":"markdown","c5766ad9":"markdown","f53f64c6":"markdown","7e073322":"markdown","e44a0611":"markdown","1dbd0d19":"markdown","7e0e0af0":"markdown","1d1aef61":"markdown"},"source":{"c67c4420":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn \nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","f3e1ae97":"data=pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\") # readed the ","74e51902":"data.head()   #which will take first five rows","94deb6ec":"data.info() # Info function is use to give the information about particular column","cbf440b6":"data.describe() # This function describes all the columns in mathematical way.","a16a2706":"data.isnull().sum() #It will show that our data contain any null ","625f38c6":"data[\"target\"].value_counts()","d2c58503":"X=data.drop(['target'],axis=1)","14305441":"X","97f103a5":"y=data.iloc[:,-1:]\ny","7e4bf9c6":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 5)","d2d31809":"X_train","6e74fa3f":"X_test","92c9d90c":"y_train","b7348c68":"y_test","059fddaa":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","3533e4e7":"X_train_sc","f911d9d8":"X_test_sc","1cf9f1ca":"# Support vector classifier\nfrom sklearn.svm import SVC\nsvc_classifier = SVC()\nsvc_classifier.fit(X_train, y_train)\ny_pred_scv = svc_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_scv)","3ae4082c":"# Train with Standard scaled Data\nsvc_classifier2 = SVC()\nsvc_classifier2.fit(X_train_sc, y_train)\ny_pred_svc_sc = svc_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_svc_sc)","ecc2d2bf":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr_classifier = LogisticRegression(random_state = 51, penalty = 'l2')\nlr_classifier.fit(X_train, y_train)\ny_pred_lr = lr_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_lr)","3947ceeb":"# Train with Standard scaled Data\nlr_classifier2 = LogisticRegression(random_state = 51, penalty = 'l2')\nlr_classifier2.fit(X_train_sc, y_train)\ny_pred_lr_sc = lr_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_lr_sc)","16784f71":"# K \u2013 Nearest Neighbor Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_classifier.fit(X_train, y_train)\ny_pred_knn = knn_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_knn)","01fbd89b":"# Train with Standard scaled Data\nknn_classifier2 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_classifier2.fit(X_train_sc, y_train)\ny_pred_knn_sc = knn_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_knn_sc)","2cd519fd":"# Naive Bayes Classifier\nfrom sklearn.naive_bayes import GaussianNB\nnb_classifier = GaussianNB()\nnb_classifier.fit(X_train, y_train)\ny_pred_nb = nb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_nb)","55132793":"# Train with Standard scaled Data\nnb_classifier2 = GaussianNB()\nnb_classifier2.fit(X_train_sc, y_train)\ny_pred_nb_sc = nb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_nb_sc)","a8a12eed":"# Decision Tree Classifier\nfrom sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)\ndt_classifier.fit(X_train, y_train)\ny_pred_dt = dt_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_dt)","afdc70dc":"# Train with Standard scaled Data\ndt_classifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)\ndt_classifier2.fit(X_train_sc, y_train)\ny_pred_dt_sc = dt_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_dt_sc)","b524e1bb":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)\nrf_classifier.fit(X_train, y_train)\ny_pred_rf = rf_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_rf)","c92ab39a":"# Train with Standard scaled Data\nrf_classifier2 = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)\nrf_classifier2.fit(X_train_sc, y_train)\ny_pred_rf_sc = rf_classifier.predict(X_test_sc)\naccuracy_score(y_test, y_pred_rf_sc)","4b55fc49":"# Adaboost Classifier\nfrom sklearn.ensemble import AdaBoostClassifier\nadb_classifier = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = 200),\n                                    n_estimators=2000,\n                                    learning_rate=0.1,\n                                    algorithm='SAMME.R',\n                                    random_state=1,)\nadb_classifier.fit(X_train, y_train)\ny_pred_adb = adb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_adb)","41f1bb11":"# Train with Standard scaled Data\nadb_classifier2 = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = 200),\n                                    n_estimators=2000,\n                                    learning_rate=0.1,\n                                    algorithm='SAMME.R',\n                                    random_state=1,)\nadb_classifier2.fit(X_train_sc, y_train)\ny_pred_adb_sc = adb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_adb_sc)","4dfb58ad":"# XGBoost Classifier\nfrom xgboost import XGBClassifier\nxgb_classifier = XGBClassifier()\nxgb_classifier.fit(X_train, y_train)\ny_pred_xgb = xgb_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_xgb)","e2a6b4ca":"# Train with Standard scaled Data\nxgb_classifier2 = XGBClassifier()\nxgb_classifier2.fit(X_train_sc, y_train)\ny_pred_xgb_sc = xgb_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_xgb_sc)","9177398f":"cm = confusion_matrix(y_test,y_pred_adb_sc)\nplt.title('Heatmap of Confusion Matrix', fontsize = 15)\nsns.heatmap(cm, annot = True)\nplt.show()","54e1d090":"print(classification_report(y_test, y_pred_adb_sc))","abc07c00":"import joblib as jb","a463074c":"jb.dump(adb_classifier2,'heart_')","f0c28123":"heart_model=jb.load('heart_')","d64b079e":"X_name=[[40,0,1,120,230,0,1,166,1,1.2,1,1,2]]","933b2720":"heart_model.predict(X_name)","bdb3c9bf":"# Saving Model using joblib","e1a3203f":"# Information About Data","9ee2580c":"# Data Extraction","0ad2914b":"# KNN Classifier","2bba3c2c":"# Decision Tree Classifier","3f3cad7b":"# Support Vector Classifier","95db8a93":"# Libraries Imported","cb7909e1":"# Split Train Test","787e9532":"# Logistic Regression","c5766ad9":"# Ada Boost Classifier","f53f64c6":"# XG Boost Classifier","7e073322":"# Naive Bayes Classifier","e44a0611":"# Random Forest Classifier","1dbd0d19":"# Feature Scalling","7e0e0af0":"# Classification Report of Model","1d1aef61":"# Confusion Matrix"}}