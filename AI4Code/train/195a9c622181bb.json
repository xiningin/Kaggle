{"cell_type":{"e00a3bcb":"code","0b321b7b":"code","dfd55be3":"code","278e5a41":"code","d1fa8659":"code","3a6dc104":"code","6f8b0836":"code","f5af995f":"code","3e351a40":"code","cddd1133":"code","56c9546c":"code","41a25b75":"code","3eb40159":"code","7aa157c7":"code","b6ce4ea8":"code","cff7cb5a":"code","51a355ae":"code","b83526ad":"code","503083f4":"code","67e7aa99":"code","f262ad15":"code","10cda67b":"code","5fcbee1e":"code","c3918d28":"code","9a0a9397":"code","7149d776":"code","c1415d80":"code","355520a5":"code","a0ab245a":"code","58f59ac9":"code","0645a8d1":"code","ffe0a51b":"code","8f195116":"code","e7bfce01":"code","72014127":"code","4ffc0826":"code","6a187540":"code","2de6a540":"code","ebbc6164":"code","792e369b":"code","c0ae3166":"code","e579fbdf":"code","88400b54":"code","d7abc735":"code","192bf7f7":"code","bbe3972a":"code","d71ee00d":"markdown","d34940bc":"markdown","1bf2f436":"markdown"},"source":{"e00a3bcb":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","0b321b7b":"%matplotlib inline","dfd55be3":"plt.style.use('seaborn-whitegrid')","278e5a41":"df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","d1fa8659":"pd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', len(df.columns))","3a6dc104":"df.shape","6f8b0836":"df.shape","f5af995f":"df.describe()","3e351a40":"df.info()","cddd1133":"for i in df.columns:\n    print('{}:- {}\\n{}\\n\\n'.format(i, df[i].nunique(), df[i].unique()))","56c9546c":"# Distributions of columns \nfor i in df.columns:\n    plt.hist(df[i], bins = 30, color = 'steelblue', edgecolor = 'black', rwidth = 0.8, alpha = 0.7)\n    plt.title('{} Distribution\\n'.format(i.title()), fontsize = 25)\n    plt.xlabel('\\n{}'.format(i.title()), fontsize = 20)\n    plt.ylabel('Frequency\\n', fontsize = 20)\n    plt.show()","41a25b75":"class Outliers(object):\n    def __init__(self, df, col):\n        self.df = df\n        self.col = col\n        \n        self.mean = df[col].mean()\n        self.median = df[col].median()\n        self.min = df[col].min()\n        self.max = df[col].max()\n        self.std = df[col].std()\n        self.quantile_25 = self.df[self.col].quantile(0.25)\n        self.quantile_75 = self.df[self.col].quantile(0.75)\n        \n    def info(self):\n        print('Mean:- {}'.format(self.mean))\n        print('Median:- {}'.format(self.median))\n        print('Standard Deviation:- {}'.format(self.std))\n        print('Minimum value:- {}'.format(self.min))\n        print('Maximum value:- {}'.format(self.max))\n        print('25th quantile:- {}'.format(self.quantile_25))\n        print('75th quantile:- {}'.format(self.quantile_75))\n        \n        des = '*' * 20\n        return des\n        \n        \nclass IQR(Outliers):\n    def __init__(self, df, col):\n        super().__init__(df, col)\n        \n    def iqr_calc(self):\n        \n        IQR = self.quantile_75 - self.quantile_25\n        \n        lower_bound = self.quantile_25 - (1.5 * IQR)\n        upper_bound = self.quantile_75 + (1.5 * IQR)\n        \n        return lower_bound, upper_bound\n        \n    def iqr_outliers(self):\n        \n        lower_bound, upper_bound = self.iqr_calc()\n        return self.df.loc[(self.df[self.col] < lower_bound) | (self.df[self.col] > upper_bound), self.col]\n        \n    def iqr_remove(self):\n        \n        lower_bound, upper_bound = self.iqr_calc()\n        return self.df.loc[(self.df[self.col] > lower_bound) & (self.df[self.col] < upper_bound)]\n        \n    \n\nclass Z_score(Outliers):\n    def __init__(self, df, col):\n        super().__init__(df, col)\n        \n    def z_score_outliers(self):\n        outlier = []\n        for i in self.df[self.col]:\n            z = (i - self.mean) \/ self.std\n            if abs(z) > 3:\n                outlier.append(i)\n        \n        return outlier\n    \n    def z_score_remove(self):\n        \n        df_copy = self.df.copy()\n        for i in self.z_score_outliers():\n            df_copy = df_copy.loc[df_copy[self.col] != i]\n            \n        return df_copy\n    \n\nclass StandardDeviation(Outliers):\n    def __init__(self, df, col):\n        super().__init__(df, col)\n        \n    def std_calc(self):\n        \n        lower_std = self.mean - (3 * self.std)\n        upper_std = self.mean + (3 * self.std)\n        \n        return lower_std, upper_std\n        \n    def std_outliers(self):\n        \n        lower_std, upper_std = self.std_calc()\n        return self.df.loc[(self.df[self.col] < lower_std) | (self.df[self.col] > upper_std), self.col]\n    \n    def std_remove(self):\n        \n        lower_std, upper_std = self.std_calc()\n        return self.df.loc[(self.df[self.col] > lower_std) & (self.df[self.col] < upper_std)]\n        \n        \n        ","3eb40159":"columns = ['chol', 'trtbps', 'thalachh', 'oldpeak']\n\n\nfor i in columns:\n    out = Outliers(df, i)\n    iqr = IQR(df, i)\n    z_score = Z_score(df, i)\n    std = StandardDeviation(df, i)    \n\n    print('Outliers:- {}\\n'.format(i))\n\n    print('Info:- \\n')\n    out.info()\n    print('*'*40)\n    print('\\n')\n    \n    \n    print('IQR Outliers:- \\n{}\\n'.format(iqr.iqr_outliers())) \n    print('Shape of df if removed outliers with IQR:- {}'.format(iqr.iqr_remove().shape))\n    print('*'*20)\n    \n    print('Z-score Outliers:- \\n{}\\n'.format(z_score.z_score_outliers())) \n    print('Shape of df if removed outliers with Z-score:- {}'.format(z_score.z_score_remove().shape))\n    print('*'*20)\n    \n    print('StandardDeviation Outliers:- \\n{}\\n'.format(std.std_outliers())) \n    print('Shape of df if removed outliers with StandardDeviation:- {}'.format(std.std_remove().shape))\n    \n    print('\\n', '*'*100, '\\n', '*'*100, '\\n', '*'*100, '\\n')\n    ","7aa157c7":"##### Treating Outliers of chol\nz_score_chol = Z_score(df, 'chol')\ndf = z_score_chol.z_score_remove()","b6ce4ea8":"##### Treating Outliers of trtbps\nstd_trtbps = StandardDeviation(df, 'trtbps')\ndf = std_trtbps.std_remove()","cff7cb5a":"##### Treating Outliers of thalachh\niqr_thalachh = IQR(df, 'thalachh')\ndf = iqr_thalachh.iqr_remove()","51a355ae":"##### Treating Outliers of oldpeak\nz_score_oldpeak = Z_score(df, 'oldpeak')\ndf = z_score_oldpeak.z_score_remove()","b83526ad":"df.shape","503083f4":"# Distributions of columns aftet treating outliers\nfor i in df.columns:\n    plt.hist(df[i], bins = 30, color = 'steelblue', edgecolor = 'black', rwidth = 0.8, alpha = 0.7)\n    plt.title('{} Distribution\\n'.format(i.title()), fontsize = 25)\n    plt.xlabel('\\n{}'.format(i.title()), fontsize = 20)\n    plt.ylabel('Frequency\\n', fontsize = 20)\n    plt.show()","67e7aa99":"sex_out = df.groupby(['sex', 'output'])[['output']].count()\n\n#idx = pd.IndexSlice\n#sex_out.loc[idx[0, :], :].output\n\nindx = np.arange(len(sex_out.unstack().output.index))\nwidth = 0.25\n\n\nplt.bar(indx - width\/2, sex_out.unstack().output[0].values,\n        width = width, alpha = 0.7, edgecolor = 'black', label = 'less chance of heart attack')\nplt.bar(indx + width\/2, sex_out.unstack().output[1].values,\n        width = width, alpha = 0.7, edgecolor = 'black', label = 'more chance of heart attack')\n\nplt.title('Frequency of people with chance of heart attack \\n(gender wise)\\n', fontsize = 25)\nplt.xlabel('\\nSex', fontsize = 20)\nplt.ylabel('Frequency\\n', fontsize = 20)\n\n\nplt.xticks([0,1], ['Female', 'Male'])\nplt.legend(frameon = True, facecolor = 'gray', framealpha = 0.2, shadow = False, fontsize = 12.5)\nplt.show()","f262ad15":"sex_atk = df.groupby('sex')[['output']].mean()\n\nplt.bar(sex_atk.index.map({0: 'Female', 1: 'Male'}), sex_atk.output, color = 'red', \n        alpha = 0.5, edgecolor = 'black', width = 0.5)\n\nplt.title('Chance of getting heart attack of each gender type\\n', fontsize = 25)\nplt.xlabel('\\nChance of getting heart attack (in %)', fontsize = 20)\nplt.ylabel('Genders\\n', fontsize = 20)\nplt.show()","10cda67b":"sex_hrt = df.groupby('sex')[['output']].mean()\n\nplt.pie(sex_hrt.output, labels = sex_hrt.index.map({0: 'Female', 1: 'Male'}), wedgeprops = {'edgecolor': 'black'}, \n        shadow = True, textprops = {'fontsize': 15}, autopct = '%1.2f%%')\nplt.title('Chance of getting (if compared according to genders)', fontsize = 20)\nplt.show()","5fcbee1e":"sex_info = df.groupby('sex')[['chol', 'trtbps', 'thalachh', 'oldpeak']].aggregate(np.mean)\n\nplt.figure(figsize = (9, 5))\n\nindx = np.arange(len(sex_info.columns))\nwidth = 0.2\n\nplt.bar(indx - width\/2, sex_info.loc[0, :], width = width, alpha = 0.5, color = 'pink', label = 'Female', edgecolor = 'black')\nplt.bar(indx + width\/2, sex_info.loc[1, :], width = width, alpha = 0.5, color = 'blue', label = 'Male', edgecolor = 'black')\n\nplt.title('Comparing genders on avg. values of different categories\\n', fontsize = 25)\nplt.xlabel('\\nCategories', fontsize = 20)\nplt.ylabel('Average values\\n', fontsize = 20)\n\nplt.yscale('log')\nplt.xticks([0, 1, 2, 3], ['chol', 'trtbps', 'thalachh', 'oldpeak'])\nplt.legend(loc = 'best', frameon = True, fontsize = 15)\nplt.show()","c3918d28":"age_dis = pd.qcut(df.age, 5)\nage_hrt = df.pivot_table('output', index = age_dis, columns = 'sex')\n\nplt.figure(figsize = (12,9))\n\nindx = np.arange(len(age_hrt.index))\nwidth = 0.4\n\nplt.barh(indx - width\/2, age_hrt[0], height = width, alpha = 0.7, edgecolor = 'black', label = 'Female')\nplt.barh(indx + width\/2, age_hrt[1], height = width, alpha = 0.7, edgecolor = 'black', label = 'Male')\n\nplt.title('Chances of having heart attack as pereach age group\\n', fontsize = 25)\nplt.xlabel('\\nChances of heart attack (in %)', fontsize = 20)\nplt.ylabel('Age Group\\n', fontsize = 20)\n\nplt.yticks(indx, age_hrt.index)\nplt.legend(fontsize = 15, frameon = True, loc = 'best')\nplt.show()","9a0a9397":"df.head()","7149d776":"for i in df.columns:\n    print(i, ':- ', df[i].nunique())","c1415d80":"X = df.drop('output', axis = 1).copy()\ny = df['output']","355520a5":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 0)","a0ab245a":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","58f59ac9":"from sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler","0645a8d1":"cat1 = ['sex', 'fbs','exng']\ncat2 = ['cp', 'restecg', 'caa', 'thall']\nnum = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']","ffe0a51b":"trans_col = make_column_transformer((OneHotEncoder(handle_unknown = 'ignore'), cat2), \n                                    (OrdinalEncoder(), cat1), \n                                    (StandardScaler(), num), \n                                    remainder = 'passthrough')","8f195116":"from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","e7bfce01":"pipe_lr = make_pipeline(trans_col, LogisticRegression(solver = 'liblinear'))\npipe_svm = make_pipeline(trans_col, SVC())\npipe_rf = make_pipeline(trans_col, RandomForestClassifier())","72014127":"from sklearn.model_selection import GridSearchCV","4ffc0826":"params_lr = {\n    'logisticregression__penalty': ['l1', 'l2'],\n    'logisticregression__tol': [0.01, 0.001, 0.0001, 0.00001]\n}\n\ngrid_lr = GridSearchCV(estimator = pipe_lr, param_grid = params_lr, cv = 10, verbose = 10)","6a187540":"params_svm = {\n    'svc__kernel': ['linear', 'rbf'],\n    'svc__C': [1, 10, 100, 1000, 10000]\n}\n\ngrid_svm = GridSearchCV(estimator = pipe_svm, param_grid = params_svm, cv = 10, verbose = 10)","2de6a540":"params_rf = {\n    'randomforestclassifier__criterion': ['entropy', 'gini'],\n    'randomforestclassifier__max_depth': [2, 4, 6, 8, 10],\n    'randomforestclassifier__min_samples_split': [2, 4, 6, 8, 10],\n    'randomforestclassifier__min_samples_leaf': [2, 3, 4, 5]\n}\n\ngrid_rf = GridSearchCV(estimator = pipe_rf, param_grid = params_rf, cv = 10, verbose = 10, n_jobs = -1)","ebbc6164":"grid_lr.fit(X_train, y_train)","792e369b":"grid_svm.fit(X_train, y_train)","c0ae3166":"grid_rf.fit(X_train, y_train)","e579fbdf":"print(grid_lr.best_params_)\nprint(grid_lr.score(X_train, y_train))\nprint(grid_lr.score(X_test, y_test))","88400b54":"print(grid_svm.best_params_)\nprint(grid_svm.score(X_train, y_train))\nprint(grid_svm.score(X_test, y_test))","d7abc735":"print(grid_rf.best_params_)\nprint(grid_rf.score(X_train, y_train))\nprint(grid_rf.score(X_test, y_test))","192bf7f7":"from sklearn.metrics import f1_score","bbe3972a":"print(f1_score(y_test, grid_lr.predict(X_test)))\nprint(f1_score(y_test, grid_svm.predict(X_test)))\nprint(f1_score(y_test, grid_rf.predict(X_test)))","d71ee00d":"## EDA","d34940bc":"## Creating Model","1bf2f436":"## Working on outliers"}}