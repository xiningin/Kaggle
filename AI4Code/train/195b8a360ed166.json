{"cell_type":{"d148829a":"code","b039ceab":"code","fb919d20":"code","d9a9c571":"code","5efca046":"code","992278f7":"code","17c48511":"code","f50f9acc":"code","ba71ded4":"code","2d73bcea":"code","3b7cc1dc":"code","fb4245f2":"code","7cf69099":"code","8b447171":"code","ba7f0b64":"code","94425fcf":"code","d54354e5":"code","eda419e7":"code","e06ab8be":"code","19ae5442":"code","1152205f":"code","5d13f6ad":"code","02490de4":"code","08e4e929":"code","82d5a382":"code","dbac6867":"code","ed04d7a2":"code","c9f486be":"code","460063dd":"code","03ed8b20":"code","bd8f8cd0":"code","488ce5c7":"code","4750a460":"markdown","b2f0d92f":"markdown","46d4c2bb":"markdown","ae005e0b":"markdown","409ba40b":"markdown","f2b2f2ac":"markdown","4ed26d96":"markdown"},"source":{"d148829a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b039ceab":"train_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_features.csv\")\ntest_features = pd.read_csv(\"\/kaggle\/input\/lish-moa\/test_features.csv\")\n\ntrain_drug = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_drug.csv\")\n\ntrain_targets_nonscored = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv\")\ntrain_targets_scored = pd.read_csv(\"\/kaggle\/input\/lish-moa\/train_targets_scored.csv\")\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/lish-moa\/sample_submission.csv\")","fb919d20":"train_features.shape, test_features.shape","d9a9c571":"train_features","5efca046":"test_features","992278f7":"test_features.sig_id.nunique()","17c48511":"test_features.cp_type.value_counts()","f50f9acc":"test_features.cp_time.value_counts()","ba71ded4":"test_features.cp_dose.value_counts()","2d73bcea":"test_features.columns.str[:2].value_counts()","3b7cc1dc":"train_targets_scored","fb4245f2":"sample_submission","7cf69099":"( train_features.sig_id.sort_values() == train_targets_scored.sig_id.sort_values() ).value_counts()","8b447171":"ctl_sig_ids = train_features.loc[train_features.cp_type == \"ctl_vehicle\",\"sig_id\"]\ntrain_targets_scored.set_index('sig_id').loc[ctl_sig_ids].sum().sum()","ba7f0b64":"train_dataset = train_features.sort_values('sig_id').drop(['sig_id', 'cp_type'],1)\ntest_dataset = test_features.sort_values('sig_id').drop(['sig_id', 'cp_type'],1)\n\ntrain_targets = train_targets_scored.sort_values('sig_id').drop(['sig_id'],1)\n\ntrain_dataset.cp_dose = train_dataset.cp_dose.str[1:].astype('f')\ntest_dataset.cp_dose = test_dataset.cp_dose.str[1:].astype('f')\n\n[i.shape for i in [train_dataset, train_targets]]","94425fcf":"import tensorflow as tf\nimport tensorflow.keras as keras\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt","d54354e5":"np.random.seed(1291)\nX_train, X_test, y_train, y_test = train_test_split(train_dataset.values, train_targets.values, test_size=0.2)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n[i.shape for i in [X_train, X_test, y_train, y_test, X_val, y_val]]","eda419e7":"from sklearn.preprocessing import QuantileTransformer\n\ntest_dataset_X = test_dataset.values.copy()\n\nfor coli in range(X_train.shape[1]):\n\n    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n    raw_vec = np.concatenate([X_train[:,coli:(coli+1)], np.array([[-10.0],[10.0]])])\n    transformer.fit(raw_vec)\n\n    X_train[:,coli:(coli+1)] = transformer.transform(raw_vec[:-2,:])\n    X_val[:,coli:(coli+1)] = transformer.transform(X_val[:,coli:(coli+1)])\n    X_test[:,coli:(coli+1)] = transformer.transform(X_test[:,coli:(coli+1)])\n    \n    test_dataset_X[:,coli:(coli+1)] = transformer.transform(test_dataset_X[:,coli:(coli+1)])\n    \n","e06ab8be":"def get_model():\n    tf.keras.backend.clear_session()\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input((X_train.shape[1],1)),\n        \n        tf.keras.layers.Conv1D(128, 3, 2, activation = 'linear'),\n        tf.keras.layers.MaxPool1D(2),\n        tf.keras.layers.BatchNormalization(),\n        \n#         tf.keras.layers.Conv1D(64, 3, 1, activation = 'relu'),\n#         tf.keras.layers.MaxPool1D(2),\n#         tf.keras.layers.BatchNormalization(),\n        \n        tf.keras.layers.Flatten(),\n        \n#         tf.keras.layers.Dropout(0.7),\n#         tf.keras.layers.Dense(750, activation = 'relu'),\n        \n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(450, activation = 'sigmoid'),\n\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(y_train.shape[1], activation = 'sigmoid')\n\n    ])\n    return model\n\nmodel = get_model()\n# model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['mae', tf.keras.metrics.AUC()])\nmodel.summary()\n","19ae5442":"callbacks=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=25, mode=\"min\", verbose=1, restore_best_weights=True),\n    tf.keras.callbacks.ModelCheckpoint(filepath=\"best_model.hdf5\", verbose=1, save_best_only=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                            factor=0.7,\n                                            patience=3,\n                                            verbose=1,\n                                            mode='min',\n                                            min_delta=0.0001,\n                                            cooldown=0,\n                                            min_lr=0.00001)\n] ","1152205f":"np.expand_dims(X_train,2).shape","5d13f6ad":"model = get_model()\nadam = tf.keras.optimizers.Adam(lr=0.1)\nmodel.compile(loss='binary_crossentropy', optimizer=adam,metrics=['mae', tf.keras.metrics.AUC()])\nnp.random.seed(1291)\ntf.random.set_seed(1291)\nhistory = model.fit(np.expand_dims(X_train,2), y_train, epochs=1500, batch_size=120, \n                    validation_data=(np.expand_dims(X_val,2), y_val), callbacks=callbacks)","02490de4":"model = tf.keras.models.load_model('best_model.hdf5')","08e4e929":"def plot_learning_curve(history):\n        # plt.plot(history.epoch, history.history[\"auc\"], \".:\")\n        # plt.plot(history.epoch, history.history[\"val_auc\"], \".:\")\n\n        plt.plot(history.epoch, history.history[\"loss\"], \".:\", label=\"loss\")\n        plt.plot(history.epoch, history.history[\"val_loss\"], \".:\", label=\"val_loss\")\n        plt.legend()\n        plt.yscale('log')\n\nplot_learning_curve(history)\nval_auc = history.history[\"val_auc\"][-1]","82d5a382":"model.evaluate(np.expand_dims(X_test,2), y_test)","dbac6867":"# multi label ROC, rank labels to further focus on","ed04d7a2":"test_predictions = model.predict(np.expand_dims(test_dataset_X,2))","c9f486be":"test_predictions.round(2)[:1,:]","460063dd":"test_features = test_features.sort_values('sig_id')\nctl_index = np.where(test_features.cp_type!=\"trt_cp\")[0]\n\ntest_predictions_mod = test_predictions.copy()\ntest_predictions_mod[ctl_index,:] = 0\n\ntest_predictions_mod = test_predictions_mod.round(2)\ntest_predictions_mod","03ed8b20":"test_sub = sample_submission.sort_values('sig_id')\n# test_sub = pd.DataFrame(test_predictions, columns=test_sub.columns[1:])\ntest_sub = pd.DataFrame(test_predictions_mod, columns=test_sub.columns[1:])\ntest_sub[\"sig_id\"] = sample_submission.sort_values('sig_id')['sig_id']\ntest_sub","bd8f8cd0":"test_sub.to_csv(\"submission.csv\", index=False)","488ce5c7":"!head submission.csv","4750a460":"## test_features","b2f0d92f":"# Normalization","46d4c2bb":"# Model Defination","ae005e0b":"# Data Preparation","409ba40b":"# post processing","f2b2f2ac":"## Train Test Spliting","4ed26d96":"## train_targets_scored"}}