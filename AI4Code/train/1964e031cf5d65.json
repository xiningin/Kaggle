{"cell_type":{"8692bcb5":"code","c7a6d1ee":"code","4639eeba":"code","2708c585":"code","28982882":"code","d512b41b":"code","a38090da":"code","2143f1cb":"code","0d6080a8":"code","89f7ba75":"code","412e5078":"code","f68d4407":"code","2c980a3e":"code","8d4142f1":"code","510118cc":"code","a9c4cd72":"code","084202e9":"code","23a4fc09":"code","4ef8733b":"code","7e8826e8":"markdown","a7cb964d":"markdown"},"source":{"8692bcb5":"# disabling tf info and warnings\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n\n# importing necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Visualization libraries\nimport matplotlib.pyplot as plt","c7a6d1ee":"# for reproducibility\nseed = 123\nnp.random.seed(seed)","4639eeba":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","2708c585":"# Visualizing the data\nimage = np.asarray(train_data.iloc[8, 1:]).reshape(28, 28)\nlabel = train_data.iloc[8, 0]\nplt.imshow(image)\nplt.title(label, fontsize=36, color='blue')\nplt.show()","28982882":"# converting data to numpy array and reshaping it\nx_train = train_data.iloc[:,1:].to_numpy().reshape(-1, 28, 28, 1)\ny_train = train_data.iloc[:,0].to_numpy()\n\nx_test = test_data.to_numpy().reshape(-1, 28, 28, 1)\nprint(\"Training Data: \", x_train.shape, y_train.shape)\nprint(\"Testing Data: \", x_test.shape)","d512b41b":"# one-hot-encoding labels\ny_train = to_categorical(y_train, num_classes=10)","a38090da":"# Creating generator for data\nbatch_size = 64\n\ndatagen = ImageDataGenerator(rotation_range=15, rescale=1.\/255, validation_split=0.2)\n\ntrain_generator = datagen.flow(x_train, y_train, batch_size=batch_size, subset=\"training\", shuffle=True)\nval_generator = datagen.flow(x_train, y_train, batch_size=batch_size, subset=\"validation\", shuffle=True)","2143f1cb":"# visualing images form generator\nimages, labels = next(train_generator)\n\nlabels = np.argmax(labels, axis=-1)\n\nplt.figure(figsize=(12, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(images[i])\n    plt.title(labels[i], fontsize=36, color='blue')\n    plt.axis(\"off\")\nplt.show()","0d6080a8":"# Creating Model\ninput_layer = Input((28, 28, 1))\nx = Conv2D(32, 5, activation='relu')(input_layer)\nx = MaxPooling2D(2)(x)\nx = Conv2D(64, 5, activation='relu')(x)\nx = MaxPooling2D(2)(x)\nx = Flatten()(x)\nx = Dense(1024, activation='relu')(x)\noutput = Dense(10, activation=\"softmax\")(x)\n\nmodel = Model(input_layer, output)\nmodel.summary()","89f7ba75":"# creating callbacks and compiling model\ncallbacks = [EarlyStopping(monitor=\"val_loss\", patience=2, verbose=1)]\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"acc\")","412e5078":"history = model.fit(train_generator, epochs=40, batch_size=batch_size, steps_per_epoch=train_generator.n\/\/batch_size,\n                   validation_data=val_generator, validation_steps=val_generator.n\/\/batch_size,\n                   callbacks=callbacks)","f68d4407":"# plotting loss and accuracies\n\n#loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label=\"Training Loss\")\nplt.plot(epochs, val_loss, 'ro', label=\"Validation Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.legend()\nplt.show()\n\n# Acc\nplt.figure()\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nplt.plot(epochs, acc, 'b', label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, 'ro', label=\"Validation Accuracy\")\nplt.title(\"Trianing and Validation Accuracies\")\nplt.legend()\nplt.show()","2c980a3e":"# Visualizing prediction with actual and predicted labels\nimages, labels = next(val_generator)\n\npred = model.predict(images)\npred = np.argmax(pred, axis=-1)\nlabels = np.argmax(labels, axis=-1)\n\nplt.figure(figsize=(15, 15))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(images[i])\n    plt.title(f\"Original Label: {labels[i]}\\nPrdicted label: {pred[i]}\")\n    plt.axis('off')\nplt.show()","8d4142f1":"predictions = model.predict(x_test)\npredictions = np.argmax(predictions, axis=-1)","510118cc":"df = pd.DataFrame(predictions, columns=[\"Label\"])\ndf","a9c4cd72":"submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission","084202e9":"submission['Label'] = df['Label']\nsubmission","23a4fc09":"submission['Label'].unique()","4ef8733b":"submission.to_csv(\"submission.csv\",index=False)","7e8826e8":"# Test Results","a7cb964d":"# Mnist Digit Recognizer CNN"}}