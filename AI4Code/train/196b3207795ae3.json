{"cell_type":{"01748ee0":"code","6e783a02":"code","62f84e8c":"code","4a0a33ef":"code","f3f83835":"code","c39dbd7d":"code","5e34e905":"code","77ad2295":"code","94c5547c":"code","85434971":"code","5963deb8":"code","6176d6b3":"code","e00b77a6":"code","0b72b6a6":"code","fd501bc8":"code","7bbd7a1e":"code","475748ea":"code","f6660ed9":"code","773c8d50":"code","c06b5e9c":"code","8022b093":"code","99ca9177":"code","0da8a4bf":"code","9084f717":"code","4bb4d8b9":"code","c4ef2b90":"code","acd6095f":"code","6ba64ae6":"code","ea04bd4d":"code","11e4b094":"code","22bd3363":"code","94a366ea":"code","555f2768":"code","16a73c9a":"code","9a038447":"code","f23b954a":"code","695d9aea":"code","ab80d188":"code","3ce22518":"code","87377921":"code","cc6c5d27":"code","9a03c071":"code","8fdb6df2":"code","c314760a":"code","fc0f8bcf":"markdown","0a151838":"markdown","d1ef886f":"markdown","45ec78ec":"markdown"},"source":{"01748ee0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 500)\n\n\n# Standard plotly imports\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\nimport os\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6e783a02":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","62f84e8c":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb","4a0a33ef":"print(\"XGBoost version:\", xgb.__version__)","f3f83835":"# print('# File sizes')\n# total_size = 0\n# start_path = '..\/input\/jane-street-market-prediction'  # To get size of current directory\n# for path, dirs, files in os.walk(start_path):\n#     for f in files:\n#         fp = os.path.join(path, f)\n#         total_size += os.path.getsize(fp)\n# print(\"Directory size: \" + str(round(total_size\/ 1000000, 2)) + 'MB')","c39dbd7d":"%%time\ntrain = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')\nfeatures = pd.read_csv('..\/input\/jane-street-market-prediction\/features.csv')\nexample_test = pd.read_csv('..\/input\/jane-street-market-prediction\/example_test.csv')\nsample_prediction_df = pd.read_csv('..\/input\/jane-street-market-prediction\/example_sample_submission.csv')\nprint (\"Data is loaded!\")","5e34e905":"print('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))","77ad2295":"train.head()","94c5547c":"missing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing\/total_cells) * 100)","85434971":"# I have taked this cell from https:\/\/www.kaggle.com\/jazivxt\/the-market-is-reactive\n# And https:\/\/www.kaggle.com\/drcapa\/jane-street-market-prediction-starter-xgb\n\ntrain = train[train['weight'] != 0]\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\n\n","5963deb8":"nulls = train.isnull().sum()\nnulls_list = list(nulls[(nulls >239049)].index)\nnulls_list","6176d6b3":"train[nulls_list].corr().style.background_gradient(cmap='viridis')","e00b77a6":"import gc\ngc.collect()","0b72b6a6":"train.drop(columns=nulls_list,inplace=True)","fd501bc8":"train.fillna(train.mean(axis=0),inplace=True)","7bbd7a1e":"gc.collect()","475748ea":"corr = train.iloc[: ,7:-2].corr()","f6660ed9":"corr.style.background_gradient('coolwarm')","773c8d50":"gc.collect()","c06b5e9c":"featstr = [i for i in train.columns[7:-2]]","8022b093":"for i in featstr[1:]:\n    print('{}\\n0.1%:99.9% are between: {}\\nmax: {}\\nmin: {}\\n75% are under: {}'.format(i,\n        np.percentile(train[i],(.1,99.9)), \n            train[i].max(),\n                train[i].min(),\n                    np.percentile(train[i],75)),\n                        '\\n===============================')","99ca9177":"gc.collect()","0da8a4bf":"# To avoid removing more data while looping through the data set we will \n# make a list of 99.9% mark for each and every single feature\n# We will also create a list for negative outliers values \"using .1 % mark\" to be explored later\u00b6\nn999 = [ np.percentile(train[i],99.9) for i in featstr[1:]]\nn001 = [ np.percentile(train[i],.1) for i in featstr[1:]]","9084f717":"for i, j in enumerate(featstr[1:]):\n    train = train[train[j] < n999[i]]\n    gc.collect()","4bb4d8b9":"gc.collect()","c4ef2b90":"for i,j in zip(featstr[1:][2:34],n001[2:34]):\n    train = train[train[i] > j]\n    gc.collect();","acd6095f":"tr_c = train.copy()","6ba64ae6":"gc.collect()","ea04bd4d":"import os, gc\nimport cudf\nimport numpy as np\nimport cupy as cp\nimport pandas as pd\nimport janestreet\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm","11e4b094":"gc.collect()","22bd3363":"train['action'] = (train['resp'] > 0).astype('int')","94a366ea":"gc.collect()","555f2768":"train = train.query('weight > 0').reset_index(drop = True)","16a73c9a":"gc.collect()","9a038447":"gc.collect()","f23b954a":"X_train = train.loc[:, train.columns.str.contains('feature')]\ny_train = train.loc[:, 'action']","695d9aea":"x = train['action'].value_counts().index\ny = train['action'].value_counts().values\n\ntrace2 = go.Bar(\n     x=x ,\n     y=y,\n     marker=dict(\n         color=y,\n         colorscale = 'Viridis',\n         reversescale = True\n     ),\n     name=\"Imbalance\",    \n )\nlayout = dict(\n     title=\"Data imbalance - action\",\n     #width = 900, height = 500,\n     xaxis=go.layout.XAxis(\n     automargin=True),\n     yaxis=dict(\n         showgrid=False,\n         showline=False,\n         showticklabels=True,\n #         domain=[0, 0.85],\n     ), \n)\nfig1 = go.Figure(data=[trace2], layout=layout)\niplot(fig1)","ab80d188":"features2 = [col for col in list(train.columns) if 'feature' in col]","3ce22518":"del x, y, train, tr_c","87377921":"clf = xgb.XGBClassifier(\n    n_estimators=800,\n    max_depth=11,\n    learning_rate=0.07,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)","cc6c5d27":"gc.collect()","9a03c071":"%time clf.fit(X_train, y_train)","8fdb6df2":"# for (test_df, sample_prediction_df) in iter_test:\n#     X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n#     #X_test = feature_sign(X_test\n#     X_test = X_test.fillna(-999)\n#     y_preds = clf.predict(X_test)\n#     sample_prediction_df.action = y_preds\n#     env.predict(sample_prediction_df)","c314760a":"print('Creating submissions file...', end='')\nrcount = 0\nfor (test_df, prediction_df) in env.iter_test():\n    X_test = test_df.loc[:, featstr]\n    y_preds = clf.predict(X_test)\n    prediction_df.action = y_preds\n    env.predict(prediction_df)\n    rcount += len(test_df.index)\nprint(f'Finished processing {rcount} rows.')","fc0f8bcf":"## Create Environment","0a151838":"### Missing Values Count","d1ef886f":"## Training\n##### To activate GPU usage, simply use tree_method='gpu_hist' (took me an hour to figure out, I wish XGBoost documentation was clearer about that).","45ec78ec":"# Is the data balanced or not?"}}