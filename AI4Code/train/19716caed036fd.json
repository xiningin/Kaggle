{"cell_type":{"6c9bb1db":"code","0550aba4":"code","8afaf6f0":"code","36d71a70":"code","f849f23a":"code","e7b388e7":"code","9592e100":"code","d6875f34":"code","a10c4019":"code","afbcc7cd":"code","6a86481c":"code","29a18ce9":"code","7f63a89e":"code","86801961":"code","09460b02":"code","ac197b68":"code","f0a08c6f":"code","5dbaca87":"code","156e6af0":"code","faf019b5":"code","70e113e4":"code","1383eba7":"code","383c59f0":"code","8b68df94":"code","fe9003e4":"code","25e25276":"code","1dbca1c7":"code","e5638b91":"code","105c0d10":"code","342f7de8":"code","9383310c":"code","53d95412":"code","f00e3032":"code","e9b27f82":"code","c8954bd1":"code","1716e52d":"code","55420600":"code","9af5307b":"code","e4f81853":"code","197292f3":"code","5182e857":"code","ab07cc1c":"code","155a2350":"code","27a0dac4":"code","57ad8c69":"code","8288e1db":"code","61a93f2b":"code","a8e7222e":"code","5a147615":"markdown","81b82dcc":"markdown","80f725ab":"markdown","0b2e49bd":"markdown","96e99af3":"markdown","ae112e69":"markdown","e83ee80e":"markdown","55c0aa63":"markdown","364af859":"markdown","51f5c2a4":"markdown","41ab405d":"markdown","ddefbbc9":"markdown","f466e2cd":"markdown","26e8a2d4":"markdown","dd94ef1f":"markdown","cca0f715":"markdown","44507f57":"markdown","ea6a1d9c":"markdown","9bdb3389":"markdown","2eb4a4fd":"markdown","9d2de0fb":"markdown","af138fbe":"markdown","1f0391e0":"markdown","9e7e139e":"markdown","5d9c0a48":"markdown","b449fba5":"markdown","a8f97347":"markdown","f2a6eded":"markdown","0f094b22":"markdown","b401c64a":"markdown","567c9400":"markdown","dba75c66":"markdown","400e120d":"markdown","d0fb8950":"markdown"},"source":{"6c9bb1db":"from IPython.core.display import display, HTML\n\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport gc\n\nfrom joblib import Parallel, delayed\n\nfrom sklearn import preprocessing, model_selection\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.metrics import r2_score\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport numpy.matlib","0550aba4":"train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.head()","8afaf6f0":"book = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0\/c439ef22282f412ba39e9137a3fdabac.parquet')\nbook","36d71a70":"check = book[book.time_id==5]\ncheck","f849f23a":"trade = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/trade_train.parquet\/stock_id=0\/ef805fd82ff54fadb363094e3b122ab9.parquet')\ntrade.head()","e7b388e7":"check_trade = trade[trade.time_id==5]\n#samples = [\"bid_size1\",\"bid_size2\",\"ask_size1\",\"ask_size2\"]\nsamples = [\"bid_size1\",\"ask_size1\"]\n\nplt.figure(figsize=(20,5))\n\nfor num,idx in enumerate(samples):\n    \n    plt.plot(check[\"seconds_in_bucket\"],check[idx],label=idx)\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"size\"],label=\"trade_parquet\")\nplt.legend(fontsize=12)","9592e100":"check_trade = trade[trade.time_id==5]\nsamples = [\"bid_price1\",\"bid_price2\",\"ask_price1\",\"ask_price2\"]\n\nplt.figure(figsize=(20,5))\n\nfor num,idx in enumerate(samples):\n    \n    plt.plot(check[\"seconds_in_bucket\"],check[idx],label=idx)\n\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"price\"],label=\"trade_parquet\")\nplt.legend(fontsize=12)","d6875f34":"plt.figure(figsize=(20,5))\ncheck_trade = trade[trade.time_id==5]\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"order_count\"],label=\"trade_parquet\")\nplt.legend(fontsize=12)","a10c4019":"plt.figure(figsize=(20,5))\nwap1 = (check['bid_price1'] * check['ask_size1'] + check['ask_price1'] * check['bid_size1']) \/ (check['bid_size1'] + check['ask_size1'])\nwap2 = (check['bid_price2'] * check['ask_size2'] + check['ask_price2'] * check['bid_size2']) \/ (check['bid_size2'] + check['ask_size2'])\ncheck['wap1'] = wap1\ncheck['wap2'] = wap2\nplt.plot(check[\"seconds_in_bucket\"],wap1,label=\"wap1\")\nplt.plot(check[\"seconds_in_bucket\"],wap2,label=\"wap2\")\nplt.legend(fontsize=12)","afbcc7cd":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","6a86481c":"    plt.figure(figsize=(20,5))\n    check['log_return1'] = check.groupby(['time_id'])['wap1'].apply(log_return)\n    check['log_return2'] = check.groupby(['time_id'])['wap2'].apply(log_return)\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1'],label=\"log_return1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2'],label=\"log_return2\")\n    plt.legend(fontsize=12)","29a18ce9":"    plt.figure(figsize=(20,5))\n    check['price_spread'] = ( check['ask_price1'] - check['bid_price1']) \/ (( check['ask_price1'] +  check['bid_price1']) \/ 2)\n    check['price_spread2'] = ( check['ask_price2'] -  check['bid_price2']) \/ (( check['ask_price2'] +  check['bid_price2']) \/ 2)\n    check['bid_spread'] = check['bid_price1'] - check['bid_price2']\n    check['ask_spread'] = check['ask_price1'] - check['ask_price2']\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread'],label=\"price_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread2'],label=\"price_spread2\")\n    plt.legend(fontsize=12)","7f63a89e":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['bid_spread'],label=\"bid_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['ask_spread'],label=\"ask_spread\")\n    plt.legend(fontsize=12)","86801961":"    def get_stats_window(seconds_in_bucket, add_suffix = False):\n        # Group by the window\n        df_feature = check[check['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n        # Rename columns joining suffix\n        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n        # Add a suffix to differentiate windows\n        if add_suffix:\n            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n        return df_feature\n    \n    def log_return(series):\n        return np.log(series).diff()\n\n    # Calculate the realized volatility\n    def realized_volatility(series):\n        return np.sqrt(np.sum(series**2))\n\n    def count_unique(series):\n        return len(np.unique(series))# Function to read our base train and test set","09460b02":"from scipy.stats import norm\nplt.figure(figsize=(20,5))\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"price\"].apply(lambda x: norm.pdf(x)),label=\"trade_parquet\")\nplt.legend(fontsize=12)","ac197b68":"plt.figure(figsize=(20,5))\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"price\"].apply(lambda x: norm.cdf(x)),label=\"trade_parquet\")\nplt.legend(fontsize=12)","f0a08c6f":"from scipy.stats import t\nplt.figure(figsize=(20,5))\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"price\"].apply(lambda x: t.pdf(x,df=1)),label=\"trade_parquet\")\nplt.legend(fontsize=12)","5dbaca87":"from scipy.stats import chi2\nplt.figure(figsize=(20,5))\nplt.plot(check_trade[\"seconds_in_bucket\"],check_trade[\"price\"].apply(lambda x: chi2.pdf(x,df=1)),label=\"trade_parquet\")\nplt.legend(fontsize=12)","156e6af0":"def calc_wap1(df):\n    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) \/ (df['bid_size1'] + df['ask_size1'])\n    return wap\n\n# Function to calculate second WAP\ndef calc_wap2(df):\n    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) \/ (df['bid_size2'] + df['ask_size2'])\n    return wap\n\ndef book_preprocessor(file_path):\n    df = pd.read_parquet(file_path)\n    # Calculate Wap\n    df['wap1'] = calc_wap1(df)\n    df['wap2'] = calc_wap2(df)\n    # Calculate log returns\n    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n    # Calculate wap balance\n    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n    # Calculate spread\n    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) \/ ((df['ask_price1'] + df['bid_price1']) \/ 2)\n    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) \/ ((df['ask_price2'] + df['bid_price2']) \/ 2)\n    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    #add\n    df['h_spread_l1'] = df['ask_price1'] - df['bid_price1']\n    df['h_spread_l2'] = df['ask_price2'] - df['bid_price2']\n    df['v_spread_b'] = df['bid_price1'] - df['bid_price2']\n    df['v_spread_a'] = df['ask_price1'] - df['ask_price2'] \n    \n    # Dict for aggregations\n    create_feature_dict = {\n        'wap1': [np.sum, np.mean, np.std,np.min,np.max,np.median], \n        'wap2': [np.sum, np.mean, np.std,np.min,np.max,np.median], \n        'log_return1': [np.sum, realized_volatility, np.mean, np.std,np.min,np.max],\n        'log_return2': [np.sum, realized_volatility, np.mean, np.std,np.min,np.max],\n        'wap_balance': [np.sum, np.mean, np.std,np.min,np.max],\n        'price_spread':[np.sum, np.mean, np.std,np.min,np.max],\n        'price_spread2':[np.sum, np.mean, np.std,np.min,np.max],\n        'bid_spread':[np.sum, np.mean, np.std,np.min,np.max],\n        'ask_spread':[np.sum, np.mean, np.std,np.min,np.max],\n        'total_volume':[np.sum, np.mean, np.std,np.min,np.max],\n        'volume_imbalance':[np.sum, np.mean, np.std,np.min,np.max],\n        \"bid_ask_spread\":[np.sum, np.mean, np.std,np.min,np.max],\n        'h_spread_l1':[np.sum, np.mean, np.std,np.min,np.max],\n        'h_spread_l2':[np.sum, np.mean, np.std,np.min,np.max],\n    }\n        # Function to get group stats for different windows (seconds in bucket)\n    def get_stats_window(seconds_in_bucket, add_suffix = False):\n        # Group by the window\n        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n        # Rename columns joining suffix\n        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n        # Add a suffix to differentiate windows\n        if add_suffix:\n            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n        return df_feature\n    \n    # Get the stats for different windows\n    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n    df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n    #df_feature_500 = get_stats_window(seconds_in_bucket = 500, add_suffix = True)\n    df_feature_400 = get_stats_window(seconds_in_bucket = 400, add_suffix = True)\n    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n    df_feature_200 = get_stats_window(seconds_in_bucket = 200, add_suffix = True)\n    df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n    df_feature_100 = get_stats_window(seconds_in_bucket = 100, add_suffix = True)\n\n    # Merge all\n    df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n    #df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n    df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n    # Drop unnecesary time_ids\n    \n    \n    # Create row_id so we can merge\n    stock_id = file_path.split('=')[1]\n    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n    \n    return df_feature\n\n","faf019b5":"data_dir = '..\/input\/optiver-realized-volatility-prediction\/'\nstock_id='0'\nfile_path_book = data_dir + \"book_train.parquet\/stock_id=\" + str(stock_id)\nfile_path_trade = data_dir + \"trade_train.parquet\/stock_id=\" + str(stock_id)\ncheck = book_preprocessor(file_path_book)\ncheck.head()        ","70e113e4":"    check = check[:100]\n    check[\"seconds_in_bucket\"] = range(len(check))\n    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_realized_volatility'],label=\"log_return1_realized_volatility\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_realized_volatility_450'],label=\"log_return1_realized_volatility_450\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_realized_volatility_300'],label=\"log_return1_realized_volatility_300\")\n    plt.legend(fontsize=12)\n","1383eba7":"\n    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility'],label=\"log_return2_realized_volatility\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_450'],label=\"log_return2_realized_volatility_450\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_300'],label=\"log_return2_realized_volatility_300\")\n    #plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_400'],label=\"log_return2_realized_volatility_400\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_150'],label=\"log_return2_realized_volatility_150\")\n    plt.legend(fontsize=12)","383c59f0":"\n    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility'],label=\"log_return2_realized_volatility\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_450'],label=\"log_return2_realized_volatility_400\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_300'],label=\"log_return2_realized_volatility_300\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_400'],label=\"log_return2_realized_volatility_200\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_realized_volatility_150'],label=\"log_return2_realized_volatility_100\")\n    plt.legend(fontsize=12)","8b68df94":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['wap1_sum'],label=\"wap1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['wap2_sum'],label=\"wap2\")\n    plt.legend(fontsize=12)","fe9003e4":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['wap1_std'],label=\"wap1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['wap2_std'],label=\"wap2\")\n    plt.legend(fontsize=12)","25e25276":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['wap1_mean'],label=\"wap1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['wap2_mean'],label=\"wap2\")\n    plt.legend(fontsize=12)","1dbca1c7":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['wap1_median'],label=\"wap1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['wap2_median'],label=\"wap2\")\n    plt.legend(fontsize=12)","e5638b91":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['wap1_amin'],label=\"wap1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['wap2_amin'],label=\"wap2\")\n    plt.legend(fontsize=12)","105c0d10":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['wap1_amax'],label=\"wap1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['wap2_amax'],label=\"wap2\")\n    plt.legend(fontsize=12)","342f7de8":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_mean'],label=\"log1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_mean'],label=\"log2\")\n    plt.legend(fontsize=12)","9383310c":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_std'],label=\"log1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_std'],label=\"log2\")\n    plt.legend(fontsize=12)","53d95412":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_amin'],label=\"log1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_amin'],label=\"log2\")\n    plt.legend(fontsize=12)","f00e3032":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return1_amax'],label=\"log1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['log_return2_amax'],label=\"log2\")\n    plt.legend(fontsize=12)","e9b27f82":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread_mean'],label=\"price_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread2_mean'],label=\"price_spread2\")\n    plt.legend(fontsize=12)","c8954bd1":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread_std'],label=\"price_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread2_std'],label=\"price_spread2\")\n    plt.legend(fontsize=12)","1716e52d":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread_sum'],label=\"price_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread2_sum'],label=\"price_spread2\")\n    plt.legend(fontsize=12)","55420600":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread_amin'],label=\"price_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread2_amin'],label=\"price_spread2\")\n    plt.legend(fontsize=12)","9af5307b":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread_amax'],label=\"price_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['price_spread2_amax'],label=\"price_spread2\")\n    plt.legend(fontsize=12)","e4f81853":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['bid_spread_mean'],label=\"bid_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['ask_spread_mean'],label=\"ask_spread\")\n    plt.legend(fontsize=12)","197292f3":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['bid_spread_std'],label=\"bid_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['ask_spread_std'],label=\"ask_spread\")\n    plt.legend(fontsize=12)","5182e857":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['bid_spread_sum'],label=\"bid_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['ask_spread_sum'],label=\"ask_spread\")\n    plt.legend(fontsize=12)","ab07cc1c":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['bid_spread_amin'],label=\"bid_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['ask_spread_amin'],label=\"ask_spread\")\n    plt.legend(fontsize=12)","155a2350":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['bid_spread_amax'],label=\"bid_spread\")\n    plt.plot(check[\"seconds_in_bucket\"],check['ask_spread_amax'],label=\"ask_spread\")\n    plt.legend(fontsize=12)","27a0dac4":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l1_sum'],label=\"h_spread_l1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l2_sum'],label=\"h_spread_l2\")\n    plt.legend(fontsize=12)","57ad8c69":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l1_mean'],label=\"h_spread_l1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l2_mean'],label=\"h_spread_l2\")\n    plt.legend(fontsize=12)","8288e1db":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l1_std'],label=\"h_spread_l1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l2_std'],label=\"h_spread_l2\")\n    plt.legend(fontsize=12)","61a93f2b":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l1_amin'],label=\"h_spread_l1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l2_amin'],label=\"h_spread_l2\")\n    plt.legend(fontsize=12)","a8e7222e":"    plt.figure(figsize=(20,5))\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l1_amax'],label=\"h_spread_l1\")\n    plt.plot(check[\"seconds_in_bucket\"],check['h_spread_l2_amax'],label=\"h_spread_l2\")\n    plt.legend(fontsize=12)","5a147615":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Cumculative Disribution Function<\/span>","81b82dcc":"You can see how many times the standard deviation moves.","80f725ab":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">ask_spred\/bid_spred<\/span>","0b2e49bd":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Price Analyze<\/span>","96e99af3":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Book data Analyze<\/span>","ae112e69":"## June 28, 2021 - Start Date<br>\n## September 27, 2021 - Final submission deadline.","e83ee80e":"### Point graph","55c0aa63":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">T distribution<\/span>","364af859":"### bid_spread_min is meaningless?","51f5c2a4":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">wap sum<\/span>","41ab405d":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">wap mean<\/span>","ddefbbc9":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">wap1\/wap2<\/span>","f466e2cd":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">h_spred<\/span>","26e8a2d4":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">log_return<\/span>","dd94ef1f":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">price speed<\/span>","cca0f715":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Book data read<\/span>","44507f57":"### ask_spread_max is meaningless?","ea6a1d9c":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">wap median<\/span>","9bdb3389":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Price spred<\/span>","2eb4a4fd":"![image.png](attachment:af5821e7-5803-42b8-90d0-bfb9fc6739b2.png)","9d2de0fb":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Probability Density Fuction<\/span>","af138fbe":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">X**2 Distribution<\/span>","1f0391e0":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">wap min\/max<\/span>","9e7e139e":"### I think almost same as mean","5d9c0a48":"\ud83d\ude05\u3299\ud83d\udd30\ud83d\uddd1\u2b1b\ud83d\udfe5\ud83d\udfe8\ud83d\udfe9","b449fba5":"thanks https:\/\/www.kaggle.com\/mayunnan\/realized-volatility-prediction-code-template","a8f97347":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">log_return<\/span>","f2a6eded":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Order Analyze<\/span>","0f094b22":"### wap1\/wap2 are same","b401c64a":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Book size Analyze<\/span>","567c9400":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">log_return_realized_volatility<\/span>","dba75c66":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Bid\/Ask spread<\/span>","400e120d":"<span style=\"color: orange; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Train data read<\/span>","d0fb8950":"<pre>\nstock_id - ID code for the stock. Not all stock IDs exist in every time bucket. Parquet coerces this column to the categorical data type when loaded; you may wish to convert it to int8.\ntime_id - ID code for the time bucket. Time IDs are not necessarily sequential but are consistent across all stocks.\nseconds_in_bucket - Number of seconds from the start of the bucket, always starting from 0.\nbid_price[1\/2] - Normalized prices of the most\/second most competitive buy level.\nask_price[1\/2] - Normalized prices of the most\/second most competitive sell level.\nbid_size[1\/2] - The number of shares on the most\/second most competitive buy level.\nask_size[1\/2] - The number of shares on the most\/second most competitive sell level."}}