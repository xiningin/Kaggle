{"cell_type":{"92619449":"code","406af8f3":"code","ebb4b8af":"code","312cb64f":"code","79378650":"code","945a9864":"code","babe2527":"code","257b6a4e":"code","70e8eb56":"code","34fe5e53":"code","32192280":"code","970cb2b7":"code","bcc2e1c7":"code","9fa0b351":"code","3b2eab4a":"code","2a26fa04":"code","c758ba14":"code","59aa5345":"code","759760f6":"code","4a5fec05":"code","41c798a8":"code","28543c83":"code","7fcf4527":"code","bc513efe":"markdown","661daa70":"markdown","3080b48e":"markdown","30d9b37c":"markdown","2b1c137d":"markdown","10991851":"markdown","887590cf":"markdown","592b0b6d":"markdown","c924d629":"markdown","e6c53831":"markdown","f96ca597":"markdown","90b15aac":"markdown"},"source":{"92619449":"# modify Cooking.py --> substitute raise StopIteration to return\n# modify Generator.py --> embed brighten, add brightness_range to match keras.preprocessing.image.ImageDataGenerator\n#                         change image.flip_axis() to image.image.flip_axis()\n!git clone https:\/\/github.com\/rkuo2000\/AutonomousDrivingCookbook\n%cd AutonomousDrivingCookbook\/AirSimE2EDeepLearning","406af8f3":"import numpy as np\nimport pandas as pd \nimport h5py\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\nimport os","ebb4b8af":"RAW_DATA_DIR = '\/kaggle\/input\/airsim-e2e-rawdata\/data_raw\/'\nCOOKED_DATA_DIR = 'data_cooked\/'\nMODEL_OUTPUT_DIR = 'model'\nDATA_FOLDERS = ['normal_1', 'normal_2', 'normal_3', 'normal_4', 'normal_5', 'normal_6', 'swerve_1', 'swerve_2', 'swerve_3']\nFIGURE_SIZE = (10,10)","312cb64f":"sample_tsv_path = os.path.join(RAW_DATA_DIR, 'normal_1\/airsim_rec.tsv')\nsample_tsv = pd.read_csv(sample_tsv_path, sep='\\t')\nsample_tsv.head()","79378650":"sample_image_path = os.path.join(RAW_DATA_DIR, 'swerve_1\/images\/img_0.png')\nsample_image = Image.open(sample_image_path)\nplt.title('Sample Image')\nplt.axis('off')\nplt.imshow(sample_image)\nplt.show()","945a9864":"sample_image_roi = sample_image.copy()\n\nfillcolor=(255,0,0)\ndraw = ImageDraw.Draw(sample_image_roi)\npoints = [(1,76), (1,135), (255,135), (255,76)]\nfor i in range(0, len(points), 1):\n    draw.line([points[i], points[(i+1)%len(points)]], fill=fillcolor, width=3)\ndel draw\n\nplt.title('Image with sample ROI')\nplt.axis('off')\nplt.imshow(sample_image_roi)\nplt.show()","babe2527":"full_path_raw_folders = [os.path.join(RAW_DATA_DIR, f) for f in DATA_FOLDERS]\n\ndataframes = []\nfor folder in full_path_raw_folders:\n    current_dataframe = pd.read_csv(os.path.join(folder, 'airsim_rec.txt'), sep='\\t')\n    current_dataframe['Folder'] = folder\n    dataframes.append(current_dataframe)\n    \ndataset = pd.concat(dataframes, axis=0)\n\nprint('Number of data points: {0}'.format(dataset.shape[0]))\n\ndataset.head()","257b6a4e":"min_index = 100\nmax_index = 1100\nsteering_angles_normal_1 = dataset[dataset['Folder'].apply(lambda v: 'normal_1' in v)]['Steering'][min_index:max_index]\nsteering_angles_swerve_1 = dataset[dataset['Folder'].apply(lambda v: 'swerve_1' in v)]['Steering'][min_index:max_index]\n\nplot_index = [i for i in range(min_index, max_index, 1)]\n\nfig = plt.figure(figsize=FIGURE_SIZE)\nax1 = fig.add_subplot(111)\n\nax1.scatter(plot_index, steering_angles_normal_1, c='b', marker='o', label='normal_1')\nax1.scatter(plot_index, steering_angles_swerve_1, c='r', marker='o', label='swerve_1')\nplt.legend(loc='upper left');\nplt.title('Steering Angles for normal_1 and swerve_1 runs')\nplt.xlabel('Time')\nplt.ylabel('Steering Angle')\nplt.show()","70e8eb56":"dataset['Is Swerve'] = dataset.apply(lambda r: 'swerve' in r['Folder'], axis=1)\ngrouped = dataset.groupby(by=['Is Swerve']).size().reset_index()\ngrouped.columns = ['Is Swerve', 'Count']\n\ndef make_autopct(values):\n    def my_autopct(percent):\n        total = sum(values)\n        val = int(round(percent*total\/100.0))\n        return '{0:.2f}%  ({1:d})'.format(percent,val)\n    return my_autopct\n\npie_labels = ['Normal', 'Swerve']\nfig, ax = plt.subplots(figsize=FIGURE_SIZE)\nax.pie(grouped['Count'], labels=pie_labels, autopct = make_autopct(grouped['Count']))\nplt.title('Number of data points per driving strategy')\nplt.show()","34fe5e53":"bins = np.arange(-1, 1.05, 0.05)\nnormal_labels = dataset[dataset['Is Swerve'] == False]['Steering']\nswerve_labels = dataset[dataset['Is Swerve'] == True]['Steering']","32192280":"def steering_histogram(hist_labels, title, color):\n    plt.figure(figsize=FIGURE_SIZE)\n    n, b, p = plt.hist(hist_labels.to_numpy(), bins, density=1, stacked=True, facecolor=color)\n    plt.xlabel('Steering Angle')\n    plt.ylabel('Normalized Frequency')\n    plt.title(title)\n    plt.show()\n\nsteering_histogram(normal_labels, 'Normal label distribution', 'g')\nsteering_histogram(swerve_labels, 'Swerve label distribution', 'r')","970cb2b7":"from Generator import DriveDataGenerator\nfrom Cooking import checkAndCreateDir","bcc2e1c7":"import Cooking\ntrain_eval_test_split = [0.7, 0.2, 0.1]\nfull_path_raw_folders = [os.path.join(RAW_DATA_DIR, f) for f in DATA_FOLDERS]\nCooking.cook(full_path_raw_folders, COOKED_DATA_DIR, train_eval_test_split)","9fa0b351":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers, callbacks\nimport tensorflow_addons as tfa \nimport tqdm\n\nimport json\nimport os\nimport numpy as np\nimport pandas as pd\nfrom Generator import DriveDataGenerator\nfrom Cooking import checkAndCreateDir\nimport h5py\nfrom PIL import Image, ImageDraw\nimport math\nimport matplotlib.pyplot as plt\n\nCOOKED_DATA_DIR  = 'data_cooked' # cooked data path from previous cooking step\nMODEL_OUTPUT_DIR = 'model'       # model output path","3b2eab4a":"train_dataset= h5py.File(os.path.join(COOKED_DATA_DIR, 'train.h5'), 'r')\neval_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'eval.h5'), 'r')\ntest_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'test.h5'), 'r')\n\nnum_train_examples = train_dataset['image'].shape[0]\nnum_eval_examples = eval_dataset['image'].shape[0]\nnum_test_examples = test_dataset['image'].shape[0]\n\nbatch_size=32","2a26fa04":"data_generator = DriveDataGenerator(rescale=1.\/255., horizontal_flip=True)\ntrain_generator= data_generator.flow(train_dataset['image'], train_dataset['previous_state'], train_dataset['label'], batch_size=batch_size, zero_drop_percentage=0.5, roi=[76,135,0,255])\neval_generator = data_generator.flow(eval_dataset['image'], eval_dataset['previous_state'], eval_dataset['label'], batch_size=batch_size, zero_drop_percentage=0.5, roi=[76,135,0,255])","c758ba14":"from keras.preprocessing import image \nimport keras.backend as K\ndef draw_image_with_label(img, label, prediction=None):\n    theta = label * 0.69 #Steering range for the car is +- 40 degrees -> 0.69 radians\n    line_length = 50\n    line_thickness = 3\n    label_line_color = (255, 0, 0)\n    prediction_line_color = (0, 0, 255)\n    print(img.shape)\n    pil_image = image.array_to_img(img, K.image_data_format(), scale=True)\n    print('Actual Steering Angle = {0}'.format(label))\n    draw_image = pil_image.copy()\n    image_draw = ImageDraw.Draw(draw_image)\n    first_point = (int(img.shape[1]\/2),img.shape[0])\n    second_point = (int((img.shape[1]\/2) + (line_length * math.sin(theta))), int(img.shape[0] - (line_length * math.cos(theta))))\n    image_draw.line([first_point, second_point], fill=label_line_color, width=line_thickness)\n    \n    if (prediction is not None):\n        print('Predicted Steering Angle = {0}'.format(prediction))\n        print('L1 Error: {0}'.format(abs(prediction-label)))\n        theta = prediction * 0.69\n        second_point = (int((img.shape[1]\/2) + (line_length * math.sin(theta))), int(img.shape[0] - (line_length * math.cos(theta))))\n        image_draw.line([first_point, second_point], fill=prediction_line_color, width=line_thickness)\n    \n    del image_draw\n    plt.axis('off')\n    plt.imshow(draw_image)\n    plt.show()\n\n[sample_batch_train_data, sample_batch_test_data] = next(train_generator)\nfor i in range(0, 3, 1):\n    draw_image_with_label(sample_batch_train_data[0][i], sample_batch_test_data[i])","59aa5345":"image_input_shape = sample_batch_train_data[0].shape[1:]\nstate_input_shape = sample_batch_train_data[1].shape[1:]\n\n#Create the convolutional stacks\npic_input = layers.Input(shape=image_input_shape)\n\nx = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(pic_input)\nx = layers.MaxPooling2D(pool_size=(2,2))(x)\nx = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D(pool_size=(2, 2))(x)\nx = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = layers.MaxPooling2D(pool_size=(2, 2))(x)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.2)(x)\n\n#Inject the state input\nstate_input = layers.Input(shape=state_input_shape)\nm = layers.concatenate([x, state_input])\n\n# Add a few dense layers to finish the model\nm = layers.Dense(64, activation='relu')(m)\nm = layers.Dropout(0.2)(m)\nm = layers.Dense(10, activation='relu')(m)\nm = layers.Dropout(0.2)(m)\nm = layers.Dense(1)(m)\n\nmodel = models.Model(inputs=[pic_input, state_input], outputs=m)\n\nmodel.summary()","759760f6":"#adam = Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nmodel.compile(optimizer='Adam', loss='mse')","4a5fec05":"plateau_callback = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.0001, verbose=1)\ncheckpoint_filepath = os.path.join(MODEL_OUTPUT_DIR, 'models', '{0}_model.{1}-{2}.h5'.format('model', '{epoch:02d}', '{val_loss:.7f}'))\ncheckAndCreateDir(checkpoint_filepath)\ncheckpoint_callback = callbacks.ModelCheckpoint(checkpoint_filepath, save_best_only=True, verbose=1)\ncsv_callback = callbacks.CSVLogger(os.path.join(MODEL_OUTPUT_DIR, 'training_log.csv'))\nearly_stopping_callback = callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\ncallbacks=[plateau_callback, csv_callback, checkpoint_callback, early_stopping_callback, tfa.callbacks.TQDMProgressBar()]","41c798a8":"history = model.fit(train_generator, steps_per_epoch=num_train_examples\/\/batch_size, epochs=500, callbacks=callbacks,\\\n                   validation_data=eval_generator, validation_steps=num_eval_examples\/\/batch_size, verbose=2)","28543c83":"models.save_model(model, \"airsim_e2e.h5\")","7fcf4527":"[sample_batch_train_data, sample_batch_test_data] = next(train_generator)\npredictions = model.predict([sample_batch_train_data[0], sample_batch_train_data[1]])\nfor i in range(0, 3, 1):\n    draw_image_with_label(sample_batch_train_data[0][i], sample_batch_test_data[i], predictions[i])","bc513efe":"## [Raw Data](https:\/\/aka.ms\/AirSimTutorialDataset) \n* https:\/\/www.kaggle.com\/rkuo2000\/airsim-e2e-rawdata<br \/>\nrecorded from AirSim-LandscapeMountains Car","661daa70":"# AirSim End-to-End Learning for Autonomous Driving","3080b48e":"## Model Training","30d9b37c":"## distribution of labels look likes for the two strategies","2b1c137d":"### Train Model","10991851":"### Number of data points per driving strategy","887590cf":"### Save Model","592b0b6d":"### Repro [Github](https:\/\/github.com\/Microsoft\/AutonomousDrivingCookbook)","c924d629":"### Steering Angles from normal_1 and swerve_1 runs","e6c53831":"## Data Exploration and Preparation","f96ca597":"### Extracting ROI will both reduce the training time and the amount of data needed to train the model. ","90b15aac":"## Test Model"}}