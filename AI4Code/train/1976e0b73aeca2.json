{"cell_type":{"d798784e":"code","3d4d2b33":"code","2161f22e":"code","0e5d9223":"code","43d38718":"code","a322df7a":"code","964bd3b6":"code","74681a7b":"code","2d297479":"code","9d41d04b":"code","cb1d38e3":"code","f828e9f8":"code","2b1cf9dc":"code","75e76fee":"code","837fb9ae":"code","a7f92423":"code","4e613e1c":"code","b668e9a6":"code","c7190548":"code","b93a6ddc":"code","b488b41e":"code","75f34666":"code","169efc6a":"code","b1c70dae":"code","a7652692":"code","64715049":"code","2b5dfe3f":"code","7d6f19b1":"code","d079a9cb":"code","e0e0bb49":"code","479e8b42":"code","52e300da":"code","30579542":"code","73f0ab98":"code","d0cbb53b":"code","32cfaa23":"code","da11ee9b":"code","0414ed10":"code","1c8cf1fd":"code","ebfd6577":"code","49bed202":"code","f5d708d1":"code","e4ec05b4":"code","36a851b8":"code","51948318":"code","756dc50d":"code","6ce23a79":"code","5de1950a":"code","5a33e89a":"code","c8f55f32":"code","b31d7d1f":"markdown","ed31fe54":"markdown","47015276":"markdown","941d8315":"markdown","972761a4":"markdown","2237e6a2":"markdown","2a36a3cc":"markdown"},"source":{"d798784e":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tqdm import tqdm\nimport pandas as pd\nfrom sklearn import decomposition\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nimport sys\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nfrom collections import Counter\nprint(f'tensor version:{tf.__version__}')\nprint(f'sys python\/os version:{sys.version}')\n\nimport albumentations\nfrom PIL import Image, ImageOps, ImageEnhance\nfrom albumentations.core.transforms_interface import ImageOnlyTransform\nfrom albumentations.augmentations import functional as F\nfrom albumentations import (\n    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose,DualTransform, IAAAffine,IAAPerspective\n)\nfrom albumentations.augmentations import functional as Func\nfrom tensorflow_addons.optimizers import SWA,CyclicalLearningRate, AdamW\nfrom tensorflow.keras.optimizers import Adam,SGD","3d4d2b33":"class_names = ['mountain', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)","2161f22e":"data_root = '\/kaggle\/input\/sceneimage\/scene-image\/'\ndef load_data(path):\n    datasets = ['.\/seg_train\/seg_train','.\/seg_valid\/seg_valid' ]\n    output = []\n    \n    # Iterate through training and test sets\n    for data in datasets:\n        dataset = data_root + data\n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","0e5d9223":"test_root= data_root +'seg_test\/seg_test\/'\ntest_path = os.listdir(test_root)\ntest_images_ = []\nfor img_path in test_path:\n    image = cv2.imread(test_root+img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, IMAGE_SIZE) \n    test_images_.append(image)\ntest_images = np.array(test_images_, dtype = 'float32')\ntest_images \/= 255.0","43d38718":"(train_images, train_labels), (valid_images, valid_labels) = load_data(data_root)","a322df7a":"train_images, train_labels = shuffle(train_images, train_labels, random_state=25)","964bd3b6":"n_train = train_labels.shape[0]\nn_valid = valid_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of validation examples: {}\".format(n_valid))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","74681a7b":"_, train_counts = np.unique(train_labels, return_counts=True)\n_, valid_counts = np.unique(valid_labels, return_counts=True)\npd.DataFrame({'train': train_counts,\n                    'valid': valid_counts}, \n             index=class_names\n            ).plot.bar()\nplt.show()","2d297479":"plt.pie(train_counts,\n        explode=(0, 0, 0, 0, 0) , \n        labels=class_names,\n        autopct='%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","9d41d04b":"# Good practice: scale the data\ntrain_images = train_images \/ 255.0 \nvalid_images = valid_images \/ 255.0","cb1d38e3":"# Visualize the data\ndef display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","f828e9f8":"display_random_image(class_names, train_images, train_labels)","2b1cf9dc":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","75e76fee":"display_examples(class_names, train_images, train_labels)","837fb9ae":"# model goes here\n!pip install efficientnet\nimport efficientnet.tfkeras as efn\nfrom tensorflow_addons.layers import GroupNormalization\nrecipes = []\n\n# recipes.append({'backbone':efn.EfficientNetB4,\"batch_size\":36\n#         ,'name':'Efb4','val_sel':0,'input_shape':(150,150,3), 'group':True})\n# recipes.append({'backbone':efn.EfficientNetB5, \"batch_size\":22\n#         ,'name':'Efb5','val_sel':1,'input_shape':(150,150,3), 'group':True})\n# recipes.append({'backbone':efn.EfficientNetB6, \"batch_size\":18\n#         ,'name':'Efb6','val_sel':2,'input_shape':(150,150,3), 'group':True})\n# recipes.append({'backbone':efn.EfficientNetB7, \"batch_size\":14\n#         ,'name':'Efb7','val_sel':3,'input_shape':(150,150,3), 'group':True})\n\nrecipes.append({'backbone':efn.EfficientNetB0,\"batch_size\":52\n        ,'name':'Efb0','val_sel':4,'input_shape':(150,150,3), 'group':False})\nrecipes.append({'backbone':efn.EfficientNetB1, \"batch_size\":48\n        ,'name':'Efb1','val_sel':5,'input_shape':(150,150,3), 'group':False})\n# recipes.append({'backbone':efn.EfficientNetB2, \"batch_size\":44\n#         ,'name':'Efb2','val_sel':6,'input_shape':(150,150,3), 'group':False})\n# recipes.append({'backbone':efn.EfficientNetB3, \"batch_size\":40\n#         ,'name':'Efb3','val_sel':7,'input_shape':(150,150,3), 'group':False})\n\n\ndef build_model(backbone= efn.EfficientNetB4 ,input_shape = (128,128,3)\n                ,use_imagenet = 'imagenet', group=True):\n    base_model = backbone(input_shape=input_shape,weights=use_imagenet,include_top= False)\n    if group==True:\n        print('replace bn to gn')\n        for i, layer in enumerate(base_model.layers):\n            if \"_bn\" in layer.name:\n                base_model.layers[i]=GroupNormalization(groups=16)\n                \n    x = base_model.output\n    x = tf.keras.layers.GlobalAvgPool2D(name='gap')(x)\n    predictions = tf.keras.layers.Dense(len(class_names),activation='softmax'\n                    ,name='prediction')(x)\n    model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n    return model","a7f92423":"strategy = tf.distribute.MirroredStrategy(  \n                tf.config.experimental.list_logical_devices('GPU')) \ngpus= strategy.num_replicas_in_sync  # \uac00\uc6a9 gpu \uc218 \nprint('use gpus:',gpus)","4e613e1c":"class GridMask(DualTransform):\n    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n        super(GridMask, self).__init__(always_apply, p)\n        if isinstance(num_grid, int):\n            num_grid = (num_grid, num_grid)\n        if isinstance(rotate, int):\n            rotate = (-rotate, rotate)\n        self.num_grid = num_grid\n        self.fill_value = fill_value\n        self.rotate = rotate\n        self.mode = mode\n        self.masks = None\n        self.rand_h_max = []\n        self.rand_w_max = []\n\n    def init_masks(self, height, width):\n        if self.masks is None:\n            self.masks = []\n            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n                grid_h = height \/ n_g\n                grid_w = width \/ n_g\n                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n                for i in range(n_g + 1):\n                    for j in range(n_g + 1):\n                        this_mask[\n                             int(i * grid_h) : int(i * grid_h + grid_h \/ 2),\n                             int(j * grid_w) : int(j * grid_w + grid_w \/ 2)\n                        ] = self.fill_value\n                        if self.mode == 2:\n                            this_mask[\n                                 int(i * grid_h + grid_h \/ 2) : int(i * grid_h + grid_h),\n                                 int(j * grid_w + grid_w \/ 2) : int(j * grid_w + grid_w)\n                            ] = self.fill_value\n                \n                if self.mode == 1:\n                    this_mask = 1 - this_mask\n\n                self.masks.append(this_mask)\n                self.rand_h_max.append(grid_h)\n                self.rand_w_max.append(grid_w)\n\n    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n        h, w = image.shape[:2]\n        mask = Func.rotate(mask, angle) if self.rotate[1] > 0 else mask\n        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n        return image\n\n    def get_params_dependent_on_targets(self, params):\n        img = params['image']\n        height, width = img.shape[:2]\n        self.init_masks(height, width)\n\n        mid = np.random.randint(len(self.masks))\n        mask = self.masks[mid]\n        rand_h = np.random.randint(self.rand_h_max[mid])\n        rand_w = np.random.randint(self.rand_w_max[mid])\n        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n\n        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n\n    @property\n    def targets_as_params(self):\n        return ['image']\n\n    def get_transform_init_args_names(self):\n        return ('num_grid', 'fill_value', 'rotate', 'mode')","b668e9a6":"def strong_aug(p=0.5):\n    return Compose([\n        RandomRotate90(),\n        Flip(),\n        Transpose(),\n        OneOf([\n            MotionBlur(p=0.2),\n            MedianBlur(blur_limit=3, p=0.1),\n            Blur(blur_limit=3, p=0.1),\n        ], p=0.2),\n        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n        OneOf([\n            OpticalDistortion(p=0.3),\n            GridDistortion(p=0.1),\n            IAAPiecewiseAffine(p=0.3),\n        ], p=0.2),\n        OneOf([\n            RandomBrightnessContrast(),\n        ], p=0.3),\n        \n        OneOf([   \n            GridMask(num_grid=(4,4), rotate=(-15,15), mode=0),\n            GridMask(num_grid=(10,10), rotate=(-15,15), mode=0),\n            GridMask(num_grid=(30,30), rotate=(-15,15), mode=0),\n            ],p = 0.1)\n    ], p=p)\naugmentation = strong_aug(p=0.8)\n\nclass ScenGenerator(tf.keras.utils.Sequence):\n    def __init__(self,imgs,labels,input_shape,batchsize,state='Train'):\n        self.imgs = imgs\n        print('Data Check', Counter(labels))\n        self.labels = labels\n        self.batchsize = batchsize\n        self.input_shape = input_shape\n        self.label_num = 5\n        self.state = state\n        self.on_epoch_end()\n        self.len = -(-imgs.shape[0]\/\/self.batchsize) \n\n    def __len__(self):\n        return self.len\n\n    def __getitem__(self, index):\n        # batch size \ub9cc\ud07c index\ub97c \ubf51\uc74c\n        batch_idx = self.idx[index*self.batchsize:(index+1)*self.batchsize] \n        h,w,ch = self.input_shape\n        X = np.zeros((len(batch_idx), h,w,ch)) #batch\n        y = np.zeros((len(batch_idx), self.label_num))\n        \n        for i in range(self.batchsize):\n            if self.state == 'Train':\n                data = {\"image\":self.imgs[batch_idx[i]]}\n                augmented = augmentation(**data)\n                X[i, :, :, ] = augmented[\"image\"]\n            else:\n                X[i, :, :, ] = self.imgs[batch_idx[i]]\n            y[i, :] = tf.keras.utils.to_categorical(self.labels[batch_idx[i]],num_classes=self.label_num)\n        return X, y\n            \n    def smooth_labels(self,labels, factor=0.1): # mix up augmentation \uc0ac\uc6a9\uc2dc \uc0ac\uc6a9\n        labels *= (1 - factor)\n        print(len(labels))\n        labels += (factor \/ labels.shape[0])\n        return labels\n    \n    def on_epoch_end(self):\n        self.idx = np.arange(self.imgs.shape[0]) #init\n        if self.state == 'Train':\n            cnt = Counter(self.labels)\n            max_cnt = max(cnt.values())\n            over_idxs=[]\n            over_idxs.append(self.idx)\n            for k,v in cnt.items():\n                dif = max_cnt - v\n                if dif>0:\n                    over_idx = np.random.choice(np.array(np.where(self.labels==k)).squeeze(),dif)\n                    over_idxs.append(over_idx)\n            self.idx = np.concatenate(over_idxs)\n            np.random.shuffle(self.idx) \n            sla = pd.Series(self.labels)\n            print('Balanced Sampling Train Set',Counter(sla.loc[self.idx]))\n        else:\n            self.idx = np.tile(self.idx,2)\n\n            \n    \nclass CutMixGenerator(tf.keras.utils.Sequence):\n    def __init__(self, generator1, generator2, cut_p = 0.2, maxcut= 0.5, mixup_p = 0.2, maxmix = 0.5):\n        self.generator1 = generator1\n        self.generator2 = generator2\n        self.cut_p = cut_p\n        self.mixup_p = mixup_p\n        self.batch_size = self.generator1.batchsize\n        self.maxcut = maxcut\n        self.maxmix = maxmix\n        self.on_epoch_end()  \n        \n    def __len__(self):\n        return self.generator1.__len__()\n        \n    def get_rand_bbox(self,width, height, l):\n        wcut = np.random.random()*l\n        hcut = np.random.random()*l\n        r_w = np.int(width * wcut)\n        r_h = np.int(height * hcut)\n        x = np.random.randint(width - r_w)\n        y = np.random.randint(height - r_h)\n        return x, y, r_w, r_h\n    \n    def smooth_labels(self,labels, factor=0.1):\n        labels *= (1 - factor)\n        labels += (factor \/ labels.shape[0])\n        return labels\n\n    def cutmix(self,X1, X2, y1, y2):\n        width = X1.shape[1]\n        height = X1.shape[0]\n        x, y, r_w, r_h = self.get_rand_bbox(width, height, self.maxcut)\n        X1[ y:y+r_h, x:x+r_w, :] = X2[ y:y+r_h, x:x+r_w, :]\n        ra = (r_w*r_h) \/ (width*height)\n        ysm1 = self.smooth_labels(y1)\n        ysm2 = self.smooth_labels(y2)\n        return X1, (ysm1*(1.0-ra)) + (ysm2*ra)\n    \n    def mixup(self, X1, X2, y1, y2):\n        X = np.zeros(X1.shape)\n        ra = np.random.random()*self.maxmix\n        X = X1*(1-ra) + X2*ra\n        ysm1 = self.smooth_labels(y1)\n        ysm2 = self.smooth_labels(y2)\n        return X,(ysm1*(1.0-ra)) + (ysm2*ra)\n    \n    def __getitem__(self, index):\n        Data, Target = self.generator1.__getitem__(index)\n        cutmix_idx = np.random.choice(np.arange(self.batch_size),int(self.batch_size*self.cut_p), replace=False)\n        \n        for idx in cutmix_idx:\n            srcidx = np.random.randint(self.generator2.__len__())\n            orgD, orgT= Data[idx,:], Target[idx,:]\n            srcD, srcT = self.generator2.__getitem__(srcidx)\n            \n            mD, mT = self.cutmix(orgD,srcD[0], orgT, srcT[0])\n            Data[idx,:], Target[idx,:]= mD, mT\n        mixup_idx = np.random.choice(np.arange(self.batch_size),int(self.batch_size*self.mixup_p), replace=False)\n        \n        for idx in mixup_idx:\n            if idx in cutmix_idx:\n                continue\n            srcidx = np.random.randint(self.generator2.__len__())\n            orgD, orgT = Data[idx,:], Target[idx,:]\n            srcD, srcT = self.generator2.__getitem__(srcidx)\n            mD, mT1 = self.mixup(orgD,srcD[0], orgT, srcT[0])\n            Data[idx,:], Target[idx,:] = mD, mT    \n        \n        return Data, Target\n\n    def on_epoch_end(self):\n        self.generator1.on_epoch_end()\n        self.generator2.on_epoch_end()","c7190548":"recipe_sel = 0\nrecipe = recipes[recipe_sel]\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2\n                                                  , random_state=recipe_sel, stratify =train_labels )\n\ntrain_gen_base = ScenGenerator(X_train, y_train, input_shape=recipe['input_shape']\n                         ,batchsize=recipe['batch_size'],state='Train')\n\ncut_src_gen = ScenGenerator(X_train, y_train, input_shape=recipe['input_shape']\n                         ,batchsize=1,state='CutAndMixSrc')\ntrain_gen = CutMixGenerator(\n        generator1=train_gen_base,\n        generator2=cut_src_gen,\n        mixup_p = 0.5,\n        cut_p=0.5\n    )\n\nval_gen = ScenGenerator(X_val, y_val, input_shape=recipe['input_shape']\n                       ,batchsize=recipe['batch_size'],state='Valid')\ntest_gen = ScenGenerator(valid_images, valid_labels, input_shape=recipe['input_shape']\n                        ,batchsize=recipe['batch_size'],state='Test')","b93a6ddc":"tt = train_gen.__getitem__(0)\nfig = plt.figure(figsize=(12,12))\nfig.suptitle('Generator Check Augmentation!! ')\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(tt[0][i])\n    plt.xlabel(class_names[np.argmax(tt[1][i])]+str([round(p,2) for p in tt[1][i]]))\nplt.show()\nprint(tt[0].shape)","b488b41e":"# train the model\ntrain_model_list = []\nhistorys =[]\nskip_train = False\nfor i, recipe in enumerate(recipes):\n    X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2\n                                                      , random_state=recipe[\"val_sel\"], stratify =train_labels )\n    \n    train_gen_base = ScenGenerator(X_train, y_train, input_shape=recipe['input_shape']\n                             ,batchsize=recipe['batch_size'],state='Train')\n\n    cut_src_gen = ScenGenerator(X_train, y_train, input_shape=recipe['input_shape']\n                             ,batchsize=1,state='CutAndMixSrc')\n    train_gen = CutMixGenerator(\n            generator1=train_gen_base,\n            generator2=cut_src_gen,\n            mixup_p = 0.05,\n            cut_p=0.1\n        )\n    \n    val_gen = ScenGenerator(X_val, y_val, input_shape=recipe['input_shape']\n                           ,batchsize=recipe['batch_size'],state='Valid')\n\n    model_name = recipe[\"name\"] + '_val_' + str(recipe[\"val_sel\"]) \n    best_save_model_file = model_name + '.h5' \n    train_model_list.append(best_save_model_file)\n    if skip_train == True and os.path.isfile(best_save_model_file):\n        print(f'skip train and reuse weight {best_save_model_file}')\n        continue\n        \n    print('best_save_model_file path : ',best_save_model_file)\n\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5\n                ,verbose=1, patience=2,min_lr=0.00005,min_delta=0.001, mode='max') \n    check_point=tf.keras.callbacks.ModelCheckpoint(monitor='val_accuracy',verbose=1\n                                                   ,filepath=best_save_model_file,save_best_only=True,mode='max') \n    estop = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='max')\n    \n\n    with strategy.scope():   \n        model = build_model(backbone= recipe['backbone']\n        ,input_shape=recipe['input_shape'], use_imagenet = 'imagenet', group=recipe['group'])\n        model.compile(optimizer=Adam(learning_rate=0.0005*gpus)\n        ,loss='categorical_crossentropy', metrics=['accuracy'])\n        \n        if os.path.isfile(best_save_model_file):\n            print(f'weights exist so re-train file path {best_save_model_file}')\n            model.load_weights(best_save_model_file)        \n        history = model.fit(train_gen ,validation_data=val_gen,epochs=30,callbacks =[reduce_lr,check_point, estop], verbose=1)\n    historys.append(history)        \n        \n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5\n                ,verbose=1, patience=2,min_lr=0.00005,min_delta=0.001, mode='max') \n    estop = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy', min_delta=0, patience=5, verbose=1, mode='max')\n\n    with strategy.scope():   \n        opt = Adam(lr=0.00005*gpus)\n        opt = SWA(opt)\n        model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])           \n        swa_history = model.fit(train_gen ,validation_data=val_gen,epochs=30,callbacks =[reduce_lr,check_point, estop], verbose=1)\n    historys.append(swa_history)  ","75f34666":"def plot_accuracy_loss(history, text=None):\n    \"\"\"\nenumerate    Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n    if text is not None:\n        fig.suptitle(text)\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","169efc6a":"historys[1]","b1c70dae":"# plot accuracy loss\nfor idx, history in enumerate(historys):\n    if idx%2==0:\n        plot_accuracy_loss(history, recipes[idx\/\/2]['name'] )\n    else:\n        plot_accuracy_loss(history, recipes[idx\/\/2]['name'] +' w\/swa')","a7652692":"def tta_predict(model, imgs):\n    pred_val = model.predict(imgs,verbose=1)\n    pred_val_lr = model.predict(np.flip(imgs,axis=2), verbose=1)\n    return (pred_val+pred_val_lr)\/2.0\n\ndef average_ensemble(recipes, imgs, test=False):\n    res = np.zeros((len(imgs),len(class_names)))\n    for recipe in recipes:\n        model = build_model(backbone= recipe['backbone']\n                            ,input_shape=recipe['input_shape'], use_imagenet = None, group=recipe['group'])\n        path = recipe[\"name\"] + '_val_' + str(recipe[\"val_sel\"]) +'.h5'\n        model.load_weights(path)\n        pred_val = tta_predict(model, imgs)\n        if test == False:\n            np.save(path.replace('.h5','.npy'),pred_val)\n        else:\n            np.save(path.replace('.h5','_test.npy'),pred_val)\n\n        res += pred_val\n    res \/= len(recipes)\n    return res\n    \npred_val = average_ensemble(recipes,valid_images)","64715049":"pred_val_label = np.argmax(pred_val,axis=1)\nprint(f'accuracy_score : {accuracy_score(valid_labels, pred_val_label)}')\nprint(f'f1_score : {f1_score(valid_labels, pred_val_label,average=\"macro\")}')\ncm = confusion_matrix(valid_labels, pred_val_label)\n\ndf_cm = pd.DataFrame(cm, index = [i for i in class_names],\n                  columns = [i for i in class_names])\nplt.figure(figsize = (10,7))\n\nsn.heatmap(df_cm, annot=True,  fmt='d')\nplt.ylabel('Actual')\nplt.xlabel('Predict')\nplt.show()","2b5dfe3f":"preds = []\nfor recipe in recipes:\n    path = recipe[\"name\"] + '_val_' + str(recipe[\"val_sel\"]) +'.npy'\n    pred_val = np.load(path)\n    preds.append(pred_val)","7d6f19b1":"ensemble_arr = np.stack(preds,axis=-1)\nxin = tf.keras.layers.Input((5,len(recipes)))\nx = tf.keras.layers.Convolution1D(1,kernel_size=1,activation='linear',use_bias=False)(xin)\nx = tf.keras.layers.Reshape(target_shape=(5,))(x)\nwensemble_model = tf.keras.Model(inputs=xin, outputs=x)\nwensemble_model.summary()","d079a9cb":"wensemble_model.compile(optimizer=tf.keras.optimizers.Adam(1),loss='mse')\nwensemble_model.fit(x=ensemble_arr,y=tf.keras.utils.to_categorical(valid_labels)\n                    , epochs=8000, batch_size=len(ensemble_arr),verbose=0)","e0e0bb49":"wpred = wensemble_model.predict(ensemble_arr)\nwensemble_model.get_weights()","479e8b42":"pred_val_label = np.argmax(wpred,axis=1)\nprint(f'accuracy_score : {accuracy_score(valid_labels, pred_val_label)}')\nprint(f'f1_score : {f1_score(valid_labels, pred_val_label,average=\"macro\")}')\ncm = confusion_matrix(valid_labels, pred_val_label)\n\ndf_cm = pd.DataFrame(cm, index = [i for i in class_names],\n                  columns = [i for i in class_names])\nplt.figure(figsize = (10,7))\n\nsn.heatmap(df_cm, annot=True,  fmt='d')\nplt.ylabel('Actual')\nplt.xlabel('Predict')\nplt.show()","52e300da":"def display_examples_wprd(class_names, images, labels, prds):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]] + ',' + class_names[prds[i]], fontsize=10 )\n    plt.show()","30579542":"sample_idx = np.random.randint(0, valid_images.shape[0], 25)\nsample_images = valid_images[sample_idx]\nsample_labels = valid_labels[sample_idx]\nsample_prd = pred_val_label[sample_idx]\ndisplay_examples_wprd(class_names, sample_images, sample_labels, sample_prd)","73f0ab98":"def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n    \"\"\"\n        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n    \"\"\"\n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n    org_labels = test_labels[mislabeled_indices]\n    title = \"Some examples of mislabeled images by the classifier:\"\n    display_examples_wprd(class_names,  mislabeled_images,org_labels, mislabeled_labels)","d0cbb53b":"print_mislabeled_images(class_names, valid_images, valid_labels, pred_val_label )","32cfaa23":"def tta_predict_feature(recipe, imgs):\n    model = build_model(backbone= recipe['backbone']\n                        ,input_shape=recipe['input_shape'], use_imagenet = None, group=recipe['group'])\n    path = recipe[\"name\"] + '_val_' + str(recipe[\"val_sel\"]) +'.h5'\n    model.load_weights(path)\n    feature_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer('gap').output)\n    pred_val = feature_model.predict(imgs,verbose=1)\n    pred_val_lr = feature_model.predict(np.flip(imgs,axis=2), verbose=1)\n    return (pred_val+pred_val_lr)\/2.0","da11ee9b":"valid_features = tta_predict_feature(recipes[0],valid_images)","0414ed10":"from sklearn.manifold import TSNE\ntsne = TSNE(n_components=2, verbose=1, random_state=0)\ntsne_results = tsne.fit_transform(valid_features)","1c8cf1fd":"sn.set(style=\"whitegrid\")\nscplot = sn.scatterplot(x= tsne_results[:,0], y=tsne_results[:,1]\n               , hue=[class_names[i] for  i in valid_labels], hue_order = class_names,legend=False)","ebfd6577":"base_model = recipes[0]['backbone'](input_shape=recipe['input_shape'],weights='imagenet',include_top= False)\nx = base_model.output\nx = tf.keras.layers.GlobalAvgPool2D(name='gap')(x)\nnotrain_model_features = tf.keras.Model(inputs=base_model.input, outputs=x)","49bed202":"no_valid_features = notrain_model_features.predict(valid_images,verbose=1)","f5d708d1":"from sklearn.manifold import TSNE\nnotrain_tsne = TSNE(n_components=2, verbose=1, random_state=0)\nnotrain_tsne_results = notrain_tsne.fit_transform(no_valid_features)","e4ec05b4":"sn.scatterplot(x= notrain_tsne_results[:,0], y=notrain_tsne_results[:,1]\n               , hue=[class_names[i] for  i in valid_labels], hue_order = class_names,legend=False)","36a851b8":"print(test_images.shape)\nplt.imshow(test_images[0])\nplt.show()","51948318":"pred_test = average_ensemble(recipes,test_images, test=True)","756dc50d":"preds = []\nfor recipe in recipes:\n    path = recipe[\"name\"] + '_val_' + str(recipe[\"val_sel\"]) +'_test.npy'\n    pred_test = np.load(path)\n    preds.append(pred_test)","6ce23a79":"ensemble_arr = np.stack(preds,axis=-1)\nwpred = wensemble_model.predict(ensemble_arr)","5de1950a":"pred_test_label = np.argmax(wpred,axis=1)","5a33e89a":"pred_names = [class_names[label] for label in pred_test_label]\nsub_df = pd.DataFrame(test_path, columns=['image'])\nsub_df['label']=pred_names\nsub_df.to_csv('submission_4team.csv',index=None,header=None)","c8f55f32":"fig = plt.figure(figsize=(10,10))\nfig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_images[i], cmap=plt.cm.binary)\n    plt.xlabel(pred_names[i])\nplt.show()","b31d7d1f":"# Load the Dataset","ed31fe54":"## Features Distance - Imagenet Weight State ","47015276":"# Import Packages","941d8315":"# Make Submission","972761a4":"# Now Look our some test result . Good? or Bad?","2237e6a2":"# Check Features distance - our train model\n\n    - Better Splittable  ^^","2a36a3cc":"# Explore the Dataset"}}