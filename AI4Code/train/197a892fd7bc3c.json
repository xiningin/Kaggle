{"cell_type":{"84659bda":"code","0d1c1d67":"code","560d76a7":"code","9a938561":"code","38e33fe4":"code","5154e30d":"code","a76c5945":"code","cff87380":"code","e749bef7":"code","5259a3c8":"code","5af125f4":"code","872a2180":"code","91bc584c":"code","814a6422":"code","02078681":"code","c6d4a950":"code","e956c0b1":"code","9c7a475a":"code","a0680cb0":"code","f6573f54":"code","c30c1286":"code","757bec03":"code","c9ce02d2":"code","cff6f323":"code","2b8f89f3":"code","db1dcbe1":"code","1d7afb8e":"code","e0edf09e":"code","1c8b9583":"code","666dd13f":"code","481d7a65":"code","33375449":"code","b4e0b34c":"code","ec35d679":"code","4d99ee88":"code","d435d834":"code","ce33fe63":"code","41005c34":"code","f9dc2c52":"code","16e02cc7":"code","0e94b10a":"code","3b2cefb6":"code","da6f46e6":"code","72bbc9ef":"code","ddbdd724":"code","39abd54a":"code","69503607":"code","fdbd50fc":"code","d1d0499a":"code","a15d764c":"code","96dc95d2":"code","7280dd9f":"code","8be91ef4":"code","2ee72f9a":"code","fab69624":"code","7a8e2806":"code","a2585296":"code","de459243":"code","fcbb1c5e":"code","98d79c3c":"code","4440fab0":"code","1710255f":"code","9596c5b5":"code","84760e29":"code","1db2842e":"code","d46042ea":"code","fe3aaa0e":"code","413cadf8":"code","fe821c77":"code","e4554abb":"code","b516c181":"code","9220deb4":"code","c69cb173":"code","aa3ced39":"code","90be521b":"code","a1f9b900":"code","4da6a23c":"code","9368fb43":"code","8b9de5a3":"code","d8c3182c":"code","05cf7ca0":"code","168a9914":"code","59e506df":"code","11c1b148":"code","2b5f88cd":"code","abf78ca0":"code","d62d09b2":"code","b8ca4ff7":"code","28914649":"code","5be2a0b2":"markdown","13965d91":"markdown","6fc88c86":"markdown","6131cad1":"markdown","ef135681":"markdown","ff1a0f58":"markdown","9b89599b":"markdown","e5baacc3":"markdown","ce9ed69a":"markdown","3a278935":"markdown","fcf4bca6":"markdown","09a36443":"markdown","524fd3b3":"markdown","33e253e2":"markdown","6758fa3b":"markdown","74ffacc2":"markdown","778c61d9":"markdown","2765daa9":"markdown","7a803105":"markdown","e810a01c":"markdown","0f3e8f9b":"markdown","9580ce2d":"markdown","9d3ea354":"markdown","0bb68a69":"markdown","e25d8c52":"markdown","77c834f2":"markdown","0bf41a92":"markdown"},"source":{"84659bda":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom sklearn import preprocessing\npd.set_option('display.float_format', lambda x: '%.2f' % x)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\n\n# Any results you write to the current directory are saved as output.","0d1c1d67":"dataframe = pd.read_csv('..\/input\/credit_train.csv')","560d76a7":"print(\"Number of rows:\", dataframe.shape[0])\nprint(\"Number of columns:\", dataframe.shape[1])","9a938561":"dataframe.head()","38e33fe4":"dataframe.describe()","5154e30d":"df = dataframe[dataframe['Credit Score']>800]\ndf.head()","a76c5945":"dataframe['Credit Score'] = dataframe['Credit Score'].apply(lambda val: (val \/10) if val>850 else val)","cff87380":"dataframe.describe()","e749bef7":"dataframe.head()","5259a3c8":"dataframe.dropna(subset=['Loan Status'], inplace = True)","5af125f4":"le = preprocessing.LabelEncoder()\ndataframe['Loan Status'] = le.fit_transform(dataframe['Loan Status'])","872a2180":"dataframe.head()","91bc584c":"coffvalue = dataframe[dataframe['Loan Status'] == 0]['Loan Status'].count()\nfpaidvalue = dataframe[dataframe['Loan Status'] == 1]['Loan Status'].count()\ndata = {\"Counts\":[coffvalue, fpaidvalue] }\nstatusDF = pd.DataFrame(data, index=[\"Charged Off\", \"Fully Paid\"])\n# statusDF.head()\nstatusDF.plot(kind='bar', title=\"Status of the Loan\")","814a6422":"print(\"Value counts for each term: \\n\",dataframe['Term'].value_counts())\nprint(\"Missing data in loan term:\",dataframe['Term'].isna().sum())","02078681":"dataframe['Term'].replace((\"Short Term\",\"Long Term\"),(0,1), inplace=True)\ndataframe.head()","c6d4a950":"scount = dataframe[dataframe['Term'] == 0]['Term'].count()\nlcount = dataframe[dataframe['Term'] ==1]['Term'].count()\n\ndata = {\"Counts\":[scount, lcount]}\ntermDF = pd.DataFrame(data, index=[\"Short Term\", \"Long Term\"])\ntermDF.head()","e956c0b1":"termDF.plot(kind=\"barh\", title=\"Term of Loans\")","9c7a475a":"print(\"There are \", dataframe['Credit Score'].isna().sum(), \"null values for Credit score.\")","a0680cb0":"cscoredf = dataframe[dataframe['Term']==0]\nstermAVG = cscoredf['Credit Score'].mean()\nprint(stermAVG)","f6573f54":"lscoredf = dataframe[dataframe['Term']==1]\nltermAVG = lscoredf['Credit Score'].mean()\nprint(ltermAVG)","c30c1286":"dataframe.head()","757bec03":"do_nothing = lambda: None","c9ce02d2":"dataframe.loc[(dataframe.Term ==0) & (dataframe['Credit Score'].isnull()),'Credit Score'] = stermAVG","cff6f323":"dataframe.loc[(dataframe.Term ==1) & (dataframe['Credit Score'].isnull()),'Credit Score'] = ltermAVG","2b8f89f3":"dataframe['Credit Score'] = dataframe['Credit Score'].apply(lambda val: \"Poor\" if np.isreal(val) and val < 580 else val)\ndataframe['Credit Score'] = dataframe['Credit Score'].apply(lambda val: \"Average\" if np.isreal(val) and (val >= 580 and val < 670) else val)\ndataframe['Credit Score'] = dataframe['Credit Score'].apply(lambda val: \"Good\" if np.isreal(val) and (val >= 670 and val < 740) else val)\ndataframe['Credit Score'] = dataframe['Credit Score'].apply(lambda val: \"Very Good\" if np.isreal(val) and (val >= 740 and val < 800) else val)\ndataframe['Credit Score'] = dataframe['Credit Score'].apply(lambda val: \"Exceptional\" if np.isreal(val) and (val >= 800 and val <= 850) else val)","db1dcbe1":"dataframe['Credit Score'].value_counts().sort_values(ascending = True).plot(kind='bar', title ='Number of loans in terms of Credit Score category')","1d7afb8e":"print(\"There are\",dataframe['Annual Income'].isna().sum(), \"Missing Annual Income Values.\")","e0edf09e":"dataframe['Annual Income'].fillna(dataframe['Annual Income'].mean(), inplace=True)","1c8b9583":"dataframe.head()","666dd13f":"dataframe = dataframe.join(pd.get_dummies(dataframe['Credit Score'], drop_first = True))","481d7a65":"dataframe.rename(index = str, columns={'Good':'Credit Good', 'Very Good':'Credit Very Good'})","33375449":"dataframe = dataframe.drop(['Credit Score'], axis=1)","b4e0b34c":"dataframe['Purpose'].value_counts().sort_values(ascending=True).plot(kind='barh', title=\"Purpose for Loans\", figsize=(15,10))","ec35d679":"purposeloanstatus = dataframe[['Purpose','Loan Status']]\npurposeloanstatus.head()","4d99ee88":"pd.crosstab(purposeloanstatus['Purpose'], purposeloanstatus['Loan Status']).plot(kind='bar', stacked=True, figsize=(20,10), title=\"Purpose of Loan Vs Loan Payment Status\", )","d435d834":"dataframe['Home Ownership'].value_counts().sort_values(ascending = True).plot(kind='bar', title=\"Number of Loan based on Home ownership\")","ce33fe63":"dataframe = dataframe.join(pd.get_dummies(dataframe['Home Ownership'],drop_first = True))","41005c34":"dataframe = dataframe.drop(['Home Ownership'], axis=1)","f9dc2c52":"dataframe['Years in current job']=dataframe['Years in current job'].str.extract(r\"(\\d+)\")\ndataframe['Years in current job'] = dataframe['Years in current job'].astype(float)\n# dataframe['Years in current job'].fillna(dataframe['Years in current job'].mean(), inplace = True)\n","16e02cc7":"expmean = dataframe['Years in current job'].mean()","0e94b10a":"dataframe['Years in current job'].fillna(expmean, inplace=True)","3b2cefb6":"dataframe['Employment History'] = dataframe['Years in current job'].apply(lambda x: \"Emp Level Jr.\" if x<4 else (\"Emp Level Mid\" if x>4 and x<8 else \"Emp Senior\"))","da6f46e6":"dataframe.head()","72bbc9ef":"dataframe = dataframe.drop(['Years in current job'], axis=1)","ddbdd724":"dataframe = dataframe.join(pd.get_dummies(dataframe['Employment History'],drop_first = True))","39abd54a":"dataframe = dataframe.drop(['Employment History'], axis=1)","69503607":"dataframe = dataframe.drop(['Loan ID','Customer ID','Purpose'], axis=1)","fdbd50fc":"dataframe.head()","d1d0499a":"dataframe['Credit Problems'] = dataframe['Number of Credit Problems'].apply(lambda x: \"No Credit Problem\" if x==0 else (\"Some Credit promblem\" if x>0 and x<5 else \"Major Credit Problems\"))","a15d764c":"dataframe['Credit Problems'].value_counts()","96dc95d2":"dataframe['Credit Problems'].value_counts().sort_values(ascending=True).plot(kind='barh', title=\"Loans vs Credit problems of Loanee\")","7280dd9f":"dataframe = dataframe.join(pd.get_dummies(dataframe['Credit Problems'],drop_first = True))","8be91ef4":"dataframe = dataframe.drop(['Credit Problems','Number of Credit Problems'], axis=1)","2ee72f9a":"dataframe.head()","fab69624":"dataframe['Credit Age'] = dataframe['Years of Credit History'].apply(lambda x: \"Short Credit Age\" if x<5 else (\"Good Credit Age\" if x>5 and x<17 else \"Exceptional Credit Age\"))","7a8e2806":"dataframe = dataframe.join(pd.get_dummies(dataframe['Credit Age'],drop_first = True))","a2585296":"dataframe = dataframe.drop(['Credit Age','Years of Credit History'], axis =1)\ndataframe.head()","de459243":"dataframe = dataframe.drop(['Months since last delinquent','Number of Open Accounts','Maximum Open Credit','Current Credit Balance','Monthly Debt'],axis=1)","fcbb1c5e":"dataframe.head()","98d79c3c":"dataframe['Tax Liens'] = dataframe['Tax Liens'].apply(lambda x: \"No Tax Lien\" if x==0 else (\"Some Tax Liens\" if x>0 and x<3 else \"Many Tax Liens\"))","4440fab0":"dataframe = dataframe.join(pd.get_dummies(dataframe['Tax Liens'],drop_first = True))","1710255f":"dataframe = dataframe.drop(['Tax Liens'],axis=1)\ndataframe.head()","9596c5b5":"dataframe['Bankruptcies'] = dataframe['Bankruptcies'].apply(lambda x: \"No bankruptcies\" if x==0 else (\"Some Bankruptcies\" if x>0 and x<3 else \"Many Bankruptcies\"))","84760e29":"dataframe = dataframe.join(pd.get_dummies(dataframe['Bankruptcies'],drop_first = True))","1db2842e":"dataframe = dataframe.drop(['Bankruptcies'],axis=1)\ndataframe.head()","d46042ea":"dataframe.describe()","fe3aaa0e":"meanxoutlier = dataframe[dataframe['Annual Income'] < 99999999.00 ]['Annual Income'].mean()\nstddevxoutlier = dataframe[dataframe['Annual Income'] < 99999999.00 ]['Annual Income'].std()\npoorline = meanxoutlier -  stddevxoutlier\nrichline = meanxoutlier + stddevxoutlier","413cadf8":"dataframe['Annual Income'] = dataframe['Annual Income'].apply(lambda x: \"Low Income\" if x<=poorline else (\"Average Income\" if x>poorline and x<richline else \"High Income\"))","fe821c77":"dataframe = dataframe.join(pd.get_dummies(dataframe['Annual Income'],drop_first = True))","e4554abb":"dataframe = dataframe.drop(['Annual Income'], axis=1)\ndataframe.head()","b516c181":"lmeanxoutlier = dataframe[dataframe['Current Loan Amount'] < 99999999.00 ]['Current Loan Amount'].mean()\nlstddevxoutlier = dataframe[dataframe['Current Loan Amount'] < 99999999.00 ]['Current Loan Amount'].std()\nlowrange = lmeanxoutlier - lstddevxoutlier\nhighrange = lmeanxoutlier + lstddevxoutlier\nprint(lowrange, highrange)","9220deb4":"dataframe['Current Loan Amount'] = dataframe['Current Loan Amount'].apply(lambda x: \"Small Loan\" if x<=lowrange else (\"Medium Loan\" if x>lowrange and x<highrange else \"Big Loan\"))","c69cb173":"dataframe = dataframe.join(pd.get_dummies(dataframe['Current Loan Amount'],drop_first = True))","aa3ced39":"dataframe = dataframe.drop(['Current Loan Amount'], axis=1)","90be521b":"dataframe.head()","a1f9b900":"y = dataframe['Loan Status']\nX = dataframe.drop(['Loan Status'],axis=1)","4da6a23c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","9368fb43":"knnclassifier = KNeighborsClassifier(n_neighbors = int(X.shape[1]\/2))\nknnclassifier.fit(X_train, y_train)\nprediction = knnclassifier.predict(X_test)\nprint(\"Accuracy Score: \", accuracy_score(y_test, prediction))\n# y_true = y_test\n","8b9de5a3":"tneg, fpos, fneg, tpos = confusion_matrix(y_test, prediction).ravel()\nprint(tneg,fpos,fneg,tpos)","d8c3182c":"lregclassifier = LogisticRegression()\nlregclassifier.fit(X_train,y_train)\nlregprediction = lregclassifier.predict(X_test)\nprint(\"Score: \",lregclassifier.score(X_test, y_test))","05cf7ca0":"tneg, fpos, fneg, tpos = confusion_matrix(y_test, lregprediction).ravel()\nprint(tneg,fpos,fneg,tpos)","168a9914":"from sklearn.svm import SVC\nclf = SVC(gamma='auto', kernel ='linear')\nclf.fit(X_train, y_train)\npred = clf.predict(X_test)\nprint(\"Accuracy Score: \", accuracy_score(y_test, pred))","59e506df":"tneg, fpos, fneg, tpos = confusion_matrix(y_test, pred).ravel()\nprint(tneg,fpos,fneg,tpos)","11c1b148":"XGBclf = XGBClassifier()\nXGBclf.fit(X_train,y_train)","2b5f88cd":"XGBpred = XGBclf.predict(X_test)\nprint(\"Accuracy Score: \", accuracy_score(y_test, XGBpred))","abf78ca0":"tneg, fpos, fneg, tpos = confusion_matrix(y_test, XGBpred).ravel()\nprint(tneg,fpos,fneg,tpos)","d62d09b2":"SGDclf = SGDClassifier(loss='modified_huber',shuffle=True)\nSGDclf.fit(X_train,y_train)","b8ca4ff7":"SGDpred = SGDclf.predict(X_test)\nprint(\"Accuracy Score: \", accuracy_score(y_test, SGDpred))","28914649":"tneg, fpos, fneg, tpos = confusion_matrix(y_test, SGDpred).ravel()\nprint(tneg,fpos,fneg,tpos)","5be2a0b2":"***Since there are multiple ways to handle the missing data, one of which is to fill in the average of the column in the place of missing data. Here we follow the same concept but with a small tweak. We asume that the credit score of people having short term loan wouldn't be the same as credit score of people having long term loans. Hence we take separate average of credit score of people with short term loan and separate average of people with long term loan and then fill the missing credit score looking up at the term of the loan.***","13965d91":"Furthermore, we take a look at nuber of bankruptcies filed by people and categorize them.","6fc88c86":"Next up, we take a look at the Home ownership status of the people who have taken loan and try to visualize it.","6131cad1":"Since our values were only adjectives, we give it new names to make it more clear.","ef135681":"Here, we see something strange. If you notice the average credit scoe is 1076+ which is strange considering the credit score are within th range of 300-850. Let's take a look and try to find sense of the credit score data and check if there are any score that are greater than 800.","ff1a0f58":"**Before starting with any analysis, we take a small peek at our data and some of the values.**","9b89599b":"If we take a look at our data, there are columns like Loan ID, Customer ID which isn't important for our analysis. While we can argue   in some cases  purpose of loan could be one deciding factor but here we consider it to be unimportant and drop that as well.","e5baacc3":"Following up on our step with Credit Score, we now try to change it to a discrete value, but since it has multiple class, we use one hot encoding to make sure we dont increase the dimension of our data. We also look out for potential multi-colinearity as we drop one variable of the encoding, which is easily calculated given the other four variables. This is consistent through out the notebook, with the use of one hot encoding.","ce9ed69a":"**Loan Status Classification**\nHere in this notebook we take a look at the data from a bank\/financial organization of all their loans. We explore various features about the borrowers like credit score, mortgage, annual income, years of employment and try to train our classifer to predict if the loan would be paid or not.","3a278935":"Now that we have the categories for our employment history, we use one hot encoding on the column.","fcf4bca6":"As we can see most of the loans have been either by the people have mortgage on their home or by people who are in rent.","09a36443":"Since credit score is one of the important part of our analysis, we first try to explore and handle our missing data before processing further with anything.","524fd3b3":"Now we can see that we have all categorical values for our dataframe we can divide it into training and test set and plug into some classification algorithm.","33e253e2":"we then drop the Employment History column.","6758fa3b":"Another important feature for financial stability identification is the years of credit history. We look at the given credit age of individuals and categorize them using one hot encoding.","74ffacc2":"We move forward with the asumption that some of the columns are correlated with the others and hence we try to reduce the number of features. For example, we have credit score and credit problems which can is calculated using features like maximum open credit, current credit balance etc. So we drop some of the columns that we asume are already covered by features we have on our dataframe.","778c61d9":"Next up is number of credit problems reported for each individual loanee. We split that into three categories with 0 being None, 1-5 as Some and more than 5 to be major credit problems.","2765daa9":"**We already know we're predicting categorical variables hence we have to convert our cateorical variables into discrete. Next up we try to convert annual income and total loan amount into discrete variables. \nThere are some calculation we do before deciding a range from the categories. If we take a look, we have some data that are outliers and are way off the other loan amounts. so we try to calculate the average and standard deviation without the outlier. \nWe asume : Mean - 1 standard deviation = low income line\n                    Mean + 1 standard deviation = high income line\n  and similar for the loan amount as well.\n**","7a803105":"Now That we have a numerical value for our Employment Age, we use a uniform range to convert it into categories.","e810a01c":"Since our problem is a classification problem, we can't have continuos variables in our dataframe. After the calculation of the missing variables we give our credit scores a range based on **Experian's Credit Score Range**.","0f3e8f9b":"Next up we look at our annual income column and fill up the missing values with the average of the column.","9580ce2d":"Moving forward, age of employment is one of the major factor in deciding the person's financial stability and secure income sources.  Here our data was a String with non uniform spread. first we need to extract the given numbers from our data and then give it a unform range to convert it into a categorical variable","9d3ea354":"As we can see, it looks like some of the credit score are just scaled up by 10. For the ease of our calculation we can consider, scaling them back is accurate.","0bb68a69":"Further exploring the financial stability of each loanee, we take the look at number of liens on their property by court which would give us information about their previous commitments.","e25d8c52":"Now we can see our average credit score is within a normal credit score range so we can go further with our preprocessing.","77c834f2":"Looking at the graph above, we establish a common asumption that loans are generally not given to people having credit problems. Next up, we convert Credit Problems into discrete variables. ","0bf41a92":"# Loan Status is the categorical variable here denoting if the certain variable is paid off or not. In this notebook, we aim to predict that as our final output."}}