{"cell_type":{"0712fa6a":"code","4c5a44df":"code","855226b1":"code","f4238a3e":"code","9a4fc0e6":"code","1c488075":"code","f935ad1f":"code","81e667e8":"code","4166bc30":"code","31f5d0cd":"code","165556d5":"code","4c72359c":"code","3804f494":"code","0784d0cc":"code","8827f7cb":"code","e11b2cb3":"code","9cc32625":"code","ffcbad46":"code","080dcd79":"code","75e873eb":"code","75a0f550":"code","5fcc11e9":"markdown","9765f3c1":"markdown","a3ebf8c9":"markdown","52749845":"markdown","aa8c4a86":"markdown","09611e7c":"markdown","511e1bba":"markdown","68d9fac9":"markdown","d1d3d41b":"markdown","06e46ef3":"markdown","6f3562e5":"markdown","32bc0652":"markdown","550224da":"markdown","6848580e":"markdown"},"source":{"0712fa6a":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport warnings \nwarnings.simplefilter('ignore')","4c5a44df":"def hist_visualize(df_failed,df_passed,item):\n    plt.figure(figsize = (15,10))\n    plt.title(f'Distribution of {item}')\n    plt.hist(df_passed[item],bins = 15, alpha = 0.5, label = 'passed')\n    plt.hist(df_failed[item],bins = 15, alpha = 0.5, label = 'failed')\n    plt.vlines(x = df_failed[item].median(),lw = 2, color = 'r', ymin = 0, ymax = 7, label = 'median value for failed')\n    plt.vlines(x = df_passed[item].median(),lw = 2, color = 'b', ymin = 0, ymax = 7, label = 'median value for passed')\n    plt.legend()\n    plt.grid()\n    return 0","855226b1":"df = pd.read_csv('..\/input\/student-marks\/marks.txt', names = ['MID-SEM-MARKS', 'END-SEM-MARKS', 'RESULT'])","f4238a3e":"df.shape","9a4fc0e6":"df.sample(5)","1c488075":"df.info()","f935ad1f":"df.describe()","81e667e8":"sns.heatmap(df.corr(), annot = True, cbar = False, square = True)","4166bc30":"df[df.RESULT == 0]","31f5d0cd":"#split data into passed\/failed samples\ndf_failed = df[df.RESULT == 0]\ndf_passed = df[df.RESULT == 1]","165556d5":"hist_visualize(df_failed, df_passed, 'MID-SEM-MARKS')","4c72359c":"hist_visualize(df_failed, df_passed, 'END-SEM-MARKS')","3804f494":"df_temp = pd.DataFrame()\ndf_temp['RESULT'] = df['RESULT']\ndf_temp['MARKS'] = df[['MID-SEM-MARKS', 'END-SEM-MARKS']].sum(axis = 1)\ndf_temp.head()","0784d0cc":"df_temp_failed = df_temp[df_temp.RESULT == 0]\ndf_temp_passed = df_temp[df_temp.RESULT == 1]","8827f7cb":"hist_visualize(df_temp_failed, df_temp_passed, 'MARKS')","e11b2cb3":"y_pred = (df_temp.MARKS > 130).astype(int)","9cc32625":"acc_base = accuracy_score(df['RESULT'], y_pred)*100\nprint(f'Baseline accuracy: {acc_base} %')","ffcbad46":"!pip install lazypredict==0.2.8","080dcd79":"from lazypredict.Supervised import LazyClassifier","75e873eb":"y= df.RESULT\nX = df.drop(['RESULT'], axis= 1)\n\n#make 80\/20 train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state =123)\n","75a0f550":"clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\nmodels,predictions = clf.fit(X_train, X_test, y_train, y_test)\nmodels\n","5fcc11e9":"We have a huge difference in median values for passed\/failed students","9765f3c1":"Hope you enjoyed this simple ML task, follow me on [Kaggle](https:\/\/www.kaggle.com\/dzisandy)","a3ebf8c9":"# Importing data\n","52749845":"# END-SEM-MARKS\tVisualization","aa8c4a86":"We have a huge difference in median values for passed\/failed students","09611e7c":"Well, pretty nice. Let's use some data science stuff. To check best models we will use `LazyPredict` library.\n[Link to installation](https:\/\/lazypredict.readthedocs.io\/en\/latest\/readme.html#installation) ","511e1bba":"Let's check accuracy score:","68d9fac9":"\n*   No `Nan` values\n*   No full correlation between any of the features\n\n\n","d1d3d41b":"# EDA","06e46ef3":"Now we make simple rule SUM('END-SEM-MARK', 'MID-SEM-MARK') > 130 to make simple classification as a baseline.","6f3562e5":"# ML Models","32bc0652":"As we can see, our hyposesis has been proved, due to the fact that SVC found separating 2-D hyperplane. Also here we see, that lack of features tens to simpliest models, because Tree-based algorithms are less powerfull on this dataset, rather than simple models.","550224da":"# MID-SEM-MARKS Visualization","6848580e":"From previous points of view, we have a hyposesis, that sum of marks will give nice baseline result in classification."}}