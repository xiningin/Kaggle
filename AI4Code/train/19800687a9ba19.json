{"cell_type":{"7b8623da":"code","924cc158":"code","2d4ea788":"code","9ab67522":"code","a7e7ce01":"code","f9bbac52":"code","6ae88a9d":"code","96702124":"code","89e8474c":"code","d4a4dd5a":"code","3d427338":"code","45aec513":"code","47f4d4e9":"code","36ae1447":"code","0a668a29":"code","2553b551":"code","b9f90e23":"code","4f64878b":"code","f630acd7":"code","5a8c33c2":"code","0cf1f0d2":"code","3314a47a":"code","39af3081":"code","9ad9fe14":"code","d03b6ccd":"code","1b459f08":"code","ae25b048":"markdown","c9269ed4":"markdown","ef2b1652":"markdown","ee515a51":"markdown","6074c1af":"markdown","217bc787":"markdown","6dd78e28":"markdown","57d6da81":"markdown","2d742495":"markdown","92534c99":"markdown","57636b46":"markdown","94b709d4":"markdown","0404461b":"markdown","0af87c8c":"markdown","5a832a31":"markdown"},"source":{"7b8623da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()\ncsv_file = '\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv'\n\n#Ofcourse suppressing warnings is evil but sometimes they ought to be suppressed\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","924cc158":"df = pd.read_csv(csv_file)\n\ndf = df.rename(columns={'Order Number': 'order_number',\"Order Status\":\"order_status\", \"Book Name\":\"book_name\",\n                        \"Order Date\":\"order_date\",\"City (Billing)\":\"city\"})\n\n\n\ndf['city'] = df['city'].str.lower()\ndf['book_name'] = df['book_name'].str.lower()\ndf['order_status'] = df['order_status'].str.lower()\n\n#converting order_date to pandas datetime format\ndf['order_date'] = pd.to_datetime(df['order_date'])\n\n\ndf.sample(35)","2d4ea788":"df.info()","9ab67522":"df['city'].nunique()","a7e7ce01":"#if an address contains the name of a Pakistani city from the given list, the entire address is replaced with the name of the city only\n\n#list of pakistani cities obtained from https:\/\/gist.github.com\/malikbilal1997\/4f41d4d153fca7087a8875cac7db8836\npak_cities = ['islamabad', 'ahmed nager chatha', 'ahmadpur east', 'ali khan abad', 'alipur', 'arifwala', 'attock', 'bhera', 'bhalwal', 'bahawalnagar', 'bahawalpur', 'bhakkar', 'burewala', 'chillianwala', 'chakwal', 'chichawatni', 'chiniot', 'chishtian', 'daska', 'darya khan', 'dera ghazi khan', 'dhaular', 'dina', 'dinga', 'dipalpur', 'faisalabad', 'ferozewala', 'fateh jhang', 'ghakhar mandi', 'gojra', 'gujranwala', 'gujrat', 'gujar khan', 'hafizabad', 'haroonabad', 'hasilpur', 'haveli lakha', 'jatoi', 'jalalpur', 'jattan', 'jampur', 'jaranwala', 'jhang', 'jhelum', 'kalabagh', 'karor lal esan', 'kasur', 'kamalia', 'kamoke', 'khanewal', 'khanpur', 'kharian', 'khushab', 'kot addu', 'jauharabad', 'lahore', 'lalamusa', 'layyah', 'liaquat pur', 'lodhran', 'malakwal', 'mamoori', 'mailsi', 'mandi bahauddin', 'mian channu', 'mianwali', 'multan', 'murree', 'muridke', 'mianwali bangla', 'muzaffargarh', 'narowal', 'nankana sahib', 'okara', 'renala khurd', 'pakpattan', 'pattoki', 'pir mahal', 'qaimpur', 'qila didar singh', 'rabwah', 'raiwind', 'rajanpur', 'rahim yar khan', 'rawalpindi', 'sadiqabad', 'safdarabad', 'sahiwal', 'sangla hill', 'sarai alamgir', 'sargodha', 'shakargarh', 'sheikhupura', 'sialkot', 'sohawa', 'soianwala', 'siranwali', 'talagang', 'taxila', 'toba tek singh', 'vehari', 'wah cantonment', 'wazirabad', 'badin', 'bhirkan', 'rajo khanani', 'chak', 'dadu', 'digri', 'diplo', 'dokri', 'ghotki', 'haala', 'hyderabad', 'islamkot', 'jacobabad', 'jamshoro', 'jungshahi', 'kandhkot', 'kandiaro', 'karachi', 'kashmore', 'keti bandar', 'khairpur', 'kotri', 'larkana', 'matiari', 'mehar', 'mirpur khas', 'mithani', 'mithi', 'mehrabpur', 'moro', 'nagarparkar', 'naudero', 'naushahro feroze', 'naushara', 'nawabshah', 'nazimabad', 'qambar', 'qasimabad', 'ranipur', 'ratodero', 'rohri', 'sakrand', 'sanghar', 'shahbandar', 'shahdadkot', 'shahdadpur', 'shahpur chakar', 'shikarpaur', 'sukkur', 'tangwani', 'tando adam khan', 'tando allahyar', 'tando muhammad khan', 'thatta', 'umerkot', 'warah', 'abbottabad', 'adezai', 'alpuri', 'akora khattak', 'ayubia', 'banda daud shah', 'bannu', 'batkhela', 'battagram', 'birote', 'chakdara', 'charsadda', 'chitral', 'daggar', 'dargai', 'darya khan', 'dera ismail khan', 'doaba', 'dir', 'drosh', 'hangu', 'haripur', 'karak', 'kohat', 'kulachi', 'lakki marwat', 'latamber', 'madyan', 'mansehra', 'mardan', 'mastuj', 'mingora', 'nowshera', 'paharpur', 'pabbi', 'peshawar', 'saidu sharif', 'shorkot', 'shewa adda', 'swabi', 'swat', 'tangi', 'tank', 'thall', 'timergara', 'tordher', 'awaran', 'barkhan', 'chagai', 'dera bugti', 'gwadar', 'harnai', 'jafarabad', 'jhal magsi', 'kacchi', 'kalat', 'kech', 'kharan', 'khuzdar', 'killa abdullah', 'killa saifullah', 'kohlu', 'lasbela', 'lehri', 'loralai', 'mastung', 'musakhel', 'nasirabad', 'nushki', 'panjgur', 'pishin valley', 'quetta', 'sherani', 'sibi', 'sohbatpur', 'washuk', 'zhob', 'ziarat']\n\ndef get_nearest_city(city):\n  for cand_city in pak_cities:\n    if cand_city in str(city):\n      return cand_city\n  return city \n\nprint(f'total unique cities in our dataset before normalization: {df.city.nunique()}')\n\ndf['city'] = df['city'].apply(get_nearest_city)\n\nprint(f'total unique cities in our dataset after normalization: {df.city.nunique()}')\n","f9bbac52":"#since there are multiple books inside an order, I have added another column 'order_size' \n#to track the number of books purchased per order.\n\ndef get_order_size(order):\n  return str(order).count('\/') + 1\n\ndf['order_size'] = df['book_name'].apply(get_order_size)","6ae88a9d":"#rows containing missing data\ndf[(df.apply(lambda x: sum(x.isnull().values), axis = 1)>0)]","96702124":"df = df.dropna()","89e8474c":"#Multiple books can be purchased in a single transaction. Counting rows with the same book_names would give us inaccurate results.\n#We need to extract all books from an order before counting.\n\ndef split_series(ser,sep):\n    return pd.Series(ser.str.cat(sep=sep).split(sep=sep)) \n\n\ndf2=(df.groupby(df.columns.drop('book_name').tolist()) #group by all but one column\n          ['book_name'] #select the column to be split\n          .apply(split_series,sep='\/') # split 'book_name' in each group\n         .reset_index(drop=True,level=-1).reset_index()) #remove extra index created\n","d4a4dd5a":"#visualizing the top 10 best selling books\nprint('Top 10 most selling books are')\n\ndf2[['book_name','city']].groupby(['book_name'])['city'].count().nlargest(10).plot.barh()","3d427338":"#printing top 10 best selling books\ndf2[['book_name','city']].groupby(['book_name'])['city'].count().nlargest(10)","45aec513":"#printing the best selling book title\nname = df2[['book_name','city']].groupby(['book_name'])['city'].count().idxmax()\ncopies_sold = df2[['book_name','city']].groupby(['book_name'])['city'].count().max()\n\nprint(f'{name} is the best selling book with {copies_sold} copies sold')","47f4d4e9":"#visualizing the order status frequency\nsns.countplot(x='order_status',data=df)","36ae1447":"#printing the order status frequencies in tabular form\ndf.order_status.value_counts()","0a668a29":"#adding a new column for weekday\ndf['weekday'] = pd.to_datetime(df['order_date']).dt.day_name()","2553b551":"#visualizing orders status per weekday\nplt.figure(figsize=(8,6))\nsns.countplot(x='weekday',hue='order_status',data=df,order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])","b9f90e23":"#For the time, I have rounded the all timestamps to their nearest hour\n#For example, 22:27:00 is rouned to 22:00:00 while 22:31:00 is rouned to 23:00:00\ndf['time'] = pd.to_datetime(df['order_date'].dt.round('60min')).dt.time","4f64878b":"plt.figure(figsize=(22,8))\ntemp = df.groupby(['order_status', 'time']).size().reset_index(name='count').sort_values('time')\nsns.barplot(x=\"time\",y='count' ,hue=\"order_status\", data=temp)","f630acd7":"#Orders received before 12pm\nimport datetime\nplt.figure(figsize=(12,8))\ntemp = df[df['time']<=datetime.time(12,0)].groupby(['order_status', 'time']).size().reset_index(name='count').sort_values('time')\nsns.barplot(x=\"time\",y='count' ,hue=\"order_status\", data=temp)","5a8c33c2":"#Orders received after 12pm\nplt.figure(figsize=(12,8))\ntemp = df[df['time']>=datetime.time(12,0)].groupby(['order_status', 'time']).size().reset_index(name='count').sort_values('time')\nsns.barplot(x=\"time\",y='count' ,hue=\"order_status\", data=temp)","0cf1f0d2":"#printing the orders received before and after 12pm\nbefore_12 = df[df['time'] <= datetime.time(12, 0)].groupby(['order_status', 'time']).size().reset_index(name='count')['count'].sum()\nafter_12 = df[df['time'] >= datetime.time(12, 0)].groupby(['order_status', 'time']).size().reset_index(name='count')['count'].sum()\nprint(f'orders received before 12pm: {before_12}')\nprint(f'orders received after 12pm: {after_12}')","3314a47a":"#visualizing top 15 cities with most orders\n\ntop_n_cities = 15\ncities = df.groupby(['city']).size().reset_index(name='count').sort_values('count',ascending=False)[:top_n_cities]['city'].values\n\ntemp = df[df['city'].isin(cities)].groupby(['city', 'order_status']).size().reset_index(name='count').sort_values('city')\n\nplt.figure(figsize=(18,8))\nsns.barplot(x=\"city\",y='count' ,hue=\"order_status\", data=temp)","39af3081":"#cities whose citizens returned orders the most\nmost_returned = df[df['order_status']=='returned'].groupby(['city','order_status']).size().reset_index(name='count').sort_values('count',ascending=False).head(10)\nplt.figure(figsize=(18,8))\nsns.barplot(x=\"city\",y='count' ,hue=\"order_status\", data=most_returned)","9ad9fe14":"#cities whose citizens canceled orders the most\nmost_returned = df[df['order_status']=='canceled'].groupby(['city','order_status']).size().reset_index(name='count').sort_values('count',ascending=False).head(10)\nplt.figure(figsize=(18,8))\nsns.barplot(x=\"city\",y='count' ,hue=\"order_status\", data=most_returned)","d03b6ccd":"#The only way to test this hypothesis is to provide evidence from data\n#Recap: order_size indicates how many books were purchased in a single order\ndf.groupby(['order_size', 'order_status']).size().reset_index(name='count')","1b459f08":"#TODO\n# Improve the previous sections\n# Sales forcasting ","ae25b048":"### Orders Per Hour","c9269ed4":"The visualization shows that more orders were received after 12pm than before 12pm\n","ef2b1652":"# Exploratory Data Analysis (EDA)","ee515a51":"## Which is the best-selling book?","6074c1af":"## Exploring Order Status","217bc787":"### Does a Large Order Size Indicate Fraud?\n","6dd78e28":"There were more than 3500 unique billing addresses after case conversion. Now, there are only 1800 which is a significant improvement. ","57d6da81":"### Orders Per Weekday","2d742495":"# Data Cleaning and Normalization\nThis dataset comprises more than 19,000 orders. Before the data analysis part,the following columns should be normalized\n  - Billing City \n  - Book Name\n\nThe Billing City column does not follow a strict schema for addresses. Some records only have a city name in their respective 'Billing City' fields while others possess a street address.\n\nIf multiple books were purchased in a single order, they are recorded as a single string separated by a slash **\/**. All books inside an order should be taken into account before reporting the best selling books.","92534c99":"# Loading The Data and Displaying Random Records","57636b46":"### Orders Per City","94b709d4":"The data speaks against the hypothesis \ud83d\ude03 ","0404461b":"The above visualization indicates that more orders are received on weekends than on weekdays","0af87c8c":"## Dropping Rows With Missing Data","5a832a31":"This shows that more orders are received on weekends and the frequency of orders is much higher on the second part of the day.The number of orders returned or canceled vary *directly* with the total number of orders received during an hour\n"}}