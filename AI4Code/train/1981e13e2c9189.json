{"cell_type":{"d90fb00c":"code","481fe897":"code","62f8f425":"code","e195d7cd":"code","9158371b":"code","96a0a34b":"code","a41c276f":"code","2c21c2a4":"code","dd7d653e":"code","b5c45428":"code","ef445e9f":"code","97305e9a":"code","d4d0a92a":"code","f00cffa9":"code","a7ee10cf":"code","44e4457e":"code","61db899b":"code","4e26cc27":"code","8d65e544":"code","65a9cc17":"code","b4880ffd":"code","5fde39a5":"code","9e11f425":"code","c7f6663d":"code","72e944c0":"code","748de231":"code","848d7673":"code","82395221":"code","3d310307":"code","d70c86bb":"code","bc946c62":"markdown","4c1fd1aa":"markdown","f23dca07":"markdown","fcddd901":"markdown","dbb7002c":"markdown","3fcb3b98":"markdown","c558d11d":"markdown","1df7a02d":"markdown","dd8aa437":"markdown","9fd61c7a":"markdown","bb2d71d4":"markdown","b4b3333c":"markdown","c70554f3":"markdown","d76118d1":"markdown","44d2db39":"markdown","9a244095":"markdown","3b2bea01":"markdown","5e61a11e":"markdown","dd722b98":"markdown","539e08b3":"markdown","72260be6":"markdown","9dc8c2b4":"markdown","61965ec8":"markdown","d4f9f499":"markdown","055012df":"markdown","22a46d70":"markdown","e93dcb57":"markdown","118f7252":"markdown","d9e5049d":"markdown","e2f91d29":"markdown","fb9d40d8":"markdown","c8df887f":"markdown","f6b16463":"markdown","6ac8b17d":"markdown","e509224d":"markdown"},"source":{"d90fb00c":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n\n# Import Bokeh \nfrom bokeh.plotting import figure, show, output_notebook , ColumnDataSource\nfrom bokeh.tile_providers import get_provider\nfrom bokeh.models import CategoricalColorMapper\nfrom ast import literal_eval\n\n# Matplot\nimport matplotlib.pyplot as plt\n\n# Set seaborn\nsns.set()","481fe897":"# Read the CSV file\n# Download the CVS data from: https:\/\/information.stpaul.gov\/Public-Safety\/Traffic-Stop-Dataset\/kkd6-vvns\n# Read data and set the date-time index using 'DATE OF STOP' of the CSV column.\n\n\nfilename = '..\/input\/Traffic_Stop_Dataset.csv'\n\ndf = pd.read_csv(filename, index_col='DATE OF STOP', parse_dates=True)\n\n\n# Data quick summary\nprint(df.info())\nprint(\"\\n\")","62f8f425":"df.head()","e195d7cd":"# Group each column and learn about the different labels\nprint(df.groupby('RACE OF DRIVER')['RACE OF DRIVER'].count())\nprint(\"\\n\")\nprint(df.groupby('GENDER OF DRIVER')['GENDER OF DRIVER'].count())\nprint(\"\\n\")\nprint(df.groupby('DRIVER SEARCHED?')['DRIVER SEARCHED?'].count())\nprint(\"\\n\")\nprint(df.groupby('VEHICLE SEARCHED?')['VEHICLE SEARCHED?'].count())\nprint(\"\\n\")\nprint(df.groupby('CITATION ISSUED?')['CITATION ISSUED?'].count())","9158371b":"# Lets rename the index name.\ndf = df.rename_axis('stop_datetime')\n\n# Rename the name of the features so that it is easier to call later on\n# Note: driver search is sometimes know as 'stop and frisk' and we will use this name \n# to mean that frisk was performed on the dirver\ndf = df.rename(columns={'YEAR OF STOP': 'year', 'RACE OF DRIVER':'driver_race', 'GENDER OF DRIVER': 'driver_gender',\n                   'DRIVER SEARCHED?': 'frisk_performed','VEHICLE SEARCHED?': 'vehicle_searched',\n                   'CITATION ISSUED?': 'citation_issued','AGE OF DRIVER': 'driver_age', \n                   'REASON FOR STOP': 'reason_for_stop', 'POLICE GRID NUMBER': 'police_grid_number',\n                  'LOCATION OF STOP BY POLICE GRID': 'location', 'COUNT': 'count','DATE OF STOP': 'stop_datetime'})\n\n\n\nprint(df.info())","96a0a34b":"# First lets count the number of NaN values\nprint(df.isnull().values.sum())\n# This will print 629438 null values properly labeled as 'NaN'\n\n# Replace the 'No Data' label with the proper 'NaN' label\ndf = df.replace(to_replace='No Data', value=np.nan)\n\nprint(df.isnull().values.sum())\n# Now we have 1748254\n\n# print summary again\nprint(df.info())","a41c276f":"# change object data types to category\nfor col in df.columns.values:\n    if df[col].dtypes == 'object':\n        df[col] = df[col].astype('category')\n\nprint(df.info())","2c21c2a4":"# The location column has '(lat, long)' values and we will need to extract these values\n# Instead of the whole dataset, lets visualize some sample. \n# please see the fulling coloring or the map: \n#       https:\/\/information.stpaul.gov\/Public-Safety\/Traffic-Stop-Dataset\/kkd6-vvns\n# For district numbers please see: \n#       https:\/\/information.stpaul.gov\/Public-Safety\/Saint-Paul-Police-Grid-Shapefile\/ykwt-ie3e\nnew_data = df.sample(n=600000, random_state=1).dropna()\n\n\n# Note: we need to extract the latitude and longitude coordinates to X and Y and convert them\n# so that bokeh undertands where to place them.\ndef coord_extract(coord):\n    coordinates = literal_eval(coord)\n    \n    lat = coordinates[0]\n    long = coordinates[1]\n    \n    r_major = 6378137.000\n    \n    x_cord = r_major * np.radians(long)\n    scale = x_cord\/ long\n    y_cord =  180.0\/np.pi * np.log(np.tan(np.pi\/4.0 + lat * (np.pi\/180.0)\/2.0)) * scale\n    \n    return (x_cord, y_cord)\n\n\n\n# Get the coordinates \nnew_data['x_cord'] = new_data['location'].apply(lambda x: coord_extract(x)[0])\nnew_data['y_cord'] = new_data['location'].apply(lambda x: coord_extract(x)[1])","dd7d653e":"# Conver dataframe to a ColumnDataSource\nsource = ColumnDataSource(new_data)\n\n# Make a CategoricalColorMapper object: color_mapper\ncolor_mapper = CategoricalColorMapper(factors=['Asian', 'Black', 'Latino','Native American', 'Other', 'White'],\n                                      palette=['purple', 'red', 'green', 'orange', 'black', 'blue'])\n\np = figure(width=600, height=700, x_range=(new_data['x_cord'].min(), new_data['x_cord'].max()), \n           y_range=(new_data['y_cord'].min(), new_data['y_cord'].max()))\n\np.add_tile(get_provider('CARTODBPOSITRON'))\n\np.circle(x = 'x_cord', y = 'y_cord', source=source, color=dict(field='driver_race', transform=color_mapper),\n            legend='driver_race', size=15.0, fill_alpha=0.01)\n\np.legend.location = \"bottom_center\"\n\noutput_notebook()\nshow(p)","b5c45428":"# Lets now visualize annual 'citation', 'frisk' and 'search conducted' rates from 2001 to 2018\n# copy the original data\npolice_stops = df.copy()\n\n# drop raws with null values of the three features\npolice_stops = police_stops.dropna(subset=['frisk_performed','vehicle_searched','citation_issued'])\n\n# Create boolean column for each (Note: we can do maping as well:  {'Yes': True, 'No': False})\npolice_stops['bool_frisk_performed'] = police_stops['frisk_performed'] == 'Yes'\npolice_stops['bool_vehicle_searched'] = police_stops['vehicle_searched'] == 'Yes'\npolice_stops['bool_citation_issued'] = police_stops['citation_issued'] == 'Yes'\n\n\n\nannual_rates_new = police_stops.groupby(police_stops.index.year)['bool_frisk_performed','bool_vehicle_searched', \n                                                           'bool_citation_issued'].mean()\n\n\nannual_rates_new.plot(figsize=(20, 10), fontsize=16)\n\nplt.xlabel('Year', fontsize=18)\nplt.ylabel('Count', fontsize=18)\nplt.legend(['Frisk Rate', 'Vehicle Search Rate', 'Citation Rate'], fontsize=18)\n\nplt.show()","ef445e9f":"# hourly rates: How does frisk, search and citation rates look like throughout a day?\nhourly_rates = police_stops.groupby(police_stops.index.hour)['bool_frisk_performed','bool_vehicle_searched', \n                                                           'bool_citation_issued'].mean()\nsns.set()\nhourly_rates.plot(figsize=(20, 10), fontsize=16)\n\nplt.xlabel('Time (hour)', fontsize=18)\nplt.ylabel('Rate', fontsize=18)\nplt.legend(['Frisk Rate', 'Vehicle Search Rate', 'Citation Rate'], fontsize=18)\n\nplt.show()","97305e9a":"# Daily rate:\ndaily_rates = police_stops.groupby(police_stops.index.weekday_name)['bool_frisk_performed','bool_vehicle_searched', \n                                                           'bool_citation_issued'].mean()\nsns.set()\ndaily_rates.plot(kind='bar',  figsize=(20, 10), fontsize=16, rot=0)\nplt.xlabel('Day of the week', fontsize=18)\nplt.ylabel('Rate', fontsize=18)\nplt.legend(['Frisk Rate', 'Vehicle Search Rate', 'Citation Rate'], fontsize=14)\nplt.show()","d4d0a92a":"rates_by_gender = police_stops.groupby('driver_gender')['bool_frisk_performed','bool_vehicle_searched', \n                                                           'bool_citation_issued'].mean()\nrates_by_gender.plot(kind='bar', figsize=(20, 10), fontsize=18, rot=0)\n\nplt.xlabel('Driver\\'s gender', fontsize=18)\nplt.ylabel('Rate', fontsize=18)\nplt.legend(['Frisk Rate', 'Vehicle Search Rate', 'Citation Rate'], fontsize=18)\n\nplt.show()","f00cffa9":"# Frisk, search and citation rates by race\nrates_by_race = police_stops.groupby('driver_race')['bool_frisk_performed',\n                                                    'bool_vehicle_searched', \n                                                    'bool_citation_issued'].mean().sort_values('bool_citation_issued', \n                                                                                                      ascending=False)\nrates_by_race.plot(kind='bar', figsize=(20, 10), fontsize=16, rot=0)\n\nplt.xlabel('Subject Race', fontsize=18)\nplt.ylabel('Rate', fontsize=18)\nplt.legend(['Frisk Rate', 'Vehicle Search Rate', 'Citation Rate'], fontsize=18)\n\nplt.show()","a7ee10cf":"\nrates_by_reason = police_stops.groupby('reason_for_stop')['bool_frisk_performed',\n                                                    'bool_vehicle_searched', \n                                                    'bool_citation_issued'].mean().sort_values('bool_citation_issued', \n                                                                                                      ascending=False)\n\nrates_by_reason.plot(kind='bar', figsize=(20, 10), fontsize=16, rot=0)\n\nplt.xlabel('Subject Race', fontsize=18)\nplt.ylabel('Rate', fontsize=18)\nplt.legend(['Frisk Rate', 'Vehicle Search Rate', 'Citation Rate'], fontsize=18)\n\nplt.show()","44e4457e":"# lets get all the missing values for each feature\n\n# lets first calculate the % of missing labels for each feature\nlabels = []\npercent = []\n\nfor col in df.columns.values:\n    labels.append(col)\n    non_missing = df.isnull().sum()[col] * 100\n    total = df.isnull().sum()[col] + df[col].count()\n    percent.append(non_missing \/ total)\n\n\nlabels = pd.DataFrame(labels, columns=['Features'])\npercent = pd.DataFrame(percent, columns=['Missing'])\n\n\nmissing_data = pd.concat([labels, percent], axis=1)\nmissing_data = missing_data[missing_data.Missing > 0].sort_values(by='Missing', ascending=False)\nmissing_data = missing_data.set_index(missing_data.Features)\nmissing_data.plot(kind='bar', figsize=(20, 10), fontsize=16, rot=0)\n\nplt.xlabel('Featurs', fontsize=18)\nplt.ylabel('Missing labels (%)', fontsize=18)\nplt.title('% missing labels for each feature', fontsize=18)\nplt.legend(['Missing (%)'], fontsize=18)\nprint(missing_data)","61db899b":"print(df.groupby(['year','reason_for_stop'])['reason_for_stop'].count())","4e26cc27":"# Final Dataset using the 2017 and 2018 traffic stops\ntemp = police_stops[['year','driver_race','driver_gender','driver_age','reason_for_stop','police_grid_number',\n                    'bool_frisk_performed', 'bool_vehicle_searched','bool_citation_issued']]\n\nfinal_dataset = temp[(temp.year == 2017) | (temp.year == 2018)].copy()\n\n# For categorical labels we can use the median to replace NaN values \nfinal_dataset.police_grid_number.fillna(final_dataset['police_grid_number'].value_counts().index[0], inplace=True)\n\n# For driver's age, replace with the mean age\nfinal_dataset.driver_age.fillna(final_dataset.driver_age.mean(), inplace=True)\n\nprint(final_dataset.isnull().values.sum())","8d65e544":"final_dataset.info()","65a9cc17":"# Lets use a label Encoder to convert categorical variables to numeric.\n# The numerical labels are always between 0 and n_categories-1.\n# Import LabelEncoder\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Instantiate LabelEncoder\nle = LabelEncoder()\n\nx_values = final_dataset[['year','driver_race','driver_gender','driver_age','reason_for_stop','police_grid_number',\n                    'bool_frisk_performed', 'bool_vehicle_searched']].copy()\ny_values = final_dataset['bool_citation_issued'].astype('int').copy()\n\nfor col in x_values.columns.values:\n    if x_values[col].dtype.name == 'category':\n        x_values[col] = le.fit_transform(x_values[col])\n\n","b4880ffd":"x_values.head()","5fde39a5":"# Logistic regression\nfrom sklearn.linear_model import LogisticRegression\n# Import train_test_split\nfrom sklearn.model_selection import train_test_split\n# Import confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n\n# Create a report for each model\nfrom sklearn.metrics import classification_report\n\n# Instantiate a LogisticRegression classifier with default parameter values\nlogreg = LogisticRegression()\n\n\nX = x_values.values\ny = y_values.values\n\n# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                y,\n                                test_size=0.3,\n                                random_state=42)\n# Fit logreg to the train set\nlogreg.fit(X_train, y_train)\n\n# Use logreg to predict instances from the test set and store it\ny_pred = logreg.predict(X_test)\n\n# Calculate and print classification results\ncfm = confusion_matrix(y_test, y_pred)\nreports = classification_report(y_test, y_pred)\nprint(\"Confusion Matrix: \")\nprint(cfm)\nprint(\"\\n\")\nprint(reports)","9e11f425":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\nplt.show()","c7f6663d":"x_values = final_dataset[['year','driver_race','driver_gender','driver_age','reason_for_stop','police_grid_number',\n                    'bool_frisk_performed', 'bool_vehicle_searched']].copy()\ny_values = final_dataset['bool_citation_issued'].astype('int').copy()\n\nx_values = pd.get_dummies(x_values, columns=['police_grid_number'], prefix = ['police_grid_number'], drop_first=True)\nfor col in x_values.columns.values:\n    if x_values[col].dtype.name == 'category':\n        x_values = pd.get_dummies(x_values, columns=[col], prefix = [col], drop_first=True)","72e944c0":"x_values.head()","748de231":"\n# Re-apply the logistic model\n# Instantiate a LogisticRegression classifier with default parameter values\nlogreg = LogisticRegression()\n\n\nX = x_values.values\ny = y_values.values\n\n# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                y,\n                                test_size=0.3,\n                                random_state=42)\n# Fit logreg to the train set\nlogreg.fit(X_train, y_train)\n\n# Use logreg to predict instances from the test set and store it\ny_pred = logreg.predict(X_test)\n\n# Calculate and print classification results\ncfm = confusion_matrix(y_test, y_pred)\nreports = classification_report(y_test, y_pred)\nprint(\"Confusion Matrix: \")\nprint(cfm)\nprint(\"\\n\")\nprint(reports)\n\n\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\nplt.show()","848d7673":"# Import models, including VotingClassifier meta-model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN \nfrom sklearn.ensemble import VotingClassifier\n\n\n# Split data into 70% train and 30% test\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                y,\n                                test_size=0.3,\n                                random_state=42)","82395221":"# Set seed for reproducibility\nSEED=1\n\n# Instantiate lr\nlr = LogisticRegression(random_state=SEED)\n\n# Instantiate knn\nknn = KNN(n_neighbors=2)\n\n# Instantiate dt\ndt = DecisionTreeClassifier(criterion='gini', random_state=SEED)\n\n# Define the list classifiers\nclassifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]","3d310307":"from sklearn.metrics import accuracy_score\n\n# Before applying the VotingClassifier, let's first run each model and compare.\nfor clf_name, clf in classifiers:    \n \n    # Fit clf to the training set\n    clf.fit(X_train, y_train)    \n   \n    # Predict y_pred\n    y_pred = clf.predict(X_test)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_test, y_pred) \n    cfm = confusion_matrix(y_test, y_pred)\n    reports = classification_report(y_test, y_pred)\n    # Evaluate clf's accuracy on the test set\n    print('{:s} reports:'.format(clf_name))\n    # Print the confusion matrix of the logreg model\n    print(\"Confusion Matrix: \")\n    print(cfm)\n    print(\"\\n\")\n    print(reports)\n    print(\"\\n\")\n    \n    \n    y_pred_prob = clf.predict_proba(X_test)[:,1]\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr, tpr, label='Logistic Regression')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(\"{:s} AUC: {}\".format(clf_name, roc_auc_score(y_test, y_pred_prob)))\n    plt.show()","d70c86bb":"# Instantiate a VotingClassifier vc\nvc = VotingClassifier (estimators=classifiers)     \n\n# Fit vc to the training set\nvc.fit(X_train, y_train)   \n\n# Evaluate the test set predictions\ny_pred = vc.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\ncfm = confusion_matrix(y_test, y_pred)\nreports = classification_report(y_test, y_pred)\nprint('Voting Classifier: {:.3f}'.format(accuracy))\nprint(cfm)\nprint(\"\\n\")\nprint(reports)","bc946c62":"Let\u2019s encode object datatypes to category to speed up our code better. We won't be using the 'location' column in our models but for initial visualization of districts.","4c1fd1aa":"## Objective","f23dca07":"The one-hot encoder method to change categorical features to numerical values has improved the logistic regression model. Accuracy increased from 68% to 73%, the F1 score for class 0 also increased from 56% to 69%. As shown, the AUC has increased from 72% to about 80%.","fcddd901":"The purpose of this analysis arises from a conversation with a couple of friends living in the twin cities and we wanted to see if there are factual patterns in policing around gender \/ race and whether those patters are changing overtime. As a black man, someone who went to college and graduate school in St. Paul as well as living in the twin cities, I have never had an issue with caps and perhaps my experience is nothing new. But what does the data tell us? \n\nHere is how this project is organized:\n* Understand the raw data: exploratory data analysis (this will continue throughout the project)\n* Data transformation: Are there missing values? \n* Develop questions\n* Generate and apply machine learning models\n* Evaluate the models","dbb7002c":"### Model performance evaluation\nThe logistic regression model has an accuracy of 68%. However, our model does very well for class 1 but suffers a low recall and F1 score for class 0. ","3fcb3b98":"<p> As we can see, some features have 'No Data' label indicating a missing data. All these issues can be fixed with some preprocessing.<\/p>","c558d11d":"<p>The citation rate of more than 48% of traffic stops for 'other' label is extraordinary, in fact it is more than double the next highest citation rate (citation rates for black drivers with about 20.3%). Note that there are 3503 rows labeled in the entire dataset.<\/p>\n<p>Frisk and vehicle search rates are much higher for black and latino driver traffic stops.<\/p>","1df7a02d":"# Handling missing labels","dd8aa437":"From the three models, decision tree classifier performs better with 89% accuracy and 0.94 area under the curve. This perhaps is not surprising since KNN performs better for continues values.\n\nFinally, we apply the VotingClassifier to select the best model.","9fd61c7a":"Instead of using a single model, lets combine different models on the same dataset, let each model make its predictions and then chose the best performing model. ","bb2d71d4":"<p>As we can see from our first glance at the data, the dataset has a mixture of numerical and non-numerical features.  The features with '?' in the column are boolean, and all column names are in capital letters and have spaces between words. The data also contains missing labels.<\/p>","b4b3333c":"### Logistic Regression\n<p>Since our target variable is binary, we can use logistic regression to predict if citation is issued for a traffic stop.<\/p>","c70554f3":"<p>Replacing missing labels with the most common value for 'reason_for_stop' would lead to unbalanced data which would create a situation where supervised classifier needs to classify on labels it hasn't seen. A more complex method, and perhaps accurate method, would be to use association rules to estimate the missing values. Association rules look at the different combinations of values that each of the rows can take and then provides a method for determining the most likely or least likely state. This method can be applied to 'reason_for_stop' and 'driver_age'.<\/p>\n<p>Another option is to drop the two columns entirely, but this would lead to losing an important feature to our model.<\/p>\n<p>However, for the final version of our dataset, we will only look at the 2017 and 2018 part of the dataset, then we will replace missing labels using mean and median as needed.<\/p>","d76118d1":"St. Paul, MN has various data sources as part of the open data initiative of the state. The <a href=\"https:\/\/information.stpaul.gov\/Public-Safety\/Traffic-Stop-Dataset\/kkd6-vvns\" target=\"_blank\">traffic stop police<\/a>  reports dataset contains more than 700 thousands rows and in compasses reports from year 2001 to 2018. \n\n<a href=\"https:\/\/openpolicing.stanford.edu\/\" target=\"_blank\">The Stanford Open Policing Project<\/a> has reach datasets for various cities across the country including St. Paul, MN. In this project, we aim to analyze this data using Pandas, Numpy, Bokeh and sklearn.\n\nI went to college in St. Paul and lived in the twin cities for 6 years after college, and hence the interest in the data.","44d2db39":"### Frisk, citation and vehicle search by driver race","9a244095":"# Read the CSV file","3b2bea01":"# Traffic police stops in St. Paul, MN (2001 - 2018)","5e61a11e":"Citation rates are much higher (more than 18%) on Mondays than any other day during the week. Frisk and vehicle searches rates increase over the weekend and on Mondays than any other days of the week.","dd722b98":"# Exploratory Analysis and Data Transformations\n\n### Visualize location","539e08b3":"### Frisk, vehicle searched and citation rate trends over the years\nBefore we are visualizing and learn about interesting features about our data, let's drop null values for frisk, vehicle search and citation issued. Our data is large enough and dropping rows with the null values of the three features doesn't change the non-null labels of the other features.","72260be6":"# Data clean up and preprocessing","9dc8c2b4":"<p>We can see that the majority traffic stops for white drivers tend to be in West St. Paul while downtown and north St. Paul are dominated with black drivers. \nPlease click <a href=\"https:\/\/www.stpaul.gov\/sites\/default\/files\/Media%20Root\/Police\/2018%20Traffic%20Stops.pdf\" target=\"_blank\"> here <\/a> to see larger image <\/p>","61965ec8":"### Does the time of the day affect frisk and Vehicle search?","d4f9f499":"Label encoding is pretty much intuitive and straight-forward and the model gives good performance from the learning algorithm, but it has as disadvantage that the numerical values can be misinterpreted by the algorithm. To solve this issue, let's use one-hot encoder","055012df":"Frisk and Vehicle search rates are much higher at night and in the evenings than during the day. Citation rate actually goes from around 13.7 around 7:00 AM to about 19.7% from 8:00 AM to 6:00 PM. \nHow do 'citation', 'frisk' and 'Vehicle search' change for each day of the week?","22a46d70":"### Frisk, citation and vehicle search by gender","e93dcb57":"<p>As shown above in the exploratory analysis, not all frisk and vehicle searches lead to a citation. Hence:\n<\/p>\n* Is there a correlation between 'year', 'driver_race','driver_gender','driver_age','reason_for_stop','police_grid_number', frisk, and vehicle search features and citation? Can we use these features to predict if a person is issued citation?","118f7252":"## Ensemble the Models\n","d9e5049d":"There is a clear increase with rate of annual traffic citations from 2001 to 2018. In fact, the rate citation increases from less than 10% of all traffic stops to more than 50% between 2016 and 2017. Frisk and search conducted show an overall decline especially since 2007.","e2f91d29":"### Reasons for Traffic Stop\n<p>Do frisk, vehicle search and citation rates change by the reason of the traffic stop?<\/p>","fb9d40d8":"# Develop Research Questions","c8df887f":"<p>911 call\/ citizen reported, and investigative stops lead to much higher frisk and vehicle search rates. Citation rates, perhaps not surprising, are much higher for moving violations.<\/p>","f6b16463":"Women receive more tickets \/ citation than men (17.5% vs 16.5%). However, the rate of frisk and vehicle search for men are more than 3 times women.","6ac8b17d":"<p>As shown in the bar graph, more than 90% of  'reason_for_stop' and 80% of 'driver_age' labels are missing. In fact, the labels for 'reason_for_stop' feature are all missing but for the years 2017 and 2018 as can been below. <\/p> ","e509224d":"### Do the  frisk, citation and vehicle search changes in the week days?"}}