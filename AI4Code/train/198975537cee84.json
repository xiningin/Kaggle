{"cell_type":{"01b86202":"code","b05bd4d4":"code","f117609a":"code","5830dad0":"code","2567962c":"code","b31e8560":"code","05843d3b":"code","ddceb1b4":"code","dd710106":"code","61194e93":"code","6b4c4c72":"code","1af01a42":"code","da3f6393":"code","86b77926":"code","d1d846b1":"code","b4c49a75":"code","f9a82c27":"code","c8c48dd2":"code","53960417":"code","67d08fae":"code","814abd80":"code","b3eff725":"code","f42271c3":"code","7b6d8c4d":"code","55676711":"code","266ffa8d":"code","802f7f06":"code","ed5ac683":"markdown","305eff90":"markdown"},"source":{"01b86202":"!git clone https:\/\/github.com\/AlexeyAB\/darknet","b05bd4d4":"ls","f117609a":"cd darknet\/","5830dad0":"ls","2567962c":"!make","b31e8560":"!wget https:\/\/github.com\/AlexeyAB\/darknet\/releases\/download\/darknet_yolo_v3_optimal\/yolov4.weights","05843d3b":"ls","ddceb1b4":"!.\/darknet detect cfg\/yolov4.cfg yolov4.weights data\/person.jpg","dd710106":"import cv2 \nimport matplotlib.pyplot as plt\ndef show_detect(path):\n  img=cv2.imread(path)\n  plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n  plt.axis('off')\n  fig=plt.gcf()\n  fig.set_size_inches(18,10) \n","61194e93":"show_detect('predictions.jpg')","6b4c4c72":"from google.colab import drive\ndrive.mount('\/content\/drive')","1af01a42":"ls","da3f6393":"!.\/darknet detector demo cfg\/coco.data cfg\/yolov4.cfg yolov4.weights -dont_show \/content\/video_street.mp4 -i 0 -out_filename \/content\/sample_data\/video_street_results.avi","86b77926":"import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nfrom google.colab.patches import cv2_imshow\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  Conv2D ,MaxPool2D,Flatten,Dense,BatchNormalization,Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","d1d846b1":"from google.colab import drive\ndrive.mount('\/content\/drive')","b4c49a75":"import zipfile\npath='\/content\/drive\/MyDrive\/computer vision\/Computer Vision Masterclass\/Datasets\/fer_images.zip'\nzip_o=zipfile.ZipFile(file=path,mode='r')\nzip_o.extractall('.\/')\nzip_o.close()","f9a82c27":"train_gen=ImageDataGenerator(rescale=1.\/255,\n                                 rotation_range=7,\n                                 horizontal_flip=True,\n                                 zoom_range=0.2)","c8c48dd2":"train_data=train_gen.flow_from_directory('\/content\/fer2013\/train',\n                                         target_size=(48,48),\n                                         batch_size=16,\n                                         class_mode=\"categorical\",\n                                         shuffle=True)","53960417":"np.unique(train_data.classes,return_counts=True)","67d08fae":"train_data.class_indices","814abd80":"test_gen=ImageDataGenerator(rescale=1.\/255)\ntest_data=test_gen.flow_from_directory('\/content\/fer2013\/validation',\n                             target_size=(48,48),batch_size=1,\n                             class_mode=\"categorical\",\n                             shuffle=False)","b3eff725":"detectors=32\nwidth,height=48,48\nclasses=7\nepochs=100\n\nnetwork=Sequential()\nnetwork.add(Conv2D(detectors,kernel_size=(3,3),padding='same',activation='relu',input_shape=(width,height,3)))\nnetwork.add(BatchNormalization())\nnetwork.add(Conv2D(detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(BatchNormalization())\nnetwork.add(MaxPool2D(pool_size=(2,2)))\nnetwork.add(Dropout(0.2))\n\n\nnetwork.add(Conv2D(2*detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(BatchNormalization())\nnetwork.add(Conv2D(2*detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(Conv2D(2*detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(MaxPool2D(pool_size=(2,2)))\nnetwork.add(Dropout(0.2))\n\nnetwork.add(Conv2D(2*2*detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(BatchNormalization())\nnetwork.add(Conv2D(2*2*detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(Conv2D(2*2*detectors,(3,3),activation='relu',padding='same'))\nnetwork.add(MaxPool2D(pool_size=(2,2)))\nnetwork.add(Dropout(0.2))\n\nnetwork.add(Flatten())\nnetwork.add(Dense(2*detectors,activation='relu'))\nnetwork.add(BatchNormalization())\nnetwork.add(Dropout(0.2))\n\n\nnetwork.add(Dense(classes,activation='softmax'))\n\nnetwork.summary()\n","f42271c3":"network.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])","7b6d8c4d":"network.fit(train_data,epochs=5)","55676711":"with open('\/content\/drive\/MyDrive\/computer vision\/Computer Vision Masterclass\/Weights\/network_emotions.json','r') as json_file:\n  json_saved_model=json_file.read()\njson_saved_model","266ffa8d":"network_loaded=tf.keras.models.model_from_json(json_saved_model)\nnetwork_loaded.load_weights('\/content\/drive\/MyDrive\/computer vision\/Computer Vision Masterclass\/Weights\/weights_emotions.hdf5')\nnetwork_loaded.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=[\"accuracys\"])","802f7f06":"network_loaded.summary()","ed5ac683":"compile the library","305eff90":"Downlaod YOLO weights"}}