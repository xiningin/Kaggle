{"cell_type":{"79609e23":"code","48e4b345":"code","e18757df":"code","a57edd34":"code","cb51fec0":"code","56296b6b":"code","c5b06cc6":"code","3500ae48":"code","8a4c2ee3":"code","d747f864":"code","772f8104":"code","511efb2e":"code","6777e9c2":"code","eb84460b":"code","b28dd085":"code","851fb752":"code","ebef124f":"code","d3385b31":"code","cb201f0c":"code","d8bc681b":"code","bb7a1ee0":"code","8eee1196":"code","29def731":"code","a1ff07ae":"code","baa01781":"code","a2c3b7dc":"code","c2c5c3fc":"code","77ffc0cd":"code","4c05955f":"code","c07bcbbb":"markdown","12d7403a":"markdown","600c16ac":"markdown","3e84730c":"markdown","3ed146bc":"markdown"},"source":{"79609e23":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom os import *\nimport os, cv2, random\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","48e4b345":"from keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\nimport numpy as np\nfrom keras.datasets import mnist\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n%matplotlib inline \n\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import np_utils\n\nfrom keras import backend as K","e18757df":"model = ResNet50(weights='imagenet')","a57edd34":"from keras.applications.vgg16 import VGG16\nmodel_vgg16 = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n#model_vgg16.summary()","cb51fec0":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    img =cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img=cv2.cvtColor(file, cv2.COLOR_BGR2RGB)\n\n    return np.array(img).reshape((3,224,224))\n\n\ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, ROWS, COLS,CHANNELS), dtype=np.uint8)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image.T\n        if i%250 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return data","56296b6b":"TRAIN_DIR = \"..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/\"\nTEST_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/test\/'\nROWS = 224\nCOLS = 224\nCHANNELS = 3\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntrain_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog.' in i]\ntrain_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat.' in i]\n\ntest_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n\n# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\ntrain_images = train_dogs[:10000] + train_cats[:10000]\nrandom.shuffle(train_images)\ntest_images =  test_images[:25] + train_dogs[-150:] + train_cats[-150:]\n\n","c5b06cc6":"len(test_images)","3500ae48":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    img =cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    return np.array(img).reshape((3,224,224))\n\n\ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, ROWS, COLS,CHANNELS), dtype=np.uint8)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image.T\n        if i%500 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return data\n\n\ntrain = prep_data(train_images)\ntest = prep_data(test_images)\n\nprint(\"Train shape: {}\".format(train.shape))\nprint(\"Test shape: {}\".format(test.shape))","8a4c2ee3":"labels = []\nfor i in train_images:\n    if 'dog.' in i:\n        labels.append(1)\n    else:\n        labels.append(0)\n\nsns.countplot(labels)\nplt.xticks(np.arange(2),['Dogs','Cats'])\nplt.title('Cats and Dogs')\nfrom keras.utils import to_categorical\nlabels = to_categorical(labels)","d747f864":"def show_cats_and_dogs(idx):\n    dog = read_image(train_dogs[idx])\n    dog = np.array(dog).reshape((224,224,3))\n\n    cat = read_image(train_cats[idx])\n    cat = np.array(cat).reshape((224,224,3))\n\n    pair = np.concatenate((cat, dog), axis=1)\n    plt.figure(figsize=(10,5))\n    plt.imshow(pair)\n    plt.show()\n    \nfor idx in range(0,2):\n    show_cats_and_dogs(idx)","772f8104":"model.summary()","511efb2e":"#Create a New Model based on ResNEt50 \ninput_shape = (224, 224, 3)\n\nK.set_learning_phase(1)\nbase_model = ResNet50(weights='imagenet', include_top=True, input_shape=input_shape)\nbase_model.layers.pop()\nbase_model.outputs = [base_model.layers[-1].output]\nbase_model.layers[-1].outbound_nodes = []\n\nx = base_model.layers[-1].output\n#x = Flatten(name='flatten')(x)\npredictions = Dense(2, activation='softmax', name='predictions')(x)\nmodel_01 = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in model.layers[0:111]:\n    layer.trainable = False\noptimizer = RMSprop(lr=1e-4)\nmodel_01.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","6777e9c2":"len(model_01.layers)","eb84460b":"#optimizer = RMSprop(lr=1e-4)\n#objective = 'binary_crossentropy'\n#model_01.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])","b28dd085":"nb_epoch = 15\nbatch_size = 50\n\n## Callback for loss logging per epoch\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.val_losses = []\n        \n    def on_epoch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')        \n        \ndef run_catdog():\n    \n    history = LossHistory()\n    model_01.fit(x=train, y=labels, batch_size=batch_size, nb_epoch=nb_epoch,\n              validation_split=0.25, verbose=0, shuffle=True, callbacks=[history, early_stopping])\n    \n\n    predictions = model_01.predict(test, verbose=0)\n    return predictions, history\n\npredictions, history = run_catdog()","851fb752":"loss = history.losses\nval_loss = history.val_losses\n\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('VGG-16 Loss Trend')\nplt.plot(loss, 'blue', label='Training Loss')\nplt.plot(val_loss, 'green', label='Validation Loss')\nplt.xticks(range(0,nb_epoch)[0::2])\nplt.legend()\nplt.show()","ebef124f":"for i in range(0,10):\n    if predictions[i, 0] >= 0.5: \n        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n    else: \n        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n     \n    x=np.array(test[i].T).reshape((224,224,3))\n    plt.imshow(x)\n    plt.show()","d3385b31":"import tensorflow as tf\nsess = tf.Session(config=tf.ConfigProto(log_device_placement=True))","cb201f0c":"model_01.weights","d8bc681b":"#print(os.listdir(\"..\/input\/dogs-vs-cats-redux-kernels-edition\/test\"))\npredictions","bb7a1ee0":"len(test)","8eee1196":"img_path = test_images[18]\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\n#x = test[0]\n\nx = np.expand_dims(x, axis=0)\n'''x = np.float32(x)\nprint(x.shape,\nx.dtype)'''\nx = preprocess_input(x)\n\npreds = model_01.predict(x)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nprint('Predicted:', (preds.shape))","29def731":"model.input","a1ff07ae":"def show_cats_and_dogs(idx):\n    dog = read_image(test_images[idx])\n    dog = np.array(dog).reshape((224,224,3))\n\n    plt.figure(figsize=(10,5))\n    plt.imshow(dog)\n    plt.show()\n    \nshow_cats_and_dogs(0)","baa01781":"img_path = '..\/input\/tets-resnet\/sasha.jpeg'\nimg = image.load_img(img_path, target_size=(224, 224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\npreds = model.predict(x)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nprint('Predicted:', decode_predictions(preds, top=3)[0])","a2c3b7dc":"model_vgg16","c2c5c3fc":"#Create a New Model based on VGG 16\ninput_shape = (224, 224, 3)\n\nK.set_learning_phase(1)\nbase_model = model_vgg16\nbase_model.layers.pop()\nbase_model.outputs = [base_model.layers[-1].output]\nbase_model.layers[-1].outbound_nodes = []\n\nx = base_model.layers[-1].output\n#x = Flatten(name='flatten')(x)\npredictions = Dense(2, activation='softmax', name='predictions')(x)\nmodel_02 = Model(inputs=base_model.input, outputs=predictions)\n\n#for layer in model.layers[0:111]:\n#    layer.trainable = False\noptimizer = RMSprop(lr=1e-4)\nmodel_02.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","77ffc0cd":"nb_epoch = 15\nbatch_size = 150\n\n## Callback for loss logging per epoch\nclass LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n        self.val_losses = []\n        \n    def on_epoch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')        \n        \ndef run_catdog():\n    \n    history = LossHistory()\n    model_02.fit(x=train, y=labels, batch_size=batch_size, nb_epoch=nb_epoch,\n              validation_split=0.25, verbose=0, shuffle=True, callbacks=[history, early_stopping])\n    \n\n    predictions = model_02.predict(test, verbose=0)\n    return predictions, history\n\npredictions, history = run_catdog()","4c05955f":"loss = history.losses\nval_loss = history.val_losses\n\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('VGG-16 Loss Trend')\nplt.plot(loss, 'blue', label='Training Loss')\nplt.plot(val_loss, 'green', label='Validation Loss')\nplt.xticks(range(0,nb_epoch)[0::2])\nplt.legend()\nplt.show()","c07bcbbb":"# Preprocessing Train and Test Data ","12d7403a":"## VGG 16","600c16ac":"# Finish Preprocessing Train and Test Data ","3e84730c":"a","3ed146bc":"**Generating the Labels**\n\nWe're dealing with a binary classification problem here - (1) dog (0) cat. The lables can be created by looping over the file names in the train directory. It's nice to see the training data is perfectly balanced."}}