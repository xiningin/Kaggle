{"cell_type":{"1b9c9065":"code","550aa896":"code","046c4e72":"code","2f27662e":"code","c8bfb641":"code","5fac64cd":"code","06c08bc8":"code","90cc75a7":"code","dc0daa80":"code","3da6c0b1":"code","5208c3bd":"code","2f9606b8":"code","69eeeb3f":"code","bc07ae35":"code","803fde9e":"code","838c02d4":"code","4639bf58":"code","b39cb6d5":"code","4183e8b4":"code","5ab0b2ea":"code","6ef0fe03":"code","e86ab37c":"code","c69014f4":"code","aa42bb85":"code","921b4a48":"code","479d84b4":"code","ea06be5e":"code","a4da2913":"code","cfa7b230":"code","6a890ccc":"code","c6a1dfe0":"code","3496e8b7":"code","46298f6b":"code","6fe56301":"code","5a571225":"markdown","d3fbacfe":"markdown","fc5a44bb":"markdown","192d21b2":"markdown","57024d63":"markdown","01f5806a":"markdown","288bbe5b":"markdown","4ca94af9":"markdown","2050d7af":"markdown","5f90a89e":"markdown","6cb3d768":"markdown","6c98b12b":"markdown","c6c0c5d1":"markdown","7b2ab5ca":"markdown","c3c09836":"markdown","bd2469fa":"markdown","22ff6201":"markdown","ac21da37":"markdown","2ab8a293":"markdown","a93f3e56":"markdown","426dc68e":"markdown","2b0f8079":"markdown","089176a1":"markdown","17befed4":"markdown","597c8945":"markdown"},"source":{"1b9c9065":"%config Completer.use_jedi = False\n\n# !pip install -Uqqq plotnine","550aa896":"import os\nimport shutil\n\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm.notebook import tqdm\n\nfrom plotnine import *","046c4e72":"files_train = os.listdir('\/kaggle\/input\/feedback-prize-2021\/train')\nprint(f'We have {len(files_train)} files in the train folder')","2f27662e":"df = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv')\nprint(f'We have {len(df)} rows in the train.csv file')","c8bfb641":"import spacy\n\nclass Labeler():\n    ## adapted from https:\/\/www.kaggle.com\/odins0n\/feedback-prize-eda\n    def __init__(self):\n        self.df = pd.read_csv('\/kaggle\/input\/feedback-prize-2021\/train.csv').set_index('id')\n        colors = {'Lead': '#EE11D0',\n                  'Position': '#AB4DE1',\n                  'Claim': '#1EDE71',\n                  'Evidence': '#33FAFA',\n                  'Counterclaim': '#4253C1',\n                  'Concluding Statement': 'yellow',\n                  'Rebuttal': 'red'}\n        self.options = {\"ents\": list(colors.keys()), \"colors\": colors}\n    def __call__(self, idx, truncate = None):\n        ents = []\n        for i, row in self.df.loc[idx].iterrows():\n            start = int(row['discourse_start'])\n            end = int(row['discourse_end'])\n            label = row['discourse_type']\n            if truncate is not None:\n                if start < truncate:\n                    ents.append({\n                        'start': start,\n                        'end': min(end, truncate), \n                        'label': label\n                    })\n            else:\n                ents.append({\n                    'start': start,\n                    'end': end, \n                    'label': label\n                })\n        txt_file = f'\/kaggle\/input\/feedback-prize-2021\/train\/{idx}.txt'\n        with open(txt_file, 'r') as file: text_data = file.read()\n        if truncate is not None:\n            text_data = text_data[:truncate] + ' [...]'\n        doc = {\n            \"text\": text_data,\n            \"ents\": ents,\n        }\n\n        spacy.displacy.render(doc, style=\"ent\", options=self.options, manual=True, jupyter=True);\n        \nlabeler = Labeler()","5fac64cd":"labeler('0000D23A521A')","06c08bc8":"label_ordered_list = df['discourse_type'].value_counts().index.tolist()[::-1]\n\n(ggplot(df, aes('discourse_type'))\n + geom_bar(fill = 'orange', color = 'black')\n + scale_x_discrete(limits = label_ordered_list)\n + ggtitle('Frequency of Discourse Type (label)')\n + coord_flip()\n + xlab('Discourse Type')\n + ylab('Frequency')\n)","90cc75a7":"df['char_len'] = (df['discourse_end'] - df['discourse_start']).astype(int)\ndf['word_len'] = df['predictionstring'].str.split().apply(len)","dc0daa80":"from sklearn.linear_model import LinearRegression\n\nX = df[['word_len']]\ny = df['char_len']\nreg = LinearRegression().fit(X, y)\nscore, a, b = reg.score(X, y), reg.coef_.item(), reg.intercept_\nscore, a, b","3da6c0b1":"(ggplot(\n    df.sample(frac = 0.1, random_state = 42), \n    aes(x = 'word_len', y = 'char_len'))\n + geom_point(alpha = 0.1)\n + geom_smooth(method = 'lm')\n + ylab('Number of characters')\n + xlab('Number of words')\n + ggtitle('Average word length per text file')\n + annotate('text', x = 600, y = 2500, label = f'$y = {a:.2f}x + {b:.2f}$')\n)","5208c3bd":"(ggplot(df, aes(x = 'discourse_type', y = 'word_len'))\n + geom_boxplot(color = 'black', fill = 'orange')\n + scale_x_discrete(limits = label_ordered_list)\n + ylab('Length of the comment in words')\n + xlab('Discourse Type')\n + coord_flip()\n)","2f9606b8":"(ggplot(df, aes(x = 'discourse_type', y = 'word_len'))\n + geom_boxplot(color = 'black', fill = 'orange')\n + scale_x_discrete(limits = label_ordered_list)\n + ylab('Length of the comment in words')\n + xlab('Discourse Type')\n + coord_flip()\n + ylim(0, 150)\n)","69eeeb3f":"(ggplot(\n    df.sample(frac = 0.1, random_state = 42), \n    aes(x = 'discourse_type', y = 'word_len'))\n + geom_violin(color = 'black', fill = 'orange')\n + scale_x_discrete(limits = label_ordered_list)\n + ylab('Length of the comment in words')\n + xlab('Discourse Type')\n + coord_flip()\n + ylim(0, 150)\n)","bc07ae35":"label_ratio = []\nfor i, txt in tqdm(df.groupby('id')): \n    \n    txt_id = txt['id'].values[0]\n    txt_file = f\"\/kaggle\/input\/feedback-prize-2021\/train\/{txt_id}.txt\"\n    \n    with open(txt_file, 'r') as file:\n        txt_data = file.read()\n        \n    len_lbls = txt['char_len'].sum()\n    len_txt = len(txt_data)\n    ratio = len_lbls\/len_txt\n\n    label_ratio.append(pd.DataFrame({'id': [txt_id], 'ratio':[ratio]}))\n    \nlabel_ratio = pd.concat(label_ratio).reset_index(drop = True)","803fde9e":"label_ratio[['ratio']].describe().T","838c02d4":"(ggplot(label_ratio, aes('ratio'))\n + geom_histogram(bins = 100, color = 'black', fill = 'orange')\n + scale_y_log10()\n)","4639bf58":"label_ratio.sort_values('ratio').head()","b39cb6d5":"#This text could be either a bug in the file or just a \n# smart-ass kid trying to inflate the number of words in his essay\nlabeler('C278EDC82048', 1200)","4183e8b4":"#This text is clearly from a brat\nlabeler('129497C3E0FC')        ","5ab0b2ea":"#Maybe this one the kid got our of topic? instant F?\nlabeler('F5EE08CB44B9')","6ef0fe03":"# This text have a bunch of white spaces\nlabeler('9B23715DFB32')","e86ab37c":"# This one apprears to have labeling issues\nlabeler('F45B396E0A01')","c69014f4":"(label_ratio['ratio'] > 0.50).mean()","aa42bb85":"(label_ratio['ratio'] > 0.80).mean()","921b4a48":"label_ratio['ratio'].mean()","479d84b4":"files_test = os.listdir('\/kaggle\/input\/feedback-prize-2021\/test')\nprint(f'We have {len(files_test)} files in the train folder')","ea06be5e":"submission = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')\nsubmission","a4da2913":"files_to_keep = label_ratio['id'][label_ratio['ratio'] > 0.80]\ndf_clean = df.set_index('id').loc[files_to_keep].reset_index().copy()\ndf_clean = df_clean.set_index('id')","cfa7b230":"for idx, group in tqdm(df_clean.groupby(df_clean.index)):\n    txt_file_path = f'\/kaggle\/input\/feedback-prize-2021\/train\/{idx}.txt'\n    with open(txt_file_path, 'r') as file:\n        text_data = file.read()\n    txt_len = len(text_data.split())\n    df_clean.loc[idx, 'txt_len'] = int(txt_len)\n    \ndf_clean['start'] = df_clean.apply(lambda x: int(x['predictionstring'].split()[0]) \/ x['txt_len'], axis = 1)\ndf_clean['end'] = df_clean.apply(lambda x: int(x['predictionstring'].split()[-1]) \/ x['txt_len'], axis = 1)\ndf_clean = df_clean.reset_index()","6a890ccc":"(ggplot(\n    pd.melt(df_clean, ['id', 'discourse_type'], ['start', 'end']), \n    aes(y = 'value', x = 'discourse_type', fill = 'variable'))\n + geom_boxplot(color = 'black')\n + scale_x_discrete(limits = label_ordered_list)\n + ylab('Relative postion of starting word')\n + xlab('Discourse Type')\n + coord_flip()\n)","c6a1dfe0":"(pd.melt(df_clean, ['id', 'discourse_type'], ['start', 'end'])\n .groupby(['discourse_type', 'variable'])['value']\n .median()\n).to_frame().T","3496e8b7":"lead = [0, 0.05]\nposition = [0.05, 0.2]\nclaim = [0.2, 0.4]\nevidence = [0.4, 0.6]\ncounterclaim = [0.60, 0.62]\nrebuttal = [0.62, 0.68]\nconcluding_statement = [0.8, 1.0]","46298f6b":"sub = []\nfor txt_file in files_test:\n    txt_file_path = f'\/kaggle\/input\/feedback-prize-2021\/test\/{txt_file}'\n    with open(txt_file_path, 'r') as file:\n        text_data = file.read()\n    txt_len = len(text_data.split())\n    sub.append(pd.DataFrame({\n        'id': txt_file.split('.')[0],\n        'class': [\n            'Lead',\n            'Position',\n            'Claim',\n            'Evidence',\n            'Counterclaim',\n            'Rebuttal',\n            'Concluding Statement',\n        ],\n        'predictionstring': [\n            ' '.join((np.arange(txt_len*lead[0], txt_len*lead[1], dtype = int) + 1).astype(str)),\n            ' '.join((np.arange(txt_len*position[0], txt_len*position[1], dtype = int) + 1).astype(str)),\n            ' '.join((np.arange(txt_len*claim[0], txt_len*claim[1], dtype = int) + 1).astype(str)),\n            ' '.join((np.arange(txt_len*evidence[0], txt_len*evidence[1], dtype = int) + 1).astype(str)),\n            ' '.join((np.arange(txt_len*counterclaim[0], txt_len*counterclaim[1], dtype = int) + 1).astype(str)),\n            ' '.join((np.arange(txt_len*rebuttal[0], txt_len*rebuttal[1], dtype = int) + 1).astype(str)),\n            ' '.join((np.arange(txt_len*concluding_statement[0], txt_len*concluding_statement[1], dtype = int) + 1).astype(str)),\n        ]\n    }))\n\nsubmission = pd.concat(sub).reset_index(drop = True)","6fe56301":"submission.to_csv('submission.csv', index = False)\nsubmission","5a571225":"Next we normalize string start and end by the text length","d3fbacfe":"# Structure of the TRAIN data?\n\n- How many text files do we have?\n- How many labeled fragments we have?\n- Example of labeled (with color) for a single text file","fc5a44bb":"My advice would be to remove those texts from the training dataset","192d21b2":"## Example of labeled text","57024d63":"<h3 style='background:orange; color:black'><center>WORK IN PROGRESS!! Come back for more later...<\/center><\/h3>","01f5806a":"So the goal is to predict (for each text file) pairs of `class` and `predictionstring`. Note there for a single file there will be multiple predictions.","288bbe5b":"# Evaluation Score\n\n- Theory on what is the score\n- Examples on how to calculate the evaluation metric","4ca94af9":"### How much unlabeled text do we have in the train set?","2050d7af":"Now we guess the ideal splits by considering the statistics of our data","5f90a89e":"### Let's investigate those strange outliers","6cb3d768":"# Building a *very* naive baseline\n\nJust to test the submission format, we can predict that the most common occurences that happens in our dataset.\n\nFirst we filter the outliers by considering only files with label_ratio > 0.8","6c98b12b":"## How many labeled fragments we have?","c6c0c5d1":"<h1><center>Comprehensive EDA for the Feedback Prize - Evaluating Student Writing Competition<\/center><\/h1>\n                           \n                           \n<center><img src = \"https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/31779\/logos\/header.png\" width = \"1000\" height = \"400\"\/><\/center>    \n\nThis EDA aims to answer the folowing questions:   \n1. What is the Structure for the TRAIN data ?\n1. What is the distribution of the labels?\n1. What is the test data Structure?\n1. What is the submission data Structure?\n1. How is the score calculated?\n\n<h3 style='background:orange; color:black'><center>Consider upvoting this notebook if you found it helpful.<\/center><\/h3>","7b2ab5ca":"By thresholding the ratio of labeled data to 50% we still have 99.4% of the data.","c3c09836":"And we build the submission file","bd2469fa":"# Distribution of the labels\n\n- Quantity\n- Lenght (boxplot that compares length per label) (word and run-text)\n- No-label\n- Ratio of label\/total-text length","22ff6201":"# Structure of the TEST data","ac21da37":"TODO: Try to use decision trees to model this naive relationship","2ab8a293":"This is common on kernel competitions where the true test set is hiddien. according to the competition description there are about 10k test files.\n> Note that this is a code competition, in which you will submit code that will be run against an unseen test set. The unseen test set is approximately 10k documents. A small public test sample has been provided for testing your notebooks.","a93f3e56":"### How many text files we have?","426dc68e":"Also, considering the distribution, if you ignore the no-label data (i.e. assign a label to every single word) you should probably still score quite high as the average label fraction is 95%","2b0f8079":"## How many text files do we have?","089176a1":"# Structure of the SUBMISSION file\n","17befed4":"And by thresholding it on 80% we still have 94% of the data.","597c8945":"We can visualize the distribution of those labels to assure that they make sense."}}