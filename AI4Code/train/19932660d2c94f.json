{"cell_type":{"a87d238e":"code","dbfdc44c":"code","b952da4a":"code","49661c4e":"code","bfa3ce4c":"code","bc6e7919":"code","f2a034b4":"code","28a14813":"code","1a3da3a1":"code","7d09021c":"code","5df9790d":"code","5491c344":"code","d1575662":"code","bc9557d3":"code","856ab725":"code","57ecd4ed":"code","99e62747":"markdown","37a2e027":"markdown","d3026dbe":"markdown","fb55a092":"markdown","5fced0a5":"markdown","d402db25":"markdown","b59aa68e":"markdown","27d17c35":"markdown","937f7abd":"markdown"},"source":{"a87d238e":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D,Dense,Flatten,Dropout\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nimport pandas as pd","dbfdc44c":"train_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')\n","b952da4a":"train_images=train_data.drop('label',axis=1)\ntest_images=test_data.drop('label',axis=1)","49661c4e":"train_label = train_data['label']\ntest_label = test_data['label']","bfa3ce4c":"train_images = np.array(train_images).astype('float32')\ntest_images = np.array(test_images).astype('float32')","bc6e7919":"train_images = train_images.reshape(60000, 28, 28)\ntest_images = test_images.reshape(10000, 28, 28)","f2a034b4":"train_images, test_images = train_images \/ 255.0, test_images \/ 255.0","28a14813":"#Get the initial 25 pics from the datast\nclass_names = ['T-shirt\/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_label[i]])\n\nplt.show()","1a3da3a1":"#Get the shape of the train dataset\ntrain_images.shape","7d09021c":"#Get the shape of the test dataset\ntest_images.shape","5df9790d":"\t# reshape dataset to have a single channel\n\ntrain_images=train_images.reshape(len(train_images),28,28,1)\ntest_images=test_images.reshape(len(test_images),28,28,1)","5491c344":"model=Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu'))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='valid',activation='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","d1575662":"epochs = 20  # for better result increase the epochs\nbatch_size=100","bc9557d3":"model.compile(\n  'adam',\n  loss='categorical_crossentropy',\n  metrics=['accuracy'])","856ab725":"model.fit(\n  train_images,\n  to_categorical(train_label),\n  epochs=epochs,\n  batch_size=batch_size,\n  validation_data=(test_images, to_categorical(test_label)),\n)","57ecd4ed":"#make Prediction\n# predict the class\nresult = model.predict(test_images)","99e62747":"### Normalize pixel values to be between 0 and 1","37a2e027":"### **Read the data**","d3026dbe":"### **Import the libraries**","fb55a092":"## Visualize the data(initial few images)","5fced0a5":"test_loss,test_acc = model.evaluate(test_images,to_categorical(test_label), verbose=2)\nprint(\"Test loss:\", test_loss)\nprint(\"Test accuracy:\", test_acc)","d402db25":"### Converting the dimension of input image","b59aa68e":"## Model Evaluation","27d17c35":"## Creating the model","937f7abd":"### **The output variable**"}}