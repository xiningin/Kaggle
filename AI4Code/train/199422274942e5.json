{"cell_type":{"abb18386":"code","0647232f":"code","1978e369":"code","8a9c43e9":"code","55ec8963":"code","6adccd82":"code","4f0d37c0":"code","c248f9b9":"code","4ed27436":"code","c8593eed":"code","02e78e77":"code","18125f90":"code","42cb28ce":"code","65ae5675":"code","3daa8d1e":"code","58294369":"code","681e0e88":"code","05c26da7":"code","d2610e2c":"code","35f5cb97":"code","978e4015":"code","04c491de":"code","94aab252":"code","3877d5aa":"code","2a1ee89e":"code","978c03ee":"code","06c54593":"code","e582ce12":"code","bbb5b318":"code","0631ee22":"code","cfb6fff2":"code","752c717a":"code","d1c022d0":"code","98e152d1":"code","13a67c5b":"code","80a902d4":"code","5f826aa0":"markdown","11a6aed8":"markdown","8f4e8918":"markdown","fb02f29d":"markdown","e178d4b9":"markdown","f823328a":"markdown","5e42b566":"markdown","cc2378c3":"markdown","33755c8a":"markdown","c504448e":"markdown","c2a6af48":"markdown","ef2b5dcf":"markdown","a9680f3d":"markdown","434467c0":"markdown","382a1f19":"markdown","ff03c377":"markdown","7d916e9f":"markdown","738f9ae4":"markdown","b058423f":"markdown","022a9d58":"markdown","9dccb5e3":"markdown","07773cab":"markdown","74df1281":"markdown","881d06e9":"markdown","2010a2a2":"markdown","3954221b":"markdown","f99e0650":"markdown","ed0614d0":"markdown"},"source":{"abb18386":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, LeakyReLU\nfrom tensorflow.keras.layers import Flatten, Activation, BatchNormalization\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom lightgbm import LGBMClassifier\n","0647232f":"data_dictionary = pd.read_csv(\"..\/input\/widsdatathon2021\/DataDictionaryWiDS2021.csv\")\nunlabeled = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\ntraining = pd.read_csv(\"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")","1978e369":"unlabeled = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\n","8a9c43e9":"#Creating a copy before doing any modifications\ntrainingeda=training.copy()","55ec8963":"column_datatype_mapping = dict(zip(data_dictionary['Variable Name'], data_dictionary['Data Type']))\ndel training['Unnamed: 0']\ndel unlabeled['Unnamed: 0']\ntraining.diabetes_mellitus.value_counts()","6adccd82":"print(len(training), len(unlabeled))\n\nall_data = training.drop(['diabetes_mellitus'], axis=1).append(unlabeled,ignore_index=True).drop(['encounter_id', \n                          'hospital_id'], axis=1)\n\nfor col in all_data.columns:\n    if all_data.dtypes[col] == \"object\":\n        all_data[col] = all_data[col].fillna(\"NA\")\n        all_data[col] = LabelEncoder().fit_transform(all_data[col])\n        all_data[col]= all_data[col].astype('category')\n    elif column_datatype_mapping[col] == \"binary\":\n        all_data[col] = all_data[col].fillna(-1)\n    elif column_datatype_mapping[col] == \"numeric\":\n        all_data[col] = all_data[col].fillna(0)\n    else:\n        all_data[col] = all_data[col].fillna(all_data[col].median())\n    \nlen(all_data)\n\n\nall_data['weight'] = all_data['bmi']*(all_data['height']\/100)*(all_data['height']\/100)","4f0d37c0":"plt.rcParams[\"figure.figsize\"] = (7,5)\ntrainingeda.groupby('gender').age.plot(kind='kde')\nplt.xlabel(\"Age\")\n","c248f9b9":"bins = [0,18, 30, 40, 50, 60, 70, 120]\nlabels = ['0-17','18-29', '30-39', '40-49', '50-59', '60-69', '70+']\ntrainingeda['agerange'] = pd.cut(trainingeda.age, bins, labels = labels,include_lowest = True)\ntrainingedaar=pd.DataFrame(trainingeda.groupby('agerange')['bmi'].mean())\n\n\nplt.rcParams[\"figure.figsize\"] = (5,3)\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\ntrainingedaar=trainingedaar.reset_index()\nax.bar(trainingedaar['agerange'],trainingedaar['bmi'],color='slateblue')\nplt.xlabel(\"Age\")\nplt.ylabel(\"Mean_BMI\")\nplt.show()\n\n\n","4ed27436":"(trainingeda.columns).to_list()","c8593eed":"\n\n\ntrainingwe=(trainingeda[['diabetes_mellitus','weight']])\nprint(trainingwe.shape)\ntrainingwe.dropna(inplace=True)\nprint(trainingwe.shape)\ntrainingwei=pd.DataFrame(trainingwe.groupby('diabetes_mellitus')['weight'].mean())\n\nplt.rcParams[\"figure.figsize\"] = (5,3)\n\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\ntrainingwei=trainingwei.reset_index()\ntrainingwei['diabetes_mellitus'] = trainingwei['diabetes_mellitus'].apply(str)\n\nax.bar(trainingwei['diabetes_mellitus'],trainingwei['weight'],color='slateblue')\nplt.xlabel(\"0:Non-diabetic   1:Dibetic\")\nplt.ylabel(\"Mean weight\")\nplt.show()\n","02e78e77":"imbalan=pd.DataFrame(trainingeda.groupby('diabetes_mellitus')['Unnamed: 0'].count())\nimbalan=imbalan.reset_index()\nimbalan['perc']=imbalan['Unnamed: 0']\/len(trainingeda['Unnamed: 0'])\n\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\n\nimbalan['diabetes_mellitus'] = imbalan['diabetes_mellitus'].apply(str)\n\nax.bar(imbalan['diabetes_mellitus'],imbalan['perc'],color='slateblue')\nplt.xlabel(\"0:Non-diabetic   1:Dibetic\")\nplt.ylabel(\"perc\")\nplt.show()","18125f90":"#Replace the null values with mean\n\ntrainingeda['creatinine_apache'] =trainingeda['creatinine_apache'].fillna(trainingeda['creatinine_apache'].mean())\ntrainingeda['bun_apache'] =trainingeda['bun_apache'].fillna(trainingeda['bun_apache'].mean())","42cb28ce":"trainingeda['d1_creatinine_mean']=pd.DataFrame(trainingeda.groupby('encounter_id')['creatinine_apache'].mean())\ntrainingeda['d1_bun_mean']=pd.DataFrame(trainingeda.groupby('encounter_id')['bun_apache'].mean())\n\nsns.pairplot(data=trainingeda, vars=[\"creatinine_apache\", \"weight\", \"bmi\", \"bun_apache\"], hue='diabetes_mellitus');\n\n","65ae5675":"no_diabetes = trainingeda[trainingeda.diabetes_mellitus == 0]\ndiabetes = trainingeda[trainingeda.diabetes_mellitus == 1]\n\n#Visualization code\nfig, (ax1, ax2) = plt.subplots(ncols=2)\nfig.set_size_inches(12, 5)\n#non-Diabetic patient correlation visualization\n\nspike_cols_nd = [col for col in no_diabetes.columns if 'apache' in col]\ntrainingapache_nd=no_diabetes[spike_cols_nd]\ncorrs = trainingapache_nd.corr()\n# sns.set(rc={'figure.figsize':(15,15)})\nmask = np.zeros_like(corrs)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corrs, cmap='Spectral_r', mask=mask, square=True, vmin=-.4, vmax=.4,ax=ax1).set_title('Non diabetic patient levels')\n\n\n#Diabetic patient correlation visualization\nspike_cols = [col for col in diabetes.columns if 'apache' in col]\ntrainingapache=diabetes[spike_cols]\n# sns.set(rc={'figure.figsize':(15,15)})\ncorrsd = trainingapache.corr()\nmask = np.zeros_like(corrsd)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corrsd, cmap='Spectral_r', mask=mask, square=True, vmin=-.4, vmax=.4,ax=ax2).set_title('Diabetic patient levels')\nfig.tight_layout()","3daa8d1e":"# Create correlation matrix \ncorr_mat = trainingapache.corr(method='pearson') \n  \n# Retain upper triangular values of correlation matrix and \n# make Lower triangular values Null \nupper_corr_mat = corr_mat.where( \n    np.triu(np.ones(corr_mat.shape), k=1).astype(np.bool)) \n  \n# Convert to 1-D series and drop Null values \nunique_corr_pairs = upper_corr_mat.unstack().dropna() \n  \n# Sort correlation pairs \nsorted_mat = unique_corr_pairs.sort_values() \n\n\n\n# Create correlation matrix \ncorr_mat_nd = trainingapache_nd.corr(method='pearson') \n  \n# Retain upper triangular values of correlation matrix and \n# make Lower triangular values Null \nupper_corr_mat_nd = corr_mat_nd.where( \n    np.triu(np.ones(corr_mat_nd.shape), k=1).astype(np.bool)) \n  \n# Convert to 1-D series and drop Null values \nunique_corr_pairs_nd = upper_corr_mat_nd.unstack().dropna() \n  \n# Sort correlation pairs \nsorted_mat_nd = unique_corr_pairs_nd.sort_values() \n\n\nsorted_nd=pd.DataFrame(sorted_mat_nd).head(10)\nprint('Non diabetic patients')\nprint(sorted_nd.reset_index())\nprint(' ')\nprint(' ')\nsorteddiab=pd.DataFrame(sorted_mat).head(10)\nprint('Diabetic patients')\nprint(sorteddiab.reset_index())","58294369":"pd.DataFrame(trainingeda.groupby('diabetes_mellitus')['Unnamed: 0'].count())","681e0e88":"df1 = trainingeda[trainingeda['diabetes_mellitus']==1].sample(n=25000)\ndf0 = trainingeda[trainingeda['diabetes_mellitus']==0].sample(n=25000)\nsample=pd.DataFrame(pd.concat([df1,df0]))\n\nbalaned=pd.DataFrame(sample.groupby('diabetes_mellitus')['Unnamed: 0'].count())\nbalaned=balaned.reset_index()\n\nbalaned\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\n\nbalaned['diabetes_mellitus'] = balaned['diabetes_mellitus'].apply(str)\n\nax.bar(balaned['diabetes_mellitus'],balaned['Unnamed: 0'],color='slateblue')\nplt.xlabel(\"0:Non-diabetic   1:Dibetic\")\nplt.ylabel(\"perc\")\nplt.show()","05c26da7":"print(len(training), len(unlabeled))\n\nall_data = sample.drop(['diabetes_mellitus','Unnamed: 0','agerange','d1_creatinine_mean','d1_bun_mean','encounter_id','hospital_id'], axis=1)\n\nfor col in all_data.columns:\n    if all_data.dtypes[col] == \"object\":\n        all_data[col] = all_data[col].fillna(\"NA\")\n        all_data[col] = LabelEncoder().fit_transform(all_data[col])\n        all_data[col]= all_data[col].astype('category')\n    elif column_datatype_mapping[col] == \"binary\":\n        all_data[col] = all_data[col].fillna(-1)\n    elif column_datatype_mapping[col] == \"numeric\":\n        all_data[col] = all_data[col].fillna(0)\n    else:\n        all_data[col] = all_data[col].fillna(all_data[col].median())\n    \nlen(all_data)\n","d2610e2c":"print(len(training), len(unlabeled))\n\nunlabeled1 =unlabeled.drop(['encounter_id','hospital_id'], axis=1)\n\nfor col in unlabeled1.columns:\n    if unlabeled1.dtypes[col] == \"object\":\n        unlabeled1[col] = unlabeled1[col].fillna(\"NA\")\n        unlabeled1[col] = LabelEncoder().fit_transform(unlabeled1[col])\n        unlabeled1[col]= unlabeled1[col].astype('category')\n    elif column_datatype_mapping[col] == \"binary\":\n        unlabeled1[col] = unlabeled1[col].fillna(-1)\n    elif column_datatype_mapping[col] == \"numeric\":\n        unlabeled1[col] = unlabeled1[col].fillna(0)\n    else:\n        unlabeled1[col] = unlabeled1[col].fillna(unlabeled1[col].median())\n    \nlen(unlabeled1)\n","35f5cb97":"df_train = all_data.iloc[:len(training)]#[selected_columns]\ndf_pred = all_data.iloc[-len(unlabeled):].reset_index(drop=True)#[selected_columns]\nY = training['diabetes_mellitus']\nx_train, x_test, y_train, y_test = train_test_split(df_train, sample['diabetes_mellitus'], test_size=0.20, random_state=42,shuffle=True )","978e4015":"clf = RandomForestClassifier(n_estimators=4, random_state=0)\nclf.fit(x_train, y_train)\nname='RandomForest'\n\nprob_y_valrf = clf.predict_proba(x_test)[:,1]\n\n#Make Predictions\npred_y_0 = clf.predict_proba(unlabeled1)[:,1]\npd.DataFrame(pred_y_0)\nsubs=unlabeled[['encounter_id']]\nsubs['diabetes_mellitus']=pd.DataFrame(pred_y_0)\nsubs.to_csv('.\/Prediction_with_rf.csv',index=False)\n","04c491de":"df_train = all_data.iloc[:len(training)]#[selected_columns]\ndf_pred = all_data.iloc[-len(unlabeled):].reset_index(drop=True)#[selected_columns]\nY = training['diabetes_mellitus']\nx_train, x_test, y_train, y_test = train_test_split(df_train, sample['diabetes_mellitus'], test_size=0.20, random_state=42,shuffle=True )","94aab252":"x_train = x_train.values.reshape(-1, x_train.shape[1], 1)  # reshaping for convnet\nx_test = x_test.values.reshape(-1, x_test.shape[1], 1)  # reshaping for convnet","3877d5aa":"def build_model():\n    model = keras.models.Sequential()\n    model.add(Conv1D(384, kernel_size=3, input_shape=x_train.shape[1:]))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Conv1D(32, kernel_size=3))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Flatten()) \n    model.add(Dense(1))\n    model.add(Activation(\"sigmoid\"))\n    model.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n                  loss=BinaryCrossentropy(label_smoothing=0.0921),\n                  metrics=[tf.keras.metrics.AUC(name = 'auc'), \"accuracy\"])\n    return model\n    \nmodel = build_model()\nmodel.fit(x=x_train, y=y_train,\n          epochs=25, batch_size=2048,\n          callbacks=[tf.keras.callbacks.EarlyStopping('val_auc', mode='max',patience=3)],\n          validation_data=(x_test, y_test))\n\nmodel.fit(df_train.values.reshape(-1, df_pred.shape[1], 1), sample['diabetes_mellitus'],\n          epochs=3,\n          batch_size=1024)\n\n\n#Make Predictions\npd.DataFrame({\n    'encounter_id': unlabeled['encounter_id'].values,\n    'diabetes_mellitus': model.predict_proba(\n        df_pred.values.reshape(-1, df_pred.shape[1], 1)).flatten()\n             }).to_csv('.\/Prediction_with_CNN1D.csv',index=False)","2a1ee89e":"pred_cnn= model.predict_proba(\n        df_pred.values.reshape(-1, df_pred.shape[1], 1)).flatten()\n            ","978c03ee":"# Remove Dependent Variable\ndf_train_1 = sample.loc[:,'encounter_id':'solid_tumor_with_metastasis'].reset_index(drop=True)\n# Dependent Variable\ny = sample['diabetes_mellitus']\ndf_test_1 = unlabeled.loc[:,'encounter_id':'solid_tumor_with_metastasis'].reset_index(drop=True)","06c54593":"cat_clmns = df_train_1.dtypes[df_train_1.dtypes == \"object\"].index \nnumeric_clmns = df_train_1.dtypes[df_train_1.dtypes != \"object\"].index\n\n#Categorical Values\ndf_train_1[cat_clmns] = df_train_1[cat_clmns].fillna(df_train_1[cat_clmns].mode().loc[0])\n# Numerical\ndf_train_1[numeric_clmns] = df_train_1[numeric_clmns].fillna(df_train_1[numeric_clmns].mean())\n\n# Impute Test \n# Categorical Values\ndf_test_1[cat_clmns] = df_test_1[cat_clmns].fillna(df_train_1[cat_clmns].mode().loc[0])\n# Numerical\ndf_test_1[numeric_clmns] = df_test_1[numeric_clmns].fillna(df_train_1[numeric_clmns].mean())","e582ce12":"## XGBoost\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n# process columns, apply LabelEncoder to categorical features\nfor c in cat_clmns:\n    label_enc = LabelEncoder()\n    label_enc.fit(df_train_1[c].values)\n    # Training Data\n    df_train_1[c] = label_enc.transform(df_train_1[c].values)\n    # Testing Data\n    df_test_1[c] = label_enc.transform(df_test_1[c].values)\ndf_train_2 = df_train_1.drop(['encounter_id', 'hospital_id'], axis = 1)\ndf_test_2 = df_test_1.drop(['encounter_id', 'hospital_id'], axis = 1)\n\nnfold = 5\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\nX_train, X_test, y_train, y_test = train_test_split(df_train_2, y, test_size=0.2, random_state=42)\n\n\nst_xgb = XGBClassifier()\n\nst_xgb.fit(X_train,y_train)\n\npred_xgb= st_xgb.predict_proba(X_test)[:,1]\npred_xgb\n\n\n\n\n\n# frame_xgb = { 'encounter_id': df_test_1['encounter_id'], 'diabetes_mellitus': y_pred_lgb } \n# result = pd.DataFrame(frame_xgb) \n# result.to_csv('xgb_gpu.csv',index=False)\n","bbb5b318":"pred_xgb= st_xgb.predict_proba(df_test_2)\npred_xgb","0631ee22":"#This gives only 79% so not great\n\npred=0.5*pred_xgb+0.5*pred_cnn\n\ndf_test_1['diabetes_mellitus'] = pred\ndf_test_1[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission_cnn+xgb.csv\",index=False)","cfb6fff2":"from sklearn.ensemble import StackingClassifier\n\nst_clf = StackingClassifier(estimators=[('xgb', train_model), ('cnn', model)], \n                            final_estimator= RandomizedSearchCV(xgbb, \n                                   param_distributions=params, \n                                   scoring='roc_auc', \n                                   cv=skf.split(X_train,y_train), \n                                   verbose=3, \n                                   random_state=1001 ))\nst_clf.fit(X_train,y_train)","752c717a":"\nmodel = LGBMClassifier(\n                              random_state=33,\n                              early_stopping_rounds = 250,\n                              n_estimators=1000,\n                              boosting_type='gbdt', num_leaves=151, max_depth=- 1, learning_rate=0.02, subsample_for_bin=200, \n                              min_split_gain=0.5, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=0, \n                              colsample_bytree=.75, reg_alpha=1.3, reg_lambda=0.1,  n_jobs=- 1,\n                              silent=True, importance_type='split')\n\nmodel.fit(\n    X_train,\n    y_train,\n    eval_set=[(X_test, y_test)],\n    eval_metric='auc',  \n    verbose=False,\n)","d1c022d0":"print(f\"accuracy score is {accuracy_score(y_test, model.predict(X_test))}\") #0.02- 0.8423\nprint(metrics.classification_report(y_test, model.predict(X_test), labels=[0, 1]))","98e152d1":"del df_test_2['diabetes_mellitus']","13a67c5b":"df_test_2","80a902d4":"pred = model.predict_proba(df_test_2)[:,1]\ndf_test_1['diabetes_mellitus'] = pred\ndf_test_1[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission_tuned_lgbm_2.csv\",index=False)","5f826aa0":"### <Left> <font color='purple'> 4. Imbalanced training dataset?<font>","11a6aed8":"### <Left> <font color='purple'> 2. Mean BMI for different age groups<font>\n","8f4e8918":"### <span style=\"background-color:lightblue\">Diabetic patients weight 10+ pounds more when compared to non diabetic patients. When a person takes insulin as a therapy for diabetes, their body may absorb too much glucose from food, resulting in weight gain.<br>\n<br>\n<\/span><br>\n    \n    source:https:\/\/www.medicalnewstoday.com\/articles\/325328#:~:text=Eating%20more%20calories%20than%20the,food%2C%20resulting%20in%20weight%20gain.","fb02f29d":"![](https:\/\/media1.tenor.com\/images\/22d8ce3fc622207434a52bfaa7b92593\/tenor.gif?itemid=20036149)","e178d4b9":"### <span style=\"background-color:lightblue\">The dataset is obviously imbalanced as we can see from the graph above. So, we need to create a sample with balanced dataset. Balanced here means having approximately same number of records in the sample training dataset.<\/span><br>\n    ","f823328a":"### <Left> <font color='darkblue'>EDA<font>","5e42b566":"\n### <Left> <font color='purple'> 6. Make the sample data (Balanced dataset)<font>","cc2378c3":"### <Left> <font color='purple'> 1. Age distribution by Males Vs Females<font>\n","33755c8a":"### <Left> <font color='darkblue'>Test and train data split<font>","c504448e":"### <Left> <font color='purple'> 10. XG Boost<font>","c2a6af48":"![](http:\/\/)<h1><left>Lets get started!!<\/left><\/h1>\n\n![](https:\/\/media1.tenor.com\/images\/1a68aae1cddacead28b4f4626d098297\/tenor.gif?itemid=20034977)","ef2b5dcf":"### <Left> <font color='purple'> 9. CNN <font>","a9680f3d":"### <Left> <font color='purple'> 8. Random Forest Regresson model<font>","434467c0":"### <Left> <font color='purple'> 3. Did Diabetic patients weigh more?<font>","382a1f19":"### <Left> <font color='darkblue'>Import datasets<font>","ff03c377":"### <Left> <font color='darkblue'>Data Manipulation<font>","7d916e9f":"![](https:\/\/media1.tenor.com\/images\/e5d4fff0602734f5e0d23ec814dc31c5\/tenor.gif?itemid=19594862)","738f9ae4":"Diabetes is one of the most prevailing chronic conditions in the US. Based on the adverse effects the Coronavirus has on patients with diabetes, it is vital to understand the patient history for a personalized treatment plan for a patient.","b058423f":"### <center> <font color='darkblue'>                                 Lets import all necessary Libraries!<font>\n### <center><font color='darkblue'>                            All packages that this notebook needs are below. :)<font>\n    ","022a9d58":"### <span style=\"background-color:lightblue\">Based on the graph, BMI increases upto 40 - 49 Yrs and then decreases.<\/span>","9dccb5e3":"### <Left> <font color='purple'> 5. Levels in Diabetic vs. non diabetic patients?<font>\n    \n    \nsource :https:\/\/www.kaggle.com\/iamleonie\/wids-datathon-2021-diabetes-detection","07773cab":"### <span style=\"background-color:lightblue\">It is clear from the above graph that the age distribution is pretty similar between males and females.<\/span>\n\n","74df1281":"### <Left> <font color='purple'> 7. Data Manipulation of unlabeled dataset<font>","881d06e9":"# <font color='darkblue'>Diabetes prediction<\/font>\n\n#### This notebook includes a basic random forest classification model analysis. Each snippet of code shows explanation.Hopefully this will be helpful for someone who is trying kaggle competition for the first time.<br>\n\n### <span style='background :yellow'>Please feel free to upvote and comment if you have any questions<span>","2010a2a2":"### <span style=\"background-color:lightblue\">Looking at the top 10 highly correlated variables  among diabetic Vs. Non- diabetic patients,verbal component,opening eyes,motor skill scale is highly correlated with ventilation for Non diabetic patients when compared to non diabetic patients. This shows that the diabetic patients who are on ventilation are less responsive on an average when comapred to non-diabetic  patients.\n <\/span><br>\n    ","3954221b":"### <Left> <font color='goldenrod'> Top 10 highly correlated variables - Diabetc Vs. Non diabetic<font>","f99e0650":"### <Left> <font color='purple'> 11. LGBM Classifier<font>","ed0614d0":"### <Left> <font color='purple'> 6. Data Manipulation of balanced dataset<font>"}}