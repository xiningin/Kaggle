{"cell_type":{"cf3538d6":"code","1b6b8aa2":"code","c3340e2e":"code","94d6b4ea":"code","875e429b":"code","38f02cd5":"code","99830311":"code","0e201adc":"code","74d3a4e9":"code","132731b7":"code","545536ae":"code","70619040":"code","b6604b5b":"code","4222720c":"code","3a741740":"code","7aa4478c":"markdown"},"source":{"cf3538d6":"import pandas as pd\nimport numpy as np\nimport pickle\nimport torch\nfrom matplotlib import pyplot as plt\n%matplotlib inline","1b6b8aa2":"with open('..\/input\/fastai-cell-tile-prototyping-3\/tta.pickle', 'rb') as handle:\n    preds = pickle.load(handle)","c3340e2e":"class_means = preds.mean(dim=0).numpy()\nlabels = range(19)\nplt.bar(labels, class_means)\nplt.show()","94d6b4ea":"row_max = preds.max(dim=-1).values.numpy()\nplt.hist(row_max, bins=100)\nplt.show()","875e429b":"fig = plt.figure(figsize=(16, 12))\n\nfor i in labels:\n    ax = fig.add_subplot(5,4,i+1)\n    ax.hist(preds[:,i].numpy(), bins=100)\n    ax.set_title(i)\n\nplt.show()","38f02cd5":"cell_df = pd.read_csv('..\/input\/fastai-cell-tile-prototyping-3\/cell_df.csv')\ncell_df.head()\ncell_df['cls'] = ''","99830311":"threshold = 0.0\n\nfor i in range(preds.shape[0]): \n    p = torch.nonzero(preds[i] > threshold).squeeze().numpy().tolist()\n    if type(p) != list: p = [p]\n    if len(p) == 0: cls = [(preds[i].argmax().item(), preds[i].max().item())]\n    else: cls = [(x, preds[i][x].item()) for x in p]\n    cell_df['cls'].loc[i] = cls","0e201adc":"def combine(r):\n    cls = r[0]\n    enc = r[1]\n    classes = [str(c[0]) + ' ' + str(c[1]) + ' ' + enc for c in cls]\n    return ' '.join(classes)\n\ncombine(cell_df[['cls', 'enc']].loc[24])","74d3a4e9":"cell_df['pred'] = cell_df[['cls', 'enc']].apply(combine, axis=1)\ncell_df.head()","132731b7":"subm = cell_df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\n# subm = subm.loc[3:]\nsubm.head()","545536ae":"sample_submission = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv')\nsample_submission.head()","70619040":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)\nsub.head()","b6604b5b":"def isNaN(num):\n    return num != num\n\nfor i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","4222720c":"sub = sub[sample_submission.columns]\nsub.head()","3a741740":"sub.to_csv('submission.csv', index=False)","7aa4478c":"# fastai quick submission template\n\nSolution overview: https:\/\/www.kaggle.com\/c\/hpa-single-cell-image-classification\/discussion\/221550\n\nI want to experiment quickly and can't wait for the lb score, especially that with weak labels I haven't found a reasonable way to do CV, and depend on the public lb score. I have pre-processed the public test images in the same way as my prototyping dataset and submit my preds only for this piece. These submissions will get zero score on private, but there is still lots of time in the competition and better approaches will be developed ."}}