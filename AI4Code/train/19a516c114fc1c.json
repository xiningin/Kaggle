{"cell_type":{"147a4a29":"code","621a2bb3":"code","b8dc8b1c":"code","0355e99c":"code","d31cb3ff":"code","43f3aad8":"code","c29b6a4d":"code","ff4d039c":"code","8cadd79f":"code","add51ebc":"code","b5612769":"code","e9e06043":"code","bd78db0a":"code","1721f4e9":"code","aca2d62f":"markdown","6d406f44":"markdown","7ca87e7e":"markdown","e37ce32a":"markdown","5a014f82":"markdown","a14fa06b":"markdown","12e21b4a":"markdown"},"source":{"147a4a29":"pip install 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'","621a2bb3":"pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","b8dc8b1c":"import torch\n\nfrom detectron2.config import get_cfg\nfrom detectron2.engine import DefaultPredictor\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda:{}\".format(0))\nelse:\n    device = torch.device(\"cpu\")\n\nprint(\"-> Loading model\")\ncfg = get_cfg()\ncfg.merge_from_file(\"..\/input\/detectron2\/configs\/COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\")\n\ncfg.MODEL.DEVICE = str(device)\ncfg.MODEL.RPN.NMS_THRESH = 0.1\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n\ncfg.MODEL.WEIGHTS = \"..\/input\/parameters\/model_final_f10217.pkl\"\n\nmodel = DefaultPredictor(cfg)","0355e99c":"import PIL.Image as Image\n\nfrom torchvision import transforms\n\ndefault_transform = transforms.Compose([transforms.ToTensor()])\n\ndef load_image(path, transform=default_transform):\n    image = Image.open(path)\n    return transform(image)","d31cb3ff":"image_path = '..\/input\/pku-autonomous-driving\/train_images\/ID_7f6f07350.jpg'","43f3aad8":"import cv2\n\nimage = cv2.imread(image_path)\noutputs = model(image)","c29b6a4d":"from detectron2.data import MetadataCatalog\nfrom matplotlib import pyplot as plt\n\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.utils.visualizer import Visualizer\n\nv = Visualizer(image[:, :, ::-1], metadata=MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.8, instance_mode=ColorMode.IMAGE_BW)\nv = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\nv = v.get_image()[:, :, ::-1]\n\nplt.imshow(v)\nplt.show()","ff4d039c":"mask = outputs[\"instances\"].pred_masks.sum(0) > 0","8cadd79f":"import numpy as np\n\nmask = torch.stack([mask, mask, mask], dim=2)\nmask = mask.cpu().numpy().astype(\"uint8\")\n\ninstances = cv2.multiply(image, mask)\nplt.imshow(instances)\nplt.show()","add51ebc":"import os\nimport cv2\nimport pdb\nimport glob\nimport argparse\n\nimport numpy as np","b5612769":"def make_multi_channel_masks(source_dir='..\/input\/pku-autonomous-driving\/train_images',\n                dist_dir='..\/input\/pku-autonomous-driving\/train_images_mask',\n                ext='jpg'):\n    \"\"\"Function to predict for a single image or folder of images\n    \"\"\"\n\n    # FINDING INPUT IMAGES\n    if os.path.isdir(source_dir):\n        # Searching folder for images\n        paths = glob.glob(os.path.join(source_dir, '*.{}'.format(ext)))\n        output_directory = dist_dir\n    else:\n        raise Exception(\"Can not find source_dir: {}\".format(source_dir))\n\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n        \n    print(\"-> Predicting on {:d} test images\".format(len(paths)))\n\n    for idx, image_path in enumerate(paths):\n        image = cv2.imread(image_path)\n        outputs = model(image)\n\n        output_name = os.path.splitext(os.path.basename(image_path))[0]\n        name_dest_npy = os.path.join(output_directory, \"{}.npy\".format(output_name))\n        mask = outputs['instances'].pred_masks.cpu().numpy()\n        np.save(name_dest_npy, mask)\n\n        print(\"   Processed {:d} of {:d} images - saved prediction to {}\".format(\n                idx + 1, len(paths), name_dest_npy))\n\n    print('-> Done!')","e9e06043":"def make_single_channel_masks(source_dir='..\/input\/pku-autonomous-driving\/train_images',\n                dist_dir='..\/input\/pku-autonomous-driving\/train_images_mask',\n                ext='jpg'):\n    \"\"\"Function to predict for a single image or folder of images\n    \"\"\"\n\n    # FINDING INPUT IMAGES\n    if os.path.isdir(source_dir):\n        # Searching folder for images\n        paths = glob.glob(os.path.join(source_dir, '*.{}'.format(ext)))\n        output_directory = dist_dir\n    else:\n        raise Exception(\"Can not find source_dir: {}\".format(source_dir))\n\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n        \n    print(\"-> Predicting on {:d} test images\".format(len(paths)))\n\n    for idx, image_path in enumerate(paths):\n        image = cv2.imread(image_path)\n        outputs = model(image)\n\n        output_name = os.path.splitext(os.path.basename(image_path))[0]\n        name_dest_npy = os.path.join(output_directory, \"{}.npy\".format(output_name))\n        mask = outputs[\"instances\"].pred_masks.sum(0) > 0\n        mask = mask.float().unsqueeze(0)\n        mask = mask.cpu().numpy()\n        np.save(name_dest_npy, mask)\n\n        print(\"   Processed {:d} of {:d} images - saved prediction to {}\".format(\n                idx + 1, len(paths), name_dest_npy))\n\n    print('-> Done!')","bd78db0a":"def make_instances(source_dir='..\/input\/pku-autonomous-driving\/train_images',\n                dist_dir='..\/input\/pku-autonomous-driving\/train_images_mask',\n                ext='jpg'):\n    \"\"\"Function to predict for a single image or folder of images\n    \"\"\"\n\n    # FINDING INPUT IMAGES\n    if os.path.isdir(source_dir):\n        # Searching folder for images\n        paths = glob.glob(os.path.join(source_dir, '*.{}'.format(ext)))\n        output_directory = dist_dir\n    else:\n        raise Exception(\"Can not find source_dir: {}\".format(source_dir))\n\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n        \n    print(\"-> Predicting on {:d} test images\".format(len(paths)))\n\n    for idx, image_path in enumerate(paths):\n        image = cv2.imread(image_path)\n        outputs = model(image)\n\n        output_name = os.path.splitext(os.path.basename(image_path))[0]\n        name_dest_jpg = os.path.join(output_directory, \"{}.jpg\".format(output_name))\n        mask = outputs[\"instances\"].pred_masks.sum(0) > 0\n        mask = torch.stack([mask, mask, mask], dim=2)\n        mask = mask.cpu().numpy().astype(\"uint8\")\n\n        instances = cv2.multiply(image, mask)\n        cv2.imwrite(name_dest_jpg, instances)\n\n        print(\"   Processed {:d} of {:d} images - saved prediction to {}\".format(\n                idx + 1, len(paths), name_dest_jpg))\n\n    print('-> Done!')","1721f4e9":"# make_multi_channel_masks()\n# make_single_channel_masks()\n# make_instances()","aca2d62f":"## Only need instances\nSome kaggler only want to use the detected instances as input to the model (without concatenating it with the original image), you can use opencv to crop:","6d406f44":"## Requirements for Detectron2\n* Python \u2265 3.6\n* PyTorch \u2265 1.3\n* torchvision that matches the PyTorch installation. You can install them together at pytorch.org to make sure of this.\n* OpenCV, optional, needed by demo and visualization\n* pycocotools: pip install cython; pip install 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n* gcc & g++ \u2265 4.9","7ca87e7e":"## Make mask predictions","e37ce32a":"# Thanks\nThanks to @Draconda, we found that the prior mask information is very effective for this task. On the one hand, we can use mask to directly regress values of yaw, pitch, roll, x, y, z, and mask as what @Draconda told. On the other hand, we can also concanate the mask information with the original image and send them to any network structure you currently design for prediction. Here, we share a simpler way to get accurate masks using detectron2","5a014f82":"## Visualization of masks","a14fa06b":"## Only need one-channel mask\nSome kagglers find that the npy file is large. This is because the shape of the mask I store is the number of instances * image size. If you only care about the binary result of instance-background, you can do max pooling:","12e21b4a":"Choose a generator based on your needs:"}}