{"cell_type":{"c385bc17":"code","270dcc36":"code","c9969ff7":"code","6a82ffe4":"code","1973fd69":"code","02bfb679":"code","5943a222":"code","ce77b3cf":"code","b5966b9b":"code","18dcfbec":"code","e5a18859":"code","46a95c5d":"code","a66dcb8a":"code","bc50641b":"code","1c67b4cf":"code","a3341919":"markdown","fccfd781":"markdown","411ac945":"markdown","47cb0692":"markdown","a324f133":"markdown","c7d23f26":"markdown","11a8762b":"markdown","f24ca35d":"markdown"},"source":{"c385bc17":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","270dcc36":"import time\nimport sys\n\nimport random\nimport matplotlib.pylab as plt\nimport cv2\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nimport torch.nn as nn\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.nn.functional as tfunc\nimport torch.nn.functional as func\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nimport torchvision.transforms as transforms\nimport torchvision\n\nfrom glob import glob\nfrom PIL import Image","c9969ff7":"PATH = os.path.abspath(os.path.join('..', 'input\/sample\/'))\nSOURCE_IMAGES = os.path.join(PATH, \"sample\", \"images\")\nimages = glob(os.path.join(SOURCE_IMAGES, \"*.png\"))\n\nimages[0:10]","6a82ffe4":"labels = pd.read_csv('..\/input\/sample\/sample_labels.csv')\nlabels.head(10)","1973fd69":"multipleImages = glob('\/kaggle\/input\/sample\/sample\/images\/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","02bfb679":"#drop unused columns\nlabels = labels[['Image Index','Finding Labels','Follow-up #','Patient ID',\n                 'Patient Age','Patient Gender']]\n#create new columns for each decease\npathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax',\n                  'Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation',\n                  'Infiltration','Fibrosis','Pneumonia']\nfor pathology in pathology_list :\n    labels[pathology] = labels['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)\n#remove Y after age\nlabels['Age']=labels['Patient Age'].apply(lambda x: x[:-1]).astype(int)\n\nplt.figure(figsize=(15,10))\ngs = gridspec.GridSpec(8,1)\nax1 = plt.subplot(gs[:7, :])\nax2 = plt.subplot(gs[7, :])\ndata1 = pd.melt(labels,\n             id_vars=['Patient Gender'],\n             value_vars = list(pathology_list),\n             var_name = 'Category',\n             value_name = 'Count')\ndata1 = data1.loc[data1.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data1, ax=ax1, \n                order = data1['Category'].value_counts().index)\nax1.set( ylabel=\"\",xlabel=\"\")\nax1.legend(fontsize=20)\nax1.set_title('X Ray partition',fontsize=18);\n\nlabels['Nothing']=labels['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)\n\ndata2 = pd.melt(labels,\n             id_vars=['Patient Gender'],\n             value_vars = list(['Nothing']),\n             var_name = 'Category',\n             value_name = 'Count')\ndata2 = data2.loc[data2.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data2,ax=ax2)\nax2.set( ylabel=\"\",xlabel=\"Number of desease\")\nax2.legend('')\nplt.subplots_adjust(hspace=.5)\n","5943a222":"print(labels[pathology_list])","ce77b3cf":"df=labels\ndata=df.groupby('Finding Labels').count().sort_values('Patient ID',ascending=False)\ndf1=data[['|' in index for index in data.index]].copy()\ndf2=data[['|' not in index for index in data.index]]\ndf2=df2[['No Finding' not in index for index in df2.index]]\ndf2['Finding Labels']=df2.index.values\ndf1['Finding Labels']=df1.index.values\n\nf, ax = plt.subplots(sharex=True,figsize=(15, 10))\ng=sns.countplot(y='Category',data=data1, ax=ax, \n                order=data1['Category'].value_counts().index,color='b',\n                label=\"Multiple Pathologies\")\nsns.set_color_codes(\"muted\")\ng=sns.barplot(x='Patient ID',y='Finding Labels',data=df2, ax=ax, \n              color=\"r\",label=\"Single Pathology\")\nax.legend(ncol=2, loc=\"center right\", frameon=True,fontsize=20)\nax.set( ylabel=\"\",xlabel=\"Number of Patients\")\nax.set_title(\"Comparaison between Single or Multiple Pathologies\",fontsize=20)      \nsns.despine(left=True)","b5966b9b":"y = pd.concat([labels[\"Image Index\"], labels[pathology_list]], axis=1)\ny.head()","18dcfbec":"Y_train, Y_test = train_test_split(y, test_size=0.2, random_state=42, shuffle=True)\nY_train, Y_val = train_test_split(Y_train, test_size=0.1, random_state=42, shuffle=True)\nprint(Y_train.shape)\nprint(Y_test.shape)\nprint(Y_val.shape)\n\nY_train.to_csv('train_1.txt', sep='\\t', header=False, index=False)\nY_val.to_csv('val_1.txt', sep='\\t', header=False, index=False)\nY_test.to_csv('test_1.txt', sep='\\t', header=False, index=False)","e5a18859":"class DatasetGenerator (Dataset):\n    \n    def __init__ (self, pathImageDirectory, pathDatasetFile, transform):\n    \n        self.listImagePaths = []\n        self.listImageLabels = []\n        self.transform = transform\n    \n        #---- Open file, get image paths and labels\n    \n        fileDescriptor = open(pathDatasetFile, \"r\")\n        \n        #---- get into the loop\n        line = True\n        \n        while line:\n                \n            line = fileDescriptor.readline()\n            \n            #--- if not empty\n            if line:\n          \n                lineItems = line.split()\n                \n                imagePath = os.path.join(pathImageDirectory, lineItems[0])\n                imageLabel = lineItems[1:]\n                imageLabel = [int(i) for i in imageLabel]\n                \n                self.listImagePaths.append(imagePath)\n                self.listImageLabels.append(imageLabel)   \n            \n        fileDescriptor.close()\n    \n    #-------------------------------------------------------------------------------- \n    \n    def __getitem__(self, index):\n        \n        imagePath = self.listImagePaths[index]\n        \n        imageData = Image.open(imagePath).convert('RGB')\n        imageLabel= torch.FloatTensor(self.listImageLabels[index])\n        \n        if self.transform != None: imageData = self.transform(imageData)\n        \n        return imageData, imageLabel\n        \n    #-------------------------------------------------------------------------------- \n    \n    def __len__(self):\n        \n        return len(self.listImagePaths)","46a95c5d":"class DenseNet121(nn.Module):\n\n    def __init__(self, classCount, isTrained):\n        super(DenseNet121, self).__init__()\n        self.densenet121 = torchvision.models.densenet121(pretrained=isTrained)\n\n        kernelCount = self.densenet121.classifier.in_features\n        self.densenet121.classifier = nn.Sequential(nn.Linear(kernelCount, classCount), nn.Sigmoid())\n\n    def forward(self, x):\n        x = self.densenet121(x)\n        return x\n\nclass DenseNet169(nn.Module):\n    \n    def __init__(self, classCount, isTrained):\n        super(DenseNet169, self).__init__()\n        self.densenet169 = torchvision.models.densenet169(pretrained=isTrained)\n        \n        kernelCount = self.densenet169.classifier.in_features\n        self.densenet169.classifier = nn.Sequential(nn.Linear(kernelCount, classCount), nn.Sigmoid())\n        \n    def forward (self, x):\n        x = self.densenet169(x)\n        return x\n    \nclass DenseNet201(nn.Module):\n    \n    def __init__ (self, classCount, isTrained):\n        super(DenseNet201, self).__init__()\n        self.densenet201 = torchvision.models.densenet201(pretrained=isTrained)\n        \n        kernelCount = self.densenet201.classifier.in_features\n        self.densenet201.classifier = nn.Sequential(nn.Linear(kernelCount, classCount), nn.Sigmoid())\n        \n    def forward (self, x):\n        x = self.densenet201(x)\n        return x","a66dcb8a":"import gc \n# Your code with pytorch using GPU\n\n\nclass ChexnetTrainer ():\n\n    #---- Train the densenet network \n    #---- pathDirData - path to the directory that contains images\n    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n    #---- nnClassCount - number of output classes \n    #---- trBatchSize - batch size\n    #---- trMaxEpoch - number of epochs\n    #---- transResize - size of the image to scale down to (not used in current implementation)\n    #---- transCrop - size of the cropped image \n    #---- launchTimestamp - date\/time, used to assign unique name for the checkpoint file\n    #---- checkpoint - if not None loads the model and continues training\n    \n    def train (pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, nnClassCount,\n               trBatchSize, trMaxEpoch, transResize, transCrop, launchTimestamp, checkpoint):\n \n        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n        \n        model = torch.nn.DataParallel(model).cuda()\n                \n        #-------------------- SETTINGS: DATA TRANSFORMS\n        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        \n        transformList = []\n        transformList.append(transforms.RandomResizedCrop(transCrop))\n        transformList.append(transforms.RandomHorizontalFlip())\n        transformList.append(transforms.ToTensor())\n        transformList.append(normalize)      \n        transformSequence=transforms.Compose(transformList)\n\n        #-------------------- SETTINGS: DATASET BUILDERS\n        datasetTrain = DatasetGenerator(pathImageDirectory=pathDirData, \n                                        pathDatasetFile=pathFileTrain, \n                                        transform=transformSequence)\n        datasetVal =   DatasetGenerator(pathImageDirectory=pathDirData, \n                                        pathDatasetFile=pathFileVal,\n                                        transform=transformSequence)\n              \n        dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=trBatchSize,\n                                     shuffle=True,  num_workers=0, pin_memory=True)\n        dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=trBatchSize, \n                                   shuffle=False, num_workers=0, pin_memory=True)\n        \n        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), \n                                eps=1e-08, weight_decay=1e-5)\n        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n                \n        #-------------------- SETTINGS: LOSS\n        loss = torch.nn.BCELoss(size_average = True)\n        \n        #---- Load checkpoint \n        if checkpoint != None:\n            modelCheckpoint = torch.load(checkpoint)\n            model.load_state_dict(modelCheckpoint['state_dict'])\n            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n\n        \n        #---- TRAIN THE NETWORK\n        \n        lossMIN = 100000\n        \n        for epochID in range (0, trMaxEpoch):\n            \n            timestampTime = time.strftime(\"%H%M%S\")\n            timestampDate = time.strftime(\"%d%m%Y\")\n            timestampSTART = timestampDate + '-' + timestampTime\n                         \n            ChexnetTrainer.epochTrain (model, dataLoaderTrain, optimizer, scheduler, \n                                       trMaxEpoch, nnClassCount, loss)\n            lossVal, losstensor = ChexnetTrainer.epochVal (model, dataLoaderVal, optimizer, \n                                                           scheduler, trMaxEpoch, \n                                                           nnClassCount, loss)\n            \n            timestampTime = time.strftime(\"%H%M%S\")\n            timestampDate = time.strftime(\"%d%m%Y\")\n            timestampEND = timestampDate + '-' + timestampTime\n            \n            scheduler.step(losstensor.data)\n            \n            if lossVal < lossMIN:\n                lossMIN = lossVal    \n                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, 'm-' + launchTimestamp + '.pth.tar')\n                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n            else:\n                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n                     \n    #-------------------------------------------------------------------------------- \n       \n    def epochTrain (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss):\n        \n        model.train()\n        \n        for batchID, (input, target) in enumerate (dataLoader):\n                        \n            target = target.cuda(non_blocking=True)\n                 \n            varInput = torch.autograd.Variable(input)\n            varTarget = torch.autograd.Variable(target)         \n            varOutput = model(varInput)\n            \n            lossvalue = loss(varOutput, varTarget)\n                       \n            optimizer.zero_grad()\n            lossvalue.backward()\n            optimizer.step()\n            \n    #-------------------------------------------------------------------------------- \n        \n    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss):\n        \n        model.eval ()\n        \n        lossVal = 0\n        lossValNorm = 0\n        \n        losstensorMean = 0\n        \n        with torch.no_grad():\n            for i, (input, target) in enumerate (dataLoader):\n\n                target = target.cuda(non_blocking=True)\n\n                varInput = torch.autograd.Variable(input)\n                varTarget = torch.autograd.Variable(target)    \n                varOutput = model(varInput)\n\n                losstensor = loss(varOutput, varTarget)\n                losstensorMean += losstensor\n\n                lossVal += losstensor.item()\n                lossValNorm += 1\n            \n        outLoss = lossVal \/ lossValNorm\n        losstensorMean = losstensorMean \/ lossValNorm\n        \n        return outLoss, losstensorMean\n               \n    #--------------------------------------------------------------------------------     \n     \n    #---- Computes area under ROC curve \n    #---- dataGT - ground truth data\n    #---- dataPRED - predicted data\n    #---- classCount - number of classes\n    \n    def computeAUROC (dataGT, dataPRED, classCount):\n        \n        outAUROC = []\n        \n        datanpGT = dataGT.cpu().numpy()\n        datanpPRED = dataPRED.cpu().numpy()\n        \n        for i in range(classCount):\n            outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n            \n        return outAUROC\n        \n        \n    #--------------------------------------------------------------------------------  \n    \n    #---- Test the trained network \n    #---- pathDirData - path to the directory that contains images\n    #---- pathFileTrain - path to the file that contains image paths and label pairs (training set)\n    #---- pathFileVal - path to the file that contains image path and label pairs (validation set)\n    #---- nnArchitecture - model architecture 'DENSE-NET-121', 'DENSE-NET-169' or 'DENSE-NET-201'\n    #---- nnIsTrained - if True, uses pre-trained version of the network (pre-trained on imagenet)\n    #---- nnClassCount - number of output classes \n    #---- trBatchSize - batch size\n    #---- trMaxEpoch - number of epochs\n    #---- transResize - size of the image to scale down to (not used in current implementation)\n    #---- transCrop - size of the cropped image \n    #---- launchTimestamp - date\/time, used to assign unique name for the checkpoint file\n    #---- checkpoint - if not None loads the model and continues training\n    \n    def test (pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, \n              nnIsTrained, trBatchSize, transResize, transCrop, launchTimeStamp):   \n        \n        \n        CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n        \n        cudnn.benchmark = True\n        \n        #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, nnIsTrained).cuda()\n        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, nnIsTrained).cuda()\n        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, nnIsTrained).cuda()\n        \n        model = torch.nn.DataParallel(model).cuda() \n        \n        modelCheckpoint = torch.load(pathModel)\n        model.load_state_dict(modelCheckpoint['state_dict'])\n\n        #-------------------- SETTINGS: DATA TRANSFORMS, TEN CROPS\n        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        \n        #-------------------- SETTINGS: DATASET BUILDERS\n        transformList = []\n        transformList.append(transforms.Resize(transResize))\n        transformList.append(transforms.TenCrop(transCrop))\n        transformList.append(transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])))\n        transformList.append(transforms.Lambda(lambda crops: torch.stack([normalize(crop) for crop in crops])))\n        transformSequence=transforms.Compose(transformList)\n        \n        datasetTest = DatasetGenerator(pathImageDirectory=pathDirData, \n                                       pathDatasetFile=pathFileTest, \n                                       transform=transformSequence)\n        dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=trBatchSize,\n                                    num_workers=0, shuffle=False, pin_memory=True)\n        \n        outGT = torch.FloatTensor().cuda(non_blocking=True)\n        outPRED = torch.FloatTensor().cuda(non_blocking=True)\n       \n        model.eval()\n        with torch.no_grad():\n            for i, (input, target) in enumerate(dataLoaderTest):\n\n                #target = target.cuda()\n                target = target.cuda(non_blocking=True)\n                outGT = torch.cat((outGT, target), 0)\n\n                bs, n_crops, c, h, w = input.size()\n\n                varInput = torch.autograd.Variable(input.view(-1, c, h, w).cuda(), volatile=True)\n\n                out = model(varInput)\n                outMean = out.view(bs, n_crops, -1).mean(1)\n\n                outPRED = torch.cat((outPRED, outMean.data), 0)\n\n        aurocIndividual = ChexnetTrainer.computeAUROC(outGT, outPRED, nnClassCount)\n        aurocMean = np.array(aurocIndividual).mean()\n        \n        print ('AUROC mean ', aurocMean)\n        \n        for i in range (0, len(aurocIndividual)):\n            print (CLASS_NAMES[i], ' ', aurocIndividual[i])\n        \n     \n        return","bc50641b":"def main ():\n    runTest()\n    #runTrain()\n\ndef runTrain():\n    \n    DENSENET121 = 'DENSE-NET-121'\n    DENSENET169 = 'DENSE-NET-169'\n    DENSENET201 = 'DENSE-NET-201'\n    \n    timestampTime = time.strftime(\"%H%M%S\")\n    timestampDate = time.strftime(\"%d%m%Y\")\n    timestampLaunch = timestampDate + '-' + timestampTime\n    \n    #---- Path to the directory with images\n    pathDirData = '\/kaggle\/input\/sample\/sample\/sample\/images'\n    \n    #---- Paths to the files with training, validation and testing sets.\n    #---- Each file should contains pairs [path to image, output vector]\n    #---- Example: images_011\/00027736_001.png 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n    pathFileTrain = 'train_1.txt'\n    pathFileVal = 'val_1.txt'\n    pathFileTest = 'val_1.txt'\n    \n    #---- Neural network parameters: type of the network, is it pre-trained \n    #---- on imagenet, number of classes\n    nnArchitecture = DENSENET121\n    nnIsTrained = True\n    nnClassCount = 14\n    \n    #---- Training settings: batch size, maximum number of epochs\n    trBatchSize = 16\n    trMaxEpoch = 50\n    \n    #---- Parameters related to image transforms: size of the down-scaled image, cropped image\n    imgtransResize = 256\n    imgtransCrop = 224\n        \n    pathModel = 'm-' + timestampLaunch + '.pth.tar'\n    \n    print ('Training NN architecture = ', nnArchitecture)\n    ChexnetTrainer.train(pathDirData, pathFileTrain, pathFileVal, nnArchitecture, nnIsTrained, \n                         nnClassCount, trBatchSize, trMaxEpoch, imgtransResize, imgtransCrop, \n                         timestampLaunch, None)\n    \n    print ('Testing the trained model')\n    ChexnetTrainer.test(pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, \n                        nnIsTrained, trBatchSize, imgtransResize, imgtransCrop, timestampLaunch)\n\n#-------------------------------------------------------------------------------- \n\ndef runTest():\n    \n    pathDirData = '\/kaggle\/input\/sample\/sample\/sample\/images'\n    pathFileTest = '.\/test_1.txt'\n    nnArchitecture = 'DENSE-NET-121'\n    nnIsTrained = True\n    nnClassCount = 14\n    trBatchSize = 16\n    imgtransResize = 256\n    imgtransCrop = 224\n    \n    pathModel = '.\/m-25082020-060921.pth.tar'\n    \n    timestampLaunch = ''\n    \n    ChexnetTrainer.test(pathDirData, pathFileTest, pathModel, nnArchitecture, nnClassCount, \n                        nnIsTrained, trBatchSize, imgtransResize, imgtransCrop, timestampLaunch)\n\n#-------------------------------------------------------------------------------- \n\nif __name__ == '__main__':\n    main()","1c67b4cf":"class HeatmapGenerator ():\n    \n    #---- Initialize heatmap generator\n    #---- pathModel - path to the trained densenet model\n    #---- nnArchitecture - architecture name DENSE-NET121, DENSE-NET169, DENSE-NET201\n    #---- nnClassCount - class count, 14 for chxray-14\n\n \n    def __init__ (self, pathModel, nnArchitecture, nnClassCount, transCrop):\n       \n        #---- Initialize the network\n        if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, True).cuda()\n        elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, True).cuda()\n        elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, True).cuda()\n          \n        model = torch.nn.DataParallel(model).cuda()\n\n        modelCheckpoint = torch.load(pathModel)\n        model.load_state_dict(modelCheckpoint['state_dict'])\n\n        self.model = model.module.densenet121.features\n        self.model.eval()\n        \n        #---- Initialize the weights\n        self.weights = list(self.model.parameters())[-2]\n\n        #---- Initialize the image transform - resize + normalize\n        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        transformList = []\n        transformList.append(transforms.Resize(transCrop))\n        transformList.append(transforms.ToTensor())\n        transformList.append(normalize)      \n        \n        self.transformSequence = transforms.Compose(transformList)\n    \n    #--------------------------------------------------------------------------------\n     \n    def generate (self, pathImageFile, pathOutputFile, transCrop):\n        \n        #---- Load image, transform, convert \n        imageData = Image.open(pathImageFile).convert('RGB')\n        imageData = self.transformSequence(imageData)\n        imageData = imageData.unsqueeze_(0)\n        \n        input = torch.autograd.Variable(imageData)\n        \n        self.model.cuda()\n        output = self.model(input.cuda())\n        \n        #---- Generate heatmap\n        heatmap = None\n        for i in range (0, len(self.weights)):\n            map = output[0,i,:,:]\n            if i == 0: heatmap = self.weights[i] * map\n            else: heatmap += self.weights[i] * map\n        \n        #---- Blend original and heatmap \n        npHeatmap = heatmap.cpu().data.numpy()\n\n        imgOriginal = cv2.imread(pathImageFile, 1)\n        imgOriginal = cv2.resize(imgOriginal, (transCrop, transCrop))\n        \n        cam = npHeatmap \/ np.max(npHeatmap)\n        cam = cv2.resize(cam, (transCrop, transCrop))\n        heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n              \n        img = heatmap * 0.5 + imgOriginal\n            \n        cv2.imwrite(pathOutputFile, img)\n        \n#-------------------------------------------------------------------------------- \n\npathInputImage = '\/kaggle\/input\/sample\/sample\/sample\/images\/00004490_006.png'\npathOutputImage = 'heatmap.png'\npathModel = 'm-25012018-123527.pth.tar'\n\nnnArchitecture = 'DENSE-NET-121'\nnnClassCount = 14\n\ntransCrop = 224\n\nh = HeatmapGenerator(pathModel, nnArchitecture, nnClassCount, transCrop)\nh.generate(pathInputImage, pathOutputImage, transCrop)","a3341919":"## Chargement des donn\u00e9es.","fccfd781":"# 2. DEEP LEARNING","411ac945":"## Visualization des donn\u00e9es.","47cb0692":"# 1. EDA\nNous commencons par un peu d'exploration et de visualization pour mieux comprendre nos donn\u00e9es.","a324f133":"## Pretraitement des donn\u00e9es.","c7d23f26":"Le travail a ete divise en 2 grandes parties: \n- la premiere partie(EDA) c'est pour nous aider a comprendre les donn\u00e9es dans leurs organisation et leurs structures. Comme dans tous projet de data science, c'est une etape importante a ne pas negliger.\n- La deuxieme partie concerne le coeurs du projet. C'est a dire la finalisation du pretraitement, la modelisation, l'entrainement suivie de l'evaluation des performance, la prediction et en fin la generation du **CAM(class activation Map)**. C'est dans cette partie que nous executons le code de la version du **chexNet** que nous avons utilis\u00e9 pour ce projet.","11a8762b":"## Import de toutes les librairies necessaires.","f24ca35d":"### Reference: https:\/\/github.com\/zoogzog\/chexnet"}}