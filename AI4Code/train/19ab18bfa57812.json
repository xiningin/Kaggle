{"cell_type":{"a26e8de1":"code","0639062a":"code","50911a72":"code","bc05432e":"code","25ff2cf4":"code","6543708a":"code","905c13a7":"code","d941c022":"code","9b5a18a8":"code","2e7ad968":"code","f57f3cab":"code","f29108a2":"code","071e585a":"code","3c5f8a00":"code","3f024299":"code","4eebd25f":"code","9ca44d75":"code","f31bae43":"code","503de530":"code","863450a4":"code","782fe55a":"code","c60d8a10":"code","07120b00":"code","6a39d291":"code","87645dce":"code","511abfdb":"code","f8c64db1":"code","8d50eca6":"code","19e3866c":"code","9911699e":"code","1ede4107":"code","36fc821c":"code","57fe922d":"code","1e8cef1f":"code","c1fd2883":"code","67d95ec2":"code","0b21d390":"code","90fbcb8d":"code","087ef02c":"code","94cf9d8b":"code","0f7ab34b":"code","0f9bf1c2":"code","7b559274":"code","d30bff5f":"code","fa2e2f9a":"code","ad3b04b5":"code","18a3293e":"code","a1d65d77":"code","f9f71f98":"code","c1f83f29":"code","681f3c56":"code","58a966b4":"code","537459ca":"code","3693b4a5":"code","47a9c71a":"code","5934432f":"code","e590692f":"code","9594267b":"code","d90b4d38":"code","6d4b6870":"code","cc95b845":"code","c9cb41c3":"code","2342f4cc":"code","2188bd0a":"code","ad74bc5e":"code","af690710":"code","6fba2ae5":"code","b125bfc1":"code","51135b4c":"code","7b6f5ed5":"code","73e082a9":"code","6b0f5af6":"code","64590b3f":"code","4ca10fff":"code","ca5782d2":"code","4b1e9b36":"code","30f50cd3":"code","61fae7e6":"code","d9ea1cef":"code","360e1f69":"code","6cb46ead":"code","4f099782":"code","1a536bf5":"code","f2b226c8":"code","d535ac48":"code","c553ee37":"markdown","a5acba04":"markdown","1194adea":"markdown","fcd33dcd":"markdown","6a2d91f0":"markdown","57ba51f8":"markdown","a454117b":"markdown","d84726b2":"markdown","14dcbe9d":"markdown","7bd9c926":"markdown"},"source":{"a26e8de1":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","0639062a":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, random_split, DataLoader\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid","50911a72":"DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/'\nTRAIN_DIR = DATA_DIR + \"\/\" + \"train\"\nTEST_DIR = DATA_DIR + \"\/\" + \"test\"\nTRAIN_CSV = DATA_DIR +\"\/\" + \"train.csv\"","bc05432e":"train_df = pd.read_csv(TRAIN_CSV)\ntrain_df.head()","25ff2cf4":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","6543708a":"rev_labels = dict()\nfor key in labels.keys():\n    rev_labels[labels[key]] = key","905c13a7":"rev_labels","d941c022":"def num_to_name(labels):\n    return [labels[i] for i in labels]","9b5a18a8":"def name_to_num(labels):\n    return [rev_labels[i] for i in labels]","2e7ad968":"def set_seed(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","f57f3cab":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","f29108a2":"set_seed(17)","071e585a":"def encode_labels(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target","3c5f8a00":"def decode_labels(target, thresh=0.5, return_label=False):\n    result = []\n    for i, tgt in enumerate(target):\n        if tgt > thresh:\n            if return_label:\n                result.append(str(i) + \":\" + labels[i] + \"\/\")\n            else:\n                result.append(str(i))\n            \n    return result","3f024299":"class UnNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n        return tensor","4eebd25f":"def display_img(img, label=None, unnorm=False, unnorm_obj=None, invert=True, return_label=True):\n    if unnorm and unnorm_obj != None:\n        img = unnorm_obj(img)\n    \n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    \n    if label != None:\n        plt.title(decode_labels(label, return_label=return_label))","9ca44d75":"def display_batch(batch, unnorm=False, unnorm_obj=None, invert=True):    \n    imgs, labels = batch\n    \n    if unnorm and unnorm_obj:\n        unnorm_imgs = []\n        for img in imgs:\n            if invert:\n                unnorm_imgs.append(1 - unnorm_obj(img))\n            else:\n                unnorm_imgs.append(unnorm_obj(img))\n        imgs = unnorm_imgs\n    else:\n        if invert:\n            imgs = 1 - imgs\n    \n    ig, ax = plt.subplots(figsize=(16, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(imgs, nrow=16).permute(1, 2, 0))","f31bae43":"class ProteinDataset(nn.Module):\n    def __init__(self, root_dir, label_df, transforms=None):\n        assert(os.path.exists(root_dir))\n        self.root_dir = root_dir\n        self.label_df = label_df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.label_df)\n    \n    def __getitem__(self, idx):\n        row = self.label_df.loc[idx]\n        img_id, label = row['Image'], row['Label']\n        img = Image.open(self.root_dir + \"\/\" + str(img_id) + \".png\")\n        if self.transforms:\n            img = self.transforms(img)\n        return img, encode_labels(label)","503de530":"'''\nThis code can be used to get mean and std of dataset\n\nmean = 0.\nstd = 0.\nnb_samples = 0.\nfor imgs, _ in loader:\n    batch_samples = imgs.size(0)\n    imgs = imgs.view(batch_samples, imgs.size(1), -1)\n    mean += imgs.mean(2).sum(0)\n    std += imgs.std(2).sum(0)\n    nb_samples += batch_samples\n\nmean \/= nb_samples\nstd \/= nb_samples\n'''","863450a4":"mean = [0.0793, 0.0530, 0.0545]\nstd = [0.1290, 0.0886, 0.1376]","782fe55a":"normalize = transforms.Normalize(mean=mean, std=std)\n\ntrain_tf = transforms.Compose([\n    transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n    transforms.RandomHorizontalFlip(), \n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    normalize,\n    transforms.RandomErasing(inplace=True)\n])\n\ntest_tf = transforms.Compose([\n    transforms.RandomCrop(512, padding=8, padding_mode='symmetric'),\n    transforms.ToTensor(),\n    normalize\n])","c60d8a10":"val_pct = 0.1","07120b00":"msk = np.random.rand(len(train_df)) < (1- val_pct)","6a39d291":"train_split_df = train_df[msk].reset_index()\nval_split_df = train_df[~msk].reset_index()","87645dce":"len(train_split_df), len(val_split_df)","511abfdb":"train_ds = ProteinDataset(TRAIN_DIR, train_split_df, train_tf)\nvalid_ds = ProteinDataset(TRAIN_DIR, val_split_df, test_tf)","f8c64db1":"bs = 32","8d50eca6":"train_loader = DataLoader(train_ds, bs, shuffle=True, num_workers=4, pin_memory=True)\nvalid_loader = DataLoader(valid_ds, bs, num_workers=4, pin_memory=True)","19e3866c":"img, label = train_ds[0]","9911699e":"display_img(img, label)","1ede4107":"unnorm = UnNormalize(mean, std)","36fc821c":"display_img(img, label, unnorm=True, unnorm_obj=unnorm)","57fe922d":"batch = next(iter(train_loader))","1e8cef1f":"display_batch(batch)","c1fd2883":"def F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-15))\n    recall = torch.mean(TP \/ (TP + FN + 1e-15))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-15)\n    return F2.mean(0)","67d95ec2":"class AvgStats(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.losses =[]\n        self.F1 =[]\n        self.its = []\n        \n    def append(self, loss, F1, it):\n        self.losses.append(loss)\n        self.F1.append(F1)\n        self.its.append(it)","0b21d390":"import math\n\n\nclass CLR(object):\n    def __init__(self, optim, bn, base_lr=1e-7, max_lr=100):\n        self.base_lr = base_lr\n        self.max_lr = max_lr\n        self.optim = optim\n        self.bn = bn - 1\n        ratio = self.max_lr\/self.base_lr\n        self.mult = ratio ** (1\/self.bn)\n        self.best_loss = 1e9\n        self.iteration = 0\n        self.lrs = []\n        self.losses = []\n        \n    def calc_lr(self, loss):\n        self.iteration +=1\n        if math.isnan(loss) or loss > 4 * self.best_loss:\n            return -1\n        if loss < self.best_loss and self.iteration > 1:\n            self.best_loss = loss\n            \n        mult = self.mult ** self.iteration\n        lr = self.base_lr * mult\n        \n        self.lrs.append(lr)\n        self.losses.append(loss)\n        \n        return lr\n        \n    def plot(self, start=10, end=-5):\n        plt.xlabel(\"Learning Rate\")\n        plt.ylabel(\"Losses\")\n        plt.plot(self.lrs[start:end], self.losses[start:end])\n        plt.xscale('log')\n        \n        \n    def plot_lr(self):\n        plt.xlabel(\"Iterations\")\n        plt.ylabel(\"Learning Rate\")\n        plt.plot(self.lrs)\n        plt.yscale('log')","90fbcb8d":"class OneCycle(object):\n    def __init__(self, nb, max_lr, momentum_vals=(0.95, 0.85), prcnt= 10, div=10, use_cosine=False):\n        self.nb = nb\n        self.div = div\n        self.high_lr = max_lr\n        self.low_mom = momentum_vals[1]\n        self.high_mom = momentum_vals[0]\n        self.use_cosine = use_cosine\n        if self.use_cosine:\n            self.prcnt = 0\n        else:\n            self.prcnt = prcnt\n        self.iteration = 0\n        self.lrs = []\n        self.moms = []\n        if self.use_cosine:\n            self.step_len =  int(self.nb \/ 4)\n        else:\n            self.step_len =  int(self.nb * (1- prcnt\/100)\/2)\n        \n    def calc(self):\n        if self.use_cosine:\n            lr = self.calc_lr_cosine()\n            mom = self.calc_mom_cosine()\n        else:\n            lr = self.calc_lr()\n            mom = self.calc_mom()\n        self.iteration += 1\n        return (lr, mom)\n        \n    def calc_lr(self):\n        if self.iteration ==  0:\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration > 2 * self.step_len:\n            ratio = (self.iteration - 2 * self.step_len) \/ (self.nb - 2 * self.step_len)\n            #lr = self.high_lr * ( 1 - 0.99 * ratio)\/self.div\n            lr = (self.high_lr \/ self.div) * (1- ratio * (1 - 1\/self.div))\n        elif self.iteration > self.step_len:\n            ratio = 1- (self.iteration -self.step_len)\/self.step_len\n            lr = self.high_lr * (1 + ratio * (self.div - 1)) \/ self.div\n        else :\n            ratio = self.iteration\/self.step_len\n            lr = self.high_lr * (1 + ratio * (self.div - 1)) \/ self.div\n        self.lrs.append(lr)\n        return lr\n\n    def calc_mom(self):\n        if self.iteration == 0:\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration > 2 * self.step_len:\n            mom = self.high_mom\n        elif self.iteration > self.step_len:\n            ratio = (self.iteration -self.step_len)\/self.step_len\n            mom = self.low_mom + ratio * (self.high_mom - self.low_mom)\n        else :\n            ratio = self.iteration\/self.step_len\n            mom = self.high_mom - ratio * (self.high_mom - self.low_mom)\n        self.moms.append(mom)\n        return mom\n\n    def calc_lr_cosine(self):\n        if self.iteration ==  0:\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.lrs.append(self.high_lr\/self.div)\n            return self.high_lr\/self.div\n        elif self.iteration > self.step_len:\n            ratio = (self.iteration -self.step_len)\/(self.nb - self.step_len)\n            lr = (self.high_lr\/self.div) + 0.5 * (self.high_lr - self.high_lr\/self.div) * (1 + math.cos(math.pi * ratio))\n        else :\n            ratio = self.iteration\/self.step_len\n            lr = self.high_lr - 0.5 * (self.high_lr - self.high_lr\/self.div) * (1 + math.cos(math.pi * ratio))\n        self.lrs.append(lr)\n        return lr\n\n    def calc_mom_cosine(self):\n        if self.iteration == 0:\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration == self.nb:\n            self.iteration = 0\n            self.moms.append(self.high_mom)\n            return self.high_mom\n        elif self.iteration > self.step_len:\n            ratio = (self.iteration -self.step_len)\/(self.nb - self.step_len)\n            mom = self.high_mom - 0.5 * (self.high_mom - self.low_mom) * (1 + math.cos(math.pi * ratio))\n        else :\n            ratio = self.iteration\/self.step_len\n            mom = self.low_mom + 0.5 * (self.high_mom - self.low_mom) * (1 + math.cos(math.pi * ratio))\n        self.moms.append(mom)\n        return mom","087ef02c":"def save_checkpoint(model, is_best, filename='data\/checkpoint.pth'):\n    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n    if is_best:\n        torch.save(model.state_dict(), filename)  # save checkpoint\n    else:\n        print (\"=> Validation Accuracy did not improve\")","94cf9d8b":"def load_checkpoint(model, filename = 'data\/checkpoint.pth'):\n    sd = torch.load(filename, map_location=lambda storage, loc: storage)\n    names = set(model.state_dict().keys())\n    for n in list(sd.keys()):\n        if n not in names and n+'_raw' in names:\n            if n+'_raw' not in sd: sd[n+'_raw'] = sd[n]\n            del sd[n]\n    model.load_state_dict(sd)","0f7ab34b":"class AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=1):\n        super().__init__()\n        self.adavgp = nn.AdaptiveAvgPool2d(sz)\n        self.adamaxp = nn.AdaptiveMaxPool2d(sz)\n        \n    def forward(self, x):\n        x = torch.cat([self.adavgp(x), self.adamaxp(x)], 1)\n        x = x.view(x.size(0),-1)\n        return x","0f9bf1c2":"class CustomClassifier(nn.Module):\n    def __init__(self, in_features, intermed_bn= 512, out_features=10, dout=0.25):\n        super().__init__()\n        self.fc_bn0 = nn.BatchNorm1d(in_features)\n        self.dropout0 = nn.Dropout(dout)\n        self.fc0 = nn.Linear(in_features, intermed_bn, bias=True)\n        self.fc_bn1 = nn.BatchNorm1d(intermed_bn, momentum=0.01)\n        self.dropout1 = nn.Dropout(dout * 2)\n        self.fc1 = nn.Linear(intermed_bn, out_features, bias=True)\n        \n    def forward(self, x):\n        x = self.fc_bn0(x)\n        x = self.dropout0(x)\n        x = F.relu(self.fc0(x))\n        x = self.fc_bn1(x)\n        x = self.dropout1(x)\n        x = self.fc1(x)\n        return x","7b559274":"def update_lr(optimizer, lr):\n    for g in optimizer.param_groups:\n        g['lr'] = lr","d30bff5f":"def update_mom(optimizer, mom):\n    for g in optimizer.param_groups:\n        g['momentum'] = mom","fa2e2f9a":"def find_lr(model, loader, device):\n    t = tqdm(loader, leave=False, total=len(loader))\n    running_loss = 0.\n    avg_beta = 0.98\n    model.train()\n    for i, (ip, tgt) in enumerate(t):\n        ip, tgt = ip.to(device), tgt.to(device)\n        output = torch.sigmoid(model(ip))\n        loss = criterion(output, tgt)\n\n        running_loss = avg_beta * running_loss + (1-avg_beta) *loss.item()\n        smoothed_loss = running_loss \/ (1 - avg_beta**(i+1))\n        t.set_postfix(loss=smoothed_loss)\n\n        lr = clr.calc_lr(smoothed_loss)\n        if lr == -1 :\n            break\n        update_lr(optimizer, lr)   \n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()","ad3b04b5":"model = models.resnet34(pretrained=True)","18a3293e":"model","a1d65d77":"model.avgpool = AdaptiveConcatPool2d()\nmodel.fc = CustomClassifier(in_features=model.fc.in_features*2, out_features=10)","f9f71f98":"for param in model.parameters():\n    param.require_grad = True\n    \nmodel = model.to(device)","c1f83f29":"criterion = nn.BCELoss()","681f3c56":"optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)","58a966b4":"save_checkpoint(model, True, 'init.pth')","537459ca":"clr = CLR(optimizer, len(train_loader))","3693b4a5":"find_lr(model, train_loader, device)","47a9c71a":"clr.plot()","5934432f":"def train(epoch, model, optimizer, use_cycle=False, onecycle=None):\n    model.train()\n    global trn_F1, trn_losses, trn_time\n    running_loss = 0.\n    running_F1 = 0.\n    \n    start_time = time.time()\n    \n    t = tqdm(train_loader, leave=False, total=len(train_loader))\n\n    for i, (ip, tgt) in enumerate(t):\n        ip, tgt = ip.to(device), tgt.to(device)\n        \n        if use_cycle:    \n            lr, mom = onecycle.calc()\n            update_lr(optimizer, lr)\n            update_mom(optimizer, mom)\n                                    \n        output = torch.sigmoid(model(ip))\n        loss = criterion(output, tgt)\n        running_loss += loss.item()\n            \n        # Append outputs\n        running_F1 += F_score(tgt, output)\n        \n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    trn_time = time.time() - start_time        \n    trn_F1 = running_F1\/len(train_loader)\n    trn_losses = running_loss\/len(train_loader)","e590692f":"def test(model):\n    with torch.no_grad():\n        model.eval()\n        global best_F1\n        global val_F1, val_losses, val_time\n        running_loss = 0.\n        running_F1 = 0.\n        start_time = time.time()\n        \n        t = tqdm(valid_loader, leave=False, total=len(valid_loader))\n        \n        for i, (ip, tgt) in enumerate(t):\n            ip, tgt = ip.to(device), tgt.to(device)\n            output = torch.sigmoid(model(ip))\n            loss = criterion(output, tgt)\n            running_loss += loss.item()\n            running_F1 += F_score(tgt, output)\n            \n        val_time = time.time() - start_time\n        F1_score = running_F1\/len(valid_loader)\n        if F1_score > best_F1:\n            best_F1 = F1_score\n            save_checkpoint(model, True, '.\/best_model.pth')\n            \n        val_F1 = F1_score\n        val_losses = running_loss\/len(valid_loader)","9594267b":"train_stats = AvgStats()\ntest_stats = AvgStats()","d90b4d38":"best_F1 = 0\ntrn_time = 0\ntrn_losses = 0.0\ntrn_F1 = 0.0\nval_losses = 0.0\nval_F1 = 0.0\nval_time = 0","6d4b6870":"def fit(model, optimizer, epochs, sched=None, use_cycle=False, onecycle=None):\n    print(\"Epoch\\tTrn_loss\\tVal_loss\\tTrn_F1\\t\\tVal_F1\")\n    for j in range(epochs):\n        train(j, model, optimizer, use_cycle=use_cycle, onecycle=onecycle)\n        train_stats.append(trn_losses, trn_F1, trn_time)\n        test(model)\n        test_stats.append(val_losses, val_F1, val_time)\n        if sched:\n            sched.step(j)\n        print(\"{}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\\t{:06.8f}\"\n              .format(j+1, trn_losses, val_losses, trn_F1, val_F1))","cc95b845":"epochs = 15","c9cb41c3":"load_checkpoint(model, 'init.pth')","2342f4cc":"optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)","2188bd0a":"ocp = OneCycle(int(len(train_ds) * epochs \/bs), 1e-1, use_cosine=True)\n#sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)","ad74bc5e":"import time","af690710":"fit(model, optimizer, epochs, use_cycle=True, onecycle=ocp)","6fba2ae5":"plt.xlabel(\"Epochs\")\nplt.ylabel(\"Losses\")\nplt.plot(train_stats.losses, 'r', label='train')\nplt.plot(test_stats.losses, 'g', label='valid')\nplt.legend()\nplt.show()","b125bfc1":"plt.xlabel(\"Epochs\")\nplt.ylabel(\"F1-score\")\nplt.plot(train_stats.F1, 'r', label='train')\nplt.plot(test_stats.F1, 'g', label='valid')\nplt.legend()\nplt.show()","51135b4c":"def pred_single(img, return_label=True):\n    with torch.no_grad():\n        model.eval()\n        bs_img = img.unsqueeze(0)\n        bs_img = bs_img.to(device)\n        preds = torch.sigmoid(model(bs_img))\n        prediction = preds[0]\n        display_img(img, prediction, return_label)","7b6f5ed5":"TEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv'","73e082a9":"test_df = pd.read_csv(TEST_CSV)","6b0f5af6":"test_ds = ProteinDataset(TEST_DIR, test_df, test_tf)","64590b3f":"img, label = test_ds[100]","4ca10fff":"pred_single(img)","ca5782d2":"test_loader = DataLoader(test_ds, bs, num_workers=4, pin_memory=True)","4b1e9b36":"load_checkpoint(model, '.\/best_model.pth')","30f50cd3":"def predict(loader):\n    with torch.no_grad():\n        torch.cuda.empty_cache()\n        model.eval()\n        preds = []\n        t = tqdm(loader, leave=False, total=len(loader))\n        for i, (ip, _) in enumerate(t):\n            ip = ip.to(device)\n            output = torch.sigmoid(model(ip))\n            preds.append(output.cpu().detach())\n        preds = torch.cat(preds)\n        return [\" \".join(decode_labels(pred)) for pred in preds]","61fae7e6":"preds = predict(test_loader)","d9ea1cef":"len(preds), len(test_df)","360e1f69":"preds","6cb46ead":"sub_df = pd.read_csv(TEST_CSV)","4f099782":"sub_df.head()","1a536bf5":"sub_df['Label'] = preds","f2b226c8":"sub_df.head()","d535ac48":"sub_df.to_csv('submission.csv', index=False)","c553ee37":"# Display Images","a5acba04":"# Save and load checkpoint","1194adea":"# AdaptiveConcatPool and custom classifier","fcd33dcd":"# F1 Score\/Stats Function","6a2d91f0":"# Set optimizer\/loss and find lr","57ba51f8":"# Train and Test","a454117b":"# One Cycle Policy\n\n(Github: https:\/\/github.com\/nachiket273\/One_Cycle_Policy)","d84726b2":"# CLR\n\n(Github: https:\/\/github.com\/nachiket273\/One_Cycle_Policy)","14dcbe9d":"# Dataset","7bd9c926":"# Data Loading and some helper functions"}}