{"cell_type":{"c196db7d":"code","c2ec53ce":"code","ca7e36a5":"code","09a54f63":"code","98e1b6ef":"code","afa430b4":"code","b149c639":"code","96b33ae9":"code","b211b9a5":"code","f39c6800":"code","fd57377b":"code","aecc0180":"code","a0511dce":"code","13dead14":"code","f6d18502":"code","034dc7e2":"code","bad2274e":"code","50597cd0":"code","7cade41f":"code","91eec6c9":"code","d44c84bd":"code","69222951":"code","df81d9af":"code","955437d8":"code","579ad90d":"code","1592ded5":"code","008dc794":"code","96cb0bc2":"code","0bfe1e82":"markdown","7188a0c5":"markdown"},"source":{"c196db7d":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport\nimport numpy as np\nimport pandas as pd\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom lightgbm import LGBMClassifier","c2ec53ce":"# \u4e00\u89a7\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\ndf_train = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/test.csv')\ndf_action = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/actions.csv')","ca7e36a5":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\ndf_train.head()","09a54f63":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\uff08\u30c6\u30b9\u30c8\u306a\u306e\u3067\u7b54\u3048\u306f\u4ed8\u4e0e\u3055\u308c\u3066\u3044\u306a\u3044\u306e\u304c\u308f\u304b\u308a\u307e\u3059\uff09\ndf_test.head()","98e1b6ef":"# train\u306e\u4e2d\u304b\u3089\u6700\u521d\u306e\u884c\u306b\u3064\u3044\u3066\u3001\u5b9f\u969b\u306e\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092\u307f\u3066\u307f\u307e\u3057\u3087\u3046\ndf = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/train\/train_0000.csv')","afa430b4":"# 227\u884c x 21\u30ab\u30e9\u30e0\uff08\u6642\u9593+20\u30c1\u30e3\u30f3\u30cd\u30eb\u306e\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\uff09\u306b\u306a\u3063\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\n# \u305f\u3060\u3057\u3001\u53ef\u5909\u9577\u30c7\u30fc\u30bf\u3067\u3059\u306e\u3067\u884c\u6570\u306e\u65b9\u306f\u6e2c\u5b9a\u3054\u3068\u306b\u305d\u308c\u305e\u308c\u7570\u306a\u308a\u307e\u3059\ndf","b149c639":"# \u898b\u3084\u3059\u3044\u3088\u3046\u306bMinMaxScaler\u306b\u304b\u3051\u3066\u304a\u304d\u307e\u3059\nscaler = MinMaxScaler()\ndf.iloc[:] = scaler.fit_transform(df)","96b33ae9":"# \u5de6\u53f3\u306e\u8098\u90e8\u306e\u6b6a\u307f\u3092\u53ef\u8996\u5316\u3057\u3066\u307f\u307e\u3057\u305f\u3002\u307e\u305a\u5de6\u3067\u30b8\u30e3\u30d6\u3092\u6253\u3063\u305f\u306e\u3061\u306b\u53f3\u3067\u30b9\u30c8\u30ec\u30fc\u30c8\u3001\u30d5\u30c3\u30af\u3001\u30a2\u30c3\u30d1\u30fc\u3068\u9023\u6253\u3057\u3066\u3044\u308b\u306e\u304c\u898b\u3066\u3068\u308c\u307e\u3059\u306d\uff01\n# \u4ed6\u306e\u30c1\u30e3\u30cd\u30eb\u306b\u3082\u6709\u7528\u306a\u60c5\u5831\u304c\u305f\u304f\u3055\u3093\u3042\u308a\u307e\u3059\u306e\u3067\u3001\u672c\u8ab2\u984c\u306f\u304b\u306a\u308a\u4e88\u60f3\u6027\u304c\u9ad8\u3044\u3053\u3068\u304c\u898b\u8fbc\u307e\u308c\u308b\u3067\u3057\u3087\u3046\u3002\u76ee\u6307\u305b\u7cbe\u5ea6100%\uff01\nf_0 = 'ELBOW_L'\nf_1 = 'ELBOW_R'\n\nplt.figure(figsize=[15,5])\nplt.plot(df.Time, df[f_0], c='r', label=f_0)\nplt.plot(df.Time, df[f_1], c='b', label=f_1)\nplt.xlabel('Time')\nplt.show()","b211b9a5":"DataFrame(df.mean()).T","f39c6800":"# \u3055\u3066\u3001\u7279\u5fb4\u91cf\u306e\u62bd\u51fa\u65b9\u6cd5\u3082\u30e2\u30c7\u30ea\u30f3\u30b0\u306e\u30a2\u30d7\u30ed\u30fc\u30c1\u3082\u69d8\u3005\u8003\u3048\u3089\u308c\u3001\u305d\u308c\u3089\u306f\u30b3\u30f3\u30da\u671f\u9593\u4e2d\u306b\u6bb5\u968e\u3092\u8ffd\u3063\u3066\u5c55\u958b\u3057\u3066\u3044\u304d\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u304c\u3001\n# \u307e\u305a\u306f\u5404\u30c1\u30e3\u30cd\u30eb\u306e\u5e73\u5747\u5024\u3092\u7279\u5fb4\u91cf\u3068\u3059\u308b\u30b7\u30f3\u30d7\u30eb\u306a\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u3092\u69cb\u7bc9\u3059\u308b\u3068\u3053\u308d\u304b\u3089\u59cb\u3081\u305f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n\ndef add_mean_as_feature(df):\n    df_temp = DataFrame()\n    for path in df.file_path:\n        df_sensor = pd.read_csv('..\/input\/data-science-spring-osaka-2021'+path)\n        df_sensor = DataFrame(df_sensor.mean()).T # \u5e73\u5747\u5024\u3092\u96c6\u8a08\n        df_temp = pd.concat([df_temp, df_sensor])\n    df_temp.columns = [col+'_mean' for col in df_temp.columns] # \u30ab\u30e9\u30e0\u540d\u306b\u5e73\u5747\u3092\u3068\u3063\u305f\u3053\u3068\u304c\u308f\u304b\u308b\u3088\u3046\u306b\u672b\u5c3e\u306b'_mean'\u3092\u4ed8\u8a18\n    df_temp.index = df.index\n    df = pd.concat([df, df_temp], axis=1)\n    return df","fd57377b":"# \u4e0a\u8a18\u51e6\u7406\u3092\u9069\u7528\u3057\u307e\u3059\ndf_train = add_mean_as_feature(df_train)\ndf_test = add_mean_as_feature(df_test)","aecc0180":"# \u5e73\u5747\u5024\u3092\u6a2a\u6301\u3061\u3067\u7d50\u5408\u3067\u304d\u3066\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308a\u307e\u3059\ndf_train","a0511dce":"df_test","13dead14":"# \u7279\u5fb4\u91cf\uff08=\u8aac\u660e\u5909\u6570\uff09\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\uff08\u88ab\u8aac\u660e\u5909\u6570\uff09\u306b\u5206\u5272\u3057\u3066\u304a\u304d\u307e\u3059\ny_train = df_train.action_seq\nX_train = df_train.drop(['file_path', 'action_seq'], axis=1)\nX_test = df_test.drop(['file_path'], axis=1)","f6d18502":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\u3057\u3066\u304a\u304d\u307e\u3059\nle = LabelEncoder()\ny_train = le.fit_transform(y_train)","034dc7e2":"# one-hot\u30a8\u30f3\u30b3\u30fc\u30c9\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\ny_train","bad2274e":"# column\u540d\u3092\u53d6\u5f97\nnum_cols = X_train.columns.values\n# num_cols\n\n# \u6b63\u898f\u5316\u21d2mlp\u306f\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u3092\u305d\u308d\u3048\u305f\u65b9\u304c\u3088\u3044\nfrom sklearn.preprocessing import StandardScaler  \nscaler = StandardScaler()\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\nX_test[num_cols] = scaler.fit_transform(X_test[num_cols])","50597cd0":"# X_train.head()","7cade41f":"# \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u5b9a\u30c7\u30fc\u30bf\u3092\u5206\u5272\nx_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20)\n\nprint(x_train.shape)\nprint(x_val.shape)","91eec6c9":"#\u30e2\u30c7\u30eb\u306e\u69cb\u7bc9\uff08\u3068\u308a\u3042\u3048\u305a\u30b7\u30f3\u30d7\u30eb\u306b\uff09\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\ndrop=0.35\nmodel = Sequential()\nmodel.add(Dense(units=256, input_shape = (len(num_cols),), \n                kernel_initializer='he_normal',activation='relu'))    \nmodel.add(Dropout(drop))\nmodel.add(Dense(units=64, kernel_initializer='he_normal', activation='relu'))     \nmodel.add(Dropout(drop))\nmodel.add(Dense(11, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) ","d44c84bd":"# \u69cb\u7bc9\u3057\u305f\u30e2\u30c7\u30eb\u3092\u78ba\u8a8d\nmodel.summary()","69222951":"# \u30e2\u30c7\u30eb\u306e\u8a13\u7df4\nhistory = model.fit(x_train, y_train, epochs=50, batch_size=16, validation_data=(x_val, y_val), verbose=1)\n# \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\nmodel.save('.\/model.h5')","df81d9af":"# Accuracy\u306e\u30d7\u30ed\u30c3\u30c8\nplt.figure()\nplt.title('Accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.plot(history.history['accuracy'], label='x_train')\nplt.plot(history.history['val_accuracy'], label='x_val')\nplt.legend()","955437d8":"# Loss\u306e\u30d7\u30ed\u30c3\u30c8\nplt.figure()\nplt.title('categorical_crossentropy Loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.plot(history.history['loss'], label='x_train')\nplt.plot(history.history['val_loss'], label='x_val')\nplt.legend()\nplt.show()","579ad90d":"# \u8a13\u7df4\u3057\u305f\u30e2\u30c7\u30eb\u3092\u4f7f\u3063\u3066\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)","1592ded5":"df_sub = pd.read_csv('..\/input\/data-science-spring-osaka-2021\/sample_submission.csv')","008dc794":"df_sub['action_seq'] = le.inverse_transform(y_pred)\ndf_sub","96cb0bc2":"# \u51fa\u529b\u3057\u3066\u63d0\u51fa\u3057\u307e\u3059\ndf_sub.to_csv('submission.csv', index=False)","0bfe1e82":"# \u5b66\u7fd2\u72b6\u6cc1\u3092\u53ef\u8996\u5316","7188a0c5":"# keras\u3092\u4f7f\u3063\u3066\u591a\u5c64\u30d1\u30fc\u30bb\u30d7\u30c8\u30ed\u30f3(MLP)\u3092\u4f5c\u6210\u3057\u307e\u3059"}}