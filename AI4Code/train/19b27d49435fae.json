{"cell_type":{"a0be8089":"code","7c699684":"code","7dcdeb9d":"code","7b4ca206":"code","9dc34ecf":"code","9863d3b6":"code","bae0717d":"code","aa562bf9":"code","12400c03":"code","276f1365":"markdown","4d8ba777":"markdown"},"source":{"a0be8089":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7c699684":"# import data\ndata = pd.read_csv('..\/input\/column_2C_weka.csv')\n#print(data)","7dcdeb9d":"# data info\ndata.info()","7b4ca206":"# data firs five row\ndata.head()","9dc34ecf":"# before cleanin data\nabnormal = data[data['class'] == 'Abnormal']\nnormal = data[data['class'] == 'Normal']\nplt.scatter(abnormal.pelvic_incidence,abnormal.pelvic_radius,color='red',label='Abnormal',alpha=0.4)\nplt.scatter(normal.pelvic_incidence,normal.pelvic_radius,color='green',label='Normal',alpha=0.4)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('pelvic_radius')\nplt.legend()\nplt.show()","9863d3b6":"# classification and normalization\ndata['class'] = [0 if x == 'Abnormal' else 1 for x in data['class']]\ny = data['class']\nx_data = data.drop(['class'],axis=1)\nx = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data))\n#print(x)\n#print(y)\n#print(data['class'])","bae0717d":"# data train and test splite\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\nprint(x_train, x_test, y_train, y_test )","aa562bf9":"#knn\nknn = KNeighborsClassifier(n_neighbors=4)\nknn.fit(x_train,y_train)\nprint ('k: {} values score: {}'.format(4,knn.score(x_test, y_test)))","12400c03":"# Find the best k value and virtualization\nscore_list = []\n\nfor x in range(1,15):\n    knn_n = KNeighborsClassifier(n_neighbors=x)\n    knn_n.fit(x_train,y_train)\n    score_list.append(knn_n.score(x_test, y_test))\n    print ('k: {} values score: {}'.format(x,knn_n.score(x_test, y_test)))\n\nplt.plot(range(1,15), score_list)\nplt.xlabel('k values')\nplt.ylabel('accurasi')\nplt.show()\n","276f1365":"# CONCLUSION\nI try my firs K-Nearest Neighbors ","4d8ba777":"# Content\n* \u0130mport data\n* Cleanin data\n* Data Normalization\n* Data train and test splite\n* KNN\n* Find the best k value and virtualization"}}