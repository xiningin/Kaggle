{"cell_type":{"8736c38b":"code","52ed6949":"code","79d18352":"code","582f8723":"code","1335f157":"code","9e1b28f5":"code","f8d34180":"code","4048181a":"code","d5612211":"code","4d3dd405":"code","df62d5f9":"code","8f4976ae":"code","3b6b7117":"code","f3515c25":"code","7f7612b5":"code","6de1e55c":"code","6b8bf41a":"code","882dba54":"code","585c1c3a":"code","bc8255e4":"code","8fb7dbac":"code","13eafbad":"code","2cce47eb":"code","ab356221":"code","98ceac03":"code","a5cfaa5b":"code","313d8802":"code","d91f94cc":"code","b1b747ae":"code","625cb7f1":"code","3cf56af0":"code","988f0840":"code","fcd8eaf6":"code","15f034ec":"code","0a64e4e0":"markdown","c88550f4":"markdown","32cd65b5":"markdown","c1c9d753":"markdown","85a4e147":"markdown","1d01992b":"markdown","d23b2103":"markdown","53ab64c4":"markdown","5225ad41":"markdown","88ee5809":"markdown"},"source":{"8736c38b":"import os\n\n# \uae30\ubcf8\ud3f4\ub354(base folder)\ndir_ad = '\/kaggle\/input\/titanic'\n\n# \ud559\uc2b5\ub370\uc774\ud130, predict data \ud30c\uc77c\uba85(train, test file name)\ntrain = 'train.csv'\ntest = 'test.csv'\n\n# \uc5b4\ub5a4\uac83\uc744 \ubd84\uc11d \ubc0f \ub370\uc774\ud130 \ucd94\ucd9c\ud560\uc9c0 \uad6c\ubd84\ud560 \uc218 \uc788\ub294 \ud30c\uc77c\uba85 \uc120\ud0dd \n# tag = 'train_MAU_3M_pred_MAUX_4M'\u2190 \uc774\ub7f0 \ubc29\uc2dd\uc73c\ub85c \ub098\uc62c \uac83\uc73c\ub85c \uc608\uc0c1\ntag = 's_result'\n\n# \ubaa8\ub378 \ubc0f \uac01\uc885 \uc0b0\ucd9c\ubb3c\uc774 \uc800\uc7a5\ub420 \ud3f4\ub354\nmodel_dir = os.path.join(dir_ad, tag + '_v')\n\n# \ub808\uc774\ube14\uc5d0 \ud574\ub2f9\ud558\ub294 \uceec\ub7fc(column corresponding to label: Y value)\ntarget = 'Survived' \n\n# \ud0c0\uac9f\ud305 \ub300\uc0c1\uc744 \uc2dd\ubcc4\ud558\uae30 \uc704\ud55c \uceec\ub7fc(Column to identify the target)\nindex_col = 'PassengerId'\n\n# \ud3c9\uac00\ubc29\ubc95 'Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa' \ub4f1 \uc120\ud0dd (Choice of evaluation method)\nchoice = \"Accuracy\"","52ed6949":"import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import SVC\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier","79d18352":"df_train = pd.read_csv(os.path.join(dir_ad, train))\ndf_test = pd.read_csv(os.path.join(dir_ad, test))","582f8723":"num_cols = [col for col in df_test.columns if df_test[col].dtype in [\"float16\",\"float32\",\"float64\", \"int64\", \"int32\"]]\ncat_cols = [col for col in df_test.columns if df_test[col].dtype not in [\"float16\",\"float32\",\"float64\", \"int64\", \"int32\"]]","1335f157":"def detect_outliers(data, col_name):\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in col_name:\n        Q1 = np.percentile(data[col], 25)\n        Q3 = np.percentile(data[col],75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outlier_list_col = data[(data[col] < Q1 - outlier_step) | (data[col] > Q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","9e1b28f5":"# Drop outliers\ndf_train = df_train.drop(detect_outliers(df_train, num_cols), axis = 0).reset_index(drop=True)","f8d34180":"def outlier_replace(data, col_name, q1=0.25, q3=0.75):\n    quartile1 = data[col_name].quantile(q1)\n    quartile3 = data[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    data.loc[(data[col_name] < low_limit), col_name] = low_limit\n    data.loc[(data[col_name] > up_limit), col_name] = up_limit","4048181a":"for i in num_cols:\n    outlier_replace(df_train,i)\n    outlier_replace(df_test, i)","d5612211":"df_train = df_train.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\ndf_test = df_test.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)","4d3dd405":"df_train = pd.get_dummies(df_train)\ndf_test = pd.get_dummies(df_test)","df62d5f9":"test_col = []\ndelete_train = []\n\nfor i in df_test.columns:\n    test_col.append(i)\nfor j in df_train.columns:\n    if j not in test_col:\n        delete_train.append(j)\ndelete_train.remove(target)","8f4976ae":"train_col = []\ndelete_test = []\n\nfor i in df_train.columns:\n    train_col.append(i)\nfor j in df_test.columns:\n    if j not in train_col:\n        delete_test.append(j)","3b6b7117":"for delete in delete_train:\n    df_train = df_train.drop([delete],axis=1)\n    \nfor delete in delete_test:\n    df_test = df_test.drop([delete],axis=1)","f3515c25":"random_state_val =777\ntest_size_val =0.1\n\ndf_train, df_val = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)\n\ndrop_col = [target, index_col]\ny_nm = target\n\ndf_train_x = df_train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(df_train[y_nm])\n\ndf_val_x = df_val.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(df_val[y_nm])","7f7612b5":"LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   nthread=4,\n                                   n_estimators=10000,\n                                   learning_rate=0.02,\n                                   num_leaves=34,\n                                   colsample_bytree=0.9497036,\n                                   subsample=0.8715623,\n                                   max_depth=8,\n                                   reg_alpha=0.041545473,\n                                   reg_lambda=0.0735294,\n                                   min_split_gain=0.0222415,\n                                   min_child_weight=39.3259775,\n                                   silent=-1,\n                                   random_state = 42)","6de1e55c":"start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)], \n                       eval_metric ='auc',\n                       early_stopping_rounds = 200,\n                       verbose = True)\nend = datetime.datetime.now()\nend-start","6b8bf41a":"feature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_train_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp[:10].sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')","882dba54":"fpr, tpr, _ = roc_curve(df_val_y, lgbm.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_value =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if choice == 'Accuracy':\n        if max_value <= accuracy:\n            max_value = accuracy\n            opt_threshold = threshold\n    elif choice == 'Precision':\n        if max_value <= precision:\n            max_value = precision\n            opt_threshold = threshold\n    elif choice == 'Recall':\n        if max_value <= recall:\n            max_value = recall\n            opt_threshold = threshold\n    elif choice == 'F1_Score':\n        if max_value <= f1_score:\n            max_value = f1_score\n            opt_threshold = threshold\n    elif choice == 'roc_auc':\n        if max_value <= roc_auc:\n            max_value = roc_auc\n            opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max_value =%f, optimized_threshold=%f'%(max_value, opt_threshold))\nprint('Complete')","585c1c3a":"predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()","bc8255e4":"conf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","8fb7dbac":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","13eafbad":"XGBClassifier = xgb.XGBClassifier(max_depth = 6,\n                                 learning_rate = 0.01,\n                                 n_estimators = 10000,\n                                 objective = 'binary:logistic',\n                                 tree_method = 'gpu_hist',\n                                 booster = 'gbtree',\n                                 seed = 23,\n                                 min_child_weight = 35,\n                                 subsample = 0.7,\n                                 alpha = 0.25,\n                                 n_jobs = -1\n                                 )","2cce47eb":"start = datetime.datetime.now()\nxgb = XGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)], \n                       eval_metric = 'auc',\n                       early_stopping_rounds = 200,\n                       verbose = True)\nend = datetime.datetime.now()\nend-start","ab356221":"fi_vals = xgb.get_booster().get_score(importance_type = 'weight')\nfi_dict = {df_train_x.columns[i]:float(fi_vals.get('f'+str(i),0.)) for i in range(len(df_train_x.columns))}\nfeature_importance_ = sorted(fi_dict.items(), key=operator.itemgetter(1), reverse=True)\nfeature_importance_result = OrderedDict(feature_importance_)\n\nimportance = pd.DataFrame(feature_importance_)\nimportance.columns = ['feature','weight']\nimportance.head(10)","98ceac03":"importance_ten = importance[:10]\nimportance_ten.set_index('feature').sort_values(by='weight').plot(kind='barh', figsize=(5, 5))","a5cfaa5b":"fpr, tpr, _ = roc_curve(df_val_y, xgb.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_value =0.\nopt_threshold_2 =0.\nval_y_prob = xgb.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if choice == 'Accuracy':\n        if max_value <= accuracy:\n            max_value = accuracy\n            opt_threshold_2 = threshold\n    elif choice == 'Precision':\n        if max_value <= precision:\n            max_value = precision\n            opt_threshold_2 = threshold\n    elif choice == 'Recall':\n        if max_value <= recall:\n            max_value = recall\n            opt_threshold_2 = threshold\n    elif choice == 'F1_Score':\n        if max_value <= f1_score:\n            max_value = f1_score\n            opt_threshold_2 = threshold\n    elif choice == 'roc_auc':\n        if max_value <= roc_auc:\n            max_value = roc_auc\n            opt_threshold_2 = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max_value =%f, optimized_threshold=%f'%(max_value, opt_threshold_2))\nprint('Complete')","313d8802":"predict_xgb = xgb.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_xgb > opt_threshold_2, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","d91f94cc":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_xgb)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","b1b747ae":"df_test = df_test.drop(index_col, axis = 1)\n\ntest_xgb = pd.Series(xgb.predict(df_test.values), name=\"XGB\")\ntest_lgbm = pd.Series(lgbm.predict(df_test.values), name=\"LGBM\")\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_xgb,test_lgbm],axis=1)\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","625cb7f1":"votingC = VotingClassifier(estimators=[('xgb', xgb),('lgbm', lgbm)], voting='soft')\nvotingC = votingC.fit(df_train_x.values, df_train_y.values)","3cf56af0":"fpr, tpr, _ = roc_curve(df_val_y, votingC.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_value =0.\nopt_threshold_3 =0.\nval_y_prob = votingC.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if choice == 'Accuracy':\n        if max_value <= accuracy:\n            max_value = accuracy\n            opt_threshold_3 = threshold\n    elif choice == 'Precision':\n        if max_value <= precision:\n            max_value = precision\n            opt_threshold_3 = threshold\n    elif choice == 'Recall':\n        if max_value <= recall:\n            max_value = recall\n            opt_threshold_3 = threshold\n    elif choice == 'F1_Score':\n        if max_value <= f1_score:\n            max_value = f1_score\n            opt_threshold_3 = threshold\n    elif choice == 'roc_auc':\n        if max_value <= roc_auc:\n            max_value = roc_auc\n            opt_threshold_3 = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max_value =%f, optimized_threshold=%f'%(max_value, opt_threshold_3))\nprint('Complete')","988f0840":"predict_votingC = votingC.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_votingC > opt_threshold_3, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","fcd8eaf6":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_votingC)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","15f034ec":"predict_votingC = votingC.predict_proba(df_test.values)[:,1]\npred_test = np.where(predict_votingC > opt_threshold_3, 1., 0.)\n\ndf_test = pd.read_csv(os.path.join(dir_ad, test))\ntest_result= pd.DataFrame(pred_test)\ntest_result.columns = [target]\npredict = test_result[target]\nId_No = df_test[index_col]\nsubmission = pd.DataFrame({index_col: Id_No, target: predict})\nsubmission[target] = submission[target].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","0a64e4e0":"![image.png](attachment:b599c08a-3992-40e3-bdde-82b76e20b38e.png)","c88550f4":"# Import Module and Data","32cd65b5":"# Modeling","c1c9d753":"\ubaa8\ub378\ub9c1\uc740 XG-Boost\uc640 LightGBM\uc73c\ub85c \uc9c4\ud589\ud558\uc600\uace0, Soft Voting\ubc29\ubc95\uc73c\ub85c \uc559\uc0c1\ube14 \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.<br>\n\ub450 \ubaa8\ub378\uac04\uc758 \uc0c1\uad00\uad00\uacc4\uac00 \ub192\uc744\uc218\ub85d \uc88b\uc740 \uacb0\uacfc\uac00 \ub098\uc624\ub294 \uac83\uc744 \ud655\uc778\ud558\uc600\uc2b5\ub2c8\ub2e4.<br>\n\n\nModeling was done with XG-Boost and LightGBM, and an ensemble model was created using the Soft Voting method.<br>\nIt was confirmed that the higher the correlation between the two models, the better the results.<br>","85a4e147":"# Preprocessing","1d01992b":"\uc5b4\ub290 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uc5ec\ub3c4 \uc720\uc6a9\ud560\uc218 \uc788\ub294 \uc804\ucc98\ub9ac \ubc29\ubc95\uc5d0 \ub300\ud558\uc5ec \uace0\ubbfc\ud574 \ubcf4\uc558\uace0,<br>\n\uadf8 \uacb0\uacfc Outlier\uc5d0 \ub300\ud55c \uc870\uc815\uacfc null\uac12\uc5d0 \ub300\ud55c \uc870\uc815\uc5d0 \ub300\ud558\uc5ec \uc804\ucc98\ub9ac\ub97c \uc790\ub3d9\uc73c\ub85c \ud558\ub3c4\ub85d \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.<br>\nI thought about a pre-processing method that can be useful with any data, and as a result,<br>\nI made automatic pre-processing for outlier adjustment and null value adjustment.","d23b2103":"\uc544\uc2dc\ub2e4\uc2dc\ud53c \uba38\uc2e0\ub7ec\ub2dd \uc9c4\ud589\uc2dc \uc22b\uc790\ub85c \uc804\ubd80 \uc774\ub8e8\uc5b4\uc9c0\ub3c4\ub85d \ud574\uc57c\ud558\ubbc0\ub85c, One-hot encoding \uac19\uc740 \ubc29\uc2dd\uc758 \ubcc0\ud658\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.<br> \n\uc5ec\ub7ec \uae30\ubc95\uc774 \uc788\uc9c0\ub9cc, \uc774\ub7ec\ud55c \uac83\uc744 \uc0ac\uc6a9\uc2dc \ub370\uc774\ud130 \uc720\ud615\uc5d0 \ub530\ub77c \ud29c\ub2dd\ud574\uc918\uc57c\ud558\ub294 \ubb38\uc81c\uac00 \ubcf4\uc5ec\uc11c \uc800\ub294 \ub2e8\uc21c\ud788 get-dummy\ub97c \uc0ac\uc6a9\ud574 \ub2e4 \ud480\uc5b4\uc900 \ud6c4 \uc5f4\uc758 \uae38\uc774\ub97c \ub9de\ucd94\ub294 \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.<br>\n<br>\nAs you know, when machine learning is performed, it must be done entirely with numbers, so a conversion such as one-hot encoding is required.<br>\nThere are several techniques, but when using these, I see a problem that needs to be tuned according to the data type, so I simply used get-dummy to solve it and then adjust the length of the column.<br>","53ab64c4":"# Config","5225ad41":"**\uba38\uc2e0\ub7ec\ub2dd\uc744 \ubab0\ub77c\ub3c4 \"Config\"\uc5d0 5\uac00\uc9c0\ub9cc \ub123\uc73c\uba74, \uc2e4\ud589\ud560 \uc218 \uc788\uac8c \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.<br>\nEven if you don't know machine learning, you can submit only 5 things in \"config\"**\n\n\ud68c\uc0ac\uc5d0\uc11c \ub9ce\uc774 \uc0ac\uc6a9\ud558\uac8c \ub9cc\ub4e4\uc5c8\uc5c8\uace0, \ub3c4\uc6c0\uc774 \ub9ce\uc774 \ub420 \uac81\ub2c8\ub2e4.<br> \nI made a lot of use of it in company, and it will help a lot.","88ee5809":"\uc5ec\ub7ec \ubd84\ub958 \ubb38\uc81c\uc5d0 \ub300\ud558\uc5ec \ud574\ub2f9 \ubaa8\ub378\uc744 \ud29c\ub2dd \uc5c6\uc774 \ub3d9\uc77c\ud558\uac8c \uc0ac\uc6a9(\ub2e4\ub978 \ubb38\uc81c\uc5d0 \uc801\uc6a9\ud55c \uac83\uc744 \ubcf4\uc2dc\ub824\uba74 [\uc5ec\uae30 \ud074\ub9ad](https:\/\/www.kaggle.com\/hadeux\/auto-simple-ensemble-model))\ud574 \ubcf4\uc558\uace0,<br> \n\uc5b4\ub290\uc815\ub3c4 \uc88b\uc740 \uacb0\uacfc\uac00 \ub098\uc624\ub294 \uac83\uc744 \ud655\uc778\ud558\uc600\uc2b5\ub2c8\ub2e4.<br>\n\nI tried using the model identically without tuning for several classification problems ([Click here](https:\/\/www.kaggle.com\/hadeux\/auto-simple-ensemble-model) to see it applied to other problems)<br>\nIt was confirmed that some good results were obtained."}}