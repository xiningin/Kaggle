{"cell_type":{"a89d92b3":"code","5668b9c8":"code","abead12d":"code","f6934011":"code","01acd42a":"code","322c20f2":"code","e6ebd1d0":"code","8172bea4":"code","1cb7fdb3":"code","f9aa31b7":"code","61769a9b":"code","5e804b19":"code","5baaad9e":"code","e169df49":"code","e31134ab":"code","901adaea":"code","2817c631":"code","6e2e5ad4":"code","1b594499":"code","5bf0ecf9":"code","6f23491a":"code","0ba3b1e5":"code","857dd34b":"code","52bde790":"code","a93f366f":"code","40c7165f":"code","b3326ee3":"code","272bad68":"code","cb3053ff":"code","1734dbc9":"code","c1f23180":"code","4166dfbe":"code","aec729d3":"code","fb0c3ade":"code","712ae6b4":"code","253ae942":"code","0dc54d45":"code","47e711c1":"markdown"},"source":{"a89d92b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Any results you write to the current directory are saved as output.","5668b9c8":"train_df = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-2\/test.csv\")","abead12d":"train_df.head(50)","f6934011":"'''\nfrom pandas_profiling import ProfileReport\ntrain_profile = ProfileReport(train_df, title='Pandas Profiling Report', html={'style':{'full_width':True}})\ntrain_profile\n'''","01acd42a":"train_df.info()","322c20f2":"common_value = \"UNKNOWN\"\n\n# Replacing all the Province_State that are null by the Country_Region values\ntrain_df.Province_State.fillna(train_df.Country_Region, inplace=True)\ntest_df.Province_State.fillna(test_df.Country_Region, inplace=True)\n\n# Handling the Date column\n# 1. Converting the object type column into datetime type\ntrain_df.Date = train_df.Date.apply(pd.to_datetime)\ntest_df.Date = test_df.Date.apply(pd.to_datetime)\n\n# 2. Creating new features\n#train_df['ReportDay_year'] = train_df['Date'].dt.year #Not required this column because all the data is of this year\ntrain_df['ReportDay_month'] = train_df['Date'].dt.month\ntrain_df['ReportDay_week'] = train_df['Date'].dt.week\ntrain_df['ReportDay_day'] = train_df['Date'].dt.day \n\n#test_df['ReportDay_year'] = test_df['Date'].dt.year\ntest_df['ReportDay_month'] = test_df['Date'].dt.month\ntest_df['ReportDay_week'] = test_df['Date'].dt.week\ntest_df['ReportDay_day'] = test_df['Date'].dt.day","e6ebd1d0":"#Dropping the date column\ntrain_df.drop(\"Date\", inplace = True, axis = 1)\ntest_df.drop(\"Date\", inplace = True, axis = 1)","8172bea4":"train_df.Province_State.value_counts()","1cb7fdb3":"\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ntrain_df.Country_Region = le.fit_transform(train_df.Country_Region)\ntrain_df['Province_State'] = le.fit_transform(train_df['Province_State'])\n\ntest_df.Country_Region = le.fit_transform(test_df.Country_Region)\ntest_df['Province_State'] = le.fit_transform(test_df['Province_State'])\n","f9aa31b7":"'''\ndef one_hot(df, cols):\n    \"\"\"\n    @param df pandas DataFrame\n    @param cols a list of columns to encode \n    @return a DataFrame with one-hot encoding\n    \"\"\"\n    i = 0\n    for each in cols:\n        #print (each)\n        dummies = pd.get_dummies(df[each], prefix=each, drop_first= True)\n        if i == 0: \n            print (dummies)\n            i = i + 1\n        df = pd.concat([df, dummies], axis=1)\n    return df\n'''","61769a9b":"'''\n#Handling categorical data\n\nobjList = train_df.select_dtypes(include = \"object\").columns\ntrain_df = one_hot(train_df, objList) \ntest_df = one_hot(test_df, objList) \n\nprint (train_df.shape)\n'''","5e804b19":"'''\n# Removing duplicate entries\ntrain_df = train_df.loc[:,~train_df.columns.duplicated()]\ntest_df = test_df.loc[:,~test_df.columns.duplicated()]\nprint (test_df.shape)\n'''","5baaad9e":"'''\n# Dropping the object type columns\ntrain_df.drop(objList, axis=1, inplace=True)\ntest_df.drop(objList, axis=1, inplace=True)\nprint (train_df.shape)\n'''","e169df49":"'''\ntrain_df.select_dtypes(include = \"object\").columns\n#So, no columns with object data is there. Our data is ready for training\n'''","e31134ab":"test_df.info()","901adaea":"X_train = train_df.drop([\"Id\", \"ConfirmedCases\", \"Fatalities\"], axis = 1)\n\nY_train_CC = train_df[\"ConfirmedCases\"] \nY_train_Fat = train_df[\"Fatalities\"] \n\n#X_test = test_df.drop([\"ForecastId\"], axis = 1)\nX_test = test_df.drop([\"ForecastId\"], axis = 1) ","2817c631":"#print (type(Y_train_CC))\n#X_train_CC.info()","6e2e5ad4":"'''\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import make_scorer, r2_score, mean_squared_log_error\n\nn_folds = 5\ncv = KFold(n_splits = 10, shuffle=True, random_state=42).get_n_splits(X_train.values)\n\ndef test_model(model, colName):   \n    msle = make_scorer(mean_squared_log_error)\n    if colName == \"CC\":\n        #print (\"In\")\n        rmsle = np.sqrt(cross_val_score(model, X_train, Y_train_CC, cv=cv, scoring = msle))\n    elif colName == \"Fat\": \n        rmsle = np.sqrt(cross_val_score(model, X_train, Y_train_Fat, cv=cv, scoring = msle))\n    #print (rmsle)\n    score_rmsle = [rmsle.mean()]\n    return score_rmsle\n\ndef test_model_r2(model, colName):\n    r2 = make_scorer(r2_score)\n    if colName == \"CC\":\n        r2_error = cross_val_score(model, X_train, Y_train_CC, cv=cv, scoring = r2)\n    elif colName == \"Fat\": \n        r2_error = cross_val_score(model, X_train, Y_train_Fat, cv=cv, scoring = r2)\n    score_r2 = [r2_error.mean()]\n    return score_r2\n'''","1b594499":"from sklearn.model_selection import ShuffleSplit, cross_val_score\nskfold = ShuffleSplit(random_state=7)","5bf0ecf9":"\n#1.Ridge Regression\n\n#Model import \n\nfrom sklearn.linear_model import Ridge\n\n#train classifier\nreg_CC = Ridge(alpha=1.0)\nreg_Fat = Ridge(alpha=1.0)\n\n#Cross Validation to calculate the score\nscore_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)\nscore_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)\n\n#rmsle_svm = test_model_r2(clf_svm, \"CC\")\n\n#Print the scores\nprint (score_CC.mean(), score_Fat.mean())\n","6f23491a":"\n#2.Lasso Regression\n\n#Model import \n\nfrom sklearn import linear_model\n\n#train classifier\nreg_CC = linear_model.Lasso(alpha=0.1)\nreg_Fat = linear_model.Lasso(alpha=0.1)\n\n#Cross Validation to calculate the score\nscore_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)\nscore_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)\n\n#rmsle_svm = test_model_r2(clf_svm, \"CC\")\n\n#Print the scores\nprint (score_CC.mean(), score_Fat.mean())\n","0ba3b1e5":"\n#3. SVM\n\n#Model import \n\nfrom sklearn import svm\n\n#train classifier\nreg_CC = svm.SVC()\nreg_Fat = svm.SVC()\n\n#Cross Validation to calculate the score\nscore_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)\nscore_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)\n\n#Print the scores\nprint (score_CC.mean(), score_Fat.mean())\n","857dd34b":"\n#3. ElasticNet\n\n#Model import \nfrom sklearn.linear_model import ElasticNet\n\n#train classifier\nreg_CC = ElasticNet(random_state=0)\nreg_Fat = ElasticNet(random_state=0)\n\n#Cross Validation to calculate the score\nscore_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)\nscore_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)\n\n#Print the scores\nprint (score_CC.mean(), score_Fat.mean())\n","52bde790":"\n#5. LinearRegression\n\n#Model import \n\nfrom sklearn.linear_model import LinearRegression\n\n#train classifier\nreg_CC = LinearRegression()\nreg_Fat = LinearRegression()\n\n#Cross Validation to calculate the score\nscore_CC = cross_val_score(reg_CC, X_train, Y_train_CC, cv = skfold)\nscore_Fat = cross_val_score(reg_Fat, X_train, Y_train_Fat, cv = skfold)\n\n#Print the scores\nprint (score_CC.mean(), score_Fat.mean())\n\n","a93f366f":"'''\n#1. SVM algorithm\nfrom sklearn import svm\nclf_svm_CC = svm.SVC()\nclf_svm_Fat = svm.SVC()\n\nr_svm_CC = test_model(clf_svm_CC, \"CC\")\nr_svm_Fat = test_model(clf_svm_Fat, \"Fat\")\n\n#rmsle_svm = test_model_r2(clf_svm, \"CC\")\n\nprint (r_svm_CC, r_svm_Fat)\n'''","40c7165f":"'''\n#2. Decision Tree \nfrom sklearn.tree import DecisionTreeRegressor\n\nclf_dtR_CC = DecisionTreeRegressor(max_depth=5, random_state=51)\nclf_dtR_Fat = DecisionTreeRegressor(max_depth=5, random_state=51)\n\nrmsle_dtR_CC = test_model(clf_dtR_CC, \"CC\")\nrmsle_dtR_Fat = test_model(clf_dtR_Fat, \"Fat\")\n\n#print (rmsle_dtR_CC, test_model_r2(clf_dtR_CC, \"CC\"))\n\nprint (rmsle_dtR_CC, rmsle_dtR_Fat)\n'''","b3326ee3":"'''\n#3. Random Forest Regressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nclf_rFR_CC = RandomForestRegressor(max_depth=5, random_state=51)\nclf_rFR_Fat = RandomForestRegressor(max_depth=5, random_state=51)\n\nrmsle_rFR_cc = test_model(clf_rFR_CC, \"CC\")\n\nrmsle_rFR_fat = test_model(clf_rFR_Fat, \"Fat\")\n\nprint (rmsle_rFR_cc, rmsle_rFR_fat)\n'''","272bad68":"'''\n#4. Adaboost regressor\n\nfrom sklearn.ensemble import AdaBoostRegressor\nclf_aBR_CC = AdaBoostRegressor(random_state=51, n_estimators=1000)\nclf_aBR_Fat = AdaBoostRegressor(random_state=51, n_estimators=1000)\n\nrmsle_aBR_CC = test_model(clf_aBR_CC, \"CC\")\nrmsle_aBR_Fat = test_model(clf_aBR_Fat, \"Fat\")\n\nprint (rmsle_aBR_CC, rmsle_aBR_Fat)\n'''","cb3053ff":"\n#5. BaggingClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf_bgr_CC = BaggingRegressor(base_estimator = DecisionTreeRegressor())\nclf_bgr_Fat = BaggingRegressor(base_estimator = DecisionTreeRegressor())\n\nrmsle_bgr_CC = test_model(clf_bgr_CC, \"CC\")\nrmsle_bgr_Fat = test_model(clf_bgr_Fat, \"Fat\")\n\nprint (rmsle_bgr_CC, rmsle_bgr_Fat)\n","1734dbc9":"'''\n#6. Voting Regressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nreg1 = BaggingRegressor(random_state=1, n_estimators=10)\nreg2 = RandomForestRegressor(random_state=1, n_estimators=10)\nreg3 = DecisionTreeRegressor()\n\nclf_vr_CC = VotingRegressor(estimators=[('b', reg1), ('rf', reg2), ('dt', reg3)])\nclf_vr_Fat = VotingRegressor(estimators=[('b', reg1), ('rf', reg2), ('dt', reg3)])\n\nrmsle_vr_CC = test_model(clf_vr_CC, \"CC\")\nrmsle_vr_Fat = test_model(clf_vr_Fat, \"Fat\")\n\nprint (rmsle_vr_CC, rmsle_vr_Fat)\n'''","c1f23180":"#print (X_train_CC.shape, X_train_Fat.shape, X_test.shape)","4166dfbe":"reg_CC.fit(X_train, Y_train_CC)\nY_pred_CC = reg_CC.predict(X_test) \n\nreg_Fat.fit(X_train, Y_train_Fat)\nY_pred_Fat = reg_Fat.predict(X_test) ","aec729d3":"print (Y_pred_Fat)","fb0c3ade":"df_out = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\nsoln = pd.DataFrame({'ForecastId': test_df.ForecastId, 'ConfirmedCases': Y_pred_CC, 'Fatalities': Y_pred_Fat})\ndf_out = pd.concat([df_out, soln], axis=0)\ndf_out.ForecastId = df_out.ForecastId.astype('int')","712ae6b4":"df_out.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","253ae942":"'''\n# Hyper parameter \n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nparam_grid = {\n              'n_estimators':[10, 30, 50, 100,250,500,750,1000,1250,1500,1750],\n              'max_samples':[2,4,6,8,10,20,40,60,100],\n              \"max_features\": [0.5, 1.0],\n              'n_jobs':[-2, -1, 1, 2, 3, 4, 5],\n              \"bootstrap_features\": [True, False]\n             }\n\nasdf = BaggingRegressor()\n\n#clf_CC = GridSearchCV(asdf, param_grid=param_grid, scoring='r2' )\n#clf_Fat = GridSearchCV(asdf, param_grid=param_grid, scoring='r2')\nclf_CC = RandomizedSearchCV(asdf, param_grid, scoring='r2'  )\nclf_Fat = RandomizedSearchCV(asdf, param_grid, scoring='r2'  )\n\nclf_CC.fit(X_train, Y_train_CC)\nclf_Fat.fit(X_train, Y_train_Fat)\n\nprint(clf_CC.best_estimator_)\n'''","0dc54d45":"#print(clf_Fat.best_estimator_)","47e711c1":"Please upvote if you like this solution"}}