{"cell_type":{"4f39b19e":"code","d5cde114":"code","1387c2db":"code","c929f515":"code","70d96c9e":"code","869a5906":"code","6ab0cf6d":"code","92d9c857":"code","323de442":"code","4d07576b":"code","f53a8dcf":"code","f3e92fc8":"code","a6f1074e":"code","4979c2e4":"markdown"},"source":{"4f39b19e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5cde114":"train_data= pd.read_csv(\"..\/input\/leaf-classification\/train.csv.zip\",index_col=False)\ntest_data= pd.read_csv(\"..\/input\/leaf-classification\/test.csv.zip\", index_col=False)\ntrain_data.head()","1387c2db":"#obj = data.isnull().sum()\n#for key, value in obj.iteritems():\n#    print(key,\":\",value)","c929f515":"#obj_2 = test_data.isnull().sum()\n#for key, value in obj_2.iteritems():\n#    print(key,\":\",value)","70d96c9e":"from sklearn.preprocessing import LabelEncoder\nencoder=LabelEncoder()\nle=encoder.fit(train_data.species)\nlabels=le.transform(train_data.species)\nclasses=list(le.classes_)","869a5906":"train_data=train_data.drop(['id','species'],axis=1)\ntest_id=test_data.id\ntest_data=test_data.drop(['id'],axis=1)","6ab0cf6d":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(train_data,labels,test_size=.2,shuffle=True,stratify=labels)","92d9c857":"from sklearn.ensemble import ExtraTreesClassifier\nlda = ExtraTreesClassifier(bootstrap=False,\n                           ccp_alpha=0.0,\n                           class_weight=None,\n                           criterion='gini',\n                           max_depth=60,\n                           max_features='sqrt',\n                           max_leaf_nodes=None,\n                           max_samples=None,\n                           min_impurity_decrease=0.0,\n                           min_impurity_split=None,\n                           min_samples_leaf=2,\n                           min_samples_split=10,\n                           min_weight_fraction_leaf=0.0,\n                           n_estimators=195,\n                           n_jobs=None, oob_score=False,\n                           random_state=6713, verbose=0,\n                           warm_start=False)\n\nlda.fit(X_train,y_train)","323de442":"lda.score(X_train,y_train), lda.score(X_test,y_test)","4d07576b":"predicted=lda.predict_proba(test_data)\n\nsample_df=pd.read_csv('..\/input\/leaf-classification\/sample_submission.csv.zip',index_col=False)\nsample_df.head(2)\n\n","f53a8dcf":"df_sub=pd.DataFrame(predicted,columns=sample_df.columns[1:])\ndf_sub.head(2)","f3e92fc8":"df_sub1=pd.DataFrame(test_id)\ndf_sub1.head(2)","a6f1074e":"final_sub=pd.concat([df_sub1,df_sub],axis=1)\nfinal_sub.to_csv('sample_submission.csv',index=False)","4979c2e4":"# Checking Null values"}}