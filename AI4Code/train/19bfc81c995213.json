{"cell_type":{"c325c9ad":"code","55be0d9f":"code","d23c8564":"code","5b420be9":"code","98c8b1b5":"code","21cb7750":"code","5b92daa1":"code","978ebda8":"code","efe0114d":"code","8b4d7eb7":"code","41a94728":"code","8a057060":"code","c14c4ecf":"code","af99975b":"code","7e163309":"code","804fae46":"code","93c0deaa":"code","99b2b34c":"code","185ead86":"code","c71a147f":"markdown"},"source":{"c325c9ad":"import sys, os\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\nimport matplotlib.pyplot as plt\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn","55be0d9f":"rfe_min_features = 12\nrfe_step = 15\nrfe_cv = 20\nsss_n_splits = 20\nsss_test_size = 0.35\ngrid_search_cv = 20\nnoise_std = 0.01\nr2_threshold = 0.185\nrandom_seed = 213\n\nnp.random.seed(random_seed)","d23c8564":"# import data\ntrain = pd.read_csv('..\/input\/older-dataset-for-dont-overfit-ii-challenge\/train.csv')\ntrain_y = train['target']\ntrain_X = train.drop(['id','target'], axis=1).values\n\ntest_df = pd.read_csv('..\/input\/older-dataset-for-dont-overfit-ii-challenge\/test.csv')\ntest_df= test_df.drop(['id'], axis=1).values","5b420be9":"train.head()","98c8b1b5":"train.info()","21cb7750":"train.nunique()","5b92daa1":"#number of training samples is too small\nplt.bar(range(2), (train_X.shape[0], test_df.shape[0]), align='center', alpha=0.8)\nplt.xticks(range(2), ('train','test'))\nplt.ylabel('Number of data') \nplt.title('Can we avoid overfitting')\nplt.show()\n","978ebda8":"#from the hist of each column it shows that data follows a gaussian shape or normal distribution around 0 mean and std =1\nplt.figure(figsize=(15,15))\nfor i in range(5):\n    for j in range(5):\n        plt.subplot(5,5,5*i+j+1)\n        plt.hist(train[str(5*i+j)],bins=100)\n        plt.title('Column '+str(5*i+j))\nplt.show()","efe0114d":"#check the mean value and std on the train \n\n# with mean 0 and std 1 \nprint(train.mean().sum()\/300)\nprint(train.std().sum()\/300)","8b4d7eb7":"#check the mean value and std on the Test Data \nprint(test_df.mean().sum()\/300)\nprint(test_df.std().sum()\/300)","41a94728":"# scale using RobustScaler \ndata = RobustScaler().fit_transform(np.concatenate((train_X, test_df), axis=0))\ntrain_X = data[:250]\ntest_df= data[250:]\n# add a bit of noise to train_X to reduce overfitting\ntrain_X += np.random.normal(0, noise_std, train_X.shape)\n","8a057060":"# define roc_auc_metric \n#then make it as ascorer \ndef scoring_roc_auc(y, y_pred):\n    try:\n        return roc_auc_score(y, y_pred)\n    except:\n        return 0.5\n\nrobust_roc_auc = make_scorer(scoring_roc_auc)\n","c14c4ecf":"from sklearn.ensemble import ExtraTreesClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt","af99975b":"#Draw Correlation heatmap\ntrain.drop(columns=['id','target']).corr()","7e163309":"#Try hist gradient classifier without any normalization on the data then get the most important features \n\nHistGradient = ExtraTreesClassifier(warm_start=True)\n\nparam = {'n_estimators' : [250,500], \n    'max_depth' : [11],\n   \n         'min_samples_split':[9],\n         'min_samples_leaf':[9],\n        }\n\ngridSearch_HistGradient = GridSearchCV(HistGradient,param,scoring=robust_roc_auc,cv=7,verbose=3)\ngridSearch_HistGradient.fit(train_X, train_y)\n\nbest_HistGradient = gridSearch_HistGradient.best_estimator_\nbestHistGradient_testScore=best_HistGradient.score(train_X, train_y)\n","804fae46":"# from sklearn.inspection import permutation_importance\n# r = permutation_importance(gridSearch_HistGradient, train_X, train_y,\n#                             n_repeats=30)\n\n# for i in r.importances_mean.argsort()[::-1]:\n\n#     print(f\"{X_train.columns[i]} \"\n#            f\"{r.importances_mean[i]:.3f} \"\n#            f\" +\/- {r.importances_std[i]:.3f}\")\n# plt.figure(figsize=(10,7))\n# plt.barh(X_train.columns, r.importances_mean)","93c0deaa":"# define Laso model and its parameters\n#Lasso uses L1 normalization\nmodel = Lasso(alpha=0.031, tol=0.01,warm_start=True, random_state=random_seed, selection='random')\n\nparam_grid = {\n            'alpha' : [0.022, 0.021, 0.02, 0.019, 0.023, 0.024, 0.025, 0.026, 0.027, 0.029, 0.031],\n            'tol'   : [0.0013, 0.0014, 0.001, 0.0015, 0.0011, 0.0012, 0.0016, 0.0017]\n        }\n\n# define recursive elimination feature selector\nfeature_selector = RFECV(model, min_features_to_select=rfe_min_features, scoring=robust_roc_auc, step=rfe_step, verbose=0, cv=rfe_cv, n_jobs=-1)\n","99b2b34c":"predictions = pd.DataFrame()\ncounter = 0\nprint(\"counter | val_mse  |  val_mae  |  val_roc  |  val_cos  |  val_dist  |  val_r2    | feature_count \")\nprint(\"-------------------------------------------------------------------------------------------------\")\n# split training data to build one model on each traing-data-subset\nfor train_index, val_index in StratifiedShuffleSplit(n_splits=sss_n_splits, test_size=sss_test_size, random_state=random_seed).split(train_X, train_y):\n    X, val_X = train_X[train_index], train_X[val_index]\n    y, val_y = train_y[train_index], train_y[val_index]\n\n    # get the best features for this data set\n    feature_selector.fit(X, y)\n    # remove irrelevant features from X, val_X and test\n    X_important_features        = feature_selector.transform(X)\n    val_X_important_features    = feature_selector.transform(val_X)\n    test_important_features     = feature_selector.transform(test_df)\n\n    # run grid search to find the best Lasso parameters for this subset of training data and subset of features \n    grid_search = GridSearchCV(feature_selector.estimator_, param_grid=param_grid, verbose=0, n_jobs=-1, scoring=robust_roc_auc, cv=20)\n    grid_search.fit(X_important_features, y)\n\n    # score  fitted model on validation data\n    val_y_pred = grid_search.best_estimator_.predict(val_X_important_features)\n    val_mse = mean_squared_error(val_y, val_y_pred)\n    val_mae = mean_absolute_error(val_y, val_y_pred)\n    val_roc = roc_auc_score(val_y, val_y_pred)\n    val_cos = cosine_similarity(val_y.values.reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n    val_dst = euclidean_distances(val_y.values.reshape(1, -1), val_y_pred.reshape(1, -1))[0][0]\n    val_r2  = r2_score(val_y, val_y_pred)\n\n    # if model did well on validation, save its prediction on test data, using only important features\n    # r2_threshold (0.185) is a heuristic threshold for r2 error\n    # you can use any other metric\/metric combination that works for you\n    if val_r2 > r2_threshold:\n        message = '<-- OK'\n        prediction = grid_search.best_estimator_.predict(test_important_features)\n        predictions = pd.concat([predictions, pd.DataFrame(prediction)], axis=1)\n    else:\n        message = '<-- skipping'\n\n\n    print(\"{0:2}      | {1:.4f}   |  {2:.4f}   |  {3:.4f}   |  {4:.4f}   |  {5:.4f}    |  {6:.4f}    |  {7:3}         {8}  \".format(counter, val_mse, val_mae, val_roc, val_cos, val_dst, val_r2, feature_selector.n_features_, message))\n    \n    counter += 1\n\nprint(\"-------------------------------------------------------------------------------------------------\")\nprint(\"{}\/{} models passed validation threshold and will be ensembled.\".format(len(predictions.columns), sss_n_splits))\n","185ead86":"mean_pred = pd.DataFrame(predictions.mean(axis=1))\nmean_pred.index += 250\nmean_pred.columns = ['target']\nmean_pred.to_csv('submission.csv', index_label='id', index=True) ","c71a147f":"# Feature selection  using RFECV on Lasso "}}