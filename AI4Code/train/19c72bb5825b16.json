{"cell_type":{"c1df714b":"code","8a031eb8":"code","1f1f141a":"code","fc405df9":"code","3e2c5c42":"code","e7007970":"code","198befdf":"code","29d4c96d":"code","626ea398":"code","52d3cf92":"code","955d053b":"code","d81ebbc0":"code","6ec5b1b4":"code","156b5b8b":"code","9732b611":"code","54acb5ce":"code","f9a8cb26":"code","49b1afa9":"code","36e012a1":"code","c9b464ef":"code","41d552c7":"code","1204ef3d":"code","e4777430":"code","5ce10b2d":"code","f3dad926":"code","01c12fb1":"code","5f4a4370":"code","bb607fc9":"code","b3548ff3":"code","daefbb52":"code","4f3a0415":"code","f1bd3d02":"code","f3c0eab7":"code","ceeaf300":"code","4fc753b9":"code","88ef56ac":"code","fcedf343":"markdown","c328a963":"markdown","b15256b3":"markdown","7c1cd7c4":"markdown","97d7d055":"markdown","09639eb6":"markdown","5683b3ce":"markdown","79a9566a":"markdown","dd1058a1":"markdown","a064d6c2":"markdown","20a607f7":"markdown","0672e1f8":"markdown","9ff45b2d":"markdown","f7af45be":"markdown","c65eb7ad":"markdown","9e7f2c9e":"markdown"},"source":{"c1df714b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom functools import partial\n\nimport time\nstart_time = time.time()\n\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n\nimport logging\nfrom keras.callbacks import Callback\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom eli5.lime import TextExplainer\n# Any results you write to the current directory are saved as output.","8a031eb8":"tweets = pd.read_csv(\"..\/input\/clinton-trump-tweets\/tweets.csv\")\ntweets.head()","1f1f141a":"tweets.shape","fc405df9":"sum(tweets.text.isnull())","3e2c5c42":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\nraw_text = tweets[\"text\"].str.lower()","e7007970":"max_features = 130000\nmax_len = 220\ntk = Tokenizer(num_words = max_features, lower = True)\ntk.fit_on_texts(raw_text)\ntweets[\"comment_seq\"] = tk.texts_to_sequences(raw_text)","198befdf":"tweets_pad_sequences = pad_sequences(tweets.comment_seq, maxlen = max_len)","29d4c96d":"tweets_pad_sequences.shape","626ea398":"model = load_model(\"..\/input\/bi-gru-lstm-cnn-poolings-fasttext\/best_model.hdf5\")","52d3cf92":"pred = model.predict(tweets_pad_sequences, batch_size = 1024, verbose = 1)","955d053b":"pred.max()","d81ebbc0":"toxic_predictions = pd.DataFrame(columns=list_classes, data=pred)","6ec5b1b4":"toxic_predictions.head()","156b5b8b":"toxic_predictions['id'] = tweets['id'].values\ntoxic_predictions['handle'] = tweets['handle'].values\ntoxic_predictions['text'] = tweets['text'].values","9732b611":"toxic_predictions.tail()","54acb5ce":"Hillary_predictions = toxic_predictions[toxic_predictions['handle'] == 'HillaryClinton']\nTrump_predictions = toxic_predictions[toxic_predictions['handle'] == 'realDonaldTrump']","f9a8cb26":"Hillary_predictions[list_classes].describe()","49b1afa9":"Trump_predictions[list_classes].describe()","36e012a1":"def predict_texts(texts, class_idx):\n    sequence = tk.texts_to_sequences(texts)\n    sequence = pad_sequences(sequence, maxlen=max_len) \n    preds = model.predict(sequence, batch_size=100, verbose=1)[:, class_idx]\n    # Make the probability sums to 1\n    preds = np.array([preds, 1-preds]).transpose()\n    return preds\n\ndef explain_text(text, class_idx):\n    te = TextExplainer(random_state=42, n_samples=1000)\n    te.fit(text, partial(predict_texts, class_idx=class_idx))\n    print(te.metrics_)\n    return te.show_prediction(target_names=[list_classes[class_idx], \"None\"])","c9b464ef":"class_idx = 0\nprint(list_classes[class_idx])\nexplain_text(Hillary_predictions.loc[Hillary_predictions['toxic'].idxmax()]['text'], class_idx=class_idx)","41d552c7":"Hillary_predictions.loc[Hillary_predictions['toxic'].idxmax()]","1204ef3d":"class_idx = 3\nprint(list_classes[class_idx])\nexplain_text(Hillary_predictions.loc[Hillary_predictions['threat'].idxmax()]['text'], class_idx=class_idx)","e4777430":"Hillary_predictions.loc[Hillary_predictions['threat'].idxmax()]","5ce10b2d":"class_idx = 0\nprint(list_classes[class_idx])\nexplain_text(Hillary_predictions.loc[Hillary_predictions['threat'].idxmax()]['text'], class_idx=class_idx)","f3dad926":"Hillary_predictions.loc[Hillary_predictions['insult'].idxmax()]","01c12fb1":"class_idx = 4\nprint(list_classes[class_idx])\nexplain_text(Hillary_predictions.loc[Hillary_predictions['insult'].idxmax()]['text'], class_idx=class_idx)","5f4a4370":"Hillary_predictions.loc[Hillary_predictions['identity_hate'].idxmax()]","bb607fc9":"class_idx = 5\nprint(list_classes[class_idx])\nexplain_text(Hillary_predictions.loc[Hillary_predictions['identity_hate'].idxmax()]['text'], class_idx=class_idx)","b3548ff3":"Trump_predictions.loc[Trump_predictions['toxic'].idxmax()]","daefbb52":"class_idx = 0\nprint(list_classes[class_idx])\nexplain_text(Trump_predictions.loc[Trump_predictions['toxic'].idxmax()]['text'], class_idx=class_idx)","4f3a0415":"Trump_predictions.loc[Trump_predictions['threat'].idxmax()]","f1bd3d02":"class_idx = 3\nprint(list_classes[class_idx])\nexplain_text(Trump_predictions.loc[Trump_predictions['threat'].idxmax()]['text'], class_idx=class_idx)","f3c0eab7":"Trump_predictions.loc[Trump_predictions['insult'].idxmax()]","ceeaf300":"class_idx = 4\nprint(list_classes[class_idx])\nexplain_text(Trump_predictions.loc[Trump_predictions['insult'].idxmax()]['text'], class_idx=class_idx)","4fc753b9":"Trump_predictions.loc[Trump_predictions['identity_hate'].idxmax()]","88ef56ac":"class_idx = 5\nprint(list_classes[class_idx])\nexplain_text(Trump_predictions.loc[Trump_predictions['identity_hate'].idxmax()]['text'], class_idx=class_idx)","fcedf343":"I've been wanting to play with this dataset for a while. I've also been wanting to try to see how do models built on [Toxic Comment Classification Challenge](https:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge\/) perform on non-competition \"real world\" data. Here I will just use one model that was built inside of a [kernel](https:\/\/www.kaggle.com\/tunguz\/bi-gru-lstm-cnn-poolings-fasttext). The kernel scores in the 0.984x AUC range. It's a respectable score, but well below the top solutions that scored in the 0.988x range. \n\nLet's take a look. First, let's load all the required packages.","c328a963":"What's Hillary's worst insult?","b15256b3":"Massive tax increases? yeah, I can see how this could be viewed as threatening.\n\nHow about the most insulting tweet?","7c1cd7c4":"Yeah, not much going on there. As predicted with very low probability of this actually being a threat.","97d7d055":"Ouch. That's definitely below the belt, but in a more indirect kind of way. And yeah, insluting. Good job, predictive modeling!\n\nLet's look at identity hate:","09639eb6":"OK, let's move onto Trump. First, his most toxic tweet:","5683b3ce":"### Define explainer helper function","79a9566a":"That one really made me LOL. And think. Is he mocking him for his \"identity\" of bing Jeb? Or mommy's boy? Or W's brother? Or a weakling? All of the above? So many choices  ...\n\nIn the end, this exercise shows both the strengths and limitations of algorithmic approach to toxic comment classification. Since the AUC score for the training sets is relatively high (almost 0.99 for  the top models), it is most likely that in the case human insight is even more relevant than for most other ML areas. Furthermore, even though we had a pretty large dataset to work with, it is very likely that in order to get even close to human level toxic text classification, we'd need several orders of magnitude larger training set, and\/or deeper natural text understanding models. ","dd1058a1":"(Notes from Ceshine: this is a fork of @tunguz's notebook. I added is the LIME text explainer from ELI5 library. From the output of the explainer it seems the hyperlinks is interfering the prediction, and removing them seems to be a good idea.  I've also removed the part that demonstrates the embedding matrix and the pretrain embeddings dataset that wasn't used in the actual prediction. )","a064d6c2":"Based on this summary statistics, it would seem that both of them score pretty low on average for all of the \"Toxic\" categories. However, there do seem to be a few notable \"highly probable\" problemeatic tweets in each one of the six categories, with notable exception of \"threat\". Which, I think, is a good thing. For what it's worth (not much at all, IMHO), Hillary's tweets seem to be, on the average, toxic, severaly toxic, and obscene, while Trump's tweets score higher on the average for threat, insult, and identity hate. \n\nLet's see what the \"worst offenders\" are in for both candidates. Let's start with the most toxic Hillary tweet.","20a607f7":"That's just weird: there is nothign toxic about it. The same tweet has been flagged as the most severly toxic and obscene tweet as well. Not very informative.\n\nNow how about threats?","0672e1f8":"Hmm, that's interesting: seem the algorithm has marked Hillary's ReTweet of Trump's tweet. Seems like there is something deep going on here. Or the algorithm is just plain unreliable. ","9ff45b2d":"Yeah, definitely insulting. On so many levels. I can't even ...\n\nAnd what about identity hate?","f7af45be":"Meh, not really toxic. Seems like the word \"mad\", or the high frequency of special characters, have flagged this tweet as toxic. The same tweet was also marked as the top tweet in both \"severe toxic\" and \"obscene\" categories. \n\nNow let's look at \"threats\":","c65eb7ad":"Now, let's load the data and all the vector embeddings. ","9e7f2c9e":"Now we'll load the actual trained model and make the predictions on our data."}}