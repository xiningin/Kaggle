{"cell_type":{"c9aa0eea":"code","6faa6d66":"code","42693c67":"code","2945b8dc":"code","9e128f7a":"code","10323710":"code","89bdd0d8":"markdown","b515c6fe":"markdown","131f2faa":"markdown","1b3a71e3":"markdown","40d84c43":"markdown","8084afa0":"markdown","13508f79":"markdown"},"source":{"c9aa0eea":"!pip install '\/kaggle\/input\/simple-transformers-pypi\/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '\/kaggle\/input\/simple-transformers-pypi\/simpletransformers-0.22.1-py3-none-any.whl' -q","6faa6d66":"from simpletransformers.question_answering import QuestionAnsweringModel\nimport pandas as pd\nimport numpy as np\nimport json","42693c67":"train_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsub_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')\n\ntrain = np.array(train_df)\ntest = np.array(test_df)\nuse_cuda = True","2945b8dc":"%%time\n\n\"\"\"\nPrepare testing data in QA-compatible format\n\"\"\"\n\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\ndef do_qa_test(test):\n    paragraphs = []\n    for line in test:\n        context = line[1]\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        if type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answers = []\n        answers.append({'answer_start': 1000000, 'text': '__None__'})\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        paragraphs.append({'context': context.lower(), 'qas': qas})\n        output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n    return paragraphs\n\nqa_test = do_qa_test(test)\n\nwith open('test.json', 'w') as outfile:\n    json.dump(qa_test, outfile)\n","9e128f7a":"MODEL_PATH = '\/kaggle\/input\/albert-train\/outputs\/checkpoint-10308-epoch-3\/' # MODEL PATH OF PRETRAINED MODEL\n\n\nmodel = QuestionAnsweringModel('albert', \n                               MODEL_PATH, \n                                   args={'reprocess_input_data': True,\n                                     'overwrite_output_dir': True,\n                                     'learning_rate': 5e-5,\n                                     'num_train_epochs': 3,\n                                     'max_seq_length': 192,\n                                     'doc_stride': 64,\n                                     'fp16': False,\n                                    },\n                              use_cuda=use_cuda)\n\n\n# model.train_model('\/kaggle\/input\/tweet-sentiment-extraction-json\/train.json') #UNCOMMENT to TRAIN","10323710":"%%time\n# Infering on trained model\npredictions = model.predict(qa_test)\npredictions_df = pd.DataFrame.from_dict(predictions)\n\nsub_df['selected_text'] = predictions_df['answer']\nsub_df.to_csv('submission.csv', index=False)\n\nsub_df.head()","89bdd0d8":"# <a name=\"reading\" id=\"2\"><\/a> 2. Converting test data to JSON\n\n* Train data is already converted here. https:\/\/www.kaggle.com\/vaishvik25\/tweet-sentiment-extraction-json<br>\n* But during submission kaggle use full test set there it is needed to convert in kernel. <br>\n* The Code of JSON convertion from https:\/\/www.kaggle.com\/jonathanbesomi\/question-answering-starter-pack","b515c6fe":"<center><font size='3'>Extraction :ALBERT\ud83d\ude1b [Train + Infer]<\/font><\/center>\n![](https:\/\/miro.medium.com\/max\/450\/1*p3Ste5R_iJzi5IcSmFkmtg.png)\n* This competition wants us to Extract the words which are responsible for the sentiment of the tweet.\n* IMP POINT: Almost 97 % Jaccard Similarity in train data \"text\" and \"selected_text\".In conclusion maybe  we can use neutral \"text\" as it is for \"selected_text\" for test data submission. <br>\n\n\n<font size='3' color='GREEN'>Contents<\/font>\n* [Install and imports](#1)\n* [Convert to JSON](#2)\n* [MODEL TRAIN](#3)\n* [MODEL INFER](#4)\n\nThis kernel is build from refing :https:\/\/www.kaggle.com\/vaishvik25\/question-answering-starter-pack","131f2faa":"# <a name=\"imports\" id=\"1\"><\/a>1. Install and Import","1b3a71e3":"<center><font size='6' color='blue'> ALBERT (WHAT? AND WHY?) <\/font><\/center><br>\n\n\n<font size='3'>\nWHAT ?<br>The ALBERT model was proposed in ALBERT: A Lite BERT for Self-supervised Learning of Language Representations by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. It presents two parameter-reduction techniques to lower memory consumption and increase the trainig speed of BERT:<br>\n] Splitting the embedding matrix into two smaller matrices<br>\n] Using repeating layers split among groups<br>\n] https:\/\/arxiv.org\/abs\/1909.11942 <br>\n<\/font>\n<br><br>\n<font size='3'>\nWHY ?<br> Its Currently Trending on SQuAD2.0 Leaderboard for Question Answering Model F1 Accuracy. So, may be for Q&A apporch it can give nice result.\n<\/font>\n![](https:\/\/i.ibb.co\/tsJm3fj\/albert.png) ","40d84c43":"# <a name=\"Training\" id=\"3\"><\/a> 3. Model Training ....\n\nUsing my training kernel out to save GPU time.<br>\nTo train uncomment train command.","8084afa0":"\n<font size='3' color='Blue'>If you find this kernel useful, consider doing an upvote [^]<\/font>\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSMkBhNBPXLA05LbULNGM--2DOdI4z_mQOcrBHkKoLaPA4BwgpI&usqp=CAU)","13508f79":"# <a name=\"Infer\" id=\"4\"><\/a> 4. Model INFER"}}