{"cell_type":{"77b50c9b":"code","0cc0e709":"code","0b04743d":"code","102ad03b":"code","8a69c1c2":"code","1efad887":"code","f689b0bd":"code","2e6e0e43":"code","84d50fb1":"code","02f0de14":"code","406b82bf":"code","fa0feac6":"code","9c444649":"code","0ce685fb":"code","6e64cb62":"code","2a4b4830":"code","a2885675":"code","41892e63":"code","fb78cc58":"code","dd13591c":"code","fc6cd595":"code","acb04d01":"code","85c69b37":"code","7c06645f":"markdown","d307b0de":"markdown","c270e76f":"markdown","08447530":"markdown","e1970e6e":"markdown","e1c34a3f":"markdown","1ab30381":"markdown","94693921":"markdown","dfa2aa9f":"markdown","121b67d4":"markdown","0e46dc9f":"markdown","4ff29359":"markdown","ee4f47d8":"markdown","196bc35d":"markdown","cc56879e":"markdown"},"source":{"77b50c9b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\n%pylab inline\nimport matplotlib.image as mpimg\nfrom keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D\n\nfrom keras.preprocessing import image\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","0cc0e709":"df=pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntrain = df[:]\nprint(train.shape)\ntrain.head()","0b04743d":"test= pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","102ad03b":"X_train_dataset = (train.iloc[:, 1:].values).astype('float32')\ny_train_dataset = train.iloc[:, 0].values.astype('int32')\n\nx_test_dataset = test.values.astype('float32')","8a69c1c2":"X_train_dataset = X_train_dataset.reshape(\n                        X_train_dataset.shape[0], 28, 28)\nprint(X_train_dataset.shape)\nprint(y_train_dataset.shape)\n\nx_test_dataset = x_test_dataset.reshape(x_test_dataset.shape[0], 28, 28)\nx_test_dataset.shape","1efad887":"\nfig=plt.figure(figsize=(7, 7))\ncolumns = 3\nrows = 2\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    img = X_train_dataset[i]\n    plt.imshow(img)\n    # if want to show gray image\n    # plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train_dataset[i])\nplt.show()\n","f689b0bd":"X_train_dataset = X_train_dataset.reshape(\n                    X_train_dataset.shape[0], 28, 28, 1)\nprint(X_train_dataset.shape)\n\nx_test_dataset = x_test_dataset.reshape(x_test_dataset.shape[0], 28, 28, 1)\nx_test_dataset.shape","2e6e0e43":"import tensorflow as tf\n\nfig=plt.figure(figsize=(7, 7))\ncolumns = 3\nrows = 2\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    img = X_train_dataset[i]\n    plt.imshow(img.squeeze(),cmap=plt.get_cmap('gray'))\n    plt.title(y_train_dataset[i])\n    \nplt.show()\n","84d50fb1":"mean_px = X_train_dataset.mean().astype(np.float32)\nstd_px = X_train_dataset.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px","02f0de14":"y_train_dataset","406b82bf":"from sklearn.preprocessing import LabelEncoder\nprint(y_train_dataset[:3])\nlb = LabelEncoder()\nlb.fit(y_train_dataset)\ny_train_dataset = lb.transform(y_train_dataset)\n\ndata = pd.get_dummies(y_train_dataset, columns = ['label'])\ny_train_dataset = data[:]\nprint(y_train_dataset[:3])","fa0feac6":"# fixing random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","9c444649":"gen = image.ImageDataGenerator()\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False,  \n        vertical_flip=False)\n\ndatagen.fit(X_train_dataset)\n","0ce685fb":"from sklearn.model_selection import train_test_split\nX = X_train_dataset\ny = y_train_dataset\nX_train, X_val, y_train, y_val = train_test_split(X_train_dataset, y_train_dataset, test_size=0.10, random_state=42)\n\nprint('X_train {},X_val {}, y_train {}, y_val {}'.format(X_train.shape, \n                                                         X_val.shape, \n                                                         y_train.shape, y_val.shape))\n","6e64cb62":"from keras.layers import Convolution2D, MaxPooling2D\n\ndef cnn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(pool_size=(2,2)),\n        BatchNormalization(axis=1),\n        \n        Convolution2D(64,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(pool_size=(2,2)),\n        Flatten(),\n        BatchNormalization(),\n        \n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dense(10, activation='softmax')\n        ])\n    \n    model.compile(optimizer='adam' , loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","2a4b4830":"model = cnn_model()\nmodel.optimizer.lr=0.0001\n\nhistory=model.fit_generator(datagen.flow(X_train_dataset,\n                            y_train_dataset, batch_size=84),\n                            steps_per_epoch=42000, \n                            epochs=5, \n                            validation_data = (X_val,y_val)\n                           )","a2885675":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_pred_classes[:5]\n\nx = y_val.stack()\nY_true = pd.Series(pd.Categorical(x[x!=0].index.get_level_values(1)))\n","41892e63":"from sklearn.metrics import confusion_matrix\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nconfusion_mtx","fb78cc58":"import seaborn as sns\ndef plot_cm(y_true, y_pred, figsize=(20,10)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n\nplot_cm(Y_true, Y_pred_classes)","dd13591c":"prediction = model.predict_classes(x_test_dataset)","fc6cd595":"my_submission = pd.DataFrame({\"ImageId\": list(range(1,len(prediction)+1)),\n                         \"Label\": prediction})\nmy_submission.to_csv(\"submission.csv\", index=False, header=True)","acb04d01":"var = pd.read_csv(\".\/submission.csv\")","85c69b37":"var[:5]","7c06645f":"**Predicting new value using the trained model.**","d307b0de":"# taking all float type values to X_train_dataset and integer values to y_train_dataset","c270e76f":"# Splitting the dataset\n*spliting within 4 variable which will be used as training, tesing and validating the dataset.*","08447530":"# Preprocessing images","e1970e6e":"# Visualizing the dataset","e1c34a3f":"# confusion matrix\n**calculating confusion matrix to get the false negative, false positive, true negative and true positive values predicted by the classfier.**","1ab30381":"**Building a model**","94693921":"# Loading training and test data","dfa2aa9f":"# ****importing all libraries****","121b67d4":"# Convolutional Neural Network\n> making change in images so that the classifier can learn more uniquely","0e46dc9f":"# Transform categorical data\n**Transforming all the labels into dummy variables as it is a multiclass classification problem.**","4ff29359":"# Reshaping images\nThink about it, how would you store 60k images 28 by 28 pixels if it was RGB?\n\nFor each pixel you would need 3 scalars (each for one channel), so it would be 60000x28x28x3.\n\nAnd how many channels you need when the image is in greyscale? Just one, so it would be 60000x28x28x1","ee4f47d8":"**compiling the model**","196bc35d":"**saving the prediction to a csv file**","cc56879e":"# Convert train datset to (num_images, img_rows, img_cols) format"}}