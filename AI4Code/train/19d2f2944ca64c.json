{"cell_type":{"4d6a97b2":"code","39ff3f75":"code","98ca5331":"code","a6b76e89":"code","18ea6bab":"code","5f9c3688":"code","b29ea6c3":"code","9d128c7c":"code","98381fbf":"code","c0230d60":"code","664791b1":"code","0ef80e3f":"code","e43a3a89":"code","ecadefa2":"code","e3fc6ef7":"code","720bfa3e":"code","3caec9d2":"code","54cfdf36":"code","582d9a80":"code","195dbca5":"code","ab50c609":"code","2d461bc5":"code","61d39f3a":"code","913f0b74":"code","b77d91f7":"code","d764e2a5":"code","7e04839d":"code","18344839":"code","0f7eaa0d":"markdown","58bc2918":"markdown","ed482804":"markdown","21d6a876":"markdown","e053be6f":"markdown","9f9f4bdd":"markdown","47236b05":"markdown","a7e6871c":"markdown","4c707d86":"markdown","6b6cc882":"markdown","84300ec3":"markdown","4001cb92":"markdown","cce60f60":"markdown","7df9b553":"markdown","321fbc83":"markdown","6f279aee":"markdown","9f904eb0":"markdown","349cb158":"markdown","7f9041bf":"markdown","7a1af1fe":"markdown","1c55f554":"markdown","ceaf09ca":"markdown"},"source":{"4d6a97b2":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndata = pd.read_csv(\"..\/input\/adult.csv\")\n","39ff3f75":"print(len(data))\ndata.head(10)","98ca5331":"data.isnull().sum()","a6b76e89":"data.dtypes","18ea6bab":"sns.countplot(data['income'])\nplt.show()","5f9c3688":"# Sex distribution\nsns.countplot(data['sex'])\nplt.show()","b29ea6c3":"# Age distribution\nages = data['age'].hist(bins=max(data['age'])-min(data['age']))\nmean_val = np.mean(data['age'])\nplt.axvline(mean_val, linestyle='dashed', linewidth=2, color='yellow', label='mean age')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.legend()\nplt.show()","9d128c7c":"data['hours.per.week'].hist()\nplt.xlabel('hours per week')\nplt.ylabel('count')\nplt.show()","98381fbf":"fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(20, 20))\nplt.subplots_adjust(hspace=0.68)\nfig.delaxes(axs[3][1])\n\n\n# Workclass\nwc_plot = sns.countplot(data['workclass'], ax=axs[0][0])\nwc_plot.set_xticklabels(wc_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Native country\nnc_plot = sns.countplot(data['native.country'], ax=axs[0][1])\nnc_plot.set_xticklabels(nc_plot.get_xticklabels(), rotation=72, ha=\"right\")\n\n# Education\norder=['Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th', 'HS-grad',\n       'Some-college', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Masters', 'Prof-school', 'Doctorate']\ned_plot = sns.countplot(data['education'], order=order, ax=axs[1][0])\ned_plot.set_xticklabels(ed_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Marital status\nms_plot = sns.countplot(data['marital.status'], ax=axs[1][1])\nms_plot.set_xticklabels(ms_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Relationship\nrel_plot = sns.countplot(data['relationship'], ax=axs[2][0])\nrel_plot.set_xticklabels(rel_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Race\nrace_plot = sns.countplot(data['race'], ax=axs[2][1])\nrace_plot.set_xticklabels(race_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\n# Occupation\nocc_plot = sns.countplot(data['occupation'], ax=axs[3][0])\nocc_plot.set_xticklabels(occ_plot.get_xticklabels(), rotation=40, ha=\"right\")\n\nplt.show()","c0230d60":"plt.figure(figsize=(24, 6))\nro = sns.countplot(data['occupation'], hue=data['sex'])\nro.set_xticklabels(ro.get_xticklabels(), rotation=30, ha=\"right\")\nplt.show()\n","664791b1":"plt.figure(figsize=(20, 6))\nro = sns.countplot(data['education'], hue=data['sex'], order=order)\nro.set_xticklabels(ro.get_xticklabels(), rotation=40, ha=\"right\")\n#ro.set_yscale('log')\nplt.show()","0ef80e3f":"data['income'] = data['income'].map({'<=50K': 0, '>50K': 1}) ","e43a3a89":"fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(24, 28))\n#fig.delaxes(axs[3][1])\nplt.subplots_adjust(hspace=0.4)\n\n# education and income\nsns.catplot(x=\"education\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", order=order, ax=axs[0][0])\naxs[0][0].set_xticklabels(axs[0][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[0][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"workclass\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[0][1])\naxs[0][1].set_xticklabels(axs[0][1].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[0][1].set_ylabel(\">50K probability\")\n\n\nsns.catplot(x=\"relationship\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[1][0])\naxs[1][0].set_xticklabels(axs[1][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[1][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"marital.status\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[1][1])\naxs[1][1].set_xticklabels(axs[1][1].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[1][1].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"race\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[2][0])\naxs[2][0].set_xticklabels(axs[2][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[2][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"native.country\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[2][1])\naxs[2][1].set_xticklabels(axs[2][1].axes.get_xticklabels(), rotation=55, ha=\"right\")\naxs[2][1].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"sex\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[3][0])\naxs[3][0].set_xticklabels(axs[3][0].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[3][0].set_ylabel(\">50K probability\")\n\nsns.catplot(x=\"occupation\", y=\"income\", data=data, kind=\"bar\", height = 6, palette = \"muted\", ax=axs[3][1])\naxs[3][1].set_xticklabels(axs[3][1].axes.get_xticklabels(), rotation=40, ha=\"right\")\naxs[3][1].set_ylabel(\">50K probability\")\n\n#ed_income.set_ylabels(\">50K probability\")\n\nfor i in range(2,10):\n        plt.close(i)\n\nplt.show()","ecadefa2":"plt.figure(figsize=(20, 6))\nsns.countplot(data['marital.status'], hue=data['income'])\nplt.show()","e3fc6ef7":"data['sex'] = data['sex'].map({'Male': 1, 'Female': 0}) ","720bfa3e":"data['race'] = data['race'].map({'White': 1, 'Asian-Pac-Islander': 1, 'Black':0, 'Amer-Indian-Eskimo':0, 'Other':0}) \ndata['relationship'] = data['relationship'].map({'Not-in-family':0, 'Unmarried':0, 'Own-child':0, 'Other-relative':0, 'Husband':1, 'Wife':1})\ndata['marital.status'] = data['marital.status'].map({'Widowed':0, 'Divorced':0, 'Separated':0, 'Never-married':0, 'Married-civ-spouse':1, 'Married-AF-spouse':1, 'Married-spouse-absent':0})","3caec9d2":"g = sns.heatmap(data[['relationship', 'marital.status']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")\nplt.show()","54cfdf36":"data.drop(['marital.status'], axis=1,inplace=True)","582d9a80":"# data.drop(['workclass', 'education', 'occupation', 'native.country'], axis=1,inplace=True)\n\ndata.drop(['education'], axis=1,inplace=True)\n\nlabels = ['workclass', 'occupation', 'native.country']\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor l in labels:\n    data[l]=le.fit_transform(data[l])\n\n","195dbca5":"data.head(10)","ab50c609":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, StratifiedKFold, learning_curve, train_test_split, KFold\n# from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.svm import SVC","2d461bc5":"seed = 42\n\nfrom sklearn.preprocessing import StandardScaler\n\nX = StandardScaler().fit_transform(data.loc[:, data.columns != 'income'])\nY = data['income']\n\n# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n\nkf = KFold(n_splits=10, shuffle=True, random_state=seed)\n","61d39f3a":"a = len(data.loc[data.income==0])\/len(data)\nprint(a)","913f0b74":"\nfig, axs = plt.subplots(ncols=2, nrows=2, figsize=(24, 14))\n\n\nclassifiers = [\n    LogisticRegression(solver='newton-cg'),\n    KNeighborsClassifier(n_neighbors=17), # Some trial and error I don't show went into this hyperpa\n    LinearDiscriminantAnalysis(),\n    GaussianNB()\n]\n\n\nfor i, c in enumerate(classifiers):\n    \n    x_axs = i%2\n    y_axs = int(i\/2)\n    # print(c)\n    print(type(c).__name__)\n    pred = cross_val_predict(c, X, Y, cv=kf)\n    print(\"Accuracy score:\", round(accuracy_score(Y, pred), 4), '\\n')\n\n    sns.heatmap(confusion_matrix(Y, pred), annot=True, fmt='g', ax=axs[y_axs][x_axs])\n    axs[y_axs][x_axs].set_xlabel('Predicted')\n    axs[y_axs][x_axs].set_ylabel('Real')\n    axs[y_axs][x_axs].set_title(type(c).__name__)\n\nplt.show()","b77d91f7":"import warnings\nwarnings.filterwarnings(action='ignore')\nfig, axs = plt.subplots(ncols=2, nrows=3, figsize=(24, 21))\n\nclassifiers = [\n    DecisionTreeClassifier(),\n    BaggingClassifier(),\n    RandomForestClassifier(),\n    ExtraTreesClassifier(),\n    GradientBoostingClassifier(),\n    AdaBoostClassifier()\n]\n\n\nfor i, c in enumerate(classifiers):\n    \n    x_axs = i%2\n    y_axs = int(i\/2)\n    \n    # print(c)\n    print(type(c).__name__)\n    pred = cross_val_predict(c, X, Y, cv=kf)\n    print(\"Accuracy score:\", round(accuracy_score(Y, pred), 4), '\\n')\n    \n    sns.heatmap(confusion_matrix(Y, pred), annot=True, fmt='g', ax=axs[y_axs][x_axs])\n    axs[y_axs][x_axs].set_xlabel('Predicted')\n    axs[y_axs][x_axs].set_ylabel('Real')\n    axs[y_axs][x_axs].set_title(type(c).__name__)\n\nplt.show()","d764e2a5":"'''\n# This takes about 2 hours to run\nparams = {'max_depth': [5, 6, 7], \n         'n_estimators': [100, 150, 200],\n          'learning_rate': [0.1, 0.07, 0.05],\n          'max_features': ['sqrt', 'log2', 3, 4, 5]\n         }\n'''\n\n\nparams = {'max_depth': [6], \n         'n_estimators': [200],\n          'learning_rate': [0.07, 0.06],\n          'max_features': [3,4]\n         }\n\nclassifier = GradientBoostingClassifier()\n\ngrid = GridSearchCV(classifier, param_grid=params, cv=kf)\nsearch_result = grid.fit(X, Y)\n","7e04839d":"# GridSearch results\nmeans = search_result.cv_results_['mean_test_score']\nparams = search_result.cv_results_['params']\nfor m, p in zip(means, params):\n    print(f\"{m} with: {p}\")","18344839":"p = np.argmax(means)\nbest_param = params[p]\n\nfinal_model = GradientBoostingClassifier(**best_param)\n\nprint(final_model)\npred = cross_val_predict(final_model, X, Y, cv=kf)\nprint(\"Accuracy score:\", round(accuracy_score(Y, pred), 4), '\\n')\n\nsns.heatmap(confusion_matrix(Y, pred), annot=True, fmt='g')\nplt.show()\n","0f7eaa0d":"\n### How do features relate to one another?","58bc2918":"Gradient Boosting with no hyperparameter tuning gets to 86.58% accuracy. Not bad. Let's see if we can do better.","ed482804":"## Prediction","21d6a876":"relationship and marital.status contain the same information now, so one of them can be removed","e053be6f":"Logistic regression performs best with 84.25% accuracy. \n","9f9f4bdd":"The dataset is ready.","47236b05":"One would get a 76% accuracy by just always predicting <=50k. Our model has to do better than that or it's not learning anything.","a7e6871c":"#### Another way of visualizing this","4c707d86":"## Data Preparation\n\nNow the data needs to be prepared for prediction.","6b6cc882":"### Distribution of features","84300ec3":"### How do features relate to income?","4001cb92":"GridSearchCV allows to try out a lot of hyperparameters at once.","cce60f60":"### Model Tuning","7df9b553":"### Starting with some simple models","321fbc83":"LabelEncoder can be used to transform the rest of the categorical features.","6f279aee":"## Exploratory Data Analysis","9f904eb0":"Final prediction accuracy: 87.35%","349cb158":"Good.","7f9041bf":"#### Importing the relevant libraries","7a1af1fe":"# Adult Census Income EDA and Prediction\n\nIn this kernel I work with the UCI Adult Census Income dataset. The prediction task is to determine whether a person makes over $50K a year. I start with an exhaustive EDA, and I then train various models to solve the prediction task.","1c55f554":"#### Preparing data for training and testing with k-fold Cross-Validation","ceaf09ca":"### More complex models"}}