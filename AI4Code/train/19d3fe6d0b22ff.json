{"cell_type":{"2061ac2d":"code","8bf7a73d":"code","2deb4296":"code","16b1d22e":"code","e7e432f4":"code","6c35ce51":"code","7d777b6d":"code","f85cec7f":"code","d3996f33":"code","f8906048":"code","829b1b96":"code","eb99408c":"markdown","87a91d95":"markdown","833d47e5":"markdown"},"source":{"2061ac2d":"# load packages\nimport pandas as pd\nimport numpy as np\nimport math\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import LeaveOneGroupOut\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\n\nfrom catboost import CatBoostRegressor","8bf7a73d":"# define function to build model, perform cv evaluation and make prediction\ndef CatBoost_model_logo(train_data, train_label, third_party_group, test_data, \n                        model_seed, learning_rate, depth, l2_leaf_reg, random_strength, \n                        bagging_temperature, grow_policy, leaf_estimation_method, eval_metric):\n    model = CatBoostRegressor(loss_function='RMSE', iterations=80000, od_type='Iter', thread_count=-1, \n                              random_seed=model_seed, learning_rate=learning_rate,  depth=depth, \n                              eval_metric=eval_metric, grow_policy=grow_policy, use_best_model=True,\n                              leaf_estimation_method=leaf_estimation_method, l2_leaf_reg=l2_leaf_reg, \n                              random_strength=random_strength, bagging_temperature=bagging_temperature)\n    # \n    pred_y_train_np = np.zeros(shape=(train_data.shape[0]))        \n    pred_y_test_np = np.zeros(shape=(test_data.shape[0]))        \n    feature_importance_df = pd.DataFrame(columns=['feature_name','feature_importance'])   \n    feature_importance_df['feature_name'] = train_data.columns\n    feature_importance_df['feature_importance'] = 0\n    # logo cv evaluation\n    folds = 10  # 10 months in training set\n    logo = LeaveOneGroupOut()\n    counter = 0\n    for train_index, test_index in logo.split(train_data, train_label, third_party_group):\n        X_train, X_test = train_data.loc[train_index], train_data.loc[test_index]\n        y_train, y_test = train_label.loc[train_index], train_label.loc[test_index]\n        # train\n        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, early_stopping_rounds=500)\n        pred_y_train_np[test_index] = np.exp(model.predict(X_test))      \n        pred_y_test_np = pred_y_test_np + np.exp(model.predict(test_data))\/folds    \n        feature_importance_df['feature_importance'] = feature_importance_df['feature_importance'] + (model.get_feature_importance()\/folds)\n        print('Fold', str(counter), 'RMSLE:', np.sqrt(mean_squared_log_error(np.exp(y_test), pred_y_train_np[test_index])), \n              'RMSE:', np.sqrt(mean_squared_error(np.exp(y_test), pred_y_train_np[test_index])))\n        counter = counter + 1\n    print('Total ', 'RMSLE:', np.sqrt(mean_squared_log_error(np.exp(train_label), pred_y_train_np)),\n          'RMSE:', np.sqrt(mean_squared_error(np.exp(train_label), pred_y_train_np)))\n    return pred_y_test_np, pred_y_train_np, feature_importance_df","2deb4296":"# load raw data\ntrain = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv') \ntrain = train[:-1]     # remove last row\ntest = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\ntarget_columns = ['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\nsensor_columns = ['sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']\nweather_columns = ['deg_C', 'relative_humidity', 'absolute_humidity']\n# log transformation\ntrain[target_columns] = np.log(train[target_columns])\n# combine training set and testing set\nfull_data = pd.concat([train, test])\nfull_data['date_time'] = full_data['date_time'].astype('datetime64')    \ntrain_months = full_data[\"date_time\"].dt.month[:len(train)]    # third-party group to perform leave one group out cv\n# new weather-related features\nfull_data['max_absolute_humidity'] = (full_data['absolute_humidity']*100)\/full_data['relative_humidity']\npart1 = np.log(full_data['relative_humidity']\/100)\npart2 = 17.625*full_data['deg_C']\/(243.04+full_data['deg_C'])\nfull_data['dew_point'] = 243.04*(part1+part2)\/(17.625-part1-part2)\n# new time-related features\nfull_data['dayofweek'] = full_data['date_time'].dt.weekday  \nfull_data['weekend'] = np.where(full_data['date_time'].dt.dayofweek>=5, 1, 0)\nfull_data['hourofday'] = full_data['date_time'].dt.hour\nfull_data['peak_hour'] = np.where(((full_data['hourofday'].isin(np.arange(8, 20, 1)))&(full_data['weekend']==0))|\n                                  ((full_data['hourofday'].isin(np.arange(12, 24, 1)))&(full_data['weekend']==1)), 1, 0)\nfull_data['peak_month'] = np.where(full_data['date_time'].dt.month.isin([9,10,11,12,1,2,3,4,5]), 1, 0)\n# other feature\nfull_data['outlier'] = np.where((full_data['deg_C']>20)&(full_data['max_absolute_humidity']<1), 1, 0)  # outlier\n# use sin and cos to capture cyclic pattern\ndiff = full_data['date_time'] - min(full_data['date_time'])\n# yearly pattern\ndays = diff.dt.days\nfull_data['year_1_sin'] = np.sin(2 * math.pi * days \/ (365 * 1)) \nfull_data['year_1_cos'] = np.cos(2 * math.pi * days \/ (365 * 1))\nfull_data['year_2_sin'] = np.sin(2 * math.pi * days \/ (365 * 2)) \nfull_data['year_2_cos'] = np.cos(2 * math.pi * days \/ (365 * 2)) \nfull_data['year_3_sin'] = np.sin(2 * math.pi * days \/ (365 * 3)) \nfull_data['year_3_cos'] = np.cos(2 * math.pi * days \/ (365 * 3)) \nfull_data['year_4_sin'] = np.sin(2 * math.pi * days \/ (365 * 4)) \nfull_data['year_4_cos'] = np.cos(2 * math.pi * days \/ (365 * 4)) \n# daily pattern\nseconds = diff.dt.seconds\nfull_data['day_1_sin'] = np.sin(2 * math.pi * seconds \/ ( 3600 * 24 * 1))\nfull_data['day_1_cos'] = np.cos(2 * math.pi * seconds \/ ( 3600 * 24 * 1))\nfull_data['day_2_sin'] = np.sin(2 * math.pi * seconds \/ ( 3600 * 24 * 2))\nfull_data['day_2_cos'] = np.cos(2 * math.pi * seconds \/ ( 3600 * 24 * 2))\nfull_data['day_7_sin'] = np.sin(2 * math.pi * seconds \/ ( 3600 * 24 * 7))\nfull_data['day_7_cos'] = np.cos(2 * math.pi * seconds \/ ( 3600 * 24 * 7))\n# lag data    \nlags = [1, 4, 24, 7*24]\nfor feature in weather_columns+sensor_columns:\n    temp = full_data[feature]\n    # forwards\n    for lag in lags:\n        lag_name = feature + '_future_' + str(lag)\n        temp_lag = full_data[feature].shift(periods=-lag, fill_value=0)\n        full_data[lag_name] = (temp_lag - temp)\n    # backwards\n    for lag in lags:\n        lag_name = feature + '_past_' + str(lag)\n        temp_lag = full_data[feature].shift(periods=lag, fill_value=0)\n        full_data[lag_name] = (temp_lag - temp)\n# split full dataset\nfull_data = full_data.drop(columns=['date_time'])\ntrain = full_data[:len(train)].copy()\ntest = full_data[len(train):].drop(columns=target_columns).copy()\nprint(train.shape, test.shape)","16b1d22e":"# predict target_carbon_monoxide\ndrop_feature_carbon_monoxide = ['absolute_humidity_past_1','sensor_4_past_1','relative_humidity_past_1','relative_humidity_future_1','deg_C_past_1','deg_C_future_1']\nX_carbon_monoxide = train.drop(columns=target_columns+drop_feature_carbon_monoxide)\ny_carbon_monoxide = train['target_carbon_monoxide']\ntest_carbon_monoxide = test.drop(columns=drop_feature_carbon_monoxide)\nprint(X_carbon_monoxide.shape, test_carbon_monoxide.shape)\n#\ntest_y_carbon_monoxide_logo, train_y_carbon_monoxide_logo, feature_importance_carbon_monoxide_logo = CatBoost_model_logo(\n                    train_data=X_carbon_monoxide, train_label=y_carbon_monoxide, third_party_group=train_months, test_data=test_carbon_monoxide, \n                    model_seed=42, learning_rate=0.01, depth=6, l2_leaf_reg=8.9, random_strength=1.95, bagging_temperature=8.38, \n                    grow_policy='Lossguide', eval_metric='RMSE', leaf_estimation_method='Newton')","e7e432f4":"# top 20 important features\nplt.figure(figsize=(12,6))\nsns.barplot(data=feature_importance_carbon_monoxide_logo.sort_values(by=['feature_importance'], ascending=False)[:20], \n            y='feature_name', x='feature_importance')\nplt.title('carbon_monoxide')\nplt.show()","6c35ce51":"# predict target_benzene\ndrop_feature_benzene = ['sensor_4_past_168','sensor_1_future_24','sensor_1_future_168','deg_C_future_1','dayofweek','year_3_cos',\n                        'weekend','year_3_sin','day_2_cos','year_4_sin','year_4_cos','day_7_cos','day_1_sin','peak_month']\nX_benzene = train.drop(columns=target_columns+drop_feature_benzene)\ny_benzene = train['target_benzene']\ntest_benzene = test.drop(columns=drop_feature_benzene)\nprint(X_benzene.shape, test_benzene.shape)\n#\ntest_y_benzene_logo, train_y_benzene_logo, feature_importance_benzene_logo  = CatBoost_model_logo(\n                    train_data=X_benzene, train_label=y_benzene, third_party_group=train_months, test_data=test_benzene, \n                    model_seed=42, learning_rate=0.166, depth=2, l2_leaf_reg=8.7, random_strength=1.54, bagging_temperature=3.34, \n                    grow_policy='Depthwise', eval_metric='RMSE', leaf_estimation_method='Newton')","7d777b6d":"# top 20 important features\nplt.figure(figsize=(12,6))\nsns.barplot(data=feature_importance_benzene_logo.sort_values(by=['feature_importance'], ascending=False)[:20], \n            y='feature_name', x='feature_importance')\nplt.title('target_benzene')\nplt.show()","f85cec7f":"# predict target_nitrogen_oxides\nX_nitrogen_oxides = train.drop(columns=target_columns)\ny_nitrogen_oxides = train['target_nitrogen_oxides']\n#\ntest_y_nitrogen_oxides_logo, train_y_nitrogen_oxides_logo, feature_importance_nitrogen_oxides_logo  = CatBoost_model_logo(\n                    train_data=X_nitrogen_oxides, train_label=y_nitrogen_oxides, third_party_group=train_months, test_data=test, \n                    model_seed=42, learning_rate=0.028, depth=6, l2_leaf_reg=3.12, random_strength=1.8, bagging_temperature=4.42, \n                    grow_policy='Depthwise', eval_metric='RMSE', leaf_estimation_method='Newton')","d3996f33":"# top 20 important features\nplt.figure(figsize=(12,6))\nsns.barplot(data=feature_importance_nitrogen_oxides_logo.sort_values(by=['feature_importance'], ascending=False)[:20], \n            y='feature_name', x='feature_importance')\nplt.title('target_nitrogen_oxides')\nplt.show()","f8906048":"# predict\nsubmission['target_carbon_monoxide'] = test_y_carbon_monoxide_logo\nsubmission['target_benzene'] = test_y_benzene_logo\nsubmission['target_nitrogen_oxides'] = test_y_nitrogen_oxides_logo\nsubmission.to_csv('submission_Catboost_logo.csv', index=False)","829b1b96":"submission.head(10)","eb99408c":"Use adding random feature method to find out which features negatively affect model's performance. After removing them, performance is further improved.","87a91d95":"Using leave one group out as cross validation method can get better result than normal kfold cross validation","833d47e5":"Modified from: https:\/\/www.kaggle.com\/remekkinas\/tps-7-ensemble-stacking-meta-regressor and https:\/\/www.kaggle.com\/andy6804tw\/catboost-18feature-cross-validation?scriptVersionId=68459420"}}