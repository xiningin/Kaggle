{"cell_type":{"81eab2aa":"code","53f89236":"code","953ef5d4":"code","ccfc8a1f":"code","7bddebd0":"code","d403cbdd":"code","ad909203":"code","39e7e695":"code","4521e6bd":"markdown","a61e0c9b":"markdown","7f01ff6a":"markdown","9d28b93a":"markdown","11759127":"markdown"},"source":{"81eab2aa":"#packages\n%matplotlib inline\nimport numpy as np \nimport pandas as pd \nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split \nimport sklearn.metrics as skm\nfrom sklearn.preprocessing import PolynomialFeatures\nimport operator as op\nimport sklearn.metrics as skm\nimport mlxtend as ml\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(rc={'figure.figsize':(10,8)})\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","53f89236":"# Loading the data\ndf = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')\ndf.head()","953ef5d4":"# Enconding categorical variables\ndf[\"sex\"] = df[\"sex\"].astype('category')\ndf[\"sex_cat\"] = df[\"sex\"].cat.codes\ndf[\"smoker\"] = df[\"smoker\"].astype('category')\ndf[\"smoker_cat\"] = df[\"smoker\"].cat.codes\ndf[\"region\"] = df[\"region\"].astype('category')\ndf[\"region_cat\"] = df[\"region\"].cat.codes\ndf.head()","ccfc8a1f":"# From this correlation matrix, the strongest predictors\n# appears to be smoker_cat, age, and bmi\nsns.heatmap(df.corr(), annot = True)","7bddebd0":"# Distribution of target variable by smoking status\nfig = plt.figure()\ngs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3)\n(ax1, ax2), (ax3, ax4) = gs.subplots(sharex=False, sharey=False)\nfig.suptitle('Histograms for Charges')\n\nsns.histplot(ax= ax1, data=df, x ='charges', hue='smoker_cat', \n             bins=10, palette=[\"green\", \"red\"], stat='count')\nax1.set_title(\"Charges Count\")\n\nsns.histplot(ax= ax2, data=df, x ='charges', hue='smoker_cat', \n             bins=10, palette=[\"green\", \"red\"], stat='frequency')\nax2.set_title(\"Charges Freq.\")\n\nsns.histplot(ax= ax3, data=df, x ='charges', hue='smoker_cat', \n             bins=10, palette=[\"green\", \"red\"], stat='count',\n            log_scale=True)\nax3.set_title(\"Log Charges Count\")\n\nsns.histplot(ax= ax4, data=df, x ='charges', hue='smoker_cat', \n             bins=10, palette=[\"green\", \"red\"], stat='frequency',\n            log_scale=True)\nax4.set_title(\"Log Charges Freq.\")\nplt.show()","d403cbdd":"# Scatter_plot btw Charges and BMI\ncharge_per_bmi = df.eval(\"charges\/bmi\").rename(\"charge_per_bmi\")\nsns.scatterplot(data=df, x='bmi', y='charges', \n                hue=charge_per_bmi, size=charge_per_bmi)\nplt.title('Charges By BMI')\n\nplt.show()","ad909203":"# Bar Plot\nsns.scatterplot(data=df, x='age', y='charges', hue='smoker_cat')","39e7e695":"class reg_models():\n    def __init__(self, df):\n        self.df = df\n        \n    def preprocessing(self, target, drop_vars):\n        self.X = self.df.drop(drop_vars+[target], axis=1).values\n        self.Y = self.df[target].values\n        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(self.X, self.Y, \n                                           test_size = 0.2, random_state=0) \n        return self\n        \n    def fit_predict(self, model_type):\n        # Multiple Linear Regression\n        if model_type == 'sk-lin':\n            model = LinearRegression(normalize=True)\n            model.fit(self.X_train, self.Y_train)\n            self.Y_pred = model.predict(self.X_test)\n            \n        if model_type == 'sk-poly':\n            reg = LinearRegression(normalize=True)\n            pol_feat = PolynomialFeatures(2)\n            X_train_transf = pol_feat.fit_transform(self.X_train)\n            X_test_transf = pol_feat.fit_transform(self.X_test)\n\n            model = reg.fit(X_train_transf, self.Y_train)\n            self.Y_pred = model.predict(X_test_transf)\n            \n        if model_type == 'rdg':\n            model = Ridge(alpha=0.00001, normalize=True)\n            model.fit(self.X_train, self.Y_train)\n            self.Y_pred = model.predict(self.X_test)\n        \n        if model_type == 'las':\n            model = Lasso(alpha=5, normalize=True)\n            model.fit(self.X_train, self.Y_train)\n            self.Y_pred = model.predict(self.X_test)\n            \n        if model_type == 'eln':\n            model = ElasticNet(alpha=0.00001, normalize=True)\n            model.fit(self.X_train, self.Y_train)\n            self.Y_pred = model.predict(self.X_test)\n\n        return self\n    \n    def performance(self):\n        rmse = round(skm.mean_squared_error(self.Y_test, self.Y_pred, squared=False), 2)\n        r2_score = round(skm.r2_score(self.Y_test, self.Y_pred), 4)\n        ev = round(skm.explained_variance_score(self.Y_test, self.Y_pred), 4)\n        mae = round(skm.mean_absolute_error(self.Y_test, self.Y_pred), 2)\n    \n        return [mae, rmse, r2_score, ev]\n\n# Running\ndrop_vars = ['sex', 'region', 'smoker']\n# Dictionary to store model performance \nmodels = {}\nreg = reg_models(df).preprocessing('charges', drop_vars)\nmodels[\"Mult. Reg\"] = reg.fit_predict('sk-lin').performance()\nmodels[\"Poly Reg\"] = reg.fit_predict('sk-poly').performance()\nmodels[\"Ridge Reg\"] = reg.fit_predict('rdg').performance()\nmodels[\"Lasso Reg\"] = reg.fit_predict('las').performance()\nmodels[\"ElaNet Reg\"] = reg.fit_predict('eln').performance()\n\n#table with the model_performances\nmodels_df = pd.DataFrame.from_dict(models, orient='index',\n                  columns=['MAE', 'RSME', 'R_sq', 'Expl. Var.'])\nmodels_df","4521e6bd":"* Add [interaction terms](https:\/\/en.wikipedia.org\/wiki\/Interaction_(statistics)#In_regression) to model how two or more independent variables together impact the target variable\n\n* Add [spines](http:\/\/people.stat.sfu.ca\/~cschwarz\/Consulting\/Trinity\/Phase2\/TrinityWorkshop\/Workshop-handouts\/TW-04-Intro-splines.pdf) to approximate piecewise linear models\n\n* Fit [isotonic regression](https:\/\/en.wikipedia.org\/wiki\/Isotonic_regression) to remove any assumption of the target function form\n\n* Fit non-parametric models, such as [MARS](https:\/\/en.wikipedia.org\/wiki\/Multivariate_adaptive_regression_splines)","a61e0c9b":"# Exploratory Data Analysis","7f01ff6a":"# Model Building & Evaluation","9d28b93a":"# Feature Engineering","11759127":"# Data Importing"}}