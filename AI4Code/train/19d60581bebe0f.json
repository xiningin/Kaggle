{"cell_type":{"32279355":"code","816cd970":"code","4f25b255":"code","f167aaee":"code","79bf3770":"code","2742de8e":"code","0ead4ec7":"code","7491172e":"code","52248a88":"code","5254d3b6":"code","adf68db6":"code","c4738e37":"code","ffa805e2":"code","2003a9d4":"code","41925f92":"code","a4f87f84":"code","fd1021c6":"code","5033391b":"code","3cb0af1f":"code","a7648f03":"code","12d92a38":"code","5b7027a7":"code","617ea8dd":"code","677f634d":"code","77e39636":"code","18273b8b":"code","a0d03735":"code","8a4bd009":"code","6702fc1e":"code","b38dd591":"code","8a3e14ef":"code","8d8b67c0":"code","d8d517a7":"code","8f87e2b2":"code","5b13bbc6":"code","e53ee81b":"code","c87eb297":"code","89dc5158":"code","c9676b9d":"code","9057ed45":"code","d04848a2":"code","ca2a705b":"code","af0ea65e":"code","0f4a749f":"code","26fda7fa":"code","4c9e588d":"code","12fd2cae":"code","beff315f":"code","fc2dde12":"code","4dbe2445":"code","236a4506":"code","fe71b7d3":"code","ef8aecdc":"code","a96b1619":"code","b97fd0b5":"code","8e08a51f":"code","1799d909":"code","04f2dcfd":"code","c72c2ccb":"code","ba756a75":"code","e98abaf3":"code","96e1daf0":"code","02215378":"code","27f765cd":"code","c1f19fd0":"code","b5b63fb4":"code","67715708":"code","10da0ec2":"code","eb20e017":"code","aa0d1e85":"code","2e10e2b5":"code","c55a7726":"code","ab8976d8":"code","a01cd7a7":"code","8a31784d":"code","7f5e7fbb":"code","c52e60ae":"code","9f8273df":"code","00c60795":"code","712557b9":"code","cf677de6":"code","657621b8":"markdown","2fa71189":"markdown","ceb44c8e":"markdown","a70174e6":"markdown","02048996":"markdown","f9719bb9":"markdown","64d3a511":"markdown","93848d9f":"markdown","8330b325":"markdown","efd1b052":"markdown","c9065e97":"markdown","c778d4fb":"markdown","30f24ded":"markdown","c90ef44e":"markdown","a9b5edac":"markdown","9e5ae63d":"markdown","789f9b7a":"markdown","3968487b":"markdown","31793638":"markdown","b95bc282":"markdown","e6133df1":"markdown","dc18fc7e":"markdown","ba905959":"markdown","ba63d2f2":"markdown","7869c0b1":"markdown","580554d9":"markdown","ed393e27":"markdown","3424ef63":"markdown","5f334a61":"markdown","0f75d122":"markdown"},"source":{"32279355":"import tifffile as tiff\nimport datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport glob\nimport datetime\nfrom tqdm.notebook import tqdm\n\nimport sklearn\n\nfrom sklearn.utils.class_weight import compute_class_weight\n\nfrom sklearn.inspection import permutation_importance\nfrom scipy.stats.mstats import gmean\n\n# Models\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import BaggingClassifier\nimport catboost\nfrom catboost import CatBoostClassifier\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nfrom sklearn.model_selection import cross_val_predict, train_test_split\nfrom sklearn.metrics import log_loss\n\nimport os","816cd970":"catboost.__version__ #0.22","4f25b255":"sklearn.__version__ #0.22.2","f167aaee":"eli5.__version__ #0.10.1","79bf3770":"dates_raw = [\ndatetime.datetime(2019, 6, 6, 0, 0),\ndatetime.datetime(2019, 7, 1, 0, 0),\ndatetime.datetime(2019, 7, 6, 0, 0),\ndatetime.datetime(2019, 7, 11, 0, 0),\ndatetime.datetime(2019, 7, 21, 0, 0),\ndatetime.datetime(2019, 8, 5, 0, 0),\ndatetime.datetime(2019, 8, 15, 0, 0),\ndatetime.datetime(2019, 8, 25, 0, 0),\ndatetime.datetime(2019, 9, 9, 0, 0),\ndatetime.datetime(2019, 9, 19, 0, 0),\ndatetime.datetime(2019, 9, 24, 0, 0),\ndatetime.datetime(2019, 10, 4, 0, 0),\ndatetime.datetime(2019, 11, 3, 0, 0)\n]\n\ndates = []\n\nfor i in range(13):\n    dt = \"\".join(str(dates_raw[i].date()).split(\"-\"))\n    dates.append(dt)","2742de8e":"bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12']","0ead4ec7":"# Including Cloud Layer\nbands_all = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12', 'CLD']","7491172e":"def load_file(fp):\n    \"\"\"Takes a PosixPath object or string filepath\n    and returns np array\"\"\"\n    \n    return tiff.imread(fp.__str__())","52248a88":"row_locs = []\ncol_locs = []\nfield_ids = []\nlabels = []\ntiles = []\n\nfor tile in range(4):\n    fids = f'..\/input\/crop-classification\/ref_african_crops_kenya_02_labels\/ref_african_crops_kenya_02_labels\/ref_african_crops_kenya_02_tile_0{tile}_label\/field_ids.tif'\n    labs = f'..\/input\/crop-classification\/ref_african_crops_kenya_02_labels\/ref_african_crops_kenya_02_labels\/ref_african_crops_kenya_02_tile_0{tile}_label\/labels.tif'\n    fid_arr = load_file(fids)\n    lab_arr = load_file(labs)\n    for row in range(len(fid_arr)):\n        \n        for col in range(len(fid_arr[0])):\n            if fid_arr[row][col] != 0:\n                row_locs.append(row)\n                col_locs.append(col)\n                field_ids.append(fid_arr[row][col])\n                labels.append(lab_arr[row][col])\n                tiles.append(tile)","5254d3b6":"df_generated = pd.DataFrame({\n    'fid':field_ids,\n    'label':labels,\n    'row_loc': row_locs,\n    'col_loc':col_locs,\n    'tile':tiles\n})","adf68db6":"df_generated.head()","c4738e37":"df_generated.shape","ffa805e2":"col_names = []\ncol_values = []\n\nfor tile in range(4): # 1) For each tile\n    print('Tile: ', tile)\n    for d in dates: # 2) For each date\n        print(str(d))\n#         d = ''.join(str(d.date()).split('-')) # Nice date string\n        t = '0' + str(tile)\n        for b in bands_all: # 3) For each band\n            col_name = d + '_' + b\n\n            if tile == 0:\n                # If the column doesn't exist, create it and populate with 0s\n                df_generated[col_name] = 0\n\n            # Load im\n            im = load_file(f\"..\/input\/crop-classification\/ref_african_crops_kenya_02_source\/ref_african_crops_kenya_02_source\/ref_african_crops_kenya_02_tile_{t}_{d}\/{b}.tif\")\n\n            # Going four levels deep. Each second on the outside is four weeks in this loop\n            # If we die here, there's no waking up.....\n            vals = []\n            for row, col in df_generated.loc[df_generated.tile == tile][['row_loc', 'col_loc']].values: # 4) For each location of a pixel in a field\n                vals.append(im[row][col])\n            df_generated.loc[df_generated.tile == tile, col_name] = vals","2003a9d4":"df_generated.head()","41925f92":"df_generated.shape","a4f87f84":"df_generated.to_csv(\"bands_ungrouped.csv\", index = False)","fd1021c6":"sample_submission = pd.read_csv(\"..\/input\/field-id\/SampleSubmission.csv\")","5033391b":"df_ungrouped = pd.read_csv(\".\/bands_ungrouped.csv\")","3cb0af1f":"df_ungrouped.head()","a7648f03":"df_ungrouped.shape","12d92a38":"# Spatial features to be merged with dataset (by Field ID) later on\nrow_size = df_ungrouped.groupby(\"fid\")[\"row_loc\"].nunique()\ncolumn_size = df_ungrouped.groupby(\"fid\")[\"col_loc\"].nunique()\nnum_pixels = df_ungrouped.groupby(\"fid\")[\"label\"].count()","5b7027a7":"# Grouped Data\ndf_grouped = df_ungrouped.groupby(\"fid\", as_index = False).mean()","617ea8dd":"# Dataframe for 1st modelling\ndf_all = df_grouped.copy()","677f634d":"# Dataframe for 2nd modelling\ndf_pixels = df_grouped.copy()","77e39636":"# Drop non-allowed features. Field ID is dropped later on as it's still needed for further processing\ndf_all = df_all.drop(columns = [\"row_loc\", \"col_loc\", \"tile\"])\ndf_pixels = df_pixels.drop(columns = [\"row_loc\", \"col_loc\", \"tile\"])","18273b8b":"cloud_columns = ['20190606_CLD', '20190701_CLD', '20190706_CLD', '20190711_CLD', '20190721_CLD', '20190805_CLD', '20190815_CLD', '20190825_CLD', '20190909_CLD', '20190919_CLD', '20190924_CLD', '20191004_CLD', '20191103_CLD']","a0d03735":"# Drop Cloud probabilities, and Field ID's in 2nd Dataframe.\n# Field ID in 1st Dataframe will be dropped later\ndf_pixels.drop(columns = cloud_columns + [\"fid\"], inplace = True)","8a4bd009":"df_all.head()","6702fc1e":"df_pixels.head()","b38dd591":"spectral_indices = [\"NDVI\", \"GNDVI\", \"EVI\", \"EVI2\", \"AVI\", \"BSI\", \"SI\", \"NDWI\", \"NDMI\", \"NPCRI\"]","8a3e14ef":"for i in range(13):\n#     Band Pixel values per timestamp\n    b1 = df_all.filter(like = \"B01\").values[:,i]\n    b2 = df_all.filter(like = \"B02\").values[:,i]\n    b3 = df_all.filter(like = \"B03\").values[:,i]\n    b4 = df_all.filter(like = \"B04\").values[:,i]\n    b5 = df_all.filter(like = \"B05\").values[:,i]\n    b6 = df_all.filter(like = \"B06\").values[:,i]\n    b7 = df_all.filter(like = \"B07\").values[:,i]\n    b8 = df_all.filter(like = \"B08\").values[:,i]\n    b8a = df_all.filter(like = \"B8A\").values[:,i]\n    b9 = df_all.filter(like = \"B09\").values[:,i]    \n    b11 = df_all.filter(like = \"B11\").values[:,i]\n    b12 = df_all.filter(like = \"B12\").values[:,i]\n    \n#     Computation of indices\n    ndvi = (b8 - b4) \/ (b8 + b4)\n    gndvi = (b8 - b3) \/ (b8 + b3)\n    evi = 2.5 * (b8 - b4) \/ ((b8 + 6.0 * b4 - 7.5 * b2) + 1.0)    \n    evi2 = 2.4 * (b8 - b4) \/ (b8 + b4 + 1.0)\n    avi = (b8 * (1 - b4) * (b8 - b4))\n    bsi = ((b11 + b4) - (b8 + b2)) \/ ((b11 + b4) + (b8 + b2))\n    si = ((1 - b2) * (1 - b3) * (1 - b4))\n    ndwi = (b3 - b8) \/ (b3 + b8)\n    ndmi = (b8 - b11) \/ (b8 + b11)\n    npcri = (b4 - b2) \/ (b4 + b2) \n    \n#     Add indices as features to 1st dataframe per timestamp\n    df_all[f'NDVI_{dates[i]}'] = ndvi \n    df_all[f'GNDVI_{dates[i]}'] = gndvi\n    df_all[f'EVI_{dates[i]}'] = evi\n    df_all[f'EVI2_{dates[i]}'] = evi2\n    df_all[f'AVI_{dates[i]}'] = avi\n    df_all[f'BSI_{dates[i]}'] = bsi\n    df_all[f'SI_{dates[i]}'] = si    \n    df_all[f'NDWI_{dates[i]}'] = ndwi\n    df_all[f'NDMI_{dates[i]}'] = ndmi\n    df_all[f'NPCRI_{dates[i]}'] = npcri","8d8b67c0":"# Add spectral indices statistics related to 1st dataframe\nfor i in spectral_indices:\n    df_all[f'{i}_min'] = df_all.filter(regex = f'^{i}').min(axis = 1)\n    df_all[f'{i}_max'] = df_all.filter(regex = f'^{i}').max(axis = 1)\n    df_all[f'{i}_avg'] = df_all.filter(regex = f'^{i}').mean(axis = 1)\n    df_all[f'{i}_std'] = df_all.filter(regex = f'^{i}').std(axis = 1)    ","d8d517a7":"# Add band pixel values statistics related to 2nd dataframe\nfor i in bands:\n    df_pixels[f'{i}_std'] = df_pixels.filter(like = f'_{i}').std(axis = 1)\n    df_pixels[f'{i}_max'] = df_pixels.filter(like = f'_{i}').max(axis = 1)\n    df_pixels[f'{i}_min'] = df_pixels.filter(like = f'_{i}').min(axis = 1)\n    df_pixels[f'{i}_avg'] = df_pixels.filter(like = f'_{i}').mean(axis = 1)","8f87e2b2":"# NB: \"new_df\" represents 1st dataframe\nnew_df = df_all.copy()","5b13bbc6":"new_df.head()","e53ee81b":"new_df[\"row_size\"] = new_df.fid.map(row_size)\nnew_df[\"col_size\"] = new_df.fid.map(column_size)\nnew_df[\"area\"] = new_df.apply(lambda row: row.row_size * row.col_size, axis = 1)\n# number of pixels covered by a field in the area computed\nnew_df[\"num_pixels\"] = new_df.fid.map(num_pixels)","c87eb297":"# Drop non-allowed Field ID in 1st dataframe\nnew_df = new_df.drop(columns = [\"fid\"])","89dc5158":"# 1st dataframe\ndf_all_train = new_df[new_df.label != 0].copy()\ndf_all_test = new_df[new_df.label == 0].copy()\n\ndf_all_train = df_all_train.reset_index(drop = True)\ndf_all_test = df_all_test.reset_index(drop = True)","c9676b9d":"# 2nd dataframe\ndf_pixels_train = df_pixels[df_pixels.label != 0].copy()\ndf_pixels_test = df_pixels[df_pixels.label == 0].copy()\n\ndf_pixels_train = df_pixels_train.reset_index(drop = True)\ndf_pixels_test = df_pixels_test.reset_index(drop = True)","9057ed45":"(df_all_train.shape, df_all_test.shape), (df_pixels_train.shape, df_pixels_test.shape)","d04848a2":"# Drop crop labels (0) from test sets\ndf_all_test.drop(\"label\", inplace = True, axis = 1)\ndf_pixels_test.drop(\"label\", inplace = True, axis = 1)","ca2a705b":"# 1st dataframe\ntrain_X_all = df_all_train.drop(\"label\", axis = 1)\ntrain_y_all = df_all_train.label","af0ea65e":"# 2nd dataframe\ntrain_X_pixels = df_pixels_train.drop(\"label\", axis = 1)\ntrain_y_pixels = df_pixels_train.label","0f4a749f":"train_X_all.shape, df_all_test.shape","26fda7fa":"train_X_pixels.shape, df_pixels_test.shape","4c9e588d":"# Class weights for cross validation\n# Cross validation weights are based on 80% of train set\nX_trn, X_val, y_trn, y_val = train_test_split(train_X_all, train_y_all, test_size = 0.2, stratify = train_y_all, random_state = 5, shuffle = True)\nlabel_weights1 = compute_class_weight(\"balanced\", np.unique(y_trn), y_trn)","12fd2cae":"label_weights1","beff315f":"# Class weights for full training\n# Cross validation weights are based on full train set\nlabel_weights2 = compute_class_weight(\"balanced\", np.unique(train_y_all), train_y_all)","fc2dde12":"# cb_pi --> catboost_permutation_importance\ncb_pi = CatBoostClassifier(n_estimators = 1400, learning_rate = 0.03, random_state = 11, task_type = \"GPU\")\ncb_pi.fit(X_trn, y_trn)","4dbe2445":"pi = PermutationImportance(cb_pi, random_state = 90, n_iter = 5)\npi.fit(X_val, y_val)","236a4506":"eli5.show_weights(pi, feature_names = train_X_all.columns.tolist(), top = None)","fe71b7d3":"pi_results = eli5.formatters.as_dataframe.explain_weights_df(pi, feature_names = train_X_all.columns.tolist())","ef8aecdc":"# feature importance weigth threshold is 0\nlow_importance = pi_results[pi_results.weight <= 0].feature.values","a96b1619":"low_importance","b97fd0b5":"features_to_drop = [\n    '20190815_CLD', '20191004_CLD', '20190919_CLD', '20190701_CLD',\n    '20190924_CLD', '20190706_CLD', 'SI_avg', '20190606_B07',\n    'BSI_max', 'BSI_20191103', '20190805_B04', '20191004_B03',\n    'SI_std', 'NPCRI_20190606', '20190919_B03', '20190805_B08',\n    'NPCRI_20190909', 'EVI_min', '20190721_B07', '20190711_B07',\n    '20190721_B05', 'AVI_20191103', 'SI_20190924', '20190805_B09',\n    '20190706_B09', 'EVI_20191004', 'EVI_20190711', '20191004_B08',\n    'NDVI_20191004', '20190825_B8A', '20190919_B01', '20190805_B06',\n    'GNDVI_20190706', 'SI_20190805', 'EVI2_20190805', '20190706_B11',\n    'col_size', '20190701_B04', 'GNDVI_20191004', 'GNDVI_20190924',\n    'NPCRI_max', 'EVI_20190701', 'BSI_20190711', '20190805_B12',\n    'SI_20191103', '20190919_B04', 'NDMI_20190924', 'BSI_avg',\n    'NPCRI_20190706', '20190919_B8A', '20190909_B05', '20190706_B06',\n    'GNDVI_20190606', '20190924_B8A', 'NDWI_20190701', 'AVI_avg',\n    'GNDVI_20190919', 'NDVI_20190606', 'NDVI_20191103', 'SI_20190919',\n    'GNDVI_20190721', 'NPCRI_20190721', '20190919_B09', '20190606_B01',\n    '20190825_B05', '20190909_B09', '20191004_B01', '20190805_B03',\n    'GNDVI_20191103', 'NPCRI_20190919', 'EVI_20190805', '20190706_B07',\n    '20190909_CLD', '20190825_B12', '20190606_B06', '20190909_B07',\n    'BSI_20190825', '20190805_B8A', '20190924_B09', '20190701_B07',\n    'EVI2_20190721', 'NPCRI_20190805'\n]","8e08a51f":"train_X_all = train_X_all.drop(columns = features_to_drop)\ndf_all_test = df_all_test.drop(columns = features_to_drop)","1799d909":"cb = CatBoostClassifier(n_estimators = 1500, learning_rate=0.03, depth = 6,\n                        random_state = 11, bagging_temperature = 1, task_type = \"GPU\")\n# Use \"class_weights = label_weights1\" for cross validation\ncb2 = CatBoostClassifier(n_estimators = 1100, learning_rate=0.03, depth = 6,\n                         random_state = 11, bagging_temperature = 1, task_type = \"GPU\", class_weights = label_weights2)\n\ncb_pixels = CatBoostClassifier(n_estimators = 1500, learning_rate=0.03, depth = 6, \n                               random_state = 11, bagging_temperature = 1, task_type = \"GPU\")\n# Use \"class_weights = label_weights1\" for cross validation\ncb2_pixels = CatBoostClassifier(n_estimators = 1100, learning_rate=0.03, depth = 6,\n                                random_state = 11, bagging_temperature = 1, task_type = \"GPU\", class_weights = label_weights2)\n\nlda = LinearDiscriminantAnalysis()\nbc = BaggingClassifier(base_estimator = lda, n_estimators = 30, random_state = 0)","04f2dcfd":"# Catboost\ncv_all_1 = cross_val_predict(cb, train_X_all, train_y_all, cv = 5, method = \"predict_proba\", verbose = 5)","c72c2ccb":"# Catboost with weights\ncv_all_2 = cross_val_predict(cb2, train_X_all, train_y_all, cv = 5, method = \"predict_proba\", verbose = 5)","ba756a75":"# Bagged LDA\ncv_all_3 = cross_val_predict(bc, train_X_all, train_y_all, cv = 5, method = \"predict_proba\", verbose = 5)","e98abaf3":"# Weighted Average of above 3 (in two steps)\ncv_all_1_2 = (0.72 * cv_all_1) + ((1 - 0.72) * cv_all_2)\ncv_all_1_2_3 = (0.7 * cv_all_1_2) + ((1 - 0.7) * cv_all_3)","96e1daf0":"# Catboost\ncv_pixels_1 = cross_val_predict(cb_pixels, train_X_pixels, train_y_pixels, cv = 5, method = \"predict_proba\", verbose = 5)","02215378":"# Catboost with weights\ncv_pixels_2 = cross_val_predict(cb2_pixels, train_X_pixels, train_y_pixels, cv = 5, method = \"predict_proba\", verbose = 5)","27f765cd":"# Bagged LDA\ncv_pixels_3 = cross_val_predict(bc, train_X_pixels, train_y_pixels, cv = 5, method = \"predict_proba\", verbose = 5)","c1f19fd0":"# Weighted Average of above 3 (in two steps)\ncv_pixels_1_2 = (0.76 * cv_pixels_1) + ((1 - 0.76) * cv_pixels_2)\ncv_pixels_1_2_3 = (0.67 * cv_pixels_1_2 ) + ((1 - 0.67) * cv_pixels_3)","b5b63fb4":"# Code to determine weights\nscores = []\n\nfor w in range(0, 100):\n    w = w \/ 100.\n#     two cross-validation results of choice should be imputed to determine appropriate weights\n    scores.append(log_loss(train_y_all, (w * cv_all_1_2_3) + ((1 - w) * cv_pixels_1_2_3)))\n\nbest_score = min(scores)\nweight = scores.index(best_score) \/ 100.\n\nprint(weight, best_score)","67715708":"cb.fit(train_X_all, train_y_all)","10da0ec2":"cb2.fit(train_X_all, train_y_all)","eb20e017":"bc.fit(train_X_all, train_y_all)","aa0d1e85":"test_preds_all_1 = cb.predict_proba(df_all_test)\ntest_preds_all_2 = cb2.predict_proba(df_all_test)\ntest_preds_all_3 = bc.predict_proba(df_all_test)","2e10e2b5":"# Level 1\ntest_preds_all = (0.72 * test_preds_all_1) + ((1 - 0.72) * test_preds_all_2)\n# Level 2\ntest_preds_all = (0.7 * test_preds_all) + ((1 - 0.7) * test_preds_all_3)","c55a7726":"cb_pixels.fit(train_X_pixels, train_y_pixels)","ab8976d8":"cb2_pixels.fit(train_X_pixels, train_y_pixels)","a01cd7a7":"bc.fit(train_X_pixels, train_y_pixels)","8a31784d":"test_preds_pixels_1 = cb_pixels.predict_proba(df_pixels_test)\ntest_preds_pixels_2 = cb2_pixels.predict_proba(df_pixels_test)\ntest_preds_pixels_3 = bc.predict_proba(df_pixels_test)","7f5e7fbb":"# Level 1\ntest_preds_pixels = (0.76 * test_preds_pixels_1) + ((1 - 0.76) * test_preds_pixels_2)\n# Level 2\ntest_preds_pixels = (0.67 * test_preds_pixels) + ((1 - 0.67) * test_preds_pixels_3)","c52e60ae":"# Level 3\ntest_preds = (0.68 * test_preds_all) + ((1 - 0.68) * test_preds_pixels)","9f8273df":"test_preds = pd.DataFrame(test_preds)","00c60795":"sample_submission.Crop_ID_1 = test_preds[0]\nsample_submission.Crop_ID_2 = test_preds[1]\nsample_submission.Crop_ID_3 = test_preds[2]\nsample_submission.Crop_ID_4 = test_preds[3]\nsample_submission.Crop_ID_5 = test_preds[4]\nsample_submission.Crop_ID_6 = test_preds[5]\nsample_submission.Crop_ID_7 = test_preds[6]","712557b9":"sample_submission.head()","cf677de6":"sample_submission.to_csv(\"SampleSub.csv\", index = False)","657621b8":"### Weighted Average","2fa71189":"## MODELLING\n\ncb = Catboost model - Dataframe 1  \ncb2 = Catboost (with class weights) -  Dataframe 1  \n\ncb_pixels = Catboost -  Dataframe 2  \ncb2_pixels = Catboost (with class weights) -  Dataframe 2 \n\nlda = LinearDiscriminantAnalysis model  \nbc = BaggingClassifier (Bagged Ensemble) with lda as it's base estimator  \n\n**NB: Catboost is trained with GPU enabled**","ceb44c8e":"1. Normalized Difference Vegetation Index (NDVI)\n2. Green Normalized Difference Vegetation Index (GNDVI)\n3. Enhanced Vegetation Index (EVI)\n4. Enhanced Vegetation Index 2 (EVI2)\n5. Advanced Vegetation Index (AVI)\n6. Bare Soil Index (BSI)\n7. Shadow Index (SI)\n8. Normalized Difference Water Index (NDWI)\n9. Normalized Difference Moisture Index (NDMI)\n10. Normalized Pigment Chlorophyll Ratio Index (NPCRI)","a70174e6":"### Two separate modelling was done on different set of features, and later combined through ensembling\n> ### 1st modelling \nFeatures used:\n1. Pixel values of each of the 12 bands, INCLUDING the cloud probabilities (for the 13 timestamps)\n2. Vegetation\/Spectral indices like NDVI, GNDVI, AVI etc, and relevant statistics related to the indices like mean, max etc.\n3. Spatial features - row_size, column_size (both indicating height, and width), area of field, and number of pixels covered by a field in the area computed  \n\nRelevant code variables are usually suffixed with \"_all\"  \n\n> ### 2nd modelling  (Pixel related)\nFeatures used:\n1. Pixel values of each of the 12 bands, EXCLUDING the cloud probabilities (for the 13 timestamps)\n2. Statistics related to pixel values of each band like mean, max etc.  \n\nRelevant code variables are usually suffixed with \"_pixels\"","02048996":"# DATA GENERATION - based on JW starter code\n> NB: Directory of competition data (multi spectral satellite images) should be named \"data\", and all relevant images should be included in their respective tile folder and sub folders","f9719bb9":"## Modelling Architecture - Explanation\n\nThe two different datasets each have the same model pipeline.  \n\nFor each of the datasets:  \n### Level 1\nTraining is done using both a CatboostClassifier (without class_weights), and another CatboostClassifier (with class_weights), denoted by \"cb\" and \"cb2\" respectively.  \nThe weighted average of the predictions from both classifiers are obtained, using:   \n1. 72% of cb,  and 28% of cb2 for dataset 1;\n2. 76% of cb, and 24% of cb2 for dataset 2  \n\n### Level 2\nThe model used for training here is a bagged ensemble (using sklearn's BaggingClassifier), with the LinearDiscriminantAnalysis alogrithm as the base estimator.  \nThe predicitons from the bagged classifier is then averaged (weighted) with the individual results from level 1, using:   \n1. 70% of level 1, and 30% of bagged classifier for dataset 1;  \n2. 67% of level 1, and 33% of bagged classifier for dataset 2  \n\n### Level 3\nThis level simply finds the weighted average of the final predictions from both datasets.  \nIt takes 68% of the final predictions from dataset 1, and 32% from dataset 2.  ","64d3a511":"## Final Predictions - Weighted Average of 2 parts","93848d9f":"# DATA PREPARATION\/PRE-PROCESSING","8330b325":"### Convert to DataFrame","efd1b052":"# Package versions","c9065e97":"## CV with 1st DataFrame","c778d4fb":"## CV with 2nd DataFrame","30f24ded":"## 1st part of model - using dataset 1","c90ef44e":"## Class\/Label weights","a9b5edac":"## 2nd part of model - using dataset 2","9e5ae63d":"# TRAINING","789f9b7a":"### Vegetation\/Spectral indices","3968487b":"### Merge predictions with Sample Submission format","31793638":"### Export ","b95bc282":"## Spatial statistics - used in first dataframe","e6133df1":"### Predictions","dc18fc7e":"## Cross Validation (CV)\nCross validation is also used to determine weights to be applied to the average (weighted averga) of models ensembled later on.","ba905959":"### Weighted Average","ba63d2f2":"## Train X, and y generation (Features, and Target\/Label)","7869c0b1":"# Data was generated based on the Starter Notebook created by John Whitaker (JW)\nhttps:\/\/colab.research.google.com\/drive\/1DPizsNT7GUK776TRDmk5rZVMsB1kJY5H","580554d9":"### Predictions","ed393e27":"## Drop below features based on Permutation Importance (PI) performed above\n> NB: Features returned by the PI above may not be the same as the features I decided to eventually drop due to subjective reasons","3424ef63":"## Train, and Test set generation","5f334a61":"## Permutation Importance for Feature Selection\n> NB: Feature selection\/dropping was only carried out on 1st dataframe","0f75d122":"# Import data\n> NB: The above \"Data Generation\" code is preliminary. The data generated isn't used directly, but rather exported to .csv format, and imported below for further usage"}}