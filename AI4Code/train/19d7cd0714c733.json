{"cell_type":{"a025c08f":"code","f679effb":"code","73a67386":"code","67313929":"code","9370fadb":"code","60bfd372":"code","4b57b44a":"code","f102190e":"code","2fe37a10":"code","6e11741e":"code","824cc6c2":"code","d3ff3e33":"code","7443b77e":"code","fde37696":"code","8427d0e3":"code","9757bf6a":"markdown","970fe33a":"markdown","8ee19895":"markdown","ab1e99f5":"markdown","6892ef69":"markdown","4be113b9":"markdown","f3af7e0b":"markdown","a6e39c35":"markdown","d29e446b":"markdown","7aeb6662":"markdown"},"source":{"a025c08f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f679effb":"# Import all required libraries\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\nimport sys\n\n#!conda install -c conda-forge geopy --yes # uncomment this line to install geopy\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this to install folium\nimport folium # map rendering library\n\n#!conda install -c plotly plotly_express --yes\n\nprint('Libraries imported.')","73a67386":"import requests, zipfile, io\nimport urllib.error\n\nmycountry_url= 'https:\/\/download.geonames.org\/export\/zip\/US.zip'\nmyfile= 'US.txt'\nmyloc= 'New York'\n\n# Site containing zip codes(postal codes) of every country in the world along wiht lat\/long codes\ntry:\n    r = requests.get(mycountry_url)\nexcept urllib.error.URLError:\n    sys.exit(\"Cannot access geonames file from: \",my_country_url)\n    \nz = zipfile.ZipFile(io.BytesIO(r.content))\n\n# Reading Zip File into a dataframe\ndf_US= pd.read_table(z.open(myfile), header= None)\nz.close()\n\n# The dataframe contains all the cities in the US. Load only the NewYork city Zip codes into a new dataframe\n# Drop columns that are not required\ndf_US.drop(columns=[0, 4, 6, 7, 8, 11], axis=0, inplace=True)\ndf_US.rename(columns = {1:'Postal Code', 2: 'Locale', 3:'State', 5: 'Area', 9:'Latitude', 10:'Longitude'}, inplace = True)\n\ndf_ny_data= pd.DataFrame(columns=['Postal Code','Locale', 'State', 'Area', 'Latitude', 'Longitude'])\n\n\nfor index in range(len(df_US)):\n    if((df_US['State'].iloc[index]==  myloc) & (df_US['Postal Code'].iloc[index] <= 10499)):        \n        df_ny_data= df_ny_data.append(pd.Series([df_US['Postal Code'].iloc[index],\n                                                df_US['Locale'].iloc[index],\n                                                df_US['State'].iloc[index],\n                                                df_US['Area'].iloc[index],\n                                                df_US['Latitude'].iloc[index],\n                                                df_US['Longitude'].iloc[index]],\n                                                index=df_ny_data.columns), ignore_index= True)\n\nprint('NYC zip codes (10000- 10499) and lat\/long data downloaded from geonames!')\ndf_ny_data","67313929":"df_ny_data.shape","9370fadb":"# This is step #3 where we find the lat and long of NY City using geocode\naddress = 'New York,NY'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of New York,NY are {}, {}.'.format(latitude, longitude))","60bfd372":"from folium import plugins\n\n# create map of New York using latitude and longitude values\nmap_myCity = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# instantiate a mark cluster object for the incidents in the dataframe\nmy_regions = plugins.MarkerCluster().add_to(map_myCity)\n\n# add markers to map\nfor lat, lng, postal, locale in zip(df_ny_data['Latitude'], df_ny_data['Longitude'], df_ny_data['Postal Code'], df_ny_data['Locale']):\n    label = '{}: {}, {}'.format(\"NY Zip\", postal, locale)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(my_regions)  \n    \nmap_myCity","4b57b44a":"CLIENT_ID = 'OM1SXYU0TXVYK115IQ0RQ4RSVCA4IXPME03N54EVLCCDFLG5' # your Foursquare ID\nCLIENT_SECRET = 'I5ZW4EZLOESCLF0OPX0O3TFZMS0JW4R3AQW5BBW0S5YZZOTQ' # your Foursquare Secret\nVERSION = '20200418' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","f102190e":"# Another option is to get a hospital json file for USA only.. \n# https:\/\/services1.arcgis.com\/Hp6G80Pky0om7QvQ\/arcgis\/rest\/services\/Hospitals_1\/FeatureServer\/0\/query?where=1%3D1&outFields=ID,NAME,ADDRESS,CITY,STATE,ZIP,TYPE,STATUS,POPULATION,SOURCEDATE,OBJECTID,TELEPHONE&outSR=4326&f=json\n\n# Code below is for foursquare based seach of hospitals around a given zip code\/postal code... foursquare can work any where is \nLIMIT = 20 # limit of number of hospitals returned by Foursquare API for each neighborhood to 10\n\ncategoryID= '4bf58dd8d48988d196941735' # category for hospitals\ndf_hosp= pd.DataFrame()\n\n# Copy relevant entries from the dictionary into a dataframe\nfor lat, lng, postal in zip(df_ny_data['Latitude'], df_ny_data['Longitude'], df_ny_data['Postal Code']):\n    # create URL\n    foursquare_url = 'https:\/\/api.foursquare.com\/v2\/venues\/search?ll={},{}&categoryId={}&client_id={}&client_secret={}&limit={}&v={}'.format(\n    lat, \n    lng,\n    categoryID,\n    CLIENT_ID, \n    CLIENT_SECRET, \n    LIMIT,\n    VERSION)\n \n    t_hosp= requests.get(foursquare_url).json()\n    hospitals= t_hosp['response']['venues']\n    df= json_normalize(hospitals)\n           \n    # Remove the unncessary columns\n    # for each list of hospitals build a master dataframe\n    df.drop(['hasPerk', 'categories','id', 'location.cc', 'location.crossStreet','location.address', 'location.city', 'location.country', 'location.formattedAddress', 'location.labeledLatLngs', 'location.state', 'referralId'], axis=1, inplace=True)\n    # Create a new column that has the first part of the postal code\n    new= df['location.postalCode'].str.split(\" \",n= 1, expand=True)\n    df[\"postal Prefix\"]= new[0]\n    df[\"Source Lat\"]= lat\n    df[\"Source Long\"]= lng\n    df[\"Source Postal Code\"]= postal\n    # Append this new data frame to the last one\n    df_hosp= df_hosp.append(df, ignore_index= True)","2fe37a10":"# List the unique hospital names\nhospital_names= df_hosp['name'].value_counts()\nhospital_names","6e11741e":"# Extend the df_cn_data with the list of hospitals found for each Postal code\/Borough\ndf_ny_hospitals= pd.DataFrame(columns=['Postal Code','Locale', 'Area', 'Latitude', 'Longitude','Nearest Hospital', 'Nearest Distance'])\n\n# Initialize temp storage\nshortest_distance=[1000000]*len(df_ny_data)\nnearest_hosp= [' ']*len(df_ny_data)\n\nfor index in range(len(df_ny_data)):\n    shortest_distance[index]= 1000000\n    nearest_hosp[index]= \" \"\n    for index2 in range(len(df_hosp)):\n        if (df_ny_data['Postal Code'].iloc[index]==  df_hosp['Source Postal Code'].iloc[index2]):\n            if(df_hosp['location.distance'].iloc[index2] < shortest_distance[index]):\n                shortest_distance[index]= df_hosp['location.distance'].iloc[index2]\n                nearest_hosp[index]= df_hosp['name'].iloc[index2]\n     # Write the details of the \n    df_ny_hospitals= df_ny_hospitals.append(pd.Series([df_ny_data['Postal Code'].iloc[index],\n                                                         df_ny_data['Locale'].iloc[index],\n                                                         df_ny_data['Area'].iloc[index],\n                                                         df_ny_data['Latitude'].iloc[index],\n                                                         df_ny_data['Longitude'].iloc[index],\n                                                         nearest_hosp[index],\n                                                         shortest_distance[index]],\n                                                         index=df_ny_hospitals.columns),\n                                                    ignore_index=True)\n# Print the dataframe containing the master mappings\ndf_ny_hospitals","824cc6c2":"# Generate data for COVID-19 cases per neighborhood, read from excel\n# Data is based on https:\/\/raw.githubusercontent.com\/datasets\/covid-19\/master\/data\/key-countries-pivoted.csv using US growth rates\n# The US growth rates for the prior two weeks will be randomly distributed across the borough areas\n# Generate data for hospital load factors, read from excel\n# Based on the number of COVID-19 cases and hospital load factors, \n# the preferred hospital will be modified to the next closest hospital\n# Use gitbuhub API to get data from a given user\n\nimport urllib.error\n\nmygitname= 'muraliinsd'\nmygittoken= 'e06c0c22f9a028992aebcd0fb94066551f1db23d'\ngithub_api = \"https:\/\/api.github.com\"\ngh_session = requests.Session()\ngh_session.auth = (mygitname, mygittoken)\n\nurl = github_api + '\/repos\/nychealth\/coronavirus-data\/commits'\ncommits = gh_session.get(url = url)\ncommits_json= commits.json()\n\ndf_json= json_normalize(commits_json, 'parents',['commit'])\n\ndf_nycovid19= pd.DataFrame()\nfor num in range(len(df_json)):\n    df_nyc_sha= df_json['sha'].iloc[num]\n    nychealth_url = 'https:\/\/raw.githubusercontent.com\/nychealth\/coronavirus-data\/{}\/tests-by-zcta.csv'.format(df_nyc_sha)\n    df_nyc_date= df_json['commit'].iloc[num]\n    newday= df_nyc_date['committer']['date'].split('T',1)\n    try:\n        df_c19_thisday= pd.read_csv(nychealth_url, names=['Postal code','Covid-19 positive', 'Total cases', 'Cum. Perc'], skiprows=[0,1])\n    except urllib.error.URLError:\n        continue\n        \n    df_c19_thisday= df_c19_thisday.astype({\"Postal code\": 'int64'})\n    for num2 in range(len(df_c19_thisday)):\n        if(df_c19_thisday['Postal code'].iloc[num2] <= 10499):   \n            df_nycovid19= df_nycovid19.append(pd.Series([df_c19_thisday['Postal code'].iloc[num2],\n                                                     df_c19_thisday['Covid-19 positive'].iloc[num2],\n                                                     df_c19_thisday['Total cases'].iloc[num2],\n                                                     df_c19_thisday['Cum. Perc'].iloc[num2],\n                                                     newday[0]],index=['Postal code','Covid-19 positive','Total cases','Cum. Perc','Date']), ignore_index=True)\n            \ndf_nycovid19= df_nycovid19[['Date', 'Postal code', 'Covid-19 positive','Total cases','Cum. Perc']]\ndf_nycovid19= df_nycovid19.astype({\"Postal code\": 'int64'})\ndf_nycovid19","d3ff3e33":"# Let's use facebook Prophet for forecsting simple COVID-projections and load factors\nfrom fbprophet import Prophet\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\n# Prophet can only predict one simply notated date and value pair series. We will separate the df by zipcode\n# Get unique zip codes from the list\nzipslist= list(df_nycovid19['Postal code'].unique())\ndf_covid19_forecast= pd.DataFrame()\n\nfor zipcode in zip(zipslist):\n    df_CC= pd.DataFrame()                                  # Clear the data frame each time\n    for count in range(len(df_nycovid19)):\n        if(zipcode== df_nycovid19['Postal code'].iloc[count]):\n            df_CC= df_CC.append(pd.Series([df_nycovid19['Date'].iloc[count],\n                                                     df_nycovid19['Covid-19 positive'].iloc[count]]\n                                                     ,index=['ds','y']), ignore_index=True)\n    # Fit the Covid cases for each zip code and predict the future 10 days \n    m_CC = Prophet()\n    m_CC.fit(df_CC)\n\n    # Let's predict 10 days into the future\n    future = m_CC.make_future_dataframe(periods=10)\n    forecast = m_CC.predict(future)\n    df_forecastzip= forecast[['ds','yhat']].tail(10)\n    df_forecastzip.reset_index(inplace= True)\n    df_zipcodes= pd.DataFrame()\n    for count2 in range(len(df_forecastzip)):                      # Create a temp df with the same zipcodes\n        df_zipcodes= df_zipcodes.append(pd.Series([zipcode], index=['zip']),ignore_index=True)\n    df_forecastzip= df_forecastzip.assign(zipcode= df_zipcodes.get('zip'))  # Add a new zipcode colunm to the prediction\n    df_covid19_forecast= df_covid19_forecast.append(df_forecastzip, ignore_index=True)","7443b77e":"df_covid19_forecast","fde37696":"# The forecasts ( df_covid19_forecast) made by Prophet contains a 10 day lookahead. To show them on a map, a chorpleth would be idea but we need to \n# show the average increase counts rather than each day\n# Also, the zip code is an series object.. need to convert it into an integer to be able to map to the json file\n\ndf_choro= pd.DataFrame()\ncurrent_zip= 0\nfor count in range(len(df_covid19_forecast)):\n    int_zip= df_covid19_forecast[\"zipcode\"].iloc[count]\n    zip_value= int_zip[0]\n    if(current_zip != zip_value):\n        average_covid= 0\n        for count2 in range(10):\n            average_covid= average_covid+df_covid19_forecast[\"yhat\"].iloc[count]\n        # find the average over 10 counts\n        average_covid= average_covid\/count2\n        current_zip= zip_value\n        df_choro= df_choro.append(pd.Series([int(zip_value),average_covid],\n                                            index=['postalCode', 'covid-19 Ten day increase forecast']),\n                                            ignore_index=True)\ndf_choro= df_choro.astype({\"postalCode\":'int64', \"covid-19 Ten day increase forecast\":'int64'})","8427d0e3":"# Creating a chloropleth map to show the prediciton of covid-19 cases for the next 10 days\n# Let's see them on a map along with zip codes shoiwng the closest hospital (as reported by foursquare)\n# NOTE: Foursquare seems to be missing some close-in hospitals\nimport urllib\nfrom urllib.request import urlopen\nimport json\nimport plotly\nfrom folium.map import Marker, Popup\nfrom folium import plugins\n\n# We need a GeoJSON files that contains the boundaries of the countries. The json file by zip code can be downloaded from the github page\n# https:\/\/github.com\/OpenDataDE\/State-zip-code-GeoJSON\n# Clicking on ny_new_york_zip_codes_geo.min.json and clicking download leads to:\n# https:\/\/raw.githubusercontent.com\/OpenDataDE\/State-zip-code-GeoJSON\/master\/ny_new_york_zip_codes_geo.min.json\n# Better option: https:\/\/raw.githubusercontent.com\/fedhere\/PUI2015_EC\/master\/mam1612_EC\/nyc-zip-code-tabulation-areas-polygons.geojson\n\n# download geojson file and store it into a dictionary\nnyc_zipcodes=json.load(urlopen('https:\/\/raw.githubusercontent.com\/fedhere\/PUI2015_EC\/master\/mam1612_EC\/nyc-zip-code-tabulation-areas-polygons.geojson'))\n\nkeep_entry= [0]*len(nyc_zipcodes['features'])\nfor il in range(len(df_choro)):\n    for zips in range(len(nyc_zipcodes['features'])):\n        if(df_choro['postalCode'].iloc[il]== int(nyc_zipcodes['features'][zips]['properties']['postalCode'])):\n            keep_entry[zips]= 1\n            nyc_zipcodes['features'][zips]['properties']['postalCode']= int(nyc_zipcodes['features'][zips]['properties']['postalCode'])\n\n# Let's see them on a map\n# create map of NYC showing neighborhoods as blue circles and hospitals as blue markers.  \n# Clicking on each neighborhood will show the name and the distance to the closest hospital\n# When armed with COVID-19 incidences and hospital load factors, other hospital choices will be chosen\nmap_hospitals = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# instantiate a mark cluster object for the incidents in the dataframe\nmy_regions = plugins.MarkerCluster().add_to(map_hospitals)\n\nzipcode= 0;\nfor index in range(len(df_ny_hospitals)):\n    postal= df_ny_hospitals['Postal Code'].iloc[index]\n    if(zipcode != postal):\n        lat= df_ny_hospitals['Latitude'].iloc[index]\n        lng= df_ny_hospitals['Longitude'].iloc[index]\n        area=df_ny_hospitals['Locale'].iloc[index]\n        nearest_hosp= df_ny_hospitals['Nearest Hospital'].iloc[index]\n        nearest_distance=df_ny_hospitals['Nearest Distance'].iloc[index]\n        label = '{} {} {}, {} {} {} {} {}'.format(\"For Zip code: \", postal, area, \"Hospital-->\", nearest_hosp, \"is\", nearest_distance, \"m away\")\n        label = folium.Popup(label, parse_html=True)\n        folium.CircleMarker(\n            [lat, lng],\n            radius=5,\n            popup=label,\n            color='blue',\n            fill=True,\n            fill_color='#3186cc',\n            fill_opacity=0.7, parse_html=False\n            ).add_to(my_regions)\n        zipcode= postal\n\nmap_hospitals.choropleth(\n    geo_data= nyc_zipcodes,\n    data= df_choro,\n    columns=['postalCode', 'covid-19 Ten day increase forecast'],\n    key_on= 'properties.postalCode',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='covid-19 10-day forecast by NYC Zipcode')\n\n# Let's now show the hosptials as markers from the df_hosp dataframe. Note that there are repeated names in df_hosp that needs\n# to be tidied\nnew_df= df_hosp[['name', 'location.lat','location.lng']]\nnew_df= new_df.drop_duplicates(subset=['name']).reset_index()\n\nfor index in range(len(new_df)):\n    hosp_name= new_df['name'].iloc[index]\n    hosp_lat=  new_df['location.lat'].iloc[index]\n    hosp_lng=  new_df['location.lng'].iloc[index]\n    #show hospitals as markers\n    label = '{}'.format(hosp_name)\n    label = folium.Popup(label, parse_html=True)\n    my_regions.add_child(folium.Marker(\n                         location= [hosp_lat, hosp_lng],\n                         popup=label))\n\n# Hovering over each marker will show the zip code and the nearest hospital to the zipcode and the number of covid-19 cases\nmap_hospitals","9757bf6a":"cluster the neighborhoods in New York and Bronx","970fe33a":"**Welcome to 07- Nokia Team Load Balancers**\n\n\u00a9 2020 Nokia\n\nLicensed under the BSD 3-Clause License\n\nSPDX-License-Identifier: BSD-3-Clause\n\nOur covid-19 challenge aims to solve the problem of load balancing patient load beteeen available hospitals in a given area\n\nWe answer the basic question: \"If you are headed to the ER, would you rather go to an overflowing ER closest to you or travel a longer distance where the necessary medical staff and logistics are waiting for you\"\n\n**Vision**: \"We are optimized for pandemics\"\n\n**NOTE:** This prototype is configured for NYC but can be extended to any city through the use of appropriate credentials required for access to data sources","8ee19895":"Now that we have a list of hospitals closest and alternates for each neighborhood, we need:\n1) COVID-19 cases in each neighborhood\n2) Hospital load factors\nAs of today, all reporting agencies for COVID are limiting information to city wide numbers and not by zip code or neighborhoods\nFor the current exercise, we will assume some self-generated inputs or use available gross level data sources (ex. covid-19 cases by city or country)\nIn the future, we can link to pertinent web sites that can arm us with the appropriate data\nWith this 10 day prediction horizon, we can distribute the predicted loading across the granularity of our regions (neighborhoods)\nA similar capability to monitor current hospital load factors will allow us to direct COVID-19 patients to the other hospitals\nAbsent hospital load factors, the solution will only predict demand in terms of resources in specific regions without the capability to direct new cases to unloaded hospitals\nData for NY showing daily COVID-19 cases by zip code is now available at:\nhttps:\/\/github.com\/nychealth\/coronavirus-data\/blob\/master\/tests-by-zcta.csv\u00b6","ab1e99f5":"We now have the 20 nearest hospitals to every postal code. We also have the distance (in metres) to these hospitals\nWith added details such as Covid-19 outbreak rates in each borough and the loading\/logistics\/avaialble beds\/staff information in each hospital, we can direct the next patient to the right hospit","6892ef69":"Now that we have the next 10 day prediction for each zip code, let's plot them on a choropleth and find the best hospitals to send these patients to","4be113b9":"We now have a dictionary object with hospital names and location for each postal code etc\n\nwe can now create a dataframe that contains the relevant data and map them into each neighborhood based on the Postal Codes\u00b6\n","f3af7e0b":"## Use geonames.org-  a website that contains zip code or neighborhoods for any city in the world\n## Read: https:\/\/download.geonames.org\/export\/zip\/readme.txt for file names and how the data is stored","a6e39c35":"Now we draw a folium map centered around New York, NY\u00b6","d29e446b":"Find the category ID for hospitals and create a http query to FourSquare to get 20 hospitals centred around each neighborhood\nThe four square database returns only postal codes for each hospital so we will find all hospitals around each postal code\nGet rid of data that we will not need. Since we are iterating for each neighborhood and finding the 10 closest hospitals,\nthe distance and postal codes along with the hospital names are the data of interest to map to the nieghborhood data that we already have mapped\u00b6","7aeb6662":"We have the maps of neighborhoods, need to find the hospitals now\n**find the closest hospital that we can send COVID-19 patients to from each neighborhood**\n\nFor this project I will use foursquare to query all the hospitals in each neighborhood in the NYC area. The following steps will be followed:\n\nRead the hospital list from foursquare for each neighborhood\nFind the Postal code of each hospital and add the hospital to the neighborhood(s) that are in that postal code\nCount the number of hospitals in each neighborhood\nCreate an assumed capacity for each hospital\nCalculate the total capacity for the neighborhood\nCreate a random demand that indicates the number of COVID-19 patients that falls in the capacity range for a given neigborhood\nIf the random demand exceeds the available neighborhood capacity, find the closest neighborhood that has excess capacity: we call this \"Load Balancing\"\nShow on a map, the number of hospitals in each Toronto neighborhood\nUsing k-means clustering or other methods, to validate the load balancing methodology\n\nProblem Statement\nHospital overcrowding and lack of beds and personal protective equipment become commonplace in the event of pandemics as well as natural disasters and large scale emergencies. When this happens, an uneven utilization of available assets across area hospitals leads to the need for temporary facilities so that the delivery of assets and logistics can be better managed\u00b6\n\n![image.png](attachment:image.png)"}}