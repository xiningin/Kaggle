{"cell_type":{"af43296b":"code","8f1afd4c":"code","c5f75f6f":"code","f9052e92":"code","8c5c1bfb":"code","403b78ed":"code","e581f3e5":"code","9def0f08":"code","f223857f":"code","3f9baee0":"code","5292ee54":"code","1429a0e4":"code","a8014520":"code","9ad04469":"code","238620bc":"code","9cd82f16":"code","23ba0e60":"code","c8141069":"markdown","b10b60eb":"markdown","6bfec08e":"markdown","3f9b65a8":"markdown","74fad03e":"markdown","06956e34":"markdown","94573f60":"markdown","e3fbb941":"markdown","b1c3a98a":"markdown","61d899d8":"markdown","433964fc":"markdown","692f43f9":"markdown"},"source":{"af43296b":"import numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error","8f1afd4c":"df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')","c5f75f6f":"print('DataFrame shape:', df.shape)\ndf.head()","f9052e92":"df.describe()","8c5c1bfb":"sns.set(rc={'figure.figsize':(15,15), \"lines.linewidth\": 2.5})\nsns.set_style(\"white\")\nf, axes = plt.subplots(3, 3)\nsns.boxplot(data=df, x='Eyes', y='Pawpularity', ax=axes[0, 0])\nsns.boxplot(data=df, x='Face', y='Pawpularity', ax=axes[0, 1])\nsns.boxplot(data=df, x='Near', y='Pawpularity', ax=axes[0, 2])\nsns.boxplot(data=df, x='Action', y='Pawpularity', ax=axes[1, 0])\nsns.boxplot(data=df, x='Face', y='Pawpularity', ax=axes[1, 1])\nsns.boxplot(data=df, x='Accessory', y='Pawpularity', ax=axes[1, 2])\nsns.boxplot(data=df, x='Collage', y='Pawpularity', ax=axes[2, 0])\nsns.boxplot(data=df, x='Human', y='Pawpularity', ax=axes[2, 1])\nsns.boxplot(data=df, x='Occlusion', y='Pawpularity', ax=axes[2, 2])\nplt.subplots_adjust(wspace = 0.3, hspace = 0.3)\nf.show()","403b78ed":"sns.set(rc={'figure.figsize':(10,5), \"lines.linewidth\": 2.5})\nsns.distplot(df[\"Pawpularity\"], label=\"Pawpularity\")","e581f3e5":"df = df.loc[(df[\"Pawpularity\"]<100) & (df[\"Pawpularity\"]>3)]\nX = df.iloc[:,1:-1]\ny = df.iloc[:,-1]","9def0f08":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","f223857f":"model = XGBRegressor(learning_rate =0.1,\n n_estimators=1000,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n nthread=4,\n scale_pos_weight=1,\n seed=42)\nmodel.fit(X_train, y_train)","3f9baee0":"kfold = KFold(n_splits=10, random_state=42)\nresults = cross_val_score(model, X_train, y_train, cv=kfold)","5292ee54":"y_test_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_test_pred, squared=False)\nmse","1429a0e4":"model_dtrgr = DecisionTreeRegressor()\nmodel_dtrgr.fit(X_train, y_train)","a8014520":"kfold_dtrgr = KFold(n_splits=10, random_state=42)\nresults_dtrgr = cross_val_score(model, X_train, y_train, cv=kfold)","9ad04469":"y_test_pred_dtrgr = model_dtrgr.predict(X_test)\nmse_dtrgr = mean_squared_error(y_test, y_test_pred_dtrgr, squared=False)\nmse_dtrgr","238620bc":"df_test = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","9cd82f16":"output = pd.DataFrame(np.asarray([list(df_test['Id']), list(model.predict(df_test.iloc[:,1:]))]).T, columns=['Id', 'Pawpularity'])\noutput.to_csv('submission.csv', encoding='utf-8', index=False)","23ba0e60":"output","c8141069":"# Descrpition\n\nPetFinder.my is Malaysia\u2019s leading animal welfare platform, featuring over 180,000 animals with 54,000 happily adopted. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n\nCurrently, PetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. While this basic tool is helpful, it's still in an experimental stage and the algorithm could be improved.\n\n### Features\n\n* Focus - Pet stands out against uncluttered background, not too close \/ far.\n* Eyes - Both eyes are facing front or near-front, with at least 1 eye \/ pupil decently clear.\n* Face - Decently clear face, facing front or near-front.\n* Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n* Action - Pet in the middle of an action (e.g., jumping).\n* Accessory - Accompanying physical or digital accessory \/ prop (i.e. toy, digital sticker), excluding collar and leash.\n* Group - More than 1 pet in the photo.\n* Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n* Human - Human in the photo.\n* Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all * blocking objects are considered occlusion.\n* Info - Custom-added text or labels (i.e. pet name, description).\n* Blur - Noticeably out of focus or noisy, especially for the pet\u2019s eyes and face. For Blur entries, \u201cEyes\u201d column is always set to 0.\n\n### Goal\n\nOur goal is to predict the value of Pawpularity using the provided metadata, first finding out if this is possible by EDA.","b10b60eb":"Let's create output file:","6bfec08e":"As we can see, our dataset looks pretty normal and it doesn't contain some awkward values.","3f9b65a8":"After plotting the box-and-whiskers diagram for each feature, we can conclude that it will be difficult to make a valid forecast, because in every case distribution of animals with some specific feature almost don't have any influence on Pawpularity value.","74fad03e":"We'll use XGBoost Regressor with parameters preparely found by GridSearchCV.","06956e34":"# Step 3. Model","94573f60":"Let's make train test split in the ratio 80\/20.","e3fbb941":"As we can see, RMSE was not improved significantly by using more complex method. It means that we must use dataset with other features or apply computer vision for the images considered in that problem.","b1c3a98a":"# Step 2. EDA","61d899d8":"As you can see, there are jumps at the borders of the histogram. I am inclined to believe that such data should be discarded (or normalized) due to the fact that very often such data may not reflect an objective picture of the situation.","433964fc":"# Step 1. Importing libraries","692f43f9":"For comparison we'll use more simple algorithm (DecisionTreeRegressor)."}}