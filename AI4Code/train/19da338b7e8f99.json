{"cell_type":{"36c0be04":"code","c94b96ae":"code","52bbf4c0":"code","9c0a2917":"code","fcfd7b26":"code","ffb42e44":"code","fe5fe2a5":"code","6d490090":"code","790c7639":"code","94950d22":"code","9b5f0bfb":"code","87d2d3f7":"code","c941bba4":"code","f518f028":"code","e0d966e2":"code","0984a6a9":"code","a6c8722e":"code","0ac300c1":"code","c819e079":"code","8bff8453":"code","cfa6799d":"code","5ac33e5b":"code","a6d15ece":"code","75dcce71":"code","7a3ee4e9":"code","c95e68ed":"code","b16e8cb6":"code","cad9b5a7":"code","24cabe0c":"code","1aa4ce52":"code","a38106f4":"code","48124bd2":"code","c8fe0458":"code","648dafee":"markdown","2e4a545d":"markdown","00a662b2":"markdown","46def82a":"markdown","b6e757ae":"markdown","191e5ee6":"markdown","86c95c0f":"markdown","ea003e53":"markdown","1a987e0d":"markdown"},"source":{"36c0be04":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","c94b96ae":"#Dataset files\nfile1 = '..\/input\/winemag-data-130k-v2.csv'\nfile2 = '..\/input\/winemag-data_first150k.csv' \n\n\n#Read files\nf1 = pd.read_csv(file1)\nf2 = pd.read_csv(file2)\n\n#To convet dataset into a single dataframe\ndf1 = pd.DataFrame(f1)\ndf2 = pd.DataFrame(f2)\nframes = [df1, df2]\ndfd= pd.concat(frames)\n\n#To re-index de dataframe\n##Create a list of number like a new column\ndfd['index'] = range(0, len(dfd))\n##Set a copy of this column like the index\ndfd.set_index(dfd['index'], inplace=True)\n##Drop the column that we have previously created\ndfd=dfd.drop(columns=['index'])\n\n\n#To transform variables as 'category type'\n\ndfd['variety']=dfd['variety'].astype('category')\ndfd['country']=dfd['country'].astype('category')\ndfd['winery']=dfd['winery'].astype('category')\n","52bbf4c0":"\nLDF = [df1, df2, dfd]\n    \nfor i in LDF:\n    print( i.shape)\n    \nfor i in LDF:\n    print( i.columns)\nprint ('\\n \\n')\n\nprint('DFD info \\n')\n\n\nprint(dfd.info())","9c0a2917":"pd.options.display.max_colwidth = 500\n\n\ndfd.loc[[132],['description','designation','variety']]","fcfd7b26":"# Dataset slice filtering by one variety ('Cabernet Sauvignon'), and swhowing two variables (variety and description)\n#dfd.loc[dfd['variety']=='Cabernet Sauvignon',['variety','points','description']]","ffb42e44":"dfdv=dfd.loc[:,['description','country']]\n\n#LC = List of countries\nLC = dfdv.groupby('country').count()\n\nDLC = pd.DataFrame(LC)\nDLC['Country']=DLC.index\nDLC['index1'] = range(0, len(DLC))\nDLC.set_index(DLC['index1'], inplace=True)\nDLC=DLC.drop(columns=['index1'])\n\nDLC.rename(columns={'description': 'QR'}, inplace=True)","fe5fe2a5":"print(DLC.head())","6d490090":"price=dfd['price'], \npoints=dfd['points']\ndfd[dfd['price'] < 4000].plot.scatter(x='price', y='points')","790c7639":"\nfig, axarr = plt.subplots(2, 2, figsize=(14, 10))\n#Gr\u00e1ph 1\ndfd['price'].value_counts().sort_index().plot.hist(\n    ax=axarr[0][0]\n)\n## T\u00edtle\naxarr[0][0].set_title(\"Wine Price\", fontsize=18)\n\n#Graph 2\ndfd['points'].value_counts().sort_index().plot.bar(\n    ax=axarr[0][1]\n)\n## Title\naxarr[0][1].set_title(\"Score Distribution\", fontsize=18)\n\n#Graph 3\ndfd['country'].value_counts().head(20).plot.bar(\n   ax=axarr[1][0]\n)\n## Title\naxarr[1][0].set_title(\"Countries\", fontsize=18)\n\n\ndfd['variety'].value_counts().head(30).plot.bar(\n    ax=axarr[1][1]\n)\n## Title\naxarr[1][1].set_title(\"Vairety Distribution\", fontsize=18)","94950d22":"#Libraries needed\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.snowball import SnowballStemmer\n","9b5f0bfb":"import spacy\nnlp = spacy.load('en_core_web_sm')","87d2d3f7":"#To identify the duplicated description\nDD= dfd[dfd['description'].duplicated(keep = False)].sort_values('description')\n\nprint( dfd.shape)\nprint(DD.shape)\n\n# To drop out the duplicated description to avoid be part of the tokenizen process\n\ndfd = dfd.drop_duplicates('description')","c941bba4":"#To filter by those varieties which have at least 1500 description\nvariety_df = dfd.groupby('variety').filter(lambda x: len(x) > 1500)\nvarieties=variety_df['variety'].unique()\nprint('Number of relevant varieties:', varieties.shape)\n#To create a bargrpah with the number of description by variety\nfig, ax = plt.subplots(figsize = (25, 10))\nsns.countplot(x = variety_df['variety'], order = varieties, ax = ax)\nplt.xticks(rotation = 90)\nplt.show()","f518f028":"#To convert df['description'] into documents that can be used by Spacy\ndoc = variety_df['description'].values\n\ndoc2=variety_df['description']","e0d966e2":"print(doc.shape)","0984a6a9":"# Import countvectorizr\nfrom sklearn.feature_extraction.text import  CountVectorizer\n\n#To create a instance of CV in which de words that show up in the 80% of documents are removed and it's needed that the word\n#at leasts appear in two documents\ncv = CountVectorizer(max_df=0.8, min_df=2, stop_words='english' )","a6c8722e":"#To apply CV over doc --> Document Text Matrix\n\ndtm = cv.fit_transform(doc)\n\ndtm ","0ac300c1":"from sklearn.decomposition import LatentDirichletAllocation\n","c819e079":"LDA = LatentDirichletAllocation(n_components = 10, random_state=42)","8bff8453":"LDA.fit(dtm)","cfa6799d":"# To check the lenth of the vocabulary set","5ac33e5b":"len(cv.get_feature_names())","a6d15ece":"cv.get_feature_names()[890]","75dcce71":"#To Check topics","7a3ee4e9":"#To define first topic\nfirst_topic = LDA.components_[0]\n#To order the word by index position from leat to great (according relevance)\nfirst_topic.argsort()","c95e68ed":"# To watch al the topics:\n\nfor i, topic in enumerate (LDA.components_):\n    print(f\"The top 15 words for topic #{i}\")\n    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n    print('\\n')\n    print('\\n')","b16e8cb6":"#To define the beloging to a particular topic\nTopic_results = LDA.transform(dtm)","cad9b5a7":"print(Topic_results[14].round(2))\nprint(Topic_results[14].argmax())","24cabe0c":"VDF= pd.DataFrame(variety_df)","1aa4ce52":"VDF['Topic']=Topic_results.argmax(axis=1)","a38106f4":"PN = VDF[VDF['variety']=='Pinot Noir']","48124bd2":"len(PN['Topic'].unique())","c8fe0458":"clusters = VDF.groupby(['Topic', 'variety']).size()\nfig2, ax2 = plt.subplots(figsize = (30, 15))\nsns.heatmap(clusters.unstack(level = 'variety'), ax = ax2, cmap = 'Reds')","648dafee":"## Import Libraries","2e4a545d":"# Prepare Raw Data","00a662b2":"##  Shape","46def82a":"## Read data","b6e757ae":"# Object: \n\nStarting from the notebook (https:\/\/www.kaggle.com\/kitakoj18\/exploring-wine-descriptions-with-nlp-and-kmeans) we are going to:\n- Tokennize description\n- Lemmanize tokens to reduce de list of worbs\n- Transform the descriptions\n- Clusterized data according with tokens to compare with varieties, points, and varieties + points\n","191e5ee6":"# Description Analisis","86c95c0f":"# Object\n\nThe object of this notebook is analysis the data set WineReview from Kaggle (https:\/\/www.kaggle.com\/zynicide\/wine-reviews\/downloads\/wine-reviews.zip\/4)\n\nThe Dataset has been created from scratch the reviews from https:\/\/www.winemag.com\/?s=&drink_type=wine\n","ea003e53":"Attach article with topics","1a987e0d":"# # Tokenize"}}