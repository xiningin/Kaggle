{"cell_type":{"23f375f0":"code","1201dca0":"code","7fa99ce2":"code","224270a7":"code","99fcfd24":"code","4f26cc0b":"code","b0a1dec5":"code","615a8d3b":"code","2160d886":"code","397e65cb":"code","704401d0":"code","0c97f440":"code","616d3530":"code","05da9ad6":"code","8f3dcd2e":"code","f5934b68":"code","7be7d77d":"code","d4b75935":"code","5060a386":"code","885cac38":"code","12a7d2b8":"code","de77b9d7":"code","8846fd5a":"code","05d0da46":"code","aef46eb9":"code","0d5df82e":"code","55a22683":"code","5cb8b368":"code","c0503395":"code","1a71c770":"markdown","28e5ee77":"markdown","fa27ab41":"markdown","56a76acc":"markdown","010371c6":"markdown","8f449372":"markdown","7b5b72f8":"markdown","2676d78c":"markdown","4692f771":"markdown","d52a9cbd":"markdown"},"source":{"23f375f0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nsns.set()\n","1201dca0":"gender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\", index_col=\"PassengerId\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\", index_col=\"PassengerId\")\ndfs = [train, test]","7fa99ce2":"train.head(3)","224270a7":"test.tail(3)","99fcfd24":"total_passangers = train.shape[0] + test.shape[0]\nprint(f' Total Passangers = {total_passangers} \\n')\nprint(f' Train Dataset \\n Rows:{train.shape[0]}  Features: {train.shape[1]} ({train.shape[0]\/total_passangers * 100}) \\n')\nprint(f' Test Dataset \\n Rows:{test.shape[0]}  Features: {test.shape[1]} ({test.shape[0]\/total_passangers * 100}) ')","4f26cc0b":"print(f'Train: {dfs[0].isnull().sum()} \\n')\nprint(f'Test: {dfs[1].isnull().sum()}')","b0a1dec5":"fig = plt.figure(figsize=(25,5))\nax1 = fig.add_subplot(151)\nax2 = fig.add_subplot(152)\nax3 = fig.add_subplot(153)\nax4 = fig.add_subplot(154)\nax5 = fig.add_subplot(155)\n\n\nage_cut = pd.cut(train['Age'], 5)\n\nsns.countplot(x=train['Survived'], ax=ax1)\nsns.countplot(x=train['Survived'], hue=train['Sex'], ax=ax2)\nsns.countplot(x=train['Survived'], hue=train['Pclass'], ax=ax3)\nsns.countplot(x=train['Survived'], hue=train['Parch'], ax=ax4)\nsns.countplot(x=train['Survived'], hue=age_cut, ax=ax5)","615a8d3b":"# Checkpoint\ndf = train.copy()\ndf_test = test.copy()\ndfs = [df, df_test]","2160d886":"# Update embarked\n\ndef update_embarked(data):\n  highest = data['Embarked'].value_counts().index[0]\n  data['Embarked'] = data['Embarked'].fillna(highest)\n  return data\n\ndf = update_embarked(df)\ndf_test = update_embarked(df_test)","397e65cb":"# Check if passanger had a Cabin\n\ndef get_cabin(data):\n  data['HadCabin'] = data['Cabin'].notna()\n  data['HadCabin'] = data['HadCabin'].astype(int)  \n  return data\n\ndf = get_cabin(df)\ndf_test = get_cabin(df_test)\n\nsns.countplot(x=df['Survived'], hue=df['HadCabin'])","704401d0":"# FARE\n\ndef classify_fare(fare):\n  if fare <= 7.91:\n    return 0\n  elif fare > 7.91 and fare <= 14.454:\n    return 1\n  elif fare > 14.454 and fare <= 31:\n    return 2\n  elif fare > 31:\n    return 3\n  else:\n    return 4\n\ndef update_fare(df):  \n  df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n  df['FareCat'] = df['Fare'].apply(classify_fare)\n  df['Fare'] = df['Fare'].astype(int)\n  return df\n\ndf = update_fare(df)\ndf_test = update_fare(df_test)","0c97f440":"# AGE\ndef classify_age(age):    \n    if age > 0 and age < 17:\n      return 0        \n    elif age >= 17 and age < 32:\n      return 1\n    elif age >= 32 and age < 42:\n      return 2        \n    elif age >= 42 and age < 64:\n      return 3        \n    elif age >= 64:\n      return 4\n    else:\n      return 2        \n\ndef update_age(df):\n  df['Age'] = df['Age'].fillna(df['Age'].median())\n  df['AgeCat'] = df['Age'].apply(classify_age)\n  return df\n\ndf = update_age(df)\ndf_test = update_age(df_test)\n\nfig = plt.figure(figsize=(15,5))\nax1 = fig.add_subplot(131)\nax2 = fig.add_subplot(132)\nax3 = fig.add_subplot(133)\n\nsns.countplot(x=df['Survived'], hue=df['AgeCat'], ax=ax1)\nsns.countplot(x=df['AgeCat'], ax=ax2)\nsns.countplot(x=df['AgeCat'], hue=df['Sex'], ax=ax3)","616d3530":"# Check if is a Male Adult\n\ndef get_male_adult(df):\n  df['IsMaleAdult'] = 0  \n  df['IsMaleAdult'] = np.where( (df['Sex'] == 'male') & (df['Age'] >= 17), 1, 0)\n  return df\n\ndf = get_male_adult(df)\ndf_test = get_male_adult(df_test)\nsns.countplot(x=df['Survived'], hue=df['IsMaleAdult'])","05da9ad6":"def update_family(df):\n  df['Family'] = df['SibSp'] + df['Parch'] + 1\n  df['IsAlone'] = 0\n  df['IsAlone'] = df['Family'] < 2\n  df['IsAlone'] = df['IsAlone'].astype(int)\n  return df\n\ndf = update_family(df)\ndf_test = update_family(df_test)\nsns.countplot(x=df['Survived'], hue=df['IsAlone'])","8f3dcd2e":"# CheckPoint\nprocessed_df = df.copy()\nprocessed_df_test = df_test.copy()\nprocessed_df","f5934b68":"def get_categoricals(df, columns):\n  return pd.get_dummies(df, columns=columns, drop_first=True)\n\ncolumns = processed_df.columns\nprint(columns)\n\ncolumns = ['Pclass', 'Embarked', 'AgeCat', 'FareCat']\n\nprocessed_df = get_categoricals(processed_df, columns)\nprocessed_df_test = get_categoricals(processed_df_test,columns)","7be7d77d":"def drop_columns(df, columns):\n  for col in columns:\n    df = df.drop(col, axis=1)\n  return df\n\ncolumns =  ['Sex', 'Parch','Fare','Age', 'Ticket', 'Cabin', 'Name', 'SibSp']\n\nprocessed_df = drop_columns(processed_df, columns) \nprocessed_df_test = drop_columns(processed_df_test, columns) \n\n# Final Table\n\nprocessed_df","d4b75935":"# Final correlation\nplt.figure(figsize=(30,20))\nsns.heatmap(processed_df.corr(), vmax=0.6, square=True, annot=True, cmap=\"coolwarm\")\nprocessed_df","5060a386":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","885cac38":"X = processed_df.iloc[:, 1:].values\ny = processed_df.iloc[:, 0].values\nX_test_pred = processed_df_test.iloc[:].values\nprocessed_df","12a7d2b8":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.85)","de77b9d7":"scaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\nX_test_pred = scaler.transform(X_test_pred)","8846fd5a":"# X_train = X_train.reshape(-1, X_train.shape[0],  X_train.shape[1])\n# X_test = X_test.reshape(-1, X_test.shape[0],  X_test.shape[1])\nX_test.shape","05d0da46":"# !pip install tensorflow==2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report, confusion_matrix","aef46eb9":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(X_test_pred.shape)","0d5df82e":"model = Sequential()\n\nmodel.add(Dense(X_train.shape[1] + 2 , activation='sigmoid'))\n# model.add(Dense(X_train.shape[1] \/\/ 2 , activation='sigmoid'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# model.summary()","55a22683":"es = EarlyStopping(patience=2)\nepochs = 300\nbatch_size = X_train.shape[0] \/\/ 12\n\nmodel.fit(X_train, \n          y_train, \n          batch_size = batch_size,\n          validation_split=0.2, \n          epochs=epochs, callbacks=[es], \n          verbose=0)\n\nloss = pd.DataFrame(model.history.history)\nloss.plot()\n\nplt.show()","5cb8b368":"pred = model.predict_classes(X_test)\nrep = classification_report(y_test, pred)\nmx = confusion_matrix(y_true=y_test, y_pred=pred)\nsns.heatmap(mx, annot=True, xticklabels=False, yticklabels=False)\nprint(rep)","c0503395":"pred_test = model.predict_classes(X_test_pred)\nd = pd.DataFrame(pred_test, columns=['Survived'])\nd.index = test.index\nsns.countplot(x='Survived', data=d)\nd.to_csv('Survived.csv')","1a71c770":"## Insights\n\n- Most of the survivors are Woman and Kids\n- 3rd Class are the most dead\n- Who did not have parents died at most\n- Who had a Cabin had their chances improved","28e5ee77":"## Loading the common libraries","fa27ab41":"The information provided diverges from the data collected  while the page says there were 1502, the datasets contains only 1309 people\n\nThe train dataset contains 68% of information about the survivors\nThe test dataset only contains the information of the features describing the passagenger, not the their live status ~31%\n","56a76acc":"## Data Cleaning\n\n### Insights\n\n- There were only a fell people without cab, let`s complete it\n- Separete the Adult males from kids and women\n- Get the Age and Fare median to fullfill the missing values\n- Check if the passanger was alone\n","010371c6":"### Loading the CSV Files","8f449372":"## Add categorical columns and Drop the useless","7b5b72f8":"## Survivors\nLet's take a look of the graphs about the survivors correlations","2676d78c":"As we can see, fields Cabin and Age are the major with empty os missing values","4692f771":"### First look at the Data","d52a9cbd":"# Titanic: Machine Learning from Disaster\n\n## The Challenge\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n"}}