{"cell_type":{"bb94964c":"code","f7956ca4":"code","39af6e0a":"code","d9a9edbe":"code","b1637847":"code","5bf2fe8d":"code","9a209cb9":"code","6e6ad0f3":"code","4737d7f8":"code","b706e225":"code","a3c2a03c":"code","565fc356":"code","0a70261b":"code","d201d682":"code","df5cd46a":"code","e735a778":"code","0ab232f1":"code","09d50d1c":"code","9781051a":"code","4e87fd60":"code","f243a403":"code","aa30aadd":"code","768973a6":"markdown","a3e9f7aa":"markdown","4f2dc644":"markdown","aa12f01a":"markdown","8a46f5e2":"markdown","04aafd1a":"markdown","45d44124":"markdown","cca25bf7":"markdown","5df5b252":"markdown","d9a148d9":"markdown","b266597f":"markdown","e5cbe7c5":"markdown"},"source":{"bb94964c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f7956ca4":"data=pd.read_csv(\"\/kaggle\/input\/youtubevideodataset\/Youtube Video Dataset.csv\")\ndata.head()","39af6e0a":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nsns.countplot(data=data,x=\"Category\")","d9a9edbe":"data2=data.dropna()","b1637847":"x=data2[\"Description\"]\ny=data2[\"Category\"]\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer=TfidfVectorizer(stop_words=\"english\",max_features=2000)\nx_new=vectorizer.fit_transform(x)\nx_new.shape","5bf2fe8d":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nx_2_dimension=pca.fit_transform(x_new.toarray())","9a209cb9":"dataframe=pd.DataFrame(x_2_dimension)\ndataframe.columns=[\"f1\",\"f2\"]","6e6ad0f3":"dataframe[\"Category\"]=y\ndataframe.head(6)","4737d7f8":"plt.figure(figsize=(18,18))\nax=sns.relplot(data=dataframe,x=\"f1\",y=\"f2\",hue=\"Category\")\nplt.show()","b706e225":"from sklearn.decomposition import PCA\npca = PCA(n_components=10)\nx_10_dimension=pca.fit_transform(x_new.toarray())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nfrom sklearn.feature_selection import SelectKBest, chi2\nX_new = SelectKBest(chi2, k=2).fit_transform(scaler.fit_transform(x_10_dimension), y)","a3c2a03c":"dataframe=pd.DataFrame(X_new)\ndataframe.columns=[\"f1\",\"f2\"]\ndataframe[\"Category\"]=y\nplt.figure(figsize=(18,18))\nax=sns.relplot(data=dataframe,x=\"f1\",y=\"f2\",hue=\"Category\")\nplt.show()","565fc356":"pca = PCA(n_components=400)\nx_400_dimension=pca.fit_transform(x_new.toarray())\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_400_dimension, y, test_size=0.33, random_state=421)","0a70261b":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train=scaler.fit_transform(x_train)\nX_test=scaler.transform(x_test)","d201d682":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=43)\nknn.fit(X_train,y_train)\nypred=knn.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","df5cd46a":"from sklearn.naive_bayes import GaussianNB\nnaive= GaussianNB()\nnaive.fit(X_train,y_train)\nypred=naive.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","e735a778":"from sklearn.svm import SVC\nlsvm=SVC(kernel=\"linear\")\nlsvm.fit(X_train,y_train)\nypred=lsvm.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","0ab232f1":"from sklearn.svm import SVC\nlsvm_pro=SVC(kernel=\"linear\",probability=True)\nlsvm_pro.fit(X_train,y_train)\nypred=lsvm_pro.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","09d50d1c":"from sklearn.tree import DecisionTreeClassifier\ndtree= DecisionTreeClassifier(random_state=46)\ndtree.fit(X_train,y_train)\nypred=dtree.predict(X_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","9781051a":"import shap\nexplainer=shap.TreeExplainer(dtree)\nshap_values = explainer.shap_values(X_test)","4e87fd60":"shap.summary_plot(shap_values, X_test, plot_type=\"bar\")","f243a403":"sel= SelectKBest(chi2, k=10)\nX_new_40010_train = sel.fit_transform(scaler.fit_transform(X_train), y_train)\nX_new_40010_test=sel.transform(X_test)","aa30aadd":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=43)\nknn.fit(X_new_40010_train,y_train)\nypred=knn.predict(X_new_40010_test)\nimport sklearn.metrics as metrik\nprint(metrik.accuracy_score(y_pred=ypred,y_true=y_test))\nprint(metrik.confusion_matrix(y_pred=ypred,y_true=y_test))","768973a6":"What about LinearSVM","a3e9f7aa":"with Feature Selection.","4f2dc644":"Travel Blogs and Science and Technology is clearly separated. Others not so much.","aa12f01a":"## TFIDF with PCA and SVM work just good for these data.","8a46f5e2":"Linear SVM is work best.","04aafd1a":"Not the best not the worst. Still overlap is too much.","45d44124":"What About Naive Bayes:","cca25bf7":"For Classification KNN with 400 dimension is work well. ","5df5b252":"Shap can explain some relationship between classes and features. ","d9a148d9":"Better than Expected.","b266597f":"Worse than KNN","e5cbe7c5":"Travel Videos is everywhere and Geeks is still in the INTERNET"}}