{"cell_type":{"dd797475":"code","a000cbb0":"code","13c81c95":"code","9b4c6a2d":"code","4d716bf0":"code","1e8e3ed0":"code","1db1f821":"code","64883479":"code","ade81019":"code","8d2d99e3":"code","c0536c16":"code","93bdd317":"code","b0644226":"code","978f4d76":"code","451c691a":"code","cf0e538e":"code","586de1c7":"code","1e279583":"code","094c9176":"code","c4035ae1":"code","d975784b":"code","085a5974":"code","5034e710":"code","d0b7c8fd":"code","4be0fcf8":"code","631736d1":"code","beed12f1":"code","6a9ba2dd":"code","4748a01f":"code","aadcc576":"code","f69a8eba":"code","895bb8c1":"code","7e90386f":"code","0b734037":"code","c5f14c75":"code","88fc58fa":"code","71a174eb":"code","851c2bb5":"code","4de01e97":"code","c7256c97":"code","d3b96a7e":"code","d4489f90":"code","8b703586":"code","294b0242":"code","c3027740":"code","e538d6d6":"code","ee7bcc05":"code","7c75b6bf":"code","bb3dfb53":"code","2ccfa626":"code","711f1b8b":"code","5cb3cadd":"code","27c1cc1e":"code","700af94c":"code","0b7b4eba":"code","d1f6706e":"markdown","5dbaa61f":"markdown","cb099191":"markdown","cd2515fa":"markdown","1f74bda8":"markdown","e6533b4b":"markdown","11f0ea90":"markdown","d1c5cad6":"markdown","44b09760":"markdown","3d0a5bb3":"markdown","c00d1159":"markdown","d3525a46":"markdown","a82c7721":"markdown","2dc018d7":"markdown","05704d92":"markdown","4d8286b8":"markdown","2c195e4e":"markdown","43db89ee":"markdown","e592f53a":"markdown","860e5e4a":"markdown","de2a706a":"markdown","71aaf16f":"markdown","93ae7773":"markdown","6d5eb8e8":"markdown","7d1620ba":"markdown","a0396852":"markdown","f1dfa27e":"markdown","b4a9eda9":"markdown","60870fb3":"markdown","b7238900":"markdown","63bf4d1c":"markdown"},"source":{"dd797475":"import pandas as pd","a000cbb0":"url = \"https:\/\/raw.githubusercontent.com\/eastmountaincode\/heartFailure\/main\/heart.csv\"\ndf=pd.read_csv(url)\ndisplay(df)","13c81c95":"df.shape","9b4c6a2d":"df.isnull().sum()","4d716bf0":"df.isin([0]).sum()","1e8e3ed0":"df.info()","1db1f821":"df.nunique()","64883479":"# One-hot encoding ExerciseAngina\n\nX = pd.get_dummies(df['ExerciseAngina'])\nX = X.drop(['N'], axis = 1)\nX.head()","ade81019":"X = X.rename(columns = {'Y': \"HasExerciseAngina\"})\nX","8d2d99e3":"df = pd.merge(left = df, right = X, left_index=True, right_index=True)\ndf.head()","c0536c16":"df = df.drop(['ExerciseAngina'], axis = 1)\ndf.head()","93bdd317":"# One-hot encoding sex\n\nX = pd.get_dummies(df['Sex'])\nX = X.drop(['F'], axis = 1)\nX.head()","b0644226":"X = X.rename(columns = {'M': \"isMale\"})\nX.head()","978f4d76":"df = pd.merge(left = df, right = X, left_index=True, right_index=True)\ndf.head()","451c691a":"df = df.drop(['Sex'], axis = 1)\ndf.head()","cf0e538e":"df.info()","586de1c7":"df.nunique()","1e279583":"df = pd.get_dummies(df)","094c9176":"df.head()","c4035ae1":"df.info()","d975784b":"df.nunique()","085a5974":"df[\"HeartDisease\"].replace({0: \"N\", 1: \"Y\"}, inplace=True)","5034e710":"df.describe()","d0b7c8fd":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15, 8))","4be0fcf8":"plt.hist(df['Age'], bins = [x for x in range(0, max(df['Age']), 1)]); #Semicolon used to suppress verbose output\nplt.title(\"Age distribution\")","631736d1":"plt.hist(df['RestingBP'], bins = [x for x in range(min(df['RestingBP']), max(df['RestingBP']), 2)]); #Semicolon used to suppress verbose output\nplt.title(\"Resting Blood Pressure distribution\")","beed12f1":"plt.hist(df['Cholesterol'], bins = [x for x in range(min(df['Cholesterol']), max(df['Cholesterol']), 4)]); #Semicolon used to suppress verbose output\nplt.title(\"Cholesterol distribution\")","6a9ba2dd":"plt.hist(df['MaxHR'], bins = [x for x in range(0, max(df['MaxHR']), 2)]); #Semicolon used to suppress verbose output\nplt.title(\"Max heart rate distribution\")","4748a01f":"plt.hist(df['Oldpeak'], bins = 50); #Semicolon used to suppress verbose output\nplt.title(\"Oldpeak distribution\")","aadcc576":"import numpy as np","f69a8eba":"cols = ['RestingBP', 'Cholesterol']\ndf[cols] = df[cols].replace(['0', 0], np.nan)","895bb8c1":"df.isnull().sum()","7e90386f":"!pip install -f http:\/\/h2o-release.s3.amazonaws.com\/h2o\/latest_stable_Py.html h2o","0b734037":"import h2o\nfrom h2o.automl import H2OAutoML\nimport random, os, sys\nfrom datetime import datetime\nimport logging\nimport csv\nimport optparse\nimport time\nimport json\nfrom distutils.util import strtobool\nimport psutil\nimport numpy as np","c5f14c75":"# Set a minimum memory size and a run time in seconds\nmin_mem_size=6 \nrun_time=333\n\n# Use 50% of availible resources\npct_memory=0.5\nvirtual_memory=psutil.virtual_memory()\nmin_mem_size=int(round(int(pct_memory*virtual_memory.available)\/1073741824,0))\nprint(min_mem_size)\n\n# 65535 Highest port no\n# Start the H2O server on a random port\nport_no=random.randint(5555,55555)\n\n#  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\ntry:\n  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\nexcept:\n  logging.critical('h2o.init')\n  h2o.download_all_logs(dirname=logs_path, filename=logfile)      \n  h2o.cluster().shutdown()\n  sys.exit(2)","88fc58fa":"hf = h2o.H2OFrame(df)","71a174eb":"hf.head()","851c2bb5":"# Create a 80\/20 train\/test split\npct_rows=0.80\nhf_train, hf_test = hf.split_frame([pct_rows])","4de01e97":"print(hf_train.shape)\nprint(hf_test.shape)","c7256c97":"print('missing:', hf_train.isna().sum())\nprint('missing:', hf_test.isna().sum())","d3b96a7e":"mean_impute = hf_train.impute(method = 'mean')\nmean_impute = hf_test.impute(method = 'mean')","d4489f90":"print('missing:', hf_train.isna().sum())\nprint('missing:', hf_test.isna().sum())","8b703586":"# Set the features and target\nX=hf.columns\nprint(X)","294b0242":"# Set target and predictor variables\ny ='HeartDisease'\nX.remove(y) \nprint(X)","c3027740":"# Set up AutoML\naml = H2OAutoML(max_runtime_secs=run_time, seed=1)","e538d6d6":"hf.types","ee7bcc05":"aml.train(x=X,y=y,training_frame=hf_train)","7c75b6bf":"print(aml.leaderboard)","bb3dfb53":"model_index=0\nglm_index=0\nglm_model=''\naml_leaderboard_df=aml.leaderboard.as_data_frame()\nmodels_dict={}\nfor m in aml_leaderboard_df['model_id']:\n  models_dict[m]=model_index\n  if 'StackedEnsemble' not in m:\n    break \n  model_index=model_index+1  \n\nfor m in aml_leaderboard_df['model_id']:\n  if 'GLM' in m:\n    models_dict[m]=glm_index\n    break  \n  glm_index=glm_index+1     \nmodels_dict","2ccfa626":"print(model_index)\nbest_model = h2o.get_model(aml.leaderboard[model_index,'model_id'])","711f1b8b":"best_model.algo","5cb3cadd":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nimport matplotlib.cbook\nwarnings.filterwarnings(\"ignore\", category = matplotlib.cbook.mplDeprecation)","27c1cc1e":"if best_model.algo in ['gbm','drf','xrt','xgboost']:\n  best_model.varimp_plot()","700af94c":"best_model.explain(hf_test)","0b7b4eba":"best_model.partial_plot(hf, cols=['Age'])","d1f6706e":"# Correcting the data","5dbaa61f":"Now there are no missing values, as expected.","cb099191":"There are some other features like ChestPainType that have only a few unique values. Let's use pd.get_dummies(df) to one-hot encode these as well. ","cd2515fa":"## Data size","1f74bda8":"# Descriptive Analytics","e6533b4b":"The above descriptive analysis shows us how many '0's each column has. Unfortunately, there is one column that shouldn't have a zero in it: Cholesterol. It doesn't make much sense to have zero cholesterol. Therefore, we'll need to either (1) remove rows with zeros or (2) impute the data.\n\n","11f0ea90":"Let's take another look at df.info and df.nunique","d1c5cad6":"We have 918 rows and 12 features.","44b09760":"# Run AutoML","3d0a5bb3":"Remember when we replaced all the zeros in Cholesterol and RestingBP with NaNs? This makes it easy to impute the mean of the column in the next step.","c00d1159":"We have NO null data.","d3525a46":"Using nunique() shows us the count of all the distinct values in each column. It makes sense for the columns that have only two distinct values to be binary integers. This is already the case for HeartDisease and Fasting BS, but ExerciseAngina and Sex are both objects. We should turn these features with only two distinct values into binary integers.","a82c7721":"We have evidence that replacing zeros with NaN worked above. Previously we had no NaNs. Now we have a number of NaNs in RestingBP and Cholesterol equal to the number of zeros there were.","2dc018d7":"# About the Dataset","05704d92":"We can prepare for imputation by replacing zeros in RestingBP and Cholesterol with NaN. ","4d8286b8":"We can see there are many zeros. We should impute the data.","2c195e4e":"We can see there is a lone zero. We should remove or impute that.","43db89ee":"Dataset was obtained from Kaggle: https:\/\/www.kaggle.com\/fedesoriano\/heart-failure-prediction","e592f53a":"# Initializing AutoML","860e5e4a":"There are many zeros, but whether this is appropriate is unclear. Perhaps we can trying modeling with imputation and without imputation on this feature.","de2a706a":"Doing this replacement of 0 with N and 1 with Y because otherwise H2O's AutoML treats the response variable as numerical and defaults to logistic regression instead of classification.","71aaf16f":"# Loading the data","93ae7773":"To do:\n\n\n*   Remove or impute zero row from RestingBP\n*   Impute data for Cholesterol\n*   Remember to consider imputing for old peak distribution after we run models\n\nLet's first try imputing the data for the one zero row in RestingBP and for the zeros in Cholesterol. However, we need to split our data into train and test data so that information doesn't \"leak\" between these two subsets.\n\n\n\n","6d5eb8e8":"# Research question(s)","7d1620ba":"From Kaggle dataset description:     \n\n**Context**\n\nCardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease.\n\nPeople with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management wherein a machine learning model can be of great help.\nAttribute Information\n\n    Age: age of the patient [years]\n    Sex: sex of the patient [M: Male, F: Female]\n    ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n    RestingBP: resting blood pressure [mm Hg]\n    Cholesterol: serum cholesterol [mm\/dl]\n    FastingBS: fasting blood sugar [1: if FastingBS > 120 mg\/dl, 0: otherwise]\n    RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]\n    MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]\n    ExerciseAngina: exercise-induced angina [Y: Yes, N: No]\n    Oldpeak: oldpeak = ST [Numeric value measured in depression]\n    ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n    HeartDisease: output class [1: heart disease, 0: Normal]\n\n**Source**\n\nThis dataset was created by combining different datasets already available independently but not combined before. In this dataset, 5 heart datasets are combined over 11 common features which makes it the largest heart disease dataset available so far for research purposes. The five datasets used for its curation are:\n\n    Cleveland: 303 observations\n    Hungarian: 294 observations\n    Switzerland: 123 observations\n    Long Beach VA: 200 observations\n    Stalog (Heart) Data Set: 270 observations\n\nTotal: 1190 observations\n\nDuplicated: 272 observations\n\n**Final dataset: 918 observations**","a0396852":"## Checking For Missing and Null Data","f1dfa27e":"\n\n*   What are the most important features for predicting heart disease?\n*   How well can we predict heart disease with a machine learning model?\n\n\n\n","b4a9eda9":"Looking at the above analysis, the Cholesterol feature once again stands out. The max cholesterol of 603 is wildly above what we would expect for a normal observation, and of course the many zeros (172, found in 'Checking For Missing and Null Data' section) in this feature are troubling as well. \n\nThe zero in RestingBP is problematic as well.\n\nThe Oldpeak min of a negative number is also concerning.","60870fb3":"## Data types \/ One-hot encoding","b7238900":"## Examining Distribution","63bf4d1c":"There should be 173 missing values, and there are."}}