{"cell_type":{"47696c68":"code","7ea66550":"code","36af7fcf":"code","f3ec8a23":"code","a90011ec":"code","7fb2545a":"code","8e23a40e":"code","9c08c28f":"code","91bc4bf6":"code","94a15414":"code","39f4b21e":"code","f13002e7":"code","2870b53d":"code","aa787cf0":"code","83699bc2":"code","0a023bf7":"code","48abc2ef":"code","fa7d33f6":"markdown","d8ee545e":"markdown","a288482d":"markdown","444321a0":"markdown","e59a8456":"markdown","76b85b76":"markdown","6236cc92":"markdown","0c86c3d8":"markdown","d1e82145":"markdown","9be9783c":"markdown","737d6358":"markdown","44ab1b82":"markdown","e9c3bf30":"markdown","ef2c2d03":"markdown"},"source":{"47696c68":"import os\nimport json\nimport csv\nimport random\nimport pickle\nimport cv2\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.transforms as transforms\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.ndimage.measurements import label\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n# For augmentation\nfrom skimage.transform import rotate\nfrom skimage.util import random_noise\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage.morphology import binary_dilation, binary_erosion, binary_closing, binary_opening, binary_fill_holes\n","7ea66550":"class RefugeDataset(Dataset):\n\n    def __init__(self, root_dir, split='train', output_size=(256,256)):\n        # Define attributes\n        self.output_size = output_size\n        self.root_dir = root_dir\n        self.split = split\n        \n        # Transforms\n        trans_img = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Resize(self.output_size, interpolation=Image.BILINEAR),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n        \n        \n            \n        # Load data index\n        with open(os.path.join(self.root_dir, self.split, 'index.json')) as f:\n            self.index = json.load(f)\n            \n        self.images = []\n        for k in range(len(self.index)):\n            print('Loading {} image {}\/{}...'.format(split, k, len(self.index)), end='\\r')\n            img_name = os.path.join(self.root_dir, self.split, 'images', self.index[str(k)]['ImgName'])\n            img = np.array(Image.open(img_name).convert('RGB'))\n            img = transforms.functional.to_tensor(img)\n            img = transforms.functional.resize(img, self.output_size, interpolation=Image.BILINEAR)\n            self.images.append(img)\n            #Augmentation for training set :\n            if split == 'train' :\n                if self.index[str(k)]['Label'] == 1 :\n                    # Flip vertically around the y axis\n                    flip_vertival_img = transforms.functional.hflip(img)\n                    self.images.append(flip_vertival_img)\n                    # Flip horizontally around the x axis\n                    flip_horizontal_img = transforms.functional.vflip(img)\n                    self.images.append(flip_horizontal_img)\n                    # Random noise\n                    noisy_img = transforms.functional.gaussian_blur(img,kernel_size= [5,5])\n                    self.images.append(noisy_img)\n                    # Rotation +5\u00b0\n                    rot_pos_img = transforms.functional.rotate(img,angle = 5)\n                    self.images.append(rot_pos_img)\n                    # Rotation -5\u00b0\n                    rot_neg_img = transforms.functional.rotate(img,angle = -5)\n                    self.images.append(rot_neg_img)\n\n\n\n        # Load ground truth for 'train' and 'val' sets\n        if split != 'test':\n            self.segs = []\n            for k in range(len(self.index)):\n                print('Loading {} segmentation {}\/{}...'.format(split, k, len(self.index)), end='\\r')\n                seg_name = os.path.join(self.root_dir, self.split, 'gts', self.index[str(k)]['ImgName'].split('.')[0]+'.bmp')\n                seg = np.array(Image.open(seg_name)).copy()\n                seg = 255. - seg\n                od = (seg>=127.).astype(np.float32)\n                oc = (seg>=250.).astype(np.float32)\n                od = torch.from_numpy(od[None,:,:])\n                oc = torch.from_numpy(oc[None,:,:])\n                od = transforms.functional.resize(od, self.output_size, interpolation=Image.NEAREST)\n                oc = transforms.functional.resize(oc, self.output_size, interpolation=Image.NEAREST)\n                seg = torch.cat([od, oc], dim=0)\n                self.segs.append(seg)\n                #Augmentation for training set :\n                if split == 'train' :\n                    if self.index[str(k)]['Label'] == 1 :\n                        # Flip vertically around the y axis\n                        flip_vertival_od = transforms.functional.hflip(od)\n                        flip_vertival_oc = transforms.functional.hflip(oc)\n                        flip_vertical_seg = torch.cat([flip_vertival_od, flip_vertival_oc], dim=0)\n                        self.segs.append(flip_vertical_seg)\n                        # Flip horizontally around the x axis\n                        flip_horizontal_od = transforms.functional.vflip(od)\n                        flip_horizontal_oc = transforms.functional.vflip(oc)\n                        flip_horizontal_seg = torch.cat([flip_horizontal_od, flip_horizontal_oc], dim=0)\n                        self.segs.append(flip_horizontal_seg)\n                        # Random noise. We won't add noise on segmentation, it has no sense.\n                        # We will just add again the initial segmentation\n                        self.segs.append(seg)\n                        # Rotation +5\u00b0\n                        rot_pos_od = transforms.functional.rotate(od, angle= 5)\n                        rot_pos_oc = transforms.functional.rotate(oc, angle= 5)\n                        rot_pos_seg = torch.cat([rot_pos_od, rot_pos_oc], dim=0)\n                        self.segs.append(rot_pos_seg)\n                        # Rotation -5\u00b0\n                        rot_neg_od = transforms.functional.rotate(od, angle= -5)\n                        rot_neg_oc = transforms.functional.rotate(oc, angle= -5)\n                        rot_neg_seg = torch.cat([rot_neg_od, rot_neg_oc], dim=0)\n                        self.segs.append(rot_neg_seg)\n                        \n                        \n        print('Succesfully loaded {} dataset.'.format(split) + ' '*50)\n            \n            \n    def __len__(self):\n        return len(self.index)\n\n    def __getitem__(self, idx):\n        # Image\n        img = self.images[idx]\n    \n        # Return only images for 'test' set\n        if self.split == 'test':\n            return img\n        \n        # Else, images and ground truth\n        else:\n            # Label\n            lab = torch.tensor(self.index[str(idx)]['Label'], dtype=torch.float32)\n\n            # Segmentation masks\n            seg = self.segs[idx]\n\n            # Fovea localization\n            f_x = self.index[str(idx)]['Fovea_X']\n            f_y = self.index[str(idx)]['Fovea_Y']\n            fov = torch.FloatTensor([f_x, f_y])\n        \n            return img, lab, seg, fov, self.index[str(idx)]['ImgName']","36af7fcf":"EPS = 1e-7\n\ndef compute_dice_coef(input, target):\n    '''\n    Compute dice score metric.\n    '''\n    batch_size = input.shape[0]\n    return sum([dice_coef_sample(input[k,:,:], target[k,:,:]) for k in range(batch_size)])\/batch_size\n\ndef dice_coef_sample(input, target):\n    iflat = input.contiguous().view(-1)\n    tflat = target.contiguous().view(-1)\n    intersection = (iflat * tflat).sum()\n    return (2. * intersection) \/ (iflat.sum() + tflat.sum())\n\n\ndef vertical_diameter(binary_segmentation):\n    '''\n    Get the vertical diameter from a binary segmentation.\n    The vertical diameter is defined as the \"fattest\" area of the binary_segmentation parameter.\n    '''\n\n    # get the sum of the pixels in the vertical axis\n    vertical_axis_diameter = np.sum(binary_segmentation, axis=1)\n\n    # pick the maximum value\n    diameter = np.max(vertical_axis_diameter, axis=1)\n\n    # return it\n    return diameter\n\n\n\ndef vertical_cup_to_disc_ratio(od, oc):\n    '''\n    Compute the vertical cup-to-disc ratio from a given labelling map.\n    '''\n    # compute the cup diameter\n    cup_diameter = vertical_diameter(oc)\n    # compute the disc diameter\n    disc_diameter = vertical_diameter(od)\n\n    return cup_diameter \/ (disc_diameter + EPS)\n\ndef compute_vCDR_error(pred_od, pred_oc, gt_od, gt_oc):\n    '''\n    Compute vCDR prediction error, along with predicted vCDR and ground truth vCDR.\n    '''\n    pred_vCDR = vertical_cup_to_disc_ratio(pred_od, pred_oc)\n    gt_vCDR = vertical_cup_to_disc_ratio(gt_od, gt_oc)\n    vCDR_err = np.mean(np.abs(gt_vCDR - pred_vCDR))\n    return vCDR_err, pred_vCDR, gt_vCDR\n\n\ndef classif_eval(classif_preds, classif_gts):\n    '''\n    Compute AUC classification score.\n    '''\n    auc = roc_auc_score(classif_gts, classif_preds)\n    return auc\n\n\ndef fov_error(pred_fov, gt_fov):\n    '''\n    Fovea localization error metric (mean root squared error).\n    '''\n    err = np.sqrt(np.sum((gt_fov-pred_fov)**2, axis=1)).mean()\n    return err","f3ec8a23":"def refine_seg(pred):\n    '''\n    Only retain the biggest connected component of a segmentation map.\n    '''\n    np_pred = pred.numpy()\n    \n    #optional\n    #np_pred = binary_fill_holes(binary_closing(np_pred_1))    \n                                \n    largest_ccs = []\n    for i in range(np_pred.shape[0]):\n        labeled, ncomponents = label(np_pred[i,:,:])\n        bincounts = np.bincount(labeled.flat)[1:]\n        if len(bincounts) == 0:\n            largest_cc = labeled == 0\n        else:\n            largest_cc = labeled == np.argmax(bincounts)+1\n        largest_cc = torch.tensor(largest_cc, dtype=torch.float32)\n        largest_ccs.append(largest_cc)\n    largest_ccs = torch.stack(largest_ccs)\n    \n    return largest_ccs","a90011ec":"try:\n    import segmentation_models_pytorch as smp\nexcept:\n    !pip install segmentation-models-pytorch\n    import segmentation_models_pytorch as smp","7fb2545a":"root_dir = '\/kaggle\/input\/eurecom-aml-2021-challenge-2\/refuge_data\/refuge_data'\nlr = 1e-4\nbatch_size = 8\nnum_workers = 8\ntotal_epoch = 1","8e23a40e":"# Datasets\ntrain_set = RefugeDataset(root_dir, \n                          split='train')\nval_set = RefugeDataset(root_dir, \n                        split='val')\ntest_set = RefugeDataset(root_dir, \n                         split='test')\n\n# Dataloaders\ntrain_loader = DataLoader(train_set, \n                          batch_size=batch_size, \n                          shuffle=True, \n                          num_workers=num_workers,\n                          pin_memory=True,\n                         )\nval_loader = DataLoader(val_set, \n                        batch_size=batch_size, \n                        shuffle=False, \n                        num_workers=num_workers,\n                        pin_memory=True,\n                        )\ntest_loader = DataLoader(test_set, \n                        batch_size=batch_size, \n                        shuffle=False, \n                        num_workers=num_workers,\n                        pin_memory=True)","9c08c28f":"print(' Number of training image : ', len(train_set.images))\nprint(' Check if the images are not weird : ', type(train_set.images))\nprint(' Number of training segmentations : ', len(train_set.segs))\nprint(' Check if the segmentations are not weird : ', type(train_set.segs[0]))\nprint(train_set.segs[0].shape)\n#train_set.segs.size()","91bc4bf6":"num1, num2 = train_set.segs[0][0], train_set.segs[0][1]\nfrom scipy.ndimage.morphology import binary_dilation, binary_erosion, binary_closing, binary_opening, morphological_gradient, morphological_laplace\n\ntransformed_image = binary_opening(train_set.segs[0][0])\ntransformed_image2 = binary_closing(train_set.segs[0][0])\n\nfig,ax = plt.subplots(nrows=1,ncols=3,figsize=(20,20))\nax[0].matshow(255. - num1, cmap='gray')\nax[0].axis('off')\nax[1].imshow(255. - num2, cmap='gray')\nax[1].axis('off')\n#ax[1].imshow(transformed_image)\n#ax[1].axis('off')\nax[2].imshow(transformed_image2)\nax[2].axis('off')","94a15414":"# Device\ndevice = torch.device(\"cuda:0\")","39f4b21e":"# Network\n#model = EffUNet(in_channels=3, classes=2).to(device)\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"efficientnet-b4\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n    classes=2,                      # model output channels (number of classes in your dataset)\n    activation='sigmoid'\n).to(device)\n\n# Loss\nseg_loss = torch.nn.BCELoss(reduction='mean')\n\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)","f13002e7":"#uncomment in case of using the morphology on imgs\n#pip install kornia","2870b53d":"import kornia\nfrom kornia.morphology.basic_operators import dilation, erosion","aa787cf0":"# Define parameters\nnb_train_batches = len(train_loader)\nprint('number of train batches : ', nb_train_batches)\nnb_val_batches = len(val_loader)\nnb_iter = 0\nbest_val_auc = 0.\nepoch = 0\nwhile epoch < total_epoch:\n    # Accumulators\n    train_vCDRs, val_vCDRs = [], []\n    train_classif_gts, val_classif_gts = [], []\n    train_loss, val_loss = 0., 0.\n    train_dsc_od, val_dsc_od = 0., 0.\n    train_dsc_oc, val_dsc_oc = 0., 0.\n    train_vCDR_error, val_vCDR_error = 0., 0.\n    \n    ############\n    # TRAINING #\n    ############\n    model.train()\n    train_data = iter(train_loader)\n    for k in range(nb_train_batches):\n        torch.backends.cudnn.determinstic = True\n        torch.backends.cudnn.benchmark = False\n        # Loads data\n        imgs, classif_gts, seg_gts, fov_coords, names = train_data.next()\n        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n        \n        # Uncomment if you want to apply it\n        \n        # Morphology operation\n        #kernel = torch.ones(3, 3).type(torch.float32).cpu().to(device)\n        #imgs = erosion(dilation(imgs, kernel), kernel)\n\n        # Forward pass\n        logits = model(imgs)\n        loss = seg_loss(logits, seg_gts)\n \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() \/ nb_train_batches\n        \n        with torch.no_grad():\n            # Compute segmentation metric\n            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n            dsc_od = compute_dice_coef(pred_od, gt_od)\n            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n            train_dsc_od += dsc_od.item()\/nb_train_batches\n            train_dsc_oc += dsc_oc.item()\/nb_train_batches\n\n\n            # Compute and store vCDRs\n            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n            train_vCDRs += pred_vCDR.tolist()\n            train_vCDR_error += vCDR_error \/ nb_train_batches\n            train_classif_gts += classif_gts.cpu().numpy().tolist()\n            \n        # Increase iterations\n        nb_iter += 1\n        \n        # Std out\n        print('Epoch {}, iter {}\/{}, loss {:.6f}'.format(epoch+1, k+1, nb_train_batches, loss.item()) + ' '*20, \n              end='\\r')\n        \n    # Train a logistic regression on vCDRs\n    train_vCDRs = np.array(train_vCDRs).reshape(-1,1)\n    train_classif_gts = np.array(train_classif_gts)\n    clf = LogisticRegression(random_state=0, solver='lbfgs').fit(train_vCDRs, train_classif_gts)\n    train_classif_preds = clf.predict_proba(train_vCDRs)[:,1]\n    train_auc = classif_eval(train_classif_preds, train_classif_gts)\n    \n    ##############\n    # VALIDATION #\n    ##############\n    model.eval()\n    with torch.no_grad():\n        val_data = iter(val_loader)\n        for k in range(nb_val_batches):\n            # Loads data\n            imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n            imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n            \n            \n            # Uncomment if you want to apply it\n\n            # Morphology operation\n            #kernel = torch.ones(3, 3).type(torch.float32).cpu().to(device)\n            #imgs = erosion(dilation(imgs, kernel), kernel)\n\n            # Forward pass\n            logits = model(imgs)\n            val_loss += seg_loss(logits, seg_gts).item() \/ nb_val_batches\n\n            # Std out\n            print('Validation iter {}\/{}'.format(k+1, nb_val_batches) + ' '*50, \n                  end='\\r')\n            \n            # Compute segmentation metric\n            pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n            pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n            gt_od = seg_gts[:,0,:,:].type(torch.int8)\n            gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n            dsc_od = compute_dice_coef(pred_od, gt_od)\n            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n            val_dsc_od += dsc_od.item()\/nb_val_batches\n            val_dsc_oc += dsc_oc.item()\/nb_val_batches\n            \n            # Compute and store vCDRs\n            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n            val_vCDRs += pred_vCDR.tolist()\n            val_vCDR_error += vCDR_error \/ nb_val_batches\n            val_classif_gts += classif_gts.cpu().numpy().tolist()\n            \n\n    # Glaucoma predictions from vCDRs\n    val_vCDRs = np.array(val_vCDRs).reshape(-1,1)\n    val_classif_gts = np.array(val_classif_gts)\n    val_classif_preds = clf.predict_proba(val_vCDRs)[:,1]\n    val_auc = classif_eval(val_classif_preds, val_classif_gts)\n        \n    # Validation results\n    print('VALIDATION epoch {}'.format(epoch+1)+' '*50)\n    print('LOSSES: {:.4f} (train), {:.4f} (val)'.format(train_loss, val_loss))\n    print('OD segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_od, val_dsc_od))\n    print('OC segmentation (Dice Score): {:.4f} (train), {:.4f} (val)'.format(train_dsc_oc, val_dsc_oc))\n    print('vCDR error: {:.4f} (train), {:.4f} (val)'.format(train_vCDR_error, val_vCDR_error))\n    print('Classification (AUC): {:.4f} (train), {:.4f} (val)'.format(train_auc, val_auc))\n    \n    # Save model if best validation AUC is reached\n    if val_auc > best_val_auc:\n        torch.save(model.state_dict(), '\/kaggle\/working\/best_AUC_weights.pth')\n        with open('\/kaggle\/working\/best_AUC_classifier.pkl', 'wb') as clf_file:\n            pickle.dump(clf, clf_file)\n        best_val_auc = val_auc\n        print('Best validation AUC reached. Saved model weights and classifier.')\n    print('_'*50)\n        \n    # End of epoch\n    epoch += 1\n        \n","83699bc2":"# Load model and classifier\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"efficientnet-b4\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n    classes=2,                      # model output channels (number of classes in your dataset)\n    activation='sigmoid'\n).to(device)\n\nmodel.load_state_dict(torch.load('\/kaggle\/working\/best_AUC_weights.pth'))\nwith open('\/kaggle\/working\/best_AUC_classifier.pkl', 'rb') as clf_file:\n    clf = pickle.load(clf_file)","0a023bf7":"model.eval()\nval_vCDRs = []\nval_classif_gts = []\nval_loss = 0.\nval_dsc_od = 0.\nval_dsc_oc = 0.\nval_vCDR_error = 0.\nwith torch.no_grad():\n    val_data = iter(val_loader)\n    for k in range(nb_val_batches):\n        # Loads data\n        imgs, classif_gts, seg_gts, fov_coords, names = val_data.next()\n        imgs, classif_gts, seg_gts = imgs.to(device), classif_gts.to(device), seg_gts.to(device)\n        \n        \n        # Uncomment if you want to apply it\n        # Morphology operation\n        #kernel = torch.ones(3, 3).type(torch.float32).cpu().to(device)\n        #imgs = erosion(dilation(imgs, kernel), kernel)\n\n        # Forward pass\n        logits = model(imgs)\n        val_loss += seg_loss(logits, seg_gts).item() \/ nb_val_batches\n\n        # Std out\n        print('Validation iter {}\/{}'.format(k+1, nb_val_batches) + ' '*50, \n              end='\\r')\n\n        # Compute segmentation metric\n        pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n        pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n        gt_od = seg_gts[:,0,:,:].type(torch.int8)\n        gt_oc = seg_gts[:,1,:,:].type(torch.int8)\n        dsc_od = compute_dice_coef(pred_od, gt_od)\n        dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n        val_dsc_od += dsc_od.item()\/nb_val_batches\n        val_dsc_oc += dsc_oc.item()\/nb_val_batches\n\n        # Compute and store vCDRs\n        vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n        val_vCDRs += pred_vCDR.tolist()\n        val_vCDR_error += vCDR_error \/ nb_val_batches\n        val_classif_gts += classif_gts.cpu().numpy().tolist()\n\n\n# Glaucoma predictions from vCDRs\nval_vCDRs = np.array(val_vCDRs).reshape(-1,1)\nval_classif_gts = np.array(val_classif_gts)\nval_classif_preds = clf.predict_proba(val_vCDRs)[:,1]\nval_auc = classif_eval(val_classif_preds, val_classif_gts)\n\n# Validation results\nprint('VALIDATION '+' '*50)\nprint('LOSSES: {:.4f} (val)'.format(val_loss))\nprint('OD segmentation (Dice Score): {:.4f} (val)'.format(val_dsc_od))\nprint('OC segmentation (Dice Score): {:.4f} (val)'.format(val_dsc_oc))\nprint('vCDR error: {:.4f} (val)'.format(val_vCDR_error))\nprint('Classification (AUC): {:.4f} (val)'.format(val_auc))","48abc2ef":"nb_test_batches = len(test_loader)\nmodel.eval()\ntest_vCDRs = []\nwith torch.no_grad():\n    test_data = iter(test_loader)\n    for k in range(nb_test_batches):\n        # Loads data\n        imgs = test_data.next()\n        imgs = imgs.to(device)\n        \n        # Uncomment if you want to apply it\n        # Morphology operation\n        #kernel = torch.ones(3, 3).type(torch.float32).cpu().to(device)\n        #imgs = erosion(dilation(imgs, kernel), kernel)\n\n        # Forward pass\n        logits = model(imgs)\n\n        # Std out\n        print('Test iter {}\/{}'.format(k+1, nb_test_batches) + ' '*50, \n              end='\\r')\n            \n        # Compute segmentation\n        pred_od = refine_seg((logits[:,0,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n        pred_oc = refine_seg((logits[:,1,:,:]>=0.5).type(torch.int8).cpu()).to(device)\n            \n        # Compute and store vCDRs\n        pred_vCDR = vertical_cup_to_disc_ratio(pred_od.cpu().numpy(), pred_oc.cpu().numpy())\n        test_vCDRs += pred_vCDR.tolist()\n            \n\n    # Glaucoma predictions from vCDRs\n    test_vCDRs = np.array(test_vCDRs).reshape(-1,1)\n    test_classif_preds = clf.predict_proba(test_vCDRs)[:,1]\n    \n# Prepare and save .csv file\ndef create_submission_csv(prediction, submission_filename='\/kaggle\/working\/submission.csv'):\n    \"\"\"Create a sumbission file in the appropriate format for evaluation.\n\n    :param\n    prediction: list of predictions (ex: [0.12720, 0.89289, ..., 0.29829])\n    \"\"\"\n    \n    with open(submission_filename, mode='w') as csv_file:\n        fieldnames = ['Id', 'Predicted']\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        writer.writeheader()\n\n        for i, p in enumerate(prediction):\n            writer.writerow({'Id': \"T{:04d}\".format(i+1), 'Predicted': '{:f}'.format(p)})\n\ncreate_submission_csv(test_classif_preds, submission_filename='\/kaggle\/working\/TA_Unetplusplus_smp_augmentedGLAUCOMA_submission.csv')\n\n# The submission.csv file is under \/kaggle\/working\/submission.csv.\n# If you want to submit it, you should download it before closing the current kernel.","fa7d33f6":"# Markdown","d8ee545e":"Just visualize the inputs","a288482d":"# Optional pre processing","444321a0":"# Segmentation models\nhttps:\/\/github.com\/qubvel\/segmentation_models.pytorch#architectures  \nTraining example: https:\/\/github.com\/qubvel\/segmentation_models.pytorch\/blob\/master\/examples\/cars%20segmentation%20(camvid).ipynb\n\n## Improved Unet++ \nDocs: https:\/\/smp.readthedocs.io\/en\/latest\/models.html#id2","e59a8456":"# Post-processing functions","76b85b76":"# Device, model, loss and optimizer","6236cc92":"# Load best model + classifier","0c86c3d8":"# Dataset class","d1e82145":"# Check performance is maintained on validation","9be9783c":"# Settings","737d6358":"# Train for OC\/OD segmentation","44ab1b82":"# Create datasets and data loaders\nAll image files are loaded in RAM in order to speed up the pipeline. Therefore, each dataset creation should take a few minutes.","e9c3bf30":"# Predictions on test set","ef2c2d03":"# Network"}}