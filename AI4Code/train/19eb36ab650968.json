{"cell_type":{"4a590e05":"code","6288cb0a":"code","54244754":"code","f9f1ace4":"code","7654b1ba":"code","62725b15":"code","8f0fab92":"code","c4d39ac2":"code","988711eb":"code","ea0a2658":"code","f17aa29e":"code","18f6714f":"code","4c0a9b0d":"code","d05b654e":"code","f41a0824":"code","b8124929":"code","c96b7136":"code","d7d69a9e":"code","3bc0a822":"code","b8209f5d":"code","8ca33e17":"code","e3c3dfe3":"code","18b29412":"code","958eabc7":"code","e1e3d52a":"code","b629d2ea":"code","253a8515":"code","d65c34c5":"code","f3af575f":"code","0a343098":"code","e41b68fc":"code","55bd85ae":"markdown","7597748e":"markdown","3372b30b":"markdown","f1178006":"markdown","7bd48156":"markdown","2754d062":"markdown","9e860c66":"markdown","6ef743f9":"markdown","68005abf":"markdown","f427ac1c":"markdown","be7f7b7d":"markdown","f84e2c42":"markdown","961ce966":"markdown","3224cd86":"markdown","9cbfc733":"markdown","0353acdb":"markdown","ef2fa7f8":"markdown","c781eb3f":"markdown"},"source":{"4a590e05":"# !pip install tensorflow-gpu==2.1-rc2","6288cb0a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, classification_report\nsns.set(style='whitegrid')\n# DL libraries\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, BatchNormalization, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","54244754":"df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","f9f1ace4":"# Let's see train data\ndf.head()","7654b1ba":"df.info()","62725b15":"plt.figure(figsize=(14, 6))\nax = sns.countplot(data = df, x= 'label', palette = 'Set2')\nfor p in ax.patches:\n    x = 0\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:}'.format(height),\n            ha=\"center\") \n    x+=1\nplt.show()","8f0fab92":"def plot_samples(df, cls = 1):\n    fig = plt.figure(figsize = (10,10))\n    fig.suptitle('Samples of Class - {}'.format(cls), fontsize=16)\n    data = df[df.label == cls]\n    for i in range(1, 10):\n        fig.add_subplot(3,3,i)\n        plt.imshow(data.iloc[i, 1:].values.reshape(28, 28))\n        plt.axis('off')\n    plt.show()","c4d39ac2":"for i in range(1, 10):\n    plot_samples(df, cls = i)","988711eb":"X = df.iloc[:, 1:].values\ny = df.iloc[:, 0]","ea0a2658":"X.shape, y.shape","f17aa29e":"# create scaler\nscaler = MinMaxScaler()\n# fit scaler on data\nscaler.fit(X)\n# apply transform\nnormalized = scaler.transform(X)","18f6714f":"# Reshaping data into 28X28\nX = X.reshape(-1, 28, 28, 1)\ny = to_categorical(y, num_classes = 10)","4c0a9b0d":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.20, random_state = 8)\n\nprint('Train Shape: {}\\nValid Shape: {}'.format(X_train.shape, X_valid.shape))","d05b654e":"data_gen = ImageDataGenerator(rescale=1.\/255,\n                                rotation_range=10,\n                                width_shift_range=.10,\n                                height_shift_range=.10,\n                                horizontal_flip=False,\n                                zoom_range = 0.10)","f41a0824":"# model = Sequential() \n\n# model.add(Conv2D(128, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(128, (5,5),activation ='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# model.add(Conv2D(64, (3,3),activation ='relu'))\n# model.add(BatchNormalization())\n# model.add(Conv2D(64, (3,3),activation ='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D((2,2), (2,2)))\n# model.add(Dropout(0.4))\n\n# model.add(Conv2D(32, (3,3), activation ='relu'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.3))\n\n# model.add(Flatten())\n# model.add(Dense(256, activation = \"relu\"))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.4))\n\n# model.add(Dense(10, activation = \"softmax\"))\n# model.summary()\n","b8124929":"from tensorflow import Tensor\nfrom tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Add, AveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.activations import elu\n# tf.compat.v1.enable_eager_execution(\n#     config=None, device_policy=None, execution_mode=None\n# )\ndef Elu_BN(x):\n    x = elu(x, alpha=0.5)\n    x = BatchNormalization()(x)\n    return x\n\ndef residual_block(r, filters, kernel_size, name):\n    \n    y = Conv2D(kernel_size=kernel_size,filters=filters, padding=\"same\", name = name)(r)\n    y = ReLU()(y)\n    y = BatchNormalization()(y)\n    y = Conv2D(kernel_size=kernel_size, filters=filters, padding=\"same\")(y)\n        \n    out = Add()([r, y])\n    out = ReLU()(out)\n    out = BatchNormalization()(out)\n    return out\n\n\ninputs = Input((28, 28, 1))\nnum_filters = 64\n\nr = BatchNormalization()(inputs)\nr = Conv2D(kernel_size=5, strides=1, filters=num_filters, padding=\"same\")(r)\nr = Elu_BN(r)\nr = residual_block(r, filters = 64, kernel_size = 5, name = 'Residual_Block_1')\nr = residual_block(r, filters = 64, kernel_size = 5, name = 'Residual_Block_2')\nr = AveragePooling2D(2)(r)\nr = residual_block(r, filters = 64, kernel_size = 3,name = 'Residual_Block_3')\nr = residual_block(r, filters = 64, kernel_size = 3,name = 'Residual_Block_4')\nr = AveragePooling2D(2)(r)\nr = Flatten()(r)\nr = Dense(100, activation = 'relu')(r)\nr = Dropout(0.2)(r)\nr = Dense(100, activation = 'relu')(r)\noutputs = Dense(10, activation='softmax')(r)\n\nmodel = Model(name = 'ResidualNet', inputs = inputs, outputs =outputs)\n\nmodel.summary()","c96b7136":"# Plot Model\nplot_model(model, to_file='model.png', show_shapes=True)","d7d69a9e":"model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","3bc0a822":"## Callbacks\nmodel_check = ModelCheckpoint('best_model.h5', monitor='accuracy', verbose=0, save_best_only=True, mode='max')\n\nearly = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=0, mode='max', restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, min_lr=0.000001)","b8209f5d":"history = model.fit_generator(data_gen.flow(X_train, y_train, batch_size=64, seed=1),\n                              steps_per_epoch=(len(X_train)*0.8)\/\/64, epochs=100, \n                              validation_data=data_gen.flow(X_valid, y_valid, batch_size=64, seed=2), \n                              validation_steps=(len(X_valid)*0.2)\/\/64,\n                             callbacks = [model_check, early, reduce_lr])","8ca33e17":"hist_df = pd.DataFrame(data = history.history)\nfig = go.Figure()\nind = np.arange(1, len(history.history['accuracy'])+1)\nfig.add_trace(go.Scatter(x=ind, mode='lines+markers', y=hist_df['accuracy'], marker=dict(color=\"dodgerblue\"), name=\"Train_Accyracy\"))\n    \nfig.add_trace(go.Scatter(x=ind, mode='lines+markers', y=hist_df['val_accuracy'], marker=dict(color=\"darkorange\"),name=\"Validation_Accuracy\"))\n    \nfig.update_layout(title_text='Accuracy', yaxis_title='Accuracy', xaxis_title=\"Epochs\", template=\"plotly_white\")\n\nfig.show()","e3c3dfe3":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=ind, mode='lines+markers', y=hist_df['loss'], marker=dict(color=\"dodgerblue\"), name=\"Train_Loss\"))\n    \nfig.add_trace(go.Scatter(x=ind, mode='lines+markers', y=hist_df['val_loss'], marker=dict(color=\"darkorange\"),name=\"Validation_Loss\"))\n    \nfig.update_layout(title_text='Loss', yaxis_title='Loss', xaxis_title=\"Epochs\", template=\"plotly_white\")\n\nfig.show()","18b29412":"loss, acc = model.evaluate(data_gen.flow(X_valid, y_valid, batch_size=64, seed=2))\nprint(\"Loss: {}\\nAccuracy: {}\".format(loss, acc))","958eabc7":"pred = np.argmax(model.predict(X_valid, verbose=1), axis=1)","e1e3d52a":"plt.figure(figsize = (15, 15))\nsns.heatmap(confusion_matrix(np.argmax(y_valid, axis=1), pred), annot=True, annot_kws={\"size\": 16}, fmt = 'd') \nplt.show()","b629d2ea":"print(classification_report(np.argmax(y_valid, axis=1), pred))","253a8515":"fig = plt.figure(figsize = (10, 10))\nfor i in range(1, 10):\n    fig.add_subplot(3,3,i)\n    q = np.random.randint(len(X_valid))\n    plt.imshow(X_valid[q].reshape(28, 28))\n    plt.title(\"True: {} --- Pred: {}\".format(np.argmax(y_valid[q]), np.argmax(model.predict(X_valid[q].reshape(-1,28,28,1)))))\n    plt.axis('off')\nplt.show()","d65c34c5":"X_test = test.iloc[:, :].values\n\nscaler = MinMaxScaler()\nscaler.fit(X_test)\nX_test = scaler.transform(X_test)\n\nX_test = X_test.reshape(-1, 28, 28, 1)\nprint('Test Data Shape: ', X_test.shape)","f3af575f":"predictions = np.argmax(model.predict(X_test), axis=1)","0a343098":"sub = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsub['Label'] = predictions\n\nsub.head()","e41b68fc":"sub.to_csv('MNIST_Submission_ResNet_5.csv', index=False)","55bd85ae":"## Classification Report","7597748e":"## Prediction","3372b30b":"## Read Data","f1178006":"## Visualizing data w.r.t each class","7bd48156":"# <font color='tomato'>Digit Recognizer Uisng CNN<\/font>","2754d062":"## Sample predicted Images","9e860c66":"## Confusion Matrix","6ef743f9":"## Data Agumentation\n\nBest [bolg](https:\/\/machinelearningmastery.com\/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks\/) to learn about Data Agumentaion.","68005abf":"### Countplot","f427ac1c":"#### <font color = 'tomato'>Version - 1<\/font>: [Convolutional Neural Network(CNN)](https:\/\/www.kaggle.com\/syamkakarla\/digit-recognizer-using-cnn-99-55?scriptVersionId=32857972)\n#### <font color = 'tomato'>Version - 2<\/font>:[ Residual Network(ResNet)](https:\/\/www.kaggle.com\/syamkakarla\/digit-recognizer-using-cnn-99-55?scriptVersionId=32918260)","be7f7b7d":"## Normalizating the Data\n\nwhy should we do [normalization](https:\/\/machinelearningmastery.com\/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling\/).","f84e2c42":"## Build CNN Model ","961ce966":"## Accuracy and Loss Graphs","3224cd86":"## Importing Data and Libraries","9cbfc733":"Important links to learn about CNN and it's implementation:\n\n1. [Keras Documentation](https:\/\/keras.io\/layers\/core\/)\n","0353acdb":"## Split data into train and validation","ef2fa7f8":"---","c781eb3f":"## Model Evaluation"}}