{"cell_type":{"8195152d":"code","900962d9":"code","da61000b":"code","bb1badcf":"code","f31cbdde":"code","f1e744f0":"code","4338b60d":"code","6a5e3c79":"code","68a10b43":"code","c928365d":"code","5e17fd04":"code","a18af0c2":"code","a6a78de8":"code","bb7c8a16":"code","44aba820":"code","1a020a5a":"code","57cd08ef":"code","76ab72ac":"code","f94fac3a":"code","7af8f639":"code","de87cbc9":"code","468f28c9":"code","215d28d9":"code","436b2dd9":"code","24179963":"code","109d3945":"code","17eb3b09":"code","1948965d":"code","43382a0a":"code","61249639":"code","4663a719":"code","a141fe0e":"code","d3242a0b":"code","86e25ffd":"code","0bc44e93":"code","8c259eaf":"code","c68811a2":"code","d64c1a38":"code","6a0eaf4b":"code","98e18962":"code","6fcb4eb2":"code","aaee9e83":"markdown","c3e421a3":"markdown","4b90a64c":"markdown","2ddc977a":"markdown","fe588766":"markdown","c91186d8":"markdown","849074a2":"markdown","4ed5eb72":"markdown","72c91ba4":"markdown","aebbd783":"markdown","e94d196a":"markdown","eec9b6fc":"markdown","ce094652":"markdown","7bf1afe3":"markdown","9a6d7960":"markdown","2b531800":"markdown","6d6c42ea":"markdown","b54d3de8":"markdown","935162c6":"markdown","239c3439":"markdown","dd45eaef":"markdown","6fa5712c":"markdown","3d58c5c1":"markdown","00c5a0ac":"markdown"},"source":{"8195152d":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom functools import reduce\nimport dateutil.parser as dateparser\nfrom datetime import datetime\nimport re\nimport pdb\nfrom tqdm import tqdm\nfrom collections import Counter","900962d9":"import spacy\nfrom spacy.lang.en import English","da61000b":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable","bb1badcf":"nlp_en = English()","f31cbdde":"Path.ls = lambda self: [fn for fn in self.glob('*')]","f1e744f0":"PATH = Path('..\/input\/cityofla\/CityofLA\/')\nbulletins = PATH\/'Job Bulletins'","4338b60d":"fn = bulletins.ls()[39]","6a5e3c79":"with open(fn, encoding='latin-1') as f:\n    print(fn.name)\n    print(''.join(f.readlines()[:10]))","68a10b43":"def new_data():\n    return {\n        'File Name': [],\n        'Class Code': [],\n        'Job Title': [],\n        'Open Date': [],\n        'ANNUAL SALARY': [],\n        'DUTIES': [],\n        'REQUIREMENTS': [],\n        'WHERE TO APPLY': [],\n        'APPLICATION DEADLINE': [],\n        'SELECTION PROCESS': []\n    }\n\nsections = ['ANNUAL SALARY', 'DUTIES', 'REQUIREMENTS', 'WHERE TO APPLY', 'APPLICATION DEADLINE', 'SELECTION PROCESS']\n\ndef is_open_date(line):\n    return line.startswith('Open Date:')\n\ndef on_open_date(data, key, value):\n    data[key][-1] = dateparser.parse(value.split()[2])\n    key, value = None, None\n    return key, value\n\ndef is_section_begin(sections, line):\n    def _startswith(n=None):\n        return len(list(filter(lambda section: line.startswith(section[:n]), sections)))>0\n    return (line in sections) or _startswith() or _startswith(n=-1)\n\ndef get_section_key(sections, line):\n    if line in sections:\n        return line\n    # find appropriate key, e.g. REQUIREMENTS\/MINIMUM QUALIFICATIONS -> REQUIREMENTS\n    for section in sections:\n        if line.startswith(section) or line.startswith(section[:-1]):\n            return section\n\ndef on_section_begin(data, key, value):\n    return key, value\n\ndef on_section_end(data, key, value):\n    if key is not None:\n        key = get_section_key(sections, key)\n        data[key][-1] = value\n        key, value = None, None\n    return key, value\n\ndef add_row(data, sections):\n    for section in sections:\n        data[section].append('')\n\ndef parse_sections(f, data, sections):\n    add_row(data, sections + ['File Name', 'Job Title', 'Class Code', 'Open Date'])\n    data['File Name'][-1] = fn.name\n    key, value = None, None\n    for index, line in enumerate(f):\n        line = line.strip()\n        if index == 0:\n            data['Job Title'][-1] = line.strip()\n        elif line.startswith('Class Code:'):\n            data['Class Code'][-1] = line.split()[2]\n        elif is_open_date(line):\n            key, value = on_open_date(data, 'Open Date', line)    # handle Open Date section\n        elif is_section_begin(sections, line):\n            key, value = on_section_end(data, key, value)         # end previous section\n            key, value = on_section_begin(data, line, '') # begin current section\n        elif key is not None:\n            value += line  \n    on_section_end(data, key, value)                              # end last section","c928365d":"data = new_data()\nwith open(fn, encoding='latin-1') as f:\n    parse_sections(f, data, sections)","5e17fd04":"assert data['File Name'][0] == 'POLICE COMMANDER 2251 092917.txt'\nassert data['Class Code'][0] == '2251'\nassert data['Job Title'][0] == 'POLICE COMMANDER'\nassert data['Open Date'][0].strftime('%m-%d-%Y') == '09-29-2017'","a18af0c2":"pd.DataFrame(data)","a6a78de8":"data = new_data()\nfor fn in tqdm(bulletins.ls()):\n    with open(fn, encoding='latin-1') as f:\n        parse_sections(f, data, sections)","bb7c8a16":"df = pd.DataFrame(data)\ndf.head()","44aba820":"df['DUTIES'].str.len().hist()","1a020a5a":"df['REQUIREMENTS'].str.len().hist()","57cd08ef":"df['WHERE TO APPLY'].str.len().hist()","76ab72ac":"df['ANNUAL SALARY'].values[10]","f94fac3a":"def get_minmax_salary(s):\n    if not s or len(s) == 0:\n        return 0, 0\n    salary_regex = r'\\$[0-9]+,?[0-9]+\\.?[0-9]*'\n    salaries = re.findall( salary_regex, s)\n    if len(salaries)==0:\n        return 0, 0\n    salaries = list(map(lambda s: float(s.replace('$', '').replace(',', '')), salaries))\n    return min(salaries), max(salaries)","7af8f639":"salary_minmax = list(map(get_minmax_salary, df['ANNUAL SALARY'].values))\nsalary_ranges = [max_salary-min_salary for (min_salary, max_salary) in salary_minmax]","de87cbc9":"# plot a histogram for the ranges\nplt.hist(salary_ranges)","468f28c9":"top10 = sorted(salary_ranges, reverse=True)[:10]; top10\n#salary_ranges.sort(reverse=True); salary_ranges[:10]","215d28d9":"mask = [x in top10 for x in salary_ranges]\ndf[mask]","436b2dd9":"df.groupby(df['Open Date'].dt.year).agg({'File Name': 'count'}).plot(figsize=(8, 8), marker='*')","24179963":"df.groupby(df['Open Date'].dt.month).agg({'File Name': 'count'}).plot(figsize=(8, 8), kind='bar')","109d3945":"doc = nlp_en(' '.join(df['Job Title'].values).lower())","17eb3b09":"# all tokens that arent stop words or punctuations\nwords = [token.text for token in doc if not (token.is_stop or token.is_punct or token.is_space)]\n# noun tokens that arent stop words or punctuations\nnouns = [token.text for token in doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\"]","1948965d":"ax = sns.barplot(y='word', x='frequency', data=pd.DataFrame(Counter(words).most_common(20), columns=['word', 'frequency']))","43382a0a":"nlp_en.add_pipe(nlp_en.create_pipe('sentencizer')) # enable spacy to split sentences","61249639":"#doc2 = list(map(lambda text: [sent for sent in nlp_en(text.lower()).sents], df['Job Title'].values))\ndoc2 = [sent for sent in nlp_en(df['REQUIREMENTS'].values[0].lower()).sents]","4663a719":"sents_len = list(map(lambda text: [len(sent) for sent in nlp_en(text.lower()).sents], df['REQUIREMENTS'].values))","a141fe0e":"fig = plt.figure(figsize=(10, 10))\nstart, end = 0, 10\nfor i in range(start, end):\n    plt.plot(sents_len[i], label=('%2d' % i))\nplt.legend()","d3242a0b":"plt.hist([len(sl) for sl in sents_len])","86e25ffd":"# pad the array of sentences length\ndef right_pad(a, m):\n    while len(a)<m: a.append(0)\n    return a\nmax_len = min(30, max([len(sl) for sl in sents_len]))\n\ntrimed_sents_len = [sl if len(sl)<=max_len else sl[:max_len] for sl in sents_len]\n\npadded_sents_len = [sl if len(sl)==max_len else right_pad(sl, max_len) for sl in trimed_sents_len]","0bc44e93":"arr = np.array(padded_sents_len)\n\nplt.figure(figsize=(30, 30))\nax = plt.gca()\nim = ax.imshow(arr, cmap='viridis')\n\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n\nplt.colorbar(im, cax=cax)\nplt.show()","8c259eaf":"nlp_en_web = spacy.load('en_core_web_sm')","c68811a2":"requirements_doc = nlp_en_web(df['REQUIREMENTS'].values[0].lower())\nrequirements_tag_df = pd.DataFrame([(token.text, token.pos_) for token in requirements_doc], columns=['word', 'tag'])\nrequirements_tag_df.head()","d64c1a38":"requirements_tag_df['tag'].unique()","6a0eaf4b":"requirements_tag_df[requirements_tag_df['tag']=='PRON']","98e18962":"duties_doc = nlp_en_web(df['DUTIES'].values[0].lower())\nduties_tag_df = pd.DataFrame([(token.text, token.pos_) for token in duties_doc], columns=['word', 'tag'])\nduties_tag_df.head()","6fcb4eb2":"duties_tag_df['tag'].unique() # no pronoun use","aaee9e83":"### DUTIES","c3e421a3":"looking for pronouns that could indicate gender bias","4b90a64c":"### Finding all columns","2ddc977a":"displaying the sentences lengths with a heatmap","fe588766":"## Looking at a Job listing","c91186d8":"### REQUIREMENTS","849074a2":"### Gender bias in Requirements section","4ed5eb72":"Running the parser on all files","72c91ba4":"### Tap 10 job listings with higher salary range","aebbd783":"## How is the salary","e94d196a":"## Readability","eec9b6fc":"### What's the salary range?","ce094652":"test the parsing on one file","7bf1afe3":"few job postings have over 30 sentence, let's trim at 30 and pad those with fewer sentences","9a6d7960":"### Gender bias in Duties section","2b531800":"## How long is each section","6d6c42ea":"### Popular job class","b54d3de8":"looking for pronouns that could indicate gender bias","935162c6":"### Exploring sentenses length","239c3439":"## Gender bias","dd45eaef":"### How does the job listings changes over month","6fa5712c":"## Job listings over year","3d58c5c1":"To be continued.","00c5a0ac":"### WHERE TO APPLY"}}