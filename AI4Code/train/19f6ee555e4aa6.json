{"cell_type":{"b035441f":"code","43e6a076":"code","3e413c3f":"code","e4da2dd1":"code","f2463acf":"code","526cd2f6":"code","c9099dfa":"code","e2416123":"code","ed7cfa9c":"code","ee82e46d":"code","a9433dd1":"code","96707919":"code","94a51043":"code","54f9f9de":"code","434ac0c4":"code","38afd024":"code","77ee2e58":"code","5fbc4659":"code","78fcc0a1":"code","9ddf8095":"code","dfd15437":"code","812562f1":"code","adf0c682":"code","ab24cf01":"code","df6f659a":"code","8e0b1848":"code","86bf124c":"code","6fc4304b":"code","edc13f67":"code","ef63c026":"markdown","14d75684":"markdown","69aaa913":"markdown","be2e663a":"markdown","2aad9a5a":"markdown","0e494cb9":"markdown","4f39f8fc":"markdown","5c329fab":"markdown","f77b6bb9":"markdown","14e4270c":"markdown","3dac834f":"markdown","ed69bf4e":"markdown","fcac25f8":"markdown","49aee006":"markdown","7a092e04":"markdown","7c8aa39d":"markdown","f4a6692c":"markdown","a74fec86":"markdown","74ca4b8c":"markdown"},"source":{"b035441f":"!pip install -q tensorflow==2.6.0","43e6a076":"import tensorflow as tf\nimport numpy as np\nfrom sklearn import metrics\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","3e413c3f":"class Config:\n    batch_size = 128\n    epochs = 10\n    embed_dim = 128\n    validation_split = 0.15\n    maxlen = 192\n    vocab_size = 10000\n    labels = np.array([\"neg\", \"pos\"])\n    num_classes = len(labels)\n    label_display_names = np.array([\"Negative\", \"Positive\"])\n    model_path = \"model.tf\"\nconfig = Config()","e4da2dd1":"data = pd.read_csv(\"\/kaggle\/input\/imdb-review-dataset\/imdb_master.csv\", encoding='unicode_escape')\ndata.head()","f2463acf":"data[\"label\"].hist()","526cd2f6":"data = data[(data[\"label\"] == \"neg\") | (data[\"label\"] == \"pos\")]","c9099dfa":"data[\"label\"].hist()","e2416123":"vectorizer = layers.TextVectorization(\n    max_tokens=config.vocab_size, \n    output_sequence_length=config.maxlen\n)\nvectorizer.adapt(data[\"review\"])","ed7cfa9c":"vocab = vectorizer.get_vocabulary()\nlen(vocab)","ee82e46d":"vocab[:10]","a9433dd1":"labels = list(Config.labels)\ndata[\"label\"] = data[\"label\"].apply(lambda label: labels.index(label))","96707919":"data.head()","94a51043":"sentences = list(data.iloc[np.random.choice(data.shape[0], 10)][\"review\"])\nprint(sentences)","54f9f9de":"vectorizer(sentences)","434ac0c4":"train, test = train_test_split(data, shuffle=True, test_size=config.validation_split, random_state=42)\ntrain.shape, test.shape","38afd024":"train_ds = tf.data.Dataset.from_tensor_slices((train[\"review\"], train[\"label\"])).batch(config.batch_size)\ntrain_ds = train_ds.shuffle(256).take(train.shape[0] \/\/ config.batch_size).cache().repeat(1).prefetch(16)","77ee2e58":"test_ds = tf.data.Dataset.from_tensor_slices((test[\"review\"], test[\"label\"])).batch(config.batch_size)\ntest_ds = test_ds.take(test.shape[0] \/\/ config.batch_size).cache().repeat(1).prefetch(16)","5fbc4659":"for x, y in train_ds.take(1):\n    print(x.shape, y.shape)\n    print(x[:10])\n    print(y[:10])","78fcc0a1":"def get_model():\n    model = keras.Sequential([\n        layers.Input((None, ), dtype=\"string\"),\n        vectorizer,\n        layers.Embedding(config.vocab_size, config.embed_dim, mask_zero=True),\n        layers.Bidirectional(layers.LSTM(32, return_sequences=True)),\n        layers.LSTM(32),\n        layers.GaussianDropout(0.5),\n        layers.Dense(config.num_classes, activation=\"softmax\")\n    ])\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model","9ddf8095":"model = get_model()","dfd15437":"model.summary()","812562f1":"keras.utils.plot_model(model, show_shapes=True)","adf0c682":"checkpoint = keras.callbacks.ModelCheckpoint(config.model_path, save_best_only=True, save_weights_only=True)\nhistory = model.fit(train_ds, epochs=config.epochs, validation_data=test_ds, callbacks=[checkpoint])\nmodel.load_weights(config.model_path)","ab24cf01":"pd.DataFrame(history.history).plot()","df6f659a":"y_pred = model.predict(test_ds)\ny_pred = np.argmax(y_pred, axis=-1)\ny_pred.shape","8e0b1848":"cm = metrics.confusion_matrix(test[\"label\"][:y_pred.shape[0]], y_pred)\nsns.heatmap(cm, annot=True, cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.show()","86bf124c":"cls_report = metrics.classification_report(test[\"label\"][:y_pred.shape[0]], y_pred)\nprint(cls_report)","6fc4304b":"sentences = test.iloc[np.random.choice(test.shape[0], 30)][\"review\"]\nresults = config.label_display_names[np.argmax(model.predict(sentences), axis=-1)]","edc13f67":"for sentence, result in zip(sentences, results):\n    print(\"%s: %s\"%(sentence, result))","ef63c026":"## Conclusion\nThis Model can achieve 85% validation accuracy, there's still a lot to improve. For example, finding a better preprocessing technique, better hyperparameters.","14d75684":"## Model Training","69aaa913":"## Make Predictions","be2e663a":"## Loading data","2aad9a5a":"## Model Development","0e494cb9":"## Model Evaluation","4f39f8fc":"### Convert labels to numerical values","5c329fab":"Most reviews are neutral. The amount of positive reviews and negative reviews are close. I will only predict negative and positive labels for simplicity, so I will only choose these two kinds of labels.","f77b6bb9":"### Loss & Accuracy over time","14e4270c":"## Setup","3dac834f":"### Train test split","ed69bf4e":"### Classification Report","fcac25f8":"### Build a TextVectorization layer","49aee006":"### Visualize the architecture","7a092e04":"# IMDB Reviews Classification: Bidirectional-LSTM","7c8aa39d":"### Confusion Matrix","f4a6692c":"## Overview\nIn this notebook I will:\n* Build a IMDB Reviews Classifier with Bidirectional-LSTM Model.\n* Use [TextVectorization](https:\/\/keras.io\/api\/layers\/preprocessing_layers\/text\/text_vectorization\/) Layer to do text preprocessing easily.\n* Repalce common Dropout layer with [GaussianDropout](https:\/\/keras.io\/api\/layers\/regularization_layers\/gaussian_dropout\/). ","a74fec86":"Choose a few samples to understand inputs and outputs of this layer.","74ca4b8c":"## Table of Contents\n* Overview\n* Setup\n* Loading data\n* Model Development\n* Model Evaluation\n* Save the Model\n* Conclusion"}}