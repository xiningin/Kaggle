{"cell_type":{"e1426996":"code","91f83b8d":"code","226a866f":"code","10ac78cb":"code","46cf4b2c":"code","88d7dc2d":"code","6aff1ccf":"code","69a1ff37":"code","7ac3a35a":"code","9f58bd38":"code","2e012eb3":"code","df34f52f":"code","40e4bd95":"code","4789aa8f":"code","081c9d93":"code","f5a6f2b6":"markdown","089c523a":"markdown","4b1c7ae8":"markdown","6366172d":"markdown","04f8d4ce":"markdown","3bc14c67":"markdown","abc2a36f":"markdown","fa7ed79b":"markdown","4cdf0b11":"markdown","3f52e2bc":"markdown","a251d9b1":"markdown","bb217be7":"markdown","50922c88":"markdown","12b8cded":"markdown","707e5805":"markdown","3f9b58bb":"markdown","a39a3fda":"markdown","1c81218b":"markdown","f23f2886":"markdown","d9bae401":"markdown","a753ed1a":"markdown"},"source":{"e1426996":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra,math functions\nimport tensorflow as tf # tensorflow\nimport random # for seed value\nimport os # for folder functions\nimport string # for making alphabet labels as string\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns # data visualization\nfor dirname, _, filenames in os.walk('\/kaggle\/input'): # default\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","91f83b8d":"seed=42\nos.environ['PYTHONHASHSEED']=str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\n# We are using random seeds for controlling randomness.","226a866f":"train_data=pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv\")\ntest_data=pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv\")\nprint(\"Shape of train_data: \",train_data.shape,\"Shape of test_data: \",test_data.shape)","10ac78cb":"strlabels=list(string.ascii_uppercase) # Appending alphabet to a list.\nstrlabels.remove(\"J\") # Removing J letter because of the hand gesture problem.\nprint(strlabels) # Making a new list that contains letters for each indices.","46cf4b2c":"train_labels=train_data[\"label\"]\ntrain_images=train_data.drop(\"label\",axis=1).values # Dropping labels axis=1 > all column (axis=0 is all row)\ntest_labels=test_data[\"label\"]\ntest_images=test_data.drop(\"label\",axis=1).values # Dropping Labels axis=1 > all column (axis=0 is all row)\n                                               \ntrain_images=train_images\/255.0 # We are scaling our pixels between 0 and 1 for the sake of computing performance.\ntest_images=test_images\/255.0\n\ntrain_images=train_images.reshape(-1,28,28,1) # Reshaping for making images ready to go.\ntest_images=test_images.reshape(-1,28,28,1)\nprint(train_images.shape) # We have 27.455 images as 28x28x1 (2D Image with one channel)","88d7dc2d":"plt.figure() # Matplotlib for visualization.\nplt.tight_layout() # Wide space for images.\nfig,ax=plt.subplots(2,1) # Making space for 2 rows and 4 images for each row.\nsns.set(rc={'figure.figsize':(15,5)}) # Size of images.\nsns.countplot(train_labels,ax=ax[0])\nax[0].set(ylabel=\"Train Images\", xlabel = \"Train Labels\") # Setting labels.\nsns.countplot(test_labels,ax=ax[1])\nax[1].set(ylabel=\"Test Images\", xlabel = \"Test Labels\") # Setting labels.\nfig.show()","6aff1ccf":"plt.figure() # Matplotlib for visualization.\nf, graph = plt.subplots(2,4) # Making space for 2 rows and 4 images for each row.\nf.set_size_inches(14, 5) # Size of images.\nz=0\nfor i in range(2): # i for rows\n    for k in range(4): # k for columns\n        graph[i][k].imshow(train_images[z].reshape(28,28),cmap=\"gray\") # Showing each train image.\n        graph[i][k].grid(False) # Removing grids for each train image.\n        z+=1\nplt.tight_layout() # Wide space for images.\nplt.show()","69a1ff37":"generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ngenerator.fit(train_images)\n# We use ImageDataGenerator for changing images randomly and train our model better.","7ac3a35a":"acc_treshold = 1.0 # Accuracy treshold.\nclass myCallback(tf.keras.callbacks.Callback):\n    epc=0\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('acc') >= acc_treshold-0.005 and logs.get('val_acc') >= acc_treshold):\n            print(\"\\nReached %2.2f%% accuracy !\" %(logs.get('val_acc')*100)) # Printing accuracy as percentage.\n            self.model.stop_training = True\n            self.epc=epoch+1\ncallbacks = myCallback()\n# We are using callbacks because we want to shut our training process down when it learns 100%.","9f58bd38":"model=tf.keras.Sequential([ # Using tf.keras for build our sequential.\n    tf.keras.layers.Conv2D(64,(3,3),padding=\"same\",activation=\"relu\",input_shape=(28,28,1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D((2,2),strides=2),\n    \n    tf.keras.layers.Dropout(0.2), # Dropping random 2% data out for learning variety.\n    \n    tf.keras.layers.Conv2D(32,(3,3),padding=\"same\",activation=\"relu\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D((2,2),strides=2),\n    \n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(16,(3,3),padding=\"same\",activation=\"relu\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D((2,2)),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(25,activation=\"softmax\")\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),loss=\"sparse_categorical_crossentropy\",metrics=[\"acc\"])\nmodel.summary() # Summary of our model.\nepochs=80\nhistory=model.fit(generator.flow(train_images,train_labels,batch_size=128),epochs=epochs,callbacks=[callbacks],validation_data=(test_images,test_labels),verbose=1)\n# generator.flow() for applying data augmentation.\ntest_loss,test_acc=model.evaluate(test_images,test_labels)\nprint(\"test acc:\",test_acc)","2e012eb3":"prediction=model.predict(test_images) # Making predictions of test images with our model.","df34f52f":"epoch_range=range(1,callbacks.epc+1 if callbacks.epc != 0 else epochs) # Epoch range for plotting our x-axis.\nplt.figure() # Matplotlib for visualization.\nf, ax = plt.subplots(1,2) # Making space for 2 rows and 4 images for each row.\nfig.set_size_inches(30, 5) # Size of images.\nplt.tight_layout() # Wide space for images.\nax[0].plot(epoch_range,history.history[\"acc\"],color=\"blue\",marker=\"o\")\nax[0].plot(epoch_range,history.history[\"val_acc\"],color=\"orange\",marker=\"o\")\nax[0].legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\nax[1].plot(epoch_range,np.array(history.history[\"loss\"]),color=\"blue\",marker=\"o\")\nax[1].plot(epoch_range,np.array(history.history[\"val_loss\"]),color=\"orange\",marker=\"o\")\nax[1].legend(['Training Loss', 'Validation Loss'], loc='upper right')\nplt.show()","40e4bd95":"predictions=[]\ntest_labels_string=[]\nfor i in range(0,test_labels.size):\n    predictions.append(strlabels[np.argmax(prediction[i])]) # np.argmax() for taking highest value among the others.\n    test_labels_string.append(strlabels[test_labels[i]])\n# Converting predictions to letters.","4789aa8f":"from sklearn.metrics import confusion_matrix # Sklearn for making confusion matrix.\nfrom mlxtend.plotting import plot_confusion_matrix # Mlxtend for plotting confusion matrix.\ncf=confusion_matrix(predictions,test_labels_string)\nfig, ax = plot_confusion_matrix(conf_mat=cf)\nfig.set_size_inches(15, 15) # Size of image.\nplt.tight_layout() # Wide space for image.\nplt.show()","081c9d93":"n=1\nplt.imshow(test_images[n].reshape(28,28),cmap=\"gray\") # Showing images\nplt.grid(False) # Removing grid for each image.\nprint(\"Predicted letter is:\",predictions[n],\"\\nTrue Answer:\",test_labels_string[n]) # Prediction - True Answer","f5a6f2b6":"## Building CNN Model<a class=\"anchor\" id=\"cnn\"><\/a>","089c523a":"![image](https:\/\/miro.medium.com\/max\/696\/0*vmgQDtKZthpE9Fel)","4b1c7ae8":"<hr>","6366172d":"# Importing Libraries and Tensorflow<a class=\"anchor\" id=\"importing\"><\/a>","04f8d4ce":"## Callbacks<a class=\"anchor\" id=\"callbacks\"><\/a>","3bc14c67":"# Description About Notebook<a class=\"anchor\" id=\"description\"><\/a>","abc2a36f":"## Data Augmentation<a class=\"anchor\" id=\"augmentation\"><\/a>","fa7ed79b":"## First 8 Samples<a class=\"anchor\" id=\"firsteight\"><\/a>","4cdf0b11":"# Table of Contents\n1. [Description About Notebook](#description)\n2. [Importing Libraries and Tensorflow](#importing)\n3. [Data Preprocessing](#preprocess)\n    - [Countplot of Labels](#countplot)\n    - [First Eight Samples](#firsteight)\n4. [Building Model](#model)\n    - [Data Augmentation](#augmentation)\n    - [Callbacks](#callbacks)\n    - [Building CNN Model](#cnn)\n    - [Plot of Progress](#progress)\n    - [Confusion Matrix for Checking Results](#confusion)\n5. [Testing](#testing)   ","3f52e2bc":"# Building Model<a class=\"anchor\" id=\"model\"><\/a>","a251d9b1":"## Plot of Progress<a class=\"anchor\" id=\"progress\"><\/a>","bb217be7":"<hr>","50922c88":"## Countplot of Labels<a class=\"anchor\" id=\"countplot\"><\/a>","12b8cded":"# Building CNN Algorithm on American Sign Language Dataset","707e5805":"# Testing<a class=\"anchor\" id=\"testing\"><\/a>","3f9b58bb":"## Confusion Matrix for Checking Results<a class=\"anchor\" id=\"confusion\"><\/a>","a39a3fda":"<hr>","1c81218b":"\n\nAs we know, there are many health issues that affect human interaction, and deafness is one of them. We are getting more solutions while Artificial Intelligence concept is progressing. In this notebook, we are going to build a Deep Learning model by using CNN Algorithm as being a part of the process of solving communication problems that deafness causes.\n\n### Note 1: This dataset has 25 labels instead of 26 because 'J' and 'Z' letters are need to hand gestures for understanding but maker of the dataset may have thought that the 'Z' letter has a specific looking and can be stored, because of that we still have 'Z' letter and the other letters except 'J'.\n\n#### Note 2: This dataset has incorrect labeling for a few labels, it rarely gives wrong answers for image but we can see it is correct when we compare how it labeled below.","f23f2886":"<hr>","d9bae401":"<hr>","a753ed1a":"# Data Preprocessing<a class=\"anchor\" id=\"preprocess\"><\/a>"}}