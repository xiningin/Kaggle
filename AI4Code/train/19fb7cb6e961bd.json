{"cell_type":{"f601ff40":"code","18d51af4":"code","6a0c6409":"code","d3433682":"code","9aaa810b":"code","63066e0a":"code","ad7e8296":"code","41fdd122":"code","6c3bdb24":"code","5e7ad0f0":"code","d12827ac":"code","e57d9f7c":"code","def32caa":"code","997f2c2e":"code","326ec6b3":"code","bfe30bb3":"code","b9f8ca60":"code","30d255ef":"code","16f1f1aa":"code","4186342a":"code","aade3a34":"code","9427c2fe":"code","c26bcb36":"code","466812c3":"code","9d368cc4":"code","81917fab":"code","243cf268":"code","ef6f9558":"code","bf50362e":"code","a259044e":"markdown","14156a44":"markdown","b573c4a1":"markdown","32a22fcf":"markdown","c792365d":"markdown","77b72061":"markdown","d3841679":"markdown","2946f979":"markdown","87dbab7a":"markdown","2c87c398":"markdown","7d74b711":"markdown","075f7907":"markdown","7d12108c":"markdown","b9da556e":"markdown","dba7330a":"markdown","78957c46":"markdown","49b079c2":"markdown","ed53c1e4":"markdown","3e2f5fc7":"markdown","40789a04":"markdown","d7717bfc":"markdown","d612306a":"markdown","60b79922":"markdown"},"source":{"f601ff40":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","18d51af4":"data=pd.read_csv(\"..\/input\/retail-analysis-with-walmart-data\/Walmart_Store_sales.csv\")\ndata.head() #Fetches default first 5 rows","6a0c6409":"#basic Functions\ndata.isnull().sum() #Null value check","d3433682":"data.shape","9aaa810b":"data.describe()","63066e0a":"data.info()","ad7e8296":"max_sales = data.groupby('Store')['Weekly_Sales'].sum()\nmax_sales.idxmax()","41fdd122":"#plotting the max sales in the Bar chart\nplt.figure(figsize=(15,5))\nsns.barplot(x=data.Store, y = data.Weekly_Sales)","6c3bdb24":"# maximum Standard deviation\nmax_std = data.groupby('Store')['Weekly_Sales'].std()\nmax_std.idxmax()","5e7ad0f0":"# maximum coefficient of variation\nmax_cov = ((data.groupby('Store')['Weekly_Sales'].std())\/(data.groupby('Store')['Weekly_Sales'].mean()))*100\nmax_cov.idxmax()","d12827ac":"#plotting the max sales in the Bar chart\nstores = data.groupby('Store')\nstore_35 = stores.get_group(35)\nplt.figure(figsize=(10,5))\nsns.distplot(store_35.Weekly_Sales, color='green', label='Weekly Sales for Store 35')","e57d9f7c":"# Identify Outliers in weekly_sales for store 35\nsns.boxplot(store_35.Weekly_Sales, color='cyan') #less outliers","def32caa":"# Grouping data by year and month\ngrowth = data.copy()\ngrowth['Date'] = pd.to_datetime(growth.Date,format='%d-%m-%Y')\ngrowth['Year'] = growth['Date'].dt.year\ngrowth['Month'] = growth['Date'].dt.month\ngrowth","997f2c2e":"# Group data with year = 2012\ngrowth_rate = growth.groupby('Year')\ngrowth_rate_2012 = growth_rate.get_group(2012)\ngrowth_rate_2012.head()","326ec6b3":"# Getting data for 4 quaters for year 2012\n\ngrowth_rate_2012_Quaters = growth_rate_2012.groupby('Month')\ngrowth_rate_2012_Q1_1 = growth_rate_2012_Quaters.get_group(1)\ngrowth_rate_2012_Q1_2 = growth_rate_2012_Quaters.get_group(2)\ngrowth_rate_2012_Q1_3 = growth_rate_2012_Quaters.get_group(3)\n\nQuater_1 = growth_rate_2012_Q1_1.append(growth_rate_2012_Q1_2)\nQuater_1 = Quater_1.append(growth_rate_2012_Q1_3) #Q1 data of 2012\ndisplay(Quater_1.head())  \n\ngrowth_rate_2012_Q2_4 = growth_rate_2012_Quaters.get_group(4)\ngrowth_rate_2012_Q2_5 = growth_rate_2012_Quaters.get_group(5)\ngrowth_rate_2012_Q2_6 = growth_rate_2012_Quaters.get_group(6)\n\nQuater_2 = growth_rate_2012_Q2_4.append(growth_rate_2012_Q2_5)\nQuater_2 = Quater_2.append(growth_rate_2012_Q2_6)  #Q2 data of 2012\ndisplay(Quater_2.head())\n\ngrowth_rate_2012_Q3_7 = growth_rate_2012_Quaters.get_group(7)\ngrowth_rate_2012_Q3_8 = growth_rate_2012_Quaters.get_group(8)\ngrowth_rate_2012_Q3_9 = growth_rate_2012_Quaters.get_group(9)\nQuater_3 = growth_rate_2012_Q3_7.append(growth_rate_2012_Q3_8)\nQuater_3 = Quater_3.append(growth_rate_2012_Q3_9)  #Q3 data of 2012\ndisplay(Quater_3.head())\n\n# Q4 data of 2012\ngrowth_rate_2012_Q4_10 = growth_rate_2012_Quaters.get_group(10)\nQuater_4 = growth_rate_2012_Q4_10\ndisplay(Quater_4.head())","bfe30bb3":"# Grouping the data \"Store\" wise each Quarter\n\ndf2 = pd.DataFrame(Quater_1.groupby('Store')['Weekly_Sales'].sum())\n\ndf2[\"Quater1_Sales\"] = pd.DataFrame(Quater_1.groupby('Store')['Weekly_Sales'].sum())\ndf2[\"Quater2_Sales\"] = pd.DataFrame(Quater_2.groupby('Store')['Weekly_Sales'].sum())\ndf2[\"Quater3_Sales\"] = pd.DataFrame(Quater_3.groupby('Store')['Weekly_Sales'].sum())\ndf2[\"Quater4_Sales\"] = pd.DataFrame(Quater_4.groupby('Store')['Weekly_Sales'].sum())\ndf2.drop('Weekly_Sales', axis = 1, inplace = True)\ndf2","b9f8ca60":"# Growth rate formula- ((Present value \u2014 Past value )\/Past value )*100\n\ndf2['Q3 - Q2'] = df2['Quater3_Sales'] - df2['Quater2_Sales']\ndf2['Overall Growth Rate in 2012 Q3 %'] = (df2['Q3 - Q2']\/df2['Quater2_Sales'])*100\n\ndf2['Overall Growth Rate in 2012 Q3 %'].idxmax() # Store which has good growth in Q3-2012","30d255ef":"# Plotting the data in Bar chart\nplt.figure(figsize=(15,5))\nsns.barplot(x=df2.index, y = 'Overall Growth Rate in 2012 Q3 %', data = df2)","16f1f1aa":"#finding the mean sales of non holiday and holiday \ndata.groupby('Holiday_Flag')['Weekly_Sales'].mean()","4186342a":"# Marking the holiday dates \ndata['Date'] = pd.to_datetime(data['Date'])\n\nChristmas1 = pd.Timestamp(2010,12,31)\nChristmas2 = pd.Timestamp(2011,12,30)\nChristmas3 = pd.Timestamp(2012,12,28)\nChristmas4 = pd.Timestamp(2013,12,27)\n\nThanksgiving1=pd.Timestamp(2010,11,26)\nThanksgiving2=pd.Timestamp(2011,11,25)\nThanksgiving3=pd.Timestamp(2012,11,23)\nThanksgiving4=pd.Timestamp(2013,11,29)\n\nLabourDay1=pd.Timestamp(2010,9,10)\nLabourDay2=pd.Timestamp(2011,9,9)\nLabourDay3=pd.Timestamp(2012,9,7)\nLabourDay4=pd.Timestamp(2013,9,6)\n\nSuperBowl1=pd.Timestamp(2010,2,12)\nSuperBowl2=pd.Timestamp(2011,2,11)\nSuperBowl3=pd.Timestamp(2012,2,10)\nSuperBowl4=pd.Timestamp(2013,2,8)\n\n#Calculating the mean sales during the holidays\nChristmas_mean_sales=data[(data['Date'] == Christmas1) | (data['Date'] == Christmas2) | (data['Date'] == Christmas3) | (data['Date'] == Christmas4)]\nThanksgiving_mean_sales=data[(data['Date'] == Thanksgiving1) | (data['Date'] == Thanksgiving2) | (data['Date'] == Thanksgiving3) | (data['Date'] == Thanksgiving4)]\nLabourDay_mean_sales=data[(data['Date'] == LabourDay1) | (data['Date'] == LabourDay2) | (data['Date'] == LabourDay3) | (data['Date'] == LabourDay4)]\nSuperBowl_mean_sales=data[(data['Date'] == SuperBowl1) | (data['Date'] == SuperBowl2) | (data['Date'] == SuperBowl3) | (data['Date'] == SuperBowl4)]\nChristmas_mean_sales\n\nlist_of_mean_sales = {'Christmas_mean_sales' : round(Christmas_mean_sales['Weekly_Sales'].mean(),2),\n'Thanksgiving_mean_sales': round(Thanksgiving_mean_sales['Weekly_Sales'].mean(),2),\n'LabourDay_mean_sales' : round(LabourDay_mean_sales['Weekly_Sales'].mean(),2),\n'SuperBowl_mean_sales':round(SuperBowl_mean_sales['Weekly_Sales'].mean(),2),\n'Non holiday weekly sales' : round(data[data['Holiday_Flag'] == 0 ]['Weekly_Sales'].mean(),2)}\nlist_of_mean_sales\n","aade3a34":"#Monthly sales \nmonthly = data.groupby(pd.Grouper(key='Date', freq='1M')).sum() # groupby each 1 month\nmonthly=monthly.reset_index()\nfig, ax = plt.subplots(figsize=(10,5))\nX = monthly['Date']\nY = monthly['Weekly_Sales']\nplt.plot(X,Y)\nplt.title('Month Wise Sales')\nplt.xlabel('Monthly')\nplt.ylabel('Weekly_Sales')\n\n# Analysis- highest sum of sales is recorded in between jan-2011 to march-2011.","9427c2fe":"#Semester Sales \nSemester = data.groupby(pd.Grouper(key='Date', freq='6M')).sum()\nSemester = Semester.reset_index()\nfig, ax = plt.subplots(figsize=(10,5))\nX = Semester['Date']\nY = Semester['Weekly_Sales']\nplt.plot(X,Y)\nplt.title('Semester Wise Sales')\nplt.xlabel('Semester')\nplt.ylabel('Weekly_Sales')\n\n# ANalysis- sales are lowest in beginning of 1st sem of 2010 and 1st sem of 2013","c26bcb36":"hypothesis = growth.groupby('Store')[['Fuel_Price','Unemployment', 'CPI','Weekly_Sales', 'Holiday_Flag']]\nfactors  = hypothesis.get_group(1) #Filter by Store 1\nday_arr = [1]\nfor i in range (1,len(factors)):\n    day_arr.append(i*7)\n    \nfactors['Day'] = day_arr.copy()\nfactors","466812c3":"sns.heatmap(factors.corr(), annot = True)","9d368cc4":"sns.lmplot(x='Fuel_Price', y = 'Unemployment', data = factors)\n#plt.figure()\nsns.lmplot(x='CPI', y = 'Unemployment', data = factors)","81917fab":"from scipy import stats\nttest,pval = stats.ttest_rel(factors['Weekly_Sales'],factors['CPI'])\nsns.distplot(factors.CPI)\nplt.figure()\nprint(pval)\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n    \nsns.scatterplot(x='CPI', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lmplot(x='CPI', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lineplot(x='CPI', y = 'Weekly_Sales', data = factors)","243cf268":"from scipy import stats\nttest,pval = stats.ttest_rel(factors['Weekly_Sales'],factors['Fuel_Price'])\nsns.distplot(factors.Fuel_Price)\nplt.figure()\nprint(pval)\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n    \nsns.scatterplot(x='Fuel_Price', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lmplot(x='Fuel_Price', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lineplot(x='Fuel_Price', y = 'Weekly_Sales', data = factors)","ef6f9558":"from scipy import stats\nttest,pval = stats.ttest_rel(factors['Weekly_Sales'],factors['Unemployment'])\nsns.distplot(factors.Unemployment)\nplt.figure()\nprint(pval)\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n    \nsns.scatterplot(x='Unemployment', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lmplot(x='Unemployment', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lineplot(x='Unemployment', y = 'Weekly_Sales', data = factors)","bf50362e":"plt.figure(figsize=(10,5))\nsns.barplot(x='Day', y = 'Weekly_Sales', data = factors.head(50), hue = 'Holiday_Flag')","a259044e":"### Hypothesis Testing - CPI","14156a44":"1) Earlier, we rejected the null hypothesis saying that ther is no relationship between Weekly_sales and CPI. But we found there is a positive corrlation between CPI and Weekly_sales as shown in the above graphs.\n\n2) The CPI is not normally distributed and line regression plot is showing how CPI is varying with Weekly_Sales on days of Holidays and non holiday weeks.","b573c4a1":"### Plotting the Weekly_sales for store 1 (Day wise)","32a22fcf":"Store 20 has maximum Sales","c792365d":"## Thank you!!","77b72061":"Store 7 has good growth in Q3-2012","d3841679":"### Hypothesis Testing - Uneployment","2946f979":"As the Fuel_price and Cpi goes high, rate of Unemployment Fairly Decreases (shown above in Line Regression plot).","87dbab7a":"We can see as the rate of unemployment increases, people only buy during holiday seasons, as there are only few outliers present for weekly_sales and which are on the day of Holiday. Speaking of which people only buy necessary products and try to save more. Hence rejecting the null hypothesis was appropriate.","2c87c398":"### 5. Provide a monthly and semester view of sales in units and give insights","7d74b711":"### 3. Which store\/s has good quarterly growth rate in Q3\u20192012 ?","075f7907":"We can infer during the days of holidays, there is comparatively more sales for store1.","7d12108c":"### 4. Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together.","b9da556e":"Store 14 has maximum standard deviation and store 35 has maximum Coefficient of Variance.","dba7330a":"\"Thanksgiving Day\" has much high sale than mean sales in Non-Holiday season.","78957c46":"#### Analysis- It is rightly skewed graph which is giving the intutions that sales are centred around 800000 for weekly sales for store 35.","49b079c2":"##### Please upvote if you like this kernel representation!","ed53c1e4":"Few variables which are positive and have value greater than zero are correlated with Weekly_Sales. We can also see CPI and Holiday_Flag is fairly strongly correlated to Weekly_Sales. Holiday_Flag = 1 means it's holiday_week we have sales more than the non_holiday_weeks.","3e2f5fc7":"There are more number of Sales when the Fuel_Price are higher and also we can see more Sales during Holiday_Weeks when fuel_prices were fairly low. So its not clear to say on what factors Fuel_price has a direct dependency on Sales.","40789a04":"### 2. Which store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation.","d7717bfc":"###  For Store 1 \u2013 Build  prediction models to forecast demand\n\nLinear Regression \u2013 Utilize variables like date and restructure dates as 1 for 5 Feb 2010 (starting from the earliest date in order). Hypothesize if CPI, unemployment, and fuel price have any impact on sales.","d612306a":"### 1. Which store has maximum sales ?","60b79922":"### Hypothesis Testing - Fuel_Price"}}