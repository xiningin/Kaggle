{"cell_type":{"fae1e58c":"code","66b6e6c8":"code","945aef1f":"code","7c3a246b":"code","fb59620e":"code","f849f5c4":"code","b5ab6248":"code","9bf29710":"code","93441905":"code","79777e7d":"code","581477b0":"code","bf289e2e":"code","fee40795":"code","b7bb9935":"code","2b8020b8":"code","40c8c39e":"code","63135d55":"markdown","5be3ab3e":"markdown"},"source":{"fae1e58c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","66b6e6c8":"train_data = pd.read_csv('..\/input\/sign_mnist_train.csv') \ntrain_data.head()","945aef1f":"test_data = pd.read_csv('..\/input\/sign_mnist_test.csv') \ntest_data.head()","7c3a246b":"X_train = train_data.drop(columns='label').values\ny_train = train_data['label'].values","fb59620e":"X_test = test_data.drop(columns='label').values\ny_test = test_data['label'].values","f849f5c4":"X_train = X_train.reshape(len(X_train),28,28,1)\nX_test = X_test.reshape(len(X_test),28,28,1)","b5ab6248":"# data normalization\n\nX_train = X_train \/ 255.\nX_test = X_test \/ 255.","9bf29710":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.imshow(X_train[0].reshape(28,28))","93441905":"from tensorflow import keras\nfrom keras.utils import to_categorical","79777e7d":"# one-hot encode target column\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","581477b0":"# define some callbacks\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nclass my_max_acc_callback(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('acc')>0.99):\n      print(\"\\nReached 99% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\n# my max accuracy callback\nmy_mxaccb = my_max_acc_callback()\n\n# checkpoint for best weights\nfilepath='model-best-weights.hdf5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n\n# early stopping\nearlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', restore_best_weights=True)\n\n# reducing_Learning_Rate\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='auto')\n\n#collecting all callbacks\ncallbacks_list = [my_mxaccb, checkpoint, earlyStopping, reduce_lr_loss]","bf289e2e":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n\n# create model\nmodel = Sequential()\n\n#add model layers\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(2,2))\n#\nmodel.add(Conv2D(64, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n#\nmodel.add(Dense(256,activation='relu'))\n#\nmodel.add(Conv2D(64, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n#\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\n#\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(25, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(\n    loss = 'categorical_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy'])","fee40795":"history = model.fit(\n    X_train, \n    y_train,\n    validation_split=0.3,\n    epochs=50,\n    verbose=1,\n    callbacks=callbacks_list)","b7bb9935":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'ro-', label='Training accuracy')\nplt.plot(epochs, val_acc, 'bo-', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()","2b8020b8":"plt.plot(epochs, loss, 'go-', label='Training loss')\nplt.plot(epochs, val_loss, 'yo-', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend(loc=0)\nplt.figure()","40c8c39e":"# testing model on test set\ntest_loss = model.evaluate(X_test, y_test)\nprint(model.metrics_names)\nprint(test_loss)","63135d55":"### Creating data-sets","5be3ab3e":"### Loading data from workspace"}}