{"cell_type":{"63331284":"code","cea95ee7":"code","b38ef0c9":"code","c340374c":"code","923fa53f":"code","80259106":"code","af9b0077":"markdown"},"source":{"63331284":"!pip install textstat","cea95ee7":"import pandas as pd\nimport textstat","b38ef0c9":"file_path = \"..\/input\/commonlitreadabilityprize\/\"\ntrain_df = pd.read_csv(file_path+\"train.csv\")\ntrain_df = train_df[['id', 'excerpt', 'target']]\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)","c340374c":"def text_features(excerpt):\n    feat = excerpt.map(lambda x: {\n        \"flesch_reading_ease\": textstat.flesch_reading_ease(x),\n        \"smog_index\": textstat.smog_index(x),\n        \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade(x),\n        \"coleman_liau_index\": textstat.coleman_liau_index(x),\n        \"automated_readability_index\": textstat.automated_readability_index(x),\n        \"dale_chall_readability_score\": textstat.dale_chall_readability_score(x),\n        \"difficult_words\": textstat.difficult_words(x),\n        \"linsear_write_formula\": textstat.linsear_write_formula(x),\n        \"gunning_fog\": textstat.gunning_fog(x),\n#        textstat.text_standard(excerpt)\n    })\n    return pd.DataFrame([pd.Series(x) for x in pd.DataFrame(feat).iloc[:,0]])\n\ndef include_text_features(df):\n    return pd.concat([df, text_features(df.excerpt)], axis=1)","923fa53f":"augmented_df = include_text_features(train_df)\naugmented_df","80259106":"augmented_df.to_csv(\"augmented_df.csv\")","af9b0077":"# What & why\n\nThis notebook provides a function that adds a number of text features to all of the CommonLit Readability challenge dataset.\n\nDepending on your model, it might be worth trying out including those features. Although they are comparatively rough in contrast to more sophisticated methods such as transformer-based models, some of these metrics are correlated with excerpt complexity. In addition, adding a model based on them to your prediction ensemble might improve performance.\n\n# How\n\nThis function is based on the package `textstat`. It provides a very easy-to-use API to extract a number of features from texts. For more details on these metrics, please refer to their documentation at https:\/\/textstat.readthedocs.io\/en\/latest\/.\n\n# How to use\n\nYou can either: \n1) import the dataset into your inference notebook; or\n2) use the function `include_text_features` in your dataset. \n\nIf you choose (1), please consider using a good validation scheme. If you choose (2), pass the function separately to your training, validation and test datasets could also help with performance.\n\nAlso, if you pass the values to a neural network, consider subtracting the batch mean and dividing by the batch standard deviation, since neural networks prefer working on normalised data.\n\n# Ok, that's it...\n\nGood luck in the competition, and leave your comment below with feedback and with your impressions from using these features!\n\n# Code"}}