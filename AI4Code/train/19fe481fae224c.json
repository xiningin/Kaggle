{"cell_type":{"90e92ed4":"code","e11102f8":"code","a67e0e58":"code","a52bcd57":"code","3e1bd4be":"code","04c23150":"code","1fe5978f":"code","26a96627":"code","c8cc51ea":"code","5a25230c":"code","a56baba3":"code","1ee229e8":"code","c6ae1164":"markdown","1b1af1d5":"markdown","ecbf38fc":"markdown","e687e677":"markdown","d740b6e0":"markdown","ac4b781c":"markdown","092a63ae":"markdown","42b9aced":"markdown"},"source":{"90e92ed4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport math\nimport random\nfrom sklearn.metrics import confusion_matrix\nfrom tqdm import tqdm_notebook","e11102f8":"dataset = pd.read_csv(\"..\/input\/contest1likeordislike\/train.csv\")\nfeatures = [\"Brand\", \"Capacity\", \"Network Support\", \"Operating System\", \"Screen Size\", \"Internal Memory\", \"RAM\", \"VoLTE\"]     # 8 features selected\nX_train = dataset[features]\ny_train = dataset[[\"Rating\"]]\nX_test = pd.read_csv(\"..\/input\/contest1likeordislike\/test.csv\")[features]\ntotal_dataset = pd.concat([X_train, X_test], ignore_index=True)","a67e0e58":"#############################\n# Filling out the missing values\n#############################\n# Remove columns containing nan in Brand\nX_train.isnull().sum()\nX_test.isnull().sum()\ntotal_dataset = total_dataset.drop(5)\n\n# Filling missing values in Operating System\ntotal_dataset.isnull().sum()\ntotal_dataset[\"Operating System\"] = total_dataset[\"Operating System\"].fillna(\"Android v8.1 (Oreo)\")\n\n# Filling missing values in VoLTE\ntotal_dataset[\"VoLTE\"] = total_dataset[\"VoLTE\"].fillna(\"no\")\n\n#############################\n# Encoding the categorical data\n#############################\n# Encoding the brands\nlabelcoder = LabelEncoder()\ntotal_dataset[\"Brand\"] = labelcoder.fit_transform(total_dataset[\"Brand\"])\n\n# Encoding the Network Support\nlabelcoder2 = LabelEncoder()\ntotal_dataset[[\"Network Support\"]] = labelcoder2.fit_transform(total_dataset[[\"Network Support\"]])\n\n# Encoding the Operating System\nlabelcode3 = LabelEncoder()\ntotal_dataset[[\"Operating System\"]] = labelcode3.fit_transform(total_dataset[[\"Operating System\"]])\n\n# Getting the capacity values\ntotal_dataset[\"Capacity\"] = total_dataset[\"Capacity\"].str.rstrip(\" mAh\")\ntotal_dataset[\"Capacity\"] = total_dataset[\"Capacity\"].astype(int)\n\n# Getting the Screen Size value\nfor index, row in total_dataset.iterrows():\n    total_dataset.at[index, \"Screen Size\"] = row[\"Screen Size\"].split(\" \")[0]\ntotal_dataset[\"Screen Size\"] = total_dataset[\"Screen Size\"].astype(float)\n\n\n# Encoding VoLTE\nlabelcoder4 = LabelEncoder()\ntotal_dataset[[\"VoLTE\"]] = labelcoder4.fit_transform(total_dataset[[\"VoLTE\"]])\n\n# Getting the Internal Memory\ntotal_dataset[\"Internal Memory\"] = total_dataset[\"Internal Memory\"].fillna(\"Random\")\nfor index, row in total_dataset.iterrows():\n    if (row['Internal Memory'].split(\" \")[0] == \"Random\"):\n        total_dataset.at[index, 'Internal Memory'] = 0\n    else:\n        total_dataset.at[index, 'Internal Memory'] = row['Internal Memory'].split(\" \")[0]\ntotal_dataset['Internal Memory'] = total_dataset['Internal Memory'].astype(float)\ntotal_dataset['Internal Memory'] = total_dataset['Internal Memory'].replace(0, 32)\n\n# Getting the RAM\ntotal_dataset[\"RAM\"] = total_dataset[\"RAM\"].fillna(\"Random\")\nfor index, row in total_dataset.iterrows():\n    if (row['RAM'].split(\" \")[0] == \"Random\"):\n        total_dataset.at[index, 'RAM'] = float(0)\n    else:\n        if(row['RAM'].split(\" \")[1] == \"MB\"):\n            total_dataset.at[index, 'RAM'] = float(row['RAM'].split(\" \")[0])\/1024\n        else:\n            total_dataset.at[index, 'RAM'] = float(row['RAM'].split(\" \")[0])\ntotal_dataset[\"RAM\"] = total_dataset[\"RAM\"].astype(float)\ntotal_dataset['RAM'] = total_dataset['RAM'].replace(0, 4)\n\n#############################\n# Encoding the results\n#############################\n# Deleting row 5\ny_train = y_train.drop(5)\n\n# Encoding the rating\nfor index, row in y_train.iterrows():\n    if(row[\"Rating\"] >= 4):\n        y_train.at[index, \"Rating\"] = 1\n    else:\n        y_train.at[index, \"Rating\"] = 0\n        \n#############################\n# Splitting data back into train and test set\n#############################\nX_train = total_dataset.iloc[:354, :]\nX_test = total_dataset.iloc[354:, :]","a52bcd57":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nbias1 = np.ones((354, 1))\nX_train = np.append(bias1, X_train, axis=1)\nX_test = scaler.transform(X_test)\nbias2 = np.ones((119, 1))\nX_test = np.append(bias2, X_test, axis = 1)","3e1bd4be":"x_train, x_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.25, random_state =1, stratify = y_train)\nx_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size = 0.5, random_state = 1, stratify = y_test)\ny_train = y_train.to_numpy()\ny_val = y_val.to_numpy()\ny_test = y_test.to_numpy()","04c23150":"print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape, X_test.shape)","1fe5978f":"class NeuralNetwork:\n    def __init__(self, hidden1_size):\n        self.hidden1_size = hidden1_size\n        self.w1 = np.random.randn(hidden1_size, 9)\n        self.w2 = np.random.randn(1, hidden1_size+1)\n        self.a1 = np.ones(hidden1_size+1)\n        self.a2 = None\n    def Sigmoid(self, x):\n        s = 1 + math.exp(-x)\n        s = 1\/s\n        return s\n    def model(self, x):\n        for i in range(self.hidden1_size):\n            self.a1[i] = self.Sigmoid(np.dot(self.w1[i], x))\n        self.a2 = self.Sigmoid(np.dot(self.w2, self.a1))\n        return self.a2\n    def predict(self, X):\n        y = []\n        for x in X:\n            y_pred = 1 if self.model(x)>=0.5 else 0\n            y.append(y_pred)\n        return y\n    def Loss(self, y_pred, y):\n        loss = y*np.log(y_pred) + (1 - y)*np.log(1 - y_pred)\n        return loss\n    def fit(self, X, Y, epochs, lr, size):\n        loss_matrix = []\n        acc_matrix = []\n        acc_val_matrix = []\n        for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n            loss = 0\n            for x, y in zip(X, Y):\n                self.a2 = self.model(x)\n                y_hat = self.a2\n                loss = loss + self.Loss(y_hat, y)\n                for i in range(self.hidden1_size+1):\n                    self.w2[0, i] = self.w2[0, i] - lr*(y_hat - y)*self.a1[i]\n                for i in range(self.hidden1_size):\n                    for j in range(9):\n                        self.w1[i, j] = self.w1[i, j] - lr*(y_hat - y)*self.w2[0, i]*self.a1[i]*(1 - self.a1[i])*x[j]\n            loss_matrix.append(-loss[0]\/size)\n            acc = accuracy_score(self.predict(X), Y)\n            acc_val = accuracy_score(self.predict(x_val), y_val)\n            acc_matrix.append(acc)\n            acc_val_matrix.append(acc_val)\n        plt.plot(loss_matrix, 'r-')\n        plt.plot(acc_matrix, 'b-')\n        plt.plot(acc_val_matrix, 'g-')\n        print('Loss before training: ', loss_matrix[0])\n        print('Loss after training: ', loss_matrix[-1])\n        print('Accuracy before training: ', acc_matrix[0])\n        print('Accuracy after training: ', acc_matrix[-1])","26a96627":"fn = NeuralNetwork(10)","c8cc51ea":"ans = fn.fit(x_train, y_train, 500, 0.024, 283)","5a25230c":"print(\"Validation Set Accuracy : \"+str(accuracy_score(fn.predict(x_val), y_val)))","a56baba3":"print(\"Test Set Accuracy : \"+str(accuracy_score(fn.predict(x_test), y_test)))","1ee229e8":"submission = fn.predict(X_test)\nsubmission = pd.DataFrame(submission)\nphone_id = pd.read_csv(\"..\/input\/contest1likeordislike\/test.csv\")\nphone_id = phone_id[\"PhoneId\"]\nsubmission = pd.concat([phone_id, submission], axis = 1)\nsubmission.to_csv(\"submission3.csv\", header = [\"PhoneId\", \"Class\"], index = False)","c6ae1164":"Importing the dataset","1b1af1d5":"Splitting into Training, Validation and Testing sets","ecbf38fc":"Cleaning the dataset","e687e677":"Scaling of dataset elements","d740b6e0":"Importing the required liabraries","ac4b781c":"Validation Set Score","092a63ae":"Test Set Score","42b9aced":"Submission file creation"}}