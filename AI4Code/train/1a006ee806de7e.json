{"cell_type":{"adddd607":"code","8e18bb40":"code","1b9a7a39":"code","ab0d59cc":"code","6ff59c5b":"code","dae0c74a":"code","cacb3eb5":"code","5e3f1982":"markdown","f18572dc":"markdown","b428a211":"markdown","88f7ac55":"markdown","34ff1ff2":"markdown","b89652f6":"markdown"},"source":{"adddd607":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\n\"all set!\"","8e18bb40":"# Load the meta data\ntrain_data = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Test.csv')\n\n# Load the labels\ntrain_labels = train_data['ClassId']\ntest_labels = test_data['ClassId']\n\n# Load the images\ntrain_image_paths = train_data['Path'].apply(lambda x: '\/kaggle\/input\/gtsrb-german-traffic-sign\/' + x).tolist()\ntest_image_paths = test_data['Path'].apply(lambda x: '\/kaggle\/input\/gtsrb-german-traffic-sign\/' + x).tolist()\n\n# Test output to make sure we're all good\ntrain_images.shape","1b9a7a39":"# three things are happening in these lines:\n# 1. We are loading the images based of the file paths read in the previous cell.\n# 2. We are changing the images from cv2's default blue green red, to red green blue. \n# This doesn't change training, but if we were to view the images the colors would be wrong.\n# 3. scaling to 32 x 32 pixels. This will make training easier\ntrain_images = np.array([cv2.cvtColor(cv2.resize(cv2.imread(fname), (32, 32), interpolation = cv2.INTER_AREA), cv2.COLOR_BGR2RGB) for fname in train_image_paths])\ntest_images = np.array([cv2.cvtColor(cv2.resize(cv2.imread(fname), (32, 32), interpolation = cv2.INTER_AREA), cv2.COLOR_BGR2RGB) for fname in test_image_paths])","ab0d59cc":"plt.figure()\nplt.imshow(train_images[101], cmap='gray')\nplt.colorbar()\nplt.grid(False)\nplt.show()","6ff59c5b":"train_images = np.sum(train_images\/3, axis=3, keepdims=True)\ntrain_images = train_images \/ 255.0\n\ntest_images = np.sum(test_images\/3, axis=3, keepdims=True)\ntest_images = test_images \/ 255.0","dae0c74a":"# Create the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters = 6, kernel_size = (5, 5), strides=(1, 1), padding='valid', \n                        activation='relu', data_format = 'channels_last', input_shape = (32, 32, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(16, (5, 5), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Train\nconv = model.fit(train_images, train_labels, batch_size=128, epochs=10, validation_data=(test_images, test_labels))","cacb3eb5":"# Graph Accuracy and Loss to see how we did:\n\nacc = [conv.history['accuracy'], conv.history['val_accuracy']]\nloss = [conv.history['loss'], conv.history['val_loss']]\n\nepoch = range(10)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epoch, acc[0], label='Training Accuracy')\nplt.plot(epoch, acc[1], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epoch, loss[0], label='Training Loss')\nplt.plot(epoch, loss[1], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","5e3f1982":"There's a couple more things we need to do, but we're almost ready.\n\n**Let's view an image to see how it looks:**","f18572dc":"**Now we'll load and create the actual images:**","b428a211":"# Loading the data\n\nthe data is pre-split into training and testing data. It contains the following:\n- csv files for meta-data. All we care about from here is the class id, and path to the file.\n- The training images. These are organized by their type into different folders\n- The Test images. These are all together in the same folder.\n\n**Let's load the data:**","88f7ac55":"# Traffic Sign Recognition\n\nThis is a completed working classification network for the german traffic sign recognition database.\n\n**First We will load all the required libraries:**","34ff1ff2":"It should be looking pretty good now, but the data isn't quite ready! This this model we will be using a grayscale image, so we need to convert to that. We are also going to want to scale the values down. Right now they are 0-255, but if we scale it to 0-1 it will train quite a bit faster.\n\n**Let's do both of those things now:**","b89652f6":"## Training\n\nNow that the data is all ready, we can start training!\n\nFor this I am creating a convalutional nerual network with two convalutional layers, followed by two dense layers. Feel free to try different values for everything to see if you can get better results!\n\n**First we will need to create our model, then we will start training:**"}}