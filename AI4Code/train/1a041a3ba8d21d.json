{"cell_type":{"cf17e908":"code","acd01411":"code","464c225d":"code","8fefe21b":"code","c2cebbb9":"code","44ecce1d":"code","2b8b4103":"code","5a05e5c9":"code","addf389f":"code","1f4ac415":"code","a6f18fdf":"code","8546c163":"code","0d9c14c9":"code","01f1554e":"code","6696f187":"code","32fbd765":"code","6c822a49":"code","dd2e0fbc":"code","28361081":"code","653336ea":"code","8793994b":"code","5eb59a91":"code","de2cc727":"code","9abfbc9f":"code","13e35837":"code","9716647a":"code","0484fc84":"code","c15243c3":"code","733b3c3e":"code","10d57eff":"code","d9397d4f":"code","34f7e16b":"code","9ace4e8d":"markdown","c1c39d6b":"markdown","15df3cf1":"markdown","1795622b":"markdown","c8aa40c4":"markdown","4ee467ad":"markdown","3d4a2289":"markdown","aaa4d435":"markdown","7cec50a8":"markdown","42f7e5d0":"markdown","ed432272":"markdown"},"source":{"cf17e908":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom graphviz import Source\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","acd01411":"df = pd.read_excel('\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\ndf.head()","464c225d":"cols_to_drop=['AGE_PERCENTIL', 'WINDOW']\ndf=df.drop(cols_to_drop,axis=1)\ndf.columns","8fefe21b":"plt.style.use('dark_background')\ndf['ICU'].value_counts().plot.barh()","c2cebbb9":"import missingno as msno\n# checking null values\nmsno.bar(df, figsize=(16, 4))","44ecce1d":"(df.isnull().sum() \/ df.shape[0]).sort_values(ascending=False).head()","2b8b4103":"contain_null_series = (df.isnull().sum() != 0).index","5a05e5c9":"#target = 'ICU'\n#just_one_target = []\n\n#for col in contain_null_series:\n#    i = df[df[col].notnull()][target].nunique()\n#    if i == 1:\n#        just_one_target.append(col)    \n\n# columns that only are present when ICU is needed        \n#print(just_one_target)","addf389f":"#for col in just_one_target:\n #   print(df[df[col].notnull()][target].unique())","1f4ac415":"#df.drop(just_one_target, axis=1, inplace=True)","a6f18fdf":"not_null_series = (df.isnull().sum() == 0)\nnot_null_columns = not_null_series[not_null_series == True].index\nnot_null_columns = not_null_columns[1:]","8546c163":"def plot_histograms(df, cols, subplots_rows, subplots_cols, figsize=(16, 8), target='ICU'):\n    df_neg = df[df[target] == 'negative']\n    df_pos = df[df[target] == 'positive']\n    \n    cols = cols.tolist()\n    cols.remove(target)\n    \n    plt.figure()\n    fig, ax = plt.subplots(subplots_rows, subplots_cols, figsize=figsize)\n    \n    i = 0    \n    for col in cols:\n        i += 1\n        plt.subplot(subplots_rows, subplots_cols, i)\n        sns.distplot(df_neg[col], label=\"Negative\", bins=15, kde=False)\n        sns.distplot(df_pos[col], label=\"Positive\", bins=15, kde=False)\n        plt.legend()\n    plt.show()\n    \nplot_histograms(df, not_null_columns, 2, 2)","0d9c14c9":"x = df.drop(['PATIENT_VISIT_IDENTIFIER', 'ICU'], axis=1)\nx.fillna(999999, inplace=True)\ny = df['ICU']","01f1554e":"dt = DecisionTreeClassifier(max_depth=3)","6696f187":"dt = DecisionTreeClassifier(max_depth=3)","32fbd765":"dt.fit(x, y)","6c822a49":"dt_feat = pd.DataFrame(dt.feature_importances_, index=x.columns, columns=['feat_importance'])\ndt_feat.sort_values('feat_importance').tail(8).plot.barh()\nplt.show()","dd2e0fbc":"from IPython.display import SVG\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin\/'\n\ngraph = Source(export_graphviz(dt, out_file=None, feature_names=x.columns, filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","28361081":"sns.distplot(df[df['ICU'] == 1]['LEUKOCYTES_MAX'], label=\"ICU\")\nsns.distplot(df[df['ICU'] == 0]['LEUKOCYTES_MAX'], label=\"NO ICU\")\nplt.legend()","653336ea":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler","8793994b":"classifiers = {'Logistic Regression' : LogisticRegression(),\n               'KNN': KNeighborsClassifier(),\n               'Decision Tree': DecisionTreeClassifier(),\n               'Random Forest': RandomForestClassifier(),\n               'AdaBoost': AdaBoostClassifier(),\n               'SVM': SVC()}\n\nsamplers = {'Random_under_sampler': RandomUnderSampler(),\n            'Random_over_sampler': RandomOverSampler()}\n\ndrop_cols = ['PATIENT_VISIT_IDENTIFIER']","5eb59a91":"def df_split(df, target='ICU', drop_cols=drop_cols):\n    df = df.drop(drop_cols, axis=1)\n    df = df.fillna(999)\n    x = df.drop(target, axis=1)\n    y = df[target]    \n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)                          \n    return x_train, x_test, y_train, y_test\n\ndef train_clfs(df, classifiers, samplers):\n    \n    x_train, x_test, y_train, y_test = df_split(df)\n    \n    names_samplers = []\n    names_clfs = []\n    results_train_cv_roc_auc = []\n    results_train_cv_recall = []\n    results_train_cv_accuracy = []\n    results_test_roc_auc = []\n    results_test_recall = []\n    results_test_accuracy = []\n    \n    for name_sampler, sampler in samplers.items():\n        print(f'Sampler: {name_sampler}\\n')\n        for name_clf, clf in classifiers.items():\n            print(f'Classifier: {name_clf}\\n')\n            \n            pipeline = Pipeline([('sampler', sampler),\n                                 ('clf', clf)])\n            \n            cv_auc = cross_val_score(pipeline, x_train, y_train, cv=10, scoring='roc_auc') \n            cv_rec = cross_val_score(pipeline, x_train, y_train, cv=10, scoring='recall')                                \n            cv_acc = cross_val_score(pipeline, x_train, y_train, cv=10, scoring='accuracy')        \n\n            pipeline.fit(x_train, y_train)        \n            y_pred = pipeline.predict(x_test)\n            \n            names_samplers.append(name_sampler)\n            names_clfs.append(name_clf)\n            results_train_cv_roc_auc.append(cv_auc)\n            results_train_cv_recall.append(cv_rec)\n            results_train_cv_accuracy.append(cv_acc)\n            results_test_roc_auc.append(roc_auc_score(y_test, y_pred))\n            results_test_recall.append(recall_score(y_test, y_pred))\n            results_test_accuracy.append(accuracy_score(y_test, y_pred))\n\n            print(f'CV\\t-\\troc_auc:\\t{round(cv_auc.mean(), 3)}')\n            print(f'CV\\t-\\trecall:\\t\\t{round(cv_rec.mean(), 3)}')\n            print(f'CV\\t-\\taccuracy:\\t{round(cv_acc.mean(), 3)}')\n\n            print(f'Test\\t-\\troc_auc:\\t{round(roc_auc_score(y_test, y_pred), 3)}')         \n            print(f'Test\\t-\\trecall:\\t\\t{round(recall_score(y_test, y_pred), 3)}')          \n            print(f'Test\\t-\\taccuracy:\\t{round(accuracy_score(y_test, y_pred), 3)}')      \n            print('\\n<-------------------------->\\n')\n\n    df_results_test = pd.DataFrame(index=[names_clfs, names_samplers], columns=['ROC_AUC', 'RECALL', 'ACCURACY'])\n    df_results_test['ROC_AUC'] = results_test_roc_auc\n    df_results_test['RECALL'] = results_test_recall\n    df_results_test['ACCURACY'] = results_test_accuracy\n\n    return df_results_test","de2cc727":"from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","9abfbc9f":"df_results_test = train_clfs(df, classifiers, samplers)","13e35837":"def train_xgb(df, clf):\n    \n    x_train, x_test, y_train, y_test = df_split(df)\n\n    scale_pos_weight = len(df[df['ICU'] == 0]) \/ len(df[df['ICU'] == 1])\n\n    param_grid = {'xgb__max_depth': [3, 4, 5, 6, 7, 8],\n                  'xgb__learning_rate': [0.01, 0.05, 0.1, 0.2],\n                  'xgb__colsample_bytree': [0.6, 0.7, 0.8],\n                  'xgb__min_child_weight': [0.4, 0.5, 0.6],\n                  'xgb__gamma': [0, 0.01, 0.1],\n                  'xgb__reg_lambda': [6, 7, 8, 9, 10],\n                  'xgb__n_estimators': [150, 200, 300],\n                  'xgb__scale_pos_weight': [scale_pos_weight]}\n\n    rs_clf = RandomizedSearchCV(clf, param_grid, n_iter=100,\n                                n_jobs=-1, verbose=2, cv=5,                            \n                                scoring='roc_auc', random_state=42)\n\n    rs_clf.fit(x_train, y_train)\n    \n    print(f'XGBOOST BEST PARAMS: {rs_clf.best_params_}')\n    \n    y_pred = rs_clf.predict(x_test)\n\n    df_results_xgb = pd.DataFrame(index=[['XGBoost'], ['No_sampler']], columns=['ROC_AUC', 'RECALL', 'ACCURACY'])\n\n    df_results_xgb['ROC_AUC'] = roc_auc_score(y_test, y_pred)\n    df_results_xgb['RECALL'] = recall_score(y_test, y_pred)\n    df_results_xgb['ACCURACY'] = accuracy_score(y_test, y_pred)\n    \n    return df_results_xgb","9716647a":"df_results_xgb = train_xgb(df, xgb.XGBClassifier())","0484fc84":"df_results = pd.concat([df_results_test, df_results_xgb])","c15243c3":"df_plot = pd.concat([df_results.sort_values('ROC_AUC', ascending=False).head(3),\n                     df_results.sort_values('RECALL', ascending=False).head(3),\n                     df_results.sort_values('ACCURACY', ascending=False).head(3)])","733b3c3e":"def plot_test(df, xlim_min, xlim_max):\n\n    f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10,12))\n    color = ['blue', 'red', 'green', 'yellow', 'orange', 'purple', 'navy', 'turquoise', 'darkorange']\n\n    df['ROC_AUC'].plot(kind='barh', ax=ax1, xlim=(xlim_min, xlim_max), title='ROC_AUC', color=color)\n    df['RECALL'].plot(kind='barh', ax=ax2, xlim=(xlim_min, xlim_max), title='RECALL', color=color)\n    df['ACCURACY'].plot(kind='barh', ax=ax3, xlim=(xlim_min, xlim_max), title='ACCURACY', color=color)\n    plt.show()","10d57eff":"plot_test(df_plot, 0.4, 1)","d9397d4f":"def plot_confusion_matrix(y_test, y_pred, title='Confusion matrix'):\n    \n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \ndef train_clf_threshold(df, clf, sampler=None):\n    thresholds = np.arange(0.1, 1, 0.1)\n    \n    x_train, x_test, y_train, y_test = df_split(df)\n    \n    if sampler:\n        clf_train = Pipeline([('sampler', sampler),\n                              ('clf', clf)])\n        \n    else:        \n        clf_train = clf\n            \n    clf_train.fit(x_train, y_train)\n    y_proba = clf_train.predict_proba(x_test)\n    \n    plt.figure(figsize=(10,10))\n\n    j = 1\n    for i in thresholds:\n        y_pred = y_proba[:,1] > i\n\n        plt.subplot(4, 3, j)\n        j += 1\n\n        # Compute confusion matrix\n        cnf_matrix = confusion_matrix(y_test,y_pred)\n        np.set_printoptions(precision=2)\n\n        print(f\"Threshold: {round(i, 1)} | Test Accuracy: {round(accuracy_score(y_test, y_pred), 2)}| Test Recall: {round(recall_score(y_test, y_pred), 2)} | Test Roc Auc: {round(roc_auc_score(y_test, y_pred), 2)}\")\n\n        # Plot non-normalized confusion matrix\n        plot_confusion_matrix(y_test, y_pred, title=f'Threshold >= {round(i, 1)}')","34f7e16b":"train_clf_threshold(df, RandomForestClassifier(), sampler=RandomUnderSampler())","9ace4e8d":"The top 9 pipelines for each metric ROC_AUC, RECALL, and ACCURACY in the test dataset below:","c1c39d6b":"#Hospital S\u00edrio e Liban\u00eas and AI.\n\nHow can artificial intelligence change the future of medicine? The doctor and general director of the S\u00edrio-Liban\u00eas hospital , Paulo Chapchap , spoke exclusively to the Consumidor Moderno and Whow! on the use of new technologies and the main challenges faced in daily application, such as ethics in the use of patient data.\n\nHe also commented on the evolution in the relationship with the hospital's clients , the plans for an expansion of the application of voice within the medical field, in addition to the possible elimination of diseases through the use of big data, artificial intelligence and machine learning.https:\/\/translate.google.com.br\/translate?hl=en&sl=pt&u=https:\/\/www.consumidormoderno.com.br\/2020\/02\/14\/sirio-libanes-experiencia-de-voz\/&prev=search&pto=aue","15df3cf1":"Right data, wrong snippet. No distplots","1795622b":"We've many values null in the dataset. Drop the columns that only have one value in the target, since they'll hardly help.","c8aa40c4":"Das War's, Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","4ee467ad":"We'll plot the columns that doesn't have any null to check if they can discriminate the target.","3d4a2289":"![](https:\/\/www.hospitalsiriolibanes.org.br\/solidariedade-coronavirus\/PublishingImages\/banner-solidariedade-coronavirus.png)\nhospitalsiriolibanes.org.br\n\nPhilanthropy has been the raison d'\u00eatre of the Sociedade Beneficente de Senhoras Hospital S\u00edrio-Liban\u00eas for almost 100 years. Their history was born from the feeling of solidarity and it is our mission to exercise it.\n\nIn this unprecedented moment of global crisis, due to the COVID-19 pandemic, they are mobilizing to minimize the impact of this scenario on the lives of the most vulnerable families and health professionals, and to support society in general.\n\nTherefore, they have structured their own initiatives and in partnership with other institutions, in a joint effort, to deliver the greatest possible number of solutions, which aim to overcome this crisis as soon as possible.\nOn April 8, they launched the Campaign \u201cSolidarity Action to Combat Covid-19\u201d. \n\n#My Notebook Plot.Solidarity  https:\/\/www.kaggle.com\/mpwolke\/plot-solidarity","aaa4d435":"I dropped the columns below because I couldn't encode them.","7cec50a8":"#Modeling\n\nWe'll try to identify ICU need by applying several models combined with random over sampler and random under sampler. The samplers will balance the dataset, therefore it should reduce the bias of the models. We'll also apply xgboost with hyperparameter tuning.","42f7e5d0":"#Codes from Ossamu  https:\/\/www.kaggle.com\/ossamum\/eda-and-feat-import-recall-0-95-roc-auc-0-61","ed432272":"#All codes from  Ossamu  https:\/\/www.kaggle.com\/ossamum\/eda-and-feat-import-recall-0-95-roc-auc-0-61"}}