{"cell_type":{"3fb41296":"code","bd7e0f4d":"code","e1081ff9":"code","8228270f":"code","75ea6ec3":"code","8f037d34":"code","d0b0e4ad":"code","c000322a":"code","1cca7dc6":"code","2d628834":"code","7632b53d":"code","ff9399b8":"code","f420029f":"code","21ebc5c9":"code","71b7a949":"code","64d043ea":"code","b2e38d78":"code","0fee632b":"code","2635eee7":"code","8aeca223":"code","93d2ae2b":"code","53b8ea79":"code","2700b64a":"code","2279e17e":"code","be2e8630":"code","19de7f81":"code","8ad001b0":"code","7896f098":"code","ad4a52a9":"code","b3e7eeec":"code","0fd0661a":"code","070c5d91":"code","1c69fca1":"code","57f92730":"code","ee43c68b":"code","af656b4a":"code","9b9885da":"code","35dee55d":"code","7419f3ba":"code","12843703":"code","080e5ff5":"code","46789c6b":"code","f41f70af":"code","03460c19":"code","da45d325":"code","f0d25e5d":"code","ca7a5b58":"code","83912ef7":"code","14b60984":"code","7327e315":"code","4e286db7":"code","6ecc6d67":"code","3077b2c7":"code","80b8c847":"code","ba0933a9":"code","8308518b":"code","2251aa7b":"code","a5a25673":"code","8b880060":"code","df4c2bc5":"code","913690bc":"code","9b90cd1a":"code","9b262b33":"code","8a52383c":"code","a488fb9e":"code","6346605d":"code","4405036d":"code","a6278ab7":"code","ee3bb230":"code","5b8bb6f1":"code","2495a0b0":"markdown","408445b8":"markdown","776e5c24":"markdown","be973b1a":"markdown","b1c7136a":"markdown","5023beff":"markdown","fd653e11":"markdown","98cce9d2":"markdown","a8fbd7a7":"markdown","8fcb37d0":"markdown","d99b02d7":"markdown","48e44ab3":"markdown","f42f05d6":"markdown","1def886a":"markdown","aeec6ae8":"markdown","839da1f9":"markdown","ee911bc6":"markdown","55ae3d9d":"markdown","f595f95d":"markdown","76c9e440":"markdown","324e7f05":"markdown","93b2ce13":"markdown","fff128f1":"markdown","688671cc":"markdown","7daa5b11":"markdown","bb2abbdb":"markdown","d33d4bad":"markdown","500e4e82":"markdown","d313f09a":"markdown","b7c866c6":"markdown","bf1e2324":"markdown","e6c3d23d":"markdown"},"source":{"3fb41296":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch","bd7e0f4d":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e1081ff9":"def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","8228270f":"# Load Data\ntrain_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nxsubmission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","75ea6ec3":"print(train_df.shape)\nprint(test_df.shape)","8f037d34":"train_df['sentiment'].value_counts()","d0b0e4ad":"test_df['sentiment'].value_counts()","c000322a":"train_df.dropna(inplace=True)","1cca7dc6":"train_df.head(5)","2d628834":"train_sentiment = train_df['sentiment'].value_counts().reset_index()\ntest_sentiment = test_df['sentiment'].value_counts().reset_index()\ntrain_sentiment.columns = [\"sentiment\",\"counts\"]\ntest_sentiment.columns = [\"sentiment\",\"counts\"]","7632b53d":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,6))\nsns.set(style=\"darkgrid\")\nax1.set_title(\"Train\")\nax2.set_title(\"Test\")\nax1.set_ylim([0,12000])\nax2.set_ylim([0,12000])\nsns.countplot(x='sentiment',data=train_df,ax=ax1,order=[\"positive\",\"neutral\",\"negative\"])\nsns.countplot(x='sentiment',data=test_df,ax=ax2,order=[\"positive\",\"neutral\",\"negative\"])\nplt.show()","ff9399b8":"plt.figure(figsize=(16,10))\nplt.title(\"Train\")\nplt.pie(train_sentiment['counts'], labels = train_sentiment['sentiment'] ,autopct=\"%1.1f%%\", startangle=90)\nplt.show()\nplt.figure(figsize=(16,10))\nplt.title(\"Test\")\nplt.pie(test_sentiment['counts'], labels = test_sentiment['sentiment'] ,autopct=\"%1.1f%%\", startangle=90)\nplt.show()","f420029f":"temp = train_df.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","21ebc5c9":"fig = go.Figure(go.Funnelarea(\n    text =temp.sentiment,\n    values = temp.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","71b7a949":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","64d043ea":"results_jaccard=[]\n\nfor ind,row in train_df.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])","b2e38d78":"jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain = train_df.merge(jaccard,how='outer')","0fee632b":"train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text","2635eee7":"train.head()","8aeca223":"hist_data = [train['Num_words_ST'],train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels,show_curve=False)\nfig.update_layout(title_text='Distribution of Number Of words')\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=700,\n    paper_bgcolor=\"LightSteelBlue\",\n)\nfig.show()","93d2ae2b":"p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\np1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")","53b8ea79":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\np2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")","2700b64a":"plt.figure(figsize=(12,6))\nsns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)","2279e17e":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\np2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\nplt.legend(labels=['positive','negative'])","be2e8630":"plt.figure(figsize=(12,6))\nsns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)","19de7f81":"k = train[train['Num_word_text']<=2]","8ad001b0":"k.groupby('sentiment').mean()['jaccard_score']","7896f098":"k[k['sentiment']=='positive']","ad4a52a9":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","b3e7eeec":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","0fd0661a":"train.head()","070c5d91":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","1c69fca1":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","57f92730":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","ee43c68b":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","af656b4a":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","9b9885da":"train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords","35dee55d":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","7419f3ba":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","12843703":"Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']","080e5ff5":"#Most common positive words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Greens')","46789c6b":"fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","f41f70af":"#Most common negative words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Reds')","03460c19":"fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\nfig.show()","da45d325":"#MosT common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Reds')","f0d25e5d":"fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","ca7a5b58":"fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\nfig.show()","83912ef7":"raw_text = [word for word_list in train['temp_list1'] for word in word_list]","14b60984":"def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","7327e315":"Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","4e286db7":"fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\nfig.show()","6ecc6d67":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Positive Words')\nplt.show()","3077b2c7":"Unique_Negative= words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap='Reds')","80b8c847":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Negative Words')\nplt.show()","ba0933a9":"Unique_Neutral= words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap='Oranges')","8308518b":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Neutral Words')\nplt.show()","2251aa7b":"os.listdir('..\/input')","a5a25673":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'u', \"im\"}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=400, \n                    height=200,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n\n","8b880060":"df_train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\ndf_submission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","df4c2bc5":"df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set","913690bc":"df_train = df_train[df_train['Num_words_text']>=3]","9b90cd1a":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'..\/working\/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","9b262b33":"\n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","8a52383c":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models\/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models\/model_neg'\n    return model_out_path","a488fb9e":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","6346605d":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n# For DEmo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","4405036d":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)","a6278ab7":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","ee3bb230":"selected_texts = []\nMODELS_BASE_PATH = '..\/input\/tse-spacy-model\/models\/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","5b8bb6f1":"df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","2495a0b0":"#### KDE of Jaccard Scores across different Sentiments","408445b8":"### Sentiments Wise Most common words","776e5c24":"#### View Data after Generating Meta-Features","be973b1a":"#### Distribution of Number Of words","b1c7136a":"**View first 5 rows from training Data**","5023beff":" ### Look Train Data Summary of sentiment column","fd653e11":"# Import library\n\nImport necessary library for this compitition. There needed lots of library for NLP.","98cce9d2":"*The number of words plot is really interesting ,the tweets having number of words greater than 25 are very less and thus the number of words distribution plot is right skewed*","a8fbd7a7":"*It will be more interesting to see the differnce in number of words and jaccard_scores across different Sentiments*","8fcb37d0":"# Modelling","d99b02d7":"** View Sentiment column in a count plot from Train data, in sentiment column, there are 8582 are positive, 7781 are negative and 11118 are negative. From Test data, in sentiment column, there are 1103 are positive, 1001 are negative and 1430 are negative. **","48e44ab3":"** View Sentiment column in a Pie plot from Train data, in sentiment column, there are 8582 are positive, 7781 are negative and 11118 are negative. From Test data, in sentiment column, there are 1103 are positive, 1001 are negative and 1430 are negative. **","f42f05d6":"#### Generating Meta-Features","1def886a":"**Looking Positive sentiment**","aeec6ae8":"**Training models for Positive and Negative tweets**","839da1f9":"### Unique Words in each Segment","ee911bc6":"**Drop rows where rows are null**","55ae3d9d":"**Load resources from input folder**","f595f95d":"### Most Common words in Text","76c9e440":"# EDA for Tweet Sentiment","324e7f05":"**There are 27481 row and 4 columns in train data set and 3534 row and 3 column in test data set**","93b2ce13":"*remove the stop words *","fff128f1":"**Predicting with the trained Model**","688671cc":"# About Competetion:\n\n\n\"My ridiculous dog is amazing.\" [sentiment: positive]\n\nWith all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment.\n\nHelp build your skills in this important area with this broad dataset of tweets. Work on your technique to grab a top spot in this competition. What words in tweets support a positive, negative, or neutral sentiment? How can you help make that determination using machine learning tools?\n\nIn this competition we've extracted support phrases from Figure Eight's Data for Everyone platform. The dataset is titled Sentiment Analysis: Emotion in Text tweets with existing sentiment labels, used here under creative commons attribution 4.0. international licence. Your objective in this competition is to construct a model that can do the same - look at the labeled sentiment for a given tweet and figure out what word or phrase best supports it.\n\nDisclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.","7daa5b11":"### Cleaning the Corpus","bb2abbdb":"**From Train data, in sentiment column, there are 8582 are positive, 7781 are negative and 11118 are negative.**","d33d4bad":"**View afte remove the stop words **","500e4e82":"## Read data from train, test and submission files","d313f09a":"### ----------------------------- The Preject End --------------------------------------------","b7c866c6":"**From Test data, in sentiment column, there are 1103 are positive, 1001 are negative and 1430 are negative.**","bf1e2324":"## Target-Selected Text in Most Common words","e6c3d23d":"#### Look sentiment in Funnel-Chart for better visualization"}}