{"cell_type":{"d9c1c5e9":"code","20f9ecb4":"code","786dd9f4":"code","799d8f26":"code","3bb19430":"code","ce43e5da":"code","06123c2d":"code","638d1ba2":"code","3e46138c":"code","321de407":"code","62fb64e7":"code","0db4f81d":"code","7ea2bc6e":"code","ed074856":"code","50f9a632":"code","5ce1f780":"code","346126b3":"code","02dc466e":"code","4388db72":"code","0c29e301":"code","e0ab71e4":"code","22102800":"code","9f3763e6":"code","45c80b7e":"code","1c8c4581":"code","41669c77":"code","9e0ad13a":"code","fe38484c":"markdown","50d74251":"markdown","6c1aba19":"markdown","b8fe9f5c":"markdown","4932596d":"markdown","a6ae15c3":"markdown","a1ebd979":"markdown","5ff510ee":"markdown","3aeec165":"markdown","3adea4c2":"markdown"},"source":{"d9c1c5e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras.layers import Dense,Dropout\nfrom keras.models import Sequential\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20f9ecb4":"train_data=pd.read_csv('\/kaggle\/input\/sf-crime\/train.csv.zip')\ntrain_data.head()","786dd9f4":"test_data=pd.read_csv('\/kaggle\/input\/sf-crime\/test.csv.zip')\ntest_data.head()","799d8f26":"train_data.drop(['Descript','Resolution','Address'],inplace=True,axis=1)\ntest_data.drop('Address',axis=1,inplace=True)","3bb19430":"train_data.head()","ce43e5da":"test_data.head()","06123c2d":"print(train_data['DayOfWeek'].unique())\nprint(test_data['DayOfWeek'].unique())","638d1ba2":"train_data['DayOfWeek'].replace(to_replace=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],value=[i for i in range(0,7)],inplace=True)\ntest_data['DayOfWeek'].replace(to_replace=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],value=[i for i in range(0,7)],inplace=True)\n\ndummies_train=pd.get_dummies(train_data['PdDistrict'])\ndummies_test=pd.get_dummies(test_data['PdDistrict'])\n\ntrain_data=pd.concat([train_data,dummies_train],axis=1)\ntrain_data.drop('PdDistrict',inplace=True,axis=1)\n\ntest_data=pd.concat([test_data,dummies_test],axis=1)\ntest_data.drop('PdDistrict',inplace=True,axis=1)","3e46138c":"train_data.head()","321de407":"test_data.head()","62fb64e7":"ls1=list(train_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][:4:]\ntrain_data['Year']=ls1 \n\nls1=list(train_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][5:7:]\ntrain_data['Month']=ls1 \n\nls1=list(train_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][8:10:]\ntrain_data['Day']=ls1 \n\nls1=list(train_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][11:-6:]\ntrain_data['Hours']=ls1\n\nls1=list(train_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][-5:-3:]\ntrain_data['Minutes']=ls1\n\ntrain_data.drop('Dates',axis=1,inplace=True)\ntrain_data.head()","0db4f81d":"ls1=list(test_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][:4:]\ntest_data['Year']=ls1 \n\nls1=list(test_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][5:7:]\ntest_data['Month']=ls1 \n\nls1=list(test_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][8:10:]\ntest_data['Day']=ls1 \n\nls1=list(test_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][11:-6:]\ntest_data['Hours']=ls1\n\nls1=list(test_data['Dates'])\nfor i in range(len(ls1)):\n    ls1[i]=ls1[i][-5:-3:]\ntest_data['Minutes']=ls1\n\ntest_data.drop('Dates',axis=1,inplace=True)\ntest_data.head()","7ea2bc6e":"test_data.drop('Id',axis=1).columns==train_data.drop('Category',axis=1).columns","ed074856":"y=pd.get_dummies(train_data['Category'])\ny.head()","50f9a632":"X=train_data.drop(['Category'],axis=1)\nX=X.astype(float)\nX","5ce1f780":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=42)\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","346126b3":"y_train.dtypes","02dc466e":"model=Sequential()\nmodel.add(Dense(128,input_shape=(X.shape[1],)))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(39,activation='softmax'))\nmodel.summary()","4388db72":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","0c29e301":"train=model.fit(X_train,y_train, \n         batch_size=32,\n         epochs=10,\n         verbose=2,\n         validation_data=(X_test,y_test))","e0ab71e4":"test=test_data.drop(['Id'],axis=1)\ntest=test.astype(float)\ntest.dtypes","22102800":"pred=model.predict(test)","9f3763e6":"m = np.max(pred, axis=1).reshape(-1, 1)\npredicted = np.array((pred == m), dtype='int32')\npredicted","45c80b7e":"sample=pd.read_csv('\/kaggle\/input\/sf-crime\/sampleSubmission.csv.zip')\ncol_names=list(sample.columns)\ncol_names.remove('Id')","1c8c4581":"submission = pd.DataFrame()\nsubmission['Id']=test_data['Id']\nfor i, entry in enumerate(col_names):\n    submission[entry] = predicted[:,i]","41669c77":"submission.head()","9e0ad13a":"submission.to_csv('..\/working\/submission.csv', index=False)","fe38484c":"### Hot Encoding","50d74251":"### Detailing test data","6c1aba19":"### Submitting prediction","b8fe9f5c":"### Compiling and fitting data","4932596d":"### Cleaning train and test data","a6ae15c3":"### Neural Network Model","a1ebd979":"### Loading the data","5ff510ee":"### Splitting the data for training and testing","3aeec165":"### Handling Dates","3adea4c2":"### Predicting"}}