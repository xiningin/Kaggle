{"cell_type":{"9ef67897":"code","f8da8266":"code","c283b2a9":"code","ed7cc876":"code","3514dc83":"code","2de5457d":"code","9a5aaf75":"code","10dcf8a0":"code","b5c467db":"code","e9b80f6b":"markdown","7339f895":"markdown","f9049053":"markdown","0ea3967f":"markdown","f5f4b22e":"markdown","c5b91909":"markdown","98f7bc79":"markdown"},"source":{"9ef67897":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","f8da8266":"train_dataset = pd.read_csv('..\/input\/loan-prediction-based-on-customer-behavior\/Training Data.csv')\nprint(train_dataset)","c283b2a9":"train_dataset[\"Profession\"]=pd.factorize(train_dataset.Profession)[0]\ntrain_dataset[\"CITY\"]=pd.factorize(train_dataset.CITY)[0]\ntrain_dataset[\"STATE\"]=pd.factorize(train_dataset.STATE)[0]\ntrain_dataset[\"Married\/Single\"]=pd.factorize(train_dataset['Married\/Single'])[0]\ntrain_dataset[\"House_Ownership\"]=pd.factorize(train_dataset.House_Ownership)[0]\ntrain_dataset[\"Car_Ownership\"]=pd.factorize(train_dataset.Car_Ownership)[0]\n\n\nprint(train_dataset)","ed7cc876":"# plot the number of the deflat and not deflat\ncount_class=pd.value_counts(train_dataset['Risk_Flag'],sort=True).sort_index()\ncount_class.plot(kind='bar')\nplt.title('Risk_Flag')\nplt.xlabel('riks_status')\nplt.ylabel('Frequency')\nplt.show()\n","3514dc83":"# split data\nx_train = train_dataset.loc[:,train_dataset.columns!='Risk_Flag']\n#\u6807\u7b7e\ny_train = train_dataset.loc[:,train_dataset.columns=='Risk_Flag']\ndata = train_dataset\ninput_shape = [x_train.shape[1]]\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the data\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.33, shuffle= True)\n\nx_train = tf.convert_to_tensor(x_train, dtype=tf.float32) \ny_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\nx_valid = tf.convert_to_tensor(x_valid, dtype=tf.float32) \ny_valid = tf.convert_to_tensor(y_valid, dtype=tf.int32)","2de5457d":"model = tf.keras.Sequential([\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu', input_shape=input_shape),\n    layers.Dropout(0.5),\n    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='elu'),\n    layers.Dropout(0.5),\n    layers.Dense(10, kernel_regularizer=regularizers.l2(0.0001),\n                 activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1,activation='sigmoid')\n])\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n              metrics=['accuracy'])","9a5aaf75":"model.fit(x_train,y_train, epochs=200,validation_data=(x_valid,y_valid),verbose=2)","10dcf8a0":"predictions = model.predict(x_valid)\ny_pred = np.argmax(predictions, axis=-1)\nprint(y_pred)\n","b5c467db":"from sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_valid, y_pred)\nprint(auc)","e9b80f6b":"# 7 make train_ test_ data turn into tensor","7339f895":"# 1 set up","f9049053":"# 3 turn words to math, tensorflow,she like math","0ea3967f":"# 4 normlized the income","f5f4b22e":"# 2 import data","c5b91909":"# modeling","98f7bc79":"# 5 make the train_dataset input pre"}}