{"cell_type":{"56a7a6a2":"code","cf225d6f":"code","166e3b0e":"code","74ff887f":"code","f1574ec8":"code","6a22c76e":"code","8c745fc0":"code","5da30f38":"code","b926f962":"code","daebaa8e":"code","d9609a8d":"code","aacf2959":"code","8e78d890":"code","5057f35c":"code","14b8789d":"code","5d16db6a":"code","5360db91":"code","e267a1a6":"code","4f294f97":"code","9bd626f9":"code","943be727":"code","cd0c339d":"code","a67ed1e6":"code","53160f0a":"code","f46752cd":"code","7f85233d":"code","ce5e7589":"code","4ce01b1f":"code","7b3b7983":"code","176d6b65":"code","bca2b08a":"code","dc11cb3c":"code","a2fb5d17":"code","dc398982":"code","620fbc76":"code","44a9966a":"markdown","852dc1da":"markdown","ed7808ea":"markdown","e0bc7823":"markdown","76b7ee09":"markdown","3560a95e":"markdown","b4afff28":"markdown","6d4bc5ea":"markdown","5f7ee002":"markdown","dfaa2c85":"markdown","7577da6f":"markdown","1835ce96":"markdown","3120ce53":"markdown","22f6a191":"markdown","ac08be21":"markdown","b6f5264d":"markdown"},"source":{"56a7a6a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n","cf225d6f":"df=pd.read_csv(\"\/kaggle\/input\/amazon-top-50-bestselling-books-2009-2019\/bestsellers with categories.csv\")","166e3b0e":"df.head()","74ff887f":"df.corr()","f1574ec8":"df.dtypes","6a22c76e":"df.duplicated().sum()","8c745fc0":"df.isna().sum()","5da30f38":"\ndef outliers(df):\n    out=[]\n    q1=df.quantile(0.25)\n    q3=df.quantile(0.75)\n    iqr=q3-q1\n    upper_value=q3+1.5*iqr\n    lower_value=q1-1.5*iqr\n    for x in df:\n        if x > upper_value or x< lower_value:\n            out.append(x)\n    print(\"OUTLIERS ARE : \\n\",out)\n    \n    \n    \n    ","b926f962":"sns.boxplot(df[\"User Rating\"])\nplt.show()","daebaa8e":"outliers(df[\"User Rating\"])","d9609a8d":"sns.boxplot(df[\"Reviews\"])\nplt.show()","aacf2959":"outliers(df[\"Reviews\"])","8e78d890":"sns.boxplot(df[\"Price\"])\nplt.show()","5057f35c":"outliers(df[\"Price\"])","14b8789d":"df.head()","5d16db6a":"df[\"Name\"].value_counts().sort_values(ascending=False)[0:96]","5360db91":"editions=df[\"Name\"].value_counts().sort_values(ascending=False)[0:10].reset_index()\neditions.columns=[\"Name\",\"editions\"]\nplt.figure(figsize=(10,6))\nsns.barplot(x=editions[\"Name\"],y=editions[\"editions\"])\nplt.xticks(rotation=90)\nplt.title(\"TOP TEN BOOKS WITH MAX. NUMBER OF EDITIONS\",fontsize=20)\nplt.show()","e267a1a6":"Authors_with_max_books=df[\"Author\"].value_counts().sort_values()[-10:].reset_index()\nAuthors_with_max_books.columns=[\"Author\",\"Number_of_books\"]\nplt.figure(figsize=(10,6))\nax=sns.barplot(x=Authors_with_max_books[\"Author\"],y=Authors_with_max_books[\"Number_of_books\"])\nplt.xticks(rotation=90)\nplt.title(\"TOP TEN AUTHORS WITH MAX NUMBER OF BOOKS\",fontsize=20)\nplt.show()\n\n\n","4f294f97":"plt.figure(figsize=(10,6))\nax=sns.countplot(df[\"User Rating\"])\nplt.title(\"COUNT OF RATINGS\",fontsize=20)\n\n\n\nfor i in ax.patches:\n    ax.text(i.get_x()+.25,i.get_height()+2.3,str(int((i.get_height()))),\n            rotation=0,fontsize=15,color='black')\n","9bd626f9":"plt.figure(figsize=(10,6))\nsns.histplot(df[\"Reviews\"])\nplt.title(\"DISTRIBUTION OF REVIEWS\")\nplt.show()","943be727":"plt.figure(figsize=(10,6))\nsns.displot(df[\"Price\"])\nplt.title(\"DISTRIBUTION OF PRICE\")\nplt.show()","cd0c339d":"df.head()","a67ed1e6":"ax=sns.countplot(df[\"Genre\"])\n\nfor i in ax.patches:\n    ax.text(i.get_x()+.25,i.get_height()+2.3,str(int((i.get_height()))),\n            rotation=0,fontsize=15,color='black')\n","53160f0a":"top_reviews=df.groupby(df[\"Author\"])[\"Reviews\"].max().sort_values()[-10:].reset_index()\nplt.figure(figsize=(10,6))\nax=sns.barplot(x=top_reviews[\"Author\"],y=top_reviews[\"Reviews\"])\nplt.xticks(rotation=90)\nplt.title(\"TOP TEN AUTHORS WITH HIGHEST NUBER OF REVIEWS\",fontsize=20)\n\nfor i in ax.patches:\n    ax.text(i.get_x()+.25,i.get_height()+2.3,str(int((i.get_height()))))\n            #rotation=0,fontsize=15,color='black')","f46752cd":"print(\"TOP TEN BOOKS WITH HIGHEST RATING\")\ndf.groupby(df[\"Name\"])[\"User Rating\"].max().sort_values()[-10:]","7f85233d":"books_with_high_price=df.groupby(df[\"Name\"])[\"Price\"].max().sort_values()[-10:].reset_index()\nplt.figure(figsize=(10,6))\nax=sns.barplot(x=books_with_high_price[\"Name\"],y=books_with_high_price[\"Price\"])\nplt.xticks(rotation=90)\nplt.title(\"TOP TEN BOOKS WITH HIGHEST PRICE\",fontsize=20)\nfor i in ax.patches:\n    ax.text(i.get_x()+.25,i.get_height()+2.3,str(int((i.get_height()))),\n            rotation=0,fontsize=15,color='black')","ce5e7589":"plt.figure(figsize=(10,6))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","4ce01b1f":"Gen=df[[\"Genre\",\"User Rating\"]].value_counts().reset_index()\nGen.columns=[\"Genre\",\"User Rating\",\"Count\"]\nplt.figure(figsize=(15,7))\nsns.barplot(hue=Gen[\"Genre\"],x=Gen[\"User Rating\"],y=Gen[\"Count\"])\nplt.title(\"BASED ON GENRE COUNT OF RATING\",fontsize=20)\nplt.show()","7b3b7983":"top=df[[\"Name\",\"Price\",\"Author\"]].sort_values(by=\"Price\")[-20:].reset_index()\nplt.figure(figsize=(10,6))\nsns.barplot(x=top[\"Name\"],y=top[\"Price\"],hue=top[\"Author\"])\nplt.xticks(rotation=90)\nplt.title(\"BOOKS WITH HIGH PRICE AND THEIR AUTHORS \",fontsize=20)\nplt.show()\n","176d6b65":"top=df[[\"Name\",\"Reviews\",\"Author\"]].sort_values(by=\"Reviews\")[-20:].reset_index()\nplt.figure(figsize=(10,6))\nsns.barplot(x=top[\"Name\"],y=top[\"Reviews\"],hue=top[\"Author\"])\nplt.xticks(rotation=90)\nplt.title(\"BOOKS WITH HIGHEST REVIEWS AND THEIR AUTHORS \",fontsize=20)\nplt.show()","bca2b08a":"fiction=df[df[\"Genre\"]==\"Fiction\"]\ntop=fiction[[\"Author\",\"Name\",\"Reviews\"]].sort_values(\"Reviews\")[-20:].reset_index()\nplt.figure(figsize=(10,6))\nsns.barplot(x=top[\"Name\"],y=top[\"Reviews\"],hue=top[\"Author\"])\nplt.title(\"TOP FICTION BOOKS WITH AUTHOR AND THEIR REVIEWS\",fontsize=20)\nplt.xticks(rotation=90)\nplt.show()\n","dc11cb3c":"fiction=df[df[\"Genre\"]==\"Non Fiction\"]\ntop=fiction[[\"Author\",\"Name\",\"Reviews\"]].sort_values(\"Reviews\")[-20:].reset_index()\nplt.figure(figsize=(10,6))\nsns.barplot(x=top[\"Name\"],y=top[\"Reviews\"],hue=top[\"Author\"])\nplt.title(\"TOP NON FICTION BOOKS WITH AUTHOR AND THEIR REVIEWS\",fontsize=20)\nplt.xticks(rotation=90)\nplt.show()","a2fb5d17":"from wordcloud import WordCloud, STOPWORDS","dc398982":"imp_words = df['Author'].to_list()\n\nwordcloud = WordCloud(width = 500, height = 500, \n                background_color ='black', \n                min_font_size = 10).generate(str(imp_words))\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","620fbc76":"imp_words = df['Name'].to_list()\n\nwordcloud = WordCloud(width = 500, height = 500, \n                background_color ='black', \n                min_font_size = 10).generate(str(imp_words))\nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \n  \nplt.show()","44a9966a":"#### There are no duplicate values present in the data set:","852dc1da":"## IMPORT LIBRARIES","ed7808ea":"# IF YOU LIKE IT PLEASE UPVOTE::\n## And please let me know the things that i should have add in this notebook:\n","e0bc7823":"## clean the data:","76b7ee09":"## There are around 96 books who have MORE THAN ONE Edition: \n  ","3560a95e":"<img style=\"float: center;\"  src=\"https:\/\/static.amazon.jobs\/business_categories\/15\/thumbnails\/Amazon_Books.jpg?1465411410\" width=\"800px\">","b4afff28":"# Let's do some Analysis:","6d4bc5ea":"#### Also there are no null values present in the data set:","5f7ee002":"## let's get the basic info. about the data set:","dfaa2c85":"## 01. Univariate Analysis:","7577da6f":"### Those are the outliers in the numerical values:\n#### We will ignore them because we aren't building any model:","1835ce96":"## IMPORT DATA-SET:","3120ce53":"## 02. Bivariate Analysis:","22f6a191":"### Lets's check the Outliers:","ac08be21":"# EDA ON AMAZON TOP SELLING BOOKS \ud83d\udcda\ud83d\udcda\ud83d\udcda:","b6f5264d":"## 03.Multivariate Analysis:"}}