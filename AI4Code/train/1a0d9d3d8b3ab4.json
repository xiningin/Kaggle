{"cell_type":{"46f40411":"code","28f52b28":"code","b5bc413f":"code","485bfdd7":"code","09996fac":"code","35484a22":"code","3aeb27c7":"code","d8c9595f":"code","654dcbe0":"code","5ec79f73":"code","0aec8a23":"code","294ef89b":"code","60af021d":"code","e374ca60":"code","1d39c8f0":"code","65756d05":"code","9cfc2d12":"code","901b0e3e":"code","c9696df6":"code","1b8defb8":"code","4ae7b283":"markdown","5c2f3388":"markdown","211a2e7d":"markdown","5884dd5f":"markdown","32747be4":"markdown","7e16ea25":"markdown"},"source":{"46f40411":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nimport os \nimport tqdm\nimport glob\nimport tensorflow \n\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nfrom skimage.color import grey2rgb\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.densenet import DenseNet169\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","28f52b28":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range=30,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   validation_split = 0.2)\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split = 0.2)\n\ntest_datagen  = ImageDataGenerator(rescale = 1.\/255)","b5bc413f":"train_dataset  = train_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n                                                   target_size = (224,224),\n                                                   class_mode = 'categorical',\n                                                   subset = 'training',\n                                                   batch_size = 128)","485bfdd7":"valid_dataset = valid_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/train',\n                                                  target_size = (224,224),\n                                                  class_mode = 'categorical',\n                                                  subset = 'validation',\n                                                  batch_size = 128)","09996fac":"fig, ax = plt.subplots(nrows = 1, ncols = 5, figsize=(20,20))\n\nfor i in tqdm(range(0,5)):\n    rand1 = np.random.randint(len(train_dataset))\n    rand2 = np.random.randint(100)\n    ax[i].imshow(train_dataset[rand1][0][rand2])\n    ax[i].axis('off')\n    a = train_dataset[rand1][1][rand2]\n    if a[0] == 1:\n        ax[i].set_title('Mild Dementia')\n    elif a[1] == 1:\n        ax[i].set_title('Moderate Dementia')\n    elif a[2] == 1:\n        ax[i].set_title('Non Demetia')\n    elif a[3] == 1:\n        ax[i].set_title('Very Mild Dementia')","35484a22":"# Model Initialization\n\nbase_model = DenseNet169(input_shape=(224,224,3), \n                         include_top=False,\n                         weights=\"imagenet\")","3aeb27c7":"# Freezing Layers\n\nfor layer in base_model.layers:\n    layer.trainable=False","d8c9595f":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(2048,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4,activation='softmax'))","654dcbe0":"# Summary\n\nmodel.summary()","5ec79f73":"# Model Compile \n\nOPT    = tensorflow.keras.optimizers.Adam(lr=0.001)\n\nmodel.compile(loss='categorical_crossentropy',\n              metrics=[tensorflow.keras.metrics.AUC(name = 'auc')],\n              optimizer=OPT)","0aec8a23":"# Defining Callbacks\n\nfilepath = '.\/best_weights.hdf5'\n\nearlystopping = EarlyStopping(monitor = 'val_auc', \n                              mode = 'max' , \n                              patience = 15,\n                              verbose = 1)\n\ncheckpoint    = ModelCheckpoint(filepath, \n                                monitor = 'val_auc', \n                                mode='max', \n                                save_best_only=True, \n                                verbose = 1)\n\n\ncallback_list = [earlystopping, checkpoint]","294ef89b":"model_history=model.fit(train_dataset,\n                        validation_data=valid_dataset,\n                        epochs = 500,\n                        callbacks = callback_list,\n                        verbose = 1)","60af021d":"# Summarize history for loss\n\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\nplt.show()","e374ca60":"# Summarize history for loss\n\nplt.plot(model_history.history['auc'])\nplt.plot(model_history.history['val_auc'])\nplt.title('Model AUC')\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\nplt.show()","1d39c8f0":"# Test Data \n\ntest_dataset  = test_datagen.flow_from_directory(directory = '..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test',\n                                                 target_size = (224,224),\n                                                 class_mode = 'categorical',\n                                                 batch_size = 128)","65756d05":"# Evaluating Loss and AUC\n\nmodel.evaluate(test_dataset)","9cfc2d12":"# Test Case 1: Non-Dementia\n\ndic = test_dataset.class_indices\nidc = {k:v for v, k in dic.items()}\n\nimg = load_img('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/NonDemented\/26 (100).jpg', target_size = (224,224,3))\nimg = img_to_array(img)\nimg = img\/255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\nanswer = model.predict_classes(img)\nprobability = round(np.max(model.predict_proba(img)*100),2)\n\nprint(probability, '% chances are there that the image is',idc[answer[0]])","901b0e3e":"# Test Case 2: Mild Demented\n\ndic = test_dataset.class_indices\nidc = {k:v for v, k in dic.items()}\n\nimg = load_img('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/MildDemented\/26 (19).jpg', target_size = (224,224,3))\nimg = img_to_array(img)\nimg = img\/255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\nanswer = model.predict_classes(img)\nprobability = round(np.max(model.predict_proba(img)*100),2)\n\nprint(probability, '% chances are there that the image is',idc[answer[0]])","c9696df6":"# Test Case 3: Moderate Demented\n\ndic = test_dataset.class_indices\nidc = {k:v for v, k in dic.items()}\n\nimg = load_img('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/ModerateDemented\/27 (2).jpg', target_size = (224,224,3))\nimg = img_to_array(img)\nimg = img\/255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\nanswer = model.predict_classes(img)\nprobability = round(np.max(model.predict_proba(img)*100),2)\n\nprint(probability, '% chances are there that the image is',idc[answer[0]])","1b8defb8":"# Test Case 4: Very Mild Demented\n\ndic = test_dataset.class_indices\nidc = {k:v for v, k in dic.items()}\n\nimg = load_img('..\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/test\/VeryMildDemented\/26 (55).jpg', target_size = (224,224,3))\nimg = img_to_array(img)\nimg = img\/255\nimshow(img)\nplt.axis('off')\nimg = np.expand_dims(img,axis=0)\nanswer = model.predict_classes(img)\nprobability = round(np.max(model.predict_proba(img)*100),2)\n\nprint(probability, '% chances are there that the image is',idc[answer[0]])","4ae7b283":"Conclusion:\n\nSo, we have finally built are deep learning model using DenseNet162 transfer learning algorithm and acheived and AUC-90%.","5c2f3388":"> `DATA AUGMENTATION`","211a2e7d":"### MODEL EVALUATION","5884dd5f":"### IMPORT \/ VIEWING \/ PREPROCESSING DATASET","32747be4":"### MODEL BUILDING","7e16ea25":"### IMPORT LIBRARIES"}}