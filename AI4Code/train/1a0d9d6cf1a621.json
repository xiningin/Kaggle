{"cell_type":{"94e02f0a":"code","98b5367f":"code","268e53ad":"code","e5b129a2":"code","e6f68d4f":"code","775bf9ab":"code","41930256":"code","750637c0":"code","35e89054":"code","80d24c87":"code","6e9fd4aa":"code","c263f101":"code","33b76b10":"code","e01ffa73":"code","c76f3989":"code","2464e3f7":"code","36640af0":"code","d04b23ec":"code","443e1cc1":"code","5d1848ad":"code","136c5ac9":"code","7b3de895":"code","e1ed0dab":"code","2b4e144b":"code","4c041844":"code","4e1dd4c1":"code","252c9f9f":"code","72c40b78":"code","ef27b405":"code","140b2b14":"code","1e694b45":"code","9a796e4c":"code","5c264d8e":"code","3a8eb43a":"code","3b24b3d0":"code","f772395b":"code","402a5bfa":"code","89f9fed4":"code","faba8394":"code","981e5522":"code","19963cb7":"code","00f9d983":"code","c54ef10c":"code","0818718c":"code","5f0a7522":"code","88a23f41":"code","213d460f":"code","88855368":"markdown","9e26aca0":"markdown","ae9714ea":"markdown","faab52a0":"markdown","6a3b22ba":"markdown","7a0b081f":"markdown","18fa40b2":"markdown","2cc0796e":"markdown","f96b8b3f":"markdown","0983362c":"markdown","6e2598be":"markdown","ce65b5ff":"markdown","f4ee0a1d":"markdown","327a221d":"markdown","f5523067":"markdown","5f067000":"markdown","9e4c022d":"markdown","cee52f42":"markdown","6cfc1f26":"markdown","9a75da09":"markdown","262be74d":"markdown","7320ab57":"markdown","7a8492f2":"markdown","e38a77de":"markdown","dc7afa23":"markdown","d880a70d":"markdown","88bb360c":"markdown","42a097bb":"markdown","a981064c":"markdown","09c49f4f":"markdown","e30a5b44":"markdown","a372a31c":"markdown","219cfddb":"markdown","e3c83a53":"markdown","35b01180":"markdown","fcc48289":"markdown","5415fe9e":"markdown","8cb06190":"markdown","dcf72b5c":"markdown","023d2c68":"markdown","5d7b4087":"markdown","b137c57e":"markdown","953764ed":"markdown","c585ec14":"markdown"},"source":{"94e02f0a":"#Importando Bibliotecas\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n#Importando os dados para as vari\u00e1veis= pd.readcsv(\"..\/input\/train.csv\")\ntreino =  pd.read_csv('..\/input\/repository\/lucasreism-titanic-em-portugues-bbe38eb\/train.csv')\nteste =  pd.read_csv('..\/input\/repository\/lucasreism-titanic-em-portugues-bbe38eb\/test.csv')\n\n#Colunas Renomeadas\ntreino = treino.rename(columns={'passengerid': 'Passengerid', 'survived': 'Survived', 'pclass': 'Pclass', 'name':'Name', 'sex': 'Sex', 'age': 'Age', 'sibsp': 'Sibsp', 'parch':'Parch','ticket': 'Ticket', 'fare':'Fare', 'cabin': 'Cabin', 'embarked': 'Embarked'})\n\n#Lista que cont\u00e9m nossas matrizes\ntodosdados = [treino,teste]","98b5367f":"#Colunas e informa\u00e7\u00f5es sobre o arquivo Treino\nprint(treino.columns)\nprint('_'*60)\nprint(treino.head(5))\nprint('_'*60)\nprint(treino.tail(5))\nprint('_'*60)\nprint(treino.shape)","268e53ad":"#Colunas e informa\u00e7\u00f5es sobre o arquivo Teste\nprint(teste.columns)\nprint('_'*60)\nprint(teste.head(5))\nprint('_'*60)\nprint(teste.tail(5))\nprint('_'*60)\nprint(teste.shape)","e5b129a2":"#Colunas e informa\u00e7\u00f5es sobre o arquivo Teste\nprint(treino.columns.values)\nprint('_'*60)\ntreino.info()\nprint('_'*60)\nteste.info()","e6f68d4f":"#Dados estat\u00edsticos para an\u00e1lise de colunas num\u00e9ricas\ntreino.describe()","775bf9ab":"#Dados estat\u00edsticos para an\u00e1lise de colunas com texto\ntreino.describe(include=['O'])","41930256":"#Quantidade de dados faltando em cada coluna do arquivo treino\ntreino.isnull().sum()","750637c0":"#treino.plot(kind='scatter', x='Age', y='Passengerid', rot=70)\n#Removendo outlier por Interquartile range : https:\/\/www.itl.nist.gov\/div898\/handbook\/prc\/section1\/prc16.htm\n\ndef remove_outlier(dataset, nome_col):\n    q1 = dataset[nome_col].quantile(0.25)\n    q3 = dataset[nome_col].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    qbaixo  = q1-1.5*iqr\n    qcima = q3+1.5*iqr\n    dataset_saida = dataset.loc[(dataset[nome_col] > qbaixo) & (dataset[nome_col] < qcima)]\n    print(qbaixo)\n    print(qcima)\n    return dataset_saida\n\n\ntreino = remove_outlier(treino, 'Age')\nteste  = remove_outlier(teste, 'Age')\n\n#remover outliers da coluna 'Fare'\ntreino = remove_outlier(treino, 'Fare')\nteste  = remove_outlier(teste, 'Fare')\n\n\n#Foi ultilizada a mediana por raz\u00e3o da distribui\u00e7\u00e3o dos dados 'Age'\n#Preencher os dados faltando com a mediana da idade\nfor dataset in todosdados:\n    dataset['Age'] = dataset['Age'].fillna(dataset['Age'].median())  \n\n##treino.['Age'].transform(lambda s: 1 if s  0 else 0 )    \ntreino.boxplot( column='Age', figsize = (12,8))\n#Temos idades que est\u00e3o com um '0.' na frente\n#Assumindo que as idades com decimal foram retiradas pela diferen\u00e7a do tempo de duas datas\n\n#treino['Age'] = treino['Age'].astype(int)\ntreino.describe()","35e89054":"#Quantidade de dados faltando\ntreino.isnull().sum()","80d24c87":"#Quantidade de dados faltando\nteste.isnull().sum()","6e9fd4aa":"#Retirando as colunas Ticket\ntreino = treino.drop(['Ticket'], axis=1)\nteste = teste.drop(['Ticket'], axis=1)\ntreino.head()\n\n#Observado que falta o pre\u00e7o da passagem da pessoa no dataset Teste que embarcou em Southampton com classe econ\u00f4mica\n#Pegar a mediana de todos os que embarcaram em Southampton com classe econ\u00f4mica\nembarcouS_classe3 = teste['Fare'].loc[(teste['Pclass']==3) & (teste['Embarked']=='S')] + treino['Fare'].loc[(treino['Pclass']==3) & (treino['Embarked']=='S')]\n\n#Preencher o valor com essa mediana\nteste['Fare'] = teste['Fare'].fillna(embarcouS_classe3.median())\n\n#Quantidades de dados faltando\nteste.isnull().sum()","c263f101":"#Dois dados preenchidos com o local de maior frequ\u00eancia\nmais_embarcado = treino['Embarked'].value_counts().index[0]\ntreino['Embarked'] = treino['Embarked'].fillna(mais_embarcado)\ntreino['Embarked'].describe()\n\n#Preenchendo a classe que estava faltando com a classe mais comprada\ntreino['Pclass'] = treino['Pclass'].fillna(treino['Pclass'].median()) \ntreino['Pclass'].value_counts()","33b76b10":"print(treino.Sex.value_counts())\n\n#Todos os t\u00edtulos que est\u00e3o padronizados entre uma virgula e um ponto.\ntreino['New_Sex'] = treino.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n\n#Diccion\u00e1rio Homem\/Mulher\nrelacao_titulo_sex = {\n    \"Capt\":       \"male\",\n    \"Col\":        \"male\",\n    \"Major\":      \"male\",\n    \"Jonkheer\":   \"male\",\n    \"Don\":        \"male\",\n    \"Sir\" :       \"male\",\n    \"Dr\":         \"male\",\n    \"Rev\":        \"male\",\n    \"the Countess\":\"female\",\n    \"Dona\":       \"female\",\n    \"Mme\":        \"female\",\n    \"Mlle\":       \"female\",\n    \"Ms\":         \"female\",\n    \"Mr\" :        \"male\",\n    \"Mrs\" :       \"female\",\n    \"Miss\" :      \"female\",\n    \"Master\" :    \"male\",\n    \"Lady\" :      \"female\"\n}\n\n#Mapeamento da nova coluna pelo dicion\u00e1rio criado acima\ntreino.New_Sex = treino.New_Sex.map(relacao_titulo_sex)\nprint(treino.New_Sex.value_counts())","e01ffa73":"treino['Titulo'] = treino.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\nrelacao_titulo = {\n    \"Capt\":       \"Oficial\",\n    \"Col\":        \"Oficial\",\n    \"Major\":      \"Oficial\",\n    \"Jonkheer\":   \"Realeza\",\n    \"Don\":        \"Realeza\",\n    \"Sir\" :       \"Realeza\",\n    \"Dr\":         \"Oficial\",\n    \"Rev\":        \"Oficial\",\n    \"the Countess\":\"Realeza\",\n    \"Dona\":       \"Realeza\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Realeza\"\n}\n\ntreino['Titulo'] = treino.Titulo.map(relacao_titulo)\n\nteste['Titulo'] = teste.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\n\nteste['Name'] = teste.Titulo.map(relacao_titulo)","c76f3989":"treino.Cabin.fillna('0', inplace=True)\ntreino.loc[treino.Cabin.str[0] == 'A', 'Cabin'] = 1\ntreino.loc[treino.Cabin.str[0] == 'B', 'Cabin'] = 2\ntreino.loc[treino.Cabin.str[0] == 'C', 'Cabin'] = 3\ntreino.loc[treino.Cabin.str[0] == 'D', 'Cabin'] = 4\ntreino.loc[treino.Cabin.str[0] == 'E', 'Cabin'] = 5\ntreino.loc[treino.Cabin.str[0] == 'F', 'Cabin'] = 6\ntreino.loc[treino.Cabin.str[0] == 'G', 'Cabin'] = 7\ntreino.loc[treino.Cabin.str[0] == 'T', 'Cabin'] = 8\n\nteste.Cabin.fillna('0', inplace=True)\nteste.loc[teste.Cabin.str[0] == 'A', 'Cabin'] = 1\nteste.loc[teste.Cabin.str[0] == 'B', 'Cabin'] = 2\nteste.loc[teste.Cabin.str[0] == 'C', 'Cabin'] = 3\nteste.loc[teste.Cabin.str[0] == 'D', 'Cabin'] = 4\nteste.loc[teste.Cabin.str[0] == 'E', 'Cabin'] = 5\nteste.loc[teste.Cabin.str[0] == 'F', 'Cabin'] = 6\nteste.loc[teste.Cabin.str[0] == 'G', 'Cabin'] = 7\nteste.loc[teste.Cabin.str[0] == 'T', 'Cabin'] = 8","2464e3f7":"teste['Family'] = teste['SibSp'] + teste['Parch'] \nteste['Sozinho'] = teste['Family'].map(lambda s: 1 if s == 0 else 0)\nteste['Pequena_familia'] = teste['Family'].map(lambda s: 1 if 1 <= s <= 3 else 0)\nteste['Grande_familia'] = teste['Family'].map(lambda s: 1 if 4 <= s else 0)\n\ntreino['Family'] = treino['Sibsp'] + treino['Parch'] \ntreino['Sozinho'] = treino['Family'].map(lambda s: 1 if s == 0 else 0)\ntreino['Pequena_familia'] = treino['Family'].map(lambda s: 1 if 1 <= s <= 3 else 0)\ntreino['Grande_familia'] = treino['Family'].map(lambda s: 1 if 4 <= s else 0)\ntreino.head()","36640af0":"#Quantidades de dados faltando\ntreino.isnull().sum()","d04b23ec":"#Quantidades de dados faltando\nteste.isnull().sum()","443e1cc1":"treino.info()\nteste.info()","5d1848ad":"sns.barplot(x=\"Cabin\", y=\"Survived\", data=treino,\n            label=\"Cabine vs Taxa de sobreviv\u00eancia\",palette=\"Blues_d\", ci= None)","136c5ac9":"sns.barplot(x= treino['Titulo'] , y=treino['Survived'], palette=\"Blues_d\", ci= None)","7b3de895":"fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(15,10))\n\nsns.barplot(x = 'New_Sex', y = 'Survived', hue = 'Embarked', palette=\"Blues_d\", data=treino, ax = ax1, ci= None)\nax1.set_title('Sexo vs Embarked compara\u00e7\u00e3o de sobreviv\u00eancia')\n\nsns.barplot(x = 'New_Sex', y = 'Survived', hue = 'Pclass',palette=\"Blues_d\", data=treino, ax  =  ax2, ci= None)\nax2.set_title('Sex vs Pclass compara\u00e7\u00e3o de sobreviv\u00eancia')\n\nsns.barplot(x = 'New_Sex', y = 'Survived', hue = 'Sozinho',palette=\"Blues_d\", data=treino, ax  = ax3, ci= None)\nax3.set_title('Sex vs Sozinho compara\u00e7\u00e3o de sobreviv\u00eancia')","e1ed0dab":"sns.pointplot(x=\"Family\", y=\"Survived\", hue=\"New_Sex\", data=treino, palette={\"male\": \"blue\", \"female\": \"c\"}, ci=None)","2b4e144b":"treino.hist(column='Age', figsize = (12,5))","4c041844":"facet = sns.FacetGrid(treino, hue=\"Survived\",aspect=4, height  = 3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.add_legend()","4e1dd4c1":"#Transformaremos a coluna sexo para Masculino: 0 e Feminino:1\nmapeamento_sexo = {'male': 0, 'female':1}\ntreino['New_Sex'] = treino['New_Sex'].map(mapeamento_sexo)\nteste['Sex'] = teste['Sex'].map(mapeamento_sexo)","252c9f9f":"#Transforma\u00e7\u00e3o usando a func\u00e3o 'get_dummies' que nos dar\u00e1 uma coluna para cada valor \u00fanico em cada coluna\ntreino = pd.get_dummies(treino, columns=['Embarked'])\nteste = pd.get_dummies(teste, columns=['Embarked'])\ntreino = pd.get_dummies(treino, columns=['Pclass'])\nteste = pd.get_dummies(teste, columns=['Pclass'])\ntreino = pd.get_dummies(treino, columns=['Titulo'])\nteste = pd.get_dummies(teste, columns=['Titulo'])\n#treino = pd.get_dummies(treino, columns=['Tem_Cabine'])\n#teste = pd.get_dummies(teste, columns=['Tem_Cabine'])\n\n\ntreino.head()","72c40b78":"teste.columns","ef27b405":"treino.columns","140b2b14":"teste = teste.rename(columns={'Sex': 'New_Sex'})\ntreino = treino.rename(columns ={'Sibsp': 'SibSp','Pclass_1.0':'Pclass_1','Pclass_2.0':'Pclass_2', 'Pclass_3.0':'Pclass_3'})\ntreino.head()","1e694b45":"#Precisarei transformar meus valores em tipo 'Float' para classifica\u00e7\u00e3o.\ntreino = treino.astype({'New_Sex': float, 'Embarked_C': float, 'Embarked_Q': float, 'Embarked_S': float, 'Pclass_1': float,\n                        'Pclass_2': float,'Pclass_3': float,'Sozinho': float,'Pequena_familia': float,'Grande_familia': float,\n                        'Titulo_Master': float,'Titulo_Miss': float,'Titulo_Mrs': float,'Titulo_Mr': float,\n                        'Cabin': float })\nteste = teste.astype({'New_Sex': float, 'Embarked_C': float, 'Embarked_Q': float, 'Embarked_S': float, 'Pclass_1': float,\n                        'Pclass_2': float,'Pclass_3': float,'Sozinho': float,'Pequena_familia': float,'Grande_familia': float,\n                        'Titulo_Master': float,'Titulo_Miss': float,'Titulo_Mrs': float,'Titulo_Mr': float,\n                        'Cabin': float })","9a796e4c":"treino.info()","5c264d8e":"x_treino=treino[['Age', 'Fare', 'New_Sex', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                 'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                 'Cabin']]\ny_treino=treino['Survived']\nx_teste=treino[['Age', 'Fare', 'New_Sex', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                'Cabin']]\n\nx_treino, X_teste_A, y_treino, Y_teste_A = train_test_split(treino[['Age', 'Fare', 'New_Sex', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                 'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                 'Cabin']], treino['Survived'], random_state=1, test_size=0.3)\n#Algoritmo de Floresta aleat\u00f3ria\nrnf_A=RandomForestClassifier()\n\n#Aprendizado do algoritmo\nrnf_A.fit(x_treino,y_treino)\n\ny_prever_rnf_A = rnf_A.predict(X_teste_A)\n\n#Pontua\u00e7\u00e3o do algoritmo\nprint(rnf_A.score(x_treino,y_treino))\n\nprint('Accuracy score: {}'.format(accuracy_score(Y_teste_A, y_prever_rnf_A)))\nprint('Precision score: {}'.format(precision_score(Y_teste_A, y_prever_rnf_A)))\nprint('Recall score: {}'.format(recall_score(Y_teste_A, y_prever_rnf_A)))\nprint('F1 score: {}'.format(f1_score(Y_teste_A, y_prever_rnf_A)))","3a8eb43a":"importancia = rnf_A.feature_importances_\nprint(importancia)\ntesteimpo_A = pd.DataFrame ({'Importancia':importancia,'Colunas':x_treino.columns})\nprint(testeimpo_A)\nsns.set(rc={'figure.figsize':(18,12)})\nsns.barplot(x=testeimpo_A['Importancia'],y=testeimpo_A['Colunas'],palette=\"Blues_d\")","3b24b3d0":"conf_matrix_A = confusion_matrix(Y_teste_A, y_prever_rnf_A)\nprint(pd.crosstab(Y_teste_A, y_prever_rnf_A, rownames=['Real'],\n                  colnames=['Predito'], margins=True))","f772395b":"# Colunas para cada var\u00edavel de teste\/ Top 8\nx_treino=treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Titulo_Miss','Titulo_Mrs', 'Cabin']]\ny_treino=treino['Survived']\nx_teste=treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Titulo_Miss','Titulo_Mrs', 'Cabin']]\n\nx_treino, X_teste_8, y_treino, Y_teste_8 = train_test_split(treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Titulo_Miss','Titulo_Mrs', 'Cabin']], treino['Survived'], random_state=1, test_size= 0.3)\n#Algoritmo de Floresta aleat\u00f3ria\nrnf_8=RandomForestClassifier()\n\n#Aprendizado do algoritmo\nrnf_8.fit(x_treino,y_treino)\n\n#Predi\u00e7\u00e3o do algoritmo\ny_prever_rnf_8 = rnf_8.predict(X_teste_8)\n\n#Pontua\u00e7\u00e3o do algoritmo\nprint(rnf_8.score(x_treino,y_treino))\n\nprint('Accuracy score: {}'.format(accuracy_score(Y_teste_8, y_prever_rnf_8)))\nprint('Precision score: {}'.format(precision_score(Y_teste_8, y_prever_rnf_8)))\nprint('Recall score: {}'.format(recall_score(Y_teste_8, y_prever_rnf_8)))\nprint('F1 score: {}'.format(f1_score(Y_teste_8, y_prever_rnf_8)))","402a5bfa":"importancia_8 = rnf_8.feature_importances_\nprint(importancia_8)\ntesteimpo_8 = pd.DataFrame ({'Importancia':importancia_8,'Colunas':x_treino.columns})\nprint(testeimpo_8)\nsns.set(rc={'figure.figsize':(18,12)})\nsns.barplot(x=testeimpo_8['Importancia'],y=testeimpo_8['Colunas'],palette=\"Blues_d\")","89f9fed4":"conf_matrix_8 = confusion_matrix(Y_teste_8, y_prever_rnf_8)\nprint(pd.crosstab(Y_teste_8, y_prever_rnf_8, rownames=['Real'],\n                  colnames=['Predito'], margins=True))","faba8394":"# Colunas para cada var\u00edavel de teste\/ Top 6\nx_treino=treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Cabin']]\ny_treino=treino['Survived']\nx_teste=treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Cabin']]\n\nx_treino, X_teste_6, y_treino, Y_teste_6 = train_test_split(treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Cabin']], treino['Survived'], random_state=1)\n\n#Algoritmo de Floresta aleat\u00f3ria\nrnf_6=RandomForestClassifier()\n\n#Aprendizado do algoritmo\nrnf_6.fit(x_treino,y_treino)\n\n#Predi\u00e7\u00e3o do algoritmo\ny_prever_rnf_6 = rnf_6.predict(X_teste_6)\n\n#Pontua\u00e7\u00e3o do algoritmo\nprint(rnf_6.score(x_treino,y_treino))\n\nprint('Accuracy score: {}'.format(accuracy_score(Y_teste_6, y_prever_rnf_6)))\nprint('Precision score: {}'.format(precision_score(Y_teste_6, y_prever_rnf_6)))\nprint('Recall score: {}'.format(recall_score(Y_teste_6, y_prever_rnf_6)))\nprint('F1 score: {}'.format(f1_score(Y_teste_6, y_prever_rnf_6)))","981e5522":"importancia_6 = rnf_6.feature_importances_\nprint(importancia_6)\ntesteimpo_6 = pd.DataFrame ({'Importancia':importancia_6,'Colunas':x_treino.columns})\nprint(testeimpo_6)\nsns.set(rc={'figure.figsize':(18,12)})\nsns.barplot(x=testeimpo_6['Importancia'],y=testeimpo_6['Colunas'],palette=\"Blues_d\")","19963cb7":"conf_matrix_6 = confusion_matrix(Y_teste_6, y_prever_rnf_6)\nprint(pd.crosstab(Y_teste_6, y_prever_rnf_6, rownames=['Real'],\n                  colnames=['Predito'], margins=True))","00f9d983":"# Colunas para cada var\u00edavel de treino teste final\nx_treino_T=treino[['Age', 'Fare', 'New_Sex', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                 'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                 'Cabin']]\ny_treino_T=treino['Survived']\nx_teste_T=treino[['Age', 'Fare', 'New_Sex', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                 'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                 'Cabin']]\n\n#Algoritmo de Floresta aleat\u00f3ria\nrnf_T=RandomForestClassifier()\n\n#Aprendizado do algoritmo\nrnf_T.fit(x_treino_T, y_treino_T)\n\n#Predi\u00e7\u00e3o do algoritmo\ny_prever_rnf_T = rnf_T.predict(x_teste_T)\n\n#Pontua\u00e7\u00e3o do algoritmo\nprint(rnf_T.score(x_treino_T,y_treino_T))\n\nprint('Accuracy score: {}'.format(accuracy_score(y_treino_T, y_prever_rnf_T)))\nprint('Precision score: {}'.format(precision_score(y_treino_T, y_prever_rnf_T)))\nprint('Recall score: {}'.format(recall_score(y_treino_T, y_prever_rnf_T)))\nprint('F1 score: {}'.format(f1_score(y_treino_T, y_prever_rnf_T)))","c54ef10c":"print(pd.crosstab(y_treino_T, y_prever_rnf_T, rownames=['Real'],\n                  colnames=['Predito'], margins=True))","0818718c":"# Colunas para cada var\u00edavel de treino teste final\nx_treino_T8=treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Titulo_Miss','Titulo_Mrs', 'Cabin']]\ny_treino_T8=treino['Survived']\nx_teste_T8=treino[['Age', 'Fare', 'New_Sex','Pclass_3',\n                 'Titulo_Mr','Titulo_Miss','Titulo_Mrs', 'Cabin']]\n\n#Algoritmo de Floresta aleat\u00f3ria\nrnf_T8=RandomForestClassifier()\n\n#Aprendizado do algoritmo\nrnf_T8.fit(x_treino_T8, y_treino_T8)\n\n#Predi\u00e7\u00e3o do algoritmo\ny_prever_rnf_T8 = rnf_T8.predict(x_teste_T8)\n\n#Pontua\u00e7\u00e3o do algoritmo\nprint(rnf_T8.score(x_treino_T8,y_treino_T8))\n\nprint('Accuracy score: {}'.format(accuracy_score(y_treino_T8, y_prever_rnf_T8)))\nprint('Precision score: {}'.format(precision_score(y_treino_T8, y_prever_rnf_T8)))\nprint('Recall score: {}'.format(recall_score(y_treino_T8, y_prever_rnf_T8)))\nprint('F1 score: {}'.format(f1_score(y_treino_T8, y_prever_rnf_T8)))","5f0a7522":"print(pd.crosstab(y_treino_T8, y_prever_rnf_T8, rownames=['Real'],\n                  colnames=['Predito'], margins=True))","88a23f41":"# Colunas para cada var\u00edavel do modelo final\nx_treino_F=treino[['Age', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                 'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                 'Cabin']]\ny_treino_F=treino['Survived']\nx_teste_F=teste[['Age', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Pclass_1','Pclass_2','Pclass_3',\n                 'Sozinho','Pequena_familia','Grande_familia','Titulo_Master','Titulo_Miss','Titulo_Mrs','Titulo_Mr',\n                 'Cabin']]\n\n#Algoritmo de Floresta aleat\u00f3ria\nrnf_F=RandomForestClassifier()\n\n#Aprendizado do algoritmo\nrnf_F.fit(x_treino_F, y_treino_F)\n\n#Predi\u00e7\u00e3o do algoritmo\ny_prever_rnf_F = rnf_F.predict(x_teste_F)\n\n#Pontua\u00e7\u00e3o do algoritmo\nprint(rnf_F.score(x_treino_F, y_treino_F))","213d460f":"df_teste_rnf = pd.DataFrame({\n        \"PassengerId\": teste[\"PassengerId\"],\n        \"Survived\": y_prever_rnf_F\n         })","88855368":"### 6.4 Teste maior modelo contra ele mesmo","9e26aca0":"### 4.4 Idade","ae9714ea":"Para auxiliar na escolha do modelo usaremos a Matriz de Confus\u00e3o; um layout que permite a visualiza\u00e7\u00e3o do desempenho de um algoritmo, podendo nos dar 4 m\u00e9tricas importantes para qualquer modelo de aprendizado da m\u00e1quina:\n- Precis\u00e3o \n- Acur\u00e1cia\n- Recall\n- F1 Score","faab52a0":"### 3.5 Criando uma nova coluna _T\u00edtulo_\nDo mesmo modo que foi trabalhado no item 3.4, usaremos os t\u00edtulos que conseguimos para an\u00e1lise posterior; faremos outro dicion\u00e1rio onde alguns dos t\u00edtulos ser\u00e3o transformados em \"Oficiais\", para os militares oficiais, e \"Realeza\", para os que faziam parte de alguma casa Real.\n\n\"Situados no teto dos quartos dos oficiais atr\u00e1s da casa do leme, todos os botes, exceto dois, estavam situados no Conv\u00e9s dos Botes, o conv\u00e9s mais alto do Titanic. Eles estavam instalados em cal\u00e7os de madeira nas partes dianteira e traseira do Conv\u00e9s dos Botes, em ambos os lados do navio; dois grupos de tr\u00eas na parte dianteira e dois grupos de quatro na parte traseira.\"","6a3b22ba":"#### An\u00e1lise final para sabermos se falta algum dado a ser preenchido","7a0b081f":"### 4.3 Estar sozinho \u00e9 melhor do que com fam\u00edlia?","18fa40b2":"### 5.1 Covertendo colunas para valores num\u00e9ricos","2cc0796e":"### 3.3 Preenchendo os dados que faltam na coluna _Embarked_ e _Pclass_\nA coluna _Embarked_ do arquivo Treino possui dois dados faltando, como n\u00e3o foi poss\u00edvel achar um padr\u00e3o de pre\u00e7o\/classe para onde cada um embarcou (possivelmente pela data de compra do ticket), ser\u00e1 preenchida a coluna _Embarked_ com o local de maior frequ\u00eancia, Southampton. Na coluna _Pclass_ o mesmo ser\u00e1 realizado.","f96b8b3f":"### 4.1 Localiza\u00e7\u00e3o da Cabine","0983362c":"## 5 Transforma\u00e7\u00f5es\nEm 1959, Arthur Samuel definiu aprendizado de m\u00e1quina como o \"campo de estudo que d\u00e1 aos computadores a habilidade de aprender sem serem explicitamente programados.\" Existem tr\u00eas principais categorias para o aprendizado da m\u00e1quina: aprendizagem supervisionada, n\u00e3o supervisionada e por refor\u00e7o. Usaremos, neste caso, o aprendizado supervisionado.\nProblemas de aprendizagem supervisionada s\u00e3o classificados em problemas de \u201cregress\u00e3o\u201d e \u201cclassifica\u00e7\u00e3o\u201d. Em um problema de classifica\u00e7\u00e3o estamos tentando prever os resultados em uma sa\u00edda discreta. Em outras palavras, estamos procurando mapear vari\u00e1veis de entrada em categorias distintas.Para que o algoritmo funcione da melhor maneira ser\u00e3o feitos simples reparos, criadas e transformadas colunas.","6e2598be":"### 3.6 N\u00famero de S\u00e9rie de Cabine\nAlguns passageiros t\u00eam uma s\u00e9rie para indicar a sua cabine, pelo link abaixo conseguimos ver que existem marca\u00e7\u00f5es de A a T para saber altura e localiza\u00e7\u00e3o das cabines. Ser\u00e1 usada essa s\u00e9rie para descobrir onde cada passageiro estava situado na embarca\u00e7\u00e3o.\n\nA maior parte das instala\u00e7\u00f5es e acomoda\u00e7\u00f5es de Primeira Classe situava-se nos [conveses superiores](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/8\/84\/Titanic_cutaway_diagram.png \"Diagrama Titanic\"), dentro da superestrutura do Titanic, onde as vibra\u00e7\u00f5es e barulhos dos motores eram bem menores. A totalidade do Conv\u00e9s A foi dedicada ao espa\u00e7o de recrea\u00e7\u00e3o e alojamento da Primeira classe, juntamente com a maioria dos conveses B e C. As acomoda\u00e7\u00f5es da Primeira Classe estavam localizadas em todos os n\u00edveis at\u00e9 o Conv\u00e9s F, o que significa que os passageiros da Primeira Classe desfrutavam de mais espa\u00e7o do que qualquer outra classe de passageiros do navio.","ce65b5ff":"Nesta se\u00e7\u00e3o transformaremos as colunas 'New_sex', 'Embarked' e 'Tem_Cabine' para valores num\u00e9ricos, faremos com que elas e as colunas 'Titulo' e 'Pclass' se tornem colunas distintas para cada resposta poss\u00edvel, e que os \u00fanicos valores sejam 1 e 0, representando \"Sim\" ou \"N\u00e3o\", \"True\" ou \"False\".","f4ee0a1d":"Nesta se\u00e7\u00e3o e na que segue testaremos o modelo com todas as caracter\u00edsticas e o modelo Top 8. Os treinaremos com o modelo inteiro e os testaremos procurando prever a pr\u00f3pia coluna _'Survived'_.\nO objetivo deste teste \u00e9 ter maior an\u00e1lise dos modelos e testar a sua probabilidade de estar _overfit_.","327a221d":"## 3 Limpeza e corre\u00e7\u00e3o de dados\n\n### 3.1 Limpando e completando a coluna _Age_\nPara alguns algor\u00edtmos de Machine Learning (aprendizado de m\u00e1quina) a falta de dados faz com que o modelo falhe, e para melhor visualiza\u00e7\u00e3o \u00e9 prefer\u00edvel que estes estejam limpos. Nas vizualiza\u00e7\u00f5es acima \u00e9 poss\u00edvel perceber que existem dados faltando, assim como dados _sujos_. Portanto, \u00e9 importante que estes sejam corrigidos.\nNa coluna _Age_, temos dados faltando e ainda _outliers_ (dados absurdos), completaremos e retiraremos estes.\n\n_\"O preenchimento dos botes salva-vidas come\u00e7ou por volta d\u00e0s 0h20min. O segundo oficial Lightoller se dirigiu ao capit\u00e3o e sugeriu que a evacua\u00e7\u00e3o fosse iniciada com as mulheres e crian\u00e7as. Smith, ainda em estado de paralisia, concordou com a cabe\u00e7a e disse \"coloque as mulheres e crian\u00e7as e abaixe-os\". Lightoller assumiu o lan\u00e7amento dos botes no lado bombordo enquanto Murdoch ficou encarregado do lado estibordo. Entretanto, os dois homens interpretaram as ordens de maneira diferente: o primeiro oficial entendeu que eram mulheres e crian\u00e7as primeiro, enquanto o segundo oficial presumiu que eram mulheres e crian\u00e7as apenas. Dessa forma, Lightoller lan\u00e7ava seus botes caso n\u00e3o houvesse nenhuma mulher por perto para embarcar, enquanto Murdoch por sua vez permitia a entrada de homens depois de embarcadas todas as mulheres e crian\u00e7as. Nenhum dos dois sabia a capacidade exata dos barcos e temeram superlot\u00e1-los, assim v\u00e1rios botes foram abaixados com menos da metade de sua capacidade total.\"_","f5523067":"Para melhor categorizar, essas colunas ser\u00e3o criadas de acordo com o n\u00famero de membros familiares que os passageiros possu\u00edam a bordo:\n- Family \u00e9 a quantidade de familiares\n- Sozinho se o passageiro estava sozinho a bordo\n- Pequena_familia se o passageiro tinha entre 1 a 3 familiares\n- Grande_familia se o passageiro possuia 4 ou mais familiares","5f067000":"### 3.2 Completando a coluna _Fare_ e removendo as colunas _Ticket_ \nA coluna _Ticket_ n\u00e3o apresentou padr\u00e3o que nos ajude na aplica\u00e7\u00e3o do projeto, portanto, ser\u00e1 removida.\n\nPara a coluna _Fare_, no arquivo Teste, percebe-se que h\u00e1 um pre\u00e7o faltando; este passageiro comprou um ticket para Classe Econ\u00f4mica e embarcou em Southampton, assim, ser\u00e1 usada a mediana do valor dos demais passageiros com as mesmas caracter\u00edsticas de embarque, e preenchido o seu com esta mediana.","9e4c022d":"### 6.6 Modelo Final","cee52f42":"Renomearemos algumas colunas nescess\u00e1rias para o uso do algoritmo.","6cfc1f26":"Podemos ver no gr\u00e1fico acima quais foram as colunas com maior import\u00e2ncia no modelo anterior, ent\u00e3o selecionando essas 8 vari\u00e1veis \u00e9 poss\u00edvel tentar manter ou melhorar a acur\u00e1cia com menor n\u00famero de colunas.","9a75da09":"_\"Por fim, a terceira classe era onde estavam os imigrantes. Eram pessoas que muitas vezes viajavam em grandes grupos familiares de at\u00e9 doze membros. Eles vinham de diferentes partes da Europa como Escandin\u00e1via, Leste Europeu, Irlanda e at\u00e9 mesmo da \u00c1sia.\"_","262be74d":"### 5.2 Renomeando colunas","7320ab57":"### 6.5 Teste Top 8 contra ele mesmo","7a8492f2":"Podemos observar com este gr\u00e1fico que mulheres com mais de 3 familiares na embarca\u00e7\u00e3o tendem a menor chance de sobreviv\u00eancia, assim como homens sozinhos e com at\u00e9 3 familiares tendem a maior chance de sobreviv\u00eancia.","e38a77de":"Antes de rodar nosso algoritmo com o arquivo Teste, faremos algumas tentativas com o pr\u00f3pio arquivo Treino.\nPrimeiramente usaremos a fun\u00e7\u00e3o 'train_test_split()' do sklearn, que faz com que o arquivo seja dividido em 70% do conjunto de dados para realmente treinar o algoritmo e 30% desse conjunto para test\u00e1-lo.\nPor j\u00e1 possuir os resultados deste arquivo, conseguiremos medir acur\u00e1cia, precis\u00e3o, recall e pontua\u00e7\u00e3o de F1, essas 4 caracter\u00edsticas ir\u00e3o ajudar a 'afinar' o algoritmo.","dc7afa23":"Tentaremos agora utilizar as 6 categorias mais importantes.","d880a70d":"## 7 Conclus\u00e3o","88bb360c":"### 6.1 Todas Caracter\u00edsticas","42a097bb":"_\"Os comiss\u00e1rios de bordo logo foram bater de porta em porta chamando os passageiros e pedindo para que eles fossem para o conv\u00e9s dos botes. O tratamento recebido dependia da posi\u00e7\u00e3o social; os comiss\u00e1rios da primeira classe cuidavam cada um de apenas algumas cabines, ent\u00e3o eles podiam ajudar os passageiros a se vestirem e irem para o conv\u00e9s, enquanto os comiss\u00e1rios da segunda e terceira classe tinham de percorrer v\u00e1rias cabines rapidamente, rudemente acordar os passageiros e mand\u00e1-los colocarem coletes salva-vidas.\"_","a981064c":"### 3.7 Criando novas colunas Family, Sozinho, Pequena_familia, Grande_familia","09c49f4f":"### 4.2 Titulo \/ Sobreviv\u00eancia","e30a5b44":"## 4 An\u00e1lise com visualiza\u00e7\u00e3o e estat\u00edstica\n","a372a31c":"### 4.2 Sexo importa","219cfddb":"## 6 Aplica\u00e7\u00e3o do algoritmo","e3c83a53":"Nestre trabalho foi realizada a limpeza, corre\u00e7\u00e3o e transforma\u00e7\u00e3o de dados. Foi feito remo\u00e7\u00e3o de outliers e preenchimento de dados faltantes para melhor an\u00e1lise posterior. Na constru\u00e7\u00e3o do modelo tamb\u00e9m foi avaliada a sele\u00e7\u00e3o de features, realizado um top 8 e top 6 para poder, em um futuro, nos dar um melhor retorno com maior n\u00famero de dados.\nAn\u00e1lisando o gr\u00e1fico 4.1 percebemos o quanto a localiza\u00e7\u00e3o das cabines influencia na taxa de sobreviv\u00eancia. Percebemos com o gr\u00e1fico 4.2 que as mulheres, n\u00e3o importando idade ou localiza\u00e7\u00e3o, tinham chances muito maiores de sobreviv\u00eancia do que os homems. De acordo com o segundo gr\u00e1fico do 4.4 observamos a faixa et\u00e1ria com maior chance de sobreviv\u00eancia.","35b01180":"Lembrando que a coluna Sex foi substitu\u00edda por New_Sex ","fcc48289":"## 8 Refer\u00eancias\n- [RMS Titanic](https:\/\/pt.wikipedia.org\/wiki\/RMS_Titanic).\n- [Botes salva-vidas do RMS Titanic](https:\/\/pt.wikipedia.org\/wiki\/Botes_salva-vidas_do_RMS_Titanic).\n- [Titanic by History](https:\/\/www.history.com\/topics\/early-20th-century-us\/titanic).","5415fe9e":"_\"O n\u00famero exato de mortos no naufr\u00e1gio \u00e9 incerto devido a v\u00e1rios fatores, como confus\u00e3o sobre a lista de passageiros, que inclu\u00eda nomes de pessoas que cancelaram a viagem no \u00faltimo momento e o fato de alguns passageiros terem embarcado sob pseud\u00f4nimos.\"_","8cb06190":"### 6.2 Top 8","dcf72b5c":"## 2 Primeiro contato com os dados\n### 2.1 Importar bibliotecas e dados\nO c\u00f3digo foi inteiramente escrito em Python 3, usaremos algumas bibliotecas muito conhecidas na \u00e1rea de Ci\u00eancia de dados:\n- Numpy para matrizes multidimensionais\n- Pandas para manipula\u00e7\u00e3o e an\u00e1lise de dados\n- Matplotlib e Seaborn para visualiza\u00e7\u00e3o de dados\n- Scikit-learn para modelos de Machine Learning\n\nOs dados foram importados em duas vari\u00e1veis: Treino, referente ao primeiro arquivo, e Teste, referente ao segundo.\nColunas renomeadas para melhorar a leitura e para padronizar ambos os arquivos.","023d2c68":"### 3.4 Limpando e Preenchendo a coluna _Sex_\nFoi verificado que a coluna _Sex_ possui 12 vari\u00e1veis \u00fanicas, sabemos que deveria apresentar 2 (Homem ou Mulher), ainda foi visto que possui 46 dados faltantes.\nPara preencher e limpar a coluna _Sex_ usaremos o nome e t\u00edtulo de cada passageiro. Para isso, criaremos uma nova coluna chamada __New_Sex__, qual ser\u00e1 usada daqui para frente em todas vizualiza\u00e7\u00f5es e modelos preditivos. Foi criado um dicion\u00e1rio para completar, de acordo com o seu t\u00edtulo, o sexo como masculino ou feminino.","5d7b4087":"### 6.3 Top 6","b137c57e":"Por ser um algoritmo que trabalha bem com v\u00e1rias categorias, ser conhecido por n\u00e3o possuir muito overfit e por trabalhar bem com atributos de diferentes escalas foi escolhido o Random Forest (floresta aleat\u00f3ria). Aplicaremos o algoritmo e o testaremos tentando descobrir o pr\u00f3prio conjunto de dados do arquivo Treino, e assim verificar se a sua sa\u00edda condiz com a realidade.\n\nUma \u00f3tima maneira de analisar o projeto \u00e9 observar a import\u00e2ncia de cada coluna para o resultado final do algoritmo, ent\u00e3o plotaremos um gr\u00e1fico de barras para verificar se a import\u00e2ncia de cada coluna condiz com as informa\u00e7\u00f5es que temos e aprender mais sobre o conjunto de dados.","953764ed":"# Projeto Titanic em portugu\u00eas para brasileiros\n## 1 Introdu\u00e7\u00e3o\n\n__Dados coletados:__ Foram enviados dois arquivos, um contendo um conjunto de dados com informa\u00e7\u00f5es de 936 passageiros (train.csv) e um para testes, contendo os dados de 418 passageiros(test.csv). O primeiro possui uma coluna que nos informa se o passageiro sobreviveu ou n\u00e3o, no segundo esta coluna deve ser prevista com o algoritmo proposto.","c585ec14":"### 2.2 Conhecendo os dados\nEm nossas colunas teremos as v\u00e1riaveis descritas a seguir:\n\nSurvived:\n  * Se o passageiro sobreviveu ou n\u00e3o\n  * Valores poss\u00edveis:\n    0 = N\u00e3o\n    1 = Sim\n\nPclass:\n  * classe da Passagem no navio\n  * Valores poss\u00edveis:\n    1 = primeira classe,\n    2 = classe executiva,\n    3 = classe econ\u00f4mica\n\nSex:\n  * O g\u00eanero do passageiro\n\nAge:\n  * Idade em anos\n\nSibSp\n  * N\u00famero de irmaos\/companheiros dentro do navio\n\nParch:\n  * N\u00famero de parentes e filhos no navio\n\nTicket:\n  * C\u00f3digo da passagem\n\nFare:\n  * Valor da passagem\n\nCabin:\n  * N\u00famero da cabine\n\nEmbarked:\n  * Local onde embarcou no Titanic\n  * Poss\u00edveis valores: \n    C = Cherbourg,\n    Q = Queenstown,\n    S = Southampton"}}