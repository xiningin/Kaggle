{"cell_type":{"3f6bc29d":"code","b666bd41":"code","528cc96c":"code","df324a59":"code","b5bc52c4":"code","1e99914f":"code","ceabd697":"code","d16f12c2":"code","7fd14023":"code","b503e1a0":"code","1638f69a":"code","48132029":"code","0c60ab9e":"code","5d94c096":"code","5aa39972":"code","394a69e4":"code","9554226b":"code","91a9d228":"code","9cffbf03":"code","108e5a9c":"code","ab36c7f5":"code","ee0751fe":"code","acaaa4db":"code","1ecfb7bc":"code","71e9c6cc":"code","cafbf274":"code","4d75c328":"code","b5605232":"code","5dfb1dfe":"code","c3b2d6e3":"code","571c7385":"code","3050bdf9":"code","737fa8f1":"code","b7e02d0d":"code","5da9c6d6":"code","08c2a15e":"code","5df790e5":"code","6442e72f":"code","56c6b9d2":"code","d38889a8":"code","0286f49a":"code","bfc711cd":"code","0248dca4":"code","45e14a73":"code","049b581e":"code","7b3fee65":"code","a8f7556e":"code","ba64726d":"code","d24ffb8d":"code","f080a5b5":"code","5ab77a7e":"code","14f5e577":"code","0618a2b4":"code","5bd3f083":"code","0949a3b7":"code","6e28ea71":"code","bf0d019c":"code","672b27de":"code","4b8a48cb":"code","6435cfd9":"code","0ecb9ec4":"code","ddae848e":"code","fea853e4":"code","2ab8be11":"code","d94a624c":"code","f59e1307":"code","f5473dd6":"code","266d9da7":"code","cec9766f":"code","c9cdeb64":"code","0dd1dd1a":"code","1fd34f58":"code","8bc45348":"code","22331158":"code","3a7a0485":"code","a50ef1a4":"code","34d69521":"code","c8c364e0":"code","2de8fc7a":"code","dba2f79e":"code","65e46813":"code","e9e70a80":"code","09354403":"code","d7f29d74":"code","0bef7f0c":"code","f94beaeb":"code","6e0b61ff":"code","8fc98bed":"code","a34c21c4":"code","d56c9734":"code","e12c32ee":"code","f76e3ee3":"code","f0761bd9":"code","0441821e":"code","b042eea3":"code","349b36c8":"code","8e726845":"code","f369e882":"code","01d22806":"code","45f70525":"code","efb7ee01":"code","9fb734a7":"code","169a5b45":"code","5bf1a048":"code","5a78e359":"code","a5038523":"code","b41dc6cd":"code","78e0c6c0":"code","9f6e0ed9":"code","94f34e08":"code","64e52d15":"code","2d182b43":"code","b5df5610":"code","f5d3e6d2":"code","56cd72f0":"code","d4e5594c":"code","d394b4cf":"code","16f625ac":"code","8f75154c":"code","5987de3e":"code","f2ffea12":"code","940713a0":"code","a081a281":"code","0e0fadef":"code","625b4deb":"code","4953d862":"code","ec967360":"code","5794d773":"markdown","998e299a":"markdown","e263b59e":"markdown","602ce540":"markdown","3bd93a20":"markdown","8095bb1f":"markdown","9f3572f0":"markdown","d92976ea":"markdown","930debd9":"markdown","f061b38d":"markdown","9355e361":"markdown","c834bd37":"markdown","83706f52":"markdown","8783224b":"markdown","6085c665":"markdown","34419e99":"markdown","3b226737":"markdown","7410519b":"markdown","f932d346":"markdown","d85b9dd1":"markdown","0bc0d64d":"markdown","babb8c73":"markdown","f6e5fbb7":"markdown","41756356":"markdown","bb0e9b23":"markdown","90ad431f":"markdown","bd6b53a6":"markdown","1b2828b8":"markdown","3cd3b8c5":"markdown","eeca892d":"markdown","67236a6b":"markdown","18bcb74a":"markdown","d057799d":"markdown","45169dfc":"markdown","c53bbefc":"markdown","ac4d70b0":"markdown","f1b712ec":"markdown","350da76d":"markdown","d747cb05":"markdown","472f6ad2":"markdown","604f3862":"markdown","2ced81d9":"markdown","240a2eee":"markdown","173345ed":"markdown","97d1dfb1":"markdown","e88a45ae":"markdown","1c851f7a":"markdown"},"source":{"3f6bc29d":"import os\nimport numpy as np\nimport pandas as pd\nimport spacy\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set\n%matplotlib inline","b666bd41":"df_train = pd.read_csv(os.path.join('..', 'input', 'train.csv'))\ndf_test = pd.read_csv(os.path.join('..', 'input', 'test.csv'))","528cc96c":"df_train.head()","df324a59":"df_train.shape, df_test.shape","b5bc52c4":"df_train.info()","1e99914f":"df_train['target'].value_counts().plot(kind='bar');","ceabd697":"insincere_ratio = (80810 \/ 1225312) * 100\ninsincere_ratio","d16f12c2":"y = df_train['target']\nX = df_train['question_text']","7fd14023":"X_insincere = X[y == 1]\nX_insincere.head()","b503e1a0":"X_sincere = X[y == 0]\nX_sincere.head()","1638f69a":"from nltk.tokenize import word_tokenize","48132029":"corpus = [word_tokenize(token) for token in X]","0c60ab9e":"lowercase_train = [[token.lower() for token in doc] for doc in corpus]","5d94c096":"alphas = [[token for token in doc if token.isalpha()] for doc in lowercase_train]","5aa39972":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')","394a69e4":"train_no_stop = [[token for token in doc if token not in stop_words] for doc in alphas]","9554226b":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\nstemmed = [[stemmer.stem(token) for token in doc] for doc in train_no_stop]","91a9d228":"train_clean_str = [ ' '.join(doc) for doc in stemmed]","9cffbf03":"nb_words = [len(tokens) for tokens in alphas]","108e5a9c":"alphas_unique = [set(doc) for doc in alphas]","ab36c7f5":"nb_words_unique = [len(doc) for doc in alphas_unique]","ee0751fe":"train_str = [ ' '.join(doc) for doc in lowercase_train]","acaaa4db":"nb_characters = [len(doc) for doc in train_str]","1ecfb7bc":"train_stopwords = [[token for token in doc if token in stop_words] for doc in alphas]","71e9c6cc":"nb_stopwords = [len(doc) for doc in train_stopwords]","cafbf274":"non_alphas = [[token for token in doc if token.isalpha() == False] for doc in lowercase_train]","4d75c328":"nb_punctuation = [len(doc) for doc in non_alphas]","b5605232":"train_title = [[token for token in doc if token.istitle() == True] for doc in corpus]","5dfb1dfe":"nb_title = [len(doc) for doc in train_title]","c3b2d6e3":"df_clean = pd.DataFrame(data={'text_clean': train_clean_str})\ndf_clean.head()","571c7385":"nb_words = pd.Series(nb_words)\nnb_words_unique = pd.Series(nb_words_unique)\nnb_characters = pd.Series(nb_characters)\nnb_stopwords = pd.Series(nb_stopwords)\nnb_punctuation = pd.Series(nb_punctuation)\nnb_title = pd.Series(nb_title)","3050bdf9":"df_show = pd.concat([df_clean, nb_words, nb_words_unique, nb_characters, nb_stopwords, nb_punctuation, nb_title], axis=1).rename(columns={\n    0: \"Number of words\", 1: 'Number of unique words', 2: 'Number of characters', 3: 'Number of stopwords', 4: 'Number of punctuations',\n    5: 'Number of titlecase words'\n})\ndf_show.head()","737fa8f1":"df_feat = df_show.drop(['text_clean'], axis=1)\ndf_feat.head()","b7e02d0d":"df_feat.info()","5da9c6d6":"from nltk.tokenize import word_tokenize","08c2a15e":"%%time\ncorpus_insincere = [word_tokenize(t) for t in X_insincere]","5df790e5":"lowercase = [[t.lower() for t in doc] for doc in corpus_insincere]","6442e72f":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')","56c6b9d2":"no_stops = [[t for t in doc if t not in stop_words] for doc in lowercase]","d38889a8":"alphas_insincere = [[token for token in doc if token.isalpha()] for doc in no_stops]","0286f49a":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\nstemmed_insincere = [[stemmer.stem(token) for token in doc] for doc in alphas_insincere]","bfc711cd":"nb_words_insincere_nostop = [len(tokens) for tokens in no_stops]","0248dca4":"avg_nostop = np.mean(nb_words_insincere_nostop)\navg_nostop","45e14a73":"nb_words_insincere_stop = [len(tokens) for tokens in lowercase]\navg_stop = np.mean(nb_words_insincere_stop)\navg_stop","049b581e":"np.median(nb_words_insincere_nostop)","7b3fee65":"np.median(nb_words_insincere_stop)","a8f7556e":"nb_words_insincere_stop = pd.Series(nb_words_insincere_stop)\nnb_words_insincere_nostop = pd.Series(nb_words_insincere_nostop)","ba64726d":"df_insincere =  pd.DataFrame(X_insincere)","d24ffb8d":"df_insincere.info()","f080a5b5":"df_insincere = pd.concat([X_insincere.reset_index(), nb_words_insincere_nostop, nb_words_insincere_stop], axis=1).set_index('index').rename(columns={\n    0: \"nb_words_no_stop\", 1: 'nb_words_stop'\n})\ndf_insincere.head()","5ab77a7e":"#plt.hist(nb_words_insincere_nostop, bins=30)\n#plt.hist(nb_words_insincere_stop, bins=30)\nsns.distplot(np.log1p(nb_words_insincere_nostop), kde=False, label=\"No stop\")\nsns.distplot(np.log1p(nb_words_insincere_stop), kde=False, label=\"Stop\")\nplt.legend();","14f5e577":"sns.distplot(nb_words_insincere_stop, hist=False, color='red', label='Stop')\nsns.distplot(nb_words_insincere_nostop, hist=False, color='blue', label='No stop')\nplt.legend();","0618a2b4":"from collections import defaultdict\n\ncounter = defaultdict(int)\nfor doc in alphas_insincere:\n    for token in doc:\n        counter[token] += 1\n\nfrom collections import Counter\n\nc = Counter(counter)\n\nc.most_common(10)","5bd3f083":"corpus_sincere = [word_tokenize(t) for t in X_sincere]","0949a3b7":"lowercase_sincere = [[t.lower() for t in doc] for doc in corpus_sincere]","6e28ea71":"no_stop_sincere = [[t for t in doc if t not in stop_words] for doc in lowercase_sincere]","bf0d019c":"alphas_sincere = [[token for token in doc if token.isalpha()] for doc in no_stop_sincere]","672b27de":"nb_words_sincere_nostop = [len(t) for t in no_stop_sincere]","4b8a48cb":"avg_words_sincere_nostop = np.mean(nb_words_sincere_nostop)\navg_words_sincere_nostop","6435cfd9":"nb_words_sincere_stop = [len(t) for t in lowercase_sincere]\navg_words_sincere = np.mean(nb_words_sincere_stop)\navg_words_sincere","0ecb9ec4":"np.median(nb_words_sincere_nostop)","ddae848e":"np.median(nb_words_sincere_stop)","fea853e4":"nb_words_sincere_stop = pd.Series(nb_words_sincere_stop)\nnb_words_sincere_nostop = pd.Series(nb_words_sincere_nostop)","2ab8be11":"df_sincere =  pd.DataFrame(X_sincere)","d94a624c":"df_sincere.info()","f59e1307":"df_sincere = pd.concat([X_sincere.reset_index(), nb_words_sincere_nostop, nb_words_sincere_stop], axis=1).set_index('index').rename(columns={\n    0: \"nb_words_no_stop\", 1: 'nb_words_stop'\n})\ndf_sincere.head()","f5473dd6":"from collections import defaultdict\n\ncounter_sincere = defaultdict(int)\nfor doc in alphas_sincere:\n    for token in doc:\n        counter[token] += 1\n\nfrom collections import Counter\n\nc_sincere = Counter(counter)\n\nc_sincere.most_common(10)","266d9da7":"from gensim import corpora\ndictionary = corpora.Dictionary(alphas_insincere)","cec9766f":"corpus_1 = [dictionary.doc2bow(t) for t in alphas_insincere]","c9cdeb64":"from gensim.models.ldamodel import LdaModel","0dd1dd1a":"%%time\nlda_model = LdaModel(\n    corpus=corpus_1, id2word=dictionary, num_topics=4, random_state=42)","1fd34f58":"from pprint import pprint\npprint(lda_model.print_topics())","8bc45348":"%%time\nlda_model_1 = LdaModel(\n    corpus=corpus_1, id2word=dictionary, num_topics=4, random_state=42, iterations=10)","22331158":"from pprint import pprint\npprint(lda_model_1.print_topics())","3a7a0485":"import pyLDAvis.gensim","a50ef1a4":"pyLDAvis.enable_notebook()","34d69521":"pyLDAvis.gensim.prepare(lda_model, corpus_1, dictionary)","c8c364e0":"pyLDAvis.gensim.prepare(lda_model_1, corpus_1, dictionary)","2de8fc7a":"weight_topic = lda_model_1.top_topics(corpus=corpus_1, dictionary=dictionary, topn=30)","dba2f79e":"politic, religion, sex, america = weight_topic","65e46813":"politic = politic[0]\npolitic = [tup[1] for tup in politic]\npolitic","e9e70a80":"religion = religion[0]\nreligion = [tup[1] for tup in religion]\nreligion","09354403":"sex = sex[0]\nsex = [tup[1] for tup in sex]\nsex","d7f29d74":"america = america[0]\namerica = [tup[1] for tup in america]\namerica","0bef7f0c":"y_labeled = []","f94beaeb":"for doc in train_no_stop:\n    counter = 0\n    for word in doc:\n        if word in politic or word in religion or word in sex or word in america:\n            counter += 1\n    if counter >= 3:\n        y_labeled.append(1)\n    else:\n        y_labeled.append(0)\n        ","6e0b61ff":"y_labeled[:10]","8fc98bed":"y_labeled = pd.Series(y_labeled)\ny_labeled[:3]","a34c21c4":"df_feat['y_topic_labeled'] = y_labeled","d56c9734":"df_show['y_topic_labeled'] = y_labeled","e12c32ee":"df_feat.head()","f76e3ee3":"df_feat['y_topic_labeled'].value_counts()","f0761bd9":"df_show.head()","0441821e":"from sklearn.model_selection import train_test_split","b042eea3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","349b36c8":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","8e726845":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer","f369e882":"tvec = TfidfVectorizer(stop_words='english')","01d22806":"tf = tvec.fit_transform(X_train)\ntf","45f70525":"cvec = CountVectorizer(stop_words='english')","efb7ee01":"from sklearn.decomposition import TruncatedSVD","9fb734a7":"svd = TruncatedSVD(n_components=100, random_state=42)","169a5b45":"from sklearn.pipeline import Pipeline","5bf1a048":"preprocessing_pipeline = Pipeline([('tvec', tvec), ('svd', svd)])","5a78e359":"preprocessing_pipeline.fit_transform(X_train)","a5038523":"from sklearn.metrics import confusion_matrix, classification_report","b41dc6cd":"from sklearn.naive_bayes import MultinomialNB","78e0c6c0":"mnb = MultinomialNB()","9f6e0ed9":"pipe_mnb = Pipeline([('vectorizer', cvec), ('mnb', mnb)])","94f34e08":"pipe_mnb.fit(X_train, y_train)","64e52d15":"y_pred_mnb = pipe_mnb.predict(X_test)\ny_pred_mnb","2d182b43":"cm = confusion_matrix(y_test, y_pred_mnb)\ncm","b5df5610":"cr = classification_report(y_test, y_pred_mnb)\nprint(cr)","f5d3e6d2":"from sklearn.ensemble import RandomForestClassifier","56cd72f0":"rf = RandomForestClassifier()","d4e5594c":"#pipe_rf = Pipeline([('vectorizer', tvec), ('rf', rf)])","d394b4cf":"#pipe_rf.fit(X_train, y_train)","16f625ac":"#y_pred = pipe_rf.predict(X_test)\n#y_pred","8f75154c":"#cm = confusion_matrix(y_test, y_pred)\n#cm","5987de3e":"#cr = classification_report(y_test, y_pred)\n#print(cr)","f2ffea12":"from sklearn.linear_model import LogisticRegression","940713a0":"lr = LogisticRegression()","a081a281":"pipe_lr = Pipeline([('vectorizer', cvec), ('lr', lr)])","0e0fadef":"pipe_lr.fit(X_train, y_train)","625b4deb":"y_pred_lr = pipe_lr.predict(X_test)\ny_pred_lr","4953d862":"cm = confusion_matrix(y_test, y_pred_lr)\ncm","ec967360":"cr = classification_report(y_test, y_pred_lr)\nprint(cr)","5794d773":"Our goal is to determine most common topics among the insincere questions.\n\nFirst, we use our tokenized document that has been preprocessed.","998e299a":"For now, this represents too much data to visualise. We'll start with the insincere one.","e263b59e":"# Load the dataset","602ce540":"## EDA on the X_sincere","3bd93a20":"Average number of words per insincere question ","8095bb1f":"## Over our raw questions","9f3572f0":"**6)** Number of title case words","d92976ea":"**5)** Number of punctuations","930debd9":"### Logistic Regression","f061b38d":"## Preprocessing","9355e361":"Let's tokenize our document","c834bd37":"# Topic Modeling","83706f52":"# Preprocessing","8783224b":"**2)** Number of unique words","6085c665":"## Latent Semantic Analysis","34419e99":"The average number of words within the insincere questions is around **11 words** (without the stop_words) and **19 words** with the stop_words.\nLet's compare it with the proper questions.","3b226737":"**Counting the ten most common words in the insincere questiosn**","7410519b":"**1)** Number of words","f932d346":"Then we use Gensim to achieve our LSA.","d85b9dd1":"# Import","0bc0d64d":"# Machine Learning","babb8c73":"# Look at the dataset","f6e5fbb7":"Lowercase all the words","41756356":"# New Dataframe with features","bb0e9b23":"The data is clean, there is no Naan values","90ad431f":"### TfidfVectorizer","bd6b53a6":"## on X","1b2828b8":"### CountVectorizer","3cd3b8c5":"### Random Forest","eeca892d":"Remove stop words","67236a6b":"## Machine learning models","18bcb74a":"**4)** Number of stopwords","d057799d":"### MultinomialNB","45169dfc":"Whereas within the sincere question, the questions are legit.","c53bbefc":"We can already notice the troll content within the questions.","ac4d70b0":"Stem the words","f1b712ec":"**3)** Number of characters","350da76d":" We will now add  a new feature to check whether a question contains at least 2 words of a topic to tag it insincere.","d747cb05":"Remove non-alpha-numerical caracters","472f6ad2":"### Preprocessing pipeline","604f3862":"### Truncated SVD","2ced81d9":"The average number of words within the sincere questions is around **8 words** (without the stop_words) and **14 words** with the stop_words. Let's compare it with the proper questions.","240a2eee":"## EDA on the X_insincere","173345ed":"## Features ","97d1dfb1":"We'll try to combine two models : \n\n1) First, we will process over our raw document as intermediate predictions.\n\n\n2) Secondly, we will add our predictions as a new feature in our dataframe features and try ML models over them.","e88a45ae":"Show the length of \"insincere\" sentence ","1c851f7a":"**Counting the ten most common words in the sincere questiosn**"}}