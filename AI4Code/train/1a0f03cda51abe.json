{"cell_type":{"a323b821":"code","ddffa599":"code","234d13a3":"code","92621f89":"code","92a8ff48":"code","78871644":"code","36e1cc2c":"code","29495020":"markdown"},"source":{"a323b821":"import numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import pairwise_distances_chunked","ddffa599":"COMPUTE_CV = True\n\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n\nif len(test)>3: COMPUTE_CV = False\n    \nif COMPUTE_CV:\n    train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    print('train shape is', train.shape )\n    train.head()\n    \nelse:\n    train = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n","234d13a3":"print('Computing text embeddings...')\nvectorizer = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntrain_embeddings = vectorizer.fit_transform(train['title'])\nprint('text embeddings shape',train_embeddings.shape)","92621f89":"preds1=[]\nr = 0.45\nstart=0\nend=0\n\ndef reduce_func(D_chunk, start):\n    neigh = [np.flatnonzero(d < r) for d in D_chunk]\n    return neigh\n\n\nfor neigh in pairwise_distances_chunked(train_embeddings, reduce_func=reduce_func, metric='cosine',n_jobs=-1):\n    start+=end\n    end+=len(neigh)\n    print(f'chuck {start} to {end}')\n    for i in range(len(neigh)):\n        o = train.iloc[neigh[i]].posting_id.values\n        preds1.append(o)\n\ntrain['preds1']=preds1","92a8ff48":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['preds2'] = train.image_phash.map(tmp)\ntrain.head()","78871644":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds1,row.preds2])\n    return np.unique(x)\n\ndef combine_for_sub(row):\n    x = np.concatenate([row.preds1,row.preds2])\n    return ' '.join( np.unique(x) )\n\n\nif COMPUTE_CV:\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    train['f1'] = train.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train.f1.mean() )\n    \n    \n    \ntrain['matches'] = train.apply(combine_for_sub,axis=1)","36e1cc2c":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head(10)","29495020":"Notebook inspired by the great notebook from Chris Deotte\n\nRAPIDS TfidfVectorizer http:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700.\n\nRapids are great but you can get also great performance with sklearn."}}