{"cell_type":{"29f79bf1":"code","b7e018cd":"code","9ae10148":"code","d464da2c":"code","ef14314d":"code","efc4cec2":"code","536167ac":"code","ccf65571":"code","8716ba39":"code","775b98b9":"code","6edd7fa8":"code","179978cb":"code","e49b7d86":"code","98a84bcc":"code","16d6c3e2":"code","51f9d207":"code","d473dbd0":"code","0e8aa197":"code","0916a0ed":"code","0eef1184":"code","dcd1ed23":"code","a3ca22ae":"code","70d0a6ba":"code","f915e8bf":"code","a438d06a":"code","cbffb324":"code","bc796378":"code","3f5e09ce":"code","a26091cf":"code","7da72b9d":"code","b4280e07":"code","5b972935":"code","c83a4b83":"code","d33a4d82":"code","133d8bca":"code","d9c4d392":"code","09ec903b":"code","dc92cff6":"code","a5e75abb":"code","eb3ee719":"code","25cd8884":"markdown"},"source":{"29f79bf1":"!pip install plotly","b7e018cd":"import pandas as pd\nimport numpy as py\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.model_selection import GridSearchCV, KFold\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport datetime\n\n\nimport sklearn.discriminant_analysis\nimport sklearn.linear_model as skl_lm\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom datetime import timedelta\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.metrics import hamming_loss, accuracy_score \nfrom pandas import DataFrame\nfrom datetime import datetime\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf","9ae10148":"train= pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/train.csv')\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/test.csv')\nsubmission = pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/submission.csv')\nprint(train.shape)\ntrain.head()","d464da2c":"\n#date=pd.to_datetime(datatrain['Date'])\n#datet=pd.to_datetime(datatest['Date'])\n#print(date)","ef14314d":"#ldate=int(len(date))\n#ldatet=int(len(datet))\n","efc4cec2":"#m = []\n#d = []\n##for i in range(0,ldate):\n  #  dx = (date[i].strftime(\"%d\"))\n   # mx = (date[i].strftime(\"%m\"))\n    #m.append(int(mx))\n    #d.append(int(dx))\n\n#mt = []\n#dt = []\n#for i in range(0,ldatet):\n #   dtx = (datet[i].strftime(\"%d\"))\n  #  mtx = (datet[i].strftime(\"%m\"))\n   # mt.append(int(mtx))\n    #dt.append(int(dtx))\n","536167ac":"#train = datatrain\n#test = datatest","ccf65571":"#train.insert(6,\"Month\",m,False)\n#train.insert(7,\"Day\",d,False)\n#test.insert(4,\"Month\",mt,False)\n#test.insert(5,\"Day\",dt,False)\n","8716ba39":"#print(\"Datatrain\")\n#traindays = datatrain['Date'].nunique()\n#print(\"Number of Country_Region: \", datatrain['Country_Region'].nunique())\n#print(\"Number of Province_State: \", datatrain['Province_State'].nunique())\n#print(\"Number of Days: \", traindays)\n\n#notrain = datatrain['Id'].nunique()\n#print(\"Number of datapoints in train:\", notrain)\n#lotrain = int(notrain\/traindays)\n#print(\"L Trains:\", lotrain)","775b98b9":"#print(\"Datatest\")\n#testdays = datatest['Date'].nunique()\n#print(\"Number of Days: \", testdays)\n#notest = datatest['ForecastId'].nunique()\n#print(\"Number of datapoints in test:\", notest)\n#lotest = int(notest\/testdays)\n#print(\"L Test:\", lotest)","6edd7fa8":"#zt = datet[0]\n#daycount = []\n#for i in range(0,lotrain):\n #   for j in range(1,traindays+1):\n  #      daycount.append(j)\n","179978cb":"#for i in range(traindays):\n #   zx=0\n  #  if(zt == date[i]):\n   #     \n    #    zx = i\n     #   print(zx)\n        \n#daytest = []\n#for i in range(0,lotest):\n #   for j in range(1,testdays+1):\n  #      jr = zx + j\n   #     daytest.append(jr)\n\n","e49b7d86":"#train.insert(8,\"DayCount\",daycount,False)\n#test.insert(6,\"DayCount\",daytest,False)","98a84bcc":"#train.head()","16d6c3e2":"#traincount = int(len(train[\"Date\"]))\n\n#testcount = int(len(test[\"Date\"]))","51f9d207":"#train.Province_State = train.Province_State.fillna(0)\n#empty = 0\n#for i in range(0,traincount):\n #   if(train.Province_State[i] == empty):\n  #      train.Province_State[i] = train.Country_Region[i]","d473dbd0":"#test.Province_State = test.Province_State.fillna(0)\n#empty = 0\n#for i in range(0,testcount):\n #   if(test.Province_State[i] == empty):\n  #      test.Province_State[i] = test.Country_Region[i]","0e8aa197":"#label = preprocessing.LabelEncoder()\n#train.Country_Region = label.fit_transform(train.Country_Region)\n#train.Province_State = label.fit_transform(train.Province_State)","0916a0ed":"#test.Country_Region = label.fit_transform(test.Country_Region)\n#test.Province_State = label.fit_transform(test.Province_State)","0eef1184":"#X = py.c_[train[\"Province_State\"], train[\"Country_Region\"], train[\"DayCount\"], train[\"Month\"], train[\"Day\"]]\n#Xt = py.c_[test[\"Province_State\"], test[\"Country_Region\"], test[\"DayCount\"], test[\"Month\"], test[\"Day\"]]\n#X","dcd1ed23":"#Y1 = train[train['Target']==\"ConfirmedCases\"]\n#Y2=train[train['Target']==\"Fatalities\"]\n#Y11=Y1.iloc[:,-1]\n#Y22=Y2.iloc[:,-1]\n#Y11\n#Y22\n","a3ca22ae":"fig = px.pie(train, values='TargetValue', names='Target')\nfig.update_traces(textposition='inside')\nfig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\nfig.show()","70d0a6ba":"ww_me=pd.melt(train,id_vars=['Date'],value_vars=['Target'])\nww_me","f915e8bf":"train.corr()","a438d06a":"train=train.drop(['County','Province_State','Country_Region','Target'],axis=1)\ntest=test.drop(columns=['County','Province_State','Country_Region','Target'])\ntrain","cbffb324":"from sklearn.preprocessing import OrdinalEncoder\n\ndef create_features(df):\n    df['day'] = df['Date'].dt.day\n    df['month'] = df['Date'].dt.month\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['dayofyear'] = df['Date'].dt.dayofyear\n    df['quarter'] = df['Date'].dt.quarter\n    df['weekofyear'] = df['Date'].dt.weekofyear\n    return df","bc796378":"def train_dev_split(df, days):\n    #Last days data as dev set\n    date = df['Date'].max() - dt.timedelta(days=days)\n    return df[df['Date'] <= date], df[df['Date'] > date]","3f5e09ce":"test_date_min = test['Date'].min()\ntest_date_max = test['Date'].max()\n","a26091cf":"def avoid_data_leakage(df, date=test_date_min):\n    return df[df['Date']<date]\n","7da72b9d":"def to_integer(dt_time):\n    return 10000*dt_time.year + 100*dt_time.month + dt_time.day","b4280e07":"train['Date']=pd.to_datetime(train['Date'])\ntest['Date']=pd.to_datetime(test['Date'])\n","5b972935":"test['Date']=test['Date'].dt.strftime(\"%Y%m%d\").astype(int)\ntrain['Date']=train['Date'].dt.strftime(\"%Y%m%d\").astype(int)","c83a4b83":"from sklearn.model_selection import train_test_split\n\npredictors = train.drop(['TargetValue', 'Id'], axis=1)\ntarget = train[\"TargetValue\"]\nX_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","d33a4d82":"test=test.drop(['ForecastId'],axis=1)","133d8bca":"\nmodel = XGBRegressor(n_estimators = 2500 , alpha=0,gamma=0,learning_rate=0.04,max_depth=23,random_state=42)\nmodel.fit(X_train, y_train)\n\nscores = []\n\nscores.append(model.score(X_test, y_test))\nX_test\n\n","d9c4d392":"y_pred2 = model.predict(X_test)\ny_pred2\npredictions=[]\npredictions = model.predict(test)\n\npred_list = [int(x) for x in predictions]\n\noutput = pd.DataFrame({'Id': test.index, 'TargetValue': pred_list})\nprint(output)","09ec903b":"a=output.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['Id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['Id'])['TargetValue'].quantile(q=0.95).reset_index()\n","dc92cff6":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05'].clip(0,10000)\na['q0.5']=a['q0.5'].clip(0,10000)\na['q0.95']=a['q0.95'].clip(0,10000)\na","a5e75abb":"a['Id'] =a['Id']+ 1\na","eb3ee719":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)","25cd8884":"model = RandomForestRegressor(n_jobs=-1)\nestimators = 100\nscores = []\nmodel.set_params(n_estimators=estimators)\nmodel.fit(X_train, y_train)\nscores.append(model.score(X_test, y_test))\nX_test"}}