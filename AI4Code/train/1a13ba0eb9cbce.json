{"cell_type":{"36c038a7":"code","4e9728c3":"code","60230c45":"code","638a0fd4":"code","7fd71a5e":"code","024dc86d":"code","1a2fa8ca":"code","d34394fa":"code","5a17ae60":"code","c6b76818":"code","2f01b5bf":"code","596ceca1":"code","f6266dea":"code","02311774":"code","13c2c01c":"code","bc633536":"code","509dcf54":"code","20d9563e":"markdown","d20fd6c9":"markdown","722c0d49":"markdown","6567523b":"markdown","1057b8d6":"markdown","c255612e":"markdown","ac75035c":"markdown","e3a805e1":"markdown","8ab94df3":"markdown","c2512407":"markdown","fb4cb30b":"markdown","2395004c":"markdown"},"source":{"36c038a7":"# Import stuff\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\nprint(os.listdir(\"..\/input\"))","4e9728c3":"df = pd.read_csv('..\/input\/StudentsPerformance.csv')\ndf.head()","60230c45":"df.info()","638a0fd4":"df.describe()","7fd71a5e":"df[\"average score\"] = (df[\"math score\"] + df[\"reading score\"] + df[\"writing score\"]) \/3\ndf['average score group'] = pd.cut(df[\"average score\"], bins=[g for g in range(0, 101, 10)], include_lowest=True)\n","024dc86d":"df.hist(bins=20, figsize=(12,8))","1a2fa8ca":"plt.figure(figsize=(12, 8))\np = sns.countplot(x='parental level of education', data = df, palette='deep')","d34394fa":"plt.figure(figsize=(12, 8))\n\n\np = sns.countplot(x='parental level of education', data = df, hue='average score group', palette=\"deep\")","5a17ae60":"plt.figure(figsize=(12, 8))\np = sns.countplot(x='race\/ethnicity', data = df, palette='deep')","c6b76818":"plt.figure(figsize=(12, 8))\n\n\np = sns.countplot(x='race\/ethnicity', data = df, hue='average score group', palette=\"deep\")","2f01b5bf":"plt.figure(figsize=(12, 8))\np = sns.countplot(x='lunch', data = df, palette='deep')","596ceca1":"plt.figure(figsize=(12, 8))\n\n\np = sns.countplot(x='lunch', data = df, hue='average score group', palette=\"deep\")","f6266dea":"fr_lunch = df[df['lunch']=='free\/reduced']\nstd_lunch = df[df['lunch']=='standard']\n\nprint(\"Free\/Reduced lunch mean\",fr_lunch['average score'].mean())\nprint(\"Standard lunch mean\",std_lunch['average score'].mean())","02311774":"new_df = df.copy()\n\none_hot = pd.get_dummies(df['gender'], prefix='gender')\nnew_df = new_df.join(one_hot)\none_hot = pd.get_dummies(df['race\/ethnicity'], prefix='race\/ethnicity')\nnew_df = new_df.join(one_hot)\none_hot = pd.get_dummies(df['parental level of education'], prefix='parental level of education')\nnew_df = new_df.join(one_hot)\none_hot = pd.get_dummies(df['lunch'], prefix='lunch')\nnew_df = new_df.join(one_hot)\none_hot = pd.get_dummies(df['test preparation course'], prefix='test preparation course')\nnew_df = new_df.join(one_hot)\n\nnew_df.drop([\"reading score\", \"writing score\", \"math score\", \"gender\", \"race\/ethnicity\", \"parental level of education\", \"test preparation course\",\"lunch\", \"average score group\"], axis=1, inplace=True)\n\nnew_df.head()","13c2c01c":"train_set, test_set = train_test_split(new_df, test_size=0.20, random_state=21)\n\ntrain_X = train_set.drop('average score', axis=1)\ntrain_Y = train_set['average score'].copy()\n\ntest_X = test_set.drop('average score', axis=1)\ntest_Y = test_set['average score'].copy()","bc633536":"\nlin_reg = LinearRegression()\n\nresults = cross_validate(lin_reg, train_X, train_Y, cv=10, return_estimator=True)\n\nscores = results['test_score']\nprint(\"Scores:\",scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard deviation:\", scores.std())","509dcf54":"# Find the best model\n\nbest = np.where(scores == min(scores))[0][0]\nbest_estimator = results['estimator'][best]\nfinal_predictions = best_estimator.predict(test_X)\nfinal_mse = mean_squared_error(test_Y, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nprint(final_rmse)\n\n","20d9563e":"We can see that only the scores are actually numerical values and the rest are categorical. Since our model only accepts numerical values we will have to deal with this problem.\nFor now let's create a new feature that is the average of all the scores and a grouping of those scores  and see how they are distributed.","d20fd6c9":"Let's check our other attributes and their distribution","722c0d49":"Finnaly we can start training the model! \nWe will be using the Linear Regression algorithm inside a Cross Validation function with 10 folds.","6567523b":"With the lunch feature we can start to see a small distinction where the students that have a free\/reduced lunch tend to have sligthly smaller grades. Let's analyse this assumption further","1057b8d6":"Let's first check the shape of our data and how it is distributed","c255612e":"Now we separate the data into two groups, the train data which we will use to train our model and the test data where we will test the performance of our model.\nWe will also split both the groups into the actual features and the labels we are trying to predict, in this case the average score.","ac75035c":"We can see that we don't have that many data about children whose parents have a master's or bachelor's degree compared to the other groups.\nWe can also identify that there doesn't seem to exist a clear correlation between the different grades of the students and their parent's education.","e3a805e1":"We can indeed see a small difference between the means of both groups, which our algorithm will use to improve it's predictions.\n\nLike we said before,* scikit learn*'s ** Linear Regression** will not accept non numeric features so we will now change these into a **One Hot Encoding** version that will be better suited.","8ab94df3":"So as we can see our estimator gives us a final error of around 12.6","c2512407":"By analising the results we can see that our model has a mean error of about 0.2 which isn't very good. \nWe can also see that there is a large variance between the models that we attained with the Cross Validation.\n\nOf course all of this is based on the test group data. Let's see how our best model works when paired aggainst our test set.","fb4cb30b":"# Linear Regression to predict the average score \n\nMy first kernel, just trying to learn by practicing some some easy models, in this case Linear Regression\n","2395004c":"Again we cannot see a clear distinction of the grades based on the race group that the student belongs to."}}