{"cell_type":{"23d7d0c9":"code","3f3f34c6":"code","5507295d":"code","f09a357d":"code","60d6ca2c":"code","71ea8b1f":"code","bf7f7e93":"code","7e921224":"code","2956c314":"code","fa3f4ba0":"code","86e70aaa":"code","54e677fb":"code","889e726f":"code","2da20b3e":"code","c4c8b666":"code","d512b009":"code","a9fd57f0":"code","f9525ed0":"code","a5df15ef":"code","75c4c7c0":"code","0f1c5398":"code","85860391":"code","bea5ff7f":"code","9c32d2eb":"markdown","a7258db2":"markdown","07933856":"markdown","ba22134a":"markdown","9c1c9491":"markdown","223baac4":"markdown","329df18d":"markdown","aad9dbbf":"markdown"},"source":{"23d7d0c9":"# Data preprocessing\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport glob\n\n# Deep learning\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing import image\n\nimport os","3f3f34c6":"dirname = '\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database'\nos.listdir(dirname)","5507295d":"dirname2 = '..\/input\/actualmedcovidchestxraydataset'\nos.listdir(dirname2)","f09a357d":"metadata = pd.read_csv(os.path.join(dirname2, 'metadata.csv'))\nmetadata","60d6ca2c":"metadata['finding'].value_counts()","71ea8b1f":"metadata[metadata['finding']=='COVID-19'].head()","bf7f7e93":"images_covid19 = metadata[metadata['finding']=='COVID-19']['imagename'].to_list()","7e921224":"normal_images = []\ncount = 0\n\n# load images\nfor img_path in glob.glob(dirname + \"\/NORMAL\/*\"):\n    count += 1\n    normal_images.append(image.load_img(str(img_path), target_size = (150,150,3)))\n    if count > 280:   # we keep 280 images since there are only 219+58 images of covid-19, then the distribution of classes can be balanced.\n        break\n\n# plot the first normal lung images in the dataset\nfig = plt.figure()\nfig.suptitle(\"Normal Lungs\")\nplt.imshow(normal_images[0], cmap=\"gray\")\nplt.show()","2956c314":"covid_images = []\ncount = 0\n\nfor img_path in glob.glob(dirname + \"\/COVID-19\/*\"):\n    count += 1\n    covid_images.append(image.load_img(str(img_path), target_size = (150,150,3)))\n    if count > 280:   # we keep 280 images since there are only 219+58 images of covid-19, then the distribution of classes can be balanced.\n        break\n\nfor image_name in images_covid19:\n    img_path = os.path.join(dirname2, 'images', image_name)\n    normal_images.append(image.load_img(str(img_path), target_size = (150,150,3)))\n\n# plot the first image of covid-19 infection.\nfig = plt.figure()\nfig.suptitle(\"Covid-19 Patient's Lungs\")\nplt.imshow(covid_images[0], cmap=\"gray\")\nplt.show()","fa3f4ba0":"pneumonia_images = []\ncount = 0\n\nfor img_path in glob.glob(dirname + \"\/Viral Pneumonia\/*\"):\n    count += 1\n    pneumonia_images.append(image.load_img(str(img_path), target_size = (150,150,3)))\n    if count > 280:   # we keep 280 images since there are only 219+58 images of covid-19, then the distribution of classes can be balanced.\n        break\n\n# plot the first Viral Pneumonia image\nfig = plt.figure()\nfig.suptitle(\"Viral Pneumonia Lungs\")\nplt.imshow(pneumonia_images[0], cmap=\"gray\")\nplt.show()","86e70aaa":"images_together = []\n\nfor i in normal_images:\n    images_together.append(img_to_array(i))\n    \nfor i in covid_images:\n    images_together.append(img_to_array(i))\n    \nfor i in pneumonia_images:\n    images_together.append(img_to_array(i))\n\n# normal-> 0, covid-19-> 1, pneumonia-> 2\ntargets = np.zeros((len(images_together), 3), int)\ntargets[:len(normal_images)] = [1, 0, 0]\ntargets[len(normal_images):] = [0, 1, 0]\ntargets[len(normal_images)+len(covid_images):] = [0, 0, 1]","54e677fb":"print(\"image list length: \",len(images_together))\nprint(\"target list length: \",len(targets))","889e726f":"targets = np.array(targets)\nprint(\"targets: \",targets.shape)\n# targets = targets.reshape(-1,1)\n# print(\"new shape of targets: \",targets.shape)","2da20b3e":"# look at the shape of the imges\nimages_together = np.array(images_together)\nprint(\"shape of images together: \",images_together.shape)","c4c8b666":"# Re-construct the dataset to meet the input dimensions.\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(images_together, targets, test_size=0.2, stratify=targets)\n\nimages_together = np.concatenate((X_train, X_val))\ntargets = np.concatenate((y_train, y_val))","d512b009":"# Define HyperParameters\ninput_shape = (150, 150, 3)\nnum_classes = 3\nepochs = 32\nbatch_size = 40","a9fd57f0":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), input_shape = input_shape, activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 48, kernel_size = (3,3), activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = (1,1)))\nmodel.add(Dropout(0.25))\n\n#fully connected\nmodel.add(Flatten())\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(3, activation = \"softmax\"))\n\n# compile \nmodel.compile(loss = \"categorical_crossentropy\",\n             optimizer = \"rmsprop\",\n             metrics = [\"accuracy\"])","f9525ed0":"model.summary()","a5df15ef":"tf.config.experimental.list_physical_devices('GPU')","75c4c7c0":"# Create iterable training set with Data Augmentation methodologies such as rescale, shear, zoom and filp the data.\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  shear_range = 0.2,\n                                  zoom_range = 0.2,\n                                  horizontal_flip = True,\n                                  validation_split = 0.2)\n\n\n# training iterable\ntrain_generator = train_datagen.flow(\nimages_together, targets,\nbatch_size = batch_size,\nsubset = \"training\")\n\n# validation iterable\nvalidation_generator = train_datagen.flow(\nimages_together, targets,\nbatch_size = batch_size,\nshuffle = False,\nsubset = \"validation\")\n\n#Train the model using GPU acceleration\nwith tf.device('\/GPU:0'):\n    hist = model.fit_generator(\n    train_generator,\n    steps_per_epoch = (450*0.8)\/\/batch_size,\n    validation_data = validation_generator,\n    validation_steps = (450*0.2)\/\/ batch_size,\n    epochs = epochs)","0f1c5398":"# plot the model accuracy changes through training\nplt.figure(figsize = (13,7))\nplt.plot(hist.history[\"accuracy\"])\nplt.plot(hist.history[\"val_accuracy\"])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Test\"], loc = \"upper left\")\n#plt.text(23,0.5,\"Current Training Accuracy: \"+str(np.round(hist.history[\"accuracy\"][-1]*100,2))+\"%\",fontsize = 18,color = \"black\")\n#plt.text(23,0.46,\"Current Validation Accuracy: \"+str(np.round(hist.history[\"val_accuracy\"][-1]*100,2))+\"%\",fontsize = 18,color = \"black\")\nplt.show()","85860391":"print(\"Training Accuracy: \"+str(np.round(hist.history[\"accuracy\"][-1]*100,2))+\"%\")\nprint(\"Validation Accuracy: \"+str(np.round(hist.history[\"val_accuracy\"][-1]*100,2))+\"%\")","bea5ff7f":"# measure the execution time\nimport time\nstart = time.time()\n# making predictions\npreds = model(X_val)\nend = time.time()\nprint(f'in order to predict {len(X_val)} images, it takes {end-start} seconds')\n\n# plot the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ny_pred = np.argmax(preds, axis=1)\ny_true = np.argmax(y_val, axis=1)\nmatrix = confusion_matrix(y_true, y_pred)\n\nax = sns.heatmap(matrix, annot=True, fmt='d')\nax.set(xlabel='Predicted', ylabel='True')\nlabels = ['Normal', 'COVID-19', 'Viral Pneumonia']\nplt.title('Confusion matrix of the classifier')\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.show()","9c32d2eb":"### Path for Actualmed-COVID-chestxray-dataset","a7258db2":"### Load Images of each class","07933856":"## Build Basic CNN Model","ba22134a":"## Data Loading and Preprocessing","9c1c9491":"## Model Evaluation","223baac4":"## Model Training","329df18d":"### Look at how many covid-19 images in Actualmed-COVID-chestxray-dataset","aad9dbbf":"### Path for covid19-radiography-database"}}