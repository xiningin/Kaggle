{"cell_type":{"795ca081":"code","3d374518":"code","038e8b1a":"code","03b0df4d":"code","ed9679a5":"code","22b1f670":"code","2ab0812d":"code","07062bdd":"code","6a423ccf":"code","0ca9f690":"code","2ec27186":"code","e0e23e05":"code","11c19576":"code","7c7b15e6":"markdown","cd1b59c0":"markdown","45686b8b":"markdown","5686d62b":"markdown","53a1cd06":"markdown"},"source":{"795ca081":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nimport plotly.express as px\n\nfrom nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrom nltk import ngrams\n\nimport os\n\nimport json\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nsns.set_palette('Set3_r')\n\npd.set_option(\"display.max_rows\", 20, \"display.max_columns\", None)\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))\n\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = Warning)","3d374518":"train = pd.read_csv('\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/train.csv')\nprint(train.shape)\ntrain.head()","038e8b1a":"test = pd.read_csv('\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/test.csv')\nprint(test.shape)\ntest.head()","03b0df4d":"sub = pd.read_csv('\/kaggle\/input\/chaii-hindi-and-tamil-question-answering\/sample_submission.csv')\nprint(sub.shape)\nsub.head()","ed9679a5":"fig, (ax1, ax2) = plt.subplots(1, 2)\nsns.countplot(x = 'language', data = train, ax = ax1).set_title('Train Language Counts')\nfor p in ax1.patches:\n    ax1.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\nsns.countplot(x = 'language', data = test, ax = ax2).set_title('Test Language Counts')\nfor p in ax2.patches:\n    ax2.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","22b1f670":"# Download Tamil\/hindi fonts and extract\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Devanagari.zip\n!wget -q http:\/\/www.lipikaar.com\/sites\/www.lipikaar.com\/themes\/million\/images\/support\/fonts\/Tamil.zip\n\n!unzip -qq Devanagari.zip\n!unzip -qq Tamil.zip","2ab0812d":"def length_dist(data, text = None):\n    length = train['context'].apply(lambda x: len(x))\n    words_len = train['context'].apply(lambda x: len(x.split(' ')))\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 10))\n    sns.distplot(length, ax = ax1).set_title(f'{text} Length')\n    sns.distplot(words_len, ax = ax2).set_title(f'{text} Word Count')","07062bdd":"length_dist(train['context'], text = 'Train Context')","6a423ccf":"length_dist(train['question'], text = 'Train Question')","0ca9f690":"freq_dist = pd.Series(' '.join(train[train['language'] == 'tamil']['context']).split()).value_counts()\nfig = px.line(freq_dist, \n             title = 'Train Context - Word Frequency')\nfig.update_layout(showlegend = False)","2ec27186":"freq_dist = pd.Series(' '.join(train[train['language'] == 'tamil']['question']).split()).value_counts()\nfig = px.line(freq_dist, \n             title = 'Train Question - Word Frequency')\nfig.update_layout(showlegend = False)","e0e23e05":"freq_dist = pd.Series(' '.join(train[train['language'] == 'tamil']['answer_text']).split()).value_counts()\nfig = px.line(freq_dist, \n             title = 'Train Answer - Word Frequency')\nfig.update_layout(showlegend = False)","11c19576":"freq_dist = pd.Series(' '.join(train[train['language'] == 'hindi']['context']).split()).value_counts()\nfig = px.line(freq_dist, \n             title = 'Train Context - Word Frequency')\nfig.update_layout(showlegend = False)","7c7b15e6":"# Competition Overview:\n\nIn this competition, the goal is to predict answers to real questions about Wikipedia articles. You will use chaii-1, a new question answering dataset with question-answer pairs. The dataset covers Hindi and Tamil, collected without the use of translation. It provides a realistic information-seeking task with questions written by native-speaking expert data annotators. ","cd1b59c0":"# Brief Introduction\n\n### Tamil\n\n- Tamil is a Dravidian language spoken by Tamils in southern India, Sri Lanka, and elsewhere\n- Tamil language originated from Proto-Dravidian in 450BCE\n- Tamil language is derived from the Dravidian language family written in Tamil scripts. It is one of the four Dravidian languages along with Telegu, Malayalam, and Kannada\n- It is the oldest of all Dravidian languages\n- Tamil language witnesses it\u2019s existence for more than 2000 years making it the oldest and longest surviving classical language in the world\n- The Tamil language is spoken widely in India, Sri Lanka, Malaysia, Singapore, South Africa and Mauritius\n\n### Hindi\n\n- Hindi is an Indic language of northern India that derived from Vedic Sanskrit language\n- Hindi is written in the Devanagari script\n- Hindi language originated from the Indo-Aryans linguistic Family in the 17th century CE\n- It is one of the official languages of India which includes Tamil as well","45686b8b":"# Competition Metrics:\nThe metric in this competition is the word-level Jaccard score\n\n`def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))`","5686d62b":"# WIP","53a1cd06":"\n# Competition Rules:\n- CPU Notebook <= 5 hours run-time\n-GPU Notebook <= 5 hours run-time\n-Internet access disabled\n- Freely & publicly available external data is allowed, including pre-trained models\n- Submission file must be named submission.csv"}}