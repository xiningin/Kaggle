{"cell_type":{"2e67ccaf":"code","14094a9e":"code","1e24228c":"code","b599d7b1":"code","1a064554":"code","0ff1fe19":"code","11c3aef8":"code","ce2f2434":"code","baf8f6b3":"code","c34bcc34":"code","224bbd20":"code","4a415ef1":"code","b7055271":"code","c4ade959":"code","e2bd9682":"code","152cfa3e":"code","7280e059":"code","8854bf14":"code","2ceeadae":"code","bde89527":"code","c3e742fc":"code","7ea07280":"code","e97c8044":"code","00941f98":"markdown","6bede610":"markdown","ad71de57":"markdown","650ce770":"markdown","6ef13e54":"markdown","6835a03a":"markdown","03759d01":"markdown","d3fcbca1":"markdown","d819292d":"markdown","ba19fc6d":"markdown","7962f4b4":"markdown","47bbb619":"markdown","216c7979":"markdown","c46f108a":"markdown","a924729a":"markdown"},"source":{"2e67ccaf":"pip install imutils","14094a9e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.spatial import distance as dist\nimport os\nimport cv2\nimport glob as gb\nfrom skimage.filters import gaussian\nfrom skimage.morphology import dilation,erosion\nfrom skimage.feature import canny\nfrom skimage.measure import find_contours\nimport imutils\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n","1e24228c":"def findedges(image):\n    gray = cv2.GaussianBlur(image, (1, 1), 0)\n    edged = cv2.Canny(gray, 100, 400)\n    edged = cv2.dilate(edged, None, iterations=1)\n    edged = cv2.erode(edged, None, iterations=1)\n    return edged\n    ","b599d7b1":"def getimageconturs(edged):\n    contours = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    contours = imutils.grab_contours(contours)\n    contours = sorted(contours, key=lambda x: cv2.contourArea(x))\n    return contours\n    ","1a064554":"def getboxes(contours,orig):\n    boxes = []\n    centers = []\n    for contour in contours:\n        box = cv2.minAreaRect(contour)\n        box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n        box = np.array(box, dtype=\"int\")\n        (tl, tr, br, bl) = box\n        if (dist.euclidean(tl, bl)) > 0 and (dist.euclidean(tl, tr)) > 0:\n            boxes.append(box)\n    return boxes","0ff1fe19":"image_size=(120,120)\ncode={\"EOSINOPHIL\":0,\"LYMPHOCYTE\":1,\"MONOCYTE\":2,\"NEUTROPHIL\":3}\ndef getcode(n):\n    if type(n)==str:\n        for x,y in code.items():\n            if n==x:\n                return y \n    else:\n        for x,y in code.items():\n            if n==y:\n                return x","11c3aef8":"def loaddata():\n    datasets=[\"..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TRAIN\/\",\n          \"..\/input\/blood-cells\/dataset2-master\/dataset2-master\/images\/TEST\/\",]\n\n\n\n    \n    images=[]\n    labels=[]\n    count=0\n    for dataset in datasets:\n        for folder in os.listdir(dataset):\n            files=gb.glob(pathname=str(dataset+folder+\"\/*.jpeg\"))\n            label=getcode(folder)\n            for file in files:\n                image = cv2.imread(file)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # add padding to the image to better detect cell at the edge\n                image = cv2.copyMakeBorder(image,10,10,10,10,cv2.BORDER_CONSTANT,value=[198, 203, 208])\n                \n                #thresholding the image to get the target cell\n                image1 = cv2.inRange(image,(80, 80, 180),(180, 170, 245))\n                \n                # openning errosion then dilation\n                kernel = np.ones((3, 3), np.uint8)\n                kernel1 = np.ones((5, 5), np.uint8)\n                img_erosion = cv2.erode(image1, kernel, iterations=2)\n                image1 = cv2.dilate(img_erosion, kernel1, iterations=5)\n                \n                #detecting the blood cell\n                edgedImage = findedges(image1)\n                edgedContours = getimageconturs(edgedImage)\n                edgedBoxes =  getboxes(edgedContours, image.copy())\n                if len(edgedBoxes)==0:\n                    count +=1\n                    continue\n                # get the large box and get its cordinate\n                last = edgedBoxes[-1]\n                max_x = int(max(last[:,0]))\n                min_x = int( min(last[:,0]))\n                max_y = int(max(last[:,1]))\n                min_y = int(min(last[:,1]))\n                \n                # draw the contour and fill it \n                mask = np.zeros_like(image)\n                cv2.drawContours(mask, edgedContours, len(edgedContours)-1, (255,255,255), -1) \n                \n                # any pixel but the pixels inside the contour is zero\n                image[mask==0] = 0\n                \n                # extract th blood cell\n                image = image[min_y:max_y, min_x:max_x]\n\n                if (np.size(image)==0):\n                    count +=1\n                    continue\n                # resize th image\n                image = cv2.resize(image, image_size)\n\n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n\n    images = np.array(images, dtype = 'float32')\n    labels = np.array(labels, dtype = 'int32')\n\n    return images,labels\n        ","ce2f2434":"images,labels=loaddata()","baf8f6b3":"images,labels=shuffle(images,labels,random_state=10)","c34bcc34":"images=images\/255\ntrain_image,test_image,train_label,test_label=train_test_split(images,labels,test_size=.2)\ntest_image,val_image,test_label,val_label=train_test_split(test_image,test_label,test_size=.5)\n","224bbd20":"def displayrandomimage(image,label,typeofimage):\n    plt.figure(figsize=(15,15))\n    plt.suptitle(\"some random image of \"+typeofimage,fontsize=17)\n    for n,i in  enumerate(list(np.random.randint(0,len(image),36))):\n        plt.subplot(6,6,n+1)\n        plt.imshow(image[i])\n        plt.axis(\"off\")\n        plt.title(getcode(label[i]))","4a415ef1":"displayrandomimage(train_image,train_label,\"train image\")","b7055271":"displayrandomimage(test_image,test_label,\"test image\")","c4ade959":"displayrandomimage(val_image,val_label,\"val image\")","e2bd9682":"model=keras.models.Sequential([\n    keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(120,120,3)),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(.25),\n    keras.layers.Conv2D(128,(3,3),activation='relu'),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(.25),\n    keras.layers.Conv2D(256,(3,3),activation=\"relu\"),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(.25),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1024,activation='relu'),\n    #keras.layers.Dense(2048,activation='relu'),\n    keras.layers.Dropout(.25),\n    keras.layers.Dense(4,activation='softmax')\n    \n    \n    \n])","152cfa3e":"model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])","7280e059":"model.summary()","8854bf14":"epochs=30","2ceeadae":"history=model.fit(train_image,\n                  train_lafigure\n                  epochs=epochs,\n                  batch_size=32,\n                  validation_data=(val_image,val_label))","bde89527":"loss,acuracy=model.evaluate(test_image,test_label)\nprint(\"the accuracy of test image is : \",acuracy)","c3e742fc":"def plot_acc_and_loss_of_train_and_val(history):\n    #plt.figure(figsize=(15,15))\n    #plt.suptitle(\"acc,loss of train VS acc,loss of val\")\n    epochs=[i for i in range(30)]\n    train_acc=history.history['accuracy']\n    train_loss=history.history['loss']\n    val_acc=history.history['val_accuracy']\n    val_loss=history.history['val_loss']\n    fig , ax=plt.subplots(1,2)\n    fig.set_size_inches(20,10)\n    ax[0].plot(epochs,train_acc,'go-',label='training accuracy')\n    ax[0].plot(epochs,val_acc,'ro-',label='validation accuracy')\n    ax[0].set_title('Training & Validation Accuracy')\n    ax[0].legend()\n    ax[0].set_xlabel(\"Epochs\")\n    ax[0].set_ylabel(\"Accuracy\")\n    ax[1].plot(epochs,train_loss,'g-o',label='training loss')\n    ax[1].plot(epochs,val_loss,'r-o',label='validation loss')\n    ax[1].set_title('Training & Validation loss')\n    ax[1].legend()\n    ax[1].set_xlabel(\"Epochs\")\n    ax[1].set_ylabel(\"Training & Validation Loss\")","7ea07280":"plot_acc_and_loss_of_train_and_val(history)","e97c8044":"model.save(\"CNN BLOOD DISEASE\")","00941f98":"**Let's go to show the summry of our model**","6bede610":"**Let's go to create function to select the edges of the images**","ad71de57":"**Let's go to create function to get the boxes of the images**","650ce770":"**Now let's go to buil our model**","6ef13e54":"**Woundderfull**\n\n**Let's go to train our model**\n\n","6835a03a":"there are four blood disease :\n1.  MONOCYTE\n2.  NEUTROPHIL\n3.  LYMPHOCYTE\n4.  EOSINOPHIL","03759d01":"***Here we call displayrandomimage function to display some image of train image ***","d3fcbca1":"**Here we create a function to load data and do collection of operations**","d819292d":"there are two folder of the data :\n1. train\n2. test\n\n,and there are four folder in each folder (train,test,predict),for every blood disease","ba19fc6d":"****Here we call displayrandomimage function to display some image of val image ****","7962f4b4":"**Let's go to create function to get the contours of the images**","47bbb619":"**Import the tool we need it**","216c7979":"***Here we call displayrandomimage function to display some image of test image ***","c46f108a":"***In this project we make blood disease classification using tensorflow and keras ***","a924729a":"**Please if you find this notebook useful upvote it**"}}