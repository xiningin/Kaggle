{"cell_type":{"35ee21bd":"code","1a7a42df":"code","fb7b2590":"code","90676158":"code","a3b2df4e":"code","6bacd0fc":"code","e33076d9":"code","64e1abb5":"code","f07b5af1":"code","0d9e3f6b":"code","1fee60aa":"code","0ac44601":"code","7e1a3119":"code","94c5c954":"code","edeb4b98":"code","e7d99006":"code","c280530f":"code","83199286":"code","579ccecc":"code","15f2f9d2":"code","567cfcc1":"code","0478e207":"code","c3786661":"code","4bc63f41":"code","1a9ecf4a":"code","2f5b7154":"code","a63d466e":"code","9d071947":"code","84dd52f1":"code","5a83b822":"code","c26f0cd4":"code","0a07176d":"code","6a1b8628":"code","4581dc5d":"code","e9946291":"code","cb583344":"code","32824296":"code","e37d2443":"code","36205078":"code","7ce7596e":"code","a1c79f2f":"code","efecd54d":"code","61d34d81":"code","05f7b39d":"code","c04e4da8":"code","19dfd155":"code","2b1f0b84":"code","5a2e1eaa":"code","e1d336b9":"code","a266e68a":"code","11484b5a":"code","6e479ebf":"code","60564117":"code","a74a1020":"code","79f402c8":"code","a90e8ed9":"code","99c3c370":"code","6724bbbc":"code","38086e12":"code","564c1310":"code","5455bbed":"code","38201989":"code","7fc4725f":"code","c6f80281":"code","0a1bc42d":"code","c06f7491":"code","36b2f632":"code","3c241080":"code","84e3bc7e":"code","77e48698":"code","b5593d06":"code","c8b928b8":"code","af6f8c90":"code","e83d4fce":"code","79281553":"code","ff7be452":"code","6dfe820a":"code","d198e65b":"code","55de137f":"code","8694bacc":"code","cec8f7a8":"code","a4dd4785":"code","293cc47d":"code","2d3640bf":"code","f6b10203":"code","872b3e4a":"code","8534bdfc":"code","b2455103":"code","1a536b9b":"code","b25db463":"code","22914119":"code","44dafd68":"code","1b2f46f2":"code","0e369060":"code","58263831":"code","cc70e3e3":"code","d305ccda":"code","50e4f9ad":"code","31e6bf2a":"code","6245f6d9":"code","60507c87":"code","f765a1f3":"code","bd79318e":"code","8ebd3a14":"code","a1badbe9":"markdown","a5516d38":"markdown","d468a3e2":"markdown","6fecb974":"markdown","c1241847":"markdown","3862c75a":"markdown","31cd9cbc":"markdown","f843a483":"markdown","79ddfbc4":"markdown","c7bb6165":"markdown","9b37b3e4":"markdown","dae7c954":"markdown","29e87b82":"markdown","c4cff354":"markdown","a370f82b":"markdown","52264b38":"markdown","d60cdfb1":"markdown","dd44c08e":"markdown","fc0a263e":"markdown","454a74e7":"markdown","c3913e72":"markdown","310b4019":"markdown","b75e781a":"markdown","0a58300a":"markdown","eba7e55a":"markdown","c5fad263":"markdown","5e078738":"markdown","58faa9f5":"markdown","647d5d94":"markdown","f7385df7":"markdown","325083a2":"markdown","24cd2388":"markdown","cfea41d5":"markdown","fc3004ee":"markdown","9ac7f382":"markdown","1c42928a":"markdown","22e0966b":"markdown","99e0e08d":"markdown","0a6a93d4":"markdown","be32523b":"markdown","d4c77e41":"markdown","ae1bc307":"markdown","2fb9da77":"markdown","90ad7757":"markdown","524170c9":"markdown","cfcb55ed":"markdown","771bd4e3":"markdown","c333f447":"markdown","5ba239b1":"markdown","e41cd5c9":"markdown","78672d70":"markdown","1e7c8d59":"markdown","1ee487af":"markdown","2b3e6cb8":"markdown","b2b801dc":"markdown","1c9ef43e":"markdown","ed607633":"markdown","6b8d924c":"markdown","0cbd35dd":"markdown"},"source":{"35ee21bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a7a42df":"#Importing the necessary libraries.\nimport matplotlib.pyplot as plt\nimport seaborn as sns","fb7b2590":"#Loading the dataset.\ndf = pd.read_csv('..\/input\/credit-case-study-project\/application_data.csv')","90676158":"df.head()","a3b2df4e":"df.shape","6bacd0fc":"df.describe()","e33076d9":"df.isnull().sum()","64e1abb5":"#Identifying the major null values.\nnull_values_percent = (df.isnull().sum()\/len(df))*100\nmajor_missing_datacols = null_values_percent[null_values_percent >= 50] \nmajor_missing_datacols","f07b5af1":"#Dropping these values.\napplication_data = df.drop(columns=major_missing_datacols.index)\napplication_data.shape","0d9e3f6b":"missing_rows = application_data.isnull().sum(axis=1)\/application_data.shape[1]\nmissing_rows[missing_rows > 50]","1fee60aa":"minor_missing_datacols = null_values_percent[(null_values_percent > 0) & (null_values_percent <= 15)].sort_values(ascending=False)\nminor_missing_datacols","0ac44601":"#Selecting columns with less than or equal to than 13% null values.\nlist(df.columns[(df.isnull().mean() <= 0.13) & (df.isnull().mean() > 0)])","7e1a3119":"df['EXT_SOURCE_2'].value_counts()","94c5c954":"# EXT_SOURCE_2 is a continuous variable. So checking for outliers.\nplt.style.use('ggplot')\nplt.figure(figsize=(8,5))\nsns.boxplot(df['EXT_SOURCE_2'])\nplt.show();","edeb4b98":"# Since EXT_SOURCE_2 has no outlier, we can choose mean to impute the column.\nimputVAL = round(df['EXT_SOURCE_2'].mean(),2)\nprint(f'Since EXT_SOURCE_2 has no outliers the column can be imputed using the mean of the column, i.e., {imputVAL}')","e7d99006":"df['AMT_ANNUITY'].value_counts()","c280530f":"# Since AMT_ANNUITY is a continuous variable. So checking for outliers.\nsns.boxplot(df['AMT_ANNUITY'])\nplt.show();","83199286":"# Since AMT_ANNUITY has outlier, we can choose median to impute the column.\nimputVAL = round(df['AMT_ANNUITY'].median(),2)\nprint(f'Since AMT_ANNUITY has outliers the column can be imputed using the median of the column, i.e., {imputVAL}')","579ccecc":"df['NAME_TYPE_SUITE'].value_counts()","15f2f9d2":"imputVAL = df['NAME_TYPE_SUITE'].mode()\nprint(f'Since NAME_TYPE_SUITE is a categorical column. So this column can be imputed using mode of the column, i.e.,{imputVAL[0]}')","567cfcc1":"# Since this is count of family members, this is a continuous variable and we can impute the mean\/median.\nsns.boxplot(df['CNT_FAM_MEMBERS'])\nplt.show();","0478e207":"# This has outliers therefore we use median.\nimputVAL = round(df['CNT_FAM_MEMBERS'].median(),2)\nprint(f'Since CNT_FAM_MEMBERS has outliers the column can be imputed using the median of the column, i.e., {imputVAL}')","c3786661":"df['AMT_GOODS_PRICE'].value_counts()","4bc63f41":"# AMT_GOODS_PRICE is a continuous variable. So checking for outliers.\nsns.boxplot(df['AMT_GOODS_PRICE'])\nplt.show();","1a9ecf4a":"# This has outliers therefore we use median.\nimputVAL = round(df['AMT_GOODS_PRICE'].median(),2)\nprint(f'Since AMT_GOODS_PRICE has outliers the column can be imputed using the median of the column, i.e., {imputVAL}')","2f5b7154":"#Checking the float type columns.\ndf.select_dtypes(include='float64').columns","a63d466e":"#Converting these count columns to int64.\nColumnToConvert = ['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n                   'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n                   'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n                   'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\ndf.loc[:,ColumnToConvert]=df.loc[:,ColumnToConvert].apply(lambda col: col.astype('int', errors='ignore'))\nColumnToConvert = list(df.select_dtypes(include='object').columns)\ndf.loc[:,ColumnToConvert] = df.loc[:,ColumnToConvert].apply(lambda col: col.astype('str', errors='ignore'))\ndf.head()","9d071947":"# Now making Gender more readable.\ndf['CODE_GENDER'].value_counts()","84dd52f1":"# Dropping the Gender = XNA from the data set as there are just 4 entries.\ndf = df[df['CODE_GENDER'] != 'XNA']\ndf['CODE_GENDER'].replace(['M','F'], ['Male','Female'],inplace=True)\ndf","5a83b822":"df[['DAYS_BIRTH' ,'DAYS_EMPLOYED' ,'DAYS_REGISTRATION' ,'DAYS_ID_PUBLISH']]","c26f0cd4":"df[['DAYS_BIRTH','DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH']].describe()","0a07176d":"days_cols = ['DAYS_BIRTH','DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH']\ndf[days_cols] = (df[days_cols].abs())\/365\ndf[days_cols].describe()","6a1b8628":"#Now let's rename the columns names to years as well.\ndf.rename(columns={'DAYS_BIRTH':'YEARS_BIRTH','DAYS_EMPLOYED':'YEARS_EMPLOYED',\n                   'DAYS_REGISTRATION':'YEARS_REGISTRATION','DAYS_ID_PUBLISH':'YEARS_ID_PUBLISH'},inplace=True)\n","4581dc5d":"#Finally we'll be binning variables for analysis.\n#Creating bins for income amount.\nbins = [0,25000,50000,75000,100000,125000,150000,175000,200000,225000,250000,275000,\n        300000,325000,350000,375000,400000,425000,450000,475000,500000,10000000000]\nslot = ['0-25000', '25000-50000','50000-75000','75000,100000','100000-125000', '125000-150000', '150000-175000','175000-200000',\n       '200000-225000','225000-250000','250000-275000','275000-300000','300000-325000','325000-350000','350000-375000',\n       '375000-400000','400000-425000','425000-450000','450000-475000','475000-500000','500000 and above']\ndf['AMT_INCOME_RANGE'] = pd.cut(df['AMT_INCOME_TOTAL'], bins, labels=slot)\ndf.head()","e9946291":"# Creating bins for Credit amount\nbins = [0,150000,200000,250000,300000,350000,400000,450000,500000,550000,600000,650000,700000,750000,800000,850000,900000,1000000000]\nslots = ['0-150000', '150000-200000','200000-250000', '250000-300000', '300000-350000', '350000-400000','400000-450000',\n        '450000-500000','500000-550000','550000-600000','600000-650000','650000-700000','700000-750000','750000-800000',\n        '800000-850000','850000-900000','900000 and above']\ndf['AMT_CREDIT_RANGE']=pd.cut(df['AMT_CREDIT'],bins=bins,labels=slots)\ndf.head()","cb583344":"# Dividing the dataset into two dataset of  target=1(client with payment difficulties) and target=0(all other).\ntarget0_df = df.loc[df['TARGET']==0]\ntarget1_df = df.loc[df['TARGET']==1]\ndf['TARGET'].value_counts()","32824296":"# Calculating Imbalance percentage\n# Since the majority is target0 and minority is target1.\nround(len(target0_df)\/len(target1_df),2)","e37d2443":"# Plotting a bar plot to visualize the percentage of value_counts.\nsns.countplot(df['TARGET'])\nplt.xlabel('TARGET Value')\nplt.ylabel('Count of TARGET Value')\nplt.title('Distribution of TARGET variable')\nplt.show();","36205078":"#Creating new datadrame for target=0.\ntarget0 = df[df['TARGET']==0]\ntarget0.head()","7ce7596e":"#Creating new datadrame for target=1.\ntarget1 = df[df['TARGET']==1]\ntarget1.head()","a1c79f2f":"target0.shape","efecd54d":"target1.shape","61d34d81":"#Now we need to find top 10 correlations for target0.\ncorr0 = target0.corr()\ncorr_df0 = corr0.where(np.triu(np.ones(corr0.shape), k=1).astype(np.bool))\ncorr_df0 = corr_df0.unstack().reset_index().dropna(subset=[0])\ncorr_df0.columns = ['VAR1','VAR2','Correlation_Value']\ncorr_df0['Corr_abs'] = abs(corr_df0['Correlation_Value'])\ncorr_df0.sort_values(by='Corr_abs', ascending=False, inplace=True)\ncorr_df0.head(10)","05f7b39d":"#Now we need to find top 10 correlations for target1.\ncorr1 = target1.corr()\ncorr_df1 = corr1.where(np.triu(np.ones(corr1.shape),k=1).astype(np.bool))\ncorr_df1 = corr1.unstack().reset_index().dropna(subset=[0])\ncorr_df1.columns = ['VAR1','VAR2','Correlation_Value']\ncorr_df1['Corr_abs'] = abs(corr_df1['Correlation_Value'])\ncorr_df1.sort_values(by='Corr_abs',ascending=False,inplace=True)\ncorr_df1.head(10)","c04e4da8":"#Function to count plot for categorical variables.\ndef allinoneplot(var):\n    plt.style.use('ggplot')\n    sns.despine\n    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,6))\n    \n    sns.countplot(x=var, data=target0, ax=ax1)\n    ax1.set_ylabel('Total Counts')\n    ax1.set_title(f'Distribution of {var} for Non-Defaulters', fontsize=10)\n    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha='right')\n    \n    for p in ax1.patches:\n        ax1.annotate('{:.1f}%'.format((p.get_height()\/len(target0))*100),(p.get_x()+0.1, p.get_height()+50))\n    sns.countplot(x=var, data=target1,ax=ax2)\n    ax2.set_ylabel('Total Counts')\n    ax2.set_title(f'Distribution of {var} for Defaulters', fontsize=10)\n    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=40, ha='right')\n                     \n    for p in ax2.patches:\n        ax2.annotate('{:1f}%'.format((p.get_height()\/len(target1))*100),(p.get_x()+0.1, p.get_height()+50))\n    plt.show()              ","19dfd155":"allinoneplot('CODE_GENDER')","2b1f0b84":"allinoneplot('FLAG_OWN_CAR')","5a2e1eaa":"allinoneplot('NAME_INCOME_TYPE')","e1d336b9":"allinoneplot('NAME_FAMILY_STATUS')","a266e68a":"allinoneplot('NAME_HOUSING_TYPE')","11484b5a":"allinoneplot('NAME_EDUCATION_TYPE')","6e479ebf":"allinoneplot('REGION_RATING_CLIENT')","60564117":"def allinoneplot1(df,col,title,hue =None):\n    \n    sns.set_style('darkgrid')\n    sns.set_context('talk')\n    plt.rcParams[\"axes.labelsize\"] = 20\n    plt.rcParams['axes.titlesize'] = 22\n    plt.rcParams['axes.titlepad'] = 30\n    \n    \n    temp = pd.Series(data = hue)\n    fig, ax = plt.subplots()\n    width = len(df[col].unique()) + 7 + 4*len(temp.unique())\n    fig.set_size_inches(width , 8)\n    plt.xticks(rotation=45)\n    plt.yscale('log')\n    plt.title(title)\n    ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue,palette='husl') \n        \n    plt.show()","a74a1020":"allinoneplot1(target0,col='AMT_INCOME_RANGE',title='Distribution of income range')","79f402c8":"allinoneplot1(target1,col='AMT_INCOME_RANGE',title='Distribution of income range')","a90e8ed9":"allinoneplot1(target0,col='NAME_CONTRACT_TYPE',title='Distribution of contract type')","99c3c370":"allinoneplot1(target1,col='NAME_CONTRACT_TYPE',title='Distribution of contract type')","6724bbbc":"def plotnew(var1,var2):\n\n    plt.style.use('ggplot')\n    sns.despine\n    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(20,6))\n    \n    sns.scatterplot(x=var1, y=var2,data=target0,ax=ax1)\n    ax1.set_xlabel(var1)    \n    ax1.set_ylabel(var2)\n    ax1.set_title(f'{var1} vs {var2} for Non-Defaulters',fontsize=15)\n    \n    sns.scatterplot(x=var1, y=var2,data=target1,ax=ax2)\n    ax2.set_xlabel(var1)    \n    ax2.set_ylabel(var2)\n    ax2.set_title(f'{var1} vs {var2} for Defaulters',fontsize=15)\n            \n    plt.show()","38086e12":"plotnew('AMT_CREDIT','CNT_FAM_MEMBERS')","564c1310":"plotnew('AMT_GOODS_PRICE','AMT_CREDIT')","5455bbed":"plotnew('OBS_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE')","38201989":"plotnew('AMT_ANNUITY','AMT_GOODS_PRICE')","7fc4725f":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(data=target0,x='NAME_CONTRACT_TYPE',hue='AMT_CREDIT_RANGE')\nplt.title('Customer without payment difficulties')\nplt.legend(loc='upper right')\n\n\nplt.subplot(1,2,2)\nax = sns.countplot(data=target1,x='NAME_CONTRACT_TYPE',hue='AMT_CREDIT_RANGE')\nplt.title('Customer with payment difficulties')\nplt.legend(loc='upper right')\nplt.show()","c6f80281":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(data=target0,x='CODE_GENDER',hue='AMT_INCOME_RANGE')\nplt.title('Customer without payment difficulties')\nplt.legend(loc='upper right')\n\n\nplt.subplot(1,2,2)\nax = sns.countplot(data=target1,x='CODE_GENDER',hue='AMT_INCOME_RANGE')\nplt.title('Customer with payment difficulties')\nplt.legend(loc='upper right')\nplt.show()","0a1bc42d":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(data=target0,y='AMT_CREDIT',x='NAME_EDUCATION_TYPE')\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.boxplot(data=target1,y='AMT_CREDIT',x='NAME_EDUCATION_TYPE')\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","c06f7491":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(data=target0[target0['AMT_INCOME_TOTAL']<5000000],y='AMT_INCOME_TOTAL',x='NAME_EDUCATION_TYPE')\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.boxplot(data=target1[target1['AMT_INCOME_TOTAL']<5000000],y='AMT_INCOME_TOTAL',x='NAME_EDUCATION_TYPE')\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","36b2f632":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(data=target0,y='AMT_CREDIT',x='OCCUPATION_TYPE')\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.boxplot(data=target1,y='AMT_CREDIT',x='OCCUPATION_TYPE')\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","3c241080":"prev_appl = pd.read_csv('..\/input\/credit-case-study-project\/previous_application.csv')","84e3bc7e":"prev_appl.head()","77e48698":"prev_appl.shape","b5593d06":"prev_appl.info()","c8b928b8":"prev_appl.describe()","af6f8c90":"prev_appl.isnull().sum()","e83d4fce":"percent_of_null = round((prev_appl.isnull().sum()*100\/prev_appl.shape[0]),2)\npercent_of_null","79281553":"# Lets consider only columns having less than 20 percent of null values in it\nprev_appl = prev_appl[percent_of_null[percent_of_null<20].index]\nprev_appl.head()","ff7be452":"def anotherplot(var):\n    plt.style.use('ggplot')\n    sns.despine\n    fig,ax = plt.subplots(1,1,figsize=(10,8))\n    sns.countplot(x=var, data=prev_appl, ax=ax, hue='NAME_CONTRACT_STATUS')\n    ax.set_ylabel('Total Counts')\n    ax.set_title(f'Distribution of {var}', fontsize=15)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right')\n    plt.show()","6dfe820a":"anotherplot('NAME_CONTRACT_TYPE')","d198e65b":"anotherplot('NAME_PAYMENT_TYPE')","55de137f":"anotherplot('NAME_CLIENT_TYPE')","8694bacc":"#Getting the top 10 correlation PreviousApplication.\ncorr = prev_appl.corr()\ncorr_df = corr.where(np.triu(np.ones(corr.shape),k=1).astype(np.bool)).unstack().reset_index()\ncorr_df.columns = ['Column1','Column2','Correlation']\ncorr_df.dropna(subset=['Correlation'],inplace=True)\ncorr_df['Abs_Correlation'] = corr_df['Correlation'].abs()\ncorr_df = corr_df.sort_values(by=['Abs_Correlation'],ascending=False)\ncorr_df.head(10)","cec8f7a8":"#merging the application_data with previous application data.\nall_data = pd.merge(left=df,right=prev_appl,how='inner',on='SK_ID_CURR',suffixes='_x')","a4dd4785":"all_data.head()","293cc47d":"all_data.shape","2d3640bf":"all_data.NAME_CONTRACT_STATUS.unique()","f6b10203":"sns.countplot(all_data.NAME_CONTRACT_STATUS)\nplt.xlabel(\"Contract Status\")\nplt.ylabel(\"Count of Contract Status\")\nplt.title(\"Distribution of Contract Status\")\nplt.show();","872b3e4a":"#Lets find the percentage of each type of contract status.\nall_data['NAME_CONTRACT_STATUS'].value_counts()*100\/len(all_data)","8534bdfc":"def plotcombined(Varx,Vary):\n    \n    plt.style.use('ggplot')\n    sns.despine\n    NewDat = all_data.pivot_table(values='SK_ID_CURR', \n                      index=Varx,\n                      columns=Vary,\n                      aggfunc='count')\n    NewDat=NewDat.div(NewDat.sum(axis=1),axis='rows')*100\n    sns.set()\n    NewDat.plot(kind='bar',stacked=True,figsize=(15,5))\n    plt.title(f'Effect Of {Varx} on Loan Approval')\n    plt.xlabel(f'{Varx}')\n    plt.ylabel(f'{Vary}%')\n    plt.show()","b2455103":"plotcombined('FLAG_OWN_CAR','NAME_CONTRACT_STATUS')","1a536b9b":"plotcombined('CODE_GENDER','NAME_CONTRACT_STATUS')","b25db463":"plotcombined('TARGET','NAME_CONTRACT_STATUS')","22914119":"# Dividing the new dataframe into 4 parts based on the contract status, i.e: Approved, refused, canceled, unused\napproved_df = all_data[all_data['NAME_CONTRACT_STATUS']=='Approved']\nrefused_df = all_data[all_data['NAME_CONTRACT_STATUS']=='Refused']\ncanceled_df = all_data[all_data['NAME_CONTRACT_STATUS']=='Canceled']\nunused_df = all_data[all_data['NAME_CONTRACT_STATUS']=='Unused offer']","44dafd68":"all_data['NAME_CONTRACT_TYPEx'].value_counts()","1b2f46f2":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2,ncols=2, figsize=(15,10),sharey=True)\n\nax1 = sns.countplot(ax=ax1,data=approved_df,x='NAME_CONTRACT_TYPEx')\nax1.set_title(\"Refused\", fontsize=10)\nax1.set_xlabel('NAME_CONTRACT_TYPEx')\nax1.set_ylabel(\"Number of Loans\")\n# ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n\nax2 = sns.countplot(ax=ax2,data=refused_df,x='NAME_CONTRACT_TYPEx')\nax2.set_title(\"Approved\", fontsize=10)\nax2.set_xlabel('NAME_CONTRACT_TYPEx')\nax2.set_ylabel(\"Number of Loans\")\n# ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n\nax3 = sns.countplot(ax=ax3,data=canceled_df,x='NAME_CONTRACT_TYPEx')\nax3.set_title(\"Canceled\", fontsize=10)\nax3.set_xlabel('NAME_CONTRACT_TYPEx')\nax3.set_ylabel(\"Number of Loans\")\n# ax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n\nax4 = sns.countplot(ax=ax4,data=unused_df,x='NAME_CONTRACT_TYPEx')\nax4.set_title(\"Unused\", fontsize=10)\nax4.set_xlabel('NAME_CONTRACT_TYPEx')\nax4.set_ylabel(\"Number of Loans\")\n# ax4.set_xticklabels(ax4.get_xticklabels(),rotation=90)\nplt.show()","0e369060":"def multi_plot(variable_name):\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2,ncols=2, figsize=(15,12), sharey='all')\n    fig.tight_layout(pad=10.0)\n\n    ax1 = sns.countplot(ax=ax1,data=approved_df,x=variable_name)\n    ax1.set_title(\"Refused\", fontsize=10)\n    ax1.set_ylabel(\"Number of Loans\")\n    ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n\n    ax2 = sns.countplot(ax=ax2,data=refused_df,x=variable_name)\n    ax2.set_title(\"Approved\", fontsize=10)\n    ax2.set_ylabel(\"Number of Loans\")\n    ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n\n    ax3 = sns.countplot(ax=ax3,data=canceled_df,x=variable_name)\n    ax3.set_title(\"Canceled\", fontsize=10)\n    ax3.set_xlabel(variable_name)\n    ax3.set_ylabel(\"Number of Loans\")\n    ax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n\n    ax4 = sns.countplot(ax=ax4,data=unused_df,x=variable_name)\n    ax4.set_title(\"Unused\", fontsize=10)\n    ax4.set_xlabel(variable_name)\n    ax4.set_ylabel(\"Number of Loans\")\n    ax4.set_xticklabels(ax4.get_xticklabels(),rotation=90)\n    \n    plt.show()","58263831":"multi_plot('NAME_CLIENT_TYPE')","cc70e3e3":"multi_plot('CODE_GENDER')","d305ccda":"multi_plot('NAME_EDUCATION_TYPE')","50e4f9ad":"multi_plot('NAME_INCOME_TYPE')","31e6bf2a":"multi_plot('NAME_FAMILY_STATUS')","6245f6d9":"multi_plot('NAME_PAYMENT_TYPE')","60507c87":"multi_plot('NAME_PORTFOLIO')","f765a1f3":"multi_plot('OCCUPATION_TYPE')","bd79318e":"multi_plot('NAME_GOODS_CATEGORY')","8ebd3a14":"multi_plot('PRODUCT_COMBINATION')","a1badbe9":"\nHere laborers are getting most refused and most approved loans. And aslo Sales staff is also getting the second most refused and approved loans.","a5516d38":"Thus, points to be concluded:\n\n-- Income range from 100000 to 200000 is having more number of credits. -- Very less count for income range 400000 and above. -- For income type \u2018working\u2019, \u2019commercial associate\u2019, and \u2018State Servant\u2019 the number of credits are higher than others. -- Less number of credits for income type \u2018student\u2019 ,\u2019pensioner\u2019, \u2018Businessman\u2019 and \u2018Maternity leave\u2019. -- For contract type \u2018cash loans\u2019 is having higher number of credits than \u2018Revolving loans\u2019 contract type.","d468a3e2":"Okay so now here we can see that Females contribute 66.6% to the non-defaulters while 57.1% to the defaulters. We can conclude that we see more female applying for loans than males and hence the more number of female defaulters as well. But the rate of defaulting of FEMALE is much lower compared to their MALE counterparts.","6fecb974":"Here both are linearly related just like below.","c1241847":"# Exploratory Data Analysis","3862c75a":"Again a lot of null values here. let's have a look at the percentage of null values.","31cd9cbc":"We see that car ownership doesn't have any effect on application approval or rejection. But we saw earlier that the people who has a car has lesser chances of default. The bank can add more weightage to car ownership while approving a loan amount","f843a483":"Checking the values to impute in columns\n\n1) EXT_SOURCE_2 imputation","79ddfbc4":"Okay there obviously are a lot of null values here. One approach is to look at the columns having more than or equal to 50% null values and removing them.","c7bb6165":"Here we can see that the Married people are applying and taking loans more than the others.","9b37b3e4":"This is quite obvious that sum of Amount_ANNUITY(Term repayments) is equal to the loan amount and our plot depicts the same when both plots scales are compared it says that the AMT_ANNUITY scale is less than 140000,when compared with No payment difficulties it says that the higher amount installments dont have much much defaulters which is one way profit to the bank with regular payments from customers","dae7c954":"3) NAME_TYPE_SUITE imputation","29e87b82":"4) CNT_FAM_MEMBERS imputation","c4cff354":"### Target: Creating a function to carry out univariate analysis via a bar plot.","a370f82b":"From the above chart, we can infer that, most of the applications are for 'Cash loan' and 'Consumer loan'. Although the cash loans are refused more often than others.","52264b38":"## Bivariate Data Analysis","d60cdfb1":"Here we can see that the range of the customers without payment more as compare to the customers with payment.","dd44c08e":"# Importing the dataset","fc0a263e":"We can see that the density in the lower left corner is similar in both the cases, so the people are equally likely to default if the family is small and the AMT_CREDIT is low. We can observe that larger families and people with larger AMT_CREDIT default less often.","454a74e7":"\nNow here people from 2nd- tier regions apply for loans a lot as their contribution is high in both defaulters and non-defaulters. While people from 3rd- tier regions tend to be more defaulters than non-defaulters. And the 1st- tier people apply for loans very less also they tend to be more non-defaulters than defaulters.","c3913e72":"Now checking datatypes of columns and modify them appropriately.","310b4019":"## Target: Analysing the Target Column","b75e781a":"### Target: Looking at the income dataset deeply","0a58300a":"The most accepting loan is Cash X-sell: low And most canceled loan is Cash and Most Unused loan is POS mobile with interest.","eba7e55a":"Here we can see that the people are taking more loan in format of cash through the bank.","c5fad263":"We can see that the people who were approved for a loan earlier, defaulted less often where as people who were refused a loan earlier have higher chances of defaulting.","5e078738":"# Data Cleaning","58faa9f5":"\nSummary:\n\n--Here we were given two huge datasets namely new_application.csv and previous_application.csv. new_application.csv's shape was (307511, 122) while previous_application.csv's shape was (1670214, 37). Both needed data cleaning as they had a lot of null and NaN values.\n\n--EDA for new_application: After performing eda on new_application data the following insights were discovered:\n\n1. Customers falling under Category: 1(Defaulters\/Having payment difficulties) is about 8 percent and Customers falling under Category : 0(Non-Defaulters) is about 92 percent. Also its ratio was 11.38:1.\n\n2. Females contribute 66.6% to the non-defaulters while 57.1% to the defaulters. We can conclude that we see more female applying for loans than males and hence the more number of female defaulters as well. But the rate of defaulting of FEMALE is much lower compared to their MALE counterparts.\n\n3. People with cars contribute 65.7% to the non-defaulters while 69.5% to the defaulters. We can conclude that While people who have car default more often, the reason could be there are simply more people without cars Looking at the percentages in both the charts, we can conclude that the rate of default of people having car is low compared to people who don't.\n\n4. Most of the loans are distributed to working class people We also see that working class people contribute 51% to non defaulters while they contribute to 61% of the defaulters.\n\n5. Married people tends to apply for loans more often here. But single\/non Married people also contribute 14.5% to Non Defaulters and 18% to the defaulters. So there is more risk associated with them.\n\n6. People living with parents tend to default more often when compared with others.The reason could be their living expenses are more as their parents are living with them.\n\n7. Almost all of the Education categories are equally likely to default except for the higher educated ones who are less likely to default and secondary educated people are more likely to default.\n\n8. The 1st- tier people apply for loans very less also they tend to be more non-defaulters than defaulters.\n\n9. Income range from 100000 to 200000 is having more number of credits.\n\n10. For contract type \u2018cash loans\u2019 is having higher number of credits than \u2018Revolving loans\u2019 contract type.\n\n11. Larger families and people with larger AMT_CREDIT default less often.\n\n12. The higher amount installments dont have much much defaulters.\n\n13. The range of customers without payment of Academic degree is higher than the customer of with payment. And the rest of the Education type is almost same for both the cases.\n\n14. The range of the customers without payment more as compare to the customers with payment.\n\n-- EDA for previous_application: After performing eda on previous_application and all_data data the following insights were discovered:\n\n1. Most of the applications are for 'Cash loan' and 'Consumer loan'. Although the cash loans are refused more often than others.\n\n2. Most of the clients chose to repay the loan using the 'Cash through the bank' option We can also see that 'Non-Cash from your account' & 'Cashless from the account of the employee' options are not at all popular in terms of loan repayment amongst the customers.\n\n3. Most of the loan applications are from repeat customers, out of the total applications 70% of customers are repeaters.\n\n4. Car ownership doesn't have any effect on application approval or rejection. But we saw earlier that the people who has a car has lesser chances of default. The bank can add more weightage to car ownership while approving a loan amount.\n\n5. Code gender doesn't have any effect on application approval or rejection. But we saw earlier that female have lesser chances of default compared to males. The bank can add more weightage to female while approving a loan amount.\n\n6. People who were approved for a loan earlier, defaulted less often where as people who were refused a loan earlier have higher chances of defaulting.\n\n7. The Revolving loan is much more acceptable as compare to the cash and consumer loans.","647d5d94":"5) AMT_GOODS_PRICE","f7385df7":"### Target: compare and look at the datasets for better insights","325083a2":"Here Most Refused loan is of Mobile and most approved loan is Mobile.","24cd2388":"Here we can see that the Revolving loan is much more acceptable as compare to the cash and consumer loans. as we can see that to visualize 4 plots we wrote same code multiple times. so to avoid redundancy, and to save our time, we will put the above code in a function and generalize it for our following plots, so that its easy to visualize and saves time.","cfea41d5":"\nAlmost all of the Education categories are equally likely to default except for the higher educated ones who are less likely to default and secondary educated people are more likely to default.","fc3004ee":"## Previous_application dataset","9ac7f382":"\nHere we can see that the range of customers without payment of Academic degree is higher than the customer of with payment. And the rest of the Education type is almost same for both the cases","1c42928a":"Here we can see that the customers without payment is having more outliers as compare to the customer with payment.","22e0966b":"Here target variables are 1 - client with payment difficulties: he\/she had late payment more than X days on at least one of the first Y installments of the loan in our sample; and 0 - all other cases.","99e0e08d":"\nHere we notice that \"DAYS_BIRTH\",'DAYS_EMPLOYED','DAYS_REGISTRATION'& 'DAYS_ID_PUBLISH' columns have negative values,which is not not possible so we will try to correct this","0a6a93d4":"Here we can see that Secondary\/ Secondary special is more effective in every case.","be32523b":"Thus the imbalance ratio is 11.39.","d4c77e41":"Here we can see that the working type people are applying more loans as compare to others and also Commercial associates people are taking more loans.","ae1bc307":"We can see that people with cars contribute 65.7% to the non-defaulters while 69.5% to the defaulters. We can conclude that While people who have car default more often, the reason could be there are simply more people without cars Looking at the percentages in both the charts, we can conclude that the rate of default of people having car is low compared to people who don't.","2fb9da77":"Thus, Customers falling under Category: 1(Defaulters\/Having payment difficulties) is about 8 percent and Customers falling under Category : 0(Non-Defaulters) is about 92 percent.","90ad7757":"As we can see from the top 10 correlations from both the dataframes, some of top 10 correlations for both are quite similar.","524170c9":"From the above chart, we can infer that most of the clients chose to repay the loan using the 'Cash through the bank' option We can also see that 'Non-Cash from your account' & 'Cashless from the account of the employee' options are not at all popular in terms of loan repayment amongst the customers.","cfcb55ed":"Married people tends to apply for loans more often here. But single\/non Married people also contribute 14.5% to Non Defaulters and 18% to the defaulters. So there is more risk associated with them.","771bd4e3":"Here we can see that the Repeater is getting more Refused but also we can see that the it also getting more approved and even that it is getting more canceled and more usused.","c333f447":"Interesting!\n\nWe notice here that the students don't default. But now here the reason can be that they are not required to pay during the time they are students. We can also see that the BusinessMen never default and so does Unemployed(which is quite obvious) and Maternity leave category. Most of the loans are distributed to working class people We also see that working class people contribute 51% to non defaulters while they contribute to 61% of the defaulters. Clearly, the chances of defaulting are more in their case","5ba239b1":"Most of the loan applications are from repeat customers, out of the total applications 70% of customers are repeaters. They also get refused most often.","e41cd5c9":"Okay now people who have House\/Appartment, tend to apply for more loans. People living with parents tend to default more often when compared with others.The reason could be their living expenses are more as their parents are living with them.","78672d70":"\nAs we can see there are few columns with percentage of null values >0 and <=15 and then among these the columns which have percentage of null values between 0-1 are very few.So, for these columns we can either drop them or impute them with mode value respectively.\n\nFor columns having missing values around 13%, we will check them individually and determine what would be the best possible value to impute them with.","1e7c8d59":"Here most approved loan were through POS and Most refused loans were in cash.","1ee487af":"\nOkay so no rows have more than 50% NaN values. So lets dive deeper.","2b3e6cb8":"2) AMT_ANNUITY imputation","b2b801dc":"## Univariate Data Analysis","1c9ef43e":"We see that code gender doesn't have any effect on application approval or rejection. But we saw earlier that female have lesser chances of default compared to males. The bank can add more weightage to female while approving a loan amount.","ed607633":"Here we observe that OBS_30_CNT_SOCIAL_CIRCLE and OBS_60_CNT_SOCIAL_CIRCLE are linearly related.","6b8d924c":"Here we can see that Female is getting more Refused more approved more canceled more unused but in case of male it is having average in every category","0cbd35dd":"Just checking once again to be sure."}}