{"cell_type":{"6e408ebc":"code","796bff34":"code","ad596c17":"code","e8425236":"code","0cd61c25":"code","d07815c7":"code","aaa8cc03":"code","cf8a6ed4":"code","ef4bd007":"code","a91088ea":"code","e9ffd90d":"code","16d78a84":"code","b5754b07":"code","0fa68eea":"code","9f4d10d3":"code","df3f4de6":"code","1a1e6259":"code","554ed0b2":"code","7d396cda":"code","e62f2177":"code","ba6be5c3":"code","514f6f24":"code","b1f6adc7":"code","d67461e4":"code","ae7520d4":"code","d8d24aff":"code","77b1e7ca":"code","10ea7437":"code","c42ecfc2":"code","0496dc74":"code","f12aa09c":"code","442ef60e":"code","1f6cabbb":"code","132b6ca0":"code","352640ef":"code","d411a42a":"code","01aad38f":"code","cd14d068":"code","fded4166":"code","f88c7fe7":"code","d114e215":"code","270d27e0":"code","08936aa7":"code","1bc074df":"code","519b6205":"code","a2a4dc52":"code","0843e5db":"code","0ee8d597":"markdown","8de5662f":"markdown","46222048":"markdown","168f141c":"markdown","a4d191b0":"markdown","2ac29b6c":"markdown","3fa0e615":"markdown","7c522815":"markdown","7392eb28":"markdown","7f3b5031":"markdown","dcf79dab":"markdown","136ef868":"markdown","af213bf4":"markdown","8dcea840":"markdown","969f332d":"markdown","a6c41f4c":"markdown","a08ad3dd":"markdown","7a7e9d35":"markdown","848ee079":"markdown","4c66054d":"markdown"},"source":{"6e408ebc":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","796bff34":"import warnings\nwarnings.filterwarnings('ignore')","ad596c17":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","e8425236":"train.sample(5)","0cd61c25":"train.info()","d07815c7":"test.info()","aaa8cc03":"for sex in 'male', 'female':\n    mask = (train['Sex'] == sex)\n    value = train.loc[(mask & train['Age'].notnull()), 'Age'].mean()\n    train.loc[mask, 'Age'] = train.loc[mask, 'Age'].fillna(value)","cf8a6ed4":"for sex in 'male', 'female':\n    mask = (test['Sex'] == sex)\n    value = test.loc[(mask & test['Age'].notnull()), 'Age'].mean()\n    test.loc[mask, 'Age'] = test.loc[mask, 'Age'].fillna(value)","ef4bd007":"print(f'Number of NaN in train age data: {train[\"Age\"].isna().sum()}')\nprint(f'Number of NaN in test age data: {test[\"Age\"].isna().sum()}')","a91088ea":"pclass = int(test[test['Fare'].isna()]['Pclass'])\nvalue = round(test[test['Pclass'] == pclass]['Fare'].mean(), 2)\ntest['Fare'].fillna(value, inplace=True)","e9ffd90d":"print(f'Number of NaN in test fare data: {test[\"Fare\"].isna().sum()}')","16d78a84":"train['Cabin'] = train['Cabin'].notnull().astype(int)\ntest['Cabin'] = test['Cabin'].notnull().astype(int)","b5754b07":"pd.DataFrame(train.groupby('Cabin')['Survived'].mean())","0fa68eea":"train['Embarked'].value_counts()","9f4d10d3":"train['Embarked'].fillna('S', inplace=True)","df3f4de6":"train['Title'] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntest['Title'] = test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]","1a1e6259":"pd.crosstab(train['Sex'], train['Title'])","554ed0b2":"royal = ['the Countess', 'Lady', 'Sir', 'Jonkheer', 'Don', 'Dona']\nuncommon = ['Capt', 'Col', 'Dr', 'Major', 'Rev']\nmiss = ['Mlle', 'Ms', 'Miss']\nmrs = ['Mme', 'Mrs']\n\nfor df in train, test:\n    df['Title'] = df['Title'].replace(royal, 'Royal')\n    df['Title'] = df['Title'].replace(uncommon, 'Uncommon')\n    df['Title'] = df['Title'].replace(miss, 'Miss')\n    df['Title'] = df['Title'].replace(mrs, 'Mrs')","7d396cda":"plt.figure(figsize=(12,9))\nsns.histplot(data=train, x='Age', hue='Survived', bins=6, kde=True)\nplt.show()","e62f2177":"train['AgeCategory'] = pd.cut(train['Age'], 6, labels=range(1,7)).astype(int)\ntest['AgeCategory'] = pd.cut(test['Age'], 6, labels=range(1,7)).astype(int)\n\npd.DataFrame(train.groupby('AgeCategory')['Survived'].mean())","ba6be5c3":"plt.figure(figsize=(12,9))\nsns.histplot(data=train, x='Fare', hue='Survived', bins=4)\nplt.show()","514f6f24":"train['FareCategory'] = pd.cut(train['Fare'], 4, labels=range(1,5)).astype(int)\ntest['FareCategory'] = pd.cut(test['Fare'], 4, labels=range(1,5)).astype(int)\n\npd.DataFrame(train.groupby('FareCategory')['Survived'].mean())","b1f6adc7":"train['Sex'] = train['Sex'] == 'male'\ntrain['Sex'] = train['Sex'].astype(int)\n\ntest['Sex'] = test['Sex'] == 'male'\ntest['Sex'] = test['Sex'].astype(int)","d67461e4":"train.info()","ae7520d4":"train = pd.get_dummies(train, columns=['Pclass', 'Embarked', 'Title'])\ntest = pd.get_dummies(test, columns=['Pclass', 'Embarked', 'Title'])","d8d24aff":"data = train.drop('PassengerId', axis=1)\npallete = sns.color_palette(\"magma_r\", as_cmap=True)\n\ndata = abs(data.corr(method='spearman'))\ntril = np.tril(np.ones(data.shape), k=-1).astype(bool)\ndata = data.where(tril)\n\nplt.figure(figsize=(20,15))\nplt.title('Feature Correlation', fontsize=14)\nsns.heatmap(data=data, annot=True, linewidths=.5, cmap=pallete);","77b1e7ca":"X = train.drop(['PassengerId', 'Name', 'Ticket', 'Survived', 'Age', 'Fare'], axis=1)\ny = train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n\nrfc = RandomForestClassifier(random_state=0)\nrfc.fit(X_train, y_train)\n\nfeatures = pd.DataFrame()\nfeatures['feature'] = X_train.columns\nfeatures['importance'] = rfc.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(12, 9))\nplt.show()","10ea7437":"features_col = features.sort_values('importance').index[-10:]\nfeatures_col","c42ecfc2":"# columns = ['Name', 'Ticket', 'AgeCategory', 'FareCategory']\n\n# train.drop(columns, axis=1, inplace=True)\n# test.drop(columns, axis=1, inplace=True)","0496dc74":"train.sample(5)","f12aa09c":"X = train.drop(['PassengerId', 'Survived'], axis=1)[features_col]\ny = train['Survived']","442ef60e":"scaler = StandardScaler().fit(X)\nX = scaler.transform(X)","1f6cabbb":"def model_train(estimator):\n    splits = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n    cv = cross_validate(estimator=estimator, X=X, y=y, scoring='accuracy', cv=splits, n_jobs=-1)\n\n    return cv['test_score'].mean()","132b6ca0":"rfc = RandomForestClassifier(random_state=0)\nrfc_score = model_train(rfc)\nrfc_score","352640ef":"abc = AdaBoostClassifier(random_state=0)\nabc_score = model_train(abc)\nabc_score","d411a42a":"gbc = GradientBoostingClassifier(random_state=0)\ngbc_score = model_train(gbc)\ngbc_score","01aad38f":"gnb = GaussianNB()\ngnb_score = model_train(gnb)\ngnb_score","cd14d068":"svc = SVC(random_state=0)\nsvc_score = model_train(svc)\nsvc_score","fded4166":"lr = LogisticRegression(random_state=0)\nlr_score = model_train(lr)\nlr_score","f88c7fe7":"dtc = DecisionTreeClassifier(random_state=0)\ndtc_score = model_train(dtc)\ndtc_score","d114e215":"knn = KNeighborsClassifier()\nknn_score = model_train(knn)\nknn_score","270d27e0":"lgb = LGBMClassifier(random_state=0, n_jobs=-1)\nlgb_score = model_train(lgb)\nlgb_score","08936aa7":"xgb = XGBClassifier(random_state=0, n_jobs=-1)\n# xgb_score = model_train(xgb)\nxgb_score = 0.8059368526771702\nxgb_score","1bc074df":"estimators = [\n        'RandomForestClassifier',\n        'AdaBoostClassifier',\n        'GradientBoostingClassifier',\n        'GaussianNB',\n        'SVC',\n        'LogisticRegression',\n        'DecisionTreeClassifier',\n        'KNeighborsClassifier',\n        'LGBMClassifier',\n        'XGBClassifier'\n]\n\nscores = [\n        rfc_score,\n        abc_score,\n        gbc_score,\n        gnb_score,\n        svc_score,\n        lr_score,\n        dtc_score,\n        knn_score,\n        lgb_score,\n        xgb_score\n]\n\nestimators = [\n        rfc,\n        abc,\n        gbc,\n        gnb,\n        svc,\n        lr,\n        dtc,\n        knn,\n        lgb,\n        xgb\n]\n","519b6205":"models = pd.DataFrame({'Model': estimators, 'Score': scores})\nmodels.sort_values(by='Score', ascending=False)","a2a4dc52":"def create_submission(estimator):\n    X_test = test.drop('PassengerId', axis=1)[features_col]\n    X_train = train.drop(['PassengerId', 'Survived'], axis=1)[features_col]\n    y_train = train['Survived']\n\n    for X in X_train, X_test:\n        scaler = StandardScaler().fit(X)\n        X = scaler.transform(X)\n    \n    estimator.fit(X_train, y_train)\n    prediction = estimator.predict(X_test)\n    \n    df = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': prediction})\n    df.to_csv('submission.csv', index=False)    \n    print(\"Your submission was successfully saved!\")","0843e5db":"create_submission(lr)","0ee8d597":"# Titanic - Exploratory Data Analysis and Machine Learning from Disaster\n\nAuthor: **Renato Holzlsauer Mattos Macedo**<br>\nContact: **renato.holzlsauer@gmail.com** - [**GitHub**](https:\/\/github.com\/Holzlsauer) - [**LinkedIn**](https:\/\/www.linkedin.com\/in\/holzlsauer\/)\n\n","8de5662f":"# Selecting the model","46222048":"# Feature engineering","168f141c":"# Setup","a4d191b0":"# Feature correlation","2ac29b6c":"## **Age category**","3fa0e615":"## **Age**","7c522815":"# Submission","7392eb28":"## **Passenger title**","7f3b5031":"## **Encoding**","dcf79dab":"## **Cabin**","136ef868":"## **Fare category**","af213bf4":"# Dataset cleaning","8dcea840":"## **Embarked**","969f332d":"## **Training**","a6c41f4c":"## **Fare**","a08ad3dd":"## **Gender**","7a7e9d35":"## **Selecting features**","848ee079":"## **Preprocessing**","4c66054d":"\n    Gaussian Naive Bayes\n    Logistic Regression\n    Support Vector Machines\n    k-Nearest Neighbors\n    AdaBoost Classifier\n    Random Forest Classifier\n    Decision Tree Classifier\n    Gradient Boosting Classifier\n    Extreme Gradient Boosting Machine\n    Light Gradient Boosting Machine\n"}}