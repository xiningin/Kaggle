{"cell_type":{"44a6597a":"code","7b574b5c":"code","b66076da":"code","4fbceb5e":"code","d19f35fb":"code","95d0b51c":"code","b311872f":"code","48c3e21c":"code","2d9b49d3":"code","724f52b2":"code","f3835a09":"code","570a2c5b":"code","56f95196":"code","2ae5e27a":"code","cd736de6":"code","1c9f6519":"code","0206bda7":"markdown","bacf76f0":"markdown","5d6939c4":"markdown","c93d9fb5":"markdown","f85cd2d3":"markdown","4a76c6a4":"markdown","1e58fb9e":"markdown","ec768309":"markdown","5edd6fec":"markdown","0f2d4f69":"markdown","97da4bfa":"markdown","d888e843":"markdown"},"source":{"44a6597a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport pandas as pd\n","7b574b5c":"from sklearn.model_selection import train_test_split\ndf = pd.read_csv('..\/input\/cardiovasc-preprocessed\/cardiovasc.csv',index_col='Unnamed: 0')\n#Aufspalten in Features und Zielvariable\nXfeaturenames = set(df.columns) - set(['y'])\nX = df[Xfeaturenames]\ny = df['y'] #kopiere y\nX.shape,y.shape #Anzahl Zeilen m\u00fcssen \u00fcbereinstimmen (je 68737)\nX_train,X_test, y_train, y_test = train_test_split(X,y,train_size=0.8,random_state=42)\nX_train,X_valid, y_train, y_valid = train_test_split(X_train,y_train,train_size=5000,random_state=42)\nX_train.shape,X_valid.shape","b66076da":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nsvc = SVC(kernel='linear',C=1.0)\nsvc.fit(X_train,y_train);\ny_hat_valid = svc.predict(X_valid)\naccuracy_score(y_hat_valid,y_valid)","4fbceb5e":"def plot_parametercurve(train_scores,test_scores,param_range,xscale='log',xlabel='',title='Validation Curve'):\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(\"Score\")\n    plt.ylim(0.0, 1.1)\n    lw = 2\n    if xscale=='log':\n        pl=plt.semilogx\n    else:\n        pl=plt.plot\n    pl(param_range, train_scores_mean, label=\"Training score\",\n                 color=\"darkorange\", lw=lw,marker='x')\n    \n\n    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.2,\n                     color=\"darkorange\", lw=lw)\n    pl(param_range, test_scores_mean, label=\"Cross-validation score\",\n                 color=\"navy\", lw=lw,marker='x')\n    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.2,\n                     color=\"navy\", lw=lw)\n    plt.legend(loc=\"best\")\n    plt.ylim(0.5,1)","d19f35fb":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import validation_curve\nsvc_linear = SVC(kernel='linear')\nC_param_range = [0.01,0.1,1,10,50,100]\n#accuracies_svc = cross_val_score(estimator=svc, X=x_train_part, y=y_train_part, cv=10)\ntrain_scores ,valid_scores = validation_curve(svc_linear,X_train,y_train,param_name='C',param_range=C_param_range,verbose=2,cv=5,n_jobs=5)","95d0b51c":"plot_parametercurve(train_scores,valid_scores,C_param_range,xscale='log',xlabel='C',title='Validation Curve for linear SVC')","b311872f":"optimaler_C_Wert=1.0 #<--- Finden Sie einen geeigneten Wert","48c3e21c":"accuracies_svc = cross_val_score(estimator=SVC(C=optimaler_C_Wert,#<--- Hier Ihre Wahl des Hyperparameters C eingeben\n                                               kernel='linear' # <-- sollte gleich sein wie in svc in der vorletzeten Zelle\n                                              ), \n                                 X=X_train, y=y_train, \n                                 cv=10 # die Anzahl Cross-Validation Folds. Sie sollten verstehen, was das bedeutet\n                                )\nprint(f'Genauigkeit lineare SVC: {np.mean(accuracies_svc):1.3f}+\/-{np.std(accuracies_svc):1.3f}')","2d9b49d3":"gamma=1.0  #ob dieser Wert gut ist...? \nsvc_rbf = SVC(kernel='rbf',gamma=gamma)\nC_param_range = [0.01,0.1,1,10,50,100]\n\ntrain_scores ,valid_scores = validation_curve(svc_rbf,X_train,y_train,param_name='C',param_range=C_param_range,verbose=2,cv=5,n_jobs=5)\nplot_parametercurve(train_scores,valid_scores,C_param_range,xscale='log',xlabel='C',title=fr'Validation Curve for rbf SVM with $\\gamma={gamma}$')","724f52b2":"gamma_param_range = [0.001,0.01,0.1,0.5,1,10]\nsvc_rbf = SVC(kernel='rbf',C=1.0)\n\ntrain_scores ,valid_scores = validation_curve(svc_rbf,X_train,y_train,param_name='gamma',param_range=gamma_param_range,verbose=2,cv=5,n_jobs=5)\nplot_parametercurve(train_scores,valid_scores,C_param_range,xscale='log',xlabel='C',title=fr'Validation Curve for rbf SVM with $\\gamma={gamma}$')","f3835a09":"accuracies_svc = cross_val_score(estimator=SVC(C=1,kernel='rbf',gamma=1.0), X=X_train, y=y_train,n_jobs=5, cv=10,verbose=1)\nprint(f'Genauigkeit rbf-SVM: {np.mean(accuracies_svc):1.3f}+\/-{np.std(accuracies_svc):1.3f}')","570a2c5b":"svc_rbf = SVC(kernel='rbf',C=2, gamma=0.1)","56f95196":"C=1.0 # <- Spielen Sie mit dem Wert des Parameters!\nsvc_rbf = SVC(kernel='rbf',C=C, gamma=0.1)\n\n\ntrain_scores ,valid_scores = validation_curve(svc_rbf,X_train,y_train,param_name='gamma',param_range=gamma_param_range,verbose=2,cv=5,n_jobs=5)\nplot_parametercurve(train_scores,valid_scores,C_param_range,xscale='log',xlabel=r'$\\gamma$',title=f'Validation Curve for rbf SVM for C={C}')","2ae5e27a":"from sklearn.model_selection import GridSearchCV\nC_param_range=  [0.001,0.01,0.1,1,10,100,500,1000]\ngamma_param_range\nsvc = SVC(kernel='rbf')\n#GridSearchCV?\ngs = GridSearchCV(svc,{'C':C_param_range,'gamma':gamma_param_range},cv=5,n_jobs=5,verbose=1,return_train_score=True)\ngs.fit(X_train,y_train)","cd736de6":"gs.cv_results_","1c9f6519":"\naccuracies_svc = cross_val_score(estimator=gs.best_estimator_, X=X_valid.iloc[:10000], y=y_valid.iloc[:10000],n_jobs=10, cv=10,verbose=2)\nprint(f'Genauigkeit rbf-SVM: {np.mean(accuracies_svc):1.3f}+\/-{np.std(accuracies_svc):1.3f}')","0206bda7":"### Grid Search \nIm obigen Ansatz haben Sie zun\u00e4chst den Parameter C (f\u00fcr gamma=1.0) optimiert, dann f\u00fcr diesen optimalen Wert von C den Parameter gamma optimiert. Vermuten Sie hier auch einen Fehlschluss? Besser w\u00e4re es, alle Kombinationen von ($\\gamma$,C)-Wertpaaren zu \u00fcberpr\u00fcfen. Das ist aufw\u00e4ndig, bringt aber manchmal etwas:","bacf76f0":"### **Datenimport**","5d6939c4":"### Parameterkurven f\u00fcr Supportvektormaschinen (mit Kernel Trick)\nAnstatt des linearen Soft-Margin-Klassifikators nehmen wir nun die Supportvektormaschine mit einem rbf-Kernel. Dies f\u00fchrt einen weiteren Parameter ein, $\\gamma$. Angenommen, wir w\u00fcssten den bestm\u00f6glichen Wert f\u00fcr $\\gamma$ bereits: Dann k\u00f6nnen wir f\u00fcr C und $\\gamma$ ebenfalls jeweils eine Parameterkurve zeichnen:","c93d9fb5":"- Versuchen Sie, die erhaltenen Resultate zu beschreiben. Was wurde hier mit den Parameterkurven bzw. dem GridSearch erreicht? Hat sich der Aufwand gelohnt? Welche Leistung w\u00fcrden Sie einem Abnehmer Ihres Prototypen versprechen?","f85cd2d3":"## Cardiovascular Disease Prediction\n**Verwandtes Notebook von Benan AKCA, https:\/\/www.kaggle.com\/benanakca\nPhD Student, Marmara University \u0130stanbul, Turkey** <a id=\"0\"><\/a>\n\n## Einf\u00fchrung <a id=\"1\"><\/a>\n<mark>[Return Contents](#0)\n<hr>\nBasierend auf nummerischen und kategorischen Merkmalen des \"cardiovascular disease datasets\" soll eine Supportvektormaschine optimiert werden. Wir laden erst mal die Daten:","4a76c6a4":"F\u00fcr die beste Parameterkombination werten wir den Klassifikator auf einem Validierungsset aus. (Streng genommen wird hier auf dem Validierungsset auch trainiert. Die Overfitting- bzw. Data Snooping-Gefahr besteht, aber in einer milden Art, die wir f\u00fcr einmal akzeptieren.","1e58fb9e":"[![smile.jpg](https:\/\/i.postimg.cc\/0jVh4z64\/smile.jpg)](https:\/\/postimg.cc\/fS0HtTf7)","ec768309":"### **Import der Module** <a id=\"2\"><\/a>\n<mark>[Return to Contents](#0)\n<hr>\n\nImporting the necessary modules.","5edd6fec":"The \"default\" values in the following classifiers are already updated using the validation curves shown later. ","0f2d4f69":" \n### Parameterkurven f\u00fcr Linearen SVC","97da4bfa":"- Interpretieren Sie den obigen Plot. Welche Aussagen lassen sich machen? Was empfehlen Sie f\u00fcr den weiteren Projektverlauf?","d888e843":"- W\u00e4hlen Sie nun an Hand des obigen Plots einen passenden Wert f\u00fcr C, und werten Sie in der n\u00e4chsten Zeile Ihre Supportvektormaschine aus"}}