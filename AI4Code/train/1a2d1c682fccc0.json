{"cell_type":{"85a18201":"code","e158a6c3":"code","47ac5c9b":"code","45d328e2":"code","51dd031c":"code","af6524ad":"code","da47e100":"code","49357894":"code","fb9770fa":"code","5bea1a8c":"code","17d510b9":"code","ce63dabe":"code","11d1551f":"code","6cc4a57f":"code","3812aaf3":"code","4e5d936e":"code","74125151":"code","59d39292":"code","9f46f096":"code","a12061a2":"markdown","2b99228c":"markdown"},"source":{"85a18201":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e158a6c3":"import tensorflow as tf\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import regularizers, optimizers\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.datasets import mnist\n\n# Ignore the warnings\nimport warnings\n\n# suppress display of warnings\nwarnings.filterwarnings('ignore')","47ac5c9b":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","45d328e2":"# Extract label\ny = train['label']\n\n# Extract features\nfeatures = train.drop('label', axis=1)","51dd031c":"print(train.shape, test.shape, y.shape)","af6524ad":"# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n# x_train = x_train.reshape(60000, -1)\n# x_test = x_test.reshape(10000, -1)\n# train = np.concatenate([train, x_train, x_test], axis = 0)\n# y = np.concatenate([y, y_train, y_test], axis = 0)\n# print(train.shape, y.shape)","da47e100":"# train = tf.reshape(train, (-1, 28, 28, 1))\n# test = tf.reshape(test, (-1, 28, 28, 1))\n# print(train.shape, test.shape)","49357894":"# Train images\nX = np.array(features)\nX_train = X.reshape(X.shape[0], 28, 28)\n\n# Test images\nX_test = np.array(test)","fb9770fa":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","5bea1a8c":"print(\"X_train shape:\", X_train.shape)\nprint(\"Images in X_train:\", X_train.shape[0])\nprint(\"Images in X_test:\", X_test.shape[0])\nprint(\"Max value in X_train:\", X_train.max())\nprint(\"Min value in X_train:\", X_train.min())","17d510b9":"y = to_categorical(y, num_classes=10)      \nprint(\"Shape of y_train:\", y.shape)      \nprint(\"One value of y_train:\", y[0])      ","ce63dabe":"# model = Sequential() \n# model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1))) \n# model.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\")) \n# model.add(Flatten()) \n# model.add(Dense(128, activation=\"relu\")) \n# model.add(Dense(10, activation=\"softmax\")) ","11d1551f":"# # Compile the model\n# model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\n# # Fit the model\n# model.fit( X_train, y, batch_size=32, epochs=20, validation_split = 0.3)","6cc4a57f":"# Initialize the model\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size=3, activation=\"relu\"))\nmodel.add(BatchNormalization()) \nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(10, activation = \"softmax\"))","3812aaf3":"# Optimizer\nsgd = optimizers.SGD(lr = 2e-2, decay = 1e-6, momentum = 0.9)\n  \n# Compile the model \nmodel.compile(loss = \"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer=sgd)","4e5d936e":"# Adding callbacks\n# es = EarlyStopping(monitor='val_loss', mode = 'min', patience=10, min_delta=1E-4, restore_best_weights=True)\nrlrp = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.01, patience = 10, min_delta = 1E-4)\n\ncallbacks = [rlrp]\n# Fit the model\nhistory = model.fit(x = X_train, y = y, batch_size = 16, epochs = 100, validation_split = 0.3, callbacks=[callbacks]) ","74125151":"# Predict on Test set\npreds = np.argmax(model.predict(X_test), axis=1)  ","59d39292":"submission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv') ","9f46f096":"submission['Label'] = preds\nsubmission.to_csv('submission_1.csv',index=False) ","a12061a2":"# Digit Recognizer","2b99228c":"* This notebook contains the code for the Digit Recognizer Competition.\n* in this notebook, I tried out architectures using Conv2D, Dense, Dropout, MaxPool2D and BatchNormalization.\n* I also used various optimizers i.e. RMSProp, Adam, SGD and different callbacks like Reduce Learning Rate on Plateau and Early Stop."}}