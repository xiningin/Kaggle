{"cell_type":{"29f7dd61":"code","457dbd05":"code","3e4b05b7":"code","a562797b":"code","43522482":"code","353c7fae":"code","b3a57d34":"code","e42ab738":"code","c1f3cc93":"code","ccbecc12":"code","8f445fda":"code","212ed610":"code","57aa41aa":"code","c4320fa4":"code","17a1b9cb":"code","406593f7":"code","f8b5ccc0":"code","f0de6db8":"code","130502e8":"code","e57f398e":"code","0c579f9d":"code","637515b8":"code","c946037f":"code","831f7604":"code","3c69b413":"code","5f527481":"code","643ec9e8":"code","8cc63166":"code","1e33fabd":"code","208d5771":"code","b9026256":"code","44553ee2":"code","d4151469":"code","968f0a68":"code","26957f80":"code","6e7756f3":"code","be9d86b6":"code","b86d3073":"code","93c2a403":"code","b082b1f9":"code","42910891":"markdown","aeda8022":"markdown","6d5418f5":"markdown","9c0e71a2":"markdown","c6897c58":"markdown","f596fc47":"markdown","34e23f05":"markdown","9a22b577":"markdown","1eddc2c3":"markdown","efc1df6b":"markdown","e8d60b43":"markdown","5e11cc54":"markdown","0eed35ea":"markdown","25108085":"markdown","951f48bc":"markdown"},"source":{"29f7dd61":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nsns.set_style('darkgrid')","457dbd05":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nalldata = pd.concat([train,test],sort=False)\ntrain.head()","3e4b05b7":"plt.figure(figsize=(10,20))\nplt.subplot(3,1,1)\nsns.barplot(y='Survived',\n            x='Pclass',\n            hue='Sex',\n            data=train)\n\nplt.subplot(3,1,2)\nsns.barplot(y=alldata['Survived'],\n            x=alldata['Cabin'].str[0],\n            hue=alldata['Sex'],\n            ci=None)\n\nplt.subplot(3,1,3)\nsns.barplot(y='Survived',\n            x='Embarked',\n            hue='Sex',\n           data=train)","a562797b":"plt.figure(figsize=(10,15))\nplt.subplot(2,1,1)\nsns.distplot(alldata['Age'])\n\n\nplt.subplot(2,1,2)\nsns.distplot(np.log1p(alldata['Fare']))","43522482":"alldata['Age'] = alldata['Age'].fillna(value=alldata['Age'].median())\nalldata['Fare'] = alldata['Fare'].fillna(value=alldata['Fare'].median())\nalldata['Embarked'] = alldata['Embarked'].fillna('S') #S is median","353c7fae":"#Age\nalldata.loc[ alldata['Age'] <= 20, 'Age_Band'] = 0\nalldata.loc[(alldata['Age'] > 20) & (alldata['Age'] <= 25), 'Age_Band'] = 1\nalldata.loc[(alldata['Age'] > 25) & (alldata['Age'] <= 30), 'Age_Band'] = 2\nalldata.loc[(alldata['Age'] > 30) & (alldata['Age'] <= 40), 'Age_Band'] = 3\nalldata.loc[ alldata['Age'] > 40, 'Age_Band'] = 4 ","b3a57d34":"alldata['Fare_Log'] =np.log1p(alldata['Fare'])\nplt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nsns.distplot(alldata['Fare_Log'])\n\n\nplt.subplot(1,2,2)\nsns.boxplot(alldata['Fare_Log'])","e42ab738":"alldata.loc[alldata['Fare_Log'] < 2,'Fare_Band'] = 1\nalldata.loc[(alldata['Fare_Log'] >= 2) & (alldata['Fare_Log'] < 2.5),'Fare_Band'] = 2\nalldata.loc[(alldata['Fare_Log'] >= 2.5) & (alldata['Fare_Log'] < 3),'Fare_Band'] = 3\nalldata.loc[(alldata['Fare_Log'] >= 3) & (alldata['Fare_Log'] < 4),'Fare_Band'] = 4\nalldata.loc[alldata['Fare_Log'] >= 4,'Fare_Band'] = 5","c1f3cc93":"alldata[[\"Fare_Band\",\"PassengerId\",\"Survived\"]].groupby('Fare_Band').count()","ccbecc12":"alldata[[\"Age_Band\",\"PassengerId\",\"Survived\"]].groupby('Age_Band').count()","8f445fda":"plt.figure(figsize=(10,15))\nplt.subplot(2,1,1)\nsns.barplot(y='Survived',\n           x='Age_Band',\n            ci=None,\n           data=alldata)\n\n\nplt.subplot(2,1,2)\n\nsns.barplot(y='Survived',\n           x='Age_Band',\n            hue='Sex',\n            ci=None,\n           data=alldata)","212ed610":"import re\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+\\.)', name)\n    \n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nalldata['Title'] = alldata['Name'].apply(get_title)\n#alldata['Title'].value_counts()","57aa41aa":"alldata['Title'] = alldata['Title'].replace(['Capt.', 'Dr.', 'Major.', 'Rev.',\"Col.\"], 'Officer.')\nalldata['Title'] = alldata['Title'].replace(['Lady.', 'Countess.', 'Don.', 'Sir.', 'Jonkheer.', 'Dona.'], 'Royal.')\nalldata['Title'] = alldata['Title'].replace(['Mlle.', 'Ms.'], 'Miss.')\nalldata['Title'] = alldata['Title'].replace(['Mme.'], 'Mrs.')\nalldata['Title'].value_counts()","c4320fa4":"alldata['Family_Size'] = alldata['SibSp'] + alldata['Parch'] + 1\nalldata['IsAlone'] = 0\nalldata.loc[alldata['Family_Size']==1, 'IsAlone'] = 1\nalldata.head()","17a1b9cb":"#Cabin\nalldata['Cabin'] = alldata['Cabin'].fillna('Missing')\nalldata['Cabin'] = alldata['Cabin'].str[0]\n#alldata['Cabin'].value_counts()","406593f7":"#Drop unwanted variables\nall_1 = alldata.drop(['Name', 'Ticket'], axis = 1)\nall_1.head()","f8b5ccc0":"#Uncomment Below Line to Go ahead with Onehot encoding\n\nall_dummies = pd.get_dummies(all_1, drop_first = False)\nall_dummies","f0de6db8":"all_train = all_dummies[all_dummies['Survived'].notna()]\n#all_train.head()\nall_test = all_dummies[all_dummies['Survived'].isna()]\n#all_test.head()","130502e8":"#all_lab_enc = all_1.copy()\nall_lab_enc[['Title','Survived']].groupby('Title').count()","e57f398e":"all_lab_enc = all_lab_enc.drop(columns=['Cabin'])\nall_lab_enc['Embarked'] = all_lab_enc['Embarked'].map({\"C\":0 , \"S\":1 , \"Q\":2})\nall_lab_enc['Sex'] = all_lab_enc['Sex'].map( {'female': 1, 'male': 0} )\n\ntitle_mapping = {\"Mr.\": 1, \"Miss.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Officer.\": 5 ,\"Royal.\": 6}\nall_lab_enc['Title'] = all_lab_enc['Title'].map( title_mapping )\n\nall_lab_enc = all_lab_enc.drop(columns=['Family_Size','Parch','SibSp'])\nall_lab_enc['Age_Band'] = all_lab_enc['Age_Band'].astype(int)\nall_lab_enc['Fare_Band'] = all_lab_enc['Fare_Band'].astype(int)\n\nall_lab_enc = all_lab_enc.drop(columns=['Age','Fare','Fare_Log'])","0c579f9d":"all_train = all_lab_enc[all_lab_enc['Survived'].notna()]\n#all_train.head()\nall_test = all_lab_enc[all_lab_enc['Survived'].isna()]\n#all_test.head()","637515b8":"plt.figure(figsize=(30,15+10))\n#plt.figure(figsize=(7,7))\n\ncorr_mat = all_train.drop(columns=['PassengerId']).corr()\nmask = np.triu(np.ones_like(corr_mat, dtype=np.bool))\nsns.heatmap(corr_mat,mask=mask,cmap='RdBu',annot=True)","c946037f":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nX = all_train.drop(['PassengerId','Survived'],axis=1)\ny = all_train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=0,\n                                                    stratify = all_train['Survived'])","831f7604":"accuracy_model ={}","3c69b413":"logmodel = LogisticRegression(solver = 'liblinear')\nlogmodel.fit(X_train,y_train)\npredictions = logmodel.predict(X_test)\nacc_logreg = logmodel.score(X_test,y_test)\n\nprint(acc_logreg)\naccuracy_model['Logistic Regression'] = acc_logreg","5f527481":"#print(classification_report(y_test,predictions))\nsns.heatmap(confusion_matrix(y_test,predictions),annot=True,cmap='OrRd')","643ec9e8":"coeff_df = pd.DataFrame(X.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logmodel.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False).style.background_gradient(cmap=\"OrRd\")","8cc63166":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = (decision_tree.score(X_test, y_test))\nprint(acc_decision_tree)\naccuracy_model['Decision Tree'] = acc_decision_tree\n#print(classification_report(y_test,Y_pred))","1e33fabd":"sns.heatmap(confusion_matrix(y_test,decision_tree.predict(X_test)),annot=True,\n            cmap='OrRd');","208d5771":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","b9026256":"rf = RandomForestClassifier(random_state = 42)\nrf_random = RandomizedSearchCV(estimator = rf,\n                               param_distributions = random_grid,\n                               n_iter = 50, \n                               cv = 3, \n                               verbose=2, \n                               random_state=42,\n                               n_jobs = -1)","44553ee2":"#rf_random.fit(X_train,y_train)\n#print(rf_random.best_params_)","d4151469":"rf2 = RandomForestClassifier(n_estimators = 400,\n                           min_samples_split = 5,\n                           min_samples_leaf = 1,\n                           max_features = 'sqrt',\n                           max_depth = 30,\n                           bootstrap = True)\n\nrf2.fit(X_train,y_train)\n\nacc_random_forest = rf2.score(X_test,y_test)\naccuracy_model['Random Forest'] = acc_random_forest\n\nprint(acc_random_forest)\nsns.heatmap(confusion_matrix(y_test,rf2.predict(X_test)),annot=True,cmap ='OrRd');","968f0a68":"svc = SVC()\nsvc.fit(X_train, y_train)\nY_pred = svc.predict(X_test)\n\nacc_svc = svc.score(X_test, y_test)\nprint(acc_svc)\naccuracy_model['Support Vector Machines'] = acc_svc","26957f80":"sns.heatmap(confusion_matrix(y_test,svc.predict(X_test)),\n            annot=True,\n            cmap='OrRd');","6e7756f3":"knn = KNeighborsClassifier(n_neighbors = 3)\n\nknn.fit(X_train, y_train)\nY_pred = knn.predict(X_test)\nacc_knn = (knn.score(X_test, y_test))\n\naccuracy_model['KNN'] = acc_knn\nprint(acc_knn)","be9d86b6":"sns.heatmap(confusion_matrix(y_test,knn.predict(X_test)),\n            annot=True,\n            cmap='OrRd');","b86d3073":"model_summ=pd.DataFrame({'Model': list(accuracy_model.keys()),\n                          'Score': list(accuracy_model.values()) })\n\nplt.figure(figsize=(10,5))\nsns.barplot(data=model_summ,\n           y='Model',\n           x='Score',\n           palette='muted')","93c2a403":"finalmodel = logmodel\ntest_features = all_test.drop(['PassengerId','Survived'],axis=1)\n\nfinalmodel.fit(X,y)\npredictions = finalmodel.predict(test_features)","b082b1f9":"submissions = pd.DataFrame(zip(all_test.PassengerId,predictions.astype(int)),columns=['PassengerId','Survived'])\nsubmissions.to_csv(\"Submissions.csv\",index=False)","42910891":"Now, as with age, classifying Fares into slabs, but first lognormalize it","aeda8022":"### Random Forest Classifier","6d5418f5":"### Label Encoding Approach","9c0e71a2":"As the Logistic Regression Model performs the best, We will use it for Prediction","c6897c58":"## Model Creation and Evaluation","f596fc47":"### Logistic Regression","34e23f05":"## Visualizing the Data ","9a22b577":"## Model Summary","1eddc2c3":"### KNN Classification","efc1df6b":"## Prediction using Test Data","e8d60b43":"### Decision Tree Classifier","5e11cc54":"## Feature Engineering & Pre Processing","0eed35ea":"### One Hot Encoding All Categories","25108085":"### Visualizing Correlation between Variables","951f48bc":"### Support Vector Machines"}}