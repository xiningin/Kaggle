{"cell_type":{"23069548":"code","236b8fe3":"code","76e015de":"code","3585d40e":"code","b30bff66":"code","ca7803d6":"code","2a8b2a85":"code","d87980c2":"code","6be544bc":"code","187a1a8b":"code","f823da48":"code","5658395c":"code","ab831695":"code","0a435a51":"code","a497a69f":"code","59c5b355":"code","c0b21d0a":"code","6e9a7bdc":"code","d8ab8d80":"code","48bd5ae9":"code","a11d0e08":"code","c3577aeb":"code","02f26916":"code","cfbf098d":"code","550b2807":"code","d3e6527d":"code","48b0ebde":"code","f964d9e8":"code","299cb7c9":"code","f4da37d4":"code","508a5754":"code","0f4e7c99":"code","8646574f":"code","4f84d670":"code","5eecf1a7":"code","31566ff2":"code","caf14bc4":"code","44f68ef2":"code","62a5e963":"code","6ff75c7e":"code","9c5c56cc":"code","30287b3a":"code","143b65bd":"code","49fb8450":"code","49457bda":"code","4f573a34":"code","3885be1a":"code","9e87ae97":"code","b6766031":"code","cb537909":"code","57a69e0b":"code","33629e18":"code","d3918290":"code","41574099":"code","1a41a96e":"code","a2fc7eb0":"code","b7f53a26":"code","0d52838f":"code","fbad611f":"code","87ef1d4b":"code","2c862803":"code","4dc0aa3b":"code","31c3a9af":"code","f0dfa4ca":"code","49d9ba39":"code","9e6e4460":"code","a9ab5cee":"code","2a2a1b2c":"code","e7a980ef":"code","a50bc68e":"code","b3eb142a":"markdown","d4828bd8":"markdown","32c2a9db":"markdown","962e3c9d":"markdown","817c3bb4":"markdown","7d1f11e4":"markdown","8cabe06d":"markdown","5989436d":"markdown","4d0f8abc":"markdown","cbd3bacb":"markdown","ec6bbf59":"markdown","46464437":"markdown","51a2bcab":"markdown","c73c4fd8":"markdown","b4b93a21":"markdown","3804f57e":"markdown","620e11d1":"markdown","cef3c920":"markdown","35d1232d":"markdown","153fa7ae":"markdown","87dbdd9c":"markdown","b01f9ff5":"markdown","6b17947a":"markdown","b90d589d":"markdown","f266674d":"markdown","fa75b6bd":"markdown","71ec7366":"markdown","1a8066eb":"markdown","f885c4b7":"markdown"},"source":{"23069548":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport missingno as msno\nimport seaborn as sns\nfrom collections import Counter\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom xgboost.sklearn import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","236b8fe3":"df = pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')","76e015de":"print(df.head(10))","3585d40e":"print(df.shape)","b30bff66":"print(df.info())","ca7803d6":"unique_count = []\n\nfor col in df.columns:\n    unique_count.append(len(df[col].unique()))\n\nprint(pd.Series(unique_count, index = df.columns))","2a8b2a85":"print(df.describe(include='all'))","d87980c2":"x = df.Potability.value_counts()\nlabels = [0, 1]\nprint(x)","6be544bc":"fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(16,6))\n\nax[0].pie(x, \n        labels = labels,\n        autopct = '%1.1f%%',\n        colors=['orange', 'steelblue'], \n        explode = [0.005]*len(labels),\n        textprops={'size': 'x-large'},\n        wedgeprops={'linewidth': 3.0, 'edgecolor': 'white'})\n\nax[1].bar(labels,height=x,color=['orange', 'steelblue'])\nax[1].set_xlabel('Potability')\nax[1].set_ylabel('Count')\nax[1].set_xticks([0, 1])\n\nplt.show()","187a1a8b":"cor_mat = df.corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig = plt.gcf()\nfig.set_size_inches(30, 12)\nsns.heatmap(data=cor_mat, mask=mask, square=True, annot=True, cbar=True)","f823da48":"fig, ax = plt.subplots(ncols=2, nrows=9, figsize=(14, 42))\n\nfeatures = list(df.columns.drop('Potability'))\ntarget = 'Potability'\nidx = 0\n\nfor col in features:\n    sns.violinplot(data=df, y=col, x=target, ax=ax[idx, 0],\n                   inner='quartile', color='pink')\n    \n    sns.boxplot(data=df, y=col, x=target, ax=ax[idx, 1],\n                palette=('orange', 'steelblue'))\n    \n    idx += 1\nplt.show()","5658395c":"df.drop('Potability', axis=1).hist(bins=10, figsize=(20, 20))\nplt.show()","ab831695":"msno.matrix(df, color=(0, 0, 0))","0a435a51":"df.isnull().sum() \/ 2620 * 100","a497a69f":"phMean_0 = df[df['Potability'] == 0]['ph'].mean(skipna=True)\ndf.loc[(df['Potability'] == 0) & (df['ph'].isna()), 'ph'] = phMean_0\nphMean_1 = df[df['Potability'] == 1]['ph'].mean(skipna=True)\ndf.loc[(df['Potability'] == 1) & (df['ph'].isna()), 'ph'] = phMean_1\n\nSulfateMean_0 = df[df['Potability'] == 0]['Sulfate'].mean(skipna=True)\ndf.loc[(df['Potability'] == 0) & (df['Sulfate'].isna()), 'Sulfate'] = SulfateMean_0\nSulfateMean_1 = df[df['Potability'] == 1]['Sulfate'].mean(skipna=True)\ndf.loc[(df['Potability'] == 1) & (df['Sulfate'].isna()), 'Sulfate'] = SulfateMean_1\n\nTrihalomethanesMean_0 = df[df['Potability'] == 0]['Trihalomethanes'].mean(skipna=True)\ndf.loc[(df['Potability'] == 0) & (df['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_0\nTrihalomethanesMean_1 = df[df['Potability'] == 1]['Trihalomethanes'].mean(skipna=True)\ndf.loc[(df['Potability'] == 1) & (df['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_1","59c5b355":"X = df.drop('Potability', axis=1)\ny = df.Potability\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(X_train.shape, X_test.shape)","c0b21d0a":"print('Balancing the data by SMOTE - Oversampling of Minority level\\n')\nsmt = SMOTE()\n\ncounter = Counter(y_train)\nprint('Before SMOTE', counter)\n\nX_train, y_train = smt.fit_resample(X_train, y_train)\n\ncounter = Counter(y_train)\nprint('\\nAfter SMOTE', counter)","6e9a7bdc":"models = [LogisticRegression(), LinearSVC(), SVC(kernel='rbf'), KNeighborsClassifier(), RandomForestClassifier(),\n          DecisionTreeClassifier(), GradientBoostingClassifier(), GaussianNB()]\nmodel_names = ['LogistivRegression', 'LinearSVM', 'rbfSVM', 'KNearestNeighbors', 'RandomForestClassifier', 'DecisionTree',\n               'GradientBoostingClassifier', 'GaussianNB']\n\nacc = []\n\nfor model in range(len(models)):\n    clf = models[model]\n    clf.fit(X_train, y_train)\n    pred = clf.predict(X_test)\n    acc.append(accuracy_score(pred, y_test))\n\nmodels = {'Modelling Algo': model_names, 'Accuracy': acc}","d8ab8d80":"models_df = pd.DataFrame(models)","48bd5ae9":"models_df","a11d0e08":"sns.barplot(y='Modelling Algo', x='Accuracy', data=models_df)","c3577aeb":"def feature_scaling(X_train, X_test, y_train, y_test, name_scaler):\n    models = [LogisticRegression(), LinearSVC(), SVC(kernel='rbf'), KNeighborsClassifier(), RandomForestClassifier(),\n              DecisionTreeClassifier(), GradientBoostingClassifier(), GaussianNB()]\n\n    acc_sc = []\n    for model in range(len(models)):\n        clf = models[model]\n        clf.fit(X_train, y_train)\n        pred = clf.predict(X_test)\n        acc_sc.append(accuracy_score(pred, y_test))\n\n    models_df[name_scaler] = np.array(acc_sc)","02f26916":"scalers = [MinMaxScaler(), StandardScaler()]\nnames = ['Acc_Min_Max_Scaler', 'Acc_Standard_Scaler']\nfor scale in range(len(scalers)):\n    scaler = scalers[scale]\n\n    scaled_X_train = scaler.fit_transform(X_train)\n    scaled_X_test = scaler.transform(X_test)\n\n    feature_scaling(scaled_X_train, scaled_X_test, y_train, y_test, names[scale])","cfbf098d":"models_df","550b2807":"ssc = StandardScaler()\n\nX_train = ssc.fit_transform(X_train)\nX_test = ssc.transform(X_test)","d3e6527d":"sns.barplot(y='Modelling Algo', x='Accuracy', data=models_df)","48b0ebde":"sns.barplot(y='Modelling Algo', x='Acc_Min_Max_Scaler', data=models_df)","f964d9e8":"sns.barplot(y='Modelling Algo', x='Acc_Standard_Scaler', data=models_df)","299cb7c9":"model, test_accuracy = [], []","f4da37d4":"param_grid = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000]}\n\nlogreg_clf = GridSearchCV(LogisticRegression(), param_grid, scoring='accuracy', cv=10)\nlogreg_clf.fit(X_train, y_train)","508a5754":"logreg_clf.best_params_","0f4e7c99":"logreg_clf.best_score_","8646574f":"pred = logreg_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('LogisticRegression')\ntest_accuracy.append(accuracy)\nprint(\"Logistic Regression Accuracy:\", accuracy)","4f84d670":"print(classification_report(y_test, pred))","5eecf1a7":"param_grid = {'C': [0.98, 1.0, 1.2, 1.5, 2.0, 5.0], \n              'gamma': [0.50, 0.60, 0.70, 0.80, 0.90, 1.00], \n              'kernel': ['linear', 'rbf']}\n\nsvm_clf = GridSearchCV(SVC(), param_grid, scoring='accuracy', cv=10)\nsvm_clf.fit(X_train, y_train)","31566ff2":"svm_clf.best_params_","caf14bc4":"svm_clf.best_score_","44f68ef2":"pred = svm_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('SVM')\ntest_accuracy.append(accuracy)\nprint(\"SVM Accuracy:\", accuracy)","62a5e963":"print(classification_report(y_test, pred))","6ff75c7e":"param_grid = {'n_neighbors': [i+1 for i in range(50)], 'n_jobs': [-1]}\n\nknn_clf = GridSearchCV(KNeighborsClassifier(),param_grid, scoring='accuracy', cv=10)\nknn_clf.fit(X_train, y_train)","9c5c56cc":"knn_clf.best_params_","30287b3a":"knn_clf.best_score_","143b65bd":"pred = knn_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('KNN')\ntest_accuracy.append(accuracy)\nprint(\"KNN Accuracy:\", accuracy)","49fb8450":"print(classification_report(y_test, pred))","49457bda":"param_grid = {'criterion': ['gini', 'entropy'], \n              'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 120, 150]}\n\ndt_clf = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='accuracy', cv=10)\ndt_clf.fit(X_train, y_train)","4f573a34":"dt_clf.best_params_","3885be1a":"dt_clf.best_score_","9e87ae97":"pred = dt_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('Decision Tree')\ntest_accuracy.append(accuracy)\nprint(\"Decision Tree Accuracy:\", accuracy)","b6766031":"print(classification_report(y_test, pred))","cb537909":"param_grid = {'n_estimators': [100, 200, 300, 400, 500], 'max_features': ['auto', 'sqrt', 'log2']}\n\nrf_clf = GridSearchCV(RandomForestClassifier(n_jobs=-1), param_grid, scoring='accuracy', cv=10)\nrf_clf.fit(X_train, y_train)","57a69e0b":"rf_clf.best_params_","33629e18":"rf_clf.best_score_","d3918290":"pred = rf_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('Random Forest')\ntest_accuracy.append(accuracy)\nprint(\"Random Forest Accuracy:\", accuracy)","41574099":"print(classification_report(y_test, pred))","1a41a96e":"param_grid = {'n_estimators': [100, 200, 300, 400, 500, 600, 700]}\n\ngb_clf = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10)\ngb_clf.fit(X_train, y_train)","a2fc7eb0":"gb_clf.best_params_","b7f53a26":"gb_clf.best_score_","0d52838f":"pred = gb_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('Gradient Boosting')\ntest_accuracy.append(accuracy)\nprint(\"Gradient Boosting Accuracy:\", accuracy)","fbad611f":"print(classification_report(y_test, pred))","87ef1d4b":"param_dict = {'n_estimators': list(range(1, 201, 20))}\n\nadaboost_clf = GridSearchCV(\n    AdaBoostClassifier(DecisionTreeClassifier(criterion='gini', max_depth=1000),  algorithm='SAMME.R'),\n    param_grid)\nadaboost_clf.fit(X_train, y_train)","2c862803":"adaboost_clf.best_params_","4dc0aa3b":"adaboost_clf.best_score_","31c3a9af":"pred = adaboost_clf.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('Adaboost')\ntest_accuracy.append(accuracy)\nprint(\"Adaboost Accuracy:\", accuracy)","f0dfa4ca":"print(classification_report(y_test, pred))","49d9ba39":"param_grid = {'n_estimators': [100, 200, 300, 400, 500, 600, 700], 'eval_metric': ['mlogloss']}\n\nxg_boost = GridSearchCV(XGBClassifier(), param_grid)\nxg_boost.fit(X_train, y_train)","9e6e4460":"xg_boost.best_params_","a9ab5cee":"xg_boost.best_score_","2a2a1b2c":"pred = xg_boost.predict(X_test)\naccuracy = accuracy_score(y_test, pred)\n\nmodel.append('XGBoost')\ntest_accuracy.append(accuracy)\nprint(\"XGBoost Accuracy:\", accuracy)","e7a980ef":"evalutation = pd.DataFrame({\n    'Model': model,\n    'Accuracy': test_accuracy\n})","a50bc68e":"evalutation","b3eb142a":"## Importing the dataset","d4828bd8":"We get Random Forest, XGBoost and Gradient Boosting Algorithm get accuracy more than 75%","32c2a9db":"### SVM","962e3c9d":"### Looking at the target distribution","817c3bb4":"## Final Evaluation","7d1f11e4":"Let's look at percent missing values","8cabe06d":"Inferences from heat map\n- shows absence of multicollinearity.\n- most of the features are negatively correlated with Potability","5989436d":"## Parameter Tuning and Model Selection","4d0f8abc":"### KNN","cbd3bacb":"### LogisticRegression","ec6bbf59":"## Preparing data for model ","46464437":"### Violin Plot & Box Plot","51a2bcab":"## Upvote if you learned from it!","c73c4fd8":"### Random Forest Classifier","b4b93a21":"### Information about the data","3804f57e":"## Importing the libraries","620e11d1":"# Water Quality\n\n## Drinking water potability","cef3c920":"## Exploratory Data Analysis","35d1232d":"- ph feature have almost 15% of data missing.\n- Sulfate feature have almost 24% of data missing.\n- Trihalomethanes feature have almost 5% missing data.","153fa7ae":"## Handling missing data","87dbdd9c":"### Correlation between different features","b01f9ff5":"### Adaboost Classifier","6b17947a":"## Splitting the dataset into Training set and Testing set","b90d589d":"### Decision Tree","f266674d":"### Gradient Boosting","fa75b6bd":"- All 10 variables of the data are **numerical**. \n- The **target variable takes binary values** 0 and 1. \n- The **feature variables are real numbers**.","71ec7366":"- 1998 data with Potability=1\n- 1278 with Potability=0. \n\nHence we conclude that the **data is imbalanced**.","1a8066eb":"### XGBoost","f885c4b7":"## Feature Scaling"}}