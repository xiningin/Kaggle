{"cell_type":{"7422fd71":"code","e998c2d6":"code","d1688a4a":"code","5a9da9df":"code","b68f19d7":"code","39ecbaaf":"code","fd57e3e1":"code","6eaabec2":"code","2036aa46":"code","f5714e85":"code","e428dda1":"code","827b0ca7":"code","d9a7cd25":"code","47d369d3":"code","3303230b":"code","d87f3df2":"code","d9e9e065":"code","09ce405c":"code","e2a6fbb7":"code","d4863ae3":"code","c87a8d65":"code","a484eb4c":"code","0791a652":"code","790439d0":"code","241eb07f":"code","b52bc816":"code","4a6cf75f":"code","c0e27be7":"code","a8a2de6b":"code","dc257133":"code","7af65366":"code","e2478093":"code","ce58543d":"code","666acbd6":"code","ae979d48":"code","9513138f":"markdown","c5a82771":"markdown","cd5c14f0":"markdown","05549d1f":"markdown","28a090fa":"markdown","092d36b8":"markdown","4849c469":"markdown","134a668a":"markdown","3011cdd2":"markdown","231dc467":"markdown","446f2945":"markdown","3b984ce0":"markdown","3e5fb625":"markdown","25d19872":"markdown"},"source":{"7422fd71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","e998c2d6":"import pandas as pd\ncovid=pd.read_csv(\"..\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv\")\ncovid.head()\n","d1688a4a":"covid.shape","5a9da9df":"# Satir Sayisi\nprint(\"Sat\u0131r Say\u0131s\u0131:\\n\",covid.shape[0:])\n\n# Sutun Adlari\nprint(\"S\u00fctun Adlari:\\n\",covid.columns.tolist())\n\n# Veri Tipleri\nprint(\"Veri Tipleri:\\n\",covid.dtypes)","b68f19d7":"# Eksik veri say\u0131lar\u0131 ve veri setindeki oranlar\u0131 \nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.concat([covid.isnull().sum(), 100 * covid.isnull().sum()\/len(covid)], \n              axis=1).rename(columns={0:'Missing Records', 1:'Percentage (%)'})\n\n","39ecbaaf":"import pandas as pd\ncovid1=pd.read_csv(\"..\/input\/novel-corona-virus-2019-dataset\/COVID19_open_line_list.csv\")\ncovid1.head()","fd57e3e1":"covid1.shape","6eaabec2":"#Amerika i\u00e7in korelasyon grafi\u011fi\n\nus=covid.copy()\ny = (us['Country\/Region'] == 'US').astype(int)\nfields = list(us.columns[1:])  # everything except \"country name\"\ncorrelations = us[fields].corrwith(y)\ncorrelations.sort_values(inplace=True)\ncorrelations","2036aa46":"ax = correlations.plot(kind='bar')\nax.set(ylim=[-1, 1], ylabel='US Correlation');","f5714e85":"df1=pd.Series(covid['Country\/Region'],name=\"Country\")\ndf2=pd.Series(covid['Last Update'],name=\"Last\")\ndf3=pd.Series(covid['Confirmed'],name=\"Confirmed\")\ndf4=pd.Series(covid['Deaths'],name=\"Deaths\")\ndf5=pd.Series(covid['Recovered'],name=\"Recovered\")\ndf6=pd.Series(covid1['latitude'],name=\"lat\")\ndf7=pd.Series(covid1['longitude'],name=\"long\")\n\ndf_covid=pd.concat([df1, df2,df3, df4,df5,df6,df7], axis=1)\ndf_covid.describe().T","e428dda1":"plt.figure()\ndf_covid.boxplot(column=['Confirmed','Deaths','Recovered'])\n\nfig,axs=plt.subplots(2,2) \naxs[0, 0].boxplot(df_covid['Confirmed'])\naxs[0, 0].set_title('Hasta Say\u0131s\u0131')\n\naxs[0, 1].boxplot(df_covid['Recovered'])\naxs[0, 1].set_title('\u0130yile\u015fen Hasta Say\u0131s\u0131')\n\naxs[1, 0].boxplot(df_covid['Deaths'])\naxs[1, 0].set_title('Hayat\u0131n\u0131 Kaybeden Hasta Say\u0131s\u0131')\n\n","827b0ca7":"who_region = {}\n\n# African Region \nafrica = \"Algeria, Angola, Cabo Verde, Eswatini, Sao Tome and Principe, Benin, South Sudan, Western Sahara, Congo (Brazzaville), Congo (Kinshasa), Cote d'Ivoire, Botswana, Burkina Faso, Burundi, Cameroon, Cape Verde, Central African Republic, Chad, Comoros, Ivory Coast, Democratic Republic of the Congo, Equatorial Guinea, Eritrea, Ethiopia, Gabon, Gambia, Ghana, Guinea, Guinea-Bissau, Kenya, Lesotho, Liberia, Madagascar, Malawi, Mali, Mauritania, Mauritius, Mozambique, Namibia, Niger, Nigeria, Republic of the Congo, Rwanda, S\u00e3o Tom\u00e9 and Pr\u00edncipe, Senegal, Seychelles, Sierra Leone, Somalia, South Africa, Swaziland, Togo, Uganda, Tanzania, Zambia, Zimbabwe\"\nafrica = [i.strip() for i in africa.split(',')]\nfor i in africa:\n    who_region[i] = 'africa'\n    \n# Region of the Americas \namerica = 'Antigua and Barbuda, Argentina, Bahamas, Barbados, Belize, Bolivia, Brazil, Canada, Chile, Colombia, Costa Rica, Cuba, Dominica, Dominican Republic, Ecuador, El Salvador, Grenada, Guatemala, Guyana, Haiti, Honduras, Jamaica, Mexico, Nicaragua, Panama, Paraguay, Peru, Saint Kitts and Nevis, Saint Lucia, Saint Vincent and the Grenadines, Suriname, Trinidad and Tobago, United States, US, Uruguay, Venezuela'\namerica = [i.strip() for i in america.split(',')]\nfor i in america:\n    who_region[i] = 'america'\n\n# South-East Asia Region \nasia = 'Bangladesh, Bhutan, North Korea, India, Indonesia, Maldives, Myanmar, Burma, Nepal, Sri Lanka, Thailand, Timor-Leste'\nasia = [i.strip() for i in asia.split(',')]\nfor i in asia:\n    who_region[i] = 'asia'\n    \n# European Region \neuro = 'Albania, Andorra, Greenland, Kosovo, Holy See, Liechtenstein, Armenia, Czechia, Austria, Azerbaijan, Belarus, Belgium, Bosnia and Herzegovina, Bulgaria, Croatia, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Georgia, Germany, Greece, Hungary, Iceland, Ireland, Israel, Italy, Kazakhstan, Kyrgyzstan, Latvia, Lithuania, Luxembourg, Malta, Monaco, Montenegro, Netherlands, North Macedonia, Norway, Poland, Portugal, Moldova, Romania, Russia, San Marino, Serbia, Slovakia, Slovenia, Spain, Sweden, Switzerland, Tajikistan, Turkey, Turkmenistan, Ukraine, United Kingdom, Uzbekistan'\neuro = [i.strip() for i in euro.split(',')]\nfor i in euro:\n    who_region[i] = 'euro'\n\n# Eastern Mediterranean Region \nemro = 'Afghanistan, Bahrain, Djibouti, Egypt, Iran, Iraq, Jordan, Kuwait, Lebanon, Libya, Morocco, Oman, Pakistan, Palestine, West Bank and Gaza, Qatar, Saudi Arabia, Somalia, Sudan, Syria, Tunisia, United Arab Emirates, Yemen'\nemro = [i.strip() for i in emro.split(',')]\nfor i in emro:\n    who_region[i] = 'emro'\n\n# Western Pacific Region \nwpro = 'Australia, Brunei, Cambodia, China, Cook Islands, Fiji, Japan, Kiribati, Laos, Malaysia, Marshall Islands, Micronesia, Mongolia, Nauru, New Zealand, Niue, Palau, Papua New Guinea, Philippines, South Korea, Samoa, Singapore, Solomon Islands, Taiwan, Taiwan*, Tonga, Tuvalu, Vanuatu, Vietnam'\nwpro = [i.strip() for i in wpro.split(',')]\nfor i in wpro:\n    who_region[i] = 'wpro'\n\n","d9a7cd25":"df_covid['Region'] = df_covid['Country'].map(who_region)\ndf_covid[df_covid['Region'].isna()]['Region'].unique()","47d369d3":"df_covid['Region'].unique()","3303230b":"df_covid[\"Region\"].fillna(\"Other\", inplace = True) ","d87f3df2":"df_covid.isnull().sum()","d9e9e065":"import folium\n# D\u00fcnya Geneli\ntemp = df_covid[df_covid['Last'] == max(df_covid['Last'])]\nm = folium.Map(location=[0, 0], titles='D\u00fcnya Haritas\u0131 \u00dczerindeki De\u011ferler',\n               min_zoom=1, max_zoom=4, zoom_start=1)\n\nfor i in range(0, len(temp)):\n    folium.Circle(\n        location=[temp.iloc[i]['lat'], temp.iloc[i]['long']],\n        color='crimson', fill='crimson',\n        tooltip =   '<li><bold>Country : '+str(temp.iloc[i]['Country'])+\n                    '<li><bold>Province : '+str(temp.iloc[i]['Region'])+\n                    '<li><bold>Confirmed : '+str(temp.iloc[i]['Confirmed'])+\n                    '<li><bold>Deaths : '+str(temp.iloc[i]['Deaths']),\n        radius=int(temp.iloc[i]['Confirmed'])**0.5).add_to(m)\nm\n","09ce405c":"# Zaman \u0130\u00e7erisindeki De\u011fi\u015fim\nimport plotly.express as px\nfig = px.choropleth(df_covid, locations=\"Country\", locationmode='country names', color=np.log(df_covid[\"Confirmed\"]), \n                    hover_name=\"Country\", animation_frame=df_covid[\"Last\"],\n                    title='Zaman \u0130\u00e7erisindeki De\u011fi\u015fim', color_continuous_scale=px.colors.sequential.Purp)\nfig.update(layout_coloraxis_showscale=False)\nfig.show()","e2a6fbb7":"import plotly.express as px\n\n\n\nfig = px.line(df_covid.sort_values(\"Confirmed\"),\n            x='Region', y=\"Confirmed\",\n            hover_name=\"Region\",\n            hover_data=[\"Recovered\",\"Deaths\",\"Confirmed\"],\n            title='COVID-19: B\u00f6lgelere G\u00f6re Test Sonucu Pozitif Olan Hasta Say\u0131s\u0131',\n)\nfig.update_xaxes(title_text=\"Region\")\nfig.update_yaxes(title_text=\"Positif Test Say\u0131s\u0131(%)\")\nfig.show()\nfig = px.line(df_covid.sort_values(\"Recovered\"),\n            x='Region', y=\"Recovered\",\n            hover_name=\"Region\",\n            hover_data=[\"Confirmed\",\"Deaths\",\"Recovered\"],\n            title='COVID-19: B\u00f6lgelere G\u00f6re \u0130yile\u015fen Hasta Say\u0131s\u0131 ',\n)\nfig.update_xaxes(title_text=\"Region\")\nfig.update_yaxes(title_text=\"\u0130yile\u015fen Hasta Say\u0131s\u0131\")\nfig.show()\nfig = px.line(df_covid.sort_values(\"Deaths\"),\n            x='Region', y=\"Deaths\",\n            hover_name=\"Region\",\n            hover_data=[\"Confirmed\",\"Recovered\",\"Deaths\"],\n            title='COVID-19:  B\u00f6lgelere G\u00f6re Hayat\u0131n\u0131 Kaybeden Hasta Say\u0131s\u0131 ',\n)\nfig.update_xaxes(title_text=\"Region\")\nfig.update_yaxes(title_text=\"Hayat\u0131n\u0131 Kaybeden Hasta Say\u0131s\u0131\")\nfig.show()","d4863ae3":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX = df_covid.iloc[:,2:5]\ny = df_covid['Recovered']\n\nmms = MinMaxScaler()\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.3, random_state=0)\nX_train = mms.fit_transform(X_train) \nX_test= mms.fit_transform(X_test)\n\nprint(\"Dataframe boyutu: \",df_covid.shape)\nprint(\"E\u011fitim verisi boyutu: \",X_train.shape, y_train.shape)\nprint(\"Test verisi boyutu: \",X_test.shape,y_test.shape)","c87a8d65":"# type error i\u00e7in target types\u0131 \"Label Encoder\" ile  multiclassa \u00e7evirdim.(Target=Y_train)\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y)\nprint(utils.multiclass.type_of_target(y))\nprint(utils.multiclass.type_of_target(y_train.astype('int')))\nprint(utils.multiclass.type_of_target(encoded))\n\nlab_enc = preprocessing.LabelEncoder()\nY_train = lab_enc.fit_transform(y_train)","a484eb4c":"import numpy as np\nfrom sklearn    import metrics, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import  linear_model","0791a652":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error","790439d0":"# Lineer Regresyon\nprint(\"\\nLineer Regresyon\")\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X_train, Y_train)\ny_true1 , y_pred1 =y_test,lm.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred1)\nplt.scatter(y_true1, y_pred1,c='blue')\nplt.scatter(y_true1, y_test,c='pink')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","241eb07f":"#Lineer Regresyon\n#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v = lab_enc.fit_transform(y_true1)\nutils.multiclass.type_of_target(y_true1.astype('int'))\nypred1= lab_enc.fit_transform(y_pred1)\nutils.multiclass.type_of_target(ypred1.astype('int'))\nconf=confusion_matrix(encoded_v, ypred1)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v, ypred1))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v, ypred1))\nprint(\"MSE:\",mean_squared_error(encoded_v, ypred1))","b52bc816":"# Decision Tree Classifier\nprint(\"Decision Tree Classifier\")\nclf = DecisionTreeClassifier()\nclf.fit(X_train, Y_train)\ny_true5 , y_pred5=y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred5)\nplt.scatter(y_true5, y_pred5,c='orange')\nplt.scatter(y_true5, y_test,c='purple')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","4a6cf75f":"#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v4 = lab_enc.fit_transform(y_true5)\nutils.multiclass.type_of_target(y_true5.astype('int'))\nypred5= lab_enc.fit_transform(y_pred5)\nutils.multiclass.type_of_target(ypred5.astype('int'))\nconf=confusion_matrix(encoded_v4, ypred5)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v4, ypred5))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v4, ypred5))\nprint(\"MSE:\",mean_squared_error(encoded_v4, ypred5))","c0e27be7":"# GaussianNB\nprint(\"GaussianNB\")\nclf = GaussianNB()\nclf.fit(X_train, Y_train)\ny_true3 , y_pred3=y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred3)\nplt.scatter(y_true3, y_pred3,c='pink')\nplt.scatter(y_true3, y_test,c='orange')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","a8a2de6b":"# GaussianNB\n#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v2 = lab_enc.fit_transform(y_true3)\nutils.multiclass.type_of_target(y_true3.astype('int'))\nypred3= lab_enc.fit_transform(y_pred3)\nutils.multiclass.type_of_target(ypred3.astype('int'))\nconf=confusion_matrix(encoded_v2, ypred3)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v2, ypred3))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v2, ypred3))\nprint(\"MSE:\",mean_squared_error(encoded_v2, ypred3))","dc257133":"# SVR(Support Vector Regressions)\nprint(\"SVR(Support Vector Regressions)\")\nclf = svm.SVR(gamma=\"auto\")\n# modelimizi e\u011fitim verilerimiz ve buna kar\u015f\u0131l\u0131k gelen Y_train(target ) de\u011ferleri ile e\u011fitildi.\nclf.fit(X_train, Y_train)\n# test de\u011ferlerimize kar\u015f\u0131l\u0131k gelecek olan tahmin de\u011ferleri olu\u015fturuldu.\ny_true2 , y_pred2 =y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred2)\nplt.scatter(y_true2, y_pred2,c='pink')\nplt.scatter(y_true2, y_test,c='red')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","7af65366":"#SVR\n#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v1 = lab_enc.fit_transform(y_true2)\nutils.multiclass.type_of_target(y_true2.astype('int'))\nypred2= lab_enc.fit_transform(y_pred2)\nutils.multiclass.type_of_target(ypred2.astype('int'))\nconf=confusion_matrix(encoded_v1, ypred2)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v1, ypred2))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v1, ypred2))\nprint(\"MSE:\",mean_squared_error(encoded_v1, ypred2))","e2478093":"# KNeighborsClassifier\nprint(\"KNeighbors Classifier\")\nclf = KNeighborsClassifier()\nclf.fit(X_train, Y_train)\ny_true7 , y_pred7=y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred7)\nplt.scatter(y_true7, y_pred7,c='green')\nplt.scatter(y_true7, y_test,c='yellow')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","ce58543d":"#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v6 = lab_enc.fit_transform(y_true7)\nutils.multiclass.type_of_target(y_true7.astype('int'))\nypred7= lab_enc.fit_transform(y_pred7)\nutils.multiclass.type_of_target(ypred7.astype('int'))\nconf=confusion_matrix(encoded_v6, ypred7)\nprint(\"\\nConfusion matrix :\\n\",conf)\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v6, ypred7))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v6, ypred7))\nprint(\"MSE:\",mean_squared_error(encoded_v6, ypred7))","666acbd6":"# Linear Discriminant Analysis\nprint(\"Linear Discriminant Analysis\")\nclf = LinearDiscriminantAnalysis()\nclf.fit(X_train, Y_train)\ny_true8 , y_pred8=y_test,clf.predict(X_test)\nprint(\"\\nTahmin de\u011ferleri: \",y_pred8)\nplt.scatter(y_true8, y_pred8,c='purple')\nplt.scatter(y_true8, y_test,c='grey')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predictions\")","ae979d48":"# Linear Discriminant Analysis\n#predictions multiclass oldu\u011fundan y_validation da multiclassa d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc\nencoded_v7 = lab_enc.fit_transform(y_true8)\nutils.multiclass.type_of_target(y_true8.astype('int'))\nypred8= lab_enc.fit_transform(y_pred8)\nutils.multiclass.type_of_target(ypred8.astype('int'))\nconf=confusion_matrix(encoded_v7, ypred8)\nprint(\"\\nConfusion matrix :\\n\",conf)\nsns.heatmap(conf, cmap=\"Blues\")\n\n\nprint(\"Accuracy score(Do\u011fruluk de\u011feri):\\n\",accuracy_score(encoded_v7, ypred8))\nprint(\"\\nClassification Report:\\n\",classification_report(encoded_v7, ypred8))\nprint(\"MSE:\",mean_squared_error(encoded_v7, ypred8))","9513138f":"-> Ayk\u0131r\u0131 de\u011fer g\u00f6zlemi yapabilmek ad\u0131na s\u00fcrekli de\u011fi\u015fkenler i\u00e7in boxplotlar olu\u015fturuldu. Ayk\u0131r\u0131 de\u011fer analizi ile de\u011fi\u015fkenler i\u00e7erisindeki de\u011ferlerin ortalama ile mi seyretti\u011fi yoksa b\u00fcy\u00fck farkl\u0131l\u0131klar\u0131n m\u0131 oldu\u011fu sonucuna var\u0131r\u0131z.","c5a82771":"Bu veri seti Covid-19 olarak ortaya \u00e7\u0131kan vir\u00fcs i\u00e7in d\u00fcnya genelinde \u2018Covid Pozitif Hasta Say\u0131s\u0131\u2019 , \u2018\u0130yile\u015fen Hasta Say\u0131s\u0131\u2019 , \u2018Hayat\u0131n\u0131 Kaybeden Hasta Say\u0131s\u0131\u2019 de\u011ferlerini i\u00e7ermektedir.","cd5c14f0":"-> Olu\u015fturulan dataframe i\u00e7in 'Deaths ,Recovered ,Confirmed ' de\u011fi\u015fkenleri \u00fczerinden 'Recovered'(\u0130yile\u015fen hasta say\u0131s\u0131) \u00fczerine tahminleme yap\u0131ld\u0131.\n\nVeri modellemeden \u00f6nce normalize edildi.Bunu yaparken MinMaxScaler kullan\u0131ld\u0131.\n\nBu y\u00f6ntemde, bir grup verinin i\u00e7erisindeki en b\u00fcy\u00fck ve en k\u00fc\u00e7\u00fck de\u011ferler ele al\u0131n\u0131r. Di\u011fer b\u00fct\u00fcn veriler, bu de\u011ferlere g\u00f6re normalle\u015ftirilir.\n\nYap\u0131lan ba\u015far\u0131 k\u0131yaslamalar\u0131 sonu\u00e7lar\u0131na bak\u0131ld\u0131\u011f\u0131nda en iyi sonu\u00e7lar Lineer Regresyon, Linear Discriminant Analysis ve Decision Tree Classifier algoritmalar\u0131 ile elde edilmi\u015ftir.\n","05549d1f":"-> Veri setleri i\u00e7erisinden belirli alanlar se\u00e7ilerek yeni bir veriseti olu\u015fturuldu. Sonra dataframedeki s\u00fcrekli de\u011fi\u015fkenler i\u00e7in describe metodu ile \"count,mean ,min ,max\" de\u011ferleri \u00f6\u011frenildi.","28a090fa":"-> \u0130\u00e7erisinde \u00fclkelerin koordinatlar\u0131n\u0131n da yer ald\u0131\u011f\u0131 yeni dataframe ile harita \u00fczerinden \u00fclkelerin \u2018Covid Pozitif Hasta Say\u0131s\u0131\u2019(Confirmed) , \u2018\u0130yile\u015fen Hasta Say\u0131s\u0131\u2019(Recovered) , \u2018Hayat\u0131n\u0131 Kaybeden Hasta Say\u0131s\u0131\u2019(Deaths) de\u011ferleri g\u00f6rselle\u015ftirildi.","092d36b8":"-> Yap\u0131lan tahminleme sonucunda al\u0131nan tahmin de\u011ferleri ve do\u011fruluk de\u011ferleri ili\u015fkisi g\u00f6sterildi.","4849c469":"-> Amerika i\u00e7in \"Deaths, Recovered ve Confirmed\" aras\u0131ndaki ili\u015fkiyi g\u00f6zlemleyebilmek ad\u0131na korelasyon grafi\u011fi olu\u015fturuldu.","134a668a":"-> Se\u00e7ilen veri seti import edildi ve i\u00e7indeki veriler okutuldu.","3011cdd2":"-> Yeni olu\u015fturaca\u011f\u0131m datasette enlem ve boylam de\u011ferlerini de alabilmek i\u00e7in di\u011fer kullanaca\u011f\u0131m 'COVID19_open_line_list.csv' dosyas\u0131 import edildi ve okutuldu.","231dc467":"-> Her bir modelin do\u011fruluk de\u011feri ,s\u0131n\u0131fland\u0131rma raporu , kar\u0131\u015f\u0131kl\u0131k matrisi ve MSE(Ortalama Kare Hata Regresyon Oran\u0131) de\u011ferlerini hesaplamak i\u00e7in import edildi.","446f2945":"->  Dataset \u00fczerinde analiz , modelleme yapabilmek i\u00e7in eksik veri say\u0131s\u0131 kontrol\u00fc yap\u0131ld\u0131. ","3b984ce0":"-> Olu\u015fturulan \"line\" plotlar \u00fczerinde 'Region' de\u011fi\u015fkeni g\u00f6rselle\u015ftirildi. B\u00f6ylelikle b\u00f6lgelere g\u00f6re \"Test Sonucu Pozitif Olan Hasta Say\u0131s\u0131,\u0130yile\u015fen Hasta Say\u0131s\u0131,Hayat\u0131n\u0131 Kaybeden Hasta Say\u0131s\u0131\" g\u00f6zlemlenmi\u015f oldu.","3e5fb625":"-> Veri setindeki sat\u0131r say\u0131s\u0131,veri tipi ve de\u011fi\u015fken isimleri \u00f6\u011frenilerek dataset hakk\u0131nda genel bilgiye sahip olundu.","25d19872":"-> Dataset i\u00e7erisinde yer alan \u00fclkeler i\u00e7in b\u00f6lge baz\u0131nda de\u011ferlendirme yapabilmek ad\u0131na datasete 'Region' de\u011fi\u015fkeni eklendi."}}