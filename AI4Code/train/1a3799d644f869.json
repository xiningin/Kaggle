{"cell_type":{"5e783e92":"code","7040cac5":"code","a55862ce":"code","d5d3f86e":"code","0f55f490":"code","50defd65":"code","6797ecaf":"code","5d01e424":"code","9d7b746a":"code","ff34ead3":"code","f077458d":"code","62ff6da8":"code","bae37111":"code","a0794e14":"code","569b2be5":"code","a74345c8":"code","b2b3207a":"code","e178e9fa":"code","6cc02be5":"code","e84034c4":"code","f384a9d7":"code","951d0306":"code","2b443e51":"code","b2a2e0d9":"code","0cadd0ca":"code","02c2fcd8":"code","b2637066":"code","5a956dae":"code","fda4e824":"code","2a33f279":"code","3dd21ccf":"code","e74eab09":"code","b79825c1":"code","b7bf7887":"code","f8690a88":"code","a428cc74":"code","2a5c5a41":"code","99f55362":"code","85a63a65":"code","e0d1d0ae":"code","cc4e087c":"code","ea833349":"code","61143da1":"code","7589b8af":"code","8857c182":"code","e31c9223":"code","0698b99f":"code","be347e2a":"code","feaa3cb1":"code","455122d9":"code","d712dcfc":"code","5ecf4daa":"code","a183fc06":"code","4ee5a7d7":"code","4b7326d0":"code","4699b774":"code","f61eb004":"code","241500c3":"code","af19b86b":"code","a77b4766":"code","8a81a2c5":"code","d9bc5288":"code","8b0d9987":"code","cc307a3c":"code","ee6408df":"code","0a7277c3":"code","c81a30f4":"code","b4363dcc":"code","1919def1":"code","92e63808":"code","1da96dba":"code","9bc696ca":"code","388d2c2a":"code","3ce6c323":"code","3dfbf4ba":"code","9630c3d3":"code","427cc58d":"code","47e26fe1":"code","e6c66ccc":"code","988a9bd5":"code","e52a9bd3":"code","124df5ab":"code","e6eaf2bf":"code","4e88fde2":"code","695d9ea8":"code","2d94467d":"code","0848241a":"code","b131c4d0":"code","a6a6cd1b":"code","d4c072c5":"code","be3aba3e":"code","9fa7feb5":"code","e9059746":"code","07dff9b6":"code","2e4e8c09":"code","ced7abc9":"markdown","cca9891d":"markdown","0744c36d":"markdown","ddee0e2e":"markdown","0012310c":"markdown","36b1aa74":"markdown","ebbbe297":"markdown","e978b7d6":"markdown","8ea1f532":"markdown","eecac5c3":"markdown","773df988":"markdown","c1fb8474":"markdown","15e57f30":"markdown","c1698f57":"markdown","6ea948d7":"markdown","a8bdd218":"markdown","57bdb362":"markdown","c4c73bff":"markdown"},"source":{"5e783e92":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport calendar\nimport matplotlib.pylab as plt # pyplot + numpy\nfrom IPython.display import HTML # display HTML\nimport warnings\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport datetime\nfrom time import time\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.model_selection import GroupKFold # K fold \nfrom typing import Any\nfrom numba import jit\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\nfrom itertools import product\nimport copy\nimport time\n\nimport random\nseed = 1234\nrandom.seed(seed)\nnp.random.seed(seed)\n\n\nimport os\nimport json\nimport matplotlib.pyplot as plt2\nfrom tqdm import tqdm_notebook as tqdm\n%matplotlib inline\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\npd.set_option('max_columns', 100)\nwarnings.filterwarnings('ignore')\nsns.set_style('darkgrid')\nmy_pal = sns.color_palette(n_colors=10)","7040cac5":"!ls -GFlash ..\/input\/data-science-bowl-2019\/","a55862ce":"# original variable for multiple analysis\ntrain_original = pd.read_csv('..\/input\/data-science-bowl-2019\/train.csv')\ntrain_labels_original = pd.read_csv('..\/input\/data-science-bowl-2019\/train_labels.csv')\ntest_original = pd.read_csv('..\/input\/data-science-bowl-2019\/test.csv')\nspecs_original = pd.read_csv('..\/input\/data-science-bowl-2019\/specs.csv')\nsample_submission_original = pd.read_csv('..\/input\/data-science-bowl-2019\/sample_submission.csv')","d5d3f86e":"import copy\ntrain = copy.deepcopy(train_original)\ntrain_labels = copy.deepcopy(train_labels_original)\ntest = copy.deepcopy(test_original)\nspecs = copy.deepcopy(specs_original)\nsample_submission = copy.deepcopy(sample_submission_original)","0f55f490":"import copy\ntrain_df = copy.deepcopy(train_original)\ntrain_labels_df = copy.deepcopy(train_labels_original)\ntest_df = copy.deepcopy(test_original)\nspecs_df = copy.deepcopy(specs_original)\nsample_submission_df = copy.deepcopy(sample_submission_original)","50defd65":"import copy\ntrain_df2 = copy.deepcopy(train_original)\ntrain_labels_df2 = copy.deepcopy(train_labels_original)\ntest_df2 = copy.deepcopy(test_original)\nspecs_df2 = copy.deepcopy(specs_original)\nsample_submission_df2 = copy.deepcopy(sample_submission_original)","6797ecaf":"train_df2.shape","5d01e424":"keep_id = train_df2[train.type == 'Assessment'][['installation_id']].drop_duplicates()\ntrain_df2 = pd.merge(train, keep_id, on='installation_id', how='inner')","9d7b746a":"pd.set_option('max_colwidth', 800)\nspecs_df.head()","ff34ead3":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum() \/ data.isnull().count() * 100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return np.transpose(tt)","f077458d":"display(missing_data(train_df))\ndisplay(missing_data(test_df))\ndisplay(missing_data(train_labels_df))\ndisplay(missing_data(specs_df))","62ff6da8":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return np.transpose(tt)","bae37111":"display(unique_values(train_df))\ndisplay(unique_values(test_df))\ndisplay(unique_values(train_labels_df))\ndisplay(unique_values(specs_df))","a0794e14":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    most_frequent_items = []\n    freqs = []\n    for col in data.columns:\n        most_frequent_item = data[col].value_counts().index[0]\n        freq = data[col].value_counts().values[0]\n        most_frequent_items.append(most_frequent_item)\n        freqs.append(freq)\n    tt['Most frequenct item'] = most_frequent_items\n    tt['Frequency'] = freqs\n    tt['Percent from total'] = np.round(freqs \/ total * 100, 3)\n    return (np.transpose(tt))\n    ","569b2be5":"display(most_frequent_values(train_df))\ndisplay(most_frequent_values(test_df))\ndisplay(most_frequent_values(train_labels_df))\ndisplay(most_frequent_values(specs_df))","a74345c8":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1, 1, figsize=(4*size, 4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if size > 2:\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x() + p.get_width() \/ 2., height + 3, '{:1.2f}%'.format(100*height\/total), ha='center')\n    plt.show()\n    \n# this function is used to count the number of a specified feature","b2b3207a":"display(plot_count('title', 'title (first most frequent 20 values - train)', train_df, size=4))\ndisplay(plot_count('title', 'title (first most frequent 20 values - test)', test_df, size=4))","e178e9fa":"plot_count('title', 'title - train_labels', train_labels_df, size=3)","6cc02be5":"plot_count('accuracy', 'accuracy - train_labels', train_labels_df, size=4)","e84034c4":"plot_count('accuracy_group', 'accuracy_group - train_labels', train_labels_df, size=2)","f384a9d7":"plot_count('num_correct', 'num_correct - train_labels', train_labels_df, size=1)","951d0306":"plot_count('num_incorrect', 'num_incorrect - train_labels', train_labels_df, size=4)","2b443e51":"sample_train_df = train_df.sample(100000)","b2a2e0d9":"sample_train_df.head(5)","0cadd0ca":"sample_train_df.iloc[0]['event_data']","02c2fcd8":"%%time\nextracted_event_data = pd.io.json.json_normalize(sample_train_df['event_data'].apply(json.loads)) # normalize json","b2637066":"extracted_event_data.head(3)","5a956dae":"missing_data(extracted_event_data)","fda4e824":"def existing_data(data):\n    total = data.isnull().count() - data.isnull().sum()\n    percent = 100 - (data.isnull().sum() \/ data.isnull().count() * 100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    tt = pd.DataFrame(tt.reset_index())\n    \n    return tt.sort_values(['Total'], ascending=False)","2a33f279":"stat_event_data = existing_data(extracted_event_data)","3dd21ccf":"stat_event_data.head(5)","e74eab09":"plt.figure(figsize=(10, 10))\nsns.set(style='darkgrid')\nax = sns.barplot(x='Percent', y='index', data=stat_event_data.head(40), color='gold')\nplt.title('Most frequent features in event_data')\nplt.ylabel('Features')","b79825c1":"specs_df.head(3)","b7bf7887":"specs_df.iloc[0]['args']","f8690a88":"specs_args_extracted = pd.DataFrame()\nfor i in range(0, specs_df.shape[0]):\n    for item in json.loads(specs_df.args[i]):\n        new_df = pd.DataFrame({'event_id': specs_df['event_id'][i],\\\n                               'info': specs_df['info'],\\\n                               'args_name': item['name'],\\\n                               'args_type': item['type'],\\\n                               'args_info': item['info']}, index=[i]\n                              )\n        specs_args_extracted = specs_args_extracted.append(new_df)\n","a428cc74":"print(f'Extracted args from specs: {specs_args_extracted.shape}')","2a5c5a41":"specs_args_extracted.head(10)","99f55362":"tmp = specs_args_extracted.groupby(['event_id'])['event_id'].count() # event - number of arguments per event\ndf = pd.DataFrame({'event_id': tmp.index, 'count': tmp.values})\nplt.figure(figsize=(6, 4))\nsns.set(style='darkgrid')\nax = sns.distplot(df['count'], kde=True, hist=True, bins=30)\nplt.title('Distribution of number of arguments per event_id')\nplt.xlabel('Number of arguments'); plt.ylabel('Density'); plt.show()\n# it is a plot about the density of arguments per event","85a63a65":"plot_count('args_name', 'args_name (first 20 most frequent values) - specs', specs_args_extracted, size=4)","e0d1d0ae":"plot_count('args_type', 'args_type (first 20 most frequent values) - specs', specs_args_extracted, size=3)","cc4e087c":"plot_count('args_info', 'args_info (first 20 most frequent values) - specs', specs_args_extracted, size=3)","ea833349":"def extract_time_features(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['date'] = df['timestamp'].dt.date\n    df['month'] = df['timestamp'].dt.month\n    df['year'] = df['timestamp'].dt.year\n    df['hour'] = df['timestamp'].dt.hour\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    df['weekofyear'] = df['timestamp'].dt.weekofyear\n    df['dayofyear'] = df['timestamp'].dt.dayofyear\n    df['quarter'] = df['timestamp'].dt.quarter\n    df['is_month_start'] = df['timestamp'].dt.is_month_start\n    return df","61143da1":"train_df = extract_time_features(train_df)\n","7589b8af":"test_df = extract_time_features(test_df)","8857c182":"plot_count('year', 'year - train', train_df, size=2)","e31c9223":"plot_count('is_month_start', 'is_month_start - train', train_df, size=2)","0698b99f":"plot_count('month', 'month - train', train_df, size=2)\n# do the same with rest of the date info","be347e2a":"numerical_columns = ['game_time', 'month', 'dayofweek', 'hour']\ncategorical_columns = ['type', 'world']\n\ncomp_train_df = pd.DataFrame({'installation_id': train_df['installation_id'].unique()})\ncomp_train_df.set_index('installation_id', inplace=True)","feaa3cb1":"comp_train_df.head(10)","455122d9":"def get_numeric_columns(df, column):\n    df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std', 'skew']})\n    df[column].fillna(df[column].mean(), inplace=True)\n    df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_min', f'{column}_max', f'{column}_std', f'{column}_skew']\n    return df","d712dcfc":"for numerical_column in numerical_columns:\n    comp_train_df = comp_train_df.merge(get_numeric_columns(train_df, numerical_column), left_index=True, right_index=True)","5ecf4daa":"print(f'comp_train shape: {comp_train_df.shape}')","a183fc06":"comp_train_df.columns","4ee5a7d7":"# for some reason the dataframe I produces has game_time_xx_y, droping it and renaming game_time_xx_x to game_time_x\n# comp_train_df.drop(columns=['game_time_mean_y', 'game_time_sum_y', 'game_time_min_y',\n#        'game_time_max_y', 'game_time_std_y', 'game_time_skew_y'], inplace=True)\ncomp_train_df.rename({'game_time_mean_x': 'game_time_mean', 'game_time_sum_x': 'game_time_sum', 'game_time_min_x': 'game_time_min',\n       'game_time_max_x': 'game_time_max', 'game_time_std_x': 'game_time_std', 'game_time_skew_x': 'game_time_skew'}, axis=1, inplace=True)","4b7326d0":"comp_train_df.head()","4699b774":"comp_train_df.shape","f61eb004":"train_labels_df.head()","241500c3":"train_labels_df.groupby('title')['accuracy_group'].head()","af19b86b":"# this part I don't understand\nlabels_map = dict(train_labels_df.groupby('title')['accuracy_group'].agg(lambda x: x.value_counts().index[0])) \n# value_counts gets frequencies for different accuracy_group, and get the first value??\nlabels = train_labels_df[['installation_id', 'title', 'accuracy_group']]\nlabels['title'] = labels['title'].map(labels_map)\ncomp_train_df = labels.merge(comp_train_df, on='installation_id', how='left')\nprint('We have {} training rows'.format(comp_train_df.shape[0]))\n","a77b4766":"comp_train_df.head()","8a81a2c5":"print(f'comp_train_df shape: {comp_train_df.shape}')\nfor feature in comp_train_df.columns.values[3: 20]:\n    print(f'{feature} unique values: {comp_train_df[feature].nunique()}') # dataframe.nunique => series, series => integer","d9bc5288":"plot_count('title', 'title - compound train', comp_train_df)","8b0d9987":"plot_count('accuracy_group', 'accuracy_group - compound train', comp_train_df)","cc307a3c":"plt.figure(figsize=(16, 6))\n_titles = comp_train_df['title'].unique() # pandas.series.unique => array of unique values\nplt.title('Distribution of log(game time mean) values (grouped by title) in the comp train')\nfor _title in _titles:\n    red_comp_train_df = comp_train_df.loc[comp_train_df.title == _title] # find rows where the titles are the same\n    sns.distplot(np.log(red_comp_train_df['game_time_mean']), kde=True, label=f'title: {_title}')\nplt.legend()\nplt.show()\n\n# do the same with different stats features such as game_time_skew, hour_mean, hour_std etc","ee6408df":"train_labels.head()","0a7277c3":"train_labels.groupby('accuracy_group')['game_session'].count().plot(kind='barh', figsize=(15, 5), title='Target (accuracy group)')\nplt.show()","c81a30f4":"# don't really understand how pairplot works\nsns.pairplot(train_labels, hue='accuracy_group')\nplt.show()","b4363dcc":"train.head()","1919def1":"# change event_id and game_session from hex into integer\ntrain['event_id_as_int'] = train['event_id'].apply(lambda x : int(x, 16))\ntrain['game_session_as_int'] = train['game_session'].apply(lambda x : int(x, 16))","92e63808":"type(train['timestamp'][0]) # timestamp is string","1da96dba":"train['timestamp'], test['timestamp'] = pd.to_datetime(train['timestamp']), pd.to_datetime(test['timestamp']) # convert string into datetime\ntrain['date'], train['hour'], train['weekday_name'] = train['timestamp'].dt.date, train['timestamp'].dt.hour, train['timestamp'].dt.weekday_name\ntest['date'], test['hour'], test['weekday_name'] = test['timestamp'].dt.date, test['timestamp'].dt.hour, test['timestamp'].dt.weekday_name","9bc696ca":"print(f'Train data has shape: {train.shape}')\nprint(f'Test data has shape: {test.shape}')","388d2c2a":"train.columns # train has two more columns - \"game_session_as_int\" and \"event_id_as_int\"","3ce6c323":"train.groupby('date')['event_id'].agg('count').plot(figsize=(15, 3), title='Number of Event Observations by Date', color='blue')\nplt.show()\n","3dfbf4ba":"train.groupby('hour')['event_id'].agg('count').plot(figsize=(15, 3), title='Number of Event Observations by Date', color='blue')\nplt.show()\n# can see that during 15 - 20 more activities than 5 - 10 ","9630c3d3":"train.groupby('weekday_name')['event_id'].agg('count').plot(figsize=(15, 3), title='Number of Event Observations by Date', color='blue')\nplt.show()\n# can see that Friday has most activities","427cc58d":"print(train['event_data'][4])\nprint(train['event_data'][5])","47e26fe1":"train['installation_id'].nunique() # number of unique installation ids ","e6c66ccc":"train.groupby('installation_id').count()['event_id'].plot(kind='hist', bins=40, color='pink', figsize=(15, 5), title='Count of Observations by installation_id')\nplt.show()","988a9bd5":"train.groupby('installation_id').count()['event_id'].apply(np.log1p).plot(kind='hist', bins=40, color='pink', figsize=(15, 5), title='Log(Count) of Observations by installation_id')\nplt.show()\n\n# why log(count)? ","e52a9bd3":"train.groupby('installation_id').count()['event_id'].sort_values(ascending=False).head(5)","124df5ab":"train.query('installation_id == \"f1c21eda\"').set_index('timestamp')['event_code'].plot(figsize=(15, 5), title='installation_id #f1c21eda event Id - event code vs time', style='.', color='orange')\nplt.show()\n\n# this graph is not natural, the interface could be installed by a bot","e6eaf2bf":"train.groupby('event_code').count()['event_id'].sort_values().plot(kind='bar', figsize=(15, 5), title='Count of different event codes.')\nplt.show()","4e88fde2":"train['game_time'].apply(np.log1p).plot(kind='hist', bins=100, title='Log Transform of game_time', color='gold')\nplt.show()","695d9ea8":"train.groupby('title')['event_id'].count().sort_values().plot(kind='barh', title='Count of Observation by Game\/Video title', figsize=(15, 15))\nplt.show()\n","2d94467d":"train.groupby('type')['event_id'].count().sort_values().plot(kind='barh', figsize=(15, 4), title='Count by Type', color='turquoise')\nplt.show()","0848241a":"train.groupby('world')['event_id'].count().sort_values().plot(kind='bar', figsize=(15, 4), title='Count by World', color='gold')\nplt.show()","b131c4d0":"train['log_game_time'] = train['game_time'].apply(np.log1p)","a6a6cd1b":"fig, ax = plt.subplots(figsize=(15, 5))\nsns.catplot(x='type', y='log_game_time', data=train.sample(10000), alpha=0.5, ax=ax)\nax.set_title('Distribution of log(game_time) by Type')\nplt.close()\nplt.show()\n\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.catplot(x='world', y='log_game_time', data=train.sample(10000), alpha=0.5, ax=ax)\nax.set_title('Distribution of log(game_time) by World')\nplt.close()\nplt.show()","d4c072c5":"specs.head()","be3aba3e":"specs.describe()","9fa7feb5":"specs.iloc[0][-2]","e9059746":"from sklearn.model_selection import train_test_split\n\ntrain['cleared'] = True\ntrain.loc[train['event_data'].str.contains('false') & train['event_code'].isin([4100, 4110]), 'cleared'] = False # why 4100-4110\n\ntest['cleared'] = True\ntest.loc[test['event_data'].str.contains('false') & test['event_code'].isin([4100, 4110]), 'cleared'] = False # why 4100-4110\n\naggs = {'hour':['max', 'min', 'mean'], 'cleared': ['mean']}\n\ntrain_aggs = train.groupby('installation_id').agg(aggs)\ntest_aggs = test.groupby('installation_id').agg(aggs)\n\ntrain_aggs = train_aggs.reset_index()\ntest_aggs = test_aggs.reset_index()\n\ntrain_aggs.columns = ['_'.join(col).strip() for col in train_aggs.columns.values]\ntest_aggs.columns = ['_'.join(col).strip() for col in test_aggs.columns.values]\n\ntrain_aggs = train_aggs.rename(columns={'installation_id_' : 'installation_id'})\n","07dff9b6":"train_aggs.head(5)","2e4e8c09":"train_aggs.merge(train_labels[['installation_id', 'accuracy_group']], how='left')","ced7abc9":"World","cca9891d":"**Extract features from train\/event_data**","0744c36d":"Game_time","ddee0e2e":"**Train label analysis**","0012310c":"Game\/Video titles","36b1aa74":"event_code","ebbbe297":"installation_id","e978b7d6":"**Unique Values**","8ea1f532":"Extract time features","eecac5c3":"Event data","773df988":"**train analysis**","c1fb8474":"**Merged data distribution**","15e57f30":"**Extract features from specs\/args**","c1698f57":"Time Stamp","6ea948d7":"**Missing data**","a8bdd218":"Game\/Video Type","57bdb362":"**Baseline Model**","c4c73bff":"**specs.csv**"}}