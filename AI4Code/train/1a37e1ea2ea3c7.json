{"cell_type":{"e684bd08":"code","cde80907":"code","534af9cc":"code","bc8f520b":"code","532f73f4":"code","41747bfc":"code","e5f542b3":"code","d1454ec3":"code","eddccded":"code","d46429c8":"code","1ccc1f0b":"code","f6f51209":"code","1ac796b4":"code","de209e8e":"code","7e90e876":"code","3abd3528":"code","e9921d32":"code","f2ba27a3":"code","87f99937":"code","9367ac2f":"code","5b1d9b18":"code","1aa539a7":"code","f3fc15d8":"code","1cac6936":"code","ef604c62":"markdown"},"source":{"e684bd08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cde80907":"# importing the necessary library\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans","534af9cc":"# reading the data\ndata = pd.read_csv('..\/input\/unsupervised-learning-on-country-data\/Country-data.csv')\ndf = pd.read_csv('..\/input\/unsupervised-learning-on-country-data\/Country-data.csv')\n# df = ","bc8f520b":"# dropping the column\ndf.drop(columns = 'health',inplace= True)","532f73f4":"# first 5 rows of the dataset\ndata.head()","41747bfc":"# check for the null values\nsns.heatmap(data.isnull())","e5f542b3":"# looking for the realtions of columns with each other\nsns.heatmap(data.corr(),annot = True)","d1454ec3":"# dropping the column\ndata.drop(columns = 'health',inplace=True)\ndata.drop(columns = 'country',inplace=True)\n","eddccded":"# seeing the income and gdp distribution\n\nsns.scatterplot(x = 'income',y = 'gdpp',data=data)\n\n","d46429c8":"#  seeing how import and exports are related to gdp\nsns.scatterplot(x = 'imports',y = 'exports',hue = 'gdpp',data=data)","1ccc1f0b":"# histrogram based on the child mortalitry rate per 1000 capita\nsns.distplot(data['child_mort'],bins = 10,kde= False)","f6f51209":"data.describe()","1ac796b4":"from sklearn.preprocessing import MinMaxScaler\n","de209e8e":"# to scale the data\nscalar = MinMaxScaler()\ndata = scalar.fit_transform(data)","7e90e876":"df = pd.DataFrame(data = data,columns=df.columns[1:])\n","3abd3528":"df.head()\n","e9921d32":"df.describe()\n","f2ba27a3":"# to get the sum of distance\nclf = KMeans()\nssd = []\nK = range(1,9)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(data)\n    ssd.append(km.inertia_) ","87f99937":"plt.figure(figsize=(10,6))\nplt.plot(K, ssd, 'bx-')\nplt.xlabel('Clusters')\nplt.ylabel('Distance')\nplt.title('Elbow Method For Optimization')\nplt.show()","9367ac2f":"# dividing the the dataset into clusters of 5\nkmean = KMeans(n_clusters=5)\nkmean.fit(data)","5b1d9b18":"# distributed labels\npred = kmean.labels_\nprint(pred)","1aa539a7":"df1 = pd.read_csv('..\/input\/unsupervised-learning-on-country-data\/Country-data.csv')\n","f3fc15d8":"# gdp and income based on the clusters\nsns.scatterplot(data= df1,x = 'gdpp',y = 'income',hue=kmean.labels_)","1cac6936":"''' list of countries which require utmost need for the money based on \nthe income less than 1000 noticed from the above diagram'''\ndf1['country'][df1['income']<1000]","ef604c62":"Just a Simple Attempt to the unsupervised learning and finding the solution for the problem statement \n\n\nDo upvote if this notebook was helpful!!!!"}}