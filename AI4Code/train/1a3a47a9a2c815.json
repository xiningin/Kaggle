{"cell_type":{"14fec126":"code","4a44ceec":"code","8f933c84":"code","d0bf68bf":"code","a63baf1d":"code","42be98a7":"code","2e5e2c05":"code","9f197e98":"code","c49afaab":"code","ecc76cb2":"code","eb9f1078":"code","4e954e83":"code","f8fc447c":"code","eecb9731":"code","c5f67f28":"code","c6e8fd5b":"code","dfb0702a":"code","7ae4d7f5":"code","d5f280c9":"code","b081938b":"code","7a938b34":"code","0e877b69":"code","2dac0392":"code","e2a44ba1":"code","ecd6589c":"code","9ba19fec":"code","4b585546":"code","16555dbd":"code","81636963":"code","8ea2d1e7":"code","f0c196ae":"code","20e1a77f":"code","008b58f7":"code","09902825":"code","4c187eba":"code","c7acb4d5":"code","fd62cae2":"code","0ed38564":"code","861a9f4b":"code","7a7dd15d":"code","9df0f856":"code","83535bb7":"code","b134820f":"code","b1734354":"code","52dbdde0":"code","ac7f7fa6":"code","d8034ed8":"code","94ecdb61":"markdown","53d0f35f":"markdown","34dcbe3b":"markdown","9375e95c":"markdown","c9e37797":"markdown","186c7577":"markdown","34a205c7":"markdown","e67c44b2":"markdown","d32ac5e9":"markdown","bd6b7b74":"markdown","3b37716c":"markdown","1a0d0a50":"markdown","c7d793f0":"markdown","1aed1a79":"markdown","c34f7656":"markdown","e26d15c3":"markdown","e896b9f4":"markdown","607e1484":"markdown","f49c9c7c":"markdown","0c5ed15f":"markdown","bbd2e0f5":"markdown","16fffdfe":"markdown","50c2df17":"markdown","6f837a73":"markdown","878b7e21":"markdown","a2657ae1":"markdown","452b98ec":"markdown"},"source":{"14fec126":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom keras_tuner import RandomSearch, HyperParameters\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4a44ceec":"df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\n\nprint(df.shape)\ndf.head()","8f933c84":"target = 'output'","d0bf68bf":"df.groupby(target)['age'].count().plot.bar()\nplt.ylabel('count')\nplt.show()","a63baf1d":"print('Y: {}%'.format(round(df[target].value_counts()[0] * 100 \/ len(df), 3)))\nprint('Y: {}%'.format(round(df[target].value_counts()[1] * 100 \/ len(df), 3)))","42be98a7":"df.isnull().sum()","2e5e2c05":"dis_features = [feature for feature in df.columns if len(df[feature].unique()) < 20 and feature != target]\n\nprint(dis_features)","9f197e98":"for feature in dis_features:\n    df.groupby(feature)[target].count().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","c49afaab":"for feature in dis_features:\n    df.groupby(feature)[target].mean().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel(target)\n    plt.show()","ecc76cb2":"con_features = [feature for feature in df.columns if feature not in dis_features and feature != target]\n\nprint(con_features)","eb9f1078":"for feature in con_features:\n    iqr = stats.iqr(df[feature], interpolation = 'midpoint')\n    h = (2 * iqr) \/ (len(df[feature]) ** (1\/3))\n    bins = round((max(df[feature]) - min(df[feature])) \/ h)\n    \n    df[feature].hist(bins = bins)\n    plt.xlabel(feature)\n    plt.ylabel('count')\n    plt.show()","4e954e83":"for feature in con_features:\n    df.boxplot(column = feature)\n    plt.xlabel(feature)\n    plt.ylabel('value')\n    plt.show()","f8fc447c":"for feature in con_features:\n    extreme = df[feature].median() + 3 * df[feature].std()\n    print('{} values to replace: {}%'.format(feature, len(df.loc[df[feature] > extreme])))\n    \n    data = df.copy()\n    data[feature] = np.where(data[feature] > extreme, extreme, data[feature])\n    \n    iqr = stats.iqr(data[feature], interpolation = 'midpoint')\n    h = (2 * iqr) \/ (len(data[feature]) ** (1\/3))\n    bins = round((max(data[feature]) - min(data[feature])) \/ h)\n    \n    data[feature].hist(bins = bins)\n    plt.show()","eecb9731":"for feature in con_features[-1:]:\n    data = df.copy()\n    \n    data[feature] = data[feature] ** 0.5\n    \n    iqr = stats.iqr(data[feature], interpolation = 'midpoint')\n    h = (2 * iqr) \/ (len(data[feature]) ** (1\/3))\n    bins = round((max(data[feature]) - min(data[feature])) \/ h)\n    \n    data[feature].hist(bins = bins)\n    plt.show()","c5f67f28":"df['slp'] = np.where(df['slp'] == 0, 1, df['slp'])\ndf['caa'] = np.where(df['caa'] == 4, 0, df['caa'])\ndf['thall'] = np.where(df['thall'] == 0, 1, df['thall'])","c6e8fd5b":"for feature in con_features:\n    extreme = df[feature].median() + 3 * df[feature].std()\n    df[feature] = np.where(df[feature] > extreme, extreme, df[feature])","dfb0702a":"df['oldpeak'] = df['oldpeak'] ** 0.5","7ae4d7f5":"X = df.iloc[:, :-1]\ny = df[target]","d5f280c9":"cor = X.corr()\n\nplt.figure(figsize = (10, 8))\nsns.heatmap(cor, annot = True, cmap = plt.cm.CMRmap_r)\nplt.show()","b081938b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","7a938b34":"scaler = StandardScaler()\n\nscaler.fit(X_train)","0e877b69":"X_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","2dac0392":"model = LogisticRegression()","e2a44ba1":"model.fit(X_train_scaled, y_train)","ecd6589c":"y_pred_lr = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred_lr))\nprint(classification_report(y_test, y_pred_lr, digits = 4))","9ba19fec":"scores = []\nneighbors = np.arange(5, 13)\n\nfor n in neighbors:\n    model = KNeighborsClassifier(n_neighbors = n)\n    model.fit(X_train_scaled, y_train)\n    scores.append(model.score(X_test_scaled, y_test))\n    \nbest_neighbors = neighbors[scores.index(max(scores))]\nprint(best_neighbors)","4b585546":"model = KNeighborsClassifier(n_neighbors = best_neighbors)\n\nmodel.fit(X_train_scaled, y_train)","16555dbd":"y_pred_knn = model.predict(X_test_scaled)","81636963":"y_pred_knn = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn, digits = 4))","8ea2d1e7":"model = SVC()","f0c196ae":"model.fit(X_train_scaled, y_train)","20e1a77f":"y_pred_svm = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred_svm))\nprint(classification_report(y_test, y_pred_svm, digits = 4))","008b58f7":"model = RandomForestClassifier()","09902825":"model.fit(X_train, y_train)","4c187eba":"y_pred_rf = model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred_rf))\nprint(classification_report(y_test, y_pred_rf, digits = 4))","c7acb4d5":"model = XGBClassifier(use_label_encoder = False)","fd62cae2":"model.fit(X_train, y_train)","0ed38564":"y_pred_xgb = model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred_xgb))\nprint(classification_report(y_test, y_pred_xgb, digits = 4))","861a9f4b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","7a7dd15d":"scaler = StandardScaler()\n\nscaler.fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","9df0f856":"def build_model(hp):\n    model = keras.Sequential([\n        keras.layers.Dense(units = hp.Int('dense_1_units', min_value = 32, max_value = 128, step = 8),\n                           kernel_initializer = hp.Choice('dense_1_kernel', values = ['he_normal', 'he_uniform']),\n                           activation = 'relu',\n                           input_dim = 13),\n        keras.layers.Dense(units = hp.Int('dense_2_units', min_value = 32, max_value = 64, step = 8),\n                           kernel_initializer = hp.Choice('dense_1_kernel', values = ['he_normal', 'he_uniform']),\n                           activation = 'relu'),\n        keras.layers.Dropout(0.3),\n        keras.layers.Dense(units = hp.Int('dense_3_units', min_value = 32, max_value = 64, step = 8),\n                           kernel_initializer = hp.Choice('dense_1_kernel', values = ['he_normal', 'he_uniform']),\n                           activation = 'relu'),\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\n    ])\n    \n    model.compile(optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', values = [1e-2, 1e-3])),\n                  loss = 'binary_crossentropy',\n                  metrics = ['accuracy'])\n    \n    return model","83535bb7":"tuner_search = RandomSearch(build_model, objective = 'val_accuracy', max_trials = 3, directory = 'ann_hp_output', project_name = 'heart_disease')","b134820f":"tuner_search.search(X_train_scaled, y_train, epochs = 5, validation_split = 0.1)","b1734354":"model = tuner_search.get_best_models(num_models = 1)[0]","52dbdde0":"model.summary()","ac7f7fa6":"model.fit(X_train_scaled, y_train, epochs = 10, validation_split = 0.1, initial_epoch = 5)","d8034ed8":"y_pred_ann = np.round(model.predict(X_test_scaled)).astype(int)\n\nprint(confusion_matrix(y_test, y_pred_ann))\nprint(classification_report(y_test, y_pred_ann, digits = 4))","94ecdb61":"# EDA","53d0f35f":"# Models","34dcbe3b":"## Discrete Features","9375e95c":"## Discrete Features","c9e37797":"- for 'slp': 0 value can be replaced with 1 as both have almost identical relationship with target variable\n- for 'caa': 4 value can be replaced with 0 as both have almost identical relationship with target variable\n- for 'thall': 0 value can be replaced with 1 as both have almost identical relationship with target variable","186c7577":"### XGBoost","34a205c7":"## Continuous Features","e67c44b2":"### vs Target Variable","d32ac5e9":"### Distribution","bd6b7b74":"## Target Variable","3b37716c":"## Ensemble Models","1a0d0a50":"# Feature Engineering","c7d793f0":"## SVM","1aed1a79":"Datset is balanced","c34f7656":"- age : Age of the patient\n\n\n- sex : Sex of the patient\n\n\n- exng: exercise induced angina (1 = yes; 0 = no)\n\n\n- caa: number of major vessels (0-3)\n\n\n- cp : Chest Pain type chest pain type\n\n    -Value 1: typical angina\n    \n    -Value 2: atypical angina\n    \n    -Value 3: non-anginal pain\n    \n    -Value 4: asymptomatic\n\n\n- trtbps : resting blood pressure (in mm Hg)\n\n\n- chol : cholestoral in mg\/dl fetched via BMI sensor\n\n\n- fbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\n\n- restecg : resting electrocardiographic results\n\n    -Value 0: normal\n    \n    -Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    \n    -Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n\n\n- thalachh : maximum heart rate achieved\n\n\n - output : 0= less chance of heart attack \n            1= more chance of heart attack","e26d15c3":"## KNN","e896b9f4":"### Transformation","607e1484":"## Missing Values","f49c9c7c":"## Logistic Regression","0c5ed15f":"# Feature Selection","bbd2e0f5":"## Information about data","16fffdfe":"### Outliers","50c2df17":"### Distribution","6f837a73":"## Continuous Features","878b7e21":"### Random Forest","a2657ae1":"## ANN","452b98ec":"## Scaling"}}