{"cell_type":{"f69b7fe7":"code","bf5289f8":"code","34fa09b9":"code","827fefa7":"code","bd77260b":"code","7be9458f":"code","97af7d29":"code","6c46dd1d":"code","a903db61":"code","f355ab0a":"code","d5ba5526":"code","7a57928b":"code","85ab540c":"code","12a64c0c":"code","4e8b58da":"code","8c01012b":"code","84192f4b":"code","24018de2":"code","17007a9b":"code","d1c290df":"code","9561986d":"code","6e6d61b8":"code","ca890bcb":"code","a7e0e6ff":"code","7f5bfa9a":"code","60124242":"code","d9aa625d":"code","8f0a3014":"code","5524686a":"code","8ccf6418":"code","fd3f5b6e":"code","e01b7729":"code","e19aad41":"code","99b0b3d4":"code","0b80dbb3":"code","4270c427":"markdown","b5f2a3ca":"markdown","345b8157":"markdown","8797c6e2":"markdown","f9bbd0f3":"markdown","e3afbc12":"markdown","7e657dc3":"markdown","ee747ebf":"markdown","2159d4f3":"markdown","b5aa6387":"markdown","7029e338":"markdown","4aec1e6c":"markdown","ccb0b047":"markdown","f3dbc181":"markdown","4f3b80f5":"markdown","0f91065e":"markdown","382baadb":"markdown","ad14a1ec":"markdown","2eee95bc":"markdown","317f8a3c":"markdown","f2fcbfbd":"markdown","3844cc30":"markdown","3f7e365f":"markdown","9a54a2e7":"markdown","941eedef":"markdown","65939b49":"markdown","b79f09ac":"markdown","509a879e":"markdown","3c70e094":"markdown","439d5777":"markdown","e76cacfe":"markdown"},"source":{"f69b7fe7":"from IPython.display import Image\nImage(filename='..\/input\/ffffff\/1111.jpg', width=\"800\", height='50')","bf5289f8":"\nfrom IPython.display import Image\nImage(filename='..\/input\/dddddd\/1.png', width=\"800\", height='50')","34fa09b9":"Image(filename='..\/input\/dddddd\/x2.jpg', width=\"800\", height='50')","827fefa7":"Image(filename='..\/input\/x12345\/x3.jpg', width=\"800\", height='50')","bd77260b":"Image(filename='..\/input\/x12345\/x33.jpg', width=\"800\", height='50')","7be9458f":"Image(filename='..\/input\/x12345\/x4.png', width=\"800\", height='50')","97af7d29":"Image(filename='..\/input\/x12345\/x5.png', width=\"800\", height='50')","6c46dd1d":"Image(filename='..\/input\/finalx\/01.png', width=\"800\", height='50')","a903db61":"Image(filename='..\/input\/finalx\/02.png', width=\"800\", height='50')","f355ab0a":"Image(filename='..\/input\/finalx\/03.png', width=\"800\", height='50')","d5ba5526":"Image(filename='..\/input\/finalx\/05.png', width=\"800\", height='50')","7a57928b":"Image(filename='..\/input\/finalx\/06.png', width=\"800\", height='50')","85ab540c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")\n\n# for interactive visualizations\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected = True)\nfrom plotly import tools\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","12a64c0c":"### Loading the Datasets\nmall_data = pd.read_csv(\"\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")","4e8b58da":"#### Read the top 5 rows using plotly library\ndata = ff.create_table(mall_data.head())\npy.iplot(data)","8c01012b":"##### Check the Descriptions of the datasets using plotly library. \ndesc = ff.create_table(mall_data.describe())\npy.iplot(desc)","84192f4b":"#### Visualizing the null values using missingo function\n\nimport missingno as msno\nmsno.matrix(mall_data)","24018de2":"plt.figure(figsize = (16,5))\n\nplt.subplot(1, 3, 1)\nsns.distplot(mall_data['Age'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(mall_data['Annual Income (k$)'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(mall_data['Spending Score (1-100)'])\n\nplt.show()","17007a9b":"# Prepare Data\ndf = mall_data.groupby('Gender').size()\n\n# Make the plot with pandas\ndf.plot(kind='pie', subplots=True, figsize=(15, 8))\nplt.title(\"Pie Chart of Vehicle Class - Bad\")\nplt.ylabel(\"\")\nplt.show()","d1c290df":"### hist plot\nmall_data.hist(figsize = (15, 12))\nplt.show()","9561986d":"### Pair plot\nsns.pairplot(mall_data)\nplt.title('Pairplot for the Data')\nplt.show()","6e6d61b8":"#### Pairplot only three columns beteen Gender columns\nsns.pairplot(mall_data,vars = ['Spending Score (1-100)', 'Annual Income (k$)', 'Age'], hue=\"Gender\")","ca890bcb":"plt.figure(figsize = (16,8))\nsns.countplot(mall_data['Age'], palette = 'hsv')\nplt.title('Distribution of Age', fontsize = 20)","a7e0e6ff":"plt.figure(figsize = (20,8))\nsns.countplot(mall_data['Annual Income (k$)'], palette = 'rainbow')\nplt.title('Distribution of Annual Income', fontsize = 20)","7f5bfa9a":"plt.figure(figsize = (20,8))\nsns.countplot(x ='Spending Score (1-100)', data = mall_data,palette = 'rainbow' ) \nplt.title('Distribution of Annual Income')","60124242":"#visualize the correlation\nplt.figure(figsize = (20,8))\nsns.heatmap(mall_data.corr(), cmap = 'Wistia', annot = True)\nplt.title('Heatmap for the Data')\nplt.show()","d9aa625d":"plt.figure(1 , figsize = (15 , 6))\nfor gender in ['Male' , 'Female']:\n    plt.scatter(x = 'Age' , y = 'Annual Income (k$)' , data = mall_data[mall_data['Gender'] == gender] ,\n                s = 200 , alpha = 0.5 , label = gender)\nplt.xlabel('Age')\nplt.ylabel('Annual Income') \nplt.title('Age vs Annual Income w.r.t Gender')\nplt.legend()\nplt.show()","8f0a3014":"plt.figure(1 , figsize = (15 , 6))\nfor gender in ['Male' , 'Female']:\n    plt.scatter(x = 'Annual Income (k$)',y = 'Spending Score (1-100)' ,\n                data = mall_data[mall_data['Gender'] == gender] ,s = 200 , alpha = 0.5 , label = gender)\nplt.xlabel('Annual Income (k$)'), \nplt.ylabel('Spending Score (1-100)') \nplt.title('Annual Income vs Spending Score w.r.t Gender')\nplt.legend()\nplt.show()","5524686a":"#Considering only 2 features (Annual income and Spending Score) and no Label available\nX= mall_data.iloc[:, [3,4]].values","8ccf6418":"#Building the Model\n#KMeans Algorithm to decide the optimum cluster number , KMeans++ using Elbow Mmethod\n\nfrom sklearn.cluster import KMeans\nk=[]\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    k.append(kmeans.inertia_)","fd3f5b6e":"#Visualizing the ELBOW method to get the optimal value of K \n\nplt.figure(1 , figsize = (15 , 6))\nplt.plot(range(1,11), k)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","e01b7729":"#Model Build\nmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\ny_kmeans= model.fit_predict(X)\n\n#For unsupervised learning we use \"fit_predict()\" where in for supervised learning we use \"fit_tranform()\"\n#y_kmeans is the final model . Now how and where we will deploy this model in production is depends on what tool we are using.\n#This use case is very common and it is used in BFS industry(credit card) and retail for customer segmenattion.","e19aad41":"#Visualizing all the clusters \nplt.figure(1 , figsize = (15 , 8))\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'magenta', label = 'Cluster 1') ### Cluster 1\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')  ## Cluster 2\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'cyan', label = 'Cluster 3')  ## Cluster 3\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'green', label = 'Cluster 4')  ## Cluster 4\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'red', label = 'Cluster 5')   ## Cluster 5\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 200, c = 'black', label = 'Centroids')\nplt.title('K Means Clustering Algorithm')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","99b0b3d4":"#Awesome! Here, we can clearly visualize five clusters. The black dots represent the centroid of each cluster.\n\n\n#Cluster 1 (Red Color) -> earning high but spending less\n#cluster 2 (Blue Colr) -> average in terms of earning and spending \n#cluster 3 (Green Color) -> earning high and also spending high [TARGET SET]\n#cluster 4 (cyan Color) -> earning less but spending more\n#Cluster 5 (magenta Color) -> Earning less , spending less","0b80dbb3":"### Refrence:  https:\/\/www.analyticsvidhya.com\/blog\/2019\/08\/comprehensive-guide-k-means-clustering\/","4270c427":"<font size=\"+3\" color=\"purple\"><b>Reading the Dataset<\/b><\/font>","b5f2a3ca":"This Clustering Analysis gives us a very clear insight about the different segments of the customers in the Mall. There are clearly Five segments of Customers namely Miser, General, Target, Spendthrift, Careful based on their Annual Income and Spending Score which are reportedly the best factors\/attributes to determine the segments of a customer in a Mall.","345b8157":"<font size=\"+3\" color=\"purple\"><b>What is Clustering?<\/b><\/font>","8797c6e2":"Here, the red and green crosses are the new centroids.\n\n \n\n## Step 5: Repeat steps 3 and 4\nWe then repeat steps 3 and 4:","f9bbd0f3":"Customers in the red and blue clusters are quite similar to each other. The top four points in the red cluster share similar properties as that of the top two customers in the blue cluster. They have high income and high debt value. Here, we have clustered them differently. Whereas, if you look at case II:\n\n","e3afbc12":"Here, the red and green circles represent the centroid for these clusters.\n\n \n\n### Step 3: Assign all the points to the closest cluster centroid\nOnce we have initialized the centroids, we assign each point to the closest cluster centroid:\n\n","7e657dc3":"<font size=\"+3\" color=\"purple\"><b>Data Visualization<\/b><\/font>","ee747ebf":"<font size=\"+3\" color=\"purple\"><b>Properties of Clusters<\/b><\/font>\n\nHow about another example? We\u2019ll take the same bank as before who wants to segment its customers. For simplicity purposes, let\u2019s say the bank only wants to use the income and debt to make the segmentation. They collected the customer data and used a scatter plot to visualize it:","2159d4f3":"<font size=\"+3\" color=\"purple\"><b>Introduction to K-Means Clustering<\/b><\/font>\n\nWe have finally arrived at the meat of this article!\n\nRecall the first property of clusters \u2013 it states that the points within a cluster should be similar to each other. So, **our aim here is to minimize the distance between the points within a cluster.**","b5aa6387":"# Problem Statement\n### You own the mall and want to understand the customers like who can be easily converge [Target Customers] so that the sense can be given to marketing team and plan the strategy accordingly.","7029e338":"<a href=\"#top\" class=\"btn btn-success btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOP<\/a>","4aec1e6c":"- In Age columns most people belong to 18 to 50 Age, \n- Maximum Annual Income 45k to 90k.\n- Maximum Spending Sore is 50","ccb0b047":"<font size=\"+3\" color=\"purple\"><b>Model Building: Clustering using K- means<\/b><\/font>","f3dbc181":"# <font size=\"+3\" color=red ><b> <center><u>Customer Segmentation Analysis<\/u><\/center><\/b><\/font><br><a id=\"top\"><\/a>","4f3b80f5":"### Step 1: Choose the number of clusters k\nThe first step in k-means is to pick the number of clusters, k.\n\n \n\n### Step 2: Select k random points from the data as centroids\nNext, we randomly select the centroid for each cluster. Let\u2019s say we want to have 2 clusters, so k is equal to 2 here. We then randomly select the centroid:","0f91065e":"Here you can see that the points which are closer to the red point are assigned to the red cluster whereas the points which are closer to the green point are assigned to the green cluster.\n\n \n\n### Step 4: Recompute the centroids of newly formed clusters\nNow, once we have assigned all of the points to either cluster, the next step is to compute the centroids of newly formed clusters:","382baadb":"# <font color='blue'> Table of Contant<\/font>\n\n1. What is Clustring?\n2. Properties of Cluster\n3. Application of Clustring in Real World\n5. KMeans Clustring\n6. Stopping Creteria of K-means Clustring\n7. Importing the Library & Datasets\n8. Checking Null Values using Visualization\n9. Data Visualization & EDA\n    - Pairplot\n    - Countplot\n    - DistPlot\n    - BarPlot\n    - Heatmap\n    - Scatter Plot\n10. Model Building","ad14a1ec":"**There is an algorithm that tries to minimize the distance of the points in a cluster with their centroid \u2013 the k-means clustering technique.**\n\nK-means is a centroid-based algorithm, or a distance-based algorithm, where we calculate the distances to assign a point to a cluster. In K-Means, each cluster is associated with a centroid.\n\n**The main objective of the K-Means algorithm is to minimize the sum of distances between the points and their respective cluster centroid.**\n\nLet\u2019s now take an example to understand how K-Means actually works:","2eee95bc":"As a simple example. A bank wants to give credit card offers to its customers. Currently, they look at the details of each customer and based on this information, decide which offer should be given to which customer.\n\nNow, the bank can potentially have millions of customers. Does it make sense to look at the details of each customer separately and then make a decision? Certainly not! It is a manual process and will take a huge amount of time.\n\nSo what can the bank do? One option is to segment its customers into different groups. For instance, the bank can group the customers based on their income:","317f8a3c":"On the X-axis, we have the income of the customer and the y-axis represents the amount of debt. Here, we can clearly visualize that these customers can be segmented into 4 different clusters as shown below:","f2fcbfbd":"This is how clustering helps to create segments (clusters) from the data. The bank can further use these clusters to make strategies and offer discounts to its customers. So let\u2019s look at the properties of these clusters.\n\n \n\n## Property 1\n\n**All the data points in a cluster should be similar to each other.** Let me illustrate it using the above example:\n\n","3844cc30":"We have these 8 points and we want to apply k-means to create clusters for these points. Here\u2019s how we can do it.","3f7e365f":"## Property 2\n\nThe data points from different clusters should be as different as possible. This will intuitively make sense if you grasped the above property. Let\u2019s again take the same example to understand this property:\n\n","9a54a2e7":"Points in the red cluster are completely different from the customers in the blue cluster. All the customers in the red cluster have high income and high debt and customers in the blue cluster have high income and low debt value. Clearly we have a better clustering of customers in this case.\n\nHence, data points from different clusters should be as different from each other as possible to have more meaningful clusters.\n\nSo far, we have understood what clustering is and the different properties of clusters. But why do we even need clustering? Let\u2019s clear this doubt in the next section and look at some applications of clustering.\n\n<font size=\"+3\" color=\"purple\"><b>Applications of Clustering in Real-World Scenarios<\/b><\/font>\n\nClustering is a widely used technique in the industry. It is actually being used in almost every domain, ranging from banking to recommendation engines, document clustering to image segmentation.\n\n1. Customer Segmentation\n2. Document Clustering\n3. Image Segmentation\n4. Recommendation Engines","941eedef":"Can you see where I\u2019m going with this? The bank can now make three different strategies or offers, one for each group. Here, instead of creating different strategies for individual customers, they only have to make 3 strategies. This will reduce the effort as well as the time.\n\nThe groups I have shown above are known as clusters and the process of creating these groups is known as clustering. Formally, we can say that:\n\n### Clustering is the process of dividing the entire data into groups (also known as clusters) based on the patterns in the data.\n\nCan you guess which type of learning problem clustering is? Is it a supervised or unsupervised learning problem?\n\nThink about it for a moment and make use of the example we just saw. Got it? Clustering is an unsupervised learning problem!","65939b49":"<font size=\"+3\" color=\"purple\"><b>Importing the Library<\/b><\/font>","b79f09ac":"The step of computing the centroid and assigning all the points to the cluster based on their distance from the centroid is a single iteration. But wait \u2013 when should we stop this process? It can\u2019t run till eternity, right?\n\n \n\n### Stopping Criteria for K-Means Clustering\nThere are essentially three stopping criteria that can be adopted to stop the K-means algorithm:\n\n1. Centroids of newly formed clusters do not change\n2. Points remain in the same cluster\n3. Maximum number of iterations are reached\n\nWe can stop the algorithm if the centroids of newly formed clusters are not changing. Even after multiple iterations, if we are getting the same centroids for all the clusters, we can say that the algorithm is not learning any new pattern and it is a sign to stop the training.\n\nAnother clear sign that we should stop the training process if the points remain in the same cluster even after training the algorithm for multiple iterations.\n\nFinally, we can stop the training if the maximum number of iterations is reached. Suppose if we have set the number of iterations as 100. The process will repeat for 100 iterations before stopping.","509a879e":"# Thank you and please upvote for the motivation.","3c70e094":"Which of these cases do you think will give us the better clusters? If you look at case I:","439d5777":"If the customers in a particular cluster are not similar to each other, then their requirements might vary, right? If the bank gives them the same offer, they might not like it and their interest in the bank might reduce. Not ideal.\n\nHaving similar data points within the same cluster helps the bank to use targeted marketing. You can think of similar examples from your everyday life and think about how clustering will (or already does) impact the business strategy.","e76cacfe":"### <font color=\"purple\"><b>Main Aim of this Notebook is Understanding of K-means Clustring Algorithm & Model Building using Customer Data<\/b><\/font>"}}