{"cell_type":{"72db1d50":"code","f31201a0":"code","1ed95bca":"code","e3ca6e28":"code","9d8208d4":"code","f45913f5":"code","d3f012c6":"code","3e5ca560":"code","8d5400a6":"code","fec2d19b":"code","e6b859d6":"code","4c466283":"code","aaee6586":"code","505d6352":"code","f220d748":"code","9a200452":"code","b5f2cf1b":"code","8bddef75":"code","8413fb8d":"code","2389372f":"code","dc6a4662":"code","0520c40e":"code","769a48de":"code","955d2471":"code","2ebe0f98":"code","30bb2ef4":"code","7c543e75":"code","982c39e5":"code","c6648edc":"code","368746c2":"code","a1179e92":"code","3fa36238":"code","035352fc":"code","03e9f9e4":"code","5f173564":"code","e0646aa9":"code","edd7b329":"code","97e89122":"code","77ab57a5":"code","f59cf49a":"code","374e3f39":"code","40c8b25f":"code","f4bf8cec":"code","ab7db96d":"code","d5953015":"code","25cb8749":"code","37cfebcb":"markdown","9335f443":"markdown","a82dbe72":"markdown","75967e96":"markdown","6278269e":"markdown","2e7e4ecb":"markdown","d9996915":"markdown","d604fcd8":"markdown","3f9945d0":"markdown","b2d89a08":"markdown","606d4cc4":"markdown","40919564":"markdown","83a5d220":"markdown"},"source":{"72db1d50":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats","f31201a0":"import warnings\nwarnings.filterwarnings('ignore')","1ed95bca":"df = pd.read_csv('\/kaggle\/input\/paysim1\/PS_20174392719_1491204439457_log.csv')\ndf = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\nprint(df.head())\nprint(df.isnull().values.sum())","e3ca6e28":"df.info()","9d8208d4":"dfFraud = df[df.isFraud == 1]\nprint(f'Number of frauds: {len(dfFraud)}')\nprint(f'% of frauds among transactions: {len(dfFraud)\/len(df)*100}%')\nprint(f'Number of frauds, by type: {list(dict(dfFraud.type.value_counts()).keys())[0]}: {list(dict(dfFraud.type.value_counts()).values())[0]}\\n{list(dict(dfFraud.type.value_counts()).keys())[1]}: {list(dict(dfFraud.type.value_counts()).values())[1]}')\nprint(f'Flagged as fraud: {len(df[df.isFlaggedFraud==1])}')","f45913f5":"sns.pairplot(df[df.isFlaggedFraud==1])","d3f012c6":"print(df.shape)\ndf.drop(columns=\"isFlaggedFraud\", inplace=True)\nprint(df.shape)\nprint(df.columns)","3e5ca560":"df['type_nameOrig'] = df.nameOrig.apply(lambda x: x[0])\nprint(df.type_nameOrig.value_counts())\ndf['type_nameDest'] = df.nameDest.apply(lambda x: x[0])\nprint(df.type_nameDest.value_counts())","8d5400a6":"df.drop('type_nameOrig', axis=1, inplace=True)\ndf.drop('nameOrig', axis=1, inplace=True)\ndf.drop('nameDest', axis=1, inplace=True)","fec2d19b":"dfFraud = df[df.isFraud == 1]\nprint('type_nameDest')\nprint(f\"% among all: {len(df[df.type_nameDest == 'C'])\/len(df)*100}%\")\nprint(f\"% among frauds: {len(dfFraud[dfFraud.type_nameDest == 'C'])\/len(dfFraud)*100}%\")","e6b859d6":"dummies = pd.get_dummies(df['type_nameDest'], prefix='type_nameDest', drop_first=True)\ndf = pd.concat([df, dummies], axis=1)\ndf.drop('type_nameDest', axis=1, inplace=True)\ndf.info()","4c466283":"dfFraud = df[df.isFraud == 1]  \nprint(dfFraud.type.value_counts())\ndfFraud = []","aaee6586":"X = df[(df.type == 'TRANSFER') | (df.type == 'CASH_OUT')]\ny = X['isFraud']\nXfraud = X.loc[y == 1]\nX['type'] = X.type.apply(lambda x: 1 if x == 'CASH_OUT' else 0)\nprint(X.type.value_counts())","505d6352":"X.type_nameDest_M.value_counts()","f220d748":"X.drop('type_nameDest_M', axis=1, inplace=True)","9a200452":"limit = len(X)\n\ndef plotStrip(x, y, hue, figsize = (14, 9)):\n    \n    fig = plt.figure(figsize = figsize)\n    colours = plt.cm.tab10(np.linspace(0, 1, 9))\n    with sns.axes_style('ticks'):\n        ax = sns.stripplot(x, y, \\\n             hue = hue, jitter = 0.4, marker = '.', \\\n             size = 4, palette = colours)\n        ax.set_xlabel('')\n        ax.set_xticklabels(['genuine', 'fraudulent'], size = 16)\n        for axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(2)\n\n        handles, labels = ax.get_legend_handles_labels()\n        plt.legend(handles, ['Transfer', 'Cash out'], bbox_to_anchor=(1, 1), \\\n               loc=2, borderaxespad=0, fontsize = 16);\n    return ax","b5f2cf1b":"ax = plotStrip(y, np.log(X.amount), X.type)\nax.set_ylabel('log_amount', size = 25)","8bddef75":"maxtds = X.amount.max()\nmaxfraud = X[X.isFraud == 1].amount.max()\n\nprint(f\"Max amount among all: {maxtds}\\nMax amount among frauds: {maxfraud}\")\nprint(f'Equal to max \u00e0 among all: {len(X[(X.amount == maxtds)])}\\nEqual to max among frauds: {len(Xfraud[Xfraud.amount == maxfraud])}\\n')\nprint()\nprint(f'Equal to 10.000.000 among all: {len(X[X.amount==10000000])}')\nprint(f'Equal to 10.000.000 among frauds: {len(Xfraud[Xfraud.amount==10000000])}')\nprint()\nprint(f'% of 10.000.000 among all: {len(X[X.amount==10000000])\/len(X)*100}%')\nprint(f'% of 10.000.000 among frauds: {len(Xfraud[X.amount==10000000])\/len(Xfraud)*100}%')\n\nX['amount10'] = X.amount.apply(lambda x: 1 if x == 10000000 else 0)","8413fb8d":"plt.hist(X[X.isFraud==1].oldBalanceDest, range=[0, 1000000], bins=20, color='r')","2389372f":"plt.hist(X[X.isFraud==0].oldBalanceDest, range=[0, 1000000], bins=20, color='b')","dc6a4662":"plt.hist(X[X.isFraud==1].newBalanceDest, range=[0, 5000000], bins=20, color='r')","0520c40e":"plt.hist(X[X.isFraud==0].newBalanceDest, range=[0, 5000000], bins=20, color='b')","769a48de":"plt.hist(np.log1p(X[X.isFraud==1].newBalanceOrig), range=[0, 19], bins=14, color='r')","955d2471":"plt.hist(np.log1p(X[X.isFraud==0].newBalanceOrig), range=[0, 19], bins=14, color='b')","2ebe0f98":"plt.hist(np.log1p(X[X.isFraud==1].oldBalanceOrig), range=[-5, 19], bins=14, color='r')","30bb2ef4":"plt.hist(np.log1p(X[X.isFraud==0].oldBalanceOrig), range=[-5, 19], bins=14, color='b')","7c543e75":"xis = X.loc[(np.log1p(X.newBalanceOrig)>10) & (np.log1p(X.newBalanceOrig)<20)]\nprint(f'% among all entre todos: {len(xis)\/len(X)*100}%')\nxis = Xfraud.loc[(np.log1p(Xfraud.newBalanceOrig)>10) & (np.log1p(Xfraud.newBalanceOrig)<20)]\nprint(f'% among frauds: {len(xis)\/len(Xfraud)*100}%')\nxis = 0","982c39e5":"sns.scatterplot(np.log1p(X.oldBalanceOrig), np.log1p(X.amount), hue=X.isFraud)","c6648edc":"sns.scatterplot(np.log1p(X.loc[X.amount == X.oldBalanceOrig].oldBalanceOrig),\n                np.log1p(X.loc[X.amount == X.oldBalanceOrig].amount), alpha=0.05, hue=X.isFraud)","368746c2":"sns.scatterplot(np.log1p(X.newBalanceDest),np.log1p(X.oldBalanceDest), hue=X.isFraud)","a1179e92":"sns.scatterplot(np.log1p(X.loc[X.newBalanceDest == X.oldBalanceDest].newBalanceDest),\n                np.log1p(X.loc[X.newBalanceDest == X.oldBalanceDest].oldBalanceDest), alpha=0.9, hue=X.isFraud)","3fa36238":"X['newBalanceDest0'] = X.newBalanceDest.apply(lambda x: 1 if x == 0 else 0)\nX['oldBalanceDest0'] = X.oldBalanceDest.apply(lambda x: 1 if x == 0 else 0)\n\nX.loc[(df.oldBalanceDest == 0) & (df.newBalanceDest == 0), 'newoldBalanceDest0'] = 1\nX.loc[(df.oldBalanceDest != 0) | (df.newBalanceDest != 0), 'newoldBalanceDest0'] = 0\n\nX.loc[(X.newBalanceDest == X.oldBalanceDest), 'balanceDestEqual'] = 1\nX.loc[(X.newBalanceDest != X.oldBalanceDest), 'balanceDestEqual'] = 0\n\nX.loc[(X.amount == X.oldBalanceOrig), 'amountOldBalanceOrigEqual'] = 1\nX.loc[(X.amount != X.oldBalanceOrig), 'amountOldBalanceOrigEqual'] = 0\n\nX.loc[(X.oldBalanceOrig == 0), 'oldBalanceOrig0'] = 1\nX.loc[(X.oldBalanceOrig != 0), 'oldBalanceOrig0'] = 0\nX.loc[(X.newBalanceOrig == 0), 'newBalanceOrig0'] = 1\nX.loc[(X.newBalanceOrig != 0), 'newBalanceOrig0'] = 0\n\n\nXfraud = X.loc[y == 1]\n\nli = ['newBalanceDest0','oldBalanceDest0', 'newoldBalanceDest0',  'balanceDestEqual', 'amountOldBalanceOrigEqual', 'oldBalanceOrig0', 'newBalanceOrig0']\nfor l in li:\n    print(l)\n    print(f'% among all: {X[l].mean()*100}%')\n    print(f'% among frauds: {Xfraud[l].mean()*100}%')\n    print()","035352fc":"del X['newBalanceOrig0']","03e9f9e4":"X['erroOrig'] = X.newBalanceOrig + X.amount - X.oldBalanceOrig\nX['erroDest'] = X.oldBalanceDest + X.amount - X.newBalanceDest","5f173564":"ax = plotStrip(y, X.erroDest, X.type)\nax.set_ylabel('erroDest', size = 25)","e0646aa9":"X['erroDest<0'] = X.erroDest.apply(lambda x: 1 if x == 0 else 0)\nXfraud = X[X.isFraud == 1]\nprint(f\"% among all: {X['erroDest<0'].mean()*100}%\")\nprint(f\"% among frauds: {Xfraud['erroDest<0'].mean()*100}%\")","edd7b329":"ax = plotStrip(y, X.erroOrig, X.type)\nax.set_ylabel('erroOrig', size = 25)","97e89122":"print(f'% among all: {len(X[X.erroOrig == 0])\/len(X)*100}%')\nprint(f'% among frauds: {len(Xfraud[Xfraud.erroOrig == 0])\/len(Xfraud)*100}%')\nX['erroOrig0'] = X.erroOrig.apply(lambda x: 1 if x==0 else 0)","77ab57a5":"numeric_feats = X.dtypes[X.dtypes != \"object\"].index\n\nskewed_feats = X[numeric_feats].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkewness: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(20)","f59cf49a":"nolog = ['amount10','isFlaggedFraud','erroDest<0', 'newBalanceDest0',\n          'erroDest', 'type', 'step', 'isFraud', 'balanceDestEqual', 'amountOldBalanceOrigEqual',\n          'oldBalanceDest0', 'newoldBalanceDest0', 'oldBalanceOrig0', 'newBalanceOrig0', 'erroOrig0']\n\nfor c in X.columns:\n    if c not in nolog:\n        X[f'log_{c}'] = np.log1p(X[c])\n        X[f'standard_log_{c}'] = (X[f'log_{c}'] - X[f'log_{c}'].mean()) \/ X[f'log_{c}'].std()\n        del X[c]\n        del X[f'log_{c}']\n\nnumeric_feats = X.dtypes[X.dtypes != \"object\"].index\n\nskewed_feats = X[numeric_feats].apply(lambda x: stats.skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkewness: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(20)","374e3f39":"X[X.columns[0:]].corr()['isFraud'][:-1]","40c8b25f":"X.drop(columns=\"isFraud\", inplace=True)","f4bf8cec":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split \n\nsm = SMOTE(random_state = 33)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 38) \nX_train_new, y_train_new = sm.fit_sample(X_train, y_train.ravel())\ny_train = pd.Series(y_train_new)\nX_train = pd.DataFrame(X_train_new)","ab7db96d":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import metrics\n\nclf = GradientBoostingClassifier(random_state = 0)\n\n# Fitting the model\nclf.fit(X_train, y_train)\nprint()\nprint('****Results****')\n# Making Predictions\ny_pred = clf.predict(X_test)\n# Printing metrics\nprint(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\", metrics.precision_score(y_test, y_pred))\nprint(\"Recall:   \", metrics.recall_score(y_test, y_pred))\nprint(\"F1:       \", metrics.f1_score(y_test, y_pred))\nprint(\"AUPRC:    \", metrics.average_precision_score(y_test, y_pred))","d5953015":"#AUPRC CURVE\n\nprecision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\nno_skill = len(y_test[y_test==1]) \/ len(y_test)\nplt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\nplt.plot(recall, precision, marker='.', label='Classifier')\n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","25cb8749":"# FEATURE IMPORTANCE\nfeature_importance = clf.feature_importances_\n# make importances relative to max importance\nfeature_importance = feature_importance \/ feature_importance.max()\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","37cfebcb":"There are only two types among frauds. I'll limit my DataFrame to those two types","9335f443":"It does not seem relevant","a82dbe72":"Creating variables with errors in each of the end of the transaction","75967e96":"### **BALANCING DATAFRAME AND DIVISION BETWEEN TRAIN AND TEST**","6278269e":"As percentages differ a lot, I will create a dummie for type_nameDest","2e7e4ecb":"### **EXPLORATORY DATA ANALYSIS AND FEATURE ENGINEERING**","d9996915":"The difference in newBalanceOrig0 does not seem significant. I'll drop it.","d604fcd8":"Now all of them have the same value, therefore I will delete the dummie column I created (type_nameDest_M)","3f9945d0":"### **DATA CLEANING**","b2d89a08":"### **MACHINE LEARNING**","606d4cc4":"This notebook was partly based upon another work, whose author is Arjun Joshua and that is registered **[here](https:\/\/www.kaggle.com\/arjunjoshua\/predicting-fraud-in-financial-payment-services)**. I did not reached his metrics, but got pretty close.\n\nIn this notebook, I analyzed \"**Synthetic Financial Datasets For Fraud Detection**\" dataset and tried to predict the occurrence of fraud. I explored the data and thereafter I started applying extensive feature engineering (maybe even too much of it, based on the feature importance graph at the end of the notebook). I used smote to oversample fraudulent data and the classifier I chose to make the prediction is **GradientBoostingClassifie**r (Although the tests are not here, I also tried Decision Tree, whose results were a bit less impressive, and Random Forest, which presented very little difference in results). Since the data is very imbalanced, I chose recall, precision and  metrics that combined them --f1 and average_precision (or AUPRC)-- to evaluate my model. As you can see below, I reached: **Precision - 1.00, Recall - 0.9952, F1 - 0.9976, AUPRC - 0.9952**.\n\nI'm open for questions, corrections and tips, if anyone has them.","40919564":"As they're all equal (C), it's not worth to keep type_nameOrig column","83a5d220":"Variables newBalanceDest = 0 e oldBalanceDest = 0 seem to be the cause of transitions being flagged as fraudulent. I will look at those variables below and delete isFlaggedFraud to prevent any kind of data leakage."}}