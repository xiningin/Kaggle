{"cell_type":{"abae4af8":"code","cd8edbea":"code","9abd180e":"code","197fe97e":"code","4366d810":"code","8a577b22":"code","974d6b79":"code","46bac428":"code","67ff71a5":"code","4c816a08":"code","4b8dbe1c":"code","1c454644":"code","ee44b241":"code","bca28b44":"code","c4367627":"code","0f210d22":"code","68d6c6e4":"code","00d4c55b":"code","d3e030a3":"code","1a398733":"code","be64a74a":"code","219af027":"code","a1554ff5":"markdown","fbe6e9de":"markdown","b95c33a7":"markdown","aa492787":"markdown","f951e38e":"markdown","d00a943e":"markdown"},"source":{"abae4af8":"import numpy as np\nimport pandas as pd\nimport random\nimport imageio\nimport os\nimport datetime\nimport io\nfrom PIL import Image\nfrom IPython.display import Image as IPyImage\nimport matplotlib.pyplot as plt \nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras.utils import plot_model","cd8edbea":"class IdentityBlock(tf.keras.Model):\n    def __init__(self, filters, kernel_size_1, kernel_size_2=0, conv=False):\n        super(IdentityBlock, self).__init__(name='')\n        self.conv = conv\n        \n        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size_1, padding='same')\n        self.bn1 = tf.keras.layers.BatchNormalization()\n\n        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size_1, padding='same')\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        \n        if conv:\n            self.conv3 = tf.keras.layers.Conv2D(filters, kernel_size_2, padding='same')\n\n        self.act = tf.keras.layers.Activation('relu')\n        self.add = tf.keras.layers.Add()\n    \n    def call(self, input_tensor):\n        x = self.conv1(input_tensor)\n        x = self.bn1(x)\n        x = self.act(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        \n        if self.conv:\n            input_tensor = self.conv3(input_tensor)\n\n        x = self.add([x, input_tensor])\n        x = self.act(x)\n        return x","9abd180e":"class ResNet(tf.keras.Model):\n    def __init__(self, num_classes):\n        super(ResNet, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.act = tf.keras.layers.Activation('relu')\n        self.max_pool = tf.keras.layers.MaxPool2D((3, 3))\n\n        # Use the Identity blocks that we just defined\n        self.id_a = IdentityBlock(64, 3)\n        self.id_b = IdentityBlock(64, 3)\n        \n        self.id_c = IdentityBlock(64, 3, 1, True)\n        self.id_d = IdentityBlock(64, 3)\n        \n        self.id_e = IdentityBlock(64, 3, 1, True)\n        self.id_f = IdentityBlock(64, 3)\n        \n        self.id_g = IdentityBlock(64, 3, 1, True)\n        self.id_h = IdentityBlock(64, 3)\n        \n        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n\n    def call(self, inputs):\n        x = self.conv(inputs)\n        x = self.bn(x)\n        x = self.act(x)\n        x = self.max_pool(x)\n\n        # insert the identity blocks in the middle of the network\n        x = self.id_a(x)\n        x = self.id_b(x)\n        \n        x = self.id_c(x)\n        x = self.id_d(x)\n        \n        x = self.id_e(x)\n        x = self.id_f(x)\n        \n        x = self.id_g(x)\n        x = self.id_h(x)\n        \n        x = self.global_pool(x)\n        return self.classifier(x)","197fe97e":"df_train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","4366d810":"df_train.head()","8a577b22":"df_test.head()","974d6b79":"X_train = np.reshape(df_train.iloc[0:,1:].values\/255, (60000,28, 28, 1))\ny_train = df_train['label']\n\nX_test = np.reshape(df_test.iloc[0:,1:].values\/255, (10000,28, 28, 1))\ny_test = df_test['label']","46bac428":"print(f'training data shape: {X_train.shape}')\nprint(f'test data shape: {X_test.shape}')","67ff71a5":"# random.seed(42)\nexample = random.sample(range(0, len(X_train)+1), 10)","4c816a08":"font = {'color':  'darkred',\n        'weight': 'normal',\n        'size': 16,\n        }\nplt.subplots(2, 5, figsize=(15,7))\nfor i in range(len(example)):\n    plt.subplot(2, 5, i+1)\n    plt.title(y_train[example[i]], fontdict=font)\n    plt.imshow(X_train.reshape(-1, 28, 28, 1)[example[i]][:,:,0])","4b8dbe1c":"# Visualization utilities\nplt.rc('font', size=20)\nplt.rc('figure', figsize=(15, 3))\n\ndef display_digits(inputs, outputs, ground_truth, epoch, n=10):\n    plt.clf()\n\n    plt.yticks([])\n    plt.grid(None)\n    inputs = np.reshape(inputs, [n, 28, 28])\n    inputs = np.swapaxes(inputs, 0, 1)\n    inputs = np.reshape(inputs, [28, 28*n])\n    plt.imshow(inputs)\n    plt.xticks([28*x+14 for x in range(n)], outputs)\n    for i, t in enumerate(plt.gca().xaxis.get_ticklabels()):\n        if np.array(outputs)[i] == np.array(ground_truth)[i]: \n            t.set_color('green') \n        else: \n            t.set_color('red')\n    plt.grid(None)","1c454644":"GIF_PATH = 'animation.gif'","ee44b241":"class VisCallback(tf.keras.callbacks.Callback):\n    def __init__(self, inputs, ground_truth, display_freq=2, n_samples=10):\n        self.inputs = inputs\n        self.ground_truth = ground_truth\n        self.images = []\n        self.display_freq = display_freq\n        self.n_samples = n_samples\n\n    def on_epoch_end(self, epoch, logs=None):\n        # Randomly sample data\n        indexes = np.random.choice(len(self.inputs), size=self.n_samples)\n        X, y = self.inputs[indexes], self.ground_truth[indexes]\n        predictions = np.argmax(self.model.predict(X), axis=1)\n\n        # Plot the digits\n        display_digits(X, predictions, y, epoch, n=self.n_samples)\n\n        # Save the figure\n        buf = io.BytesIO()\n        plt.savefig(buf, format='png')\n        buf.seek(0)\n        image = Image.open(buf)\n        self.images.append(np.array(image))\n\n        # Display the digits every 'display_freq' number of epochs\n        if epoch % self.display_freq == 0:\n            plt.show()\n\n    def on_train_end(self, logs=None):\n        imageio.mimsave(GIF_PATH, self.images, fps=1)","bca28b44":"logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\ntensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n\ncallbacks=[VisCallback(X_test, y_test), tensorboard_callback]","c4367627":"y_train.shape","0f210d22":"resnet = ResNet(10)\nresnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","68d6c6e4":"input_shape = (None, 28, 28, 1)\nresnet.build(input_shape) # `input_shape` is the shape of the input data\n                         # e.g. input_shape = (None, 32, 32, 3)\na = resnet.summary()","00d4c55b":"history = resnet.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=callbacks) ","d3e030a3":"SCALE = 60\n\n# FYI, the format is set to PNG here to bypass checks for acceptable embeddings\nIPyImage(GIF_PATH, format='png', width=15 * SCALE, height=3 * SCALE)","1a398733":"history.history.keys()","be64a74a":"# Summarize the training process\nfig = plt.figure(figsize=(20,7))\nfig.add_subplot(121)\n\n# Accuracy\nplt.plot(history.epoch, history.history['accuracy'], label = \"accuracy\")\nplt.plot(history.epoch, history.history['val_accuracy'], label = \"val_accuracy\")\n\nplt.title(\"Accuracy\", fontsize=18)\nplt.xlabel(\"Epochs\", fontsize=15)\nplt.ylabel(\"Accuracy\", fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n\n#Adding Subplot 1 (For Loss)\nfig.add_subplot(122)\n\nplt.plot(history.epoch, history.history['loss'], label=\"loss\")\nplt.plot(history.epoch, history.history['val_loss'], label=\"val_loss\")\n\nplt.title(\"Loss\", fontsize=18)\nplt.xlabel(\"Epochs\", fontsize=15)\nplt.ylabel(\"Loss\", fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()","219af027":"%load_ext tensorboard\n%tensorboard --logdir logs","a1554ff5":"Here, we define a visual callback that in every two epochs, chooses random indices from the test set, and shows how the model predicts those indices. It shows the precited labels as titles below the image, and if it has predicted correctly, the title would be green, and otherwise, it would be red. After the training is done, it makes a gif from the whole process that we will display at the end. ","fbe6e9de":"ResNet18 is composed of several blocks that are also known as Identity Blocks. The following figures illustrate two Identity Blocks being used in the ResNet18 architecture. Following the figures, you can find the Identity Block code.","b95c33a7":"![](https:\/\/d2l.ai\/_images\/resnet18.svg)","aa492787":"![](https:\/\/d2l.ai\/_images\/resnet-block.svg)","f951e38e":"The architecture and the code of ResNet18 are shown and written below using the custom layer or Indentity Block that we defined.","d00a943e":"By running the below code, you can have access to TensorBoard, but apparently, in Kaggle, this feature is not accessible right now."}}