{"cell_type":{"49b2e4f0":"code","c0c204ee":"code","b4b5d4aa":"code","4b3f1bfb":"code","f2800af4":"code","90eee48d":"code","e369cdd4":"code","59f042ed":"code","5ff66196":"code","87faed94":"code","c7f0c9e5":"code","21761d28":"code","79379ae4":"code","b256d894":"code","454cff7c":"code","dfd595a0":"code","4ceffb9e":"code","7a1a680e":"code","5647895b":"code","b42d12b1":"code","86a1d40d":"code","889bdb25":"code","ca15a200":"code","3aa93c09":"code","b8350435":"code","6fa97bc7":"code","d9868478":"code","d8715c37":"code","ffd2dc4a":"markdown","f1d2b22d":"markdown","c7935bd8":"markdown","4830fe4a":"markdown","fe55f038":"markdown","28b91a9f":"markdown","c29e8a75":"markdown","dce32d03":"markdown","29952e73":"markdown","e581dd01":"markdown","81997ad7":"markdown","1cd7a26e":"markdown","af1fe5c6":"markdown","751fd6f2":"markdown","b7ccd989":"markdown","305a4748":"markdown","5cc62c92":"markdown","f7c31868":"markdown","17201768":"markdown","0df73de5":"markdown"},"source":{"49b2e4f0":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport matplotlib.animation as animation\nfrom sklearn.model_selection import train_test_split\nfrom osgeo import gdal\nfrom IPython.display import HTML\nfrom base64 import b64encode\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as mpatches\nfrom matplotlib import colors ","c0c204ee":"dataset = '..\/input\/land-use-land-cover-time-series\/time_series.csv'\n\nclasse_info = {\n  'not identified':           {'value':0, 'color': '#000000'},\n  'soybean':                  {'value':1, 'color': '#ffe32e'},\n  'maize':                    {'value':2, 'color': '#FF0000'},\n  'cotton':                   {'value':3, 'color': '#0000FF'},\n  'coffee':                   {'value':4, 'color': '#75781f'},\n  'beans':                    {'value':5, 'color': '#e5eb34'},\n  'wheat':                    {'value':6, 'color': '#ff24e5'},\n  'sorghum':                  {'value':7, 'color': '#a80a96'},\n  'millet':                   {'value':8, 'color': '#fa73eb'},\n  'eucalyptus':               {'value':9, 'color': '#c75e0e'},\n  'pasture':                  {'value':10, 'color': '#fff68f'},\n  'hay':                      {'value':11, 'color': '#c9cf91'},\n  'grass':                    {'value':12, 'color': '#12e362'},\n  'crotalari':                {'value':13, 'color': '#12e362'},\n  'maize+crotalari':          {'value':14, 'color': '#f77159'},\n  'cerrado':                  {'value':15, 'color': '#5e2e10'},\n  'conversion area':          {'value':16, 'color': '#12e0e3'},\n  'uncultivated soil':        {'value':17, 'color': '#a9b0b0'},\n  'ncc':                      {'value':18, 'color': '#12e362'},\n  'brachiaria':               {'value':19, 'color': '#12e362'},\n}\n\nclasses = {x : y.get('value') for x, y in classe_info.items()}\n\nclasse_colors = [y.get('color') for x, y in classe_info.items()]\n\nfeatures = ['red', 'nir', 'swir']\nn_features = len(features)\n\nsequence_size = 30\n\nmodel_dir = '.\/logs'","b4b5d4aa":"df = pd.read_csv(dataset)\ndf.head()","4b3f1bfb":"df['class_name'] = df.apply(lambda row: list(classes.keys())[list(classes.values()).index(row['class'])], axis = 1) \ndf['date'] = pd.to_datetime(df['date'])\ndf.head()","f2800af4":"points = df.id.unique()\n\nfor point in points[:7]:\n    point_df = df[df['id'] == point]\n    point_df = point_df.sort_values(by=['date'])\n    ax = point_df.plot(x='date', y=features, figsize=(20, 5))\n\n    axes1 = plt.gca()\n    axes2 = axes1.twiny()\n    \n    class_names = point_df['class_name'].tolist()\n    axes2.set_xticks(np.arange(len(class_names)))\n    axes2.set_xticklabels(class_names, rotation=50, fontsize=12, minor=False)\n\n    axes1.set_ylabel(\"Features\")\n    axes1.set_xlabel(\"Image Date\")\n    axes2.set_xlabel(\"Land Use\/Land Cover\")","90eee48d":"X = []\ny = []\n\nfor point in points:\n    point_df = df[df['id'] == point]\n    point_df = point_df.sort_values(by=['date'])\n    \n    x_values = point_df[features].to_numpy()\n    y_values = point_df['class'].tolist()\n\n    x_values = tf.keras.preprocessing.sequence.pad_sequences([x_values], \n                                                             maxlen=sequence_size, dtype='float32')[0]\n    y_values = tf.keras.preprocessing.sequence.pad_sequences([y_values], \n                                                             maxlen=sequence_size, \n                                                             value=classes.get('not identified'), dtype='float32')[0]\n    \n    X.append(x_values)\n    \n    labels = []\n    for y_value in y_values:\n        values = np.zeros(len(classes))\n        np.put(values, [y_value], [1])\n        labels.append(values)\n        \n    y.append(labels)\n    \nX = np.array(X)\ny = np.array(y)\n\nX = X.reshape((X.shape[0], X.shape[1], n_features))\n\nX.shape, y.shape","e369cdd4":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\nX_validation, X_test, y_validation, y_test = train_test_split(X_validation, y_validation, test_size=0.5)\n\nprint(\"Train: \", len(X_train), \"\\nValidation: \", len(X_validation), \"\\nTest:\", len(X_test))","59f042ed":"X_train.shape, y_train.shape","5ff66196":"def LSTM(n_classes, sequence_size, n_features):\n    model = tf.keras.models.Sequential()\n\n    model.add(tf.keras.layers.LSTM(200, input_shape=(sequence_size, n_features)))\n    \n    model.add(tf.keras.layers.RepeatVector(sequence_size))\n    \n    model.add(tf.keras.layers.LSTM(200, activation='relu', return_sequences=True))\n    \n    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation='relu')))\n\n    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_classes)))\n    \n    model.add(tf.keras.layers.Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n\n    return model\n              \nmodel = LSTM(n_classes=len(classes), sequence_size=sequence_size, n_features=n_features)\n              \nmodel.summary()\n\ntf.keras.utils.plot_model(model, show_shapes=True, to_file='\/kaggle\/working\/model.png')","87faed94":"checkpoint_path = \"{dir}\/model.ckpt\".format(dir=model_dir)\n\nlatest = tf.train.latest_checkpoint(model_dir)\n\nif latest:\n    model.load_weights(latest)\n\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True)\n\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', \n                                            baseline=None, restore_best_weights=True)\n\ncallbacks = [cp_callback, es_callback]","c7f0c9e5":"epochs = 100\nbatch_size = 128\n\nhistory = model.fit(x=X_train, y=y_train, \n          validation_data=(X_validation, y_validation),\n          epochs=epochs, batch_size=batch_size, callbacks=callbacks, use_multiprocessing=False, verbose=1)","21761d28":"fig, ax = plt.subplots(2,1, figsize=(15, 10))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","79379ae4":"model.evaluate(X_test, y_test, batch_size=128)","b256d894":"model.save('model.h5')","454cff7c":"image_path = '..\/input\/land-use-land-cover-time-series\/image_2019-10-01_2020-10-01.tif'\npredicted_path = '.\/predicted_2019-10-01_2020-10-01.tif'\ndata_source = gdal.Open(image_path)\nimage = data_source.ReadAsArray()\nimage.shape","dfd595a0":"flat_image = image.reshape(image.shape[0],\n                           image.shape[1] * image.shape[2])\n\nflat_image = flat_image.transpose()\n\nflat_image = flat_image.reshape((flat_image.shape[0],\n                                 int(flat_image.shape[1] \/ n_features), n_features))\n\nflat_image = np.array(flat_image).astype(float)\n\nflat_image.shape","4ceffb9e":"padded_image = tf.keras.preprocessing.sequence.pad_sequences(flat_image, maxlen=sequence_size, dtype='float32')\n\npadded_image.shape","7a1a680e":"rescaled_image = padded_image \/ 10000.0","5647895b":"flat_predicted = model.predict(rescaled_image, batch_size=1024)\nflat_predicted.shape","b42d12b1":"flat_labels = np.argmax(flat_predicted, axis=2)\nflat_predicted.shape, '-->', flat_labels.shape","86a1d40d":"flat_labels.shape, flat_image.shape[1]","889bdb25":"valid_flat_labels = flat_labels[:,-flat_image.shape[1]:]\nvalid_flat_labels.shape","ca15a200":"predicted_image = valid_flat_labels.reshape((image.shape[1], image.shape[2], valid_flat_labels.shape[-1]))\npredicted_image.shape","3aa93c09":"predicted_image = predicted_image[:, :, predicted_image.shape[-1] - image.shape[0]:]\npredicted_image.shape","b8350435":"# save results\ndriver = data_source.GetDriver()\noutput_dataset = driver.Create(predicted_path,\n                               predicted_image.shape[1],\n                               predicted_image.shape[0],\n                               predicted_image.shape[-1],\n                               gdal.GDT_Byte,\n                               ['COMPRESS=DEFLATE'])\noutput_dataset.SetGeoTransform(data_source.GetGeoTransform())\noutput_dataset.SetProjection(data_source.GetProjection())\n\nfor band_id in range(predicted_image.shape[-1]):\n    band_data = predicted_image[:, : , band_id]        \n    output_dataset.GetRasterBand(band_id + 1).WriteArray(band_data, 0, 0)\noutput_dataset.FlushCache()\ndel output_dataset\nprint(\"Completed!\")","6fa97bc7":"data_source = gdal.Open(predicted_path)\nimage = data_source.ReadAsArray()\nimage.shape","d9868478":"def play(filename):\n    html = ''\n    video = open(filename,'rb').read()\n    src = 'data:video\/mp4;base64,' + b64encode(video).decode()\n    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video\/mp4\"><\/video>' % src \n    return HTML(html)","d8715c37":"fig, ax = plt.subplots(figsize=(15, 10))\n\nims = []\n\ncmap = colors.ListedColormap(classe_colors) \n\nfor band in image:\n    im = ax.imshow(band, vmin=0, vmax=len(classe_colors)-1, cmap=cmap, animated=True)\n    ims.append([im])\n\nani = animation.ArtistAnimation(fig, ims, interval=1000, blit=True, repeat_delay=1000)\n\npatches = list(map(lambda item: mpatches.Patch(color=item[1].get('color'), label=item[0]), classe_info.items() ))\nplt.legend(handles=patches, loc='center left', bbox_to_anchor=(1, 0.5))\n    \n\noutput = '\/kaggle\/working\/predicted.mp4'\n\nani.save(output)\n\nplay(output)","ffd2dc4a":"## Imports","f1d2b22d":"## Load dataset","c7935bd8":"## Create LSTM model","4830fe4a":"## Create callbacks","fe55f038":"## Plot time series","28b91a9f":"### Reescale time series values. From 0-10000 to 0-1","c29e8a75":"### Predict time series","dce32d03":"### Load image","29952e73":"## Predict image","e581dd01":"## Plot training and validation loss","81997ad7":"## Load predicted image","1cd7a26e":"## Split dataset in train, validation and test sets","af1fe5c6":"## Plot predicted image","751fd6f2":"## Evaluate model","b7ccd989":"## Prepare datasets","305a4748":"## Train model","5cc62c92":"### Reshape image","f7c31868":"## Save model","17201768":"## Settings","0df73de5":"### Pad time series"}}