{"cell_type":{"323c99df":"code","c9f7aa73":"code","08d4a823":"code","c489abcf":"code","6c4c5b83":"code","92eda158":"code","26416d03":"code","76a0d932":"code","5c10386d":"code","592682dc":"code","d2ad265b":"markdown","51ae0b94":"markdown","e7c5d1c9":"markdown","22f8a08c":"markdown","c32d0023":"markdown","3dfee557":"markdown","95c4f4b7":"markdown","7473213b":"markdown"},"source":{"323c99df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c9f7aa73":"import glob\nfrom keras.preprocessing.image import load_img, img_to_array\n\nimg_size = (224, 224)\nimg_array_list = []\ncls_list = []\n\ndir = '..\/input\/train\/PNEUMONIA'\nimg_list = glob.glob(dir + '\/*.jpeg')\nfor i in img_list:\n    img = load_img(i, color_mode='grayscale', target_size=(img_size))\n    img_array = img_to_array(img) \/ 255\n    img_array_list.append(img_array)\n    cls_list.append(1)\n\ndir = '..\/input\/train\/NORMAL'\nimg_list = glob.glob(dir + '\/*.jpeg')\nfor i in img_list:\n    img = load_img(i, color_mode='grayscale', target_size=(img_size))\n    img_array = img_to_array(img) \/ 255\n    img_array_list.append(img_array)\n    cls_list.append(0)\n\nX_train = np.array(img_array_list)\ny_train = np.array(cls_list)\nprint(X_train.shape, y_train.shape)","08d4a823":"from sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\nfrom keras.utils.np_utils import to_categorical\n\nX_learn, X_valid, y_learn, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\nshape = X_learn.shape\n\nX_learn = np.reshape(X_learn, (shape[0], shape[1] * shape[2] * shape[3]))\nros = RandomOverSampler(random_state=0)\nX_res, y_res = ros.fit_resample(X_learn, y_learn)\nX_res = np.reshape(X_res, (X_res.shape[0], shape[1], shape[2], shape[3]))\nY_res = to_categorical(y_res)\nY_valid = to_categorical(y_valid)\nprint('Train:', X_res.shape, Y_res.shape)\nprint('Test:', X_valid.shape, Y_valid.shape)","c489abcf":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nimport tensorflow as tf\n\ndef auc(y_true, y_pred):\n    auc = tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)\n    return auc\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 1)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 1)))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Dense(units=2, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', auc])","6c4c5b83":"model.fit(X_res, Y_res, batch_size=32, epochs=10)\nmodel.evaluate(X_valid, Y_valid, batch_size=32)","92eda158":"from sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\nfrom keras.utils.np_utils import to_categorical\n\nshape = X_train.shape\n\nX_train = np.reshape(X_train, (shape[0], shape[1] * shape[2] * shape[3]))\nros = RandomOverSampler(random_state=0)\nX_res, y_res = ros.fit_resample(X_train, y_train)\nX_train = np.reshape(X_train, (shape[0], shape[1], shape[2], shape[3]))\nX_res = np.reshape(X_res, (X_res.shape[0], shape[1], shape[2], shape[3]))\nY_res = to_categorical(y_res)\nprint('Train:', X_res.shape, Y_res.shape)","26416d03":"model.fit(X_res, Y_res, batch_size=32, epochs=10)","76a0d932":"import glob\nfrom keras.preprocessing.image import load_img, img_to_array\n\nimg_array_list = []\n\ndir = '..\/input\/test'\nimg_list = glob.glob(dir + '\/*.jpeg')\nimg_list.sort()\nfor i in img_list:\n    img = load_img(i, color_mode='grayscale', target_size=(img_size))\n    img_array = img_to_array(img) \/ 255\n    img_array_list.append(img_array)\n\nX_test = np.array(img_array_list)\nprint(X_test.shape)","5c10386d":"predict = model.predict(X_test)[:, 1]","592682dc":"submit = pd.read_csv('..\/input\/sampleSubmission.csv')\nsubmit['pneumonia'] = predict\nsubmit.to_csv('submission.csv', index=False)","d2ad265b":"# \u5b66\u7fd2","51ae0b94":"\u691c\u8a3c\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066\u3053\u306e\u30e2\u30c7\u30eb\u304c\u5341\u5206\u3067\u3042\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u305f\u3089\u3001\u5168\u3066\u306e\u8a13\u7df4\u30c7\u30fc\u30bf\u304b\u3089\u5b66\u7fd2\u3057\u76f4\u3059\u3002\n\n\uff08\u5341\u5206\u3067\u306a\u3044\u3068\u304d\u306f\u3001\u30e2\u30c7\u30eb\u306e\u69cb\u6210\u3092\u898b\u76f4\u3057\u3066\u3084\u308a\u76f4\u3059\u3002\uff09\n\n# \u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\n\n\u8a13\u7df4\u30c7\u30fc\u30bf\u5168\u4f53\u3092\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3002","e7c5d1c9":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf","22f8a08c":"# \u4e88\u6e2c","c32d0023":"# \u691c\u8a3c\uff08\u5b66\u7fd2\u3068\u8a55\u4fa1\uff09","3dfee557":"# \u691c\u8a3c\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\u3068\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\n\u8a13\u7df4\u30c7\u30fc\u30bf\u3092\u8a13\u7df4\u7528\u3068\u691c\u8a3c\u7528\u306b\u5206\u3051\u3001\u8a13\u7df4\u7528\u30c7\u30fc\u30bf\u3092RandomOverSampler\u3092\u4f7f\u3063\u3066\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3002\n\nimblearn\u304c\u5165\u529bX\u306f\u884c\u5217\uff082\u6b21\u5143\u30c7\u30fc\u30bf\uff09\u3001\u51fa\u529by\u306f\u30d9\u30af\u30c8\u30eb\uff081\u6b21\u5143\u30c7\u30fc\u30bf\uff09\u3057\u304b\u6271\u3048\u306a\u3044\u306e\u3067\u3001\u5165\u529bX\u304c(\u30c7\u30fc\u30bf\u6570, \u7e26, \u6a2a, \u30c1\u30e3\u30f3\u30cd\u30eb\u6570)\u3068\u306a\u3063\u3066\u3044\u308b\u3082\u306e\u3092 (\u30c7\u30fc\u30bf\u6570, \u7e26\u00d7\u6a2a\u00d7\u30c1\u30e3\u30f3\u30cd\u30eb\u6570) \u306breshape\u3057\u3066\u304b\u3089\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u9069\u7528\u3059\u308b\u3002\n\nkeras\u306e\u5206\u985e\u5668\u3067\u306fOne-hot\u8868\u73fe\u3092\u4f7f\u3046\u306e\u3067\u51fa\u529by\u3092\u5909\u63db\u3059\u308b\u3002","95c4f4b7":"# \u30e2\u30c7\u30eb\n\u7573\u307f\u8fbc\u307fx2\u3001\u6700\u5927\u30d7\u30fc\u30ea\u30f3\u30b0\u3001\u30c9\u30ed\u30c3\u30d7\u30a2\u30a6\u30c8\u30922\u30d6\u30ed\u30c3\u30af\u3001\u5e73\u6ed1\u5316\u3001\u5168\u7d50\u5408","7473213b":"# \u8a13\u7df4\u30c7\u30fc\u30bf"}}