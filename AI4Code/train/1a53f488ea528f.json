{"cell_type":{"0217b5c9":"code","1e88872e":"code","d9da9485":"code","0b5dc444":"code","e1774c48":"code","6e60a807":"code","da552649":"code","24ebf546":"code","2a291288":"code","3d803e19":"code","a142a8eb":"code","b9d77fc9":"code","107595b4":"code","0400e917":"code","c90e283b":"code","4d3ae06e":"code","d9c906d8":"code","bfe2d741":"code","5c5635ff":"code","02bfaf15":"code","2fb39812":"code","4eba8284":"code","dfdf0fcc":"code","6df38457":"code","6278965e":"code","4c4783b0":"code","01fd4c08":"markdown","5083e87f":"markdown","444e9e78":"markdown","bee1cfe1":"markdown","5ded01b6":"markdown","a3f6231b":"markdown","9168908e":"markdown","bc5c4c69":"markdown","bf01a0f3":"markdown","503f8fff":"markdown","fd9c7cd6":"markdown","d7930aca":"markdown","ca7f5440":"markdown","afac5d81":"markdown","e780688d":"markdown","059c7fe8":"markdown","731acc2a":"markdown","21ef5f51":"markdown","35057155":"markdown","a3de8d2a":"markdown","0289c5a1":"markdown","b68eb7e7":"markdown","61826cc5":"markdown","6b639294":"markdown","eb642412":"markdown","b7ac4a7f":"markdown","ae5d193a":"markdown"},"source":{"0217b5c9":"import numpy as np # almost everything\nimport pandas as pd # working with tables\nimport seaborn as sns # plotting library\n%matplotlib inline\nfrom matplotlib import patches\nimport matplotlib.pyplot as plt # importing pyplot\nfrom scipy import stats # importing some stats that will be useful later on","1e88872e":"sns.set_style('whitegrid') # white grid background on plots\nsns.set_palette('colorblind', 10) # color palette for colorblinds with 10 colors\ncurrent_palette = sns.color_palette() # saving this palette in separate variable\nsns.set_context('poster') # setting notebook context","d9da9485":"data = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv', low_memory=False); # loading data\nUSA = data[data['Q3'] == 'United States of America'].copy() # copying only US ones","0b5dc444":"print('Number of US respondents: ', USA.shape[0])","e1774c48":"us_salary = USA['Q10'].str.replace(',','').str.replace('$','').str.replace('>','').str.strip(' ').str.split('-').apply(pd.Series).astype(np.float32) # getting numeric values of salary\nus_salary.columns = ['min', 'max'] # renaming columns\nus_salary['midrange'] = (us_salary['max'] + us_salary['min']) \/ 2 # calculating mid-range https:\/\/en.wikipedia.org\/wiki\/Mid-range\n\n# renaming columns for transparency\nus_salary_prediction = pd.get_dummies(USA[['Q4', 'Q6', 'Q7', 'Q8', 'Q15', 'Q23']].rename({'Q4': 'Education',\n                                                                                          'Q6': 'Company Size',\n                                                                                          'Q7': 'DS involvement',\n                                                                                          'Q8': 'ML use',\n                                                                                          'Q15': 'Overall DS experience',\n                                                                                          'Q23': 'Overall ML experience'}, axis='columns'), prefix_sep=': ')","6e60a807":"# calculating correlations that we will use in \"Salary\" section\ncorrs = pd.DataFrame()\nfor idx, col in enumerate(us_salary_prediction.columns):\n    t_min, p_min = stats.kendalltau(us_salary_prediction[col], us_salary['min'], nan_policy='omit')\n    t_max, p_max = stats.kendalltau(us_salary_prediction[col], us_salary['max'], nan_policy='omit')\n    t_mr, p_mr = stats.kendalltau(us_salary_prediction[col], us_salary['midrange'], nan_policy='omit')\n    corrs.loc[idx, 'Feature'] = col\n    corrs.loc[idx, 'Kendall'] = np.min([t_min, t_max, t_mr])\n    corrs.loc[idx, 'Pval'] = np.max([p_min, p_max, p_mr])\ncorrs.set_index('Feature', inplace=True)","da552649":"USA.loc[USA[(USA['Q1'] == '50-54') | (USA['Q1'] == '55-59') | (USA['Q1'] == '60-69') | (USA['Q1'] == '70+')].index, 'Q1'] = '>50' \nUSA.loc[USA[(USA['Q2'] == 'Prefer to self-describe')].index, 'Q2'] = 'Self-described' \nage_gender_plot_data = USA.drop(USA[(USA['Q2'] == 'Prefer not to say')].index, axis=0).groupby('Q1')['Q2'].value_counts().rename('Percentage').reset_index()\nage_gender_plot_data = age_gender_plot_data.rename({'Q1': 'Age', 'Q2': 'Gender'}, axis='columns').pivot(columns='Gender', index='Age', values='Percentage')\nage_gender_plot_data.plot(kind='barh', stacked=True, title='Age-Gender', figsize=(20,12));","24ebf546":"ed_plot_data = USA['Q4'].value_counts(normalize=True).rename('Percentage').reset_index().rename({'index': 'Education'}, axis='columns')\ned_plot_data['Education'] = ed_plot_data['Education'].map({'Master\u2019s degree': 'Master', \n                                                           'Bachelor\u2019s degree': 'Bachelor', \n                                                           'Doctoral degree': 'Doctor', \n                                                           'Some college\/university study without earning a bachelor\u2019s degree': 'Audition',\n                                                           'No formal education past high school': 'High School',\n                                                           'I prefer not to answer': 'Other',\n                                                           'Professional degree': 'Professional'})\ned_plot_data.drop(ed_plot_data[ed_plot_data['Education'] == 'Other'].index, axis=0, inplace=True)\ned_order = ['High School', 'Professional', 'Audition', 'Bachelor', 'Master', 'Doctor']\ned_plot_data.set_index('Education').loc[ed_order].plot(kind='bar', figsize=(16,12), legend=False, title='Percentage of people with different degrees');","2a291288":"USA.loc[USA[(USA['Q7'] == '0') | (USA['Q7'] == '1-2') | (USA['Q7'] == '3-4')].index, 'Q7'] = '<5'\nUSA.loc[USA[(USA['Q7'] == '5-9') | (USA['Q7'] == '10-14') | (USA['Q7'] == '15-19')].index, 'Q7'] = '5-20'\nUSA.loc[USA[(USA['Q7'] == '20+')].index, 'Q7'] = '>20' \nsize_order = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees', '> 10,000 employees']\n\ncompanies_plot_data = USA.groupby('Q6')['Q7'].value_counts().rename('Count').reset_index()\ncompanies_plot_data = companies_plot_data.rename({'Q6': 'Company size', 'Q7': 'DS involvement'}, axis='columns').pivot(columns='DS involvement', index='Company size', values='Count')\ncompanies_plot_data = companies_plot_data.loc[size_order]\n\ncompanies_plot_data[['<5', '5-20', '>20']].plot(kind='barh', stacked=True, figsize=(16,12), title='Number of data scientists in companies');","3d803e19":"companies_plot_data_norm = USA.groupby('Q6')['Q7'].value_counts(normalize=True).rename('Percentage').reset_index()\ncompanies_plot_data_norm = companies_plot_data_norm.rename({'Q6': 'Company size', 'Q7': 'DS involvement'}, axis='columns').pivot(columns='DS involvement', index='Company size', values='Percentage')\ncompanies_plot_data_norm = companies_plot_data_norm.loc[size_order]\n\ncompanies_plot_data_norm[['<5', '5-20', '>20']].plot(kind='barh', stacked=True, figsize=(16,12), title='Number of data scientists in companies (normalized)');","a142a8eb":"USA.loc[USA[(USA['Q8'] == 'No (we do not use ML methods)')].index, 'Q8'] = 'None'\nUSA.loc[USA[(USA['Q8'] == 'We use ML methods for generating insights (but do not put working models into production)') | (USA['Q8'] == 'We are exploring ML methods (and may one day put a model into production)')].index, 'Q8'] = 'Low'\nUSA.loc[USA[(USA['Q8'] == 'We recently started using ML methods (i.e., models in production for less than 2 years)') | (USA['Q8'] == 'We have well established ML methods (i.e., models in production for more than 2 years)')].index, 'Q8'] = 'High' \n\nds_ml_companies_plot_data = USA.drop(USA[USA['Q8'] == 'I do not know'].index, axis=0).groupby(['Q6', 'Q8'])['Q7'].value_counts().rename('Count').reset_index().rename({'Q6': 'Company size', 'Q7': 'DS involvement', 'Q8': 'ML use'}, axis='columns')\n\nds_less_5 = ds_ml_companies_plot_data[ds_ml_companies_plot_data['DS involvement'] == '<5'].pivot(columns='ML use', index='Company size', values='Count')\nds_less_5 = ds_less_5.loc[size_order].fillna(0)\n\nds_from_5_to_20 = ds_ml_companies_plot_data[ds_ml_companies_plot_data['DS involvement'] == '5-20'].pivot(columns='ML use', index='Company size', values='Count')\nds_from_5_to_20 = ds_from_5_to_20.loc[size_order].fillna(0)\n\nds_more_20 = ds_ml_companies_plot_data[ds_ml_companies_plot_data['DS involvement'] == '>20'].pivot(columns='ML use', index='Company size', values='Count')\nds_more_20 = ds_more_20.loc[size_order].fillna(0)\n\nds_less_5_norm = (ds_less_5 \/ ds_less_5.sum(axis=1).values.reshape(5,1))\nds_more_20_norm = (ds_more_20 \/ ds_more_20.sum(axis=1).values.reshape(5,1))\nds_from_5_to_20_norm = (ds_from_5_to_20 \/ ds_from_5_to_20.sum(axis=1).values.reshape(5,1))","b9d77fc9":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Normalized plot of company sizes with different number of data scientists and ML methods usage')\n\nds_less_5_norm.plot(kind='barh', stacked=True, width=0.2, position=1.5, ax=ax, legend=False, hatch='\/\/\/');\nds_more_20_norm.plot(kind='barh', stacked=True, width=0.2, position=-0.5, ax=ax, legend=False);\nds_from_5_to_20_norm.plot(kind='barh', stacked=True, width=0.2, position=0.5, ax=ax, legend=False, hatch='...');\n\nq8_hatch_legend = plt.legend([patches.Patch(hatch='\/\/\/'), patches.Patch(hatch='...'), patches.Patch()], \n                             ['Less than 5 DS', 'From 5 to 20 DS', 'More than 20 DS'], \n                             loc='lower right', bbox_to_anchor=(1.3, 0), borderaxespad=0.)\n\nq8_color_legend = plt.legend([patches.Patch(facecolor=current_palette[0]), patches.Patch(facecolor=current_palette[1]), patches.Patch(facecolor=current_palette[2])], \n                             ['High ML use', 'Low ML use', 'No ML use'],\n                             loc='upper right', bbox_to_anchor=(1.245, 1), borderaxespad=0.)\n\nax = plt.gca().add_artist(q8_hatch_legend)","107595b4":"q9_rename_dict = {'Q9_Part_1': 'Analyze and understand data to influence product or business decisions',\n                  'Q9_Part_2': 'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data',\n                  'Q9_Part_3': 'Build prototypes to explore applying machine learning to new areas',\n                  'Q9_Part_4': 'Build and\/or run a machine learning service that operationally improves my product or workflows',\n                  'Q9_Part_5': 'Experimentation and iteration to improve existing ML models'}\n\nq9_size_plot = USA[['Q6', 'Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4', 'Q9_Part_5']].groupby('Q6').count().rename(q9_rename_dict, axis='columns')\nq9_size_plot = q9_size_plot.loc[size_order].T\nq9_size_plot_norm = q9_size_plot \/ q9_size_plot.sum(axis=0)\n\nq9_size_plot_norm.plot(kind='pie', subplots=True, figsize=(32,6), legend=False, labels=None, autopct='%.1f', title='Pie charts for comapy sizes vs their ML usage', layout=(1,5));\n\nq9_legend = plt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(6)], \n                       [q9_rename_dict['Q9_Part_1'], q9_rename_dict['Q9_Part_2'], q9_rename_dict['Q9_Part_3'], \n                        q9_rename_dict['Q9_Part_4'], q9_rename_dict['Q9_Part_5']], bbox_to_anchor=(1, -1), loc='lower right', borderaxespad=0.)\n\nplt.gca().add_artist(q9_legend);","0400e917":"mr_male_us_salary = us_salary[USA.Q2 == 'Male']['midrange']\nmr_female_us_salary = us_salary[USA.Q2 == 'Female']['midrange']\nmr_sd_us_salary = us_salary[USA.Q2 == 'Self-described']['midrange']","c90e283b":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Midrange salary KDE for males and females');\n\nmale_mode = mr_male_us_salary.mode()[0]\nmale_mean = mr_male_us_salary.mean()\nmale_median = mr_male_us_salary.median()\nmr_male_us_salary.rename('Male midrange salary', inplace=True).plot.kde(ax=ax, bw_method='silverman');\nplt.axvline(male_mean, color='r', linestyle='dotted', lw=3, label='Male salary mean')\nplt.axvline(male_median, color='r', linestyle='dashed', lw=3, label='Male salary median')\n\nfemale_mode = mr_female_us_salary.mode()[0]\nfemale_mean = mr_female_us_salary.mean()\nfemale_median = mr_female_us_salary.median()\nmr_female_us_salary.rename('Female midrange salary', inplace=True).plot.kde(ax=ax, bw_method='silverman');\nplt.axvline(female_mean, color='k', linestyle='dotted', lw=3, label='Female salary mean')\nplt.axvline(female_median, color='k', linestyle='dashed', lw=3, label='Female salary median')\n\nplt.legend();","4d3ae06e":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Midrange salary KDE for self-described gender');\n\nsd_mode = mr_sd_us_salary.mode()[0]\nsd_mean = mr_sd_us_salary.mean()\nsd_median = mr_sd_us_salary.median()\nmr_sd_us_salary.rename('Self-described midrange salary', inplace=True).plot.kde(ax=ax, bw_method='silverman');\nplt.axvline(sd_mean, color='y', linestyle='dotted', lw=2, label='Salary mean')\nplt.axvline(sd_median, color='y', linestyle='dashed', lw=2, label='Salary median')\n\nplt.legend();","d9c906d8":"corrs[(corrs['Pval'] < 0.01) & (corrs['Kendall'] > 0)]['Kendall'].sort_values().plot(kind='barh', title='Positive Kendall Tau correlation (p < 0.01)', figsize=(16,12));","bfe2d741":"corrs[(corrs['Pval'] < 0.01) & (corrs['Kendall'] < 0)]['Kendall'].sort_values().plot(kind='barh', title='Negative Kendall Tau correlation (p < 0.01)', figsize=(16,12));","5c5635ff":"loglogtime = np.log(np.log(USA['Time from Start to Finish (seconds)'].astype(np.int32)))\nq1 = np.percentile(loglogtime, 25)\nq3 = np.percentile(loglogtime, 75)\n\nfast = loglogtime[loglogtime < q1].index\nslow = loglogtime[loglogtime > q3].index\n\nage_order = ['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '>50']\n\nprint('Median duration for slow respondents is {} min'.format(int(np.round(USA.loc[slow]['Time from Start to Finish (seconds)'].astype(np.int32).median() \/ 60))))\nprint('Median duration for quick respondents is {} min'.format(int(np.round(USA.loc[fast]['Time from Start to Finish (seconds)'].astype(np.int32).median() \/ 60))))\nprint('Number of respondents in each group is {}'.format(int(USA.loc[fast].shape[0])))","02bfaf15":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Age comparison between slow and quick respondents')\nUSA.loc[slow]['Q1'].value_counts(normalize=True).loc[age_order].plot(kind='bar', ax=ax, color=current_palette[0], alpha=0.75);\nUSA.loc[fast]['Q1'].value_counts(normalize=True).loc[age_order].plot(kind='bar', ax=ax, color=current_palette[1], alpha=0.75);\nplt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(2)], ['Slow respondents', 'Quick respondents'], loc='upper center');","2fb39812":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Gender comparison between slow and quick respondents')\nUSA.loc[slow]['Q2'].value_counts(normalize=True).plot(kind='bar', ax=ax, color=current_palette[0], alpha=0.75);\nUSA.loc[fast]['Q2'].value_counts(normalize=True).plot(kind='bar', ax=ax, color=current_palette[1], alpha=0.75);\nplt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(2)], ['Slow respondents', 'Quick respondents'], loc='upper center');","4eba8284":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Degree comparison between slow and quick respondents')\nUSA.loc[slow]['Q4'].map({'Master\u2019s degree': 'Master', \n                         'Bachelor\u2019s degree': 'Bachelor', \n                         'Doctoral degree': 'Doctor', \n                         'Some college\/university study without earning a bachelor\u2019s degree': 'Audition',\n                         'No formal education past high school': 'High School',\n                         'I prefer not to answer': 'Other',\n                         'Professional degree': 'Professional'}).value_counts(normalize=True).loc[ed_order].plot(kind='bar', ax=ax, color=current_palette[0], alpha=0.75);\nUSA.loc[fast]['Q4'].map({'Master\u2019s degree': 'Master', \n                         'Bachelor\u2019s degree': 'Bachelor', \n                         'Doctoral degree': 'Doctor', \n                         'Some college\/university study without earning a bachelor\u2019s degree': 'Audition',\n                         'No formal education past high school': 'High School',\n                         'I prefer not to answer': 'Other',\n                         'Professional degree': 'Professional'}).value_counts(normalize=True).loc[ed_order].plot(kind='bar', ax=ax, color=current_palette[1], alpha=0.75);\nplt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(2)], ['Slow respondents', 'Quick respondents'], loc='upper center');","dfdf0fcc":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Company size comparison between slow and quick respondents')\nUSA.loc[slow]['Q6'].value_counts(normalize=True).loc[size_order].plot(kind='bar', ax=ax, color=current_palette[0], alpha=0.75);\nUSA.loc[fast]['Q6'].value_counts(normalize=True).loc[size_order].plot(kind='bar', ax=ax, color=current_palette[1], alpha=0.75);\nplt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(2)], ['Slow respondents', 'Quick respondents'], loc='upper center');","6df38457":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Number of DS in company comparison between slow and quick respondents')\nUSA.loc[slow]['Q7'].value_counts(normalize=True).loc[['<5','5-20','>20']].plot(kind='bar', ax=ax, color=current_palette[0], alpha=0.75);\nUSA.loc[fast]['Q7'].value_counts(normalize=True).loc[['<5','5-20','>20']].plot(kind='bar', ax=ax, color=current_palette[1], alpha=0.75);\nplt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(2)], ['Slow respondents', 'Quick respondents'], loc='upper center');","6278965e":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('ML use company comparison between slow and quick respondents')\nUSA.loc[slow]['Q8'].value_counts(normalize=True).plot(kind='bar', ax=ax, color=current_palette[0], alpha=0.75);\nUSA.loc[fast]['Q8'].value_counts(normalize=True).plot(kind='bar', ax=ax, color=current_palette[1], alpha=0.75);\nplt.legend([patches.Patch(facecolor=current_palette[color]) for color in range(2)], ['Slow respondents', 'Quick respondents'], loc='upper center');","4c4783b0":"fig, ax = plt.subplots(figsize=(16,12));\nplt.title('Salary comparison between slow and quick respondents')\nus_salary.loc[slow]['midrange'].rename('Slow respondents', inplace=True).plot.kde(ax=ax, bw_method='silverman');\nus_salary.loc[fast]['midrange'].rename('Quick respondents', inplace=True).plot.kde(ax=ax, bw_method='silverman');\n\nslow_mode = us_salary.loc[slow]['midrange'].mode()[0]\nslow_mean = us_salary.loc[slow]['midrange'].mean()\nslow_median = us_salary.loc[slow]['midrange'].median()\n\nfast_mode = us_salary.loc[fast]['midrange'].mode()[0]\nfast_mean = us_salary.loc[fast]['midrange'].mean()\nfast_median = us_salary.loc[fast]['midrange'].median()\n\nplt.axvline(slow_mean, color='b', linestyle='dotted', lw=3, label='Slow respondents salary mean')\nplt.axvline(slow_median, color='b', linestyle='dashed', lw=3, label='Slow respondents salary median')\nplt.axvline(fast_mean, color='r', linestyle='dotted', lw=3, label='Quick respondents salary mean')\nplt.axvline(fast_median, color='r', linestyle='dashed', lw=3, label='Quick respondents salary median')\n\nplt.gca().add_artist(plt.legend(loc='upper right'));","01fd4c08":"*Dropping all not answered people*","5083e87f":"### Thoughts\n\n* I can't spot a difference between company size and it's ML\/DS utilizing strategy, don't think that there is one;\n\n* Small companies could change their approach to ML\/DS to differentiate themselves.\n***","444e9e78":"### Thoughts\n\n* Most kagglers have a master's degree;\n\n* It's safe to assume that some of them are writing their PhD thesis to get to the next step. They also want to get real experience in solving real problems and get some honor and respect along the way. And some cash of course. Some of them are happy with their degree and kaggle as a hobby or a side job.\n* * *","bee1cfe1":"Now we will try to find some predicatives for a higher salary\n\nFor this one education (Q4), company size (Q6), number of DS working in company (Q7), intensity of ML use in company (Q8), overall data analysis experience (Q15) and overall ML coding experience (Q23) were used to calculate correlation with annual salary using Kendall tau with p-value. In order to do this annual salary was divided into minimal, maximal and midrange salary. For the final tau minimal value of 3 were taken, while for the p-value maximum from 3 were taken, after that all features with low p-value (0.01) were eliminated.\nIn other words, we will take worst-case scenario values for every predictor and use a very harsh threshold to separate useful ones.","5ded01b6":"# Companies","a3f6231b":"*Reducing the number of categories in Question 7: \"Approximately how many individuals are responsible for data science workloads at your place of business?\" from 7 to 3 for better visual representation*","9168908e":"# Slow and steady","bc5c4c69":"# US Kaggle Survey EDA","bf01a0f3":"Today we are going to extract some interesting (and not so much) info. I decided to look at the US since it is the most interesting job market and has a lot of respondents.","503f8fff":"# Education","fd9c7cd6":"### Thoughts\n\n* Big companies are in the lead;\n\n* Big companies use more DS and ML specialists all things consider (even that they *are bigger*).","d7930aca":"### Thoughts\n\n* There is a bunch of small companies with high ML use, which means ML is their main business;\n\n* \"Medium\" sized companies aren't good friends with machine learning techniques;\n\n* Obvious trend: more DS -> higher ML use which somewhy got violated in small companies.","ca7f5440":"We will compare respondents that spent more than time than the 3rd quartile (slow) and ones that spent less time than the 1st quartile (fast).","afac5d81":"### Thoughts\n\n* Most of the stuff right here is obvious: bigger companies, better education, higher ML methods use in workflow, more experience in data science and ML;\n\n* Not getting M and D degree, having very little experience (<2 years of ML and <5 years of DS) and working in a very small company with undeveloped ML usage strategy are all signs of a bad paycheck.\n***","e780688d":"For a tad bit more of speed analysis [visit this kernel](https:\/\/www.kaggle.com\/altprof\/slow-and-steady)","059c7fe8":"# Age & Gender","731acc2a":"We will use mid-range of every bin to build histogram and then compare different central tendencies of different genders.","21ef5f51":"# Salary","35057155":"| Central tendency | Absolute difference |\n|---|\n| Mean | 22786 |\n| Median | 17500 |\n| Mode | 0 |\n\n***","a3de8d2a":"![](https:\/\/assets.pokemon.com\/assets\/cms2\/img\/pokedex\/full\/079.png)","0289c5a1":"### What do companies do?","b68eb7e7":"*Dropping all the secretive people*","61826cc5":"*Reducing the number of categories in Question 8: \"Does your current employer incorporate machine learning methods into their business?\" from 6 to 3 for better visual representation*\n\n| Original category | New category |\n|---|\n| I do not know | Dropped\n| No (we do not use ML methods) | None\n| We use ML methods for generating insights (but do not put working models into production) | Low\n| We are exploring ML methods (and may one day put a model into production) | Low\n| We recently started using ML methods (i.e., models in production for less than 2 years) | High\n| We have well established ML methods (i.e., models in production for more than 2 years) | High","6b639294":"| Central tendency | Absolute difference |\n|---|\n| Mean | 27158 |\n| Median | 17500 |\n| Mode | 62500 |","eb642412":"### Thoughts\n\n* There is a difference between the male and female median and mean salaries judging by the survey;\n\n* Sadly, there are only 13 respondents, so it is not representative by any stretch of the imagination.","b7ac4a7f":"### Thoughts\n\n* Most of the Kaggle users from the US falling into 25-35 y.o. category. There are also a lot of people over 50;\n\n* I think one of the reasons behind this is that the US has a very strong background in statistics. It is used everywhere: in economics, sociology, medicine, political science, so there is a demand for people who can correctly collect useful data and analyze it. If you add immigration factor on top, the picture above will make more sense;\n\n* Gender distribution is not uniform. From the data it is impossible to say if it's skewed by discrimination or under-representation or by other factors (like not being interested in competing in ML field or taking surveys);\n\n* Gender and age are not connected at all in this case: at every age group gender ratios were roughly the same.\n* * *","ae5d193a":"### A bit deeper"}}