{"cell_type":{"0e79ec0d":"code","ca86507d":"code","c2b36532":"code","af58fb0c":"code","3e70d85f":"code","17c0939b":"code","92e5fdd3":"code","9530eb62":"code","35560d06":"code","38cdaf11":"code","e9878934":"markdown","42360248":"markdown","8ca539c0":"markdown","43886cb1":"markdown","226caf8f":"markdown","8c3f65f1":"markdown","3a593198":"markdown","81bba58e":"markdown","145e1a54":"markdown","5378e610":"markdown"},"source":{"0e79ec0d":"import pandas as pd\nimport numpy as np\nimport sklearn as sk\nimport matplotlib.pyplot as plt\nimport seaborn as sb","ca86507d":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.stats import rankdata\n\njr = pd.read_csv(\"..\/input\/jigsaw-regression-based-data\/train_data_version2.csv\")\njr.shape\ndf = jr[['text', 'y']]\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=1, ngram_range=(2, 5) )\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 2)\n\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\ndf_test = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ntest=vec.transform(df_test['text'])\njr_preds=model1.predict(test)\ndf_test['score1']=rankdata( jr_preds, method='ordinal') \nrud_df = pd.read_csv(\"..\/input\/ruddit-jigsaw-dataset\/Dataset\/ruddit_with_text.csv\")\n#print(f\"rud_df:{rud_df.shape}\")\nrud_df['y'] = rud_df[\"offensiveness_score\"] \ndf = rud_df[['txt', 'y']].rename(columns={'txt': 'text'})\nvec = TfidfVectorizer(analyzer='char_wb', max_df=0.7, min_df=3, ngram_range=(3, 4) )\nX = vec.fit_transform(df['text'])\nz = df[\"y\"].values\ny=np.around ( z ,decimals = 1)\nmodel1=Ridge(alpha=0.5)\nmodel1.fit(X, y)\ntest=vec.transform(df_test['text'])\nrud_preds=model1.predict(test)\ndf_test['score2']=rankdata( rud_preds, method='ordinal')\ndf_test['score']=df_test['score1']+df_test['score2']\ndf_test['score']=rankdata( df_test['score'], method='ordinal')\ndf_test[['comment_id', 'score']].to_csv(\"submission1.csv\", index=False)","c2b36532":"import numpy as np\nimport pandas as pd\nimport nltk\nimport re\nfrom bs4 import BeautifulSoup\nfrom tqdm.auto import tqdm\n\nTRAIN_DATA_PATH = \"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\"\nVALID_DATA_PATH = \"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\"\nTEST_DATA_PATH = \"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\"\n\ndf_train2 = pd.read_csv(TRAIN_DATA_PATH)\ndf_valid2 = pd.read_csv(VALID_DATA_PATH)\ndf_test2 = pd.read_csv(TEST_DATA_PATH)\ncat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    df_train2[category] = df_train2[category] * cat_mtpl[category]\n\ndf_train2['score'] = df_train2.loc[:, 'toxic':'identity_hate'].mean(axis=1)\n\ndf_train2['y'] = df_train2['score']\n\nmin_len = (df_train2['y'] > 0).sum()  # len of toxic comments\ndf_y0_undersample = df_train2[df_train2['y'] == 0].sample(n=min_len, random_state=41)  # take non toxic comments\ndf_train_new = pd.concat([df_train2[df_train2['y'] > 0], df_y0_undersample])  # make new df\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)\n\nraw_tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\nraw_tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)\nfrom datasets import Dataset\n\ndataset = Dataset.from_pandas(df_train_new[['comment_text']])\n\ndef get_training_corpus():\n    for i in range(0, len(dataset), 1000):\n        yield dataset[i : i + 1000][\"comment_text\"]\n\nraw_tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)\n\nfrom transformers import PreTrainedTokenizerFast\n\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge\n\ndef dummy_fun(doc):\n    return doc\n\nlabels = df_train_new['y']\ncomments = df_train_new['comment_text']\ntokenized_comments = tokenizer(comments.to_list())['input_ids']\n\nvectorizer = TfidfVectorizer(\n    analyzer = 'word',\n    tokenizer = dummy_fun,\n    preprocessor = dummy_fun,\n    token_pattern = None)\n\ncomments_tr = vectorizer.fit_transform(tokenized_comments)\n\nregressor = Ridge(random_state=42, alpha=0.8)\nregressor.fit(comments_tr, labels)\n\nless_toxic_comments = df_valid2['less_toxic']\nmore_toxic_comments = df_valid2['more_toxic']\n\nless_toxic_comments = tokenizer(less_toxic_comments.to_list())['input_ids']\nmore_toxic_comments = tokenizer(more_toxic_comments.to_list())['input_ids']\n\nless_toxic = vectorizer.transform(less_toxic_comments)\nmore_toxic = vectorizer.transform(more_toxic_comments)\n\n# make predictions\ny_pred_less = regressor.predict(less_toxic)\ny_pred_more = regressor.predict(more_toxic)\n\nprint(f'val : {(y_pred_less < y_pred_more).mean()}')\ntexts = df_test2['text']\ntexts = tokenizer(texts.to_list())['input_ids']\ntexts = vectorizer.transform(texts)\n\ndf_test2['prediction'] = regressor.predict(texts)\ndf_test2 = df_test2[['comment_id','prediction']]\n\ndf_test2['score'] = df_test2['prediction']\ndf_test2 = df_test2[['comment_id','score']]\n\ndf_test2.to_csv('.\/submission2.csv', index=False)","af58fb0c":"import pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nfrom bs4 import BeautifulSoup\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nimport re \nimport scipy\nfrom scipy import sparse\n\nfrom IPython.display import display\nfrom pprint import pprint\nfrom matplotlib import pyplot as plt \n\nimport time\nimport scipy.optimize as optimize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.options.display.max_colwidth=300\npd.options.display.max_columns = 100\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.linear_model import Ridge, Lasso, BayesianRidge\nfrom sklearn.svm import SVR\n\ndf_train = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\ndf_sub = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\n\ncat_mtpl = {'obscene': 0.16, 'toxic': 0.32, 'threat': 1.5, \n            'insult': 0.64, 'severe_toxic': 1.5, 'identity_hate': 1.5}\n\nfor category in cat_mtpl:\n    df_train[category] = df_train[category] * cat_mtpl[category]\n\ndf_train['score'] = df_train.loc[:, 'toxic':'identity_hate'].sum(axis=1)\n\ndf_train['y'] = df_train['score']\n\nmin_len = (df_train['y'] > 0).sum()  # len of toxic comments\ndf_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=201)  # take non toxic comments\ndf_train_new = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\ndf_train = df_train.rename(columns={'comment_text':'text'})\n\ndef text_cleaning(text):\n    '''\n    Cleans text into a basic form for NLP. Operations include the following:-\n    1. Remove special charecters like &, #, etc\n    2. Removes extra spaces\n    3. Removes embedded URL links\n    4. Removes HTML tags\n    5. Removes emojis\n    \n    text - Text piece to be cleaned.\n    '''\n    template = re.compile(r'https?:\/\/\\S+|www\\.\\S+') #Removes website links\n    text = template.sub(r'', text)\n    \n    soup = BeautifulSoup(text, 'lxml') #Removes HTML tags\n    only_text = soup.get_text()\n    text = only_text\n    \n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    \n    text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n    text = re.sub(' +', ' ', text) #Remove Extra Spaces\n    text = text.strip() # remove spaces at the beginning and at the end of string\n\n    return text\n\ntqdm.pandas()\ndf_train['text'] = df_train['text'].progress_apply(text_cleaning)\ndf = df_train.copy()\ndf['y'].value_counts(normalize=True)\nmin_len = (df['y'] >= 0.1).sum()\ndf_y0_undersample = df[df['y'] == 0].sample(n=min_len * 2, random_state=402)\ndf = pd.concat([df[df['y'] >= 0.1], df_y0_undersample])\nvec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))\nX = vec.fit_transform(df['text'])\nmodel = Ridge(alpha=0.5)\nmodel.fit(X, df['y'])\nl_model = Ridge(alpha=1.)\nl_model.fit(X, df['y'])\ns_model = Ridge(alpha=2.)\ns_model.fit(X, df['y'])\ndf_val = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ntqdm.pandas()\ndf_val['less_toxic'] = df_val['less_toxic'].progress_apply(text_cleaning)\ndf_val['more_toxic'] = df_val['more_toxic'].progress_apply(text_cleaning)\nX_less_toxic = vec.transform(df_val['less_toxic'])\nX_more_toxic = vec.transform(df_val['more_toxic'])\np1 = model.predict(X_less_toxic)\np2 = model.predict(X_more_toxic)\n# Validation Accuracy\nprint(f'val : {(p1 < p2).mean()}')\ndf_sub = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ntqdm.pandas()\ndf_sub['text'] = df_sub['text'].progress_apply(text_cleaning)\nX_test = vec.transform(df_sub['text'])\np3 = model.predict(X_test)\np4 = l_model.predict(X_test)\np5 = s_model.predict(X_test)\ndf_sub['score'] = (p3 + p4 + p5) \/ 3.\ndf_sub['score'] = df_sub['score']\ndf_sub[['comment_id', 'score']].to_csv(\"submission3.csv\", index=False)","3e70d85f":"from sklearn.linear_model import LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntest_df = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\nvalid_df = pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ntrain_df=pd.read_csv(\"..\/input\/ruddit-jigsaw-dataset\/Dataset\/ruddit_with_text.csv\")\n\ntrain = train_df[[\"txt\", \"offensiveness_score\"]]\n\ntfvec = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (3,5))\ntfv = tfvec.fit_transform(train[\"txt\"])\n\nX=tfv\nY=train['offensiveness_score']\nreg = LinearRegression().fit(X,Y)\nprint(reg.score(X,Y))\ntfv_comments = tfvec.transform(test_df[\"text\"])\npred1 = reg.predict(tfv_comments)\n\ndata2 = pd.read_csv(\"..\/input\/jigsaw-regression-based-data\/train_data_version2.csv\")\ndf2 = data2[['text', 'y']]\n\nvec = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 5))\nX = vec.fit_transform(df2['text'])\nw = df2[\"y\"].values\ny = np.around (w ,decimals = 2)\n\nfrom sklearn.linear_model import Ridge\nreg2=Ridge(alpha=0.3)\nreg2.fit(X, y)\nreg2.score(X,y)\n\ntest=vec.transform(test_df['text'])\npred2=reg2.predict(test)\n\nsub = pd.DataFrame()\nsub[\"comment_id\"] = test_df[\"comment_id\"]\nsub[\"score\"] = pred1 + pred2\nsub.to_csv('submission4.csv',index=False)","17c0939b":"data = pd.read_csv(\".\/submission1.csv\",index_col=\"comment_id\")\ndata[\"score1\"] = data[\"score\"]\n\ndata[\"score2\"] = pd.read_csv(\".\/submission2.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score2\"] = rankdata( data[\"score2\"], method='ordinal')\n\ndata[\"score3\"] = pd.read_csv(\".\/submission3.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score3\"] = rankdata( data[\"score3\"], method='ordinal')\n\ndata[\"score4\"] = pd.read_csv(\".\/submission4.csv\",index_col=\"comment_id\")[\"score\"]\ndata[\"score4\"] = rankdata( data[\"score4\"], method='ordinal')\n\ndata[\"score\"] = .66*data[\"score1\"] + .66*data[\"score2\"] +  data[\"score4\"]*1.22","92e5fdd3":"data[\"score\"] = rankdata( data[\"score\"], method='ordinal')\ndata.head()","9530eb62":"df_test = data\nfor i in range(0, 500):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.35\nfor i in range(801, 1200):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.45\nfor i in range(1701, 2300):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.81\nfor i in range(2501, 2980):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.85    \nfor i in range(3001, 4000):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.42    \nfor i in range(4001, 4500):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.45   \nfor i in range(4501, 4940):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.86\nfor i in range(5501, 5980):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 0.83\nfor i in range(6001, 6500):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.45\nfor i in range(7001, 7536):\n    df_test['score'].iloc[i] = df_test['score'].iloc[i] * 1.42 ","35560d06":"df_test[\"score\"] = rankdata( df_test[\"score\"], method='ordinal')\ndf_test[\"score\"].to_csv('.\/submission.csv')","38cdaf11":"pd.read_csv(\".\/submission.csv\")","e9878934":"[Sub1 : 0.869](https:\/\/www.kaggle.com\/ayhampar\/very-simple-code-with-score-0-869\/notebook)","42360248":"Credit : [Tokenizer training + TFIDF + RIDGE [LB 0.860]](https:\/\/www.kaggle.com\/coldfir3\/tokenizer-training-tfidf-ridge-lb-0-860) by [Adriano Passos](https:\/\/www.kaggle.com\/coldfir3)","8ca539c0":"[Sub2 : 0.860](https:\/\/www.kaggle.com\/coldfir3\/tokenizer-training-tfidf-ridge-lb-0-860)","43886cb1":"for even more overfit :","226caf8f":"sub4\uff1a0.873[https:\/\/www.kaggle.com\/ahmetarifturkmen\/baseline-linear-regression](http:\/\/)","8c3f65f1":"Credit : [[RAPIDS] TFIDF_linear_model_ensemble](https:\/\/www.kaggle.com\/tenffe\/rapids-tfidf-linear-model-ensemble\/notebook) by [zhangxin](https:\/\/www.kaggle.com\/tenffe)","3a593198":"Credit : [\ud83d\udca5 Scaling for \u2728Jigsaw Ensemble \ud83d\udca5](https:\/\/www.kaggle.com\/chryzal\/scaling-for-jigsaw-ensemble) by [Chryzal](https:\/\/www.kaggle.com\/chryzal)\n\nI updated the weights, because I don't use them on a score but rather on a rank (from 0.892 to 0.896)","81bba58e":"**You can try to modify the parameters to get a better score\uff01\uff01\uff01**\n\ndata[\"score\"] = a1* data[\"score1\"] + a2* data[\"score2\"] + a3* data[\"score3\"]+ a4* data[\"score4\"]","145e1a54":"Credit : [very simple code with score 0.886](https:\/\/www.kaggle.com\/ayhampar\/very-simple-code-with-score-0-886?scriptVersionId=85850016) by [AYAHM BARISH](https:\/\/www.kaggle.com\/ayhampar)","5378e610":"[Sub3 : 0.858](https:\/\/www.kaggle.com\/tenffe\/rapids-tfidf-linear-model-ensemble\/notebook)"}}