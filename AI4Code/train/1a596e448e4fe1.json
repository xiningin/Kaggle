{"cell_type":{"c677e483":"code","ec6773bd":"code","c28df1a7":"code","2a69dc89":"code","72d0779e":"code","04ff5f29":"code","3a5fb676":"code","db63bc42":"code","19e252e7":"code","f269d461":"code","c5fd8d0b":"code","ddd79fe5":"code","9321db57":"code","9f133c0f":"code","72479973":"code","078bf1fd":"code","eb17e7f7":"code","b524a8da":"code","3fe9def9":"code","e49376cd":"code","da2539ff":"code","435cf82d":"code","46f51b3a":"code","66100252":"code","eb275ddb":"code","7aff4e50":"code","ae7c6d97":"code","a74f29b7":"code","c4ca0a06":"code","39acbc19":"code","903466e6":"code","16cf2c75":"code","cecd9b7c":"code","acfc9136":"code","c7909dd4":"code","ff8bb5ae":"code","167080ed":"code","ba173823":"code","933af628":"code","f280200f":"markdown","f4ca274c":"markdown","b21ad545":"markdown","1debe3b7":"markdown","04f2bad1":"markdown","afc357be":"markdown","06e620b3":"markdown","8a0861cb":"markdown","6366473c":"markdown","c9f32b43":"markdown","80be4589":"markdown","2f0beb84":"markdown","2655730f":"markdown","bf6b68fc":"markdown","08486fd6":"markdown","cee8b4db":"markdown","6fceb00f":"markdown","b901ee38":"markdown","cad9da64":"markdown","6202dacd":"markdown","781074b0":"markdown","93ddf19c":"markdown","9b8466ec":"markdown","23100ac4":"markdown"},"source":{"c677e483":"!pip install pmdarima","ec6773bd":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(16,8)})\nsns.set(font_scale=1.3)\nplt.style.use('fivethirtyeight')\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, RepeatVector, TimeDistributed\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport plotly\nimport plotly.graph_objs as go\nimport plotly.express as ex\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom pmdarima.arima import auto_arima\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math","c28df1a7":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","2a69dc89":"import os\nos.chdir('..\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/')\nlist = os.listdir()\nnumber_files = len(list)\nprint(number_files)","72d0779e":"import random\nfilenames = random.sample([x for x in os.listdir() if x.endswith('.txt') \n                           and os.path.getsize(os.path.join('',x)) > 0], 8)\nprint(filenames)","04ff5f29":"data = []\nfor filename in filenames:\n    df = pd.read_csv(os.path.join('',filename), sep=',')\n    label, _, _ = filename.split(sep='.')\n    df['Label'] = label\n    df['Date'] = pd.to_datetime(df['Date'])\n\n    data.append(df)","3a5fb676":"len(data)","db63bc42":"data[0].info()","19e252e7":"data[0].describe()","f269d461":"data[0] = data[0].sort_values('Date')\nplt.figure(figsize=(16,8))\nplt.plot(data[0]['Close'], label='Close Price history',color='b')\nplt.xlabel('Date',size=20)\nplt.ylabel('Stock Price',size=20)\nplt.title('Stock Price Over the Years',size=25);","c5fd8d0b":"data[1] = data[1].sort_values('Date')\nplt.figure(figsize=(16,8))\nplt.plot(data[1]['Close'], label='Close Price history',color='b')\nplt.xlabel('Date',size=20)\nplt.ylabel('Stock Price',size=20)\nplt.title('Stock Price Over the Years',size=25);","ddd79fe5":"# Normalizes the data\ndef to_dataset(data):\n    data = data.astype('float32')\n    #scaler = MinMaxScaler(feature_range=(0,1))\n    #return scaler.fit_transform(data)\n    return data\/255.\n\n# Data train and test\ndef train_test(data):\n    train_size = int(len(data) * 0.75)\n    train, test = data[0:train_size, :], data[train_size:len(data), :]\n    return train, test\n\n# Time windows - use 10 days to forecast the nest 10 days \ndef windows(sequence, step_in, step_out):\n    x, y = [], []\n    for i in range(len(sequence)):\n        end_i = i + step_in\n        out_i = end_i + step_out\n        if out_i > len(sequence):\n            break\n        seq_x, seq_y = sequence[i:end_i, :], sequence[end_i:out_i, :]\n        x.append(seq_x)\n        y.append(seq_y)\n    return np.array(x), np.array(y)\n\n# Model\ndef creat_model(step_in, step_out, features):\n    model = Sequential()\n    model.add(LSTM(50, activation='relu', input_shape=(step_in, features)))\n    model.add(RepeatVector(step_out))\n    model.add(LSTM(200, activation='relu', return_sequences=True))\n    model.add(TimeDistributed(Dense(features)))\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n    return model\n\n# Run all functions\ndef prepare_training(data, step_in, step_out):\n    data = to_dataset(data)\n    train, test = train_test(data)\n    x_train, x_test = windows(train, step_in, step_out)\n    y_train, y_test = windows(test, step_in, step_out)\n    features = 1\n    return x_train, x_test, y_train, y_test, features","9321db57":"step_in, step_out = 10, 10 \nepochs = 50 \nbatch_size = 32\n\nearly = EarlyStopping(monitor='val_loss',patience=5)\nreduce = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, mil_lr=0.001)","9f133c0f":"df = data[0]['Close'].values\ndf = df.reshape(-1, 1)","72479973":"## SPlit data into train and test\nx_train, y_train, x_test, y_test, feature = prepare_training(df, step_in, step_out)","078bf1fd":"model = creat_model(step_in, step_out, feature)","eb17e7f7":"history = model.fit(x_train, y_train, epochs=epochs, batch_size=50, verbose=1,\n         validation_data=(x_test, y_test), callbacks=[early,reduce])","b524a8da":"# # summarize history for metric\n# fig=go.Figure()\n# fig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n#                          y=history.history['loss'],\n#                          name=\"Training Loss\",\n#                          mode=\"markers+lines\",\n#                          marker=dict(color='green',size=4)))\n# fig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n#                          y=history.history['val_loss'],\n#                          name=\"Validation Loss\",\n#                          mode=\"markers+lines\",\n#                          marker=dict(color='red',size=4)))\n# fig.update_layout(title=\"Model Loss - Training and Validation\",\n#                   xaxis_title=\"Epochs\",\n#                   yaxis_title=\"MAE(Mean Absolute Error)\",\n#                   template=\"plotly_dark\"\n#                  )\n# fig.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('MSE')\nplt.legend(['Train','Test']);","3fe9def9":"# summarize history for metric\n# fig=go.Figure()\n# fig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n#                          y=history.history['mean_squared_error'],\n#                          name=\"Training MAE\",\n#                          mode=\"markers+lines\",\n#                          marker=dict(color='green',size=4)))\n# fig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n#                          y=history.history['val_mean_squared_error'],\n#                          name=\"Validation MAE\",\n#                          mode=\"markers+lines\",\n#                          marker=dict(color='red',size=4)))\n# fig.update_layout(title=\"Model Metric - Training and Validation\",\n#                   xaxis_title=\"Epochs\",\n#                   yaxis_title=\"MAE(Mean Absolute Error)\",\n#                   template=\"plotly_dark\"\n#                  )\n# fig.show()\n\nplt.plot(history.history['mean_squared_error'])\nplt.plot(history.history['val_mean_squared_error'])\nplt.xlabel('Epochs')\nplt.ylabel('MSE')\nplt.legend(['Train','Test']);","e49376cd":"pred = model.predict(x_test)","da2539ff":"## rescale the data\ny_act = x_test[0]*255.0\ny_pred = pred[0]*255.0","435cf82d":"y_act.reshape(1,10)[0]","46f51b3a":"y_pred","66100252":"# fig=go.Figure()\n# fig.add_trace(go.Scatter(x=[n for n in range(1,10)],\n#                          y=y_act.reshape(1,10)[0],\n#                          name=\"Test Actual\",\n#                          mode=\"markers+lines\",\n#                          marker=dict(color='green',size=4)))\n# fig.add_trace(go.Scatter(x=[n for n in range(1,10)],\n#                          y=y_pred.reshape(1,10)[0],\n#                          name=\"Test Predicted\",\n#                          mode=\"markers+lines\",\n#                          marker=dict(color='red',size=4)))\n# fig.update_layout(title=\"LSTM Model Prediction\",\n#                   xaxis_title=\"Values\",\n#                   yaxis_title=\"Days\",\n#                   template=\"plotly_dark\"\n#                  )\n# fig.show()\n\nplt.plot(y_act)\nplt.plot(y_pred)\nplt.legend(['Real Value','Predicted Value']);","eb275ddb":"## Check KDE plot for 1 dataset\ndata[0]['Close'].plot(kind='kde')","7aff4e50":"def adfuller_test(stocks):\n    result=adfuller(stocks)\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n\n# if result[1] <= 0.05:\n#     print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary\")\n# else:\n#     print(\"weak evidence against null hypothesis,indicating it is non-stationary \")","ae7c6d97":"adfuller_test(data[0]['Close'])","a74f29b7":"## Differencing the data\ndata[0]['Close First diff'] = data[0]['Close'] - data[0]['Close'].shift(1)\ndata[0]['Close Seasonal diff']=data[0]['Close']- data[0]['Close'].shift(12)\ndata[0].head()","c4ca0a06":"# Again testing if data is stationary\nadfuller_test(data[0]['Close Seasonal diff'].dropna())","39acbc19":"plt.figure(figsize=(16,8))\nplt.plot(data[0]['Close Seasonal diff'], label='Close Seasonal Diff.',color='r')\nplt.xlabel('Date',size=20)\nplt.ylabel('Stock Price',size=20)\nplt.title('Stock Price Over the Years',size=25);","903466e6":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(data[0]['Close'])\nplt.show()","16cf2c75":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nimport statsmodels.api as sm\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(data[0]['Close Seasonal diff'].dropna(),lags=40,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(data[0]['Close Seasonal diff'].dropna(),lags=40,ax=ax2)","cecd9b7c":"## removing trend element\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 6\ndf_log = np.log(data[0]['Close'])\nmoving_avg = df_log.rolling(12).mean()\nstd_dev = df_log.rolling(12).std()\nplt.legend(loc='best')\nplt.title('Moving Average')\nplt.plot(std_dev, color =\"black\", label = \"Standard Deviation\")\nplt.plot(moving_avg, color=\"red\", label = \"Mean\")\nplt.legend()\nplt.show()","acfc9136":"#split data into train and training set\ntrain_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):]\nplt.figure(figsize=(10,6))\nplt.grid(True)\nplt.xlabel('Dates')\nplt.ylabel('Closing Prices')\nplt.plot(df_log, 'green', label='Train data')\nplt.plot(test_data, 'blue', label='Test data')\nplt.legend()","c7909dd4":"model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\nprint(model_autoARIMA.summary())\nmodel_autoARIMA.plot_diagnostics(figsize=(15,8))\nplt.show()","ff8bb5ae":"model = ARIMA(train_data, order=(1,1,0))  \nfitted = model.fit(disp=-1)  \nprint(fitted.summary())","167080ed":"# Forecast\nfc, se, conf = fitted.forecast(43, alpha=0.05)  # 95% conf","ba173823":"# Make as pandas series\nfc_series = pd.Series(fc, index=test_data.index)\nlower_series = pd.Series(conf[:, 0], index=test_data.index)\nupper_series = pd.Series(conf[:, 1], index=test_data.index)\n# Plot\nplt.figure(figsize=(10,5), dpi=100)\nplt.plot(train_data, label='training data')\nplt.plot(test_data, color = 'blue', label='Actual Stock Price')\nplt.plot(fc_series, color = 'orange',label='Predicted Stock Price')\nplt.fill_between(lower_series.index, lower_series, upper_series, \n                 color='k', alpha=.10)\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()","933af628":"# report performance\nmse = mean_squared_error(test_data, fc)\nprint('MSE: '+str(mse))\nmae = mean_absolute_error(test_data, fc)\nprint('MAE: '+str(mae))\nrmse = math.sqrt(mean_squared_error(test_data, fc))\nprint('RMSE: '+str(rmse))\nmape = np.mean(np.abs(fc - test_data)\/np.abs(test_data))\nprint('MAPE: '+str(mape))","f280200f":"<h1 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: red;\">Performing Auto Arima&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","f4ca274c":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">ARIMA Model Training&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> \n\nA popular and widely used statistical method for time series forecasting is the ARIMA model. Exponential smoothing and ARIMA models are the two most widely used approaches to time series forecasting and provide complementary approaches to the problem. While exponential smoothing models are based on a description of the trend and seasonality in the data, ARIMA models aim to describe the autocorrelations in the data.\n\n**`Stationarity`**\n\nA stationary time series data is one whose properties do not depend on the time, That is why time series with trends, or with seasonality, are not stationary. the trend and seasonality will affect the value of the time series at different times, On the other hand for stationarity it does not matter when you observe it, it should look much the same at any point in time. In general, a stationary time series will have no predictable patterns in the long-term.\n\nARIMA is an acronym that stands for Auto-Regressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data.\n\nIn this tutorial, We will talk about how to develop an ARIMA model for time series forecasting in Python.\n\nAn ARIMA model is a class of statistical models for analyzing and forecasting time series data. It is really simplified in terms of using it, Yet this model is really powerful.\n\nARIMA stands for Auto-Regressive Integrated Moving Average.\n\nThe parameters of the ARIMA model are defined as follows:\n\np: The number of lag observations included in the model, also called the lag order.<br>\nd: The number of times that the raw observations are differenced, also called the degree of difference.<br>\nq: The size of the moving average window, also called the order of moving average.<br>\nA linear regression model is constructed including the specified number and type of terms, and the data is prepared by a degree of differencing in order to make it stationary, i.e. to remove trend and seasonal structures that negatively affect the regression model.\n\n**`Test for Stationarity`**\n\nTo identify the nature of data, we will be using the null hypothesis.\n\nH0: The null hypothesis: It is a statement about the population that either is believed to be true or is used to put forth an argument unless it can be shown to be incorrect beyond a reasonable doubt.\n\nH1: The alternative hypothesis: It is a claim about the population that is contradictory to H0 and what we conclude when we reject H0.\n\n#Ho: It is non-stationary\n#H1: It is stationary\nWe will be considering the null hypothesis that data is not stationary and the alternate hypothesis that data is stationary.","b21ad545":"<a id = \"results\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EC5555; border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:white;padding:10px \">Conclusion and Further Improvement<\/span><\/h1>\n\n* LSTM might not be a good model to fit. Some fine tuning on the parameters of LSTM may improve the model accuracy\n* Further fine tuning the LSTM may improve the model performance.","1debe3b7":"<a id = \"eda\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EC5555; border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:white;padding:10px \">EDA<\/span><\/h1>","04f2bad1":"<h1 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: red;\">Differencing the data&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","afc357be":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Import Libraires&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","06e620b3":"<h1 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: red;\">Plotting the autocorrelation plot&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","8a0861cb":"<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #EC5555 ; color : white; text-align: center; border-radius: 100px 100px;padding:10px\">Stock Price Prediction<\/h1>\n<img src=\"https:\/\/images.cnbctv18.com\/wp-content\/uploads\/2021\/06\/trending-stocks-1019x573.jpg\">\n\n<h1 style=\"font-size:30px; font-family:Garamond ; font-weight : normal\"><b>What is a stock?<\/b><\/h1>\n\nA stock (also known as equity) is a security that represents the ownership of a fraction of a corporation. This entitles the owner of the stock to a proportion of the corporation's assets and profits equal to how much stock they own. Units of stock are called \"shares.\"\nStocks are bought and sold predominantly on stock exchanges, though there can be private sales as well, and are the foundation of many individual investors' portfolios. These transactions have to conform to government regulations which are meant to protect investors from fraudulent practices. Historically, they have outperformed most other investments over the long run.1\ufeff These investments can be purchased from most online stock brokers.\n\n**KEY TAKEAWAYS** \n\n`1) A stock is a form of security that indicates the holder has proportionate ownership in the issuing corporation.`<br>\n`2) Corporations issue (sell) stock to raise funds to operate their businesses. There are two main types of stock: common and preferred.`<br>\n`3) Stocks are bought and sold predominantly on stock exchanges, though there can be private sales as well, and they are the foundation of nearly every portfolio.`<br>\n`4) Historically, they have outperformed most other investments over the long run.`\n\n<h1 style=\"font-size:30px; font-family:Garamond ; font-weight : normal\"><b>Problem Statement<\/b><\/h1>\n\nThe data (last updated 11\/10\/2017) is presented in CSV format as follows: Date, Open, High, Low, Close, Volume, OpenInt. Note that prices have been adjusted for dividends and splits.\n\n<h1 style=\"font-size:30px; font-family:Garamond ; font-weight : normal\"><b>Way Ahead<\/b><\/h1>\nIn this notebook we will see the use of LSTM on stock data to predict the future stock prices. Also how to read the data and import into pandas dataframe.","6366473c":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Data for Dataset 1&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","c9f32b43":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Plot the Loss and Accuracy curves&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","80be4589":"<h1 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: red;\">Split Data into Train and Test&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","2f0beb84":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Declare default values for the parameters&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","2655730f":"<a id = \"OV\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EC5555; border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:white; padding:10px\">Data Read<\/span><\/h1>","bf6b68fc":"<a id = \"model\"><\/a><h1 id=\"Libraries and Utilities\"><span class=\"label label-default\" style=\"background-color:#EC5555; border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:white;padding:10px \">Model Building<\/span><\/h1>","08486fd6":"Here P-value is 0.004, which means we will be rejecting the null hypothesis. So data is stationary.","cee8b4db":"<br>\n<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #EC5555 ; color : white; text-align: center; border-radius: 100px 100px;padding:10px\">Content <\/h1>\n<br>\n<p id=\"toc\"><\/p>\n\n--- \n<h3 style=\"text-indent: 3vw; font-family: Garamond; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; color: black; background-color: white;\"><a href=\"#OV\" style=\"color:red;text-decoration:none\">&nbsp;&nbsp;&nbsp;&nbsp;1.Data Read and Import<\/a><\/h3>\n\n---\n<h3 style=\"text-indent: 3vw; font-family: Garamond; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; color: navy; background-color: #ffffff;\"><a href=\"#eda\" style=\"color:red;text-decoration:none\">&nbsp;&nbsp;&nbsp;&nbsp;2.EDA<\/a><\/h3>\n\n---\n<h3 style=\"text-indent: 3vw; font-family: Garamond; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; color: navy; background-color: #ffffff;\"><a href=\"#model\" style=\"color:red;text-decoration:none\">&nbsp;&nbsp;&nbsp;&nbsp;3.Model Building<\/a><\/h3>\n\n---\n<h3 style=\"text-indent: 3vw; font-family: Garamond; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; color: navy; background-color: #ffffff;\"><a href=\"#results\" style=\"color:red;text-decoration:none\">&nbsp;&nbsp;&nbsp;&nbsp;4.Conclusion and Further improvement<\/a><\/h3>\n\n---","6fceb00f":"The best ARIMA model with p,d,q values is 1,1,0 and Seasonal P,D,Q with 0,0,0","b901ee38":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Functions for LSTM Model Training&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","cad9da64":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Priors On ARIMA Model&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","6202dacd":"Here P-value is 0.36 which is greater than 0.05, which means data is accepting the null hypothesis, which means data is non-stationary.","781074b0":"<h1 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: red;\">Plotting the seasonal difference&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","93ddf19c":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Train the Model&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","9b8466ec":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Make Predictions&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> ","23100ac4":"<h1 style=\"font-family: Verdana; font-size: 15px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: red;\">AD Fuller test&nbsp;&nbsp;&nbsp;&nbsp;<\/h1> "}}