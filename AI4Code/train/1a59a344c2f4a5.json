{"cell_type":{"72275f8c":"code","5379526a":"code","88c2015f":"code","229d0c54":"code","28d2c2d2":"code","6fc434e1":"code","5b9c7fd8":"code","af461fa0":"code","268ca618":"code","d20e3053":"code","6d3bbbde":"code","a422ecfb":"code","c9067961":"code","667de192":"code","b1b28855":"code","d9708a5f":"markdown","d0280c80":"markdown","32cbdf30":"markdown","0f61a421":"markdown","1a9e3406":"markdown","1a2c7d06":"markdown"},"source":{"72275f8c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(200)","5379526a":"# Initializing the values\ndf = pd.DataFrame({\n    'x': [12, 20, 28, 18, 29, 33, 24, 45, 45, 52, 51, 52, 55, 53, 55, 61, 64, 69, 72],\n    'y': [39, 36, 30, 52, 54, 46, 55, 59, 63, 70, 66, 63, 58, 23, 14, 8, 19, 7, 24]\n})\n\ndf.head()","88c2015f":"#let's select 3 centroids or cluster centers randomnly\nk = 3\n#centroids[i] = [x, y]\ncentroids = {\n    i+1: [np.random.randint(0, 80), np.random.randint(0, 80)] for i in range(k)\n}\nprint(centroids)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.scatter(df['x'], df['y'], color='k')\ncolmap = {1: 'r', 2: 'g', 3: 'b'}\nfor i in centroids.keys():\n    ax.scatter(*centroids[i], color=colmap[i])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)\n# plt.show()","229d0c54":"#Calculating the distance and assigning the clusters to the datapoints\ndef assignment(df, centroids):\n    for i in centroids.keys():\n        # sqrt((x1 - x2)^2 - (y1 - y2)^2)\n        df['distance_from_{}'.format(i)] = (\n            np.sqrt((df['x'] - centroids[i][0]) ** 2 + (df['y'] - centroids[i][1]) ** 2)\n        )\n    centroid_distance_cols = ['distance_from_{}'.format(i) for i in centroids.keys()]\n    df['closest'] = df.loc[:, centroid_distance_cols].idxmin(axis=1)\n    df['closest'] = df['closest'].map(lambda x: int(x.lstrip('distance_from_')))\n    df['color'] = df['closest'].map(lambda x: colmap[x])\n    return df\n\ndf = assignment(df, centroids)\nprint(df.head())\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.scatter(df['x'], df['y'], color=df['color'], alpha=0.5, edgecolor='k')\nfor i in centroids.keys():\n    ax.scatter(*centroids[i], color=colmap[i])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)\n# plt.show()","28d2c2d2":"# Update Stage\nimport copy\n\nold_centroids = copy.deepcopy(centroids)\n\ndef update(k):\n    for i in centroids.keys():\n        centroids[i][0] = np.mean(df[df['closest'] == i]['x'])\n        centroids[i][1] = np.mean(df[df['closest'] == i]['y'])\n    return k\n\ncentroids = update(centroids)\n    \nfig, ax = plt.subplots(figsize=(5, 5))\nax.scatter(df['x'], df['y'], color=df['color'], alpha=0.5, edgecolor='k')\nfor i in centroids.keys():\n    ax.scatter(*centroids[i], color=colmap[i])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)\n\nfor i in old_centroids.keys():\n    old_x = old_centroids[i][0]\n    old_y = old_centroids[i][1]\n    dx = (centroids[i][0] - old_centroids[i][0]) * 0.75\n    dy = (centroids[i][1] - old_centroids[i][1]) * 0.75\n    ax.arrow(old_x, old_y, dx, dy, head_width=2, head_length=3, fc=colmap[i], ec=colmap[i])\n# plt.show()","6fc434e1":"# Repeat Assigment Stage\n\ndf = assignment(df, centroids)\n\n# Plot results\nfig, ax = plt.subplots(figsize=(5, 5))\nax.scatter(df['x'], df['y'], color=df['color'], alpha=0.5, edgecolor='k')\nfor i in centroids.keys():\n    ax.scatter(*centroids[i], color=colmap[i])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)\n# plt.show()","5b9c7fd8":"# Continue until all assigned categories don't change any more\nwhile True:\n    closest_centroids = df['closest'].copy(deep=True)\n    centroids = update(centroids)\n    df = assignment(df, centroids)\n    if closest_centroids.equals(df['closest']):\n        break\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.scatter(df['x'], df['y'], color=df['color'], alpha=0.5, edgecolor='k')\nfor i in centroids.keys():\n    ax.scatter(*centroids[i], color=colmap[i])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)\n# plt.show()","af461fa0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nnp.random.seed(200)\nfrom sklearn.cluster import KMeans","268ca618":"df = pd.DataFrame({\n    'x': [12, 20, 28, 18, 29, 33, 24, 45, 45, 52, 51, 52, 55, 53, 55, 61, 64, 69, 72],\n    'y': [39, 36, 30, 52, 54, 46, 55, 59, 63, 70, 66, 63, 58, 23, 14, 8, 19, 7, 24]\n})\n\nkmeans = KMeans(n_clusters=2)  #here n_clusters is selected as 2 randomly.\nkmeans.fit(df)","d20e3053":"#print SSE\nkmeans.inertia_","6d3bbbde":"labels = kmeans.predict(df)\nlabels","a422ecfb":"centroids = kmeans.cluster_centers_\ncentroids","c9067961":"fig, ax = plt.subplots(figsize=(5, 5))\ncolmap = {1: 'r', 2: 'g', 3: 'b'}\ncolors = map(lambda x: colmap[x+1], labels)\ncolors1=list(colors)\nprint(colors1)\n\nax.scatter(df['x'], df['y'], color=colors1, alpha=0.5, edgecolor='k')\nfor idx, centroid in enumerate(centroids):\n    ax.scatter(*centroid, color=colmap[idx+1])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)","667de192":"# fitting multiple k-means algorithms and storing the values in an empty list\nSSE = []\nfor cluster in range(1,20):\n    kmeans = KMeans(n_jobs = -1, n_clusters = cluster, init='k-means++')\n    kmeans.fit(df)\n    SSE.append(kmeans.inertia_)\n\n# converting the results into a dataframe and plotting them\nframe = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\nfig, ax = plt.subplots(figsize=(12,6))\nax.plot(frame['Cluster'], frame['SSE'], marker='o')\nax.set_xlabel('Number of clusters')\nax.set_ylabel('Inertia')","b1b28855":"# k means using 3 clusters and k-means++ initialization\nkmeans = KMeans(n_jobs = -1, n_clusters = 3, init='k-means++')\nkmeans.fit(df)\n\nprint(kmeans.inertia_)\npred = kmeans.predict(df)\nprint(pred)\n\nfig, ax = plt.subplots(figsize=(5, 5))\ncolmap = {1: 'r', 2: 'g', 3: 'b'}\ncolors = map(lambda x: colmap[x+1], labels)\ncolors1=list(colors)\nprint(colors1)\n\nax.scatter(df['x'], df['y'], color=colors1, alpha=0.5, edgecolor='k')\nfor idx, centroid in enumerate(kmeans.cluster_centers_):\n    ax.scatter(*centroid, color=colmap[idx+1])\nax.set_xlim(0, 80)\nax.set_ylim(0, 80)","d9708a5f":"#### Interpretation\nThe SSE has significantly come down with right value of K.","d0280c80":"# Implementing K-Means using Sklearn","32cbdf30":"### How to Choose the Right Number of Clusters in K-Means Clustering?\nOne of the most common doubts everyone has while working with K-Means is selecting the right number of clusters.","0f61a421":"Can you tell the optimum cluster value from this plot? Looking at the above elbow curve, we can choose any number of clusters between 3 to 5. Let\u2019s set the number of clusters as 3 and fit the model.\n\n### Build the final model","1a9e3406":"#### References\n* https:\/\/www.naftaliharris.com\/blog\/visualizing-k-means-clustering\/\n* https:\/\/www.analyticsvidhya.com\/blog\/2019\/08\/comprehensive-guide-k-means-clustering\/\n* https:\/\/www.analyticsvidhya.com\/blog\/2016\/11\/an-introduction-to-clustering-and-different-methods-of-clustering\/\n* https:\/\/www.analyticsvidhya.com\/blog\/2017\/02\/test-data-scientist-clustering\/","1a2c7d06":"# K-Means Algorithm: Step by Step"}}