{"cell_type":{"1e8fd43a":"code","b3735e6a":"code","c5cc55a8":"code","3e05c13f":"code","5a450e36":"code","ae9d44a8":"code","334746ba":"code","355c9020":"code","f162a53a":"code","81a4ea4b":"code","9ca0cc45":"code","4bb571b3":"code","badc6ee6":"code","b0cc1f6f":"code","f614e218":"code","044077f2":"code","79855485":"code","3ade5d36":"code","550add6a":"code","3591271a":"code","e302a428":"code","60671e4e":"code","dfb81d71":"code","710dd6b8":"code","621da20f":"code","9066aaa0":"code","4676d8e1":"code","0424976c":"code","38884fbd":"code","6996129e":"code","bd222e0a":"code","135b9d2a":"code","24900768":"code","7b4747bc":"code","bc6bd612":"code","0ee2b5df":"code","e30448a5":"code","4d39b8e6":"code","9e8dc91d":"markdown","0223bb95":"markdown","e6953c1e":"markdown","cc41e559":"markdown","5655f9e7":"markdown","402c2393":"markdown","2a0fdcf9":"markdown","2b6517b2":"markdown","c6e0cb20":"markdown","72d5cfa8":"markdown","f6f3da30":"markdown","c1175029":"markdown","22c21c0c":"markdown","3a844087":"markdown","dc1625c9":"markdown","5561b2c4":"markdown","6d198479":"markdown","fe37e05c":"markdown","17d0301c":"markdown","88ba6cf4":"markdown","dffbad8f":"markdown"},"source":{"1e8fd43a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3735e6a":"#Grab the training data\ntrain = pd.read_csv(\"..\/input\/covid-data\/train.csv\/train.csv\")\ntrain.head()\ntrain.dtypes                    ","c5cc55a8":"#Grab the test data\ntest = pd.read_csv(\"..\/input\/covid-data\/test.csv\")\ntest.head()\ntest.dtypes","3e05c13f":"#Grab the submission data, just to have on hand\nsample_submission = pd.read_csv(\"..\/input\/covid-data\/sample_submission.csv\")\nsample_submission.head()","5a450e36":"#Missing training data\nprint(train.isnull().sum())","ae9d44a8":"#Filled in missing covid data with deaths since we are trying to build a model to predict the amount of covid deaths, we should fill in these missing values\ntrain = train[train['COVID-19 Deaths'].notna()]\ntrain = train[train['Total Deaths'].notna()]\ntrain = train[train['MMWR Week'].notna()]\n\n\n\nprint(train.isnull().sum())","334746ba":"#Describe the training data\ntrain.describe()\ntrain.info()","355c9020":"#Find any missing testing data\nprint(test.isnull().sum())","f162a53a":"#Describe the test data\ntest.describe()\ntest.info()","81a4ea4b":"# Visualizing the data with histograms\ntrain.hist(bins=5, figsize=(30,10))\nplt.show()","9ca0cc45":"#Check if there is correlation between race and covid\nfig, ax = plt.subplots(figsize = (10, 5))\n\nax.xaxis.set_tick_params(pad = 30)\nfig.autofmt_xdate()\n\n\n# # # creating the bar plot\nplt.bar(train['Race and Hispanic Origin Group'] , train['COVID-19 Deaths'], color ='maroon',width = 0.4)\nplt.show()","4bb571b3":"#Check if there is correlation between race and covid\nfig, ax = plt.subplots(figsize = (10, 5))\n\nax.xaxis.set_tick_params(pad = 30)\nfig.autofmt_xdate()\n\n\n# # # creating the bar plot\nplt.bar(train['Age Group'] , train['COVID-19 Deaths'], color ='maroon',\nwidth = 0.4)\nplt.show()","badc6ee6":"#Searching for outliers in the covid deaths data\nsns.boxplot(x = train['COVID-19 Deaths'])\nplt.show()","b0cc1f6f":"# Searching for outliers in the total deaths data\nsns.boxplot(x = train['Total Deaths'])\nplt.show()","f614e218":"# Searching for outliers in the id data\nsns.boxplot(x = train['id'])\nplt.show()","044077f2":"# Searching for outliers in the id data\nsns.boxplot(x = train['MMWR Week'])\nplt.show()","79855485":"# We also won't need footnote too\ntrain = train.drop('Footnote', axis = 1)\n\n# A lot of the columns of time are redundant so we won't use those\ntrain = train.drop('Week-Ending Date', axis = 1)\ntrain = train.drop('Data As Of', axis = 1)\n\n\n\ntrain.info()","3ade5d36":"train = train.drop(train[train['Year'] == '2019\/2020'].index)\ntrain = train.drop(train[train['Year'] == '2020\/2021'].index)","550add6a":"train['Start Date Converted'] = pd.to_datetime(train['Start Date'])\ntrain['End Date Converted'] = pd.to_datetime(train['End Date'])\ntrain['Year'] = pd.to_datetime(train['Year'])\ntrain['Time Difference'] = (train['End Date Converted'] - train['Start Date Converted'])\n\ntrain['Start Date Converted'] = (train['Start Date Converted'] - train['Start Date Converted'].min()).dt.total_seconds()\ntrain['End Date Converted'] = (train['End Date Converted'] - train['End Date Converted'].min()).dt.total_seconds()\ntrain['Time Difference'] = (train['Time Difference'] - train['Time Difference'].min()).dt.total_seconds()\ntrain['Year'] = (train['Year'] - train['Year'].min()).dt.total_seconds()\n\ntrain.info()","3591271a":"train = train.drop('Month', axis = 1)\ntrain.info()","e302a428":"train = pd.get_dummies(train, columns = ['Race and Hispanic Origin Group'])","60671e4e":"train = pd.get_dummies(train, columns = ['Age Group'])","dfb81d71":"train = pd.get_dummies(train, columns = ['HHS Region'])","710dd6b8":"train = pd.get_dummies(train, columns = ['Group'])\ntrain.columns","621da20f":"X = train[['HHS Region_01',\n       'HHS Region_02', 'HHS Region_03', 'HHS Region_04', 'HHS Region_05',\n       'HHS Region_06', 'HHS Region_07', 'HHS Region_08', 'HHS Region_09',\n       'HHS Region_10', 'HHS Region_United States', 'Year','End Date Converted','MMWR Week','Start Date Converted','Race and Hispanic Origin Group_Hispanic', 'Race and Hispanic Origin Group_Non-Hispanic American Indian or Alaska Native','Race and Hispanic Origin Group_Non-Hispanic Asian','Race and Hispanic Origin Group_Non-Hispanic Black', 'Race and Hispanic Origin Group_Non-Hispanic More than one race','Race and Hispanic Origin Group_Non-Hispanic Native Hawaiian or Other Pacific Islander', 'Race and Hispanic Origin Group_Non-Hispanic White', 'Race and Hispanic Origin Group_Unknown','Age Group_0-4 years','Age Group_18-29 years', 'Age Group_30-39 years', 'Age Group_40-49 years', 'Age Group_5-17 years','Age Group_50-64 years', 'Age Group_65-74 years', 'Age Group_75-84 years', 'Age Group_85 years and over', 'Total Deaths']]\ny = train['COVID-19 Deaths']","9066aaa0":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)","4676d8e1":"model_ols = sm.OLS(y_train, X_train)","0424976c":"fit_ols = model_ols.fit()","38884fbd":"fit_ols.pvalues","6996129e":"fit_ols.summary()","bd222e0a":"ols_train_predictions = fit_ols.predict(X_test)\nprint(\"-----------------------------------------\")\nprint(\"Train Predictions: \",ols_train_predictions)","135b9d2a":"ols_train_predictions.describe()","24900768":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\n\nridge = Ridge()\nparameters = {'alpha':[1,5,10,20,50,100]}\nridge_regressor = GridSearchCV(ridge, parameters, scoring = 'neg_mean_squared_error', cv = 3)\nridge_regressor_fit = ridge_regressor.fit(X_train, y_train)\n\nprint(ridge_regressor_fit.predict(X_test))","7b4747bc":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\n\nlasso = Lasso()\nlasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv = 3)\n\nlasso_regressor.fit(X_train,y_train)\n\nprint(lasso_regressor.predict(X_test))\n\n# print(lasso_regressor.best_params_)\n# print(lasso_regressor.best_score_)","bc6bd612":"from sklearn.linear_model import ElasticNetCV\ne_net = ElasticNetCV(cv=3)\ne_net.fit(X_train, y_train)\n\nprint(e_net.predict(X_test))","0ee2b5df":"from statsmodels.tools.eval_measures import rmse\nols_rmse = rmse(y_test,fit_ols.predict(X_test))\nprint(\"OLS Score: \", ols_rmse)\nridge_rmse = rmse(y_test,ridge_regressor_fit.predict(X_test))\nprint(\"Ridge Regression Score: \", ridge_rmse)\nlasso_rmse = rmse(y_test,lasso_regressor.predict(X_test))\nprint(\"Lasso Regression Score: \", lasso_rmse)\ne_net_rmse = rmse(y_test,e_net.predict(X_test))\nprint(\"Elastic Net Regression Score: \", e_net_rmse)","e30448a5":"describe_rmse = pd.DataFrame([ols_rmse,ridge_rmse,lasso_rmse,e_net_rmse])\ndescribe_rmse.describe()","4d39b8e6":"output = pd.DataFrame({'id': test.id, 'COVID-19 Deaths': fit_ols.predict(X_test)}).fillna(0)\nprint(output)\noutput.to_csv('finalSubmit.csv')\nprint(\"Your submission was successfully saved!\")","9e8dc91d":"# **Best Score**","0223bb95":"Before I begin, I will find and describe the missing data, starting with training data","e6953c1e":"**Elastic Net Regression**","cc41e559":"**Score Gathering**","5655f9e7":"**Ordinary Least Squares Model**","402c2393":"Describe the results of the model","2a0fdcf9":"**Ridge Regression**","2b6517b2":"# **Finding Outliers**","c6e0cb20":"Although there are outliers in the data, I plan on keeping them as removing them may cause bias to occur in my data. The next thing I will remove though, is any redundant data","72d5cfa8":"**Lasso Regression**","f6f3da30":"Noah Law","c1175029":"# **EDA (cont)**","22c21c0c":"Since the data for races are simply categorical data, I will create a series of dummy variables that will hold the r","3a844087":"To start, I will convert the start date column to a datetime data type so it can serve better as a feature for modeling","dc1625c9":"Taking the data we need, we will begin to train, test and split the data","5561b2c4":"# **Training the Data**","6d198479":"Of the models, OLS seems to be the best one overall","fe37e05c":"Same for ages, since we don't know OF the ages who is and isn't specifically a certain age in the age range, we're just going to make it categorical data","17d0301c":"# **Feature Engineering**","88ba6cf4":"# **Load Data In**","dffbad8f":"# **EDA**"}}