{"cell_type":{"dbca5937":"code","0294f9fd":"code","43db4ea3":"code","8ea78dcb":"code","79569de1":"code","d208a6c4":"code","3da5e607":"code","6d795568":"code","dd87c079":"code","8e135429":"code","a255e15b":"code","b7a07693":"code","a57fb7c6":"code","2c5704fd":"code","b1506ea5":"code","22c72515":"code","d92d38b8":"code","52301b84":"code","2f6a8078":"code","57656d96":"code","3f3372fd":"code","ad6965d7":"code","ad771e28":"markdown","c83ddf77":"markdown","c7c80e07":"markdown","71a0524a":"markdown","33dbb200":"markdown","1f03a2c8":"markdown","84678a98":"markdown","eb118d2d":"markdown","94917251":"markdown","b8ced8c7":"markdown","fdff53f2":"markdown","5dd494da":"markdown","3a5ca2ee":"markdown","ca2bd767":"markdown","a9263a99":"markdown","b552d537":"markdown","bb7ed8b2":"markdown"},"source":{"dbca5937":"pip install lightautoml","0294f9fd":"pip install transformers -U","43db4ea3":"pip install navec","8ea78dcb":"# Standard python libraries\nimport os\nimport time\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport matplotlib.pyplot as plt\nfrom navec import Navec\n\n# Imports from our package\nfrom lightautoml.automl.presets.text_presets import TabularNLPAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\n","79569de1":"N_THREADS = 4 # threads cnt for lgbm and linear models\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 9000 # Time in seconds for automl run\nTARGET_NAME = 'sentiment' # Target column name","d208a6c4":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","3da5e607":"%%time\n\ndata = pd.read_csv('..\/input\/lama-datasets\/rureviews.csv', sep='\\t')\ndata.head()","6d795568":"data.sentiment.value_counts()","dd87c079":"data['review'].str.split(' ').apply(len).hist(bins=100)\nplt.show()","8e135429":"%%time\n\ntrain_data, test_data = train_test_split(data, \n                                         test_size=TEST_SIZE, \n                                         stratify=data[TARGET_NAME], \n                                         random_state=RANDOM_STATE)\n\ntrain_data = train_data.sample(n=25_000, random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: train_data = {}, test_data = {}'\n              .format(train_data.shape, test_data.shape))","a255e15b":"train, valid = train_test_split(train_data, \n                                         test_size=TEST_SIZE, \n                                         stratify=train_data[TARGET_NAME], \n                                         random_state=RANDOM_STATE)\n\nprint('Data splitted. Parts sizes: train = {}, valid = {}'\n              .format(train.shape, valid.shape))","b7a07693":"!wget https:\/\/storage.yandexcloud.net\/natasha-navec\/packs\/navec_hudlit_v1_12B_500K_300d_100q.tar","a57fb7c6":"path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\nnavec = Navec.load(path)","2c5704fd":"def f1_macro(y_true, y_pred):\n    return f1_score(y_true, np.argmax(y_pred, axis=1), average='macro')","b1506ea5":"%%time\n\ntask = Task('multiclass', metric=f1_macro)","22c72515":"%%time\n\nroles = {'target': TARGET_NAME, 'text': ['review']}","d92d38b8":"%%time\n      \nstart = time.time()\nautoml = TabularNLPAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb']]},\n                       linear_pipeline_params = {'text_features': \"tfidf\"},\n                       gbm_pipeline_params = {'text_features': 'embed'},\n                       text_params = {'lang': 'ru', 'bert_model': 'DeepPavlov\/rubert-base-cased-conversational'},\n                       autonlp_params = {'model_name': 'random_lstm',\n                                         'embedding_model': navec,\n                                         'transformer_params': {'dataset_params': {\n                                                                                  'max_length': 150,\n                                                                                  'embed_size': 300}, \n                                                              }\n                                        },\n                       tfidf_params = {'svd': True, 'tfidf_params': {'ngram_range': (1, 1)} }\n                       \n                    )\n\noof_pred = automl.fit_predict(train, valid_data = valid, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\ntime_automl = time.time() - start","52301b84":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))\n\nprint('Check scores...')\nprint('VALID score: {}'.format(f1_macro(valid[TARGET_NAME].map(automl.reader.class_mapping).values,\n                                           oof_pred.data)))\ntest_automl = f1_macro(test_data[TARGET_NAME].map(automl.reader.class_mapping ).values, test_pred.data)\nprint('TEST score: {}'.format(test_automl))\n","2f6a8078":"%%time \nstart = time.time()\nautoml = TabularNLPAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'nested_cv': False, 'use_algos': [['nn']]},\n                       text_params = {'lang': 'ru', 'bert_model': 'DeepPavlov\/rubert-base-cased-conversational'},\n                       nn_params = {'opt_params': { 'lr': 1e-5},\n                                    'max_length': 150, 'bs': 32, 'epoch': 1\n                                    },\n                       )\n\noof_pred = automl.fit_predict(train, valid_data = valid, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\ntime_automl_sbert = time.time() - start","57656d96":"automl.levels","3f3372fd":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))","ad6965d7":"print('Check scores...')\nprint('VALID score: {}'.format(f1_macro(valid[TARGET_NAME].map(automl.reader.class_mapping).values,\n                                           oof_pred.data)))\ntest_automl_sbert = f1_macro(test_data[TARGET_NAME].map(automl.reader.class_mapping ).values, test_pred.data)\nprint('TEST score: {}'.format(test_automl_sbert))","ad771e28":"## Step 2. Setup columns roles","c83ddf77":"# Step 0.3. Fix torch number of threads and numpy seed ","c7c80e07":"#  ==== AutoML preset usage ====\n\n\n## Step 1. Create Task","71a0524a":"Dataset from https:\/\/github.com\/sismetanin\/rureviews","33dbb200":"## Step 3. Create AutoML from preset","1f03a2c8":"# Step 0.7. (Optional) Load RU text embeddings","84678a98":"# Step 0. Install LAMA","eb118d2d":"# Step 0.5. Some user feature preparation ","94917251":"Block below can be omitted if you are going to train model only or you have specific train and test files:","b8ced8c7":"To create AutoML model here we use `TabularNLPAutoML` preset.\n\n\nAll params we set above can be send inside preset to change its configuration:","fdff53f2":"# Step 0.6. (Optional) Data splitting for train-test ","5dd494da":"# Step 0.1. Import necessary libraries ","3a5ca2ee":"# Step 0.4. Example data load ","ca2bd767":"## Step 5. Same Preset with Bert.","a9263a99":"# Step 0.2. Parameters ","b552d537":"Cell below shows some user feature preparations to create task more difficult (this block can be omitted if you don't want to change the initial data):","bb7ed8b2":"## Step 4. Predict to test data and check scores"}}