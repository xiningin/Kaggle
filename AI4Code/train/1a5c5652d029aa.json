{"cell_type":{"28d0b00d":"code","87e8ed21":"code","6981f93d":"code","e53cf0be":"code","808667e4":"code","4cd51b85":"code","3307e01a":"code","f4729eb5":"code","3930ec14":"code","6e668793":"code","dfb86dc0":"code","6fd23823":"code","d24246d5":"code","55c98caa":"code","bf72471f":"code","e99191f7":"code","836802bb":"code","cefe005d":"code","e76bacf1":"code","2b3d917c":"code","8c992a90":"code","ca268231":"code","7aa29c66":"code","17a4ae62":"code","f47aa624":"code","7482613b":"code","9310cf52":"code","dda57181":"code","a0c2074a":"code","ae3230e6":"code","181518fc":"code","2e8d2c8e":"code","8cb12835":"code","b059def4":"code","620e16f2":"code","cc40b815":"code","f7b3bfb8":"markdown","b7614830":"markdown","6367d394":"markdown","9e2e17eb":"markdown","f47c39c8":"markdown","307a7eab":"markdown","d9a09f37":"markdown","47d1b0bd":"markdown","14879f49":"markdown","11b02a21":"markdown","c151593f":"markdown","45fc7a48":"markdown","8f753e47":"markdown","adb885c5":"markdown","41d010c8":"markdown"},"source":{"28d0b00d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87e8ed21":"# Loading libs\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","6981f93d":"# Set palette\n\nsns.set_palette('colorblind')","e53cf0be":"# File path\n\nsample = '\/kaggle\/input\/tabular-playground-series-jan-2022\/sample_submission.csv'\nfile_train = '\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv'\nfile_test = '\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv'","808667e4":"# Load files\n\ndf_sample = pd.read_csv(sample)\ndf_train = pd.read_csv(file_train)\ndf_test = pd.read_csv(file_test)\n\ndf_sample.head(3)","4cd51b85":"df_test.head(3)","3307e01a":"# For each day, 18 observations = 3 countries * 2 stores * 3 products\n\ndf_train.head(20)","f4729eb5":"# What to predict?\n\ntarget = 'num_sold'","3930ec14":"df_train.shape","6e668793":"# 4 years in train set and 1 year in test set\n\nprint( (df_train.shape[0] \/ 18) \/ (365*3 + 366*1) )\nprint( (df_test.shape[0] \/ 18) \/ 365 )","dfb86dc0":"df_train.info()","6fd23823":"# Convert str to datetime for 'date' column\n\ndf_train['date'] = pd.to_datetime(df_train['date'])","d24246d5":"df_train.info()","55c98caa":"df_train.describe().T","bf72471f":"df_train.isnull().sum()","e99191f7":"countries = list(df_train['country'].unique())\nstores = list(df_train['store'].unique())\nproducts = list(df_train['product'].unique())","836802bb":"print(countries)\nprint(stores)\nprint(products)","cefe005d":"# Seperate the sales by country, store, and product (with the help of 'hue' in seaborn)\n\nfig, ax = plt.subplots(3, 2, figsize=(30, 20))\n\nfor i, country in enumerate(countries):\n    for j, store in enumerate(stores):\n        sns.lineplot(data=df_train[(df_train['country']==country) & (df_train['store']==store)],\n                     x='date', y=target, hue='product', ax=ax[i, j])\n        ax[i, j].set_title(f'{country} - {store}', fontsize=15)\n        # The y axis should be identical\n        ax[i, j].set_ylim([0, 3000])\n\nplt.show()","e76bacf1":"# Create some features for date\n\n# https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/timeseries.html#time-date-components\n\ndf_train['year'] = df_train.date.dt.year\ndf_train['quarter'] = df_train.date.dt.quarter\ndf_train['month'] = df_train.date.dt.month\ndf_train['day'] = df_train.date.dt.day\ndf_train['dayofweek'] = df_train.date.dt.dayofweek\ndf_train['dayofyear'] = df_train.date.dt.dayofyear\ndf_train['weekofyear'] = df_train.date.dt.weekofyear\n\ndf_train.head(1)","2b3d917c":"date_features = list(df_train.columns)[-7:]","8c992a90":"# Create dummy variables\n\ndummy_c = pd.get_dummies(df_train['country'], prefix='c_', drop_first=True)\ndummy_s = pd.get_dummies(df_train['store'], prefix='s_', drop_first=True)\ndummy_p = pd.get_dummies(df_train['product'], prefix='p_', drop_first=True)","ca268231":"# Concatenate data\n\nX_all = pd.concat([df_train[date_features], dummy_c, dummy_s, dummy_p], axis=1)\ny_all = df_train[target]","7aa29c66":"# Validate the data\n\nassert(len(X_all) == len(y_all))\nassert(list(X_all.index.values) == list(y_all.index.values))","17a4ae62":"# Train test ('valid' in this case) split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, test_size=0.25, random_state=42)","f47aa624":"# Linear regression as the benchmark for later comparisons\n\nfrom sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nlr.score(X_valid, y_valid)","7482613b":"y_pred = lr.predict(X_valid)\nplt.scatter(np.arange(len(y_pred)), y_pred, alpha=0.3, label='Prediction')\nplt.scatter(np.arange(len(y_pred)), y_valid, alpha=0.3, label='True')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()","9310cf52":"# CatBoost - a gradient boosting machine\n# For me, it is still a black box, which requires further digging.\n\nfrom catboost import CatBoostRegressor\n\ncb = CatBoostRegressor(random_state=42)\ncb.fit(X_train, y_train, verbose=0)\ncb.score(X_valid, y_valid)","dda57181":"y_pred = cb.predict(X_valid)\nplt.scatter(np.arange(len(y_pred)), y_pred, alpha=0.3, label='Prediction')\nplt.scatter(np.arange(len(y_pred)), y_valid, alpha=0.3, label='True')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()","a0c2074a":"# Fit the model with all training data\n\ncb.fit(X_all, y_all, verbose=0)","ae3230e6":"df_test","181518fc":"# Convert str to datetime for 'date' column\ndf_test['date'] = pd.to_datetime(df_test['date'])\n\n# Create some features for date\n\ndf_test['year'] = df_test.date.dt.year\ndf_test['quarter'] = df_test.date.dt.quarter\ndf_test['month'] = df_test.date.dt.month\ndf_test['day'] = df_test.date.dt.day\ndf_test['dayofweek'] = df_test.date.dt.dayofweek\ndf_test['dayofyear'] = df_test.date.dt.dayofyear\ndf_test['weekofyear'] = df_test.date.dt.weekofyear\n\n# Create dummy variables\ndummy_c = pd.get_dummies(df_test['country'], prefix='c_', drop_first=True)\ndummy_s = pd.get_dummies(df_test['store'], prefix='s_', drop_first=True)\ndummy_p = pd.get_dummies(df_test['product'], prefix='p_', drop_first=True)\n\n# Concatenate data\nX_test = pd.concat([df_test[date_features], dummy_c, dummy_s, dummy_p], axis=1)","2e8d2c8e":"# Validate the data\n\nassert(X_test.shape[1]==X_all.shape[1])","8cb12835":"df_test['num_sold'] = cb.predict(X_test)\n# df_test['num_sold'] = df_test['num_sold']\ndf_test['num_sold'] = df_test['num_sold'].astype('int')\n\ndf_test","b059def4":"output = df_test[['row_id', 'num_sold']]\noutput","620e16f2":"# Validate the data\n\nassert(df_sample.shape == output.shape)","cc40b815":"# Save the file for submission\n\noutput.to_csv('submission.csv', index=False)","f7b3bfb8":"***","b7614830":"### **\"Replay\" the procedures**","6367d394":"# 3. Visualization","9e2e17eb":"## We can see that linear regression is limited by model capacity,\n## however catboost is able to capture these non-linear relationships and interaction effects.","f47c39c8":"# 5. Models","307a7eab":"# 1. Libs and Datasets","d9a09f37":"## From this short and shallow analysis, we captured some trend and seasonal components in the given datasets.\n## We can see that Kaggle Rama outperforms Kaggle Mart on average, especially in Norway!\n## In order to increase revenue or visibility, some promotions and campaigns are needed between Autumn and Winter.\n## In my opinion, I think sequence is very important for time-series data, so using some traditional time-series forecast models might be a good idea as well.\n## I'll try another version using SARIMA, Holt-Winters, and NN (if possible).","47d1b0bd":"# 4. More features","14879f49":"# 2. Identify predictors and target","11b02a21":"***","c151593f":"## **BTW, this notebook skipped cross-validation, hyper-parameter optimization and essential metric, etc., which is A BIG PROBLEM!**","45fc7a48":"# ***7. Findings and Thoughts***\n","8f753e47":"***","adb885c5":"***","41d010c8":"# 6. Output"}}