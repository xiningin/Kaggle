{"cell_type":{"64f7b949":"code","f1f788c0":"code","f0a4fe19":"code","df1de6ee":"code","e4d30ee7":"code","b73c5247":"code","0692bbbe":"code","c0db71b7":"code","af32d59d":"code","5db61c68":"code","19cc9fce":"code","cc01f1a7":"code","2ff2dfd6":"code","8e0fcdba":"markdown","6de7bc0a":"markdown","423de300":"markdown","990038c4":"markdown","f6951b15":"markdown","5bde2ee2":"markdown","cd3ebf48":"markdown","949ea566":"markdown","8cb848f0":"markdown","1d6de8a5":"markdown","5e46d22a":"markdown","866ba60c":"markdown","1373d316":"markdown"},"source":{"64f7b949":"#importing libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report","f1f788c0":"#importing the dataset\n\ndf = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","f0a4fe19":"df.head()","df1de6ee":"df.info()","e4d30ee7":"sns.pairplot(df)","b73c5247":"X = df.drop(['Outcome'], axis=1)\ny = df['Outcome']","0692bbbe":"#train test split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,\n                                               test_size=0.31,random_state=30)\n\nprint('train size is %i'%y_train.shape[0])\nprint('test size is %i'%y_test.shape[0])","c0db71b7":"#getting the accuracy rate initially\n\nsvm = SVC()\nsvm.fit(X_train,y_train)\n\n\ny_pred1=svm.predict(X_test)\naccuracy_score(y_pred1,y_test)","af32d59d":"print(\"Testing Classification Report: \\n\", classification_report(y_test,y_pred1))","5db61c68":"train=[]\ntest=[]\n\nfor i in np.arange(1.0,20.0,0.3):\n    svm=SVC(kernel='rbf',C=i)\n    svm.fit(X_train,y_train)\n    y_pred1=svm.predict(X_train)\n    y_pred2=svm.predict(X_test)\n    train.append(accuracy_score(y_pred1,y_train))\n    test.append(accuracy_score(y_pred2,y_test))","19cc9fce":"#getting the C value where the accuracy is max\n\nprint(\"Maximum accuracy is at :\",max(test)*100,\"% where c value is = \",np.argmax(test))\n","cc01f1a7":"train=[]\ntest=[]\n\nfor i in np.arange(1.0,20.0,0.3):\n    svm=SVC(kernel='poly',C=i)\n    svm.fit(X_train,y_train)\n    y_pred1=svm.predict(X_train)\n    y_pred2=svm.predict(X_test)\n    train.append(accuracy_score(y_pred1,y_train))\n    test.append(accuracy_score(y_pred2,y_test))\n    \n#getting the C value where the accuracy is max\n\nprint(\"Maximum accuracy is at :\",max(test)*100,\"% where c value is = \",np.argmax(test))\n","2ff2dfd6":"train=[]\ntest=[]\n\nfor i in np.arange(1.0,20.0,0.3):\n    svm=SVC(kernel='sigmoid',C=i)\n    svm.fit(X_train,y_train)\n    y_pred1=svm.predict(X_train)\n    y_pred2=svm.predict(X_test)\n    train.append(accuracy_score(y_pred1,y_train))\n    test.append(accuracy_score(y_pred2,y_test))\n    \n#getting the C value where the accuracy is max\n\nprint(\"Maximum accuracy is at :\",max(test)*100,\"% where c value is = \",np.argmax(test))\n","8e0fcdba":"**Let us better tune our hyper-parameters to get a better accuracy**","6de7bc0a":"*With sigmoid kernel and C tuning*","423de300":"**Initially we are getting 79.5% accuracy on my testing data**","990038c4":"# Thus to conclude, we got the best accuracy of 83% while using \"**POLY**\" kernel when the C parameter is working at 4.","f6951b15":"**With poly kernel we are getting an accuracy of 83% with C tuned at 4**","5bde2ee2":"**Getting a very poor accuracy with sigmoid kernel**","cd3ebf48":"**We are getting an accuracy of 80% with rbf kernel with C tuned at 15**","949ea566":"*With poly kernel and C tuning*","8cb848f0":"# Training & testing\n\n**We will be using SVM and will tune C parameter as much as possible.**","1d6de8a5":"**For getting a better accuracy we can also tune hyper-parameters with grid search \/ random search\/k folds.**","5e46d22a":"**Analysis**","866ba60c":"**Knowing my dataset**","1373d316":"*With rbf kernel and C tuning*"}}