{"cell_type":{"3df73e25":"code","db229a4f":"code","d4412a08":"code","fa55b48b":"code","350b2559":"code","5fb785b7":"code","bafbccd5":"code","a45f6693":"code","4c4a3afa":"code","a2fd9e68":"code","b6103348":"code","5408ad35":"code","7041a252":"code","b0a53bf4":"code","721ef060":"code","0e6cf658":"code","c5174efa":"code","a99deca3":"code","4120db33":"code","bee6be9b":"code","9aa4e6c1":"code","a94be795":"code","19d0893b":"code","be6e2b0b":"code","3bf99caf":"code","0400338e":"code","80ae6051":"code","2e49d81a":"code","6fdb4553":"code","d8e5e4dd":"code","2a170a53":"code","73fff245":"code","38d6ebf0":"code","eb04f0a0":"code","deb7820c":"code","acaa5893":"markdown","2103f068":"markdown","8ca82daf":"markdown","1d3dfcfd":"markdown","af42e5ee":"markdown","8735555f":"markdown","c4a730a6":"markdown","0a79a916":"markdown","f4cdce20":"markdown","e824913e":"markdown","4619b5ce":"markdown","0db6da30":"markdown","52c875c9":"markdown","4801ae3f":"markdown","62ca3eb7":"markdown","d7a75856":"markdown","7a85f381":"markdown","6bf65dbb":"markdown","ad8ad2d2":"markdown","4976ba5f":"markdown","119ef703":"markdown"},"source":{"3df73e25":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline","db229a4f":"!ls ..\/input\/flowers\/flowers","d4412a08":"train_dir = \"..\/input\/flowers\/flowers\/\"\nclasses = os.listdir(train_dir)\nclasses = sorted(classes)\nnclasses = len(classes)\nclasses","fa55b48b":"for _class in classes:\n    print('{} {} images'.format(_class, len(os.listdir(os.path.join(train_dir, _class)))))","350b2559":"from PIL import Image, ImageOps, ImageFilter","5fb785b7":"other_extensions = [\".db\", \".pyc\", \".py\"]\ndef open_images_pil(path, classes, dim=32):\n    \n    xall = []\n    yall = []\n    label = 0\n    j = 0\n\n    for cl in classes:\n        clsdir = os.path.join(path, cl)\n        for imgname in os.listdir(clsdir):\n            bad_ext_found = 0\n            for other_ext in other_extensions:\n                if imgname.endswith(other_ext):\n                    bad_ext_found = 1\n                    break\n            if not bad_ext_found:\n                print(\"Opening files in {}: {}\".format(cl, str(j + 1)), end=\"\\r\")\n                imgpath = os.path.join(clsdir, imgname)\n\n                #open and pre-process images\n                img = Image.open(imgpath)\n                img = ImageOps.fit(img, (dim, dim), Image.ANTIALIAS).convert('RGB')\n                \n                xall.append(img)  # Get image \n                yall.append(label)  # Get image label (folder name)\n                j += 1\n\n        j = 0\n        label += 1\n        print()\n\n    n = len(xall)\n    print(\"{} images in set\".format(n))\n    return xall, yall","bafbccd5":"xall, yall = open_images_pil(train_dir, classes, 256)","a45f6693":"im = xall[0]\nim","4c4a3afa":"im.format, im.size, im.mode","a2fd9e68":"blur = im.filter(ImageFilter.BLUR)\nblur","b6103348":"gray = im.convert('L')\nrgb = gray.convert(\"RGB\")\ngray","5408ad35":"box = (100, 100, 400, 400)\ncrpd = im.crop(box)\ncrpd","7041a252":"enh = im.filter(ImageFilter.DETAIL)\nenh","b0a53bf4":"_xall = np.stack(xall, axis=0) # from list of len 56 of ndarrays (dim, dim, 3) to ndarray (52, dim, dim, 3)\n_xall.shape","721ef060":"from sklearn.preprocessing import LabelBinarizer\nlb = LabelBinarizer().fit(yall)","0e6cf658":"label = lb.transform(yall) \nlabel.shape","c5174efa":"#_xall = np.asarray(xall)\n\nfor i in range(0,9): # how many imgs will show from the 3x3 grid\n    plt.subplot(330 + (i+1)) # open next subplot\n    plt.imshow(_xall[i + 155], cmap=plt.get_cmap('gray'))\n    plt.title(yall[i + 155]);","a99deca3":"import imageio\nfrom skimage.transform import resize\n\nclasspath = os.path.join(train_dir, classes[0])\nimgpath = os.listdir(classpath)[0] # first imagepath of first class, as example\nimgpath = os.path.join(classpath, imgpath)\n\nimg = imageio.imread(imgpath)\ndim = 128\nimg = resize(img, (dim, dim, 3))","4120db33":"import cv2\nfrom cv2 import imread, cvtColor, resize, threshold, calcHist, equalizeHist","bee6be9b":"def trim_margin(img, lim):\n    return img[lim:-lim, lim:-lim]","9aa4e6c1":"supported_dims = [16, 32, 64, 128, 256]\ndef img_resize(img, dims):\n    if dims in supported_dims:\n        return cv2.resize(img, (dims, dims))\n    else:\n        print(\"Incorrect image dimensions.\\n\")\n        return None","a94be795":"other_extensions = [\".db\", \".pyc\", \".py\"]\ndef open_images_cv2(path, classes, dim=32):\n    \n    xall = []\n    yall = []\n    label = 0\n    j = 0\n\n    for cl in classes:\n        clsdir = os.path.join(path, cl)\n        for imgname in os.listdir(clsdir):\n            bad_ext_found = 0\n            for other_ext in other_extensions:\n                if imgname.endswith(other_ext):\n                    bad_ext_found = 1\n                    break\n            if not bad_ext_found:\n                print(\"Opening files in {}: {}\".format(cl, str(j + 1)), end=\"\\r\")\n                imgpath = os.path.join(clsdir, imgname)\n\n                #open and pre-process images\n                img = imread(imgpath, cv2.IMREAD_COLOR)\n                img = cvtColor(img, cv2.COLOR_BGR2RGB)\n                img = trim_margin(img, int(img.shape[0] * 0.05))\n                img = img_resize(img, dim)\n                #img = equalize_hist(img)\n\n                xall.append(img)  # Get image \n                yall.append(label)  # Get image label (folder name)\n                j += 1\n\n        j = 0\n        label += 1\n        print()\n\n    n = len(xall)\n    print(\"{} images in set\".format(n))\n    return xall, yall","19d0893b":"xall, yall = open_images_cv2(train_dir, classes, 256)","be6e2b0b":"xall = np.asarray(xall)\nyall = np.asarray(yall)","3bf99caf":"image = xall[0]\nplt.imshow(image, cmap=plt.get_cmap('gray'))\nplt.title(yall[0]);","0400338e":"color = ('b','g','r')\nfor i,col in enumerate(color):\n    histr = cv2.calcHist([image],[i],None,[256],[0,256])\n    plt.plot(histr,color = col)\n    plt.xlim([0,256])\nplt.show()","80ae6051":"img_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n\n# equalize the histogram of the Y channel\nimg_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n\n# convert the YUV image back to RGB format\nimgo = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n\nplt.imshow(imgo)","2e49d81a":"color = ('r','g','b')\nfor i,col in enumerate(color):\n    histr = cv2.calcHist([imgo],[i],None,[256],[0,256])\n    print(max(histr))\n    plt.plot(histr,color=col)\n    plt.xlim([0,256])\nplt.show()","6fdb4553":"# https:\/\/lmcaraig.com\/image-histograms-histograms-equalization-and-histograms-comparison\/\n\nfrom matplotlib import ticker\n\nbins = 256\ntick_spacing = 5\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 5))\nchannels_mapping = {0: 'B', 1: 'G', 2: 'R'}\nfor i, channels in enumerate([[0, 1], [0, 2], [1, 2]]):\n    hist = cv2.calcHist([image], channels, None, [bins]*2, [0, 256]*2)\n\n    channel_x = channels_mapping[channels[0]]\n    channel_y = channels_mapping[channels[1]]\n\n    ax = axes[i]\n    ax.set_xlim([0, bins - 1])\n    ax.set_ylim([0, bins - 1])\n\n    ax.set_xlabel(f'Channel {channel_x}')\n    ax.set_ylabel(f'Channel {channel_y}')\n    ax.set_title(f'2D Color Histogram for {channel_x} and {channel_y}')\n\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n\n    im = ax.imshow(hist)\n\nfig.colorbar(im, ax=axes.ravel().tolist(), orientation='orizontal')\nfig.suptitle(f'2D Color Histograms with {bins} bins', fontsize=16)\nplt.show()","d8e5e4dd":"clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(8, 8))\ngray = cvtColor(image, cv2.COLOR_RGB2GRAY)\nclaheImg = clahe.apply(gray)\nplt.imshow(claheImg)","2a170a53":"imgpath = \"..\/input\/files\/files\/unsplash\/-537308-unsplash.jpg\"\n\ngray\nimg = cv2.medianBlur(gray,5)\n\nret, th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\nth2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,11,2)\nth3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n\ntitles = ['Original Image', 'Global Thresholding (v = 127)',\n            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\nimages = [img, th1, th2, th3]\n\nfor i in range(4):\n    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\nplt.show()\n\n# doesn't look very good","73fff245":"kernel = np.ones((5,5),np.uint8)\nerosion = cv2.erode(image, kernel, iterations=1)\n\nplt.subplot(1,2,1)\nplt.imshow(image)\nplt.subplot(1,2,2)\nplt.imshow(erosion)","38d6ebf0":"opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.subplot(1,2,1)\nplt.imshow(image)\nplt.subplot(1,2,2)\nplt.imshow(opening)","eb04f0a0":"closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.subplot(1,2,1)\nplt.imshow(image)\nplt.subplot(1,2,2)\nplt.imshow(closing)","deb7820c":"from skimage.measure import compare_ssim\nfrom skimage.transform import resize\n\nimage2 = xall[1]\n\n(score, diff) = compare_ssim(image, image2, full=True, multichannel=True)\ndiff = (diff * 255).astype(\"uint8\")\nprint(\"SSIM: {}\".format(score))","acaa5893":"### 4.5. 2D histogram","2103f068":"### 4.3. Calculate histogram\n```python\ncv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n```\n\n* **images** : it is the source image of type uint8 or float32. it should be given in square brackets, ie, \u201c[img]\u201d.\n* **channels** : it is also given in square brackets. It the index of channel for which we calculate histogram. For example, if input is grayscale image, its value is [0]. For color image, you can pass [0],[1] or [2] to calculate histogram of blue,green or red channel respectively.\n* **mask** : mask image. To find histogram of full image, it is given as \u201cNone\u201d. But if you want to find histogram of particular region of image, you have to create a mask image for that and give it as mask. (I will show an example later.)\n* **histSize** : this represents our BIN count. Need to be given in square brackets. For full scale, we pass [256].\n* **ranges** : this is our RANGE. Normally, it is [0,256].\n* **[Other references][1]**\n\n[1]: https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_histograms\/py_histogram_begins\/py_histogram_begins.html","8ca82daf":"# Image processing: PIL, imagenio, openCV\n<hr>\nLast version date: 12-09-2018\n<hr>\n\n## Table of Contents\n\n1. **Initial exploration**  \n2. **Open images with PIL Image**  \n   2.1. Blur  \n   2.2. Grayscale \/ RGB  \n   2.3. Resize \/ crop  \n   2.4. Enhance  \n   2.5. Binarize labels  \n3. **Open images with imageio**  \n4. **Open images with openCV**  \n   4.1. Trim borders  \n   4.2. Resize  \n   4.3. Calculate histogram  \n   4.4. Equalize histogram  \n   4.5. 2D histogram  \n   4.6. CLAHE  \n   4.7. Adaptive Gaussian thresholding  \n   4.8. Erosion  \n   4.9. Opening  \n   4.10. Closing  \n   4.11. Calculate image difference","1d3dfcfd":"### 2.1. Blur","af42e5ee":"### 4.11. [Calculate image difference with opencv][1]\n\nThis value gives insight about how similar two images are.\n\n[1]: https:\/\/www.pyimagesearch.com\/2017\/06\/19\/image-difference-with-opencv-and-python\/","8735555f":"### 4.4. Equalize histogram\n\n* **channels** = [0,1] because we need to process both H and S plane.\n* **bins** = [180,256] 180 for H plane and 256 for S plane.\n* **range** = [0,180,0,256] Hue value lies between 0 and 180 & Saturation lies between 0 and 256.\n* **[Other references][1]**\n\n[1]: https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_histograms\/py_2d_histogram\/py_2d_histogram.html","c4a730a6":"## 4. Open images with OpenCV (cv2)","0a79a916":"### 4.9. Opening\n(same link)","f4cdce20":"### 4.1. Trim margin","e824913e":"### 2.5. Binarize label","4619b5ce":"### 4.8. [Erosion][1]\n\n[1]: https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_morphological_ops\/py_morphological_ops.html","0db6da30":"### 4.10. Closing\n(same link)","52c875c9":"## 2. Open images with PIL Image","4801ae3f":"### 4.6 Contrast Limited Adaptive Histogram Equalization (CLAHE)\n\n[From Github][1]\n\n[1]: https:\/\/github.com\/jagracar\/OpenCV-python-tests\/blob\/master\/OpenCV-tutorials\/imageProcessing\/histogramEqualization2.py\n","62ca3eb7":"### 2.4. Enhance","d7a75856":"### 2.2. Grayscale and RGB","7a85f381":"## 3. Open images with imageio","6bf65dbb":"### 2.3. Resize \/ crop","ad8ad2d2":"## 1. Initial exploration","4976ba5f":"### 4.2. Resize","119ef703":" ### 4.7. Adaptive Gaussian thresholding\n \n [From opencv tutorial][1]\n \n[1]: https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_thresholding\/py_thresholding.html"}}