{"cell_type":{"1c74cd34":"code","a53c3194":"code","684d0805":"code","8453df48":"code","b4b6a3fa":"code","10743f7c":"code","64bace56":"code","6e6b7a0e":"code","57f46e75":"code","c3e822ce":"code","ce75e616":"code","38b48481":"code","0a07b7e5":"code","1022c5df":"code","1aa29b43":"code","3c55c28b":"code","1668c222":"code","a6c34cce":"code","f042f130":"code","64228603":"code","4ad17efa":"code","8a9ab951":"code","835a8819":"code","607060ee":"code","4d02f6d4":"code","35146d4c":"code","a00120d6":"code","14c20c34":"code","16722550":"code","f586cfd0":"code","2efdcd04":"code","2b75744b":"markdown","1dd70104":"markdown","6630dd6f":"markdown","391b2890":"markdown","e4020ad3":"markdown","fa2101ed":"markdown","a86b9fc1":"markdown","10ad4b4b":"markdown","dd6f427e":"markdown","b8eef9cf":"markdown","a07a7fcd":"markdown","d43b9254":"markdown","f83476c5":"markdown","41ad5ef6":"markdown","f389914f":"markdown","2611f65f":"markdown","6f6bb0e8":"markdown","6cd6d40a":"markdown","ad2e5d48":"markdown","538d07d3":"markdown","71e1db1a":"markdown","4f010f3c":"markdown","21b1b1e6":"markdown","111e55b5":"markdown","f4e54164":"markdown","8c3d93e6":"markdown","cfd6c0a0":"markdown","21121613":"markdown","68bd21c7":"markdown","0d16c168":"markdown","36c1e535":"markdown","3e108332":"markdown","5216cc7c":"markdown","6a4ee70a":"markdown","b1f8ddda":"markdown","ee146868":"markdown","2bc5953b":"markdown","5a6da2d7":"markdown","cd0ae86d":"markdown"},"source":{"1c74cd34":"!pip install -q joypy","a53c3194":"# Importing dependencies\n\nfrom sklearn.model_selection import KFold, train_test_split\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nimport joypy\n\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nimport gc\n\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport nibabel as nib\n\nimport h5py\n\nimport lightgbm as lgb\n\nfrom scipy.stats import skew, kurtosis\n\nimport os, random\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\n\nfrom tensorflow.keras.utils import Sequence","684d0805":"# Loading train scores\n\nMAIN_DATA_PATH = '\/kaggle\/input\/trends-assessment-prediction\/'\n\ntrain_scores_df = pd.read_csv(MAIN_DATA_PATH + 'train_scores.csv')\nicn_numbers_df = pd.read_csv(MAIN_DATA_PATH + 'ICN_numbers.csv')\nloading_df = pd.read_csv(MAIN_DATA_PATH + 'loading.csv')\nfnc_df = pd.read_csv(MAIN_DATA_PATH + 'fnc.csv')","8453df48":"train_scores_df.head()","b4b6a3fa":"# Plot the distribution of the target variables\n\nfig, ax = plt.subplots(1, 5, figsize=(20, 5))\n\nsns.distplot(train_scores_df['age'], ax=ax[0])\nax[0].set_title('Age')\n\nsns.distplot(train_scores_df['domain1_var1'], ax=ax[1])\nax[1].set_title('Domain 1 - Var 1')\n\nsns.distplot(train_scores_df['domain1_var2'], ax=ax[2])\nax[2].set_title('Domain 1 - Var 2')\n\nsns.distplot(train_scores_df['domain2_var1'], ax=ax[3])\nax[3].set_title('Domain 2 - Var 1')\n\nsns.distplot(train_scores_df['domain2_var2'], ax=ax[4])\nax[4].set_title('Domain 2 - Var 2')\n\nfig.suptitle('Target distributions', fontsize=14)","10743f7c":"# Compute statistics\n\nprint(\"Kurtosis (Fisher's definition)\")\ntrain_scores_df.kurtosis()","64bace56":"round(train_scores_df.isna().sum() \/ len(train_scores_df) * 100, 2)","6e6b7a0e":"train_scores_df.fillna(train_scores_df.mean(), inplace=True)","57f46e75":"train_scores_df.isna().sum()","c3e822ce":"loading_df.head()","ce75e616":"targets = loading_df.columns[1:]\n\nplt.figure(figsize=(16,10), dpi= 80)\nfig, axes = joypy.joyplot(loading_df, column=list(targets), ylim='own', figsize=(14,10))\n\n# Decoration\nplt.title('Source-based morphometry loadings distribution', fontsize=22)\nplt.show()","38b48481":"features_df = pd.merge(train_scores_df, loading_df, on=['Id'], how='left')\nfeatures_df.head()","0a07b7e5":"fig, ax = plt.subplots(figsize=(20, 20))\ncols = features_df.columns[1:]\nsns.heatmap(features_df[cols].corr(), annot=True, cmap='RdYlGn', ax=ax)","1022c5df":"fnc_df.head()","1aa29b43":"# No NaN values in the DataFrame\n\nfnc_df.isna().sum().sum()","3c55c28b":"features_df = pd.merge(features_df, fnc_df, how='left', on='Id')\nfeatures_df.head()","1668c222":"!wget https:\/\/github.com\/Chaogan-Yan\/DPABI\/raw\/master\/Templates\/ch2better.nii","a6c34cce":"mask_filename = '..\/input\/trends-assessment-prediction\/fMRI_mask.nii'\nsmri_filename = 'ch2better.nii'\n\nmask_niimg = nl.image.load_img(mask_filename)\n\ndef load_subject(filename, mask_niimg):\n    subject_data = None\n    \n    with h5py.File(filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n        \n    subject_data = np.moveaxis(subject_data, [0, 1, 2, 3], [3, 2, 1, 0])\n    subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n    \n    return subject_niimg ","f042f130":"fMRI_train_data_path = '..\/input\/trends-assessment-prediction\/fMRI_train\/'\nfilenames = random.choices(os.listdir(fMRI_train_data_path), k=4)","64228603":"for filename in filenames:\n    subject_filename = os.path.join(fMRI_train_data_path, filename)\n    subject_niimg = load_subject(subject_filename, mask_niimg)\n\n    print(\"Image shape is %s\" % (str(subject_niimg.shape)))\n    num_components = subject_niimg.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n\n    nlplt.plot_prob_atlas(subject_niimg, \n                          bg_img=smri_filename,\n                          view_type='filled_contours',\n                          draw_cross=False,\n                          title='All %d spatial maps' % num_components,\n                          threshold='auto')","4ad17efa":"filename = random.choice(os.listdir(fMRI_train_data_path))\nsubject_filename = os.path.join(fMRI_train_data_path, filename)\nsubject_niimg = load_subject(subject_filename, mask_niimg)\n\ngrid_size = int(np.ceil(np.sqrt(53)))\nfig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*10, grid_size*10))\n[axi.set_axis_off() for axi in axes.ravel()]\nrow = -1 \n\nfor i, cur_img in enumerate(nl.image.iter_img(subject_niimg)):\n    col = i % grid_size\n    if col == 0:\n        row += 1\n    \n    nlplt.plot_stat_map(cur_img,\n                        bg_img=smri_filename,\n                        title='IC %d' % i,\n                        axes=axes[row, col],\n                        threshold=3,\n                        colorbar=False)","8a9ab951":"# Loading \nfnc_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/fnc.csv\")\nloading_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/loading.csv\")\nlabels_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/train_scores.csv\")\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntarget_cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\ntest_df = df[df[\"is_train\"] != True].copy()\ntrain_df = df[df[\"is_train\"] == True].copy()","835a8819":"y_train_df = train_df[target_cols]\ntrain_df = train_df.drop(target_cols + ['is_train'], axis=1)\ntest_df = test_df.drop(target_cols + ['is_train'], axis=1)\n\nFNC_SCALE = 1\/500\ntest_df[fnc_features] *= FNC_SCALE\ntrain_df[fnc_features] *= FNC_SCALE","607060ee":"train_df.head()","4d02f6d4":"test_df.head()","35146d4c":"def metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)\/np.sum(y_true, axis=0))","a00120d6":"param = {'objective':'regression',\n        'metric':'rmse',\n        'bossting_type':'gbdt',\n        'learning_rate':0.01,\n        'max_depth':-1}\n\noutput = pd.DataFrame()\n\nfor target in ['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']:\n    \n    X_train, X_val, y_train, y_val = train_test_split(train_df.iloc[:,1:], y_train_df[target], test_size=0.2, shuffle=True, random_state=20)\n    train_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_val, label=y_val)\n    \n    model = lgb.train(param, \n                      train_data, \n                      10000, \n                      early_stopping_rounds=15, \n                      valid_sets=[val_data], \n                      verbose_eval=50)\n    \n    temp = pd.DataFrame(test_df['Id'].apply(lambda x:str(x)+ '_'+ target))\n    temp['Predicted'] = model.predict(test_df.iloc[:,1:])\n    output = pd.concat([output,temp])","14c20c34":"sample_submission = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv\")\noutput = sample_submission.drop('Predicted',axis=1).merge(output,on='Id',how='left')","16722550":"sub_df = pd.read_csv(\"..\/input\/trends-svc-rapids-ai\/submission.csv\")","f586cfd0":"final_sub = pd.DataFrame(data={\n    'id':sample_submission['Id'],\n    'Predicted': 0.7*output['Predicted'] + 0.3*sub_df['Predicted']\n})","2efdcd04":"sub_df.to_csv(\"submission.csv\", index=False)","2b75744b":"The distributions are bell-shaped. Age and domain 2 variables seems to have a slight skew. Furthermore, the kurtosis is small, meaning that there is not much weight in the tails.","1dd70104":"This dataframe contains static FNC correlation features for both train and test samples.\n\nAs given in the competition data summary,\n\n> The second set are static functional network connectivity (FNC) matrices. These are the subject-level cross-correlation values among 53 component timecourses estimated from group inform guided ICA of resting state functional MRI.","6630dd6f":"**Sources**: \n- https:\/\/www.healthline.com\/health\/head-mri\n- https:\/\/kids.frontiersin.org\/article\/10.3389\/frym.2019.00023\n- https:\/\/www.kaggle.com\/soham1024\/visualization-using-nilearn\n- https:\/\/www.kaggle.com\/zacktack\/data-scientist-journey-neuroimaging-lgbm\n\n**For a deeper understanding**:\n- https:\/\/www.youtube.com\/watch?v=Gpa0Pgsx7SI\n- https:\/\/www.youtube.com\/watch?v=Ok9ILIYzmaY\n\n\n**Previous competitons**: \n- https:\/\/www.kaggle.com\/c\/mlsp-2014-mri\/overview","391b2890":"## <a href=\"5-1\">Submission - Ensemble<\/a>","e4020ad3":"### <a href='#3-1'> Preparing data<\/a>","fa2101ed":"## <a id='#1'>A gentle introduction to MRI<\/a>","a86b9fc1":"## <a href='#3'>Basic modelling<\/a>","10ad4b4b":"### <a href='#3-2'> Training<\/a>","dd6f427e":"### <a id=\"#1-2\">One should not confound MRI, CT scan and X-ray...<\/a>\n\nA MRI scan is different from a CT scan or an X-ray in that **it doesn\u2019t use radiation to produce images**. An MRI scan combines images to create **a 3-D picture of your internal structures**, so it\u2019s more effective than other scans at detecting abnormalities in small structures of the brain such as the pituitary gland and brain stem. ","b8eef9cf":"Credits to: https:\/\/www.kaggle.com\/soham1024\/visualization-using-nilearn","a07a7fcd":"### <a href='#1-3'>How does a MRI actually work?<\/a>\n\nMRI allows us to see inside the human body with amazing detail, by using magnets and radio waves. The MRI scanner is essentially a giant magnet. MRI uses magnetic fields and radio waves to measure how much water is in different tissues of the body, maps the location of the water and then uses this information to generate a detailed image. The images are so detailed because our bodies are made up of around 65% water, so we have lots of signal to measure.\n\n","d43b9254":"#### Visualize independent components (IC)","f83476c5":"For this model, we will only be using basic features, and not the actual MRI image. As you'll see, the model works decently.","41ad5ef6":"\n- <a href='#1'>1. A gentle introduction to MRI<\/a>  \n     - <a href='#1-1'>1.1 What is a MRI?<\/a>\n     - <a href='#1-2'>1.2 One should not confuse MRI, CT scan and X-ray<\/a>\n     - <a href='#1-3'>1.3 How does a MRI actually work?<\/a>\n     - <a href='#1-4'>1.4 How do we translate magnetic fields into an image?<\/a>\n- <a href='#2'>2. Data exploration<\/a>\n     - <a href='#2-1'>2.1 Target distributions<\/a>\n     - <a href='#2-2'>2.2 SBM loadings<\/a>\n     - <a href='#2-3'>2.3 FNC correlation<\/a>\n     - <a href='#2-4'>2.4 Visualizing 3D spatial maps<\/a>\n- <a href='#3'>3. Basic modelling<\/a>\n     - <a href='#3-1'>3.1 Preparing data<\/a>\n     - <a href='#3-2'>3.2 Training<\/a>\n- <a href='#4'>4. Advanced modelling<\/a>\n     - <a href='#4-1'>4.1 Preparing data<\/a>\n     - <a href='#4-2'>4.2 Modelling<\/a>\n     - <a href='#4-3'>4.3 Training<\/a>\n- <a href='#5'>5. Submission<\/a>","f389914f":"![image.png](attachment:image.png)","2611f65f":"**This kenrel will be a work in progress, and I will keep on updating it as the competition progresses and I gain more insight about the data.**\n\nIf you find this kernel useful, please consider upvoting it, it motivates me to write more quality content.","6f6bb0e8":"## Contents","6cd6d40a":"### <a href='#2-1'>Target distributions<\/a>","ad2e5d48":"### <a href='#1-4'>How do we translate magnetic fields into an image?<\/a>\n\nWhen the RF pulse is turned off, the protons flip back and realign along the main magnetic field, B0. As the protons flip back and realign with B0, they give off energy. Different tissues in the body give off different amounts of energy. To measure this emitted energy, we require some special equipment (called a coil) that is placed around the body part we are imaging. The coil acts as an antenna and detects the released energy as an electrical current. The electrical current is transformed via a Fourier transform. Because protons in the different kinds of tissues in the brain, such as gray matter, white matter and blood, all give off different amounts of energy, the result of the transformed energy is a highly detailed image of the tissue inside the brain.","538d07d3":"#### If the whole body is full of hydrogen \u201cup\u201d protons all spinning at the same precessing frequency in the B0, how do we target just the ones in the brain to investigate mental health? \n\nWe use the fact that the precessional frequency of the protons is dependant on the magnetic field strength. We apply a second magnetic field, B1 that varies across the body. In the example shown in hydrogen protons in the head will then be spinning faster than those in the chest, stomach and feet. Then, we tune the RF pulse to the precessing frequency of the hydrogen protons in the head. The RF pulse will then only be resonant with the protons in the brain. Therefore, only the protons in the brain will absorb energy from the RF pulse and be flipped away from the B0 field. We can obviously tune our RF pulse to be resonant with protons in other parts of the body, like the feet, if we were interested in imaging the feet!","71e1db1a":"Since we still have relatively few features, let's investigate the correlation between target variables and features.","4f010f3c":"For a basic modelling using SVM, I hhave used RAPIDS SVM as shown in Ahmet Erdem's kernel: https:\/\/www.kaggle.com\/aerdem4\/rapids-svm-on-trends-neuroimaging and used feature engineering from https:\/\/www.kaggle.com\/jafarib\/trends-eda-fe-submission","21b1b1e6":"**We know that there is no data leakage between patients since each patient has a unique id.**","111e55b5":"Per the competition documentation,\n\n> The first set of features are source-based morphometry (SBM) loadings. These are subject-level weights from a group-level ICA (independent component analysis) decomposition of gray matter concentration maps from structural MRI (sMRI) scans.","f4e54164":"As you know, the data is multimodal, meaning that multiple features can be fed to a machine learning model. In addition to the MRI images, we are given several additional features to increase our model performance.","8c3d93e6":"Let's know build our training set composed of multiple sets of features.","cfd6c0a0":"#### What are functional network connectivity matrices?\n\nFunctional connectivity is the **connectivity between brain regions that share functional properties**. More specifically, it can be defined as the temporal correlation between spatially remote neurophysiological events, expressed as deviation from statistical independence across these events in distributed neuronal groups and areas. This applies to both resting state and task-state studies. While functional connectivity can refer to correlations across subjects, runs, blocks, trials, or individual time points, resting state functional connectivity focuses on connectivity assessed across individual BOLD time points during resting conditions. Functional connectivity has also been evaluated using the perfusion time series sampled with arterial spin labeled perfusion fMRI.\n\nSource: https:\/\/en.wikipedia.org\/wiki\/Resting_state_fMRI#Functional","21121613":"### <a href='#2-3'>FNC correlation<\/a>","68bd21c7":"### <a href='#2-4'>Visualizing 3D spatial maps<\/a>","0d16c168":"Around 7.5% of domain1_var1 and domain1_var2 are missing. An appropriate pre-processing needs to be tested. We can either drop them (not the best strategy, since we have only 5000-odd samples) or use the mean or the column (the option we choose here).","36c1e535":"### <a href='#2-2'>SBM loadings<\/a>","3e108332":"Indeed, the target variables are normally-distributed. Note that Fisher's definition means that the kurtosis of a Gaussian distribution is 0.","5216cc7c":"The train_scores.csv file contains the targets that we need to predict.","6a4ee70a":"# TReNDS Neuroimaging - Data exploration","b1f8ddda":"### <a id='#1-1'>What is a MRI?<\/a>\n\nThe Magnetisc Resonance Imaging (MRI) is non-invasive test that produces detailed images of your brain and brain stem. An MRI machnie creates the images using a magnetic field and radio waves. ","ee146868":"## <a href='#2'>Data exploration<\/a>","2bc5953b":"Using soham1024's function, we change the dimensions of the 4d array that is in the Matlab file. We flip the axes such that the first two axes are the width and height.","5a6da2d7":"Water molecule is H2O, meaning it is made up of two hydrogen atoms and one oxygen atom. Looking closer at hydrogen, we see it has central nucleus containing a single proton. Like the Earth spinning on its axis with a north and south magnetic pole, each spinning hydrogen proton is like a tiny magnet that spins around on its own axis. This spinning motion is known as precession. At any moment in time, all the billions of hydrogen protons in our bodies are all in random positions and spinning on their axes. \n\nHowever, this randomness changes when we place a human body into a very strong magnetic field, like an MRI scanner. We call the scanners magnetic field the B0 field. The hydrogen protons do not physically move in your body when you enter an MRI scanner, their axes just align along the direction of the B0 field. Some will align \u201cup\u201d (parallel) and some will align \u201cdown\u201d (anti-parallel), while still spinning around on their own axes. Due to the law of quantum physics, there are always just slightly more \u201cup\u201d protons than \u201cdown.\u201d If you now think about the total magnet field generated from all our hydrogen protons, these tiny magnets almost cancel each other out, to leave only the magnetic field from the small proportion of extra \u201cup\u201d protons, and it is this small magnetic field that we can measure using MRI.\n\nWe use something called a radio frequency (RF) pulse, to disturb or flip all the protons, at the same time, out of alignment from the scanner's magnetic field. The frequency of the RF pulse must be the same as the frequency of the spinning hydrogen protons, so they can exchange energy, so that they are in resonance with each other. Resonance enables the protons to absorb enough energy from the RF pulse to rotate their axes away from the B0 field, so that the MRI scanner can measure it. \n","cd0ae86d":"Always double-check your work..."}}