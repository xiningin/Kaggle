{"cell_type":{"5c5ff16f":"code","a98ef57c":"code","7cbeb4b3":"code","7f6eefee":"code","1124704b":"code","51a4b1e8":"code","f89727e2":"code","ff8f8e92":"code","fd3162e3":"code","ab4025cc":"code","5b78dd54":"code","9a8858bb":"code","7be78717":"code","2e5e8070":"code","805dcb12":"code","9bda0354":"code","296ce8a4":"code","6db7f73b":"code","c39d3ed0":"code","7b97e0a6":"code","ef5a1547":"code","83d71925":"code","55224fe2":"code","1abb25b8":"code","a5235be8":"code","66d600a4":"code","c389ba16":"code","76a8172f":"code","fcc665f5":"code","0f7d707b":"code","a6c2780a":"markdown","9b5e4355":"markdown","2af0e373":"markdown","41f185b7":"markdown","4ed1abc6":"markdown","481ad6fc":"markdown","b9459625":"markdown","d212c7a7":"markdown","c70c96d0":"markdown","ad82d5d5":"markdown","19419525":"markdown","0803a362":"markdown","596313a4":"markdown","9ff947c5":"markdown"},"source":{"5c5ff16f":"import pandas as pd\nimport numpy as np\n\npd.set_option('max_columns', 200)\nnp.random.seed(42)\n%config InlineBackend.figure_format = 'retina'\n\ndata = (pd\n        .read_csv('..\/input\/hair-salon-no-show-data-set\/hair_salon_no_show_wrangled_df.csv')\n        .fillna({'book_tod':'Undecided','last_category':'NotApplicable','last_staff':'NotApplicable','last_dow':'NotApplicable', 'last_tod':'NotApplicable'})\n        .drop(columns=['Unnamed: 0']))\n\ndata.head()","a98ef57c":"data.head()","7cbeb4b3":"import plotly.express as px\n\npx.pie(data, names='noshow', title='How many appointments are No-Shows?')","7f6eefee":"print(f'This dataset has {data.shape[0]} rows and {data.shape[1]-1} features')","1124704b":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef score_group(y_true, y_pred):\n    '''Closer to 0 is better'''\n    bookings = len(y_true)\n    actual_no_shows = sum(y_true)\n    expected_noshows = sum(y_pred)\n    actual_arrivals = bookings - actual_no_shows\n    predicted_arrivals = bookings - expected_noshows\n\n    return float(predicted_arrivals - actual_arrivals)\n\ndef score_predictions(y_true, y_pred, store_size=10, n_samples=1000):\n    scores = []\n    y_true = pd.Series(y_true)\n    y_pred = pd.Series(y_pred)\n    \n    for i in range(n_samples):\n        sample_ids = np.random.randint(low=0, high=len(y_true), size=store_size)\n        y_true_sample = np.take(y_true, sample_ids)\n        y_pred_sample = np.take(y_pred, sample_ids)\n        scores.append(score_group(y_true_sample, y_pred_sample))\n        \n    ax = sns.boxplot(scores)\n    ax.set_title(f'Average: {np.mean(scores):.2f}')\n    ax.set_xlabel(\"Number of extra employees\")\n    ax.set_xlim(-store_size,store_size)\n    plt.show()\n    return pd.Series(scores).describe().to_frame().T.round(3)","51a4b1e8":"# Example\ny_true = [0,0,0,1,0,0,1,0,0]\ny_pred = [0,0,0,0,0,0,0,0,1]\n\nscore_predictions(y_true, y_pred)","f89727e2":"data['noshow']","ff8f8e92":"# Example\ny_true = [0 ,  1,  0, 1, 1,  0,  1,  0,  1]\ny_pred = [.4, .4, .2, 0, 0, .1, .7, .3, .9] # Probabilities of not showing up\n\nscore_predictions(y_true, y_pred)","fd3162e3":"features = data.drop(columns=['noshow'])\ny_true = data['noshow']","ab4025cc":"y_pred = np.zeros_like(y_true)\n\nscore_predictions(y_true, y_pred)","5b78dd54":"data.head()","9a8858bb":"# https:\/\/plot.ly\/python\/parallel-categories-diagram\/\npx.parallel_categories(data, color='noshow')","7be78717":"# Sample Solution\ndef predict_on_row(row):\n    if row['book_tod'] is 'Undecided':\n        return 0.5\n    elif row['book_tod'] in ['morning','evening']:\n        return 0.05\n    else:\n        return 0.10\n    \ny_pred = features.apply(predict_on_row, axis=1)","2e5e8070":"score_predictions(y_true, y_pred)","805dcb12":"# Try writing your own rules\n\ndef predict_on_row(row):\n    if (row['last_noshow'] is 1) and (row['last_staff'] is 'NotApplicable'):\n        return 0.90\n    elif (row['last_noshow'] is 0) and (row['last_staff'] is not 'NotApplicable'):\n        return 0.05\n    else:\n        return 0.20\n    \ny_pred = features.apply(predict_on_row, axis=1)\nscore_predictions(y_true, y_pred)","9bda0354":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier(max_depth=4, random_state=2)\n\nmodel","296ce8a4":"# Example\ndf = pd.DataFrame({\n    'Col1':['A','A','B','A'],\n    'Col2':['X','Y','Y','Y']\n})\n\ndf","6db7f73b":"pd.get_dummies(df)","c39d3ed0":"X = pd.get_dummies(features)\nX.head()","7b97e0a6":"from sklearn.model_selection import cross_val_predict\n\ndef get_predictions_from_model(model, X, y):\n    y_proba = cross_val_predict(model, X, y_true, cv=5, method='predict_proba')\n    y_pred = y_proba[:,1]\n    return y_pred\n    \ny_pred = get_predictions_from_model(model, X, y_true)","ef5a1547":"score_predictions(y_true, y_pred)","83d71925":"from sklearn.tree import plot_tree\n\ndef visualize_model(model, X, y):\n    model.fit(X, y)\n    plt.figure(figsize=(50,10))\n    \n    plot_tree(model, filled=True, feature_names=X.columns, \n                  class_names=model.classes_.astype(str), \n                  proportion=True, impurity=False, rounded=True)\n    \n    plt.show()\n    \nvisualize_model(model, X, y_true)","55224fe2":"\nhelp(DecisionTreeClassifier)","1abb25b8":"model = DecisionTreeClassifier(max_depth=1, random_state=1)\n\ny_pred = get_predictions_from_model(model, X, y_true)\n\nscore_predictions(y_true, y_pred)","a5235be8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel_lr = LogisticRegression()\nmodel_rfc = RandomForestClassifier(n_estimators=100)\nmodel_knn = KNeighborsClassifier()","66d600a4":"# Experiment\n","c389ba16":"import shap\nshap.initjs()","76a8172f":"model = DecisionTreeClassifier(max_depth=5)\nmodel.fit(X,y_true)\n\nexplainer = shap.TreeExplainer(model, data=X)\nshap_values =  explainer.shap_values(X=X)[1]\n\ndef visualize_row_predictions(ix, shap_values=shap_values, features=X):\n    return shap.force_plot(np.mean(shap_values), shap_values[ix,:], feature_names=X.columns, features=features.iloc[ix,:], link='logit')","fcc665f5":"visualize_row_predictions(2)","0f7d707b":"visualize_row_predictions(190)","a6c2780a":"# Optimizing the Model","9b5e4355":"# Building a Model (and what is a model anyhow?)\n\nWe need to give every booking a probability of being a no-show.\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/b\/b8\/Apple_slicing_function.png)\n\nA **Model** is any set of assumptions and rules that let us do this.\n\nThe input is the set of features we know about each booking. e.g.\n\n    {'book_tod': 'afternoon',\n     'book_dow': 'Wednesday',\n     'book_category': 'STYLE',\n     'book_staff': 'JJ',\n     'last_category': 'NotApplicable',\n     'last_staff': 'NotApplicable',\n     'last_day_services': 0,\n     'last_receipt_tot': 0.0,\n     'last_dow': 'NotApplicable',\n     'last_tod': 'NotApplicable',\n     'last_noshow': 0,\n     'last_prod_flag': 0,\n     'last_cumrev': 0,\n     'last_cumbook': 0,\n     'last_cumstyle': 0,\n     'last_cumcolor': 0,\n     'last_cumprod': 0,\n     'last_cumcancel': 0,\n     'last_cumnoshow': 0,\n     'recency': 0}\n     \nand the output is a probability that they will be a No-Show","2af0e373":"# Baseline Model 1: What if we predicted that everyone is going to show up?","41f185b7":"# Can we help the salon owner reduce their costs without compromising service?\n\nHow can we measure this?","4ed1abc6":"# Building a Machine Learning Model\n\n![image.png](attachment:image.png)\n\nThere are many machine learning algorihms, each with dozens of variations and infinitely many configurations...\n\nExamples:\n\n- **Neighbor Algorithms**: Find similar data-points and use them to make predictions\n\n<img src=\"https:\/\/www.edureka.co\/blog\/wp-content\/uploads\/2018\/07\/KNN-Algorithm-k3-edureka-437x300.png\" width=\"200\" height=\"200\" \/>\n\n- **Suport vector machines**: Find a boundary between the samples from one type and another\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/7\/72\/SVM_margin.png\/300px-SVM_margin.png\" width=\"200\" height=\"200\" \/>\n\n- **Tree Algorithms**: Find a list questions that indicate what the prediction should be\n<img src=\"https:\/\/www.researchgate.net\/profile\/Haiqiang_Niu\/publication\/313097644\/figure\/download\/fig6\/AS:669651600158730@1536668791749\/Color-online-Decision-tree-classifier-and-corresponding-rectangular-regions-shown-for.ppm\" width=\"200\" height=\"200\" \/>","481ad6fc":"# Predicting No-Shows for a Hair Salon Owner","b9459625":"# Cross-Validation\n\n![Bias-Variance-Trade-Off](https:\/\/miro.medium.com\/max\/771\/1*cdvfzvpkJkUudDEryFtCnA.png)\n\n![Cross-Validation-Gif](https:\/\/imada.sdu.dk\/~marco\/Teaching\/AY2010-2011\/DM825\/animation.gif)","d212c7a7":"# What is the model doing?","c70c96d0":"# What is the problem we are trying to solve?","ad82d5d5":"# Other Models","19419525":"# Preparing the data\n\nScikit-Learn's implementation can't handle non-numeric features. We can use one-hot encoding (dummy columns) to turn all our data into numbers.","0803a362":"# Baseline 2: Rule Based Model\n\nCan we come up with a set of rules that generate better predictions than the rule based model?","596313a4":"# Explaining the Predictions Using SHAP","9ff947c5":"# Data Dictionary\n\nSee definitions at: https:\/\/www.kaggle.com\/frederickferguson\/hair-salon-no-show-data-set#hair_salon_no_show_wrangled_df.csv\n\n|Column | Meaning |\n|-------|---------|\n|book_tod |The booking time of day.|\n|book_dow|The booking day-of-week.|\n|book_category|The booked service category (COLOR or STYLE)|\n|book_staff|The staff member to provide the service.|\n|last_category|The client's last booked service category before the current booking or today whichever is greater.|\n|last_staff|The staff member who provided the client's last service before the current booking or today whichever is greater.|\n|last_day_services|The number of services provided to the client on their last visit before the current booking or today whichever is greater.|\n|last_receipt_tot|The amount paid by the client on their last visit before the current booking or today whichever is greater.|\n|last_dow|The day-of-week of the client's last booking before before the current booking or today whichever is greater.|\n|last_tod|The time-of-day of the client's last booking before the current booking or today whichever is greater.|\n|last_noshow|Did the client no-show on their last booking before the current booking or today whichever is greater? (0 - no, 1 - yes)|\n|last_prod_flag|Did the client buy a retail product on their last booking before the current booking or today whichever is greater? (0 - no, 1 - yes)|\n|last_cumrev|The client's cumulative service revenue as of their last booking before the current booking or today whichever is greater.|\n|last_cumbook|The client's cumulative number of bookings as of their last booking before the current booking or today whichever is greater.|\n|last_cumstyle|The client's cumulative number of STYLE bookings as of their last booking before the current booking or today whichever is greater.|\n|last_cumcolor|The client's cumulative number of COLOR bookings as of their last booking before the current booking or today whichever is greater.|\n|last_cumprod|The client's cumulative number of bookings with retail product purchases as of their last booking before the current booking or today whichever is greater.|\n|last_cumcancel|The client's cumulative number of appointment cancellations as of their last booking before the current booking or today whichever is greater.|\n|last_cumnoshow|The client's cumulative number of no-shows as of their last booking before the current booking or today whichever is|"}}