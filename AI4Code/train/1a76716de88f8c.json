{"cell_type":{"09d6a07d":"code","17df75a8":"code","3a13b778":"code","5d71c265":"code","2ef3cd9d":"code","51455ddf":"code","6bd42f4c":"markdown","de30add2":"markdown","98b549f7":"markdown"},"source":{"09d6a07d":"import numpy as np\nfrom keras import layers\nfrom keras import models\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n","17df75a8":"# Split images into Training and Validation (20%)\n\ntrain = ImageDataGenerator(rescale=1.\/255,horizontal_flip=True, shear_range=0.2, zoom_range=0.2,width_shift_range=0.2,height_shift_range=0.2, fill_mode='nearest', validation_split=0.2)\n\nimg_size = 128\nbatch_size = 20\nt_steps = 3462\/batch_size\nv_steps = 861\/batch_size\n\ntrain_gen = train.flow_from_directory(\"..\/input\/flowers\/flowers\", target_size = (img_size, img_size), batch_size = batch_size, class_mode='categorical', subset='training')\nvalid_gen = train.flow_from_directory(\"..\/input\/flowers\/flowers\/\", target_size = (img_size, img_size), batch_size = batch_size, class_mode = 'categorical', subset='validation')","3a13b778":"# Model\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_size,img_size,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(5, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","5d71c265":"model_hist = model.fit_generator(train_gen, steps_per_epoch=t_steps, epochs=20, validation_data=valid_gen, validation_steps=v_steps)","2ef3cd9d":"model.save('flowers_model.h5')","51455ddf":"acc = model_hist.history['acc']\nval_acc = model_hist.history['val_acc']\nloss = model_hist.history['loss']\nval_loss = model_hist.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize=(15, 6));\nplt.subplot(1,2,1)\nplt.plot(epochs, acc, color='#0984e3',marker='o',linestyle='none',label='Training Accuracy')\nplt.plot(epochs, val_acc, color='#0984e3',label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend(loc='best')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(epochs, loss, color='#eb4d4b', marker='o',linestyle='none',label='Training Loss')\nplt.plot(epochs, val_loss, color='#eb4d4b',label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend(loc='best')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","6bd42f4c":"**Standard Conv2D model used, with the addition of a Dropout to help decrease the amount of overfitting.**","de30add2":"**Here is my current attempt at a classification model using convolutional networks in Keras.**","98b549f7":"**I implemented the ImageDataGenerator for augmentation of the image set. A 20% split leaves only 3462 images for training 5 different flowers. This should marginally improve validation without the use of a pre-trained network.**"}}