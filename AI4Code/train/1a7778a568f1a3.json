{"cell_type":{"60d5cbea":"code","9b7016b1":"code","e61915b9":"code","c7111e72":"code","9c94118c":"code","fdb4e613":"code","e750db43":"code","1ea2beaa":"code","a8cabe2d":"code","9854d7e7":"code","2ae69cfe":"code","d36ef0ef":"code","b2a34f1d":"code","d86d9e15":"code","b3041f48":"code","4fafeae0":"code","4f703247":"markdown","5df6ee2b":"markdown","4edb4297":"markdown","221087d4":"markdown","5ec41bfc":"markdown","3c5c7590":"markdown"},"source":{"60d5cbea":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler","9b7016b1":"digits, y = load_digits(return_X_y = True)","e61915b9":"plt.matshow(digits[6].reshape(8,8)) ","c7111e72":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, Ytrain, Ytest = train_test_split(digits,y,test_size=0.2)","9c94118c":"scaler = StandardScaler()\nscaler.fit(Xtrain)\nXtrain_scaled = scaler.transform(Xtrain)\n\n\"\"\"scaler.fit(Ytrain.reshape(-1,1))\nYtrain_scaled = scaler.transform(Ytrain.reshape(-1,1))\"\"\"\n\nscaler = StandardScaler()\nscaler.fit(Xtest)\nXtest_scaled = scaler.transform(Xtest)","fdb4e613":"Xtrain_scaled.shape","e750db43":"pca = PCA()\npca.fit(Xtrain_scaled)\nXtrain_pca = pca.transform(Xtrain_scaled)","1ea2beaa":"expl = pca.explained_variance_ratio_\nprint('suma:',sum(expl[0:-1]))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')\nplt.show()\n ","a8cabe2d":"pca.components_","9854d7e7":"var_exp = 0.95\nMv = np.min(np.where(np.cumsum(pca.explained_variance_ratio_)\n                         >var_exp))\nM,P = pca.components_.shape\n#print(P,M)\nrel_vec = np.zeros((P))\nfor i in range(Mv):\n    #print(i)\n    rel_vec += abs(pca.explained_variance_ratio_[i]*pca.components_[i,:])\nrel_vec = rel_vec\/sum(rel_vec)\nrel_vec = rel_vec - min(rel_vec)\nrel_vec = rel_vec\/max(rel_vec)","2ae69cfe":"rel_vec","d36ef0ef":"plt.imshow(rel_vec.reshape(8,8),cmap='jet')\nplt.colorbar()","b2a34f1d":"import seaborn as sns","d86d9e15":"sns.heatmap(abs((sum(pca.components_)\/len(pca.components_)).reshape(8,8)))","b3041f48":"knn = KNeighborsClassifier(n_neighbors=14)# Seria el maximo numero de neighbors recomendable\nknn.fit(Xtrain_pca,Ytrain)\nypredict = knn.predict(Xtrain_pca)","4fafeae0":"np.sum(ypredict == Ytrain) \/ len(Ytrain)","4f703247":"Para establecer el numero de componentes principales establecimos un porcentaje de Explained variation, en este caso 90%. Este criterio esta bien?","5df6ee2b":"Al minimizar el numero de n_neighbors el modelo se sobreajusta, para evitar ese variamos entre 7 y 20, pero a partir del 15 los aciertos bajan del 95%, que creemos es un buen porcentaje.","4edb4297":"Los pixeles con mayor importancia para la clasificaci\u00f3n deberian ser los centrales.","221087d4":"Variamos los n_components y comprobamos que entre mayor sea, la eficiencia de la clasificacion tambien sera mayor. Pero con el fin de extraer mejor la informaci\u00f3n:","5ec41bfc":"Creemos que el metodo de arriba es el mas acertado pero no estamos seguros, de todos modos intentamos sacar la relevancia de una manera mas simple.","3c5c7590":"Para analizar la relevancia de cada pixel decidimos dejar el numero de componentes de forma default, es decir con los 64 componentes configurados en pca"}}