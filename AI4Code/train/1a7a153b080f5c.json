{"cell_type":{"ce351226":"code","e7ec8607":"code","cc34314d":"code","7f08d46c":"code","de2973c7":"code","50d3bc4e":"code","851a86da":"code","544a6930":"code","ccf0ec01":"code","1a8e826b":"code","878c8e82":"code","03ac3cf5":"code","445bc137":"markdown","cf9f2832":"markdown","3fe937d7":"markdown","80ba74d7":"markdown"},"source":{"ce351226":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7ec8607":"!pip install transformers==4.6.1","cc34314d":"import torchvision\nfrom torchvision.transforms import ToTensor\n\ntrain_ds = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/train', transform=ToTensor())\nvalid_ds = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/valid', transform=ToTensor())\ntest_ds = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/test', transform=ToTensor())","7f08d46c":"from transformers import ViTModel\nfrom transformers.modeling_outputs import SequenceClassifierOutput\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ViTForImageClassification(nn.Module):\n    def __init__(self, num_labels=10):\n        super(ViTForImageClassification, self).__init__()\n        self.vit = ViTModel.from_pretrained('google\/vit-base-patch16-224-in21k')\n        self.dropout = nn.Dropout(0.15)\n        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n        self.num_labels = num_labels\n\n    def forward(self, pixel_values, labels):\n        outputs = self.vit(pixel_values=pixel_values)\n        output = self.dropout(outputs.last_hidden_state[:,0])\n        logits = self.classifier(output)\n\n        loss = None\n        if labels is not None:\n          loss_fct = nn.CrossEntropyLoss()\n          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        if loss is not None:\n          return logits, loss.item()\n        else:\n          return logits, None","de2973c7":"EPOCHS = 10\nBATCH_SIZE = 16\nLEARNING_RATE = 2e-5","50d3bc4e":"from transformers import ViTFeatureExtractor\nimport torch.nn as nn\nimport torch\n# Define Model\nmodel = ViTForImageClassification(len(train_ds.classes))    \n# Feature Extractor\nfeature_extractor = ViTFeatureExtractor.from_pretrained('google\/vit-base-patch16-224-in21k')\n# Adam Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n# Cross Entropy Loss\nloss_func = nn.CrossEntropyLoss()\n# Use GPU if available  \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \nif torch.cuda.is_available():\n    model.cuda() ","851a86da":"import torch.utils.data as data\nfrom torch.autograd import Variable\nimport numpy as np\n\nprint(\"Number of train samples: \", len(train_ds))\nprint(\"Number of test samples: \", len(test_ds))\nprint(\"Detected Classes are: \", train_ds.class_to_idx) \n\ntrain_loader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\ntest_loader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) \n\n# Train the model\nfor epoch in range(EPOCHS):        \n  for step, (x, y) in enumerate(train_loader):\n    # Change input array into list with each batch being one element\n    if x.shape[0] != BATCH_SIZE:\n      continue\n    x = np.split(np.squeeze(np.array(x)), BATCH_SIZE)\n    # Remove unecessary dimension\n    for index, array in enumerate(x):\n      x[index] = np.squeeze(array)\n    # Apply feature extractor, stack back into 1 tensor and then convert to tensor\n    x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n    # Send to GPU if available\n    x, y  = x.to(device), y.to(device)\n    b_x = Variable(x)   # batch x (image)\n    b_y = Variable(y)   # batch y (target)\n    # Feed through model\n    output, loss = model(b_x, None)\n    # Calculate loss\n    if loss is None: \n      loss = loss_func(output, b_y)   \n      optimizer.zero_grad()           \n      loss.backward()                 \n      optimizer.step()\n\n    if step % 50 == 0:\n      # Get the next batch for testing purposes\n      test = next(iter(test_loader))\n      test_x = test[0]\n      # Reshape and get feature matrices as needed\n      test_x = np.split(np.squeeze(np.array(test_x)), BATCH_SIZE)\n      for index, array in enumerate(test_x):\n        test_x[index] = np.squeeze(array)\n      test_x = torch.tensor(np.stack(feature_extractor(test_x)['pixel_values'], axis=0))\n      # Send to appropirate computing device\n      test_x = test_x.to(device)\n      test_y = test[1].to(device)\n      # Get output (+ respective class) and compare to target\n      test_output, loss = model(test_x, test_y)\n      test_output = test_output.argmax(1)\n      # Calculate Accuracy\n      accuracy = (test_output == test_y).sum().item() \/ BATCH_SIZE\n      print('Epoch: ', epoch, '| train loss: %.4f' % loss, '| test accuracy: %.2f' % accuracy)","544a6930":"import matplotlib.pyplot as plt\nimport numpy as np\n\nEVAL_BATCH = 1\neval_loader  = data.DataLoader(valid_ds, batch_size=EVAL_BATCH, shuffle=True, num_workers=4) \n# Disable grad\nwith torch.no_grad():\n    \n  inputs, target = next(iter(eval_loader))\n  # Reshape and get feature matrices as needed\n  inputs = np.squeeze(np.array(inputs))\n  for index, array in enumerate(inputs):\n    inputs[index] = np.squeeze(array)\n  inputs = torch.tensor(np.stack(feature_extractor(inputs)['pixel_values'], axis=0))\n  # Send to appropriate computing device\n  inputs = inputs.to(device)\n  target = target.to(device)\n \n  # Generate prediction\n  prediction, loss = model(inputs, target)\n    \n  # Predicted class value using argmax\n  predicted_class = np.argmax(prediction.cpu())\n  value_predicted = list(valid_ds.class_to_idx.keys())[list(valid_ds.class_to_idx.values()).index(predicted_class)]\n  value_target = list(valid_ds.class_to_idx.keys())[list(valid_ds.class_to_idx.values()).index(target)]\n    \n  # Reshape image\n  inputs = inputs.cpu().reshape(224, 224,3)\n    \n  # Show result\n  plt.imshow(np.array(inputs))\n  plt.xlim(50,0)\n  plt.ylim(50,0)\n  plt.title(f'Prediction: {value_predicted} - Actual target: {value_target}')\n  plt.show()","ccf0ec01":"from tqdm.notebook import tqdm\ny_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    for x_batch, y_batch in tqdm(test_loader):\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        # Generate prediction\n        prediction,loss = model(x_batch, y_batch)\n        \n        y_test_pred = np.argmax(prediction.cpu())\n        \n        value_predicted = list(valid_ds.class_to_idx.keys())[list(valid_ds.class_to_idx.values()).index(predicted_class)]\n        value_target = list(valid_ds.class_to_idx.keys())[list(valid_ds.class_to_idx.values()).index(target)]\n        \n        y_pred_list.append(value_predicted)\n        y_true_list.append(value_target)","1a8e826b":"import helper\n\nimages, labels = next(iter(test_loader))\nimages[5]","878c8e82":"torch.save(model, '.\/model.pt')","03ac3cf5":"model.eval()","445bc137":"## Dependency","cf9f2832":"## Define the Model","3fe937d7":"## Train the Model","80ba74d7":"## Define the Model Parameters"}}