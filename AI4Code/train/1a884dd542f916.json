{"cell_type":{"14ad64d6":"code","dc2c0a5f":"code","08d0a232":"code","e849dc75":"code","cb60bf09":"code","2cf748df":"code","a7d1fe1f":"code","29b2dc2b":"code","b3fff8c3":"code","8396d2fd":"code","df6e8384":"code","c5eafb7d":"code","66c7ef5b":"code","6f47ee65":"code","935c7a8b":"code","0ef7d013":"code","8cddb5ee":"code","5f154797":"code","96983003":"code","429008d6":"code","bc2987e7":"code","7e2be364":"code","eba5e737":"code","568e48f0":"markdown","c52a423d":"markdown","3cf901fc":"markdown","862fef94":"markdown","db41964c":"markdown","12836af4":"markdown","86676183":"markdown","69e5f522":"markdown","07c68189":"markdown","281b7216":"markdown","56782ad6":"markdown","d9d26025":"markdown","943bf7b5":"markdown","e6a9e584":"markdown","cadb02fc":"markdown","573505d5":"markdown","d6b31154":"markdown","f6fe2485":"markdown","190a23d0":"markdown","c9b24715":"markdown","258549b7":"markdown","12abb902":"markdown","3553135e":"markdown","37fedaec":"markdown","e7881ee9":"markdown"},"source":{"14ad64d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc2c0a5f":"#Code By Paul Mooney\n\nfauci_file = '..\/input\/anthony-fauci-emails-the-face-of-us-on-covid\/leopold-nih-foia-anthony-fauci-emails.txt'\nwith open(fauci_file, encoding = 'ISO-8859-2') as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","08d0a232":"df = pd.DataFrame(\n    {\n        \"text\": [\n            \"Fauci, Anthony,NIH\",\"NIAID,Please review:\",\"House Oversight Letter on Coronavirus Diagnostics\", \"I do not understand\", \"why you are asking me\", \"to review this\", \" Is this an FYI??\",\n            123,\n            np.nan,\n            \"NULL\",\n        ]\n    }\n)\ndf","e849dc75":"!pip install dataprep","cb60bf09":"from dataprep.clean import clean_text\nclean_text(df, \"text\")","2cf748df":"from dataprep.clean import clean_text\nclean_text(df, \"text\", stopwords={\"on\", \"an\"})","a7d1fe1f":"custom_pipeline = [\n    {\"operator\": \"lowercase\"},\n    {\"operator\": \"remove_digits\"},\n    {\"operator\": \"remove_whitespace\"},\n]\nclean_text(df, \"text\", pipeline=custom_pipeline)","29b2dc2b":"import re\n\ndef split(text: str) -> str:\n    return str(text).split()\n\ndef replace_z(text: str, value: str) -> str:\n    return re.sub(r\"z\", value, str(text), flags=re.I)\n\ncustom_pipeline = [\n    {\"operator\": \"lowercase\"},\n    {\"operator\": \"remove_digits\"},\n    {\"operator\": split},\n    {\"operator\": replace_z, \"parameters\": {\"value\": \"*\"}},\n    {\"operator\": \"remove_whitespace\"},\n]\nclean_text(df, \"text\", pipeline=custom_pipeline)","b3fff8c3":"custom_pipeline = [\n    {\n        \"operator\": \"<operator_name>\",\n        \"parameters\": {\"<parameter_name>\": \"<parameter_value>\"},\n    }\n]","8396d2fd":"from dataprep.clean import default_text_pipeline\ndefault_text_pipeline()","df6e8384":"custom_pipeline = [{\"operator\": \"fillna\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","c5eafb7d":"custom_pipeline = [{\"operator\": \"fillna\", \"parameters\": {\"value\": \"<NAN>\"}}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","66c7ef5b":"custom_pipeline = [{\"operator\": \"lowercase\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","6f47ee65":"custom_pipeline = [{\"operator\": \"sentence_case\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","935c7a8b":"custom_pipeline = [{\"operator\": \"title_case\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","0ef7d013":"custom_pipeline = [{\"operator\": \"uppercase\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","8cddb5ee":"custom_pipeline = [{\"operator\": \"remove_accents\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","5f154797":"custom_pipeline = [\n    {\"operator\": \"remove_bracketed\", \"parameters\": {\"brackets\": \"round\"}}\n]\nclean_text(df, \"text\", pipeline=custom_pipeline)","96983003":"custom_pipeline = [\n    {\n        \"operator\": \"remove_bracketed\",\n        \"parameters\": {\"brackets\": \"round\", \"inclusive\": False},\n    }\n]\nclean_text(df, \"text\", pipeline=custom_pipeline)","429008d6":"custom_pipeline = [\n    {\n        \"operator\": \"remove_bracketed\",\n        \"parameters\": {\"brackets\": {\"angle\", \"curly\", \"round\", \"square\"}},\n    }\n]\nclean_text(df, \"text\", pipeline=custom_pipeline)","bc2987e7":"custom_pipeline = [{\"operator\": \"remove_digits\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","7e2be364":"custom_pipeline = [{\"operator\": \"remove_html\"}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","eba5e737":"custom_pipeline = [{\"operator\": \"replace_stopwords\", \"parameters\": {\"value\": \"<S>\"}}]\nclean_text(df, \"text\", pipeline=custom_pipeline)","568e48f0":"#To get the default pipeline in the form of a list, call default_text_pipeline().\n\n#This can be used as a template to build a list of cleaning operations to be passed into the pipeline parameter.","c52a423d":"#Users can also define and pass in their own functions using the pipeline parameter.","3cf901fc":"#replace_stopwords\n\nReplace common words with the value. By default, the set of stopwords to replace is NLTK\u2019s English stopwords.","862fef94":"#uppercase\n\nConvert all characters to uppercase.","db41964c":"![](https:\/\/media0.giphy.com\/media\/ej2J5DVP7LeVDZo7AZ\/giphy.gif)giphy.com","12836af4":"#To specify a specific value to replace null values, use the value parameter.","86676183":"#title_case\n\nConvert the first character of each word to uppercase and the remaining words to lowercase.","69e5f522":"#In general, custom pipelines can be defined using the form:","07c68189":"#Commas removed, Null became Nan and now text in lower case.","281b7216":"#Custom pipeline\n\nUsers can pass in a custom pipeline to clean_text() using the pipeline parameter.","56782ad6":"#The brackets parameter can also take in a set, which allows multiple bracket styles to be specified at a time.","d9d26025":"#lowercase\n\nConvert all characters to lowercase.","943bf7b5":"#Removing stopwords.","e6a9e584":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 20px; background: #001f3f;\"><i><b style=\"color:orange;\">Dataprep Clean<\/b><\/i><\/h1><\/center>\n\n\nDataPrep.Clean provides functions for quickly and easily cleaning and validating your data.\n\nSection Contents: Column Headers, Country Names, Dates and Times, Duplicate Values, Email Addresses,\n\nGeographic Goordinates, IP Addresses, Phone Numbers, Text, URLs, US Street Addresses, Whole DataFrame\n\n\nDataprep is an initiative by SFU Data Science Research Group to speed up Data Science.\n\nAcknowlegdements\n\nSFU Data Science Research Group - SIMON FRASER UNIVERSITY\n\nhttps:\/\/docs.dataprep.ai\/user_guide\/clean\/introduction.html\n\nhttps:\/\/dataprep.ai\/\n","cadb02fc":"#To remove the text but keep the brackets, set inclusive to False.","573505d5":"#remove_accents\n\nRemove accents (diacritic marks) from the text.","d6b31154":"![](https:\/\/media4.giphy.com\/media\/qlKet9iC1Woo7g5HO7\/200w.gif)giphy.com","f6fe2485":"#remove_digits\n\nRemove all digits.","190a23d0":"#sentence_case\n\nConvert the first character of the string to uppercase and all remaining characters to lowercase.","c9b24715":"#Built-in functions\n\nThis section demonstrates the built-in cleaning operations which can be called using the pipeline parameter.\n\nclean_text() assumes the DataFrame column contains text data. As such, any int values will be cast to str after applying a cleaning function.\n\n#fillna\n\nBy default, fillna replaces all null values with NaN.","258549b7":"#remove_html\n\nRemove HTML tags, including the non-breaking space &nbsp;.","12abb902":"#Thanks to Dataprep Clean - SFU Data Science Research Group - SIMON FRASER UNIVERSITY\n\n#https:\/\/docs.dataprep.ai\/user_guide\/clean\/introduction.html","3553135e":"#We must type quotation marks and separate with commas each part. So that it will be divided in columns.","37fedaec":"#remove_bracketed\n\nRemove text between brackets.\n\nThe style of the brackets can be specified using the brackets parameter:\n\n\u201cangle\u201d: <>\n\n\u201ccurly\u201d: {}\n\n\u201cround\u201d: ()\n\n\u201csquare\u201d: []\n\nBy default, the inclusive parameter is set to True and the brackets are removed along with the text in between.","e7881ee9":"#Do Not Remove your Masks!\n\nTill the Pandemic is gone."}}