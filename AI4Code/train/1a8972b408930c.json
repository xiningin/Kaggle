{"cell_type":{"0a1f9c7e":"code","5faef0ad":"code","3c2d234b":"code","beffc00c":"code","1b34df03":"code","efb30ca2":"code","67a2566c":"code","266e17db":"code","93e75469":"code","a0351d6b":"code","1e31b538":"code","91636524":"code","715c4a91":"code","16d53b1e":"code","6e05299e":"code","9d9ab9cf":"code","3714571b":"code","04643e1b":"code","c4de03ab":"code","61679691":"code","fb0f4594":"code","b74f2745":"code","55e97e79":"code","afa0f520":"code","a76b0ca2":"code","c579340f":"code","863b83ad":"code","0cb9906e":"code","2d926f10":"code","2b9768a1":"code","87aa2031":"code","c50c8e74":"markdown","fcd4dec6":"markdown","ed36fcd1":"markdown","455cd8d7":"markdown","e07d0b34":"markdown","dd346846":"markdown","913fae4c":"markdown","9ff5b80b":"markdown","0b5a4e17":"markdown","5d65c49f":"markdown","34f59d4c":"markdown","f1b1097a":"markdown","6b66bca3":"markdown"},"source":{"0a1f9c7e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","5faef0ad":"Puro = np.load('..\/input\/train_images_pure.npy')\nplt.subplot(141)\nplt.imshow(Puro[0], cmap=plt.get_cmap('gray'))\nplt.subplot(142)\nplt.imshow(Puro[1], cmap=plt.get_cmap('gray'))\nplt.subplot(143)\nplt.imshow(Puro[2], cmap=plt.get_cmap('gray'))\nplt.subplot(144)\nplt.imshow(Puro[3], cmap=plt.get_cmap('gray'))\nplt.show()","3c2d234b":"Rot = np.load('..\/input\/train_images_rotated.npy')\nplt.subplot(141)\nplt.imshow(Rot[0], cmap=plt.get_cmap('gray'))\nplt.subplot(142)\nplt.imshow(Rot[1], cmap=plt.get_cmap('gray'))\nplt.subplot(143)\nplt.imshow(Rot[2], cmap=plt.get_cmap('gray'))\nplt.subplot(144)\nplt.imshow(Rot[3], cmap=plt.get_cmap('gray'))\nplt.show()","beffc00c":"Ruido = np.load('..\/input\/train_images_noisy.npy')\nplt.subplot(141)\nplt.imshow(Ruido[0], cmap=plt.get_cmap('gray'))\nplt.subplot(142)\nplt.imshow(Ruido[1], cmap=plt.get_cmap('gray'))\nplt.subplot(143)\nplt.imshow(Ruido[2], cmap=plt.get_cmap('gray'))\nplt.subplot(144)\nplt.imshow(Ruido[3], cmap=plt.get_cmap('gray'))\nplt.show()","1b34df03":"Tudo = np.load('..\/input\/train_images_both.npy')\nplt.subplot(141)\nplt.imshow(Tudo[0], cmap=plt.get_cmap('gray'))\nplt.subplot(142)\nplt.imshow(Tudo[1], cmap=plt.get_cmap('gray'))\nplt.subplot(143)\nplt.imshow(Tudo[2], cmap=plt.get_cmap('gray'))\nplt.subplot(144)\nplt.imshow(Tudo[3], cmap=plt.get_cmap('gray'))\nplt.show()","efb30ca2":"Teste = np.load('..\/input\/Test_images.npy')\nplt.subplot(141)\nplt.imshow(Teste[0], cmap=plt.get_cmap('gray'))\nplt.subplot(142)\nplt.imshow(Teste[1], cmap=plt.get_cmap('gray'))\nplt.subplot(143)\nplt.imshow(Teste[2], cmap=plt.get_cmap('gray'))\nplt.subplot(144)\nplt.imshow(Teste[3], cmap=plt.get_cmap('gray'))\nplt.show()","67a2566c":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping","266e17db":"semente = 7\nnp.random.seed(semente)","93e75469":"Y = pd.read_csv(\"..\/input\/train_labels.csv\",index_col=0)","a0351d6b":"Xfit = Puro.reshape(Rot.shape[0], 1, 28, 28).astype('float32')\nXteste = Rot.reshape(Rot.shape[0], 1, 28, 28).astype('float32')\nXteste2 = Tudo.reshape(Rot.shape[0], 1, 28, 28).astype('float32')\nXfit = Xfit \/ 255\nXteste = Xteste \/ 255\nXteste2 = Xteste2 \/ 255\n\nYfit = np_utils.to_categorical(Y)\nnum_classes = Yfit.shape[1]\n\nXtreino,Xvalid,Ytreino,Yvalid = train_test_split(Xfit,Yfit, test_size = 0.2)","1e31b538":"def baseline_modelo1():\n    modelo1 = Sequential()\n    modelo1.add(Conv2D(32, (5,5), input_shape=(1, 28, 28), activation='relu'))\n    modelo1.add(Dropout(0.2))\n    modelo1.add(Flatten())\n    modelo1.add(Dense(128, activation='relu'))\n    modelo1.add(Dense(num_classes, activation='softmax'))\n    modelo1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return modelo1","91636524":"# build the model\nmodelo1 = baseline_modelo1()\nmodelo1.summary()","715c4a91":"callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)]","16d53b1e":"modelo1.fit(Xtreino, Ytreino, validation_data=(Xvalid,Yvalid), epochs=20, \n          batch_size=400, verbose=1, callbacks = callbacks)\n#Foi utilizado epochs=20","6e05299e":"scores = modelo1.evaluate(Xteste, Yfit, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","9d9ab9cf":"scores = modelo1.evaluate(Xteste2, Yfit, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","3714571b":"from keras.layers.convolutional import MaxPooling2D\ndef baseline_modelo2():\n    modelo2 = Sequential()\n    modelo2.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n    modelo2.add(MaxPooling2D(pool_size=(2, 2)))\n    modelo2.add(Dropout(0.2))\n    modelo2.add(Flatten())\n    modelo2.add(Dense(128, activation='relu'))\n    modelo2.add(Dense(num_classes, activation='softmax'))\n    modelo2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return modelo2","04643e1b":"modelo2 = baseline_modelo2()\nmodelo2.summary()","c4de03ab":"modelo2.fit(Xtreino, Ytreino, validation_data=(Xvalid,Yvalid), epochs=20, \n          batch_size=400, verbose=1, callbacks = callbacks)\n#Foi utilizado epochs=20","61679691":"scores = modelo2.evaluate(Xteste, Yfit, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","fb0f4594":"scores = modelo2.evaluate(Xteste2, Yfit, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","b74f2745":"Xnovo = Tudo.reshape(Rot.shape[0], 1, 28, 28).astype('float32')\nXnovo = Xnovo\/255\n\nYnovo = np_utils.to_categorical(Y)\n\nXt,Xv,Yt,Yv = train_test_split(Xnovo,Ynovo, test_size = 0.2)","55e97e79":"Teste = np.load('..\/input\/Test_images.npy')\nTeste = Teste.reshape(Teste.shape[0], 1, 28, 28).astype('float32')","afa0f520":"def modelo():\n    modelo = Sequential()\n    modelo.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n    modelo.add(Conv2D(15, (3, 3), activation='relu'))\n    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n    modelo.add(Dropout(0.2))\n    modelo.add(Flatten())\n    modelo.add(Dense(128, activation='relu'))\n    modelo.add(Dense(50, activation='relu'))\n    modelo.add(Dense(num_classes, activation='softmax'))\n    modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return modelo","a76b0ca2":"modelo = modelo()\nmodelo.summary()","c579340f":"modelo.fit(Xt, Yt, validation_data=(Xv,Yv), epochs=20, \n          batch_size=200, verbose=1, callbacks = callbacks)\n#Foi utilizado epochs=20","863b83ad":"def encode(p):\n    resp=[]\n    for linha in p:\n        flag=False\n        for j in range(len(linha)):\n            if linha[j]==1:\n                resp.append(j)\n                flag=True\n        if not flag:\n            resp.append(8)\n    return resp","0cb9906e":"Pred1 = modelo1.predict(Teste)\n","2d926f10":"Pred2 = modelo2.predict(Teste)","2b9768a1":"Pred = modelo.predict(Teste)","87aa2031":"P1 = pd.DataFrame(columns = ['Id','label'])\nP1.label = encode(Pred1)\nP1.Id = range(len(Teste))\nP1.to_csv(\"Pred1.csv\",index=False)\n\nP2 = pd.DataFrame(columns = ['Id','label'])\nP2.label = encode(Pred2)\nP2.Id = range(len(Teste))\nP2.to_csv(\"Pred2.csv\",index=False)\n\nP = pd.DataFrame(columns = ['Id','label'])\nP.label = encode(Pred)\nP.Id = range(len(Teste))\nP.to_csv(\"Pred.csv\",index=False)","c50c8e74":"Vamos treinar modificando nossa base original com os mesmos problemas que iremos enfrentar na base de Teste. Note que na base Tudo ('train_images_both.npy') isso j\u00e1 foi feito.","fcd4dec6":"## Parte II","ed36fcd1":"## Parte Extra: Single Pixel Attack","455cd8d7":"Um pixel com uma determinada cor e situado em uma posi\u00e7\u00e3o espec\u00edfica da imagem, que representa um ponto de confian\u00e7a para alguma determinada classe de objeto, pode resultar na classifica\u00e7\u00e3o errada da figura.","e07d0b34":"<br\/>\nVamos olhar a base de Teste!<br\/><br\/>","dd346846":"<br\/>\nFoi obtido maior acur\u00e1cia na base rotacionada com 53%\n<br\/>Enquanto na base Tudo foi obtido apenas 46,5%\n<br\/><br\/>","913fae4c":"<br\/> Ap\u00f3s a explora\u00e7\u00e3o, ficou claro a diferen\u00e7a entre as bases.<br\/> <br\/> \n\nBase Puro   (train_images_pure.npy): As imagens est\u00e3o intactas;<br\/> \nBase Rot (train_images_rotated.npy): As imagens foram rotacionadas;<br\/> \nBase Ru\u00eddo (train_images_noisy.npy): As imagens est\u00e3o com ruidos mas orientadas corretamente;<br\/> \nBase Tudo   (train_images_both.npy): As imagens apresentam ru\u00eddos e orienta\u00e7\u00f5es aleat\u00f3rias. <br\/>\n\nA base de teste (Test_images.npy) possui imagens corrompidas semelhantes as figuras encontradas na base Tudo (train_images_both.npy), mas notamos que est\u00e3o levemente distintas no angulo de orienta\u00e7\u00e3o e no pixels atingidos pelo ru\u00eddo <br\/><br\/>","9ff5b80b":"# <br\/> Atividade 4 - Versao 2- Fashion Mnist - 08dbd26023<br\/>","0b5a4e17":"<br\/>Foi obtido um resultado semelhante ao anterior na base rotacionada utilizando pooling\n<br\/>Na base Tudo foi obtido uma acur\u00e1cia de 37%, piorando em rela\u00e7\u00e3o ao modelo anterior\n<br\/><br\/>","5d65c49f":"## <br\/> Parte I\nVamos explorar as bases de treino <br\/> <br\/> \n","34f59d4c":"## Parte II","f1b1097a":"Predi\u00e7\u00e3o:","6b66bca3":"## Parte Extra: Melhorando o classificador\npr\u00e9-processamento"}}