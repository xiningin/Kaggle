{"cell_type":{"f695e871":"code","c5330ceb":"code","3adb52fb":"code","bfc2e235":"code","2470268f":"code","1d265124":"code","36ea5392":"code","6bec239a":"code","8f1177ef":"code","7dcefe10":"code","e3f0637c":"code","2214a7c6":"code","2eef4a52":"code","930f554c":"code","c2040361":"code","e003081c":"code","0b988502":"code","9cca204f":"code","6c486c87":"code","5334e6e6":"code","f6512440":"code","a343e36b":"code","16648406":"code","cfbeec9b":"code","c0b91a62":"code","fec5b74b":"code","dbf0ed72":"code","96795573":"markdown","0b24da8c":"markdown","73021895":"markdown","01c3334b":"markdown","e2d72c46":"markdown","98024e18":"markdown","f54e0a72":"markdown","6243738d":"markdown","9c7f75bd":"markdown","78c4feb8":"markdown","d5fdc26c":"markdown","bd8b5a7e":"markdown","a10000f1":"markdown","d1270dd4":"markdown","8eba61ee":"markdown","9492ee49":"markdown","6f536dc5":"markdown","96b0ca68":"markdown"},"source":{"f695e871":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","c5330ceb":"train_data=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')","3adb52fb":"train_data.info()","bfc2e235":"train_data","2470268f":"word_len=[]\nfor i in range(len(train_data)):\n    word_len.append(len(train_data.text.values[i].split(' ')))    ","1d265124":"plt.figure(figsize=(12,6))\nsns.countplot(word_len)\nplt.xlabel(\"Word lengths:\")\nplt.ylabel('Counts:')\nplt.title('Train Data \\n Max length='+str(max(word_len)))\nplt.show()","36ea5392":"plt.figure(figsize=(10,8))\nsns.countplot(train_data.target)\nplt.title('Count for Zeros:'+str(train_data.target.value_counts()[0])+'\\n'+\n         'Count for Ones:'+str(train_data.target.value_counts()[1]))\nplt.show()","6bec239a":"train_data=train_data.drop('keyword',axis=1)\ntrain_data=train_data.drop('location',axis=1)","8f1177ef":"Y_train=train_data.target\nX_train=train_data.text","7dcefe10":"Y_train=tf.reshape(Y_train,(-1,1))","e3f0637c":"Y_train","2214a7c6":"max_words = 100000\nmax_len = 100\n\ntok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_train)\nsequences = tok.texts_to_sequences(X_train)\nsequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)","2eef4a52":"sequences_matrix[1729]","930f554c":"model=tf.keras.Sequential()\n\nmodel.add(tf.keras.layers.Input(shape=[max_len]))\nmodel.add(tf.keras.layers.Embedding(max_words,128,input_length=max_len))    \n\nmodel.add(tf.keras.layers.LSTM(200, return_sequences=True))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.LSTM(200,return_sequences=True))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.LSTM(200))\nmodel.add(tf.keras.layers.Dropout(0.5))\n          \nmodel.add(tf.keras.layers.Dense(256))\nmodel.add(tf.keras.layers.Dropout(0.5))\n\nmodel.add(tf.keras.layers.Dense(1,activation='sigmoid')) #output layer","c2040361":"model.summary()","e003081c":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])","0b988502":"hist=model.fit(sequences_matrix,Y_train,batch_size=64,epochs=30)","9cca204f":"model.evaluate(sequences_matrix,Y_train)","6c486c87":"plt.plot(hist.history['loss'],'g')\nplt.xlabel('Epochs:')\nplt.ylabel('Loss:')\nplt.show()","5334e6e6":"#accuracy\n\nplt.plot(hist.history['acc'],'r')\nplt.xlabel('Epochs:')\nplt.ylabel('Accuracy:')\nplt.show()","f6512440":"test_data=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","a343e36b":"X_test=test_data.text","16648406":"tok = Tokenizer(num_words=max_words)\ntok.fit_on_texts(X_test)\nsequences_test = tok.texts_to_sequences(X_test)\nsequences_matrix_test = sequence.pad_sequences(sequences_test,maxlen=max_len)","cfbeec9b":"pred=model.predict(sequences_matrix_test)","c0b91a62":"pred=(pred>0.5)*1","fec5b74b":"p=pd.DataFrame()\np['id']=test_data['id']\np['target']=pred","dbf0ed72":"p.to_csv('.\/Submission_sachin.csv',index=False)","96795573":"# Step 6: Metrics and results","0b24da8c":"## Visualizing the number of words in sentences\n","73021895":"# Step 2: Read Train data (Descriptive and Exploratory analysis)","01c3334b":"## Tokenizing the train text data","e2d72c46":"## Submission","98024e18":"# Step 7: Prediction on test data","f54e0a72":"# Step 1: Import required libraries.","6243738d":"## Reshaping Y_train so that it's easier to process it when using LSTM.","9c7f75bd":"## As we can see there are 2 columns that contain null values (keyword and location), we will drop them since anyways we will only use the text and target columns","78c4feb8":"## Visualizing Train loss and accuracy epoch wise","d5fdc26c":"# Step 5: Training the model","bd8b5a7e":"## Predict","a10000f1":"## This step is required because i have used sigmoid activation function at the output layer. ","d1270dd4":"## Train Accuracy","8eba61ee":"## Define X_train and Y_train data.","9492ee49":"# Step 3: Pre-processing","6f536dc5":"## Visualizing the number of instances in target field","96b0ca68":"# Step 4: Creating RNN Model "}}