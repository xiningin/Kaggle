{"cell_type":{"a8953298":"code","7d412583":"code","b0a83d65":"code","2c2cad74":"code","99f2533e":"code","280c30dd":"code","58b75dc7":"code","5c77f69c":"code","2b778cd5":"code","5657272b":"code","1425766f":"code","a6bf0335":"code","8a7eaace":"code","71520bf3":"code","cfbcfb7e":"code","1673863b":"code","bac01983":"code","e5b74b2c":"code","12601166":"code","4450c05a":"code","657dd38e":"code","7d3bd12d":"code","08df667c":"code","e70e6041":"code","209215f9":"code","d18d267b":"code","17285659":"code","2ca774e0":"code","8e110c4e":"code","739896c1":"markdown","c03d9c27":"markdown","c4e88ce9":"markdown","879423a0":"markdown","466db3ce":"markdown","6e0bde91":"markdown","86a01eaa":"markdown","c09240bd":"markdown","a8654466":"markdown","7175617c":"markdown"},"source":{"a8953298":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))","7d412583":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")","b0a83d65":"train_df.head()","2c2cad74":"train_df.info()","99f2533e":"test_df.head()","280c30dd":"test_df.info()","58b75dc7":"train_df.columns.groupby(train_df.dtypes)","5c77f69c":"def count_nulls(df):\n    null_counter = df.isnull().sum(axis=0)\n    null_counter = null_counter[null_counter > 0]\n    null_percent = df.isnull().sum(axis=0) \/ df.shape[0] * 100\n    null_percent = null_percent[null_percent > 0]\n    null_df = pd.concat([null_counter,null_percent],axis=1)\n    null_df.columns = ['count','percent']\n    display(null_df)","2b778cd5":"count_nulls(train_df)","5657272b":"count_nulls(test_df)","1425766f":"exclude_cols = ['Id','Target','v2a1','v18q1','rez_esc']","a6bf0335":"np.unique(train_df['Target'])","8a7eaace":"train_df['Target'].value_counts()","71520bf3":"plt.hist(train_df['Target'])\nplt.show()","cfbcfb7e":"print([x for x in train_df.columns if train_df[x].dtype=='O'])","1673863b":"train_df.idhogar = train_df.idhogar.astype('category')\ntest_df.idhogar = test_df.idhogar.astype('category')","bac01983":"train_df.dependency.value_counts()","e5b74b2c":"train_df['dependency_calculated'] = (train_df.hogar_nin + train_df.hogar_mayor)\/(train_df.hogar_adul - train_df.hogar_mayor)","12601166":"train_df[['dependency','dependency_calculated']]","4450c05a":"train_df.dependency.replace('no','0',inplace=True)\ntrain_df.dependency.replace('yes','1',inplace=True)\ntrain_df.dependency_calculated.replace(float('inf'),8,inplace=True)","657dd38e":"all(np.isclose(train_df.dependency.astype('float'), train_df.dependency_calculated))","7d3bd12d":"test_df.dependency.replace('no','0',inplace=True)\ntest_df.dependency.replace('yes','1',inplace=True)\ntrain_df.dependency = train_df.dependency.astype('float')\ntest_df.dependency = test_df.dependency.astype('float')\ntrain_df.drop('dependency_calculated', axis=1, inplace=True)","08df667c":"train_df.edjefe.value_counts()","e70e6041":"train_df.edjefe.replace('no','0',inplace=True)\ntrain_df.edjefe.replace('yes','1',inplace=True)\ntrain_df.edjefe = train_df.edjefe.astype('float')\ntest_df.edjefe.replace('no','0',inplace=True)\ntest_df.edjefe.replace('yes','1',inplace=True)\ntest_df.edjefe = test_df.edjefe.astype('float')\n\ntrain_df.edjefa.replace('no','0',inplace=True)\ntrain_df.edjefa.replace('yes','1',inplace=True)\ntrain_df.edjefa = train_df.edjefa.astype('float')\ntest_df.edjefa.replace('no','0',inplace=True)\ntest_df.edjefa.replace('yes','1',inplace=True)\ntest_df.edjefa = test_df.edjefa.astype('float')","209215f9":"exclude_cols","d18d267b":"use_cols = train_df.columns.difference(exclude_cols)\nprint(len(use_cols))\nprint(use_cols)","17285659":"for x in use_cols.difference(['idhogar']):\n    train_df[x] = train_df[x].astype('float')\n    test_df[x] = test_df[x].astype('float')","2ca774e0":"train_df[use_cols].dtypes.value_counts()","8e110c4e":"test_df[use_cols].dtypes.value_counts()","739896c1":"Looks like for some reason, 1 is replaced with 'yes', 0 with 'no' and 'inf' (when there is no adult between 19 and 64) with 8! Let's try these and see:","c03d9c27":"There are some numbers that show the years of education of male\/female head of household and some yes\/no values that need to be replace by 1 and 0 respectively. ","c4e88ce9":"Train and test sets have 9557 and 23856 records respectively, which means test set has almost 2.5 times more data. There are 143 columns in train set, which includes Target and ID, so there are 141 features available for training, from which 8 are float, 129 are int and 4 are object. \n\nLet's take a quick look at the columns with null values in both train and test sets:","879423a0":"As we expected, there are only four values in the target values where 1 means extreme poverty and 4 means non-vulnerable families, and 2 and 3 are in between. The majority (~60%) are non-vulnerable. \n\nLet's take a look at the columns with dtype='O' (object) to prepare them for training. These are columns that have mixed types.","466db3ce":"Let's take a look at the Target values:","6e0bde91":"edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, **yes=1 and no=0**\n\nedjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, **yes=1 and no=0**","86a01eaa":"'Id' is a unique identifier of each row, which we are going to exclude, and 'idhogar' is the unique identifier of each household. ","c09240bd":"We have from the Column descriptions:\n\ndependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)\/(number of member of household between 19 and 64)\n\nIt is pretty strange to have yes\/no values for a rate that can be calculated. Looks like we can calculate this rate ourselves from the data using these columns:\n\nhogar_nin, Number of children 0 to 19 in household\n\nhogar_adul, Number of adults in household\n\nhogar_mayor, # of individuals 65+ in the household\n\nhogar_total, # of total individuals in the household","a8654466":"Looks like it was a correct guess. This was fun, but probably not very important as far as training a model is concerned! :) \n\nLet's update the type and look at other object types.","7175617c":"Looks like train and test sets have the same columns with missing values with almost the same percent! Let's exclude the three columns that have > 70% missing values:"}}