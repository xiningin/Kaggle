{"cell_type":{"11a4863e":"code","dbb5b756":"code","c906073d":"code","af69cb4e":"code","6373dbbe":"code","e6d34ab0":"code","398105d5":"code","5b9b3b5b":"code","f33fdd35":"code","11a72327":"code","0a361871":"code","616b84b6":"code","dabc7e4c":"code","f0811ae5":"code","2bf1cea9":"code","9501657f":"markdown"},"source":{"11a4863e":"import os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","dbb5b756":"CONFIG = dict(\n    seed = 42,\n    model_name = '..\/input\/0804tinyb\/ftmodel',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])","c906073d":"MODEL_PATHS = [\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-0.bin',\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-1.bin',\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-2.bin',\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-3.bin',\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-4.bin',\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-5.bin',\n    '..\/input\/0804tinyb\/ftmodel\/Loss-Fold-6.bin'\n]","af69cb4e":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","6373dbbe":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\ndf.head()","e6d34ab0":"class JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }","398105d5":"test_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)","5b9b3b5b":"class JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.1)\n        self.fc = nn.Linear(128, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs","f33fdd35":"@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS","11a72327":"def inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds","0a361871":"preds = inference(MODEL_PATHS, test_loader, CONFIG['device'])","616b84b6":"print(f\"Total Predictiions: {preds.shape[0]}\")\nprint(f\"Total Unique Predictions: {np.unique(preds).shape[0]}\")","dabc7e4c":"df['score'] = preds\ndf.head()","f0811ae5":"df['score'] = df['score'].rank(method='first')\ndf.head()","2bf1cea9":"df.drop('text', axis=1, inplace=True)\ndf.to_csv(\"submission.csv\", index=False)","9501657f":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">\ud83c\udfaf Training Kernel: <strong><a href=\"https:\/\/www.kaggle.com\/debarshichanda\/pytorch-w-b-jigsaw-starter\">[Pytorch + W&B] Jigsaw Starter<\/a><\/strong>.<\/span>"}}