{"cell_type":{"d86fdd41":"code","9a199117":"code","2ae49d5a":"code","dbabad09":"code","dfb776d6":"code","fc82ddc3":"code","b60ecb13":"code","67a9561a":"code","3a24c072":"code","3bf5c9b6":"code","9c7d5a01":"code","07801a25":"code","deeb99ec":"code","4180d341":"code","a7c61062":"code","b3d1ee1f":"code","731a42a7":"code","75fab3cc":"code","aeea9845":"code","d4c4ce17":"code","9b19cd4e":"code","74b55922":"code","895d5df4":"code","92303b4b":"code","824eb87d":"code","289388cd":"code","5a993dc3":"code","1051b6b0":"code","7531e29e":"code","d6979379":"code","683dcd5b":"code","0fc3b795":"code","006b4b1d":"code","0dd641c1":"code","e7e5a019":"code","c1d5904d":"code","fca610c2":"code","590652f2":"code","98eb1560":"code","37ed9266":"code","635c9983":"code","7397b54a":"code","8d1d2033":"code","819d434e":"code","e7fc01b5":"code","116d64df":"code","217612e3":"code","529d5f92":"code","b085ae2e":"code","76f740e0":"code","d6005e6a":"code","61c99e6e":"code","0364ba60":"code","48718f07":"code","75ba7b0d":"markdown","0c62f459":"markdown","f6c6d60b":"markdown","4328b23d":"markdown","97815bc3":"markdown","7220d9eb":"markdown","f645d7d2":"markdown","2500fcab":"markdown"},"source":{"d86fdd41":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(font_scale=1)","9a199117":"#importing data from csv file using pandas\ntrain=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ntrain.head()","2ae49d5a":"#lets create heatmap first of all lest see on which feature SalePrice is dependent\n\ncorr = train.drop('Id',1).corr().sort_values(by='SalePrice',ascending=False).round(2)\nprint(corr['SalePrice'])","dbabad09":"#lets create scatterplot of GrLivArea and SalePrice\nsns.scatterplot(x='OverallQual',y='SalePrice',data=train)","dfb776d6":"sns.scatterplot(x='GrLivArea',y='SalePrice',data=train)","fc82ddc3":"#as per above plot we can see there are two outliers which can affect on out model,lets remove those outliers\ntrain=train.drop(train.loc[(train['GrLivArea']>4000) & (train['SalePrice']<200000)].index,0)\ntrain.reset_index(drop=True, inplace=True)","b60ecb13":"#let we how its look after removing outliers\nsns.scatterplot(x='GrLivArea',y='SalePrice',data=train)","67a9561a":"#here we can see SalePrice mostly dependent on this features OverallQual,GrLivArea,TotalBsmtSF,GarageCars,1stFlrSF,GarageArea \nplt.subplots(figsize=(12, 9))\nsns.heatmap(corr, vmax=.8, square=True);","3a24c072":"#now lets create heatmap for top 10 correlated features\ncols = corr['SalePrice'].head(10).index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1)\nhm = sns.heatmap(cm, annot=True, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","3bf5c9b6":"cols = corr['SalePrice'].head(10).index\ncm = np.corrcoef(train[cols].values.T)\ncm","9c7d5a01":"#lets see relation of 10 feature with SalePrice through Pairplot\nsns.pairplot(train[corr['SalePrice'].head(10).index])","07801a25":"#lets store number of test and train rows\ntrainrow=train.shape[0]\ntestrow=test.shape[0]","deeb99ec":"#copying id data\ntestids=test['Id'].copy()","4180d341":"#copying sales priece\ny_train=train['SalePrice'].copy()","a7c61062":"#combining train and test data\ndata=pd.concat((train,test)).reset_index(drop=True)\ndata=data.drop('SalePrice',1)","b3d1ee1f":"#dropping id columns\ndata=data.drop('Id',axis=1)","731a42a7":"data.head()","75fab3cc":"#checking missing data\nmissing = data.isnull().sum().sort_values(ascending=False)\nmissing","aeea9845":"missing = missing.drop(missing[missing==0].index)\nmissing","d4c4ce17":"# fillna\nfor cols in [\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\",\"FireplaceQu\",\"GarageCond\",\"GarageQual\",\"GarageFinish\"]:\n    data[cols].fillna(\"NA\",inplace=True)","9b19cd4e":"for bsmt in [\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\"]:\n    data[bsmt].fillna(\"NA\",inplace=True)","74b55922":"for gar in ['GarageYrBlt','GarageType','GarageCars', 'GarageArea']:\n    data[gar].fillna(0,inplace=True)","895d5df4":"#BsmtFinSF1,BsmtFinSF2 \ndata['BsmtFinSF1']=data['BsmtFinSF1'].fillna(0)\ndata['BsmtFinSF2']=data['BsmtFinSF2'].fillna(0)","92303b4b":"#MasVnrType,MasVnrArea\ndata['MasVnrType']=data['MasVnrType'].fillna('NA')\ndata['MasVnrArea']=data['MasVnrArea'].fillna(0)","824eb87d":"#MSZoning \ndata['MSZoning']=data['MSZoning'].fillna(data['MSZoning'].dropna().sort_values().index[0])","289388cd":"#Utilities\ndata['Utilities']=data['Utilities'].fillna(data['Utilities'].dropna().sort_values().index[0])","5a993dc3":"#BsmtFullBath\ndata['BsmtFullBath']=data['BsmtFullBath'].fillna(0)\n\n#Functional\ndata['Functional']=data['Functional'].fillna(data['Functional'].dropna().sort_values().index[0])\n\n#BsmtHalfBath\ndata['BsmtHalfBath']=data['BsmtHalfBath'].fillna(0)\n\n#BsmtUnfSF\ndata['BsmtUnfSF']=data['BsmtUnfSF'].fillna(0)","1051b6b0":"#Exterior2nd\ndata['Exterior2nd']=data['Exterior2nd'].fillna('NA')\n\n#Exterior1st\ndata['Exterior1st']=data['Exterior1st'].fillna('NA')","7531e29e":"#TotalBsmtSF\ndata['TotalBsmtSF']=data['TotalBsmtSF'].fillna(0)","d6979379":"#SaleType\ndata['SaleType']=data['SaleType'].fillna(data['SaleType'].dropna().sort_values().index[0])","683dcd5b":"#Electrical\ndata['Electrical']=data['Electrical'].fillna(data['Electrical'].dropna().sort_values().index[0])","0fc3b795":"#KitchenQual\ndata['KitchenQual']=data['KitchenQual'].fillna(data['KitchenQual'].dropna().sort_values().index[0])","006b4b1d":"#lets check any missing remain\nmissing=data.isnull().sum().sort_values(ascending=False)\nmissing=missing.drop(missing[missing==0].index)\nmissing","0dd641c1":"#LotFrontage: all house have linear connected feet so putting most mean value\ndata['LotFrontage']=data['LotFrontage'].fillna(data['LotFrontage'].dropna().mean())","e7e5a019":"#lets check any missing remain\nmissing=data.isnull().sum().sort_values(ascending=False)\nmissing=missing.drop(missing[missing==0].index)\nmissing","c1d5904d":"#as we know some feature are highly co-related with SalePrice so lets create some feature using these features\ndata['GrLivArea_2']=data['GrLivArea']**2\ndata['GrLivArea_3']=data['GrLivArea']**3\ndata['GrLivArea_4']=data['GrLivArea']**4\n\ndata['TotalBsmtSF_2']=data['TotalBsmtSF']**2\ndata['TotalBsmtSF_3']=data['TotalBsmtSF']**3\ndata['TotalBsmtSF_4']=data['TotalBsmtSF']**4\n\ndata['GarageCars_2']=data['GarageCars']**2\ndata['GarageCars_3']=data['GarageCars']**3\ndata['GarageCars_4']=data['GarageCars']**4\n\ndata['1stFlrSF_2']=data['1stFlrSF']**2\ndata['1stFlrSF_3']=data['1stFlrSF']**3\ndata['1stFlrSF_4']=data['1stFlrSF']**4\n\ndata['GarageArea_2']=data['GarageArea']**2\ndata['GarageArea_3']=data['GarageArea']**3\ndata['GarageArea_4']=data['GarageArea']**4","fca610c2":"#lets add 1stFlrSF and 2ndFlrSF and create new feature floorfeet\ndata['Floorfeet']=data['1stFlrSF']+data['2ndFlrSF']\ndata=data.drop(['1stFlrSF','2ndFlrSF'],1)","590652f2":"#MSSubClass,MSZoning\ndata=pd.get_dummies(data=data,columns=['MSSubClass'],prefix='MSSubClass')\ndata=pd.get_dummies(data=data,columns=['MSZoning'],prefix='MSZoning')\ndata.head()","98eb1560":"#Street,Alley,LotShape,LandContour,Utilities,LotConfig,LandSlope,Neighborhood,Condition1,Condition2,BldgType,HouseStyle\ndata=pd.get_dummies(data=data,columns=['Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle'])\ndata.head()","37ed9266":"#OverallQual\ndata=pd.get_dummies(data=data,columns=['OverallQual'],prefix='OverallQual')\n#OverallCond\ndata=pd.get_dummies(data=data,columns=['OverallCond'],prefix='OverallCond')","635c9983":"#we have remodel year data so lest one new feature home is remodeled or not\ndata['Remodeled']=0\ndata.loc[data['YearBuilt']!=data['YearRemodAdd'],'Remodeled']=1\ndata=data.drop('YearRemodAdd',1)\ndata=pd.get_dummies(data=data,columns=['Remodeled'])","7397b54a":"#creating dummies fo all categorical data\ndata=pd.get_dummies(data=data,columns=['RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Heating','HeatingQC','CentralAir','Electrical','KitchenQual','Functional','FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive','PoolQC','Fence','MiscFeature','SaleType','SaleCondition'])","8d1d2033":"#lets add all bath in one feature\ndata['Bath']=data['BsmtFullBath']+data['BsmtHalfBath']*.5+data['FullBath']+data['HalfBath']*.5\ndata=data.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'],1)","819d434e":"#dummies\ndata=pd.get_dummies(data=data,columns=['BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd'])","e7fc01b5":"#here we  has one more outliers lets replace it with 0\ndata.loc[data['GarageYrBlt']==2207.,'GarageYrBlt']=0","116d64df":"#lets import StandardScaler from sklearn for feature scalling\nfrom sklearn.preprocessing import StandardScaler","217612e3":"#lets split data using trainrow data and scale data\nx_train=data.iloc[:trainrow]\nx_test=data.iloc[trainrow:]\nscaler=StandardScaler()\nscaler=scaler.fit(x_train)\nx_train_scaled=scaler.transform(x_train)\nx_test_scaled=scaler.transform(x_test)","529d5f92":"from sklearn.linear_model import LinearRegression\nreg_liner=LinearRegression()\nreg_liner.fit(x_train_scaled,y_train)\nreg_liner.score(x_train_scaled,y_train)","b085ae2e":"from xgboost import XGBRegressor\n\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\nmy_model.fit(x_train_scaled, y_train)\nprint(my_model.score(x_train_scaled,y_train))","76f740e0":"from sklearn.tree import DecisionTreeRegressor\ntree=DecisionTreeRegressor(criterion='mse',max_depth=5)\ntree.fit(x_train_scaled,y_train)\nprint(tree.score(x_train_scaled,y_train))","d6005e6a":"from sklearn import svm\nsvm_model=svm.SVC()\nsvm_model.fit(x_train_scaled,y_train)\nprint(svm_model.score(x_train_scaled,y_train))","61c99e6e":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\ngnb=GaussianNB()\nmnb=MultinomialNB()\ngnb.fit(x_train_scaled,y_train)\nmnb.fit(x_train,y_train)\nprint(gnb.score(x_train_scaled,y_train))\nprint(mnb.score(x_train,y_train))","0364ba60":"#7.Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor(n_estimators=1000)\nrfr.fit(x_train_scaled,y_train)\nprint(rfr.score(x_train_scaled,y_train))","48718f07":"predictions = my_model.predict(x_test)\n\nsubmission = pd.DataFrame(columns=['Id', 'SalePrice'])\nsubmission['Id'] = test['Id']\nsubmission['SalePrice'] = predictions\nsubmission.to_csv('submission.csv', index=False)\nprint(\"submission worked\")","75ba7b0d":"### 2) XGBoost","0c62f459":"# Regression - \n### 1) Linear Regression\n","f6c6d60b":"### 4) Support Vector Regression","4328b23d":"### 3) Decision Tree\n","97815bc3":"### 5) Naive Bayes\n","7220d9eb":".drop takes 2 params\n\n1) labels               \t\nIndex or column labels to drop.\nsingle label or list-like\tRequired\n\n2) axis   \t\nWhether to drop labels from the index (0 or \u2018index\u2019) or columns (1 or \u2018columns\u2019).\t{0 or \u2018index\u2019, 1 or \u2018columns\u2019}\nDefault Value: 0\tRequired","f645d7d2":"### 6) Random Forest","2500fcab":"# Feature Scaling"}}