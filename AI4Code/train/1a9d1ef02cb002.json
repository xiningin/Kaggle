{"cell_type":{"be039b51":"code","00b04af9":"code","2f4f1ae4":"code","b344238d":"code","57b22645":"code","1155f282":"code","7519f6e3":"code","48b150bd":"code","092133c5":"code","fb684c58":"code","88f425f4":"code","c490fff7":"code","1901f8b2":"code","55ce5a34":"code","0e499ba0":"code","4c8edf32":"code","b544602f":"code","90806f77":"code","a6bb4311":"code","a433a83c":"code","74182665":"code","2b600c7e":"code","380c85ec":"code","d2f6c77a":"code","162f1b97":"code","32e55a16":"code","90394117":"code","c1383ee3":"code","bf3a9245":"code","6e6ec8de":"code","6745f0c7":"code","d84ee0eb":"code","25b022a4":"code","8db8dd9a":"markdown","fe8b6bb7":"markdown","3625db6d":"markdown","3a80cebc":"markdown","f1c0a077":"markdown","ada35da3":"markdown","e231d106":"markdown","194603af":"markdown","df89901b":"markdown","ec97653a":"markdown","0ba56538":"markdown","214686df":"markdown","c2e452ed":"markdown","3c3e4127":"markdown","c76777f1":"markdown","c7615bea":"markdown","18e1f030":"markdown","526841d8":"markdown","27d393b4":"markdown","60dd62b9":"markdown","fa5be806":"markdown","a2d07fca":"markdown","a975a77c":"markdown","3451f63d":"markdown","c9128c57":"markdown","9ae9510d":"markdown"},"source":{"be039b51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00b04af9":"titanic_path = '\/kaggle\/input\/titanic'\n\ndef load_data(filename, path = titanic_path):\n    csv_path = os.path.join(titanic_path, filename)\n    return pd.read_csv(csv_path)","2f4f1ae4":"train_set = load_data('train.csv')\ntest_set = load_data('test.csv')","b344238d":"train_set.head()","57b22645":"train_set.info()","1155f282":"train_set.describe()","7519f6e3":"%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt","48b150bd":"fig, axes = plt.subplots(1, 4, figsize=(16,4))\n\nsurvive1   = train_set[train_set['Survived'] == 1]['Survived'].value_counts().sort_index()\nsurvive0   = train_set[train_set['Survived'] == 0]['Survived'].value_counts().sort_index()\npclass1    = train_set[train_set['Survived'] == 1]['Pclass'].value_counts().sort_index()\npclass0    = train_set[train_set['Survived'] == 0]['Pclass'].value_counts().sort_index()\nsex1       = train_set[train_set['Survived'] == 1]['Sex'].value_counts().sort_index()\nsex0       = train_set[train_set['Survived'] == 0]['Sex'].value_counts().sort_index()\nembarked1  = train_set[train_set['Survived'] == 1]['Embarked'].value_counts().sort_index()\nembarked0  = train_set[train_set['Survived'] == 0]['Embarked'].value_counts().sort_index()\n\naxes[0].bar(list(survive1.index), list(survive1))\naxes[0].bar(list(survive0.index), list(survive0))\naxes[0].set_title(\"Survived\")\naxes[0].set_ylabel(\"Count\")\n\naxes[1].bar(list(pclass1.index), list(pclass1))\naxes[1].bar(list(pclass0.index), list(pclass0), bottom=list(pclass1))\naxes[1].set_title(\"Passenger class\")\n\naxes[2].bar(list(sex1.index), list(sex1))\naxes[2].bar(list(sex0.index), list(sex0), bottom=list(sex1))\naxes[2].set_title(\"Sex\")\n\naxes[3].bar(list(embarked1.index), list(embarked1));\naxes[3].bar(list(embarked0.index), list(embarked0), bottom=list(embarked1));\naxes[3].set_title(\"Embarked\");","092133c5":"fig, ax = plt.subplots(1,2, sharey=True, figsize=(10,4), tight_layout=True)\n\nax[0].hist(list(train_set['Age']), bins=20, density=True,)\nax[1].hist(list(train_set['Fare']), bins=20, density=True);","fb684c58":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# column index\nAge_ix, SibSp_ix, Parch_ix, Fare_ix = 0,1,2,3\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Adding the following features:\n    1. AgeBucket: age bucket categories\n    2. RelativesOnboard: number of relatives onboard\n    \"\"\"\n    def __init__(self, add_column = True):\n        self.add_column = add_column\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        AgeBucket = X[:, Age_ix] \/\/ 15 * 15\n        RelativesOnboard = X[:, SibSp_ix] + X[:, Parch_ix]\n        FareBucket = X[:, Fare_ix]\n        return np.c_[X, AgeBucket, RelativesOnboard]","88f425f4":"class DataFrameSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    spesicif attribute selector for partial preprocess\n    \"\"\"\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names]","c490fff7":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nnum_pipeline = Pipeline([\n    ('select_numeric', DataFrameSelector(['Age', 'SibSp', 'Parch', 'Fare'])),\n    ('imputer', SimpleImputer(strategy = 'median')),\n    ('attribs_adder', CombinedAttributesAdder()),\n])","1901f8b2":"class MostFrequentImputer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    fill missing with the most frequent value from one column\n    \"\"\"\n    def fit(self, X, y=None):\n        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.most_frequent_)","55ce5a34":"from sklearn.preprocessing import OneHotEncoder\n\ncat_pipeline = Pipeline([\n    ('select_cat', DataFrameSelector(['Pclass', 'Sex', 'Embarked'])),\n    ('imputer', MostFrequentImputer()),\n    ('cat_encoder', OneHotEncoder(sparse=False))\n])","0e499ba0":"from sklearn.pipeline import FeatureUnion\n\npreprocess_pipeline = FeatureUnion(transformer_list=[\n    ('num_pipeline', num_pipeline),\n    ('cat_pipeline', cat_pipeline)\n])","4c8edf32":"X_train = preprocess_pipeline.fit_transform(train_set)\nX_train","b544602f":"y_train = train_set['Survived']","90806f77":"from sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC\n\nsvm_clf = SVC(gamma = 'auto')\nsvm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\nsvm_scores.mean()","a6bb4311":"from sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(n_estimators=200, max_depth=10, criterion='entropy', min_samples_split=5, random_state=42)\nforest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\nforest_scores.mean()","a433a83c":"from xgboost import XGBClassifier\n\nxgb_clf = XGBClassifier(max_depth=10, n_estimators=250, learning_rate=0.01, reg_alpha=0.5, reg_lambda=0.5, random_state=42)\nxgb_scores = cross_val_score(xgb_clf, X_train, y_train, cv=10)\nxgb_scores.mean()","74182665":"from catboost import CatBoostClassifier\n\ncat_clf = CatBoostClassifier(iterations=15, learning_rate=0.1, depth=5, verbose=0, random_state=42)\ncat_scores = cross_val_score(cat_clf, X_train, y_train, cv=10)\ncat_scores.mean()","2b600c7e":"plt.figure(figsize=(8, 4))\nplt.plot([1]*10, svm_scores, \".\")\nplt.plot([2]*10, forest_scores, \".\")\nplt.plot([3]*10, xgb_scores, \".\")\nplt.plot([4]*10, cat_scores, \".\")\n\nplt.boxplot([svm_scores, forest_scores, xgb_scores, cat_scores], labels=(\"SVM\",\"Random Forest\",\"XGBoost\",\"CatBoost\"))\nplt.ylabel(\"Accuracy\", fontsize=14)\nplt.show()","380c85ec":"!pip install pycaret","d2f6c77a":"from pycaret.classification import create_model,setup\nfrom pycaret import classification","162f1b97":"classification_setup = setup(data= train_set, target='Survived', ignore_features= ['Name'])","32e55a16":"classification.compare_models()","90394117":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3\u00d72) combinations of hyperparameters\n    {'iterations': [10, 15, 30], 'learning_rate': [0.05, 0.1]},\n    # then try 3 (3\u00d71) combinations with bootstrap set as False\n    {'depth': [3, 5, 7]},\n  ]\n\n\ncat_clf = CatBoostClassifier(random_state=42)\n# train across 5 folds, that's a total of (12+3)*5=75 rounds of training \ngrid_search = GridSearchCV(cat_clf, param_grid, cv=5,\n                           return_train_score=True)\n\ngrid_search.fit(X_train, y_train)","c1383ee3":"pd.DataFrame(grid_search.cv_results_)","bf3a9245":"(pd.Series(grid_search.best_estimator_.feature_importances_)\n .nlargest(14)\n .plot(kind='barh'));","6e6ec8de":"X_test = preprocess_pipeline.transform(test_set)\ny_pred = grid_search.predict(X_test)","6745f0c7":"my_submission = pd.DataFrame({'PassengerId': test_set.PassengerId, 'Survived': y_pred})","d84ee0eb":"my_submission.head()","25b022a4":"my_submission.to_csv('submission.csv', index=False)","8db8dd9a":"![TITANIC](https:\/\/www.rmg.co.uk\/sites\/default\/files\/styles\/banner\/public\/Atlantic%20liner%20%27Titanic%27%20%28Br%2C%201912%29%20sinking%2C%20bow%20first%2C%201912%2C%20with%20eight%20full%20lifeboats%20nearby%20and%20an%20iceberg%20in%20the%20distance_banner.jpg?itok=_3RM6_e4)","fe8b6bb7":"## Modeling","3625db6d":"* Finally, let's join the numerical and categorical pipelines:","3a80cebc":"## Submission","f1c0a077":"* Using grid search to find best parameters of the selected algorithm:","ada35da3":"## Preprocessing Pipeline","e231d106":"### Thanks for reviewing my notebook! Hope that it will be useful","194603af":"### CatBoost","df89901b":"Let's use one of the validated model above to make predictions on the test set","ec97653a":"# TITANIC","0ba56538":"* Seems that age, cabin and embarked features have missing values for some passengers","214686df":"#### *The meaning of the attributes:*\n\n* **Survived**: Target variable, whether the passenger survived or not (1\/0)\n* **Pclass**: Passenger class\n* **Name**, Sex, Age: Personal informations of the passengers \n* **SibSp**: How many siblings or spouses of the passenger abord the Titanic\n* **Parch** How many children or parents of the passenger abord the Titanic\n* **Ticket**: Ticket id\n* **Fare**: Price paid\n* **Cabin**: Passenger's cabin number \n* **Embarked**: Where the passenger embarked the Titanic","c2e452ed":"### Random Forest","3c3e4127":"* Feature importance:","c76777f1":"### XGBoost","c7615bea":"* There is a super useful library allows you to compare all ML models at once.\n\nHave a look for detail information about pycaret:\n[PyCaret Introduction (Classification & Regression)](https:\/\/www.kaggle.com\/frtgnn\/pycaret-introduction-classification-regression\/comments#828333) ","18e1f030":"* The pipepile for the numerical attributes:","526841d8":"* Applying preprocess pipeline to test set and prediction:","27d393b4":"### Support Vector Machine","60dd62b9":"* Imputer for string categorical variables:","fa5be806":"If you get an error while running pycaret, uninstall and reinstall scikit library\n!pip uninstall scikit-learn --yes\n!pip install -U numpy scipy scikit-learn\n!pip install scikit-learn","a2d07fca":"* The pipeline for the categorical attributes:","a975a77c":"*  Let's take a quick look at categorical attributes:","3451f63d":"* Let's compare the models:","c9128c57":"* Grid search results:","9ae9510d":"* Now we have a pipeline that takes raw data and makes it ready for modeling!"}}