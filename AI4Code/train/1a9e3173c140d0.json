{"cell_type":{"0019495d":"code","f5e98492":"code","6d35d465":"code","d89c2e93":"code","a2bc92fb":"code","2c6df4ba":"code","996ae337":"code","4d585052":"code","1750d3a2":"code","8f2e7212":"code","1d35b7c9":"code","7e80a644":"code","ebb8851e":"code","5dfe879a":"code","c177a0da":"code","d3d4fe53":"code","0c62a68e":"code","7ba7b033":"code","a8929f84":"markdown","b50fa35c":"markdown","36d29fc3":"markdown","153f943a":"markdown"},"source":{"0019495d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5e98492":"# import libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt","6d35d465":"print(tf.__version__)","d89c2e93":"train_data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","a2bc92fb":"img_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef data_prep(raw):\n    out_y = keras.utils.to_categorical(raw.label, num_classes)\n\n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,1:]\n    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n    out_x = x_shaped_array \/ 255\n    return out_x, out_y","2c6df4ba":"x, y = data_prep(train_data)","996ae337":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size =0.2, random_state=1)","4d585052":"# initializng the CNN\ncnn = keras.models.Sequential()","1750d3a2":"# step 1: Convolution .. classicals architecture (f =32)\ncnn.add(keras.layers.Conv2D(filters = 32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))","8f2e7212":"# step 2: MaxPooling\ncnn.add(keras.layers.MaxPool2D(pool_size = 2, strides=2))","1d35b7c9":"# step 3: Flattering\ncnn.add(keras.layers.Flatten())","7e80a644":"# step 4: Full connection\ncnn.add(keras.layers.Dense(128, activation='relu'))","ebb8851e":"# step 5: output layer\ncnn.add(keras.layers.Dense(10,activation='softmax'))","5dfe879a":"# compiling the CNN\ncnn.compile(  optimizer='Adam', loss = tf.keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])","c177a0da":"# Training the CNN on the Training and evaluating it on the Test set\nhistory = cnn.fit(x_train, y_train,epochs=10) ","d3d4fe53":"# evaluate accuracy\ntest_loss, test_acc = cnn.evaluate(x_test,  y_test, verbose=2)\nprint('\\nTest accuracy:', test_acc)","0c62a68e":"# make predictions\nprobability_model = tf.keras.Sequential([cnn, \n                                         tf.keras.layers.Softmax()])","7ba7b033":"predictions = probability_model.predict(x_test)","a8929f84":"# Part 1: Data preprocessing","b50fa35c":"# Part 4: Making prediction","36d29fc3":"# Part 2: Building CNN","153f943a":"# Part 3: Training the CNN"}}