{"cell_type":{"c8101c3e":"code","8a48e7c1":"code","5caa17b6":"code","d95fb063":"code","ea528133":"code","21c9e695":"code","9fdabf41":"code","7e860a57":"code","f3cf44d4":"code","99172a72":"code","42e48234":"code","fb34a70f":"code","94536904":"code","8c80995f":"code","5b4111d2":"code","461401cb":"code","c4c7656f":"code","cd809b0a":"code","78919bcb":"code","8ff28a2d":"code","27315bb1":"code","f5d4bc96":"code","e50431a5":"code","85e46381":"code","a13c7a97":"markdown","6715a2fc":"markdown","c7729507":"markdown","0323f0de":"markdown","c8798502":"markdown","00706ff8":"markdown","d0a62329":"markdown","1c6d92e3":"markdown","d67f8f01":"markdown","3baf953a":"markdown","0c814a8a":"markdown","568a2e91":"markdown","861ba1cc":"markdown"},"source":{"c8101c3e":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","8a48e7c1":"tfm = transforms.Compose(\n[transforms.ToTensor(),\ntransforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n","5caa17b6":"bs = 8\ntrain = torchvision.datasets.CIFAR10(root='.\/data', train = True, download = True, transform=tfm)\ntrnloader = torch.utils.data.DataLoader(train, batch_size = bs, shuffle = True, num_workers = 2)\ntest = torchvision.datasets.CIFAR10(root='.\/data', train = False, download = True, transform=tfm)\ntestloader = torch.utils.data.DataLoader(train, batch_size = bs, shuffle = False, num_workers = 2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","d95fb063":"!ls -l .\/data","ea528133":"#Show some images\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef imshow(img):\n    img = img \/ 2 + 0.5 #un-normalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)))\n    plt.show()\n    \ndataiter = iter(trnloader) #Create itterator to step through the batches of images\nimages, labels = dataiter.next() \n\nimshow(torchvision.utils.make_grid(images))\n\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","21c9e695":"dataiter.workers","9fdabf41":"import torch.nn as nn\nimport torch.nn.functional as F","7e860a57":"# With square kernels and equal stride\nm = nn.Conv2d(3,4, 2, stride=2)\n# non-square kernels and unequal stride and with padding\n#m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n# non-square kernels and unequal stride and with padding and dilation\n#m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\ninput = torch.ones(1,3, 5,5)\noutput = m(input)","f3cf44d4":"m","99172a72":"output","42e48234":"??nn.Conv2d","fb34a70f":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\\\n        #The init section of the class creates the layers needed for the NN\n        self.conv1 = nn.Conv2d(3,6,5) #in channels, out channels, kernel size\n        self.pool = nn.MaxPool2d(2,2)\n        self.conv2 = nn.Conv2d(6,16,5)\n        self.fc1 = nn.Linear(16*5*5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84,10) #Final layer here is linear prediction of each categories. Typically we'd use a softmax instead\n        \n    def forward(self, x):\n        #Create the foreward method to step through each of the layers created above\n        #Note that the output of each layer is the input to the next layer\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 *5*5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    \nnet = Net()\nprint(net)","94536904":"import torch.optim as optim\n\ncrit = nn.CrossEntropyLoss()\nopt = optim.SGD(net.parameters(), lr= 0.0001, momentum = 0.9)","8c80995f":"%%time\nfor epoch in range(4):\n    \n    running_loss = 0.0\n    \n    for i, data in enumerate(trnloader, 0):\n        inputs, labels = data #get the inputs\n        \n        opt.zero_grad() #zero out the parameter gradients\n        \n        out = net(inputs) #Automatically perform forward step\n        loss = crit(out, labels) #Calculate Loss Function\n        loss.backward() #TAke the derivative of the loss function\n        opt.step() #opt.step takes the new gradients calculated in .backward multiplies by learning rate, then updates net parameters\n        \n        #print statistic\n        running_loss += loss.item() #Take out the value of the loss function for printing out results\n        \n        if i % 2000 == 1999:\n            print('[%d, %5d] loss: %.3f' % (epoch +1, i+1, running_loss\/2000))\n            running_loss = 0.0\nprint('Finished Training')","5b4111d2":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n#images, labels = dataiter.next()\n\n#print images\nimshow(torchvision.utils.make_grid(images))\nprint('Ground Truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","461401cb":"images.shape","c4c7656f":"output = net(images)\noutput.shape","cd809b0a":"_, predicted = torch.max(output, 1)\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n#Not Bad, not great, 1 for 4","78919bcb":"%%time\ncorrect = 0\ntotal = 0 \nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        output = net(images)\n        _,predicted = torch.max(output.data, 1)\n        total += labels.size(0)\n        correct+=(predicted == labels).sum().item()\n        \nprint('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct \/ total))","8ff28a2d":"%%time\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1) \n        c = (predicted ==labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n            \nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (classes[i], 100*class_correct[i]\/class_total[i]))","27315bb1":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","f5d4bc96":"net = net.to(device)","e50431a5":"for p in opt.state.keys():\n    param_state = opt.state[p]\n    buf = param_state[\"momentum_buffer\"]\n    param_state[\"momentum_buffer\"] = buf.cuda()  # move buf to device","85e46381":"%%time\nfor epoch in range(4):\n    \n    running_loss = 0.0\n    \n    for i, data in enumerate(trnloader, 0):\n        inputs, labels = data #get the inputs\n        inputs =  inputs.to(device)\n        labels = labels.to(device)\n        \n        \n        opt.zero_grad() #zero out the parameter gradients\n        \n        out = net(inputs)\n        loss = crit(out, labels)\n        loss.backward()\n        opt.step()\n        \n        #print statistic\n        running_loss += loss.item()\n        \n        if i % 2000 == 1999:\n            print('[%d, %5d] loss: %.3f' % (epoch +1, i+1, running_loss\/2000))\n            running_loss = 0.0\nprint('Finished Training') ","a13c7a97":"Now we can take our trained 'net' model and use it to meke predictions on the 4 images shown above. Output of model will give 10 linear (not SoftMax) predictions for each of the classes","6715a2fc":"## Test network on dataset","c7729507":"## Training a Simple CNN PyTorch Tutorial\nWorking through the CIFAR10 image tutorial on the pytorch instructional page found [here](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html)\n\nFor this tutorial, we will use the CIFAR10 dataset. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n\n![classes](https:\/\/pytorch.org\/tutorials\/_images\/cifar10.png)\n\nAll calculations are run on the CPU first then shown how to run on GPU.","0323f0de":"In order to send data to pytorch modules we need to create data-loaders for the images. This will allow pytorch to interact with the data, apply transforms\/normalization, and create batches for the NN","c8798502":"## Define loss function and optimizer","00706ff8":"Note that the time to solve the model has improved dramatically","d0a62329":"## Calculate the accuracy on the entire network\n* Use the testloader data loader we created above\n* calculate the output for each of the images\n* compare to the labeled image","1c6d92e3":"## Create the Convolutional Neural Network\nA convolutional layer allows the NN to find features within the model such as edges and shapes. \n![Convolution example](https:\/\/pytorch.org\/tutorials\/_images\/mnist.png)\nNote that the NN finds the kernels itself, and pytorch initializes the Conv layer with random kernels\n\nnn.Conv2d(#input channels, # output channels, kernel size, stride= stride dims)","d67f8f01":"At every step of the way you need to send inptus and targets to the GPU as well\n\nAdditionally need to clear out the momentum buffers from the optimizer class (since they're stored in CPU, it'll throw an error if the buffer's not cleared) See [here](https:\/\/discuss.pytorch.org\/t\/runtimeerror-expected-type-torch-floattensor-but-got-torch-cuda-floattensor-while-resuming-training\/37936\/2)","3baf953a":"Recall that random chance is 1\/10, case in tutorial is still improvement over random, but something is different in code\n\nWe can loop through this again, this time checking the accuracy of each of the classes","0c814a8a":"Create the small deep NN we'll use to classify the images","568a2e91":"## Train the network\n\nCreate the function that will actually preform the solving of the NN. \n\nThe number of epochs is the number of times the function below will loop through the entire dataset (recall each loop below where gradients are updated are done with a batch of data from the data loader)","861ba1cc":"## Training on GPU\n* All the above code is run on a CPU processor, next we'll port model over to GPU\n* GPU should give marked improvements in training the model"}}