{"cell_type":{"e0abcca6":"code","f7eaaa8c":"code","3ec9ad15":"code","fd4ee764":"code","05d20378":"code","b9af4253":"code","b199d16d":"code","6379375f":"code","61a839cd":"code","52832d85":"code","12359d18":"code","2a699804":"code","c105ecaf":"code","f360a5f8":"code","2fe504be":"code","54181849":"code","6eb72d8e":"code","36e16e74":"code","fb1764ae":"code","46d1c80f":"code","db3103e0":"code","d96813d4":"code","e7821216":"code","312f885f":"code","056c8c31":"code","87aa8c71":"code","35c3bd5d":"code","c70bffc2":"code","cafa0d7a":"code","3c56c754":"code","5310ee42":"code","ef02698c":"code","b9c5667a":"code","2fe9a569":"code","10f2ed2a":"code","c12a1121":"code","790e984a":"code","817c5557":"code","790cf05e":"code","56a33a6f":"code","1f643265":"code","4b2d81cd":"code","e1872c0d":"code","4bbc4d99":"code","74756f03":"code","3bbd7775":"code","65a8f86b":"code","0b3f67b5":"code","13d445da":"code","7f55b93c":"code","a68585bc":"code","8e3b643c":"code","924db659":"code","b949cf34":"code","59221820":"code","ab30a428":"code","1d6f3abb":"code","bff51aea":"code","a71b4344":"code","57797b36":"code","19ee8952":"code","235183bb":"code","b34d0f5a":"code","b999b3c5":"code","48f12767":"code","9bc01440":"code","fa022bc6":"code","07784582":"code","d1af17de":"code","907c58fe":"code","469e0b95":"code","6fc78d93":"code","a697f6f5":"code","6e66e8d8":"markdown","15ac2177":"markdown","10a8f0ee":"markdown","dede9ae3":"markdown","1f5bb99e":"markdown","72cb98a4":"markdown","376eac6d":"markdown","5fbc4d99":"markdown","102fd728":"markdown","5e8bd725":"markdown","c67bb3c9":"markdown","68e35865":"markdown","50d7fa5d":"markdown","840adc13":"markdown","8b6d2d83":"markdown","d1e07f15":"markdown","c51bfcfc":"markdown","633a03e2":"markdown","869e0243":"markdown","647bb434":"markdown","35e9d0fc":"markdown","acf9bde2":"markdown","98bf42fc":"markdown","ded5e9c1":"markdown","ac012c76":"markdown","0a8667aa":"markdown","62185134":"markdown","2b68644b":"markdown","19e1b4c8":"markdown","64b4c0cb":"markdown","5193e085":"markdown","f71a1719":"markdown","eac617db":"markdown","9fc71e3e":"markdown","cb4c2a7c":"markdown","9f606ccd":"markdown","274bee66":"markdown"},"source":{"e0abcca6":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f7eaaa8c":"#loading useful libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom matplotlib import rc\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom cycler import cycler\n\nget_ipython().run_line_magic('load_ext', 'autoreload')\nget_ipython().run_line_magic('autoreload', '2')\n\nget_ipython().run_line_magic('matplotlib', 'inline')\nplt.style.use('dark_background')\nmpl.rcParams['axes.prop_cycle'] = cycler('color', ['#ff0000', '#0000ff',   '#00ffff','#ffA300', '#00ff00', \n     '#ff00ff', '#990000', '#009999', '#999900', '#009900', '#009999'])\n\nrc('font', size=16)\nrc('font',**{'family':'serif','serif':['Computer Modern']})\nrc('text', usetex=False)\nrc('figure', figsize=(12, 10))\nrc('axes', linewidth=.5)\nrc('lines', linewidth=1.75)","3ec9ad15":"df = pd.read_csv(\"\/kaggle\/input\/noshowappointments\/KaggleV2-May-2016.csv\")","fd4ee764":"df.head()","05d20378":"df['scheduled_day'] = pd.to_datetime(df['ScheduledDay'], format= \"%Y-%m-%d %H:%M:%S\")\ndf['appointment_day'] = pd.to_datetime(df['AppointmentDay'], format= \"%Y-%m-%d %H:%M:%S\")","b9af4253":"df.head()","b199d16d":"df['no_show'] = df['No-show'].map({\"No\": 0, \"Yes\": 1}).astype(bool)\ndf.drop(columns=['No-show', \"ScheduledDay\",\"AppointmentDay\"], inplace=True)","6379375f":"df.head()","61a839cd":"df.rename(columns={'Hipertension': \"hypertension\", \"Handcap\": \"handicap\",\n                       \"PatientId\": \"patient_id\", \"AppointmentID\": \"appointment_id\"}, inplace=True)\nrename_cols = {col: col.lower() for col in df.columns}\ndf.rename(columns=rename_cols, inplace=True)\ndf['gender'] = df['gender'].map({\"M\": 0, \"F\": 1}).astype(bool)\nfor col in ['scholarship',\"hypertension\",\"diabetes\",\"alcoholism\",\"handicap\",\"sms_received\"]:\n    df[col] = df[col].astype(bool)    ","52832d85":"df.head()","12359d18":"df.dtypes","2a699804":"df.patient_id.nunique()","c105ecaf":"df.shape","f360a5f8":"pids_unique = df.patient_id.unique()\nmap_pids = {i: k for k, i in enumerate(pids_unique)}\ndf['patient_id'] = df['patient_id'].map(map_pids)","2fe504be":"df.age.agg([max, min, 'mean'])","54181849":"df.loc[df.age>90].shape","6eb72d8e":"df['age'] = df['age'].clip(0,90)","36e16e74":"df['appointment_day'].nunique()","fb1764ae":"df['appointment_day'].agg([min,max])","46d1c80f":"df['scheduled_day'].agg([min,max])","db3103e0":"df['scheduled_day'].nunique()","d96813d4":"(df['appointment_day'] < df['scheduled_day']).sum()","e7821216":"def diagnose_cols(df_small):\n    for col in df.columns:\n        nunique = df_small[col].nunique()\n        print(f\"number of unique values in {col}\", nunique)\n        if nunique == 1:\n            print(df_small[col].unique())\n    print(\"Average number of no-shows\", df_small[\"no_show\"].mean())","312f885f":"diagnose_cols(df.loc[df.appointment_day < df.scheduled_day])","056c8c31":"df['no_show'].mean()","87aa8c71":"df.loc[df.appointment_day < df.scheduled_day,[\"scheduled_day\",\"appointment_day\"]].head()","35c3bd5d":"df.loc[df.appointment_day < df.scheduled_day, \"appointment_day\"] = df.loc[\n        df.appointment_day < df.scheduled_day, \"appointment_day\"] + pd.Timedelta(\"1d\")","c70bffc2":"df.query('appointment_day < scheduled_day').shape","cafa0d7a":"df.drop(df.loc[df.appointment_day < df.scheduled_day].index, inplace=True)","3c56c754":"for col in ['patient_id', 'appointment_id']:\n    df[col] = df[col].astype('category')","5310ee42":"age_bins = {k: i for i, k in enumerate(np.sort(pd.cut(df['age'], bins= 9, retbins=False).unique()))}\ndf['age_group'] = pd.cut(df['age'], bins=9).map(age_bins).astype(int)","ef02698c":"df.head()","b9c5667a":"# Plot no show for each age group, across the two genders\nax = df.pivot_table(values='no_show', index=\"age_group\", columns=\"gender\", aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and gender\");","2fe9a569":"ax = df.pivot_table(values='no_show', index=\"age_group\", columns=\"scholarship\", aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and scholarship\");","10f2ed2a":"df.groupby(\"scholarship\")['no_show'].mean()","c12a1121":"ax = df.pivot_table(values='no_show', index=\"age_group\", columns=\"hypertension\", aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and hypertension\");","790e984a":"ax = df.pivot_table(values='no_show', index=\"age_group\", columns=\"diabetes\", aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and diabetes\");","817c5557":"ax = df.pivot_table(values='no_show', index=\"age_group\", columns=\"alcoholism\", aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and alcoholism\");","790cf05e":"df.groupby('alcoholism')['no_show'].mean()","56a33a6f":"ax =df.pivot_table(values='no_show', index=\"age_group\", columns=\"handicap\", aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and handicap\");","1f643265":"df.groupby('handicap')['no_show'].mean()","4b2d81cd":"ax = df.pivot_table(index='age_group', columns='sms_received', values='no_show', aggfunc=np.mean).plot()\nax.set_xlabel(\"age groups\");\nax.set_ylabel(\"Rate of no shows\");\nax.set_title(\"Rate of no shows across age groups and sms_received\");","e1872c0d":"df_rates = pd.DataFrame()\nfor col in df.dtypes[df.dtypes == 'bool'].index:\n    if col != \"no_show\":\n        mean_rate = df.groupby(col)['no_show'].mean()\n        mean_rate.name = mean_rate.index.name\n        #print(ser.name)\n        mean_rate.index.name = ''\n        df_rates[mean_rate.name] = mean_rate","4bbc4d99":"df_rates = df_rates.T","74756f03":"ax = df_rates.plot.barh();\nax.set_title('average rate of no shows for different categories of no show variables');","3bbd7775":"df_agg = pd.DataFrame(index = np.array([(False, False), (False, True), (True, False), (True, True)]))\nbool_cols =  df.dtypes[df.dtypes == 'bool'].index\nbool_cols = bool_cols[bool_cols != 'no_show']\n\nfrom itertools import combinations\nfor t in combinations(bool_cols, 2):\n    cols_to_groupby = list(t)\n    grouped = df.groupby(cols_to_groupby)['no_show'].mean()\n    name1 = grouped.index.get_level_values(0).name\n    name2 = grouped.index.get_level_values(1).name\n    print(name1, name2)\n    grouped.index = grouped.index.values\n    col_name = f'{name1}_{name2}'\n    df_agg[col_name] = grouped\ndf_agg = df_agg.T","65a8f86b":"df_agg.head()","0b3f67b5":"df_agg.plot.barh(figsize=(10,30));","13d445da":"df.neighbourhood.nunique()","7f55b93c":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(df.groupby('neighbourhood')['no_show'].agg(['mean','count']).sort_values(by='count',\n                                                                                  ascending=True))","a68585bc":"df_geo = pd.read_csv(\"\/kaggle\/input\/latitude-longitude-brazil\/cleaned_geo_info.csv\")","8e3b643c":"df_geo.head()","924db659":"df_r = df_geo[['latitude','longitude']].round()\nfor cols in df_r.columns:\n    print(df_r[cols].unique())","b949cf34":"df_geo['long_round'] = df_geo.longitude.round()","59221820":"# we remove the extreme values in longitude to make plotting easier. These extreme values correspond to off shore islands, which have very few\n# appointments anyway\ndf_geo.drop(df_geo.query('long_round in [-35,-29]').index, inplace=True)","ab30a428":"df_geo.plot.scatter(x = 'longitude', y='latitude')","1d6f3abb":"df_neighbourhood = df.groupby('neighbourhood')['no_show'].mean().reset_index()","bff51aea":"df_geo = pd.merge(df_geo, df_neighbourhood, how='left', on='neighbourhood')","a71b4344":"df_geo.drop(columns='long_round', inplace=True)","57797b36":"df_geo.head()","19ee8952":"plt.figure(figsize=(15,15))\nplt.scatter(x=df_geo['longitude'], y=df_geo['latitude'], c=df_geo['no_show']);\nplt.title('Geographic variation in no show rates');\nplt.colorbar()","235183bb":"# %load utils.py\nimport pandas as pd\nimport numpy as np\n\ndef load_data():\n    df = pd.read_csv(\"\/kaggle\/input\/noshowappointments\/KaggleV2-May-2016.csv\")\n    # setting the correct date time formats\n    df['scheduled_day'] = pd.to_datetime(df['ScheduledDay'], format= \"%Y-%m-%d %H:%M:%S\")\n    df['appointment_day'] = pd.to_datetime(df['AppointmentDay'], format= \"%Y-%m-%d %H:%M:%S\")\n    df.rename(columns={'Hipertension': \"hypertension\", \"Handcap\": \"handicap\",\n                       \"PatientId\": \"patient_id\", \"AppointmentID\": \"appointment_id\"}, inplace=True)\n    df['no_show'] = df['No-show'].map({\"No\": 0, \"Yes\": 1}).astype(bool)\n    df.drop(columns=['No-show', \"ScheduledDay\",\"AppointmentDay\"], inplace=True)\n    rename_cols = {col: col.lower() for col in df.columns}\n    df.rename(columns=rename_cols, inplace=True)\n    df['gender'] = df['gender'].map({\"M\": 0, \"F\": 1}).astype(bool)\n    for col in ['scholarship',\"hypertension\",\"diabetes\",\"alcoholism\",\"handicap\",\"sms_received\"]:\n        df[col] = df[col].astype(bool)\n    # patient_ids are float numbers. Mapping them to integers\n    pids_unique = df.patient_id.unique()\n    map_pids = {i: k for k, i in enumerate(pids_unique)}\n    df['patient_id'] = df['patient_id'].map(map_pids)\n    # Age more than 90 is unlikely, so clipping\n    df.loc[df.age > 90, \"age\"] = 90\n    # One age value is negative. Replacing with zero\n    df.loc[df.age < 0, \"age\"] = 0\n    # calling a function to remove errors in dates\n    correct_date_errors(df)\n    for col in ['patient_id', 'appointment_id']:\n        df[col] = df[col].astype('category')\n    # converting age into a categorical feature. This is useful for visualization and to create cross category features\n    map_bins = {k: i for i, k in enumerate(np.sort(pd.cut(df['age'], bins= 9, retbins=False).unique()))}\n    df['age_group'] = pd.cut(df['age'], bins=9).map(map_bins).astype(int)\n    return df\n\n\n# This function removes errors in date. Some appointment dates are behind scheduled dates. This is impossible.\n# So I add 1 day to fix this. The ones that are still behind ( I counted five), I drop, since they are too few to affect prediction\ndef correct_date_errors(df):\n    df['error_occured'] = df['appointment_day'] < df['scheduled_day']\n    df.loc[df.appointment_day < df.scheduled_day, \"appointment_day\"] = df.loc[\n        df.appointment_day < df.scheduled_day, \"appointment_day\"] + pd.Timedelta(\"1d\")\n    df.drop(df.loc[df.appointment_day < df.scheduled_day].index, inplace=True)","b34d0f5a":"from itertools import combinations\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom time import perf_counter\ndef get_features():\n    time_now = perf_counter()\n    df = load_data()\n    # loading latitude and longitude data: pre-generated\n    geo = pd.read_csv(\"\/kaggle\/input\/latitude-longitude-brazil\/cleaned_geo_info.csv\")\n    # merge the longitude latitude data\n    df = pd.merge(df, geo, on = \"neighbourhood\", how=\"left\")\n    # select only boolean columns\n    bool_cols =  df.dtypes[df.dtypes == 'bool'].index\n    bool_cols = bool_cols[bool_cols != 'no_show']\n\n    \n    # make cross category boolean columns.\n    # example: gender = F and alcoholism = True\n    for combs in combinations(bool_cols,2):\n        comb_list = list(combs)\n        df['_'.join(comb_list)] = df[comb_list].product(axis=1)\n    # interaction term between age and boolean columns\n    for bool_col in bool_cols:\n        df[f\"{bool_col}_age\"] = df[\"age\"] * df[bool_col]\n    df[bool_cols] = df[bool_cols].astype(np.int16)\n    \n    # neighbourhood are string objects. Convert them to integers\n    unique_neighbourhoods = df.neighbourhood.unique()\n    neighbourhood_map = {x: k for k,x in enumerate(unique_neighbourhoods)}\n    df[\"neighbourhood\"] = df[\"neighbourhood\"].map(neighbourhood_map)\n    # interaction feature between neighbourhoods and boolean columns\n    for bool_col in bool_cols:\n        df[f\"{bool_col}_neighbourhoods\"] = df[\"neighbourhood\"] * df[bool_col]\n    # interaction between neighbourhood and age\n    #df[\"neighbourhood_age\"]  = df[\"neighbourhood\"]*10 + df[\"age_group\"]\n    #unique_pairs_map = {x:i for i,x in enumerate(df[\"neighbourhood_age\"].unique())}\n    #df[\"neighbourhood_age\"] = df[\"neighbourhood_age\"].map(unique_pairs_map)\n    #df[\"neighbourhood_age\"] = df[\"neighbourhood_age\"].astype(int)\n    df[\"neighbourhood\"] = df[\"neighbourhood\"].astype(int)\n    \n    df[\"appointment_date\"] = df[\"appointment_day\"].dt.date\n    df[\"scheduled_date\"] = df[\"scheduled_day\"].dt.date\n    # date features\n    for date_type in [\"appointment_day\", \"scheduled_day\"]:\n        df[f\"{date_type}_day\"] = df[date_type].dt.day \n        df[f\"{date_type}_weekday\"] = df[date_type].dt.weekday\n        df[f\"{date_type}_month\"] = df[date_type].dt.month\n        df[f\"{date_type}_hour\"] = df[date_type].dt.hour\n    \n    # time between appointments\n    df[\"days_to_appointment\"] = (df[\"appointment_day\"] - df[\"scheduled_day\"]).dt.days\n    \n    # time-based features\n    # historic features for patient, location\n    \n    # patient:\n    # for each patient and appointment: take scheduled_day\n    # take all appointments of patient with appointmentday less than scheduled_day\n    # take mean of df[\"no_show\"]\n    # similarly for locations\n    add_history_to_df(df, \"patient_id\")\n    add_history_to_df(df, \"neighbourhood\")\n    df.drop(columns=[\"appointment_id\", \"patient_id\", \"age_group\", \n                     \"appointment_day\", \"appointment_day_hour\", \"scheduled_day\", \"error_occured\", \"appointment_date\", \"scheduled_date\"], inplace = True)\n    print(f\"{df.shape[1]-1} features generated in \", perf_counter() - time_now, \" seconds\")\n    return df\n\n\n# This function calculates the historical cancellation probability for patient_id and location\n# For example: at this location what is the probabiity of cancelled appointments till now?\ndef add_history_to_df(df, col_name):\n    appointment_days = np.sort(df[\"appointment_day\"].dt.date.unique())\n    df[f\"{col_name}_history\"]  = 0\n    print(f\"generating {col_name} features\")\n    df_res = get_no_show_history(df, appointment_days, col_name)\n    for k in range(1,len(appointment_days)):\n        low_lim = appointment_days[k]\n        try:\n            up_lim = appointment_days[k+1]\n        except:\n            up_lim = appointment_days.max() + pd.Timedelta(\"2d\")\n        map_df = df_res.query(\"appointment_day == @low_lim\").set_index(col_name)[\"no_show\"]\n        df_temp = df.query(\"@low_lim <= scheduled_date < @up_lim\")\n        df.loc[(df.scheduled_date >= low_lim) & (df.scheduled_date < up_lim),f\"{col_name}_history\"] = df_temp[col_name].map(map_df)\n        \n        \ndef get_no_show_history(df, appointment_days, col_name):\n    u_pid = df[col_name].unique()\n    df_full = []\n    for k in appointment_days[1:]:\n        df_past = df.query(\"appointment_date < @k\")\n        df_past = df_past.groupby(col_name)[\"no_show\"].mean()\n        df_all = pd.Series(0,index = u_pid, name=\"no_show\")\n        df_all.index.name = col_name\n        df_all.update(df_past)\n        df_all = df_all.reset_index()\n        df_all[\"appointment_day\"] = k\n        df_full.append(df_all)\n    df_res = pd.concat(df_full)\n    return df_res","b999b3c5":"df_features = get_features()","48f12767":"predictors = df_features.columns[df_features.columns != 'no_show']\ndf_x = df_features[predictors]\ndf_y = df_features['no_show']","9bc01440":"from sklearn.model_selection import train_test_split\n# notice the stratification. This is important because of slightly imbalanced classes\nx_train, x_test, y_train, y_test = train_test_split(df_x, df_y, stratify = df_y, random_state=23)","fa022bc6":"from sklearn.ensemble import RandomForestClassifier\nrf  = RandomForestClassifier(n_jobs=-1, n_estimators=300)","07784582":"rf.fit(x_train, y_train)","d1af17de":"pd.Series(rf.feature_importances_, index = predictors).sort_values(ascending=False).head(20).plot.barh(figsize = (10,20))","907c58fe":"# let us take 25 most important variables\nmost_imp_variables = pd.Series(rf.feature_importances_, index = predictors).sort_values(ascending=False).head(25).index","469e0b95":"print(most_imp_variables)","6fc78d93":"from sklearn.metrics import roc_auc_score\nrf  = RandomForestClassifier(n_jobs=-1, n_estimators=300, random_state=23)\nrf.fit(x_train[most_imp_variables], y_train)\ntrain_score = rf.predict_proba(x_train[most_imp_variables])[:,1]\nprint(\"ROC AUC curve for train data is \", roc_auc_score(y_train, train_score))\ntest_score = rf.predict_proba(x_test[most_imp_variables])[:,1]\nprint(\"ROC AUC curve for test data is\" , roc_auc_score(y_test, test_score))","a697f6f5":"from sklearn.metrics import accuracy_score\ntest_pred = rf.predict(x_test[most_imp_variables])\naccuracy_score(y_test, test_pred)","6e66e8d8":"Curiously patient_id is a float number.  We will convert it to an integer. ","15ac2177":"### Feature Generation","10a8f0ee":"308 records have age greater than 90. We remove the outliers by clipping `age` to the range [0,90]","dede9ae3":"So there are only 27 unique values in appointment_day and for around 40000 records these dates are behind scheduled_day! This clearly represents an error in data entry, since appointment_day cannot be behind the day when the appointment was booked!","1f5bb99e":"The above plot shows that the dependence of no show on hypertension depends on the age variable. That is, for some age groups ( 1, 5-8) the people with hypertension miss more appointments than people with hypertension=False. Whereas for age groups 2 - 4, people without hypertension miss appointments more. This means that our model will benefit from considering an interaction term between age and hypertension.","72cb98a4":"Indeed, people with scholarship have a slightly higher global rate of no shows than for those without!","376eac6d":"There is no striking pattern in these columns except that most appointments in these records didn't miss their appointments since the rate of no_shows is much less than the global rate","5fbc4d99":"There are five records that are still \"wrong\" despite the correction. We will just drop them since they are so few","102fd728":"4 neighbourhoods have less than 10 total appointments each. Since this is not enough data for meaningful inference, it'd be a good\nidea to combine these small neighbourhoods with others to reduce the cardinality of the neighbourhood category variable","5e8bd725":"## EDA\n\nThe data contains a lot of boolean variables. Let us analyze how the output variable no_show relates to these boolean variables","c67bb3c9":"I chose ROC AUC score because the data is slightly imbalanced. The model is heavily overfit to train data. However we obtain a test score of 0.75\nwhich is not bad. Tuning the hyperparameters can help to reduce overfitting and improve test score even more","68e35865":"Another example of why considering feature interactions is important. Alcoholism on an average does not seem to have much influence on the no_show variable ( rate of no shows is around 0.2 for alcoholics and others). But when we consider interactions across age groups, we can see that the rate of no shows changes with alcoholism.","50d7fa5d":"# Data Exploration and Cleaning","840adc13":"Let us recode the No-show column to boolean and also rename it to make indexing easier","8b6d2d83":"`sms_received` seems to have a huge impact on `no_show`\n\nWeirdly people who received a reminder sms missed appointments more! It could be that an sms was sent out to those who were likely to miss appointments? This is something to be explored.","d1e07f15":"From the above plot we can see the variables `gender`, `alcoholism` used by themselves are the least informative, and `sms_received` and `scholarship` are the most informative","c51bfcfc":"How does no show vary among neighbourhoods?","633a03e2":"First let us load the required libraries and configure plot settings","869e0243":"Now let us look at the interactions of these variables","647bb434":"In order to better study the geographical variation in appointment no shows, I manually found the latitude and longitude info for each neighbourhood from Google Maps. It was helpful that all neighbourhoods are in Vitoria, Esperito Santo. They are in the file `cleaned_geo_info.csv`","35e9d0fc":"### Plot feature importances","acf9bde2":"We can observe that the appointment_day column does not have the hour information and that most appointments happen on the same day as the scheduled_day. It could be that the appointment_day column is off by 1 day. We will correct this error by adding 1 day to the appointment columns that are in error","98bf42fc":"### Utility function to load data\n\nWe make a function with all the data cleaning and correction presented above","ded5e9c1":"Although the geographic pattern is not striking, we can see small values (blueish) tend to cluster together, and large values (yellowish) tend to cluster together, and neighbourhoods of large values tend to have large values and vice versa. So including geographic info could still be useful.","ac012c76":"## Fitting a Random Forest","0a8667aa":"There are 81 unique neighbourhoods","62185134":"We can see that gender does not influence the rate of no shows by much. However the rate does depend on age. It peaks for ages between 10-20 and drops as the age increases. ","2b68644b":"In this kernel I explore the dataset \"Appointment No shows\". This dataset contains medical appointment no-shows over a period of two \nyears in the Brazilian state of Esperito Santo. We are given patient information such as preexisting medical conditions and economic and social backgrounds\nand the goal is to predict the probability that the patient does not show up for their appointment.","19e1b4c8":"Let us make sure to parse the date columns correctly using pandas date_time functionality","64b4c0cb":"`patient_id` is float but has only around half the number of unique elements as the total number of records.\nIt will be useful to recode patient_id to an integer","5193e085":"So we see that for people with scholarship the rate of missed appointments is slightly higher than for those without.\nSo scholarship represents an important variable","f71a1719":"## Hypertension and no show dependence","eac617db":"Let us go deep into what the issue is.","9fc71e3e":"Before fitting a random forest, we need to first generate features. Based on the EDA we did above, we know that we need to include\ninteraction terms as well as geographic info like latitude and longitude","cb4c2a7c":"The max age is 115 and minimum is -1. These are clearly erroneous. ","9f606ccd":"Now let us look at the `appointment_day` and `scheduled_day` columns","274bee66":"People with diabetes miss appointments more than people without diabetes"}}