{"cell_type":{"d8deee32":"code","6204e268":"code","2041e5ba":"code","ed35680b":"code","a31ccfd0":"code","1aa74286":"code","acd8dfc6":"code","3566f94a":"code","2da6e1b7":"code","b649902e":"code","d7a412b0":"code","bfa166a6":"code","63b988b2":"code","4e44df1f":"code","925747d9":"code","2d482155":"code","90f75f9f":"code","8ca088d4":"code","517b651c":"code","340e5295":"code","7995dfbb":"code","290856fe":"code","a2e8d31f":"code","d06efb88":"code","2341f1d4":"code","691f0457":"code","260bdcd6":"code","28b01e3b":"code","4d8c65fa":"code","4527a215":"code","df492c75":"code","ff5da592":"code","ac2966a1":"code","c7c93a02":"code","3b62ecc1":"code","9884da02":"code","59bebc6a":"code","860c8e0f":"code","47252047":"code","372ba355":"code","193d9439":"code","03470f1f":"code","70ea9226":"code","db5bac69":"code","d2a8a105":"code","2e048951":"code","05036dee":"code","5c2c01c3":"code","d523ad90":"code","c63a70c0":"code","4a1f3fdf":"code","988050eb":"code","9185512c":"code","607a1160":"code","4ec5cc0e":"markdown","3f0b8ff5":"markdown","931494fe":"markdown","ff1b17a7":"markdown","527dcf28":"markdown","92e9f743":"markdown","21fd8ef7":"markdown","4e1aa351":"markdown","1b7aede1":"markdown","d2cae25c":"markdown","5b209618":"markdown","903d7863":"markdown","ee23638f":"markdown","cb26ec3d":"markdown","4532cdeb":"markdown","ab8740c4":"markdown","69ebb2db":"markdown","dcfdf2e0":"markdown","6d5e30b2":"markdown","cfa35816":"markdown","6dbc2d9c":"markdown","4ca68275":"markdown","c248ed53":"markdown","1a1ec765":"markdown","cba2401e":"markdown","d86aef9e":"markdown","9fe99771":"markdown","945c6b6d":"markdown","def062b2":"markdown","d75ce340":"markdown","452a092f":"markdown","7725f373":"markdown","64f8f8c1":"markdown"},"source":{"d8deee32":"# This is a Python 3 environment \n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# Importing libraries for\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport os # files\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # plotting\nfrom sklearn.ensemble import RandomForestClassifier # machine learning","6204e268":"# Installing and importing PyCaret, which will be demonstrated in this notebook\n!pip install pycaret\nfrom pycaret.classification import *","2041e5ba":"# Importing the files\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ed35680b":"# Loading the training dataset\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head(10)","a31ccfd0":"# Loading the testing dataset\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head(10)","1aa74286":"# Training data information\ntrain_data.info()","acd8dfc6":"# Null values count in each column\nprint(train_data.isnull().sum())","3566f94a":"# Description of dataset\ntrain_data.describe()","2da6e1b7":"# Description of dataset including non-numeric values\ntrain_data.describe(include=\"all\")","b649902e":"f,ax=plt.subplots(1,2,figsize=(18,8))\ntrain_data['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived',data=train_data,ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","d7a412b0":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\nprint(\"Women survival: \", round(rate_women*100, 2), \"%\")","bfa166a6":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nprint(\"Men survivial: \", round(rate_men*100, 2), \"%\")","63b988b2":"f,ax=plt.subplots(1,2,figsize=(18,8))\ntrain_data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex',hue='Survived',data=train_data,ax=ax[1])\nax[1].set_title('Sex:Survived vs Dead')\nplt.show()","4e44df1f":"sns.heatmap(train_data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) \nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","925747d9":"# Sorting the ages into logical categories\ntrain_data[\"Age\"] = train_data[\"Age\"].fillna(-0.5)\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain_data['AgeGroup'] = pd.cut(train_data[\"Age\"], bins, labels = labels)\ntest_data['AgeGroup'] = pd.cut(test_data[\"Age\"], bins, labels = labels)\n\n# Bar plot\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train_data)\nplt.show()","2d482155":"# CabinBool\ntrain_data[\"CabinBool\"] = (train_data[\"Cabin\"].notnull().astype('int'))\ntest_data[\"CabinBool\"] = (test_data[\"Cabin\"].notnull().astype('int'))\n\nprint(\"Percentage of CabinBool = 1 who survived:\", train_data[\"Survived\"][train_data[\"CabinBool\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of CabinBool = 0 who survived:\", train_data[\"Survived\"][train_data[\"CabinBool\"] == 0].value_counts(normalize = True)[1]*100)\n\n# CabinBool vs. Survival\nsns.barplot(x=\"CabinBool\", y=\"Survived\", data=train_data)\nplt.show()","90f75f9f":"# For filling in the missing values in the Embarked feature\nprint(\"Number of people embarking in Southampton (S):\")\nsouthampton = train_data[train_data[\"Embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = train_data[train_data[\"Embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = train_data[train_data[\"Embarked\"] == \"Q\"].shape[0]\nprint(queenstown)","8ca088d4":"# Replacing the missing values in the Embarked feature with S(with mode)\ntrain_data = train_data.fillna({\"Embarked\": \"S\"})","517b651c":"# Create a combined group of both datasets\ncombine = [train_data, test_data]\n\n# Extract a title for each Name in the train and test datasets\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_data['Title'], train_data['Sex'])","340e5295":"# Replace various titles with more common names\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\ntrain_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","7995dfbb":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_data.head()","290856fe":"# Fill missing age with mode age group for each title\nmr_age = train_data[train_data[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\nmiss_age = train_data[train_data[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\nmrs_age = train_data[train_data[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\nmaster_age = train_data[train_data[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\nroyal_age = train_data[train_data[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\nrare_age = train_data[train_data[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n\nfor x in range(len(train_data[\"AgeGroup\"])):\n    if train_data[\"AgeGroup\"][x] == \"Unknown\":\n        train_data[\"AgeGroup\"][x] = age_title_mapping[train_data[\"Title\"][x]]\n        \nfor x in range(len(test_data[\"AgeGroup\"])):\n    if test_data[\"AgeGroup\"][x] == \"Unknown\":\n        test_data[\"AgeGroup\"][x] = age_title_mapping[test_data[\"Title\"][x]]","a2e8d31f":"# Map each Age value to a numerical value\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain_data['AgeGroup'] = train_data['AgeGroup'].map(age_mapping)\ntest_data['AgeGroup'] = test_data['AgeGroup'].map(age_mapping)\n\ntrain_data.head()","d06efb88":"# Remaining null values\nprint(train_data.isnull().sum())","2341f1d4":"# Dropping the Cabin feature since not a lot more useful information can be extracted from it\ntrain_data = train_data.drop(['Cabin'], axis = 1)\ntest_data = test_data.drop(['Cabin'], axis = 1)","691f0457":"# Convering Embarked to numerical value\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain_data['Embarked'] = train_data['Embarked'].map(embarked_mapping)\ntest_data['Embarked'] = test_data['Embarked'].map(embarked_mapping)\n\ntrain_data.head()","260bdcd6":"print(train_data.info())\nprint('-'*25)\nprint(\"Null Values:\")\nprint(train_data.isnull().sum())","28b01e3b":"y = train_data[\"Survived\"]\n\n# Features to be taken into account for training\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"AgeGroup\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n# Training\nmodel.fit(X, y)\n# Predicting using the test dataset\npredictions = model.predict(X_test)","4d8c65fa":"# Saving the submission with PassengerId, and Survival prediction\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('random_forest_submission.csv', index=False)\nprint(\"Submission file was successfully saved!\")","4527a215":"clf1 = setup(train_data, target = 'Survived', ignore_features = ['Ticket', 'Name', 'PassengerId'], silent = True, session_id = 786) ","df492c75":"# Different models\nmodels()","ff5da592":"compare_models()","ac2966a1":"lr = create_model('lr')","c7c93a02":"tuned_lr = tune_model(lr, optimize = 'AUC', n_iter = 100)","3b62ecc1":"plot_model(tuned_lr)","9884da02":"plot_model(tuned_lr, plot =\"confusion_matrix\")","59bebc6a":"plot_model(tuned_lr, plot =\"threshold\")","860c8e0f":"plot_model(tuned_lr, plot =\"pr\")","47252047":"plot_model(tuned_lr, plot =\"error\")","372ba355":"plot_model(tuned_lr, plot =\"rfe\")","193d9439":"plot_model(tuned_lr, plot =\"learning\")","03470f1f":"plot_model(tuned_lr, plot =\"vc\")","70ea9226":"plot_model(tuned_lr, plot =\"feature\")","db5bac69":"plot_model(tuned_lr, plot =\"boundary\")","d2a8a105":"predictions = predict_model(tuned_lr, data = test_data)\npredictions.head()","2e048951":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.Label})\noutput.to_csv('lr_submission.csv', index=False)\nprint(\"Submission file was successfully saved!\")\noutput.head()","05036dee":"catboost = create_model('catboost')","5c2c01c3":"tuned_catboost = tune_model(catboost, optimize = 'AUC', n_iter = 100)","d523ad90":"\ninterpret_model(tuned_catboost)","c63a70c0":"interpret_model(tuned_catboost, plot=\"correlation\")","4a1f3fdf":"interpret_model(tuned_catboost, plot = 'reason', observation = 10)","988050eb":"predictions = predict_model(tuned_catboost, data = test_data)","9185512c":"predictions.head()","607a1160":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.Label})\noutput.to_csv('catboost_submission.csv', index=False)\nprint(\"Submission file was successfully saved!\")","4ec5cc0e":"### Feature Importance","3f0b8ff5":"## PyCaret\n\nPyCaret is an open source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within minutes in your choice of notebook environment.\nFor more, go to...\nhttps:\/\/pycaret.org\n\n","931494fe":"# Data Exploration","ff1b17a7":"# Data Preprocessing","527dcf28":"### Making prediction on test data","92e9f743":"### Area Under the Curve","21fd8ef7":"## Correlation","4e1aa351":"### Saving the submission","1b7aede1":"# Now using PyCaret to visualize and train with various models","d2cae25c":"### Recursive Feature Selection","5b209618":"### Interpretations are implemented based on the SHAP (SHapley Additive exPlanations) ","903d7863":"### Data Setup","ee23638f":"### Using Logistic Regression","cb26ec3d":"### Class Prediction Error","4532cdeb":"# Importing libraries and dataset","ab8740c4":"### Confusion Matrix","69ebb2db":"## Women who survived","dcfdf2e0":"## Now using CatBoost Classifier","6d5e30b2":"## Data Dictionary\n* survival\tSurvival\t0 = No, 1 = Yes\n* pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n* sex\tSex\t\n* Age\tAge in years\t\n* sibsp\t# of siblings \/ spouses aboard the Titanic\t\n* parch\t# of parents \/ children aboard the Titanic\t\n* ticket\tTicket number\t\n* fare\tPassenger fare\t\n* cabin\tCabin number\t\n* embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n### Variable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","cfa35816":"# Modeling and Training","6dbc2d9c":"### Preicision - Recall Curve","4ca68275":"### Learning Curve","c248ed53":"## Basic RandomForest Classifier","1a1ec765":"## Survival","cba2401e":"## Men who survived","d86aef9e":"### Making predicton on test data","9fe99771":"### Reason Plot at Observation Level\n","945c6b6d":"### Comparing different models","def062b2":"### Correlation Plot","d75ce340":"### Threshold","452a092f":"### Tuning model","7725f373":"### Validation Curve","64f8f8c1":"### Decision Boundary"}}