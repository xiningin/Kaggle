{"cell_type":{"6f64dfa9":"code","918ea717":"code","d8474608":"code","8b2f722f":"code","bff6301e":"code","97ae2e4b":"code","835e965f":"code","6e515541":"code","95ce71ff":"code","c6fd3f68":"code","08362899":"code","5368fbc2":"code","de803cfb":"code","aac91976":"code","aeb8bb30":"code","b5002290":"code","6a0dc068":"code","56905558":"code","e90c1975":"code","412303b3":"code","2d2ce1c2":"code","ec2c5c12":"code","05ace7da":"code","e1f8754e":"code","81f9531b":"code","33ee87f4":"code","f93376a0":"code","d7f64982":"code","9559d340":"code","cf46f27f":"code","57c1b925":"code","9e8ada28":"code","47c10409":"code","bb1a42dd":"code","984c4156":"code","bfb60dd5":"code","30828304":"code","83b48d64":"code","f0fb0a7c":"code","7658c012":"code","a0d594c1":"code","7dd7b458":"code","c5d650a3":"code","86af2638":"code","ba4f5eb5":"code","e34f31d4":"code","2cafa043":"code","ebd0d876":"code","c5fe511f":"code","6fecff41":"code","1c7f2ed8":"code","0cfb2a4e":"code","ed2bbea6":"code","c70ee292":"code","b02f4b05":"code","444e9c13":"code","a9e7be33":"code","9c8d665b":"code","77a65ef1":"code","11ffee0f":"code","3d0f8601":"code","40fba869":"code","034e0595":"code","438f7fc8":"code","d69b2c2b":"code","753e1951":"markdown","07e24873":"markdown","9a573d28":"markdown","8e3f588c":"markdown","4e757026":"markdown","b505dc50":"markdown"},"source":{"6f64dfa9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","918ea717":"import pandas as pd\nimport numpy as np\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nsn.set_style('darkgrid')\nimport folium as folium\nfrom folium import plugins\nfrom folium.plugins import HeatMap","d8474608":"db=pd.read_csv(\"..\/input\/califo\/housing1.csv\", sep = \",\" , encoding=\"utf-8\")\ndb.head(5)","8b2f722f":"db.isnull().sum()","bff6301e":"sn.heatmap(db.isnull(), cbar = False)","97ae2e4b":"db.info()","835e965f":"dbCopy = db.copy()\nsn.heatmap(dbCopy.corr() , annot = True)","6e515541":"plt.scatter(dbCopy['longitude'] , dbCopy['latitude'] , color = 'green')","95ce71ff":"plt.figure(figsize=(18,10))\nplt.scatter(db['latitude'],db['longitude'],c=db['population'], cmap='cool', alpha = 0.8)\nplt.colorbar().set_label(\"Population\")\nplt.title('Population Magnitude')\nplt.xlabel('Latitude')\nplt.ylabel('Longitude')\nplt.show()","c6fd3f68":"dbCopy.hist(bins = 120 , figsize=(18,14))","08362899":"db.isnull().sum()","5368fbc2":"db[\"households\"].value_counts()","de803cfb":"db[\"households\"].replace(\"no\" , np.nan , inplace  = True)\ndb[\"households\"] = pd.to_numeric(db[\"households\"])\ndb[\"households\"].value_counts()","aac91976":"plt.subplot(2,1,1)\nplt.title('Distribution Of Room Numbers',fontsize=20)\nsn.kdeplot(db['households'])\nplt.show()","aeb8bb30":"#check doubplicat data\nlen(db)-len(db.drop_duplicates())","b5002290":"db['gender'].value_counts()","6a0dc068":"gender_num = db['gender'].value_counts().sum()\nfemale = db[\"gender\"].value_counts()[0]\nmale = db[\"gender\"].value_counts()[1]\ngender_num","56905558":"male_ratio = male\/ gender_num\nfemale_ratio = female \/ gender_num\ngender_li = [\"female\" , \"male\"]\ndb['gender'] = db['gender'].fillna(pd.Series(np.random.choice(gender_li,  p=[female_ratio,male_ratio], size=len(db))))\nchart=db['gender'].value_counts()\nchart.plot.pie(autopct='%1.1f%%',\n        shadow=True, startangle=70)","e90c1975":"db.isnull().sum() # null in gender become zero","412303b3":"db.dropna(subset=[\"population\"] , inplace = True)\ndb.isnull().sum() #drop population because small part of data is null","2d2ce1c2":"db['housing_median_age']=db['housing_median_age'].replace(np.nan , db['housing_median_age'].mean())\ndb.isnull().sum() # remove null in housing_median_age","ec2c5c12":"plt.figure(figsize=(10, 6))\nplt.hist(db.housing_median_age, bins=100, ec = 'black', color = '#ffcda3')\nplt.xlabel('House age', fontsize=16)\nplt.ylabel('values', fontsize=16)\n\nplt.axvline(db.median_house_value.all(), color='#21209c', linestyle='dashed', linewidth=3)\nplt.xlim(0, 10)\nplt.show()\nplt.style.use('dark_background')","05ace7da":"sn.heatmap(db.isnull(), cbar = True)","e1f8754e":"ra = db['total_bedrooms'] \/ db['total_rooms'] # to see ratio of bedrom to room depend on no nulls in room\ndb['total_bedrooms'].fillna(ra.mean()*db['total_rooms'] , inplace = True)","81f9531b":"plt.subplot(2,1,1)\nplt.title('Distribution Of Room Numbers',fontsize=20)\nsn.kdeplot(db['total_rooms'])\nplt.show()\nplt.subplot(2,1,2)\nplt.title('Distribution Of Total Bedrooms',fontsize=20)\nsn.kdeplot(db['total_bedrooms'])\nplt.show()","33ee87f4":"db.isnull().sum() # remove null data in total_bedrooms depend on rooms bec every room has bedroom so we use the mean","f93376a0":"sn.heatmap(db.isnull(), cbar = True)","d7f64982":"db.info() # we should change type of  households and population to int to fill nulls in households","9559d340":"db['households'].fillna(1 ,inplace  = True)\ndb['households'] =db['households'].astype('int64')\ndb['population'] = db['population'].astype('int64')\ndb.info()","cf46f27f":"# we will use households with population bec they are depened on each other \n#we will calcuate ratio from every house to population  to get value help us to fill the nulls\nrat_mean=(db['households']\/db['population']).mean()\nrat_mean","57c1b925":"db['households'].fillna(rat_mean*db[\"population\"] , inplace = True)\ndb.isnull().sum()","9e8ada28":"sn.kdeplot(db['households'],color='teal')\nplt.show()","47c10409":" #now remain median_income and this depend on median_house_value so we will get ratio to fill nulls \nratio_median=db['median_income'] \/ db['median_house_value']\nmedian = ratio_median.mean()           \nratio_median","bb1a42dd":"#fill nulls\ndb['median_income'].fillna(median * db['median_house_value'] ,inplace =True)","984c4156":"plt.figure(figsize=(10, 6))\nsn.distplot(db.median_house_value, bins = 45, color = '#f88f01', hist = True)\nplt.style.use('dark_background')\nplt.xlabel('Median Price of Houses in a block in $', fontsize=16)\nplt.ylabel('Number of Houses', fontsize=16)\nplt.title('Average Distribution of Median Price of Housing in a Block', fontsize=16)\nplt.show()","bfb60dd5":"db.isnull().sum() #no nulls data preprocessing done","30828304":"california_map = folium.Map(location=[36.7783,-119.4179], zoom_start = 6, min_zoom=5)\ndf_map = db[['latitude', 'longitude']]\ndata = [[row['latitude'],row['longitude']] for index, row in df_map.iterrows()]\n_ = HeatMap(data, radius=10).add_to(california_map)\ncalifornia_map","83b48d64":"db.head()","f0fb0a7c":"freq = db.population.value_counts()\nplt.figure(figsize=(10, 6))\nplt.bar(freq.index, height = freq,ec='#21209c',color='#008891')\nplt.xlabel('population', fontsize=16)\nplt.ylabel('No. of Households', fontsize=16)\nplt.show()","7658c012":"sn.heatmap(db.isnull(), cbar = False)  # no nulls","a0d594c1":"db.hist( bins=120, figsize=(18,14))","7dd7b458":"db.plot(kind = \"box\" , subplots = True , figsize = (18,18), layout = (3,5))","c5d650a3":"db.info()","86af2638":"figure, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(nrows=3, ncols=2)\nfigure.set_size_inches(24,30)\nsn.regplot(db['total_rooms'], db['median_house_value'], ax=ax1)\nsn.regplot(db['total_bedrooms'], db['median_house_value'], ax=ax2)\nsn.regplot(db['population'], db['median_house_value'], ax=ax3)\nsn.regplot(db['households'], db['median_house_value'], ax=ax4)\nsn.regplot(db['median_income'], db['median_house_value'], ax=ax5)\nsn.regplot(db['median_house_value'], db['median_house_value'], ax=ax6)","ba4f5eb5":"db['total_rooms']=np.log(db['total_rooms'])\ndb['total_bedrooms']=np.log(db['total_bedrooms'])\ndb['population']=np.log(db['population'])\ndb['households']=np.log(db['households'])\ndb.describe()","e34f31d4":"Q1 = db.quantile(0.25)\nQ3 = db.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","2cafa043":"#print(db < (Q1 - 1.5 * IQR)) |(db > (Q3 + 1.5 * IQR))","ebd0d876":"db.plot(kind = \"box\" , subplots = True , figsize = (18,18), layout = (3,5))","c5fe511f":"plt.figure(figsize=(10,6))\nsn.heatmap(db.corr() , annot = True)","6fecff41":"db.replace(\"female\", 1 , inplace = True)\ndb.replace(\"male\", 0 , inplace = True) \ndb.drop('ocean_proximity' , axis=1 , inplace = True)","1c7f2ed8":"\nX = db.drop(\"median_house_value\" , axis = 1).values\ny = db['median_house_value'].values","0cfb2a4e":"from sklearn.model_selection import train_test_split\n","ed2bbea6":"X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25 , random_state=42)","c70ee292":"from sklearn.preprocessing import StandardScaler\nscale = StandardScaler ()\nX_train = scale.fit_transform(X_train)\nX_test = scale.fit_transform(X_test)","b02f4b05":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)","444e9c13":"lr.score(X_train,y_train)","a9e7be33":"lr.score(X_test,y_test)","9c8d665b":"from sklearn.linear_model import Ridge\nrid = Ridge()\nrid.fit(X_train,y_train)","77a65ef1":"rid.score(X_train,y_train)","11ffee0f":"rid.score(X_test,y_test)","3d0f8601":"y_pre = lr.predict(X_test)","40fba869":"y_pre","034e0595":"from sklearn.metrics import r2_score\nr2 = r2_score(y_test , y_pre)\nr2","438f7fc8":"db.info()","d69b2c2b":"import statsmodels.api as sm\nfrom scipy import stats\nm = sm.add_constant(X)\nest=sm.OLS(y,m)\nest2 = est.fit()\nprint(est2.summary())","753e1951":"**preprocessing data**","07e24873":" the population is more denser in the Northern Part of California","9a573d28":"the mean house price is around  206855.81..\nthe median value is  179700..\nthe houses in california is expensive..","8e3f588c":"**EDA process**","4e757026":"when house more older its price increase","b505dc50":"**Outlier**"}}