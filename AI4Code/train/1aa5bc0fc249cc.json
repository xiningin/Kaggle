{"cell_type":{"a98cfcda":"code","1e843f3b":"code","da997c68":"code","b18b83a9":"code","01200243":"code","e5eb4470":"code","70067bf7":"code","53dfcd25":"code","7ee76585":"code","80910ee9":"code","9a696166":"code","52a01869":"code","c6c207b8":"code","f8586599":"code","f5d2d3f3":"code","65b7a378":"code","7f5a6805":"code","593ccd20":"code","81967417":"code","7c36ebb3":"code","b3b2abf3":"code","34276de0":"code","a1986d66":"code","f84e11e2":"code","508e920d":"code","ac6cad4d":"code","aab12d77":"code","a3f11d4e":"code","74fe2cb5":"code","ed93436d":"markdown","18583dd0":"markdown","316b936b":"markdown","24240fbe":"markdown","ef9e998b":"markdown","2d6a447d":"markdown","04ab06c1":"markdown","a133ca4e":"markdown","879fcb6d":"markdown","cb0f3e89":"markdown","d8b5ee31":"markdown","193c3226":"markdown","d31053a0":"markdown","6b118220":"markdown","5552772c":"markdown","97528101":"markdown","66d5d981":"markdown"},"source":{"a98cfcda":"! pip install pycaret # Quite large depencies to install !","1e843f3b":"import numpy as np\nimport pandas as pd\nfrom tpot import TPOTClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","da997c68":"data = pd.read_csv('..\/input\/titanic\/train.csv')\ndata.head()","b18b83a9":"import pycaret\nfrom pycaret.classification import *","01200243":"clf1 = setup(data = data, \n             target = 'Survived',\n             numeric_imputation = 'mean',\n             categorical_features = ['Sex','Embarked'], \n             ignore_features = ['PassengerId','Name','Ticket','Cabin'],\n             silent = True)","e5eb4470":"compare_models()","70067bf7":"lgbm  = create_model('lightgbm')     ","53dfcd25":"tuned_lgbm = tune_model('lightgbm')","7ee76585":"plot_model(estimator = tuned_lgbm, plot = 'learning')","80910ee9":"plot_model(estimator = tuned_lgbm, plot = 'feature')","9a696166":"plot_model(estimator = tuned_lgbm, plot = 'confusion_matrix')","52a01869":"# AUC Curve for Classifications models\nplot_model(estimator = tuned_lgbm, plot = 'auc')","c6c207b8":"# Understand which feature had most role to play in the classification task\ninterpret_model(tuned_lgbm)","f8586599":"save_model(tuned_lgbm, 'Titaniclgbm')\n# code to load the model for future uses or when making predictions\n# trained_model = load_model('Titaniclgbm')","f5d2d3f3":"# Load the test data\ntest = pd.read_csv('..\/input\/titanic\/test.csv') \npredict_model(tuned_lgbm, data=test)","65b7a378":"predictions = predict_model(tuned_lgbm, data=test)\npredictions.head()","7f5a6805":"sub   = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","593ccd20":"sub['Survived'] = round(predictions['Score']).astype(int)\nsub.to_csv('submission.csv',index=False)","81967417":"# Blend your model ton other algorithm.\nxgb   = create_model('xgboost');    \nlogr  = create_model('lr');   \nblend = blend_models(estimator_list=[tuned_lgbm,logr,xgb])","7c36ebb3":"data = pd.read_csv('..\/input\/titanic\/train.csv')\ndata.head()","b3b2abf3":"data.isna().sum()","34276de0":"data =  data.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\ndata['Sex'] = le.fit_transform(data.Sex)","a1986d66":"replacer = {'S':2,'C':1,'Q':0}\ndata['Embarked'] = data['Embarked'].map(replacer)\ndata.head()","f84e11e2":"train = data.drop('Survived',axis=1)\ntest = data['Survived']\ntrain.shape, test.shape","508e920d":"X_train, X_test, y_train, y_test = train_test_split(train,test,test_size=0.25)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","ac6cad4d":"# Import tpot classifier and fit train and test datasets\n# Set up Hyper-parameters of the TPOT Classifer such max_time_mins, which states maximum time for training the model through iterations of generations.\ntpot = TPOTClassifier(verbosity=2, max_time_mins=10)\n\ntpot.fit(X_train, y_train)\nprint(tpot.score(X_test, y_test))","aab12d77":"# Check the specifications of the best fit algorith found out by TPOT\ntpot.fitted_pipeline_","a3f11d4e":"print(tpot.score(X_test, y_test))","74fe2cb5":"tpot.export('TPOTSOLN.py')\n# Check the output dir of the Notebook to your top-right. Download it and as a surprise you will see python code of your model with perfectly tuned hyper-parameters. ","ed93436d":"# Compare and Select the Best Algorithm","18583dd0":"# Kindly UPVOTE and Suggest your views and ideas ! Happy Learning !!","316b936b":"Steps invloved in PyCaret Model Building and Development\n1. Installing and Importing PyCaret Library\n2. Dataset Loading\n3. Problem Statement understanding, Classfication or Regression\n4. Loading data into PyCaret framework using setup\n5. Find best models by training it with different algorithms.\n6. Choose the best algorithm\/s and hyper-tune the parameters for better performance.\n7. Visualize the Results\n8. Predictive Analytics using PyCaret\n9. Deployment ready model development\n* **Note:** It hardly takes 6 lines of code to build a deployable predictive model","24240fbe":"Find the sum of missing values in the dataset","ef9e998b":"# Choose the Best performing Algorithm and Check for various Evaluations metrics","2d6a447d":"# 2) TPOT AutoML (Tree Based Pipeline Optimization Tool)","04ab06c1":"Import the Dataset as usual","a133ca4e":"**Automated Machine Learning** or **AutoML** is the automation of Machine Learning algorithms which helps to find best algorithm\/s that best fit the dataset in hand. With advancements in AutoML techniques, the life cycle of a data science process is reduced to a larger extent, making it easier for a company to derive efficient results by investing less time and workflow. It is considered that most Data Scientists spend their time in cleaning and organizing the data to structured formats ready for analysis and further process. Though these AutoML frameworks are not capable of these tasks, however, it helps a Data Science professional to increase his\/her time to look for insights in the data provided or collected, by saving time needed for model building. \n\n\nAdvantages of Automated Machine Learning over traditional Model Development\n1. Increases Productivity by automating repetitive tasks in Data science work flow, which in turn help data scientists and analysts to concentrate more on problem statement and extracting useful insights from data. Thus, one can save lot of time and invest the same in other tasks. \n1. \tReduces the chances of errors when dealing with complex datasets with lot of advanced data-types and features.  Eg. ML models do not work well when dealing with categorical variables but the AutoML frameworks handles this like a piece of cake. \n1. \tEasier to learn for everyone and simple to apply for Developers into their projects in a shorter duration of time.\n1. \tUseful in Hackathons, as one can find the find the optimal solution in a shorter span of time.\n1. \tDeployment ready model can be developed with no risk.","879fcb6d":"# Predictive Analysis using Test data","cb0f3e89":"Save the model you trained to a deployable pickle file (.pkl) using a simple line of code written below. ","d8b5ee31":"# Hypertune the parameters using tune_model function","193c3226":"# Convert the predictions into structured dataframe, such as submission.csv","d31053a0":"Dropping some columns or features and Label Encoding features with categorical values. ","6b118220":"Train and test set splitting","5552772c":"Confusion matrix at its ease!","97528101":"This is an extraoridnary feature of TPOT as it provides the code of the model as output. Here i exported the code of my model that best fits the problem statement. ","66d5d981":"# Load and setup the dataset into PyCaret frame work"}}