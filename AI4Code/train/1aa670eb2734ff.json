{"cell_type":{"96443d03":"code","a73bbe2a":"code","72ff3949":"code","0e250b09":"code","e62c2018":"code","76e9a534":"code","c0473846":"code","aef64908":"code","df59a8e4":"code","411f01b9":"code","9b26e2de":"code","2c51151d":"code","f2f97834":"code","c587686c":"code","a6735020":"code","b28a972c":"code","9fe2c2b8":"code","e9d8a955":"code","107f318e":"code","4ce6672f":"code","91261aa1":"code","207944bc":"code","2cd85e7c":"code","3ca7b82a":"code","eac15002":"code","6272f083":"code","1ef16059":"code","4de84346":"code","ecba1f8d":"code","0a2e6740":"code","14709068":"code","96acee2f":"code","d5e287a6":"markdown","c1e45704":"markdown","f899926b":"markdown","b9f720bd":"markdown","65a92f92":"markdown","4a3640ce":"markdown"},"source":{"96443d03":"!pip install -q git+https:\/\/github.com\/fastai\/fastai2\n!pip install -q git+https:\/\/github.com\/fastai\/fastcore","a73bbe2a":"from fastai2.vision.all import *","72ff3949":"path = Path(\"\/kaggle\/input\/alaska2-image-steganalysis\")","0e250b09":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(15)","e62c2018":"# def label_func(f): return False if f.parent.name == \"Cover\" else True\ndef label_func(f): return f.parent.name","76e9a534":"read_files = partial(get_image_files, folders=[\"JUNIWARD\", \"JMiPOD\", \"Cover\", \"UERD\"])","c0473846":"files = read_files(path)","aef64908":"valid_idx = np.concatenate([np.random.permutation(75_000)[:15_000],\n                            np.random.permutation(range(135_000, 150_000))[:15_000],\n                            np.random.permutation(range(210_000, 225_000))[:15_000],\n                            np.random.permutation(range(285_000, 300_000))[:15_000]])","df59a8e4":"def get_data(bs=8):\n    return DataBlock(blocks=(ImageBlock, CategoryBlock),\n                     get_items=lambda x:files,\n                     get_y=label_func,\n                     splitter=IndexSplitter(valid_idx),\n                     item_tfms=None,\n                     #only flips\n                     batch_tfms=aug_transforms(flip_vert=True, max_rotate=0, min_zoom=1,\n                                               max_zoom=1, max_lighting=0, max_warp=0),\n                      ).dataloaders(path, bs=bs)","411f01b9":"# dls = get_data()","9b26e2de":"# dls.show_batch()","2c51151d":"# dls.vocab","f2f97834":"# len(dls.train_ds), len(dls.valid_ds)","c587686c":"# del dls","a6735020":"from sklearn import metrics\n        \ndef alaska_weighted_auc(y_true, y_valid):\n    \"\"\"\n    https:\/\/www.kaggle.com\/anokas\/weighted-auc-metric-updated\n    \"\"\"\n    tpr_thresholds = [0.0, 0.4, 1.0]\n    weights = [2, 1]\n\n    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_valid, pos_label=1)\n\n    # size of subsets\n    areas = np.array(tpr_thresholds[1:]) - np.array(tpr_thresholds[:-1])\n\n    # The total area is normalized by the sum of weights such that the final weighted AUC is between 0 and 1.\n    normalization = np.dot(areas, weights)\n    competition_metric = 0\n    for idx, weight in enumerate(weights):\n        y_min = tpr_thresholds[idx]\n        y_max = tpr_thresholds[idx + 1]\n        mask = (y_min < tpr) & (y_max > tpr)\n        if mask.sum() == 0:\n            continue\n\n        x_padding = np.linspace(fpr[mask][-1], 1, 100)\n        x = np.concatenate([fpr[mask], x_padding])\n        y = np.concatenate([tpr[mask], [y_max] * len(x_padding)])\n        y = y - y_min  # normalize such that curve starts at y=0\n        score = metrics.auc(x, y)\n        submetric = score * weight\n        best_subscore = (y_max - y_min) * weight\n        competition_metric += submetric\n\n    return competition_metric \/ normalization\n\ndef weighted_roc_auc(preds, targs):\n    return alaska_weighted_auc(targs, 1 - preds.clamp(0,1).numpy()[:, 0])","b28a972c":"def get_learner(bs, model):\n    dls = get_data(bs)\n    display(dls.vocab)\n    return cnn_learner(dls, model,\n                       metrics=[error_rate, AccumMetric(weighted_roc_auc, flatten=False)],\n                       ).to_fp16()","9fe2c2b8":"# learn = get_learner(bs=60, model=resnet50)\nlearn = get_learner(bs=160, model=resnet34)","e9d8a955":"# learn.lr_find()","107f318e":"# learn.recorder.plot_lr_find(skip_end=10)","4ce6672f":"lr = 1e-3","91261aa1":"learn.unfreeze()","207944bc":"learn.fit_one_cycle(5, lr)","2cd85e7c":"# interp = ClassificationInterpretation.from_learner(learn)","3ca7b82a":"# interp.plot_top_losses(9, figsize=(15, 10))","eac15002":"# interp.plot_confusion_matrix()","6272f083":"tst_dl = learn.dls.test_dl(get_image_files(path\/\"Test\"))","1ef16059":"preds, _ = learn.get_preds(dl=tst_dl)","4de84346":"subm = pd.read_csv(path\/\"sample_submission.csv\")","ecba1f8d":"subm.head()","0a2e6740":"# subm.iloc[:, 1:] = preds[:, 1]\nsubm.iloc[:, 1:] = 1- preds.numpy()[:, 0]","14709068":"subm.to_csv(\"submission.csv\", index=False)","96acee2f":"pd.read_csv(\"submission.csv\")","d5e287a6":"# Model","c1e45704":"# Submission","f899926b":"# Interpretation","b9f720bd":"This notebook demonstrates how fastai2 makes it easier to do practical DL for domain experts. Imagine you are a detective.","65a92f92":"22\n\nFixed metrics\n\n\n17\n\nAdded metrics","4a3640ce":"# Behold, the DataBlock"}}