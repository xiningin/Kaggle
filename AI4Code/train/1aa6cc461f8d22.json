{"cell_type":{"a8a495c9":"code","8932fbbe":"code","07bbea92":"code","def2510c":"code","c2bd277e":"code","215000b4":"code","a17c47f8":"code","d786aedf":"code","f989fdb1":"code","83cae9f5":"code","290a630b":"code","d3ce9a2c":"code","6147c7fb":"markdown","81b1e47d":"markdown","bca686fc":"markdown","fa774731":"markdown","bce974f1":"markdown","b164871f":"markdown","ac007cfa":"markdown"},"source":{"a8a495c9":"!pip install ..\/input\/keras-applications\/Keras_Applications-1.0.8\/ -f .\/ --no-index\n!pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps","8932fbbe":"import sklearn\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport matplotlib.pyplot as plt\n\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler","07bbea92":"train = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\ntest = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/sample_submission.csv\")\n\n## adding image file names\ntrain[\"file_path\"] = train[\"Id\"].apply(lambda identifier: \"..\/input\/petfinder-pawpularity-score\/train\/\" + identifier + \".jpg\")\ntest[\"file_path\"] = test[\"Id\"].apply(lambda identifier: \"..\/input\/petfinder-pawpularity-score\/test\/\" + identifier + \".jpg\")\n\ntrain.head()","def2510c":"%%time\n\nFEATURE_COLUMNS = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nCAT_FEATURES = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nTARGET_COLUMN = \"Pawpularity\"\n\ndef add_cross_features(df):\n    for feature1 in FEATURE_COLUMNS:    \n        for feature2 in FEATURE_COLUMNS:\n            if feature1 != feature2:\n                x2_feature_name = f'{feature1}-{feature2}'\n                if x2_feature_name not in df.columns:\n                    df[x2_feature_name] = df[feature1].astype(str) + '_' + df[feature2].astype(str)\n                    CAT_FEATURES.append(x2_feature_name)\n                    for feature3 in FEATURE_COLUMNS:\n                        if feature3 != feature2 and feature3 != feature1:\n                            x3_feature_name = f'{feature1}-{feature2}-{feature3}'\n                            if x3_feature_name not in df.columns:\n                                df[x3_feature_name] = df[feature1].astype(str) + '_' + df[feature2].astype(str) + '_' + df[feature3].astype(str)\n                                CAT_FEATURES.append(x3_feature_name)\n    return df\n                \n                \ntrain = add_cross_features(train)\ntest = add_cross_features(test)\n\n## set all features as categorical\nfor c in CAT_FEATURES:\n    train[c] = keras.utils.to_categorical(train[c])\n    test[c] = keras.utils.to_categorical(test[c])\n\nFEATURE_COLUMNS = np.unique(CAT_FEATURES).tolist()\nprint('features len:', len(FEATURE_COLUMNS))\nprint('train shape:',train.shape)\nprint('test shape:',test.shape)","c2bd277e":"IMAGE_SIZE=128\n\n## Feature model\ndef build_feature_model(inputs):\n    width = 64\n    depth = 2\n    activation = \"relu\"\n    dropout = 0.1\n    x = keras.layers.Dense(width, activation=activation)(inputs)\n    for i in range(depth):\n        if i == 0:\n            x = inputs\n        x = keras.layers.Dense(width, activation=activation)(x)\n        #x = keras.layers.Dropout(dropout)(x)\n        if (i + 1) % 3 == 0:\n            x = keras.layers.BatchNormalization()(x)\n            x = keras.layers.Concatenate()([x, inputs])\n    return x\n\ndef RMSE(y_true, y_pred):\n    loss = tf.math.sqrt(tf.math.reduce_mean(tf.math.square(tf.subtract(y_true, y_pred))))\n    return loss\n\ndef block(x, filters, kernel_size, repetitions, pool_size=2, strides=2):\n    for i in range(repetitions):\n        x = tf.keras.layers.Conv2D(filters, kernel_size, activation='relu', padding='same')(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size, strides)(x)\n    return x\n\n# CNN + feature model\ndef build_full_model():\n    image_inputs = tf.keras.Input((IMAGE_SIZE, IMAGE_SIZE , 3))\n    tabular_inputs = tf.keras.Input(len(FEATURE_COLUMNS))\n    efficient_model = efn.EfficientNetB4(include_top=False, \n                                weights='..\/input\/efficientnet-weights-for-keras\/noisy-student\/notop\/efficientnet-b4_noisy-student_notop.h5', \n                                pooling=None)\n    image_x = efficient_model(image_inputs)\n    #block(x, filters, kernel_size, 2, pool_size=2, strides=2)\n    image_x = tf.keras.layers.GlobalAveragePooling2D()(image_x)\n    tabular_x = build_feature_model(tabular_inputs)\n    x = tf.keras.layers.Concatenate(axis=1)([image_x, tabular_x])\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(64)(x)\n    output = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs=[image_inputs, tabular_inputs], outputs=[output])\n    return model\n\nmodel = build_full_model()\ntf.keras.utils.plot_model(model, show_shapes=True)","215000b4":"EPOCHS = 30\nRANDOM_SEED=42\nBATCH_SIZE = 32\nTOTAL_SPLITS = 6\n\ndef preprocess(image_url, tabular, target):\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    return (image, tabular), tf.cast(target, tf.float32)\n\ndef get_dataset(X, train_idx, val_idx):\n\n    X_file = X.loc[train_idx, \"file_path\"]\n    X_features = X.loc[train_idx, FEATURE_COLUMNS ]\n    y = X.loc[train_idx, TARGET_COLUMN ]\n\n    X_val_file = X.loc[val_idx, \"file_path\"]\n    X_val_features = X.loc[val_idx, FEATURE_COLUMNS ]\n    y_val = X.loc[val_idx, TARGET_COLUMN ]\n    \n    dataset = tf.data.Dataset.from_tensor_slices((X_file, X_features, y)).map(preprocess).shuffle(512).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n    val_dataset = tf.data.Dataset.from_tensor_slices((X_val_file, X_val_features, y_val)).map(preprocess).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n    return dataset, val_dataset\n\n# convert tagret to 0-1 range\ntrain[TARGET_COLUMN] = train[TARGET_COLUMN]\/100\n\nimage = np.random.normal(size=(1, IMAGE_SIZE, IMAGE_SIZE, 3))\ntabular = np.random.normal(size=(1, len(FEATURE_COLUMNS)))\n\nprint(image.shape, tabular.shape)\nprint(model((image, tabular)).shape)","a17c47f8":"def get_lr_callback(batch_size=8, plot=False, scheduler='exp', epochs=EPOCHS ):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) \/ lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        elif scheduler=='exp':\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        elif scheduler=='cosine':\n            decay_total_epochs = epochs - lr_ramp_ep - lr_sus_ep + 3\n            decay_epoch_index = epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index \/ decay_total_epochs\n            cosine_decay = 0.5 * (1 + math.cos(phase))\n            lr = (lr_max - lr_min) * cosine_decay + lr_min\n        return lr\n    if plot:\n        plt.figure(figsize=(10,5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('learnig rate')\n        plt.title('Learning Rate Scheduler')\n        plt.show()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n_=get_lr_callback(BATCH_SIZE, plot=True )","d786aedf":"%%time\n\ntf.keras.backend.clear_session()\nearly_stop = tf.keras.callbacks.EarlyStopping(min_delta=1e-4, patience=10)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.3,patience=2, min_lr=1e-7)\noptimizer = tf.keras.optimizers.Adam(0.001)\n\nmodels = []\nhistorys = []\nkfold = KFold(n_splits=TOTAL_SPLITS, shuffle=True, random_state=RANDOM_SEED)\nfor index, (train_idx, val_idx) in enumerate(kfold.split(train)):\n    \n    train_ds, val_ds = get_dataset( train, train_idx, val_idx)\n        \n    checkpoint_path = \"model_%d.h5\"%(index)\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True)\n    callbacks = [early_stop, checkpoint, get_lr_callback(BATCH_SIZE)]    \n    \n    rmse = tf.keras.metrics.RootMeanSquaredError(name='rmse')\n    model.compile(loss=RMSE, optimizer=optimizer, metrics=[rmse])\n    history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=callbacks)\n    \n    model.load_weights(checkpoint_path)\n    historys.append(history)\n    models.append(model)    ","f989fdb1":"xx = range(0, EPOCHS)\ncol_metrics = [\"loss\", \"val_loss\", \"lr\"]\n\nf, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize=(16, 8))\nfor hist in historys:\n    df = pd.DataFrame(hist.history, columns=col_metrics)\n    ax1.plot( df[[col_metrics[0], col_metrics[1]]])\nax2.plot( df[[col_metrics[2]]])\n\nplt.show()","83cae9f5":"def preprocess_test_data(image_url, tabular):\n    print(image_url, tabular)\n    image_string = tf.io.read_file(image_url)\n    image = tf.image.decode_jpeg(image_string, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.central_crop(image, 1.0)\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    # 0 won't be used in prediction, but it's needed in this senario or the tabular variable is treated as label.\n    return (image, tabular), 0\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test[\"file_path\"], test[FEATURE_COLUMNS])).map(preprocess_test_data).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)","290a630b":"results = []\nfor model in models:\n    results.append(model.predict(test_ds).reshape(-1))\n\n# convert back to 100 range\npredictions = np.mean(results, axis=0).reshape(-1)*100\n\nsample_submission[\"Pawpularity\"] = predictions\nsample_submission.to_csv(\"submission.csv\", index=False)","d3ce9a2c":"sample_submission.head(20)","6147c7fb":"# TensorFlow multi-input model + EfficientNet + FE\n\nThis is a first try to build multi model, based on notebooks:\n\nhttps:\/\/www.kaggle.com\/yamqwe\/tf-efficientnet-multi-input\n\nhttps:\/\/www.kaggle.com\/yamqwe\/tf-nfnet-vit-efn-tta-infer\/notebook\n\nhttps:\/\/www.kaggle.com\/awsaf49\/tf-petfinder-image-tpu-train\n\n\nAdding cross-featutes idea is from excelent notebook by Ekaterina Dranitsyna: \n\nhttps:\/\/www.kaggle.com\/ekaterinadranitsyna\/xgboost-for-tabular-data\n","81b1e47d":"## Model","bca686fc":"## Learning-Rate Scheduler\n\nhttps:\/\/www.kaggle.com\/awsaf49\/tf-petfinder-image-tpu-train#Learning-Rate-Scheduler","fa774731":"## Submission","bce974f1":"## Display metrics","b164871f":"## Training","ac007cfa":"## Import datasets"}}