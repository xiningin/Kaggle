{"cell_type":{"18814b5d":"code","7a6db490":"code","9b2c5bae":"code","ee20448f":"code","31a252b9":"code","325379ad":"code","957fd941":"code","e9df7356":"markdown","6fe425cd":"markdown","7fe2c1f8":"markdown"},"source":{"18814b5d":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls ","7a6db490":"import torch\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.data import DatasetCatalog\nimport cv2\nimport pycocotools.mask as mask_util\nimport numpy as np\n","9b2c5bae":"from sartorius_vis import show_predictions, show_zoomed","ee20448f":"register_coco_instances('sartorius_val',{},'..\/input\/sartorius-cell-instance-segmentation-coco\/annotations_val.json', \n                        '..\/input\/sartorius-cell-instance-segmentation\/')\n\nval_ds = DatasetCatalog.get('sartorius_val')","31a252b9":"##Helper functions\ndef read_target_masks(item):\n    enc_targs = list(map(lambda x:x['segmentation'], item['annotations']))\n    #enc_targs = mask_util.frPyObjects(enc_targs, 520, 704)\n    tars = torch.tensor(mask_util.decode(enc_targs)).cuda()\n    return tars.permute(2,0,1).bool()\n\ndef get_preds_and_tars(item):\n    im = cv2.imread(item['file_name'])\n    pred = predictor(im) \n    pred_masks = pred['instances'].pred_masks\n    tars = read_target_masks(item)\n    return item['file_name'], pred_masks, tars\n\n\ndef precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n\ndef score(pred, targ):\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n    enc_targs = list(map(lambda x:x['segmentation'], targ['annotations']))\n    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, ious)\n        p = tp \/ (tp + fp + fn)\n        prec.append(p)\n    return np.mean(prec)\n\ndef score_all(model):\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\n    cfg.INPUT.MASK_FORMAT='bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n    cfg.MODEL.WEIGHTS = model\n    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n    predictor = DefaultPredictor(cfg)\n\n    scores = []\n    for item in val_ds:\n        im =  cv2.imread(item['file_name'])\n        pred = predictor(im)       \n        \n        sc = score(pred, item)\n        scores.append(sc)\n        \n    return np.mean(scores)","325379ad":"import os\n\npath = '..\/input\/sartorius-models' #change model paths according to your private model datasets\nm_paths = []; cv_scores = []\nfor i in os.listdir(path):\n    m_paths.append(path+'\/'+i)\n    \nfor i in m_paths:\n    cv_scores.append([score_all(i),i])\n    print(score_all(i))\n    \nprint(\"best CV score and assosiated file is: \", max(cv_scores))","957fd941":"cv_scores","e9df7356":"## Finally calculate score across all validation files:","6fe425cd":"This is a simple adaptation of slawekbiel's validation notebook to validate multiple detectron2 files. I created this since performing inference every epoch was memory costing on Colab and simply doing it afterwards would obviosly lead to no changes in CV\/LB scores.\n\nJust comment out \"eval period\" param in detectron notebooks and proceed as you normally would.\n\nHope this helps anyone else stuck with \"OOM Cuda\" or CPU Error","7fe2c1f8":"### A quick example on displaying detailed predictions from a model and calculating validation score\nhttps:\/\/www.kaggle.com\/slawekbiel\/sartorius-vis\/ script is used for visualisation. You need to do File->Add utility script to use it."}}