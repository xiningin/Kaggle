{"cell_type":{"16eb9f73":"code","f1928223":"code","daf3ecbc":"code","f63a01ab":"code","e3225957":"code","f2116dd6":"code","0db6ac9e":"code","d28d5326":"code","516a1716":"code","a0ba16a5":"code","21efb8a6":"code","e06ba569":"code","a86ca42e":"code","49098067":"code","98790ef2":"code","ee9cad6a":"code","0c267b54":"code","993f2b48":"code","42ecd174":"code","1edc2356":"code","342597e5":"code","8583ec88":"code","b46cdba7":"code","2b57860e":"code","2f187fa2":"code","c8b5795a":"code","af62a054":"code","adf8a191":"code","8d23d227":"code","3c9f1c6e":"code","e5109145":"code","147fcf52":"code","7192ad61":"code","fe82fffb":"code","294d3fc1":"code","4c26098e":"code","117d90c1":"code","14084f98":"code","e1feacd6":"markdown","69f41449":"markdown","1258a199":"markdown","b0e540a3":"markdown","23b89c6d":"markdown","bdada24e":"markdown","b5d6687f":"markdown","ee6c1dcd":"markdown","bae56ef2":"markdown","a2f43390":"markdown"},"source":{"16eb9f73":"import cv2\nimport glob\nimport numpy as np\nimport pandas as pd \nimport pydicom\nfrom tqdm import tqdm_notebook as tqdm\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image","f1928223":"SAMPLE_DATA_DIR = '..\/input\/siim-acr-pneumothorax-segmentation\/sample images'\nDATA_DIR = '..\/input\/siim-train-test\/siim\/'\nBASE_WIDTH = 1024\nIMAGE_ID = '1.2.276.0.7230010.3.1.4.8323329.4904.1517875185.355709'","daf3ecbc":"os.listdir(SAMPLE_DATA_DIR)","f63a01ab":"ds = pydicom.dcmread(f\"{SAMPLE_DATA_DIR}\/{IMAGE_ID}.dcm\")","e3225957":"print(ds.pixel_array.shape)","f2116dd6":"plt.imshow(ds.pixel_array, cmap=plt.cm.bone)","0db6ac9e":"Image.fromarray(ds.pixel_array)","d28d5326":"def rle2mask(rle, width, height):\n    mask= np.zeros(width * height, dtype=np.uint8)\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        current_position += start\n        # see https:\/\/github.com\/tensorflow\/models\/issues\/3906#issuecomment-391998102\n        # The segmentation ground truth images in your custom dataset should have\n        # 1, 2, 3, ..., num_class grayscale value at each pixel (0 for background).\n        # For example if you have 2 classes, you should use 1 and 2 for corresponding pixel.\n        # Of course the segmentation mask will look almost \"black\". If you choose,\n        # say 96 and 128, for your segmentation mask to make the it looks more human friendly,\n        #the network may end up predicting labels greater than num_class,\n        # which leads to the error in this issue.\n        mask[current_position:current_position+lengths[index]] = 1  # Do NOT use 255\n        current_position += lengths[index]\n\n    return mask.reshape(width, height)","516a1716":"df = pd.read_csv(os.path.join(SAMPLE_DATA_DIR, 'train-rle-sample.csv'), header=None, names=['ImageId', 'EncodedPixels'])","a0ba16a5":"df.head()","21efb8a6":"df[df['ImageId'] == IMAGE_ID]","e06ba569":"rle: str = df[df['ImageId'] == IMAGE_ID]['EncodedPixels'].values[0]","a86ca42e":"image_bytes = rle2mask(rle, BASE_WIDTH, BASE_WIDTH)","49098067":"Image.fromarray(image_bytes.T * 255)","98790ef2":"fig,ax = plt.subplots(1)\nax.imshow(ds.pixel_array, cmap=plt.cm.bone)\nax.imshow(image_bytes.T, alpha=0.5)\nplt.show()","ee9cad6a":"def dcm_to_png(dcm_file: str, png_file: str, width=BASE_WIDTH):\n    assert os.path.exists(dcm_file)\n    assert dcm_file.endswith('.dcm')\n    assert png_file.endswith('.png')\n    ds = pydicom.dcmread(dcm_file)\n    img_bytes = ds.pixel_array if width == BASE_WIDTH else cv2.resize(ds.pixel_array, (width, width))\n    res, im_png = cv2.imencode('.png', img_bytes)\n    assert res == True\n    with open(png_file, 'wb') as f:\n        f.write(im_png.tobytes())","0c267b54":"dcm_to_png(\n    os.path.join(SAMPLE_DATA_DIR, IMAGE_ID+'.dcm'),\n    f'{IMAGE_ID}.png',\n)","993f2b48":"img = cv2.imread(f'{IMAGE_ID}.png', cv2.IMREAD_GRAYSCALE)","42ecd174":"assert img.shape == (BASE_WIDTH, BASE_WIDTH)","1edc2356":"assert np.array_equal(img, pydicom.dcmread(os.path.join(SAMPLE_DATA_DIR, IMAGE_ID+'.dcm')).pixel_array)","342597e5":"Image.fromarray(img)","8583ec88":"os.remove(f'{IMAGE_ID}.png')","b46cdba7":"def mask_to_png(rle: str, png_file: str, width=BASE_WIDTH):\n    assert rle\n    assert png_file.endswith('.png')\n    img = rle2mask(rle, width, width) if rle != '-1' else np.zeros((width, width), dtype=np.uint8)\n    res, img_png = cv2.imencode('.png', img.T)\n    assert res == True\n    with open(png_file, 'wb') as f:\n        f.write(img_png)","2b57860e":"mask_to_png(rle, 'mask.png')","2f187fa2":"img = cv2.imread('mask.png', cv2.IMREAD_GRAYSCALE)","c8b5795a":"assert img.shape == (BASE_WIDTH, BASE_WIDTH)","af62a054":"Image.fromarray(img * 255)","adf8a191":"os.remove('mask.png')","8d23d227":"def dcm_to_png_dir(input_dir: str, output_dir: str, width=BASE_WIDTH):\n    assert os.path.exists(input_dir)\n    assert not os.path.exists(output_dir)\n    os.makedirs(output_dir)\n\n    dcm_files = glob.glob(f'{input_dir}\/**\/*.dcm', recursive=True)\n    \n    for dcm_file in tqdm(dcm_files, desc=f'{os.path.basename(output_dir)}'):\n        image_id = os.path.basename(dcm_file)[0: -len('.dcm')]\n        dcm_to_png(dcm_file, os.path.join(output_dir, image_id + '.png'), width)","3c9f1c6e":"dcm_to_png_dir(SAMPLE_DATA_DIR, '..\/data\/preprocessed\/sample-images-128x128', 128)","e5109145":"dcm_to_png_dir(f'{DATA_DIR}\/dicom-images-test', '..\/data\/preprocessed\/128x128\/test', 128)","147fcf52":"dcm_to_png_dir(f'{DATA_DIR}\/dicom-images-train', '..\/data\/preprocessed\/128x128\/train', 128)","7192ad61":"def calc_mask(grouped: pd.core.groupby.DataFrameGroupBy, image_id: str, width:int)->np.ndarray:\n    df = grouped.get_group(image_id)\n    result = []\n    for _, row in df.iterrows():\n        rle = row['EncodedPixels'].strip()\n        if rle == '-1':\n            mask = np.zeros((width, width), dtype=np.uint8)\n        else:\n            mask = rle2mask(rle, width, width)\n        result.append(mask)\n\n    assert len(result) == len(df)\n    if len(df) > 1:\n        mask = np.array(result).sum(0).astype(np.uint8)\n    else:\n        mask = result[0]\n    return mask.T\n\ndef mask_to_png_dir(rle_df: pd.DataFrame, output_dir: str, width=BASE_WIDTH):\n    assert not os.path.exists(output_dir)\n    os.makedirs(output_dir)\n\n    rle_df['EncodedPixels'] = rle_df['EncodedPixels'].astype(str)\n    grouped = rle_df.groupby('ImageId')\n    for image_id in tqdm(grouped.groups.keys(), desc=f'{os.path.basename(output_dir)}'):\n        mask = calc_mask(grouped, image_id, width)\n        res, img_png = cv2.imencode('.png', mask)\n        assert res == True\n\n        with open(os.path.join(output_dir, image_id+'.png'), 'wb') as f:\n            f.write(img_png)","fe82fffb":"mask_to_png_dir(\n    pd.read_csv(f'{SAMPLE_DATA_DIR}\/train-rle-sample.csv', header=None, names=['ImageId', 'EncodedPixels']),\n    '..\/data\/preprocessed\/128x128\/sample-masks',\n    128,\n)","294d3fc1":"mask_to_png_dir(\n    pd.read_csv(f'{DATA_DIR}\/train-rle.csv', skiprows=1, header=None, names=['ImageId', 'EncodedPixels']),\n    '..\/data\/preprocessed\/128x128\/masks',\n    128,\n)","4c26098e":"def missing_masks(train_masks_dir: str, train_images_dir: str, width: int):\n    train_images = [os.path.basename(file_path)[0: -len('.dcm')] for file_path in glob.glob(f'{train_images_dir}\/**\/*.png', recursive=True)]\n    train_masks = [os.path.basename(file_path)[0: -len('.dcm')] for file_path in glob.glob(f'{train_masks_dir}\/*.png', recursive=True)]\n    missing_masks = set(train_images) - set(train_masks)\n    for image_id in tqdm(missing_masks, desc='Missing Masks'):\n        mask = np.zeros((width, width), dtype=np.uint8)\n        res, img_png = cv2.imencode('.png', mask)\n        assert res == True\n\n        with open(os.path.join(train_masks_dir, image_id+'.png'), 'wb') as f:\n            f.write(img_png)","117d90c1":"missing_masks(\n    '..\/data\/preprocessed\/128x128\/masks',\n    '..\/data\/preprocessed\/128x128\/train',\n    128,\n)","14084f98":"for width in tqdm([256, 512, 1024]):\n    dcm_to_png_dir(f'{DATA_DIR}\/dicom-images-test', f'..\/data\/preprocessed\/{width}x{width}\/test', width)\n    dcm_to_png_dir(f'{DATA_DIR}\/dicom-images-train', f'..\/data\/preprocessed\/{width}x{width}\/train', width)\n    mask_to_png_dir(\n        pd.read_csv(f'{DATA_DIR}\/train-rle.csv', skiprows=1, header=None, names=['ImageId', 'EncodedPixels']),\n        f'..\/data\/preprocessed\/{width}x{width}\/masks',\n        width,\n    )\n    missing_masks(\n        f'..\/data\/preprocessed\/{width}x{width}\/masks',\n        f'..\/data\/preprocessed\/{width}x{width}\/train',\n        width,\n    )","e1feacd6":"png is a **lossless** compression format:","69f41449":"## Convert Masks to PNG Images","1258a199":"## Convert A Whole Folder","b0e540a3":"## Visuaize Images","23b89c6d":"## Convert `.dcm` Files to PNG Images","bdada24e":"## Acknowledgments\n\n* [Simple Pneumothorax EDA](https:\/\/www.kaggle.com\/aleksandradeis\/simple-pneumothorax-eda)\n* [playing_with_the_data](https:\/\/www.kaggle.com\/abhi3ichigo\/playing-with-the-data)\n* [Visualizing Submission File](https:\/\/www.kaggle.com\/abhishek\/visualizing-submission-file)\n* [pneumothorax fastai starter U-Net 128x128](https:\/\/www.kaggle.com\/mnpinto\/pneumothorax-fastai-5-fold-u-net-128x128\/)","b5d6687f":"All images are of size `1024x1024`","ee6c1dcd":"## Visualize Masks","bae56ef2":"# Convert to PNG Images","a2f43390":"## Draw the image and its mask together"}}