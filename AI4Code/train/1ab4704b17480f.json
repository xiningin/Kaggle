{"cell_type":{"194ee54e":"code","886b244f":"code","8895a20c":"code","5e414284":"code","65011475":"code","a4b9e055":"code","8a83026c":"code","80cb9e10":"code","3cc471b1":"code","7ca579e6":"code","fabc668f":"code","213307f9":"code","1cd61e3d":"code","37898ce1":"code","d323600f":"code","912deb07":"code","f7a8c930":"code","4f15eedf":"code","17ad3af4":"code","5064e88d":"code","86237fe9":"code","daab9491":"code","ccab64f1":"code","29b82ac7":"code","6722c2b4":"code","c9441265":"code","c6e7787a":"code","1fba2252":"code","1aa84910":"code","a3babf51":"code","646cf13b":"code","04b55eae":"code","6108ad85":"code","82c84858":"code","d4ae3042":"code","4ad185fc":"code","b3338f59":"code","db3dd9b6":"code","a7475bbe":"code","90cc0b7b":"markdown","3a382492":"markdown","648c606b":"markdown","4d6fe247":"markdown","acf6cb86":"markdown","3910db60":"markdown","46260cb0":"markdown","119da3bf":"markdown","6a9c7c2c":"markdown","de34d958":"markdown","a6233d78":"markdown","f5c1a460":"markdown","c6c3e1b1":"markdown","c91a045a":"markdown","85044248":"markdown","540db550":"markdown","809e67f0":"markdown"},"source":{"194ee54e":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS","886b244f":"data_df = pd.read_csv(\"\/kaggle\/input\/bbc-youtube-videos-metadata\/bbc.csv\")","8895a20c":"print(f\"data shape: {data_df.shape}\")","5e414284":"data_df.info()","65011475":"data_df.describe()","a4b9e055":"data_df.head()","8a83026c":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","80cb9e10":"missing_data(data_df)","3cc471b1":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))","7ca579e6":"unique_values(data_df)","fabc668f":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))","213307f9":"most_frequent_values(data_df)","1cd61e3d":"def plot_count(feature, title, df, size=1, ordered=True):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    if ordered:\n        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    else:\n        g = sns.countplot(df[feature], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()    ","37898ce1":"plot_count(\"video_category_id\", \"Video category\", data_df,4)","d323600f":"plot_count(\"video_category_label\", \"Video category label\", data_df,4)","912deb07":"plot_count(\"definition\", \"Video definition\", data_df,2)","f7a8c930":"plot_count(\"licensed_content\", \"Licensed content\", data_df,1)","4f15eedf":"plot_count(\"caption\", \"Caption\", data_df,1)","17ad3af4":"plot_count(\"dimension\", \"Dimmension\", data_df,1)","5064e88d":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","86237fe9":"show_wordcloud(data_df['video_title'], title = 'Prevalent words in video title')","daab9491":"hd_df = data_df.loc[data_df.definition == 'hd']\nshow_wordcloud(hd_df['video_title'], title = 'Prevalent words in high definition video title')","ccab64f1":"sd_df = data_df.loc[data_df.definition == 'sd']\nshow_wordcloud(sd_df['video_title'], title = 'Prevalent words in simple definition video title')","29b82ac7":"d_df = data_df.loc[data_df.video_category_label == 'Entertainment']\nshow_wordcloud(d_df['video_title'], title = 'Prevalent words in entertainment video title')","6722c2b4":"d_df = data_df.loc[data_df.video_category_label == 'Comedy']\nshow_wordcloud(d_df['video_title'], title = 'Prevalent words in comedy video title')","c9441265":"d_df = data_df.loc[data_df.video_category_label == 'News & Politics']\nshow_wordcloud(d_df['video_title'], title = 'Prevalent words in News & Politics video title')","c6e7787a":"d_df = data_df.loc[data_df.video_category_label == 'Science & Technology']\nshow_wordcloud(d_df['video_title'], title = 'Prevalent words in Science & Technology video title')","1fba2252":"show_wordcloud(data_df['video_description'], title = 'Prevalent words in video description')","1aa84910":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=True, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=True, bins=120, label=feature)\n    plt.xlabel('#')\n    plt.legend()\n    plt.show()","a3babf51":"plot_features_distribution(['duration_sec'], 'Video duration distribution (sec.)', data_df)","646cf13b":"plot_features_distribution(['duration_sec'], 'Video duration distribution (sec.\/logaritmic)', data_df, isLog=True)","04b55eae":"plot_features_distribution(['view_count'], 'View count distribution (logaritmic)', data_df, isLog=True)","6108ad85":"plot_features_distribution(['like_count'], 'Like count distribution (logaritmic)', data_df, isLog=True)","82c84858":"plot_features_distribution(['dislike_count'], 'Dislike count distribution (logaritmic)', data_df, isLog=True)","d4ae3042":"plot_features_distribution(['comment_count'], 'Comments count distribution (logaritmic)', data_df, isLog=True)","4ad185fc":"plot_features_distribution(['comment_count', 'dislike_count', 'like_count', 'view_count'],\n                           'Feedback distribution - all (logaritmic)', data_df, isLog=True)","b3338f59":"def plot_feature_distribution_grouped(feature, title, df, hue, size=4):\n    plt.figure(figsize=(size*5,size*2))\n    plt.title(title)\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    g = sns.countplot(df[feature], hue=df[hue], palette='Set3')\n    plt.xlabel('#')\n    plt.legend()\n    plt.show()","db3dd9b6":"plot_feature_distribution_grouped('video_category_label', 'Video category label grouped by video definition', data_df, 'definition', size=3)","a7475bbe":"plot_feature_distribution_grouped('caption', 'Video caption grouped by video category label', data_df, 'video_category_label', size=3)","90cc0b7b":"# Data exploration\n\n\n## Glimpse the data","3a382492":"## Visualize the data distribution","648c606b":"### Video duration distribution","4d6fe247":"### Grouped distribution","acf6cb86":"### Video resolution","3910db60":"### Video reactions distribution","46260cb0":"## Load data","119da3bf":"<h1>BBC YouTube Channel Videos Metadata EDA<\/h1>\n\n\n<img src=\"https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F769452%2F3c07321245b5cbec0dad06a5d9c3201d%2Fssssss.png?generation=1597339315897882&alt=media\" width=\"600\"><\/img>\n\n\n# Introduction\n\n\nThe Dataset we are using here is collected using YouTube Data Tools.  It stores all the metadata for the BBC main YouTube channel, from 2007 to present. \n\nIt contains such fields like:\n\n* date of publishing;  \n* video title;  \n* video description;  \n* video category id & video category label;  \n* duration;  \n* definition;  \n* caption;  \n* license;  \n* reach\/feedback count (likes, dislikes, favorites, views, comments)\n\n","6a9c7c2c":"### Text wordcloauds","de34d958":"### Most frequent values","a6233d78":"### Video category","f5c1a460":"### Unique values","c6c3e1b1":"### Caption","c91a045a":"### Missing data","85044248":"### Licensed content","540db550":"# Data preparation\n\n## Load packages","809e67f0":"### Dimmension"}}