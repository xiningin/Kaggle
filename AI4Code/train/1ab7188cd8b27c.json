{"cell_type":{"25c1f1fa":"code","d08534c4":"code","4a53be17":"code","cc0dfb4d":"code","dc3e1de4":"code","0db1056b":"code","ed0ce956":"code","58aebf2d":"code","6ecc841a":"code","88d27bdc":"code","f5fd55fd":"code","bc858106":"code","70825f6e":"code","495f16d7":"code","3ff89d5a":"code","d67406c7":"code","c310c292":"code","7f937192":"code","28bac934":"code","bfa609dc":"code","be2fe85e":"code","ebee0e8b":"code","0bf168b1":"code","23067879":"code","1d8cb452":"code","03b61f3b":"code","7b792f65":"code","60a5eec5":"code","ef66279e":"code","2c17c19a":"code","17cdc9fa":"code","bd9aa4a7":"code","213dae44":"code","2294ef76":"code","26a497fa":"code","7c36011d":"markdown","f2a77b65":"markdown","5f40109d":"markdown","a51fb901":"markdown","e55fceea":"markdown","5148c3c6":"markdown","e37f0f3e":"markdown","8fe9d7a2":"markdown","bca0489c":"markdown","1e51a1a4":"markdown","0f21704d":"markdown"},"source":{"25c1f1fa":"# %reload_ext autoreload\n# %autoreload 2\n%matplotlib inline","d08534c4":"import torch\nimport cv2\nimport matplotlib.pyplot as plt\nimport PIL\nprint(PIL.PILLOW_VERSION)","4a53be17":"from fastai.vision import *\nfrom fastai.metrics import error_rate\nimport fastai\nfastai.__version__","cc0dfb4d":"import os\nimport pandas as pd","dc3e1de4":"os.listdir('..\/input\/')","0db1056b":"train_folder = '..\/input\/train\/train\/'\ntest_folder = '..\/input\/test1\/test1\/'\nprint(os.listdir(train_folder)[:10])\nprint(os.listdir(test_folder)[:10])","ed0ce956":"np.random.seed(2)\nfnames = get_image_files(train_folder)\nprint(fnames[:5])\npat = re.compile(r'(cat|dog)\\.\\d+\\.jpg') # we specify a regex for finding cat or dog images","58aebf2d":"sz = 64\nbs = 64\ndata = ImageDataBunch.from_name_re(\n                                train_folder,\n                                fnames,\n                                pat,\n                                ds_tfms=get_transforms(),\n                                size=sz, bs=bs,\n                                valid_pct = 0.25,\n                                num_workers = 0, # for code safety on kaggle\n).normalize(imagenet_stats)\ndata","6ecc841a":"data.classes","88d27bdc":"data.show_batch(rows=4, figsize=(7,6))","f5fd55fd":"learn = cnn_learner(\n    data,\n    models.resnet34,\n    metrics=error_rate,\n    model_dir=\"\/tmp\/model\/\"\n)","bc858106":"learn.data","70825f6e":"learn.lr_find()\nlearn.recorder.plot()","495f16d7":"learn.fit_one_cycle(1, max_lr=slice(2e-3))","3ff89d5a":"learn.unfreeze()\nlearn.fit_one_cycle(4)","d67406c7":"interp = ClassificationInterpretation.from_learner(learn)\nlosses,idxs = interp.top_losses()\nprint(len(data.valid_ds)==len(losses)==len(idxs))","c310c292":"interp.plot_top_losses(9, figsize=(15,11))","7f937192":"interp.plot_confusion_matrix(figsize=(5,5), dpi=100)","28bac934":"mc = interp.most_confused(min_val=2)\nmcc = [x[0] for x in mc[:5]]\nmcc","bfa609dc":"train = pd.DataFrame(os.listdir(train_folder))","be2fe85e":"a = ['0']\ntrain.sample(n=10, random_state=1)","ebee0e8b":"item1_path = data.items[100]\nprint(item1_path)\nitem1 = data.open( item1_path )\nitem1","0bf168b1":"pred_class, pred_idx, outputs = learn.predict(item1)\nprobs = torch.nn.functional.softmax(np.log(outputs), dim=0)\nprint(pred_class)\nprint(probs)","23067879":"data_test = ImageList.from_folder(test_folder).split_none().label_empty()\ndata_test","1d8cb452":"dst = data_test.train.x[:20]\ndst","03b61f3b":"learn.data","7b792f65":"data.add_test(items=dst)\ndata","60a5eec5":"learn.data = data\nlearn.data","ef66279e":"pred_probs, pred_class = learn.get_preds(ds_type=DatasetType.Test)","2c17c19a":"print(pred_probs)\nprint(pred_class)\nprint((pred_probs.numpy()[:,0]>0.5)+0)","17cdc9fa":"df = pd.DataFrame(os.listdir(test_folder))\nprint(len(df))\ndf.head()","bd9aa4a7":"img_idx = 8\nprint(pred_class[img_idx])\ndata_test.train.x[img_idx]\nplt.imshow(plt.imread(test_folder+df[0].iloc[img_idx]))\n# test_folder+df[0]","213dae44":"\nsubmission_data = [ids, pred_class]\n\ndf = pd.DataFrame(submission_data).T\ndf.columns = ['id','label']\ndf.head()","2294ef76":"df.to_csv('.\/kaggle_catsdogs.csv', index=False)\nprint( os.path.exists('.\/kaggle_catsdogs.csv') )","26a497fa":"!rm -rf dogscats","7c36011d":"## Results","f2a77b65":"This is a simple kernel you can use as a base experiment for your first submission, implemented with the fastAI v1 library, by [fast.ai](https:\/\/www.fast.ai\/).  \nIt is based on the [first lesson](https:\/\/nbviewer.jupyter.org\/github\/fastai\/course-v3\/blob\/master\/nbs\/dl1\/lesson1-pets.ipynb) of the course-v3, which is explained in [this](https:\/\/course.fast.ai\/videos\/?lesson=1) video.  \nIf you are interested in other edited FastAI ipynb, you can find another one here:\n* [fastaiv1 Collaborative Filtering](https:\/\/www.kaggle.com\/gianfa\/fastaiv1-collaborative-filtering\/)","5f40109d":"## Modeling and Training","a51fb901":"## Data Loading\nIt is very fast to do with fastAI","e55fceea":"Take the image names and split them by regex","5148c3c6":"Now the **Test Set**","e37f0f3e":"## Main imports","8fe9d7a2":"Now add _dst_ to the learner dataBunch","bca0489c":"## Prepare submission","1e51a1a4":"You can see that after a single cycle it's able to reach around 0.03 of valid_loss, great job fasta.ai!","0f21704d":"## Data Retrieving"}}