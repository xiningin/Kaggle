{"cell_type":{"66db6273":"code","e2017679":"code","62e9bcf1":"code","95d05871":"code","a63027c9":"code","c46d1d74":"code","1a65d01f":"code","b1e801e5":"code","3cd84af5":"code","81f03023":"code","1caea068":"code","a0517eec":"code","2334a1c7":"code","f55c259e":"code","1ad1d92c":"code","51686785":"code","f8881c52":"code","a26b7d49":"markdown","24a292b8":"markdown","aeb68d40":"markdown","9645048f":"markdown","17ce1123":"markdown","fc1a88f5":"markdown","864325a3":"markdown"},"source":{"66db6273":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom keras import layers\nfrom keras import regularizers\nfrom keras import models\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model","e2017679":"#loading data\ntrain=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')","62e9bcf1":"train_images=train.iloc[:,1:].values\ntrain_labels=train.iloc[:,0:1].values\ntest_X=test.iloc[:,:].values","95d05871":"sns.countplot(train['label'])","a63027c9":"train_images","c46d1d74":"train_images = train_images.reshape((-1, 28, 28, 1))\ntrain_images = train_images.astype('float32') \/ 255\ntest = test.values.reshape(-1,28,28,1)\ntest = test \/ 255.0","1a65d01f":"train_images.shape","b1e801e5":"# Some examples\ng = plt.imshow(train_images[20][:,:,0])\ng=plt.title(train_labels[20])","3cd84af5":"train_labels = to_categorical(train_labels)","81f03023":"#using data agumenteation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(train_images)","1caea068":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (28,28,1)))\nmodel.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.25))\nmodel.add(layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.35))\nmodel.add(layers.Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam',\nloss='categorical_crossentropy',\nmetrics=['accuracy'])","a0517eec":"# Fit the model\nhistory = model.fit_generator(datagen.flow(train_images,train_labels, batch_size=64),\n                              epochs = 100, \n                              verbose = 2, steps_per_epoch=train_images.shape[0] \/\/ 64\n                              )","2334a1c7":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='r', label=\"Training accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","f55c259e":"# predict results\nresults = model.predict(test)","1ad1d92c":"# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","51686785":"#concatinating result with series of numbers from 1 to 28000\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","f8881c52":"model.save('digit_clfr.h5')","a26b7d49":"## Training and Evaluating","24a292b8":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.","aeb68d40":"## CNN","9645048f":"## Data preparation ","17ce1123":"## Content\n1. Introduction\n2. Data preparation\n3. CNN\n4. Training and Evaluating the model\n5. Prediction and submition","fc1a88f5":"## Prediction and Submission","864325a3":"# Introduction\n"}}