{"cell_type":{"b734febf":"code","bc53ede6":"code","9ab5b210":"code","23132a12":"code","276a0e6d":"code","2ba91663":"code","945c5a26":"code","a0aaaad1":"code","4598144c":"code","a5ee6a61":"markdown","99e0aab8":"markdown","dc592e39":"markdown","ace612e2":"markdown","b2d52885":"markdown","c2527288":"markdown","4f14e985":"markdown","e0803bd0":"markdown"},"source":{"b734febf":"#NLTK for natural language processing\nimport nltk\n#for maths\nimport numpy as np\n#for string manipulation\nimport string\n#for importing and managing our dataset\nimport pandas as pd\n#for pre-processing our dataset\nimport re\n\nimport warnings\nwarnings.filterwarnings('ignore')","bc53ede6":"df = pd.read_csv('..\/input\/customer-support-on-twitter\/twcs\/twcs.csv')","9ab5b210":"#Specify which company we want to work with\ncompany = \"VirginTrains\"\n\n#Filter for answers only made by that company\nanswers = df.loc[df['author_id'] == company]","23132a12":"#Convert all our text to lower case\nanswers['text'] = answers.apply(lambda row: row['text'].lower(), axis=1)\n#Strip off any trailing full stops\nanswers['text'] = answers.apply(lambda row: row['text'].rstrip('.'), axis=1)\n#Remove any mentions to users e.g. \"@johnsmith you can do this by....\"\nanswers['text'] = answers.apply(lambda row: re.sub(\"\\B@\\w+\", \"\", row['text']), axis=1)","276a0e6d":"#variable for concatinating all answers sent by the company\nraw = \"\"\n\n#concatinate answers into raw variable\nfor index, row in answers.iterrows():\n    raw += \". \" + row['text']","2ba91663":"#download nltk assets\nnltk.download('punkt')\nnltk.download('wordnet')\n\n#convert our raw sentences into sentence tokens\nsentence_tokens = nltk.sent_tokenize(raw)\n#convert our raw sentences into word tokens\nword_tokens = nltk.word_tokenize(raw);","945c5a26":"lemmer = nltk.stem.WordNetLemmatizer()\n\ndef LemTokens(tokens):\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))","a0aaaad1":"#import necessary libraries\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n#define our function for processing a response\ndef response(user_response):\n    #define our response variable\n    robo_response=''\n    #add our users input as a response\n    sentence_tokens.append(user_response)\n    #create out vectorizer\n    vectorizer = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    #process our tokens\n    diff = vectorizer.fit_transform(sentence_tokens)\n    #find the similarity\n    vals = cosine_similarity(diff[-1], diff)\n    #select our sentence\n    idx = vals.argsort()[0][-2]\n    #calculate accuracy\n    flat = vals.flatten()\n    flat.sort()\n    req_diff = flat[-2]\n    if(req_diff==0):\n        #if no appropriate response can be made\n        robo_response=robo_response+\"Sorry! I don't think I can help you with that.\"\n        return robo_response\n    else:\n        #if an appropriate response is found\n        robo_response = sentence_tokens[idx]        \n        return robo_response","4598144c":"#define our flag to exit the loop\nflag=True\n#print welcome message for our chosen company\nprint(\"{companyname} Support: Welcome to {companyname} Support. I will answer your queries about {companyname}. If you wish to end the chat, type bye!\".format(companyname = company))\nwhile(flag==True):\n    #get an input\n    user_response = input()\n    #convert to lower\n    user_response=user_response.lower()\n    #if they type something other than 'bye'\n    if(user_response!='bye'):\n        #if they show appriciation\n        if(user_response=='thanks' or user_response=='thank you' ):\n            #exit the loop\n            flag=False\n            #thank you message\n            print(\"{companyname} Support: You are welcome.\".format(companyname = company))\n        else:\n            #show bot is typing\n            print(\"{companyname} Support: \".format(companyname = company), end=\"\")\n            #print our AI response\n            print(response(user_response))\n            sentence_tokens.remove(user_response)\n    else:\n        #exit the loop\n        flag=False\n        #exit message\n        print(\"{companyname} Support: Thanks for chatting. I hope we could assist you today.\".format(companyname = company))","a5ee6a61":"For our chatbot to be able to best make links between different strings and user inputs, it will be important to process the data to make it as easy as possible for the NLTK library to make links between strings.","99e0aab8":"First, when developing the chat bot, I imported the dataset the chatbot should work from.","dc592e39":"There are messages from multiple companies to tailor our chat bot to a given company, the dataset should be filtered accordingly.","ace612e2":"Concatinate our question text into a raw string. Format into lower case and remove unnecessary characters.","b2d52885":"For processing by the NLTK library, we can provide our data as a raw input set of text in the form of individual sentences. Therefore, we should concatenate all our text answers into one string of sentences.","c2527288":"Import our necessary Libraries","4f14e985":"We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens.\n\nTaken from: https:\/\/medium.com\/analytics-vidhya\/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e","e0803bd0":"To respond to a users questions, we will compare their question with our data frame of previously asked questions to find a suitable response."}}