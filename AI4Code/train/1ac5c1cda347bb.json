{"cell_type":{"00136129":"code","81ebf9ff":"code","2629e92e":"code","a8d58484":"code","a12d3618":"code","76830c4f":"code","276f91ae":"code","928f3785":"code","56ea423f":"code","efb2d072":"code","250b53b3":"code","28edf382":"code","e932d0f4":"code","96a37ff2":"code","ef2fdc3d":"code","a4c44957":"code","d7d8805d":"code","de5e824b":"code","23f75f94":"code","55354d6d":"code","abe75342":"code","6d7d4931":"code","58e574cc":"code","c8e52365":"code","b57dbe85":"code","88782942":"markdown"},"source":{"00136129":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81ebf9ff":"import pandas as pd \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n","2629e92e":"df=pd.read_csv('\/kaggle\/input\/hotel-reviews\/7282_1.csv')\ndf.head()","a8d58484":"df.info()","a12d3618":"df.drop(df.columns[[0, 1, 3, 5,6,7,8,9,10,11,12,15,16, 4,17,18, 2]], axis = 1, inplace = True)  ","76830c4f":"df.head()","276f91ae":"df.dropna(inplace=True)","928f3785":"df.info()","56ea423f":"import re\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nnltk.download('wordnet')\n\n\nlemm=WordNetLemmatizer()\n","efb2d072":"df.reset_index(inplace=True)\ndf=df[:10000]","250b53b3":"df.head()","28edf382":"df.shape","e932d0f4":"Corpus=[]\nfor i in range (0,10000):\n  filter= re.sub('[^a-zA-Z]',' ', df['reviews.text'][i])\n  filter = filter.lower()\n  filter=filter.split()\n  filter=[lemm.lemmatize(word) for word in filter if not word in stopwords.words('english')]\n  filter=' '.join(filter)\n  Corpus.append(filter)","96a37ff2":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=None) \n\nX_df = tfidf_vectorizer.fit_transform(Corpus)\n","ef2fdc3d":"X_df.shape","a4c44957":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=12000) \n\nX_df = tfidf_vectorizer.fit_transform(Corpus)","d7d8805d":"Y=df.iloc[:,0].values","de5e824b":"Y.shape","23f75f94":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X_df,Y,test_size=0.2,random_state=0)","55354d6d":"x_train","abe75342":"y_train","6d7d4931":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()\nmodel.fit(x_train,y_train)\n","58e574cc":"y_pred=model.predict(x_test)","c8e52365":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)","b57dbe85":"print(model.score(x_train,y_train))","88782942":"please feel free to criticize, like, comment"}}