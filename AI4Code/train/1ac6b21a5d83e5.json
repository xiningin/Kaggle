{"cell_type":{"bac4cd99":"code","84caa998":"code","ddbfc570":"code","71d5eaf5":"code","8eb4a475":"code","ccd6a049":"code","ca9f5bcb":"code","5593366d":"code","60909328":"code","d75d97a9":"code","c7ee2a75":"code","cf0adad1":"code","92ae5490":"code","7e000fc8":"code","d61fedfd":"code","ff0b245e":"code","bb780bbc":"code","9ead733a":"code","3a964d20":"code","275d4c4c":"code","4155023e":"code","3ba3888d":"code","fdbfcf54":"code","9a5459c9":"code","c6fe5365":"code","ee501973":"code","6dcd2481":"code","183bedec":"code","9d0a31a1":"code","d9f8a403":"markdown"},"source":{"bac4cd99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","84caa998":"# Carregando os dados\ndf = pd.read_csv(\"\/kaggle\/input\/adult-income-dataset\/adult.csv\")\n\ndf.shape","ddbfc570":"# Visualizando as informa\u00e7\u00f5es\ndf.info()","71d5eaf5":"# Visualizando os dados\ndf.head()","8eb4a475":"# N\u00e3o temos valores nulos\ndf.isna().sum()","ccd6a049":"# Mas temos um valor estranho '?' em algumas colunas\n# Verificando a ocorrencia de '?'\nprint('Workclass - Qtde ?: ',df['workclass'][df['workclass']=='?'].count())\nprint('Porcentagem: {0:.2f}%'.format(df['workclass'][df['workclass']=='?'].count()\/(len(df))*100))","ca9f5bcb":"# Valor mais comum em 'Workclass'\ndf['workclass'].value_counts()","5593366d":"# Verificando a ocorrencia de '?'\nprint('Occupation - Qtde ?: ',df['occupation'][df['occupation']=='?'].count())\nprint('Porcentagem: {0:.2f}%'.format(df['occupation'][df['occupation']=='?'].count()\/(len(df))*100))","60909328":"# Valor mais comum em 'occupation'\ndf['occupation'].value_counts()","d75d97a9":"# Verificando a ocorrencia de '?'\nprint('Native Country - Qtde ?: ',df['native-country'][df['native-country']=='?'].count())\nprint('Porcentagem: {0:.2f}%'.format(df['native-country'][df['native-country']=='?'].count()\/(len(df))*100))","c7ee2a75":"# Valor mais comum em 'native-country'\ndf['native-country'].value_counts()","cf0adad1":"# Vamos corrigir as colunas pelo valor mais frequente\ndf['workclass'] = df['workclass'].replace('?','Private')\ndf['occupation'] = df['occupation'].replace('?','Prof-specialty')\ndf['native-country'] = df['native-country'].replace('?','United-States')","92ae5490":"# Transformando a coluna 'Income' em bin\u00e1ria\ndf.income = df.income.replace('<=50K', 0)\ndf.income = df.income.replace('>50K', 1)","7e000fc8":"# Verificando a distribui\u00e7\u00e3o dos valores categ\u00f3ricos\ncat_cols = [c for c in df.columns if (df[c].dtype == 'object')]\n\nfor i in cat_cols:\n    print(i,':')\n    print('')\n    print(df[i].value_counts())\n    print('')","d61fedfd":"# Limitando as categorias\n\n# Education\ndf.education = df.education.replace(['Preschool','1st-4th','5th-6th','7th-8th','9th','10th','11th','12th'],'left')\ndf.education = df.education.replace('HS-grad','school')\ndf.education = df.education.replace(['Assoc-voc','Assoc-acdm','Prof-school','Some-college'],'higher')\ndf.education = df.education.replace('Bachelors','undergrad')\ndf.education = df.education.replace('Masters','grad')\ndf.education = df.education.replace('Doctorate','doc')","ff0b245e":"# Marital status\ndf['marital-status'] = df['marital-status'].replace(['Married-civ-spouse','Married-AF-spouse'],'married')\ndf['marital-status'] = df['marital-status'].replace(['Never-married','Divorced','Separated','Widowed', 'Married-spouse-absent'], 'not-married')","bb780bbc":"# Para Native country vamos seprar em USA e os demais\ndf['native-country'] = df['native-country'].apply(lambda country: 1 if country.strip() == \"United-States\" else 0)","9ead733a":"# Verificando os dados\ndf.head(20)","3a964d20":"# Separando as colunas num\u00e9ricas\nnum_cols = [c for c in df.columns if (df[c].dtype == 'int64')]\n\nnum_cols.remove('income')\n\nnum_cols","275d4c4c":"# Separando as colunas categ\u00f3ricas\ncat_cols = [c for c in df.columns if (df[c].dtype == 'object')]\n\ncat_cols","4155023e":"# Separando as feats\nfeats = cat_cols + num_cols\n\nfeats","3ba3888d":"# Separando o dataframe\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df, random_state = 42)\n\ntrain.shape, test.shape","fdbfcf54":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Preprocessamento dos dados num\u00e9ricos\nnumerical_transformer = SimpleImputer(strategy='mean')\n\n# Preprocessamento das colunas categ\u00f3ricas\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n# Juntando o preprocessamento\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('cat', categorical_transformer, cat_cols)\n    ])","9a5459c9":"# Modelo RF\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n\n# Montando o pipeline\npipe_rfc = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('model', rfc)\n                             ])\n\npipe_rfc.fit(train[feats], train['income'])","c6fe5365":"print(\"Acur\u00e1cia no training set: {:.3f}\".format(pipe_rfc.score(train[feats], train['income'])))\nprint(\"Acur\u00e1cia no test set: {:.3f}\".format(pipe_rfc.score(test[feats], test['income'])))","ee501973":"# Modelo GBC\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(n_estimators=200, learning_rate=1, random_state=42)\n\n# Montando o pipeline\npipe_gbc = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('model', gbc)\n                             ])\n\npipe_gbc.fit(train[feats], train['income'])","6dcd2481":"print(\"Acur\u00e1cia no training set: {:.3f}\".format(pipe_gbc.score(train[feats], train['income'])))\nprint(\"Acur\u00e1cia no test set: {:.3f}\".format(pipe_gbc.score(test[feats], test['income'])))","183bedec":"# Modelo XGB\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(n_estimators=200, learning_rate=1, random_state=42)\n\n# Montando o pipeline\npipe_xgb = Pipeline(steps=[('preprocessor', preprocessor),\n                            ('model', xgb)\n                             ])\n\npipe_xgb.fit(train[feats], train['income'])","9d0a31a1":"print(\"Acur\u00e1cia no training set: {:.3f}\".format(pipe_xgb.score(train[feats], train['income'])))\nprint(\"Acur\u00e1cia no test set: {:.3f}\".format(pipe_xgb.score(test[feats], test['income'])))","d9f8a403":"## IESB - CIA035 - Aula 9.2 - Pipeline 2"}}