{"cell_type":{"6b360843":"code","53c88639":"code","29257e2e":"code","f7a7fd04":"code","be22940d":"code","3fc16dde":"code","99873e09":"code","8105f858":"code","53e8f338":"code","0545729a":"code","7cf57e39":"code","7cd62ed5":"code","40580755":"code","ab822231":"code","a90b36ba":"code","52d7c353":"code","8f62f73d":"code","bb36b584":"code","26de443a":"code","173b9a12":"markdown","540ee9da":"markdown","c5fb3312":"markdown","df5b54f2":"markdown","c671125f":"markdown","714aad58":"markdown","9c10ec2c":"markdown"},"source":{"6b360843":"import dask.bag as db\nimport itertools\nimport json\nimport numpy as np\nimport os\nimport pandas as pd\nfrom statistics import mean, median\nfrom tqdm.auto import tqdm","53c88639":"%%time\n\npaper_metadata = db.read_text(\n    \"..\/input\/s2_article_metadata-2020-04-18\/*.json\", files_per_partition=2000\n).map(\n    json.loads\n)","29257e2e":"list(paper_metadata.take(1)[0].keys())","f7a7fd04":"%%time\n\nauthor_metadata = db.read_text(\n    \"..\/input\/s2_author_metadata-2020-04-18\/*.json\", files_per_partition=2000\n).map(\n    json.loads\n)","be22940d":"list(author_metadata.take(1)[0].keys())","3fc16dde":"def get_semantic_author_influence(author_semantic_metadata: dict) -> dict:\n    author_id = author_semantic_metadata.get(\"author_uid\")\n    author_influence = {}\n    if not author_semantic_metadata.get(\"error\"):\n        author_influence[author_id] = {\n            author_semantic_metadata[\"name\"]: author_semantic_metadata[\n                \"influentialCitationCount\"\n            ]\n        }\n    else:\n        author_influence[author_id] = \"error\"\n    return author_influence","99873e09":"%%time\n\nauthor_influence_list = author_metadata.map(get_semantic_author_influence).compute()\nauthor_influence = {\n    author_id: influence_values\n    for author in author_influence_list\n    for author_id, influence_values in author.items()\n}","8105f858":"%%time\n\npaper_to_author_ids = paper_metadata.map(\n    lambda paper_semantic_metadata: {\n        paper_semantic_metadata.get(\"cord_uid\"): [\n            author[\"authorId\"] for author in paper_semantic_metadata.get(\"authors\", [])\n        ]\n    }\n).compute()","53e8f338":"%%time\n\npaper_to_author_names = paper_metadata.map(\n    lambda paper_semantic_metadata: {\n        paper_semantic_metadata.get(\"cord_uid\"): [\n            author[\"name\"] for author in paper_semantic_metadata.get(\"authors\", [])\n        ]\n    }\n).compute()","0545729a":"paper_author_influence = []\nfor paper_authors in paper_to_author_ids:\n    for cord_uid, author_list in paper_authors.items():\n        author_influence_dict = {}\n        for author_id in author_list:\n            author_name_citations = author_influence.get(author_id)\n            if author_name_citations != \"error\":\n                author_influence_dict.update(author_name_citations)\n            else:\n                author_influence_dict.update({author_id: \"error\"})\n        paper_author_influence.append(\n            {\n                \"cord_uid\": cord_uid,\n                \"author_influential_citations\": author_influence_dict\n            }\n        )","7cf57e39":"%%time\n\npaper_influence = paper_metadata.map(\n    lambda paper: {\n        \"cord_uid\": paper.get(\"cord_uid\", np.nan),\n        \"title\": paper.get(\"title\", np.nan),\n        \"venue\": paper.get(\"venue\", np.nan),\n        \"year\": paper.get(\"year\", np.nan),\n        \"citation_velocity\": paper.get(\"citationVelocity\", np.nan),\n        \"influential_citation_count\": paper.get(\"influentialCitationCount\", np.nan),\n    }\n).compute()","7cd62ed5":"semantic_influence_df = (\n    pd.DataFrame(paper_influence)\n    .set_index(\"cord_uid\")\n    .join(pd.DataFrame(paper_author_influence).set_index(\"cord_uid\"))\n)","40580755":"semantic_influence_df[\"author_influential_citations_percentile\"] = (\n    semantic_influence_df[\"author_influential_citations\"]\n    .apply(lambda x: sum([i for i in x.values() if i != \"error\"]))\n    .rank(pct=True)\n)","ab822231":"semantic_influence_df.sort_values(by=\"author_influential_citations_percentile\", ascending=False).head(50)","a90b36ba":"topic_frequencies = sorted(\n    paper_metadata.pluck(\"topics\", [{\"topic\": None}])\n    .flatten()\n    .pluck(\"topic\")\n    .frequencies()\n    .compute(),\n    key=lambda x: x[1],\n    reverse=True,\n)","52d7c353":"study_design_categories = [\n    \"Meta analysis\",\n    \"Randomized control trial\",\n    \"Non-randomized trial\",\n    \"Prospective cohort\",\n    \"Retrospective cohort\",\n    \"Case control\",\n    \"Cross-sectional\",\n    \"Case study\",\n    \"Other\",\n]","8f62f73d":"study_design_keywords = list(\n    itertools.chain.from_iterable(\n        [design.lower().split() for design in study_design_categories]\n    )\n)","bb36b584":"study_design_keywords","26de443a":"study_design_topics = []\nfor topic in topic_frequencies:\n    for keyword in study_design_keywords:\n        if topic not in study_design_topics and topic[0] and keyword in topic[0].lower().split():\n            study_design_topics.append(topic)\n\nstudy_design_topics","173b9a12":"Looks like there are some promising leads-- \"Phase I\/II\/III Trial\", \"Control Groups\", \"Cross-Sectional Studies\", etc!\n\nOne might train a text categorizer by:\n1. Identifying those S2-extracted topics most aligned to each category in study_design_categories\n2. Pulling those out for annotation\/confirmation\n3. Training a custom textcat model against them\n\nWe will have to contend with unbalanced categories, but it's a start.","540ee9da":"Can we identify study design from the topics that S2 has extracted? These are the categories:\n\n* \"Meta analysis\"\n* \"Randomized control trial\"\n* \"Non-randomized trial\"\n* \"Prospective cohort\"\n* \"Retrospective cohort\"\n* \"Case control\"\n* \"Cross-sectional\"\n* \"Case study\"\n* \"Other\"","c5fb3312":"## Introduction\nThis notebook demonstrates how to begin working with the the CORD-19 S2 metadata. \n\nI use dask.bag in deference to your local RAM, but dask.bag seems to be a bit more pokey in Kaggle kernels.","df5b54f2":"Question for the reader: is the sum of authors' influential citations the right metric to attend to? Or is the average of each author's influential citations more important?","c671125f":"## Conclusion\nFeel free to post in the discussion forum if you have any questions. To go forward from here, click the blue \"Edit Notebook\" button at the top of the kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling!","714aad58":"One assumes that papers from authors with a relatively higher number of influential citations have more face validity to the research community.","9c10ec2c":"Let's take a look at topic frequencies-- nb that there is a very long tail here and S2 surfaces some topics that may or may not be relevant."}}