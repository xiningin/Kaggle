{"cell_type":{"80a2e37a":"code","5a044f59":"code","a18e88dd":"code","e821002e":"code","9b1ae954":"code","326bb9b4":"code","bb1bee35":"code","a7d7bb1d":"code","fe26276b":"code","cdbde667":"code","eb96a0d3":"code","a32655f1":"code","d6103b57":"code","92d887d5":"code","e4658298":"code","2ae4cc83":"code","c5083e5d":"code","c1736daa":"code","da7f78d6":"code","968a5edb":"code","0f495fa8":"code","67ad1be5":"code","01eae649":"code","bf77c499":"code","279c0f4f":"code","7ff785ad":"code","a43a51d7":"code","68b8d2e6":"code","80783937":"code","46d4a32a":"code","514856ee":"code","b4fa0398":"code","baa91ef4":"code","1e68cd30":"code","4b291d91":"code","6bd5cdef":"code","b9bb3517":"code","02f9f247":"code","af2462bb":"code","92142619":"code","3f332fe9":"code","b52d1083":"code","d490e728":"code","b70ee7d6":"code","db95a000":"code","3832a1a7":"code","e9fe86d3":"code","d1dc649c":"code","eac98b72":"code","6b6ab606":"code","86f77c7a":"code","eb899e9c":"code","8e8a6a91":"code","818ab2f0":"code","c88ec0b3":"code","26122d11":"code","344d4b5e":"code","718e1f9f":"code","fbd89b09":"code","2e39d2c7":"code","813bc395":"code","1ebb9abe":"code","60021fe3":"code","8b9c1a65":"code","41a9458c":"code","b4384837":"code","f9e15c2d":"code","3c24f565":"code","03b525b8":"code","0f0f1382":"code","014e3d53":"code","95b52c97":"code","d77ac1c8":"code","976167f0":"code","4f66654f":"code","fdb0eb5b":"code","ed3747a4":"code","209b3486":"code","16de04c5":"code","5f980db8":"code","a35b31cd":"code","591b7159":"code","256dc429":"code","ec311638":"code","e2b5df76":"code","8a584194":"code","e9d3dd9b":"code","bb7cbacb":"markdown","744dd35f":"markdown","4ac35033":"markdown","e87f91e5":"markdown","e7b17d33":"markdown","5bc26f74":"markdown","0fb11055":"markdown","e328b94a":"markdown","dad0c515":"markdown","a98b005d":"markdown","cba70c08":"markdown","2bed615f":"markdown","7e4424f7":"markdown","9a4b9ae3":"markdown","2b1cdb6b":"markdown","a22e57de":"markdown","59113983":"markdown","4fb059bb":"markdown","ad20db3b":"markdown","676c463f":"markdown","d66aba69":"markdown","2f74cd76":"markdown","eb65d778":"markdown","b9d7c0f3":"markdown","1a649bdb":"markdown","3a2817bc":"markdown","5ef4240a":"markdown","7afb32bc":"markdown","6d49560b":"markdown","2a65b8ad":"markdown","e5903959":"markdown","c7942fb8":"markdown","d970595e":"markdown","5efd32f1":"markdown","4fad4c47":"markdown","8f6c75cf":"markdown","fa357063":"markdown","7ed2387a":"markdown","27adffca":"markdown","590c13ae":"markdown","20478cfc":"markdown","410d9a46":"markdown","7ea5c433":"markdown","9202d5fd":"markdown","961d5cab":"markdown","650d3af4":"markdown","92fcb8b2":"markdown","876136d8":"markdown","297fb271":"markdown","48a35f6d":"markdown","f1039e8d":"markdown","1cc5e6bd":"markdown"},"source":{"80a2e37a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom scipy.sparse import csr_matrix\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import GridSearchCV\nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_rows', 500)","5a044f59":"movies = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\nmovies.head()","a18e88dd":"tags = pd.read_csv(\"..\/input\/movielens-20m-dataset\/tag.csv\")\ntags.head()","e821002e":"ratings = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")\nratings.head()","9b1ae954":"links = pd.read_csv(\"..\/input\/movielens-20m-dataset\/link.csv\")\nlinks.head()","326bb9b4":"genome_scores = pd.read_csv(\"..\/input\/movielens-20m-dataset\/genome_scores.csv\")\ngenome_scores.head()","bb1bee35":"genome_tags = pd.read_csv(\"..\/input\/movielens-20m-dataset\/genome_tags.csv\")\ngenome_tags.head()","a7d7bb1d":"print(\"Movies shape: \", movies.shape)\nprint(\"Tags shape: \", tags.shape)\nprint(\"Ratings shape: \", ratings.shape)\nprint(\"Links shape: \", links.shape)\nprint(\"Genome shape: \", genome_scores.shape)\nprint(\"Genome tags shape: \", genome_tags.shape)","fe26276b":"movies[\"movieId\"].nunique()","cdbde667":"links[\"movieId\"].nunique()","eb96a0d3":"movies_df = pd.concat([movies, links], axis=1)\nmovies_df.head()","a32655f1":"movies_df.head()","d6103b57":"movies_df = movies_df.loc[:, ~movies_df.columns.duplicated()]","92d887d5":"movies_df.shape","e4658298":"movies_df.info()","2ae4cc83":"movies_df.describe()","c5083e5d":"movies_df.isnull().sum()","c1736daa":"movies_df.corr()","da7f78d6":"f, ax = plt.subplots(figsize=(15, 5))\nsns.heatmap(movies_df.corr(), annot=True, ax=ax, cmap=\"Blues\")","968a5edb":"columns = [\"MovieID\", \"Title\", \"Genres\", \"IMDBID\", \"TMBDID\"]\nmovies_df.columns = columns","0f495fa8":"movies_df.head()","67ad1be5":"movies_df[\"MovieID\"].head()","01eae649":"movies_df[\"MovieID\"].value_counts()","bf77c499":"movies_df[\"MovieID\"].nunique()","279c0f4f":"movies_df[\"Title\"].head()","7ff785ad":"movies_df[\"Title\"].value_counts()","a43a51d7":"movies_df[\"Title\"].nunique()","68b8d2e6":"movies_df[\"Title\"].describe().T","80783937":"movies_df[movies_df[\"Title\"] == \"Black Field (2009)\"]","46d4a32a":"movies_df[\"Genres\"].head()","514856ee":"movies_df[\"Genres\"].value_counts()","b4fa0398":"movies_df[movies_df[\"Genres\"] == \"Drama\"].head()","baa91ef4":"movies_df[\"Genres\"].nunique()","1e68cd30":"movies_df[\"Genres\"].unique()","4b291d91":"movies_df[\"Genres\"].describe().T","6bd5cdef":"movies_df[\"IMDBID\"].head()","b9bb3517":"movies_df[\"IMDBID\"].value_counts()","02f9f247":"movies_df[\"IMDBID\"].nunique()","af2462bb":"movies_df[\"IMDBID\"].unique()","92142619":"movies_df[\"TMBDID\"].head()","3f332fe9":"movies_df[\"TMBDID\"].value_counts()","b52d1083":"movies_df[movies_df[\"TMBDID\"] == 141971.0]","d490e728":"movies_df[\"TMBDID\"].nunique()","b70ee7d6":"movies_df[\"TMBDID\"].isnull().sum()","db95a000":"movies_df[movies_df[\"TMBDID\"].isna()]","3832a1a7":"movies_df[movies_df[\"TMBDID\"].isna()][\"Genres\"].value_counts()","e9fe86d3":"movies_df[movies_df[\"Genres\"] == \"Documentary\"]","d1dc649c":"movies_df.interpolate(method=\"linear\", inplace=True)","eac98b72":"movies_df.isnull().sum()","6b6ab606":"ratings.head()","86f77c7a":"ratings.columns = [\"UserID\", \"MovieID\", \"Rating\", \"TimeStamp\"]","eb899e9c":"movie_df = movies_df.merge(ratings, on=\"MovieID\")","8e8a6a91":"movie_df.head()","818ab2f0":"tags.columns = [\"UserID\", \"MovieID\", \"Tag\", \"TimeStamp\"]","c88ec0b3":"movie_df.head()","26122d11":"movie_df[\"Rating\"].head()","344d4b5e":"movie_df[\"Rating\"].value_counts()","718e1f9f":"plt.figure(figsize=(20, 5))\nmovie_df[\"Rating\"].value_counts().plot(kind=\"bar\", color=\"#f74d69\")\nplt.xlabel(\"Rating Keys\", fontsize=15)\nplt.ylabel(\"Rating Frequencies\", fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.title(\"Rating Keys and Values\", fontsize=15)\nplt.legend()\nplt.show()","fbd89b09":"movie_df[\"TimeStamp\"].head()","2e39d2c7":"movie_df[\"TimeStamp\"].dtype","813bc395":"movie_df.drop([\"TimeStamp\"], axis=1, inplace=True)","1ebb9abe":"movie_df.head()","60021fe3":"movie_df[\"Genres\"].unique()","8b9c1a65":"movie_df[\"Genres\"].head(20)","41a9458c":"number_rating = movie_df.groupby(\"Title\")[\"Rating\"].count().reset_index()","b4384837":"number_rating","f9e15c2d":"number_rating.rename(columns={\"Title\": \"Title\",\n                              \"Rating\": \"Number of Ratings\"}, inplace=True)","3c24f565":"number_rating.head()","03b525b8":"df = movie_df.merge(number_rating, on=\"Title\")\ndf.head()","0f0f1382":"df = df[df[\"Number of Ratings\"] >= 1000]","014e3d53":"pivot_table = df.pivot_table(index=\"Title\", columns=\"UserID\", values=\"Rating\")\npivot_table.head()","95b52c97":"pivot_table.fillna(0, inplace=True)","d77ac1c8":"movie_sparse = csr_matrix(pivot_table)","976167f0":"model = NearestNeighbors(n_neighbors=5, algorithm=\"brute\", metric=\"cosine\")\nmodel","4f66654f":"model.fit(movie_sparse)","fdb0eb5b":"df.drop(columns=[\"Genres\", \"UserID\", \"Rating\"],inplace=True)","ed3747a4":"df1 = df.copy()\nt_list = []\nfor i in df[\"Title\"]:\n    t_list.append(i.split(\" (\")[0])\ndf1[\"Title\"] = t_list","209b3486":"def get_recommendations(movie_name):\n    distances, suggestions = model.kneighbors(\n        pivot_table.loc[movie_name].values.reshape(1, -1), n_neighbors = 5)\n    for i in range(0, len(distances.flatten())):\n        if i == 0:\n            print('Recommendations for {0}:\\n'.format(pivot_table.index[i]))\n        else:\n            print('{0}: {1}, with distance of {2}:'.format(i,\n                                                           pivot_table.index[suggestions.flatten()[i]],\n                                                           distances.flatten()[i]))","16de04c5":"for i in range(0, len(pivot_table)):\n    print(\"\\n****************************\\n\")\n    get_recommendations(pivot_table.index[i])\n    print(\"\\n****************************\\n\")","5f980db8":"movie_df.head()","a35b31cd":"pip install tfidf","591b7159":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import sigmoid_kernel","256dc429":"tfv = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 1000), min_df=1)\nx = tfv.fit_transform(movie_df[\"Genres\"])","ec311638":"model = sigmoid_kernel(x, x)","e2b5df76":"df1=df.copy()\nti=[]\nfor i in df1[\"Title\"]:\n    ti.append(i.split(' (')[0])\ndf1[\"Title\"]=ti","8a584194":"def get_contentbasedrecommendations(title):\n    i_d=[]\n    indices=pd.Series(df1.index,index=df1[\"Title\"]).drop_duplicates()\n    idx = indices[title]\n    dis_scores = list(enumerate(model[idx]))\n    dis_scores = sorted(dis_scores, key=lambda x: x[1], reverse=True)\n    dis_scores = dis_scores[1:31]\n    idn = [i[0] for i in dis_scores]\n    final =df1.iloc[idn].reset_index()\n    idn = [i for i in final['index']]\n    for j in idn:\n        if(j<15951):\n            i_d.append(j)\n    indices=pd.Series(df.index,index=df[\"Title\"]).drop_duplicates()\n    for i in range(1,8):\n        if (idn):\n            print(indices.iloc[i_d].index[i])\n     \n","e9d3dd9b":"for i in range(0, len(pivot_table)):\n    print(\"\\n****************************\\n\")\n    get_contentbasedrecommendations(\"Unforgettable (1996)\")\n    print(\"\\n****************************\\n\")","bb7cbacb":"### IMDBID","744dd35f":"Movie dataframe and the tags dataframe could not merged cause of the size of the dataframe, soo we can really say this could not merged.","4ac35033":"By looking the correlation graph, Imdb ID and tmbdID has a high correlation with 82%. Maybe we can fill the nan tmbsID by using ImdbID's. Let's change the column names,this makes more cleare visualization for making operations.","e87f91e5":"We can limited the dataframe as they are greater than 1000 counts.The frmae should be simplified by decreases the observations amount by using these operations.","e7b17d33":"Let's merged the number rating and movie_df frames. Merging operation is made a super dataframe.","5bc26f74":"## Rating","0fb11055":"Let's make some questions and try to find the respectives by asked questions.\n* Inspirations are described from the orginal site;\n    * Which genres receive the highest ratings? How does this change over time?\n    * Determine the temporal trends in the genres\/tagging activity of the movies released?","e328b94a":"First we should look that shapes of the frames,this should be useful for us to concat the frames.","dad0c515":"Let's remove one of the duplicate columns.","a98b005d":"# PART I - Review The Structure of Data","cba70c08":"Let's load the libraries.This would be helpful to make our operations","2bed615f":"Movies and links frames have same size observation, we should look their unique count,then we can concatenate them","7e4424f7":"## PART II. II - Ratings - Movie Df Merge Operation","9a4b9ae3":"Let's use the command for the text formatter vectorizer in our kernel by using python command.","2b1cdb6b":"## PART II. I - Movies_Df Reviews","a22e57de":"We now concatenate these movies and links dataframe as well.","59113983":"#  PART III - Analysis","4fb059bb":"Let's read our datasets, All the forms of dataset are distinct,we should need to group them.","ad20db3b":"Let's look the top frequent values.**\"Black Field (2009)\"**","676c463f":"Let's remember our content-based algorithm. We will use TFID vectorizer for the content-based recommendation techniques.","d66aba69":"Control the nan values, when we concatenate we can faced with some of them.","2f74cd76":"# PART V - Content-Based Algorithm","eb65d778":"Found a way like the most frequenct nan values are gonna filled by the genres mean.By using interpolation technique, we can fill them respectively.","b9d7c0f3":"### Title","1a649bdb":"# PART VI - Final Part\n<br><\/br>\nFinally, we wanted to built a recommendation system engine to predict the similar items of users prefers and we aimed with this collaborative item based filtering algorithm and also content-based filtering techniques.The all output gives us such a way to predict the future data by looking the previous data in movielens dataset.","3a2817bc":"Some films are repeat more than once times.","5ef4240a":"We combined the movies and links frames for now, later we can concateate the others, however we should start to observe the history and infrastucture of the dataframe.","7afb32bc":"### Genres","6d49560b":"* Step I; We will look the movies_df.\n* Step II; We will look the ratings.\n* Step III; Merge ratings and movies_df for making one super dataframe.","2a65b8ad":"### TimeStamp","e5903959":"We have some missing values in that dataframe, this column nan values should be checked.","c7942fb8":"Visualize the correlation between the properties of our dataframe.","d970595e":"# PART IV - K Nearest Neighbors - Collaborative Filtering Analysis\n<BR><\/BR>\nthis algorithms is a supervised machine learning algorithm.This is non parametric --> Not predicting anything any assumptions from the dataset, Lazy algorithm --> KNN does not have any training step.\nThis algorithm is used both classification and regression problems.\n<BR><\/BR>\n\nKNN works like the way of selecting a value for the real ideal value as K.Then we calculate the all distances between the K points and all observation points.After that, we can find the KNearestNeighbors to the new data points. For the classification problems, we count the number of data points in each category among the K values. For regression, value for the new datapoint will be the average of the K Neighbors.\n<BR><\/BR>\n\nDistance can be calculated using \n* \"Euclidean distance\", \n* \"Manhattan distance\", \n* \"Hamming Distance\", \n* \"Minkowski Distance\".\n<BR><\/BR>\n\nEuclidean distance is calculated by getting the square of differences of independent and dependent values and their predictions.\nManhattan distance is calculated by getting the absolute value of the differences between the actual and predicted values.\nHamming distance is calculated by grouping categoric values. If my catgeoric values are grouped as large and medium, it returns 1, otherwise large-large combination returns only 0.\nMinkowski distance is calculated by grouping the absolute values of the differences between actual and predicted values.The total number of repeats time gives as a exponential.The results exponential is gonna 1\/p too.\n<BR><\/BR>\nKNN provides pros and cons too.Let's dive into them. \n* PROS: \n    ** Simple and easy to implement.\n    ** Non parametric - no assumptions about underlaying data.\n    ** Both classification and regression.\n    ** Training step is faster. \n* CONS:\n    ** KNN is expensive for new point predictions.\n    ** Sensitive to the outliers.\n    ** Accuracy can be deviate from the target by the noise and irrelevant data.  \n    ","5efd32f1":"### MovieID","4fad4c47":"Lots of users are voted as 4 stars for the films recommendation.Visualization of the stars frequency could be very helpful for us.","8f6c75cf":"Let's look the observations and proeprties.","fa357063":"### TMBDID","7ed2387a":"We can gentely say this column's all observations are unique and repeats only once.All the frequencies are 1.","27adffca":"TMBDID could be samne if one film can released in different years even it is updated or not.This can effects the situation of ID.","590c13ae":"# PART II - Review The Attributes of Dataframes","20478cfc":"movie_df = movie_df.merge(tags, on=\"MovieID\")\nmovie_df.head()","410d9a46":"Control the nan values distribution,maybe we can find some way to out.","7ea5c433":"Let's control the exitence of nan values.","9202d5fd":"Let's change the columns of ratings dataframe.","961d5cab":"Let's look the types and the information of the dataframe","650d3af4":"This dataset has integer, objects and float values relatively.Let's look the statistical description of the numeric values.","92fcb8b2":"This means that could be one person can rates the different movies respectively.","876136d8":"Timestamp values should be converted to datetime from integer based.Let's control the datatypes of the property.","297fb271":"Finally, TimeStamp column has no meanings for us, we only want to review the rating not the timestamp,this would not give any tricks to traack the data.","48a35f6d":"We should merge movies_df and ratings, because they specifies the same meaning by ratings values.","f1039e8d":"We have approximately hundred **nan** values in the movies dataframe.Think about to fill or drop them by the approach of our real dataset.","1cc5e6bd":"# Recommender System Projectdef recommendations(title):\n    i_d=[]\n    indices=pd.Series(df1.index,index=df1['title']).drop_duplicates()\n    idx = indices[title]\n    dis_scores = list(enumerate(model[idx]))\n    dis_scores = sorted(dis_scores, key=lambda x: x[1], reverse=True)\n    dis_scores = dis_scores[1:31]\n    idn = [i[0] for i in dis_scores]\n    final =df1.iloc[idn].reset_index()\n    idn = [i for i in final['index']]\n    for j in idn:\n        if(j<15951):\n            i_d.append(j)\n    indices=pd.Series(df.index,index=df['title']).drop_duplicates()\n    for i in range(1,8):\n        if (idn):\n            print(indices.iloc[i_d].index[i])\n     \n"}}