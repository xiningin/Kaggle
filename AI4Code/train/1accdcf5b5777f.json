{"cell_type":{"4036e219":"code","650ecbb2":"code","c4b4b117":"code","9d48a51a":"code","5b7250fa":"code","c44c772d":"code","fdf73331":"code","8158536d":"code","c761ac72":"code","99d1bf12":"code","2bf7eb5d":"code","aafd48ed":"code","9eed3cb9":"code","2b9ff8a7":"code","5876d5ef":"code","470ee1f5":"code","67f524a9":"code","985e622f":"code","642cbf9c":"code","8f34f0b6":"code","77336464":"code","b8239b41":"code","9b61edee":"code","598b72e0":"code","9d005d9d":"code","86604f90":"code","0f468c28":"code","c215d78f":"code","a814d5ba":"code","f5a94b2b":"code","8b55782d":"code","7d0b2434":"code","efbd4679":"code","8d9517c8":"code","e9e79bff":"code","72a177df":"code","f45ca353":"code","5b22c98e":"code","be0b598a":"code","55b85368":"markdown","e92d095f":"markdown","aa4d5a73":"markdown","744de36e":"markdown","7bf5ce5c":"markdown","61e86ed7":"markdown","f133bf41":"markdown","fa332513":"markdown","cb8c6d3c":"markdown","aae053d7":"markdown"},"source":{"4036e219":"import os,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20, 10\n\nfrom sklearn.utils import shuffle\nfrom  sklearn.model_selection import train_test_split\n\nimport keras\n\nfrom keras.utils import np_utils\n\nfrom keras import backend as K\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD,RMSprop,adam\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd","650ecbb2":"# get the data\nfilname = '..\/input\/facial-expression\/fer2013\/fer2013.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\ndf=pd.read_csv('..\/input\/facial-expression\/fer2013\/fer2013.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","c4b4b117":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","9d48a51a":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) \/ 255.0, np.array(Y)\n    return X, Y","5b7250fa":"X, Y = getData(filname)\nnum_class = len(set(Y))\nprint(num_class)","c44c772d":"# keras with tensorflow backend\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","fdf73331":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","8158536d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c761ac72":"from keras.models import load_model\n","99d1bf12":"model = load_model('\/kaggle\/input\/model-visualize\/menu_visualize\/model_keras.h5')\nmodel.load_weights('\/kaggle\/input\/model-visualize\/menu_visualize\/model_weights.h5')","2bf7eb5d":"model.summary()","aafd48ed":"from keras.utils import plot_model\nplot_model(model, to_file='model.png',show_shapes=True, show_layer_names=True)","9eed3cb9":"def predict_emotion(image):\n    x_test = np.expand_dims(image,axis=0)\n    y_predict = np.argmax(model.predict(x_test))\n    emotion_dict = {0:'Anger',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',6:'Neutral'}\n    return(emotion_dict[y_predict])\n    ","2b9ff8a7":"from pylab import rcParams\nrcParams['figure.figsize'] = 5, 10\ndef plot_image(image):\n    img = image.reshape(48,48)\n    plt.imshow(img, interpolation='nearest')\n    plt.show()\n","5876d5ef":"image_tes1 = X_test[4]\nplot_image(image_tes1)\npredict_emotion(image_tes1)","470ee1f5":"image_tes2 = X_test[800]\nplot_image(image_tes2)\npredict_emotion(image_tes2)","67f524a9":"image_tes3 = X_test[90]\nplot_image(image_tes3)\npredict_emotion(image_tes3)","985e622f":"image_tes4 = X_test[60]\nplot_image(image_tes4)\npredict_emotion(image_tes4)","642cbf9c":"import cv2","8f34f0b6":"img_5 = cv2.imread('\/kaggle\/input\/test-images-gray\/test_images_small\/g.png')\nimg_gray_5 = cv2.cvtColor(img_5, cv2.COLOR_BGR2GRAY)\n\nimg_5_resize = cv2.resize(img_gray_5, (48, 48))\nimg_5 = img_5_resize.reshape(48, 48, 1)\n\nplot_image(img_5)\npredict_emotion(img_5)","77336464":"img_5 = cv2.imread('\/kaggle\/input\/test-images-gray\/test_images_small\/c.png')\nimg_gray_5 = cv2.cvtColor(img_5, cv2.COLOR_BGR2GRAY)\n\nimg_5_resize = cv2.resize(img_gray_5, (48, 48))\nimg_5 = img_5_resize.reshape(48, 48, 1)\n\nplot_image(img_5)\npredict_emotion(img_5)","b8239b41":"img_5 = cv2.imread('\/kaggle\/input\/test-images-gray\/test_images_small\/e.png')\nimg_gray_5 = cv2.cvtColor(img_5, cv2.COLOR_BGR2GRAY)\n\nimg_5_resize = cv2.resize(img_gray_5, (48, 48))\nimg_5 = img_5_resize.reshape(48, 48, 1)\n\nplot_image(img_5)\npredict_emotion(img_5)","9b61edee":"from keras.models import Model\n\ndef layer_image(input_image, col_size, row_size, act_index):\n\n    image_array = input_image\n    x_enpanded = np.expand_dims(image_array, axis=0)\n    y_pred = np.argmax(model.predict(x_enpanded))\n    emotion_dict = {0:'Anger',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',6:'Neutral'}\n    label = emotion_dict[y_pred]\n\n    layer_outputs = [layer.output for layer in model.layers][1:]\n    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n    activations = activation_model.predict(x_enpanded)\n\n    activation = activations[act_index]\n    activation_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*5,col_size*5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(activation[0, :, :, activation_index])\n            activation_index += 1\n    return fig","598b72e0":"image_gain1 = layer_image(image_tes1, 8,8,1)","9d005d9d":"#image_gain2 = layer_image(image_tes2, 8,8,1)","86604f90":"#image_gain3 = layer_image(image_tes3, 8,8,1)","0f468c28":"#image_gain4 = layer_image(image_tes4, 8,8,0)","c215d78f":"best_model = model","a814d5ba":"from sklearn.metrics import confusion_matrix\nresults = best_model.predict_classes(X_test)\ncm = confusion_matrix(np.where(y_test == 1)[1], results)\n#cm = cm.astype(np.float) \/ cm.sum(axis=1)[:, np.newaxis]","f5a94b2b":"import seaborn as sns\nimport pandas as pd","8b55782d":"label_mapdisgust = ['anger','contempt','disgust','fear','happy','sadness','surprise']","7d0b2434":"#Transform to df for easier plotting\ncm_df = pd.DataFrame(cm, index = label_mapdisgust,\n                     columns = label_mapdisgust\n                    )","efbd4679":"final_cm = cm_df","8d9517c8":"plt.figure(figsize = (5,5))\nsns.heatmap(final_cm, annot = True,cmap='Greys',cbar=False,linewidth=2,fmt='d')\nplt.title('CNN Emotion Classify')\nplt.ylabel('True class')\nplt.xlabel('Prediction class')\nplt.show()","e9e79bff":"from sklearn.metrics import roc_curve,auc\nfrom itertools import cycle","72a177df":"new_label = ['anger','contempt','disgust','fear','happy','sadness','surprise']\nfinal_label = new_label\nnew_class = 7","f45ca353":"#predict\ny_pred = best_model.predict(X_test)","5b22c98e":"#ravel flatten the array into single vector\ny_pred_ravel = y_pred.ravel()\nlw = 2","be0b598a":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(new_class):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \n#colors = cycle(['red', 'green','black'])\ncolors = cycle(['red', 'green','black','blue', 'yellow','purple','orange'])\nfor i, color in zip(range(new_class), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0}'''.format(final_label[i]))\n    \n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","55b85368":"# CNN VISUALIZATION","e92d095f":"# Data except the FER2013","aa4d5a73":"# Function to plot image","744de36e":"# Confusion Matrix","7bf5ce5c":"# Image Preprocessing","61e86ed7":"# Load pretrained model","f133bf41":"# ROC Curve","fa332513":"# Model Visualization","cb8c6d3c":"# Function to predict image emotion","aae053d7":"# Model Summary"}}