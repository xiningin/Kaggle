{"cell_type":{"7225647e":"code","5c9ad1fb":"code","d8372492":"code","41358eca":"code","890a5acf":"code","291c0a74":"code","a5d02687":"code","46529e88":"code","6aeaa2e2":"code","2525e518":"code","500c9a83":"code","514a087e":"code","f5822f8c":"code","67894ecc":"code","777370e1":"code","0b1264ce":"code","0b1286ba":"code","9933512d":"code","8e81622f":"code","c3ab9146":"code","7c59fe80":"code","6cfab6f5":"code","228aa6bb":"code","08a7fdfe":"code","761f193a":"code","acc448fd":"code","656c6379":"code","3300ed48":"markdown","23daa9c8":"markdown","0c2fe681":"markdown","b9f53390":"markdown","d56e6b51":"markdown","aa8ea104":"markdown","a5c2c1bd":"markdown","f17116ad":"markdown","0ffa1cd7":"markdown","29692434":"markdown","76eb8905":"markdown","9ad8f17a":"markdown","6605662c":"markdown","dfb0cd38":"markdown","86e2de82":"markdown","aa3f670f":"markdown","b5b55b36":"markdown","52577dd1":"markdown","2da35236":"markdown","7f551182":"markdown","065479be":"markdown","b15ba774":"markdown"},"source":{"7225647e":"import pandas as pd\nimport numpy as np\nfrom sklearn.base import BaseEstimator,TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression","5c9ad1fb":"src = pd.read_csv('..\/input\/iris\/Iris.csv')\ndata = (src.iloc[:,1:-1]).copy()\ndata.head()","d8372492":"class OutlierRemover(BaseEstimator,TransformerMixin):\n    def __init__(self,factor=1.5):\n        self.factor = factor\n        \n    def outlier_removal(self,X,y=None):\n        X = pd.Series(X).copy()\n        q1 = X.quantile(0.25)\n        q3 = X.quantile(0.75)\n        iqr = q3 - q1\n        lower_bound = q1 - (self.factor * iqr)\n        upper_bound = q3 + (self.factor * iqr)\n        X.loc[((X < lower_bound) | (X > upper_bound))] = np.nan \n        return pd.Series(X)\n    \n    def fit(self,X,y=None):\n        return self\n    \n    def transform(self,X,y=None):\n        return X.apply(self.outlier_removal)","41358eca":"#creating outlier_remover object of OutlierRemover class\noutlier_remover = OutlierRemover()","890a5acf":"outlier_remover.get_params()","291c0a74":"test = pd.DataFrame({'col1':[100,200,300,999],'col2':[0,0,1,2],'col3':[-10,0,1,2]})\ntest","a5d02687":"outlier_remover.fit(test)","46529e88":"outlier_remover.transform(test)","6aeaa2e2":"outlier_remover.fit_transform(test)","2525e518":"outlier_remover = OutlierRemover(factor=100)","500c9a83":"test","514a087e":"outlier_remover.fit_transform(test)","f5822f8c":"data.plot(kind=\"box\",subplots=True,figsize=(15,5),title=\"Data with Outliers\");","67894ecc":"outlier_remover = OutlierRemover()\n\n#ColumnTransformer to remove outliers\nct = ColumnTransformer(transformers=[['outlier_remover',OutlierRemover(),list(range(data.shape[1]))]],remainder='passthrough')\n\n#iris data after outlier removal\ndata_without_outliers = pd.DataFrame(ct.fit_transform(data),columns=data.columns)\n\n#iris data box plot after outlier removal\ndata_without_outliers.plot(kind=\"box\",subplots=True,figsize=(15,5),title=\"Data without Outliers\");","777370e1":"# 4 outliers are removed from SepalWidthCm, other columns stayed the same as they have no outliers.\ndata_without_outliers.isnull().sum()","0b1264ce":"#outliers removed from sepal width (cm)\nlist(data.loc[data_without_outliers.isnull().sum(axis=1)>0,'SepalWidthCm'])","0b1286ba":"X = data.copy()\ny = load_iris()['target'].copy()\n\n#Pipeline with outlier remover, imputer and regressor\npipeline = Pipeline(steps=[['outlier_removal',ct],['imputer',SimpleImputer()],['regressor',LogisticRegression(max_iter=1000)]]) \n\nparam_grid = {'outlier_removal__outlier_remover__factor':[0,1,2,3,4],\n              'imputer__strategy':['mean','median','most_frequent'],\n              'regressor__C':[0.01,0.1,1,10,100]}\n\ngs = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='accuracy', cv=3)\n\ngs.fit(X,y)\n\ngs.best_params_","9933512d":"def outlier_removal(X,factor):\n    X = pd.DataFrame(X).copy()\n    for i in range(X.shape[1]):\n        x = pd.Series(X.iloc[:,i]).copy()\n        q1 = x.quantile(0.25)\n        q3 = x.quantile(0.75)\n        iqr = q3 - q1\n        lower_bound = q1 - (factor * iqr)\n        upper_bound = q3 + (factor * iqr)\n        X.iloc[((X.iloc[:,i] < lower_bound) | (X.iloc[:,i] > upper_bound)),i] = np.nan \n    return X","8e81622f":"#creating outlier_remover object using FunctionTransformer with factor=1.5\noutlier_remover = FunctionTransformer(outlier_removal,kw_args={'factor':1.5})","c3ab9146":"test = pd.DataFrame({'col1':[100,200,300,999],'col2':[0,0,1,2],'col3':[-10,0,1,2]})\ntest","7c59fe80":"outlier_remover.fit_transform(test)","6cfab6f5":"outlier_remover.inverse_transform(outlier_remover.fit_transform(test))","228aa6bb":"data.plot(kind=\"box\",subplots=True,figsize=(15,5),title=\"Data with Outliers\");","08a7fdfe":"#ColumnTransformer to remove outliers\nct = ColumnTransformer(transformers=[['outlier_remover',outlier_remover,list(range(data.shape[1]))]],remainder='passthrough')\n\n#iris data after outlier removal\ndata_without_outliers = pd.DataFrame(ct.fit_transform(data),columns=data.columns)\n\n#iris data box plot after outlier removal\ndata_without_outliers.plot(kind=\"box\",subplots=True,figsize=(15,5),title=\"Data without Outliers\");","761f193a":"# 4 outliers are removed from SepalWidthCm, other columns stayed the same as they have no outliers.\ndata_without_outliers.isnull().sum()","acc448fd":"#outliers removed from sepal width (cm)\nlist(data.loc[data_without_outliers.isnull().sum(axis=1)>0,'SepalWidthCm'])","656c6379":"X = data.copy()\ny = load_iris()['target'].copy()\n\npipeline = Pipeline(steps=[['outlier_removal',ct],['imputer',SimpleImputer()],['regressor',LogisticRegression(max_iter=1000)]]) \n\nparam_grid = {'outlier_removal__outlier_remover__kw_args':[{'factor':0},{'factor':1},{'factor':2},{'factor':3},{'factor':4}],\n              'imputer__strategy':['mean','median','most_frequent'],\n              'regressor__C':[0.01,0.1,1,10,100]}\n\ngs = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='accuracy', cv=3)\n\ngs.fit(X,y)\n\ngs.best_params_","3300ed48":"<h4 style=\"font-family:arial;font-size:16px\">The OutlierRemover class replaces the outliers detected using IQR method with NaN.<br><br> \n__init__ is the first method that's called upon creating an instance\/object of the class. This is used to initialize the class attributes. We'll initialize the factor of the IQR method with 1.5 (default value).<br><br>\noutlier_removal method replaces the outliers in a Series with NaN.<br><br>\nfit() method returns self always.<br><br>    \ntransform() method takes in an array\/data frame as input and applies the outlier_removal method to all the columns of the data frame\/array and returns it.","23daa9c8":"<h1 style=\"font-family:arial;font-size:30px\">Creating Custom Transformers Using Scikit-Learn<\/h1>\n<h3 style=\"font-family:arial\">This notebook explains the methods to create custom transformers using Scikit-Learn. We'll use the Iris dataset to create an outlier removal transformer.<\/h3>","0c2fe681":"<h4 style=\"font-family:arial;font-size:16px\">We can see that the outliers are removed. Now let's see which were the outliers removed.","b9f53390":"<h3>transform()","d56e6b51":"<h4 style=\"font-family:arial;font-size:16px\">Below we'll use a box plot to show the outliers in the Iris Data.","aa8ea104":"<h3 style=\"font-family:arial\">In the above param_grid, the parameters of 'outlier_removal' look a bit different because we have to tune the kw_args hyperparameter of the FunctionTransformer, unlike 'factor' in method 1.","a5c2c1bd":"<h4 style=\"font-family:arial;font-size:16px\">The above function takes an array\/data frame along with 'factor' as inputs and replaces the outliers in each column with NaN ","f17116ad":"<h3>Object initialization with custom factor (higher the factor, higher would be the outlier boundaries","0ffa1cd7":"<h4 style=\"font-family:arial;font-size:16px\">The above boxplot shows that only the variable 'SepalWidthCm' has outliers, 4 to be precise. We'll create a ColumnTransformer to apply the 'outlier_remover' to all the variables of the Iris dataset and visualize the variables after outlier removal, using a boxplot.","29692434":"<h3>fit_transform()","76eb8905":"<h4 style=\"font-family:arial;font-size:16px\">In the above code cell, we've fit and transformed a data frame with outliers in 'col1' and 'col2' and they have been replaced with NaN. ","9ad8f17a":"<h4 style=\"font-family:arial;font-size:16px\">We can see that the outliers are removed. Now let's see which were the outliers removed.","6605662c":"<h3>Inverse Transform<\/h3><h4 style=\"font-family:arial;font-size:16px\">FunctionTransformer also provides an inverse_transform method.","dfb0cd38":"<h4 style=\"font-family:arial;font-size:16px\">We can see that 'SepalWidthCm'>4 and 'SepalWidthCm'<=2 are removed as they were outliers. The same can be seen in the earlier boxplot showing outliers.<\/h4>\n\n<h3 style=\"font-family:arial\">Now, we'll create a pipeline that removes the outliers, imputes the removed outliers and fits a logistic regression model. We'll tune the hyperparameters using Grid Search.","86e2de82":"<h3>fit()<\/h3>","aa3f670f":"<h4 style=\"font-family:arial;font-size:16px\">In the above code cell, we've fit and transformed a data frame with outliers in 'col1' and 'col2' and they have been replaced with NaN.","b5b55b36":"<h4 style=\"font-family:arial;font-size:16px\">We can see that 'SepalWidthCm'>4 and 'SepalWidthCm'<=2 are removed as they were outliers. The same can be seen in the earlier boxplot showing outliers.<\/h4>\n\n<h3 style=\"font-family:arial\">Now, we'll create a pipeline that removes the outliers, imputes the removed outliers and fits a logistic regression model. We'll tune the hyperparameters using Grid Search.","52577dd1":"<h4 style=\"font-family:arial;font-size:16px\">The above boxplot shows that only the variable 'SepalWidthCm' has outliers, 4 to be precise. We'll create a ColumnTransformer to apply the OutlierRemover to all the variables of the Iris dataset and visualize the variables after outlier removal, using a boxplot.","2da35236":"<h2 style=\"font-family:arial\">Method 1<\/h2>\n<h2 style=\"font-family:arial\">This method uses BaseEstimator and TransformerMixin to create a custom class for outlier removal.<\/h2>\n<h4 style=\"font-family:arial;font-size:16px\">BaseEstimator class of Scikit-Learn enables hyperparameter tuning by adding the methods set_params and get_params. While, TransformerMixin adds the fit_transform method without explicitly defining it. We'll create an OutlierRemover class below.<\/h4>","7f551182":"<h3>get_params()","065479be":"<h4 style=\"font-family:arial;font-size:16px\">Since the factor is high, no outliers were removed.<br><br>Below we'll use a box plot to show the outliers in the Iris Data.","b15ba774":"<h2 style=\"font-family:arial\">Method 2<\/h2>\n<h2 style=\"font-family:arial\">This method uses FunctionTransformer class of Scikit-Learn to create a custom transformer for outlier removal.<\/h2>"}}