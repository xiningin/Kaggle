{"cell_type":{"162ce344":"code","cb01ec36":"code","7adb3f18":"code","424efd2b":"code","d10be028":"code","4ac4d9a5":"code","f0fabcff":"code","0fad630f":"code","9e41b623":"code","a779cc61":"code","bd1785fd":"code","6113975c":"code","61323be5":"code","7cbb1172":"code","4fe461dd":"code","b585e969":"markdown","aebc34ea":"markdown","4b55f8c0":"markdown","af26f4d4":"markdown","c90899b9":"markdown","1449c358":"markdown","fc65a599":"markdown","7efe4165":"markdown","d8920977":"markdown","f977092d":"markdown","59521726":"markdown","3f105af5":"markdown","933ea83a":"markdown"},"source":{"162ce344":"import numpy as np \nimport pandas as pd \n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom bayes_opt import BayesianOptimization\nfrom datetime import datetime\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nimport catboost\nfrom catboost import Pool\n\n# Suppr warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport itertools\nfrom scipy import interp\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import rcParams\n\n#Timer\ndef timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('Time taken for Modeling: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))","cb01ec36":"%%time\ntrain_transaction = pd.read_csv('..\/input\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv', index_col='TransactionID')\ntrain_identity = pd.read_csv('..\/input\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='TransactionID')","7adb3f18":"# merge \ntrain_df = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest_df = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(\"Train shape : \"+str(train_df.shape))\nprint(\"Test shape  : \"+str(test_df.shape))","424efd2b":"pd.set_option('display.max_columns', 500)","d10be028":"# GPreda, missing data\ndef missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","4ac4d9a5":"display(missing_data(train_df), missing_data(test_df))","f0fabcff":"#fillna\ntrain_df = train_df.fillna(-999)\ntest_df = test_df.fillna(-999)","0fad630f":"del train_transaction, train_identity, test_transaction, test_identity","9e41b623":"# Label Encoding\nfor f in train_df.columns:\n    if  train_df[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n        train_df[f] = lbl.transform(list(train_df[f].values))\n        test_df[f] = lbl.transform(list(test_df[f].values))  \ntrain_df = train_df.reset_index()\ntest_df = test_df.reset_index()","a779cc61":"features = list(train_df)\nfeatures.remove('isFraud')\ntarget = 'isFraud'","bd1785fd":"# Confusion matrix \ndef plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion matrix\"',\n                          cmap = plt.cm.Blues) :\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6113975c":"param_cb = {\n        'learning_rate': 0.2,\n        'bagging_temperature': 0.1, \n        'l2_leaf_reg': 30,\n        'depth': 12, \n        'max_leaves': 48,\n        'max_bin':255,\n        'iterations' : 1000,\n        'task_type':'GPU',\n        'loss_function' : \"Logloss\",\n        'objective':'CrossEntropy',\n        'eval_metric' : \"AUC\",\n        'bootstrap_type' : 'Bayesian',\n        'random_seed':1337,\n        'early_stopping_rounds' : 100,\n        'use_best_model': True \n}","61323be5":"print('CatBoost GPU modeling...')\nstart_time = timer(None)\nplt.rcParams[\"axes.grid\"] = True\n\nnfold = 5\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=42)\n\noof = np.zeros(len(train_df))\nmean_fpr = np.linspace(0,1,100)\ncms= []\ntprs = []\naucs = []\ny_real = []\ny_proba = []\nrecalls = []\nroc_aucs = []\nf1_scores = []\naccuracies = []\nprecisions = []\npredictions = np.zeros(len(test_df))\nfeature_importance_df = pd.DataFrame()\n\ni = 1\nfor train_idx, valid_idx in skf.split(train_df, train_df.isFraud.values):\n    print(\"\\nfold {}\".format(i))\n    trn_data = Pool(train_df.iloc[train_idx][features].values,\n                   label=train_df.iloc[train_idx][target].values\n                   )\n    val_data = Pool(train_df.iloc[valid_idx][features].values,\n                   label=train_df.iloc[valid_idx][target].values\n                   )   \n\n    clf = catboost.train(trn_data, param_cb, eval_set= val_data, verbose = 300)\n\n    oof[valid_idx]  = clf.predict(train_df.iloc[valid_idx][features].values)   \n    oof[valid_idx]  = np.exp(oof[valid_idx]) \/ (1 + np.exp(oof[valid_idx]))\n    \n    predictions += clf.predict(test_df[features]) \/ nfold\n    predictions = np.exp(predictions)\/(1 + np.exp(predictions))\n    \n    # Scores \n    roc_aucs.append(roc_auc_score(train_df.iloc[valid_idx][target].values, oof[valid_idx]))\n    accuracies.append(accuracy_score(train_df.iloc[valid_idx][target].values, oof[valid_idx].round()))\n    recalls.append(recall_score(train_df.iloc[valid_idx][target].values, oof[valid_idx].round()))\n    precisions.append(precision_score(train_df.iloc[valid_idx][target].values ,oof[valid_idx].round()))\n    f1_scores.append(f1_score(train_df.iloc[valid_idx][target].values, oof[valid_idx].round()))\n    \n    # Roc curve by fold\n    f = plt.figure(1)\n    fpr, tpr, t = roc_curve(train_df.iloc[valid_idx][target].values, oof[valid_idx])\n    tprs.append(interp(mean_fpr, fpr, tpr))\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.4f)' % (i,roc_auc))\n\n    # Precion recall by folds\n    g = plt.figure(2)\n    precision, recall, _ = precision_recall_curve(train_df.iloc[valid_idx][target].values, oof[valid_idx])\n    y_real.append(train_df.iloc[valid_idx][target].values)\n    y_proba.append(oof[valid_idx])\n    plt.plot(recall, precision, lw=2, alpha=0.3, label='P|R fold %d' % (i))  \n    \n    i= i+1\n    \n    # Confusion matrix by folds\n    cms.append(confusion_matrix(train_df.iloc[valid_idx][target].values, oof[valid_idx].round()))\n    \n    # Features imp\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = features\n    fold_importance_df[\"importance\"] = clf.get_feature_importance()\n    fold_importance_df[\"fold\"] = nfold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n# Metrics\nprint(\n        '\\nCV roc score        : {0:.4f}, std: {1:.4f}.'.format(np.mean(roc_aucs), np.std(roc_aucs)),\n        '\\nCV accuracy score   : {0:.4f}, std: {1:.4f}.'.format(np.mean(accuracies), np.std(accuracies)),\n        '\\nCV recall score     : {0:.4f}, std: {1:.4f}.'.format(np.mean(recalls), np.std(recalls)),\n        '\\nCV precision score  : {0:.4f}, std: {1:.4f}.'.format(np.mean(precisions), np.std(precisions)),\n        '\\nCV f1 score         : {0:.4f}, std: {1:.4f}.'.format(np.mean(f1_scores), np.std(f1_scores))\n)\n\n#ROC\nf = plt.figure(1)\nplt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'grey')\nmean_tpr = np.mean(tprs, axis=0)\nmean_auc = auc(mean_fpr, mean_tpr)\nplt.plot(mean_fpr, mean_tpr, color='blue',\n         label=r'Mean ROC (AUC = %0.4f)' % (np.mean(roc_aucs)),lw=2, alpha=1)\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Catboost ROC curve by folds')\nplt.legend(loc=\"lower right\")\n\n# PR plt\ng = plt.figure(2)\nplt.plot([0,1],[1,0],linestyle = '--',lw = 2,color = 'grey')\ny_real = np.concatenate(y_real)\ny_proba = np.concatenate(y_proba)\nprecision, recall, _ = precision_recall_curve(y_real, y_proba)\nplt.plot(recall, precision, color='blue',\n         label=r'Mean P|R')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Catboost P|R curve by folds')\nplt.legend(loc=\"lower left\")\n\n# Confusion maxtrix & metrics\nplt.rcParams[\"axes.grid\"] = False\ncm = np.average(cms, axis=0)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title= 'CatBoost Confusion matrix [averaged\/folds]')\n# Timer end    \ntimer(start_time)","7cbb1172":"plt.style.use('dark_background')\ncols = (feature_importance_df[[\"Feature\", \"importance\"]]\n    .groupby(\"Feature\")\n    .mean()\n    .sort_values(by=\"importance\", ascending=False)[:30].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(10,10))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False),\n        edgecolor=('white'), linewidth=2, palette=\"rocket\")\nplt.title('CatBoost Features importance (averaged\/folds)', fontsize=18)\nplt.tight_layout()","4fe461dd":"sample_submission['isFraud'] = predictions\nsample_submission.to_csv('submission_IEEE.csv')","b585e969":"----------\n**IEEE - Catboost GPU baseline(5 Kfold)**\n=====================================\n\n***Vincent Lugat***\n\n*July 2019*\n\n----------","aebc34ea":"# <a id='4'>4. Submission<\/a> ","4b55f8c0":"# <a id='1'>1. Librairies and data<\/a> ","af26f4d4":"## MERGE, MISSING VALUE, FILL NA","c90899b9":"## DATASETS","1449c358":"## PARAMS ","fc65a599":"## ENCODING","7efe4165":"## CONFUSION MATRIX","d8920977":"![](https:\/\/image.noelshack.com\/fichiers\/2019\/29\/2\/1563297157-cis-logo.png)","f977092d":"# <a id='2'>2. Catboost<\/a> ","59521726":"## CV 5 FOLDS AND METRICS","3f105af5":"- <a href='#1'>1. Libraries and Data<\/a>  \n- <a href='#2'>2. Catboost GPU <\/a> \n- <a href='#3'>3. Features importance<\/a>\n- <a href='#4'>4. Submission<\/a>","933ea83a":"# <a id='3'>3. Feature importance<\/a> "}}