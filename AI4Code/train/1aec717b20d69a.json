{"cell_type":{"56d0fd9f":"code","e2473456":"code","6c985a98":"code","b68e1975":"code","5a1a543d":"code","6cdf73d7":"code","5160b57c":"code","a52461fc":"code","e9cf4936":"code","7bab2478":"code","eeeca1ad":"code","0bdd2996":"markdown"},"source":{"56d0fd9f":"#importing libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics","e2473456":"#fetching data\nelec_cons = pd.read_csv(\"..\/input\/totalelectricconsumption\/total-electricity-consumption-us.csv\",  sep = ',', header= 0 )\nelec_cons.head()","6c985a98":"# number of observations: 51\nelec_cons.shape","b68e1975":"# checking NA\n# there are no missing values in the dataset\nelec_cons.isnull().values.any()","5a1a543d":"size = len(elec_cons.index)\nindex = range(0, size, 5)\n\ntrain = elec_cons[~elec_cons.index.isin(index)]\ntest = elec_cons[elec_cons.index.isin(index)]\n","6cdf73d7":"test","5160b57c":"print(len(train))\nprint(len(test))","a52461fc":"# converting X to a two dimensional array, as required by the learning algorithm\nX_train = train.Year.values.reshape(-1,1) #Making X two dimensional\ny_train = train.Consumption\n\nX_test = test.Year.values.reshape(-1,1) #Making X two dimensional\ny_test = test.Consumption","e9cf4936":"y_train","7bab2478":"# Doing a polynomial regression: Comparing linear, quadratic and cubic fits\n# Pipeline helps you associate two models or objects to be built sequentially with each other, \n# in this case, the objects are PolynomialFeatures() and LinearRegression()\n\nr2_train = []\nr2_test = []\ndegrees = [1, 2, 3]\n\nfor degree in degrees:\n    pipeline = Pipeline([('poly_features', PolynomialFeatures(degree=degree)),\n                     ('model', LinearRegression())])\n    pipeline.fit(X_train, y_train)\n    y_pred = pipeline.predict(X_test)\n    r2_test.append(metrics.r2_score(y_test, y_pred))\n    \n    # training performance\n    y_pred_train = pipeline.predict(X_train)\n    r2_train.append(metrics.r2_score(y_train, y_pred_train))\n    \n# plot predictions and actual values against year\n    fig, ax = plt.subplots()\n    ax.set_xlabel(\"Year\")                                \n    ax.set_ylabel(\"Power consumption\")\n    ax.set_title(\"Degree= \" + str(degree))\n    \n    # train data in blue\n    ax.scatter(X_train, y_train)\n    ax.plot(X_train, y_pred_train)\n    \n    # test data\n    ax.scatter(X_test, y_test)\n    ax.plot(X_test, y_pred)\n    \n    plt.show()","eeeca1ad":"# respective test r-squared scores of predictions\nprint(degrees)\nprint(r2_train)\nprint(r2_test)","0bdd2996":"# Generalised Regression\n\nIn this notebook, we will build a generalised regression model on the **electricity consumption** dataset. The dataset contains two variables - year and electricity consumption."}}