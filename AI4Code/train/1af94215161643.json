{"cell_type":{"1bd951f6":"code","b4a790a8":"code","895f9298":"code","2d731495":"code","23bca1f2":"code","6cd9d8bd":"code","d557911c":"code","eafed227":"code","b5adc113":"code","c2870d0d":"code","e9781263":"code","245ae222":"code","44841052":"markdown","be8f91e4":"markdown","50526677":"markdown","b3962dc6":"markdown","1181dcd8":"markdown","18e26875":"markdown","09f4b85a":"markdown","5749e8f5":"markdown","48e4de97":"markdown","442b378c":"markdown","c4e18444":"markdown","2e1c9100":"markdown","a6de0f36":"markdown"},"source":{"1bd951f6":"!pip install -q tensorflow-addons\n!pip install -q gdown","b4a790a8":"import gdown\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nfrom glob import glob\n\nfrom tensorflow_addons.layers import InstanceNormalization","895f9298":"input_image_size = (256, 256, 3)\n\nchosen_monet_file_id = \"1diLgk2a-snDTHI7_nbqjJjKEZR8kXjPQ\"\nphotos_zip_file_id = \"1HCYFybMEle_KQaL2KBKoOPjEVq2eA0dz\"\nmonet_generator_file_id = '1-HLVUS-OHe8qqM4pbymkdtlBUcULYxB_' #TODO CHANGE TO GOOD MODEL\n\nchosen_monet_filename = 'chosen_monet.tfrec'\nphotos_tfrec_folder_name = 'photo_tfrec'\nmonet_generator_filename = 'monet_generator_model.h5'","2d731495":"def local_download_files_from_drive(id, filename, isZip=False):\n    file_url = f\"https:\/\/drive.google.com\/uc?id={id}\"\n    ext = '.zip' if isZip else ''\n    gdown.download(file_url, filename+ext, quiet=True)\n    if isZip is True:\n        shutil.unpack_archive(filename+ext, extract_dir=filename)\n        os.remove(filename+ext)","23bca1f2":"# Download all remote files to local memory:\nlocal_download_files_from_drive(monet_generator_file_id, monet_generator_filename)\nlocal_download_files_from_drive(chosen_monet_file_id, chosen_monet_filename)\nlocal_download_files_from_drive(photos_zip_file_id, photos_tfrec_folder_name, isZip=True)","6cd9d8bd":"# Map values in the range [-1, 1]\ndef normalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return (img \/ 127.5) - 1.0\n\n# Map values in the range [0, 255]\ndef denormalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return tf.cast((img + 1.0) * 127.5, tf.uint8)\n    \ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = normalize_img(image)\n    image = tf.reshape(image, [*input_image_size])\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord)\n    return dataset\n\ndef visualize_dataset(dataset, rows, cols, images_normalized=True, imsize=3):\n    plt.figure(figsize=(cols*imsize,rows*imsize))\n    for i, im in enumerate(dataset.take(rows*cols)):\n        if images_normalized is True:\n            im = denormalize_img(im)\n        plt.subplot(rows, cols, i+1)\n        plt.imshow(im)\n        plt.axis(False)\n    plt.tight_layout()\n    plt.show()","d557911c":"filenames = glob(f\".\/{photos_tfrec_folder_name}\/*.tfrec\")\nphoto_dataset = load_dataset(filenames)\nvisualize_dataset(photo_dataset, rows=2, cols=6, images_normalized=True)","eafed227":"chosen_monet_dataset = load_dataset(chosen_monet_filename)\nvisualize_dataset(chosen_monet_dataset, rows=5, cols=6, images_normalized=True)","b5adc113":"class ReflectionPadding2D(tf.keras.layers.Layer):\n\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n\n    def call(self, input_tensor, mask=None):\n        padding_width, padding_height = self.padding\n        padding_tensor = [\n            [0, 0],\n            [padding_height, padding_height],\n            [padding_width, padding_width],\n            [0, 0],\n        ]\n        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'padding': self.padding\n        })\n        return config","c2870d0d":"monet_generator = tf.keras.models.load_model('.\/' + monet_generator_filename, compile=False, custom_objects={'ReflectionPadding2D': ReflectionPadding2D})","e9781263":"def visualize_predictions(model, images_dateset, rows, cols, imsize=3):\n    plt.figure(figsize=(cols*imsize, rows*imsize))\n    amount_to_show = rows*cols\n    for i, img in zip(range(1, amount_to_show, 2), images_dateset.take(amount_to_show).batch(1)):\n        input_img = denormalize_img(img[0]).numpy()\n        plt.subplot(rows, cols, i)\n        plt.title(\"Input image\")\n        plt.imshow(input_img)\n\n        prediction = model(img, training=False).numpy()\n        prediction = denormalize_img(prediction[0])\n        plt.subplot(rows, cols, i+1)\n        plt.title(\"Translated image\")\n        plt.imshow(prediction)\n\n    plt.tight_layout()\n    plt.show()\n\nvisualize_predictions(monet_generator, photo_dataset, rows=3, cols=6, imsize=4)","245ae222":"from tqdm import tqdm\nfrom PIL import Image\n!mkdir ..\/images\ni = 1\nfor img in tqdm(photo_dataset.batch(1)):\n    prediction = monet_generator.predict(img)\n    prediction = denormalize_img(prediction)\n    im = Image.fromarray(prediction[0].numpy())\n    im.save(\"..\/images\/\" + str(i) + \".jpg\")\n    i += 1\n\nshutil.make_archive(\"\/kaggle\/working\/images\", 'zip', \"\/kaggle\/images\")","44841052":"## Chosen Monet Files","be8f91e4":"# Load required libraries","50526677":"We must define the special reflection padding layer in order to load the model","b3962dc6":"## Download remote data","1181dcd8":"# Generate all the photos to monet images\n\nUsed for kaggle submissions","18e26875":"# **Deep Learning Inference Notebook**\n### Authors: Simon Raviv, Adam Gavriely\n##### Deep Learning Course BIU, 2021.\n---\n<br\/>\n\nIn this project we were asked to train a Cycle GAN that can transfer style from images painted by Monet to 'regular' images using only 30 monet images.\n\nThe training notebook was submitted to the [Kaggle competition](https:\/\/www.kaggle.com\/c\/gan-getting-started) which use MiFID metric to evaluate the model performance.  \nOur best MiFID score was : \n\nThis is the best results we achieved in this project timeframe, but there's a lot more that can be done to improve the time and performance of the model.\n","09f4b85a":"## Read the NON-Monet photos","5749e8f5":"# Read the data\n","48e4de97":"# Visualize predictions","442b378c":"# Load the model and visualize predictions","c4e18444":"As you can see we perform pretty well on nature images such as water, skies, mountains etc. and perform not quite as well on other stuff images e.g geometric objects, animals or people.\n\nWe believe this is due to the fact that Monet chose to focus the nature as his inpiration the vast majority of his paintings and you can see from our manually selected 30 monet images that we aimed to focus on that part of his paintings to make the learning of the model more focused.\n","2e1c9100":"# Global Parameters & Paths","a6de0f36":"## Utility functions for downloading, reading, parsing and visualizing the images"}}