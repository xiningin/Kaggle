{"cell_type":{"5361cbee":"code","93ce704b":"code","d19e9405":"code","49f0b89a":"code","b1467fe4":"code","d4c924fc":"code","a17f7b06":"code","a0a2d18b":"code","4515dd69":"code","f8934150":"code","527ad858":"code","288710d7":"code","05612ddc":"code","c88f1cd1":"code","af87ab7b":"code","b22fd1bb":"code","1abc4dda":"code","67e20dbe":"code","5fec952a":"code","6a8faaff":"code","1a5fceb7":"code","b827920c":"code","4cca70dd":"code","1787f95e":"code","a13d921a":"code","36e6eef8":"code","8fc47e6c":"code","647046e5":"code","f71e2b98":"code","7245cf09":"code","8706bd92":"code","b2aff6c1":"code","bf296d33":"code","0a3bbf60":"code","0c36366f":"code","c0a07a65":"code","bb5f8bc8":"code","766bda4a":"code","e6dd19f5":"code","0948fbb5":"code","dea4047d":"code","61f82b11":"code","3b09e77b":"code","93a0f0b2":"code","d79ee165":"code","8e7e19f0":"code","4a8c29ba":"code","82364567":"code","8341d57a":"code","d821932d":"code","dcae82e8":"code","3eb1a47f":"code","3c736507":"code","0371e6fe":"code","bcd92def":"code","50a8ff7a":"code","f481dcec":"code","fdf52dba":"code","f20c3501":"code","d149cbb0":"code","ceef10f7":"code","825b9e15":"code","e0c4bb03":"code","64c4ea78":"markdown","40d0e81a":"markdown","16e011bb":"markdown","ef4016d4":"markdown","f9ae22bf":"markdown","c83094e4":"markdown","f2450259":"markdown","efff6fbf":"markdown","8e4da21e":"markdown","1355ca19":"markdown","5214693c":"markdown","c846e3f1":"markdown","ed4bd963":"markdown","aa9b4ba0":"markdown","4832365a":"markdown","811db70f":"markdown","dcfd3a96":"markdown","b079afbb":"markdown"},"source":{"5361cbee":"import pandas as pd\nimport numpy as np","93ce704b":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","d19e9405":"train.isnull().sum()\nprint(\"Train Shape:\",train.shape)\ntest.isnull().sum()\nprint(\"Test Shape:\",test.shape)","49f0b89a":"train.info()","b1467fe4":"test.info()","d4c924fc":"train.head(10)","a17f7b06":"train.describe()","a0a2d18b":"test.describe()","4515dd69":"train.isnull().sum()","f8934150":"test.isnull().sum()\ntest[\"Survived\"] = \"\"\ntest.head()","527ad858":"import matplotlib.pyplot as plt # Plot the graphes\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","288710d7":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","05612ddc":"bar_chart('Sex')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Sex'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Sex'].value_counts())","c88f1cd1":"bar_chart('Pclass')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Pclass'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Pclass'].value_counts())","af87ab7b":"bar_chart('SibSp')\nprint(\"Survived :\\n\",train[train['Survived']==1]['SibSp'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['SibSp'].value_counts())","b22fd1bb":"bar_chart('Parch')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Parch'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Parch'].value_counts())","1abc4dda":"bar_chart('Embarked')\nprint(\"Survived :\\n\",train[train['Survived']==1]['Embarked'].value_counts())\nprint(\"Dead:\\n\",train[train['Survived']==0]['Embarked'].value_counts())","67e20dbe":"train.head()","5fec952a":"train.head(10)","6a8faaff":"train_test_data = [train,test] # combine dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","1a5fceb7":"train['Title'].value_counts()","b827920c":"test['Title'].value_counts()","4cca70dd":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset[\"Title\"].map(title_mapping)","1787f95e":"dataset.head()","a13d921a":"test.head()","36e6eef8":"bar_chart('Title')","8fc47e6c":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","647046e5":"train.head()","f71e2b98":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","7245cf09":"bar_chart('Sex')","8706bd92":"test.head()","b2aff6c1":"train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace= True)\ntest[\"Age\"].fillna(test.groupby('Title')['Age'].transform(\"median\"), inplace= True)","bf296d33":"train.head(30)\n#train.groupby(\"Title\")[\"Age\"].transform(\"median\")","0a3bbf60":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend() \nplt.show()\n\nfacet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend() \nplt.xlim(10,50)\n","0c36366f":"train.info()\ntest.info()","c0a07a65":"train.head()","bb5f8bc8":"Pclass1 = train[train['Pclass'] == 1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass'] == 2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass'] == 3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1,Pclass2,Pclass3])\ndf.index = ['1st Class','2nd Class','3rd Class']\ndf.plot(kind = 'bar', stacked =  True, figsize=(10,5))\nplt.show()\nprint(\"Pclass1:\\n\",Pclass1)\nprint(\"Pclass2:\\n\",Pclass2)\nprint(\"Pclass3:\\n\",Pclass3)","766bda4a":"for dataset in train_test_data:\n    dataset['Embarked'] =  dataset['Embarked'].fillna('S')","e6dd19f5":"train.head()","0948fbb5":"embarked_mapping = {'S':0,'C':1,'Q':2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","dea4047d":"# train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"])\n# train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace = True)\n# test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace = True)\n# train.head(50)\n\n\n# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(50)\n","61f82b11":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4 )\nfacet.map(sns.kdeplot, 'Fare', shade = True)\nfacet.set(xlim = (0, train['Fare'].max()))\nfacet.add_legend()\nplt.show()","3b09e77b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","93a0f0b2":"train.head()","d79ee165":"train.Cabin.value_counts()","8e7e19f0":"for dataset in train_test_data:\n    dataset['Cabin'] =  dataset['Cabin'].str[:1]","4a8c29ba":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","82364567":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","8341d57a":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","d821932d":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","dcae82e8":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","3eb1a47f":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","3c736507":"train.head()","0371e6fe":"features_drop = ['Ticket','SibSp','Parch']\ntrain = train.drop(features_drop, axis = 1)\ntest = test.drop(features_drop,axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","bcd92def":"train_data = train.drop('Survived', axis = 1)\ntarget = train['Survived']\ntrain_data.shape, target.shape","50a8ff7a":"train_data.head(10)","f481dcec":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","fdf52dba":"train.info()","f20c3501":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","d149cbb0":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","ceef10f7":"#learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nclf = [KNeighborsClassifier(n_neighbors = 13),DecisionTreeClassifier(),\n       RandomForestClassifier(n_estimators=13),GaussianNB(),SVC(),ExtraTreeClassifier(),\n      GradientBoostingClassifier(n_estimators=10, learning_rate=1,max_features=3, max_depth =3, random_state = 10),AdaBoostClassifier(),ExtraTreesClassifier()]\ndef model_fit():\n    scoring = 'accuracy'\n    for i in range(len(clf)):\n        score = cross_val_score(clf[i], train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n        print(\"Score of Model\",i,\":\",round(np.mean(score)*100,2))\n#     round(np.mean(score)*100,2)\n#     print(\"Score of :\\n\",score)\nmodel_fit()","825b9e15":"clf1 = SVC()\nclf1.fit(train_data, target)\ntest\ntest_data = test.drop(['Survived','PassengerId'], axis=1)\nprediction = clf1.predict(test_data)\n# test_data\n","e0c4bb03":"test_data['Survived'] = prediction\nsubmission = pd.DataFrame(test['PassengerId'],test_data['Survived'])\nsubmission.to_csv(\"Submission.csv\")","64c4ea78":"The Chart confirms a **person aboarded from C** slightly more likely survived.  \nThe Chart confirms a **person aboarded from Q** more likely dead.  \nThe Chart confirms a **person aboarded from S** more likely dead.  ","40d0e81a":"#### Title Map\n\nMr : 0   \nMiss : 1  \nMrs: 2  \nOthers: 3  ","16e011bb":"Those who were **20 to 30 years old** were **more dead and more survived.**","ef4016d4":"# Data Visualization using Matplotlib and Seaborn packages.","f9ae22bf":"**Binning**\n\nBinning\/Converting Numerical Age to Categorical Variable\n\nfeature vector map:\n* child: 0\n* young: 1\n* adult: 2\n* mid-age: 3\n* senior: 4","c83094e4":"## 4. Feature engineering","f2450259":"# 6.Cross Validation(k-fold)","efff6fbf":"Feature engineering is the process of using domain knowledge of the data\nto create features (**feature vectors**) that make machine learning algorithms work.  \n\nfeature vector is an n-dimensional vector of numerical features that represent some object.\nMany algorithms in machine learning require a numerical representation of objects,\nsince such representations facilitate processing and statistical analysis.","8e4da21e":"The Chart confirms a **person aboarded with more than 2 parents or children more likely survived.**  \nThe Chart confirms a **person aboarded alone more likely dead**","1355ca19":"# Bar Chart for Categorical Features \n\n* Pclass\n* Sex\n* SibSp ( # of siblings and spouse)\n* Parch ( # of parents and children)\n* Embarked\n* Cabin","5214693c":"<h2>Titanic Passanger Survival Analysis<\/h2>","c846e3f1":"more than 50 % of 1st class are from S embark.  \nmore than 50 % of 2st class are from S embark.   \nmore than 50 % of 3st class are from S embark.  \n\n**fill out missing embark with S embark**","ed4bd963":"The Chart confirms **1st class** more likely survivied than **other classes**.  \nThe Chart confirms **3rd class** more likely dead than **other classes**","aa9b4ba0":"### Data Dictionary\n\n* Survived: 0 = No, 1 = Yes\n* pclass: Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n* sibsp: # of siblings \/ spouses aboard the Titanic\n* parch: # of parents \/ children aboard the Titanic\n* ticket: Ticket number\n* cabin: Cabin number\n* embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n\n**Total rows and columns**\n\nWe can see that there are 891 rows and 12 columns in our training dataset.","4832365a":"The Chart confirms a **person aboarded with more than 2 siblings or spouse** more likely survived.  \nThe Chart confirms a **person aboarded without siblings or spouse** more likely dead","811db70f":"The Chart confirms **Women more likely survivied than Men**.","dcfd3a96":"# 5. Modelling","b079afbb":"**family Size**"}}