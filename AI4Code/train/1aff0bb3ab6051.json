{"cell_type":{"3882775d":"code","4997f93f":"code","7e1d7275":"code","55ae7a74":"code","87115cc8":"code","1d80ff10":"code","e120f6c6":"code","83aa9fee":"code","9308f0f4":"code","030c1fb7":"code","81b4ec86":"code","5138cbc6":"code","3373fcac":"code","73abc5ef":"code","7d2fccb4":"code","cf6ab795":"code","34099959":"code","99efb21e":"code","61dade28":"code","d34b7aad":"code","01ecbd4e":"code","be807dee":"code","6dbfeca5":"code","00c244e8":"code","19612dbf":"code","9f1791ca":"code","52535ee5":"code","36f6108b":"markdown","79140e8c":"markdown","8f14419b":"markdown","bf450dfb":"markdown","03696268":"markdown","8eb3e7ae":"markdown","72b3fa0a":"markdown","64a479ab":"markdown","724438dd":"markdown","3dc7e91e":"markdown","cbb52902":"markdown","b06cf9e1":"markdown","37b78209":"markdown","18e4a1d5":"markdown","6c409f4d":"markdown","f32b302e":"markdown","38f64f9a":"markdown","bfee504f":"markdown","67eed23c":"markdown","c0d713e4":"markdown","75fef50b":"markdown","3209f07c":"markdown"},"source":{"3882775d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pydicom\nfrom matplotlib import pyplot\nimport cv2 \nimport random\nimport os","4997f93f":"os.listdir('..\/input')","7e1d7275":"treino = pd.read_csv('..\/input\/stage_1_train_labels.csv')\npac = pd.read_csv('..\/input\/stage_1_detailed_class_info.csv')\nimg =[]\n                  \nfor pid in treino['patientId']:\n    DICOM = pydicom.read_file('..\/input\/stage_1_train_images\/{}.dcm'.format(pid))\n    img.append(DICOM)                 \n    ","55ae7a74":"pyplot.imshow(img[random.randrange(len(img))].pixel_array)","87115cc8":"pyplot.imshow(img[random.randrange(len(img))].pixel_array, cmap = 'gray')","1d80ff10":"numIm = [4,4]\nlista=[]\nlistaId=[]\nfor i in range(numIm[0]*numIm[1]):\n    lista.append(img[random.randrange(len(img))].pixel_array)\n    listaId.append(img[random.randrange(len(img))].PatientID)\n    \ngraf, loc= pyplot.subplots(numIm[0],numIm[1], figsize=(20,20))\ni=0\nfor lo in loc:\n    for l in lo:\n        l.imshow(lista[i])\n        i =i+1","e120f6c6":"positives = treino[treino['Target'] == 1]\nrand = random.randrange(len(positives))\ntempInfo = positives.iloc[rand]\nfor pid in img:\n    if(pid.PatientID == tempInfo.patientId):\n        temp = pid.pixel_array\n        t1 = pid.PatientID","83aa9fee":"graf, loc= pyplot.subplots(2, figsize=(20,20))\ntemp2 = temp.copy()\ntemp2=cv2.rectangle(temp2, (int(tempInfo['x']),int(tempInfo['y'])), (int(tempInfo['x']+tempInfo['width']), int(tempInfo['y']+tempInfo['height'])) , 255, 3)\nloc[0].imshow(temp2)\n\ntemp4 = temp2[  int(tempInfo['y']) : int(tempInfo['y']+tempInfo['height']+1), int(tempInfo['x']) : int(tempInfo['x']+tempInfo['width']+1) ]\nloc[1].imshow(temp4)\n","9308f0f4":"rand = random.randrange(len(positives))\ntempInfo = positives.iloc[rand]\nfor pid in img:\n    if(pid.PatientID == tempInfo.patientId):\n        temp = pid.pixel_array\n        t1 = pid.PatientID\n#temp with the marked place\ntempM = temp.copy()\ntempM=cv2.rectangle(tempM, (int(tempInfo['x']),int(tempInfo['y'])), (int(tempInfo['x']+tempInfo['width']), int(tempInfo['y']+tempInfo['height'])) , 255, 3)\n","030c1fb7":"kernel=(5,5)\ntemp2 = cv2.blur(temp, (kernel))\ntemp2 = cv2.blur(temp2, (kernel))\ntemp2 = cv2.blur(temp2, (kernel))\ntemp2 = cv2.blur(temp2, (kernel))\n\ngraf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM)\nloc[1].imshow(temp2)","81b4ec86":"kernel=(3,3)\ntemp2 =  cv2.GaussianBlur(temp,(kernel),0)\ntemp2 =  cv2.GaussianBlur(temp2,(kernel),0)\ntemp2 =  cv2.GaussianBlur(temp2,(kernel),0)\ntemp2 =  cv2.GaussianBlur(temp2,(kernel),0)\n\ngraf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM)\nloc[1].imshow(temp2)","5138cbc6":"temp2 = cv2.medianBlur(temp, 5)\ntemp2 = cv2.medianBlur(temp2, 5)\ntemp2 = cv2.medianBlur(temp2, 5)\ntemp2 = cv2.medianBlur(temp2, 5)\n\ngraf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM)\nloc[1].imshow(temp2)","3373fcac":"kernel =(5,5)\ntemp2 = cv2.erode(temp, (kernel),1)\ntemp2 = cv2.dilate(temp2, (kernel),1)\nfor i in range(50):\n    temp2 = cv2.erode(temp2, (kernel),1)\nfor i in range(50):\n    temp2 = cv2.dilate(temp2, (kernel),1)","73abc5ef":"graf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM)\nloc[1].imshow(temp2)","7d2fccb4":"kernel =(3,3)\ntemp2 = cv2.erode(temp, (kernel),1)\ntemp2 = cv2.erode(temp2, (kernel),1)\ntemp3 = cv2.dilate(temp, (kernel),1)\ntemp3 = cv2.dilate(temp3, (kernel),1)\ntemp2 = temp3-temp2\npyplot.figure(figsize=(15,15))\n\ntemp2=cv2.rectangle(temp2, (int(tempInfo['x']),int(tempInfo['y'])), (int(tempInfo['x']+tempInfo['width']), int(tempInfo['y']+tempInfo['height'])) , 255, 3)\npyplot.imshow(temp2)","cf6ab795":"temp2 =  cv2.GaussianBlur(temp,(5,5),0)\nret, temp2 = cv2.threshold(temp2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\ngraf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM)\nloc[1].imshow(temp2)","34099959":"ret, temp2 = cv2.threshold(temp2,175,255,cv2.THRESH_BINARY)\ngraf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM)\nloc[1].imshow(temp2)","99efb21e":"ret, temp2 = cv2.threshold(temp,70,1,1)\ngraf, loc= pyplot.subplots(1,2, figsize=(15,15))\nloc[0].imshow(tempM, cmap=\"gray\")\ntemp2=cv2.addWeighted(temp, 1.2, temp2, -50, 1.0)\nloc[1].imshow(temp2, cmap=\"gray\")","61dade28":"graf, loc= pyplot.subplots(1,3, figsize=(15,15))\nret, temp2 = cv2.threshold(temp,50,255,1)\nloc[0].imshow(tempM)\ntemp2 = temp-temp2\nloc[1].imshow(temp2)\nret, temp2 = cv2.threshold(temp2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nloc[2].imshow(temp2)","d34b7aad":"temp2= cv2.convertScaleAbs(temp, alpha=3, beta=-350)\ntemp3= cv2.convertScaleAbs(temp, alpha=5, beta=-700) \ntemp4= cv2.convertScaleAbs(temp, alpha=3.5, beta=-500)\n\ngraf, loc= pyplot.subplots(2,2, figsize=(15,15))\n\nloc[0,0].imshow(tempM, cmap='gray')\nloc[0,1].imshow(temp2, cmap='gray')\nloc[1,0].imshow(temp3, cmap='gray')\nloc[1,1].imshow(temp4, cmap='gray')\nloc[1,1].set_title('the selected values after some observation')","01ecbd4e":"rand = random.randrange(len(positives))\ntempInfo = positives.iloc[rand]\nfor pid in img:\n    if(pid.PatientID == tempInfo.patientId):\n        temp = pid.pixel_array\n        t1 = pid.PatientID","be807dee":"def density(imag, x,y, alt, larg):    \n    dLin=[0]*alt\n    dCol=[0]*larg\n    for col in range(larg):       \n        for row in range(alt):  \n            dLin[row] = imag[y+row, x+col] + dLin[row]\n            dCol[col] = imag[y+row, x+col] + dCol[col]  \n    return({'lin':dLin , 'col':dCol})          ","6dbfeca5":"temp2 = cv2.convertScaleAbs(temp, alpha=3.5, beta=-500)\nret = density(temp2, int(tempInfo['x']), int(tempInfo['y']),int(tempInfo['height']), int(tempInfo['width']) )\nret2= density(temp2, 0, 0, len(temp), len(temp) )\n\ngraf, loc= pyplot.subplots(3,2, figsize=(20,20))\nloc[0,0].barh(range(len(ret['lin'])),list(reversed(ret['lin'])))\nloc[0,0].set_title('Vertical density (roi)')\nloc[0,1].bar(range(len(ret['col'])),ret['col'])\nloc[0,1].set_title('Horizontal density (roi)')\nloc[2,0].barh(range(len(ret2['lin'])),list(reversed(ret2['lin'])))\nloc[2,0].set_title('Vertical density (whole image)')\nloc[2,1].bar(range(len(ret2['col'])),ret2['col'])\nloc[2,1].set_title('Horizontal density (whole image)')\nloc[1,0].imshow(temp2[  int(tempInfo['y']) : int(tempInfo['y']+tempInfo['height']+1), int(tempInfo['x']) : int(tempInfo['x']+tempInfo['width']+1) ],cmap='gray')\nloc[1,0].set_title('ROI')\nloc[1,1].imshow(temp2, cmap='gray')\nloc[1,1].set_title('whole image')","00c244e8":"graf, loc= pyplot.subplots(3,2, figsize=(20,20))\ntemp2 = temp.copy()\ntemp2=cv2.rectangle(temp2, (int(tempInfo['x']),int(tempInfo['y'])), (int(tempInfo['x']+tempInfo['width']), int(tempInfo['y']+tempInfo['height'])) , 255, 3)\nloc[0,0].imshow(temp2)\nloc[0,0].set_title('Original')\n\ntemp2= cv2.convertScaleAbs(temp, alpha=3.5, beta=-500)\ntemp2=cv2.rectangle(temp2, (int(tempInfo['x']),int(tempInfo['y'])), (int(tempInfo['x']+tempInfo['width']), int(tempInfo['y']+tempInfo['height'])) , 255, 3)\nloc[0,1].imshow(temp2)\nloc[0,1].set_title('Alfa\/Beta changes')\n\ntemp2 = cv2.medianBlur(temp, 5)\ntemp2 = cv2.medianBlur(temp2, 5)\ntemp2 = cv2.medianBlur(temp2, 5)\ntemp2= cv2.convertScaleAbs(temp2, alpha=3.5, beta=-500)\ntemp2=cv2.rectangle(temp2, (int(tempInfo['x']),int(tempInfo['y'])), (int(tempInfo['x']+tempInfo['width']), int(tempInfo['y']+tempInfo['height'])) , 255, 3)\nloc[1,0].imshow(temp2)\nloc[1,0].set_title('Alfa\/Beta + blur')\n\ntemp3 = cv2.resize(temp, (64,64))\ntemp3= cv2.convertScaleAbs(temp3, alpha=3.5, beta=-500)\nloc[1,1].imshow(temp3)\nloc[1,1].set_title('Alfa\/Beta + resize')\n\ntemp4 = temp2[  int(tempInfo['y']) : int(tempInfo['y']+tempInfo['height']+1), int(tempInfo['x']) : int(tempInfo['x']+tempInfo['width']+1) ]\nloc[2,0].imshow(temp4)\nloc[2,0].set_title('Alfa\/Beta + blur on ROI')\n\ntemp5= cv2.resize(temp4, (32,32))\nloc[2,1].imshow(temp5)\nloc[2,1].set_title('Alfa\/Beta + resize on ROI')","19612dbf":"negatives = treino[treino['Target'] == 0]\nrand = random.randrange(len(negatives))\ntempInfoN = negatives.iloc[rand]\nfor pid in img:\n    if(pid.PatientID == tempInfoN.patientId):\n        tempN = pid.pixel_array\n        t1 = pid.PatientID\n        \ntempN = cv2.convertScaleAbs(tempN, alpha=3.5, beta=-500)","9f1791ca":"rand = random.randrange(len(positives))\ntempInfo = positives.iloc[rand]\nfor pid in img:\n    if(pid.PatientID == tempInfo.patientId):\n        temp = pid.pixel_array\n        t1 = pid.PatientID\ntemp = cv2.convertScaleAbs(temp, alpha=3.5, beta=-500)","52535ee5":"graf, loc= pyplot.subplots( 2 , figsize=(15,15))\n\ntemp = temp[int(tempInfo['y']) : int(tempInfo['y']+tempInfo['height']+1), int(tempInfo['x']) : int(tempInfo['x']+tempInfo['width']+1)]\ntemp = cv2.resize(temp, (32,32))\n\nloc[0].imshow(temp)\nloc[0].set_title('random positive sample')\ntam = 1024 - 32\n\nx= random.randrange(tam)\ny= random.randrange(tam)\n\nloc[1].imshow(tempN[y:y+32 , x:x+32] )       \nloc[1].set_title('random negative sample')","36f6108b":"Again, I am not convinced that it might help, specially since \"fog\" and the bones have a very close color and they end up together","79140e8c":"Visualizing...","8f14419b":"Perhaps some erode\/dilatations  (operations sometimes good to extract features)?","bf450dfb":"Kind hard to evaluate, but at a closer look, also seems be hard to diferentiate between the diferent fogs","03696268":"Can't say much from just that, so let's get a positive image and see what a \"pneumonia region\" looks like\n","8eb3e7ae":"To have a broader sample, let's get more images together.\n\n*Obs: The images on this notebook are randomly selected, so if you want more samples, just re-run the code lines*","72b3fa0a":" So let's try some transformations and see what happens. \n \n \n First, applying some blur filters (there are 3 types)\n","64a479ab":"After some attempts, I figured that not only it is possible to reduce the image size without losing too much information (in this case, the \"fog\" still kind of looks likes an amoeba, what is a must to gain efficiency.\n\nSo, let's compare with some random negative data to see if they are really diferent and might be good subjects to a ml model\n","724438dd":" Can't see anything new from that.","3dc7e91e":"hmm... I can see that it is foggy, but can't really differentiate from any other \"foggy part\".\n\nSo, still no ideia on how to approach this.   I also don't know how doctors classify penumonia,  so I can only try to play with the information at hand \n","cbb52902":"And some changes to the alfa e beta changes, trying to increasing the contrast","b06cf9e1":"Now it seems to be a better solution. Increasing the contrast exposes a lot more (at least visually) the \"fog\". \n\nIf we start from here and try to extract the features, we might have good results. So let's define a kernel to use to train the future ml model","37b78209":"By the way, you can change the way the image is read including a maping option to make it looks more like a x-ray:","18e4a1d5":"<h1>Hello everyone!<\/h1>\nIn this notebook, I will show a bit of my fun... i mean, work with the DICOM imagens and how I have analised them in order to try to extract better samples for a future training (probably a ConvNet)\n\nIt is a step by step of what I was thinking at the time, so it goes to some dead ends and not necessarily leads to the best solution, but I hope that it might be usefull to compare different lines of thought and perhaps give you a few ideas on how to approach this matter.\n(Feel free to comment on yours thoughts on it as well)\n","6c409f4d":"Overall, the positive samples are more \"granulated\" than the negatives ones.\nSeems promissing!\n\nNow, all that is left to do is test this concept and see if we can train something from this.\n\n<hr>\n I hope that this might have been usefull to you.\n Please excuse any language mistakes and feel free to share your toughts\/tips on this notebook as well!","f32b302e":"Now some thresholding","38f64f9a":"Now let's set up the data and see what we are dealing with:","bfee504f":"No ideia if the density might be significative, hehe. \n\nBut I am starating to think that  the \"pneumonia fog\" have a shape that is closer to a \"amoeba\"  (with some \"little arms\" on the edges) than a random fog, what gives a insteresting pattern to work with.\n\nAll that is left is to find the a way to extract this information from the image","67eed23c":"First, let's check if the image has anything significant in the density distribution","c0d713e4":"Using some image oparations ( dilateded minus eroded image) to extract the borders","75fef50b":"So let's start. I am using these libraries, with special mention to OpenCV","3209f07c":"It seems pretty interesting to \"reduce\" the bones over the lungs, leaving a higher density on places that had some \"fog\" previously, but I am not convinced that it will help to diferentiation between \"non-pneumonia\" and \"pneumonia\" fogs, so I will try other things"}}