{"cell_type":{"418ca3cb":"code","5cde6e7e":"code","eb3c7965":"code","c25370cf":"code","091c119a":"code","0c18d78d":"code","13b4f89b":"code","bdea3bc8":"code","c305417e":"code","a353594c":"code","79bb401a":"code","9ba3dc20":"code","1ba9c6c3":"code","dcce4bbc":"code","2820590c":"code","e28d8d93":"code","b833ad40":"code","0987094e":"code","a772a57e":"code","d880a6d3":"code","30731a7e":"code","7593ee31":"code","e00b6909":"code","7fe9fe3a":"code","73aae44f":"code","32a3eb1e":"code","d8ef1199":"code","9648384c":"code","0b91b471":"markdown","4b80572a":"markdown","820f5a79":"markdown","43212859":"markdown","700ac1b5":"markdown","2a789e5f":"markdown","db3cc12a":"markdown","f174f056":"markdown","ebb577c8":"markdown","3a1e9489":"markdown","446d325c":"markdown","dee6fe3e":"markdown","1c5cf179":"markdown","0e659966":"markdown","92df604c":"markdown","30d6b206":"markdown","0f8b0b9e":"markdown","578a5245":"markdown"},"source":{"418ca3cb":"from random import randint\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","5cde6e7e":"data_directory = os.path.join(os.getcwd(), '..\/input')\nprint(os.listdir(data_directory))","eb3c7965":"!cat '..\/input\/readme.txt'","c25370cf":"data_dictionnary = {}\n\noperational_settings = ['op_setting_{}'.format(i + 1) for i in range (3)]\nsensor_columns = ['sensor_{}'.format(i + 1) for i in range(27)]\nfeatures = operational_settings + sensor_columns\nmetadata = ['engine_no', 'time_in_cycles']\nlist_columns = metadata + features\n\n\nlist_file_train = [x for x in sorted(os.listdir(data_directory)) if 'train' in x]\n\nfor file_train in list_file_train:\n    data_set_name = file_train.replace('train_', '').replace('.txt', '')\n    file_test = 'test_' + data_set_name + '.txt'\n    rul_test = 'RUL_' + data_set_name + '.txt'\n    \n    data_dictionnary[data_set_name] = {\n        'df_train': pd.read_csv(os.path.join(data_directory, file_train), sep=' ', header=-1, names=list_columns),\n        'df_test': pd.read_csv(os.path.join(data_directory, file_test), sep=' ', header=-1, names=list_columns),\n        'RUL_test' :pd.read_csv(os.path.join(data_directory, rul_test), header=-1, names=['RUL']),\n    }","091c119a":"def add_rul(g):\n    g['RUL'] = [max(g['time_in_cycles'])] * len(g)\n    g['RUL'] = g['RUL'] - g['time_in_cycles']\n    del g['engine_no']\n    return g.reset_index()\n\nfor data_set in data_dictionnary:\n    data_dictionnary[data_set]['df_train'] = data_dictionnary[data_set]['df_train']\\\n                        .groupby('engine_no').apply(add_rul).reset_index()\n    del data_dictionnary[data_set]['df_train']['level_1']","0c18d78d":"CHOSEN_DATASET = 'FD001'\n\ndf = data_dictionnary[CHOSEN_DATASET]['df_train'].copy()\n\ndf_eval = data_dictionnary[CHOSEN_DATASET]['df_test'].copy()","13b4f89b":"dataset_description = df.describe()\ndataset_description","bdea3bc8":"axes = dataset_description.T.plot.bar(subplots=True, figsize=(15,10))","c305417e":"###############< ??? >###############\n# What can you conclude from the graph above?","a353594c":"df_plot = df.copy()[features]\ndf_corr = df_plot.corr(method='pearson')\nfig, ax = plt.subplots(figsize=(15,15))\naxes = sns.heatmap(df_corr, linewidths=.2, )","79bb401a":"###############< ??? >###############\n# Can you plot a correlation matrix with another correlation coeficient?","9ba3dc20":"###############< ??? >###############\n# What can append when you have correlated features?","1ba9c6c3":"nan_column = df.columns[df.isna().any()].tolist()\nconst_columns = [c for c in df.columns if len(df[c].drop_duplicates()) <= 2]\nprint('Columns with all nan: \\n' + str(nan_column) + '\\n')\nprint('Columns with all const values: \\n' + str(const_columns) + '\\n')","dcce4bbc":"###############< ??? >###############\n# Can you find all the couples that are strongly correlated ?","2820590c":"df_plot = df.copy()\ndf_plot = df_plot.sort_values(metadata)\ngraph = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=features, hue=\"engine_no\", height=4, aspect=6,)\ngraph = graph.map(plt.plot, alpha=0.5)\ngraph = graph.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))\n# graph = graph.add_legend()","e28d8d93":"###############< ??? >###############\n# What can you see from the graphs above?","b833ad40":"###############< ??? >###############\n# Is is better to train on a smaller part?","0987094e":"number_of_engine_no = len(df['engine_no'].drop_duplicates())\n\nengine_no_val = range(50, 70)\nengine_no_train = [x for x in range(number_of_engine_no) if x not in engine_no_val]","a772a57e":"selected_features = [x for x in features if x not in nan_column + const_columns]","d880a6d3":"data_train = df[df['engine_no'].isin(engine_no_train)]\ndata_val = df[df['engine_no'].isin(engine_no_val)]\n\nX_train, y_train = data_train[selected_features], data_train['RUL'] \nX_val, y_val = data_val[selected_features], data_val['RUL']\n\nX_eval = df_eval[selected_features]\n\n\nX_all, y_all = df[selected_features], df['RUL']","30731a7e":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor()\nrf_reg.fit(X_train, y_train)","7593ee31":"print(\"Score on train data : \" + str(rf_reg.score(X_train, y_train)))\nprint(\"Score on test data : \" + str(rf_reg.score(X_val, y_val)))","e00b6909":"###############< ??? >###############\n# Did you overfit?","7fe9fe3a":"###############< ??? >###############\n# Can you have the RMSE?","73aae44f":"###############< ??? >###############\n# Try to improve you model.","32a3eb1e":"df_pred = data_train.copy()\ndf_pred['pred'] = rf_reg.predict(X_train)\ndf_pred['error'] = df_pred['pred'] - df_pred['RUL']","d8ef1199":"df_plot = df_pred.copy()\ndf_plot = df_plot.sort_values(['engine_no', 'time_in_cycles'])\ng = sns.PairGrid(data=df_plot, x_vars=\"RUL\", y_vars=['RUL', 'pred', 'error'], hue=\"engine_no\", height=6, aspect=6,)\ng = g.map(plt.plot, alpha=0.5)\ng = g.set(xlim=(df_plot['RUL'].max(),df_plot['RUL'].min()))","9648384c":"df_eval['pred'] = rf_reg.predict(X_eval)\n\ndf_eval['result'] = df_eval['pred']\ndf_eval['engine_id'] = list(range(len(df_eval)))\n\ndf_eval[['engine_id','result']].to_csv('submission.csv', index=False)","0b91b471":"### Splitting test \/ train data","4b80572a":"# Prediction on test data and Output","820f5a79":"# Making a prediction","43212859":"# Imports","700ac1b5":"# List data directory","2a789e5f":"### Training a random forest","db3cc12a":"# Chosing a dataset ","f174f056":"# Load DATA","ebb577c8":"### Actually making the split","3a1e9489":"### Plotting some description of the dataset","446d325c":"### Plotting the result ","dee6fe3e":"# Data analysis","1c5cf179":"### Selecting only relevant features","0e659966":"### Plot a temporal vizualisation of the features","92df604c":"### Find columns that can be droped ","30d6b206":"# Add RUL","0f8b0b9e":"### Score the model ","578a5245":"### Correlation matrix"}}