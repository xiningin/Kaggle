{"cell_type":{"253df723":"code","f98b7d05":"code","28882c5d":"code","91b168a3":"code","2529245b":"code","1f94dd17":"code","acafd083":"code","4b291de0":"code","d2a7f402":"code","0493da64":"code","7557a708":"code","81d98744":"code","662dcf1c":"code","0758f0f1":"code","2bcde170":"code","ec56b54e":"code","3a1c6a5e":"code","91379f3f":"code","beab1b69":"code","26f29bfe":"code","c88039fb":"code","fa1b635d":"code","c2b624b9":"code","d3b9fbce":"code","22d9510b":"code","08b5775c":"code","11f75322":"code","8636f11b":"code","a849df28":"code","d4a62ba9":"code","a10b3aa4":"code","91de2135":"code","36e2717d":"code","662e3aaa":"code","bb5ded48":"code","8823d653":"code","50d0a881":"code","2650f4c9":"code","87d748f8":"code","69e5ca1f":"markdown","dc0d97a3":"markdown","2a01f0fd":"markdown","be2417a9":"markdown","3cd32ccc":"markdown","4fa6a763":"markdown","9c10b579":"markdown","da0e82e4":"markdown","684ab29d":"markdown","a13c0f40":"markdown","eda1b0e2":"markdown","6a2216dc":"markdown","2f80950a":"markdown","24beece2":"markdown","c1fa916e":"markdown","8adfb748":"markdown","b9c0af78":"markdown"},"source":{"253df723":"import pandas as pd\nimport numpy as np\nimport math\nimport time\nimport os\nfrom skimage import io, transform\nimport PIL","f98b7d05":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torchvision import datasets, transforms, models\n\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ExponentialLR\nfrom torch.utils.data import Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler","28882c5d":"# Config\ndata_dir = '..\/input\/petfinder-pawpularity-score\/'\nmodel_dir = '..\/input\/resnet50-pretrained-model\/'\nworking_dir = '.\/'\nglobal_batch_size = 64\nworkers = 2\nnp.random.seed(10)\nprint(os.listdir(data_dir))\nprint(os.listdir(f'{data_dir}train')[0:4])","91b168a3":"train_df = pd.read_csv(f'{data_dir}train.csv')","2529245b":"train_df.head()","1f94dd17":"train_df.info()","acafd083":"# Annotations\nnp.array(train_df.iloc[2, 1:13])","4b291de0":"# Scores\ntrain_df.iloc[2, 13]","d2a7f402":"n, bins, patches = plt.hist(train_df.iloc[:, 13], 50, density=True, facecolor='g', alpha=0.75)\n\nplt.xlabel('Pawpularity')\nplt.ylabel('Frequency')\nplt.title('Pawpularity Histogram')\nplt.xlim(0, 100)\n# plt.ylim(0, 0.03)\nplt.grid(True)\nplt.show()","0493da64":"class PawpularityDataset(Dataset):\n    \"\"\"Dataset connecting animal images to the score and annotations\"\"\"\n\n    def __init__(self, csv_file, img_dir, transform=transforms.ToTensor()):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            img_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n\n        self.annotations_csv = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations_csv)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.img_dir,\n                                self.annotations_csv.iloc[idx, 0])\n\n        # load each image in PIL format for compatibility with transforms\n        image = PIL.Image.open(img_name + '.jpg')\n        \n        # Columns 1 to 12 contain the annotations\n        annotations = np.array(self.annotations_csv.iloc[idx, 1:13])\n        annotations = annotations.astype('float')\n        # Column 13 has the scores\n        score = np.array(self.annotations_csv.iloc[idx, 13])\n        score = torch.tensor(score.astype('float')).view(1).to(torch.float32)\n\n        # Apply the transforms\n        image = self.transform(image)\n\n        sample = [image, annotations, score]\n        return sample","7557a708":"# Test out the transforms on an image (images need to be made the same size for the dataset to work)\n# Apply some image augmentation on the training set (rotation, flip)\n# Normalize using imagenet RGB mean and std\n\nimg_transforms = transforms.Compose([transforms.Resize(255),\n                                     transforms.CenterCrop(224),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.RandomRotation(20),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                          std=[0.229, 0.224, 0.225])])\n\nimg_transforms_valid = transforms.Compose([transforms.Resize(255),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                std=[0.229, 0.224, 0.225])])","81d98744":"## Load and set up the final training and validation dataset (use different transforms)\n\ntrain_data = PawpularityDataset(f'{data_dir}train.csv', f'{data_dir}train', transform=img_transforms)\nvalid_data = PawpularityDataset(f'{data_dir}train.csv', f'{data_dir}train', transform=img_transforms_valid)\n\nnp.random.seed(13)\n\n# obtain random indices that will be used for traingin\/validation split\nvalid_size = 0.1\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=global_batch_size,\n                                           sampler=train_sampler, num_workers=workers,\n                                           pin_memory=True) \n# sample the validation dataset from a separate dataset the doesn't include the image aug transformations.\nvalid_loader = torch.utils.data.DataLoader(valid_data, batch_size=global_batch_size,\n                                           sampler=valid_sampler, num_workers=workers,\n                                           pin_memory=True) \n\nprint(len(train_loader)*global_batch_size)\nprint(len(valid_loader)*global_batch_size)","662dcf1c":"# Batch size of 8\nimages, annotations, scores = next(iter(train_loader))\nprint(images.shape)\nprint(scores.shape)\nprint(annotations.shape)","0758f0f1":"# Helper function to unnormalize and plot images\ndef im_convert(tensor):\n    \"\"\" Display a tensor as an image. \"\"\"\n    \n    image = tensor.to(\"cpu\").clone().detach()\n    image = image.numpy().squeeze()\n    image = image * np.array((0.229, 0.224, 0.225)).reshape(3, 1, 1) + np.array((0.485, 0.456, 0.406)).reshape(3, 1, 1)\n    img = (image * 255).astype(np.uint8) # unnormalize\n    \n\n    return plt.imshow(np.transpose(img, (1, 2, 0)))","2bcde170":"im_numpy = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(20, 10))\n# display 20 images\nfor idx in np.arange(8):\n    ax = fig.add_subplot(2, 4, idx+1, xticks=[], yticks=[])\n    im_convert(images[idx])\n    ax.set_title(scores[idx].item())","ec56b54e":"import torch.nn as nn\nimport torch.nn.functional as func\nimport torch.optim as optim","3a1c6a5e":"# model = models.resnet50(pretrained=True)\n# torch.save(model, 'resnet50_pretrained.pt')","91379f3f":"# Load the pretrained resnet50\nmodel = torch.load(f'{model_dir}resnet50_pretrained.pt')\n\n# Disable gradients on all model parameters to freeze the weights\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace the final fully connected resnet layer with a 2 fc layer network and sigmoid output\nmodel.fc = nn.Sequential(nn.Linear(2048, 256),\n                         nn.ReLU(),\n                         nn.Linear(256, 1),\n                         nn.Sigmoid())\n\nfor param in model.fc.parameters():\n    param.requires_grad = True\n    \n# Unfreeze the last few layers of the model\n\nfor param in model.layer4.parameters():\n    param.requires_grad = True","beab1b69":"print(model)","26f29bfe":"torch.manual_seed(13)\n\ncriterion = nn.MSELoss(reduction='sum')\n\n#Adam with L2 regularization\noptimizer = optim.AdamW(model.parameters(), lr=0.000025, weight_decay=50)\n\n# Learning rate decay\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [1, 2, 6], gamma=0.5)","c88039fb":"# Test out the forward pass on a single batch\n\nimages, annotations, scores = next(iter(train_loader))\nwith torch.no_grad():\n    train_loss = 0.0\n    output = model(images)*100 # convert sigmoid output to pawpularity scale\n    loss = criterion(output, scores)\n    math.sqrt(loss.item()\/global_batch_size)\n\nprint(scores.dtype)\nprint(output.dtype)\nprint('Starting RMSE: ', torch.mean(output))\nprint('Prediction Standard Deviation: ', torch.std(output))","fa1b635d":"# check if CUDA is available and set the training device\n\ntrain_on_gpu = torch.cuda.is_available()\ndevice = torch.cuda.get_device_name()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print(f'CUDA is available!  Training on GPU {device}...')","c2b624b9":"# Training and validation loop\n\nif train_on_gpu:\n    model.cuda()\n\nn_epochs = 10\n\nvalid_loss_min = np.Inf # track change in validation loss\n\ntrain_losses, valid_losses = [], []\n\nfor epoch in range(1, n_epochs+1):\n    \n    start = time.time()\n    current_lr = scheduler.get_last_lr()[0]\n    \n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    # Stop training the convolutional layers after a certain point\n    if epoch > 3:\n        for param in model.layer4.parameters():\n            param.requires_grad = False\n    \n    ###################\n    # train the model #\n    ###################\n    # put in training mode (enable dropout)\n    model.train()\n    for images, annotations, scores in train_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(images)*100 # multiply by 100 the sigmoid output to 0-100 pawpularity scale\n        # print(output.dtype)\n        # print(scores.dtype)\n        # calculate the batch loss\n        loss = criterion(output, scores)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()\n        \n    ######################    \n    # validate the model #\n    ######################\n    # eval mode (no dropout)\n    model.eval()\n    with torch.no_grad():\n        for images, annotations, scores in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if train_on_gpu:\n                images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(images)*100 # multiply by 100 the sigmoid output to 0-100 pawpularity scale\n            # calculate the batch loss\n            loss = criterion(output, scores)\n            # update average validation loss \n            valid_loss += loss.item()\n    \n    # calculate RMSE\n    train_loss = math.sqrt(train_loss\/len(train_loader.sampler))\n    valid_loss = math.sqrt(valid_loss\/len(valid_loader.sampler))\n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # increment learning rate decay\n    scheduler.step()\n    \n    # print training\/validation statistics \n    # print(f'Epoch: {e}, {float(time.time() - start):.3f} seconds, lr={optimizer.lr}')\n    print('Epoch: {}, time: {:.1f}s, lr: {:.7f} \\tTraining Loss: {:.3f} \\tValidation Loss: {:.3f}'.format(\n        epoch, float(time.time() - start), current_lr, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.3f} --> {:.3f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), f'{working_dir}pawpularity_best_model.pt')\n        valid_loss_min = valid_loss    ","d3b9fbce":"# Load the best performing model on the validation set\nmodel.load_state_dict(torch.load(f'{working_dir}pawpularity_best_model.pt'))","22d9510b":"# get the distribution of predictions\n\npredictions = []\nscore_list = []\n\nmodel.eval()\nwith torch.no_grad():\n    for images, annotations, scores in valid_loader:\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            images, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(images)*100\n        predictions.extend(list(output.cpu().detach().numpy().reshape(len(output),)))\n        score_list.extend(list(scores.cpu().detach().numpy().reshape(len(scores),)))\n        \n\npreds_df = pd.DataFrame({'preds': predictions})\npreds_df.describe()","08b5775c":"# Manually Check RMSE\n\ndiffs = np.array(score_list) - np.array(predictions)\nprint(math.sqrt((diffs @ diffs)\/len(valid_loader.sampler)))\n","11f75322":"# Check that manually increasing the variance doesn't help\n\nmean = np.mean(np.array(predictions))\nstddev = np.std((np.array(predictions)))\nprint(mean, stddev)\nupdated_normalized = 1.5*(predictions-mean)\/stddev\nnew_predictions = updated_normalized+predictions\n\ndiffs = np.array(score_list) - np.array(new_predictions)\nprint(math.sqrt((diffs @ diffs)\/len(valid_loader.sampler)))","8636f11b":"# Histogram of validation predictions - if this is too narrow that's an issue\n\nn, bins, patches = plt.hist(predictions, 50, density=True, facecolor='g', alpha=0.75)\n\nplt.xlabel('Pawpularity')\nplt.ylabel('Frequency')\nplt.title('Predicted Pawpularity Histogram')\nplt.xlim(0, 100)\nplt.ylim(0, .2)\nplt.grid(True)\nplt.show()","a849df28":"# Histogram of validation set actual scores\n\nn, bins, patches = plt.hist(train_df.iloc[valid_idx, 13], 50, density=True, facecolor='g', alpha=0.75)\n\nplt.xlabel('Pawpularity')\nplt.ylabel('Frequency')\nplt.title('Actual Pawpularity Histogram')\nplt.xlim(0, 100)\nplt.ylim(0, .2)\nplt.grid(True)\nplt.show()","d4a62ba9":"# Plot the losses\nfig = plt.figure()\nax = plt.axes()\nax.plot(list(range(1, len(train_losses))), train_losses[1:])\nax.plot(list(range(1, len(valid_losses))), valid_losses[1:]);\nprint(f'best score: {valid_loss_min}')","a10b3aa4":"images, annotations, scores = next(iter(valid_loader))\nimages, annotations, scores = images.cuda(), annotations.cuda(), scores.cuda()","91de2135":"output_plot = model(images).cpu()*100\nimages, annotations, scores = images.cpu(), annotations.cpu(), scores.cpu()","36e2717d":"# plot the images in the batch, along with the corresponding labels and predictions\n\nfig = plt.figure(figsize=(20, 10))\n# display 20 images\nfor idx in np.arange(12):\n    ax = fig.add_subplot(3, 4, idx+1, xticks=[], yticks=[])\n    im_convert(images[idx])\n    ax.set_title(f'Act: {round(scores[idx].item())} Pred: {round(output_plot[idx].item())}')","662e3aaa":"test_df = pd.read_csv(f'{data_dir}test.csv')\ntest_df.head(10)","bb5ded48":"# Load the best performing model on the validation set\nmodel.load_state_dict(torch.load('pawpularity_best_model.pt'))","8823d653":"class PawpularityTestDataset(Dataset):\n    \"\"\"Dataset connecting dog images to the score and annotations\"\"\"\n\n    def __init__(self, csv_file, img_dir, transform=transforms.ToTensor()):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            img_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n\n        self.annotations_csv = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations_csv)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.img_dir,\n                                self.annotations_csv.iloc[idx, 0])\n\n        # load each image in PIL format for compatibility with transforms\n        image = PIL.Image.open(img_name + '.jpg')\n\n        annotations = np.array(self.annotations_csv.iloc[idx, 1:13])\n        annotations = annotations.astype('float')\n\n        # Apply the transforms\n        image = self.transform(image)\n\n        sample = [image, annotations]\n        return sample","50d0a881":"## Load the test dataset (careful to use validation transforms without img augmentation)\n\ntest_data = PawpularityTestDataset(f'{data_dir}test.csv', f'{data_dir}test', transform=img_transforms_valid)\n\nbatch_size = min(len(test_data), global_batch_size)\n\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=workers) ","2650f4c9":"# Step through with a reasonable batch size and build up the output dataset\n\nmodel.eval()\noutputs = []\nfor images, annotations in test_loader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n        images, annotations = images.cuda(), annotations.cuda()\n    test_output = model(images)*100\n    outputs.extend(list(test_output.cpu().detach().numpy().reshape(len(test_output),)))\n    \nimg_names = list( test_df.iloc[:, 0].values)\noutputs = [round(x, 2) for x in outputs]\n\noutput_df = pd.DataFrame({'Id': img_names, 'Pawpularity': outputs})\noutput_df.head(10)","87d748f8":"# Write the output in the required format\noutput_df.to_csv('submission.csv', index=False)","69e5ca1f":"### Load Dependencies","dc0d97a3":"**Load the model, replace the output layer, and choose which layers to freeze\/train**","2a01f0fd":"**Model training loop**\n\nRun the training and validation steps for a fixed number of epochs, and save the model anytime the validation loss decreases.  ","be2417a9":"The range could still be a greater, and the model is failing completely at predicting the highest ranked images that get a score of 100.  That said, it is producing a much higher range of predictions than the and feels like it would give useful information to users submitting photos.  ","3cd32ccc":"**Define global image transforms**","4fa6a763":"### Train the model","9c10b579":"**Custom dataset class to attach annotations and scores to the images**\n\nThis is a critical step to attach the classes and annotations to the image files and allow this to be put into a pytorch dataloader.  ","da0e82e4":"**Look at the annotations**","684ab29d":"### Show examples of images and predicted vs. actual scores","a13c0f40":"### Set up the model structure","eda1b0e2":"**Look at some images**","6a2216dc":"## Pawpularity Transfer Learning Approach in Pytorch\n\nThis notebook implements a resnet50 architecture with pre-trained weights, replacing the final layer and re-training the last convlutional layer set to predict a pawpularity score bounded between 0 and 100.  Everything is implemented from scratch in pytorch.  \n\n\n- A custom pytorch dataset class is implemented to attach scores to each image file, as well as the annotations.  Currently only the images are being used to train the model.  \n- The model is a resnet50 architectur where the final fully connected layer is replaced with two fully connected layers and output 1 value.\n- The model starts with pretrained weights for all of the convolutional layers, and the final set of layers in the model (layer4) is unfrozen to allow it to learn a feature representation more specifi to this task.  Training refreezes layer4 after 4 epochs and continues to only train the fully connected layers after that to reduce overfitting.  \n- The final activation is sigmoid to bound the output between 1 and 0, and output is multiplied by 100 in the training loop to give it a bounded output between 0 and 100 which matches the range of pawpularity scores.  \n- The model is optimising for mean squared error(MSE), using Adam with weight decay to reduce overfitting.\n- The final competition evaluation metric is the square root of MSE or \n$ \\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $\n","2f80950a":"**Downloading the pretrained model**\n\nTo access the pretrained model in a kaggle notebook, download it via pytorch on a local notebook, save the model using torch.save.  Then upload it to your kaggle notebook as a dataset which you can then load via torch.load without having to connect to the internet.","24beece2":"**Load and check out the datasets**","c1fa916e":"### Diagnostics and performance","8adfb748":"### Use the model to predict the test dataset","b9c0af78":"### Load and Explore data"}}