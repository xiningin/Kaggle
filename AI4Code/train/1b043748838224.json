{"cell_type":{"3b76bca3":"code","effc7077":"code","55442d73":"code","ca132585":"code","40db86f4":"code","fb430f89":"code","f48aae4f":"code","6a893a5e":"code","ae6d515a":"code","212d6bab":"code","b74b56db":"code","424601c1":"code","927c37da":"code","07f51145":"code","3c6543e9":"code","c2a5172b":"code","7159c477":"code","4b28cd45":"code","6617a7ea":"code","0bf1bbb2":"code","1dc62876":"code","00dbd630":"code","bdb017de":"code","f05ea6fe":"code","cd5caef6":"code","9e2f5540":"code","c20b0cb5":"code","afde8795":"code","b7f7773a":"code","e176d530":"code","14f5891b":"code","71aed8f8":"code","197939f7":"code","ffa6cc7b":"code","cc3165d9":"code","012f28fd":"code","3bbba85f":"code","240b8e5c":"code","0fcab0cf":"code","19902e03":"code","b4a29356":"code","b99710a6":"code","469c058e":"code","f23b6cd0":"code","802a4125":"code","91844fdb":"code","e2c0e015":"code","8948aa92":"markdown","efe6adb2":"markdown","0bb2f51a":"markdown","92c58329":"markdown","3fba4f2a":"markdown","10c45003":"markdown","47e32c6f":"markdown","f03f4ed8":"markdown","ea8756da":"markdown","9d7201cf":"markdown","de2e85f1":"markdown","0a0ab0c8":"markdown","ec6f3d74":"markdown"},"source":{"3b76bca3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.datasets import load_breast_cancer\n!pip install optuna\n\n\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nimport lightgbm as lgb\nimport xgboost as xgb\n# sklearn\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler\n\nimport sklearn.metrics\n\nimport numpy as np\nimport pandas as pd\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nsns.set()\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import NearestNeighbors\n\nimport operator as op \nfrom itertools import combinations\n\nfrom sklearn.metrics  import accuracy_score, auc, roc_curve, precision_recall_curve, roc_auc_score, precision_score, recall_score, average_precision_score\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nfrom itertools import combinations, permutations\n# Display all columns\npd.set_option('display.max_columns', None)\nplt.style.use('seaborn-colorblind')\n\ndf = pd.read_excel('\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx')\n\n\n# source: https:\/\/www.kaggle.com\/felipeveiga\/starter-covid-19-sirio-libanes-icu-admission\ncomorb_lst = [i for i in df.columns if \"DISEASE\" in i]\ncomorb_lst.extend([\"HTN\", \"IMMUNOCOMPROMISED\", \"OTHER\"])\n\ndemo_lst = [i for i in df.columns if \"AGE_\" in i]\ndemo_lst.append(\"GENDER\")\n\nvitalSigns_lst = df.iloc[:,193:-2].columns.tolist()\n\nlab_lst = df.iloc[:,13:193].columns.tolist()","effc7077":"### Redundant Feature Check\ndef is_one_to_one(df, cols):\n    \"\"\"Check whether any number of columns are one-to-one match.\n\n    df: a pandas.DataFrame\n    cols: must be a list of columns names\n\n    Duplicated matches are allowed:\n        a - 1\n        b - 2\n        b - 2\n        c - 3\n    (This two cols will return True)\n    Source: [link](https:\/\/stackoverflow.com\/questions\/50643386\/easy-way-to-see-if-two-columns-are-one-to-one-in-pandas)\n\n    \"\"\"\n    if len(cols) == 1:\n        return True\n        # You can define you own rules for 1 column check, Or forbid it\n\n    # MAIN THINGs: for 2 or more columns check!\n    res = df.groupby(cols).count()\n    uniqueness = [res.index.get_level_values(i).is_unique\n                for i in range(res.index.nlevels)]\n    return all(uniqueness)\n\n# Getting combinations of all the colmns\ncombos = list(combinations(df.columns,2))\n\n# Running to see if any of them are identical\nidentical_cols = []\n\nfor col in np.arange(0,len(combos),1):\n    x = [combos[col][0],combos[col][1]]\n    if is_one_to_one(df,x) == True:\n         identical_cols.append(combos[col][0])","55442d73":"all_cols = [x for x in df.columns if x not in identical_cols]\ndf = df.loc[:, all_cols]","ca132585":"df.info()","40db86f4":"# source cell 6: https:\/\/www.kaggle.com\/fernandoramacciotti\/interpretable-icu-risk-0-2-window-only\n# missing values\ndf = df\\\n    .sort_values(by=['PATIENT_VISIT_IDENTIFIER', 'WINDOW'])\\\n    .groupby('PATIENT_VISIT_IDENTIFIER', as_index=False)\\\n    .fillna(method='ffill')\\\n    .fillna(method='bfill')","fb430f89":"df = df.set_index('PATIENT_VISIT_IDENTIFIER') ","f48aae4f":"w02 = df[df.WINDOW == '0-2']\nw24 = df[df.WINDOW == '2-4']\nw46 = df[df.WINDOW == '4-6']\nw612 = df[df.WINDOW == '6-12']\nwa12 = df[df.WINDOW == 'ABOVE_12']\n\nw02['ICU_W24'] = w24['ICU']\nw02['ICU_W46'] = w46['ICU']\nw02['ICU_W612'] = w612['ICU']\nw02['ICU_Wa12'] = wa12['ICU'] \n\nw24['ICU_W46'] = w46['ICU']\nw24['ICU_W612'] = w612['ICU']\nw24['ICU_Wa12'] = wa12['ICU'] \n\nw46['ICU_W612'] = w612['ICU']\nw46['ICU_Wa12'] = wa12['ICU'] \n\nw612['ICU_Wa12'] = wa12['ICU'] ","6a893a5e":"# FIRST REMOVE ICU 1 FROM WINDOW 0-2\nw02 = w02[w02.ICU == 0]\n\n# NEW TARGET \"NOT ICU\"\nw02['temp'] = w02.loc[:,['ICU','ICU_W24','ICU_W46','ICU_W612','ICU_Wa12']].sum(axis=1) \ndef label_icu(x):\n    if (x['temp'] == 0):\n        val = 0\n    elif (x['temp'] > 0):\n        val = 1\n    return val\n\nw02['EVENTUAL_ICU'] = w02.apply(label_icu, axis=1)\n\n# REMOVE UNWANTED COLUMNS \nw02_df = w02.drop(['EVENTUAL_ICU', 'temp','WINDOW','ICU','ICU_W24','ICU_W46','ICU_W612','ICU_Wa12'], axis = 1)\n\n\n# FIRST REMOVE ICU 1 FROM WINDOW 2-4\nw24 = w24[w24.ICU == 0]\n\n# NEW TARGET \"NOT ICU\"\nw24['temp'] = w24.loc[:,['ICU','ICU_W46','ICU_W612','ICU_Wa12']].sum(axis=1) \ndef label_icu(x):\n    if (x['temp'] == 0):\n        val = 0\n    elif (x['temp'] > 0):\n        val = 1\n    return val\n\nw24['EVENTUAL_ICU'] = w24.apply(label_icu, axis=1)\n\n# REMOVE UNWANTED COLUMNS \nw24_df = w24.drop(['EVENTUAL_ICU', 'temp','WINDOW','ICU','ICU_W46','ICU_W612','ICU_Wa12'], axis = 1)\n\n# FIRST REMOVE ICU 1 FROM WINDOW 4-6\nw46 = w46[w46.ICU == 0]\n\n# NEW TARGET \"NOT ICU\"\nw46['temp'] = w46.loc[:,['ICU','ICU_W612','ICU_Wa12']].sum(axis=1) \ndef label_icu(x):\n    if (x['temp'] == 0):\n        val = 0\n    elif (x['temp'] > 0):\n        val = 1\n    return val\n\nw46['EVENTUAL_ICU'] = w46.apply(label_icu, axis=1)\n\n# REMOVE UNWANTED COLUMNS \nw46_df = w46.drop(['EVENTUAL_ICU', 'temp','WINDOW','ICU','ICU_W612','ICU_Wa12'], axis = 1)\n\n\n# FIRST REMOVE ICU 1 FROM WINDOW 6-12\nw612 = w612[w612.ICU == 0]\n\n# NEW TARGET \"NOT ICU\"\nw612['temp'] = w612.loc[:,['ICU','ICU_Wa12']].sum(axis=1) \ndef label_icu(x):\n    if (x['temp'] == 0):\n        val = 0\n    elif (x['temp'] > 0):\n        val = 1\n    return val\n\nw612['EVENTUAL_ICU'] = w612.apply(label_icu, axis=1)\n\n# REMOVE UNWANTED COLUMNS \nw612_df = w612.drop(['EVENTUAL_ICU', 'temp','WINDOW','ICU','ICU_Wa12'], axis = 1)","ae6d515a":"w02['EVENTUAL_ICU'].value_counts()","212d6bab":"datacopy = w02_df\nx =[]\nfor col in w02_df.columns:\n  n = len(datacopy[col].unique())\n  if (15 < n):\n       continue\n  if (15 > n > 2 ): # making a list of columns that are greater than 2 levels\n      y = col\n      x.append(y)  \n\nw02X = pd.get_dummies(datacopy, columns = x)\n\nX = w02X\ny =  w02['EVENTUAL_ICU']","b74b56db":"models = ['gp', 'et', 'xgb', 'gbm'] # when you want to try all of them\/ iteration: 1 \ncomb = list(combinations(models, 3))\n\n\ndef scaler_fuc(scaler, X, y):\n\n  train_x, valid_x, train_y, valid_y = train_test_split(X, y,\n                                              test_size=0.25, random_state = 123)\n  if (scaler == 'minmax'):\n    scaler = MinMaxScaler()\n    scaler.fit(train_x)\n    train_x = scaler.transform(train_x)\n    scaler.fit(valid_x)\n    valid_x = scaler.transform(valid_x)\n\n  if (scaler == 'stand'):\n    scaler = StandardScaler()\n    scaler.fit(train_x)\n    train_x = scaler.transform(train_x)\n    scaler.fit(valid_x)\n    valid_x = scaler.transform(valid_x)\n\n  if (scaler == 'log'):\n    transformer = FunctionTransformer(np.log1p, validate=True)\n    train_x = transformer.transform(train_x)\n    valid_x = transformer.transform(valid_x)\n    # prevent log 0 error\n    np.seterr(divide = 'ignore')  # invalid value encountered in log1p\n    train_x = np.where(np.isneginf(train_x), 0, train_x)\n    valid_x = np.where(np.isneginf(valid_x), 0, valid_x)\n    train_x = np.where(np.isinf(train_x), 0, train_x)\n    valid_x = np.where(np.isinf(valid_x), 0, valid_x)\n    train_x = np.where(np.isnan(train_x), 0, train_x)\n    valid_x = np.where(np.isnan(valid_x), 0, valid_x)\n\n  # turning these train\/tests into lgb\/xgb datasets\n  dtrain_gbm = lgb.Dataset(train_x, label=train_y)\n  dvalid_gbm = lgb.Dataset(valid_x, label=valid_y)\n\n  dtrain_xbg = xgb.DMatrix(train_x, label=train_y)\n  dvalid_xbg = xgb.DMatrix(valid_x, label=valid_y)\n  return train_x, valid_x, train_y, valid_y,  dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg\n\n\nclass Objective:\n\n    def __init__(self):\n        self.best_gbm = None\n        self._gbm = None\n        self.best_xgb = None\n        self._xgb = None\n        self.predictions = None\n        self.fpredictions = None\n\n    def __call__(self, trial):\n\n        i = trial.suggest_int(\"combos\", 0, (len(comb)-1))\n        gbm_preds = np.zeros((math.ceil(len(y)*0.25),1), dtype=np.int)\n        xgb_preds = np.zeros((math.ceil(len(y)*0.25),1), dtype=np.int)\n        et_preds = np.zeros((math.ceil(len(y)*0.25),1), dtype=np.int)\n        gp_preds = np.zeros((math.ceil(len(y)*0.25),1), dtype=np.int)\n\n\n   \n        ###############################################################################\n        #                 . GaussianProcess   +  Radial-Basis Function                #\n        ###############################################################################\n        if any(x == 'gp' for x in comb[i]):\n          gp_scaler = trial.suggest_categorical(\"gp_Scaler\", ['minmax','stand','log'])\n          train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc(gp_scaler,X, y)\n          a_gp = trial.suggest_loguniform(\"gp_a\", 0.001, 10)\n          gp_kern= trial.suggest_int(\"gp_kern\", 1, 15)\n          gpkernel = a_gp * RBF(gp_kern)\n          gp = GaussianProcessClassifier(kernel=gpkernel, random_state=0, n_jobs = -1).fit(train_x, train_y)\n          gp_preds = gp.predict_proba(valid_x)[:,1]\n\n        ###############################################################################\n        #                              . Extra Trees                                  #\n        ###############################################################################\n        if any(x == 'et' for x in comb[i]):\n          et_scaler = trial.suggest_categorical(\"et_Scaler\", ['minmax','stand','log'])\n          train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc(et_scaler,X, y)\n          et_md = trial.suggest_int(\"et_max_depth\", 1, 100)\n          et_ne = trial.suggest_int(\"et_ne\", 1, 500) #1000\n          et = ExtraTreesClassifier(max_depth=et_md, n_estimators = et_ne,\n                                     random_state=0).fit(train_x, train_y)\n          et_preds = et.predict_proba(valid_x)[:,1]\n        ###############################################################################\n        #                                 . XGBoost                                   #\n        ###############################################################################\n        if any(x == 'xgb' for x in comb[i]): \n          xgb_scaler = trial.suggest_categorical(\"xgb_Scaler2\", ['minmax','stand','log'])\n          train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc(xgb_scaler,X, y)\n          xgb_param = {\n              \"silent\": 1,\n              \"objective\": \"binary:logistic\", # change for multiclass\n              \"eval_metric\": \"auc\",\n              # \"num_class\": 3, # change this up depending on multiclass | dont use with binary\n              \"booster\": trial.suggest_categorical(\"booster2\", [\"gbtree\", \"gblinear\", \"dart\"]),\n              \"lambda\": trial.suggest_loguniform(\"lambda2\", 1e-8, 1.0),\n              \"alpha\": trial.suggest_loguniform(\"alpha2\", 1e-8, 1.0),\n          }\n          if xgb_param[\"booster\"] == \"gbtree\" or xgb_param[\"booster\"] == \"dart\":\n              xgb_param[\"max_depth\"] = trial.suggest_int(\"max_depth2\", 1, 100)\n              xgb_param[\"eta\"] = trial.suggest_loguniform(\"eta2\", 1e-8, 1.0)\n              xgb_param[\"gamma\"] = trial.suggest_loguniform(\"gamma2\", 1e-8, 1.0)\n              xgb_param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy2\", [\"depthwise\", \"lossguide\"])\n          if xgb_param[\"booster\"] == \"dart\":\n              xgb_param[\"sample_type\"] = trial.suggest_categorical(\"sample_type2\", [\"uniform\", \"weighted\"])\n              xgb_param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type2\", [\"tree\", \"forest\"])\n              xgb_param[\"rate_drop\"] = trial.suggest_loguniform(\"rate_drop2\", 1e-8, 1.0)\n              xgb_param[\"skip_drop\"] = trial.suggest_loguniform(\"skip_drop2\", 1e-8, 1.0)\n          # Add a callback for pruning.\n          xgb_pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\" )\n          xgb_ = xgb.train(xgb_param, dtrain_xbg, evals=[(dvalid_xbg, \"validation\")], verbose_eval=False, callbacks=[xgb_pruning_callback])\n          xgb_preds = xgb_.predict(dvalid_xbg)\n          self._xgb = xgb_\n        ###############################################################################\n        #                          . Light Gradient Boosting                          #\n        ###############################################################################\n        if any(x == 'gbm' for x in comb[i]):\n          gbm_scaler = trial.suggest_categorical(\"gbm_Scaler2\", ['minmax','stand','log'])\n          train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc(gbm_scaler,X, y)\n          gbm_param = {\n            'objective': 'binary', # change for multiclass\n            'metric': 'auc',\n              \"verbosity\": -1,\n              \"boosting_type\": \"gbdt\",\n              \"lambda_l1\": trial.suggest_loguniform(\"lambda_l12\", 1e-8, 10), \n              \"lambda_l2\": trial.suggest_loguniform(\"lambda_l22\", 1e-8, 10),\n              \"num_leaves\": trial.suggest_int(\"num_leaves2\", 2, 256), \n              \"feature_fraction\": trial.suggest_uniform(\"feature_fraction2\", 0.4, 1.0), \n              \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction2\", 0.4, 1.0),\n              \"bagging_freq\": trial.suggest_int(\"bagging_freq2\", 1, 7), \n              \"min_child_samples\": trial.suggest_int(\"min_child_samples2\", 2, 20), \n          }\n          # Add a callback for pruning.\n          gbm_pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n          gbm = lgb.train(gbm_param, dtrain_gbm, valid_sets=[dvalid_gbm], verbose_eval=False, callbacks=[gbm_pruning_callback])\n          gbm_preds = gbm.predict(valid_x)\n          self._gbm = gbm\n        ###############################################################################\n        #                            . Stacking Strategy                              #\n        ###############################################################################\n\n        preds = (gbm_preds + xgb_preds +  \\\n         + et_preds + \\\n         gp_preds ) \/ 3 \n        preds = preds[:1][0]\n\n\n        self.predictions = preds\n        auc = average_precision_score(valid_y, preds)\n        return auc\n\n    def callback(self, study, trial):\n        if study.best_trial == trial:\n            self.best_gbm = self._gbm\n            self.best_xgb = self._xgb\n            self.fpredictions = self.predictions\n            \n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning) # for log error\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","424601c1":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 0-2')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","927c37da":"datacopy = w24_df\nx =[]\nfor col in w24_df.columns:\n  n = len(datacopy[col].unique())\n  if (15 < n):\n       continue\n  if (15 > n > 2 ): # making a list of columns that are greater than 2 levels\n      y = col\n      x.append(y)  \n\nw24X = pd.get_dummies(datacopy, columns = x)\n\nX = w24X\ny =  w24['EVENTUAL_ICU']\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning) # for log error\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","07f51145":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 2-4')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","3c6543e9":"datacopy = w46_df\nx =[]\nfor col in w46_df.columns:\n  n = len(datacopy[col].unique())\n  if (15 < n):\n       continue\n  if (15 > n > 2 ): # making a list of columns that are greater than 2 levels\n      y = col\n      x.append(y)  \n\nw46X = pd.get_dummies(datacopy, columns = x)\n\nX = w46X\ny =  w46['EVENTUAL_ICU']\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning) # for log error\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","c2a5172b":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 4-6')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","7159c477":"datacopy = w612_df\nx =[]\nfor col in w612_df.columns:\n  n = len(datacopy[col].unique())\n  if (15 < n):\n       continue\n  if (15 > n > 2 ): # making a list of columns that are greater than 2 levels\n      y = col\n      x.append(y)  \n\nw612X = pd.get_dummies(datacopy, columns = x)\n\nX = w612X\ny =  w612['EVENTUAL_ICU']\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning) # for log error\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","4b28cd45":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 6-12')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","6617a7ea":"list1_as_set = set(demo_lst + vitalSigns_lst)\nintersection = list1_as_set.intersection(w02X.columns.tolist())\ndemo_vitalSigns = list(intersection)","0bf1bbb2":"X = w02X[demo_vitalSigns]\ny =  w02['EVENTUAL_ICU']\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","1dc62876":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 0-2')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","00dbd630":"intersection = list1_as_set.intersection(w24X.columns.tolist())\ndemo_vitalSigns = list(intersection)\nX = w24X.loc[:,demo_vitalSigns]\ny =  w24['EVENTUAL_ICU']\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","bdb017de":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 2-4')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","f05ea6fe":"intersection = list1_as_set.intersection(w46X.columns.tolist())\ndemo_vitalSigns = list(intersection)\nX = w46X.loc[:,demo_vitalSigns]\ny =  w46['EVENTUAL_ICU']\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","cd5caef6":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 4-6')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","9e2f5540":"intersection = list1_as_set.intersection(w612X.columns.tolist())\ndemo_vitalSigns = list(intersection)\nX = w612X.loc[:,demo_vitalSigns]\ny =  w612['EVENTUAL_ICU']\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","c20b0cb5":"train_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions\naccuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 6-12')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","afde8795":"list1_as_set = set(demo_lst + lab_lst)\nintersection = list1_as_set.intersection(w02X.columns.tolist())\ndemo_lab = list(intersection)\n\nX = w02X.loc[:,demo_lab]\ny =  w02['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","b7f7773a":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 0-2')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","e176d530":"intersection = list1_as_set.intersection(w24X.columns.tolist())\ndemo_lab = list(intersection)\n\nX = w24X.loc[:,demo_lab]\ny =  w24['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \n\ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","14f5891b":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 2-4')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","71aed8f8":"intersection = list1_as_set.intersection(w46X.columns.tolist())\ndemo_lab = list(intersection)\n\nX = w46X.loc[:,demo_lab]\ny =  w46['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n\ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","197939f7":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 4-6')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","ffa6cc7b":"intersection = list1_as_set.intersection(w612X.columns.tolist())\ndemo_lab = list(intersection)\n\nX = w612X.loc[:,demo_lab]\ny =  w612['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","cc3165d9":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 6-12')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","012f28fd":"list1_as_set = set(demo_lst + comorb_lst)\nintersection = list1_as_set.intersection(w02X.columns.tolist())\ndemo_como = list(intersection)\n\nX = w02X.loc[:,demo_como]\ny =  w02['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","3bbba85f":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 0-2')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","240b8e5c":"intersection = list1_as_set.intersection(w24X.columns.tolist())\ndemo_como = list(intersection)\n\nX = w24X.loc[:,demo_como]\ny =  w24['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","0fcab0cf":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 2-4')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","19902e03":"intersection = list1_as_set.intersection(w46X.columns.tolist())\ndemo_como = list(intersection)\n\nX = w46X.loc[:,demo_como]\ny =  w46['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","b4a29356":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 4-6')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","b99710a6":"intersection = list1_as_set.intersection(w612X.columns.tolist())\ndemo_como = list(intersection)\n\nX = w612X.loc[:,demo_como]\ny =  w612['EVENTUAL_ICU']\n\n\nimport optuna\nobjective = Objective()\n\n# Setting SEED \nfrom optuna.samplers import TPESampler\nsampler = TPESampler(seed=10)\n\nstudy = optuna.create_study(\n    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\",\n    sampler=sampler\n)\nstudy.optimize(objective, n_trials=1000, callbacks=[objective.callback]) # change this to 500 + \n\nprint(\"Best trial:\")\ntrial = study.best_trial\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\n    \ntrain_x, valid_x, train_y, valid_y, dtrain_gbm, dvalid_gbm, dtrain_xbg, dvalid_xbg = scaler_fuc('log',X,y) # just taking the validation set\npredictions = objective.fpredictions","469c058e":"accuracy  = accuracy_score(valid_y, predictions >= 0.5)\nroc_auc   = roc_auc_score(valid_y, predictions)\nprecision = precision_score(valid_y, predictions >= 0.5)\nrecall    = recall_score(valid_y, predictions >= 0.5)\npr_auc    = average_precision_score(valid_y, predictions)\n\nprint('WINDOW 6-12')\nprint(f'Accuracy: {round(accuracy,4)}')\nprint(f'ROC AUC: {round(roc_auc,4)}')\nprint(f'Precision: {round(precision,4)}')\nprint(f'Recall: {round(recall,4)}')\nprint(f'PR Score: {round(pr_auc,4)}')","f23b6cd0":"def boxplot(data,col,title):\n    sns.set_style('ticks')\n    f, ax = plt.subplots(figsize=(32, 18))\n#     ax.set_xscale(\"log\")\n    sns.set(font_scale=0.8)\n    sns.boxplot(data=data[col],palette=\"vlag\", orient=\"h\")\n    plt.title(title, size= 14)\n    ax.yaxis.grid(True)\n    sns.despine()\n    ax.set(ylabel='')\n    plt.show()\n    \nboxplot(w02,vitalSigns_lst,'Vital Signs')","802a4125":"list1_as_set = set(lab_lst)\nintersection = list1_as_set.intersection(w02X.columns.tolist())\nlab = list(intersection)\nboxplot(w02,lab,'Lab')","91844fdb":"sns.set(style=\"ticks\")\nfig, axs = plt.subplots(1,len(demo_lst))\nfig.set_size_inches(32, 18)\ni=0\nfor col in demo_lst:\n    sns.set_style(\"white\")\n    sns.countplot(col, data=df, palette=\"vlag\",  ax=axs[i])\n    i+=1\nsns.despine()\nplt.show()","e2c0e015":"def make_corr(data,subgroup,title=''):\n    sns.set(font_scale=0.8)\n    cols = subgroup  #columns gohere\n    plt.figure(figsize=(32,18)) # plotting heapmap\n    sns.heatmap(data[cols].corr(), cmap='RdBu_r', annot=False, center=0.0)\n    if title!='': plt.title(title) # title based on input \n    plt.show()\n\nmake_corr(w02, w02.columns.tolist(),'All Column Corr')","8948aa92":"onehot encode","efe6adb2":"those last variables are dropped before being put inside the models ^ ","0bb2f51a":"# Question 1: Can we predict which inpatient will need intensive care unit (ICU)?","92c58329":"# Question 2: Can we predict which inpatient will need intensive care unit (ICU) using only (Vital signs + Demographics)?","3fba4f2a":"# Question 4: Can we predict which inpatient will need intensive care unit (ICU) using only (Comorbities + Demographics)?","10c45003":"This shows that 163 patients eventually end up in ICU of the intial 353 patients in window 0-2","47e32c6f":"# QUICK EDA","f03f4ed8":"# EDA & 3 Model Ensemble\n\n\n## Aim\nThe aim is to provide tertiary and quarternary hospitals with the most **accurate** answer, so ICU resources can be arranged or patient transfer can be scheduled.\n\n\n## Task 1\n*Based on the data available, is it **feasible** to predict which patients will need intensive care unit support?*\n\n\n\n- Can we predict which inpatient will need intensive care unit (ICU)?\n- Can we predict which inpatient will need intensive care unit (ICU) using only (Vital signs + Demographics)?\n- Can we predict which inpatient will need intensive care unit (ICU) using only (Laboratory exams + Demographics)?\n- Can we predict which inpatient will need intensive care unit (ICU) using only (Comorbities + Demographics)?\n\nWhat is the best time window for each previous question. Justify.\n\nGiven the explanation of the data [here](https:\/\/www.kaggle.com\/S%C3%ADrio-Libanes\/covid19). ICU admission data must be removed if the window is **greater than 12**. \n\n\n## Methodology\n\n### Task 1\n\n#### 1. Data Preparation\n\n- Data with a window greater than 12 is removed. \n- Reduntant\/ Duplicated features are removed. \n\n#### 2. Model Creation\n\n- Train set is 480 samples and the test set is 160 samples. (75\/25)\n\n- Of 4 machine learning models 3 are self-chosen using the hyper-optimisation library Optuna. These models are uniquely scaled, uniquely featured engineered, uniquely undersampled and parametered tunned as normal.\n\n#### 3. Evaluation.\n\n- Using a callback, the predictions are analysied for Accuracy, Precision Recall & ROC AUC. \n\n## Results\n\n### Can we predict which inpatient will need intensive care unit (ICU)?\n\nWindow  | Accuracy | Average Precision Score | ROC AUC\n------------- | ------------- | ------------- | ------------- \nWindow 0-2  | 0.7528 | 0.8066 | 0.8248\nWindow 2-4  | 0.7805 | 0.8484 | 0.8788 \nWindow 4-6  | 0.7222 | 0.6983 | 0.7726 \nWindow 6-12  | 0.8906 | 0.7383 | 0.9333 \n\n\n### Can we predict which inpatient will need intensive care unit (ICU) using only (Vital signs + Demographics)?\n\nWindow  | Accuracy | Average Precision Score | ROC AUC\n------------- | ------------- | ------------- | ------------- \nWindow 0-2  | 0.6966 | 0.7296 | 0.7557\nWindow 2-4  | 0.7195 | 0.7784 | 0.8192\nWindow 4-6  | 0.6667 | 0.6788 | 0.7205 \nWindow 6-12  | 0.7812 | 0.4446 | 0.7778  \n\n\n\n### Can we predict which inpatient will need intensive care unit (ICU) using only (Laboratory exams + Demographics)?\n\nWindow  | Accuracy | Average Precision Score | ROC AUC\n------------- | ------------- | ------------- | ------------- \nWindow 0-2  | 0.7191 | 0.7918 | 0.8129 \nWindow 2-4  | 0.7927 | 0.8234 | 0.8641 \nWindow 4-6  | 0.8333 | 0.8241 | 0.8681 \nWindow 6-12  | 0.9062 | 0.7217 | 0.9111 \n\n\n\n### Can we predict which inpatient will need intensive care unit (ICU) using only (Comorbities + Demographics)?\n\nWindow  | Accuracy | Average Precision Score | ROC AUC\n------------- | ------------- | ------------- | ------------- \nWindow 0-2  | 0.6292 | 0.5912 | 0.6642\nWindow 2-4  | 0.6341 | 0.5379 | 0.6885 \nWindow 4-6  | 0.6806 | 0.511 | 0.6775 \nWindow 6-12  | 0.8594 | 0.3016 | 0.6172 \n\n\n## Key Take Aways\n\n*Looks like using window 2-4 and all the usable data obtains the best precision score.*\n\n- To ensure a more robust model. Instead of taking the mean of the 3 predictions. A formula such as one on my github displayed below could be used. \n\n\n\n## Acknowledgement & Improvements\n\nI've hidden the inputs of all the boring code to keep the notbook concise, feel free to click on show input\/output. \n\nIn this notebook i only used 4 models, and picked 3, however on my github you can pick from 11 for classification and 7 for regression. \nA fully detailed version of the ensemble is avaliable on my github: \n\nhttps:\/\/github.com\/CodeByHarri\/Stacking-Ensemble-Machine-Learning\n\n\n*feel free to comment below any questions or provide feedback :)*\n\n## Check out My Task 2 Solutions [here](https:\/\/www.kaggle.com\/harriwashere\/task-2-3-model-ensemble-pr-83-63)","ea8756da":"Check to see if there are any duplicate features. ","9d7201cf":"making the dataframe by removing: window,  ICU = 1 and using only window 0-2. ","de2e85f1":"getting demographic + vital sign dataframe","0a0ab0c8":"removing duplicate features","ec6f3d74":"# Question 3: Can we predict which inpatient will need intensive care unit (ICU) using only (Laboratory exams + Demographics)?"}}