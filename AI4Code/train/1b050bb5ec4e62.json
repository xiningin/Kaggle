{"cell_type":{"3fe74f4b":"code","e647271c":"code","1946751e":"code","3018db4a":"code","f6ba0cf7":"code","05607ef9":"code","129e8f4a":"code","efd1fc0b":"code","36f21e6a":"code","359ffae2":"code","8724337f":"code","7d7bf60b":"code","cd6d14de":"code","3a456c42":"code","3115bddb":"code","696917ce":"code","72053a8e":"code","1655f19c":"markdown"},"source":{"3fe74f4b":"import numpy as np  \nimport datetime\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.layers import  Flatten, Dense, Dropout\nfrom tensorflow.keras import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt","e647271c":"# -- Global Variables -- \nTRAIN_PATH = '..\/input\/pepsico-lab-potato-quality-control\/Pepsico RnD Potato Lab Dataset\/Train'\nTEST_PATH = '..\/input\/pepsico-lab-potato-quality-control\/Pepsico RnD Potato Lab Dataset\/Test'\nBATCH_SIZE = 32\nCOLOR_MODE = 'rgb'\nTARGET_SIZE = (255, 255)\nGRAY_SCALL = (3,)\nINPUT_SIZE = TARGET_SIZE + GRAY_SCALL\nEPOCHS = 10\nCLASSES = ['Defective','Non-Defective']","1946751e":"# -- Data Normalization --\ndata_generator = ImageDataGenerator(samplewise_center=True, #making sure that each image has a mean of 0\n                                    samplewise_std_normalization=True, #and standard deviation 1\n                                    horizontal_flip=True, #Randomly flip inputs horizontally\n                                    validation_split=0.3,\n                                    )","3018db4a":"# -- Data iterators -- \ntrain_data = data_generator.flow_from_directory(directory=TRAIN_PATH,\n                                                target_size=TARGET_SIZE,\n                                                batch_size=BATCH_SIZE,\n                                                class_mode='categorical',\n                                                color_mode=COLOR_MODE,\n                                                subset='training',\n                                                shuffle=True)         \n    \nvalidation_data = data_generator.flow_from_directory(directory=TRAIN_PATH,\n                                                     target_size=TARGET_SIZE,\n                                                     batch_size=BATCH_SIZE,\n                                                     class_mode='categorical',\n                                                     color_mode=COLOR_MODE,\n                                                     subset='validation',\n                                                     shuffle=True)             \n\ntest_data = data_generator.flow_from_directory(directory=TEST_PATH,\n                                               target_size=TARGET_SIZE,\n                                               batch_size=BATCH_SIZE,\n                                               class_mode='categorical',\n                                               color_mode=COLOR_MODE,\n                                               shuffle=True)","f6ba0cf7":"# -- plot random batch -- \nimages, labels = train_data.next()\nclasses = np.asarray(CLASSES)\n\n_, axs = plt.subplots(4, 8, figsize=(12,12))\naxs = axs.flatten()\nfor img, label, ax in zip(images, labels, axs):\n    ax.imshow(img)\n    ax.axis('off')\n    label = label.astype(int)\n    ax.set_title(classes[label == 1])\nplt.show()","05607ef9":"def my_model():\n  vgg19_model = VGG19(weights='imagenet',include_top=False,input_shape=INPUT_SIZE)\n  vgg19_model.trainable = False\n  flatten =Flatten()(vgg19_model.layers[-1].output)\n  fc1 = Dense(units=4096, activation ='relu')(flatten)\n  dropout = Dropout(0.2)(fc1)\n  fc2 = Dense(units=1024,activation='relu')(dropout)\n  output = Dense(2, activation='softmax')(fc2)\n  model = Model(inputs = vgg19_model.input, outputs=output)\n  model.summary()\n  return model","129e8f4a":"model = my_model()","efd1fc0b":"tf.keras.utils.plot_model(\n    model, to_file='model.png', show_shapes=True, show_dtype=False,\n    show_layer_names=True, rankdir='T', expand_nested=False, dpi=96\n)","36f21e6a":"# -- Define optimizer and loss --\nopt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\nloss = tf.keras.losses.CategoricalCrossentropy()","359ffae2":"# -- Compile model --\nmodel.compile(optimizer=opt, loss=loss, metrics=['accuracy'])","8724337f":" # -- Callbacks --\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', \n                                                    monitor='accuracy', verbose=1, \n                                                    save_best_only=True, \n                                                    save_weights_only=False, \n                                                    mode='auto', \n                                                    save_freq='epoch')\n    \nearlystoping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', \n                                                    min_delta=0, \n                                                    patience=5,  #Number of epochs with no improvement after which training will be stopped.\n                                                    verbose=1, \n                                                    mode='auto')\n    \nlog_dir = '.\/logs\/fit\/' + datetime.datetime.now().strftime('%m.%d.%Y--%H-%M-%S')\ntensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n                                                 histogram_freq=1, \n                                                 write_graph=True,\n                                                 write_images=False, \n                                                 update_freq='epoch')","7d7bf60b":"# -- Train model --\nhistory = model.fit(x=train_data, \n                        epochs=EPOCHS, \n                        steps_per_epoch=len(train_data), \n                        verbose=1, \n                        validation_data=validation_data, \n                        validation_steps=1)\n    \n# -- Save model -- \nmodel.save('my_model.h5')","cd6d14de":"def learning_curves(history):\n    '''plot learning curves'''\n    \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    \n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    plt.figure(figsize=(10, 8))\n    \n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy')\n    \n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.ylabel('Loss - Cross Entropy')\n    plt.xlabel('epoch')\n    plt.ylim([0,1.6])\n    plt.title('Training and Validation Loss')\n    \n    plt.show()","3a456c42":"# -- Plot learning curves -- \nlearning_curves(history)","3115bddb":"# -- Evaluate the model on the test data -- \nloss, accuracy = model.evaluate(x=test_data)\nprint(\"test loss: \", loss, \", test acc: \" , 100*accuracy, \"%\")","696917ce":"def defective_or_not(img_path):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(255,255,3))\n    img = np.asarray(img)\n    img = np.expand_dims(img, axis=0)\n    model = tf.keras.models.load_model('my_model.h5')\n    output = model.predict(img)\n    print(classes[output[0]==1])","72053a8e":"# defective_or_not(image.png)","1655f19c":"<a href=\"https:\/\/colab.research.google.com\/github\/concaption\/PepsiCo-Lab-Potato-Quality-Control\/blob\/main\/Potato_Starter_Code_.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>"}}