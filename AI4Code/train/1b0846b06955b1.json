{"cell_type":{"76ee86b8":"code","74fece16":"code","48b3d663":"code","042b6e45":"code","1989b108":"code","42a3754d":"code","4c3c4085":"code","12767dcd":"code","ad1425e7":"code","654c8fa0":"code","d9e98653":"code","254d92b6":"code","15f2e6f5":"code","f4cbffbd":"code","0cd005c6":"code","e6c34a4b":"code","c38268ce":"code","4d4c8734":"code","9d6f2bbc":"code","6ef52643":"code","cb9b2e5a":"markdown","df08e011":"markdown","9155ba67":"markdown","d9ccf969":"markdown","7600f20a":"markdown","40ce74a0":"markdown","3981aedc":"markdown","42ad2ad6":"markdown","55c6ccdf":"markdown","f11183fa":"markdown","f9fba6f4":"markdown","f6e17db1":"markdown","ad2a5790":"markdown","18ca6713":"markdown","031a63b6":"markdown"},"source":{"76ee86b8":"import matplotlib.pyplot as plt\nplt.figure(figsize = (16,16))\nimg = plt.imread('\/kaggle\/input\/sign-language-mnist\/amer_sign2.png')\nplt.imshow(img)\nplt.show()","74fece16":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport random\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Dropout\nimport warnings\n\nsns.set()\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","48b3d663":"df_train = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ndf_train.head(-5)","042b6e45":"df_test = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')\ndf_test.head(-5)","1989b108":"plt.figure(figsize = (15,10))\nsns.set_style(\"darkgrid\")\nsns.countplot(df_train['label'])\nplt.show()","42a3754d":"y_train = df_train['label']\ndf_train.drop(['label'], axis=1, inplace=True)\ndf_train.head(-5)","4c3c4085":"y_test = df_test['label']\ndf_test.drop(['label'], axis=1, inplace=True)\ndf_test.head(-5)","12767dcd":"size  = 28\nchannels = 1\nbatch = 128\nepochs = 100","ad1425e7":"X_train = df_train.values.reshape(df_train.shape[0], size, size, channels)\nX_test = df_test.values.reshape(df_test.shape[0], size, size, channels)\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)","654c8fa0":"datagen = ImageDataGenerator(rescale=1.\/255,\n                             zoom_range=0.2,\n                             width_shift_range=.2, height_shift_range=.2,\n                             rotation_range=30,\n                             brightness_range=[0.8, 1.2],\n                             horizontal_flip=True)\n\ndatagenRescale = ImageDataGenerator(rescale=1.\/255)\n\nX_train = datagen.flow(X_train, y_train, batch_size=batch)\n\nX_test = datagenRescale.flow(X_test, y_test)","d9e98653":"alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\nplt.figure(figsize=(15, 15))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    for X_batch, Y_batch in X_train:\n        image = X_batch[i]\n        plt.imshow(image, cmap='gray')\n        plt.xlabel(alphabet[Y_batch[i]])\n        break\nplt.show()","254d92b6":"checkpoint_filepath = 'best_model.hdf5'\n\ncallback_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\ncallback_learningrate = ReduceLROnPlateau(monitor='loss', mode='min', min_delta=0.01, patience=3, factor=.75, min_lr=0.00001, verbose=1)\n\ncallbacks = [callback_checkpoint, callback_learningrate]","15f2e6f5":"Model = Sequential([Conv2D(filters=32,  kernel_size=(3,3), activation=\"relu\", input_shape=(size,size,channels)),\n                    MaxPool2D(2,2, padding='same'),\n                    Dropout(0.2),\n                 \n                    Conv2D(filters=128,  kernel_size=(3,3), activation=\"relu\"),\n                    MaxPool2D(2,2, padding='same'),\n                    Dropout(0.2),\n                \n                    Conv2D(filters=512, kernel_size=(3,3), activation=\"relu\"),\n                    MaxPool2D(2,2, padding='same'),\n                    Dropout(0.2),\n                    \n                    \n                    Flatten(),\n                    \n                    Dense(units=4096, activation=\"relu\"),                 \n                    Dropout(0.2),\n                    \n                    Dense(units=1024, activation=\"relu\"),\n                    Dropout(0.2),\n                                  \n                    Dense(units=256, activation=\"relu\"),\n                    Dropout(0.2),\n                    \n                    Dense(units=25, activation=\"softmax\"),\n])\n\n\nModel.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n\n\nModel.summary()","f4cbffbd":"history = Model.fit(X_train, validation_data=X_test, epochs=epochs, callbacks=callbacks)","0cd005c6":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","e6c34a4b":"score = Model.evaluate(X_test) \n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","c38268ce":"df_test = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')\ny_test = df_test['label']\ndf_test.drop(['label'], axis=1, inplace=True)\nX_test = df_test.values.reshape(df_test.shape[0], size, size, channels)","4d4c8734":"y_pred = np.argmax(Model.predict(X_test),axis = 1) ","9d6f2bbc":"from sklearn.metrics import confusion_matrix\nCM = confusion_matrix(y_test, y_pred)\nplt.figure(figsize = (15,15))\nsns.heatmap(CM, annot=True, cmap=\"Blues\", fmt = 'g')\nplt.xlabel(\"Predicted Classes\")\nplt.ylabel(\"True Classes\")\nplt.title(\"Confusion Matrix\")\nplt.show()","6ef52643":"plt.figure(figsize=(15,15))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[i],cmap='gray')\n    plt.ylabel(f\"True: {alphabet[y_test[i]]}\")\n    plt.xlabel(f\"Predicted: {alphabet[y_pred[i]]}\")\n    \nplt.show()","cb9b2e5a":"Let's split the **label** column from train and test data frames.","df08e011":"# 2- Import\nFirst we import our libraries that will we need.","9155ba67":"# 9- Confusion Matrix","d9ccf969":"Define the size of image and its channel, batch size  and the number of epochs.","7600f20a":"The dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions). The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, pixel1,pixel2\u2026.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.","40ce74a0":"# 6- Desighn the Neural Network","3981aedc":"# 5- Setup Callbacks","42ad2ad6":"# 4- Data Augmentation\nLet's make augmentation on training data and only scaling validation and test data.","55c6ccdf":"# 8- Let's evaluate","f11183fa":"# 3- Prepare Data\nImport **train** and **test** data as dataframes.","f9fba6f4":"The classes of data and their number of images.","f6e17db1":"# 7- Let's train","ad2a5790":"# 10- Let's Check","18ca6713":"# 1- Hello Friends\n\n**Hello Future Engineers, Nice to meet you!**","031a63b6":"Reshape the data to make images ready for **ImageDataGenerator**:\n> reshape(number of rows, img width, img height, channels)"}}