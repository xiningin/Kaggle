{"cell_type":{"e4245916":"code","07f344ca":"code","b665e950":"code","d6ddfe7a":"code","ba2b2106":"code","5ea48e48":"code","84444d78":"code","1203689c":"code","2f714819":"code","da4dc54b":"code","984de470":"code","c5109fec":"code","afa4a48e":"code","7d2474dc":"code","d709e8c8":"code","794be43c":"code","a748fbe0":"code","a0b74004":"code","27aa5f31":"code","c25fefb5":"code","aa4a7302":"code","a361e144":"code","bd6c04d2":"code","c696d4c1":"code","8b0afcab":"code","f9e903d1":"code","3dbca2dd":"code","5818304b":"code","c2977095":"code","1a228ff4":"code","fddc8116":"code","8375238c":"code","1e8e0f8e":"code","b77d5921":"code","d1429742":"code","87ce5ea5":"code","3a1f7535":"code","4234d4f2":"code","eb41c794":"code","3ebdc3a3":"code","2b4a5d2b":"code","8c3d895c":"code","e1cf2ded":"code","b671c50e":"code","de817a6a":"markdown","26481539":"markdown","f05b2a88":"markdown","f0c3a90b":"markdown","a2f29a9e":"markdown","347ce85c":"markdown","5ddfaab7":"markdown","b092e4d6":"markdown","c96c15b2":"markdown","5dd79532":"markdown","22c6104d":"markdown","d04a7189":"markdown","832bb147":"markdown","4adda0f4":"markdown","2b193d06":"markdown","ae25767f":"markdown","86521d3e":"markdown","ad97bd5f":"markdown","40767734":"markdown","90227fae":"markdown","dbaf9292":"markdown","5966cb4e":"markdown","557ecf14":"markdown","d5fc3d7c":"markdown","1d04949a":"markdown","b6c65fa2":"markdown","f5ad2112":"markdown","eb3439a1":"markdown","7caceb0d":"markdown","e9e97c46":"markdown"},"source":{"e4245916":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport shap\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","07f344ca":"df = pd.read_csv('..\/input\/customer-personality-analysis\/marketing_campaign.csv',sep = '\\t')\ndf.head()","b665e950":"df.info()","d6ddfe7a":"df.dropna(inplace = True)\nprint(\"No of data points in data are : \" , len(df))","ba2b2106":"df.describe()","5ea48e48":"!pip install dataprep","84444d78":"from dataprep.eda import plot, plot_correlation, create_report, plot_missing\nplot(df)","1203689c":"## Dt_Customer: Date of customer's enrollment with the company\ndf[\"Dt_Customer\"] = pd.to_datetime(df[\"Dt_Customer\"])\ndates= []\nfor i in df[\"Dt_Customer\"]:\n    i = i.date()\n    dates.append(i)  \n\nprint(\"The newest customer's enrolment date in the records:\",max(dates))\nprint(\"The oldest customer's enrolment date in the records:\",min(dates))\n\n\n\ndays = []\nd1 = max(dates) \nfor i in dates:\n    delta = d1 - i\n    days.append(delta)\ndf[\"Customer_days\"] = days\ndf[\"Customer_days\"] = pd.to_numeric(df[\"Customer_days\"], errors=\"coerce\")","2f714819":"### Age will provide more clearity\ndf[\"Age\"] = 2021-df[\"Year_Birth\"]  \n\n## Let's see whole spending\ndf[\"Spent\"] = df[\"MntWines\"]+ df[\"MntFruits\"]+ df[\"MntMeatProducts\"]+ df[\"MntFishProducts\"]+ df[\"MntSweetProducts\"]+ df[\"MntGoldProds\"]\n\n\n## Let's define Marital Status in a more  better way to get more clarity how many members are in household\ndf[\"Living_With\"]=df[\"Marital_Status\"].replace({\"Married\":\"Partner\", \"Together\":\"Partner\", \"Absurd\":\"Alone\", \"Widow\":\"Alone\", \"YOLO\":\"Alone\", \"Divorced\":\"Alone\", \"Single\":\"Alone\",})\n\n## To get a more clarity about family's background\ndf[\"Children\"]=df[\"Kidhome\"]+df[\"Teenhome\"]\n\n\ndf[\"Family_Size\"] = df[\"Living_With\"].replace({\"Alone\": 1, \"Partner\":2})+ df[\"Children\"]\n\n\ndf[\"Is_Parent\"] = np.where(df.Children> 0, 1, 0)\n\n\n\n\n### Dropping the engineered features\nfeatures_to_drop = [\"ID\",\"Marital_Status\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Year_Birth\"]\ndf.drop(features_to_drop, axis=1,inplace = True)","da4dc54b":"df.head()","984de470":"df.describe()","c5109fec":"cont_vars = ['Income','Spent',\"MntWines\",\"MntFruits\",\"MntMeatProducts\",\"MntFishProducts\",\"MntSweetProducts\",\"MntGoldProds\",'NumDealsPurchases',\n       'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n       'NumWebVisitsMonth','Recency','Children']\n\n","afa4a48e":"\nplt.figure(figsize = (20,7))\nfor i in range(len(cont_vars)):\n    plt.subplot(5,3,i+1)\n    sns.scatterplot(data = df , y =cont_vars[i],x = 'Age',palette = 'viridis')\n    plt.tight_layout()\n    \n","7d2474dc":"df = df[(df[\"Age\"]<100)]\ndf = df[(df[\"Income\"]<600000)]\nprint(\"After Removing Outliers Number  of Datapoints are : \",len(df))","d709e8c8":"df.columns","794be43c":"plt.figure(figsize=(20,7))\nsns.heatmap(df.corr(),annot =True,cmap = \"YlGnBu\");","a748fbe0":"le = LabelEncoder()\ndf['Education'] = le.fit_transform(df['Education'])\ndf['Living_With'] = le.fit_transform(df['Living_With'])","a0b74004":"data = df.copy()","27aa5f31":"promotion_vars = ['AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1','AcceptedCmp2', 'Complain', 'Response']\ndata.drop(promotion_vars,axis=1,inplace = True)","c25fefb5":"# let's scale every column\nsc = StandardScaler()\n\nscaled_df = pd.DataFrame(sc.fit_transform(data),columns = data.columns)\nscaled_df.head()","aa4a7302":"pca = PCA(n_components = 3)\n\npca_df = pd.DataFrame(pca.fit_transform(scaled_df),columns = ['PC1','PC2','PC3'])\npca_df.head()","a361e144":"elbow= KElbowVisualizer(KMeans(), k=10)\nelbow.fit(pca_df)\nelbow.show();","bd6c04d2":"# iner = [] \n# for i in range(1, 11): \n#     kmeans = KMeans(n_clusters = i, init = 'k-means++')\n#     kmeans.fit(pca_df) \n#     iner.append(kmeans.inertia_)\n# plt.plot(range(1,11),iner,marker ='o')\n# plt.xlabel('K')\n# plt.ylabel('Distortion Scroe')\n# plt.show()","c696d4c1":"cluster = KMeans(n_clusters = 4).fit_predict(pca_df)\npca_df['cluster'] =cluster\npca_df.head()\n","8b0afcab":"## Let's put this clusters as a feature in data before it was processed\ndata['cluster'] = cluster","f9e903d1":"data.head()","3dbca2dd":"fig = plt.figure(figsize=(10,8))\nax = plt.subplot(111, projection='3d')\nax.scatter(pca_df['PC1'], pca_df['PC2'],pca_df['PC3'], c=pca_df[\"cluster\"], marker='o',s=50,cmap = 'brg' )\nplt.show()","5818304b":"sns.countplot(pca_df['cluster']);","c2977095":"sns.scatterplot(data = data,x = 'Spent',y = 'Income',hue = 'cluster',palette = 'viridis');","1a228ff4":"sns.boxenplot(x = 'cluster' , y ='Spent' ,data = data);","fddc8116":"# Spent vs Products\nProduct_vars = ['MntWines',\n       'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n       'MntGoldProds']\n\nfor i in Product_vars:\n    plt.figure(figsize = (7,7))\n    sns.barplot(x  = 'cluster' , y = i,data = data)\n    plt.show()\n    ","8375238c":"Personal_vars = ['Customer_days','Age','Education','Kidhome','Teenhome','Children','Family_Size','Is_Parent','Living_With']\nplt.figure(figsize = (10,7))\nfor i in (Personal_vars):\n    \n    sns.catplot(data = data,x='cluster',y=i)\n    \n    \n    ","1e8e0f8e":"Place_vars = ['NumDealsPurchases', 'NumWebPurchases',\n       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']\n\nfor i in Place_vars:\n    plt.figure(figsize = (7,7))\n    sns.boxplot(x='cluster',y=i,data= data)\n    plt.show()","b77d5921":"df['cluster'] = cluster\ndf[\"Total\"] = df[\"AcceptedCmp1\"]+ df[\"AcceptedCmp2\"]+ df[\"AcceptedCmp3\"]+ df[\"AcceptedCmp4\"]+ df[\"AcceptedCmp5\"]\n\nsns.countplot(x=df[\"Total\"],hue=df[\"cluster\"]);\n\n","d1429742":"sns.boxenplot(y = 'NumDealsPurchases',x = 'cluster',data=data);","87ce5ea5":"sns.countplot(df[\"Response\"] , hue= df['cluster']);","3a1f7535":"promotion_vars.append('NumDealsPurchases')\npromotion_vars.remove('Complain')\npromotion_vars","4234d4f2":"df_promotion = df[promotion_vars]\ndf_promotion.head() ","eb41c794":"sns.countplot(df['Total'],hue = df['Response']);","3ebdc3a3":"train,test = train_test_split(df_promotion,test_size= 0.2)\n","2b4a5d2b":"X_train = train.drop('Response',axis = 1)\ny_train = train['Response']\nX_test = test.drop('Response',axis = 1)\ny_test = test['Response']","8c3d895c":"xgb = XGBClassifier()\nfit =xgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\naccuracy_score(y_pred,y_test)","e1cf2ded":"pred = xgb.predict(X_test, output_margin=True)\nexplainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(X_test)\nnp.abs(shap_values.sum(1) + explainer.expected_value - pred).max()","b671c50e":"shap.summary_plot(shap_values, X_test)","de817a6a":"### Group 3 spend more on wines and gold.\n","26481539":"# Conclusion Segmentation\n\n## Write a short text of what is the key business takeaway of the recommendation.","f05b2a88":"Z_Revenue and Z_Cost should be removed as they don't contribute anything to training","f0c3a90b":"# Loading Data","a2f29a9e":"## Group 0 <br>\n- high spending and average income\n- Are a parent\n- Are older\n- has teen at home\n- Family size is atleast 2\n\n\n\n## Group 1 \n- high spending and high income\n- More number of store purchases and catalog purchases\n- Family size is atmost 3\n- Atmost 1 child\n- Spend on all products\n\n## Group 2 \n- low spending and low income\n- more web visits\n- at most 2 children\n- have only 1 teen\n\n## Group 3 \n- high spending and low income\n- spends more on wines and gold.\n- more store purchases\n- atleast size of family is 2\n- definitely a parent\n ","347ce85c":" # Classification ","5ddfaab7":"- [Importing Libraries](#Importing-Libraries)\n- [Loading Data](#Loading-Data)\n- [Auto EDA](#Auto-EDA)\n- [Feature Engineering](#Feature-Engineering)\n- [Visualize](#Visualize)\n- [Removing Outliers](#Removing-Outliers)\n- [Preprocessing for Modelling](#Preprocessing-For-Modelling)\n- [Dimensionality Reduction](#Dimensionality-reduction-PCA)\n- [Clustering](#Clustering)\n- [Insights](#Get-insights)\n- [Conclusion Segmentation](#Conclusion-Segmentation)\n- [Promotion EDA](#Promotion-EDA)\n- [SHAP Analysis](#SHAP-Analysis)\n- [Classification](#Classification)\n- [Conclusion Promotion](#Conclusion-Promotion)","b092e4d6":"### It looks like income too has outliers!","c96c15b2":"### Group 1 is the biggest spender","5dd79532":"# Preprocessing For Modelling","22c6104d":"- Group 0: high spending and average income\n- Group 1: high spending and high income\n- Group 2: low spending and low income\n- Group 3: high spending and low income\n","d04a7189":"# Auto EDA\n\nthis will help to get some crucial insights easily.. ","832bb147":"# Removing Outliers","4adda0f4":"# SHAP Analysis","2b193d06":"# Feature Engineering","ae25767f":"# Elbow Method","86521d3e":"# Dimensionality reduction PCA","ad97bd5f":"# Get insights","40767734":"# Importing Libraries","90227fae":"# Visualize","dbaf9292":"### Removing all the Promotion Variables","5966cb4e":"# Clustering","557ecf14":"### Group 1 is not much into Deals even it has high income","d5fc3d7c":"# Table Of Contents","1d04949a":"# Conclusion Promotion","b6c65fa2":"### Promotions overall has'nt done very well","f5ad2112":"There seems to be outliers in Age as 128 is highest.<br>\nThis can be clearly seen but some may not let's go for plotting","eb3439a1":"### Run SHAP analysis on the model results, and write a short text of what would be your recommendation to business for the next round of campaigns.?\n\n<i>It looks like the campaigns had a very least effect on people and it has'nt pulled the audience to buy the product. Deals made with Disocunt may had been able to make more effect then Campaigns.Perhaps there is a need of better targeted and well planned campaigns.<i><br>\n##### Recommendation to business for the next round of campaigns.\n- Discounts can be mentioned in the campaigns\n- Campaigns should be  more family oriented as we saw our data mostly contains families\n- A strategy can be followed as we have already clustered data so we can provide valid recommendations to customers according to their interests.\n- Some discounts  can be made on products displayed via campaign so that to sell more products at a cheap rate. This will help to retain customers.\n-  Meat and Fish can be sold together at some discount rate.\n- Campaigns should represent cultural aspects of the country that will drive more people towards them.\n- Campaigns can use humour. As the memes will do the rest.\n- Social Media can be used more effectively.\n\n\n\n\n\n\n\n","7caceb0d":"# Promotion EDA","e9e97c46":"There are some missing values in income.Let's remove them."}}