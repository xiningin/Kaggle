{"cell_type":{"94d9eb8c":"code","6bf4e076":"code","cf2e74aa":"code","568dae20":"code","98b29954":"code","ed07a04b":"code","83d1de71":"code","f2a9cd9e":"code","f3a8e78e":"code","e4fbc3d7":"code","87a9f187":"code","b9ba5603":"code","bdf6eaf5":"code","6b908457":"code","35efb860":"code","5c78f288":"code","ef2cb4ec":"code","9e28d58f":"code","e7919983":"code","1116a9f7":"code","3b96db18":"code","0fc4cd77":"code","1fae0f0b":"code","59839ebb":"code","8504b906":"code","c36c4b5e":"code","adac58b1":"code","7995610e":"code","7c2ad789":"code","565e49f0":"code","f5e072b7":"code","e0f3d879":"code","c9d090c0":"code","98b72cf5":"code","f3efa75b":"code","773d83d3":"code","9cad8797":"code","0e432ea6":"code","a345b2d7":"code","915a812a":"code","1f5f4b32":"code","15ca3a97":"code","a6476139":"code","d743ce06":"code","f8be5a3e":"code","6dabcdcf":"code","c304ed51":"code","922459f0":"code","a5c291f5":"markdown","72a79a17":"markdown","3ee52423":"markdown","4963f992":"markdown","fd0d585d":"markdown"},"source":{"94d9eb8c":"import numpy as np \nimport os \nimport pandas as pd\nimport tensorflow\ndir_path = '.\/input'\n\ntrain_dir = os.path.join(dir_path,'train.csv')\ntest_dir = os.path.join(dir_path,'test.csv')","6bf4e076":"train_csv = pd.read_csv(train_dir)\ntest_csv = pd.read_csv(test_dir)\ntrain_csv.head()\ntrain_csv.shape","cf2e74aa":"split_df = pd.DataFrame([train_csv['pixels'][i].split() for i in range(train_csv.shape[0])])","568dae20":"train_joined = train_csv.join(split_df)","98b29954":"train_joined.drop('pixels',axis = 1,inplace = True)","ed07a04b":"Y_train = train_joined['emotion']","83d1de71":"X_train = train_joined.iloc[:,1:2305]","f2a9cd9e":"import matplotlib\nimport matplotlib.pyplot as plt \n\nx_train_raw = X_train.to_numpy()\ny_train_raw = Y_train.to_numpy()\n\nx_train = x_train_raw.astype(np.float64)\ny_train = y_train_raw.astype(np.int)\n\nx_train\/=255","f3a8e78e":"# Showing a couple of images taken from the train data set\nfig = plt.figure()\nax1 = fig.add_subplot(221)\nax1.imshow(x_train[0].reshape((48,48)))\nax2 = fig.add_subplot(222)\nax2.imshow(x_train[1].reshape((48,48)))\nax3 = fig.add_subplot(223)\nax3.imshow(x_train[2].reshape((48,48)))\nax4 = fig.add_subplot(224)\nax4.imshow(x_train[3].reshape((48,48)))\nplt.show()","e4fbc3d7":"# Looking at the histogram of the emotions \n#plt.hist(range(len(np.unique(y_train))),y_train)\n\nplt.hist(y_train_raw,range(6))\n\n# Emotion nb 1 seems to be very underrepresented, \n# with that lack of data it is most likely we will perform poorly on recognizing those","87a9f187":"print(x_train_raw.shape)\nprint(y_train_raw.shape)","b9ba5603":"# We build a train\/test data set\n# We have a lot of data (overall) so we can afford to take a relatively large validation set\nfrom sklearn.model_selection import train_test_split\n\nx_train,x_val, y_train,y_val = train_test_split(x_train,y_train,test_size = 0.2,stratify = y_train_raw)","bdf6eaf5":"print(x_train.shape)\nprint(y_train.shape)\nprint(y_val.shape)","6b908457":"plt.hist(y_val,range(6),label='histogram of the validation set')\nplt.hist(y_train,range(6),fc= (0,0,1,0.5),label='histogram of the training set')\nplt.legend()\nplt.xlabel('Classes')\nplt.ylabel('Instances')\nplt.show()","35efb860":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(x_train, y_train)","5c78f288":"pred = rf.predict(x_val)","ef2cb4ec":"from sklearn.metrics import accuracy_score\n\nscore = accuracy_score(pred,y_val)\n# 44 % Accuracy\nprint('Accuracy of the random forest classifier :',score)\n\n# We have managed to get better than a random classifier (around 1\/7)\n# This is a good baseline model\n\n# We use it to show the importance of the pixels \n\nfi = rf.feature_importances_\nplt.imshow(np.reshape(fi,(48,48)))\nplt.show()\n\n# Showing a couple of images taken from the train data set\nfig = plt.figure()\nax1 = fig.add_subplot(221)\nax1.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nax2 = fig.add_subplot(222)\nax2.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nax3 = fig.add_subplot(223)\nax3.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nax4 = fig.add_subplot(224)\nax4.imshow(x_train[np.random.randint(15)].reshape((48,48)))\nplt.show()","9e28d58f":"# We will now train a convnet (duh) to tacke the problem\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical","e7919983":"x_train = np.reshape(x_train,(x_train.shape[0],48,48,1))\nx_val = np.reshape(x_val,(x_val.shape[0],48,48,1))","1116a9f7":"y_train = to_categorical(y_train)\ny_val = to_categorical(y_val)","3b96db18":"import tensorflow\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu', padding = 'same',input_shape = (48,48,1)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(64,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(7,activation='softmax'))\nmodel.summary()","0fc4cd77":"model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(x_train,y_train,validation_data = (x_val,y_val),epochs = 50, batch_size = 128)","1fae0f0b":"# First model, only a bit better than the random forest \n# Lets see what's wrong with it\n\n# A first obvious thing is the fact that is not complex enough to learn the training set\n# We are quite obviously under fitting\n\n# Lets try to make the model a bit more complex to make the hypothesis space larger ","59839ebb":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1,len(loss)+1)\n\nplt.plot(epochs,loss,'bo',label='training loss')\nplt.plot(epochs,val_loss,'b',label='val loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.show()\n\nplt.plot(epochs,acc,'bo',label='training acc')\nplt.plot(epochs,val_acc,'b',label='val acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('accuracies')\nplt.show()\n","8504b906":"model_2 = Sequential()\n\nmodel_2.add(Conv2D(256,(3,3),activation = 'relu', padding = 'same',input_shape = (48,48,1)))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Conv2D(256,(5,5),activation = 'relu', padding = 'same'))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Conv2D(256,(5,5),activation = 'relu', padding = 'same'))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Conv2D(256,(5,5),activation = 'relu', padding = 'same'))\nmodel_2.add(MaxPooling2D(2,2))\nmodel_2.add(Dropout(0.3))\n\n\nmodel_2.add(Flatten())\nmodel_2.add(Dense(256,activation='relu'))\nmodel_2.add(Dense(256,activation='relu'))\nmodel_2.add(Dense(7,activation='softmax'))\nmodel_2.summary()\n\nmodel_2.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model_2.fit(x_train,y_train,validation_data = (x_val,y_val),epochs = 20, batch_size = 128,verbose=1)\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1,len(loss)+1)\n\nplt.plot(epochs[1:],loss[1:],'bo',label='training loss')\nplt.plot(epochs[1:],val_loss[1:],'b',label='val loss')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.show()\n\nplt.plot(epochs,acc,'bo',label='training acc')\nplt.plot(epochs,val_acc,'b',label='val acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('accuracies')\nplt.show()\n","c36c4b5e":"# The model is severely over fitting, so we'll try to tune the first one a bit \n\n# We now use a pretrained model, facenet","adac58b1":"m_pre = Sequential()\nfrom tensorflow.keras.applications import InceptionResNetV2\n\n# Since ResNetV2 expects 3 input channels we repeat the image\n\nx_train_3c = x_train[:,:,:,:,np.newaxis]\nx_train_3c.shape\nx_train_rgb = np.repeat(x_train, 3, -1)\n\nplt.imshow(x_train_rgb[0,:,:,0].reshape(48,48))\nplt.show()\nplt.imshow(x_train_rgb[0,:,:,1].reshape(48,48))\nplt.show()\nplt.imshow(x_train_rgb[0,:,:,2].reshape(48,48))\nplt.show()\n\nx_val_rgb = np.repeat(x_val,3,-1)\n\n# It worked","7995610e":"print(x_val_rgb.shape)\nprint(x_train_rgb.shape)","7c2ad789":"conv_base = InceptionResNetV2(include_top = False,weights ='imagenet')","565e49f0":"conv_base.trainable = False","f5e072b7":"model = Sequential()\nmodel.add(tensorflow.keras.layers.ZeroPadding2D((75,75), input_shape = (48,48,3)))","e0f3d879":"model.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(128, activation ='relu'))\nmodel.add(Dense(7,activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop',metrics = ['accuracy'],loss='categorical_crossentropy')","c9d090c0":"history = model.fit(x_train_rgb,y_train, validation_data = (x_val_rgb,y_val), epochs = 20, batch_size = 256)","98b72cf5":"# the model is very, very long to train, and I don't have the ressources to experiment on it, so we'll keep the handmade one","f3efa75b":"# We train the model on the validation + training data set","773d83d3":"x_train_full = np.concatenate((x_train,x_val))","9cad8797":"y_train_full = np.concatenate((y_train,y_val))\ny_train_full.shape","0e432ea6":"full = os.path.join(dir_path, 'icml_face_data.csv')\n\nfull_csv = pd.read_csv(full)","a345b2d7":"cop[full_csv['Usage'] != 'Training']","915a812a":"testing_csv = full_csv[full_csv['Usage'] == 'PublicTest']\nprivate_csv = full_csv[full_csv['Usage'] == 'PrivateTest']","1f5f4b32":"testing_csv.drop('Usage',axis=1,inplace=True)\nprivate_csv.drop('Usage',axis=1,inplace=True)","15ca3a97":"testing_csv.reset_index(inplace=True)\nprivate_csv.reset_index(inplace=True)","a6476139":"def convert_tests(df):\n    \n    # We plit the data set \n    split_df_test = pd.DataFrame([df['pixels'][i].split() for i in range(df.shape[0])])\n    temp_joined = df.join(split_df_test)\n    \n    # We drop the pixels column\n    temp_joined.drop('pixels',axis = 1,inplace = True)\n    \n    # We get the X : pixels \n    X = temp_joined.iloc[:,1:2305]\n    x_raw = X.to_numpy()\n    x = x_raw.astype(np.float64)\n    x\/=255\n\n    # We get the Y : labels\n    Y = temp_joined['emotion']\n    y_raw = Y.to_numpy()\n    y = y_raw.astype(np.int)\n    y = to_categorical(y)\n\n    x = np.reshape(x,(x.shape[0],48,48,1))\n    \n    print('Shape of attributes matrix',x.shape)\n    print('Shape of label matrix',y.shape)\n    \n    return x,y","d743ce06":"x_public, y_public = convert_tests(testing_csv)\nx_private,y_private = convert_tests(private_csv)","f8be5a3e":"plt.imshow(x_public[2].reshape(48,48))\nplt.show()\ny_public[2]","6dabcdcf":"import tensorflow\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu', padding = 'same',input_shape = (48,48,1)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(64,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128,(3,3),activation = 'relu', padding = 'same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(7,activation='softmax'))\nmodel.summary()\n\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n\nhistory = model.fit(x_train_full,y_train_full,epochs = 150, batch_size = 128)\n\nloss = history.history['loss']\n\nacc = history.history['accuracy']\n\nepochs = range(1,len(loss)+1)\n\nplt.plot(epochs,loss,'bo',label='training loss')\nplt.plot(epochs,acc,'b',label='training acc')\nplt.legend()\nplt.xlabel('epochs')\nplt.ylabel('losses')\nplt.show()","c304ed51":"model.evaluate(x_private,y_private)","922459f0":"model.save('model_facial_recognition.h5')","a5c291f5":"# Evaluation\n\n","72a79a17":"# My Model Accuracy : 62.41 % (10\/58)","3ee52423":"Interesting fact, the model seems to look for clues mainly around the mouth, gives importance to the cheeks, and also a bit to the forehead. Pretty much what we do as humans ! ","4963f992":"# MODEL 2 ","fd0d585d":"# MODEL 1"}}