{"cell_type":{"a7e276e8":"code","92db0583":"code","4224c8d9":"code","79a53e41":"code","5e3be38b":"code","59a5f136":"code","1e3686c2":"code","56d748d6":"code","7049af4e":"code","264fdef0":"code","23a95074":"code","45ba9f03":"code","d439cfb9":"code","23b23a3d":"code","cbb3dc53":"code","447a880d":"code","93bff53e":"code","24590285":"code","1efc39f5":"markdown","4964476d":"markdown","361c614b":"markdown","3a9c9689":"markdown","217b38b4":"markdown","f9b5bf53":"markdown","d9a427f0":"markdown","d01ab12d":"markdown","450facc2":"markdown","8e4ccc8c":"markdown","48beb9e3":"markdown","9e78f630":"markdown","057f4108":"markdown","a0c050ae":"markdown","677c021a":"markdown","b9d7f297":"markdown","858d5ca4":"markdown","c3750c46":"markdown"},"source":{"a7e276e8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92db0583":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4224c8d9":"# Viewing data head and types\nprint(df.head())\nprint(df.dtypes)\nprint(df.size)","79a53e41":"firstclass = df.loc[df.Pclass == 1][\"Survived\"]\nrate_1stclass = sum(firstclass)\/len(firstclass)\n\nsecondclass = df.loc[df.Pclass == 2][\"Survived\"]\nrate_2ndclass = sum(secondclass)\/len(secondclass)\n\nthirdclass = df.loc[df.Pclass == 3][\"Survived\"]\nrate_3rdclass = sum(thirdclass)\/len(thirdclass)\n\nprint(\"% of 1st class who survived:\", rate_1stclass)\nprint(\"% of 2nd class who survived:\", rate_2ndclass)\nprint(\"% of 3rd class who survived:\", rate_3rdclass)","5e3be38b":"men = df.loc[df.Sex == \"male\"][\"Survived\"]\nrate_men = sum(men)\/len(men)\nwomen = df.loc[df.Sex == \"female\"][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of men who survived:\", rate_men)\nprint(\"% of women who survived:\", rate_women)","59a5f136":"ages = df['Age']\nages_survived = df.query('Survived==1')['Age']\n\nplt.hist(ages, bins=10)\nplt.show()\nplt.hist(ages_survived, bins=10)\nplt.show()\n# Largely looks the same, but might be something there for younger passengers","1e3686c2":"fares = df['Fare']\nplt.hist(fares, bins=50)\nplt.show()\nfares_survived = df.query('Survived==1')['Fare']\nplt.hist(fares_survived, bins=50)\nplt.show()","56d748d6":"# Parch = number of parents and children aboard\n# SibSp = number of siblings and spouses aboard\n# I really feel like those two should be split up into four, but we're gonna roll with it.\n\nprint(df['Parch'].max())\nprint(df['Parch'].min())\nparch = df['Parch']\nplt.hist(parch, bins=6)\nplt.show()\nparch_survived = df.query('Survived==1')['Parch']\nplt.hist(parch_survived, bins=6)\nplt.show()\n\nprint(df['SibSp'].max())\nprint(df['SibSp'].min())\nsibsp = df['SibSp']\nplt.hist(sibsp, bins=8)\nplt.show()\nsibsp_survived = df.query('Survived==1')['SibSp']\nplt.hist(sibsp_survived, bins=4)\nplt.show()","7049af4e":"embarked_S = df.loc[df.Embarked == 'S'][\"Survived\"]\nrate_S = sum(embarked_S)\/len(embarked_S)\n\nembarked_Q = df.loc[df.Embarked == 'Q'][\"Survived\"]\nrate_Q = sum(embarked_Q)\/len(embarked_Q)\n\nembarked_C = df.loc[df.Embarked == \"C\"][\"Survived\"]\nrate_C = sum(embarked_C)\/len(embarked_C)\n\nprint(\"% survival for those departing from S:\", rate_S)\nprint(\"% survival for those departing from Q:\", rate_Q)\nprint(\"% survival for those departing from C:\", rate_C)\n\n## looks like noise. will drop","264fdef0":"pid = df['PassengerId']\npid_survived = df.query('Survived==1')['PassengerId']\nplt.hist(pid)\nplt.show()\nplt.hist(pid_survived)\nplt.show()\n# Nothing much there; not surprising.\n# Going to skip name, ticket numnber, and cabin number since those are going to be totally irrelevant, just like the passenger id","23a95074":"# more imports for our assorted models\nfrom sklearn.linear_model import LinearRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\n\ny = df[['Survived']]","45ba9f03":"# Creating training variables\nX_train = df.drop(['PassengerId', 'Name', 'Survived', 'Ticket', 'Cabin', 'Embarked'], axis=1)\nsex = pd.get_dummies(X_train, drop_first=False)\nX_train = X_train.drop('Sex', axis=1)\nX_train = pd.concat([sex], axis=1)\n\n# there are some empty ages. we replace them with the mean\nX_train['Age'] = X_train['Age'].replace(np.nan, X_train['Age'].mean())\n#X_train['Age'] = X_train['Age'].replace(np.nan, 0)\n\n# our y_train data\ny_train = df['Survived']\n\n# Creating test data variable\nX_test = test_data.drop([\"PassengerId\", 'Name', 'Ticket', 'Cabin', 'Embarked'], axis=1).copy()\nsex = pd.get_dummies(X_test, drop_first=False)\nX_test = X_test.drop('Sex', axis=1)\nX_test = pd.concat([sex], axis=1)\n\n# Filling empty values in test data with their col's mean\nX_test['Age'] = X_test['Age'].replace(np.nan, X_test['Age'].mean())\n#X_test['Age'] = X_test['Age'].replace(np.nan, 0)\nX_test['Fare'] = X_test['Fare'].replace(np.nan, X_test['Fare'].mean())","d439cfb9":"# Model creation\nreg = LinearRegression()\nreg.fit(X_train, y_train)\ncoeffs = reg.coef_\nprint(\"Coeffs: \", coeffs)\ny_pred = reg.predict(X_test)\nrsq = reg.score(X_train, y_train)\nprint(\"R-squared value: \", rsq)\n# .3949\n# oh no\n# that's awful\n# it's even worse if you replace the missing ages in X_train with 0 instead of the mean\n# but an r^2 < .40 is basically unusable. let's move on\n# also, i put in a lot of time and effort into getting a variable with a coeff of 0.0004 to work and now i'm sad","23b23a3d":"# most of train and test data is already in a usable form from the previous block(s)\n\n# model creation. starting with n_n=5. also tested with n_n=3\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\n\n# scoring\nprint(\"Mean accuracy: \", knn.score(X_train, y_train))\n# .8204 for our accuracy is much better. we can work with that","cbb3dc53":"# Building the CLF based on the docs on the scikit site\nclf = DecisionTreeClassifier(random_state=42)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\n# scoring\nprint(clf.score(X_train, y_train))\n# Wow, .9820\n# That's probably too good to be true, but such is life","447a880d":"# Building the SGD model\nsgd = SGDClassifier(max_iter=10000, tol=1e-3)\nsgd.fit(X_train, y_train)\ny_pred = sgd.predict(X_test)\n\n# Scoring\nprint(sgd.score(X_train, y_train))\n# .7015 on first run with max_iter=10000","93bff53e":"# Multiple Linear Regression model\nprint(\"Coefficients of Multiple Linear Regression Model: \", coeffs)\nprint(\"R-squared value of Multiple Linear Regression Model: \", rsq)\n\n# KNN\nprint(\"Mean accuracy of KNN: \", knn.score(X_train, y_train))\n\n# Decision Tree\nprint(\"Mean accuracy of Decision Tree: \", clf.score(X_train, y_train))\n\n# SGD\nprint(\"Mean accuracy of SGD: \", sgd.score(X_train, y_train))","24590285":"# since the decision tree data consistently scores the best with the .score function, we'll use that.\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","1efc39f5":"# Examining parch and sibsp","4964476d":"# Examining Survival Rate by Port","361c614b":"# Default Kaggle Block + Other Imports","3a9c9689":"# Building the Models","217b38b4":"# Examining Survival rate by Age","f9b5bf53":"# Linear Regression Model(s)","d9a427f0":"# Loading training data into a dataframe ","d01ab12d":"# Examining survival rate by sex","450facc2":"# Generating submission data for best model","8e4ccc8c":"# Examining survival rate by pid","48beb9e3":"# Examining survival rate by Fare price","9e78f630":"# Exploratory Data Analysis","057f4108":"# Evaluating the Models","a0c050ae":"# Decision Trees","677c021a":"# KNN Model","b9d7f297":"# SDG Classifier Model","858d5ca4":"# Examining survival rate by Pclass","c3750c46":"# Modifying data so that it can be used in models"}}