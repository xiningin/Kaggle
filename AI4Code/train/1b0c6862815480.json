{"cell_type":{"eabc8af6":"code","c1fae4fa":"code","db5035d7":"code","dec88f04":"code","f6c28451":"code","56d35429":"code","265355f4":"code","57879773":"code","bd0ff008":"code","79e5e875":"code","932749d1":"markdown","a2a1d730":"markdown","4354f19e":"markdown","d49bc51b":"markdown","74eb8fb1":"markdown","7470d7e4":"markdown","db71b11c":"markdown","36efc47f":"markdown","4ef3a11c":"markdown","7233592a":"markdown","bc8d7b78":"markdown"},"source":{"eabc8af6":"import os\nfrom distutils.dir_util import copy_tree\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import preprocessing\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, experimental","c1fae4fa":"# copy data current directory to working directory\nmain_dir = \"..\/input\/microsoft-catsvsdogs-dataset\/PetImages\/\"\n\n# create dataset directory path\nwork_dir = \"\/kaggle\/working\/PetImages\/\"\n\ncopy_tree(main_dir, work_dir)","db5035d7":"# Let's create function to filter & remove corrupted images\ndef CorruptImage():\n    num_corrupted = 0\n    for category in (\"Cat\", \"Dog\"):\n        path = os.path.join(work_dir, category)\n\n        for img in os.listdir(path):\n            image_path = os.path.join(path, img)\n            try:\n                file_Obj = open(image_path, \"rb\")\n                is_jfif = tf.compat.as_bytes(\"JFIF\") in file_Obj.peek(10)\n            finally:\n                file_Obj.close()\n            \n            if not is_jfif:\n                num_corrupted +=1\n                os.remove(image_path)\n    print(\"Total deleted images is = %d\" % num_corrupted)\n\nCorruptImage()","dec88f04":"# Let's function to remove non jpg images\ndef NonJpg():\n    j=0\n    for catagory in os.listdir(work_dir):\n        sub_folder = os.path.join(work_dir, catagory)\n        for name in os.listdir(sub_folder):\n            img_path = os.path.join(sub_folder,name)\n            if name.split('.')[1] == 'jpg':\n                if os.path.getsize(img_path) <= 0:\n                    if os.path.isfile(img_path) == False:\n                        print(img_path)\n                    os.remove(img_path)\n                elif os.path.getsize(img_path) > 0:\n                    j +=1\n            if name.split('.')[1] != 'jpg':\n                print(img_path)\n                os.remove(img_path)\n    print(j)\nNonJpg()","f6c28451":"# Let's split image dataset into Train & validation\n\nimage_size = (128, 128)\n\ntrain_dataset = preprocessing.image_dataset_from_directory(\n    work_dir,\n    image_size = image_size,\n    validation_split= 0.2,\n    subset=\"training\",\n    batch_size =32,    \n    seed = 1337,\n    shuffle = True,\n)\n\ntest_dataset = preprocessing.image_dataset_from_directory(\n    work_dir,\n    image_size = image_size,\n    validation_split = 0.2,\n    subset = \"validation\",\n    batch_size = 32,    \n    seed = 1337,\n    shuffle= True,\n)","56d35429":"# image visualization function\ndef dataVisual():\n    plt.figure(figsize=(10,10))\n    for images, labels in train_dataset.take(1):\n        for i in range(9):\n            ax =plt.subplot(3,3, i+1)\n            plt.imshow((images[i].numpy().astype(\"uint8\")))\n            plt.title(int(labels[i]))\n            plt.axis(\"off\")\n\ndataVisual()","265355f4":"# Let's create callback function\nearlystop = EarlyStopping(monitor=\"loss\", patience=5)\nl_rate_reduce = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.5, verbose=1, min_lr=0.0001)\ncallback = [earlystop, l_rate_reduce]","57879773":"if tf.keras.backend.image_data_format() == \"channels_first\":\n    input_shapes = (3, 128, 128)\nelse:\n    input_shapes = (128, 128, 3)\n\nmodel=Sequential()\n\nmodel.add(experimental.preprocessing.Rescaling(1.0\/255, input_shape=(input_shapes)))\n\nmodel.add(Conv2D(16,(3,3),activation='relu',input_shape=input_shapes))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))","bd0ff008":"model.compile(\n    loss='binary_crossentropy', \n    optimizer='adam', \n    metrics=['accuracy']\n)\n\nmodel.fit(\n    train_dataset, \n    epochs=15,\n    verbose=1, \n    callbacks=callback, \n    validation_data=test_dataset,\n)","79e5e875":"# Let's save the trained model\nkeras.models.save_model(\n    model,\n    \"cats_dogs_classification_model.h5\"\n)","932749d1":"### Visualizing the train images","a2a1d730":"### Saving the model","4354f19e":"### Trained the Model","d49bc51b":"### Creating Callbacks Function","74eb8fb1":"### Spliting the image dataset","7470d7e4":"# Cats and Dogs classification with convolutional Neural Network\n### (No pretrained model or transfer learning techniques)","db71b11c":"## Import necessary libaries ","36efc47f":"### Building a CNN Model","4ef3a11c":"### Removing non jpg images from database","7233592a":"## Loading data ","bc8d7b78":"### Filter and remove corrupted images"}}