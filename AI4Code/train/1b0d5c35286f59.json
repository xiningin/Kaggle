{"cell_type":{"f0002ffe":"code","294c6ca4":"code","a8ed3321":"code","b943037c":"code","57abf217":"code","fb5bdbc8":"code","b4bc2c5c":"code","29bff027":"code","458582af":"code","38f5b78f":"code","e6d7d68d":"code","d430c5ee":"code","e2ec6f81":"code","83c2d55b":"code","dfaa5816":"code","1524b450":"code","8f810cf2":"code","e9309649":"code","08a2fec0":"code","c85e7a1d":"code","8b249a35":"code","36017bf8":"code","2977ed11":"code","8096cc7a":"code","b708d5a6":"markdown","bd53bdf2":"markdown"},"source":{"f0002ffe":"# import important libraries\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","294c6ca4":"# load dataset\ndf=pd.read_csv('\/kaggle\/input\/parkinsons-data-set\/parkinsons.data')","a8ed3321":"# top 5 rows\ndf.head()","b943037c":"# check rows and features in Parkinsons Data\ndf.shape","57abf217":"# some important info about data like null values ,datatype\ndf.info()\n\n# in this dataset there is no null values ","fb5bdbc8":"# Data Analysis With Matplotlib and Seaborn\nnumeric_columns=df.select_dtypes(include=['float','int']).columns\nstring_columns=df.select_dtypes(include='object').columns\n# Total Numeric Columns\nlen(numeric_columns)","b4bc2c5c":"# univariant analysis \n# histogram\nplt.figure(figsize=(30,35))\nfor i,v in enumerate(numeric_columns,1):\n    plt.subplot(6,5,i)\n    plt.title(v)\n    sns.distplot(df[v],bins=10)\nplt.show();","29bff027":"# target variable analysis\nsns.countplot(df['status']);\n","458582af":"# target variable check percentage using pie chart\ndf['status'].value_counts().plot(kind='pie',autopct='%.2f');\n","38f5b78f":"# check outliers\nplt.figure(figsize=(25,30))\nfor i,col in enumerate(numeric_columns,1):\n    plt.subplot(6,4,i)\n    sns.set_theme(style=\"whitegrid\")\n    plt.title(col)\n    sns.boxplot(df[col])\n        \nplt.show()\n","e6d7d68d":"# now fixed outlier using capping technique\n# Computing 10th, 90th percentiles and replacing the outliers\nimport numpy as np\ntenth_per=[]\nninety_per=[]\nfor i,col in enumerate(numeric_columns,1):\n    tenth_percentile = np.percentile(df[col], 10)\n    tenth_per.append(tenth_percentile)\n    ninetieth_percentile = np.percentile(df[col], 90)\n    ninety_per.append(ninetieth_percentile)\n#     print(f\"{i}  tenth percentile {tenth_percentile} ninetieth percentile {ninetieth_percentile}\")\n    \n    ","d430c5ee":"# capping\nfor index,i in enumerate(numeric_columns):\n    df[i]=df[i].apply(lambda x : tenth_per[index] if (x<tenth_per[index]) else x)\n    \n    df[i]=df[i].apply(lambda x : ninety_per[index] if (x>ninety_per[index]) else x)","e2ec6f81":"# after capping all values\n# check outliers once again\nplt.figure(figsize=(25,30))\nfor i,col in enumerate(numeric_columns,1):\n    plt.subplot(6,4,i)\n    sns.set_theme(style=\"whitegrid\")\n    plt.title(col)\n    sns.boxplot(df[col])\n        \nplt.show()","83c2d55b":"# check correlation \nplt.figure(figsize=(19,7))\nsns.heatmap(df.corr(),annot=True);","dfaa5816":"# top 5 rows\ndf.head()","1524b450":"# independent and dependent variable\nx=df.drop(columns=['name','status'],axis=1)\ny=df['status']","8f810cf2":"# Data Standardization\n# Al the values of the dataset of all the columns varies. So we need to convert all the values in a common range.\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx=scaler.fit_transform(x)","e9309649":"# divide in test and train data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=2)","08a2fec0":"# model selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\ndef best_model(model,X,y):\n    xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)\n    print(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)\n    model.fit(xtrain,ytrain)\n    print('Train Score',model.score(xtrain,ytrain))\n    pred=model.predict(xtest)\n    print('Prediction Score',accuracy_score(pred,ytest))\n    print('Test Score',model.score(xtest,ytest))\n    print(\"***********************************************\")\n    print(confusion_matrix(ytest,pred))\n    print(\"***********************************************\")\n    print(\"Precision Score\",precision_score(ytest,pred))\n    print(\"Recall Score\",recall_score(ytest,pred))\n    \n    ","c85e7a1d":"# logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nbest_model(lr,x,y)","8b249a35":"# svc\nfrom sklearn.svm import SVC\nsvc=SVC(kernel='linear')\nbest_model(svc,x,y)","36017bf8":"# k nearest neighbour\nfrom sklearn.neighbors import KNeighborsClassifier  \nclassifier= KNeighborsClassifier(n_neighbors=5 )  \nbest_model(classifier,x,y)","2977ed11":"# random forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nbest_model(rf,x,y)","8096cc7a":"x=[119.992,157.302,75.6146,0.007840,0.00007,40,0.00370,55,455,76,0.005540,0.011090,0.043740,0.06545,0.022110,21.033,0.414783,0.789799,-4.813031,0.266482,2.301442,0.284654]\nresult=svc.predict(scaler.fit_transform([x]))\nif result[0]==1:\n    print(\"Parkinsons Disease\")\nelse:\n    print('Healthy')","b708d5a6":"# Parkinsons disease\nA disorder of the central nervous system that affects movement, often including tremors.\nNerve cell damage in the brain causes dopamine levels to drop, leading to the symptoms of Parkinson's.\nParkinson's often starts with a tremor in one hand. Other symptoms are slow movement, stiffness and loss of balance.\nMedication can help control the symptoms of Parkinson's.\n\n\n# What are the risk factors for Parkinson's disease?\n\nAge,Sex,Genetic factors\nHead trauma,Exposure to chemicals,Medications and other drugs,Impact of smoking.\n\n","bd53bdf2":"svc has highest accuracy score because\n\nEffective in high dimensional spaces.\n\nStill effective in cases where number of dimensions is greater than the number of samples.\n\n"}}