{"cell_type":{"fa69105f":"code","814e6efb":"code","d4964bf6":"code","ee19ef9f":"code","90952983":"code","16dd40c0":"code","bc3ab9fb":"code","29f8255c":"code","cec1749b":"code","7510ca20":"code","32c3deb3":"code","8bc3a31f":"code","c5879fb4":"code","7390214e":"code","8ba7b94b":"code","6c84eb4e":"code","5e590cfa":"code","e2fcc183":"code","6610579e":"code","e5b718fa":"code","d715d674":"code","302c95a8":"markdown"},"source":{"fa69105f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical","814e6efb":"directory = '..\/input\/english-handwritten-characters-dataset\/Img'\nfiles=os.listdir(directory)\nprint(files[0:5])\nprint(len(files))","d4964bf6":"# filename and image data\ndatafile=[]\ndata=[]\nfor file in files:\n    image=load_img(os.path.join(directory,file),grayscale=False,color_mode='rgb',target_size=(100,100))\n    image=img_to_array(image)\n    image=image\/255.0\n    data+=[image]\n    datafile+=[file]\nprint(datafile[0:5])\nprint(len(datafile))","ee19ef9f":"data1=np.array(data)\nprint(data1.shape)","90952983":"# filename and label\nengl=pd.read_csv('..\/input\/english-handwritten-characters-dataset\/english.csv')\nengl.head()","16dd40c0":"factlabel=pd.factorize(engl['label'])\n\nprint(factlabel[0])\nprint(factlabel[1])","bc3ab9fb":"labelfile=[]\nfor item in engl['image']:\n    labelfile+=[item[4:]]\nengl['file']=labelfile\nengl['labeln']=factlabel[0]\n\nprint(engl.head())","29f8255c":"# set labels in image data order\nengl2=[]\nfor item in datafile:\n    engl2+=[engl['labeln'][engl['file']==item].values[0]]\n    \nprint(engl2[0:5])\nprint(datafile[0:5])","cec1749b":"labels1=to_categorical(engl2)\nlabels2=np.array(labels1)\n\nprint(\"Data Shape:{}\\nLabels shape: {}\".format(data1.shape,labels2.shape))","7510ca20":"from sklearn.model_selection import train_test_split\ntrainx,testx,trainy,testy=train_test_split(data1,labels2,test_size=0.2,random_state=44)","32c3deb3":"print(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","8bc3a31f":"datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rotation_range=20,zoom_range=0.2,\n                    width_shift_range=0.2,height_shift_range=0.2,shear_range=0.1,fill_mode=\"nearest\")","c5879fb4":"pretrained_model0 = tf.keras.applications.MobileNetV2(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model1 = tf.keras.applications.ResNet50(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model2 = tf.keras.applications.VGG16(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model3 = tf.keras.applications.DenseNet121(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model4 = tf.keras.applications.Xception(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\npretrained_model5 = tf.keras.applications.InceptionV3(input_shape=(100,100,3),include_top=False,weights='imagenet',pooling='avg')\n\npretrained_model0.trainable = False\npretrained_model1.trainable = False\npretrained_model2.trainable = False\npretrained_model3.trainable = False\npretrained_model4.trainable = False\npretrained_model5.trainable = False","7390214e":"inputs0 = pretrained_model0.input\ninputs1 = pretrained_model1.input\ninputs2 = pretrained_model2.input\ninputs3 = pretrained_model3.input\ninputs4 = pretrained_model4.input\ninputs5 = pretrained_model5.input\n\nx0 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model0.output)\noutputs0 = tf.keras.layers.Dense(62, activation='softmax')(x0)\nx1 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model1.output)\noutputs1 = tf.keras.layers.Dense(62, activation='softmax')(x1)\nx2 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model2.output)\noutputs2 = tf.keras.layers.Dense(62, activation='softmax')(x2)\nx3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model3.output)\noutputs3 = tf.keras.layers.Dense(62, activation='softmax')(x3)\nx4 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model4.output)\noutputs4 = tf.keras.layers.Dense(62, activation='softmax')(x4)\nx5 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model5.output)\noutputs5 = tf.keras.layers.Dense(62, activation='softmax')(x5)\n\nmodel0 = tf.keras.Model(inputs=inputs0, outputs=outputs0)\nmodel1 = tf.keras.Model(inputs=inputs1, outputs=outputs1)\nmodel2 = tf.keras.Model(inputs=inputs2, outputs=outputs2)\nmodel3 = tf.keras.Model(inputs=inputs3, outputs=outputs3)\nmodel4 = tf.keras.Model(inputs=inputs4, outputs=outputs4)\nmodel5 = tf.keras.Model(inputs=inputs5, outputs=outputs5)","8ba7b94b":"#model0.summary()\n#model1.summary()\n#model2.summary()\n#model3.summary()\n#model4.summary()\n#model5.summary()","6c84eb4e":"model0.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel3.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel4.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel5.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhis0=model0.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis1=model1.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis2=model2.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis3=model3.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis4=model4.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)\nhis5=model5.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=20)","5e590cfa":"y_pred0=model0.predict(testx)\ny_pred1=model1.predict(testx)\ny_pred2=model2.predict(testx)\ny_pred3=model3.predict(testx)\ny_pred4=model4.predict(testx)\ny_pred5=model5.predict(testx)\n\npred0=np.argmax(y_pred0,axis=1)\npred1=np.argmax(y_pred1,axis=1)\npred2=np.argmax(y_pred2,axis=1)\npred3=np.argmax(y_pred3,axis=1)\npred4=np.argmax(y_pred4,axis=1)\npred5=np.argmax(y_pred5,axis=1)\n\nground = np.argmax(testy,axis=1)\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(ground,pred0))\nprint(classification_report(ground,pred1))\nprint(classification_report(ground,pred2))\nprint(classification_report(ground,pred3))\nprint(classification_report(ground,pred4))\nprint(classification_report(ground,pred5))","e2fcc183":"get_acc0 = his0.history['accuracy']\nget_acc1 = his1.history['accuracy']\nget_acc2 = his2.history['accuracy']\nget_acc3 = his3.history['accuracy']\nget_acc4 = his4.history['accuracy']\nget_acc5 = his5.history['accuracy']\n\nepochs = range(len(get_acc0))\n\nplt.plot(epochs, get_acc0, 'r', label='MobileNetV2')\nplt.plot(epochs, get_acc1, 'b', label='ResNet50')\nplt.plot(epochs, get_acc2, 'g', label='VGG16')\nplt.plot(epochs, get_acc3, 'y', label='DenseNet121')\nplt.plot(epochs, get_acc4, 'm', label='Xception')\nplt.plot(epochs, get_acc5, 'c', label='InceptionV3')\n\nplt.title('Accuracy comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","6610579e":"get_loss0 = his0.history['loss']\nget_loss1 = his1.history['loss']\nget_loss2 = his2.history['loss']\nget_loss3 = his3.history['loss']\nget_loss4 = his4.history['loss']\nget_loss5 = his5.history['loss']\n\nepochs = range(len(get_loss0))\n\nplt.plot(epochs, get_loss0, 'r', label='MobileNetV2')\nplt.plot(epochs, get_loss1, 'b', label='ResNet50')\nplt.plot(epochs, get_loss2, 'g', label='VGG16')\nplt.plot(epochs, get_loss3, 'y', label='DenseNet121')\nplt.plot(epochs, get_loss4, 'm', label='Xception')\nplt.plot(epochs, get_loss5, 'c', label='InceptionV3')\n\nplt.title('Loss comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","e5b718fa":"value_acc0 = his0.history['val_accuracy']\nvalue_acc1 = his1.history['val_accuracy']\nvalue_acc2 = his2.history['val_accuracy']\nvalue_acc3 = his3.history['val_accuracy']\nvalue_acc4 = his4.history['val_accuracy']\nvalue_acc5 = his5.history['val_accuracy']\n\nepochs = range(len(get_acc0))\n\nplt.plot(epochs, value_acc0, 'r', label='MobileNetV2')\nplt.plot(epochs, value_acc1, 'b', label='ResNet50')\nplt.plot(epochs, value_acc2, 'g', label='VGG16')\nplt.plot(epochs, value_acc3, 'y', label='DenseNet121')\nplt.plot(epochs, value_acc4, 'm', label='Xception')\nplt.plot(epochs, value_acc5, 'c', label='InceptionV3')\n\nplt.title('Validation accuracy comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","d715d674":"val_loss0 = his0.history['val_loss']\nval_loss1 = his1.history['val_loss']\nval_loss2 = his2.history['val_loss']\nval_loss3 = his3.history['val_loss']\nval_loss4 = his4.history['val_loss']\nval_loss5 = his5.history['val_loss']\n\nepochs = range(len(val_loss0))\n\nplt.plot(epochs, val_loss0, 'r', label='MobileNetV2')\nplt.plot(epochs, val_loss1, 'b', label='ResNet50')\nplt.plot(epochs, val_loss2, 'g', label='VGG16')\nplt.plot(epochs, val_loss3, 'y', label='DenseNet121')\nplt.plot(epochs, val_loss4, 'm', label='Xception')\nplt.plot(epochs, val_loss5, 'c', label='InceptionV3')\n\nplt.title('Validation loss comparison')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","302c95a8":"## Keras applications ('MobileNetV2', 'ResNet50', 'VGG16', 'DenseNet121', 'Xception' and 'InceptionV3') were compared on English handwritten characters images.\n[https:\/\/keras.io\/api\/applications\/](https:\/\/keras.io\/api\/applications\/)"}}