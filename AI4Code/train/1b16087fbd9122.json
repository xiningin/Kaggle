{"cell_type":{"3f40c6d8":"code","ff17af0b":"code","975154ea":"code","9d618de9":"code","15966d5a":"code","f27ec41e":"code","3cede401":"code","5d247901":"code","bd09cc9c":"code","4641e3be":"code","8fea2af6":"code","274b0a1e":"code","ceaf0a24":"code","3c666926":"code","ae42db05":"code","2dac8863":"code","f9e14eba":"code","889842f7":"code","6fd43d3e":"code","86c71e40":"code","3c130ae7":"code","29bc2c27":"code","69346d53":"code","dd0cd407":"code","f055553f":"code","a39df5e6":"code","589d697c":"code","614c6b38":"code","a02c86f0":"code","e05147c2":"code","422fa9e7":"code","3844ab1a":"code","278ef109":"code","6f23d547":"code","a946bdde":"code","6a6e596a":"code","c925b0e0":"code","c10297ea":"code","1b957ed1":"code","4d987b41":"code","3803bb51":"code","b9d04a04":"code","c6e993f7":"code","a2fac92f":"code","c783cf4d":"code","cfd8f695":"code","b3de4c05":"code","7e00c75d":"code","04866ed6":"code","a74170a9":"code","eea5c8e4":"code","178faaae":"markdown","7b0ce6fe":"markdown","dae6edac":"markdown","4b1b59be":"markdown","44794e89":"markdown","31b6de2e":"markdown","bd7d0d13":"markdown","e02345a2":"markdown","6d19b506":"markdown","9caa5828":"markdown","7d84bcc7":"markdown","1d43fe47":"markdown","555cd4b7":"markdown","739e0457":"markdown","35a8432c":"markdown","794622b4":"markdown","b6d90486":"markdown","38a9a94f":"markdown"},"source":{"3f40c6d8":"#Importing Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nsns.set(style=\"darkgrid\")","ff17af0b":"# Dowloading and reading data\ndf = pd.read_csv(\"..\/input\/bank-note-authentication-uci-data\/BankNote_Authentication.csv\")","975154ea":"#Check NaN\ndf.isnull().values.any()","9d618de9":"df.head()","15966d5a":"df.shape","f27ec41e":"#Column Names\ndf.columns","3cede401":"df.info()","5d247901":"#Summary Stastiscs\ndf.describe()","bd09cc9c":"pd.pivot_table(df, index=[\"class\"], aggfunc=[np.mean])","4641e3be":"pd.pivot_table(df, index=[\"class\"], aggfunc=[np.std])","8fea2af6":"# Distribution of Each Feature: Boxplot\ncolnames = df.columns\n\nfig, ax=plt.subplots(nrows=2, ncols=2, figsize=(15,12))\nfor i in range(2):\n    x = colnames[i]\n    ax[0,i].boxplot(df[str(x)], labels=[str(x)])\n    ax[0,i].set_ylabel(str(x))\n    ax[0,i].set_title(str(x) + \"\\nBoxplot\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    ax[1,i-4].boxplot(df[str(x)], labels=[str(x)])\n    ax[1,i-4].set_ylabel(str(x))\n    ax[1,i-4].set_title(str(x) + \"\\nBoxplot\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","274b0a1e":"# Distribution of Each Feature: Histogram\n\nfig, ax=plt.subplots(nrows=2, ncols=2, figsize=(15,12), sharey=True)\nfor i in range(2):\n    x = colnames[i]\n    ax[0,i].hist(df[str(x)], color=\"red\", bins=20)\n    ax[0,i].set_ylabel(str(x))\n    ax[0,i].set_title(str(x) + \"\\nHistogram\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    ax[1,i-4].hist(df[str(x)], color=\"red\", bins=20)\n    ax[1,i-4].set_ylabel(str(x))\n    ax[1,i-4].set_title(str(x) + \"\\nHistogram\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.3, \n                    hspace=0.4)","ceaf0a24":"# Distribution of Each Feature: Violinplot\n\nfig, ax=plt.subplots(nrows=2, ncols=2, figsize=(15,12))\nfor i in range(2):\n    x = colnames[i]\n    ax[0,i].violinplot(df[str(x)])\n    ax[0,i].set_ylabel(str(x))\n    ax[0,i].set_title(str(x) + \"\\nViolinplot\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    ax[1,i-4].violinplot(df[str(x)])\n    ax[1,i-4].set_ylabel(str(x))\n    ax[1,i-4].set_title(str(x) + \"\\nViolinplot\")\n\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","3c666926":"# Distribution of Each Feature By Outcome: Barplot\n\nfig, ax =plt.subplots(2,2, figsize=(15,12))\n\nfor i in range(2):\n    x = colnames[i]\n    sns.barplot(data=df, y=str(x), x=\"class\", ax=ax[0, i])\n    ax[0,i].set_title(str(x) + \"\\nDistribution by Outcome\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    sns.barplot(data=df, y=str(x), x=\"class\", ax=ax[1, i-4])\n    ax[1,i-4].set_title(str(x) + \"\\nDistribution by Outcome\")\n    \nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","ae42db05":"# Distribution of Each Feature By Outcome: Boxplot\n\nfig, ax =plt.subplots(2,2, figsize=(15,12))\n\nfor i in range(2):\n    x = colnames[i]\n    sns.boxplot(data=df, y=str(x), x=\"class\", ax=ax[0, i])\n    ax[0,i].set_title(str(x) + \"\\nDistribution by Outcome\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    sns.boxplot(data=df, y=str(x), x=\"class\", ax=ax[1, i-4])\n    ax[1,i-4].set_title(str(x) + \"\\nDistribution by Outcome\")\n    \nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","2dac8863":"# Distribution of Each Feature By Outcome: Violinplot\n\nfig, ax =plt.subplots(2,2, figsize=(15,12))\n\nfor i in range(2):\n    x = colnames[i]\n    sns.violinplot(data=df, y=str(x), x=\"class\", ax=ax[0, i])\n    ax[0,i].set_title(str(x) + \"\\nDistribution by Outcome\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    sns.violinplot(data=df, y=str(x), x=\"class\", ax=ax[1, i-4])\n    ax[1,i-4].set_title(str(x) + \"\\nDistribution by Outcome\")\n    \nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","f9e14eba":"# Distribution of Each Feature By Outcome: Stripplot\n\nfig, ax =plt.subplots(2,2, figsize=(15,12))\n\nfor i in range(2):\n    x = colnames[i]\n    sns.stripplot(data=df, y=str(x), x=\"class\", ax=ax[0, i])\n    ax[0,i].set_title(str(x) + \"\\nDistribution by Outcome\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    sns.stripplot(data=df, y=str(x), x=\"class\", ax=ax[1, i-4])\n    ax[1,i-4].set_title(str(x) + \"\\nDistribution by Outcome\")\n    \nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","889842f7":"# Distribution of Each Feature By Outcome: Density plot\n\nfig, ax =plt.subplots(2,2, figsize=(15,12))\n\nfor i in range(2):\n    x = colnames[i]\n    sns.kdeplot(data=df, x=str(x), hue=\"class\", shade=True, ax=ax[0, i])\n    ax[0,i].set_title(str(x) + \"\\nDistribution by Outcome\")\n\nfor i in range(2,4):\n    x = colnames[i]\n    sns.kdeplot(data=df, x=str(x), hue=\"class\", shade=True, ax=ax[1, i-4])\n    ax[1,i-4].set_title(str(x) + \"\\nDistribution by Outcome\")\n    \nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.5, \n                    hspace=0.4)","6fd43d3e":"#Using Pearson Correlation to create Correlation heatmap\nplt.figure(figsize=(12,10))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","86c71e40":"# Pairwise Plotting\n# Principal Diagonal Plots- Univaraite Analysis (Density plots) coloured by Class\n# Other Plots: Bivariate Analysis (Scatter plots) coloured by Class\nsns.pairplot(data=df, hue=\"class\")","3c130ae7":"#Importing Necessary Packages:\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nsns.set(style=\"darkgrid\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc","29bc2c27":"#Split x and y\nx=df.drop(['class'], axis=1)\ny=df['class']\n\n#Scale x\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nx_scaled=scaler.fit_transform(x)\nx=pd.DataFrame(x_scaled, columns=x.columns)\n\n#Split test, train, and validation\nfrom sklearn.model_selection import train_test_split\ntrain_x, test_x, train_y, test_y=train_test_split(x, y, random_state=56, stratify=y, test_size=0.1)\ntrain_val_x, valid_x, train_val_y, valid_y=train_test_split(train_x, train_y, random_state=56, stratify=train_y, test_size=1\/9)","69346d53":"#Implement knn classifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\n\n#KNN Classifier for some random k=10 without validation:\nclf=KNN(n_neighbors=10)\nclf.fit(train_x, train_y)\ntest_predict=clf.predict(test_x)\nprint(\"Recall:\", recall_score(test_y, test_predict), \n      \"\\nF1 Score:\", f1_score(test_y, test_predict), \n      \"\\nAccuracy:\", accuracy_score(test_y, test_predict))","dd0cd407":"#Elbow Curve (Thresholding) for optimising k (Stratified Hold Out Validation)\ndef Elbow(K):\n    clf=KNN(n_neighbors=K)\n    clf.fit(train_val_x, train_val_y)\n    valid_predict=clf.predict(valid_x)\n    acc = accuracy_score(valid_y, valid_predict)\n    return 1-acc\n       \nk=list(range(1, 40, 2))\ner=list(map(Elbow, k))\nplt.plot(k, er)\nplt.xlabel(\"K\")\nplt.ylabel(\"Error (FNR) on Validation Set\")\nplt.title(\"Elbow Curve for KNN Classifier\")","f055553f":"#KNN Classifier on Optimum k:\nclf=KNN(n_neighbors=k[er.index(min(er))])\nclf.fit(train_x, train_y)\ntest_predict=clf.predict(test_x)\nprint(\"Recall:\", recall_score(test_y, test_predict), \n    \"\\nF1 Score:\", f1_score(test_y, test_predict), \n    \"\\nAccuracy:\", accuracy_score(test_y, test_predict))\n\n#Confusion Matrix:\ncm = confusion_matrix(test_y, test_predict, labels=[1,0])\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0']);\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(test_y, test_predict, labels=[1,0])\nprint('Classification report : \\n',matrix)","a39df5e6":"#KNN ROC Curve:\nclf=KNN(n_neighbors=5)\nclf.fit(train_x, train_y)\ntest_scores = clf.predict_proba(test_x)\nfpr, tpr, threshold = roc_curve(test_y, test_scores[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of KNN')\nplt.show()","589d697c":"#Implement knn classifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.model_selection import cross_val_score\n\n#7-Fold Cross validation Mean Score Elbow Curve (Thresholding)  for optimising k\ndef Elbow_cross_val_mean(K):\n    score=cross_val_score(KNN(n_neighbors=K), X=train_x, y=train_y, cv=7, scoring='recall')\n    return score.mean()*100\n\n#7-Fold Cross validation STD score Elbow Curve (Thresholding) for optimising k\ndef Elbow_cross_val_std(K):\n    score=cross_val_score(KNN(n_neighbors=K), X=train_x, y=train_y, cv=7, scoring='recall')\n    return score.std()*1000\n\n#The Elbow Curve Plot\nk=list(range(1, 40, 1))\nfig, ax = plt.subplots(figsize=(5,5))\nax.plot(k, list(map(Elbow_cross_val_mean, k)))\nax.set_xlabel(\"K\")\nax.set_ylabel(\"Mean_Score_Metric\")\nax.set_title(\"Score Elbow Curve for KNN Classifier\")\nax2=ax.twinx()\nax2.plot(k, list(map(Elbow_cross_val_std, k)), color=\"red\")\nax2.set_ylabel(\"STD_Score_Metric\")","614c6b38":"#Taking k=3 for instance:\nclf=KNN(n_neighbors=3)\nclf.fit(train_x, train_y)\ntest_predict_cv=clf.predict(test_x)\nprint( \"Accuracy on Test:\", accuracy_score(test_y, test_predict_cv),\n      \"\\nRecall on Test:\", recall_score(test_y, test_predict_cv),\n     \"\\nF1 Score on Test:\", f1_score(test_y, test_predict_cv))\n\n#Confusion Matrix:\ncm = confusion_matrix(test_y, test_predict_cv, labels=[1,0])\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0']);\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(test_y, test_predict_cv, labels=[1,0])\nprint('Classification report : \\n',matrix)","a02c86f0":"#KNN ROC Curve:\nclf=KNN(n_neighbors=3)\nclf.fit(train_x, train_y)\ntest_scores = clf.predict_proba(test_x)\nfpr, tpr, threshold = roc_curve(test_y, test_scores[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of KNN')\nplt.show()","e05147c2":"#Implement Linear Regressor\nfrom sklearn.linear_model import LinearRegression as LR\n\n# Creating instance of Logistic Regresssion\nlr = LR(normalize=True)\n\n# Fitting the model\nlr.fit(train_val_x, train_val_y)\n\n# Predicting over the Validation Set\nvalid_predict = lr.predict(valid_x)\n\n#Decision Rule (By maximising f1 score on the validation set):\ner=[]\nfor i in range(0, 100, 1):\n    v=i\/100\n    def func_dec(x):\n        if x >= v:\n            return 1\n        else:\n            return 0\n    valid_predict_clf=list(map(func_dec, valid_predict))\n    er_f1 = 1-f1_score(valid_y, valid_predict_clf)\n    er.append(er_f1)\n    \ni=list(range(0, 100, 1))\nv = list(map(lambda x: x\/100, i))\nplt.plot(v, er)\nplt.xlabel(\"Decision Rule Parameter\")\nplt.ylabel(\"Error on Validation Set\")\nplt.title(\"Elbow Curve for Linear Regressor\")","422fa9e7":"#Using algorithm on entire train (itrain set) set and looking at coefficients\nlr = LR()\nlr.fit(train_x, train_y)\ntest_predict = lr.predict(test_x)\n\nprint(\"Regression Coefficients: \", lr.coef_)\n\nplt.figure(dpi=120, facecolor='w', edgecolor='b')\nx = range(len(train_x.columns))\ny = lr.coef_\nplt.bar( x, y )\nplt.xlabel( \"Variables\")\nplt.ylabel('Coefficients')\nplt.title('Coefficient plot')","3844ab1a":"#Making Final Predictions and evaluating performance\n\n#Using Decision Rule with Optimum Parameter:\ndef func_dec(x):\n    if x >= v[er.index(min(er))]:\n        return 1\n    else:\n        return 0\ntest_predict_clf=list(map(func_dec, test_predict))\n\nprint( \"Accuracy on Test:\", accuracy_score(test_y, test_predict_clf),\n      \"\\nRecall on Test:\", recall_score(test_y, test_predict_clf),\n     \"\\nF1 Score on Test:\", f1_score(test_y, test_predict_clf))\n\n#Confusion Matrix:\ncm = confusion_matrix(test_y, test_predict_clf, labels=[1,0])\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0']);\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(test_y, test_predict_clf, labels=[1,0])\nprint('Classification report : \\n',matrix)","278ef109":"#Linear Regression ROC Curve:\nlr = LR()\nlr.fit(train_x, train_y)\ntest_scores = lr.predict(test_x)\nfpr, tpr, threshold = roc_curve(test_y, test_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of  Multivariate Linear Regression')\nplt.show()","6f23d547":"#Implement Logistic Regressor\nfrom sklearn.linear_model import LogisticRegression as LogReg\nfrom sklearn.model_selection import cross_val_score\n\n# Creating instance of Logistic Regresssion\nlogreg = LogReg()\n\n# Fitting the model\nlogreg.fit(train_x, train_y)\n\n# Predicting over the Test Set\ntest_predict = logreg.predict(test_x)\n\n#Printing the coefficients\nprint(\"Regression Coefficients: \", logreg.coef_)\n\nplt.figure(figsize=(8, 6), dpi=120, facecolor='w', edgecolor='b')\nx = range(len(train_x.columns))\nc = logreg.coef_.reshape(-1)\nplt.bar( x, c )\nplt.xlabel( \"Variables\")\nplt.ylabel('Coefficients')\nplt.title('Coefficient plot')","a946bdde":"#Making Final Predictions and evaluating performance\n\nprint( \"Accuracy on Test:\", accuracy_score(test_y, test_predict),\n      \"\\nRecall on Test:\", recall_score(test_y, test_predict),\n     \"\\nF1 Score on Test:\", f1_score(test_y, test_predict))\n\n#Confusion Matrix:\ncm = confusion_matrix(test_y, test_predict, labels=[1,0])\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0']);\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(test_y, test_predict, labels=[1,0])\nprint('Classification report : \\n',matrix)","6a6e596a":"#Logistic Regression ROC Curve:\ntest_scores = logreg.predict_proba(test_x)\nfpr, tpr, threshold = roc_curve(test_y, test_scores[:,1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of  Logistic Regression')\nplt.show()","c925b0e0":"#Implement Ridge Linear Regressor\nfrom sklearn.linear_model import Ridge\n\n#Creating a list of regularisation strength values\nalpha_ridge = [0, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20, 25, 1000]\n\n#Creating empyty lists to store f1 score and recall for ridge regression (with optimal dceision parameter) \n#for each value of alpha:\nacc_alpha=[]\nf1_alpha=[]\n\n#Running the simulations\ndef ridge_alpha_max_f1(alpha):\n    # Creating instance of Ridge Regresssion\n    ridgelr = Ridge(normalize=True, alpha=alpha)\n    # Fitting the model\n    ridgelr.fit(train_val_x, train_val_y)\n    # Predicting over the Validation Set\n    valid_predict = ridgelr.predict(valid_x)\n    #Decision Rule (By maximising f1 score on the validation set):\n    er=[]\n    for i in range(0, 100, 1):\n        v=i\/100\n        def func_dec(x):\n            if x >= v:\n                return 1\n            else:\n                return 0\n        valid_predict_clf=list(map(func_dec, valid_predict))\n        er_f1 = 1-f1_score(valid_y, valid_predict_clf)\n        er.append(er_f1)\n    #Using optimum decision parameter\n    j=list(range(0, 100, 1))\n    v = list(map(lambda x: x\/100, j))\n    ridgelr = Ridge(alpha=alpha)\n    ridgelr.fit(train_val_x, train_val_y)\n    valid_predict = ridgelr.predict(valid_x)\n    def func_dec_opt(x):\n        if x >= v[er.index(min(er))]:\n            return 1\n        else:\n            return 0\n    valid_predict_clf=list(map(func_dec_opt, valid_predict))\n    acc_alpha.append(accuracy_score(valid_y, valid_predict_clf))\n    f1_alpha.append(f1_score(valid_y, valid_predict_clf))\n    i=list(range(0, 100, 1))\n    v = list(map(lambda x: x\/100, i))\n    f, ax = plt.subplots(figsize=(10, 5))\n    ax.plot(v, er)\n    plt.xlabel(\"Decision Rule Parameter\")\n    plt.ylabel(\"Error on Validation Set\")\n    plt.title(\"Elbow Curve for Linear Regressor\")\n    \nfor i in alpha_ridge:\n    plt.figure(i)\n    ridge_alpha_max_f1(i)\n","c10297ea":"pd.DataFrame({\"Alpha\":alpha_ridge, \"F1\":f1_alpha, \"Accuracy\":acc_alpha})","1b957ed1":"fig, ax = plt.subplots(figsize=(5,5))\nax.plot(alpha_ridge, f1_alpha)\nax.set_xlabel(\"Alpha (Regularization Strength)\")\nax.set_ylabel(\"F1 Score\")\nax.set_title(\"Performance vs Alpha\")\nax2=ax.twinx()\nax2.plot(alpha_ridge, acc_alpha, color=\"red\")\nax2.set_ylabel(\"Accuracy Score\")","4d987b41":"fig, ax = plt.subplots(figsize=(5,5))\nax.plot(alpha_ridge[0:7], f1_alpha[0:7])\nax.set_xlabel(\"Alpha (Regularization Strength)\")\nax.set_ylabel(\"F1 Score\")\nax.set_title(\"Performance vs Alpha\")\nax2=ax.twinx()\nax2.plot(alpha_ridge[0:7], acc_alpha[0:7], color=\"red\")\nax2.set_ylabel(\"Accuracy Score\")","3803bb51":"ridgelr = Ridge(normalize=True, alpha=1e-8)\nridgelr.fit(train_val_x, train_val_y)\nvalid_predict = ridgelr.predict(valid_x)\ner=[]\nfor i in range(0, 100, 1):\n    v=i\/100\n    def func_dec(x):\n        if x >= v:\n            return 1\n        else:\n            return 0\n    valid_predict_clf=list(map(func_dec, valid_predict))\n    er_f1 = 1-f1_score(valid_y, valid_predict_clf)\n    er.append(er_f1)\n\n\n#Using algorithm on entire train (itrain set) set and looking at coefficients\nridgelr = Ridge(normalize=True, alpha=1)\nridgelr.fit(train_x, train_y)\ntest_predict = ridgelr.predict(test_x)\n\nprint(\"Ridge Regression Coefficients: \", ridgelr.coef_)\n\nplt.figure(dpi=120, facecolor='w', edgecolor='b')\nx = range(len(train_x.columns))\ny = lr.coef_\nplt.bar( x, y )\nplt.xlabel( \"Variables\")\nplt.ylabel('Coefficients')\nplt.title('Coefficient plot')","b9d04a04":"#Using Decision Rule with Optimum Parmeter\ni=list(range(0, 100, 1))\nv = list(map(lambda x: x\/100, i))\ndef func_dec_opt(x):\n    if x >= v[er.index(min(er))]:\n        return 1\n    else:\n        return 0\ntest_predict_clf=list(map(func_dec_opt, test_predict))\nprint( \"Accuracy on Test:\", accuracy_score(test_y, test_predict_clf),\n      \"\\nRecall on Test:\", recall_score(test_y, test_predict_clf),\n     \"\\nF1 Score on Test:\", f1_score(test_y, test_predict_clf))\n\n#Confusion Matrix:\ncm = confusion_matrix(test_y, test_predict_clf, labels=[1,0])\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0']);\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(test_y, test_predict_clf, labels=[1,0])\nprint('Classification report : \\n',matrix)","c6e993f7":"#Ridge Regression ROC Curve:\nridgelr = Ridge(normalize=True, alpha=1)\nridgelr.fit(train_x, train_y)\ntest_scores = ridgelr.predict(test_x)\nfpr, tpr, threshold = roc_curve(test_y, test_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of  Ridge Linear Regression')\nplt.show()","a2fac92f":"#Packages:\nimport tensorflow as tf\nfrom sklearn.model_selection import cross_val_score\n\n#defining f1 score and recall score metric\nimport keras.backend as K\ndef f1_metric(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val\n\nnp.random.seed(52)\n#Initialising ANN\nann = tf.keras.models.Sequential()\n\n#Adding First Hidden Layer with 6 neurons\nann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))\n\n#Adding Second Hidden Layer with 6 neurons\nann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))\n\n#Adding Output Layer with 1 neuron as it's a classification problem.\nann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n\n#Compiling ANN\nann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[f1_metric])\n#Binary cross entropy is the loss function we use for classification purposes.\n#The popular adam optimizer has been used as a trial.\n\nnp.random.seed(52)\n#Fitting ANN\nann.fit(train_val_x,train_val_y,batch_size=128,epochs = 100)\n#Used a mini batch gradient descent for trial, 32 is a popular batch size and each training sample will be use 100 times.\n","c783cf4d":"#ANN Classifier\nvalid_predict = ann.predict(valid_x)","cfd8f695":"#Decision Rule (By maximising f1 score on the validation set):\ner=[]\nfor i in range(0, 100, 1):\n    v=i\/100\n    def func_dec(x):\n        if x >= v:\n            return 1\n        else:\n            return 0\n    valid_predict_clf=list(map(func_dec, valid_predict))\n    er_f1 = 1-f1_score(valid_y, valid_predict_clf)\n    er.append(er_f1)\n    \ni=list(range(0, 100, 1))\nv = list(map(lambda x: x\/100, i))\nplt.plot(v, er)\nplt.xlabel(\"Decision Rule Parameter\")\nplt.ylabel(\"Error on Validation Set\")\nplt.title(\"Elbow Curve for ANN\")","b3de4c05":"#Making Final Predictions and evaluating performance\nnp.random.seed(52)\nann.fit(train_x, train_y,batch_size=128,epochs = 100)\ntest_predict = ann.predict(test_x)\n\n#Using Decision Rule with Optimum Parameter:\ndef func_dec_opt(x):\n    if x >= v[er.index(min(er))]:\n        return 1\n    else:\n        return 0\n\ntest_predict_clf=list(map(func_dec_opt, test_predict))\n\nprint( \"Accuracy on Test:\", accuracy_score(test_y, test_predict_clf),\n      \"\\nRecall on Test:\", recall_score(test_y, test_predict_clf),\n     \"\\nF1 Score on Test:\", f1_score(test_y, test_predict_clf))","7e00c75d":"#Confusion Matrix:\ncm = confusion_matrix(test_y, test_predict_clf, labels=[1,0])\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0']);\n\n# classification report for precision, recall f1-score and accuracy\nmatrix = classification_report(test_y, test_predict_clf, labels=[1,0])\nprint('Classification report : \\n',matrix)","04866ed6":"fpr, tpr, threshold = roc_curve(test_y, test_predict)\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC Curve of  Artificial Neural Network \\n(Untuned)')\nplt.show()","a74170a9":"!pip install nnv","eea5c8e4":"from nnv import NNV\n\nlayersList = [\n    {\"title\":\"Input\\n(ReLU)\", \"units\": 4, \"color\": \"darkBlue\", \"edges_width\":1},\n    {\"title\":\"Hidden 1\\n(ReLU)\", \"units\": 6, \"edges_width\":1},\n    {\"title\":\"Hidden 2\\n(ReLU)\", \"units\": 6, \"edges_color\":\"red\", \"edges_width\":1},\n    {\"title\":\"Output\\n(Sigmoid)\", \"units\": 1,\"color\": \"darkBlue\"},\n]\n\nNNV(layersList, max_num_nodes_visible=8, node_radius=50, spacing_layer=200, font_size=10).render()","178faaae":"### 1) KNN Classifier (Stratified Hold Out Validation)","7b0ce6fe":"There is no optimum k, as inferred from the above plot. For any random k, e.g. k=3, the accuracy on the valiadtion set remains the same.","dae6edac":"## IV) Supervised Deep Learning Model: Artificial Neural Network (ANN)","4b1b59be":"Final Results:  \n    Max Accuracy: 99.187%  \n    Algotithm: Artificial Neural Network (See above for structure).","44794e89":"**Interpretation:** The distribution of varaince and skewness is highly depedndent on the outcome, indicating that features may have high importance in making the predictions. The distribution of curtosis is less, but dependent on the outcome, indicating a moderate feature importance. Entropy seems to be similarly distributed across both outcomes, indicating its diminsished importance while making predictions.","31b6de2e":"**Note:** Prevalence (proportion of fake notes) is seen to be 44%, indicating that the dataset is quite balanced.","bd7d0d13":"## II) Visualization","e02345a2":"## I) Data Set Description and Preliminary Analysis:\n\n**Description:** Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images\n\n**Objective:** Use Machine Learning Algrorithms (Supervised & Unsupervised) to predict whether a given banknote is authentic given a number of measures taken from a photograph.\n<br>\n**Features:** \n1. Variance of Wavelet Transformed image (continuous).\n2. Skewness of Wavelet Transformed image (continuous).\n3. Kurtosis of Wavelet Transformed image (continuous).\n4. Entropy of image (continuous).\n5. Class (0 for authentic, 1 for inauthentic)","6d19b506":"For none of the feature pairs, the correlation coeffiecients exceed 0.5, indicating that the features are quite independent to ecah other. The higheset correlation is seen between curtosis and entropy (0.32).","9caa5828":"### 2) KNN Classifier (Using k-Fold Cross Validation)","7d84bcc7":"$$L=\\cfrac{1}{n} \\sum_{i=1}^n (\\hat{Y}_i-Y_i)^2 + \\cfrac{\\lambda}{n}\\sum_{j=1}^m \\beta_j^2$$","1d43fe47":"Problems with this Model:\n1. Theshold is shifting with every new data point added.\n2. R=There are also negetive values after performing regression, interpreting which as a a probability is abstract. In, other words, it's difficult to interpret the model in the extrememes. \n\nTherefore, we use logistic regression.","555cd4b7":"**Interpretation:** variance and skewness have similar distribution.  Curtosis is skewed towards the right, while entropy is skewed towards the left. All 4 features have median close to 0.","739e0457":"## III) Prediction Models: Supervised","35a8432c":"### 4) Logistic Regression","794622b4":"# Bank Note Authentication Project","b6d90486":"### 3) Multivariate Linear Regression (Stratified Hold Out Validation for Decison Rule)","38a9a94f":"### 5) Ridge Regularised Multivariate Linear Regression (Stratified Hold Out Validation for Tuning Decision Parameter and Regularisation Strength)"}}