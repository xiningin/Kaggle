{"cell_type":{"b009ab87":"code","348ab085":"code","4250b042":"code","7cbf1da3":"code","c1ff5362":"code","285699c3":"code","7e62bec8":"code","746534dc":"code","fcfbe2d7":"code","65001ed9":"code","127f1583":"code","726fa742":"code","6383ef78":"code","42eac8a6":"code","b6bc818c":"markdown","55114116":"markdown","588278d3":"markdown"},"source":{"b009ab87":"!pip install -q python-speech-features\n\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom python_speech_features import mfcc, logfbank\nfrom matplotlib import pyplot as plt","348ab085":"FOLDS = 8\nSEED = 2809","4250b042":"train_df = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\ntrain_df['path'] = train_df['id'].apply(lambda x: f'..\/input\/g2net-gravitational-wave-detection\/train\/{x[0]}\/{x[1]}\/{x[2]}\/{x}.npy')","7cbf1da3":"sub_df = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv')\nsub_df['path'] = sub_df['id'].apply(lambda x: f'..\/input\/g2net-gravitational-wave-detection\/test\/{x[0]}\/{x[1]}\/{x[2]}\/{x}.npy')","c1ff5362":"train_df.head()","285699c3":"class GlobalMinMaxScaler:\n    def __init__(self, size=256):\n        self.__min = []\n        self.__max = []\n        self.__is_initialized = False\n        \n    def fit(self, x):\n        for i in range(3):\n            if not self.__is_initialized:\n                self.__min.append(np.min(x[..., i]))\n                self.__max.append(np.max(x[..., i]))\n            else:\n                self.__min[i] = np.min([self.__min[i], np.min(x[..., i])])\n                self.__max[i] = np.max([self.__max[i], np.max(x[..., i])])\n        self.__is_initialized = True\n        \n    def transform(self, x):\n        if self.__is_initialized:\n            for i in range(3):\n                x[..., i] = (x[..., i] - self.__min[i]) \/ (self.__max[i] - self.__min[i])\n        return x","7e62bec8":"def get_data(path):\n    return np.load(path)\n\ndef get_power(path):\n    power_vec = []\n    data = get_data(path)\n    for i in range(3):\n        vec = data[i]\n        power = logfbank(vec, samplerate=2., winlen=256, winstep=8, nfft=512, nfilt=256, preemph=0.)\n        power_vec.append(power)\n    return np.dstack(power_vec)\n\ndef get_img_power(path, scaler):\n    power_vec = []\n    data = get_data(path)\n    for i in range(3):\n        vec = data[i]\n        power = logfbank(vec, samplerate=2., winlen=256, winstep=8, nfft=512, nfilt=256, preemph=0.)\n        power_vec.append(power)\n    power_vec = np.dstack(power_vec)\n    power_vec = scaler.transform(power_vec)\n    return (power_vec * 255).astype(np.uint8)","746534dc":"scaler = GlobalMinMaxScaler()\nweight = 0\nfor p, t in tqdm(zip(train_df.path.values[:10_000], train_df.target.values[:10_000])):\n    scaler.fit(get_power(p))\n    weight += t\nprint('Scaler Balance Weight', weight \/ 10_000)","fcfbe2d7":"data = get_data(train_df.path.values[0])\n\nfig, ax = plt.subplots(3, 1, figsize=(21, 21))\n\nfor i in range(3):\n    ax[i].plot(data[i])\nplt.show();","65001ed9":"power = get_img_power(train_df.path.values[1], scaler)\n\nfig, ax = plt.subplots(1, 3, figsize=(24, 8))\n\n\nfor i in range(3):\n    ax[i].imshow(power[..., i].T)","127f1583":"from sklearn.model_selection import KFold\nskf = KFold(n_splits=FOLDS, shuffle=False)\nsub_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(skf.split(sub_df)):\n    sub_df.loc[val_idx,'fold'] = fold","726fa742":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string \/ byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float \/ double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool \/ enum \/ int \/ uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","6383ef78":"def train_serialize_example(feature0, feature1):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","42eac8a6":"show=True\nfolds = sorted(sub_df.fold.unique().tolist())\nfor fold in tqdm(folds):\n    if fold not in range(0, 4):\n        continue\n    fold_df = sub_df[sub_df.fold==fold]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('test%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it:\n            row = fold_df.iloc[k,:]\n            image      = get_img_power(row['path'], scaler)[...,::-1]\n            image_id   = row['id']\n            example  = train_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id)\n                )\n            writer.write(example)\n        if show:\n            filepath = 'test%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('\/')[-1]\n            filesize = os.path.getsize(filepath)\/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","b6bc818c":"<a id=\"0\"><\/a>\n## 0. EDA","55114116":"<a id=\"1\"><\/a>\n## 2. Save in TFRecords","588278d3":"<a id=\"1\"><\/a>\n## 1. Grouped by Target"}}