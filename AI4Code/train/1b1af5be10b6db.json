{"cell_type":{"2c726f48":"code","6c72f334":"code","43d7b9d2":"code","4cae1ec6":"code","0c7f15c2":"code","1193f83a":"code","dc9e6c82":"code","1e9222f6":"code","32119204":"code","48250010":"code","9c4d7aa1":"code","4fa3bfad":"code","73c1bd08":"code","383ce6d0":"code","60dbaddd":"code","aedc09f3":"code","79323493":"code","270f9a22":"code","38683c03":"code","6a4a3ac0":"code","8c41bbdd":"code","e3a4fccc":"code","b8578537":"code","4b30d15d":"markdown","4801601b":"markdown","cd121c90":"markdown","08fda14c":"markdown","a9cb5ee3":"markdown","796d53cc":"markdown","3f2e789d":"markdown"},"source":{"2c726f48":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c72f334":"import numpy as np \nimport pandas as pd\n# Reading the data \ndf = pd.read_csv('..\/input\/insurance\/insurance.csv')\ndf_original = df.copy()\n# Exploring the data\ndf.head()","43d7b9d2":"# Checking to see if there are null values in the dataset \ndf.isnull().sum()","4cae1ec6":"# Checking the data information \ndf.info()","0c7f15c2":"np.sum(df.duplicated() == True)","1193f83a":"# From the data, sex and smoker attributes are cartegorical data. For us to be able feed them to \n# the scikit-learn for further analysis, we will have to convert them to integers\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df['sex'])\ndf['sex'] = le.transform(df['sex'])\ndf['smoker'] = le.fit_transform(df['smoker'])\ndf.region = le.fit_transform(df.region)","dc9e6c82":"df.head()","1e9222f6":"# Checking the correlation of the dataset\ndf.corr()","32119204":"import matplotlib.pyplot as plt \nimport seaborn as sns\nfig = plt.figure(figsize = (10, 7))\nsns.heatmap(df.corr(), annot = True);","48250010":"pd.DataFrame(df.corr()['charges'].sort_values())","9c4d7aa1":"import seaborn as sns \nimport matplotlib.pyplot as plt \nfig, ax = plt.subplots(figsize = (15, 10))\ndf.hist(ax = ax);","4fa3bfad":"fig, ax = plt.subplots(figsize = (5, 3))\nsns.distplot(df[(df.smoker == 1)]['charges'], color = 'c', ax = ax)\nax.set(title = 'Distribution of charges for smokers')\n\nfig, ax = plt.subplots(figsize = (5, 3))\nsns.distplot(df[df['smoker']== 0]['charges'], color = 'g', ax = ax)\nax.set(title = 'Distribution of charges for non-smokers');","73c1bd08":"X = df.drop(['charges', 'region'], axis = 1)\ny = df['charges']","383ce6d0":"X.head()","60dbaddd":"y.head()","aedc09f3":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","79323493":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)","270f9a22":"lr.score(X_test, y_test)","38683c03":"from sklearn.metrics import mean_absolute_error\ny_pred = lr.predict(X_test)\nmean_absolute_error(y_test, y_pred)","6a4a3ac0":"from sklearn.preprocessing import PolynomialFeatures\na = df.drop(['charges', 'region'], axis = 1)\nb = df.charges\n\nquad = PolynomialFeatures(degree = 2)\na_quad = quad.fit_transform(a)\na_train, a_test, b_train, b_test = train_test_split(a_quad, b, random_state = 0)\npoly_lr = LinearRegression()\npoly_lr.fit(a_train, b_train)\nprint(poly_lr.score(a_test, b_test))\nprint(mean_absolute_error(poly_lr.predict(a_test), b_test))","8c41bbdd":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha = 0.01)\nlasso.fit(X_train, y_train)\nprint(lasso.score(X_test, y_test))\nprint(mean_absolute_error(lasso.predict(X_test), y_test))","e3a4fccc":"from sklearn.linear_model import Ridge\nridge = Ridge(alpha = 0.00001)\nridge.fit(X_train, y_train)\nprint(ridge.score(X_test, y_test))\nprint(mean_absolute_error(ridge.predict(X_test), y_test))","b8578537":"from sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators = 100, random_state = 1)\nforest.fit(X_train, y_train)\nprint(forest.score(X_test, y_test))\nprint(mean_absolute_error(forest.predict(X_test), y_test))","4b30d15d":"# Splitting Data ","4801601b":"# Model 3 - Ridge","cd121c90":"# Using polinomial features to try to improve the effect of the linear regression prediction on our datasets","08fda14c":"# Exploring the Dataset","a9cb5ee3":"# Model 1: Linear Regression","796d53cc":"# Model 2 - Lasso","3f2e789d":"# Model 4 - Random Forest"}}