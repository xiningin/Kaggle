{"cell_type":{"fbc4a510":"code","c2c4bcbf":"code","5c8510a6":"code","9f0497ec":"code","a44aa843":"code","6866d64f":"code","583df0ee":"code","b6eafc12":"code","2acdaaf6":"code","49205fe3":"code","9e784d80":"code","1426a42a":"code","0dabc3f3":"code","d02f6c57":"code","bfa1eacd":"code","e4764fc6":"code","c6862115":"code","ed42d23f":"code","ded903a1":"code","83a8c62e":"code","8cf7e870":"code","5d2735a3":"code","3b38ef74":"code","885638c1":"code","6cc8bfb9":"code","481aaf49":"code","6d1bba7b":"code","e3dbf206":"code","227d8450":"code","25c162f7":"code","68468287":"code","baa74324":"code","bc074266":"code","db01da69":"code","3f8297cd":"code","171cb439":"code","d4fda20d":"code","3485f103":"code","21380f6f":"code","b001c5d5":"code","f3ad65f6":"code","c0f8a80b":"code","cbc8208c":"code","124a00ec":"code","363cf185":"code","20a25495":"code","5edef8a7":"code","7d36c50e":"markdown","8db927c1":"markdown","c812da69":"markdown","2be2273c":"markdown","c1d3c1f9":"markdown","6ef0291c":"markdown","ffc21ece":"markdown","50a52788":"markdown","a2c74c4e":"markdown","341ecc12":"markdown","a36df968":"markdown","42268fd0":"markdown","fdf2867a":"markdown","9627ee63":"markdown","8b20c25a":"markdown","b603ad74":"markdown","3c21a110":"markdown","6f7050c1":"markdown","85ffa83a":"markdown"},"source":{"fbc4a510":"import numpy as np\nimport pandas as pd\nimport tensorflow\nimport seaborn as sns\n","c2c4bcbf":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")","5c8510a6":"#printing first five rows of  train_dataset\ntrain_data.head() ","9f0497ec":"test_data.head()","a44aa843":"# checking shape of train_data\ntrain_data.shape # 891 rows and 12 columns","6866d64f":"#checking shape of test data\ntest_data.shape","583df0ee":"train_data.info()","b6eafc12":"test_data.info()","2acdaaf6":"# sumarie and statistics\ntrain_data.describe()","49205fe3":"test_data.describe()","9e784d80":"train_data.isnull().sum()","1426a42a":"test_data.isnull().sum()","0dabc3f3":"# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \ng = sns.heatmap(train_data[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True\n                , fmt = \".2f\", cmap = \"coolwarm\")","d02f6c57":"# survival probability\ng1 = sns.barplot(x=\"Sex\",y=\"Survived\",data=train_data)\ng1 = g.set_ylabel(\"Survival Probability\")","bfa1eacd":"# handle missing value in train_data\ntrain_data[\"Age\"] = train_data[\"Age\"].fillna(train_data[\"Age\"].mean())","e4764fc6":"train_data[\"Age\"].head()","c6862115":"train_data.isnull().sum()","ed42d23f":"# handle missing value in test_data\ntest_data[\"Age\"] = test_data[\"Age\"].fillna(test_data[\"Age\"].mean())","ded903a1":"test_data.isnull().sum()","83a8c62e":"# train_data\ntrain_data['Cabin']=train_data['Cabin'].fillna(train_data['Cabin'].mode()[0])\ntrain_data['Embarked']=train_data['Embarked'].fillna(train_data['Embarked'].mode()[0])\n\n","8cf7e870":"train_data.isnull().sum() # all missing values handle","5d2735a3":"# test_data\ntest_data['Cabin']=test_data['Cabin'].fillna(test_data['Cabin'].mode()[0])\ntest_data['Fare']=test_data['Fare'].fillna(test_data['Fare'].mode()[0])\n","3b38ef74":"test_data.isnull().sum()","885638c1":"dataset =  pd.concat([train_data, test_data], axis=0)","6cc8bfb9":"dataset.shape","481aaf49":"# Fill empty and NaNs values with NaN\ndataset = dataset.fillna(np.nan)","6d1bba7b":"# drop name column\ndataset.drop(['Name'],axis=1,inplace=True)","e3dbf206":"dataset.columns","227d8450":"from sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()","25c162f7":"encode = dataset[['Sex','Ticket','Cabin','Embarked']].apply(enc.fit_transform)\nencode","68468287":"dataset[['Sex','Ticket','Cabin','Embarked']] = encode[['Sex','Ticket','Cabin','Embarked']]","baa74324":"dataset.head()","bc074266":"dataset.shape","db01da69":"train_len = len(train_data)","3f8297cd":"train = dataset[:train_len]\ntest= dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","171cb439":"test.shape","d4fda20d":"train.shape","3485f103":"train[\"Survived\"] = train[\"Survived\"].astype(int)","21380f6f":"Y_train = train[\"Survived\"]\n\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","b001c5d5":"from sklearn.ensemble import GradientBoostingClassifier\n","f3ad65f6":"model = GradientBoostingClassifier(learning_rate=0.01,max_depth = 2)\nmodel.fit(X_train, Y_train)","c0f8a80b":"Score = model.score(X_train, Y_train)\nprint(\"Score: %.2f%%\" % (Score * 100.0))","cbc8208c":"predictions = model.predict(test)","124a00ec":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})","363cf185":"output","20a25495":"output.to_csv('my_submission3.csv', index=False)\nprint(\"Your submission was successfully saved!\")","5edef8a7":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","7d36c50e":"# joining test and train data_set","8db927c1":"# Predication","c812da69":"# check missing values in train and test data","2be2273c":"# Training ","c1d3c1f9":"If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That will keep me motivated :)","6ef0291c":"# One_Hot_Coding","ffc21ece":"# Data exploratory","50a52788":"# Modeling","a2c74c4e":"# handle missing values","341ecc12":"# problem","a36df968":"#  use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","42268fd0":"# numerical_values","fdf2867a":"# load and check data","9627ee63":"# Output","8b20c25a":"# Categorical values","b603ad74":"#  Saving submission csv file","3c21a110":"# Feature analysis","6f7050c1":"\u2022\tIntroduction::\n\u2022\tLoad data\n\u2022\tData exploratory\n\u2022\tCheck missing value\n\u2022\tFeature analysis\n\u2022\tHandle missing values\n\u2022\tJoining test and train data\n\u2022\tOne hot coding\n\u2022\tSplitting data\n\u2022\tTraning model using RandomForestClassifier\n\u2022\tPredication\n\u2022\tSaving submission file in csv format\n","85ffa83a":"# How to handle categorical data?"}}