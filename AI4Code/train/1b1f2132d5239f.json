{"cell_type":{"1e54a6bc":"code","9c1a431a":"code","5f787ddd":"code","2d6b8d58":"code","364ede65":"code","4fa40548":"code","10e278c6":"code","ea131637":"code","62b70077":"code","9715cde9":"code","856f71d0":"code","69c8bdc5":"code","d08a8ccb":"code","93f68974":"code","5816fc57":"code","3c5097fa":"code","8cae0a43":"code","dbca0dda":"code","7e3d2863":"code","87a0d51d":"code","4f5b8e8a":"code","caf41103":"code","7dfb92cc":"code","7214fc4d":"code","564cc9a7":"code","6dad9a3b":"code","86c4cfa3":"code","703241fe":"code","e5e8a9d0":"code","011b95f5":"code","c61217c4":"code","7ed4c403":"code","dcb92450":"code","689c6b49":"code","ce9eead2":"code","3019ec74":"code","219de20b":"code","dd8877eb":"code","53c2515e":"code","1995e2dc":"code","d5b1a5f4":"code","a7653d7c":"code","4ede2005":"code","8429d81a":"code","5c096106":"code","eb8ed508":"code","a76058c4":"code","e5984fcf":"code","ffcdc007":"code","25bc8391":"code","46ca27f9":"code","8ab06ab0":"code","1b1aa970":"code","2f4b7151":"code","c06a3a6a":"code","98b951c5":"code","552f074d":"code","7b7419f9":"code","7f837811":"code","6ff150d9":"code","e16cbdb8":"code","4e4403e9":"code","5d515f73":"code","213bdb6d":"code","36f8bc6a":"code","585c5a12":"code","a99d1ebe":"code","e7edab35":"code","7785a086":"code","3c0ce6aa":"code","3174673c":"code","f88aeed4":"code","a914745c":"code","5f948260":"code","48f1695b":"code","9ac236f4":"code","adf40111":"code","3ba15da7":"code","1c32a701":"code","8cfdafc6":"code","85899502":"code","4e30a17d":"code","c16f3840":"code","ffcb24ab":"code","08add53e":"code","c7fbfed3":"code","454765ed":"code","8f00bbae":"code","75b4229b":"code","73331caa":"code","2e9f9d2c":"code","e9993dce":"code","17fd8fd2":"code","6d999bcb":"code","c6f24cc2":"code","36f1ac77":"code","80f10ac8":"code","8ddf3199":"code","818ff389":"code","2869e147":"code","6f040233":"code","ffea611a":"code","36681442":"code","36ef742c":"code","e4ce3b07":"code","f40d0a3c":"code","76c24e7c":"code","f1eb2685":"code","70f8818b":"code","23b8a248":"markdown","5b1187e2":"markdown","a354a1f7":"markdown","7ad71f75":"markdown","203716b9":"markdown","4f1e20f1":"markdown","619e8054":"markdown","b13dd5b0":"markdown","c25309b2":"markdown","30acc1e3":"markdown","8309769a":"markdown","795e8c90":"markdown","fa812d7a":"markdown","c169263b":"markdown","d27126ff":"markdown","bbdecc4d":"markdown","54b096bc":"markdown","08ea965d":"markdown","39a53599":"markdown","c5e7413c":"markdown","46777ce0":"markdown","8ce995ea":"markdown","183199ec":"markdown","cefc7c17":"markdown","58ae0aba":"markdown","a01104c0":"markdown","970bdc9f":"markdown","49a50c87":"markdown","151c7b04":"markdown","eecb2841":"markdown","5a197d4d":"markdown","2a383b80":"markdown"},"source":{"1e54a6bc":"%matplotlib inline\nimport warnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport datetime\nfrom functools import reduce\nfrom sklearn.preprocessing import MinMaxScaler\n\nwarnings.filterwarnings('ignore')","9c1a431a":"!pip install tensorflow==1.15.0rc3","5f787ddd":"# Bibliotecas Keras\nimport tensorflow as tf\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Input, Dense, LSTM, GRU, Embedding, Dropout\nfrom tensorflow.python.keras.optimizers import RMSprop\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau","2d6b8d58":"print('Vers\u00e3o do TensorFlow: ',tf.__version__)\nprint('Vers\u00e3o do Keras: ',tf.keras.__version__)\nprint('Vers\u00e3o do Pandas: ',pd.__version__)","364ede65":"## Leitura Dados\n# Monte Alegre\nmtal = pd.read_csv('..\/input\/dataset\/dados_monte_alegre.csv', delimiter=';')\n# Belterra\nbelt = pd.read_csv('..\/input\/dataset\/dados_belterra.csv', delimiter=';')\n# Oriximina\norix = pd.read_csv('..\/input\/dataset\/dados_oriximina.csv', delimiter=';')","4fa40548":"### Organiza\u00e7\u00e3o dataset\nmtal[['day','month','year']] = mtal.Data.str.split('\/', n = 3, expand = True)\nmtal['day'] = pd.to_numeric(mtal.day)\nmtal['month'] = pd.to_numeric(mtal.month)\nmtal['year'] = pd.to_numeric(mtal.year)\nmtal = mtal.replace([1200,1800],[12,18])\n\nmtal['datetime'] = mtal[['day','month','year','Hora']].apply(lambda row:\n                    datetime.datetime(year=row['year'], month=row['month'],day=row['day'],hour=row['Hora']),axis=1)\nmtal = mtal.drop(columns=['Data','Hora','day','month','year','Unnamed: 10'])\nmtal = mtal.set_index('datetime')\nmtal.sort_values('datetime',ascending=True,inplace=True)\nmtal = mtal['1988':'2018']\n\nbelt[['day','month','year']] = belt.Data.str.split('\/', n = 3, expand = True)\nbelt['day'] = pd.to_numeric(belt.day)\nbelt['month'] = pd.to_numeric(belt.month)\nbelt['year'] = pd.to_numeric(belt.year)\nbelt = belt.replace([1200,1800],[12,18])\n\nbelt['datetime'] = belt[['day','month','year','Hora']].apply(lambda row:\n                    datetime.datetime(year=row['year'], month=row['month'],day=row['day'],hour=row['Hora']),axis=1)\nbelt = belt.drop(columns=['Data','Hora','day','month','year','Unnamed: 10'])\nbelt = belt.set_index('datetime')\nbelt.sort_values('datetime',ascending=True,inplace=True)\nbelt = belt['1988':'2018']\n\norix[['day','month','year']] = orix.Data.str.split('\/', n = 3, expand = True)\norix['day'] = pd.to_numeric(orix.day)\norix['month'] = pd.to_numeric(orix.month)\norix['year'] = pd.to_numeric(orix.year)\norix = orix.replace([1200,1800],[12,18])\n\norix['datetime'] = orix[['day','month','year','Hora']].apply(lambda row:\n                    datetime.datetime(year=row['year'], month=row['month'],day=row['day'],hour=row['Hora']),axis=1)\norix = orix.drop(columns=['Data','Hora','day','month','year','Unnamed: 10'])\norix = orix.set_index('datetime')\norix.sort_values('datetime',ascending=True,inplace=True)\norix = orix['1988':'2018']","10e278c6":"print('Tamanho do dataframe Monte Alegre: ',mtal.shape[0], ', Vari\u00e1veis:',mtal.shape[1])\nprint('Tamanho do dataframe Belterra: ',belt.shape[0], ', Vari\u00e1veis:',belt.shape[1])\nprint('Tamanho do dataframe Obidos: ',orix.shape[0], ', Vari\u00e1veis:',orix.shape[1])","ea131637":"## Merge entre os datasets\ndfs = [mtal,belt,orix]\ndfs_final = reduce(lambda left,right: pd.merge(left,right, on='datetime'),dfs)\n\n# Remover colunas\ndfs_final = dfs_final.drop(columns=['Estacao_x','DirecaoVento_x','VelocidadeVento_x','Nebulosidade_x',\n                                   'Estacao_y','DirecaoVento_y','VelocidadeVento_y','Nebulosidade_y',\n                                   'Estacao','DirecaoVento','VelocidadeVento','Nebulosidade',\n                                   'TempBulboUmido_x','TempBulboUmido_y','TempBulboUmido'])\n\ndfs_final = dfs_final.rename(columns={'TempBulboSeco_x':'TempBS_MTA','UmidadeRelativa_x':'UmidR_MTA','PressaoAtmEstacao_x':'Pres_MTA',\n                                      'TempBulboSeco_y':'TempBS_BLT','UmidadeRelativa_y':'UmidR_BLT','PressaoAtmEstacao_y':'Pres_BLT',\n                                      'TempBulboSeco':'TempBS_OBD','UmidadeRelativa':'UmidR_OBD','PressaoAtmEstacao':'Pres_OBD'} )\ndfs_final.head()","62b70077":"# Visualiza\u00e7\u00e3o do sensor Temperatura Bulbo Seco para as 3 esta\u00e7\u00f5es\nTempBulboS = dfs_final[['TempBS_MTA','TempBS_BLT','TempBS_OBD']].plot(figsize=(15,5),title='Temperatura de Bulbo Seco')\nTempBulboS.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Temperatura em C\u00ba')\nplt.show()","9715cde9":"# Visualiza\u00e7\u00e3o do sensor Umidade para as 3 esta\u00e7\u00f5es\nHumid = dfs_final[['UmidR_MTA','UmidR_BLT','UmidR_OBD']].plot(figsize=(15,5),title='Umidade Relativa do Ar')\nHumid.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Umidade em %')\nplt.show()","856f71d0":"# Visualiza\u00e7\u00e3o do sensor Press\u00e3o Atmosf\u00e9rica para as 3 esta\u00e7\u00f5es\nPressaoP = dfs_final[['Pres_MTA','Pres_BLT','Pres_OBD']].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica')\nPressaoP.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","69c8bdc5":"# Descri\u00e7\u00e3o do DataFrame\ndfs_final.describe()","d08a8ccb":"## Remo\u00e7\u00e3o de Outliers por quantil\nlow = .001\nhigh = .9999\nquant_df = dfs_final.quantile([low,high])","93f68974":"# Valores que representam os outliers\nquant_df","5816fc57":"# Fun\u00e7\u00e3o para corre\u00e7\u00e3o dos outliers\nfilt_df = dfs_final.apply(lambda x: x[(x>quant_df.loc[low,x.name]) & \n                                    (x < quant_df.loc[high,x.name])], axis=0)\n\nfilt_df.describe()","3c5097fa":"# Numerode elementos sem registro no DataFrame sem corre\u00e7\u00e3o\ndfs_final.isna().sum()","8cae0a43":"# Numerode elementos sem registro no DataFrame com corre\u00e7\u00e3o\nfilt_df.isna().sum()","dbca0dda":"# Visualiza\u00e7\u00e3o dos outliers por boxplot dados sem corre\u00e7\u00e3o\nimport seaborn as sns","7e3d2863":"plt.figure(figsize=(15,3))\nplt.title('Temperatura Bulbo Seco para esta\u00e7\u00e3o Monte Alegre com outliers')\nsns.boxplot(x=dfs_final['TempBS_MTA'])\nplt.show()","87a0d51d":"# Visualiza\u00e7\u00e3o dos outliers por boxplot dados com corre\u00e7\u00e3o\nplt.figure(figsize=(15,3))\nplt.title('Temperatura Bulbo Seco para esta\u00e7\u00e3o Monte Alegre sem outliers')\nsns.boxplot(x=filt_df['TempBS_MTA'])\nplt.show()","4f5b8e8a":"# Visualiza\u00e7\u00e3o do sensor Press\u00e3o Atmosf\u00e9rica para as 3 esta\u00e7\u00f5es\nPressaoP = filt_df[['Pres_MTA','Pres_BLT','Pres_OBD']].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica')\nPressaoP.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","caf41103":"# Exemplo de visualiza\u00e7\u00e3o para imputa\u00e7\u00e3o\n# Exemplo entre os dias 01 e 07 de janeiro de 1996\npreE = filt_df[['Pres_MTA','Pres_BLT','Pres_OBD']]['1996\/01\/01':'1996\/01\/07'].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica sem Imputa\u00e7\u00e3o')\npreE.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","7dfb92cc":"# Media entre Belterra e Oriximina\nfilt_df['Pres_MTA'] = filt_df.Pres_MTA.fillna(filt_df[['Pres_BLT','Pres_OBD']].mean(axis=1))","7214fc4d":"# Exemplo de visualiza\u00e7\u00e3o para imputa\u00e7\u00e3o\n# Exemplo entre os dias 01 e 07 de janeiro de 1996\npreE = filt_df[['Pres_MTA','Pres_BLT','Pres_OBD']]['1996\/01\/01':'1996\/01\/07'].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica sem Imputa\u00e7\u00e3o')\npreE.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","564cc9a7":"# Visualiza\u00e7\u00e3o do sensor Press\u00e3o Atmosf\u00e9rica para as 3 esta\u00e7\u00f5es\nPressaoP = filt_df[['Pres_MTA','Pres_BLT','Pres_OBD']].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica ap\u00f3s imputa\u00e7\u00e3o simples')\nPressaoP.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","6dad9a3b":"# Numerode elementos sem registro no DataFrame com corre\u00e7\u00e3o\nfilt_df.isna().sum()","86c4cfa3":"# Exemplo de visualiza\u00e7\u00e3o para imputa\u00e7\u00e3o\n# Exemplo entre os dias 01 e 07 de janeiro de 1996\nhumE = filt_df[['UmidR_MTA','UmidR_BLT','UmidR_OBD']]['1995\/12\/27':'1996\/01\/07'].plot(figsize=(15,5),title='Umidade Relativa sem Imputa\u00e7\u00e3o')\nhumE.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Umidade em %')\nplt.show()","703241fe":"# Media entre Belterra e Oriximina\nfilt_df['UmidR_MTA'] = filt_df.UmidR_MTA.fillna(filt_df[['UmidR_BLT','UmidR_OBD']].mean(axis=1))","e5e8a9d0":"# Exemplo de visualiza\u00e7\u00e3o para imputa\u00e7\u00e3o\n# Exemplo entre os dias 01 e 07 de janeiro de 1996\nhumE = filt_df[['UmidR_MTA','UmidR_BLT','UmidR_OBD']]['1995\/12\/27':'1996\/01\/07'].plot(figsize=(15,5),title='Umidade Relativa com imputa\u00e7\u00e3o estat\u00edstica')\nhumE.legend(['Monte Alegre','Belterra','\u00d3bidos'])\nplt.xlabel('Data')\nplt.ylabel('Umidade em %')\nplt.show()","011b95f5":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","c61217c4":"imp = IterativeImputer(max_iter=10, random_state=0)\n\n## Imputa\u00e7\u00e3o para Temperatura Bulbo Seco\ntimp = imp.fit(filt_df.loc[:,['TempBS_MTA','TempBS_BLT','TempBS_OBD']].to_numpy())\ntimp = timp.transform(filt_df.loc[:,['TempBS_MTA','TempBS_BLT','TempBS_OBD']].to_numpy())","7ed4c403":"df_final = filt_df.drop(['TempBS_MTA','TempBS_BLT','TempBS_OBD'], axis=1)","dcb92450":"df_final['TempBS_MTA'] = timp[:,0]\ndf_final['TempBS_BLT'] = timp[:,1]\ndf_final['TempBS_OBD'] = timp[:,2]","689c6b49":"df_final.isna().sum()","ce9eead2":"# Removendo os valores nulos\ndf_final = df_final.dropna()","3019ec74":"df_final[['Pres_MTA','Pres_BLT','Pres_OBD']].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica ap\u00f3s imputa\u00e7\u00e3o simples')\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","219de20b":"df_final[['Pres_MTA','Pres_BLT','Pres_OBD']]['1988':'2013'].plot(figsize=(15,5),title='Press\u00e3o Atmosf\u00e9rica ap\u00f3s imputa\u00e7\u00e3o estat\u00edstica final')\nplt.xlabel('Data')\nplt.ylabel('Press\u00e3o Atmosf\u00e9rica em hPa')\nplt.show()","dd8877eb":"f, ax = plt.subplots(figsize=(15, 8))\nplt.title('Matriz de Correla\u00e7\u00e3o entre as vari\u00e1veis')\ncorr = df_final.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.show()","53c2515e":"df = df_final\ndf.head()","1995e2dc":"print('Quantidade de registros: ', df.values.shape[0], ', Quantidade de atributos: ', df.values.shape[1])","d5b1a5f4":"# df['Day'] = df.index.dayofyear\n# df['Hour'] = df.index.hour","a7653d7c":"# Reorganizar dados\n# df = df_final[['Day','Hour','TempBS_MTA','TempBU_MTA','UmidR_MTA','Pres_MTA',\n#                'TempBS_BLT','TempBU_BLT','UmidR_BLT','Pres_BLT',\n#                'TempBS_ORX','TempBU_ORX','UmidR_ORX','Pres_ORX']]\n\ndf = df_final[['TempBS_MTA','UmidR_MTA','Pres_MTA',\n               'TempBS_BLT','UmidR_BLT','Pres_BLT',\n               'TempBS_OBD','UmidR_OBD','Pres_OBD']]","4ede2005":"df.head()","8429d81a":"target_city = 'Monte Alegre'\ntarget_names = ['TempBS_MTA','UmidR_MTA','Pres_MTA']\nshift_days = 3\nshift_steps = shift_days * 3 # N\u00famero de horas","5c096106":"# Novo dataframe\ndf_targets = df[target_names].shift(-shift_days)\ndf_targets","eb8ed508":"# Vetor de ENTRADA\nx_data = df.values[0:-shift_steps]\n\nprint('Tipo dos dados: ',type(x_data))\nprint(\"Tamanho de entradas (observa\u00e7\u00f5es) e n\u00famero de atributos \", x_data.shape)","a76058c4":"# Vetor de sa\u00edda a partir do DataFrame target (Cidade Odense), ultimas linhas para previs\u00e3o\ny_data = df_targets.values[:-shift_steps]\nprint('Tipo dos dados: ',type(y_data))\nprint(\"Tamanho de sa\u00edda (observa\u00e7\u00f5es) e n\u00famero de atributos \", y_data.shape)","e5984fcf":"print('Tamanho do Vetor de Entrada: ', len(x_data))\nprint('Tamanho do Vetor de Sa\u00edda: ', len(y_data))","ffcdc007":"# numero de dados de oberserva\u00e7\u00e3o\nnum_data = len(x_data)\n\n# fra\u00e7\u00e3o para treinamento\ntrain_split = 0.9\n\n# n\u00famero de elementos para treinamento\nnum_train = int(train_split * num_data)\nprint('N\u00famero de elementos para treinamento: ', num_train)\nnum_test = num_data - num_train\nprint('N\u00famero de elementos para teste: ', num_test)","25bc8391":"# vetores de entrada para teste e treinamento\nx_train = x_data[0:num_train]\nx_test = x_data[num_train:]","46ca27f9":"# vetores de sa\u00edda para teste e treinamento\ny_train = y_data[0:num_train]\ny_test = y_data[num_train:]","8ab06ab0":"# numero de atributos de entrada\nnum_x_signals = x_data.shape[1]\nprint('Atributos de entrada: ', num_x_signals)\nnum_y_signals = y_data.shape[1]\nprint('Atributos de sa\u00edda: ', num_y_signals)","1b1aa970":"print(\"Min:\", np.min(x_train))\nprint(\"Max:\", np.max(x_train))","2f4b7151":"# objeto para os sinais de entrada\nx_scaler = MinMaxScaler()","c06a3a6a":"# fun\u00e7\u00e3o para normaliza\u00e7\u00e3o dos dados de entrada do treinamento\nx_train_scaled = x_scaler.fit_transform(x_train)","98b951c5":"print(\"Min:\", np.min(x_train_scaled))\nprint(\"Max:\", np.max(x_train_scaled))","552f074d":"# o mesmo objeto x_caler \u00e9 utilizado para os valores de teste\nx_test_scaled = x_scaler.transform(x_test)","7b7419f9":"# outra funcao para normaliza\u00e7\u00e3o dos dados de treinamento e teste da sa\u00edda\ny_scaler = MinMaxScaler()\ny_train_scaled = y_scaler.fit_transform(y_train)\ny_test_scaled = y_scaler.transform(y_test)","7f837811":"print(\"Min:\", np.min(y_train_scaled))\nprint(\"Max:\", np.max(y_train_scaled))","6ff150d9":"def batch_generator(batch_size, sequence_length):\n    \"\"\"\n    Generator function for creating random batches of training-data.\n    \"\"\"\n\n    # Infinite loop.\n    while True:\n        # Allocate a new array for the batch of input-signals.\n        x_shape = (batch_size, sequence_length, num_x_signals)\n        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n\n        # Allocate a new array for the batch of output-signals.\n        y_shape = (batch_size, sequence_length, num_y_signals)\n        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n\n        # Fill the batch with random sequences of data.\n        for i in range(batch_size):\n            # Get a random start-index.\n            # This points somewhere into the training-data.\n            idx = np.random.randint(num_train - sequence_length)\n            \n            # Copy the sequences of data starting at this index.\n            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n        \n        yield (x_batch, y_batch)","e16cbdb8":"# Tamanho do batch\nbatch_size = 19","4e4403e9":"# Sequ\u00eancia para cada batch\nsequence_length = 1229","5d515f73":"# gerador de dados em lote\ngenerator = batch_generator(batch_size=batch_size,\n                            sequence_length=sequence_length)","213bdb6d":"# teste para o gerador de dados em lote\nx_batch, y_batch = next(generator)","36f8bc6a":"x_train_scaled.shape","585c5a12":"print(x_batch.shape)\nprint(y_batch.shape)","a99d1ebe":"batch = 0   # Primeiro bloco \nsignal = 2  #Sinal a partir dos dados com 9 atributos\nseq = x_batch[batch, :, signal]\nplt.figure(figsize=(15,3))\nplt.title(label='Sinal de entrada com 9 atributos, tamanho do lote = 1229')\nplt.plot(seq)\nplt.show()","e7edab35":"seq = y_batch[batch, :, signal]\nplt.figure(figsize=(15,3))\nplt.title(label='Sinal de sa\u00edda com 9 atributos, tamanho do lote = 1229')\nplt.plot(seq)\nplt.show()","7785a086":"validation_data = (np.expand_dims(x_test_scaled, axis=0),\n                   np.expand_dims(y_test_scaled, axis=0))","3c0ce6aa":"print('Formato dos dados de valida\u00e7\u00e3o entrada: ', validation_data[0].shape )\nprint('Formato dos dados de valida\u00e7\u00e3o sa\u00edda: ', validation_data[1].shape )","3174673c":"# tensorflow e keras engine\nmodel = Sequential()","f88aeed4":"print('Num\u00e9ro de sinais de entrada:',num_x_signals)","a914745c":"model.add(GRU(units=256,\n              return_sequences=True,\n              input_shape=(None, num_x_signals,)))\nmodel.add(Dropout(0.3,))","5f948260":"model_lstm = Sequential()\nmodel_lstm.add(LSTM(units = 256,\n                return_sequences=True,\n                input_shape=(None,num_x_signals)))\nmodel_lstm.add(Dropout(0.3))","48f1695b":"#GRU Dense\nmodel.add(Dense(num_y_signals, activation='sigmoid'))\n\n#LSTM Dense\nmodel_lstm.add(Dense(num_y_signals, activation='sigmoid'))","9ac236f4":"# periodos para warmup-period\nwarmup_steps = 50","adf40111":"def loss_mse_warmup(y_true, y_pred):\n    \n    \"\"\"\n    Calcula MSE entre as sa\u00eddas verdadeiras e sa\u00eddas previsas\n    por\u00e9m ignora a sequ\u00eancia inicial de aquecimento.\n    \n    y_true \u00e9 a sa\u00edda desejada.\n    y_pred \u00e9 a sa\u00edda do modelo.\n    \"\"\"\n\n    # tamanho para os dois tensores de entrada:\n    #  Ignora parte da sequec\u00eancia \"warmup\", tomando como medida parte do tamanho dos tensores\n\n    y_true_slice = y_true[:, warmup_steps:, :]\n    y_pred_slice = y_pred[:, warmup_steps:, :]\n\n    # Calcula o MSE para cada valor de tensores\n    loss = tf.losses.mean_squared_error(labels=y_true_slice,\n                                        predictions=y_pred_slice)\n\n    loss_mean = tf.reduce_mean(loss)\n\n    return loss_mean","3ba15da7":"optimizer = RMSprop(lr=1e-3)","1c32a701":"model.compile(loss=loss_mse_warmup, optimizer=optimizer)\nmodel.summary()","8cfdafc6":"model_lstm.compile(loss=loss_mse_warmup, optimizer=optimizer)\nmodel_lstm.summary()","85899502":"path_checkpoint = 'GRU_256N_01.keras'\ncallback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n                                      monitor='val_loss',\n                                      verbose=1,\n                                      save_weights_only=True,\n                                      save_best_only=True)","4e30a17d":"path_checkpoint_LSTM = 'LSTM_256N_01.keras'\ncallback_checkpoint_lstm = ModelCheckpoint(filepath=path_checkpoint_LSTM,\n                                      monitor='val_loss',\n                                      verbose=1,\n                                      save_weights_only=True,\n                                      save_best_only=True)","c16f3840":"callback_early_stopping = EarlyStopping(monitor='val_loss',\n                                        patience=5, verbose=1)","ffcb24ab":"callback_tensorboard = TensorBoard(log_dir='.\/GRU_log\/',\n                                   histogram_freq=0,\n                                   write_graph=True,\n                                   write_images=True)","08add53e":"callback_tensorboard_lstm = TensorBoard(log_dir='.\/LSTM_log\/',\n                                   histogram_freq=0,\n                                   write_graph=True,\n                                   write_images=True)","c7fbfed3":"callback_early_stopping_lstm = EarlyStopping(monitor='val_loss',\n                                        patience=5, verbose=1)","454765ed":"callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                                       factor=0.1,\n                                       min_lr=1e-4,\n                                       patience=0,\n                                       verbose=1)","8f00bbae":"callbacks = [callback_early_stopping,\n             callback_checkpoint,\n             callback_tensorboard,\n             callback_reduce_lr]","75b4229b":"callbacks_LSTM = [callback_early_stopping_lstm,\n             callback_checkpoint_lstm,\n             callback_tensorboard_lstm,\n             callback_reduce_lr]","73331caa":"%%time\ngru_history = model.fit_generator(generator=generator,\n                    epochs=80,\n                    steps_per_epoch=100,\n                    validation_data=validation_data,\n                    callbacks=callbacks)","2e9f9d2c":"%%time\nlstm_history = model_lstm.fit_generator(generator=generator,\n                    epochs=80,\n                    steps_per_epoch=100,\n                    validation_data=validation_data,\n                    callbacks=callbacks_LSTM)","e9993dce":"try:\n    model.load_weights(path_checkpoint)\nexcept Exception as error:\n    print(\"Error trying to load checkpoint.\")\n    print(error)","17fd8fd2":"plt.figure(figsize=(15,5))\nplt.title('Gr\u00e1fico de perdas')\nplt.plot(lstm_history.history['loss'], label='LSTM - loss',color='green')\nplt.plot(lstm_history.history['val_loss'], label='LSTM - val_loss',color='black')\nplt.plot(gru_history.history['loss'], label='GRU - loss',color='blue')\nplt.plot(gru_history.history['val_loss'], label='GRU - val_loss',color='red')\nplt.xlabel('\u00c9pocas')\nplt.ylabel('%')\nplt.legend()\nplt.show()","6d999bcb":"result = model.evaluate(x=np.expand_dims(x_test_scaled, axis=0),\n                        y=np.expand_dims(y_test_scaled, axis=0))","c6f24cc2":"result2 = model_lstm.evaluate(x=np.expand_dims(x_test_scaled, axis=0),\n                        y=np.expand_dims(y_test_scaled, axis=0))","36f1ac77":"print(\"loss (test-set):\", result)","80f10ac8":"def output_frame_GRU(start_idx, length, train=True):\n    \"\"\"\n    :param start_idx: Indice inicial da s\u00e9rie temporal.\n    :param length: Comprimento da sequ\u00eancia, n\u00famero de elementos ap\u00f3s o indice inicial.\n    :param train: Valor Booleano para utilizar dados treinamento ou teste.\n    \"\"\"\n    \n    if train == True:\n        # Usar dados de treinamento.\n        x = x_train_scaled\n        y_true = y_train\n    else:\n        # Usar dados de teste.\n        x = x_test_scaled\n        y_true = y_test\n    \n    # Indice final para sequ\u00eancia, tempo inicial mais comprimento.\n    end_idx = start_idx + length\n    \n    #Selecione a seq\u00fc\u00eancia do \u00edndice inicial especificado e comprimento.\n    x = x[start_idx:end_idx]\n    y_true = y_true[start_idx:end_idx]\n    \n    # Sinais de entrada para o modelo.\n    x = np.expand_dims(x, axis=0)\n\n    # Usar o modelo para prever os sinais de sa\u00edda.\n    y_pred = model.predict(x)\n    \n    # A sa\u00edda do modelo tem valores entre 1 e 0.\n    # Ser\u00e1 necess\u00e1rio aplicar uma fun\u00e7\u00e3o de mapeamento inverso para deixar os dados rescalados\n    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n    \n    output = pd.DataFrame()\n    output['Prev_TempBS_MTA'] = y_pred_rescaled[:,0]\n    output['Prev_UmidR_MTA'] = y_pred_rescaled[:,1]\n    output['Prev_Pres_MTA'] = y_pred_rescaled[:,2]\n    output['Datetime'] = df[0:-shift_steps][num_train:].index[start_idx:start_idx+length]\n    output = output.set_index('Datetime')\n    \n    return output","8ddf3199":"def output_frame_LSTM(start_idx, length, train=True):\n    \"\"\"\n    :param start_idx: Indice inicial da s\u00e9rie temporal.\n    :param length: Comprimento da sequ\u00eancia, n\u00famero de elementos ap\u00f3s o indice inicial.\n    :param train: Valor Booleano para utilizar dados treinamento ou teste.\n    \"\"\"\n    \n    if train == True:\n        # Usar dados de treinamento.\n        x = x_train_scaled\n        y_true = y_train\n    else:\n        # Usar dados de teste.\n        x = x_test_scaled\n        y_true = y_test\n    \n    # Indice final para sequ\u00eancia, tempo inicial mais comprimento.\n    end_idx = start_idx + length\n    \n    #Selecione a seq\u00fc\u00eancia do \u00edndice inicial especificado e comprimento.\n    x = x[start_idx:end_idx]\n    y_true = y_true[start_idx:end_idx]\n    \n    # Sinais de entrada para o modelo.\n    x = np.expand_dims(x, axis=0)\n\n    # Usar o modelo para prever os sinais de sa\u00edda.\n    y_pred = model_lstm.predict(x)\n    \n    # A sa\u00edda do modelo tem valores entre 1 e 0.\n    # Ser\u00e1 necess\u00e1rio aplicar uma fun\u00e7\u00e3o de mapeamento inverso para deixar os dados rescalados\n    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n    \n    output = pd.DataFrame()\n    output['Prev_TempBS_MTA'] = y_pred_rescaled[:,0]\n    output['Prev_UmidR_MTA'] = y_pred_rescaled[:,1]\n    output['Prev_Pres_MTA'] = y_pred_rescaled[:,2]\n    \n    output['Datetime'] = df[0:-shift_steps][num_train:].index[start_idx:start_idx+length]\n    output = output.set_index('Datetime')\n    \n    return output","818ff389":"length = 500\nstart_idx = 0","2869e147":"# apenas com os dados de treinamento\nsaida_LSTM = output_frame_LSTM(start_idx=start_idx, length=length, train=False)\nsaida_GRU = output_frame_GRU(start_idx=start_idx, length=length, train=False)\nsaida_LSTM.head()","6f040233":"from math import sqrt\nfrom sklearn.metrics import mean_squared_error","ffea611a":"x = df['TempBS_MTA'][0:-shift_steps][num_train:][start_idx:start_idx+length].values.reshape(-1,1)\ny_L = saida_LSTM['Prev_TempBS_MTA'].values.reshape(-1,1)\ny_G = saida_GRU['Prev_TempBS_MTA'].values.reshape(-1,1)\n\nxscaler = MinMaxScaler()\n\nscalx = xscaler.fit_transform(x)\nscaly_L = xscaler.fit_transform(y_L)\nscaly_G = xscaler.fit_transform(y_G)\n\nplt.figure(figsize=(15,5))\nplt.plot(df['TempBS_MTA'][0:-shift_steps][num_train:][start_idx:start_idx+length], label='Verdadeira',)\nplt.plot(saida_LSTM['Prev_TempBS_MTA'], label='Prevista')\nrmse = sqrt(mean_squared_error(scalx,scaly_L))*100\nplt.title('Temperatura de Bulbo Seco - LSTM: atual vs previsto: error: %.3f' %rmse + '%')\nplt.legend()\nplt.show()","36681442":"plt.figure(figsize=(15,5))\nplt.plot(df['TempBS_MTA'][0:-shift_steps][num_train:][start_idx:start_idx+length], label='Verdadeira')\nplt.plot(saida_GRU['Prev_TempBS_MTA'], label='Prevista')\nrmse = sqrt(mean_squared_error(scalx,scaly_G))*100\nplt.title('Temperatura de Bulbo Seco - GRU: atual vs previsto: error: %.3f' %rmse + '%')\nplt.legend()\nplt.show()","36ef742c":"plt.figure(figsize=(15,5))\nplt.plot(df['UmidR_MTA'][0:-shift_steps][num_train:][start_idx:start_idx+length][start_idx:start_idx+length], label='Verdadeira')\nplt.plot(saida_GRU['Prev_UmidR_MTA'], label='Prevista')\nplt.legend()","e4ce3b07":"plt.figure(figsize=(15,5))\nplt.plot(df['Pres_MTA'][0:-shift_steps][num_train:][start_idx:start_idx+length][start_idx:start_idx+length], label='Verdadeira')\nplt.plot(saida_GRU['Prev_Pres_MTA'], label='Prevista')\nplt.legend()","f40d0a3c":"def plot_comparison(start_idx, length=100, train=True):\n    \"\"\"\n    Plot the predicted and true output-signals.\n    \n    :param start_idx: Start-index for the time-series.\n    :param length: Sequence-length to process and plot.\n    :param train: Boolean whether to use training- or test-set.\n    \"\"\"\n    \n    if train:\n        print('s')\n        # Use training-data.\n        x = x_train_scaled\n        y_true = y_train\n    else:\n        # Use test-data.\n        x = x_test_scaled\n        y_true = y_test\n    \n    # End-index for the sequences.\n    end_idx = start_idx + length\n    \n    # Select the sequences from the given start-index and\n    # of the given length.\n    x = x[start_idx:end_idx]\n    y_true = y_true[start_idx:end_idx]\n    \n    # Input-signals for the model.\n    x = np.expand_dims(x, axis=0)\n\n    # Use the model to predict the output-signals.\n    y_pred = model_lstm.predict(x)\n    \n    # The output of the model is between 0 and 1.\n    # Do an inverse map to get it back to the scale\n    # of the original data-set.\n    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n    \n    # For each output-signal.\n    for signal in range(len(target_names)):\n        # Get the output-signal predicted by the model.\n        signal_pred = y_pred_rescaled[:, signal]\n        \n        # Get the true output-signal from the data-set.\n        signal_true = y_true[:, signal]\n\n        # Make the plotting-canvas bigger.\n        plt.figure(figsize=(15,5))\n        \n        # Plot and compare the two signals.\n        plt.plot(signal_true, label='true')\n        plt.plot(signal_pred, label='pred')\n        \n        # Plot grey box for warmup-period.\n        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n        \n        # Plot labels etc.\n        plt.ylabel(target_names[signal])\n        plt.legend()\n        plt.show()","76c24e7c":"plot_comparison(start_idx=200, length=500, train=False)","f1eb2685":"def plot_comparison_GRU(start_idx, length=100, train=True):\n    \"\"\"\n    Plot the predicted and true output-signals.\n    \n    :param start_idx: Start-index for the time-series.\n    :param length: Sequence-length to process and plot.\n    :param train: Boolean whether to use training- or test-set.\n    \"\"\"\n    \n    if train:\n        print('s')\n        # Use training-data.\n        x = x_train_scaled\n        y_true = y_train\n    else:\n        # Use test-data.\n        x = x_test_scaled\n        y_true = y_test\n    \n    # End-index for the sequences.\n    end_idx = start_idx + length\n    \n    # Select the sequences from the given start-index and\n    # of the given length.\n    x = x[start_idx:end_idx]\n    y_true = y_true[start_idx:end_idx]\n    \n    # Input-signals for the model.\n    x = np.expand_dims(x, axis=0)\n\n    # Use the model to predict the output-signals.\n    y_pred = model.predict(x)\n    \n    # The output of the model is between 0 and 1.\n    # Do an inverse map to get it back to the scale\n    # of the original data-set.\n    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])\n    \n    # For each output-signal.\n    for signal in range(len(target_names)):\n        # Get the output-signal predicted by the model.\n        signal_pred = y_pred_rescaled[:, signal]\n        \n        # Get the true output-signal from the data-set.\n        signal_true = y_true[:, signal]\n\n        # Make the plotting-canvas bigger.\n        plt.figure(figsize=(15,5))\n        \n        # Plot and compare the two signals.\n        plt.plot(signal_true, label='true')\n        plt.plot(signal_pred, label='pred')\n        \n        # Plot grey box for warmup-period.\n        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n        \n        # Plot labels etc.\n        plt.ylabel(target_names[signal])\n        plt.legend()\n        plt.show()","70f8818b":"plot_comparison_GRU(start_idx=200, length=500, train=False)","23b8a248":"Este ser\u00e1 um modelo relativamente pequeno com apenas duas camadas, e sua forma de sa\u00edda ser\u00e1 (None, None, 4) que significa que o modelo ir\u00e1 produzir um lote com um n\u00famero de sequ\u00eancias onde cada uma corresponde a observa\u00e7\u00e3o de 4 sinais que est\u00e3o sendo previstos.","5b1187e2":"### Resultados\n\n> Compara\u00e7\u00e3o entre os resultados para sa\u00edda da rede GRU e LSTM com dados de teste","a354a1f7":"Quanto maior o tamanho do lote, maior a carga de trabalhos para os processadores, por tanto \u00e9 necess\u00e1rio que o valor do batch_size seja de acordo com um valor ideial para o processodor e mem\u00f3ria.","7ad71f75":"Em seguida esse modelo ser\u00e1 compilado pelo Keras e estara pronto a parte do treinamento.\n\n","203716b9":"## Rede Neural Recorrente\n\nPrepara\u00e7\u00e3o da Redes","4f1e20f1":"### Selecionando Cidade Para Previs\u00e3o\n\nA cidade selecionada ser\u00e1 a cidade de Oriximin\u00e1 e as vari\u00e1veis ser\u00e3o **(TempBS_MTA, TempBU_MTA, UmidR_MTA e Pres_MTA)**, sendo que a previs\u00e3o busca por dados das pr\u00f3ximas 24 horas acumuladas.","619e8054":"#### Treinamento e Teste\n\nPara este experimento ser\u00e3o selecionados 90% dos dados para treinamento e 10% para teste","b13dd5b0":"## Imputa\u00e7\u00e3o de dados\n\nNota-se que no gr\u00e1fico de Press\u00e3o atmosf\u00e9rica existe uma quantidade consideravel de valores nulos para cidade de Monte Alegre, ou seja, ser\u00e1 necess\u00e1rio aplicar uma m\u00e9trica inicial para preencher os dados sem registro, desta forma iremos aplicar uma imputa\u00e7\u00e3o simples para os dados de Press\u00e3o Atmosf\u00e9rica na cidade de Monte Alegre, que consistem em usar os valores das cidades de Belterra e Oriximin\u00e1 para estimar a os valores de Monte Alegre pela m\u00e9dia entre as cidades Belterra e Oriximin\u00e1. Como a esta\u00e7\u00e3o meteorol\u00f3gica de Monte Alegre fica a uma altitude entre as cidades de Oriximin\u00e1 e e Belterra seu valor estimado por uma imputa\u00e7\u00e3o simples n\u00e3o sofrera grandes impactos.","c25309b2":"### LSTM","30acc1e3":"#### Desempenho para o conjunto de teste\n\n\u00c9 poss\u00edvel avaliar o desempenho do modelo para os dados de teste","8309769a":"### Fun\u00e7\u00e3o de perda\n\nPara a fun\u00e7\u00e3o de perda (Loss) ser\u00e1 utilizado o Erro Quadr\u00e1tico M\u00e9dio (do ingl\u00eas Mean Squared Error sigla MSE) isso ir\u00e1 medir quanto a sa\u00edda do modelo corresponde aos valores verdadeiros do sinal de sa\u00edda. Por\u00e9m, no in\u00edcio de uma sequ\u00eancia, o modelo s\u00f3 viu sinais de entrada por durante algumas etapas e sua sa\u00edda gerada pode ser muito imprecisa e o uso do valor da perda nas etapas iniciais pode fazer com que o modelo distor\u00e7a a sa\u00edda anterior para resolver isso atribu\u00edmos ao modelo um \"warmup-period\" de 50 etapas no tempo em que n\u00e3o ser\u00e1 utilizaada sua precis\u00e3o na fun\u00e7\u00e3o de perda com objetivo de melhorar a precis\u00e3o nas etapas anteriores.","795e8c90":"#### Modelo de otimiza\u00e7\u00e3o\n\nO RMSprop \u00e9 um m\u00e9todo para otimiza\u00e7\u00e3o com taxa adaptativa que usa uma m\u00e9dia movel exponencial e ser\u00e1 o modelo inicial para otimiza\u00e7\u00e3o.\nTaxa de aprendizado","fa812d7a":"### Rede Neural Recorrente\n\nO conceito b\u00e1sico por tr\u00e1s de uma Rede Neural Recorrente (sigla para Recurrent Neural Network - RNN) \u00e9 a sua Unidade Recorrente (UR), existem algumas varia\u00e7\u00f5es de unidades recorrentes, como a LSTM (do ingl\u00eas Long-Short-Term-Memory) e a Gated Recurrent Unit (GRU). Para este tutorial iremos utilizar a implementa\u00e7\u00e3o da GRU disponivel na biblioteca do Keras.\n\nA ideia b\u00e1sica da GRU \u00e9 que sua UR possui um valor interno que \u00e9 atualizado sempre que a unidade recebe uma nova entrada, esse estado interno serve como uma mem\u00f3ria que armazena os valores para o treinamento da rede usando um gradiente descendente. O novo valor do estado depente do valor antigo e de sua entrada atual.\n\nPara treinar a UR, \u00e9 necess\u00e1rio alterar gradualmente as matrizes de peso de cada entrada para que a UR produza a sa\u00edda desejada para uma sequ\u00eancia de entrada, isso \u00e9 feito automaticamente no TensorFlow.","c169263b":"A GRU \u00edra gerar um lote de sequ\u00eancias com 512 valores, e desejamos prever tr\u00eas sa\u00eddas, portanto adicionamos mais uma camada densa que mapeia esses 512 valores para apenas 4 sa\u00eddas, esses sinais foram limitados a estar entre 0 e 1 devido a fun\u00e7\u00e3o scaler, ent\u00e3o tamb\u00e9m \u00e9 necess\u00e1rio limitar a sa\u00edda da rede para uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o sigmoid que limita o valor de sa\u00edda entre 0 e 1.","d27126ff":"### Treinamento da Rede Neural Recorrente\n\nTreinamento da Rede Neural Recorrente\nO pr\u00f3ximo bloco de c\u00f3digos ir\u00e1 treinar a rede neural, onde uma \u00fanica \u00e9poca n\u00e3o corresponde a um \u00fanico processamento mas sim a um lote gerado pela fun\u00e7\u00e3o que empacota e seleciona de forma aleat\u00f3ria uma sub-sequ\u00eancia do conjunto de treinamento.\n\nEsse modelo foi treinado sobre um processador Intel Core i7","bbdecc4d":"### Normaliza\u00e7\u00e3o dos dados\n\nOs dados de entrada e sa\u00edda est\u00e3o em escalas diferentes, variando de valores negativos (ex: temperatura) a valores altos (press\u00e3o), por tanto, \u00e9 necess\u00e1rio aplicar uma normaliza\u00e7\u00e3o dos dados para que esta varia\u00e7\u00e3o seja de 0 \u00e0 1 pois as redes neurais trabalham melhor nesta escala, para isso \u00e9 poss\u00edvel utilizar a fun\u00e7\u00e3o MinMaxScaler da biblioteca scikit-learn.","54b096bc":"#### Gera\u00e7\u00e3o de previs\u00f5es\n\nA fun\u00e7\u00e3o a baixo auxlia na visualiza\u00e7\u00e3o dos sinais de sa\u00edda previstos e compara-los com os valores verdadeiros Esta fun\u00e7\u00e3o auxiliar tra\u00e7a os sinais de sa\u00edda previstos e verdadeiros.","08ea965d":"### Visualiza\u00e7\u00e3o dos dados\n\nAp\u00f3s organizar os dados ser\u00e1 necess\u00e1rio visualizar para que se possa definir quais as vari\u00e1veis mais importantes para a imputa\u00e7\u00e3o.\n\nOs dados foram plotados e divididos a partir de suas vari\u00e1veis (Temperatura de Bulbo Seco; Temperatura de Bulbo Umido, Umidade e Press\u00e3o Atmosf\u00e9rica)","39a53599":"#### Gera\u00e7\u00e3o de dados em lote\nOs dados j\u00e1 est\u00e3o preparados de forma vetorial e bi-dimensional, por\u00e9m para o treinamento \u00e9 possivel melhorar a forma de entrada para rede, organizando os mesmos em lotes, a fun\u00e7\u00e3o a baixo cria o melhor lote para sub-sequ\u00eancia dos dados de forma aleat\u00f3ria.","c5e7413c":"### Range dos Dados\n\nDevido a vari\u00e1vel \"Pres_ORX\" apresentar uma maior quantidade de dados faltantes (total 3370) para o ultimo periodo da s\u00e9rie temporal, iremos considerar apenas os ultimos 25 anos de dados para nossa s\u00e9rie final, ou seja, apenas dados dos anos **(1988 a 2013)** ser\u00e3o utilizados para o treinamento da rede. ","46777ce0":"### Corre\u00e7\u00e3o de outliers\n\nAlgumas medi\u00e7\u00f5es apresentam valores incongruentes com a m\u00e9dia dos dados, e para isso ser\u00e1 necess\u00e1rio aplicar um m\u00e9todo que fa\u00e7a a corre\u00e7\u00e3o desses dados discrepantes.","8ce995ea":"### Imputa\u00e7\u00e3o Multivariada\n\nDevido a alta correla\u00e7\u00e3o entre os valores de temperatura \u00e9 poss\u00edvel aplicar uma imputa\u00e7\u00e3o multivariada entre os dados.","183199ec":"#### Fun\u00e7\u00f5es de Callback\n\nDurante o treinamento \u00e9 necess\u00e1rio salvar os checkpoints e os registros do processo para o TensorBoard criando fun\u00e7\u00f5es de callback para o Keras, essa fun\u00e7\u00e3o ir\u00e1 escrever checkpoints durante o treinamento","cefc7c17":"### Dados de valida\u00e7\u00e3o\n\nUma rede neural pode treinar rapidamente v\u00e1rias epocas, no entanto existe um risco de \"overfitting\" sobre o modelo treinado e para que n\u00e3o haja uma generaliza\u00e7\u00e3o no treinamento o gerador de lote seleciona aleatoriamente uma sequ\u00eancia curta de dados e o utiliza durante o treinamento, por\u00e9m para valida\u00e7\u00e3o \u00e9 necess\u00e1rio percorrer toda a sequ\u00eancia do conjunto de testes e medir a precis\u00e3o da previs\u00e3o para toda sequ\u00eancia de teste e treinamento. Por tanto, a variavel \"validation_data\" reune os dois vetores de entrada e saida para que possa validar os resultados.","58ae0aba":"### Carregando os checkpoints\n\nDevido o uso da fun\u00e7\u00e3o call back que faz uma parada antecipada no treinamento, \u00e9 poss\u00edvel que o desempenho do modelo piore depois de v\u00e1rias \u00e9pocas antes da interrup\u00e7\u00e3o do treinamento, ou sej\u00e1, \u00e9 necess\u00e1rio carregar o \u00faltimo ponto de verifica\u00e7\u00e3o salvo pois esse ter\u00e1 o melhor desempenho para os pesos de treinamento.","a01104c0":"## Carregando dados\nOs arquivos brutos foram baixados do INMET e armazenados no diret\u00f3rio '\/dataset'.","970bdc9f":"Ap\u00f3s o modelo podemos adicionar a RU para \u00e0 rede, neste caso teram 512 sa\u00eddas para cada intervalo de tempo da sequ\u00eancia, um fator importante \u00e9 que essa ser\u00e1 a primeira camada do modelo e o Keras precisa reconhecer o formato da entrada, ou seja, a entrada ser\u00e1 um lote de sequ\u00eancias com um comprimento arbitr\u00e1rio onde cada observa\u00e7\u00e3o possui 14 sinais de entrada (num_x_signals).","49a50c87":"### Adicionando atributos aos dados","151c7b04":"### DataFrame para Vetor\n\nPara entrada da rede \u00e9 necess\u00e1rio converter o DataFrame (Pandas) para um vetor, isso \u00e9 feito atrav\u00e9s da biblioteca NumPy, \u00e9 necess\u00e1rio remover a ultima parte que contem valores NaN","eecb2841":"### Prepara\u00e7\u00e3o dos dados","5a197d4d":"### Bibliotecas","2a383b80":"## Exemplo 02 - Aplica\u00e7\u00e3o de RNN para predi\u00e7\u00e3o de s\u00e9rie temporal de microesta\u00e7\u00f5es na Amaz\u00f4nia\n\nNeste exemplo, ser\u00e1 utilizado das redes neurais recorrentes para imputa\u00e7\u00e3o de dados clim\u00e1ticas da cidade de Monte Alegre no estado do Par\u00e1.\n\n#### Dataset\nOs dados das esta\u00e7\u00f5es meteorol\u00f3gicas das cidades de Monte Alegre, Oriximina e Belterra a partir do ano 1988 \u00e0 2018"}}