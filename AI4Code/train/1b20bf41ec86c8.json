{"cell_type":{"2dd11912":"code","4b96ab09":"code","2445acf9":"code","2e1be6ef":"code","faa048cf":"code","9443d165":"code","755fb75a":"code","72358f30":"code","879e7095":"code","b7e48d6f":"code","4d7b3dc6":"code","9f84b97b":"code","96637ac3":"code","3392df76":"code","d45fcc5e":"code","1ea50724":"code","73cf70be":"code","674fc3d4":"code","66508188":"code","f723e585":"markdown","33ff2664":"markdown","33a596ad":"markdown","497869f4":"markdown","67e8f7be":"markdown","e838c6b4":"markdown","51fa6213":"markdown","c20c1daf":"markdown","3f3da30f":"markdown","36cbc00d":"markdown","e309ee4d":"markdown","ac4a9816":"markdown","576dd4b1":"markdown","038d91ee":"markdown","c13ac013":"markdown","dc11c903":"markdown","bf2a3e67":"markdown","bc488a51":"markdown","d4c21b14":"markdown","a240fd7d":"markdown","940085de":"markdown","a4cae518":"markdown","6d5afffe":"markdown","4306c481":"markdown","43c2b6c0":"markdown","399119c4":"markdown"},"source":{"2dd11912":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.express as px\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.classify import SklearnClassifier\nfrom wordcloud import WordCloud,STOPWORDS\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b96ab09":"import pandas as pd\ndf = pd.read_csv('\/kaggle\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv')\ndf.head()","2445acf9":"sns.countplot(x= df['Rating'])\n\n","2e1be6ef":"import nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nsid = SentimentIntensityAnalyzer()","faa048cf":"df['scores'] = df['Review'].apply(lambda hotel_overview: sid.polarity_scores(str(hotel_overview)))\ndf.head()","9443d165":"df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\ndf['sentiment_type']=''\ndf.loc[df.compound>0,'sentiment_type']='POSITIVE'\ndf.loc[df.compound==0,'sentiment_type']='NEUTRAL'\ndf.loc[df.compound<0,'sentiment_type']='NEGATIVE'\ndf.head()","755fb75a":"df.sentiment_type.value_counts().plot(kind='bar',title=\"sentiment analysis\")","72358f30":"data = df[['Review','sentiment_type','compound', 'Rating']]\ndata","879e7095":"from sklearn.model_selection import train_test_split # function for splitting data to train and test sets\ntrain, test = train_test_split(data,test_size = 0.1)","b7e48d6f":"# Removing neutral sentiments\ntrain = train[train.sentiment_type != \"NEUTRAL\"]","4d7b3dc6":"train_pos = train[ train['sentiment_type'] == 'POSITIVE']\ntrain_pos = train_pos['Review']\ntrain_neg = train[ train['sentiment_type'] == 'NEGATIVE']\ntrain_neg = train_neg['Review']\n\ndef wordcloud_draw(data, color = 'black'):\n    words = ' '.join(data)\n    cleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and not word.startswith('#')\n                                and word != 'RT'\n                            ])\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(13, 13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Positive words\")\nwordcloud_draw(train_pos,'white')\nprint(\"Negative words\")\nwordcloud_draw(train_neg)","9f84b97b":"data.head()","96637ac3":"pip install --upgrade pycaret-nightly","3392df76":"from pycaret.nlp import *\nexp_name = setup(data = data, target = 'Review')","d45fcc5e":"lda = create_model('lda', num_topics = 6, multi_core = True)","1ea50724":"lda_top = assign_model(lda)\nlda_top.head()","73cf70be":"evaluate_model(lda)","674fc3d4":"plot_model(lda,'topic_model')","66508188":"save_model(lda,'Final LDA Model 07212020')","f723e585":"Sentiment analysis is essential for businesses and academai alike to better understand customers emotions. \n\n**Importance of SA from a business perspective:** You have just launched a new range of products and you want to identify the areas of opportunities to further enhance the product and to do that Sentiment Analysis can come in quite handy to identify those granular level of details to understand the product improvement opportunities relative to the sentiment of the customer. \n\n**From the perspective of academia:** Analysing students' feedback using sentiment analysis techniques can identify the students' positive or negative feelings, or even more re\ufb01ned emotions, that students have towards the current teaching.\n\nThere are otherways to slice and dice the data to get down to finer insights by utilizing demography, goegraphy and timestamp data and make valuable business decisions. ","33ff2664":"For this phase of the analysis I will be utilizing PyCaret's capabilities to perform NLP routine!","33a596ad":"**Step 1: Let's read the data**","497869f4":"\nNow let's split the data into training and a testing sets. The test set is the 10% of the original dataset. For this particular analysis I dropped reviews with neutral sentiment, as the reviews for neutral are almost none and may not have a great impact on the over all dataset. ","67e8f7be":"**SENTIMENT ANALYSIS PROCESS FLOW** *(SOURCE: DATACAMP)*\n\n![](https:\/\/cdn-images-1.medium.com\/max\/361\/0*ga5rNPmVYBsCm-lz.)","e838c6b4":"**Generating Sentiment Scores using Vader Sentiment Analyzer**","51fa6213":"This end to end sentiment analysis and prediction routine is based on TripAdvisor's hotel reviews, this data set has two columns Review and Ratings. The objective of this analysis cum prediction routine is to identify sentiments for the reviews posted by various customers using the NLTK Vader Sentiment Analyser and later create a model to predict the sentiment scores based on the input text. \n\nWe will also use a low code library named PyCaret to perform topic modeling to better understand the leading topic models within this corpus.\n\nSo let's get started!","c20c1daf":"# **PyCaret the ML Workhorse \ud83d\udc34**","3f3da30f":"**Step 2. EDA**","36cbc00d":"**LDAvis** = **L**atent **D**irichlet **A**llocation **Vis**ualization \ud83d\udc46\n\n**LDAvis** tool helps to create an interactive web-based visualization of a topic model that has been fit to a corpus of text data using Latent Dirichlet Allocation (LDA). \n\nGiven the estimated parameters of the topic model, it computes various summary statistics as input to an interactive visualization built with D3.js that is accessed via a browser. The goal is to help users interpret the topics in their LDA topic model.","e309ee4d":"# **Objective of the Analysis**","ac4a9816":"Now that we have performed some basic EDA on the data, we are ready for the next step that is Topic Modelling. From this point onwards I will be using the original data set for the remainder of the predictive analysis cycle.","576dd4b1":"# **Why it is so important for academicians and organizations to perform sentiment analysis?**","038d91ee":"# **Get the Data Ready**","c13ac013":"# **Let's Understand What is Sentiment Analysis?**","dc11c903":"From the above graph we can clearl see that most of the hotel reviews have a positive sentiments compared to negative and neurtal sentiments are quite low,hence,it will be agood idea to focus only on positive and negative set of reviews for further analysis. \n\nI will also reduce the data set by including only the review, sentiment type and compound score cols. ","bf2a3e67":"Interesting to notice the following words and expressions in the positive word set: good, room, people, lovely, nice, restaurant\n\nMy interpretation relted to these words are, in general customers had a positive experience as their rooms were well appointed and taken care of by good people.\n\nAt the same time, negative reviews contains words like: bad, clean, toilets, bathroom, reservation, paid, disappointed, problem\n\nMy interpertation about these words are that overall the experience was good (that's why high positive sentiment), however, cleanliness of toilets and washrooms could have caused bad experience and at the same time problematic reservation experience may have disappointed the customers.\n\nStop Word: Stop Words are words which do not contain important significance to be used in Search Queries. Usually these words are filtered out from search queries because they return vast amount of unnecessary information. ( the, for, this etc. )","bc488a51":"From the above graph, we can see that most of the customer rating is within the positive zone (high = 4-5). This leads us to believe that most reviews will be pretty positive too, which will be analyzed in a while.Now, we can create some wordclouds to see the most frequently used words in the reviews.","d4c21b14":"# **Saving the Model \ud83d\udcbe**","a240fd7d":"# Let's Setup the Environment\n\nSetting up the nlp environment entails the following actions, automagically performed!\n\n**Removing Numeric Characters:** All numeric characters are removed from the text. They are replaced with blanks.\n\n**Removing Special Characters:** All non-alphanumeric special characters are removed from the text. They are also replaced with blanks.\n\n**Word Tokenization:** Word tokenization is the process of splitting a large sample of text into words.\n\n**Stopword Removal:** A stop word (or stopword) is a word that is often removed from text because it is common and provides little value for information retrieval, even though it might be linguistically meaningful. Example of such words in english language are: \"the\", \"a\", \"an\", \"in\" etc.\n\n**Bigram Extraction:** A bigram is a sequence of two adjacent elements from a string of tokens, which are typically letters, syllables, or words.\n\n**Trigram Extraction:** Similar to bigram extraction, trigram is a sequence of three adjacent elements from a string of tokens.\n\n**Lemmatizing:** Lemmatization is the process of grouping together the inflected forms of a word so they can be analysed as a single word, identified by the word's lemma, or dictionary form. In English language, word appears in several inflected forms. For example the verb 'to walk' may appear as 'walk', 'walked', 'walks', 'walking'. The base form, 'walk', that one might look up in a dictionary, is called the lemma for the word.\n\n**Custom Stopwords:** We didn't use it but this option lets the user define specific words that they want to exclude from the text.","940085de":"# **Sentiment Analysis**","a4cae518":"Sentiment analysis is a method of identifying sentiment from a piece of text, it entails the process of text classification into a positive, negative or a neutral emotions leveragin various analytical techniques.","6d5afffe":"As a next step I separated the Positive and Negative tweets of the training set in order to easily visualize their contained words. After that I cleaned the text. Now they were ready for a WordCloud visualization which shows only the most emphatic words of the Positive and Negative tweets.","4306c481":"Now, we will take a look at the variable \u201cRating\u201d to see if majority of the customer ratings are positive or negative.","43c2b6c0":"Let's take a step back to better understand how the compound scores are calculated in Vader\n\nWhat does **VADER** stands for?\n\n**V**alence **A**ware **D**ictionary and s**E**ntiment **R**easoner\n\n**What is a compound score and how it is calculated?**\n\nThe compound score is the sum of positive, negative & neutral scores which is then normalized between **-1(most extreme negative)** and **+1 (most extreme positive)**.\n**The more Compound score closer to +1**, the higher the positivity of the text. These scores are calculated based on the Valence scores for the words in a sentence.\n\n**What is a Valence Score?**\n\nIt is a score assigned to the word under consideration by means of observation and experiences rather than pure logic.\n\nConsider the words 'terrible' , 'hopeless', 'miserable'. Any self-aware Human would easily gauge the sentiment of these words as Negative.\n\nWhile on the other side, words like 'marvellous', 'worthy', 'adequate' are signifying positive sentiment.\n\nAccording to the academic paper on VADER, the Valence score is measured on a scale from -4 to +4, where -4 stands for the most \u2018Negative\u2019 sentiment and +4 for the most \u2018Positive\u2019 sentiment. Intuitively one can guess that midpoint 0 represents \u2018Neutral\u2019 Sentiment, and this is how it is defined actually too.","399119c4":"**Creating Compound Scores along with the Sentiment Description for further analysis**"}}