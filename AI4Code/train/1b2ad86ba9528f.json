{"cell_type":{"04cd6ece":"code","0c5b50f1":"code","0dd9cc62":"code","b0c26c81":"code","1b0ccbb0":"code","116922c6":"code","025257e8":"code","2ff20dd5":"code","12585521":"code","444c485e":"markdown","6a1f814f":"markdown","0693967e":"markdown"},"source":{"04cd6ece":"import numpy as np\nimport pandas as pd\nfrom numpy import array, hstack\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","0c5b50f1":"path = \"..\/input\/mushroom-classification-updated-dataset\/mushroomsupdated.csv\"\npd.read_csv(path).head()","0dd9cc62":"class MushroomsDataset():\n    '''\n        Mushrooms Dataset\n    '''\n    def __init__(self, path):\n        self.df = pd.read_csv(path)\n        self.categories_idx()\n        self.one_hot_encoding()\n        \n    def one_hot_encoding(self):\n        self.df.replace(self.categories_to_idx, inplace=True)\n        \n    def get_features_labels(self):\n        labels = self.df['class'].values\n        features = self.df[list(self.df.columns)[1:]].values\n        return features, labels\n        \n    def categories_idx(self):\n        self.categories_to_idx = {}\n        self.idx_to_categories = {}\n\n        for column in self.df.columns:\n            temp = np.unique(self.df[column].values)\n            self.idx_to_categories[column] = {k:v for k,v in enumerate(temp)}\n            self.categories_to_idx[column] = {v:k for k,v in enumerate(temp)}","b0c26c81":"mdset = MushroomsDataset(path)\nmdset.df.head()","1b0ccbb0":"features, labels = mdset.get_features_labels()\nprint(features.shape, labels.shape)","116922c6":"X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33)","025257e8":"class OutOfFold():\n    '''\n        Out-of-Fold\n        \n        model1 - DecisionTreeClassifier\n        model2 - KNeighborsClassifier\n        model3 - LogisticRegression\n    '''\n    def __init__(self, n_split):\n        self.kfold = KFold(n_splits=n_split, shuffle=True)\n        \n    def create_meta_dataset(self, data_x, yhat1, yhat2):\n        yhat1 = array(yhat1).reshape((len(yhat1), 1))\n        yhat2 = array(yhat2).reshape((len(yhat2), 1))\n        return hstack((data_x, yhat1, yhat2))\n\n    def stack_prediction(self, model1, model2, model3, X):\n        yhat1 = model1.predict_proba(X)[:, 0]\n        yhat2 = model2.predict_proba(X)[:, 0]\n        return model3.predict(self.create_meta_dataset(X, yhat1, yhat2))\n    \n    def get_accuracy(self, model1, model2, X_test, y_test):\n        acc1 = accuracy_score(y_test, model1.predict(X_test))\n        acc2 = accuracy_score(y_test, model2.predict(X_test))\n        print('Decision_Tree Accuracy: %.3f, k-NN Accuracy: %.3f' % (acc1, acc2))\n        \n    def train_metadata(self, model1, model2, meta_X, data_y, X_test):\n        model3 = LogisticRegression(solver='liblinear')\n        model3.fit(meta_X, data_y)\n        yhat = self.stack_prediction(model1, model2, model3, X_test)\n        acc = accuracy_score(y_test, yhat)\n        return model3, yhat, acc\n        \n    def train(self, X, y):\n        data_x, data_y = list(), list()\n        dtree_yhat, knn_yhat = list(), list()\n        \n        for ix_train, ix_test in self.kfold.split(X):\n            data_x.extend(X[ix_test])\n            data_y.extend(y[ix_test])\n            model1, model2, yhat1, yhat2 = self.fit(X[ix_train], \n                                                    X[ix_test],\n                                                    y[ix_train])\n            dtree_yhat.extend(yhat1)\n            knn_yhat.extend(yhat2)\n        \n        return model1, model2, \\\n               data_x, data_y, \\\n               knn_yhat, dtree_yhat\n            \n    def fit(self, X_train, X_test, y_train):\n        model1 = DecisionTreeClassifier()\n        model1.fit(X_train, y_train)\n        yhat1 = model1.predict_proba(X_test)[:, 0]\n        \n        model2 = KNeighborsClassifier()\n        model2.fit(X_train, y_train)\n        yhat2 = model2.predict_proba(X_test)[:, 0]\n        \n        return model1, model2, yhat1, yhat2","2ff20dd5":"oof = OutOfFold(3)\n\n# Train\n# model1 - Decision Tree\n# model2 - k-NN\nmodel1, model2, data_x, data_y, knn_yhat, dtree_yhat = oof.train(X_train, y_train)\n\n# get accuracy for both models\noof.get_accuracy(model1, model2, X_test, y_test)","12585521":"# stack the k-NN + Decision Tree\nmeta_X = oof.create_meta_dataset(data_x, knn_yhat, dtree_yhat)\n\n# Train\n# LogisticRegression\nmodel1, model2, _, _ = oof.fit(X_train, X_test, y_train)\nmeta_model, yhat, acc = oof.train_metadata(model1, model2, meta_X, data_y, X_test)\nprint(\"Metadata Accuracy:{:1.3f}\".format(acc))","444c485e":"<pre>\n                       .-'~~~-.\n                     .'o  oOOOo`.\n                    :~~~-.oOo   o`.\n                     `. \\ ~-.  oOOo.\n                       `.; \/ ~.  OO:\n                       .'  ;-- `.o.'\n                      ,'  ; ~~--'~\n                      ;  ;\n_______\\|\/__________\\\\;_\\\\\/\/___\\|\/________\n\nMushrooms - Out-Of-Fold Prediction 100% accuracy\n<\/pre>","6a1f814f":"# Prepare Data","0693967e":"# Out of Fold"}}