{"cell_type":{"684a66fb":"code","420ce73e":"code","3f0d4b38":"code","0997f4a3":"code","6b801525":"code","db92d3f9":"code","6918cc87":"code","4d85db3e":"code","254f88e0":"code","7272029e":"code","1cb35b49":"code","70c6f39a":"code","71b55161":"code","33d2f5a8":"code","dfff7c12":"code","7407e864":"code","c37ba934":"code","d15bc3e7":"code","e67396a6":"code","83a3f52f":"code","3edfe5f4":"code","5700e840":"code","33d1a379":"code","b78038e0":"code","22a7f91e":"code","aa89df1a":"code","df97da1b":"code","23dd77ac":"code","3a514630":"code","535c86b2":"code","bdcafda2":"code","e90177dd":"code","c98fd6ca":"code","af10ac80":"code","4bdda583":"code","f3a90046":"code","e8c4f017":"code","72ab90f4":"code","fda55060":"code","86254d36":"code","fea99d6b":"code","2a87539a":"code","d97a344b":"code","fdea3051":"code","e8d65914":"code","85d4abe1":"code","b1c077a3":"code","6ba21985":"markdown","7aa9e648":"markdown","56950325":"markdown","b2f03ecb":"markdown","58a49c5c":"markdown","21f74980":"markdown","b7d12b6a":"markdown","95f5f330":"markdown","4f5464a7":"markdown","a875c295":"markdown","da66bffa":"markdown","02340fd6":"markdown","4a6be342":"markdown","69458941":"markdown","cf072a4c":"markdown","b438ea17":"markdown","314c0016":"markdown","fbe78e1e":"markdown","268a8a0a":"markdown","02c31453":"markdown","455125b8":"markdown","36303bd6":"markdown","0523dd05":"markdown","2884db24":"markdown","f53c165b":"markdown","730df3a0":"markdown","bf573766":"markdown","5c12f2b3":"markdown","b519ac9c":"markdown","20a0f7bc":"markdown","57bd53b7":"markdown","c3ac1935":"markdown","c41e02c1":"markdown","2973d7ae":"markdown","aca6b518":"markdown","a2127c4e":"markdown","c91e9c3e":"markdown","7686d95a":"markdown","055b201e":"markdown","3b856a07":"markdown","d3c46456":"markdown","d52395c8":"markdown","a8cfe313":"markdown","24877db5":"markdown","04f1d806":"markdown","793facd6":"markdown","63b8b5ec":"markdown"},"source":{"684a66fb":"#importing tools that we may need\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np\nimport re\nfrom mpl_toolkits.mplot3d import Axes3D","420ce73e":"#defining all the data set csv files so we can combine them later\ndf201809 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2018-10-greater-manchester-street.csv')\ndf201810 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2018-10-greater-manchester-street.csv')\ndf201811 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2018-11-greater-manchester-street.csv')\ndf201812 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2018-12-greater-manchester-street.csv')\ndf201901 = pd.read_csv('..\/input\/gmcdata\/2019-01-greater-manchester-street.csv')\ndf201902 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2019-02-greater-manchester-street.csv')\ndf201903 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2019-03-greater-manchester-street.csv')\ndf201904 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2019-04-greater-manchester-street.csv')\ndf201905 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2019-05-greater-manchester-street.csv')\ndf201906 = pd.read_csv('..\/input\/greater-manchester-street-crime-092018-062019\/2019-06-greater-manchester-street.csv')","3f0d4b38":"#making a list of the data frames we just created from CSV's, we can later use this list to make combining easier)\ndfs = [df201809,df201810,df201811,df201812,df201901,df201902,df201903,df201904,df201905,df201906]","0997f4a3":"# here we will check what the sum of the size of all csv's is so we. can compare it to the combined file\n\nrows_all = 0\nfor x in dfs:\n    rows_all = rows_all + x.size\nprint(rows_all)\n    \n    \n    \n    ","6b801525":"#combing the files into a new dataset\ncombined = pd.concat(dfs,axis = 0)\n\n#checking the size of the new data set\nprint(\"combined data size: \",combined.size)\nprint(\"variance between individual and combined: \", rows_all - combined.size)\n","db92d3f9":"# remove spaces in columns name\ncombined.columns = combined.columns.str.replace(' ','_')","6918cc87":"# looking at the data to see how many unique values it has\ncombined.nunique()","4d85db3e":"print('Crime_type: ',combined.Crime_type.value_counts())\nprint(\"\")\nprint('Last_outcome_category: ',combined.Last_outcome_category.value_counts())","254f88e0":"combined.head(5)","7272029e":"combined = combined.drop(columns = ['Crime_ID','Reported_by', 'Falls_within', 'Context'])\n# lets check the drop has worked\ncombined.head()\n#looks good!","1cb35b49":"combined.isna().sum()","70c6f39a":"combined['Last_outcome_category'] = combined['Last_outcome_category'].fillna('Unknown')\ncombined.isna().sum()","71b55161":"combined.dtypes","33d2f5a8":"combined.Month = pd.to_datetime(combined.Month)","dfff7c12":"print(combined.dtypes)\ncombined.head()","7407e864":"total_number_crimes = len(combined)\ntotal_number_crimes","c37ba934":"#number of periods\nperiods = combined.Month.nunique()\navg_crimes_per_period = total_number_crimes \/ periods\navg_crimes_per_period\n\n#didnt really need a computer to calculate this for us..","d15bc3e7":"crime_types = combined[['Crime_type','Month']]\n\ncrime_types = pd.DataFrame({'count_of_crimes' : crime_types.groupby( [ \"Crime_type\"] ).size()}).reset_index()\ncrime_types = crime_types.sort_values(by=['count_of_crimes'], ascending=False)\ncrime_types","e67396a6":"crime_types['propn'] = (crime_types.count_of_crimes) \/ total_number_crimes*100\ncrime_types\n\n\n","83a3f52f":"(combined.Crime_type.value_counts().plot.bar(figsize=(10,10)))","3edfe5f4":"\n# Quick look at the crime type data\n\n(combined.Crime_type.value_counts().plot.pie(figsize=(10,10)))\n\n","5700e840":"crime_time = combined.Month.value_counts()\ncrime_time.plot()\n","33d1a379":"#lets install folium \n!pip install folium\n","b78038e0":"#responding to the above question\n#[y]","22a7f91e":"#importing folium so we can make a map!\nimport folium\nfrom folium.plugins import HeatMap, MarkerCluster","aa89df1a":"#using most of the rows in the dataset as its making computer too slow and crashing colab\n\nnp.random.seed(10)\n\nremove_n = 137900\ndrop_indices = np.random.choice(combined.index, remove_n, replace=False)\ndf_subset = combined.drop(drop_indices)\n\n#checking the original size and the reduced size of the dataframes\nprint(\"Starting rows: \",len(combined))\nprint(\"New df rows: \",len(df_subset))\n\n\n","df97da1b":"#focusing the map on the center of al lthe points\ncrime_map = folium.Map(location=[df_subset.Latitude.mean(), \n                        df_subset.Longitude.mean()], \n                        zoom_start=13, \n                       tiles = \"Stamen Terrain\",\n                        #width=1000,height=400,\n                       control_scale=True)\n\n","23dd77ac":"for index, location_info in df_subset.iterrows():\n    folium.Marker([location_info[\"Latitude\"], location_info[\"Longitude\"]], popup=location_info[\"Crime_type\"]).add_to(crime_map)\ncrime_map","3a514630":"#we try plotting the crimes as scatter and see if we can get all datasets\n\nplt.figure(num=None, figsize=(10, 8))\nplt.scatter(\"Longitude\", \"Latitude\", data = combined, c = 'y',alpha = 0.1, edgecolor = 'black', s=2)\nplt.grid()\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.title('Greater Manchester Crime')\nplt.tight_layout()\nplt.axis('tight')\n\nplt.show()","535c86b2":"def heat_map_creator(data, crime):\n\n    #this time we are focusing on manchester city center as its more interesting!\n    crime_heat_map = folium.Map(location=[53.4817925337945, -2.2427961874491795],\n                       zoom_start=13,\n                       tiles = \"OpenStreetMap\",\n                       #width=1000,height=400,\n                       control_scale=True)\n    \n\n    heat_data = data[['Latitude', 'Longitude']]\n    heat_data = data[data.Crime_type == crime]\n    heat_data = heat_data.dropna(axis=0, subset=['Latitude','Longitude'])\n\n    # List comprehension to make out list of lists\n    heat_data = [[row['Latitude'],row['Longitude']] for index, row in heat_data.iterrows()]\n\n    HeatMap(heat_data, radius = 10).add_to(crime_heat_map)\n\n    return crime_heat_map\n    #return print(len(heat_data))\n","bdcafda2":"combined.Crime_type.unique()","e90177dd":"heat_map_creator (combined,'Shoplifting')","c98fd6ca":"heat_map_creator (combined,'Bicycle theft')","af10ac80":" heat_map_creator (combined,'Violence and sexual offences')","4bdda583":"    # lets look at all the outcomes to see if any \ncombined.Last_outcome_category.value_counts().plot.bar()\nprint(combined.Last_outcome_category.value_counts())","f3a90046":"\ncombined.Last_outcome_category.unique()\n\n#after looking at the outcomes i think they can be grouped into three broad categories, 1. unknown, where the conclusion isnt know, 2. Positive, where the person responsible for the crime has had some form of punishment, even if it is only a warning, and 3. Negative where the suspect could not be prosecuted or an offender not identified\n \n\n","e8c4f017":"#choosing the columns\noutcomes_df = combined[['Month','Crime_type', 'Last_outcome_category']]\n\n#adding an extra columbn with data we will replace\noutcomes_df['New_class'] = outcomes_df['Last_outcome_category']\n\n#checking the data\noutcomes_df.head()","72ab90f4":"#replace values in New_class with the new classifications\noutcomes_df.New_class.replace({'Unable to prosecute suspect':'Negative',\n                               'Investigation complete; no suspect identified':'Negative',\n                               'Further investigation is not in the public interest':'Negative',\n                               'Defendant found not guilty': 'Negative',\n                               'Court case unable to proceed':'Negative',\n                               'Formal action is not in the public interest': 'Negative',\n                               'Offender given absolute discharge':'Negative',\n                               'Status update unavailable' :'Unknown',\n                               'Court result unavailable' : 'Unknown',\n                               'Offender given community sentence':'Positive',\n                               'Offender fined':'Positive',\n                               'Offender given suspended prison sentence':'Positive',\n                               'Local resolution':'Positive',\n                               'Offender given a caution':'Positive',\n                               'Offender given conditional discharge':'Positive',\n                               'Offender otherwise dealt with':'Positive',\n                               'Offender sent to prison':'Positive',\n                               'Defendant sent to Crown Court':'Positive',\n                               'Offender given a drugs possession warning':'Positive',\n                               'Action to be taken by another organisation':'Positive',\n                               'Offender ordered to pay compensation':'Positive',\n                               'Offender given penalty notice':'Positive',\n                               'Suspect charged as part of another case':'Positive',\n                               'Offender deprived of property':'Positive',\n                              \n                               }, inplace=True)\n\noutcomes_df.tail(15)\n","fda55060":"#breakdown of all crimes with outcomes\npropn = outcomes_df.groupby('New_class').agg({'New_class': 'count'})\n\npropn = propn.apply(lambda x:\n    100 * x \/ float(x.sum()))\n\npropn = propn.unstack(level=-1)\n\npropn","86254d36":"outcomes_df.New_class.value_counts().plot.pie()","fea99d6b":"outcomes_df.New_class.value_counts()\noutcomes_df.New_class.value_counts().plot()\n","2a87539a":"outcomes_df","d97a344b":"DELETE\n\n\ncombined[['Crime_type','Month']]\n\ncrime_types = pd.DataFrame({'count_of_crimes' : crime_types.groupby( [ \"Crime_type\"] ).size()}).reset_index()\ncrime_types = crime_types.sort_values(by=['count_of_crimes'], ascending=False)\ncrime_types\n","fdea3051":"#the number of crimes of each type that have positive, negative or unknown outcomes\ngk = outcomes_df.groupby(['Crime_type', 'New_class']).agg({'New_class': 'count'})\ngk = gk.unstack(level=-1)\ngk","e8d65914":"#as above but with %'s \ngk = outcomes_df.groupby(['Crime_type', 'New_class']).agg({'New_class': 'count'})\n\n# workout the %\ngk2 = gk.groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))\ngk2 = gk2.unstack(level=-1)\ngk2","85d4abe1":"gk2 = pd.read_csv('..\/input\/crime-conclusions-exported-rearanged-imported\/crime_rearanged.csv')\ngk2.head(50)","b1c077a3":"#plotting the data\n\ngk2.plot.bar()","6ba21985":"Lets check the data","7aa9e648":"We can see that most drug incidents are solved as i classed confiscation of items as a positive outcome as there has been some kind of punishment for breaking the law. It is common with drug incidents for the only punishment to be confiscation. \n\nPossessin of weapons is in second place at 11%\n\n9% of shoplifters result in a positive outcome. This may be becase the shopkeeper holds the suspect untul the police arrive.","56950325":"Load all the crime data files from google drive.\n\nThis data is street crime for the whole of the greater manchester area. Each file is a month and the data ranges from September 2018 to June 2019. This is the most recent data available. Data source: https:\/\/data.police.uk\/data\/","b2f03ecb":"Install folium","58a49c5c":"Useful\n to have the Crime Types handy.","21f74980":"Let's count the rows of data in the files so we can check that combining them works correctly","b7d12b6a":"Voilent and Sexual offenses. These crimes seem to be everywhere and in particular match up to city centers, high population density areas.","95f5f330":"Now we will combine the seperate data sets into one Panda's dataframe. We will also check the number of rows in the combined file and see if it matches the seperate files","4f5464a7":"Pie chat provides another perspective on the data","a875c295":"Now with percentages's in the table to make it more clear","da66bffa":"# Which crimes get solved and which dont?\n\n\n\n\n\n\n","02340fd6":"We will make a list of the data so its easier to combine","4a6be342":"Let's remove the columns that we dont need.","69458941":"Below are crimes over time.\n\nThe chart looks a bit dramatic given the scale but is quite interesting  that the number of crimes seems to go down over the deepest winter months. I dont think we have anywhere near enough data to decide if this is significant or not. If the data were available it would encourage me to carry out a deeper time-series analysis of overall crime over time and specific crime types over time. This could help give recomendations on where to focus police efforts at which time of year.","cf072a4c":"Having a quick look at the ratio of outcomes","b438ea17":"Just for fun lets plot the crime coordinates on a axis and see if the plot looks like greater Manchester. \n\nIt does! I'm not sure if this is a good or a bad thing!\n","314c0016":"Where to park your bike if you dont want it to be stolen. The heatmap hot areas match areas of high population density. ","fbe78e1e":"What is the total number of crimes in the period","268a8a0a":"Here we enter the variable with a crime type and our heatmap is generated. Not suprisingly for Shoplifting the hotspots are around town centers, supermarkets.","02c31453":"# Geo Mapping of crime locations\n\nWe have around 300k data points to map, so lets take a look at it\n\n","455125b8":"We will place the markers on the map.\n\nThis map is quite slow and when i tried it with the full dataset it was just impossible. Would be good to make the map interactive and to change the markers dependning on the crime. \n\nThis data could provide intereting insights for people buying \/ renting homes or just of general interest when looking at their neighbourhood.\n\nI would be interested in knowing if the coordinates are exact as if they are it could mean the data generates privacy concerns although consdering that the data is about 2 years out of date it is less of a problem.","36303bd6":"Lets check which data type we have. ","0523dd05":"# Lets start to answer questions","2884db24":"What is the average number of crimes per perod\n","f53c165b":"Lets change the  Last_outcome_category null values to \"Unknown\" and check the data","730df3a0":"We see that month is stored as an object, so lets convert that","bf573766":"Lets check the Crime_type and Last_outcome_category to see if they do actually contain structured data. Data is structured and can be rally \n\n\n\nuseful The data for Last_outcome_category can probably be grouped \n\n\ninto broader categories.","5c12f2b3":"Replacing the entries in the new column with the new classification, Positive, Negative and Unknown","b519ac9c":"We can clearly see that Voiolent and Sexual crimes are by far the most common type of street crime in Greater Manchester being 28% of the total the closet other crime type makes up only 16%, so almost half. It would be intereting to be able to drill down into these categories as they are already quite broad. The breadth of the categories makes it hard to come to conclusions. \n\nBike theft is the lowest type of crime, i would be interested to see this over a long time horizon and see if it correlates with the increasing popularity of cycling. ","20a0f7bc":"# Greater Manchester Crime Data Exploration\n\nI downloaded data from https:\/\/data.police.uk\/data\/ and will run some initial analysis and well as trying to answer some specific questions:\n\n1. How many crimes were committed in the period\n2. Breakdown by crime type\n3. Crimes by broad region of greater Manchester\n\ttotal number per region \n\tPercentage of all created manchester crime\n4. Where are you most likely to get your bike stolen\n5. Which crimes get solved and which don\u2019t\n\nIn almost all of this notbook i have stuck to using python rather than jumping out to BigQueery or a spreadsheet. As much as a i love python i also believe that other tools are faster for most people. ","57bd53b7":"I'm preparing the data set to work with folium markers, i will reduce it using Numpy random row resampler","c3ac1935":"# Get the inital bits out of the way.\nwe will mount google drive, load librarries collect the data and combine it into one pandas dataframe","c41e02c1":"# Basic data cleaning and preparing\nWe will make the data easier to use, starting by removing spaces in column names and replacing with underscore","2973d7ae":"We can look at the breakdown of solves by crime type","aca6b518":"Looking at the data head we can see that the following are not useful, so we will remove these columns:\n\n- Crime_ID\n- Reported_by\n- Falls_within\n- Context \n\n","a2127c4e":"I will combine some of the crime outcomes broarder categories\n\nlets look at the options for outcomes to see what we can combine\n\nafter looking at the outcomes i think they can be grouped into three broad categories, 1. unknown, where the conclusion isnt known, 2. Positive, where the person responsible for the crime has had some form of punishment, even if it is only a warning, and 3. Negative where the suspect could not be prosecuted or an offender not identified.\n\n","c91e9c3e":"It will be easier if we add the % of total crime and make a pie chart and bar chart. I would rather use Tableau for visulisations so now we will just produce basic, illustrative charts","7686d95a":"i dont know wht but im struggling to sort the data form the above, so i exported to GSheets and back in to here.","055b201e":"Making a new dataset specific to the needs of looking at outcomes","3b856a07":"The below charts make it clear that Negative is by far the biggest outcome of crimes, showing that around 70% of crimes go unsolved. 3.2% are solved but a large part of the solved is warnings and cautions.","d3c46456":"Firstly we need to define \"solved\" and not solved. I will base this on my own judgement for now however it would be good to get expert clarification to increase reliablity of findings. \n\nWe have a lot of listed crime outcomes, lets take a look at them\n\n","d52395c8":"Let's make some heatmaps to better show where crime is and is not focused. I will make a function that lets us pass a variable for each crime type so we can easilty make new maps","a8cfe313":"Which crimes make up the total\n\n","24877db5":"A quick grouping of data by the crime type","04f1d806":"Importing Folium library\n\n","793facd6":"Lets check the data to see if it needs cleaning. We will look for duplications in the crime type,and crime outcomes, we will check for blank data ","63b8b5ec":"Looking at the data we can check how many unique values each column has. We can see that crime type and crime outcome have small values so it is likely this data is structured, this will make it good for analysis."}}