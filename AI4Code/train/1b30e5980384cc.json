{"cell_type":{"60f73755":"code","f2d5ffa5":"code","48371a5a":"code","863f1fdc":"code","769acde5":"code","763f32a0":"code","adca8915":"code","97f7ef34":"code","f6c51de5":"code","cfa8abef":"code","44bd61d1":"code","f52bde2f":"code","d144c9c1":"code","e2c7a65d":"code","a94f79fe":"code","fc9e0096":"code","76d93bf0":"code","2b4e2535":"markdown","df01a48b":"markdown","f147b080":"markdown","31b209bf":"markdown","1a70277b":"markdown","0e8bf6b1":"markdown","ec26a56b":"markdown","7c770185":"markdown","5ee40d0c":"markdown","050cd0f5":"markdown","198bce9a":"markdown","64f89ff7":"markdown","4a1cc079":"markdown","ae61fede":"markdown","425c3f6d":"markdown","e5c37fed":"markdown","93a0958c":"markdown","d0996133":"markdown","78f10c6d":"markdown","dfa4ab3b":"markdown","89c589df":"markdown","96d4fcd1":"markdown"},"source":{"60f73755":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f2d5ffa5":"import pandas as pd\nimport statsmodels.api as sm\n\ndf = pd.read_csv(\"\/kaggle\/input\/insurance\/insuranceMarketing.csv\")\n# Show all columns of data frame.\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)\n\nprint(df.head())","48371a5a":"# This performs a weighted regression for ranking with string variables as\n# levels.\n\nattributeNames = [ 'Collision', 'Deductable', 'Roadside', 'Extra']\ny = df[['Rank']]\nX = df[attributeNames]\nX = pd.get_dummies(X, columns =attributeNames )\nX = sm.add_constant(X)\nprint(X.head())","863f1fdc":"def shortenColumnNames(X):\n    XCopy = X.copy()\n    for colName in X.keys():\n        pos = colName.find('_')\n        if(pos>0):\n            X = X.rename(columns={colName: colName[pos+1:]})\n    return X\n\nX = shortenColumnNames(X)\n#print(X)\n\ncounter         = 0\nNUM_QUESTIONS   = 9\nstart           = 0\nend             = NUM_QUESTIONS\n\ndef getPreferences(attributeNames, utilities, levelNames):\n    utilityDict = {}\n    levelNames = list(levelNames)\n    counter = 1\n    levelNames.pop(0)  # Remove constant for intercept.\n    ranges = []\n\n    # Iterate through all attributes to create part-worths.\n    for attributeName in attributeNames:\n        partWorths = []\n\n        # Iterate through all levels.\n        for levelName in levelNames:\n            # If level name contains the attribute store the part worth.\n            if (attributeName in levelName):\n                partWorth = utilities[counter]  # Store corresponding model coeff.\n                #print(\" :\", levelName + \": \" + str(partWorth))\n                partWorths.append(partWorth)\n                utilityDict[levelName] = round(partWorth, 4)\n                counter += 1\n\n        # Summarize utility range for the attribute.\n        partWorthRange = max(partWorths) - min(partWorths)\n        ranges.append(partWorthRange)\n\n    # Calculate relative importance scores for each attribute.\n    importances = []\n    for i in range(0, len(ranges)):\n        importance = 100 * ranges[i] \/ sum(ranges)\n        importances.append(importance)\n        #print(attributeNames[i] + \" importance: \" + str(importance))\n        utilityDict[attributeNames[i]] = round(importance, 4)\n\n    # Return dictionary containing level preferences\n    # and attribute importance.\n    return utilityDict\n\nimport pandas as pd\ndf2 = pd.DataFrame(columns=[\n    # Demographic\n    'Age', 'Income', 'KidsAtHomeWhoDrive', 'VehicleYear',\n    # Attribute importance\n    'Roadside', 'Deductable', 'Extra', 'Collision',\n    # Levels\n    '300_Deductable', '500_Deductable', '1000_Deductable',\n    '1mill_Collision',  '2mill_Collision', '5mill_Collision',\n    'no_Extra',  'yes_Extra',  'no_Roadside',  'yes_Roadside'])\n\nwhile(end<=len(df)):\n    subDf = df.iloc[start:end, :]\n    subDf = df.iloc[start:start+1, :]\n    subX  = X[start:end][:]\n    subY  = y[start:end][:]\n\n    lr_model = sm.OLS(subY, subX).fit()\n    #print(\"***params\")\n    #print(lr_model.params)\n    dict = getPreferences(attributeNames, lr_model.params, X.keys())\n\n    # Add demographic data to dictionary.\n    dict['Age']                 = subDf.iloc[0]['Age']\n    dict['KidsAtHomeWhoDrive']  = subDf.iloc[0]['KidsAtHomeWhoDrive']\n    dict['Income']              = subDf.iloc[0]['Income']\n    dict['VehicleYear']         = subDf.iloc[0]['VehicleYear']\n\n    df2 = df2.append(dict, ignore_index=True)\n\n    # Advance through dataframe.\n    start += NUM_QUESTIONS\n    end   += NUM_QUESTIONS\n","769acde5":"df2","763f32a0":"from   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\ndf2 = df2.rename({'300_Deductable': 'Deductable_300'}, axis = 1)\ndf2 = df2.rename({'500_Deductable': 'Deductable_500'}, axis = 1)\ndf2 = df2.rename({'1000_Deductable': 'Deductable_1000'}, axis = 1)\nplt.rcParams[\"figure.figsize\"] = (20,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(Deductable_300) AS Deductable_300, AVG(Deductable_500) AS Deductable_500, AVG(Deductable_1000) AS Deductable_1000 FROM Insurance GROUP BY Age HAVING Age <= 30\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n#print(ageExtraDf)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_300',\n                          'val':ageExtraDf.iloc[i]['Deductable_300']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_500',\n                          'val':ageExtraDf.iloc[i]['Deductable_500']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_1000',\n                          'val':ageExtraDf.iloc[i]['Deductable_1000']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Deductable_300,Deductable_500 and Deductable_1000 for less than 30 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","adca8915":"from   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\ndf2 = df2.rename({'300_Deductable': 'Deductable_300'}, axis = 1)\ndf2 = df2.rename({'500_Deductable': 'Deductable_500'}, axis = 1)\ndf2 = df2.rename({'1000_Deductable': 'Deductable_1000'}, axis = 1)\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(Deductable_300) AS Deductable_300, AVG(Deductable_500) AS Deductable_500, AVG(Deductable_1000) AS Deductable_1000 FROM Insurance GROUP BY Age HAVING Age BETWEEN 31 AND 60\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n#print(ageExtraDf)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_300',\n                          'val':ageExtraDf.iloc[i]['Deductable_300']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_500',\n                          'val':ageExtraDf.iloc[i]['Deductable_500']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_1000',\n                          'val':ageExtraDf.iloc[i]['Deductable_1000']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Deductable_300,Deductable_500 and Deductable_1000 for 31 to 60 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","97f7ef34":"from   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\ndf2 = df2.rename({'300_Deductable': 'Deductable_300'}, axis = 1)\ndf2 = df2.rename({'500_Deductable': 'Deductable_500'}, axis = 1)\ndf2 = df2.rename({'1000_Deductable': 'Deductable_1000'}, axis = 1)\nplt.rcParams[\"figure.figsize\"] = (20,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(Deductable_300) AS Deductable_300, AVG(Deductable_500) AS Deductable_500, AVG(Deductable_1000) AS Deductable_1000 FROM Insurance GROUP BY Age HAVING Age >60\"\nageExtraDf = getQueryResult(SQLExtra, df2)\nprint(ageExtraDf)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_300',\n                          'val':ageExtraDf.iloc[i]['Deductable_300']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_500',\n                          'val':ageExtraDf.iloc[i]['Deductable_500']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Deductable_1000',\n                          'val':ageExtraDf.iloc[i]['Deductable_1000']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Deductable_300,Deductable_500 and Deductable_1000 for greater than 60 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","f6c51de5":"\n\nfrom   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\ndf2 = df2.rename({'1mill_Collision': 'Collision_1mil'}, axis = 1)\ndf2 = df2.rename({'2mill_Collision': 'Collision_2mil'}, axis = 1)\ndf2 = df2.rename({'5mill_Collision': 'Collision_5mil'}, axis = 1)\n\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(Collision_1mil) AS Collision_1mil, AVG(Collision_2mil) AS Collision_2mil, AVG(Collision_5mil) AS Collision_5mil FROM Insurance GROUP BY Age HAVING Age <= 30\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_1mil',\n                          'val':ageExtraDf.iloc[i]['Collision_1mil']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_2mil',\n                          'val':ageExtraDf.iloc[i]['Collision_2mil']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_5mil',\n                          'val':ageExtraDf.iloc[i]['Collision_5mil']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Collision_1Mil,Collision_2Mil and Collision_5Mil for less than 30 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","cfa8abef":"\n\nfrom   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\ndf2 = df2.rename({'1mill_Collision': 'Collision_1mil'}, axis = 1)\ndf2 = df2.rename({'2mill_Collision': 'Collision_2mil'}, axis = 1)\ndf2 = df2.rename({'5mill_Collision': 'Collision_5mil'}, axis = 1)\n\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(Collision_1mil) AS Collision_1mil, AVG(Collision_2mil) AS Collision_2mil, AVG(Collision_5mil) AS Collision_5mil FROM Insurance GROUP BY Age HAVING Age BETWEEN 31 AND 60\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_1mil',\n                          'val':ageExtraDf.iloc[i]['Collision_1mil']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_2mil',\n                          'val':ageExtraDf.iloc[i]['Collision_2mil']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_5mil',\n                          'val':ageExtraDf.iloc[i]['Collision_5mil']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Collision_1Mil,Collision_2Mil and Collision_5Mil for 31 and 60 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","44bd61d1":"\n\nfrom   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\ndf2 = df2.rename({'1mill_Collision': 'Collision_1mil'}, axis = 1)\ndf2 = df2.rename({'2mill_Collision': 'Collision_2mil'}, axis = 1)\ndf2 = df2.rename({'5mill_Collision': 'Collision_5mil'}, axis = 1)\n\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(Collision_1mil) AS Collision_1mil, AVG(Collision_2mil) AS Collision_2mil, AVG(Collision_5mil) AS Collision_5mil FROM Insurance GROUP BY Age HAVING Age > 60\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_1mil',\n                          'val':ageExtraDf.iloc[i]['Collision_1mil']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_2mil',\n                          'val':ageExtraDf.iloc[i]['Collision_2mil']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'Collision_5mil',\n                          'val':ageExtraDf.iloc[i]['Collision_5mil']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Collision_1Mil,Collision_2Mil and Collision_5Mil for greater than 60 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","f52bde2f":"\n\nfrom   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\n\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(no_Extra) AS no_Extra, AVG(yes_Extra) AS yes_Extra, AVG(no_Roadside) AS no_Roadside, AVG(yes_Roadside) AS yes_Roadside FROM Insurance GROUP BY Age HAVING Age <= 30\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'no_Extra',\n                          'val':ageExtraDf.iloc[i]['no_Extra']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'yes_Extra',\n                          'val':ageExtraDf.iloc[i]['yes_Extra']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'no_Roadside',\n                          'val':ageExtraDf.iloc[i]['no_Roadside']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'yes_Roadside',\n                          'val':ageExtraDf.iloc[i]['yes_Roadside']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Extra and Roadside for less than 30 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","d144c9c1":"\n\nfrom   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\n\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(no_Extra) AS no_Extra, AVG(yes_Extra) AS yes_Extra, AVG(no_Roadside) AS no_Roadside, AVG(yes_Roadside) AS yes_Roadside FROM Insurance GROUP BY Age HAVING Age BETWEEN 31 AND 60\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'no_Extra',\n                          'val':ageExtraDf.iloc[i]['no_Extra']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'yes_Extra',\n                          'val':ageExtraDf.iloc[i]['yes_Extra']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'no_Roadside',\n                          'val':ageExtraDf.iloc[i]['no_Roadside']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'yes_Roadside',\n                          'val':ageExtraDf.iloc[i]['yes_Roadside']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Extra and Roadside for 31 to 60 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","e2c7a65d":"\n\nfrom   sqlalchemy import create_engine\nimport matplotlib.pyplot as plt\n\n# Placed query in this function to enable code re-usuability.\ndef getQueryResult(sql, df):\n    # This code creates an in-memory table called 'Insurance'.\n    engine     = create_engine('sqlite:\/\/', echo=False)\n    connection = engine.connect()\n\n    df.to_sql(name='Insurance', con=connection, if_exists='replace', index=False)\n\n    # This code executes the query.\n    queryResult = pd.read_sql(sql, connection)\n    return queryResult\n\n\nplt.rcParams[\"figure.figsize\"] = (24,8)\n\n\nSQLExtra  = \"SELECT Age, AVG(no_Extra) AS no_Extra, AVG(yes_Extra) AS yes_Extra, AVG(no_Roadside) AS no_Roadside, AVG(yes_Roadside) AS yes_Roadside FROM Insurance GROUP BY Age HAVING Age >60\"\nageExtraDf = getQueryResult(SQLExtra, df2)\n\n# Age is the group.\ndfGroupedBar = pd.DataFrame(columns=['Age', 'Importance', 'val'])\n\nfor i in range(0, len(ageExtraDf)):\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age': int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'no_Extra',\n                          'val':ageExtraDf.iloc[i]['no_Extra']},\n                          ignore_index=True)\n\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'yes_Extra',\n                          'val':ageExtraDf.iloc[i]['yes_Extra']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'no_Roadside',\n                          'val':ageExtraDf.iloc[i]['no_Roadside']},\n                          ignore_index=True)\n    dfGroupedBar = dfGroupedBar.append({ 'Age':int(ageExtraDf.iloc[i]['Age']),\n                          'Importance':'yes_Roadside',\n                          'val':ageExtraDf.iloc[i]['yes_Roadside']},\n                          ignore_index=True)\n\n \ndfGroupedBar.pivot(\"Age\", \"Importance\",  \"val\").plot(kind='bar')\nplt.title(\"Importance of Extra and Roadside for greater than 60 year old\")\nplt.xlabel(\"Age\")\nplt.show()\n#print(dfGroupedBar)","a94f79fe":"#!pip install factor-analyzer\n\n# Create data frame without ID and target variable columns.\ndf3 = df2.copy()\ny = df3[['Age']]\nX = df3[['Income',\n         'KidsAtHomeWhoDrive',\n         'VehicleYear',\n         'Deductable_300',\n         'Deductable_500',\n         'Deductable_1000',\n         'Collision_1mil',\n         'Collision_2mil',\n         'Collision_5mil',\n         'no_Extra',\t\n         'yes_Extra',\t\n         'no_Roadside',\t\n         'yes_Roadside']]\n\n\n# Bartlett's test of sphericity checks for enough correlation.\n# A small p-value indicates that enough correlation exists.\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nchi_square_value, p_value=calculate_bartlett_sphericity(X)\n\nprint(\"\\nBartlett's test chi-square value: \")\nprint(chi_square_value)\n\nprint(\"\\nBartlett's test p-value: \")\nprint(p_value)\n\n# Kaiser-Meyer-Olkin (KMO) test checks for common variance.\n# Factor analysis is suitable for scores of 0.6 (and\n# sometimes 0.5) and above.\nfrom factor_analyzer.factor_analyzer import calculate_kmo\nkmo_all,kmo_model=calculate_kmo(X)\nprint(\"\\nKaiser-Meyer-Olkin (KMO) Test\")\nprint(kmo_model)\n","fc9e0096":"from factor_analyzer import FactorAnalyzer\n# Create components loading vectors without rotation\n# and obtain the Eigenvalues.\nfa = FactorAnalyzer(rotation=None)\nfa.fit(X)\n\nev, v = fa.get_eigenvalues()\nprint(\"\\nEignenvalues:\")\nprint(ev)\n\n\n","76d93bf0":"# Generate and interpret factors.\n# Pick factors where eigenvalues are greater than 1.\nfa = FactorAnalyzer(rotation=\"varimax\",n_factors=4)\nfa.fit(X)\n\n# Create formatted factor loading matrix.\ndfFactors = pd.DataFrame(fa.loadings_)\ndfFactors['Categories'] = list(X.keys())\ndfFactors = dfFactors.rename(columns={0:'Factor 1',\n          1:'Factor 2', 2:'Factor 3', 3:'Factor 4'})\nprint(\"\\nFactors: \")\nprint(dfFactors)","2b4e2535":"For people who are above 60, generally there is more demand for Deductable 300 if you are 72 and above, while the demand for Deductable 500 is very low for 71 and above.\n","df01a48b":"In this age group most people are wanting to take on Deductable 500 first, then Deductable 300, and at last Deductable 1000.\n\nLet's look at the age above 60 now:\n","f147b080":"## Importance of each Collision for people with ages above 30, between 30 and 60, and above 60?","31b209bf":"Different Market Segments:\n1. Young people who dont much care for Roadside support, who want 1 million collision protection and prefer Deductable 1000.\n1. MidRange people who have recent enough Vehicle age and high income, they prefer Collision 3 mil protection and would prefer Roadside support,\n1. Senions who have older vehicles who prefer Collision 5 mil protection,want Roadside support and also want Extra coverage with Deductible 300.","1a70277b":"Now that we have our factors, lets see if we can decipher which variables are good in each factor.\nWe are reading the variables based on 0.2 and above factor values.\n\n* Factor 1: We can see Yes_Extra and No_Extra has a positive-negative or to be precise a inverse relationship. We have a similar thing for Yes and no roadside.We can also see that Deductable 300 is highly positive and 500 and 1000 deductible are negatively correlated.\n* Factor 2: In this factor, we can see a inverse relationship between Collision_1mil and Collision_3mil. A positive connective between Income and VehicleYear.\n* Factor 3: In this factor, we can see Deductable 1000 is very high, while Deductible 500 is fairly negatively low.\n* Factor 4: In this factor, we can see Collision 5 mil is very high negatively, while collision 2mil and 1mil are decent positively.\n\nWith this information we can assign proper labels to these Formats:\n* Factor 1 = YESTO_Extra_And_Roadside_And_Dedctable_300\n* Factor 2 = Collision_1mil_Income_VehicleYear\n* Factor 3 = YES_Deductable_1000_AND_Collision_1mil\n* Factor 4 = NOTO_Collision_5mil_AND_YESTO_1mil2mil\n\nMost of the  observations extracted from the Factors were also noticed by grouping different market segments.","0e8bf6b1":"We are working with 10 columns in this dataset:\n\n\u2022\t**ID**: the associated ID with a client\n\n\u2022\t**Age**: Client\u2019s respective age\n\n\u2022\t**KidsAtHomeWhoDrive**: Number of kids at home who drive\n\n\u2022\t**Income**: Yearly income of the Client\n\n\u2022\t**VehicleYear**: The Year in which the vehicle was created \n\n\u2022\t**Collision**: Different plans for Collision Protection\n\n\u2022\t**Deductable**: Different deductable that can user has to pay out of their pocket\n\n\u2022\t**Roadside**: Whether or not any roadside assistance is provided or not\n\n\u2022\t**Extra**: If any extra help is provided.\n\n\u2022\t**Rank**: The associated demand for this specific type of request\n\nLet's take a look at the dataframe\n","ec26a56b":"Now, we have all the columns that we will be working with as well as their Importance number assigned.\nLet's try to figure out certain groups by grouping different variables\n1. What is the Importance of each Deductalbe for people with ages above 30, between 30 and 60, and above 60?  \n1. What is the importance of each collision protection for people with ages above 30, between 30 and 60, and above 60?\n1. What is the importace of each roadside and extra based for people with ages above 30, between 30 and 60, and above 60?","7c770185":"## What is the importace of each roadside and extra based for people with ages above 30, between 30 and 60, and above 60?","5ee40d0c":"The previous pattern follows until the age of 62, then there is a high positive preferance for Collision 5 million and high negative importance for Collision 1 million.\n\nSummary of Collision based on Age:\nIt seems the older you are the likelihood that you would prefer Collision 5 million is increased, and the younger you are the likelihood you would prefer collision 1 million is increased. This is most likely due to the fact that as people grow older their average income increases and they tend to buy expensive cars, also the fact that people start having kids when they get older i.e increasing the number in KidsWhoDriveAtHome variable.","050cd0f5":"After the age of 35, the importance of having Roadside assistance in their insurance plan increases drastically, while the need for extra coverage is reducing slightly as they grow older.\n\nLets look at people above the age of 60.","198bce9a":"As we can see, we are working with various categories that are dealing with Categorical data. Let's sove that issue:","64f89ff7":"# Market Segmentation\n","4a1cc079":"## Importance of each Deductalbe for people with ages above 30, between 30 and 60, and above 60?","ae61fede":"# Factor Analysis","425c3f6d":"By looking at these eigenvalues, we can see that up to 4 variables would be good to use for creating Factors.\nSo, lets make some factors.","e5c37fed":"A lot of people in this range do not give very high importance to Roadside support installed in their insurance who are in theirs 22 to 30s. This could be most likely because they are young and consider themselves to be able to fix all minor issues by themselves.\n\nLets look at ages 30 to 60.","93a0958c":"For some reason there seems to be a high importance from the range of 66 to 74 for no roadside coverage and high importance for Extra coverage. But after that peoiod the need for Roadside covereage is resumed again for most parts.\n\nSummary:\nBoth Extra coverage and Roadside coverage seems to have quite a demand between the ages of 30 and 60.","d0996133":"# Conclusion\n","78f10c6d":"There is almost a direct proportionality between Collision 1mil and 5mil. Most young people below Age 30 have high positive importance for 1 million collision coverage, and has a high negative importance for 5 million Collision coverage.\n\nLet's look at the ages between 30 and 60.","dfa4ab3b":"So almost immediately, after the age of 35 the previous high importance that we see for 1 million coverage is reduced drastically in favour for 3 million coverage and there is stil a high negative importance for Collision 5 million.\n\nLet's check for people above age 60.","89c589df":"Okay so the Barlett's test tells us that we are working with significant variables, and Kaiser-Meyer tells us that our variable cover about 60% of variance in our data.\nThis is pretty good to start.\n\nNow, let's find the Eigenvalues of our data and then choose some factors.","96d4fcd1":"In the above graph, we can observe that there is a high preference for Deductable 1000 for people under 22.\nMost clients appear to be somewhat satisfied with Deductable 500 in this age group.\nSuprisingly, one would think that younger people would want less deductable to be paid for insurance, but the \nabove data shows that they most of the time prefer Deductable 500, then Deductable 300.\n\nNow, let's check the range between 30 to 60.\n"}}