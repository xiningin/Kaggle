{"cell_type":{"1f04ec6e":"code","74a11ef9":"code","89b74343":"code","913ee01f":"code","ff79f72b":"code","98d909ac":"code","b221c48b":"code","2e006c7c":"code","3aad1d39":"code","d66f8a13":"code","26369e0b":"code","a5d00da5":"code","ff9a0037":"code","c71076e0":"code","c895b7aa":"code","ce004636":"code","e2520253":"code","796f5967":"code","9276c80a":"code","4526553b":"code","4338fa3d":"code","8f29bb1c":"code","1e500ee7":"code","ad6e53dd":"code","7fe48b58":"code","a54f1032":"code","9cd6047a":"code","c646c700":"code","93b01736":"code","45ddca09":"code","b9b735e9":"code","8a245777":"code","14a1dd4b":"code","4d77af1d":"code","3a9552fb":"code","da14e039":"code","c976d217":"code","3be60fdf":"code","ec9c6e23":"code","1fc12539":"code","d2a6fe9e":"code","3f445c9f":"code","a8395719":"code","ef3e00f1":"code","f686c9ee":"code","8bf31b68":"code","0a6b9d67":"code","0f7263df":"code","b51ec791":"markdown","5cf5ccc4":"markdown","1175f20e":"markdown","80c9d701":"markdown","01ca4aa2":"markdown","8ca0bd2e":"markdown","c5f89ff2":"markdown","49e404a5":"markdown","54079436":"markdown","669e05dd":"markdown","f21d2d9a":"markdown","a3c00ae8":"markdown","f9f78149":"markdown","256cb5d3":"markdown","c2ab4111":"markdown","af06ceb8":"markdown","7846064f":"markdown","b3cc78a6":"markdown","b675a952":"markdown","099b5434":"markdown"},"source":{"1f04ec6e":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport cv2","74a11ef9":"import keras\nfrom keras.layers import Dense,Conv2D,Dropout,BatchNormalization,Activation,Flatten,MaxPool2D,Input,LeakyReLU\nfrom keras.models import Sequential\nfrom keras.activations import relu\nfrom keras.optimizers import Adam,RMSprop,SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.applications.vgg16 import VGG16\nfrom sklearn import svm\nfrom keras.preprocessing import image\nimport xgboost\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport sklearn.preprocessing as pr","89b74343":"x_train = []\ny_train = []\n\ntrain_path='..\/input\/plant-seedlings-classification\/train'\ntest_path='..\/input\/plant-seedlings-classification\/test'","913ee01f":"for subfolder in os.listdir(train_path):\n    for file in os.listdir(train_path+'\/' +subfolder):\n        path = train_path+'\/' +subfolder+ \"\/\" + file\n        im = cv2.imread(path)\n        ims = cv2.resize(im,(64,64))\n        ims = ims\/127.0\n        x_train.append(ims)\n        y_train.append(subfolder)","ff79f72b":"x_train_ann =[];\ny_train_ann =[]\n\nfor subfolder in os.listdir(train_path):\n    for file in os.listdir(train_path+'\/' +subfolder):\n        path = train_path+'\/' +subfolder+ \"\/\" + file\n        im = cv2.imread(path)\n        ims = cv2.resize(im,(128,128))\n        ims = ims\/255.0\n        x_train_ann.append(ims)\n        y_train_ann.append(subfolder)","98d909ac":"le_ann = pr.LabelEncoder()\ny_train_le_ann = le_ann.fit_transform(y_train_ann)\n\n\nx_ann,x_test_ann,y_ann,y_test_ann =  train_test_split(x_train_ann,y_train_le_ann ,test_size=0.2,random_state=10)\n#y_train_1_le = le.fit_transform(y_train_1)\nx_array_ann = np.array(x_ann)\nx_test_arr_ann = np.array(x_test_ann)","b221c48b":"y_train_ann_cat = to_categorical(y_ann)\ny_test_ann_cat = to_categorical(y_test_ann)","2e006c7c":"len(x_train)","3aad1d39":"le = pr.LabelEncoder()\ny_train_le = le.fit_transform(y_train)\n\n\nx_svm,x_test_svm,y_svm,y_test_svm =  train_test_split(x_train,y_train_le ,test_size=0.2,random_state=10)\n#y_train_1_le = le.fit_transform(y_train_1)\nx_array_svm = np.array(x_svm)\nx_test_arr_svm = np.array(x_test_svm)","d66f8a13":"y_train_cat = to_categorical(y_train_le)\n#y_train_1_cat = to_categorical(y_train_1_le)","26369e0b":"flat_arr_size = len(x_array_svm[0])*len(x_array_svm[0][0])*len(x_array_svm[0][0][0])\nx_arr_flat_svm = x_array_svm.reshape(len(x_array_svm),flat_arr_size)\nx_test_arr_flat_svm = x_test_arr_svm.reshape(len(x_test_arr_svm),flat_arr_size)","a5d00da5":"from sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import roc_curve, auc","ff9a0037":"# define support vector classifier\nsvm = SVC(kernel='linear', probability=True, random_state=10)\n\n# fit model\nsvm.fit(x_arr_flat_svm, y_svm)","c71076e0":"# generate predictions\ny_pred = svm.predict(x_test_arr_flat_svm)\n\n# calculate accuracy\naccuracy = accuracy_score(y_test_svm, y_pred)\nprint('Model accuracy is: ', accuracy)","c895b7aa":"import pickle\n\nfilename = 'finalized_svm_model.sav'\npickle.dump(svm, open(filename, 'wb'))","ce004636":"image_size = 256\nbatch_size = 32","e2520253":"idg = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    #rotation_range=20, # You can uncomment these parameters to make you generator rotate & flip the images to put the train model in stricter conditions.\n    #width_shift_range=0.2,\n    #height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2\n)","796f5967":"train_gen = idg.flow_from_directory('..\/input\/plant-seedlings-classification\/train\/',\n                                                    target_size=(image_size, image_size),\n                                                    subset='training',\n                                                    class_mode='categorical',\n                                                    batch_size=batch_size,\n                                                    shuffle=True,\n                                                    seed=1\n                                                )","9276c80a":"val_gen = idg.flow_from_directory('..\/input\/plant-seedlings-classification\/train\/',\n                                                   target_size=(image_size, image_size),                                                   \n                                                   subset='validation',\n                                                   class_mode='categorical',\n                                                   batch_size=batch_size,\n                                                   shuffle=True,\n                                                   seed=1\n                                                )","4526553b":"256*256*3","4338fa3d":"model_nn = Sequential()\n\ninputs = Input(shape=(128,128,3))\nmodel_nn.add(tf.keras.layers.Flatten())\n\nmodel_nn.add(Dense(512,activation = \"relu\"))\nmodel_nn.add(Dropout(0.2))\n# Normalization layer\nmodel_nn.add(tf.keras.layers.BatchNormalization())\n\nmodel_nn.add(Dense(256,activation = \"relu\"))\nmodel_nn.add(Dropout(0.2))\n# Normalization layer\nmodel_nn.add(tf.keras.layers.BatchNormalization())\n\nmodel_nn.add(Dense(128,activation = \"relu\"))\nmodel_nn.add(Dropout(0.2))\n# Normalization layer\n\nmodel_nn.add(tf.keras.layers.BatchNormalization())\nmodel_nn.add(Dense(32,activation = \"relu\"))\nmodel_nn.add(Dropout(0.2))\n\n\nmodel_nn.add(Dense(12,activation='softmax'))\n#model_nn.summary()","8f29bb1c":"model_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","1e500ee7":"# You can save the best model to the checkpoint\ncheckpoint_ann = tf.keras.callbacks.ModelCheckpoint('plant_ANN_classifier.h5', #where to save the model\n                                                    save_best_only=True, \n                                                    monitor='val_accuracy', \n                                                    mode='max', \n                                                    verbose = 1)","ad6e53dd":"len(train_gen)\n3803\/\/32","7fe48b58":"print(len(x_ann[0][0][0]))\nprint(len(y_train_ann_cat))\ny_train_ann_cat[0]","a54f1032":"print(len(x_test_ann))\nprint(len(y_test_ann_cat))\ny_test_ann_cat[0]","9cd6047a":"\n#model_nn.fit(x_train_ann,y,epochs=150,validation_data=(x_train_ann,y_train_ann_cat),batch_size=128,callbacks = [checkpoint_ann],\n #         verbose = 1)\nhistory = model_nn.fit_generator(train_gen,\n          epochs=50, # Increase number of epochs if you have sufficient hardware\n          steps_per_epoch= 3803\/\/batch_size,  # Number of train images \/\/ batch_size\n          validation_data=val_gen,\n          validation_steps = 947\/\/batch_size, # Number of val images \/\/ batch_size\n          callbacks = [checkpoint_ann],\n          verbose = 1\n)","c646c700":"unique, counts = np.unique(train_gen.classes, return_counts=True)\ndict1 = dict(zip(train_gen.class_indices, counts))\n\nkeys = dict1.keys()\nvalues = dict1.values()\n\nplt.xticks(rotation='vertical')\nbar = plt.bar(keys, values)","93b01736":"x,y = next(train_gen)","45ddca09":"from mpl_toolkits.axes_grid1 import ImageGrid\n\ndef show_grid(image_list, nrows, ncols, label_list=None, show_labels=False, figsize=(10,10)):\n\n    fig = plt.figure(None, figsize,frameon=False)\n    grid = ImageGrid(fig, 111, \n                     nrows_ncols=(nrows, ncols),  \n                     axes_pad=0.2, \n                     share_all=True,\n                     )\n    for i in range(nrows*ncols):\n        ax = grid[i]\n        ax.imshow(image_list[i],cmap='Greys_r')\n        ax.axis('off')","b9b735e9":"show_grid(x,2,4,show_labels=True,figsize=(10,10))","8a245777":"model = tf.keras.models.Sequential()\n\n# Input layer\n# Can be omitted, you can specify the input_shape in other layers\nmodel.add(tf.keras.layers.InputLayer(input_shape=(image_size,image_size,3,)))\n\n# Here we add a 2D Convolution layer\n# Check https:\/\/keras.io\/api\/layers\/convolution_layers\/convolution2d\/ for more info\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n\n# Max Pool layer \n# It downsmaples the input representetion within the pool_size size\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n\n# Normalization layer\n# The layer normalizes its output using the mean and standard deviation of the current batch of inputs.\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# 2D Convolution layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides = (1,1), activation='relu'))\n\n# Max Pool layer \nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n\n# Normalization layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# 2D Convolution layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu'))\n\n# Max Pool layer \nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n\n# Normalization layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# 2D Convolution layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu'))\n\n# Max Pool layer \nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2)))\n\n# Global Max Pool layer\nmodel.add(tf.keras.layers.GlobalMaxPool2D())\n\n# Dense Layers after flattening the data\nmodel.add(tf.keras.layers.Flatten())\n\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\n\n# Dropout\n# is used to nullify the outputs that are very close to zero and thus can cause overfitting.\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\n\n# Normalization layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n#Add Output Layer\nmodel.add(tf.keras.layers.Dense(12, activation='softmax')) # = 12 predicted classes","14a1dd4b":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","4d77af1d":"model.summary()","3a9552fb":"# You can save the best model to the checkpoint\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('plant_cnn_classifier.h5', #where to save the model\n                                                    save_best_only=True, \n                                                    monitor='val_accuracy', \n                                                    mode='max', \n                                                    verbose = 1)","da14e039":"history = model.fit(train_gen,\n          epochs=20, # Increase number of epochs if you have sufficient hardware\n          steps_per_epoch= 3803\/\/batch_size,  # Number of train images \/\/ batch_size\n          validation_data=val_gen,\n          validation_steps = 947\/\/batch_size, # Number of val images \/\/ batch_size\n          callbacks = [checkpoint],\n          verbose = 1\n)","c976d217":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xticks(list(range(1,21)))\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","3be60fdf":"maize = cv2.imread('..\/input\/plant-seedlings-classification\/train\/Maize\/6e9ff31e7.png')","ec9c6e23":"plt.imshow(maize)","1fc12539":"maize = cv2.resize(maize, (256,256))","d2a6fe9e":"maize_batch = np.expand_dims(maize, axis=0)","3f445c9f":"conv_maize = model.predict(maize_batch)","a8395719":"conv_maize.shape","ef3e00f1":"def visualize(maize_batch):\n    maize = np.squeeze(maize_batch, axis=0)\n    print(maize.shape)\n    plt.imshow(maize)","f686c9ee":"plt.imshow(conv_maize)","8bf31b68":"simple_model = tf.keras.models.Sequential()\nsimple_model.add(tf.keras.layers.Conv2D(1,3,3,input_shape=maize.shape)) # 3x3 kernel","0a6b9d67":"# Function to show the mask of the image (aka how the model sees the image)\ndef visualize_color(simple_model, maize):\n    maize_batch = np.expand_dims(maize, axis=0)\n    conv_maize2 = simple_model.predict(maize_batch)\n    conv_maize2 = np.squeeze(conv_maize2, axis=0)\n    \n    print(conv_maize2.shape)\n    conv_maize2 = conv_maize2.reshape(conv_maize2.shape[:2])\n    print(conv_maize2.shape)\n    plt.imshow(conv_maize2)","0f7263df":"visualize_color(simple_model, maize)","b51ec791":"# 3. Visualizing","5cf5ccc4":"**The images are nicely loaded and do not have any rotation and distortion.**","1175f20e":"**Here is the example of visualizing probabilities of predictions of a particular image.**","80c9d701":"# 2. Model building","01ca4aa2":"**We need to preprocess the image before passing it on to the model: resize + expand_dims.**","8ca0bd2e":"# 4. Conclusion\n\nWe have built a **CNN-model** to predict the class of a plant, which works quite well. (Increasing **number of epochs** and\/or **adding layers** to a model can even increase the performance.\n\n**CNN + Maxpooling + Global pooling + Dense** is a good combination for image classification.\n\nIf you want to understand how your neural network works and what features of images it considers important, you can build a function similar to **visualize_color** (see above).","c5f89ff2":"**Let's visualize a portion of images to make sure they're correctly loaded.**","49e404a5":"***** For image classification, SVM classifier, Data resize 64\/64 ****","54079436":"**Here we will check the predictions made by our model as well as visualize how the model filter one of the images taken from the dataset.**\n\n**Let's first check the prediction power.**","669e05dd":"**Learning curves vs epoch graph**","f21d2d9a":"**Quick description, before heading on:**\n\n**Model type:** Sequential\n\n**Layers used:**\n\n    0. InputLayer\n    1. Conv2D (64, 128 filters)\n    2. MaxPool2D\n    3. GlobalMaxPool2D\n    4. Batch Normalization\n    5. Flatten\n    6. Dropout\n    6. Dense\n    \n**Input size:** 256 x 256 x 3 (size x colors)\n\n**Pool size:** 2 x 2 (for MaxPool2D)\n\n**Kernel size:** 3 x 3 (for Conv2D)","a3c00ae8":"* Importing Images for Folder for supervise learning model","f9f78149":"**Train set**","256cb5d3":"**Let's now build a very simple model to witness the filtering ability of a neural network.**\n\n**Please note that this model (simple_model) should not be used to make trustworthy predictions. This is just for the purpose of exercise.**","c2ab4111":"**Okay, our model can see the pattern of leaves and can make some predictions based on it. That's good.**","af06ceb8":"**I will load the images using ImageDataGeneretor class and explicitly indicate the needed parameters (rescaling, flipping, validation splitting.**","7846064f":"**2. Artificial Neural Network Model**","b3cc78a6":"# 1. Image importing","b675a952":"**The train dataset is quite balanced.**","099b5434":"**Validation set**"}}