{"cell_type":{"4ac649b3":"code","84bc2e75":"code","d2301fe2":"code","05ba5be3":"code","8ac0651b":"code","5cd6e855":"code","b332ed33":"code","53937fdd":"code","857feb3c":"code","49181839":"markdown","88de3bad":"markdown","1bc37623":"markdown","314c544d":"markdown","b3a04d43":"markdown","9763ebda":"markdown","52eb5c19":"markdown","92d904f3":"markdown"},"source":{"4ac649b3":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport glob\nfrom PIL import Image\nimport hashlib\nfrom io import BytesIO\nfrom skimage import io\nimport contextlib2\nimport json\nimport cv2\nimport os, shutil  \nfrom functools import partial\n%matplotlib inline  ","84bc2e75":"# A few helper functions for reading in image and masks (from json)\n\ndef read_tif_file(fname):\n    img = io.imread(fname)\n    img = np.squeeze(img)\n    if img.shape[0] == 3: # swap axes as required\n        img = img.swapaxes(0,1)\n        img = img.swapaxes(1,2)\n    return img\n\ndef read_mask_file(fname, mshape):\n    with open(fname) as f:\n        mdata = json.load(f)\n        polys = []\n        for index in range(mdata.__len__()):\n            if mdata[index]['properties']['classification']['name'] == 'glomerulus':\n                geom = np.array(mdata[index]['geometry']['coordinates'])\n                if geom.shape[0] == 1:\n                    polys.append(geom[0].astype('int32'))\n        mask = np.zeros(mshape, dtype=np.int8)\n        cv2.fillPoly(mask, polys, 1)\n        mask = mask.astype(bool, copy=False)\n    return mask","d2301fe2":"# patches are stored as jpeg, masks as PNG\ndef create_tf_example(patch, m_patch, fid, x, y, size):\n    filename = fid+'.tiff'\n    height = size # Image height\n    width = size # Image width\n    buf= BytesIO()\n    im = Image.fromarray(np.uint8(patch))\n    im.save(buf, format= 'JPEG') # encode to jpeg in memory\n    encoded_image_data= buf.getvalue()\n    image_format = b'jpeg'\n    source_id = fid+'-'+str(x)+'-'+str(y) # must be unique\n    # A hash of the image is used in some frameworks\n    key = hashlib.sha256(encoded_image_data).hexdigest()\n    # Mask encoding\n    buf= BytesIO()\n    mim = Image.fromarray(np.uint8(m_patch))\n    mim.save(buf, format= 'PNG') # encode to png in memory\n    encoded_mask_data= buf.getvalue()\n    mask_format = b'png'\n    \n    tf_record = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        'image\/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        'image\/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n        'image\/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n        'image\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n        'image\/key\/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n        'image\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n        'image\/patch-x': tf.train.Feature(int64_list=tf.train.Int64List(value=[x])),\n        'image\/patch-y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n        'mask\/patch-x': tf.train.Feature(int64_list=tf.train.Int64List(value=[x])),\n        'mask\/patch-y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n        'mask\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_mask_data])),\n        'mask\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[mask_format])),\n    }))\n    \n    return tf_record","05ba5be3":"PATH = '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/'\nfilelist = glob.glob(PATH+'*.tiff')\nfilelist","8ac0651b":"#%%time\nPATH = '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/'\nIMG_SIZE = 1024 # adjust according to desired tile size\nOVERLAP = IMG_SIZE\/\/2 # overlap between each tile\nSTEP = IMG_SIZE-OVERLAP\nSCALES = 2 # number of times to downscale each patch (generate SCALES+1 sets of images)\nSCALE_FACTOR = 2 # scale factor to use for each set, adjust according to needs\nimg_sizes = np.zeros(SCALES+1, dtype=int)\nimg_sizes[0] = IMG_SIZE\nfor i in range(SCALES):\n    img_sizes[i+1] = int(img_sizes[i]\/SCALE_FACTOR)\n\nfilelist = glob.glob(PATH+'*.tiff')\nFCNT = len(filelist)\n\ndef open_sharded_tfrecords(exit_stack, base_path, size, num_shards):\n    tf_record_output_filenames = [\n        '{}-{}-{:03d}-of-{:03d}.tfrecord'.format(base_path, size, idx, num_shards)\n        for idx in range(num_shards)\n        ]\n    tfrecords = [\n        exit_stack.enter_context(tf.io.TFRecordWriter(file_name))\n        for file_name in tf_record_output_filenames\n    ]\n    return tfrecords\n\nnum_shards = FCNT # one shard per image\n\noutput_filebase1='.\/Tissue' # dataset covering Tissue\noutput_filebase2='.\/Bkgnd' # dataset covering everything else\ngcnt, ncnt = np.zeros(num_shards, dtype=int), np.zeros(num_shards, dtype=int)\n\n# A context2.ExitStack is used to automatically close all the TFRecords created \nwith contextlib2.ExitStack() as tf_record_close_stack:\n    # create list of TFRecords\n    output_tfrecords1 = []\n    output_tfrecords2 = []\n    for scnt in range(SCALES+1):\n        output_tfrecords1.append(open_sharded_tfrecords(tf_record_close_stack, output_filebase1, img_sizes[scnt], num_shards))\n        output_tfrecords2.append(open_sharded_tfrecords(tf_record_close_stack, output_filebase2, img_sizes[scnt], num_shards))\n    # process images w\/overlapped tiles\n    output_shard_index = 0\n    for file in filelist:\n        print(file)\n        fid = file.replace('\\\\','.').replace('\/','.').split('.')[-2]        \n        img, mask = np.zeros(10), np.zeros(10) \n        img = read_tif_file(file)\n        dims = np.array(img.shape[:2])\n        mask = read_mask_file(file.split('.')[0]+'.json', dims)\n        for x in range((img.shape[0]-OVERLAP)\/\/STEP):\n            for y in range((img.shape[1]-OVERLAP)\/\/STEP):\n                # Extract patch\n                patch = img[x*STEP:x*STEP+IMG_SIZE, y*STEP:y*STEP+IMG_SIZE]\n                m_patch = mask[x*STEP:x*STEP+IMG_SIZE, y*STEP:y*STEP+IMG_SIZE]*255\n                # separate tissue from bakground by checking for non-zero pixels in mask\n                IsTissue = False\n                if np.max(m_patch) == 255:\n                    IsTissue = True;\n                tf_record = create_tf_example(patch, m_patch, fid, x, y, size=img_sizes[0])\n                if IsTissue:\n                    output_tfrecords1[0][output_shard_index].write(tf_record.SerializeToString())\n                    gcnt[output_shard_index] += 1\n                else:\n                    output_tfrecords2[0][output_shard_index].write(tf_record.SerializeToString())\n                    ncnt[output_shard_index] += 1\n                # create downscaled images\n                for s in range(SCALES): \n                    spatch = cv2.resize(patch, dsize=(img_sizes[s+1], img_sizes[s+1]), interpolation = cv2.INTER_AREA)\n                    sm_patch = cv2.resize(m_patch.astype(int), dsize=(img_sizes[s+1], img_sizes[s+1]), interpolation = cv2.INTER_NEAREST)\n                    tf_record = create_tf_example(spatch, sm_patch, fid, x, y, size=img_sizes[s+1])\n                    if IsTissue:\n                        output_tfrecords1[s+1][output_shard_index].write(tf_record.SerializeToString())\n                    else:\n                        output_tfrecords2[s+1][output_shard_index].write(tf_record.SerializeToString())\n        output_shard_index += 1\n","5cd6e855":"dparams = {\n    \"IMG_SIZE\": IMG_SIZE,\n    \"SCALE_FACTOR\": SCALE_FACTOR}\nwith open(\"dparams.json\", \"w\") as json_file:\n    json_file.write(json.dumps(dparams, indent = 4))","b332ed33":"import pandas as pd\n\nrecsizes = []\nfor i in range(num_shards):\n    for j in range(len(img_sizes)):\n        recsizes.append([output_filebase1.split('\/')[-1]+'-{}-{:03d}-of-{:03d}.tfrecord'.format(img_sizes[j],i, num_shards), gcnt[i]])\nfor i in range(num_shards):\n    for j in range(len(img_sizes)):\n        recsizes.append([output_filebase2.split('\/')[-1]+'-{}-{:03d}-of-{:03d}.tfrecord'.format(img_sizes[j], i, num_shards), ncnt[i]])\ndf = pd.DataFrame(recsizes, columns=['File', 'ImgCount'])\ndf.to_pickle('.\/record_stats.pkl')\ndf.sample(5)","53937fdd":"def plot_imgs(dataset):\n    fig = plt.figure(figsize=(18,18))\n    idx=1\n    for raw_record in dataset.take(36):\n        axes = fig.add_subplot(6, 6, idx)\n        example = tf.train.Example()\n        example.ParseFromString(raw_record.numpy())\n        img_encoded=example.features.feature['image\/encoded'].bytes_list.value[0]\n        img = Image.open(BytesIO(img_encoded))\n        mask_encoded=example.features.feature['mask\/encoded'].bytes_list.value[0]\n        mask = Image.open(BytesIO(mask_encoded))\n        plt.setp(axes, xticks=[], yticks=[])\n        plt.imshow(img)\n        plt.imshow(mask, alpha=0.25)\n        idx=idx+1","857feb3c":"fname='.\/Tissue-1024-004-of-015.tfrecord'\ndataset = tf.data.TFRecordDataset(fname)\ndataset = dataset.shuffle(2048, reshuffle_each_iteration=True)\nplot_imgs(dataset)","49181839":"Export a table with number of images per TFRecord.","88de3bad":"# TFRecords creation using patches\nThe super-resolution cell scan images need to be split into patches (or tiles if you like).   \n\nHere we go for 1024x1024 as the primary tile (patch) size. Adjust the IMG_SIZE variable further below to suit needs. We also create downscaled versions of 512x512 and 256x256.   ","1bc37623":"## Create TFRecord per image\nWe create a separate TFRecord file for each image. Well, actually two: One for tiles containing glomeruli (\"Tissue\") and one for the rest (\"Bkgnd\").","314c544d":"# Check the output files\nThe final check is to load and plot a couple of TFRecords and verify that everything loads OK.","b3a04d43":"The function below creates a TFRecord from a single patch. The image is stored as JPEG, while the mask is stored as PNG (lossless). We also put in some extra metadata.","9763ebda":"## References\nThis notebook uses\/modifies some code snippets from these notebooks:\n* [Global Wheat to TFRecords](https:\/\/www.kaggle.com\/mistag\/global-wheat-to-tfrecords) (own work)\n* [HuBMap: Read data and build TFRecords](https:\/\/www.kaggle.com\/marcosnovaes\/hubmap-read-data-and-build-tfrecords)   \n\nIn addition some sample code from Keras documentation.","52eb5c19":"Create a .json file with a few useful parameters we might need during training\/inference:","92d904f3":"# TIF to TFRecords in multiple resolutions\nIn this notebook we will transform the huge train images into TFRecords format.\nWhen creating TFRecords of a dataset it is most efficient for the processing pipeline to have TFRecords of a certain size, generally >10MBytes, to benefit from I\/O prefetching.  \n\n**Updated with the latest dataset!**"}}