{"cell_type":{"e280bef8":"code","3ee43a85":"code","aa9325aa":"code","370e479e":"code","725b6acf":"code","82c96719":"code","9078d5c8":"code","6ef23dae":"code","8cc9f451":"code","e7376a19":"code","dac5d247":"code","f9d48dde":"code","e5bc2215":"code","fedf3b1d":"code","009849ef":"markdown","356a63de":"markdown","fff1f187":"markdown","4e5f34ec":"markdown","2f43214a":"markdown","260ad642":"markdown","6168eeb0":"markdown","e1dd5430":"markdown","9377efa1":"markdown","08316b0b":"markdown","37153d99":"markdown","06e57945":"markdown"},"source":{"e280bef8":"import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.model_selection import train_test_split        \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix","3ee43a85":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head()","aa9325aa":"dummies_1 = pd.get_dummies(train['Sex'],drop_first=True)\ndummies_1 = dummies_1.rename(columns={\"male\": \"Sex\"})\ndummies_1 = dummies_1.astype(np.int64)\ntrain['Sex'] = dummies_1\ntrain.loc[train[\"Embarked\"] == \"S\", \"Embarked\"] = 1\ntrain.loc[train[\"Embarked\"] == \"C\", \"Embarked\"] = 2\ntrain.loc[train[\"Embarked\"] == \"Q\", \"Embarked\"] = 3\ntrain = train.drop(['Name','PassengerId','Ticket','Cabin','Age','Fare'],axis=1)\n\ntrain = train.dropna()\n\ntrain.count()","370e479e":"X_train = train.drop(['Survived'],axis=1)\ny_train = train['Survived']","725b6acf":"dtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)","82c96719":"test = pd.read_csv('..\/input\/titanic\/test.csv')","9078d5c8":"dummies_2 = pd.get_dummies(test['Sex'],drop_first=True)\ndummies_2 = dummies_2.rename(columns={\"male\": \"Sex\"})\ndummies_2 = dummies_2.astype(np.int64)\ntest['Sex'] = dummies_2\ntest.loc[test[\"Embarked\"] == \"S\", \"Embarked\"] = 1\ntest.loc[test[\"Embarked\"] == \"C\", \"Embarked\"] = 2\ntest.loc[test[\"Embarked\"] == \"Q\", \"Embarked\"] = 3\ntest = test.drop(['Name','PassengerId','Ticket','Cabin','Age','Fare'],axis=1)","6ef23dae":"X_test = test.dropna()\nX_test.count()","8cc9f451":"y_pred = dtree.predict(X_test)","e7376a19":"df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ndf.count()","dac5d247":"print(confusion_matrix(df['Survived'], y_pred))\nprint(classification_report(df['Survived'], y_pred))","f9d48dde":"passenger_id = {'PassengerId': pd.Series(range(891,1311))}\nsurvivors = {'Survived':y_pred}\nprediction = pd.DataFrame(passenger_id,survivors)\nprediction","e5bc2215":"pred = pd.DataFrame(data=y_pred)\npred = pred.rename(columns = {0: 'Survived'}, inplace = False)\npred['PassengerId'] = pd.RangeIndex(start=892, stop=1310,step=1)\npred","fedf3b1d":"pred.to_csv(\"submission.csv\",index = False)","009849ef":"## Titanic Survivors Decision Tree Classifier\n\nIn this notebook I will make a decision tree in order to predict which passenger survived the Titanic shipwreck.\n\nThe first thing is to import the necessary libraries.","356a63de":"As we did before, we need to clean the test dataset to compare with the model:\n* Make the Sex column binary and int64 type\n* Convert the Embarked column to numeric\n* Drop Name, Passenger Id, Ticket, Cabin, Age and Fare from the dataset because they won\u00b4t work for the decision tree.","fff1f187":"Analysing the results, we can see that the precision of the model is 0.87 for the deaths and 0.85 predicting the survivors which are really good results.\nThe false positivies are 21 and the false negatives 37 from the 418 records.\n\nThe accuracy of the model is 0.86.\n\nLet\u00b4s print out the output as the case is asking.","4e5f34ec":"In order to perform the model, we need to split the train dataset:","2f43214a":"Finally let\u00b4s print the confusion matrix and the classification report to evaluate the model","260ad642":"Now let\u00b4s drop the NaN values from the test in order to create the X_test dataset","6168eeb0":"Using the decision tree model that we made and trained using the train dataset, we will predict the survivors using the X_test","e1dd5430":"Now that we have used the model to predict the results, let\u00b4s compare it to the real results. Let\u00b4s load the real survivors dataset:","9377efa1":"Second, we need to understand the train dataset:","08316b0b":"Based on the fact that we need numeric variables in order to build the decision tree, We need to make these changes to the train dataset:\n* Make the Sex column binary and int64 type\n* Convert the Embarked column to numeric\n* Drop Name, Passenger Id, Ticket, Cabin, Age and Fare from the dataset because they won\u00b4t work for the decision tree.\n* Finally we need to drop NaN values from the table","37153d99":"Then we create the model using Sklearn","06e57945":"Now that the model is completed and trained, we will predict the results based on the test dataset:"}}