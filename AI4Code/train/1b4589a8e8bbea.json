{"cell_type":{"284fa572":"code","974ef8fc":"code","7c4b5acf":"code","f10061fb":"code","5f0b0101":"code","c35977fd":"code","32c718d6":"code","98864230":"code","dedf6e5d":"code","fbe1df42":"code","a3356f03":"code","eea95110":"code","601134ba":"code","f1543ea5":"code","f5beb783":"code","86abb3c3":"code","2090a04c":"code","bcd27c0e":"code","011b6133":"code","208a671f":"code","cb5d9ed3":"code","af421395":"code","d75a8893":"code","c6f87334":"code","827d3df5":"code","a78c14d4":"code","013acacd":"code","e8cb1822":"code","ba229fc6":"code","acbdcd9a":"code","2119f8af":"code","f3fa52eb":"code","fd93ad47":"code","f523374c":"code","beea81ee":"code","d739b086":"code","0b6da98b":"code","f6c5acc4":"code","9471e23b":"markdown"},"source":{"284fa572":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","974ef8fc":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","7c4b5acf":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","f10061fb":"train_data.drop(['Name', 'Cabin'], axis=1, inplace=True)\ntest_data.drop(['Name', 'Cabin'], axis=1, inplace=True)","5f0b0101":"train_data","c35977fd":"test_data","32c718d6":"from sklearn.preprocessing import LabelEncoder\nlab_en = LabelEncoder()\ntrain_data.iloc[:,3] = lab_en.fit_transform(train_data.iloc[:,3].values)\ntrain_data.iloc[:,9] = lab_en.fit_transform(train_data.iloc[:,9].values)\n\ntest_data.iloc[:,2] = lab_en.fit_transform(test_data.iloc[:,2].values)\ntest_data.iloc[:,8] = lab_en.fit_transform(test_data.iloc[:,8].values)","98864230":"test_data","dedf6e5d":"train_data.drop('Ticket', axis=1, inplace=True)\n\ntest_data.drop('Ticket', axis=1, inplace=True)","fbe1df42":"print(train_data.isnull().any())\nprint(test_data.isnull().any())","a3356f03":"train_data = train_data.dropna()\ntest_data.fillna({'Age': test_data['Age'].mean(),'Fare': test_data['Fare'].mean()}, \n                 inplace=True)","eea95110":"train_data.head()","601134ba":"test_data.head()","f1543ea5":"x_train = train_data.iloc[:,2::].values\nx_test = test_data.iloc[:,1::].values\n\ny_train = train_data.iloc[:,1].values","f5beb783":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","86abb3c3":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3, weights='distance')\n\nknn.fit(x_train, y_train)\nknn.score(x_train, y_train)","2090a04c":"from sklearn.model_selection import cross_val_score\n\nknn = KNeighborsClassifier(n_neighbors = 3, weights='distance')\nscore_valid = cross_val_score(knn, x_train, y_train, cv= 12, scoring = 'accuracy')\nprint(score_valid)","bcd27c0e":"ks = np.arange(1, 15, 1)\nk_scores = []\nfor k in ks:\n    knn = KNeighborsClassifier(n_neighbors = k, weights='distance')\n    k_scores.append(cross_val_score(knn, x_train, y_train, cv= 10, \n                                    scoring = 'accuracy').mean())\n","011b6133":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(ks,k_scores)","208a671f":"from sklearn.svm import SVC\nkernels = ['linear', 'poly', 'rbf', 'sigmoid']\n\nfor k in kernels:\n    print(k, ':', cross_val_score(SVC(kernel=k), x_train, y_train, cv= 10, \n                                    scoring = 'accuracy').mean())","cb5d9ed3":"c_list = np.arange(0.1, 1, 0.1)\nc_scores = []\nfor c in c_list:\n    svc = SVC(kernel='rbf', C=c)\n    c_scores.append(cross_val_score(svc, x_train, y_train, cv=10, \n                                    scoring = 'accuracy').mean())\n    \n\n%matplotlib inline\nplt.plot(c_list,c_scores)","af421395":"svc = SVC(kernel='rbf', C=0.8)\nscore_valid = cross_val_score(svc, x_train, y_train, cv=10, scoring = 'accuracy')\nprint(score_valid.mean())","d75a8893":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\n\ndep_list = np.arange(1, 20, 1)\ndep_scores = []\nfor d in dep_list:\n    tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=d, random_state = 0)\n    dep_scores.append(cross_val_score(tree, x_train, y_train, cv=10, \n                                    scoring = 'accuracy').mean())\n\n%matplotlib inline\nplt.plot(dep_list,dep_scores)","c6f87334":"svc = SVC(kernel='rbf', C=0.8)\nsvc.fit(x_train, y_train)\nprint(svc.score(x_train, y_train))\n\n#prediction = svc.predict(x_test)\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': prediction})\n\n#output.to_csv('hw2_submission.csv', index=False)","827d3df5":"from sklearn.ensemble import RandomForestClassifier\n\nest_list = np.arange(60, 110, 10)\nest_scores = []\nfor est in est_list:\n    forest = RandomForestClassifier(n_estimators=est, max_depth=5, random_state=0)\n    est_scores.append(cross_val_score(forest, x_train, y_train, cv=10, \n                                    scoring = 'accuracy').mean())\n\n%matplotlib inline\nplt.plot(est_list,est_scores)\n\n#model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n#model.fit(X, y)\n#predictions = model.predict(X_test)","a78c14d4":"forest = RandomForestClassifier(n_estimators=107, max_depth=5, random_state=0)\nforest.fit(x_train, y_train)\nprint(forest.score(x_train, y_train))\n","013acacd":"d_list = np.arange(5, 15, 1)\nd_scores = []\nfor d in d_list:\n    forest = RandomForestClassifier(n_estimators=107, max_depth=d, random_state=0)\n    d_scores.append(cross_val_score(forest, x_train, y_train, cv=10, \n                                    scoring = 'accuracy').mean())\n\n%matplotlib inline\nplt.plot(d_list,d_scores)","e8cb1822":"forest = RandomForestClassifier(n_estimators=107, max_depth=9, random_state=0)\nforest.fit(x_train, y_train)\nprint(forest.score(x_train, y_train))","ba229fc6":"forest = RandomForestClassifier(n_estimators=107, max_depth=9, random_state=0)\nforest.fit(x_train, y_train)\nprint(forest.score(x_train, y_train))\n\n#prediction = forest.predict(x_test)\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': prediction})\n\n#output.to_csv('hw2_submission.csv', index=False)","acbdcd9a":"new_train_data = train_data.drop(['SibSp', 'Parch'], axis=1)\nnew_test_data = test_data.drop(['SibSp', 'Parch'], axis=1)","2119f8af":"new_train_data.head()","f3fa52eb":"new_test_data.head()","fd93ad47":"new_x_train = new_train_data.iloc[:,2::].values\nnew_x_test = new_test_data.iloc[:,1::].values","f523374c":"forest = RandomForestClassifier(n_estimators=107, max_depth=9, \n                                random_state=0)\nforest.fit(new_x_train, y_train)\nprint(forest.score(new_x_train, y_train))","beea81ee":"samp_list = np.arange(2, 7, 1)\nsamp_scores = []\nfor s in samp_list:\n    forest = RandomForestClassifier(n_estimators=107, max_depth=9, min_samples_split=s, \n                                    random_state=0)\n    samp_scores.append(cross_val_score(forest, x_train, y_train, cv=10, \n                                    scoring = 'accuracy').mean())\n\n%matplotlib inline\nplt.plot(samp_list,samp_scores)","d739b086":"forest = RandomForestClassifier(n_estimators=107, max_depth=9, min_samples_split=3, \n                                random_state=0)\nforest.fit(new_x_train, y_train)\nprint(forest.score(new_x_train, y_train))","0b6da98b":"leaf_list = np.arange(3, 10, 1)\nleaf_scores = []\nfor l in leaf_list:\n    forest = RandomForestClassifier(n_estimators=107, max_depth=9, min_samples_split=2, \n                                    min_samples_leaf=l, random_state=0)\n    leaf_scores.append(cross_val_score(forest, x_train, y_train, cv=10, \n                                    scoring = 'accuracy').mean())\n\n%matplotlib inline\nplt.plot(leaf_list,leaf_scores)","f6c5acc4":"forest = RandomForestClassifier(n_estimators=200, max_depth=9, \n                               random_state=1)\nforest.fit(new_x_train, y_train)\nprint(forest.score(new_x_train, y_train))\n\nprediction = forest.predict(new_x_test)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': prediction})\n\noutput.to_csv('hw2_submission.csv', index=False)","9471e23b":"dec_tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=7, random_state = 0)\ndec_tree.fit(x_train, y_train)\nprint(dec_tree.score(x_train, y_train))\n\nprediction = dec_tree.predict(x_test)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': prediction})\n\noutput.to_csv('hw2_submission.csv', index=False)"}}