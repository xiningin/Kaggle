{"cell_type":{"50e07a64":"code","6aa44fc6":"code","19a95bfa":"code","09444214":"code","25563b8d":"code","85017fb6":"code","eab78f49":"code","b4952e52":"code","571c909a":"code","0dd7aec1":"code","d953b1c0":"code","58ac938e":"code","ce5aefb0":"code","7facc892":"code","04574352":"code","1d2050d6":"code","318e05b3":"code","f65e1999":"code","37453835":"code","9b80ba73":"code","e0633923":"code","c7f09cc4":"code","22d0af76":"code","49cb70e7":"code","eefe5cae":"code","81d757bc":"code","6a92da1f":"code","a501be1c":"code","fcf712d9":"code","6786f90e":"code","72904ad0":"code","c1bc3d6e":"code","1d7ba253":"code","239eb179":"code","80078752":"code","30266f00":"code","1aabe4f8":"markdown","e8a9f233":"markdown","c8bcc3c3":"markdown","145ab7eb":"markdown","b069b3f8":"markdown","64e2ba54":"markdown","7bb80587":"markdown","362f32ec":"markdown","0a42173f":"markdown","db75eb05":"markdown","79307f24":"markdown","e8fe34b3":"markdown","3b94d2d4":"markdown","4bd18c61":"markdown","b863b478":"markdown","85942a33":"markdown","bd8347d6":"markdown","00f82532":"markdown","72627d4c":"markdown","ec996f29":"markdown","9d033117":"markdown","962d3be1":"markdown","9feb835a":"markdown","9efd3da3":"markdown","d1861ba3":"markdown","2d118877":"markdown","2c57f6fb":"markdown","31486a99":"markdown","1598eb1c":"markdown","7399334d":"markdown","204c32cf":"markdown","2aa4380c":"markdown","db7b81a6":"markdown","368a2a91":"markdown","a8a3df81":"markdown","ca39092d":"markdown","bb345538":"markdown","e0377eff":"markdown","66c0fda2":"markdown","556a2124":"markdown","0f53bd4e":"markdown"},"source":{"50e07a64":"import pandas as pd \nimport numpy as np ","6aa44fc6":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go","19a95bfa":"#import cufflinks as cf\n#cf.go_offline()\ninit_notebook_mode(connected=True)","09444214":"df = pd.read_csv('..\/input\/CO_level_2000_-.csv')\ndel df['Unnamed: 0']\ndf.head()","25563b8d":"df = df.groupby(['Address','State','County','City','Date']).mean().reset_index()\ndf.info()","85017fb6":"df.describe()","eab78f49":"df['State'].unique()","b4952e52":"df = df[~df['State'].isin(['Puerto Rico', 'Country Of Mexico'])]","571c909a":"tempYear = []\ntempMonth = []\ntotalTuples = df.count()['State']\nfor i in range(totalTuples):\n    delement = (df['Date'].iloc[i]).split('-')\n    tempYear.append(int(delement[0]))\n    tempMonth.append(delement[0]+'-'+delement[1])\ndf['Year'] = tempYear\ndf['Month'] = tempMonth\ndf.head()","0dd7aec1":"stateData = {}\naddrDict = {}\nfor i in df['State'].unique():\n    #create a dicionary of data frames for state-wise record\n    stateData[i] = df[df['State'] == i]\n    addrDict[i] = stateData[i]['Address'].nunique()\naddrdf = pd.DataFrame.from_dict(addrDict, orient = 'index', columns = ['Address Count']).reset_index().rename(columns = {'index' : 'State'})\n\n# addrdf\naddrdf.head()","d953b1c0":"data = go.Bar(x = addrdf['State'], \n              y = addrdf['Address Count'], \n              text = addrdf['State'])\nlayout = go.Layout(dict(title = 'Number of unique addresses per State', \n                        xaxis = dict(title = 'State'),\n                        yaxis = dict(title = 'Count')))\nfig = dict(data = [data],layout = layout)\niplot(fig)\n\n#addrdf.iplot(kind='bar', x='State', y='Address Count', title='Number of unique addresses per State (Zoom in or hover over)', orientation='h')\n","58ac938e":"yeardf = df.groupby('Year').count().reset_index()\n\ndata = go.Bar(x = yeardf['Year'], \n              y = yeardf['Address'], \n              text = yeardf['Year'])\nlayout = go.Layout(dict(title = 'Number of records per year', \n                        xaxis = dict(title='Year'),\n                        yaxis = dict(title = 'Count')))\nfig = dict(data=[data],layout = layout)\niplot(fig)\n\n# df.groupby('Year').count().reset_index().iplot(kind='bar', x='Year', y='Address', title='Number of records per year')","ce5aefb0":"df[df['Year'] == 2018]['Month'].unique()","7facc892":"datesAddr = ['3847 W EARLL DR-WEST PHOENIX STATION', '6767 Ojo De Agua', 'LFC #1-LAS FLORES CANYON', 'NW Corner Interstate 10 & Etiwanda Ave', '700 North Bullis Road', '10 S. 11th St\/ Evansville- Lloyd', '1301 E. 9TH ST.', '4113 SHUTTLESWORTH DRIVE']\ndatesState = ['Arizona', 'Texas', 'California', 'California', 'California', 'Indiana', 'Ohio', 'Alabama']\ndatesStart = []\ndatesEnd = []\nfor i in range(len(datesAddr)):\n    datesStart.append(df[df['Address'] == datesAddr[i]]['Date'].min())\n    datesEnd.append(df[df['Address'] == datesAddr[i]]['Date'].max())\n    datesAddr[i] += ', '+datesState[i]\ndatesDF = pd.DataFrame([datesAddr, datesStart, datesEnd],index=['Address','Start date','Last Date']).transpose()\ndatesDF#.head()","04574352":"maximumYear = df[['Year','Arithmetic Mean']]\nmaximumYear = maximumYear.groupby('Year').max().reset_index()\n\nmaxTable = pd.DataFrame()\nfor i in range(19):\n    x = maximumYear.iloc[i]['Arithmetic Mean']\n    record = df[df['Year'] == (2000 + i)]\n    record = record[record['Arithmetic Mean'] == x].head(1) # pick only one\n    maxTable = maxTable.append(record)\nmaxTable = maxTable[['Address','State','Arithmetic Mean','Month']]\nmaxTable","1d2050d6":"# lets extract minimum records year - wise. Same logic upside - down.\nminimumYear = df[['Year','Arithmetic Mean']]\n# neglect 0 and negative values\nminimumYear = minimumYear[minimumYear['Arithmetic Mean'] > 0]\nminimumYear = minimumYear.groupby('Year').min().reset_index()\n\nminTable = pd.DataFrame()\nfor i in range(19):\n    x = minimumYear.iloc[i]['Arithmetic Mean']\n    record = df[df['Year'] == (2000 + i)]\n    record = record[record['Arithmetic Mean'] == x].head(1) # pick one record\n    minTable = minTable.append(record)\nminTable = minTable[['Address','State','Arithmetic Mean','Month']]\nminTable","318e05b3":"addr = '3847 W EARLL DR-WEST PHOENIX STATION'\naddr","f65e1999":"addrdf = stateData['Arizona'][stateData['Arizona']['Address'] == addr]\n\ntempdf = addrdf.groupby('Month').count().reset_index()\ndata = go.Bar(x = tempdf['Month'], \n              y = tempdf['Address'], \n              text = tempdf['Month'])\nlayout = go.Layout(dict(title = 'Number of records for selected address month wise', \n                        xaxis = dict(title = 'Year'),\n                        yaxis = dict(title = 'Count')))\nfig = dict(data = [data],layout = layout)\niplot(fig)\n\n#addrdf.groupby('Month').count().reset_index().iplot(kind='bar', x='Month', y='Address', title='Number of records for selected address month wise')","37453835":"seasonrange = ['2016-12', '2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12']\n\nfor i in range(len(seasonrange)):\n    tempdf = addrdf[addrdf['Month'] == seasonrange[i]]\n    data = go.Scatter(x = tempdf['Date'], \n                           y = tempdf['Arithmetic Mean'],\n                           text = tempdf['Date'], \n                           mode = 'lines+markers', \n                           name = seasonrange[i])\n    fig = dict(data = [data],layout = go.Layout(dict(title = seasonrange[i], \n                                                 xaxis = dict(title = 'Days'), \n                                                yaxis = dict(range = [0, 2], title = 'CO (in ppm)'))))\n    iplot(fig)\n\n#for i in range(len(seasonrange)):\n#    addrdf[addrdf['Month']==seasonrange[i]].iplot(x='Date',y='Arithmetic Mean',layout=go.Layout(yaxis=dict(range=[0,2]),title=seasonrange[i]))","9b80ba73":"winterdf = addrdf[addrdf['Month'].isin(['2016-12', '2017-01', '2017-02'])][['Arithmetic Mean', '1st Max Hour']]\nspringdf = addrdf[addrdf['Month'].isin(['2017-03', '2017-04', '2017-05'])][['Arithmetic Mean', '1st Max Hour']]\nsummerdf = addrdf[addrdf['Month'].isin(['2017-06', '2017-07', '2017-08'])][['Arithmetic Mean', '1st Max Hour']]\nautumndf = addrdf[addrdf['Month'].isin(['2017-09', '2017-10', '2017-11'])][['Arithmetic Mean', '1st Max Hour']]","e0633923":"seasondf = [winterdf, springdf, summerdf, autumndf]\ndftext = ['Winter', 'Spring', 'Summer', 'Autumn']\n\ndata = []\nfor i in range(len(seasondf)):\n    data.append(go.Box(y = seasondf[i]['Arithmetic Mean'], \n                  name = dftext[i]))\nlayout = go.Layout(title = 'Distribution of Arithmetic Mean across different season (2016-12 to 2017-11)', \n                   xaxis = dict(title = 'Season'), \n                   yaxis = dict(title = 'CO (in ppm)'))\nfig = dict(data = data, layout = layout)\niplot(fig)\n\n#pd.concat([winterdf['Arithmetic Mean'], springdf['Arithmetic Mean'], summerdf['Arithmetic Mean'], autumndf['Arithmetic Mean']], axis=1, keys=['Winter','Spring','Summer','Autumn']).iplot(kind='box')","c7f09cc4":"data = []\nfor i in range(len(seasondf)):\n    data.append(go.Box(y = seasondf[i]['1st Max Hour'], \n                  name = dftext[i]))\nlayout = go.Layout(title = 'Distribution of Hour values at which maximum reading was taken', \n                   xaxis = dict(title = 'Season'), \n                   yaxis = dict(title = 'Hours'))\nfig = dict(data = data, layout = layout)\niplot(fig)\n\n#pd.concat([winterdf['1st Max Hour'], springdf['1st Max Hour'], summerdf['1st Max Hour'], autumndf['1st Max Hour']], axis=1, keys=['Winter','Spring','Summer','Autumn']).iplot(kind='box')","22d0af76":"winterdf = df[df['Month'].isin(['2016-12', '2017-01', '2017-02'])][['Arithmetic Mean', 'State']]\nspringdf = df[df['Month'].isin(['2017-03', '2017-04', '2017-05'])][['Arithmetic Mean', 'State']]\nsummerdf = df[df['Month'].isin(['2017-06', '2017-07', '2017-08'])][['Arithmetic Mean', 'State']]\nautumndf = df[df['Month'].isin(['2017-09', '2017-10', '2017-11'])][['Arithmetic Mean', 'State']]\n\n# group by and sort by State to map it easily ahead\nwinterdf = winterdf.groupby('State').mean().reset_index().sort_values('State')\nspringdf = springdf.groupby('State').mean().reset_index().sort_values('State')\nsummerdf = summerdf.groupby('State').mean().reset_index().sort_values('State')\nautumndf = autumndf.groupby('State').mean().reset_index().sort_values('State')\n                                                                      \nabbState = ['US State:', 'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'Commonwealth\/Territory:', 'American Samoa', 'District Of Columbia', 'Federated States of Micronesia', 'Guam', 'Marshall Islands', 'Northern Mariana Islands', 'Palau', 'Puerto Rico', 'Virgin Islands', 'Military \"State\":', 'Armed Forces Africa', 'Armed Forces Americas', 'Armed Forces Canada', 'Armed Forces Europe', 'Armed Forces Middle East', 'Armed Forces Pacific']\nabbAB = ['Abbreviation:', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'Abbreviation:', 'AS', 'DC', 'FM', 'GU', 'MH', 'MP', 'PW', 'PR', 'VI', 'Abbreviation:', 'AE', 'AA', 'AE', 'AE', 'AE', 'AP']\nabbDF = pd.DataFrame([abbState,abbAB]).transpose()\n\n#small correction, so things go smooth ahead\nabbDF.iloc[53][0] = 'District Of Columbia'\n\n# creating label to display when hovered over\nmapA = []\nmapS = []\nfor i in winterdf.index:\n    mapA.append(str(winterdf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == winterdf['State'].iloc[i]][1].values[0])\nwinterdf['text'] = mapA\nwinterdf['code'] = mapS\n\nmapA = []\nmapS = []\nfor i in springdf.index:\n    mapA.append(str(springdf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == springdf['State'].iloc[i]][1].values[0])\nspringdf['text'] = mapA\nspringdf['code'] = mapS\n\nmapA = []\nmapS = []\nfor i in summerdf.index:\n    mapA.append(str(summerdf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == summerdf['State'].iloc[i]][1].values[0])\nsummerdf['text'] = mapA\nsummerdf['code'] = mapS\n\nmapA = []\nmapS = []\nfor i in autumndf.index:\n    mapA.append(str(autumndf['Arithmetic Mean'].iloc[i])[:5]+' ppm')\n    mapS.append(abbDF[abbDF[0] == autumndf['State'].iloc[i]][1].values[0])\nautumndf['text'] = mapA\nautumndf['code'] = mapS","49cb70e7":"data = dict(type='choropleth',\n            locations = winterdf['code'],\n            z = winterdf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = winterdf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'Arithmetic Mean Value in Winter by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","eefe5cae":"data = dict(type='choropleth',\n            locations = springdf['code'],\n            z = springdf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = springdf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'CO Mean Value in Spring by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","81d757bc":"data = dict(type='choropleth',\n            locations = summerdf['code'],\n            z = summerdf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = summerdf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'CO Mean Value in Summer by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","6a92da1f":"data = dict(type='choropleth',\n            locations = autumndf['code'],\n            z = autumndf['Arithmetic Mean'],\n            locationmode = 'USA-states',\n            text = autumndf['text'],\n            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),\n            colorbar = {'title':\"CO Mean in ppm\"}) \nlayout = dict(title = 'CO Mean Value in Autumn by State',\n              geo = dict(scope = 'usa',\n                         showlakes = True,\n                         lakecolor = 'rgb(85,173,240)'))\nchoromap = go.Figure(data = [data],layout = layout)\niplot(choromap)","a501be1c":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","fcf712d9":"chosenAddress = addrdf[['Month','Arithmetic Mean']]\n#aggregate them\nchosenAddress = chosenAddress.groupby('Month').mean().reset_index().reset_index()\n# we will use monthID on X-axis such that the first month in record will have monthID = 0\nchosenAddress = chosenAddress.rename(columns = {'index':'monthID'})","6786f90e":"start = addrdf['Month'].min()\n# start is first month in record of given address is of form '2000-01\u2018\n# tofind is input feature for which the CO Mean values is to be predicted is of form '2018-11\u2018\ndef toID(tofind,start = start):\n    startY = int(start.split('-')[0])\n    startM = int(start.split('-')[1])\n    tofindY = int(tofind.split('-')[0])\n    tofindM = int(tofind.split('-')[1])\n    id = 12 - startM\n    id += ((tofindY - startY) - 1 ) * 12\n    id += tofindM\n    return id","72904ad0":"# init our model\nlm = LinearRegression()\n# lets get data ready\nX = chosenAddress[['monthID']] #feature\nY = chosenAddress[['Arithmetic Mean']] #label\n# split train and test data\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=101)\n# train our model\nlm.fit(X_train,Y_train)","c1bc3d6e":"print(\"Intercept is \"+str(lm.intercept_))","1d7ba253":"print(\"Coefficient is \"+str(lm.coef_))","239eb179":"# predictions (Y) for trained data\nline = X_train['monthID'] * lm.coef_[0] + lm.intercept_[0]\n\n# display values\n#annotation = go.Annotation(x = 3.5, y = 3, text = '$R^2 = 0.9551,\\\\Y = 0.716X + 19.18$',  showarrow = False, font = go.Font(size=16))\n\n# actual points\ntrain = go.Scatter(x = X_train['monthID'],\n                   y = Y_train['Arithmetic Mean'],\n                   mode = 'markers',\n                   marker = dict(color = 'rgb(255, 127, 14)'),\n                   name = 'Data')\n\n# fitted line\nfit = go.Scatter(x = X_train['monthID'],\n                 y = line,\n                 mode = 'lines',\n                 marker = dict(color = 'rgb(31, 119, 180)'),\n                 name = 'Fit')\n\nlayout = go.Layout(title = 'Linear Fit Model',\n                   xaxis = dict(title = 'Month ID'),\n                   yaxis = dict(title = 'CO (in ppm)'))\n                   \ndata = [train, fit]\n\nfig = go.Figure(data=data, layout=layout)\n\niplot(fig)","80078752":"predictions = lm.predict(X_test)\ndata = go.Histogram(x = (Y_test - predictions)['Arithmetic Mean'],\n                    xbins = dict(start = -6, end = 6, size = 0.1))\nlayout = go.Layout(xaxis = dict(title = 'Error'))\n\nfig = dict(data = [data], layout = layout)\niplot(fig)\n\n#(Y_test - predictions).iplot(kind='hist', bins=10)","30266f00":"inMonth = '2018-08'\nprint('In month '+inMonth+', predicted value of CO Mean is '+str(lm.predict([[toID(inMonth)]])[0][0])[:5])","1aabe4f8":"**While prediction, following method will map input month to monthID**","e8a9f233":"** Examine states in record **","c8bcc3c3":"**Check 1st Max Hour value to find distirbution of hour values at which max values are recorded. <br>\nBecause of same phenomenon, distribution of hour early in morning for Summer is high **","145ab7eb":"** Lets plot for every month from December 2016 to December 2017<br>\nHover over graph to get reading**","b069b3f8":"** Take number of addresses present in each state **","64e2ba54":"** Records in month July-2002 and May-2005 seem missing, otherwise they are complete **","7bb80587":"** 0th and 6th record seem covered a lot **","362f32ec":"** It is till 2018-05**","0a42173f":"**Predict a value**","db75eb05":"** Visualize our trained model**","79307f24":"** Map state-wise distribution of Arithmetic Mean in Autumn**","e8fe34b3":"** Add month and year columns to help analysing data by month and year**","3b94d2d4":"**It is high in winter because of inversion. Check -->> https:\/\/en.wikipedia.org\/wiki\/Inversion_(meteorology)  **","4bd18c61":"** Check for what months we have records for 2018**","b863b478":"** Check records with maximum values in Arithmetic Mean year-wise**","85942a33":"**Examine change in values from December 2016 to November 2017 (one season cycle in U.S.)<br>\nWe will also take an extra for December 2017<br>\nSet layout to fix a range for ease of comparison and pass title as month **","bd8347d6":"**Follows same trend as for CO Mean.**","00f82532":"** Map state-wise distribution of Arithmetic Mean in Summer**","72627d4c":"** Transform data for choropleth maps**","ec996f29":"**Import Linear Regression from scikit-learn to predict further values for before selected address**","9d033117":"** Map state-wise distribution of Arithmetic Mean in Winter**","962d3be1":"** Eliminate duplicate entries of same date of same location **","9feb835a":"** Check number of records in each year **","9efd3da3":"** Import data analysis and visualization libraries**","d1861ba3":"** Check its accuracy by by plotting distribution of predicted_value - Y_test values **","2d118877":"**In Winter, CO Level seems high. While CO Level goes a bit low for Summer, it rises Autumn and Winter.**","2c57f6fb":"**For seasonal analysis, make separate DF to simplify further**","31486a99":"**Highest number of locations come from California (148), followed by Florida (42), Pennsylvania (39), Texas (35), Ohio (30), and so on.**","1598eb1c":"** Not all addresses records lie from 2000-01 to 2018-05. Take some examples.**","7399334d":"**Reduce addrdf to Month and Arithmetic Mean columns only.**","204c32cf":"** Pick a address for further analysis . We will pick '3847 W EARLL DR-WEST PHOENIX STATION, Arizona' as it appears in maxTable where year=2018. We can simply change this value to analyse other address in further analysis**","2aa4380c":"** Initilaise model, do train test split and train model using train_data**","db7b81a6":"** Check records with minimum values in Arithmetic Mean year-wise**","368a2a91":"** Check how CO Mean values are distributed by seasons**","a8a3df81":"**Records goes down as we walk right.**","ca39092d":"** Map state-wise distribution of Arithmetic Mean in Spring**","bb345538":"** We have Puerto Rico and Country of Mexico that we need to exclude while using Maps **","e0377eff":"** Cufflinks has got some internal error wih latest version 3.0.0 of plotly <br>\nCheck https:\/\/github.com\/santosjorge\/cufflinks\/issues\/119 <br>\nHad to replace those one liners that worked with dataframe with actual script**","66c0fda2":"# Carbon Monoxide (CO) analysis with Plotly","556a2124":"** Check month wise record count for selected address**\n","0f53bd4e":"** Visualize above**"}}