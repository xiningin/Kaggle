{"cell_type":{"1a962a80":"code","00127ddc":"code","b52cf012":"code","7f0b9990":"code","fb453658":"code","cc88d951":"code","f405a90f":"code","cea0d5a6":"code","84d7c157":"code","e17b3923":"code","2e793e69":"code","abeb0569":"code","3ccd1641":"code","7d54f152":"code","359a907c":"code","f4ec6582":"code","a9a20956":"code","de0a1e62":"code","056baad7":"code","d995308e":"code","56be5301":"code","e77c974d":"code","5a7cbd9c":"code","001a0f09":"code","e940716a":"code","de872f59":"code","3846ebe8":"code","3ad1c8f1":"code","22c693b2":"code","1d5190cc":"code","7db6139d":"code","68299db8":"code","1fb3e186":"code","0cd1aac8":"markdown","bec1e15e":"markdown","d9106d1c":"markdown","6fc6f242":"markdown","046147d0":"markdown","21d1e2c7":"markdown","f3ff7075":"markdown","3b0c50c9":"markdown","fa0777d9":"markdown","91b28c86":"markdown","f5c7704f":"markdown","ff357621":"markdown","c20b2340":"markdown","07be8284":"markdown","d0f45b92":"markdown","b4a22d62":"markdown","64bccfbd":"markdown","dde4ae52":"markdown","fb8de39e":"markdown","e8d78c14":"markdown","54b86638":"markdown","8d18d5b2":"markdown","3d6e9e1d":"markdown","5eb66e47":"markdown","923fd6c8":"markdown","cf248f97":"markdown","f836c87d":"markdown","f5a3933b":"markdown","5faac159":"markdown","59a4d838":"markdown","e9ede8d3":"markdown","6d2cad43":"markdown","7ae12f43":"markdown","fbbd9402":"markdown","0e71ba7b":"markdown","22bda4e1":"markdown","55bee57e":"markdown","931f8083":"markdown","8653db54":"markdown","97a53316":"markdown","4a9a8b54":"markdown","5f4eada0":"markdown","bd8382be":"markdown"},"source":{"1a962a80":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00127ddc":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_df.head()","b52cf012":"print(train_df.columns)","7f0b9990":"\n\n\n#  passing by reference is convenient, because we can clean both datasets at once\ncombine = [train_df,test_df]\n","fb453658":"train_df[['Pclass',\"Survived\"]].groupby(['Pclass']).mean().sort_values(by = 'Survived', ascending=False)","cc88d951":"train_df[['Sex','Survived']].groupby('Sex').mean().sort_values('Survived', ascending=False)","f405a90f":"train_df[['SibSp','Survived']].groupby('SibSp').mean().sort_values('Survived',ascending =False)","cea0d5a6":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","84d7c157":"g = sns.FacetGrid(train_df,col='Survived')\ng.map(plt.hist, 'Age',bins=30);","e17b3923":"grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass', height=2.2, aspect =1.6)\ngrid.map(plt.hist, 'Age', alpha = 0.5, bins=20 )\ngrid.add_legend()","2e793e69":"# the x category is the Pclass and the hue category is the Sex. Hence you need to add\n# order = [1,2,3], hue_order=[\"male\", \"female\"]\n\ngrid = sns.FacetGrid(train_df, row = 'Embarked', height = 2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass','Survived','Sex', order = [1,2,3], hue_order=[\"female\",\"male\"],palette = 'deep')\ngrid.add_legend()\nplt.show()","abeb0569":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', height =2.2, aspect=1.6 )\ngrid.map(sns.barplot, 'Sex','Fare', alpha=0.5, ci=None, order = ['male',\"female\"])\ngrid.add_legend();","3ccd1641":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","7d54f152":"for dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","359a907c":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby('Title').mean()","f4ec6582":"title_mapping = {'Mr':1,'Miss':2, 'Mrs':3, 'Master':4, 'Rare':5}\n\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain_df.head()  ","a9a20956":"train_df = train_df.drop([\"PassengerId\",\"Name\"],axis= 1)\ntest_df = test_df.drop(['Name'], axis=1)\n\ncombine = [train_df, test_df]\n\n","de0a1e62":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()","056baad7":"### COMPLETING or replacing the NAN values with relevant values\n\nfor dataset in combine:\n    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(),inplace=True)\n    \n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0],inplace=True)\n    \n    #complete missing fare with median\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n    \n    \n\nprint(\"Training data with null values per column: \\n\",train_df.isnull().sum())\nprint(\"\\n\")\n\nprint(\"testing data with null values per column: \\n\", test_df.isnull().sum())\n\n\n","d995308e":"train_df['Age'] = train_df['Age'].astype(int)\ntrain_df['Age'] = train_df['Age'].astype(int)\ntrain_df['AgeBand'] = pd.cut(train_df['Age'],5 )\ntrain_df[['AgeBand','Survived']].groupby('AgeBand',as_index=False).mean().sort_values(by='AgeBand', ascending=True)","56be5301":"for dataset in combine:\n    dataset.loc[dataset['Age'] <=16, 'Age'] =0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n","e77c974d":"train_df =train_df.drop(['AgeBand'],axis = 1)\ncombine = [train_df, test_df]\ntrain_df.head()","5a7cbd9c":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] +1\n    \ntrain_df[[\"FamilySize\",\"Survived\"]].groupby([\"FamilySize\"],as_index=False).mean().sort_values(by='Survived',ascending=False)","001a0f09":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize']==1, 'IsAlone']=1\n\ntrain_df[[\"IsAlone\", \"Survived\"]].groupby([\"IsAlone\"], as_index = False).mean()","e940716a":"train_df = train_df.drop([\"Parch\",\"SibSp\", \"FamilySize\"],axis=1)\ntest_df = test_df.drop([\"Parch\",\"SibSp\", \"FamilySize\"],axis=1)\n\ncombine = [train_df, test_df]\ntrain_df.head()","de872f59":"for dataset in combine:\n    dataset[\"Age*Class\"] = dataset.Age * dataset.Pclass\n    \ntrain_df[[\"Age*Class\", \"Age\",\"Pclass\"]].head()    ","3846ebe8":"for dataset in combine:\n    dataset['Embarked'] = dataset.Embarked.map({'S': 0, 'C': 1, 'Q': 2}) .astype(int)\n    \ntrain_df.head()    ","3ad1c8f1":"train_df[\"FareBand\"] = pd.qcut(train_df['Fare'],4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).count().sort_values(by='FareBand', ascending=True)","22c693b2":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","1d5190cc":"# using Logistic regression\nX_train = train_df.drop('Survived',axis=1)\nY_train = train_df['Survived']\nX_test = test_df.drop('PassengerId',axis=1).copy()\n","7db6139d":"logreg = LogisticRegression()\nlogreg.fit(X_train,Y_train)\ny_predict = logreg.predict(X_test)\nlogistics_regression_acc_log = round(logreg.score(X_train,Y_train)*100,2)\nlogistics_regression_acc_log","68299db8":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","1fb3e186":"submission = pd.DataFrame({\"PassengerId\": test_df[\"PassengerId\"],\n                           \"Survived\":y_predict })\nsubmission.to_csv('submission.csv', index=False)","0cd1aac8":"We may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).","bec1e15e":"1. We can also create an artificial feature combining Pclass and Age.","d9106d1c":"### Creating new feature extracting from existing\n\nWe want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n\nIn the following code we extract Title feature using regular expressions. The RegEx pattern `(\\w+\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\n\n","6fc6f242":"Decisions: \n\n* Add Sex feature to model training.\n* Complete and add Embarked feature to model training","046147d0":"## Correlating numerical and ordinal features","21d1e2c7":"# Creating new feature extracting from existing","f3ff7075":"# Create new feature combining existing features","3b0c50c9":"# Converting Categorical feature to numeric","fa0777d9":"## Correlating numerical features ","91b28c86":"Let us create Age bands and determine correlations with Survived.","f5c7704f":"We can convert the categorical titles to ordinal.","ff357621":"We can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.","c20b2340":"# Analysing data by Pivoting","07be8284":"We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n\nPositive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\n\n* Sex is highest positivie coefficient, implying as the Sex value increases (male: 0 to female: 1), the probability of Survived=1 increases the most.\n* Inversely as Pclass increases, probability of Survived=1 decreases the most.\n* This way Age*Class is a good artificial feature to model as it has second highest negative correlation with Survived.\n* So is Title as second highest positive correlation.","d0f45b92":"observation:\n* Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n* Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2)","b4a22d62":"\n## Correlating categorical features","64bccfbd":"# Acquire data","dde4ae52":"Observations:\n* Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n* Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n* Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n* Pclass varies in terms of Age distribution of passengers.","fb8de39e":"from the above table we can see that Female passengers had highest survival rate****","e8d78c14":"Let us replace Age with ordinals based on these bands.","54b86638":"# Model, predict, Solve","8d18d5b2":"\nObsevations:\n\n* female passengers has more survival rate than men.\n* Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports.\n","3d6e9e1d":"Now we can convert features which contain strings to numerical values. This is required by most model algorithms. Doing so will also help us in achieving the feature completing goal.\n\nLet us start by converting Sex feature to a new feature called Gender where female=1 and male=0.","5eb66e47":"Now we can easily drop the Name feature from train ,test dataset. we also do not need Passenger_ID column from train\" dataset","923fd6c8":"Description of dataset:\n\nsurvival:    Survival \nPassengerId: Unique Id of a passenger. \npclass:    Ticket class     \nsex:    Sex     \nAge:    Age in years     \nsibsp:    # of siblings \/ spouses aboard the Titanic     \nparch:    # of parents \/ children aboard the Titanic     \nticket:    Ticket number     \nfare:    Passenger fare     \ncabin:    Cabin number     \nembarked:    Port of Embarkation","cf248f97":"# Converting a categorical feature","f836c87d":"# # Creating a new feature using Fare","f5a3933b":"We can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets","5faac159":"Let us start by understanding correlations between numerical features and our solution goal (Survived)","59a4d838":"We can now remove the AgeBand feature.","e9ede8d3":"from the above table we can see that passengers on Pclass1 had highest survival rate","6d2cad43":"Observations :\n\n\n* Infants (Age <=4) had high survival rate.\n* Oldest passengers (Age = 80) survived.\n* Large number of 15-25 year olds did not survive.\n* Most passengers are in 15-35 age range.\n","7ae12f43":"We can replace many titles with a more common name or classify them as `Rare`.","fbbd9402":"Using this we can now create new feature called IsAlone","0e71ba7b":"Observations:\n* Most titles band Age groups accurately. For example: Master title has Age mean of 5 years.\n* Survival among Title Age bands varies slightly.\n* Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).\n\nDecision.\n\n* We decide to retain the new Title feature for model training.","22bda4e1":"Decisions:\n* Consider banding decision feature","55bee57e":"# Analyzing by Visualizing data","931f8083":"Decisions:\n\n* We should consider Age (our assumption classifying #2) in our model training.\n* Complete the Age feature for null values (completing #1).\n* We should band age groups (creating #3)","8653db54":"converting the Fare feature to ordinal values based on FareBand.","97a53316":"Now we can correlate categorical features with our solution goal.","4a9a8b54":"Let us drop Parch, Sibsp and FamilySize in favour of IaAlone","5f4eada0":"Decision:\n* Consider Pclass for model training.","bd8382be":"### Correlating categorical and numerical feature"}}