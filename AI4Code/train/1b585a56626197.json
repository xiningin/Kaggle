{"cell_type":{"eabef1f9":"code","1ac411a8":"code","9da51fe6":"code","046fd494":"code","aa35cfc6":"code","07d2367c":"code","6c91ce90":"code","2c68e14b":"code","2588c475":"code","e389e5da":"code","e95cbdcb":"code","5b8f0304":"code","4751a371":"code","c2c8e373":"code","3fb82243":"code","2a40b0f1":"code","2c52399f":"code","fb2f7e54":"code","c0e92756":"code","bdfcdac3":"code","b2d4d925":"code","d2e19337":"code","a807e84f":"code","886d62b2":"code","9d40d7c3":"code","401cc091":"code","ad8118d7":"code","70f8bb7d":"code","259e900c":"code","7b2660fa":"markdown","3cac6409":"markdown","cd9b4b3c":"markdown","5b227572":"markdown","8e4cc364":"markdown","32c449f2":"markdown","84ca83e1":"markdown","fdad54c2":"markdown","48f9dd97":"markdown","02c0b546":"markdown","b7a72ac9":"markdown","aaa74e7e":"markdown","66231bc9":"markdown","8d675962":"markdown","a458644e":"markdown","0bc0c5fb":"markdown","9186e5d7":"markdown","fb002161":"markdown","369825ac":"markdown","c2f6ebbd":"markdown","f1feaf8b":"markdown","31a0f774":"markdown","5b3d7984":"markdown","5709f284":"markdown","079245ea":"markdown","3c2523d8":"markdown","a67ff88a":"markdown","daf7a965":"markdown","26c57afa":"markdown","726da7c5":"markdown","9be5807d":"markdown","032fd2a0":"markdown","fdbaf8d2":"markdown","7c652444":"markdown","09a7c660":"markdown","52c4c96d":"markdown","ec26839a":"markdown","b0a8246c":"markdown"},"source":{"eabef1f9":"# Disable warnings in Anaconda\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","1ac411a8":"from matplotlib import rcParams\nrcParams['figure.figsize'] = 11, 8","9da51fe6":"def fill_nan(table):\n    for col in table.columns:\n        table[col] = table[col].fillna(table[col].median())\n    return table   ","046fd494":"data = pd.read_csv('..\/input\/credit_scoring_sample.csv')\ndata.head()","aa35cfc6":"data.dtypes","07d2367c":"ax = data['SeriousDlqin2yrs'].hist(orientation='horizontal', color='red')\nax.set_xlabel(\"number_of_observations\")\nax.set_ylabel(\"unique_value\")\nax.set_title(\"Target distribution\")\n\nprint('Distribution of the target:')\ndata['SeriousDlqin2yrs'].value_counts()\/data.shape[0]","6c91ce90":"independent_columns_names = [x for x in data if x != 'SeriousDlqin2yrs']\nindependent_columns_names","2c68e14b":"table = fill_nan(data)","2588c475":"X = table[independent_columns_names]\ny = table['SeriousDlqin2yrs']","e389e5da":"def get_bootstrap_samples(data, n_samples):\n    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n    samples = data[indices]\n    return samples\n\ndef stat_intervals(stat, alpha):\n    boundaries = np.percentile(stat, [100 * alpha \/ 2., 100 * (1 - alpha \/ 2.)])\n    return boundaries\n\ndelay_age = data.loc[data['SeriousDlqin2yrs'] == 1,'age'].values\nnp.random.seed(0)\n\ndelay_age_scores = [np.mean(sample) \n                       for sample in get_bootstrap_samples(delay_age, 1000)]\nprint(\"mean interval\", stat_intervals(delay_age_scores, 0.05))\n","e95cbdcb":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold","5b8f0304":"lr = LogisticRegression(random_state=5, class_weight='balanced')","4751a371":"parameters = {'C': (0.0001, 0.001, 0.01, 0.1, 1, 10)}","c2c8e373":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)","3fb82243":"gcv = GridSearchCV(lr, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='roc_auc')\ngcv.fit(X,y)\ngcv.best_params_\n","2a40b0f1":"best_rocauc = gcv.best_score_\nstd_val = gcv.cv_results_['std_test_score'][gcv.best_index_] * 100 \nprint ('Standard deviation % on validation = ' + str(std_val) )","2c52399f":"print ('LR ROC AUC SCORE % = ' + str(gcv.best_score_* 100))","fb2f7e54":"from sklearn import preprocessing\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(X.values)\nX_norm = pd.DataFrame(x_scaled)\nX_norm.mean()\n\n","c0e92756":"#Double check with correlation matrix and heat map\n\nsns.heatmap(data.corr(),annot=True)\n\n#Highest correlation is between age and seriousdlqin2yrs ","bdfcdac3":"def softmax(x):\n    return np.exp(x) \/ np.sum(np.exp(x), axis=0)\n\n#softmax(X_norm[2])\n#gcv.fit(X,y)\n#gcv.best_params_\n\n#softmax should be applied to outputs not normalized features\n# but which value is demanded in this question? \n# How much Debt Ratio affection could be calculated?","b2d4d925":"from sklearn.ensemble import RandomForestClassifier","d2e19337":"rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42, \n                            class_weight='balanced')","a807e84f":"parameters = {'max_features': [1, 2, 4], 'min_samples_leaf': [3, 5, 7, 9], 'max_depth': [5,10,15]}","886d62b2":"gcv2 = GridSearchCV(rf, parameters, n_jobs=-1, cv=skf, verbose=1,scoring='roc_auc')\ngcv2.fit(X,y)\n","9d40d7c3":"print ('ROC AUC score of RF is higher by ' + str((gcv2.best_score_ - gcv.best_score_)*100) + '%')","401cc091":"rf.fit(X,y)\nrf.feature_importances_\n","ad8118d7":"rf.feature_importances_.min()\n","70f8bb7d":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV\n\nparameters = {'max_features': [2, 3, 4], 'max_samples': [0.5, 0.7, 0.9], \n              'base_estimator__C': [0.0001, 0.001, 0.01, 1, 10, 100]}","259e900c":"bg = BaggingClassifier(base_estimator=100,random_state=42 )\nbg.fit\nrcv = RandomizedSearchCV(bg, parameters, cv=skf,n_iter=20, random_state=1,scoring='roc_auc')\n#Roc auc score is missing","7b2660fa":"Let's set up our environment:","3cac6409":"**Question 6.** Calculate how much `DebtRatio` affects our prediction using the [softmax function](https:\/\/en.wikipedia.org\/wiki\/Softmax_function). What is its value?\n\n1. 0.38\n2. -0.02\n3. 0.11\n4. 0.24","cd9b4b3c":"We will search for the best parameters among the following values:","5b227572":"**Question 8.** How much higher is the *ROC AUC* of the best random forest model than that of the best logistic regression on validation?\n\n1. 4%\n2. 3%\n3. 2%\n4. 1%\n\nA: 1. 4%","8e4cc364":"Apply the function to replace *NaN* values:","32c449f2":"Look at the variable types:","84ca83e1":"**Question 10.** What is the most significant advantage of using *Logistic Regression* versus *Random Forest* for this problem?\n\n1. Spent less time for model fitting;\n2. Fewer variables to iterate;\n3. Feature interpretability;\n4. Linear properties of the algorithm.\n\nA: All of above","fdad54c2":"    **Question 4.** Can we consider the best model stable? The model is *stable* if the standard deviation on validation is less than 0.5%. Save the *ROC AUC* value of the best model; it will be useful for the following tasks.\n\n1. Yes\n2. No\n\nA: 2. No (0.6%)","48f9dd97":"One of the important metrics of model quality is the *Area Under the Curve (AUC)*. *ROC AUC* varies from 0 to 1. The closer ROC AUC is to 1, the better the quality of the classification model.","02c0b546":"**Question 7.** Let's see how we can interpret the impact of our features. For this, recalculate the logistic regression with absolute values, that is without scaling. Next, modify the customer's age by adding 20 years, keeping the other features unchanged. How many times will the chance that the customer will not repay their debt increase? You can find an example of the theoretical calculation [here](https:\/\/www.unm.edu\/~schrader\/biostat\/bio2\/Spr06\/lec11.pdf).\n\n1. -0.01\n2. 0.70\n3. 8.32\n4. 0.66","b7a72ac9":"Separate the input variable names by excluding the target:","aaa74e7e":"**Question 1.** There are 5 jurors in a courtroom. Each of them can correctly identify the guilt of the defendant with 70% probability, independent of one another. What is the probability that the jurors will jointly reach the correct verdict if the final decision is by majority vote?\n\n1. 70.00%\n2. 83.20%\n3. 83.70%\n4. 87.50%\n\nA: 4. 83.70%","66231bc9":"# <center>Assignment # 5 (demo)<\/center>\n## <center>Logistic Regression and Random Forest in the credit scoring problem<\/center>  ","8d675962":"In this assignment, you will build models and answer questions using data on credit scoring.\n\nPlease write your code in the cells with the \"Your code here\" placeholder. Then, answer the questions in the [form](https:\/\/docs.google.com\/forms\/d\/1gKt0DA4So8ohKAHZNCk58ezvg7K_tik26d9QND7WC6M\/edit).\n\nLet's start with a warm-up exercise.","a458644e":"In order to find the optimal value of `C`, let's apply stratified 5-fold validation and look at the *ROC AUC* against different values of the parameter `C`. Use the `StratifiedKFold` function for this: ","0bc0c5fb":"Initialize Random Forest with 100 trees and balance target classes:","9186e5d7":"Separate the target variable and input features:","fb002161":"**Question 11.** Fit a bagging classifier with `random_state=42`. For the base classifiers, use 100 logistic regressors and use `RandomizedSearchCV` instead of `GridSearchCV`. It will take a lot of time to iterate over all 54 variants, so set the maximum number of iterations for `RandomizedSearchCV` to 20. Don't forget to set the parameters `cv` and `random_state=1`. What is the best *ROC AUC* you achieve?\n\n1. 80.75%\n2. 80.12%\n3. 79.62%\n4. 76.50%","369825ac":"Let's set up to use logistic regression:","c2f6ebbd":"**Question 3.** Perform a *Grid Search* with the scoring metric \"roc_auc\" for the parameter `C`. Which value of the parameter `C` is optimal? \n\n1. 0.0001\n2. 0.001\n3. 0.01\n4. 0.1\n5. 1\n6. 10\n\nA: 2. 0.001","f1feaf8b":"<center>\n<img src=\"https:\/\/habrastorage.org\/files\/fd4\/502\/43d\/fd450243dd604b81b9713213a247aa20.jpg\">\n## Open Machine Learning Course\n<center>\nAuthor: Vitaly Radchenko, Data Scientist at YouScan\n\nThis material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source.","31a0f774":"## Feature importance\n\n**Question 5.** *Feature importance* is defined by the absolute value of its corresponding coefficient. First, you need to normalize all of the feature values so that it will be valid to compare them. What is the most important feature for the best logistic regression model?\n\n1. age\n2. NumberOfTime30-59DaysPastDueNotWorse\n3. DebtRatio\n4. NumberOfTimes90DaysLate\n5. NumberOfTime60-89DaysPastDueNotWorse\n6. MonthlyIncome\n7. NumberOfDependents\n\nA: 1. age (as it have the largest mean after normalization)","5b3d7984":"Check the class balance:","5709f284":"## Logistic regression","079245ea":"Import the Random Forest classifier:","3c2523d8":"Now, we will create a `LogisticRegression` model and use `class_weight='balanced'` to make up for our unbalanced classes.","a67ff88a":"Let's write the function that will replace *NaN* values with the median for each column.","daf7a965":"Let's try to find the best regularization coefficient, which is the coefficient `C` for logistic regression. Then, we will have an optimal model that is not overfit and is a good predictor of the target variable.","26c57afa":"Great! Let's move on to machine learning.\n\n## Credit scoring problem setup\n\n#### Problem\n\nPredict whether the customer will repay their credit within 90 days. This is a binary classification problem; we will assign customers into good or bad categories based on our prediction.\n\n#### Data description\n\n| Feature | Variable Type | Value Type | Description |\n|:--------|:--------------|:-----------|:------------|\n| age | Input Feature | integer | Customer age |\n| DebtRatio | Input Feature | real | Total monthly loan payments (loan, alimony, etc.) \/ Total monthly income percentage |\n| NumberOfTime30-59DaysPastDueNotWorse | Input Feature | integer | The number of cases when client has overdue 30-59 days (not worse) on other loans during the last 2 years |\n| NumberOfTimes90DaysLate | Input Feature | integer | Number of cases when customer had 90+dpd overdue on other credits |\n| NumberOfTime60-89DaysPastDueNotWorse | Input Feature | integer | Number of cased when customer has 60-89dpd (not worse) during the last 2 years |\n| NumberOfDependents | Input Feature | integer | The number of customer dependents |\n| SeriousDlqin2yrs | Target Variable | binary: <br>0 or 1 | Customer hasn't paid the loan debt within 90 days |\n","726da7c5":"**Question 12.** Give an interpretation of the best parameters for bagging. Why are these values of `max_features` and `max_samples` the best?\n\n1. For bagging it's important to use as few features as possible;\n2. Bagging works better on small samples;\n3. Less correlation between single models;\n4. The higher the number of features, the lower the loss of information.","9be5807d":"## Bagging","032fd2a0":"Import modules and set up the parameters for bagging:","fdbaf8d2":"## Bootstrapping","7c652444":"**Question 9.** What feature has the weakest impact in the Random Forest model?\n\n1. age\n2. NumberOfTime30-59DaysPastDueNotWorse\n3. DebtRatio\n4. NumberOfTimes90DaysLate\n5. NumberOfTime60-89DaysPastDueNotWorse\n6. MonthlyIncome\n7. NumberOfDependents\n\nA: 7. NumberOfDependents","09a7c660":"Now, read the data:","52c4c96d":"Also, we will use the stratified k-fold validation again. You should still have the `skf` variable.","ec26839a":"## Random Forest","b0a8246c":"**Question 2.** Make an interval estimate of the average age for the customers who delayed repayment at the 90% confidence level. Use the example from the article as reference, if needed. Also, use `np.random.seed(0)` as before. What is the resulting interval estimate?\n\n1. 52.59 \u2013 52.86\n2. 45.71 \u2013 46.13\n3. 45.68 \u2013 46.17\n4. 52.56 \u2013 52.88\n\nA: 3. 45.68 \u2013 46.17"}}