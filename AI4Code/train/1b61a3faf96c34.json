{"cell_type":{"42735b85":"code","c54052d1":"code","cfb71592":"code","9581fe65":"code","dd332a2f":"code","ba43771e":"code","7cf72f3e":"code","b9e47efb":"code","d4fe7f78":"code","524f51e0":"code","1522c05a":"code","4d2f60e1":"code","f96b7724":"code","1c2f32e0":"code","d6484e18":"code","4c739da4":"code","c049a3d6":"code","58d4fdc8":"code","268f289d":"code","374f0ae1":"code","1e98083f":"code","d0979e18":"code","8d9a2763":"code","7ae1265d":"code","72a9d162":"code","a4648700":"code","96ef3476":"code","48006023":"code","23fd285e":"code","1c052880":"code","c53322cb":"code","e9c24f97":"code","397c04f1":"code","e1ea64a1":"code","a38d8e1c":"code","166a6f5d":"code","2525fd7c":"markdown","83484880":"markdown","8879c69a":"markdown","60a3336d":"markdown","45b4b53e":"markdown","b240df8b":"markdown","6840bf11":"markdown","4f94a406":"markdown","535abf02":"markdown","cbb01577":"markdown","5b5d152a":"markdown","af55a947":"markdown","56f746ff":"markdown","35d09ce5":"markdown","f358f2c0":"markdown","850fa08d":"markdown","83036ac2":"markdown","38ca1e9d":"markdown","02a45ce4":"markdown","c4a54acd":"markdown"},"source":{"42735b85":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")\nplt.style.use('ggplot')\ncolor_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]","c54052d1":"# List all the files in the input directory\n!ls -GFlash --color ..\/input","cfb71592":"# Transaction CSVs\ntrain_transaction = pd.read_csv('..\/input\/train_transaction.csv')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv')\n# Identity CSVs - These will be merged onto the transactions to create additional features\ntrain_identity = pd.read_csv('..\/input\/train_identity.csv')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv')\n# Sample Submissions\nss = pd.read_csv('..\/input\/sample_submission.csv')","9581fe65":"print('train_transaction shape is {}'.format(train_transaction.shape))\nprint('test_transaction shape is {}'.format(test_transaction.shape))\nprint('train_identity shape is {}'.format(train_identity.shape))\nprint('test_identity shape is {}'.format(test_identity.shape))","dd332a2f":"# Here we confirm that all of the transactions in `train_identity`\nprint(np.sum(train_transaction['TransactionID'].isin(train_identity['TransactionID'].unique())))\nprint(np.sum(test_transaction['TransactionID'].isin(test_identity['TransactionID'].unique())))","ba43771e":"train_transaction['TransactionDT'].plot(kind='hist',\n                                        figsize=(15, 5),\n                                        label='train',\n                                        bins=50,\n                                        title='Train vs Test TransactionDT distribution')\ntest_transaction['TransactionDT'].plot(kind='hist',\n                                       label='test',\n                                       bins=50)\nplt.legend()\nplt.show()","7cf72f3e":"ax = train_transaction.plot(x='TransactionDT',\n                       y='TransactionAmt',\n                       kind='scatter',\n                       alpha=0.01,\n                       label='TransactionAmt-train',\n                       title='Train and test Transaction Ammounts by Time (TransactionDT)',\n                       ylim=(0, 5000),\n                       figsize=(15, 5))\ntest_transaction.plot(x='TransactionDT',\n                      y='TransactionAmt',\n                      kind='scatter',\n                      label='TransactionAmt-test',\n                      alpha=0.01,\n                      color=color_pal[1],\n                       ylim=(0, 5000),\n                      ax=ax)\n# Plot Fraud as Orange\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    .plot(x='TransactionDT',\n         y='TransactionAmt',\n         kind='scatter',\n         alpha=0.01,\n         label='TransactionAmt-train',\n         title='Train and test Transaction Ammounts by Time (TransactionDT)',\n         ylim=(0, 5000),\n         color='orange',\n         figsize=(15, 5),\n         ax=ax)\nplt.show()","b9e47efb":"print('  {:.4f}% of Transactions that are fraud in train '.format(train_transaction['isFraud'].mean() * 100))","d4fe7f78":"train_transaction.groupby('isFraud') \\\n    .count()['TransactionID'] \\\n    .plot(kind='barh',\n          title='Distribution of Target in Train',\n          figsize=(15, 3))\nplt.show()","524f51e0":"train_transaction['TransactionAmt'] \\\n    .apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          figsize=(15, 5),\n          title='Distribution of Log Transaction Amt')\nplt.show()","1522c05a":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    ['TransactionAmt'].apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='Log Transaction Amt - Fraud',\n          color=color_pal[1],\n          xlim=(-3, 10),\n         ax= ax1)\ntrain_transaction.loc[train_transaction['isFraud'] == 0] \\\n    ['TransactionAmt'].apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='Log Transaction Amt - Not Fraud',\n          color=color_pal[2],\n          xlim=(-3, 10),\n         ax=ax2)\ntrain_transaction.loc[train_transaction['isFraud'] == 1] \\\n    ['TransactionAmt'] \\\n    .plot(kind='hist',\n          bins=100,\n          title='Transaction Amt - Fraud',\n          color=color_pal[1],\n         ax= ax3)\ntrain_transaction.loc[train_transaction['isFraud'] == 0] \\\n    ['TransactionAmt'] \\\n    .plot(kind='hist',\n          bins=100,\n          title='Transaction Amt - Not Fraud',\n          color=color_pal[2],\n         ax=ax4)\nplt.show()","4d2f60e1":"print('Mean transaction amt for fraud is {:.4f}'.format(train_transaction.loc[train_transaction['isFraud'] == 1]['TransactionAmt'].mean()))\nprint('Mean transaction amt for non-fraud is {:.4f}'.format(train_transaction.loc[train_transaction['isFraud'] == 0]['TransactionAmt'].mean()))","f96b7724":"train_transaction.groupby('ProductCD') \\\n    ['TransactionID'].count() \\\n    .sort_index() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n         title='Count of Observations by ProductCD')\nplt.show()","1c2f32e0":"train_transaction.groupby('ProductCD')['isFraud'] \\\n    .mean() \\\n    .sort_index() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n         title='Percentage of Fraud by ProductCD')\nplt.show()","d6484e18":"card_cols = [c for c in train_transaction.columns if 'card' in c]\ntrain_transaction[card_cols].head()","4c739da4":"color_idx = 0\nfor c in card_cols:\n    if train_transaction[c].dtype in ['float64','int64']:\n        train_transaction[c].plot(kind='hist',\n                                      title=c,\n                                      bins=50,\n                                      figsize=(15, 2),\n                                      color=color_pal[color_idx])\n    color_idx += 1\n    plt.show()","c049a3d6":"train_transaction_fr = train_transaction.loc[train_transaction['isFraud'] == 1]\ntrain_transaction_nofr = train_transaction.loc[train_transaction['isFraud'] == 0]\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\ntrain_transaction_fr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax1, title='Count of card4 fraud')\ntrain_transaction_nofr.groupby('card4')['card4'].count().plot(kind='barh', ax=ax2, title='Count of card4 non-fraud')\ntrain_transaction_fr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax3, title='Count of card6 fraud')\ntrain_transaction_nofr.groupby('card6')['card6'].count().plot(kind='barh', ax=ax4, title='Count of card6 non-fraud')\nplt.show()","58d4fdc8":"print(' addr1 - has {} NA values'.format(train_transaction['addr1'].isna().sum()))\nprint(' addr2 - has {} NA values'.format(train_transaction['addr2'].isna().sum()))","268f289d":"train_transaction['addr1'].plot(kind='hist', bins=500, figsize=(15, 2), title='addr1 distribution')\nplt.show()\ntrain_transaction['addr2'].plot(kind='hist', bins=500, figsize=(15, 2), title='addr2 distribution')\nplt.show()","374f0ae1":"train_transaction['dist1'].plot(kind='hist',\n                                bins=5000,\n                                figsize=(15, 2),\n                                title='dist1 distribution',\n                                color=color_pal[1],\n                                logx=True)\nplt.show()\ntrain_transaction['dist2'].plot(kind='hist',\n                                bins=5000,\n                                figsize=(15, 2),\n                                title='dist2 distribution',\n                                color=color_pal[1],\n                                logx=True)\nplt.show()","1e98083f":"c_cols = [c for c in train_transaction if c[0] == 'C']\ntrain_transaction[c_cols].head()","d0979e18":"# Sample 500 fraud and 500 non-fraud examples to plot\nsampled_train = pd.concat([train_transaction.loc[train_transaction['isFraud'] == 0].sample(500),\n          train_transaction.loc[train_transaction['isFraud'] == 1].sample(500)])\n\nsns.pairplot(sampled_train, \n             hue='isFraud',\n            vars=c_cols)\nplt.show()","8d9a2763":"d_cols = [c for c in train_transaction if c[0] == 'D']\ntrain_transaction[d_cols].head()","7ae1265d":"sns.pairplot(sampled_train, \n             hue='isFraud',\n            vars=d_cols)\nplt.show()","72a9d162":"m_cols = [c for c in train_transaction if c[0] == 'M']\ntrain_transaction[m_cols].head()","a4648700":"(train_transaction[m_cols] == 'T').sum().plot(kind='bar',\n                                              title='Count of T by M column',\n                                              figsize=(15, 2),\n                                              color=color_pal[3])\nplt.show()\n(train_transaction[m_cols] == 'F').sum().plot(kind='bar',\n                                              title='Count of F by M column',\n                                              figsize=(15, 2),\n                                              color=color_pal[4])\nplt.show()\n(train_transaction[m_cols].isna()).sum().plot(kind='bar',\n                                              title='Count of NaN by M column',\n                                              figsize=(15, 2),\n                                              color=color_pal[0])\nplt.show()","96ef3476":"# Looking at M4 column since it is different than the others\ntrain_transaction.groupby('M4')['TransactionID'] \\\n    .count() \\\n    .plot(kind='bar',\n          title='Count of values for M4',\n          figsize=(15, 3))\nplt.show()","48006023":"v_cols = [c for c in train_transaction if c[0] == 'V']\ntrain_transaction[v_cols].head()","23fd285e":"train_transaction[v_cols].describe()","1c052880":"train_transaction['v_mean'] = train_transaction[v_cols].mean(axis=1)","c53322cb":"fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 6))\ntrain_transaction.loc[train_transaction['isFraud'] == 1]['v_mean'] \\\n    .apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='log transformed mean of V columns - Fraud',\n          ax=ax1)\ntrain_transaction.loc[train_transaction['isFraud'] == 0]['v_mean'] \\\n    .apply(np.log) \\\n    .plot(kind='hist',\n          bins=100,\n          title='log transformed mean of V columns - Not Fraud',\n          color=color_pal[5],\n          ax=ax2)\nplt.show()","e9c24f97":"# Add the `isFraud` column for analysis\ntrain_identity_ = train_identity.merge(train_transaction[['TransactionID',\n                                                         'TransactionDT',\n                                                         'isFraud']],\n                                      on=['TransactionID'])\n\ntest_identity_ = test_identity.merge(test_transaction[['TransactionID',\n                                                      'TransactionDT']],\n                                    on=['TransactionID'])","397c04f1":"train_identity_.groupby('DeviceType') \\\n    .mean()['isFraud'] \\\n    .sort_values() \\\n    .plot(kind='barh',\n          figsize=(15, 5),\n          title='Percentage of Fraud by Device Type')\nplt.show()","e1ea64a1":"train_identity_.groupby('DeviceInfo') \\\n    .count()['TransactionID'] \\\n    .sort_values(ascending=False) \\\n    .head(20) \\\n    .plot(kind='barh', figsize=(15, 5), title='Top 20 Devices in Train')\nplt.show()","a38d8e1c":"id_cols = [c for c in train_identity.columns if 'id' in c]\nfor i in id_cols:\n    try:\n        train_identity_.set_index('TransactionDT')[i].plot(style='.', title=i, figsize=(15, 3))\n        test_identity_.set_index('TransactionDT')[i].plot(style='.', title=i, figsize=(15, 3))\n        plt.show()\n    except TypeError:\n        pass","166a6f5d":"for c in ['addr2','C11','D5','D8','D1','D15','V144','V145','V150','V151','V159','V160']:\n    try:\n        train_transaction.set_index('TransactionDT')[c].plot(style='.', title=c, figsize=(15, 3), alpha=0.01)\n        test_transaction.set_index('TransactionDT')[c].plot(style='.', title=c, figsize=(15, 3), alpha=0.01)\n        plt.show()\n    except TypeError:\n        pass\n    except KeyError:\n        pass","2525fd7c":"# dist1 & dist2\nPlotting with logx to better show the distribution. Possibly this could be the distance of the transaction vs. the card owner's home\/work address. This is just a guess.","83484880":"## DeviceType","8879c69a":"# D1-D9\nSimilarly for features D1-D9. In these plots we can see some linear and non-linear interactions between features. We may want to create additional features using these interactions if we think it would help our model better find relationship between fraud and non-fraud observations.","60a3336d":"# Train vs Test are Time Series Split\n\nThe `TransactionDT` feature is a timedelta from a given reference datetime (not an actual timestamp). One early discovery about the data is that the train and test appear to be split by time. There is a slight gap inbetween, but otherwise the training set is from an earlier period of time and test is from a later period of time. This will impact which cross validation techniques should be used.\n\nWe will look into this more when reviewing differences in distribution of features between train and test.","45b4b53e":"- Fraudulent charges appear to have a higher average transaction ammount ","b240df8b":"# Categorical Features - Transaction\nWe are told in the data description that the following transaction columns are categorical:\n- ProductCD\n- emaildomain\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9","6840bf11":"# Distribution of Target in Training Set\n- 3.5% of transacations are fraud","4f94a406":"# Data\n\nIn the competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud.\n\nThe data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information.","535abf02":"# Identity Data\nNext we will explore the identity data. These are provided for some, but not all `TransactionID`s. It contains information about the identity of the customer.\n- Categorical Features\n- `DeviceType`\n- `DeviceInfo`\n- `id_12` - `id_38`","cbb01577":"# C1 - C14\nBecause we are provided many numerical columns, we can create a pairplot to plot feature interactions. I know these plots can be hard to read, but it is helpful for gaining intution about potential feature interactions and if certain features have more variance than others.","5b5d152a":"- 24.4% of TransactionIDs in **train** (144233 \/ 590540) have an associated train_identity.\n- 28.0% of TransactionIDs in **test** (144233 \/ 590540) have an associated train_identity.","af55a947":"# IEEE Fraud Detection Competition\n![fraud](https:\/\/abcountrywide.com.au\/wp-content\/uploads\/2018\/04\/fraud.jpg)\n\nIn this kernel I do some basic exploritory data analysis on the IEEE Fraud Detection dataset. Please upvote if you find this kernel helpful. I will continue to update as I find more discoveries. I suggest you also read the complete competition overview and data description found in the competition page.\n\nI purposefully show all of my code. The intention is to not only show the results, but also have clear code that shows how similar analysis can be done on any dataset.\n\nFrom the [competition overview](https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/overview):\n\n*In this competition, you\u2019ll benchmark machine learning models on a challenging large-scale dataset. The data comes from Vesta's real-world e-commerce transactions and contains a wide range of features from device type to product features. You also have the opportunity to create new features to improve your results.*\n   \n*If successful, you\u2019ll improve the efficacy of fraudulent transaction alerts for millions of people around the world, helping hundreds of thousands of businesses reduce their fraud loss and increase their revenue. And of course, you will save party people just like you the hassle of false positives.*","56f746ff":"## Identity info as a function of time","35d09ce5":"## TransactionAmt\nThe ammount of transaction. I've taken a log transform in some of these plots to better show the distribution- otherwise the few, very large transactions skew the distribution. Because of the log transfrom, any values between 0 and 1 will appear to be negative.","f358f2c0":"## ProductCD\n- For now we don't know exactly what these values represent.\n- `W` has the most number of observations, `C` the least.\n- ProductCD `C` has the most fraud with >11%\n- ProductCD `W` has the least with ~2%","850fa08d":"# addr1 & addr2\nThe data description states that these are categorical even though they look numeric. Could they be the address value?","83036ac2":"## Compare Numeric Features in Train and Test\nSimilar to above but for the transaction data, specific examples that look interesting.","38ca1e9d":"# M1-M9\n- Values are `T` `F` or `NaN`\n- Column `M4` appears to be different with values like `M2` and `M0`","02a45ce4":"# V1 - V339\nLots of 1s 0s and Nans, some larger values","c4a54acd":"# card1 - card6\n- We are told these are all categorical, even though some appear numeric."}}