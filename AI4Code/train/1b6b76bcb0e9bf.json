{"cell_type":{"2ff73bab":"code","e92a7bd4":"code","b83caf11":"code","ded92a2b":"code","38deef40":"code","74dbd333":"code","9b485731":"code","9d78c0e2":"code","70174eac":"code","665668d9":"code","a1f98c47":"code","e4778371":"code","cbe1c7ef":"code","c58d28c6":"code","5d9af501":"code","d4ff93c1":"code","92ba508d":"code","ec00e53f":"code","5f7cc06b":"markdown","53d19a6d":"markdown","0ece8859":"markdown","ebaae3e1":"markdown","e27d5b05":"markdown"},"source":{"2ff73bab":"# Importing Libraries\n\nimport numpy as np \nimport pandas as pd \n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, SpatialDropout2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\n\nimport keras\nfrom keras.callbacks import EarlyStopping , ModelCheckpoint , ReduceLROnPlateau\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model\n\nimport matplotlib.pyplot as plt\n\n\nprint(\"packages imported.\")","e92a7bd4":"# Setting the paths\n\naugmented_images_base_path    = '..\/input\/stanford-cars-augmented-balanced\/Augmented_Balanced_Stanford_Car_Images_Uncropped\/'\n\ntraining_folder_path          = augmented_images_base_path + 'Train_Augmented_Images'\nvalidation_folder_path        = augmented_images_base_path + 'Validation_Augmented_Images'\ntesting_folder_path           = augmented_images_base_path + 'Test_Images'\n\nprint('Paths defined')","b83caf11":"# Utility to unfreeze layers of a pretrained model\ndef unfreeze(conv_base, n_layers = 0, verbose = 0):\n    '''\n    Receive a convbase and unfreeze a certain number of layers in it, as per passed parameter.\n    '''\n    total_layers = len(conv_base.layers)\n    unfreeze     = n_layers\n\n    for pos, layr in enumerate(conv_base.layers):\n        layr.trainable = False\n        if pos >= total_layers - unfreeze:\n            layr.trainable = True\n        if verbose:\n            print(layr, bool(layr.trainable))\n    print('conv_base ready.')\n    return conv_base        \nprint('unfreeze function ready')   ","ded92a2b":"from keras.applications import MobileNetV2 as pretrained_model\n\nsize    = (224, 224)\n\nprint(f'Pretrained model {pretrained_model} loaded.')\nprint('Size of input image set at', size)","38deef40":"# The Image Generators\nbatch_size      = 128\n\ndatagen         = ImageDataGenerator(  rescale         =1.\/255,\n                                       rotation_range  = 3,\n                                       shear_range     = 0.05,\n                                       zoom_range      = 0.2,\n                                       horizontal_flip = True\n                                    )\n\ntrain_generator = datagen.flow_from_directory(\n                                            directory   = training_folder_path,\n                                            class_mode  = \"categorical\",\n                                            target_size = size,\n                                            seed        = 42,\n                                            batch_size  = batch_size)\nval_generator   = datagen.flow_from_directory(\n                                            directory   = validation_folder_path,\n                                            class_mode  = \"categorical\",\n                                            target_size = size,\n                                            seed        = 42,\n                                            batch_size  = batch_size)\n\nprint('train_generator ,val_generator are ready for use')\nprint(f'Using image size {size}')\nprint(f'Using batch size {batch_size}')","74dbd333":"# Configure the pretrained base by specifying the number of layers that are to be 'unfrozen'\n\nn_unfreeze    =  0  \n\n\ninput_shape   = (size[0], size[1], 3)\nconv_base     = pretrained_model(weights = 'imagenet',\n                                      include_top = False,\n                                      input_shape = input_shape)\n\nconv_base     = unfreeze(conv_base, n_layers = n_unfreeze, verbose = 0)","9b485731":"# Model Architecture\n\ntf.keras.backend.clear_session()\n##########################################################################################\nmodel = Sequential()\nmodel.add(conv_base)\nmodel.add(SpatialDropout2D(0.30))\n\nmodel.add(Conv2D(2048,(1,1), padding = 'same'))\nmodel.add(SpatialDropout2D(0.25))\n\nmodel.add(Conv2D(1024,(1,1), padding = 'same'))\nmodel.add(SpatialDropout2D(0.25))\n\nmodel.add(Conv2D(256,(1,1), padding = 'same'))\nmodel.add(SpatialDropout2D(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.40))\nmodel.add(Dense(196, activation='softmax'))\nprint(model.summary())","9d78c0e2":"# basework for the callbacks\n\n# Metrics to track\nmetrics = ['categorical_accuracy',\n           tf.keras.metrics.TopKCategoricalAccuracy(k = 3, name=\"top_3_acc\", dtype=None),\n           tf.keras.metrics.TopKCategoricalAccuracy(k = 5, name=\"top_5_acc\", dtype=None)\n          ]\n\nmode = 'max'\nmonit = 'val_top_3_acc'\nsave_model_name = 'MobileNetv2_model_1.h5'   # remember to use the h5 extension\n\n# The callbacks\neskb = EarlyStopping(monitor = monit, mode = mode, verbose = 1, patience = 4, restore_best_weights = True)\nmckb = ModelCheckpoint(save_model_name, monitor = monit, mode = mode, verbose=1, save_best_only=True)\nrlkb = ReduceLROnPlateau(monitor = monit,  factor=0.1,    mode = mode, patience = 2, verbose = 1) \ncb   = [eskb, mckb, rlkb]\n\nprint(f'All set to save model as \"{save_model_name}\"')","70174eac":"# Compile the model\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer  =  Adam(learning_rate = 1e-3),\n              metrics    =  metrics)\nprint(f'Model compiled with {n_unfreeze} pre-trained layers unfrozen.')  \n\n# stop --> consider-->execute\n\n# setup for iterative training if you wish to fiddle with dropouts or callbacks etc.\n# weights_ = keras.models.load_model('').get_weights() # when re-running the notebook with the model in the output directory. Set the model path accordingly.\n# weights_ = keras.models.load_model('').get_weights()  # first run, when you want use weights from the input directory. Set the model path accordingly.\n# model.set_weights(weights_)\n\nstep_size = 20\n\n\n# Having a step size of 20 with batches of 128 lets one approximate the original dataset numbers per epoch.\n# This is just to speed up the iteration. One can easily change this to run through the entire training set every epoch.\n# Be warned, though, that takes a lot of time.\n\nhistory = model.fit(x=train_generator,\n                    steps_per_epoch  = step_size*3,\n                    validation_data  = val_generator,\n                    validation_steps = step_size,\n                    verbose = 1, callbacks = cb,\n                    epochs  = 100) # The idea of using a hundred epochs is to give the model a free run and let the callback keep tabs.\nprint('All done !!')","665668d9":"#code to download output files from kaggle\n\nfrom IPython.display import FileLink\nFileLink(r'MobileNetv2_model_1.h5')","a1f98c47":"# Looking at the history\ndef plot_model_history(model_history):\n    print(\"Plotting Model History -- Model Accuracy & Model Loss\")    \n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['categorical_accuracy'])+1),model_history.history['categorical_accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_categorical_accuracy'])+1),model_history.history['val_categorical_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(range(0 , len(model_history.history['categorical_accuracy'])+4, 5))   \n    axs[0].legend(['Training', 'Validation'], loc='best')\n    \n    ###################\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[0].set_xticks(range(0 , len(model_history.history['loss'])+7,5 ))   \n    axs[1].legend(['Training', 'Validation'], loc='best')\n    plt.show()\n\nprint('*plot_model_history* function ready to use')","e4778371":"plot_model_history(history)","cbe1c7ef":"test_datagen    = ImageDataGenerator(rescale=1. \/ 255)\n\ntest_generator  = test_datagen.flow_from_directory(\n    directory   = testing_folder_path,\n    target_size = size,\n    batch_size  = 32,\n    class_mode  = \"categorical\",\n    shuffle     = False  )\n\ntest_generator.reset()\n\npreds           =  model.predict(test_generator,verbose=1, steps = None)\n\npredicted_class_indices = np.argmax(preds,axis=1)\n\n# Next step is I want the name of the classes:\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\n# create a dataframe with the image names and class predicted.\n\nfilenames     =  test_generator.filenames\nresults       =  pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\n\ndisplay(results.sample(5))\n\n","c58d28c6":"# !nvidia-smi","5d9af501":"# Now we create a dataframe with actual car class name and predicted car classnames, to allow further analysis\n\ncomparison = results.copy()\ncomparison['Actual'] = comparison['Filename'].apply(lambda x: x.split('\/')[0])\ncomparison.drop('Filename', axis = 1, inplace = True)\ndisplay(comparison.sample(5))","d4ff93c1":"from sklearn.metrics import classification_report \nprint(classification_report(comparison['Actual'],comparison['Predictions']))","92ba508d":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Confusion Matrix\ncm = confusion_matrix(comparison['Predictions'],comparison['Actual'])\nprint('\\n Confusion Matrix :- \\n')\nprint(cm)\nprint(\"\")\n\n# Plot Confusion matrix\nf, ax = plt.subplots(figsize=(12,7))\nsns.heatmap(cm,annot = False, linewidths=0,linecolor=\"blue\",fmt=\".0f\",ax=ax,cmap='YlGnBu')\n# plt.xlabel('Actual Classes', fontsize = 15)\n# plt.ylabel('Predicted Classes', fontsize = 15)\nplt.xlabel('')\nplt.ylabel('')\nplt.xticks([])\nplt.yticks([])\nplt.title('Confusion Matrix HeatMap - Stanford Cars\\nNote the nice diagonal\\n', fontsize = 15)\nplt.show()","ec00e53f":"# Making single image predictions\n\nfrom PIL import Image\n\ndef single_image_prediction(path, n = 5):\n    '''\n    1. read image\n    2. resize\n    3. reshape\n    4. pass to model\n    5. generate top 3 predictions\n    6. Display image and predictions with confidence levels    \n    '''\n    # read path and show image\n    img_ = Image.open(path)\n    plt.imshow(img_)\n    plt.show()   \n    \n    # resize and reshape\n        \n    img_ = img_.resize(size)\n    img_ = np.array(img_).reshape((1,size[0],size[1],3 ))\n    \n    # run the model and make the prediction\n    function_pred = model.predict(img_)\n    \n    rep = pd.DataFrame(index = range(0,196))\n    rep['probabilities'] = function_pred[0]\n    rep = rep.reset_index(drop = False)\n    rep['Class Name']   = rep['index'].apply(labels.get)\n    rep.drop('index', axis = 1, inplace = True)\n    \n    rep = rep.sort_values(by = 'probabilities', ascending = False).head(n)\n    rep = rep[['Class Name', 'probabilities']]\n    \n    display(rep)\n    \n    \n#     display(pd.DataFrame(prediction).T)\n    print('all done')\n    return\n#####################################################    \n    \n# path = '..\/input\/stanford-cars-augmented-balanced\/Augmented_Balanced_Stanford_Car_Images_Uncropped\/Test_Images\/Jaguar XK XKR 2012\/Test_01_03025.jpg'\npath = '..\/input\/stanford-cars-augmented-balanced\/Augmented_Balanced_Stanford_Car_Images_Uncropped\/Test_Images\/AM General Hummer SUV 2000\/Test_01_01199.jpg' # hummer\nsingle_image_prediction(path,3)","5f7cc06b":"The idea of using top-3 categorical accuracy as a monitored metric is this.\n\nThe overall validation accuracy is not very high. This is partly due to the large number of classes. So to let the training process go on, I'm happy if the model continues to improve its second and third guesses.","53d19a6d":"# Model Making","0ece8859":"So clearly the model has a lot to learn. Feel free to experiment and put in a comment if you find something interesting to share.\n\nIf you liked the workflow, don't forget to upvote the notebook. Thanks !!","ebaae3e1":"# Car Model Classification\n\n>https:\/\/www.kaggle.com\/saurabhsawhney\n\n>https:\/\/www.kaggle.com\/ameyapat\n\n>https:\/\/www.kaggle.com\/mewtyunjay\n\n>https:\/\/www.kaggle.com\/muraligollapudi\n\n>https:\/\/www.kaggle.com\/rohithandagl\n\n","e27d5b05":"## EVALUATION"}}