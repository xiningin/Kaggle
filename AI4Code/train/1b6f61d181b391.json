{"cell_type":{"739f9fe7":"code","e2903bfe":"code","56915635":"code","989fbcb9":"code","47271941":"code","022fc6a9":"code","5ce16cd6":"code","341a39d8":"code","7bee8455":"code","b7d9a869":"code","abff9ce9":"code","10902192":"code","5e0ec71d":"code","3ebf88e1":"code","812463f1":"code","bda580fd":"code","30fd03af":"code","5a34ce8c":"code","02d17934":"code","600bbce1":"code","a62edc6d":"code","eb7a4d32":"code","35adad2f":"code","608c45bf":"code","67b59ead":"code","e7045313":"code","c8780168":"code","60c73e64":"code","fc364166":"code","e64eb5f9":"code","2960eb03":"code","143be6ce":"code","630ec764":"code","67eeca6b":"code","80b242fe":"code","fc5af145":"code","e4fc5679":"code","4fd8ecd7":"code","a4913457":"code","bd67330a":"code","4d84bb30":"code","fc0296f2":"code","f1ee7b53":"code","5c33e876":"code","cc92492e":"code","61d3977f":"code","84d3a698":"code","391df2f1":"code","34c53d51":"code","14f13ad6":"code","1fab9582":"code","eed6db1d":"code","81c6205c":"code","e1fc40a6":"code","5ff487f4":"code","bb72fbdd":"code","99cd2e39":"code","9ee32cbe":"code","359fea78":"code","587601f6":"code","bc783622":"code","98e565bb":"code","17c0c292":"code","1d12e494":"code","44cde29c":"code","d8021ea1":"code","19bd4a4b":"code","24b0a92e":"code","bbc8a592":"code","908c1a7a":"code","1b93642b":"code","3277399b":"code","7a5c9490":"code","8dc658fc":"code","f0e0c3e7":"markdown","21169e8b":"markdown","9c51a677":"markdown","5f6c7d04":"markdown","5108870e":"markdown","3f0fef50":"markdown","1d45d674":"markdown","7678bdef":"markdown","97d27ac3":"markdown","27be9db3":"markdown","ee3264c6":"markdown","db6487eb":"markdown","e15babf1":"markdown","277bb520":"markdown","808ab283":"markdown","37a7a617":"markdown","b9ffdcd4":"markdown","31721546":"markdown","e6c410ea":"markdown","39d0b58c":"markdown","73b63aa5":"markdown","e2ddd1a6":"markdown","89472336":"markdown","432d5847":"markdown","91f0bf60":"markdown","84a6df88":"markdown","836e0e8e":"markdown","0d72e164":"markdown","916697ab":"markdown","16eb36b0":"markdown","f522c4ee":"markdown","dda9b05a":"markdown","0f54f6c9":"markdown","8411e437":"markdown","8173faee":"markdown","100de35e":"markdown","f406d65f":"markdown","769ac142":"markdown","f2afd8c9":"markdown","58066891":"markdown","81400f4f":"markdown","e26a85cf":"markdown","69b16b89":"markdown","7dfc34e8":"markdown","cf4ecd8a":"markdown","63f09d48":"markdown","ee12d7c3":"markdown","7c6b437e":"markdown","ff844a47":"markdown","56f0d0d6":"markdown","0ca3285b":"markdown","c1592c95":"markdown","b5d12a4a":"markdown","a5283d4a":"markdown","e2920631":"markdown","6ce6cf0f":"markdown","9bf6ea53":"markdown","dfb5b3ce":"markdown","f4b424fd":"markdown","fdde5dab":"markdown","45402fe9":"markdown"},"source":{"739f9fe7":"import pandas as pd","e2903bfe":"df = pd.read_csv('..\/input\/titanic\/train.csv')","56915635":"df.head()","989fbcb9":"df.isnull().sum()","47271941":"df[df['Embarked'].isnull()]","022fc6a9":"df = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Age','Fare','Survived'])\ndf.head()","5ce16cd6":"df.isnull().sum()","341a39d8":"df.isnull().mean()","7bee8455":"def impute_nan(df, variable, median):\n    df[variable+'_median'] = df[variable].fillna(median)","b7d9a869":"median = df['Age'].median()\nmedian","abff9ce9":"impute_nan(df, 'Age', median)","10902192":"df.head()","5e0ec71d":"print(df['Age'].std())\nprint(df['Age_median'].std())","3ebf88e1":"import matplotlib.pyplot as plt\n%matplotlib inline","812463f1":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde', ax=ax)\ndf['Age_median'].plot(kind='kde', ax=ax, color='red')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","bda580fd":"df = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Age','Fare','Survived'])\ndf.head()","30fd03af":"df.isnull().sum()","5a34ce8c":"# We are trying to remove na from df and from all the other values left, sample will be chosen \n# The sample of the size is nothing but 'df['Age'].isnull().sum()'\ndf['Age'].dropna().sample(df['Age'].isnull().sum(), random_state = 0)","02d17934":"df[df['Age'].isnull()].index","600bbce1":"def impute_nan(df, variable, median):\n    df[variable+'_median'] = df[variable].fillna(median)\n    df[variable+'_random'] = df[variable]\n    # random sample to fill na\n    random_sample = df[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)\n    # we have random values of count na but we don't have their index to fill na values\n    # pandas need to have same index in order to merge the dataset\n    random_sample.index = df[df[variable].isnull()].index\n    # replace the values\n    df.loc[df[variable].isnull(), variable+'_random'] = random_sample","a62edc6d":"median = df['Age'].median()\nmedian","eb7a4d32":"impute_nan(df, 'Age', median)","35adad2f":"df.head()","608c45bf":"import matplotlib.pyplot as plt\n%matplotlib inline","67b59ead":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde', ax=ax)\ndf.Age_random.plot(kind='kde', ax=ax, color='green')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","e7045313":"fig = plt.figure()\nax = fig.add_subplot(111)\ndf['Age'].plot(kind='kde', ax=ax)\ndf.Age_median.plot(kind='kde', ax=ax, color='red')\ndf.Age_random.plot(kind='kde', ax=ax, color='green')\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","c8780168":"df = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Age','Fare','Survived'])\ndf.head()","60c73e64":"import numpy as np\ndf['Age_Nan'] = np.where(df['Age'].isnull(),1,0)","fc364166":"df.head()","e64eb5f9":"df['Age'].median()","2960eb03":"df['Age'].fillna(df['Age'].median(), inplace=True)","143be6ce":"df.head(10)","630ec764":"df = pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Age','Fare','Survived'])\ndf.head()","67eeca6b":"df['Age'].hist(bins=50)","80b242fe":"extreme = df['Age'].mean()+3*df['Age'].std()","fc5af145":"import seaborn as sns\nsns.boxplot(df['Age'])","e4fc5679":"def impute_nan(df, variable, median, extreme):\n    df[variable+'_end_distribution'] = df[variable].fillna(extreme)\n    df[variable].fillna(median, inplace = True)","4fd8ecd7":"impute_nan(df, 'Age', df['Age'].median(), extreme)","a4913457":"df.head()","bd67330a":"df['Age'].hist(bins=50)","4d84bb30":"df['Age_end_distribution'].hist(bins = 50)","fc0296f2":"sns.boxplot(df['Age_end_distribution'])","f1ee7b53":"df=pd.read_csv('..\/input\/titanic\/train.csv', usecols=['Age','Fare','Survived'])\ndf.head()","5c33e876":"def impute_nan(df, variable):\n    df[variable+'_zero'] = df[variable].fillna(0)\n    df[variable+'_hundred'] = df[variable].fillna(100)","cc92492e":"impute_nan(df, 'Age')","61d3977f":"df['Age_zero'].hist(bins=50)","84d3a698":"df = pd.read_csv('..\/input\/loancsv\/train (1).csv')\ndf.columns","391df2f1":"df = pd.read_csv('..\/input\/loancsv\/train (1).csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])","34c53d51":"df.shape","14f13ad6":"df.head()","1fab9582":"df.isnull().sum()","eed6db1d":"df.isnull().mean().sort_values(ascending = True)","81c6205c":"df['BsmtQual'].value_counts().plot.bar()","e1fc40a6":"df['GarageType'].value_counts().plot.bar()","5ff487f4":"df['FireplaceQu'].value_counts().plot.bar()","bb72fbdd":"df['FireplaceQu'].mode()[0]","99cd2e39":"df['FireplaceQu'].value_counts().index[0]","9ee32cbe":"def impute_nan(df, variable):\n    most_freq_category = df[variable].mode()[0]\n    df[variable].fillna(most_freq_category, inplace=True)","359fea78":"for feature in ['BsmtQual','FireplaceQu','GarageType']:\n    impute_nan(df, feature)","587601f6":"df.head()","bc783622":"df.isnull().sum()","98e565bb":"# df = pd.read_csv('..\/input\/mercedesbenz-greener-manufacturing\/train.csv')\n# df.columns","17c0c292":"df = pd.read_csv('..\/input\/loancsv\/train (1).csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])","1d12e494":"df.head()","44cde29c":"import numpy as np\ndef impute_nan(df, variable, frequent):\n    df[variable+'_new'] = np.where(df[variable].isnull(),1,0)\n    df[variable].fillna(frequent, inplace = True)","d8021ea1":"for feature in ['BsmtQual','FireplaceQu','GarageType']:\n    frequent = df[feature].mode()[0]\n    impute_nan(df, feature, frequent)","19bd4a4b":"df.head()","24b0a92e":"df = pd.read_csv('..\/input\/loancsv\/train (1).csv', usecols=['BsmtQual','FireplaceQu','GarageType','SalePrice'])","bbc8a592":"df.head()","908c1a7a":"def impute_nan(df, variable):\n    df[variable+'_new_var'] = np.where(df[variable].isnull(),'missing',df[variable])","1b93642b":"for feature in ['BsmtQual','FireplaceQu','GarageType']:\n    impute_nan(df, feature)","3277399b":"df.head()","7a5c9490":"df = df.drop(['BsmtQual','FireplaceQu','GarageType'], axis=1)","8dc658fc":"df.head()","f0e0c3e7":"#### Disadvantages","21169e8b":"There are various techniques of feature engineering. Few of them are listed below:\n* Imputation\n* Handling Outliers\n* Binning\n* Log Transform\n* One-Hot Encoding\n* Grouping Operations\n* Scaling","9c51a677":"# Arbitrary value Imputation","5f6c7d04":"#### Disadvantages ","5108870e":"Missing at random (MAR) occurs when the missingness is not random, but where missingness can be fully accounted for by variables where there is complete information. Since MAR is an assumption that is impossible to verify statistically, we must rely on its substantive reasonableness. An example is that males are less likely to fill in a depression survey but this has nothing to do with their level of depression, after accounting for maleness. Depending on the analysis method, these data can still induce parameter bias in analyses due to the contingent emptiness of cells (male, very high depression may have zero entries). However, if the parameter is estimated with Full Information Maximum Likelihood, MAR will provide asymptotically unbiased estimates","3f0fef50":"# Advantages and Disadvantages of End of Distribution Imputation","1d45d674":"* Easy to implement\n* Captures the importance of missingess if there is one","7678bdef":"## Advantages and disadvantages of Random Sample Imputation","97d27ac3":"* Preparing the proper input dataset, compatible with the machine learning algorithm requirements\n* Improving the performance of machine learning models","27be9db3":"## Compute the frequency with every feature","ee3264c6":"Using this code in the final function ","db6487eb":"* Can bring out the importance of missing values","e15babf1":"Let us first understand that why the data is missing from the dataset?\nAssume that the source of data is a survey...Now some people might not be comfortable in sharing their salaries, age, weight, etc.\n\nSince people hesitate to share personal life, they might not answer all the survey questions\n\nThere might also be a case where the person knowing the answer is not in a position to answer your questionnaire. Either they are not alive or have medical issues.\n\nDue to all these reasons the data contains missing values","277bb520":"Random sample imputation consists of taking random observation from the dataset and we use this observation to replace the nan values\n\nWhen should it be used? It assumes that the data are missing completely at random(MCAR)","808ab283":"# Random Sample Imputation ","37a7a617":"* Easy To implement\n* Faster way to implement","b9ffdcd4":"## Advantages of replacing nan with mode ","31721546":"#### Disadvantages ","e6c410ea":"# Missing Completely at Random ","39d0b58c":"Missing Completely at Random, MCAR: A variable is missing completely at random (MCAR) if the probability of being missing is the same for all the observations. When data is MCAR, there is absolutely no relationship between the data missing and any other values, observed or missing, within the dataset. In other words, those missing data points are a random subset of the data. There is nothing systematic going on that makes some data more likely to be missing than other.","73b63aa5":"# Missing Data ","e2ddd1a6":"* Easy to implement\n* Captures the importance of missing values","89472336":"# If you have more frequent categories, we just replace NAN with a new category ","432d5847":"# Handling Categroical Missing Values","91f0bf60":"## Advantages and Disadvantages of Arbitrary value Imputation ","84a6df88":"Understanding the reasons why data are missing is important for handling the remaining data correctly. If values are missing completely at random, the data sample is likely still representative of the population. But if the values are missing systematically, analysis may be biased. For example, in a study of the relation between IQ and income, if participants with an above-average IQ tend to skip the question \u2018What is your salary?\u2019, analyses that do not take into account this missing at random may falsely fail to find a positive association between IQ and salary. Because of these problems, methodologists routinely advise researchers to design studies to minimize the occurrence of missing values.","836e0e8e":"# Adding a variable to capture nan","0d72e164":"#### Disadvantages ","916697ab":"#### Advantages","16eb36b0":"# What is feature Engineering ","f522c4ee":"This technique was derived from kaggle competition It consists of replacing NAN by an arbitrary value. In this technique, all the nan values are replaced by any one value which is decided by the data scientist","dda9b05a":"# Capturing Nan values with a new feature","0f54f6c9":"#### Disadvantages\n\n* Change or Distortion in the original variance\n* Impacts Correlation","8411e437":"# Missing at Random ","8173faee":"Trying to find out the outlier and filling the na values with that outlier","100de35e":"When should we apply? \n\nMean\/median imputation has the assumption that the data are missing completely at random(MCAR). We solve this by replacing the NAN with the most frequent occurance of the variables","f406d65f":"Now let's discuss what are the types of missing data","769ac142":"Men---hide their salary<br>\nWomen---hide their age","f2afd8c9":"# Mean\/Median\/Mode Imputation ","58066891":"### Few techniques of handling missing values","81400f4f":"# Types of missing data ","e26a85cf":"<img src=https:\/\/as2.ftcdn.net\/jpg\/02\/66\/42\/59\/500_F_266425971_tyuVCOtVdfDNSObd2DwcG4TMxKZnHEU1.jpg width=\"400\" height=\"400\">","69b16b89":"#### Advantages ","7dfc34e8":"#### Advantages ","cf4ecd8a":"#### Advantages\n\n* Easy to implement(Robust to outliers)\n* Faster way to obtain the complete dataset","63f09d48":"* Distorts the original distribution of the variable\n* If missingess is not important, it may mask the predictive power of the original variable by distorting its distribution\n* Hard to decide which value to use","ee12d7c3":"# Frequent Category Imputation","7c6b437e":"#### Advantages\n\n* Easy To implement\n* There is less distortion in variance","ff844a47":"# End of Distribution Imputation ","56f0d0d6":"##### Replacing nan with mode ","0ca3285b":"* Creating Additional Features(Curse of Dimensionality)","c1592c95":"Although we have got sample random values but we don't know their index and for that the next code is required","b5d12a4a":"#### Advanatages ","a5283d4a":"It works well if the data are not missing completely at random\n\nCreating a new column, if the value from the 'Age' is missing then enter 1 in new column else enter 0","e2920631":"## Advantages and disadvantages of Capturing Nan values with a new feature","6ce6cf0f":"## Advantages and Disadvantages of Mean\/Median\/Mode imputation ","9bf6ea53":"<img src=\"https:\/\/image.freepik.com\/free-vector\/problem-solving-creative-decision-difficult-task-lateral-thinking-man-assembling-puzzle-cartoon-character-right-choice-missing-item_335657-2108.jpg\" width=\"300\" height=\"300\">","dfb5b3ce":"#### Disadvantages\n\n* Every situation randomness won't work","f4b424fd":"* Since we are using the more frequent labels, it may use them in an over respresented way, if there are many nan's\n* It distorts the relation of the most frequent label","fdde5dab":"* Mean\/Median\/Mode replacement\n* Random Sample Imputation\n* Capturing nan values with new feature\n* End of distribution imputation\n* Arbitrary imputation\n* Frequent category imputation\n* Predicting using linear regression","45402fe9":"* Changes Co-variance\/variance\n* May create biased data"}}