{"cell_type":{"00ae9fd7":"code","82177186":"code","aeff99e5":"code","5d8b4783":"code","567bc9e9":"code","74ced443":"code","e3bc2b63":"code","1cf4ca4d":"code","1f7a063e":"code","ed6ff276":"code","7a020221":"code","27e6274d":"code","7b0ffc04":"code","21c1b7a7":"code","b3d77d89":"code","850e44ab":"code","47ade954":"code","6795e6ab":"markdown","c79283a1":"markdown","88ffd44c":"markdown","4a71cb76":"markdown","2b314056":"markdown"},"source":{"00ae9fd7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\n","82177186":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/lossespy\/Losses.py\", dst = \"..\/working\/Losses.py\")\n\n# import all our functions\nfrom Losses import *","aeff99e5":"splitYear = 2014","5d8b4783":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\nprint('Done!')\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df.shape, news_train_df.shape","567bc9e9":"market_train_df.head()","74ced443":"cat_cols = ['assetCode']\nnum_cols = ['volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1',\n                    'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', 'returnsClosePrevMktres10',\n                    'returnsOpenPrevMktres10']","e3bc2b63":"from sklearn.preprocessing import StandardScaler\n \nmarket_train_df[num_cols] = market_train_df[num_cols].fillna(0)\nprint('scaling numerical columns')\n\nscaler = StandardScaler()\n\n#col_mean = market_train[col].mean()\n#market_train[col].fillna(col_mean, inplace=True)\nscaler = StandardScaler()\nmarket_train_df[num_cols] = scaler.fit_transform(market_train_df[num_cols])\n\n#col_mean = np.mean(market_train_df.returnsOpenPrevMktres10)\n#market_train_df['returnsOpenPrevMktres10'].fillna(col_mean, inplace=True)","1cf4ca4d":"market_train_df['y'] = ((market_train_df.returnsOpenNextMktres10 > 0).values).astype(int)","1f7a063e":"market_train_df['year'] = pd.to_datetime(market_train_df.time).dt.year\ntrain = market_train_df[market_train_df.year <= splitYear]\ntest = market_train_df[market_train_df.year > splitYear]","ed6ff276":"def get_input(market_train, indices):\n    X_num = market_train.loc[indices, num_cols].values\n    X = {'num':X_num}\n    for cat in cat_cols:\n        X[cat] = market_train.loc[indices, cat_cols].values\n    y = (market_train.loc[indices,'returnsOpenNextMktres10'] >= 0).values\n    r = market_train.loc[indices,'returnsOpenNextMktres10'].values\n    u = market_train.loc[indices, 'universe']\n    d = market_train.loc[indices, 'time'].dt.date\n    return X,y,r,u,d\n\n# r, u and d are used to calculate the scoring metric\ntest_indices = np.where(market_train_df.year > splitYear)[0]\ntrain_indices = np.where(market_train_df.year <= splitYear)[0]\nX_train, y_train, r_train, u_train, d_train = get_input(market_train_df, train_indices)\nX_test, y_test, r_test, u_test, d_test = get_input(market_train_df, test_indices)","7a020221":"colsToUse = ['volume',\n'close',\n'open',\n'returnsClosePrevRaw1',\n'returnsOpenPrevRaw1',\n'returnsClosePrevMktres1',\n'returnsOpenPrevMktres1',\n'returnsClosePrevRaw10',\n'returnsOpenPrevRaw10',\n'returnsClosePrevMktres10',\n'returnsOpenPrevMktres10']","27e6274d":"# fit the models\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(C = 1)\nX = train[colsToUse]\nlr.fit(X = X, y = train.y)","7b0ffc04":"# get the test and train predictions\nXtest = test[colsToUse]\nprobs_test = lr.predict_proba(Xtest)[:,1]\nconfidence_test = 2*(probs_test - 0.5)\nplt.hist(confidence_test, bins='auto')\n\nXtrain = train[colsToUse]\nprobs_train = lr.predict_proba(Xtrain)[:,1]\nconfidence_train = 2*(probs_train - 0.5)","21c1b7a7":"def computeSigmaScore(preds, r, u, d):\n    x_t_i = preds * r * u\n    data = {'day' : d, 'x_t_i' : x_t_i}\n    df = pd.DataFrame(data)\n    x_t = df.groupby('day').sum().values.flatten()\n    mean = np.mean(x_t)\n    std = np.std(x_t)\n    score_valid = mean \/ std\n    return(score_valid)","b3d77d89":"def computeCrossEntropyLoss(probs, r, eps = 1e-12):\n    labels = (r >= 0).astype(int)\n    probs_clipped = np.clip(probs, eps, 1.0-eps)\n    return(np.mean(labels*np.log(probs_clipped) + (1-labels)*np.log(1-probs_clipped)))","850e44ab":"[computeSigmaScore(confidence_test, r_test, u_test, d_test), \n computeCrossEntropyLoss(probs_test, r_test)]","47ade954":"[computeSigmaScore(confidence_train, r_train, u_train, d_train), \n computeCrossEntropyLoss(probs_train, r_train)]","6795e6ab":"Pre-processing for all the relevant columns. ","c79283a1":"# Data Management\nread in and explore the data","88ffd44c":"# Logistic regression\nLet's fit an incredibly simple model","4a71cb76":"Mean fill some of the missing values.","2b314056":"Make the outcome binary and split the data between training and test. "}}