{"cell_type":{"b7b5b2e7":"code","ebce8f74":"code","303d5732":"code","54533cee":"code","43d62b08":"code","92ee820c":"code","e3339d7a":"code","b2912706":"code","c141a363":"code","69cbbbd0":"code","166f2a0f":"code","d84a9951":"code","fe4f4970":"code","03aaf2d1":"code","95486125":"code","c8d972a8":"code","ba09b0f8":"code","d340e174":"code","c4c58039":"code","b373e966":"code","0306a79b":"code","8bb8c55f":"code","366286bc":"code","0cbdfbc7":"code","7dfe3a0f":"code","04fd0cc3":"code","fbb95c42":"code","999be22b":"code","ef521cae":"markdown","bf3004a1":"markdown","7856d259":"markdown","f514ca29":"markdown","ab81ed57":"markdown","4056501f":"markdown","cb00eed4":"markdown","dfa31610":"markdown","0e33a862":"markdown","8529f422":"markdown","adb63548":"markdown","d9f5896f":"markdown","b05dcb37":"markdown","25a231f0":"markdown","d00952a5":"markdown","c203b357":"markdown","5e46d3ff":"markdown","d31ba17c":"markdown"},"source":{"b7b5b2e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(\"Setup Complete.\")\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ebce8f74":"import re\nimport string\nimport nltk\nimport matplotlib.pyplot as plt\nplt.rc('figure',figsize=(17,13))\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport plotly.express as ex\nfrom plotly.subplots import make_subplots\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom wordcloud import WordCloud,STOPWORDS, ImageColorGenerator\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(\"Library Setup Complete.\")","303d5732":"# Reading Data\nvaccine_filepath = '..\/input\/all-covid19-vaccines-tweets\/vaccination_all_tweets.csv'\nvaccine_data = pd.read_csv(vaccine_filepath)\nprint(\"Read Complete.\")","54533cee":"# Examining Data\nvaccine_data.head()","43d62b08":"# Examining Data\nvaccine_data.tail()","92ee820c":"# Determining size\nvaccine_data.shape","e3339d7a":"# Examining statistics\nvaccine_data.describe()","b2912706":"# Determining data types\nvaccine_data.dtypes","c141a363":"# Looking for unfilled values\nvaccine_data.isnull().sum()","69cbbbd0":"# Lowercase\nvaccine_data['text'] = vaccine_data['text'].str.lower()\nvaccine_data['text']","166f2a0f":"# URL Removal\nvaccine_data['text'] = vaccine_data['text'].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\nvaccine_data[\"text\"]","d84a9951":"# Punctuation Removal\npunctuation_removal = string.punctuation\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', punctuation_removal))\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(lambda text: remove_punctuation(text))\nvaccine_data[\"text\"]","fe4f4970":"# Single character and double space removal\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\nvaccine_data[\"text\"]","03aaf2d1":"# Stopword Removal\n\", \".join(stopwords.words('english'))\nSTOPWORDS = set(stopwords.words('english'))\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(lambda text: remove_stopwords(text))\nvaccine_data[\"text\"]","95486125":"# Emoji Removal\ndef remove_emoji(string):\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               u\"\\U0001f926-\\U0001f937\"\n                               u\"\\U00010000-\\U0010ffff\"\n                               u\"\\u2640-\\u2642\"\n                               u\"\\u2600-\\u2B55\"\n                               u\"\\u200d\"\n                               u\"\\u23cf\"\n                               u\"\\u23e9\"\n                               u\"\\u231a\"\n                               u\"\\ufe0f\"  # dingbats\n                               u\"\\u3030\"\n                               \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', string)\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(str)\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(remove_emoji)\nvaccine_data[\"text\"]","c8d972a8":"# Single character and double space removal\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\nvaccine_data[\"text\"] = vaccine_data[\"text\"].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\nvaccine_data[\"text\"]","ba09b0f8":"# Most common words\nfrom collections import Counter\ncnt = Counter()\nfor text in vaccine_data[\"text\"].values:\n    for word in text.split():\n        cnt[word] += 1\n        \ncnt.most_common(10)","d340e174":"# Sentiment analysis\nsid = SIA()\nvaccine_data['sentiments'] = vaccine_data[\"text\"].apply(lambda x: sid.polarity_scores(' '.join(re.findall(r'\\w+',str(x).lower()))))\nvaccine_data['Positive Sentiment'] = vaccine_data['sentiments'].apply(lambda x: x['pos']+1*(10**-6)) \nvaccine_data['Neutral Sentiment'] = vaccine_data['sentiments'].apply(lambda x: x['neu']+1*(10**-6))\nvaccine_data['Negative Sentiment'] = vaccine_data['sentiments'].apply(lambda x: x['neg']+1*(10**-6))\nvaccine_data.head()","c4c58039":"#Number of Words\nvaccine_data['Number_Of_Words'] = vaccine_data['text'].apply(lambda x:len(x.split(' ')))\n#Average Word Length\nvaccine_data['Mean_Word_Length'] = vaccine_data['text'].apply(lambda x:np.round(np.mean([len(w) for w in x.split(' ')]),2) )\nvaccine_data.head()","b373e966":"# Tokenization and lemmatization\ndef tokenization(text):\n    text = re.split('\\W+', text)\n    return text\nvaccine_data['tokenized'] = vaccine_data['text'].apply(lambda x: tokenization(x.lower()))\nwn = nltk.WordNetLemmatizer()\ndef lemmatizer(text):\n    text = [wn.lemmatize(word) for word in text]\n    return text\nvaccine_data['lemmatized'] = vaccine_data['tokenized'].apply(lambda x: lemmatizer(x))\nvaccine_data.head()\nvaccine_data.tail()","0306a79b":"# World Cloud\ntweet_All = \" \".join(review for review in vaccine_data[\"text\"])\n\nfig, ax = plt.subplots(1, 1, figsize  = (10,10))\n# Create and generate a word cloud image:\nwordcloud_ALL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_All)\n\n# Display the generated image:\nax.imshow(wordcloud_ALL, interpolation='bilinear')\n\nax.axis('off')","8bb8c55f":"# Sentiment Distribution\nplt.subplot(2,1,1)\nplt.title('Distriubtion Of Sentiments Across Tweets',fontsize=19,fontweight='bold')\nsns.kdeplot(vaccine_data['Negative Sentiment'], color = 'blue')\nsns.kdeplot(vaccine_data['Positive Sentiment'], color = 'orange')\nsns.kdeplot(vaccine_data['Neutral Sentiment'], color = 'green')\nplt.xlabel(' ')\nplt.legend(['Negative Sentiment','Positive Sentiment','Neutral Sentiment'])\nplt.subplot(2,1,2)\nplt.title('Average Sentiments Across Tweets',fontsize=19,fontweight='bold')\nneg_total_avg = (vaccine_data['Negative Sentiment'].sum())\/len(vaccine_data.index)\nprint(neg_total_avg)\npos_total_avg = (vaccine_data['Positive Sentiment'].sum())\/len(vaccine_data.index)\nprint(pos_total_avg)\nneu_total_avg = (vaccine_data['Neutral Sentiment'].sum())\/len(vaccine_data.index)\nprint(neu_total_avg)\nsentiment_type = ['Negative','Positive','Neutral']\nsentiment_total_avg = [neg_total_avg, pos_total_avg, neu_total_avg]\nplt.bar(sentiment_type, sentiment_total_avg, color = ['blue', 'orange', 'green'])\nplt.ylabel('Average Sentiment Per Tweet',fontsize=19)\nplt.xlabel('Sentiment Type',fontsize=19)\nplt.show()","366286bc":"# 50 most common words\nall_words=[]\nfor i in range(len(vaccine_data['lemmatized'])):\n    a=vaccine_data['lemmatized'][i]\n    for i in a:\n        all_words.append(i)\nall_words=pd.Series(np.array(all_words))\n\ncommon_words=all_words.value_counts()[:50].rename_axis('Common Words').reset_index(name='count')\n\nfig = ex.treemap(common_words, path=['Common Words'], values='count',title='50 Most Common Words In Tweets')\nfig.show()","0cbdfbc7":"# Change variables\nft_data = vaccine_data.copy()\nft_data['date'] = pd.to_datetime(vaccine_data['date']).dt.date\nft_data['year'] = pd.DatetimeIndex(ft_data['date']).year\nb_date_count = ft_data.groupby(by='date').count().reset_index()\nb_date_count = b_date_count.rename(columns={'id':'Tweets Per Day'})\nfig = ex.line(b_date_count,x='date',y='Tweets Per Day')\n\nfig.add_shape(type=\"line\",\n    x0=b_date_count['date'].values[0], y0=b_date_count['Negative Sentiment'].mean(), x1=b_date_count['date'].values[-1], y1=b_date_count['Negative Sentiment'].mean(),\n    line=dict(\n        color=\"Red\",\n        width=2,\n        dash=\"dashdot\",\n    ),\n        name='Mean',\n)\n\nfig.update_traces(mode=\"markers+lines\")\nfig.update_layout(hovermode=\"x unified\")\n\n\n# ###annots\nb_date_count.date = pd.to_datetime(b_date_count.date)\nb_date_count_dt = b_date_count.set_index('date')\n\nfig.add_annotation(x=datetime.datetime(2021,3,1), y=b_date_count_dt.loc[pd.Timestamp('2021-03-1'),'year'],\n            text=r\"J&J authorization\",\n            showarrow=True,\n            arrowhead= 3,\n            bordercolor=\"#c7c7c7\")\n\nfig.add_annotation(x=datetime.datetime(2021,4,21), y=b_date_count_dt.loc[pd.Timestamp('2021-04-21'),'year'],\n            text=r\"Fear of supply outstripping demand & CDC discussion of J&J bloodclots\",\n            showarrow=True,\n            arrowhead=3,\n            yshift=5,bordercolor=\"#c7c7c7\")\n\nfig.add_annotation(x=datetime.datetime(2021,6,29), y=b_date_count_dt.loc[pd.Timestamp('2021-06-29'),'year'],\n            text=r\"Discussion of vaccine protection against delta variant\",\n            showarrow=True,\n            arrowhead=3,\n            yshift=5,ay=-30,bordercolor=\"#c7c7c7\")\n\nfig.update_layout(title='<b>Daily Tweets<b>',width=1000)\nfig.show()","7dfe3a0f":"# Assigning sentiment \nPositive_tweet = vaccine_data[vaccine_data['Positive Sentiment'] >= 0.5].reset_index()\nNegative_tweet = vaccine_data[vaccine_data['Negative Sentiment']>= 0.5].reset_index()\nNeutral_tweet = vaccine_data[vaccine_data['Neutral Sentiment']>= 0.5].reset_index()","04fd0cc3":"# 50 most common positive words\n\nall_positive_words=[]\nfor i in range(len(Positive_tweet['lemmatized'])):\n    a=Positive_tweet['lemmatized'][i]\n    for i in a:\n        all_positive_words.append(i)\nall_positive_words=pd.Series(np.array(all_positive_words))\ncommon_words=all_positive_words.value_counts()[:50].rename_axis('Common Positive Words').reset_index(name='count')\nfig = ex.treemap(common_words, path=['Common Positive Words'], values='count',title='50 Most Common Words In Positive Tweets')\nfig.show()\n","fbb95c42":"# 50 most common negative words\n\nall_negative_words=[]\nfor i in range(len(Negative_tweet['lemmatized'])):\n    a=Negative_tweet['lemmatized'][i]\n    for i in a:\n        all_negative_words.append(i)\nall_negative_words=pd.Series(np.array(all_negative_words))\ncommon_words=all_negative_words.value_counts()[:50].rename_axis('Common Negative Words').reset_index(name='count')\nfig = ex.treemap(common_words, path=['Common Negative Words'], values='count',title='50 Most Common Words In Negative Tweets')\nfig.show()","999be22b":"# 50 most common neutral words\n\nall_neutral_words=[]\nfor i in range(len(Neutral_tweet['lemmatized'])):\n    a=Neutral_tweet['lemmatized'][i]\n    for i in a:\n        all_neutral_words.append(i)\nall_neutral_words=pd.Series(np.array(all_neutral_words))\ncommon_words=all_neutral_words.value_counts()[:50].rename_axis('Common Neutral Words').reset_index(name='count')\nfig = ex.treemap(common_words, path=['Common Neutral Words'], values='count',title='50 Most Common Words In Neutral Tweets')\nfig.show()","ef521cae":"![image.png](attachment:fa194c86-466d-428d-ab8a-fd8b642b1141.png)","bf3004a1":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Reading & Examining Data<\/h1>\n\n\n<\/div>","7856d259":"***","f514ca29":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Postive, Negative, & Neutral Analysis<\/h1>\n\n\n<\/div>","ab81ed57":"***","4056501f":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Text Preprocessing<\/h1>\n\n\n<\/div>","cb00eed4":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Feauture Engineering<\/h1>\n\n\n<\/div>","dfa31610":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Overall Analysis<\/h1>\n\n\n<\/div>","0e33a862":"***","8529f422":"***","adb63548":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:110%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">COVID Vaccine Sentiment and Time Series Analysis<\/h1>\n\n<\/div>","d9f5896f":"***","b05dcb37":"***","25a231f0":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Sentiment Analysis<\/h1>\n\n\n<\/div>","d00952a5":"***","c203b357":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Time Series Analysis<\/h1>\n\n\n<\/div>","5e46d3ff":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#3390FF;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Importing Libraries<\/h1>\n\n\n<\/div>","d31ba17c":"***"}}