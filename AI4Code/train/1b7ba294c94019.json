{"cell_type":{"707917ec":"code","e068f3b3":"code","b9096972":"code","f5156948":"code","f28db411":"code","83315c92":"code","f8b1a5ed":"code","17f57088":"code","6121c182":"code","00085a20":"code","b0b82d2d":"code","1d082183":"markdown","3d74f190":"markdown","308d7deb":"markdown","644a667e":"markdown","1bddfb34":"markdown","4aa82028":"markdown","b3e9e472":"markdown","e310b823":"markdown","489f9070":"markdown","326a0bb4":"markdown","e02beaa5":"markdown","23c173cc":"markdown","9a10955d":"markdown","b7081935":"markdown","7f377670":"markdown","e2ab818c":"markdown","eb20d1ab":"markdown","86758e9b":"markdown","b02359d4":"markdown","79658f7c":"markdown"},"source":{"707917ec":"! pip install simpletransformers","e068f3b3":"import pandas as pd\nimport numpy as np\nfrom simpletransformers.ner import NERModel\nimport warnings\nwarnings.filterwarnings('ignore')","b9096972":"train_data = [\n    [0, \"huggingface\", \"B-ORG\", 10, 15, 50, 20, 500, 1000],\n    [0, \"has\" , \"O\", 55, 15, 60, 20, 500, 1000],\n    [0, \"layoutLM\", \"B-MDL\", 65, 15, 80, 20, 500, 1000],\n    [0, \"model\", \"O\", 85, 15, 95, 20, 500, 1000],\n    \n    [1, \"Microsoft\", \"B-ORG\", 10, 2500, 60, 2560, 5000, 9000],\n    [1, \"released\", \"O\", 70, 2500, 120, 2560, 5000, 9000],\n    [1, \"LayoutLM\", \"B-MDL\", 130, 2500, 180, 2560, 5000, 9000],\n    [1, \"in\", \"O\", 190, 2500, 200, 2560, 5000, 9000],\n    [1, \"2020\", \"O\", 210, 2500, 230, 2560, 5000, 9000],\n]\n\ntrain_data = pd.DataFrame(train_data, columns = \n                          [\"sentence_id\", \"words\", \"labels\", \n                           \"x0\", \"y0\", \"x1\", \"y1\", \n                           \"image_width\", \"image_height\"])","f5156948":"## re-scale them if not 1000x1000\ndef scalingto1000(row):\n    return int(1000 * row[0] \/ row[1])\n\ntrain_data.x0 = train_data[['x0', 'image_width']].apply (scalingto1000, axis=1)\ntrain_data.x1 = train_data[['x1', 'image_width']].apply (scalingto1000, axis=1)\ntrain_data.y0 = train_data[['y0', 'image_height']].apply(scalingto1000, axis=1)\ntrain_data.y1 = train_data[['y1', 'image_height']].apply(scalingto1000, axis=1)","f28db411":"train_data.drop([\"image_width\", \"image_height\"], axis=1, inplace = True)","83315c92":"## just for presentation purpose we set evaluation dataset as the same as train set. Wow, too lazy!\neval_data = train_data","f8b1a5ed":"# define the list of tags. \n# Here, we have 3. \"B-ORG\" for organizations, \"B-MDL\" for model names and \"O\" for others.\nlabels = [ \"B-ORG\",\"B-MDL\" ,\"O\"]\n\nmodeltype = 'layoutlm'\n\n# pretrained_model = 'microsoft\/layoutlm-base-uncased'\npretrained_model = 'microsoft\/layoutlmv2-base-uncased'\n# We have several options and you can find other models here: \n# https:\/\/huggingface.co\/models?sort=downloads&search=layout\n\n# do not forget the \"microsoft\" in front of the model name\n\nmodel = NERModel(modeltype, pretrained_model, labels, \n     args={ \"fp16\": False, \n            \"train_batch_size\": 1, ## change the batch size to either 8 or 16 or 32 for real-world cases\n            \"gradient_accumulation_steps\": 1,\n            \"eval_batch_size\": 1, ## change the batch size to either 8 or 16 or 32 for real-world cases\n            \"num_train_epochs\": 10, ## change the number of epochs, based on the usecase between 2, 5\n            \"weight_decay\": 0.7,\n            \"learning_rate\": 5e-5,  ## between 1e-5 and 5e-5 is recommended                                                  \n            \"adam_epsilon\": 1e-8,                                                    \n#            \"output_dir\": '.\/outputs', \n#            \"best_model_dir\": \".\/outputs\/best_model\/\",\n#             \"cache_dir\": \".\/outputs\/cache_dir\/\",\n            \"classification_report\":True,\n            'n_gpu': 1,\n            \"max_seq_length\": 512,\n            'no_save': True,    # set True if you want to save the model to disk\n            'no_cache': True,\n            'overwrite_output_dir': False,                                                      \n            'reprocess_input_data': True,\n            \"save_model_every_epoch\": False,\n            \"evaluate_during_training\": False,\n#             \"evaluate_during_training_steps\": 1000,\n            \"evaluate_during_training_verbose\": False,\n            \"use_cached_eval_features\": False,\n            \"save_eval_checkpoints\": False,\n            \"use_early_stopping\": False,\n            \"early_stopping_patience\": 4,\n            \"early_stopping_metric\": \"eval_loss\",\n            \"early_stopping_metric_minimize\": True,\n            \"manual_seed\": 12345\n          }\n                )\n\n## YES! You can definitely change the args based on your project.","17f57088":"# Train the model\nmodel.train_model(train_data, eval_df = eval_data)","6121c182":"model.eval_model(eval_data)","00085a20":"test_df = eval_data.drop(['labels'], axis=1)\ntest_data = []\nfor i in test_df.sentence_id.unique():\n    test_data.append([\" \".join(test_df.words.loc[test_df.sentence_id ==i].tolist()),\n                      test_df.x0.loc[test_df.sentence_id ==i].tolist(),\n                      test_df.y0.loc[test_df.sentence_id ==i].tolist(),\n                      test_df.x1.loc[test_df.sentence_id ==i].tolist(),\n                      test_df.y1.loc[test_df.sentence_id ==i].tolist()])\n ","b0b82d2d":"model.predict(test_data)","1d082183":"# Introduction","3d74f190":"As mentioned above, it is assumed that you alread convered your document (pdf or image) to a table of words and their coordination using OCR\/tesseract.\n\nNote that LayoutLM model assumes that your document size is 1000x1000. Therefore, you need to rescale the coordinates if your document size is not 1000x1000. \n\nSince the purpose of this kernel is just to show how to setup simpletransformers for LayoutLM, I create a synthetic pandas table with two synthetic docuemnts each has only one sentence (what a lazy!). The documents size is different than 1000x100, so, we must rescale them as well.","308d7deb":"# Load\/Generate Data","644a667e":"The fine-tuned model predicted all the entities correctly (no surprise! the model is over-fitted as planned).","1bddfb34":"Simpletransformers for layoutLM only needs these columns [\"sentence_id\", \"words\", \"labels\", \"x0\", \"y0\", \"x1\", \"y1\"]. Drop the uneccessary columns.","4aa82028":"# Prediction","b3e9e472":"This notebook shows how to use Transformer models (Here is Microsoft [LayoutLM](https:\/\/arxiv.org\/pdf\/1912.13318.pdf) family) easily via [simpletransfomers](https:\/\/pypi.org\/project\/simpletransformers\/) Python package. Thanks to [huggingface](https:\/\/huggingface.co\/) team, it is now easy to load and train different state-of-the-art transformer models where one doesn't need to deal much with pytorch programming, similar to what Keras does with tensorflow. Simpletransformers made it even much easier to create and train such models. What you need to do is to create your training dataset and model configurations. You don't have to take care of loading transformer tokenizers, defining the optimizers, generating the input text files and etc. \n\nLayoutLM model (Pre-trained of Text and Layout for Document Image Understanding) was originally designed and released by Microsoft and today the second version [LayoutLMv2](https:\/\/arxiv.org\/abs\/2012.14740) and [LayoutXLM](https:\/\/arxiv.org\/abs\/2104.08836) version are also available. LayoutLM model is pre-trained to take into acount both textual context as well as the page layout. Although in the original paper, authors discussed the remarkable impact of adding token images embedding to the pre-trained embeddings on various NLP tasks, the available platforms such as huggingface or simpletransformers do not include\/require the image embeddings yet. The authors discussed that adding image embedding adds valuable information on top of the transfomers embedding vectors. These information are not limited to but includes the font size, font style (bold, italic, underlines). If a token appears in bold style and the text in front of it is in regular format, it is more probable that the bold token is a title or an important phrase in the corpus. LayoutLM model does what other regular transfomer models do (such as BERT or RoBerta) but it also takes into account the layout of document. It is a suitable model for forms, tables, and all other docuemnt that is a mix of plain text and tables where the alignment and position of words matters. \n[Huggingface](https:\/\/huggingface.co\/models?sort=downloads&search=layoutlm) has the pre-trained weights in their model repository as well. \n\nOne major step to prepare the input data for LayoutLM model is OCR ([Optical Character Recognition](https:\/\/en.wikipedia.org\/wiki\/Optical_character_recognition)). This notebook does not focus on that part. I assume that you already converted your pdf or images into pandas table using pytesseract or other available tools. You can refer to this [notebook](https:\/\/www.kaggle.com\/jpmiller\/layoutlm-starter) on how to get the pandas table out of pdf. In addition, the referred notebook inspired me and helped me with applying LayoutLM models to my own real-world projects. Thanks [John](https:\/\/www.kaggle.com\/jpmiller).  ","e310b823":"Restart the kernel after installation, if you get error about simpletransformer","489f9070":"Note that the number of epochs is intentionally chosen 10 which is high for fine-tuning. The reason is to make sure that the model has learned from our super small train set and the model setup is correct. We want the model to over-fit and see if it can predict the test set (which is our train set here) correctly. In the real world projects, any number between 2 to 5 is a reasonable choice depending on the usecase, the number of samples and their distribution. ","326a0bb4":"# Model Settings","e02beaa5":"To make prediction, the input must be in this shape [sentence, x0, y0, x1, y1], each term is a list of lists. Sentence is a list of all sentences, x0 is a list of all x0s and so on.","23c173cc":"### If you have reached up to this point, you probably enjoyed it. Please support this notebook by upvoting. Thanks!","9a10955d":"# Training","b7081935":"Let's create input pandas table:","7f377670":"x0 is x coordinate of top left of each word\n\ny0 is y coordinate of top left of each word\n\nx1 is y coordinate of bottom right of each word\n\ny1 is y coordinate of bottom right of each word\n\n(0,0) is the most top left and (1000, 1000) is the most bottom right of your docuemnt.","e2ab818c":"To evaluate your data with eval_data or any new dataset:","eb20d1ab":"# Install\/Import Packages","86758e9b":"Note: The older versions of simpletransfomers do not have layoutlm models. Update your package first with the latest version.","b02359d4":"# Evaluation","79658f7c":"Make prediction:"}}