{"cell_type":{"17b5204d":"code","00f74d4e":"code","5e2f71ea":"code","018cc02e":"code","7c3f9163":"code","8ab54bda":"code","e29551e4":"code","7d7e1e1e":"code","c9fe2f55":"code","957a80d2":"code","7c3bed0b":"code","9d414830":"code","49f6cacb":"code","7464e8d6":"code","387b7003":"code","ed84ea0d":"code","52b0f3be":"code","88bd4e9a":"code","a76aaec9":"code","11418a10":"code","0667c07b":"code","a3213c2f":"code","3f384077":"code","187fcee4":"code","cd0563e3":"code","493d7d4d":"code","922003ce":"code","fb22882a":"code","2f624cf0":"code","0fd72fae":"code","17e12003":"code","dbbb69eb":"markdown","0b59e43e":"markdown","86bc0d0c":"markdown","61b3b65d":"markdown","e5aee376":"markdown","277d611d":"markdown","1b4bb090":"markdown","e88a4144":"markdown","5f975afe":"markdown","124f291a":"markdown","61236c39":"markdown"},"source":{"17b5204d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","00f74d4e":"'''# # Creating Train \/ Val \/ Test folders (One time use)\nimport os\nimport numpy as np\nimport shutil\nimport random\n#root_dir = 'C:\/Users\/Edward Z\/Downloads\/Google-Image-Scraper-master\/RashData\/' # data root path\n#classes_dir = ['LymePositive', 'LymeNegative'] #total labels\n\nval_ratio = 0.2\n#test_ratio = 0.05\n\n#for cls in classes_dir:\n#    print(cls)\n#    os.makedirs(root_dir +'val\/' + cls)\n#src = root_dir + cls # Folder to copy images from\n\nallFileNames = os.listdir(\"C:\/Users\/Edward Z\/Downloads\/Google-Image-Scraper-master\/RashData\/\")\nprint(allFileNames)'''","5e2f71ea":"'''# # Creating Train \/ Val \/ Test folders (One time use)\nimport os\nimport numpy as np\nimport shutil\nimport random\nroot_dir = '..\/kaggle\/input\/lyme-disease-rashes\/RashData\/' # data root path\nclasses_dir = ['LymePositive', 'LymeNegative'] #total labels\n\nval_ratio = 0.2\n#test_ratio = 0.05\n\nfor cls in classes_dir:\n    os.makedirs(root_dir +'train\/' + cls)\n    os.makedirs(root_dir +'val\/' + cls)\n# os.makedirs(root_dir +'test\/' + cls)\n\n\n# Creating partitions of the data after shuffeling\nsrc = root_dir + cls # Folder to copy images from\n\nallFileNames = os.listdir(src)\nnp.random.shuffle(allFileNames)\ntrain_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n                                                          [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), \n                                                           int(len(allFileNames)* (1 - test_ratio))])\n\n\ntrain_FileNames = [src+'\/'+ name for name in train_FileNames.tolist()]\nval_FileNames = [src+'\/' + name for name in val_FileNames.tolist()]\ntest_FileNames = [src+'\/' + name for name in test_FileNames.tolist()]\n\nprint('Total images: ', len(allFileNames))\nprint('Training: ', len(train_FileNames))\nprint('Validation: ', len(val_FileNames))\nprint('Testing: ', len(test_FileNames))\n\n# Copy-pasting images\nfor name in train_FileNames:\n    shutil.copy(name, root_dir +'train\/' + cls)\n\nfor name in val_FileNames:\n    shutil.copy(name, root_dir +'val\/' + cls)\n\nfor name in test_FileNames:\n    shutil.copy(name, root_dir +'test\/' + cls)`'''","018cc02e":"from numpy import asarray\n\nfrom PIL import Image\n# load the image\nimage = Image.open('\/kaggle\/input\/lyme-disease-rashes\/RashData\/Validation\/Validation_2_Cases\/Lyme_Positive\/erythema migrans30.jpg')\n# summarize some details about the image\nprint(image.format)\nprint(image.mode)\nprint(image.size)\n# show the image\nimage.show()\npixels = asarray(image)","7c3f9163":"import matplotlib.pyplot as plt\nfig, (ax0, ax1) = plt.subplots(1, 2)\nax0.imshow(image)\nax0.axis('off')\nax0.set_title('image')\nax1.imshow(pixels)\nax1.axis('off')\nax1.set_title('result')\nplt.show()","8ab54bda":"from skimage import io\n\ndef imshow(image_RGB):\n  io.imshow(image_RGB)\n  io.show()","e29551e4":"from keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.resnet50 import preprocess_input","7d7e1e1e":"TRAIN_DIR = '\/kaggle\/input\/lyme-disease-rashes\/RashData\/Train\/Train_2_Cases'\n\nTEST_DIR = '\/kaggle\/input\/lyme-disease-rashes\/RashData\/Validation\/Validation_2_Cases'","c9fe2f55":"import tensorflow as tf\n\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout\nfrom keras.models import Sequential, Model \nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import TensorBoard\nimport keras\nimport matplotlib.pyplot as plt\n\nHEIGHT = 300\nWIDTH = 300\n\nBATCH_SIZE = 8\nclass_list = [\"class_1\", \"class_2\"]\nFC_LAYERS = [1024, 512, 256]\ndropout = 0.5\nNUM_EPOCHS = 100\nBATCH_SIZE = 8\n","957a80d2":"import tensorflow\nimport keras\ntrain_datagen_resnet = ImageDataGenerator(preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input,\n                                   \n                                   rotation_range = 90,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.1,)\n\ntest_datagen_resnet = ImageDataGenerator(preprocessing_function = tensorflow.keras.applications.resnet50.preprocess_input,\n                                  rotation_range = 90,\n                                  horizontal_flip = True,\n                                  vertical_flip = False)\n\ntrain_datagen_mobilenet = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n                                   \n                                   rotation_range = 90,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.1,)\n\ntest_datagen_mobilenet = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n                                  rotation_range = 90,\n                                  horizontal_flip = True,\n                                  vertical_flip = False)","7c3bed0b":"\n\ntrain_generator_resnet = train_datagen_resnet.flow_from_directory(TRAIN_DIR,\n                                                    target_size = (HEIGHT, WIDTH),\n                                                    batch_size = BATCH_SIZE)\n\ntest_generator_resnet = test_datagen_resnet.flow_from_directory(TEST_DIR,\n                                                  target_size = (HEIGHT, WIDTH),\n                                                  batch_size = BATCH_SIZE)\n\n\ntrain_generator_mobilenet = train_datagen_mobilenet.flow_from_directory(TRAIN_DIR,\n                                                    target_size = (HEIGHT, WIDTH),\n                                                    batch_size = BATCH_SIZE)\n\ntest_generator_mobilenet = test_datagen_mobilenet.flow_from_directory(TEST_DIR,\n                                                  target_size = (HEIGHT, WIDTH),\n                                                  batch_size = BATCH_SIZE)","9d414830":"def build_model(base_model, dropout, fc_layers, num_classes):\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    x = base_model.output\n    x = Flatten()(x)\n    for fc in fc_layers:\n        print(fc)\n        x = Dense(fc, activation='relu')(x)\n        x = Dropout(dropout)(x)\n    preditions = Dense(num_classes, activation='softmax')(x)\n    finetune_model = Model(inputs = base_model.input, outputs = preditions)\n    return finetune_model","49f6cacb":"#from tensorflow.python.keras.applications import MobileNetV2\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nnum_classes = 2\n\nbase_model_2 = (tf.keras.applications.MobileNetV2(weights = 'imagenet',\n                                                 include_top = False,\n                                                 input_shape = (HEIGHT, WIDTH, 3)))\n\n# Say not to train first layer (ResNet) model. It is already trained\n#base_model_2.layers[0].trainable = False\nMobileNet = build_model(base_model_2,\n                                      dropout = dropout,\n                                      fc_layers = FC_LAYERS,\n                                      num_classes = len(class_list))\nadam = Adam(lr = 0.00001)\n\nMobileNet.compile(adam, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nMobileNet.summary()\n","7464e8d6":"'''\nbase_model_1 = ResNet50(weights = 'imagenet',\n                       include_top = False,\n                       input_shape = (HEIGHT, WIDTH, 3))\n\nresnet50_model = build_model(base_model_1,\n                                      dropout = dropout,\n                                      fc_layers = FC_LAYERS,\n                                      num_classes = len(class_list))\n\nadam = Adam(lr = 0.00001)\nresnet50_model.compile(adam, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nfilepath = \".\/checkpoints\" + \"RestNet50\" + \"_model_weights.h5\"\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, monitor = [\"acc\"], verbose= 1, mode = \"max\")\ncb=TensorBoard(log_dir=(\"\/home\/ubuntu\/\"))\ncallbacks_list = [checkpoint, cb]\n\n#print(train_generator.class_indices)\n\nresnet50_model.summary()'''","387b7003":"import matplotlib.pyplot as plt\n%matplotlib inline\nimage_batch,label_batch = train_generator_resnet.next()\n\nprint(len(image_batch))\nfor i in range(0,len(image_batch)):\n    image = image_batch[i]\n    print(label_batch[i])\n    imshow(image)\n'''\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_generator.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")'''","ed84ea0d":"import matplotlib.pyplot as plt\n%matplotlib inline\nimage_batch,label_batch = train_generator_mobilenet.next()\n\nprint(len(image_batch))\nfor i in range(0,len(image_batch)):\n    image = image_batch[i]\n    print(label_batch[i])\n    imshow(image)","52b0f3be":"import tensorflow as tf\n\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') >= 0.93):\n            print(\"\\nReached 99.7% accuracy so cancelling training!\")\n            self.model.stop_training = True\n\n            \n            \nbestLoss = 10\nbestWeights = None\n\ndef storeWeights(e, logs):\n    if logs['val_loss'] < bestLoss:\n        bestLoss = logs['val_loss']\n        bestWeights = model.get_weights()\n            \ncheckpoint_path = 'C:\/Users\/Edward Z\/Downloads\/Google-Image-Scraper-master\/model'\n#early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, mode='max',\n#                                        restore_best_weights=True)\n\nearly = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, mode='max'),\n             tf.keras.callbacks.ModelCheckpoint(filepath='C:\/Users\/Edward Z\/Downloads\/Google-Image-Scraper-master\/model\/lymemodel.h5', monitor='val_accuracy', save_best_only=True)]\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,monitor='val_my_iou_metric',mode='max', patience=10, verbose=1)\n    \n#history = resnet50_model.fit_generator(generator = train_generator, epochs = 150, steps_per_epoch = 20, \n#                                       shuffle = True, validation_data = test_generator, callbacks = [early])\n\n\nhistory = MobileNet.fit_generator(generator = train_generator_mobilenet, epochs = 150, steps_per_epoch = 20, \n                                       shuffle = True, validation_data = test_generator_mobilenet, callbacks = [early])","88bd4e9a":"\nhistory = MobileNet.fit_generator(generator = train_generator_mobilenet, epochs = 150, steps_per_epoch = 20, \n                                       shuffle = True, validation_data = test_generator_mobilenet, callbacks = [early])","a76aaec9":"\nhistory = MobileNet.fit_generator(generator = train_generator_mobilenet, epochs = 150, steps_per_epoch = 20, \n                                       shuffle = True, validation_data = test_generator_mobilenet, callbacks = [early, reduce_lr])","11418a10":"MobileNet.save('LymeMobileModel.h5')\n","0667c07b":"#history = resnet50_model.fit_generator(generator = train_generator, epochs = 150, steps_per_epoch = 20, \n     #                                  shuffle = True, validation_data = test_generator, callbacks = [early])","a3213c2f":"#history = resnet50_model.fit_generator(generator = train_generator, epochs = 150, steps_per_epoch = 20, #\n    #                                   shuffle = True, validation_data = test_generator, callbacks = [early])","3f384077":"#history = resnet50_model.fit_generator(generator = train_generator, epochs = 150, steps_per_epoch = 20, #\n   #                                    shuffle = True, validation_data = test_generator)","187fcee4":"#resnet50_model.save('LymeModel.h5')\n\n#resnet50_model.save_weights('C:\\Kaggle\\Lymemodel.h5')\n#model.save_weights('my_model_weights.h5')\n\n\n\n\n\n\n","cd0563e3":"'''acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs_range = range(50)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()'''","493d7d4d":"#from tensorflow.keras.applications.inception_v3 import InceptionV3#\n#from tensorflow.keras.optimizers import RMSprop","922003ce":"#base_model_2 = InceptionV3(weights = 'imagenet',#\n #                      include_top = False,\n #                      input_shape = (HEIGHT, WIDTH, 3))","fb22882a":"'''\ninception_model = build_model(base_model_2,\n                                      dropout = dropout,\n                                      fc_layers = FC_LAYERS,\n                                      num_classes = len(class_list))\ninception_model.compile(optimizer = RMSprop(lr = 0.00001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\ninception_model.summary()'''","2f624cf0":"'''\nhistory_2 = inception_model.fit_generator(generator = train_generator, epochs = 20, steps_per_epoch = 20, \n                                       shuffle = True, validation_data = test_generator)'''","0fd72fae":"#import tensorflow as tf\n#new_model = tf.keras.models.load_model('\/kaggle\/input\/lyme-model\/LymeModel.h5')\n","17e12003":"#import tensorflow as tf\n#converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n#converter.post_training_quantize = True\n\n#tflite_model = converter.convert()\n## Save the model.\n#with open('Lymemodel.tflite', 'wb') as f:\n#  f.write(tflite_model)\n\n","dbbb69eb":"If you enjoyed this notebook, please also check out the first Lyme Disease EM rash Dataset, which I webscraped myself.\n\nhttps:\/\/www.kaggle.com\/sshikamaru\/lyme-disease-rashes","0b59e43e":"# **Preprocessing**","86bc0d0c":"Background:\n\nLyme Diease also known as the \"Silent Epidemic\" is very much malfunded and it affects more than 300,000 people each year.\n\nLyme disease is caused by the bacterium Borrelia burgdorferi and rarely, Borrelia mayonii. It is transmitted to humans through the bite of infected blacklegged ticks. Typical symptoms include fever, headache, fatigue, and a characteristic skin rash called erythema migrans.\n\n**This is the FIRST Kaggle notebook with a Lyme Disease model.**","61b3b65d":"**Basic Imports**","e5aee376":"# **Introduction**\n","277d611d":"# **Modeling**","1b4bb090":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/01\/Erythema_migrans_-_erythematous_rash_in_Lyme_disease_-_PHIL_9875.jpg\/310px-Erythema_migrans_-_erythematous_rash_in_Lyme_disease_-_PHIL_9875.jpg)","e88a4144":"# **RESNET 50**","5f975afe":"# **MOBILE NET v2**","124f291a":"# **INCEPTION v3**","61236c39":"![](http:\/\/https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/01\/Erythema_migrans_-_erythematous_rash_in_Lyme_disease_-_PHIL_9875.jpg\/310px-Erythema_migrans_-_erythematous_rash_in_Lyme_disease_-_PHIL_9875.jpg)"}}