{"cell_type":{"fcc5edb6":"code","59e007ef":"code","982912ce":"code","23ecc2d9":"code","b2fa54b7":"code","fc9fd093":"code","68a2551d":"code","66d8d7d6":"code","6aeb6d6e":"code","9931d551":"code","bbc59a56":"code","6b97277a":"code","442d4efd":"code","11d892f6":"code","85c5c696":"code","08cf8074":"code","d90d8317":"code","bbc42729":"code","6cc6fff3":"code","71a5d1cf":"code","48be8e56":"code","7b81ff5d":"code","798a38d9":"code","6bd4b9d1":"code","00f912fc":"code","5ae15307":"code","dc8320ac":"code","7dce8f60":"code","42f4c9ae":"code","75ea579c":"code","b3866d14":"code","3c5d345a":"code","14951ed3":"code","b797f14b":"code","1372b432":"code","0a354397":"code","31f9dac3":"code","f903b0ff":"code","f296daee":"code","24de0f51":"code","68dbddf0":"code","fba0c506":"code","8ef7c3be":"code","5cc6a5ef":"code","4bc738f0":"code","b634efe2":"code","c6ee0195":"code","199b06c1":"code","c6ed7dc5":"code","a2d33256":"code","bf1f0d61":"code","b1002f43":"code","3394268c":"code","0826a982":"code","7a0649c8":"code","7f09f54c":"markdown","2a009110":"markdown","da73d483":"markdown","e59e9f66":"markdown","1078fd0b":"markdown","154f70b2":"markdown","97ec386f":"markdown","0bfe2013":"markdown","f1867a6d":"markdown","0c2774c9":"markdown","bb382173":"markdown","784badbe":"markdown","3a995285":"markdown","5f00b73e":"markdown","6ddba35f":"markdown","22aa5f2e":"markdown","56938689":"markdown","09c3a202":"markdown","f30c42b9":"markdown","5fe92915":"markdown","ffea9e0c":"markdown","33a5afad":"markdown","c67348b1":"markdown","288fb93f":"markdown","ed74e75a":"markdown","a139ddfb":"markdown"},"source":{"fcc5edb6":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression","59e007ef":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","982912ce":"train","23ecc2d9":"test","b2fa54b7":"print('Train')\ndisplay(train.nunique())\n\nprint('Test')\ndisplay(test.nunique())","fc9fd093":"print('Train')\ndtypes = train.dtypes\ndisplay(dtypes)\n\nprint('Test')\ndtypes = test.dtypes\ndisplay(dtypes)","68a2551d":"print('Train')\ndisplay(train.isnull().sum())\n\nprint('Test')\ndisplay(test.isnull().sum())","66d8d7d6":"fig, ax  = plt.subplots(2, 3, figsize = (20, 20))\n\nsurvived_plot = sns.histplot(\n    data = train,\n    x = 'Survived',\n    ax = ax[0, 0]\n)\n\ng0 = sns.histplot(\n    data = train,\n    x = 'Pclass',\n    ax = ax[0, 1]\n)\n\ngender_plot = sns.histplot(\n    data = train,\n    x = 'Sex',\n    ax = ax[0, 2]\n)\n\nage_plot = sns.histplot(\n    data = train,\n    x = 'Age',\n    ax = ax[1, 0]\n)\n\n\nsbspo_plot = sns.histplot(\n    data = train,\n    x = 'SibSp',\n    ax = ax[1, 1]\n)\n\n\nparch_plot = sns.histplot(\n    data = train,\n    x = 'Parch',\n    ax = ax[1, 2]\n)\n\nplt.show()","6aeb6d6e":"g0 = sns.displot(\n    data = train,\n    x = 'Sex',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)\n\ng1 = sns.displot(\n    data = train,\n    x = 'Age',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)\n\ng2 = sns.displot(\n    data = train,\n    x = 'Pclass',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)\n\ng3 = sns.displot(\n    data = train,\n    x = 'Survived',\n    hue = 'Embarked',\n    multiple='dodge',\n)\n\ng4 = sns.displot(\n    data = train,\n    x = 'Parch',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)","9931d551":"g0 = sns.displot(\n    data = train,\n    x = 'Sex',\n    col = 'Embarked',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)\n\ng1 = sns.displot(\n    data = train,\n    x = 'Age',\n    col = 'Sex',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)\n\ng1 = sns.displot(\n    data = train,\n    x = 'Fare',\n    row = 'Pclass',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green'],\n    height=10,\n    aspect = 5\n)","bbc59a56":"g0 = sns.displot(\n    data = train,\n    x = 'Age',\n    col = 'Sex',\n    row = 'Pclass',\n    hue = 'Embarked',\n    multiple='dodge'\n)\n\ng1 = sns.displot(\n    data = train,\n    x = 'Age',\n    col = 'Sex',\n    row = 'Pclass',\n    hue = 'Survived',\n    multiple='dodge',\n    palette=['red', 'green']\n)","6b97277a":"train = train.drop('Ticket', axis = 1)\ntest = test.drop('Ticket', axis = 1)","442d4efd":"# Count different values\ntrain['Cabin'].value_counts()","11d892f6":"train['Cabin'] = train['Cabin'].str[0]\ntrain","85c5c696":"# Count different values\ntrain['Cabin'].value_counts()","08cf8074":"sns.displot(\n    data=train,\n    x='Pclass',\n    col='Cabin',\n    hue='Survived',\n    multiple='dodge',\n    palette=['red', 'green'],\n    height=30, \n    aspect=0.2\n)\n\nsns.displot(\n    data=train,\n    x='Survived',\n    col='Cabin',\n    hue='Embarked',\n    multiple='dodge',\n    height=30, \n    aspect=0.2\n)\n\nsns.set(font_scale=3)","d90d8317":"train = train.drop('Cabin', axis = 1)\ntest = test.drop('Cabin', axis = 1)\n","bbc42729":"train[train['Embarked'].isnull()]","6cc6fff3":"train['Embarked'] = train['Embarked'].fillna('C')","71a5d1cf":"# Look at this fellow\ntest[test['Fare'].isnull()]","48be8e56":"test['Fare'] = train['Fare'].fillna(train[train['Pclass'] == 3]['Fare'].mean())","7b81ff5d":"test[test['PassengerId'] == 1044]","798a38d9":"train","6bd4b9d1":"train_copy = train.dropna()\n\nX = train_copy.drop('Age', axis=1).iloc[:, 1:]\nX = X.drop('Name', axis=1)\nX = X.drop('Survived', axis=1)\nX = X.dropna()\nX = pd.get_dummies(X, columns=['Sex'])\nX = pd.get_dummies(X, columns=['Embarked'])\nX = pd.get_dummies(X, columns=['Pclass'])\nX[['Fare']] = StandardScaler().fit_transform(X[['Fare']])\n\ny = train_copy.iloc[:, 5].values\n\nX = X.values\n\ndisplay(X)\ndisplay(y)","00f912fc":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30, random_state=0)","5ae15307":"X_train","dc8320ac":"X_test","7dce8f60":"classifier = KNeighborsRegressor(n_neighbors=5)\nclassifier.fit(X_train, y_train)","42f4c9ae":"y_pred = classifier.predict(X_test)","75ea579c":"print(y_pred)\nprint(y_test)","b3866d14":"mse = np.sqrt(((y_pred - y_test)**2)).mean()\nprint('Error: ', mse, 'Years')","3c5d345a":"train","14951ed3":"train_copy = train.copy()\n\ntrain_copy = train_copy[train_copy['Age'].isnull()]\ntrain_copy = train_copy.drop('Age', axis=1).iloc[:, 1:]\ntrain_copy = train_copy.drop('Name', axis=1)\ntrain_copy = train_copy.drop('Survived', axis=1)\ntrain_copy = pd.get_dummies(train_copy, columns=['Sex'])\ntrain_copy = pd.get_dummies(train_copy, columns=['Embarked'])\ntrain_copy = pd.get_dummies(train_copy, columns=['Pclass'])\ntrain_copy[['Fare']] = StandardScaler().fit_transform(train_copy[['Fare']])\n\ny = train_copy.iloc[:, 5].values\n\ntrain_copy = train_copy.values","b797f14b":"display(train_copy)\ndisplay(y)","1372b432":"nans_pred = classifier.predict(train_copy)","0a354397":"print(nans_pred)","31f9dac3":"train","f903b0ff":"m = train['Age'].isna()\ntrain.loc[m, 'Age'] = nans_pred","f296daee":"train","24de0f51":"test_copy = test.copy()\n\ntest_copy = test_copy[test_copy['Age'].isnull()]\ntest_copy = test_copy.drop('Age', axis=1).iloc[:, 1:]\ntest_copy = test_copy.drop('Name', axis=1)\ntest_copy = pd.get_dummies(test_copy, columns=['Sex'])\ntest_copy = pd.get_dummies(test_copy, columns=['Embarked'])\ntest_copy = pd.get_dummies(test_copy, columns=['Pclass'])\ntest_copy[['Fare']] = StandardScaler().fit_transform(test_copy[['Fare']])\n\ny = test_copy.iloc[:, 5].values\n\ntest_copy = test_copy.values","68dbddf0":"nans_pred_test = classifier.predict(test_copy)","fba0c506":"len(nans_pred_test)","8ef7c3be":"m = test['Age'].isna()\ntest.loc[m, 'Age'] = nans_pred_test","5cc6a5ef":"train","4bc738f0":"X = train.iloc[:, 1:]\nX = X.drop('Name', axis=1)\nX = X.drop('Survived', axis=1)\nX = pd.get_dummies(X, columns=['Sex'])\nX = pd.get_dummies(X, columns=['Embarked'])\nX = pd.get_dummies(X, columns=['Pclass'])\nX[['Fare']] = StandardScaler().fit_transform(X[['Fare']])\n\ny = train.iloc[:, 1].values\n\ndisplay(X)\n\nX = X.values\n\ndisplay(X)\ndisplay(y)","b634efe2":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30, random_state=0)","c6ee0195":"rf_classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\nrf_classifier.fit(X_train, y_train)","199b06c1":"y_pred = rf_classifier.predict(X_test)","c6ed7dc5":"cm = confusion_matrix(y_test, y_pred)\nprint('Confussion matrix:\\n', cm)\nprint('Accuracy: %.2f' % accuracy_score(y_test, y_pred))","a2d33256":"test","bf1f0d61":"test_copy = test.copy()\n\ntest_copy = test_copy.iloc[:, 1:]\ntest_copy = test_copy.drop('Name', axis=1)\ntest_copy = pd.get_dummies(test_copy, columns=['Sex'])\ntest_copy = pd.get_dummies(test_copy, columns=['Embarked'])\ntest_copy = pd.get_dummies(test_copy, columns=['Pclass'])\ntest_copy[['Fare']] = StandardScaler().fit_transform(test_copy[['Fare']])\n\ntest_copy = test_copy.values\n\ndisplay(test_copy)","b1002f43":"final_pred = rf_classifier.predict(test_copy)","3394268c":"test","0826a982":"submission = test['PassengerId'].to_frame()\nsubmission['Survived'] = final_pred","7a0649c8":"submission.to_csv('submission_titanic.csv', index = False)","7f09f54c":"### Two people not embarking?\n\nWe got two missing values for embarking column. Let's look at them","2a009110":"## Prediction over test.csv","da73d483":"## Data visualization","e59e9f66":"# <center> Titanic Survivors <center>\n---","1078fd0b":"## Basic information","154f70b2":"Unique values","97ec386f":"#### Applying regressor over train set","0bfe2013":"## Data processing","f1867a6d":"### Dealing with NaNs\n\n- Cabing: we'll explore this column to chosee between predict or delete the column\n- Embarked: predict embarked over other columns\n- Fare: predict fare over other columns\n- Age: predict ages based on other columns","0c2774c9":"Eliminate the number. Let's play with letters","bb382173":"It seem like there's no significant correlation between any columns and, indeed, we don't have enough data about the cabin values. Let's drop that column","784badbe":"#### Same over test set","3a995285":"### Missing cabins...","5f00b73e":"He is in class 3 so make him pay the mean of class 3 fares","6ddba35f":"## Predictions","22aa5f2e":"Fill the original train dataframe with these values","56938689":"#### Create submission","09c3a202":"### KNN Model to predict ages","f30c42b9":"The previous visualization told us that most females from class 1 embarked throug 'C' so:","5fe92915":"### Someone didn't paid in the test set","ffea9e0c":"Mean square root error","33a5afad":"That's all... for now.","c67348b1":"Types","288fb93f":"### Tickets\n\nThe ticket is correlated with Pclass and Embarked port. We got too many unique values and it doesn't give us more information about survival of the passenger. Drop it","ed74e75a":"NaN values","a139ddfb":"#### Cabin visualization"}}