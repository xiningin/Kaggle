{"cell_type":{"bbf3aa64":"code","5accaeb2":"code","81c31d0f":"code","d04fc92a":"code","fd182e0f":"code","60f14030":"code","858e9d6c":"code","3c186beb":"code","b58deea4":"code","c494f979":"code","45a6d070":"code","7eb79e4b":"code","7f6618bf":"code","d37743e2":"code","b691d33b":"code","61609222":"code","ff37c4ce":"markdown"},"source":{"bbf3aa64":"import os\nimport numpy as np  \nimport datetime\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import  Flatten, Dense, Dropout\nfrom tensorflow.keras import Model\nimport matplotlib.pyplot as plt","5accaeb2":"# -- Global Variables -- \nTRAIN_PATH = '\/kaggle\/input\/walk-or-run\/walk_or_run_train\/train'\nTEST_PATH = '\/kaggle\/input\/walk-or-run\/walk_or_run_test\/test'\nBATCH_SIZE = 32\nCOLOR_MODE = 'rgb'\nTARGET_SIZE = (224, 224)\nGRAY_SCALL = (3,)\nINPUT_SIZE = TARGET_SIZE + GRAY_SCALL\nEPOCHS = 10\nCLASSES = ['Run','Walk']","81c31d0f":"# -- Data Normalization --\ndata_generator = tf.keras.preprocessing.image.ImageDataGenerator(samplewise_center=True, #making sure that each image has a mean of 0 \n                                                                 samplewise_std_normalization=True, #and standard deviation 1\n                                                                 horizontal_flip=True, #Randomly flip inputs horizontally\n                                                                 validation_split=0.3)","d04fc92a":"# -- Data iterators -- \ntrain_data = data_generator.flow_from_directory(directory=TRAIN_PATH, \n                                                    target_size=TARGET_SIZE, \n                                                    batch_size=BATCH_SIZE, \n                                                    class_mode='categorical', \n                                                    color_mode=COLOR_MODE, \n                                                    subset='training')         \n    \nvalidation_data = data_generator.flow_from_directory(directory=TRAIN_PATH, \n                                                    target_size=TARGET_SIZE, \n                                                    batch_size=BATCH_SIZE, \n                                                    class_mode='categorical', \n                                                    color_mode=COLOR_MODE, \n                                                    subset='validation')             \n\ntest_data = data_generator.flow_from_directory(directory=TEST_PATH, \n                                                   target_size=TARGET_SIZE, \n                                                   batch_size=BATCH_SIZE, \n                                                   class_mode='categorical', \n                                                   color_mode=COLOR_MODE)","fd182e0f":"# -- plot random batch -- \nimages, labels = train_data.next()\nclasses = np.asarray(CLASSES)\n\n_, axs = plt.subplots(4, 8, figsize=(12, 12))\naxs = axs.flatten()\n\nfor img, l, ax in zip(images, labels, axs):\n    ax.imshow(img)\n    ax.axis('off')\n    l = l.astype(int)\n    ax.set_title(classes[l == 1])\n\nplt.show()","60f14030":"# -- Define model -- \n# since we have a small amount of data I'll use the trained weights of VGG16, \n# but I will change the last few layers, and train them.\n\ndef my_model():\n    #Load vgg16 model without classifier layers\n    vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SIZE)\n\n    #Freeze the convolutional base\n    vgg16_model.trainable = False\n    \n    #Add new classifier layers\n    flatten = Flatten()(vgg16_model.layers[-1].output)\n    fc1 = Dense(units=4096, activation='relu')(flatten)\n    dropout = Dropout(0.2)(fc1) \n    fc2 = Dense(units=1024,activation='relu')(dropout)\n    output = Dense(2, activation='softmax')(fc2)\n   \n    #Define a new modol\n    model = Model(inputs = vgg16_model.input, outputs=output)\n    \n    #Model summary\n    model.summary()\n    \n    return model","858e9d6c":"model = my_model()","3c186beb":"# -- Define optimizer and loss --\nopt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\nloss = tf.keras.losses.CategoricalCrossentropy()","b58deea4":"# -- Compile model --\nmodel.compile(optimizer=opt, loss=loss, metrics=['accuracy'])","c494f979":" # -- Callbacks --\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5', \n                                                    monitor='accuracy', verbose=1, \n                                                    save_best_only=True, \n                                                    save_weights_only=False, \n                                                    mode='auto', \n                                                    save_freq='epoch')\n    \nearlystoping = tf.keras.callbacks.EarlyStopping(monitor='accuracy', \n                                                    min_delta=0, \n                                                    patience=5,  #Number of epochs with no improvement after which training will be stopped.\n                                                    verbose=1, \n                                                    mode='auto')\n    \nlog_dir = '.\/logs\/fit\/' + datetime.datetime.now().strftime('%m.%d.%Y--%H-%M-%S')\ntensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n                                                 histogram_freq=1, \n                                                 write_graph=True,\n                                                 write_images=False, \n                                                 update_freq='epoch')","45a6d070":"# -- Train model --\nhistory = model.fit(x=train_data, \n                        epochs=EPOCHS, \n                        steps_per_epoch=len(train_data), \n                        verbose=1, \n                        validation_data=validation_data, \n                        validation_steps=1, \n                        callbacks=[checkpoint, earlystoping, tensorboard])\n    \n# -- Save model -- \nmodel.save('my_model.h5')","7eb79e4b":"def learning_curves(history):\n    '''plot learning curves'''\n    \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    \n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    plt.figure(figsize=(10, 8))\n    \n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy')\n    \n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.ylabel('Loss - Cross Entropy')\n    plt.xlabel('epoch')\n    plt.ylim([0,1.6])\n    plt.title('Training and Validation Loss')\n    \n    plt.show()","7f6618bf":"# -- Plot learning curves -- \nlearning_curves(history)","d37743e2":"# -- Evaluate the model on the test data -- \nloss, accuracy = model.evaluate(x=test_data)\nprint(\"test loss: \", loss, \", test acc: \" , 100*accuracy, \"%\")","b691d33b":"def run_or_walk(img_path):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224,224,3))\n    img = np.asarray(img)\n    img = np.expand_dims(img, axis=0)\n    model = tf.keras.models.load_model('my_model.h5')\n    output = model.predict(img)\n    print(classes[output[0]==1])","61609222":"run_or_walk(TEST_PATH + '\/run\/run_82ee1773.png')","ff37c4ce":"# **Run Or Walk - VGG16 Transfer Learning** "}}