{"cell_type":{"61612b95":"code","95e12671":"code","4f2114df":"code","0010a93f":"code","f7d30ecd":"code","0c6552a8":"code","7d783b0f":"code","4fe2a011":"code","533863c5":"code","f7f3baaf":"code","23b11756":"code","b3cbd455":"code","e54d17b2":"code","eaf66cdf":"code","e1749aa9":"code","2f615890":"code","47d6a70e":"code","30b8d8ea":"code","dfd51999":"markdown","ada81b98":"markdown","53db6b1a":"markdown","961a0f44":"markdown","624ee6f1":"markdown","84a31fcc":"markdown","5fef2b54":"markdown","1e74154c":"markdown","85187e75":"markdown","ffb3d862":"markdown","dbf64d1c":"markdown","bba405ce":"markdown","a0e60922":"markdown","fe0569ad":"markdown","43af642b":"markdown","23669043":"markdown"},"source":{"61612b95":"%%time\nimport sys\n!cp ..\/input\/rapids\/rapids.0.15.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","95e12671":"import cudf, cuml\nimport pandas as pd, numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom cuml.neighbors import KNeighborsClassifier, NearestNeighbors\nprint('cuML version',cuml.__version__)","4f2114df":"IMAGE_PATH = '..\/\/input\/\/chinese-mnist\/\/data\/\/data\/\/'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\nIMAGE_CHANNELS = 1\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2","0010a93f":"import os\nos.listdir(\"..\/\/input\/\/chinese-mnist\")","f7d30ecd":"data_df=pd.read_csv('..\/\/input\/\/chinese-mnist\/\/chinese_mnist.csv')","0c6552a8":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","7d783b0f":"def create_file_name(x):\n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","4fe2a011":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)","533863c5":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","f7f3baaf":"print(f\"Number of suites: {data_df.suite_id.nunique()}\")\nprint(f\"Samples: {data_df.sample_id.unique()}\")","23b11756":"train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=42, stratify=data_df[\"code\"].values)","b3cbd455":"print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))","e54d17b2":"import cv2\ndef read_image(file_name):\n    image_data = cv2.imread(IMAGE_PATH + file_name, cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image_data, (IMAGE_WIDTH * IMAGE_HEIGHT, 1))\n\n    return image[0,:]","eaf66cdf":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(train_df['character'])\nprint(le.classes_)","e1749aa9":"def prepare_data(dataset,label_encoding=le):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = label_encoding.transform(dataset['character'])\n    return X, y","2f615890":"X_train, y_train = prepare_data(train_df)\nX_test, y_test = prepare_data(test_df)","47d6a70e":"for k in range(1,16):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_hat_p = knn.predict_proba(X_test)\n    y_tr_hat_p = knn.predict_proba(X_train)\n    y_pred = pd.DataFrame(y_hat_p).values.argmax(axis=1)\n    y_tr_pred = pd.DataFrame(y_tr_hat_p).values.argmax(axis=1)\n    acc = (y_pred==y_test).sum()\/y_test.shape[0]\n    acc_tr = (y_tr_pred==y_train).sum()\/y_train.shape[0]\n    print(f\"k: {k} accuracy(train): {round(acc_tr,3)} accuracy(test): {round(acc,3)} \")","30b8d8ea":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred, target_names=le.classes_))","dfd51999":"## <a id='40'>Split the data<\/a>  \n\nFirst, we split the whole dataset in train and test. We will use **random_state** to ensure reproductibility of results. We also use **stratify** to ensure balanced train\/validation\/test sets with respect of the labels. \n\nThe train-test split is **80%** for training set and **20%** for test set.\n","ada81b98":"## <a id='41'>Build the model<\/a>    \n\n\nNext step in our creation of a predictive model.  \n\nLet's define few auxiliary functions that we will need for creation of our models.\n\n* A function for reading images from the image files; resize them to prepare for KNN\n* A function to prepare the data: call the read\/resize image function + label encoding","53db6b1a":"Now we are ready to start experiment with the KNN model.","961a0f44":"Let's also check the image sizes.","624ee6f1":"Next, we will split further the **train** set in **train** and **validation**. We want to use as well a validation set to be able to measure not only how well fits the model the train data during training (or how well `learns` the training data) but also how well the model is able to generalize so that we are able to understands not only the bias but also the variance of the model.  \n\nThe train-validation split is **80%** for training set and **20%** for validation set.","84a31fcc":"# <a id='1'>Introduction<\/a>  \n\n\nWe will use RAPIDS to solve Chinese MNIST problem.\n\nFor more details about the problem, you can check this Notebook: [Tensorflow\/Keras\/GPU for Chinese MNIST Prediction](https:\/\/www.kaggle.com\/gpreda\/tensorflow-keras-gpu-for-chinese-mnist-prediction)\n\n\nWe will follow the preparation steps in the model Notebook, changing the solution approach, to use KNN & RAPIDS, as shown in Chris Deotte Notebook: \n[RAPIDS GPU kNN - MNIST - [0.97]](https:\/\/www.kaggle.com\/cdeotte\/rapids-gpu-knn-mnist-0-97\/data).\n\nNote: I updated the installation steps for RAPIDS using inspiration from this Notebook: [\ud83d\udc68\u200d\ud83c\udf93Answer Correctness - RAPIDS crazy fast](https:\/\/www.kaggle.com\/andradaolteanu\/answer-correctness-rapids-crazy-fast)\n\n<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  ","5fef2b54":"Let's check the shape of the three datasets.","1e74154c":"# <a id='21'>Install RAPIDS & load packages<\/a>\n\n\n","85187e75":"We are now ready to start building our first model.","ffb3d862":"<a href=\"#0\"><font size=\"1\">Go to top<\/font><\/a>  \n\n\n# <a id='22'>Load the data<\/a>  \n\nLet's see first what data files do we have in the root directory.","dbf64d1c":"We load the packages used for the analysis.","bba405ce":"<h1><center><font size=\"6\">Tensorflow\/Keras\/GPU for Chinese MNIST Prediction<\/font><\/center><\/h1>\n\n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Prepare the analysis<\/a>   \n- <a href='#4'>Characters classification<\/a>       \n- <a href='#5'>Conclusions<\/a>       \n","a0e60922":"There is a dataset file and a folder with images.  \n\nLet's load the dataset file first.","fe0569ad":"We also set a number of parameters for the data and model.","43af642b":"# <a id='2'>Prepare the analysis<\/a>   \n\n\nBefore starting the analysis, we need to make few preparation: install RAPIDS from the dataset, load the packages, load and inspect the data.\n\n","23669043":"# <a id='4'>Characters classification<\/a>\n\nOur objective is to use the images that we investigated until now to correctly identify the Chinese numbers (characters).   \n\nWe have a unique dataset and we will have to split this dataset in **train** and **test**. The **train** set will be used for training a model and the test will be used for testing the model accuracy against new, fresh data, not used in training.\n\n"}}