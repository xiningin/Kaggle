{"cell_type":{"49a55cdd":"code","a0e970f3":"code","8d5108a2":"code","0d8c8049":"code","58f208b3":"code","c23d3b00":"code","829483b1":"code","63e2f4ec":"code","821217e4":"code","b90c6a49":"code","3bc24bde":"code","32b191c1":"code","6efdeb93":"code","2ab07e01":"markdown","4ec2219e":"markdown"},"source":{"49a55cdd":"import nltk\n\nimport numpy as np \nimport pandas as pd\n\nimport sklearn \nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier","a0e970f3":"from sklearn.pipeline import FeatureUnion\nfrom sklearn.base import BaseEstimator, TransformerMixin \n# The pipeline for preparing the dataframe\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Additional characteristic standardization\nfrom sklearn.preprocessing import StandardScaler\n\nclass TextSelector(BaseEstimator, TransformerMixin):\n    # A function that selects each text attribute of a dataset for additional transformations\n    \n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X):\n        return X[self.key]\n    \nclass NumberSelector(BaseEstimator, TransformerMixin):\n    # A function that selects each numeric attribute of a dataset for additional transformations\n       \n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y = None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]","8d5108a2":"df = pd.read_csv('..\/input\/pipelineauthoridentification\/pipeline-author-identification.csv')\n\ndf.dropna(axis = 0)\n\ndf.set_index('id', inplace = True)\ndf.head()","0d8c8049":"features = [c for c in df.columns.values if c  not in ['id', 'text', 'author']]\nnumeric_features = [c for c in df.columns.values if c  not in ['id', 'text', 'author', 'processed']]\n\ntarget = 'author'\n\nX_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size = 0.33, random_state = 42)\nX_train.head()","58f208b3":"text = Pipeline([\n                ('selector', TextSelector(key = 'processed')),\n                ('tfidf', TfidfVectorizer(stop_words = 'english'))\n            ])\n\n# Passing text data to the model\ntext.fit_transform(X_train)","c23d3b00":"length =  Pipeline([\n                ('selector', NumberSelector(key = 'length')),\n                ('standard', StandardScaler())\n            ])\n\n# Passing numerical data to the model\nlength.fit_transform(X_train)","829483b1":"words =  Pipeline([\n                ('selector', NumberSelector(key = 'words')),\n                ('standard', StandardScaler())\n            ])\n\nwords.fit_transform(X_train)","63e2f4ec":"words_not_stopword =  Pipeline([\n                ('selector', NumberSelector(key = 'words_not_stopword')),\n                ('standard', StandardScaler())\n            ])\n\nwords_not_stopword.fit_transform(X_train)","821217e4":"avg_word_length =  Pipeline([\n                ('selector', NumberSelector(key = 'avg_word_length')),\n                ('standard', StandardScaler())\n            ])\n\navg_word_length.fit_transform(X_train)","b90c6a49":"commas =  Pipeline([\n                ('selector', NumberSelector(key = 'commas')),\n                ('standard', StandardScaler())\n            ])\n\ncommas.fit_transform(X_train)","3bc24bde":"feats = FeatureUnion([('text', text),             \n                      ('length', length),\n                      ('words', words),\n                      ('words_not_stopword', words_not_stopword),\n                      ('avg_word_length', avg_word_length),\n                      ('commas', commas)])","32b191c1":"feature_processing = Pipeline([('feats', feats)])\n\nfeature_processing.fit_transform(X_train)","6efdeb93":"pipeline = Pipeline([\n    ('features', feats),\n    ('classifier', RandomForestClassifier(random_state = 42)),\n])\n\npipeline.fit(X_train, y_train)\n\npreds = pipeline.predict(X_test)\nnp.mean(preds == y_test)","2ab07e01":"# Get text and numeric features","4ec2219e":"# Combining features "}}