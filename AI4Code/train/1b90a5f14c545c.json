{"cell_type":{"9ec4b8b7":"code","13a376a9":"code","7ec61963":"code","6cde1b25":"code","b43c851c":"code","74bda9df":"code","7fed037f":"code","5ecebc5a":"code","22e9e867":"code","72ccdb3e":"code","0b8c5d2b":"code","51579fc4":"code","849b3674":"code","6d23b29b":"code","e146f065":"code","c133cfd9":"code","001ea584":"code","5dc8e4a9":"code","06067679":"code","d443d058":"code","03338a36":"code","2472c084":"code","24e0f5a4":"code","777a4f23":"code","83a9003f":"code","fa8694c7":"code","ab02684f":"code","ffceb7a5":"code","7cc49ac1":"code","a5b35680":"code","4629d4e1":"code","b9d3b531":"code","7c0f687c":"code","c16b8d6d":"code","8e612c56":"code","fa2bc728":"code","2aca4d7b":"code","6546338a":"code","6987311c":"code","adf63bc8":"code","f90c85ea":"code","d71fc041":"code","25ba954a":"code","421efef6":"code","dd143341":"code","99b2aa97":"code","f914966b":"code","ec024afc":"code","04e52efc":"code","c0f84ddf":"code","c5b5c138":"code","17ddc120":"code","126ee810":"code","7bca69a7":"code","c0f665ae":"code","322c9cb7":"code","e440da6c":"code","efcf31b3":"code","d78578d6":"code","23ee6836":"code","73634c8c":"code","0f43ef04":"code","95ef9f74":"code","c9d5cda8":"code","c2a93727":"code","1ec702b8":"code","c2489138":"code","e324d2fa":"code","40f62910":"code","0a4e23c0":"code","4cfa9055":"code","84518a49":"code","51a0f8be":"code","4f1a291d":"code","278bb41e":"code","ccc99926":"code","01182cef":"code","9694f4f5":"markdown","f9c34533":"markdown","7fd9814a":"markdown","5856e287":"markdown","50285c92":"markdown","d7d5d571":"markdown","d99fdbcf":"markdown","310b48ad":"markdown","06f71d3b":"markdown","1e3fcdba":"markdown","7e1cd7a4":"markdown","a82a5e10":"markdown","50821b4c":"markdown","e50da39e":"markdown","e9897dc8":"markdown","0513c715":"markdown","a1cbc738":"markdown","d1a416d6":"markdown","0f56dcd5":"markdown","a17e6af0":"markdown","e892a594":"markdown","f47acaf2":"markdown","4251734e":"markdown","25fb9992":"markdown","7a93bcc1":"markdown","4105d4e8":"markdown","503c63b0":"markdown","15610b24":"markdown","06463a86":"markdown","fb6e675e":"markdown","25721813":"markdown","f75851c3":"markdown","c0b32b40":"markdown","76168c25":"markdown","d955d621":"markdown","afcac32d":"markdown","ad67ddc2":"markdown","3893d12d":"markdown","5ccf368d":"markdown","890cd1c9":"markdown","34b9f145":"markdown","23e7a089":"markdown","3820d4ac":"markdown","f057f4c1":"markdown","e22c139d":"markdown","deae5efe":"markdown","c6167e76":"markdown","027b8b01":"markdown","0d607374":"markdown","7686ff7d":"markdown","fd845dc6":"markdown"},"source":{"9ec4b8b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13a376a9":"file = open('..\/input\/c2-dataset\/files\/ch03\/adult.data', 'r')\n","7ec61963":"def chr_int(a):\n    if a.isdigit():\n        return int(a)\n    else:\n        return 0\n                \ndata=[]\nfor line in file:\n     data1=line.split(', ')\n     if len(data1)==15:\n        data.append([chr_int(data1[0]),data1[1],chr_int(data1[2]),data1[3],chr_int(data1[4]),data1[5],data1[6],\\\n            data1[7],data1[8],data1[9],chr_int(data1[10]),chr_int(data1[11]),chr_int(data1[12]),data1[13],\\\n            data1[14]])","6cde1b25":"print (data[1:2])","b43c851c":"\ndf = pd.DataFrame(data) #  Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes \n\ndf.columns = ['age', 'type_employer', 'fnlwgt', 'education', \n                \"education_num\",\"marital\", \"occupation\", \"relationship\", \"race\",\"sex\",\n                \"capital_gain\", \"capital_loss\", \"hr_per_week\",\"country\",\"income\"]\ndf.head()","74bda9df":"df.tail()","7fed037f":"df.shape","5ecebc5a":"counts = df.groupby('country').size()\n\nprint (counts) ","22e9e867":"counts = df.groupby('age').size() # grouping by age\nprint (counts)\ncounts.idxmax()\n","72ccdb3e":"ml = df[(df.sex == 'Male')] # grouping by sex\nml.shape\nml1 = df[(df.sex == 'Male')&(df.income=='>50K\\n')]\nml1.shape","0b8c5d2b":"fm =df[(df.sex == 'Female')]\nfm.shape","51579fc4":"fm1 =df[(df.sex == 'Female')&(df.income=='>50K\\n')]\nfm1.shape","849b3674":"df1=df[(df.income=='>50K\\n')]\n\nprint ('The rate of people with high income is: ', int(len(df1)\/float(len(df))*100), '%.' )\nprint ('The rate of men with high income is: ', int(len(ml1)\/float(len(ml))*100), '%.' )\nprint ('The rate of women with high income is: ', int(len(fm1)\/float(len(fm))*100), '%.' )","6d23b29b":"df1=df[(df.income=='>50K\\n')]\n\nprint ('The rate of people with high income is: ', int(len(df1)\/float(len(df))*100), '%.' )\nprint ('The rate of men with high income is: ', int(len(ml1)\/float(len(ml))*100), '%.' )\nprint ('The rate of women with high income is: ', int(len(fm1)\/float(len(fm))*100), '%.' )","e146f065":"print ('The average age of men is: ', ml['age'].mean(), '.' )\nprint ('The average age of women is: ', fm['age'].mean(), '.')","c133cfd9":"print ('The average age of high-income men is: ', ml1['age'].mean(), '.' )\nprint ('The average age of high-income women is: ', fm1['age'].mean(), '.')","001ea584":"ml_mu = ml['age'].mean()\nfm_mu = fm['age'].mean()\nml_var = ml['age'].var()\nfm_var = fm['age'].var()\nml_std = ml['age'].std()\nfm_std = fm['age'].std()\n\nprint ('Statistics of age for men: mu:', ml_mu, 'var:', ml_var, 'std:', ml_std)\nprint ('Statistics of age for women: mu:', fm_mu, 'var:', fm_var, 'std:', fm_std)","5dc8e4a9":"ml_mu_hr = ml['hr_per_week'].mean()\nfm_mu_hr = fm['hr_per_week'].mean()\nml_var_hr = ml['hr_per_week'].var()\nfm_var_hr = fm['hr_per_week'].var()\nml_std_hr = ml['hr_per_week'].std()\nfm_std_hr = fm['hr_per_week'].std()\n\nprint ('Statistics of hours per week for men: mu:', ml_mu_hr, 'var:', ml_var_hr, 'std:', ml_std_hr)\nprint ('Statistics of hours per week for women: mu:', fm_mu_hr, 'var:', fm_var_hr, 'std:', fm_std_hr)","06067679":"ml_median= ml['age'].median()\nfm_median= fm['age'].median()\n\nprint (\"Median age per men and women: \", ml_median, fm_median)","d443d058":"ml_median_age= ml1['age'].median()\nfm_median_age= fm1['age'].median()\n\nprint (\"Median age per men and women with high-income: \", ml_median_age, fm_median_age)","03338a36":"ml_median_hr= ml['hr_per_week'].median()\nfm_median_hr= fm['hr_per_week'].median()\nprint (\"Median hours per week per men and women: \", ml_median_hr, fm_median_hr)","2472c084":"import matplotlib.pyplot as plt\nml_age=ml['age']\nml_age.hist(density=0, histtype='stepfilled', bins=20)","24e0f5a4":"fm_age=fm['age']\nfm_age.hist(density=0, histtype='stepfilled', bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Female samples',fontsize=15)\nplt.show()","777a4f23":"import seaborn as sns\nfm_age.hist(density=0, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\nml_age.hist(density=0, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Samples',fontsize=15)\nplt.show()","83a9003f":"fm_age.hist(density=1, histtype='stepfilled', alpha=.5, bins=20)   # default number of bins = 10\nml_age.hist(density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75), bins=10)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('PMF',fontsize=15)\nplt.show()","fa8694c7":"ml_age.hist(density=1, histtype='stepfilled', bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","ab02684f":"fm_age.hist(density=1, histtype='stepfilled', bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","ffceb7a5":"ml_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","7cc49ac1":"fm_age.hist(density=1, histtype='step', cumulative=True, linewidth=3.5, bins=20)\n\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","a5b35680":"ml_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5)   # default number of bins = 10\nfm_age.hist(bins=10, density=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Probability',fontsize=15)\nplt.show()","4629d4e1":"ml_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20)\nfm_age.hist(density=1, histtype='step', cumulative=True,  linewidth=3.5, bins=20, color=sns.desaturate(\"indianred\", .75))\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","b9d3b531":"print (\"The mean sample difference is \", ml_age.mean() - fm_age.mean())","7c0f687c":"df['age'].median()","c16b8d6d":"len(df[(df.income == '>50K\\n') & (df['age'] < df['age'].median() - 15)])","8e612c56":"len(df[(df.income == '>50K\\n') & (df['age'] > df['age'].median() + 35)])","fa2bc728":"df2 = df.drop(df.index[(df.income=='>50K\\n') & (df['age']>df['age'].median() +35) & (df['age'] > df['age'].median()-15)])\n\ndf2.shape","2aca4d7b":"ml1_age=ml1['age']\nfm1_age=fm1['age']","6546338a":"ml2_age = ml1_age.drop(ml1_age.index[(ml1_age >df['age'].median()+35) & (ml1_age>df['age'].median() - 15)])\n\nfm2_age = fm1_age.drop(fm1_age.index[(fm1_age > df['age'].median()+35) & (fm1_age > df['age'].median()- 15)])","6987311c":"mu2ml = ml2_age.mean()\nstd2ml = ml2_age.std()\nmd2ml = ml2_age.median()\n\n# Computing the mean, std, median, min and max for the high-income male population\n\nprint (\"Men statistics: Mean:\", mu2ml, \"Std:\", std2ml, \"Median:\", md2ml, \"Min:\", ml2_age.min(), \"Max:\",ml2_age.max())","adf63bc8":"mu3ml = fm2_age.mean()\nstd3ml = fm2_age.std()\nmd3ml = fm2_age.median()\n\n# Computing the mean, std, median, min and max for the high-income female population\nprint (\"Women statistics: Mean:\", mu2ml, \"Std:\", std2ml, \"Median:\", md2ml, \"Min:\", fm2_age.min(), \"Max:\",fm2_age.max())","f90c85ea":"print ('The mean difference with outliers is: %4.2f.'% (ml_age.mean() - fm_age.mean()))\nprint (\"The mean difference without outliers is: %4.2f.\"% (ml2_age.mean() - fm2_age.mean()))","d71fc041":"plt.figure(figsize=(13.4,5))\n\ndf.age[(df.income == '>50K\\n')].plot(alpha=.25, color='blue')\ndf2.age[(df2.income == '>50K\\n')].plot(alpha=.45,color='red')\n\nplt.ylabel('Age')\nplt.xlabel('Samples')","25ba954a":"import numpy as np\n\ncountx,divisionx = np.histogram(ml2_age, normed=True)\ncounty,divisiony = np.histogram(fm2_age, normed=True)","421efef6":"import matplotlib.pyplot as plt\n\nval = [(divisionx[i]+divisionx[i+1])\/2 for i in range(len(divisionx)-1)]\n\nplt.plot(val, countx-county,'o-')\nplt.title('Differences in promoting men vs. women')\nplt.xlabel('Age',fontsize=15)\nplt.ylabel('Differences',fontsize=15)\nplt.show()","dd143341":"print (\"Remember:\\n We have the following mean values for men, women and the difference:\\nOriginally: \", ml_age.mean(), fm_age.mean(),  ml_age.mean()- fm_age.mean()) # The difference between the mean values of male and female populations.)\nprint (\"For high-income: \", ml1_age.mean(), fm1_age.mean(), ml1_age.mean()- fm1_age.mean()) # The difference between the mean values of male and female populations.)\nprint (\"After cleaning: \", ml2_age.mean(), fm2_age.mean(), ml2_age.mean()- fm2_age.mean()) # The difference between the mean values of male and female populations.)\n\nprint (\"\\nThe same for the median:\")\nprint (ml_age.median(), fm_age.median(), ml_age.median()- fm_age.median()) # The difference between the mean values of male and female populations.)\nprint (ml1_age.median(), fm1_age.median(), ml1_age.median()- fm1_age.median()) # The difference between the mean values of male and female populations.)\nprint (ml2_age.median(), fm2_age.median(), ml2_age.median()- fm2_age.median()), # The difference between the mean values of male and female populations.)","99b2aa97":"def skewness(x):\n    res=0\n    m=x.mean()\n    s=x.std()\n    for i in x:\n        res+=(i-m)*(i-m)*(i-m)\n    res\/=(len(x)*s*s*s)\n    return res\n\nprint (\"The skewness of the male population is:\", skewness(ml2_age))\nprint (\"The skewness of the female population is:\", skewness(fm2_age))","f914966b":"def pearson(x):\n    return 3*(x.mean()-x.median())\/x.std()\n\nprint (\"The Pearson's coefficient of the male population is:\", pearson(ml2_age))\nprint (\"The Pearson's coefficient of the female population is:\", pearson(fm2_age))","ec024afc":"ml1 = df[(df.sex == 'Male')&(df.income=='>50K\\n')]\n\nml2 = ml1.drop(ml1.index[(ml1['age']>df['age'].median() +35)&(ml1['age']> df['age'].median()- 15)])\n\nfm2 = fm1.drop(fm1.index[(fm1['age']> df['age'].median() + 35)& (fm1['age']> df['age'].median() - 15)])\n\nprint (ml2.shape, fm2.shape)","04e52efc":"print (\"Men grouped in 3 categories:\")\nprint (\"Young:\",int(round(100*len(ml2_age[ml2_age<41])\/float(len(ml2_age.index)))),\"%.\")\nprint (\"Elder:\", int(round(100*len(ml2_age[ml2_age >44])\/float(len(ml2_age.index)))),\"%.\")\nprint (\"Average age:\", int(round(100*len(ml2_age[(ml2_age>40) & (ml2_age< 45)])\/float(len(ml2_age.index)))),\"%.\")","c0f84ddf":"print (\"Women grouped in 3 categories:\")\nprint (\"Young:\",int(round(100*len(fm2_age[fm2_age <41])\/float(len(fm2_age.index)))),\"%.\")\nprint (\"Elder:\", int(round(100*len(fm2_age[fm2_age >44])\/float(len(fm2_age.index)))),\"%.\")\nprint (\"Average age:\", int(round(100*len(fm2_age[(fm2_age>40) & (fm2_age< 45)])\/float(len(fm2_age.index)))),\"%.\")","c5b5c138":"print (\"The male mean:\", ml2_age.mean())\nprint (\"The female mean:\", fm2_age.mean())","17ddc120":"ml2_young = len(ml2_age[(ml2_age<41)])\/float(len(ml2_age.index))\nfm2_young  = len(fm2_age[(fm2_age<41)])\/float(len(fm2_age.index))\nprint (\"The relative risk of female early promotion is: \", 100*(1-ml2_young\/fm2_young))","126ee810":"ml2_elder = len(ml2_age[(ml2_age>44)])\/float(len(ml2_age.index))\nfm2_elder  = len(fm2_age[(fm2_age>44)])\/float(len(fm2_age.index))\nprint (\"The relative risk of male late promotion is: \", 100*ml2_elder\/fm2_elder)","7bca69a7":"l = 3\nx=np.arange(0,2.5,0.1)\ny= 1- np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential CDF: $\\lambda$ =%.2f'% l ,fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('CDF',fontsize=15)\nplt.show()","c0f665ae":"from __future__ import division\nimport scipy.stats as stats\n\nl = 3\nx=np.arange(0,2.5,0.1)\ny= l * np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential PDF: $\\lambda$ =%.2f'% l, fontsize=15)\nplt.xlabel('x', fontsize=15)\nplt.ylabel('PDF', fontsize=15)\nplt.show()","322c9cb7":"l = 0.25\n\nx=np.arange(0,25,0.1)\ny= l * np.exp(-l*x)\n\nplt.plot(x,y,'-')\nplt.title('Exponential: $\\lambda$ =%.2f' %l ,fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('PDF',fontsize=15)\nplt.show()","e440da6c":"u=6 # mean\ns=2 # standard deviation\n\nx=np.arange(0,15,0.1)\n\ny=(1\/(np.sqrt(2*np.pi*s*s)))*np.exp(-(((x-u)**2)\/(2*s*s)))\n\nplt.plot(x,y,'-')\nplt.title('Gaussian PDF: $\\mu$=%.1f, $\\sigma$=%.1f'%(u,s),fontsize=15)\nplt.xlabel('x',fontsize=15)\nplt.ylabel('Probability density',fontsize=15)\nplt.show()","efcf31b3":"fig, ax = plt.subplots(1, 4, sharey=True, squeeze=True, figsize=(14, 5))\nx = np.linspace(0, 1, 100)\nfor i in range(4):\n    f = np.mean(np.random.random((10000, i+1)), 1)\n    m, s = np.mean(f), np.std(f, ddof=1)\n    fn = (1\/(s*np.sqrt(2*np.pi)))*np.exp(-(x-m)**2\/(2*s**2))  # normal pdf            \n    ax[i].hist(f, 40, density=True, color=[0, 0.2, .8, .6]) \n    ax[i].set_title('n=%d' %(i+1))\n    ax[i].plot(x, fn, color=[1, 0, 0, .6], linewidth=5)\nplt.suptitle('Demonstration of the central limit theorem for a uniform distribution', y=1.05)\nplt.show()","d78578d6":"from scipy.stats.distributions import norm\n\n# Some random data\ny = np.random.random(15) * 10\nx = np.linspace(0, 10, 100)\n\nx1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\nx2 = np.random.normal(6, 3, 10)\ny = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\nx = np.linspace(min(y), max(y), 100)\n\n# Smoothing parameter\ns = 0.4\n\n# Calculate the kernels\nkernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n\nplt.plot(x, kernels, 'k:')\nplt.plot(x, kernels.sum(1), 'r')\nplt.plot(y, np.zeros(len(y)), 'go', ms=10)","23ee6836":"from scipy.stats import kde\n\nx1 = np.random.normal(-1, 0.5, 15)\n\n# parameters: (loc=0.0, scale=1.0, size=None)\n\nx2 = np.random.normal(6, 1, 10)\ny = np.r_[x1, x2]\n\n# r_ Translates slice objects to concatenation along the first axis.\n\nx = np.linspace(min(y), max(y), 100)\ns = 0.4   # Smoothing parameter\n\nkernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n\n# Calculate the kernels\ndensity = kde.gaussian_kde(y)\n\nplt.plot(x, kernels, 'k:')\nplt.plot(x, kernels.sum(1), 'r')\nplt.plot(y, np.zeros(len(y)), 'bo', ms=10)","73634c8c":"xgrid = np.linspace(x.min(), x.max(), 200)\nplt.hist(y, bins=28, density=True)\nplt.plot(xgrid, density(xgrid), 'r-')","0f43ef04":"# Create a bi-modal distribution with a mixture of Normals.\n\nx1 = np.random.normal(-1, 2, 15) # parameters: (loc=0.0, scale=1.0, size=None)\nx2 = np.random.normal(6, 3, 10)\n\n# Append by row\nx = np.r_[x1, x2]\n\n# r_ Translates slice objects to concatenation along the first axis.\nplt.hist(x, bins=18, density=True)","95ef9f74":"density = kde.gaussian_kde(x)\nxgrid = np.linspace(x.min(), x.max(), 200)\nplt.hist(x, bins=18, density=True)\nplt.plot(xgrid, density(xgrid), 'r-')","c9d5cda8":"x = np.random.normal(0.0, 1.0, 10000)\na = plt.hist(x,50,density='True')","c2a93727":"print ('The empirical mean of the sample is ', x.mean())","1ec702b8":"NTs=200\nmu=0.0\nvar=1.0\nerr = 0.0\nNPs=1000\nfor i in range(NTs):\n    x = np.random.normal(mu, var, NPs)\n    err += (x.mean()-mu)**2\n\nprint ('MSE: ', err\/NTs)","c2489138":"def Cov(X, Y):\n    def _get_dvis(V):\n        return [v - np.mean(V) for v in V]\n    dxis = _get_dvis(X)\n    dyis = _get_dvis(Y)\n    return np.sum([x * y for x, y in zip(dxis, dyis)])\/len(X)\n\n\nX = [5, -1, 3.3, 2.7, 12.2]\nX= np.array(X)\nY = [10, 12, 8, 9, 11]\n\nprint (\"Cov(X, X) = %.2f\" % Cov(X, X))\nprint (\"Var(X) = %.2f\" % np.var(X))\n\nprint (\"Cov(X, Y) = %.2f\" % Cov(X, Y))","e324d2fa":"MAXN=100\nMAXN=40\n\nX=np.array([[1,9],[3, 2], [5,3],[5.5,4],[6,4],[6.5,4],[7,3.5],[7.5,3.8],[8,4],\n[8.5,4],[9,4.5],[9.5,7],[10,9],[10.5,11],[11,11.5],[11.5,12],[12,12],[12.5,12],[13,10]])","40f62910":"plt.subplot(1,2,1)\nplt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\nplt.xlabel('Economic growth(T)',fontsize=15)\nplt.ylabel('Stock market returns(T)',fontsize=15)\nplt.gcf().set_size_inches((20,6))","0a4e23c0":"X=np.array([[1,8],[2, 7], [3,6],[4,8],[5,8],[6,7],[7,7],[8,5],[9,5],[10,6],[11,4],[12,5],[13,3],[14,2],[15,2],[16,1]])\n\nplt.subplot(1,2,1)\nplt.scatter(X[:,0],X[:,1],color='b',s=120, linewidths=2,zorder=10)\nplt.xlabel('World Oil Production(T)',fontsize=15)\nplt.ylabel('Gasoline prices(T)',fontsize=15)\nplt.gcf().set_size_inches((20,6))","4cfa9055":"def Corr(X, Y):\n    assert len(X) == len(Y)\n    return Cov(X, Y) \/ np.prod([np.std(V) for V in [X, Y]])\n\nprint (\"Corr(X, X) = %.5f\" % Corr(X, X))\n\nY=np.random.random(len(X))\n\nprint (\"Corr(X, Y) = %.5f\" % Corr(X, Y))","84518a49":"def list2rank(l):\n    #l is a list of numbers\n    # returns a list of 1-based index; mean when multiple instances\n    return [np.mean([i+1 for i, sorted_el in enumerate(sorted(l)) if sorted_el == el]) for el in l]\n\nl = [7, 1, 2, 5]\nprint (\"ranks: \", list2rank(l))\n\ndef spearmanRank(X, Y):\n    # X and Y are same-length lists\n    print (list2rank(X) )\n    print (list2rank(Y))\n    return Corr(list2rank(X), list2rank(Y))\n\nX = [10, 20, 30, 40, 1000]\nY = [-70, -1000, -50, -10, -20]\nplt.plot(X,'ro')\nplt.plot(Y,'go')\n\nprint (\"Pearson rank coefficient: %.2f\" % Corr(X, Y))\nprint (\"Spearman rank coefficient: %.2f\" % spearmanRank(X, Y))","51a0f8be":"X=np.array([[10.0, 8.04,10.0, 9.14, 10.0, 7.46, 8.0, 6.58],\n[8.0,6.95, 8.0, 8.14, 8.0, 6.77, 8.0, 5.76],\n[13.0,7.58,13.0,8.74,13.0,12.74,8.0,7.71],\n[9.0,8.81,9.0,8.77,9.0,7.11,8.0,8.84],\n[11.0,8.33,11.0,9.26,11.0,7.81,8.0,8.47],\n[14.0,9.96,14.0,8.10,14.0,8.84,8.0,7.04],\n[6.0,7.24,6.0,6.13,6.0,6.08,8.0,5.25],\n[4.0,4.26,4.0,3.10,4.0,5.39,19.0,12.50],\n[12.0,10.84,12.0,9.13,12.0,8.15,8.0,5.56],\n[7.0,4.82,7.0,7.26,7.0,6.42,8.0,7.91],\n[5.0,5.68,5.0,4.74,5.0,5.73,8.0,6.89]])","4f1a291d":"plt.subplot(2,2,1)\nplt.scatter(X[:,0],X[:,1],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)","278bb41e":"plt.subplot(2,2,2)\nplt.scatter(X[:,2],X[:,3],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\nplt.subplot(2,2,3)\nplt.scatter(X[:,4],X[:,5],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)","ccc99926":"plt.subplot(2,2,4)\nplt.scatter(X[:,6],X[:,7],color='r',s=120, linewidths=2,zorder=10)\nplt.xlabel('x1',fontsize=15)\nplt.ylabel('y1',fontsize=15)\nplt.gcf().set_size_inches((10,10))","01182cef":"import statistics\n\ndef Cov(X, Y):\n    def _get_dvis(V):\n        return [v - np.mean(V) for v in V]\n    dxis = _get_dvis(X)\n    dyis = _get_dvis(Y)\n    return np.sum([x * y for x, y in zip(dxis, dyis)])\/len(X)\n\ndef PearsCorr(X, Y):\n    assert len(X) == len(Y)\n    return Cov(X, Y) \/ np.prod([np.std(V) for V in [X, Y]])\n\ndef spearmanRank(X, Y):\n    # X and Y are same-length lists\n    return Corr(list2rank(X), list2rank(Y))\n\n#The code is separated for each statistic measure, even though it can be made for all at the same time\n\n#MEAN OF X,Y PAIR\nmean_list = []\nfor ind, i in enumerate(X.T):\n        mean_list.append([])\n        mean = i.mean()\n        if ind%2==0:\n            mean_list[ind].append(mean)\n        else:\n            mean_list[ind-1].append(mean)\nmean_list_x_y = list(filter(None, mean_list))\n#Mean of X,Y pair on column\nmean_list_x_y\n        \n#VARIANCE OF X,Y PAIR\n\nvariance_list = []\nfor ind, i in enumerate(X.T):\n        variance_list.append([])\n        variance = statistics.variance(i)\n        if ind%2==0:\n            variance_list[ind].append(variance)\n        else:\n            variance_list[ind-1].append(variance)\nvariance_list_x_y = list(filter(None, variance_list))\n#Variance of X,Y pair on column\nvariance_list_x_y\n\ncovariance_list = []\nfor ind, i in enumerate(X.T):\n        covariance_list.append([])\n        covariance = Cov(X[ind],X[ind+1])\n        if ind%2==0:\n            covariance_list[ind].append(covariance)\n        else:\n            pass\ncovariance_list_x_y = list(filter(None, covariance_list))\n#Covariance of X,Y pair on column\ncovariance_list_x_y\n\n\nPearCor_list = []\nfor ind, i in enumerate(X.T):\n        PearCor_list.append([])\n        PearCor = PearsCorr(X[ind],X[ind+1])\n        if ind%2==0:\n            PearCor_list[ind].append(PearCor)\n        else:\n            pass\nPearCor_list_x_y = list(filter(None, PearCor_list))\n#Covariance of X,Y pair on column\nPearCor_list_x_y\n\nSpRank_list = []\nfor ind, i in enumerate(X.T):\n        SpRank_list.append([])\n        SpRank = spearmanRank(X[ind],X[ind+1])\n        if ind%2==0:\n            SpRank_list[ind].append(SpRank)\n        else:\n            pass\nSpRank_list_x_y = list(filter(None, SpRank_list))\n#Covariance of X,Y pair on column\nSpRank_list_x_y\n\n","9694f4f5":"# 2. Describe an explain the result.\n\nUsing the previous code \"paragraph\", we create a dataframe (we can see we also have indexes) with the columns defined in df.columns. If it wasn't for the command df.columns, instead of the name of the columns we would also have indexes, starting from 0. ","f9c34533":"The first scatter plot (top left) appears to be a simple linear relationship, corresponding to two variables correlated where y could be modelled as gaussian with mean linearly dependent on x.\n\nThe second graph (top right) is not distributed normally; while a relationship between the two variables is obvious, it is not linear, and the Pearson correlation coefficient is not relevant. A more general regression and the corresponding coefficient of determination would be more appropriate.\n\nIn the third graph (bottom left), the distribution is linear, but should have a different regression line (a robust regression would have been called for). The calculated regression is offset by the one outlier which exerts enough influence to lower the correlation coefficient from 1 to 0.816.\n\nFinally, the fourth graph (bottom right) shows an example when one high-leverage point is enough to produce a high correlation coefficient, even though the other data points do not indicate any relationship between the variables.\n\nThe quartet is still often used to illustrate the importance of looking at a set of data graphically before starting to analyze according to a particular type of relationship, and the inadequacy of basic statistic properties for describing realistic datasets.\n\n**From the given results it can be shown that is very important to look at the data and analyze it before starting to find the statistics, as they can be missleading. **\n\nThe Pearson Correlation is not relevant for the second pair\n","7fd9814a":"# PIPELINE. .Exploring data collections using decriptive statistics.\n# \n\nThis Notebook was a helpful tool to understand the stepts that are taken to assess a data set. \nThe stepts that need to be taken when starting to work with a dataset are:\nGetting acquainted with data (vizualize, see how the dataframe is composed, see some interesting values)\nSummarize the data (calculate statistical values like mean, the sample variance, sample median, quantiles and percentiles, data distributions). This step help us find some statistical insights on the data and helps us to have a broad ideea about what are we looking for.\nThe next stept is to find the outliers, so basically to curate the dataframe according to our needs, keeping an unbiased perspective. This step is done depending on what data we need, what are the values in the range of interest or how odd some values are in respect to the other in the dataframe. \nAfter exploring the data, we obtained some apparent effects that support our initial assumptions. For example, the mean age for men in our dataset is 39.4 years; while for women, is 36.8 years. When analyzing the high-income salaries, the mean age for men increased to 44.6 years; while for women, increased to 42.1 years. When the data were cleaned from outliers, we obtained mean age for high-income men: 44.3, and for women: 41.8. Moreover, histograms and other statistics show the skewness of the data and the fact that women used to be promoted a little bit earlier than men, in general.\nIn order to not make inferences and have empirical observations, we may be interested to associate distributions that are defined by a continuous functions. Those are the exponential distribution, the normal distribution, etc)\nOn the other hand, in many real problems we may not be interested in the parameters of a particular distribution data, but just a continuous representation of the data. So, we can use a method that is called Kernel Density. This method is used if we have a set of data measurements without knowing their distribution and we need to estimate the continuous representation of their distribution.  \nAnother important step when looking at a dataframe is assessing the unknown parameters. In order to do that we can use the mean, variance, covariance or standard deviation. Furthermore we can see if there are any correlations in the data through the Pearson's coefficient method or Spearsman's rank correlation, which must be used when no outliers are still left in the dataframe. ","5856e287":"# 12. Show the graphics and an explain the result.\n\nThe following graph is showing the CDF (cumulative distribution function) of age distribution for both men and women. We can see that the probability a real-valued random variable X is more common to appear in the left part of the graph for women, while men have a higher probability in the range of 40 years old. ","50285c92":"# 4.3     Estimation","d7d5d571":"# 20. Explain the result.\n\nIn the following line of code we find the median of all values according to the age of the individuals. So, we can conclude that we can find most individuals in the range of 37 years old. ","d99fdbcf":"# 4.2.2 Data distributions","310b48ad":"# 4.2.6      Kernel Density","06f71d3b":"# 4.2.1.4 Quantiles and Percentiles","1e3fcdba":"# Explain the result\n\nIn the code above we calculated the skewness of the values by age. So, the population of both females and males are skewed to the right, meaning that is more probable to have more values in the right part of the age interval. ","7e1cd7a4":"# 4.2.5.2 Normal distribution","a82a5e10":"# 6. What is the age of the most represented people?\n\nTge size function counts the number of elements along a given axis.I used idmax() to find the age of the most represented people. The age is 36","50821b4c":"# 18. Show the graphics and an explain the result.\n\nIn the following graph the CDF is shown. We can see that for females the probability is higher to find younger subjects than for male by about 10%.","e50da39e":"# 15. Show the graphics and an explain the result.\n\nIn the following graph the CDF is plotted. Is depicted the probability distribution to find a value less than or equal to x (value from x axis; age). We can see that the probability to find persons with an age lower than 90 is 100%.","e9897dc8":"# 4.2.3.1 Outliner Treatment","0513c715":"# 17. Show the graphics and an explain the result.\n\nIn the following graph the probability to find a value on x axis is shown, the number of bins being at default value for both data sets.","a1cbc738":"# 16. Show the graphics and an explain the result.\n\nThe explaination is similar to point 15, but now the dataframe is women only. ","d1a416d6":"# 4.3.1.4 Covariance","0f56dcd5":"# 4.3.1.1 Mean","a17e6af0":"# 4.2.1.5 Data distributions","e892a594":"# 4.2.5.3 Central limit theorem\n\n# Example: Uniform Distribution","f47acaf2":"# 1. What is the obtained result? What did you ask for in the previous command? Explain.\n\n\nThe program goes through the content of the file and creates a list of lists from the content of the file\nwe started with an empty data set. We input the strings as strings, but the numbers as integer type. ","4251734e":"# 7. Describe an explain the result.\n\ndf1 is a dataframe derived from df and containts only the persons with an income greater than 50k. \nTo find the rate of people with high income we calculate: the number of all persons divided by the number of persons who earn more than 50k.\nThe same ideea is used to find the rate of men and women with high income. ml1 is a dataframe containing men with high income and ml total men. Same for females. \n","25fb9992":"# 4. Describe an explain the result.\n\nThe df.shape is returning a tuple representing the dimensionality of the dataframe. 32561 Rows, 15 columns","7a93bcc1":"#  13. Show the graphics and an explain the result.\n\nBelow the probability a value is locating in an ange group is depicted. The explaination is similar to point 12.","4105d4e8":"# 4.3.2.6 Spearsman\u2019s rank correlation","503c63b0":"# 4.3.1.2 Variance","15610b24":"# 21. What does the figure shows?\n\nThe following plot has, instead of a smoothed continuous version of a histogram estimated from the data as in the plot before has a histogram. \n","06463a86":"# 3. Describe and explain the result. Compare with the previous one.\n\nThe result gives us the last rows of the dataframe. The tail method is the opposite of head(). ","fb6e675e":"# 10. Show the graphics and an explain the result.\n\nA histogram is an approximate representation of the distribution of numerical data. Therefore, in the next graph we will see how the dataframe containing female samples is distributed according to the age of each individual. We can see that the most common group is around 20 to 30 years. ","25721813":"# 10. Describe an explain the result.\n\nThe median age for men and women is 38, respectively 35.\nThe median age per men and women with high income is 44, respectively 41.\nThe median hours per week per men and women is 40. \n\nSo, in the dataframe there are more men at around 38 years and more women at around 35 years old. Usually, there are more men that are earning a higher income at 44 and more women in the same situation at 41.\nThe median hours per week is 40h.\n\n","f75851c3":"**Exercise:** Obtain for the Anscombe's quartet [2] given in the figures bellow, the different estimators (mean, variance, covariance for each pair, Pearson's correlation and Spearman's rank correlation.","c0b32b40":"# 8. Describe an explain the result.\n\nWe use the mean function to calculate the mean of the column age. We use ml1 and ml or fm1 and fm which are the dataframes for men\/female with higher income and all male\/female. \n","76168c25":"# 4.2.1.3 Sample Median","d955d621":"# 4.2.1 Summarizing the Data","afcac32d":"# 4.2.1.7 Measuring Asymmetry","ad67ddc2":"# 4.2 Explanatory Data Analysis","3893d12d":"# 11. Show the graphics and an explain the result.\n\nIn the following graph we have to metrics represented in the same place; one for females, one for males. We can see that the most common age for females is in the left side of the age axis, while for males is around 40 years old. ","5ccf368d":"# 4.3.1.5 Pearson\u2019s correlation","890cd1c9":"# 9. Describe an explain the result.\n\nFrom the results we can observe that the mean in age for men is 39, while the mean in age for females is 36. The spread around the mean is 13,4 for men and 14 for women. \nThe mean number of working hours per week for men is 42,4 with a standard deviation of 12, while for females is 36,4 with a standard deviation of 11.81. \n\n","34b9f145":"# 14. Show the graphics and an explain the result.\n\nThe explaination is similar to point 13 and 12.","23e7a089":"# 4.3.1.3 Standard scores","3820d4ac":"# 5. How many items are there for USA? and for Mexico?\n\nUnited states has 29170 measures and Mexico 643.","f057f4c1":"# 4.2.5 Continuous Distribution\n\n# 4.2.5.1 Exponential distribution","e22c139d":"# What do you obtained as result?\n\nWe obtained the sample mean of the created data set. MSE = 1\/(number_of_values) * (SUM(sample_mean - mean)^2)","deae5efe":"# 4.2.3 Outliers\n\n","c6167e76":"# 4.3.1 Sample and Estimated Mean, Variance and Standard Scores","027b8b01":"# 4.2.1.8 Relative Risk","0d607374":"# 4.2.1.2 Sample Variance","7686ff7d":"# 19. Show the graphics and an explain the result.\n\nIn the following line of code we compute the difference in mean values for male and female. The difference in mean value is 2.57. ","fd845dc6":"# 4.2.1.1 Mean"}}