{"cell_type":{"f204a4d2":"code","de3de336":"code","46cad474":"code","7b63537c":"code","351dc401":"code","21a03467":"code","a82383e2":"code","5e1a5177":"code","8b48b6ef":"code","9e2964c9":"code","5a6f1626":"code","f8a1b68e":"code","53eca97e":"code","d1085f46":"code","cb410471":"code","2a777cc2":"code","f764db3a":"code","06812328":"code","d1d4b908":"code","491d8631":"code","b789391f":"code","17c227ea":"code","74f53af7":"code","608c47c6":"code","02a8305e":"code","df68de5d":"code","3fa2d9ee":"code","93300c09":"code","27f7d8c6":"code","0c54a2a8":"code","f10de4cb":"code","e889deb5":"code","990e64b6":"code","3720f907":"code","b8e7408b":"code","7d17e87e":"code","0078d930":"code","9ccc9014":"code","abc08680":"code","addddeb3":"code","fc4e9b2e":"code","09069157":"code","45f3ed35":"code","71aaa98a":"code","9432910f":"code","f482c024":"code","1e526932":"code","de450a53":"code","5a49470a":"code","29942510":"code","293ed6f2":"code","b0fbb8be":"code","0c8c5260":"code","21761364":"code","7b9c8bed":"code","86cb7449":"code","4b32e8f0":"code","0a55e726":"code","b13b34a7":"code","9b29a795":"code","14437fd8":"code","0e9b856a":"code","bf5459ed":"code","e8bcc824":"code","b60afe37":"code","b65bd812":"code","2a1f84a3":"code","54cab51e":"code","74291758":"code","3e323683":"code","604d5ff3":"code","b5367b41":"code","c0af7a73":"code","e0d78a11":"code","00b4f673":"code","360de874":"code","8c31570b":"code","5e2d81f6":"code","d39b1821":"code","7d6c203b":"code","da41d860":"code","8e2440d9":"code","9c2e8e07":"code","3f304ec8":"code","2eb1e453":"code","534af281":"code","69e3fcd2":"code","f8330ae1":"code","4f8ff8d1":"markdown","cddfb019":"markdown","59147c8c":"markdown","0593b90e":"markdown","7530dd44":"markdown","4aaf0bb2":"markdown","31b413bb":"markdown","59e56dac":"markdown","67699159":"markdown","6d25aacc":"markdown","81c33925":"markdown","8fe9d4eb":"markdown","62b6dc6c":"markdown","b6c6f18e":"markdown","e62dbc25":"markdown","2c3fc9f9":"markdown","4f505cd3":"markdown","29956391":"markdown","584032a6":"markdown","7955f925":"markdown","e7550ace":"markdown","01b11f6a":"markdown","ef87f1b6":"markdown"},"source":{"f204a4d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport glob\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","de3de336":"Sl_no = [1,2,3,4,5]\nQuestions = ['What is the picture of digital connectivity and engagement in 2020?',\n            'What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?',\n            'How does student engagement with different types of education technology change over the course of the pandemic?',\n            'How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)?Learning context? Socioeconomic status?',\n            'Do certain state interventions, practices or policies (e.g., stimulus, reopening,eviction moratorium) correlate with the increase or decrease online engagement?']","46cad474":"Findings = [\"Every School district is unique in the Connectivity all year long.Similarities<br> could be found in the summer breaks &<br> the spring break that were given.<br> TownsVsCities, RuralVsSuburbs sets followed a very similar kind of connectivity.<br>1)Arizona City tops in overall Engagement.<br> Some cities had very low engagement, to no engagement.<br>Notable is North Dakota, there is no engagement even <br>though FCC has given it Connection ratio as the highest.<br> Wisconsin, Illinois, Washington & Texas the<br> prominent states have much lower Engagement\",\n           \"Given data contains the data from 1st Jan20 to 31st Dec20.The Covid cases in US were reported in Early Jan, so that is visible in the time-series in multiple engagement chart.The online tools engagement steadily reduces towards the start of summer breaks and then gradually raisesfrom there. Concluding that online\/ distance learning has been embraced by the school districts.\",\n           'Major educational technology products engaged were<br>1) Google <br>2)Docs Google Classroom<br>3)Meet<br>4)Google Drive<br>5)Kahoot!<br>6)Google Sheets<br>7)Canvas<br>8)Schoology<br>9)Lexia Core5 Reading<br>10)YouTube<br>Kahoot, Meet, and Youtube showed very <br>different engagement behaviour compared to all the other<br>major educational products. The engagement<br> is driven by Google products. The engagement of the Google products are atleast 5 to 10 times that of other products.',\n           'Engagement is high in The schools with 0 to 20% reduced\/subsidised lunch has higher engagement. Schools offering 80 to 100% Reduced\/Subsidised lunch comes close to the 0 to 20%.The School Districts where the Per Pupil Total Expenditure were 18,000 to 20,000 the engagement was highest.0 to 20% black\/hispanic Schools have the highest engagement.Schools with 80 to 100% black\/hispanic population next.',\n           'Data on the intervention can be taken from https:\/\/www.openicpsr.org\/openicpsr\/project\/119446\/version\/V75\/view?path=\/openicpsr\/119446\/fcr:versions\/V75\/COVID-19-US-State-Policy-Database-master\/Previously-Published-Versions&type=folder. The school closing Policy in all the states were implemented from Mar20 onwards, and stayed fo the whole year.The school closure policy implementation has not ifluenced the engagement.']","7b63537c":"fig = go.Figure()\nfig.add_trace(\n    go.Table(\n        columnorder = [1,2,3],\n        columnwidth = [20,200,400],\n        header=dict(\n            values=[\"Sl_no\", \"Questions\", \"Findings\"],\n            font=dict(size=12),\n            line_color='darkslategray',\n            fill_color='lightskyblue',\n            align=\"left\",\n            height = 40\n        ),\n        cells=dict(\n            values=[Sl_no,Questions,Findings],\n            font=dict(size=12),\n            line_color='darkgray',\n            fill_color='azure',\n            align = \"left\",\n            height = 150)\n    ))\nfig.update_layout(title='The Key Findings from the Learn Platform Data')","351dc401":"!pip install openpyxl","21a03467":"#Bringing in the Covid_Policy Intervention files\n# \"!\" commands are called \"magic commands\" and allow you to use bash\nfile_dir = '\/\/kaggle\/input\/covid-intervention-unitedstates\/'\n# Get a python list of csv files\nfiles = glob.glob(os.path.join(file_dir, \"*.xlsx\"))\n# Make a list of dataframes while adding a district column\ndataframes = [pd.read_excel(file,sheet_name=1).assign(date=os.path.basename(file).strip(\".xlsx\")) for file in files]\n# Concatenate all the dataframes into one\nintervention = pd.concat(dataframes, ignore_index=True)","a82383e2":"#Taking the collection date from the file name\nintervention.date = [x.replace(' ','')[29:] for x in intervention.date]","5e1a5177":"sl_no = [1,2,3,4,5,6]\ninterv = ['STEMERG','CLSCHOOL','EVICENF','RNTGP','UTILSO','SNAPEBT']\nexplanation =['The first date a state declared any type of emergency declaration',\n              'The date a state closed K-12 schools statewide. Order must apply to entire state',\n              'The date a state allowed a renter grace period or the use of security deposit to pay rent. Did not include guidance or recommendations. Order must apply to entire state.',\n              'The date a state allowed a renter grace period or the use of security deposit to pay rent. Did not include guidance or recommendations. Order must apply to entire state.',\n              'The date a state froze utility shut offs. Utilities could include water, gas, or electricity. Did not include guidance or recommendations. Order must apply to entire state.',\n              'The date a state was approved the use of a waiver to provide meal replacement benefits through SNAP, known as \u201cPandemic EBT\u201d (for electronic benefit transfer), for households with children who attend a school that\u2019s closed and who would otherwise receive free or reduced-price meals.']\n\n","8b48b6ef":"intervention_tab = go.Figure()\nintervention_tab.add_trace(\n    go.Table(\n        columnorder = [1,2,3],\n        columnwidth = [20,100,400],\n        header=dict(\n            values=[\"Sl_no\", \"Policy\", \"Definition\"],\n            font=dict(size=12),\n            line_color='darkslategray',\n            fill_color='lightskyblue',\n            align=\"left\",\n            height = 40\n        ),\n        cells=dict(\n            values=[sl_no,interv,explanation],\n            font=dict(size=12),\n            line_color='darkgray',\n            fill_color='azure',\n            align = \"left\",\n            height = 40)\n    ))\nintervention_tab.update_layout(title='The intervention data from OpenICSPR')","9e2964c9":"interve_data = intervention[['date','STATE','STEMERG','CLSCHOOL','SNAPEBT','UTILSO','EVICENF','RNTGP']]\ninterve_data.STATE.unique()","5a6f1626":"STATE = ['Alabama', 'Alaska','Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n         'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii',\n         'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n         'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n         'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska',\n         'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n         'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n         'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n         'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n         'West Virginia', 'Wisconsin', 'Wyoming']","f8a1b68e":"#Remove the metadata related to each of the columns, and maintain only the Closure of school data\ninterve_data = interve_data[interve_data.STATE.isin(STATE)]","53eca97e":"interve_data.head()","d1085f46":"#Coercing the date column to native Datetime type\ninterve_data[\"date\"] = interve_data[\"date\"].apply(lambda x:x.strip('_'))\ninterve_data[\"date\"] = interve_data[\"date\"].apply(lambda x:x.replace('_','-'))","cb410471":"interve_data[\"date\"] = pd.to_datetime(interve_data[\"date\"], format='%m-%d-%Y')","2a777cc2":"interve_data.loc[:,'UTILSO'] = interve_data.loc[(interve_data.UTILSO != 0),'UTILSO'].apply(lambda x:pd.to_datetime(x,format='%m-%d-%Y'))\ninterve_data.loc[:,'STEMERG'] = interve_data.loc[(interve_data.STEMERG != 0),'STEMERG'].apply(lambda x:pd.to_datetime(x,format='%m-%d-%Y'))\ninterve_data.loc[:,'CLSCHOOL'] = interve_data.loc[(interve_data.CLSCHOOL != 0),'CLSCHOOL'].apply(lambda x:pd.to_datetime(x,format='%m-%d-%Y'))\ninterve_data.loc[:,'SNAPEBT'] = interve_data.loc[(interve_data.SNAPEBT != 0),'SNAPEBT'].apply(lambda x:pd.to_datetime(x,format='%m-%d-%Y'))\ninterve_data.loc[:,'EVICENF'] = interve_data.loc[(interve_data.EVICENF != 0),'EVICENF'].apply(lambda x:pd.to_datetime(x,format='%m-%d-%Y'))\ninterve_data.loc[:,'RNTGP'] = interve_data.loc[(interve_data.RNTGP != 0),'RNTGP'].apply(lambda x:pd.to_datetime(x,format='%m-%d-%Y'))","f764db3a":"interve_data.head()","06812328":"state = 'Alabama'\ndf_state = interve_data[interve_data.STATE == state]\ndf_state = df_state[['date', 'STATE', 'STEMERG', 'CLSCHOOL', 'SNAPEBT','UTILSO', 'EVICENF', 'RNTGP']]\n\nstate = go.Figure()\nstate.add_trace(\n    go.Table(\n        header=dict(\n            values=['date','state','STEMERG','CLSCHOOL','SNAPEBT','UTILSO','EVICENF','RNTGP'],\n            font_size=12,\n            line_color='darkslategray',\n            fill_color='lightskyblue',\n            align=\"left\",\n            height = 40\n        ),\n        cells=dict(\n            values=[df_state.date,df_state.STATE,\n                    df_state.STEMERG,df_state.CLSCHOOL,\n                    df_state.SNAPEBT,df_state.UTILSO,\n                    df_state.EVICENF,df_state.RNTGP],\n            font_size=12,\n            font_color='black',\n            line_color='darkgray',\n            fill_color='azure',\n            align = \"left\",\n            height = 40)\n        ))\nstate.show()","d1d4b908":"#Let extract the month in which a particular covid_intervention was initiated.\nfor col in ['STEMERG','CLSCHOOL','SNAPEBT','UTILSO','EVICENF','RNTGP']:\n    interve_data.loc[:,col] = interve_data.loc[:,col].apply(lambda x:  x.month if type(x) != int else x)\n    \n#Converting object into integers\n#interve_data.loc[:,'RNTGP'] = interve_data.loc[:,'RNTGP'].astype(int)","491d8631":"intervention_fig = go.Figure()\nfor colum in ['STEMERG','CLSCHOOL','SNAPEBT','UTILSO','EVICENF','RNTGP']:\n    intervention_fig.add_trace(go.Scatter(x=interve_data.STATE,y=interve_data[colum],\n                                          name=colum,mode='lines',line_shape='hv'))\nintervention_fig.show()","b789391f":"sl_no_obs = [1,2,3,4,5,6]\ninterv_obs = ['STEMERG','CLSCHOOL','EVICENF','RNTGP','UTILSO','SNAPEBT']\nObservation =['State of Emergency was called by all the states from the beginning, that is in the month Mar_20. The dates of emergency implemented varied across the states',\n              'Close school was implemented by all the states from the start of the emergency in Mar_21. Exception were the state of California & Rhode Island, which had no policies for closing schools immediately.',\n              'Eviction Moratorium was not implemented in 10 states. The other states did implement the moratarium eventually. Maine and Virginia implemented it, but late in May_21',\n              'Rent payment through advance was implemented only by Connecticut, New Jersey and Wyoming. None of the other states implemented.',\n              'Utility Shut-off has not been implemented by many of the states, so correlation between intervention is less',\n              'SNAP EBT payment were not implemented in Utah, Nevada, Nebraska, Oklahama,Idaho & South Carolina. Those other states implemented in Apr_20 or May_20.']","17c227ea":"intervention_obs = go.Figure()\nintervention_obs.add_trace(\n    go.Table(\n        columnorder = [1,2,3],\n        columnwidth = [20,100,400],\n        header=dict(\n            values=[\"Sl_no\", \"Policy\", \"Observation\"],\n            font=dict(size=12),\n            line_color='darkslategray',\n            fill_color='lightskyblue',\n            align=\"left\",\n            height = 40\n        ),\n        cells=dict(\n            values=[sl_no_obs,interv_obs,Observation],\n            font=dict(size=12),\n            line_color='darkgray',\n            fill_color='azure',\n            align = \"left\",\n            height = 40)\n    ))\nintervention_obs.update_layout(title='The observation from OpenICSPR')","74f53af7":"# See how many files there are in the directory. \n# \"!\" commands are called \"magic commands\" and allow you to use bash\nfile_dir = '\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/'\n# Get a python list of csv files\nfiles = glob.glob(os.path.join(file_dir, \"*.csv\"))\n# Make a list of dataframes while adding a district column\ndataframes = [pd.read_csv(file).assign(district=os.path.basename(file).strip(\".csv\")) for file in files]\n# Concatenate all the dataframes into one\ndf = pd.concat(dataframes, ignore_index=True)","608c47c6":"df.sample(10)","02a8305e":"#The time column will be more useful if it is datetime format. Lets parse that \n#df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n\n# Check if the conversion is successful\n#assert df[\"time\"].dtype == \"datetime64[ns]\"","df68de5d":"#making the 'time' column as the index\n#df.set_index('time',inplace=True)","3fa2d9ee":"data = [1,2,3,4,5,6,7,8,9,10]\ninfo = ['pct_access','engagement_index','pct_black\/hispanic','pct_free\/reduced',\n          'countyconnectionsratio','pptotalraw','Product Name','Provider\/Company',\n         'Sector(s)','Primary Essential Function']\ndefined =['%_students in School district have one page-load event','Total page-load events per one 1000 students',\n          '%_Black or Hispanic Student','%_students free or reduced-price lunch',\n          'ratio of fixed high-speed connections','Per-pupil total expenditure',\n          'Name of the specific product','Name of the product provider',\n          'Sector of education where the product is used','The basic function of the product']\ntype = ['Continous Variable','Continous Variable',\n          'Categorical','Categorical','Categorical','Categorical','ID','ID','Categorical','Categorical']","93300c09":"product_tab = go.Figure()\nproduct_tab.add_trace(\n    go.Table(\n        columnorder = [1,2,3,4],\n        columnwidth = [20,100,200,100],\n        header=dict(\n            values=[\"Sl_no\", \"Feature\", \"Definition\",\"Type\"],\n            font=dict(size=12),\n            line_color='darkslategray',\n            fill_color='lightskyblue',\n            align=\"left\",\n            height = 40\n        ),\n        cells=dict(\n            values=[data,info,defined,type],\n            font=dict(size=12),\n            line_color='darkgray',\n            fill_color='azure',\n            align = \"left\",\n            height = 40)\n    ))\nproduct_tab.update_layout(title='The product table features and definition')","27f7d8c6":"#Loading the District information file\ndistrict = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\ndistrict.info()","0c54a2a8":"district.head()","f10de4cb":"print('The {}% of state name data is not applicable'.format(100 * district[district.state.isna()].district_id.count()\/district.shape[0]))\nprint('The {}% of connection data which data is not available'.format(100 * district[district.county_connections_ratio.isna()].district_id.count()\/district.shape[0]))","e889deb5":"district_nona = district[~district.state.isna()]\ndistrict_nona.info()","990e64b6":"district_nona.district_id = district_nona.district_id.apply(lambda x:str(x))","3720f907":"district_nona.sample(5)","b8e7408b":"district_nona.to_csv('district_clean.csv')","7d17e87e":"sd_pct = district_nona.groupby('state')['district_id'].count().reset_index()\nsd_pct['pct'] = round(100*(sd_pct.district_id\/sum(sd_pct.district_id)),0)","0078d930":"bh_pct = district_nona.groupby(['pct_black\/hispanic','locale'])['district_id'].count().reset_index()\nbh_pct['pct'] = round(100*(bh_pct.district_id\/sum(bh_pct.district_id)),0)","9ccc9014":"fr_pct = district_nona.groupby(['pct_free\/reduced','locale'])['district_id'].count().reset_index()\nfr_pct['pct'] = round(100*(fr_pct.district_id\/sum(fr_pct.district_id)),0)","abc08680":"ptr_pct = district_nona.groupby(['pp_total_raw','locale'])['district_id'].count().reset_index()\nptr_pct['pct'] = round(100*(ptr_pct.district_id\/sum(ptr_pct.district_id)),0)","addddeb3":"lo_pct = district_nona.groupby('locale')['district_id'].count().reset_index()\nlo_pct['pct'] = round(100*(lo_pct.district_id\/sum(lo_pct.district_id)),0)","fc4e9b2e":"pfr_pct = district_nona.groupby(['pct_black\/hispanic','pct_free\/reduced'])['district_id'].count().reset_index()\npfr_pct['pct'] = round(100*(pfr_pct['district_id']\/sum(pfr_pct['district_id'])),0)","09069157":"from plotly.subplots import make_subplots\n#Making Subplots\nstate_bar =  make_subplots(rows=4, cols=2,\n                           specs=[[{\"rowspan\": 2},{}],[None,{}],[{\"colspan\":2},None],[{},{}]],\n                           subplot_titles=(\"No of Schools in States\",\n                                           \"Black\/Hispanic %\", \"Subsidised Lunch%\",\n                                           \"%of Spending\",\"Distribution of schools\",\n                                           \"Subsidised Food Vs Black\/Hispanic Schools\",))\n#Creating empty traces\nbh_trace =[]\nfr_trace =[]\npr_trace =[]\npfr_trace=[]\n\ncolors = {'[0.8, 1[': 'red',\n          '[0.6, 0.8[': 'orange',\n          '[0.4, 0.6[': 'lightgreen',\n          '[0.2, 0.4[': 'darkgreen',\n          '[0, 0.2[': 'Black'}\n\n#Building the layout and data\nbh = px.bar(data_frame=bh_pct,y='pct_black\/hispanic',x='district_id',color='locale',barmode='relative',\n           labels={'locale': \"Locality\"})\nfr = px.bar(data_frame=fr_pct,y='pct_free\/reduced',x='district_id',color='locale',barmode='relative',\n            labels={})\npr = px.bar(data_frame=ptr_pct,x='pp_total_raw',y='district_id',color='locale')\npfr = px.bar(data_frame=pfr_pct,x='pct_black\/hispanic',y='district_id',color='pct_free\/reduced',\n            color_discrete_map=colors)\n\nfor trace in range(len(bh[\"data\"])):\n    bh_trace.append(bh[\"data\"][trace])\nfor trace in range(len(fr[\"data\"])):\n    fr_trace.append(fr[\"data\"][trace])\nfor trace in range(len(pr[\"data\"])):\n    pr_trace.append(pr[\"data\"][trace])\nfor trace in range(len(pfr[\"data\"])):\n    pfr_trace.append(pfr[\"data\"][trace])\n    \n\n#Removing the legends from the additional traces\nfor x in range(len(fr_trace)):\n    fr_trace[x]['showlegend'] = False\nfor x in range(len(pr_trace)):\n    pr_trace[x]['showlegend'] = False\n    \n#Populating the empty trace lists\nfor traces in bh_trace:\n    state_bar.append_trace(traces, row=1, col=2)\nfor traces in fr_trace:\n    state_bar.append_trace(traces, row=2, col=2)\nfor traces in pr_trace:\n    state_bar.append_trace(traces, row=3, col=1)\nfor traces in pfr_trace:\n    state_bar.append_trace(traces, row=4, col=2)","45f3ed35":"state_bar.add_trace(go.Bar(x=lo_pct.locale,y=lo_pct.district_id),row=4,col=1)\nstate_bar.add_trace(go.Bar(y=sd_pct.state,x=sd_pct.district_id,orientation='h'),row=1, col=1,)\nstate_bar.update_layout(\n        autosize=False,\n        width=1000,\n        height=1000,\n        margin=dict(\n            l=50,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        ),\n        paper_bgcolor=\"LightSteelBlue\",\n    )","71aaa98a":"products = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')","9432910f":"products.head()","f482c024":"#Changing the columns name to make it easier to work with.\nproducts.columns = [(column.replace(' ','_')) for column in products.columns]\nproducts.columns = [(column.replace('\/','_')) for column in products.columns]\nproducts.columns = [(column.replace('(','')) for column in products.columns]\nproducts.columns = [(column.replace(')','')) for column in products.columns]","1e526932":"#How many products each company in the datasets have, which sector do they belong to\n#How many unique companies\n#print(products.Provider_Company_Name.unique())\nprint('There are total {} providers in the dataset'.format(len(products.Provider_Company_Name.unique())))","de450a53":"products.info()\n#There are 20 data with missing sectors and primary_essential_function","5a49470a":"# Assign function as 'Support' and Sector as \"other\"\nproducts.loc[products.Primary_Essential_Function.isnull(),'Primary_Essential_Function'] = 'SDO - Support'\nproducts.loc[products.Sectors.isnull(),'Sector(s)'] = 'Other'  \nproducts.loc[products.Provider_Company_Name.isnull(),'Provider_Company_Name'] = 'Power Soft'","29942510":"#How many products each company in the datasets have, which sector do they belong to\n#How many unique sectors?\nprint(products.Sectors.unique())\nprint('There are total {} sectors in the dataset'.format(len(products.Sectors.unique())))","293ed6f2":"#How many unique primary functions?\n#print(products.Primary_Essential_Function.unique())\nprint('There are total {} Primary Essential Function in the dataset'.format(len(products.Primary_Essential_Function.unique())))","b0fbb8be":"products['MainFunction'] = products.Primary_Essential_Function.apply(lambda x: x.split('-')[0])\nproducts.MainFunction.unique()","0c8c5260":"#Sector wise product_id percentage\nsct = products.groupby('Sectors')['LP_ID'].count().reset_index()\nsct['pct'] = round(100*(sct.LP_ID\/sum(sct.LP_ID)),0)\n#Main function wise product_id percentage\nmfd = products.groupby('MainFunction')['LP_ID'].count().reset_index()\nmfd['pct'] = round(100*(mfd.LP_ID\/sum(mfd.LP_ID)),0)\npef = products.groupby('Primary_Essential_Function')['LP_ID'].count().reset_index()\npef['pct'] = round(100*(pef.LP_ID\/sum(pef.LP_ID)),0)","21761364":"pdt_piv1 = pd.pivot_table(products, columns='MainFunction',index='Sectors',aggfunc='count',dropna=True)['LP_ID']\npdt_piv2 = pd.pivot_table(products, columns='Primary_Essential_Function',index='Sectors',aggfunc='count',dropna=True)['LP_ID']","7b9c8bed":"product_fig = go.Figure()\n\n#Initiating empty traces\npro_mf = []\npro_sec = []\npro_dist = []\n\n#Building the layout and data\nproduct_fig.add_trace(go.Bar(y=sct.Sectors,x=sct.LP_ID,orientation='h'))\nproduct_fig.add_trace(go.Bar(y=mfd.MainFunction,x=mfd.LP_ID,visible=False,orientation='h',showlegend=False))\nproduct_fig.add_trace(go.Bar(y=pef.Primary_Essential_Function,x=pef.LP_ID,visible=False,\n                             orientation='h',showlegend=False))\n\nproduct_fig.update_layout(\n    updatemenus=[go.layout.Updatemenu(\n        active=0,\n        buttons=list(\n            [dict(label = 'Sectors',\n                  method = 'update',\n                  args = [{'visible': [True, False, False]}, # the index of True aligns with the indices of plot traces\n                          {'title': 'Sectors',\n                           'showlegend':True}]),\n             dict(label = 'Main_Functions',\n                  method = 'update',\n                  args = [{'visible': [False, True, False]},\n                          {'title': 'MainFunctions',\n                           'showlegend':True}]),\n             dict(label = 'Essential_Functions',\n                  method = 'update',\n                  args = [{'visible': [False, False, True]},\n                          {'title': 'Essential_Functions',\n                           'showlegend':True}]),\n            ])\n        )\n    ])\n\nproduct_fig.show()","86cb7449":"#List of School district that we have the information\ndistrict_list = district_nona.district_id.unique()\nproduct_list = products.LP_ID.unique()\nprint(len(product_list))\nprint(len(district_list))","4b32e8f0":"#Create the engagement dataframe based on the product_id for which we have details.\npdt_engagement = df[df.district.isin(district_list)]","0a55e726":"#Check the type of the variable before using it for filtering the data.\npdt_engagement.lp_id.unique()[0]\nproduct_list[0]","b13b34a7":"#Filtering the engagement to include only the products in the products info dataset\npdt_engagement = pdt_engagement[pdt_engagement.lp_id.isin(product_list)]\npdt_engagement.shape","9b29a795":"sl_no_dat = [1,2]\nfeat_name= ['pct_access','engagement_index']\ndefinition = ['%_students in School district have one page-load event',\n             'Total page-load events per one 1000 students']\ndescription = ['If a school district has 10000 students and pct_access is 0.1, then 0.1*10000 = 10 students had one page load event of that productTo answer the above question, the access of each product is additive under each district. To answer how the connectivity changed over the year, this feature can be additive for each day.',\n               'If the page loads of a product is 10,000 in a day, then engagement index will be 10,000 \/1000 = 10.0. Same product can be used by multiple student, and multiple time under multiple districts. Mean of the Engagement_index of the products over itself can show the popularity of the product. Mean of the Engagement_index of the products over time period will show the popularity change of the product.']","14437fd8":"pro_tab = go.Figure()\npro_tab.add_trace(\n    go.Table(\n            columnorder = [1,2,3,4],\n            columnwidth = [20,50,100,200],\n            header=dict(\n                values=[\"Sl_no\", \"Feature\", \"Definition\",\"Description\"],\n                font=dict(size=12),\n                line_color='darkslategray',\n                fill_color='lightskyblue',\n                align=\"left\",\n                height = 40\n            ),\n            cells=dict(\n                values=[sl_no_dat,feat_name,definition,description],\n                font=dict(size=12),\n                line_color='darkgray',\n                fill_color='azure',\n                align = \"left\",\n                height = 40)\n        ))\npro_tab.update_layout(title=' Starting the Product Engagement dataset')","0e9b856a":"pdt_engagement.describe()","bf5459ed":"#Day_Engagement dataframe. We are interested on the pct_access and engagement_index, so product & districts dropped\npdt_engagement_day = pdt_engagement.groupby('time')['pct_access','engagement_index'].mean().reset_index()\n\n#converting the time column into time-series\npdt_engagement_day[\"time\"] = pd.to_datetime(pdt_engagement_day[\"time\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n\n#making the 'time' column as the index\npdt_engagement_day.set_index('time',inplace=True)","e8bcc824":"pdt_engagement_fig = go.Figure()\npdt_engagement_fig.add_trace(go.Scatter(x=pdt_engagement_day.resample('W')['pct_access'].max().index,name='max',\n                                       y=pdt_engagement_day.resample('W')['pct_access'].max().values,mode='lines',\n                                       visible=False))\npdt_engagement_fig.add_trace(go.Scatter(x=pdt_engagement_day.resample('W')['pct_access'].min().index,name='min',\n                                       y=pdt_engagement_day.resample('W')['pct_access'].min().values,mode='lines',\n                                       visible=False))\npdt_engagement_fig.add_trace(go.Scatter(x=pdt_engagement_day.resample('W')['pct_access'].mean().index,name='mean',\n                                       y=pdt_engagement_day.resample('W')['pct_access'].mean().values,mode='lines',\n                                       visible=False))\n\npdt_engagement_fig.add_trace(go.Scatter(x=pdt_engagement_day.resample('W')['engagement_index'].max().index,name='max',\n                                       y=pdt_engagement_day.resample('W')['engagement_index'].max().values,mode='lines'))\npdt_engagement_fig.add_trace(go.Scatter(x=pdt_engagement_day.resample('W')['engagement_index'].min().index,name='min',\n                                       y=pdt_engagement_day.resample('W')['engagement_index'].min().values,mode='lines'))\npdt_engagement_fig.add_trace(go.Scatter(x=pdt_engagement_day.resample('W')['engagement_index'].mean().index,name='mean',\n                                       y=pdt_engagement_day.resample('W')['engagement_index'].mean().values,mode='lines'))\n\npdt_engagement_fig.update_layout(\n    updatemenus=[go.layout.Updatemenu(\n        active=0,\n        buttons=list(\n            [dict(label = 'Pct_Access',\n                  method = 'update',\n                  args = [{'visible': [True, True, True,False,False,False]}, # the index of True aligns with the indices of plot traces\n                          {'title': 'Percetage_Access',\n                           'showlegend':True}]),\n             dict(label = 'Engagement_index',\n                  method = 'update',\n                  args = [{'visible': [False,False,False,True, True, True]},\n                          {'title': 'Engagement_index',\n                           'showlegend':True}]),\n            ])\n        )\n    ])\n\n\npdt_engagement_fig.show()","b60afe37":"pdt_min_eng = pdt_engagement_day.resample('W')['engagement_index'].min()\n#There is spike in the minimum engagement on the week of 12th Apr. This could be due to increase in \n#activity of supporting application before \"Spring Break\"\npdt_min_eng.idxmax()","b65bd812":"pdt_engagement_district = pdt_engagement.groupby('district')['pct_access','engagement_index'].mean().reset_index()\npdt_engagement_district['state'] = pdt_engagement_district.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'state'].values[0])\npdt_engagement_district['locale'] = pdt_engagement_district.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'locale'].values[0])\npdt_engagement_district\n#Lets bring in the state and the locale details into this dataframe","2a1f84a3":"pdt_engagement_district['pct_blk_hsp'] = pdt_engagement_district.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'pct_black\/hispanic'].values[0])\npdt_engagement_district['pp_total_raw'] = pdt_engagement_district.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'pp_total_raw'].values[0])\npdt_engagement_district['pct_red_lunch'] = pdt_engagement_district.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'pct_free\/reduced'].values[0])\npdt_engagement_district\n#Lets bring in the state and the locale details into this dataframe","54cab51e":"# Re-naming NAN values\npdt_engagement_district.loc[pdt_engagement_district.pp_total_raw.isna(),'pp_total_raw'] = 'No_Data'\npdt_engagement_district.loc[pdt_engagement_district.pct_red_lunch.isna(),'pct_red_lunch'] = 'No_Data'","74291758":"pdt_engagement_district.loc[:,'pct_blk_hsp'] = pdt_engagement_district.pct_blk_hsp.apply(lambda x: x+'BlkHisp%')\npdt_engagement_district.loc[:,'pct_red_lunch'] = pdt_engagement_district.pct_red_lunch.apply(lambda x: x+'subsidy%')\npdt_engagement_district.loc[:,'pp_total_raw'] = pdt_engagement_district.pp_total_raw.apply(lambda x: x+'Spend')","3e323683":"tree_prd = px.treemap(pdt_engagement_district, path=[px.Constant(\"all\"), 'locale', 'state', 'district'], \n                      values='engagement_index')\ntree_prd.update_traces(root_color=\"lightgrey\")\ntree_prd.update_layout(margin = dict(t=50, l=25, r=25, b=25))\ntree_prd.show()","604d5ff3":"tree_prd = px.treemap(pdt_engagement_district, path=[px.Constant(\"all\"), 'pct_blk_hsp', 'pp_total_raw', \n                                                     'pct_red_lunch'],\n                      values='engagement_index')\ntree_prd.update_traces(root_color=\"lightgrey\")\ntree_prd.update_layout(margin = dict(t=50, l=25, r=25, b=25))\ntree_prd.show()","b5367b41":"#How is the engagement with respect to race and ethnicity, amount of money spent and free_lunch provided\npdt_eng_eth_piv = pd.pivot_table(pdt_engagement_district, columns='locale',index='pct_blk_hsp',aggfunc='mean',dropna=True)['engagement_index']\nplt.figure(figsize=(10,14))\nax = plt.subplot(3,1,1)\npdt_eng_eth_piv.plot(kind='barh',stacked=True,sort_columns=True,ax=ax)\n\npdt_eng_frl_piv = pd.pivot_table(pdt_engagement_district, columns='locale',index='pct_red_lunch',aggfunc='mean',dropna=True)['pct_access']\nay = plt.subplot(3,1,2)\npdt_eng_frl_piv.plot(kind='barh',stacked=True,sort_columns=True,ax=ay)\n\npdt_eng_ptr_piv = pd.pivot_table(pdt_engagement_district, columns='locale',index='pp_total_raw',aggfunc='mean',dropna=True)['pct_access']\nay = plt.subplot(3,1,3)\npdt_eng_ptr_piv.plot(kind='barh',stacked=True,sort_columns=True,ax=ay)","c0af7a73":"grouper = pd.Grouper(freq='W')\n#converting the time column into time-series\npdt_engagement[\"time\"] = pd.to_datetime(pdt_engagement[\"time\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n\n#making the 'time' column as the index\npdt_engagement.set_index('time',inplace=True)\n\npdt_time_stt = pdt_engagement.groupby([grouper,'district'])['pct_access','engagement_index'].mean().reset_index()","e0d78a11":"#Adding Locale and State to the main product engagement dataset\npdt_time_stt['state'] = pdt_time_stt.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'state'].values[0])\npdt_time_stt['locale'] = pdt_time_stt.district.apply(lambda x: district_nona.loc[district_nona.district_id == x,'locale'].values[0])","00b4f673":"pdt_time_stt['time'] = pd.to_datetime(pdt_time_stt[\"time\"], format=\"%Y-%m-%d\", errors=\"coerce\")\npdt_time_stt.set_index('time',inplace=True)\npdt_time_stt.info()","360de874":"grouper = pd.Grouper(freq='W')\npdt_time_locale = pdt_time_stt.groupby([grouper,'locale'])['pct_access','engagement_index'].mean().reset_index()\npdt_time_locale","8c31570b":"grouper = pd.Grouper(freq='W')\npdt_time_state = pdt_time_stt.groupby([grouper,'state'])['pct_access','engagement_index'].mean().reset_index()\n#pdt_time_state","5e2d81f6":"sub = []\nfor i in range(len(pdt_time_state.state.unique())):\n    visible = [False] * len(pdt_time_state.state.unique())\n    visible[i] = True\n    sub.append(dict(label = pdt_time_state.state.unique()[i],\n                    method = 'update',\n                    args = [{'visible': visible}, # the index of True aligns with the indices of plot traces\n                            {'title': pdt_time_state.state.unique()[i],'showlegend':True}]))","d39b1821":"state_fig = go.Figure()\nfor state in pdt_time_state.state.unique():\n    state_fig.add_trace(go.Scatter(x=pdt_time_state[pdt_time_state.state == state].index,\n                                   y=pdt_time_state[pdt_time_state.state == state].engagement_index,\n                                  name=state,visible=False))\n\nstate_fig.update_layout(\n    updatemenus=[go.layout.Updatemenu(\n        active=1,\n        buttons=sub,\n        )\n    ])\nstate_fig.show()","7d6c203b":"pdt_engagement_lpid = pdt_engagement.groupby('lp_id')['pct_access','engagement_index'].mean().reset_index()","da41d860":"pdt_engagement_lpid['Name'] = pdt_engagement_lpid.lp_id.apply(lambda x: products.loc[products.LP_ID == x,'Product_Name'].values[0])\npdt_engagement_lpid['MainFunction'] = pdt_engagement_lpid.lp_id.apply(lambda x: products.loc[products.LP_ID == x,'MainFunction'].values[0])\npdt_engagement_lpid['Sector'] = pdt_engagement_lpid.lp_id.apply(lambda x: products.loc[products.LP_ID == x,'Sectors'].values[0])\n#Lets bring in the state and the locale details into this dataframe","8e2440d9":"#Re-assigning Null values in Sectors to Others\npdt_engagement_lpid.loc[pdt_engagement_lpid.Sector.isna(),'Sector'] = 'Other'","9c2e8e07":"pro_eng = px.treemap(data_frame=pdt_engagement_lpid,path=[px.Constant(\"all\"), 'Sector', 'MainFunction', \n                                                     'Name'],\n                      values='engagement_index')\n\npro_eng.show()","3f304ec8":"grouper = pd.Grouper(freq='W')\n#converting the time column into time-series\n#pdt_engagement[\"time\"] = pd.to_datetime(pdt_engagement[\"time\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n\n#making the 'time' column as the index\n#pdt_engagement.set_index('time',inplace=True)\n\npdt_time_MainFn = pdt_engagement.groupby([grouper,'lp_id'])['pct_access','engagement_index'].mean().reset_index()\npdt_time_MainFn","2eb1e453":"#Adding Main Function and Sector to the main product engagement dataset\npdt_time_MainFn['MainFunction'] = pdt_time_MainFn.lp_id.apply(lambda x: products.loc[products.LP_ID == x,'MainFunction'].values[0])\npdt_time_MainFn['Sector'] = pdt_time_MainFn.lp_id.apply(lambda x: products.loc[products.LP_ID == x,'Sectors'].values[0])\npdt_time_MainFn['Name'] = pdt_time_MainFn.lp_id.apply(lambda x: products.loc[products.LP_ID == x,'Product_Name'].values[0])\npdt_time_MainFn","534af281":"pdt_time_MainFn.loc[pdt_time_MainFn.Sector.isna(),'Sector'] = 'Other'","69e3fcd2":"px.treemap(data_frame=pdt_time_MainFn,path=['MainFunction', 'Sector','Name'],\n                      values='engagement_index')","f8330ae1":"pdt_line = go.Figure()\n\nfor pdt in pdt_time_MainFn.Name.unique():\n    pdt_line.add_trace(go.Scatter(x=pdt_time_MainFn[pdt_time_MainFn.Name == pdt].index,\n                               y=pdt_time_MainFn[pdt_time_MainFn.Name == pdt].engagement_index,\n                              visible=False,name=pdt))\n    \nbut_pro = []\nfor i in range(len(pdt_time_MainFn.Name.unique())):\n    visible = [False] * len(pdt_time_MainFn.Name.unique())\n    visible[i] = True\n    but_pro.append(dict(label = pdt_time_MainFn.Name.unique()[i],\n                    method = 'update',\n                    args = [{'visible': visible}, # the index of True aligns with the indices of plot traces\n                            {'title': pdt_time_MainFn.Name.unique()[i],'showlegend':True}]))\n\npdt_line.update_layout(\n    updatemenus=[go.layout.Updatemenu(\n        active=1,\n        buttons=but_pro)])\npdt_line.show()","4f8ff8d1":"# Understanding the Covid intervention policy data from US State policy database\nhttps:\/\/www.openicpsr.org\/openicpsr\/project\/\n\nThere are many sources from which the data has been collected and aggregated into a regular update. The data consists of 110 interventions, mandates and orders(collectively called policies in this Notebook). All these individual policies are updated in the file that has been imported above. \n\nThere are 3 major policies that are required for our analysis. ","cddfb019":"# Thanks for joining me in the journey till the end :)","59147c8c":"# School districts distribution based on the Location \/ Population categories","0593b90e":"# Product Engagement with respect to states \n\n**Which are the top 5 states with maximum engagement?**\n\nConnecticut, Utah, Massachusetts, Illinois, New York\n\n**How do these state fare all through the year?** \n\nArizona looks to be leading when we look at the timeseries. New-York, Illinois have higher engagement compared to Connecticut, Utah, Massachusetts \n\nNorth Dakota which were showing higher connectivity in reality is not having engagement. Minessota also having similar drop in engagement.\n\nMuch of the States have very low engagement throughout the year, like that of Wisconsin, Washington, Tenesse, Michigan etc ","7530dd44":"# Analysing the product info dataset","4aaf0bb2":"# Product Engagement over time with respect to District location & ethnicity","31b413bb":"# Distribution of products based on Sectors\/ Functions","59e56dac":"### Learning Plotly and understanding the Innerworkings of the Express & Graph Objects\n\nThe notebook is culmination of trying methods to bring the dashboard experience to LearnPF dataset using Python & Plotly. Using Dash became a bottleneck since the Kaggle notebooks do not allow the connection to the flask server open always. There is uncertainity involved. \n\n### Another reason to make this notebook: PRACTICE\n\nTo Practice Story telling with the data. The data can be made to talk through the bars and lines. They are strangely memorable. Fascinated, I started digging ever deeper into the Plotly applications. ","67699159":"The distribution of people, intervention, connections ratio and Per Pupil Total expenditure is considered \nas Normal distribution. The provided ranges of percentages are split and the average values are taken below. ","6d25aacc":"There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labele","81c33925":"# Products engagement based on the type of users","8fe9d4eb":"# District Info dataset Analysis","62b6dc6c":"# What are the observations based on the products engagement? \n\n1) US schools go for summer break somewhere between May\/june and students return to school late Aug or early September. The same is matching the above holiday calendar. From the week of 28th June to 09th Aug the schools engagement_Index has comedown to 62 \n\n2) There is a minimum 25 to 100 engagement_index across the entire year, and this can be assigned to the supporting products that the schools, and teachers use all around the year.\n\n3) The outlier at 175 occurs in the week of 12th Apr, followed by dip in the max\/mean usages subsequent week. I hypothesise that week of 19th Apr was start of the spring break for a week.","b6c6f18e":"**Which locale is with maximum pct_access and engagement?**\n1) Suburbs schools across the states have highest access & engagement \n\n**How the engagement of Locales changes over the time of the year?**\n1) Each locale has a very different weekly engagements across their school districts. The City engagement is opposite to Town engagement. The Town schools engagement reduced after the summer holidays. \n\n2) Town had longer holidays compared to City Kids. The Holidays in the City started atleast 2 weeks later than the other locales.\n\n3) The Suburb engagement is lower to Rural engagement. Their summer holidays gap matches with only a few days gap. ","e62dbc25":"# How the data of covid intervention is visualised? \n\n**Purpose** \n\n- To see the which month of the year the policies were implemented \n\n- The online-engagement had begun before the policies were implemented, then we can safely conclude the engagement were not driven by the interventions.\n\n- If there is mismatch between the above conclusion, more in-depth analysis to be done to find what is the driver of engagement.\n\nData provided in Open ICPSR starts for May-20 and is continuing till date. We can infer the data is updated every 2 to 5 days interval from the Interve_data dataset. This dataset is similar to the \"engagement_data\" that has been shared from the Learn Platform.  ","2c3fc9f9":"# Distribution of the Product engagement with respect Location & Ethnicity factors","4f505cd3":"# Starting the Analysis of the School District, Products Info and Product Engagement data ","29956391":"# Analysing the Products Engagement over time\n\nOn each day there are multiple product used in each school district. There are mutiple districts data for each day. \n\nThe aggregation of products will give a view about **products** usage on a day, and aggregation over district will give a view about the **district.** \n\nWhen we have to find the overall engagement_index and connectivity on each day, just **aggregating over the day** would be meaningful enough.","584032a6":"# Product Engagement distribution based on Main Function and essential function \n\nBefore diving headlong into locating the usage profile of a product, seeing the overview of the market will provide clarity and a baseline for future understanding of the data. \n\nLC- Study Tools - Test Prep & Study Skills \n\nCM- Classroom Engagement,Instruction and Management \n\nSDO - Admissions, Enrollment, Rostering & Highlevel Administration\n\nLC\/CM\/SDO - Which comes under all the three, kind of application with multiple capabilities.\n\n- LC Study Tools usage is at the Top with 68% engagement\n- SDO follows by 21%\n\n**Which are the products are having the maximum engagement?** \n\n**Which sector of Products having maximum engagement?**\n\n**What are the products at the top under each Sector?**\n\nNext we will see how these sectors, mainfuctions and products doing across the entire year","7955f925":"How much of the District Info file has Null_values? \n\nSome of the school district data has been completely remove, as you can see the entire row is Null. So safely removed. Lets use the district_Id which only has the State names. \n\nThe entire district dataset is useful for categorising, and filtering. All the columns are categorical in nature. The connection ratio column will come in handy to verify one of the findings later in the notebook.","e7550ace":"# Various Interventions and their statewise implementation","01b11f6a":"### Idea is \n\nTo create the time-series plot with multiple drop downs, one for each Main Function, Sector and Name.\n","ef87f1b6":"There are **36 Primary functions** which can be grouped under bigger categories such as CM, SDO, LC. Our concentration is on \"LC\" that is used by the kids."}}