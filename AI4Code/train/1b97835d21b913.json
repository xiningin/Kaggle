{"cell_type":{"129682bd":"code","bdd19531":"code","6c3c1079":"code","372c3ad5":"code","e66d01a8":"code","f5f2385b":"code","f6f70378":"code","ddfea2d8":"code","61ddab74":"code","e0691d5f":"code","c0d49760":"code","c957216e":"code","6e7b8b8e":"code","054d9386":"code","2f93def0":"code","0f81aac1":"code","654bbe39":"code","dd560e4e":"code","a54a4d56":"code","96173b2c":"code","fcbd9c21":"code","1f2ad5dc":"code","82eba81c":"code","9042a6ce":"markdown","12a496b9":"markdown","d223e41e":"markdown","a39baeb5":"markdown","3ac3e3fd":"markdown","df81154a":"markdown","3335bc45":"markdown","1920f625":"markdown","7b95520e":"markdown","82f502a8":"markdown","360473f2":"markdown","777a8f4d":"markdown","1153bed0":"markdown","b0b4ff77":"markdown","6a783ee1":"markdown","0fefd868":"markdown","acc4e0ce":"markdown","06a460b6":"markdown","cccc2f05":"markdown","199c213d":"markdown","b07e65c2":"markdown","e4249e86":"markdown"},"source":{"129682bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport ipywidgets as widgets\nfrom ipywidgets import interact, interact_manual\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bdd19531":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","6c3c1079":"train.head()","372c3ad5":"X_train, X_val, y_train, y_val = train_test_split(train.iloc[:, 1:], train.iloc[:, 0], test_size=0.2)\nprint('X_train:', X_train.shape)\nprint('y_train:', y_train.shape)\nprint('X_val:', X_val.shape)\nprint('y_val:', y_val.shape)\n","e66d01a8":"@interact\ndef show_digital(x=(0, 1000)):\n    return plt.imshow(np.array(X_train.iloc[x]).reshape((28,28))), print('The number is', y_train.iloc[x])\n","f5f2385b":"def normalization(X):\n    X = X \/ 255.0\n    return X","f6f70378":"X_train = np.array(normalization(X_train))\nX_val = np.array(normalization(X_val))\ny_train = np.array(y_train)\ny_val = np.array(y_val)","ddfea2d8":"%%time\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\nprint('Score:', LR.score(X_val, y_val))","61ddab74":"%%time\nfrom sklearn.svm import LinearSVC\nSVM = LinearSVC().fit(X_train, y_train)\nprint('Score:', SVM.score(X_val, y_val))","e0691d5f":"%%time\nfrom sklearn.neighbors import KNeighborsClassifier\nKNN = KNeighborsClassifier(n_neighbors=5, n_jobs=-1).fit(X_train, y_train)\nprint('Score:', KNN.score(X_val, y_val))","c0d49760":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adadelta","c957216e":"X_train = X_train.reshape(-1, 28, 28)\nX_train = np.expand_dims(X_train, axis=1)\nX_val = X_val.reshape(-1, 28, 28)\nX_val = np.expand_dims(X_val, axis=1)\ny_train = to_categorical(y_train, 10)\ny_val = to_categorical(y_val, 10)\n","6e7b8b8e":"X_train.shape","054d9386":"def CNN_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(1,28,28), data_format='channels_first'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(10, activation='softmax'))\n    return model","2f93def0":"%%time\nCNN = CNN_model()\n\nCNN.compile(loss=categorical_crossentropy,\n              optimizer=Adadelta(),\n              metrics=['accuracy'])\n\nCNN.fit(X_train, y_train,\n          batch_size=128,\n          epochs=30,\n          verbose=1,\n          validation_data=(X_val, y_val))\n","0f81aac1":"X_train = train.iloc[:, 1:]\ny_train = train.iloc[:, 0]\nX_test = test","654bbe39":"X_train = np.array(normalization(X_train))\ny_train = np.array(y_train)\nX_test = np.array(normalization(X_test))","dd560e4e":"X_train = X_train.reshape(-1, 28, 28)\nX_train = np.expand_dims(X_train, axis=1)\nX_test = X_test.reshape(-1, 28, 28)\nX_test = np.expand_dims(X_test, axis=1)\ny_train = to_categorical(y_train, 10)","a54a4d56":"CNN = CNN_model()\n\nCNN.compile(loss=categorical_crossentropy,\n              optimizer=Adadelta(),\n              metrics=['accuracy'])\n\nCNN.fit(X_train, y_train,\n          batch_size=128,\n          epochs=30,\n          verbose=1)","96173b2c":"prediction_prob = CNN.predict(X_test)","fcbd9c21":"prediction = np.argmax(prediction_prob, axis=1)","1f2ad5dc":"prediction","82eba81c":"prediction_df = {\"ImageId\":range(1, X_test.shape[0]+1), \"Label\":prediction}\nprediction_df = pd.DataFrame(prediction_df)\nprediction_df.to_csv(\"prediction.csv\", index = False)","9042a6ce":"### Predicting","12a496b9":"Let's take a look at some data.","d223e41e":"#### Preprocessing","a39baeb5":"Convolutional Neural Network scored the highest on validation accuracy, so we will use that model to train on the whole trianing set and make prediction on the test set.","3ac3e3fd":"### Convolutional Neural Network (CNN)\nhttps:\/\/keras.io\/layers\/convolutional\/","df81154a":"## Import Dataset","3335bc45":"## Import Libraries","1920f625":"### Preprocessing","7b95520e":"### K-Nearest Neighbors (KNN)\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html","82f502a8":"The only preprocessing we will do here is to normalize the dataset to distribution of [0,1], and turn the Pandas data structure into Numpy arrays.","360473f2":"The MNIST dataset is the de facto \"hello world\" dataset of computer vision. It contains images of handwritten digits 0-9. In this notebook, we will take a look at some of the data, preprocess it, and build models for classifying the digits. ","777a8f4d":"We will run couple classification algorithms on the dataset, and train the best one on the entire training set (train+val) to predict the test set.","1153bed0":"#### Model Building and Training\n","b0b4ff77":"Separate the training dataset into training and validation sets.","6a783ee1":"# Digit Recognition ","0fefd868":"## Prediction","acc4e0ce":"#### Import Libraies","06a460b6":"### Support Vector Machines (SVM)\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html","cccc2f05":"## Modeling","199c213d":"## Preprocessing","b07e65c2":"### Logistic Regression\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html","e4249e86":"### Training"}}