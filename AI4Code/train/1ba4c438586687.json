{"cell_type":{"b35f2dfd":"code","2de3ad89":"code","d5d44de5":"code","b95cfe93":"code","bc02d9e7":"code","bc255b6f":"code","2c153f84":"code","c6eb6340":"code","a98cc5e5":"code","2f3995fa":"code","dba5c60c":"code","280e4598":"code","eb539994":"code","4307b27c":"code","fa2d0d06":"code","3c5e3980":"code","cc58cb86":"code","6e670854":"code","e82aa770":"code","47d362b7":"code","ed16858b":"code","bc94ed7f":"markdown"},"source":{"b35f2dfd":"import os\nimport gensim\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","2de3ad89":"data = pd.read_json('..\/input\/whats-cooking-kernels-only\/train.json')\ntest = pd.read_json('..\/input\/whats-cooking-kernels-only\/test.json')","d5d44de5":"print('Training data shape: {}'.format(data.shape))\nprint('Test data shape: {}'.format(test.shape))","b95cfe93":"# Target variable \ntarget = data.cuisine","bc02d9e7":"data['ingredient_count'] = data.ingredients.apply(lambda x: len(x))","bc255b6f":"def flatten_lists(lst):\n    \"\"\"Remove nested lists.\"\"\"\n    return [item for sublist in lst for item in sublist]","2c153f84":"f = plt.figure(figsize=(14,8))\ngs = gridspec.GridSpec(2, 2)\n\nax1 = plt.subplot(gs[0, :])\ndata.ingredient_count.value_counts().hist(ax=ax1)\nax1.set_title('Recipe richness', fontsize=12)\n\nax2 = plt.subplot(gs[1, 0])\npd.Series(flatten_lists(list(data['ingredients']))).value_counts()[:20].plot(kind='barh', ax=ax2)\nax2.set_title('Most popular ingredients', fontsize=12)\n\nax3 = plt.subplot(gs[1, 1])\ndata.groupby('cuisine').mean()['ingredient_count'].sort_values(ascending=False).plot(kind='barh', ax=ax3)\nax3.set_title('Average number of ingredients in cuisines', fontsize=12)\n\nplt.show()","c6eb6340":"# Feed a word2vec with the ingredients\nw2v = gensim.models.Word2Vec(list(data.ingredients), size=350, window=10, min_count=2, iter=20)","a98cc5e5":"w2v.most_similar(['meat'])","2f3995fa":"w2v.most_similar(['chicken'])","dba5c60c":"def document_vector(doc):\n    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n    doc = [word for word in doc if word in w2v.wv.vocab]\n    \n    print(doc)\n    print(w2v[doc])\n    print(np.mean(w2v[doc]))\n    print(\"\\n\")\n    return np.mean(w2v[doc], axis=0)\n    ","280e4598":"data['doc_vector'] = data.ingredients.apply(document_vector)\ntest['doc_vector'] = test.ingredients.apply(document_vector)","eb539994":"lb = LabelEncoder()\ny = lb.fit_transform(target)","4307b27c":"X = list(data['doc_vector'])\nX_test = list(test['doc_vector'])","fa2d0d06":"clf = LogisticRegression(C=100)","3c5e3980":"clf.fit(X, y)","cc58cb86":"y_test = clf.predict(X_test)\ny_pred = lb.inverse_transform(y_test)","6e670854":"test_id = [id_ for id_ in test.id]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('clf_output.csv', index=False)","e82aa770":"data[\"doc_vector\"]","47d362b7":"w2v.wv.vocab","ed16858b":"data.ingredients","bc94ed7f":"Let's try some examples"}}