{"cell_type":{"7f132d61":"code","06fbc742":"code","c8514cde":"code","2e1356ea":"code","f7b89f17":"code","9913b862":"code","bb94593e":"code","e62da7dd":"code","59619bcd":"code","4ba3f1de":"code","fb45551f":"code","d6037947":"code","c9e56b24":"code","8f5d3ac8":"code","f9cbaf89":"code","037b1e3f":"code","7c531086":"code","9b014f78":"code","409d5b81":"markdown","cf7b0d0d":"markdown","6c863388":"markdown","76e8f056":"markdown","2cbf7e3f":"markdown","71d4ffea":"markdown","74086351":"markdown","6acfef4e":"markdown","413fd627":"markdown","5f08f85d":"markdown","b91c796d":"markdown","9b8f369b":"markdown","7610bbde":"markdown","b894a0b7":"markdown","92a2ba4e":"markdown","a054f624":"markdown"},"source":{"7f132d61":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06fbc742":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import  confusion_matrix,accuracy_score,precision_score,recall_score,f1_score","c8514cde":"data= pd.read_csv(\"\/kaggle\/input\/dishonest-internet-users-dataset-data-set\/main.csv\")\ndf = pd.DataFrame(data)\ndf","2e1356ea":"df.info()","f7b89f17":"print('ctrust',df.ctrust.unique())\nprint('cuntrust',df.cuntrust.unique())\nprint('last',df['last'].unique())\nprint('context',df.context.unique())\nprint('score',df.score.unique())","9913b862":"df['score'].replace({'untrustworthy':0,'trustworthy':1},inplace=True)\ndf","bb94593e":"df['context'].replace({'sport':1,'game':2,'ECommerce':3,'holiday':4},inplace=True)\ndf","e62da7dd":"y=data.score.values\nx_data=data.drop(\"score\",axis=1)","59619bcd":"x=(x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data))\nx","4ba3f1de":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=37)","fb45551f":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='linear')\nsvclassifier.fit(x_train, y_train)\ny_pred = svclassifier.predict(x_test)\nconfu_svm=confusion_matrix(y_test,y_pred)\naccuracy_svm=accuracy_score(y_test,y_pred)\nprecision_svm=precision_score(y_test,y_pred)\nrecall_svm=recall_score(y_test,y_pred)\nf1_svm=f1_score(y_test,y_pred)","d6037947":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(x_train,y_train)\ny_pred = nb.predict(x_test)\nconfu_nb=confusion_matrix(y_test,y_pred)\naccuracy_nb=accuracy_score(y_test,y_pred)\nprecision_nb=precision_score(y_test,y_pred)\nrecall_nb=recall_score(y_test,y_pred)\nf1_nb=f1_score(y_test,y_pred)","c9e56b24":"from tabulate import tabulate\na='SVM'\nb='Naive Bayes'\nresult1=(a,accuracy_svm,precision_svm,recall_svm,f1_svm)\nresult2=(b,accuracy_nb,precision_nb,recall_nb,f1_nb)\nresult=(result1,result2)\nprint('confusion matrix SVM')\nprint(confu_svm)\n\nprint('confusion matrix Naive Bayes')\nprint(confu_nb)\n\nprint(tabulate(result, headers=[\"accuracy\", \"precision\", \"recall\",\"f1_score\"]))","8f5d3ac8":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import StackingClassifier","f9cbaf89":"def get_stacking():\n    # define the base models\n    level0 = list()\n    level0.append(('svm', SVC()))\n    level0.append(('bayes', GaussianNB()))\n    # define meta learner model\n    level1 = LogisticRegression()\n    # define the stacking ensemble\n    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n    return model","037b1e3f":"def get_models():\n    models = dict()\n    models['Meta Learner LR'] = LogisticRegression()\n    models['Base Learner SVM'] = SVC()\n    models['Base Learner Bayes'] = GaussianNB()\n    models['Final stacking'] = get_stacking()\n    return models","7c531086":"def evaluate_model(model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=1)\n    return scores","9b014f78":"models = get_models()\nresults, names = list(), list()\nfor name, model in models.items():\n    scores = evaluate_model(model)\n    results.append(scores)\n    names.append(name)\n    \n    \n    print('>%s accuracy=%.3f ' % (name, mean(scores)))\n","409d5b81":"**SVM**","cf7b0d0d":"**Split dataset into training and test dataset**","6c863388":"**Naive Bayes**","76e8f056":"**Reading the dataset**","2cbf7e3f":"**Normalize the data**","71d4ffea":"**Ensembling:Stacking**","74086351":"We can see that the accuracy of SVM alone is 0.85 and Naive baayes alone is 0.67\n\nBut when we ensemble these two models the resulting accuracy increases that is 0.994\n","6acfef4e":"**Importing Packages**","413fd627":"function stacking ensemble of models","5f08f85d":"**Convert categorical value to binary**","b91c796d":"Here the output data which is score is assigned to variable y and input data is assigned to x_data variable","9b8f369b":"**Convert categorical value to integral value**","7610bbde":"function for list of models to evaluate","b894a0b7":"**Split X and Y data**","92a2ba4e":"function to evaluate a given model using cross-validation","a054f624":"**Comparing SVM and Naive Bayes**"}}