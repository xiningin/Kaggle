{"cell_type":{"efa046e3":"code","03e784d8":"code","1534f558":"code","03424f66":"code","e113a2ed":"code","af71a74f":"code","94b3fd55":"code","e945873f":"markdown"},"source":{"efa046e3":"import numpy as np \nimport pandas as pd \ndf=pd.read_csv('\/kaggle\/input\/malware-executable-detection\/uci_malware_detection.csv')\ndf.head()","03e784d8":" \ndf.describe()","1534f558":"X=df[df.columns[1:]]\ny=df['Label']","03424f66":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=101)","e113a2ed":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nerror_rate=[]\nfor i in range(1,40):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred=knn.predict(X_test)\n    error_rate.append(np.mean(pred!=y_test))\n    ","af71a74f":"# Now create the following plot using the information from your for loop\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,linestyle='--',color='blue', marker='o',markerfacecolor='red',markersize=10)\nplt.title('Error Rate vs K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","94b3fd55":"# train your model with the best K value (up to you to decide what you want) and re-do the classification report and the confusion matrix.\n\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\nprint('WITH K=5')\nprint('\\n')\nprint(confusion_matrix(y_test,pred))\nprint('\\n------------------------------------------------------------------------------\\n')\nprint(classification_report(y_test,pred))\n","e945873f":"#Choosing a K Value\nLet's use the elbow method to pick a good K Value!\n\nCreate a for loop that trains various KNN models with different k values, then keep track of the error_rate for each of these models with a list. Refer to the lecture if you are confused on this step."}}