{"cell_type":{"98e27528":"code","2025bdb8":"code","a24ab3b3":"code","cab30fe3":"code","df81ca21":"code","eb190101":"code","6188cc88":"code","4cf6ad99":"code","566047ef":"code","d04633f1":"code","5cb8cab1":"code","06776521":"markdown","714d8fa4":"markdown","92de843f":"markdown","d3156bcd":"markdown","33a78ca6":"markdown","195e4cb4":"markdown","e6e320e0":"markdown","25549f33":"markdown","d7abc3a7":"markdown"},"source":{"98e27528":"try:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n    pass\n  \nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport numpy as np\nimport matplotlib.pyplot as plt","2025bdb8":"def map_image_with_noise(image, label):\n    '''Normalizes the images and generates noisy inputs.'''\n    image = tf.cast(image, dtype=tf.float32)\n    image = image \/ 255.0\n    \n    noise_factor = 0.5\n    factor = noise_factor * tf.random.normal(shape=image.shape)\n    image_noisy = image + factor\n    image_noisy = tf.clip_by_value(image_noisy, 0.0, 1.0)\n \n    return image_noisy, image ","a24ab3b3":"BATCH_SIZE = 128\nSHUFFLE_BUFFER_SIZE = 1024\n\ntrain_dataset = tfds.load('fashion_mnist', as_supervised=True, split=\"train\")\ntrain_dataset = train_dataset.map(map_image_with_noise)\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\ntest_dataset = tfds.load('fashion_mnist', as_supervised=True, split=\"test\")\ntest_dataset = test_dataset.map(map_image_with_noise)\ntest_dataset = test_dataset.batch(BATCH_SIZE).repeat()","cab30fe3":"def encoder(inputs):\n    '''Defines the encoder with two Conv2D and max pooling layers.'''\n    conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n    max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_1)\n\n    conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(max_pool_1)\n    max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_2)\n\n    return max_pool_2","df81ca21":"def bottle_neck(inputs):\n    '''Defines the bottleneck.'''\n    bottle_neck = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n    encoder_visualization = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(bottle_neck)\n\n    return bottle_neck, encoder_visualization","eb190101":"def decoder(inputs):\n    '''Defines the decoder path to upsample back to the original image size.'''\n    conv_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n    up_sample_1 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_1)\n\n    conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(up_sample_1)\n    up_sample_2 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_2)\n\n    conv_3 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(up_sample_2)\n\n    return conv_3","6188cc88":"def convolutional_auto_encoder():\n    '''Builds the entire autoencoder model.'''\n    inputs = tf.keras.layers.Input(shape=(28, 28, 1,))\n    encoder_output = encoder(inputs)\n    bottleneck_output, encoder_visualization = bottle_neck(encoder_output)\n    decoder_output = decoder(bottleneck_output)\n  \n    model = tf.keras.Model(inputs =inputs, outputs=decoder_output)\n    encoder_model = tf.keras.Model(inputs=inputs, outputs=encoder_visualization)\n    return model, encoder_model","4cf6ad99":"convolutional_model, convolutional_encoder_model = convolutional_auto_encoder()\nconvolutional_model.summary()","566047ef":"train_steps = 60000 \/\/ BATCH_SIZE\nvalid_steps = 60000 \/\/ BATCH_SIZE\n\nconvolutional_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')\nconv_model_history = convolutional_model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=test_dataset, validation_steps=valid_steps, epochs=40)","d04633f1":"def display_one_row(disp_images, offset, shape=(28, 28)):\n    '''Display sample outputs in one row.'''\n    for idx, noisy_image in enumerate(disp_images):\n        plt.subplot(3, 10, offset + idx + 1)\n        plt.xticks([])\n        plt.yticks([])\n        noisy_image = np.reshape(noisy_image, shape)\n        plt.imshow(noisy_image, cmap='gray')\n\n\ndef display_results(disp_input_images, disp_encoded, disp_predicted, enc_shape=(8,4)):\n    '''Displays the input, encoded, and decoded output values.'''\n    plt.figure(figsize=(15, 5))\n    display_one_row(disp_input_images, 0, shape=(28,28,))\n    display_one_row(disp_encoded, 10, shape=enc_shape)\n    display_one_row(disp_predicted, 20, shape=(28,28,))","5cb8cab1":"# take 1 batch of the dataset\ntest_dataset = test_dataset.take(1)\n\n# take the input images and put them in a list\noutput_samples = []\nfor input_image, image in tfds.as_numpy(test_dataset):\n      output_samples = input_image\n\n# pick 10 indices\nidxs = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\n# prepare test samples as a batch of 10 images\nconv_output_samples = np.array(output_samples[idxs])\nconv_output_samples = np.reshape(conv_output_samples, (10, 28, 28, 1))\n\n# get the encoder ouput\nencoded = convolutional_encoder_model.predict(conv_output_samples)\n\n# get a prediction for some values in the dataset\npredicted = convolutional_model.predict(conv_output_samples)\n\n# display the samples, encodings and decoded values!\ndisplay_results(conv_output_samples, encoded, predicted, enc_shape=(7,7))","06776521":"## Compile and Train the Model","714d8fa4":"You will use the same model from the previous lab.","92de843f":"## Prepare the Dataset","d3156bcd":"# Ungraded Lab: Denoising with a CNN Autoencoder\n\nIn the final lab for this week, you will introduce noise to the Fashion MNIST dataset and train an autoencoder to reconstruct the original input images.","33a78ca6":"<img src=\"https:\/\/drive.google.com\/uc?export=view&id=15zh7bst9KKvciRdCvMAH7kXt3nNkABzO\" width=\"75%\" height=\"75%\"\/>","195e4cb4":"## Build the Model","e6e320e0":"## Imports","25549f33":"## Display sample results\n\nLet's see if the model can generate the clean image from noisy inputs.","d7abc3a7":"You will prepare the train and test sets a little differently this time. Instead of just normalizing the images, you will also introduce random noise and the generated images will be used as input to your model. The target or label will still be the clean images."}}