{"cell_type":{"53abc0f6":"code","e382445c":"code","47ab49a0":"code","f7a736d4":"code","bb76e728":"code","b631ba5c":"code","72d23264":"code","001f134d":"code","e9e0c7c9":"code","bfbf21bb":"code","9ee52f71":"code","35dd1a46":"code","0155dc1c":"code","525afc01":"code","d021b3b5":"code","1a64d3e7":"code","27fada80":"code","a86fde0c":"code","37c6badb":"code","cb76b25b":"code","b731f244":"code","8eb4fe32":"code","44279b11":"code","812b2242":"code","fb4a50da":"code","fe76740d":"code","a4a0679e":"code","37727787":"code","7ca92493":"code","26b65988":"markdown","0e03023b":"markdown","1ac98a69":"markdown"},"source":{"53abc0f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e382445c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","47ab49a0":"toyota = pd.read_csv('\/kaggle\/input\/used-car-dataset-ford-and-mercedes\/toyota.csv')\n\ntoyota.head()","f7a736d4":"toyota.isnull().sum()","bb76e728":"toyota.info()","b631ba5c":"toyota.describe()","72d23264":"skew = toyota.describe().T\nskew['coef']=skew['std']\/skew['mean']\n\nskew","001f134d":"toyota.describe(include='O')","e9e0c7c9":"cat_columns = ['model', 'transmission', 'fuelType']\nnum_columns = ['year', 'price', 'mileage', 'tax', 'mpg', 'engineSize']\nnum_columns_no_label = ['year', 'mileage', 'tax', 'mpg', 'engineSize']","bfbf21bb":"toyota['price'].value_counts().plot(kind='hist')\nplt.title = 'Price Distribution'\nplt.show()","9ee52f71":"fig, ax = plt.subplots(3, 2, figsize=(20,30))\nc=1\nfor i in toyota[num_columns].columns:\n    plt.subplot(4,2,c)\n    sns.distplot(toyota[i], color='blue')\n    c=c+1\n    plt.xlabel(i, fontsize=9)\n    plt.legend()\nplt.show()","35dd1a46":"fig, ax = plt.subplots(3, 1, figsize=(15,30))\nc=1\nfor i in toyota[cat_columns].columns:\n    plt.subplot(3,1,c)\n    sns.countplot(toyota[i])\n    c=c+1\n    plt.xlabel(i, fontsize=9)\n    plt.legend()\nplt.show()","0155dc1c":"plt.figure(figsize=(10,6))\nsns.heatmap(toyota.corr(), annot=True, cmap='coolwarm')","525afc01":"X=toyota.drop(['price'], axis=1)\nY=toyota['price']","d021b3b5":"toyota2 = pd.get_dummies(toyota, columns=cat_columns)","1a64d3e7":"toyota2.head()","27fada80":"toyota2.info()","a86fde0c":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","37c6badb":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nscaler=StandardScaler()\n\nx_train= scaler.fit_transform(x_train[num_columns_no_label])\nx_test= scaler.transform(x_test[num_columns_no_label])","cb76b25b":"X=toyota2.drop(['price'], axis=1)\nY=toyota2['price']","b731f244":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","8eb4fe32":"from sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.tree import DecisionTreeRegressor","44279b11":"lin_model = LinearRegression()\nlin_model.fit(x_train, y_train)\nlin_pred = lin_model.predict(x_test)\nprint('Train Accuracy: %f' % lin_model.score(x_train, y_train))\nprint('Test Accuracy: %f' % lin_model.score(x_test, y_test))","812b2242":"from sklearn.model_selection import ShuffleSplit, cross_val_score, GridSearchCV\n\nCV=ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)","fb4a50da":"def find_best(X,y):\n    algos = {\n        'linear': {\n            'model': LinearRegression(),\n            'params': {\n                'normalize': [True, False]\n            }\n        },\n        'lasso': {\n            'model': Lasso(),\n            'params': {\n                'alpha': [1,2], \n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree': {\n            'model': DecisionTreeRegressor(),\n            'params': {\n                'criterion': ['mse','friedman_mse'], \n                'splitter': ['best', 'random']\n            }\n        }\n    }\n    scores=[]\n    cv=ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n    for algo_name, config in algos.items():\n        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score= False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_\n        })\n    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n\n","fe76740d":"find_best(X,Y)","a4a0679e":"final_model = DecisionTreeRegressor()\n\nfinal_model.fit(x_train, y_train)\nfinal_pred = final_model.predict(x_test)\nprint('Train Accuracy: %f' % final_model.score(x_train, y_train))\nprint('Test Accuracy: %f' % final_model.score(x_test, y_test))","37727787":"print('R2 Score: %f' % r2_score(y_test, final_pred)) ","7ca92493":"plt.scatter(y_test, final_pred)\nplt.xlabel('Actual Labels')\nplt.ylabel('Predicted Labels')\n\nz=np.polyfit(y_test, final_pred, 1)\np = np.poly1d(z)\nplt.plot(y_test, p(y_test), color='magenta')\nplt.show()","26b65988":"I'm going to make a function to find the best model","0e03023b":"EngineSize and Price have high positive correlation\n(Year and Mileage) and (tax and mpg) and (price and mileage) are significantly negatively correlated","1ac98a69":"None have a particularly high coefficient of variation"}}