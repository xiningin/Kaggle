{"cell_type":{"bc9899b5":"code","031ec1fa":"code","ab0440a8":"code","0ea827f7":"code","190332f2":"code","723d35c8":"code","c116ba5f":"code","66311f66":"code","22feece7":"code","e1893094":"code","080293e5":"code","51b6e65f":"code","29ba5e92":"code","5d464e5e":"code","e24273b8":"code","5c5a16ac":"code","ac350f5e":"code","ae3301e9":"code","163c8fa6":"code","77824f16":"code","eb83f94b":"code","b48aad01":"code","8e9836ee":"code","3ae12d46":"code","14c035a6":"code","2bf72813":"code","95b3ca62":"code","eeecc0a6":"code","2402847d":"code","d23b1bd4":"code","df872bb9":"code","1bb01264":"code","0f991e2a":"code","8a5b31fc":"code","5e841d71":"code","20a0e283":"code","925ff7bd":"code","d9b1c9fc":"code","ff7c6fe5":"code","37f457ea":"code","b39b30e8":"code","bf081c98":"code","15b5e98c":"code","d2ff68b3":"code","e26b6359":"code","1b00d806":"code","1700a916":"code","3a207bb3":"code","c4380d3b":"code","5d412af2":"code","bfe82539":"code","ba4fe5fa":"code","44c245bb":"code","8ab7439f":"code","66a64794":"code","b7311279":"code","1f44bca7":"code","724f6c0d":"code","9f59b65c":"code","2bccf054":"code","30472844":"code","92a470bc":"code","2681f2ad":"code","acd7b4bf":"code","aec3bce8":"code","80c1622b":"code","5464ca73":"code","531d92f2":"code","c604b8f4":"code","8bec1cbc":"code","c71bab20":"code","1fd5caac":"code","2bbe9e05":"code","f558aee4":"code","d4adc98b":"code","3ec70ea5":"code","40dedc3b":"code","4094a8fc":"code","894eebd7":"code","273245bb":"code","4546b9a1":"code","f6317709":"code","33a51f50":"code","bed7a429":"code","8e243629":"code","84fd7f5f":"code","aa42f230":"code","23db6219":"code","ea240e5c":"code","0589020d":"code","ffd2f912":"code","ecc326fd":"code","b738a852":"code","ca6fc4b3":"code","8ed292e4":"code","717fa4db":"code","9aa4b9c2":"code","56ef71e8":"code","f50ed3d7":"code","198376f3":"code","e2523c0e":"code","87c85f8b":"code","f5190ed4":"code","8b738f42":"code","e9b43f90":"code","220bf7a2":"markdown","ed21f815":"markdown","ddd13811":"markdown","37e04eff":"markdown","30d456d4":"markdown","c449e78c":"markdown","6be50fcb":"markdown","e5610c8f":"markdown"},"source":{"bc9899b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","031ec1fa":"data = pd.read_csv('\/kaggle\/input\/pokemon\/Pokemon.csv')\ndata.info()","ab0440a8":"data.corr()","0ea827f7":"\nf,ax = plt.subplots(figsize=(16, 16))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","190332f2":"data.head(10)","723d35c8":"data.columns","c116ba5f":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","66311f66":"# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defence')\nplt.title('Attack Defense Scatter Plot')            # title = title of plot\nplt.show()","22feece7":"# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 70,figsize = (12,12))\nplt.show()","e1893094":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","080293e5":"#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","51b6e65f":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)","29ba5e92":"# In order to run all code you need to take comment this line\ndel dictionary         # delete entire dictionary     \nprint(dictionary)       # it gives error because dictionary is deleted","5d464e5e":"data = pd.read_csv('..\/input\/pokemon\/Pokemon.csv')\nseries = data['Defense']        # data['Defense'] = series\nprint(type(series))\ndata_frame = data[['Defense']]  # data[['Defense']] = data frame\nprint(type(data_frame))","e24273b8":"# Comparison operator\nprint(3 > 2)\nprint(3!=2)\n# Boolean operators\nprint(True and False)\nprint(True or False)","5c5a16ac":"# 1 - Filtering Pandas data frame\nx = data['Defense']>200     # There are only 3 pokemons who have higher defense value than 200\nprint(x)\ndata[x]","ac350f5e":" #2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['Defense']>200, data['Attack']>100 )]","ae3301e9":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Defense']>200) & (data['Attack']>100)]","163c8fa6":"lis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index,value in data[['Attack']][0:1].iterrows():\n    print(index,\" : \",value)","77824f16":"num1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nfor i in num1:\n    if i == 10 :\n        print(i**2)\n    else :\n        print(i-5)\nnum3 = [i**2 if i < 7 else i+5 for i in num1]\nprint(num2)\nprint(num3)","eb83f94b":"def tuble_ex():\n    \"\"\" return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","b48aad01":"# guess print what\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x)      # x = 2 global scope\nprint(f())    # x = 3 local scope","8e9836ee":"# What if there is no local scope\nx = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","3ae12d46":"import builtins\ndir(builtins)","14c035a6":"#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())    ","2bf72813":"def f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","95b3ca62":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)","eeecc0a6":"def f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():               # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456)","2402847d":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(4))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))","d23b1bd4":"number_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","df872bb9":"# iteration example\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(*it)         # print remaining iteration","1bb01264":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)","0f991e2a":"un_zip = zip(*z_list)\nprint(un_zip)\nun_list1,un_list2 = list(un_zip) # unzip returns tuble\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))","8a5b31fc":"# Example of list comprehension\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)","5e841d71":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","20a0e283":" #lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed)\/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later","925ff7bd":"data.info()","d9b1c9fc":"data.describe()","ff7c6fe5":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","37f457ea":"# For example lets look frequency of pokemom types\nprint(data['Type 2'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","b39b30e8":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","bf081c98":"# For example max HP is 255 or min defense is 5\ndata['Type 2'].describe() #ignore null entries","15b5e98c":"data.dropna(inplace = True)  \ndata.describe()","d2ff68b3":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","e26b6359":"data_new = data.head()    # I only take 5 rows into new data\ndata_new","1b00d806":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","1700a916":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","3a207bb3":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","c4380d3b":"data3 = data['Name'].head()\ndata1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data3,data1,data2],axis =1) # axis = 0 : adds dataframes in row\nconc_data_col","5d412af2":"data.dtypes\n","bfe82539":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","ba4fe5fa":"data.info()\ndata.head(30)","44c245bb":"data[\"Type 2\"].value_counts(dropna =False)","8ab7439f":"\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1.dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?\ndata1.info()","66a64794":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","b7311279":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","1f44bca7":"data[\"Type 2\"].fillna('empty',inplace = True)\ndata[\"Type 2\"].value_counts(dropna =False)","724f6c0d":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","9f59b65c":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\nprint(zipped)\ndata_dict = dict(zipped)\ndata_dict\ndf = pd.DataFrame(data_dict)\ndf","2bccf054":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","30472844":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","92a470bc":"# Plotting all data \ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\n# it is confusing","2681f2ad":"# subplots\ndata1.plot(subplots = True)\nplt.show()","acd7b4bf":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","aec3bce8":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = False)","80c1622b":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\n","5464ca73":"data.describe()","531d92f2":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","c604b8f4":"data2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","8bec1cbc":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","c71bab20":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","1fd5caac":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","2bbe9e05":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","f558aee4":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","d4adc98b":"# read data\ndata = pd.read_csv('..\/input\/pokemon\/Pokemon.csv')\ndata= data.set_index(\"#\")\ndata.head()","3ec70ea5":"# indexing using square brackets\ndata[\"HP\"][1]","40dedc3b":"# using column attribute and row label\ndata.HP[1]","4094a8fc":"# using loc accessor\ndata.loc[1,[\"HP\"]]","894eebd7":"data[[\"HP\",\"Attack\"]]","273245bb":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","4546b9a1":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"] ","f6317709":"# Reverse slicing \ndata.loc[10:1:-1,\"Name\":\"Defense\"] ","33a51f50":"# From something to end\ndata.loc[1:10,\"Speed\":] ","bed7a429":"# Creating boolean series\nboolean = data.HP > 200\nprint(boolean)\ndata[boolean]","8e243629":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter]","84fd7f5f":"# Filtering column based others\ndata.HP[data.Speed<15]","aa42f230":"def div(n):\n    return n\/2\ndata.HP.apply(div)","23db6219":"# Or we can use lambda function\ndata.HP.apply(lambda n : n\/2)","ea240e5c":"data[\"total_power\"] = data.Attack + data.Defense\ndata.head()","0589020d":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","ffd2f912":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()","ecc326fd":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)\ndata1.loc[\"Fire\",\"Flying\"] # howw to use indexes","b738a852":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","ca6fc4b3":"df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","8ed292e4":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1","717fa4db":"df1.unstack(level=0)","9aa4b9c2":"df1.unstack(level=1)","56ef71e8":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","f50ed3d7":"df","198376f3":"pd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","e2523c0e":"df","87c85f8b":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","f5190ed4":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","8b738f42":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","e9b43f90":"df.info()","220bf7a2":"RESAMPLING PANDAS TIME SERIES\nResampling: statistical method over different time intervals\nNeeds string to specify frequency like \"M\" = month or \"A\" = year\nDownsampling: reduce date time rows to slower frequency like from daily to weekly\nUpsampling: increase date time rows to faster frequency like from daily to hourly\nInterpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","ed21f815":"* single column = series\n* NaN = not a number\n* dataframe.values = numpy","ddd13811":"### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","37e04eff":"INDEXING DATA FRAMES\nIndexing using square brackets\nUsing column attribute and row label\nUsing loc accessor\nSelecting only some columns","30d456d4":"DEFAULT and FLEXIBLE ARGUMENTS\nDefault argument example:\ndef f(a, b=1):\n  \"\"\" b = 1 is default argument\"\"\"\nFlexible argument example:\ndef f(*args):\n \"\"\" *args can be one or more\"\"\"\n\ndef f(** kwargs)\n \"\"\" **kwargs is a dictionary\"\"\"\n\n\nlets write some code to practice","c449e78c":"EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\noutliers: the value that is considerably higher or lower from rest of the data\n\nLets say value at 75% is Q3 and value at 25% is Q1.\nOutlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\nWe will use describe() method. Describe method includes:\ncount: number of entries\nmean: average of entries\nstd: standart deviation\nmin: minimum entry\n25%: first quantile\n50%: median or second quantile\n75%: third quantile\nmax: maximum entry\n\nWhat is quantile?\n\n1,4,5,6,8,9,11,12,13,14,15,16,17\nThe median is the number that is in middle of the sequence. In this case it would be 11.\n\nThe lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n\nThe upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","6be50fcb":"DATA TYPES\nThere are 5 basic data types: object(string),boolean, integer, float and categorical.\nWe can make conversion data types like from str to categorical or from int to float\nWhy is category important:\n\nmake dataframe smaller in memory\ncan be utilized for anlaysis especially for sklear(we will learn l","e5610c8f":"### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"}}