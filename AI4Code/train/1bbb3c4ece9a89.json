{"cell_type":{"34fbef82":"code","f7571b15":"code","6dc5736d":"code","333110fb":"code","759081ac":"code","20ecaa81":"code","70c12319":"code","d5346b9f":"code","4dcce1b6":"code","e3210f8a":"code","04b5a8d9":"code","78b6d24e":"code","7ccb294c":"code","560296b0":"code","c6877c4c":"code","4b291a24":"code","d99295a1":"code","4d3bd2e3":"code","a2fb29e5":"code","965e5c18":"code","07da479a":"code","ca7231e4":"code","3dd62ce7":"code","9519f052":"code","c61f04c7":"code","142d5011":"code","1ecc3c68":"code","73b7d403":"code","53fa911b":"code","2a95e3dc":"code","3db3e63b":"code","47b36a3c":"markdown","f1d1a0d0":"markdown","d9539da1":"markdown","b3ec2459":"markdown","b6412c89":"markdown","5015d2e1":"markdown","10043048":"markdown","56915f93":"markdown","8dd25321":"markdown","add56644":"markdown","da4e12e9":"markdown","bdb84b4e":"markdown","68332a78":"markdown","d6982592":"markdown","6a332b51":"markdown","ee6f2d22":"markdown","8fdcdb96":"markdown","2aa48e25":"markdown","89204642":"markdown","95410210":"markdown","b4c43fc8":"markdown","a6c5097b":"markdown","8b5d9945":"markdown","09f28fdf":"markdown","73f2903a":"markdown","76353971":"markdown","f09301c2":"markdown","3129726b":"markdown","0d6410b8":"markdown"},"source":{"34fbef82":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom matplotlib import pyplot\nfrom numpy import where\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","f7571b15":"# Training data\ndata = pd.read_csv('..\/input\/customer-churn-prediction-pharmaceutical-data\/purchase_data_bill_level_sept.csv')\ndata[\"created_at_bill\"] = pd.to_datetime(data[\"created_at_bill\"]).dt.date\ndata.head()","6dc5736d":"# test target data\ntest_target = pd.read_csv('..\/input\/customer-churn-prediction-pharmaceutical-data\/out_of_time_test_oct.csv')\ntest_target = test_target.rename(columns={\"oct_purchase_flag\": \"flag\"})\ntest_target.head()","333110fb":"data.shape","759081ac":"df_pivot = pd.DataFrame({'types': data.dtypes,\n                         'nulls': data.isna().sum(),\n                          '% nulls': data.isna().sum() \/ data.shape[0],\n                          'size': data.shape[0],\n                          'uniques': data.nunique()})\ndf_pivot","20ecaa81":"data.payment_method.hist()","70c12319":"for i in [7898076, 6754310, 6076893]:\n    print(data[data[\"customer_ref_id\"]==i ][[\"customer_ref_id\",\"payment_method\",\"total_spend_bill\",\"total_quantity_bill\"]])","d5346b9f":"#based on the above we can impute the missing values as following:\n# 1. for customer 7898076, most payments are done with card so we'll impute that value\n# 2. for customer 6754310, the more expensive purchases were with phonepe and since this pament is above average we will impute phonepe\n# 3. for customer 6076893, we will impute cash since most purchases under 100 are paid with cash\n\ndata[\"payment_method\"].loc[50493] = \"card\"\ndata[\"payment_method\"].loc[82850] = \"phonepe\"\ndata[\"payment_method\"].loc[83285] = \"cash\"\n\n#now that we've made the necessary adjustments we can copy the dataset for when we prepare the test set\ntest = data.copy()","4dcce1b6":"data.describe()","e3210f8a":"target = data.copy()\n\ntarget[\"flag\"] = [1 if i.month == 9 else 0 for i in target[\"created_at_bill\"]]\n\n#take the last instance of each customer_ref_id sorted by created_at_bill and keep necessary variables\ntarget = target.sort_values('created_at_bill').groupby('customer_ref_id').tail(1)\ntarget = target[['customer_ref_id','flag']]\n\ntarget.flag.hist()","04b5a8d9":"target.head()","78b6d24e":"#first, for the training set, we will take out all instances of september\ndata[\"flag\"] = [1 if x.month == 9 else 0 for x in data[\"created_at_bill\"]]\nprint(data.flag.value_counts())\n\ndata = data[data[\"flag\"] == 0]\nprint(data.flag.value_counts())\n\ndata = data.drop('flag', axis=1)","7ccb294c":"#training data\nsummary_reg = data.groupby('customer_ref_id')[[col for col in data if col not in [\"doctor_ref_id\", \"customer_ref_id\", \"bill_ref_id\", \"store_ref_id\", \"payment_method\" \"created_at_bill\"]]].agg(['mean'])\nsummary_reg.columns = ['_'.join(col).strip() for col in summary_reg.columns.values]\n\n#test data\nsummary_reg_test = test.groupby('customer_ref_id')[[col for col in test if col not in [\"doctor_ref_id\", \"customer_ref_id\", \"bill_ref_id\", \"store_ref_id\", \"payment_method\" \"created_at_bill\"]]].agg(['mean'])\nsummary_reg_test.columns = ['_'.join(col).strip() for col in summary_reg_test.columns.values]","560296b0":"#training set\ndata[\"count\"] = 1\npayment = data[[\"customer_ref_id\", \"count\"]].groupby(by=\"customer_ref_id\").count()\n\n#test set\ntest[\"count\"] = 1\npayment_test = test[[\"customer_ref_id\", \"count\"]].groupby(by=\"customer_ref_id\").count()","c6877c4c":"################\n##training set##\n################\n\n#sort the data\nd_sort = data.sort_values(['customer_ref_id', 'created_at_bill'], ascending=[1, 1])\n\n#take the last instance of each customer_ref_id sorted by created_at_bill and keep necessary variables\nd_sort2 = d_sort.sort_values('created_at_bill').groupby('customer_ref_id').tail(1)\nd_sort2 = d_sort2[['customer_ref_id', 'created_at_bill','payment_method']]\n\n#to train we will do days before September but when we test the model we will use October\nfrom datetime import datetime\nend = datetime.strptime('01\/09\/19', '%d\/%m\/%y').date()\n\n#Create days before vaariable\nd_sort2['days_before'] = [(end - x).days for x in d_sort2[\"created_at_bill\"]]\nd_sort2 = d_sort2[[\"customer_ref_id\", \"payment_method\",\"days_before\"]]\n\n################\n####test set####\n################\n\n#sort the data\nd_sort_test = test.sort_values(['customer_ref_id', 'created_at_bill'], ascending=[1, 1])\n\n#take the last instance of each customer_ref_id sorted by created_at_bill and keep necessary variables\nd_sort2_test = d_sort_test.sort_values('created_at_bill').groupby('customer_ref_id').tail(1)\nd_sort2_test = d_sort2_test[['customer_ref_id', 'created_at_bill','payment_method']]\n\n#to train we will do days before September but when we test the model we will use October\nend_test = datetime.strptime('01\/10\/19', '%d\/%m\/%y').date()\n\n#Create days before vaariable\nd_sort2_test['days_before'] = [(end_test - x).days for x in d_sort2_test[\"created_at_bill\"]]\nd_sort2_test = d_sort2_test[[\"customer_ref_id\", \"payment_method\",\"days_before\"]]","4b291a24":"#training set\nmerged = summary_reg.merge(payment, how=\"left\", on=\"customer_ref_id\").merge(d_sort2, how=\"left\", on=\"customer_ref_id\")\n\n#test set\nmerged_test = summary_reg_test.merge(payment_test, how=\"left\", on=\"customer_ref_id\").merge(d_sort2_test, how=\"left\", on=\"customer_ref_id\")","d99295a1":"#training set\nmerged2 = pd.get_dummies(merged)\n\n#test set\ntest = pd.get_dummies(merged_test)","4d3bd2e3":"#training set\ntrain = merged2.merge(target, how=\"left\", on=\"customer_ref_id\")\n\n#test set\ntest = test.merge(test_target, how=\"left\", on=\"customer_ref_id\")","a2fb29e5":"style.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (30,30))\n## Plotting heatmap. Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(train.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, );\nplt.title(\"Heatmap of all the Features of Train data set\", fontsize = 25);","965e5c18":"corr = train[train.columns[1:]].corr()['flag'][:].sort_values(ascending=True)\n# print(corr)\n\ncorr[:-1].plot(kind='barh', figsize = (20,10), fontsize = 17)\n","07da479a":"#Libraries for modeling\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\n\n# Import required libraries for performance metrics\nfrom sklearn import metrics\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\n\n# Import required libraries for machine learning classifiers\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression","ca7231e4":"# Before we begin modeling let's drop the customer_ref_if, which is a unique identifier, in both the test and training set\ntrain = train.drop(columns=['customer_ref_id'])\ntest = test.drop(columns=['customer_ref_id'])","3dd62ce7":"print(train.shape)\nprint(test.shape)","9519f052":"accuracies = {}\nkappaScores= {}\nf1scores={}\n\ndef Models(models, X_train, X_test, y_train, y_test, title):\n    model = models\n    model.fit(X_train,y_train)\n    \n    test_matrix = pd.crosstab(y_test, model.predict(X_test), rownames=['Actual'], colnames=['Predicted'])\n    \n    g2 = sns.heatmap(test_matrix, annot=True, fmt=\".1f\",cbar=False)\n    g2.set_title(title)\n    g2.set_ylabel('Total Observed October Sales = {}'.format(y_test.sum()), rotation=90)\n    g2.set_xlabel('Accuracy score for Testing Dataset = {}'.format(accuracy_score(model.predict(X_test), y_test)))\n    \n    #record metrics\n    accuracies[title]=accuracy_score(model.predict(X_test), y_test)*100\n    f1scores[title]=f1_score(model.predict(X_test), y_test)*100\n    kappaScores[title]=cohen_kappa_score(model.predict(X_test), y_test)*100\n    \n    plt.show()","c61f04c7":"import plotly.graph_objects as go\n\ndef Featureimportances(models, X_train, y_train):\n    model = models\n    model.fit(X_train,y_train)\n    importances = model.feature_importances_\n    features = X_train.columns\n    if len(importances)<len(features): \n        features = X_train.columns[:len(importances)]\n    else:\n        importances = model.feature_importances_[:len(features)]\n    imp = pd.DataFrame({'Features': features, 'Importance': importances})\n    imp = imp.sort_values(by = 'Importance', ascending=False)[:15]\n    imp['Sum Importance'] = imp['Importance'].cumsum()\n    \n    fig = go.Figure()\n    fig.add_trace(go.Bar(x=imp.Features,y=imp.Importance, marker=dict(color=list(range(20)), colorscale=\"Sunsetdark\")))\n\n    fig.update_layout(title=\"Feature Importance\",\n                                 xaxis_title=\"Features\", yaxis_title=\"Importance\",title_x=0.5, paper_bgcolor=\"mintcream\",\n                                 title_font_size=20)\n    fig.show()","142d5011":"X_train = train.drop(columns=['flag'],axis=1)\ny_train = train['flag']\n\nX_test = test.drop(columns=['flag'],axis=1)\ny_test = test['flag']","1ecc3c68":"# Define dictionary with performance metrics\nscoring = {'accuracy':make_scorer(accuracy_score), \n           'precision':make_scorer(precision_score),\n           'recall':make_scorer(recall_score), \n           'f1_score':make_scorer(f1_score)}\n\n# Instantiate the machine learning classifiers\nlog_model = LogisticRegression(max_iter=10000)\nsvc_model = LinearSVC(dual=False)\ndtr_model = DecisionTreeClassifier()\nrfc_model = RandomForestClassifier()\ngnb_model = GaussianNB()\nxgb_model = XGBClassifier()\nlgb_model = LGBMClassifier()\nknn_model = KNeighborsClassifier(n_neighbors=3)\ngbc_model = GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_features=2, max_depth=2, random_state=0)\nlda_model = LinearDiscriminantAnalysis()","73b7d403":"def models_evaluation(X, y, folds):\n    \n        # Perform cross-validation to each machine learning classifier\n    log = cross_validate(log_model, X, y, cv=folds, scoring=scoring)\n    svc = cross_validate(svc_model, X, y, cv=folds, scoring=scoring)\n    dtr = cross_validate(dtr_model, X, y, cv=folds, scoring=scoring)\n    rfc = cross_validate(rfc_model, X, y, cv=folds, scoring=scoring)\n    gnb = cross_validate(gnb_model, X, y, cv=folds, scoring=scoring)\n    \n    xgb = cross_validate(xgb_model, X, y, cv=folds, scoring=scoring)\n    lgb = cross_validate(lgb_model, X, y, cv=folds, scoring=scoring)\n    knn = cross_validate(knn_model, X, y, cv=folds, scoring=scoring)\n    gbc = cross_validate(gbc_model, X, y, cv=folds, scoring=scoring)\n    lda = cross_validate(lda_model, X, y, cv=folds, scoring=scoring)\n\n\n    # Create a data frame with the models perfoamnce metrics scores\n    models_scores_table = pd.DataFrame({'Logistic Regression':[log['test_accuracy'].mean(),\n                                                               log['test_precision'].mean(),\n                                                               log['test_recall'].mean(),\n                                                               log['test_f1_score'].mean(),\n                                                               log['fit_time'].mean(),\n                                                               log['score_time'].mean()],\n                                       \n                                      'Support Vector Classifier':[svc['test_accuracy'].mean(),\n                                                                   svc['test_precision'].mean(),\n                                                                   svc['test_recall'].mean(),\n                                                                   svc['test_f1_score'].mean(),\n                                                                   svc['fit_time'].mean(),\n                                                                   svc['score_time'].mean()],\n                                       \n                                      'Decision Tree':[dtr['test_accuracy'].mean(),\n                                                       dtr['test_precision'].mean(),\n                                                       dtr['test_recall'].mean(),\n                                                       dtr['test_f1_score'].mean(),\n                                                       dtr['fit_time'].mean(),\n                                                       dtr['score_time'].mean()],\n                                       \n                                      'Random Forest':[rfc['test_accuracy'].mean(),\n                                                       rfc['test_precision'].mean(),\n                                                       rfc['test_recall'].mean(),\n                                                       rfc['test_f1_score'].mean(),\n                                                       rfc['fit_time'].mean(),\n                                                       rfc['score_time'].mean()],\n                                       \n                                      'XGB':[xgb['test_accuracy'].mean(),\n                                                              xgb['test_precision'].mean(),\n                                                              xgb['test_recall'].mean(),\n                                                              xgb['test_f1_score'].mean(),\n                                                              xgb['fit_time'].mean(),\n                                                              xgb['score_time'].mean()],\n                                        \n                                       'LGB':[lgb['test_accuracy'].mean(),\n                                                              lgb['test_precision'].mean(),\n                                                              lgb['test_recall'].mean(),\n                                                              lgb['test_f1_score'].mean(),\n                                                              lgb['fit_time'].mean(),\n                                                              lgb['score_time'].mean()],\n                                        \n                                       'KNN':[knn['test_accuracy'].mean(),\n                                                              knn['test_precision'].mean(),\n                                                              knn['test_recall'].mean(),\n                                                              knn['test_f1_score'].mean(),\n                                                              knn['fit_time'].mean(),\n                                                              knn['score_time'].mean()],\n                                        \n                                       'GBC':[gbc['test_accuracy'].mean(),\n                                                              gbc['test_precision'].mean(),\n                                                              gbc['test_recall'].mean(),\n                                                              gbc['test_f1_score'].mean(),\n                                                              gbc['fit_time'].mean(),\n                                                              gbc['score_time'].mean()],\n                                        \n                                        'LDA':[lda['test_accuracy'].mean(),\n                                                              lda['test_precision'].mean(),\n                                                              lda['test_recall'].mean(),\n                                                              lda['test_f1_score'].mean(),\n                                                              lda['fit_time'].mean(),\n                                                              lda['score_time'].mean()],\n                                       \n                                       'Gaussian Naive Bayes':[gnb['test_accuracy'].mean(),\n                                                              gnb['test_precision'].mean(),\n                                                              gnb['test_recall'].mean(),\n                                                              gnb['test_f1_score'].mean(),\n                                                              gnb['fit_time'].mean(),\n                                                              gnb['score_time'].mean()]},\n                                       \n                                       \n                                      \n                                      index=['Accuracy', 'Precision', 'Recall', 'F1 Score', 'fit_time', 'score_time'])\n    \n    # Add 'Best Score' column\n    models_scores_table['Best Score'] = models_scores_table.idxmax(axis=1)\n    \n    # Return models performance metrics scores data frame\n    return(models_scores_table)\n","53fa911b":"models_evaluation(X_train, y_train, 5)","2a95e3dc":"# below is the confusion matrix using the test or holdout set (this is the actual October set)\ntitle = 'LGBMClassifier'\n%time Models(LGBMClassifier(),X_train, X_test, y_train, y_test, title)","3db3e63b":"Featureimportances(LGBMClassifier(), X_train, y_train)","47b36a3c":"## One hot encoding to fix the payment_method varible","f1d1a0d0":"# Training Set Construction","d9539da1":"# Import Dataset","b3ec2459":"# Modeling","b6412c89":"# Pharma Churn Prediction","5015d2e1":"## Append target variable to the datasets","10043048":"The above feature importance chart shows the top 15 features. We see that by far the most impactful feature is days_before which measures the number of days between October first and the most recent purchase of that particular customer. We expected this based on the strong correlation with our target variable. The next few variables captures the average amount of cronic drugs purchased by the customer for each visit, the total amout of times the customer made a purchase, and the average amount spent by the customer. Although all of these features intuitivly make sense it is interesting to see which fields the models prefers and by how much","56915f93":"Below we are comparing multiple models using a 5 fold cross validation. It is important to note that we are not using the test set (or holdout) with the actual October values. Thse will be used when evaluating the chosen model","8dd25321":"## Table 1: Grouped data mean of each numeric value","add56644":"## Explore Model Metrics","da4e12e9":"In the end I created a powerful model by organizing the data and testing different models. I began by sculpting the data so that every observation represents a customer while still maintaining value in the data. I did this by adjusting each field based on the field type and understanding how they interact with my target variable. I chose to take the mean of many of our numeric variables because I thought that would accurately represent the behavior of the customer. I also made sure to keep track of the number of times each customer made a purchase and decided to keep the last instance of how the customer paid, using one-hot encoding to translate that field so that our model could digest the data. Finally, I counted the number of days since each customer's most recent visit until the first day of October, this ended up being my most predictive feature in our model.\n\nAfter I organized the data, I ran 10 classification machine learning models. I compared each model by using a variety of metrics, discussed how to go about choosing the model based on the performance metrics of each model, and considered the business problem at hand. I ultimately chose the model with the best accuracy score although I went through different scenarios on how and when I would have chose a model based on any of the other metrics listed above.","bdb84b4e":"Below are a few functions to streamline modeling","68332a78":"## Import Libraries","d6982592":"## Descision ","6a332b51":"## Results","ee6f2d22":"We will choose the model that contains the largest accuracy, which based on the above table is LGBM Classifier. The accuracy reflects the amount of correct true and false predictions made and therefore is a good representation of the overall performance of the model. in this notebook we aim to predict whether a customer will make a purchase in the month of October, based on this we can explore other models to choose. If the pharma company's goal is to prevent lapse and thus identify those who will not purchase in October, then we might consider choosing a model based on the specificity which I did not calculate. On the other hand, if we were only interested in having the model maximize the number of predictions that predicted October correctly (ignoring which predictions the model accurately predicted not an October sale) we could focus on the Recall. Nonetheless, we will move forward with the LGBM or Light Gradient Boosting Model.  ","8fdcdb96":"# Model Output","2aa48e25":"## Organize the data for the training and test set","89204642":"### Impute payment method","95410210":"# Conclusion","b4c43fc8":"## Table 3: Get payment method and \"days before\" variable","a6c5097b":"## Create a target variable for the training set","8b5d9945":"## Exploritory Analysis","09f28fdf":"# Future Next Steps","73f2903a":"## Correlation","76353971":"When I revisit this project, I hope to spend more time on tuning the hyperparameters. After I chose the LGBM Classification model I experimented with tweaking the hyperparameters but in each case it failed to significantly boost the performance of the model when scoring the model using the test set. Because of this I left that analysis out.","f09301c2":"In this notebook I will predict whether a pharmacy customer will make a purchase in the month of October using data we have from the preceding months. To give a bit more detail we will use the data from April 2019 to September 2019 as my training set and the October data as my test set. Because this a classification problem, we will assign our target variable called \"flag\" a value of 1 if an October purchase is made and 0 if an October purchase is not made. In this notebook I will focus on two areas of data science:\n\n1.\tOrganization of the data \u2013 Because each observation represents a single purchase at the pharmacy, I will have to spend time carefully organizing the data so that each observation is rolled up to the customer level while carefully maintaining predictive power.\n2.\tSelecting a model \u2013 In this notebook we will test 10 different classification machine learning models and choose the best performing one based on several different metrics. \n\n","3129726b":"## Table 2: Count number of times each customer made a purchase","0d6410b8":"## Merge count to grouped data using customer ref id"}}