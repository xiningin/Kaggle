{"cell_type":{"c3f2cf15":"code","32d946bc":"code","70de3a60":"code","735abade":"code","0b5f66ac":"code","ccaf1cf6":"code","4913f16b":"code","6f3604ea":"code","94bc8c58":"code","1aa47466":"code","3c1fe555":"code","8f263ea7":"code","6bcb172c":"code","9fdb9051":"code","bf828571":"code","79e88836":"code","aa2aa08d":"code","29d4dd6e":"code","d697445b":"code","2a4bf75e":"code","374f102c":"code","bc49d497":"code","e875d69e":"code","032f8c79":"markdown","45b4c71a":"markdown","e525fd0d":"markdown","d33b3af0":"markdown"},"source":{"c3f2cf15":"\"\"\"\nCreates a EfficientNetV2 Model as defined in:\nMingxing Tan, Quoc V. Le. (2021). \nEfficientNetV2: Smaller Models and Faster Training\narXiv preprint arXiv:2104.00298.\nimport from https:\/\/github.com\/d-li14\/mobilenetv2.pytorch\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport math\n\n__all__ = ['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl']\n\n\ndef _make_divisible(v, divisor, min_value=None):\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/slim\/nets\/mobilenet\/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor \/ 2) \/\/ divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\n# SiLU (Swish) activation function\nif hasattr(nn, 'SiLU'):\n    SiLU = nn.SiLU\nelse:\n    # For compatibility with old PyTorch versions\n    class SiLU(nn.Module):\n        def forward(self, x):\n            return x * torch.sigmoid(x)\n\nclass SELayer(nn.Module):\n    def __init__(self, inp, oup, reduction=4):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n                nn.Linear(oup, _make_divisible(inp \/\/ reduction, 8)),\n                SiLU(),\n                nn.Linear(_make_divisible(inp \/\/ reduction, 8), oup),\n                nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\n\ndef conv_3x3_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        SiLU()\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        SiLU()\n    )\n\n\nclass MBConv(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio, use_se):\n        super(MBConv, self).__init__()\n        assert stride in [1, 2]\n\n        hidden_dim = round(inp * expand_ratio)\n        self.identity = stride == 1 and inp == oup\n        if use_se:\n            self.conv = nn.Sequential(\n                # pw\n                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                SELayer(inp, hidden_dim),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # fused\n                nn.Conv2d(inp, hidden_dim, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n\n\n    def forward(self, x):\n        if self.identity:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass EffNetV2(nn.Module):\n    def __init__(self, cfgs, num_classes=1000, width_mult=1.):\n        super(EffNetV2, self).__init__()\n        self.cfgs = cfgs\n\n        # building first layer\n        input_channel = _make_divisible(24 * width_mult, 8)\n        layers = [conv_3x3_bn(3, input_channel, 2)]\n        # building inverted residual blocks\n        block = MBConv\n        for t, c, n, s, use_se in self.cfgs:\n            output_channel = _make_divisible(c * width_mult, 8)\n            for i in range(n):\n                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t, use_se))\n                input_channel = output_channel\n        self.features = nn.Sequential(*layers)\n        # building last several layers\n        output_channel = _make_divisible(1792 * width_mult, 8) if width_mult > 1.0 else 1792\n        self.conv = conv_1x1_bn(input_channel, output_channel)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(output_channel, num_classes)\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.conv(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.001)\n                m.bias.data.zero_()\n\n\ndef effnetv2_s(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-S model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  24,  2, 1, 0],\n        [4,  48,  4, 2, 0],\n        [4,  64,  4, 2, 0],\n        [4, 128,  6, 2, 1],\n        [6, 160,  9, 1, 1],\n        [6, 256, 15, 2, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n\ndef effnetv2_m(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-M model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  24,  3, 1, 0],\n        [4,  48,  5, 2, 0],\n        [4,  80,  5, 2, 0],\n        [4, 160,  7, 2, 1],\n        [6, 176, 14, 1, 1],\n        [6, 304, 18, 2, 1],\n        [6, 512,  5, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n\ndef effnetv2_l(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-L model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  32,  4, 1, 0],\n        [4,  64,  7, 2, 0],\n        [4,  96,  7, 2, 0],\n        [4, 192, 10, 2, 1],\n        [6, 224, 19, 1, 1],\n        [6, 384, 25, 2, 1],\n        [6, 640,  7, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n\ndef effnetv2_xl(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-XL model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  32,  4, 1, 0],\n        [4,  64,  8, 2, 0],\n        [4,  96,  8, 2, 0],\n        [4, 192, 16, 2, 1],\n        [6, 256, 24, 1, 1],\n        [6, 512, 32, 2, 1],\n        [6, 640,  8, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)","32d946bc":"import os\nimport json\nimport glob\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","70de3a60":"import sys \n\nimport time\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\n\n#from sklearn.model_selection import StratifiedKFold","735abade":"def load_dicom(path):\n    image = dicom.read_file(path)\n    data = image.pixel_array\n    data = data - np.min(data)\n    if(np.max(data) != 0):\n        data = data\/np.max(data)\n    data = (data *256).astype(np.uint8)\n    data = cv2.resize(data, (256, 256))\n    data = cv2.cvtColor(data,cv2.COLOR_GRAY2RGB)\n    return data","0b5f66ac":"def is_valid_image(path, threshold=32768):\n    data = load_dicom(path)\n    if (np.count_nonzero(data) > threshold):\n        return True\n    else:\n        return False","ccaf1cf6":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","4913f16b":"class DataCustomer(torch_data.Dataset):\n    def __init__(self, paths, labels):\n        self.paths = paths\n        self.labels = labels\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, index):\n        data_path = self.paths[index]\n        data = load_dicom(data_path)\n        data = torch.tensor(data).float()\n        \n        data = torch.reshape(data, (3,256,256))\n        Y = torch.tensor(self.labels[index]).float()\n        return {\"X\":data, \"y\":Y}","6f3604ea":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count \/ self.n + last_n \/ self.n * self.avg","94bc8c58":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n    \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n\n            if True:\n#             if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = torch.sigmoid(self.model(X)).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n\n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}\/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n                \n                #torch.sigmoid(model(batch[\"X\"].to(device)))\n                \n                outputs = torch.sigmoid(self.model(X)).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n        \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            save_path,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","1aa47466":"df = pd.read_csv(\"..\/input\/dfdxinnhathemattroi\/filetrainxin.csv\", index_col = False)\n\nindx = df['patient_id'].unique()\nindx_train, indx_val = sk_model_selection.train_test_split(\n    indx,\n    test_size = 0.2,\n    random_state = 42,\n)\ndf_train = df[df['patient_id'].isin(indx_train)]\ndf_valid = df[df['patient_id'].isin(indx_val)]\ndisplay(len(df_train['patient_id'].unique()))\ndisplay(len(df_valid['patient_id'].unique()))","3c1fe555":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# #device = \"cpu\"\n\n\n# train_data_retriever = DataCustomer(\n#     df_train[\"file_paths\"].values, \n#     df_train[\"label\"].values, \n# )\n\n# valid_data_retriever = DataCustomer(\n#     df_valid[\"file_paths\"].values, \n#     df_valid[\"label\"].values,\n# )\n\n# train_loader = torch_data.DataLoader(\n#     train_data_retriever,\n#     batch_size=64,\n#     shuffle=True,\n#     num_workers=8,\n# )\n\n# valid_loader = torch_data.DataLoader(\n#     valid_data_retriever, \n#     batch_size=64,\n#     shuffle=False,\n#     num_workers=8,\n# )\n\n# model = effnetv2_s(num_classes = 1)\n# model.to(device)\n\n# checkpoint = torch.load(\"..\/input\/v336epoch\/best-modelv3.pth\")\n# model.load_state_dict(checkpoint[\"model_state_dict\"])\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# criterion = torch_functional.binary_cross_entropy_with_logits\n\n# trainer = Trainer(\n#     model, \n#     device, \n#     optimizer, \n#     criterion, \n#     LossMeter, \n#     AccMeter\n# )\n\n# history = trainer.fit(\n#     7, \n#     train_loader, \n#     valid_loader, \n#     \"best-modelv4.pth\", \n#     100,\n# )","8f263ea7":"sample_df = pd.read_csv('..\/input\/dfdxinnhathemattroi\/filetestxin.csv', index_col = False)\nsample_df.shape","6bcb172c":"tmp = sample_df.paths.values\ntmp[0]","9fdb9051":"IMG_PATH_TEST = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\"\nf = []\nfor (dirpath, dirnames, filenames) in os.walk(IMG_PATH_TEST):\n    f.extend(os.path.join(dirpath, x) for x in filenames)\n    \ntest_file_paths_df = pd.DataFrame({'file_paths': f})\ntest_file_paths_df['directory'] = IMG_PATH_TEST\ntest_file_paths_df['dataset'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[3]\ntest_file_paths_df['patient_id'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[4]\ntest_file_paths_df['scan_type'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[5]\ntest_file_paths_df['file'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[6]\ndisplay(test_file_paths_df.head(2))\ntest_file_paths_df.shape[0]","bf828571":"test_df=test_file_paths_df[test_file_paths_df['file_paths'].isin(tmp)]\ndisplay(test_df.shape)","79e88836":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodels = []\nfor i in range(1):\n    model = effnetv2_s(num_classes = 1)\n    model.to(device)\n    \n    checkpoint = torch.load(\"..\/input\/v557epoch\/v5-57epoch.pth\",map_location=torch.device('cpu'))\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","aa2aa08d":"_id = test_df['patient_id'].map(int).tolist()","29d4dd6e":"class TestDataCustomer(torch_data.Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        data_path = self.paths[index]\n        data = load_dicom(data_path)\n        \n        data = torch.tensor(data).float()\n        data = torch.reshape(data, (3,256,256))\n        \n        return {\"X\": data, \"id\": _id[index]}","d697445b":"submission = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\")\n\ntest_data_retriever = TestDataCustomer( \n    test_df['file_paths'].values,\n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=64,\n    shuffle=False,\n    num_workers=8,\n)","2a4bf75e":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}\/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n        y_pred.extend(tmp_pred)\n        ids.extend(batch[\"id\"].numpy().tolist())","374f102c":"submission = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\nsubmission = submission.groupby(['BraTS21ID'], as_index = False).median()\nsubmission.to_csv(\"submission.csv\",float_format='{:.1f}'.format, encoding='utf-8', index=False)\nsubmission","bc49d497":"plt.figure(figsize=(5, 5))\nplt.hist(submission[\"MGMT_value\"]);","e875d69e":"# # def is_valid_image(path, threshold=10):\n# #     data = load_dicom(path)\n# #     if np.mean(data)<threshold:\n# #         return False\n# #     else:\n# #         return True\n\n\n# def change_path(path):\n#     path = path.replace(\"rsna-miccai-png\",\"rsna-miccai-brain-tumor-radiogenomic-classification\")\n#     path = path.replace(\".png\", \".dcm\")\n#     return path","032f8c79":"## Support Function","45b4c71a":"## WORK IN PROGRESS...","e525fd0d":"## Visualize on labels","d33b3af0":"# FILTER TESTDATA WITH THRESHOLD = 10 AND ONLY USE T2w SCAN TYPE"}}