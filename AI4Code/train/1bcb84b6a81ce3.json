{"cell_type":{"30a3afbe":"code","a8083547":"code","edfbb0bb":"code","608d72bb":"code","b4ddcf23":"code","be54b1cc":"code","b55bef42":"code","4ba7ff9d":"code","d5029d87":"code","79df390a":"code","ca111146":"code","f967e816":"code","34f18a0e":"code","aee682ce":"code","6ae13d64":"code","211656de":"code","0606cf4d":"code","2a9fb7af":"code","c8f47d0b":"code","bfc40718":"code","90753109":"code","e1bd8d78":"code","56eb4a2e":"code","9d4edcc2":"markdown","20b2e8eb":"markdown","a1b8a70e":"markdown","fbfdfc39":"markdown","9560e053":"markdown","79730ea0":"markdown","564868da":"markdown","f60994bb":"markdown","49f41daa":"markdown","3f57255b":"markdown","919e3689":"markdown","9ac26fda":"markdown","b0eca4c9":"markdown","ab95b075":"markdown","fbbc9286":"markdown","4dbf2f9d":"markdown","ba2e7a25":"markdown","abcd0e44":"markdown","ab19b492":"markdown"},"source":{"30a3afbe":"from sklearn.cluster import KMeans\nimport pandas as pd\nimport numpy as np","a8083547":"df = pd.read_csv(\"..\/input\/iris-flower-dataset\/IRIS.csv\")","edfbb0bb":"df.head()","608d72bb":"train = df.species","b4ddcf23":"classes = df.drop('species', axis=1)","be54b1cc":"# Fun\u00e7\u00e3o que retorna a dist\u00e2ncia eucludiana de dois vetores de duas dimens\u00f5es.\nfrom sklearn.neighbors import DistanceMetric\ndef calcula_distancia(x,c):\n    dist = DistanceMetric.get_metric('euclidean')\n    return dist.pairwise(x,c)","b55bef42":"v1 = [[1.2,1,2.1,1]]\nv2 = [[1,1.9,5.4,3.2]]\n\ncalcula_distancia(v1,v2)","4ba7ff9d":"v3 = [[0.5,0,2.1,1.5]]\nv4 = [[0.5,0,2.1,1.5]]\n\ncalcula_distancia(v3,v4)","d5029d87":"kmeans = KMeans(n_clusters=3)","79df390a":"kmeans.fit(classes)\ncentros = kmeans.cluster_centers_\ncentros","ca111146":"import random","f967e816":"classes[34:35]","34f18a0e":"for i in range(1,4):\n    num = round(random.uniform(1,50),0)\n    num_int = int(num)\n    print(\"Para a amostra de dado n\u00famero n\u00famero \", num_int,\" a dist\u00e2ncia para os centros \u00e9 de: \", calcula_distancia(classes[(num_int-1):num_int],centros))\n    print(\"\\n\")","aee682ce":"distancia = kmeans.fit_transform(classes)\ndistancia","6ae13d64":"import seaborn as sns","211656de":"sns.kdeplot(classes.sepal_length,shade=True )","0606cf4d":"sns.kdeplot(classes.sepal_width,shade=True )","2a9fb7af":"sns.kdeplot(classes.petal_length,shade=True )","c8f47d0b":"sns.kdeplot(classes.petal_width,shade=True )","bfc40718":"X = []\nnum1 = random.uniform(4,8)\nX.append(num1)\nnum2 = random.uniform(1.5,4.5)\nX.append(num2)\nnum3 = random.uniform(0,8)\nX.append(num3)\nnum4 = random.uniform(0,3)\nX.append(num4)\nX = np.array(X).reshape(1,4)\nX","90753109":"calcula_distancia(X,centros)","e1bd8d78":"print(kmeans.predict(X))","56eb4a2e":"i = 0\nwhile i < 10:\n    X = []\n    num1 = random.uniform(4,8)\n    X.append(num1)\n    num2 = random.uniform(1.5,4.5)\n    X.append(num2)\n    num3 = random.uniform(0,8)\n    X.append(num3)\n    num4 = random.uniform(0,3)\n    X.append(num4)\n    X = np.array(X).reshape(1,4)\n    print(\"Dado\", i+1, \"gerado: \", X,\"Distancia para os centros de: \", calcula_distancia(X,centros),\" Classifica\u00e7\u00e3o prevista: \", kmeans.predict(X))\n    i = i + 1","9d4edcc2":"09) Imprima os valores dos **centroides**.","20b2e8eb":"2) Leia a base de dados **iris.csv** localizada no diretorio **datasets** e crie um Dataframe.","a1b8a70e":"<font color=blue><b> Data Science do Zero<\/b><\/font><br>\n www.minerandodados.com.br  ","fbfdfc39":"1) Importe as bibliotecas para visualiza\u00e7\u00e3o de dados e clustering.","9560e053":"- Calcule a dist\u00e2ncia entre os vetores **v1 e v2** abaixo\n> v1 = [[1.2,1,2.1,1]]<br>\n> v2 = [[1,1.9,5.4,3.2]]","79730ea0":"10) Selecione **tr\u00eas amostras da base de dados e calcule a dist\u00e2ncia euclidiana entre as amostras de dados e cada um dos valores de centroids**.","564868da":"5) Armazene os dados de classes na vari\u00e1vel classes.","f60994bb":"Percebi que o indice 0 corresponde a classe 2, o indice 1 corresponde a classe 0 e o indice 2 corresponde a classe 1. Ao gerar valores aleatorios varias vezes, pode-se ver isso**","49f41daa":"11) Gere a **tabela de dist\u00e2ncia** e verifique os valores atrav\u00e9s do m\u00e9todo fit_transform().","3f57255b":"12) Utilizando o m\u00e9todo **predict()** defina novos valores de dados e fa\u00e7a a predi\u00e7\u00e3o.","919e3689":"7) Utilizando a fun\u00e7\u00e3o **calcula_distancia** fa\u00e7a:","9ac26fda":"8) Inst\u00e2ncie o algoritmo Kmeans com o n\u00famero de clusters **igual ao n\u00famero de classes** da sua base de dados e execute o algoritmo KMeans.","b0eca4c9":"Vou gerar os gr\u00e1ficos da distribui\u00e7\u00e3o de tamanhos. Assim posso gerar valores aleatorios denrto dessas distribui\u00e7\u00f5es para fazer um m\u00e9todo predict a partir de dados gerados aleatoriamente.","ab95b075":"6) Utilizando o c\u00f3digo abaixo, crie uma fun\u00e7\u00e3o que fa\u00e7a o **calculo da dist\u00e2ncia euclidiana entre dois vetores**.","fbbc9286":"# KMeans- Exerc\u00edcios","4dbf2f9d":"3) Armazene apenas as **features e seus dados** na vari\u00e1vel train.","ba2e7a25":"- Calcule a dist\u00e2ncia entre os vetores **v3 e v4** abaixo e explique o retorno\n> v3 = [[0.5,0,2.1,1.5]]<br>\n> v4 = [[0.5,0,2.1,1.5]]","abcd0e44":"- DICA: Use um la\u00e7o for...","ab19b492":"Como pode ser visto no while acim. O indice 0 corresponde a classe 2, o indice 1 corresponde a classe 0 e o indice 2 corresponde a classe 1. Ao gerar valores aleatorios varias vezes, pode-se ver isso"}}