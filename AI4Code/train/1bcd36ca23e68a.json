{"cell_type":{"d37f3823":"code","9ffa814c":"code","d972e0b5":"code","ff7de6ed":"code","e560855c":"code","169ff4e2":"code","b30965a1":"code","26fe3d2b":"markdown","2b4611ca":"markdown","1287dd21":"markdown","e96b1fee":"markdown","65d2d03e":"markdown","395e3013":"markdown","9a24ca56":"markdown"},"source":{"d37f3823":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9ffa814c":"\n#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nfrom __future__ import print_function, division\nfrom builtins import range, input\n# Note: you may need to update your version of future\n# sudo pip install -U future\n\nfrom keras.models import Model\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\n\nimport numpy as np\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d972e0b5":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\nimage_path = '..\/input\/kaggle-pog-series-s01e01\/thumbnails'\nimage_files = glob(image_path +  '\/*.jpg')# original was *.JP*G, then I changed to jpeg to avoid error \"ValueError: 'a' cannot be empty unless no samples are taken\"","ff7de6ed":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# look at an image for fun\n\nplt.imshow(image.load_img(np.random.choice(image_files)));","e560855c":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# add preprocessing layer to the front of VGG\nresnet = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=True)\n\n# view the structure of the model\n# if you want to confirm we need activation_49\nresnet.summary()","169ff4e2":"#Code by Yvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map\n\n# make a model to get output before flatten\nactivation_layer = resnet.get_layer('conv5_block3_out')\n\n# create a model object\nmodel = Model(inputs=resnet.input, outputs=activation_layer.output)","b30965a1":"# get the feature map weights\nfinal_dense = resnet.get_layer('predictions')\nW = final_dense.get_weights()[0]\n\n\n#while True:\ni = 0\nfor i in range(10):\n  img = image.load_img(np.random.choice(image_files), target_size=(224, 224))\n  x = preprocess_input(np.expand_dims(img, 0))\n  fmaps = model.predict(x)[0] # 7 x 7 x 2048\n\n  # get predicted class\n  probs = resnet.predict(x)\n  classnames = decode_predictions(probs)[0]\n  print(classnames)\n  classname = classnames[0][1]\n  pred = np.argmax(probs[0])\n\n  # get the 2048 weights for the relevant class\n  w = W[:, pred]\n\n  # \"dot\" w with fmaps\n  cam = fmaps.dot(w)\n\n  # upsample to 224 x 224\n  # 7 x 32 = 224\n  cam = sp.ndimage.zoom(cam, (32, 32), order=1)\n\n  plt.subplot(1,2,1)\n  plt.imshow(img, alpha=0.8)\n  plt.imshow(cam, cmap='jet', alpha=0.5)\n  plt.subplot(1,2,2)\n  plt.imshow(img)\n  plt.title(classname)\n  plt.show()","26fe3d2b":"#Build the model","2b4611ca":"#Image files","1287dd21":"![](https:\/\/d3i71xaburhd42.cloudfront.net\/9b6a8ed4b6d4e072d9910bad54257a67ee9c180a\/1-Figure1-1.png)semanticscholar.org","e96b1fee":"#Acknowledgment:\n\nYvtsan Levy https:\/\/www.kaggle.com\/yvtsanlevy\/introduction-to-class-activition-map","65d2d03e":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:orange;\">Class Activation Maps (CAM)<\/b><\/h1><\/center>\n\n\"Class Activation Maps (CAM) is a powerful technique used in Computer Vision for classification tasks. It allows the scientist to inspect the image to be categorized and understand which parts\/pixels of that image have contributed more to the final output of the model.\"","395e3013":"#Import Libraries","9a24ca56":"#Look at an image for fun."}}