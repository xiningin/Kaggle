{"cell_type":{"0117333b":"code","94388148":"code","8ee73544":"code","708fb30b":"code","cd8c33eb":"code","0b4144c2":"code","e45ab659":"code","bd1a391c":"code","35f979ac":"code","99023aab":"code","e3122d74":"code","9fca772b":"code","6a988d95":"code","0ea0845c":"code","1bf6265c":"code","da352d81":"code","ed6c0d7e":"code","928cbdab":"code","0a1e09fe":"code","d98cf298":"code","e6ab2a72":"code","7eac7eff":"code","9e16fe85":"code","a7d04b79":"code","ceed60df":"code","b5097cbe":"code","9979dbfb":"code","be83e252":"code","ad042e9d":"code","b77b3ce4":"code","5f50c4fe":"code","4b7727e8":"code","2458281c":"code","3d3e15fc":"code","f99f4938":"code","f94c5b21":"code","e4a67963":"code","bf2d17b2":"code","5cbfa09a":"code","1a6b2443":"code","1a114a78":"code","4c463056":"code","8af74236":"code","81f08e00":"markdown","51187be4":"markdown","25f3205b":"markdown","a8c18f4c":"markdown","53dc6224":"markdown","fba9f8d6":"markdown","aaed25eb":"markdown"},"source":{"0117333b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94388148":"df_wine_data = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","8ee73544":"df_wine_data.shape","708fb30b":"df_wine_data.columns","cd8c33eb":"df_wine_data.dtypes","0b4144c2":"for col in df_wine_data.columns :\n    print(df_wine_data[col].isnull().value_counts())","e45ab659":"fig = plt.figure(figsize = (8,5))\nax = fig.add_subplot(111)\ndf_wine_data['quality'].plot(kind = 'hist',bins=20,ax=ax)\nax.set_xlabel('Quality',size = 12)","bd1a391c":"#df_wine_data.loc[df_wine_data['quality']>=6.5,'quality'] =1\n#df_wine_data.loc[(df_wine_data['quality']<6.5) & (df_wine_data['quality'] !=1) ,'quality'] =0","35f979ac":"#GoodOrBad feature will used for classification in later part\ndf_wine_data['GoodOrBad'] = df_wine_data['quality']\ndf_wine_data.loc[df_wine_data['GoodOrBad']>=6.5,'GoodOrBad'] =1\ndf_wine_data.loc[(df_wine_data['GoodOrBad']<6.5) & (df_wine_data['GoodOrBad'] !=1) ,'GoodOrBad'] =0","99023aab":"#Fixed Acidity have a similar kind of level in all kinds of wines \nsns.barplot(data= df_wine_data,x='quality',y='fixed acidity')","e3122d74":"#Sugar level are pretty much same irrespective of quality.\nsns.barplot(data= df_wine_data,x='quality',y='residual sugar')","9fca772b":"#Cholrides level decrease as quality increases\nsns.barplot(data= df_wine_data,x='quality',y='chlorides')","6a988d95":"#citric acid level increases as quality increases\nsns.barplot(data= df_wine_data,x='quality',y='citric acid')","0ea0845c":"#volatile acidity level decrease as quality increases\nsns.barplot(data= df_wine_data,x='quality',y='volatile acidity')","1bf6265c":"#free sulfur dioxide are high in midium quality of wines and low in low quality of wines.\nsns.barplot(data= df_wine_data,x='quality',y='free sulfur dioxide')","da352d81":"#like free sulfur dioxide, total sulfur dioxide are also high in midium quality of wines and low in low quality of wines.\nsns.barplot(data= df_wine_data,x='quality',y='total sulfur dioxide')","ed6c0d7e":"#Bar plot is unable to give any significant info lets try a different plot \nsns.barplot(data= df_wine_data,x='quality',y='density')","928cbdab":"#density is pretty is in similar levels irrespective of quality\nsns.swarmplot(data= df_wine_data,x='quality',y='density')\n","0a1e09fe":"\nsns.barplot(data= df_wine_data,x='quality',y='pH')","d98cf298":"#Majority Wines with quality 5,6,7 tend have a pH value between 3.6 to 3.0\n#but wines with quality 3,8 also same kind of range 3.6 to 3.2\n#pH level will not be able to play a significant role in deciding the quality\nsns.swarmplot(data= df_wine_data,x='quality',y='pH')","e6ab2a72":"#sulphates quantity is showing upward trend w.r.t to quality\nsns.barplot(data= df_wine_data,x='quality',y='sulphates')","7eac7eff":"#Alcohol content is high in wines with quality 7,8 but similar in wines\n#with quality 3,4,5,6\nsns.barplot(data= df_wine_data,x='quality',y='alcohol')","9e16fe85":"columns = ['volatile acidity', 'citric acid',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'sulphates', 'alcohol']","a7d04b79":"from sklearn.preprocessing import StandardScaler\nstd_scaler = StandardScaler()\nstd_scaler.fit(df_wine_data[columns])\ndf_wine_data[columns] = std_scaler.transform(df_wine_data[columns])","ceed60df":"df_wine_data.shape","b5097cbe":"#GoodOrBad is just a categorical variable that we have created earlier\n#This plot shows us the strength of coorelation of feature with quality variable.\ndf_wine_data.corr()['quality'].plot(kind = 'bar')","9979dbfb":"#Through the coorelation matrix we can see that 'volatile acidity', 'citric acid',\n#'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'sulphates', 'alcohol'\n#features have strong coorelation with quality\nfig = plt.figure(figsize = (12,6))\nsns.heatmap(df_wine_data.corr(),annot = True)","be83e252":"df_wine_data.columns","ad042e9d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(np.array(df_wine_data[columns])\n                                                    ,np.array(df_wine_data['quality']),random_state =20,test_size =0.4,train_size = 0.6)","b77b3ce4":"X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,random_state =20,test_size =0.5,train_size = 0.5)","5f50c4fe":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nmses= []\nks = np.arange(1,5,1)\nfor k in ks :\n    poly = PolynomialFeatures(k)\n    X_train_poly = poly.fit_transform(X_train)\n    X_val_poly = poly.fit_transform(X_val)\n    reg = LinearRegression()\n    reg.fit(X_train_poly,y_train)\n    y_hat = reg.predict(X_val_poly)\n    mses.append(mean_squared_error(y_val,y_hat))","4b7727e8":"plt.plot(ks,mses)\nplt.xticks(ks)\nplt.xlabel('degree of polynomial',size =12)\nplt.ylabel('MSE',size =12)","2458281c":"#We will use polynomial feature with degree 3 because if we increase degree further\n#MSE incresing which we don't want\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Lasso\nks = np.arange(1,10,1) *0.01\nmses = []\nfor k in ks :\n    poly = PolynomialFeatures(3)\n    X_train_poly = poly.fit_transform(X_train)\n    X_val_poly = poly.fit_transform(X_val)\n    reg = Lasso(alpha = k,max_iter =1000)\n    reg.fit(X_train_poly,y_train)\n    y_hat = reg.predict(X_val_poly)\n    mses.append(mean_squared_error(y_val,y_hat))","3d3e15fc":"plt.figure(figsize=(12,5))\nplt.plot(ks,mses)\nplt.xticks(ks)\nplt.xlabel('Regularization Parameter',size =12)\nplt.ylabel('MSE on Validation Dataset',size =12)\nplt.gca().ticklabel_format(axis='both', style='plain', useOffset=False)","f99f4938":"#We consider regularization parameter as 0.02\npoly = PolynomialFeatures(3)\nX_train_poly = poly.fit_transform(X_train)\nX_val_poly = poly.fit_transform(X_val)\nreg = Lasso(alpha = 0.02)\nmses_train = []\nmses_val = []\nsplit_arr = np.arange(179,717,179)\ntemp = 0\nfor i in split_arr :\n    reg.fit(X_train_poly[temp:i,:],y_train[temp:i])\n    y_train_hat = reg.predict(X_train_poly)\n    y_val_hat = reg.predict(X_val_poly)\n    mses_train.append(mean_squared_error(y_train,y_train_hat))\n    mses_val.append(mean_squared_error(y_val,y_val_hat))\n    i =i+1\n    temp =1","f94c5b21":"plt.figure(figsize = (13,4))\nplt.plot(split_arr,mses_train,label = 'Training Error')\nplt.plot(split_arr,mses_val,label = 'Validation Error')\nplt.xlabel('Training Sample',size =12)\nplt.ylabel('MSE',size =12)\nplt.legend()\nplt.gca().ticklabel_format(axis='both', style='plain', useOffset=False)","e4a67963":"#with best degree of polynomial as and regularization paramter\n#will try to predict on test data\npoly = PolynomialFeatures(3)\nX_test_poly = poly.fit_transform(X_test)\ny_test_hat = reg.predict(X_test_poly)\nmean_squared_error(y_test,y_test_hat)","bf2d17b2":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(np.array(df_wine_data[columns])\n                                                    ,np.array(df_wine_data['GoodOrBad']),random_state =20,test_size =0.4,train_size = 0.6)","5cbfa09a":"X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,random_state =20,test_size =0.5,train_size = 0.5)","1a6b2443":"from sklearn.svm import SVC\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nclf = SVC()\nclf.fit(X_train,y_train)\ny_val_hat = clf.predict(X_val)","1a114a78":"#Performance on Validation Set\nprint('Accuracy Score :',accuracy_score(y_val,y_val_hat))\nprint('Precision Score :',precision_score(y_val,y_val_hat))\nprint('Recall Score :',recall_score(y_val,y_val_hat))\nsns.heatmap(confusion_matrix(y_val,y_val_hat),annot =True,fmt='d')\n","4c463056":"#Performance of Test Set\ny_tst_hat = clf.predict(X_test)\nprint('Accuracy Score :',accuracy_score(y_test,y_tst_hat))\nprint('Precision Score :',precision_score(y_test,y_tst_hat))\nprint('Recall Score :',recall_score(y_test,y_tst_hat))\nsns.heatmap(confusion_matrix(y_test,y_tst_hat),annot =True,fmt='d')","8af74236":"#figure = plt.figure(figsize = (10,10))\n#ax = figure.add_subplot(111)\n#sns.boxplot(data = df_wine_data[columns],width = 0.8,orient = 'h')\n#Here we are using 1.5 times Inter Quartile Range to filter outliers there are other ways also like Z-Score. \n#Q1 = df_wine_data[columns].quantile(0.25) #First Quartile\n#Q3 = df_wine_data[columns].quantile(0.75) #Thrid Quartile\n#IQR = Q3 - Q1                             #Inter Quartile Range\n#df_wine_data = df_wine_data[~((df_wine_data < (Q1 - 1.5 * IQR)) |(df_wine_data > (Q3 + 1.5 * IQR))).any(axis=1)]","81f08e00":"alcohol,sulphates,total sulfur dioxide,free sulfur dioxide,volatile acidity,citric acid,chlorides. So these were all the features that were showing change with increase or decrease in quality ","51187be4":"# Thank You ","25f3205b":"Lets jump to some visualization.","a8c18f4c":"If you find my notebook useful then give an upvote.If you have any comments or questions please drop a comment, I am more then happy to answner your question. ","53dc6224":"# Now lets try applying a regression model which will predict the quality","fba9f8d6":"Changing the quality variable to a categorical variable with quality score >=6.5: **good** and quality score<6.5 : **bad**","aaed25eb":"Lets try a classification model using an Support Vector Machine"}}