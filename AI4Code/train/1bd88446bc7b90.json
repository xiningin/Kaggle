{"cell_type":{"fda0168b":"code","0d01e9d4":"code","f993078d":"code","2644d261":"code","322defdd":"code","cc3e241f":"code","b4aa7dfa":"code","5863067e":"code","cc266d13":"code","3fcc292b":"code","fc2cb96e":"code","44367b9d":"code","e00cec91":"code","eaacf589":"code","e8bd5a58":"code","f1db41f0":"code","f6cc52b5":"code","192cbca8":"code","7c2a208b":"code","9eca12d1":"code","599f0377":"code","2269093a":"code","1367ace1":"code","b9f7ed58":"code","d7cb295b":"code","8b368e5d":"code","a0b57900":"code","4d1bad7f":"code","351483ec":"code","ceaec2ec":"code","dec6bf1a":"code","96739bf2":"code","339caffe":"code","88181eff":"code","54437af6":"code","5e26a13f":"code","f43b24e9":"code","7224653b":"code","a60c1662":"code","e08cd1f7":"code","a2e954fe":"code","5047e3c5":"code","2caa1026":"code","8fb30a3f":"code","ff1b70dc":"code","c0244f9d":"code","307828ae":"code","d5b793fd":"code","fa0d884a":"code","3c4d9de6":"code","ad1d3770":"code","d5e3da77":"code","ab277fb4":"code","b05ecc78":"code","de6a67a8":"code","45e2482a":"code","1c92ee35":"code","2f590925":"code","412b387f":"code","36aacf03":"code","8bd1002a":"code","c99d69cb":"code","f70e5ebe":"code","410a0d8f":"code","9cae9259":"code","79f07697":"code","ef8cdcf9":"code","3f74d65d":"code","8df1d80c":"code","bf998efb":"code","2b914060":"code","624a51ed":"code","00cd6d6d":"code","960ec7e3":"code","c12024b2":"code","6bba876d":"code","8bca64c7":"code","38f73cf7":"code","f123413e":"code","cf0a53c7":"code","f8b7a1e4":"code","80b6b5fe":"code","5a5bf865":"code","b482a151":"code","330a3eb8":"code","2c1c26c2":"code","9fe82d7c":"code","7ce917bc":"code","f319a311":"code","d7fa3326":"code","3104316e":"code","28d56bee":"code","0e62f3f8":"code","fc4f035f":"code","174f3acf":"code","743ee490":"code","7a98cc5c":"code","4d79cf75":"code","5afccf7b":"code","5d753aa8":"code","352686e0":"code","77ec46b2":"code","0289d814":"code","11aced43":"code","f7b09d06":"code","27fe4cef":"code","9ba360f7":"markdown","1ae23b10":"markdown","9f966d55":"markdown","d5424c0b":"markdown","c245d039":"markdown","f1828ed3":"markdown","b202ca96":"markdown","3f82fe4f":"markdown","917c7af4":"markdown","6469d53b":"markdown","fd8b2fd4":"markdown","2fe864a9":"markdown","4e15df59":"markdown","4ce33adc":"markdown","617f60a4":"markdown","7805d79c":"markdown","718b9376":"markdown","c47a0ae2":"markdown","a21a6e8f":"markdown","096d98da":"markdown","5e4f39cb":"markdown","ecb5db28":"markdown","2df9592e":"markdown","1ddceb98":"markdown","260d445c":"markdown","83a0b875":"markdown","ed5c2661":"markdown","f0592e1e":"markdown","4acbeb0e":"markdown","222b2c88":"markdown","e428cba1":"markdown","53f7690d":"markdown","761937c9":"markdown","55fc8ce8":"markdown","5d378314":"markdown","b10761c6":"markdown","09ef2bf7":"markdown","65e11067":"markdown","18dac974":"markdown","b47fa3f5":"markdown","d8ad35c8":"markdown","e90b02f2":"markdown","2aafe35a":"markdown","aeee69a2":"markdown","7b8a5559":"markdown","fa530ab1":"markdown","8589c1f9":"markdown","da77407f":"markdown","a995e8e7":"markdown","e96cd296":"markdown","9184916c":"markdown","fdaa1c88":"markdown","4134d973":"markdown","36bc0a33":"markdown","cc5feb75":"markdown","3929c53a":"markdown","0102164a":"markdown","9f7a4c34":"markdown","6add0c18":"markdown","7ac32d1f":"markdown","dd0d09c0":"markdown","fbef546d":"markdown","a826c69e":"markdown","dbdc55a0":"markdown","90923102":"markdown","49990045":"markdown","aab39661":"markdown","a27ceda5":"markdown","aea5399a":"markdown","01901bb9":"markdown","9ed773d0":"markdown","70ca528d":"markdown","aef41135":"markdown","a3d4fbee":"markdown","9c1d0fad":"markdown","98d72fc3":"markdown","1ff1c222":"markdown","7bc8eb30":"markdown","aeec5d33":"markdown","2a6ce37d":"markdown","be310884":"markdown","3f47b8df":"markdown","e46e94d9":"markdown","4cb0c301":"markdown","a0d89169":"markdown","2e098cb8":"markdown","bb1e8138":"markdown","face46b4":"markdown","c79f9b8e":"markdown","1ab65e15":"markdown","56884f0d":"markdown","285141dc":"markdown","22b15efa":"markdown","9da454ac":"markdown","6da62661":"markdown","76e90855":"markdown","52e591af":"markdown","1e8e9f32":"markdown","ac4f1fc9":"markdown","008c1524":"markdown","52743269":"markdown","1bb51d3e":"markdown"},"source":{"fda0168b":"# importer les biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n!pip install yfinance\nimport yfinance as yf\nimport requests, json","0d01e9d4":"url = 'https:\/\/www.investing.com\/crypto\/bitcoin\/historical-data'","f993078d":"\nheader = {\n  \"User-Agent\": \"Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/50.0.2661.75 Safari\/537.36\",\n  \"X-Requested-With\": \"XMLHttpRequest\"\n}\n\n","2644d261":"r = requests.get(url, headers=header)\n\npd_data = pd.read_html(r.text)[0]","322defdd":"pd_data","cc3e241f":"data = yf.Ticker(\"BTC-USD\")\nyf_df = data.history(start='2014-09-01', end='2022-02-1')","b4aa7dfa":"yf_df","5863067e":"api_data = json.loads(requests.get('https:\/\/coincodex.com\/api\/coincodexcoins\/get_historical_data_by_slug\/bitcoin\/2021-1-1\/2021-9-30\/1?t=5459791').text)\napi_df = pd.DataFrame(api_data['data'])","cc266d13":"api_df","3fcc292b":"#  ignorer les avertissements\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n","fc2cb96e":"# Dataset d'amazon\nBTC_data = pd.read_csv(\"..\/input\/bitcoin\/BTC-USD.csv\")","44367b9d":"BTC_data.head()","e00cec91":"BTC_data.tail()","eaacf589":"# Types de donn\u00e9es\nBTC_data.info()","e8bd5a58":"# description des donn\u00e9es num\u00e9riques\nBTC_data.describe()","f1db41f0":"# Cellules vides\nprint(f\"Le nombre de cellule vides dans notre dataset est :\\n{BTC_data.isna().sum()}\")","f6cc52b5":"BTC_Data = BTC_data.set_index('Date', drop=True)","192cbca8":"BTC_Data = BTC_Data[BTC_Data.index>='2020-01-01']","7c2a208b":"BTC_Data.head()","9eca12d1":"BTC_Data.info()","599f0377":"BTC_Data.describe()","2269093a":"import seaborn as sb\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py","1367ace1":"# visualiser la valeur \"Close\"\nbtc_trace = go.Figure(data=[go.Scatter(x=BTC_Data.index, y=BTC_Data['Close'], name= 'Close')])\n\nbtc_trace.update_layout(\ntitle = {\n    'text': 'btc_trace for Close Value',\n    'y':0.90,\n    'x':0.5,\n    'xanchor': 'center',\n    'yanchor': 'top'} , \ntemplate=\"plotly_white\")\n\nbtc_trace.show()","b9f7ed58":"# visualiser la valeur \"Volume\"\n\nbtc_trace = go.Figure(data=[go.Scatter(x=BTC_Data.index, y=BTC_Data['Volume'], name= 'Volume')])\n\nbtc_trace.update_layout(\ntitle = {\n    'text': 'btc_trace for Volume Value',\n    'y':0.90,\n    'x':0.5,\n    'xanchor': 'center',\n    'yanchor': 'top'} , \ntemplate=\"plotly_white\")\n\nbtc_trace.show()","d7cb295b":"# the correlation matrix \nmat = BTC_Data.corr()\nplt.figure(figsize=(12, 8))\nsb.heatmap(mat,annot=True)\n\nplt.show()","8b368e5d":"def candelstick_chart(data,title):\n    candlestick = go.Figure(data = [go.Candlestick(x =data.index, \n                                               open = data[('Open')], \n                                               high = data[('High')], \n                                               low = data[('Low')], \n                                               close = data[('Close')],\n                                               #increasing_line_color= 'cyan', \n                                               #decreasing_line_color= 'gray'\n                                                )])\n    candlestick.update_xaxes(title_text = 'Time',\n                             rangeslider_visible = True)\n\n    candlestick.update_layout(\n    title = {\n        'text': '{:} Candelstick Chart'.format(title),\n        'y':0.90,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'} , \n    template=\"plotly_white\")\n\n    candlestick.update_yaxes(title_text = 'Prix en USD', ticksuffix = '$')\n    return candlestick","a0b57900":"btc_plot = candelstick_chart(BTC_Data[-90:],title = \"Bitcoin(BTC)\")\nbtc_plot.show()","4d1bad7f":"def ohlc_chart(data,title):\n    ohlc = go.Figure(data = [go.Ohlc(x =data.index, \n                                               open = data[('Open')], \n                                               high = data[('High')], \n                                               low = data[('Low')], \n                                               close = data[('Close')])])\n    ohlc.update_xaxes(title_text = 'Time',\n                             rangeslider_visible = True)\n\n    ohlc.update_layout(\n    title = {\n        'text': '{:} OHLC Chart'.format(title),\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'},\n        template=\"plotly_white\")\n\n    ohlc.update_yaxes(title_text = 'Prix en USD', ticksuffix = '$')\n    return ohlc","351483ec":"ohlc_chart(BTC_Data[:-200], title = \"Bitcoin\")","ceaec2ec":"def vol_traded(data ,title,color):\n    area = px.area(data_frame=data,\n               x = data.index ,\n               y = \"Volume\",\n               markers = True)\n    area.update_traces(line_color=color)\n    area.update_xaxes(\n        title_text = 'Time',\n        rangeslider_visible = True)\n    area.update_yaxes(title_text = 'Number of trades every minute')\n    area.update_layout(showlegend = True, xaxis_rangeslider_visible=False,\n        title = {\n            'text': '{:} Volume Traded'.format(title),\n            'y':0.94,\n            'x':0.5,\n            'xanchor': 'center',\n            'yanchor': 'top'},\n        template=\"plotly_white\")\n    return area","dec6bf1a":"vol_traded(BTC_Data[-90:], \"Bitcoin\",color = \"blue\")","96739bf2":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","339caffe":"closedf = BTC_data[['Date','Close']]\nprint(\"Forme du dataframe close\", closedf.shape)","88181eff":"closedf = closedf[closedf['Date'] > '2020-09-13']\nclose_stock = closedf.copy()\nprint(\"Donn\u00e9es totales pour la pr\u00e9diction\u00a0: \",closedf.shape[0])","54437af6":"del closedf['Date']\nscaler=MinMaxScaler(feature_range=(0,1))\nclosedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\nprint(closedf.shape)","5e26a13f":"training_size=int(len(closedf)*0.70)\ntest_size=len(closedf)-training_size\ntrain_data,test_data=closedf[0:training_size,:],closedf[training_size:len(closedf),:1]","f43b24e9":"print(\"la taille des donn\u00e9es d'entra\u00eenement est: \",train_data.shape[0])\nprint(\"la taille d'\u00e9chantillon du test est: \",test_data.shape[0])","7224653b":"\nfig, ax = plt.subplots(figsize=(20, 10))\nsb.lineplot(x = close_stock['Date'][:train_data.shape[0]], y = close_stock['Close'][:train_data.shape[0]], color = 'black')\nsb.lineplot(x = close_stock['Date'][train_data.shape[0]:], y = close_stock['Close'][train_data.shape[0]:], color = 'red')\n\n# Formatting\nax.set_title('Train & Test data', fontsize = 20, loc='center', fontdict=dict(weight='bold'))\nax.set_xlabel('Date', fontsize = 16, fontdict=dict(weight='bold'))\nax.set_ylabel('Weekly Sales', fontsize = 16, fontdict=dict(weight='bold'))\nplt.tick_params(axis='y', which='major', labelsize=16)\nplt.tick_params(axis='x', which='major', labelsize=16)\nplt.legend(loc='upper right' ,labels = ('train', 'test'))","a60c1662":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, time_step=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-time_step-1):\n        a = dataset[i:(i+time_step), 0]   #i=0, 0,1,2,3-----99   100 \n        dataX.append(a)\n        dataY.append(dataset[i + time_step, 0])\n    return np.array(dataX), np.array(dataY)","e08cd1f7":"time_step = 15\nX_train, y_train = create_dataset(train_data, time_step)\nX_test, y_test = create_dataset(test_data, time_step)\n\n\nprint(\"X_train: \", X_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"X_test: \", X_test.shape)\nprint(\"y_test\", y_test.shape)","a2e954fe":"from sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport math\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n","5047e3c5":"LR=LinearRegression()\n\nXGBoost = XGBRegressor(n_estimators=100, learning_rate=0.3,\n                     max_delta_step=0, max_depth=6, n_jobs=4,\n                     num_parallel_tree=1, random_state=0)\n\nRFR = RandomForestRegressor(max_depth=1000)\nmodels = {\"Linear Regression\":LR, \"XGBoost Regressor\":XGBoost, \"Random Forest Regressor\":RFR}","2caa1026":"def train_model(model_name):\n    models[model_name].fit(X_train,y_train)\n    predictions = models[model_name].predict(X_test)\n    print(\"\\n---------------\"+model+\"---------------\\n\")\n    print(\"Mean Absolute Error - MAE : \" + str(mean_absolute_error(y_test, predictions)))\n    print(\"Root Mean squared Error - RMSE : \" + str(math.sqrt(mean_squared_error(y_test, predictions)))+\"\\n\")\n    ","8fb30a3f":"for model in models:\n    train_model(model)","ff1b70dc":"def predict(model_name):\n    train_predict=models[model_name].predict(X_train)\n    test_predict=models[model_name].predict(X_test)\n\n    # Transform back to original form\n    train_predict = train_predict.reshape(-1,1)\n    test_predict = test_predict.reshape(-1,1)\n\n    train_predict = scaler.inverse_transform(train_predict)\n    test_predict = scaler.inverse_transform(test_predict)\n    \n    return train_predict, test_predict","c0244f9d":"from itertools import cycle","307828ae":"def eval(model):\n    train_predict, test_predict = predict(model)\n    # shift train predictions for plotting\n    look_back=time_step\n    trainPredictPlot = np.empty_like(closedf)\n    trainPredictPlot[:, :] = np.nan\n    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n\n    # shift test predictions for plotting\n    testPredictPlot = np.empty_like(closedf)\n    testPredictPlot[:, :] = np.nan\n    testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = test_predict\n    \n    original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \n    original_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) \n    \n\n    \n    names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n\n    plotdf = pd.DataFrame({'date': close_stock['Date'],\n                           'original_close': close_stock['Close'],\n                          'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n                          'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n\n    fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n                                              plotdf['test_predicted_close']],\n                  labels={'value':'Close price','date': 'Date'})\n    fig.update_layout(title_text='Prediction avec le '+model,\n                      plot_bgcolor='white', font_size=15, font_color='black',legend_title_text='Close Price')\n    fig.for_each_trace(lambda t:  t.update(name = next(names)))\n\n    fig.update_xaxes(showgrid=False)\n    fig.update_yaxes(showgrid=False)\n    fig.show()\n    \n    ## Variance Regression Score\n    print(\"\\n\\nTrain data explained variance regression score:\", \n          explained_variance_score(original_ytrain, train_predict))\n    print(\"Test data explained variance regression score:\", \n          explained_variance_score(original_ytest, test_predict))\n\n    ## R square score for regression\n    print(\"\\nTrain data R2 score:\", r2_score(original_ytrain, train_predict))\n    print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))\n    \n","d5b793fd":"for model in models:\n    eval(model) \n    ","fa0d884a":"# reshape input\nX_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n\nprint(\"X_train: \", X_train.shape)\nprint(\"X_test: \", X_test.shape)","3c4d9de6":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import LSTM","ad1d3770":"LSTM_model=Sequential()\n\nLSTM_model.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n\nLSTM_model.add(Dense(1))","d5e3da77":"LSTM_model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")","ab277fb4":"LSTM_model.summary()","b05ecc78":"history = LSTM_model.fit( X_train, y_train,\n                         validation_data=(X_test,y_test),\n                         epochs=100, batch_size=32,\n                         verbose=True)","de6a67a8":"predictions = LSTM_model.predict(X_test)\nprint(\"\\n---------------LSTM---------------\\n\")\nprint(\"Mean Absolute Error - MAE : \" + str(mean_absolute_error(y_test, predictions)))\nprint(\"Root Mean squared Error - RMSE : \" + str(math.sqrt(mean_squared_error(y_test, predictions)))+\"\\n\")","45e2482a":"# Plotting Loss vs Validation loss\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(loss))\n\nplt.figure(figsize=(12, 7))\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend(loc=0)\n\nplt.show()","1c92ee35":"train_predict=LSTM_model.predict(X_train)\ntest_predict=LSTM_model.predict(X_test)\ntrain_predict.shape, test_predict.shape\n\n# Transform back to original form\n\ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)\noriginal_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \noriginal_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) ","2f590925":"## Variance Regression Score\nprint(\"Train data explained variance regression score:\", \n      explained_variance_score(original_ytrain, train_predict))\nprint(\"Test data explained variance regression score:\", \n      explained_variance_score(original_ytest, test_predict))","412b387f":"## R square score for regression\nprint(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\nprint(\"Test data R2 score:\", r2_score(original_ytest, test_predict))","36aacf03":"# shift train predictions for plotting\n\nlook_back=time_step\ntrainPredictPlot = np.empty_like(closedf)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(closedf)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = test_predict\n\nnames = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n\n\nplotdf = pd.DataFrame({'date': close_stock['Date'],\n                       'original_close': close_stock['Close'],\n                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n\nfig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n                                          plotdf['test_predicted_close']],\n              labels={'value':'Close price','date': 'Date'})\nfig.update_layout(title_text='Prediction avec LSTM',\n                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\nfig.for_each_trace(lambda t:  t.update(name = next(names)))\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","8bd1002a":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tools.sm_exceptions import ValueWarning, HessianInversionWarning, ConvergenceWarning\n\nwarnings.filterwarnings('ignore', category=ValueWarning)\nwarnings.filterwarnings('ignore', category=HessianInversionWarning)\nwarnings.filterwarnings('ignore', category=ConvergenceWarning)","c99d69cb":"tickerSymbol = 'BTC-USD'\ndata = yf.Ticker(tickerSymbol)","f70e5ebe":"prices = data.history(start='2020-01-01', end='2022-01-31').Close\nreturns = prices.pct_change().dropna()","410a0d8f":"returns","9cae9259":"fig = px.line(prices)\n\nfig.update_layout(title='BTC\/USD Price',\n                   xaxis_title='Time',\n                   yaxis_title='Price',\n                   plot_bgcolor='white')\n\nfig.show()","79f07697":"\nfig = px.line(returns)\n\nfig.update_layout(title='BTC\/USD Price',\n                   xaxis_title='Time',\n                   yaxis_title='Returns',\n                   plot_bgcolor='white')\n\nfig.show()","ef8cdcf9":"log_df = np.log(prices) #log df\n\nfig = px.line(log_df, x=log_df.index, y=\"Close\")\n\nfig.update_layout(title='BTC\/USD Log Price Representation',\n                   xaxis_title='Years',\n                   yaxis_title='LOG Price',\n                   plot_bgcolor='white')\n\nfig.show()","3f74d65d":"# Faisons la diff\u00e9rence et regardons les ACF\nfig, axes = plt.subplots(1, 3,figsize=(24,6))\n\nplt.style.use('seaborn-deep')\n\naxes[0].plot(log_df, color=\"#636EFA\");\naxes[0].set_title('S\u00e9rie lin\u00e9aris\u00e9e')\n             \n# 1\u00e8re diff\u00e9renciation\ny_diff = log_df.diff().dropna()\naxes[1].plot(y_diff, color=\"#636EFA\");\naxes[1].set_title('Diff\u00e9renciation du 1er ordre')\n\n# 2e diff\u00e9renciation\ny_diff_diff = log_df.diff().diff().dropna()\naxes[2].plot(y_diff_diff, color=\"#636EFA\");\naxes[2].set_title('Diff\u00e9renciation de 2\u00e8me ordre')","8df1d80c":"from statsmodels.tsa.stattools import adfuller","bf998efb":"adfuller(log_df)","2b914060":"# check with ADF Test for stationarity\n\ny_diff= log_df.diff().dropna()\ny_diff_diff= log_df.diff().diff().dropna()\n\nprint('p-value zero-diff: ', adfuller(log_df)[1])\nprint('p-value first-diff: ', adfuller(y_diff)[1])\nprint('p-value second-diff: ', adfuller(y_diff_diff)[1])","624a51ed":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\n#figure setup\nfig = plt.figure(figsize=(24,12))\nax1 = fig.add_subplot(2,1,1)\nax1.set_title('1st Order Differencing')\nax2 = fig.add_subplot(2,2,3)\nax3 = fig.add_subplot(2,2,4)\n\n#plots\nax1.plot(y_diff, color=\"#636EFA\")\nplot_acf(y_diff, lags=20, ax=ax2, color=\"#636EFA\");\nplot_pacf(y_diff, lags=20, ax=ax3, color='r', method='ywm')\nplt.show()","00cd6d6d":"log_df","960ec7e3":"#from statsmodels.tsa.arima_model import ARIMA #statsmodels 0.11\nfrom statsmodels.tsa.arima.model import ARIMA #statsmodels >=0.12\n\ny= log_df #just to be precise\n\narima = ARIMA(y, order=(1,1,1))\n#arima = arima.fit(disp = 0 )\narima = arima.fit()\narima.summary()","c12024b2":"!pip install pmdarima\nimport pmdarima as pm\nsmodel = pm.auto_arima(y,\n                       start_p =0, max_p = 5,\n                       start_d = 0, max_d = 5,\n                       start_q = 0, max_q = 5,\n                       seasonal = False,\n                       trace = True)","6bba876d":"train_size=0.7 #70% of data\n\nindex = round(train_size*log_df.shape[0])\n\ny_train = log_df.iloc[:index] #first 70% rows for training set\ny_test = log_df.iloc[index:] #last 30% rows for test set\nn_train=len(y_train)\n\n#results from autoarima\nbest_order = smodel.order # best (p,d,q)","8bca64c7":"print(\"la taille des donn\u00e9es d'entra\u00eenement est: \",y_train.shape[0])\nprint(\"la taille d'\u00e9chantillon du test est: \",y_test.shape[0])","38f73cf7":"y_train","f123413e":"plt.figure(figsize=(20,8))\nplt.plot(ARIMA(y_train,order=best_order).fit().get_forecast(10).predicted_mean)\nplt.plot(ARIMA(y_train,order=best_order).fit().get_forecast(10).conf_int())","cf0a53c7":"arima_df = ARIMA(y_train,order=best_order).fit().get_forecast(10).conf_int()\narima_df['pred'] = ARIMA(y_train,order=best_order).fit().get_forecast(10).predicted_mean\narima_df","f8b7a1e4":"def walk_forward_validation(n_train, test):\n    # create dataframe to store the outcome\n    result = pd.DataFrame(columns=['forecast', 'lower_interval', 'upper_interval'])\n    # predict one point at a time\n    for i in range(len(test)):\n        # define train set\n        train_ = log_df.iloc[:n_train+i].copy()\n        # train the model\n        arima = ARIMA(endog = train_, order=best_order).fit(method_kwargs={\"warn_convergence\": False})\n        # get the forecast\n        results = arima.get_forecast(1, alpha=0.05)\n        # central\n        result.loc[i, 'forecast'] = results.predicted_mean[0]\n        # lower interval\n        result.loc[i, 'lower_interval'] = results.conf_int().iloc[0, 0]\n        # upper interval\n        result.loc[i, 'upper_interval'] = results.conf_int().iloc[0, 1]\n    # join with test dataframe\n    result.index=test.index\n    result = result.apply(pd.to_numeric)\n    test = test.to_frame()\n    print(type(test))\n    return test.join(result)\n\nresult = walk_forward_validation(n_train, y_test)","80b6b5fe":"result","5a5bf865":"# baseline = tomorrows prediction is todays price\nresult['base'] = result['Close'].shift()\nresult['base'].iloc[0] = y_train.to_frame().Close[-1]\nresult.apply(lambda x: np.exp(x).astype('float16')).tail(5) #exp for visualization only","b482a151":"def plot_forecast(fc, train, test, upper=None, lower=None):\n    # shift train predictions for plotting\n    is_confidence_int = isinstance(upper, np.ndarray) and isinstance(lower, np.ndarray)\n    # Prepare plot series\n    fc_series = pd.Series(fc, index=test.index)\n    lower_series = pd.Series(upper, index=test.index) if is_confidence_int else None\n    upper_series = pd.Series(lower, index=test.index) if is_confidence_int else None\n\n    names = cycle(['Training data','Actual close price','Forecast close price'])\n\n\n    plotdf = pd.DataFrame({'date': log_df.index,\n                           'training': train,\n                           'actual': test,\n                           'Forecast': fc_series})\n\n    fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['training'],plotdf['actual'],\n                                              plotdf['Forecast']],\n                  labels={'value':'Close price','date': 'Date'})\n    fig.update_layout(title_text='Prediction avec ARIMA (1, 1, 1)',\n                      plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n    fig.for_each_trace(lambda t:  t.update(name = next(names)))\n\n    fig.update_xaxes(showgrid=False)\n    fig.update_yaxes(showgrid=False)\n    fig.show()","330a3eb8":"plot_forecast(result.forecast, y_train, y_test, np.array(result.upper_interval), np.array(result.lower_interval))","2c1c26c2":"# define a function to get MAPE using y_pred, y_true\ndef get_mape(y_true, y_pred):\n    '''takes y_true, y_pred (pandas series)\n    returns mean absolute percentage error'''\n    mape = 100*((y_true - y_pred)\/y_true).abs().mean()\n    return round(mape, 2)\n\n# define a function to get MASE using y_pred, y_true\ndef get_mase(y_true, y_pred, y_train):\n    '''takes y_true, y_pred (pandas series)\n    returns mean absolute scaled error'''\n    mae_test = (y_true - y_pred).abs().mean()\n    y_t = y_train\n    y_t_1 = y_train.shift(-1)\n    mae_train = (y_t - y_t_1).abs().mean()\n    return round(mae_test\/mae_train, 2)","9fe82d7c":"# MAPE and MASE \nprint('mape model:', get_mape(result.Close, result.forecast))\nprint('mape baseline:', get_mape(result.Close, result.base))\nprint('')\nprint('mase model:', get_mase(result.Close, result.forecast, y_train.to_frame().Close))\nprint('mase baseline', get_mase(result.Close, result.base, y_train.to_frame().Close))","7ce917bc":"forecast_recons = np.exp(result.forecast)\ntrain_recons = np.exp(y_train)\ntest_recons = np.exp(y_test)\nlower_recons = np.array(np.exp(result.lower_interval))\nupper_recons = np.array(np.exp(result.upper_interval))\n\n# plt \nplot_forecast(forecast_recons, train_recons, test_recons, upper_recons, lower_recons)","f319a311":"from tqdm import tqdm\n\nfrom statsmodels.tsa.arima.model import ARIMA\n\nfrom statsmodels.tools.sm_exceptions import ValueWarning, HessianInversionWarning, ConvergenceWarning\nimport warnings\n\n#in practice do not supress these warnings, they carry important information about the status of your model\nwarnings.filterwarnings('ignore', category=ValueWarning)\nwarnings.filterwarnings('ignore', category=HessianInversionWarning)\nwarnings.filterwarnings('ignore', category=ConvergenceWarning)\n\n\n\nprices = data.history(start='2021-04-01', end='2021-10-01').Close\nreturns = prices.pct_change().dropna()","d7fa3326":"def run_simulation(returns, prices, amt, order, thresh, verbose=False, plot=True):\n    if type(order) == float:\n        thresh = None\n        \n    curr_holding = False\n    events_list = []\n    init_amt = amt\n\n    #go through dates\n    for date, r in tqdm (returns.iloc[14:].items(), total=len(returns.iloc[14:])):\n        #if you're currently holding the stock, sell it\n        if curr_holding:\n            sell_price = prices.loc[date]\n            curr_holding=False\n            ret = (sell_price-buy_price)\/buy_price\n            amt *= (1+ret)\n            events_list.append(('s', date, ret))\n            \n            if verbose:\n                print('Sold at $%s'%sell_price)\n                print('Predicted Return: %s'%round(pred,4))\n                print('Actual Return: %s'%(round(ret, 4)))\n                print('=======================================')\n            continue\n\n        #get data til just before current date\n        curr_data = returns[:date]\n        \n        if type(order) == tuple:\n            try:\n                #fit model\n                model = ARIMA(curr_data, order=order).fit()\n                #get forecast\n                pred = model.forecast()[0]\n            \n            except Exception as e:\n                print(e)\n                pred = thresh - 1\n\n\n\n        #if you predict a high enough return and not holding, buy stock\n        if (not curr_holding) and \\\n        ((type(order) == float and np.random.random() < order) \n         or (type(order) == tuple and pred > thresh)\n         or (order == 'last' and curr_data[-1] > 0)):\n            \n            curr_holding = True\n            buy_price = prices.loc[date]\n            events_list.append(('b', date))\n            if verbose:\n                print('Bought at $%s'%buy_price)\n                \n    if verbose:\n        print('Total Amount: $%s'%round(amt,2))\n        \n    #graph\n    if plot:\n    \n        plt.figure(figsize=(18,8))\n        plt.plot(prices[14:])\n\n        y_lims = (int(prices.min()*.95), int(prices.max()*1.05))\n        shaded_y_lims = int(prices.min()*.5), int(prices.max()*1.5)\n\n        for idx, event in enumerate(events_list):\n            plt.axvline(event[1], color='k', linestyle='--', alpha=0.4)\n            if event[0] == 's':\n                color = 'green' if event[2] > 0 else 'red'\n                plt.fill_betweenx(range(*shaded_y_lims), \n                                  event[1], events_list[idx-1][1], color=color, alpha=0.1)\n\n        tot_return = round(100*(amt \/ init_amt - 1), 2)\n        tot_return = str(tot_return) + '%'\n        plt.title(\"%s Price Data\\nThresh=%s\\nTotal Amt: $%s\\nTotal Return: %s\"%(tickerSymbol, thresh, round(amt,2), tot_return), fontsize=20)\n        plt.ylim(*y_lims)\n        plt.show()\n    \n    return amt","3104316e":"run_simulation(returns, prices, 1000, 0.5, None, verbose=False)","28d56bee":"final_amts = [run_simulation(returns, prices, 1000, 0.5, None, verbose=False, plot=False) for _ in range(1000)]","0e62f3f8":"plt.figure(figsize=(20,10))\nsb.distplot(final_amts)\nplt.axvline(np.mean(final_amts), color='r', linestyle='--')\nplt.axvline(1000, color='g')\nplt.title('Avg: $%s\\nSD: $%s'%(round(np.mean(final_amts),2), round(np.std(final_amts),2)), fontsize=20)","fc4f035f":"run_simulation(returns, prices, 1000, 'last', None, verbose=False)","174f3acf":"run_simulation(returns, prices, 1000, (1,1,1), 0.01, verbose=False)","743ee490":"for thresh in [0, 0.001, 0.005]:\n    run_simulation(returns, prices, 1000, (1,0,0), thresh, verbose=False)","7a98cc5c":"for thresh in [0, 0.001, 0.005]:\n    run_simulation(returns, prices, 100, (5,0,5), thresh, verbose=False)","4d79cf75":"!pip install python-binance\nfrom binance.client import Client\nfrom binance.exceptions import BinanceAPIException","5afccf7b":"# Entrez votre cl\u00e9 API ici\napi_key=\"API_KEY_HERE\"\napi_secret=\"API_SECRET_HERE\"","5d753aa8":"client = Client(api_key,api_secret)","352686e0":"pd.DataFrame(client.get_historical_klines('BTCUSDT','1m','30 m ago UTC')).tail()","77ec46b2":"def getminutedata(symbol, interval, lookback):\n    frame = pd.DataFrame(client.get_historical_klines(symbol,interval, lookback+' m ago UTC'))\n    frame = frame.iloc[:,:6]\n    frame.columns = ['Time','Open','High','Low','Close','Volume']\n    frame = frame.set_index('Time')\n    frame.index = pd.to_datetime(frame.index, unit='ms')\n    frame = frame.astype(float)\n    return frame\n","0289d814":"visual_test=getminutedata('BTCUSDT','1m','30')","11aced43":"\nfig = px.line(visual_test.Open)\n\nfig.update_layout(title='BTC\/USD Price',\n                   xaxis_title='Time',\n                   yaxis_title='Price',\n                   plot_bgcolor='white')\n\nfig.show()","f7b09d06":"\ndef strategy(symbol, qty, entried=False):\n    df = getminutedata(symbol, '1m', '30')\n    cumulret = (df.Open.pct_change() + 1).cumprod() - 1\n    if not entried:\n        if cumulret[-1] < -0.002:\n            order = client.create_order(symbol=symbol, side='BUY', type='MARKET', quantity=qty)\n            print(order)\n            enteried = True\n        else:\n            print (\"Aucune transaction n'a \u00e9t\u00e9 ex\u00e9cut\u00e9e\")\n    if entried:\n        while True:\n            df = getminutedata(symbol, '1m', '30')\n            sincebuy = df.loc[df.index > pd.tp_datetime(order['transactTime'], unit='ms')]\n            if len(sincebuy) > 0:\n                sincebuyret = (sincebuy.Open.pct_change() + 1).cumprod() - 1\n                if sincebuyret[-1] > 0.0015 or sincebuyret[-1] \\\n                    < -0.0015:\n                    order = client.create_order(symbol=symbol,\n                            side='SELL', type='MARKET', quantity=qty)\n                    print(order)\n                    break\n","27fe4cef":"\ntry:\n    strategy('BTCUSDT',0.001)\nexcept BinanceAPIException:\n    print(\"le compte a un solde insuffisant pour l'action demand\u00e9e.\")\nexcept Exception as e:\n    print(e)","9ba360f7":"<div style=\"color:grey; font-size:1.2em\">Le travail que nous avons r\u00e9alis\u00e9 a consist\u00e9 \u00e0 exploirer le cycle de vie d'un project de Data Science en general et du Deep Learning et des s\u00e9ries chronologiques en particulier. On bien appris comment collecter les donn\u00e9es, analyser et transformer les donn\u00e9es, dans la partie du Pr\u00e9-traitement on a diviser les donn\u00e9es et adapater nous donn\u00e9es, et derni\u00e8rement la construction des mod\u00e8les en essayant diff\u00e9rentes approches: Mod\u00e8les de base, les R\u00e9seaux de neurones et les Pr\u00e9vision avec les s\u00e9ries chronologiques. Enfin, On a r\u00e9alis\u00e9 des simulations pour evaluer nos mod\u00e8les ainsi qu'on a conncet\u00e9 un service de Trading Beninace pour effecturer les trades.\n<br>\n<br>\n<span style=\"color:black; font-size:1.2em; background-color:#FFFFA6\">Ce projet nous a permis d'acqu\u00e9rir nouvelles techniques, plusieurs biblioth\u00e8ques et packages, ainsi qu'un vision plus claire sur le monde de trading et de crypto-monnaie.<\/span>\n<\/div>","1ae23b10":"\n<h4 style=\"color:red; font-size:1.2em\">Nous perdrons donc environ 5% de notre argent.<\/h4>","9f966d55":"<span style=\"color:grey; font-size:1.2em\">Tra\u00e7ons la valeur du <b>\"Volume\"<\/b> du Bitcoin<\/span>  \n","d5424c0b":"<span style=\"color:grey; font-size:1.2em\">C'est temps d' <b>\u00e9valuer<\/b> notre mod\u00e8le \u00e0 la fois sur les donn\u00e9es d'entra\u00eenement et de test et d'obtenir <b>scores<\/b> de pr\u00e9cision.<\/span>","c245d039":"#### Transformation","f1828ed3":"<span style=\"color:grey; font-size:1.2em\">Encore une fois, nous avons atteint un meilleur score avec des pr\u00e9vision de s\u00e9ries chronologiques en utilisant <b>ARIMA<\/b><\/span>","b202ca96":"\n<span style=\"color:grey; font-size:1.2em\">R\u00e9p\u00e9tez la simulation d'achat al\u00e9atoire <b>1000 fois<\/b> pour vous assurer que nous serons toujours <b>sous la moyenne<\/b> de la somme d'argent <b>1000$<\/b> avec laquelle nous avons commenc\u00e9.<\/span>","3f82fe4f":"<span style=\"color:grey; font-size:1.2em\">Les donn\u00e9es n'ont pas de <b>valeurs manquantes<\/b>, nous n'effectuerons donc pas un <b>nettoyage des donn\u00e9es.<\/b> <\/span>","917c7af4":"\n<span style=\"color:grey; font-size:1.2em\">Juste pour le plaisir, nous allons commencer mais en suivant une approche <b>d'achat al\u00e9atoire<\/b>.<\/span>","6469d53b":"<span style=\"color:grey; font-size:1.2em\">Un aper\u00e7u des donn\u00e9es en utilisant les fonctions <b>info()<\/b> et <b>describe()<\/b> du pandas pour examiner les donn\u00e9es. <\/span>","fd8b2fd4":"<span style=\"color:grey; font-size:1.2em\">Apr\u00e8s avoir appliqu\u00e9 le mod\u00e8le de r\u00e9gression lin\u00e9aire \u00e0 nos donn\u00e9es, nous allons essayer d'impl\u00e9menter un mod\u00e8le de deep learning : LSTM qui est tr\u00e8s adapt\u00e9 \u00e0 ce cas.<\/span>","2fe864a9":"<span style=\"color:grey; font-size:1.2em\">Important nos jeu de donn\u00e9es sous les fichier <b>amazon_cells_labelled.txt<\/b> content les , <b>imdb_labelled.txt<\/b> et <b>yelp_labelled.txt<\/b> content  <b>csv<\/b>.<\/span>","4e15df59":"<span style=\"color:grey; font-size:1.2em\">Dataframe du prix de close du Bitcoin.<\/span>","4ce33adc":"<center id=\"deep-learning\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Approache avec le Deep Learning \ud83e\udde0\n        <\/h2>\n<\/center>","617f60a4":"<span style=\"color:grey; font-size:1.2em\">La fonction `read_html()` transofrome des tableaux HTML dans une liste d'objets DataFrame<\/span>","7805d79c":"#### Technique: AR(1) Model","718b9376":"<span style=\"color:grey; font-size:1.2em\">Les mod\u00e8les des s\u00e9ries chronologiques fonctionnent mieux avec s\u00e9rie stationnaire !\n<b>Essayons de diff\u00e9rencier la version lin\u00e9aris\u00e9e de la s\u00e9rie chronologique.<\/b>\n<br>\n&emsp;&emsp;\ud83d\udc49 Une s\u00e9rie temporelle stationnaire est une s\u00e9rie dont les propri\u00e9t\u00e9s ne d\u00e9pendent pas du moment auquel la s\u00e9rie est observ\u00e9e.<\/span>","c47a0ae2":"<h4 style=\"color:grey\"> Importation de biblioth\u00e8ques <\/h4>","a21a6e8f":"\n<span style=\"color:grey; font-size:1.2em\"><b>Donn\u00e9es \u00e0 utiliser: Bitcoin<\/b><br>\nCes donn\u00e9es doivent \u00eatre subdivis\u00e9es en deux parties: une partie pour l'apprentissage du mod\u00e8le utilis\u00e9 dans le trading (par exemple un historique des donn\u00e9es de l'ann\u00e9e 2020). Une deuxi\u00e8me partie pour la validation (backtesting) du mod\u00e8le (donn\u00e9es 2021 par exemple).<\/span>\n","096d98da":"<span style=\"color:grey; font-size:1.2em\">Commen\u00e7ons le \"training\" notre mod\u00e8le<\/span>","5e4f39cb":"<center id=\"Conclusion\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Conclusion \ud83d\udccc\n        <\/h2>\n<\/center>","ecb5db28":"<div id=\"vis\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Visualisation de donn\u00e9es\n        <\/h3>\n<\/div>","2df9592e":"\n<span style=\"color:grey; font-size:1.2em\">Tra\u00e7ons <b>la matrice de corr\u00e9lation<\/b> pour s\u00e9lectionner les colonnes appropri\u00e9es.<\/span>","1ddceb98":"<center id=\"data\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Collecte de donn\u00e9es \ud83d\udcc2\n        <\/h2>\n<\/center>","260d445c":"\n<span style=\"color:grey; font-size:1.2em\">chaque jour, nous pr\u00e9voyons quelle sera la valeur du Bitcoin du jour suivant si ce r\u00e9sultat pr\u00e9dit est sup\u00e9rieur \u00e0 un seuil que nous sp\u00e9cifions => le bot le fera mais sinon => aucun \u00e9change ne sera ex\u00e9cut\u00e9<\/span>","83a0b875":"**Remarque:**\n- Une p-value (<0,05) sugg\u00e8re une preuve solide contre H0, donc vous **rejetez l'hypoth\u00e8se nulle**. \ud83d\udc49 Stationnaire\n- Une p-value (> 0,05) indique une preuve faible contre H0, donc vous **ne parvenez pas \u00e0 rejeter l'hypoth\u00e8se nulle**. \ud83d\udc49 Non stationnaire","ed5c2661":"<div id=\"model-building\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Evaluation des mod\u00e8les\n        <\/h3>\n<\/div>","f0592e1e":"#### Stationarisation","4acbeb0e":"<span style=\"color:grey; font-size:1.2em\">Normalizing close price value.<\/span>","222b2c88":"<span style=\"color:grey; font-size:1.2em\">Faisons la pr\u00e9diction pour v\u00e9rifer les mesures de performance.<\/span>","e428cba1":"\n<span style=\"color:grey; font-size:1.2em\">Chaque jour, nous pr\u00e9voyons quelle sera la valeur du <b>Bitcoin<\/b> du jour suivant. <br>&emsp;&emsp;Si ce r\u00e9sultat pr\u00e9dit est sup\u00e9rieur \u00e0 un seuil que nous sp\u00e9cifions => <b>Le bot va acheter \ud83d\udcb0<\/b> <br> &emsp;&emsp;Sinon => <b>Aucun \u00e9change ne sera ex\u00e9cut\u00e9 \ud83d\ude34<\/b><\/span>","53f7690d":"<span style=\"color:grey; font-size:1.2em\">Voyons un <b>summary<b> des param\u00e8tres de notre mod\u00e8le<\/span>","761937c9":"<div id=\"eda\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Exploration de donn\u00e9es\n        <\/h3>\n<\/div>","55fc8ce8":"<span style=\"color:grey; font-size:1.2em\">Trouvons les hyperparam\u00e8tres p et q<\/span>","5d378314":"<span style=\"color:grey; font-size:1.2em\">\"Reshape\" l'entr\u00e9e pour qu'elle soit <b>[samples, time steps, features]<\/b> , ce qui est requis pour LSTM.<\/span>  \n","b10761c6":"<center id=\"Intro-section\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Introduction \ud83d\udcd6\n        <\/h2>\n<\/center>","09ef2bf7":"<h4 style=\"color:grey\">Diviser les donn\u00e9es<\/h4>","65e11067":"<span style=\"color:grey; font-size:1.2em\">Dans le cadre de nos \u00e9tudes de la mati\u00e8re Python pour Data Science nous sommes amenez \u00e0 r\u00e9aliser Ce projet qui vise a <b>r\u00e9aliser un bot de trading sous python<\/b>. Le but final est de r\u00e9aliser un  <b>gain maximal<\/b> sur une p\u00e9riode donn\u00e9e (ann\u00e9e 2021 par exemple).\n<\/span>","18dac974":"<span style=\"color:grey; font-size:1.2em\">On va <b>\u00e9valuer<\/b> nos mod\u00e8les \u00e0 la fois sur les donn\u00e9es d'entra\u00eenement et de test et d'obtenir <b>scores<\/b> de pr\u00e9cision.<\/span>","b47fa3f5":"<div id=\"simulation\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Cr\u00e9ation d'une Simulation\n        <\/h3>\n<\/div>\n\n","d8ad35c8":"<div id=\"binance\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Trading in Binance\n        <\/h3>\n<\/div>\n\n","e90b02f2":"<div id=\"eval\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Evaluation\n        <\/h3>\n<\/div>","2aafe35a":"<center id=\"model-eval\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Approache avec les s\u00e9ries chronologiques \ud83d\udcc8\n        <\/h2>\n<\/center>","aeee69a2":"#### Technique: Si le dernier retour \u00e9tait positif, achetez","7b8a5559":"<span style=\"color:grey; font-size:1.2em\"><b>Binance<\/b> est une plateforme qui permet de stocker, acheter, revendre, et \u00e9changer des <b>cryptomonnaies<\/b> contre d'autres cryptomonnaies mais \u00e9galement contre des monnaies fiduciaires telles que l'Euro2 ou le Dollar.<\/span>","fa530ab1":"<span style=\"color:grey; font-size:1.2em\">Nous utilisons le diagramme <b>PACF<\/b> pour calculer la valeur de <b>p<\/b><br>Nous utilisons le graphique <b>ACF<\/b> pour calculer la valeur de <b>q<\/b>\n<\/span>","8589c1f9":"#### Visualisation","da77407f":"<div id=\"pre-processing\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Pr\u00e9-traitement\n        <\/h3>\n<\/div>","a995e8e7":"\n<span style=\"color:grey; font-size:1.2em\">Maintenant on va diviser notre jeu de donn\u00e9es <b>70%<\/b> pour l'entra\u00eenement et <b>30%<\/b> pour le test.<\/span>","e96cd296":"<div id=\"overview\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Aper\u00e7u\n        <\/h3>\n<\/div>","9184916c":"#### Diviser notre s\u00e9rie","fdaa1c88":"<div id=\"data-prep\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Pr\u00e9-traitement\n        <\/h3>\n<\/div>","4134d973":"<h4 style=\"color:grey\"> Explorant notre jeu de donn\u00e9es <\/h4>","36bc0a33":"\n<span style=\"color:grey; font-size:1.2em\">Essayons maintenant un <b>ARIMA(5,0,5)<\/b> <\/span>","cc5feb75":"#### La Strat\u00e9gie de notre Trading Bot","3929c53a":"<h4 style=\"color:grey\"> CANDELSTICK CHARTS<\/h4>","0102164a":"<span style=\"color:grey; font-size:1.2em\">Explorant donc le nouveau Dataframe.<\/span>  \n","9f7a4c34":"<div id=\"trans\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Transformation de donn\u00e9es\n        <\/h3>\n<\/div>","6add0c18":"<div id=\"api\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Les APIs\n        <\/h3>\n<\/div>","7ac32d1f":"<span style=\"color:grey; font-size:1.2em\">Puisqu'on a pas de solde sur mes comptes, nous pouvons pas tester le bot dans le pratique \ud83d\ude1f<span>","dd0d09c0":"<div id=\"LSTM\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  LSTM\n        <\/h3>\n<\/div>","fbef546d":"<span style=\"color:grey; font-size:1.2em\">La cl\u00e9 API est un identifiant unique qui authentifie les requ\u00eates associ\u00e9es \u00e0 votre projet \u00e0 des fins d'utilisation et de facturation. Vous devez avoir au moins une cl\u00e9 API associ\u00e9e \u00e0 votre projet<\/span>","a826c69e":"<div id=\"yfinance\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  La Biblioth\u00e8que yfinance\n        <\/h3>\n<\/div>","dbdc55a0":"<span style=\"color:grey; font-size:1.2em\"><b>yfinance<\/b> est une biblioth\u00e8que open source populaire qui offre un acc\u00e8s aux donn\u00e9es financi\u00e8res disponibles sur <b>Yahoo Finance<\/b>.<\/span>","90923102":"<span style=\"color:grey; font-size:1.2em\">Comme nous pouvons le voir, nous avons atteint un meilleur score avec un r\u00e9seau de neurones artificiels pour nos donn\u00e9es du test qui provient de diff\u00e9rentes sources<\/span>","49990045":"<span style=\"color:grey; font-size:1.2em\">On va scaper les donn\u00e9es du Bitcoin sur le site <b>https:\/\/www.investing.com<\/b><\/span>","aab39661":"<center><h1 style=\"color:#1a1a1a;\n                    font-size:3em\">\n        Python pour \ud83d\udcca Data Science\n        <\/h1> \n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Mini-Projet: Bitcoin Trading \ud83e\udd16 Bot.\n       <\/h2>\n<\/center>","a27ceda5":"<span style=\"color:grey; font-size:1.2em\">\ud83d\udc49 V\u00e9rifiez la stationnarit\u00e9 \u00e0 l'aide du test Augmented Dickey-Fuller\u00a0:\n<br>\n     &emsp;&emsp;\u274c Hypoth\u00e8se nulle : La stationnarit\u00e9 <b>n'existe pas<\/b> dans la s\u00e9rie.\n<br>\n      &emsp;&emsp; \u2757  Hypoth\u00e8se alternative\u00a0: la stationnarit\u00e9 <b>existe<\/b> dans la s\u00e9rie.\n<\/span>","aea5399a":"<div id=\"pandas\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  En utilisant Pandas\n        <\/h3>\n<\/div>","01901bb9":"<span style=\"color:grey; font-size:1.2em\">Nous ne conservons que les donn\u00e9es apr\u00e8s le <b>01\/01\/2020<\/b> comme demand\u00e9.<\/span>  \n","9ed773d0":"<span style=\"color:grey; font-size:1.2em\">Lorsque une s\u00e9rie chronologique a une croissance exponentielle, il est g\u00e9n\u00e9ralement judicieux d'utiliser le logarithme pour rendre l'intrigue plus lin\u00e9aire.<\/span>","70ca528d":"<span style=\"color:grey; font-size:1.2em\">Comme on peut le voir, les approches ml de base obtiennent des r\u00e9sultats respectables, mais nous n'avons obtenu un mod\u00e8le qui fonctionne tr\u00e8s bien sur toutes les donn\u00e9es<\/span>","aef41135":"<div id=\"dataset\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Jeu de donn\u00e9es\n        <\/h3>\n<\/div>","a3d4fbee":"<div id=\"testing\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Tester Les Approaches\n        <\/h3>\n<\/div>\n\n","9c1d0fad":"<div id=\"validation\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Validation\n        <\/h3>\n<\/div>","98d72fc3":"\n<span style=\"color:grey; font-size:1.2em\">Le <b>ARIMA(1,0,0)<\/b> avec un seuil de 0.001 atteint <b>44%<\/b> de retour ce qui est un <b>r\u00e9sultat exceptionnel<\/b> \ud83e\udd11.<\/span>","1ff1c222":"\n<span style=\"color:grey; font-size:1.2em\">Nous d\u00e9finissons la colonne <b>Date<\/b> comme index de notre Dataframe.<\/span>  ","7bc8eb30":"<div id=\"forcasting\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  Pr\u00e9vision\n        <\/h3>\n<\/div>","aeec5d33":"<span style=\"color:grey; font-size:1.2em\">Utilisant par example l'api du <b>coincodex<\/b>.<\/span>","2a6ce37d":"<span style=\"color:grey; font-size:1.2em\">\u00c9valuons \u00e0 l'aide de mesures de performances.<\/span>","be310884":"\n<span style=\"color:grey; font-size:1.2em\">Convertir un tableau de valeurs en une matrice de jeu de donn\u00e9es.<\/span>","3f47b8df":"<span style=\"color:grey; font-size:1.2em\">\u00c0 quoi ressemble ma s\u00e9rie chronologique\u00a0?<\/span>","e46e94d9":"<center id=\"ml-basic\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Approache avec les mod\u00e8les de base du Machine Learning \ud83d\udee0\ufe0f\n        <\/h2>\n<\/center>","4cb0c301":"### Technique: AR(5) Model","a0d89169":"#### Recomposer la s\u00e9rie chronologique initiale","2e098cb8":"\n<span style=\"color:grey; font-size:1.2em\">La technique d'acheter le dernier retour si il est positif est ne fonctionne bien pas pour le bitcoin.<\/span>","bb1e8138":"<span style=\"color:grey; font-size:1.2em\">On choisit les param\u00e8tres de la m\u00e9thode `.compile()`. <br>pour le param\u00e8tre <b>loss<\/b> est <i>mean_squared_error<\/i> afin de calculer la perte d'entropie crois\u00e9e entre les deux \"Labels\" et les pr\u00e9dictions. pour <b>optimizer<\/b> on choisit: <i>adam<\/i> et bien s\u00fbr <i>accuracy<\/i> comme <b>metrics<\/b> <\/span>","face46b4":"<span style=\"color:grey; font-size:1.2em\">Afin de r\u00e9cup\u00e9rer des donn\u00e9es, nous devons sp\u00e9cifier une fausse valeur pour <b>headers<b\/><\/span>","c79f9b8e":"<span style=\"color:grey; font-size:1.2em\">Simulez l'achat et la vente d'actions du Bitcoin en utilisant l'un des mod\u00e8les que nous sp\u00e9cifierons<\/span>","1ab65e15":"<span style=\"color:grey; font-size:1.2em\">Tra\u00e7ons <b>le prix<\/b> du Bitcoin<\/span>  \n","56884f0d":"#### ARIMA","285141dc":"<center id=\"Analysis-section\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Analyses et Transformations \ud83d\udd0e\n        <\/h2>\n<\/center>","22b15efa":"<div style=\"font-size:1.5em\">\n    <p>\ud83d\udcdc Table des mati\u00e8res:<\/p>\n    <ul>\n       <li>\n          <a href=\"#Intro-section\">Introduction \ud83d\udcd6<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#overview\">Aper\u00e7u<\/a><\/li>\n             <li><a href=\"#dataset\">Jeu de donn\u00e9es<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n       <li>\n          <a href=\"#data\">Collecte de donn\u00e9es \ud83d\udcc2<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#pandas\">En utilisant Pandas<\/a><\/li>\n             <li><a href=\"#yfinance\">La Biblioth\u00e8que yfinance<\/a><\/li>\n             <li><a href=\"#api\">Les APIs<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n       <li>\n          <a href=\"#Analysis-section\">Analyses et Transformations \ud83d\udd0e<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#eda\">Exploration de donn\u00e9es<\/a><\/li>\n             <li><a href=\"#trans\">Transformation de donn\u00e9es<\/a><\/li>\n             <li><a href=\"#vis\">Visualisation de donn\u00e9es<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n       <li>\n          <a href=\"#ml-basic\">Approache avec les mod\u00e8les de base du Machine Learning \ud83d\udee0\ufe0f<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#data-pre\">Pr\u00e9paration des donn\u00e9es<\/a><\/li>\n             <li><a href=\"#model-building\">Construction des mod\u00e8les<\/a><\/li>\n             <li><a href=\"#model-eval\">Evaluation des mod\u00e8les<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n        <li>\n          <a href=\"#deep-learning\">Approache avec le Deep Learning \ud83e\udde0<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#pre-processing\">Pr\u00e9-traitement<\/a><\/li>\n             <li><a href=\"#LSTM\">LSTM<\/a><\/li>\n             <li><a href=\"#eval\">Evaluation<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n       <li>\n          <a href=\"#ts\">Approache avec les s\u00e9ries chronologiques \ud83d\udcc8<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#decomposition\">D\u00e9composition<\/a><\/li>\n             <li><a href=\"#forcasting\">Pr\u00e9vision<\/a><\/li>\n             <li><a href=\"#validation\">Validation<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n       <li>\n          <a href=\"#Bot\">Trading \ud83e\udd16 Bot<\/a>\n          <ul>\n              <br>\n             <li><a href=\"#simulation\">Cr\u00e9ation d'une simulation<\/a><\/li>\n             <li><a href=\"#testing\">Tester Les Approaches<\/a><\/li>\n             <li><a href=\"#binance\">Trading in Binance<\/a><\/li>\n              <br>\n          <\/ul>\n       <\/li>\n       <li><a href=\"#Conclusion\">Conclusion \ud83d\udccc<\/a><\/li>\n    <\/ul>\n<\/div>","9da454ac":"<h4 style=\"color:grey\">OHLC CHARTS<\/h4>","6da62661":"<span style=\"color:grey; font-size:1.2em\">Nous allons choisir un ensemble de mod\u00e8les pour commencer<\/span>  \n","76e90855":"<span style=\"color:grey; font-size:1.2em\">Maintenant nous cr\u00e9ons un nouveau mod\u00e8le `Sequential()` puis nous ajoutons<b> 2 couches:<\/b> <br> une couche avec l'activation <b>relu<\/b> avec 10 unit\u00e9s et la deuxieme avec une unit\u00e9.<\/span>","52e591af":"<center id=\"Bot\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Trading \ud83e\udd16 Bot\n        <\/h2>\n<\/center>`","1e8e9f32":"<div id=\"pre-processing\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         \u2b9e  Construction des mod\u00e8les\n        <\/h3>\n<\/div>","ac4f1fc9":"<div id=\"decomposition\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n             \u2b9e  D\u00e9composition\n        <\/h3>\n<\/div>","008c1524":"<span style=\"color:grey; font-size:1.2em\">Nous n'avons pas r\u00e9ussi \u00e0 obtenir un meilleur r\u00e9sultat. Il est possible que nous ayons commenc\u00e9 d'entre dans la phase de \"Overfitting\"<\/span>","52743269":"<div style=\"font-size:1.3em\">\n    <span>\n    R\u00e9alis\u00e9 par :\u00b6\n    <\/span>\n      <ul>\n         <li>ELGHABI Taha<\/li>\n         <li>ELBATOURI Badr-eddine<\/li>\n      <\/ul>\n    <span>\n    Encadr\u00e9 par :\u00b6\n    <\/span>\n      <ul>\n         <li>Pr. H.Laanaya<\/li>\n      <\/ul>\n<\/div>","1bb51d3e":"#### Training the ARIMA"}}