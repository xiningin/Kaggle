{"cell_type":{"6029e246":"code","ac0fe723":"code","543449b1":"code","f3b3b838":"code","5eb7ff23":"code","8fe8505e":"code","450e0acd":"code","74c2a45c":"code","b5a27f39":"code","533ad6ce":"code","f5cbecac":"code","627d06d4":"code","7e495987":"code","72873646":"code","6977d1aa":"code","eaa2b517":"code","03afa060":"markdown","7b65966f":"markdown","b8475757":"markdown","e3b1e0dd":"markdown","eac94e4d":"markdown","c2b3df75":"markdown","b4eb9068":"markdown","48915a74":"markdown"},"source":{"6029e246":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport seaborn as sns","ac0fe723":"!ls ..\/input\/cat-in-the-dat\/ -GFlash --color","543449b1":"train = pd.read_csv('..\/input\/cat-in-the-dat\/train.csv')\ntest = pd.read_csv('..\/input\/cat-in-the-dat\/test.csv')\nss = pd.read_csv('..\/input\/cat-in-the-dat\/sample_submission.csv')","f3b3b838":"target_0_pct = (train.groupby('target').count()['id'][0] \/ len(train) * 100)\ntarget_0_count = train.groupby('target').count()['id'][0]\ntarget_1_pct = (train.groupby('target').count()['id'][1] \/ len(train) * 100)\ntarget_1_count = train.groupby('target').count()['id'][1]","5eb7ff23":"print('Target of 0: in {} observations {:0.2f}%'.format(target_0_count, target_0_pct))\nprint('Target of 1: in {} observations {:0.2f}%'.format(target_1_count, target_1_pct))","8fe8505e":"train.groupby('target').count()['id'].plot(kind='barh', figsize=(15, 5), title='Target 1 vs 0')\nplt.show()","450e0acd":"train[['bin_0','bin_1','bin_2','bin_3','bin_4','target']].head()","74c2a45c":"bin_feats = ['bin_0','bin_1','bin_2','bin_3','bin_4']\nfor b in bin_feats:\n    print(f'Feature {b} has unique values: {train[b].unique()}')","b5a27f39":"for f in bin_feats:\n    fig, ax = plt.subplots(figsize=(15, 3))\n    sns.catplot(y=f, hue=\"target\", kind=\"count\",\n                palette=\"Greens_r\", edgecolor=\".6\",\n                data=train, ax=ax)\n    ax.set_title(f'Distribution of Feature {f}')\n    plt.close(2)\n    plt.show()","533ad6ce":"nom_feats = [f for f in train.columns if 'nom_' in f]","f5cbecac":"for n in nom_feats:\n    if len(train[n].unique()) < 20:\n        print(f'Feature {n} has unique values: {train[n].unique()}')\n    else:\n        print(f'Feature {n} has a lot of values: {len(train[n].unique())}')","627d06d4":"for f in nom_feats[:5]:\n    fig, ax = plt.subplots(figsize=(15, 5))\n    sns.catplot(y=f, hue=\"target\", kind=\"count\",\n                palette=\"Blues_r\", edgecolor=\".6\",\n                data=train, ax=ax)\n    ax.set_title(f'Distribution of Feature {f}')\n    plt.close(2)\n    plt.show()","7e495987":"ord_feats = [f for f in train.columns if 'ord_' in f]","72873646":"for n in ord_feats:\n    if len(train[n].unique()) < 200:\n        print(f'Feature {n} has unique values: {train[n].unique()}')\n    else:\n        print(f'Feature {n} has a lot of values: {len(train[n].unique())}')","6977d1aa":"for f in ord_feats[:4]:\n    fig, ax = plt.subplots(figsize=(15, 5))\n    sns.catplot(y=f, hue=\"target\", kind=\"count\",\n                palette=\"Reds_r\", edgecolor=\".6\",\n                data=train, ax=ax)\n    ax.set_title(f'Distribution of Feature {f}')\n    plt.close(2)\n    plt.show()","eaa2b517":"ts_feats = ['day','month']\nfor f in ts_feats:\n    fig, ax = plt.subplots(figsize=(15, 5))\n    sns.catplot(y=f, hue=\"target\", kind=\"count\",\n                palette=\"Dark2_r\", edgecolor=\".6\",\n                data=train, ax=ax)\n    ax.set_title(f'Distribution of Feature {f}')\n    plt.close(2)\n    plt.show()","03afa060":"# Categorical Feature Challenge\n\nThis notebook provides some simple exploratory data analysis of the Categorical Feature Challenge data. Get ready for a lot of horizontal bar plots due to the nature of this data!\n\nFrom the competition description: **This Playground competition will give you the opportunity to try different encoding schemes for different algorithms to compare how they perform. We encourage you to share what you find with the community.**","7b65966f":"# ord features","b8475757":"# bin Features\n- bin_0 to bin_2 : Binary Features (1 or 0)\n- bin_3 : T\/F\n- bin_4 : Y\/N\n\nRegardless these are all binary features with only two possible values","e3b1e0dd":"# nom Features","eac94e4d":"# Data\nFrom the data description:\n\n***\nIn this competition, you will be predicting the probability [0, 1] of a binary target column.\n\nThe data contains binary features (bin_*), nominal features (nom_*), ordinal features (ord_*) as well as (potentially cyclical) day (of the week) and month features. The string ordinal features ord_{3-5} are lexically ordered according to string.ascii_letters.\n\nSince the purpose of this competition is to explore various encoding strategies, the data has been simplified in that (1) there are no missing values, and (2) the test set does not contain any \"unseen\" feature values. (Of course, in real-world settings both of these factors are often important to consider!)\n***","c2b3df75":"# Time series features\n- Day\n- Month","b4eb9068":"## Files\n- train.csv\n- test.csv\n- sample_submission.csv","48915a74":"## Distribution of Target"}}