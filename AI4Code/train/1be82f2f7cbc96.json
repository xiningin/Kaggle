{"cell_type":{"99a0d217":"code","3b8f4f74":"code","82d1b6f2":"code","6f377053":"code","b9393abe":"code","5e1c5c94":"code","44e59a6a":"code","01879a32":"code","58905a1a":"code","971ff308":"code","a53b6ce5":"code","700b281f":"code","e7b4cec6":"markdown","8ae72d2e":"markdown","366935f1":"markdown","5de1cb5f":"markdown","ab1bdac6":"markdown","ed40046a":"markdown","06174a25":"markdown","6ee0940e":"markdown","1015283a":"markdown"},"source":{"99a0d217":"import os\nimport pandas as pd\n\n# set parameters\nproc_img_width = 224\nproc_img_height = 224\n\n# load csv data\ntrain_data = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\n\n# set image path\ntrain_img_path = '..\/input\/petfinder-pawpularity-score\/train'","3b8f4f74":"from tqdm import tqdm, trange\nimport numpy as np\nimport tensorflow as tf\n\ntrain_ids = train_data['Id'][:]\ntrain_label = train_data['Pawpularity'][:]\n\n# train_imgs = []\n# for i in trange(len(train_ids)):\n#     path = os.path.join(train_img_path, train_ids[i] + '.jpg')\n#     image = tf.image.decode_jpeg(tf.io.read_file(path), channels = 3)\n#     image = tf.cast(tf.image.resize_with_pad(image, proc_img_width, proc_img_height), dtype = tf.int32)\n#     train_imgs.append(image)\n# train_imgs = np.array(train_imgs)\n\nprint(train_ids.shape, train_label.shape)","82d1b6f2":"total_cnt = train_ids.shape[0]\nprint(total_cnt)\n\nsplit_rate = 0.9\n\ntrain_label_re = np.array(train_label).reshape(-1, 1)\n\ntrain_id = np.array(train_ids[:(int)(total_cnt * split_rate)])\nval_id = np.array(train_ids[(int)(total_cnt * split_rate):])\ntrain_pawp = train_label_re[:(int)(total_cnt * split_rate)]\nval_pawp = train_label_re[(int)(total_cnt * split_rate):]\n\nprint(train_id.shape, train_pawp.shape)\nprint(val_id.shape, val_pawp.shape)","6f377053":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.metrics import *\nfrom tensorflow.keras import *\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0\n\npre_train_model = load_model('..\/input\/keras-applications-models\/EfficientNetB0.h5')\npre_train_model.trainable = False","b9393abe":"input1 = Input(shape = (proc_img_width, proc_img_height, 3))\n# input2 = Input(shape = (train_other_fe.shape[1],))\n\nmodel_feat1 = layers.experimental.preprocessing.RandomFlip(mode = 'horizontal')(input1)\n\nmodel_feat1 = pre_train_model(model_feat1)\n\nmodel_feat1 = BatchNormalization()(model_feat1)\nmodel_feat1 = Dropout(0.2)(model_feat1)\nmodel_feat1 = Dense(32, activation = \"relu\")(model_feat1)\n\n# model_feat1 = Dense(8, activation = \"relu\", kernel_initializer = \"normal\")(model_feat1)\n\n# model_feat2 = Dense(8, activation = \"relu\", kernel_initializer = \"normal\")(input2)\n# model_feat2 = Dense(8, activation = \"relu\", kernel_initializer = \"normal\")(model_feat2)\n\n# model_feat = add([model_feat1, model_feat2])\n\n# model_feat = Dense(16, activation = \"relu\", kernel_initializer = \"normal\")(model_feat1)\nmodel_feat = Dense(1)(model_feat1)\n\n# model = Model(inputs = [input1, input2], outputs = model_feat)\nmodel = Model(inputs = input1, outputs = model_feat)\n\n# gradually decrease learning rate\nlr_schedule = schedules.ExponentialDecay(\n    initial_learning_rate = 1e-3,\n    decay_steps = 100,\n    decay_rate = 0.96,\n    staircase = True)\n\n# compile model network\nmodel.compile(optimizer = Adam(learning_rate = lr_schedule),\n             loss = losses.MeanSquaredError(),\n             metrics = [metrics.RootMeanSquaredError()])\n\nmodel.summary()","5e1c5c94":"from tensorflow.keras.utils import *\nfrom sklearn.utils import shuffle\n\nclass DataGenerator(Sequence):\n    def __init__(self, id_data, pawp_data, batch_size = 128, shuffle = True):\n        'Initialization'\n        self.id_data = id_data\n        self.pawp_data = pawp_data\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(self.pawp_data.shape[0] \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        id_batch = self.id_data[index * self.batch_size : (index + 1) * self.batch_size]\n        pawp_data = self.pawp_data[index * self.batch_size : (index + 1) * self.batch_size]\n\n        # make image batch\n        img_batch = []\n        for i in range(self.batch_size):\n            path = os.path.join(train_img_path, id_batch[i] + '.jpg')\n            image = tf.image.decode_jpeg(tf.io.read_file(path), channels = 3)\n            image = tf.cast(tf.image.resize_with_pad(image, proc_img_width, proc_img_height), dtype = tf.int32)\n            img_batch.append(image)\n            \n            # release buffer\n            del path\n            del image\n        img_batch = np.array(img_batch).astype(np.float32)\n        \n        # release buffer\n        del id_batch\n\n        # return [img_batch.astype(np.float32), feat_batch.astype(np.float32)], pawp_data\n        return img_batch, pawp_data\n\n    def on_epoch_end(self):\n        if self.shuffle == True:\n            self.id_data, self.pawp_data = shuffle(self.id_data, self.pawp_data)","44e59a6a":"from tensorflow.keras.callbacks import *\n\n# define callback for best result training\nearly_stop = EarlyStopping(\n    monitor = 'val_loss', patience = 5, restore_best_weights = True)","01879a32":"train_gen = DataGenerator(train_id, train_pawp, shuffle = False)\nval_gen = DataGenerator(val_id, val_pawp, shuffle = False)\n\nhistory = model.fit(train_gen, epochs = 1, validation_data = val_gen,\n                    # use_multiprocessing = True, workers = -1)\n                    use_multiprocessing = True, workers = -1,\n                    callbacks = [early_stop])","58905a1a":"import matplotlib.pyplot as plt\n\nrmse = history.history['root_mean_squared_error']\nval_rmse = history.history['val_root_mean_squared_error']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(rmse) + 1)\n\nplt.plot(epochs, rmse, 'bo', label='Training rmse')\nplt.plot(epochs, val_rmse, 'b', label='Validation rmse')\nplt.title('Training and validation rmse')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","971ff308":"del train_data\ndel train_img_path\n\ndel train_ids\ndel train_label\n\ndel train_label_re\ndel train_id\ndel val_id\ndel train_pawp\ndel val_pawp\n\ndel train_gen\ndel val_gen\ndel history","a53b6ce5":"test_data = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest_img_path = '..\/input\/petfinder-pawpularity-score\/test'\n\ntest_ids = test_data['Id'][:]\n\ntest_imgs = []\nfor i in trange(len(test_ids)):\n    path = os.path.join(test_img_path, test_ids[i] + '.jpg')\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels = 3)\n    image = tf.cast(tf.image.resize_with_pad(image, proc_img_width, proc_img_height), dtype = tf.int32)\n    test_imgs.append(image)\ntest_imgs = np.array(test_imgs)\n\nprint(test_imgs.shape)","700b281f":"commit_x1 = np.array(test_imgs)\n# commit_x2 = np.array(test_other_feat).astype(np.float32)\n\n# predictions = model.predict([commit_x1, commit_x2]).reshape(commit_x1.shape[0],)\npredictions = model.predict(commit_x1).reshape(commit_x1.shape[0],)\nsubmission_df = pd.DataFrame()\n\nsubmission_df['Id'] = test_ids\nsubmission_df['Pawpularity'] = predictions\nsubmission_df.to_csv('submission.csv',index = False)\n\n# show result\nprint(submission_df.head(10))\n\nprint('Finished')","e7b4cec6":"Start training.","8ae72d2e":"# Process Image\nResize all image as predefined size (proc_img_width x proc_img_height).\n\nAlso make image batch for train and test data.","366935f1":"# Clear Buffer\n\nClear all buffer for reduce memory.","5de1cb5f":"And then define model network.","ab1bdac6":"# Train with NN\n\nTrain data with simple neural network.\n\nFirst load pretrained image classification model (EfficientNet B0)","ed40046a":"# Show Train Result\n\nShow trained result as graph.","06174a25":"# Hello\nThis notebook is for PetFinder.my competition.\n\nI'll use tensorflow for training data.\n\nFirst import train and test data for process.","6ee0940e":"# Prepare Test Data\n\nPrepare test data with feature and train_data.","1015283a":"# Evaluation & Submit\n\nEvaluation with trained model and save result as csv."}}