{"cell_type":{"8dead118":"code","881f1670":"code","fd044dba":"code","634fc3bc":"code","5c971cfc":"code","59c0e852":"code","2a9887b8":"code","f9b2418f":"code","71e3b4b8":"code","a0e5dd8d":"code","e8ca7a18":"code","639384a7":"code","9576e192":"code","d1ed24ed":"code","0e64bf6e":"code","c5ddcda1":"code","1cedf9a8":"markdown","8b0e4c2a":"markdown","513c187f":"markdown","6e3e96f3":"markdown"},"source":{"8dead118":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nimport scipy as sc\nimport sklearn as sk\nfrom sklearn import decomposition\nfrom sklearn import svm\nfrom sklearn import preprocessing\nfrom sklearn import ensemble\nfrom sklearn import metrics \nimport seaborn as sn\nfrom scipy import stats\nimport lightgbm as lgbm\nimport catboost as catgbm\nfrom sklearn.feature_selection import SelectFromModel\nimport warnings\nwarnings.filterwarnings('ignore')   ","881f1670":"df_train= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test  = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndf_test_index = df_test.Id\ndf_out = df_train.SalePrice  #seperating output\ndf_train = df_train.drop(['Id','SalePrice','MiscVal','MiscFeature','Alley'],axis=1) #dropping ID, output and few not so useful features\ndf_test  = df_test.drop(['Id','MiscVal','MiscFeature','Alley'],axis=1)\ndf = pd.concat([df_train,df_test], ignore_index = True)  #joining train and test data\n\ndataType = pd.read_csv('..\/input\/datatype\/categoricalDataType.csv',header = None,index_col = 0)","fd044dba":"#handling missing data for lot frontage based on building type and lot area\n#Town houses\nTwnhs1 = np.mean(df.LotFrontage.loc[df.BldgType.\n            isin(['TwnhsE','Twnhs'])&(df.LotFrontage.notnull())\n             &(df['LotArea']<=6000)])\nTwnhs2  = np.mean(df.LotFrontage.loc[df.BldgType.\n            isin(['TwnhsE','Twnhs'])&(df.LotArea>=6000)\n            &(df['LotFrontage'].notnull())])    \ndf.LotFrontage.loc[df.BldgType.\n            isin(['TwnhsE','Twnhs'])&df.LotFrontage.isnull()&\n            (df['LotArea']<=6000)] = Twnhs1\ndf.LotFrontage.loc[df.BldgType.\n            isin(['TwnhsE','Twnhs'])&df.LotFrontage.isnull()&\n            (df['LotArea']>=6000)] = Twnhs2 \n# rest of the houses\nrhse1 = np.mean(df.LotFrontage.loc[~(df.BldgType.\n            isin(['TwnhsE','Twnhs']))&(df.LotFrontage.notnull())\n             &(df['LotArea']<=6000)])\nrhse2  = np.mean(df.LotFrontage.loc[~(df['BldgType'].\n            isin(['TwnhsE','Twnhs']))&(df['LotArea']>=6000)\n            &(df['LotFrontage'].notnull())])    \ndf.LotFrontage.loc[df.LotFrontage.isnull()&\n            (df.LotArea<=6000)] = rhse1\ndf.LotFrontage.loc[df.LotFrontage.isnull()&\n            (df.LotArea>=6000)] = rhse2","634fc3bc":"#handling categorical variables\ndf_cat = df.fillna(0)\ndf = df.fillna(0)\ndataType = dataType.fillna(0)\nfor col in df.columns: \n    if (dataType.loc[col,1] == 'ordinal'): \n        df_cat = pd.get_dummies(df_cat,columns=[col])\n    if (dataType.loc[col,1] == 'nominal'):\n        if (dataType.loc[col,2] == 0):\n           df_cat.loc[:,col] = df_cat.loc[:,col].astype('category')\n           df_cat.loc[:,col] = df_cat.loc[:,col].cat.codes\n        else:\n          labels = dataType.loc[col,2].split(\",\")\n          replace_map_comp = {col: {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n          print(replace_map_comp)\n          df_cat.replace(replace_map_comp, inplace=True)","5c971cfc":"#Seperating the training data and the test data\ndf_cat_train = df_cat.iloc[0:1460,:]\ndf_cat_test = df_cat.iloc[1460:,:]","59c0e852":"#Identify the continuous variables for outlier detection.\ncont_variables = df_train.columns[(dataType.loc[df_train.columns,1]=='continuous')]\nprint(cont_variables)","2a9887b8":"outlier_filter = (np.abs(df_cat_train[cont_variables].apply(sc.stats.zscore)) < 5).all(axis=1) \ntrain_inp_no_outlier = df_cat_train[outlier_filter]\ntrain_out_no_outlier = df_out[(outlier_filter)]    \nprint(train_inp_no_outlier.shape)\nsn.scatterplot(x = train_inp_no_outlier['GrLivArea'],y = train_out_no_outlier)","f9b2418f":"#scaling the data\nscaler =  preprocessing.StandardScaler()\ntrain_scale = scaler.fit(train_inp_no_outlier)\ntest_inp  = scaler.transform(df_cat_test)\ntrain_inp_scale= scaler.transform(train_inp_no_outlier)\ntrain_out_scale = preprocessing.minmax_scale(train_out_no_outlier,feature_range=(0,1))","71e3b4b8":"train_inp,valid_inp,train_out,valid_out = sk.model_selection.train_test_split(train_inp_scale,train_out_scale,test_size=0.1,random_state=50)","a0e5dd8d":"#pca_fsel = decomposition.PCA(n_components = 30).fit(df_train_inp)\n#train_inp = pca_fsel.fit_transform(df_train_inp)\n#valid_inp = pca_fsel.fit_transform(df_valid_inp)\n#test_inp  = pca_fsel.fit_transform(df_cat_test)\n#train_inp =  preprocessing.minmax_scale(train_inp,feature_range=(0, 1))\n#valid_inp =  preprocessing.minmax_scale(valid_inp,feature_range=(0, 1))\n#test_inp  =  preprocessing.minmax_scale(test_inp,feature_range=(0, 1))\n#train_out_pre = preprocessing.minmax_scale(df_train_out,feature_range=(0,1))","e8ca7a18":"#defining the model a.k.a setting the hyperparameters\nclf_lgbm = lgbm.LGBMRegressor(boosting_type='gbdt', max_depth=4, learning_rate=0.1, n_estimators=200)\nclf_gbt = sk.ensemble.GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=120,\n                                           min_samples_split=2, max_depth=4,validation_fraction=0.1)\n\n# Fitting regression model a.k.a training the model \nclf_lgbm.fit(train_inp, train_out)\nclf_gbt.fit(train_inp,train_out)\n\n#predicting the validation output and rescaling it to original price\nvalid_pred1 = clf_lgbm.predict(valid_inp)\nvalid_pred2 = clf_gbt.predict(valid_inp)\nvalid_pred1 = preprocessing.minmax_scale(valid_pred1,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nvalid_pred2 = preprocessing.minmax_scale(valid_pred2,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nvalid_out_rescaled = preprocessing.minmax_scale(valid_out,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nvalid_out_rescaled = preprocessing.minmax_scale(valid_out,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\n#calculating the error\nprint(metrics.mean_squared_log_error(valid_pred1,valid_out_rescaled))\nprint(metrics.mean_squared_log_error(valid_pred2,valid_out_rescaled))\n\n#calculating the training error.\ntrain_pred1 = clf_lgbm.predict(train_inp)\ntrain_pred2 = clf_gbt.predict(train_inp)\ntrain_pred1 = preprocessing.minmax_scale(train_pred1,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\ntrain_pred2 = preprocessing.minmax_scale(train_pred2,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\ntrain_out_rescaled = preprocessing.minmax_scale(train_out,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\ntrain_out_rescaled = preprocessing.minmax_scale(train_out,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nprint(metrics.mean_squared_log_error(train_pred1,train_out_rescaled))\nprint(metrics.mean_squared_log_error(train_pred2,train_out_rescaled))","639384a7":"featSel = SelectFromModel(clf_lgbm,prefit = True)\ntrain_inp_imp = featSel.transform(train_inp)\nvalid_inp_imp = featSel.transform(valid_inp)\n\nclf_lgbm_imp = lgbm.LGBMRegressor(boosting_type='gbdt', max_depth=3, learning_rate=0.1, n_estimators=400)\nclf_gbt_imp = sk.ensemble.GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=400,\n                                           min_samples_split=10, max_depth=3,validation_fraction=0.1)\n# Fit regression model\nclf_lgbm_imp.fit(train_inp_imp, train_out)\nclf_gbt_imp.fit(train_inp_imp,train_out)\n\n#calculating the validation error\nvalid_pred1 = clf_lgbm_imp.predict(valid_inp_imp)\nvalid_pred2 = clf_gbt_imp.predict(valid_inp_imp)\nvalid_pred1 = preprocessing.minmax_scale(valid_pred1,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nvalid_pred2 = preprocessing.minmax_scale(valid_pred2,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nprint(metrics.mean_squared_log_error(valid_pred1,valid_out_rescaled))\nprint(metrics.mean_squared_log_error(valid_pred2,valid_out_rescaled))\n\n#calculating the training error\ntrain_pred1 = clf_lgbm_imp.predict(train_inp_imp)\ntrain_pred2 = clf_gbt_imp.predict(train_inp_imp)\ntrain_pred1 = preprocessing.minmax_scale(train_pred1,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\ntrain_pred2 = preprocessing.minmax_scale(train_pred2,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\nprint(metrics.mean_squared_log_error(train_pred1,train_out_rescaled))\nprint(metrics.mean_squared_log_error(train_pred2,train_out_rescaled))","9576e192":"print(np.shape(train_inp_imp))","d1ed24ed":"!pwd","0e64bf6e":"#test predict\ntest_inp_imp = featSel.transform(test_inp)\ndf_test_index.reset_index()\ntest_pred = clf_gbt_imp.predict(test_inp_imp)\ntest_pred =preprocessing.minmax_scale(test_pred,feature_range=(min(train_out_no_outlier),max(train_out_no_outlier)))\npred_values = pd.DataFrame(test_pred, columns=['SalePrice'])\npred_val = pd.concat([df_test_index,pred_values],axis = 1)\npred_val.to_csv('\/kaggle\/working\/submission.csv',index = False)","c5ddcda1":"    from IPython.display import FileLink\n    FileLink(r'submission.csv')","1cedf9a8":"## preprocessing with pca","8b0e4c2a":"## Loading Data and preprocessing","513c187f":"## Model Fit with feature selection","6e3e96f3":"## Defining the models"}}