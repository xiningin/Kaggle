{"cell_type":{"fb214f6d":"code","6b8f1adf":"code","a767c1b3":"code","08cd07b8":"code","9c4bbbc2":"code","7eb98c09":"code","44c43762":"code","34e6cbbf":"code","171a13b6":"code","08f40248":"code","1a5197ab":"code","86b78785":"code","db65b57c":"code","0065089d":"code","40111794":"code","27e1fe9f":"code","0135c463":"code","31384a56":"code","0825ef7d":"code","f6ccfce0":"code","47492f3b":"code","71415c7c":"code","84c60f65":"code","9be2259f":"code","c6bb2372":"markdown","d2c97805":"markdown","6d35b8c8":"markdown","0fcf83d2":"markdown","5ee69a9f":"markdown","cafd2319":"markdown","0632b582":"markdown","a0d56424":"markdown","33965264":"markdown","0ed39630":"markdown","122a519d":"markdown","fffdf7ee":"markdown","907119fc":"markdown","b947c9f5":"markdown","556a4d69":"markdown","c39e9ac0":"markdown","58b6a1d2":"markdown"},"source":{"fb214f6d":"#installing the tweepy library to access the twitter API\n\n!pip install tweepy==3.10.0\n\n#textblob library is installed and used for the sentiment analysis\n\n!pip install textblob\n\n#wordcloud library for WordCloud visualization\n\n!pip install wordcloud","6b8f1adf":"from textblob import TextBlob\nfrom wordcloud import WordCloud,STOPWORDS\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tweepy as tw\n\nimport re\nimport datetime\nimport time","a767c1b3":"#Saving unique consumer keys of Twitter API provided via twitter dev account\n\nconsumer_key = 'enter your key here'\nconsumer_secret = 'enter your key here'\naccess_token = 'enter your key here'\naccess_token_secret = 'enter your key here'\n\n#Above hidden for since keys are confidential. You can get access by apply for a twitter development account mentioned above.","08cd07b8":"#Authorizing Twitter API\n\nauth = tw.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\napi = tw.API(auth, wait_on_rate_limit=True)","9c4bbbc2":"polarity_values= [] #initializing an empty list for extending df withe new scrapes \ndate_list= [] #initializing an empty list for extending df withe new scrapes","7eb98c09":"search = input(\"Enter keyword\/hashtag: \")\nsearchterm = search + \" -filter:retweets\" #Applying filter to ignore retweets\nNumberOfTerms = int(input(\"Number of tweets to be extracted every 24 hours (max 3000):\"))\n#cycle = int (input(\"Tweets are extracted after these many days(max 7): \"))","44c43762":"#Defining a fuction to clean tweets and remove URLs\n\ndef remove_url(txt):\n    \n    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\\/\\\/\\S+)\", \"\",txt).split())","34e6cbbf":"def scrape_to_list(n):\n        \n#Getting Date of n no of days from current date\n    \n    today = datetime.datetime.now()\n    days = datetime.timedelta(n)\n\n    minus = today - days\n\n    formated_date = '\"'+minus.strftime(\"%Y-%m-%d\")+'\"' #date the tweet will be scraped until\n\n    date_label = (today - datetime.timedelta(n+1)).strftime(\"%Y-%m-%d\") #date just for printing label\n    \n    \n#first query for scraping tweets to calculate polarity via textblob\n\n    tweets1 = tw.Cursor(api.search,q=searchterm,  \n                       result_type='recent', \n                       timeout=999999,\n                       lang = 'en',\n                       tweet_mode='extended',\n                       until = formated_date, #supports max of 7 days from current date\n                       count=NumberOfTerms).items(NumberOfTerms)\n\n#removing url from tweets using the functioned defined before\n    \n    tweets_no_urls = [remove_url(tweet.full_text) for tweet in tweets1] \n\n#creating objects of Tweets for applying TextBlob\n\n    sentiment_objects = [TextBlob(tweet) for tweet in tweets_no_urls]\n\n#Extending polarity calculated using textBlob and tweets to a list (polarity_values)\n    polarity_values.extend ([[tweet.sentiment.polarity, str(tweet)] \n                        for tweet in sentiment_objects]) #appending the list with new tweets added after every cycle\n\n#second query for scraping dates from tweets\n\n    tweets2= tw.Cursor(api.search,q=searchterm,  \n                       result_type='recent', \n                       timeout=999999,\n                       lang = 'en',\n                       tweet_mode='extended',\n                       until = formated_date,\n                       count=NumberOfTerms).items(NumberOfTerms)\n\n#scraping dates from tweet and extending them into the date_list\n    date_list.extend([[tweet.created_at] for tweet in tweets2])\n    \n    print ('max %s tweets scraped and extended to list from:'%NumberOfTerms, date_label)","171a13b6":"def scrape_tweets():\n\n    print('started scraping tweets for [%s]...'%search)\n\n    scrape_to_list(-1)\n    scrape_to_list(0)\n    scrape_to_list(1)\n    scrape_to_list(2)\n    scrape_to_list(3)\n    scrape_to_list(4)\n    scrape_to_list(5)\n\n    print('scraping complete!')","08f40248":"#tweets are scraped for last 7 days\n\nscrape_tweets()","1a5197ab":"#saving list of polarity values and tweet into a DF\npolarity_df = pd.DataFrame(polarity_values, columns=[\"polarity\", \"tweet\"])\n\n#saving dates in a sepearate dataframe\ndate_df = pd.DataFrame(date_list,columns=['Date'])","86b78785":"#Merging the two DFs into one\n\ntweets_merged_df = pd.concat([polarity_df, date_df], axis=1).reindex(polarity_df.index)\n\ntweets_merged_df #this dataset does not include retweets and url only tweets","db65b57c":"# Tagging polarity with respective sentiment category\n\ntweets_merged_df.loc[tweets_merged_df['polarity'] > 0.0, 'Sentiment'] = 'POSITIVE'\ntweets_merged_df.loc[tweets_merged_df['polarity'] < 0.0, 'Sentiment'] = 'NEGATIVE'\ntweets_merged_df.loc[tweets_merged_df['polarity'] == 0.0, 'Sentiment'] = 'NEUTRAL'\n\ntweets_merged_df","0065089d":"#Removing duplicated Tweets if any\ntweets_merged_df.drop_duplicates(subset=None, keep='first', inplace=True)\n\ntweets_merged_df","40111794":"# Removing polarity values equal to zero as that can askew analysis\n\ntweets_merged_df = tweets_merged_df[tweets_merged_df.polarity != 0.0]\n\ntweets_merged_df","27e1fe9f":"#Exporting Raw Data Data Frame to CSV\ntweets_merged_df.to_csv('Tweets_Raw_Data (%s) .csv'%search)","0135c463":"#Counting and aggregating positive and negative sentiments into respective variables to be analyzed\n\nPositive = tweets_merged_df[tweets_merged_df.Sentiment == 'POSITIVE'].shape[0]\nNegative = tweets_merged_df[tweets_merged_df.Sentiment == 'NEGATIVE'].shape[0]\n\nprint ('Positive Sentiments:',Positive)\nprint ('Negative Sentiments:',Negative)","31384a56":"#Pie Chart (Positive vs Negative Percentage)\n\nlabels = 'Positive', 'Negative'\nsizes = [Positive, Negative]\ncolors = ['yellowgreen', 'lightcoral']\nexplode = (0.1, 0)  # explode 1st slice\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\nplt.axis('equal')\nplt.savefig('piechart.png')\nplt.show()","0825ef7d":"#Creating DF to plot sentiment values against date | New tweets will be added if code is scheduled to run evey 7 days\n\ndf_by_day_sentiment = tweets_merged_df.groupby([pd.Grouper(key='Date', freq='D'), 'Sentiment']) \\\n    .size().unstack('Sentiment')\n\ndf_by_day_sentiment","f6ccfce0":"#Plotting day by day negative and positive sentiments\ndf_by_day_sentiment.plot(marker='o',color=['red','green'], legend=True, \n                      label = ['Negative','Positive'],figsize=(15, 6))\nplt.savefig('daybyday.png')","47492f3b":"#Creating DF to plot sentiment values against weeks\n\ndf_by_week_sentiment = tweets_merged_df.groupby([pd.Grouper(key='Date', freq='W'), 'Sentiment']) \\\n    .size().unstack('Sentiment')\n\n\ndf_by_week_sentiment.head()","71415c7c":"df_by_week_sentiment.plot(marker='o',color=['red','green'], legend=True, \n                      label = ['Negative','Positive'],figsize=(15, 6))\n\nplt.savefig('weekbyweek.png')","84c60f65":"new_df_pos=tweets_merged_df[tweets_merged_df['Sentiment']=='POSITIVE']\nwords = ' '.join(new_df_pos['tweet'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.savefig('wordcloud_pos.png')\nplt.show()","9be2259f":"new_df_neg=tweets_merged_df[tweets_merged_df['Sentiment']=='NEGATIVE']\nwords = ' '.join(new_df_neg['tweet'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.savefig('wordcloud_neg.png')\nplt.show()","c6bb2372":"**Importing required packages**","d2c97805":"### Data Visualization","6d35b8c8":"**We are running this for the brand #Pepsi and extracting 500 tweets per day to be cleaned and analyzed for thier general sentiment.**","0fcf83d2":"# Twitter Sentiment Analysis Tool","5ee69a9f":"**Installing required packages**","cafd2319":"**Enter the Keyword\/Hashtag to be scraped and number of tweets per day to be analyzed for sentiment**","0632b582":"#### Post scrape data cleaning","a0d56424":"#### WORDCLOUD for POSITIVE tweets\n\nThe larger the size of the word, the more frequently it has been used in the positive tweets.","33965264":"#### WORDCLOUD for NEGATIVE tweets\n\nThe larger the size of the word, the more frequently it has been used in the NEGATIVE tweets.","0ed39630":"**Exporting raw data to CSV file (saved in script libraray)**\n\nThis is for the user to get all the tweet data in a single CSV file so it can be used for other analysis if need be.","122a519d":"##### Week by Week visalization of sentiments against selected keyword\n\nEven though this visualization seems irrelevant for a single run of this tool, if the script is set to auto run every week, a brand can follow the sentiment and change therein against thier twitter #campaign or #product by week.","fffdf7ee":"#### Defining function which runs above defined 'scrape_to_list' function sepearately for last 7 days (max supported by tweepy):\n\n*The tweets a scraped for each of the 7 past days seperately so that the sample is representative of each day. If lets suppose 1000 tweets were scraped for the past 7 days, the function would extract the latest 1000 tweets which will most likely fall in the latest day only. This will obviously help if the script is auto run every week to scrape new tweets. This does increase the run time significantly but it helps extract an accurately representative sample of tweets.*  ","907119fc":"I've developed this Twitter Sentiment Anlysis tool as my term project for my Masters in Data Science program's foundation course: Introduction to Application Development.\n\n_**Having no coding background, this was developed with only 2 months of coding experience in any language and was my first coding project.**_","b947c9f5":"**Scraping and Cleansing the tweets**\n\nDefining a single master function which extracts tweeets and their dates, cleans tweets, calculates polarity for the tweets via textblob and extends them into respective lists.\n\nNote that the list is 'extended', not 'appended'. This is done to ensure that if the user decides to auto run this script  every 7 days for thier respective keyword\/campaign, the list doesn't get overwritten, rather it gets extended to collect long term tweet sentiment data.","556a4d69":"* Author: Yawar Khalid\n* Course: Intorduction to Application Development\n* Project: Term Project\n* Applications: \n    * To assess the effectiveness of a certain #Campaign executed by a brand on Twitter.\n    * Assesing the opinion of people regarding specific political personality or thier campaign.\n    * Track opinion on twitter regarding a certain event or a developing story.","c39e9ac0":"#### Initializing empty lists for tweets and dates to be scraped in\n\nThis step should be left out after the first run if the user plans to auto run scraping on same #keyword every 7 days.","58b6a1d2":"**Authorizing the twitter API with unique access keys**\n\nGet access by applying for a twitter developer account at following link.\n(https:\/\/developer.twitter.com\/en\/apply-for-access)"}}