{"cell_type":{"aa11411e":"code","e5ac53aa":"code","4d482c49":"code","d307c794":"code","03ce762a":"code","cfe7e37c":"code","e64fdc73":"code","80837e4b":"code","c293bd9e":"markdown","11938d06":"markdown","3c318f7e":"markdown","96978bc5":"markdown","e51e9c12":"markdown","912ae8b5":"markdown","fd0b72e2":"markdown","1149c79a":"markdown"},"source":{"aa11411e":"import pandas as pd\nimport numpy as np\nimport datetime\nimport random\nimport glob\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Activation,Dropout,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n# \u4e71\u6570\u30b7\u30fc\u30c9\u56fa\u5b9a\nseed = 2020\nseed_everything(seed)","e5ac53aa":"train = pd.read_csv('..\/input\/5th-datarobot-ai-academy-deep-learning\/train.csv')\ndisplay(train.shape)\ndisplay(train.head())","4d482c49":"def load_images(df,inputPath,size,roomType):\n    images = []\n    for i in df['id']:\n        basePath = os.path.sep.join([inputPath, \"{}_{}*\".format(i,roomType)])\n        housePaths = sorted(list(glob.glob(basePath)))\n        for housePath in housePaths:\n            image = cv2.imread(housePath)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (size, size))\n        images.append(image)\n    return np.array(images) \/ 255.0\n\n# load train images\ninputPath = '..\/input\/5th-datarobot-ai-academy-deep-learning\/images\/train_images\/'\nsize = 64\nroomType = 'frontal'\ntrain_images = load_images(train,inputPath,size,roomType)\ndisplay(train_images.shape)\ndisplay(train_images[0][0][0])","d307c794":"train_x, valid_x, train_images_x, valid_images_x = train_test_split(train, train_images, test_size=0.2, random_state=seed)\ntrain_y = train_x['price'].values.reshape(-1,1)\nvalid_y = valid_x['price'].values.reshape(-1,1)\ndisplay(train_images_x.shape)\ndisplay(valid_images_x.shape)\ndisplay(train_y.shape)\ndisplay(valid_y.shape)","03ce762a":"def create_cnn(inputShape):\n    model = Sequential()\n\n    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=(1, 1), padding='valid',\n                     activation='relu', kernel_initializer='he_normal', input_shape=inputShape))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Conv2D(filters=64, kernel_size=(2, 2), strides=(1, 1), padding='valid', \n                     activation='relu', kernel_initializer='he_normal'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Conv2D(filters=128, kernel_size=(2, 2), strides=(1, 1), padding='valid', \n                     activation='relu', kernel_initializer='he_normal'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(units=512, activation='relu',kernel_initializer='he_normal'))      \n    model.add(Dense(units=256, activation='relu',kernel_initializer='he_normal'))  \n    model.add(Dense(units=32, activation='relu',kernel_initializer='he_normal'))    \n    model.add(Dense(units=1, activation='linear'))\n    \n    model.compile(loss='mape', optimizer='adam', metrics=['mape']) \n    return model","cfe7e37c":"# callback parameter\nfilepath = \"cnn_best_model.hdf5\" \nes = EarlyStopping(patience=5, mode='min', verbose=1) \ncheckpoint = ModelCheckpoint(monitor='val_loss', filepath=filepath, save_best_only=True, mode='auto') \nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',  patience=5, verbose=1,  mode='min')\n\n# \u8a13\u7df4\u5b9f\u884c\ninputShape = (size, size, 3)\nmodel = create_cnn(inputShape)\nhistory = model.fit(train_images_x, train_y, validation_data=(valid_images_x, valid_y),epochs=30, batch_size=16,\n    callbacks=[es, checkpoint, reduce_lr_loss])\n","e64fdc73":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\n# load best model weights\nmodel.load_weights(filepath)\n\n# \u8a55\u4fa1\nvalid_pred = model.predict(valid_images_x, batch_size=32).reshape((-1,1))\nmape_score = mean_absolute_percentage_error(valid_y, valid_pred)\nprint (mape_score)","80837e4b":"# load test csv\ninputPath = '..\/input\/5th-datarobot-ai-academy-deep-learning\/'\ntest = pd.read_csv(inputPath+'test.csv')\n\n# load test images\ninputPath = '..\/input\/5th-datarobot-ai-academy-deep-learning\/images\/test_images\/'\nsize = 64\nroomType = 'frontal'\ntest_images = load_images(test,inputPath,size,roomType)\ndisplay(test_images.shape)\ndisplay(test_images[0][0][0])\n\n# prediction\ntest_pred = model.predict(test_images, batch_size=32).reshape((-1,1))\ntest['price'] = test_pred\ntest[['id','price']].to_csv('submission.csv',index=False)\ndisplay(test.head())","c293bd9e":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4e88\u6e2c","11938d06":"# CNN\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3059\u308b","3c318f7e":"# \u8a13\u7df4\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u4f5c\u6210","96978bc5":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","e51e9c12":"# \u753b\u50cf\u3092\u8aad\u307f\u8fbc\u307f","912ae8b5":"# \u30e2\u30c7\u30eb\u8a13\u7df4","fd0b72e2":"# \u6570\u5024\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f","1149c79a":"# \u30e2\u30c7\u30eb\u8a55\u4fa1"}}