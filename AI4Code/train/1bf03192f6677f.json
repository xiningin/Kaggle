{"cell_type":{"c5cd2a7a":"code","86b07f90":"code","8070ec33":"code","d0d14fb8":"code","2d2f5292":"code","b2ae71d2":"code","3af1b06b":"code","eca5fce8":"markdown","444aa914":"markdown","1f3330e3":"markdown","d997c196":"markdown","e955d09e":"markdown"},"source":{"c5cd2a7a":"import numpy as np\nimport pandas as pd\nimport itertools\nimport glob\nimport os\nimport cv2\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.auto import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nimport random","86b07f90":"debug = False\nCONF_THRE = 0.3\nBASE_DIR = '..\/input\/nfl-health-and-safety-helmet-assignment'\n\nlabels = pd.read_csv(f'{BASE_DIR}\/train_labels.csv')\nif debug:\n    tracking = pd.read_csv(f'{BASE_DIR}\/train_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}\/train_baseline_helmets.csv')\nelse:\n    tracking = pd.read_csv(f'{BASE_DIR}\/test_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}\/test_baseline_helmets.csv')","8070ec33":"# copied from https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\ndef add_track_features(tracks, fps=59.94, snap_frame=10):\n    \"\"\"\n    Add column features helpful for syncing with video data.\n    \"\"\"\n    tracks = tracks.copy()\n    tracks[\"game_play\"] = (\n        tracks[\"gameKey\"].astype(\"str\")\n        + \"_\"\n        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n    )\n    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n    snap_dict = (\n        tracks.query('event == \"ball_snap\"')\n        .groupby(\"game_play\")[\"time\"]\n        .first()\n        .to_dict()\n    )\n    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n        \"timedelta64[ms]\"\n    ) \/ 1_000\n    # Estimated video frame\n    tracks[\"est_frame\"] = (\n        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n    )\n    return tracks\ntracking = add_track_features(tracking)","d0d14fb8":"if debug:\n    sample_keys = random.sample(list(tracking['gameKey'].unique()), 3)\n    helmets['gameKey'] = helmets['video_frame'].str.split('_').str[0]\n    tracking = tracking[tracking['gameKey'].isin(sample_keys)]\n    helmets = helmets[helmets['gameKey'].astype(int).isin(sample_keys)]\n    labels = labels[labels['gameKey'].astype(int).isin(sample_keys)]\ntracking.shape, helmets.shape, labels.shape","2d2f5292":"def find_nearest(array, value):\n    value = int(value)\n    array = np.asarray(array).astype(int)\n    idx = (np.abs(array - value)).argmin()\n    return array[idx]\n\ndef norm_arr(a):\n    a = a-a.min()\n    a = a\/a.max()\n    return a\n    \ndef dist(a1, a2):\n    return np.linalg.norm(a1-a2)\n\nmax_iter = 2000\ndef dist_for_different_len(a1, a2):\n    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}'\n    len_diff = len(a1) - len(a2)\n    a2 = norm_arr(a2)\n    if len_diff == 0:\n        a1 = norm_arr(a1)\n        return dist(a1,a2), ()\n    else:\n        min_dist = 10000\n        min_detete_idx = None\n        cnt = 0\n        del_list = list(itertools.combinations(range(len(a1)),len_diff))\n        if len(del_list) > max_iter:\n            del_list = random.sample(del_list, max_iter)\n        for detete_idx in del_list:\n            this_a1 = np.delete(a1, detete_idx)\n            this_a1 = norm_arr(this_a1)\n            this_dist = dist(this_a1, a2)\n            #print(len(a1), len(a2), this_dist)\n            if min_dist > this_dist:\n                min_dist = this_dist\n                min_detete_idx = detete_idx\n                \n        return min_dist, min_detete_idx\n        \ndef rotate_arr(u, t, deg=True):\n    if deg == True:\n        t = np.deg2rad(t)\n    R = np.array([[np.cos(t), -np.sin(t)],\n                  [np.sin(t),  np.cos(t)]])\n    return  np.dot(R, u)\n\ndef dist_rot(tracking_df, a2):\n    tracking_df = tracking_df.sort_values('x')\n    x = tracking_df['x']\n    y = tracking_df['y']\n    min_dist = 10000\n    min_idx = None\n    min_x = None\n    dig_step = 3\n    dig_max = dig_step*10\n    for dig in range(-dig_max,dig_max+1,dig_step):\n        arr = rotate_arr(np.array((x,y)), dig)\n        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2)\n        if min_dist > this_dist:\n            min_dist = this_dist\n            min_idx = this_idx\n            min_x = arr[0]\n    tracking_df['x_rot'] = min_x\n    player_arr = tracking_df.sort_values('x_rot')['player'].values\n    players = np.delete(player_arr,min_idx)\n    return min_dist, players\n\n\ndef mapping_df(args):\n    video_frame, df = args\n    gameKey,playID,view,frame = video_frame.split('_')\n    gameKey = int(gameKey)\n    playID = int(playID)\n    frame = int(frame)\n    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n    est_frame = find_nearest(this_tracking.est_frame.values, frame)\n    this_tracking = this_tracking[this_tracking['est_frame']==est_frame]\n    len_this_tracking = len(this_tracking)\n    df['center_h_p'] = (df['left']+df['width']\/2).astype(int)\n    df['center_h_m'] = (df['left']+df['width']\/2).astype(int)*-1\n    df = df[df['conf']>CONF_THRE].copy()\n    if len(df) > len_this_tracking:\n        df = df.tail(len_this_tracking)\n    df_p = df.sort_values('center_h_p').copy()\n    df_m = df.sort_values('center_h_m').copy()\n    \n    if view == 'Endzone':\n        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n    a2_p = df_p['center_h_p'].values\n    a2_m = df_m['center_h_m'].values\n\n    min_dist_p, min_detete_idx_p = dist_rot(this_tracking ,a2_p)\n    min_dist_m, min_detete_idx_m = dist_rot(this_tracking ,a2_m)\n    if min_dist_p < min_dist_m:\n        min_dist = min_dist_p\n        min_detete_idx = min_detete_idx_p\n        tgt_df = df_p\n    else:\n        min_dist = min_dist_m\n        min_detete_idx = min_detete_idx_m\n        tgt_df = df_m\n    #print(video_frame, len(this_tracking), len(df), len(df[df['conf']>CONF_THRE]), this_tracking['x'].mean(), min_dist_p, min_dist_m, min_dist)\n    tgt_df['label'] = min_detete_idx\n    return tgt_df[['video_frame','left','width','top','height','label']]\n\np = Pool(processes=4)\nsubmission_df_list = []\ndf_list = list(helmets.groupby('video_frame'))\nwith tqdm(total=len(df_list)) as pbar:\n    for this_df in p.imap(mapping_df, df_list):\n        submission_df_list.append(this_df)\n        pbar.update(1)\np.close()","b2ae71d2":"submission_df = pd.concat(submission_df_list)\nsubmission_df.to_csv('submission.csv', index=False)","3af1b06b":"# copied from https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\nclass NFLAssignmentScorer:\n    def __init__(\n        self,\n        labels_df: pd.DataFrame = None,\n        labels_csv=\"train_labels.csv\",\n        check_constraints=True,\n        weight_col=\"isDefinitiveImpact\",\n        impact_weight=1000,\n        iou_threshold=0.35,\n        remove_sideline=True,\n    ):\n        \"\"\"\n        Helper class for grading submissions in the\n        2021 Kaggle Competition for helmet assignment.\n        Version 1.0\n        https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\n\n        Use:\n        ```\n        scorer = NFLAssignmentScorer(labels)\n        scorer.score(submission_df)\n\n        or\n\n        scorer = NFLAssignmentScorer(labels_csv='labels.csv')\n        scorer.score(submission_df)\n        ```\n\n        Args:\n            labels_df (pd.DataFrame, optional):\n                Dataframe containing theground truth label boxes.\n            labels_csv (str, optional): CSV of the ground truth label.\n            check_constraints (bool, optional): Tell the scorer if it\n                should check the submission file to meet the competition\n                constraints. Defaults to True.\n            weight_col (str, optional):\n                Column in the labels DataFrame used to applying the scoring\n                weight.\n            impact_weight (int, optional):\n                The weight applied to impacts in the scoring metrics.\n                Defaults to 1000.\n            iou_threshold (float, optional):\n                The minimum IoU allowed to correctly pair a ground truth box\n                with a label. Defaults to 0.35.\n            remove_sideline (bool, optional):\n                Remove slideline players from the labels DataFrame\n                before scoring.\n        \"\"\"\n        if labels_df is None:\n            # Read label from CSV\n            if labels_csv is None:\n                raise Exception(\"labels_df or labels_csv must be provided\")\n            else:\n                self.labels_df = pd.read_csv(labels_csv)\n        else:\n            self.labels_df = labels_df.copy()\n        if remove_sideline:\n            self.labels_df = (\n                self.labels_df.query(\"isSidelinePlayer == False\")\n                .reset_index(drop=True)\n                .copy()\n            )\n        self.impact_weight = impact_weight\n        self.check_constraints = check_constraints\n        self.weight_col = weight_col\n        self.iou_threshold = iou_threshold\n\n    def check_submission(self, sub):\n        \"\"\"\n        Checks that the submission meets all the requirements.\n\n        1. No more than 22 Boxes per frame.\n        2. Only one label prediction per video\/frame\n        3. No duplicate boxes per frame.\n\n        Args:\n            sub : submission dataframe.\n\n        Returns:\n            True -> Passed the tests\n            False -> Failed the test\n        \"\"\"\n        # Maximum of 22 boxes per frame.\n        max_box_per_frame = sub.groupby([\"video_frame\"])[\"label\"].count().max()\n        if max_box_per_frame > 22:\n            print(\"Has more than 22 boxes in a single frame\")\n            return False\n        # Only one label allowed per frame.\n        has_duplicate_labels = sub[[\"video_frame\", \"label\"]].duplicated().any()\n        if has_duplicate_labels:\n            print(\"Has duplicate labels\")\n            return False\n        # Check for unique boxes\n        has_duplicate_boxes = (\n            sub[[\"video_frame\", \"left\", \"width\", \"top\", \"height\"]].duplicated().any()\n        )\n        if has_duplicate_boxes:\n            print(\"Has duplicate boxes\")\n            return False\n        return True\n\n    def add_xy(self, df):\n        \"\"\"\n        Adds `x1`, `x2`, `y1`, and `y2` columns necessary for computing IoU.\n\n        Note - for pixel math, 0,0 is the top-left corner so box orientation\n        defined as right and down (height)\n        \"\"\"\n\n        df[\"x1\"] = df[\"left\"]\n        df[\"x2\"] = df[\"left\"] + df[\"width\"]\n        df[\"y1\"] = df[\"top\"]\n        df[\"y2\"] = df[\"top\"] + df[\"height\"]\n        return df\n\n    def merge_sub_labels(self, sub, labels, weight_col=\"isDefinitiveImpact\"):\n        \"\"\"\n        Perform an outer join between submission and label.\n        Creates a `sub_label` dataframe which stores the matched label for each submission box.\n        Ground truth values are given the `_gt` suffix, submission values are given `_sub` suffix.\n        \"\"\"\n        sub = sub.copy()\n        labels = labels.copy()\n\n        sub = self.add_xy(sub)\n        labels = self.add_xy(labels)\n\n        base_columns = [\n            \"label\",\n            \"video_frame\",\n            \"x1\",\n            \"x2\",\n            \"y1\",\n            \"y2\",\n            \"left\",\n            \"width\",\n            \"top\",\n            \"height\",\n        ]\n\n        sub_labels = sub[base_columns].merge(\n            labels[base_columns + [weight_col]],\n            on=[\"video_frame\"],\n            how=\"right\",\n            suffixes=(\"_sub\", \"_gt\"),\n        )\n        return sub_labels\n\n    def get_iou_df(self, df):\n        \"\"\"\n        This function computes the IOU of submission (sub)\n        bounding boxes against the ground truth boxes (gt).\n        \"\"\"\n        df = df.copy()\n\n        # 1. get the coordinate of inters\n        df[\"ixmin\"] = df[[\"x1_sub\", \"x1_gt\"]].max(axis=1)\n        df[\"ixmax\"] = df[[\"x2_sub\", \"x2_gt\"]].min(axis=1)\n        df[\"iymin\"] = df[[\"y1_sub\", \"y1_gt\"]].max(axis=1)\n        df[\"iymax\"] = df[[\"y2_sub\", \"y2_gt\"]].min(axis=1)\n\n        df[\"iw\"] = np.maximum(df[\"ixmax\"] - df[\"ixmin\"] + 1, 0.0)\n        df[\"ih\"] = np.maximum(df[\"iymax\"] - df[\"iymin\"] + 1, 0.0)\n\n        # 2. calculate the area of inters\n        df[\"inters\"] = df[\"iw\"] * df[\"ih\"]\n\n        # 3. calculate the area of union\n        df[\"uni\"] = (\n            (df[\"x2_sub\"] - df[\"x1_sub\"] + 1) * (df[\"y2_sub\"] - df[\"y1_sub\"] + 1)\n            + (df[\"x2_gt\"] - df[\"x1_gt\"] + 1) * (df[\"y2_gt\"] - df[\"y1_gt\"] + 1)\n            - df[\"inters\"]\n        )\n        # print(uni)\n        # 4. calculate the overlaps between pred_box and gt_box\n        df[\"iou\"] = df[\"inters\"] \/ df[\"uni\"]\n\n        return df.drop(\n            [\"ixmin\", \"ixmax\", \"iymin\", \"iymax\", \"iw\", \"ih\", \"inters\", \"uni\"], axis=1\n        )\n\n    def filter_to_top_label_match(self, sub_labels):\n        \"\"\"\n        Ensures ground truth boxes are only linked to the box\n        in the submission file with the highest IoU.\n        \"\"\"\n        return (\n            sub_labels.sort_values(\"iou\", ascending=False)\n            .groupby([\"video_frame\", \"label_gt\"])\n            .first()\n            .reset_index()\n        )\n\n    def add_isCorrect_col(self, sub_labels):\n        \"\"\"\n        Adds True\/False column if the ground truth label\n        and submission label are identical\n        \"\"\"\n        sub_labels[\"isCorrect\"] = (\n            sub_labels[\"label_gt\"] == sub_labels[\"label_sub\"]\n        ) & (sub_labels[\"iou\"] >= self.iou_threshold)\n        return sub_labels\n\n    def calculate_metric_weighted(\n        self, sub_labels, weight_col=\"isDefinitiveImpact\", weight=1000\n    ):\n        \"\"\"\n        Calculates weighted accuracy score metric.\n        \"\"\"\n        sub_labels[\"weight\"] = sub_labels.apply(\n            lambda x: weight if x[weight_col] else 1, axis=1\n        )\n        y_pred = sub_labels[\"isCorrect\"].values\n        y_true = np.ones_like(y_pred)\n        weight = sub_labels[\"weight\"]\n        return accuracy_score(y_true, y_pred, sample_weight=weight)\n\n    def score(self, sub, labels_df=None, drop_extra_cols=True):\n        \"\"\"\n        Scores the submission file against the labels.\n\n        Returns the evaluation metric score for the helmet\n        assignment kaggle competition.\n\n        If `check_constraints` is set to True, will return -999 if the\n            submission fails one of the submission constraints.\n        \"\"\"\n        if labels_df is None:\n            labels_df = self.labels_df.copy()\n\n        if self.check_constraints:\n            if not self.check_submission(sub):\n                return -999\n        sub_labels = self.merge_sub_labels(sub, labels_df, self.weight_col)\n        sub_labels = self.get_iou_df(sub_labels).copy()\n        sub_labels = self.filter_to_top_label_match(sub_labels).copy()\n        sub_labels = self.add_isCorrect_col(sub_labels)\n        score = self.calculate_metric_weighted(\n            sub_labels, self.weight_col, self.impact_weight\n        )\n        # Keep `sub_labels for review`\n        if drop_extra_cols:\n            drop_cols = [\n                \"x1_sub\",\n                \"x2_sub\",\n                \"y1_sub\",\n                \"y2_sub\",\n                \"x1_gt\",\n                \"x2_gt\",\n                \"y1_gt\",\n                \"y2_gt\",\n            ]\n            sub_labels = sub_labels.drop(drop_cols, axis=1)\n        self.sub_labels = sub_labels\n        return score\n\nif debug:\n    scorer = NFLAssignmentScorer(labels)\n    baseline_score = scorer.score(submission_df)\n    print(f\"validation score {baseline_score:0.4f}\") # this would be 0.33","eca5fce8":"## adding Estimated video frame to tracking\n\nI used @robikscube's great code here.","444aa914":"## setting and loading data","1f3330e3":"## mapping helmet box and NGS tracking data","d997c196":"## validation\nI used @robikscube's great code here.","e955d09e":"In this notebook I will show you how to map helmet bbox and NGS tracking data.\n\n- I used [train|test]_baseline_helmets.csv for helmet bbox.\n- Compare the NGS tracking data with the lateral coordinates of the boxes.\n- Map the players to have the smallest difference between each boxes and coordinates.\n- The reason why I did not use vertical coordinates is because simplicity and the lateral direction is more accurate, but we can get more accurate mapping if we use depth as well.\n- The direction of the axis changes depending on the camera position, so I choose the one that gives smaller distance for both directions.\n- Since the camera and the XY axis will be rotated if it is out of the center of the court. So the angle at which the distance is the smallest is selected by grid-search.\n\nPlease check the code for details."}}