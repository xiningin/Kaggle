{"cell_type":{"837f55c7":"code","5388d97a":"code","48b5909c":"code","8f5e5850":"code","034fafe7":"code","8c01c194":"code","f6c5dd5d":"code","c893a550":"code","021c17aa":"code","06be9da9":"code","e77efc8a":"code","878d23d6":"code","55f8e49f":"code","3ab8cc44":"code","b92c3b06":"code","24f93525":"code","a90208cc":"code","57ebee79":"code","69fb5412":"code","9ea9e59f":"code","92eb5c9e":"code","4907435a":"markdown","cc7dda14":"markdown"},"source":{"837f55c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5388d97a":"df = pd.read_csv('..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')","48b5909c":"df.head()","8f5e5850":"df1 = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)","034fafe7":"df1.head()","8c01c194":"df1.dtypes","f6c5dd5d":"df1.isnull().sum()","c893a550":"df2 = pd.get_dummies(data=df1, columns=['Geography', 'Gender'])","021c17aa":"df2","06be9da9":"df2_col = ['CreditScore', 'Balance', 'EstimatedSalary']","e77efc8a":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf2[df2_col] = scaler.fit_transform(df2[df2_col])","878d23d6":"df2","55f8e49f":"for col in df2:\n    print(f'{col}: {df2[col].unique()}')","3ab8cc44":"X = df2.drop('Exited',axis='columns')\ny = df2['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)","b92c3b06":"import tensorflow as tf\nfrom tensorflow import keras\n\n\nmodel = keras.Sequential([\n    keras.layers.Dense(32, input_shape=(13,), activation='relu'),\n    keras.layers.Dense(13, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\n# opt = keras.optimizers.Adam(learning_rate=0.01)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=100)","24f93525":"model.evaluate(X_test, y_test)","a90208cc":"yp = model.predict(X_test)\nyp[:5]","57ebee79":"y_pred = []\nfor element in yp:\n    if element > 0.5:\n        y_pred.append(1)\n    else:\n        y_pred.append(0)","69fb5412":"y_pred[:10]","9ea9e59f":"y_test[:10]","92eb5c9e":"from sklearn.metrics import confusion_matrix , classification_report\nprint(classification_report(y_test,y_pred))","4907435a":"#### One hot encoding for categorical columns","cc7dda14":"#### First of all, drop customerID column as it is of no use"}}