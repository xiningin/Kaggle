{"cell_type":{"7aea911a":"code","36931dad":"code","cb05de32":"code","60cc12ae":"code","929a5ae9":"code","ac458bf3":"code","d10bdce3":"code","521023c6":"code","7f6c9880":"code","639fd9e2":"code","ca02ff61":"code","4acf2ad1":"code","6a83014f":"markdown","8585d2cf":"markdown","6c22a7d8":"markdown","64ce2488":"markdown","9fa5ed79":"markdown","d1bd0277":"markdown","015ff2d0":"markdown","b160fd88":"markdown","5d2867bf":"markdown","519ff3b7":"markdown","11ea1157":"markdown","9ba62d6f":"markdown","79aebd26":"markdown","0b1ec2bb":"markdown"},"source":{"7aea911a":"import pandas as pd \nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import make_scorer,mean_squared_error,mean_absolute_error,r2_score,explained_variance_score\n","36931dad":"train = pd.read_csv('\/kaggle\/input\/sec3-eda-fe-categorical\/eng_filt_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/sec3-eda-fe-categorical\/eng_filt_test.csv')\ntrain['MSSubClass'] = train['MSSubClass'].astype('category')\ntest['MSSubClass'] = test['MSSubClass'].astype('category')\ntraintest = pd.concat([train,test],axis=0,ignore_index = True)","cb05de32":"train.shape,test.shape,traintest.shape","60cc12ae":"train.columns","929a5ae9":"def prepare_data_for_linear_model(whole,tr,te):\n    \"\"\" \n    Preparing data for non-tree based modelling approach and returns train, test\n    \"\"\"\n    \n    # Removing unnecessary columns\n    whole = whole.drop(['LogPrice','SalePrice','Id'],axis = 1)\n    tr = tr.drop(['LogPrice','SalePrice','Id'],axis = 1)\n    te = te.drop(['Id'],axis = 1)\n    \n    # Select cats column and one hot encode remaining columns keep as it is\n    cats = train.select_dtypes(include=['object','category']).columns\n    \n    whole = pd.get_dummies(whole,columns = cats)\n    tr = whole[:1425]\n    te = whole[1425:]\n    \n    return tr,te\n    \n    \ntrs,tes = prepare_data_for_linear_model(traintest,train,test)\nfeatures = trs.columns\n\nscaler = StandardScaler(with_mean=False)\n\n\ntr = scaler.fit_transform(trs)\nte = scaler.transform(tes)","ac458bf3":"def rmse(y_test,pred):\n    y = np.exp(y_test)-1\n    y_ = np.exp(pred)-1\n    mse = mean_squared_error(y,y_)\n    return np.sqrt(mse)\n\ndef mae(y_test,pred):\n    y = np.exp(y_test)-1\n    y_ = np.exp(pred)-1\n    mae = mean_absolute_error(y,y_)\n    return mae\n\ndef r2score(y_test,pred):\n    y = np.exp(y_test)-1\n    y_ = np.exp(pred)-1\n    r2 = r2_score(y,y_)\n    return r2\n\ndef exp_var(y_test,pred):\n    y = np.exp(y_test)-1\n    y_ = np.exp(pred)-1\n    evs = explained_variance_score(y,y_)\n    return evs\n\n    \nscorer = {'mae':make_scorer(mae,greater_is_better=False),'rmse': make_scorer(rmse,greater_is_better=False), \n          'r2score':make_scorer(r2score),'expvar':make_scorer(exp_var)}\n\ndef parameter_select(model,hyperparameters,tr,features):\n    \"\"\"\n    Grid search for best parameter based on lowest RMSE score for given model. Display 2 plots 1.RMSE plot with lower and upper bound\n    2. R2 score and explained variance score plot\n    \"\"\"\n    grid = GridSearchCV(model,hyperparameters,scoring = scorer,cv=3,n_jobs = -1,refit='rmse')\n    grid.fit(tr,train['LogPrice'])\n    print('Best RMSE Score:', -grid.best_score_)\n    print('Best Params',grid.best_params_)\n    print()\n    result = grid.cv_results_\n    \n    fig = plt.figure(figsize=(20,13))\n\n    X_axis = np.array(result['param_alpha'].data, dtype=float)\n    plt.subplot(2,2,1)\n    plt.semilogx(X_axis,-result['mean_test_rmse'], linestyle='--', marker='x',label='RMSE')\n    plt.fill_between(X_axis, -result['mean_test_mae'],np.sqrt(len(tr)\/3)*(-result['mean_test_mae']),alpha=0.1)\n    plt.semilogx(grid.best_params_['alpha'],-grid.best_score_, 'Xr')\n    plt.xlabel('alpha')\n    plt.ylabel('score')\n\n    plt.subplot(2,2,2)\n    plt.semilogx(X_axis, result['mean_test_r2score'],  linestyle='--', marker='x',label='r2score')\n    plt.semilogx(X_axis, result['mean_test_expvar'],  linestyle='--', marker='x',label='expvar')\n    plt.legend(loc = 'best')\n    plt.xlabel('alpha')\n    plt.ylabel('score')\n    \n    plt.subplot(2,1,2)\n    plt.bar(x= features,height=grid.best_estimator_.coef_)\n    plt.xticks(rotation=90)\n    \n    return grid.best_params_","d10bdce3":"##------Linear Regression------##\n# lr = LinearRegression(fit_intercept=False,copy_X=True,n_jobs=-1)\n# rmse,r2 = test_model(lr,tr)\n# print(\"Linear Regression:\\nRMSE:{:.3f}\\nScore:{:.3f}\".format(rmse,r2))\n\n\n##-----Lasso Regression-------##\nlasso = Lasso()\nhyperparameters = {'alpha':[0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000],\n                   'random_state' : [1],\n                   'fit_intercept':[True],\n                   'max_iter':[2000]}\nprint( 'Lasso Regression Analysis')\nbest_params = parameter_select(lasso,hyperparameters,tr,features)","521023c6":"##-----Ridge Regression-------##\nridge = Ridge()\nhyperparameters = {'alpha':[0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000],\n                   'random_state' : [1],\n                   'fit_intercept':[True],\n                   'max_iter':[2000]}\nprint('Ridge Regression Analysis')\nbest_params = parameter_select(ridge,hyperparameters,tr,features)\n","7f6c9880":"\n##---ElasticNet Regression----##\neln = ElasticNet()\nhyperparameters = {'alpha': [0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000],\n                   'l1_ratio':[0.1,0.3,0.5,0.7,0.9,1],\n                   'fit_intercept':[True],\n                   'max_iter':[2000]}\n\nprint('Elastic Net regression analysis')\nbest_params = parameter_select(eln,hyperparameters,tr,features)\n","639fd9e2":"selector = RFECV(Ridge(),step = 1, cv=5,scoring = 'neg_mean_squared_error',n_jobs = -1).fit(tr,train['LogPrice'])\nselected_features = trs.columns[selector.support_]\n\nselected_features","ca02ff61":"ridge = ElasticNet()\nhyperparameters = {'alpha':[0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000],\n                   'l1_ratio':[0.1,0.3,0.5,0.7,0.9,1],\n                   'random_state' : [1],\n                   'fit_intercept':[True],\n                   'max_iter':[2000],\n                   'tol': [1e-4]}\nsc = StandardScaler()\nfinaltrain =sc.fit_transform(trs[selected_features])\nbest_params = parameter_select(ridge,hyperparameters,finaltrain,selected_features)\n","4acf2ad1":"\nmodel = ElasticNet(**best_params).fit(finaltrain,train['LogPrice'])\n\nfinal_test = sc.transform(tes[selected_features])\npred = model.predict(final_test)\npred = np.exp(pred)-1\nsubmission = pd.DataFrame({'Id':test['Id'].astype(int),'SalePrice':pred})\nsubmission.to_csv('submission.csv',index=False)","6a83014f":"## Linear Models:\n\nVarious types of linear regression models has been studied for this prediction problem. They are as follows:\n1. Simple linear regression\n2. Lasso regression \n3. Ridge regression\n4. Elastic Net regression\n\n#### **Simple Linear Regression:**\n\nThis modelling technique attempts to minimize the sum of squared error. The error in this case is the difference between the actual data point and its predicted value. Linear regression model tend to overfit in case of large number of features. To avoid this regularization technique needs to be applied. For given problem some predictions are really going crazy(i.e.Inf) so we skip the analysis for this model.\n\n#### **Lasso Regression:**\n\nThis is L1 regularization method.It adds penalty equivalent to absolute value of the magnitude of coefficients.\n\nMin. objective = Least Square Obj + \u03b1 * (sum of absolute value of coefficients)\n\nIf \u03b1 = 0, it works as a simple linear regression model. Suitable value of \u03b1 can drive coefficients to zero. Larger the value more the features will shrunk to zero and hence eliminate some features completely and give a subset of features. It helps mitigate collinearity and overfitting due to model complexity.","8585d2cf":"## Load Data","6c22a7d8":"## Feature Selection\nRFECV i.e. Recursive feture elimination with cross validation has been applied in this feature selection stage. This method recursively eliminates the (less important) feature based on their ranking and train a model with remaining feature\/features.It uses the model score(defined by scoring parameter) to identify which features or combination of features contribute the most to predicting the target.","64ce2488":"Metric plots are not smooth unlike previous two cases. Some abrupt behavior has been observed its because we are varying two parameters at a time i.e alpha and l1-ratio. But for best paramter value, same behaviour as previous has been observed for all metrics.\n\nElastic Net seems to be out performed among all other linear models w.r.t RMSE score.Therefore Elastic Net model has been chosen as our final model. At further stage, model complexity will be reduced furher by applying recursive feature elimination technique.","9fa5ed79":"## Introduction\n\nIn data modelling section, various linear and tree based method has been studied. Given dataset contains numerical as well as categorical features. For modelling purpose categorical data need to be convert to numeric one and it is termed as encoding. Label encoder, ordinal encoder, one hot encoder, binary encoder are various types of encoding. In this context, one hot encoding is used in case of linear modelling and label encoder is used in case of tree based modelling.\n\n### **Why One Hot Encoding(OHE) in linear model?**\nSimple label encoder encodes categorical level with random number. If linear model is chosen, then during training phase these number could be misinterpreted and model wrongly assumes that there is certain order.OHE is used to avoid such wrong interpretation. In OHE,seperate feature has been created for each categorical level and it is coded as 0 or 1 based on the presence of that level for given sample.\n\nTherefore, seperate dataset has been prepared for linear model and tree based model.\n\n\n## Dataflow\n\n\nThis notebook focused on linear modelling only. Engineered and filtered dataset(train and test) from previous section has been used for modelling purpose.Training set contains total 84 columns including target along with its logform and Testing set contains 82 columns. Feature set includes both categorical and numerical type data. Data follows following path to predict final SalePrice on test data\n\n1. Prepare a data: Numerical features kept as it is and categorical features are encoded using OHE\n2. Pick model: one model picked from linear regresssion, ridge, lasso, elastic net at a time\n3. Grid search for appropriate hyperparameter setting\n4. Error evaluation: MAE(mean absolute error), RMSE(root mean squared error), r2score(coefficient of determination), explained variance for validation data\n5. Best model is chosen based on lowest RMSE as well as other metrics are monitored for its validity,\n6. Feature selection for best model\n7. Hyperparameter tuning and retraining with best parameter for model\n8. Testing out final model on test set.\n\n### Something about Error Evaluation:\n\n**MAE and RMSE:**\n\nMAE is termed as mean absolute error and represents average error amount while RMSE is termed as root mean square error its square root of average of squared error.It has ability to panalize larger error more. Both are ranges from 0 to infinity and negatively oriented score . It means lower values are better. In regular case, RMSE >= MAE. If there are some error ouliers means some very less frquent high error terms are present then RMSE <= MAE\\*sqrt(n). Here, n represnts number of samples under consideration. Therefore, we can set bounding for RMSE; upper bound is MAE\\*sqrt(n) and lower bound is MAE. (Refer this nice article for more details: https:\/\/medium.com\/human-in-a-machine-world\/mae-and-rmse-which-metric-is-better-e60ac3bde13d)\n\nIn model evaluation step, we are calculating RMSE and MAE for different version of each model type  (version refer as various values of model parameter( alpha in this case )). and try to observe the plot of RMSE. Desirable behaviour of RMSE plot is it must be much closer or equal to lower bound. If such behavior is not observed then it implies that our model is performing worst.\n\n**R2-score and explained variance:**\n\nExplained variance (also called explained variation) is used to measure the discrepancy between a model and actual data. Higher percentages of explained variance indicates a stronger strength of association. It also means that you make better predictions. R2-score is coefficient of determination which measures the amount of variation explained by the (least-squares) Linear Regression. Both are positively oriented score and range is 0 to 1.\n\nR2 = 1 - [(Sum of Squared Residuals \/ n) \/ Variancey_actual]\n\nExplained Variance Score = 1 - [Variance(Ypredicted - Yactual) \/ Variancey_actual]\n\nVariance(Ypredicted - Yactual) = (Sum of Squared Residuals - Mean Error) \/ n \n\nWhen we compare the R2 Score with the Explained Variance Score, we are basically checking the Mean Error; so if R2 = Explained Variance Score, that means The Mean Error = 0\n\nThe Mean Error reflects the tendency of our estimator, that is: the Biased v.s Unbiased Estimation.\n\nSo in model evaluation step, if we find R2 score = Explained Variance score that means our model is unbiased and if they are not equal then Mean Error != 0 and our model is biased. Bias can be interpreted from sign of mean error, positive means overestimating and negative means underestimating.","d1bd0277":"RMSE seems to be quite close to lower bound all the time that means it indicates low error variance. Best value of alpha parameter is highlighted with red color. R2score corresponds to this best alpha value seems to be high (>0.9). That means more than 90 percent of variability can be explained by best Lasso model. Explained variance score is quite close to R2 score it implise our model unbiased which is good indication.","015ff2d0":"#### **Ridge Regression:**\n\nIt is L2 regularization method. It adds penalty equivalent to square of the magnitude of coefficients\n\nMin. objective = Least Square Obj + \u03b1 * (sum of square of coefficients)\n\nif \u03b1 = 0, it works as a simple linear regression model. If this vale is greater than 0 it minimizes the coefficient and it tends to zero if \u03b1 is sufficiently high but not equal to zero. Shrinking the coefficients leads to a lower variance and in hence a lower error value. Therefore Ridge regression decreases the complexity of a model and thus avoids overfitting but does not reduce the number of features, it rather just shrinks their effect.\n","b160fd88":"## Helper function for model training and evaluation\n\nHelper function named parameter_select has been created which grid search for parameter especially alpha for given linear model and evaluate model performance based on four different metric score as discussed before. Best model parameter is obtained based on lowest RMSE score.","5d2867bf":"## Prepare Data","519ff3b7":"Let's train model with selected feature and search for optimum hyper parameter through grid search.","11ea1157":"Similar behavior as previous has been observed. But the RMSE for best model is slightly higher than previous best model.\n\n#### **Elastic Net :**\n\nElastic Net which incorporates penalties from both L1 and L2 regularization. This will effectively shrink some coefficients and set some coeff to zero.\n\nMin. Objective = Least Square Obj + a \\* L1-penalty + b \\* L2-penalty\n\nalpha = a + b and l1_ratio = a \/ (a + b)              ----- as per sklearn tutorial\n\n","9ba62d6f":"## Hyperparameter selection for selected model with selected features","79aebd26":"## Evaluate model on test data\nTrain final model with selected feature and optimum hyperparameter setting and evaluate on test data.","0b1ec2bb":"We have obtained 13809 RMSE on test data which lies in top 3% ranking which indicates that linear model with regularization has ability produce satifactory and competitive performance for given regression problem."}}