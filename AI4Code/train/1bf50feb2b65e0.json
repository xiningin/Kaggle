{"cell_type":{"4c2243c6":"code","2bd51301":"code","c7dfd60c":"code","d7ccb593":"code","3ad2f8a1":"code","602f5375":"code","9afb9f87":"code","1eca38f3":"code","ecd10012":"code","f805f588":"code","d77d563c":"code","042abd6a":"code","b7d122fb":"code","6604e082":"code","7e460b28":"code","27abe807":"code","5edf03ec":"code","b3ae8986":"code","ed5fa400":"code","5542cf7a":"code","aba4ab20":"code","63c2f39f":"code","645ca61e":"code","b3c4f493":"code","1893a98b":"code","d26ed3bf":"code","9a4e6ee9":"code","a58cf1e8":"code","1f24e287":"code","63541a48":"code","6e1986cc":"code","3db88485":"code","dd835a28":"code","7b0c64ac":"code","8fbd7451":"code","b637cbfd":"code","eaa14be3":"code","e504dd3c":"code","43f0e9b9":"code","b3cbab34":"code","adbac35b":"code","f71e5294":"code","6a62469e":"code","28866d66":"code","99e59835":"code","48f2320a":"code","a7334077":"code","9e57aa9f":"code","48688750":"code","1d2b7787":"markdown"},"source":{"4c2243c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2bd51301":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport nltk\nimport scipy\nimport warnings\nimport re","c7dfd60c":"df_train = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip',sep='\\t')\n\ndf_test = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/testData.tsv.zip',sep='\\t')\n","d7ccb593":"df_train.head()","3ad2f8a1":"df_test.head()","602f5375":"df_train.info()","9afb9f87":"df_train.describe()","1eca38f3":"pd.options.display.max_colwidth = 500\nprint(df_train['review'])","ecd10012":"# Remove HTML tags\ntxt = \" the source.<br \/><br \/>Here's a pretensions:<br \/><br \/>Just when\"\ncleanr = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});','',txt)\ncleanr","f805f588":"# Removing digits\ntext = \" the source.<br \/><br \/>Here's a 20 preten 103s and 120th sions:<br \/><br \/>Just when\"\ntext = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text) \ntext","d77d563c":"# Let's clean text\ndef clean_text(text):\n  text = text.lower()\n  text = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});','',text)  # for removal of html tags\n  text = re.sub(r\"can't\",\"cannot\",text)\n  text = re.sub(r\"shan't\",\"shall not\",text)\n  text = re.sub(r\"won't\",\"will not\",text)\n  text = re.sub(r\"n't\",\" not\",text) # see the space before not. \n  text = re.sub(r\"i'm\",\"i am\",text)\n  text = re.sub(r\"what's\",\"what is\",text)\n  text = re.sub(r\"let's\",\"let us\",text)\n  text = re.sub(r\"'re\",\" are\",text)\n  text = re.sub(r\"'s\",\" \",text)  # space because we dont know the tense , it can be is\/has anything.\n  text = re.sub(r\"'ve\",\" have\",text)\n  text = re.sub(r\"\\'ll\", \" will \", text)\n  text = re.sub(r\"\\'scuse\", \" excuse \", text)\n  text = re.sub(r\"[^a-zA-Z]\",\" \",text)\n  text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text) # Removing digits\n  text = re.sub('\\W', ' ', text)  # If the comment\/word does not contain any alphabets\n  text = re.sub('\\s+', ' ', text) # If there are more than one whitespace simultenously, then replace them by only 1 whitespace and also replace the punctuation marks\n  text = text.strip(' ') # Removing leading and trailing white spaces\n  return text","042abd6a":"df_train['review'] = df_train['review'].apply(lambda text: clean_text(text))","b7d122fb":"print(df_train['review'])","6604e082":"df_test['review'] = df_test['review'].apply(lambda text: clean_text(text))","7e460b28":"print(df_test['review'])","27abe807":"# For train file\n\nX = df_train['review']\ny = df_train['sentiment']\n\n# For test file\n\nX_test = df_test['review']","5edf03ec":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score,roc_curve","b3ae8986":"tf = TfidfVectorizer(stop_words='english',max_features=50000)\ntf","ed5fa400":"# For training\n\nX = tf.fit_transform(X)\n\n# For test \n\nX_test = tf.transform(X_test)","5542cf7a":"len(tf.get_feature_names()) ,","aba4ab20":"print(X.toarray().shape)\nX.toarray()","63c2f39f":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.1,random_state=50)","645ca61e":"from sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier()","b3c4f493":"rf_clf.fit(X_train,y_train)","1893a98b":"y_val_pred = rf_clf.predict(X_val)","d26ed3bf":"print(accuracy_score(y_val_pred,y_val))","9a4e6ee9":"print(roc_curve(y_val_pred,y_val))","a58cf1e8":"print(roc_auc_score(y_val_pred,y_val))","1f24e287":"rfc1 = rf_clf.predict(X_test)\nrfc2 = rf_clf.predict_proba(X_test)[:,1]","63541a48":"rfc1\nrfc2","6e1986cc":"submission_file = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')\nsubmission_file.head()","3db88485":"submission_file['sentiment'] = rfc1","dd835a28":"submission_file","7b0c64ac":"submission_file.to_csv('Using ensemble model.csv',index=False)","8fbd7451":"import xgboost as xgb","b637cbfd":"xg_clf = xgb.XGBClassifier(objective ='binary:logistic',learning_rate=0.2,n_estimators=1000,max_depth=20,tree_method = 'gpu_hist')","eaa14be3":"xg_clf.fit(X_train,y_train)","e504dd3c":"print(roc_auc_score(y_val_pred,y_val))","43f0e9b9":"xgb1 = xg_clf.predict(X_test)\nxgb2 = xg_clf.predict_proba(X_test)[:,1]","b3cbab34":"xgb2","adbac35b":"submission_file = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')\nsubmission_file.head()","f71e5294":"submission_file['sentiment'] = xgb1\nsubmission_file.to_csv('Using xgboost.csv',index=False)","6a62469e":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()","28866d66":"lr.fit(X_train,y_train)\ny_val_pred = lr.predict(X_val)\n\nprint(roc_auc_score(y_val_pred,y_val))\n\nlr1 = lr.predict(X_test)\nlr2 = lr.predict_proba(X_test)[:,1]","99e59835":"submission_file = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')\nsubmission_file['sentiment'] = lr1\nsubmission_file.to_csv('Using Logistic Regression.csv',index=False)","48f2320a":"a = rfc2+xgb2+lr2\na = a\/3\nprint(a)","a7334077":"submission_file = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')\nsubmission_file['sentiment'] = a\nsubmission_file.to_csv('Model Mixing.csv',index=False)","9e57aa9f":"a1 = xgb2+lr2\na1 = a1\/2\nprint(a1)","48688750":"submission_file = pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')\nsubmission_file['sentiment'] = a1\nsubmission_file.to_csv('2 Model Mixing.csv',index=False)","1d2b7787":"~84% accuract"}}