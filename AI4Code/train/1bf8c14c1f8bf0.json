{"cell_type":{"3a2721e0":"code","8b0d1d91":"code","252a42be":"code","7f88f00a":"code","8ca05117":"code","a2fce788":"code","7b7898c1":"code","b6c1dfe0":"code","01525bfc":"code","2200b6b6":"code","71c35d36":"code","cd3cc6cc":"code","7aa64241":"code","634e0fbf":"code","5d0e0a2e":"code","e998136a":"code","d4a1fb06":"code","9a2901bb":"code","bb34aa25":"code","bd2109f5":"markdown","5d328d9f":"markdown","af199375":"markdown","3236d86c":"markdown","fd39fd5a":"markdown","e73a23f7":"markdown","5e93df00":"markdown","7f29be91":"markdown","b8adf686":"markdown","dad5e73c":"markdown","cf4066b2":"markdown","f8b5e454":"markdown","fbcd6f6b":"markdown","173c43be":"markdown","0628a494":"markdown","36706880":"markdown","cac13f31":"markdown","7d874a59":"markdown","026f9b80":"markdown","0010cbad":"markdown","446636b5":"markdown"},"source":{"3a2721e0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n!pip install pmdarima\nimport pmdarima as pm\nfrom pmdarima.model_selection import train_test_split\nfrom pmdarima import arima\nfrom pmdarima import model_selection\nfrom pmdarima import pipeline\nfrom pmdarima import preprocessing\nfrom pmdarima.datasets._base import load_date_example\nfrom pmdarima.utils import tsdisplay\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n# Load the data\nmosquito_totals = pd.read_csv('..\/input\/massachusetts-arbovirus-survalliance-data-201419\/mosquito_totals.csv')\n\n# Convert dates\nmosquito_totals['Collection Date'] = pd.to_datetime(mosquito_totals['Collection Date'])\n\n# Sort by Collection date\nmosquito_totals = mosquito_totals.sort_values(by='Collection Date', ascending=True).reset_index()\n\nprint(\"Total number of observations:\", len(mosquito_totals))\n\nmosquito_totals.head()","8b0d1d91":"# Print a random mosquito bite as a sample\nsample_index = 25\nprint(mosquito_totals.iloc[sample_index])","252a42be":"import plotly.express as px\nimport plotly.graph_objects as go\n\nmosquito_cases = pd.DataFrame(mosquito_totals.groupby(['Collection Date']).Virus.count()).reset_index()\nmosquito_cases.columns = ['Date', 'Cases']\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=mosquito_cases['Date'],\n                         y=mosquito_cases['Cases'],\n                         mode='lines',\n                         name='Mosquito cases',\n                         showlegend=True))\nfig.update_layout(title='New confirmed cases per year',\n                   xaxis_title='Year',\n                   yaxis_title='New cases')\nfig.show()","7f88f00a":"mosquito_totals['Year'] = mosquito_totals['Collection Date'].dt.year\nmosquito_per_year = pd.DataFrame(mosquito_totals.groupby(['Year'])['Virus'].count()).reset_index()\nmosquito_per_year.columns = ['Year', 'Cases']\nfig = px.bar(mosquito_per_year, x='Year', y='Cases')\nfig.update_layout(title='Total confirmed cases per year',\n                   xaxis_title='Year',\n                   yaxis_title='New cases')\nfig.show()","8ca05117":"mosquito_virus = mosquito_totals.groupby(['Year', 'Virus'], as_index=False).count()\nmosquito_virus = mosquito_virus.iloc[:,:3]\nmosquito_virus.columns = ['Year', 'Virus', 'Cases']\nfig = px.bar(mosquito_virus, x=\"Year\", y=\"Cases\", color=\"Virus\", title=\"Confirmed cases by virus\")\nfig.show()","a2fce788":"mosquito_virus_sum = mosquito_virus.groupby(['Year', 'Virus'], as_index=False).agg('sum')\nfig = px.line(mosquito_virus_sum, x=\"Year\", y=\"Cases\", color='Virus')\nfig.update_layout(title='New EEE and WNV cases per year',\n                   xaxis_title='Year',\n                   yaxis_title='New cases')\nfig.show()","7b7898c1":"# Remake the mosquito cases dataframe for clarity\nmosquito_cases = pd.DataFrame(mosquito_totals.groupby(['Collection Date']).Virus.count()).reset_index()\nmosquito_cases.columns = ['Date', 'Cases']\n\n# Set date column to index\nmosquito_cases.set_index('Date',inplace=True)\n\ntrain_size = int(0.9*len(mosquito_cases))\ny_train, y_test = train_test_split(mosquito_cases, train_size=train_size)\n\n# Show the ACF and frequency plot of the data\ntsdisplay(y_train, lag_max=90)","b6c1dfe0":"baseline_model = pm.auto_arima(y_train, suppress_warnings=True, start_p=0, start_q=0,\n                      max_p=5, max_q=5, stepwise=True, trace=True, seasonal=True, m=12)","01525bfc":"baseline_model.summary()","2200b6b6":"# Make predictions using naive model\npredictions = baseline_model.predict(n_periods=y_test.shape[0])\n\n# Plot baseline mode\nfig = go.Figure()\nx = np.arange(y_test.shape[0])\nfig.add_trace(go.Scatter(x=x, y=y_test['Cases'], mode='markers', name='Actual cases', showlegend=True))\nfig.add_trace(go.Scatter(x=x, y=predictions, mode='lines', name='Predicated cases'))\n\nfig.update_layout(title='Baseline naive model for m=12',\n                   xaxis_title='Days',\n                   yaxis_title='New cases')\n\nfig.show()","71c35d36":"from pmdarima.preprocessing import LogEndogTransformer\n\ny_train_log, _ = LogEndogTransformer(lmbda=1e-6).fit_transform(y_train)\ntsdisplay(y_train_log, lag_max=100)","cd3cc6cc":"from pmdarima.preprocessing import BoxCoxEndogTransformer\n\ny_train_bc, _ = BoxCoxEndogTransformer(lmbda2=1e-6).fit_transform(y_train)\ntsdisplay(y_train_bc, lag_max=100)","7aa64241":"# Make a column containing the difference in cases for train and test set\n# We shift by 12 since m=12\n\npd.set_option('mode.chained_assignment', None)\ny_train['Cases Difference'] = y_train['Cases'] - y_train['Cases'].shift(12)\ny_test['Cases Difference'] = y_test['Cases'] - y_test['Cases'].shift(12)\n\n# Fill missing values (the first 12)\ny_train = y_train.fillna(0)\ny_test = y_test.fillna(0)\n\n# Display the new data\npm.tsdisplay(y_train['Cases Difference'], lag_max=90, show=True)","634e0fbf":"x = np.arange(y_train.shape[0])\n\nfig = make_subplots(rows=1, cols=2)\nfig.add_trace(go.Scatter(x=x, y=y_train['Cases'], name=\"New cases\"), row=1, col=1)\nfig.add_trace(go.Scatter(x=x, y=y_train['Cases Difference'], name=\"New cases differentiated\"), row=1, col=2)\n\nfig.update_layout(title_text=\"Test samples count vs. differentiated\")\nfig.show()","5d0e0a2e":"# Create a default ARIMA model\nmodel1 = pm.ARIMA(order=(1, 0, 1),\n               seasonal_order=(1, 0, 1, 12),\n               suppress_warnings=True)\n\n# Create the one we found previously using AutoARIMA\nmodel2 = pm.ARIMA(order=(2, 1, 1),\n               seasonal_order=(0, 0, 1, 12),\n               suppress_warnings=True)\n\n# Set the CV strategy\ncv = model_selection.SlidingWindowForecastCV(window_size=100, step=24, h=1)\n\n# Run CV and get scores for each model\nprint(\"Creating model 1 (1, 0, 1): \\n\")\nmodel1_cv_scores = model_selection.cross_val_score(model1, y_train['Cases Difference'], scoring='smape', cv=cv, verbose=2)\nprint()\nprint(\"Creating model 2 (2, 1, 1): \\n\")\nmodel2_cv_scores = model_selection.cross_val_score(model2, y_train['Cases Difference'], scoring='smape', cv=cv, verbose=2)\nprint()\n\nprint(\"Model 1 CV scores: {}\".format(model1_cv_scores.tolist()))\nprint(\"Model 2 CV scores: {}\".format(model2_cv_scores.tolist()))\n\n# Pick the with lowest mean error rate\nm1_average_error = np.average(model1_cv_scores)\nm2_average_error = np.average(model2_cv_scores)\nerrors = [m1_average_error, m2_average_error]\nmodels = [model1, model2]\n\n# Print out the answer\nbetter_index = np.argmin(errors)  # type: int\nprint(\"Lowest average SMAPE: {} (model{})\".format(errors[better_index], better_index + 1))\nprint(\"Best model: {}\".format(models[better_index]))","e998136a":"from pmdarima import model_selection\n\n# Create the model\nmodel = pm.ARIMA(order=(2, 1, 1),\n               seasonal_order=(0, 0, 1, 12),\n               suppress_warnings=True)\n\n# Set the CV strategy\ncv = model_selection.SlidingWindowForecastCV(window_size=100, step=1, h=4)\n\n# Make predictions\npredictions = model_selection.cross_val_predict(model, y_train['Cases Difference'], cv=cv, verbose=1, averaging=\"median\")\n\n# Plot the predictions on the training data\nx_axis = np.arange(y_train.shape[0])\nn_test = predictions.shape[0]\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x_axis, y=y_train['Cases Difference'], name='Actual cases'))\nfig.add_trace(go.Scatter(x=x_axis[-n_test:], y=predictions, name='Forecasted cases'))\nfig.update_layout(title='Cross-validated mosquito forecasts', xaxis_title='Days', yaxis_title='New cases')\nfig.show()","d4a1fb06":"# Remove the first 12 zero samples\ny_test = y_test.iloc[12:]\n\n# Create the best model we found\nmodel = pm.ARIMA(order=(2, 1, 1),\n                 seasonal_order=(0, 0, 1, 12),\n                 suppress_warnings=True)\n\n# Fit on the difference score\nmodel.fit(y_train['Cases Difference'])\n\n# Make predictions\npredictions = model.predict(n_periods=y_test.shape[0])\n\n# Plot the result\nx = np.arange(y_test.shape[0])\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x, y=y_test['Cases Difference'], mode='markers', name='Actual cases', showlegend=True))\nfig.add_trace(go.Scatter(x=x, y=predictions, mode='lines', name='Forecasted cases'))\n\nfig.update_layout(title='Forecasting 16 unseen mosquito cases',\n                   xaxis_title='Days',\n                   yaxis_title='New cases')\nfig.show()","9a2901bb":"model.summary()","bb34aa25":"from sklearn.metrics import mean_squared_error as mse\nfrom scipy.stats import normaltest\n\n# Set axis\nx = np.arange(y_train.shape[0] + predictions.shape[0])\nfig, axes = plt.subplots(2, 1, sharex=False, figsize=(10,10))\n\n# Make y_test an array\ny_test_arr = np.array(y_test['Cases Difference'])\n\n# Plot the forecasts\naxes[0].plot(x[:y_train.shape[0]], y_train, c='b')\naxes[0].plot(x[y_train.shape[0]:], predictions, c='g')\naxes[0].set_xlabel(f'RMSE = {np.sqrt(mse(y_test_arr, predictions)):.3f}')\naxes[0].set_xlabel('Days')\naxes[0].set_ylabel('New cases +\/-')\naxes[0].set_title('Forecasting new mosquito cases')\n\n# Plot the residuals\nresid = y_test_arr - predictions\n_, p = normaltest(resid)\naxes[1].hist(resid, bins=15)\naxes[1].axvline(0, linestyle='--', c='r')\naxes[1].set_xlabel('New cases +\/-')\naxes[1].set_ylabel('Residaul strength')\naxes[1].set_title(f'Residuals (p={p:.3f})')\n\nplt.tight_layout()\nplt.show()","bd2109f5":"Let's plot the predictions together with the original training data. The predicts should continue the trend observed in the training data, but fall off slightly, as we predicting from the summer and onwards (recall that the number of mosquito cases wear off after August).","5d328d9f":"# Finding the best model (CV)\n\nCross-validation is a model validation technique for assessing how the results of a statistical analysis will generalize to an independent data set. In this case, we want to know how well our ARIMA model can predict the future basically (new cases of mosquito bites). Scitit-learn offers various methods for cross-validating normal regressions and with Pmdarmia, we can cross-validate our time series models as well.\n\nLet's create two different models know: One using default ARIMA() parameters (1, 0, 1) and one using those found by AutoARIMA (2, 1, 1).","af199375":"# Making mosquito forecasts (CV)\n\nLet's use the model we just found, which is a SARIMAX(2,1,1) with m=12, to make forecasts about new mosquito bites.\n\nUnlike normal CV, time series CV might have different folds (windows) forecasting the same time step. After all forecast windows are made, we build a matrix of y x n_folds, populating each fold\u2019s forecasts, and then we average each time step\u2019s forecasts to end up with our final prediction results. So we with averaging strategy to \"median\".","3236d86c":"The frequency bins still does not still not look normal. Let's try manually differentiating the data, so that we create a new column with the difference between every observations. This will reduce the spikyness of the curve and make the data more stationary. Hopefully, this will produce a more normal frequency distribution.","fd39fd5a":"Let's visualize the two times we have now. First is a line showing new cases, and the second is the scalar difference between cases each day.","e73a23f7":"Examining the summary gives us:","5e93df00":"# Making mosquito forecasts (unseen data)\n\nWe'll now train the same ARIMA model as before using the best parameters obtained and have it forecast on unseen test data. The code below should not contain any surprise, as it is mostly a reprise of what's been done before.\n\nThough notice that the model gets through for a loop at the spike around day 4, where the number of cases suddently increases to 16 and drops to 0 the next day.","7f29be91":"# EDA\n\nLet's start off by investating the data a bit. The data is a recorded list of all registered mosquito bites and comes with the following columns:\n\n* County: The county the bite was registered in.\n* Town: The town the bite was registered in.\n* Collection Date: The day the person was bitten.\n* Specices: The mosquito species that made the bite.\n* Virus: The type of pathological infection that was detected following the bite.\n\nThe following plots are simple illustrations of the data.","b8adf686":"# Examining the timeseries\n\nTime series data is a bit different from traditional machine learning in the sense that it\u2019s temporally sensitive. That means the larger our test set, the higher we would expect our error to be for later forecasts, since our model won\u2019t be able to effectively forecast for too many periods into the future.\n\nHere, we\u2019ll take the first 2750 samples for training, and leave the last 70 as our test set.\n\nWe use the tsdisplay() function to visalize our data, take a look at the auto-correlation plot, and see the histogram of values.","dad5e73c":"Notice that we are not using the SMAPE (symmetric mean absolute percentage error) as we normally might, because our time series contains zeros. When the actual or forecasted value is zero, SMAPE is known to produce misleadingly large error terms. Instead, we\u2019re using the RMSE.\n\nThe first image shows the training data and our prediction as a continous line graph.\n\nThe second image shows the distribution of the residuals. The appear somewhat normally distributed and at least much more than the first residual plot we made using the raw new case numbers and not the differentated version.","cf4066b2":"![image.png](attachment:image.png)\n\n# Introduction\n\nIn the United States, an average of seven cases of Eastern Equine Encephalitis (EEE) are reported to the CDC annually. In 2019, however, the CDC confirmed 38 cases of EEE and 15 deaths. It has a fatality rate estimated to be around 33%, with many survivors experiencing permanent neurological damage, and there is currently no effective treatment. Other arboviruses, such as West Nile Virus (WNV), are also prevalent and deadly.\n\nMassachusetts was one of the most impacted states of the 2019 outbreak, with 12 reported cases and six deaths. Many towns in Massachusetts cancelled outdoor activities and imposed curfews during hours when mosquitos were most active with the hope of mitigating potential exposures, but such guidelines were reactive, not proactive. With fears of new, emerging arboviruses being more virulent, and in light of the recent outbreak of SARS-CoV-2, society should be better prepared to predict potential outbreaks and respond to them effectively before they happen.\n\nThis notebook demonstrates use of ARIMA models (Auto vs. manual) to forecast mosquito outbreaks based on data from Massachusetts.\n\nKey takeaways:\n\n* More cases are seen during the summer period.\n* The data is non-stationary and forecasting benefits when we differentiatate the case count.\n* A seasonal ARIMA model (SARIMAX) fits the data well.\n* Using AutoARIMA and CV we can improve the baseline model significantly.\n\nSources:\n\nhttps:\/\/alkaline-ml.com\/pmdarima\/tips_and_tricks.html <br>\nhttps:\/\/alkaline-ml.com\/pmdarima\/usecases\/sun-spots.html <br>\nhttps:\/\/alkaline-ml.com\/pmdarima\/auto_examples\/model_selection\/example_cross_val_predict.html","f8b5e454":"The log transformation didn\u2019t seem to help too much. In fact, it seems like it just shifted the skew to the other tail. Let\u2019s try the Box-Cox transformation. When .fit() is called, it will learn the lambda transformation parameter:","fbcd6f6b":"# Conclusion\n\nWe have demonstrated how the number of mosquito cases in Massachusetts can be forecasted using a SARIMAX (seasonal ARIMA) model. We used AutoARIMA to find the best model parameters and discovered via frequency plots that it's a good idea to differentiate the raw count. AutoARIMA also told us that by setting d=1.","173c43be":"More normal data is observed by the second plot, so we'll stick for that for now. Recall that AutoARIMA() found d=1, so differentiating the data is a good idea in this case.","0628a494":"# Understanding P, D, and Q\n\nARIMA models are made up of three different terms:\n\n**P:** The order of the auto-regressive (AR) model (i.e., the number of lag observations). A time series is considered AR when previous values in the time series are very predictive of later values. An AR process will show a very gradual decrease in the ACF plot.\n\n**D:** The degree of differencing.\n\n**Q:** The order of the moving average (MA) model. This is essentially the size of the \u201cwindow\u201d function over your time series data. An MA process is a linear combination of past errors.\n\nOften times, ARIMA models are written in the form ARIMA(p,d,q), where a model with no differencing term, e.g., ARIMA(1,0,12), would be an ARMA (made up of an auto-regressive term and a moving average term, but no integrative term, hence no \u201cI\u201d). One of the challenges of timeseries modelling with ARIMA is finding the hyperparameters P, D, and Q. Fortunately, the library offers a AutoARIMA() function that can estimate these values for us, as we'll see next.","36706880":"Reading this plot can give us several pieces of information:\n\n* We are looking at a seasonal time series. Our apriori knowledge of the dataset (mosquito bites varies by time of year) and the fact that the ACF has a spike around lag=12 informs us that this data has a seasonal periodicity of m=12.\n* There seems to be some significant data skew, looking at the histogram. It is very zero-inflated. A lot of the statistical techniques used in time series modeling behave better when the data is normally distributed, so this may be something to look into. This can possibilty be archived by differentiating the cases values to make the data stationary, as we'll see shortly.\n\nDifferentiating the cases will also likely make the time series more stationary. A series is defined as stationary when its mean, variance and auto-correlation, etc., are constant over time. Many time-series methods perform better when a time-series is stationary, since forecasting values becomes a far easier task for a stationary time series. ARIMAs that include differencing (i.e., d > 0) assume that the data becomes stationary after differencing. This is called difference-stationary. Auto-correlation plots are an easy way to determine whether your time series is sufficiently stationary for modeling.\n\nLook above and see, that our plot does not appear stationary, so our model will likely need a differencing term.","cac13f31":"# Fitting a baseline model\n\nBefore we start manipulating our data, let\u2019s examine what would happen if we just fit a model straight out of the box:","7d874a59":"Not bad, the model we found seems to do a good job at forecasting mosquito bites on the training data. Note that it starts off slow at the 0-100 interval, then fluctuatats after 150 as the number of new bites recoded every day increases. This plot is consistent with our discovery during EDA as the number of recorded mosquito cases as increased rapidly in 2018 and 2019 compared to the years ago. Perhaps we could get a even better model by only examining the data from 2018 and onwards.\n\nLet's make a prediction on the never-seen-before test set.","026f9b80":"Note that the AutoARIMA() produces a seasonal arima model (SARIMAX) with parameters p=2, d=1 and q=1. These are calculated by performing a stepwise search to minimize the AIC score (see above). Akaike\u2019s Information Criterion (AIC), which was useful in selecting predictors for regression, is also useful for determining the order of an ARIMA model. A lower AIC is always better, hence the model ended up with (2,1,1).\n\nWe used 222 oberservations to train this model and ended with an AIC=1452. Since d=1, the model suggests that differentiating the case count could be beneficial when making forecasting, thus we expext our model to perform better over more normal data (stationary).\n\nFor fun, let's use the baseline model to make forecasts already on the test set.","0010cbad":"And here's the model's summary:","446636b5":"# Transforming the data\n\nSince we expect our model to perform better over more normal data, let\u2019s experiment with log transformations and the Box-Cox transformation, each of which is provided as an endogenous transformer in the Pmdarima package."}}