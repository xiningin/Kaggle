{"cell_type":{"32942a56":"code","dc84d83b":"code","d55b3050":"code","01b7156a":"code","9b245ce4":"code","e6daecf4":"code","43350b5f":"code","1f5cf5b9":"code","78eae0c2":"code","2880998f":"code","fb29c75a":"code","43dba7c6":"code","b19f08a8":"code","0043efd9":"code","e5dde47e":"code","ad3d2047":"code","5928d8f2":"code","01b88069":"code","c2384eb4":"code","e7bbad43":"code","364493e1":"code","08798040":"code","f15140dc":"code","f4fb2063":"code","506f01ce":"code","697ca859":"code","1dd4f4a1":"code","ba47370f":"code","797e6cdf":"code","cb8cd73b":"code","1bc6d3d4":"code","68265e94":"code","5a20ba45":"code","4afab6c5":"code","a5bda96a":"code","ab69ea80":"code","4f3678e8":"code","123d22a8":"code","08238c53":"code","c03f7d6b":"code","c8062dbd":"code","082f1773":"code","a4d92814":"code","f343d9d7":"code","781808ae":"code","9eb87dc4":"code","8d524f21":"code","e3c3151f":"code","76fa4ef2":"code","5237b301":"code","9d8c65e6":"code","c2c240ec":"code","99adb9a7":"code","f94195e1":"code","5bd6d500":"code","7297129b":"code","4f95ffc1":"code","c16a8c80":"markdown","9b8d2b4e":"markdown","9e1e5439":"markdown","718c7209":"markdown","acb5bea8":"markdown","16436708":"markdown","764ef599":"markdown","8a25278e":"markdown","cbc0c7c2":"markdown","1d7a27ca":"markdown","68419269":"markdown","22ea21d1":"markdown","6050583b":"markdown","d8039d26":"markdown","086adadd":"markdown","eae01283":"markdown","57be2981":"markdown","6b588c06":"markdown"},"source":{"32942a56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc84d83b":"# load the train dataset\ntrn_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n# head() method for top five records of dataset\ntrn_data.head()","d55b3050":"# check whether howmany rows and columns are present in titanic dataset.\ntrn_data.shape","01b7156a":"#drop the passanger id because index is also work like id,\ntrn_data = trn_data.drop('PassengerId',axis=1)","9b245ce4":"# check the missing value\ntrn_data.isnull().sum()","e6daecf4":"# describe the trn_data\ntrn_data.describe()","43350b5f":"\"\"\"see correlation\"\"\"\ntrn_data.corr()","1f5cf5b9":"plt.figure(figsize=(10,8),dpi=100)\nsns.heatmap(trn_data.corr(),annot=True)","78eae0c2":"sns.pairplot(trn_data,hue='Survived',kind='kde')","2880998f":"\"\"\"perform visualization\"\"\"\nsns.countplot(trn_data['Survived'])","fb29c75a":"fig,ax = plt.subplots(1,2,figsize=(10,6))\nsns.countplot(x='Pclass',data=trn_data,hue='Survived',ax=ax[0])\nsns.countplot(x='Survived',data=trn_data,hue='Sex',ax=ax[1])","43dba7c6":"# percentage of how many women servived in titanic.\n\nwomen = trn_data.loc[trn_data.Sex == 'female']['Survived']\n# prct_women is % servived\nprct_women = sum(women)\/len(women)\n#print the women percentage\nprint('% of women survived:',prct_women)","b19f08a8":"# % men servived in titanic\nmen = trn_data.loc[trn_data.Sex == 'male']['Survived']\nprct_men = sum(men)\/len(men)\nprint(\"% men survived:\",prct_men)","0043efd9":"100*trn_data.isnull().sum()\/len(trn_data)","e5dde47e":"trn_data = trn_data.drop('Cabin',axis=1)","ad3d2047":"# check again missing value\n100*trn_data.isnull().sum()\/len(trn_data)","5928d8f2":"# fill NaN values for Age\ntrn_data['Age'].fillna(trn_data['Age'].mean(),inplace=True)\n# fill NaN values for embarked\nmost_occurance = trn_data['Embarked'].mode()[0]\ntrn_data['Embarked'].fillna(most_occurance,inplace=True)\n","01b88069":"# check again missing value\n100*trn_data.isnull().sum()\/len(trn_data)","c2384eb4":"# print all the column name with object datatype.\ntrn_data.dtypes","e7bbad43":"sex_dummies = pd.get_dummies(trn_data['Sex'],drop_first=True)\nembarked_dummies = pd.DataFrame(pd.get_dummies(trn_data['Embarked'],drop_first=True))","364493e1":"embarked_dummies","08798040":"trn_data = pd.concat([trn_data,embarked_dummies],axis=1)","f15140dc":"trn_data['Sex'] = sex_dummies\ntrn_data = trn_data.drop('Embarked',axis=1)","f4fb2063":"trn_data","506f01ce":"# drop the name and ticket feature from trn_data\ntrn_data = trn_data.drop(['Name','Ticket'],axis=1)","697ca859":"# split the target and features data.\n\ny = trn_data['Survived']\n\n# X is features of dataset.\nX = trn_data.copy()\nX = X.drop('Survived',axis=1)","1dd4f4a1":"X","ba47370f":"from sklearn.preprocessing import StandardScaler\nstscaler = StandardScaler()\nX = stscaler.fit_transform(X)\n","797e6cdf":"X","cb8cd73b":"# split the train and test data\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=1)","1bc6d3d4":"y_train","68265e94":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n","5a20ba45":"model1 = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=1)\nmodel2 = LogisticRegression()\nmodel3 = SVC()\nmodel4 = KNeighborsClassifier(n_neighbors=5)","4afab6c5":"model1.fit(X_train,y_train)\nmodel2.fit(X_train,y_train)\nmodel3.fit(X_train,y_train)\nmodel4.fit(X_train,y_train)","a5bda96a":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix","ab69ea80":"pred1 = model1.predict(X_test)\npred2 = model2.predict(X_test)\npred3 = model3.predict(X_test)\npred4 = model4.predict(X_test)","4f3678e8":"print(\"Accuracy Score with RandomForest:\",accuracy_score(y_test,pred1))\nprint(\"Accuracy Score with LogisticRegression:\",accuracy_score(y_test,pred2))\nprint(\"Accuracy Score with SVC:\",accuracy_score(y_test,pred3))\nprint(\"Accuracy Score with KNN:\",accuracy_score(y_test,pred4))","123d22a8":"# plot the create the classification report\nprint(\"Classification report for RandomForest:\",classification_report(y_test,pred1))\nprint(\"Classification report for LogisticRegression:\",classification_report(y_test,pred2))\nprint(\"Classification report for SVC:\",classification_report(y_test,pred3))\nprint(\"Classification report for KNN:\",classification_report(y_test,pred4))","08238c53":"# confusion metrixs\nprint(\"Confusion metrix  for Randomforest:\",confusion_matrix(y_test,pred1))\nprint(\"Confusion metrix  for LogisticRegression:\",confusion_matrix(y_test,pred2))\nprint(\"Confusion metrix  for SVC:\",confusion_matrix(y_test,pred3))\nprint(\"Confusion metrix  for KNN:\",confusion_matrix(y_test,pred4))","c03f7d6b":"print(\"Confusion Metrix for RandomForest:\")\nplot_confusion_matrix(model1,X_test,y_test)","c8062dbd":"print(\"Confusion Metrix for LogisticRegression:\")\nplot_confusion_matrix(model2,X_test,y_test)","082f1773":"print(\"Confusion Metrix for SVC:\")\nplot_confusion_matrix(model3,X_test,y_test)","a4d92814":"print(\"Confusion Metrix for KNN:\")\nplot_confusion_matrix(model4,X_test,y_test)","f343d9d7":"# take test data to test the model and save in a file\ntst_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")","781808ae":"tst_data.head()","9eb87dc4":"# check dtypes\ntst_data.dtypes","8d524f21":"# split the passengerid for save file output\npassangerid = tst_data['PassengerId']","e3c3151f":"# check null values\ntst_data.isnull().sum()","76fa4ef2":"# drop the cabin ,name and ticket column\ntst_data = tst_data.drop(['PassengerId','Cabin','Name','Ticket'],axis=1)","5237b301":"tst_data","9d8c65e6":"# perform labelencoding in Sex and Embarked and fill Null values.\nsex_d = pd.get_dummies(tst_data['Sex'],drop_first=True)\nembarked_d = pd.DataFrame(pd.get_dummies(tst_data['Embarked'],drop_first=True))","c2c240ec":"# fill the Null value in Age and Fare\ntst_data = pd.concat([tst_data,embarked_d],axis=1)\ntst_data['Age'].fillna(tst_data['Age'].mean(),inplace=True)\ntst_data['Fare'].fillna(tst_data['Fare'].mean(),inplace=True)","99adb9a7":"# replace the categorical data with dummies integer data\ntst_data['Sex'] = sex_d\n# after the labelencoding on Embarked remove the original Embarked column\ntst_data = tst_data.drop('Embarked',axis=1)","f94195e1":"# check agian null values\ntst_data.isnull().sum()","5bd6d500":"# perform StandardScaler\nsc2 = StandardScaler()\ntest_data = sc2.fit_transform(tst_data)","7297129b":"# fetch the LogisticRegression Model and predict the test_data \nprediction = model2.predict(test_data)","4f95ffc1":"output = pd.DataFrame({'PassengerId': passangerid, 'Survived': prediction.astype(int)})\noutput.to_csv('my_submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")","c16a8c80":"<h2>5. Validate the Model<\/h2>","9b8d2b4e":"<h2>4. Create a Model<\/h2>","9e1e5439":"here, four features with object datatype, we are going to with **Sex** and **Embarked** feature only.","718c7209":"<h3>Choose Perfect Model<\/h3>","acb5bea8":"<h2>2. Perform EDA<\/h2>","16436708":"<h2>1. Load Dataset<\/h2>","764ef599":"<h2>3. Feature Selection<\/h2>\n","8a25278e":"<h3>Saving Output in CSV file<\/h3>","cbc0c7c2":"check how many percentage missing value is available in dataset.\n","1d7a27ca":"from the above plot maximum number of person survived from **pclass 1** and Pclass 2 have less survived. Maximum number of women have survived in titanic.\n","68419269":"We are going to choose Logistic Regression with higher accuracy to test the in test.csv file and save output in csv file.","22ea21d1":"After Prediction save in file **mysubmission.csv**","6050583b":"<h1> Steps for creating model for Classification Titanic Survival.<\/h1>\n<ul>\n    <li>Load the Dataset <\/li>\n        <li>Perform EDA <\/li>\n        <li>Perform Feature Engineering <\/li>\n        <li>Perform Feature Selection<\/li>\n        <li>Create a Model <\/li>\n        <li>Validate the Model<\/li>\n<\/ul>","d8039d26":"In **Cabin** feature there are 77.14% missing value which is large amount, instead of filling value we should drop the particuar column\/feature.","086adadd":"convert categorical data to integer data using getdummies function. first of all check howmany features have object or string datatype.","eae01283":"Now we have only **Age** and **Embarked** missing value column\/feature, lets perform **Imputer** on it.","57be2981":"**Congratulations**, we have done with missing values.No one feature have missing values.","6b588c06":"<h2>3. Feature Engineering<\/h2>"}}