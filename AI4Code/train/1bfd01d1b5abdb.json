{"cell_type":{"a2342356":"code","966d8636":"code","022457af":"code","3bac3ffc":"code","3da98bff":"code","d53ccada":"code","b516eeed":"code","83138c17":"code","6ef630ea":"code","0b2530c0":"code","c8f73e50":"code","c60cfb96":"code","541f4a7c":"code","5f413835":"code","22ba02e0":"code","3c107aa2":"code","92fe0cb6":"code","1c195bfc":"code","e60fdfe9":"code","c2ffa4a4":"code","8898cbc7":"code","51dce3e1":"code","4b696c5d":"code","7e1e9f8e":"code","90406189":"code","f74b1827":"code","7d5f227e":"code","6781ccea":"code","08da6d7b":"code","70f8a398":"code","d07a31b7":"code","34af98ec":"code","d8199a5d":"code","d7506220":"code","a961cbcd":"code","eeafae29":"code","ff400f77":"code","30b718ff":"code","fbac5b96":"code","fd18b409":"code","a6a84976":"code","ddee677c":"code","277fe66c":"code","11fe05b8":"code","c6dd68fb":"code","c1ce6fb3":"code","67d2be60":"code","2e2a842a":"code","06f1340a":"code","12af7b99":"code","4b63d092":"code","266c0185":"code","1662e9ec":"code","1ca83125":"code","4a027981":"code","6a54e7c6":"code","e37a5bd2":"code","dd4bbcdc":"code","6752e559":"code","5f6b9a5a":"code","3c6d8bcb":"code","175d77ef":"code","c7134868":"code","058286de":"code","ce3a2a8d":"code","421bab47":"code","6049ce5a":"code","e6d434ab":"code","a03e3996":"code","1ad0a733":"code","3a72c494":"code","651f4ca5":"code","947076fa":"code","31180ff7":"code","82756d69":"code","5532af42":"code","925526f5":"code","990cbccc":"code","4793976a":"code","3bfecfb2":"code","087b892a":"code","85399552":"code","aec123ba":"code","3f098018":"code","62a3d3e3":"code","9f293f6a":"code","49f41c13":"code","a22ea54f":"code","6f281bb7":"code","4da0131c":"code","53632887":"code","1dd09392":"code","e995c6b0":"code","b33b9313":"code","37758c8f":"code","518d13fa":"code","c805740d":"code","f1933de8":"code","1824d0e5":"code","cf14ac66":"code","2e495da6":"code","149c04cf":"code","516ca6d4":"code","ee412fe4":"code","dc5b778f":"code","50e5fdba":"code","13181ea9":"code","5e69cc19":"code","ab1dc92e":"code","0134d11a":"code","e02b385a":"code","bcc60168":"code","f7c6700c":"code","ccf05ad3":"code","7abd81b6":"code","92e04672":"code","6eec1080":"code","920df6ec":"code","f1331001":"code","985c87e9":"code","2a267757":"code","932556f1":"code","a379d51c":"code","75e7a298":"markdown","b8eb8ff0":"markdown","d133a60a":"markdown","882e4d9a":"markdown","e251d26e":"markdown","26cfcd89":"markdown","db5973a4":"markdown","d43d3e2b":"markdown","bfff6bdb":"markdown","e149bb6c":"markdown","ef80e073":"markdown","d4e00d79":"markdown","a1875a40":"markdown","07e92468":"markdown","bfc2cb10":"markdown","1fc755b3":"markdown","a019b4b9":"markdown","0ead5f11":"markdown","107f416b":"markdown","03e765ce":"markdown","53dcd85e":"markdown","103c7afa":"markdown","b9c494a1":"markdown","11631a83":"markdown","b24b302c":"markdown","acd40ec4":"markdown","c474fed8":"markdown"},"source":{"a2342356":"import pandas as pd\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nimport numpy as np\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nimport matplotlib.pyplot as plt#visualization\nfrom PIL import  Image\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n%matplotlib inline\n\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport io\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization","966d8636":"print(os.listdir(\"..\/input\"))","022457af":"df = pd.read_excel(open('..\/input\/club-data-set\/Assignment.xlsx', 'rb'),\n...               sheet_name='Data')\n\ndf.START_DATE = pd.to_datetime(df.START_DATE, format = '%Y%m%d', errors='coerce')\ndf.END_DATE = pd.to_datetime(df.END_DATE, format = '%Y%m%d', errors='coerce')\ndf[\"CHURN\"] = df[\"MEMBERSHIP_STATUS\"].replace({\"CANCELLED\":1,\"INFORCE\":0})\ndf.drop(columns=[\"MEMBERSHIP_STATUS\"], inplace=True)","3bac3ffc":"df.head()","3da98bff":"print(df.info())\nprint(df.describe())\nprint (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values : \\n \", df.isnull().sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","d53ccada":"# # split private test set\n# df_private_test_1 = df.sample(259)#.reset_index(drop = True)\n# df = df.drop(df_private_test_1.index)\n# df_private_test_2 = df.tail(259)#.reset_index(drop = True)\n# df = df.drop(df_private_test_2.index)\n# df = df.reset_index(drop=True)#df.drop(df_private_test_1.index + df_private_test_2.index)\n# df_private_test_1 = df_private_test_1.reset_index(drop = True)\n# df_private_test_1 = df_private_test_1.reset_index(drop = True)\n","b516eeed":"def plot_cor(df):\n    # ex plot_cor(train[cons_id + ['isFraud']])\n    correlations = df.corr()\n\n    # Using seaborn package\n    # Generate a mask for the upper triangle\n    mask = np.zeros_like(correlations, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n\n    # Set up the matplotlib figure\n    f, ax = plt.subplots(figsize=(8, 8))\n\n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(260, 10, as_cmap=True)\n\n    # Draw the heatmap with the mask and correct aspect ratio\n    sns.heatmap(correlations, mask=mask, cmap=cmap, vmin = -1, vmax= 1 , center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    plt.yticks(rotation=0)","83138c17":"plot_cor(df)","6ef630ea":"def find_topcorr_bycol(col):\n    df_corr = df.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n    df_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}\n                , inplace=True) \n    return df_corr[df_corr[\"Feature 1\"]==col]","0b2530c0":"find_topcorr_bycol('ADDITIONAL_MEMBERS')","c8f73e50":"#Separating churn and non churn customers\nchurn     = df[df[\"CHURN\"] == 1]\nnot_churn = df[df[\"CHURN\"] == 0]\n\n#Separating catagorical and numerical columns\nId_col     = [\"MEMBERSHIP_NUMBER\"]\ntarget_col = [\"CHURN\"]\ncat_cols   = df.nunique()[df.nunique() < 7].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\nprint(\"categorical cols: {}\\nnumerical cols: {} \".format(cat_cols,num_cols))","c60cfb96":"#function  for pie plot for customer attrition types\ndef plot_pie(column) :\n    \n    trace1 = go.Pie(values  = churn[column].value_counts().values.tolist(),\n                    labels  = churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"Churn Customers\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    hole    = .6\n                   )\n    trace2 = go.Pie(values  = not_churn[column].value_counts().values.tolist(),\n                    labels  = not_churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    domain  = dict(x = [.52,1]),\n                    hole    = .6,\n                    name    = \"Non churn customers\" \n                   )\n\n\n    layout = go.Layout(dict(title = column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .15, y = .5),\n                                           dict(text = \"Non churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .88,y = .5\n                                               )\n                                          ]\n                           )\n                      )\n    data = [trace1,trace2]\n    fig  = go.Figure(data = data,layout = layout)\n    py.iplot(fig)\n\n\n#function  for histogram for customer attrition types\ndef histogram(column) :\n    trace1 = go.Histogram(x  = churn[column],\n                          histnorm= \"percent\",\n                          name = \"Churn Customers\",\n                          marker = dict(line = dict(width = .5,\n                                                    color = \"black\"\n                                                    )\n                                        ),\n                         opacity = .9 \n                         ) \n    \n    trace2 = go.Histogram(x  = not_churn[column],\n                          histnorm = \"percent\",\n                          name = \"Non churn customers\",\n                          marker = dict(line = dict(width = .5,\n                                              color = \"black\"\n                                             )\n                                 ),\n                          opacity = .9\n                         )\n    \n    data = [trace1,trace2]\n    layout = go.Layout(dict(title =column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = column,\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = \"percent\",\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                           )\n                      )\n    fig  = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)","541f4a7c":"#function  for scatter plot matrix  for numerical columns in data\ndef scatter_matrix(df)  :\n    \n    df  = df.sort_values(by = \"CHURN\" ,ascending = True)\n    classes = df[\"CHURN\"].unique().tolist()\n    classes\n    \n    class_code  = {classes[k] : k for k in range(2)}\n    class_code\n\n    color_vals = [class_code[cl] for cl in df[\"CHURN\"]]\n    color_vals\n\n    pl_colorscale = \"Portland\"\n\n    pl_colorscale\n\n    text = [df.loc[k,\"CHURN\"] for k in range(len(df))]\n    text\n\n    trace = go.Splom(dimensions = [dict(label  = \"MEMBERSHIP_TERM_YEARS\",\n                                       values = df[\"MEMBERSHIP_TERM_YEARS\"]),\n                                  dict(label  = 'ANNUAL_FEES',\n                                       values = df['ANNUAL_FEES']),\n                                  dict(label  = 'MEMBER_ANNUAL_INCOME',\n                                       values = df['MEMBER_ANNUAL_INCOME'])],\n                     text = text,\n                     marker = dict(color = color_vals,\n                                   colorscale = pl_colorscale,\n                                   size = 3,\n                                   showscale = False,\n                                   line = dict(width = .1,\n                                               color='rgb(230,230,230)'\n                                              )\n                                  )\n                    )\n    axis = dict(showline  = True,\n                zeroline  = False,\n                gridcolor = \"#fff\",\n                ticklen   = 4\n               )\n    \n    layout = go.Layout(dict(title  = \n                            \"Scatter plot matrix for Numerical columns for customer attrition\",\n                            autosize = False,\n                            height = 800,\n                            width  = 800,\n                            dragmode = \"select\",\n                            hovermode = \"closest\",\n                            plot_bgcolor  = 'rgba(240,240,240, 0.95)',\n                            xaxis1 = dict(axis),\n                            yaxis1 = dict(axis),\n                            xaxis2 = dict(axis),\n                            yaxis2 = dict(axis),\n                            xaxis3 = dict(axis),\n                            yaxis3 = dict(axis),\n                           )\n                      )\n    data   = [trace]\n    fig = go.Figure(data = data,layout = layout )\n    py.iplot(fig)","5f413835":"#for all categorical columns plot pie\nfor i in cat_cols :\n    plot_pie(i)\n","22ba02e0":"#for all categorical columns plot histogram    \nfor i in num_cols :\n    histogram(i)\n\n","3c107aa2":"#scatter plot matrix\nscatter_matrix(df)","92fe0cb6":"df[\"CHURN\"].value_counts()","1c195bfc":"#labels\nlab = df[\"CHURN\"].value_counts().keys().tolist()\n#values\nval = df[\"CHURN\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab ,\n               values = val ,\n               marker = dict(colors =  [ 'royalblue' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width = 1)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Customer attrition in data\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data,layout = layout)\npy.iplot(fig)","e60fdfe9":"def plot_analyze1_catcol(col,target, df):    \n#     col = 'MEMBER_GENDER'\n#     target = 'MEMBERSHIP_STATUS'\n\n    tmp = pd.crosstab(df[col], df[target], normalize='index') * 100\n    tmp = tmp.reset_index()\n    print(tmp)\n\n    plt.figure(figsize=(14,10))\n    plt.suptitle(f'{col} Distributions', fontsize=22)\n\n    plt.subplot(221)\n    g = sns.countplot(x=col, data=df)\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n    g.set_title(f'{col} Distributions', fontsize=19)\n    g.set_ylim(0,9000)\n    g.set_xlabel(\"Card4 Category Names\", fontsize=17)\n    g.set_ylabel(\"Count\", fontsize=17)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/len(df)*100),\n                ha=\"center\",fontsize=14) \n\n\n    plt.subplot(222)\n    g1 = sns.countplot(x=col, hue=target, data=df)\n    plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n#     gt = g1.twinx()\n#     gt = sns.pointplot(x=col, y=target, data=tmp, \n#                        color='black', legend=False)\n#     #                    #,order=['discover', 'mastercard', 'visa', 'american express'])\n#     gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n    g1.set_title(f\"{col} by Target({target})\", fontsize=19)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=17)\n    g1.set_ylabel(\"Count\", fontsize=17)\n\n    # compare with annual fees\n    plt.subplot(212)\n    g3 = sns.boxenplot(x=col, y='ANNUAL_FEES', hue=target, \n                  data=df)#[df['ANNUAL_FEES'] <= 200000] )\n    g3.set_title(f\"ANNUAL_FEES Distribuition by {col} & Target\", fontsize=20)\n    g3.set_xlabel(f\"{col} Category Names\", fontsize=17)\n    g3.set_ylabel(\"Transaction Values\", fontsize=17)\n\n    plt.subplots_adjust(hspace = 0.6, top = 0.85)\n\n    plt.show()","c2ffa4a4":"tmp = df.copy()\ntmp['MEMBER_GENDER'] = tmp['MEMBER_GENDER'].fillna('N')","8898cbc7":"#tmp['MEMBER_GENDER','CHURN'].value_counts()\ntmp.groupby(['MEMBER_GENDER','CHURN']).size()","51dce3e1":"plot_analyze1_catcol('MEMBER_GENDER','CHURN',tmp)","4b696c5d":"tmp[(tmp['MEMBER_GENDER']=='N')]['MEMBER_ANNUAL_INCOME'].value_counts()#& (tmp['ANNUAL_FEES'] < 1000000)& (tmp['MEMBER_ANNUAL_INCOME'] < 5000000)]","7e1e9f8e":"plot_analyze1_catcol('MEMBER_GENDER','CHURN',tmp[(tmp['ANNUAL_FEES'] < 1000000) & (tmp['MEMBER_ANNUAL_INCOME'] < 5000000)])","90406189":"tmp = df.copy()\ntmp = tmp[tmp['MEMBER_GENDER'].notnull()]\n","f74b1827":"tmp_grp = tmp.groupby(['MEMBER_OCCUPATION_CD','MEMBER_AGE_AT_ISSUE','MEMBER_GENDER']).agg({\n   #'MEMBER_ANNUAL_INCOME':[lambda x: x.notnull().mean(),'mean','count'],\n    'ANNUAL_FEES':'mean',\n    'MEMBERSHIP_NUMBER':'count',\n    'CHURN':'sum'\n}).reset_index()","7d5f227e":"tmp['MEMBER_OCCUPATION_CD'].value_counts()","6781ccea":"plot_analyze1_catcol('MEMBER_OCCUPATION_CD','CHURN', tmp)","08da6d7b":"tmp['MEMBER_OCCUPATION_CD'] = tmp['MEMBER_OCCUPATION_CD'].replace({4:3,5:3,6:3})#.value_counts()","70f8a398":"plot_analyze1_catcol('MEMBER_OCCUPATION_CD','CHURN', tmp)","d07a31b7":"plot_analyze1_catcol('MEMBER_OCCUPATION_CD','CHURN', tmp[(tmp['ANNUAL_FEES'] < 1000000) & (tmp['MEMBER_ANNUAL_INCOME'] < 5000000)])","34af98ec":"# final data processing\ntmp['MEMBER_MARITAL_STATUS'] = tmp['MEMBER_MARITAL_STATUS'].fillna('UNK')\ntmp['MEMBER_MARITAL_STATUS'] = tmp['MEMBER_MARITAL_STATUS'].replace({'S':'S-W-D','W':'S-W-D','D':'S-W-D'})\ntmp['MEMBER_MARITAL_STATUS'].value_counts()\n\nplot_analyze1_catcol('MEMBER_MARITAL_STATUS','CHURN', tmp)","d8199a5d":"tmp.groupby(['MEMBER_OCCUPATION_CD','MEMBER_MARITAL_STATUS','MEMBER_GENDER']).agg({\n   #'MEMBER_ANNUAL_INCOME':[lambda x: x.notnull().mean(),'mean','count'],\n    'ANNUAL_FEES':'mean',\n    'MEMBERSHIP_NUMBER':'count'\n})","d7506220":"num_cols","a961cbcd":"Id_col","eeafae29":"aggent_code_churn = tmp.groupby(['AGENT_CODE']).agg({\n    \"MEMBERSHIP_NUMBER\":\"count\",\n    \"CHURN\":'mean',\n    \"ANNUAL_FEES\":'mean',\n    \"MEMBER_ANNUAL_INCOME\":'mean',\n}).reset_index()","ff400f77":"x = pd.qcut(aggent_code_churn[\"MEMBER_ANNUAL_INCOME\"].to_list(),q = 6,duplicates='drop')\nx.categories = [1,2,3,4,5,6]\naggent_code_churn[\"Agent_income_rank\"] = x\naggent_code_churn.groupby([\"Agent_income_rank\"]).agg({\n   \"CHURN\":('size','mean'), \n})","30b718ff":"aggent_code_churn","fbac5b96":"tmp = df_processing(df)","fd18b409":"tmp","a6a84976":"tmp = tmp[tmp['END_DATE'].notnull()]","ddee677c":"age_at_end = (tmp['END_DATE'] - tmp['START_DATE']).dt.days.astype('int16')\/365 + tmp['MEMBER_AGE_AT_ISSUE']","277fe66c":"sns.distplot(age_at_end)","11fe05b8":"plot_cor(tmp)","c6dd68fb":"tmp2 = tmp.groupby('MEMBERSHIP_TERM_YEARS')['MEMBER_ANNUAL_INCOME'].mean()","c1ce6fb3":"histogram('MEMBERSHIP_TERM_YEARS')","67d2be60":"def mem_term_lab(df) :    \n    if df[\"MEMBERSHIP_TERM_YEARS\"] <= 12 :\n        return \"Term_0-12\"\n    elif (df[\"MEMBERSHIP_TERM_YEARS\"] > 12) & (df[\"MEMBERSHIP_TERM_YEARS\"] <= 24 ):\n        return \"Term_12-24\"\n    elif (df[\"MEMBERSHIP_TERM_YEARS\"] > 24) & (df[\"MEMBERSHIP_TERM_YEARS\"] <= 48) :\n        return \"Term_24-48\"\n    elif (df[\"MEMBERSHIP_TERM_YEARS\"] > 48) & (df[\"MEMBERSHIP_TERM_YEARS\"] <= 60) :\n        return \"Term_48-60\"\n    elif df[\"MEMBERSHIP_TERM_YEARS\"] > 60 :\n        return \"Term_gt_60\"","2e2a842a":"tmp = df.copy()\ntmp['MEMBERSHIP_TERM_YEARS'] = tmp.apply(lambda tmp:mem_term_lab(tmp), axis = 1)","06f1340a":"plot_analyze1_catcol('MEMBERSHIP_TERM_YEARS','CHURN',tmp)","12af7b99":"\"\"\"Plotting the continous features :    \n1. A box plot (or box-and-whisker plot) shows the distribution of quantitative data \nin a way that facilitates comparisons between variables.\n2. Distribution graph :to check the linearity of the variables and look \nfor skewness of features.\"\"\"\ndef plot_continous(cols, target, df):\n    # Using boxplot to analyze the continous feature\n    for col in cols:\n        plt.figure(figsize=(15,6))\n        plt.subplot(1, 2, 1)\n        if target == None:\n            fig = sns.boxplot(col, whis=1.5, data=df)\n            fig.legend()\n        else:\n            fig = sns.boxplot(x=target, y=col, whis=1.5, data=df)\n            fig.legend()\n        # which defined as the proportion of the IQR past the low and high quartiles to extend the plot whiskers \n        # or interquartile range (IQR)\n        # therefore, maximum = Q3 + 1.5*IQR , min = Q1 - 1.5*IQR\n        Q1 = df[col].quantile(0.25)\n        Q3 = df[col].quantile(0.75)\n        IQR = Q3 - Q1\n        print('Column name: %s' %col)    \n        print('> No.outliner between Q1 = {} and Q3 = {}: {} \\n' .format(Q1,Q3,((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()))\n\n        plt.subplot(1, 2, 2)\n        fig = sns.distplot(df[col].dropna())#.hist(bins=20)\n        fig.set_ylabel('Volumn')\n        fig.set_xlabel(col)    \n        plt.show() ","4b63d092":"'''\nQuantile\n'''\ndf['ANNUAL_FEES'] = df['ANNUAL_FEES'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(df['ANNUAL_FEES'].quantile([.01, .025, .1, .25, .5, .75, .9, .975, .99]))\n\n\nprint(pd.concat([df[df['CHURN'] == 1]['ANNUAL_FEES']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 df[df['CHURN'] == 0]['ANNUAL_FEES']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Churn', \"No Churn\"]))","266c0185":"df[df['ANNUAL_FEES'] >= 1000000 ]","1662e9ec":"#df[(df['ANNUAL_FEES'] >= df['MEMBER_ANNUAL_INCOME']) & (df['MEMBERSHIP_STATUS'] == 'CANCELLED') ]#['MEMBERSHIP_STATUS'].value_counts()#.count()\ndf[(df['ANNUAL_FEES'] >= df['MEMBER_ANNUAL_INCOME']) | (df['ANNUAL_FEES'] >= 2000000)]","1ca83125":"plot_continous(['ANNUAL_FEES'],'CHURN',df[(df['ANNUAL_FEES'] > 0)&(df['ANNUAL_FEES'] <= df['MEMBER_ANNUAL_INCOME'])])","4a027981":"df[df['ANNUAL_FEES'] > df['MEMBER_ANNUAL_INCOME']]","6a54e7c6":"#tmp = df[(df['ANNUAL_FEES'] > 0)&(df['ANNUAL_FEES'] < 2000000)]['ANNUAL_FEES']\ntmp2 = df[(df['ANNUAL_FEES'] > 0)&(df['ANNUAL_FEES'] < df['MEMBER_ANNUAL_INCOME'])&(df['ANNUAL_FEES'] < 1000000)]['ANNUAL_FEES']\nplt.figure(figsize=(16,12))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\nplt.subplot(221)\ng = sns.distplot(tmp2)\ng.set_title(\"ANNUAL_FEES Distribuition < 2000000\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=15)\n\nplt.subplot(222)\ng1 = sns.distplot(np.log(tmp2))\ng1.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Probability\", fontsize=15)\n\nplt.figure(figsize=(16,12))","e37a5bd2":"tmp = tmp[tmp['ANNUAL_FEES'] < 1000000]","dd4bbcdc":"df[df['PAYMENT_MODE'] != 'SINGLE-PREMIUM']","6752e559":"tmp = tmp[tmp['PAYMENT_MODE'] != 'SINGLE-PREMIUM']","5f6b9a5a":"tmp.shape","3c6d8bcb":"tmp2 = tmp[tmp['MEMBER_ANNUAL_INCOME'].notnull()]","175d77ef":"tmp2.groupby(['MEMBER_OCCUPATION_CD','MEMBER_MARITAL_STATUS','MEMBER_GENDER']).agg({\n    'MEMBER_ANNUAL_INCOME':[lambda x: x.notnull().mean(),'mean','median',lambda x:x.value_counts().index[0],'count'],\n    'ANNUAL_FEES':'mean',\n    'MEMBERSHIP_NUMBER':'count'\n})","c7134868":"tmp['MEMBER_ANNUAL_INCOME'] = tmp.groupby(['MEMBER_OCCUPATION_CD','MEMBER_MARITAL_STATUS','MEMBER_GENDER'])['MEMBER_ANNUAL_INCOME'].apply(lambda x: x.fillna(x.median()))","058286de":"plot_continous(['MEMBER_ANNUAL_INCOME'],'CHURN',tmp)","ce3a2a8d":"'''\nQuantile\n'''\n#df['ANNUAL_FEES'] = df['ANNUAL_FEES'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(df['MEMBER_ANNUAL_INCOME'].quantile([.01, .025, .1, .25, .5, .75, .9, .975, .99]))\n\n\nprint(pd.concat([df[df['CHURN'] == 1]['MEMBER_ANNUAL_INCOME']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 df[df['CHURN'] == 0]['MEMBER_ANNUAL_INCOME']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Churn', \"No Churn\"]))","421bab47":"plot_continous(['MEMBER_ANNUAL_INCOME'],'CHURN',df)","6049ce5a":"tmp = tmp[tmp['ANNUAL_FEES'] < tmp['MEMBER_ANNUAL_INCOME']]","e6d434ab":"tmp[tmp['MEMBER_ANNUAL_INCOME'] > 9000000]['CHURN'].value_counts()","a03e3996":"df[df['ANNUAL_FEES'] > 2000000]['CHURN'].value_counts()","1ad0a733":"df[df['ANNUAL_FEES'] >= df['MEMBER_ANNUAL_INCOME']]['CHURN'].value_counts()","3a72c494":"df = pd.read_excel(open('..\/input\/club-data-set\/Assignment.xlsx', 'rb'),\n...               sheet_name='Data')\n\ndf.START_DATE = pd.to_datetime(df.START_DATE, format = '%Y%m%d', errors='coerce')\ndf.END_DATE = pd.to_datetime(df.END_DATE, format = '%Y%m%d', errors='coerce')\ndf[\"CHURN\"] = df[\"MEMBERSHIP_STATUS\"].replace({\"CANCELLED\":1,\"INFORCE\":0})\ndf.drop(columns=[\"MEMBERSHIP_STATUS\"], inplace=True)","651f4ca5":"# manipuation MEMBERSHIP_TERM_YEARS\ndef mem_term_lab(df) :    \n    if df[\"MEMBERSHIP_TERM_YEARS\"] <= 12 :\n        return \"Term_0-12\"\n    elif (df[\"MEMBERSHIP_TERM_YEARS\"] > 12) & (df[\"MEMBERSHIP_TERM_YEARS\"] <= 24 ):\n        return \"Term_12-24\"\n    elif (df[\"MEMBERSHIP_TERM_YEARS\"] > 24) & (df[\"MEMBERSHIP_TERM_YEARS\"] <= 48) :\n        return \"Term_24-48\"\n    elif (df[\"MEMBERSHIP_TERM_YEARS\"] > 48) & (df[\"MEMBERSHIP_TERM_YEARS\"] <= 60) :\n        return \"Term_48-60\"\n    elif df[\"MEMBERSHIP_TERM_YEARS\"] > 60 :\n        return \"Term_gt_60\"","947076fa":"def df_processing(df):\n    df = df[df['MEMBER_GENDER'].notnull()]\n    df['MEMBER_OCCUPATION_CD'] = df['MEMBER_OCCUPATION_CD'].fillna(7)\n    df['MEMBER_OCCUPATION_CD'] = df['MEMBER_OCCUPATION_CD'].replace({4:3,5:3,7:3,6:4})\n    df['MEMBER_MARITAL_STATUS'] = df['MEMBER_MARITAL_STATUS'].fillna('UNK')\n    df['MEMBER_MARITAL_STATUS'] = df['MEMBER_MARITAL_STATUS'].replace({'S':'S-W-D','W':'S-W-D','D':'S-W-D'})\n\n    df = df[df['PAYMENT_MODE'] != 'SINGLE-PREMIUM']\n\n    df = df[df['ANNUAL_FEES'] > 0]\n    df = df[df['ANNUAL_FEES'] < df['MEMBER_ANNUAL_INCOME']]\n    df = df[df['ANNUAL_FEES'] < 1000000]\n    df['MEMBER_ANNUAL_INCOME'] = df.groupby(['MEMBER_OCCUPATION_CD','MEMBER_MARITAL_STATUS','MEMBER_GENDER'])['MEMBER_ANNUAL_INCOME'].apply(lambda x: x.fillna(x.median()))\n    df = df[df['MEMBER_ANNUAL_INCOME'] < 9000000]\n    \n    # special kids\n    df = df[df[\"MEMBER_AGE_AT_ISSUE\"] > 12]\n    \n    df[\"PAYMENT_MODE_NUM\"] = df[\"PAYMENT_MODE\"].replace({'ANNUAL':1,'SEMI-ANNUAL':1\/2,\n                                                        'QUARTERLY':1\/4,'MONTHLY':1\/12\n                                                        })\n    \n    df['MEMBERSHIP_TERM_YEARS_BIN'] = df.apply(lambda df:mem_term_lab(df), axis = 1)\n    # age group\n    x = pd.qcut(df[\"MEMBER_AGE_AT_ISSUE\"].to_list(),q = 8)\n    x.categories = [\"age_g1\",\"age_g2\",\"age_g3\",\"age_g4\",\"age_g5\",\"age_g6\",\"age_g7\",\"age_g8\"]\n    df[\"AGE_GROUP\"] = x.to_list()\n    \n    # manipuation agent\n    aggent_code_churn = df.groupby(['AGENT_CODE']).agg({\n        \"ANNUAL_FEES\":'mean',\n        \"MEMBER_ANNUAL_INCOME\":'mean',\n    }).reset_index()\n    x = pd.qcut(aggent_code_churn[\"ANNUAL_FEES\"].to_list(),q = 6,duplicates='drop')\n    x.categories = [1,2,3,4,5]\n    aggent_code_churn[\"AGENT_RANK_FEES\"] = x.to_list()\n    x = pd.qcut(aggent_code_churn[\"MEMBER_ANNUAL_INCOME\"].to_list(),q = 6,duplicates='drop')\n    x.categories = [1,2,3,4,5,6]\n    aggent_code_churn[\"AGENT_RANK_INCOMES\"] = x.to_list()\n    aggent_code_churn.drop(columns= [\"ANNUAL_FEES\",\"MEMBER_ANNUAL_INCOME\"], inplace=True)\n\n    df = pd.merge(df,aggent_code_churn, on = \"AGENT_CODE\")\n    \n    return df\ndf = df_processing(df)","31180ff7":"plot_continous(['ANNUAL_FEES'],'CHURN',df)\n#df[(df['ANNUAL_FEES'] < 1000000)&(df['MEMBER_ANNUAL_INCOME'] < 9000000)]","82756d69":"plot_continous(['MEMBER_ANNUAL_INCOME'],'CHURN',df)","5532af42":"print (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures :\\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :\\n\", df.isnull().sum())\nprint (\"\\nUnique values :\\n\",df.nunique())","925526f5":"def df_fe(df):\n    # START_DATE\n    df[\"START_YEAR\"] = df[\"START_DATE\"].dt.year\n    df[\"START_YEAR\"] = df[\"START_DATE\"].dt.month\n\n    # LOG\n    df[\"LOG_INCOMES\"] = np.log(df[\"ANNUAL_FEES\"])\n    df[\"LOG_FEES\"] = np.log(df[\"MEMBER_ANNUAL_INCOME\"])\n\n    # Ratio\n    df[\"RATIO_FEE_INCOME\"] = df[\"ANNUAL_FEES\"]\/df[\"MEMBER_ANNUAL_INCOME\"]\n    df[\"PER_FEE_INCOME\"] = 1- df[\"ANNUAL_FEES\"]\/df[\"MEMBER_ANNUAL_INCOME\"]\n    df[\"RATIO_FEE_TERMS\"] = df[\"ANNUAL_FEES\"]\/df[\"MEMBERSHIP_TERM_YEARS\"]\n    df[\"RATIO_INCOME_TERMS\"] = df[\"MEMBER_ANNUAL_INCOME\"]\/df[\"MEMBERSHIP_TERM_YEARS\"]\n    \n    # Payment\n    df[\"MONTHLY_FEES\"] = df[\"ANNUAL_FEES\"]*df[\"PAYMENT_MODE_NUM\"]\n    df[\"MONTHLY_INCOME\"] = df[\"MEMBER_ANNUAL_INCOME\"]*df[\"PAYMENT_MODE_NUM\"]\n    return df\n\ndf = df_fe(df)\n","990cbccc":"sns.distplot(df[\"ANNUAL_FEES\"]*df[\"PAYMENT_MODE_NUM\"])","4793976a":"#Separating churn and non churn customers\nchurn     = df[df[\"CHURN\"] == 1]\nnot_churn = df[df[\"CHURN\"] == 0]\n\n#Separating catagorical and numerical columns\nId_col     = [\"MEMBERSHIP_NUMBER\"]\ntarget_col = [\"CHURN\"]\ncat_cols   = df.nunique()[df.nunique() < 10].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col+['PAYMENT_MODE_NUM','ADDITIONAL_MEMBERS','AGENT_RANK_FEES','AGENT_RANK_INCOMES']]\nnum_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\nprint(\"categorical cols: {}\\nnumerical cols: {} \".format(cat_cols,num_cols))","3bfecfb2":"sns.distplot(df[\"PER_FEE_INCOME\"])","087b892a":"plot_cor(df)","85399552":"##copy data\n#tmp = df.copy()\n#Drop tenure column\n#tmp = tmp.drop(columns = \"MEMBERSHIP_TERM_YEARS_BIN\",axis = 1)\n\ntrace1 = go.Scatter3d(x = churn[\"MEMBER_ANNUAL_INCOME\"],\n                      y = churn[\"ANNUAL_FEES\"],\n                      z = churn[\"MEMBERSHIP_TERM_YEARS\"],\n                      mode = \"markers\",\n                      name = \"Churn customers\",\n                      text = \"Id : \" + churn[\"MEMBERSHIP_NUMBER\"],\n                      marker = dict(size = 1,color = \"red\")\n                     )\ntrace2 = go.Scatter3d(x = not_churn[\"MEMBER_ANNUAL_INCOME\"],\n                      y = not_churn[\"ANNUAL_FEES\"],\n                      z = not_churn[\"MEMBERSHIP_TERM_YEARS\"],\n                      name = \"Non churn customers\",\n                      text = \"Id : \" + not_churn[\"MEMBERSHIP_NUMBER\"],\n                      mode = \"markers\",\n                      marker = dict(size = 1,color= \"green\")\n                     )\n\n\n\nlayout = go.Layout(dict(title = \"Monthly charges,total charges & tenure in customer attrition\",\n                        scene = dict(camera = dict(up=dict(x= 0 , y=0, z=0),\n                                                   center=dict(x=0, y=0, z=0),\n                                                   eye=dict(x=1.25, y=1.25, z=1.25)),\n                                     xaxis  = dict(title = \"annual incomes\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'),\n                                     yaxis  = dict(title = \"annual fees\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  ),\n                                     zaxis  = dict(title = \"term years\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  )\n                                    ),\n                        height = 700,\n                       )\n                  )\n                  \n\ndata = [trace1,trace2]\nfig  = go.Figure(data = data,layout = layout)\npy.iplot(fig)","aec123ba":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n\nencoded_features = []\nfor feature in cat_cols:\n    print(\"Feature  name\",feature)\n    encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n    n = df[feature].nunique()\n    cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n    encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n    encoded_df.index = df.index\n    encoded_features.append(encoded_df)\n\ntmp = pd.concat([df, *encoded_features], axis=1)","3f098018":"drop_cols =  ['AGENT_CODE','START_DATE','END_DATE'] #+target_col + Id_col \n# cat_drops =  [x for x in cat_cols if x not in []]\ntmp.drop(columns= cat_cols + drop_cols, inplace=True)\n\ntmp.head()","62a3d3e3":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 2)\n\nX = tmp[[i for i in tmp.columns if i not in Id_col + target_col]]\nY = tmp[target_col + Id_col]\n\nprincipal_components = pca.fit_transform(X)\npca_data = pd.DataFrame(principal_components,columns = [\"PC1\",\"PC2\"])\npca_data = pca_data.merge(Y,left_index=True,right_index=True,how=\"left\")\npca_data[\"CHURN\"] = pca_data[\"CHURN\"].replace({1:\"CANCELLED\",0:\"INFORCE\"})\n\ndef pca_scatter(target,color) :\n    tracer = go.Scatter(x = pca_data[pca_data[\"CHURN\"] == target][\"PC1\"] ,\n                        y = pca_data[pca_data[\"CHURN\"] == target][\"PC2\"],\n                        name = target,mode = \"markers\",\n                        marker = dict(color = color,\n                                      line = dict(width = .5),\n                                      symbol =  \"diamond-open\"),\n                        text = (\"Customer Id : \" + \n                                pca_data[pca_data[\"CHURN\"] == target]['MEMBERSHIP_NUMBER'])\n                       )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Visualising data with principal components\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"principal component 1\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"principal component 2\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        height = 600\n                       )\n                  )\ntrace1 = pca_scatter(\"CANCELLED\",'red')\ntrace2 = pca_scatter(\"INFORCE\",'royalblue')\ndata = [trace2,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","9f293f6a":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n#select columns\ncols = [i for i in tmp.columns if i not in Id_col + target_col ]\n\n#dataframe with non negative values\ndf_x = tmp[cols]\ndf_y = tmp[target_col]\n\n#fit model with k= 3\nselect = SelectKBest(score_func = chi2,k = 3)\nfit    = select.fit(df_x,df_y)\n\n#Summerize scores\nprint (\"scores\")\nprint (fit.scores_)\nprint (\"P - Values\")\nprint (fit.pvalues_)\n\n#create dataframe\nscore = pd.DataFrame({\"features\":cols,\"scores\":fit.scores_,\"p_values\":fit.pvalues_ })\nscore = score.sort_values(by = \"scores\" ,ascending =False)\n\n\n#createing new label for categorical and numerical columns\nscore[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols),\"Numerical\",\"Categorical\")\n\n#plot\ntrace  = go.Scatter(x = score[score[\"feature_type\"] == \"Categorical\"][\"features\"],\n                    y = score[score[\"feature_type\"] == \"Categorical\"][\"scores\"],\n                    name = \"Categorial\",mode = \"lines+markers\",\n                    marker = dict(color = \"red\",\n                                  line = dict(width =1))\n                   )\n\ntrace1 = go.Bar(x = score[score[\"feature_type\"] == \"Numerical\"][\"features\"],\n                y = score[score[\"feature_type\"] == \"Numerical\"][\"scores\"],name = \"Numerical\",\n                marker = dict(color = \"royalblue\",\n                              line = dict(width =1)),\n                xaxis = \"x2\",yaxis = \"y2\"\n               )\nlayout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     tickfont = dict(size =10),\n                                     domain=[0, 0.7],\n                                     tickangle = 90,zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"scores\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(b=200),\n                        xaxis2=dict(domain=[0.8, 1],tickangle = 90,\n                                    gridcolor = 'rgb(255, 255, 255)'),\n                        yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                        )\n                  )\n\ndata=[trace,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","49f41c13":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\nfrom yellowbrick.classifier import DiscriminationThreshold\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 42","a22ea54f":"#Scaling Numerical columns\nstd = StandardScaler()\nscale_cols = [i for i in num_cols if i not in drop_cols]\nscaled = std.fit_transform(df[scale_cols])\nscaled = pd.DataFrame(scaled,columns=scale_cols)\nprint(\"scaled cos: \", scale_cols)\n#dropping original values merging scaled values for numerical columns\n#tmp = df.copy()\ntmp = tmp.drop(columns = scale_cols,axis = 1)\ntmp = tmp.reset_index(drop=True)\ntmp = tmp.merge(scaled,left_index=True,right_index=True,how = \"left\")\n\n\n#splitting train and test data \ntrain,test = train_test_split(tmp,test_size = .2 ,random_state = 111)\n\ncols    = [i for i in tmp.columns if i not in Id_col + target_col]\nX_train = train[cols]\ny_train = train[\"CHURN\"]\nX_test = test[cols]\ny_test  = test[\"CHURN\"]\n\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\nprint('y_test shape: {}'.format(y_test.shape))","6f281bb7":"plot_cor(tmp)","4da0131c":"#Function attributes\n#dataframe     - processed dataframe\n#Algorithm     - Algorithm used \n#training_x    - predictor variables dataframe(training)\n#testing_x     - predictor variables dataframe(testing)\n#training_y    - target variable(training)\n#training_y    - target variable(testing)\n#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n                                 #regression,features for tree based models)\n\n#threshold_plot - if True returns threshold plot for model\n    \ndef club_churn_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    #coeffs\n    if   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n    \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix ,\n                        x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Picnic\",\n                        name = \"matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot coeffs\n    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Picnic\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                            subplot_titles=('Confusion Matrix',\n                                            'Receiver operating characteristic',\n                                            'Feature Importances'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()  ","53632887":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG,display\n\n#top 3 categorical features\nfeatures_cat  = score[score[\"feature_type\"] == \"Categorical\"][\"features\"][:3].tolist()\n\n#top 3 numerical features\nfeatures_num  = score[score[\"feature_type\"] == \"Numerical\"][\"features\"][:3].tolist()\n\n\n#Function attributes\n#columns        - selected columns\n#maximum_depth  - depth of tree\n#criterion_type - [\"gini\" or \"entropy\"]\n#split_type     - [\"best\" or \"random\"]\n#Model Performance - True (gives model output)\n\ndef plot_decision_tree(columns,maximum_depth,criterion_type,\n                       split_type,model_performance = None) :\n    \n    #separating dependent and in dependent variables\n    dtc_x = df_x[columns]\n    dtc_y = df_y[target_col]\n    \n    #model\n    dt_classifier = DecisionTreeClassifier(max_depth = maximum_depth,\n                                           splitter  = split_type,\n                                           criterion = criterion_type,\n                                          )\n    dt_classifier.fit(dtc_x,dtc_y)\n    \n    #plot decision tree\n    graph = Source(tree.export_graphviz(dt_classifier,out_file=None,\n                                        rounded=True,proportion = False,\n                                        feature_names = columns, \n                                        precision  = 2,\n                                        class_names=[\"Not churn\",\"Churn\"],\n                                        filled = True                         \n                                       )\n                  )\n    \n    #model performance\n    if model_performance == True :\n        club_churn_prediction(dt_classifier,\n                                 dtc_x,X_test[columns],\n                                 dtc_y,y_test,\n                                 columns,\"features\",threshold_plot = True)\n    display(graph)\n    \nplot_decision_tree(features_num,3,\"gini\",\"best\")","1dd09392":"plot_decision_tree(features_cat,3,\"entropy\",\"best\",\n                   model_performance = True ,)","e995c6b0":"cols    = [i for i in tmp.columns if i not in Id_col + target_col]\nX_train = train[cols].values\ny_train = train[\"CHURN\"].values\nX_test = test[cols].values\ny_test  = test[\"CHURN\"].values\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\nprint('y_test shape: {}'.format(y_test.shape))","b33b9313":"single_best_model = RandomForestClassifier(criterion='gini', \n                                           n_estimators=1100,\n                                           max_depth=5,\n                                           min_samples_split=4,\n                                           min_samples_leaf=5,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=SEED,\n                                           n_jobs=-1,\n                                           verbose=1)\nN = 5\noob = 0\nprobs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\nimportances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=cols)\nfprs, tprs, scores = [], [], []\n\nskf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n    print('Fold {}\\n'.format(fold))\n    \n    # Fitting the model\n    #leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])\n    model = single_best_model\n    model.fit(X_train[trn_idx], y_train[trn_idx])\n    \n    # Computing Train AUC score\n    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], model.predict_proba(X_train[trn_idx])[:, 1])\n    trn_auc_score = auc(trn_fpr, trn_tpr)\n    # Computing Validation AUC score\n    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], model.predict_proba(X_train[val_idx])[:, 1])\n    val_auc_score = auc(val_fpr, val_tpr)  \n    print(\"Train AUC score {}, Validation AUC score {}\".format(trn_auc_score, val_auc_score))  \n    scores.append((trn_auc_score, val_auc_score))\n    fprs.append(val_fpr)\n    tprs.append(val_tpr)\n    \n    # X_test probabilities\n    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = model.predict_proba(X_test)[:, 0]\n    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = model.predict_proba(X_test)[:, 1]\n    importances.iloc[:, fold - 1] = model.feature_importances_\n        \n    oob += model.oob_score_ \/ N\n    print('Fold {} OOB Score: {}\\n'.format(fold, model.oob_score_))   \n    \nprint('Average OOB Score: {}'.format(oob))","37758c8f":"scores","518d13fa":"pred_prob = model.predict_proba(X_test)\n\npred = pd.DataFrame()\npred['0'] = pred_prob[:,0]\npred['1'] = pred_prob[:,1]\npred['pred'] = 0\npos = pred[pred['1'] >= 0.5].index\npred.loc[pos, 'pred'] = 1\n\ny_pred = pred['pred'].astype(int)\n\nprint(\"AUC \",roc_auc_score(y_test, y_pred))\nconf_mat = confusion_matrix(y_test, y_pred)\nprint(conf_mat)\n\nsns.heatmap(conf_mat)\nplt.show()\n\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","c805740d":"importances['Mean_Importance'] = importances.mean(axis=1)\nimportances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\n\nplt.figure(figsize=(15, 20))\nsns.barplot(x='Mean_Importance', y=importances.index, data=importances)\n\nplt.xlabel('')\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\nplt.title('Random Forest Classifier Mean Feature Importance Between Folds', size=15)\nplt.tick_params(axis='x', colors='black')\nplt.tick_params(axis='y', colors='black')\nplt.show()\n\n\ndef plot_roc_curve(fprs, tprs):\n    \n    tprs_interp = []\n    aucs = []\n    mean_fpr = np.linspace(0, 1, 100)\n    f, ax = plt.subplots(figsize=(15, 15))\n    \n    # Plotting ROC for each fold and computing AUC scores\n    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n        tprs_interp[-1][0] = 0.0\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc)\n        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n        \n    # Plotting ROC for random guessing\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n    \n    mean_tpr = np.mean(tprs_interp, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_auc = auc(mean_fpr, mean_tpr)\n    std_auc = np.std(aucs)\n    \n    # Plotting the mean ROC\n    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n    \n    # Plotting the standard deviation around the mean ROC Curve\n    std_tpr = np.std(tprs_interp, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n    \n    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n    ax.tick_params(axis='x', labelsize=15)\n    ax.tick_params(axis='y', labelsize=15)\n    ax.set_xlim([-0.05, 1.05])\n    ax.set_ylim([-0.05, 1.05])\n\n    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n    ax.legend(loc='lower right', prop={'size': 13})\n    plt.rcParams['text.color'] = 'black'\n    ax.tick_params(axis='x', colors='black')\n    ax.tick_params(axis='y', colors='black')\n    plt.show()\n\nplot_roc_curve(fprs, tprs)","f1933de8":"#splitting train and test data \ntrain,test = train_test_split(tmp,test_size = .2 ,random_state = 111)\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\n\ncols    = [i for i in tmp.columns if i not in Id_col + target_col]\nX_train = train[cols]\ny_train = train[\"CHURN\"]\nX_test = test[cols]\ny_test  = test[\"CHURN\"]\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\nprint('y_test shape: {}'.format(y_test.shape))","1824d0e5":"logit  = LogisticRegression(\n    C=0.01,  # Inverse of regularization strength\n    class_weight=None, \n    dual=False, \n    fit_intercept=True,\n    intercept_scaling=1, \n    max_iter=100, \n    multi_class='ovr', \n    n_jobs=1,\n    penalty='l2', \n    random_state=None, \n    solver='liblinear', \n    tol=0.0001,\n    verbose=0, \n    warm_start=False)","cf14ac66":"club_churn_prediction(logit,X_train,X_test,y_train,y_test,\n                         cols,\"coefficients\",threshold_plot = True)","2e495da6":"# Grid search cross validation\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\ngrid={\n    \"C\":np.logspace(-3,3,7), \n    \"penalty\":[\"l1\",\"l2\"]# l1 lasso l2 ridge,\n    \n}\nlogreg=LogisticRegression()\nlogreg_cv=GridSearchCV(logreg,grid,cv=10)\nlogreg_cv.fit(X_train,y_train)\n\nprint(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\nprint(\"accuracy :\",logreg_cv.best_score_)","149c04cf":"kf = StratifiedKFold(n_splits=4,shuffle=True,random_state=SEED)\npred_test_full =0\ncv_score =[]\ni=1\nfor train_index,test_index in kf.split(X_train,y_train):\n    print('{} of KFold {}'.format(i,kf.n_splits))\n    xtr,xvl = X_train.loc[train_index],X_train.loc[test_index]\n    ytr,yvl = y_train.loc[train_index],y_train.loc[test_index]\n    \n    #model\n    lr = logit\n    lr.fit(xtr,ytr)\n    score = roc_auc_score(yvl,lr.predict(xvl))    \n    print('ROC AUC score:',score)\n    print(\"accuracy :\",accuracy_score(yvl,lr.predict(xvl)))\n    cv_score.append(score)    \n    pred_test = lr.predict_proba(X_test)[:,1]\n    pred_test_full +=pred_test\n    i+=1","516ca6d4":"print('Confusion matrix\\n',confusion_matrix(yvl,lr.predict(xvl)))\nprint('Cv',cv_score,'\\nMean cv Score',np.mean(cv_score))","ee412fe4":"from imblearn.over_sampling import SMOTE\n\ncols    = [i for i in tmp.columns if i not in Id_col+target_col]\n\nsmote_X = tmp[cols]\nsmote_Y = tmp[target_col]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = 0.2 ,\n                                                                         random_state = 111)\n\n#oversampling minority class using smote\nos = SMOTE(random_state = 10)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)\n###\n","dc5b778f":"logit_smote  = LogisticRegression(\n    C=1,  # Inverse of regularization strength\n    class_weight=None, \n    dual=False, \n    fit_intercept=True,\n    intercept_scaling=1, \n    max_iter=100, \n    multi_class='ovr', \n    n_jobs=1,\n    penalty='l2', \n    random_state=None, \n    solver='liblinear', \n    tol=0.0001,\n    verbose=0, \n    warm_start=False)","50e5fdba":"club_churn_prediction(logit_smote,os_smote_X,X_test,os_smote_Y,y_test,\n                         cols,\"coefficients\",threshold_plot = True)","13181ea9":"def club_churn_prediction_alg(algorithm,training_x,testing_x,\n                                 training_y,testing_y,threshold_plot = True) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy Score   : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc)\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n     \n    #plot roc curve\n    trace1 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2),\n                       )\n    trace2 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot confusion matrix\n    trace3 = go.Heatmap(z = conf_matrix ,x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Blues\",name = \"matrix\",\n                        xaxis = \"x2\",yaxis = \"y2\"\n                       )\n    \n    layout = go.Layout(dict(title=\"Model performance\" ,\n                            autosize = False,height = 500,width = 800,\n                            showlegend = False,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(title = \"false positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         domain=[0, 0.6],\n                                         ticklen=5,gridwidth=2),\n                            yaxis = dict(title = \"true positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         zerolinewidth=1,\n                                         ticklen=5,gridwidth=2),\n                            margin = dict(b=200),\n                            xaxis2=dict(domain=[0.7, 1],tickangle = 90,\n                                        gridcolor = 'rgb(255, 255, 255)'),\n                            yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                           )\n                  )\n    data = [trace1,trace2,trace3]\n    fig = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()\n","5e69cc19":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\n\n\nclub_churn_prediction_alg(knn,os_smote_X,X_test,\n                             os_smote_Y,y_test,threshold_plot = True)","ab1dc92e":"knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\n\n\nclub_churn_prediction_alg(knn,X_train,X_test,\n                             y_train,y_test,threshold_plot = True)","0134d11a":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB(priors=None)\n\nclub_churn_prediction_alg(gnb,os_smote_X,X_test,os_smote_Y,y_test)\n\n","e02b385a":"club_churn_prediction_alg(gnb,X_train,X_test,y_train,y_test)","bcc60168":"from sklearn.svm import SVC\n\n#Support vector classifier\n#using linear hyper plane\nsvc_lin  = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n               max_iter=-1, probability=True, random_state=None, shrinking=True,\n               tol=0.001, verbose=False)\n\ncols = [i for i in tmp.columns if i not in Id_col + target_col]\nclub_churn_prediction(svc_lin,X_train,X_test,y_train,y_test,\n                         cols,\"coefficients\",threshold_plot = False)","f7c6700c":"#tuning parameters\n#Support vector classifier\n#using non-linear hyper plane(\"rbf\")\n\nsvc_rbf  = SVC(C=1.0, kernel='rbf', \n               degree= 3, gamma=1.0, \n               coef0=0.0, shrinking=True,\n               probability=True,tol=0.001,\n               cache_size=200, class_weight=None,\n               verbose=False,max_iter= -1,\n               random_state=None)\n\nclub_churn_prediction_alg(svc_rbf,os_smote_X,X_test,os_smote_Y,y_test,threshold_plot = False)","ccf05ad3":"def club_churn_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    l = algorithm.predict(training_x)\n    print(\"train auc:\",roc_auc_score(training_y,l) )\n    \n    #coeffs\n    if   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Test Accuracy Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n    \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix ,\n                        x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Picnic\",\n                        name = \"matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot coeffs\n    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Picnic\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                            subplot_titles=('Confusion Matrix',\n                                            'Receiver operating characteristic',\n                                            'Feature Importances'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof() ","7abd81b6":"#splitting train and test data \ntrain,test = train_test_split(tmp,test_size = .2 ,random_state = 111)\n\ncols    = [i for i in tmp.columns if i not in Id_col + target_col]\nX_train = train[cols]\ny_train = train[\"CHURN\"]\nX_test = test[cols]\ny_test  = test[\"CHURN\"]\n\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\nprint('y_test shape: {}'.format(y_test.shape))","92e04672":"from lightgbm import LGBMClassifier\n\nlgbm_c = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=7, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\n\ncols = [i for i in tmp.columns if i not in Id_col + target_col]\nclub_churn_prediction(lgbm_c,X_train,X_test,y_train,y_test,\n                         cols,\"features\",threshold_plot = True)","6eec1080":"params = {\n    \"boosting_type\": \"gbdt\",    \n    'objective': 'binary',\n    \"metric\": 'auc',\n    #'is_unbalance': True, \n    \n    'colsample_bytree':1.0,\n    \n    'learning_rate': 0.01, \n    'num_leaves': 500,    \n    #\"verbosity\": -1, #default= 1, controls the level of LightGBM\u2019s verbosity    \n\n    'max_depth': 10,\n    'num_leaves': 100, # max number of leaves in one tree\n    'min_child_weight': 0.01, #default = 1e-3= 0.001,minimal sum hessian in one leaf.\n    'min_child_samples':20,\n    'min_data_in_leaf': 100, #default = 20, minimal number of data in one leaf.\n    'min_split_gain':0.0,\n    \n    'subsample':1.0,\n    'subsample_for_bin':200000,  # default, number of data that sampled to construct histogram bins\n    'subsample_freq':0,\n    \n    'reg_alpha': 0.0,\n    'reg_lambda': 0.0,    \n    \n    # LightGBM can subsample the data for training (improves speed):    \n    'feature_fraction': 0.5, # randomly select a fraction of the features.\n    'bagging_fraction': 0.5, # randomly bag or subsample training data. \n    #\"bagging_seed\": 11, default = 3 random seed for bagging \n\n    'random_state': 100,    \n    'nthread': 4, # best set to number of actual cores.    \n}","920df6ec":"from sklearn.model_selection import KFold\nimport lightgbm as lgb","f1331001":"%%time\n\nNFOLDS = 5\nfolds = KFold(n_splits=NFOLDS)\nX = X_train.copy()\ny = y_train.copy()\n\ncolumns = X.columns\nsplits = folds.split(X, y)\ny_preds = np.zeros(X_test.shape[0])\ny_oof = np.zeros(X.shape[0])\nscore = 0\n\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = columns\n  \nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    dtrain = lgb.Dataset(X_train, label=y_train)\n    dvalid = lgb.Dataset(X_valid, label=y_valid)\n\n    clf = lgb.train(params, dtrain, 2000, valid_sets = [dtrain, dvalid], \n                    verbose_eval=200, early_stopping_rounds=500)\n    \n    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(X_valid)\n    y_oof[valid_index] = y_pred_valid\n    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n    \n    score += roc_auc_score(y_valid, y_pred_valid) \/ NFOLDS\n    y_preds += clf.predict(X_test) \/ NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    # gc.collect()\n    \nprint(f\"\\nMean AUC = {score}\")\nprint(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")","985c87e9":"y_pred = np.where(y_preds>=0.5,1,0)\n\nprint(\"AUC \",roc_auc_score(y_test, y_pred))\nconf_mat = confusion_matrix(y_test, y_pred)\nprint(conf_mat)\n\nsns.heatmap(conf_mat)\nplt.show()\nprint (\"\\n Classification report : \\n\",classification_report(y_test,y_pred))\nprint (\"Accuracy Score   : \",accuracy_score(y_test,y_pred))\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","2a267757":"\n\nfeature_importances['average'] = feature_importances[[f'fold_{fold_n + 1}' for fold_n in range(folds.n_splits)]].mean(axis=1)\nfeature_importances.to_csv('feature_importances.csv')\n\nplt.figure(figsize=(16, 16))\nsns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(50), x='average', y='feature');\nplt.title('50 TOP feature importance over {} folds average'.format(folds.n_splits));\n\n","932556f1":"#splitting train and test data \ntrain,test = train_test_split(tmp,test_size = .2 ,random_state = 111)\n\ncols    = [i for i in tmp.columns if i not in Id_col + target_col]\nX_train = train[cols]\ny_train = train[\"CHURN\"]\nX_test = test[cols]\ny_test  = test[\"CHURN\"]\n\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\nprint('y_test shape: {}'.format(y_test.shape))","a379d51c":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\n\nclub_churn_prediction(xgc,X_train,X_test,y_train,y_test,\n                         cols,\"features\",threshold_plot = True)","75e7a298":"## Target","b8eb8ff0":"## PAYMENT_MODE","d133a60a":"## Gender\n- tat ca mem_gender = nan deu co income = nan\n- remove all mem_gender = nan","882e4d9a":"## kfold RF","e251d26e":"# Gaussian Naive Bayes.","26cfcd89":"# Import lib","db5973a4":"# Random forest model","d43d3e2b":"# SVC","bfff6bdb":"## MEMBER_MARITAL_STATUS","e149bb6c":"# Baseline model","ef80e073":"Instructions:\nPlease use Python to solve this problem and revert with a document which includes the following details:\n1. Solution approach and rationale\n- Firstly, exploring and analyzing the data will give me the basic ideas about the data, I will know about the distribution of the target, as well as the propotion of other features with target\n- After that, I have to deal with the missing values and think about some techniques to treat the outliers, anormally. \n- Then I move to the data processing process where I manipulate and group the data to get the better distribution, as well as finding some domain knowledge and using my data institution to generate and engineer new features\n- Finally, I take the advantages of several ML models to classify the target\n    - Baseline model: logistic regression\n    - Clustering: Support vector classifier, \n    - Treebased model: Random Forest, XGBoost, LightGBM\n2. Details of:\n    - [Data pre-processing](#Data_Processing): In this step, I do many transformations in the data, especially in ANNUAL_FEES, and MEMBER_ANNUAL_INCOMES. The further details are noted in the code.\n    - The created model: I try my best with several ML models. I use kfold CV to make models get the better results. \n        - For data prepairation before fiiting models, I use Onehot-encoding for several categorical features, and use StandardScaler for some needed numerical features. \n        - The train set and test set are splitted randomly in the ratio = 0.2    \n    - Training and test results\n        - My highest result belongs in LighGBM model, with \n3. Relevant Python code\n4. Anything else that you feel can help us appreciate your solution better.","d4e00d79":"## Annual fee","a1875a40":"#  Synthetic Minority Oversampling TEchnique (SMOTE)\n\n    Randomly pick a point from the minority class.\n    Compute the k-nearest neighbors (for some pre-specified k) for this point.\n    Add k new points somewhere between the chosen point and each of its neighbors\n","07e92468":"# LightGBM","bfc2cb10":"## Plot function","1fc755b3":"## MEMBER_ANNUAL_INCOME","a019b4b9":"# EDA","0ead5f11":"## Occupation CD","107f416b":"# Data Processing","03e765ce":"# XGBoost","53dcd85e":"# KNN Classifier","103c7afa":"## AGENT_CODE","b9c494a1":"### Feature Engineering","11631a83":"### Preparing fit model","b24b302c":"# Time","acd40ec4":"## MEMBERSHIP_TERM_YEARS","c474fed8":"# Modelling"}}