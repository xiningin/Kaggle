{"cell_type":{"72b98b41":"code","4e59b8d4":"code","d5e505fd":"code","a2dbf858":"code","a3f890c4":"code","7f8b05f8":"code","7b62e223":"code","534ed6d4":"code","57068ce1":"code","f35c799a":"code","8d5f2fbb":"code","edd8e413":"code","e399e9f0":"code","31dbe30e":"code","7cbd67df":"code","3ba409b4":"code","30c88437":"code","31f7722a":"code","9abe378c":"code","3ae8e332":"code","522e79e8":"code","4b788a48":"code","8c39a572":"code","eb1be81c":"code","d1238fb7":"code","74d0e797":"code","224de6d8":"markdown","295e468c":"markdown"},"source":{"72b98b41":"!pip install -U tensorflow==2.0.0-alpha0","4e59b8d4":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\ntf.random.set_seed(123)","d5e505fd":"tf.__version__","a2dbf858":"train = pd.read_csv(\"..\/input\/train.csv\")","a3f890c4":"train.head()","7f8b05f8":"train.columns","7b62e223":"train.info()","534ed6d4":"train.describe()","57068ce1":"train.Age[train.Age.isnull()] = train.Age.mean","f35c799a":"train.Embarked.fillna(\"unknown\", inplace=True)","8d5f2fbb":"train.head()","edd8e413":"train.info()","e399e9f0":"dftrain, dfeval = train_test_split(train, test_size=0.2, random_state=42)","31dbe30e":"y_train = dftrain.Survived\ndftrain.drop(columns=[\"Survived\", \"Cabin\", \"Ticket\", 'Age', 'Fare'], inplace=True)\ny_eval = dfeval.Survived\ndfeval.drop(columns=[\"Survived\", \"Cabin\", \"Ticket\", 'Age', 'Fare'], inplace=True)","7cbd67df":"dftrain.head()","3ba409b4":"dftrain.info()","30c88437":"fc = tf.feature_column\nCATEGORICAL_COLUMNS = ['Sex', 'Parch', 'Pclass', 'SibSp', \"Embarked\"]\n# NUMERIC_COLUMNS = ['Age', 'Fare']","31f7722a":"def one_hot_cat_column(feature_name, vocab):\n    return tf.feature_column.indicator_column(\n        tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab))","9abe378c":"feature_columns = []\nfor feature_name in CATEGORICAL_COLUMNS:\n    # Need to one-hot encode categorical features.\n    vocabulary = dftrain[feature_name].unique()\n    feature_columns.append(one_hot_cat_column(feature_name, vocabulary))","3ae8e332":"# TODO: not solved feature_columns add num_columns error\n#   for feature_name in NUMERIC_COLUMNS:\n#     feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))","522e79e8":"feature_columns","4b788a48":"example = dict(dftrain.head(1))\nclass_fc = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Pclass', (1, 2, 3)))\nprint('Feature value: \"{}\"'.format(example['Pclass'].iloc[0]))\nprint('One-hot encoded: ', tf.keras.layers.DenseFeatures([class_fc])(example).numpy())","8c39a572":"tf.keras.layers.DenseFeatures(feature_columns)(example).numpy()","eb1be81c":"# Use entire batch since this is such a small dataset.\nNUM_EXAMPLES = len(y_train)\n\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n    def input_fn():\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n        if shuffle:\n            dataset = dataset.shuffle(NUM_EXAMPLES)\n        # For training, cycle thru dataset as many times as need (n_epochs=None).    \n        dataset = dataset.repeat(n_epochs)\n        # In memory training doesn't use batching.\n        dataset = dataset.batch(NUM_EXAMPLES)\n        return dataset\n    return input_fn\n\n# Training and evaluation input functions.\ntrain_input_fn = make_input_fn(dftrain, y_train)\neval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)","d1238fb7":"linear_est = tf.estimator.LinearClassifier(feature_columns)\n\n# Train model.\nlinear_est.train(train_input_fn, max_steps=100)\n\n# Evaluation.\nresult = linear_est.evaluate(eval_input_fn)\n# clear_output()\nprint(pd.Series(result))","74d0e797":"# Since data fits into memory, use entire dataset per layer. It will be faster.\n# Above one batch is defined as the entire dataset. \nn_batches = 1\nest = tf.estimator.BoostedTreesClassifier(feature_columns,\n                                          n_batches_per_layer=n_batches)\n\n# The model will stop training once the specified number of trees is built, not \n# based on the number of steps.\nest.train(train_input_fn, max_steps=100)\n\n# Eval.\nresult = est.evaluate(eval_input_fn)\n# clear_output()\nprint(pd.Series(result))","224de6d8":"https:\/\/www.tensorflow.org\/alpha\/tutorials\/estimators\/boosted_trees\nhttps:\/\/github.com\/tensorflow\/docs\/blob\/master\/site\/en\/r2\/tutorials\/estimators\/boosted_trees.ipynb","295e468c":"Let's kernel restart after execute \"!pip install -U tensorflow==2.0.0-alpha0\".\n\nHow to \"kernel restart\" here.\n\n> Ctrl+shift+p and select \"confirm restart kernel\" This will restart the Jupyter Kernel instance and reload the installed libraries.\n\nhttps:\/\/github.com\/Kaggle\/docker-python\/issues\/340\n"}}