{"cell_type":{"d2373616":"code","5ab71905":"code","6cca4457":"code","5b137377":"code","4ac9c1ae":"code","71255d92":"code","6a470a1f":"code","f44f5298":"code","b6f95b74":"code","f15b0974":"code","a095a953":"code","ce179354":"code","88365fd6":"code","4e9e528b":"code","ce684ff4":"code","d912f57a":"code","a1e6bbd2":"code","562b31f2":"code","9340db8f":"code","ecbdfc84":"code","573df0fe":"code","dbe62fb1":"code","1a3b4b03":"code","7119fb57":"code","8cdecb55":"code","d2b9e2c2":"code","4d960d10":"code","5a2d0c12":"code","4622efd4":"code","ac67ce63":"code","81a56cff":"code","1c9e9d10":"code","33d80949":"code","9da0e817":"code","30d86039":"code","c9c5aa5f":"code","bdbbefd7":"code","c14f9983":"markdown","fba2f1b7":"markdown","9d5472c1":"markdown","6ce3454d":"markdown","79a74188":"markdown","c24d66d8":"markdown","245b1370":"markdown","246ffbf2":"markdown","d5faaf97":"markdown","b215c226":"markdown","9d65c33a":"markdown","6421ec94":"markdown","dd45a8b6":"markdown","96324e61":"markdown","554cbc63":"markdown","81594c8a":"markdown","d5986960":"markdown","9ed7eb44":"markdown","5672e8b3":"markdown","5a731e3d":"markdown","e001b45d":"markdown","26f36341":"markdown","55b974a5":"markdown","fe6874e8":"markdown","abf35793":"markdown","67c811a5":"markdown","c64dc956":"markdown","bf6fce2c":"markdown","23cb3429":"markdown","5ecc2366":"markdown","f7a30421":"markdown","12e62c30":"markdown","a7908bdd":"markdown","1f964447":"markdown","114fbfbc":"markdown","09aaa317":"markdown","9de81eca":"markdown"},"source":{"d2373616":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5ab71905":"import numpy as np\nimport keras\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D\nimport matplotlib.pyplot as plt\n","6cca4457":"# Download the MNIST dataset and partition train \/ test\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\") \ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\") \n\nx_train_orig = np.array(train.iloc[:, :-1].values)\ny_train_orig = np.array(train.iloc[:, 1].values)\nx_test_orig = np.array(test.iloc[:, :-1].values)\ny_test_orig = np.array(test.iloc[:, 1].values)\n","5b137377":"# Checking an example\nfirst_image = x_train_orig[0]\nfirst_image = np.array(first_image, dtype='float')\npixels = first_image.reshape((28, 28))\nplt.imshow(pixels, cmap='gray')\nplt.show()","4ac9c1ae":"# Shape\nx_train_orig[0].shape","71255d92":"print('Training data shape : ', x_train_orig.shape, y_train_orig.shape)\n\nprint('Testing data shape : ', x_test_orig.shape, y_test_orig.shape)\n","6a470a1f":"nCols, nDims = 784, 1\ninput_shape = (nRows, nCols, nDims)\nx_train = x_train_orig.reshape(x_train_orig.shape, nCols, nDims, 1)\nx_test = x_test_orig.reshape(x_test_orig.shape, nCols, nDims, 1)","f44f5298":"print(nRows, nCols, nDims, 1)","b6f95b74":"x_train = x_train \/ 255\nx_test = x_test \/ 255\n\nnum_classes = 10\ny_train = to_categorical(y_train_orig, num_classes)\ny_test = to_categorical(y_test_orig, num_classes)","f15b0974":"y_train[5]","a095a953":"num_classes = 10\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(28,28,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation='softmax'))","ce179354":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","88365fd6":"#Entrenamiento del modelo\nn_epochs_onelayer = 9\nmfit_onelayer = model.fit(x_train, y_train,\n                              epochs=n_epochs_onelayer,\n                              verbose=1,\n                              validation_data=(x_test, y_test))\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","4e9e528b":"# plot del training loss y el accuracy\ndef plot_prediction(n_epochs, mfit):\n\n    # Plot training & validation loss values\n    plt.plot(mfit.history['loss'])\n    plt.plot(mfit.history['val_loss'])\n    title = 'Model loss (' + str(n_epochs) + ' epochs)'\n    plt.title(title)\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n    \n    return plt","ce684ff4":"plot_prediction(n_epochs_onelayer, mfit_onelayer)","d912f57a":"mfit_onelayer","a1e6bbd2":"# Hacemos la predicci\u00f3n para las 4 primeras im\u00e1genes del set de test\nprint(model.predict(x_test[:4]))\n\n# Mostramos el ground truth para las primeras 4 im\u00e1genes\ny_test[:4]","562b31f2":"y_train = to_categorical(y_train_orig)\ny_test = to_categorical(y_test_orig)","9340db8f":"def creaModeloRedNeuronalProfunda():\n    num_classes = 10\n\n    model = Sequential()\n\n    ##TODO: A\u00f1adir las capas\n    model.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(28,28,1)))\n    model.add(Conv2D(64, (3, 3), padding='valid', activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    return model\n","ecbdfc84":"batch_size = 128\nn_epochs = 12 \n\ndeep_model = creaModeloRedNeuronalProfunda()\n\ndeep_model.compile(optimizer='adadelta',\n                   loss='categorical_crossentropy',\n                   metrics=['accuracy'])\n\ndeep_model.summary()","573df0fe":"mfit = deep_model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epochs, verbose=1, \n                   validation_data=(x_test, y_test))\n\n\n# Evaluation in test\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n","dbe62fb1":"# Visualizci\u00f3n de la evoluci\u00f3n de la m\u00e9trica accuracy\nplot_prediction(n_epochs, mfit)","1a3b4b03":"# Prediction\nprint(model.predict(x_test[:4]))\ny_test[:4]","7119fb57":"x_train = x_train_orig[:, ::2, ::2]\nx_test = x_test_orig[:, ::2, ::2]","8cdecb55":"# Normalizamos los valores de los p\u00edxeles\nx_train = x_train \/ 255.0\nx_test = x_test \/ 255.0\n\ny_train = x_train_orig \/ 255.0\ny_test = x_test_orig \/ 255.0\n\n# Ajustamos las dimensiones de los datos\nx = np.expand_dims(x_train, axis=3)\ny = np.expand_dims(y_train, axis=3)\n\nx_test_final = np.expand_dims(x_test, axis=3)\ny_test_final = np.expand_dims(y_test, axis=3)","d2b9e2c2":"y_test.shape\n","4d960d10":"y.shape","5a2d0c12":"def creaModeloRedNeuronalConvolucional():\n    num_classes = 10\n\n    model = Sequential()\n\n    # Add layer  \n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(14, 14, 1)))    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n    # deconvolutional layer\n    model.add(keras.layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n    model.add(keras.layers.Conv2DTranspose(1, (3, 3), strides=(2, 2), padding='same', activation='sigmoid'))\n    \n    return model","4622efd4":"# Model creation\nconvolutional_network = creaModeloRedNeuronalConvolucional()\n\nconvolutional_network.summary()","ac67ce63":"#Entrenar y compilar el modelo\nconvolutional_network.compile(loss='binary_crossentropy',\n              optimizer='Adadelta',\n              metrics=['accuracy'])","81a56cff":"n_epochs = 12 \nconvolutional_network.fit(x, y, epochs=n_epochs, validation_data=(x_test_final, y_test_final))","1c9e9d10":"# Predicci\u00f3n de tres im\u00e1genes del conjunto de test\nn_images = 3\nidx_images = np.random.randint(x_test.shape[0], size=n_images)\n\nimages = np.expand_dims(np.stack([x_test[i] for i in idx_images]), axis=3)\n\npred = convolutional_network.predict(images)\n","33d80949":"# Ajustamos las dimensiones de las im\u00e1genes predichas al formato adecuado y desnormalizamos los p\u00edxeles\npred = np.squeeze(pred)\npred = pred * 255.0","9da0e817":"def drawImage(i, pred, alto, ancho):\n  #Visualizamos la imagen i del dataset\n  first_image = pred[i]\n  first_image = np.array(first_image, dtype='float')\n  pixels = first_image.reshape((alto, ancho))\n  plt.imshow(pixels, cmap='gray')\n  plt.show()","30d86039":"#Visualizamos la primera imagen \ndrawImage(0, images, 14, 14)\ndrawImage(0, pred, 28, 28)\n","c9c5aa5f":"#Visualizamos la segunda imagen \ndrawImage(1, images, 14, 14)\ndrawImage(1, pred, 28, 28)\n","bdbbefd7":"#Visualizamos la tercera imagen \ndrawImage(2, images, 14, 14)\ndrawImage(2, pred, 28, 28)","c14f9983":"### 1.4 Model training\n\nWe now train the model. To do this, we will make the model see each image 9 different times, and we will use the test set to validate the process.","fba2f1b7":"Here we can observe first the reduced image and secondly the image predicted from our neural network model. Next we will do the same with the other 2 remaining examples.","9d5472c1":"Next we will create and train the model with the following characteristics:\n\n- A convolutional layer of 32 kernels of 3x3 size, and with a relu activation function.\n- A MaxPooling layer with a size of 2x2.\n- Another convolutional layer of 32 kernels of 3x3 size, and with relu activation function.\n- A deconvolutionary layer with 32 kernels, size 3x3, stride 2x2, and relu activation function.\n- A last deconvolutionary layer with a single kernel of size 3x3, stride 2x2, and activation function sigmoid.\n\nAll convolutional and deconvolutionary layers have to have the padding parameter \"sames\", so that the size of the images is not affected in these layers.","6ce3454d":"We then compile, train and evaluate the model. For compilation we will use the cost function \"categorical_crossentropy\" and the metric \"accuracy\" again, but in this case we will use the Adadelta optimizer.\n\nWe will train the model for 12 periods, using a batch_size of 128, and the test set to validate. Finally we will also use the test set to evaluate the model.","79a74188":"### 1.3 Build the model\n\nOnce the model is defined, it must be compiled so that Keras prepares the training. For this we are going to use the ADAM optimization algorithm, the cost function \"categorical_crossentropy\" and the \"accuracy\" metric","c24d66d8":"# 0 Initialization and load data\n","245b1370":"By looking at the graphs of the Accuracy measurement of a '* normal convolutional network *' and a deep '* CNN + Dropout *' we can assure that ** this second ** method (CNN + Dropout) has a higher ** accuracy ** comparing it to the first one. In addition, it greatly minimizes the cost function (** loss function **), obtaining much smaller * loss * values. The two layers *** dropout *** probability ** 0.25 and 0.5 ** contribute to the model ** with much more outstanding results, allowing a noticeable increase in the generalizability of the network ** and consequently better results are obtained. On the other hand, ** CNN + Dropout training is much faster ** for each epoch (epoch).\n\nIncreasing the number of intermediate layers can be a possible improvement of the model and an increase in the processing and classification capacity, but we must take into account and adjust the possible over-specialization that this may imply.","246ffbf2":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Model construction<\/strong>\n<\/div>","d5faaf97":"### 3.1 Model creation and training\n","b215c226":"And we normalize the pixel values and adjust the dimensions of the data:","9d65c33a":"### 1.2 Model Creation\n\n\nWe are going to use a Keras Sequential model since it is very easy to use. These types of models allow us to build the model layer by layer. Specific:\n\n- The first layer we will add will be a convolutional layer with the following properties:\n\u00a0\u00a0\u00a0\u00a0 - Number of kernels (neurons) first layer: 64 neurons\n\u00a0\u00a0\u00a0\u00a0 - Kernels size: 3x3\n\u00a0\u00a0\u00a0\u00a0 - Activation of kernels: ReLU\n- Next we will add a Flatten layer to connect the output of the convolutional layer with the input of a dense layer.\n- Finally, we will add a dense output layer, and therefore it will have as many neurons as we want to predict classes. The activation of this last layer will be Softmax. The final prediction of the model will then be the class with the highest probability.","6421ec94":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong> Coding the output (Y output): <\/strong> Coding the values of the output tags into a one-hot vector. For example, the output vector for an image containing a 5 would be: [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]. TIP: Keras.utils to_categorical function can be used.\n<\/div>","dd45a8b6":"### 1.6 Prediction\n\nFinally we can make the prediction for four of the images in the test set and see if the results are correct or not","96324e61":"## 2. Deep CNN + Dropout ","554cbc63":"## 1. Convolutional Neural Network with one layer\n","81594c8a":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Training the model<\/strong> \n<\/div>","d5986960":"The following code loads the necessary packages for the practice and also reads the data that we will use to train the neural network. The MNIST Dataset corresponds to images of digits from 0 to 9 of size 28x28 pixels.","9ed7eb44":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Coding the Y output tags<\/strong> \n<\/div>","5672e8b3":"### 3.2 Predicci\u00f3n de algunas im\u00e1genes del conjunto de test","5a731e3d":"### 1.5  Accuracy evolution","e001b45d":"In this practice, we are going to implement two convolutional neural networks to recognize the digits of the MNIST reference data set. In addition, we will also train a simple super-resolution model. Specifically, the following three points will be implemented:\n\n1. A convolutional neural network of one layer\n2. A deep convolutional neural network with x layers\n3. A super-resolution model\n\nIn all three cases, the Keras library will be used for model implementation, compilation, and training. Next we will also use Keras to predict the image classification of the test set.\n","26f36341":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\nVisualize the evolution of accuracy in the training and test set according to the times.\n<\/div>","55b974a5":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Analysis<\/strong>\n<\/div>","fe6874e8":"In this exercise we will build a convolutional neural network such that, given low resolution images, it allows us to obtain the same images but with a higher resolution. To do this, from the same MNIST dataset we will create low-resolution images with which we will train our model.","abf35793":"### 1.1 Pre-processing data\n\nThe first step in training a neural network is to pre-process the training and test data to match the input of the neural network.\n","67c811a5":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Ejercicio [1 pto.]:<\/strong> Visualizar tres im\u00e1genes al azar del conjunto de test. Mostrar la versi\u00f3n original de la imagen, la versi\u00f3n con resoluci\u00f3n reducida, y la predicci\u00f3n del modelo.\n<\/div>","c64dc956":"\n\n\n\n# Convolutional Neural Networks with KERAS","bf6fce2c":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Development<\/strong> \n<\/div>","23cb3429":"In this case we will use a Keras Sequential model again that will consist of:\n- Two convolution layers of 32 and 64 kernels respectively of 3x3 size, and with a reluctance activation function\n- A MaxPooling layer with a size of 2x2\n- A Dropout layer with a rate = 0.25\n- A Flatten layer\n- A dense layer with 128 neurons and a brilliant activation function\n- A Dropout layer with a rate = 0.5\n- A dense layer with softmax activation function","5ecc2366":"First we reduce the resolution of the images:","f7a30421":"In the previous exercise we have implemented a single layer convolutional network. Now we are going to implement a deep convolutional neural network and we will see how this translates into better performance in the results. We will initialize and pre-process the data first.","12e62c30":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Model creation<\/strong>\n<\/div>","a7908bdd":"<div style=\"background-color: #C7FCE5; border-color: #61FEBA; border-left: 5px solid #61FEBA; padding: 0.5em;\">\nWe have 'reshaped' x_train_orig and x_test_orig since our CNN will only accept a four-dimensional vector. Also, we set our tuple consisting of:\n     <ul>\n         <li> the 60,000 images that we have in training camp, <\/li>\n         <li> 28 the height of the image, <\/li>\n         <li> 28 the width of the image and <\/li>\n         <li> 1 which will be the number of channels. (1 for grayscale and 3 for RGB colors) <\/li>\n     <\/ul>\n<\/div>","1f964447":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Training<\/strong> \n<\/div>","114fbfbc":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n\n<strong> Adjust dimensions in images (X input): <\/strong> Adjust the size of the training and test data using 4 dimensions (the last dimension has to be 1 to indicate that the images are in gray scale). TIP: use the number of training and test data and the size of the images.\n<\/div>","09aaa317":"## 3. CNN applying for super resolution (encoder-decoder)","9de81eca":"Next we will implement a convolutional neural network of one layer and we will do the training and test on the MNIST dataset. We have 60,000 images to train and 10,000 to test."}}