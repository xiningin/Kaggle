{"cell_type":{"003b18e1":"code","d6c6caac":"code","46cb3ae7":"code","d6881f36":"code","91d968f9":"code","7c9d7a6b":"code","869ab441":"code","e9aec52c":"code","05ee450f":"code","d6758457":"code","1c15e669":"code","6ec16bca":"code","5c97ae2a":"code","4e480cb1":"code","658dd7fc":"code","e1508e15":"code","c64756d2":"code","5375a5b0":"code","0020286f":"code","0fe9ee6e":"code","17c7b2d1":"code","b6ac38f6":"code","83720efd":"code","f88f7f0a":"code","678f0953":"code","e5993e98":"code","4f780e12":"code","eb599fba":"code","502f6794":"code","36407983":"code","6b4934a4":"code","f3509514":"code","084951fe":"code","afc25aa5":"code","3a3cb267":"markdown","f894bfb2":"markdown","4d31f3f1":"markdown","046c31f7":"markdown","28244bef":"markdown","956ebbd3":"markdown","9db83ac9":"markdown"},"source":{"003b18e1":"# Training in Kaggle by Hung Anh\n# link kaggle: https:\/\/www.kaggle.com\/hnganhlnguyn\/ex3-cnn\n#link dataset https:\/\/www.kaggle.com\/hnganhlnguyn\/bird-dataset\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,BatchNormalization,SeparableConv2D,Activation,GlobalAveragePooling2D,Add\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling,Resizing\nimport datetime\n#AUTOTUNE = tf.data.experimental.AUTOTUNE","d6c6caac":"!nvidia-smi","46cb3ae7":"# Set batch size\n#BATCH_SIZE = 8 * strategy.num_replicas_in_sync\nBATCH_SIZE = 32\n\n# Set number of epochs\nEPOCHS = 500\n\n# Patience for the learning rate\nLR_PATIENCE = 5\n\n# Patience for early stopping\nSTOPPING_PATIENCE = 30","d6881f36":"train_directory = '..\/input\/bird-dataset\/Bird_DataClassification\/Train'\nvalid_directory = '..\/input\/bird-dataset\/Bird_DataClassification\/Valid'\ntest_directory = '..\/input\/bird-dataset\/Bird_DataClassification\/Test'","91d968f9":"import glob\nprint('Train: parrot - ',len(glob.glob(train_directory+'\/0\/*')),' || oriole - ',len(glob.glob(train_directory+'\/1\/*')))\nprint('Validation: parrot - ',len(glob.glob(valid_directory+'\/0\/*')),' || oriole - ',len(glob.glob(valid_directory+'\/1\/*')))\nprint('Test: parrot - ',len(glob.glob(test_directory+'\/0\/*')),' || oriole - ',len(glob.glob(test_directory+'\/1\/*')))","7c9d7a6b":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(train_directory,seed=123,image_size=(256,256),batch_size=BATCH_SIZE)","869ab441":"valid_ds = tf.keras.preprocessing.image_dataset_from_directory(valid_directory,seed=13,image_size=(256,256),batch_size=BATCH_SIZE)","e9aec52c":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_directory,seed=123,image_size=(256,256),batch_size=BATCH_SIZE)","05ee450f":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","d6758457":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1)])","1c15e669":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","6ec16bca":"def classifier_model(input_shape = (256,256,3), num_classes = 2):\n    inputs = tf.keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = Rescaling(1.0\/ 255)(x)\n    x = Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(64, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n    for size in [128, 256, 512, 728]:\n        x = Activation(\"relu\")(x)\n        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = BatchNormalization()(x)\n\n        x = Activation(\"relu\")(x)\n        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = BatchNormalization()(x)\n\n        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n        x = Add()([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = Dropout(0.5)(x)\n    outputs = Dense(units, activation=activation)(x)\n    return Model(inputs, outputs)","5c97ae2a":"classifier1 = classifier_model(input_shape = (256,256,3), num_classes=2)\nloss = 'binary_crossentropy'\nmetrics=['accuracy']\nclassifier1.compile(optimizer='adam',loss=loss,metrics=metrics)","4e480cb1":"classifier1.summary()","658dd7fc":"learning_rate = ReduceLROnPlateau(patience=LR_PATIENCE,verbose=1,factor=0.5,min_delta=0.000001)\nearly_stopping = EarlyStopping(patience=STOPPING_PATIENCE,monitor='val_loss',verbose=1,restore_best_weights=True,mode='min')","e1508e15":"t0 = datetime.datetime.now()","c64756d2":"history = classifier1.fit(train_ds,validation_data=valid_ds,epochs=EPOCHS,callbacks=[learning_rate,early_stopping])","5375a5b0":"t1 = datetime.datetime.now()\nprint('Time training: ',t1-t0)","0020286f":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='upper left')\nplt.show()","0fe9ee6e":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='upper left')\nplt.show()","17c7b2d1":"classifier1.save('Ex3classifier1.h5')","b6ac38f6":"from tensorflow.keras.models import load_model\nfrom sklearn.metrics import classification_report\nloadEx3_model = load_model('.\/Ex3classifier1.h5') ","83720efd":"train_score = loadEx3_model.evaluate(train_ds)","f88f7f0a":"valid_score = loadEx3_model.evaluate(valid_ds)","678f0953":"test_score = loadEx3_model.evaluate(test_ds)","e5993e98":"new_url1 = 'https:\/\/sudospaces.com\/gaocung-com\/2021\/01\/chim-vang-anh-an-gi-1.jpg'\nnew_url2 = 'https:\/\/cdn.chotot.com\/MfxqCZMCgcr-PqIvoOCcmP8VZGqZnWVpfbB_wl59QXM\/preset:view\/plain\/5a0e729ef5c9265889ab6e0a6b86d68d-2745499794937820100.jpg'","4f780e12":"f = open(\"..\/input\/bird-dataset\/Bird_DataClassification\/info.txt\", \"r\")\nprint(f.read()) # in ra b\u1ea3ng th\u00f4ng tin nh\u00e3n","eb599fba":"from PIL import Image\nimport requests\n\ndef get_imgURL(url): \n    im = Image.open(requests.get(url, stream=True).raw)\n    im = im.resize((256,256))\n    img_array = np.asarray(im)\n    img_array = tf.expand_dims(img_array,0)\n    return img_array","502f6794":"img1 = get_imgURL(new_url1)\nimg1.shape","36407983":"predictions1 = loadEx3_model.predict(img1)\nscore1 = predictions1[0]\nprint(\"This image is %.2f percent parrot and %.2f percent oriole.\"% (100 * (1 - score1), 100 * score1))","6b4934a4":"plt.imshow(img1[0]) # oriole","f3509514":"img2 = get_imgURL(new_url2)\nimg2.shape","084951fe":"predictions2 = loadEx3_model.predict(img2)\nscore2 = predictions2[0]\nprint(\"This image is %.2f percent parrot and %.2f percent oriole.\"% (100 * (1 - score2), 100 * score2))","afc25aa5":"plt.imshow(img2[0]) # parrot","3a3cb267":"<h1>Evaluation<\/h1>","f894bfb2":"<h1>Build and Train model<\/h1>\n<strong>K\u1ebft h\u1ee3p vi\u1ec7c t\u0103ng c\u01b0\u1eddng d\u1eef li\u1ec7u trong build model:<\/strong>\n<div><code>\n    inputs = tf.keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n<\/code><\/div>\n\n","4d31f3f1":"<h1>Augmentation<\/h1>","046c31f7":"<h1>Prepare Data and Parameters<\/h1>","28244bef":"<h1>Import<\/h1>","956ebbd3":"<h2>Nh\u1eadn x\u00e9t:<\/h2>\n<li>Model ho\u1ea1t \u0111\u1ed9ng t\u1ed1t tr\u00ean t\u1eadp gi\u1eef li\u1ec7u v\u1edbi \u0111\u1ed9 ch\u00ednh x\u00e1c cao \u1edf c\u1ea3 3 t\u1eadp<\/li>","9db83ac9":"<h1>Visualize samples<\/h1>"}}