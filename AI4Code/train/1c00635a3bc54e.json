{"cell_type":{"8d7d18a8":"code","d457627a":"code","21f156a4":"code","c0b2e3dd":"code","40af7d4e":"code","f967d5e2":"markdown","a2a9a88f":"markdown","db7f1738":"markdown","e5bc5e92":"markdown","c4641637":"markdown","e7495077":"markdown","b5ac4673":"markdown","3d1e5f55":"markdown","478dd442":"markdown","ff306934":"markdown","84d890d9":"markdown"},"source":{"8d7d18a8":"# Install required libraries\n!pip3 install --upgrade pip\n!pip install moviepy\n!pip install pytube3\n\n# Import libraries\nimport os\nimport cv2\nimport moviepy\nimport numpy as np \nfrom pytube import YouTube\nfrom datetime import timedelta\nfrom IPython.display import Video\nfrom IPython.display import YouTubeVideo\nfrom moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n\nURL_YouTube = 'https:\/\/www.youtube.com\/watch?v=d-souLImH-I'\n\n","d457627a":"def YouTube_time_window(url, **kwargs):\n    id_ = url.split(\"=\")[-1]\n    return YouTubeVideo(id_, **kwargs)\n\n# enter time window [hr;mn;sec]\ntime_start = int(timedelta(hours=0, minutes=0, seconds=57).total_seconds())\n\n# enter Duration [sec]\ntime_duration = 25\n\n# Launch\ntime_end = time_start + time_duration\nwidth, height = 550, 350\nYouTube_time_window(URL_YouTube, start=time_start, width=width, height=height)\n","21f156a4":"# Download and rename files \nVideo_file_raw = YouTube(URL_YouTube).streams.first().download()\nDIR_vid = '\/kaggle\/working\/'\nVideo_file = DIR_vid + 'Vid_in.mp4'\nos.rename(Video_file_raw, Video_file)\n\n# Extract desired segment \nVideo_out_name = 'Vid_out.mp4'\nffmpeg_extract_subclip(Video_file, time_start, time_end, targetname=Video_out_name)\nVideo(Video_out_name, width=width, height=height)","c0b2e3dd":"def region_of_interest(img, vertices):\n    mask = np.zeros_like(img)\n    match_mask_color = 255\n    cv2.fillPoly(mask, vertices, match_mask_color)\n    masked_image = cv2.bitwise_and(img, mask)\n    return masked_image\n\ndef draw_the_lines(img, lines):\n    img = np.copy(img)\n    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n\n    for line in lines:\n        for x1, y1, x2, y2 in line:\n            cv2.line(blank_image, (x1,y1), (x2,y2), (255, 0, 0), thickness=5)\n\n    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n    return img\n\ndef process(image):\n    height = image.shape[0]\n    width = image.shape[1]\n    region_of_interest_vertices = [(0, height), (width\/2, height\/2), (width, height)]\n    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    canny_image = cv2.Canny(gray_image, 100, 120)\n    cropped_image = region_of_interest(canny_image,\n                                       np.array([region_of_interest_vertices], np.int32))\n    lines = cv2.HoughLinesP(cropped_image, rho=2, theta=np.pi\/180, threshold=50,\n                           lines=np.array([]), minLineLength=40, maxLineGap=100)\n    image_with_lines = draw_the_lines(image, lines)\n    return image_with_lines","40af7d4e":"cap = cv2.VideoCapture(DIR_vid + 'Vid_out.mp4')\nfourcc = cv2.VideoWriter_fourcc(*'MP4V')\nvid_out = cv2.VideoWriter(DIR_vid + 'Vid_Mask.mp4', fourcc, 20, (int(cap.get(3)), int(cap.get(4))))\n\n# ----------------- Initialization ----------------- #\n_, img_org = cap.read()\nframe1 = img_org; frame2 = frame1\nframe_i, frame_tot = 0, 480\n\nwhile cap.isOpened() & (frame_i < frame_tot):\n    if (frame_i%25 == 0):\n        print('frame : %d \/ %d'% (frame_i, frame_tot) )\n    frame_i = frame_i + 1 # frame_idx\n    # ------- Hough Transform for alignment -------- #\n    frame2 = process(frame2)\n    # cv2_imshow(frame2)\n\n    # -------------- Object Detection -------------- #\n    diff = cv2.absdiff(frame1, frame2)\n    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n    blur = cv2.GaussianBlur(gray, (29, 29), 0)\n    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n    dilated = cv2.dilate(thresh, None, iterations=3)\n    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    for contour in contours:\n        (x, y, w, h) = cv2.boundingRect(contour)\n\n        if cv2.contourArea(contour) < 500:\n            continue\n        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n\n    cv2.drawContours(frame1, contours, -1, (0, 0, 255), 1)\n    vid_out.write(frame1)\n    # cv2_imshow(frame1)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n    # ------------- Towards next step ------------- #\n    frame1 = frame2\n    _, frame2 = cap.read()\n    # frame2 = cv.resize(frame2, low_res) # uncomment to resize resolution\n\ncap.release()\nvid_out.release()\ncv2.destroyAllWindows()","f967d5e2":"<a id=\"1\"><\/a>\n\n### $\\text{Processing tools } \ud83d\udd27$\n\nFirst the user will enter YouTube URL, from which a desired segment will be cropped. \\\nThen, it will undergo several procedures (Generally speaking ... \ud83e\udd2b): \n\n\n* [**Gaussian filter**](https:\/\/en.wikipedia.org\/wiki\/Gaussian_filter#:~:text=In%20electronics%20and%20signal%20processing,as%20it%20has%20infinite%20support) : $$\nG(x, y, \\sigma) = \\frac{1}{2 \\pi \\sigma^2} e^{- \\frac{x^2+y^2}{2 \\sigma^2}} \\quad \\Rightarrow \\quad \\nabla^2 (I^t * G(x, y)) = I^t * \\nabla^2 G(x, y) $$\n* [**Hough transform**](https:\/\/en.wikipedia.org\/wiki\/Hough_transform) : $$ r = x \\cdot \\cos \\theta + y \\cdot \\sin \\theta \\quad \\Leftrightarrow \\quad y = - \\frac{\\cos \\theta}{\\sin \\theta} \\cdot x + \\frac{r}{\\sin \\theta} $$\n* [**Image dilation**](https:\/\/en.wikipedia.org\/wiki\/Dilation_(morphology)) : $$\nI_{(x,y)} \\oplus B = \\bigcup_{b\\in B} A_b \\quad \\quad B:=\\text{structuring element}\n$$\n* [**Image differencing**](https:\/\/en.wikipedia.org\/wiki\/Image_differencing) : $$\nI_{(x, y)}^{t+1} - I_{(x, y)}^{t} \\quad \\forall \\quad t := \\text{frame}\n$$","a2a9a88f":"After extracting the object's visual features, the shape is delineate as such :\n\n<img src=https:\/\/i.imgur.com\/22eqlrF.png width=300 \/>\n\n* [**Bounding box**](https:\/\/machinelearningmastery.com\/object-recognition-with-deep-learning\/) : \n$$ \\  \\ (x_1, y_1) = \\big( \\max (iX) \\, , \\, \\max (iY) \\big) \\\\  \\ (x_2, y_2) = \\big( \\min (iX) \\, , \\ \\min (iY) \\big)  $$\n\n","db7f1738":"### $\\text{Trim video : } \u2702\ufe0f $  \ud83c\udf9e\ufe0f\n\nNormally there is **no need** in the entire footage, but only in a certain **clipped** footage :","e5bc5e92":"<a id=\"3\"><\/a>\n### $\\text{IP Algorithms : } $ \ud83d\udcc8\n\nThis section contains the algorithmic core (manually written) that implements the above formulation :","c4641637":"$$\n- fin -\n$$","e7495077":"## $\\text{Voil\u00e0 : }$ \ud83c\udf89\n\n<img src=https:\/\/github.com\/Daniboy370\/Computer-Vision\/raw\/master\/OpenCV_Demo\/Upload\/Github_GIF.gif width=800\/>","b5ac4673":"<img src=https:\/\/upload.wikimedia.org\/wikipedia\/commons\/5\/53\/OpenCV_Logo_with_text.png width=125 \/>","3d1e5f55":"### $ \\text{Abstract}$\n\nIn this notebook I demonstrate a simple object recognition using **OpenCV** library, based on simple image process methods. Different parameters such as ***Gaussian kernel size***, ***binary threshold***, ***Hough transform sensitivity*** - will have a direct influence upon the recognition outcome. The general workflow satisfies :\n\n<img src=https:\/\/i.imgur.com\/Cme04tm.png width=700 \/>\n","478dd442":"### $\\text{Table of Contents}$\n\n* [Processing tools : \ud83e\uddd9\u200d\u2642\ufe0f](#1)\n* [YouTube video : \ud83c\udfa5](#2)\n* [Algorithms : \u2702\ufe0f  \ud83c\udf9e\ufe0f](#3)\n* [Download : \ud83d\udce5](#4)\n","ff306934":"<a id=\"2\"><\/a> \n<img src=https:\/\/i.imgur.com\/JmOvb15.png width=450\/>","84d890d9":"<a id=\"4\"><\/a>\n### $\\text{Download : } \ud83d\udce5$\n\n<img src=https:\/\/i.imgur.com\/RiJC55L.png width=\"325\" \/>"}}