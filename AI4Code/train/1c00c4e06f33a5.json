{"cell_type":{"70422b6c":"code","1eccca43":"code","5f50a78b":"code","f5e7fb69":"code","b1ffdcbf":"code","047cb451":"code","4a8319e0":"code","29b4c271":"code","4723a5b0":"code","00ed1041":"code","42068871":"code","830096e6":"code","d74184e8":"markdown","90eb08cd":"markdown","d59334d6":"markdown","c76172a1":"markdown","4fe7bedd":"markdown","b2edeaeb":"markdown"},"source":{"70422b6c":"!rm -r \/opt\/conda\/lib\/python3.6\/site-packages\/lightgbm\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","1eccca43":"!apt-get install -y -qq libboost-all-dev","5f50a78b":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","f5e7fb69":"!cd LightGBM\/python-package\/;python3 setup.py install --precompile","b1ffdcbf":"!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","047cb451":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn import metrics\nimport gc\n\npd.set_option('display.max_columns', 200)","4a8319e0":"import gc\nimport os\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')\n\n#logger\ndef get_logger():\n    FORMAT = '[%(levelname)s]%(asctime)s:%(name)s:%(message)s'\n    logging.basicConfig(format=FORMAT)\n    logger = logging.getLogger('main')\n    logger.setLevel(logging.DEBUG)\n    return logger\n    \nlogger = get_logger()\nlogger.info('Input data')\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\n\nlogger.info('Features engineering')\nidx = [c for c in train_df.columns if c not in ['ID_code', 'target']]\nfor df in [test_df, train_df]:\n    df['sum'] = df[idx].sum(axis=1)  \n    df['min'] = df[idx].min(axis=1)\n    df['max'] = df[idx].max(axis=1)\n    df['mean'] = df[idx].mean(axis=1)\n    df['std'] = df[idx].std(axis=1)\n    df['skew'] = df[idx].skew(axis=1)\n    df['kurt'] = df[idx].kurtosis(axis=1)\n    df['med'] = df[idx].median(axis=1)\n\nlogger.info('Prepare the model')\nfeatures = [c for c in train_df.columns if c not in ['ID_code', 'target']]\ntarget = train_df['target']","29b4c271":"!nvidia-smi","4723a5b0":"param = {\n        'num_leaves': 7,\n        'max_bin': 119,\n        'min_data_in_leaf': 6,\n        'learning_rate': 0.03,\n        'min_sum_hessian_in_leaf': 0.00245,\n        'bagging_fraction': 1.0, \n        'bagging_freq': 5, \n        'feature_fraction': 0.05,\n        'lambda_l1': 4.972,\n        'lambda_l2': 2.276,\n        'min_gain_to_split': 0.65,\n        'max_depth': 14,\n        'save_binary': True,\n        'seed': 1337,\n        'feature_fraction_seed': 1337,\n        'bagging_seed': 1337,\n        'drop_seed': 1337,\n        'data_random_seed': 1337,\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'auc',\n        'is_unbalance': True,\n        'boost_from_average': False,\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n    }","00ed1041":"%%time\nnfold = 5\n\ntarget = 'target'\npredictors = train_df.columns.values.tolist()[2:]\n\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, train_df.target.values):\n    print(\"\\nfold {}\".format(i))\n    xg_train = lgb.Dataset(train_df.iloc[train_index][predictors].values,\n                           label=train_df.iloc[train_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    xg_valid = lgb.Dataset(train_df.iloc[valid_index][predictors].values,\n                           label=train_df.iloc[valid_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    \n    clf = lgb.train(param, xg_train, 5000, valid_sets = [xg_valid], verbose_eval=500, early_stopping_rounds = 250)\n    oof[valid_index] = clf.predict(train_df.iloc[valid_index][predictors].values, num_iteration=clf.best_iteration) \n    \n    predictions += clf.predict(test_df[predictors], num_iteration=clf.best_iteration) \/ nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(train_df.target.values, oof)))","42068871":"sub_df = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\nsub_df[\"target\"] = predictions\nsub_df[:10]","830096e6":"sub_df.to_csv(\"lightgbm_gpu.csv\", index=False)","d74184e8":"<a id=\"2\"><\/a> \n## 2. Loading the data","90eb08cd":"In order to leverage the GPU, we need to set the following parameters: \n\n        'device': 'gpu',\n        'gpu_platform_id': 0,\n        'gpu_device_id': 0\n        \n        ","d59334d6":"<a id=\"1\"><\/a> \n## 1. Re-compile LGBM with GPU support\nIn Kaggle notebook setting, set the `Internet` option to `Internet connected`, and `GPU` to `GPU on`.","c76172a1":"# GPU-accelerated LightGBM\n\nThis kernel explores a GPU-accelerated LGBM model to predict customer transaction.\n\n## Notebook  Content\n1. [Re-compile LGBM with GPU support](#1)\n1. [Loading the data](#2)\n1. [Training the model on CPU](#3)\n1. [Training the model on GPU](#4)\n1. [Submission](#5)","4fe7bedd":"<a id=\"5\"><\/a>\n## 5. Submission","b2edeaeb":"<a id=\"4\"><\/a>\n## 4. Train model on GPU"}}