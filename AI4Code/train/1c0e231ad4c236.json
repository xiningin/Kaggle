{"cell_type":{"3a86cf61":"code","c7586a3b":"code","a6a15136":"code","4079fdce":"code","e9fa4ba2":"code","1e0d9d84":"code","7fb338f0":"code","3281ce98":"code","74b95fe6":"code","35ab2f1d":"code","95ab930d":"code","e3abbd66":"code","ba644b4f":"code","a9cde5ea":"markdown","49f63ff8":"markdown","5a3fee29":"markdown","91db57cb":"markdown","df5d59b1":"markdown","00e6aeb8":"markdown","7d95e460":"markdown"},"source":{"3a86cf61":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c7586a3b":"import matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn.svm import SVR\nfrom xgboost.sklearn import XGBRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.decomposition import PCA","a6a15136":"df_train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')","4079fdce":"X = df_train.drop(['id', 'loss'], axis = 1)\nY = df_train['loss']","e9fa4ba2":"sc=StandardScaler()\nX_train = sc.fit_transform(X)\nX_test = sc.transform(df_test.drop('id', axis = 1))\ny_train=Y","1e0d9d84":"# n_components = 100\n# pca = PCA(n_components=n_components).fit(df_train.values)","7fb338f0":"# pca = PCA(n_components=100)\n# pca.fit(X_train)\n# X_d = pca.transform(X_train)\n# X_d.shape, X_train.shape","3281ce98":"### LINEAR REGRESSION\n# model = LinearRegression().fit(X_train, y_train)","74b95fe6":"### XGB REGRESSION\n# xgb_params = {'n_estimators': 10000,\n#               'learning_rate': 0.010154255408501112,\n#               'subsample': 0.8406787739843629,\n#               'colsample_bytree': 0.7078557348809151,\n#               'max_depth': 7,\n#               'reg_lambda': 93.9874814976386,\n#               'reg_alpha': 33.26324929265035,\n#               'random_state': 42,\n#               'n_jobs': 4}\n\n# model = XGBRegressor(**xgb_params)\n# model.fit(X_train, y_train,\n#           eval_metric=\"rmse\",\n#           verbose=True)","35ab2f1d":"### model = HistGradientBoostingRegressor()\nmodel = HistGradientBoostingRegressor()\nmodel = model.fit(X_train, y_train)\ny_pred = model.predict(X_test)","95ab930d":"model.score(X_train, y_train)","e3abbd66":"y_pred = model.predict(X_test)","ba644b4f":"submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\nsubmission[\"loss\"]= y_pred\nsubmission.to_csv(\"submission_hist_.csv\", index=False)","a9cde5ea":"# Submitting the Predictions","49f63ff8":"I used various models to train the dataset - \n* Linear Regression\n* XGB Regression\n* Hist Gradient Boosting\n\nThe best result was from Hist Gradient Boosting. \n\nIf you like my notebook, please upvote!!\n\n","5a3fee29":"# Importing the packages","91db57cb":"# Tabular Playground Series August 2021","df5d59b1":"# Training the model","00e6aeb8":"# Importing the data","7d95e460":"# Pre-Processig the data"}}