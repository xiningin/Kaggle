{"cell_type":{"61d4ceda":"code","161473fe":"code","0539bfb9":"code","3d937014":"code","f5fa5220":"code","ebff9d54":"code","5abaa6a3":"code","22f1f179":"code","3e83893d":"code","6a1e1a33":"code","e7e801cc":"code","51b5e405":"code","1d40632a":"code","fedf3a35":"code","eae3059b":"markdown","76f0cd74":"markdown","822a6d75":"markdown","fbca457d":"markdown","da9e8691":"markdown"},"source":{"61d4ceda":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\n\n## Downloading Keras Libraries\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img\nfrom sklearn.metrics import classification_report, confusion_matrix","161473fe":"train_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/train\/'\nval_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/val\/'\ntest_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/test\/'\n\nprint(os.listdir(train_folder))","0539bfb9":"train_n = train_folder+'NORMAL\/'\ntrain_p = train_folder+'PNEUMONIA\/'","3d937014":"# Getting the name of a pic and the location of that specific example\n\n# normal pic\n\nrand_norm = np.random.randint(0, len(train_n))\nnorm_pic = os.listdir(train_n)[rand_norm]\n\nnorm_pic_address = train_n + norm_pic\n\nprint(norm_pic_address)\n\n# pneumonia pic\n\nrand_norm = np.random.randint(0, len(train_n))\npneumonia_pic = os.listdir(train_p)[rand_norm]\n\npneumonia_pic_address = train_p + pneumonia_pic\n\nprint(pneumonia_pic_address)\n\nnormal_pic = Image.open(norm_pic_address)\npneumonia_pic = Image.open(pneumonia_pic_address)\n","f5fa5220":"# Plotting these images\n\nf = plt.figure(figsize=(10,6))\na1 = f.add_subplot(1,2,1)\nimg_plot = plt.imshow(normal_pic)\na1.set_title('Normal')\n\na2 = f.add_subplot(1,2,2)\nimg_plot = plt.imshow(pneumonia_pic)\na2.set_title('Pneumonia')","ebff9d54":"cnn = Sequential()\n\n# First convolution layer\ncnn.add(Conv2D(32,(3,3), activation = 'relu',input_shape = (64,64,3)))\n\n# 1st Max pooling layer\ncnn.add(MaxPooling2D(pool_size = (2,2)))\n\n# Second convolution layer\ncnn.add(Conv2D(32,(3,3), activation = 'relu'))\n\n# 2nd Max pooling layer\ncnn.add(MaxPooling2D(pool_size = (2,2)))\n\n# Flatten the layer\ncnn.add(Flatten())\n\n# Fully connected layers\ncnn.add(Dense(activation = 'relu', units = 128))\ncnn.add(Dense(activation = 'sigmoid', units = 1))\n\n# Compile the neural network\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","5abaa6a3":"number_test_samples = 600\nbatch_size = 32\n","22f1f179":"train_datagen = ImageDataGenerator(rescale = 1\/255,\n                                    shear_range = 0.2,\n                                    zoom_range = 0.2,\n                                    horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(1\/255)\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/train', \n                                                 target_size = (64,64),\n                                                batch_size = 32,\n                                                class_mode = 'binary')\n\nvalidation_generator = train_datagen.flow_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/val', \n                                                 target_size = (64,64),\n                                                batch_size = 32,\n                                                class_mode = 'binary')\n\ntest_set = train_datagen.flow_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/test', \n                                                 target_size = (64,64),\n                                                batch_size = 32,\n                                                class_mode = 'binary')","3e83893d":"# Visualizing images in the first batch\n\nbatch_image = training_set[0][0]\n\nplt.figure(figsize= (20,5))\n\nfor i in range(len(batch_image)):\n    plt.subplot(4,8,i+1)\n    pil_img = array_to_img(batch_image[i])\n    plt.imshow(pil_img)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","6a1e1a33":"cnn.summary()","e7e801cc":"len(validation_generator)","51b5e405":"cnn_model = cnn.fit_generator(training_set,\n                             steps_per_epoch = len(training_set),\n                             epochs = 50,\n                             validation_data = validation_generator,\n                             validation_steps = len(validation_generator))","1d40632a":"test_accu = cnn.evaluate_generator(test_set, steps = 624)","fedf3a35":"test_accu[1]*100","eae3059b":"### Setting the hyper parameters","76f0cd74":"### Loading the libraries","822a6d75":"### Building CNN model\n\n0. We will ensure that our images are of size 64,64,3 when we load them in using ImageDatagenerator\n\n1. We will first add a convolution layer which will define the total number of filters (32) our model will be learning and then we will also define the kernel size (3,3)\n\n2. We will then use a max pooling to reduce the spatial dimensionality\n\n3. We will add a second convolution layer of 32 filters with size 3,3\n\n4. We will again use a max pooling to reduce the dimensionality\n\n5. We will then flatten the input to 1-D and connect to two fully connected layers\n\n6. We will use the 'adam' optimizer and since it is has only two class, we will use 'binary_crossentropy'","fbca457d":"### Predicting the results\n\nNow that we have trained the model, we can use the test dataset to predict if the images should be labelled 'Pneumonia' or 'No Pneumonia (normal)'","da9e8691":"### Visualizing the dataset prior to fitting\n\nOnce training and testing sets are generated, it is important to investigate how images look like.\n\nUnderstanding the structure of the training and validation sets is important to manipulate them. Let's take the training set as an example.\n\n* 'train_set[0]' corresponds to the first set of image batches flowed from the source folder;\n* 'train_set[0][0]' corresponds to the first batch of 32 images included in the first set of batches;\n\nEach of the 16 images in this first batch can be accessed via the 'array_to_img' method and properly plotted.\nThe analysis of the first batch in the training set shows that augmentation has been successfully performed. Some images have been slightly shared, zoomed in and\/or flipped vertically. Also, it is evident that we are now dealing with grayscale images, as expected"}}