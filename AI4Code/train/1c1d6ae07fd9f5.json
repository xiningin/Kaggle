{"cell_type":{"035cc59c":"code","128ff957":"code","cf8d18cd":"code","3823189c":"code","0eea9cdc":"code","88ef5f4c":"code","2ba3f82c":"code","cf0ad2c1":"code","5924918c":"code","9ab9b7e3":"code","cc73544c":"code","47444548":"code","23131080":"code","a40da8c3":"code","60e1238f":"code","0a5c1814":"code","2718bb35":"code","acfbec6c":"code","1e59a221":"code","ec056fe7":"code","0609cc29":"code","56ade809":"code","25d2c0fe":"code","23123681":"code","36c4b0b2":"code","35e71278":"markdown","52003520":"markdown","f8a992cc":"markdown","c94c0cdd":"markdown","c07c7db5":"markdown","1cd5b011":"markdown","f8b06d9e":"markdown","03beb1b4":"markdown","eb5fdfbc":"markdown","c135fe5e":"markdown","812d5723":"markdown","b9396a9c":"markdown","ddcb2289":"markdown","b79e581f":"markdown","8596fa60":"markdown","48ae5413":"markdown","1a1bf856":"markdown","4821d37c":"markdown","75f1b250":"markdown","5286e961":"markdown","25ba24ec":"markdown","2f2598cb":"markdown","e1ead1ab":"markdown","a7fb375a":"markdown"},"source":{"035cc59c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\")\n%matplotlib inline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten ,Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\n","128ff957":"train_data = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(f'Training Data size is : {train_data.shape}')\nprint(f'Test Data size is : {test_data.shape}')","cf8d18cd":"train_data.head()","3823189c":"test_data.head()","0eea9cdc":"X = train_data.drop(['label'], axis=1, inplace=False)\ny = train_data['label']\n\nprint('X shape is ' , X.shape)\nprint('y shape is ' , y.shape)","88ef5f4c":"plt.figure(figsize=(12,10))\nplt.style.use('ggplot')\nfor i in  range(20)  :\n    plt.subplot(4,5,i+1)\n    plt.imshow(X.values[ np.random.randint(1,X.shape[0])].reshape(28,28))","2ba3f82c":"y.value_counts()","cf0ad2c1":"plt.figure(figsize=(12,12))\nplt.pie(y.value_counts(),labels=list(y.value_counts().index),autopct ='%1.2f%%' ,\n        labeldistance = 1.1,explode = [0.05 for i in range(len(y.value_counts()))] )\nplt.show()\n","5924918c":"X = X \/ 255.0\ntest_data = test_data \/ 255.0","9ab9b7e3":"X.shape","cc73544c":"X = X.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","47444548":"X.shape","23131080":"test_data.shape","a40da8c3":"ohe  = OneHotEncoder()\ny = np.array(y)\ny = y.reshape(len(y), 1)\nohe.fit(y)\ny = ohe.transform(y).toarray()","60e1238f":"y.shape","0a5c1814":"X_part, X_cv, y_part, y_cv = train_test_split(X, y, test_size=0.15, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_part.shape)\nprint('X_test shape is ' , X_cv.shape)\nprint('y_train shape is ' , y_part.shape)\nprint('y_test shape is ' , y_cv.shape)","2718bb35":"X_train, X_test, y_train, y_test = train_test_split(X_part, y_part, test_size=0.25, random_state=44, shuffle =True)\n\nprint('X_train shape is ' , X_train.shape)\nprint('X_test shape is ' , X_test.shape)\nprint('y_train shape is ' , y_train.shape)\nprint('y_test shape is ' , y_test.shape)","acfbec6c":"KerasModel = keras.models.Sequential([\n        keras.layers.Conv2D(filters = 32, kernel_size = (3,3),  activation = tf.nn.relu , padding = 'same'),\n        keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n        keras.layers.BatchNormalization(),\n        keras.layers.Conv2D(filters=32, kernel_size=(2,2),activation = tf.nn.relu , padding='same'),\n        keras.layers.MaxPool2D(),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(0.5),        \n        keras.layers.Flatten(),    \n        keras.layers.Dropout(0.5),        \n        keras.layers.Dense(64),    \n        keras.layers.Dropout(0.3),            \n        keras.layers.Dense(units= 10,activation = tf.nn.softmax ),                \n\n    ])","1e59a221":"KerasModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","ec056fe7":"KerasModel.fit(X_train,y_train,validation_data=(X_cv, y_cv),epochs=8,batch_size=64,verbose=1)","0609cc29":"KerasModel.summary()","56ade809":"ModelLoss, ModelAccuracy = KerasModel.evaluate(X_test, y_test)\n\nprint('Test Loss is {}'.format(ModelLoss))\nprint('Test Accuracy is {}'.format(ModelAccuracy ))","25d2c0fe":"y_pred = KerasModel.predict(X_test)\n\nprint('Prediction Shape is {}'.format(y_pred.shape))","23123681":"for i in list(np.random.randint(0,len(X_test) ,size= 20)) : \n    print(f'for sample  {i}  the predicted value is   {np.argmax(y_pred[i])}   , while the actual letter is {np.argmax(y_test[i])}')\n    if np.argmax(y_pred[i]) != np.argmax(y_test[i]) : \n        print('==============================')\n        print('Found mismatch . . ')\n        plt.figure(figsize=(5,5))\n        plt.style.use('ggplot')\n        plt.imshow(X_test[i].reshape(28,28))\n        plt.show()\n        print('==============================')","36c4b0b2":"FinalResults = KerasModel.predict(test_data)\nFinalResults = pd.Series(np.argmax(FinalResults,axis = 1) ,name=\"Label\")\n\nFileSubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),FinalResults],axis = 1)\nFileSubmission.to_csv(\"sample_submission.csv\",index=False)","35e71278":"then read the data ","52003520":"ow how X dimension looks like","f8a992cc":"and test data ? ","c94c0cdd":"_____\n\n# Data Processing\n\nthen we can define X & y data ","c07c7db5":"complie the model using adam optimizer & loss function : categorical crossentropy , since it's multilassifier","1cd5b011":"____\n\n# Dimension Adjusting\n\nit;s very important to adjust dimensions for data before building the CNN , let;s first normalize both X & test data . \n\nofcourse y will not be normalized or it will mislead the training","f8b06d9e":"Ok great , let's make a pie chart for it","03beb1b4":"____\n\n# Conv2D Model\n\nnow we can build our model , which will contain Conv layer then Maxpooling then normalize it \n\nthen second layer contain Conv then Max then normalize\n\nthen drop it out with 50 %\n\nthen Flatten it \n\nthen drop it out , then a FC with 64 units , then drop out , then last FC output layer ","eb5fdfbc":"then we need to reshape them , to be 4 dimensions , so first dimension will be open for all sample size , then 28 x 28 as image size , then 1","c135fe5e":"let's have a look to a random 20 numbers ","812d5723":"now how X dimension looks like","b9396a9c":"97% , good enough , & might be better if we increase epochs little bit\n\nnow to predict the results","ddcb2289":"greart . how it looks like now ? ","b79e581f":"____\n\nok no mismatch found . \n\nnow to submit the results ","8596fa60":"____\n\n# Data Splitting .\n\nwe have to split our data twice , first to get cross-validation data , then to get test data\n\nso first we'll get X_part, X_cv, y_part, y_cv , then later we'll divide \"part\" into training & testing data","48ae5413":"how it looks like ? ","1a1bf856":"also we have to categorize y , to convert single numbers like (7) into One Hot Matrix like [0 0 0 0 0 0 1 0 0 0]","4821d37c":"how is accuracy for test data , which never seen by the model yet","75f1b250":"# CNN for Digit Recognizer\nBy : Hesham Asem\n\n______\n\n\nlet's build Conv2D Neural Network , to classify tens of thousands of numbers which is in hand written format . . \n\nfirst to import needed libraries\n","5286e961":"great , now we'll split part into train & test data , so we can test the accuracy percisely","25ba24ec":"let's check random 20 samples , & we need to have a look to any mismatch images , to see why it confused","2f2598cb":"we also need to be sure that output numbers are kinda equally distributed","e1ead1ab":"now we can start training for 8 epochs , without exceeding to avoid any OF","a7fb375a":"now how y looks like ? "}}