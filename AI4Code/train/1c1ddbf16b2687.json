{"cell_type":{"073b00af":"code","c7944a44":"code","078611f3":"code","449df785":"code","9dd7c4aa":"code","6669c1ee":"code","8fd622c8":"code","53e75921":"code","dbfbe360":"code","baad8fb6":"code","d389d784":"code","f4072f1b":"code","95956188":"code","2fa1a0bf":"code","8966a85f":"markdown","c172cdad":"markdown","0a9da271":"markdown","b770c693":"markdown"},"source":{"073b00af":"# import standard libraries\nimport os\nos.environ['TF_KERAS'] = '1'\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom skimage.io import imread\nimport itertools\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport tensorflow as tf\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nsns.set(style='white', context='notebook', palette='deep')","c7944a44":"import sys\nprint(sys.version)","078611f3":"!pip install -U efficientnet\n!pip install keras-rectified-adam","449df785":"# import keras\n# from keras.models import Model\n# from keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\n# from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\n# tf.keras\nfrom tensorflow import keras\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten, GlobalAveragePooling2D\n\nimport efficientnet.tfkeras as enet","9dd7c4aa":"# load train data\ntrain_data = pd.read_csv('\/kaggle\/input\/syde522\/train.csv')\ntrain_dir = '\/kaggle\/input\/syde522\/train\/train'\ntest_dir = '\/kaggle\/input\/syde522\/test'\ntrain_data.head()","6669c1ee":"from keras.preprocessing.image import ImageDataGenerator\n\nnum_classes = len(train_data.Id)\n\n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# train_batch_size = 16 * tpu_strategy.num_replicas_in_sync\n# val_batch_size = 16 * tpu_strategy.num_replicas_in_sync\n\ntrain_batch_size = 64\nval_batch_size = 64\n\nval_split = 0.2 # 80:20 training to validation set\ntrain_num_sample = int(num_classes*(1-val_split))\nval_num_sample = int(num_classes*(val_split))\n\nSTEPS_PER_EPOCH = train_num_sample \/\/ train_batch_size\nVALIDATION_STEPS = val_num_sample \/\/ val_batch_size\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1\/255,\n    validation_split=val_split,\n    rotation_range=90,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='reflect'\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_data,\n    directory = train_dir,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(150,150),\n    subset=\"training\",\n    batch_size=train_batch_size,\n    shuffle=True,\n    class_mode=\"categorical\"\n)\n\nval_generator = train_datagen.flow_from_dataframe(\n    dataframe = train_data,\n    directory = train_dir,\n    x_col=\"Id\",\n    y_col=\"Category\",\n    target_size=(150,150),\n    subset=\"validation\",\n    batch_size=val_batch_size,\n    shuffle=True,\n    class_mode=\"categorical\"\n)\n","8fd622c8":"# number of classes\nnum_classes = len(train_data.Category.unique())\n\n# map class to index\ninteger_mapping = {x: i for i,x in enumerate(sorted(train_data.Category.unique()))}\nprint(integer_mapping)","53e75921":"# Preview 100 samples\nplt.figure(figsize=(30, 30))\nfor idx, (_, entry) in enumerate(train_data.sample(n=100).iterrows()):\n    \n    plt.subplot(10, 10, idx+1)\n    plt.imshow(imread(train_dir+'\/'+entry.Id))\n    plt.axis('off')\n    plt.title(entry.Category)\n    idx+=2","dbfbe360":"from tensorflow.keras.backend import sigmoid\n\nclass SwishActivation(Activation):\n    \n    def __init__(self, activation, **kwargs):\n        super(SwishActivation, self).__init__(activation, **kwargs)\n        self.__name__ = 'swish_act'\n\ndef swish_act(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nget_custom_objects().update({'swish_act': SwishActivation(swish_act)})","baad8fb6":"\nprint(tf.__version__)\n\nprint(tf.keras.__version__)\n\nenet_model = enet.EfficientNetB4(include_top=False, input_shape=(150,150,3), pooling='avg', weights='noisy-student')\n\nmodel = tf.keras.Sequential([\n    enet_model,\n    BatchNormalization(),\n    Dropout(0.3),\n\n    Dense(512),\n    BatchNormalization(),\n    Activation(swish_act),\n    Dropout(0.5),\n\n    Dense(128),\n    BatchNormalization(),\n    Activation(swish_act),\n    Dense(8, activation=\"softmax\")\n])\n\nmodel.summary()\n\n\n# from keras_radam.training import RAdamOptimizer\n\n# model.compile(optimizer=RAdamOptimizer(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# # instantiating the model in the strategy scope creates the model on the TPU\n# # with tpu_strategy.scope():\n# model = enet.EfficientNetB4(include_top=False, input_shape=(150,150,3), pooling='avg', weights='noisy-student')\n\n# x = model.output\n\n# x = BatchNormalization()(x)\n# x = Dropout(0.7)(x)\n\n# x = Dense(512)(x)\n# x = BatchNormalization()(x)\n# x = Activation(swish_act)(x)\n# x = Dropout(0.5)(x)\n\n# x = Dense(128)(x)\n# x = BatchNormalization()(x)\n# x = Activation(swish_act)(x)\n\n# # Output layer, categorical one-hot output\n# predictions = Dense(8, activation=\"softmax\")(x)\n\n# model_final = Model(inputs = model.input, outputs = predictions)\n\n# #     model_final.summary()\n\n# model_final.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n    ","d389d784":"# history = model_final.fit(\n#     train_generator,\n#     epochs = 140,\n#     steps_per_epoch = STEPS_PER_EPOCH,\n#     validation_data = val_generator,\n#     validation_steps = VALIDATION_STEPS\n# )\n\nfrom keras_radam import RAdam\n\nmodel.compile(optimizer=RAdam(lr=0.00008), loss='categorical_crossentropy', metrics=['accuracy'])\n\nes = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=30, restore_best_weights=True)\nhistory = model.fit_generator(\n        train_generator,\n        epochs = 120,\n        steps_per_epoch = STEPS_PER_EPOCH,\n        validation_data = val_generator,\n        validation_steps = VALIDATION_STEPS,\n        callbacks=[es]\n)","f4072f1b":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc) + 1)\n\nplt.plot(epochs,acc,'bo',label = 'Training Accuracy')\nplt.plot(epochs,val_acc,'b',label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,loss,'bo',label = 'Training loss')\nplt.plot(epochs,val_loss,'b',label = 'Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\nplt.show()","95956188":"# preparing the submission\n\nimport glob\nimport os\n\ntest_datagen = ImageDataGenerator(\n    rescale=1\/255\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(150,150),\n    batch_size=1,\n    shuffle=False,\n    class_mode=None\n)\n\npreds = model.predict_generator(\n    test_generator,\n    steps=len(test_generator.filenames)\n)\n\nimage_ids = [name.split('\/')[-1] for name in test_generator.filenames]\n\n# convert probability back to one-hot encoding\npredictions = preds.argmax(axis=-1)\n# map index to label strings\nstr_predictions = [sorted(train_data.Category.unique())[i] for i in predictions]\n\ndata = {'id': image_ids, 'Category':str_predictions} \nsubmission = pd.DataFrame(data)\nprint(submission.head())\n\nsubmission.to_csv('submission.csv', index=False)","2fa1a0bf":"!ls","8966a85f":"## Fit model\n\nUsing RAdam\n\nhttps:\/\/arxiv.org\/abs\/1908.03265","c172cdad":"# Swish activation function\nf = x*sigmoid(x)\n\nhttps:\/\/arxiv.org\/pdf\/1710.05941v1.pdf","0a9da271":"# Data augmentation and generator setup","b770c693":"# Model definition\nUsing efficientnetb4 and noisy-student weights for transfer learning"}}