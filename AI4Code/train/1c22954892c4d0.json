{"cell_type":{"cc2eb4ba":"code","75b8f081":"code","4d924207":"code","b479117b":"code","222a13ef":"code","b53d43b5":"code","206df8c7":"code","ebbc1c3b":"code","22641be1":"code","6807d135":"code","0c7013ea":"code","c2286df8":"code","58401810":"code","0c185786":"code","98d646f3":"code","a30ed276":"code","195b7509":"code","8e00923f":"code","386eb5a9":"code","76c9c4de":"code","75acca28":"code","58604d6d":"code","2d6d3672":"code","34d3d48b":"markdown","e2928d21":"markdown","03255fd3":"markdown","edaa26ca":"markdown","fdede2ef":"markdown","6d2520e6":"markdown","0d09b337":"markdown","b4f00896":"markdown","795d5eb8":"markdown","d1d84f10":"markdown","29b57cfe":"markdown"},"source":{"cc2eb4ba":"import glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.linear_model import LinearRegression","75b8f081":"lst_fire_img = glob.glob('\/kaggle\/input\/fire-dataset\/fire_dataset\/fire_images\/*.png')\nlst_non_fire_img = glob.glob('\/kaggle\/input\/fire-dataset\/fire_dataset\/non_fire_images\/*.png')","4d924207":"#lst_fire_img","b479117b":"#lst_non_fire_img","222a13ef":"#print('Number of images with fire : {}'.format(len(lst_fire_img)))\n#print('Number of images with non-fire : {}'.format(len(lst_non_fire_img)))","b53d43b5":"lst_images_random = random.sample(lst_fire_img,10) + random.sample(lst_non_fire_img,10)\nrandom.shuffle(lst_images_random)\n\nplt.figure(figsize = (20,20))\n\nfor i in range(len(lst_images_random)):\n    \n    plt.subplot(4,5,i+1)\n\n\n    if \"non_fire\" in lst_images_random[i]:\n        img = cv2.imread(lst_images_random[i])\n        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n        plt.imshow(img,cmap = 'gray')\n        plt.title('Yang\u0131n YOK')\n\n    else:\n        img = cv2.imread(lst_images_random[i])\n        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n        plt.imshow(img,cmap = 'gray')\n        plt.title(\"Yang\u0131n VAR\")\n\n\n\nplt.show()","206df8c7":"lst_fire = []\n\nfor x in lst_fire_img:\n  lst_fire.append([x,1])\n\nlst_nn_fire = []\n\nfor x in lst_non_fire_img:\n  lst_nn_fire.append([x,0])\n\nlst_complete = lst_fire + lst_nn_fire\nrandom.shuffle(lst_complete)","ebbc1c3b":"df = pd.DataFrame(lst_complete,columns = ['files','target'])\n#df.head(10)","22641be1":"filepath_img = '\/kaggle\/input\/fire-dataset\/fire_dataset\/non_fire_images\/non_fire.189.png'\ndf = df.loc[~(df.loc[:,'files'] == filepath_img),:]","6807d135":"#df.shape","0c7013ea":"#plt.figure(figsize = (10,10))\n\n\n#sns.countplot(x = \"target\",data = df)\n\n#plt.show()","c2286df8":"def preprocessing_image(filepath):\n  img = cv2.imread(filepath) #read\n  img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR) #convert\n  img = cv2.resize(img,(196,196))  # resize\n  img = img \/ 255 #scale\n  return img","58401810":"def create_format_dataset(dataframe):\n  X = []\n  y = []\n  for f,t in dataframe.values:\n    X.append(preprocessing_image(f))\n    y.append(t)\n  \n  return np.array(X),np.array(y)","0c185786":"X, y = create_format_dataset(df)","98d646f3":"X.shape,y.shape","a30ed276":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,stratify = y)","195b7509":"[X_train.shape,y_train.shape],...,[X_test.shape,y_test.shape]","8e00923f":"model = Sequential()\n\nmodel.add(Conv2D(128,(2,2),input_shape = (196,196,3),activation='relu'))\nmodel.add(Conv2D(64,(2,2),activation='relu'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(32,(2,2),activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dense(1,activation= \"sigmoid\"))","386eb5a9":"model.summary()","76c9c4de":"callbacks = [EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)]\nmodel.compile(optimizer='adam',loss = 'binary_crossentropy',metrics=['accuracy'])\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 10,batch_size = 32,callbacks = callbacks)","75acca28":"val_loss, val_acc = model.evaluate(X_test, y_test)\nprint('Test Accuracy: {}'.format(val_acc))","58604d6d":"y_pred = model.predict(X_test)\n\ny_pred = y_pred.reshape(-1)\ny_pred[y_pred<0.5] = 0\ny_pred[y_pred>=0.5] = 1\ny_pred = y_pred.astype('int')\n\nprint(y_pred)","2d6d3672":"plt.figure(figsize = (20,10))\n\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.show()","34d3d48b":"> Import etme ad\u0131mlar\u0131","e2928d21":"> Verileri Glob k\u00fct\u00fcphanesi ile y\u00fckl\u00fcyoruz","03255fd3":"> Al\u0131nan g\u00f6rsellerin listelemesini yap\u0131yoruz","edaa26ca":"> Burda train_test_split i\u015fleminden k\u0131saca bahsedicek olursak; dizilerimizi veya matrislerimizi rastgele subsetlere ve test datalar\u0131na d\u00f6n\u00fc\u015ft\u00fcr\u00fcyoruz.","fdede2ef":"> Non_fire_images i\u00e7indeki g\u00f6r\u00fcnt\u00fc 189 ile ilgili bir sorunumuz var, bu y\u00fczden onu b\u0131rak\u0131yoruz","6d2520e6":"* > Numpy ile dizi X ve y'yi olu\u015fturuyoruz. X, (196,196,3) \u015feklinde 998 g\u00f6r\u00fcnt\u00fcd\u00fcr, y hedef (998,) \u015feklidir.\n* > X \u00fczerinde g\u00f6rseller, Y \u00fczerinde ise 1,0 lar vard\u0131r.","0d09b337":"> T\u00fcm g\u00f6r\u00fcnt\u00fcleri \u00f6nceden i\u015fliyoruz","b4f00896":"> Edindi\u011fimiz veri setleri i\u00e7erisindeki verilerin nas\u0131l oldu\u011funu g\u00f6rmek i\u00e7in iki s\u0131n\u0131ftanda toplam 20 resim \u00e7iziyoruz","795d5eb8":"> Dosya yolu g\u00f6r\u00fcnt\u00fcleri ve etiketi i\u00e7eren bir veri \u00e7er\u00e7evesi olu\u015fturuyoruz (1 = yang\u0131n var, 0 = yang\u0131n yok)","d1d84f10":"> Veri setinin dengesiz oldu\u011funu g\u00f6rebiliriz, ancak ImageDataGenerator kullanm\u0131yoruz \u00e7\u00fcnk\u00fc buna ra\u011fmen sonu\u00e7 olduk\u00e7a iyi.","29b57cfe":"> Verilerin B\u00f6l\u00fcnmeden \u00f6nceki boyutu"}}