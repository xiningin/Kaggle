{"cell_type":{"b915428b":"code","94081c9b":"code","253681e9":"code","ff2300ef":"code","14b8ce95":"code","da7f67cc":"code","eed7ab3f":"code","b22739ba":"code","5e699104":"code","97e2c329":"code","9c4fdb59":"code","3de80606":"code","183fd487":"markdown"},"source":{"b915428b":"import os\nimport sys\nimport json\nimport datetime\nimport numpy as np\nimport skimage.draw","94081c9b":"SAMPLES_DIR = '\/kaggle\/input\/balloon\/balloon'\n\nDATA_DIR = '\/kaggle\/input'\n\n# Directory to save logs and trained model\nROOT_DIR = '\/kaggle\/working'","253681e9":"!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git ..\/Mask_RCNN\nos.chdir('..\/Mask_RCNN')\n#!python setup.py -q install","ff2300ef":"# Import Mask RCNN\nprint(os.path.join(ROOT_DIR, '..\/Mask_RCNN'))\nsys.path.append(os.path.join(ROOT_DIR, '..\/Mask_RCNN'))  # To find local version of the library\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log","14b8ce95":" !wget --quiet https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n #!ls -lh mask_rcnn_coco.h5\n\n COCO_WEIGHTS_PATH = \"mask_rcnn_coco.h5\"","da7f67cc":"# print(os.listdir(\".\/\"))\n# Directory to save logs and model checkpoints, if not provided\n# through the command line argument --logs\n# DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\") #\/kaggle\/working\/logs\nDEFAULT_LOGS_DIR = '\/kaggle\/working'\n# print(os.path.join(ROOT_DIR, \"logs\"))","eed7ab3f":"class BalloonConfig(Config):\n    \"\"\"Configuration for training on the toy  dataset.\n    Derives from the base Config class and overrides some values.\n    \"\"\"\n    # Give the configuration a recognizable name\n    NAME = \"balloon\"\n\n    # We use a GPU with 12GB memory, which can fit two images.\n    # Adjust down if you use a smaller GPU.\n    IMAGES_PER_GPU = 2\n\n    # Number of classes (including background)\n    NUM_CLASSES = 1 + 1  # Background + baloon\n\n    # Number of training steps per epoch\n    STEPS_PER_EPOCH = 100\n\n    # Skip detections with < 90% confidence\n    DETECTION_MIN_CONFIDENCE = 0.9","b22739ba":"############################################################\n#  Dataset\n############################################################\n\nclass BalloonDataset(utils.Dataset):\n\n    def load_balloon(self, dataset_dir, subset):\n        \"\"\"Load a subset of the Balloon dataset.\n        dataset_dir: Root directory of the dataset.\n        subset: Subset to load: train or val\n        \"\"\"\n        # Add classes. We have only one class to add.\n        self.add_class(\"balloon\", 1, \"balloon\")\n\n        # Train or validation dataset?\n        assert subset in [\"train\", \"val\"]\n        dataset_dir = os.path.join(dataset_dir, subset)\n\n        # Load annotations\n        # VGG Image Annotator saves each image in the form:\n        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n        #   'regions': {\n        #       '0': {\n        #           'region_attributes': {},\n        #           'shape_attributes': {\n        #               'all_points_x': [...],\n        #               'all_points_y': [...],\n        #               'name': 'polygon'}},\n        #       ... more regions ...\n        #   },\n        #   'size': 100202\n        # }\n        # We mostly care about the x and y coordinates of each region\n        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n        annotations = list(annotations.values())  # don't need the dict keys\n\n        # The VIA tool saves images in the JSON even if they don't have any\n        # annotations. Skip unannotated images.\n        annotations = [a for a in annotations if a['regions']]\n\n        # Add images\n        for a in annotations:\n            # Get the x, y coordinaets of points of the polygons that make up\n            # the outline of each object instance. There are stores in the\n            # shape_attributes (see json format above)\n            polygons = [r['shape_attributes'] for r in a['regions'].values()]\n\n            # load_mask() needs the image size to convert polygons to masks.\n            # Unfortunately, VIA doesn't include it in JSON, so we must read\n            # the image. This is only managable since the dataset is tiny.\n            image_path = os.path.join(dataset_dir, a['filename'])\n            image = skimage.io.imread(image_path)\n            height, width = image.shape[:2]\n\n            self.add_image(\n                \"balloon\",\n                image_id=a['filename'],  # use file name as a unique image id\n                path=image_path,\n                width=width, height=height,\n                polygons=polygons)\n\n    def load_mask(self, image_id):\n        \"\"\"Generate instance masks for an image.\n       Returns:\n        masks: A bool array of shape [height, width, instance count] with\n            one mask per instance.\n        class_ids: a 1D array of class IDs of the instance masks.\n        \"\"\"\n        # If not a balloon dataset image, delegate to parent class.\n        image_info = self.image_info[image_id]\n        if image_info[\"source\"] != \"balloon\":\n            return super(self.__class__, self).load_mask(image_id)\n\n        # Convert polygons to a bitmap mask of shape\n        # [height, width, instance_count]\n        info = self.image_info[image_id]\n        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n                        dtype=np.uint8)\n        for i, p in enumerate(info[\"polygons\"]):\n            # Get indexes of pixels inside the polygon and set them to 1\n            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n            mask[rr, cc, i] = 1\n\n        # Return mask, and array of class IDs of each instance. Since we have\n        # one class ID only, we return an array of 1s\n        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n\n    def image_reference(self, image_id):\n        \"\"\"Return the path of the image.\"\"\"\n        info = self.image_info[image_id]\n        if info[\"source\"] == \"balloon\":\n            return info[\"path\"]\n        else:\n            super(self.__class__, self).image_reference(image_id)                  ","5e699104":"def train(model):\n    \"\"\"Train the model.\"\"\"\n    # Training dataset.\n    dataset_train = BalloonDataset()\n    dataset_train.load_balloon(SAMPLES_DIR, \"train\")\n    dataset_train.prepare()\n\n    # Validation dataset\n    dataset_val = BalloonDataset()\n    dataset_val.load_balloon(SAMPLES_DIR, \"val\")\n    dataset_val.prepare()\n\n    # *** This training schedule is an example. Update to your needs ***\n    # Since we're using a very small dataset, and starting from\n    # COCO trained weights, we don't need to train too long. Also,\n    # no need to train all layers, just the heads should do it.\n    print(\"Training network heads\")\n    model.train(dataset_train, dataset_val,\n                learning_rate=config.LEARNING_RATE,\n                epochs=15,\n                layers='heads')  \n    \n#     model.save('64x3-CNN.model')\n\n# checkpoint = ModelCheckpoint(\"models\/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) #","97e2c329":"if __name__ == '__main__':\n    print('Train')\n    \n    config = BalloonConfig()\n    \n    model = modellib.MaskRCNN(mode=\"training\", config=config,\n                          model_dir=DEFAULT_LOGS_DIR)\n    \n    weights_path = COCO_WEIGHTS_PATH\n#     COCO_WEIGHTS_PATH = '..\/..\/..\/mask_rcnn_coco.h5'\n    \n    # Find last trained weights\n    # weights_path = model.find_last()[1]\n    \n    \n    model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n    \n    train(model)","9c4fdb59":"# remove files to allow committing (hit files limit otherwise)\n#!rm -rf \/kaggle\/working\/Mask_RCNN","3de80606":"# from IPython.display import HTML\n\n# def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n#     html = '<a href={filename}>{title}<\/a>'\n#     html = html.format(title=title,filename=filename)\n#     return HTML(html)\n\n# # create a link to download the dataframe which was saved with .to_csv method\n# # create_download_link(filename='\/kaggle\/working\/logs\/balloon20190325T1747\/mask_rcnn_balloon_0001.h5')\n# create_download_link(filename='balloon20190326T1301\/mask_rcnn_balloon_0001.h5')","183fd487":"### Install Matterport's Mask-RCNN model from github.\nSee the [Matterport's implementation of Mask-RCNN](https:\/\/github.com\/matterport\/Mask_RCNN)."}}