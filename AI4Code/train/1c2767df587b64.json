{"cell_type":{"d5b98a62":"code","7a6abf1a":"code","31ff8a14":"code","0791a314":"code","306e386c":"code","4c0e1b77":"code","44d71ec9":"code","43c1a4cc":"code","ebc3e2de":"code","02f78073":"code","d034ad87":"code","72a5cc0d":"code","5f04b11a":"code","1c761ffd":"code","ee25287d":"code","c95b5b7f":"code","f032092b":"code","caf6f605":"code","a469152d":"code","9e9f9dfc":"code","af5b62c0":"code","7fd93a29":"code","376ab3a3":"markdown","7a0b0997":"markdown","e977b680":"markdown","41421354":"markdown","0df06a22":"markdown","b6eb473f":"markdown","83a76ccf":"markdown","088041dd":"markdown","20cc54d5":"markdown","87d7fc6e":"markdown","d02ba6f9":"markdown","22a3d74a":"markdown","cfca413d":"markdown","6188e36a":"markdown"},"source":{"d5b98a62":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7a6abf1a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","31ff8a14":"df = pd.read_excel(r\"..\/input\/machinery-breaking-analysis\/Combined_Cycle_powerplant.xlsx\")","0791a314":"df.shape","306e386c":"df.columns","4c0e1b77":"df.head()","44d71ec9":"df.info()","43c1a4cc":"df.describe()","ebc3e2de":"#Check for missing values\ndf.duplicated().sum()","02f78073":"#Drop duplicates\ndf.drop_duplicates(inplace=True)","d034ad87":"#check for missing values\ndf.isnull().sum()","72a5cc0d":"#it comapres all column with all the columns and shows the graph\nsns.pairplot(df)\nplt.show()","5f04b11a":"cor=df.corr()\nplt.figure(figsize=(9,7))\nsns.heatmap(cor,annot=True,cmap='coolwarm')\nplt.show()","1c761ffd":"#Separate features and label\nx = df[['AT','V','AP','RH']]\ny = df[['PE']]","ee25287d":"# split data into train and test\nfrom sklearn.model_selection import train_test_split\nxtr,xts,ytr,yts = train_test_split(x,y,test_size=0.2)\n# we have to split the data into 80% as train and 20% as test so we have specified test_size as 0.2\nprint(x.shape)\nprint(xtr.shape)\nprint(xts.shape)\nprint(y.shape)\nprint(ytr.shape)\nprint(yts.shape)","c95b5b7f":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()","f032092b":"#train the model with the training data\nmodel.fit(xtr,ytr)","caf6f605":"new_data=np.array([[13.97,39.16,1016.05,84.6]])\nmodel.predict(new_data)","a469152d":"#get prediction of xts\nypred = model.predict(xts)\n","9e9f9dfc":"#calculating r2score\nfrom sklearn.metrics import r2_score\nr2_score(yts,ypred)\n","af5b62c0":"#To find the error\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(yts,ypred)","7fd93a29":"import joblib\n#from sklearn.externals import joblib\njoblib.dump(model,r\"..\\output\\kaagle\\working\\ccpp_model.pkl\")","376ab3a3":"## 6.Performance Analysis:-","7a0b0997":"Linear REgression can be used when the attributes are having some linear relationship between each other,\nso first we have to check the correlation values  . If the attributes are having a good correlation value,\nthen applying llinear regression algorithm it will give us an effective result .","e977b680":"From the figure it it clear that all the attributes are having some specific relation with each of the attribute so \nhere all the attribute are equally important . We do not need to rremove any column for further processing","41421354":"The percentage value are not that far in the data so it don't have any outlier .\n\n\nAccording to Chevbvey's theorem 68% of data lies between mean-std to mean+std","0df06a22":"## 4. Preprocessing:-","b6eb473f":"## 3. Feature Engineerring:-\n- Feature Extraction : Extracting relavant data\n- Feature Selection : Selecting relavant data","83a76ccf":"We got to know that our model is giving 92% of accurate value . So we are happy with our model so no potimisation\ntuning is required in this case .","088041dd":"## Data Science Structure:-\n#### 10 step logical performance for any datascience project\n1. Data Exploration,Domain understanding and Data collection\n2. Feature Engineering\n   a. Feature Extraction\n   b. Feature Selection\n4. Preprocessing\n5. Apply Machine learning algorithm \n6. Performance Analysis\n7. Optimisation and Tuning\n8. Export optimised model\n9. Deployment to Production\n10. Monitoring Perfomance in production","20cc54d5":"## 2. Data Cleaning:-","87d7fc6e":"## 7. Export model as a portable file - pickle file","d02ba6f9":"# Importing Libraries:","22a3d74a":"# **Load data**","cfca413d":"## 1. Data Exploration:-","6188e36a":"## 5.Applying ML Algorithm:-"}}