{"cell_type":{"7ec4d910":"code","2bcac762":"code","09998389":"code","40f7ea39":"code","e1b967d7":"code","eafab381":"code","8480415c":"code","0e7ab32c":"code","66fef0ac":"code","8520de24":"code","a6cbb741":"code","0b99f6dd":"code","f383d058":"code","6faab981":"code","d658c15d":"markdown","b8f0fa97":"markdown","2c3ae22a":"markdown","56e65632":"markdown","e361f36d":"markdown","4c978ded":"markdown","fc1ddd13":"markdown","a467b130":"markdown","e5792982":"markdown"},"source":{"7ec4d910":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","2bcac762":"print(os.listdir('..\/input'))","09998389":"x = np.load(\"..\/input\/clock_image.npy\")\ny = np.load(\"..\/input\/clock_time.npy\")","40f7ea39":"# print a few images\nfor i in range(5):\n    print (\"label\", \"{}:{}\".format(y[i][0], y[i][1]))\n    img = x[i]\n    plt.imshow(img, origin=\"lower\")\n    plt.show()\n","e1b967d7":"# split training and validation set\ndef preprocess(x, y):\n    x = x.reshape(x.shape[0], 64, 64, 1)\n    share = 400\n    x_train = x[:share]\n    y_train = y[:share]\n    x_val = x[share:]\n    y_val = y[share:]\n    return x_train, y_train, x_val, y_val\nx_train, y_train, x_val, y_val = preprocess(x, y)","eafab381":"#build cnn model\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Conv2D,MaxPool2D,Flatten\nfrom tensorflow.keras.optimizers import Adam\n\ndef build_model(x):\n    opt = Adam(lr=0.001)\n    \n    model = Sequential()\n    model.add(Conv2D(32, 5, padding = \"valid\", input_shape=x.shape[1:],activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Conv2D(64, 5, padding = \"valid\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Flatten())\n    model.add(Dense(256,activation=\"relu\"))\n    model.add(Dense(2))\n              \n    model.compile(loss='mse',\n              optimizer=opt,\n              metrics=['mse'])\n    return model\n\nmodel = build_model(x_train)","8480415c":"print(model.summary())\ndef train(model, x, y, xval, yval):\n    model.fit(x, y, batch_size=16, epochs=60, validation_data=(xval,yval))\ntrain(model, x_train, y_train, x_val, y_val)","0e7ab32c":"# How many cases are perfectly correct\ndef get_accuracy(x, ylabel):\n    r = np.round(model.predict(x))\n    diff = r - ylabel\n    a = np.min(np.abs(diff), axis=1)\n    return np.count_nonzero(a==0)\/a.shape[0]\n\nprint(\"train accuracy: \", get_accuracy(x_train, y_train))\nprint(\"validation accuracy: \", get_accuracy(x_val, y_val))","66fef0ac":"#build activation model\nfrom tensorflow.keras.models import  Model\nlayer_outputs = [layer.output for layer in model.layers] # Extracts the outputs of the top 12 layers\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(x_val[4:5])\n\nlayer_names = []\nfor layer in model.layers[:4]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \nimages_per_row = 8\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    n_features = layer_activation.shape[-1] # Number of features in the feature map\n    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n    n_cols = n_features \/\/ images_per_row # Tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n            channel_image \/= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, # Displays the grid\n                         row * size : (row + 1) * size] = channel_image\n    scale = 1. \/ size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n","8520de24":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Conv2D,MaxPool2D,Flatten,UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\n\ndef build_auto_encoder(x):\n    opt = Adam(lr=0.001)\n    model = Sequential()\n    \n    model.add(Conv2D(32, 3, padding = \"same\", input_shape=x.shape[1:],activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    model.add(Conv2D(32, 3, padding = \"same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2), strides=2))\n    \n    model.add(Conv2D(32, 3, padding = \"same\", input_shape=x.shape[1:],activation=\"relu\"))\n    model.add(UpSampling2D(size=(2,2)))\n    model.add(Conv2D(32, 3, padding = \"same\", activation=\"relu\"))\n    model.add(UpSampling2D(size=(2,2)))\n    model.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n    \n    model.compile(loss='binary_crossentropy',\n              optimizer=opt)\n    return model\nauto_encoder = build_auto_encoder(x_train)\n\n#train a regressor from encoded layer\n\n\n\n\n\n","a6cbb741":"auto_encoder.fit(x_train, x_train, batch_size=16, epochs=60, validation_data=(x_val,x_val))","0b99f6dd":"import random\n#visulaize difference\nplt.figure()\nn = 3\nc = np.random.choice(x_val.shape[0], n)\nxs = x_val[c]\nxs_pred = auto_encoder.predict(xs)\nfor i in range(n):\n    plt.subplot(n, 2, i*2 + 1)\n    plt.imshow(xs[i].reshape([64,64]))\n    plt.subplot(n, 2, i*2 + 2)\n    plt.imshow(xs_pred[i].reshape([64,64]))\nplt.show()","f383d058":"#build a regressor on top of the reduced representation\nfor layer in auto_encoder.layers:\n    layer.trainable = False\n    \nencoded = auto_encoder.layers[3].output\nf = Flatten()(encoded)\nd = Dense(128, activation=\"relu\")(f)\ndout = Dense(2)(d)\nmodel2 = Model(inputs = auto_encoder.inputs, outputs=dout)\n\nmodel2.compile(loss='mse',\n              optimizer=Adam(lr=0.001),\n              metrics=[\"mse\"])\n\n","6faab981":"#print (model2.summary())\nmodel2.fit(x_train, y_train, batch_size=100, epochs=60, validation_data=(x_val,y_val))","d658c15d":"Use an auto encoder framework","b8f0fa97":"## Introduction\nGreetings from the Kaggle bot! This is an automatically-generated kernel with starter code demonstrating how to read in the data and begin exploring. If you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.","2c3ae22a":"## Train the model","56e65632":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","e361f36d":"## Conclusion\nWithin 5 mintues, we could train 20 epochs of the cnn and achieve a 99.2% accuracy. From the intermediate layers' output image, we could see two clock finger is separated in some of these activation maps, which provides solid foundation for the output layer's prediction. \n","4c978ded":"## Build a cnn model","fc1ddd13":"# Visualize the intermediate layer output","a467b130":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","e5792982":"There is 0 csv file in the current version of the dataset:\n"}}