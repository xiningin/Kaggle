{"cell_type":{"08602810":"code","c589e579":"code","7094d486":"code","1bb461dc":"code","3ea1b41b":"code","292d15b4":"code","d14024e9":"code","d3be1b10":"code","055c164c":"code","df24b22e":"code","ba0da636":"code","6d250fba":"code","cd61e1ef":"code","6ed3197c":"code","d220b10c":"code","9b04efb1":"code","b31c4770":"code","d37dfa6c":"code","1af6fc23":"code","61dc0c57":"markdown","d09e21ca":"markdown","d8511326":"markdown","6f9c0f1d":"markdown","0d022890":"markdown","6d93db38":"markdown","5b88439d":"markdown","523d85e3":"markdown","48fbf40c":"markdown","b94c4933":"markdown","52779516":"markdown","5e9da9bc":"markdown","5a50996c":"markdown","2c1d8ebe":"markdown"},"source":{"08602810":"! pip install -q pip install git+https:\/\/github.com\/ildoonet\/pytorch-gradual-warmup-lr.git","c589e579":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport gc\nimport torch\nprint(torch.__version__)","7094d486":"train = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntest = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/train\/{}\/{}.npy\".format(image_id[0], image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/test\/{}\/{}.npy\".format(image_id[0], image_id)\n\ntrain['file_path'] = train['id'].apply(get_train_file_path)\ntest['file_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","1bb461dc":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","3ea1b41b":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    print_freq=100\n    num_workers=4\n    model_name='efficientnet_b0'  #'efficientnet_b0', 'vit_base_patch16_224', 'tf_efficientnet_b4_ns'\n    input_size=640   #512, 768, 1028, 'original'\n    output_size=384 \n    scheduler='CosineAnnealingLR' #'ReduceLROnPlateau', 'CosineAnnealingLR'\n    epochs=15\n    factor=0.2 # ReduceLROnPlateau\n    patience=4 # ReduceLROnPlateau\n    eps=1e-6 # ReduceLROnPlateau\n    T_max=15 # CosineAnnealingLR\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=32\n    optimizer='adamw'   #adamw', 'adam' \n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1100\n    seed=29\n    target_size=1\n    target_col='target'\n    n_fold=5\n    trn_folds=[1]\n    train=True\n    mode='spatial_3'   #'channel_3', 'channel_6', 'spatial_3', spatial_6'\n    aug_mode='mixup'   #'mixup', 'fmix'\n    warmup_epochs=2\n    multiplier=10\n    epoch_no_aug=0\n    \nif CFG.debug:\n    CFG.epochs=3\n    train=train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)   ","292d15b4":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/image-fmix\/FMix-master')\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nfrom fmix import sample_mask\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, AdamW\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","d14024e9":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","d3be1b10":"Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col])):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby(['fold', 'target']).size())","055c164c":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, mode=CFG.mode, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        label = self.labels[idx]\n        image = np.load(file_path)\n        \n        if self.mode in ['spatial_3', 'channel_3']:\n            image = image[::2]\n            image = image.astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n        if self.mode in ['spatial_3', 'spatial_6']: \n            image = np.vstack(image).transpose((1, 0))\n        elif self.mode in ['channel_3', 'channel_6']:\n            image = np.transpose(image, (1,2,0))\n            \n        if self.transform:\n            image = self.transform(image=image)['image']\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n            \n        label = torch.tensor(label).float()\n        return image, label\n    \nclass TestDataset(Dataset):\n    def __init__(self, df, mode=CFG.mode, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        image = np.load(file_path)\n        if self.mode in ['spatial_3', 'channel_3']:\n            image = image[::2].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n        if self.mode in ['spatial_3', 'spatial_6']:\n            image = np.vstack(image).transpose((1, 0))\n        elif self.mode in ['channel_3', 'channel_6']:\n            image = np.transpose(image, (1,2,0))\n        if self.transform:\n            image = self.transform(image=image)['image']\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n        return image\n    \ndef worker_init_fn(worker_id):                                                          \n    np.random.seed(np.random.get_state()[1][0] + worker_id)","df24b22e":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'train':\n        if type(CFG.input_size) == int:\n            return A.Compose([\n                   A.Resize(CFG.input_size, CFG.input_size),\n                   A.HorizontalFlip(p=.5),\n                   A.VerticalFlip(p=.5),\n                   A.ShiftScaleRotate(rotate_limit=0, p=.25),\n                   A.MotionBlur(p=.2),\n                   A.IAASharpen(p=.25),\n                   ToTensorV2(),\n            ])\n        else:\n            return A.Compose([\n                   A.HorizontalFlip(p=.5),\n                   A.VerticalFlip(p=.5),\n                   A.ShiftScaleRotate(rotate_limit=0, p=.25),\n                   A.MotionBlur(p=.2),\n                   A.IAASharpen(p=.25),\n                   ToTensorV2(),\n            ])\n            \n    elif data == 'valid':\n        if type(CFG.input_size) == int:\n            return A.Compose([\n                   A.Resize(CFG.input_size, CFG.input_size),\n                   ToTensorV2(),\n            ])\n        else:\n            return A.Compose([\n                   ToTensorV2(),\n            ])","ba0da636":"# https:\/\/github.com\/facebookresearch\/mixup-cifar10\/blob\/master\/train.py\ndef mixup_data(x, y, alpha=1, use_cuda=True):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n    mixed_x = (lam**.5) * x + ((1 - lam)**.5) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef fmix_data(data, targets, alpha=1.0, \n              decay_power=3.0,\n              max_soft=0.0,\n              shape=(CFG.input_size, CFG.input_size),):\n    lam, mask = sample_mask(alpha, decay_power, shape, max_soft)\n    indices = torch.randperm(data.size(0)).cuda()\n    shuffled_data = data[indices]\n    \n    targets_a = targets\n    targets_b = targets[indices]\n    x1 = torch.from_numpy(mask).float()*data\n    x2 = torch.from_numpy(1-mask).float()*shuffled_data\n    return (x1+x2), targets_a, targets_b, lam\n\ndef aug_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","6d250fba":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.n = 16\n        self.slope = .1\n        self.r = 1\n        \n        if self.cfg.mode in ['spatial_3', 'spatial_6']: \n            self.cnn = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=1)\n        elif self.cfg.mode == 'channel_3':\n            self.cnn = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=3)\n        elif self.cfg.mode == 'channel_6':\n            self.cnn = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=6)\n        if hasattr(self.cnn, \"fc\"):\n            nb_ft = self.cnn.fc.in_features\n            self.cnn.fc = nn.Identity()\n        elif hasattr(self.cnn, \"_fc\"):\n            nb_ft = self.cnn._fc.in_features\n            self.cnn._fc = nn.Identity()\n        elif hasattr(self.cnn, \"classifier\"):\n            nb_ft = self.cnn.classifier.in_features\n            self.cnn.classifier = nn.Identity()\n        elif hasattr(self.cnn, \"last_linear\"):\n            nb_ft = self.cnn.last_linear.in_features\n            self.cnn.last_linear = nn.Identity()\n        elif hasattr(self.cnn, \"head\"):\n            nb_ft = self.cnn.head.in_features\n            self.cnn.head = nn.Identity()\n        \n        self.block1 = nn.Sequential(\n                nn.Conv2d(1, self.n, kernel_size=(7, 7), stride=(1,1), padding=(1, 1), bias=False),\n                nn.LeakyReLU(negative_slope=self.slope),\n                nn.Conv2d(self.n, self.n, kernel_size=(1, 1), stride=(1,1), padding=(1, 1), bias=False),\n                nn.LeakyReLU(negative_slope=self.slope),\n                nn.BatchNorm2d(self.n))\n        self.block2 = nn.Sequential(\n                nn.Conv2d(self.n, self.n, kernel_size=(3, 3), stride=(1,1), padding=(1, 1), bias=False),\n                nn.BatchNorm2d(self.n),\n                nn.LeakyReLU(negative_slope=self.slope),\n                nn.Conv2d(self.n, self.n, kernel_size=(3, 3), stride=(1,1), padding=(1, 1), bias=False),\n                nn.BatchNorm2d(self.n))\n        self.block3 = nn.Sequential(\n                nn.Conv2d(self.n, self.n, kernel_size=(3, 3), stride=(1,1), padding=(1, 1), bias=False),\n                nn.BatchNorm2d(self.n))\n        self.block4 = nn.Sequential(\n                nn.Conv2d(self.n, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False))\n        self.fc = nn.Linear(nb_ft, self.cfg.target_size)\n\n    def forward(self, x):\n        res1 = F.interpolate(x, size=(self.cfg.output_size, self.cfg.output_size), mode='bilinear')\n        x = self.block1(x)\n        res2 = F.interpolate(x, size=(self.cfg.output_size, self.cfg.output_size), mode='bilinear')\n\n        x = self.block2(res2)\n        x += res2\n        if self.r > 1:\n            for _ in range(self.r):\n                res2 = x\n                x = self.block2(x)\n                x += res2\n \n        x = self.block3(x)\n        x += res2\n        \n        x = self.block4(x)\n        x += res1\n        \n        x = self.cnn(x)\n        x = self.fc(x)\n        return x","cd61e1ef":"class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) \/ self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch \/ self.total_epoch + 1.) for base_lr in self.base_lrs]","6ed3197c":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, mode):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        if mode == 'mixup':\n            images, targets_a, targets_b, lam = mixup_data(images, labels.view(-1, 1), use_cuda=True)\n            images = images.to(device)\n            targets_a = targets_a.to(device)\n            targets_b = targets_b.to(device)\n            y_preds = model(images)\n            loss = aug_criterion(criterion, y_preds, targets_a, targets_b, lam)\n            \n        elif mode == 'fmix':\n            images, targets_a, targets_b, lam = fmix_data(images, labels.view(-1, 1))\n            images = images.to(device)\n            targets_a = targets_a.to(device)\n            targets_b = targets_b.to(device)\n            y_preds = model(images)\n            loss = aug_criterion(criterion, y_preds, targets_a, targets_b, lam)\n\n        else:\n            images = images.to(device)\n            labels = labels.to(device)\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n            \n        batch_size = labels.size(0)\n        \n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}\/{2}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  #'LR: {lr:.6f}  '\n                  .format(\n                   epoch+1, step, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(train_loader)),\n                   grad_norm=grad_norm,\n                   #lr=scheduler.get_lr()[0],\n                   ))\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        \n        loss = criterion(y_preds.view(-1), labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}\/{1}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)\/len(valid_loader)),\n                   ))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions\n\ndef flip_inference(models, test_loader, device):\n    preds = []\n    for i, fold in enumerate(CFG.trn_folds):\n        model = models[i]\n        probs = []\n        for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            images = images.to(device)\n            with torch.no_grad():\n                y_preds1 = model(images)\n                y_preds2 = model(images.flip(-1))\n                y_preds3 = model(images.flip(-2))\n                y_preds4 = model(images.flip(-1).flip(-2))\n            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy() + y_preds3.sigmoid().to('cpu').numpy() + y_preds4.sigmoid().to('cpu').numpy()) \/ 4\n            probs.append(y_preds[:, 0])\n        preds.append(np.concatenate(probs))\n    return preds\n\ndef get_models(CFG, mode='loss'):\n    models = []\n    for fold in CFG.trn_folds:\n        model = CustomModel(cfg=CFG, pretrained=False)\n        path = OUTPUT_DIR + f'{CFG.model_name}_fold{fold}_best_{mode}.pth'\n        model.load_state_dict(torch.load(path)['model'])\n        model.eval()\n        model.to(device)\n        models.append(model)\n    return models","d220b10c":"def train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True,\n                              drop_last=True, worker_init_fn=worker_init_fn)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    # ====================================================\n    # optimizer\n    # ====================================================\n    def get_optimizer(lr=CFG.lr):\n        if CFG.optimizer == 'adam':\n            optimizer = Adam(model.parameters(), lr=lr, weight_decay=CFG.weight_decay, amsgrad=False)\n        elif CFG.optimizer == 'adamw':\n            optimizer = AdamW(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n        return optimizer\n    \n    # ====================================================\n    # criterion\n    # ====================================================\n    def get_criterion():\n        criterion = nn.BCEWithLogitsLoss()\n        return criterion\n    \n    # ====================================================\n    # scheduler\n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        if CFG.warmup_epochs > 0:\n            scheduler = GradualWarmupSchedulerV2(optimizer, multiplier=CFG.multiplier,\n                                                 total_epoch=CFG.warmup_epochs, \n                                                 after_scheduler=scheduler)\n        return scheduler \n    \n    # ====================================================\n    # training loop\n    # ====================================================\n    model = CustomModel(CFG, pretrained=True)\n    model.to(device)\n    \n    optimizer = get_optimizer()\n    scheduler = get_scheduler(optimizer)\n    criterion = get_criterion()\n\n    best_score = 0.\n    best_loss = np.inf\n\n    for epoch in range(CFG.epochs + CFG.epoch_no_aug):\n        start_time = time.time()\n        \n        # train\n        if epoch < CFG.epochs:\n            avg_loss = train_fn(train_loader, model, criterion, optimizer,\n                                 epoch, scheduler,\n                                 device,\n                                 mode=CFG.aug_mode)\n        else:\n            optimizer = get_optimizer(lr=1e-6)\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n            avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, mode='none')\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n    \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, GradualWarmupSchedulerV2):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n    \n    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth', \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","9b04efb1":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train \n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_folds:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","b31c4770":"if __name__ == '__main__':\n    main()","d37dfa6c":"models = get_models(CFG, mode='loss')\nmodels_ = get_models(CFG, mode='score')\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size*2, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\nfold_preds = flip_inference(models, test_loader, device)\nfold_preds_ = flip_inference(models_, test_loader, device)\npreds = np.mean(fold_preds, axis=0)\npreds_ = np.mean(fold_preds_, axis=0)","1af6fc23":"test = test[['id', 'target']]\ntest[CFG.target_col] = (preds + preds_) \/ 2\ntest.to_csv(OUTPUT_DIR+'submission.csv', index=False)\ndisplay(test)","61dc0c57":"# Utils","d09e21ca":"# Inference","d8511326":"# Transforms","6f9c0f1d":"# Train Loop","0d022890":"# CV split","6d93db38":"# CFG","5b88439d":"# Library","523d85e3":"# Learning Rate","48fbf40c":"# Dataset","b94c4933":"# Directory settings","52779516":"# Model","5e9da9bc":"# About \n\nWhen training CNNs, we typically resize our input images to some standard size before passing them to the model. For example, if the original images are `600 x 400` we might resize them to a resolution like `248 x 248` or `512 x 512` as a preprocessing step.\n\nBut this resizing results in information loss, and every time we resize images with `opencv`, we rely on some interpolation algorithm to decrease this resize-loss as much as possible. Instead of using `cv2.INTER_LINEAR` or `cv2.INTER_AREA`, why not train our own 'algorithm' to resize the images? The simplest example would be to take a `1024 x 1024` image and convolve it to size `512 x 512` before giving it to the CNN backbone. This way, the model learns how to best resize the images alongside the main training task. \n\nThis was done succesfully [here](https:\/\/www.kaggle.com\/c\/ranzcr-clip-catheter-line-classification\/discussion\/226557) and [here](https:\/\/www.kaggle.com\/c\/understanding_cloud_organization\/discussion\/118255) - two competitions in which the native image resolutions where > `1400 x 1400`. Seeing as we have fairly large 'images' for this competition, let's try it here. Instead of using either of the two above approaches, I want to try to implement the approach from [this paper](https:\/\/arxiv.org\/abs\/2103.09950) in which the proposed 'learned image resizer' looks like:\n\n![Capture.PNG](attachment:ccf6a3fd-9ee4-4cff-b6a6-4fd3d1588735.PNG)\n\nIn this commit, we will feed the learned image resizer original resolution images for it to resize to `256 x 256`. Note that I am not 100% sure I coded all this correctly, so if you see anything suspicious, please let me know. While I opted for the approach taken in the paper, the previously linked approaches seem fruitful as well and require less training time. \n\nCode template is taken from the one and only [yasufuminakama](https:\/\/www.kaggle.com\/yasufuminakama).","5a50996c":"# Helper functions","2c1d8ebe":"# Data Loading"}}