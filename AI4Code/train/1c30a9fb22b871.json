{"cell_type":{"95b03226":"code","cfbeee9e":"code","06dcbbd7":"code","88078a28":"code","8d064cf3":"code","076a9ae6":"code","29dc4b00":"code","d567d7b2":"code","6fef84ad":"code","b13787e1":"code","b46568cd":"code","9d005331":"code","f25d8de4":"code","ae850c9e":"code","e79c2220":"code","478d7f35":"code","55a88852":"code","21980e93":"code","3e00f07a":"code","b78b8989":"code","855ea00a":"code","47721bdb":"code","0e432da9":"code","cfb53271":"code","ccfea29e":"code","d5531183":"code","14bc3e95":"code","b831815e":"code","eb619147":"code","a644af43":"code","4744b4d7":"code","1eb357e5":"code","cc7e7ef8":"code","1ca89d9a":"code","55e4d121":"code","e3bf6a28":"code","bbb514d4":"code","f68d55ea":"code","d184a650":"code","3e952cea":"code","fc8aa13f":"code","cd95e3e2":"code","050d898f":"code","1c19dcaf":"code","d9c4ed73":"code","c6227703":"code","5720e344":"code","4ae15b53":"code","a1c5dea2":"code","308015ff":"markdown","4fc9f23d":"markdown","1e791f39":"markdown","f27be30f":"markdown","34180e81":"markdown","817fd94b":"markdown","3dfeafb6":"markdown","c574ae44":"markdown","e4140e9c":"markdown","572f017f":"markdown","d90e5537":"markdown","3f2bb117":"markdown","da17e586":"markdown","4dbc293c":"markdown","5ba532b0":"markdown","b648edb6":"markdown","b5756fd8":"markdown","2ee26bb8":"markdown","3439e9eb":"markdown","64a54595":"markdown","c129c111":"markdown","2d7f5486":"markdown","411121da":"markdown","d89b3091":"markdown","cde0d58d":"markdown","4cdb81ad":"markdown","63653aa1":"markdown","ca00e8fe":"markdown","73b923e9":"markdown"},"source":{"95b03226":"# for basic operations\nimport numpy as np\nimport pandas as pd\n\n# for getting the file path\nimport os\nprint(os.listdir('..\/input'))\n\n# for data visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport plotly.graph_objs as go","cfbeee9e":"# reading the dataset\n\ndata = pd.read_csv('..\/input\/online_shoppers_intention.csv')\n\n# checking the shape of the data\ndata.shape","06dcbbd7":"# checking the head of the data\n\ndata.head()","88078a28":"# describing the data\n\ndata.describe()","8d064cf3":"# checking the percentage of missing data contains in all the columns\n\nmissing_percentage = data.isnull().sum()\/data.shape[0]\nprint(missing_percentage)","076a9ae6":"# checking the Distribution of customers on Revenue\n\nplt.rcParams['figure.figsize'] = (18, 7)\n\nplt.subplot(1, 2, 1)\nsns.countplot(data['Weekend'], palette = 'pastel')\nplt.title('Buy or Not', fontsize = 30)\nplt.xlabel('Revenue or not', fontsize = 15)\nplt.ylabel('count', fontsize = 15)\n\n\n# checking the Distribution of customers on Weekend\nplt.subplot(1, 2, 2)\nsns.countplot(data['Weekend'], palette = 'inferno')\nplt.title('Purchase on Weekends', fontsize = 30)\nplt.xlabel('Weekend or not', fontsize = 15)\nplt.ylabel('count', fontsize = 15)\n\nplt.show()","29dc4b00":"data['VisitorType'].value_counts()","d567d7b2":"# plotting a pie chart for browsers\n\nplt.rcParams['figure.figsize'] = (18, 7)\nsize = [10551, 1694, 85]\ncolors = ['violet', 'magenta', 'pink']\nlabels = \"Returning Visitor\", \"New_Visitor\", \"Others\"\nexplode = [0, 0, 0.1]\nplt.subplot(1, 2, 1)\nplt.pie(size, colors = colors, labels = labels, explode = explode, shadow = True, autopct = '%.2f%%')\nplt.title('Different Visitors', fontsize = 30)\nplt.axis('off')\nplt.legend()\n\n# plotting a pie chart for browsers\nsize = [7961, 2462, 736, 467,174, 163, 300]\ncolors = ['orange', 'yellow', 'pink', 'crimson', 'lightgreen', 'cyan', 'blue']\nlabels = \"2\", \"1\",\"4\",\"5\",\"6\",\"10\",\"others\"\n\nplt.subplot(1, 2, 2)\nplt.pie(size, colors = colors, labels = labels, shadow = True, autopct = '%.2f%%', startangle = 90)\nplt.title('Different Browsers', fontsize = 30)\nplt.axis('off')\nplt.legend()\nplt.show()","6fef84ad":"# visualizing the distribution of customers around the Region\n\nplt.rcParams['figure.figsize'] = (18, 7)\n\nplt.subplot(1, 2, 1)\nplt.hist(data['TrafficType'], color = 'lightgreen')\nplt.title('Distribution of diff Traffic',fontsize = 30)\nplt.xlabel('TrafficType Codes', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\n\n# visualizing the distribution of customers around the Region\n\nplt.subplot(1, 2, 2)\nplt.hist(data['Region'], color = 'lightblue')\nplt.title('Distribution of Customers',fontsize = 30)\nplt.xlabel('Region Codes', fontsize = 15)\nplt.ylabel('Count', fontsize = 15)\n\nplt.show()","b13787e1":"# checking the no. of OSes each user is having\n\ndata['OperatingSystems'].value_counts()","b46568cd":"#checking the months with most no.of customers visiting the online shopping sites\n\ndata['Month'].value_counts()","9d005331":"# creating a donut chart for the months variations'\n\n# plotting a pie chart for different number of OSes users have.\n\nsize = [6601, 2585, 2555, 478, 111]\ncolors = ['orange', 'yellow', 'pink', 'crimson', 'lightgreen']\nlabels = \"2\", \"1\",\"3\",\"4\",\"others\"\nexplode = [0, 0, 0, 0, 0]\n\ncircle = plt.Circle((0, 0), 0.6, color = 'white')\n\nplt.subplot(1, 2, 1)\nplt.pie(size, colors = colors, labels = labels, explode = explode, shadow = True, autopct = '%.2f%%')\nplt.title('OSes Users have', fontsize = 30)\np = plt.gcf()\np.gca().add_artist(circle)\nplt.axis('off')\nplt.legend()\n\n# plotting a pie chart for share of special days\n\nsize = [3364, 2998, 1907, 1727, 549, 448, 433, 432, 288, 184]\ncolors = ['orange', 'yellow', 'pink', 'crimson', 'lightgreen', 'cyan', 'magenta', 'lightblue', 'lightgreen', 'violet']\nlabels = \"May\", \"November\", \"March\", \"December\", \"October\", \"September\", \"August\", \"July\", \"June\", \"February\"\nexplode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\ncircle = plt.Circle((0, 0), 0.6, color = 'white')\n\nplt.subplot(1, 2, 2)\nplt.pie(size, colors = colors, labels = labels, explode = explode, shadow = True, autopct = '%.2f%%')\nplt.title('Special Days', fontsize = 30)\np = plt.gcf()\np.gca().add_artist(circle)\nplt.axis('off')\nplt.legend()\n\nplt.show()","f25d8de4":"# product related duration vs revenue\n\nplt.rcParams['figure.figsize'] = (18, 15)\n\nplt.subplot(2, 2, 1)\nsns.boxenplot(data['Revenue'], data['Informational_Duration'], palette = 'rainbow')\nplt.title('Info. duration vs Revenue', fontsize = 30)\nplt.xlabel('Info. duration', fontsize = 15)\nplt.ylabel('Revenue', fontsize = 15)\n\n# product related duration vs revenue\n\nplt.subplot(2, 2, 2)\nsns.boxenplot(data['Revenue'], data['Administrative_Duration'], palette = 'pastel')\nplt.title('Admn. duration vs Revenue', fontsize = 30)\nplt.xlabel('Admn. duration', fontsize = 15)\nplt.ylabel('Revenue', fontsize = 15)\n\n# product related duration vs revenue\n\nplt.subplot(2, 2, 3)\nsns.boxenplot(data['Revenue'], data['ProductRelated_Duration'], palette = 'dark')\nplt.title('Product Related duration vs Revenue', fontsize = 30)\nplt.xlabel('Product Related duration', fontsize = 15)\nplt.ylabel('Revenue', fontsize = 15)\n\n# exit rate vs revenue\n\nplt.subplot(2, 2, 4)\nsns.boxenplot(data['Revenue'], data['ExitRates'], palette = 'spring')\nplt.title('ExitRates vs Revenue', fontsize = 30)\nplt.xlabel('ExitRates', fontsize = 15)\nplt.ylabel('Revenue', fontsize = 15)\n\n\nplt.show()\n","ae850c9e":"# page values vs revenue\n\nplt.rcParams['figure.figsize'] = (18, 7)\n\nplt.subplot(1, 2, 1)\nsns.stripplot(data['Revenue'], data['PageValues'], palette = 'autumn')\nplt.title('PageValues vs Revenue', fontsize = 30)\nplt.xlabel('PageValues', fontsize = 15)\nplt.ylabel('Revenue', fontsize = 15)\n\n# bounce rates vs revenue\nplt.subplot(1, 2, 2)\nsns.stripplot(data['Revenue'], data['BounceRates'], palette = 'magma')\nplt.title('Bounce Rates vs Revenue', fontsize = 30)\nplt.xlabel('Boune Rates', fontsize = 15)\nplt.ylabel('Revenue', fontsize = 15)\n\nplt.show()","e79c2220":"# weekend vs Revenue\n\ndf = pd.crosstab(data['Weekend'], data['Revenue'])\ndf.div(df.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (15, 5), color = ['orange', 'crimson'])\nplt.title('Weekend vs Revenue', fontsize = 30)\nplt.show()","478d7f35":"# Traffic Type vs Revenue\n\ndf = pd.crosstab(data['TrafficType'], data['Revenue'])\ndf.div(df.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (15, 5), color = ['lightpink', 'yellow'])\nplt.title('Traffic Type vs Revenue', fontsize = 30)\nplt.show()","55a88852":"# visitor type vs revenue\n\ndf = pd.crosstab(data['VisitorType'], data['Revenue'])\ndf.div(df.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (15, 5), color = ['lightgreen', 'green'])\nplt.title('Visitor Type vs Revenue', fontsize = 30)\nplt.show()\n","21980e93":"# region vs Revenue\n\ndf = pd.crosstab(data['Region'], data['Revenue'])\ndf.div(df.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True, figsize = (15, 5), color = ['lightblue', 'blue'])\nplt.title('Region vs Revenue', fontsize = 30)\nplt.show()","3e00f07a":"# lm plot\n\nplt.rcParams['figure.figsize'] = (20, 10)\n\nsns.lmplot(x = 'Administrative', y = 'Informational', data = data, x_jitter = 0.05)\nplt.title('LM Plot between Admistrative and Information', fontsize = 15)\n","b78b8989":"# month vs pagevalues wrt revenue\n\nplt.rcParams['figure.figsize'] = (18, 15)\nplt.subplot(2, 2, 1)\nsns.boxplot(x = data['Month'], y = data['PageValues'], hue = data['Revenue'], palette = 'inferno')\nplt.title('Mon. vs PageValues w.r.t. Rev.', fontsize = 30)\n\n# month vs exitrates wrt revenue\nplt.subplot(2, 2, 2)\nsns.boxplot(x = data['Month'], y = data['ExitRates'], hue = data['Revenue'], palette = 'Reds')\nplt.title('Mon. vs ExitRates w.r.t. Rev.', fontsize = 30)\n\n# month vs bouncerates wrt revenue\nplt.subplot(2, 2, 3)\nsns.boxplot(x = data['Month'], y = data['BounceRates'], hue = data['Revenue'], palette = 'Oranges')\nplt.title('Mon. vs BounceRates w.r.t. Rev.', fontsize = 30)\n\n# visitor type vs exit rates w.r.t revenue\nplt.subplot(2, 2, 4)\nsns.boxplot(x = data['VisitorType'], y = data['BounceRates'], hue = data['Revenue'], palette = 'Purples')\nplt.title('Visitors vs BounceRates w.r.t. Rev.', fontsize = 30)\n\nplt.show()","855ea00a":"# visitor type vs exit rates w.r.t revenue\n\nplt.rcParams['figure.figsize'] = (18, 15)\nplt.subplot(2, 2, 1)\nsns.violinplot(x = data['VisitorType'], y = data['ExitRates'], hue = data['Revenue'], palette = 'rainbow')\nplt.title('Visitors vs ExitRates wrt Rev.', fontsize = 30)\n\n# visitor type vs exit rates w.r.t revenue\nplt.subplot(2, 2, 2)\nsns.violinplot(x = data['VisitorType'], y = data['PageValues'], hue = data['Revenue'], palette = 'gnuplot')\nplt.title('Visitors vs PageValues wrt Rev.', fontsize = 30)\n\n# region vs pagevalues w.r.t. revenue\nplt.subplot(2, 2, 3)\nsns.violinplot(x = data['Region'], y = data['PageValues'], hue = data['Revenue'], palette = 'Greens')\nplt.title('Region vs PageValues wrt Rev.', fontsize = 30)\n\n#region vs exit rates w.r.t. revenue\nplt.subplot(2, 2, 4)\nsns.violinplot(x = data['Region'], y = data['ExitRates'], hue = data['Revenue'], palette = 'spring')\nplt.title('Region vs Exit Rates w.r.t. Revenue', fontsize = 30)\n\nplt.show()","47721bdb":"# Inputing Missing Values with 0\n\ndata.fillna(0, inplace = True)\n\n# checking the no. of null values in data after imputing the missing values\ndata.isnull().sum().sum()","0e432da9":"# Q1: Time Spent by The Users on Website vs Bounce Rates\n\n'''\nBounce Rate :The percentage of visitors to a particular website who navigate away from the site after \nviewing only one page.\n'''\n# let's cluster Administrative duration and Bounce Ratw to different types of clusters in the dataset.\n# preparing the dataset\nx = data.iloc[:, [1, 6]].values\n\n# checking the shape of the dataset\nx.shape\n\n\nfrom sklearn.cluster import KMeans\n\nwcss = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i,\n              init = 'k-means++',\n              max_iter = 300,\n              n_init = 10,\n              random_state = 0,\n              algorithm = 'elkan',\n              tol = 0.001)\n    km.fit(x)\n    labels = km.labels_\n    wcss.append(km.inertia_)\n    \nplt.rcParams['figure.figsize'] = (15, 7)\nplt.plot(range(1, 11), wcss)\nplt.grid()\nplt.tight_layout()\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()","cfb53271":"km = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means = km.fit_predict(x)\n\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'pink', label = 'Un-interested Customers')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'yellow', label = 'General Customers')\nplt.scatter(x[y_means == 2, 0], x[y_means == 2, 1], s = 100, c = 'cyan', label = 'Target Customers')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.title('Administrative Duration vs Duration', fontsize = 20)\nplt.grid()\nplt.xlabel('Administrative Duration')\nplt.ylabel('Bounce Rates')\nplt.legend()\nplt.show()","ccfea29e":"# informational duration vs Bounce Rates\nx = data.iloc[:, [3, 6]].values\n\nwcss = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i,\n              init = 'k-means++',\n              max_iter = 300,\n              n_init = 10,\n              random_state = 0,\n              algorithm = 'elkan',\n              tol = 0.001)\n    km.fit(x)\n    labels = km.labels_\n    wcss.append(km.inertia_)\n    \nplt.rcParams['figure.figsize'] = (15, 7)\nplt.plot(range(1, 11), wcss)\nplt.grid()\nplt.tight_layout()\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()","d5531183":"km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means = km.fit_predict(x)\n\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'pink', label = 'Un-interested Customers')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'yellow', label = 'Target Customers')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.title('Informational Duration vs Bounce Rates', fontsize = 20)\nplt.grid()\nplt.xlabel('Informational Duration')\nplt.ylabel('Bounce Rates')\nplt.legend()\nplt.show()","14bc3e95":"# informational duration vs Bounce Rates\nx = data.iloc[:, [1, 7]].values\n\nwcss = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i,\n              init = 'k-means++',\n              max_iter = 300,\n              n_init = 10,\n              random_state = 0,\n              algorithm = 'elkan',\n              tol = 0.001)\n    km.fit(x)\n    labels = km.labels_\n    wcss.append(km.inertia_)\n    \nplt.rcParams['figure.figsize'] = (15, 7)\nplt.plot(range(1, 11), wcss)\nplt.grid()\nplt.tight_layout()\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()","b831815e":"km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means = km.fit_predict(x)\n\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'pink', label = 'Un-interested Customers')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'yellow', label = 'Target Customers')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.title('Administrative Clustering vs Exit Rates', fontsize = 20)\nplt.grid()\nplt.xlabel('Administrative Duration')\nplt.ylabel('Exit Rates')\nplt.legend()\nplt.show()","eb619147":"# informational duration vs Bounce Rates\nx = data.iloc[:, [13, 14]].values\n\nwcss = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i,\n              init = 'k-means++',\n              max_iter = 300,\n              n_init = 10,\n              random_state = 0,\n              algorithm = 'elkan',\n              tol = 0.001)\n    km.fit(x)\n    labels = km.labels_\n    wcss.append(km.inertia_)\n    \nplt.rcParams['figure.figsize'] = (15, 7)\nplt.plot(range(1, 11), wcss)\nplt.grid()\nplt.tight_layout()\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()","a644af43":"km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means = km.fit_predict(x)\n\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'pink', label = 'Un-interested Customers')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'yellow', label = 'Target Customers')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.title('Region vs Traffic Type', fontsize = 20)\nplt.grid()\nplt.xlabel('Region')\nplt.ylabel('Traffic')\nplt.legend()\nplt.show()","4744b4d7":"# informational duration vs Bounce Rates\nx = data.iloc[:, [1, 13]].values\n\nwcss = []\nfor i in range(1, 11):\n    km = KMeans(n_clusters = i,\n              init = 'k-means++',\n              max_iter = 300,\n              n_init = 10,\n              random_state = 0,\n              algorithm = 'elkan',\n              tol = 0.001)\n    km.fit(x)\n    labels = km.labels_\n    wcss.append(km.inertia_)\n    \nplt.rcParams['figure.figsize'] = (15, 7)\nplt.plot(range(1, 11), wcss)\nplt.grid()\nplt.tight_layout()\nplt.title('The Elbow Method', fontsize = 20)\nplt.xlabel('No. of Clusters')\nplt.ylabel('wcss')\nplt.show()","1eb357e5":"km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\ny_means = km.fit_predict(x)\n\nplt.scatter(x[y_means == 0, 0], x[y_means == 0, 1], s = 100, c = 'pink', label = 'Unproductive Customers')\nplt.scatter(x[y_means == 1, 0], x[y_means == 1, 1], s = 100, c = 'yellow', label = 'Target Customers')\nplt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:, 1], s = 50, c = 'blue' , label = 'centeroid')\n\nplt.title('Adminstrative Duration vs Region', fontsize = 20)\nplt.grid()\nplt.xlabel('Administrative Duration')\nplt.ylabel('Region Type')\nplt.legend()\nplt.show()","cc7e7ef8":"# one hot encoding \n\ndata1 = pd.get_dummies(data)\n\ndata1.columns","1ca89d9a":"# label encoding of revenue\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndata['Revenue'] = le.fit_transform(data['Revenue'])\ndata['Revenue'].value_counts()","55e4d121":"# getting dependent and independent variables\n\nx = data1\n# removing the target column revenue from x\nx = x.drop(['Revenue'], axis = 1)\n\ny = data['Revenue']\n\n# checking the shapes\nprint(\"Shape of x:\", x.shape)\nprint(\"Shape of y:\", y.shape)\n","e3bf6a28":"# splitting the data\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n\n# checking the shapes\n\nprint(\"Shape of x_train :\", x_train.shape)\nprint(\"Shape of y_train :\", y_train.shape)\nprint(\"Shape of x_test :\", x_test.shape)\nprint(\"Shape of y_test :\", y_test.shape)","bbb514d4":"# MODELLING\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nmodel = RandomForestClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\n# evaluating the model\nprint(\"Training Accuracy :\", model.score(x_train, y_train))\nprint(\"Testing Accuracy :\", model.score(x_test, y_test))\n\n# confusion matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.rcParams['figure.figsize'] = (6, 6)\nsns.heatmap(cm ,annot = True)\n\n# classification report\ncr = classification_report(y_test, y_pred)\nprint(cr)","f68d55ea":"# finding the Permutation importance\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model, random_state = 0).fit(x_test, y_test)\neli5.show_weights(perm, feature_names = x_test.columns.tolist())","d184a650":"# plotting the partial dependence plot for adminisrative duration\n\n# importing pdp\nfrom pdpbox import pdp, info_plots\n\nbase_features = x_test.columns.values.tolist()\n\nfeat_name = 'Administrative_Duration'\npdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","3e952cea":"# plotting partial dependency plot for Informational Duration\n\nbase_features = x_test.columns.tolist()\n\nfeat_name = 'Informational_Duration'\npdp_dist = pdp.pdp_isolate(model, x_test, base_features, feat_name)\n\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","fc8aa13f":"# let's take a look at the shap values\n\n# importing shap\nimport shap\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(x_test)\n\nshap.summary_plot(shap_values[1], x_test, plot_type = 'bar')","cd95e3e2":"shap.summary_plot(shap_values[1], x_test)","050d898f":"# let's create a function to check the customer's conditions\n\ndef customer_analysis(model, customer):\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(customer)\n    shap.initjs()\n    return shap.force_plot(explainer.expected_value[1], shap_values[1], customer)","1c19dcaf":"# let's do some real time prediction for patients\n\ncustomers = x_test.iloc[1,:].astype(float)\ncustomer_analysis(model, customers)","d9c4ed73":"# let's do some real time prediction for patients\n\ncustomers = x_test.iloc[15,:].astype(float)\ncustomer_analysis(model, customers)","c6227703":"# let's do some real time prediction for patients\n\ncustomers = x_test.iloc[100,:].astype(float)\ncustomer_analysis(model, customers)","5720e344":"# let's do some real time prediction for patients\n\ncustomers = x_test.iloc[150,:].astype(float)\ncustomer_analysis(model, customers)","4ae15b53":"# let's do some real time prediction for patients\n\ncustomers = x_test.iloc[200,:].astype(float)\ncustomer_analysis(model, customers)","a1c5dea2":"shap_values = explainer.shap_values(x_train.iloc[:50])\nshap.initjs()\n\nshap.force_plot(explainer.expected_value[1], shap_values[1], x_test.iloc[:50])","308015ff":"**Random Forest Classifier**","4fc9f23d":"## Trying to learn the user characteristics of in terms of time spent on the Website\n","1e791f39":"**Attribute Information:**\n\n* * The dataset consists of 10 numerical and 8 categorical attributes. \n* The 'Revenue' attribute can be used as the class label. \n* \n* \"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" and \"Product Related Duration\" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The \"Bounce Rate\", \"Exit Rate\" and \"Page Value\" features represent the metrics measured by \"Google Analytics\" for each page in the e-commerce site. The value of \"Bounce Rate\" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server during that session. The value of \"Exit Rate\" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The \"Page Value\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother\u2019s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina\u2019s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.\n\n","f27be30f":"### 2. Adminstrative Duration vs Region","34180e81":"**Splitting of the Data**","817fd94b":"**Force Plot**","3dfeafb6":"**Customer Analysis**","c574ae44":"**Partial Dependency Plots**","e4140e9c":"**Importing Some Basic Libraries**","572f017f":"## Clustering Analysis","d90e5537":"**By,  Looking at this Clustering plot, we can say confindently say that the customers who spent a longer administrative duration in a website are very less likely to bounce from the website that is navigating away from the website just after navigating one page of that website.**\n\n**There are Three Groups, The Pink Group is a group of customers who stay for shortest adminstrative duration and have highest chance for Navigating away from a w**","3f2bb117":"**Visualizing the Cluster using Scatter Plot.**","da17e586":"> Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from   1 to 10 clusters.\n\n> For each k, calculate the total within-cluster sum of square (wss).\n\n> Plot the curve of wss according to the number of clusters k.\n\n> The location of a bend (knee) in the plot is generally considered as an indicator of the appropriate number of       clusters.","4dbc293c":"**Bi-Variate Analysis**","5ba532b0":"**Evaluating Model**","b648edb6":"**According to this plot, the maximum bend is at third index, that is the number of Optimal no. of Clusters for Adminstrative Duration and Revenue is Three.\nLet's go to the next step, i.e., Plotting the Clusters.**","b5756fd8":"**Reading the Dataset**","2ee26bb8":"**Uni-Variate Analysis of the Data**","3439e9eb":"**3.Administrative Duration vs Exit Rates**","64a54595":"**The Elbow Method to Find out the Maximum no. of Optimal Clusters**","c129c111":"## Where from the Users of the Website come?","2d7f5486":"### 1. Region vs Traffic Type","411121da":"## Data Preprocessing","d89b3091":"**Some Analysis to Understand the Data**","cde0d58d":"**Multi-Variate Analysis**","4cdb81ad":"**Shap Values**","63653aa1":"**One Hot and Label Encoding**","ca00e8fe":"**1. Administrative Duration vs Bounce Rate**","73b923e9":"### 2. Informative Duration vs Bounce Rates"}}