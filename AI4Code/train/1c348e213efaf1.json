{"cell_type":{"f4a128f5":"code","6f107b92":"code","02016018":"code","aaccca57":"code","ac03bb60":"code","ace79bad":"code","f21def56":"code","7a3d7a4e":"code","c15d4bd4":"code","7e117054":"code","4f57b6d0":"code","b66314f6":"code","b06bbb58":"code","7efc7f42":"code","cb76feb7":"code","9db04e90":"code","53b215e5":"code","302c1269":"code","b8957243":"code","62e5093a":"code","e3d4a8b6":"code","da5aedd2":"code","2391c24e":"code","d4e3e339":"code","7c3a4f71":"code","9da365be":"code","ea315560":"code","9200f362":"markdown","cfae6fc3":"markdown","7a7c49ac":"markdown","f403a7ba":"markdown","6cbc66c4":"markdown","489cbedf":"markdown","8f0a6181":"markdown","2448bdd9":"markdown","351e4c8e":"markdown","b2dab551":"markdown","cdaeed48":"markdown","e785d01c":"markdown","8550dd6c":"markdown","d8be0339":"markdown","576f430e":"markdown","89b3fdd1":"markdown","19be734d":"markdown"},"source":{"f4a128f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6f107b92":"%ls","02016018":"import cv2\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm","aaccca57":"%pwd","ac03bb60":"df = pd.read_csv(\"..\/input\/urban-sound-8k-images\/UrbanSound8K.csv\")\ndf","ace79bad":"from matplotlib import pyplot\nfrom matplotlib.image import imread\n%matplotlib inline\nfor i in range(4):\n    filename = '..\/input\/urban-sound-8k-images\/Images\/Images\/fold' + str(df[\"fold\"][i]) + '\/' + df[\"slice_file_name\"][i] + '.jpg'\n    image = imread(filename)\n    pyplot.imshow(image)\n    pyplot.show()","f21def56":"from numpy import asarray\nfrom numpy import save\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n\nX = []\n\n# enumerate files in the directory\nfor i in tqdm(range(8732)):\n    filename = '..\/input\/urban-sound-8k-images\/Images\/Images\/fold' + str(df[\"fold\"][i]) + '\/' + df[\"slice_file_name\"][i] + '.jpg'\n    photo = load_img(filename, target_size=(224, 224))\n    # convert to numpy array\n    photo = img_to_array(photo, dtype=np.float16)\n    # store\n    X.append(photo)\n# convert to a numpy arrays\nX = asarray(X)\nprint(X.shape)\n# save the reshaped photos\nsave('X.npy', X)","7a3d7a4e":"Y = []\nfor i in tqdm(range(8732)):\n    Y.append(df[\"classID\"])\nY = np.asarray(Y)\nY = Y[0:1]\nY = Y.reshape(8732,)\nY.shape\nsave('label.npy',Y)","c15d4bd4":"!ls","7e117054":"# from numpy import load\n# X = load('X.npy')\n# Y = load('label.npy')\n# print(X.shape, Y.shape)\n# print(type(X))\n# print(type(Y))","4f57b6d0":"import sys \nnp.set_printoptions(threshold=sys.maxsize)\n#print(Y)","b66314f6":"!pip install np_utils\nimport tensorflow as tf\nfrom numpy import array\nfrom numpy import argmax\n\n# one hot encode\nY = tf.keras.utils.to_categorical(Y, num_classes=10)\n#print(Y)","b06bbb58":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)","7efc7f42":"%whos","cb76feb7":"import gc\ngc.collect()\ndel X \ndel Y \ngc.collect()","9db04e90":"%whos","53b215e5":"print(\"X_train shape: \", X_train.shape)\nprint(\"Y_train shape: \", Y_train.shape)\nprint(\"X_test shape: \", X_test.shape)\nprint(\"Y_test shape: \", Y_test.shape)","302c1269":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten","b8957243":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","62e5093a":"from keras.optimizers import Adam\nimport keras\nopt = Adam(learning_rate=0.001)\nmodel.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])","e3d4a8b6":"from keras.callbacks import ModelCheckpoint, EarlyStopping\nfilepath = 'VGG4_best.hdf5'\ncheckpoint = ModelCheckpoint(filepath=filepath,monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\ncallbacks = [checkpoint]\nhistory = model.fit(X_train, Y_train, batch_size=128, epochs = 50, validation_data = (X_test, Y_test), callbacks=callbacks, verbose = 1)","da5aedd2":"import matplotlib.pyplot as plt\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Test Accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","2391c24e":"plt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","d4e3e339":"gc.collect()\nmodel = keras.models.load_model(\"VGG4_best.hdf5\")","7c3a4f71":"score = model.evaluate(X_test, Y_test)\nprint(score)","9da365be":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nY_pred = model.predict(X_test)\nY_pred=np.argmax(Y_pred, axis=1)\nY_test=np.argmax(Y_test, axis=1)\ncm = confusion_matrix(Y_test, Y_pred)","ea315560":"print(cm)","9200f362":">Do not run the below block now. Run it only if you have closed the notebook before this and starting again.","cfae6fc3":">Printing label array Y to check its contents.","7a7c49ac":">Checking contents of RAM\n\n","f403a7ba":">Defining Model","6cbc66c4":">Stacking images in the form of a numpy array and saving it to Google drive for later use. This is to save processing time.\n---\nStoring it as file \"X.npy\"","489cbedf":">One Hot Encoding","8f0a6181":"> Clearing RAM due to memory limitations","2448bdd9":">Training loss vs Validation loss","351e4c8e":">Creating labels and storing in array Y\n---\nStoring it as file \"label.npy\"","b2dab551":"> Model Fitting\n---\n>Batch size: 128\n---\n>Epochs: 50\n---\n>Monitor Validation accuracy and save best model.","cdaeed48":">Optimizer: Adam\n---\n>Learning Rate: 0.001\n---\n>Loss: Categorical Crossentropy","e785d01c":">Reading UrbanSound8K.csv (Metadata)\n---\nMetadata: Metadata is \"data that provides information about other data\". In other words, it is \"data about data\". \n","8550dd6c":">Train vs Test accuracy","d8be0339":">Visualizing a few images\n---\nTo make sure it is working","576f430e":">Importing requisite libraries","89b3fdd1":"Making sure we are working in the required directory","19be734d":">80% for test and 20% for train."}}