{"cell_type":{"b2100bcf":"code","08691be0":"code","ce3d46ab":"code","1fe3e557":"code","6f490e6a":"code","ca2882dc":"code","90349e99":"code","47b6ef30":"code","ab3f1830":"code","17885c48":"code","bb40913c":"code","8f56b366":"code","d9c879b7":"code","0c088750":"code","5bfda599":"code","62edbdaa":"code","9d1f63fb":"code","0e15c619":"code","e635d522":"code","6e917a0a":"code","6901d350":"code","5292591d":"code","c0e769e1":"markdown","afd2d0a0":"markdown","20d42980":"markdown","c18ce2d3":"markdown"},"source":{"b2100bcf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08691be0":"DATA_DIR = '\/kaggle\/input\/titanic'\n\ntrain_data = pd.read_csv(\n    os.path.join(DATA_DIR, 'train.csv'),\n    index_col='PassengerId',\n)\ntest_data = pd.read_csv(\n    os.path.join(DATA_DIR, 'test.csv'),\n    index_col='PassengerId',\n)","ce3d46ab":"TARGET = 'Survived'","1fe3e557":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (14,8)\nsns.set()","6f490e6a":"# numeric\nnumeric_features = ['Fare',]\nfamily = ['Parch', 'SibSp']\n\n# categorical\nordinal_encode = ['Ticket', 'Name']\none_hot_encode = ['Sex', 'Embarked', 'Pclass']","ca2882dc":"# utilities for creating ML pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import cross_validate, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import (\n    FunctionTransformer, OneHotEncoder,\n    OrdinalEncoder, StandardScaler\n)","90349e99":"random_state = 42\nX = train_data.copy()\ny = X.pop(TARGET)\ndisplay(y.value_counts())\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)","47b6ef30":"def get_first_item(string):\n    try:\n        return string.split()[0]\n    except AttributeError as e:\n        return string","ab3f1830":"ordinal_pipeline = Pipeline([\n    ('get_first_item', FunctionTransformer(np.vectorize(get_first_item))),\n    ('ordinal_encode', OrdinalEncoder(\n        handle_unknown='use_encoded_value',\n        unknown_value=-100\n    )),\n])","17885c48":"one_hot_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('one_hot', OneHotEncoder(handle_unknown='ignore')),\n])","bb40913c":"numeric_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])","8f56b366":"summation_pipeline = Pipeline([\n    ('expand_dims', FunctionTransformer(np.expand_dims,\n                                        kw_args={'axis':-1})),\n    ('sum', FunctionTransformer(np.sum, kw_args={'axis':-2})),\n    ('numeric_pipeline', numeric_pipeline),\n])","d9c879b7":"transformers = ColumnTransformer([    \n    ('one_hot', one_hot_pipeline, one_hot_encode),\n    ('ordinal', ordinal_pipeline, ordinal_encode),\n    ('numeric', numeric_pipeline, numeric_features),\n    ('sum', summation_pipeline, family),\n])","0c088750":"# models\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier","5bfda599":"random_state = 42\nada_boost = AdaBoostClassifier(random_state=random_state)\ncatboost = CatBoostClassifier(\n    random_state=random_state,\n    verbose=False\n)\n\ndecision_tree = DecisionTreeClassifier(random_state=random_state)\nknn = KNeighborsClassifier(n_jobs=-1)\nlightgbm = LGBMClassifier(random_state=random_state)\nlogreg = LogisticRegression(n_jobs=-1)\nrandom_forest = RandomForestClassifier(\n    random_state=random_state,\n    n_jobs=-1\n)\n\nrbf_svc = SVC(random_state=random_state)\nxgboost = XGBClassifier(\n    eval_metric='logloss',\n    use_label_encoder=False,\n    random_state=random_state,\n    n_jobs=-1,\n    verbosity=1\n)\n\nmodels = {\n    'ada_boost': ada_boost,\n    'catboost': catboost,\n    'decision_tree': decision_tree,\n    'knn': knn,\n    'lightgbm': lightgbm,\n    'logreg': logreg,\n    'random_forest': random_forest,\n    'rbf_svc': rbf_svc,\n    'xgboost': xgboost,\n}","62edbdaa":"import time\n\nmodel_performance = []\n\nfor name, estimator in models.items():\n    test_models_pipeline = Pipeline([\n        ('transformers', transformers),\n        (name, estimator),\n    ], verbose=1)\n    start_time = time.perf_counter()\n    test_models_pipeline.fit(X_train, y_train)\n    fitting_time = time.perf_counter() - start_time\n    \n    start_time = time.perf_counter()\n    y_pred = test_models_pipeline.predict(X_test)\n    prediction_time = time.perf_counter() - start_time\n\n    roc_auc = roc_auc_score(y_test,y_pred)\n    accuracy = accuracy_score(y_test,y_pred)\n    model_performance.append([\n        name, fitting_time, prediction_time, roc_auc, accuracy\n    ])","9d1f63fb":"columns = ['model', 'fit time', 'prediction time', 'roc_auc', 'accuracy']\nperformance = pd.DataFrame(model_performance, columns=columns)\nperformance = performance.sort_values('accuracy', ascending=False)\nperformance.set_index('model', inplace=True)\nperformance","0e15c619":"fig, axes = plt.subplots(2, 2)\n\nfor i, col in enumerate(performance.columns):\n    ax = axes[i\/\/2, i%2]\n    sns.barplot(x=performance.index, y=col, data=performance, ax=ax)\n    ax.set_title(f\"Bar plot of {col}\", pad=-10)\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=15)\n\nplt.show()","e635d522":"pipe = Pipeline([\n    ('transformers', transformers),\n    ('model', random_forest),\n])","6e917a0a":"cross_val_params = {\n    'scoring': ['roc_auc', 'accuracy'],\n    'cv': 5,\n    'return_estimator': False,\n    'n_jobs': -1,\n    'verbose': 3\n}\nscores = cross_validate(pipe, X_train, y_train, **cross_val_params)\n\n# performance\nperformance_df = pd.DataFrame(index=['mean', 'standard deviation'])\nfor key, value in scores.items():\n    performance_df[key] =  value.mean(), value.std()\n\nperformance_df.T","6901d350":"y_pred = pipe.predict(X_test)\nprint(f\"ROC AUC: {roc_auc_score(y_test, y_pred)}\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")","5292591d":"predictions = pipe.predict(test_data)\n\noutput = pd.DataFrame({'PassengerId': test_data.index, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","c0e769e1":"# Titanic Modelling","afd2d0a0":"Split the data into a training and validation set","20d42980":"# Modelling","c18ce2d3":"# Loading the data"}}