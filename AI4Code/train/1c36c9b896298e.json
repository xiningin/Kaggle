{"cell_type":{"49b52e30":"code","10e8793d":"code","84cbd412":"code","06f31057":"code","8b253bdf":"code","63635f65":"code","9aa0e142":"code","bf74013d":"code","118f4d30":"code","dc0580eb":"code","56243b1e":"code","b0844326":"code","5167c66d":"code","f9ceaec4":"code","735aa73a":"code","87a7b973":"code","b2e139be":"code","562eae24":"code","a9a7e3be":"code","ae199708":"code","fb7faae1":"code","f48cd3a2":"code","a0dd95da":"code","67f058ce":"code","e339bcdd":"code","da2da13d":"code","d764982e":"code","254ce68c":"markdown","f3f00d34":"markdown","5ddac563":"markdown","c804266d":"markdown","43834646":"markdown","a13a62bd":"markdown","69b5b9c3":"markdown","5c82334e":"markdown","7d37579a":"markdown","4d63d1b0":"markdown","689f4bea":"markdown","e63bcd7c":"markdown","3b7ca052":"markdown","47a4fa47":"markdown","1f729a4d":"markdown","38f8ddf7":"markdown","281981e6":"markdown","c8f032d6":"markdown","85ba2b33":"markdown"},"source":{"49b52e30":"import numpy as np\nimport pandas as pd\n\ntrain_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","10e8793d":"def preprocessing_null(data_df):\n    # I drop features with many null values.\n    data_df.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'Id'], axis=1, inplace=True)\n    # I fill the null data of features with appropriate values.\n    Bsmtlist =  ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n    Bsmtlist2=['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF']\n    Garagelist = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n    Bathlist = ['BsmtFullBath', 'BsmtHalfBath']\n    Extlist = ['Exterior1st', 'Exterior2nd']\n    \n    data_df.loc[:, Bsmtlist]=data_df.loc[:, Bsmtlist].fillna('TA')\n    data_df['Electrical']=data_df['Electrical'].fillna('SBrkr')\n    data_df['LotFrontage']=data_df['LotFrontage'].fillna(data_df['LotFrontage'].mean())\n    data_df['FireplaceQu'] = data_df['FireplaceQu'].fillna('NA')\n    data_df.loc[:, Garagelist] = data_df.loc[:, Garagelist].fillna('NA')\n    data_df['GarageYrBlt']=data_df['GarageYrBlt'].fillna(2005)\n    data_df.loc[:, 'MasVnrType'] = data_df.loc[:, 'MasVnrType'].fillna('None')\n    data_df['MasVnrArea']=data_df['MasVnrArea'].fillna(0)\n    data_df.loc[:, Bsmtlist2]=data_df[Bsmtlist2].fillna(0)\n    data_df['TotalBsmtSF']=data_df['TotalBsmtSF'].fillna(0)\n    data_df['GarageArea']=data_df['GarageArea'].fillna(data_df['GarageArea'].median())\n    data_df['GarageCars']=data_df['GarageCars'].fillna(data_df['GarageCars'].median())\n    data_df[Bathlist]=data_df[Bathlist].fillna(0)\n    \n    data_df[Extlist]=data_df[Extlist].fillna('VinylSd')\n    data_df['MSZoning']=data_df['MSZoning'].fillna('TA')\n    data_df['Utilities']=data_df['Utilities'].fillna('AllPub')\n    data_df['KitchenQual']=data_df['KitchenQual'].fillna('TA')\n    data_df['Functional']=data_df['Functional'].fillna('Typ')\n    data_df['SaleType']=data_df['SaleType'].fillna('WD')\n    \n    return data_df","84cbd412":"train_target = train_df['SalePrice']\ntrain_feature = train_df.drop('SalePrice', axis=1)","06f31057":"train_feature = preprocessing_null(train_feature)\ntest_feature = preprocessing_null(test_df)","8b253bdf":"train_feature.info()","63635f65":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","9aa0e142":"train_corr = train_df\nplt.figure(figsize=(9, 9))\ncorr = train_corr.corr()\nsns.heatmap(corr)","bf74013d":"pd.set_option('display.max_columns', 500)\ncorr[corr>0.7] # 1stFlrSF-2ndFlrSF, GrLivArea-TotRmsAbvGrd, GarageYrBlt-YearBuilt, GarageArea-GarageCars's corr is over 0.7","118f4d30":"def drop_corr_ftr(data_df):\n    data_df=data_df.drop(['2ndFlrSF', 'TotRmsAbvGrd', 'GarageYrBlt', 'GarageArea'], axis=1)\n    \n    return data_df","dc0580eb":"train_feature = drop_corr_ftr(train_feature)\ntest_feature = drop_corr_ftr(test_feature)\nprint(train_feature.shape, test_feature.shape)","56243b1e":"def split_num_obj(data_df):\n    df_num = data_df.select_dtypes(exclude='object')\n    df_obj = data_df.select_dtypes(include='object')\n    \n    return df_num, df_obj","b0844326":"train_feature_num, train_feature_obj = split_num_obj(train_feature)\ntest_feature_num, test_feature_obj = split_num_obj(test_feature)","5167c66d":"train_dummies = pd.get_dummies(train_feature_obj)\ntest_dummies = pd.get_dummies(test_feature_obj)\n\nnot_in_train = [column for column in train_dummies.columns if column not in test_dummies.columns]\nnot_in_test = [column for column in test_dummies.columns if column not in train_dummies.columns]\n\nprint('##train_dummies_shape, test_dummies_shape##\\n',train_dummies.shape, test_dummies.shape, '\\n')\nprint('##not in train_dummies columns but in test_dummies columns##\\n', not_in_train, '\\n')\nprint('##not in test_dummies columns but in train_dummies columns##\\n', not_in_test)","f9ceaec4":"df_num_col = train_feature_num.columns","735aa73a":"fig, ax = plt.subplots(16, 2, figsize=(10, 80))\n\nfor i in range(0, train_feature_num.shape[1]):\n    row = int((i)\/2)\n    col = (i)%2\n    rand_ind = np.random.permutation(1460)[:200]\n    sns.scatterplot(x=train_feature.loc[rand_ind, df_num_col[i]], y=train_target, ax=ax[row][col])","87a7b973":"df_num_cat_col = df_num_col[[0, 3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 28, 29, 30, 31]]","b2e139be":"def split_num_cat(data_df_num):\n    data_df_num_cat = data_df_num[df_num_cat_col]\n    data_df_num_non_cat = data_df_num.drop(df_num_cat_col, axis=1)\n    \n    return data_df_num_cat, data_df_num_non_cat\n\ntrain_feature_num_cat, train_feature_num_non_cat = split_num_cat(train_feature_num) \ntest_feature_num_cat, test_feature_num_non_cat = split_num_cat(test_feature_num)\nprint(train_feature_num_cat.shape,test_feature_num_cat.shape)\nprint(train_feature_num_non_cat.shape, test_feature_num_non_cat.shape)","562eae24":"# concatenate train_dt and test_df\nall_data = pd.concat((train_df, test_df)).reset_index(drop=True)\nall_data.drop('SalePrice', axis=1, inplace=True)\nprint(all_data.shape)\n\n# preprocessing data\nall_data = preprocessing_null(all_data)\nall_data = drop_corr_ftr(all_data)\nprint(all_data.shape)\n\n# extract obj data for LabelEncoding\nall_data_num, all_data_obj = split_num_obj(all_data)\nprint(all_data_obj.shape)","a9a7e3be":"import warnings\nwarnings.filterwarnings(action='ignore')\n\nfrom sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\n\nfor col in all_data_obj.columns:\n    label.fit(all_data_obj.loc[:, col])\n    train_feature_obj.loc[:, col] = label.transform(train_feature_obj.loc[:, col])\n    test_feature_obj.loc[:, col] = label.transform(test_feature_obj.loc[:, col])","ae199708":"train_target = np.log1p(train_target)\ntrain_feature_num_non_cat = np.log1p(train_feature_num_non_cat)\ntest_feature_num_non_cat = np.log1p(test_feature_num_non_cat)","fb7faae1":"train_feature_fin = pd.concat([train_feature_num_cat, train_feature_num_non_cat, train_feature_obj], axis=1)\ntest_feature_fin = pd.concat([test_feature_num_cat, test_feature_num_non_cat, test_feature_obj], axis=1)","f48cd3a2":"cond1 = train_target>500000\ncond2 = train_feature_num_non_cat['GrLivArea']>4000","a0dd95da":"train_feature_fin = train_feature_fin.drop(train_feature_num_non_cat[cond1|cond2].index, axis=0)","67f058ce":"from sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# print best rmse and return best_estimator\ndef get_best_estimator(model, params):\n    grid_model = GridSearchCV(model, param_grid=params, scoring=\"neg_mean_squared_error\", cv=5)\n    grid_model.fit(train_feature_fin, train_target)\n    rmse = np.sqrt(-1*grid_model.best_score_)\n    print('{0}, param:{1}, rmse:{2}'.format(model.__class__.__name__, grid_model.best_params_,\\\n                                            np.round(rmse, 4)))\n    return grid_model.best_estimator_\n\nridge_params = {'alpha':[0.05, 0.1, 1, 5, 8, 10, 15]}\nlasso_params = {'alpha':[0.001, 0.005, 0.008, 0.05, 0.1, 0.3, 0.5, 1, 5, 10]}\nelastic_params = {'alpha':[0.05, 0.1, 0.5, 1, 3, 5, 8]}\nridge_reg = Ridge()\nlasso_reg = Lasso() \nelastic_reg = ElasticNet(l1_ratio=0.7)\n\nlasso_be = get_best_estimator(lasso_reg, lasso_params)\nridge_be = get_best_estimator(ridge_reg, ridge_params)\nelastic_be = get_best_estimator(elastic_reg, elastic_params)","e339bcdd":"lgbm_params = {\n    'max_depth':[5, 10, 15, 20, 25, 30],\n    'learning_rate':[0.01, 0.05, 0.1, 0.5, 1],\n}\nlgbm_reg = LGBMRegressor(n_estimators=1000)\n\nlgbm_be = get_best_estimator(lgbm_reg, lgbm_params)","da2da13d":"preds = np.expm1(lgbm_be.predict(test_feature_fin))","d764982e":"test=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nmy_submission = pd.DataFrame({'Id': test.Id,\n                             'SalePrice': preds})\nmy_submission.to_csv('submission.csv', index=False)","254ce68c":"### **test availability of Label encoding**","f3f00d34":"**we finish data preprocessing**","5ddac563":"i split num type fetures into cat and non-cat. because i tranform non-cat feature to log scale","c804266d":"## **combine data**","43834646":"## **Drop high corr feature**","a13a62bd":"## **Make all data for Label encoding**","69b5b9c3":"## **Data preprocessing**","5c82334e":"The columns below are category features.","7d37579a":"### **Load Data**","4d63d1b0":"## **log transform, Label encoding using all-data**","689f4bea":"## **Find category feature**","e63bcd7c":"## **Submit answer**","3b7ca052":"### **preprocessing null data**","47a4fa47":"split train data into feature data and target data ","1f729a4d":"#### Compare Ridge, Lasso, ElasticNet, LGBM","38f8ddf7":"**We need to add all-data(train+test) as there are columns that don't exist to apply LabelEncoding.**","281981e6":"## **Predict House Price**","c8f032d6":"### remove outlier of important features. **GrLivArea**","85ba2b33":"## **change log scale to original scale**"}}