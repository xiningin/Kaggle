{"cell_type":{"c4e3ae66":"code","92595f2d":"code","f0014f31":"code","7c688d9c":"code","b3763ad1":"code","41f6e30d":"code","6b462f6c":"code","7cdd38f2":"code","ff4fabe1":"code","07172265":"code","44fbd183":"code","69c078bb":"code","5546c683":"code","49c04044":"code","6abd677f":"code","28dfe7ef":"code","6f3547c7":"code","f337ef95":"code","9bcc8a11":"code","1a9aca8a":"code","9c98b962":"code","d04bd474":"code","56151aa4":"code","b4f0a628":"code","016ecba7":"code","8816dc83":"code","a9ae35b7":"code","eb1bbb23":"code","3187df5d":"markdown","80f71d00":"markdown","d1e6050e":"markdown","40501099":"markdown","2da5d02e":"markdown","dfad41f6":"markdown","ca852566":"markdown","5fefd7f9":"markdown","719a11c4":"markdown","7a0949c1":"markdown","84c3fec0":"markdown"},"source":{"c4e3ae66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport numpy as np \nimport pandas as pd \n\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import confusion_matrix\nimport cv2 \nimport torch\nimport torch.nn.functional as F\n\nimport gc\n","92595f2d":"data = np.genfromtxt(\"\/kaggle\/input\/digit-recognizer\/train.csv\", delimiter=',', skip_header=1)","f0014f31":"print(data.shape)\nX, y = data[:, 1:], data[:, 0]\n# Centring images to be of mean 0 and standard deviation of 1\nX = (X - np.mean(X, axis=1).reshape(-1, 1))\nX = X\/np.std(X).reshape(-1, 1)\nprint(f\"X-shape: {X.shape}\")\nprint(f\"y-shape: {y.shape}\")\nprint(np.mean(X[10, :]))\nprint(np.std(X[10, :]))","7c688d9c":"X_transformed = X.copy().reshape(X.shape[0], 28, 28)\nprint(X_transformed.shape)\nindeces = []\n\nfor i in range(0, 10):\n    indeces.append(np.where(y == i)[0][0])\n\ngs = GridSpec(2, 5)\n\naxes = []\nfor row in range(0, 2):\n    for col in range(0, 5):\n        axes.append(plt.subplot(gs[row, col]))\n\nfor row in range(0, 2):\n    for col in range(0, 5):\n        axes[row*5 + col].imshow(X_transformed[indeces[row* 5 + col]], cmap=\"gray\")\n        axes[row*5 + col].set_xticks([])\n        axes[row*5 + col].set_yticks([])\n\n        ","b3763ad1":"class DifferentTransformation(object):\n    \n    @staticmethod\n    def rotation(X, y, cols, rows, arr):\n        X_tr = []\n        y_tr = []\n        tx = 1\n        ty = 1\n        counter = 0\n        #iterate over examples\n        while counter < X.shape[0]:\n            for x_angle in arr:\n                M = cv2.getRotationMatrix2D((cols\/2, rows\/2), x_angle, 1)\n                X_tr.append(cv2.warpAffine(X[counter], M, (cols, rows)))\n                y_tr.append(y[counter])\n            counter += 1\n        \n        return np.asarray(X_tr), np.asarray(y_tr)\n    \n    @staticmethod\n    def translation(X, y, cols, rows, arr):\n        X_tr = []\n        y_tr = []\n        tx = 1\n        ty = 1\n        M = np.float32([[1, 0, tx], [0, 1, ty]])\n        counter = 0\n        #iterate over examples\n        while counter < X.shape[0]:\n            for i in  arr:\n                tx = i\n                for j in arr:\n                    M[0, 2] = tx\n                    M[1, 2] = ty\n                    X_tr.append(cv2.warpAffine(X[counter], M, (cols, rows)))\n                    y_tr.append(y[counter])\n                    ty = j\n            counter += 1\n        \n        return np.asarray(X_tr), np.asarray(y_tr)","41f6e30d":"# \nX_augmented, y_augmented = DifferentTransformation.rotation(X_transformed, y, X_transformed[0].shape[1], X_transformed[0].shape[0], [0, 15, 30, 45]) #In order to ensure that some numbers aren't flipped to be another number, like 6 and 9\n#X_augmented, y_augmented = DifferentTransformation.translation(X_transformed, y, X_transformed[0].shape[1], X_transformed[0].shape[0], list(range(-2, 2, 2)))\n","6b462f6c":"X_augmented.shape","7cdd38f2":"fig, axes = plt.subplots(1, 4)\naxes[0].imshow(X_augmented[np.where(y_augmented == 6)[0][0]])\naxes[1].imshow(X_augmented[np.where(y_augmented == 6)[0][1]])\naxes[2].imshow(X_augmented[np.where(y_augmented == 6)[0][2]])\naxes[3].imshow(X_augmented[np.where(y_augmented == 6)[0][3]])\naxes[0].set_xticks([])\naxes[1].set_xticks([])\naxes[2].set_xticks([])\naxes[3].set_xticks([])\naxes[0].set_yticks([])\naxes[1].set_yticks([])\naxes[2].set_yticks([])\naxes[3].set_yticks([])\nplt.show()","ff4fabe1":"X_train = None\nX_validation = None\ny_train = None\ny_validation = None\n\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_ind, test_ind in splitter.split(X_augmented, y_augmented):\n    X_train = X_augmented[train_ind]\n    y_train = y_augmented[train_ind]\n    X_validation = X_augmented[test_ind]\n    y_validation = y_augmented[test_ind]\n\nprint(X_train.shape)\nprint(X_validation.shape)","07172265":"fig, (ax1, ax2) = plt.subplots(2, 1)\n\nax1.hist(y_train, density=True)\nax2.hist(y_train, density=True)\nplt.show()","44fbd183":"X_train_tensor = torch.from_numpy(X_train)\ny_train_tensor = torch.from_numpy(y_train)\nX_validation_tensor = torch.from_numpy(X_validation)\ny_validation_tensor = torch.from_numpy(y_validation)\n\nX_train_tensor_4d = torch.ones((len(X_train_tensor), 1, 28, 28))\nX_train_tensor_4d[:, 0, :, :] = X_train_tensor\nX_validation_tensor_4d = torch.ones((len(X_validation_tensor), 1, 28, 28))\nX_validation_tensor_4d[:, 0, :, :] = X_validation_tensor\nX_train_tensor_4d.shape","69c078bb":"class LeNet5(torch.nn.Module):\n    \n    def __init__(self, *args, **kwargs):\n        super(LeNet5, self).__init__()\n        self.cnn1 = torch.nn.Conv2d(1, 6, (5, 5), 1)\n        self.pool = torch.nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        self.cnn2 = torch.nn.Conv2d(6, 16, (5, 5), 1)\n        self.cnn3 = torch.nn.Conv2d(16, 120, (5, 5), 1)\n        self.fc1 = torch.nn.Linear(120, 84)\n        self.fc2 = torch.nn.Linear(84, 10)\n        \n    def forward(self, x):\n        #Pad the image because in the original paper the first CNN had same padding\n        x = F.pad(x, (2, 2, 2, 2))#pad it from all sides\n        x = torch.tanh(self.cnn1(x))\n        x = self.pool(x)\n        x = torch.tanh(self.cnn2(x))\n        x = self.pool(x)\n        x = torch.tanh(self.cnn3(x))\n        # flatten the layer\n        x = x.view(-1, 120)#nx120\n        x = torch.tanh(self.fc1(x))\n        x = F.softmax(self.fc2(x), dim=1)#Apply softmax to the rows of the column vector.\n        \n        return x\n\n","5546c683":"def init_param(layer):\n    if type(layer) == torch.nn.Linear:\n        torch.nn.init.xavier_normal_(layer.weight)\n    if type(layer) == torch.nn.Conv2d:\n        torch.nn.init.xavier_uniform_(layer.weight)\n","49c04044":"model = LeNet5()\nmodel.apply(init_param)\ncounter = 1\n# Check the layers with their initalized values\n# for param in model.parameters():\n#     print(\"Level: \", counter)\n#     print(param)\n#     counter += 1","6abd677f":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\nloss_fn = torch.nn.CrossEntropyLoss()\ntraining_error = []\nvalidation_error = []\nprint(model)","28dfe7ef":"import time\n\nbatch_size = 256\nnum_batches = int(len(X_train_tensor_4d)\/batch_size)\n\nbegin = time.time()\n\nfor epoch in range(0, 5):\n    counter = 0\n    current_error = []\n    for batch in range(0, num_batches):\n        optimizer.zero_grad()\n        y_pred = model(X_train_tensor_4d[counter: counter + batch_size])\n        loss = loss_fn(y_pred, y_train_tensor[counter: counter + batch_size].type(torch.LongTensor))\n        loss.backward()\n        optimizer.step()\n        current_error.append(loss.item())\n        counter += batch_size\n    if counter < len(X_train_tensor_4d):\n        optimizer.zero_grad()\n        y_pred = model(X_train_tensor_4d[counter: ])\n        loss = loss_fn(y_pred, y_train_tensor[counter: ].type(torch.LongTensor))\n        loss.backward()\n        optimizer.step()\n        current_error.append(loss.item())\n        \n    y_pred = model(X_validation_tensor_4d)\n    \n    validation_error.append(loss_fn(y_pred, y_validation_tensor.type(torch.LongTensor)).item())\n    training_error.append(np.mean(current_error))\n    print(f\"#epoch: {epoch} and the -log training error is {np.mean(current_error)}\")    \n    print(f\"#epoch: {epoch} and the -log validation error is {validation_error[epoch]}\")\n\n    print(f\"Time taken to finish training the model is {time.time() - begin} sec\")","6f3547c7":"# Training vs Validation error\nplt.plot(training_error, c=\"green\")\nplt.plot(validation_error, c=\"red\")\nplt.legend([\"Training_error\", \"Validation_error\"])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"-log-likelihood\")\nplt.show()","f337ef95":"#Training confusion matrix \ny_pred = model(X_train_tensor_4d)\ny_p = torch.argmax(y_pred, dim=1)\ncnf = confusion_matrix(y_train_tensor, y_p)\n# plt.matshow(cnf)\n# plt.colorbar()\nprint(f\"Accuracy {np.sum(np.diag(cnf))\/len(X_train_tensor_4d)}\")\ncnf","9bcc8a11":"del X_train_tensor_4d\ndel y_train_tensor\ndel cnf\ndel y_pred","1a9aca8a":"#Validation confusion matrix \ny_pred = model(X_validation_tensor_4d)\ny_p = torch.argmax(y_pred, dim=1)\ncnf = confusion_matrix(y_validation_tensor, y_p)\nprint(f\"Accuracy {np.sum(np.diag(cnf))\/len(X_validation_tensor_4d)}\")\ncnf","9c98b962":"del X_validation_tensor_4d\ndel y_validation_tensor\ndel cnf\ndel y_pred","d04bd474":"data = np.genfromtxt(\"\/kaggle\/input\/digit-recognizer\/test.csv\", delimiter=',', skip_header=1)\ndata = data - np.mean(data, axis=1).reshape(-1, 1)\ndata = data\/np.std(data, axis=1).reshape(-1, 1)\nprint(np.mean(data[0]))\nprint(np.std(data[0]))\ndata.shape","56151aa4":"X_transformed = data.reshape(data.shape[0], 28, 28)\nX_tensor = torch.from_numpy(X_transformed)\nX_tensor_4d = torch.ones((len(X_tensor), 1, 28, 28))\nX_tensor_4d[:, 0, :, :] = X_tensor\nX_tensor_4d.shape","b4f0a628":"y_pred = model(X_tensor_4d)","016ecba7":"y_pred.shape","8816dc83":"results = pd.DataFrame(np.c_[torch.IntTensor(list(range(1, len(y_pred) + 1))), torch.argmax(y_pred, dim=1)], columns=[\"ImageId\", \"Label\"])\nresults.to_csv(\"submission.csv\", index=False)\nresults.shape","a9ae35b7":"fig, axes = plt.subplots(5, 5)\n\ncounter = 0\nfor row in range(0, 5):\n    for col in range(0, 5):\n        axes[row, col].imshow(X_tensor_4d[counter, 0, :, :])\n        axes[row, col].set_xticks([])\n        axes[row, col].set_yticks([])\n        counter += 1\nplt.show()","eb1bbb23":"torch.argmax(y_pred[0:25], dim=1)","3187df5d":"# Transforming our data from numpy to tensors","80f71d00":"# Confusion Matrix performance for the Training, and Validation set","d1e6050e":"# Building the LeNet-5 model from scratch","40501099":"## Initialize parameters","2da5d02e":"# Test Set Prediction","dfad41f6":"# Splitting Data into Train and validation set","ca852566":"# Data Augmentation","5fefd7f9":"# Training Model","719a11c4":"# Loading Data and Processing the Data","7a0949c1":"# Reference \nhttp:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-98.pdf","84c3fec0":"# Training  vs Validation error curve"}}