{"cell_type":{"42505c8e":"code","dbf28c72":"code","78aabc90":"code","d4808508":"code","e865daab":"code","cd434729":"code","eff4de57":"code","f89ddc84":"code","c3b24dbd":"code","d7e351c3":"code","8889628f":"code","a2bd64bf":"code","011005f9":"code","dfc7e2e8":"code","195744b5":"code","526c6e82":"code","2b2ec8d1":"code","c3339b7f":"code","b1a2da1f":"code","59693141":"code","7f389fc1":"code","87602d71":"code","4d771727":"code","22359552":"code","eaf3160a":"code","6cf270ce":"code","94b506c1":"code","918da5cb":"code","6294f866":"code","d06951e3":"code","8d096cd8":"code","6d3815c3":"code","c177b2b3":"code","3fbf10ec":"code","f072a00a":"code","8e7f69be":"code","9ecab832":"code","f09760cd":"code","e35bf0f7":"code","a55c8fdb":"code","71086331":"code","d8e0b0e8":"code","921fc9cc":"code","224a09f5":"code","4caaf801":"code","4a0be136":"code","39728939":"code","3a163fd0":"code","8b866379":"code","82535832":"code","971ece3e":"code","415702fa":"markdown","6a760863":"markdown","287df9dd":"markdown","81b48308":"markdown","8d853298":"markdown","c804b0c2":"markdown","eb565c3a":"markdown","02f469e9":"markdown","ba1a00b6":"markdown","30ad5d65":"markdown","7743e49f":"markdown","613550b6":"markdown","2b65377f":"markdown","8bc4359a":"markdown","bc2bf4b6":"markdown","9e66bc41":"markdown","4c55272d":"markdown"},"source":{"42505c8e":"# File operation\nimport os\nimport numpy as np\nimport pandas as pd\nimport missingno as msno\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport altair as alt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix\n\n# Modelling\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')","dbf28c72":"base_dir = \"..\/input\/breast-cancer-wisconsin-data\/data.csv\"","78aabc90":"df = pd.read_csv(base_dir)","d4808508":"df.head().T","e865daab":"df.shape","cd434729":"df.info()","eff4de57":"# Check the missing values\n\nmsno.matrix(df, figsize=(15,5));","f89ddc84":"# Drop unnecessary columns\n\ndf = df.drop([\"id\", \"Unnamed: 32\"], axis=1)","c3b24dbd":"df.diagnosis.value_counts().plot(kind=\"bar\", \n                                 title=\"Counts of Diagnosis Types\", \n                                 xlabel=\"Type\", \n                                 ylabel=\"Count\", \n                                 colormap=\"YlGn_r\");","d7e351c3":"# Splitting columns by fields for better analysis\n\nmean_columns = df.iloc[:, 1:11]\nse_columns = df.iloc[:, 11: 21]\nworst_columns = df.iloc[:, 21:31]","8889628f":"mean_columns.describe().T","a2bd64bf":"se_columns.describe().T","011005f9":"worst_columns.describe().T","dfc7e2e8":"fields = [\"mean\", \"se\", \"worst\"]\ncolumns = [\"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\", \"concavity\", \"concave points\", \"symmetry\", \"fractal_dimension\"]","195744b5":"fig, axs = plt.subplots(10,3, figsize=(25,45))\n\nfor col in range(len(columns)):\n    \n    for f in range(len(fields)):\n        \n        sns.histplot(df, \n                     x=columns[col]+\"_\"+fields[f], \n                     hue=\"diagnosis\", element=\"poly\", \n                     stat=\"count\", \n                     palette=[\"#7158e2\", \"#32ff7e\"],\n                     ax=axs[col][f])","526c6e82":"def heat(data, color, size):\n    \n    corr = data.corr()\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(corr)] = True\n    \n    plt.figure(figsize=size)\n    sns.heatmap(corr, mask=mask, annot=True, cmap=color)\n    plt.show()","2b2ec8d1":"heat(mean_columns, \"Reds\", (10,8))","c3339b7f":"heat(se_columns, \"Greens\", (10,8))","b1a2da1f":"heat(worst_columns, \"Blues\", (10,8))","59693141":"def scatter_columns(feature1, feature2, title):\n    \n    fig = go.Figure()\n    fig.update_layout(\n        title=title,\n        width=600,\n        height=400,\n        margin=dict(\n                    l=20,\n                    r=20,\n                    t=40,\n                    b=20,\n                )\n    )\n    \n    fig.add_trace(go.Scatter(x=df[feature1+\"_\"+fields[0]], \n                             y=df[feature2+\"_\"+fields[0]], \n                             mode=\"markers\", \n                             name=\"mean\",\n                             ))\n\n    fig.add_trace(go.Scatter(x=df[feature1+\"_\"+fields[1]], \n                             y=df[feature2+\"_\"+fields[1]], \n                             mode=\"markers\", \n                             name=\"se\",\n                             ))\n\n    fig.add_trace(go.Scatter(x=df[feature1+\"_\"+fields[2]], \n                             y=df[feature2+\"_\"+fields[2]], \n                             mode=\"markers\", \n                             name=\"worst\",\n                             ))\n    fig.show()","7f389fc1":"scatter_columns(\"perimeter\", \"radius\", \"Perimeter & Radius\")","87602d71":"scatter_columns(\"area\", \"radius\", \"Area & Radius\")","4d771727":"scatter_columns(\"area\", \"perimeter\", \"Area & Perimeter\")","22359552":"scatter_columns(\"concavity\", \"compactness\", \"Concavity & Compactless\")","eaf3160a":"scatter_columns(\"fractal_dimension\", \"compactness\", \"Fractal Dimension & Compactness\")","6cf270ce":"cols = [\"radius\", \"perimeter\", \"area\", \"compactness\", \"concavity\"]\n\nfig = make_subplots(rows=5, cols=1, \n                    subplot_titles=[ \"Radius & Concave Points\",\n                                     \"Perimeter & Concave Points\",\n                                     \"Area & Concave Points\",\n                                     \"Compactness & Concave Points\",\n                                     \"Concavity & Concave Points\",\n                                    ])\n    \nfor i in range(len(cols)):\n    \n    fig.update_layout(\n    width=900,\n    height=1600,\n    margin=dict(\n                l=40,\n                r=40,\n                t=30,\n                b=0,\n            )\n    )\n    \n    fig.update_xaxes(title_text=cols[i], row=i+1, col=1)\n    fig.update_yaxes(title_text=\"concave points\", row=i+1, col=1)\n    \n    fig.add_trace(go.Scatter(x=df[cols[i]+\"_\"+fields[0]],\n                             y=df[\"concave points\"+\"_\"+fields[0]], \n                             mode=\"markers\", \n                             name=\"mean\",\n                             ),\n                  row=i+1,\n                  col=1,\n                 )\n\n    fig.add_trace(go.Scatter(x=df[cols[i]+\"_\"+fields[1]], \n                             y=df[\"concave points\"+\"_\"+fields[1]], \n                             mode=\"markers\", \n                             name=\"se\",\n                             ),\n                 \n                  row=i+1,\n                  col=1,\n                 )\n\n    fig.add_trace(go.Scatter(x=df[cols[i]+\"_\"+fields[2]], \n                             y=df[\"concave points\"+\"_\"+fields[2]], \n                             mode=\"markers\", \n                             name=\"worst\",\n                            ),\n                 \n                  row=i+1,\n                  col=1,\n                 )\n                             \nfig.show()","94b506c1":"df.head()","918da5cb":"for col in range(len(columns)):\n    \n    for f in range(len(fields)):\n        \n        Q1 = df[columns[col]+\"_\"+fields[f]].quantile(0.25)\n        Q3 = df[columns[col]+\"_\"+fields[f]].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        lower_bound = Q1 - 1.5*IQR\n        upper_bound = Q3 + 1.5*IQR\n        \n        outliers = (df[columns[col]+\"_\"+fields[f]] < lower_bound) | (df[columns[col]+\"_\"+fields[f]] > upper_bound)\n        df[columns[col]+\"_\"+fields[f]][outliers] = df[columns[col]+\"_\"+fields[f]].mean()","6294f866":"x = df.drop(\"diagnosis\", axis=1)   # our feautures\ny = df.diagnosis                   # our label","d06951e3":"# For Diagnosis column, we have to transform benign-malign to 0-1 for better modeling\n\ny = pd.get_dummies(y)\ny = y.drop(\"B\", axis=1)  # we dropping the \"B\" column because we dont need it. If a label is Benign, then \"M\" column will be 0.","8d096cd8":"x.head()","6d3815c3":"y.head()","c177b2b3":"scaler = StandardScaler()\nx = scaler.fit_transform(x)","3fbf10ec":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","f072a00a":"print(f\"x_train: {x_train.shape}\")\nprint(f\"x_test: {x_test.shape}\")\nprint(f\"y_train: {y_train.shape}\")\nprint(f\"y_test: {y_test.shape}\")","8e7f69be":"x_train","9ecab832":"!pip install lightgbm\n!pip install xgboost","f09760cd":"from lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier","e35bf0f7":"algorithms = [LogisticRegression, \n              RidgeClassifier, \n              SVC, \n              LinearSVC, \n              RandomForestClassifier,\n              KNeighborsClassifier,\n              GaussianNB, \n              Perceptron, \n              SGDClassifier, \n              DecisionTreeClassifier,\n              AdaBoostClassifier,\n              GradientBoostingClassifier,\n              LGBMClassifier,\n              XGBClassifier,\n             ]","a55c8fdb":"df_algorithms = pd.DataFrame(columns=[\"Model\", \"Train Accuracy\", \"Test Accuracy\"])","71086331":"def autoML(algorithm): \n\n    model = algorithm().fit(x_train, y_train)\n    train_acc = model.score(x_train, y_train)\n    model_name = algorithm.__name__\n    \n    y_pred = model.predict(x_test)\n    test_acc = accuracy_score(y_test, y_pred)\n    \n    return model_name, train_acc, test_acc","d8e0b0e8":"for alg in algorithms:\n    \n    model_name, train_acc, test_acc = autoML(alg)\n    \n    df_algorithms = df_algorithms.append({\"Model\" : model_name,\n                                          \"Train Accuracy\": train_acc,\n                                          \"Test Accuracy\": test_acc}, ignore_index=True)","921fc9cc":"df_algorithms.sort_values(by=[\"Test Accuracy\", \"Train Accuracy\"],ascending=False)","224a09f5":"model = LinearSVC()","4caaf801":"parameters = {\"penalty\": [\"l1\",\"l2\"],\n              \"loss\": [\"hinge\", \"squared_hinge\"], \n              \"C\": [0.001, 0.01, 0.1, 1, 10],\n              \"multi_class\": [\"ovr\", \"crammer_singer\"], \n              }","4a0be136":"cv_model = GridSearchCV(model, \n                        parameters, \n                        cv=5, \n                        n_jobs=-1\n\n                       ).fit(x_train, y_train)","39728939":"cv_model.best_params_","3a163fd0":"tuned_model = LinearSVC(C = 0.01, \n                        loss = \"hinge\",\n                        multi_class = \"crammer_singer\", \n                        penalty = \"l1\"\n\n                        ).fit(x_train, y_train)","8b866379":"y_pred = tuned_model.predict(x_test)\naccuracy_score(y_test, y_pred)","82535832":"print(classification_report(y_pred, y_test))","971ece3e":"plot_confusion_matrix(tuned_model,\n                      x_test,\n                      y_test,\n                      display_labels=[\"Benign\", \"Malign\"],\n                      cmap=plt.cm.Blues,\n                     )","415702fa":"# Importing Libraries\n\n---","6a760863":"## Attribute Information:\n\n---\n\n* 1) ID number\n* 2) Diagnosis (M = malignant, B = benign)\n* 3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\n* a) radius (mean of distances from center to points on the perimeter)\n* b) texture (standard deviation of gray-scale values)\n* c) perimeter\n* d) area\n* e) smoothness (local variation in radius lengths)\n* f) compactness (perimeter^2 \/ area - 1.0)\n* g) concavity (severity of concave portions of the contour)\n* h) concave points (number of concave portions of the contour)\n* i) symmetry\n* j) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.","287df9dd":"# Preprocessing\n\n---","81b48308":"![](https:\/\/miro.medium.com\/max\/1400\/1*pxFCmhRFTighUn88baLcSA.png)","8d853298":"# Breast Cancer Analysis And Prediction","c804b0c2":"# Relationship Between Features & Features\n\n---","eb565c3a":"### Thanks for reading! Hope this notebook helped","02f469e9":"### Train-Test Split\n\n---","ba1a00b6":"### Standard Scaler\n\n---\n\n> Standardize features by removing the mean and scaling to unit variance","30ad5d65":"# Tuning\n\n---","7743e49f":"# Relationship Between Features & Diagnosis\n\n---","613550b6":"### From Outliers to Mean\n\n---\n\n*We can transform outlier to the mean of each column for better modeling*","2b65377f":"# Understanding The Data\n\n---","8bc4359a":"### With heatmaps, we can see correlation between this columns:\n---\n\n* *perimeter - radius*\n* *area - radius*\n* *area - perimeter*\n* *concavity - compactness*\n* *fractal_dimension - compactness*\n* *concave points - compactness*\n* *concave points - concavity*\n* *concave points - radius*\n* *concave points - perimeter*\n* *concave points - area*","bc2bf4b6":"# Modeling\n\n---","9e66bc41":"Resources\n\n1. <a href=\"https:\/\/www.kaggle.com\/vincentlugat\/breast-cancer-analysis-and-prediction#Breast-Cancer-Analysis-and-Prediction\">Notebook<\/a>\n2. <a href=\"https:\/\/medium.com\/analytics-vidhya\/breast-cancer-diagnostic-dataset-eda-fa0de80f15bd\">Medium<\/a>\n","4c55272d":"### Split The Data\n\n---"}}