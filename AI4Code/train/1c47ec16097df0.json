{"cell_type":{"8ef58b37":"code","04ceca77":"code","ad56abc5":"code","b092b03e":"code","7567b852":"code","cda17ff6":"code","9f9508a2":"code","b9ffcafe":"code","58e3ec41":"code","14e81e6b":"code","4997f0b3":"code","dcf486cd":"code","07910ea9":"code","5245d679":"code","a81ca25f":"code","06f07bf0":"code","dd142eff":"code","8145a023":"code","4725daba":"code","d74d02e5":"code","09185bbd":"code","73682184":"code","8cd30e58":"code","4aa4fccd":"code","88af70ea":"code","338a831d":"code","9a6d7985":"code","9b60ada1":"code","dd7dab14":"code","d9a0721f":"code","881ab9d8":"code","c9f8824c":"code","17d6723d":"code","b0999400":"code","98c504c5":"code","26e6af0d":"code","17b8f5d7":"code","41e6465f":"code","1498f643":"code","26bb9abc":"code","365833dd":"code","c6c3bbe0":"code","e460347e":"code","a6028eeb":"code","92c4422a":"code","47b4ef33":"code","e6f09a1c":"code","7fe1f431":"code","42196e7c":"code","60084db8":"code","40533e93":"code","4a262b74":"code","be2af439":"code","fdac20b5":"code","47642f59":"code","eec24b9f":"code","8024e8c7":"code","47ab8a54":"code","bb6a8f22":"code","a9f2c950":"code","040da792":"code","c0fc4003":"code","466e95b3":"code","57c1df8d":"code","c167279b":"code","a1239816":"code","0057937e":"code","fa516639":"code","5333d80d":"code","75750d4e":"code","8ea981c8":"code","6593bd35":"code","3dbb1e89":"code","7c9f2513":"code","50fe7b6d":"code","a4d1e554":"code","96dfcf9f":"code","b3bb1d0a":"code","f54720f3":"code","621f2ef7":"code","9aad52e3":"code","c84588d8":"code","cc2a803e":"code","9e2ca0a1":"code","05ce0625":"code","5088fda5":"code","5a85a546":"code","cb055245":"code","80feb9a9":"code","9b4cd31c":"code","63aa83ed":"code","8b05bd7e":"code","50188472":"code","afd9a4b9":"code","e21bec66":"code","2c5f9a4d":"code","6a06d0b9":"code","faed0f4f":"code","b820e1ed":"markdown","2eac79b0":"markdown","d826e43f":"markdown","afdcb5a7":"markdown","6525abdb":"markdown","27457497":"markdown","ec676ec2":"markdown","58b81fad":"markdown","e715c146":"markdown","6e54620f":"markdown","3aab9c08":"markdown","d03e5fb5":"markdown","b729c011":"markdown","3114d27b":"markdown","aa8679e3":"markdown","e105094c":"markdown","8a1144fc":"markdown","43ad6cd0":"markdown","c558a9b1":"markdown","f1606be5":"markdown","beea3e99":"markdown","9c98078b":"markdown","b3cbadc4":"markdown","e07646e6":"markdown","c7e131fd":"markdown","2b10cce7":"markdown","a2d8373a":"markdown","08d88717":"markdown","812d8754":"markdown","31821fe5":"markdown","d8f226d5":"markdown","ee949ea9":"markdown","4a47ca64":"markdown","e36e0c82":"markdown","385c1a09":"markdown","82777ada":"markdown","3a4635df":"markdown","ddebcef0":"markdown","43a1b8ba":"markdown","c7a533a5":"markdown","d30565e7":"markdown","2faafb86":"markdown","88500b14":"markdown","1766d71e":"markdown","8f63e546":"markdown","6a7fb66d":"markdown","681761c2":"markdown","84b62b28":"markdown","5d2ac1f4":"markdown","2fcd6d40":"markdown","5dd0faf6":"markdown","3e07abde":"markdown","8ed5844a":"markdown","6dee393f":"markdown"},"source":{"8ef58b37":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport os\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport io\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\ndata_path = \"..\/input\/\"\ndata = pd.read_csv(data_path+\"WA_Fn-UseC_-Telco-Customer-Churn.csv\", dtype='unicode', encoding=\"utf-8-sig\")\ndata.head()","04ceca77":"data.dtypes","ad56abc5":"# Changing datatypes to category\n\n#data[\"gender\"] = data[\"gender\"].astype('category')\n#data[\"SeniorCitizen\"] = data[\"SeniorCitizen\"].astype('category')\n\n#Replacing spaces with null values in total charges column\ndata['TotalCharges'] = data[\"TotalCharges\"].replace(\" \",np.nan)\n\n#Dropping null values from total charges column which contain .15% missing data \ndata = data[data[\"TotalCharges\"].notnull()]\ndata = data.reset_index()[data.columns]\n\nreplace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                'TechSupport','StreamingTV', 'StreamingMovies']\nfor i in replace_cols : \n    data[i]  = data[i].replace({'No internet service' : 'No'})\n    \ndata[\"SeniorCitizen\"] = data[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n\nobj = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n'PaperlessBilling', 'PaymentMethod', 'Churn']\n\ndata[obj] = data[obj].astype('category')","b092b03e":"data['tenure'] = data['tenure'].astype('int')\n\ndef tenure_bracket(data) :\n    if data[\"tenure\"] <= 12 :\n        return \"0-12\"\n    elif (data[\"tenure\"] > 12) & (data[\"tenure\"] <= 24 ):\n        return \"12-24\"\n    elif (data[\"tenure\"] > 24) & (data[\"tenure\"] <= 48) :\n        return \"24-48\"\n    elif (data[\"tenure\"] > 48) & (data[\"tenure\"] <= 60) :\n        return \"48-60\"\n    elif data[\"tenure\"] > 60 :\n        return \"> 60\"\n\ndata[\"tenure_group\"] = data.apply(lambda data:tenure_bracket(data), axis = 1)","7567b852":"data.head(10)","cda17ff6":"Idcol     = ['customerID']\ntarget_col = [\"Churn\"]\ncat_cols   = data.nunique()[data.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in data.columns if x not in cat_cols + target_col + Idcol]","9f9508a2":"#  Check for missing data\n\nmissing_data = data.isnull().sum(axis=0).reset_index()\nmissing_data","b9ffcafe":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 8\nfig_size[1] = 9\nplt.rcParams[\"figure.figsize\"] = fig_size\nsns.countplot(x='Churn', data=data)","58e3ec41":"no = len(data[data['Churn'] == 'No'])\nyes = len(data[data['Churn'] == 'Yes'])\n\nd = {'Churn': ['Yes', 'No'], 'Perc': [yes\/(yes+no) * 100, no\/(yes+no) * 100 ]}\npd.DataFrame(data=d)","14e81e6b":"label = data[\"Churn\"].value_counts().keys().tolist()\nvalues = data[\"Churn\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = label ,\n               values = values ,\n               marker = dict(colors =  [ 'green' ,'red'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Customer Churn\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata1 = [trace]\nfig = go.Figure(data = data1,layout = layout)\npy.iplot(fig)","4997f0b3":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 9\nfig_size[1] = 6\nplt.rcParams[\"figure.figsize\"] = fig_size\n\ns = data['SeniorCitizen'].value_counts().head(10)\nprint (s)\n\nax=s.plot.bar(width=.8) \n\nfor i, v in s.reset_index().iterrows():\n    ax.text(i, v.SeniorCitizen + 0.2 , v.SeniorCitizen, color='red')","dcf486cd":"label = data[\"SeniorCitizen\"].value_counts().keys().tolist()\nvalues = data[\"SeniorCitizen\"].value_counts().values.tolist()\nlabel[0] = 'No'\nlabel[1] = 'Yes'\n\ntrace = go.Pie(labels = label ,\n               values = values ,\n               marker = dict(colors =  ['blue' ,'pink'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Senior Citizen\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata2 = [trace]\nfig = go.Figure(data = data2,layout = layout)\npy.iplot(fig)","07910ea9":"fig, axes = plt.subplots(3, 4, figsize=(25, 25))\nsns.countplot('gender',data=data, ax=axes[0,0])\nsns.countplot('PhoneService',data=data, ax=axes[0,1])\nsns.countplot('MultipleLines',data=data, ax=axes[0,2])\nsns.countplot('InternetService',data=data, ax=axes[0,3])\nsns.countplot('OnlineSecurity',data=data, ax=axes[1,0])\nsns.countplot('OnlineBackup',data=data, ax=axes[1,1])\nsns.countplot('DeviceProtection',data=data, ax=axes[1,2])\nsns.countplot('TechSupport',data=data, ax=axes[1,3])\nsns.countplot('StreamingTV',data=data, ax=axes[2,0])\nsns.countplot('StreamingMovies',data=data, ax=axes[2,0])\nsns.countplot('Contract',data=data, ax=axes[2,1])\nsns.countplot('PaperlessBilling',data=data, ax=axes[2,2])\nsns.countplot('PaymentMethod',data=data, ax=axes[2,3])","5245d679":"from bokeh.io import show, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.models import HoverTool\nfrom bokeh.palettes import Spectral6 \nfrom bokeh.models import ColumnDataSource, LabelSet\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom bokeh.io import save, push_notebook, output_notebook, curdoc\noutput_notebook()\n\nx = list(data.PaymentMethod.unique())#['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']\ncounts = data['PaymentMethod'].value_counts()\n\nhover = HoverTool(\n        tooltips=[\n            (\"Type\", \"@x\"),\n            (\"Count\", \"@counts{int}\")\n            ]\n    )\n\nsource = ColumnDataSource(data=dict(x=x, counts=counts, color=Spectral6))\np = figure(x_range=x, y_range=(0,2500), plot_height=400, plot_width = 800, tools=[hover])\np.vbar(x='x', top='counts', width=0.9, color='color', legend=\"x\", source=source)\n\np.xgrid.grid_line_color = None\np.legend.orientation = \"horizontal\"\np.legend.location = \"top_center\"\n\nshow(p)","a81ca25f":"# -- convert to numeric \n\ndata.TotalCharges=pd.to_numeric(data.TotalCharges,errors='coerce')\ndata.MonthlyCharges=pd.to_numeric(data.MonthlyCharges,errors='coerce')\ndata.tenure=pd.to_numeric(data.tenure,errors='coerce')","06f07bf0":"# Tenure \n\nimport plotly.figure_factory as ff\n\na = data['tenure']\n\nhist_data = [a]\ngroup_labels = ['Distribution']\n\nfig = ff.create_distplot(hist_data, group_labels)\npy.iplot(fig, filename='Basic Distplot')","dd142eff":"print(\"The skewness of SalePrice is {}\".format(data['tenure'].skew()))","8145a023":"# Monthly Charges\n\nm = data['MonthlyCharges']\n\nimport plotly.figure_factory as ff\n\nhist_data = [m]\ngroup_labels = ['Distribution of Monthly Charges']\n\nfig = ff.create_distplot(hist_data, group_labels)\npy.iplot(fig, filename='Basic Distplot')","4725daba":"print(\"The skewness of SalePrice is {}\".format(data['MonthlyCharges'].skew()))","d74d02e5":"# Total Charges\n\nt = data['TotalCharges']\n\nimport plotly.figure_factory as ff\n\nhist_data = [t]\ngroup_labels = ['Distribution of Total Charges']\n\nfig = ff.create_distplot(hist_data, group_labels)\npy.iplot(fig, filename='Basic Distplot')","09185bbd":"print(\"The skewness of SalePrice is {}\".format(data['TotalCharges'].skew()))","73682184":"# check count of yes \/ no churns among gender in the dataset\n\nfig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 12\nfig_size[1] = 9\nplt.rcParams[\"figure.figsize\"] = fig_size\nsns.countplot(x='Churn', hue = 'gender', data=data)","8cd30e58":"srchurn = data[((data['Churn']=='Yes' ) & (data['SeniorCitizen']== '0'))|((data['Churn']=='No') & (data['SeniorCitizen']== '0'))].groupby(['Churn'])['Churn'].count()\nsrchurn\nlabels = (np.array(srchurn.index))\nsizes = (np.array((srchurn \/ srchurn.sum())*100))\ncolors = ['Green', 'lightskyblue']\nplt.subplots(figsize=(10, 8))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title(\"% of Churns versus No-churns among non Senior citizens\")\nplt.show()","4aa4fccd":"srcchurn = data[((data['Churn']=='Yes' ) & (data['SeniorCitizen']== '1'))|((data['Churn']=='No') & (data['SeniorCitizen']== '1'))].groupby(['Churn'])['Churn'].count()\nsrcchurn","88af70ea":"labels = (np.array(srcchurn.index))\nsizes = (np.array((srcchurn \/ srcchurn.sum())*100))\ncolors = ['Pink', 'Gold']\nplt.subplots(figsize=(10, 8))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title(\"% of Churns versus No-churns among Senior citizens\")\nplt.show()","338a831d":"# Males and Females who have not left Telco vs who left\n\ngchurn = data[((data['Churn']=='Yes' ) & (data['gender']== 'Male'))|((data['Churn']=='Yes') & (data['gender']== 'Female'))].groupby(['gender'])['gender'].count()\ngchurn","9a6d7985":"labels = (np.array(gchurn.index))\nsizes = (np.array((gchurn \/ gchurn.sum())*100))\ncolors = ['Pink', 'Violet']\nplt.subplots(figsize=(10, 8))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.title(\"% of Churns among Gender\")\nplt.show()","9b60ada1":"churn     = data[data[\"Churn\"] == \"Yes\"]\nnot_churn = data[data[\"Churn\"] == \"No\"]","dd7dab14":"cat_cols_ch = data.nunique()[data.nunique() < 3].keys()\ncat_cols_ch\ndf = data[cat_cols_ch]","d9a0721f":"# Males and Females who have not left Telco vs who left\n#for i in range(12):\n #   gsschurn = data[((data['Churn']=='Yes' ) & (data[data.columns[i]]== pd.unique(data[data.columns[i]]).unique()[0]))|((data['Churn']=='Yes') & (data[data.columns[i]]== pd.unique(data[data.columns[i]]).unique()[1]))].groupby([data.columns[i]])[data.columns[i]].count()\n  #  gsschurn\n   # labels = (np.array(gsschurn.index))\n    #sizes = (np.array((gsschurn \/ gsschurn.sum())*100))\n    #colors = ['Red', 'Green']\n    ##plt.subplots(figsize=(10, 8))\n    ##plt.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n    ##plt.title(\"% of Churns\")\n   # plt.show()","881ab9d8":"from bokeh.io import show, output_file\nfrom bokeh.plotting import figure\nfrom bokeh.palettes import Spectral6 \nfrom bokeh.models import ColumnDataSource, LabelSet\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom bokeh.io import save, push_notebook, output_notebook, curdoc\noutput_notebook()\n\nx = list(data.Churn.unique())\ncounts = data.groupby(['Churn'])['tenure'].mean()\n\nhover = HoverTool(\n        tooltips=[\n            (\"Churn\", \"@x\"),\n            (\"Mean\", \"@counts{int}\")\n            ]\n    )\n\nsource = ColumnDataSource(data=dict(x=x, counts=counts, color=Spectral6))\np = figure(x_range=x, y_range=(0,50), plot_height=400, plot_width = 800, tools=[hover])\np.vbar(x='x', top='counts', width=0.9, color='color', legend=\"x\", source=source)\n\np.xgrid.grid_line_color = None\np.legend.orientation = \"horizontal\"\np.legend.location = \"top_center\"\n\nshow(p)","c9f8824c":"from bokeh.plotting import figure, show, output_file\nfrom bokeh.models import ColumnDataSource, LabelSet\nfrom bokeh.models import HoverTool\nfrom bokeh.io import save, push_notebook, output_notebook, curdoc\noutput_notebook()\n\nsource = ColumnDataSource(data=dict(\n            x=data['tenure'],\n            y=data['TotalCharges']            \n        )\n    )\n\np = figure(title=\"Bokeh Markers\", toolbar_location=None)\np.grid.grid_line_color = None\np.background_fill_color = \"#eeeeee\"\n\nhover = HoverTool(\n        tooltips=[\n            (\"Tenure\", \"@x\"),\n            (\"Total Charges\", \"@y{int}\")\n            ]\n    )\n\np = figure(plot_width=700, plot_height=700, tools=[hover],\n           title=\"Mouse over the dots\")\n\np.circle('x', 'y', size=10, source=source)\n\nshow(p)\n\n# sns.regplot(data.tenure, data.TotalCharges)","17d6723d":"from bokeh.plotting import figure, show, output_file\nfrom bokeh.models import ColumnDataSource, LabelSet\nfrom bokeh.models import HoverTool\nfrom bokeh.io import save, push_notebook, output_notebook, curdoc\noutput_notebook()\n\nsource = ColumnDataSource(data=dict(\n            x=data['tenure'],\n            y=data['MonthlyCharges']            \n        )\n    )\n\np = figure(title=\"Bokeh Markers\", toolbar_location=None)\np.grid.grid_line_color = None\np.background_fill_color = \"#eeeeee\"\n\nhover = HoverTool(\n        tooltips=[\n            (\"Tenure\", \"@x\"),\n            (\"Monthly Charges\", \"@y{int}\")\n            ]\n    )\n\np = figure(plot_width=700, plot_height=700, tools=[hover],\n           title=\"Mouse over the dots\")\n\np.circle('x', 'y', size=10, source=source)\nshow(p)","b0999400":"numdata = (data[['MonthlyCharges','TotalCharges','tenure']].corr())\nmask = np.zeros_like(numdata, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True","98c504c5":"f, ax = plt.subplots(figsize=(12, 10))\n\n# colormap\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(numdata, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5 , cbar_kws={\"shrink\": .5})","26e6af0d":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 11\nfig_size[1] = 9\nplt.rcParams[\"figure.figsize\"] = fig_size\n\nsns.set(style=\"whitegrid\")\nax = sns.boxplot(x=data['TotalCharges'], y=data['Churn'])","17b8f5d7":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 12\nfig_size[1] = 12\nplt.rcParams[\"figure.figsize\"] = fig_size\n\nsns.set(style=\"whitegrid\")\nax = sns.boxplot(x=data['MonthlyCharges'], y=data['Churn'])","41e6465f":"crosstab = pd.crosstab(data['Churn'], data['gender'])\ncrosstab","1498f643":"from scipy import stats\nstats.chi2_contingency(crosstab)","26bb9abc":"crosstab1 = pd.crosstab(data['Churn'], data['InternetService'])\nfrom scipy import stats\nstats.chi2_contingency(crosstab1)","365833dd":"crosstab2 = pd.crosstab(data['Churn'], data['Contract'])\nfrom scipy import stats\nstats.chi2_contingency(crosstab2)","c6c3bbe0":"crosstab3 = pd.crosstab(data['Churn'], data['SeniorCitizen'])\nfrom scipy import stats\nstats.chi2_contingency(crosstab3)","e460347e":"# missing value check\n\ndata.isnull().sum() \n\n# treating missing values in total charges column\n\ndata['TotalCharges'] = data['TotalCharges'].fillna((data['TotalCharges'].median()))","a6028eeb":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 10\nfig_size[1] = 7\nplt.rcParams[\"figure.figsize\"] = fig_size\n\nsns.set(style=\"whitegrid\")\nax = sns.boxplot(x=data['tenure'])","92c4422a":"fig_size = plt.rcParams[\"figure.figsize\"]\nfig_size[0] = 10\nfig_size[1] = 7\nplt.rcParams[\"figure.figsize\"] = fig_size\n\nsns.set(style=\"whitegrid\")\nax = sns.boxplot(x=data['TotalCharges'], palette=\"Set2\")","47b4ef33":"data_model=data\ndata_model=data_model.drop(columns=['customerID'])","e6f09a1c":"data_dummy=pd.get_dummies(data_model, drop_first=True)","7fe1f431":"data.head(5)","42196e7c":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nIdcol     = ['customerID']\n\n#Target columns\ntarget_col = [\"Churn\"]\n\n#categorical columns\ncat_col   = data.nunique()[data.nunique() < 6].keys().tolist()\ncat_col   = [x for x in cat_col if x not in target_col]\n\n#numerical columns\nnum_col   = [x for x in data.columns if x not in cat_col + target_col + Idcol]\n              \n#Binary columns with 2 values\nbin_col = data.nunique()[data.nunique() == 2].keys().tolist()\n              \n#Columns more than 2 values\nmulti_col = [i for i in cat_col if i not in bin_col]\n\n#Label encoding Binary columns\n              \nle = LabelEncoder()\nfor i in bin_col :\n    data[i] = le.fit_transform(data[i])\n    \n#Duplicating columns for multi value columns\n              \ndata = pd.get_dummies(data = data,columns = multi_col )\n\n#Scaling Numerical columns\n              \nstd = StandardScaler()\nscaled = std.fit_transform(data[num_col])\nscaled = pd.DataFrame(scaled,columns=num_col)\n\n#dropping original values merging scaled values for numerical columns\n\ndf_data = data.copy()\ndata = data.drop(columns = num_col,axis = 1)\ndata = data.merge(scaled,left_index=True,right_index=True,how = \"left\")","60084db8":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\n\ntrain,test = train_test_split(data,test_size = .25 ,random_state = 111)\n    \ncols    = [i for i in data.columns if i not in Idcol + target_col]\nX_train = train[cols]\nY_train = train[target_col]\nX_test  = test[cols]\nY_test  = test[target_col]","40533e93":"X_test.shape\nX_train.shape\nY_test.shape\nY_train.shape","4a262b74":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train_lg=sc.fit_transform(X_train)\nX_test_lg=sc.transform(X_test)","be2af439":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlgmodel = LogisticRegression()\nlgmodel.fit(X_train_lg, Y_train)","fdac20b5":"y_pred = lgmodel.predict(X_test_lg)\nprint('Accuracy of logistic regression model on test data: {:.2f}'.format(lgmodel.score(X_test, Y_test)))","47642f59":"X = data[cols]\nY = data[target_col]","eec24b9f":"from sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nmodelCV = LogisticRegression()\nresults = model_selection.cross_val_score(modelCV, X, Y, cv=kfold, scoring='accuracy')\nprint(\"10-fold cross validation average accuracy: %.2f\" % (results.mean()))","8024e8c7":"lgmodel.coef_","47ab8a54":"import numpy as np\ncoefs=lgmodel.coef_[0]\ntop_three = np.argpartition(coefs, -10)[-10:]\ntop_ten_sorted=top_three[np.argsort(coefs[top_three])]","bb6a8f22":"print(data.columns.values[top_ten_sorted])","a9f2c950":"#data['Churn']= data.Churn.map(dict(Yes=1, No=0))","040da792":"Y=data['Churn']","c0fc4003":"import statsmodels.api as sm\nlogit = sm.Logit(Y,X)\n\n# fit the model\nresult = logit.fit()","466e95b3":"from scipy import stats\nstats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n\nprint(result.summary())","57c1df8d":"np.exp(result.params)","c167279b":"import tensorflow as tf\nlearning_rate = 0.01\ntraining_epochs = 1000\n\ntf.reset_default_graph()\nnum_features = X_train.shape[1]","a1239816":"X = tf.placeholder(tf.float32, [None, num_features], name=\"X\")\nY = tf.placeholder(tf.float32, [None, 1], name=\"Y\")","0057937e":"# Initialize our weigts & bias\n\nW = tf.get_variable(\"W\", [num_features, 1], initializer = tf.contrib.layers.xavier_initializer())\nb = tf.get_variable(\"b\", [1], initializer = tf.zeros_initializer())","fa516639":"Z = tf.add(tf.matmul(X, W), b)\nprediction = tf.nn.sigmoid(Z)","5333d80d":"# Calculate the cost\ncost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Z, labels = Y))","75750d4e":"optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\ninit = tf.global_variables_initializer()","8ea981c8":"cost_history = np.empty(shape=[1],dtype=float)\n\nwith tf.Session() as sess:\n    sess.run(init)\n    \n    for epoch in range(training_epochs):\n        _, c = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n               \"W=\", sess.run(W), \"b=\", sess.run(b))\n        cost_history = np.append(cost_history, c)\n        \n        \n    # Calculate predictions\n    correct_prediction = tf.to_float(tf.greater(prediction, 0.5))\n\n    # Calculate accuracy on the test set\n    accuracy = tf.reduce_mean(tf.to_float(tf.equal(Y, correct_prediction)))\n\n    print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n    print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))","6593bd35":"from xgboost import XGBClassifier\nxgb1 = XGBClassifier()","3dbb1e89":"xgb1.fit(X_train, Y_train)","7c9f2513":"from sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nxgb1_pred = xgb1.predict(X_test)\nxgb1_pred_prob = xgb1.predict_proba(X_test)\naccuracy = accuracy_score(Y_test, xgb1_pred)\nprint('Accuracy = {:0.2f}%.'.format(accuracy))","50fe7b6d":"importances = xgb1.feature_importances_\n\n# Sort feature importances in descending order\nindices = np.argsort(importances)[::-1]\n\n# Rearrange feature names so they match the sorted feature importances\nnames = [X_train.columns[i] for i in indices]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature Importance\")\nplt.bar(range(X.shape[1]), importances[indices])\nplt.xticks(range(X.shape[1]), names, rotation=90)\nplt.show()","a4d1e554":"params = {\n        'objective': ['binary:logistic'],\n        'min_child_weight': range(1,8,2),\n        'gamma':[i\/10.0 for i in range(0,5)],\n        'max_depth': [3, 4, 5, 6, 7, 8],\n        'learning_rate' : [0.1, 0.2, 0.01],\n        'n_estimators' : [1000, 2000],\n        'subsample':[i\/10.0 for i in range(6,10)],\n        'colsample_bytree':[i\/10.0 for i in range(6,10)],\n        'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n        }","96dfcf9f":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nrs = GridSearchCV(xgb1,\n                  params,\n                  cv=5,\n                  scoring=\"accuracy\",\n                  n_jobs=1,\n                  verbose=2)","b3bb1d0a":"#rs.fit(X_train, Y_train)\n#best_est = rs.best_estimator_\n#print(best_est)","f54720f3":"xgb2 = XGBClassifier(colsample_bylevel= 0.6,\n colsample_bytree = 0.8,\n max_depth = 9,\n min_child_weight = 2, gamma= 1,\n n_estimators = 600, learning_rate=0.01, nthread = 1, reg_alpha = 0.1)","621f2ef7":"xgb2.get_params\nxgb2.fit(X_train, Y_train)","9aad52e3":"from sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nxgb2_pred = xgb2.predict(X_test)\nxgb2_pred_prob = xgb2.predict_proba(X_test)\naccuracy = accuracy_score(Y_test, xgb2_pred)\nprint('Accuracy = {:0.2f}%.'.format(accuracy))","c84588d8":"from sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nresults = model_selection.cross_val_score(xgb2, X_train, Y_train, cv=kfold, scoring='accuracy')\nprint(\"10-fold cross validation average accuracy: %.2f\" % (results.mean()))","cc2a803e":"print(\"10-fold cross validation average accuracy: %.2f\" % (results.mean()))","9e2ca0a1":"rfc = RandomForestClassifier(n_estimators=1000, max_depth=None)\nrfc = rfc.fit(X_train, Y_train)","05ce0625":"# Check for missing data\n\n#from sklearn.model_selection import train_test_split\n#X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=1)\n#missing_data1 = X_train.isnull().sum(axis=0).reset_index()\n#missing_data1\n#X_train['TotalCharges'] = X_train['TotalCharges'].fillna((X_train['TotalCharges'].median()))","5088fda5":"#check for missing data\n#missing_data_test = X_test.isnull().sum(axis=0).reset_index()\n#missing_data_test\n#X_test['TotalCharges'] = X_test['TotalCharges'].fillna((X_test['TotalCharges'].median()))","5a85a546":"bigrfc_predictions = rfc.predict(X_test)\nbigrfc_predictions_prob = rfc.predict_proba(X_test)\naccuracy_rf = accuracy_score(Y_test, bigrfc_predictions)\nprint('Accuracy = {:0.2f}%.'.format(accuracy_rf))","cb055245":"from sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nkfold = model_selection.KFold(n_splits=10, random_state=7)\nresults = model_selection.cross_val_score(rfc, X_train, Y_train, cv=kfold, scoring='accuracy')\nprint(\"10-fold cross validation average accuracy: %.2f\" % (results.mean()))","80feb9a9":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(Y_test, lgmodel.predict(X_test))","9b4cd31c":"fpr, tpr, thresholds = roc_curve(Y_test, lgmodel.predict_proba(X_test)[:,1])\nplt.figure(figsize=(20,10))\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","63aa83ed":"#xgb_roc_auc = roc_auc_score(y_test, xgb2.predict(X_test))\nrf_roc_auc = roc_auc_score(Y_test, rfc.predict(X_test))\nrf_roc_auc","8b05bd7e":"fpr, tpr, thresholds = roc_curve(Y_test, rfc.predict_proba(X_test)[:,1])\nplt.figure(figsize=(20,10))\nplt.plot(fpr, tpr, label='RF (area = %0.2f)' % rf_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","50188472":"# Random Forest\n\nfrom sklearn.metrics import confusion_matrix\nrf_confusion_matrix = confusion_matrix(Y_test, bigrfc_predictions)\nprint(rf_confusion_matrix)","afd9a4b9":"import plotly.graph_objs as go\n\ntrace = go.Heatmap(z=rf_confusion_matrix,\n                   x = [\"Not churn\",\"Churn\"],\n                   y = [\"Not churn\",\"Churn\"],)\ndata1=[trace]\npy.iplot(data1, filename='rf_heatmap')","e21bec66":"# XGB\n\nfrom sklearn.metrics import confusion_matrix\nxgb_confusion_matrix = confusion_matrix(Y_test, xgb2_pred)\nprint(xgb_confusion_matrix)","2c5f9a4d":"import plotly.graph_objs as go\n\ntrace = go.Heatmap(z=xgb_confusion_matrix,\n                   x = [\"Not churn\",\"Churn\"],\n                   y = [\"Not churn\",\"Churn\"],)\ndata1=[trace]\npy.iplot(data1, filename='xgb_heatmap')","6a06d0b9":"# Logistic model\n\nfrom sklearn.metrics import confusion_matrix\nlg_confusion_matrix = confusion_matrix(Y_test, y_pred)\nprint(lg_confusion_matrix)","faed0f4f":"import plotly.graph_objs as go\n\ntrace = go.Heatmap(z=lg_confusion_matrix,\n                   x = [\"Not churn\",\"Churn\"],\n                   y = [\"Not churn\",\"Churn\"],)\ndata1=[trace]\npy.iplot(data1, filename='lr_heatmap')","b820e1ed":"   ### Stats model approach to check coefficients","2eac79b0":"#### Monthly Charges distribution with respect to Churn","d826e43f":"#### The above results tell us that there is  a significance or dependency between Senior Citizenship and churn.","afdcb5a7":"### Distribution of numeric variables","6525abdb":"#### A Logit model gives 80% accuracy on the test set. lets check the CV score.","27457497":"### Relation between Tenure & Monthly charges","ec676ec2":"<a id='GB'><\/a>\n\n### Gradient Boosting","58b81fad":"<a id='LR'><\/a>\n\n### Logistic Regression using Scikit learn","e715c146":"#### Payment method","6e54620f":"<a id='UV'><\/a>\n\n## Univariate analysis","3aab9c08":"### Distribution of Senior Citizens in the dataset","d03e5fb5":"#### As seen above, tenure and total charges do seem to be linearly related, with an increase in tenure gradually increasing the total charges of a customer","b729c011":"### RF ROC-AUC","3114d27b":"### Logistic ROC-AUC","aa8679e3":"#### Total Charges distribution with respect to Churn","e105094c":"#### The above results tell us that there is no significance or dependency between gender and churn.","8a1144fc":"### Data preprocessing","43ad6cd0":"<a id='ME'><\/a>\n\n### Model Evaluation","c558a9b1":"### XGB gives an ~80% accuracy for the test set and the CV score is at 80%","f1606be5":"## Table of Contents\n\n1. [Exploratory Analysis](#eda)\n   * 1.1 [Univariate](#UV)\n   * 1.2 [Bivariate](#BV)\n   * 1.3 [Correlation plot](#CP)\n   * 1.4 [Statistical tests](#ST)\n2. [Data Pre-processing- Outlier & Missing value treatment](#DC)\n3. [Modeling](#MD)\n    * 3.1 [Logistic Regression](#LR)\n    * 3.2 [Gradient Boost](#GB)\n    * 3.3 [Random Forest](#RF)\n4. [Model Evaluation](#ME)","beea3e99":"#### Its almost equal with females a little higher than the males","9c98078b":"### Tensorflow gives us 80% accuracy as well. ","b3cbadc4":"   ### Among MALE and FEMALE, who churned more?","e07646e6":"### Relation between tenure & Total charges","c7e131fd":"#### The above results tell us that there is  a significance or dependency between Internet Service and churn.","2b10cce7":"### Not sure if we should use over-sampling techniques. Lets get ahead without it.","a2d8373a":"#### The Numeric variables score high in the Xgb feature importance","08d88717":"#### Check for missing data","812d8754":"### Using Tensorflow","31821fe5":"### Count plot of other categorical variables","d8f226d5":"### In Percentage","ee949ea9":"<a id='CP'><\/a>\n\n### Correlation Plot","4a47ca64":"<a id='ST'><\/a>\n\n## Statistical Tests","e36e0c82":"### Senior citizens who have not left Telco vs who left","385c1a09":"#### Hyperparameter tuning","82777ada":"<a id='BV'><\/a>\n\n## Bivariate analysis","3a4635df":"### Among the 3 numeric variables, total charges seem to be a little positively skewed.","ddebcef0":"#### ROC-AUC for the above models","43a1b8ba":"### Total Charges and Tenure seem to be correlated.","c7a533a5":"### to be continued..","d30565e7":"<a id='eda'><\/a>\n\n## Exploratory Analysis","2faafb86":"#### Median is higher for Yes, than for customers who have not churned","88500b14":"<a id='RF'><\/a>\n\n### Random Forest","1766d71e":"#### The above results tell us that there is  a significance or dependency between Contract and churn.","8f63e546":"### How skewed is it?","6a7fb66d":" ## Modeling","681761c2":"#### Confusion Matrix","84b62b28":"####  Mean tenure of Churned Customers Vs No-Churn Customers ","5d2ac1f4":"### Non-Senior citizens who have not left Telco vs who left","2fcd6d40":"### Customer Churn ","5dd0faf6":"#### Going by the plots above, i have imputed but have not treated outliers as they seem realistic. Going ahead as is","3e07abde":"<a id='DC'><\/a>\n\n## Data Pre-processing","8ed5844a":"#### Median is higher for No than for customers who have churned","6dee393f":"### No missing values - A dream data set"}}