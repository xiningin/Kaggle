{"cell_type":{"5fce19b7":"code","ceedcce7":"code","1fae7500":"code","a4ba265b":"code","e34f0db1":"code","e7a702e5":"code","5a3cc6be":"code","0a46fcd7":"code","26960259":"code","0180f076":"code","988651b4":"code","506319dc":"code","8bcbec56":"code","3eeea8ea":"code","78481aaa":"code","eb506d9d":"code","24eced5b":"code","66bef68e":"code","6b424527":"code","d7317b47":"code","27cab25b":"code","29173d8f":"code","0772121a":"code","c550c663":"code","447fd8f9":"code","58eb5767":"code","67eaa4e9":"code","46bc55d7":"code","3a7bb3ca":"code","5dae987a":"code","5ce5e467":"markdown","8e425d28":"markdown","717e9fc8":"markdown","87325fda":"markdown","66acc39d":"markdown"},"source":{"5fce19b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ceedcce7":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom tqdm import tqdm","1fae7500":"from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score, precision_score, recall_score, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler","a4ba265b":"df = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\nprice_df = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\ncal_df = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")","e34f0db1":"cal_df[\"d\"]=cal_df[\"d\"].apply(lambda x: int(x.split(\"_\")[1]))\nprice_df[\"id\"] = price_df[\"item_id\"] + \"_\" + price_df[\"store_id\"] + \"_validation\"","e7a702e5":"for day in tqdm(range(1886, 1914)):\n    wk_id = list(cal_df[cal_df[\"d\"]==day][\"wm_yr_wk\"])[0]\n    wk_price_df = price_df[price_df[\"wm_yr_wk\"]==wk_id]\n    df = df.merge(wk_price_df[[\"sell_price\", \"id\"]], on=[\"id\"], how='inner')\n    df[\"unit_sales_\" + str(day)] = df[\"sell_price\"] * df[\"d_\" + str(day)]\n    df.drop(columns=[\"sell_price\"], inplace=True)","5a3cc6be":"df[\"dollar_sales\"] = df[[c for c in df.columns if c.find(\"unit_sales\")==0]].sum(axis=1)","0a46fcd7":"df.drop(columns=[c for c in df.columns if c.find(\"unit_sales\")==0], inplace=True)","26960259":"df[\"weight\"] = df[\"dollar_sales\"] \/ df[\"dollar_sales\"].sum()","0180f076":"df.drop(columns=[\"dollar_sales\"], inplace=True)","988651b4":"df[\"weight\"] \/= 12","506319dc":"agg_df = pd.DataFrame(df[[c for c in df.columns if c.find(\"d_\") == 0]].sum()).transpose()\nagg_df[\"level\"] = 1\nagg_df[\"weight\"] = 1\/12\ncolumn_order = agg_df.columns","8bcbec56":"level_groupings = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n              6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], 9: [\"store_id\", \"dept_id\"],\n              10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}","3eeea8ea":"for level in tqdm(level_groupings):\n    temp_df = df.groupby(by=level_groupings[level]).sum().reset_index()\n    temp_df[\"level\"] = level\n    agg_df = agg_df.append(temp_df[column_order])\n\ndel temp_df","78481aaa":"print(df.shape[0], agg_df.shape[0], df.shape[0] + agg_df.shape[0])","eb506d9d":"agg_df[\"weight\"].sum() + df[\"weight\"].sum()","24eced5b":"h = 28\ndef rmsse(ground_truth, forecast, train_series, axis=1, n=1885):\n    # assuming input are numpy array or matrices\n    assert axis == 0 or axis == 1\n    assert type(ground_truth) == np.ndarray and type(forecast) == np.ndarray and type(train_series) == np.ndarray\n    \n    if axis == 1:\n        # using axis == 1 we must guarantee these are matrices and not arrays\n        assert ground_truth.shape[1] > 1 and forecast.shape[1] > 1 and train_series.shape[1] > 1\n    \n    numerator = ((ground_truth - forecast)**2).sum(axis=axis)\n    if axis == 1:\n        denominator = 1\/(n-1) * ((train_series[:, 1:] - train_series[:, :-1]) ** 2).sum(axis=axis)\n    else:\n        denominator = 1\/(n-1) * ((train_series[1:] - train_series[:-1]) ** 2).sum(axis=axis)\n    return (1\/h * numerator\/denominator) ** 0.5","66bef68e":"pd.get_dummies(df.drop(columns=[\"id\", \"item_id\", \"weight\"]))","6b424527":"df.head()","d7317b47":"df = df[[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"weight\"]].join(pd.get_dummies(df.drop(columns=[\"id\", \"item_id\", \"weight\"])))","27cab25b":"import random","29173d8f":"best_s = 100\nbest_m = None\nbest_start_date = 1000","0772121a":"1885 - 28+28","c550c663":"for _ in tqdm(range(50)):\n    rand_est = random.randint(20, 50)\n    rand_depth = random.randint(10, 30)\n    rand_start_date = random.randint(1200, 1500)\n    \n    print(rand_est, rand_depth)\n    \n    \n    average = []\n    \n    for cv in range(1, 4):\n        train_start = rand_start_date - 28 * cv\n        train_end = 1885 - 28 * cv\n        \n        regressor = ExtraTreesRegressor(n_estimators=rand_est, max_depth=rand_depth, random_state=42)\n        \n        drop_cols = [item for item in [c for c in df.columns if c.find(\"F_\")==0] + ['wrmsse', 'rmsse'] if item in df.columns]\n        df.drop(columns=drop_cols, inplace=True)\n\n        regressor.fit(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\\\n                              [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(train_start, train_end + 1)]),\n              df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) in range(train_end + 1, train_end + 28 + 1)]])\n\n        pred_df = pd.DataFrame(regressor.predict(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\\\n                                       [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(train_start+28, train_end + 28 + 1)])))\n        pred_df.columns = [\"F_\" + str(d) for d in range(train_end + 28 + 1, train_end + 28 + 28 + 1)]\n        df = df.join(pred_df)\n\n        # remake agg_df\n        new_agg_df = pd.DataFrame(df[[c for c in df.columns if c.find(\"d_\") == 0 or c.find(\"F_\") == 0]].sum()).transpose()\n        new_agg_df[\"level\"] = 1\n        new_agg_df[\"weight\"] = 1\/12\n        column_order = new_agg_df.columns\n\n        for level in level_groupings:\n            temp_df = df.groupby(by=level_groupings[level]).sum().reset_index()\n            temp_df[\"level\"] = level\n            new_agg_df = new_agg_df.append(temp_df[column_order])\n        del temp_df\n\n        agg_df = new_agg_df\n        \n        train_series_cols = [c for c in df.columns if c.find(\"d_\") == 0][:-28]\n        ground_truth_cols = [c for c in df.columns if c.find(\"d_\") == 0][-28:]\n        forecast_cols = [c for c in df.columns if c.find(\"F_\") == 0]\n\n        df[\"rmsse\"] = rmsse(np.array(df[ground_truth_cols]), \n                np.array(df[forecast_cols]), np.array(df[train_series_cols]))\n        agg_df[\"rmsse\"] = rmsse(np.array(agg_df[ground_truth_cols]), \n                np.array(agg_df[forecast_cols]), np.array(agg_df[train_series_cols]))\n\n        df[\"wrmsse\"] = df[\"weight\"] * df[\"rmsse\"]\n        agg_df[\"wrmsse\"] = agg_df[\"weight\"] * agg_df[\"rmsse\"]\n\n        print(\"CV\", cv, \":\", df[\"wrmsse\"].sum() + agg_df[\"wrmsse\"].sum())\n\n        average.append(df[\"wrmsse\"].sum() + agg_df[\"wrmsse\"].sum())\n    \n    this_s = np.array(average).mean()\n    if this_s < best_s:\n        best_s = this_s\n        best_m = regressor\n        best_start_date = rand_start_date\n        \n    print(this_s, best_s)","447fd8f9":"# fit the best_m with the closest training set\nbest_m.fit(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\\\n                              [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(best_start_date, 1886)]),\n              df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) in range(1886, 1914)]])","58eb5767":"submit_df = df[[\"id\"]]\npred = best_m.predict(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\n                               [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(best_start_date+28, 1914)]))\nfor i in range(1, 29):\n    submit_df[\"F\" + str(i)] = pred[:, i-1]","67eaa4e9":"submit_df2 = submit_df.copy()\nsubmit_df2[\"id\"] = submit_df2[\"id\"].apply(lambda x: x.replace('validation',\n                                                              'evaluation'))","46bc55d7":"submit_df = submit_df.append(submit_df2).reset_index(drop=True)","3a7bb3ca":"submit_df.to_csv(\"submission.csv\", index=False)","5dae987a":"submit_df","5ce5e467":"## 3. Multi Label Regression with ExtraTreesRegressor","8e425d28":"## 0. Import libraries and read in data","717e9fc8":"## 1. Calculate weight for the level 12 series","87325fda":"## 2. Infer round truth values, and weights for all the higher level series by aggregating","66acc39d":"###### Make submission file"}}