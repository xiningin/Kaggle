{"cell_type":{"8bb21e4f":"code","75577fc7":"code","dd569034":"code","b4c0ecfe":"code","9af06afa":"code","c805706e":"code","23a524c3":"code","24b58f09":"markdown","341323d5":"markdown","3125693f":"markdown","9d65ae1b":"markdown","9bfe840d":"markdown","52cab6a4":"markdown","64257191":"markdown","f4141a7e":"markdown","68f32ff9":"markdown","c136e1ea":"markdown"},"source":{"8bb21e4f":"# Import libraries necessary for this project\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport numpy  as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n%matplotlib inline\n\nfrom keras.utils.np_utils    import to_categorical\nfrom keras.models            import Sequential\nfrom keras.layers            import Dense\nfrom keras.layers            import Dropout\nfrom keras.layers            import Conv2D\nfrom keras.layers            import Activation\nfrom keras.layers            import MaxPooling2D\nfrom keras.layers            import Flatten\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib.pyplot       import imshow\nfrom PIL                     import Image\n\nprint(\"Input data : \",os.listdir(\"..\/input\"))\n\nprint(\"\\nImporting \u2713\\n\")","75577fc7":"# Load the MNIST dataset\n\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data  = pd.read_csv('..\/input\/test.csv' )\n\ny_train = train_data[\"label\"]\nx_train = train_data.drop(labels=[\"label\"], axis=1) \n\nprint(\"\\nLoading \u2713\\n\")","dd569034":"print(\"There are\", x_train.shape[0] , \"training examples.\")\nprint(\"And\", test_data.shape[0], \"testing examples.\")\nprint(x_train.shape)\nprint(\"\\nThe classes we have are :\",np.unique(y_train))\n\n%matplotlib inline\n# everytime you run you'll get another data point \nrandom = np.random.randint(0, 42000)\nprint (\"\\nThe class you got is\",y_train[random])\nimshow(x_train.iloc[random].values.reshape((28, 28)))\nprint(\"\\nExploring \u2713\\n\")","b4c0ecfe":"#  Normalizing the data to be in range from 0 to 1 instead of 0 to 255\nx_train   =   x_train.values.reshape(-1, 28, 28, 1) \/ 255 \ntest_data = test_data.values.reshape(-1, 28, 28, 1) \/ 255\nprint(x_train.shape)\nprint(test_data.shape)\n# Splitting the output to 10 distinct calsses\ny_train = to_categorical(y_train, num_classes = 10)\nprint(y_train.shape)\n\nprint(\"\\nReshaping \u2713\\n\")","9af06afa":"model = Sequential()\n\nmodel.add(Conv2D(128, padding='same',data_format='channels_last', kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, padding='same', kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(256, padding='same', kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(128, padding='same', kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\n# Output layer\nmodel.add(Dense(units=10, activation='softmax'))\n\n# compiling the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(\"\\nCompiling \u2713\\n\")","c805706e":"model.fit(x = x_train, y = y_train, epochs=32, verbose=2)\nprint(\"\\nTraining \u2713\\n\")","23a524c3":"res = model.predict(test_data)\nres = np.argmax(res,axis = 1)\nres = pd.Series(res, name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1 ,28001) ,name = \"ImageId\"),   res],axis = 1)\nsubmission.to_csv(\"cnn_mnist_class.csv\",index=False)\n\nprint(\"\\nSubmission \u2713\\n\")","24b58f09":"### Exploring the data\nThis step is a very important step, sice we need to know the characteristics of the data to choose later the algorithm with which we can classify the data and which accuracy metric you are going to use. We will know the shape the data is saved with and the classes we have.\n\nIn the 2nd part of the code we will get a point from the training set and print an image of it along with the class to get an idea of the data points.","341323d5":"### Reshaping the Data to fit the Model\n\nSince we are deciding to make a sequential model the data needs to be reshaped to fit as following :\n\n- Normalizing the input data that ranges from 0 to 255 to range from 0 to 1 by deviding it by 255.\n- Using to_categorial to split the output into 10 distinct  class labels so that we can use the [Softmax function](https:\/\/en.wikipedia.org\/wiki\/Softmax_function) as out multicalss classifier in the next section.","3125693f":"### Training the Model\n\nIn this section we will train the Network on the data we have with 30 epochs and 60% of the data as training set, 20% as validation and the remaining 20% as a test set that we will evaluate the model on in the next section.","9d65ae1b":"### Selectin the Model\n\nThe model is a [sequential model](https:\/\/keras.io\/models\/sequential\/) with 1 hidden layar (_ofcourse you can use more than 1 hidden layar, in fact just uncomment the line after TODO and rerun all the following codes again and see the difference yourself_) with 1024 neurons, ReLU and an output layar with 10 neurons, Softmax as out multiclass classifier as explained above.","9bfe840d":"### Loading the Data\nWe will load the data into x_train, y_train and test_data, in the next section we will get information about the data.","52cab6a4":"One can see that the dataset consists of 42,000 training example each is a 1D array -vector if you like- with size 784. One can also see that we have 10 classes which represent the digits from 0 to 9 crossponding to the data.","64257191":"### Submission","f4141a7e":"## Using [Convolutional Neural Network](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network) to classify [MNIST Dataset](https:\/\/en.wikipedia.org\/wiki\/MNIST_database)","68f32ff9":"### Introduction\n\nIn this tutorial we will use [Convolutional Neural Networks](https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network) to classify hand digit characters in the [MNIST dataset](https:\/\/en.wikipedia.org\/wiki\/MNIST_database).\n\nWe will use a higher level library called [keras](https:\/\/keras.io\/backend\/) with tensorflow as the backend.","c136e1ea":"### Importing All Libraries\n\nI prefere that all importings to be first but ofcourse you can import anywhere (This is Python, not as restrected as java :D )"}}