{"cell_type":{"f6d7de91":"code","0db66b00":"code","a0b47687":"code","a750d64a":"code","58307495":"code","fdb40aef":"code","f7ea5ee1":"code","51a806e4":"code","1ff9c976":"code","b3bb4dd5":"code","15d7184e":"code","9266e014":"markdown","359fd6ca":"markdown","da55d3b8":"markdown","8b7e1791":"markdown","1748149a":"markdown","c0778f88":"markdown","8363d7c2":"markdown","ab6dbe8c":"markdown","cad286db":"markdown","7315d2bb":"markdown","f11dfcd9":"markdown"},"source":{"f6d7de91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0db66b00":"df=pd.read_csv(\"..\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv\")","a0b47687":"df.head()","a750d64a":"df.info()","58307495":"st=df[\"class\"].value_counts().index\nsy=df[\"class\"].value_counts().values\nexplode=[0.2,0.2]\n\n\nplt.pie(sy,explode=explode,labels=st,autopct=\"%1.1f%%\")\nplt.title(\"abnormal-normal rate\")\nplt.show()","fdb40aef":"sns.countplot(df[\"class\"])\nplt.show()","f7ea5ee1":"sayici=0\nfor i in df[\"class\"]:\n    if(i==\"Abnormal\"):\n        df[\"class\"][sayici]=1\n    else:\n            df[\"class\"][sayici]=0\n    sayici+=1            \n\ndf[\"class\"]=df[\"class\"].astype(\"int64\")","51a806e4":"y=df[\"class\"].values\nx_data=df.drop([\"class\"],axis=1)","1ff9c976":"x=(x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data)).values","b3bb4dd5":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)","15d7184e":"#knn model\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn=KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(x_train,y_train)\n\nscore=knn.score(x_test,y_test)\n\nprint(\"accuracy:\",score)","9266e014":"We look at how the top 5 data of our data look like.It is important to recognize the data.","359fd6ca":"Last step normalization.Why important normalization??.Cool story bro.","da55d3b8":"First of all, let's break down our data. If you want, you can do this manually.","8b7e1791":"And here it is..","1748149a":"Calm down almost ready","c0778f88":"But before converting it let's look visually.","8363d7c2":"We are looking closer than our data and see some problems.So we are on the right way.\n\"Class\" feature not available to classification so that we must convert it.","ab6dbe8c":"# Introduction\n.\n.\n.\n.","cad286db":"Yes has finished finally.At now we can start building the \"KNN\" structure.","7315d2bb":"## Load Data","f11dfcd9":"We are ready for converting now!!"}}