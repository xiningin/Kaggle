{"cell_type":{"d2bc775b":"code","915e4797":"code","4ca827c3":"code","971b533a":"code","171cc845":"code","a5fdf23a":"code","af86061d":"code","c3e0fbc5":"code","a82b7003":"code","62a9c806":"code","166ffbc2":"code","698546d0":"code","638ca1f1":"code","c311d06a":"code","7c1fbf1e":"markdown","ef248862":"markdown","88fb6bfc":"markdown","25e72ced":"markdown","aad6a0c6":"markdown","e1a1e4ec":"markdown","08215f78":"markdown","4ac3e172":"markdown","2a7fcde4":"markdown","b1d77179":"markdown","934abd08":"markdown","23331ac5":"markdown","a642bbee":"markdown","3af14dce":"markdown","d9059ae8":"markdown","cf935a25":"markdown","307404f7":"markdown","8de09c13":"markdown","51de4b65":"markdown"},"source":{"d2bc775b":"## Essential Python Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#data Visualization\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n#Feature Engineering \nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nimport string\nimport gc\neng_stopwords = set(stopwords.words(\"english\"))\npd.options.mode.chained_assignment = None\n\ncolor = sns.color_palette()\n%matplotlib inline","915e4797":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4ca827c3":"train_df=pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df=pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsample_df=pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","971b533a":"print(\"Number of rows in train dataset:\",train_df.shape[0])\nprint(\"Number of rows test dataset:\",test_df.shape[0])","171cc845":"train_df.isnull().sum()","a5fdf23a":"test_df.isnull().sum()","af86061d":"train_df.head()","c3e0fbc5":"cnt_target = train_df['target'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(cnt_target.index, cnt_target.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Target', fontsize=12)\nplt.show()","a82b7003":"grouped_df = train_df.groupby('target')\nfor target_type, group in grouped_df:\n    print(\"Target type:\",target_type )\n    cnt = 0\n    for ind, row in group.iterrows():\n        print(row[\"text\"])\n        cnt += 1\n        if cnt == 5:\n            break\n    print(\"\\n\")","62a9c806":"df=train_df.append(test_df) ##we have appended the train and test dataset into a single dataframe\nprint(\"Missing Target values:\",(df.target.isnull().sum())) ","166ffbc2":"##Number of words in the text\ndf[\"num_words\"] = df[\"text\"].apply(lambda x : len(str(x).split()))\n\n##Number of Unique words in the text\ndf[\"num_unique_words\"]=df[\"text\"].apply(lambda x: len(set(str(x).split())))\n\n##Number of Characters in the text\ndf[\"num_characters\"]=df[\"text\"].apply(lambda x : len(str(x)))\n\n##Number of Stopwords in the text\ndf[\"num_stopwords\"]=df[\"text\"].apply(lambda x : len([w for w in str(x).lower().split() if w in eng_stopwords]))\n\n##Number of Punctuations in the text\ndf[\"num_punctuations\"]=df[\"text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n\n\n##Number of words in Upper case\ndf[\"num_uppercase\"]=df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n##Number of words in Title case\ndf[\"num_titlecase\"]=df[\"text\"].apply(lambda x:len([w for w in str(x).split() if w.istitle()]))\n\n#Average words of each words\ndf[\"avg_words\"]=df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","698546d0":"train_df=df[df[\"target\"].isnull()!=True]\ntest_df=df[df[\"target\"].isnull()==True]\ntest_df.drop(\"target\",axis=1,inplace=True)\n\ndel df\ngc.collect()","638ca1f1":"plt.figure(figsize=(12,8))\nsns.violinplot(x='target', y='num_words', data=train_df)\nplt.xlabel('target', fontsize=12)\nplt.ylabel('Number of words in text', fontsize=12)\nplt.title(\"Number of words by type\", fontsize=15)\nplt.show()","c311d06a":"plt.figure(figsize=(12,8))\nsns.violinplot(x='target', y='num_punctuations', data=train_df)\nplt.xlabel('target', fontsize=12)\nplt.ylabel('Number of punctuations in text', fontsize=12)\nplt.title(\"Number of punctuations by type\", fontsize=15)\nplt.show()","7c1fbf1e":"## **Feature Engineering**","ef248862":"Let's split the df into train and test dataframe","88fb6bfc":"## Data preparation","25e72ced":"The data doesn't contain imbalance, this looks good. Let us print some lines of each of the categories to try and understand their writing style if possible.","aad6a0c6":"We'll try to find the distribution of the target variables.  ","e1a1e4ec":"## **Objective of the competition:**\n* The competition dataset has conatins data from the tweets of people from twitter.\n* Twitter has become an important communication channel in times of emergency.\n* People use twitter to announce an emergency they\u2019re observing in real-time.\n* But, it\u2019s not always clear whether a person\u2019s words are actually announcing a disaster.\n* So our goal here is to classify whether the tweet is about a real disaster (1) or not (0).","08215f78":"**About this kernel:**\n\n* In this notebook, let us try to create different features that will help us in identifying the nature of tweets\n \n* As a first step, we will do some basic data visualization and cleaning before we delve deep into the feature engineering part.","4ac3e172":"**Observation:**\n\nWe can clearly see that the tweets in this data set which are not disaster are mostly sarcastic and happy minded. So if we are able to find the emotional state of the tweet it might be a very valuable column while predicting the target variable.","2a7fcde4":"FE while predicting the text data can be done in two parts:\n* Meta Feature Extraction\n* Text based features ","b1d77179":"**Now let's check the impact of these new features on the target variables**","934abd08":"**Observations:**\n\nFrom the graph we can able to see that more tweets are not about the real disaster, this clearly tells us the need for this competition.","23331ac5":"The missing target values are the test data we have to use that as a key to boil down the data into train and test after Feature Engineering","a642bbee":"## Upvote the kernel if you find it useful","3af14dce":"## **Data Exploration**","d9059ae8":"**Meta Features**\n\nFeatures that can be extracted from the tweets like number of words, number of punctuation, stopwords etc are called meta features.\n\nFollowing feature's can be created using the tweet data\n\n* Number of words in the text\n* Number of unique words in the text\n* Number of characters in the text\n* Number of stopwords\n* Number of punctuations\n* Number of upper case words\n* Number of title case words\n* Average length of the words\n","cf935a25":"**Important Observations:**","307404f7":"Let's join train and test data into a single dataframe so that we do feature engineering in a single stretch","8de09c13":"**Reference**\n\nThanks Sudalai Raj Kumar for his amazing work([link](https:\/\/github.com\/SudalaiRajkumar\/Kaggle\/blob\/master\/SpookyAuthor\/simple_fe_notebook_spooky_author.ipynb))","51de4b65":"##  This kernel is under construction please stay tuned for more updates"}}