{"cell_type":{"5d344d2c":"code","e66c4591":"code","07cfc7c7":"code","782f99ea":"code","b487a9b8":"code","fe5f32eb":"code","584b7ced":"code","dd142e3c":"code","5cd0b938":"code","ffcc4166":"code","9d346d1f":"code","f729c7e7":"code","ead91a9f":"code","7d39baf1":"code","f95d52f3":"code","a76b1bbc":"code","174514de":"code","1596a62c":"code","ed2190b7":"code","dd932a1b":"code","7c664fb9":"code","3fabbb13":"code","be6f677c":"code","d20acf99":"code","5f359472":"code","d5fdcdef":"code","010c6e97":"code","182a82ba":"code","a4ca1130":"code","a974cbbb":"code","667e3041":"code","39c11fc2":"code","0dd2e06f":"code","6ff87442":"code","ce9cdae6":"code","7485150d":"code","bbe4f48c":"code","830c0bdd":"code","ae694d03":"code","b3b781d8":"markdown","2bc3f02d":"markdown","c6a9381b":"markdown","56b48641":"markdown","1a4ce8f2":"markdown","5504ecad":"markdown","93037444":"markdown","d5e0c22a":"markdown","70a7b7e5":"markdown","d83aaea1":"markdown","941a18ca":"markdown","afd6f9bd":"markdown","cc49b064":"markdown","f6fd0134":"markdown","3f5dfb01":"markdown","d7053b03":"markdown","c0a169f3":"markdown","5a93be94":"markdown","3d78708a":"markdown","e2f6011c":"markdown","d1000f3d":"markdown","89b9b2be":"markdown","ba047500":"markdown","452daba0":"markdown","5ecd157a":"markdown","af515f4b":"markdown","19e628d7":"markdown","d1f3ab23":"markdown","a8398b5c":"markdown","e65b10f4":"markdown","e8a24a41":"markdown","060745f7":"markdown","19a0c799":"markdown","b126069d":"markdown","3abe5fb8":"markdown","2af670dc":"markdown","d9d497a9":"markdown"},"source":{"5d344d2c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import tree,svm\nfrom sklearn.metrics import accuracy_score","e66c4591":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data","07cfc7c7":"print('The shape of our training set: %s passengers and %s features'%(train_data.shape[0],train_data.shape[1]))","782f99ea":"train_data.info()","b487a9b8":"train_data.isnull().sum()","fe5f32eb":"sns.heatmap(train_data[[\"Survived\", \"SibSp\", \"Parch\", \"Age\", \"Fare\"]].corr(), annot = True)\nsns.set(rc={'figure.figsize':(12,10)})","584b7ced":"train_data['SibSp'].unique()\nsns.catplot(x = \"SibSp\", y = \"Survived\", data = train_data, kind=\"bar\", height = 8)","dd142e3c":"sns.FacetGrid(train_data, col=\"Survived\", height = 7).map(sns.distplot, \"Age\").set_ylabels(\"Survival Probability\")","5cd0b938":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train_data)","ffcc4166":"sns.catplot(x = \"Pclass\", y=\"Survived\", data = train_data, kind=\"bar\", height = 6)","9d346d1f":"train_data['Embarked'].value_counts(), train_data['Embarked'].isnull().sum()","f729c7e7":"train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna('S')\ntrain_data.isnull().sum()","ead91a9f":"sns.catplot(x=\"Embarked\", y=\"Survived\", data=train_data, height = 5, kind=\"bar\")","7d39baf1":"sns.catplot(x=\"Pclass\", col=\"Embarked\", data = train_data, kind=\"count\", height=7)","f95d52f3":"mean_age = train_data[\"Age\"].mean()\nstd_age = train_data[\"Age\"].std()\nmean_age, std_age","a76b1bbc":"random_age = np.random.randint(mean_age-std_age, mean_age+std_age, size = 177)\nage_slice = train_data[\"Age\"].copy()\nage_slice[np.isnan(age_slice)] = random_age\ntrain_data[\"Age\"] = age_slice","174514de":"train_data.isnull().sum()","1596a62c":"list_column_to_drop = [\"PassengerId\", \"Ticket\", \"Cabin\", \"Name\"]\ntrain_data.drop(list_column_to_drop, axis=1, inplace=True)\ntrain_data.head(10)","ed2190b7":"genders = {\"male\":0, \"female\":1}\ntrain_data[\"Sex\"] = train_data[\"Sex\"].map(genders)\n\nports = {\"S\":0, \"C\":1, \"Q\":2}\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].map(ports)","dd932a1b":"train_data.head()","7c664fb9":"df_train_x = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\ndf_train_y = train_data[['Survived']] #Target Variable ","3fabbb13":"x_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.20, random_state=18)","be6f677c":"# Creating alias for Classifier\nclf1 = RandomForestClassifier()\n\n# Fitting the model using training data\nclf1.fit(x_train, y_train)\n\n# Predicting on test data\nrfc_y_pred = clf1.predict(x_test)\n\n# Calculating Accuracy to compare all models\nrfc_accuracy = accuracy_score(y_test,rfc_y_pred) * 100\nprint(\"accuracy=\",rfc_accuracy)","d20acf99":"clf2 = KNeighborsClassifier(5)\nclf2.fit(x_train, y_train)\nknc_y_pred = clf2.predict(x_test)\nknc_accuracy = accuracy_score(y_test,knc_y_pred)*100\n\nprint(\"accuracy=\",knc_accuracy)","5f359472":"clf3 = tree.DecisionTreeClassifier()\nclf3 = clf3.fit(x_train, y_train)\ndtc_y_pred = clf3.predict(x_test)\ndtc_accuracy = accuracy_score(y_test,dtc_y_pred)*100\n\nprint(\"accuracy=\",dtc_accuracy)","d5fdcdef":"clf4 = svm.SVC()\nclf4.fit(x_train, y_train)\nsvm_y_pred = clf4.predict(x_test)\nsvm_accuracy = accuracy_score(y_test,svm_y_pred)*100\nprint(\"accuracy=\",svm_accuracy)","010c6e97":"clf5 = LogisticRegression(solver='liblinear')\nclf5.fit(x_train, y_train)\nlr_y_pred = clf5.predict(x_test)\nlr_accuracy = accuracy_score(y_test,lr_y_pred)*100\n\nprint(\"accuracy=\",lr_accuracy)","182a82ba":"print(\"Accuracy of Random Forest Classifier =\",rfc_accuracy)\nprint(\"Accuracy of Logistic Regressor =\",lr_accuracy)\nprint(\"Accuracy of K-Neighbor Classifier =\",knc_accuracy)\nprint(\"Accuracy of Decision Tree Classifier = \",dtc_accuracy)\nprint(\"Accuracy of Support Vector Machine Classifier = \",svm_accuracy)","a4ca1130":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head(10)","a974cbbb":"test_data.info()","667e3041":"test_data.isnull().sum()","39c11fc2":"mean_age = test_data[\"Age\"].mean()\nstd_age = test_data[\"Age\"].std()\nrandom_age = np.random.randint(mean_age-std_age, mean_age+std_age, size = 86)\nage_slice = test_data[\"Age\"].copy()\nage_slice[np.isnan(age_slice)] = random_age\ntest_data[\"Age\"] = age_slice","0dd2e06f":"test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\ntest_data.isnull().sum()","6ff87442":"list_column_to_drop = [\"PassengerId\", \"Ticket\", \"Cabin\", \"Name\"]\ntest_data.drop(list_column_to_drop, axis=1, inplace=True)\ntest_data.head(10)","ce9cdae6":"genders = {\"male\":0, \"female\":1}\ntest_data[\"Sex\"] = test_data[\"Sex\"].map(genders)\n\nports = {\"S\":0, \"C\":1, \"Q\":2}\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].map(ports)\n\ntest_data.head()","7485150d":"test_data.isnull().sum()","bbe4f48c":"x_test = test_data\ny_pred = clf1.predict(x_test)\noriginaltest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission = pd.DataFrame({\n        \"PassengerId\": originaltest_data[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nsubmission.head(20)","830c0bdd":"submission.to_csv('submission.csv',index=False)","ae694d03":"submission.info()","b3b781d8":"<h2> Dropping Un-necessary Columns from the Dataset <\/h2>","2bc3f02d":"<h4> So, there are 177 null values in 'Age' Column, 687 null values in 'Cabin' Column and 2 null values in 'Embarked' Column <\/h4>","c6a9381b":"<h2> Reading the Training Data using Pandas <\/h2>","56b48641":"<h2> Passengers embarked from C station had the most of the 1st Class booking and so the Survival chances of Passengers embarked from C Station is High <\/h2>","1a4ce8f2":"<h3>Chances of survival :-<\/h3>\n<h3>1st Class > 2nd Class > 3rd Class<\/h3>","5504ecad":"<h2> Analyzing the Pclass column to get the survival chance analysis using bar plot <\/h2>","93037444":"<h4> From the heatmap we can say that those who have paid higher fares have a better chance of Survival <\/h4>","d5e0c22a":"<h2> Checking for Null values <\/h2>","70a7b7e5":"<h1> Final Notebook Submission <\/h1>","d83aaea1":"<h2> Using Barplot to visulalize the survival rate w.r.t gender of survivor <\/h2>","941a18ca":"<h2> Fitting the machine learning model on 4 different classification algorithms namely Random Forest Classifier, K-Neighbor Classifier, Decision Tree Classifier, Support Vector Machine and Logistic Regression and comparing them <\/h2>","afd6f9bd":"<h3>5. Logistic Regression <\/h3>","cc49b064":"<h2> Converting Categorical Variables (Sex, Embarked) to Numeric <\/h2>","f6fd0134":"<h2> Plotting a graph so as to see the distribution of age w.r.t Target Variable(Survival) <\/h2>","3f5dfb01":"<h4> Replacing the null values with the most frequent value 'S' <\/h4>","d7053b03":"<h3>3. Decision Tree Classifier <\/h3>","c0a169f3":"<h4> From above it is crystal clear that \"There were more Female survivors than compared to Male survivors <\/h4>","5a93be94":"<h2>  Plotting a heat map to see the correlation between the parameters and the target variable (Survived) <\/h2>","3d78708a":"<h3> Accuracies of all Classifiers <\/h3>","e2f6011c":"<h2> Replacing missing values\/null values from the 'Fare' Column with Average Fare <\/h2>","d1000f3d":"<h3> 1. Random Forest Classifier <\/h3>","89b9b2be":"<h2> Converting Categorical Variables (Sex, Embarked) to Numeric <\/h2>","ba047500":"<h4> From the distribution plot we can say that people with more age have a lesser chance of survival than people with less age <\/h4>","452daba0":"<h4> From the Bar Graph we can say that Passengers with 1 or 2 siblings have a better chance of survival than those have more than 2 siblings<\/h4>","5ecd157a":"<h3>2. K-Neighbor classifier <\/h3>","af515f4b":"<h2> Handling missing values \/ null values from the 'Age' Column and replacing them with random values within the range of the Average Age - Standard Age and Average Age + Standard Age <\/h2>","19e628d7":"<h3> So we have 2 null values in 'Embarked' Column of the data set <\/h3>","d1f3ab23":"<h2> Dropping Un-necessary Columns from the Dataset <\/h2>","a8398b5c":"<h2> Importing the required Libraries <\/h2>","e65b10f4":"<h2> Train, Test and Splitting <\/h2>","e8a24a41":"<h3>4. Support Vector Machine <\/h3>","060745f7":"<h3>Since maximum accuracy score is with Random Forest Classifier so we choose it for making predictions on test.csv.<\/h3>","19a0c799":"<h2> Handling missing values \/ null values from the 'Age' Column and replacing them with random values within the range of the Average Age - Standard Age and Average Age + Standard Age <\/h2>","b126069d":"<h1> Final Prediction with Machine Learning Model <\/h1>","3abe5fb8":"<h2> Plotting Bar Graph to visualize the Surviving Probability w.r.t SibSp (Siblings\/Spouses)<\/h2>","2af670dc":"<h1> Building Machine Learning Model <\/h1>","d9d497a9":"<h2> Embarked column analysis and correction of null values <\/h2>"}}