{"cell_type":{"50206a7d":"code","58af2511":"code","72a701bc":"code","5583f0a0":"code","f8c2aece":"code","eae3b784":"code","1b808f29":"code","dc11cfdc":"code","2df8cc19":"code","058c356f":"code","3d11ca71":"code","39d5a4be":"code","d9b9b1ec":"code","940e73ac":"code","4f94ec74":"code","65b17685":"code","9fda9f59":"code","472500d5":"code","a5adcc38":"code","055eaaed":"code","35562738":"code","2947fdce":"code","32989618":"code","4911973e":"code","582e55f3":"code","2441425d":"code","061004a3":"code","d22da1ac":"code","2e317fdf":"code","73661e46":"code","4c1ab293":"code","e5960dd4":"code","a26e0144":"code","abded64e":"code","dbc8fab2":"code","304dcb86":"code","cdcd57ad":"code","f67e63e3":"code","2c22641a":"code","0d7febae":"code","7857d159":"code","a0ee3cbc":"code","f39d64c0":"code","885fe2eb":"code","71251cec":"code","c1d3e944":"code","09af6e66":"code","fbb1ddc5":"code","c242626d":"code","f5940389":"code","fb3229ff":"code","39310f09":"code","b758a892":"code","0602d49b":"code","4a12fddf":"markdown","df7b100c":"markdown","eb75880f":"markdown","3bf78de8":"markdown","f5c541f2":"markdown","dd0ba979":"markdown","63dd4e7c":"markdown","392d98be":"markdown","a5b87027":"markdown","d0fe8760":"markdown","e5d34298":"markdown","7ab3d983":"markdown","24085cd7":"markdown","8717ba0c":"markdown","0ed55262":"markdown","6898ba0f":"markdown","8cd19559":"markdown","03230b56":"markdown","385d8bf0":"markdown","bcc4f0d7":"markdown","2dc14a2d":"markdown"},"source":{"50206a7d":"### import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import style\nimport seaborn as sns  \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","58af2511":"#This function will draw histogram by passing data column name and tilte name\ndef plot_histogram(data_val,title_name):\n    plt.figure(figsize=[10,6])\n    plt.hist(data_val,edgecolor=\"red\")\n    #plt.grid(axis='y', alpha=0.75)\n    plt.title(title_name,fontsize=15)\n    plt.show()\n    ","72a701bc":"#function to get total count of zeros and outcome details together\ndef get_zeros_outcome_count(data,column_name):\n    count = data[data[column_name] == 0].shape[0]\n    print(\"Total No of zeros found in \" + column_name + \" : \" + str(count))\n    print(data[data[column_name] == 0].groupby('Outcome')['Age'].count())","5583f0a0":"#function to create scatter plot\ndef create_scatter_plot(first_value,second_value,x_label,y_label,colour):\n    plt.scatter(first_value,second_value, color=[colour])\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    title_name = x_label + '&' + y_label\n    plt.title(title_name)\n    plt.show()","f8c2aece":"diabetes_data = pd.read_csv(\"..\/input\/datasciencecapstonehealthcare\/capstone_healthcare_diabetes.csv\")","eae3b784":"diabetes_data.head()","1b808f29":"#Get count of outcome column\ndiabetes_data.groupby('Outcome').size()","dc11cfdc":"#checking null value\ndiabetes_data.isnull().any()","2df8cc19":"diabetes_data.info()","058c356f":"#Now lets create a count (frequency) plot describing the data types and the count of variables. ","3d11ca71":"diabetes_data['Glucose'].value_counts().head(10)","39d5a4be":"diabetes_data['Glucose']","d9b9b1ec":"#Drawing histogram for glucose\nplot_histogram(diabetes_data['Glucose'],'Glucose Histogram')","940e73ac":"#Now will check for another column bloodpressure\ndiabetes_data['BloodPressure'].value_counts().head(7)","4f94ec74":"#Drawing Bloodpressure histogram\nplot_histogram(diabetes_data['BloodPressure'],'BloodPressure Histogram')","65b17685":"diabetes_data.groupby('Outcome').hist(figsize=(14, 13))","9fda9f59":"#Checking count of zeros in blood pressure\nget_zeros_outcome_count(diabetes_data,'BloodPressure')","472500d5":"#Checking count of zeros in Glucose\nget_zeros_outcome_count(diabetes_data,'Glucose')","a5adcc38":"#Checking count of zeros in SkinThickness \nget_zeros_outcome_count(diabetes_data,'SkinThickness')","055eaaed":"#Checking count of zeros in BMI \nget_zeros_outcome_count(diabetes_data,'BMI')","35562738":"#Checking count of zeros in BMI \nget_zeros_outcome_count(diabetes_data,'Insulin')","2947fdce":"diabetes_data_mod = diabetes_data[(diabetes_data.BloodPressure != 0) & (diabetes_data.BMI != 0) & (diabetes_data.Glucose != 0)]\nprint(diabetes_data_mod.shape)","32989618":"#Now we will check the stats of data after removing BloodPressure, BMI and Glucose 0 rows\ndiabetes_data_mod.describe().transpose()","4911973e":"#Lets create positive variable and store all 1 value Outcome data\nPositive = diabetes_data_mod[diabetes_data_mod['Outcome']==1]\nPositive.head(5)","582e55f3":"Positive.groupby('Outcome').hist(figsize=(14, 13),histtype='stepfilled',bins=20,color=\"green\",edgecolor=\"red\")","2441425d":"BloodPressure = Positive['BloodPressure']\nGlucose = Positive['Glucose']\nSkinThickness = Positive['SkinThickness']\nInsulin = Positive['Insulin']\nBMI = Positive['BMI']","061004a3":"create_scatter_plot(Positive['BloodPressure'],Positive['Glucose'],'BloodPressure','Glucose','orange')","d22da1ac":"#Creating scatter plot for negative outcome\nNegative = diabetes_data_mod[diabetes_data_mod['Outcome']==0]","2e317fdf":"create_scatter_plot(Negative['BloodPressure'],Negative['Glucose'],'BloodPressure','Glucose','blue')","73661e46":"g =sns.scatterplot(x= \"BloodPressure\" ,y= \"Glucose\",\n              hue=\"Outcome\",\n              data=diabetes_data_mod);","4c1ab293":"B =sns.scatterplot(x= \"BMI\" ,y= \"Insulin\",\n              hue=\"Outcome\",\n              data=diabetes_data_mod);","e5960dd4":"S =sns.scatterplot(x= \"SkinThickness\" ,y= \"Insulin\",\n              hue=\"Outcome\",\n              data=diabetes_data_mod);","a26e0144":"### correlation matrix\ndiabetes_data_mod.corr()","abded64e":"### create correlation heat map\nplt.subplots(figsize=(8,8))\nsns.heatmap(diabetes_data_mod.corr())","dbc8fab2":"### gives correlation value\nplt.subplots(figsize=(10,10))\nsns.heatmap(diabetes_data_mod.corr(),annot=True,cmap='viridis')","304dcb86":"feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nX = diabetes_data_mod[feature_names]\ny = diabetes_data_mod.Outcome\n","cdcd57ad":"X.head()","f67e63e3":"#Train test split\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state =10)","2c22641a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","0d7febae":"#LR Model\nmodel_LR = LogisticRegression(solver='liblinear')\nmodel_LR.fit(X_train,y_train)","7857d159":"#now check LR model score and accuracy score \n\nprint(\"LogisticRegression Score :{}\".format(model_LR.score(X_train,y_train)))\ny_pred = model_LR.predict(X_test)\nscores = (accuracy_score(y_test, y_pred))\nprint(\"LogisticRegression Accuracy Score :{}\".format(scores))","a0ee3cbc":"accuracyScores = []\nmodelScores = []\nmodels = []\nnames = []\n#Store algorithm into array to get score and accuracy\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('SVC', SVC()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('DT', DecisionTreeClassifier()))\nmodels.append(('GNB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('GB', GradientBoostingClassifier()))","f39d64c0":"#We fit each model in a loop and calculate the accuracy of the respective model using the \u201caccuracy_score\u201d\nfor name, model in models:\n    model.fit(X_train, y_train)\n    modelScores.append(model.score(X_train,y_train))\n    y_pred = model.predict(X_test)\n    accuracyScores.append(accuracy_score(y_test, y_pred))\n    names.append(name)\n    \ntr_split_data = pd.DataFrame({'Name': names, 'Score': modelScores,'Accuracy Score': accuracyScores})\nprint(tr_split_data)","885fe2eb":"#Lets draw graph to understand more. ","71251cec":"plt.subplots(figsize=(12,7))\naxis = sns.barplot(x = 'Name', y = 'Accuracy Score', data = tr_split_data)\naxis.set(xlabel='Classifier Name', ylabel='Accuracy Score')\nfor p in axis.patches:\n    height = p.get_height()\n    axis.text(p.get_x() + p.get_width()\/2, height + 0.005, '{:1.3f}'.format(height), ha=\"center\")\n    \nplt.show()","c1d3e944":"names = []\nscores = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=10) \n    score = cross_val_score(model, X, y, cv=kfold, scoring='accuracy').mean()\n    names.append(name)\n    scores.append(score)\nk_fold_cross_val_score = pd.DataFrame({'Name': names, 'Score': scores})\nprint(k_fold_cross_val_score)","09af6e66":"plt.subplots(figsize=(12,7))\naxis = sns.barplot(x = 'Name', y = 'Score', data = k_fold_cross_val_score)\naxis.set(xlabel='Classifier Name', ylabel='Accuracy Score')\nfor p in axis.patches:\n    height = p.get_height()\n    axis.text(p.get_x() + p.get_width()\/2, height + 0.005, '{:1.3f}'.format(height), ha=\"center\")\n    \nplt.show()","fbb1ddc5":"#y is label value & X is feature value\ncm = confusion_matrix(y,model_LR.predict(X))\ncm","c242626d":"print(classification_report(y,model_LR.predict(X)))","f5940389":"\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n","fb3229ff":"#Preparing ROC Curve (Receiver Operating Characteristics Curve) - LR, KNN\n# predict probabilities for LR\nprobs_LR = model_LR.predict_proba(X)\n# predict probabilities for KNN - where models[2] is KNN \nmodel_KNN = KNeighborsClassifier(n_neighbors=4)\nmodel_KNN.fit(X_train, y_train)\nprobs_KNN = model_KNN.predict_proba(X)\n\n# Sklearn has a very potent method roc_curve() which computes the ROC for your classifier in a matter of seconds! It returns the FPR, TPR, and threshold values: calculate roc curve\nfpr, tpr, thresholds = roc_curve(y, probs_LR[:, 1],pos_label=1)\nfpr1, tpr1, thresholds1 = roc_curve(y, probs_KNN[:, 1],pos_label=1)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y))]\np_fpr, p_tpr, _ = roc_curve(y, random_probs, pos_label=1)\n\n# plot no skill\nplt.plot(p_fpr, p_tpr, linestyle='--',color='blue')\nplt.plot(fpr, tpr, linestyle='--',color='red', label='Logistic Regression')\nplt.plot(fpr1, tpr1, linestyle='--',color='green', label='KNN')\n\n# plot the roc curve for the model\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n#plt.plot(fpr, tpr, marker='.')\nplt.legend(loc='best')\nplt.show();\n# keep probabilities for the positive outcome only\n#The AUC score can be computed using the roc_auc_score() method of sklearn: calculate AUC\nauc_LR = roc_auc_score(y, probs_LR[:, 1])\nauc_KNN = roc_auc_score(y, probs_KNN[:, 1])\nprint('AUC LR: %.5f' % auc_LR, 'AUC KNN: %.5f' % auc_KNN)\n","39310f09":"def generate_graph(recall, precision,name):    \n    # plot no skill\n    # plot the precision-recall curve for the model\n    plt.figure()\n    plt.subplots(figsize=(10,4))\n    plt.plot([0, 1], [0.5, 0.5], linestyle='--',label='No Skill')\n    plt.plot(recall, precision, marker='.',label=name)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(name)\n    plt.legend(loc='best')\n    plt.show()","b758a892":"#Store algorithm into array to get score and accuracy\np_r_Models = []\np_r_Models.append(('LR', LogisticRegression(solver='liblinear')))\np_r_Models.append(('KNN', KNeighborsClassifier()))\np_r_Models.append(('DT', DecisionTreeClassifier()))\np_r_Models.append(('GNB', GaussianNB()))\np_r_Models.append(('RF', RandomForestClassifier()))\np_r_Models.append(('GB', GradientBoostingClassifier()))\n#Precision Recall Curve for All classifier\nfor name, model in p_r_Models:\n    from sklearn.metrics import precision_recall_curve\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import auc\n    from sklearn.metrics import average_precision_score\n    print(\"\\n===================------------------- Precision Recall Curve for {} -------------------===================\\n\".format(name))\n    model.fit(X_train, y_train)\n    # predict probabilities\n    probs = model.predict_proba(X)\n    # keep probabilities for the positive outcome only\n    probs = probs[:, 1]\n    # predict class values\n    yhat = model.predict(X)\n    # calculate precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y, probs)\n    # calculate F1 score, # calculate precision-recall AUC\n    f1, auc = f1_score(y, yhat), auc(recall, precision)\n    # calculate average precision score\n    ap = average_precision_score(y, probs)\n    generate_graph(recall, precision,name)\n    print(str(name) + \" calculated value : \" + 'F1 Score =%.3f, Area Under the Curve=%.3f, Average Precision=%.3f\\n' % (f1, auc, ap))\n    print(\"The above precision-recall curve plot is showing the precision\/recall for each threshold for a {} model (orange) compared to a no skill model (blue).\".format(name))\n","0602d49b":"from IPython import display\ndisplay.Image(\"..\/input\/datasciencecapstonehealthcare\/Health - Tableau.JPG\")","4a12fddf":"<b>Create a classification report by analyzing sensitivity, specificity, AUC (ROC curve), etc -<\/b>\nAUC-ROC curve helps us visualize how well our machine learning classifier is performing.","df7b100c":"<h2 style=\"color:blue\">Data Reporting:<\/h2>\n\nCreate a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. The dashboard must entail the following:\n\na. Pie chart to describe the diabetic or non-diabetic population\n\nb. Scatter charts between relevant variables to analyze the relationships\n\nc. Histogram or frequency charts to analyze the distribution of the data\n\nd. Heatmap of correlation analysis among the relevant variables\n\ne. Create bins of these age values: 20-25, 25-30, 30-35, etc. Analyze different variables for these age brackets using a bubble chart.","eb75880f":"<h3>*************** Function start here **********************<\/h3>","3bf78de8":"<h3>Now lets perform K-Fold Cross Validation with Scikit Learn <\/h3>\n<p> We will move forward with K-Fold cross validation as it is more accurate and use the data efficiently. We will train the models using 10 fold cross validation and calculate the mean accuracy of the models. <span style=\"color:blue\">\"k_fold_cross_val_score\"<\/span> provides its own training and accuracy calculation interface.<\/p>","f5c541f2":"<h1 style=\"color:Brown\">Healthcare<\/h1>\n<h3 style=\"color:red\">Problem Statement<\/h3>\n<p>NIDDK (National Institute of Diabetes and Digestive and Kidney Diseases) research creates knowledge about and treatments for the most chronic, costly, and consequential diseases.\nThe dataset used in this project is originally from NIDDK. The objective is to predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\nBuild a model to accurately predict whether the patients in the dataset have diabetes or not.<\/p>\nDataset Description\nThe datasets consists of several medical predictor variables and one target variable (Outcome). Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and more.\n<table>\n    <tr><td>Variables<\/td><td>Description<\/td><\/tr>\n    <tr><td>Pregnancies<\/td><td>Number of times pregnant<\/td><\/tr>\n    <tr><td>Glucose<\/td><td>Plasma glucose concentration in an oral glucose tolerance test<\/td><\/tr>\n    <tr><td>BloodPressure<\/td><td>Diastolic blood pressure (mm Hg)<\/td><\/tr>\n    <tr><td>SkinThickness<\/td><td>Triceps skinfold thickness (mm)<\/td><\/tr>\n    <tr><td>Insulin<\/td><td>Two hour serum insulin<\/td><\/tr>\n    <tr><td>BMI<\/td><td>Body Mass Index<\/td><\/tr>\n    <tr><td>DiabetesPedigreeFunction<\/td><td>Diabetes pedigree function<\/td><\/tr>\n    <tr><td>Age<\/td><td>Age in years<\/td><\/tr>\n    <tr><td>Outcome<\/td><td>Class variable (either 0 or 1). 268 of 768 values are 1, and the others are 0<\/td><\/tr>\n<\/table>\n\nData Exploration:\n\n1. Perform descriptive analysis. Understand the variables and their corresponding values. On the columns below, a value of zero does not make sense and thus indicates missing value:\n\n\u2022 Glucose\n\n\u2022 BloodPressure\n\n\u2022 SkinThickness\n\n\u2022 Insulin\n\n\u2022 BMI\n\n2. Visually explore these variables using histograms. Treat the missing values accordingly.\n\n3. There are integer and float data type variables in this dataset. Create a count (frequency) plot describing the data types and the count of variables. \n\nData Exploration:\n\n1. Check the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of action.\n\n2. Create scatter charts between the pair of variables to understand the relationships. Describe your findings.\n\n3. Perform correlation analysis. Visually explore it using a heat map.\n\nData Modeling:\n\n1. Devise strategies for model building. It is important to decide the right validation framework. Express your thought process.\n\n2. Apply an appropriate classification algorithm to build a model. Compare various models with the results from KNN algorithm.\n\n\nData Modeling:\n\n1. Create a classification report by analyzing sensitivity, specificity, AUC (ROC curve), etc. Please be descriptive to explain what values of these parameter you have used.\n\nData Reporting:\n\n2. Create a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. The dashboard must entail the following:\n\na. Pie chart to describe the diabetic or non-diabetic population\n\nb. Scatter charts between relevant variables to analyze the relationships\n\nc. Histogram or frequency charts to analyze the distribution of the data\n\nd. Heatmap of correlation analysis among the relevant variables\n\ne. Create bins of these age values: 20-25, 25-30, 30-35, etc. Analyze different variables for these age brackets using a bubble chart.\n\n ","dd0ba979":"<h4>After analysing above data we found lots of 0 in Insulin and SkinThickness and removing them or putting mean value will not good dataset. However, we can remove \"BloodPressure\", \"BMI\" and \"Glucose\" zeros row<\/h4>","63dd4e7c":"<p>Here we need to predict outcome column. 1 indicate person is diabetes and 0 denote person is non-diabetes.<\/p>","392d98be":"<h3>URL to view created data reporting viz - <a href=\"https:\/\/public.tableau.com\/app\/profile\/md.mushtaque.ansari\/viz\/DataScienceCapstone-Healthcare_16296264514340\/DiabetesDashboard?publish=yes\"> LINK <\/a><\/h3> ","a5b87027":"<p>From positive outcome histogram we can see the outlier in SkinThickness, BMI & Insulin. <\/p>","d0fe8760":"At the baseline Logistic Regression managed to achieve a classification accuracy of 77.64 %.","e5d34298":"<p>We can see the Logistic Regression, Gaussian Naive Bayes, Random Forest and Gradient Boosting have performed better than the rest. From the base level we can observe that the Logistic Regression performs better than the other algorithms.<\/p>","7ab3d983":"<h4> Now lets check confussion matric<\/h4>","24085cd7":"<h3>Create Model<\/h3>","8717ba0c":"<p>We don't need to create negative scatter plot, but I am creating it to verify the values and points which we will get for both outcome value using sns scatterplot. <\/p>\n","0ed55262":"<h4 style=\"color:blue\">After analyzing the histogram we can identify that there are some outliers in some columns.<\/h4>\n<b>For Example:- <\/b>\n<ul>\n    <li>BloodPressure - A living person cannot have a diastolic blood pressure of zero.<\/li>\n    <li>Plasma glucose levels - Zero is invalid number as fasting glucose level would never be as low as zero. <\/li>\n    <li>Skin Fold Thickness - For normal people, skin fold thickness can\u2019t be less than 10 mm better yet zero. <\/li>\n    <li>BMI: Should not be 0 or close to zero unless the person is really underweight which could be life-threatening.<\/li>\n    <li>Insulin: In a rare situation a person can have zero insulin but by observing<\/li>\n<\/ul>","6898ba0f":"<h3>*************** Function End here **********************<\/h3>","8cd19559":"<h3>Logistic Regreation and model building<\/h3>","03230b56":"<p>As you can compare postive & negative scatter plot with sns scatter plot all the value is matching, so now I will create common scatter plot for both outcome.<\/p>","385d8bf0":"<h3>Instead of creating historam one by one. With the help of group by and Outcome we can create all column hisotram<\/h3>","bcc4f0d7":"<h2>Data Exploration:<\/h2>\n\n1. Check the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of action.\n\n2. Create scatter charts between the pair of variables to understand the relationships. Describe your findings.\n\n3. Perform correlation analysis. Visually explore it using a heat map.","2dc14a2d":"<h3>Now creating scatter plot for positive outcome<\/h3>"}}