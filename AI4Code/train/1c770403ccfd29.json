{"cell_type":{"4cd990f7":"code","dc2aefd6":"code","2de7b135":"code","603a3166":"code","b8e94d0b":"code","aa070776":"code","27277d64":"code","c8c5f07d":"code","dde05f1d":"code","8e7244b4":"code","41518a1b":"code","7764d6b2":"code","3c9d64b5":"code","e9caefb2":"code","43297fa4":"code","30659672":"code","74287564":"code","e80cfa86":"code","75747678":"code","fee0d527":"code","c86dc173":"code","961e0ad7":"code","5d08d2ae":"code","309cd88a":"code","70c6304a":"code","05c102b8":"markdown","9ae60398":"markdown","d20274e9":"markdown","629f7de4":"markdown","d1bf382c":"markdown","99b65e06":"markdown","da6364d3":"markdown","94cd59a2":"markdown","0ab681b4":"markdown","2fc7efaf":"markdown","534061dd":"markdown"},"source":{"4cd990f7":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\n\nfrom keras.layers import Dense, Flatten, Conv1D,MaxPooling1D, Dropout,BatchNormalization,Embedding,Concatenate, Input\nfrom keras.models import Model","dc2aefd6":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\n\n# DAE files From Remek Kinas :\n\ntrain_DAE = pd.read_csv('..\/input\/denoiser\/tps-05-train_dae_coded.csv')\ntest_DAE = pd.read_csv('..\/input\/denoiser\/tps-05-test_dae_coded.csv')","2de7b135":"!pip install git+https:\/\/github.com\/Lpourchot\/dfencoding.git","603a3166":"from dfencoding import utilities","b8e94d0b":"train_dum = train.copy() # need to change type in string \ntest_dum = test.copy()","aa070776":"train_dum = train_dum.iloc[:,1:].astype('str')\ntest_dum = test_dum.iloc[:,1:].astype('str')","27277d64":"dfe = utilities.dfencoding(train_dum,'target',test_dum, missing_value = 'Y', cat_limit = 150, dummies_limit = 150)","c8c5f07d":"X = dfe.data.iloc[:len(train),:-1].astype('float')\ntest = dfe.data.iloc[len(train):,:-1].astype('float')\nX.shape, test.shape","dde05f1d":"dfe.get_dummies()","8e7244b4":"X_Onehot = dfe.data.iloc[:len(train_dum),1:]\ntest_Onehot = dfe.data.iloc[len(train_dum):,1:]\nprint(X_Onehot.shape)\nprint(test_Onehot.shape)","41518a1b":"target = pd.get_dummies(train['target']).astype('float')\ny = train['target']","7764d6b2":"X_DAE = train_DAE.iloc[:,1:-1]","3c9d64b5":"test_DAE = test_DAE.iloc[:,1:]","e9caefb2":"# To avoid negative values (for embedding), we just add 8 to all categories :\nX = X + 8\ntest = test + 8\nX.shape, test.shape, y.shape, target.shape","43297fa4":"es = callbacks.EarlyStopping(\n                monitor = 'val_categorical_crossentropy', \n                min_delta = 0.0000001, \n                patience = 2,\n                mode = 'min',\n                baseline = None, \n                restore_best_weights = True,\n                verbose = 1)\n\nplateau  = callbacks.ReduceLROnPlateau(\n                monitor = 'val_categorical_crossentropy',\n                factor = 0.5, \n                patience = 1, \n                mode = 'min', \n                min_delt = 0.0000001,\n                cooldown = 0, \n                min_lr = 1e-7,\n                verbose = 1) \n\nmetrics = [tf.keras.metrics.CategoricalCrossentropy()]\nloss = tf.keras.losses.CategoricalCrossentropy(\n                from_logits=False,\n                label_smoothing=0,\n                reduction=\"auto\",\n                name=\"categorical_crossentropy\")\n","30659672":"def api_DAE():\n    inputs_DAE = layers.Input(shape = (228,))\n    q = layers.Dense(200, activation=\"relu\")(inputs_DAE)\n    q = layers.Dropout(0.3)(q)\n    q = layers.Dense(100, activation = \"relu\")(q)\n    q = layers.Dropout(0.3)(q)\n    outputs_DAE = layers.Dense(50, activation = \"relu\")(q)\n    \n    return  outputs_DAE,inputs_DAE","74287564":"def api_onehot():\n    inputs_Onehot = layers.Input(shape = (1285,))\n    w = layers.Dense(100, activation=\"relu\")(inputs_Onehot)\n    w = layers.Dropout(0.3)(w)\n    \n    outputs_Onehot = layers.Dense(40, activation = \"relu\")(w)\n    \n    return  outputs_Onehot,inputs_Onehot","e80cfa86":"def api_embedding_row():\n    inputs_Embedding_row = layers.Input(shape = (50,))\n    x = layers.Embedding(80, 10, input_length = 50)(inputs_Embedding_row)\n    x = layers.Flatten()(x)\n    x = layers.Dense(100, activation = 'relu')(x)\n    x = layers.Dropout(0.3)(x)\n    \n    outputs_Embedding_row = layers.Dense(40, activation='relu')(x)\n    \n    return outputs_Embedding_row,inputs_Embedding_row","75747678":"def api_conv1D():\n    inputs_Conv1D = layers.Input(shape=(50,1)) \n    v = layers.Conv1D(\n                filters = 256, \n                kernel_size = 4,\n                padding = 'same', \n                activation = 'relu',\n                )(inputs_Conv1D)\n\n    v = layers.MaxPooling1D(pool_size = 3)(v)\n    v = layers.Flatten()(v)\n    v = layers.Dense(200, activation='relu')(v)\n    v = layers.Dropout(0.3)(v)\n    v = layers.Dense(100, activation = 'relu')(v)\n    v = layers.Dropout(0.3)(v)\n    outputs_Conv1D = layers.Dense(50, activation = 'relu')(v)\n    \n    return outputs_Conv1D,inputs_Conv1D","fee0d527":"def api_embedding_col():    \n    inputs_Embedding_col = layers.Input(shape = (50,))\n    a = layers.Reshape((-1,1))(inputs_Embedding_col)\n    a = layers.Embedding(80, 10,input_length = 128)(a)\n    a = layers.Flatten()(a)\n    a = layers.Dense(100, activation='relu')(a)\n    a = layers.Dropout(0.3)(a)\n    outputs_Embedding_col = layers.Dense(40, activation = 'relu')(a)\n\n    return outputs_Embedding_col,inputs_Embedding_col","c86dc173":"def api_conv1D_col():    \n    inputs_conv1D_col = layers.Input(shape = (50,))\n    c = layers.Reshape((-1,1))(inputs_conv1D_col)\n    c = layers.Conv1D(\n                filters = 256, \n                kernel_size = 4,\n                padding = 'same', \n                activation = 'relu',\n                )(c)\n    c = layers.MaxPooling1D(pool_size = 3)(c)\n    c = layers.Flatten()(c)\n    c = layers.Dense(200, activation='relu')(c)\n    c = layers.Dropout(0.3)(c)\n    c = layers.Dense(100, activation = 'relu')(c)\n    outputs_conv1D_col = layers.Dense(50, activation = 'relu')(c)\n\n    return outputs_conv1D_col,inputs_conv1D_col","961e0ad7":"def api_seq():    \n    inputs_seq = layers.Input(shape = (50,))\n    seq = layers.Dense(200, activation=\"relu\")(inputs_seq)\n    seq = layers.Dropout(0.3)(seq)\n    seq = layers.Dense(100, activation = \"relu\")(seq)\n    outputs_seq = layers.Dense(50, activation = \"relu\")(seq)\n\n    return outputs_seq ,inputs_seq ","5d08d2ae":"N_FOLDS = 10\nSEED = 2021\noof = np.zeros((X.shape[0],4))\npred = np.zeros((test.shape[0],4))\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n    print(f\"===== FOLD {fold} =====\")\n       \n    x_tr = X.iloc[tr_idx]\n    x_Onehot_tr = X_Onehot.iloc[tr_idx]\n    x_DAE_tr = X_DAE.iloc[tr_idx]\n    y_tr = target.iloc[tr_idx] \n    x_ts = X.iloc[ts_idx] \n    x_Onehot_ts = X_Onehot.iloc[ts_idx]\n    x_DAE_ts = X_DAE.iloc[ts_idx]\n    y_ts = target.iloc[ts_idx] \n    \n    outputs_Onehot,inputs_Onehot = api_onehot()\n    outputs_DAE,inputs_DAE = api_DAE()\n    outputs_Embedding_row,inputs_Embedding_row = api_embedding_row()\n    outputs_Embedding_col, inputs_Embedding_col = api_embedding_col()\n    outputs_conv1D,inputs_conv1D = api_conv1D()\n    outputs_conv1D_col,inputs_conv1D_col = api_conv1D()\n    outputs_seq ,inputs_seq = api_seq()\n    \n    z = layers.Concatenate(axis=1)([\n                    #outputs_Onehot,\n                    outputs_DAE,\n                    #outputs_Embedding_row,\n                    #outputs_Embedding_col,\n                    outputs_conv1D,\n                    outputs_conv1D_col,\n                    outputs_seq\n                    ])\n    \n    z = layers.Dense(16, activation = 'relu')(z)\n    z = layers.Dense(8, activation = 'sigmoid')(z)\n    \n    k = layers.Concatenate(axis=1)([\n                    outputs_Onehot,\n                    outputs_Embedding_row,\n                    outputs_Embedding_col])\n    k = layers.Dense(16, activation = 'relu')(k)\n    k = layers.Dense(8, activation = 'sigmoid')(k)\n   \n    k = layers.Concatenate(axis=1)([z,k])\n    out = layers.Dense(4, activation = 'softmax', name = 'out')(k)\n    \n    model_merged = Model(inputs= [\n                    inputs_DAE,\n                    inputs_conv1D,\n                    inputs_conv1D_col,\n                    inputs_seq,\n                    inputs_Onehot,\n                    inputs_Embedding_row,\n                    inputs_Embedding_col,\n                    ],\n                    outputs = out, \n                    name=\"model_merged\")\n    \n    model_merged.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n                    loss = loss ,\n                    metrics = metrics)\n    \n    model_merged.fit([\n                    x_DAE_tr,\n                    x_tr,\n                    x_tr,\n                    x_tr,\n                    x_Onehot_tr,\n                    x_tr,\n                    x_tr\n                    ],                    \n                     y_tr,\n                    validation_data = ([\n                    x_DAE_ts,\n                    x_ts,\n                    x_ts,\n                    x_ts,\n                    x_Onehot_ts,\n                    x_ts,\n                    x_ts\n                    ],\n                    y_ts),        \n                    batch_size = 128,\n                    epochs = 25,\n                    verbose = 1,\n                    callbacks = [es,plateau]\n                    )\n    oof[ts_idx] = model_merged.predict(\n                    [\n                    x_DAE_ts,\n                    x_ts,\n                    x_ts,\n                    x_ts,\n                    x_Onehot_ts,\n                    x_ts,\n                    x_ts]\n                    )\n\n    score = log_loss(y_ts, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n    \n    pred += model_merged.predict(\n                                [\n                    test_DAE,\n                    test,\n                    test,\n                    test,\n                    test_Onehot,\n                    test,\n                    test]\n                                ) \/ N_FOLDS\n\nscore = log_loss(target, oof)\nprint(f\"Score total {score}\\n\") ","309cd88a":"submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","70c6304a":"submission_df = pd.DataFrame(pred)\nsubmission_df.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\nsubmission_df['id'] = submission['id']\nsubmission_df = submission_df[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4']]\nsubmission_df.to_csv(\"submission_Keras_22.csv\", index=False)\ndisplay(submission_df.head())","05c102b8":"<h3> Conv1D Model","9ae60398":"<h2> Base models : Row Embedding + Column Emedding + Conv1D + Onehot","d20274e9":"<h3> DAE Model","629f7de4":"<h3> Parameters for the training","d1bf382c":"<h3> Sequential Model","99b65e06":"<h3> Data for others Models","da6364d3":"<h3> Data for OneHot Models","94cd59a2":"<h3> Column Embedding Model","0ab681b4":"<h2> Basic data cooking","2fc7efaf":"<h3> Onehot Model","534061dd":"<h3> Row Embedding Model"}}