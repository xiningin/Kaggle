{"cell_type":{"ee42f906":"code","5afa4b1a":"code","3af08720":"code","a5aab656":"code","605d21c9":"code","bacd3e1a":"code","d5203144":"code","1ff7c662":"code","db4d6791":"code","fa77efab":"code","67082a04":"code","c59a1624":"code","32434c40":"code","c40f83c9":"code","8baab5cf":"code","82d98c34":"code","d0dd6b68":"code","1cfb73e0":"code","b8881d61":"code","31bb8c36":"code","f3ae10d9":"code","26d082d5":"code","7e5f161d":"code","1ae4fb58":"code","62084c68":"code","0d4ab607":"code","5add208f":"code","3108debe":"code","2841a6b8":"code","c4b590b4":"markdown","5fb01c5f":"markdown","7a9c9b52":"markdown","a502f9d2":"markdown","b8822057":"markdown","ac1d5f01":"markdown","d40b8510":"markdown","53d3d690":"markdown","4b395088":"markdown","dd60b11a":"markdown","e437f04b":"markdown","214e7675":"markdown","84f77453":"markdown","39494c94":"markdown","6e3482cc":"markdown","cf5851e5":"markdown","8aae8d69":"markdown","39c7cb88":"markdown"},"source":{"ee42f906":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn\nprint(sklearn.__version__)\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5afa4b1a":"!pip install sklearn -U","3af08720":"import numpy as np\n\nimport sklearn\n\npd.options.display.max_columns = 500 # this will set limit of columns to 500","a5aab656":"file_path = '..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv'\ndf = pd.read_csv(file_path)","605d21c9":"for column in df.columns:\n    print(column)\n    \nlabel = ['Churn']\n\nID = ['customerID']\n\nfeatures = [column for column in df.columns if column not in label+ID]\nprint('DataFrame - Telco Customer Churn\\n')\nprint(df.info())\nprint('\\n')\nprint(df.head(5))\n\nfor column in df.columns:\n    print('\\n')\n    print(column+' - number of unique elements: ', df.loc[:,column].nunique())\n    \ndf2 = df.loc[:,(df.nunique()==2)|(df.nunique()==4)].copy()\nnrows = df2.shape[0]\nfor column in df2.columns:\n    print(column+'\\n')\n    print(df2[column].unique())\n    print('\\n')\n    print(df2[column].value_counts()\/nrows*100)\n    print('\\n#########################\\n')\n    \ndf3 = df.loc[:,(df.nunique()==3)].copy()\nnrows = df3.shape[0]\nfor column in df3.columns:\n    print(column+'\\n')\n    print(df3[column].unique())\n    print('\\n')\n    print(df3[column].value_counts()\/nrows*100)\n    print('\\n#########################\\n')","bacd3e1a":"df.TotalCharges = df.TotalCharges.replace(' ', 0).astype(float)","d5203144":"def StratifiedSplitting(X: pd.DataFrame):\n    from sklearn.model_selection import train_test_split\n    return sklearn.model_selection.train_test_split(X,test_size = 0.2, stratify = X.Churn)\n\nX = df.copy()\nX_train, X_val = StratifiedSplitting(X)","1ff7c662":"def get_features(df: pd.DataFrame, ID, label):\n    return [column for column in df.columns if column not in label+ID]","db4d6791":"X = X_train\n\ndef build_new_feature(df_churn: pd.DataFrame):\n    X = df_churn.copy()\n    \n    \n    \n    X['AverageCharges'] = X['TotalCharges']\/(X.tenure)\n    X['AverageCharges'] = X.AverageCharges.replace([np.inf, -np.inf],np.nan).fillna(X.MonthlyCharges)\n    X['PriceChange'] = (X.MonthlyCharges - X.AverageCharges)\/(X.AverageCharges)\n    X['Years'] = (X.tenure\/(12.0)).astype(int)\/6\n    X['NewCustomer'] = np.where(X.tenure==0,1,0)\n    \n    X.drop(columns=['TotalCharges','MonthlyCharges','tenure'], inplace = True)\n    return X\n\nX = build_new_feature(X)\n\nfeatures = get_features(X, ID, label)\n\ndef convert_to_bool(df_churn: pd.DataFrame):\n    X = df_churn.copy()\n    \n    X['gender'] = (X.gender=='Male')\n    X['Partner'] = (X.Partner=='Yes')\n    X['Dependents'] = (X.Dependents=='Yes')\n    \n    X['PhoneService'] = (X.PhoneService=='Yes')\n    X['MultipleLines'] = (X.MultipleLines=='Yes')\n    X['OnlineService'] = (X.OnlineSecurity=='Yes') | (X.OnlineBackup =='Yes')\n    X['DeviceProtection'] = (X.DeviceProtection == 'Yes')\n    X['TechSupport'] = (X.TechSupport == 'Yes')\n    X['Streaming'] = (X.StreamingTV == 'Yes') | (X.StreamingMovies == 'Yes')\n    X['PaperlessBilling'] = (X.PaperlessBilling == 'Yes')\n    X['Fiber'] = (X.InternetService=='Fiber optic')\n    X['M2m'] = (X.Contract=='Month-to-month')\n    X['OneYearContract'] = (X.Contract=='One year')\n    \n    X['NumberInternetServices'] = (X.OnlineSecurity=='Yes')+(X.OnlineBackup =='Yes')+(X.DeviceProtection == 'Yes')+(X.TechSupport == 'Yes')+(X.StreamingTV == 'Yes') + (X.StreamingMovies == 'Yes')\n    X['NumberInternetServices'] = X['NumberInternetServices']\/6\n    \n    \n    X['AutomaticPayment'] = (X.PaymentMethod=='Bank transfer (automatic)')|(X.PaymentMethod=='Credit card (automatic)')\n    X['CreditCard'] = X.PaymentMethod=='Credit card (automatic)'\n    X['Mail'] = (X.PaymentMethod=='Mailed check')\n    \n    X.drop(columns=['PhoneService', 'OnlineSecurity', 'OnlineBackup', \n                    'StreamingTV', 'StreamingMovies','PaymentMethod','InternetService','Contract'], \n           inplace=True)\n    \n    return X\n\nX = convert_to_bool(X)\n\ndef normalize(X, x_min = None, x_max = None):\n    if (x_min == None)|(x_max == None):\n        x_min = X.min()\n        x_max = X.max()\n        return (X - x_min)\/(x_max - x_min), x_min, x_max\n    else:\n        return (X - x_min)\/(x_max - x_min)\n\nX.AverageCharges, x_min,x_max = normalize(X.AverageCharges)\n\nX_val = convert_to_bool(\n    build_new_feature(X_val)\n)\nX_val.AverageCharges = normalize(X_val.AverageCharges,x_min,x_max)","fa77efab":"features = get_features(X, ID, label)\nfeatures","67082a04":"numerical_features = X.select_dtypes(include='number').columns.to_list()\n\nbool_features = X.select_dtypes(include='bool').columns.to_list()\n\nassert set(numerical_features + bool_features) == set(features) ","c59a1624":"import seaborn as sns\nsns.set(style=\"ticks\", color_codes=True)\n\nnYes = X[X.Churn=='Yes'].shape[0]\nnNo = nrows - nYes\n\nX_sample = pd.concat([\n    X[X.Churn=='Yes'],\n    X[X.Churn=='No'].sample(n=nYes)\n])[numerical_features + label].sample(frac=1)\n\nsns.pairplot(X_sample, hue=\"Churn\")","32434c40":"def display_PrecisionRecallCurve(classifier, X, Y, pos_label = 'Yes'):\n    \n    from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n    \n    model = classifier['model']\n    name = classifier['name']\n    \n    predict_proba = model.predict_proba(X)\n    precision, recall, thresholds = precision_recall_curve(Y==pos_label,\n                                                           probas_pred = predict_proba[:,1],\n                                                           pos_label=True)\n    display = PrecisionRecallDisplay(recall, \n                                     precision, \n                                     estimator_name = name)                                                \n    display.plot()\n    \n    aucpr = average_precision_score((Y==pos_label).values.ravel(), \n                                             model.predict_proba(X)[:,1], \n                                             pos_label=True)\n    print('AUCPR - '+ name + ': ', aucpr)\n    \n    return precision, recall, thresholds, aucpr","c40f83c9":"def train_dummy_classifier(train: pd.DataFrame, ID, label):\n    \n    import matplotlib.pyplot as plt\n    from sklearn.dummy import DummyClassifier\n    from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n    \n    features = get_features(train, ID, label)\n    \n    dummy_model = DummyClassifier(strategy='constant', constant='No')\n    \n    X,Y = train[features], train[label]\n\n    dummy_model.fit(X,Y)\n    \n    precision, recall, thresholds, aucpr = display_PrecisionRecallCurve(\n        {'model':dummy_model,'name':'dummy'}, X,Y\n    )\n    \n    return {'name':'dummy_model',\n            'model': dummy_model, \n            'precision': precision, \n            'recall': recall, \n            'thresholds': thresholds, \n            'aucpr': aucpr}\n\nX_train = X\ndummy_cl = train_dummy_classifier(X_train, ID, label) ","8baab5cf":"def train_logistic_regression(train: pd.DataFrame, ID, label):\n    from sklearn.linear_model import LogisticRegression\n    from imblearn.pipeline import make_pipeline\n    from imblearn.under_sampling import RandomUnderSampler\n    \n    from sklearn.model_selection import cross_validate\n    from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n\n    model = make_pipeline(\n        RandomUnderSampler(random_state=0),\n        LogisticRegression(solver='sag', max_iter=1000, tol=0.001)\n    )\n    \n    features = get_features(train, ID, label)\n    X,Y = train[features], train[label]\n    \n    print(X.info())\n    \n    cv_results = cross_validate(estimator = model,X = X.values, y = (Y=='Yes').values.ravel(), \n                                cv = 7, scoring = ['average_precision','precision','recall'],\n                                return_estimator = True, return_train_score = True\n                               )\n    \n    model = make_pipeline(\n        RandomUnderSampler(random_state=0),\n        LogisticRegression(solver='sag', max_iter=1000, tol=0.0001)\n    )\n    \n    model.fit(X, (Y=='Yes').values.ravel())\n    \n    precision = {\n        'avg':np.mean(cv_results['test_precision']),\n        'std': np.std(cv_results['test_precision'])\n    }\n    \n    recall = {\n        'avg':np.mean(cv_results['test_recall']),\n        'std': np.std(cv_results['test_recall'])\n    }\n    \n    aucpr = {\n        'avg':np.mean(cv_results['test_average_precision']),\n        'std': np.std(cv_results['test_average_precision'])\n    }\n    \n    \n    _ = display_PrecisionRecallCurve(\n        {'name':'LogisticRegression',\n         'model': model['logisticregression']}, \n        X,Y\n    )\n    \n    return {'name':'LogisticRegression',\n    'model': model['logisticregression'], \n            'precision': precision, \n            'recall': recall, \n            'aucpr': aucpr}\n\nX_train = X\nlogistic_cl = train_logistic_regression(X_train, ID, label)\n\nprint('\\n'+logistic_cl['name']+'\\n')\nprint('AUCPR (training):',logistic_cl['aucpr']['avg'],' (+\/- ',round(logistic_cl['aucpr']['std'],5),')')","82d98c34":"model = logistic_cl['model']\n\nfeature_importance = pd.DataFrame(list(zip(features,np.exp(model.coef_[0]))), columns = ['Feature','Importance'])\nfeature_importance.sort_values(by = 'Importance',ascending = False).plot.bar(x='Feature', title = 'Feature Importance for ' + logistic_cl['name'])\n","d0dd6b68":"def train_lgb(train: pd.DataFrame, ID, label):\n    from lightgbm import LGBMClassifier\n    from imblearn.pipeline import make_pipeline\n    from imblearn.under_sampling import RandomUnderSampler\n    \n    from sklearn.model_selection import cross_validate\n    \n    from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n    \n    model = make_pipeline(\n        #RandomUnderSampler(),\n        LGBMClassifier(boosting_type='gbdt', n_estimators = 50, \n                       max_depth = 3, learning_rate= 0.3, is_unbalance = True)\n    )\n    \n    features = get_features(train, ID, label)\n    X,Y = train[features], train[label]\n    \n    print(X.info())\n    \n    cv_results = cross_validate(estimator = model,X = X.values, y = (Y=='Yes').values.ravel(), \n                                cv = 7, scoring = ['average_precision','precision','recall'],\n                                return_estimator = True, return_train_score = True\n                               )\n    \n    model = make_pipeline(\n        #RandomUnderSampler(random_state=0),\n        LGBMClassifier(boosting_type='gbdt', n_estimators = 50, \n                       max_depth = 3, learning_rate= 0.3, is_unbalance = True)\n    )\n    \n    model.fit(X, (Y=='Yes').values.ravel())\n    \n    precision = {\n        'avg':np.mean(cv_results['test_precision']),\n        'std': np.std(cv_results['test_precision'])\n    }\n    \n    recall = {\n        'avg':np.mean(cv_results['test_recall']),\n        'std': np.std(cv_results['test_recall'])\n    }\n    \n    aucpr = {\n        'avg':np.mean(cv_results['test_average_precision']),\n        'std': np.std(cv_results['test_average_precision'])\n    }\n    \n    _ = display_PrecisionRecallCurve(\n        {'name':'LGBMClassifier',\n         'model': model['lgbmclassifier']}, \n        X,Y\n    )\n    \n    print(model)\n    return {'name':'LGBMClassifier', 'model':model['lgbmclassifier'],'precision':precision,'recall':recall,'aucpr':aucpr}\n\n\nlgb_cl = train_lgb(X_train, ID, label)\nlgb_cl\n\nprint('\\n'+lgb_cl['name']+'\\n')\nprint('AUCPR (training):',lgb_cl['aucpr']['avg'],' (+\/- ',round(lgb_cl['aucpr']['std'],5),')')","1cfb73e0":"feature_importance = pd.DataFrame(\n    list(zip(lgb_cl['model'].feature_importances_, lgb_cl['model'].feature_name_)),\n    columns=['Importance','Feature'])\nfeature_importance.sort_values(by='Importance', ascending=False).plot.bar(x='Feature')","b8881d61":"def train_svc(train: pd.DataFrame, ID, label):\n    from sklearn.svm import SVC\n    from imblearn.pipeline import make_pipeline\n    from imblearn.under_sampling import RandomUnderSampler\n    \n    from sklearn.model_selection import cross_validate\n    \n    from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n    \n    model = make_pipeline(\n        RandomUnderSampler(),\n        SVC(kernel='rbf', gamma = 'auto', C = 1, probability = True)\n    )\n    \n    features = get_features(train, ID, label)\n    X,Y = train[features], train[label]\n    \n    print(X.info())\n    \n    cv_results = cross_validate(estimator = model,X = X.values, y = (Y=='Yes').values.ravel(), \n                                cv = 7, scoring = ['average_precision','precision','recall'],\n                                return_estimator = True, return_train_score = True\n                               )\n    \n    model = make_pipeline(\n        RandomUnderSampler(random_state=0),\n        SVC(kernel='rbf', gamma = 'auto', C = 1e-1, probability = True)\n    )\n    \n    model.fit(X, (Y=='Yes').values.ravel())\n    \n    precision = {\n        'avg':np.mean(cv_results['test_precision']),\n        'std': np.std(cv_results['test_precision'])\n    }\n    \n    recall = {\n        'avg':np.mean(cv_results['test_recall']),\n        'std': np.std(cv_results['test_recall'])\n    }\n    \n    aucpr = {\n        'avg':np.mean(cv_results['test_average_precision']),\n        'std': np.std(cv_results['test_average_precision'])\n    }\n    \n    _ = display_PrecisionRecallCurve(\n        {'name':'SVCClassifier',\n         'model': model['svc']}, \n        X,Y\n    )\n    \n    print(model)\n    return {'name':'SVCClassifier', 'model':model['svc'],'precision':precision,'recall':recall,'aucpr':aucpr}\n\n\nsvc_cl = train_svc(X_train, ID, label)\nsvc_cl\n\nprint('\\n'+lgb_cl['name']+'\\n')\nprint('AUCPR (training):',svc_cl['aucpr']['avg'],' (+\/- ',round(svc_cl['aucpr']['std'],5),')')","31bb8c36":"lgb_cl, logistic_cl, svc_cl","f3ae10d9":"from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n\nfor classifier in [lgb_cl, logistic_cl, svc_cl]:\n    model = classifier['model']\n    name = classifier['name']\n    \n    _ = display_PrecisionRecallCurve(\n        {'name':name,\n         'model': model}, \n        X[features],X[label]\n    )","26d082d5":"from lightgbm import plot_importance\n\nmodel = lgb_cl['model']\nfeatures = lgb_cl['model'].feature_name_\n\nplot_importance(lgb_cl['model'], height = 0.5)\n\nfor n,feature in enumerate(features):\n    print('No.'+ str(n)+': '+feature)","7e5f161d":"from sklearn.inspection import partial_dependence, plot_partial_dependence\n\n\npdp,axes = partial_dependence(model, X_val[features], ['PriceChange'])\nPriceChange_PDP = pd.DataFrame({'x':axes[0],'pdp':pdp[0]})\nPriceChange_PDP.plot.line(x='x',y='pdp', title='PriceChange PDP')\n\npdp,axes = partial_dependence(model, X_val[features], ['AverageCharges'])\nAverageCharges_PDP = pd.DataFrame({'x':axes[0],'pdp':pdp[0]})\nAverageCharges_PDP.plot.line(x='x',y='pdp', title='AverageCharges PDP')\n\n\npdp,axes = partial_dependence(model, X_val[features], ['Years'])\nYears_PDP = pd.DataFrame({'x':axes[0],'pdp':pdp[0]})\nYears_PDP.plot.line(x='x',y='pdp', title='Years PDP')\n","1ae4fb58":"import shap\n\nmodel = lgb_cl['model']\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X_val[features])\nexpected_value = explainer.expected_value\n\n\n############## visualizations #############\n# Generate summary dot plot\nshap.summary_plot(shap_values, X_val[features],title=\"SHAP summary plot\",plot_type='bar') \n\n\n\"\"\"# Generate waterfall plot  \nshap.plots._waterfall.waterfall_legacy(expected_value[0], \n                                       shap_values[0], \n                                       features=X[features].loc[0,:], feature_names=features, max_display=15, show=True)\"\"\"\n\n\n\"\"\"# Generate dependence plot\nfor name in X_val.columns:\n     shap.dependence_plot(name, shap_values, X_val)\"\"\"\n\"\"\"\n# Generate force plot - Multiple rows \nshap.force_plot(explainer.expected_value, shap_values[:100,:], X_val[features].iloc[:100,:])\"\"\"\n\nTrue","62084c68":"import lime\nimport lime.lime_tabular\nistance_number = 0\n\n############## create explainer ###########\n# we use the dataframes splits created above for SHAP\nlime_explainer = lime.lime_tabular.LimeTabularExplainer(X_val[features].to_numpy(), feature_names=X_val[features], class_names=['No','Yes'], verbose=True)\n\n############## visualizations #############\nexp = lime_explainer.explain_instance(X_val[features].iloc[istance_number,:], model.predict_proba, num_features=20)\nexp.show_in_notebook(show_table=True)","0d4ab607":"!pip install dice-ml","5add208f":"import dice_ml\n\nfrom dice_ml.utils import helpers # helper functions\n\ncontinuous_features = X_val.select_dtypes(include='float').columns.to_list()\n\ndataframe = X_val[features+label].copy()\ndataframe.loc[:,dataframe.dtypes.eq('bool')] = dataframe.loc[:,dataframe.dtypes.eq('bool')].astype(int)\n\n#dataset for explaination\nd = dice_ml.Data(\n    dataframe = dataframe,\n    continuous_features = continuous_features,\n    outcome_name = label[0]\n)\n\n#trained model\nm = dice_ml.Model(model=model, backend = 'sklearn')\n\n# DiCE explanation instance\nexp = dice_ml.Dice(d,m)\n","3108debe":"instance_number = 1\n\n# Generate counterfactual examples\ndice_exp = exp.generate_counterfactuals(\n    dataframe[features][1:2], \n    total_CFs=4, \n    desired_class='opposite',\n)\n# Visualize counterfactual explanation\ndice_exp.visualize_as_dataframe(show_only_changes=True)\n","2841a6b8":"instance_number = 1\n\npredicted_outcome = np.array(list(map(lambda x: np.argmax(x),\n                                      m.get_output(dataframe[features])\n                                     ))).reshape(-1,1)\n\n# Generate counterfactual examples\ndice_exp = exp.generate_counterfactuals(\n    dataframe[predicted_outcome==1][features][5:6], \n    total_CFs=4, \n    desired_class=0,\n    features_to_vary = ['Partner','PriceChange']\n)\n# Visualize counterfactual explanation\ndice_exp.visualize_as_dataframe(show_only_changes=True)\n","c4b590b4":"### Building New Features","5fb01c5f":"#### Feature Importance (model specific)","7a9c9b52":"### Logistic Regression","a502f9d2":"## Section I - Retrieve Data","b8822057":"### Apply Models on Validation Set","ac1d5f01":"#### Basic cleaning for TotalCharges\n\nThe total charges are missing if the tenure is equal to 0. Hence, we replace null values with 0s.","d40b8510":"#### Shap Values (shap)","53d3d690":"#### Lime","4b395088":"#### Dummy Classifier","dd60b11a":"## Explain Prediction\n\nWIP","e437f04b":"### LightGBM","214e7675":"## Section II - Model Training","84f77453":"# Introduction\n\nIn this notebook, I'll try to bring some insights and explanation on a ML model using XAI techniques. Since my goal is to exercise and improve my skills and knowledge about XAI, in this notebook I'm going to focus on these things. For this reason I'm not going to put much effort on model tuning or other fundamental tasks.\n\nFor this purpose, I've chosen the *telco-customer-churn* dataset. A Churn Model is in my opinion a good use case for XAI. Indeed, it allows to address few tasks based on XAI:\n\n- Address model fairness and feature impact on target\n- Explain (locally) a prediction\n- Find counterfactuals\n\n\n\nThis notebook is organized as follows:\n1) In the **First Section**, I retrieve data, summarise some statistical info and apply basic cleaning to the raw dataset;\n\n2) In the **Second Section**, I focus on build some classifiers and validate the using the Precision-Recall curve;\n\n3) In the **Last Section**, I choose one of the classifiers and provide some insights on it. Even if some of the technique may be model-specific, this section mainly use model-agnostic methods.\n\nSome useful libraries that I've been exploring for this notebook:\n- [Scikit-learn Inspection submodule](https:\/\/scikit-learn.org\/stable\/inspection.html): it is rather interesting and useful. However, there are issues due to the wrong version which is available on Kaggle.\n- [Shap](https:\/\/shap.readthedocs.io\/en\/latest\/index.html)\n- [LIME - by marcotcr](https:\/\/github.com\/marcotcr\/lime)\n- [alibi - by SeldonIO](https:\/\/github.com\/SeldonIO\/alibi)\n- [DiCE - by interpretml](https:\/\/github.com\/interpretml\/DiCE)","39494c94":"*Bool features' plots - WIP*","6e3482cc":"### Splitting Dataset","cf5851e5":"### SVC Model","8aae8d69":"#### Partial Dependence Plot (sklearn)","39c7cb88":"#### Counterfactual (DiCE)"}}