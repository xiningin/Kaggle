{"cell_type":{"da21c87d":"code","51d1210d":"code","9435054c":"code","34ca1a83":"code","5ab5a825":"code","1d6bd871":"code","2e32ca3c":"code","2a47547c":"code","8d1165ea":"code","3af13f73":"code","e81511c4":"code","9aa40920":"code","90596c23":"code","c3c9aaf2":"code","f114e9db":"code","804d6561":"code","4177d852":"code","13da7dff":"code","695249f7":"code","9e7958a3":"code","33639a53":"code","b5531a47":"code","b712404c":"code","b5bd93ae":"code","815677d3":"code","726b532b":"code","4cbb9f16":"code","d5b4c060":"code","6b43e509":"code","9fc97194":"code","b58d6c75":"code","3a916da8":"markdown","46280ba4":"markdown"},"source":{"da21c87d":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","51d1210d":"train_folder = '\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/'","9435054c":"import os","34ca1a83":"#find number of files in train folder\nn = 0\nfor _, _, filenames in os.walk(train_folder):\n    for filename in filenames:\n        n += 1","5ab5a825":"n","1d6bd871":"ds_filelist_train = tf.data.Dataset.list_files(file_pattern = train_folder + '*\/*', shuffle = False)","2e32ca3c":"ds_filelist_train = ds_filelist_train.shuffle(buffer_size = n, reshuffle_each_iteration = False)","2a47547c":"table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(tf.constant(['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']), tf.range(6)), -1)\ndef load_imgs(filepath):\n    img = tf.io.read_file(filepath)\n    img = tf.io.decode_jpeg(img, channels = 3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, [150, 150])\n    \n    tag = tf.strings.split(filepath, os.path.sep)[-2]\n\n    label = table.lookup(tag)\n    \n    return img, label","8d1165ea":"ds_train = ds_filelist_train.map(load_imgs, num_parallel_calls = tf.data.experimental.AUTOTUNE)","3af13f73":"def img_augmentation(img, label):\n    #img = tf.image.random_contrast(img, 0.1, 0.9)\n    #img = tf.image.random_hue(img, 0.5)\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_crop(img, (125, 125, 3))\n    return tf.image.resize(img, (150, 150)), label","e81511c4":"ds_train = ds_train.map(img_augmentation, num_parallel_calls = tf.data.experimental.AUTOTUNE)","9aa40920":"for i in ds_train.take(1):\n    print(i)","90596c23":"#Tranfer Learning using InceptionV3\nInception_v3 = tf.keras.applications.InceptionV3(include_top = False, input_shape = (150, 150, 3), weights = None)\n\n#load weights\nlocal_weights_file = '\/kaggle\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\nInception_v3.load_weights(local_weights_file)","c3c9aaf2":"Inception_v3.summary()","f114e9db":"#freeze layers\nfor layer in Inception_v3.layers:\n    layer.trainable = False","804d6561":"#get last layer\nlast_layer = Inception_v3.layers[-1]\nprint(last_layer.output_shape)\nlast_output = last_layer.output","4177d852":"x = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(1024, activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(6)(x)\n\nmodel = tf.keras.Model(inputs = Inception_v3.input, outputs = x)","13da7dff":"model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])","695249f7":"#Prepare the data for training\nds_train_orig = ds_train\nds_train = ds_train_orig.take(13000)\nds_valid = ds_train_orig.skip(13000)\n\n#shuffle, batch\nds_train = ds_train.shuffle(n).batch(20).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\nds_valid = ds_valid.batch(20).cache().prefetch(buffer_size = tf.data.experimental.AUTOTUNE)","9e7958a3":"#Adding Callbacks\ncallback_1 = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3, verbose = 1)\ncallback_2 = tf.keras.callbacks.ModelCheckpoint(filepath = '\/kaggle\/working\/model_checkpoints\/checkpoint_{epoch}.ckpt', save_weights_only = True, verbose = 1)","33639a53":"history = model.fit(ds_train, epochs = 20, validation_data = ds_valid, callbacks = [callback_1, callback_2])","b5531a47":"hist = history.history","b712404c":"epochs = np.arange(len(hist['loss'])) + 1\n\nfig, ax = plt.subplots(1, 2, figsize = (20, 8))\n\nax[0].plot(epochs, hist['loss'], '-o', label = 'training_loss')\nax[0].plot(epochs, hist['val_loss'], '--<', label = 'val_loss')\nax[0].legend()\nax[0].set_title('Training vs. Val Loss')\n\nax[1].plot(epochs, hist['accuracy'], '-o', label = 'training_accuracy')\nax[1].plot(epochs, hist['val_accuracy'], '--<', label = 'val_accuracy')\nax[1].legend()\nax[1].set_title('Training vs. Val Accuracy')\n","b5bd93ae":"test_folder = '\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/'\nds_filelist_test = tf.data.Dataset.list_files(file_pattern = test_folder + '*\/*', shuffle = False)\nds_test = ds_filelist_test.map(load_imgs, num_parallel_calls = tf.data.experimental.AUTOTUNE)","815677d3":"ds_test = ds_test.batch(20)","726b532b":"model.evaluate(ds_test)","4cbb9f16":"ds_sample = ds_test.unbatch().shuffle(n, reshuffle_each_iteration = False).batch(10).take(1)","d5b4c060":"pred = model.predict(ds_sample)","6b43e509":"pred_prob = tf.nn.softmax(pred, axis = 1)\npred_label = tf.math.argmax(pred_prob, axis = 1)\npred_label_prob = tf.math.reduce_max(pred_prob, axis = 1)","9fc97194":"rev_table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(tf.range(6), tf.constant(['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street'])), 'x')\npred_tag = rev_table.lookup(tf.cast(pred_label, tf.int32))","b58d6c75":"fig = plt.figure(figsize = (15, 8))\nfor i, sample in enumerate(ds_sample.unbatch()):\n    img = sample[0]\n    ax = fig.add_subplot(2, 5, i + 1)\n    ax.imshow(img)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n    actual_tag = rev_table.lookup(sample[1])\n    ax.text(0.5, -0.15, f'Actual: {actual_tag.numpy()}\\nPredicted: {pred_tag[i].numpy()}\\nProbability: {pred_label_prob[i].numpy():.2%}',\n            size = 14, horizontalalignment = 'center', verticalalignment = 'center', transform = ax.transAxes)\n    \nplt.tight_layout()\nplt.show()","3a916da8":"model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), metrics = ['accuracy'])","46280ba4":"#Build the CNN Model\nmodel = tf.keras.Sequential() #input (150, 150, 3)\nmodel.add(tf.keras.layers.Conv2D(filters = 27, kernel_size = 2, padding = 'same', activation = 'relu', input_shape = (150, 150, 3))) #result in (150, 150, 27)\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = 5)) #result in (30, 30, 27)\nmodel.add(tf.keras.layers.Dropout(0.2)) #Drop out prob 20%\nmodel.add(tf.keras.layers.Conv2D(filters = 54, kernel_size = 5, padding = 'same')) #result in (30, 30, 54)\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = 5)) #result in (6, 6, 54)\nmodel.add(tf.keras.layers.Flatten()) #Flatten to 6 * 6 * 54\nmodel.add(tf.keras.layers.Dense(100, activation = 'relu')) # 100\nmodel.add(tf.keras.layers.Dropout(0.5)) #Drop out prob 50%\nmodel.add(tf.keras.layers.Dense(6)) # number of outputs = 6\n\nmodel.summary()"}}