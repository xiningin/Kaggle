{"cell_type":{"5bb1d886":"code","076bea68":"code","9e3aac4a":"code","32c9e441":"code","125bffb7":"code","d0cd0853":"code","e4790be5":"code","8ad20c6b":"code","b7b79ea5":"code","5ecfc41e":"code","1eade640":"code","88142b47":"code","81cf0aa1":"code","cadc3f3b":"code","8ec22b43":"markdown"},"source":{"5bb1d886":"import tensorflow as tf\nimport os\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nimport PIL","076bea68":"%cd ..\/input\/\nos.listdir()","9e3aac4a":"os.listdir('merged-trash-dataset\/DATASET\/')","32c9e441":"print('TRAIN R IS ', len(os.listdir('merged-trash-dataset\/DATASET\/TRAIN\/R')))\nprint('TRAIN O IS ', len(os.listdir('merged-trash-dataset\/DATASET\/TRAIN\/O')))\nprint('TEST R IS ', len(os.listdir('merged-trash-dataset\/DATASET\/TEST\/R')))\nprint('TEST O IS ', len(os.listdir('merged-trash-dataset\/DATASET\/TEST\/O')))","125bffb7":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Input, Dropout\n\nmodel = Sequential()\nmodel.add(Conv2D(224, kernel_size=(5, 5), input_shape=(224,224,3),activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (5, 5), activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\nmodel.summary()","d0cd0853":"train_gen = ImageDataGenerator(rescale=1.\/255,\n                               rotation_range=40,\n                              shear_range=0.2,\n                              zoom_range=0.2,\n                              horizontal_flip=True\n                              )\ntest_gen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_dir = 'merged-trash-dataset\/DATASET\/TRAIN\/'\ntest_dir = 'merged-trash-dataset\/DATASET\/TEST\/'\n\ntrain_generator = train_gen.flow_from_directory(train_dir, batch_size = 32, target_size = (224, 224), class_mode = 'binary')\ntest_generator = test_gen.flow_from_directory(test_dir, batch_size = 32, target_size = (224, 224), class_mode = 'binary')\n\nprint(train_generator)\nprint(test_generator)","e4790be5":"hist = model.fit_generator(train_generator, epochs = 40, validation_data = test_generator)\n","8ad20c6b":"%matplotlib inline\nacc = hist.history['acc']\nloss = hist.history['loss']\nval_acc = hist.history['val_acc']\nval_loss = hist.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Testing Accuracy\")\nplt.title('Training vs Testing Accuracy')\nplt.figure()\n\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Testing Loss\")\nplt.title('Training vs Testing Loss')\nplt.show()","b7b79ea5":"from sklearn.metrics import classification_report, confusion_matrix\n\npred = model.predict_generator(test_generator, verbose = 1)\ny_pred = np.argmax(pred, axis = 1)\nprint('Confusion Matrix')\nprint(confusion_matrix(test_generator.classes,y_pred))\nprint('Classification Report')\ntarget_names = ['Organic', 'Recyclable']\nprint(classification_report(test_generator.classes,y_pred, target_names = target_names))\n\n","5ecfc41e":"%cd ..\/working\/ \nos.listdir() \nmodel.save('trashModel2.h5')","1eade640":"import cv2\nvideo_capture = cv2.VideoCapture(0)\n# Check success\nif not video_capture.isOpened():\n    raise Exception(\"Could not open video device\")\n# Read picture. ret === True on success\nret, frame = video_capture.read()\n# Close device\nvideo_capture.release()\n\nimport sys\nfrom matplotlib import pyplot as plt\nframeRGB = frame[:,:,::-1] # BGR => RGB\nplt.imshow(frameRGB)","88142b47":"%cd ..\/input\/predictiondata\/\nfrom PIL import Image\nimport numpy\norg_img = Image(\"Organic.jpg\")\nrec_img = Image(\"Recyclable.jpg\")\nlabelNames=['Organic','Recyclable']","81cf0aa1":"#Organic prediction\norg_img1 = numpy.array(org_img)\nprint('Actual label: Organic')\n# Prepare image to predict\n#test_image =np.expand_dims(org_img, axis=0)\n#print('Input image shape:',org_img.shape)\nprint('Predict Label:',labelNames[model.predict_classes(org_img1,batch_size=1)[0]])\nprint('\\nPredict Probability:\\n', model.predict_proba(org_img1,batch_size=1))","cadc3f3b":"#Recyclable prediction\nplt.imshow(rec_img,aspect='auto')\nprint('Actual label: Recyclable')\n# Prepare image to predict\ntest_image =np.expand_dims(rec_img, axis=0)\nprint('Input image shape:',test_image.shape)\nprint('Predict Label:',labelNames[model.predict_classes(test_image,batch_size=1)[0]])\nprint('\\nPredict Probability:\\n', model.predict_proba(test_image,batch_size=1))","8ec22b43":"Using Model 1 - prediction\n"}}