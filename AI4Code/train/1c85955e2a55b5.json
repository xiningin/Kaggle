{"cell_type":{"2eca3185":"code","bf4fa878":"code","b1d24cb5":"code","5ca5c414":"code","8155f28b":"code","51d5adac":"code","39cb417f":"code","928173f6":"code","79408737":"code","5cb4cd62":"code","62c8bad8":"code","b97aa1cb":"code","b6293fc4":"code","048191d0":"code","c8af5d50":"code","40435029":"code","e2d36885":"code","62269ce4":"code","1161a37a":"code","124eb2a0":"markdown","c3dc6683":"markdown"},"source":{"2eca3185":"# Imported Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport collections\nimport imblearn\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn import model_selection\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 14, 8\nRANDOM_SEED = 42\nLABELS = [\"Normal\", \"Fraud\"]\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")","bf4fa878":"import pandas as pd\ndata = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndata.head()\n","b1d24cb5":"data.isnull().sum().max()\n","5ca5c414":"print('Legitimate transactions are', round(data['Class'].value_counts()[0]\/len(data) * 100,2), '% of the dataset')\nprint('Fraud transactions are', round(data['Class'].value_counts()[1]\/len(data) * 100,2), '% of the dataset')","8155f28b":"#colors = [\"#DF0101\", \"#0101DF\"]\ncolors = ['red', 'gold']\nexplode = (0.1, 0)  # explode 1st slice\n\n#sns.countplot('Class', data=data, palette=colors)\nlabels = ['Fraud (0.17)', 'Legit (99.83)']\nsizes = [492,284315]\nplt.pie(sizes,explode = explode, colors=colors, labels = labels,shadow=True, startangle=90)\n#plt.title('Distribution of 2 classes \\n (0: Legit || 1: Fraud)', fontsize=10)\n\n\n","51d5adac":"# Scaling the Time and Amount features\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\nstd_scaler = StandardScaler()\nrob_scaler = RobustScaler()\n\ndata['scaled_amount'] = std_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\ndata['scaled_time'] = std_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n\ndata.drop(['Time','Amount'], axis=1, inplace=True)\nscaled_amount = data['scaled_amount']\nscaled_time = data['scaled_time']\n\ndata.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\ndata.insert(0, 'scaled_amount', scaled_amount)\ndata.insert(1, 'scaled_time', scaled_time)\n\n# Amount and Time are Scaled!\n\ndata.head()","39cb417f":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nprint('No Frauds', round(data['Class'].value_counts()[0]\/len(data) * 100,2), '% of the dataset')\nprint('Frauds', round(data['Class'].value_counts()[1]\/len(data) * 100,2), '% of the dataset')\n\nX = data.drop('Class', axis=1)\ny = data['Class']\n\nsss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n\n# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the Distribution of the labels\n\n\n# Turn into an array\noriginal_Xtrain = original_Xtrain.values\noriginal_Xtest = original_Xtest.values\noriginal_ytrain = original_ytrain.values\noriginal_ytest = original_ytest.values\n\n# See if both the train and test label distribution are similarly distributed\ntrain_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\nprint('-' * 100)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label\/ len(original_ytrain))\nprint(test_counts_label\/ len(original_ytest))","928173f6":"# To improve the accuracy of the model, we can remove those features that are highly\n# correlated with the class and are extreme outliers. We can change the threshold \n# to detect the outliers\nfrom scipy.stats import norm\n\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n\nv14_fraud_dist = data['V14'].loc[data['Class'] == 1].values\nsns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\nax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv12_fraud_dist = data['V12'].loc[data['Class'] == 1].values\nsns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\nax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n\n\nv17_fraud_dist = data['V17'].loc[data['Class'] == 1].values\nsns.distplot(v17_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\nax3.set_title('V17 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nplt.show()","79408737":"# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)\nv14_fraud = data['V14'].loc[data['Class'] == 1].values\nq25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\nprint('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\nv14_iqr = q75 - q25\nprint('iqr: {}'.format(v14_iqr))\n\nv14_cut_off = v14_iqr * 1.5\nv14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\nprint('Cut Off: {}'.format(v14_cut_off))\nprint('V14 Lower: {}'.format(v14_lower))\nprint('V14 Upper: {}'.format(v14_upper))\n\noutliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\nprint('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\nprint('V10 outliers:{}'.format(outliers))\n\ndata = data.drop(data[(data['V14'] > v14_upper) | (data['V14'] < v14_lower)].index)\nprint('----' * 44)\n\n# -----> V12 removing outliers from fraud transactions\nv12_fraud = data['V12'].loc[data['Class'] == 1].values\nq25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\nv12_iqr = q75 - q25\n\nv12_cut_off = v12_iqr * 1.5\nv12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\nprint('V12 Lower: {}'.format(v12_lower))\nprint('V12 Upper: {}'.format(v12_upper))\noutliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\nprint('V12 outliers: {}'.format(outliers))\nprint('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\ndata = data.drop(data[(data['V12'] > v12_upper) | (data['V12'] < v12_lower)].index)\nprint('Number of Instances after outliers removal: {}'.format(len(data)))\nprint('----' * 44)\n\n\n# Removing outliers V17 Feature\nv17_fraud = data['V17'].loc[data['Class'] == 1].values\nq25, q75 = np.percentile(v17_fraud, 25), np.percentile(v17_fraud, 75)\nv17_iqr = q75 - q25\n\nv17_cut_off = v17_iqr * 1.5\nv17_lower, v17_upper = q25 - v17_cut_off, q75 + v17_cut_off\nprint('V17 Lower: {}'.format(v17_lower))\nprint('V17 Upper: {}'.format(v17_upper))\noutliers = [x for x in v17_fraud if x < v17_lower or x > v17_upper]\nprint('V17 outliers: {}'.format(outliers))\nprint('Feature V17 Outliers for Fraud Cases: {}'.format(len(outliers)))\ndata = data.drop(data[(data['V17'] > v17_upper) | (data['V17'] < v17_lower)].index)\nprint('Number of Instances after outliers removal: {}'.format(len(data)))\n\n# Boxplots with outliers removed\n\nf,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n\ncolors = ['#B3F9C5', '#f9c5b3']\n# Feature V14\nsns.boxplot(x=\"Class\", y=\"V14\", data=data,ax=ax1, palette=colors)\nax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\nax1.annotate('Fewer extreme \\n outliers', xy=(0.98, -17.5), xytext=(0, -12),\n            arrowprops=dict(facecolor='black'),\n            fontsize=14)\n\n# Feature 12\nsns.boxplot(x=\"Class\", y=\"V12\", data=data, ax=ax2, palette=colors)\nax2.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\nax2.annotate('Fewer extreme \\n outliers', xy=(0.98, -17.3), xytext=(0, -12),\n            arrowprops=dict(facecolor='black'),\n            fontsize=14)\n\n# Feature V17\nsns.boxplot(x=\"Class\", y=\"V17\", data=data, ax=ax3, palette=colors)\nax3.set_title(\"V17 Feature \\n Reduction of outliers\", fontsize=14)\nax3.annotate('Fewer extreme \\n outliers', xy=(0.95, -16.5), xytext=(0, -12),\n            arrowprops=dict(facecolor='black'),\n            fontsize=14)\n\n\nplt.show()","5cb4cd62":"import itertools\n\n# Create a confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=14)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","62c8bad8":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix\n\n\n\nprint('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\nprint('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n\n# List to append the score and then find the average\naccuracy_lst = []\nprecision_lst = []\nrecall_lst = []\nf1_lst = []\nauc_lst = []\n\n# Logistic Regression\n\nlog_reg_sm = LogisticRegression()\nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\nrand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n# Implementing SMOTE Technique for Log reg\n# Cross Validating the right way\n# Parameters\nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\nfor train, test in sss.split(original_Xtrain, original_ytrain):\n    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n    best_est = rand_log_reg.best_estimator_\n    prediction = best_est.predict(original_Xtrain[test])\n    \n    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n    precision_lst.append(precision_score(original_ytrain[test], prediction))\n    recall_lst.append(recall_score(original_ytrain[test], prediction))\n    f1_lst.append(f1_score(original_ytrain[test], prediction))\n    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n    \nprint('---' * 45)\nprint('Logistic Regression')\nprint(\"accuracy: {}\".format(np.mean(accuracy_lst)))\nprint(\"precision: {}\".format(np.mean(precision_lst)))\nprint(\"recall: {}\".format(np.mean(recall_lst)))\nprint(\"f1: {}\".format(np.mean(f1_lst)))\nprint('---' * 45)\n\n# Prediction for Logistic Regression with SMOTE\nlabels = ['No Fraud', 'Fraud']\nsmote_prediction = best_est.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction, target_names=labels))\n\n\n\n","b97aa1cb":"from sklearn.metrics import confusion_matrix\n\nlog_reg_cf = confusion_matrix(original_ytest, smote_prediction)\nplot_confusion_matrix(log_reg_cf, labels, title=\"Logistic Regression \\n Confusion Matrix\")","b6293fc4":"# I skip cross validation bcs of long run time\n\nsm = SMOTE(ratio='minority', random_state=42)\nXsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)\n\n\nXsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)\n\n# KNN\nKNN_sm = KNeighborsClassifier()\n\nKNN_sm.fit(Xsm_train, ysm_train)\n# Prediction for KNN with SMOTE\nlabels = ['No Fraud', 'Fraud']\nsmote_prediction_KNN = KNN_sm.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction_KNN, target_names=labels))","048191d0":"from sklearn.metrics import confusion_matrix\n\nKNN_cf = confusion_matrix(original_ytest, smote_prediction_KNN)\nplot_confusion_matrix(KNN_cf, labels, title=\"KNN \\n Confusion Matrix\")","c8af5d50":"# I skip cross validation bcs of long run time\n\nsm = SMOTE(ratio='minority', random_state=42)\nXsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)\n\n\nXsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)\n# We Improve the score by 2% points approximately \n# Implement GridSearchCV and the other models.\n\n# RF\nRF_sm = RandomForestClassifier()\n\nRF_sm.fit(Xsm_train, ysm_train)\n# Prediction for RF with SMOTE\nlabels = ['No Fraud', 'Fraud']\nsmote_prediction_RF = RF_sm.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction_RF, target_names=labels))","40435029":"from sklearn.metrics import confusion_matrix\n\nRF_cf = confusion_matrix(original_ytest, smote_prediction_RF)\nplot_confusion_matrix(RF_cf, labels, title=\"RF \\n Confusion Matrix\")","e2d36885":"# This algorithm runs faster than the othe ones\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\n#XGBoost\naccuracy_lst = []\nprecision_lst = []\nrecall_lst = []\nf1_lst = []\nauc_lst = []\nxgb_sm = XGBClassifier()   \nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['binary:logistic'],\n              'learning_rate': [0.05], #so called `eta` value\n              'max_depth': [6],\n              'min_child_weight': [11],\n              'silent': [1],\n              'subsample': [0.8],\n              'colsample_bytree': [0.7],\n              'n_estimators': [10], #number of trees, change it to 1000 for better results\n              'missing':[-999],\n              'seed': [1337]}\nrand_xgb = RandomizedSearchCV(XGBClassifier(), parameters, n_iter=4)\n# Implementing SMOTE Technique for xgb\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['binary:logistic'],\n              'learning_rate': [0.05], #so called `eta` value\n              'max_depth': [6],\n              'min_child_weight': [11],\n              'silent': [1],\n              'subsample': [0.8],\n              'colsample_bytree': [0.7],\n              'n_estimators': [10], #number of trees, change it to 1000 for better results\n              'missing':[-999],\n              'seed': [1337]}\nfor train, test in sss.split(original_Xtrain, original_ytrain):\n    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_xgb) # SMOTE happens during Cross Validation not before..\n    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n    best_est = rand_xgb.best_estimator_\n    prediction = best_est.predict(original_Xtrain[test])\n    \n    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n    precision_lst.append(precision_score(original_ytrain[test], prediction))\n    recall_lst.append(recall_score(original_ytrain[test], prediction))\n    f1_lst.append(f1_score(original_ytrain[test], prediction))\n    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n    \nprint('---' * 45)\nprint('XGBoost')\nprint(\"accuracy: {}\".format(np.mean(accuracy_lst)))\nprint(\"precision: {}\".format(np.mean(precision_lst)))\nprint(\"recall: {}\".format(np.mean(recall_lst)))\nprint(\"f1: {}\".format(np.mean(f1_lst)))\nprint('---' * 45)\n\n# Prediction for XGBoost with SMOTE\nlabels = ['No Fraud', 'Fraud']\nsmote_prediction_xgb = best_est.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction_xgb, target_names=labels))\n\n","62269ce4":"from sklearn.metrics import confusion_matrix\n\nxgb_cf = confusion_matrix(original_ytest, smote_prediction_xgb)\nplot_confusion_matrix(xgb_cf, labels, title=\"XGB \\n Confusion Matrix\")","1161a37a":"#%% Neural Networks with SMOTE\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.layers import Dropout\n\nn_inputs = original_Xtrain.shape[1]\n\n\n# Oversampling\nn_inputs = Xsm_train.shape[1]\n\noversample_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(2, activation='softmax')\n])\noversample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\noversample_model.fit(Xsm_train, ysm_train, validation_split=0.2, batch_size=300, epochs=20, shuffle=True, verbose=2)\noversample_predictions = oversample_model.predict(original_Xtest, batch_size=200, verbose=0)\noversample_fraud_predictions = oversample_model.predict_classes(original_Xtest, batch_size=200, verbose=0)\n\noversample_smote = confusion_matrix(original_ytest, oversample_fraud_predictions)\nactual_cm = confusion_matrix(original_ytest, original_ytest)\nlabels = ['No Fraud', 'Fraud']\n\nfig = plt.figure(figsize=(16,8))\n\nfig.add_subplot(221)\nplot_confusion_matrix(oversample_smote, labels, title=\"OverSampling (SMOTE) \\n Confusion Matrix\", cmap=plt.cm.Oranges)\n\nfig.add_subplot(222)\nplot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)    \n\nprint('Neural Networks with SMOTE:')\nprint(classification_report(original_ytest, oversample_fraud_predictions))","124eb2a0":"I have examined the following classifiers to detect the fraud transactions in a dataset oversampled with SMOTE and instead of Accuracy, I have used other metrics such as confusion matrix and f1 score to evaluate the models.\nLogisiticRegression\nKNN\nRandom Forest Classifier\nXGBoost Classifier\nNeural Networks\n\n","c3dc6683":"Inspired by this notebook:\n[https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets]"}}