{"cell_type":{"b0741394":"code","1ae49043":"code","e1788346":"code","21a855df":"code","c72e0032":"code","bb7529c8":"markdown"},"source":{"b0741394":"import os\nimport torch\n# print(os.listdir('..\/input\/'))\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np","1ae49043":"# Original images\nimg5=mpimg.imread('..\/input\/000005_10.png')\nimg11=mpimg.imread('..\/input\/000011_10.png')\n\n# Monodepth results\nmono5=mpimg.imread('..\/input\/000005_10_disp.png')\nmono11=mpimg.imread('..\/input\/000011_10_disp.png')\n\n# Psmnet results\npsnet5=mpimg.imread('..\/input\/disp_kaggle.png')\npsnet11=mpimg.imread('..\/input\/disp_w.png')","e1788346":"from PIL import Image\nimg = Image.open('..\/input\/disp_w.png').convert('P', palette='ADAPTIVE')\nplt.imshow(img)","21a855df":"# Displaying monodepth images\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 10))\nax1.imshow(img5)\nax2.imshow(img5)\nax3.imshow(mono5)\nax4.imshow(psnet5)","c72e0032":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 10))\nax1.imshow(img11)\nax2.imshow(img11)\nax3.imshow(mono11)\nax4.imshow(psnet11)","bb7529c8":"# Comparing results from PSMNet and Monodepth\nComparative analysis of depth maps produced by two different approaches. PSMNet (Pyramid Stereo Matching Network) uses two images as an input while Monodepth (Unsupervised Monocular Depth Estimation with Left-Right Consistency) uses only one image.\n* PSMNet based on KinglittleQ's implementation: [https:\/\/github.com\/KinglittleQ\/PSMNet](https:\/\/github.com\/KinglittleQ\/PSMNet)  \n* Monodepth based on mrharicot's implementation: [https:\/\/github.com\/mrharicot\/monodepth](https:\/\/github.com\/mrharicot\/monodepth)"}}