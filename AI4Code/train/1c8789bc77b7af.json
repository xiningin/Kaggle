{"cell_type":{"f4a2b94c":"code","2cd2bc3a":"code","cce39807":"code","e7729032":"code","25a44556":"code","e7f22bdf":"code","f5020622":"code","e34760d0":"code","2d0561eb":"code","aa8ea917":"code","64394a7d":"code","025b4ee8":"code","83bf7134":"code","c46cd7e9":"code","7267da94":"code","eba3ec54":"code","33eb505d":"code","cddcaae7":"code","72ac6517":"code","f596b3cb":"code","25282486":"code","41e31cb0":"code","263b5b8a":"code","5a194269":"code","1884b1ca":"code","05bb5235":"code","77a427ad":"code","47758aed":"code","5c119f5e":"markdown","8570615b":"markdown","a06ad108":"markdown","15e652c5":"markdown","f9264c33":"markdown","5a7eb090":"markdown","bca2073f":"markdown","e49ca9b8":"markdown","4c047718":"markdown","8a7d4828":"markdown"},"source":{"f4a2b94c":"import pandas as pd\nimport numpy as np\nimport datetime\nimport random\nimport glob\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm_notebook as tqdm\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization,Activation,Dropout,Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n# \u4e71\u6570\u30b7\u30fc\u30c9\u56fa\u5b9a\nseed_everything(2020)","2cd2bc3a":"train = pd.read_csv('..\/input\/4th-datarobot-ai-academy-deep-learning\/train.csv')\ndisplay(train.shape)\ndisplay(train.head())","cce39807":"train_y = train['price'].values","e7729032":"#\u8907\u6570\u753b\u50cf\u3092\u8aad\u307f\u8fbc\u3080\u95a2\u6570\u3092\u5b9a\u7fa9\ndef load_multi_images(df,inputPath,size,roomType1,roomType2,roomType3,roomType4):\n    images = []\n    for i in df['id']:\n        basePath1 = os.path.sep.join([inputPath, \"{}_{}*\".format(i,roomType1)])\n        basePath2 = os.path.sep.join([inputPath, \"{}_{}*\".format(i,roomType2)])\n        basePath3 = os.path.sep.join([inputPath, \"{}_{}*\".format(i,roomType3)])\n        basePath4 = os.path.sep.join([inputPath, \"{}_{}*\".format(i,roomType4)])\n        housePaths1 = sorted(list(glob.glob(basePath1)))\n        housePaths2 = sorted(list(glob.glob(basePath2)))\n        housePaths3 = sorted(list(glob.glob(basePath3)))\n        housePaths4 = sorted(list(glob.glob(basePath4)))\n        for housePath1 in housePaths1:\n            image1 = cv2.imread(housePath1)\n            image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n            image1 = cv2.resize(image1, (size, size))\n        for housePath2 in housePaths2:\n            image2 = cv2.imread(housePath2)\n            image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n            image2 = cv2.resize(image2, (size, size))\n        for housePath3 in housePaths3:\n            image3 = cv2.imread(housePath3)\n            image3 = cv2.cvtColor(image3, cv2.COLOR_BGR2RGB)\n            image3 = cv2.resize(image3, (size, size))\n        for housePath4 in housePaths4:\n            image4 = cv2.imread(housePath4)\n            image4 = cv2.cvtColor(image4, cv2.COLOR_BGR2RGB)\n            image4 = cv2.resize(image4, (size, size))\n        image1= cv2.vconcat([image1, image2])\n        image2= cv2.vconcat([image3, image4])\n        images_concat =cv2.hconcat([image1, image2]) \n        images.append(images_concat)\n    return np.array(images) \/ 255.0","25a44556":"#\u8907\u6570\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ninputPath = '..\/input\/4th-datarobot-ai-academy-deep-learning\/images\/train_images\/'\nroomType1 = 'frontal'\nroomType2 = 'bathroom'\nroomType3 = 'bedroom'\nroomType4 = 'kitchen'\nsize = 128\n\ntrain_images = load_multi_images(train,inputPath,size,roomType1,roomType2,roomType3,roomType4)\ndisplay(train_images.shape)\ndisplay(train_images[0][0][0])\nprint(train_images.shape[1])","e7f22bdf":"test = pd.read_csv('..\/input\/4th-datarobot-ai-academy-deep-learning\/test.csv')\ndisplay(test.shape)\ndisplay(test.head())","f5020622":"#\u8907\u6570\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ninputPath = '..\/input\/4th-datarobot-ai-academy-deep-learning\/images\/test_images\/'\nroomType1 = 'frontal'\nroomType2 = 'bathroom'\nroomType3 = 'bedroom'\nroomType4 = 'kitchen'\nsize = 128\n\ntest_images = load_multi_images(test,inputPath,size,roomType1,roomType2,roomType3,roomType4)\ndisplay(test_images.shape)\ndisplay(test_images[0][0][0])\nprint(test_images.shape[1])","e34760d0":"train_table = train[['bedrooms','bathrooms','area','zipcode']]\ntest_table = test[['bedrooms','bathrooms','area','zipcode']]","2d0561eb":"num_cols =['bedrooms', 'bathrooms']\ncat_cols =['area','zipcode']","aa8ea917":"# num_cols\u3092\u6b63\u898f\u5316\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain_table[num_cols] = scaler.fit_transform(train_table[num_cols])\ntest_table[num_cols] = scaler.fit_transform(test_table[num_cols])\n\n#cat_cols\u3092Onehotencoding\ntrain_test_table = pd.concat([train_table,test_table])\ntrain_test_table = pd.get_dummies(train_test_table, drop_first=True, columns=cat_cols)\n\ntrain_table = train_test_table[:423]\ntest_table = train_test_table[423:]","64394a7d":"size = size*2","025b4ee8":"#\u8ee2\u79fb\u5b66\u7fd2\u306e\u30e2\u30c7\u30eb\u3092\u5148\u306b\u8aad\u307f\u8fbc\u3080\nfrom tensorflow.keras.applications import VGG16\nbackbone = VGG16(weights='imagenet', \n                 include_top=False,\n                 input_shape=(size, size, 3))","83bf7134":"from keras.models import Model\nfrom keras import layers\nfrom keras import Input\n\ndef multi_input_model():\n\n    #image\u30c7\u30fc\u30bf\n    image_input = backbone.output\n    x = layers.GlobalAveragePooling2D()(image_input)\n    x = layers.Dense(256, activation='relu',kernel_initializer='he_normal')(x)\n    #x = layers.Dense(128, activation='relu',kernel_initializer='he_normal')(x)\n    x = Dropout(0.5)(x)\n    output_image = layers.Dense(32, activation='relu',kernel_initializer='he_normal')(x)\n\n\n    #table_data\n    table_input = Input(shape=(479,))\n    y = layers.Dense(512, activation='relu',kernel_initializer='he_normal')(table_input)\n    y = layers.Dropout(0.2)(y)\n    y = layers.Dense(256, activation='relu',kernel_initializer='he_normal')(y)\n    y = layers.Dropout(0.2)(y)\n    y = layers.Dense(32, activation='relu',kernel_initializer='he_normal')(y)\n    y = layers.Dropout(0.2)(y)\n    output_table = Dense(32, activation='relu')(y)\n\n    #\u9023\u7d50\u3055\u305b\u308b\n    concatenated = layers.concatenate([output_image,output_table])\n\n\n    #\u5168\u7d50\u5408\u5c64\n    z = Dense(32, activation='relu')(concatenated)\n    z = Dense(8, activation='relu')(z)\n    answer = layers.Dense(1, activation='linear')(z)\n\n    model = Model(inputs=[backbone.input,table_input],outputs=answer)\n    \n    for layer in model.layers[:15]:\n        layer.trainable=False\n\n    model.compile(loss='mape', optimizer='adam', metrics=['mape']) \n\n    return model","c46cd7e9":"# callback parameter\nfilepath = \"cnn_best_model.hdf5\" \nes = EarlyStopping(patience=6, monitor='val_loss', mode='min', verbose=1) \ncheckpoint = ModelCheckpoint(monitor='val_loss', filepath=filepath, save_best_only=True, mode='auto') \nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss',  patience=3, verbose=1,  mode='min')","7267da94":"#\u8a55\u4fa1\u95a2\u6570\u306e\u5b9a\u7fa9\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","eba3ec54":"#cnn\u306e\u4e88\u6e2c\u7d50\u679c\u3092\u5165\u308c\u308barray\u4f5c\u6210\ny_pred_test = np.zeros(len(test_images))","33eb505d":"#flat\u306b\u3059\u308b\u95a2\u6570\nimport collections\ndef flatten(l):\n    for el in l:\n        if isinstance(el, collections.abc.Iterable) and not isinstance(el, (str, bytes)):\n            yield from flatten(el)\n        else:\n            yield el","cddcaae7":"#seedav1\n#kf\nseed_everything(2020)\nscores = []\nkf = KFold(n_splits=5, shuffle=True)\n\n\nfor train_ix, test_ix in kf.split(train_y):\n    X_train_=train_images[train_ix]\n    X_train_table=train_table.iloc[train_ix]\n    y_train_=train_y[train_ix]\n    X_val=train_images[test_ix]\n    X_val_table=train_table.iloc[test_ix]\n    y_val=train_y[test_ix]\n    \n    model = multi_input_model()\n    \n    history = model.fit([X_train_,X_train_table],y_train_,\n    validation_data=([X_val,X_val_table], y_val),\n    steps_per_epoch=len(X_train_) \/ 32, \n    epochs=30,\n    batch_size=32,\n    callbacks=[es, checkpoint, reduce_lr_loss])\n    \n    \n    # load best model weights\n    model.load_weights(filepath)\n    # \u8a55\u4fa1\n    valid_pred = model.predict([X_val,X_val_table], batch_size=32).reshape((-1,1))\n    mape_score = mean_absolute_percentage_error(y_val, valid_pred)\n    scores.append(mape_score)\n\n    y_pred_test += list(flatten(model.predict([test_images,test_table], batch_size=32,verbose=1)))# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f","72ac6517":"print (scores)","f596b3cb":"#seedav2\n#kf\nseed_everything(37)\nscores = []\nkf = KFold(n_splits=5, shuffle=True)\n\n\nfor train_ix, test_ix in kf.split(train_y):\n    X_train_=train_images[train_ix]\n    X_train_table=train_table.iloc[train_ix]\n    y_train_=train_y[train_ix]\n    X_val=train_images[test_ix]\n    X_val_table=train_table.iloc[test_ix]\n    y_val=train_y[test_ix]\n    \n    model = multi_input_model()\n      \n    history = model.fit([X_train_,X_train_table],y_train_,\n    validation_data=([X_val,X_val_table], y_val),\n    steps_per_epoch=len(X_train_) \/ 32, \n    epochs=30,\n    batch_size=32,\n    callbacks=[es, checkpoint, reduce_lr_loss])\n    \n    \n    # load best model weights\n    model.load_weights(filepath)\n    # \u8a55\u4fa1\n    valid_pred = model.predict([X_val,X_val_table], batch_size=32).reshape((-1,1))\n    mape_score = mean_absolute_percentage_error(y_val, valid_pred)\n    scores.append(mape_score)\n\n    y_pred_test += list(flatten(model.predict([test_images,test_table], batch_size=32,verbose=1)))# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f","25282486":"print (scores)","41e31cb0":"#seedav3\n#kf\nseed_everything(71)\nscores = []\nkf = KFold(n_splits=5, shuffle=True)\n\n\nfor train_ix, test_ix in kf.split(train_y):\n    X_train_=train_images[train_ix]\n    X_train_table=train_table.iloc[train_ix]\n    y_train_=train_y[train_ix]\n    X_val=train_images[test_ix]\n    X_val_table=train_table.iloc[test_ix]\n    y_val=train_y[test_ix]\n    \n    model = multi_input_model()\n    \n    history = model.fit([X_train_,X_train_table],y_train_,\n    validation_data=([X_val,X_val_table], y_val),\n    steps_per_epoch=len(X_train_) \/ 32, \n    epochs=30,\n    batch_size=32,\n    callbacks=[es, checkpoint, reduce_lr_loss])\n    \n    \n    # load best model weights\n    model.load_weights(filepath)\n    # \u8a55\u4fa1\n    valid_pred = model.predict([X_val,X_val_table], batch_size=32).reshape((-1,1))\n    mape_score = mean_absolute_percentage_error(y_val, valid_pred)\n    scores.append(mape_score)\n\n    y_pred_test += list(flatten(model.predict([test_images,test_table], batch_size=32,verbose=1)))# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u5024\u3092\u8db3\u3057\u3066\u3044\u304f","263b5b8a":"print (scores)","5a194269":"y_pred_test \/= 15 # \u6700\u5f8c\u306bfold\u6570\u3067\u5272\u308b","1884b1ca":"model.summary()","05bb5235":"plot_model(model, to_file='cnn.png')","77a427ad":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo' ,label = 'training loss')\nplt.plot(epochs, val_loss, 'b' , label= 'validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","47758aed":"#submit\u30c7\u30fc\u30bf\u306e\u4f5c\u6210\nsubmission = pd.read_csv('..\/input\/4th-datarobot-ai-academy-deep-learning\/sample_submission.csv')\nsubmission.price = y_pred_test\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission","5c119f5e":"# \u753b\u50cf\u3092\u8aad\u307f\u8fbc\u307f","8570615b":"# \u8a13\u7df4\u5c65\u6b74\u53ef\u8996\u5316","a06ad108":"# KFold\u3067\u30e9\u30f3\u30c0\u30e0\u30b7\u30fc\u30c9\u3092\u5909\u3048\u306a\u304c\u3089Avg\u3092\u53d6\u308b","15e652c5":"# \u6570\u5024\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f","f9264c33":"# \u30e2\u30c7\u30eb\u8a13\u7df4","5a7eb090":"# \u30e2\u30c7\u30eb\u53ef\u8996\u5316","bca2073f":"# Functional API","e49ca9b8":"# \u6700\u7d42\u7684\u306a\u30b9\u30b3\u30a2\u306enotebook\u3068\u540c\u3058\u3082\u306e\u306b\u306a\u308a\u307e\u3059","4c047718":"# Table\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0","8a7d4828":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8"}}