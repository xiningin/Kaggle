{"cell_type":{"8bc523c7":"code","0e730070":"code","2d18617b":"code","e1b86ef3":"code","428742eb":"code","a88a8c38":"code","f7c83d7a":"code","fd3483e4":"code","90b16a10":"code","af74f1d7":"code","aee24dbe":"code","b06dae4a":"code","54661221":"code","6cc53813":"code","4b7c0074":"code","3dae2aef":"code","1c78fbd8":"code","62c5c2eb":"code","1fdcac9c":"code","85babcb3":"code","7e76faa9":"code","60356a72":"code","7d9f3966":"code","6a9bab21":"code","a51fcbfd":"code","47d94f9d":"code","3afb68d6":"code","a36f993f":"code","0b10d5f5":"code","687d9d75":"code","cdef3344":"code","13912165":"code","2bd8e083":"code","9074e639":"code","bb929e4a":"code","da0b5ca1":"code","d7c94546":"code","51d4fcb3":"code","d056f6ea":"code","d979206c":"code","5d8b7d5c":"code","1b55d247":"code","0f5f8866":"code","89111ce4":"code","a8c57565":"code","09c86441":"code","87af1f03":"code","a625065e":"code","5cf2f5bb":"code","55520f8c":"code","fcb6b009":"code","a688518f":"code","14ca7f21":"code","d7d5dd14":"code","bbe7ac6e":"code","36c7f87d":"code","f41740dd":"code","d89b3e1c":"code","74eaf2c4":"code","5807814c":"code","e15c5de3":"code","c8a65447":"code","5872cd13":"code","4f7ec4d5":"code","71b1998a":"code","951a0f7f":"code","70d135bf":"code","1ba07678":"markdown","f1efacdc":"markdown","ea261cab":"markdown","a7095cea":"markdown","44d8bf9d":"markdown","601d0040":"markdown","28cb4d83":"markdown","3ee8c3dc":"markdown"},"source":{"8bc523c7":"on_kaggle = True","0e730070":"# Non-max suppression parameters for phase 0\nOTHRESH=0.05    # Maximum acceptable overlap\nPTHRESH=0.94    # Confidence threshold\nAVPTHRESH=0.65  # Minimum average confidence\n# Class probability threshold for phase 1\nTHRESH = .175\n# Confidence threshold for phase 2\nMIN_MAX_MRCNN_CONF = .975\n# Parameters for phase 3\nMINPROB = 0.69  # Value to set for below threshold confidence (<0.7)\nC1 = 1e6  # Logistic regularization parameters\nC2 = 0.06\n# Parameters for phase 5\nUNET_MINPROB = 0.28  # Minimum probability to add Unet cases\nUNET_MINCONF = 0.35  # Minimum confidence to add Unet cases\n# Parameters for phase 6\nYOLO_MINCONF = 0.15  # Minimum confidence for a yolo box to be considered\nMINMIN = 0.20  # Minimum minimum probability in an iteration of yolo additions before stopping","2d18617b":"import numpy as np \nimport pandas as pd \nimport os\nfrom sklearn import metrics\nfrom scipy.special import logit,expit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error","e1b86ef3":"os.listdir('..\/input')","428742eb":"!ls ..\/input\/gs-dense-chexnet-predict-test-from-all-models","a88a8c38":"RESULTS_LOC = '..\/input'  # Outputs from base models\nRAW_DATA_LOC = '..\/input\/rsna-pneumonia-detection-challenge'          # Raw input data\nYOLO_SUB_STEM = 'yolov3-inference-from-multiple-saved-wts-stage-2\/submission_yolo'    # YoloV3 predictions\nYOLO_SUB_STEM2 = 'yolov3-inference-from-more-saved-weights-stage-2\/submission_yolo'    # YoloV3 predictions\nMORE_YOLO_EPOCHS = [5300, 1500, 6700, 2000] if on_kaggle else []\nUNET_RESULTS_PATH = '..\/input\/resnet-unet-from-saved-weights-stage-2\/submission_resnet34unet_thr0.35.csv'  # Resnet-Unet predictions\nCHEXNET_OOF_STEM = 'rsna-oof-predictions\/predictions_valid_fold_'        # Giulia's classification model\nCHEXNET_TEST_STEM = 'gs-dense-chexnet-predict-stage-2-from-all-models\/test_preds_pth_fold'\n# ^ but fold0 may be different\nSPECIAL_FILE0 = 'gs-dense-chexnet-predict-stage-2-from-all-models\/test_preds_pth_fold0_for_combined_folds'\nCHEXNET_TEST_FILE0 = SPECIAL_FILE0 if on_kaggle else CHEXNET_TEST_STEM + '0'\nADENSE_TEST_STEM = 'andy-densenet-from-multiple-saved-weights-stage-2\/submission_adense_f'                    # Andy's classification model\nADEMSE_OOF_STEM = 'rsna-oof-predictions\/val_dense_v5_a1_f'\nMRCNN_TEST_STEM = 'mrcnn-inference-from-saved-wts-4dig-70-stage-2\/submission_mrcnn_v'  # MRCNN predicted boxes\n# ^ need to fix v8 vs v9 (same weights, different output, but here both used v8 name, so 'v8'+'',\n#   instead of 'v'+'9')\nMRCNN95_TEST_STEM = 'mrcnn-inference-from-saved-wts-2dig-95-stage-2\/submission_mrcnn_v' \\\n   if on_kaggle else MRCNN_TEST_STEM  # MRCNN predicted boxes\nMRCNN_OUT_STEM = 'temp_mrcnn_v' if on_kaggle else MRCNN_TEST_STEM\nMRCNN_OOF_STEM = 'rsna-oof-predictions\/val_v'\nMRCNN_OOF_OUT_STEM = 'val_v' if on_kaggle else MRCNN_OOF_STEM\nMRCNN_TEST_SEP = ''\nMRCNN_OOF_SEP = '_'\nIN_OOF_SUFFIX = ''\nIN_SUFFIX = '.csv'\nOUT_SUFFIX = '.csv'\nCHEX_CLASS_PRED_PATH = '..\/input\/combine-fold-class-predictions-stage-2\/test_probs.csv'  # Logisitc average of Giulia's test class preds\nKERNEL_OUTPUT_PATH = '..\/input\/filter-199-final-with-higher-thresh-stage-2\/filter199.csv'      # \"Pneumonia - Segm. filtered through Class.\" kernel","f7c83d7a":"# For phase 3 only\nN_FOLDS = 5\nOUTPUT_LOC = '.'\n\nOOF_INFILE_STEM = MRCNN_OOF_STEM + '9' + MRCNN_OOF_SEP + 'a1' + MRCNN_OOF_SEP + 'f'\nvers = '8' if on_kaggle else '9'\nTEST_INFILE_STEM = MRCNN_TEST_STEM + vers + MRCNN_TEST_SEP + 'a1' + MRCNN_TEST_SEP + 'f'\nOOF_OUTFILE_NAME = MRCNN_OOF_OUT_STEM + '10' + MRCNN_OOF_SEP + 'a1' + \\\n                   MRCNN_OOF_SEP + 'allfolds_out.csv'\n#TEST_OUTFILE_STEM = MRCNN_TEST_STEM + '10' + MRCNN_TEST_SEP + 'a1' + MRCNN_TEST_SEP + 'f_out'\n# above won't work on kaggle\nTEST_OUTFILE_STEM = MRCNN_OUT_STEM + '10' + MRCNN_TEST_SEP + 'a1' + MRCNN_TEST_SEP + 'f_out'\nOOF_CLASS_PROBS_OUTFILE = 'phase3_oof_out.csv'\nTEST_CLASS_PROBS_OUTFILE_STEM = 'phase3_test_out'\nFULL_TEST_CLASS_PROBS_OUTFILE = 'phase3_test_avg_out.csv'","fd3483e4":"dfs = []\n\nfor a in range(1,3):\n    for f in range(5):\n        vers = '8' if a==2 and f==0 else '1'\n        fn = RESULTS_LOC +'\/'+ MRCNN95_TEST_STEM + vers + MRCNN_TEST_SEP + \\\n             'a' + str(a) + MRCNN_TEST_SEP + 'f' + str(f) + IN_SUFFIX\n        dfs.append( pd.read_csv(fn).set_index('patientId') )\n\nfor i,f in enumerate(dfs):\n    if i:\n        df = df.join(f.rename(columns={'PredictionString':'pred'+str(i)}))\n    else:\n        df = f.rename(columns={'PredictionString':'pred'+str(i)})","90b16a10":"# Implementation of non-max suppression from\n#   https:\/\/github.com\/jrosebr1\/imutils\/blob\/master\/imutils\/object_detection.py\ndef non_max_suppression(boxes, probs=None, overlapThresh=OTHRESH):\n\t# if there are no boxes, return an empty list\n\tif len(boxes) == 0:\n\t\treturn []\n\n\t# if the bounding boxes are integers, convert them to floats -- this\n\t# is important since we'll be doing a bunch of divisions\n\tif boxes.dtype.kind == \"i\":\n\t\tboxes = boxes.astype(\"float\")\n\n\t# initialize the list of picked indexes\n\tpick = []\n\n\t# grab the coordinates of the bounding boxes\n\tx1 = boxes[:, 0]\n\ty1 = boxes[:, 1]\n\tx2 = boxes[:, 2]\n\ty2 = boxes[:, 3]\n\n\t# compute the area of the bounding boxes and grab the indexes to sort\n\t# (in the case that no probabilities are provided, simply sort on the\n\t# bottom-left y-coordinate)\n\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n\tidxs = y2\n\n\t# if probabilities are provided, sort on them instead\n\tif probs is not None:\n\t\tidxs = probs\n\n\t# sort the indexes\n\tidxs = np.argsort(idxs)\n\n\t# keep looping while some indexes still remain in the indexes list\n\twhile len(idxs) > 0:\n\t\t# grab the last index in the indexes list and add the index value\n\t\t# to the list of picked indexes\n\t\tlast = len(idxs) - 1\n\t\ti = idxs[last]\n\t\tpick.append(i)\n\n\t\t# find the largest (x, y) coordinates for the start of the bounding\n\t\t# box and the smallest (x, y) coordinates for the end of the bounding\n\t\t# box\n\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n\n\t\t# compute the width and height of the bounding box\n\t\tw = np.maximum(0, xx2 - xx1 + 1)\n\t\th = np.maximum(0, yy2 - yy1 + 1)\n\n\t\t# compute the ratio of overlap\n\t\toverlap = (w * h) \/ area[idxs[:last]]\n\n\t\t# delete all indexes from the index list that have overlap greater\n\t\t# than the provided overlap threshold\n\t\tidxs = np.delete(idxs, np.concatenate(([last],\n\t\t\tnp.where(overlap > overlapThresh)[0])))\n\n\t# return only the bounding boxes that were picked\n\treturn boxes[pick].astype(\"int\"), list(np.array(probs)[pick])","af74f1d7":"box_dict = {}\nconf_dict = {}\nfor pat,row in df.iterrows():\n    boxes = []\n    confs = []\n    maxconfs = []\n    for pred in row:\n        maxconf = 0.\n        if isinstance(pred, str):\n            s = pred.split(' ')\n            if s[-1]=='':\n                s.pop()  # remove terminating null\n            if s[0]=='':\n                s.pop(0)  # remove initial null\n            if ( len(s)%5 ):\n                print( 'Bad prediction string.')\n            while len(s):\n                conf = float(s.pop(0))\n                x = int(round(float(s.pop(0))))\n                y = int(round(float(s.pop(0))))\n                w = int(round(float(s.pop(0))))\n                h = int(round(float(s.pop(0))))\n                if conf>maxconf:\n                    maxconf = conf\n                if conf>PTHRESH:\n                    boxes.append( [x,y,x+w,y+h] )\n                    confs.append( conf )\n        maxconfs.append(maxconf)\n    avgconf = sum(maxconfs)\/len(maxconfs)\n    if len(boxes) and avgconf>AVPTHRESH:\n        box_dict[pat] = boxes\n        conf_dict[pat] = confs\nlen(box_dict), len(conf_dict)","aee24dbe":"box_dict_nms = {}\nconf_dict_nms = {}\nfor p in box_dict:\n    boxes, confs = non_max_suppression(np.array(box_dict[p]), np.array(conf_dict[p]))\n    box_dict_nms[p] = boxes\n    conf_dict_nms[p] = confs","b06dae4a":"sub_dict = {}\nfor p in df.index:\n    predictionString = ''\n    if p in box_dict_nms:\n        for box, conf in zip(box_dict_nms[p], conf_dict_nms[p]):\n            # retrieve x, y, height and width\n            x, y, x2, y2 = box\n            height = y2 - y\n            width = x2 - x\n            # add to predictionString\n            predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '\n    sub_dict[p] = predictionString\n\n# save submission file\nsub = pd.DataFrame.from_dict(sub_dict,orient='index')\nsub.index.names = ['patientId']\nsub.columns = ['PredictionString']\nphase0_output = sub","54661221":"probs = pd.read_csv(CHEX_CLASS_PRED_PATH)","6cc53813":"df = phase0_output.join(probs.set_index('patientId'))\nout = df.copy()\nout.loc[df.prob<THRESH,'PredictionString'] = np.nan\nout.loc[df.PredictionString=='','PredictionString'] = np.nan\nphase1_output = out.drop(['prob'],axis=1)","4b7c0074":"df1 = pd.read_csv(KERNEL_OUTPUT_PATH).set_index('patientId')\ndf2 = phase1_output\ndf1_cases = df1[~df1.PredictionString.isnull()]\ndf2_cases = df2[~df2.PredictionString.isnull()]\ndf1_pos_ids = df1_cases.index.values\ndf2_pos_ids = df2_cases.index.values","3dae2aef":"df1_only_dict = {}\nfor p in df1_pos_ids:\n    if not p in df2_pos_ids:\n        df1_only_dict[p] = float(df1_cases.loc[p,'PredictionString'].split(' ')[0])","1c78fbd8":"df2_only_dict = {}\nfor p in df2_pos_ids:\n    if not p in df1_pos_ids:\n        df2_only_dict[p] = float(df2_cases.loc[p,'PredictionString'].split(' ')[0])","62c5c2eb":"df_out = df1.copy()\nfor p,r in df1.iterrows():\n    if p in df2_only_dict:\n        if df2_only_dict[p] > MIN_MAX_MRCNN_CONF:\n            df_out.loc[p,'PredictionString'] = df2.loc[p,'PredictionString']\nphase2_output = df_out","1fdcac9c":"phase2_output.head()","85babcb3":"# Read in OOF predictions from MRCNN model\n\ninput_dir = RESULTS_LOC\ninfile_stem = OOF_INFILE_STEM\noof_preds_input = []\nfor ifold in range( N_FOLDS ):\n    fp_in = os.path.join(input_dir, infile_stem + str(ifold) + IN_OOF_SUFFIX)\n    oof_preds_input.append( pd.read_csv(fp_in) )\n    oof_preds_input[-1]['fold'] = ifold\noof_preds = pd.concat(oof_preds_input).set_index('patientId')","7e76faa9":"# Convert to class probabilities by taking maximum conf for each patient\nprobs_dict = {}\nfor p, r in oof_preds.iterrows():\n    probs_dict[p] = MINPROB\noof_positive = oof_preds[~oof_preds.PredictionString.isnull()]\nfor p, r in oof_positive.iterrows():\n    s = r.PredictionString.split(' ')\n    if s[-1]=='':\n        s.pop()  # remove terminating null\n    if s[0]=='':\n        s.pop(0)  # remove initial null\n    if ( len(s)%5 ):\n        print( 'Bad prediction string.')\n    while len(s):\n        conf = float(s.pop(0))\n        x = int(round(float(s.pop(0))))\n        y = int(round(float(s.pop(0))))\n        w = int(round(float(s.pop(0))))\n        h = int(round(float(s.pop(0))))\n        if conf>probs_dict[p]:\n            probs_dict[p] = conf\nprob_df = pd.DataFrame(probs_dict,index=['prob']).transpose()","60356a72":"# Read in actual classes and join with class predictions\ninput_dir = RAW_DATA_LOC\nfp = os.path.join(input_dir, 'stage_2_train_labels.csv')\nact = pd.read_csv(fp).set_index('patientId').rename(columns={'Target':'actual'})[['actual']]\nact = act[~act.index.duplicated()]","7d9f3966":"df = act.join(prob_df,how='right')  # Have to do right join because using stage 1 OOF data\ndf.head()","6a9bab21":"# Fit logistic-on-logits model\nrawprobs = df.prob.values.reshape(-1,1)\nlr = LogisticRegression(C=C1)\nlr.fit(logit(rawprobs),df.actual)\nb1 = lr.coef_[0,0]\nb0 = lr.intercept_[0]\nb0, b1","a51fcbfd":"# Patient IDs for folds\nfolds = []\nfor ifold in range(N_FOLDS):\n    folds.append( oof_preds[oof_preds.fold==ifold].index.values )","47d94f9d":"def run_logistic_by_fold():\n    df = act.join(prob_df,how='right')   # Have to do right join because using stage 1 OOF data\n    logits = df.prob.apply(logit)\n    df['oofprob'] = np.nan\n    b1 = []\n    b0 = []\n    for i in range(len(folds)):\n\n        fs = folds.copy()\n        te = fs.pop(i)  # pop off current validation fold\n        tr = np.concatenate(fs)  # the rest is for training\n\n        # Divide the data\n        Xtr = logits[tr].values.reshape(-1,1)\n        Xte = logits[te].values.reshape(-1,1)\n        ytr = df.actual[tr].copy()\n        yte = df.actual[te].copy()\n\n        # Fit and predict for this fold\n        lr.fit(Xtr, ytr)\n        df.loc[te,'oofprob'] = lr.predict_proba(Xte)[:,1]\n        b1.append(lr.coef_[0,0])\n        b0.append(lr.intercept_[0])\n\n    coefs = pd.DataFrame( {'b0':b0, 'b1':b1}, index=range(len(folds)) )\n    coefs.index.name = 'fold'\n\n    return( df.sort_values('oofprob'), coefs )   ","3afb68d6":"lr = LogisticRegression(C=C2)","a36f993f":"df, coefs = run_logistic_by_fold()","0b10d5f5":"# Transform confidences in OOF data to show realistic probabilities\npat_dict = {}\nfold_dict = {}\nfor pat,row in oof_preds.iterrows():\n    fold = row.fold\n    pred = row.PredictionString\n    boxes = []\n    confs = []\n    if isinstance(pred, str):\n        s = pred.split(' ')\n        if s[-1]=='':\n            s.pop()  # remove terminating null\n        if s[0]=='':\n            s.pop(0)  # remove initial null\n        if ( len(s)%5 ):\n            print( 'Bad prediction string.')\n        b0 = coefs.b0[fold]\n        b1 = coefs.b1[fold]\n        while len(s):\n            conf = float(s.pop(0))\n            x = int(round(float(s.pop(0))))\n            y = int(round(float(s.pop(0))))\n            w = int(round(float(s.pop(0))))\n            h = int(round(float(s.pop(0))))\n            boxes.append( [x,y,w,h] )\n            confs.append( expit( b0+b1*logit(conf) ) )\n    predictionString = ''\n    if len(boxes):\n        for box, conf in zip(boxes, confs):\n            x, y, w, h = box\n            # add to predictionString\n            predictionString += '{:6.4f} '.format(conf)\n            predictionString += str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + ' '\n    pat_dict[pat] = predictionString\n    fold_dict[pat] = fold\nxform_oof_preds = pd.DataFrame(pat_dict, \n                               index=['PredictionString']).transpose()\nxform_oof_preds.index.name = 'patientId'\nxform_oof_preds['fold'] = [fold_dict[x] for x in xform_oof_preds.index.values]\nxform_oof_preds.head()","687d9d75":"output_dir = OUTPUT_LOC\nxform_oof_preds.to_csv(os.path.join(output_dir, OOF_OUTFILE_NAME))","cdef3344":"input_dir = RESULTS_LOC\noutput_dir = OUTPUT_LOC\ninfile_stem = TEST_INFILE_STEM\noutfile_stem = TEST_OUTFILE_STEM","13912165":"for ifold in range(N_FOLDS):\n    \n    fp_in = os.path.join(input_dir, infile_stem + str(ifold) + IN_SUFFIX)\n    fp_out = os.path.join(output_dir, outfile_stem + str(ifold) + OUT_SUFFIX)\n    inpreds = pd.read_csv(fp_in).set_index('patientId')\n    pat_dict = {}\n\n    for pat,row in inpreds.iterrows():\n        pred = row.PredictionString\n        boxes = []\n        confs = []\n        if isinstance(pred, str):\n            s = pred.split(' ')\n            if s[-1]=='':\n                s.pop()  # remove terminating null\n            if s[0]=='':\n                s.pop(0)  # remove initial null\n            if ( len(s)%5 ):\n                print( 'Bad prediction string.')\n            while len(s):\n                conf = float(s.pop(0))\n                x = int(round(float(s.pop(0))))\n                y = int(round(float(s.pop(0))))\n                w = int(round(float(s.pop(0))))\n                h = int(round(float(s.pop(0))))\n                boxes.append( [x,y,w,h] )\n                confs.append( expit( b0+b1*logit(conf) ) )\n        predictionString = ''\n        if len(boxes):\n            for box, conf in zip(boxes, confs):\n                x, y, w, h = box\n                # add to predictionString\n                predictionString += '{:6.4f} '.format(conf)\n                predictionString += str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + ' '\n        pat_dict[pat] = predictionString\n    outpreds = pd.DataFrame(pat_dict, \n                            index=['PredictionString']).transpose()\n    outpreds.index.name = 'patientId'\n    outpreds.to_csv(fp_out)\nfp_out","2bd8e083":"# Generate class probability file for OOF data\noutprobs = prob_df.join(oof_preds[['fold']])\nb0_ = coefs.b0[outprobs.fold].values\nb1_ = coefs.b1[outprobs.fold].values\noutprobs['prob'] =  expit( b0_ + logit(outprobs.prob)*b1_ )\noutprobs.index.name = 'patientId'\noutput_dir = OUTPUT_LOC\noutprobs.to_csv(os.path.join(output_dir, OOF_CLASS_PROBS_OUTFILE))\noutprobs.head()","9074e639":"# Generate class probability files for test data (by training fold)\noutput_dir = OUTPUT_LOC\nbox_outfile_stem = TEST_OUTFILE_STEM\nprobs_outfile_stem = TEST_CLASS_PROBS_OUTFILE_STEM\nminprob_out = expit( b0 + b1*logit(MINPROB))\n\nfor ifold in range(N_FOLDS):\n    \n    fp_in = os.path.join(output_dir, box_outfile_stem + str(ifold) + OUT_SUFFIX)\n    inpreds = pd.read_csv(fp_in).set_index('patientId')\n    fp_out = os.path.join(output_dir, probs_outfile_stem + str(ifold) + OUT_SUFFIX)\n\n    probs_dict = {}\n\n    for p, r in inpreds.iterrows():\n        probs_dict[p] = minprob_out\n    inpreds_positive = inpreds[~inpreds.PredictionString.isnull()]\n    for p, r in inpreds_positive.iterrows():\n        s = r.PredictionString.split(' ')\n        if s[-1]=='':\n            s.pop()  # remove terminating null\n        if s[0]=='':\n            s.pop(0)  # remove initial null\n        if ( len(s)%5 ):\n            print( 'Bad prediction string.')\n        while len(s):\n            conf = float(s.pop(0))\n            s.pop(0)\n            s.pop(0)\n            s.pop(0)\n            s.pop(0)\n            if conf>probs_dict[p]:\n                probs_dict[p] = conf\n    outprob_df = pd.DataFrame(probs_dict,index=['prob']).transpose()\n    outprob_df.index.name = 'patientId'\n    outprob_df.to_csv(fp_out)\n    if not ifold:\n        allprobs_df = outprob_df.rename(columns={'prob':ifold})\n    else:\n        allprobs_df = allprobs_df.join(outprob_df.rename(columns={'prob':ifold}))","bb929e4a":"fp = OOF_CLASS_PROBS_OUTFILE\noof_probs_mrcnn = pd.read_csv(fp).set_index('patientId').rename(columns={'prob':'ph'})","da0b5ca1":"for i in range(N_FOLDS):\n    fp = TEST_CLASS_PROBS_OUTFILE_STEM + str(i) + '.csv'\n    indf = pd.read_csv(fp).set_index('patientId').rename(columns={'prob':'ph'+str(i)})\n    if i:\n        test_prob_df = test_prob_df.join(indf)\n    else:\n        test_prob_df = indf","d7c94546":"test_prob_df.head()","51d4fcb3":"coefs","d056f6ea":"df.tail()","d979206c":"f0 = pd.read_csv(RESULTS_LOC + '\/' + ADEMSE_OOF_STEM + '0.csv').set_index('patientId')\nf1 = pd.read_csv(RESULTS_LOC + '\/' + ADEMSE_OOF_STEM + '1.csv').set_index('patientId')\nf2 = pd.read_csv(RESULTS_LOC + '\/' + ADEMSE_OOF_STEM + '2.csv').set_index('patientId')\nf3 = pd.read_csv(RESULTS_LOC + '\/' + ADEMSE_OOF_STEM + '3.csv').set_index('patientId')\nf4 = pd.read_csv(RESULTS_LOC + '\/' + ADEMSE_OOF_STEM + '4.csv').set_index('patientId')","5d8b7d5c":"den = pd.concat([f0,f1,f2,f3,f4],axis=0)\nprint( den.shape )\nden.head()","1b55d247":"tf0 = pd.read_csv(RESULTS_LOC + '\/' + ADENSE_TEST_STEM + '0.csv').set_index('patientId')\ntf1 = pd.read_csv(RESULTS_LOC + '\/' + ADENSE_TEST_STEM + '1.csv').set_index('patientId')\ntf2 = pd.read_csv(RESULTS_LOC + '\/' + ADENSE_TEST_STEM + '2.csv').set_index('patientId')\ntf3 = pd.read_csv(RESULTS_LOC + '\/' + ADENSE_TEST_STEM + '3.csv').set_index('patientId')\ntf4 = pd.read_csv(RESULTS_LOC + '\/' + ADENSE_TEST_STEM + '4.csv').set_index('patientId')","0f5f8866":"test_den = tf0.rename(columns={'predicted':'pa0'})\ntest_den = test_den.join(tf1.rename(columns={'predicted':'pa1'}))\ntest_den = test_den.join(tf2.rename(columns={'predicted':'pa2'}))\ntest_den = test_den.join(tf3.rename(columns={'predicted':'pa3'}))\ntest_den = test_den.join(tf4.rename(columns={'predicted':'pa4'}))\nprint( test_den.shape )\ntest_den.head()","89111ce4":"# Patient IDs for folds\np0 = f0.index.values\np1 = f1.index.values\np2 = f2.index.values\np3 = f3.index.values\np4 = f4.index.values\npt = test_den.index.values","a8c57565":"c0 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_OOF_STEM + '0.csv').set_index('patientId')\nc1 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_OOF_STEM + '1.csv').set_index('patientId')\nc2 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_OOF_STEM + '2.csv').set_index('patientId')\nc3 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_OOF_STEM + '3.csv').set_index('patientId')\nc4 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_OOF_STEM + '4.csv').set_index('patientId')\nchex = pd.concat([c0,c1,c2,c3,c4],axis=0)\nprint( chex.shape )\nchex.head()","09c86441":"df = den.join(chex[['validPredProba']]).rename(columns={'predicted':'pa','validPredProba':'pg'})\ndf = df.join(oof_probs_mrcnn).drop(['fold'],axis=1)\nprint( df.shape )\ndf.head()","87af1f03":"tc0 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_TEST_FILE0 + '.csv').set_index('patientId')\ntc1 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_TEST_STEM + '1.csv').set_index('patientId')\ntc2 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_TEST_STEM + '2.csv').set_index('patientId')\ntc3 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_TEST_STEM + '3.csv').set_index('patientId')\ntc4 = pd.read_csv(RESULTS_LOC + '\/' + CHEXNET_TEST_STEM + '4.csv').set_index('patientId')\ntc0.head()","a625065e":"INFINITY = 100  # No regularization\nlr = LogisticRegression(C=INFINITY)","5cf2f5bb":"test_chex = tc0.rename(columns={'targetPredProba':'pg0'}).drop(['targetPred'],axis=1)\ntest_chex = test_chex.join(tc1.rename(columns={'targetPredProba':'pg1'}).drop(['targetPred'],axis=1))\ntest_chex = test_chex.join(tc2.rename(columns={'targetPredProba':'pg2'}).drop(['targetPred'],axis=1))\ntest_chex = test_chex.join(tc3.rename(columns={'targetPredProba':'pg3'}).drop(['targetPred'],axis=1))\ntest_chex = test_chex.join(tc4.rename(columns={'targetPredProba':'pg4'}).drop(['targetPred'],axis=1))\nprint( test_chex.shape )\ntest_chex.head()","55520f8c":"all_test_probs = test_prob_df.join(test_den.join(test_chex))\nall_test_probs.head()","fcb6b009":"test_sets = []\ntest_set = ['pa','pg','ph']\nfor i in range(5):\n    this_set = [n + str(i) for n in test_set]\n    test_sets.append(this_set)\ntest_sets","a688518f":"yps = []\nMAXCONF = .996\nXtr = df.drop('actual',axis=1).copy()\nytr = df.actual.copy()\nX_train_adjust = Xtr\nX_train_adjust.loc[Xtr.ph>MAXCONF,'ph'] = MAXCONF\nX_train_logit = X_train_adjust.apply(logit)\nlr.fit(X_train_logit, ytr)\nfor tset in test_sets:\n    Xte = all_test_probs[tset].copy()\n    Xte.columns = test_set\n    X_test_adjust = Xte\n    X_test_adjust.loc[Xte.ph>MAXCONF,'ph'] = MAXCONF\n    X_test_logit = X_test_adjust.apply(logit)\n    yp = lr.predict_proba(X_test_logit)[:,1]\n    yps.append(yp)\nlen(yps), [len(y) for y in yps]","14ca7f21":"p = pd.DataFrame(yps,columns=Xte.index).transpose().apply(logit).mean(axis=1).apply(expit)\nclass_preds = pd.DataFrame(p,columns=['prob'])\nclass_preds.index.name = 'patientId'\nprint(class_preds.shape)\nclass_preds.head()","d7d5dd14":"phase4_test_output = class_preds","bbe7ac6e":"yps = []\nids = []\nMAXCONF = .995\nfolds = [p0,p1,p2,p3,p4]\nfor i in range(len(folds)):\n    fs = folds.copy()\n    te = fs.pop(i)\n    tr = np.concatenate(fs)\n    Xtr = df.loc[tr,:].drop('actual',axis=1).copy()\n    Xte = df.loc[te,:].drop('actual',axis=1).copy()\n    ytr = df.actual[tr].copy()\n    yte = df.actual[te].copy()\n    X_train_adjust = Xtr\n    X_test_adjust = Xte\n    X_train_adjust.loc[Xtr.ph>MAXCONF,'ph'] = MAXCONF\n    X_test_adjust.loc[Xte.ph>MAXCONF,'ph'] = MAXCONF\n    X_train_logit = X_train_adjust.apply(logit)\n    X_test_logit = X_test_adjust.apply(logit)\n    lr.fit(X_train_logit, ytr)\n    yp = lr.predict_proba(X_test_logit)[:,1]\n    yps = yps + list(yp)\n    ids = ids + list(Xte.index.values)","36c7f87d":"oof_class_preds = pd.DataFrame({'prob':yps},index=ids)\noof_class_preds.index.name = 'patientId'\nprint(oof_class_preds.shape)\noof_class_preds.head()","f41740dd":"phase4_oof_output = oof_class_preds","d89b3e1c":"df1 = phase2_output\ndf2 = pd.read_csv(UNET_RESULTS_PATH).rename(columns={\n    'predictionString':'PredictionString'}).set_index('patientId')\n\nclass_preds = phase4_test_output\nclass_probs = class_preds.prob.to_dict()\n\ndf1_cases = df1[~df1.PredictionString.isnull()]\ndf2_cases = df2[~df2.PredictionString.isnull()]\n\ndf1_pos_ids = df1_cases.index.values\ndf2_pos_ids = df2_cases.index.values","74eaf2c4":"df1_only_dict = {}\nfor p in df1_pos_ids:\n    if not p in df2_pos_ids:\n        df1_only_dict[p] = float(df1_cases.loc[p,'PredictionString'].split(' ')[0])\n\ndf2_only_dict = {}\nfor p in df2_pos_ids:\n    if not p in df1_pos_ids:\n        df2_only_dict[p] = float(df2_cases.loc[p,'PredictionString'].split(' ')[0])\n        \ncandidates = pd.DataFrame(pd.Series(df2_only_dict,name='conf')).join(class_preds,how='left')\naccepted = candidates[ (candidates.prob>UNET_MINPROB) & (candidates.conf>UNET_MINCONF)\n                     ].index.values","5807814c":"accepted","e15c5de3":"df_out = df1.copy()\nfor p,r in df1.iterrows():\n    if p in accepted:\n        df_out.loc[p,'PredictionString'] = df2.loc[p,'PredictionString']\nphase5_output = df_out\nphase5_output.head()","c8a65447":"yolo_epochs = [1500, 2000, 3200, 4100, 5300, 6700, 10000, 13700]","5872cd13":"df1 = phase5_output\n\ndfs = []\nfor eps in yolo_epochs:\n    yolo_stem = YOLO_SUB_STEM2 if (eps in MORE_YOLO_EPOCHS) else YOLO_SUB_STEM\n    dfs.append( \n        pd.read_csv(RESULTS_LOC+'\/'+yolo_stem+str(eps)+'.csv').set_index('patientId'))\n\nclass_preds = phase4_test_output\nclass_probs = class_preds.prob.to_dict()\n\ndf1_cases = df1[~df1.PredictionString.isnull()]\ndf1_pos_ids = df1_cases.index.values\nincluded = df1_pos_ids.tolist()\ndf_out = df1.copy()","4f7ec4d5":"while True:\n    for df2 in dfs:\n        df2_cases = df2[~df2.PredictionString.isnull()]\n        df2_pos_ids = df2_cases.index.values\n        df2_only_dict = {}\n        outstring_dict = {}\n        for p in df2_pos_ids:\n            if not p in included:\n                maxconf = 0\n                boxes = []\n                confs = []\n                s = df2.loc[p,'PredictionString'].split(' ')\n                if s[-1]=='':\n                    s.pop()  # remove terminating null\n                if s[0]=='':\n                    s.pop(0)  # remove initial null\n                if ( len(s)%5 ):\n                    print( 'Bad prediction string.')\n                while len(s):\n                    conf = float(s.pop(0))\n                    x = int(round(float(s.pop(0))))\n                    y = int(round(float(s.pop(0))))\n                    w = int(round(float(s.pop(0))))\n                    h = int(round(float(s.pop(0))))\n                    if (conf>YOLO_MINCONF):\n                        boxes.append( [x,y,w,h] )\n                        confs.append( conf )\n                        if conf>maxconf:\n                            maxconf = conf\n                predictionString = ''\n                if len(boxes):\n                    for box, conf in zip(boxes, confs):\n                        x, y, w, h = box\n                        # add to predictionString\n                        predictionString += '{:6.4f} '.format(conf)\n                        predictionString += str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + ' '\n                        df2_only_dict[p] = maxconf*class_probs[p]\n                outstring_dict[p] = predictionString\n        candidates = pd.DataFrame(pd.Series(df2_only_dict,name='prod'))\n        best = candidates.sort_values('prod').tail(1).index.values[0]\n        print(best,candidates.loc[best,'prod'])\n        df_out.loc[best,'PredictionString'] = outstring_dict[best]\n        included.append( best )\n    minprob = class_preds.loc[included[-8:],:].prob.min()\n    if minprob<MINMIN:\n        break","71b1998a":"class_preds.loc[included[-32:],:]   # This was 16 in stage 1. Changed to 32 for curiosity.","951a0f7f":"df_out.to_csv('phase6_output.csv')","70d135bf":"df_out.head()","1ba07678":"### Phase 3<br>Convert MRCNN confidence to fitted class proability","f1efacdc":"## Phases of post-processing for RSNA predictions","ea261cab":"### Phase 4<br>Stack class probability estimates","a7095cea":"### Phase 2<br>Add high-confidnence results from phase1 to results form Kaggle kernel","44d8bf9d":"### Phase 1<br>Apply classification probability threshold to non-max suppression output","601d0040":"### Phase 0:<br> Apply non-max suppression to fold predictions for 2 different 5-fold assignments","28cb4d83":"### Phase 6<br>Add high-confidnece yolo results to results from phase 5","3ee8c3dc":"### Phase 5<br>Add high-confidence Resnet-uunet results to results from phase 2"}}