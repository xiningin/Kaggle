{"cell_type":{"ae995c15":"code","a668431c":"code","e4f11508":"code","069bc48b":"code","840951a0":"code","aae1b619":"code","b92df2f0":"code","0b77b23e":"code","a686860c":"markdown","aba15163":"markdown","a7e05a70":"markdown","6689ef87":"markdown"},"source":{"ae995c15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a668431c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [20,8]\nimport seaborn as sns","e4f11508":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\ndf = pd.read_csv('..\/input\/ccdata\/CC GENERAL.csv')\n##\ndf.drop(['CUST_ID'], axis=1, inplace=True)\ndf.dropna(subset=['CREDIT_LIMIT'], inplace=True)\ndf['MINIMUM_PAYMENTS'].fillna(df['MINIMUM_PAYMENTS'].median(), inplace=True)\n##\ncols=df.columns\nfor col in cols:\n    df[col] = np.log(1 + df[col])\n    \n##\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=0.95)\nX_red = pca.fit_transform(df)\n\nn_clusters=10\nkmeans_models = [KMeans(n_clusters=k, random_state=23).fit(X_red) for k in range (2, n_clusters)] #https:\/\/stackoverflow.com\/questions\/51382250\/valueerror-number-of-labels-is-1-valid-values-are-2-to-n-samples-1-inclusiv\n# print(silhouette_score(X_red, kmeans_models[0].labels_))\nsilhoutte_scores = [silhouette_score(X_red, model.labels_) for model in kmeans_models]\ninnertia = [model.inertia_ for model in kmeans_models]\ndata={'n_clusters':range(2,n_clusters),'innertia':innertia,'silhoutte_scores':silhoutte_scores}\nk_df=pd.DataFrame(data)\ndisplay(k_df)\n##\nplt.figure(figsize=(20,8))\nplt.title('Elbow method',fontsize=24)\nplt.xlabel('Number of Clusters',fontsize=24)\nplt.ylabel('WCSS(inertia)',fontsize=24)\nplt.plot(range(2, n_clusters), innertia,'-gD', label='line with marker')\nplt.show()\n\nfrom sklearn.metrics import silhouette_score\n\nsilhoutte_scores = [silhouette_score(X_red, model.labels_) for model in kmeans_models[1:5]]\nplt.figure(figsize=(20,8))\nplt.plot(range(2,6), silhoutte_scores, '-rD')\nplt.xticks([2, 3, 4,5,6,7])\nplt.title('Silhoutte scores vs Number of clusters',fontsize=24)\nplt.xlabel('Number of clusters',fontsize=24)\nplt.ylabel('Silhoutte score',fontsize=24)\nplt.show()","069bc48b":"#Inverse transforming the log transformation that we did earlier to visualize the results on original scale.\nfor col in cols:\n    df[col] = np.exp(df[col])\n##\n\ndef kmean_fn(n_clusters=6):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=23)\n    kmeans.fit(X_red)\n    return kmeans.labels_\n\ndf['cluster_id 2'] = kmean_fn(n_clusters=2)\ndf['cluster_id 3'] = kmean_fn(n_clusters=3)\ndf.sample(5)\n\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(20,8))\nax1.set_xlabel('PURCHASES_FREQUENCY',fontsize=24)\nax1.set_ylabel('PURCHASES_INSTALLMENTS_FREQUENCY',fontsize=24)\nsns.scatterplot(data=df, x='PURCHASES_FREQUENCY', y='PURCHASES_INSTALLMENTS_FREQUENCY',s=45, hue='cluster_id 2',palette=\"Set1\",ax=ax1)\nax2.set_xlabel('PURCHASES_FREQUENCY',fontsize=24)\nax2.set_ylabel('PURCHASES_INSTALLMENTS_FREQUENCY',fontsize=24)\nsns.scatterplot(data=df, x='PURCHASES_FREQUENCY', y='PURCHASES_INSTALLMENTS_FREQUENCY',s=45,hue='cluster_id 3',palette=\"Set1\",ax=ax2)","840951a0":"X = pd.read_csv('..\/input\/ccdata\/CC GENERAL.csv')\nX.drop(['CUST_ID'], axis=1, inplace=True)\nX.dropna(subset=['CREDIT_LIMIT'], inplace=True)\nX['MINIMUM_PAYMENTS'].fillna(X['MINIMUM_PAYMENTS'].median(), inplace=True)\n##\nkmean= KMeans(n_clusters=6)\nkmean.fit(X)\nlabels=kmean.labels_\nclusters=pd.concat([X, pd.DataFrame({'cluster':labels})], axis=1)\nclusters.dropna(subset=['cluster'], inplace=True)\n# display(clusters.sample(5))\n\n##\nsample_cluster=clusters[['PURCHASES_FREQUENCY','PURCHASES_INSTALLMENTS_FREQUENCY']]\nfor c in sample_cluster:\n    grid= sns.FacetGrid(clusters, col='cluster')\n    grid.map(plt.hist, c)\n\n# Using PCA to transform data to 2 dimensions for visualization\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import PCA\nprint('\\nBefore: ',X.shape)\ncos_dist = 1 - cosine_similarity(X)\npca = PCA(n_components=2)\nX_PCA=pca.fit_transform(cos_dist)\nprint('\\nAfter: ',X_PCA.shape)","aae1b619":"pc1, pc2 = X_PCA[:, 0], X_PCA[:, 1]\n\ncolors = {0: 'red',1: 'blue',2: 'green', 3: 'yellow', 4: 'orange',  5:'purple'}\n\nnames = {0: 'who make all type of purchases', 1: 'more people with due payments', 2: 'who purchases mostly in installments', 3: 'who take more cash in advance', \n         4: 'who make expensive purchases',5:'who don\\'t spend much money'}\n  \ndf = pd.DataFrame({'pc1': pc1, 'pc2':pc2, 'label':labels}) \ngroups = df.groupby('label')\nprint(type(groups))\ndisplay(groups.apply(lambda x1: x1)) #https:\/\/stackoverflow.com\/questions\/46236925\/slicing-a-datagramegroupby-object\n\nfig, ax = plt.subplots(figsize=(20, 13))\nfor name, group in groups:\n    ax.plot(group.pc1, group.pc2, marker='o', linestyle='', ms=5,color=colors[name],label=names[name], mec='none')\n    ax.set_aspect('auto')\n    ax.tick_params(axis='x',which='both',bottom='off',top='off',labelbottom='off')\n    ax.tick_params(axis= 'y',which='both',left='off',top='off',labelleft='off')\n    \nax.legend()\nax.set_title(\"Customers Segmentation based on their Credit Card usage bhaviour.\")\nplt.show()","b92df2f0":"raw_df = pd.read_csv('..\/input\/ccdata\/CC GENERAL.csv')\nraw_df = raw_df.drop('CUST_ID', axis = 1) \nraw_df.fillna(method ='ffill', inplace = True) \ndisplay(raw_df.sample(2))\n\n# Standardize data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler() \nscaled_df = scaler.fit_transform(raw_df) \n  \n# Normalizing the Data \nfrom sklearn.preprocessing import normalize\nnormalized_df = normalize(scaled_df) \n  \n# Converting the numpy array into a pandas DataFrame \nnormalized_df = pd.DataFrame(normalized_df) \n  \n# Reducing the dimensions of the data \npca = PCA(n_components = 2) \nX_principal = pca.fit_transform(normalized_df) \nX_principal = pd.DataFrame(X_principal)\nX_principal.columns = ['PC1', 'PC2'] \ndisplay(X_principal.sample(2))\n\nsse = {}\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X_principal)\n    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center\nplt.figure(figsize=(14,6))\nplt.plot(list(sse.keys()), list(sse.values()),'--bo', label='line with marker')\nplt.title('Elbow method',fontsize=24)\nplt.xlabel(\"Number of cluster\",fontsize=24)\nplt.ylabel(\"Sum of distances of samples\",fontsize=24)\nplt.show()\n\nsilhouette_scores = [] \n\nfor n_cluster in range(2, 8):\n    silhouette_scores.append( silhouette_score(X_principal, KMeans(n_clusters = n_cluster).fit_predict(X_principal)))\n\n# kmeans_models = [KMeans(n_clusters=k, random_state=23).fit(X_red) for k in range (2, n_clusters)]\n# silhoutte_scores = [silhouette_score(X_red, model.labels_) for model in kmeans_models[1:5]]    \n\n# Plotting a bar graph to compare the results \n# k = [2, 3, 4, 5, 6,7] \nplt.figure(figsize=(14,6))\nplt.bar(range(2, 8), silhouette_scores)\nplt.xlabel('Number of clusters', fontsize = 20) \nplt.ylabel('Silhouette Score', fontsize = 20) \nplt.show() ","0b77b23e":"# Visualizing the clustering \nplt.scatter(X_principal['PC1'], X_principal['PC2'],  \n           c = KMeans(n_clusters = 3).fit_predict(X_principal), cmap =plt.cm.winter) \nplt.show() ","a686860c":"# Approach 3","aba15163":"# reference\n\nhttps:\/\/www.kaggle.com\/ankits29\/credit-card-customer-clustering-with-explanation\n\nhttps:\/\/seaborn.pydata.org\/tutorial\/color_palettes.html\n\nhttps:\/\/www.kaggle.com\/sabanasimbutt\/clustering-visualization-of-clusters-using-pca\n","a7e05a70":"# Approach 1","6689ef87":"# Approach 2"}}