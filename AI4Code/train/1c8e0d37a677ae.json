{"cell_type":{"1f819ec3":"code","f512e12f":"code","6e192b15":"code","8a5f7968":"code","8acca1da":"code","6e01c5b8":"code","1cebed6a":"code","50deaa26":"code","0b970f56":"code","78296fb6":"code","6b711bd3":"code","ceea6d32":"code","6740d78e":"code","ba3bf79c":"code","0d5cbfbd":"code","e71fab2c":"code","27596c2e":"code","b925d7eb":"code","f5655a1c":"code","9c70da4d":"code","a2ad3e0d":"code","87016359":"code","d542fc5b":"code","81493e44":"code","e9d59240":"code","9bb1ee53":"code","368b1622":"code","eb21d5a8":"code","1ee36cf7":"code","50f56910":"markdown","7ad302dc":"markdown","a7e46ef7":"markdown","6e8ca122":"markdown","ce356b2e":"markdown","f25897ff":"markdown","1e1d68a6":"markdown","00c62f06":"markdown","3affbcb8":"markdown","1e7c3daa":"markdown","327e2630":"markdown","28ec25ab":"markdown","06e58fa6":"markdown","31c2cee5":"markdown","feca55a3":"markdown","7f8f38cf":"markdown"},"source":{"1f819ec3":"import warnings\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport seaborn as sns","f512e12f":"# Install AutoGluon\n!pip install -U pip setuptools wheel\n!pip uninstall typing -y\n!pip install -U mxnet\n!pip install -U --pre autogluon.tabular[all]\n!pip install -U pyarrow\n!pip install -U pandas==1.1.*\n!pip install -U scikit-optimize\n!pip install -U catboost\n!pip install -U lightgbm","6e192b15":"PATH_TO_DATA = Path('..\/input\/flight-delays-fall-2018\/')\ndf_train = pd.read_csv(PATH_TO_DATA \/ 'flight_delays_train.csv.zip')\ndf_test = pd.read_csv(PATH_TO_DATA \/ 'flight_delays_test.csv.zip')","8a5f7968":"df_train.head()","8acca1da":"import autogluon.core as ag\nfrom autogluon.tabular import TabularPrediction as task","6e01c5b8":"metric = 'roc_auc'\ndep_var = 'dep_delayed_15min'","1cebed6a":"# The models below are not strong, so to keep training overhead low, let's remove them\n# Also, KNN uses lots of disk space, which might make it unusable for Kaggle kernel setting.\nexcluded_model_types = ['KNN', 'RF', 'XT', 'NN']\n\n\npredictor = task.fit(\n    train_data=df_train, label=dep_var, eval_metric=metric,\n    excluded_model_types=excluded_model_types,\n    verbosity=3,\n)\n\npredictor.leaderboard(silent=True)","50deaa26":"predictor.leaderboard(silent=True)","0b970f56":"df_train['flight'] = df_train['Origin'] + '-->' + df_train['Dest']\ndf_test['flight'] = df_test['Origin'] + '-->' + df_test['Dest']","78296fb6":"small_ones ={'AS': 'small',\n             'YV': 'small',\n             'B6': 'small',\n             'HP': 'small',\n             'F9': 'small',\n             'DH': 'small',\n             'HA': 'small',\n             'TZ': 'small',\n             'AQ': 'small'} \n\ndf_train['UniqueCarrier'] = df_train['UniqueCarrier'].replace(small_ones)\ndf_test['UniqueCarrier'] = df_test['UniqueCarrier'].replace(small_ones)","6b711bd3":"predictor = task.fit(\n    train_data=df_train, label=dep_var, eval_metric=metric,\n    excluded_model_types=excluded_model_types,\n    verbosity=3,\n)\n\npredictor.leaderboard(silent=True)","ceea6d32":"train = pd.read_csv(\"..\/input\/flight-delays-fall-2018\/flight_delays_train.csv.zip\", compression='zip')\ntest = pd.read_csv(\"..\/input\/flight-delays-fall-2018\/flight_delays_test.csv.zip\", compression='zip')\nall_data = pd.concat([train, test], ignore_index=True)","6740d78e":"all_data['Route'] = all_data['Origin'] + all_data['Dest']\nall_data['UniqueCarrier_Origin'] = all_data['UniqueCarrier'] + \"_\" + all_data['Origin']\nall_data['UniqueCarrier_Dest'] = all_data['UniqueCarrier'] + \"_\" + all_data['Dest']\nall_data['is_weekend'] = (all_data['DayOfWeek'] == 6) | (all_data['DayOfWeek'] == 7)\n\n# Hour and minute\nall_data['hour'] = all_data['DepTime'] \/\/ 100\nall_data.loc[all_data['hour'] == 24, 'hour'] = 0\nall_data.loc[all_data['hour'] == 25, 'hour'] = 1\nall_data['minute'] = all_data['DepTime'] % 100\n\n# give more importance to hour variable\nall_data['hour_sq'] = all_data['hour'] ** 2\nall_data['hour_sq2'] = all_data['hour'] ** 4\n\n# Binning\nall_data['summer'] = (all_data['Month'].isin([6, 7, 8]))\nall_data['autumn'] = (all_data['Month'].isin([9, 10, 11]))\nall_data['winter'] = (all_data['Month'].isin([12, 1, 2]))\nall_data['spring'] = (all_data['Month'].isin([3, 4, 5]))\n\nall_data['DayTime'] = 0\nall_data.loc[all_data.DepTime <= 600 , 'DepTime_bin'] = 'Night'\nall_data.loc[(all_data.DepTime > 600) & (all_data.DepTime <= 1200), 'DepTime_bin'] = 'Morning'\nall_data.loc[(all_data.DepTime > 1200) & (all_data.DepTime <= 1800), 'DepTime_bin'] = 'Afternoon'\nall_data.loc[(all_data.DepTime > 1800) & (all_data.DepTime <= 2600), 'DepTime_bin'] = 'Evening'\n\nall_data['DepTime_bin'] = 0\nall_data.loc[all_data.DepTime <= 600 , 'DepTime_bin'] = 'vem'\nall_data.loc[(all_data.DepTime > 600) & (all_data.DepTime <= 900), 'DepTime_bin'] = 'm'\nall_data.loc[(all_data.DepTime > 900) & (all_data.DepTime <= 1200), 'DepTime_bin'] = 'mm'\nall_data.loc[(all_data.DepTime > 1200) & (all_data.DepTime <= 1500), 'DepTime_bin'] = 'maf'\nall_data.loc[(all_data.DepTime > 1500) & (all_data.DepTime <= 1800), 'DepTime_bin'] = 'af'\nall_data.loc[(all_data.DepTime > 1800) & (all_data.DepTime <= 2100), 'DepTime_bin'] = 'n'\nall_data.loc[(all_data.DepTime > 2100) & (all_data.DepTime <= 2400), 'DepTime_bin'] = 'nn'\nall_data.loc[all_data.DepTime > 2400, 'DepTime_bin'] = 'lm'\nall_data = all_data.drop(['DepTime'], axis=1)\n\nall_data['Dist_bin'] = 0\nall_data.loc[all_data.Distance <= 500 , 'Dist_bin'] = 'vshort'\nall_data.loc[(all_data.Distance > 500) & (all_data.Distance <= 1000), 'Dist_bin'] = 'short'\nall_data.loc[(all_data.Distance > 1000) & (all_data.Distance <= 1500), 'Dist_bin'] = 'mid'\nall_data.loc[(all_data.Distance > 1500) & (all_data.Distance <= 2000), 'Dist_bin'] = 'midlong'\nall_data.loc[(all_data.Distance > 2000) & (all_data.Distance <= 2500), 'Dist_bin'] = 'long'\nall_data.loc[all_data.Distance > 2500, 'Dist_bin'] = 'vlong'\nall_data = all_data.drop(['Distance'], axis=1)","ba3bf79c":"df_train = all_data.iloc[:len(train)].reset_index(drop=True)\ndf_test = all_data.iloc[len(train):].drop(columns=dep_var).reset_index(drop=True)","0d5cbfbd":"all_data.head()","e71fab2c":"predictor = task.fit(\n    train_data=df_train, label=dep_var, eval_metric=metric,\n    excluded_model_types=excluded_model_types,\n)","27596c2e":"predictor.leaderboard(silent=True)","b925d7eb":"importance_scores = predictor.feature_importance(df_train)\nprint(importance_scores)","f5655a1c":"drop = ['is_weekend', 'summer', 'autumn', 'winter', 'spring', 'DayTime', 'hour', 'hour_sq2']\ndf_train = df_train.drop(columns=drop).copy()\ndf_test = df_test.drop(columns=drop).copy()","9c70da4d":"predictor = task.fit(\n    train_data=df_train, label=dep_var, eval_metric=metric,\n    excluded_model_types=excluded_model_types,\n)\npredictor.leaderboard(silent=True)","a2ad3e0d":"preds = predictor.predict_proba(df_test)\nsubmission = pd.read_csv(PATH_TO_DATA \/ 'sample_submission.csv.zip', index_col='id')\nsubmission[dep_var] = preds\nsubmission.to_csv('submission-quick-feature-engineering.csv')","87016359":"excluded_model_types = ['KNN', 'RF', 'XT', 'NN']\npredictor = task.fit(\n    train_data=df_train, label=dep_var, eval_metric=metric,\n    presets='best_quality',\n    excluded_model_types=excluded_model_types,\n)","d542fc5b":"predictor.leaderboard(silent=True)","81493e44":"preds = predictor.predict_proba(df_test)","e9d59240":"submission = pd.read_csv(PATH_TO_DATA \/ 'sample_submission.csv.zip', index_col='id')\nsubmission[dep_var] = preds\nsubmission.to_csv('submission-full-ensemble.csv')","9bb1ee53":"predictor.refit_full();","368b1622":"predictor.leaderboard(silent=True)","eb21d5a8":"preds_refit_full = predictor.predict_proba(df_test, model='WeightedEnsemble_FULL_L2')","1ee36cf7":"submission = pd.read_csv(PATH_TO_DATA \/ 'sample_submission.csv.zip', index_col='id')\nsubmission[dep_var] = preds_refit_full\nsubmission.to_csv('submission-refit-ensemble.csv')","50f56910":"As we can see the ensembled results are much better compared to individual models:","7ad302dc":"# Read the data","a7e46ef7":"We are going to exclude some models from this fast baseline beacuse they take extra time to train and it's not needed for experimentation. All supported model types are available [here](https:\/\/github.com\/awslabs\/autogluon\/blob\/master\/tabular\/src\/autogluon\/tabular\/task\/tabular_prediction\/tabular_prediction.py#L241-L257).\n\nAlternatively, you can pick specific models by passing [hyperparameters](https:\/\/github.com\/awslabs\/autogluon\/blob\/master\/tabular\/src\/autogluon\/tabular\/task\/tabular_prediction\/tabular_prediction.py#L185-L212) (defaults are documented [here](https:\/\/github.com\/awslabs\/autogluon\/blob\/master\/tabular\/src\/autogluon\/tabular\/task\/tabular_prediction\/tabular_prediction.py#L215-L238)) instead of `excluded_model_types`.\n\nThe code below will fit the following ensemble:\n![image.png](attachment:image.png)","6e8ca122":"# Dropping useless and noisy features","ce356b2e":"# Feature importance\n\nTo better understand our trained predictor, we can estimate the overall importance of each feature:","f25897ff":"For predictions AutoGluon will automatically pick the best models:","1e1d68a6":"# Fit baseline Model\n\nNow let's use AutoGluon to train multiple models. Normally at this stage you would have to encode labels, handle missing values and categorical variables. All this going to be automatically handled by the framework.\n\nHere we discuss what happened during fit().\n\nSince there are only two possible values of the class variable, this was a binary classification problem. AutoGluon automatically infers this as well as the type of each feature (i.e., which columns contain continuous numbers vs. discrete categories). AutogGluon can also automatically handle common issues like missing data and rescaling feature values.\n\nWe did not specify separate validation data and so AutoGluon automatically choses a random training\/validation split of the data. The data used for validation is seperated from the training data and is used to determine the models and hyperparameter-values that produce the best results. Rather than just a single model, AutoGluon trains multiple models and ensembles them together to ensure superior predictive performance.\n\nBy default, AutoGluon tries to fit various types of models including neural networks and tree ensembles. Each type of model has various hyperparameters, which traditionally, the user would have to specify. AutoGluon automates this process.\n\nTo control runtimes, you can specify various arguments in fit() as demonstrated in [In-Depth tutorial](https:\/\/auto.gluon.ai\/stable\/tutorials\/tabular_prediction\/tabular-indepth.html).","00c62f06":"# Feature Engineering\n\nLet's add some features from this notebook: [Flight delay](https:\/\/www.kaggle.com\/mobelahcen\/flight-delay)","3affbcb8":"# Collapsing bagged ensembles via refit_full\n\nFor an ensemble predictor trained with bagging (as done above), recall there ~10 bagged copies of each individual model trained on different train\/validation folds. We can collapse this bag of ~10 models into a single model that\u2019s fit to the full dataset, which can greatly reduce its memory\/latency requirements (but may also reduce accuracy). Below we refit such a model for each original model but you can alternatively do this for just a particular model by specifying the model argument of `refit_full()`.","1e7c3daa":"As you can see the new `_FULL` models are added to ensemble:","327e2630":"This concludes the tutorial. To explore more, please visit [Tutorial section](https:\/\/auto.gluon.ai\/stable\/tutorials\/index.html) of AutoGluon. Contribututions are welcomed too: [github](https:\/\/github.com\/awslabs\/autogluon).","28ec25ab":"To predict get predictions from refitted networks we can pass `model` parameter to specify the model to use. The prediction will be much faster because the smaller subset of the features is going to be used. This is helpful if faster inference is required:","06e58fa6":"![image.png](attachment:image.png)\n\nIn this tutorial we introduce AutoGluon-Tabular, an open-source AutoML framework that requires only a single line of Python to train highly accurate machine learning models on an unprocessed tabular dataset such as a CSV file. Unlike existing AutoML frameworks that primarily  focus on model\/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers. Experiments reveal that our multi-layer combination of many models offers better use of allocated training time than seeking out the best.","31c2cee5":"# Refit To Full Ensemble\n\nNow let's refit the whole model with full stacked ensemble:\n![image.png](attachment:image.png)\nEnsembles that combine predictions from multiple modelshave long been known to outperform individual models,often drastically reducing the variance of the final predic-tions (Dietterich, 2000). All of the best-performing AutoMLframeworks today rely on some form of model ensemblingsuch as bagging (Breiman, 1996), boosting (Freund et al.,1996), stacking (Ting & Witten, 1997), or weighted combi-nations. In particular, various AutoML frameworks utilizeshallow stack ensembling. Here a collection of individual\u201cbase\u201d models are individually trained in the usual fashion.Subsequently, a \u201cstacker\u201d model is trained using the aggre-gated predictions of the base models as its features.  Thestacker model can improve upon shortcomings of the in-dividual base predictions and exploit interactions betweenbase models that offer enhanced predictive power (Van derLaan et al., 2007).\n\nBecause this code trains much more models, it will take significantly better, but it should produce better results than the previous approach.","feca55a3":"# Adding some features\nFeature engineering is taken from [mlcourse.ai. Fall 2019. Catboost starter](https:\/\/www.kaggle.com\/nogayev\/mlcourse-ai-fall-2019-catboost-starter) kernel.","7f8f38cf":"Computed via [permutation-shuffling](https:\/\/explained.ai\/rf-importance\/), these feature importance scores quantify the drop in predictive performance (of the already trained predictor) when one column\u2019s values are randomly shuffled across rows. The top features in this list contribute most to AutoGluon\u2019s metric. Features with non-positive importance score hardly contribute to the predictor\u2019s accuracy, or may even be actively harmful to include in the data (consider removing these features from your data and calling fit again). These scores facilitate interpretability of the predictor\u2019s global behavior (which features it relies on for all predictions) rather than [local explanations](https:\/\/christophm.github.io\/interpretable-ml-book\/taxonomy-of-interpretability-methods.html) that only rationalize one particular prediction."}}