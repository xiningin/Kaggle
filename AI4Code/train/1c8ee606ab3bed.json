{"cell_type":{"4b102002":"code","f69918f9":"code","8dc1ede4":"code","ee5aa168":"code","fa559d11":"code","fedadabe":"code","e8d5611f":"code","3cb0192b":"code","3de54db0":"code","c17fe8f3":"code","a8f4412f":"code","1b99ce94":"code","6cb3dbac":"code","66735237":"markdown","be44a4f4":"markdown","52b81c94":"markdown","271a9c88":"markdown","9ea2b315":"markdown","89fa3ad0":"markdown","c438913c":"markdown","0583e25d":"markdown","656a66d0":"markdown","0ad6331a":"markdown","47760cb2":"markdown","c738fd2a":"markdown","3d91de16":"markdown","d5d92517":"markdown","ee4db8d2":"markdown","98f79d1e":"markdown","a1f40b50":"markdown","a7ba5382":"markdown"},"source":{"4b102002":"#Import library\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n#Set dataframe view options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 1000)\n\n#Data cleansing function\ndef arrange_onehot_var_df(multi_choise_df, onehot_var_list):\n    for var in onehot_var_list:\n        qestion_no = var[:3]\n        rename_df = pd.DataFrame(multi_choise_df[var].value_counts()).reset_index()['index']            \n        rename_col = rename_df.values[0]\n        multi_choise_df = multi_choise_df.rename(columns={var : qestion_no + rename_col})\n        multi_choise_df[qestion_no + rename_col] = multi_choise_df[qestion_no + rename_col].fillna(0)\n        multi_choise_df[qestion_no + rename_col] = multi_choise_df[qestion_no + rename_col].apply(lambda x: 0 if x == 0 else 1)\n    return multi_choise_df\n\ndef question_no_sum(multi_choise_df, quetion_no_list):\n    for question_no in quetion_no_list:\n        extract_list = [item for item in multi_choise.columns if item.find(question_no) != -1]\n        i = 0\n        for var in extract_list:\n            if i == 0:\n                multi_choise_df[question_no + '_sum'] = multi_choise_df[var]\n            else:\n                multi_choise_df[question_no + '_sum'] = multi_choise_df[question_no + '_sum'] + multi_choise_df[var]\n            i = i + 1\n    return multi_choise_df\n\n#Make dataframe\nmulti_choise = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')[1:]\n\n#Drop useless variable\ndrop_col = [item for item in multi_choise.columns if item.find('_TEXT') != -1]\nmulti_choise.drop(drop_col, axis=1, inplace=True)\n\n#Data cleansing\nonehot_var_list = [item for item in multi_choise.columns if item.find('Part') != -1]\nmulti_choise = arrange_onehot_var_df(multi_choise_df=multi_choise, onehot_var_list=onehot_var_list)\n\nquetion_no_list = ['Q9','Q12','Q13','Q16','Q17','Q18','Q20','Q21','Q24','Q25',\n                   'Q26','Q27','Q28','Q29','Q30','Q31','Q32','Q33','Q34']\nmulti_choise = question_no_sum(multi_choise_df=multi_choise, quetion_no_list=quetion_no_list)\n\ndef Q10_cond(x):\n    if  x == '$0-999':\n        return '01. $0-999'\n    elif x == '1,000-1,999':\n        return '02. $1,000-1,999'\n    elif x == '2,000-2,999':\n        return '03. $2,000-2,999'\n    elif x == '3,000-3,999':\n        return '04. $3,000-3,999'\n    elif x == '4,000-4,999':\n        return '05. $4,000-4,999'\n    elif x == '5,000-7,499':\n        return '06. $5,000-7,499'\n    elif x == '7,500-9,999':\n        return '07. $7,500-9,999'\n    elif x == '10,000-14,999':\n        return '08. $10,000-14,999'\n    elif x == '15,000-19,999':\n        return '09. $15,000-19,999'\n    elif x == '20,000-24,999':\n        return '10. $20,000-24,999'\n    elif x == '25,000-29,999':\n        return '11. $25,000-29,999'\n    elif x == '30,000-39,999':\n        return '12. $30,000-39,999'\n    elif x == '40,000-49,999':\n        return '13. $40,000-49,999'\n    elif x == '50,000-59,999':\n        return '14. $50,000-59,999'\n    elif x == '60,000-69,999':\n        return '15. $60,000-69,999'\n    elif x == '70,000-79,999':\n        return '16. $70,000-79,999'\n    elif x == '80,000-89,999':\n        return '17. $80,000-89,999'\n    elif x == '90,000-99,999':\n        return '18. $90,000-99,999'\n    elif x == '100,000-124,999':\n        return '19. $100,000-124,999'\n    elif x == '125,000-149,999':\n        return '20. $125,000-149,999'\n    elif x == '150,000-199,999':\n        return '21. $150,000-199,999'\n    elif x == '200,000-249,999':\n        return '22. $200,000-249,999'\n    elif x == '250,000-299,999':\n        return '23. $250,000-299,999'\n    elif x == '300,000-500,000':\n        return '24. $300,000-500,000'\n    elif x == '> $500,000':\n        return '25. $500,000 and over'\n\nmulti_choise['Q10'] = multi_choise['Q10'].apply(Q10_cond)\n\ndef Q10_earn_cond(x):\n    if x == '01. $0-999':\n        return 'Not earn'\n    elif x == '02. $1,000-1,999':\n        return 'Not earn'\n    elif x == '03. $2,000-2,999':\n        return 'Not earn'\n    elif x == '04. $3,000-3,999':\n        return 'Not earn'\n    elif x == '05. $4,000-4,999':\n        return 'Not earn'\n    elif x == '06. $5,000-7,499':\n        return 'Not earn'\n    elif x == '07. $7,500-9,999':\n        return 'Not earn'\n    elif x == '08. $10,000-14,999':\n        return 'Not earn'\n    elif x == '09. $15,000-19,999':\n        return 'Not earn'\n    elif x == '10. $20,000-24,999':\n        return 'Not earn'\n    elif x == '11. $25,000-29,999':\n        return 'Not earn'\n    elif x == '12. $30,000-39,999':\n        return 'Not earn'\n    elif x == '13. $40,000-49,999':\n        return 'Not earn'\n    elif x == '14. $50,000-59,999':\n        return 'Earn'\n    elif x == '15. $60,000-69,999':\n        return 'Earn'\n    elif x == '16. $70,000-79,999':\n        return 'Earn'\n    elif x == '17. $80,000-89,999':\n        return 'Earn'\n    elif x == '18. $90,000-99,999':\n        return 'Earn'\n    elif x == '19. $100,000-124,999':\n        return 'Earn'\n    elif x == '20. $125,000-149,999':\n        return 'Earn'\n    elif x == '21. $150,000-199,999':\n        return 'Earn'\n    elif x == '22. $200,000-249,999':\n        return 'Earn'\n    elif x == '23. $250,000-299,999':\n        return 'Earn'\n    elif x == '24. $300,000-500,000':\n        return 'Earn'\n    elif x == '25. $500,000 and over':\n        return 'Earn'\n\nmulti_choise['Q10_earn_flg'] = multi_choise['Q10'].apply(Q10_earn_cond)\n\n#Fill Nan\nmulti_choise = multi_choise.fillna('No Answer')\n\n#Extract Earn or not\nmulti_choise = multi_choise[multi_choise['Q10_earn_flg'] != 'No Answer']","f69918f9":"#Calc Earn Rate in occupations\ndef calc_earn_rate(df, occupation_list):\n    i = 0\n    for occupation in occupation_list:\n        gb_df = df[(df['Q5'] == occupation)]\n        gb_df = pd.DataFrame(gb_df.groupby('Q10_earn_flg').count()['Q5']).reset_index()\n        rate = round(gb_df['Q5'][0] \/ gb_df['Q5'].sum() * 100, 1)\n        if i == 0:\n            rate_df = pd.DataFrame([[rate]], columns=['rate'])\n            rate_df['Earn'] = gb_df['Q5'][0]\n            rate_df['Not Earn'] = gb_df['Q5'][1]\n            rate_df['sum'] = gb_df['Q5'].sum()\n            rate_df['occupation'] = occupation\n            i = i + 1\n        else:\n            tmp_rate_df = pd.DataFrame([[rate]], columns=['rate'])\n            tmp_rate_df['Earn'] = gb_df['Q5'][0]\n            tmp_rate_df['Not Earn'] = gb_df['Q5'][1]\n            tmp_rate_df['sum'] = gb_df['Q5'].sum()\n            tmp_rate_df['occupation'] = occupation\n            rate_df = rate_df.append(tmp_rate_df)\n    return rate_df\n\noccupation_list = ['Data Scientist', 'Software Engineer', 'Data Analyst', 'Research Scientist', 'Business Analyst', \n                   'Product\/Project Manager', 'Data Engineer', 'Statistician', 'DBA\/Database Engineer']\n\noccupation_rate_df = calc_earn_rate(df=multi_choise, occupation_list=occupation_list)\n\n#Add occupation All\nrate = round(occupation_rate_df['Earn'].sum() \/ occupation_rate_df['sum'].sum() * 100, 1)\ntmp_rate_df = pd.DataFrame([[rate]], columns=['rate'])\ntmp_rate_df['Earn'] = occupation_rate_df['Earn'].sum()\ntmp_rate_df['Not Earn'] = occupation_rate_df['Not Earn'].sum()\ntmp_rate_df['sum'] = occupation_rate_df['sum'].sum()\ntmp_rate_df['occupation'] = 'ALL'\noccupation_rate_df = occupation_rate_df.append(tmp_rate_df)\n\n#Sort\noccupation_rate_df = occupation_rate_df.sort_values('rate')\n\n#Make graph\ncolors=['blue',] * 10\ncolors[8]='crimson'\n\nx=occupation_rate_df['rate'].values\ny=occupation_rate_df['occupation'].values\n\nfig = go.Figure(data=[go.Bar(x=x,y=y,text=x,textposition='auto',orientation='h',marker_color=colors)])\nfig.update_layout(title='\"Earn\" rate by occupation')\nfig.show()","8dc1ede4":"#Make graph function\ndef make_onehot_var_graph(df, var, drop_list, title, height):\n    qvar_list = [item for item in df.columns if item.find(var) != -1]\n    qvar_list.append('Q10_earn_flg')\n\n    gb_df = ds[qvar_list]\n    gb_df = gb_df.groupby('Q10_earn_flg').sum()\n\n    df_col = []\n    for i in range(len(qvar_list)-1):\n        tmp_df_col = qvar_list[i][3:]\n        df_col.append(tmp_df_col)\n\n    gb_df.columns = df_col\n    gb_df.drop(drop_list, axis=1, inplace=True)\n    gb_df = gb_df.T.reset_index()\n    gb_df['Earn_rate'] = round(gb_df['Earn'] \/ earn * 100, 1)\n    gb_df['Not earn_rate'] = round(gb_df['Not earn'] \/ notearn * 100, 1)\n\n    if var == 'Q9':\n        def Q9_cond(x):\n            if  x == 'Do research that advances the state of the art of machine learning':\n                return 'Research that advances the cutting-edge ML'\n            elif x == 'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data':\n                return 'Build the data infrastructure'\n            elif x == 'None of these activities are an important part of my role at work':\n                return 'I do not play an important role in data science'\n            elif x == 'Build prototypes to explore applying machine learning to new area':\n                return 'Build prototypes to explore applying ML to new area'\n            elif x == 'Analyze and understand data to influence product or business decisions':\n                return 'Analyze data to influence business decisions'\n            elif x == 'Build and\/or run a machine learning service that operationally improves my product or workflows':\n                return 'Build ML service that operationally improves our products'\n            elif x == 'Other':\n                return 'Other'\n\n        gb_df['index'] = gb_df['index'].apply(Q9_cond)\n\n    if var == 'Q12':\n        def Q12_cond(x):\n            if  x == 'None':\n                return 'None'\n            elif x == 'Other':\n                return 'Other'\n            elif x == 'Twitter (data science influencers)':\n                return 'Twitter'\n            elif x == 'Hacker News (https:\/\/news.ycombinator.com\/)':\n                return 'Hacker News'\n            elif x == 'Reddit (r\/machinelearning, r\/datascience, etc)':\n                return 'Reddit'\n            elif x == 'Kaggle (forums, blog, social media, etc)':\n                return 'Kaggle'\n            elif x == 'Course Forums (forums.fast.ai, etc)':\n                return 'Course Forums'\n            elif x == 'YouTube (Cloud AI Adventures, Siraj Raval, etc)':\n                return 'YouTube'\n            elif x == 'Podcasts (Chai Time Data Science, Linear Digressions, etc)':\n                return 'Podcasts'\n            elif x == 'Blogs (Towards Data Science, Medium, Analytics Vidhya, KDnuggets etc)':\n                return 'Blogs'\n            elif x == 'Journal Publications (traditional publications, preprint journals, etc)':\n                return 'Journal Publications'\n            elif x == 'Slack Communities (ods.ai, kagglenoobs, etc)':\n                return 'Slack Communities'\n        \n        gb_df['index'] = gb_df['index'].apply(Q12_cond)\n\n    if var == 'Q26':\n        def Q26_cond(x):\n            if  x == 'None':\n                return 'None'\n            elif x == 'Object detection methods (YOLOv3, RetinaNet, etc)':\n                return 'Object detection methods (YOLOv3, RetinaNet, etc)'\n            elif x == 'Other':\n                return 'Other'\n            elif x == 'General purpose image\/video tools (PIL, cv2, skimage, etc)':\n                return 'General purpose image\/video tools (PIL, cv2, etc)'\n            elif x == 'Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)':\n                return 'Image classification and other general purpose networks (VGG, ResNet, etc)'\n            elif x == 'Build and\/or run a machine learning service that operationally improves my product or workflows':\n                return 'Build ML service that operationally improves our products'\n            elif x == 'Image segmentation methods (U-Net, Mask R-CNN, etc)':\n                return 'Image segmentation methods (U-Net, Mask R-CNN, etc)'\n\n        gb_df['index'] = gb_df['index'].apply(Q26_cond)\n    \n    gb_df['dif_Earn_Notearn'] = gb_df['Earn_rate'] - gb_df['Not earn_rate']\n    gb_df = gb_df.sort_values('dif_Earn_Notearn', ascending=False)\n\n    X=list(gb_df['index'].values)\n    Y1=gb_df['Earn_rate'].values\n    Y2=gb_df['Not earn_rate'].values\n\n    fig = go.Figure(data=[\n        go.Bar(name='Earn', x=X, y=Y1, text=Y1, textposition='auto'),\n        go.Bar(name='Not Earn', x=X, y=Y2, text=Y2, textposition='auto')\n    ])\n\n    fig.update_layout(title=title, barmode='group', height=height, font_size=10, xaxis_tickangle=45)\n    fig.show()\n\ndef make_onehot_var_sum_avg_graph(df, var, avg_var, title):\n    qvar_list = [item for item in df.columns if item.find(var) != -1]\n    qvar_list.append('Q10_earn_flg')\n\n    gb_df = ds[qvar_list]\n    \n    x = gb_df['Q10_earn_flg'].values\n    y = gb_df[var+avg_var].values\n\n    earn_df = gb_df[gb_df['Q10_earn_flg'] == 'Earn']\n    nearn_df = gb_df[gb_df['Q10_earn_flg'] == 'Not earn']\n    \n    p_eran = earn_df[var+avg_var].values\n    p_nearn = nearn_df[var+avg_var].values\n    p_earn_nearn = stats.ttest_ind(p_eran, p_nearn, equal_var=False)\n    pvalue = round(p_earn_nearn[1],3)\n    name = title+'(p-value='+str(pvalue)+')'\n\n    earn_mean = round(earn_df[var+avg_var].mean(),2)\n    nearn_mean = round(nearn_df[var+avg_var].mean(),2)\n    \n    fig = go.Figure(data=[\n        go.Bar(name='Earn', x=[\"Earn or Not earn\"], y=[earn_mean], text=earn_mean, textposition='auto'),\n        go.Bar(name='Not earn', x=[\"Earn or Not earn\"], y=[nearn_mean], text=nearn_mean, textposition='auto')\n    ])\n    fig.update_layout(title=name, font_size=10, height=300, barmode='group')\n    fig.show()\n\n#Make Data Scientist data frame\nds = multi_choise[multi_choise['Q5'] == 'Data Scientist']\nnotearn = ds['Q10_earn_flg'].value_counts()[0]\nearn = ds['Q10_earn_flg'].value_counts()[1]","ee5aa168":"make_onehot_var_graph(df=ds, var='Q9', drop_list='sum', title='Response rate', height=450)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q9', avg_var='_sum', title='Number of checks for questioning options')","fa559d11":"make_onehot_var_graph(df=ds, var='Q12', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q12', avg_var='_sum', title='Number of checks for questioning options')","fedadabe":"make_onehot_var_graph(df=ds, var='Q16', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q16', avg_var='_sum', title='Number of checks for questioning options')","e8d5611f":"make_onehot_var_graph(df=ds, var='Q18', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q18', avg_var='_sum', title='Number of checks for questioning options')","3cb0192b":"make_onehot_var_graph(df=ds, var='Q20', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q20', avg_var='_sum', title='Number of checks for questioning options')","3de54db0":"make_onehot_var_graph(df=ds, var='Q24', drop_list='_sum', title='Response rate', height=450)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q24', avg_var='_sum', title='Number of checks for questioning options')","c17fe8f3":"make_onehot_var_graph(df=ds, var='Q28', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q28', avg_var='_sum', title='Number of checks for questioning options')","a8f4412f":"make_onehot_var_graph(df=ds, var='Q29', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q29', avg_var='_sum', title='Number of checks for questioning options')","1b99ce94":"make_onehot_var_graph(df=ds, var='Q31', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q31', avg_var='_sum', title='Number of checks for questioning options')","6cb3dbac":"make_onehot_var_graph(df=ds, var='Q34', drop_list='_sum', title='Response rate', height=300)\nmake_onehot_var_sum_avg_graph(df=ds, var='Q34', avg_var='_sum', title='Number of checks for questioning options')","66735237":"### ML algorithms<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb79.3% of \"Earn\" use Linear or Logistic Regression.<br>\n&emsp;It is 10.7% better than compared to \"Not earn\".<br>\n\u30fb62.8% of \"Earn\" use GBM.<br>\n&emsp;It is 9.7% better than compared to \"Not earn\".<br>\n\u30fb75.2% of \"Earn\" use Decision Trees or Random Forests.<br>\n&emsp;It is 9.4% better than compared to \"Not earn\".<br>\n\u30fb32.8% of \"Earn\" use Bayesian.<br>\n&emsp;It is 7.9% better than compared to \"Not earn\".<br>\n\u30fb26.9% of \"Earn\" use RNN.<br>\n&emsp;It is 1.5% worse than compared to \"Not earn\".<br>\n\u30fb37.1% of \"Earn\" use CNN.<br>\n&emsp;It is 2.8% worse than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbYou should be able to use classical ML algorithms(Linear or Logistic Regression, GBM, Decision Trees or Random Forests, Bayesian).<br>\n\u30fbWhile, deep learning methods is used by \"Not earn\" compared to \"Earn\".<br>\n\u30fbThe person who can use many ML algorithms can earn.<br>","be44a4f4":"### Programming languages<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb61.3% of \"Earn\" use SQL.<br>\n&emsp;It is 15.0% better than compared to \"Not earn\".<br>\n\u30fb23.8% of \"Earn\" use Bash.<br>\n&emsp;It is 10.5% better than compared to \"Not earn\".<br>\n\u30fb43.3% of \"Earn\" use R.<br>\n&emsp;It is 9.9% better than compared to \"Not earn\".<br>\n\u30fb\"Earn\" and \"Not earn\" almost use Python.<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbYou should be able to use Python and SQL. It would be even better if you can use Bash and R.<br>\n\u30fbThe person who can use many programming languages can earn.<br>","52b81c94":"# \u2460 Is a Data Scientist a profitable occupation ?","271a9c88":"### Cloud computing platforms<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb39.0% of \"Earn\" use AWS.<br>\n&emsp;It is 13.6% better than compared to \"Not earn\".<br>\n\u30fb16.7% of \"Earn\" use Microsoft Azure.<br>\n&emsp;It is 5.1% better than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbYou should be able to use AWS.<br>\n\u30fbThe person who can use many cloud computing platforms can earn.<br>","9ea2b315":"### IDE or text editor<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb39.7% of \"Earn\" use Rstudio.<br>\n&emsp;It is 8.7% better than compared to \"Not earn\".<br>\n\u30fb17.3% of \"Earn\" use Vim or Emacs.<br>\n&emsp;It is 8.0% better than compared to \"Not earn\".<br>\n\u30fb16.2% of \"Earn\" use Spyder.<br>\n&emsp;It is 5.6% worse than compared to \"Not earn\".<br>\n\u30fb\"Earn\" and \"Not earn\" almost use Jupyter.<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbThere are no programming language with a difference of more than 10% between \"Earn\" and \"Not earn\".<br>\n\u30fbYou should be able to use Jupyter. It would be even better if you can use Rstudio and Vim or Emacs.<br>\n\u30fbThe person who can use many IDE or text editor can earn.<br>","89fa3ad0":"**Fact**<br>\n\u30fbData Scientists of \"Earn\" rate is 44.0%.<br>\n\u30fbIt was second after the Product\/Project Manager and 7.3% better than compared to ALL occupations.<br>\n\n**Conclusion**<br>\n\u30fbData Scientist is a profitable occupation.<br>","c438913c":"Firstly, I comfirmed whether Data Scientist is profitable occupation or not.<br>","0583e25d":"### ML frameworks<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb50.0% of \"Earn\" use Xgboost.<br>\n&emsp;It is 8.2% better than compared to \"Not earn\".<br>\n\u30fb\"Earn\" and \"Not earn\" almost use Scikit-learn.<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbYou should be able to use Scikit-learn. It would be even better if you can use Xgboost.<br>\n\u30fbThe person who can use many ML frameworks can earn.<br>","656a66d0":"### Summary<br>\n\n\u2460 Is a Data Scientist a profitable occupation ?\n\n> Data Scientist is a profitable occupation.\n\n\u2461 What do earning Data Scientists have skills ?\n\n**Play an important part of your role at work in ML**<br>\n> Analyze data to influence business decisions.(Must)<br>\n> Build ML service that operationally improves our products.(Desirable)<br>\n> Build the data infrastructure.(Desirable)<br>\n> The person who can play an important part of your role at ML work in various situations can earn.<br>\n\n**Favorite media sources that report on data science topics**<br>\n> Blogs(Must)<br>\n> Kaggle(Desirable)<br>\n> Journal Publications(Desirable)<br>\n> It doesn't matter how many sources you are reading.<br>\n\n**IDE or text editor**<br>\n> Jupyter(Must)<br>\n> Rstudio(Desirable)<br>\n> Vim or Emacs(Desirable)<br>\n> The person who can use many IDE or text editor can earn.<br>\n\n**Programming languages**<br>\n> Python(Must)<br>\n> SQL(Must)<br>\n> Bash(Desirable)<br>\n> R(Desirable)<br>\n> The person who can use many programming languages can earn.<br>\n\n**Data visualization libraries or tools**<br>\n> Seaborn(Desirable)<br>\n> Matplotlib(Desirable)<br>\n> ggplot or ggplot2(Desirable)<br>\n> The person who can use many data visualization libraries or tools can earn.<br>\n\n**ML algorithms**<br>\n> Linear or Logistic Regression(Must)<br>\n> GBM(Must)<br>\n> Decision Trees or Random Forests(Must)<br>\n> Bayesian(Desirable)<br>\n> While, deep learning methods is used by \"Not earn\" compared to \"Earn\".<br>\n> The person who can use many ML algorithms can earn.<br>\n\n**ML frameworks**<br>\n> Scikit-learn(Must)<br>\n> Xgboost(Desirable)<br>\n> The person who can use many ML frameworks can earn.<br>\n\n**Cloud computing platforms**<br>\n> AWS(Desirable)<br>\n> The person who can use many cloud computing platforms can earn.<br>\n\n**Big data analytics products**<br>\n> AWS Redshift(Desirable)<br>\n> The person who can use many big data analytics products can earn.<br>\n\n**RDB products**<br>\n> PostgresSQL(Desirable)<br>\n> Microsoft SQL server(Desirable)<br>\n> The person who can use many RDB products can earn.<br>","0ad6331a":"### Play an important part of your role at work in ML<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb77.5% of \"Earn\" work \u300cAnalyze data to influence business decisions\u300d.<br>\n&emsp;It is 15.1% better than compared to \"Not earn\".<br>\n\u30fb51.4% of \"Earn\" work \u300cBuild ML service that operationally improves our products\u300d.<br>\n&emsp;It is 10.0% better than compared to \"Not earn\".<br>\n\u30fb43.8% of \"Earn\" work \u300cBuild the data infrastructure\u300d.<br>\n&emsp;It is 10.9% better than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbYou should be able to analyze data to influence business decisions.<br>\n\u30fbIt would be even better if you can build ML service that operationally improves our products and the data infrastructure.<br>\n\u30fbThe person who can play an important part of your role at ML work in various situations can earn.<br>","47760cb2":"### Big data analytics products<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb10.0% of \"Earn\" use AWS Redshift.<br>\n&emsp;It is 5.2% better than compared to \"Not earn\".<br>\n\u30fbBig data analytics products are rarely used \"Earn\" and \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbIf I must say, You should be able to use AWS Redshift.<br>\n\u30fbThe person who can use many big data analytics products can earn.<br>","c738fd2a":"# How to earn as a Data Scientist","3d91de16":"### RDB products<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb29.3% of \"Earn\" use PostgresSQL.<br>\n&emsp;It is 10.3% better than compared to \"Not earn\".<br>\n\u30fb21.9% of \"Earn\" use Microsoft SQL server.<br>\n&emsp;It is 7.1% better than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbYou should be able to use PostgresSQL and Microsoft SQL server.<br>\n\u30fbThe person who can use many RDB products can earn.<br>","d5d92517":"Next, I comfirmed the difference between Data Scientists who can earn and can't.<br>\nHowever, the difference of attribute information(age, gender, country and so on) is not excluded.\nBecause it can't be changed.","ee4db8d2":"### Data visualization libraries or tools<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fb38.9% of \"Earn\" use ggplot or ggplot2.<br>\n&emsp;It is 8.6% better than compared to \"Not earn\".<br>\n\u30fb18.5% of \"Earn\" use shiny.<br>\n&emsp;It is 7.5% better than compared to \"Not earn\".<br>\n\u30fbSeaborn and Matplotlib are often used by \"Earn\" and \"Not earn\".<br>\n&emsp;\"Earn\" are a little worse than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is significant difference between \"Earn\" and \"Not earn\".<br>\n\n**Conclusion**<br>\n\u30fbThere are no programming language with a difference of more than 10% between \"Earn\" and \"Not earn\".<br>\n\u30fbIf I must say, you should be able to use ggplot or ggplot2.<br>\n\u30fbYou should be able to use other than Seaborn and Matplotlib.<br>\n\u30fbThe person who can use many data visualization libraries or tools can earn.<br>","98f79d1e":"### Favorite media sources that report on data science topics<br>\n\n**Fact**<br>\n<u>Response rate<\/u><br>\n\u30fbBlogs are read 75.5% of \"Earn\".<br>\n&emsp;It is 10.1% better than compared to \"Not earn\".<br>\n\u30fbJournal Publications are read 36.9% of \"Earn\".<br>\n&emsp;It is 9.2% better than compared to \"Not earn\".<br>\n\u30fbKaggle are read 55.8% of \"Earn\".<br>\n&emsp;It is 13.9% worse than compared to \"Not earn\".<br>\n\u30fbYoutube are read 29.8% of \"Earn\".<br>\n&emsp;It is 14.7% worse than compared to \"Not earn\".<br>\n<u>Number of checks for questioning options<\/u><br>\n\u30fbThere is no significant difference between \"Earn\" and \"Not earn\".\n\n**Conclusion**<br>\n\u30fbBlogs and Journal Publications may be for expert and Kaggle and Youtube may be for beginners.<br>\n\u30fbIt doesn't matter how many sources you are reading.","a1f40b50":"### Introduction<br>\n\nThese days, Data Scientist is a popular job around the world.<br>\nTherefore, I investigated the occupation of Data Scientist from the following two perspectives.<br>\n\u2460 Is a Data Scientist a profitable occupation ?<br>\n\u2461 What do earning Data Scientists have skills ?<br>\n\nAnd, I defined Data Scientists who can earn and can't.<br>\n\u30fbData Scientists who can earn : 50,000 dollars and over<br>\n\u30fbData Scientists who can't earn : 50,000 dollars fewer than<br>\nIn this analysis, Data Scientists who can earn is called \"Earn\" and Data Scientists who can't earn is called \"Not earn\".","a7ba5382":"# \u2461 What do earning Data Scientists have skills ?"}}