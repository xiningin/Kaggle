{"cell_type":{"8b82592b":"code","586a42f0":"code","87c7c87b":"code","090b8d9f":"code","da5f06ea":"code","97701551":"code","15931fff":"code","02245cc4":"code","2c0b2b14":"code","3f8342fc":"code","db31cf54":"code","88f8f73e":"code","750060f6":"code","13854aad":"code","464be244":"code","3e3bb174":"markdown","fc0ff6a6":"markdown","37ec2df9":"markdown","8d84de8f":"markdown","4ba90a59":"markdown","478a06f7":"markdown","1ce0c9ac":"markdown","bf36b123":"markdown","37ee25cc":"markdown","1783b938":"markdown","87587dc6":"markdown","a446d729":"markdown","50eea1ca":"markdown","4d17ed1f":"markdown","87994590":"markdown","782ad5b7":"markdown","3ec496db":"markdown","7657cfcd":"markdown","b83747a2":"markdown","6f1fded2":"markdown","30fbe9bd":"markdown","4cea7ae4":"markdown","27279e04":"markdown","98046034":"markdown"},"source":{"8b82592b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","586a42f0":"# Import general libraries\nimport numpy as np\nimport pandas as pd\n\n# Import plotting libraries\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport seaborn as sns\n\n# Preprocessing tools\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\n\n# ML libraries\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import confusion_matrix\n","87c7c87b":"# Plotting setup\nplt.rcParams['figure.dpi'] = 150\nsns.set(rc={\"axes.facecolor\":\"#FFF9ED\",\"figure.facecolor\":\"#FFF9ED\"})\npallet = [\"#682F2F\", \"#9E726F\", \"#D6B2B1\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"]\n# cmap = colors.ListedColormap([\"#682F2F\", \"#9E726F\", \"#D6B2B1\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"])\ncmap = colors.ListedColormap([\"#F3AB60\", \"#9F8A78\", \"#B9C0C9\", \"#9E726F\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"])\n","090b8d9f":"#Loading the dataset\ndf = pd.read_csv(\"..\/input\/league-of-legends-worlds-2021-playin-group-stats\/League of Legends 2021 World Championship Play-In Groups Statistics - Raw Data.csv\")\nprint(\"Number of datapoints:\", len(df))\ndf.head()","da5f06ea":"df.info()","97701551":"df['kill2death'] = df['Kills'] \/ (df['Deaths'] + 1)\ndf['Wards Ratio'] = df['Wards Destroyed'] \/ (df['Ward Interactions'] +1)\ndf['Game Points'] = 3*df['Kills'] + 1*df['Assists'] - 2*df['Deaths']\ndf['Dragon Points'] = df['Dragons For'] - df['Dragons Against']\ndf['Barons Points'] = df['Barons For'] - df['Barons Against']","15931fff":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnum_df = df.select_dtypes(include=numerics)\nnum_df['Result'] = df['Result']\nsns.pairplot(num_df, hue='Result', palette=([\"#682F2F\",\"#F3AB60\"]))","02245cc4":"w_corr = num_df[num_df['Result']==\"W\"].corr()\nplt.figure(figsize=(20,20)) \nplt.title(\"Winner correlation matrix\")\nsns.heatmap(w_corr, annot=True, cmap=cmap, center=0)\nplt.show()\n\nl_corr = num_df[num_df['Result']==\"L\"].corr()\nplt.figure(figsize=(20,20))  \nplt.title(\"Loser correlation matrix\")\nsns.heatmap(l_corr, annot=True, cmap=cmap, center=0)\nplt.show()","2c0b2b14":"def label_encoding(dummy_list):\n    dic = {}\n    for i, v in enumerate(dummy_list):\n        dic[v] = i\n    return dic\n\nobj_df = df.select_dtypes(include='object')\nobj_df['Result'] = [1 if r == 'W' else 0 for r in obj_df['Result']]\n\nposition_dic = label_encoding(obj_df['Position'].unique())\nteam_dic = label_encoding(obj_df['Team'].unique())\n\nobj_df['Position'] = obj_df['Position'].apply(lambda x: position_dic[x])\nobj_df['Team'] = obj_df['Team'].apply(lambda x: team_dic[x])\nobj_df['Opponent'] = obj_df['Opponent'].apply(lambda x: team_dic[x])\n\nobj_df.head()","3f8342fc":"scaler = MinMaxScaler()\nscaled_df = scaler.fit_transform(num_df[num_df.columns[:-1]])","db31cf54":"pca = PCA(n_components=0.95)\npca.fit(scaled_df)\nPCA_ds = pd.DataFrame(pca.transform(scaled_df))\nPCA_ds.columns = ['pca_{}'.format(i) for i in range(PCA_ds.shape[1])]\nPCA_ds.head()","88f8f73e":"wx = PCA_ds[\"pca_0\"][obj_df['Result']==1]\nwy = PCA_ds[\"pca_1\"][obj_df['Result']==1]\nwz = PCA_ds[\"pca_2\"][obj_df['Result']==1]\n\nlx = PCA_ds[\"pca_0\"][obj_df['Result']==0]\nly = PCA_ds[\"pca_1\"][obj_df['Result']==0]\nlz = PCA_ds[\"pca_2\"][obj_df['Result']==0]\n\nfig = plt.figure(figsize=(10,8))\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(wx,wy,wz, c='r', marker=\"o\" )\nax.scatter(lx,ly,lz, c='b', marker=\"o\" )\nax.set_title(\"A 3D Projection Of Data In The Reduced Dimension\")\nplt.show()","750060f6":"new_df = obj_df.merge(PCA_ds, left_index=True, right_index=True)\nnew_df = new_df.drop(columns=['Player','Champion'])\nnew_df.head()","13854aad":"X = new_df[['Team', 'Opponent', 'Position', 'pca_0', 'pca_1', 'pca_2',\n       'pca_3', 'pca_4', 'pca_5', 'pca_6', 'pca_7']]\ny = new_df['Result']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=123) ","464be244":"xgbc = XGBClassifier(n_estimators=100, max_depth=5, use_label_encoder=False)\n\nxgbc.fit(X_train, y_train)\n\n# - cross validataion\nscores = cross_val_score(xgbc, X_train, y_train, cv=3)\nprint(\"Mean cross-validation score: %.2f\" % scores.mean())\n\nkfold = KFold(n_splits=10, shuffle=True)\nkf_cv_scores = cross_val_score(xgbc, X_train, y_train, cv=kfold )\nprint(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n\ny_pred = xgbc.predict(X_test)\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)","3e3bb174":"## Introduction to the dataset\n\nThis dataset provides the historical competition records of the **League of Legends** (LOL). I attempt to use this dataset to study the **correlations between different attributes**. The dataset contains **220 samples** with **20 attributes**. The attributes include\n1. **Team** - team code\n2. **Player** - player name\n3. **Opponent** - opposing team code\n4. **Position** - player position in game\n5. **Champion** - hero used\n6. **Kills** - number of kills\n7. **Deaths** - number of deaths\n8. **Assists** - number of assists\n9. **Creep Score** - number of NPC killed\n10. **Gold Earned** - number of gold earned\n11. **Champion Damage Share** - percentage of total damage done by team to other champions done by player\n12. **Kill Participation** - percentage of team kills that player was part of\n13. **Wards Placed** - number of wards placed by player in match\n14. **Wards Destroyed** - number of wards killed by player in match\n15. **Ward Interactions** - sum of wards placed and wards killed by player in match\n16. **Dragons For** - number of dragons team killed in match\n17. **Dragon Against** - number of dragons opposing team killed in match\n18. **Barons For** - number of Barons killed in match\n19. **Barons Against** - number of Barons opposing team killed in match\n20. **Result** - Win or Lose \n","fc0ff6a6":"### MinMax scaling","37ec2df9":"### Visualization of principal components (PC)\n\nWe make a **3D plot** for the **first 3 PCs** to see if they can separate the **Result** well.","8d84de8f":"### Pair plot","4ba90a59":"#### Conclusion\n\nThere is **no missing value** in the dataset. We do not have to clean the dataset. There are **14 numerical** attributes and **6 object-type** attributes.","478a06f7":"#### Conclusion\n\nAs seen in the pair plot, any cell with color of **brown** or **orange**, the pair of attributes shows a **significant correlation**.","1ce0c9ac":"Now, we have both label encoded **categorical dataframe** and **PCA dataframe**, we can meger them together. Since the **player name** and the **champion** columns might not be related, I decide to drop them out.","bf36b123":"## Feature engineering\n\nBelow shows some features I am going to add into the table:\n* **Kill-to-Death ratio**: kills per life\n* **Wards Destroyed-to-Interactions ratio:** players might attempt to destroy but fail\n* **Points**: 3pts\/kill, 1pt\/assist, -2pt\/death\n* **Dragons net gain**: dragons for - dragons against\n* **Barons net gain**: barons for - barons against","37ee25cc":"Acknowledge:\n    \nhttps:\/\/www.kaggle.com\/karnikakapoor\/customer-segmentation-clustering","1783b938":"## XGBoost Classification\n\nIn the final part of the notebook, I simply build a model to try to make prediction on the **Result** based on the given data. As we can see from the **join plot** and the **3D PC cluster plot**, I expect that a simple model can easily give a high accuracy prediction.","87587dc6":"#### Conclusion\n\nAs you see that those useful categorical attributes are label encoded.","a446d729":"## Data preprocessing\nThere several things we have to do before further analysis:\n* **Label encoding** for the categorical attributes\n* **Scaling** for numerical attributes","50eea1ca":"#### Conclusion\n\nAs we can see that all numeric attributes are within [0,1]. It is suitable for performing PCA.","4d17ed1f":"## Data cleaning\n\nWe are going to check and see if there are any **missing values** in the data set.","87994590":"## Exploratory Data Analysis (EDA)\n\nTo study the correlations between different attributes, we use `seaborn` to generate `pairplot` to achieve the goal qualitatively or calculate the correlation matrix quantitatively.","782ad5b7":"## Dimensionality reduction\nAs we can see that many attributes are correlated with each other, it is better for us to perform dimensionality reduction with principal component analysis (PCA).","3ec496db":"**Conclusion**\n\nThe model shows **high validation accuracy** of **>95%**. The **accuracy on the test set** also reach **~94.9%**. ","7657cfcd":"#### Conclusion\n\nThere are so many thing we can tell from this plot. Below shows some of them:\n* Winners usually kill more, assist more and die less (obviously!)\n* Winners usually earn more gold (can get more good weapons)\n* Winners dominates both dragons and barons (level-up faster and earn more gold)\n\nWe can also see that many attitutes are correlated with each other. To estimate the correlation quatitatively, we should generate correlation matrix, which is shown below.","b83747a2":"### Train-test split","6f1fded2":"### Model training and evaluation","30fbe9bd":"### Correlation Matrix","4cea7ae4":"### Label Encoding","27279e04":"#### Conclusion\n\nWe see that the **first 3 PCs** can clearly **separate winners and losers**.","98046034":"### Principal Component Analysis"}}