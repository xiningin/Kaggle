{"cell_type":{"861e5f84":"code","77b5935f":"code","2a266e1f":"code","e5d6a813":"code","f5829639":"code","cd624926":"code","44989a33":"code","01137d17":"code","3de513e8":"code","4b2a775e":"code","7b8f2692":"code","e83f2032":"code","09a8196f":"code","ee2d7c34":"code","b8c6ce06":"code","94120886":"code","875e8f96":"code","51d65536":"code","8a7e4e20":"code","c70f283d":"code","6d18ff9f":"code","36b568bc":"code","15ad48a9":"code","d528bb4d":"code","8358b5a6":"code","a5aa2605":"code","9a90830e":"code","84903336":"code","5afae82b":"code","ee0860bf":"code","7ad1bd35":"code","f98d0987":"code","837ef66a":"code","af4b36b1":"code","765a3dfb":"code","e4af109b":"code","c6fb0151":"code","8465ee0a":"code","09fb12ed":"code","cf771cae":"code","bbe28dad":"code","92229554":"code","143d9101":"code","716ab472":"code","42734df7":"markdown","7956d5bb":"markdown","db1d3e60":"markdown","be11ee12":"markdown","487bf4ee":"markdown","967deb36":"markdown","68770489":"markdown","bd0a2fab":"markdown","e704e157":"markdown","e4abcb46":"markdown","a7374338":"markdown","8acbf2ba":"markdown","4f6bf1db":"markdown","e9203d67":"markdown","156bf245":"markdown","4ece0edd":"markdown","cdb4671b":"markdown","c640ac80":"markdown","6cfa0a0b":"markdown","da688685":"markdown","a8d8578f":"markdown","74047861":"markdown","8b454cab":"markdown","7f8d2eb0":"markdown","d9f9ff90":"markdown","a5eda410":"markdown","0bb7826e":"markdown","3f8b107f":"markdown","d43c1c97":"markdown","efa49992":"markdown","cc089aba":"markdown","b9891af6":"markdown","281d777e":"markdown","f3780e0c":"markdown","d19031e9":"markdown","6257ee11":"markdown","f84f11e5":"markdown"},"source":{"861e5f84":"import pandas as pd\nhyd_rest=pd.read_csv('..\/input\/zomato-restaurants-hyderabad\/Restaurant names and Metadata.csv')\nhyd_rev=pd.read_csv('..\/input\/zomato-restaurants-hyderabad\/Restaurant reviews.csv')","77b5935f":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer \nfrom nltk.stem import PorterStemmer, LancasterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom textblob import TextBlob\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.display import Image\n%matplotlib inline","2a266e1f":"hyd_rev['Rating'].value_counts(normalize=True)","e5d6a813":"hyd_rev['Review']=hyd_rev['Review'].astype(str)\nhyd_rev['Review_length'] = hyd_rev['Review'].apply(len)","f5829639":"import plotly.express as px\nfig = px.scatter(hyd_rev, x=hyd_rev['Rating'], y=hyd_rev['Review_length'])\nfig.update_layout(title_text=\"Rating vs Review Length\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.show()","cd624926":"hyd_rev['Polarity'] = hyd_rev['Review'].apply(lambda x: TextBlob(x).sentiment.polarity)","44989a33":"hyd_rev['Polarity'].plot(kind='hist', bins=100)","01137d17":"stop_words = stopwords.words('english')\nprint(stop_words)\nrest_word=['order','restaurant','taste','ordered','good','food','table','place','one','also']\nrest_word","3de513e8":"import re\nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: re.sub('[,\\.!?]','', x))\nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: x.lower())\nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: x.split())\nhyd_rev['Review']=hyd_rev['Review'].apply(lambda x: [item for item in x if item not in stop_words])\nhyd_rev['Review']=hyd_rev['Review'].apply(lambda x: [item for item in x if item not in rest_word])","4b2a775e":"from wordcloud import WordCloud\nhyd_rev['Review']=hyd_rev['Review'].astype(str)\n\nps = PorterStemmer() \nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: ps.stem(x))\nlong_string = ','.join(list(hyd_rev['Review'].values))\nlong_string\nwordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\nwordcloud.generate(long_string)\nwordcloud.to_image()\n","7b8f2692":"\nhyd_rev['Rating']=pd.to_numeric(hyd_rev['Rating'],errors='coerce')\npos_rev = hyd_rev[hyd_rev.Rating>= 3]\nneg_rev = hyd_rev[hyd_rev.Rating< 3]\n","e83f2032":"long_string = ','.join(list(pos_rev['Review'].values))\nlong_string\nwordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\nwordcloud.generate(long_string)\nwordcloud.to_image()","09a8196f":"long_string = ','.join(list(neg_rev['Review'].values))\nlong_string\nwordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\nwordcloud.generate(long_string)\nwordcloud.to_image()","ee2d7c34":"from gensim.models import word2vec\npos_rev = hyd_rev[hyd_rev.Rating>= 3]\nneg_rev = hyd_rev[hyd_rev.Rating< 3]","b8c6ce06":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['Review']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(neg_rev)        \ncorpus[0:2]","94120886":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt","875e8f96":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","51d65536":"tsne_plot(model)","8a7e4e20":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['Review']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(pos_rev)        \ncorpus[0:2]","c70f283d":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt","6d18ff9f":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","36b568bc":"tsne_plot(model)","15ad48a9":"from nltk.tag import pos_tag\nfrom nltk import pos_tag_sents","d528bb4d":"neg_texts = neg_rev['Review'].str.split().map(pos_tag)\nneg_texts.head()\ndef count_tags(title_with_tags):\n    tag_count = {}\n    for word, tag in title_with_tags:\n        if tag in tag_count:\n            tag_count[tag] += 1\n        else:\n            tag_count[tag] = 1\n    return(tag_count)\nneg_texts.map(count_tags).head()\n","8358b5a6":"neg_texts = pd.DataFrame(neg_texts)\nneg_texts['tag_counts'] = neg_texts['Review'].map(count_tags)\nneg_texts.head()","a5aa2605":"tag_set = list(set([tag for tags in neg_texts['tag_counts'] for tag in tags]))\nfor tag in tag_set:\n    neg_texts[tag] = neg_texts['tag_counts'].map(lambda x: x.get(tag, 0))\ntitle = 'Frequency of POS Tags in Negative Reviews'    \nneg_texts[tag_set].sum().sort_values().plot(kind='barh', logx=True, figsize=(12,8), title=title)\n","9a90830e":"import numpy as np\nimport seaborn as sns\ndef plot_10_most_common_words(count_data, count_vectorizer):\n    import matplotlib.pyplot as plt\n    words = count_vectorizer.get_feature_names()\n    total_counts = np.zeros(len(words))\n    for t in count_data:\n        total_counts+=t.toarray()[0]\n        count_dict = (zip(words, total_counts))\n    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n    words = [w[0] for w in count_dict]\n    counts = [w[1] for w in count_dict]\n    x_pos = np.arange(len(words)) \n    \n    plt.figure(2, figsize=(15, 15\/1.6180))\n    plt.subplot(title='10 most common words in Negative reviews')\n    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n    sns.barplot(x_pos, counts, palette='husl')\n    plt.xticks(x_pos, words, rotation=90) \n    plt.xlabel('words')\n    plt.ylabel('counts')\n    plt.show()\ntext2=neg_rev['Review'].values\ncount_vectorizer = CountVectorizer(stop_words='english')\n\ncount_data = count_vectorizer.fit_transform(text2)\nplot_10_most_common_words(count_data, count_vectorizer)\n\n\nimport warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\n# Load the LDA model from sk-learn\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\n \n# Helper function\ndef print_topics(model, count_vectorizer, n_top_words):\n    words = count_vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"\\nTopic #%d:\" % topic_idx)\n        print(\" \".join([words[i]\n                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n        \n# Tweak the two parameters below\nnumber_topics = 10\nnumber_words = 10\n# Create and fit the LDA model\nlda = LDA(n_components=number_topics, n_jobs=-1)\nlda.fit(count_data)\n# Print the topics found by the LDA model\nprint(\"10 Topics found via LDA for negative reviews:\")\nprint_topics(lda, count_vectorizer, number_words)\n\n\n","84903336":"import spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\ndef extract_named_ents(text):    \n    return [ ent.label_ for ent in nlp(text).ents]  \nneg_rev['named_ents'] = neg_rev['Review'].apply(extract_named_ents)   ","5afae82b":"text_ents=neg_rev[['named_ents','Review','Restaurant','Rating']]\ntext_ents['named_ents_new']=[','.join(map(str, l)) for l in text_ents['named_ents']]\ntext_ents","ee0860bf":"DATE_PROBLEM=text_ents['named_ents_new'] == 'DATE'\ntext_ents[DATE_PROBLEM]","7ad1bd35":"avg_rating=hyd_rev.groupby('Restaurant',as_index=False)['Rating'].mean()\nmerged=hyd_rest.merge(avg_rating, how='inner',left_on='Name',right_on='Restaurant')","f98d0987":"merged.head()","837ef66a":"merged[\"North_indian\"]= merged[\"Cuisines\"].str.find(\"North Indian\")  \nmerged[\"Chinese\"]=merged[\"Cuisines\"].str.find(\"Chinese\")\nmerged[\"South_Indian\"]=merged[\"Cuisines\"].str.find(\"South Indian\")","af4b36b1":"merged.loc[merged['North_indian'] == -1, 'North_Indian_menu'] = 0\nmerged.loc[merged['North_indian'] > -1, 'North_Indian_menu'] = 1\nmerged.loc[merged['Chinese'] == -1, 'Chinese_menu'] = 0\nmerged.loc[merged['Chinese'] > -1, 'Chinese_menu'] = 1\nmerged.loc[merged['South_Indian'] == -1, 'South_Indian_menu'] = 0\nmerged.loc[merged['South_Indian'] > -1, 'South_Indian_menu'] = 1","765a3dfb":"North=merged[merged['North_Indian_menu'] == 1]\nmean_rating_N=North.groupby(['Name','Cost'],as_index=False).Rating.mean()","e4af109b":"import plotly.express as px\nfig = px.bar(mean_rating_N, x=\"Name\", y=\"Cost\",color=\"Rating\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.update_layout(title_text=\"North Indian restaurant cost vs rating\")\nfig.show()","c6fb0151":"South=merged[merged['South_Indian_menu'] == 1]\n\nmean_rating_S=South.groupby(['Name','Cost'],as_index=False).Rating.mean()\nfig = px.bar(mean_rating_S, x=\"Name\", y=\"Cost\",color=\"Rating\")\nfig.update_layout(title_text=\"South Indian restaurant cost vs rating\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.show()","8465ee0a":"Chinese=merged[merged['Chinese_menu'] == 1]\nmean_rating_C=Chinese.groupby(['Name','Cost'],as_index=False).Rating.mean()\nfig = px.bar(mean_rating_C, x=\"Name\", y=\"Cost\",color=\"Rating\")\nfig.update_layout(title_text=\"Chinese restaurant cost vs rating\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.show()","09fb12ed":"merged['Cost']=merged['Cost'].str.replace(',', '').astype(float)\nmerged['Cost']=merged['Cost'].astype(float)\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2, random_state=0).fit(merged[['Cost', 'Rating']])\nmerged['Name'] = kmeans.labels_\nwith plt.style.context('bmh', after_reset=True):\n    pal = sns.color_palette('Spectral', 7)\n    plt.figure(figsize = (8,6))\n    for i in range(2):\n        ix = merged.Name == i\n        plt.scatter(merged.loc[ix, 'Rating'], merged.loc[ix, 'Cost'], color = pal[i], label = str(i))\n        plt.text(merged.loc[i, 'Rating'], merged.loc[i, 'Cost'], str(i) + ': '+str(merged.loc[i, 'Name'].round(2)), fontsize = 14, color = 'brown')\n    plt.title('KMeans Hyderabad Restaurant for Cost and Rating')\n    plt.legend()\n    plt.show()","cf771cae":"merged['Cuisines'] = merged['Cuisines'].astype(str)\nmerged['fusion_num'] = merged['Cuisines'].apply(lambda x: len(x.split(',')))\n\nfrom collections import Counter\nlst_cuisine = set()\nCnt_cuisine = Counter()\nfor cu_lst in merged['Cuisines']:\n    cu_lst = cu_lst.split(',')\n    lst_cuisine.update([cu.strip() for cu in cu_lst])\n    for cu in cu_lst:\n        Cnt_cuisine[cu.strip()] += 1\n\ncnt = pd.DataFrame.from_dict(Cnt_cuisine, orient = 'index')\ncnt.sort_values(0, ascending = False, inplace = True)\n\n\ntmp_cnt = cnt.head(10)\ntmp_cnt.rename(columns = {0:'cnt'}, inplace = True)\nwith plt.style.context('bmh'):\n    f = plt.figure(figsize = (12, 8))\n    ax = plt.subplot2grid((2,2), (0,0))\n    sns.barplot(x = tmp_cnt.index, y = 'cnt', data = tmp_cnt, ax = ax, palette = sns.color_palette('Blues_d', 10))\n    ax.set_title('# Cuisine')\n    ax.tick_params(axis='x', rotation=70)\n    ax = plt.subplot2grid((2,2), (0,1))\n    sns.countplot(merged['fusion_num'], ax=ax, palette = sns.color_palette('Blues_d', merged.fusion_num.nunique()))\n    ax.set_title('# Cuisine Provided')\n    ax.set_ylabel('')\n\n    ax = plt.subplot2grid((2,2), (1,0), colspan = 2)\n    fusion_rate = merged[['fusion_num', 'Rating']].copy()\n    fusion_rate.loc[fusion_rate['fusion_num'] > 5,'fusion_num'] = 5\n    fusion_rate = fusion_rate.loc[fusion_rate.Rating != -1, :]\n    pal = sns.color_palette('Oranges', 11)\n    for i in range(1,6):\n        num_ix = fusion_rate['fusion_num'] == i\n        sns.distplot(fusion_rate.loc[num_ix, 'Rating'], color = pal[i*2], label = str(i), ax = ax)\n        ax.legend()\n        ax.set_title('Rating Distribution for fusion_number')\n\n    plt.subplots_adjust(wspace = 0.5, hspace = 0.8, top = 0.85)\n    plt.suptitle('Cuisine _ Rating')\n    plt.show()        \nprint('# Unique Cuisine: ', len(lst_cuisine))\n","bbe28dad":"hyd_rev['total_reviews']=hyd_rev['Metadata'].str.extract('(\\d+)')\nhyd_rev","92229554":"import plotly.express as px\nfig = px.scatter_3d(hyd_rev, x='Review_length', y='total_reviews', z='Rating')\nfig.update_layout(title_text=\"Review Length vs Rating vs Number of Reviews \")\nfig.show()","143d9101":"reviewer_rating=hyd_rev.groupby(['Reviewer'],as_index=False).Rating.mean()\nmerged2=reviewer_rating.merge(hyd_rev[['Reviewer','total_reviews']],how='left',left_on='Reviewer',right_on='Reviewer')\nmerged2=merged2.drop_duplicates()\nmerged2['total_reviews']=merged2['total_reviews'].fillna(0)\nmerged2['total_reviews']=merged2['total_reviews'].astype(int)\nreveiwer_300=merged2[merged2['total_reviews']>300]","716ab472":"fig = px.scatter_matrix(reveiwer_300,dimensions=[\"total_reviews\", \"Rating\"], color=\"Reviewer\")\nfig.update_layout(title_text=\"Total Reviews vs Ratings for 300+ reviewers \")\nfig.show()","42734df7":"# Topic Modeling using LDA\nWe will plot top 10 most occuring words. Topic modeling is  a process to automatically identify topics present in a text object and to assign text corpus to one category of topic.\n \nLDA is one of the methods to assign topic to texts. If observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics.\n\nSource: https:\/\/en.wikipedia.org\/wiki\/Latent_Dirichlet_allocation","7956d5bb":"# Multiple Cuisines gives higher ratings\n\nwe will plot : \n1.what type of cuisines are served most\n2.frequency of multiple cuisines restaurant\n3.rating vs multiple cuisines\n","db1d3e60":"Tsne works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words.","be11ee12":"ambience is key factor in food business, time, and variety in food is the key like starters , main course","487bf4ee":"# Creating word embeddings and t-SNE plot( for positive and negative reviews)\n","967deb36":"## Importing the NLTK, Scikit libraries and features","68770489":"Here we have lot many frequent occurences: Chicken items like biryani kebab , cheese , burger pizza , variety service staff music ambience are key too good reviews","bd0a2fab":"## 3d plot for finding pattern between review length , rating and number of review","e704e157":"## Negative reviews wordcloud","e4abcb46":"The scatter plot confirms that length of review doesnt impact ratings","a7374338":"# wordclouds for all reviews, positive reviews and negative reviews\n\nI will create two datasets equal and above 3 rating for positive reviews and below 3 for negative reviews. Apart from stopwords i have removing common words used in restuarant business\n","8acbf2ba":"# EDA\nThe notebook will use bokeh and plotly to see ratings, reviews and cost relationships , will use NLTK,gensim, to convert text to vectors to find relatinonships between text. We will also see wordclouds ","4f6bf1db":"Service,taste,time,starters are key to good review","e9203d67":"## plot for negative reviews","156bf245":"Two people in particular have rated every restuarant very poorly, while person who have most reviews gives average ratings to every restuarant.","4ece0edd":"The plot suggest that very lengthy reviews have either very high ratings or very ratings. Average reviews have very small length of review.Number of reviews do not show much impact on ratings","cdb4671b":"Service , bad chicken , staff behavior, stale food are key reasons for neagtive reviews","c640ac80":"# Hyderabad\nIf you are Indian or have stayed in India for sometime, probably you have heard about Hyderabadi Biryani, its one of hallmark dishes of country and city. We will use Zomato reviews from Hyderabad locality to see how the food market is doing in Nizam City.\n","6cfa0a0b":"### Creating two datasets for positive and negative reviews","da688685":"# Named Entity Recoginition in negative reviews\n\nNamed-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n\nSource: https:\/\/en.wikipedia.org\/wiki\/Named-entity_recognition\n\nI will try to find negative reviews wherever they have date mentioned in specifically in the review","a8d8578f":"Thanks for your time to review this lengthy notebook, its a long effort, your upvote will motivate me.\n","74047861":"# Kmeans - 2 cluster suggesting 1000INR for two is quality bechmark\n\nTried K means clustering which gives 2 clear clusters when we cluster restuarant based on rating and cost for two, if its above 1000 INR the rating are are never low barring one near average rating of Hyatt","8b454cab":"# Extracting total reviews from metadata column","7f8d2eb0":"## The Ratings distribution","d9f9ff90":"38% reviews are 5 rated,23% are 4 rated stating that people do rate good food high.","a5eda410":"## Creating polarity variable to see sentiments in reviews(using textblob)\n\nPloarity analyzes the text ranges and search for words that express sentiments such as good or bad assignes a score to text in following manner: emotional negative (-2), rational negative (-1), neutral (0), rational positive (+1), and emotional positive (+2). In practice, neutral often means no opinion or sentiment expressed.","0bb7826e":"The words close together for negative reviews : service,staff,time suggest these are key factors in negative reviews","3f8b107f":"# POS tagging of negative rated reviews\n\nPOS tagging tags the text to grammar like if its is noun, pronoun, verb ,adjective etc are present in texts:\n\nThe complete lits of POS tags are in this website:\n\nhttps:\/\/pythonprogramming.net\/part-of-speech-tagging-nltk-tutorial\/","d43c1c97":"# Reading the files","efa49992":"The graph shows us the majority of reviews are nuetral 0,probably sugesting mixture of bad and good words in reviews, also the number of positive reviews >0 are higher than negative reviews, more than 200 odd reviews have very high positive sentiments","cc089aba":"## Positive reviews wordcloud","b9891af6":"## plot for postive reviews","281d777e":"### creating new variable review length to see if length of review impacts the ratings\n","f3780e0c":"#### Bokeh scatter plot for review length vs rating","d19031e9":"# Poeple who reviewed > 300 times, Their orders and ratings","6257ee11":"# Merging two datasets and Finding North Indian, Chinese and South Indian food options and ratings","f84f11e5":"Creating a loop that counts pos tags increments tag count of tags, then we plot the number pos tags frequency"}}