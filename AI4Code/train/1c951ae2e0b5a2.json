{"cell_type":{"73a8fe0b":"code","252a4bbf":"code","3ee2cf6e":"code","2b1e6eb4":"code","ce715aec":"code","fb5e7077":"code","1f859463":"code","54a07ecc":"code","ca45e1fe":"code","439fe6e5":"code","7edf977b":"code","5b02a915":"code","ba1e5bd3":"code","62e79a4a":"code","5fa12432":"code","0d8a0f75":"code","e8241186":"code","5a81389c":"markdown","81fdbd3f":"markdown","d587dfc9":"markdown","e85f0e76":"markdown","d34bf56a":"markdown","dbba5118":"markdown","4a68977a":"markdown","5dfbe54d":"markdown","84bdb8ce":"markdown","c81c1b92":"markdown","e88444a5":"markdown","336f9ee2":"markdown","d43811b0":"markdown","da7ef591":"markdown","4cd82804":"markdown","97077250":"markdown","c982909a":"markdown"},"source":{"73a8fe0b":"# Importing data\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id') \nX_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')\n\n","252a4bbf":"# Shape train dataset:\nprint(\"Shape train dataset (com coluna target ):\", X.shape)\n\n\n# Shape test dataset:\nprint(\"Shape test dataset:\", X_test.shape)\n\n\n# Missing rows in target column train:\nprint(\"Missing rows in target column train:\", (X.SalePrice.isnull().sum()))\n\n\n# Numeric columns:\nprint(\"Numerical columns:\", X.select_dtypes(include=np.number).shape[1])\n\n\n# Missing rows in numeric columns:\n#print(\"Numerical columns:\", X[X.select_dtypes(include=np.number).isnull().sum()>0]\n\n# Categorical columns:\n\n\n\n# Missing rows in numeric columns:","3ee2cf6e":"# separate target from predictors\n#X.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice\nX.drop(['SalePrice'], axis=1, inplace=True)\nprint(X.shape)\n\n\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=1)\nprint(X_train.shape)","2b1e6eb4":"# Selecionando numericos\nX_numerical_train = X_train.select_dtypes(exclude=['object'])\nX_numerical_valid = X_valid.select_dtypes(exclude=['object'])\nX_numerical_test = X_test.select_dtypes(exclude=['object'])\n\n# Selecionando categoricos\nX_categorical_train = X_train.select_dtypes(exclude=['int64', 'float64'])\nX_categorical_valid = X_valid.select_dtypes(exclude=['int64', 'float64'])\nX_categorical_test = X_test.select_dtypes(exclude=['int64', 'float64'])\n\nprint(X_numerical_train.shape)\nprint(X_numerical_valid.shape)\nprint(X_numerical_test.shape)\nprint(X_categorical_train.shape)\nprint(X_categorical_valid.shape)\nprint(X_categorical_test.shape) #Tudo certo, nenhum dado sumido.","ce715aec":"# Quais colunas possuem NAs?\nmissing_val_count_by_column = (X_numerical_train.isnull().sum())\nprint(\"Colunas com NA tabela treino: \\n\", missing_val_count_by_column[missing_val_count_by_column > 0])\n\nmissing_val_count_by_column2 = (X_numerical_valid.isnull().sum())\nprint(\"Colunas com NA tabela validation: \\n\",missing_val_count_by_column2[missing_val_count_by_column2 > 0])\n\n\nmissing_val_count_by_column3 = (X_numerical_test.isnull().sum())\nprint(\"Colunas com NA tabela teste: \\n\",missing_val_count_by_column3[missing_val_count_by_column3 > 0])\n\n","fb5e7077":"# Approach ser\u00e1 dividido em 2: \n    #Os Nas na coluna GarageYrBlt ser\u00e1 preenchidos com os respectivos valores da coluna YearBuilt\n    #Demais valores ser\u00e3o subsituidos pela m\u00e9dia\n    \nX_numerical_train.GarageYrBlt = X_numerical_train.GarageYrBlt.fillna(X_numerical_train.YearBuilt)\nX_numerical_valid.GarageYrBlt = X_numerical_valid.GarageYrBlt.fillna(X_numerical_valid.YearBuilt)\nX_numerical_test.GarageYrBlt = X_numerical_test.GarageYrBlt.fillna(X_numerical_test.YearBuilt)\n\n#Testando: \n    #Funciona - para retestar so colocar o codechunk acima aqui embaixo\n\n# Inputando nas outras colunas:\nfrom sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nX_numerical_train_inp = pd.DataFrame(my_imputer.fit_transform(X_numerical_train))\nX_numerical_valid_inp = pd.DataFrame(my_imputer.transform(X_numerical_valid))\nX_numerical_test_inp = pd.DataFrame(my_imputer.transform(X_numerical_test))\n\n    #recolocando nome colunas\nX_numerical_train_inp.columns = X_numerical_train.columns\nX_numerical_valid_inp.columns = X_numerical_valid.columns\nX_numerical_test_inp.columns = X_numerical_test.columns\n\n\n\n\n","1f859463":"# TESTE PRA VER SE AINDA H\u00c1\nmissing_val_count_by_column = (X_numerical_train_inp.isnull().sum())\nprint(\"Colunas com NA tabela treino: \\n\", missing_val_count_by_column[missing_val_count_by_column > 0])\n\nmissing_val_count_by_column2 = (X_numerical_valid_inp.isnull().sum())\nprint(\"Colunas com NA tabela validation: \\n\",missing_val_count_by_column2[missing_val_count_by_column2 > 0])\n\n\nmissing_val_count_by_column3 = (X_numerical_test_inp.isnull().sum())\nprint(\"Colunas com NA tabela teste: \\n\",missing_val_count_by_column3[missing_val_count_by_column3 > 0])\n\nprint(X_numerical_train_inp.isnull().sum())\n\n#Teste passado!!!","54a07ecc":"missing_val_count_by_column_cat1 = (X_categorical_train.isnull().sum())\nprint(\"Colunas com NA tabela treino: \\n\", missing_val_count_by_column_cat1[missing_val_count_by_column_cat1 > 0]) # 15 colunas\n\nmissing_val_count_by_column_cat2 = (X_categorical_valid.isnull().sum())\nprint(\"Colunas com NA tabela valid: \\n\", missing_val_count_by_column_cat2[missing_val_count_by_column_cat2 > 0]) # 13 colunas\n\nmissing_val_count_by_column_cat3 = (X_categorical_test.isnull().sum())\nprint(\"Colunas com NA tabela test: \\n\", missing_val_count_by_column_cat3[missing_val_count_by_column_cat3 > 0]) # 22 colunas\n\n","ca45e1fe":"# Teste para entender possiveis valores de cada uma das colunas\n\n# Categorical columns in the training data\nobject_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n\n\n# Get number of unique entries in each column with categorical data\nobject_nunique = list(map(lambda col: X_categorical_train[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n\n# Print number of unique entries by column, in ascending order\nsorted(d.items(), key=lambda x: x[1])","439fe6e5":"# columns where NaN values have meaning e.g. no pool etc.\ncols_fillna = ['PoolQC','MiscFeature','Alley','Fence','FireplaceQu',\n               'GarageQual','GarageCond','GarageFinish','MasVnrType','GarageType',\n               'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2']\n\n# replace 'NaN' with 'None' in these columns\n\n#Train\nfor col in cols_fillna:\n    X_categorical_train[col].fillna('None',inplace=True)\n    \n#Valid\nfor col in cols_fillna:\n    X_categorical_valid[col].fillna('None',inplace=True)\n\n#Test\nfor col in cols_fillna:\n    X_categorical_test[col].fillna('None',inplace=True)\n    \n    \n    \n\n# Checando\nmissing_val_count_by_column_cat1 = (X_categorical_train.isnull().sum())\nprint(\"Colunas com NA tabela treino: \\n\", missing_val_count_by_column_cat1[missing_val_count_by_column_cat1 > 0]) \n\nmissing_val_count_by_column_cat2 = (X_categorical_valid.isnull().sum())\nprint(\"Colunas com NA tabela valid: \\n\", missing_val_count_by_column_cat2[missing_val_count_by_column_cat2 > 0])\n\nmissing_val_count_by_column_cat3 = (X_categorical_test.isnull().sum())\nprint(\"Colunas com NA tabela test: \\n\", missing_val_count_by_column_cat3[missing_val_count_by_column_cat3 > 0])\n\n    ","7edf977b":"# Inputando nas outras colunas:\n\nmy_imputer = SimpleImputer(strategy='most_frequent')\nX_categorical_train_inp = pd.DataFrame(my_imputer.fit_transform(X_categorical_train))\nX_categorical_valid_inp = pd.DataFrame(my_imputer.transform(X_categorical_valid))\nX_categorical_test_inp = pd.DataFrame(my_imputer.transform(X_categorical_test))\n\n    #recolocando nome colunas\nX_categorical_train_inp.columns = X_categorical_train.columns\nX_categorical_valid_inp.columns = X_categorical_valid.columns\nX_categorical_test_inp.columns = X_categorical_test.columns","5b02a915":"# Checando\nmissing_val_count_by_column_cat1 = (X_categorical_train_inp.isnull().sum())\nprint(\"Colunas com NA tabela treino: \\n\", missing_val_count_by_column_cat1[missing_val_count_by_column_cat1 > 0]) \n\nmissing_val_count_by_column_cat2 = (X_categorical_valid_inp.isnull().sum())\nprint(\"Colunas com NA tabela valid: \\n\", missing_val_count_by_column_cat2[missing_val_count_by_column_cat2 > 0])\n\nmissing_val_count_by_column_cat3 = (X_categorical_test_inp.isnull().sum())\nprint(\"Colunas com NA tabela test: \\n\", missing_val_count_by_column_cat3[missing_val_count_by_column_cat3 > 0])","ba1e5bd3":"from sklearn.preprocessing import OneHotEncoder\n\n# Use as many lines of code as you need!\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_categorical_train_inp))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_categorical_valid_inp))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(X_categorical_test_inp))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = X_categorical_train_inp.index\nOH_cols_valid.index = X_categorical_valid_inp.index\nOH_cols_test.index = X_categorical_test_inp.index\n\nprint(OH_cols_train.shape)\nprint(OH_cols_valid.shape)\nprint(OH_cols_test.shape) # todos tem mesma quantidade de linhas que a parte numerica\n\nprint(X_numerical_train_inp.shape)\n\n","62e79a4a":"# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([X_numerical_train_inp, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([X_numerical_valid_inp, OH_cols_valid], axis=1)\nOH_X_test = pd.concat([X_numerical_test_inp, OH_cols_test], axis=1)\n\n\nprint(OH_X_train.shape)\nprint(OH_X_valid.shape)\nprint(OH_X_test.shape)","5fa12432":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom xgboost import XGBRegressor\n\n#Definindo modelos:\nmodel_1 = RandomForestRegressor(random_state=1, n_estimators=100, n_jobs = -1)\nmodel_2 = RandomForestRegressor(n_estimators=500, random_state=0, n_jobs = -1)\nmodel_3 = RandomForestRegressor(n_estimators=700, random_state=0, n_jobs = -1)\nmodel_4 = RandomForestRegressor(n_estimators=1500, criterion='mae', random_state=0, n_jobs = -1)\nmodel_5 = XGBRegressor(random_state = 420, n_estimators=100, n_jobs = -1)\nmodel_6 = XGBRegressor(random_state = 420, n_estimators=500, n_jobs = -1)\nmodel_7 = XGBRegressor(random_state = 420, n_estimators=700,n_jobs = -1)\nmodel_8 = XGBRegressor(random_state = 420, n_estimators=1500, n_jobs = -1)\nmodel_9 = GradientBoostingRegressor(random_state=420, n_estimators=300) \nmodel_10 = GradientBoostingRegressor(random_state=420, n_estimators=450) \nmodel_11 = GradientBoostingRegressor(random_state=420, n_estimators=550)\nmodel_12 = GradientBoostingRegressor(random_state=420, n_estimators=650)\nmodel_13 = GradientBoostingRegressor(random_state=420, n_estimators=900)\n\n\n\nmodels = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10, model_11, model_12, model_13]\n\n# Fun\u00e7\u00e3o que ir\u00e1 fazer fit, prever e retornar MAE\ndef score_model(model, X_t=OH_X_train, X_v=OH_X_valid, y_t=y_train, y_v=y_valid):\n    model.fit(X_t, y_t)\n    preds = model.predict(X_v)\n    return mean_absolute_error(y_v, preds)\n\nfor i in range(0, len(models)):\n    mae = score_model(models[i])\n    print(\"Model %d Mae: %d\" % (i+1, mae))","0d8a0f75":"preds_test = model_12.predict(OH_X_test)\n\n#pred_model7 = model_7.predict(OH_X_test)\n#pred_model8 = model_8.predict(OH_X_test)\n\n#preds_test = (pred_model8  + pred_model7)\/2\n","e8241186":"\n# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","5a81389c":"5.2 - Defini\u00e7\u00e3o modelos:","81fdbd3f":"Fazendo assim, sobram apenas:\n*  1 coluna (Eletrical) para estimar imputa\u00e7\u00e3o em treino (1 valor)\n*  0 coluna para estimar imputa\u00e7\u00e3o em treino\n*  7 colunas (MSZoning, Utilities, Exterior1st, Exterior2nd, KitchenQual, Functional, SaleType) para estimar imputa\u00e7\u00e3o em treino (4,2,1,1,1,2,1 valores respectivamente)","d587dfc9":"5.3 - Realiza\u00e7\u00e3o previs\u00f5es\n","e85f0e76":"**2.2.1 - Checar:**","d34bf56a":"**4 - Juntar tabela categoricos com numericos:**","dbba5118":"**1.1 - Checking Data:**","4a68977a":"**6 - Submiss\u00e3o resultados:**","5dfbe54d":"**3.1 - Categ\u00f3ricos: checar Nas:**","84bdb8ce":"**2.2 - Inputation em colunas com NAs:**","c81c1b92":"**3.2 - Inputation em colunas com NAs:**\n\n Para inputar as variaveis, vamos dividir em 2 approachs diferentes. \n*     Approach 1 - H\u00e1 colunas que colocam NA quando a observa\u00e7\u00e3o especifica tem valor 0 (EX: NA em alley \u00e9 quando nao h\u00e1 alley naquela casa)\n*     Approach 2 - Apos fazer isso, inputar lidando com dados nao disponiveis (bfill, ou most commom )\n    \n\n","e88444a5":"  Colunas categoricas que tem NA mas que nao \u00e9 missing value:\n*     1 -Alley - NA \u00e9 No alley access\n*     2 - BsmtQual - NA \u00e9 no basement\n*     3 - BsmtExposure - NA \u00e9 No basement\n*     4 - BsmtFinType1 - NA \u00e9 No basement\n*     5 - BsmtFinType2 - NA \u00e9 No basement\n*     6 - FireplaceQu - NA \u00e9 No fireplace\n*     7 - GarageType - NA \u00e9 No Garage\n*     8 - GarageFinish - NA \u00e9 No Garage\n*     9 - GarageQual - NA \u00e9 No Garage\n*     10 - GarageCond - NA \u00e9 No Garage\n*     11 - PoolQC - NA \u00e9 No Pool\n*     12 - Fence - NA \u00e9 No Fence\n*     13 - MiscFeature - NA \u00e9 none\n*     14 - BsmtCond - NA \u00e9 No Basement\n    ","336f9ee2":"**5 - Modegalem:**","d43811b0":"**3.3 - Processamento One Hot Encoding:**","da7ef591":"**1 - Importing Data:**","4cd82804":"**2.1 - Numericos: checar NAs**","97077250":"**1.3 - Separa\u00e7\u00e3o numerico e categorico:**","c982909a":"**1.2 - Data split train\/valid:**"}}