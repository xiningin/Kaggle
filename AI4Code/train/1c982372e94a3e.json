{"cell_type":{"f53aed47":"code","00a34ed7":"code","862731a8":"code","1fcbb3d4":"code","c0c28319":"code","057dacdb":"code","25169bb0":"code","32a72801":"code","4485133a":"code","020c50f6":"markdown","bf746971":"markdown","f66f0589":"markdown","628329d4":"markdown","1bdd04f2":"markdown","499d5642":"markdown","2d44d259":"markdown","04ffc881":"markdown","668636b0":"markdown"},"source":{"f53aed47":"import gc\n\nimport pandas as pd\nimport math\n\nimport cv2\nimport numpy as np\nimport matplotlib\nimport random\n\nfrom tensorboard.backend.event_processing import event_accumulator\n# matplotlib.use('agg')\nimport matplotlib.pyplot as plt\nimport time\nimport torch\nimport torch.nn as nn\nimport os\n\nimport torch.nn.functional as F\n\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML","00a34ed7":"\n\n\ndef state_step(state: np.array):\n    neighbour_sum = \\\n        np.roll(state, -1, axis=0) + \\\n        np.roll(state, 1, axis=0) + \\\n        np.roll(state, -1, axis=1) + \\\n        np.roll(state, 1, axis=1) + \\\n        np.roll(np.roll(state, -1, axis=0), -1, axis=1) + \\\n        np.roll(np.roll(state, -1, axis=0), 1, axis=1) + \\\n        np.roll(np.roll(state, 1, axis=0), -1, axis=1) + \\\n        np.roll(np.roll(state, 1, axis=0), 1, axis=1)\n    out = np.zeros(state.shape, dtype=np.int)\n    out[neighbour_sum == 3] = 1\n    out[np.logical_and(neighbour_sum == 2, state == 1)] = 1\n    return out\n\n\nclass TiledConv2d(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.conv = nn.Conv2d(in_features, out_features, kernel_size=3, bias=False)\n\n    def forward(self, x):\n        return self.conv(F.pad(x, [1, 1, 1, 1], mode='circular'))\n\n\nclass TiledResBlock(nn.Module):\n    def __init__(self, features):\n        super().__init__()\n        self.main = nn.Sequential(\n            nn.BatchNorm2d(features),\n            nn.ReLU(True),\n            TiledConv2d(features, features),\n            nn.BatchNorm2d(features),\n            nn.ReLU(True),\n            TiledConv2d(features, features)\n        )\n\n    def forward(self, x):\n        return self.main(x) + x\n\n\ndef best_guess_block(input_channels, channels):\n    return nn.Sequential(\n        nn.Conv2d(input_channels, channels, 1, bias=False),\n        TiledResBlock(channels),\n        TiledResBlock(channels),\n        nn.BatchNorm2d(channels),\n        nn.ReLU(True),\n    )\n\n\ndef create_net_input_array(state: np.array, predicted_mask: np.array, predictions: np.array):\n    input_dead = (1 - state).astype(np.float)\n    input_alive = state.astype(np.float)\n    input_unpredicted = (1 - predicted_mask).astype(np.float)\n    input_predicted_dead = ((1 - predictions) * predicted_mask).astype(np.float)\n    input_predicted_alive = (predictions * predicted_mask).astype(np.float)\n    sample_input = np.stack([\n        input_dead,\n        input_alive,\n        input_unpredicted,\n        input_predicted_dead,\n        input_predicted_alive],\n        axis=2\n    )\n\n    return sample_input.transpose((2, 0, 1)).astype(np.float)\n\n\nclass BestGuessModule(nn.Module):\n    def __init__(self, channels=16 * 8):\n        super().__init__()\n\n        self.main = nn.Sequential(\n            best_guess_block(5, channels),\n            best_guess_block(channels, channels * 2),\n            best_guess_block(channels * 2, channels * 4),\n            nn.Conv2d(channels * 4, 2, 1)\n        )\n\n    def forward(self, x):\n        return self.main(x)\n\n    def get_probabilities(self, x):\n        return torch.softmax(self.main(x), 1)\n\n    def get_best_guess(self, x: torch.tensor, mask: np.array):\n        probabilities = self.get_probabilities(x)\n        masked_probabilities = np.array(probabilities.tolist()) * (1 - mask)\n        guess = np.unravel_index(masked_probabilities.argmax(), masked_probabilities.shape)\n        return {\n            \"coord_yx\": np.array([guess[2], guess[3]]),\n            \"alive\": guess[1]\n        }\n\n    def get_best_guesses(self, x: torch.tensor, mask: np.array, num_guesses=2):\n        probabilities = self.get_probabilities(x)\n        masked_probabilities = np.array(probabilities.tolist()) * (1 - mask)\n        guess = np.unravel_index(masked_probabilities.argmax(), masked_probabilities.shape)\n        return {\n            \"coord_yx\": np.array([guess[2], guess[3]]),\n            \"alive\": guess[1]\n        }\n\n    def get_best_by_threshold(self, x: torch.tensor, mask: np.array, threshold: float):\n        probabilities = self.get_probabilities(x)\n        masked_probabilities = np.array(probabilities.tolist()) * (1 - mask)\n        results = np.where(masked_probabilities >= threshold)\n        return {\n            \"coord_yx\": np.array([results[2], results[3]]),\n            \"alive\": results[1]\n        }\n\n    def get_tendencies_img(self, x):\n        return np.array(self.get_probabilities(x).tolist()).transpose((0, 2, 3, 1))[0, :, :, 1]\n\n\n    def solve(self,\n              state: np.array,\n              device: torch.device,\n              ground_truth=None):\n\n        predicted_mask = np.zeros(state.shape)\n        predictions = np.zeros(state.shape)\n        total_runs = state.shape[0] * state.shape[1]\n        \n        fig = plt.figure(figsize=(8, 6))\n\n        def animate(i):\n            sample_input = create_net_input_array(state, predicted_mask, predictions)\n            batch_input = torch.from_numpy(np.expand_dims(sample_input, 0)).float().to(device)\n            guess = self.get_best_guess(batch_input, predicted_mask)\n            predicted_mask[guess['coord_yx'][0], guess['coord_yx'][1]] = 1\n            predictions[guess['coord_yx'][0], guess['coord_yx'][1]] = guess['alive']\n\n\n            # input\n            plt.clf()\n            sub = fig.add_subplot(2, 3, 1)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"start (ground truth)\")\n            if ground_truth is not None:\n                sub.imshow(ground_truth.astype(np.float))\n            sub = fig.add_subplot(2, 3, 4)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"end state\")\n            sub.imshow(state.astype(np.float))\n\n            # net\n            sub = fig.add_subplot(2, 3, 3)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"net probabilities\")\n            prob = self.get_tendencies_img(batch_input)\n            overlay = np.ones((state.shape[0], state.shape[1], 4), dtype=np.float)\n            overlay[:, :, 3] = predicted_mask\n            # prob[prob < 0.5] *= -1\n            # prob[prob < 0.5] += 1.0\n            # prob *= (1 - prev_predicted_mask)\n            sub.imshow(prob, vmin=0.0, vmax=1.0)\n            sub.imshow(overlay, vmin=0.0, vmax=1.0)\n\n            # outcome\n            sub = fig.add_subplot(2, 3, 2)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"net prediction\")\n            overlay = np.ones((state.shape[0], state.shape[1], 4), dtype=np.float)\n            overlay[:, :, 3] = (1.0 - predicted_mask) * 0.66\n            sub.imshow(predictions.astype(np.float))\n            sub.imshow(overlay, vmin=0.0, vmax=1.0)\n            sub = fig.add_subplot(2, 3, 5)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"forwarded prediction\".format(1))\n            outc = predictions\n            for d in range(1):\n                outc = state_step(outc)\n            overlay = np.zeros((state.shape[0], state.shape[1], 4), dtype=np.float)\n            overlay[outc - state != 0] = [1, 0.2, 0.2, 1]\n            sub.imshow(outc.astype(np.float))\n            sub.imshow(overlay, vmin=0.0, vmax=1.0)\n\n        anim = animation.FuncAnimation(fig, animate, frames=total_runs, interval=50)\n        plt.clf()\n        return predictions, anim\n\n    \ndevice = torch.device('cuda')\nbestGuess = BestGuessModule()\nbestGuess.load_state_dict(torch.load('..\/input\/gol-pretrained-model\/epoch_040.pt'))\nbestGuess.to(device)\nbestGuess.eval()\n","862731a8":"# feel free to enter your own end state here\nend_state = np.array([\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]])\n\n# this may take a while to calculate with the animation...\npred_start_state, anim = bestGuess.solve(end_state, device)\nHTML(anim.to_jshtml())","1fcbb3d4":"def binary_clamp(x: torch.tensor):\n    return torch.clamp(x, 0, 1)\n\n\ndef conway_layer(x: torch.tensor):\n    surround_sum = torch.roll(x, 1, 2) + torch.roll(x, -1, 2) + torch.roll(x, 1, 3) + torch.roll(x, -1, 3) +\\\n        torch.roll(x, (-1, -1), (2, 3)) + torch.roll(x, (1, -1), (2, 3)) + torch.roll(x, (-1, 1), (2, 3)) + torch.roll(x, (1, 1), (2, 3))\n    return binary_clamp(surround_sum + x - 2) - binary_clamp(surround_sum - 3)\n\n\nclass TilePad2d(nn.Module):\n    def __init__(self, left, right, top, bottom):\n        super().__init__()\n        self.left = left\n        self.right = right\n        self.top = top\n        self.bottom = bottom\n\n    def forward(self, x):\n        return F.pad(x, [self.left, self.right, self.top, self.bottom], mode='circular')\n\n\nclass BestChangeLayer(nn.Module):\n    def __init__(self, delta=1, window=(3, 3), device=torch.device('cpu')):\n        super().__init__()\n        self.device = device\n        self.window = window\n        self.influence_window = (window[0] + 4 * delta, window[1] + 4 * delta)\n        self.delta = delta\n        self.num_bins = window[0] * window[1]\n        self.num_possible_window_inputs = 2 ** self.num_bins\n        self.possible_inputs = np.zeros((self.num_possible_window_inputs, self.num_bins))\n\n        # compute all possible\n        for i in range(self.num_possible_window_inputs):\n            self.possible_inputs[i] = np.array(list(np.binary_repr(i, self.num_bins)), dtype=np.float)\n        self.possible_inputs = self.possible_inputs.reshape((1, self.num_possible_window_inputs, window[0], window[1]))\n\n        self.possible_inputs_mask = np.zeros((1, self.num_possible_window_inputs, self.influence_window[0], self.influence_window[1]), dtype=np.float)\n        self.possible_inputs_mask[:, :, 2*delta:-2*delta, 2*delta:-2*delta] = 1\n        self.possible_inputs_window = np.zeros((1, self.num_possible_window_inputs, self.influence_window[0], self.influence_window[1]), dtype=np.float)\n        self.possible_inputs_window[:, :, 2 * delta:-2 * delta, 2 * delta:-2 * delta] = self.possible_inputs\n\n        self.pi = torch.from_numpy(self.possible_inputs).float().to(device)\n        self.pi_window = torch.from_numpy(self.possible_inputs_window).float().to(device)\n        self.pi_window_mask = torch.from_numpy(self.possible_inputs_mask).float().to(device)\n        self.pi_window_inv_mask = -self.pi_window_mask + 1\n\n        self.replication_input_layer = TilePad2d(\n            delta * 2,\n            delta * 2 + window[1] - 1,\n            delta * 2,\n            delta * 2 + window[0] - 1)\n\n        self.replication_target_layer = TilePad2d(\n            delta,\n            delta + window[1] - 1,\n            delta,\n            delta + window[0] - 1)\n\n        self.unpool = nn.MaxUnpool1d(self.num_possible_window_inputs)\n\n    def forward(self, x: torch.Tensor, target: torch.Tensor):\n\n        random_x = np.random.randint(0, x.size()[3])\n        random_y = np.random.randint(0, x.size()[2])\n\n        influence_window = self.replication_input_layer(x)[:, :, random_y:(random_y + self.influence_window[0]), random_x:(random_x + self.influence_window[1])]\n        target_window = self.replication_target_layer(target)[:, :, random_y:(random_y + self.window[0] + 2 * self.delta), random_x:(random_x + self.window[1] + 2 * self.delta)]\n        process_window = influence_window.repeat(1, self.num_possible_window_inputs, 1, 1)\n        process_window = process_window * self.pi_window_inv_mask + self.pi_window\n        end = process_window\n        for d in range(self.delta):\n            end = conway_layer(end)[:, :, 1:-1, 1:-1]\n\n        errors = torch.sum(torch.abs(end - target_window.repeat(1, self.num_possible_window_inputs, 1, 1)), (2, 3))\n        seeded_errors = errors + torch.rand(errors.size(), device=self.device) * 0.5\n\n        indices = torch.argmin(seeded_errors, 1)\n        best_mask = self.unpool(torch.ones((seeded_errors.size()[0], 1, 1), device=self.device), indices.reshape(-1, 1, 1)).reshape(-1, self.num_possible_window_inputs, 1, 1)\n        best_inputs = torch.sum(self.pi * best_mask, 1).reshape((-1, 1, self.window[0], self.window[1]))\n\n        out = torch.roll(x, shifts=(-random_y, -random_x), dims=(2, 3))\n        out[:, :, :self.window[0], :self.window[1]] = best_inputs\n        out = torch.roll(out, shifts=(random_y, random_x), dims=(2, 3))\n\n        return out\n\n    def solve(self, initial_state: np.array, target: np.array, device: torch.device, num_steps=1000):\n        self.inputs_batch = torch.from_numpy(initial_state).reshape(1, 1, initial_state.shape[0], initial_state.shape[1]).float().to(device)\n        self.targets_batch = torch.from_numpy(target).reshape(1, 1, target.shape[0], target.shape[1]).float().to(device)\n        \n        fig = plt.figure(figsize=(8, 6))\n        \n        def animate(i):\n            self.inputs_batch = self(self.inputs_batch, self.targets_batch)\n            state = np.clip(np.rint(np.array(self.inputs_batch.tolist())).astype(np.int), 0, 1).reshape(initial_state.shape)\n            \n            # input\n            plt.clf()\n            sub = fig.add_subplot(2, 2, 3)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"target state\")\n            sub.imshow(target.astype(np.float))\n\n            # outcome\n            sub = fig.add_subplot(2, 2, 2)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"optimized pred.\")\n            sub.imshow(state.astype(np.float))\n            sub = fig.add_subplot(2, 2, 4)\n            plt.xticks([])\n            plt.yticks([])\n            sub.set_title(\"forwarded prediction\".format(1))\n            outc = state\n            for d in range(self.delta):\n                outc = state_step(outc)\n            overlay = np.zeros((state.shape[0], state.shape[1], 4), dtype=np.float)\n            overlay[outc - target != 0] = [1, 0.2, 0.2, 1]\n            sub.imshow(outc.astype(np.float))\n            sub.imshow(overlay, vmin=0.0, vmax=1.0)\n            \n        anim = animation.FuncAnimation(fig, animate, frames=num_steps, interval=10)\n        plt.clf()\n        state = np.clip(np.rint(np.array(self.inputs_batch.tolist())).astype(np.int), 0, 1).reshape(initial_state.shape)\n        return state, anim\n    \noptimizer = BestChangeLayer(delta=3, device=device)","c0c28319":"# feel freee to enter your own end state here\nend_state = np.array([\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1]])\ncurrent_prediction = end_state.copy()","057dacdb":"current_prediction, anim = bestGuess.solve(current_prediction, device)\nHTML(anim.to_jshtml())","25169bb0":"current_prediction, anim = bestGuess.solve(current_prediction, device)\nHTML(anim.to_jshtml())","32a72801":"current_prediction, anim = bestGuess.solve(current_prediction, device)\nHTML(anim.to_jshtml())","4485133a":"optimized_start_state, anim = optimizer.solve(current_prediction, end_state, device, 2000)\nHTML(anim.to_jshtml())","020c50f6":"Optimize the prediction with 2000 iterations:","bf746971":"Predict from delta=2 to delta=3:","f66f0589":"Thanks for reading and have a nice day!","628329d4":"Predict from delta=1 to delta=2:","1bdd04f2":"# 3rd Place Solution Part: BestGuess + Optimizer\n\n\nMain architecture:\n![grafik.png](attachment:grafik.png)\n\n\n\nHi all,\n\nthanks for the really interesting competition. I quickly want to share my solution. It is split up into 2 main blocks:\n* **BestGuess**, which is an iterative neural network approach. It predicts the start state for delta=1. Repeating it delta times for delta>1\n* And an **Optimizer**, which picks a random 3x3 reagion in the input, tries every possible combination of the 3x3 grid at once and selects randomly between the ones which produce the lowest score. It is entirely implemented on the GPU.\n\n\nThis approach reached a score of 0.018 before merging. \n","499d5642":"## Optimizer\n\n\nThe optimizer improves the input state by randomly selecting 3 by 3 regions and testinal all possible inputs for this region. It then takes only the solutions which generate the lowest score. If there are multiple solutions with the same score, it will select randomly one of them. This process gets repeated multiple times.\n\nBelow is an example with delta=3 where first BestGuess is applied 3 times and then the optimizer at the end.","2d44d259":"It can be seen how it starts with simple cells and solves the more difficult ones at the end.\nSome things I noticed:\n* It reconstrcuts the glider (middle left) correctly\n* Because it is trained to learn the distribution of given GoL states, it generates more \"game of life looking\" patterns.\n* It starts solving (is most certain) around simple patterns. Before filling empty space. This could be, because in the empty areas the probability that some structure died in the start state is higher than arround a well known pattern. \n\nI also tried training the network to predict delta>1 directy but it seemed to require a huge ammount of time and way more parameters. This model has alread 12 mio. parameters, which was enough for my gtx 980 ti.\n\nSadly, the error increases a lot when repeating the guessing algorithm for delta>1. While at delta=1 its average loss is about 0.002. With delta=2 it increased ten times to 0.017. For delta=3 already 0.11.","04ffc881":"Predict delta=1:","668636b0":"## 1 delta BestGuess\nArchitecture:\n![grafik.png](attachment:grafik.png)\n\nThe network only predicts one cell at a time, because there are many possible start states which lead to the same end state. By giving the network its previous prediction, it is enough to just estimate which cells are more likely to be alive or dead. While at the beginning the prediction might be very uncertain, by adding more and more predicted cells, the possible start state combinations narrow down and the network gets more certain.\n\nTraining is done supervised by just marking random cells in an end state as unpredicted and setting the start state as target.\n\nHere is a visualization of the solving process:"}}