{"cell_type":{"efc4a03f":"code","8a1e7fec":"code","13777275":"code","533b2f1d":"code","00cbce1e":"code","15e77da6":"code","d5560b9f":"code","2199c28c":"code","a202b947":"code","fb4e7532":"code","cfbc1489":"code","edd85ffd":"code","6540db4a":"code","db594a95":"code","0d7420a3":"code","8ecfdc7d":"code","fafa36f0":"code","adeb23f0":"code","e5bfe136":"code","dc236ca8":"code","dd1567c5":"code","a846bb14":"code","3ebcfab8":"code","89d44bba":"code","822a43fd":"code","b57af86c":"code","4de5f486":"code","53660b41":"code","9cd1ab86":"code","27d3c75b":"code","47f2971f":"code","94aa6b75":"code","e6a5611b":"code","5fb34e9a":"code","1aa25a30":"code","0cbc6582":"code","3f5bf031":"code","dc31f359":"markdown","21af20af":"markdown","a71ae63f":"markdown","79c96253":"markdown","39be1d0e":"markdown","be13f79c":"markdown","e1812c09":"markdown","82fa11ef":"markdown","5008a14d":"markdown","b0afba62":"markdown","8a679eac":"markdown","cf2adac4":"markdown","73600c0c":"markdown","19087e0f":"markdown","03166021":"markdown","c0baf871":"markdown","4e399366":"markdown","34ea5ba9":"markdown","74a33332":"markdown","e999f2b2":"markdown","cd2b51f2":"markdown","28bb1e95":"markdown","4b7d858f":"markdown","0a0a7175":"markdown","04624936":"markdown","31225cf9":"markdown","56c4f186":"markdown","54779f91":"markdown","c194ef05":"markdown","e7acdcbe":"markdown","c23c1702":"markdown","24892317":"markdown","72657b8f":"markdown","4fa1f729":"markdown","3551afe1":"markdown","ff0dd353":"markdown","4f66264d":"markdown","61a59863":"markdown","1de97392":"markdown"},"source":{"efc4a03f":"# Download YOLOv5\n!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n%cd yolov5\n\n# Install dependencies\n%pip install -qr requirements.txt  \n\n# change directory\n%cd ..\/\nimport torch\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","8a1e7fec":"# Install W&B \n!pip install -q --upgrade wandb\n\n# Login \nimport wandb\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient() \n\npersonal_key_for_api = user_secrets.get_secret(\"wandb-key\")\n\n! wandb login $personal_key_for_api\n","13777275":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport cv2\n\nfrom tqdm import tqdm\nimport shutil\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n\nfrom IPython.core.magic import register_line_cell_magic\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom glob import glob\nimport yaml\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","533b2f1d":"TRAIN_PATH = '\/kaggle\/input\/siim-covid19-resized-384512-and-640px\/SIIM-COVID19-Resized\/img_sz_512\/train\/'\nIMG_SIZE = 512\nBATCH_SIZE = 16\nEPOCHS = 10","00cbce1e":"# Load image level csv file\ndf = pd.read_csv('..\/input\/siimcovid19-detection-training-label\/train_image_df.csv')\n# Add absolute path\ndf['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)\ndf.head(3)","15e77da6":"# remove negative class=2\ndf = df[df.integer_label!=2].reset_index(drop = True)","d5560b9f":"df[\"integer_label\"][df.integer_label==3]=2","2199c28c":"class_ids, class_names = list(zip(*set(zip(df.integer_label, df.y_label))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","a202b947":"# Create train and validation split.\ntrain_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df.integer_label.values)\n\ntrain_df.loc[:, 'split'] = 'train'\nvalid_df.loc[:, 'split'] = 'valid'\n\ndf = pd.concat([train_df, valid_df]).reset_index(drop=True)","fb4e7532":"print(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')","cfbc1489":"os.makedirs('covid19\/images\/train', exist_ok=True)\nos.makedirs('covid19\/images\/valid', exist_ok=True)\nos.makedirs('covid19\/labels\/train', exist_ok=True)\nos.makedirs('covid19\/labels\/valid', exist_ok=True)","edd85ffd":"# Move the images to relevant split folder.\nfor i in tqdm(range(len(df))):\n    row = df.loc[i]\n    if row.split == 'train':\n        copyfile(row.path, f'covid19\/images\/train\/{row.id}.jpg')\n    else:\n        copyfile(row.path, f'covid19\/images\/valid\/{row.id}.jpg')","6540db4a":"with open('\/kaggle\/working\/covid19\/train.txt', 'w') as f:\n    for path in glob('\/kaggle\/working\/covid19\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open('\/kaggle\/working\/covid19\/val.txt', 'w') as f:\n    for path in glob('\/kaggle\/working\/covid19\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train = '\/kaggle\/working\/covid19\/images\/train',\n    val = '\/kaggle\/working\/covid19\/images\/valid',\n    \n    nc    = 3, # number of classes\n    names = classes # classes\n    )\n\nwith open('\/kaggle\/working\/yolov5\/data\/data.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open('\/kaggle\/working\/yolov5\/data\/data.yaml', 'r')\nprint('\\nyaml:')\nprint(f.read())","db594a95":"!ls '\/kaggle\/working\/yolov5\/data'","0d7420a3":"# Get the raw bounding box by parsing the row value of the label column.\ndef get_bbox(row):\n    bboxes = []\n    bbox = []\n    b1=row.x_min\n    b2=row.y_min\n    b3=row.x_max \n    b4=row.y_max \n    bbox.append(float(b1))\n    bbox.append(float(b2))\n    bbox.append(float(b3))\n    bbox.append(float(b4))\n\n    bboxes.append(bbox)\n    \n            \n    return bboxes\n\n# Scale the bounding boxes according to the size of the resized image. \ndef scale_bbox(row, bboxes):\n    # Get scaling factor\n    scale_x = IMG_SIZE\/row.width\n    scale_y = IMG_SIZE\/row.height\n    \n    scaled_bboxes = []\n    for bbox in bboxes:\n        x = float(bbox[0]*scale_x)\n        y = float(bbox[1]*scale_y)\n        x1 = float(bbox[2]*(scale_x))\n        y1= float(bbox[3]*scale_y)\n\n        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n        \n    return scaled_bboxes\n\n# Convert the bounding boxes in YOLO format.\ndef get_yolo_format_bbox(img_w, img_h, bboxes):\n    yolo_boxes = []\n    for bbox in bboxes:\n        w = bbox[2] - bbox[0] # xmax - xmin\n        h = bbox[3] - bbox[1] # ymax - ymin\n        xc = bbox[0] + float(w\/2) # xmin + width\/2\n        yc = bbox[1] + float(h\/2) # ymin + height\/2\n        \n        yolo_boxes.append([xc\/img_w, yc\/img_h, w\/img_w, h\/img_h]) # x_center y_center width height\n    \n    return yolo_boxes","8ecfdc7d":"dfu=df\ndfuu=dfu.drop_duplicates(subset=['id'])","fafa36f0":"for i in tqdm(dfuu.index):\n    row = df.loc[i]\n    # Get image id\n    img_id = row.id\n    # Get split\n    split = row.split\n    # Get image-level label\n    label = row.integer_label   \n    if row.split=='train':\n        file_name = f'covid19\/labels\/train\/{row.id}.txt'\n    else:\n        file_name = f'covid19\/labels\/valid\/{row.id}.txt'\n   # print(row)\n    #len(df[df.id==row.id])\n    ln=df[df.id==row.id].shape[0]\n    with open(file_name, 'w') as f:\n        for j in range(ln):\n            row1 = df.loc[j]\n            bboxes = get_bbox(row1)\n            # Scale bounding boxes\n            scale_bboxes = scale_bbox(row1, bboxes)\n            # Format for YOLOv5\n            yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n            for bbox in yolo_bboxes:\n                bbox = [label]+bbox\n                bbox = [str(i) for i in bbox]\n                bbox = ' '.join(bbox)\n                f.write(bbox)\n                f.write('\\n')","adeb23f0":"!ls covid19\/labels\/valid","e5bfe136":"import os\nlist = os.listdir(\".\/covid19\/labels\/train\/\") # dir is your directory path\nnumber_files = len(list)\nprint(number_files)","dc236ca8":"%cat covid19\/labels\/train\/ffd9b6cf2961.txt","dd1567c5":"%cd yolov5\/","a846bb14":"#!WANDB_MODE=\"dryrun\" \n!python train.py --img {IMG_SIZE} \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5m.pt \\\n                 --project kaggle-siim-covid19 \\\n                 --cache","3ebcfab8":"%cd \"..\/\"\npath = \"covid19\"\nshutil.rmtree(path)","89d44bba":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('.\/yolov5\/kaggle-siim-covid19\/exp\/labels.jpg'));","822a43fd":"import matplotlib.pyplot as plt\nplt.figure(figsize = (14, 14))\nplt.imshow(plt.imread('.\/yolov5\/kaggle-siim-covid19\/exp\/train_batch0.jpg'))\n","b57af86c":"!ls '\/kaggle\/working\/yolov5\/kaggle-siim-covid19\/exp'","4de5f486":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('\/kaggle\/working\/yolov5\/kaggle-siim-covid19\/exp\/P_curve.png'));","53660b41":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('\/kaggle\/working\/yolov5\/kaggle-siim-covid19\/exp\/PR_curve.png'));","9cd1ab86":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('\/kaggle\/working\/yolov5\/kaggle-siim-covid19\/exp\/F1_curve.png'));","27d3c75b":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('\/kaggle\/working\/yolov5\/kaggle-siim-covid19\/exp\/R_curve.png'));","47f2971f":"ig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'.\/yolov5\/kaggle-siim-covid19\/exp\/val_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'.\/yolov5\/kaggle-siim-covid19\/exp\/val_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'.\/yolov5\/kaggle-siim-covid19\/exp\/val_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'.\/yolov5\/kaggle-siim-covid19\/exp\/val_batch{row}_pred.jpg', fontsize = 12)","94aa6b75":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('.\/yolov5\/kaggle-siim-covid19\/exp\/results.png'));","e6a5611b":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('.\/yolov5\/kaggle-siim-covid19\/exp\/confusion_matrix.png'));","5fb34e9a":"TEST_PATH = '\/kaggle\/input\/siim-covid19-resized-384512-and-640px\/SIIM-COVID19-Resized\/img_sz_512\/test\/' \nweights_dir = 'kaggle-siim-covid19\/exp\/weights\/best.pt'","1aa25a30":"%cd 'yolov5'\n","0cbc6582":"!python detect.py --weights {weights_dir} \\\n                  --source {TEST_PATH} \\\n                  --img {IMG_SIZE} \\\n                  --conf 0.28 \\\n                  --iou-thres 0.5 \\\n                  --max-det 3 \\\n                  --save-txt \\\n                  --save-conf \\\n                  --exist-ok","3f5bf031":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs\/detect\/exp\/*')\nfor _ in range(3):\n    row = 4\n    col = 3\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img= cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()\n","dc31f359":"# P Curve","21af20af":"All training results are saved to runs\/train\/ with incrementing run directories, i.e. runs\/train\/exp2, runs\/train\/exp3 etc. ","a71ae63f":"# \ud83d\udcda YOLOv5\nYOLO, \"You Only Look Once\", has a long and succesful history with real time object detection.","79c96253":"# \ud83c\udf5c Create `Data.YAML` file\n\nThe `data.yaml`, is the dataset configuration file that defines:\n\n1. the dataset root directory and relative paths to train\/val\/test image directories (or paths to *.txt files with image paths).\n1. the number of classes.\n1. a list of class names.\n\n> \ud83d\udccd Note: The `data.yaml` is created in the `yolov5\/data` directory as required. ","39be1d0e":"# \ud83c\udf5a Splitting Dataset","be13f79c":"# References","e1812c09":"### Other notebooks in the competition\n- [SIIM COVID-19 Detectron2 Training](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-covid-19-detectron2-training)\n- [SIIM COVID-19 Detectron2 Inferance](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-covid-19-detectron2-inferance)\n- [SIIM-FISABIO-RSNA COVID-19 Detection-EDA](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-fisabio-rsna-covid-19-detection-eda)","82fa11ef":"### Hi kagglers, This is `Training` notebook using `YOLOv5`.\n\n> \n>  [COVID-19 Detection YOLOv5 3Classes [Inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/covid-19-detection-yolov5-3classes-inference)\n\n\n\n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","5008a14d":"### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","b0afba62":"#  \u2b07\ufe0f Download YOLOv5\nClone this repo and install requirements.txt dependencies, including Python>=3.8 and PyTorch>=1.7.","8a679eac":"# Removing Files","cf2adac4":"# \ud83d\udd28 Weights & Biases\n\n* Weights & Biases is a set of tools that tracks machine learning experiments, visualizes metrics, and shares results.\n* Weights & Biases is directly integrated into YOLOv5, providing experiment metric tracking, model and dataset versioning, rich model prediction visualization, and more.\n","73600c0c":"# PR Curve","19087e0f":"## Batch Image","03166021":"# \u2600\ufe0f Importing Libraries","c0baf871":"![91506361-c7965000-e886-11ea-8291-c72b98c25eec.jpg](attachment:812ff98c-03ef-48f5-b171-0c8b3b0fab54.jpg)","4e399366":"## GT Vs Pred","34ea5ba9":"# \ud83c\udf6e Loading Data\nI prepared **train_image_df.csv** from [this notebook](https:\/\/www.kaggle.com\/ammarnassanalhajali\/siim-fisabio-rsna-covid-19-detection-eda)","74a33332":"![model_comparison.png](attachment:6f64ed0a-fd0e-43de-9d26-77412d6e87cc.png)","e999f2b2":"![10.png](attachment:caf5c201-af01-4c90-b306-3e6e43787992.png)","cd2b51f2":"# \ud83d\uddbc\ufe0f Visualizing and Results\n\n* Weights & Biases (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration among team members.\n\n* During training you will see live updates at https:\/\/wandb.ai, and you can create Detailed Reports of your results using the W&B Reports tool.\n* To see my project on Weights & Biases (W&B) [here](https:\/\/wandb.ai\/ammaralhajali\/kaggle-siim-covid19)","28bb1e95":"![Capture.JPG](attachment:70925ee3-c3a5-4056-974f-8bb702338d84.JPG)","4b7d858f":"# Select a Model\nSelect a pretrained model to start training from. \n* Here we select YOLOv5s, the smallest and fastest model available.\n* I will try YOLO5m","0a0a7175":"## (Loss, Map) Vs Epoch\n","04624936":"![download.jpg](attachment:07de9c65-7c16-40e7-a821-d5354296394c.jpg)","31225cf9":"## Class Distribution","56c4f186":"# \ud83c\udf58 Hyperparameters","54779f91":"1. https:\/\/github.com\/ultralytics\/yolov5\/wiki\/Train-Custom-Data\n1. https:\/\/ultralytics.com\/yolov5\n1. https:\/\/docs.wandb.ai\/\n1. https:\/\/www.kaggle.com\/ayuraj\/train-covid-19-detection-using-yolov5\n1. https:\/\/www.kaggle.com\/awsaf49\/vinbigdata-cxr-ad-yolov5-14-class-train","c194ef05":"# \ud83d\ude85 Train with W&B","e7acdcbe":"# Inference Plot","c23c1702":"## Confusion Matrix","24892317":"# F1 Curve","72657b8f":"The label file corresponding to the above image contains 2 persons (class 0) and a tie (class 27):","4fa1f729":"# R Curve","3551afe1":"## \ud83c\udf5a Organize Directories\n\nI organized train and val images and labels according to the example below.\n\n```\n\/Kaggle\/working\n    \/Covid19\n         \/images\n             \/train\/img0.jpg\n             \/val\n         \/labels\n             \/train\/img0.txt\n             \/val\n    \/yolov5\n```","ff0dd353":"# Only 3 Classes","4f66264d":"# \ud83d\ude80 COVID-19 Detection YOLOv5 3Classes [Training] ","61a59863":"# Inference","1de97392":"## \ud83c\udf6e Create Labels for YOLOv5\n\nTo label your images,a `.txt` file with the same name of the image,will be created (if no objects in image, no *.txt file is required)\nThe *.txt file specifications are:\n\n* One row per object\n* Each row is class x_center y_center width height format.\n* Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n* Class numbers are zero-indexed (start from 0).\n\n> \ud83d\udccd Note: We don't have to remove the images without bounding boxes from the training or validation sets. "}}