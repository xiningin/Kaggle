{"cell_type":{"7be2fdce":"code","6a5c59e0":"code","fa9f0dee":"code","c81a67f3":"code","7240e9d4":"code","eac53b98":"code","a8147202":"code","b025360b":"code","b8853625":"code","9309a8f2":"code","158ba999":"code","ed74cfcb":"code","695cf524":"code","1ee6d343":"markdown","808dcf67":"markdown","ca7becb1":"markdown","a8e5f976":"markdown","1a66e77a":"markdown","ffd0d369":"markdown","0236ea7d":"markdown","8a85ea70":"markdown","a17a09fc":"markdown","6b682f85":"markdown"},"source":{"7be2fdce":"# Importing packages\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6a5c59e0":"# Reading the data\n\ndata = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndata.head(10).style.applymap(lambda x : \"background-color: #fcc7c7\")","fa9f0dee":"def EDA(df):\n    \n    print('\\033[1m' +'EXPLORATORY DATA ANALYSIS :'+ '\\033[0m\\n')\n    print('\\033[1m' + 'Shape of the data (rows, columns):' + '\\033[0m')\n    print(df.shape, \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'All columns from the dataframe :' + '\\033[0m')\n    print(df.columns, \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Datatpes and Missing values:' + '\\033[0m')\n    print(df.info(), \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    for col in df.columns:\n        print('\\033[1m' + 'Unique values in {} :'.format(col) + '\\033[0m',len(data[col].unique()))\n    print('\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Summary statistics for the data :' + '\\033[0m')\n    print(df.describe(include='all'), \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n        \n    print('\\033[1m' + 'Memory used by the data :' + '\\033[0m')\n    print(df.memory_usage(), \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Number of duplicate values :' + '\\033[0m')\n    print(df.duplicated().sum())\n          \nEDA(data)","c81a67f3":"# Correlation matrix\n\ndf1 = data.copy()\n\ncols = df1.columns\n\nplt.figure(figsize = (16, 10), dpi = 100)\n\ncorr = df1.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(corr,\n            mask = mask,\n            cmap = 'Reds',\n            vmax=.3,\n            annot = True,\n            linewidths = 0.5,\n            fmt = \".2f\",\n            alpha = 0.7)\n\nhfont = {'fontname':'monospace'}\nplt.xticks(**hfont)\nplt.yticks(**hfont)\n\nplt.title('Correlation matrix',\n          family = 'monospace',\n          fontsize = 20,\n          weight = 'semibold',\n          color = '#964545')\n\nplt.show()\n","7240e9d4":"data.fbs.value_counts()","eac53b98":"# Dealing with outliers\n\ndef outlier(df):\n        df_ = df.copy()\n        df = df.drop(['sex', 'cp', 'fbs', 'restecg', 'thalach',\n       'exang', 'slope', 'ca', 'thal', 'target'], axis=1)\n\n\n        q1 = df.quantile(0.25)\n        q3 = df.quantile(0.75)\n\n        iqr = q3 - q1\n\n        lower_limit = q1 -(1.5 * iqr) \n        upper_limit = q3 +(1.5 * iqr)\n\n\n        for col in df.columns:\n            for i in range(0,len(df[col])):\n                if df[col][i] < lower_limit[col]:            \n                    df[col][i] = lower_limit[col]\n\n                if df[col][i] > upper_limit[col]:            \n                    df[col][i] = upper_limit[col]    \n\n\n        for col in df.columns:\n            df_[col] = df[col]\n\n        return(df_)\n\ndata = outlier(data)","a8147202":"# Initial splitting\n\nX = data.drop('target', axis =1)\ny = data.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","b025360b":"# Logistic Regression with Hyperparameter tuning\n\nsteps = [('scaler', StandardScaler()),\n         ('log_reg', LogisticRegression())]\n\npipeline = Pipeline(steps)\n\nparameters = dict(log_reg__solver = ['newton-cg', 'lbfgs', 'liblinear'],\n                  log_reg__penalty =  ['l2'],\n                  log_reg__C = [100, 10, 1.0, 0.1, 0.01])\n\n\ncv = GridSearchCV(pipeline,\n                  param_grid = parameters,\n                  cv = 5,\n                  scoring = 'accuracy',\n                  n_jobs = -1,\n                  error_score = 0.0)\n\ncv.fit(X_train, y_train)\ny_pred = cv.predict(X_test)\nlog_accuracy = accuracy_score(y_pred, y_test) * 100\n\nprint('\\033[1m' +'Best parameters : '+ '\\033[0m', cv.best_params_)\nprint('\\033[1m' +'Accuracy : {:.2f}%'.format(log_accuracy) + '\\033[0m')\nprint('\\033[1m' +'Classification report : '+ '\\033[0m\\n', classification_report(y_test, y_pred))\n\ncm = confusion_matrix(y_pred, y_test)\nprint('\\033[1m' +'Confusion Matrix : '+ '\\033[0m')\nplt.figure(dpi=100)\nsns.heatmap(cm, cmap = 'Reds',annot = True, fmt='d')\nplt.show()","b8853625":"# Storing accuracies\n\nacc     = {'split' : [], 'random_state' : [], 'accuracy' : []}\nsplits  = np.arange(0.1,0.4, 0.01)\nrandom = range(0,100)\n\n# Trying out combinations\n\nfor i in splits:\n    for j in random:\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = i, random_state = j)\n        \n        sc = StandardScaler()\n        X_train = sc.fit_transform(X_train)\n        \n        model = LogisticRegression(C       = 0.01,\n                                   penalty ='l2',\n                                   solver  = 'liblinear')\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        accuracy = accuracy_score(y_pred, y_test)\n        \n        acc['split'].append(i)\n        acc['random_state'].append(j)\n        acc['accuracy'].append(accuracy)","9309a8f2":"acc = pd.DataFrame(acc)\nacc.sample(5).style.applymap(lambda x : \"background-color: #fcc7c7\")","158ba999":"fig = go.Figure(data=[go.Mesh3d(x=acc.split,\n                   y=acc.random_state,\n                   z=acc.accuracy,\n                   opacity=0.6,)])\n\n\n\nfig.update_layout(scene = dict(\n                    xaxis = dict(title = 'Split',\n                         backgroundcolor=\"rgb(200, 200, 230)\",\n                         gridcolor=\"#fcc7c7\",\n                         showbackground=True,\n                         zerolinecolor=\"white\",),\n                    yaxis = dict(title = 'Random State',\n                        backgroundcolor=\"rgb(200, 200, 230)\",\n                        gridcolor=\"#fcc7c7\",\n                        showbackground=True,\n                        zerolinecolor=\"white\"),\n                    zaxis = dict(title = 'Accuracy',\n                        backgroundcolor=\"rgb(200, 200, 230)\",\n                        gridcolor=\"#fcc7c7\",\n                        showbackground=True,\n                        zerolinecolor=\"white\",),),\n                    width=800, height = 600,\n\n                    title = dict(text = 'Accuracies from combinations<br>of seed and split.',\n                               x = 0.5,\n                               font = dict(size = 16, color ='#27302a',\n                               family = 'monospace')),\n                    plot_bgcolor='#fcc7c7',\n                    paper_bgcolor = '#fcc7c7'\n                  )\nfig.show()","ed74cfcb":"best = acc[acc.accuracy == acc.accuracy.max()]\n\nprint('\\033[1m' +'Split and random_state achieving the higest accuracy :- '+ '\\033[0m')\nprint('\\033[1m' +'    Split : '+ '\\033[0m', best.split.iloc[0])\nprint('\\033[1m' +'    random_state : '+ '\\033[0m', best.random_state.iloc[0])","695cf524":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x = ['Mean Accuracy', 'Max Accuracy'],\n                            y = [acc.accuracy.mean(), acc.accuracy.max()],\n                            mode = 'lines+markers'))\n\nfig.update_xaxes(\n        tickfont = dict(size=15),\n        tickmode = 'array',\n        showline = False,\n        showgrid = False,\n        ticks = 'outside')\n\nfig.update_yaxes(\n        tickfont = dict(size=15),\n        tickmode = 'array',\n        showline = False,\n        showgrid = True,\n        ticks = 'outside')\n\nfig.update_layout(width=850,\n                  title = dict(text = 'Accuracies',\n                               x = 0.5,\n                               font = dict(size = 16, color ='#27302a',\n                               family = 'monospace')),\n                  plot_bgcolor='#fcc7c7',\n                  paper_bgcolor = '#fcc7c7',\n                  showlegend = False)\n\n\nfig.show()","1ee6d343":"<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/RZZvkpGy\/6.png\">\n<\/div>","808dcf67":"# Pre-processing\n\n<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/KzkHymh4\/3-5.gif\">\n<\/div>","ca7becb1":"<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/qRfwfyJ6\/2.png\">\n<\/div>","a8e5f976":"# Preparing Model","1a66e77a":"# About the Data\n \n\n| Column      | Description |\n| ----------- | ----------- |\n| age |age in years|\n| sex |(1 = male; 0 = female)|\n| cp | chest pain type |\n| trestbps | resting blood pressure (in mm Hg on admission to the hospital) |\n| chol | serum cholestoral in mg\/dl |\n| fbs | (fasting blood sugar &gt; 120 mg\/dl) (1 = true; 0 = false) |\n| restecg | resting electrocardiographic results |\n| thalach | maximum heart rate achieved |\n| exang | exercise induced angina (1 = yes; 0 = no) |\n| oldpeak | ST depression induced by exercise relative to rest |\n| slope | the slope of the peak exercise ST segment |\n| ca | number of major vessels (0-3) colored by flourosopy |\n| thal | 3 = normal; 6 = fixed defect; 7 = reversable defect |\n| target | 1 or 0 |","ffd0d369":"<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/VkcN2NMZ\/5.png\">\n<\/div>","0236ea7d":"<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/sfkT7PPQ\/fooled-by-the-accuracy.gif\">\n<\/div>","8a85ea70":"# EDA\n\n<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/HWbYCg2r\/3.gif\">\n<\/div>","a17a09fc":"# So, what ?\n\n<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/VvsnP2gS\/7.png\">\n<\/div>\n\n<br>\n\nhttps:\/\/towardsdatascience.com\/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226","6b682f85":"<div align=\"center\">\n  <img width=\"900\"  src=\"https:\/\/i.postimg.cc\/FH6zHxJz\/4.png\">\n<\/div>"}}