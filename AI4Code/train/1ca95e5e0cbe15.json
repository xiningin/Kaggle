{"cell_type":{"8da54be0":"code","18c80595":"code","d8e715b0":"code","383224cd":"code","8e7a7552":"code","6bb0c767":"code","9ee1dea7":"code","c64e1c94":"code","9ce1293d":"code","a9136049":"code","66a2c913":"markdown","60d4ba4b":"markdown","2b168898":"markdown","940f1d4f":"markdown","3f0ec948":"markdown","938f914c":"markdown","2822a778":"markdown"},"source":{"8da54be0":"import tensorflow as tf\nfrom tensorflow.python import keras\n\nprint('Tensorflow Version: ', tf.__version__)\nprint('Keras Version: ', keras.__version__)","18c80595":"import os\nimport numpy as np\nimport keras\nfrom keras import models\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\n\npneumoniaNetModel=models.Sequential()\n\npneumoniaNetModel.add(layers.SeparableConv2D(32, 3, activation='relu', input_shape=(150,150,3)))\npneumoniaNetModel.add(layers.SeparableConv2D(64, 3, activation='relu'))\npneumoniaNetModel.add(layers.MaxPooling2D(2))\n\npneumoniaNetModel.add(layers.SeparableConv2D(64, 3, activation='relu'))\npneumoniaNetModel.add(layers.SeparableConv2D(128, 3, activation='relu'))\npneumoniaNetModel.add(layers.MaxPooling2D(2))\n\npneumoniaNetModel.add(layers.SeparableConv2D(64, 3, activation='relu'))\npneumoniaNetModel.add(layers.SeparableConv2D(128, 3, activation='relu'))\npneumoniaNetModel.add(layers.GlobalAveragePooling2D())\n\npneumoniaNetModel.add(layers.Dense(32, activation='relu'))\npneumoniaNetModel.add(layers.Dense(2, activation='softmax'))\n\npneumoniaNetModel.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['categorical_accuracy'])\npneumoniaNetModel.summary()\n\nfilepath=\"PneumoniaNet8.h5\"\ncheckpoint = ModelCheckpoint(filepath, save_best_only=True)\ncallbacks_list = [checkpoint]","d8e715b0":"image_height = 150\nimage_width = 150\nbatch_size = 8\nno_of_epochs  = 60\nnumber_of_training_samples=5216\nnumber_of_validation_samples=16\nnumber_of_test_samples=624","383224cd":"train_dir='\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train'\nvalidation_dir='\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val'\ntest_dir='\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test'","8e7a7552":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2\n                                   )\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)  \n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","6bb0c767":"training_set = train_datagen.flow_from_directory(train_dir,target_size=(image_width, image_height),batch_size=batch_size)\nvalidation_set = validation_datagen.flow_from_directory(validation_dir,target_size=(image_width, image_height),batch_size=batch_size,shuffle=False)\ntest_set = test_datagen.flow_from_directory(test_dir,target_size=(image_width, image_height),batch_size=batch_size,shuffle=False)","9ee1dea7":"import math\n\nhistory = pneumoniaNetModel.fit_generator(\n      training_set,\n      steps_per_epoch=math.ceil(number_of_training_samples\/\/batch_size),\n      epochs=no_of_epochs,\n      callbacks=callbacks_list,\n      validation_data=validation_set,\n      validation_steps=math.ceil(number_of_validation_samples\/\/batch_size))","c64e1c94":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nacc=history.history['categorical_accuracy']\nval_acc=history.history['val_categorical_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\nepochs=range(1,len(acc)+1)\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","9ce1293d":"from tensorflow.python.keras.models import load_model\n\nbest_model = load_model('PneumoniaNet8.h5')","a9136049":"steps_test=int(number_of_test_samples\/batch_size)\nresult = best_model.evaluate_generator(test_set, steps=steps_test,verbose=1)\nprint(\"Test-set classification accuracy: {0:.2%}\".format(result[1]))","66a2c913":"## Setting up the Model","60d4ba4b":"## Loading the Best Model","2b168898":"## Model Training","940f1d4f":"## Evaluating the Best Model","3f0ec948":"# Automated Chest X-ray based Pneumonia Diagnosis using PneumoniaNet","938f914c":"## Visualizing the Training Process","2822a778":"## Setting up Training and Validation Data for the experiment"}}