{"cell_type":{"979b984f":"code","614b44c3":"code","86bbda73":"code","b42a16fc":"code","65b70232":"code","2fea7998":"code","dd2590b6":"code","5e94b4b0":"code","ed73cebf":"code","6682aaee":"code","5eec7bdf":"code","df75d3eb":"code","4abb7da1":"code","95adf74f":"code","c7cef638":"code","3a55bc31":"code","ee619a25":"code","0e12df98":"code","130d2021":"code","f4d13230":"code","834570ca":"code","b4990a4c":"code","d355f2fd":"code","52b82d87":"code","b9e312b2":"code","919ba134":"code","fedfecca":"code","8dfc776b":"code","c71e0687":"code","4a45e830":"code","5777c682":"code","dfbb60c1":"code","c326cdeb":"code","18c402ce":"code","0ad366fd":"code","3a689e7c":"code","449bf555":"code","9189391e":"code","9f816e13":"code","be81d61e":"code","7d1e5d77":"code","05f5280b":"code","88f16338":"code","e70a450a":"code","235d817c":"code","5e02944d":"code","ae954fa3":"code","b78d63d4":"code","13d471b9":"code","2b216f8f":"code","02468d6f":"code","d630ba92":"code","e019f112":"code","1967157d":"code","46cd88f8":"code","db964f5b":"code","7e0d149c":"code","6d3a734f":"code","9a666038":"code","44d73130":"code","3cc8fb05":"code","fe747d86":"code","38a54ec3":"code","3a35837e":"code","1ad4cc87":"code","310fed2e":"code","7bbdf4b8":"code","61941dbe":"code","9690c30d":"code","27e8f152":"code","afc9196c":"code","f7d5b53e":"code","b3716141":"code","f85f53ef":"code","b61db188":"code","05ba630e":"code","078f1332":"code","1c7af966":"code","8515859c":"code","5daffe27":"code","5e95f698":"code","6d94c6c8":"code","daedca79":"code","311a93a4":"code","e3c8f3df":"code","7656cb7e":"code","561b3673":"code","1e949570":"code","13ef8ca2":"code","a3e07c23":"code","f64a4de8":"code","ec833296":"code","3ddbf4f3":"code","e30f1830":"code","1e66e605":"code","b65990ff":"code","20723418":"code","aa7c7220":"code","69935db2":"code","c68e616a":"code","8abc9450":"code","f5847c6d":"code","bbe447d6":"code","c9d92958":"code","a1a0504c":"code","3a45c6be":"code","c44fbf24":"code","4212f746":"code","72451da4":"code","d0c7d542":"code","29d71cb9":"code","c12ba6cc":"markdown","3e8fe784":"markdown","d90e920c":"markdown","312c2eca":"markdown","0f68be82":"markdown","5b4fc122":"markdown","1d2bfe66":"markdown","f3d25147":"markdown","fe59ab55":"markdown","8d4d7d7b":"markdown","f4ee4924":"markdown","2e3bead8":"markdown","b697be51":"markdown","0edd1b4d":"markdown","cd169c3a":"markdown","a265c13a":"markdown","e83c808c":"markdown","d157e5aa":"markdown","45a8b8f7":"markdown","2e06def9":"markdown","e04fdc4f":"markdown","57076881":"markdown","268e8ec9":"markdown","e9725aa5":"markdown","bb5391b9":"markdown","4448a494":"markdown","40078f08":"markdown","7c3caab3":"markdown","b1d48245":"markdown","a3b495d5":"markdown","4141ea9b":"markdown","c8e1359e":"markdown","0d826f22":"markdown","a65e0cd5":"markdown","e020d6b7":"markdown","444dced6":"markdown","b347fe9d":"markdown","df7e33d4":"markdown","68544592":"markdown","30e83979":"markdown","faaa9f1c":"markdown","613a4799":"markdown","2b56a43b":"markdown","6f7c1a62":"markdown","b2aebe45":"markdown","e6dd13a0":"markdown","592fb06b":"markdown","eae6ed8f":"markdown","9aeb744b":"markdown","e767b3ab":"markdown","2ccd314c":"markdown","80891b0b":"markdown","dbd882fe":"markdown","0a2e45df":"markdown","a87a7895":"markdown","794ab8b9":"markdown","deda4bc0":"markdown","87754883":"markdown","372462c5":"markdown","e4fdf0af":"markdown","4caa1ddf":"markdown","d7bf23d4":"markdown","45104830":"markdown","2398b0f8":"markdown","7adbd2fe":"markdown","254ee836":"markdown","6f8519c6":"markdown","578a3c19":"markdown","320fd867":"markdown","020c488e":"markdown","e3648194":"markdown","448e26af":"markdown","21cee0a2":"markdown","ff3b81b6":"markdown","210c3ff2":"markdown","8f9b7c9a":"markdown","31df7b5c":"markdown","475ffd97":"markdown"},"source":{"979b984f":"## Import required libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport plotly.offline as pyo\nimport plotly.graph_objects as go\nimport plotly.express as px\npyo.init_notebook_mode()\n\n%matplotlib inline\nsns.set()\ntitleid=0","614b44c3":"# #@title Enter dataset file path in drive\n# #@markdown Enter the full data path (e.g: \/content\/drive\/My Drive\/DS 200\/)\n\n# mount_point = '.\/'  #@param {type: \"string\"}\n# data_dir_path = '.\/'  #@param {type: \"string\"}\n# is_zip_file = True  #@param {type: \"boolean\"}\n# file_name = 'data-science-for-good-kiva-crowdfunding.zip'  #@param {type: \"string\"}\n# #@markdown ---\n","86bbda73":"# # load data provided by Kiva\n# dir_path = 'data-science-for-good-kiva-crowdfunding\/' # local path\n# if use_colab:\n#     from google.colab import drive\n#     drive.mount(mount_point)","b42a16fc":"# if is_zip_file:\n#   import zipfile\n#   zip_ref = zipfile.ZipFile(f'{data_dir_path}\/{file_name}', 'r')\n#   zip_ref.extractall(dir_path)\n#   zip_ref.close()","65b70232":"dir_path = '..\/input\/data-science-for-good-kiva-crowdfunding\/'","2fea7998":"loans = pd.read_csv(dir_path + 'kiva_loans.csv')\nmpi_region_location = pd.read_csv(dir_path + 'kiva_mpi_region_locations.csv')\ntheme_ids = pd.read_csv(dir_path + 'loan_theme_ids.csv')\nthemes_by_region = pd.read_csv(dir_path + 'loan_themes_by_region.csv')","dd2590b6":"loans.head(3)","5e94b4b0":"loans.shape","ed73cebf":"loans.describe()","6682aaee":"loans.columns","5eec7bdf":"plt.figure(figsize=(15,10))\ntopK = 20\nloan_amount_country = loans.groupby('country').sum()['funded_amount'].sort_values(ascending=False)\nsns.barplot(y = loan_amount_country.head(topK).index, x=loan_amount_country.head(topK));\nplt.ylabel('Country')\nplt.xlabel('Total Funded Amount (USD 10M)')\ntitleid += 1\nplt.title(f'Figure {titleid}: Top {topK} countries sorted by Total Funded Amount');","df75d3eb":"plt.figure(figsize=(15,10))\nloan_amount_country = loans.groupby('country').mean()['funded_amount'].sort_values(ascending=False)\nsns.barplot(y = loan_amount_country.head(topK).index, x=loan_amount_country.head(topK));\n\nplt.ylabel('Country')\nplt.xlabel('Average Funded Amount (USD 10M)')\ntitleid += 1\nplt.title(f'Figure {titleid}: Top {topK} countries sorted by Total Funded Amount');","4abb7da1":"loans.query(r'country == \"Cote D\\'Ivoire\"')","95adf74f":"plt.figure(figsize=(15,10))\nuseful_countries = list(loans.groupby('country').count().query('id >= 5').index)\nloan_amount_country = loans.groupby('country').mean()['funded_amount'][useful_countries].sort_values(ascending=False)\nsns.barplot(y = loan_amount_country.head(topK).index, x=loan_amount_country.head(topK));\n\nplt.ylabel('Country')\nplt.xlabel('Average Funded Amount (USD 10M)')\ntitleid += 1\nplt.title(f'Figure {titleid}: Top {topK} countries sorted by Total Funded Amount (Without Outliers)');","c7cef638":"topK = 40\nmpis_country = mpi_region_location.groupby('country').mean()['MPI'].dropna()\ncountries = loan_amount_country.head(topK)\ncommon_countries = mpis_country.index.intersection(countries.index)\ndf = pd.DataFrame({'mpis': mpis_country[common_countries], 'amount': countries[common_countries]} )\nsns.lmplot(x='mpis', y='amount', data=df)\ntitleid += 1\nplt.title(f'Figure {titleid}: Relationship between funded_amount and MPI');","3a55bc31":"## Let's take the top 20 countries with total amount of funding\ntop_countries_list = list(loans.groupby('country').sum()['funded_amount'].sort_values(ascending=False).head(10).index)\ntop_country_loans = loans.query(f'country in {top_countries_list}').copy()\ntop_country_loans.head()\n","ee619a25":"# We seen some NaN values in the region and tags columns\nfor col in top_country_loans.columns:\n  print(f'There are {len(top_country_loans[top_country_loans[col].isnull()])} records with NaN values in {col}.')","0e12df98":"import datetime\ntop_country_loans.loc[:, 'posted_time'] = pd.to_datetime(top_country_loans.posted_time)\n## Lets add the year column separately to track growth over time.\n## Parse datetime and set the day to the 1st of every month and club amounts together for easier plotting\ntop_country_loans.loc[:, 'posted_month_year'] = top_country_loans.posted_time.apply(lambda x: datetime.datetime(x.year, x.month, 1)) \n\nloan_data = top_country_loans.groupby(['posted_month_year', 'country']).sum()['funded_amount'].reset_index().sort_values(by='posted_month_year')\nloan_data","130d2021":"fig = go.Figure()\n\nfor index, country in enumerate(loan_data.country.unique()):\n  query = f\"country == '{country}'\"\n  fig.add_trace(\n      go.Scatter(\n          y=loan_data.query(query)['funded_amount'], \n          x=loan_data.query(query)['posted_month_year'], \n          text=country,\n          mode='lines',\n          name=country,\n          visible=\"legendonly\" if index <= 4 else True\n      )\n  )\n\nfig.update_layout(\n      width=1200,\n      height=1000,\n      autosize=True,\n      template=\"plotly_white\",\n  )\n\ntitleid += 1\nfig.update_layout(\n    title=f\"Figure {titleid}: Funded Amount in top 10 countries over time\",\n    xaxis_rangeslider_visible=True,\n    xaxis_title=\"Year\",\n    yaxis_title=\"Loan Amount in USD\"\n)\n\nfig.show()","f4d13230":"top_country_loans[top_country_loans.posted_time.dt.year == 2017][top_country_loans.posted_time.dt.month == 7]","834570ca":"sector_loans = loans.groupby('sector').sum()[['funded_amount', 'loan_amount']].reset_index()\nsector_loans","b4990a4c":"from plotly.subplots import make_subplots\n\nfig = go.Figure(data=[go.Pie(labels=sector_loans.sector, values=sector_loans.funded_amount)])\n    \ntitleid += 1\nfig.update_layout(dict(\n    title=f'Figure {titleid}: Funded Loan Amount per Sector',\n    width=800,\n    height=800\n))\n\nfig.show()","d355f2fd":"top_country_sector_loans = top_country_loans.groupby(['sector', 'country']).sum()['funded_amount'].reset_index()\ntop_country_sector_loans","52b82d87":"fig = go.Figure(\n    data=[\n          go.Pie(\n              labels=top_country_sector_loans.query(\"country == 'Paraguay'\").sector, \n              values=top_country_sector_loans.query(\"country == 'Paraguay'\").funded_amount\n              )\n          ]\n        )\n\ntitleid += 1  \nfig.update_layout(dict(\n    title=f'Figure {titleid}: Funded Loan Amount per Sector',\n    width=800,\n    height=800\n))\n\nfig.update_layout(\n    updatemenus=[\n        go.layout.Updatemenu(\n            buttons=list([\n                dict(\n                    args=[\n                        {\n                            \"labels\": [top_country_sector_loans.query(f\"country == '{country}'\").sector], \n                            \"values\": [top_country_sector_loans.query(f\"country == '{country}'\").funded_amount],\n                            \"title\": [\n                                f'Funded Loan Amount per Sector for {country}'\n                            ]\n                        }],\n                    label=country,\n                    method=\"restyle\"\n                ) for country in list(top_country_sector_loans.country.unique())\n            ]),\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.1,\n            xanchor=\"left\",\n            y=1.8,\n            yanchor=\"top\"\n        ),\n    ]\n)\n\nfig.show()","b9e312b2":"loans.query(\"repayment_interval == 'irregular'\").head(2)","919ba134":"repayment_data = loans.groupby(['repayment_interval', 'country', 'sector', 'activity']).sum()['funded_amount'].reset_index()\nrepayment_data","fedfecca":"fig = go.Figure(\n    data=go.Splom(\n        dimensions=[\n                    dict(\n                        label=label,\n                         values=list(repayment_data[label])\n                        ) for label in list(repayment_data.columns)\n                    ]\n))\n\ntitleid += 1\nfig.update_layout(\n    title=f'Figure {titleid}: Loan Repayment Interval',\n    dragmode='select',\n    width=1200,\n    height=1200,\n    hovermode='closest',\n)\n\nfig.show()","8dfc776b":"# for col in list(repayment_data.iloc[:, 1:].columns:\npayment_interval_dist = repayment_data.groupby(['country', 'repayment_interval']).count()['sector'].reset_index()\npayment_interval_dist","c71e0687":"fig = go.Figure(\n    data=[\n          go.Pie(\n              labels=payment_interval_dist.repayment_interval, \n              values=payment_interval_dist.sector\n              )\n          ]\n        )\n    \ntitleid += 1\nfig.update_layout(dict(\n    title=f'Figure {titleid}: Distribution of Repayment Intervals for Each Country',\n    width=800,\n    height=800\n))\n\nfig.update_layout(\n    updatemenus=[\n        go.layout.Updatemenu(\n            buttons=list([\n                dict(\n                    args=[\n                        {\n                            \"labels\": [payment_interval_dist.query(f'country == \"{country}\"').repayment_interval], \n                            \"values\": [payment_interval_dist.query(f'country == \"{country}\"').sector],\n                            \"title\": [\n                                f'Funded Loan Amount per Repayment Interval for {country}'\n                            ]\n                        }],\n                    label=country,\n                    method=\"restyle\"\n                ) for country in list(payment_interval_dist.country.unique())\n            ]),\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.1,\n            xanchor=\"left\",\n            y=1.8,\n            yanchor=\"top\"\n        ),\n    ]\n)\n\nfig.show()","4a45e830":"# for col in list(repayment_data.iloc[:, 1:].columns:\npayment_interval_dist_sector = repayment_data.groupby(['sector', 'repayment_interval']).count()['country'].reset_index()\npayment_interval_dist_sector.head(10)","5777c682":"fig = go.Figure(\n    data=[\n          go.Pie(\n              labels=payment_interval_dist_sector.repayment_interval, \n              values=payment_interval_dist_sector.country\n              )\n          ]\n        )\n    \ntitleid += 1\nfig.update_layout(dict(\n    title=f'Figure {titleid}: Distribution of Repayment Intervals for Each Sector',\n    width=800,\n    height=800\n))\n\nfig.update_layout(\n    updatemenus=[\n        go.layout.Updatemenu(\n            buttons=list([\n                dict(\n                    args=[\n                        {\n                            \"labels\": [payment_interval_dist_sector.query(f'sector == \"{sector}\"').repayment_interval], \n                            \"values\": [payment_interval_dist_sector.query(f'sector == \"{sector}\"').country],\n                            \"title\": [\n                                f'Funded Loan Amount per Repayment Interval Type for {sector}'\n                            ]\n                        }],\n                    label=sector,\n                    method=\"restyle\"\n                ) for sector in list(payment_interval_dist_sector.sector.unique())\n            ]),\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.1,\n            xanchor=\"left\",\n            y=1.8,\n            yanchor=\"top\"\n        ),\n    ]\n)\n\nfig.show()","dfbb60c1":"loan_amount_per_country = loans.groupby(['country', 'country_code']).agg(['sum', 'count'])['funded_amount'].reset_index().set_index('country')\nloan_amount_per_country['sum'] =loan_amount_per_country['sum'].astype(int)\nloan_amount_per_country","c326cdeb":"# # The country codes are not in ISO Alpha format, let's set these.\n\niso_list = mpi_region_location.groupby(['ISO', 'country']).mean()['MPI'].reset_index().set_index('country')\n\nloan_amount_per_country['country_code'] = iso_list['ISO']\n## Let's drop the countries without any country codes\n## For the countries with NaN values, set the code to the first three letters.\n## Future: maybe scrape wikipedia\/un sites to get info. Currently the data is not easily scrapped.\n\nloan_amount_per_country.loc[loan_amount_per_country.country_code.isnull(), 'country_code'] = loan_amount_per_country[loan_amount_per_country.country_code.isnull()].apply(lambda row: row.name[:3].upper(), axis=1)\nloan_amount_per_country","18c402ce":"titleid += 1\nfig = px.scatter_geo(loan_amount_per_country.reset_index(), locations=\"country_code\", color=\"country\",\n                     hover_name=\"country\", size=\"sum\",\n                     projection=\"natural earth\",\n                     title=f\"Figure {titleid}: Geo-Visualization of Funded Amount\")\nfig.show()","0ad366fd":"\"\"\"\nLet's now analyze the number of loans, the funded amount and the MPI of countries.\n\"\"\"\nloan_amount_per_country['MPI'] = iso_list['MPI']\nloan_amount_per_country = loan_amount_per_country.dropna() ## Drop NaN MPI values to not skew the plot\n\nloan_amount_per_country.head(10)","3a689e7c":"# # # ## Analyze class size and cost of attendance\nfig = px.scatter(\n    loan_amount_per_country.reset_index(), \n    x=\"MPI\",\n    y=\"sum\", \n    color=\"country\", \n    hover_name=\"country\",\n    size=\"count\"\n)\n\ntitleid += 1\nfig.update_layout(\n    height=900,\n    width=900,\n    xaxis_title=\"MPI\",\n    yaxis_title=\"Total Funded Amount\",\n    title=f'Figure {titleid}: MPI vs Funded Amount vs Number of Funded Loans'\n)\nfig.show()","449bf555":"country_peer_network = loans.groupby(['country', 'country_code']).agg(['sum', 'count'])[['funded_amount', 'lender_count']].reset_index().iloc[:, :5]\ncountry_peer_network.head(3)","9189391e":"## Let's squash the column levels\ncountry_peer_network['funded_amount_sum'] = country_peer_network['funded_amount']['sum']\ncountry_peer_network['funded_amount_count'] = country_peer_network['funded_amount']['count']\ncountry_peer_network['lender_count_sum'] = country_peer_network['lender_count']['sum']\n\ncountry_peer_network.head(10)","9f816e13":"# # # ## Analyze class size and cost of attendance\nfig = px.scatter(\n    country_peer_network, \n    x=\"lender_count_sum\",\n    y=\"funded_amount_sum\", \n    color=\"country\", \n    hover_name=\"country\",\n    size=\"funded_amount_count\"\n)\n\ntitleid += 1\nfig.update_layout(\n    height=900,\n    width=900,\n    xaxis_title=\"Total Lender Count\",\n    yaxis_title=\"Total Funded Amount\",\n    title=f'Figure {titleid}: Lender Count vs Funded Amount vs Number of Funded Loans'\n)\nfig.show()","be81d61e":"country_loans = pd.merge(\n    loans, \n    mpi_region_location, \n    how='inner', \n    on='country'\n    )[['country','MPI', 'lat', 'lon', 'lender_count', 'funded_amount']].groupby('country').agg(\n    {\n      'lat': 'mean', \n      'lon': 'mean', \n      'lender_count': 'sum', \n      'funded_amount': 'sum', \n      'MPI': 'mean'\n    }).reset_index()\ncountry_loans = country_loans.dropna()\ncountry_loans.head(2)","7d1e5d77":"titleid += 1\nfig = px.scatter(\n    country_loans, \n    x='lat', \n    y='lon',\n    title=f'Figure {titleid}: Region vs total lender count',\n    size=\"lender_count\",\n    hover_name=\"country\"\n)\nfig.show()\n\ntitleid += 1\n\nfig = px.scatter(\n    country_loans, \n    x='lat', \n    y='lon',\n    title=f'Figure {titleid}: Region vs total average MPI',\n    size=\"MPI\",\n    hover_name=\"country\"\n)\n\nfig.show()","05f5280b":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=10, random_state=0).fit(country_loans[['lat', 'lon']])\n\ncountry_loans['cluster'] = kmeans.labels_","88f16338":"from sklearn.metrics import silhouette_score\n\nsilhouette_score(country_loans[['lat', 'lon']], kmeans.predict(country_loans[['lat', 'lon']]))","e70a450a":"## Let's get the optimal number of clusters\ngeo_labels = ['lat', 'lon']\n\nfor n_clusters in range(5, 15):\n    labels = KMeans(n_clusters=n_clusters, random_state=10).fit_predict(country_loans[geo_labels])\n    silhouette_avg = silhouette_score(country_loans[geo_labels], labels)\n\n    print(f\"For n_clusters = {n_clusters}, The average silhouette_score is : {silhouette_avg}\")","235d817c":"## We see that the optimal n_clusters is 12\nkmeans = KMeans(n_clusters=12).fit(country_loans[['lat', 'lon']])\n\ncountry_loans['cluster'] = kmeans.labels_","5e02944d":"titleid += 1\nfig = px.scatter(\n    country_loans, \n    x='lat', \n    y='lon',\n    title=f'Figure {titleid}: Clustered countries vs total lender count',\n    size=\"lender_count\",\n    hover_name=\"country\",\n    color='cluster'\n)\nfig.show()","ae954fa3":"## We now analyze the trend between clusters, MPI and funded_amounts\nclustered_loans = country_loans.groupby(['cluster']).mean().reset_index()\nclustered_loans","b78d63d4":"titleid += 1\npx.scatter(\n    clustered_loans, \n    x='MPI', \n    y='funded_amount',\n    color='cluster', \n    trendline='ols', \n    title=f'Figure {titleid}: Average Funded Amount vs Average MPI',\n    labels={\n        'MPI': 'Average Multidimensional Poverty Index (MPI)',\n        'funded_amount':'Average Funded Amount'\n    }\n    )","13d471b9":"country_loans.query('cluster == 2').country","2b216f8f":"country_loans.query('cluster == 4')","02468d6f":"display(loans.isnull().sum())\ndisplay(mpi_region_location.isnull().sum())","d630ba92":"loans = loans.dropna()\nmpi_region_location = mpi_region_location.dropna()","e019f112":"# data design\nmpi_data = mpi_region_location.groupby(['country', 'region']).mean()['MPI']\nloans_data = loans.groupby(['country', 'region']).mean().drop(columns=['id', 'partner_id'])\ndata_index = mpi_data.index.intersection(loans_data.index)","1967157d":"# loss function\ndef l2(pred, true):\n    return ((pred - true) ** 2).mean()","46cd88f8":"loans_data","db964f5b":"model = LinearRegression()\n\nX_0 = loans_data.loc[data_index]\ny_0 = mpi_data.loc[data_index]","7e0d149c":"# train\ndef train_linear_regression(X, y):\n    model = LinearRegression()\n\n    kf = KFold(n_splits=5, shuffle=True)\n    train_loss = []\n    val_loss = []\n    for train_id, val_id in kf.split(X):\n        X_train = X.iloc[train_id]\n        y_train = y.iloc[train_id]\n        X_val = X.iloc[val_id]\n        y_val = y.iloc[val_id]\n        model.fit(X_train, y_train)\n        train_loss.append(l2(model.predict(X_train), y_train))\n        val_loss.append(l2(model.predict(X_val), y_val))\n    print('training loss = {}\\nvalidation loss = {}'.format(np.mean(train_loss),np.mean(val_loss)))      ","6d3a734f":"# train\ntrain_linear_regression(X_0, y_0)\n      \n# use all data to train\nmodel.fit(X_0, y_0)\nplt.figure(figsize=(14, 14))\nfor i in range(X_0.shape[1]):\n    plt.subplot(2, 2, i + 1)\n    plt.xlabel(X_0.columns[i])\n    plt.ylabel('residual')\n    plt.scatter(X_0.iloc[:, i], y_0 - model.predict(X_0))\ntitleid += 1\nplt.suptitle(f'Figure {titleid}: Residual Plots');","9a666038":"# data design\n# y: loan_amount\n# X: mpi, sector(dummy encoding)\nX_1 = loans[['country', 'region', 'loan_amount']]\nX_1 = pd.concat([X_1, pd.get_dummies(loans['sector'])], axis=1) # one hot encode sector values\nX_1 = X_1.merge(mpi_region_location[['country', 'region', 'MPI']])\ny_1 = X_1['loan_amount']\nX_1 = X_1.drop(columns=['country', 'region', 'loan_amount'])","44d73130":"data = loans[['country', 'region', 'loan_amount', 'sector']]\ndata = data.merge(mpi_region_location[['country', 'region', 'MPI']])\nplt.figure(figsize=(10, 8))\ntitleid += 1\nplt.title(f'Figure {titleid}: Loan Amount Distribution by Sector and MPI')\nsns.scatterplot(x='MPI', y='loan_amount', hue='sector', data=data);","3cc8fb05":"plt.figure(figsize=(10, 8))\nsectors = data['sector'].value_counts().head(5).index.to_series(name='sector')\ntitleid += 1\nplt.title(f'Figure {titleid}: Loan Amount(<=10000) Distribution by Major Sectors and MPI')\nsns.scatterplot(x='MPI', y='loan_amount', hue='sector', data=data.merge(sectors).query('loan_amount <= 10000'));","fe747d86":"train_linear_regression(X_1, y_1)","38a54ec3":"def train_random_forest_regressor(X, y, **params):\n    model = RandomForestRegressor(**params)\n\n    kf = KFold(n_splits=5, shuffle=True)\n    train_loss = []\n    val_loss = []\n    for train_id, val_id in kf.split(X):\n        X_train = X.iloc[train_id]\n        y_train = y.iloc[train_id]\n        X_val = X.iloc[val_id]\n        y_val = y.iloc[val_id]\n        model.fit(X_train, y_train)\n        train_loss.append(l2(model.predict(X_train), y_train))\n        val_loss.append(l2(model.predict(X_val), y_val))\n    return train_loss, val_loss    ","3a35837e":"train_loss, val_loss = train_random_forest_regressor(X_1, y_1, n_estimators=10)\nprint('training loss = {}\\nvalidation loss = {}'.format(np.mean(train_loss), np.mean(val_loss)))","1ad4cc87":"def heatmap_random_forest_regressor(ns, depths, X, y):\n    loss = np.zeros((len(ns), len(depths)))\n    for i in range(len(ns)):\n        for j in range(len(depths)):\n            _, val_loss = train_random_forest_regressor(X, y, n_estimators=ns[i], criterion='mse', max_depth=depths[j])\n            loss[i, j] = np.mean(val_loss)\n    sns.heatmap(loss, cmap='YlGnBu', xticklabels=depths, yticklabels=ns)\n    plt.xlabel('max_depth')\n    plt.ylabel('n_estimators')\n    global titleid\n    titleid += 1\n    plt.title(f'Figure {titleid}: Random Forest Regressor MSE')\n    return loss","310fed2e":"ns_reg = np.arange(1, 21, 5)\ndepths_reg = np.arange(1, 61, 5)\nloss_forest_0 = heatmap_random_forest_regressor(ns_reg, depths_reg, X_1, y_1)","7bbdf4b8":"fine_ns_reg = np.arange(5, 41, 5)\nfine_depths_reg = np.arange(7, 23, 3)\nloss_forest_1 = heatmap_random_forest_regressor(fine_ns_reg, fine_depths_reg, X_1, y_1)","61941dbe":"loss_forest_1.min()","9690c30d":"# data design\nX_logi = data[['MPI', 'loan_amount']]\ny_logi = data['sector']","27e8f152":"def train_logistic_regression(X, y):\n    model = LogisticRegression(solver='liblinear', multi_class='auto')\n    kf = KFold(n_splits=5, shuffle=True)\n    train_acc = []\n    val_acc = []\n    for train_id, val_id in kf.split(X):\n        X_train = X.iloc[train_id]\n        y_train = y.iloc[train_id]\n        X_val = X.iloc[val_id]\n        y_val = y.iloc[val_id]\n        model.fit(X_train, y_train)\n        train_acc.append((model.predict(X_train) == y_train).mean())\n        val_acc.append((model.predict(X_val) == y_val).mean())\n    print('training accuracy = {}\\nvalidation accuracy = {}'.format(np.mean(train_acc),np.mean(val_acc)))","afc9196c":"train_logistic_regression(X_logi, y_logi)","f7d5b53e":"def show_logistic_confusion_matrix(X, y):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n    model = LogisticRegression(solver='liblinear', multi_class='auto')\n    model.fit(X_train, y_train)\n    global titleid\n    titleid += 1\n    plt.title(f'Figure {titleid}: Confusion Matrix for Logistic Regression')\n    sns.heatmap(confusion_matrix(y_val, model.predict(X_val)), cmap='YlGnBu')\n\nshow_logistic_confusion_matrix(X_logi, y_logi)","b3716141":"def train_random_forest_classifier(X, y, heatmap=False, **params):\n    model = RandomForestClassifier(**params)\n    kf = KFold(n_splits=5, shuffle=True)\n    train_acc = []\n    val_acc = []\n    for train_id, val_id in kf.split(X):\n        X_train = X.iloc[train_id]\n        y_train = y.iloc[train_id]\n        X_val = X.iloc[val_id]\n        y_val = y.iloc[val_id]\n        model.fit(X_train, y_train)\n        train_acc.append((model.predict(X_train) == y_train).mean())\n        val_acc.append((model.predict(X_val) == y_val).mean())\n        if heatmap:\n            print(model.classes_)\n            sns.heatmap(confusion_matrix(y_val, model.predict(X_val)), cmap='YlGnBu')\n        plt.show()\n    return train_acc, val_acc","f85f53ef":"train_acc, val_acc = train_random_forest_classifier(X_logi, y_logi, n_estimators=10, criterion='gini')\nprint('training accuracy = {}\\nvalidation accuracy = {}'.format(np.mean(train_acc),np.mean(val_acc)))","b61db188":"def draw_decisicon_boundary(X, y, model):\n    sns_cmap = ListedColormap(np.array(sns.color_palette('Paired'))[:, :])\n\n    xx, yy = np.meshgrid(np.linspace(X.iloc[:, 0].min(), X.iloc[:, 0].max(), 30), np.linspace(X.iloc[:, 1].min(), X.iloc[:, 1].max(), 30))\n    Z_string = model.predict(np.c_[xx.ravel(), yy.ravel()])\n    categories, Z_int = np.unique(Z_string, return_inverse = True)\n    Z_int = Z_int.reshape(xx.shape)\n    cs = plt.contourf(xx, yy, Z_int, cmap = sns_cmap)\n    proxy = [plt.Rectangle((0,0),1,1,fc = pc.get_facecolor()[0]) for pc in cs.collections]\n    plt.legend(proxy, categories)\n    plt.xlabel('MPI')\n    plt.ylabel('funded amount')\n    global titleid\n    titleid += 1\n    plt.title(f'Figure {titleid}: Decision Boundaries of Random Forest Classifier');","05ba630e":"def show_forest_confusion_matrix(X, y):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n    model = RandomForestClassifier(n_estimators=10, criterion='gini')\n    model.fit(X_train, y_train)\n    plt.figure(figsize=(10, 15))\n    plt.subplot(2,1,1)\n    global titleid\n    titleid += 1\n    plt.title(f'Figure {titleid}: Confusion Matrix for Random Forest Classifier')\n    sns.heatmap(confusion_matrix(y_val, model.predict(X_val)), cmap='YlGnBu')\n    plt.subplot(2,1,2)\n    draw_decisicon_boundary(X, y, model)\n\nshow_forest_confusion_matrix(X_logi, y_logi)","078f1332":"def heatmap_random_forest_classifier(ns, depths):\n    acc = np.zeros((len(ns), len(depths)))\n    for i in range(len(ns)):\n        for j in range(len(depths)):\n            _, val_acc = train_random_forest_classifier(X_logi, y_logi, n_estimators=ns[i], criterion='gini', max_depth=depths[j])\n            acc[i, j] = np.mean(val_acc)\n    sns.heatmap(acc, cmap='YlGnBu', xticklabels=depths, yticklabels=ns)\n    plt.xlabel('max_depth')\n    plt.ylabel('n_estimators')\n    global titleid\n    titleid += 1\n    plt.title(f'Figure {titleid}: Random Forest Classifier Accuracy')\n    return acc","1c7af966":"ns = np.arange(1, 42, 10)\ndepths = np.arange(8, 25, 5)\nacc_forest_0 = heatmap_random_forest_classifier(ns, depths)","8515859c":"acc_forest_0.max()","5daffe27":"model = RandomForestClassifier(n_estimators=25, max_depth=15, criterion='gini')\nX_train, _ , y_train, _ = train_test_split(X_logi, y_logi, test_size=0.2)\nmodel.fit(X_train, y_train)\nplt.figure(figsize=(10, 10))\ndraw_decisicon_boundary(X_logi, y_logi, model)","5e95f698":"loans.columns","6d94c6c8":"## Clean gender column to keep a single gender value, which is the first gender value\nloans.borrower_genders = loans.borrower_genders.str.split(\", \").apply(lambda x: list(set(x))[0])","daedca79":"## We know there was a linear relationship between lender_count and funded_amount, let's analyze the slopes of these\n## and split based on certain columns\ndef split_show_linear(df, separator, use_plotly=False):\n    temp_df = df.groupby([separator, 'lender_count']).sum()['funded_amount'].reset_index()\n    if use_plotly:\n        global titleid\n        titleid += 1\n        fig = px.scatter(temp_df, x=\"lender_count\", y=\"funded_amount\", facet_col=separator, color=separator, trendline=\"ols\",\n                         title=f'Figure {titleid}')\n        fig.show()\n    else:\n        sns.lmplot(x=\"lender_count\", y=\"funded_amount\", hue=separator, data=temp_df)\n    \nseparator='borrower_genders'\nsplit_show_linear(loans, separator, True)","311a93a4":"#The data seems overplottled for low lender counts, let's group this into two segments\nseparator='borrower_genders'\nsplit_show_linear(loans.query('lender_count < 200'), separator, True)","e3c8f3df":"separator='borrower_genders'\nsplit_show_linear(loans.query('lender_count >= 200'), separator, True)","7656cb7e":"titleid += 1\npx.bar(\n    loans.groupby(['borrower_genders', 'sector']).sum()['funded_amount'].reset_index(),\n    x='borrower_genders',\n    y='funded_amount',\n    color='sector',\n    barmode='group',\n    title=f'Figure {titleid}: Gender specific funded amounts per sector'\n)","561b3673":"## Let's analyze the spread of repayment interval with respect to funded_amounts and sectors\nplt.figure(figsize=(20,10));\ntemp_df = loans.groupby(['repayment_interval', 'sector']).sum()['funded_amount'].reset_index()\ntitleid += 1\npx.bar(\n    temp_df, \n    color='sector', \n    y='funded_amount', \n    x='repayment_interval', \n    barmode='group',\n    title=f'Figure {titleid}: Loan Repayment Intervals vs Funded Amounts per sector',\n)","1e949570":"## We join two dataframes to get geo location values as well.\nmpi_region_location.country = mpi_region_location.country.astype('str')\nloans.country = loans.country.astype('str')\nfull_data = pd.merge(loans, mpi_region_location, on='country', how='left')","13ef8ca2":"numerical_features = ['MPI', 'lat', 'lon', 'funded_amount', 'loan_amount', 'term_in_months', 'lender_count']\ncategorical_features = ['sector', 'activity', 'country', 'region_x', 'currency']\n\nfeatures = numerical_features + categorical_features\nfeatures","a3e07c23":"## Let's split the data into train and test\noutcome_variable = 'repayment_interval'\nfull_data = full_data[features + [outcome_variable]] ## Select only certain starting features\nfull_data = full_data.dropna()\nX_train, X_test, Y_train, Y_test = train_test_split(full_data[features], full_data[outcome_variable])","f64a4de8":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n## Clean and transform data\nscaler = StandardScaler()\ncentered_data = scaler.fit_transform(X_train[numerical_features])\n\npca = PCA()\npca.fit(centered_data)","ec833296":"fig, ax = plt.subplots(1, figsize=(6,5))\n\n# plot explained variance as a fraction of the total explained variance\nax.plot(pca.explained_variance_ratio_)\n\n# mark the 1th principal component\nax.axvline(5, c='k', linestyle='--')\n\nax.set_xlabel('PC index')\nax.set_ylabel('% explained variance')\ntitleid += 1\nax.set_title(f'Figure {titleid}: Scree plot')\nfig.tight_layout()","3ddbf4f3":"sns.barplot(x=numerical_features, y=pca.components_[0])\ntitleid += 1\nplt.title(f'Figure {titleid}: 1st PC')\nplt.xticks(rotation=90);","e30f1830":"sns.barplot(x=numerical_features, y=pca.components_[1])\ntitleid += 1\nplt.title(f'Figure {titleid}: 2nd PC')\nplt.xticks(rotation=90);","1e66e605":"sns.barplot(x=numerical_features, y=pca.components_[-1])\ntitleid += 1\nplt.title(f'Figure {titleid}: last PC')\nplt.xticks(rotation=90);","b65990ff":"numerical_features.remove('loan_amount')\n\nfeatures = numerical_features + categorical_features\nfeatures","20723418":"def one_hot_encode(dataframe, categorical_features):\n  train = pd.DataFrame()\n  for feature in categorical_features:\n    train = pd.concat([train, pd.get_dummies(dataframe[categorical_features])], axis=1)\n\n  return train","aa7c7220":"### Note: Collab RAM crashes because one hot encoding region and currency takes a lot of RAM\n## let's reduce the variables and remove region, activity and currency\ncategorical_features = ['country', 'sector']\none_hot_encoded = one_hot_encode(X_train, categorical_features)","69935db2":"def merge_category_numerical(dataframe, numerical_features, one_hot_encoded_matrix):\n  return pd.concat([dataframe[numerical_features], one_hot_encoded_matrix], axis=1)","c68e616a":"X_concat = merge_category_numerical(X_train, numerical_features, one_hot_encoded)","8abc9450":"## We convert the multi class problem into a binary class problem since\n## the characteristics for one time and irregular payments would largely be the \n## same.\ndef merge_classes(Y):\n  return Y.apply(lambda x: 'regular' if x == 'monthly' else 'irregular')\n\nY_train = merge_classes(Y_train)\nY_test = merge_classes(Y_test)","f5847c6d":"#@title Logistic Classification - Set Hyperparameters\n#@markdown Set the hyperparameters for the Logistic Classification model\n\npenalty = 'l2' #@param [\"l2\", \"l1\"] {allow-input: true}\npenalty_weight =   10#@param {type: \"number\"}\nclass_weight = 'balanced' #@param [\"balanced\", \"None\"] {allow-input: true}\n#@markdown ---\n","bbe447d6":"hyperparameters = {\n    'penalty': penalty,\n    'C': penalty_weight,\n    'class_weight': None if class_weight == 'None' else class_weight\n}","c9d92958":"def get_model(hyperparameters):\n  print(f'Setting hyperparameters: {hyperparameters}')\n  return LogisticRegression(solver='liblinear', **hyperparameters)","a1a0504c":"def create_sparse_dataframe(dataframe):\n  return dataframe.to_sparse()","3a45c6be":"X_concat_sparse = create_sparse_dataframe(X_concat)","c44fbf24":"def train_logistic_classifier_payment_interval(X_train, Y_train, params):\n  kf = KFold(n_splits=5, shuffle=False)\n  train_acc = []\n  val_acc = []\n  class_model = get_model(params)\n  for train, test in kf.split(X_train):\n    class_model.fit(X_train.iloc[train], Y_train.iloc[train])\n    train_acc.append(class_model.score(X_train.iloc[train], Y_train.iloc[train]))\n    val_acc.append(class_model.score(X_train.iloc[test], Y_train.iloc[test]))\n\n  print(f'validation accuracy: {np.mean(val_acc)}, {np.mean(train_acc)}')\n  return class_model","4212f746":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nclass_model = train_logistic_classifier_payment_interval(X_concat_sparse, Y_train, hyperparameters)","72451da4":"# Run on test set\nX_test_concat = merge_category_numerical(X_test, numerical_features, one_hot_encode(X_test, categorical_features))","d0c7d542":"metric = confusion_matrix(Y_test, class_model.predict(X_test_concat))","29d71cb9":"fig = go.Figure(\n      data=go.Heatmap(\n            z=metric ,\n            x=['predicted irregular', 'predicted regular'],\n            y=['actual irregular', 'actual regular']\n          )\n    )\ntitleid += 1\nfig.update_layout(\n    title=f\"Figure {titleid}: Confusion Matrix for predicted classes\"\n)\nfig.show()","c12ba6cc":"# 4. Data Cleaning & Transformation \n\nWe now start with predicting various features to understand correlations. We form questions around these predictions to understand the value of a peer to peer network provided by companies like Kiva.org.","3e8fe784":"### 2. Obtaining Data & Data Description\n\nWe will use the dataset provided by Kiva.\n\nWe may use additional dataset to help make predictions. The data is downloaded from the [Kaggle Competition](https:\/\/www.kaggle.com\/kiva\/data-science-for-good-kiva-crowdfunding). We then upload it to Google Drive as a zip file, mount the drive contents and extract the contents of the zip file into the local Collab runtime.","d90e920c":"We see that a large number of women get high funded amounts but for lower lender counts. \nKiva.org loans are largely used to fund women led projects (81% of borrowers are women according to [this](https:\/\/www.kiva.org\/about\/impact) report), however this regression shows \nthat these are projects with few lender counts. When lender counts are >= 200 and < 1200, the regression lines\nshow that men get higher funded amounts. This doesn't give us any strong evidence of algorithmic bias, it just gives\nus some form of loose correlation. \n\n**An important note here is that a machine learning model that predicts funded amount based on other features, that takes the gender column as a feature will fit a curve that will predict a higher funded amount of men for lender counts >= 200 < 1200.** The question of whether to include gender data into a model is thus questionable. A  model can predict higher amounts of women where lender counts <= 200 as well. Moreover, gender could be embedded into the activity column if women perform specific activities that they need funds for. For e.g, in the bar plot above, we see that there are relatively more women in the clothing sector. Does that mean that including a sector information as a feature also introduces bias?\n\nFurther analysis on the region and number of rejected loans would be needed to establish bias. That said, higher lender count leading to higher funded amounts of males might be something to look into. Maybe these patterns are true for certain sectors, regions etc. We leave this question open for future work.\n","312c2eca":"Thus 5 principal components should be enough to classify the repayment_interval.\nLet's see what these features are","0f68be82":"## What is the percentage of irregular payments in countries, and how is it correlated to sector, country, activity and loan amount?","5b4fc122":"### Train Test Split","1d2bfe66":"### Data Cleaning","f3d25147":"#### Q1. Is the `funded_amount` a good predictor of the MPI of a region?","fe59ab55":"### Analyzing Bias in Lending\n\nBias in consumer lending is a prominent topic of research. We see if there are certain sections of society that get larger loans, or are more likely to get a higher loan using simple loan approval algorithms that companies commonly use.","8d4d7d7b":"It seems random forest achieves high accuracy on both the training set and the validation set.\n\nAnd the confusion matrices is also better than that of logistic regression.\n\nFrom a set of experiments, we find that the decision boundaries are not stable, however the accuracy keeps relatively stable.\n\nWe will tune the parameters of the random forest to see if the result may vary.\n\nFor now, we focus on the number of estimators and the max depth.","f4ee4924":"### Feature Selection","2e3bead8":"Cote D'Ivoire has extremely high average amount of funded loans.","b697be51":"Phillipines and Kenya are the top funded countries. This corroborates Kiva.org's real life funding operations, that occure majoratarily in these countries. The top countries also seem to be largely developing countries.\n\nFigure 2 shows the average amount of funded loans by country.","0edd1b4d":"Let's focus on loans for now.","cd169c3a":"We see above some discrepancies within clusters. In cluster 2, while Pakistan and Tajikistan have widely different MPI values, they both receive similar funded amounts and have comparable lender counts.\n\nThese countries are neighboring and thus could be seeing a spillover of microlending, however the funded amount is small compared to cluster 4.\n\nWithin Cluster 4, Indonseia and Philippines receive large amounts of funding and they have a much lower MPI than Timor-Leste.\n\nWe see a problem with this approach because of outliers. The average MPI values of both these clusters is skewed due to outliers and thus clustering and generating inference based on geographic location is **NOT** a good approach to predicting funded amounts.","a265c13a":"The confusion matrix shows acceptable classification scores. The matrix also helps understand the relative accuracy between True Positive and True Negative rates, the latter being higher. This could be due to our assumption that one time payments are irregular, hence classifying them as positive.","e83c808c":"Surprisingly MPI has very little variance in the 1st PC, let's see the 2nd PC","d157e5aa":"Draw the confusion matrix of random forest classifier:","45a8b8f7":"From Figure 6 we see that Agriculture, Food and Retails are the largest sectors that get funded on Kiva.org. Let's see if these sectors are different across countries.","2e06def9":"## [One Hot Encoding](#scrollTo=xxJ4rzkgXZGT)","e04fdc4f":"Here we seek to analyze the distribution of irregular payments. Certain parameters like country, activity, sector and loan amount will help us understand the likelihood of getting a loan based on whether the loan payment type is irregular.\n\nIn later sections, we classify a loan's payment type (regular, irregular) based on these parameters. Before classifying we analyze if there's sufficient distribution of irregular payment types across these parameters.","57076881":"To see which columns we can remove, let's see the last PC","268e8ec9":"There is only one record, thus we redo the last plot by eliminating countries with less than 5 records.\n\nFigure 3 shows the result.","e9725aa5":"Let's have a look at the data.\n\nFirst let's see what we have about loans.","bb5391b9":"1. ## [Principal Component Analysis](#scrollTo=Ns-djwZ51yir&line=4&uniqifier=1)\n\n","4448a494":"Figure 15 is messy. We choose the major sectors and remove records with amounts > 10000.","40078f08":"\n## Tasks\n\n1. [x] Frame a question of your choice that can be addressed by identifying, collecting, and analyzing relevant data.\n2. [x] Describe and obtain the data.\n3. [x] Perform exploratory data analysis (EDA) and include in your report at least two (but probably many more) data visualizations.\n4. [x] Describe any data cleaning or transformations that you perform and why they are motivated by your EDA.\n5. [x] Apply relevant inference or prediction methods (e.g., linear regression, logistic regression, or classification and regression trees), including, if appropriate, feature engineering and regularization. Use cross-validation or test data as appropriate for model selection and evaluation. Make sure to carefully describe the methods you are using and why they are appropriate for the question to be answered.\n6. [x] Summarize and interpret your results (including visualization). Provide an evaluation of your approach and discuss any limitations of the methods you used.\n7. [x] Describe any surprising discoveries that you made and future work.\n","7c3caab3":"The meaning of each column:\n\n- id: Unique ID for loan\n- funded_amount: Dollar value of loan funded on Kiva.org\n- loan_amount: Total dollar amount of loan\n- activity: Loan activity type\n- sector: Sector of loan activity as shown to lenders\n- use: text description of how loan will be used\n- country_code: 2-letter Country ISO Code\n- country: country name\n- region: name of location within country\n- currency: currency in which loan is disbursed\n- partner_id: Unique ID for field partners\n- posted_time: date and time when loan was posted on kiva.org\n- disbursed_time: date and time that the borrower received the loan\n- funded_time: date and time at which loan was fully funded on kiva.org\n- terminmonths: number of months over which loan was scheduled to be paid back\n- lender_count: number of lenders contributing to loan\n- tags: tags visible to lenders describing loan type\n- borrower_genders: gender of borrower(s)\n- repayment_interval: frequency at which lenders are scheduled to receive installments\n- date: date on which loan was posted","b1d48245":"#6. Conclusion & Future Work\n\n## Summary\n\nWe set out to analyze Kiva.org's lending patterns and understand the distribution of loans across the globe. We analyzed the loan distribution across sectors, countries and activities.\n\nA significant part of the analysis involved seeing the distribution of loans across countries and to find any geographical clustering.\n\nHere are our key findings:\n\n1. Kenya saw a large amount of growth in the initial months of Kiva.org launching (subject to the fact that the dataset is from the time when Kiva.org launched).\n\n2. We see that Agriculture, Food and Retails are the largest sectors that get funded on [Kiva.org](http:\/\/kiva.org\/)\n\n3. We see certain countries (such as Rwanda) that have a majority of loans under irregular repayment intervals. Irregular payments is a deciding factor of the loan amount.\n\n4. We see that most sectors have a majority repayment interval under monthly payments. \n\n**Interesting Finding**: For sectors like Agriculture where a microloan would be expected to be paid after a long time, or paid irregularly due to the seasonal aspect of Agriculture, especially in developing countries.\n\n5. We see a certain clustering among neighboring countries in terms of funded amounts, thus showing a potential spillover effect.\n\n6. Countries with similar MPI have a large difference between the total funded amount. This is due to weaker peer to peer networks by way of lower number of lenders.\n\n7. We see there is a strong linear correlation between total funded amount and total lender count for nations. Thus lender count is a good predictor of the strength of the microlending network.\n\n**Interesting Finding**: Countries with lower number of lenders also get higher funded amounts. Therefore, a stronger peer to peer microloan network might not mean more lenders, but lenders willing to invest larger amounts of money.\n\n8. We briefly analyze bias to see the distribution of loans for men and women and pose open ended questions for considering bias in machine learning models. We discuss the question of including features if they may contain certain implicit bias.\n\n9. Finally, we do a classification task to classify a loan as 'regular' or 'irregular' payment, as a rough proxy for the likelihood of getting a loan. We use feature engineering techniques such as principal component analysis, one hot encoding and data transformation to clean and transform the data. We then use a logistic regression model to train using cross validation and calculate the confusion matrix using a test subset.\n\nOverall, we go through the entire data science lifecycle in this project and frequently iterate between forming questions, cleaning data, doing EDA and running inference tasks.\n\n## Evaluation of our approach\n\nOur approach involved posing questions, running EDA and drawing inferences based on the EDA. \n\nSince there wasn't a prediction problem setup in the dataset, a large part of our EDA was to understand correlations between features and evaluate which features could be converted to outcome variables such that they gave unique insights. Potentially, another approach could be to draw additional external data to see what loans do not get funded.\n\nOur approach to finding bias in lending was via one specific set of features. Arguably, other features such as the tags assigned to the loan, the payment period etc could also have been used to check for bias.\n\n## Methods we used\n\nIn this project, we used a set of supervised and unsupervised learning models. For supervised methods, we used cross-validation to measure their performance.\n\nModels we used:\n\n1. Linear Regression\n2. Logistic Regression\n3. Random Forest Classifier\n4. Random Forest Regressor\n5. Principle Component Analysis\n\nFor Q1 we used linear regression trying to find the relationship between funded amount and MPI.\n\nFor Q2 we used both linear regression and a random forest regressor. The random forest approach proved to have a better performance.\n\nQ3 is a classification problem so we started from logistic regression. Then we improve the accuracy by applying random forest classifier. We visualized the results by confusion matrices and decision boundaries.\n\nWhen classifying repayment intervals we used PCA to find useful features.\n\n## Limitations\n\n1. The large amount of `null` values of the data posed a problem. We decided to drop the `null` valued data to prevent zero value bias into the EDA. We found setting null values into the dataset actually skewed the metrics on funded amounts quite a bit.\n\n2. Lack of a prediction variable made most of our analysis open ended. We posed questions and ran inferences tasks based on what we thought would be beneficial in a microlending context, however the inference is depdendent on what the microlending company deems important.\n\n3. We were limited by a computational environment and we could not one hot encode all activities due to the feature set reaching very large values. A faster approach to this problem would probably involve using parallel processing libraries on a scalable cluster.\n\n## Future Work\n\nFuture work can involve the following:\n\n1. Analyzing the social bias introduced by including or removing the `gender_borrower` column.\n2. Analyzing the social bias caused by implicit information embedded into features such as `sector` that have a correlation to the gender of the borrower.\n3. Using Neural Networks for classification and regressions tasks with better metric scores.\n4. Using ensemble methods such as Bagging, Boosting for better metric scores.\n5. Exploring hyperparameter search algorithms such as [GridSearch](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html) to find the most optimal hyperparameters for a model.\n\n\n## Acknowledgements\n\nWe would like to thank the Faculty, Staff and Students of CS200 for the opportunity to work on this project as well as their support and feedback. This work used datasets provided by Kaggle and Kiva.org, for which we are grateful.\n\nWe would also like to thank UC Berkeley for providing us this opportunity.","a3b495d5":"In general, countries with higher MPI tend to have lower average amounts of loans.\n\nThe relationship is not linear though.","4141ea9b":"We need to clean the data before we use it to train models.\n\n## Handling Null values\nFirst we will handle null values.","c8e1359e":"The simplest way to handle them is to drop any rows with null values. Potentially, we can update the data and fill in the null values. However, for this project we choose to drop null values to prevent zero value skew in financial data. Note that removing null values can also skew our inference, but dropping null values is safer and we can exclude data points (in this case certain countries), thereby excluding certain countries. Excluding certain countries should be safe based on our prior analysis that shows countries geographically close have similar characteristicss with respect to loan amounts and MPI barring a few outliers.","0d826f22":"#### Q2. Can we predict the funded amount a region is likely to get, given the mpi and sector?\n\n#### Task: Predict the amount of loans from mpi and sector:\n\nThis could be helpful for us to know about the regional financial needs in different fields.\n\nWe will first perform simple Linear Regression.","a65e0cd5":"## Geo-Vizualization: Is there a certain clustering on loan amounts for neighboring countries? Do countries with similar MPI scores that are in different geographical regions get different loan amounts?","e020d6b7":"Figure 18 shows the result does not vary a lot in the specified range.\n\nSo we can choose `n_estimators=20` and `max_depth=10`. \n\nThe minimal loss would be around 1700000, which is less than simple linear regression.","444dced6":"Next we will try to use random forest regressor.","b347fe9d":"Draw the confusion matrix Figure 19:","df7e33d4":"## Classifying repayment intervals\n\n- Repayment intervals (monthly, one time (bullet), irregular etc) for a loan get often determine the chances of getting a loan approved. Since we do not have the loan approval status, we use repayment interval as a loose proxy.\n\n- If a loan has a high probability of being classified as an irregular repayment type, lenders might not want to fund the loan. For one time payments, the lending amount and period might determine willingness to fund. We don't analyze one time repayment and thus use binary classification to classify monthly (regular) or regular payments and club bullet(one time) payments with irregular payments.","68544592":"According to Figure 5, Kenya seems to have shown high growth in the amount that was funded in the first few months of launch.\n\nAn odd occurence is that we see a sudden downward spike in July 2017 for all countries, let's check what these values are.","30e83979":"We see in the above graph that clusters with the same average MPI receive very different funding. Let's see what these countries are. We will look at cluster 2 and 4.","faaa9f1c":"## How large is a loan based on a sector? Do certain sectors like agriculture or small business get higher loans? Do they ask for higher loans?","613a4799":"Here we see what we saw on the world map before as well - neighboring countries have high lender counts.\n\nWe also see that generally the MPI of neighboring regions is the same. Poorer countries (higher MPI) are clustered together.\n\nLet's cluster these areas and use the clusters to generate trend lines between funded amount and MPI.","2b56a43b":"As expected, funded_amount and loan_amount have similar distributions. Since loan_amount values are sometimes `null`, we pick funded_amount as the feature.","6f7c1a62":"We see some distribution between sector and funded_amount when it comes to the distribution of `repayment_interval`.\nLet's run PCA to find the best features to use to predict the `repayment_interval`.\n\nWe pick only the continuous variables, since PCA on categorical variables won't give us any meaningful data.","b2aebe45":"From Figure 9 we see that countries such as Rwanda has a majority of loans under irregular repayment intervals. We will investigate during Principal Component Analysis (PCA) to see if `repayment_interval` plays a role in deciding the `funded_amount`.","e6dd13a0":"# 5. Prediction and Inference\n\nNow that the null values are dropped, we make predictions based on certain functional questions. ","592fb06b":"From Figure 7 we see that most developing nations have Agriculture, Retail and Food as the most funded sectors. Thus, the sector can be a good indicator of predicting the likelihood of getting a microloan and\/or the funded amount of the loan.","eae6ed8f":"We see that the funded amount in July 2017 is pretty low, some have zero values in `funded_amount`. There also seem to be many NaN values for funded_amount, gender etc. Since this is the tip, it's highly likely that the data is incomplete.","9aeb744b":"In Figure 8, we see at the top right graph an interesting correlation between `funded_amount` and `repayment_interval`. Let's see this graph up close per sector and per country.","e767b3ab":"Questions we explore in the subsequent sections:\n\n1. What is the general trend in funded loans? How fast is Kiva.org adopted in countries?\n\n2. How large is a loan based on a sector? Do certain sectors like agriculture or small business get higher loans? Do they ask for higher loans?\n\n3. What is the percentage of irregular payments in countries, and how is it correlated to sector, country, activity and loan amount?\n\n4. Geo-Vizualization: Is there a certain clustering on loan amounts for neighboring countries? Do countries with similar MPI scores that are in different geographical regions get different loan amounts?\n\n5. Which countries have the strongest peer to peer networks?","2ccd314c":"# Introduction\n\n## Kiva.org and Microlending\n> Kiva (commonly known by its domain name, Kiva.org) is a **501(c)(3) non-profit organization** that allows **people to lend money via the Internet to low-income entrepreneurs and students** in 77 countries. Kiva's mission is \"to expand financial access to help underserved communities thrive.\"\n\n> Kiva **relies on a network of field partners to administer the loans on the ground**. These field partners can be **microfinance institutions, social impact businesses, schools or non-profit organizations**. Kiva includes personal stories of each person who needs a loan so that their lenders can connect with their entrepreneurs on a human level.\n\n<font size=\"1\">https:\/\/en.wikipedia.org\/wiki\/Kiva_(organization)<\/font>\n\n### 1. Framing the Question\n\n#### Objective\n\nThe dataset obtained is from Kiva.org's [Kaggle Competition in 2018](https:\/\/www.kaggle.com\/kiva\/data-science-for-good-kiva-crowdfunding). The aim of the competition was provide Kiva.org with a better understanding of their impact on the localities they serve.\n\nThe original Kaggle competition does not provide any specific prediction problem and leaves the analysis open ended. In this project, we design our own objectives to understand patterns in the microlending space.\n\nSome of our key objectives are:\n\n1. Run Exploratory Data Analysis (EDA) to find patterns or characteristics in the data to help Kiva.org get insights around lending patterns.\n2. Try to predict the poverty levels of regions given loan amounts and sectors requiring loans.\n3. Predict funded amounts, sectors and poverty levels of an area via supervised learning approaches.\n4. **Explore bias in lending**: We explore if certain parts of society have a higher loan approval rate than others. This is an open ended analysis and our experiments try to show the **negative effects** of machine learning algorithms in a FinTech space if not analyzed for bias.\n\n","80891b0b":"Since funded time has a large number of NaN values, let's use posted_time to analyze Kiva.org adoption.\nLater, we will clean this data and fill or drop specific null columns.\n\n[Jump to Null value cleaning](#scrollTo=eaN0yeXpeko5&line=3&uniqifier=1)\n","dbd882fe":"### One Hot Encoding Categorical Variables\n\nLet's one hot encode the categorical variables and run classification using logistic regression and random forests.","0a2e45df":"Visualize the data design.","a87a7895":"Let's adjust the search space do it again.","794ab8b9":"### Principal Component Analysis (PCA)","deda4bc0":"There exists some patterns in Figure 16.\n\nThe amount of personal use are usually low (< 2000).\n\nThe agriculture use is less frequent in regions with higher MPI.\n\nThe majority of educational loans are in regions with quite low MPI.","87754883":"Task: Predict MPI using data in loans using Linear Regression.\n\nFrom our EDA, we see that countries with different MPI values can get different funded amounts. In this task we aim to predict the MPI of a region using loan data like `funded_amount`, `term_in_months` and `lender_count`. If loan parameters are a good predictor of the MPI of a region, it means changes in these parameters can have a large influence in a region's MPI, and thus showing that micrloans have a demonstrated impact on the MPI of a region.","372462c5":"## Which countries have the strongest peer to peer networks?\n\nHypothesis: The number of lenders for a loan should be a good predictor of the strength of the p2p network. Thus, a stronger p2p network should lead to a higher total funded amount.","e4fdf0af":"Apparently loans have different distributions in different countries. Figure 1 shows the top K(=20) countries with largest total amount of funded loans.","4caa1ddf":"From Figure 11 we see certain similarly sized bubbles in Africa (Kenya, Uganda, Rwanda) and parts of south-central America. We also see Phillipines and Cambodia as the largest markets in Southeast Asia. Generally, there is a certain clustering among neighboring countries for the total amount of funded loans for the time period of the dataset. What makes this observation important is that microlending can have a spillover effect into neighboring countries. It would be interesting to see Kiva.org's growth strategies into neighboring countries and if they were largely driven by word of mouth.","d7bf23d4":"Both the training loss and validation loss is smaller.\n\nWe will try to tune the `n_estimators` and `max_depth` and see if the result changes.","45104830":"Q: Do certain countries with similar peer to peer network strength and geographic location have similar funded amounts?\n\nWhile strong peer to peer networks are a strong metric to influence funded amounts, here we analyze if countries next to each other have the same strength of peer to peer networks.\n\nAfter clustering neighboring countries, we see if the average MPI of a cluster has an influence over the funded amount of the cluster to understand the impact of a microloan over an entire geographical cluster. Analyzing spillover is important to understand the effect of microloans in lifting entire areas out of poverty. ","2398b0f8":"<img src=\"https:\/\/www-kiva-org.global.ssl.fastly.net\/cms\/kiva_logo_2.png\" alt=\"drawing\" width=\"250px;\"\/>\n\n<font size=\"1\">(Kiva org logo accessed from Kiva.org website - copyright 2019)$<\/font>\n# Kiva.org Microlending Analysis\n\n\n---\n\n\n## Abstract: \nKiva.org is an online crowdfunding platform to extend financial services to poor and financially excluded people around the world. In this project, we intend to build models to estimate the poverty levels of residents in the regions where Kiva has active loans.\n\nWe analyze correlations between funded amounts and the sector\/activity, country and the region's [Multidimensional Poverty Index (MPI)](http:\/\/hdr.undp.org\/en\/2019-MPI), a measure of poverty in a region.\n\nWe then predict funded amounts given parameters such as MPI, sector etc and also classify payment interval patterns. We also briefly attempt to analyze the data for bias in lending.\n\n---\n\n## Authors: \n\nIshaan Malhi - UC Berkeley, M.Eng in EECS\n\nZiqian Qin - UC Berkeley, M.Eng. in EECS\n\n---\n\nSubmitted for the fulfillment of the Data 200 Graduate Student Project - \n\nOption 1. Link: http:\/\/www.ds100.org\/fa19\/gradproject\/\n\nDataset: https:\/\/www.kaggle.com\/kiva\/data-science-for-good-kiva-crowdfunding\n\nData provided by Kiva.org and Kaggle.com licensed under the CC0: Public Domain License.","7adbd2fe":"From Figure 10 we see that most sectors have a majority repayment interval under monthly payments. **This is surprising even for sectors like Agriculture** where a microloan would be expected to be paid after a long time, or paid irregularly due to the seasonal aspect of Agriculture, especially in developing countries.","254ee836":"##### Clustering \n\nWe have seen above that neighboring countries seem to have similar amounts in funding. We now aim to see if countries can be categorized by the strength of the peer networks, and how stronger peer networks influence loan amounts.","6f8519c6":"We would like to see if the average amount of funded loans is related to the poverty level in these countries.\n\nFigure 4 shows the points of amount of funded loands and MPIs, with the linear regression result.","578a3c19":"## 1. What is the general trend in funded loans? How fast is Kiva.org adopted in countries?","320fd867":"Then try to predict the sector using random forest with the same data.","020c488e":"## [Cleaning & Transforming `borrower_gender` column](#scrollTo=6ul_eBCb9moN)","e3648194":"From Figure 13 We see there is a strong linear correlation between total funded amount and total lender count for nations. **This is somewhat expected and validates our hypothesis**. **As the number of lenders grows, so does the capital\/funds available in a peer to peer network, leading to larger amounts**. We see that the radius of the circles also grow, i.e the total count of funded loans also grows as lender count grows.\n\nWhat's **interesting to note is that the points on the graph are towards the upper left of what a linear regression line would look like**. This means that countries with lower number of lenders also get higher funded amounts. Therefore, a stronger peer to peer microloan network might not mean more lenders, but lenders willing to invest larger amounts of money.\n\n**We now see the reason behind the large difference between Kenya and Cameroon's total funded amounts. Cameroon has very few lenders (~29k) while Kenya has ~1M lenders on the Kiva.org network. Even though the two countries have similar MPIs, their funded amounts differ.** Note however, that this could also be due to Kiva.org not pushing into Cameroon as aggresively, differences in cultural norms around lending and various other societal factors that we do not show.\n\nWe will analyze the correlation between lender count and funded amount in the next sections.\n\n[Jump to Lender Count vs Funded Amount Analysis](#scrollTo=C3_ywSKU-tbb&line=3&uniqifier=1)","448e26af":"Descriptions of ohter tables can be acquired from  https:\/\/www.kaggle.com\/kiva\/data-science-for-good-kiva-crowdfunding. We don't put them here.","21cee0a2":"# 3. Exploratory Data Analysis","ff3b81b6":"From Figure 14, we find that the residuals are not symmetric, indicating our linear regression does not perform well on the data.\n\nThe validation loss is also not quite satisfactory. \n\nSo our data design can be improved. Since there is no obvious patterns in the residual plots, it might be hard to explore a good way to transform the data. Therefore we currently skip this approach.\n\nOur hypothesis of predicting MPI is invalidated to a certain extent. However, this does not mean microloans do not have an impact, but rather that we need more data points to understand factors that influence the MPI of a region.","210c3ff2":"Perform a Linear Regression on all sectors:","8f9b7c9a":"#### Q3. Do certain sectors contribute more to the MPI and amount of loans?\n\nTask: Can we predict sector using MPI and amount of loans\n\nPredicting a sector can help microloan providers understand the best sectors to invest in given fixed capital\/funds for a given region (via the region's MPI). On paper, this approach ignores the feasibility of an actual sector in a region. Certain regions might not have the infrastructure to support a sector even though the loan data shows the best possible sector.\n\nFirst we will use simple Logistic Regression.","31df7b5c":"In our experiments, we find that the optimal hyperparameters are not quite stable. \n\nConsidering the time of computation, we will suggest using `max_depth=15` and `n_estimators=25`. \n\nIn general, the best validation accuracy could be above 0.50, which is better than logistic regression.\n\nDraw the decision boundaries with above parameters:\n\nThe boundaries seems a little more stable.\n\n","475ffd97":"From Figure 12 we see that countries with similar MPI have a large difference between the total funded amount. Specifically, Cameroon (MPI 0.202, funded_amount=\\$875K, count=2230) is not given as many funds as Kenya (MPI = 0.209, sum=\\$32.2M, count=75825). There are subtleties here in the data we do not capture such as MPI between regions and microloans per region which could explain this difference between the two countries. It is also possible that Cameroon and Kenya have different peer to peer networks, and Kenya's p2p network is stronger.\n\nWe thus analyze the strength (in terms of lender count) of different countries."}}