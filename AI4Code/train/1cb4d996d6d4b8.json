{"cell_type":{"1a7bba3d":"code","69cd1efe":"code","ef245f9b":"code","fa48fb47":"code","7684cc63":"code","8dc3c277":"code","b3c0bb78":"code","eb52416f":"code","2b2cd86d":"code","723cf967":"code","71ed9d27":"code","a2fc0239":"code","2ba382b6":"code","93c3fccf":"code","ffb4d991":"code","b7a6dbc6":"code","2963f322":"code","2f92d5bb":"code","132703dc":"code","75e687ac":"code","ec3dd048":"code","c492e849":"code","62113c0a":"code","bcbb9042":"code","23da981c":"code","6e624113":"code","adfb4067":"code","3f9e1149":"code","f175b62e":"code","30c3f111":"code","078720b8":"code","f23ce9af":"code","dd7049f2":"code","9a028c9a":"code","5dc348aa":"code","9aee638d":"code","53410db0":"code","9cc738ed":"code","07d1e354":"code","0e495fbb":"code","46afdd97":"code","d3191d4b":"code","18749db5":"code","b9cf1112":"code","da349011":"code","51096553":"code","e6e14dfe":"code","969b845e":"code","4b69fe1a":"code","ee4c1d7b":"code","bcc13de4":"code","35960dbc":"code","70d4d5e0":"code","eace7ba6":"code","fed3af18":"code","2f6ed312":"code","27a8fd1e":"code","4d658c67":"code","2b3ad7ca":"code","3d5f3fa6":"code","ee9146a7":"code","621b9633":"code","de6cb7e5":"code","01531345":"markdown","52cbe1f8":"markdown","5792e881":"markdown","0a98cc25":"markdown","92461ed0":"markdown","4c6f5f3c":"markdown","77f88fd1":"markdown","bb8be053":"markdown","c02e4196":"markdown","4f637821":"markdown","0791669a":"markdown","0ef3785c":"markdown","778caa03":"markdown","d595be1a":"markdown","6467c141":"markdown","cecfb558":"markdown","09c0f0c3":"markdown","28561b47":"markdown"},"source":{"1a7bba3d":"import pandas as pd \nimport numpy as np\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder","69cd1efe":"%matplotlib inline\nsns.set(color_codes=True)\npal = sns.color_palette(\"Set2\", 10)\nsns.set_palette(pal)","ef245f9b":"train = pd.read_csv('..\/input\/hackerearth-how-not-to-lose-a-customer-in-10-days\/train.csv')\ntest = pd.read_csv('..\/input\/hackerearth-how-not-to-lose-a-customer-in-10-days\/test.csv')","fa48fb47":"train.shape","7684cc63":"train.info()","8dc3c277":"train.isnull().sum()","b3c0bb78":"for col in train.columns:\n    if col not in ['customer_id','Name',  'security_no','referral_id','last_visit_time','joining_date','avg_frequency_login_days'] and train[str(col)].dtype != 'float64':\n        x = train.groupby(str(col))[str(col)].count().sort_values(ascending=False)\n        df = pd.DataFrame({str(col):x.index,'count':x.values})\n        \n        print(df.to_string(index=False))\n        print(\".............................\")","eb52416f":"for col in test.columns:\n    if col not in ['customer_id','Name',  'security_no','referral_id','last_visit_time','joining_date','avg_frequency_login_days'] and train[str(col)].dtype != 'float64':\n        x = test.groupby(str(col))[str(col)].count().sort_values(ascending=False)\n        df = pd.DataFrame({str(col):x.index,'count':x.values})\n        \n        print(df.to_string(index=False))\n        print(\".............................\")","2b2cd86d":"## Dropping rows with -1 churn risk\n\nl=[]\nfor i in range(train.shape[0]):\n    if(train['churn_risk_score'][i]==-1):\n        l.append(i)\n        \ntrain = train.drop(l,axis=0)\n","723cf967":"ab = train[train['avg_frequency_login_days']!='Error']\nab['avg_frequency_login_days'] = ab['avg_frequency_login_days'].astype('float64')\nposmean = ab[ab['avg_frequency_login_days']>0]['avg_frequency_login_days'].mean()","71ed9d27":"sns.displot(ab, x=\"avg_frequency_login_days\", kind=\"kde\",hue='churn_risk_score')","a2fc0239":"## Handling avg_frequency_login_days error value and negative values\n\nl = []\nfor i in train['avg_frequency_login_days']:\n    if i =='Error' or '-' in str(i):\n        l.append(posmean)\n    else:\n        l.append(i)\n        \ntrain['avg_frequency_login_days'] = l\ntrain['avg_frequency_login_days'] = train['avg_frequency_login_days'].astype('float64')\n\n\nl = []\nfor i in test['avg_frequency_login_days']:\n    if i =='Error' or '-' in str(i):\n        l.append(posmean)\n    else:\n        l.append(i)\n        \ntest['avg_frequency_login_days'] = l\ntest['avg_frequency_login_days'] = test['avg_frequency_login_days'].astype('float64')","2ba382b6":"sns.displot(train, x=\"avg_frequency_login_days\", kind=\"kde\",hue='churn_risk_score')","93c3fccf":"## With whole Data\n\nsns.displot(train, x=\"days_since_last_login\", kind=\"kde\",hue='churn_risk_score')","ffb4d991":"#Without Garbage Value\n\n\ndsllp = train[train['days_since_last_login']>0]\nsns.displot(dsllp, x=\"days_since_last_login\", kind=\"kde\",hue='churn_risk_score')","b7a6dbc6":"mu = np.mean(dsllp['days_since_last_login'])\nsigma = np.std(dsllp['days_since_last_login'])\nnp.random.seed(13)\ns = np.random.normal(mu, sigma, 100000).astype('int64')","2963f322":"## Handling days_since_last_login -999\n\n\nimport random\nnp.random.seed(13)\nl = []\nfor i in train['days_since_last_login']:\n    if i == -999:\n        num =0\n        f = True\n        while f:\n            num =random.choice(s)\n            if num>0 and num<=26:\n                l.append(num)\n                f=False\n    else:\n        l.append(i)\n        \ntrain['days_since_last_login'] = l\n\n\n\nl = []\nfor i in test['days_since_last_login']:\n    if i == -999:\n        num =0\n        f = True\n        while f:\n            num =random.choice(s)\n            if num>0 and num<=26:\n                l.append(num)\n                f=False\n    else:\n        l.append(i)\n        \ntest['days_since_last_login'] = l","2f92d5bb":"# After Handling Garbage Values\n\nsns.displot(train, x=\"days_since_last_login\", kind=\"kde\",hue='churn_risk_score')","132703dc":"## For Points in Wallet\n\n### Before Handling missing values\n\nsns.displot(train, x=\"points_in_wallet\", kind=\"kde\",hue='churn_risk_score')","75e687ac":"## Checking various distributions for selecting Imputation method\n\nprint('-------------------------------')\nfor i in range(0,1400,100):\n    print('From '+str(i)+' to '+str(i+100))\n    print('Total no. of observations:', train[(train['points_in_wallet']>i)&(train['points_in_wallet']<i+100)].shape[0])\n    a = train[(train['points_in_wallet']>i)&(train['points_in_wallet']<i+100)].groupby('churn_risk_score').churn_risk_score.count()\n    b = pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\n    print(b.to_string(index=False))\n    \n    print('-------------------------------')","ec3dd048":"print('For Missing Values')\nprint('Total no. of observations:', train[(train['points_in_wallet'].isnull())|(train['points_in_wallet']<0)].shape[0])\na = train[(train['points_in_wallet'].isnull())|(train['points_in_wallet']<0)].groupby('churn_risk_score').churn_risk_score.count()\nb =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\nprint(b.to_string(index=False))","c492e849":"## imputing 0 \n\nl = []\nnp.random.seed(13)\nr= np.random.uniform(500,1000,100000)\ns = set(train['points_in_wallet'])\nfor i in train['points_in_wallet']:\n    if (i not in s) or (i<0) :\n        l.append(random.choice(r))\n    else:\n        l.append(i)\ntrain['points_in_wallet'] = l\n\n\nl = []\ns = set(test['points_in_wallet'])\nfor i in test['points_in_wallet']:\n    if (i not in s) or i<0 :\n        l.append(random.choice(r))\n    else:\n        l.append(i)\ntest['points_in_wallet'] = l","62113c0a":"## After Handling Missing Values\n\nsns.displot(train, x=\"points_in_wallet\", kind=\"kde\",hue='churn_risk_score')\n","bcbb9042":"## Handling Region Category\ns = ['Town','City','Village']\nfor i in s: \n    a = train[train['region_category']==i].groupby('churn_risk_score').churn_risk_score.count()\n    b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\n    print('For ', i)\n    print('Total no. of observations : ', train[train['region_category']==i].shape[0])\n    print(b.to_string(index=False))\n    print('-------------------------------')","23da981c":"a = train[train['region_category'].isnull()].groupby('churn_risk_score').churn_risk_score.count()\nb =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\nprint('For missing values')\nprint(b.to_string(index=False))","6e624113":"## Imputing Town\n\nl = []\nfor i in train['region_category']:\n    if i in [np.nan]:\n        l.append('Town')\n    else:\n        l.append(i)\n\ntrain['region_category'] = l\n\n\nl = []\nfor i in test['region_category']:\n    if i in [np.nan]:\n        l.append('Town')\n    else:\n        l.append(i)\n\ntest['region_category'] = l\n\n","adfb4067":"s = set(train['preferred_offer_types'])\nfor i in s: \n    if i not in [np.nan]:\n        a = train[train['preferred_offer_types']==i].groupby('churn_risk_score').churn_risk_score.count()\n        b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\n        print('For ', i)\n        print('Total no. of observations : ', train[train['preferred_offer_types']==i].shape[0])\n        print(b.to_string(index=False))\n        print('-------------------------------')\n    else:\n        a = train[train['preferred_offer_types'].isnull()].groupby('churn_risk_score').churn_risk_score.count()\n        b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\n        print('For ', i)\n        print('Total no. of observations : ', train[train['preferred_offer_types'].isnull()].shape[0])\n        print(b.to_string(index=False))\n        print('-------------------------------')","3f9e1149":"## Imputing Without Offers\n\nl = []\nfor i in train['preferred_offer_types']:\n    if i in [np.nan]:\n        l.append('Without Offers')\n    else:\n        l.append(i)\n\ntrain['preferred_offer_types'] = l\n\n\nl = []\nfor i in test['preferred_offer_types']:\n    if i in [np.nan]:\n        l.append('Without Offers')\n    else:\n        l.append(i)\n\ntest['preferred_offer_types'] = l","f175b62e":"a = train[train['preferred_offer_types']=='Without Offers'].groupby('churn_risk_score').churn_risk_score.count()\nb =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\nprint('For ', i)\nprint('Total no. of observations : ', train[train['preferred_offer_types']=='Without Offers'].shape[0])\nprint(b.to_string(index=False))\nprint('-------------------------------')","30c3f111":"for col in train.columns:\n    if '?' in set(train[str(col)]):\n        print(col)","078720b8":"s = set(train['joined_through_referral'])\nfor i in s: \n    a = train[train['joined_through_referral']==i].groupby('churn_risk_score').churn_risk_score.count()\n    b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\n    print('For ', i)\n    print('Total no. of observations : ', train[train['joined_through_referral']==i].shape[0])\n    print(b.to_string(index=False))\n    print('-------------------------------')","f23ce9af":"# Imputing Yes\n\nl = []\nnp.random.seed(13)\nr = ['Yes','Yes','No']\nfor i in train['joined_through_referral']:\n    if i in ['?']:\n        l.append(random.choice(r))\n    else:\n        l.append(i)\n\ntrain['joined_through_referral'] = l\n\n\nl = []\nfor i in test['joined_through_referral']:\n    if i in ['?']:\n        l.append(random.choice(r))\n    else:\n        l.append(i)\n\ntest['joined_through_referral'] = l","dd7049f2":"## For medium of operation\n\ns = set(train['medium_of_operation'])\nfor i in s: \n    a = train[train['medium_of_operation']==i].groupby('churn_risk_score').churn_risk_score.count()\n    b =  pd.DataFrame({'Churn Risk Score': a.index, '%age':a.values*100\/a.values.sum()})\n    print('For ', i)\n    print('Total no. of observations : ', train[train['medium_of_operation']==i].shape[0])\n    print(b.to_string(index=False))\n    print('-------------------------------')","9a028c9a":"l = []\nfor i in train['medium_of_operation']:\n    if i in ['?']:\n        l.append('Laptop')\n    else:\n        l.append(i)\n\ntrain['medium_of_operation'] = l\n\nl = []\nfor i in test['medium_of_operation']:\n    if i in ['?']:\n        l.append('Laptop')\n    else:\n        l.append(i)\n\ntest['medium_of_operation'] = l","5dc348aa":"train['joining_date'] =  pd.to_datetime(train['joining_date'], format='%Y-%m-%d')\ntest['joining_date'] =  pd.to_datetime(test['joining_date'], format='%Y-%m-%d')","9aee638d":"days = []\nmonths = []\nyears = []\nfor i in train['joining_date']:\n    days.append(i.day)\n    months.append(i.month)\n    years.append(i.year)\n\ntrain['Day'] = days\ntrain['Month'] = months\ntrain['Year'] = years\n\n\n\ndays = []\nmonths = []\nyears = []\nfor i in test['joining_date']:\n    days.append(i.day)\n    months.append(i.month)\n    years.append(i.year)\n\ntest['Day'] = days\ntest['Month'] = months\ntest['Year'] = years","53410db0":"train.head()","9cc738ed":"test.head()","07d1e354":"train.info()","0e495fbb":"X = train.drop(['customer_id','Name','security_no','churn_risk_score','joining_date','referral_id','last_visit_time'],axis=1)\ny = train['churn_risk_score']\nX_test = test.drop(['customer_id','Name','security_no','joining_date','referral_id','last_visit_time'],axis=1)","46afdd97":"cat_cols1 = [col for col in X.columns if X[str(col)].dtype=='object']","d3191d4b":"## region_category\nd1 ={'Village':0, 'Town':1, 'City':2}\nl1=[]\nl2=[]\nfor i in X['region_category']:\n    l1.append(d1[i])\nX['region_category']= l1\n\nfor i in X_test['region_category']:\n    l2.append(d1[i])\nX_test['region_category'] = l2\n\n\n\n## membership_category\nd1 ={'No Membership':0, 'Basic Membership':1, 'Premium Membership':2, 'Silver Membership':3,'Gold Membership':4,'Platinum Membership':5  }\nl1=[]\nl2=[]\nfor i in X['membership_category']:\n    l1.append(d1[i])\nX['membership_category']= l1\n\nfor i in X_test['membership_category']:\n    l2.append(d1[i])\nX_test['membership_category']= l2\n\n\n\n##internet_options\nd1 ={'Without Offers':0, 'Credit\/Debit Card Offers':1, 'Gift Vouchers\/Coupons':2}\nl1=[]\nl2=[]\nfor i in X['preferred_offer_types']:\n    l1.append(d1[i])\nX['preferred_offer_types']= l1\n\nfor i in X_test['preferred_offer_types']:\n    l2.append(d1[i])\nX_test['preferred_offer_types'] = l2\n\n\n\n##internet_options\nd1 ={'Mobile_Data':0, 'Wi-Fi':1, 'Fiber_Optic':2}\nl1=[]\nl2=[]\nfor i in X['internet_option']:\n    l1.append(d1[i])\nX['internet_option']= l1\n\nfor i in X_test['internet_option']:\n    l2.append(d1[i])\nX_test['internet_option'] = l2\n\n\n\n\n##complaint_status\nd1 ={'Unsolved':0, 'Not Applicable':1, 'No Information Available':2, 'Solved in Follow-up':3, 'Solved':4}\nl1=[]\nl2=[]\nfor i in X['complaint_status']:\n    l1.append(d1[i])\nX['complaint_status']= l1\n\nfor i in X_test['complaint_status']:\n    l2.append(d1[i])\nX_test['complaint_status'] = l2\n\n\n\n##feedback\nd1 ={'Reasonable Price':1, 'Quality Customer Care':1, 'Too many ads':0, 'User Friendly Website':1, 'Poor Customer Service':0, 'No reason specified':0, 'Products always in Stock':1, 'Poor Website':0, 'Poor Product Quality':0 }\nl1=[]\nl2=[]\nfor i in X['feedback']:\n    l1.append(d1[i])\nX['feedback']= l1\n\nfor i in X_test['feedback']:\n    l2.append(d1[i])\nX_test['feedback'] = l2\n","18749db5":"cat_cols = [col for col in X.columns if X[str(col)].dtype=='object']\nnum_cols = [col for col in X.columns if X[str(col)].dtype!='object']","b9cf1112":"cat_cols_n = []\ni = 0\nfor col in X.columns:\n    if(X[str(col)].dtype=='object'):\n        cat_cols_n.append(i)\n    i = i+1","da349011":"le = LabelEncoder()\nfor col in cat_cols:\n    X[str(col)] = le.fit_transform(X[str(col)])\n    X_test[str(col)] = le.transform(X_test[str(col)])","51096553":"X","e6e14dfe":"plt.figure(figsize=(20,10))\nsns.heatmap(X.corr(),annot=True,vmin=-1,vmax=1,cmap='coolwarm')","969b845e":"from sklearn.feature_selection import mutual_info_classif\nplt.figure(figsize=(10,10))\nimp = mutual_info_classif(X,y)\nfeat_imp = pd.Series(imp,X.columns)\nfeat_imp.plot(kind='barh', color='pink')\nplt.show()","4b69fe1a":"len(X.columns)","ee4c1d7b":"X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2,random_state=42)","bcc13de4":"lg = LGBMClassifier()\nlg.fit(X_train,y_train)\ny_pred_l = lg.predict(X_dev)\nf1_score(y_dev,y_pred_l,average='macro')","35960dbc":"rf = RandomForestClassifier()\nrf.fit(X_train,y_train)\ny_pred_r = rf.predict(X_dev)\nf1_score(y_dev,y_pred_r,average='macro')","70d4d5e0":"xg = XGBClassifier(objective = 'multi:softprob')\nxg.fit(X_train,y_train)\ny_pred_x = xg.predict(X_dev)\nf1_score(y_dev,y_pred_x,average='macro')","eace7ba6":"from mlxtend.feature_selection import SequentialFeatureSelector\nffs =SequentialFeatureSelector(lg,k_features='best',forward=True, n_jobs=-1)\nffs.fit(X_train,y_train)\nfeatures = list(ffs.k_feature_names_)","fed3af18":"from mlxtend.feature_selection import SequentialFeatureSelector\nffs =SequentialFeatureSelector(rf,k_features='best',forward=True, n_jobs=-1)\nffs.fit(X_train,y_train)\nfeatures2 = list(ffs.k_feature_names_)","2f6ed312":"print(features)","27a8fd1e":"print(features2)","4d658c67":"lg.fit(X_train[features],y_train)\ny_pred_l = lg.predict(X_dev[features])\nf1_score(y_dev,y_pred_l,average='macro')","2b3ad7ca":"rf.fit(X_train[features2],y_train)\ny_pred_r = rf.predict(X_dev[features2])\nf1_score(y_dev,y_pred_r,average='macro')","3d5f3fa6":"df = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':lg.predict(X_test[features])})\ndf.to_csv('submit.csv',index=False)","ee9146a7":"df2 = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':xg.predict(X_test)})\ndf2.to_csv('submit2.csv',index=False)","621b9633":"df3 = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':rf.predict(X_test[features2])})\ndf3.to_csv('submit3.csv',index=False)","de6cb7e5":"df4 = pd.DataFrame({'customer_id':test['customer_id'],'churn_risk_score':(df['churn_risk_score']+df3['churn_risk_score'])\/\/2})\ndf4.to_csv('submit4.csv',index=False)","01531345":"## Data Prep done, now we will continue with Model Building","52cbe1f8":"## Handling Missing values","5792e881":"Less churn risk score tend to have more points","0a98cc25":"## There are some values with '?' also, Lets Handle them","92461ed0":"### Handling days_since_last_login -999 values, we will NORMALLY distribute over all values","4c6f5f3c":"### Data doesnot match any feature specifically, so we can assume this must be an other device like Tablet\/Ipad or Laptop etc.","77f88fd1":"## Handling Garbge Values","bb8be053":"## Will Keep updating, Stay tuned ","c02e4196":"### It matches with town and city data, therefore we will go with most frequent that is Town","4f637821":"## Baseline Model","0791669a":"### Missing Data more similar to Without offer and it makes sense also!!","0ef3785c":"Missing values match with data that is less than 0, Its Possible that missing values must be 0 points ","778caa03":"# EDA\/ DATA PREP","d595be1a":"WE HAVE SUCCESSFULLY SYNTHESISED THE -999 DATA","6467c141":"### Perfectly Synthesised Missing Values","cecfb558":"## Feature Selection (Forward Selection)","09c0f0c3":"## Handling Date column","28561b47":"### Missing Data is simillar to Yes and No both, but more like Yes, So not deisturbing the balance Lets impute YES in probability of 0.66 randomly"}}