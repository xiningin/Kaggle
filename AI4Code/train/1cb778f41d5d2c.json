{"cell_type":{"34a23405":"code","2fbe9fe9":"code","8531f1e3":"code","963d87cc":"code","b8bedc2f":"code","618c90cc":"code","9c977831":"markdown","7eaff5ce":"markdown","9d0cf56d":"markdown","7ec949f6":"markdown","5546dd34":"markdown","f5427ed4":"markdown"},"source":{"34a23405":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pds # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\nfrom plotly.subplots import make_subplots\nfrom plotly import graph_objs as go\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\n\nimport tensorflow as tf\n\n!pip install tabnet\nimport tabnet\n\nXLA_ACCELERATE = True\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\n\nbatch_size=500","2fbe9fe9":"tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0],True)\n","8531f1e3":"raw_data=pds.read_csv(os.path.join(dirname,'train.csv'),index_col='id')\nraw_test=pds.read_csv(os.path.join(dirname,'test.csv'),index_col='id')\nsubs=pds.read_csv(os.path.join(dirname,'sample_submission.csv'))\nraw_data['income']=raw_data.income.apply(lambda x: 1 if x=='>50K' else 0)\ntarget=tf.keras.utils.to_categorical(raw_data.pop('income'))","963d87cc":"all_data=pds.concat([raw_data,raw_test])\n\nle=LabelEncoder()\nfor col in all_data.columns:\n    le.fit(all_data[col])\n    raw_data[col]=le.transform(raw_data[col])\n    raw_test[col]=le.transform(raw_test[col])","b8bedc2f":"kf=KFold(shuffle=True)\ntest_preds=[]\n\n# test_ds = df_to_dataset(raw_test, shuffle=False, batch_size=batch_size)\n\nif not os.path.exists('model'):os.mkdir('model')\n    \nfor n,(tr_idx,vl_idx) in enumerate(kf.split(raw_data)):\n    print(f'Fold {n} Start!\\n'*3)\n#     train_ds = df_to_dataset(raw_data.iloc[tr_idx], batch_size=batch_size, labels='income')\n#     val_ds = df_to_dataset(raw_data.iloc[vl_idx], shuffle=False, batch_size=batch_size, labels='income')\n    x_tr,x_vl=raw_data.iloc[tr_idx].astype(np.float64),raw_data.iloc[vl_idx].astype(np.float64)\n    y_tr,y_vl=target[tr_idx],target[vl_idx]\n\n\n    model = tabnet.TabNetClassifier(None, num_features=x_tr.shape[1],\n                                           num_classes=2,\n                                          feature_dim=128,\n                                          output_dim=64,\n                                          num_decision_steps=6,\n                                          relaxation_factor=1.5,\n                                          batch_momentum=0.7,\n                                          virtual_batch_size=None,\n                                          )\n\n    model.compile(tf.keras.optimizers.Adam(),\n                  tf.keras.losses.CategoricalCrossentropy(),\n                  metrics='AUC')\n\n    model.fit(x_tr,y_tr,\n              batch_size=batch_size,\n              epochs=1000,\n              validation_data=(x_vl,y_vl),\n              callbacks=[tf.keras.callbacks.EarlyStopping(\n                                min_delta = 1e-4, \n                                patience = 20, \n                                mode = 'min', \n                                baseline = None, \n                                restore_best_weights = True\n                            ),\n                         tf.keras.callbacks.ModelCheckpoint(f'model-Tabnet-fold{n}',\n                                                            save_best_only = True,\n                                                            save_weights_only = True, \n                                                            mode = 'min')\n                        ])\n    \n    test_preds.append(model.predict(raw_test.astype(np.float64)))","618c90cc":"subs.prediction=np.array(test_preds).mean(0).argmax(-1)\n\nsubs.to_csv('tabnet.csv',index=False)","9c977831":"![](https:\/\/i.imgur.com\/Bdy7IWC.png)\n\n\uc606\ub3d9\ub124 MoA\uc5d0\uc11c \uc870\uba85\ubc1b\ub294 TabNet\uc785\ub2c8\ub2e4 \n\npaper link : https:\/\/arxiv.org\/abs\/1908.07442\n\n\ubd84\ub958 \uc131\ub2a5 \ud3c9\uac00\ub97c \uc704\ud55c Open dataset\uc5d0\uc11c \uaf64 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uace0 \uc788\uc2b5\ub2c8\ub2e4\n\n\uc6b0\ub9ac\uac00 \ub300\ud68c\ub85c \uc0ac\uc6a9\ud558\ub294 Adult census dataset \ub610\ud55c \ubaa8\ub378\uac80\uc99d\uc5d0 \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4\n\n\ud558\uc9c0\ub9cc Adult dataset\uc73c\ub85c \uc131\ub2a5\ud3c9\uac00\ubcf4\ub2e4\ub294 interpretablility\uc5d0 \uc911\uc810\uc744 \ub450\uc5b4 feature\ub4e4\ub9c8\ub2e4 rank\ub97c \ub9e4\uae34 \uac83\uc774 \ud2b9\uc774\uc0ac\ud56d\uc774\uaca0\ub124\uc694\n\n![](https:\/\/i.imgur.com\/42wYk9h.png)\n\nTabnet encoder\ub97c \ud65c\uc6a9\ud558\uc5ec \ucd94\uac00\uc801\uc73c\ub85c feature selection \ub610\ub294 adjusted feature weight \ub4f1\uc744 \uc2dc\ub3c4\ud574\ubcfc \uc218 \uc788\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4\n\nOfficial code\ub294 covertype\uacfc mnist, iris\ub9cc \ucc3e\uc744 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4\n\ncovertype\uc5d0\uc11c \uc0ac\uc6a9\ud55c parameter\ub85c \uba3c\uc800 \ud559\uc2b5\uc744 \uc9c4\ud589\ud574\ubcf4\uc558\uace0 \ud574\ub2f9 \ubc29\ubc95\uc744 \uac04\ub2e8\ud788 \uc2e4\ud589\ud558\ub294 \ucf54\ub4dc\ub97c \uacf5\uc720\ud574\ub4dc\ub9bd\ub2c8\ub2e4\n\n\ubcf4\ub2e4 \uc88b\uc740 parameter\ub97c \ucc3e\uc544 \uacf5\uc720\ud574\uc8fc\uc2e0\ub2e4\uba74 \ubaa8\ub450\uc758 \ubc1c\uc804\uc5d0 \ud070 \ub3c4\uc6c0\uc774 \ub420 \uac83 \uac19\uc544\uc694 :)","7eaff5ce":"\ucd9c\ub825 \uac12\uc740 \ub450 \ud074\ub798\uc2a4\uc758 \ud655\ub960\uac12\uc73c\ub85c \uc5bb\uc5b4\uc9d1\ub2c8\ub2e4\n\n\uac01 fold\ubcc4\ub85c \uc5bb\uc740 \ud655\ub960\uc744 \ubaa8\ub450 \ub354\ud55c \ub4a4 \ud655\ub960\uc774 \ub354 \ud070 \ucabd\uc744 \uc120\ud0dd\ud558\uc5ec submission\uc744 \uc81c\ucd9c\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4","9d0cf56d":"\ub17c\ubb38\uc5d0\uc11c\ub294 Covertype dataset\uc744 \ud559\uc2b5\ud560 \ub54c, \ucd08\uae30 learning rate\ub97c 0.02\ub85c \uc124\uc815\ud558\uace0, decaying learning rate\ub97c \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4\n\n\ud558\uc9c0\ub9cc \uac04\ub2e8\ud55c \uc2e4\uc2b5\uc744 \uc704\ud574 Adam optimizer\ub97c \ubcc4\ub2e4\ub978 \uc870\uac74 \uc5c6\uc774 \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4\n\n5-Fold\ub85c \ud559\uc2b5\uc744 \uc9c4\ud589\ud558\uba70 early stopping criterion\uc744 \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4","7ec949f6":"data\ub85c\ubd80\ud130 target\uc744 \ubd84\ub9ac\ud574\ub0b4\uace0 >50k \ub97c 1\ub85c, \ub2e4\ub978\uacbd\uc6b0\ub97c 0\uc73c\ub85c \ubc14\uafd4\uc8fc\uaca0\uc2b5\ub2c8\ub2e4","5546dd34":"\uc990\uac70\uc6b4 \uce90\uae00 \ub418\uc138\uc694 :)","f5427ed4":"String categorical value\ub4e4\uc744 \uc22b\uc790\ub85c \ubc14\uafd4\uc8fc\uaca0\uc2b5\ub2c8\ub2e4"}}