{"cell_type":{"dc7e3f26":"code","a58e717b":"code","0679d0ed":"code","15be59d0":"code","0954901b":"code","3b7a7ec9":"code","5612fed8":"code","186ffd17":"code","1f36313b":"code","9b8786bc":"code","d44a21a6":"code","ea17f910":"code","19502eec":"code","7145505c":"code","df2b39f5":"code","eb21b8b8":"code","8e38b8e9":"code","a6f7506e":"code","9485bcf5":"code","05077ecb":"code","b39eddc6":"code","37e85a0e":"code","e94a5c15":"code","1e1d7b29":"code","b0d0fcec":"code","cf421933":"code","eb2555e8":"code","62b5e1a1":"code","81fd89c2":"code","13555ef8":"code","79db36fd":"code","57a1c643":"code","dfe2e387":"code","067308f3":"code","2fb85b4f":"code","3d248fb2":"code","781fa33b":"code","461dbe9f":"code","b24ab711":"code","2b592ae9":"code","937653c3":"code","af556f37":"code","958792e4":"code","7f9a2276":"markdown","c72fa7f5":"markdown","de207ecb":"markdown","0a8e0422":"markdown","527167cf":"markdown","dc7076d0":"markdown","6e8db3f7":"markdown","a6755344":"markdown","e780529c":"markdown","465c0ac2":"markdown","ed5e86b6":"markdown","8dfb5384":"markdown","b92a234a":"markdown","6777168c":"markdown","b568dd5a":"markdown"},"source":{"dc7e3f26":"!pip install rank_bm25 nltk\n!pip install scispacy\n!pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_md-0.2.4.tar.gz","a58e717b":"import numpy as np # linear algebra\nimport os\nimport json\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nimport re\nimport string\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom rank_bm25 import BM25Okapi\nimport spacy\nimport  scispacy\nfrom nltk.tokenize import sent_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nimport pandas as pd","0679d0ed":"df = pd.DataFrame(columns=['paper_id', 'title', 'abstract', 'body_text'])\ni = 0\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename.endswith('.json')==True:\n            dic = json.loads(open(os.path.join(dirname, filename), 'r').read())\n            id  = dic['paper_id']\n            title = dic['metadata']['title']\n            if title.strip()=='':\n                title = None\n            abstract = dic['abstract']\n            abstract_list = []\n            for a in abstract:\n                t = a['text']\n                abstract_list.append(t)\n            abstract_string = '\\n'.join(abstract_list)\n            \n            if abstract_string == '':\n                abstract_string = None\n\n            body_text = dic['body_text']\n            body_texts_list = []\n            for text in body_text:\n                t = text['text']\n                body_texts_list.append(t)\n                \n            body_text_string = '\\n'.join(body_texts_list)\n            body_text_string = body_text_string.strip()\n            if body_text_string == '':\n                body_text_string = None\n                \n            df.loc[i] = [id, title, abstract_string, body_text_string]\n            i+=1\n                \n            ","15be59d0":"## Set the paper id as the index\ndf = df.set_index('paper_id')","0954901b":"print (df.info())","3b7a7ec9":"df.describe()","5612fed8":"### Remove the null values\ndf.dropna(inplace=True)","186ffd17":"df.info()","1f36313b":"### Create a copy of the dataframe and work on that\ndf_work = df.copy()","9b8786bc":"# medium model\nimport en_core_sci_md\nnlp = en_core_sci_md.load(disable=[\"tagger\", \"parser\", \"ner\"])\nnlp.max_length = 2000000","d44a21a6":"# New stop words list \ncustomize_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.',\n    'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da',  'dell',  'non', 'si'\n]\n\n# Mark them as stop words\nfor w in customize_stop_words:\n    nlp.vocab[w].is_stop = True","ea17f910":"stop_words = nlp.Defaults.stop_words","19502eec":"def spacy_tokenizer(sentence):\n    return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)]","7145505c":"s = ' i am a good-boy , i (am rishav) ?'\nspacy_tokenizer(s)","df2b39f5":"df_work['body_text'] = df_work['body_text'].apply(spacy_tokenizer)\ndf_work['abstract'] = df_work['abstract'].apply(spacy_tokenizer)\ndf_work['title'] = df_work['title'].apply(spacy_tokenizer)","eb21b8b8":"df_work['body_text'] = df_work['body_text'].apply(lambda x: ' '.join(x))\ndf_work['abstract'] = df_work['abstract'].apply(lambda x: ' '.join(x))\ndf_work['title'] = df_work['title'].apply(lambda x: ' '.join(x))\n","8e38b8e9":"df_work.head()","a6f7506e":"paper_ids = df_work.index\nid_2_paper = {}\nfor i, id in enumerate(paper_ids):\n    id_2_paper[i] = id\n","9485bcf5":"df_work['append_title_abstract'] = df_work['title'] + ' ' + df_work['abstract'] ","05077ecb":"corpus = df_work['append_title_abstract'].tolist()\ntokenized_corpus = [doc.split(\" \") for doc in corpus]\nbm25 = BM25Okapi(tokenized_corpus)","b39eddc6":"from IPython.display import display, Markdown","37e85a0e":"def markdown_print(line):\n    print(line)","e94a5c15":"def suggestPapers(query):\n    top_20_papers = []\n    query_pre = spacy_tokenizer(query)\n    doc_scores = bm25.get_scores(query_pre)\n    doc_scores = [(score, ind) for ind, score in enumerate(doc_scores)]\n    doc_scores = sorted(doc_scores, reverse = True)\n    doc_score_top_20 = doc_scores[:20]\n    for d in doc_score_top_20:\n        i = d[1]\n        top_20_papers.append((paper_ids[i], d[0]))\n        \n    suggested_papers_dict = {}\n    for ele in top_20_papers:\n        suggested_papers_dict[ele[0]] = ele[1]\n        \n    for paper in top_20_papers[:5]:\n        markdown_print (\"Paper Id: \" +paper[0])\n        markdown_print(\"Title: \"+df.loc[paper[0]]['title'])\n        markdown_print (\"-----\")\n    return top_20_papers, suggested_papers_dict","1e1d7b29":"def show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stop_words,\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(12, 12))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","b0d0fcec":"def create_paper_lines(suggested_papers):\n    paper_lines = []\n    for paper in suggested_papers:\n        text = df.loc[paper[0]]['abstract']\n        sentences = [(sent.strip(), paper[0]) for sent in sent_tokenize(text)]\n        sentences_2_s = []\n        for i in range(0, len(sentences)-1):\n            sent1 = sentences[i][0]\n            sent2 = sentences[i+1][0]\n            sent = sent1 + ' ' + sent2\n            sentences_2_s.append((sent, sentences[i][1]))\n        paper_lines.extend(sentences_2_s)\n    return paper_lines","cf421933":"def create_wordcloud(paper_lines):\n    word_cloud_data = []\n    for line, id in paper_lines:\n        word_cloud_data.append(line)\n    show_wordcloud(word_cloud_data)","eb2555e8":"def create_mapping(paper_lines):\n    id_paper_line_paper_id = {}\n    for i, tup in enumerate(paper_lines):\n        id_paper_line_paper_id[i] = (tup[0], tup[1])\n    return id_paper_line_paper_id\n\ndef create_paper_lines_index(paper_lines):\n    paper_lines_fmtd = []\n    for line in paper_lines:\n        paper_lines_fmtd.append(\" \".join(spacy_tokenizer(line[0])))\n    tokenized_paper_lines = [doc.split(\" \") for doc in paper_lines_fmtd]\n    bm25_task1 = BM25Okapi(tokenized_paper_lines)\n    return bm25_task1","62b5e1a1":"def top_lines_suggestor(task, bm25_task1, id_paper_line_paper_id):\n    top_50_lines = []\n    task1_pre = spacy_tokenizer(task)\n    line_scores = bm25_task1.get_scores(task1_pre)\n    line_scores = [(score, ind) for ind, score in enumerate(line_scores)]\n    line_scores = sorted(line_scores, reverse = True)\n    line_scores_top_50 = line_scores[:50]\n    for l in line_scores_top_50:\n        i = l[1]\n        paper_id = id_paper_line_paper_id[i][1]\n        actual_line = id_paper_line_paper_id[i][0]\n        line_score = l[0]\n        paper_score = suggested_papers_dict[paper_id]\n        net_score = paper_score * line_score\n        top_50_lines.append((actual_line, net_score, paper_id))\n    top_ten_sorted = sorted(top_50_lines, key = lambda x: x[1], reverse=True)[:20]\n    for line in top_ten_sorted:\n        markdown_print (\"Paper line: \" +line[0])\n        markdown_print (\"Paper id: \" +  line[2])\n        markdown_print (\"Similarity Score: \" + str(line[1]))\n        markdown_print (\"-----\")","81fd89c2":"task1 = 'Range of incubation periods for the disease in humans (and how this varies across age and health status) \\\nand how long individuals are contagious,even after recovery.'\nsuggested_papers, suggested_papers_dict = suggestPapers(task1)  ### TOP SUGGESTED PAPERS","13555ef8":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","79db36fd":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task1, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","57a1c643":"task2 = 'Prevalence of asymptomatic shedding and transmission (e.g., particularly children).'\nsuggested_papers, suggested_papers_dict = suggestPapers(task2)  ### TOP SUGGESTED PAPERS","dfe2e387":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","067308f3":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task1, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","2fb85b4f":"task3 = 'Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).'\nsuggested_papers, suggested_papers_dict = suggestPapers(task3)  ### TOP SUGGESTED PAPERS","3d248fb2":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","781fa33b":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task3, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","461dbe9f":"task4 = 'Immune response and immunity'\nsuggested_papers, suggested_papers_dict = suggestPapers(task4)  ### TOP SUGGESTED PAPER4","b24ab711":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","2b592ae9":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task4, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","937653c3":"task5 = 'Natural history of the virus and shedding of it from an infected person'\nsuggested_papers, suggested_papers_dict = suggestPapers(task5)  ### TOP SUGGESTED PAPER4","af556f37":"paper_lines = create_paper_lines(suggested_papers)\nshow_wordcloud(paper_lines)  ### Show the wordcloud for the given topic, what words are prevlant","958792e4":"id_paper_line_paper_id = create_mapping(paper_lines)  \nbm25_task = create_paper_lines_index(paper_lines)\ntop_lines_suggestor(task5, bm25_task, id_paper_line_paper_id) ### Print the top lines in the potential papers","7f9a2276":"### Download the Dependencies","c72fa7f5":"### Let's take title and abstract for paper search","de207ecb":"### Persistence of virus on surfaces of different materials (e,g., copper, stainless steel, plastic).\n","0a8e0422":"### Let's find the lines in the Paper talking about the given Query\n* Here, we are picking all the top 20 papers and forming a coupus of all pair from them. \n* This will be our corpus where we will be searching our query on.","527167cf":"### Prevalence of asymptomatic shedding and transmission (e.g., particularly children).**","dc7076d0":"### Paper to index mapping","6e8db3f7":"### Natural history of the virus and shedding of it from an infected person**","a6755344":"### Immune response and immunity","e780529c":"## Aim of the Notebook \n\n* Given a Query, Search for related papers. \n* Papers are searched using their Title and Abstract \n* Once potential papers are searched, find specific lines in the Papers talking about the given query.\n* Using BM25 Algorithm, used for creating search engines and also to search lines in Potential papers.  \n  Read about the algorithm: [https:\/\/en.wikipedia.org\/wiki\/Okapi_BM25]\n* FINAL OUTCOME: Find the right papers for a given query, and then highlight\/find right lines in the paper.\n* Discliamer: Data Analysis \/ Visualization is not done extensively. THE FOCUS IS ON CREATING ALGORITHM WHICH AND FIND RIGHT LINES IN THE PAPERS DEALING WITH THE GIVEN QUERY.\n\n    ","465c0ac2":"### Preprocessing ","ed5e86b6":"### Analysis of Incubation periods and Recovery time","8dfb5384":"### Potential papers which could contain what we want","b92a234a":"### Load All Papers (Jsons) in a Dataframe","6777168c":"### Create a index of the Papers","b568dd5a":"### Import the dependencies"}}