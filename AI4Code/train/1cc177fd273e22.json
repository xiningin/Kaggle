{"cell_type":{"3094affb":"code","09cf255b":"code","d0f0459f":"code","5f7c18d6":"code","e7e59d13":"code","5deec00d":"code","69c1ac76":"code","125b96ef":"code","f130fc9f":"code","d9de4864":"code","0ace6246":"code","9fb17ceb":"code","7f42ef70":"code","7249a16f":"code","9ba7469c":"code","8d709fd3":"code","3d11720c":"code","27899f4c":"code","68ba4526":"code","f3ba8350":"code","7be9778a":"code","70dac6eb":"markdown","ac41fd13":"markdown"},"source":{"3094affb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","09cf255b":"#------------------------------------------------------------------------------\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom xgboost import XGBRegressor","d0f0459f":"#------------------------------------------------------------------------------\n#load dataset\ntrain = pd.read_csv(\"..\/input\/train.csv\")\n\n#save and drop train id\ntrain_id = train[\"Id\"]\ntrain.drop(columns='Id',inplace=True)\n\n#select object columns\nobj_col = train.columns[train.dtypes == 'object'].values\n\n#select non object columns\nnum_col = train.columns[train.dtypes != 'object'].values\n\n#replace null value in obj columns with None\ntrain[obj_col] = train[obj_col].fillna('None')\n\n#replace null value in numeric columns with 0\ntrain[num_col] = train[num_col].fillna(0)","5f7c18d6":"#Encode ordinal features\nordinal_features = [\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\n                    \"BsmtFinType1\",\"BsmtFinType2\",\"HeatingQC\",\"Electrical\",\"KitchenQual\",\n                    \"FireplaceQu\",\"GarageQual\",\"GarageCond\",\"PoolQC\"]\n\nExterQual_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nExterCond_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1}\nBsmtQual_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nBsmtCond_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nBsmtExposure_map = {\"Gd\":5,\"Av\":4,\"Mn\":3,\"No\":2,\"None\":1}\nBsmtFinType1_map = {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,\"None\":0}\nBsmtFinType2_map = {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1,\"None\":0}\nHeatingQC_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1}\nElectrical_map = {\"SBrkr\":5,\"FuseA\":4,\"FuseF\":3,\"FuseP\":2,\"Mix\":1,\"None\":0}\nKitchenQual_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nFireplaceQu_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nGarageQual_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nGarageCond_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"Po\":1,\"None\":0}\nPoolQC_map = {\"Ex\":5,\"Gd\":4,\"TA\":3,\"Fa\":2,\"None\":1}\n\ntrain[\"ExterQual\"] = train[\"ExterQual\"].map(ExterQual_map)\ntrain[\"ExterCond\"] = train[\"ExterCond\"].map(ExterCond_map)\ntrain[\"BsmtQual\"] = train[\"BsmtQual\"].map(BsmtQual_map)\ntrain[\"BsmtCond\"] = train[\"BsmtCond\"].map(BsmtCond_map)\ntrain[\"BsmtExposure\"] = train[\"BsmtExposure\"].map(BsmtExposure_map)\ntrain[\"BsmtFinType1\"] = train[\"BsmtFinType1\"].map(BsmtFinType1_map)\ntrain[\"BsmtFinType2\"] = train[\"BsmtFinType2\"].map(BsmtFinType2_map)\ntrain[\"HeatingQC\"] = train[\"HeatingQC\"].map(HeatingQC_map)\ntrain[\"Electrical\"] = train[\"Electrical\"].map(Electrical_map)\ntrain[\"KitchenQual\"] = train[\"KitchenQual\"].map(KitchenQual_map)\ntrain[\"FireplaceQu\"] = train[\"FireplaceQu\"].map(FireplaceQu_map)\ntrain[\"GarageQual\"] = train[\"GarageQual\"].map(GarageQual_map)\ntrain[\"GarageCond\"] = train[\"GarageCond\"].map(GarageCond_map)\ntrain[\"PoolQC\"] = train[\"PoolQC\"].map(PoolQC_map)","e7e59d13":"# Encode nominal features\nnominal_features = [x for x in obj_col if x not in ordinal_features]\n\n# Transfer object to int\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\n\n# for loop nominal feature column\nfor _ in train[nominal_features].columns:\n    #fit and transform each column and assign to itself\n    train[_] = labelencoder.fit_transform(train[_])\n\n# Get dummy variable for nominal features\ntrain = pd.get_dummies(train,columns=nominal_features,drop_first=True)\n\n# Check if any null values\ntrain.isnull().any().sum()","5deec00d":"#------------------------------------------------------------------------------\n# Split data to X(features)  and y(target)\n# X should be in matrix form and y shoud be in array form\nX = train.drop(columns=\"SalePrice\").values\ny = train[\"SalePrice\"].values","69c1ac76":"#------------------------------------------------------------------------------\n# Split data to train dataset and test dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)","125b96ef":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\ntrain_scaler = StandardScaler()\nX_train_scaler = train_scaler.fit_transform(X_train)\n\ntest_scaler = StandardScaler()\nX_test_scaler = test_scaler.fit_transform(X_test)","f130fc9f":"#------------------------------------------------------------------------------\n# Feature Importance\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators = 100,random_state=1,n_jobs=1)\nforest.fit(X_train_scaler,y_train)\n\n# Grid Search - 1\nfrom sklearn.model_selection import GridSearchCV\nparameters = [{'n_estimators':[10,100],\n               'min_samples_split':[2,4],\n               'min_samples_leaf':[1,2]}]\n    \ngrid_search = GridSearchCV(estimator = forest,\n                           param_grid = parameters,\n                           cv = 5,\n                           n_jobs = -1)\n\ngrid_search = grid_search.fit(X_train_scaler,y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\n\nforest = RandomForestRegressor(n_estimators = 100,\n                               min_samples_leaf = 1,\n                               min_samples_split = 4,\n                               random_state = 1,\n                               n_jobs = 1)\n\nforest.fit(X_train_scaler,y_train)","d9de4864":"#------------------------------------------------------------------------------\n# Feature Selection\nfrom sklearn.feature_selection import SelectFromModel\nsfm = SelectFromModel(forest,threshold = 0.0005,prefit=True)\nX_selected  = sfm.transform(X_train_scaler)","0ace6246":"#------------------------------------------------------------------------------\n# Fit into linear regression model\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X_selected,y_train)\ny_pred = reg.predict(sfm.transform(X_test_scaler))\nnp.sqrt(((y_pred - y_test)**2).sum())","9fb17ceb":"#------------------------------------------------------------------------------\n# Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = reg,X = X_selected, y = y_train,cv=10)\naccuracies.mean(),accuracies.std()","7f42ef70":"#------------------------------------------------------------------------------\n# Fit into XGB linear regression model\n\nxgb = XGBRegressor(n_estimators = 100,learning_rate=0.08,gamma=0,subsample=0.75,\n                   colsample_bytree = 1,max_depth=7)\n\nxgb.fit(X_selected,y_train)\n\ny_pred_xgb = xgb.predict(sfm.transform(X_test_scaler))","7249a16f":"#------------------------------------------------------------------------------\n# Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = xgb,X = X_selected, y = y_train,cv=10)\naccuracies.mean(),accuracies.std()","9ba7469c":"#------------------------------------------------------------------------------\n#load dataset\ntest = pd.read_csv(\"..\/input\/test.csv\")","8d709fd3":"# Save Id\ntest_id = test[\"Id\"]\n\n# Drop Id column\ntest.drop(columns=[\"Id\"],inplace=True)\n\n#select object columns\nobj_col = test.columns[test.dtypes == 'object'].values\n\n#select non object columns\nnum_col = test.columns[test.dtypes != 'object'].values\n\n#replace null value in obj columns with None\ntest[obj_col] = test[obj_col].fillna('None')\n\n#replace null value in numeric columns with 0\ntest[num_col] = test[num_col].fillna(0)","3d11720c":"#------------------------------------------------------------------------------\n\ntest[\"ExterQual\"] = test[\"ExterQual\"].map(ExterQual_map)\ntest[\"ExterCond\"] = test[\"ExterCond\"].map(ExterCond_map)\ntest[\"BsmtQual\"] = test[\"BsmtQual\"].map(BsmtQual_map)\ntest[\"BsmtCond\"] = test[\"BsmtCond\"].map(BsmtCond_map)\ntest[\"BsmtExposure\"] = test[\"BsmtExposure\"].map(BsmtExposure_map)\ntest[\"BsmtFinType1\"] = test[\"BsmtFinType1\"].map(BsmtFinType1_map)\ntest[\"BsmtFinType2\"] = test[\"BsmtFinType2\"].map(BsmtFinType2_map)\ntest[\"HeatingQC\"] = test[\"HeatingQC\"].map(HeatingQC_map)\ntest[\"Electrical\"] = test[\"Electrical\"].map(Electrical_map)\ntest[\"KitchenQual\"] = test[\"KitchenQual\"].map(KitchenQual_map)\ntest[\"FireplaceQu\"] = test[\"FireplaceQu\"].map(FireplaceQu_map)\ntest[\"GarageQual\"] = test[\"GarageQual\"].map(GarageQual_map)\ntest[\"GarageCond\"] = test[\"GarageCond\"].map(GarageCond_map)\ntest[\"PoolQC\"] = test[\"PoolQC\"].map(PoolQC_map)\n\n# Encode nominal features\nnominal_features = [x for x in obj_col if x not in ordinal_features]\n\n# Transfer object to int\nlabelencoder = LabelEncoder()\n# for loop nominal feature column\nfor _ in test[nominal_features].columns:\n    #fit and transform each column and assign to itself\n    test[_] = labelencoder.fit_transform(test[_])\n\n# Get dummy variable for nominal features\ntest = pd.get_dummies(test,columns=nominal_features,drop_first=True)\n\ntest.isnull().any().sum()","27899f4c":"# Get missing columns in the training test\nmissing_cols = set(train.drop(columns=\"SalePrice\").columns) - set(test.columns)\n\n# Add a missing column in test set with default value equal to 0\nfor cols in missing_cols:\n    test[cols] = 0\n    \n# Ensure the order of column in the test set is in the same order than in train set\ntest = test[train.drop(columns=\"SalePrice\").columns]\n\n# Split data to X(features)\ntest_X = test.values","68ba4526":"#------------------------------------------------------------------------------\n# Feature Scaling\ntest_X_scaler = StandardScaler()\ntest_X_scaler = test_X_scaler.fit_transform(test_X)","f3ba8350":"#------------------------------------------------------------------------------\n# Feature selection\ntest_X_selected = sfm.transform(test_X_scaler)","7be9778a":"#------------------------------------------------------------------------------\n# Make prediction\ntest_y_pred = xgb.predict(test_X_selected)\n\nsubmission = pd.DataFrame({'Id':test_id,'SalePrice':test_y_pred})\n\n# Save results\nsubmission.to_csv(\"submission0924.csv\",index=False)","70dac6eb":"# Apply on test data set","ac41fd13":"# Linear & XGB Regression - novice\nHi there, This is Alex and I am new to machine learning.\nThis notebook is my first work on kagge.com.\nI am willing to learn so any advice on my work is highly appreciated.\n\nThis notebook consists of below parts:\n*  `1.`Handle missing data\n*  `2.`Encode ordinal and nominal categorical data\n*  `3.`Split data to X(features) and y(target),then to train\/test data set using **train_test_split from SKLEARN**\n*  `4.`Feature Scaling using **StandardScaler from SKLEARN**\n*  `5.`Feature Importance using **RandomForestRegressor from SKLEARN**\n*  `6.`Grid Search using **GridSearchCV from SKLEARN**\n*  `7.`Feature Selection using **SelectFromModel from SKLEARN**\n*  `8.`Fit into linear regression model **LinearRegression from SKLEARN**\n*  `9.`Cross Validation  **cross_val_score**\n*  `10.`Fit into XGB linear regression model  **XGBRegressor from xgboost**\n*  `11.`Cross Validation  **cross_val_score**\n*  `12.`Apply on test dataset and make prediction'\n\nI am stilling learning and will keep updating."}}