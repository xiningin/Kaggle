{"cell_type":{"9206f242":"code","84ea8fea":"code","b40b669c":"code","089bd623":"code","48ab4c48":"code","b3a5b416":"code","c7651f38":"code","87befeaf":"code","18940bd8":"code","9cf92cd4":"code","a69e88e8":"markdown","c45d2059":"markdown","f5faf9f1":"markdown","25bb3b0b":"markdown"},"source":{"9206f242":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\ndef estimate(data, price, k):\n    prices = data[price].to_numpy(dtype=np.float64)\n    log_prices = np.log(prices)\n    rets = np.diff(log_prices)\n    T = len(rets)\n    mu = np.mean(rets)\n    var_1 = np.var(rets, ddof=1, dtype=np.float64)\n    rets_k = (log_prices - np.roll(log_prices, k))[k:]\n    m = k * (T - k + 1) * (1 - k \/ T)\n    var_k = 1\/m * np.sum(np.square(rets_k - k * mu))\n\n    # Variance Ratio\n    vr = var_k \/ var_1\n    \n    # Phi2\n    def delta(j):\n        res = 0\n        for t in range(j+1, T+1):\n            t -= 1  # array index is t-1 for t-th element\n            res += np.square((rets[t]-mu)*(rets[t-j]-mu))\n        return res \/ ((T-1) * var_1)**2\n\n    phi2 = 0\n    for j in range(1, k):\n        phi2 += (2*(k-j)\/k)**2 * delta(j)\n\n    return vr, (vr - 1) \/ np.sqrt(phi2), T\n\ndef estimate_multiple_k(data, price, time_intervals):\n    # Estimate different time_intervals.\n    for time_interval in time_intervals:\n        vr, stat2, T = estimate(data, price, time_interval)\n        print('The number of observations : ' + str(T))\n        print('Variance Ratio for k = ' + str(time_interval) + ' : ' + str(vr))\n        print('Variance Ratio Test Statistic for k = ' + str(time_interval) + ' Heteroscedasticity Assumption : ' + str(stat2))\n        print('-------------------------------------------------------------------------------------------------')","84ea8fea":"local_path = \"..\/input\/w1-data-2022-spring\/\"\n\nus_index = pd.read_csv(local_path + 'w1_data.csv', na_values=['.'])\nus_index['date'] = pd.to_datetime(us_index['Date'], format='%Y%m%d')","b40b669c":"#Replace \"eindend\" with \"vindend\" for price argument\nestimate_multiple_k(us_index, \"vindend\", [2,4,6,8,16,32,64])","089bd623":"try:\n    import yfinance as yf    # import  Yahoo! Finance\nexcept:\n    !pip install yfinance    # install Yahoo! Finance\n    import yfinance as yf    # import  Yahoo! Finance","48ab4c48":"#function to highlight assets with rejected H0\ndef only_H1(tickers, start_dte, end_dte, time_intervals):\n    for i in tickers:\n        data = yf.download(i, start = start_dte, end=end_dte, progress=False)\n        \n        for interval in time_intervals:\n            vr, stat2, T = estimate(data, \"Adj Close\", interval)\n            if vr!=1 and abs(stat2) > 2:\n                print (f\"{i} has variance ratio {round(vr,4)} for interval {interval} days. Heteroscedasticity assumption: {round(stat2,4)}\")\n            else:\n                continue","b3a5b416":"#Play around with tickers to include, and time intervals.\nticker_list = [\"ARKK\", \"ICLN\", \"URA\", \"NVDA\", \"JPYUSD=X\" ]\ntime_intervals = [5,10,20,50,90,100,180,200]\nonly_H1(ticker_list, \"2012-01-25\", \"2022-01-25\", time_intervals)","c7651f38":"df_msf = pd.read_csv(\"..\/input\/msf-200901202012\/msf_200901-202012.csv\", na_values=[\"B\", \"C\", \"\"], parse_dates=[\"date\"])\n\n# The output from WRDS returns a mixed of small and large cap column names. Let's standardize everything in small caps.\ncols = df_msf.columns\nprint(cols)\nprint(type(cols))\n\n# List comprehension [expression for variable in iterable]\ndf_msf.columns = [c.lower() for c in cols]\n\n# Sanitize dataset\n\n# Drop observations with missing returns\ndf_msf = df_msf[df_msf.ret.notnull()]\n\n# Take the absolute value of the price\ndf_msf[\"prc\"] = np.abs(df_msf[\"prc\"])\n\n# Set the index (to select easily on date)\ndf_msf = df_msf.set_index(\"date\")\ndf_msf = df_msf.sort_index()\n\n# Compute continuously compounded returns (i.e. log returns).\ndf_msf[\"lret\"] = np.log(1 + df_msf[\"ret\"])\ndf_msf[\"lvwretd\"] = np.log(1 + df_msf[\"vwretd\"])\ndf_msf[\"lewretd\"] = np.log(1 + df_msf[\"ewretd\"])\n\n# Compute the market cap\ndf_msf[\"size\"] = df_msf[\"shrout\"] * df_msf[\"prc\"]","87befeaf":"form_period = 36  # 36 Formation period, in month\nstart_msf = \"2012-01-01\"\nend_msf = \"2020-12-01\"\n\n# Get the dates of portfolio formation.\n# The frequency tells how far apart to put the dates.\n# 'M' stand for month, 'MS' is for month start, to make sure we\n# have first day of the month. It needs to be a string, so we convert\n# our numbers to string.\ndates_msf = pd.date_range(\n    start=start_msf, end=end_msf, freq=str(np.int(form_period)) + \"M\"\n)","18940bd8":"def get_portfolio_performance(dates, df, form_period=36, n_stocks=35,\n                                   benchmark='ewretd', weighting = \"ew\", hold_period = 36, partition = \"permno\"):\n    \"\"\"\n    Function computes the average returns of all portfolios formed from the form period, returns both the bottom and top portfolios\n    \n    Parameters:\n        dates (list): List of dates for formation period\n        df (pandas.DataFrame): original dataframe source \n        form_period (int): the number of months used to lookback and form the portfolio\n        n_stocks (int): the number of stocks to form the portfolio \n        benchmark (str): the benchmark used, either value weighted or equal weighted. See column name in df\n        weighting (str): either value or equal weighted. \n        hold_period (int): number of months to hold the portfolio \n        partition (str): type of partition to be used\n    Returns:\n        tuple: contains 2 dataframes, the bottom portfolio and top portfolio\n    \"\"\"\n    portfolios = {}\n    bottom_portfolio_ret = []\n    top_portfolio_ret = []\n    \n    for date in dates:\n        portfolios[date] = compute_performance_portfolios(date, df, form_period, n_stocks, benchmark, partition)\n    \n    for date in dates:\n        bottom_portfolio_ret.append(compute_holding_returns(date, portfolios[date][0], df, benchmark, weighting, hold_period, partition))\n        top_portfolio_ret.append(compute_holding_returns(date, portfolios[date][1], df, benchmark, weighting, hold_period, partition))\n    \n    bottom_portfolio_ret = pd.concat(bottom_portfolio_ret)\n    top_portfolio_ret = pd.concat(top_portfolio_ret)\n    \n    return bottom_portfolio_ret, top_portfolio_ret\n\ndef plot_portfolio_performance(bottom_portfolio_ret, top_portfolio_ret, form_period, periodicity):\n    grads = []\n    i = periodicity\n    while(i < form_period):\n        grads.append(i)\n        i += periodicity\n        \n    ax = bottom_portfolio_ret.groupby('months')['exret'].mean().plot(label='Past losers')\n    top_portfolio_ret.groupby('months')['exret'].mean().plot(ax=ax, label='Past winners')\n    ax.legend()\n    ax.axhline(y=0,  color='black', alpha=0.5, linestyle=':')\n    for grad in grads:\n        ax.axvline(x=grad, color='black', alpha=0.5, linestyle='-')\n        #ax.axvline(x=24, color='black', alpha=0.5, linestyle='-')\n    return ax\n\ndef compute_holding_returns(date, portfolio, df, benchmark='ewretd', weighting='ew',\n                            hold_period=36, partition = \"permno\"):\n    \"\"\"\n    Function computes the average returns of a given portoflio previously generated by compuete_performance_portfolio() \n    \n    Parameters:\n        date (np.datetime): The date at which to start looking\n        portfolio (pandas.DataFrame): dataframe slice from compute_performance_portfolio()\n        df (pandas.DataFrame): original dataframe source \n        benchmark (str): the benchmark used, either value weighted or equal weighted. See column name in df\n        weighting (str): either value or equal weighted. \n        partition (str): type of partition to be used\n    Returns:\n        dataframe: portfolio returns \n    \"\"\"\n    \n    port = portfolio.copy()\n    end_dt = date + pd.offsets.MonthBegin(1) * hold_period\n    # Select obs for the formation period\n    crsp_t2 = df[date:end_dt].copy()\n    # Merge with stocks in portfolios, to keep only those stocks\n    crsp_t2 = pd.merge(crsp_t2.reset_index(), port, on=[partition])\n    crsp_t2\n    \n\n    # Get the dates in the dataset.\n    pairs_t2 = [{'date': d, partition: p} for d in crsp_t2['date'].unique() for p in port[partition].unique()]\n    pairs_t2 = pd.DataFrame(pairs_t2)\n    pairs_t2\n    crsp_t2 = pd.merge(crsp_t2, pairs_t2, how='outer', on=[partition, 'date'])\n    ret_cols = ['ret', 'vwretd', 'ewretd', 'lvwretd','lewretd', 'lret', 'lexret']\n    crsp_t2[ret_cols] = crsp_t2[ret_cols].fillna(0.0)\n    \n    # Now we want the return up to each point in time\n    crsp_t2['lcumret'] = crsp_t2.groupby(partition)['lret'].cumsum()\n    crsp_t2['lcum' + benchmark] = crsp_t2.groupby(partition)['l' + benchmark].cumsum()\n\n    # At each point in time, the return of the portfolio will be the \n    # cumulative return of each component weighted by the initial weight.\n    # Note that here we need the simple return average, not log return.\n    crsp_t2['cumret'] = np.exp(crsp_t2['lcumret']) - 1\n    crsp_t2['cum' + benchmark] = np.exp(crsp_t2['lcum' + benchmark]) - 1\n\n    # Add weights, equal weighted is easy.\n    port['ew'] = 1 \/ len(port)\n\n    # For value-weighted, need to get size as of formation date.\n    port['date'] = date\n    weights = pd.merge_asof(port, df[[partition, 'size']],\n                            by=partition,\n                            left_on='date',\n                            right_index=True)\n    weights['vw'] = weights['size'] \/ weights['size'].sum()\n\n    del weights['lexret']\n    del weights['date']\n    del weights['size']\n    \n    # Now merge back with returns\n    crsp_t2 = pd.merge(crsp_t2, weights, on=partition)\n    \n    # Now compute the weighted cumulative return \n    crsp_t2['wcumret'] = crsp_t2[weighting] * crsp_t2['cumret']\n    crsp_t2['wcum' + benchmark] = crsp_t2[weighting] * crsp_t2['cum' + benchmark]\n\n    portfolio_ret = crsp_t2.groupby(['date'])[['wcumret', 'wcum' + benchmark]].sum()\n    \n    # Count the months\n    portfolio_ret = portfolio_ret.reset_index()\n    portfolio_ret['months'] = portfolio_ret.index.values + 1\n    \n    portfolio_ret['exret'] = portfolio_ret['wcumret'] - portfolio_ret['wcum' + benchmark]\n    \n    return portfolio_ret\n\ndef compute_performance_portfolios(\n    date, df, form_period=36, n_stocks=35, benchmark=\"ewretd\", partition=\"permno\"\n):\n    \"\"\"\n    Function computes the performance portfolios, separated into bottom and top performing portfolios\n    \n    Parameters:\n        date (np.datetime): The date at which to start looking\n        df (pandas.DataFrame): dataframe source \n        form_period (int): the number of months used to lookback and form the portfolio\n        n_stocks (int): the number of stocks to form the portfolio \n        benchmark (str): the benchmark used, either value weighted or equal weighted. See column name in df\n        partition (str): type of partition to be used\n    Returns:\n        tuple: tuple containing the bottom and top portfolios\n    \"\"\"\n    beg_dt = (\n        date - pd.offsets.MonthEnd(1) * form_period\n    )  # find 36months before the first date\n    end_dt = date - pd.offsets.MonthEnd(1)\n    # Select obs for the formation period\n    crsp_t = df[beg_dt:end_dt].copy()\n\n    # We only want to keep stocks that are there during the full formation window\n    crsp_t[\"N\"] = crsp_t.groupby([partition])[partition].transform(\"count\")\n    max_form = max(crsp_t[\"N\"])\n\n    # Filter on number of observations. We only keep stocks for which we have returns\n    # over the full observation period.\n    crsp_t = crsp_t[crsp_t[\"N\"] >= form_period]\n    if len(crsp_t) == 0:\n        end_dt = date + pd.offsets.MonthBegin(1)\n        crsp_t = df[beg_dt:end_dt].copy()\n        crsp_t[\"N\"] = crsp_t.groupby([partition])[partition].transform(\"count\")\n        crsp_t = crsp_t[crsp_t[\"N\"] >= form_period]\n\n    # Now for each stock we want to compute the full period return. Easy with log returns, just sum up!\n    stock_ret = crsp_t.groupby(partition)[[\"lret\", \"lvwretd\", \"lewretd\"]].sum()\n\n    # Next compute excess returns based on the chosen index.\n    # Note that since the benchmark is the same for all stocks, we could use\n    # actual returns for ranking purposes.\n    stock_ret[\"lexret\"] = stock_ret[\"lret\"] - stock_ret[\"l\" + benchmark]\n\n    # Now rankings.\n    stock_ret[\"rank_asc\"] = stock_ret[\"lexret\"].rank()  # (1 = worst return)\n    stock_ret[\"rank_inv\"] = stock_ret[\"lexret\"].rank(\n        ascending=False\n    )  # (1= best return)\n\n    # Assign stock to top or bottom portfolio\n    top_portfolio = stock_ret[stock_ret.rank_inv <= n_stocks].reset_index()[\n        [partition, \"lexret\"]\n    ]\n    bottom_portfolio = stock_ret[stock_ret.rank_asc <= n_stocks].reset_index()[\n        [partition, \"lexret\"]\n    ]\n\n    return (bottom_portfolio, top_portfolio)\n\ndef get_mean_excess_returns(portfolio, end_month, end_year = '1980'):\n    \"\"\"\n    Function prints the mean excess returns of the portfolio, and checks if it deviates\n    significantly from 0. \n    \n    Paramters:\n        portfolio (pandas.DataFrame): 1 of the either portfolios formed from get_portfolio_performance()\n        end_month (int): the ending month (e.g 36 for the end of the portfolio)\n        end_year (int): year at which to end the observation\n    Returns:\n        null \n    \"\"\"\n    tset, pval = stats.ttest_1samp(portfolio[portfolio['months'] == end_month].set_index('date')[:end_year]['exret'], 0)\n    print(\"Mean Excess Return: \" + str(portfolio[portfolio['months'] == end_month].set_index('date')[:end_year]['exret'].mean()))\n    res = \"Do Not Reject Null Hypothesis\" if (pval > .05) else \"Reject Null Hypothesis\"\n    print(\"P-Value: \" + str(pval) + \", \" + res)\n\ndef get_diff_excess_returns(portfolio1, portfolio2, end_month, end_year = '1980'):\n    \"\"\"\n    Function prints the difference in excess returns of 2 portfolios, and checks if it deviates\n    significantly from 0. \n    \n    Paramters:\n        portfolio1 (pandas.DataFrame): 1 of the either portfolios formed from get_portfolio_performance()\n        portfolio2 (pandas.DataFrame): 1 of the either portfolios formed from get_portfolio_performance()\n        end_month (int): the ending month (e.g 36 for the end of the portfolio)\n        end_year (int): year at which to end the observation\n    Returns:\n        null \n    \"\"\"\n    mean_ret_1 = portfolio1[portfolio1['months'] == end_month].set_index('date')[:end_year]['exret'].mean()\n    mean_ret_2 = portfolio2[portfolio2['months'] == end_month].set_index('date')[:end_year]['exret'].mean()\n    tset, pval = stats.ttest_ind(portfolio1[portfolio1['months'] == end_month].set_index('date')[:end_year]['exret'],\n                             portfolio2[portfolio2['months'] == end_month].set_index('date')[:end_year]['exret'])\n    print(\"Mean Excess Return, Top Performers: \" + str(mean_ret_2))\n    print(\"Mean Excess Return, Bottom Performers: \" + str(mean_ret_1))\n    print(\"Mean Difference (Bottom - Top) in Excess Returns: \" + str(mean_ret_1 - mean_ret_2))\n    res = \"Do Not Reject Null Hypothesis\" if (pval > .05) else \"Reject Null Hypothesis\"\n    print(\"P-Value: \" + str(pval) + \", \" + res)","9cf92cd4":"bot_port_ret, top_port_ret = get_portfolio_performance(dates_msf, df_msf)\n\nplot_portfolio_performance(bot_port_ret, top_port_ret, form_period = 36, periodicity = 12)\n\nget_mean_excess_returns(bot_port_ret, end_month = 36, end_year = \"2020\")\n\nget_mean_excess_returns(top_port_ret, end_month = 36, end_year = \"2020\")\n\nget_diff_excess_returns(bot_port_ret, top_port_ret, end_month = 36, end_year = \"2020\")","a69e88e8":"A. General\n1. What do you think of Tesla\u2019s valuation today? Explain. [4]\n\n    <p> Answer: <\/p>\n    <p>Opinion: <br>While Tesla is definitely overvalued, their performance over the traditional automobile companies is not undeserved for the following reasons:<\/p>\n    \n    1. Tesla is unlike traditional automobile companies \n        - They sell directly to customers instead of through dealerships, thus cutting out the middleman and earning higher profits\n        - They are far less capital intensive due to their refusal to build large and expensive assembly plants\n    2. COVID-19 Pandemic\n        - Companies that were more flexible did better than companies that were more rigid in terms of have large manufacturing capacity that they could not modify, high debt, or were committed to dividends\n            - Tesla, due to its make-shift manufacturing style, lower debt than other automobile companies, and never having declared dividends, did much better than the other automobile companies\n        - Young companies benefitted at the expense of mature and aging companies\n            - The difference between Covid-19 and other crises was that risk capital stayed in the game - and they were invested in young companies who were more flexibile than mature companies like Tesla\n    3. Tesla is a tech company as well\n        - For instance, with its self-driving technology, Tesla has the potential to gain much more market share in the ridesharing industry\n        - With climate change as a ever-looming threat, Tesla's electric car model, once it solves its battery issues, will also gain much more market share.\n     \n    \n    Regardless, Tesla is overvalued, for the following reasons:\n     \n    \n\n\n2. If you are a investing decision support Fintech company targeting discretionary active traders, \nhow will you productize the empirical tests and concepts you have learned on efficient market \nhypothesis and behavioural finance? [4]","c45d2059":"The assets highlighted above have variance ratios >1 and test statistic >2 standard deviations (SDs).\n    \nVariance ratios > 1 means positive serial correlation between returns of one period and a previous period.\n\nUnder the empirical rule of normal distributions (Z(k) is asymptomatically normal), <5% of observations occur beyond 2 SDs from the mean.\n    \nZ(k) > 2 SDs implies that the variance ratios of returns being !=1 by chance is less than 5%.","f5faf9f1":"**Question 3**","25bb3b0b":"**Question 4**"}}