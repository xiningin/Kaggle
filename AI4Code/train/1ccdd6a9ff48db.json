{"cell_type":{"6d3b7376":"code","bf8783f7":"code","ffb4237d":"code","a2a7fd6d":"code","19df3abf":"code","7ebc048c":"code","a6c2f114":"code","427d82e2":"code","dba031f2":"code","c4a14398":"code","281dd0bd":"code","f3948d1d":"code","4f111d3d":"code","0929ddb3":"code","ec1a3fa0":"code","ab8eb521":"code","2c5e1027":"code","53f60c0e":"code","d1987812":"code","a5b4718d":"code","f305dcf9":"code","f47c0f13":"code","769ba95a":"code","b8b222c9":"code","86b54cc4":"code","9069f75d":"code","7c8771c5":"code","c2d7ef63":"code","e28ab6dd":"code","68808ad8":"code","cf313876":"code","c08032ee":"code","274f2c94":"code","eb8c2870":"code","6079d9dc":"code","900e8518":"code","4cb14e44":"code","d53b6aef":"code","cd156fb6":"code","6c78703e":"code","5515b1b5":"code","a5b89579":"code","4be65c8b":"code","514cf103":"code","ba1170c8":"code","f2bfb8de":"code","f348e2a9":"code","1840663e":"code","42024369":"code","9b69494a":"code","c3a45faf":"code","12b7095e":"code","55ce53cf":"code","7dc7c101":"code","26588ba4":"code","16e02f62":"code","f8e3e94a":"code","19ed4882":"code","0b24ed69":"code","6de045d4":"code","fdd28e38":"code","bacb1f20":"code","681fb41a":"markdown","00dbbddb":"markdown","3b797626":"markdown","1a0b8b92":"markdown","6e58c258":"markdown","c0772b7a":"markdown","eb94f87f":"markdown","79635bfa":"markdown","19c1b984":"markdown","b14a3171":"markdown","d412f4a9":"markdown","7b68af2f":"markdown","3606ac1b":"markdown","63738271":"markdown","6d2fe469":"markdown","cc94e8c8":"markdown","b67f7ed7":"markdown","56ff0183":"markdown","e4a789ca":"markdown","c30db762":"markdown","64a31422":"markdown","9f5a47e4":"markdown","4d554c2c":"markdown","e626b988":"markdown"},"source":{"6d3b7376":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport matplotlib as plt\nimport folium \nfrom folium import plugins\nfrom fbprophet import Prophet\nimport plotly.offline as py","bf8783f7":"# set up \n\ndataframe = pd.read_csv(\"\/kaggle\/input\/covid19-us-county-jhu-data-demographics\/covid_us_county.csv\")\ndf = dataframe\n\ndf.describe()\n","ffb4237d":"df.tail(50000)","a2a7fd6d":"#Settings for the prediction :)\n\n# you can choose how far in the future should the prediction go and how much high the confidency interval should be\n\n#Amount on months: (1 Month = 30,2 Months = 60, 3 Months = 90)\nmo = 60\n\n#Confidence interval (90% = 0.9, 95% = 0.95, 99% = 0.99)\ncon = 0.95","19df3abf":"#preparing colnames for cases for prediction- group the data by date and sum up cases (also do it for every of the top 5 states)\ncases_CA = df.query('state==\"California\"').groupby('date')[['cases']].sum().reset_index()\ncases_CA = cases_CA.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\n\ncases_PE = df.query('state==\"Pennsylvania\"').groupby('date')[['cases']].sum().reset_index()\ncases_PE = cases_PE.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\n\ncases_MA = df.query('state==\"Massachusetts\"').groupby('date')[['cases']].sum().reset_index()\ncases_MA = cases_MA.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\n\ncases_NY = df.query('state==\"New York\"').groupby('date')[['cases']].sum().reset_index()\ncases_NY = cases_NY.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\n\ncases_IL = df.query('state==\"Illinois\"').groupby('date')[['cases']].sum().reset_index()\ncases_IL = cases_IL.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})","7ebc048c":"#preparing colnames for deaths for prediction same as above just for deaths\ndeaths_CA = df.query('state==\"California\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_CA = deaths_CA.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_CA['ds'] = pd.to_datetime(deaths_CA['ds'])\n\ndeaths_PE = df.query('state==\"Pennsylvania\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_PE = deaths_PE.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_PE['ds'] = pd.to_datetime(deaths_PE['ds'])\n\ndeaths_MA = df.query('state==\"Massachusetts\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_MA = deaths_MA.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_MA['ds'] = pd.to_datetime(deaths_MA['ds'])\n\ndeaths_NY = df.query('state==\"New York\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_NY = deaths_NY.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_NY['ds'] = pd.to_datetime(deaths_NY['ds'])\n\ndeaths_IL = df.query('state==\"Illinois\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_IL = deaths_IL.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_IL['ds'] = pd.to_datetime(deaths_IL['ds'])","a6c2f114":"#Model for CA\nmc_CA = Prophet(interval_width=con)\nmc_CA.fit(cases_CA)\nfuture = mc_CA.make_future_dataframe(periods=mo,include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_CA = mc_CA.predict(future)\nforecast_CA[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_CA = mc_CA.plot(forecast_CA)","427d82e2":"#Model for CA Deaths\nmd_CA = Prophet(interval_width=con)\nmd_CA.fit(deaths_CA)\nfuture_CAD = md_CA.make_future_dataframe(periods=mo, include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_CAD = md_CA.predict(future_CAD)\nforecast_CAD[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_CAD = md_CA.plot(forecast_CAD)","dba031f2":"#Model for PE\nmc_PE = Prophet(interval_width=con)\nmc_PE.fit(cases_PE)\nfuture = mc_PE.make_future_dataframe(periods=mo,include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_PE = mc_PE.predict(future)\nforecast_PE[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_PE = mc_PE.plot(forecast_PE)","c4a14398":"#Model for PE Deaths\nmd_PE = Prophet(interval_width=con)\nmd_PE.fit(deaths_PE)\nfuture_PED = md_PE.make_future_dataframe(periods=mo, include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_PED = md_PE.predict(future_PED)\nforecast_PED[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_PED = md_PE.plot(forecast_PED)","281dd0bd":"#Model for IL\nmc_IL = Prophet(interval_width=con)\nmc_IL.fit(cases_IL)\nfuture = mc_IL.make_future_dataframe(periods=mo,include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_IL = mc_IL.predict(future)\nforecast_IL[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_IL = mc_IL.plot(forecast_IL)","f3948d1d":"#Model for IL Deaths\nmd_IL = Prophet(interval_width=con)\nmd_IL.fit(deaths_IL)\nfuture_ILD = md_IL.make_future_dataframe(periods=mo, include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_ILD = md_PE.predict(future_ILD)\nforecast_ILD[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_ILD = md_IL.plot(forecast_ILD)","4f111d3d":"#Model for MA\nmc_MA = Prophet(interval_width=con)\nmc_MA.fit(cases_MA)\nfuture = mc_MA.make_future_dataframe(periods=mo,include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_MA = mc_MA.predict(future)\nforecast_MA[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_MA = mc_MA.plot(forecast_MA)","0929ddb3":"#Model for MA Deaths\nmd_MA = Prophet(interval_width=con)\nmd_MA.fit(deaths_MA)\nfuture_MAD = md_MA.make_future_dataframe(periods=mo, include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_MAD = md_MA.predict(future_MAD)\nforecast_MAD[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_MAD = md_MA.plot(forecast_MAD)","ec1a3fa0":"#Model for NY Cases\nmc_NY = Prophet(interval_width=con)\nmc_NY.fit(cases_NY)\nfuture = mc_NY.make_future_dataframe(periods=mo, include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_NY = mc_NY.predict(future)\nforecast_NY[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_NY = mc_NY.plot(forecast_NY)","ab8eb521":"#Model for NY Deaths\nmd_NY = Prophet(interval_width=con)\nmd_NY.fit(deaths_NY)\nfuture_D = md_NY.make_future_dataframe(periods=mo, include_history=True) #prediction period 1 month = 30 days\n#future.tail()\n\nforecast_NYD = md_NY.predict(future_D)\nforecast_NYD[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_NY = md_NY.plot(forecast_NYD)","2c5e1027":"com_NY = md_NY.plot(forecast_NYD), mc_NY.plot(forecast_NY)\ncom_PE = md_PE.plot(forecast_PED), mc_PE.plot(forecast_PE)\ncom_MA = md_MA.plot(forecast_MAD), mc_MA.plot(forecast_MA)\ncom_IL = md_IL.plot(forecast_ILD), mc_IL.plot(forecast_IL)\ncom_CA = md_CA.plot(forecast_CAD), mc_CA.plot(forecast_CA)","53f60c0e":"#preparing colnames for cases for prediction test same as preparation in the regular ones just for test\/train data\ncases_CA_test = df.query('state==\"California\"').groupby('date')[['cases']].sum().reset_index() #group cases from california by date and sum cases\ncases_CA_test = cases_CA_test.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\ncases_CA_test = cases_CA_test[:-30] #drop last 30 days\n\ncases_PE_test = df.query('state==\"Pennsylvania\"').groupby('date')[['cases']].sum().reset_index()\ncases_PE_test = cases_PE_test.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\ncases_PE_test = cases_PE_test[:-30]\n\ncases_MA_test = df.query('state==\"Massachusetts\"').groupby('date')[['cases']].sum().reset_index()\ncases_MA_test = cases_MA_test.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\ncases_MA_test = cases_MA_test[:-30]\n\ncases_NY_test = df.query('state==\"New York\"').groupby('date')[['cases']].sum().reset_index()\ncases_NY_test = cases_NY_test.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\ncases_NY_test = cases_NY_test[:-30]\n\ncases_IL_test = df.query('state==\"Illinois\"').groupby('date')[['cases']].sum().reset_index()\ncases_IL_test = cases_IL_test.rename(columns={\"date\": \"ds\", \"cases\": \"y\"})\ncases_IL_test = cases_IL_test[:-30]\n\ncases_IL_test.tail(10)","d1987812":"#preparing colnames for deaths test for prediction same as preparation in the regular ones just for test\/train data\ndeaths_CA_test = df.query('state==\"California\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_CA_test = deaths_CA_test.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_CA_test['ds'] = pd.to_datetime(deaths_CA_test['ds'])\ndeaths_CA_test = deaths_CA_test[:-30]\n\ndeaths_PE_test = df.query('state==\"Pennsylvania\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_PE_test = deaths_PE_test.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_PE_test['ds'] = pd.to_datetime(deaths_PE_test['ds'])\ndeaths_PE_test = deaths_PE_test[:-30]\n\ndeaths_MA_test = df.query('state==\"Massachusetts\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_MA_test = deaths_MA_test.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_MA_test['ds'] = pd.to_datetime(deaths_MA_test['ds'])\ndeaths_MA_test =deaths_MA_test[:-30]\n\ndeaths_NY_test = df.query('state==\"New York\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_NY_test = deaths_NY_test.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_NY_test['ds'] = pd.to_datetime(deaths_NY_test['ds'])\ndeaths_NY_test = deaths_NY_test[:-30]\n\ndeaths_IL_test = df.query('state==\"Illinois\"').groupby('date')[['deaths']].sum().reset_index()\ndeaths_IL_test = deaths_IL_test.rename(columns={\"date\": \"ds\", \"deaths\": \"y\"})\ndeaths_IL_test['ds'] = pd.to_datetime(deaths_IL_test['ds'])\ndeaths_IL_test = deaths_IL_test[:-30]","a5b4718d":"Cases","f305dcf9":"#Model for NY Test Cases\nmc_NY_test = Prophet(interval_width=con)\nmc_NY_test.fit(cases_NY_test)\nfuture = mc_NY_test.make_future_dataframe(periods=30, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_NY_test = mc_NY_test.predict(future)\nforecast_NY_test[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_NY = mc_NY_test.plot(forecast_NY_test)","f47c0f13":"#Model for NY Test Cases\nmd_NY_test = Prophet(interval_width=con)\nmd_NY_test.fit(deaths_NY_test)\nfuture = md_NY_test.make_future_dataframe(periods=30, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_NY_test_d = md_NY_test.predict(future)\nforecast_NY_test_d[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ndeaths_forecast_plot_NY = md_NY_test.plot(forecast_NY_test_d)","769ba95a":"#Model for PE Test Cases\nmc_PE_test = Prophet(interval_width=con)\nmc_PE_test.fit(cases_PE_test)\nfuture = mc_PE_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_PE_test = mc_PE_test.predict(future)\nforecast_PE_test[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_PE = mc_PE_test.plot(forecast_PE_test)","b8b222c9":"#Model for PE Test Cases\nmd_PE_test = Prophet(interval_width=con)\nmd_PE_test.fit(deaths_PE_test)\nfuture = md_PE_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_PE_test_d = md_PE_test.predict(future)\nforecast_PE_test_d[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ndeaths_forecast_plot_PE = md_PE_test.plot(forecast_PE_test_d)","86b54cc4":"#Model for IL Test Cases - I don't know what's the issue here guys\nmc_IL_test = Prophet(interval_width=con)\nmc_IL_test.fit(cases_IL_test)\nfuture = mc_IL_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_IL_test = mc_IL_test.predict(future)\nforecast_IL_test[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_IL_test = mc_IL_test.plot(forecast_IL_test)","9069f75d":"#Model for IL Test Cases\nmd_IL_test = Prophet(interval_width=con)\nmd_IL_test.fit(deaths_IL_test)\nfuture = md_IL_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_IL_test_d = md_IL_test.predict(future)\nforecast_IL_test_d[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ndeaths_forecast_plot_IL = md_IL_test.plot(forecast_IL_test_d)","7c8771c5":"#Model for MA Test Cases\nmc_MA_test = Prophet(interval_width=con)\nmc_MA_test.fit(cases_MA_test)\nfuture = mc_MA_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_MA_test = mc_MA_test.predict(future)\nforecast_MA_test[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_MA = mc_MA_test.plot(forecast_MA_test)","c2d7ef63":"#Model for MA Test Cases\nmd_MA_test = Prophet(interval_width=con)\nmd_MA_test.fit(deaths_MA_test)\nfuture = md_MA_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_MA_test_d = md_MA_test.predict(future)\nforecast_MA_test_d[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ndeaths_forecast_plot_MA = md_MA_test.plot(forecast_MA_test_d)","e28ab6dd":"#Model for CA Test Cases\nmc_CA_test = Prophet(interval_width=con)\nmc_CA_test.fit(cases_MA_test)\nfuture = mc_CA_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_CA_test = mc_CA_test.predict(future)\nforecast_CA_test[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ncases_forecast_plot_CA = mc_CA_test.plot(forecast_CA_test)","68808ad8":"#Model for CA Test Cases\nmd_CA_test = Prophet(interval_width=con)\nmd_CA_test.fit(deaths_CA_test)\nfuture = md_CA_test.make_future_dataframe(periods=mo, include_history=True) #prediction time based on variable mo\n#future.tail()\n\nforecast_CA_test_d = md_CA_test.predict(future)\nforecast_CA_test_d[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\ndeaths_forecast_plot_CA = md_CA_test.plot(forecast_CA_test_d)","cf313876":"us_covid = pd.read_csv('..\/input\/covid19-us-county-jhu-data-demographics\/covid_us_county.csv')\nus_county = pd.read_csv('..\/input\/covid19-us-county-jhu-data-demographics\/us_county.csv')","c08032ee":"# set na as object\nus_covid = us_covid[us_covid.fips.notnull()]\nus_covid['fips'] = us_covid['fips'].astype(object)\nus_county['fips'] = us_county['fips'].astype(object)","274f2c94":"#add the column popultation from the county data\nus_covid = us_covid.merge(us_county[['fips', 'population']], on = ['fips'], how = \"left\")\n\n#cut out every date but the last one, with sorting the dataset and then keeping the latest\nus_cum = us_covid.sort_values(by = ['county', 'state', 'date'], ascending = [True, True, False]) #latest date is on top\nus_cum = us_cum.drop_duplicates(subset = ['county', 'state'], keep = \"first\")                    #cut out every date older than the latest","eb8c2870":"#save a copy\n#counties_us = us_cum.copy()","6079d9dc":"#group by state for state view \nus_cum = us_cum.groupby(['state', 'date'], as_index=False)['cases', 'deaths', 'population'].sum()\n\nus_cum['population'] = us_cum['population'].astype(int)","900e8518":"#rounding population to millions with 2 digits, and creating two new columns called cases per million and deaths per million\nus_cum['population'] = round((us_cum['population']\/1000000),2)\nus_cum = us_cum.rename(columns = {'population': 'Population (million)'})\nus_cum['Cases per Million'] = round((us_cum['cases']\/us_cum['Population (million)']),2)\nus_cum['Deaths per Million'] = round((us_cum['deaths']\/us_cum['Population (million)']),2)","4cb14e44":"\nurl = '..\/input\/usa-states'         # adress of the states file in the input folder\nstate_geo = f'{url}\/usa-states.json' #import the pyligons from the usa states dataset (json file)\n\nbins = list(us_cum['Cases per Million'].quantile([0, 0.5, 0.75, 0.90, 0.95, 1])) # set the steps for the legend\n\nmap1 = folium.Map(location=[34, -118], zoom_start=4)   #creat map and set zoom step and location (autofocus on californias longitude and altitude)\n\nchoropleth = folium.Choropleth(                        #setting for the graph\n    geo_data=state_geo,\n    name='choropleth',\n    data=us_cum,\n    columns=['state', 'Cases per Million'],\n    key_on='properties.name',\n    fill_color= 'PuBuGn',\n    fill_opacity=0.75,\n    line_opacity=0.2,\n    legend_name='Cases per Million',\n    bins = bins,\n    reset = True\n).add_to(map1)\n\nstyle_function = \"font-size: 15px; font-weight: bold\"\nchoropleth.geojson.add_child(\n    folium.features.GeoJsonTooltip(['name'],style=style_function, labels=False)     #mouse over feature for displaying the state names\n)\n\nmap1   # show the map","d53b6aef":"url = '..\/input\/usa-states'          #functions like the graph above just with deaths\nstate_geo = f'{url}\/usa-states.json'\nmap2 = folium.Map(location=[34, -118], zoom_start=4)\n\nbins = list(us_cum['Deaths per Million'].quantile([0, 0.5, 0.75, 0.90, 0.95, 1]))\n\nchoropleth = folium.Choropleth(\n    geo_data=state_geo,\n    name='choropleth',\n    data=us_cum,\n    columns=['state', 'Deaths per Million'],\n    key_on='properties.name',\n    fill_color= 'PuBuGn',\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name='Deaths per Million',\n    bins = bins,\n    reset = True\n).add_to(map2)\n\nstyle_function = \"font-size: 15px; font-weight: bold\"\nchoropleth.geojson.add_child(\n    folium.features.GeoJsonTooltip(['name'],style=style_function, labels=False)\n)\n\nmap2","cd156fb6":"map3 = folium.Map(location=[34, -118], zoom_start=4) #functions like the graph above just with absoulte number of cases\n\nchoropleth = folium.Choropleth(\n    geo_data=state_geo,\n    name='choropleth',\n    data=us_cum,\n    columns=['state', 'cases'],\n    key_on='properties.name',\n    fill_color= 'PuBuGn',\n    fill_opacity=0.75,\n    line_opacity=0.2,\n    legend_name='cases',\n    reset = True\n).add_to(map3)\n\nstyle_function = \"font-size: 15px; font-weight: bold\"\nchoropleth.geojson.add_child(\n    folium.features.GeoJsonTooltip(['name'],style=style_function, labels=False)\n)\n\nmap3","6c78703e":"############## Trashbin #####################\n#############################################\n#############################################\n#############################################\n#############################################\n#############################################","5515b1b5":"#State selection: nope\n#CA - California\n#PE - Pensylvania\n#MA - Massachusetts\n#NY - New York\n#IL - Illinios\n#i = pd.DataFrame(\n#    {\"code\": ['CA','PE','MA','NY','IL'],\n#     \"name\": ['California','Pensylvania','Massachusetts','New York','Illinois']},\n#    index = [1,2,3,4,5])\n\n#print(i)","a5b89579":"#creating subsets for top 5 states for descriptive stuff:\n\n#df_CA = df.query('state==\"California\"').groupby('date')[['cases','deaths']].sum().reset_index()\n#df_PE = df.query('state==\"Pensylvania\"').groupby('date')[['cases','deaths']].sum().reset_index()\n#df_MA = df.query('state==\"Massachusetts\"').groupby('date')[['cases','deaths']].sum().reset_index()\n#df_NY = df.query('state==\"New York\"').groupby('date')[['cases','deaths']].sum().reset_index()\n#df_IL = df.query('state==\"Illinois\"').groupby('date')[['cases','deaths']].sum().reset_index()","4be65c8b":"\n#ds_PE = df.query('state==\"Pensylvania\"').reset_index()\n#ds_MA = df.query('state==\"Massachusetts\"').reset_index()\n#ds_NY = df.query('state==\"New York\"').reset_index()\n#ds_IL = df.query('state==\"Illinois\"').reset_index()\n#ds_CA","514cf103":"#Map on county level # does not work :( api does not respone, url2 dataset to large ...\n#import branca\n#import json\n#import requests\n#url = 'https:\/\/raw.githubusercontent.com\/python-visualization\/folium\/master\/examples\/data'\n#url2 = 'https:\/\/public.opendatasoft.com\/explore\/embed\/dataset\/us-county-boundaries\/table'\n#county_data = f'{url}\/us_county_data.csv'\n#county_geo = f'{url2}\/us_counties_20m_topo.json'\n\n#colorscale = branca.colormap.linear.YlOrRd_09.scale(0, 50e3)\n#ds_CA = df.query('state==\"California\"').groupby('fips')['cases'].max()\n#cs_CA_o = df.set_index('fips')","ba1170c8":"#def style_function(feature):     #import of polygons for counties does not work somehow...\n#    ob = ds_CA_o.get(int(feature['id'][-5:]), None)\n#    return {\n#        'fillOpacity': 0.5,\n#        'weight': 0,\n#        'fillColor': '#white' if ob is None else colorscale(ob)\n#    }\n#\n#\n#m = folium.Map(\n#    location=[34, -118],\n#    tiles='cartodbpositron',\n#    zoom_start=7\n#)\n\n#folium.TopoJson(\n#   json.loads(requests.get(county_geo).text),\n#   'objects.us_counties_20m',\n#   style_function=style_function\n#).add_to(m)\n#\n#m","f2bfb8de":"#Model for CA\n#m = Prophet(interval_width=0.95)\n#m.fit(cases_CA)\n#future = m.make_future_dataframe(periods=30) #prediction period 1 month = 30 days\n#future.tail()\n\n#forecast_CA = m.predict(future)\n#forecast_CA[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\n#cases_forecast_plot_CA = m.plot(forecast)","f348e2a9":"#forecast = m.predict(future)#\n#forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\n#cases_forecast_plot = m.plot(forecast)\n","1840663e":"#map = folium.Map(location=(20,70), zoom_start=4, titles='Stamenterrain')\n\n#for lat, lon, value, name in zip(df['lat'], df['long'], df['cases'], df['county'] folium.CircleMarker([lat,lon], radius=value, popup=['county']))\n\n#map\n\n","42024369":"#cases_ca_agg = cases_ca.groupby('date')['cases'].sum().sort_values(ascending=False).to_frame()#\n#cases_ca_agg.style.background_gradient(cmap='Reds')","9b69494a":"#cases_ca = cases_california[[\"date\",\"cases\"]]#\n#cases_ca.head(10)","c3a45faf":"\n#dataframe = pd.read_csv(\"\/kaggle\/input\/covid19-us-county-jhu-data-demographics\/covid_us_county.csv\")\n#\n#df = dataframe\n\n#df.dropna() # deletes missing values\n\n#df2 = df\n\n#df2.pivot_table(values=\"Loan_Status\", index=[\"Credit_History\"], aggfunc=lambda x: x.map({\"Y\": 1, \"N\":0}).mean()).plot(kind=\"bar\")\n\n#df2.head(-10)","12b7095e":"#cases_CA = df_CA[['date','cases']]#\n#deaths_CA = df_CA[['date','deaths']]\n#cases_CA.head(10)\n","55ce53cf":"#highest = df.sort_values('cases').drop_duplicates('state',keep='last').tail(5)\n#grouped = highest.groupby(\"state\")[\"cases\"].plot(legend=True)\n#grouped = df.groupby(\"state\")[\"cases\"].plot(legend=True)\n#highest.plot(x=\"date\", y=\"cases\")\n\n#plt.show()","7dc7c101":"#total deaths \n#import pandas as pd\n#import matplotlib.pyplot as plt\n#dataframe = pd.read_csv(\"\/kaggle\/input\/covid19-us-county-jhu-data-demographics\/covid_us_county.csv\")\n#df = dataframe\n\n#highest = df.sort_values('deaths').drop_duplicates('state',keep='last').tail(5)\n#highest.plot(kind='bar', x='state', y='deaths')\n#plt.show()\n\n#most_cases = df.sort_values('cases').drop_duplicates('state',keep='last').tail(5)\n#most_cases.plot(kind='bar', x='state', y='cases')\n#plt.show()\n\n\n","26588ba4":"#df_new = pd.DataFrame(\n#{\"state\" : [df['state']],\n#\"date\" : [df['date']],\n#\"cases\": [df['cases']]},\n#index = [df['fips']])\n\n#df_new.head(10)","16e02f62":"#df_new2 = pd.DataFrame(\n#{\"date\" : [df['date']],\n#\"cases\": [df['cases']]},\n#index = [df['state']])\n\n#df_new2.head(10)","f8e3e94a":"#df.describe\n# prophet works only with 2 colums\n#cases_CA.colums = ['ds','y']\n#cases_CA.rename(columns = {'date':'ds'})\n#cases_CA.rename(columns = {'cases':'y'})\n#cases_CA['ds'] = pd.to_datetime(cases_CA['ds'])\n#cases_CA.tail()","19ed4882":"\n#import matplotlib.pyplot as plt\n#import datetime as dtt\n#x = df['date']\n#y = df['cases']\n#fig = plt.figure()\n#ax = fig.add_subplot(111)\n#ax.plot(x, y, color='lightblue')\n#ax.legend(loc='best')\n#plt.show\n","0b24ed69":"#dataframe.boxplot(column=\"cases\", by=\"state\", figsize=(15,8))#","6de045d4":"#cases_CA.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n#cases_CA.colums = ['ds','y']\n#cases = df.groupby('date').sum()['cases'].reset.index()\n#deaths = df.groupby('date').sum()['deaths'].reset.index()","fdd28e38":"#fig = plt.figure(figsize=(8,4))\n#axl = fig.add_subplot(121)\n#axl.set_xlabel(\"date\")\n#axl.set_ylabel(\"cases\")\n#axl.set_title(\"Total cases\")\n#dataframe1.value_counts().plot(kind=\"bar\")","bacb1f20":"# Attempt Join Dataframes\n#demo = pd.read_csv(\"\/kaggle\/input\/covid19-us-county-jhu-data-demographics\/us_county.csv\")\n#demo.head(10)\n\n#demo['median_age_state'] = \n\n#demo.pivot(index ='fips', columns ='state', values ='median_age') \n    ","681fb41a":"# Pensylvania","00dbbddb":"# Cases","3b797626":"# Illinois","1a0b8b92":"Deaths","6e58c258":"# Prepare Data","c0772b7a":"# Cases preparation","eb94f87f":"# Deaths","79635bfa":"# Deaths","19c1b984":"# Massachusetts","b14a3171":"# California","d412f4a9":"# Deaths","7b68af2f":"# Creating Map","3606ac1b":"# Cases","63738271":"# Illinois","6d2fe469":"Cases","cc94e8c8":"# Death preparation","b67f7ed7":"# Massachusetts","56ff0183":"# California","e4a789ca":"# #NEW YORK","c30db762":"Deaths","64a31422":"# New York Testing","9f5a47e4":"# Testdata","4d554c2c":"# Pensylvania","e626b988":"# Cases"}}