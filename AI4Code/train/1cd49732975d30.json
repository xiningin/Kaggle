{"cell_type":{"e488865f":"code","e1285f3e":"code","ea89b607":"code","c6f96aad":"code","5ca14fda":"code","60fc7dd3":"code","e66618e4":"code","64696013":"code","622f01ef":"code","4c82f04e":"code","13c31c2c":"code","0d2f0db8":"code","e5bbf88a":"code","d559407e":"code","770f6615":"code","157b1783":"code","6fab5aab":"code","19a96842":"code","4a52b709":"code","650f4580":"code","c48ff983":"code","1ce890d0":"code","f7e236ae":"code","859b738c":"markdown","1ca4e006":"markdown","d0393844":"markdown","d4e601be":"markdown","8a236641":"markdown","a356e6c5":"markdown","3c6d30f1":"markdown","bc5bb07f":"markdown","ad98cc69":"markdown","7538e982":"markdown","572b1695":"markdown","9a9d91c3":"markdown","209414be":"markdown","7de02f67":"markdown"},"source":{"e488865f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn import metrics\nfrom tqdm.auto import tqdm\nfrom sklearn.naive_bayes import MultinomialNB\nfrom bs4 import BeautifulSoup\nfrom tokenizers import (decoders,models,normalizers,pre_tokenizers,processors,trainers,Tokenizer)\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import Ridge\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e1285f3e":"TRAIN_DATA_PATH = \"\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\"\nVALID_DATA_PATH = \"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\"\nTEST_DATA_PATH = \"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\"\ndf_train = pd.read_csv(TRAIN_DATA_PATH)\ndf_valid = pd.read_csv(VALID_DATA_PATH)\ndf_test = pd.read_csv(TEST_DATA_PATH)","ea89b607":"df_train.head()","c6f96aad":"df_valid.head()","5ca14fda":"df_test.head()","60fc7dd3":"df_train.shape,df_valid.shape,df_test.shape","e66618e4":"for col in ['toxic','severe_toxic','obscene','threat','insult','identity_hate']:\n    print(f'------------------------{col}-----------------------')\n    display(df_train.loc[df_train[col]==1,['comment_text',col]].sample(2))","64696013":"cat_mtpl ={'obscene':0.16,'toxic':0.32,'threat':1.5,\n          'insult':0.64,'severe_toxic':1.5,'identity_hate':1.5}\n\n\nfor category in cat_mtpl:\n    df_train[category] = df_train[category]*cat_mtpl[category]\n    \ndf_train['score'] = df_train.loc[:,'toxic':'identity_hate'].mean(axis = 1)\ndf_train['y'] = df_train['score']\n\n\nmin_len = (df_train['y']>0).sum()\n\ndf_y0_undersample = df_train[df_train['y'] == 0].sample(n=min_len, random_state=41)  # take non toxic comments\n\ndf_train_new = pd.concat([df_train[df_train['y'] > 0], df_y0_undersample])  # make new df\n\ndf_train_new.head()","622f01ef":"'''def text_cleaning(text):\n    template = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    text = template.sub(r'',text)\n    \n    soup = BeautifulSoup(text,'lxml')\n    only_text = soup.get_text()\n    text = only_text\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    text = re.sub(r\"[^a-zA-Z\\d]\",\" \",text)\n    text = re.sub(' +',' ',text)\n    text = text.strip().lower()\n    \n    lemmatizer = WordNetLemmatizer()\n    stop = stopwords.words('english')\n    \n    text  = ''.join([lemmatizer.lemmatize(word) for word in text.split( ' ')])\n    \n    text = ' '.join([word for word in text.split(' ') if word not in stop])\n    \n    return text '''\n\n'''tqdm.pandas()\ndf_train_new['clean_text'] = df_train_new['comment_text'].progress_apply(text_cleaning)'''\n\n'''df_test['text'] = df_test['text'].progress_apply(text_cleaning)'''","4c82f04e":"raw_t = Tokenizer(models.WordPiece(unk_token = \"[UNK]\"))\nraw_t.normalizer = normalizers.BertNormalizer(lowercase = True)\nraw_t.pre_tokenizer  = pre_tokenizers.BertPreTokenizer()\n\nspecial_tokens = [\"[UNK]\",\"[PAD]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n\ntrainer = trainers.WordPieceTrainer(vocab_size =10000,\n                                  special_tokens = special_tokens)","13c31c2c":"from datasets import Dataset\n\ndataset = Dataset.from_pandas(df_train_new[['comment_text']])\n\ndef get_training_corpus():\n    for i in range(0,len(dataset),1000):\n        yield dataset[i:i+1000][\"comment_text\"]","0d2f0db8":"raw_t.train_from_iterator(get_training_corpus(),trainer =trainer)","e5bbf88a":"from transformers import PreTrainedTokenizerFast\n\ntokenizer =PreTrainedTokenizerFast(\ntokenizer_object = raw_t,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",)","d559407e":"def dummy_fun(doc):\n    return doc\nlabels = df_train_new['y']\ncomment = df_train_new['comment_text']\ntokenized_comments = tokenizer(comment.to_list())['input_ids']\n\nvectorizer = TfidfVectorizer(\nanalyzer = 'word',\ntokenizer = dummy_fun,\npreprocessor = dummy_fun,\ntoken_pattern =None)\n\ncom_tr = vectorizer.fit_transform(tokenized_comments)\ncom_tr","770f6615":"%%time\nregressor =Ridge(random_state = 42,alpha =5)\nregressor.fit(com_tr,labels)","157b1783":"'''%%time\nmodel = Ridge(alpha=0.5)\nmodel.fit(com_tr,labels)'''","6fab5aab":"'''%%time\nl_model = Ridge(alpha=1.)\nl_model.fit(com_tr,labels)'''","19a96842":"'''%%time\ns_model = Ridge(alpha=2.)\ns_model.fit(com_tr,labels)'''","4a52b709":"less_toxic_comments = df_valid['less_toxic']\nmore_toxic_comments = df_valid['more_toxic']\n\nless_toxic_comments = tokenizer(less_toxic_comments.to_list())['input_ids']\nmore_toxic_comments = tokenizer(more_toxic_comments.to_list())['input_ids']\n\n\nless_toxic = vectorizer.transform(less_toxic_comments)\nmore_toxic = vectorizer.transform(more_toxic_comments)\n\ny_pred_less = regressor.predict(less_toxic)\ny_pred_more = regressor.predict(more_toxic)","650f4580":"(y_pred_less<y_pred_more).mean()","c48ff983":"texts = df_test['text']\ntexts = tokenizer(texts.to_list())['input_ids']\ntexts = vectorizer.transform(texts)","1ce890d0":"df_test['prediction'] = regressor.predict(texts)\ndf_test = df_test[['comment_id','prediction']]\n\ndf_test['score'] = df_test['prediction']\ndf_test = df_test[['comment_id','score']]","f7e236ae":"df_test.to_csv('.\/submission.csv', index=False)\ndf_test.head()","859b738c":"<center><h1 style=\"font-size:300%; font-family:cursive; background:Blue; padding:10px; color:white; border-radius: 30px 30px;\"> How to deal with Toxic words?<\/h1><\/center>\n<br>\n<center><h1 style=\"font-size:200%; font-family:cursive;color:Blue; \">Jigsaw Rate Severity of Toxic Comments<\/h1><\/center>","1ca4e006":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Final Prediction on Test Data<\/b><\/h1><\/center>","d0393844":"\nIn the previous competition the task was to perform multi-class classification. Text sample could be labeled with one or several categories or not labeled with any. Non-toxic comments represent the majority of text samples, while toxic comments are a minority class and extremely toxic comments are more rare than plain toxic.In this competition we have to score texts based on the level of toxicity. To get a toxicity score from the previous data we can use two approaches:\n\n* Simply sum up all values in each row of the DataFrame. The toxicity score will vary between 0 and 6. However some unequally toxic samples could have the same score.\n    \n* Adjust the values in the DataFrame according to extremety of the category (for example, \"toxic\" and \"severe toxic\" should have different score) and then sum up per row values.\n","d4e601be":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Text Cleaning<\/b><\/h1><\/center>","8a236641":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Libraries Import<\/b><\/h1><\/center>","a356e6c5":" <center><h1 style=\"font-size:150%; font-family:solid; color:DarkOrange; border:solid; border-radius:10px 10px; padding:13px;\"><b> Updating...<\/b><\/h1><\/center>","3c6d30f1":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Processing Validation Data<\/b><\/h1><\/center>","bc5bb07f":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Submission File<\/b><\/h1><\/center>","ad98cc69":" <center><h1 style=\"font-size:150%; font-family:cursive; color:Red; border:solid; border-radius:10px 10px; padding:13px;\"><b>For Now I have not used this text cleaning<\/b><\/h1><\/center>","7538e982":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Simple Ridge <\/b><\/h1><\/center>","572b1695":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Model Training<\/b><\/h1><\/center>","9a9d91c3":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Feature Weights <\/b><\/h1><\/center>","209414be":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Data Preparations <\/b><\/h1><\/center>","7de02f67":" <center><h1 style=\"font-size:150%; font-family:solid; color:Blue; border:solid; border-radius:10px 10px; padding:13px;\"><b>Tokenizer Train<\/b><\/h1><\/center>"}}