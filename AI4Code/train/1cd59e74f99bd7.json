{"cell_type":{"ce841da0":"code","9994d9b9":"code","bd2dddfa":"code","310340d1":"code","181c3d2a":"code","49a30e49":"code","c59f6c3e":"code","38b07198":"code","3d5e2d3f":"code","bad493f4":"code","df474066":"code","92aa6c4d":"code","12c089a2":"code","96e7a744":"code","eb4855ae":"code","16769600":"code","da03cec8":"markdown","c9ccc2c6":"markdown","77e433a8":"markdown","9468484e":"markdown","180c7ed3":"markdown","c5a97bbf":"markdown","223994fc":"markdown","1758b184":"markdown","98fdfa32":"markdown","4f238afc":"markdown","9ff46e49":"markdown","89fbad11":"markdown","feda2bad":"markdown","5733833b":"markdown","490e1eed":"markdown","7518b5f3":"markdown","1b7aa548":"markdown"},"source":{"ce841da0":"import os\nimport gc\nimport time\nimport tqdm\nimport random\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9994d9b9":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerBase\nfrom matplotlib.text import Text\n\nimport warnings\nwarnings.filterwarnings('ignore')","bd2dddfa":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder","310340d1":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","181c3d2a":"SEED = 123      \nrandom.seed(SEED)\n\nTEST_SIZE = 0.20\nVAL_SIZE = 0.15\n\nEPOCHS = 100\nBATCH_SIZE = 4","49a30e49":"data = pd.read_csv(\"\/kaggle\/input\/fetal-health-classification\/fetal_health.csv\")","c59f6c3e":"data","38b07198":"plt.figure(figsize=(6,5))\nax = sns.countplot(x = data['fetal_health'])\n\n#1-Normal\n#2-Suspect\n#3-Pathological","3d5e2d3f":"label = LabelEncoder()\nlabel.fit(data['fetal_health'])\ndata['fetal_health'] = label.transform(data['fetal_health'])","bad493f4":"print('\\nData split:\\nTest size: {}\\nVal  size: {}\\n'.format(TEST_SIZE,VAL_SIZE))\nX = data.drop(columns='fetal_health')\ny = data['fetal_health']\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, \n                                                    test_size = TEST_SIZE, \n                                                    random_state=SEED)\n\nprint('TRAIN: {} & {}'.format(X_train.shape, y_train.shape))\nprint('TEST:  {} & {}'.format(X_test.shape, y_test.shape))\n\nval_len = int(X_train.shape[0]*VAL_SIZE)","df474066":"n_features = len(X_train.columns)\nn_features","92aa6c4d":"# Calculate class weights from sklearn\nclass_weight_array = class_weight.compute_class_weight('balanced', \n                                                       np.unique(y_train), \n                                                       y_train)\nprint('\\nClass weights: {}'.format(class_weight_array)) \n\n# Class weights as dictionary for Keras\nkeys = [0,1,2] \nclass_weight_dict = dict(zip(keys, class_weight_array.T))\nprint('\\nClass weights dict: {}'.format(class_weight_dict))","12c089a2":"X_train = X_train.values\nX_test = X_test.values\n\ny_train = y_train.values\ny_test = y_test.values","96e7a744":"model_0 = Sequential()\nmodel_0.add(Dense(128, activation='relu', input_dim = n_features ) )\nmodel_0.add(Dense(32, activation='relu'))\nmodel_0.add(Dense(8, activation='relu'))\nmodel_0.add(Dense(3, activation='softmax'))\n\nmodel_1 = Sequential()\nmodel_1.add(Dense(64, activation='relu', input_dim = n_features ) )\nmodel_1.add(Dense(16, activation='relu'))\nmodel_1.add(Dense(3, activation='softmax'))\n\nmodel_2 = Sequential()\nmodel_2.add(Dense(256, activation='relu', input_dim = n_features ) )\nmodel_2.add(Dense(64, activation='relu'))\nmodel_2.add(Dense(3, activation='softmax'))","eb4855ae":"models = [model_0, model_1, model_2]","16769600":"for m,model in enumerate(models):\n    model.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy']\n                 )\n\n    X_val = X_train[:val_len]\n    y_val = y_train[:val_len]\n\n    X_train_cut = X_train[val_len:]\n    y_train_cut = y_train[val_len:]\n    \n    # callback to stop the training if no improvement for 5 consecutive epochs\n    callback = keras.callbacks.EarlyStopping(monitor='loss', \n                                             patience=5)\n\n    history = model.fit(X_train_cut, y_train_cut, \n                        epochs=EPOCHS,\n                        batch_size=BATCH_SIZE,\n                        class_weight=class_weight_dict,\n                        validation_data=(X_val, y_val),\n                        callbacks=[callback],\n                        #verbose=0\n                       )\n    \n    result = model.evaluate(X_test, y_test)\n    print('\\nMODEL {}:\\n{}'.format(m,result))\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    \n    metrics = history.history['accuracy']\n    epochs = range(1, len(metrics) + 1) \n\n    plt.figure(figsize=(15,8))\n    plt.plot(epochs, loss, color='tab:blue', linestyle='-', linewidth=2, marker='*', label='Training loss')\n    plt.plot(epochs, val_loss, color='tab:orange', linestyle='-', marker='o', label='Validaion loss')\n    plt.title('Training and validation loss [model {} | {:.2f}]'.format(m,result[0]), fontsize=16)\n    plt.xlabel('Epoch', fontsize=16)\n    plt.ylabel('Loss', fontsize=16)\n    plt.legend(loc='upper right', fontsize='x-large')\n    plt.tick_params(labelsize=14)\n    plt.show()\n    plt.clf()\n    \n    plt.figure(figsize=(15,8))\n    plt.plot(epochs, accuracy, color='tab:blue', linestyle='-', linewidth=2, marker='*', label='Training accuracy')\n    plt.plot(epochs, val_accuracy, color='tab:orange', linestyle='-', marker='o', label='Validaion accuracy')\n    plt.title('Training and validation accuracy [model {} | {:.2f}%]'.format(m,result[1]*100), fontsize=16)\n    plt.xlabel('Epoch', fontsize=16)\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.legend(loc='upper left', fontsize='x-large')\n    plt.tick_params(labelsize=14)\n    plt.show()\n    plt.clf()","da03cec8":"<h2 style=color:Teal align=\"left\"> Table of Contents <\/h2>\n\n### 1 Import packages\n#### 1.1 Kaggle and other imports\n#### 1.2 Visuzalization imports\n#### 1.3 Import Scikit-Learn\n#### 1.4 Import Keras\n### 2 Configs\n### 3 Dataset\n#### 3.1 Class imbalance\n#### 3.2 Data split\n#### 3.3 Class weights\n#### 3.4 Convert to arrays for Keras\n### 4 Model\n#### 4.1 Build model\n#### 4.2 Train and evalute model","c9ccc2c6":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 3.2 Data split <\/h1>","77e433a8":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 3.3 Class weights <\/h1>","9468484e":"<div align=\"center\">\n<font size=\"4\"> Context  <\/font>  \n<\/div> \n\nReduction of child mortality is reflected in several of the United Nations' Sustainable Development Goals and is a key indicator of human progress. The UN expects that by 2030, countries end preventable deaths of newborns and children under 5 years of age, with all countries aiming to reduce under\u20115 mortality to at least as low as 25 per 1,000 live births.\n\nParallel to notion of child mortality is of course maternal mortality, which accounts for 295 000 deaths during and following pregnancy and childbirth (as of 2017). The vast majority of these deaths (94%) occurred in low-resource settings, and most could have been prevented.\n\nIn light of what was mentioned above, Cardiotocograms (CTGs) are a simple and cost accessible option to assess fetal health, allowing healthcare professionals to take action in order to prevent child and maternal mortality. The equipment itself works by sending ultrasound pulses and reading its response, thus shedding light on fetal heart rate (FHR), fetal movements, uterine contractions and more.\n\n<div align=\"center\">\n<font size=\"4\"> Data  <\/font>  \n<\/div> \n\nThis dataset contains **2126 records** of features extracted from Cardiotocogram exams, which were then classified by three expert obstetritians into **3 classes**:\n\n- Normal\n- Suspect\n- Pathological\n\nLink to dataset is [here](https:\/\/www.kaggle.com\/andrewmvd\/fetal-health-classification).","180c7ed3":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 4.1 Build model <\/h1>","c5a97bbf":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 2 Configs <\/h1>","223994fc":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 1.1 Kaggle and other imports <\/h1>","1758b184":"<div align=\"center\">\n<font size=\"6\"> Fetal Health Classification with Keras  <\/font>  \n<\/div> \n","98fdfa32":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 1 Import packages <\/h1>","4f238afc":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 4 Model <\/h1>","9ff46e49":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 4.2 Train and evaluate model <\/h1>","89fbad11":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 1.2 Visualization imports <\/h1>","feda2bad":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 3.1 Class imbalance <\/h1>","5733833b":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 3 Dataset <\/h1>","490e1eed":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 1.3 Import Scikit-Learn <\/h1>","7518b5f3":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 3.4 Convert to arrays for Keras <\/h1>","1b7aa548":"<h1 style=\"background-color:LightSeaGreen; font-family:newtimeroman; font-size:200%; text-align:left;\"> 1.4 Import Keras <\/h1>"}}