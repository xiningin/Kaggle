{"cell_type":{"fc0dc5b2":"code","052113f6":"code","b4c1d9d6":"code","aa7b5d32":"code","ecb47901":"code","e149ee00":"code","fc04847c":"code","9f360d30":"code","ee661b41":"code","f33e39ed":"code","e0f35cfb":"code","ad2a8a23":"code","b9bdc168":"code","91666e99":"code","237c4cf4":"markdown","bad00d3f":"markdown","cf14eaa1":"markdown","89bd45c7":"markdown","10e9e2f2":"markdown","0adebf8f":"markdown","a3478cf0":"markdown","a669868a":"markdown","11a955e6":"markdown","148cb39a":"markdown","73bb70e5":"markdown","6c9cc314":"markdown","779bed91":"markdown","e9709826":"markdown","f8824b49":"markdown","b7955cea":"markdown","17dbd318":"markdown","2abd14d8":"markdown","bec34224":"markdown","a9ea6724":"markdown"},"source":{"fc0dc5b2":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom scipy.stats import randint\nfrom numpy.random import uniform\n\nfrom sklearn.linear_model import Ridge ,                \\\n                                 LinearRegression,      \\\n                                 Lasso   \n\nfrom sklearn.metrics import mean_squared_log_error,     \\\n                            mean_absolute_error,        \\\n                            r2_score\n\nfrom sklearn.model_selection import RandomizedSearchCV, \\\n                                    KFold\nfrom sklearn.pipeline import Pipeline\n# from sklearn.preprocessing import MinMaxScaler\n\n!pip install xtlearn\nfrom xtlearn.feature_selection import *\nfrom xtlearn.preprocessing import *","052113f6":"sns.set(style=\"darkgrid\")","b4c1d9d6":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    files = {}\n    for filename in filenames:\n        files[filename] = os.path.join(dirname, filename)\n        \ntrain = pd.read_csv(files['train.csv'])\ntest = pd.read_csv(files['test.csv'])\n\ndef reset_datasets(dic_subs = {'1stFlrSF':'FirstFlrSF','2ndFlrSF':'SecFlrSF'}):\n    \n    # defining global variables\n    global df_trn,df_tst,X_trn,X_tst,y_trn,y_tst,train_size,test_size,full_size, df_full,X,y\n    \n    # deleting old datasets\n    try:\n        del df_trn,df_tst,X_trn,X_tst,y_trn,y_tst\n    except:\n        pass\n    \n    # get the training and test datasets \n    df_trn = train.copy()\n    X_tst = test.drop(columns=['Id']).copy()\n\n    # splitting features and target\n    X_trn = df_trn.drop(columns=['Id','SalePrice'])\n    y_trn = df_trn['SalePrice']\n    \n    # Renaming columns with naming starting by numbers\n    X_trn = X_trn.rename(columns = dic_subs)\n    X_tst = X_tst.rename(columns = dic_subs)\n    \n    # evaluating dataset lengths\n    train_size = len(train)\n    test_size  = len(test)\n    full_size  = train_size + test_size\n    \n    # concatenating test and training datasets\n    df_full = pd.concat([train,test]).set_index('Id').rename(columns = dic_subs)\n    \n    # splitting features and target of the full dataset\n    X = df_full.drop(columns = ['SalePrice'])\n    y = df_full['SalePrice']\n    \n    X = X.rename(columns = dic_subs)\n\nreset_datasets()","aa7b5d32":"class SalePriceTransformer(BaseEstimator,TransformerMixin):\n    '''\n    Description\n    ----------\n    This class will transform the target data.\n   \n    Arguments\n    ----------\n    target_name: string, default='SalePrice'\n        The name of the target column \n        \n    active: boolean\n        This parameter controls if the selection will occour. This is useful in hyperparameters searchs to test the contribution\n        of selection in the final score\n    '''\n    \n    def __init__(self,active=True,target_name = 'SalePrice'):\n        self.target_name = target_name\n        self.active = active\n        \n    def fit(self,y):\n        self.log_ymin = np.log10(y.min())\n        self.log_ymax = np.log10(y.max())\n        return self\n        \n    def transform(self,y):\n        if not self.active:\n            return y\n        else:\n            return self.__transformation(y)\n        \n    def __transformation(self,y_in):\n        y = y_in.copy()\n        log_y = np.log10(y)\n        return log_y\n    \n    def inverse_transform(self,y):\n        if not self.active:\n            return y\n        else:\n            return self.__inv_transformation(y)\n        \n    def __inv_transformation(self,log_y_in):\n        \n        log_y = log_y_in.copy()\n        \n        y = 10**(log_y)\n        \n        return y.astype(int)\n        ","ecb47901":"import matplotlib.pyplot as plt\nreset_datasets()\nraw_proc = Pipeline(steps = [\n    ('DropMissing',DropMissingDataColumns()),\n    ('Encoding',Encoder(drop_first=True)),\n])\n\nraw_proc.fit(X_trn,y_trn)\n\ny_transf = SalePriceTransformer().fit(y_trn)\n\nX = raw_proc.transform(X)\nX_trn_pp = X.iloc[:train_size]\nX_tst_pp = X.iloc[train_size:full_size]\ny_trn = y_transf.transform(y_trn)\n\ndf_corr = pd.concat(\n    [X_trn_pp.reset_index(drop=True),y_trn],\n    axis = 1).corr().abs().sort_values(by= 'SalePrice',ascending=False)                                                                      \nimp_features = df_corr[df_corr['SalePrice'] > 0.3]['SalePrice'].index.to_list()\n# imp_features.remove('SalePrice')\n\ndf_plot = pd.concat(\n    [X_trn_pp.reset_index(drop=True),y_trn],\n    axis = 1)[imp_features]","e149ee00":"df_corr[['SalePrice']].head(10)","fc04847c":"plt.scatter(df_plot['OverallQual'], df_plot['SalePrice'],  c=\"g\",  s=14,   label=\"Luck\")","9f360d30":"# fa = FeatureApply( destination = 'GrLivArea', apply = '(<GrLivArea>)')\nfa = FeatureApply( destination = 'GrLivArea', apply = '(np.log(<GrLivArea>))')\n# df_plot = fa.transform(df_plot)\nplt.scatter(fa.transform(df_plot)['GrLivArea'], df_plot['SalePrice'],  c=\"g\",  s=14,   label=\"Luck\")\nfa.transform(df_plot)[['GrLivArea','SalePrice']].corr()['SalePrice']['GrLivArea']","ee661b41":"# fa = FeatureApply( destination = 'YearBuilt', apply = '<YearBuilt>')\nfa = FeatureApply( destination = 'YearBuilt', apply = '10**14*np.log1p(<YearBuilt>\/1980)**90')\nplt.scatter(fa.transform(df_plot)['YearBuilt'], df_plot['SalePrice'],  c=\"g\",  s=14,   label=\"Luck\")\n\nfa.transform(df_plot)[['YearBuilt','SalePrice']].corr()['SalePrice']['YearBuilt']","f33e39ed":"preproc = Pipeline(steps = [\n    ('DropMissing',DropMissingDataColumns(max_missing = 0.06)),\n    ('Imputer', MeanModeImputer()),\n    ('apGrLivArea',FeatureApply( destination = 'GrLivArea', apply = '(np.log(<GrLivArea>)\/7.1)')),\n    ('apYearBuilt',FeatureApply( destination = 'YearBuilt', apply = '10**14*np.log1p(<YearBuilt>\/1980)**90')),\n    ('Encoding',Encoder()),\n    ('Scaler' , ScalerDF()), ])\n\nreset_datasets()\n\ntarget_proc = SalePriceTransformer().fit(y_trn)\ny_trn = target_proc.transform(y_trn)\n\npreproc.fit(X,y)\nX = preproc.transform(X)\nX_trn = X.iloc[:train_size]\nX_tst = X.iloc[train_size:full_size]","e0f35cfb":"def Regression_Search(X,y,\n               Regressor,\n               param_distributions,\n               n_iter = 50, scoring = 'neg_mean_squared_log_error',\n               n_splits = 10, seed = 42,\n              ):\n\n    X_trn_pp = X\n    y_trn = y\n    \n    search_cv = RandomizedSearchCV(\n         Regressor, \n         param_distributions,\n         n_iter = n_iter,\n         scoring = scoring,\n         cv = KFold(n_splits = n_splits, shuffle = True,random_state = seed))\n    \n    search_cv.fit(X_trn_pp, y_trn)\n    scv_cols = ['params','mean_test_score','std_test_score']\n    results = pd.DataFrame(search_cv.cv_results_).sort_values('rank_test_score')[scv_cols]\n    \n    estimator = search_cv.best_estimator_\n    estimator.fit(X_trn_pp,y_trn)\n    \n    y_pred = target_proc.inverse_transform(estimator.predict(X_trn_pp))\n    print('r2_score_trn = %.4f'  % r2_score(target_proc.inverse_transform(y_trn),y_pred))\n    print('RMSLE_trn = %.4f' % mean_squared_log_error(target_proc.inverse_transform(y_trn),y_pred)**0.5)\n    \n    return estimator,pd.DataFrame(search_cv.cv_results_).sort_values('rank_test_score')","ad2a8a23":"from sklearn.linear_model import SGDRegressor\nest,res = Regression_Search(\n    X_trn,y_trn,\n    Regressor = SGDRegressor(shuffle = False,loss = 'huber'),\n    param_distributions = {\n        'alpha'   : 10**uniform(np.log10(0.00005),np.log10(0.0015),200),\n        'epsilon' : 10**uniform(np.log10(0.05),np.log10(0.15),200),\n        'tol'     : 10**uniform(-195,-90,200),\n        'l1_ratio': uniform(0,1,200),\n        'learning_rate': ['optimal','adaptive'],},\n    n_iter = 100,\n    n_splits = 2,\n    scoring = 'neg_mean_squared_log_error')","b9bdc168":"res.head(5)","91666e99":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': target_proc.inverse_transform(est.predict(X_tst))})\nmy_submission.to_csv('submission.csv', index=False)\nmy_submission","237c4cf4":"## 4.2.1 Stochastic Gradient Descent - SGDRegressor","bad00d3f":"<a id=\"01\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n        <center>\n            <h1>1. Initialization<\/h1>\n        <\/center>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicializa\u00e7\u00e3o<\/a><\/li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes<\/a><\/li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes<\/a><\/li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li>\n -->\n<\/ol>\n\n\n\n<\/div>","cf14eaa1":"<a id=\"03\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n        <center>\n            <h1>3. Looking for Patterns<\/h1>\n        <\/center>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicializa\u00e7\u00e3o<\/a><\/li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes<\/a><\/li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes<\/a><\/li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li>\n -->\n<\/ol>\n\n\n\n<\/div>","89bd45c7":"My first innocent approach is:\n* to drop columns with more than 6% of missing data\n* in categorical features, replace NaN value by the mode\n* in numerical features, replace NaN values by the mean\n* feature transformation in 'GrLivArea' and 'YearBuilt' the makes the correlation with 'SalePrice' greater.\n* encode categorical features dropping one column to avoid the dummy variable trap\n* scale the features between 0 and 1","10e9e2f2":"### YearBuilt","0adebf8f":"### GrLivArea","a3478cf0":"![title](https:\/\/raw.githubusercontent.com\/emdemor\/house-prices-prediction\/master\/source\/title.png)\n<a id=\"toc\"><\/a>","a669868a":"\n<a id=\"0101\"><\/a>\n<h2>1.1 Description <a href=\"#01\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","11a955e6":"\n<a id=\"0402\"><\/a>\n<h2>4.2 Regression Approach <a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","148cb39a":"\n<a id=\"0401\"><\/a>\n<h2>4.1 Preprocessing <a href=\"#04\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","73bb70e5":"\n<a id=\"0201\"><\/a>\n<h2>1.1 Import dataset <a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","6c9cc314":"<div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n    <center>\n        <h2>Table of Contents<\/h2>\n    <\/center>\n\n   \n<ol>\n    <li><a href=\"#01\" style=\"color: #37509b;\">Initialization<\/a><\/li>\n    <li><a href=\"#02\" style=\"color: #37509b;\">Dataset<\/a><\/li>\n    <li><a href=\"#03\" style=\"color: #37509b;\">Looking for Patterns<\/a><\/li>\n    <li><a href=\"#04\" style=\"color: #37509b;\">Modelling<\/a><\/li>\n\n<\/ol>\n\n\n<\/div>","779bed91":"<a id=\"02\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n        <center>\n            <h1>2. Dataset<\/h1>\n        <\/center>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicializa\u00e7\u00e3o<\/a><\/li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes<\/a><\/li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes<\/a><\/li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li>\n -->\n<\/ol>\n\n\n\n<\/div>","e9709826":"<a id=\"04\" style=\"\n  background-color: #37509b;\n  border: none;\n  color: white;\n  padding: 2px 10px;\n  text-align: center;\n  text-decoration: none;\n  display: inline-block;\n  font-size: 10px;\" href=\"#toc\">TOC \u21bb<\/a>\n  \n  \n<div  style=\"margin-top: 9px; background-color: #efefef; padding-top:10px; padding-bottom:10px;margin-bottom: 9px;box-shadow: 5px 5px 5px 0px rgba(87, 87, 87, 0.2);\">\n        <center>\n            <h1>4. Modelling<\/h1>\n        <\/center>\n\n   \n   \n<ol type=\"i\">\n<!--     <li><a href=\"#0101\" style=\"color: #37509b;\">Inicializa\u00e7\u00e3o<\/a><\/li>\n    <li><a href=\"#0102\" style=\"color: #37509b;\">Pacotes<\/a><\/li>\n    <li><a href=\"#0103\" style=\"color: #37509b;\">Funcoes<\/a><\/li>\n    <li><a href=\"#0104\" style=\"color: #37509b;\">Dados de Indicadores Sociais<\/a><\/li>\n    <li><a href=\"#0105\" style=\"color: #37509b;\">Dados de COVID-19<\/a><\/li>\n -->\n<\/ol>\n\n\n\n<\/div>","f8824b49":"I want to work with Pipelines. However, It will not be possible to use the pipelines to every step of my approach. When this occurs, I'll redefine the dataframes. To make the work easier, I will define a function to reset the initial dataframes every time I need","b7955cea":"Start here if...\n\nYou have some experience with R or Python and machine learning basics. This is a perfect competition for data science students who have completed an online course in machine learning and are looking to expand their skill set before trying a featured competition. \n\n\n**Competition Description**\n\n\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\n![image](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/5407\/media\/housesbanner.png)\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\nPractice Skills\nCreative feature engineering \nAdvanced regression techniques like random forest and gradient boosting\nAcknowledgments\nThe Ames Housing dataset was compiled by Dean De Cock for use in data science education. It's an incredible alternative for data scientists looking for a modernized and expanded version of the often cited Boston Housing dataset. ","17dbd318":"### OverallQual","2abd14d8":"<a id=\"0102\"><\/a>\n<h2>1.2 Packages and Modules <a href=\"#01\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","bec34224":"\n<a id=\"0202\"><\/a>\n<h2>2.2 Useful Classes and Functions <a href=\"#02\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>","a9ea6724":"<a id=\"0103\"><\/a>\n<h2>1.3 Settings <a href=\"#01\"\nstyle=\"\n    border-radius: 10px;\n    background-color: #f1f1f1;\n    border: none;\n    color: #37509b;\n    text-align: center;\n    text-decoration: none;\n    display: inline-block;\n    padding: 4px 4px;\n    font-size: 14px;\n\">\u21bb<\/a><\/h2>"}}