{"cell_type":{"9a68a7b6":"code","5b44635c":"code","d51afad7":"code","18648305":"code","1f340d4c":"code","bbc27d1c":"code","90b258db":"code","048076c5":"code","6c1fa6b9":"code","e0d76b8c":"code","4f7f2550":"code","0373251a":"code","8389c5b3":"code","4100d18b":"code","4b59050a":"code","157787b5":"code","8dcc7672":"code","bd28a448":"code","4768684b":"code","5026e5c8":"code","0133e0c2":"code","88290aa3":"markdown","31835119":"markdown","b67344fa":"markdown","6ba82b26":"markdown","51037f4a":"markdown","efdfcbb0":"markdown","f7695e79":"markdown","fe836d08":"markdown","2c27b0ba":"markdown"},"source":{"9a68a7b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b44635c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score","d51afad7":"df = pd.read_csv('..\/input\/website-classification\/website_classification.csv')","18648305":"df.head()","1f340d4c":"len(df)","bbc27d1c":"df.isnull().sum()","90b258db":"df['Category'].value_counts()","048076c5":"plt.figure(figsize=(15,5))\nsns.countplot(x = 'Category', data=df)\nplt.xticks(rotation = 90)","6c1fa6b9":"X = df['cleaned_website_text']","e0d76b8c":"y = df['Category']","4f7f2550":"le = LabelEncoder()","0373251a":"le.fit(y)","8389c5b3":"le.classes_","4100d18b":"y = le.transform(y)","4b59050a":"y","157787b5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","8dcc7672":"text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])\n\ntext_clf.fit(X_train, y_train)","bd28a448":"predictions = text_clf.predict(X_test)","4768684b":"print(confusion_matrix(y_test, predictions))","5026e5c8":"print(classification_report(y_test, predictions))","0133e0c2":"print(accuracy_score(y_test, predictions).round(2))","88290aa3":"## Import the libraries","31835119":"## Label Encode the data","b67344fa":"## Prediction","6ba82b26":"## Create classifier pipeline","51037f4a":"## Create the Data","efdfcbb0":"## Split the dataset into train and test","f7695e79":"Read the data","fe836d08":"## Check for missing values","2c27b0ba":"## Visualize the classification categories"}}