{"cell_type":{"f51bb0bf":"code","b27050f1":"code","1896fd4e":"code","9d98411b":"code","5817f8d0":"code","8de4db9a":"code","6b75c79e":"code","4f68bb23":"code","5e261119":"code","73c823c8":"code","ec11e1e4":"code","e87bf12c":"code","6570ec50":"code","3ec14c26":"code","d09f8c99":"code","412283fe":"code","4fd4410f":"code","149e81f9":"code","f85e854a":"code","d932eadd":"code","e3bd0fe8":"code","89e7945d":"code","7fcb500b":"code","6c74545e":"code","ded94ff1":"code","3cf38d77":"code","32297dc9":"code","f41a12fe":"code","e3d7a07d":"markdown","d8ff6bc4":"markdown","9da20ee5":"markdown","b4c66a1c":"markdown","9eda384c":"markdown","b42d96e9":"markdown","8db27727":"markdown","a8e43640":"markdown","f1de41cb":"markdown"},"source":{"f51bb0bf":"!pip install ppscore","b27050f1":"import numpy as np\nimport pandas as pd\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\n\nimport ppscore as pps\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\n\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import plot_importance\n\nfrom math import sqrt\n\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.options.display.float_format = '{:.2f}'.format","1896fd4e":"data_dir = '\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/'","9d98411b":"train_df = pd.read_csv(data_dir + 'train.csv')\ntrain_df.head()","5817f8d0":"train_df.describe()","8de4db9a":"sns.distplot(train_df['time_to_eruption'], bins=40)","6b75c79e":"min_time_seg = train_df[train_df['time_to_eruption'] == train_df['time_to_eruption'].quantile(0.1)]\\\n                .iloc[0]['segment_id']\n\nmedian_time_seg = train_df[train_df['time_to_eruption'] == train_df['time_to_eruption'].median()]\\\n                   .iloc[0]['segment_id']\n\nmax_time_seg = train_df[train_df['time_to_eruption'] == train_df['time_to_eruption'].quantile(0.7)]\\\n                .iloc[0]['segment_id']\n\nprint('Minimum time segment -> %i (time: %i)'%(min_time_seg, train_df['time_to_eruption'].quantile(0.1)))\nprint('Median time segment -> %i (time: %i)'%(median_time_seg, train_df['time_to_eruption'].median()))\nprint('Maximum time segment -> %i (time: %i)'%(max_time_seg, train_df['time_to_eruption'].quantile(0.9)))","4f68bb23":"example_df = pd.read_csv(data_dir + 'train\/%i.csv'%(min_time_seg))\n\nrcParams['figure.figsize'] = 12, 20\nexample_df.plot(kind = 'line', subplots = True)\n\nplt.savefig('min_seg_signals.png', transparent = True)","5e261119":"example_df = pd.read_csv(data_dir + 'train\/%i.csv'%(median_time_seg))\n\nrcParams['figure.figsize'] = 12, 20\nexample_df.plot(kind = 'line', subplots = True)\n\nplt.savefig('median_seg_signals.png', transparent = True)","73c823c8":"example_df = pd.read_csv(data_dir + 'train\/%i.csv'%(max_time_seg))\n\nrcParams['figure.figsize'] = 12, 20\nexample_df.plot(kind = 'line', subplots = True)\n\nplt.savefig('max_seg_signals.png', transparent = True)","ec11e1e4":"del example_df","e87bf12c":"def get_stats(files_folder, segs_df):\n    files_dir = data_dir + files_folder\n    \n    df = segs_df.copy()\n    df.set_index('segment_id', inplace = True)\n\n    for file in tqdm(os.listdir(files_dir)):\n        file_df = pd.read_csv(files_dir + file, dtype=\"Int16\")\n\n        for sensor in file_df.columns:\n            df.loc[int(file[:-4]), '%s_max'%(sensor)] = file_df.loc[:, sensor].max()\n            df.loc[int(file[:-4]), '%s_min'%(sensor)] = file_df.loc[:, sensor].min()\n            df.loc[int(file[:-4]), '%s_std'%(sensor)] = file_df.loc[:, sensor].std()\n            df.loc[int(file[:-4]), '%s_skew'%(sensor)] = file_df.loc[:, sensor].skew()\n            df.loc[int(file[:-4]), '%s_kurtosis'%(sensor)] = file_df.loc[:, sensor].kurtosis()\n\n            df.loc[int(file[:-4]), '%s_nan'%(sensor)] = file_df.loc[:, sensor].isna().sum()\n\n            df.loc[int(file[:-4]), '%s_99q'%(sensor)] = file_df.loc[:, sensor].quantile(.99)\n            df.loc[int(file[:-4]), '%s_01q'%(sensor)] = file_df.loc[:, sensor].quantile(.01)\n\n            df.loc[int(file[:-4]), '%s_amplitude'%(sensor)] = df.loc[int(file[:-4]), '%s_max'%(sensor)] -\\\n                                                              df.loc[int(file[:-4]), '%s_min'%(sensor)]\n\n            df.loc[int(file[:-4]), '%s_neg_peaks'%(sensor)] = (file_df.loc[:, sensor] <=\\\n                                                               df.loc[int(file[:-4]), '%s_01q'%(sensor)]).sum()\n            df.loc[int(file[:-4]), '%s_pos_peaks'%(sensor)] = (file_df.loc[:, sensor] >=\\\n                                                               df.loc[int(file[:-4]), '%s_99q'%(sensor)]).sum()\n\n    df.reset_index(inplace = True)\n\n    return df","6570ec50":"stats_train_df = get_stats('train\/', train_df)\n\ntest_df = pd.DataFrame(columns=['segment_id'])\ntest_df['segment_id'] = [int(file_name[:-4]) for file_name in os.listdir(data_dir + 'test\/')]\n\nstats_test_df = get_stats('test\/', test_df)","3ec14c26":"del train_df\ndel test_df","d09f8c99":"stats_train_df['percent_missing_sensors'] = (stats_train_df.isna().sum(axis=1) +\\\n                                             (stats_train_df.isna().sum(axis=1)\/8)*2)\/100\n\nstats_test_df['percent_missing_sensors'] = (stats_test_df.isna().sum(axis=1) +\\\n                                             (stats_test_df.isna().sum(axis=1)\/8)*2)\/100","412283fe":"corr = stats_train_df.corr('pearson')[['time_to_eruption']].dropna()\ncorr = corr.sort_values('time_to_eruption')\ncorr = corr.drop(index=['time_to_eruption'])\n\ntop_corr = pd.concat([corr.head(15), corr.tail(15)])\ntop_corr.rename(columns={'time_to_eruption':'time_to_eruption_corr'}, inplace = True)\n\nrcParams['figure.figsize'] = 15, 7\nsns.barplot(data = top_corr.reset_index(), y='index', x='time_to_eruption_corr')","4fd4410f":"top_predictors = pps.predictors(stats_train_df, y='time_to_eruption').loc[:26]\n\nrcParams['figure.figsize'] = 15, 7\nsns.barplot(data=top_predictors, y='x', x='ppscore')","149e81f9":"top_ppscore_df = stats_train_df[list(top_predictors['x'])[:5] + ['time_to_eruption']]\n\ncut_min = top_ppscore_df['time_to_eruption'].min()\ncut_25 = top_ppscore_df['time_to_eruption'].quantile(0.25)\ncut_75 = top_ppscore_df['time_to_eruption'].quantile(0.75)\ncut_max = top_ppscore_df['time_to_eruption'].max()\n\ntop_ppscore_df['cut_time_to_eruption'] = pd.cut(top_ppscore_df['time_to_eruption'], \n                                                bins = [cut_min, cut_25, cut_75, cut_max], \n                                                labels = ['low', 'medium', 'high'])\n\nsns.pairplot(top_ppscore_df, hue = 'cut_time_to_eruption')","f85e854a":"top_ppscore_df_train = stats_train_df[list(top_predictors['x'])[:5]]\ntop_ppscore_df_test = stats_test_df[list(top_predictors['x'])[:5]]\n\ntop_ppscore_df_train['type'] = 'train'\ntop_ppscore_df_test['type'] = 'test'\n\nsns.pairplot(pd.concat([top_ppscore_df_train, top_ppscore_df_test]), hue = 'type')","d932eadd":"del top_corr\ndel top_predictors\ndel top_ppscore_df\ndel top_ppscore_df_train\ndel top_ppscore_df_test","e3bd0fe8":"stats_train_df.fillna(0, inplace = True)\nstats_test_df.fillna(0, inplace = True)","89e7945d":"def RMSE(y_true, y_pred):\n    return sqrt(mean_squared_error(y_true, y_pred))","7fcb500b":"cv = KFold(n_splits = 5, shuffle=True, random_state=42)","6c74545e":"x = stats_train_df.drop(columns=['segment_id', 'time_to_eruption'])\ny = stats_train_df['time_to_eruption']","ded94ff1":"train_scores = []\nval_scores = []\n\npipeline = Pipeline([('scaler', StandardScaler()), \n                     ('lgbm', LGBMRegressor(n_estimators=1000, \n                                            max_depth=14,\n                                            num_leaves=45,\n                                            learning_rate=0.1,\n                                            min_child_samples=20,\n                                            subsample=.9,\n                                            colsample_bytree=.9,\n                                            random_state=42, \n                                            eval_metric='rmse'))])\n\nfor train_index, val_index in cv.split(stats_train_df):\n    x_train, x_val = x.iloc[train_index], x.iloc[val_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n    \n    pipeline.fit(x_train, y_train)\n    \n    y_train_pred = pipeline.predict(x_train)\n    y_val_pred = pipeline.predict(x_val)\n    \n    train_score = RMSE(y_train, y_train_pred)\n    val_score = RMSE(y_val, y_val_pred)\n    \n    train_scores.append(train_score)\n    val_scores.append(val_score)\n    \n    print('Train score = %.2f'%(train_score))\n    print('Validation score = %.2f'%(val_score))\n    print()\n    \nprint('VALIDATION SCORE = %.2f+\/-%.2f'%(np.array(val_scores).mean(), np.array(val_scores).std()))","3cf38d77":"pipeline.fit(x, y)","32297dc9":"feat_importance = pd.DataFrame(data = pipeline['lgbm'].feature_importances_, columns=['value'])\nfeat_importance['name'] = x.columns\nfeat_importance.sort_values('value', inplace = True)\n\nrcParams['figure.figsize'] = 15, 30\nsns.barplot(data = feat_importance.reset_index(), y='name', x='value')","f41a12fe":"stats_test_df['time_to_eruption'] = pipeline.predict(stats_test_df.drop(columns=['segment_id']))","e3d7a07d":"![signals_volcanic.jpg](attachment:signals_volcanic.jpg)\n\n**Comparing the signs, we realize that:**\n* The shorter the time, the greater the instability of the signals\n* The shorter the time, the greater the signal amplitude\n* The signal peaks coincide by the sensors\n* Number of NaNs can mean something\n\nmedian, max, min, std, skew, kurtosis, number of NaNs, .95q, 0.05q, max - min, positive peaks, negative peaks,  ","d8ff6bc4":"### Comparing top 5 variables with higher PPScores","9da20ee5":"#### Comparing the distribution of the variables between 'train' and 'test'","b4c66a1c":"## Top variables","9eda384c":"### Top 30 correlations","b42d96e9":"### PPScore","8db27727":"* ppscore != 0","a8e43640":"## Train LGBM","f1de41cb":"* similar distribution between training and testing"}}