{"cell_type":{"4e440148":"code","ee9fc4ad":"code","671fba43":"code","2a702902":"code","41c23db4":"code","e34871e5":"code","85a6023d":"code","ed4531e4":"code","aca51add":"code","dc899010":"code","c89b99d1":"code","8e9e180d":"code","1209c056":"code","eda79bc4":"code","457a980a":"code","8c5d83f1":"code","42463de2":"code","9e2e0996":"code","2caffe9f":"code","078a3129":"code","85283880":"code","b3e46a1b":"code","07bf542a":"code","628de4c9":"code","4acbe250":"code","054771d2":"code","ddd5795a":"code","8db39bbd":"code","15ba90f3":"code","867b728a":"code","79f4e22b":"code","dfb86f6f":"code","5ec41b58":"code","319eb548":"code","bb1224d3":"code","d009f27d":"code","38cf7ca0":"code","722ba123":"code","a30b31cf":"code","b69116ae":"code","a1be90d3":"markdown","8f5179a0":"markdown","6983fefa":"markdown","d69b5136":"markdown","62a35bc7":"markdown","e3773c0e":"markdown","6ffabc46":"markdown","9a5a0127":"markdown","eb797a59":"markdown","7663e78c":"markdown","6d1b2db3":"markdown","bc5618cf":"markdown","e3ac1ce0":"markdown","1395df4f":"markdown","ea932c26":"markdown","c2479cb5":"markdown","54f6a331":"markdown","4ceeb430":"markdown","1583bd72":"markdown","e979320a":"markdown","3922e9d4":"markdown","968d2663":"markdown","db238325":"markdown","6933976c":"markdown","487da036":"markdown","3213f4b4":"markdown","f8952a9f":"markdown","398f2b07":"markdown","81e862a8":"markdown","b5056b8e":"markdown","208f30b8":"markdown"},"source":{"4e440148":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n","ee9fc4ad":"df = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')","671fba43":"df.head()","2a702902":"print(df.shape)","41c23db4":"y_train = df['Survived']\ny_train.shape","e34871e5":"df.drop(['Survived'],axis=1,inplace=True)\ndf.info()","85a6023d":"df.isnull().sum()","ed4531e4":"sns.heatmap(df.isnull(), yticklabels=False, cbar=True)","aca51add":"df[['Pclass','Age']].groupby(['Pclass'],as_index=False).mean().sort_values(['Age'],ascending=False)","dc899010":"def replace_nan_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if(pd.isnull(Age)):\n        if Pclass == 1:\n            return 38\n        elif Pclass == 2:\n            return 30\n        else:\n            return 25\n    else: \n        return Age","c89b99d1":"df['Age'] = df[['Age','Pclass']].apply(replace_nan_age, axis=1)","8e9e180d":"sns.heatmap(df.isnull(),yticklabels=False,cbar=True)","1209c056":"df.drop(columns='Cabin',axis=1,inplace=True)","eda79bc4":"sns.heatmap(df.isnull(),yticklabels=False,cbar=True)","457a980a":"df.drop(columns=['Name','Ticket'],axis=1,inplace=True)","8c5d83f1":"Sex = pd.get_dummies(df['Sex'],drop_first=True)\ndf = pd.concat([df,Sex],axis=1)\ndf.drop(['Sex'],axis=1,inplace=True)","42463de2":"df['Embarked'].value_counts()","9e2e0996":"Embarked=pd.get_dummies(df['Embarked'])\ndf=pd.concat([df,Embarked],axis=1)\ndf.drop(['Embarked'],axis=1,inplace=True)","2caffe9f":"df.info()","078a3129":"df.head()","85283880":"df_test.head()","b3e46a1b":"df_test.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)","07bf542a":"Sex = pd.get_dummies(df_test['Sex'],drop_first=True)\ndf_test = pd.concat([df_test,Sex],axis=1)\ndf_test.drop(['Sex'],axis=1,inplace=True)","628de4c9":"Embarked=pd.get_dummies(df_test['Embarked'])\ndf_test=pd.concat([df_test,Embarked],axis=1)\ndf_test.drop(['Embarked'],axis=1,inplace=True)","4acbe250":"df_test.info()","054771d2":"df_test.corr()","ddd5795a":"df_test[['Pclass','Age']].groupby(['Pclass'],as_index=False).mean().sort_values(['Age'],ascending=False)","8db39bbd":"df[['male','Age']].groupby(['male'],as_index=False).mean().sort_values(['Age'],ascending=False)","15ba90f3":"def replace_nan_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    \n    if(pd.isnull(Age)):\n        if Pclass == 1:\n            return 41\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n    else: \n        return Age","867b728a":"df_test['Age'] = df_test[['Age','Pclass']].apply(replace_nan_age, axis=1)","79f4e22b":"df_test.replace(np.nan,df_test['Fare'].mean(),inplace=True)","dfb86f6f":"df_test.info()","5ec41b58":"print(df.shape)\nprint(df_test.shape)","319eb548":"x_trn,x_valid,y_trn,y_valid=train_test_split(df,y_train,test_size=0.33,random_state=150)","bb1224d3":"model=RandomForestClassifier(n_estimators=200,random_state=200,max_features=0.5,min_samples_leaf=3,oob_score=True,n_jobs=-1)\nmodel.fit(df,y_train)","d009f27d":"model.score(x_valid,y_valid)","38cf7ca0":"predict_y = model.predict(df_test)","722ba123":"model.score(x_trn,y_trn)","a30b31cf":"model.feature_importances_\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(x_trn.shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure(figsize=(18,12))\nplt.title(\"Feature importances\")\nplt.bar(range(x_trn.shape[1]), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(x_trn.shape[1]), indices)\nplt.xlim([-1, x_trn.shape[1]])\nplt.show()","b69116ae":"my_submission = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': predict_y })\nmy_submission.to_csv('submission.csv', index=False)","a1be90d3":"**Read input train and test data**","8f5179a0":"**Replace null data of age column according to Pclass column that is most correlated together**","6983fefa":"**Applying onehot encoding on Embarked feature**","d69b5136":"## This is my first Kernel here....\n# Please Upvote my kernel so that i will be thankful to you.","62a35bc7":"## Prepare our Submission file","e3773c0e":"**Drop Name Ticket column to get with numerical values**","6ffabc46":"### Now I am understanding training data and applying feature engineering.","9a5a0127":"# Titanic Survival Competition for Starter...\n### I am using here Random Forest Classifier Algorithm that will classify which Passenger is Survived or not. For each step, running Markdown cell for better undderstanding.","eb797a59":"## Similarly Applying feature engineering on test data","7663e78c":"**Importing Simple Libraries**","6d1b2db3":"**Finally view our feature importance value of all features**","bc5618cf":"**Applying onehot encoding with Sex column**","e3ac1ce0":"**Calculating total number of blank data**","1395df4f":"**Considering Embarked column**","ea932c26":"**Applying onehot encoding on Embarked feature** ","c2479cb5":"**Visualising null data in each feature with heat map** ","54f6a331":"**Now Spliting Data into training and validation data**","4ceeb430":"## One Hot Encoding","1583bd72":"**Define a function which replace age with most specific value**","e979320a":"**Our Score on Validation Data**","3922e9d4":"**Applying Random Forest Algorthm**","968d2663":"## Modeling","db238325":"**Replace NaN value of Fare column with its mean value**","6933976c":"**All features are converted in numerical values and now look our training data**","487da036":"**Here we see age column is more correlated with Pclass as compare to Sex(male) feature**","3213f4b4":"**Prediction on Test Set**","f8952a9f":"**Now we see all values are filled and all are numerical values**","398f2b07":"**Drop Cabin column**","81e862a8":"**So we go through Pclass cloumn to replace age with its most specific values by defininig function**","b5056b8e":"**Our Score on Training data**","208f30b8":"**Applying Onehot Encoding on Sex feature**"}}