{"cell_type":{"1ef2d5c8":"code","3a7fac38":"code","d0ed5e35":"code","48658fdd":"code","0f84fa36":"code","728120e1":"code","18cf1c78":"code","711e19b4":"code","7a74a80f":"code","852c256b":"code","148fa1fa":"code","93c029ee":"code","ed91e4a4":"code","adc08ba5":"code","845a37b0":"code","80e21377":"code","c34531aa":"code","5fbddec7":"code","a22f7300":"markdown","2b798d71":"markdown","01a28297":"markdown","ece439ee":"markdown","f9f87969":"markdown","2a7a6bc8":"markdown","124a28ac":"markdown","a32cbd35":"markdown","676b4861":"markdown"},"source":{"1ef2d5c8":"from sklearn.datasets import load_breast_cancer\nbc = load_breast_cancer()\n\ndata = bc.data\ntarget = bc.target","3a7fac38":"print(data.shape)","d0ed5e35":"import numpy as np\nprint(np.unique(target))","48658fdd":"# separando os dados em treino e teste\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n\n# treinando o modelo \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=8)\nknn.fit(X_train, y_train)","0f84fa36":"probas = knn.predict_proba(X_test)\nprint(probas)","728120e1":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\nfpr, tpr, thresholds = roc_curve(y_test[:], probas[:,1])\nroc_auc = auc(fpr, tpr)\n\nplt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Aleat\u00f3rio')\nplt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % roc_auc)\n\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('Falsos Positivos')\nplt.ylabel('Positivos Verdadeiros')\nplt.title('ROC do KNN')\nplt.legend(loc=\"lower right\")\nplt.show()\n","18cf1c78":"for tp, fp, t in zip(tpr, fpr, thresholds):\n    print('tp = %.2f, fp = %.2f, t=%.2f' % (tp, fp, t))","711e19b4":"def build_contingence_table(Y, Y_pred_1, Y_pred_2):\n    y1_and_y2 = 0\n    y1_and_not_y2 = 0\n    y2_and_not_y1 = 0\n    not_y1_and_not_y2 = 0\n    for y, y1, y2 in zip(Y, Y_pred_1, Y_pred_2):\n        if y == y1 == y2:\n            y1_and_y2 += 1\n        elif y != y1 and y != y2:\n            not_y1_and_not_y2 += 1\n        elif y == y1 and y != y2:\n            y1_and_not_y2 += 1\n        elif y != y1 and y == y2:\n            y2_and_not_y1 += 1\n            \n    contingency_table = [[y1_and_y2, y1_and_not_y2], \n                         [y2_and_not_y1, not_y1_and_not_y2]]\n    \n    return contingency_table","7a74a80f":"from statsmodels.stats.contingency_tables import mcnemar","852c256b":"knn2 = KNeighborsClassifier(n_neighbors=2)\nknn2.fit(X_train, y_train)\n\nknn3 = KNeighborsClassifier(n_neighbors=3)\nknn3.fit(X_train, y_train)\n\ny_pred2 = knn2.predict(X_test)\ny_pred3 = knn3.predict(X_test)","148fa1fa":"contingence_table = build_contingence_table(y_test, y_pred2, y_pred3)\n\nimport pprint\n\npprint.pprint(contingence_table)","93c029ee":"result = mcnemar(contingence_table, exact=True)\n    \n    \nif result.pvalue >= 0.001:\n    print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\nelse:\n    print('statistic=%.3f, p-value=%.3e' % (result.statistic, result.pvalue))\n\n# interpretando o p-value\nalpha = 0.05\nif result.pvalue > alpha:\n    print('Mesma propor\u00e7\u00e3o de erros (falhou em rejeitar H0)')\nelse:\n    print('Propor\u00e7\u00f5es de erros diferentes (rejeitou H0)')","ed91e4a4":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier","adc08ba5":"# separando os dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n\n# treinando o modelo \nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\nprobas = knn.predict_proba(X_test)\n\nfpr, tpr, thresholds = roc_curve(y_test[:], probas[:,1])\nroc_auc = auc(fpr, tpr)\n\nplt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Aleat\u00f3rio')\nplt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % roc_auc)\n\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('Falsos Positivos')\nplt.ylabel('Positivos Verdadeiros')\nplt.title('ROC do KNN')\nplt.legend(loc=\"lower right\")\nplt.show()","845a37b0":"# treinando o modelo \nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\n\nprobas = knn.predict_proba(X_test)\n\nfpr, tpr, thresholds = roc_curve(y_test[:], probas[:,1])\nroc_auc = auc(fpr, tpr)\n\n\nplt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Aleat\u00f3rio')\nplt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % roc_auc)\n\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('Falsos Positivos')\nplt.ylabel('Positivos Verdadeiros')\nplt.title('ROC do KNN')\nplt.legend(loc=\"lower right\")\nplt.show()","80e21377":"def build_contingence_table(Y, Y_pred_1, Y_pred_2):\n    y1_and_y2 = 0\n    y1_and_not_y2 = 0\n    y2_and_not_y1 = 0\n    not_y1_and_not_y2 = 0\n    for y, y1, y2 in zip(Y, Y_pred_1, Y_pred_2):\n        if y == y1 == y2:\n            y1_and_y2 += 1\n        elif y != y1 and y != y2:\n            not_y1_and_not_y2 += 1\n        elif y == y1 and y != y2:\n            y1_and_not_y2 += 1\n        elif y != y1 and y == y2:\n            y2_and_not_y1 += 1\n            \n    contingency_table = [[y1_and_y2, y1_and_not_y2], \n                         [y2_and_not_y1, not_y1_and_not_y2]]\n    \n    return contingency_table","c34531aa":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=42)\n\nk_range = range(2, 11)\n\nknn_list = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    \n    y_pred = knn.predict(X_test)\n    \n    knn_list.append({'knn': knn, 'predict': y_pred})\n\nlen(knn_list)","5fbddec7":"import pprint\n\n\nfor c in range(0, len(knn_list)+1):\n    for x in range(c+1, len(knn_list)):\n        contingence_table = build_contingence_table(y_test, knn_list[c]['predict'], knn_list[x]['predict'])\n        \n        result = mcnemar(contingence_table, exact=True)\n\n        # interpretando o p-value\n        alpha = 0.05\n        if result.pvalue <= alpha:\n            print('c: ', c+2)\n            print('x: ', x+2)\n            pprint.pprint(contingence_table)\n            print('Propor\u00e7\u00f5es de erros diferentes (rejeitou H0)')\n            if result.pvalue >= 0.001:\n                print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n            else:\n                print('statistic=%.3f, p-value=%.3e' % (result.statistic, result.pvalue))\n            \n            print('\\n\\n\\n---------')","a22f7300":"Ap\u00f3s o treinamento, as m\u00e9tricas de desempenho s\u00e3o obtidas ao analisar amostra por amostra a rela\u00e7\u00e3o entre o r\u00f3tulo conhecido (y_train ou y_test) e o r\u00f3tulo informado (y_pred) pelo m\u00e9todo de classifica\u00e7\u00e3o. Para identificar a acur\u00e1cia, basta encontrar a rela\u00e7\u00e3o de r\u00f3tulos corretamente predizidos.","2b798d71":"(2) Use o teste de McNemmar e responda: Comparando todos os modelos treinados com k=2 at\u00e9 k=10, quais pares de modelos apresentam resultados estatisticamente diferentes?","01a28297":"# Exerc\u00edcios","ece439ee":"Utilizando o conjunto de dados de c\u00e2ncer de mama, o objetivo deste notebook \u00e9 avaliar as m\u00e9tricas de desempenho.","f9f87969":"***Teste Estat\u00edstico de McNemmar***\n\nEste teste permite verificar se dois modelos possuem a mesma propor\u00e7\u00e3o de erros.\n\nTemos nossa hip\u00f3tese nula H0: dois modelos possuem a mesma propor\u00e7\u00e3o de erros.\n\n- Se essa hip\u00f3tese for rejeitada, temos que os dois modelos apresentam propor\u00e7\u00f5es de erro diferentes, logo eles s\u00e3o estatisticamente diferentes (o melhor \u00e9 o que apresentar melhores resultados, de acordo com outras m\u00e9tricas)\n- Se falharmos em rejeitar essa hip\u00f3tese, ent\u00e3o n\u00e3o \u00e9 poss\u00edvel afirmar que os modelos tem resultados diferentes.\n\nPrimeiro precisamos montar a matriz de conting\u00eancia.","2a7a6bc8":"Inicialmente, \u00e9 necess\u00e1rio criar uma divis\u00e3o dos dados em treino e teste para analisar o desempenho de algum m\u00e9todo de classifica\u00e7\u00e3o atrav\u00e9s de alguma m\u00e9trica. Para isso, considere a divis\u00e3o de 33% para teste e o m\u00e9todo de classifica\u00e7\u00e3o k-NN.","124a28ac":"(1) Plote o ROC do resultado para k=3 e k=10","a32cbd35":"## M\u00e9tricas de desempenho\n\nAs m\u00e9tricas de desempenho auxiliam a entender como um determinado se comporta ao identificar padr\u00f5es de um conjunto de dados. Nem sempre identificar apenas a acur\u00e1cia de um problema \u00e9 suficiente. Muitas vezes \u00e9 necess\u00e1rio identificar se a classe cr\u00edtica de um problema (quando houver) est\u00e1 sendo considerada na escolha de um modelo.","676b4861":"**Curva ROC (Receiving Operating Characteristic)**\n\nUm modelo classificador bin\u00e1rio geralmente retorna o n\u00edvel de confian\u00e7a que o resultado retornado realmente seja de uma determinada classe - variando de 0 a 1,0. Mas a partir de qual n\u00edvel de confian\u00e7a pode-se obter o melhor resultado do classificador? Devemos simplesmente considerar que se o n\u00edvel de confian\u00e7a for > 0.50 ent\u00e3o a classe \u00e9 1, sen\u00e3o a classe \u00e9 0?\n\nNa curva ROC plotamos as taxas de verdadeiros positivos e falsos positivos para cada threshold utilizado. A \u00e1rea sob a curva (Area Under de Curve - AUC) fornece uma boa avalia\u00e7\u00e3o sobre a performance do modelo, mesmo que se utilize outros thresholds."}}