{"cell_type":{"b95528cf":"code","4fff489e":"code","5ed5aa3e":"code","6bba145f":"code","aa15984f":"code","28569859":"code","21482465":"code","bac62f16":"code","a0c72ad9":"code","286dfaeb":"code","1fb7fc10":"code","75ac2e75":"code","3a0ea487":"code","c44c61be":"code","34891536":"markdown","eed0cd6f":"markdown"},"source":{"b95528cf":"!pip install -qq git+https:\/\/www.github.com\/ildoonet\/tf-pose-estimation","4fff489e":"!pip install -qq pycocotools","5ed5aa3e":"%load_ext autoreload\n%autoreload 2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})","6bba145f":"%matplotlib inline\nimport tf_pose\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm_notebook\nfrom PIL import Image\nimport numpy as np\nimport os\ndef video_gen(in_path):\n    c_cap = cv2.VideoCapture(in_path)\n    while c_cap.isOpened():\n        ret, frame = c_cap.read()\n        if not ret:\n            break\n        yield c_cap.get(cv2.CAP_PROP_POS_MSEC), frame[:, :, ::-1]\n    c_cap.release()","aa15984f":"video_paths = glob('..\/input\/damian\/*.mp4')\nc_video = video_gen(video_paths[0])\nfor _ in range(300):\n    c_ts, c_frame = next(c_video)\nplt.imshow(c_frame)","28569859":"from tf_pose.estimator import TfPoseEstimator\nfrom tf_pose.networks import get_graph_path, model_wh\ntfpe = tf_pose.get_estimator()","21482465":"humans = tfpe.inference(npimg=c_frame, upsample_size=4.0)\nprint(humans)","bac62f16":"new_image = TfPoseEstimator.draw_humans(c_frame[:, :, ::-1], humans, imgcopy=False)\nfig, ax1 = plt.subplots(1, 1, figsize=(10, 10))\nax1.imshow(new_image[:, :, ::-1])","a0c72ad9":"body_to_dict = lambda c_fig: {'bp_{}_{}'.format(k, vec_name): vec_val \n                              for k, part_vec in c_fig.body_parts.items() \n                              for vec_name, vec_val in zip(['x', 'y', 'score'],\n                                                           (part_vec.x, 1-part_vec.y, part_vec.score))}\nc_fig = humans[0]\nbody_to_dict(c_fig)","286dfaeb":"MAX_FRAMES = 3200\nbody_pose_list = []\nfor vid_path in tqdm_notebook(video_paths, desc='Files'):\n    c_video = video_gen(vid_path)\n    c_ts, c_frame = next(c_video)\n    out_path = '{}_out.avi'.format(os.path.split(vid_path)[1])\n    out = cv2.VideoWriter(out_path,\n                          cv2.VideoWriter_fourcc('M','J','P','G'),\n                          10, \n                          (c_frame.shape[1], c_frame.shape[0]))\n    for (c_ts, c_frame), _ in zip(c_video, \n                                  tqdm_notebook(range(MAX_FRAMES), desc='Frames')):\n        bgr_frame = c_frame[:,:,::-1]\n        humans = tfpe.inference(npimg=bgr_frame, upsample_size=4.0)\n        for c_body in humans:\n            body_pose_list += [dict(video=out_path, time=c_ts, **body_to_dict(c_body))]\n        new_image = TfPoseEstimator.draw_humans(bgr_frame, humans, imgcopy=False)\n        out.write(new_image)\n    out.release()\n","1fb7fc10":"import pandas as pd\nbody_pose_df = pd.DataFrame(body_pose_list)\nbody_pose_df.describe()","75ac2e75":"fig, m_axs = plt.subplots(1, 2, figsize=(15, 5))\nfor c_ax, (c_name, c_rows) in zip(m_axs, body_pose_df.groupby('video')):\n    for i in range(17):\n        c_ax.plot(c_rows['time'], c_rows['bp_{}_y'.format(i)], label='x {}'.format(i))\n    c_ax.legend()\n    c_ax.set_title(c_name)","3a0ea487":"fig, m_axs = plt.subplots(1, 2, figsize=(15, 5))\nfor c_ax, (c_name, n_rows) in zip(m_axs, body_pose_df.groupby('video')):\n    for i in range(17):\n        c_rows = n_rows.query('bp_{}_score>0.6'.format(i)) # only keep confident results\n        c_ax.plot(c_rows['bp_{}_x'.format(i)], c_rows['bp_{}_y'.format(i)], label='BP {}'.format(i))\n    c_ax.legend()\n    c_ax.set_title(c_name)","c44c61be":"body_pose_df.to_csv('body_pose.csv', index=False)","34891536":"## Libraries we need\nInstall tf_pose and pycocotools","eed0cd6f":"# Overview\nThe kernel shows how to use the [tf_pose_estimation](https:\/\/github.com\/ildoonet\/tf-pose-estimation) package in Python on a series of running videos."}}