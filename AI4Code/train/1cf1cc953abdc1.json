{"cell_type":{"e0f5e682":"code","b9fbb001":"code","0ec62005":"code","68e28a03":"code","5781b1bd":"code","fa36d535":"code","f3cf0674":"code","7e574e72":"code","6c98c4cb":"code","5ebcb955":"code","74051ed7":"code","7e0649a4":"code","63f86248":"code","6b17c0d5":"code","bcad039f":"code","2b10259f":"code","a1974f9a":"markdown","777602fb":"markdown","eb847354":"markdown","7440b26b":"markdown","f2141cdb":"markdown","f4395220":"markdown","ef31ce64":"markdown","8192219b":"markdown","90a66580":"markdown","890ea53a":"markdown","3e6ee4cf":"markdown","19a8a578":"markdown","34b05be4":"markdown","2e811f65":"markdown","0310434e":"markdown"},"source":{"e0f5e682":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9fbb001":"# Data Handling\nimport pandas as pd\npd.set_option('display.max_columns', 150)\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='dark')\n\n# Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\n# Preprocessing\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Evaluation\nfrom sklearn.metrics import mean_squared_error\n\nseed = 1999","0ec62005":"train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","68e28a03":"print(f\"Shape of Train is : {train.shape}\")\nprint(f\"Shape of Test is : {test.shape}\")\nprint(f\"Shape of sample_submission is : {sample_submission.shape}\")\n\ntarget = 'loss'\nid_col = 'id'\nfeatures = [col for col in train.columns if col not in [id_col, target]]\n\nprint(f\"\\nThe Dataset have total {len(features)} features\")","5781b1bd":"train.head()","fa36d535":"train.describe().T.style","f3cf0674":"f, ax = plt.subplots(2, 1, figsize = (20, 10))\naxx = ax.flatten()\n\nsns.kdeplot(data = train, x = target, ax = axx[0], color = 'Blue', fill=True)\nsns.boxplot(data = train, x = target, ax = axx[1], color = 'Blue')","7e574e72":"df = pd.concat((train.nunique(), test.nunique()), axis = 1)\ndf.rename(columns={0: \"Train\", 1: \"Test\"}, inplace=True)\ndf = df.T\ndf","6c98c4cb":"f, ax = plt.subplots(10, 20, figsize = (120, 60))\naxx = ax.flatten()\n\nindex = 0\n\nfor col in features:\n    sns.kdeplot(data = train, x = col, ax = axx[index], color = 'Blue', fill = True)\n    axx[index].set_title(f'Train {col}', loc = 'right', weight = 'bold', fontsize = 12)\n    index+=1\n    sns.kdeplot(data = test, x = col, ax = axx[index], color = 'Red', fill = True)\n    axx[index].set_title(f'Test {col}', loc = 'right', weight = 'bold', fontsize = 12)\n    index+=1","5ebcb955":"plt.figure(figsize=(14 , 14))\n\ncorr = train.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, square=True, mask = mask, cmap='coolwarm_r', annot_kws={'size':20}) ","74051ed7":"train[target] = train[target]+1\ntrain[target] = np.log(train[target])","7e0649a4":"X_train, X_test, y_train, y_test = train_test_split(train[features], train[target], test_size = 0.25, random_state = seed)","63f86248":"model_dict = {}\n\nmodel_dict['Linear Regression'] = LinearRegression()\nmodel_dict['DecisionTree Regressor'] = DecisionTreeRegressor(random_state = seed)\nmodel_dict['LGBM Regressor'] = LGBMRegressor(random_state = seed)","6b17c0d5":"def model_evaluation(X_trn, X_val, y_trn, y_val, model, model_name):\n    model.fit(X_trn,y_trn)\n    y_pred = model.predict(X_val)\n    y_pred = np.exp(y_pred)-1\n    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n    print('======================================{}======================================='.format(model_name))\n    print('RMSE is : {}'.format(RMSE))\n    print()\n    print()","bcad039f":"%%time\nfor model_name,model in model_dict.items():\n    model_evaluation(X_train, X_test, y_train, y_test, model, model_name)","2b10259f":"%%time\nmodel = LGBMRegressor(random_state = seed)\nmodel.fit(train[features], train[target])\n\npreds = model.predict(test[features])\npreds = np.exp(preds) + 1\n\nsample_submission[target] = preds\nsample_submission.to_csv('sub1.csv', index = False)","a1974f9a":"<a id=\"3.2\"><\/a>\n### 3.2 Model Building","777602fb":"---\n[back to top](#table-of-contents)\n<a id=\"2\"><\/a>\n# Variable Analysis\n\n<a id=\"2.1\"><\/a>\n### 2.1 Distribution: Train Vs Test","eb847354":"<a id=\"1.4\"><\/a>\n### 1.4 Unique Values in Each Column","7440b26b":"<a id=\"1.2\"><\/a>\n### 1.2 Brief look at Dataset","f2141cdb":"\n<a id=\"0\"><\/a>\n# Preparations\n\n<a id=\"0.1\"><\/a>\n### Importing Necessary Libraries","f4395220":"# Please Do Upvote If You Like The Notebook. And Feel free to give suggestions about improving my work. Thank You. \n\n# Stay Tuned For Advance Model Building","ef31ce64":"Observations:\n1. Target Variable is Highly Right Skewed.\n2. Most of the losses are in between 0 to 10.","8192219b":"---\n[back to top](#table-of-contents)\n<a id=\"1\"><\/a>\n# Dataset Overview\n\n\n<a id=\"1.1\"><\/a>\n### 1.1 Size of Dataset. Features, Target column. ","90a66580":"<a id=\"1.3\"><\/a>\n### 1.3 Distribution of Target Column","890ea53a":"---\n[back to top](#table-of-contents)\n<a id=\"3\"><\/a>\n# Baseline Models\n\n<a id=\"3.1\"><\/a>\n### 3.1 Preprocessing\n\n**1. Since our Target Column is Right Skewed, We will do Log Transformation.**\n\n    Note: Do not forget to convert predicted values to normal form when using log transformations on target variable.","3e6ee4cf":"**Because of the limitation of computational power i've only evaluated 3 models. You can evaluate as mony models as you want.** ","19a8a578":"# Table of Contents\n<a id = \"table-of-contents\"><\/a>\n- [Preparations](#0)\n    [1 Importing Necessary Libraries](#0.1)\n    [2 Loading The Dataset](#0.2)\n- [1 Dataset Overview](#1)\n    - [1.1 Size of Dataset. Features, Target column.](#1.1)\n    - [1.2 Brief look at Dataset](#1.2)\n    - [1.3 Distribution of Target Column](#1.3)\n    - [1.4 Unique Values in Each Column](#1.4)\n- [2 Variable Analysis](#2)\n    - [2.1 Distribution: Train Vs Test](#2.1)\n    - [2.2 Corelation Analysis](#2.2)\n- [3 Baseline Models](#3)\n    - [3.1 Preprocessing](#3.1)\n    - [3.2 Model Building](#3.1)\n    - [3.3 Leaderboard Submission](#3.2)","34b05be4":"<a id=\"0.2\"><\/a>\n### Loading The Dataset","2e811f65":"<a id=\"3.3\"><\/a>\n### 3.3 Leaderboard Submission\n\n**I am going to Use LGBMRegressor to make a submission**","0310434e":"<a id=\"2.2\"><\/a>\n### 2.2 Corelation Analysis"}}