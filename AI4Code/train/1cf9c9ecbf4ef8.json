{"cell_type":{"99d15746":"code","065063cd":"code","dbf08e95":"code","44d2932f":"code","d5d3132f":"code","2290daf3":"code","413ecd5f":"code","3fcef521":"code","f7f90a43":"code","331bb137":"code","fe644131":"code","12ee9a33":"code","cd0bde24":"code","a51d0680":"code","75b00e3d":"code","3826a5bf":"code","26a940e8":"code","7ae031fe":"code","cc06ebf7":"code","cfc56f53":"code","775bfea7":"code","2666d594":"code","5438d31d":"code","b85c970b":"code","305b0936":"code","d62542c1":"code","dbf80fdb":"code","b68997ea":"code","4d83708a":"code","19344fb4":"code","0ff441ff":"code","e49ce081":"code","3bb5d896":"code","da576685":"code","02f6f3d8":"code","f54354e6":"code","7c830027":"code","bc4b4ce1":"code","561bc825":"code","79164192":"code","0906aad9":"code","a68f9102":"code","8f81cc14":"code","a8dbebd7":"code","c9c30e3e":"code","e7a24887":"code","f9691db7":"code","3fdc71ed":"code","0e8857c1":"code","3c85b9e3":"code","828ec01b":"code","e650e003":"code","ded28874":"code","d930d094":"code","c14e468a":"code","a192b4c4":"code","874947cf":"code","76c51dc4":"code","f9067a1a":"code","39a5741f":"code","000bb1d7":"code","e6523087":"code","81bfbd97":"code","2b046188":"code","aaa3bc20":"code","4f11f585":"code","331aaddc":"code","3b2c88c5":"code","3f79320b":"code","134c39cb":"code","f1c79109":"code","4ded1eef":"code","b2a8ca19":"code","b419c55a":"code","ac4409cc":"code","e2ec9dbb":"code","9e523532":"code","add13e72":"markdown","9a118833":"markdown","d7280448":"markdown","000e514d":"markdown","08bb51d5":"markdown","91279350":"markdown","1c0bd97a":"markdown","8ffe0300":"markdown","e6334faa":"markdown","b8a56007":"markdown","d3ef6a50":"markdown","eef6d23a":"markdown","d9269074":"markdown","c89df4f9":"markdown","c3f2c9cd":"markdown","6d4d3988":"markdown","66cf9607":"markdown","b904dffa":"markdown","b17b7ad6":"markdown","44eb7849":"markdown","a3918039":"markdown","f2902e09":"markdown","5e604d5f":"markdown","57a7eda4":"markdown","0f4c27a9":"markdown"},"source":{"99d15746":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","065063cd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","dbf08e95":"sns.set(style=\"ticks\", color_codes=True)\nplt.rcParams['figure.figsize'] = (8,5)\nplt.rcParams['figure.dpi'] = 150","44d2932f":"df = pd.read_csv('\/kaggle\/input\/campeonato-brasileiro-de-futebol\/campeonato-brasileiro-full.csv')","d5d3132f":"df.head()","2290daf3":"df.isnull().sum()","413ecd5f":"df.drop(['Hor\u00e1rio', 'Dia'], axis=1, inplace = True)\ndf.head()","3fcef521":"df.dtypes","f7f90a43":"df['Data'] = pd.to_datetime(df['Data'])","331bb137":"df = df[df['Data'].dt.year >= 2003]","fe644131":"def change_winner_name(row):\n    if (row['Vencedor'] == row['Clube 1']):\n        return 0\n    elif (row['Vencedor'] == row['Clube 2']):\n        return 1\n    else:\n        return 2\n\ndf['Vencedor'] = df.apply(change_winner_name, axis=1)","12ee9a33":"df.drop(['Clube 1 Estado', 'Clube 2 Estado', 'Estado Clube Vencedor'], axis=1, inplace = True)","cd0bde24":"df.reset_index(drop=True, inplace = True)","a51d0680":"df.head()","75b00e3d":"df['Rodada'] = [int(x.split('\u00aa')[0]) for x in df['Rodada'].values]","3826a5bf":"df['Clube 1'] = [x.lower() for x in df['Clube 1'].values]\ndf['Clube 2'] = [x.lower() for x in df['Clube 2'].values]","26a940e8":"df.head()","7ae031fe":"df.shape","cc06ebf7":"df['Temporada'] = df['Data'].dt.year","cfc56f53":"df['Temporada']","775bfea7":"pd.options.mode.chained_assignment = None\n\ntemporadas = df['Temporada'].value_counts().index.sort_values().values\n\ndf['Wins Home Team'] = df['Clube 1']\ndf['Wins Away Team'] = df['Clube 1']\n\ndf['Loss Home Team'] = df['Clube 1']\ndf['Loss Away Team'] = df['Clube 1']\n\ndf['Draw Home Team'] = df['Clube 1']\ndf['Draw Away Team'] = df['Clube 1']\n\nfor temporada in  temporadas:\n    dft = df[df['Temporada'] == temporada]\n    \n    for index, row in dft.iterrows():\n        df_home = dft[(dft['Rodada'] < row['Rodada']) & (dft['Clube 1'] == row['Clube 1'])]\n        c1_wins = 0\n        c1_loss = 0\n        c1_draw = 0\n        for index2, row2 in df_home.iterrows():\n            if row2['Vencedor'] == 0:\n                c1_wins+=1\n            elif row2['Vencedor'] == 1:\n                c1_loss+=1\n            elif row2['Vencedor'] == 2:\n                c1_draw+=1\n\n        df_away = dft[(dft['Rodada'] < row['Rodada']) & (dft['Clube 2'] == row['Clube 1'])]\n        for index2, row2 in df_away.iterrows():\n            if row2['Vencedor'] == 1:\n                c1_wins+=1\n            elif row2['Vencedor'] == 0:\n                c1_loss+=1\n            elif row2['Vencedor'] == 2:\n                c1_draw+=1\n\n\n        df_home = dft[(dft['Rodada'] < row['Rodada']) & (dft['Clube 1'] == row['Clube 2'])]\n        c2_wins = 0\n        c2_loss = 0\n        c2_draw = 0\n        for index2, row2 in df_home.iterrows():\n            if row2['Vencedor'] == 0:\n                c2_wins+=1\n            elif row2['Vencedor'] == 1:\n                c2_loss+=1\n            elif row2['Vencedor'] == 2:\n                c2_draw+=1\n\n        df_away = dft[(dft['Rodada'] < row['Rodada']) & (dft['Clube 2'] == row['Clube 2'])]\n        for index2, row2 in df_away.iterrows():\n            if row2['Vencedor'] == 1:\n                c2_wins+=1\n            elif row2['Vencedor'] == 0:\n                c2_loss+=1\n            elif row2['Vencedor'] == 2:\n                c2_draw+=1\n\n\n        df.at[index, 'Wins Home Team'] = c1_wins\n        df.at[index, 'Wins Away Team'] = c2_wins\n        \n        df.at[index, 'Loss Home Team'] = c1_loss\n        df.at[index, 'Loss Away Team'] = c2_loss\n        \n        df.at[index, 'Draw Home Team'] = c1_draw\n        df.at[index, 'Draw Away Team'] = c2_draw","2666d594":"df.tail()","5438d31d":"def find_wins_home(ser):\n    wins = [0]\n    \n    [wins.append(wins[-1]+1) if win==0 else wins.append(wins[-1]) for win in ser.values]\n    \n    return wins[0:-1]\n\ndef find_wins_away(ser):\n    wins = [0]\n    \n    [wins.append(wins[-1]+1) if win==1 else wins.append(wins[-1]) for win in ser.values]\n    \n    return wins[0:-1]\n\ndef find_draws(ser):\n    wins = [0]\n    \n    [wins.append(wins[-1]+1) if win==2 else wins.append(wins[-1]) for win in ser.values]\n    \n    return wins[0:-1]\n\ndf['Wins Home Home Team'] = df.groupby(['Temporada', 'Clube 1'])['Vencedor'].transform(lambda x: find_wins_home(x))\ndf['Loss Home Home Team'] = df.groupby(['Temporada', 'Clube 1'])['Vencedor'].transform(lambda x: find_wins_away(x))\ndf['Wins Away Away Team'] = df.groupby(['Temporada', 'Clube 2'])['Vencedor'].transform(lambda x: find_wins_away(x))\ndf['Loss Away Away Team'] = df.groupby(['Temporada', 'Clube 2'])['Vencedor'].transform(lambda x: find_wins_home(x))\ndf['Draws Home Home Team'] = df.groupby(['Temporada', 'Clube 1'])['Vencedor'].transform(lambda x: find_draws(x)) \ndf['Draws Away Away Team'] = df.groupby(['Temporada', 'Clube 2'])['Vencedor'].transform(lambda x: find_draws(x))","b85c970b":"df.tail()","305b0936":"df['Home Wins'] = [1 if x == 0 else 0 for x in df['Vencedor'].values]\ndf['Away Wins'] = [1 if x == 1 else 0 for x in df['Vencedor'].values]","d62542c1":"df.head()","dbf80fdb":"def find_streak(ser):\n    streak = [0]\n    \n    [streak.append(streak[-1]+1) if win==1 else streak.append(0) for win in ser.values]\n    \n    return streak[0:-1]\n\ndf['Home Winning Streak'] = df.groupby(['Temporada', 'Clube 1'])['Home Wins'].transform(lambda x: find_streak(x))","b68997ea":"df['Home Losing Streak'] = df.groupby(['Temporada', 'Clube 1'])['Away Wins'].transform(lambda x: find_streak(x))\ndf['Away Winning Streak'] = df.groupby(['Temporada', 'Clube 2'])['Away Wins'].transform(lambda x: find_streak(x))\ndf['Away Losing Streak'] = df.groupby(['Temporada', 'Clube 2'])['Home Wins'].transform(lambda x: find_streak(x))","4d83708a":"df.tail()","19344fb4":"df.drop(['Home Wins', 'Away Wins'], inplace=True, axis=1)","0ff441ff":"df.head()","e49ce081":"def find_goals(ser):\n    goals = [0]\n    \n    [goals.append(goals[-1]+goal) for goal in ser.values]\n    \n    return goals[0:-1]","3bb5d896":"df['Goals Scored at Home'] = df.groupby(['Temporada', 'Clube 1'])['Clube 1 Gols'].transform(lambda x: find_goals(x))\ndf['Goals Conceded at Home'] = df.groupby(['Temporada', 'Clube 1'])['Clube 2 Gols'].transform(lambda x: find_goals(x))\n\ndf['Goals Scored Away'] = df.groupby(['Temporada', 'Clube 2'])['Clube 2 Gols'].transform(lambda x: find_goals(x))\ndf['Goals Conceded Away'] = df.groupby(['Temporada', 'Clube 2'])['Clube 1 Gols'].transform(lambda x: find_goals(x))","da576685":"df.tail()","02f6f3d8":"import math\ntemporadas = df['Temporada'].value_counts().index.sort_values().values\n\n\ndf['Days Between'] = 0\ndf['Days Between Away'] = 0\n\n\nfor temporada in temporadas:\n    dft = df[df['Temporada'] == temporada]\n    \n    for index, row in dft.iterrows():\n        dfc = dft[(dft['Data'] <= row['Data']) & ((dft['Clube 1'] == row['Clube 1']) | (dft['Clube 2'] == row['Clube 1']))]\n        days_bet = ((dfc['Data'] - dfc['Data'].shift()).dt.days).values[-1]\n        if math.isnan(days_bet):\n            df.at[index, 'Days Between'] = 5\n        else:\n            df.at[index, 'Days Between'] = days_bet\n            \n        dfc = dft[(dft['Data'] <= row['Data']) & ((dft['Clube 1'] == row['Clube 2']) | (dft['Clube 2'] == row['Clube 2']))]\n        days_bet_away = ((dfc['Data'] - dfc['Data'].shift()).dt.days).values[-1]\n        if math.isnan(days_bet_away):\n            df.at[index, 'Days Between Away'] = 5\n        else:\n            df.at[index, 'Days Between Away'] = days_bet_away\n            \n            \n        ","f54354e6":"df.tail()","7c830027":"df.head()","bc4b4ce1":"temporadas = df['Temporada'].value_counts().index.sort_values().values\n\ndf['Is Promoted'] = 0\ndf['Is Promoted Away'] = 0\n\nfor temporada in temporadas[1:]:\n    dft = df[df['Temporada'] == temporada]\n    \n    dfw = df[df['Temporada'] == temporada-1]\n    \n    for index, row in dft.iterrows():\n        last_year_clubs = dfw['Clube 1'].value_counts().index.sort_values().values\n        \n        home_club = row['Clube 1']\n        if home_club in last_year_clubs:\n            df.at[index, 'Is Promoted'] = 0\n        else:\n            df.at[index, 'Is Promoted'] = 1\n        \n        away_club = row['Clube 2']\n        if away_club in last_year_clubs:\n            df.at[index, 'Is Promoted Away'] = 0\n        else:\n            df.at[index, 'Is Promoted Away'] = 1\n        ","561bc825":"df.tail(20)","79164192":"df.head()","0906aad9":"df['Home Agnst'] = 0\ndf['Away Agnst'] = 0\ndf['Draws Agnst'] = 0\n\nclubs = df['Clube 1'].value_counts().index.sort_values().values\n\nfor club1 in clubs:\n    for club2 in clubs:\n        dfc = df[((df['Clube 1'] == club1) & (df['Clube 2'] == club2)) | ((df['Clube 2'] == club1) & (df['Clube 1'] == club2))]\n        win_home = 0\n        win_away = 0\n        draws = 0\n        for index, row in dfc.iterrows():\n            df.at[index, 'Home Agnst'] = win_home\n            df.at[index, 'Away Agnst'] = win_away\n            df.at[index, 'Draws Agnst'] = draws\n            \n            if row['Vencedor'] == 0:\n                win_home +=1\n            elif row['Vencedor'] == 1:\n                win_away +=1\n            else:\n                draws+=1\n            \n            \n            ","a68f9102":"df.tail()","8f81cc14":"df.columns","a8dbebd7":"df.shape","c9c30e3e":"target = 'Vencedor'\nfeatures = list(df.columns.values[9:])","e7a24887":"len(features)","f9691db7":"df.dtypes","3fdc71ed":"df[[target]+features] = df[[target]+features].astype(int)","0e8857c1":"ax = sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df[features]))\nax.set_xticklabels(ax.get_xticklabels(),rotation=90)\nplt.show()","3c85b9e3":"cols = [target]+features\n\ndf_useful = df[cols]\ncorr = df_useful.corr(method='pearson')\n","828ec01b":"sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\nplt.show()","e650e003":"cols = ['Clube 1 Gols', 'Clube 2 Gols']+features\n\ndf_useful = df[cols]\ncorr = df_useful.corr(method='pearson')\n","ded28874":"sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\nplt.show()","d930d094":"from sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split","c14e468a":"X = df[features]\ny = df[target]","a192b4c4":"scaler = preprocessing.StandardScaler()\n\nscaler.fit(X)\nX_scaled = scaler.transform(X)","874947cf":"pca = PCA(n_components=5)\npca.fit(X_scaled)\nX_pca = pca.transform(X_scaled)\n\nX_pca_df = pd.DataFrame(X_pca, columns=['V1', 'V2', 'V3', 'V4', 'V5'])\nX_pca_df.tail()","76c51dc4":"sns.set(style='ticks', color_codes=True)\nsns.pairplot(X_pca_df, kind='reg')\nplt.show()","f9067a1a":"X_train, X_test, y_train, y_test = train_test_split(X_pca_df, y, random_state=0, test_size=0.3)\n\nclf = GaussianNB()\n\nclf.fit(X_train, y_train)","39a5741f":"print('Train score: {:.3f}'.format(clf.score(X_train, y_train)))\nprint('Test score: {:.3f}'.format(clf.score(X_test, y_test)))","000bb1d7":"from sklearn.metrics import confusion_matrix\n\ny_pred = clf.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(cm, index=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'],\n                    columns=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'])\n\nsns.heatmap(df_cm, annot=True)\nplt.show()","e6523087":"proba_df = pd.DataFrame(clf.predict_proba(X_test))\ndf_r = df.loc[X_test.index,['Clube 1', 'Clube 2', 'Vencedor']].reset_index(drop=True)\n\ndf_rp = df_r.merge(proba_df, left_index=True, right_index=True)\ndf_rp.tail()","81bfbd97":"from sklearn.neural_network import MLPClassifier\n\nmlp = MLPClassifier(random_state=42)\n\nmlp.fit(X_train, y_train)","2b046188":"print('Train score: {:.3f}'.format(mlp.score(X_train, y_train)))\nprint('Test score: {:.3f}'.format(mlp.score(X_test, y_test)))","aaa3bc20":"y_pred = mlp.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(cm, index=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'],\n                    columns=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'])\n\nsns.heatmap(df_cm, annot=True)\nplt.show()","4f11f585":"proba_df = pd.DataFrame(mlp.predict_proba(X_test))\ndf_r = df.loc[X_test.index,['Clube 1', 'Clube 2', 'Vencedor']].reset_index(drop=True)\n\ndf_rp = df_r.merge(proba_df, left_index=True, right_index=True)\ndf_rp.tail()","331aaddc":"pca = PCA(n_components=9)\npca.fit(X_scaled)\nX_pca = pca.transform(X_scaled)\n\nX_pca_df = pd.DataFrame(X_pca)\n","3b2c88c5":"X_train, X_test, y_train, y_test = train_test_split(X_pca_df, y, random_state=0, test_size=0.3)","3f79320b":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(C=100, max_iter=100000)\n\nlogreg.fit(X_train, y_train)","134c39cb":"print('Train score: {:.3f}'.format(logreg.score(X_train, y_train)))\nprint('Test score: {:.3f}'.format(logreg.score(X_test, y_test)))","f1c79109":"y_pred = logreg.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(cm, index=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'],\n                    columns=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'])\n\nsns.heatmap(df_cm, annot=True)\nplt.show()","4ded1eef":"proba_df = pd.DataFrame(logreg.predict_proba(X_test))\ndf_r = df.loc[X_test.index,['Clube 1', 'Clube 2', 'Vencedor']].reset_index(drop=True)\n\ndf_rp = df_r.merge(proba_df, left_index=True, right_index=True)\ndf_rp.tail()","b2a8ca19":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)","b419c55a":"from sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(max_features=5, n_estimators=500, random_state=0)\n\nforest.fit(X_train, y_train)","ac4409cc":"print('Train score: {:.3f}'.format(forest.score(X_train, y_train)))\nprint('Test score: {:.3f}'.format(forest.score(X_test, y_test)))","e2ec9dbb":"y_pred = forest.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\n\ndf_cm = pd.DataFrame(cm, index=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'],\n                    columns=['Vit\u00f3ria Mandante', 'Vit\u00f3ria Visitante', 'Empate'])\n\nsns.heatmap(df_cm, annot=True)\nplt.show()","9e523532":"proba_df = pd.DataFrame(forest.predict_proba(X_test))\ndf_r = df.loc[X_test.index,['Clube 1', 'Clube 2', 'Vencedor']].reset_index(drop=True)\n\ndf_rp = df_r.merge(proba_df, left_index=True, right_index=True)\ndf_rp.tail()","add13e72":"# Analisando as Features e criando o Modelo","9a118833":"Sem d\u00favida, \u00e9 um problema nenhuma coluna ter alta correla\u00e7\u00e3o com o resultado. Vamos analisar agora para o caso de gols marcados pelo visitante e mandante na partida.","d7280448":"# Limpeza dos Dados\n\nPrimeiro, vou selecionar apenas as colunas que v\u00e3o ter alguma utilidade, retirando Hor\u00e1rio e Dia. Tamb\u00e9m vou selecionar jogos do Brasileir\u00e3o a partir de 2003, primeira temporada dos pontos corridos.","000e514d":"Tamb\u00e9m n\u00e3o h\u00e1 alta correla\u00e7\u00e3o entre as colunas de gols marcados e as features.\n\n## Modelo 1: PCA + Naive Bayes Classifier\nVou aplicar, primeiramente, o modelo PCA para diminuir as dimens\u00f5es do dataset. Isso permitir\u00e1 uma an\u00e1lise melhor da base de dados, e tamb\u00e9m vai traduzir melhor as informa\u00e7\u00f5es da partida para o modelo.","08bb51d5":"## Gols marcados e sofridos\n\nAqui, farei da seguinte forma: computo todos os gols que o time marcou como visitante e como mandante.","91279350":"Como foi apresentado no paper, irei propor as seguintes features:\n\n- n\u00famero de vit\u00f3rias do time na temporada\n- n\u00famero de derrotas do time na temporada\n- n\u00famero de empates do time na temporada\n- n\u00famero de vit\u00f3rias do time em casa (%)\n- n\u00famero de vit\u00f3rias do time fora de casa (%)\n- n\u00famero de empates do time em casa (%)\n- n\u00famero de empates do time fora de casa (%)\n- n\u00famero de derrotas do time em casa (%)\n- n\u00famero de derrotas do time fora de casa (%)\n- sequ\u00eancia de vit\u00f3rias em casa do time mandante\n- sequ\u00eancia sem vit\u00f3rias em casa do time mandante\n- sequ\u00eancia de vit\u00f3rias fora de casa do time visitante\n- sequ\u00eancia sem vit\u00f3rias fora de casa do time visitante\n- o time jogou ou n\u00e3o a \u00faltima temporada\n- dias desde o \u00faltimo jogo \n- gols marcados essa temporada jogando em casa\n- gols sofridos essa temporada jogando em casa\n- gols marcados essa temporada jogando fora\n- gols sofridos essa temporada jogando fora\n- encontros entre os dois time em que o clube que est\u00e1 como mandante ganhou em qualquer est\u00e1dio\n- encontros entre os dois time em que o clube que est\u00e1 como visitante ganhou em qualquer est\u00e1dio\n\nAcredito que o modelo ficaria melhor com mais algumas features: dados especif\u00edcios de jogadores (autores de gols e assist\u00eancias), informa\u00e7\u00f5es sobre troca de comando t\u00e9cnico, informa\u00e7\u00f5es sobre as dist\u00e2ncias entre as cidades e possivelmente dados de casas de apostas. Por\u00e9m, vou focar no que pode ser obtido a partir desse dataset.\n\nTamb\u00e9m vou deixar a maioria das features separadas para jogos em casa e jogos fora, primeiro, a complexidade do c\u00f3digo aumenta bastante ao unir ambos os dados. Tamb\u00e9m \u00e9 v\u00e1lido separar para aumentar a participa\u00e7\u00e3o do efeito mandante no modelo, que creio que seja de bastante impacto no futebol brasileiro.}\n\nPara qualquer uma dessas features, \u00e9 necess\u00e1rio fazer a an\u00e1lise por temporada. Por isso, a primeira coisa a se fazer \u00e9 criar essa coluna:","1c0bd97a":"## Confrontos diretos\n\nEssa coluna ter\u00e1 as informa\u00e7\u00f5es dos confrontos entre cada time disputados em qualquer temporada. A ideia \u00e9 extrair vantagens hist\u00f3ricas entre times.","8ffe0300":"## Clubes promovidos\n\nEssa feature visa obter os dados dos times que subiram ou n\u00e3o de divis\u00e3o. Para todo time promovido nessa temporada (que n\u00e3o jogou temporada passada), essa coluna ser\u00e1 igual a 1. Se jogou na S\u00e9rie A no ano anterior, essa coluna ser\u00e1 igual a 0. ","e6334faa":"As colunas foram adicionadas, basicamente o que elas querem dizer \u00e9:\n\n- Home Winning Streak: vit\u00f3rias seguidas em casa do time mandante\n- Home Losing Streak: derrotas seguidas em casa do time mandante\n- Away Winning Streak: vit\u00f3rias seguidas fora de casa do time visitante\n- Away Losing Streak: derrotas seguidas fora de casa do time visitante","b8a56007":"## Modelo 2: PCA + MLP","d3ef6a50":"A coluna 'Home Wins' foi inserida s\u00f3 para facilitar o processo de obter os _streaks_","eef6d23a":"## Dias desde o \u00faltimo jogo\n\nAqui, a ideia \u00e9 analisar o cansa\u00e7o. No Brasil, o ideal seria uma feature pegando a dist\u00e2ncia percorrida pelo clube, mas dada a dificulade e como minha ideia \u00e9 usar apenas esse dataset, vou colocar s\u00f3 isso.\n\nComo o brasileir\u00e3o costuma come\u00e7ar na semana ou uma semana depois do estadual, irei colocar para todos os jogos de primeira rodada o intervalo de 5 dias.","d9269074":"O boxplot de cada uma das features vai servir para verificar quais delas t\u00eam pontos muito fora da curva e quais s\u00e3o.","c89df4f9":"## N\u00famero de vit\u00f3rias, derrotas e empates\n\nEssas 3 features precisam ser obtidas tanto para o time mandante quanto para o visitante.","c3f2c9cd":"## Sequ\u00eancia de vit\u00f3rias\n\nNovamente, \u00e9 necess\u00e1rio que para ambos os casos seja feito a an\u00e1lise pro time da casa quanto para o time visitante. A ideia aqui \u00e9 analisar os retrospectos do time mandante em casa, e do visitante fora de casa. ","6d4d3988":"O n\u00famero de vit\u00f3rias por rodada est\u00e1 adicionado. \u00c9 preciso notar que esse n\u00famero \u00e9 em rela\u00e7\u00e3o a rodada anterior. Por exemplo, o S\u00e3o Paulo entrou na \u00faltima rodada do brasileiro do ano passado com 16 vit\u00f3rias, e terminou o campeonato com 17.","66cf9607":"# Conclus\u00e3o\n\nTodos os modelos testados t\u00eam um test score muito baixo. Possivelmente, com m\u00e9tricas de avalia\u00e7\u00e3o melhor, esse score possa aumentar um pouco, por\u00e9m, mesmo assim, acho muito dif\u00edcil que com esse dataset, at\u00e9 criando mais features, o modelo atinja mais de 55% de acertos no test dataset. O pr\u00f3prio paper que usei como base para esse notebook, atinge apenas 54% no futebol holand\u00eas (que me parece ser mais previs\u00edvel que o brasileiro).\n\nAcredito que a grande dificuldade de prever partidas de futebol esteja na presen\u00e7a do empate. Se a classifica\u00e7\u00e3o for entre vit\u00f3ria do time da casa x n\u00e3o vit\u00f3ria do time da casa, todos os modelos melhoram muito em desempenho. \n\nAcho que a melhor aplica\u00e7\u00e3o desse trabalho \u00e9 analisando as probabilidades que cada modelo d\u00e1, e comparando com as odds de casas de apostas para verificar o quanto eles est\u00e3o na frente de simples modelos de ML.\n\nAl\u00e9m disso, qualquer ajuda \u00e9 bem-vinda. Se souberem alguma forma mais eficiente de treinar o modelo, ou qualquer feature que tenha maior impacto, por favor compartilhem!","b904dffa":"## N\u00famero de vit\u00f3rias, derrotas e empates em casa e fora","b17b7ad6":"# Feature Engineering\n\nO processo mais importante para obter um modelo vi\u00e1vel ser\u00e1 o de Feature Engineering. A ideia vai ser obter o m\u00e1ximo poss\u00edvel de features por meio desse dataset, e depois reduzir usando o PCA (para os modelos de Logistic Regression e Naive Bayes), ou usando os meios de redu\u00e7\u00e3o dos pr\u00f3prios modelos (caso das \u00e1rvores).","44eb7849":"## Modelo 4: Random Forest","a3918039":"# Prevendo resultados do Brasileir\u00e3o\n\nA ideia desse notebook \u00e9 criar um modelo preditivo para jogos do campeonato brasileiro. Com apenas esse dataset, pretendo criar as features necess\u00e1rias para testar alguns classificadores. Acredito que seja complicado obter bons resultados, at\u00e9 pelo paper que uso como base, onde um trabalho acad\u00eamico conseguiu chegar apenas em 54% de taxa de acerto no campeonato holand\u00eas, mas de qualquer forma pode ser interessante para analisar a rela\u00e7\u00e3o entre algumas features e o vencedor de partidas esportivas.\n\nAl\u00e9m disso, \u00e9 uma boa forma de testar minhas habilidades de manipula\u00e7\u00e3o de dataframe.\n\nUsei como fonte de estudo para an\u00e1lise esportiva o paper 'Predicting The Dutch Football Competition Using Public Data: A Machine Learning Approach', de Niek Tax e Yme Joustra. Vou tentar aplicar um modelo de Feature Engineering parecido e testar se h\u00e1 muitas diferen\u00e7as para modelos preditivos do futebol brasileiro para o holand\u00eas.\n\nPretendo testar os seguintes modelos: Logistic Regression, Naive Bayes Classifier, Multilayer Perceptron e Random Forest. A ideia \u00e9 avali\u00e1-los e comparar qual est\u00e1 tendo o melhor resultado pro futebol brasileiro.","f2902e09":"Outro ponto importante \u00e9 trocar o nome do vencedor do jogo para 0 (vit\u00f3ria do mandate), 1 (vit\u00f3ria do visitante) ou 2 (empate)","5e604d5f":"Primeiro, irei fazer uma an\u00e1lise entre as features do modelo e o vencedor dos jogos.","57a7eda4":"## Modelo 3: PCA + LogReg","0f4c27a9":"Essa feature tamb\u00e9m poderia levar a diferencia\u00e7\u00e3o entre os confrontos diretos em casa e fora, mas deixei assim para evitar muitos casos com zero (times que jogam a S\u00e9rie A pela primeira vez).\n\nAgora, temos as features do modelo e podemos prosseguir com ele. Antes disso, irei analisar a rela\u00e7\u00e3o das features com o alvo."}}