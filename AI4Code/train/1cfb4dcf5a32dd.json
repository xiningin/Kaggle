{"cell_type":{"672833c9":"code","2e1e876c":"code","98c3838f":"code","9a54b82e":"code","5e07bae7":"code","096bd903":"code","2dd0e144":"code","8b94f4dd":"code","e9c5ad5b":"code","4077afb6":"code","9ed9cc6a":"code","b2d4b0d8":"code","9fa8d93f":"code","19d68842":"code","86391a5d":"code","b6ecbf27":"code","b917b284":"code","82d1970f":"code","cbc51314":"code","5fa4ab6d":"code","da8d513b":"code","425b3bc6":"markdown","59e6d8bc":"markdown","ae23fa45":"markdown","2e41186d":"markdown","9c759ec6":"markdown","c76b542d":"markdown","c9c970d4":"markdown","38ff70e1":"markdown","a491c98f":"markdown","c85bb611":"markdown","eb24f281":"markdown"},"source":{"672833c9":"import gc\nimport os\nimport warnings\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import ImageDraw\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom keras.optimizers import Adadelta\nfrom keras.optimizers import RMSprop\nfrom keras.optimizers import Adam, SGD\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import Xception\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras import layers, models, optimizers\n\nfrom keras import backend as K\nwarnings.filterwarnings(action='ignore')\n\nK.image_data_format()","2e1e876c":"DATA_PATH = '..\/input\/2019-3rd-ml-month-with-kakr\/'\n#DATA_PATH = '..\/input\/'\nos.listdir(DATA_PATH)","98c3838f":"# \uc774\ubbf8\uc9c0 \ud3f4\ub354 \uacbd\ub85c\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\n# CSV \ud30c\uc77c \uacbd\ub85c\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))","9a54b82e":"# ResNet50 -> 224\n# Xception,InceptionResNetV2 -> 299\n# NASNetLarge -> 331\n\nIMAGE_SIZE = 299\nBATCH_SIZE = 32\nEPOCHS = 50\nk_folds=5","5e07bae7":"def crop_boxing_img(img_name, margin=0, size=(IMAGE_SIZE,IMAGE_SIZE)):\n    if img_name.split('_')[0] == 'train':\n        PATH = TRAIN_IMG_PATH\n        data = df_train\n    else:\n        PATH = TEST_IMG_PATH\n        data = df_test\n\n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n\n    return img.crop((x1, y1, x2, y2)).resize(size)","096bd903":"TRAIN_CROPPED_PATH = '..\/cropped_train'\nTEST_CROPPED_PATH = '..\/cropped_test'","2dd0e144":"if (os.path.isdir(TRAIN_CROPPED_PATH) == False):\n    os.mkdir(TRAIN_CROPPED_PATH)\n\nif (os.path.isdir(TEST_CROPPED_PATH) == False):\n    os.mkdir(TEST_CROPPED_PATH)","8b94f4dd":"for i, row in df_train.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(os.path.join(TRAIN_CROPPED_PATH, row['img_file']))\n\nfor i, row in df_test.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(os.path.join(TEST_CROPPED_PATH, row['img_file']))","e9c5ad5b":"df_train['class'] = df_train['class'].astype('str')\ndf_train = df_train[['img_file', 'class']]\ndf_test = df_test[['img_file']]","4077afb6":"model_path = '..\/working\/'\nif not os.path.exists(model_path):\n    os.mkdir(model_path)","9ed9cc6a":"def get_callback(model_name, patient):\n    ES = EarlyStopping(\n        monitor='val_f1score', \n        patience=3, \n        mode='max', \n        min_delta=0,\n        verbose=1)\n    RR = ReduceLROnPlateau(\n        monitor = 'val_f1score', \n        factor = 0.5, \n        patience = 2,\n        min_lr=0.00001, \n        verbose=1, \n        mode='max')\n    MC = ModelCheckpoint(\n        filepath=model_name, \n        monitor='val_f1score', \n        verbose=1, \n        save_best_only=True, \n        mode='max')\n\n    return [ES, RR, MC]","b2d4b0d8":"def recall(y_target, y_pred):\n    y_target_yn = K.round(K.clip(y_target, 0, 1))\n    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n    count_true_positive_false_negative = K.sum(y_target_yn)\n    recall = count_true_positive \/ (count_true_positive_false_negative + K.epsilon())\n\n    return recall\n\ndef precision(y_target, y_pred):\n    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) \n    y_target_yn = K.round(K.clip(y_target, 0, 1)) \n    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n    count_true_positive_false_positive = K.sum(y_pred_yn)\n    precision = count_true_positive \/ (count_true_positive_false_positive + K.epsilon())\n\n    return precision\n\ndef f1score(y_target, y_pred):\n    _recall = recall(y_target, y_pred)\n    _precision = precision(y_target, y_pred)\n    _f1score = ( 2 * _recall * _precision) \/ (_recall + _precision+ K.epsilon())\n    \n    return _f1score","9fa8d93f":"def get_model(model_name, iamge_size):\n    base_model = model_name(weights='imagenet', input_shape=(iamge_size,iamge_size,3), include_top=False)\n    #base_model.trainable = False\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(1024, activation='selu'))\n    model.add(layers.Dropout(0.4))\n \n    model.add(layers.Dense(196, activation='softmax', kernel_initializer='he_normal'))\n    model.summary()\n\n    # optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n    # optimizer='adam'\n    # optimizer=RMSprop(lr=0.0001)\n    # optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True)\n    # optimizer=Adadelta(rho=0.95)\n    \n    optimizer = optimizers.Adadelta(rho=0.95)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc', f1score])\n\n    return model","19d68842":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import Xception, NASNetLarge, InceptionResNetV2\n\n# Parameter\n# ResNet50, ResNeXt101 -> 224\n# Xception,InceptionResNetV2 -> 299\n# NASNetLarge -> 331\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    fill_mode='nearest'\n    )\n\nvalid_datagen = ImageDataGenerator(\n    rescale=1.\/255\n    )\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255\n    )","86391a5d":"skf = StratifiedKFold(n_splits=k_folds, random_state=2019)","b6ecbf27":"j = 1\n#model_xception_names = []\nfor (train_index, valid_index) in skf.split(\n    df_train['img_file'], \n    df_train['class']):\n\n    traindf = df_train.iloc[train_index, :].reset_index()\n    validdf = df_train.iloc[valid_index, :].reset_index()\n\n    print(\"=========================================\")\n    print(\"====== K Fold Validation step => %d\/%d =======\" % (j,k_folds))\n    print(\"=========================================\")\n    \n    train_generator = train_datagen.flow_from_dataframe(\n        dataframe=traindf,\n        directory=TRAIN_CROPPED_PATH,\n        x_col='img_file',\n        y_col='class',\n        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=BATCH_SIZE,\n        seed=2019,\n        shuffle=True\n        )\n\n#    valid_generator = valid_datagen.flow_from_dataframe(\n#        dataframe=validdf,\n#        directory=TRAIN_CROPPED_PATH,\n#        x_col='img_file',\n#        y_col='class',\n#        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n#        color_mode='rgb',\n#        class_mode='categorical',\n#        batch_size=BATCH_SIZE,\n#        seed=2019,\n#        shuffle=True\n#        )\n#\n#    model_name = model_path + str(j) + '_xception.hdf5'\n#    model_xception_names.append(model_name)\n#    \n#    model_xception = get_model(Xception, IMAGE_SIZE)\n#    \n#    try:\n#        model_xception.load_weights(model_name)\n#    except:\n#        pass\n#        \n#    history = model_xception.fit_generator(\n#        train_generator,\n#        steps_per_epoch=len(traindf.index) \/ BATCH_SIZE,\n#        epochs=EPOCHS,\n#        validation_data=valid_generator,\n#        validation_steps=len(validdf.index) \/ BATCH_SIZE,\n#        verbose=1,\n#        shuffle=False,\n#        callbacks = get_callback(model_name, 4)\n#        )\n#        \n    j+=1","b917b284":"test_generator = test_datagen.flow_from_dataframe(\n    dataframe=df_test,\n    directory=TEST_CROPPED_PATH,\n    x_col='img_file',\n    y_col=None,\n    target_size= (IMAGE_SIZE, IMAGE_SIZE),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","82d1970f":"model_xception_names = ['..\/input\/3rd-ml-month-xception-weight\/1_xception.hdf5','..\/input\/3rd-ml-month-xception-weight\/2_xception.hdf5','..\/input\/3rd-ml-month-xception-weight\/3_xception.hdf5','..\/input\/3rd-ml-month-xception-weight\/4_xception.hdf5','..\/input\/3rd-ml-month-xception-weight\/5_xception.hdf5']\n\nxception_prediction = []\nfor i, name in enumerate(model_xception_names):\n    model_xception = get_model(Xception, IMAGE_SIZE)\n    model_xception.load_weights(name)\n    test_generator.reset()\n    pred = model_xception.predict_generator(\n        generator=test_generator,\n        steps = len(df_test)\/BATCH_SIZE,\n        verbose=1\n    )\n    xception_prediction.append(pred)\n\ny_pred_xception = np.mean(xception_prediction, axis=0)","cbc51314":"preds_class_indices=np.argmax(y_pred_xception, axis=1)","5fa4ab6d":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nfinal_pred = [labels[k] for k in preds_class_indices]","da8d513b":"submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\nsubmission[\"class\"] = final_pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","425b3bc6":"## \uacb0\uacfc \uc800\uc7a5","59e6d8bc":"## Model \uc815\uc758","ae23fa45":"## Image Cropped","2e41186d":"## Generator","9c759ec6":"### \ub2e4\uc74c \ubc0f\uc758 \ucee4\ub110\ub4e4\uc744 \ucc38\uc870\ud558\uc5ec \uc791\uc131\ud558\uc600\uc2b5\ub2c8\ub2e4. \ucee4\ub110 \uacf5\uc720\ud574\uc8fc\uc154\uc11c \uc815\ub9d0 \uac10\uc0ac\ud569\ub2c8\ub2e4!\n - \uae40\ud0dc\uc9c4\ub2d8\uc758 \"[3rd ML Month] Car Model Classification Baseline\"\n - \ud5c8\ud0dc\uba85\ub2d8\uc758 \"[3rd ML Month] Car Image Cropping - updated 7.10\"\n - Jang\ub2d8\uc758 \"[3rd ML Month] Xception, StratifiedKFold, Ensemble\"","c76b542d":"## F1score(\ud3c9\uac00 \uc9c0\ud45c) \uc815\uc758","c9c970d4":"## Ensemble Model","38ff70e1":"## K-Fold Cross Validation(With StratifiedKFold)","a491c98f":"## Callback \ud568\uc218 \uc815\uc758","c85bb611":"# <center>3rd ML Month - Car Model Classification <\/center>\n![Main Image](https:\/\/t1.daumcdn.net\/cfile\/tistory\/2738983451EB766507)","eb24f281":" - \ubc11\uc758 \ucf54\ub4dc\ub294 Inference \ucee4\ub110 \ucf54\ub4dc\uc785\ub2c8\ub2e4.\n - \uc559\uc0c1\ube14\uc5d0 \uc0ac\uc6a9\ud55c Weight\ub97c \ub9cc\ub4e0 \ucee4\ub110\uc740 Version2\ub97c \ubcf4\uc2dc\uba74 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4."}}