{"cell_type":{"a31b4246":"code","78e5e240":"code","ac3132b4":"code","c13db3a7":"code","b7c288cd":"code","9fc289e9":"code","8fcf4c3a":"code","538660a5":"code","d9462eda":"code","849c325c":"code","2f5e9d5d":"code","02811dbb":"code","0b2c96f4":"code","be9e511a":"code","21d32e9e":"code","0dbb12d2":"code","ca95d808":"code","f1a80648":"code","fcb6bb3b":"code","089f9c99":"code","70b85bcc":"code","c6b23764":"code","426a816f":"code","e26f8fd4":"code","52c5bc10":"code","f81b62f2":"code","16da81e8":"code","d8282614":"code","85eff80d":"code","1aa2e8a2":"code","bdfd37cd":"code","9e9e7a4f":"code","4207f003":"code","45056232":"code","41c9443c":"code","a165d334":"code","1ec88190":"code","8326d930":"code","5a9d0b48":"code","4c618c4b":"code","50a1c231":"code","7d6dbb32":"code","d8112822":"code","ef1f8572":"code","968dd5f7":"code","f7fa53d2":"code","ad5cfe8f":"code","6c4328de":"code","6a466c8d":"code","08106d45":"code","8a8246cb":"code","87cfae5c":"code","0610faac":"code","6359c9a6":"code","bfdf951b":"code","43243d1d":"code","a5779abc":"code","e2378585":"code","fc3ef239":"code","3f6f8010":"markdown","a628d8f8":"markdown","b7a34e0b":"markdown","5bd0f229":"markdown","7982675e":"markdown","a7f4dfd8":"markdown","6025f0db":"markdown","8c89edfd":"markdown","e0278b46":"markdown","88e0e44d":"markdown","d2550b07":"markdown","d3e616c6":"markdown","68174cbe":"markdown","4e4fd779":"markdown","9e5b5251":"markdown","d8f45284":"markdown","60003a52":"markdown","52edd1ab":"markdown","dbac191b":"markdown","1134d149":"markdown","c68ee06c":"markdown","8445a870":"markdown","8a588d8e":"markdown","ae737162":"markdown","9848b98a":"markdown","024e0baa":"markdown","b059d3a1":"markdown","16b50248":"markdown","317eaf24":"markdown","5442e9f2":"markdown","c52fb17d":"markdown","a96b3e8a":"markdown","08ea4cd1":"markdown","1d3249bd":"markdown","2834b53b":"markdown","35807bce":"markdown","5e557d19":"markdown","e87149a6":"markdown","9d6fe825":"markdown","f51be22d":"markdown","97de25cd":"markdown"},"source":{"a31b4246":"import os\nimport plotly.express as px\nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport re\nfrom sklearn.neighbors import NearestNeighbors\nimport random\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n!pip install mlxtend","78e5e240":"dataNames = pd.read_csv(\"\/kaggle\/input\/movierecommenderdataset\/movies.csv\")\ndataRatings = pd.read_csv(\"\/kaggle\/input\/movierecommenderdataset\/ratings.csv\")","ac3132b4":"dataRatings.head()  # First dataset ","c13db3a7":"dataNames.head()  # Second dataset","b7c288cd":"# Inner join of two datasets (common column is movieId)\ndata = pd.merge(dataRatings, dataNames, how='inner')\ndata.head()","9fc289e9":"# Number of Users who rated at least one movie:\nprint(\"Number of Users who rated at least one move: \", data.userId.nunique())\nprint(\"-\"*25)\n\n# Number of Movies in the dataset:\nprint(\"Number of Movies in the dataset:\", data.title.nunique())\nprint(\"-\"*25)\n\n# Unique of Rating points in the dataset:\nprint(\"Unique Rating points:\", data.rating.unique())","8fcf4c3a":"# Extracting movie release years into one column\ndata['movie_year'] = data.title.str.extract('.*\\((.*)\\).*')\ndata.head()","538660a5":"# Removing year from the movie titles\ndata['title'] = data.title.str.split('(').str[0].str[:-1]\ndata.head()","d9462eda":"def UNIX_to_Readable(df):\n    return pd.to_datetime(datetime.fromtimestamp(df).strftime('%Y-%m-%d %H:%M:%S'))\n\n\n# Converting Unix date-format to readable format\ndata.timestamp = data.timestamp.apply(UNIX_to_Readable)\ndata.head()","849c325c":"# Removing decimal values to the ceiling value to decrease number of rating classes\ndata.rating = np.ceil(data.rating)\nprint(\"Unique Rating Points:\", data.rating.unique())","2f5e9d5d":"_ = data.title.value_counts()\nfig = px.histogram(_, x=_, opacity=0.85, marginal='box',\n                   labels={\n                       'x': 'Number of Ratings taken'})\nfig.update_traces(marker=dict(line=dict(color='#000000', width=1)))\nfig.update_layout(title_text='Distribution of the Number of Ratings taken by the Movies',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","02811dbb":"# Removing movies that rated less than 10\nmovieFrequency_greater_10 = data['movieId'].value_counts()[data['movieId'].value_counts() >= 10].index\ndata = data[data.movieId.isin(movieFrequency_greater_10)]\n\nprint(\"Minimum Number of Rated Movies after Drop:\", data.title.value_counts().nsmallest(5))   # So we achieved to obtain number of ratings taken by users minimum 10","0b2c96f4":"rating_val_count = data.rating.value_counts()\nfig = px.bar(rating_val_count, x=rating_val_count.index, y=rating_val_count, text=rating_val_count,\n             labels={\n                 \"index\": \"Ratings\",\n                 'y': 'Number of Ratings'},\n             color=rating_val_count\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Frequency of the Ratings',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","be9e511a":"genres_value_counts = data['genres'].str.split('|', expand=True).stack().value_counts()\nfig = px.bar(genres_value_counts, x=genres_value_counts.index, y=genres_value_counts, text=genres_value_counts,\n             labels={\n                 \"index\": \"Genres\",\n                 'y': 'Frequency'},\n             color=genres_value_counts\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top Frequent the Movie Genres',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","21d32e9e":"unique_movies = data.drop_duplicates('title')\nunique_movies = unique_movies['genres'].str.split('|', expand=True).stack().value_counts()\nfig = px.bar(unique_movies, x=unique_movies.index, y=unique_movies, text=unique_movies,\n             labels={\n                 \"index\": \"Genres\",\n                 'y': 'Number of Movies'},\n             color=unique_movies\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Number of Movies for each Genre',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","0dbb12d2":"data['timeDifferenceAfterRelease'] = data.timestamp.dt.year - data.movie_year.astype(int)\nfig = px.histogram(data, x='timeDifferenceAfterRelease', opacity=0.85, marginal='box',\n                   labels={\n                       'timeDifferenceAfterRelease': 'Time Difference After Release (years)'}\n                   )\nfig.update_traces(marker=dict(line=dict(color='#000000', width=1)))\nfig.update_layout(title_text='Year Difference Between Release Date of the Movie and the Rating Date',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","ca95d808":"num_of_rating_weekly = data.resample('m', on='timestamp').size()\nfig = px.line(num_of_rating_weekly, x=num_of_rating_weekly.index, y=num_of_rating_weekly,\n              labels={'y': 'Number of Ratings given',\n                      'timestamp': 'Months'})\nfig.update_layout(title_text='Number of Ratings given by the Users Monthly',\n                  title_x=0.5, title_font=dict(size=20))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.update_traces(line=dict(width=3))\nfig.show()","f1a80648":"unique_title = data.drop_duplicates(['title'])  # Dropping duplicate movie titles\nunique_title = unique_title.movie_year.value_counts().reset_index().sort_values('index')  # Count of each years movie frequency\nfig = px.line(unique_title, x='index', y='movie_year',\n              labels={\n                  \"index\": \"Movie Release Year\",\n                  'movie_year': 'Number of Movies Released'})\nfig.update_layout(title_text='Number of Movies Released each Year',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","fcb6bb3b":"unique_title = data.drop_duplicates(['title'])  # Dropping duplicate movie titles\nunique_title = unique_title.movie_year.value_counts().head(25)  # Count of each years movie frequency\nfig = px.bar(unique_title, x=unique_title.index, y=unique_title, text=unique_title,\n             labels={\n                 \"index\": \"Movie Release Year\",\n                 'y': 'Number of Movies Released'},\n             color=unique_title\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 25 Years with the most Number of Movies Released',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()\n","089f9c99":"genre_vs_rating = data.groupby(['genres', 'rating']).size().unstack().fillna(0)\nyear_vs_rating = data.groupby(['movie_year', 'rating']).size().unstack().fillna(0)\nmovie_vs_rating = data.groupby(['title', 'rating']).size().unstack().fillna(0)","70b85bcc":"# Let's calculate the Weighted Average for dataframe rows\ndef Weighted_Average(df):\n    x = []\n    for i in range(0, df.shape[0]):\n        x.append((np.average(df.iloc[i].index, weights=df.iloc[i].values, axis=0)).round(2))\n    return x\n\n# Weighted Average calculation for each movie_vs_rating rows\nmovie_vs_rating['weightedAverage'] = Weighted_Average(movie_vs_rating)\nmovie_vs_rating.sort_values('weightedAverage', ascending=False).head()\n\n# Weighted Average calculation for each year_vs_rating rows\nyear_vs_rating['weightedAverage'] = Weighted_Average(year_vs_rating)\n\n# Weighted Average calculation for each genre_vs_rating rows\ngenre_vs_rating['weightedAverage'] = Weighted_Average(genre_vs_rating)","c6b23764":"fig = px.bar(movie_vs_rating, x=movie_vs_rating['weightedAverage'].nlargest(15).index,\n             y=movie_vs_rating['weightedAverage'].nlargest(15),\n             text=movie_vs_rating['weightedAverage'].nlargest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=movie_vs_rating['weightedAverage'].nlargest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Movie with the highest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","426a816f":"fig = px.bar(movie_vs_rating, x=movie_vs_rating['weightedAverage'].nsmallest(15).index,\n             y=movie_vs_rating['weightedAverage'].nsmallest(15),\n             text=movie_vs_rating['weightedAverage'].nsmallest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=movie_vs_rating['weightedAverage'].nsmallest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Movie with the smallest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","e26f8fd4":"fig = px.bar(year_vs_rating, x=year_vs_rating['weightedAverage'].nlargest(15).index,\n             y=year_vs_rating['weightedAverage'].nlargest(15),\n             text=year_vs_rating['weightedAverage'].nlargest(15),\n             labels={\n                 \"x\": \"Years\",\n                 'y': 'Weighted Rating Averages'},\n             color=year_vs_rating['weightedAverage'].nlargest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Years with the highest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","52c5bc10":"fig = px.bar(year_vs_rating, x=year_vs_rating['weightedAverage'].nsmallest(15).index,\n             y=year_vs_rating['weightedAverage'].nsmallest(15),\n             text=year_vs_rating['weightedAverage'].nsmallest(15),\n             labels={\n                 \"x\": \"Years\",\n                 'y': 'Weighted Rating Averages'},\n             color=year_vs_rating['weightedAverage'].nsmallest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Years with the smallest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","f81b62f2":"fig = px.bar(genre_vs_rating, x=genre_vs_rating['weightedAverage'].nlargest(15).index,\n             y=genre_vs_rating['weightedAverage'].nlargest(15),\n             text=genre_vs_rating['weightedAverage'].nlargest(15),\n             labels={\n                 \"x\": \"Genres\",\n                 'y': 'Weighted Rating Averages'},\n             color=genre_vs_rating['weightedAverage'].nlargest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Genres with the highest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","16da81e8":"fig = px.bar(genre_vs_rating, x=genre_vs_rating['weightedAverage'].nsmallest(15).index,\n             y=genre_vs_rating['weightedAverage'].nsmallest(15),\n             text=genre_vs_rating['weightedAverage'].nsmallest(15),\n             labels={\n                 \"x\": \"Genres\",\n                 'y': 'Weighted Rating Averages'},\n             color=genre_vs_rating['weightedAverage'].nsmallest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Genres with the smallest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","d8282614":"# Creating a new DataFrame for unique movies with their weightedAverages and Genres\n_ = data.merge(movie_vs_rating.reset_index()).drop_duplicates('title')[['title', 'genres', 'weightedAverage']]\n_.head()","85eff80d":"drama_movies = _[_.genres.str.contains('Drama')].sort_values('weightedAverage', ascending=False).set_index('title')\nfig = px.bar(drama_movies, x=drama_movies['weightedAverage'].nlargest(15).index,\n             y=drama_movies['weightedAverage'].nlargest(15),\n             text=drama_movies['weightedAverage'].nlargest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=drama_movies['weightedAverage'].nlargest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Drama Movies with the largest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","1aa2e8a2":"drama_movies = _[_.genres.str.contains('Drama')].sort_values('weightedAverage', ascending=False).set_index('title')\nfig = px.bar(drama_movies, x=drama_movies['weightedAverage'].nsmallest(15).index,\n             y=drama_movies['weightedAverage'].nsmallest(15),\n             text=drama_movies['weightedAverage'].nsmallest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=drama_movies['weightedAverage'].nsmallest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Drama Movies with the smallest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","bdfd37cd":"action_movies = _[_.genres.str.contains('Action')].sort_values('weightedAverage', ascending=False).set_index('title')\nfig = px.bar(action_movies, x=action_movies['weightedAverage'].nlargest(15).index,\n             y=action_movies['weightedAverage'].nlargest(15),\n             text=action_movies['weightedAverage'].nlargest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=action_movies['weightedAverage'].nlargest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Action Movies with the largest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","9e9e7a4f":"action_movies = _[_.genres.str.contains('Action')].sort_values('weightedAverage', ascending=False).set_index('title')\nfig = px.bar(action_movies, x=action_movies['weightedAverage'].nsmallest(15).index,\n             y=action_movies['weightedAverage'].nsmallest(15),\n             text=action_movies['weightedAverage'].nsmallest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=action_movies['weightedAverage'].nsmallest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Action Movies with the smallest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","4207f003":"sci_fi_movies = _[_.genres.str.contains('Sci-Fi')].sort_values('weightedAverage', ascending=False).set_index('title')\nfig = px.bar(sci_fi_movies, x=sci_fi_movies['weightedAverage'].nlargest(15).index,\n             y=sci_fi_movies['weightedAverage'].nlargest(15),\n             text=sci_fi_movies['weightedAverage'].nlargest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=sci_fi_movies['weightedAverage'].nlargest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Sci-Fi Movies with the largest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","45056232":"sci_fi_movies = _[_.genres.str.contains('Sci-Fi')].sort_values('weightedAverage', ascending=False).set_index('title')\nfig = px.bar(sci_fi_movies, x=sci_fi_movies['weightedAverage'].nsmallest(15).index,\n             y=sci_fi_movies['weightedAverage'].nsmallest(15),\n             text=sci_fi_movies['weightedAverage'].nsmallest(15),\n             labels={\n                 \"x\": \"Movies\",\n                 'y': 'Weighted Rating Averages'},\n             color=sci_fi_movies['weightedAverage'].nsmallest(15)\n             )\nfig.update_traces(textposition='outside')\nfig.update_layout(title_text='Top 15 Sci-Fi Movies with the smallest Weighted Averages',\n                  title_x=0.5, title_font=dict(size=24))\nfig.update_traces(marker=dict(line=dict(color='#000000', width=2)))\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.show()","41c9443c":"# Created a (movieId: title) dictionary for all movieId's for replacing them with their names\nmovieId_dict = data.drop_duplicates('title')[['movieId', 'title']].set_index('movieId').to_dict()['title']\n\n# First 5 elements of this dictionary\nlist(movieId_dict.items())[:5]","a165d334":"# Creating a pivot table that has indexes as user ratings, and columns as each movie title\ndataRecommendation = data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n\n# Replacing dataRecommendation columns with the movie titles\ndataRecommendation.columns = dataRecommendation.columns.map(movieId_dict)\n\ndataRecommendation.head(10)","1ec88190":"def encode_units(k):\n    if k <= 0:\n        return 0\n    if k >= 1:\n        return 1\n\n\nsets = dataRecommendation.applymap(encode_units)\nsets.head()","8326d930":"# Applying Apriori algorithm to matrix that we created before (userId-movieId) and setting min support as 0.15\nfrequent_itemsets = apriori(sets, min_support=0.15, use_colnames=True)\n\nrules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.75).sort_values('lift', ascending=False)\n\nrules = rules[['antecedents', 'consequents', 'support', 'lift', 'confidence']]\nrules.head()","5a9d0b48":"i = random.randint(0, rules.shape[0])\nprint('Antecedents:', rules.iloc[i].antecedents)\nprint('Consequents:', rules.iloc[i].consequents)\nprint(f'Lift: {rules.iloc[i].lift.round(3)} & Confidence: {rules.iloc[i].confidence.round(3)}')","4c618c4b":"i = random.randint(0, rules.shape[0])\nprint('Antecedents:', rules.iloc[i].antecedents)\nprint('Consequents:', rules.iloc[i].consequents)\nprint(f'Lift: {rules.iloc[i].lift.round(3)} & Confidence: {rules.iloc[i].confidence.round(3)} & Support: {rules.iloc[i].support.round(3)}')","50a1c231":"i = random.randint(0, rules.shape[0])\nprint('Antecedents:', rules.iloc[i].antecedents)\nprint('Consequents:', rules.iloc[i].consequents)\nprint(f'Lift: {rules.iloc[i].lift.round(3)} & Confidence: {rules.iloc[i].confidence.round(3)} & Support: {rules.iloc[i].support.round(3)}')","7d6dbb32":"i = random.randint(0, rules.shape[0])\nprint('Antecedents:', rules.iloc[i].antecedents)\nprint('Consequents:', rules.iloc[i].consequents)\nprint(f'Lift: {rules.iloc[i].lift.round(3)} & Confidence: {rules.iloc[i].confidence.round(3)} & Support: {rules.iloc[i].support.round(3)}')","d8112822":"# I will use NearestNeighbors algorithm that I learnt from the scikit-learn documentation here\nknn = NearestNeighbors(n_neighbors=11, metric='cosine', algorithm='brute', n_jobs=-1)\nknn.fit(dataRecommendation.values.T)","ef1f8572":"# Here is our recommendations for Blade Runner, there will be 7 movie recommendations\nrecommendation_result = list(knn.kneighbors([dataRecommendation['Blade Runner'].values], 8))\n\nrecommendation_result  # As you can see from the results, we obtained cosine angles in the first array, and the second array gives us the dataRecommendation column order, I need to convert it to more readable form","968dd5f7":"recommendations = pd.DataFrame(np.vstack((recommendation_result[1], recommendation_result[0])),\n                 index=['movieId', 'Cosine_Similarity (degree)']).T\nrecommendations = recommendations.drop([0]).reset_index(drop=True)\nrecommendations  # In this step, I created a dataframe that stores the movieId (for dataRecommendation column order) and Cosine Similarity in degrees","f7fa53d2":"a = dataRecommendation.columns.to_frame().reset_index(drop=True).to_dict()['movieId']\nrecommendations.movieId = recommendations.movieId.map(a)\nrecommendations","ad5cfe8f":"# Movie Recommendation as Function\n\ndef movie_recommendation(movie_name, num_of_recommendations):\n    a = dataRecommendation.columns.to_frame().reset_index(drop=True).to_dict()['movieId']\n    recommendation_result = list(knn.kneighbors([dataRecommendation[movie_name].values], num_of_recommendations + 1))\n    recommendation_result = pd.DataFrame(np.vstack((recommendation_result[1], recommendation_result[0])),\n                                         index=['movieId', 'Cosine_Similarity (degree)']).T\n    recommendation_result = recommendation_result.drop([0]).reset_index(drop=True)\n    recommendation_result.movieId = recommendation_result.movieId.map(a)\n    return recommendation_result","6c4328de":"movie_recommendation('Amazing Spider-Man, The', 7)","6a466c8d":"movie_recommendation('Mulan', 7)","08106d45":"movie_recommendation('Final Destination', 7)","8a8246cb":"movie_recommendation('Shining, The', 7)","87cfae5c":"movie_recommendation('Pulp Fiction', 7)","0610faac":"movie_recommendation(\"Reservoir Dogs\", 7)","6359c9a6":"movie_recommendation('Batman Returns', 7)","bfdf951b":"movie_recommendation('Logan', 7)","43243d1d":"movie_recommendation('Matrix, The', 7)","a5779abc":"movie_recommendation('Casablanca', 7)","e2378585":"movie_recommendation(\"Harry Potter and the Sorcerer's Stone\", 7)","fc3ef239":"movie_recommendation('Rain Man', 7)","3f6f8010":"# <center> Movie Recommendation Engine and EDA","a628d8f8":"**Drama, Comedy and Action genres are the top frequent genres according to our dataset. These genres are rated most of the users.**","b7a34e0b":"**As we discovered above, there are some ratings are not integers. For narrowing down the number of unique rating points, I will use ceiling function and obtain only ratings between 1 and 5.**","5bd0f229":"# Top 15 Sci-Fi Movies with the smallest Weighted Averages","7982675e":"# Exploratory Data Analysis","a7f4dfd8":"# Thanks!","6025f0db":"# Some Movie Recommendations","8c89edfd":"# Top 15 Movie with the smallest Weighted Averages\n","e0278b46":"# Top 25 Years with the most Number of Movies Released\n","88e0e44d":"# Top 15 Action Movies with the smallest Weighted Averages","d2550b07":"# Creating new Features and Data Preprocessing\n","d3e616c6":"**As you can see from above, userId and movieId is two important columns for differentiate the each user and movie.**\n**For the following column which is Rating, is the rating of the each user for one or multiple movies.**\n**Following column timestamp represents the date in terms of UNIX date format.**\n**And last two columns represents the title and genre of the each movie.**","68174cbe":"# Top 15 Sci-Fi Movies with the largest Weighted Averages","4e4fd779":"**timestamp column has not readable data points. We cannot use this values for our analysis. Hence, I will convert this values into Readable format.**","9e5b5251":"# Some Examples of Apriori Rules ","d8f45284":"# Top 15 Movie with the highest Weighted Averages\n","60003a52":"**As you can see from the title column, there is a movie release date inside the parentheses after the name of the movie. I would like to extract the movie release years into one column and answer some questions such as \"Which years is the top-rated years?\", \"Which year has the highest movie release count?\", etc.**","52edd1ab":"# Apriori Algorithm Application for Movie Recommendation Dataset","dbac191b":"# Top 15 Years with the highest Weighted Averages\n","1134d149":"# Year Difference Between Release Date of the Movie and the Rating Date\n","c68ee06c":"**From now on, we can find the movie years on the movie_year column**","8445a870":"**Thank you if you followed me so far, I hope you enjoyed this notebook! I am open to feedback and suggestions, feel free to comment them down or feel free to contact me!**\n\n**For future work, I'd create a simple website that gives movie recommendations with some specific movie details. I'd share this website in the comments after it's done! See you on the other notebooks.**","8a588d8e":"# Number of Movies for each Genre","ae737162":"# Let's Build Item-Based Collaborative Filtering Recommendation Engine","9848b98a":"# Top 15 Years with the smallest Weighted Averages\n","024e0baa":"# Number of Movies Released each Year\n","b059d3a1":"**According to Apirori Algorithm above, some of the examples are looking pretty good. Antecedent and Consequent pairs are pretty reasonable for some instances, really nice.**","16b50248":"# Top 15 Genres with the highest Weighted Averages\n","317eaf24":"**Most of the movies are rated on 1996 and 1995. And the number of movies released yearly increase until 1995 pretty fast. In contrast, the number of movies released yearly decrease after 2002 rapidly**","5442e9f2":"**According to the figure above, most of the movies are rated by only one user (3272 movies). These movies wouldn't help us to create a movie recommendation engine because we are going to create a collaborative filtering-based recommendation engine. Hence, I will drop movies that rated less than 10 users.**","c52fb17d":"# Frequency of the Ratings\n","a96b3e8a":"**Hello, welcome to this Notebook!**\n\n**In this notebook, I will be working on the Movie Recommendation dataset.**\n\n**First of all, I will make some exploratory data analysis for the features and create some new columns. And then, I will try to create a Movie Recommendation Engine.**\n\n**I am open to feedback and suggestions, feel free to comment your feedback and suggestions on the comment section or contact me.**\n\n**So, let's get started!**","08ea4cd1":"# Top 15 Drama Movies with the smallest Weighted Averages\n","1d3249bd":"**According to figure above, most of the users rated movies 4.**","2834b53b":"# Top 15 Drama Movies with the largest Weighted Averages\n","35807bce":"# Top Frequent the Movie Genres","5e557d19":"**In this step, I will create new features for more detailed EDA and then, I will prepare the dataset for further steps.**","e87149a6":"# Top 15 Genres with the smallest Weighted Averages\n","9d6fe825":"# Top 15 Action Movies with the largest Weighted Averages","f51be22d":"**According to the Year Difference Between Release Date of the Movie and the Rating Date graph above, most of the movies rated after 1 year of the movie release year. There is a movie that rated after 116 years named \"Trip to the Moon\". A great movie inspired by Jules Verne's book.**\n\n**Most of the movies are distributed between 3 and 18 years after the movie release date.**","97de25cd":"# Number of Ratings given by the Users Monthly\n"}}