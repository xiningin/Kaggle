{"cell_type":{"6d530371":"code","29bda020":"code","ae0f9e7f":"code","29742174":"code","66f3fda0":"code","cdc6acae":"code","f3e63136":"code","749219d6":"code","103dea6a":"code","ab6ee095":"code","7fce95c2":"code","05908263":"code","a91705ef":"code","833b704f":"code","369f067f":"code","3b51f45f":"code","6d1e664e":"code","b2d67a62":"code","84c4006b":"code","9c1d2969":"code","6e4121c3":"code","d98f0245":"code","43ef38ca":"code","9a7bf773":"code","d5fe23b2":"markdown","2d2b0ff4":"markdown","7967f0ca":"markdown","9ed8655a":"markdown","2c6ef789":"markdown","c812a0b1":"markdown"},"source":{"6d530371":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29bda020":"import random\nimport shutil\nimport zipfile\n\n\n\npath_cats_and_dogs = '\/kaggle\/input\/dogs-vs-cats\/train.zip'\nshutil.rmtree('\/tmp')\n\nlocal_zip = path_cats_and_dogs\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/tmp\/source')\nzip_ref.close()","ae0f9e7f":"os.mkdir('\/tmp\/train')\nos.mkdir('\/tmp\/train\/cats')\nos.mkdir('\/tmp\/train\/dogs')\nos.mkdir('\/tmp\/valid')\nos.mkdir('\/tmp\/valid\/cats')\nos.mkdir('\/tmp\/valid\/dogs')","29742174":"filenames=os.listdir('\/tmp\/source\/train')\nsplit_by=int(len(filenames)*0.8)\ntrain_files=random.sample(filenames,split_by)                  \nval_files = list(set(filenames)-set(train_files)) \n# Dividing images for Training and Validation \n\nfor filename in train_files:\n    if (filename[0:3]=='dog'):\n        shutil.copyfile('\/tmp\/source\/train\/'+filename,'\/tmp\/train\/dogs\/'+filename)\n    else:\n        shutil.copyfile('\/tmp\/source\/train\/'+filename,'\/tmp\/train\/cats\/'+filename)\n        \n        \nfor filename in val_files:\n    if (filename[0:3]=='dog'):\n        shutil.copyfile('\/tmp\/source\/train\/'+filename,'\/tmp\/valid\/dogs\/'+filename)\n    else:\n        shutil.copyfile('\/tmp\/source\/train\/'+filename,'\/tmp\/valid\/cats\/'+filename)\n","66f3fda0":"print(len(os.listdir('\/tmp\/train\/dogs')))\nprint(len(os.listdir('\/tmp\/train\/cats')))\n\nprint(len(os.listdir('\/tmp\/valid\/dogs')))\nprint(len(os.listdir('\/tmp\/valid\/cats')))","cdc6acae":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","f3e63136":"train_source='\/tmp\/source\/train'\ntrain_dir='\/tmp\/train'\ntrain_cats='\/tmp\/train\/cats'\ntrain_dogs='\/tmp\/train\/dogs'\nvalid_dir='\/tmp\/valid'\nvalid_cats='\/tmp\/valid\/cats'\nvalid_dogs='\/tmp\/valid\/dogs'\n\n","749219d6":"# Displaying 4 Random cat images \n\nplt.figure(figsize=(16,16))\n\nfor i,cat in enumerate(np.random.randint(0,len(os.listdir(train_cats)),4)):\n    fig = plt.subplot(4,4,i+1)\n    fig.axis('off')\n    img=mpimg.imread(os.path.join(train_cats,os.listdir(train_cats)[cat]))\n    fig.imshow(img)\n","103dea6a":"plt.figure(figsize=(16,16))\n\nfor i,dog in enumerate(np.random.randint(0,len(os.listdir(train_dogs)),4)):\n    fig = plt.subplot(4,4,i+1)\n    fig.axis('off')\n    img=mpimg.imread(os.path.join(train_dogs,os.listdir(train_dogs)[dog]))\n    fig.imshow(img)","ab6ee095":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras import optimizers","7fce95c2":"model=Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128,128,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate=0.001), metrics=['accuracy'])\n\nmodel.summary()","05908263":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\nval_datagen=ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=20,\n                                                    target_size=(128,128),\n                                                    class_mode='binary')\nval_generator = val_datagen.flow_from_directory(valid_dir,\n                                                    batch_size=20,\n                                                    target_size=(128,128),\n                                                    class_mode='binary')\n","a91705ef":"img1=load_img(os.path.join(train_cats,os.listdir(train_cats)[4]))\n\nimg_data=img_to_array(img1)\n\nsamples=np.expand_dims(img_data,0)       \n#Loading a single image and applying the augmentation that is applied to the whole dataset \n                                        \n\ndata_gen=ImageDataGenerator(rotation_range=15,\n                            rescale=1.\/255,\n                            shear_range=0.1,\n                            zoom_range=0.2,\n                            horizontal_flip=True,\n                            width_shift_range=0.1,\n                            height_shift_range=0.1)\n \niterator=data_gen.flow(samples,batch_size=1)\n","833b704f":"plt.figure(figsize=(12, 12))\n\nfor i in range(0, 15):                  # Displaying the Augmentation Applied to every image.\n    plt.subplot(5, 3, i+1)\n    for X_batch in iterator:         \n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()\n","369f067f":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","3b51f45f":"earlystop = EarlyStopping(patience=10)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks2 = [earlystop, learning_rate_reduction]","6d1e664e":"batch_size=20\nhistory = model.fit(\n    train_generator,\n    epochs=50,\n    validation_data=val_generator,\n    callbacks=callbacks2\n     )\n\n\n","b2d67a62":"model.save_weights(\"model.h5\")","84c4006b":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 50, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 50, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()\n","9c1d2969":"path_test = '\/kaggle\/input\/dogs-vs-cats\/test1.zip'\nlocal_zip = path_test\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/tmp\/source')\nzip_ref.close()","6e4121c3":"pred = []\nfor pic in os.listdir('\/tmp\/source\/test1'):\n    path = '\/tmp\/source\/test1\/'+ pic\n    img=load_img(path, target_size=(128, 128))\n\n    x=img_to_array(img)\n    x=np.expand_dims(x, axis=0)\n    x=x\/255\n\n    pred.append(int(model.predict_classes(x)))","d98f0245":"id_ = [int(name[:-4]) for name in os.listdir('\/tmp\/source\/test1')]\nlabel = pred","43ef38ca":"import pandas as pd\nsubmission = pd.DataFrame({'id':id_,\n             'label':pred})\n","9a7bf773":"submission.sort_values('id',).to_csv('submission.csv',index=False)\n","d5fe23b2":"# Visualising the Loss and Accuracy","2d2b0ff4":"# Build Model","7967f0ca":"# Predict","9ed8655a":"### CallBack \nTo avoid Overfitting Data","2c6ef789":"# **Visualising data**","c812a0b1":"# Data Augmentation\n"}}