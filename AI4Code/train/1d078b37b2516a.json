{"cell_type":{"47c3c880":"code","12680919":"code","d3514319":"code","1d955d5a":"code","3423bf63":"code","da878d5e":"code","21a0253c":"code","91beb703":"code","8f135dfa":"code","8c9e652b":"code","70a94152":"code","6340f1e4":"code","f83e5e07":"code","c4354686":"code","2ff320aa":"markdown"},"source":{"47c3c880":"import numpy as np\nimport torch\nfrom torch.autograd import Variable","12680919":"from sklearn import datasets, model_selection\nimport matplotlib.pyplot as plt\n\n# \u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445, \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u0432 sklearn. \n# \u0414\u043b\u044f \u044d\u0442\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0431\u0443\u0434\u0435\u043c \u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043b\u0438\u043d\u0435\u0439\u043d\u0443\u044e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u043e\u043d\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c. \nboston_data = datasets.load_boston()\n\n# \u043e\u0442\u0434\u0435\u043b\u0438\u043c \u0432\u0445\u043e\u0434\u044b \u0438 \u0432\u044b\u0445\u043e\u0434\u044b\npoints = boston_data['data']\nvalues = boston_data['target'].reshape(-1, 1)\n\n\n# \u0440\u0430\u0437\u043e\u0431\u044c\u0435\u043c \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e\ntraining_points, test_points, training_values, test_values = model_selection.train_test_split(\n    points, values, test_size=0.33, random_state=42)","d3514319":"# \u0437\u0430\u0434\u0430\u0434\u0438\u043c \u043a\u043b\u0430\u0441\u0441 \u0434\u043b\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438. \u041c\u044b \u043d\u0430\u0441\u043b\u0435\u0434\u0443\u0435\u043c \u0435\u0433\u043e \u043e\u0442 torch.nn.Module\n# \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u044b \u0434\u0432\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438: \n# * __init__ \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442, \u043a\u0430\u043a \u043c\u044b \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442 \u044d\u0442\u043e\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430\n# * forward \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442, \u043a\u0430\u043a \u043c\u044b \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u043e\u0433\u043d\u043e\u0437\n\nclass linearRegression(torch.nn.Module):\n  # \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u043a\u043b\u0430\u0441\u0441\u0430\n  def __init__(self, input_dimension, output_dimension):\n    # \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u043c init \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u044b\u0439 \u0440\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u0441\u043a\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443\n    super(linearRegression, self).__init__() \n    # \u0437\u0430\u0442\u0435\u043c \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0441\u0432\u043e\u0439 \u043f\u0435\u0440\u0432\u044b\u0439 \u0441\u043b\u043e\u0439 \u043d\u0430 pytorch\n    # \u0442\u0430\u043a \u043a\u0430\u043a \u043c\u043e\u0434\u0435\u043b\u044c \u0443 \u043d\u0430\u0441 \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f, \u0442\u043e \u0438 \u0441\u043b\u043e\u0439 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0439\n    self.linear = torch.nn.Linear(input_dimension, output_dimension)\n\n  # \u043f\u043e\u0434\u0441\u0447\u0435\u0442 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0430\n  def forward(self, x):\n    out = self.linear(x)\n    return out\n\n# Class instance example:\ninput_dimension = 2# training_points.shape[1]\noutput_dimension = 1\nmodel = linearRegression(input_dimension, output_dimension)\nprint( list(model.parameters()) )\nprint(model.parameters() )\nmodel(torch.tensor([1.,2]).float() ) # That is model prediction on a given vector, it is calculated by \"forward\"","1d955d5a":"0.6781*1 -0.0031*2+0.1091","3423bf63":"c = 0\nfor t in model.parameters() :\n    print(c,type(t), t)\n    #print(dir(t))\n    c+=1","da878d5e":"dir(linearRegression)#, print(linearRegression.parameters)","21a0253c":"# \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442 \u043d\u0430\u0448\u0435\u0433\u043e \u043a\u043b\u0430\u0441\u0441\u0430, \u043f\u043e\u043b\u0443\u0447\u0438\u0432 \u0441\u043f\u0435\u0440\u0432\u0430 \u0440\u0430\u0437\u043c\u0435\u0440\u043d\u043e\u0441\u0442\u0438 \ninput_dimension = training_points.shape[1]\noutput_dimension = 1\n\nmodel = linearRegression(input_dimension, output_dimension)\n\n# \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c GPU, \u0447\u0442\u043e\u0431\u044b \u0432\u0441\u0435 \u0441\u0447\u0438\u0442\u0430\u043b\u043e\u0441\u044c \u0431\u044b\u0441\u0442\u0440\u0435\u0435\nif torch.cuda.is_available():\n    model.cuda()","91beb703":"dir(model)","8f135dfa":"# \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c, \u0447\u0442\u043e \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0438 \u043a\u0430\u043a\nlearning_rate = 1e-3\n\n# \u0431\u0443\u0434\u0435\u043c \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u043d\u0443\u044e \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u0442\u0435\u0440\u044c\ncriterion = torch.nn.MSELoss() \n# \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430 ADAM (\u0434\u0430\u043b\u044c\u0448\u0435 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0437\u043d\u044b\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 \u043f\u043e\u0434\u0440\u043e\u0431\u043d\u0435\u0435)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","8c9e652b":"type(training_points)","70a94152":"epochs = 5000\n\n# \u0432\u0445\u043e\u0434\u043d\u044b\u0435 \u0438 \u0432\u044b\u0445\u043e\u0434\u043d\u044b\u0435 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0441\u043a\u043e\u043d\u0435\u0432\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0432 \u0442\u0435\u043d\u0437\u043e\u0440\u044b\nif torch.cuda.is_available():\n  inputs = Variable(torch.from_numpy(training_points).type(torch.float).cuda())\n  outputs = Variable(torch.from_numpy(training_values).type(torch.float).cuda())\nelse:\n  inputs = Variable(torch.from_numpy(training_points ))\n  outputs = Variable(torch.from_numpy(training_values))\n\ninputs = inputs.float()\noutputs = outputs.float()\n\n    \nfor epoch in range(epochs):\n  # \u043d\u0443\u0436\u043d\u043e \u043e\u0431\u043d\u0443\u043b\u0438\u0442\u044c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b, \u0438\u043d\u0430\u0447\u0435 \u0431\u0443\u0434\u0435\u0442 \u0438\u0445 \u0430\u043a\u043a\u0443\u043c\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c\n  optimizer.zero_grad()\n\n  # \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0432\u044b\u0445\u043e\u0434 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u0432\u0445\u043e\u0434\u043e\u0432\n  training_predictions = model(inputs.float())\n\n  # \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043e\u0432\n  loss_value = criterion(training_predictions, outputs)\n  # \u043f\u043e\u0434\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u044b\n  loss_value.backward()\n\n  # \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u0430\u043f\u0434\u0435\u0439\u0442 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\n  optimizer.step()\n  \n  if epoch % 100 == 1:\n    print('epoch {}, loss {}'.format(epoch, loss_value.item()))","6340f1e4":"# \u0441\u0440\u0430\u0432\u043d\u0438\u043c \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0438 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u044b \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\ntraining_predictions = training_predictions.cpu().data.numpy()\n\nplt.figure(figsize=(9, 9))\nplt.plot(training_values, training_predictions, 'o');\nplt.plot([np.min(training_predictions), np.max(training_values)], \n         [np.min(training_predictions), np.max(training_values)])\nplt.xlabel('\u041d\u0430\u0441\u0442\u043e\u044f\u0449\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u041f\u0440\u043e\u0433\u043d\u043e\u0437');","f83e5e07":"# \u041f\u043e\u043b\u0443\u0447\u0438\u043c \u043f\u0440\u043e\u0433\u043d\u043e\u0437 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\nwith torch.no_grad():\n    if torch.cuda.is_available():\n        test_predictions = model(Variable(torch.from_numpy(test_points).type(torch.float).cuda())).cpu().data.numpy()\n    else:\n        test_predictions = model(Variable(torch.from_numpy(test_points).float())).type(torch.float).data.numpy()","c4354686":"# TODO \u0441\u0440\u0430\u0432\u043d\u0438\u043c \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0438 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u044b \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\nplt.figure(figsize=(9, 9))\nplt.plot(test_values, test_predictions, 'o');\nplt.plot([np.min(test_predictions), np.max(test_values)], \n         [np.min(test_predictions), np.max(test_values)])\nplt.xlabel('\u041d\u0430\u0441\u0442\u043e\u044f\u0449\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435')\nplt.ylabel('\u041f\u0440\u043e\u0433\u043d\u043e\u0437');","2ff320aa":"# What is about ?"}}