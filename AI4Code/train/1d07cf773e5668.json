{"cell_type":{"f1620c7e":"code","33db5fdd":"code","a92a5a98":"code","c232ab69":"code","6e774290":"code","856cebea":"code","42b0c47e":"code","59c96f37":"code","49e8ca81":"code","8bdc2776":"code","2e94ae42":"code","9b59d4fe":"code","f714af86":"markdown","990cdf07":"markdown","a897e1c5":"markdown","2a9ed08c":"markdown","126c44fa":"markdown","42e2fe51":"markdown"},"source":{"f1620c7e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn import model_selection\nimport lightgbm as lgbm\nimport xgboost as xgb\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nimport optuna\nimport tqdm","33db5fdd":"train=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntest=pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")","a92a5a98":"train.head()","c232ab69":"train.isnull().sum()","6e774290":"y = train['loss']\ntrain.drop(['id','loss'],axis=1,inplace=True)\ntest.drop(['id'],axis=1,inplace=True)","856cebea":"# Feature Distribution\n#fig = plt.figure(figsize = (15, 60))\n#for i in range(len(train.columns.tolist()[:100])):\n#    plt.subplot(20,5,i+1)\n#    sns.set_style(\"white\")\n#    plt.title(train.columns.tolist()[:100][i], size = 12, fontname = 'monospace')\n#    a = sns.kdeplot(train[train.columns.tolist()[:100][i]], color = '#34675c', shade = True, alpha = 0.9, linewidth = 1.5, edgecolor = 'black')\n#    plt.ylabel('')\n#    plt.xlabel('')\n#    plt.xticks(fontname = 'monospace')\n#    plt.yticks([])\n#    for j in ['right', 'left', 'top']:\n#        a.spines[j].set_visible(False)\n#        a.spines['bottom'].set_linewidth(1.2)\n#        \n#fig.tight_layout(h_pad = 3)\n#\n#plt.show()","42b0c47e":"# Scaling and LDA\nnot_features = ['id', 'loss']\nfeatures = []\nfor feat in train.columns:\n    if feat not in not_features:\n        features.append(feat)\n\nscaler = StandardScaler()\ntrain[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])\n\nx = train\n\nlda = LDA(n_components=42, solver='svd')\nX_lda = lda.fit_transform(x, y)\n\nEVR = lda.explained_variance_ratio_\nfor idx, R in enumerate(EVR):\n    print(\"Component {}: {}% var\".format(idx+1, np.round(R*100,2)))\n","59c96f37":"def objective(trial,data=x,target=y):\n    lda = LDA(n_components=42, solver='svd')\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25,random_state=42)\n    X_train = lda.fit_transform(X_train, y_train)\n    X_test = lda.fit_transform(X_test, y_test)\n    params = {'iterations':trial.suggest_int(\"iterations\", 1000, 20000),\n              'od_wait':trial.suggest_int('od_wait', 500, 2000),\n             'loss_function':'RMSE',\n              'task_type':\"GPU\",\n              'eval_metric':'RMSE',\n              'leaf_estimation_method':'Newton',\n              'bootstrap_type': 'Bernoulli',\n              'learning_rate' : trial.suggest_uniform('learning_rate',0.02,1),\n              'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n              'subsample': trial.suggest_uniform('subsample',0,1),\n              'random_strength': trial.suggest_uniform('random_strength',10,50),\n              'depth': trial.suggest_int('depth',1,15),\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n               }\n    model = CatBoostRegressor(**params)  \n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n        \n    y_preds = model.predict(X_test)\n    loss = np.sqrt(mean_squared_error(y_test, y_preds))\n    \n    return loss\n","49e8ca81":"OPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","8bdc2776":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","2e94ae42":"cat_params = study.best_trial.params\ncat_params['loss_function'] = 'RMSE'\ncat_params['eval_metric'] = 'RMSE'\ncat_params['bootstrap_type']= 'Bernoulli'\ncat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = 42\ncat_params['task_type']='GPU'\ntest_preds=None\n\nprint(\"\\033[93mTraining........\")\n\nkf = StratifiedKFold(n_splits = 15 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(x.values , y.values)):\n    \n    print(\"\u2059\" * 15)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = x.values[tr_index] , x.values[val_index]\n    y_train,y_val = y.values[tr_index] , y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =CatBoostRegressor(**cat_params)\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = False)\n    \n    train_preds = model.predict(x_train)    \n    val_preds = model.predict(x_val)\n    \n    print(np.sqrt(mean_squared_error(y_val, val_preds)))\n    \n    if test_preds is None:\n        test_preds = model.predict(test.values)\n    else:\n        test_preds += model.predict(test.values)\n\nprint(\"-\" * 50)\nprint(\"\\033[95mTraining Done\")\n\ntest_preds \/= 15","9b59d4fe":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\n\nsubmission['loss']=test_preds\n\nsubmission.to_csv(\"lda.csv\",index=False)","f714af86":"# Model Tuning and Training","990cdf07":"# use optima","a897e1c5":"**Optima visualization**","2a9ed08c":"# Submission","126c44fa":"# Training","42e2fe51":"# Feature distribution"}}