{"cell_type":{"df382139":"code","14298f45":"code","bf5c10e9":"code","aa069e58":"code","e703d1e9":"code","8f1d28bb":"code","41df1285":"code","0d0cbac9":"code","6d7ba04c":"code","087d7954":"code","fa3e193e":"code","2b39a564":"code","222f8bad":"code","037c5059":"code","31acf468":"code","bd3b85b9":"code","130401db":"code","2c3ade53":"code","a0be437f":"code","ca7777b6":"code","1ec6dc0b":"code","6594415d":"code","939fe36b":"code","8c608540":"code","12a5eb76":"code","0f079bf7":"code","238915b5":"code","b5b12712":"code","a5958d6e":"code","48dfd16a":"code","8439d84a":"code","9a1b9b79":"code","87584d33":"code","171a3eed":"code","b78d982f":"code","c386a47c":"code","90589401":"code","b1e46bb9":"code","c1c6cd69":"code","fb72a99b":"code","83984102":"code","31aa8273":"markdown","eb98b601":"markdown","1a58cca0":"markdown","60b65b3e":"markdown","bac6026c":"markdown","35c0a40e":"markdown","96fece4c":"markdown","53534797":"markdown"},"source":{"df382139":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","14298f45":"# importing libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n\nimport calendar\n\nfrom datetime import datetime\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nimport seaborn as sns\n\n%matplotlib inline","bf5c10e9":"df_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_sampleSubmission = pd.read_csv('..\/input\/sampleSubmission.csv')","aa069e58":"print('Training data shape',df_train.shape)\nprint('Test data shape',df_test.shape)\n","e703d1e9":"print('Training data set header')\ndf_train.head()","8f1d28bb":"print('Training data set data types')\ndf_train.dtypes","41df1285":"# to apply a function on each value in a series, use apply and lambda as below. [0] in the end is index of \n# first element in split.\ndf_train['date']=df_train['datetime'].apply(lambda x: x.split()[0])\n\n","0d0cbac9":"df_train['Hour']=df_train['datetime'].apply(lambda x:x.split()[1].split(':')[0])","6d7ba04c":"df_train['weekday']=df_train['date'].apply(lambda x: calendar.day_name[datetime.strptime(x,'%Y-%m-%d').weekday()])\n","087d7954":"# In datetime library, strptime is to create a datetime object a date into year, month, date, hour and minute. \n# Weekday returns the weekday of that date. with 0 as Monday\ndatetime.strptime(df_train['datetime'][2],'%Y-%m-%d %H:%M:%S').weekday()","fa3e193e":"df_train['Month'] = df_train['date'].apply(lambda x: calendar.month_name[datetime.strptime(x,'%Y-%m-%d').month])\n","2b39a564":"df_train['season'] = df_train['season'].map({1:'Spring',2:'Summer',3:'Fall',4:'Winter'})\ndf_train['weather'] = df_train['weather'].map({1:'Clear + Few clouds + Partly cloudy + Partly cloudy',\n                                               2:'Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist',\n                                               3:'Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                               4:'Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog'})","222f8bad":"categorical_columns=['season','weather','Hour','weekday','Month','holiday','workingday']\n\nfor col in categorical_columns:\n    df_train[col] = df_train[col].astype('category') \n\ndf_train.dtypes","037c5059":"df_train = df_train.drop(['datetime'],axis=1)","31acf468":"print('Step 1: Find missing values')\nprint('Is there any missing value?',df_train.isnull().values.any())\n","bd3b85b9":"print('----Step2: Outlier analysis----')\n\nprint('Using box plot we can find the outliers')\n\n#returns a figure with 4 subplots (2 on each row)\nfig,ax= plt.subplots(nrows=2,ncols=2)\n#set figure size\nfig.set_size_inches(12,10)\nsns.boxplot(data=df_train,y='count',orient='v',ax=ax[0][0])\nsns.boxplot(data=df_train,y='count', x='season', orient='v',ax=ax[0][1])\nsns.boxplot(data=df_train,y='count', x='Hour',orient='v',ax=ax[1][0])\nsns.boxplot(data=df_train,y='count', x='workingday',orient='v',ax=ax[1][1])\n\nax[0][0].set(ylabel='Count', title = 'Plot on Count')\nax[0][1].set(ylabel='Count', xlabel = 'Season', title = 'Plot on Season vs Count')\nax[1][0].set(ylabel='Count', xlabel = 'Hour of day', title = 'Plot on Hour of day vs Count')\nax[1][1].set(ylabel='Count', xlabel = 'Working day', title = 'Plot on Working day(or not) vs Count')","130401db":"df_train_corr = df_train.corr()\ndf_train_corr","2c3ade53":"mask = np.array(df_train_corr)\n#this will make half of the array as 0\nmask[np.tril_indices_from(mask)]=False\nfig,ax = plt.subplots()\nfig.set_size_inches(12,10)\n#cmap colors - Yellow, Green, blue\n#mask is an array. where value is missing in mask array, nothing will be drawn.\n#square is True. each box is a square\n# annot is true. each box has a value.\nsns.heatmap(df_train_corr,mask=mask,vmax=0.8, square=True,annot=True, cmap='YlGnBu' ,ax=ax)","a0be437f":"fig,ax = plt.subplots(ncols=3)\nfig.set_size_inches(20,8)\nsns.regplot(data = df_train,x='temp',y='count',ax=ax[0])\nsns.regplot(data = df_train,x='humidity', y='count',ax=ax[1])\nsns.regplot(data = df_train,x='windspeed',y='count',ax=ax[2])","ca7777b6":"from sklearn.ensemble import RandomForestRegressor","1ec6dc0b":"df_train.dtypes\n","6594415d":"columns_for_model = ['season','holiday','workingday','weather','temp','humidity','Hour','weekday','Month']","939fe36b":"fig,ax = plt.subplots()\nfig.set_size_inches(12,8)\ndf_groupingSeasonHour = pd.DataFrame(df_train.groupby(by=['Hour','season'],sort=True)['count'].mean()).reset_index()\nsns.pointplot(data=df_groupingSeasonHour,x=df_groupingSeasonHour['Hour'],y=df_groupingSeasonHour['count'], \n              hue=df_groupingSeasonHour['season'],join=True,ax=ax)\n","8c608540":"fig,ax = plt.subplots()\nfig.set_size_inches(12,8)\ndf_groupingSeasonHour = pd.DataFrame(df_train.groupby(by=['Hour','holiday'],sort=True)['count'].mean()).reset_index()\nsns.pointplot(data=df_groupingSeasonHour,x=df_groupingSeasonHour['Hour'],y=df_groupingSeasonHour['count'], \n              hue=df_groupingSeasonHour['holiday'],join=True,ax=ax)\n","12a5eb76":"fig,ax = plt.subplots()\nfig.set_size_inches(12,8)\ndf_groupingSeasonHour = pd.DataFrame(df_train.groupby(by=['Hour','workingday'],sort=True)['count'].mean()).reset_index()\nsns.pointplot(data=df_groupingSeasonHour,x=df_groupingSeasonHour['Hour'],y=df_groupingSeasonHour['count'], \n              hue=df_groupingSeasonHour['workingday'] ,join=True,ax=ax)\n","0f079bf7":"df_train.iloc[np.where(df_train['weekday']=='Monday')]","238915b5":"df_train.head()","b5b12712":"#Training set\ntraining_data = pd.read_csv('..\/input\/train.csv')\n\ntraining_data['date']= training_data['datetime'].apply(lambda x: x.split()[0])\ntraining_data['Hour']=training_data['datetime'].apply(lambda x:x.split()[1].split(':')[0])\ntraining_data['weekday']=training_data['date'].apply(lambda x: calendar.day_name[datetime.strptime(x,'%Y-%m-%d').weekday()])\ntraining_data['Month'] = training_data['date'].apply(lambda x: calendar.month_name[datetime.strptime(x,'%Y-%m-%d').month])\n\ntraining_data.head()","a5958d6e":"#dropping columns that are not required\ntraining_data.drop(columns=['datetime', 'atemp','windspeed','casual','registered','date'],inplace=True)\ntraining_data.head()","48dfd16a":"training_data.dtypes","8439d84a":"training_data.weekday=training_data.weekday.astype('category')\ntraining_data.Month = training_data.Month.astype('category')\ntraining_data.season = training_data.season.astype('category')\ntraining_data.holiday = training_data.holiday.astype('category')\ntraining_data.workingday = training_data.workingday.astype('category')\ntraining_data.weather = training_data.weather.astype('category')","9a1b9b79":"weekday_dummies = pd.get_dummies(training_data['weekday'])\nmonth_dummies = pd.get_dummies(training_data.Month)\nseason_dummies = pd.get_dummies(training_data.season)\nseason_dummies.columns = ['Spring','Summer','Fall','Winter']\nweather_dummies = pd.get_dummies(training_data.weather)\nweather_dummies.columns = ['Clear','Mist','Snow','Rain']\n\ntraining_data = pd.concat([training_data,weekday_dummies,month_dummies,season_dummies,weather_dummies],axis=1)","87584d33":"training_data.drop(columns=['season','weather','weekday','Month'],inplace=True)\n\n","171a3eed":"training_data.columns\n","b78d982f":"randomForest = RandomForestRegressor(n_estimators=100)\n\nx_trainingSet = training_data[['holiday', 'workingday', 'temp', 'humidity', 'Hour', 'Friday',\n       'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n       'March', 'May', 'November', 'October', 'September', 'Spring', 'Summer',\n       'Fall', 'Winter', 'Clear', 'Mist', 'Snow', 'Rain']]\ny_trainingSet = training_data['count']\n\nrandomForest.fit(x_trainingSet,y_trainingSet)\n\ny_hat_training = randomForest.predict(X=x_trainingSet)\n\nfrom sklearn.metrics import mean_squared_error\nprint('Root Mean square error: ',np.sqrt(mean_squared_error(y_trainingSet,y_hat_training)))","c386a47c":"#Testing set\ntesting_data = pd.read_csv('..\/input\/test.csv')\n\ntesting_data['date']= testing_data['datetime'].apply(lambda x: x.split()[0])\ntesting_data['Hour']=testing_data['datetime'].apply(lambda x:x.split()[1].split(':')[0])\ntesting_data['weekday']=testing_data['date'].apply(lambda x: calendar.day_name[datetime.strptime(x,'%Y-%m-%d').weekday()])\ntesting_data['Month'] = testing_data['date'].apply(lambda x: calendar.month_name[datetime.strptime(x,'%Y-%m-%d').month])\n\ntesting_data.drop(columns=['datetime', 'atemp','windspeed','date'],inplace=True)\n\ntesting_data.weekday=testing_data.weekday.astype('category')\ntesting_data.Month = testing_data.Month.astype('category')\ntesting_data.season = testing_data.season.astype('category')\ntesting_data.holiday = testing_data.holiday.astype('category')\ntesting_data.workingday = testing_data.workingday.astype('category')\ntesting_data.weather = testing_data.weather.astype('category')\n\nweekday_dummies = pd.get_dummies(testing_data['weekday'])\nmonth_dummies = pd.get_dummies(testing_data.Month)\nseason_dummies = pd.get_dummies(testing_data.season)\nseason_dummies.columns = ['Spring','Summer','Fall','Winter']\nweather_dummies = pd.get_dummies(testing_data.weather)\nweather_dummies.columns = ['Clear','Mist','Snow','Rain']\n\ntesting_data = pd.concat([testing_data,weekday_dummies,month_dummies,season_dummies,weather_dummies],axis=1)\n\ntesting_data.drop(columns=['season','weather','weekday','Month'],inplace=True)\n\nx_testSet = testing_data[['holiday', 'workingday', 'temp', 'humidity', 'Hour', 'Friday',\n       'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n       'April', 'August', 'December', 'February', 'January', 'July', 'June',\n       'March', 'May', 'November', 'October', 'September', 'Spring', 'Summer',\n       'Fall', 'Winter', 'Clear', 'Mist', 'Snow', 'Rain']]\n\ny_hat_testing = randomForest.predict(X=x_testSet)\n","90589401":"y_hat_testing.shape","b1e46bb9":"testing_data.head()","c1c6cd69":"testing_col = pd.read_csv('..\/input\/test.csv')\ntesting_col.head()","fb72a99b":"\nfinal_dataframe = pd.DataFrame({\"datetime\": testing_col.datetime,\"count\":[int(x) for  x in y_hat_testing]})","83984102":"final_dataframe.to_csv('bike_prediction.csv',index=False)","31aa8273":"Lets learn about the training data set.","eb98b601":"Problem statement: Predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.","1a58cca0":"Demand during working day is low in early hours, but increases with time until 800 hours. again it slips down during the day. during evening it attains its peak at around 1700 hours (570 average total demand) and 1800 hours(500 average total demand). during non-working days, the demand descreases in morning till 0500 hours and then it takes a bell curve during the day time with its peak from 1200 to 1600 hours (max avg. 400).","60b65b3e":"We have seen correlation between count and temp and humidity.\nLet us see the relation between categorical variables against count.\n- Season\n- Holiday\n- Workingday\n- weather\n- Hour\n- Weekday\n- Month","bac6026c":"The correlation between count and temp is +ve. temp and atemp are same, so removing atemp won't harm us.\nHumidity and count has negative correlation. Indicating, whenever humidity is high, number of people renting bike is low.\nCorrelation of count with windspeed is near to 0, hence it has very less impact on people renting bike.\ncasual and registered count are part of count hence not useful for us to create model.","35c0a40e":"Based on the results in graph above, it is quite obvious that the count is dependent upon\n1. Season\n2. holiday\n3. working day\n4. weather\n5. temperature\n6. humidity\n7. weekday\n8. month\n\nSo we will read the data again and use the columns mentioned above to create data model also adding the dummies in the process for categorical variables.","96fece4c":"During holiday, demand is higher that normal seasons, but in non-holiday time, there is a peak in the demand as compared to holiday season at around 0800 hours. but after that demand goes down as compared to holidays. Later in the day at around 1700 hours and 1800 hours again the demand for bike is at highest peak in a non-holiday. Maximum average demand during a holiday goes to around 380 and during non-holidays it goes to around 480 at same time (1700 hours).","53534797":"The above graph depicts that during Fall, Summer and Winter, demand for bike is almost same until evening. Overall demand for bike is highest during Fall season and lowest during spring season."}}