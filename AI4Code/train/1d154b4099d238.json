{"cell_type":{"eef0eafa":"code","a876b786":"code","b98867a0":"code","0151472e":"code","3cf52e4d":"code","12063fa7":"code","ae085c4a":"code","dc854094":"code","ac5db9f7":"code","73476f4f":"code","bbf1f401":"code","01022b85":"code","1a764c0e":"code","cd2330e0":"code","3fa9aa78":"code","c34f29f5":"code","f65dd976":"code","48bf0352":"code","2c0f6188":"code","00502335":"code","654e5cf5":"code","354e1187":"code","aaae315e":"code","175ba95e":"code","c22b6c9f":"code","ba4b2193":"code","c87e7f61":"code","ae3dd3b2":"code","f22a6402":"code","fdf7b5e8":"code","afeff61b":"code","bcfea7b4":"code","71112b7f":"code","554b088f":"code","7e84f385":"code","4c239fe1":"code","0475b056":"code","a789e3da":"code","55013ba3":"code","43e6c669":"markdown","d2f57612":"markdown","f24c0364":"markdown","f0661246":"markdown","46926967":"markdown","b94b9151":"markdown","be48d8a0":"markdown","e7fa45fa":"markdown","ae2c4934":"markdown","0c699095":"markdown","67c78064":"markdown","173dfc45":"markdown","9d753190":"markdown","604143b6":"markdown","6c24a612":"markdown","581e51a7":"markdown","7048bbc7":"markdown","ce654adb":"markdown","51f3afc8":"markdown","3e4b0f71":"markdown","cdc91b22":"markdown","ba33388d":"markdown"},"source":{"eef0eafa":"# linear algebra\nimport numpy as np \n\n# data processing\nimport pandas as pd \n\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport torch","a876b786":"test_df = pd.read_csv(\"..\/input\/test.csv\")\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_output_df = pd.read_csv(\"..\/input\/gender_submission.csv\")","b98867a0":"print(\"Dimensions of train: {}\".format(train_df.shape))\nprint(\"Dimensions of test: {}\".format(test_df.shape))","0151472e":"train_df.info()","3cf52e4d":"train_df.describe()","12063fa7":"#preview of the data\ntrain_df.head(10)","ae085c4a":"# check for duplicates in the data\nsum(train_df.duplicated())","dc854094":"def find_missing_data():\n    print('Training Data\\n')\n    train_total = train_df.isnull().sum().sort_values(ascending=False)\n    train_percent_1 = train_df.isnull().sum()\/train_df.isnull().count()*100\n    train_percent_2 = (round(train_percent_1, 1)).sort_values(ascending=False)\n    train_missing_data = pd.concat([train_total, train_percent_2], axis=1, keys=['Total', '%'])\n    print(train_missing_data.head(12))\n    \n    \n    print('\\n\\nTest Data\\n')\n    test_total = test_df.isnull().sum().sort_values(ascending=False)\n    test_percent_1 = test_df.isnull().sum()\/test_df.isnull().count()*100\n    test_percent_2 = (round(test_percent_1, 1)).sort_values(ascending=False)\n    test_missing_data = pd.concat([test_total, test_percent_2], axis=1, keys=['Total', '%'])\n    print(test_missing_data.head(12))\n    \n\nfind_missing_data()","ac5db9f7":"train_df.columns.values","73476f4f":"sns.countplot('Survived',data=train_df)\nplt.show()","bbf1f401":"# Exploring the number of survivors by gender\ntrain_df.groupby(['Sex', 'Survived'])['Survived'].count()","01022b85":"train_df[['Sex','Survived']].groupby(['Sex']).mean().plot.bar()\nsns.countplot('Sex',hue='Survived',data=train_df,)\nplt.show()","1a764c0e":"#Exploring the Pclass column\nclass_pivot = train_df.pivot_table(index=\"Pclass\",values=\"Survived\")\nclass_pivot.plot.bar()\nplt.show()","cd2330e0":"# Exploring age column\ntrain_df[\"Age\"].describe()","3fa9aa78":"print('Oldest survivor:',train_df['Age'].max())\nprint('Youngest survivor:',train_df['Age'].min())\nprint('Average survivor Age:',train_df['Age'].mean())","c34f29f5":"#plotting a histogram of Age\n\n#giving the figure size(width, height)\nplt.figure(figsize=(9,5), dpi = 100)\n\n#On x-axis \nplt.xlabel('Age', fontsize = 15)\n#On y-axis \nplt.ylabel('No.of survivors', fontsize=15)\n#Name of the graph\nplt.title('Age of the Survivors', fontsize=18)\n\n#giving a histogram plot\nplt.hist(train_df['Age'], rwidth = 0.9, bins =35)\n#displays the plot\nplt.show()","f65dd976":"survived = train_df[train_df[\"Survived\"] == 1]\ndied = train_df[train_df[\"Survived\"] == 0]\nsurvived[\"Age\"].plot.hist(alpha=0.5,color='red',bins=50)\ndied[\"Age\"].plot.hist(alpha=0.5,color='blue',bins=50)\nplt.legend(['Survived','Died'])\nplt.show()","48bf0352":"survived = 'survived'\nnot_survived = 'not survived'\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\nwomen = train_df[train_df['Sex']=='female']\nmen = train_df[train_df['Sex']=='male']\nax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\nax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\nax.legend()\nax.set_title('Female')\nax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\nax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\nax.legend()\n_ = ax.set_title('Male')","2c0f6188":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","00502335":"def merge_relatives():\n    data = [train_df, test_df]\n    for dataset in data:\n        dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    # help(train_df.loc)\n    print(train_df.head())\n    \nmerge_relatives()","654e5cf5":"train_df.head()","354e1187":"# help(sns.factorplot) - it is deprecated\n# help(sns.catplot)\naxes = sns.factorplot('relatives','Survived', \n                      data=train_df, aspect = 2.5, )","aaae315e":"def drop_useless_columns():\n    train_df.drop(['SibSp', 'Parch', 'Ticket','Name','Cabin'], axis=1, inplace=True)\n    test_df.drop(['SibSp', 'Parch', 'Ticket','Name','Cabin'], axis=1, inplace=True)\n    \ndrop_useless_columns()","175ba95e":"train_df.head()","c22b6c9f":"def set_index():\n    train_df.set_index('PassengerId',inplace=True)\n    test_df.set_index('PassengerId',inplace=True)\n\nset_index()","ba4b2193":"def encode_sex_column():\n    train_df['Sex'] = train_df['Sex'].map(dict(zip(['male','female'],[0,1])))\n    test_df['Sex'] = test_df['Sex'].map(dict(zip(['male','female'],[0,1])))\n\nencode_sex_column()","c87e7f61":"def fill_age_na():\n    # Reblace NAN with age averages\n    age_mean= train_df[\"Age\"].mean()\n    train_df[\"Age\"] = train_df[\"Age\"].fillna(age_mean)\n    \nfill_age_na()","ae3dd3b2":"train_df.dropna(inplace=True)\ntrain_df.info()","f22a6402":"def encode_embarked_column():\n    train_df['Embarked'] = train_df['Embarked'].map(dict(zip(['S','C','Q'],[0,1,2])))\n    test_df['Embarked'] = test_df['Embarked'].map(dict(zip(['S','C','Q'],[0,1,2])))\n\nencode_embarked_column()","fdf7b5e8":"test_output_df.head()","afeff61b":"# Save the final CLEAN dataset as our new file!\n# train_df.to_csv('clean_train.csv', index=False)","bcfea7b4":"from torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# number of subprocesses to use for data loading\nnum_workers = 0\n\n# percentage of training set to use as validation\nvalid_size = 0.2\n\n# obtain training indices that will be used for validation\nnum_train = len(train_df)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntargets_df = pd.DataFrame(data=train_df['Survived'])\ntargets_df.columns = ['Survived']\n\ndel train_df['Survived']\n\ntrain = torch.utils.data.TensorDataset(torch.Tensor(np.array(train_df)), torch.tensor(targets_df['Survived'].values))\n\ntrain_loader = torch.utils.data.DataLoader(train,sampler=train_sampler, num_workers=num_workers)\n\nvalid_loader = torch.utils.data.DataLoader(train,sampler=valid_sampler, num_workers=num_workers)\n\ntest_targets_df = pd.DataFrame(data=test_output_df['Survived'])\ntest_targets_df.columns = ['Survived']\n\ntest = torch.utils.data.TensorDataset(torch.Tensor(np.array(test_df)), torch.tensor(test_targets_df['Survived'].values))\n\ntest_loader = torch.utils.data.DataLoader(test,num_workers=num_workers)","71112b7f":"train_loader","554b088f":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# define the NN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # number of hidden nodes in each layer (512)\n        hidden_1 = 4\n        # linear layer (784 -> hidden_1)\n        self.fc1 = nn.Linear(6, hidden_1)\n        # linear layer (n_hidden -> 10)\n        self.fc2 = nn.Linear(hidden_1, 2)\n        # dropout layer (p=0.2)\n        # dropout prevents overfitting of data\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        x = x.view(-1, 6)\n        # add hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        # add dropout layer\n        x = self.dropout(x)\n        # add output layer\n        x = torch.sigmoid(self.fc2(x))\n        return x\n         \n\n# initialize the NN\nmodel = Net()\nprint(model)","7e84f385":"# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","4c239fe1":"# number of epochs to train the model\nn_epochs = 50\n\n# initialize tracker for minimum validation loss\nvalid_loss_min = np.Inf # set initial \"min\" to infinity\n\nfor epoch in range(n_epochs):\n    # monitor training loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train() # prep model for training\n    for data, target in train_loader:\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        \n       \n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval() # prep model for evaluation\n    for data, target in valid_loader:\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update running validation loss \n        valid_loss += loss.item()*data.size(0)\n        \n    # print training\/validation statistics \n    # calculate average loss over an epoch\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n    \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch+1, \n        train_loss,\n        valid_loss\n        ))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model.pt')\n        valid_loss_min = valid_loss","0475b056":"model.load_state_dict(torch.load('model.pt'))","a789e3da":"test_df.head()","55013ba3":"test_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nmodel.eval() # prep model for evaluation\n\nfor data, target in test_loader:\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the loss\n    #print('Data %s' % data)\n    #print('Output %s' % output)\n    loss = criterion(output, target)\n    #print('Target %s' % target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)\n    #print('Predicted %s' % pred)\n    # compare predictions to true label\n    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n    #print('Correct %s' % correct)\n    # calculate test accuracy for each object class\n    #break\n    for i in range(len(target)):\n        label = target.data\n        class_correct[label] += correct.item()\n        class_total[label] += 1\n\n# calculate and print avg test loss\ntest_loss = test_loss\/len(test_loader.sampler)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d\/%2d)' % (\n            str(i), 100 * class_correct[i] \/ class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100. * np.sum(class_correct) \/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","43e6c669":"## Combining Sibling\/Spouse and Parent\/Children feature into one so that it denotes if a person had any relative or not","d2f57612":"# Getting the Data\n","f24c0364":"The training-set has 891 examples and 12 features. 2 of the features are floats, 5 are integers and 5 are objects. \n\n**Survival** is the column of the target values we are trying to predict","f0661246":"# Data Dictionary","46926967":"# Age column has a lot of missing values, so we fill these rows with the mean of Age","b94b9151":"# Also embarked column has to be encoded as 0,1,2 since it is currently in character values","be48d8a0":"# Now we drop any missing data(2 rows missing in Embarked column)","e7fa45fa":"# We should encode Male\/Female values to 0\/1 since Neural Networks can only take numerical values","ae2c4934":"From the above graph it is clear that there are not many survivors. Out of 891 passenger in training dataset only 350, 38.4% of total training dataset survived.\n\n","0c699095":"# We have to drop the columns **Cabin** as it as a lot of missing data, and we have to drop **Name**, and **Ticket**. **SibSp** and **Parch** has to be merged as a single column and replaced as **Relatives**. ","67c78064":"# Data Exploration","173dfc45":"* PassengerID\u2014 A column added by Kaggle to identify each row and make submissions easier\n* Survived\u2014 Whether the passenger survived or not and the value we are predicting (0=No, 1=Yes)\n* Pclass\u2014 The class of the ticket the passenger purchased (1=1st, 2=2nd, 3=3rd)\n* Sex\u2014 The passenger\u2019s sex\n* Age\u2014 The passenger\u2019s age in years\n* SibSp\u2014 The number of siblings or spouses the passenger had aboard the Titanic\n* Parch\u2014 The number of parents or children the passenger had aboard the Titanic\n* Ticket\u2014 The passenger\u2019s ticket number\n* Fare\u2014 The fare the passenger paid\n* Cabin\u2014 The passenger\u2019s cabin number\n* Embarked\u2014 The port where the passenger embarked (C=Cherbourg, Q=Queenstown, S=Southampton)","9d753190":"## Checking how Embarked class affected male and females separately","604143b6":"# We can set Passenger Id column as index since it denotes unique rows","6c24a612":"We can see from exploring the data and from the graph that, 233 female survived out of 344. And out of 577 male 109 survived. The survival ratio of female is much greater than that of male.","581e51a7":"# Predicting the Survival of Titanic Passengers","7048bbc7":"# Exploring and converting the age column\n","ce654adb":"# Importing the Libraries","51f3afc8":"According to the mean of Survived feature, **38% out of the training-set survived the Titanic**.\n\nFrom the min and maax of the feature Age , We can see **passenger ages range from 0.4 to 80**.\n\nOn top of that we can already detect some features, that contain **missing values**, like the \u2018Age\u2019 feature as shown by its count.\n","3e4b0f71":"# Age and Sex","cdc91b22":"# Finding Missing Data","ba33388d":"### Dropping Name, Cabin, SibSp, Parch & Ticket columns"}}