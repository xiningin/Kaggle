{"cell_type":{"b41d94d4":"code","cb2458b0":"code","d9c3c487":"code","4120a85e":"code","0103619f":"code","3afa453e":"code","fda53e87":"code","b56fbab0":"code","c8345a6e":"code","d09506bb":"code","b42c3824":"code","c15979e3":"code","086cd574":"code","569cd70e":"code","ffbdb925":"code","41452ee9":"code","deb3400f":"code","beb859b6":"code","06f1f29f":"code","8f995478":"code","aabf4cd2":"code","1bb26191":"code","07d1e68a":"code","fd0513d6":"code","b83780fc":"code","acf6d2ba":"code","4cca00c4":"code","8b4f3e60":"code","c20354a2":"code","ce51645e":"code","880a8ce6":"code","e3008ea5":"code","0be960b5":"code","4818bd46":"code","f3f5ea31":"code","7f86b237":"code","80bf3096":"code","2f082f70":"code","1bff57de":"code","319516aa":"code","0963b853":"code","e69c1c81":"code","5feb1995":"code","3bf3f75c":"code","7f2ea355":"code","9ef82c2e":"code","f80ce296":"code","1cc8baca":"code","b4210090":"code","de7c6eeb":"code","2251ce34":"code","97efb733":"code","944a86a1":"code","4ec343c6":"code","6afe4b2f":"code","c2e5e557":"code","4b4dbe08":"code","a1347120":"code","2bd64483":"code","fed7a1eb":"code","147ed6e4":"code","a0df32b3":"code","f6a7a3b0":"code","2abe688c":"code","688590fe":"code","1c771a8f":"code","6f95e325":"code","0b59e72f":"code","ff520ed4":"code","ec68f71b":"code","f7798cd1":"code","23e35716":"code","4a507d50":"code","23b87602":"code","c82855c2":"code","534d7e82":"code","bddde335":"code","7a2cd4a6":"code","e0a2926b":"code","de240fce":"code","3f5729e1":"code","99548741":"code","d77e0cb7":"code","3f810b87":"code","1f1ec3d3":"code","28c741e6":"markdown","41296616":"markdown","e3ad2367":"markdown","82c2881e":"markdown","be5a3bba":"markdown","0204ca6b":"markdown","ade9e798":"markdown","e7341c47":"markdown","0e3c9138":"markdown","34eb63d3":"markdown","8380aede":"markdown","a5b2368c":"markdown","f759f4d6":"markdown","90a3e946":"markdown","58530cd1":"markdown","5d49f608":"markdown","1ada9a43":"markdown","e80d2650":"markdown","2b68c46c":"markdown","b3f975e7":"markdown","c63ba330":"markdown","bab7ff16":"markdown","a7d51bef":"markdown","db0c39c8":"markdown","8c2f78b1":"markdown","c0dd6265":"markdown","74429c41":"markdown","a4e7e346":"markdown","ec8253d2":"markdown","08bd4d99":"markdown"},"source":{"b41d94d4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb2458b0":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","d9c3c487":"main_df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf = main_df.copy()","4120a85e":"# Getting top 5 rows\ndf.head()","0103619f":"# Dimension of dataframe\ndf.shape","3afa453e":"# List of all columns present in dataframe\ndf.columns","fda53e87":"# To view some basic statistical details \ndf.describe()","b56fbab0":"# getting the information about dataframe\ndf.info()","c8345a6e":"#  check for null value \ndf.isnull().sum()","d09506bb":"# checking number of unique values in each column\ndf.nunique()","b42c3824":"# Checking null value using heatmap\nsns.heatmap(df.isnull())","c15979e3":"# correlation heatmap\nplt.figure(figsize=(10,8))\nsns.heatmap(df.corr(), annot = True, cmap='coolwarm')","086cd574":"ax = sns.countplot(x = \"sex\",data= df, saturation=0.8)\nplt.xticks(ticks=[0, 1], labels = [\"female\", \"male\"])\nplt.show()","569cd70e":"# Visualizing dataset and also checking for outliers \n\nfig, ax = plt.subplots(ncols = 7, nrows = 2, figsize = (20, 10))\nindex = 0\nax = ax.flatten()\n\nfor col, value in df.items():\n    sns.boxplot(y=col, data=df, ax=ax[index])\n    index += 1\nplt.tight_layout(pad = 0.5, w_pad=0.7, h_pad=5.0)","ffbdb925":"# Individual box plot for each feature\ndef Box(df):\n    plt.title(\"Box Plot\")\n    sns.boxplot(df)\n    plt.show()\nBox(df['age'])","41452ee9":"sns.histplot(x = \"age\", data=df)","deb3400f":"# Min-Max normalization\n# Here we are taking only 4 column for normalization because in this the value are too high as compare to others\n\ncols = ['trtbps', 'chol', 'thalachh', 'oldpeak', 'age']\nfor col in cols:\n    minimum = min(df[col])\n    maximum = max(df[col])\n    df[col] = (df[col] - minimum)\/ (maximum - minimum)","beb859b6":"df.head()","06f1f29f":"print(df[[\"sex\", \"output\"]].groupby(['sex']).mean())","8f995478":"print(df[[\"cp\", \"output\"]].groupby(['cp']).mean())","aabf4cd2":"print(df[[\"fbs\", \"output\"]].groupby(['fbs']).mean())\n","1bb26191":"print (df[[\"exng\", \"output\"]].groupby(['exng']).mean())","07d1e68a":"print (df[[\"exng\", \"output\"]].groupby(['exng']).mean())","fd0513d6":"# Visualizing after min-max normalization \nfig, ax = plt.subplots(ncols = 7, nrows = 2, figsize = (20, 10))\nindex = 0\nax = ax.flatten()\n\nfor col, value in df.items():\n    sns.boxplot(y=col, data=df, ax=ax[index])\n    index += 1\nplt.tight_layout(pad = 0.5, w_pad=0.7, h_pad=5.0)","b83780fc":"# Here we can see that after min-max normalization values now ranges from 0 to 1\ndf.head()","acf6d2ba":"# Exploring dataset through visualization\ndf1=df[df[\"output\"] == 1]\nsns.histplot(df1[\"thalachh\"],bins=25, color=\"lightgreen\");\nplt.xlabel(\"Heart rate when outcome is 1\")\nplt.show()","4cca00c4":"# Exploring dataset through visualization\ndf2=df[df[\"output\"]==0]\nsns.histplot(df2[\"thalachh\"],bins=25,  color=\"red\");\nplt.xlabel(\"Heart rate when outcome is 0\")\nplt.show()","8b4f3e60":"# dropping 'output' from dataframe and saving dataframe in X which is now acting as input column\nX = df.drop(\"output\", axis=1)\nX.shape","c20354a2":"df.nunique()","ce51645e":"fig =  px.pie (df, names = \"sex\", hole = 0.4, template = \"plotly_dark\")\nfig.show ()","880a8ce6":"fig =  px.pie (df, names = \"cp\", hole = 0.4, template = \"plotly_dark\")\nfig.show ()","e3008ea5":"fig =  px.pie (df, names = \"slp\", hole = 0.4, template = \"gridon\")\nfig.show ()","0be960b5":"fig =  px.pie (df, names = \"caa\", hole = 0.4, template = \"gridon\")\nfig.show ()","4818bd46":"fig = px.histogram (df, x = \"chol\",  facet_row = \"output\",  template = 'plotly_dark')\nfig.show ()","f3f5ea31":"fig = px.histogram (df, x = \"thalachh\",  facet_row = \"output\",  template = 'gridon')\nfig.show ()","7f86b237":"fig = px.scatter (df, x = \"thalachh\", y = \"oldpeak\", color = \"output\", template = \"plotly_dark\",  trendline=\"ols\")\nfig.show ()","80bf3096":"fig = px.scatter (df, x = \"trtbps\", y = \"chol\", color = \"output\", template = \"gridon\",  trendline=\"ols\")\nfig.show ()","2f082f70":"fig = px.scatter (df, x = \"thalachh\", y = \"chol\", color = \"output\", template = \"plotly_dark\",  trendline=\"lowess\")\nfig.show ()","1bff57de":"sns.pairplot(data=df, vars=['thalachh', 'chol', 'trtbps'], \\\n             hue='output', kind='reg', diag_kind='kde', markers=['*','.'], size=5, palette='husl')","319516aa":"X.head()","0963b853":"# y have only 'output' column \ny = df['output']\ny.shape","e69c1c81":"from sklearn.model_selection import  train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,random_state=42)","5feb1995":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score","3bf3f75c":"# Creating model object\nmodel_lg = LogisticRegression(max_iter=120,random_state=0, n_jobs=20)","7f2ea355":"# Training Model\nmodel_lg.fit(X_train, y_train)","9ef82c2e":"# Making Prediction\npred_lg = model_lg.predict(X_test)","f80ce296":"# Calculating Accuracy Score\nlg = accuracy_score(y_test, pred_lg)\nprint(lg)","1cc8baca":"# confusion Maxtrix\ncm1 = confusion_matrix(y_test, pred_lg)\nsns.heatmap(cm1\/np.sum(cm1), annot = True, fmt=  '0.2%', cmap = 'Reds')","b4210090":"from sklearn.tree import DecisionTreeClassifier","de7c6eeb":"# Creating model object\nmodel_dt = DecisionTreeClassifier( max_depth=4, random_state=42)","2251ce34":"# Training Model\nmodel_dt.fit(X_train,y_train)","97efb733":"# Making Prediction\npred_dt = model_dt.predict(X_test)","944a86a1":"# Calculating Accuracy Score\ndt = accuracy_score(y_test, pred_dt)\nprint(dt)","4ec343c6":"# confusion Maxtrix\ncm2 = confusion_matrix(y_test, pred_dt)\nsns.heatmap(cm2\/np.sum(cm2), annot = True, fmt=  '0.2%', cmap = 'Reds')","6afe4b2f":"from sklearn.ensemble import RandomForestClassifier","c2e5e557":"# Creating model object\nmodel_rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=0.16, random_state=42)","4b4dbe08":"# Training Model\nmodel_rf.fit(X_train, y_train)","a1347120":"# Making Prediction\npred_rf = model_rf.predict(X_test)","2bd64483":"# Calculating Accuracy Score\nrf = accuracy_score(y_test, pred_rf)\nprint(rf)","fed7a1eb":"# confusion Maxtrix\ncm3 = confusion_matrix(y_test, pred_rf)\nsns.heatmap(cm3\/np.sum(cm3), annot = True, fmt=  '0.2%', cmap = 'Reds')","147ed6e4":"from xgboost import XGBClassifier","a0df32b3":"# Creating model object\nmodel_xgb = XGBClassifier(max_depth= 8, n_estimators= 125, random_state= 0,  learning_rate= 0.03, n_jobs=5)","f6a7a3b0":"# Training Model\nmodel_xgb.fit(X_train, y_train)","2abe688c":"# Making Prediction\npred_xgb = model_xgb.predict(X_test)","688590fe":"# Calculating Accuracy Score\nxgb = accuracy_score(y_test, pred_xgb)\nprint(xgb)","1c771a8f":"# confusion Maxtrix\ncm4 = confusion_matrix(y_test, pred_xgb)\nsns.heatmap(cm4\/np.sum(cm4), annot = True, fmt=  '0.2%', cmap = 'Reds')","6f95e325":"from sklearn.neighbors import KNeighborsClassifier","0b59e72f":"# Creating model object\nmodel_kn = KNeighborsClassifier(n_neighbors=9, leaf_size=20)","ff520ed4":"# Training Model\nmodel_kn.fit(X_train, y_train)","ec68f71b":"# Making Prediction\npred_kn = model_kn.predict(X_test)\n","f7798cd1":"# Calculating Accuracy Score\nkn = accuracy_score(y_test, pred_kn)\nprint(kn)","23e35716":"# confusion Maxtrix\ncm5 = confusion_matrix(y_test, pred_kn)\nsns.heatmap(cm5\/np.sum(cm5), annot = True, fmt=  '0.2%', cmap = 'Reds')","4a507d50":"from sklearn.svm import SVC, LinearSVC","23b87602":"model_svm = SVC(kernel='rbf', random_state = 42)","c82855c2":"model_svm.fit(X_train, y_train)","534d7e82":"# Making Prediction\npred_svm = model_svm.predict(X_test)","bddde335":"# Calculating Accuracy Score\nsv = accuracy_score(y_test, pred_svm)\nprint(sv)","7a2cd4a6":"# confusion Maxtrix\ncm6 = confusion_matrix(y_test, pred_svm)\nsns.heatmap(cm6\/np.sum(cm6), annot = True, fmt=  '0.2%', cmap = 'Reds')","e0a2926b":"from sklearn.ensemble import AdaBoostClassifier","de240fce":"model_ada = AdaBoostClassifier(learning_rate= 0.002,n_estimators= 205,random_state=42)","3f5729e1":"model_ada.fit(X_train, y_train)","99548741":"# Making Prediction\npred_ada = model_ada.predict(X_test)","d77e0cb7":"# Calculating Accuracy Score\nada = accuracy_score(y_test, pred_ada)\nprint(ada)","3f810b87":"# confusion Maxtrix\ncm7 = confusion_matrix(y_test, pred_ada)\nsns.heatmap(cm7\/np.sum(cm7), annot = True, fmt=  '0.2%', cmap = 'Reds')","1f1ec3d3":"models = pd.DataFrame({\n    'Model':['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'KNeighbours', 'SVM', 'AdaBoost'],\n    'Accuracy_score' :[lg, dt, rf, xgb, kn, sv, ada]\n})\nmodels\nsns.barplot(x='Accuracy_score', y='Model', data=models)\n\nmodels.sort_values(by='Accuracy_score', ascending=False)","28c741e6":"### Logistic Regression","41296616":"## Visualization ","e3ad2367":"No dot\/marks are present in the graph (red region) it means we donot have any missing value.","82c2881e":"## Decision Tree Classifier","be5a3bba":"## AdaBoost Classifier","0204ca6b":"# <center> Heart-Attack Analysis & Prediction  <\/center>","ade9e798":"#### Performing train_test_split","e7341c47":"##### Importing libraries ","0e3c9138":"### KNeighbours","34eb63d3":"* Here,  Type-1 Error is 6.56% which is also known as False Positive.\n* Type-2 Error is 9.84% which is also known as False Negative.\n* while other % value in the confusion matrix represents that they are correctly  predicted in their specific categories.","8380aede":"Two features can be positively correlated or  negatively. But if they are highly correlated then we should drop one of them.","a5b2368c":"### About this dataset\n*  Age : Age of the patient\n\n* Sex : Sex of the patient\n\n* exang: exercise induced angina (1 = yes; 0 = no)\n\n* ca: number of major vessels (0-3)\n\n* cp : Chest Pain type chest pain type\n\n* Value 1: typical angina\n* Value 2: atypical angina\n* Value 3: non-anginal pain\n* Value 4: asymptomatic\n* trtbps : resting blood pressure (in mm Hg)\n\n* chol : cholestoral in mg\/dl fetched via BMI sensor\n\n* fbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\n* rest_ecg : resting electrocardiographic results\n\n* Value 0: normal\n* Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n* Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n* thalach : maximum heart rate achieved\n\n* target : 0= less chance of heart attack 1= more chance of heart attack","f759f4d6":"## Random Forest","90a3e946":"* Here,  Type-1 Error is 6.56% which is also known as False Positive.\n* Type-2 Error is 6.56% which is also known as False Negative.\n* while other % value in the confusion matrix represents that they are correctly  predicted in their specific categories.","58530cd1":"#### Following are the list of algorithm that are used in this notebook\n\n| **Algorithm**       |\n| : -----------  :    |\n| Logistic Regression | \n| Decision Tree       | \n| Random Forest       | \n| XGBoost             | \n| KNeighbours         |\n| SVM                 | \n| AdaBoost            | ","5d49f608":" <center> <img src=\"https:\/\/paloalto.bibliocommons.com\/events\/uploads\/images\/full\/7a9b7c271a9b80fc251ad6f2a6e5d903\/bcms%20heart%20health.png\" height=300 width= 500 alt=\"Heart Attack Analysis\"  > <\/center>\n","1ada9a43":"### XGBoost","e80d2650":"### Conclusion :- After few hyperparameter tuning Random Forest and  Kneighbour Achieved the highest accuracy here ","2b68c46c":"We have 303 rows and 14 columns in our dataset","b3f975e7":"In above cell we have listed out top 5 rows of the dataset.","c63ba330":"### Accuracy score dataframe","bab7ff16":"* Here,  Type-1 Error is 4.92% which is also known as False Positive.\n* Type-2 Error is 4.92% which is also known as False Negative.\n* while other % value in the confusion matrix represents that they are correctly  predicted in their specific categories.","a7d51bef":"In our dataset Mean age is 54, Minimum age is 29, maximum age is 77, 25% of the people in our dataset have age less than 47 and 75% of the people in our dataset have age less than 61.","db0c39c8":"* Here,  Type-1 Error is 4.92% which is also known as False Positive.\n* Type-2 Error is 9.84% which is also known as False Negative.\n* while other % value in the confusion matrix represents that they are correctly  predicted in their specific categories.","8c2f78b1":"By above table we can see that non of our value is object type, all of them are numerical type with no missing value.","c0dd6265":"#####  In this following cell we have read the dataset using pandas.\n##### It is considered as a good practice to make a copy of main data and work on the copy of dataset. ","74429c41":"##  SVM","a4e7e346":"Here we are grouping the data based on different categories and therefore we can also check other features for more information.","ec8253d2":"* Here,  Type-1 Error is 4.92% which is also known as False Positive.\n* Type-2 Error is 9.84% which is also known as False Negative.\n* while other % value in the confusion matrix represents that they are correctly  predicted in their specific categories.","08bd4d99":"* Here,  Type-1 Error is 6.56% which is also known as False Positive.\n* Type-2 Error is 3.28% which is also known as False Negative.\n* while other % value in the confusion matrix represents that they are correctly  predicted in their specific categories."}}