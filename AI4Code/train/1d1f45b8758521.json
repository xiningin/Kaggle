{"cell_type":{"abff89da":"code","bae63733":"code","5d325883":"code","afcc3177":"code","a60f71d3":"code","a76c111b":"code","d2a81cc6":"code","499ddc3d":"code","843eb893":"code","a06216c9":"code","e0605f40":"code","ad0296ec":"code","4620933f":"code","d668427a":"code","55ec6383":"code","032f21b4":"code","b9c67343":"markdown","39b7d453":"markdown","c29ffa06":"markdown","6aac4c64":"markdown","8b475a5f":"markdown","711bef72":"markdown","07ca9f7e":"markdown","1905fc82":"markdown","ce97e754":"markdown","35dd3f36":"markdown","b1854cb7":"markdown","b146c20d":"markdown","c86c5005":"markdown","9812d17f":"markdown","24b89f1f":"markdown","cf8f332b":"markdown","8ecb9b9c":"markdown","64293a5f":"markdown","f1fb8abc":"markdown","157fdedc":"markdown","8a1da59c":"markdown","71210b80":"markdown","8c07f612":"markdown","b6bc99ed":"markdown"},"source":{"abff89da":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","bae63733":"x = np.arange(-6.0, 6.0, 0.1)\n\n##You can adjust the slope and intercept to verify the changes in the graph\ny = 3*(x) + 2\ny_noise = 2 * np.random.normal(size=x.size)\nydata = y + y_noise\n#plt.figure(figsize=(8,6))\nplt.plot(x, ydata,  'bo')\nplt.plot(x,y, 'r') \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","5d325883":"x = np.arange(-6.0, 6.0, 0.1)\n\n##You can adjust the slope and intercept to verify the changes in the graph\ny = 1*(x**3) + 2*(x**2) + 1*x + 3\ny_noise = 20 * np.random.normal(size=x.size)\nydata = y + y_noise\nplt.plot(x, ydata,  'bo')\nplt.plot(x,y, 'r') \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","afcc3177":"x = np.arange(-6.0, 6.0, 0.1)\n\n##You can adjust the slope and intercept to verify the changes in the graph\n\ny = np.power(x,2)\ny_noise = 2 * np.random.normal(size=x.size)\nydata = y + y_noise\nplt.plot(x, ydata,  'bo')\nplt.plot(x,y, 'r') \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","a60f71d3":"X = np.arange(-6.0, 6.0, 0.1)\n\n##You can adjust the slope and intercept to verify the changes in the graph\n\nY= np.exp(X)\n\nplt.plot(X,Y) \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","a76c111b":"X = np.arange(1.0, 10.0, 0.1)\n\nY = np.log(X)\n\nplt.plot(X,Y) \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","d2a81cc6":"X = np.arange(-5.0, 5.0, 0.1)\n\n\nY = 1-4\/(1+np.power(3, X-2))\n\nplt.plot(X,Y) \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","499ddc3d":"import pandas as pd\npath='..\/input\/chinagdp\/china_gdp.csv'\ndf = pd.read_csv(path)\ndf.head(10)","843eb893":"plt.figure(figsize=(8,5))\nx_data, y_data = (df[\"Year\"].values, df[\"Value\"].values)\nplt.plot(x_data, y_data, 'ro')\nplt.ylabel('GDP')\nplt.xlabel('Year')\nplt.show()","a06216c9":"X = np.arange(-5,5.0, 0.1)\nY = 1.0 \/ (1.0 + np.exp(-X))\n\nplt.plot(X,Y) \nplt.ylabel('Dependent Variable')\nplt.xlabel('Indepdendent Variable')\nplt.show()","e0605f40":"def sigmoid(x, Beta_1, Beta_2):\n     y = 1 \/ (1 + np.exp(-Beta_1*(x-Beta_2)))\n     return y","ad0296ec":"beta_1 = 0.10\nbeta_2 = 1990.0\n\n#logistic function\nY_pred = sigmoid(x_data, beta_1 , beta_2)\n\n#plot initial prediction against datapoints\nplt.plot(x_data, Y_pred*15000000000000.)\nplt.plot(x_data, y_data, 'ro')","4620933f":"# Lets normalize our data\nxdata =x_data\/max(x_data)\nydata =y_data\/max(y_data)","d668427a":"from scipy.optimize import curve_fit\npopt, pcov = curve_fit(sigmoid, xdata, ydata)\n#print the final parameters\nprint(\" beta_1 = %f, beta_2 = %f\" % (popt[0], popt[1]))","55ec6383":"x = np.linspace(1960, 2015, 55)\nx = x\/max(x)\nplt.figure(figsize=(8,5))\ny = sigmoid(x, *popt)\nplt.plot(xdata, ydata, 'ro', label='data')\nplt.plot(x,y, linewidth=3.0, label='fit')\nplt.legend(loc='best')\nplt.ylabel('GDP')\nplt.xlabel('Year')\nplt.show()","032f21b4":"# split data into train\/test\nmsk = np.random.rand(len(df)) < 0.8\ntrain_x = xdata[msk]\ntest_x = xdata[~msk]\ntrain_y = ydata[msk]\ntest_y = ydata[~msk]\n\n# build the model using train set\npopt, pcov = curve_fit(sigmoid, train_x, train_y)\n\n# predict using test set\ny_hat = sigmoid(test_x, *popt)\n\n# evaluation\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_hat - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_hat - test_y) ** 2))\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(y_hat , test_y) )","b9c67343":"### Building The Model ###\nNow, let's build our regression model and initialize its parameters. ","39b7d453":"Our task here is to find the best parameters for our model. Lets first normalize our x and y:","c29ffa06":"<h2 id=\"libraries\"> Importing required libraries<\/h2>","6aac4c64":"### Choosing a model ###\n\nFrom an initial look at the plot, we determine that the logistic function could be a good approximation,\nsince it has the property of starting with a slow growth, increasing growth in the middle, and then decreasing again at the end; as illustrated below:","8b475a5f":"<h2> 4. Exponential <\/h2>","711bef72":"Now we plot our resulting regression model.","07ca9f7e":"The response $y$ is a results of applying logarithmic map from input $x$'s to output variable $y$. It is one of the simplest form of __log()__: i.e. $$ y = \\log(x)$$\n\nPlease consider that instead of $x$, we can use $X$, which can be polynomial representation of the $x$'s. In general form it would be written as  \n\\begin{equation}\ny = \\log(X)\n\\end{equation}","1905fc82":"<h2> 5. Logarithmic <\/h2>","ce97e754":"<h2>I.Introduction<\/h2>\nIf the data shows a curvy trend, then linear regression will not produce very accurate results when compared to a non-linear regression because, as the name implies, linear regression presumes that the data is linear. ","35dd3f36":"\nThe formula for the logistic function is the following:\n\n$$ \\hat{Y} = \\frac1{1+e^{\\beta_1(X-\\beta_2)}}$$\n\n$\\beta_1$: Controls the curve's steepness,\n\n$\\beta_2$: Slides the curve on the x-axis.","b1854cb7":"$$ Y = X^2 $$","b146c20d":"<h2>2. Polynomial  <\/h2>","c86c5005":"<h2>1. Linear <\/h2>","9812d17f":"<a id=\"ref2\"><\/a>\n# II. Non-Linear Regression example","24b89f1f":"$$ Y = a + \\frac{b}{1+ c^{(X-d)}}$$","cf8f332b":"<h1><center>Welcome to Non-Linear Regression Course's <\/center><\/h1>","8ecb9b9c":"Non-linear regressions are a relationship between independent variables $x$ and a dependent variable $y$ which result in a non-linear function modeled data. Essentially any relationship that is not linear can be termed as non-linear, and is usually represented by the polynomial of $k$ degrees (maximum power of $x$). \n\n$$ \\ y = a x^3 + b x^2 + c x + d \\ $$\n\nNon-linear functions can have elements like exponentials, logarithms, fractions, and others. For example: $$ y = \\log(x)$$\n    \nOr even, more complicated such as :\n$$ y = \\log(a x^3 + b x^2 + c x + d)$$","64293a5f":"An exponential function with base c is defined by $$ Y = a + b c^X$$ where b \u22600, c > 0 , c \u22601, and x is any real number. The base, c, is constant and the exponent, x, is a variable. \n\n","f1fb8abc":"### Plotting the Dataset ###\nThis is what the datapoints look like. It kind of looks like an either logistic or exponential function. The growth starts off slow, then from 2005 on forward, the growth is very significant. And finally, it decelerate slightly in the 2010s.","157fdedc":"Though Linear regression is very good to solve many problems, it cannot be used for all datasets. First recall how linear regression, could model a dataset. It models a linear relation between a dependent variable y and independent variable x. It had a simple equation, of degree 1, for example :\n                                                     y = $3x$ + 2.","8a1da59c":"#### How we find the best parameters for our fit line?\nwe can use __curve_fit__ which uses non-linear least squares to fit our sigmoid function, to data. Optimal values for the parameters so that the sum of the squared residuals of sigmoid(xdata, *popt) - ydata is minimized.\n\npopt are our optimized parameters.","71210b80":"<h2> 6.Sigmoidal\/Logistic <\/h2>","8c07f612":"Lets look at a sample sigmoid line that might fit with the data:","b6bc99ed":"<h2>3. Quadratic <\/h2>"}}