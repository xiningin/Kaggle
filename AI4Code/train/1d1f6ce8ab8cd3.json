{"cell_type":{"cd0d64d4":"code","72668daf":"code","4b7aceae":"code","ac6739df":"code","05ab95b8":"code","54757adf":"code","40f56994":"code","6c8f7466":"code","d7c2290a":"code","54abd557":"code","cbff15ca":"code","e95d10c5":"code","55da8926":"code","8cb0ceb2":"code","c0ea8b04":"code","60ab729d":"markdown","867f763d":"markdown","d3bfd998":"markdown","405592ff":"markdown","8541e159":"markdown","5d6061a4":"markdown","c83e8364":"markdown","ac081702":"markdown","34bea318":"markdown"},"source":{"cd0d64d4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\n\nimport cv2","72668daf":"BASEPATH = \"..\/input\/images\/Images\/\"\n\nLABELS = set()\n\npaths = []\n    \nfor d in os.listdir(BASEPATH):\n    LABELS.add(d)\n    paths.append((BASEPATH+d, d))","4b7aceae":"# resizing and converting to RGB\ndef load_and_preprocess_image(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (224,224))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image","ac6739df":"X = []\ny = []\n\nfor path, label in paths:\n    for image_path in os.listdir(path):\n        image = load_and_preprocess_image(path+\"\/\"+image_path)\n        \n        X.append(image)\n        y.append(label)","05ab95b8":"encoder = LabelBinarizer()\n\nX = np.array(X)\ny = encoder.fit_transform(np.array(y))\n\nprint(y[0])","54757adf":"print(X.shape)\nprint(y.shape)\nplt.imshow(X[0])","40f56994":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1)","6c8f7466":"model = Sequential()\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64,(3,3),activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128,(3,3),activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(128,(3,3),activation=\"relu\", padding=\"same\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024,activation=\"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(len(LABELS),activation=\"softmax\"))","d7c2290a":"base_model=VGG16(weights='imagenet',include_top=False)\n\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x)\nx=Dense(1024,activation='relu')(x)\nx=Dropout(0.5)(x)\nx=Dense(512,activation='relu')(x)\npreds=Dense(len(LABELS),activation='softmax')(x)\n\nmodel=Model(inputs=base_model.input,outputs=preds)\n\nfor layer in model.layers[:-5]:\n    layer.trainable=False\nfor layer in model.layers[-5:]:\n    layer.trainable=True\n    \nmodel.compile(\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nprint(model.summary())","54abd557":"early_stopping = EarlyStopping(patience=5, verbose=1,restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=3,verbose=1)","cbff15ca":"model.fit(X_train,y_train,batch_size=64,epochs=50,validation_data=(X_test,y_test), callbacks=[early_stopping, reduce_lr])","e95d10c5":"loss, acc = model.evaluate(X_test,y_test,verbose=0)\nprint(f\"loss on the test set is {loss:.2f}\")\nprint(f\"accuracy on the test set is {acc:.3f}\")","55da8926":"predictions = model.predict(X_test)","8cb0ceb2":"label_predictions = encoder.inverse_transform(predictions)","c0ea8b04":"rows, cols = 5, 3\nsize = 25\n\nfig,ax=plt.subplots(rows,cols)\nfig.set_size_inches(size,size)\nfor i in range(rows):\n    for j in range (cols):\n        index = np.random.randint(0,len(X_test))\n        ax[i,j].imshow(X_test[index])\n        ax[i,j].set_title(f'Predicted: {label_predictions[index]}\\n Actually: {encoder.inverse_transform(y_test)[index]}')\n        \nplt.tight_layout()","60ab729d":"# Introduction\n\nI found this dataset rather cute so I tried to make a deep learning model to predict the breed of the dog\n\nI used transfer learning, basically I took an already trained model and added layers to it, and trained it on this dataset.\n\nThe model I chose is the VGG16, trained on the Imagenet dataset.","867f763d":"### Encoding the labels\n\nEvery model I know of, can only work with numbers, therefore we need to create our label (n02096294-Australian_terrier) to an integer array. This is called **one-hot-encoding**","d3bfd998":"### Evaluation\n\nLast step should always be to evaluate your model","405592ff":"As we can see the accuracy on the test set is over 50% maybe by tuning the model and the hyperparameters we could increase this.","8541e159":"## Loading the images and preprocessing\n\nI chose to load all images into memory, but if you don't have enough memory (around 9.3GB) you can use the generator from keras https:\/\/keras.io\/preprocessing\/image\/.\n\nFurther we have to preprocess the image to fit the VGG16 model. The model expects a 224 by 224 RGB image.\n","5d6061a4":"### Model training\n\nI used the Adam optimizer, typically my first choice.\n\nI trained the model on 50 epochs, with a batch size of 64, I used two callbacks. Early stopping to stop the training of the validation loss does not improve for 5 epochs, and Reduce LR on plateau to reduce the learning rate to 10% if the validation loss doesn't improve for 3 epochs.","c83e8364":"This is the transfer learning model\n\nI used the VGG16 with the Imagenet weights and did not include the top, so I can add my own top. Being 3 Dense Layers with relu activation, and the last one with softmax and number of neurons is the amount of labels we have.\n\nI set the last 5 layers to trainable, which are the Dense layers I added myself. I don't want to train any layers I get from the pretrained VGG16 model.","ac081702":"This is the own model I tried. I have to say I did not have a great succes with it. Maybe it needs more finetuning.","34bea318":"## Training and evaluating\n\nNow comes to most interesting part. Training and evaluating our model\n\nFirst step is to create a training and testing dataset\n\nAfter this I have 2 approaches.\n- Creating our own model, which I tried\n- Using transfer learning on the VGG16 model"}}