{"cell_type":{"dda144d2":"code","b445934d":"code","674a0722":"code","da8229da":"code","ae58f4cb":"code","5a31fbb5":"code","b92350e4":"code","89bbd7d0":"code","f37434ee":"code","4c550801":"code","d6fa1353":"code","2cf8f3a5":"code","025e0972":"code","4fe0f0e5":"code","12b56e69":"code","4d793fd1":"code","531c6198":"code","e47809f2":"code","f6b27d10":"code","6eefa524":"code","044fc1e6":"code","41c2babb":"code","e7de6b70":"code","be282739":"code","fc1f4658":"code","9866a60b":"code","36e0a924":"code","ea270968":"code","813980a9":"code","a1d8fee1":"code","22546993":"code","b3cac402":"code","b5543018":"code","96af1d12":"code","09b19db7":"code","ad34d508":"code","633f8a74":"markdown","5a31bbe5":"markdown","f588a43b":"markdown","a2a48e9b":"markdown","ef65855a":"markdown","de9eb90e":"markdown","cfb06cda":"markdown","63c8c68d":"markdown","582955c5":"markdown","490e73c7":"markdown","7c122264":"markdown","517dbad8":"markdown","2082485d":"markdown","c7baf178":"markdown","4e940255":"markdown","8b62fbe3":"markdown","b5fa8d4a":"markdown","c1af8345":"markdown"},"source":{"dda144d2":"# Uncomment and run the commands below if imports fail\n!conda install numpy pytorch torchvision cpuonly -c pytorch -y\n!pip install matplotlib --upgrade --quiet\n!pip install jovian --upgrade --quiet","b445934d":"# Imports\nimport torch\nimport jovian\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom datetime import *\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","674a0722":"dataframe = pd.read_csv('..\/input\/airquality-uci\/AirQualityUCI.csv', delimiter =';', decimal= ',')\n# here you have to use delimiter ';' which will make your raw data into tabular form with colums and rows\n# decimal = ',' makes your column values seperated with dot rather than comma\ndataframe.head()\n# , parse_dates = [['Date', 'Time']]","da8229da":"dataframe.shape","ae58f4cb":"drop_dataframe = dataframe.dropna(axis = 1, how = 'all', inplace = True)","5a31fbb5":"drop_dataframe = dataframe.dropna(axis = 0, how = 'all')","b92350e4":"drop_dataframe.tail()","89bbd7d0":"drop_dataframe.isna() # check if there's null \n# return False if no null","f37434ee":"drop_dataframe = drop_dataframe.rename(columns={'T': 'Temperature(\\u2103)',\n                                                'RH': 'Relative Humidity(%)',\n                                                'AH': 'Absolute Humidity'})\ndrop_dataframe.head()\n# For degree Celsius symbol, you can use the followings. Both work. \n# 'Temperature \\N{DEGREE SIGN}C'\n# 'Temperature(\\u2103)'","4c550801":"# however our date is in string format \n# extract date, month and year from date \ndrop_dataframe['Day'] = pd.DatetimeIndex(drop_dataframe['Date']).day\ndrop_dataframe['month'] = pd.DatetimeIndex(drop_dataframe['Date']).month\ndrop_dataframe['year'] = pd.DatetimeIndex(drop_dataframe['Date']).year\ndrop_dataframe.head()","d6fa1353":"# Time is in string format in the given data.\n# So we cannot usse datetime.hour to select it. \n# We will extract hour by the followings. \ndrop_dataframe['Hour']=drop_dataframe['Time'].apply(lambda x: str(x)[0:2])\n# what we want is float type and so convert string to float or int\ndrop_dataframe['Hour']= drop_dataframe['Hour'].apply(lambda x: float(x))\ndrop_dataframe.dtypes","2cf8f3a5":"# remove date and time columns\ndf = drop_dataframe.drop(['Date', 'Time'], axis = 1)\ndf.head()","025e0972":"df.shape","4fe0f0e5":"import os \nos.chdir(r'\/kaggle\/working')\ndf.to_csv(r'df.csv')","12b56e69":"# To convert into Tensor, select columns in list form. If it is not numpy, you will see an error. \ninput_cols = list(df.drop(['Relative Humidity(%)'], axis = 1)) \n#target_cols = list(df.columns)[11]\ntarget_cols = list(df.drop(input_cols, axis = 1))\nprint('input_cols:', input_cols, '\\n')\nprint('target_cols: ', target_cols)","4d793fd1":"# convert to numpy\ninput_arrays = drop_dataframe[input_cols].to_numpy()\ntarget_arrays = drop_dataframe[target_cols].to_numpy()\ninput_arrays.shape, target_arrays.shape\n#target_arrays","531c6198":"# convert input and targets into Pytorch Tensor, make sure data type is torch.float32\ninputs = torch.from_numpy(np.array(input_arrays, dtype = 'float32'))\ntargets = torch.from_numpy(np.array(target_arrays, dtype = 'float32'))","e47809f2":"dataset = TensorDataset(inputs, targets)","f6b27d10":"val_percent = 0.2 \nnum_rows = df.shape[0]\nnum_cols = df.shape[1]\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(dataset, [val_size, train_size])","6eefa524":"batch_size = 64","044fc1e6":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n# need to shuffle the train_ds for better result\nval_loader = DataLoader(val_ds, batch_size)\n# validation dataset does not to be shuffled because it is just for fit and evaluation","41c2babb":"df.head()","e7de6b70":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break\n\n# you won't see the same number in the same place as shown in above table because you shuffled the data ","be282739":"target_arrays","fc1f4658":"input_size = len(input_cols)\noutput_size = len(target_cols)","9866a60b":"class AQModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size) # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb)                          # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out,targets)                      # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out,targets)                          # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))\n            \nmodel = AQModel()","36e0a924":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","ea270968":"result = evaluate(model, val_loader) # Before using model\nprint(result)","813980a9":"model = AQModel()\nepochs = 10000\nlr = 1e-8\nhistory = fit(epochs, lr, model, train_loader, val_loader)","a1d8fee1":"losses = [r['val_loss'] for r in [result] + history]\nplt.plot(losses, '-x')\nplt.xlabel('epoch')\nplt.ylabel('val_loss')\nplt.title('val_loss vs. epochs');","22546993":"def predict_single(x, model):\n    xb = x.unsqueeze(0)\n    return model(x).item()","b3cac402":"x, target = val_ds[10]\npred = predict_single(x, model)\nprint(\"Input: \", x)\nprint(\"Target: \", target.item())\nprint(\"Prediction:\", pred)","b5543018":"torch.save(model.state_dict(), 'air-quality-linear-minimal.pth')","96af1d12":"val_loss = [result] + history","09b19db7":"jovian.log_metrics(val_loss=val_loss)","ad34d508":"jovian.commit(project='air-quality-linear-minimal', environment=None, outputs=['air-quality-linear-minimal.pth'])\njovian.commit(project='air-quality-linear-minimal', environment=None, outputs=['air-quality-linear-minimal.pth']) # Kaggle commit fails sometimes, so try again..","633f8a74":"## Save and upload","5a31bbe5":"Check if it's working fine.","f588a43b":"# Relative Humidity prediction using linear regression (minimal)\n\nUsing the boston housing dataset: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Air+Quality","a2a48e9b":"## Prediction","ef65855a":"# **Check Rows and Columns**","de9eb90e":"## Training","cfb06cda":"To drop rows or cos in csv, we use dropna()\naxis = 1 means columns \nhow = 'all' means if all column values are null, we will drop\ninplace = 'True' means that this drop() will affect the origianl dataframe.","63c8c68d":"# Extract Date and Time","582955c5":"axis = 0 means index","490e73c7":"# Prepare DataSet","7c122264":"## Read file ","517dbad8":"To determine the fraction of data that will be used for creating the validation set, we will use 0.2. It means that you use 80% for training, 20 % for validation from the given data. Then use random_split to create training & validation datasets. ","2082485d":"We will define batch size which is good for memory. If you train all data at the same time, your training will take a huge time.","c7baf178":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a TensorDataset.","4e940255":"# Rename columns","8b62fbe3":"# Remove Columns with missing values","b5fa8d4a":"# Select inputs and target","c1af8345":"## Create a linear Regression Model"}}