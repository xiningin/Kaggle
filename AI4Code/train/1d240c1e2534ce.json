{"cell_type":{"3c7e250a":"code","c56ca3f6":"code","df831d16":"code","83c576df":"code","58047b59":"code","3c2eb3eb":"code","a8bc1715":"code","75be515a":"code","af346f90":"code","0161106a":"code","5eb44f2c":"code","d9a74478":"code","9255d886":"code","16e1bb1b":"code","6c6f2640":"code","b217f322":"code","c79b12d0":"code","63c8573e":"code","d9175347":"code","817ded54":"code","c27bcfaf":"code","eae1c9fd":"code","8f7797ed":"code","9d627afa":"code","6e06a895":"code","6a6c7e00":"code","6645910a":"code","a1bd6ed1":"code","3502900c":"code","af889ea2":"code","279a2d6f":"code","b926c479":"code","6fc6c595":"code","f0d1dcf0":"markdown","53ee2152":"markdown","8b43dd67":"markdown","7833b970":"markdown","a057cd8a":"markdown","80014161":"markdown","fc028d1d":"markdown","1737f60f":"markdown","fb527f15":"markdown","0cfc7a88":"markdown","4a04e5cd":"markdown"},"source":{"3c7e250a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set(style=\"ticks\")\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport sklearn\nimport scipy\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\npd.set_option('display.max_columns', 100)\n%matplotlib inline","c56ca3f6":"def format_spines(ax, right_border=True):\n    \n    ax.spines['bottom'].set_color('#666666')\n    ax.spines['left'].set_color('#666666')\n    ax.spines['top'].set_visible(False)\n    if right_border:\n        ax.spines['right'].set_color('#FFFFFF')\n    else:\n        ax.spines['right'].set_color('#FFFFFF')\n    ax.patch.set_facecolor('#FFFFFF')\n\ndef count_plot(feature, df, colors='Greens_d', hue=False, ax=None, title=''):\n    \n    # Preparing variables\n    ncount = len(df)\n    if hue != False:\n        ax = sns.countplot(x=feature, data=df, palette=colors, hue=hue, ax=ax)\n    else:\n        ax = sns.countplot(x=feature, data=df, palette=colors, ax=ax)\n        \n    format_spines(ax)\n    \n    # Setting percentage\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n#        ax.annotate('{:.1f}%'.format(100.*y\/ncount), (x.mean(), y), \n#                ha='center', va='bottom') # set the alignment of the text\n        ax.annotate(y, (x.mean(), y), \n                ha='center', va='bottom') # set the alignment of the text\n    \n    # Final configuration\n    if not hue:\n        ax.set_title(df[feature].describe().name + ' Analysis', size=13, pad=15)\n    else:\n        ax.set_title(df[feature].describe().name + ' Analysis by ' + hue, size=13, pad=15)  \n    if title != '':\n        ax.set_title(title)       \n    plt.tight_layout()\n    \n    \ndef bar_plot(x, y, df, colors='Blues_d', hue=False, ax=None, value=False, title=''):\n    \n    # Preparing variables\n    try:\n        ncount = sum(df[y])\n    except:\n        ncount = sum(df[x])\n    #fig, ax = plt.subplots()\n    if hue != False:\n        ax = sns.barplot(x=x, y=y, data=df, palette=colors, hue=hue, ax=ax, ci=None)\n    else:\n        ax = sns.barplot(x=x, y=y, data=df, palette=colors, ax=ax, ci=None)\n\n    # Setting borders\n    format_spines(ax)\n\n    # Setting percentage\n    for p in ax.patches:\n        xp=p.get_bbox().get_points()[:,0]\n        yp=p.get_bbox().get_points()[1,1]\n        if value:\n            ax.annotate('{:.2f}k'.format(yp\/1000), (xp.mean(), yp), \n                    ha='center', va='bottom') # set the alignment of the text\n        else:\n            ax.annotate('{:.1f}%'.format(100.*yp\/ncount), (xp.mean(), yp), \n                    ha='center', va='bottom') # set the alignment of the text\n    if not hue:\n        ax.set_title(df[x].describe().name + ' Analysis', size=12, pad=15)\n    else:\n        ax.set_title(df[x].describe().name + ' Analysis by ' + hue, size=12, pad=15)\n    if title != '':\n        ax.set_title(title)  \n    plt.tight_layout()\n    \n    \ndef categorical_plot(cols_cat, axs, df):\n    \n    idx_row = 0\n    for col in cols_cat:\n        # Returning column index\n        idx_col = cols_cat.index(col)\n\n        # Verifying brake line in figure (second row)\n        if idx_col >= 3:\n            idx_col -= 3\n            idx_row = 1\n\n        # Plot params\n        names = df[col].value_counts().index\n        heights = df[col].value_counts().values\n\n        # Bar chart\n        axs[idx_row, idx_col].bar(names, heights, color='navy')\n        if (idx_row, idx_col) == (0, 2):\n            y_pos = np.arange(len(names))\n            axs[idx_row, idx_col].tick_params(axis='x', labelrotation=30)\n        if (idx_row, idx_col) == (1, 1):\n            y_pos = np.arange(len(names))\n            axs[idx_row, idx_col].tick_params(axis='x', labelrotation=90)\n\n        total = df[col].value_counts().sum()\n        axs[idx_row, idx_col].patch.set_facecolor('#FFFFFF')\n        format_spines(axs[idx_row, idx_col], right_border=False)\n        for p in axs[idx_row, idx_col].patches:\n            w, h = p.get_width(), p.get_height()\n            x, y = p.get_xy()\n            axs[idx_row, idx_col].annotate('{:.1%}'.format(h\/1000), (p.get_x()+.29*w,\n                                            p.get_y()+h+20), color='k')\n\n        # Plot configuration\n        axs[idx_row, idx_col].set_title(col, size=12)\n        axs[idx_row, idx_col].set_ylim(0, heights.max()+120)","df831d16":"#Load Data\norder = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv')\ncustomer = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv')\nreview = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv')\npayment = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv')\norder_item = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv')\nproduct = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_products_dataset.csv')\nseller = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv')\ngeo = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv')\ntranslation = pd.read_csv('..\/input\/brazilian-ecommerce\/product_category_name_translation.csv')","83c576df":"#Data Pre-processing \n#Translate Product Category: \n#product = product.merge(trans, on = 'product_category_name', how = 'left')\n#product = product.drop('product_category_name', axis =1)\n\n#Convert Timestamp Data\norder_date=['order_purchase_timestamp', u'order_approved_at',\n            u'order_delivered_carrier_date', u'order_delivered_customer_date',\n            u'order_estimated_delivery_date']\nfor items in order_date:\n    order[items] = pd.to_datetime(order[items],format='%Y-%m-%d %H:%M:%S')\n    ","58047b59":"# creating master dataframe \npayment.head()\nprint(payment.shape)\ndf1 = payment.merge(order_item, on='order_id')\nprint(df1.shape)\ndf2 = df1.merge(product, on='product_id')\nprint(df2.shape)\ndf3 = df2.merge(seller, on='seller_id')\nprint(df3.shape)\ndf4 = df3.merge(review, on='order_id')\nprint(df4.shape)\ndf5 = df4.merge(order, on='order_id')\nprint(df5.shape)\ndf6 = df5.merge(translation, on='product_category_name')\nprint(df6.shape)\ndf = df6.merge(customer, on='customer_id')\nprint(df.shape)","3c2eb3eb":"#cleaning up and re-engineering some columns\ndf['order_purchase_year'] = df.order_purchase_timestamp.apply(lambda x: x.year)\ndf['order_purchase_month'] = df.order_purchase_timestamp.apply(lambda x: x.month)\ndf['order_purchase_dayofweek'] = df.order_purchase_timestamp.apply(lambda x: x.dayofweek)\ndf['order_purchase_hour'] = df.order_purchase_timestamp.apply(lambda x: x.hour)\ndf['order_purchase_day'] = df['order_purchase_dayofweek'].map({0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'})\ndf['order_purchase_mon'] = df.order_purchase_timestamp.apply(lambda x: x.month).map({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\ndf['order_count']=1\ndf['year_month'] = df['order_purchase_timestamp'].dt.strftime('%Y-%m')\n\ndf['ship_duration']=(df['order_delivered_customer_date']-df['order_purchase_timestamp'])\/24\ndf['ship_duration']=df['ship_duration'].astype('timedelta64[h]')\n\ndf['tocarrier_duration']=(df['order_delivered_carrier_date']-df['order_purchase_timestamp'])\/24\ndf['tocarrier_duration']=df['tocarrier_duration'].astype('timedelta64[h]')\n\ndf['lastmile_duration']=(df['order_delivered_customer_date']-df['order_delivered_carrier_date'])\/24\ndf['lastmile_duration']=df['lastmile_duration'].astype('timedelta64[h]')\n\ndf['expected_vs_shipdate']=(df['order_estimated_delivery_date']-df['order_delivered_customer_date'])\/24\ndf['expected_vs_shipdate']=df['expected_vs_shipdate'].astype('timedelta64[h]')\n\ndf['expected_duration']=(df['order_estimated_delivery_date']-df['order_purchase_timestamp'])\/24\ndf['expected_duration']=df['expected_duration'].astype('timedelta64[h]')","a8bc1715":"#CODE TO DELETE\n#df['year_month']=df.order_purchase_timestamp.dt.to_period('M')\n#df['month_year'] = df['order_purchase_year'].astype(str) + '-' + df['order_purchase_month'].astype(str) #won't be able to plot a correct x-axis with this\n#df['order_purchase_month'] = df['order_purchase_month'].astype(int) #won't be able to plot a correct x-axis with this\n#dropping non-needed columns\n#df = df.drop([\"product_name_lenght\", \"product_description_lenght\", \"product_photos_qty\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\", \"product_length_cm\", \"review_id\",\"review_comment_title\", \"review_comment_message\", \"product_category_name\"], axis=1)\n\n# displaying missing value counts and corresponding percentage against total observations ===> BUG-ALERT: THE CODE CAUSING 2016 and 2017 DATA LOSS\n#missing_values = df.isnull().sum().sort_values(ascending = False)\n#percentage = (df.isnull().sum()\/df.isnull().count()*100).sort_values(ascending = False)\n#pd.concat([missing_values, percentage], axis=1, keys=['Values', 'Percentage']).transpose()\n\n# dropping missing values\n#df.dropna(inplace=True)\n#df.isnull().values.any()\n\n# Creating new year-month column\n#df_cus_count['month_year'] = df_cus_count['order_purchase_year'].astype(str) + '-' + df_cus_count['order_purchase_month'].astype(str)\n#df_cus_count['order_purchase_month'] = df_cus_count['order_purchase_month'].astype(int)\n#df_cus_st = df.groupby(['customer_state'], as_index=False).sum().loc[:, ['customer_state', 'payment_value']].sort_values(by='payment_value', ascending=False)\n#df_cus_ct = df.groupby(['customer_city'], as_index=False).sum().loc[:, ['customer_city', 'payment_value']].sort_values(by='payment_value', ascending=False).head(20)\n\n# Creating new year-month column\n#df_ytsales['month_year'] = df_ytsales['order_purchase_year'].astype(str) + '-' + df_ytsales['order_purchase_month'].astype(str)\n#df_ytsales['order_purchase_month'] = df_ytsales['order_purchase_month'].astype(int)\n#df_ytsales['month_year_1'] = pd.to_datetime(df[['order_purchase_year', 'order_purchase_month']].assign(DAY=1)).dt.strftime('%Y-%m')\n#df_ytsales.rename(columns={'order_purchase_year':'year'})\n#df_ytsales.rename(columns={'order_purchase_month':'month'})\n#df_ytsales['month_year_1'] = pd.to_datetime(df[['order_purchase_year', 'order_purchase_month']].assign(DAY=1))\n#df_ytsales['month_year_1'] = pd.to_datetime(df_ytsales[['year', 'month']].assign(DAY=1))","75be515a":"# displaying first 3 rows of master dataframe\ndf.head(3)","af346f90":"#Debug code - to delete\nprint(df.shape)\ndf_2016 = df.query('order_purchase_year==\"2016\"')\nprint(df_2016.shape)","0161106a":"# Creating new datasets for each year\ndf_2016 = df.query('order_purchase_year==\"2016\"')\ndf_2017 = df.query('order_purchase_year==\"2017\"')\ndf_2018 = df.query('order_purchase_year==\"2018\"')\n\nfig, axs = plt.subplots(1, 3, figsize=(22, 5))\ncount_plot(feature='order_purchase_year', df=df, ax=axs[0], title='Total Order Purchase by Year')\ncount_plot(feature='order_purchase_year', df=df_2017, ax=axs[1], hue='order_purchase_month', title='Number of Orders by Month in 2017')\ncount_plot(feature='order_purchase_year', df=df_2018, ax=axs[2], hue='order_purchase_month', title='Number of Orders by Month in 2018')\n\n\n#count_plot(feature='order_purchase_year', df=df, ax=axs[2], hue='order_purchase_dayofweek', title='Total Yearly order Purchase by Day of the Week')\n#format_spines(ax, right_border=False)\nplt.suptitle('Score Counting Through the Years', y=1.1)\nplt.show()","5eb44f2c":"#df_ytsales_ym = df.groupby(['order_purchase_year', 'order_purchase_month','year_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month','year_month', 'payment_value','order_count']]\n#df_ytsales_ym.head(3)","d9a74478":"# Creating new datasets for each year\ndf_2016 = df.query('order_purchase_year==\"2016\"')\ndf_2017 = df.query('order_purchase_year==\"2017\"')\ndf_2018 = df.query('order_purchase_year==\"2018\"')\n\ndf_ytsales = df.groupby(['order_purchase_year', 'order_purchase_month','year_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month','year_month', 'payment_value','order_count']]\n#df_ytsales = df.groupby(['order_purchase_year', 'order_purchase_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month', 'payment_value','order_count']]\n\ndf_ytsales_2016 = df_2016.groupby(['order_purchase_year', 'order_purchase_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month', 'payment_value']]\ndf_ytsales_2017 = df_2017.groupby(['order_purchase_year', 'order_purchase_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month', 'payment_value']]\ndf_ytsales_2018 = df_2018.groupby(['order_purchase_year', 'order_purchase_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month', 'payment_value']]\n\nfig, axs = plt.subplots(1, 3, figsize=(22, 5))\nbar_plot(x='order_purchase_year', y='payment_value', df=df_ytsales, ax=axs[0], value=True)\nbar_plot(x='order_purchase_month', y='payment_value', df=df_ytsales_2017, ax=axs[1], value=True)\nbar_plot(x='order_purchase_month', y='payment_value', df=df_ytsales_2018, ax=axs[2], value=True)\n\naxs[0].set_title('Monthly Sales in 2016 to 2018')\naxs[1].set_title('Monthly Sales in 2017')\naxs[2].set_title('Monthly Sales in 2018', pad=10)\n\nplt.suptitle('Order Payment Value Through the Years', y=1.1)\nplt.show()","9255d886":"fig, ax = plt.subplots(figsize=(20, 4.5))\nax = sns.lineplot(x='year_month', y='payment_value', data=df_ytsales)\nbar_plot(x='year_month', y='payment_value', df=df_ytsales, value=True)\nformat_spines(ax, right_border=False)\nax.set_title('Brazilian E-Commerce Monthly Sales from 2016 to 2018')","16e1bb1b":"fig, ax = plt.subplots(figsize=(20, 4.5))\nax = sns.lineplot(x='year_month', y='order_count', data=df_ytsales)\nbar_plot(x='year_month', y='order_count', df=df_ytsales, value=True)\nformat_spines(ax, right_border=False)\nax.set_title('Brazilian E-Commerce Monthly Order Volume from 2016 to 2018')","6c6f2640":"# Grouping by customer state\ndf_cus_count = df.groupby(['order_purchase_year', 'order_purchase_month','year_month'], as_index=False).nunique().loc[:, ['order_purchase_year', 'order_purchase_month','year_month', 'customer_unique_id','seller_id']]\ndf_cus_count.head(10)","b217f322":"#df_ytsales.head(10)","c79b12d0":"fig, ax = plt.subplots(figsize=(20, 4.5))\nax = sns.lineplot(x='year_month', y='customer_unique_id', data=df_cus_count)\nbar_plot(x='year_month', y='customer_unique_id', df=df_cus_count, value=True)\nformat_spines(ax, right_border=False)\nax.set_title('Brazilian E-Commerce Number of Customers from 2016 to 2018')\nplt.show()","63c8573e":"df_cus_state = df.groupby(['customer_state','order_purchase_year'], as_index=False).sum().loc[:, ['customer_state','order_purchase_year', 'payment_value']].sort_values(by='payment_value', ascending=False)\ndf_cus_state.head(10)","d9175347":"df_cus_state = df.groupby(['customer_state','year_month'], as_index=False).sum().loc[:, ['customer_state','year_month', 'payment_value']].sort_values(by='payment_value', ascending=False)\n#df_top5_state = df_cus_state.query('customer_state==\"2016\"')","817ded54":"\ntop5 = ['SP', 'RJ','MG','RS','PR']\ndf_top5_state = df_cus_state.loc[df_cus_state['customer_state'].isin(top5)]\ndf_top5_state.head(3)\n\nfig, ax = plt.subplots(figsize=(20, 4.5))\nfor state in top5:\n    ax = sns.lineplot(x='year_month', y='payment_value', data=df_top5_state[df_top5_state['customer_state']==state], label=state)\nformat_spines(ax, right_border=False)\nax.set_title('Sales from the top 5 states from 2016 to 2018')","c27bcfaf":"top4_noSP = ['RJ','MG','RS','PR']\ndf_top4_noSP = df_cus_state.loc[df_cus_state['customer_state'].isin(top4_noSP)]\ndf_top4_noSP.head(3)\n\nfig, ax = plt.subplots(figsize=(20, 4.5))\nfor state in top4_noSP:\n    ax = sns.lineplot(x='year_month', y='payment_value', data=df_top4_noSP[df_top4_noSP['customer_state']==state], label=state)\nformat_spines(ax, right_border=False)\nax.set_title('Sales from the top 4 states from 2016 to 2018, excluding SP')","eae1c9fd":"fig, ax = plt.subplots(figsize=(20, 4.5))\nax = sns.lineplot(x='year_month', y='seller_id', data=df_cus_count)\nbar_plot(x='year_month', y='seller_id', df=df_cus_count, value=True)\nformat_spines(ax, right_border=False)\nax.set_title('Brazilian E-Commerce Number of Sellers from 2016 to 2018')\nplt.show()","8f7797ed":"#Create a dataframe to count how many times a customer shop \ndf_order = df.groupby(['order_id','year_month','order_purchase_year','customer_unique_id'], as_index=False).sum().loc[:, ['order_id','customer_unique_id','year_month','order_purchase_year', 'payment_value']].sort_values(by='year_month', ascending=True)\ndf_order['time_to_shop'] = 1\ndf_order['time_to_shop']=df_order.groupby(['customer_unique_id']).cumcount() + 1 #cumcount() starts at 0, add 1 so that it starts at 1\n#print(df_order.shape)\ndf_order.head(10)\n\n#df_order['new_order']=order_customer.groupby(['customer_unique_id']).cumcount() + 1\n#indices = order_customer['new_order'] != 1\n#order_customer.loc[indices,'new_order'] = 0\n\ndf_order_2016 = df_order[df_order['order_purchase_year']==2016]\ndf_order_2017 = df_order[df_order['order_purchase_year']==2017]\ndf_order_2018 = df_order[df_order['order_purchase_year']==2018]","9d627afa":"df_count_cust = df_order.groupby(['customer_unique_id']).count().reset_index()\ndf_count_cust[\"order_count\"] = df_count_cust[\"order_id\"]\ndf_count_cust = df_count_cust.drop([\"order_id\", \"year_month\", \"payment_value\", \"time_to_shop\",\"order_purchase_year\"], axis=1)\ndf_count_cust = df_count_cust.groupby([\"order_count\"]).count().reset_index().rename(columns={\"customer_unique_id\": \"num_customer\"})\ndf_count_cust[\"percentage_customer\"] = 100.0 * df_count_cust[\"num_customer\"] \/ df_count_cust[\"num_customer\"].sum()\ndf_count_cust","6e06a895":"df_count_cust= df_order_2016.groupby(['customer_unique_id']).count().reset_index()\ndf_count_cust[\"order_count\"] = df_count_cust[\"order_id\"]\ndf_count_cust = df_count_cust.drop([\"order_id\", \"year_month\", \"payment_value\", \"time_to_shop\"], axis=1)\ndf_count_cust = df_count_cust.groupby([\"order_count\"]).count().reset_index().rename(columns={\"customer_unique_id\": \"num_customer\"})\ndf_count_cust[\"percentage_customer\"] = 100.0 * df_count_cust[\"num_customer\"] \/ df_count_cust[\"num_customer\"].sum()\ndf_count_cust","6a6c7e00":"df_count_cust= df_order_2017.groupby(['customer_unique_id']).count().reset_index()\ndf_count_cust[\"order_count\"] = df_count_cust[\"order_id\"]\ndf_count_cust = df_count_cust.drop([\"order_id\", \"year_month\", \"payment_value\", \"time_to_shop\"], axis=1)\ndf_count_cust = df_count_cust.groupby([\"order_count\"]).count().reset_index().rename(columns={\"customer_unique_id\": \"num_customer\"})\ndf_count_cust[\"percentage_customer\"] = 100.0 * df_count_cust[\"num_customer\"] \/ df_count_cust[\"num_customer\"].sum()\ndf_count_cust","6645910a":"df_count_cust= df_order_2018.groupby(['customer_unique_id']).count().reset_index()\ndf_count_cust[\"order_count\"] = df_count_cust[\"order_id\"]\ndf_count_cust = df_count_cust.drop([\"order_id\", \"year_month\", \"payment_value\", \"time_to_shop\", 'order_purchase_year'], axis=1)\ndf_count_cust = df_count_cust.groupby([\"order_count\"]).count().reset_index().rename(columns={\"customer_unique_id\": \"num_customer\"})\ndf_count_cust[\"percentage_customer\"] = 100.0 * df_count_cust[\"num_customer\"] \/ df_count_cust[\"num_customer\"].sum()\ndf_count_cust","a1bd6ed1":"df_quality = df.groupby(['order_purchase_year','year_month'], as_index=False).mean().loc[:, ['order_purchase_year','year_month','expected_duration','ship_duration', 'tocarrier_duration', 'lastmile_duration','expected_vs_shipdate','review_score']]\ndf_quality.head(10)","3502900c":"df_quality = df.groupby(['order_purchase_year'], as_index=False).mean().loc[:, ['order_purchase_year','expected_duration','ship_duration', 'tocarrier_duration', 'lastmile_duration','expected_vs_shipdate','review_score']]\ndf_quality.head(10)","af889ea2":"fig, axes = plt.subplots(nrows=2, ncols=2,figsize=(20,10),dpi=120)\n\ndf['expected_duration'].plot.hist(bins=30, alpha = 1,ax = axes[0,0])\naxes[0,0].set_title('Expected Ship Duration (days)')\n\ndf['ship_duration'].plot.hist(bins=30, alpha = 1,ax = axes[1,0])\naxes[1,0].set_title('End-to-End Ship Duration (days)')\n\ndf['tocarrier_duration'].plot.hist(bins=30, alpha = 1,ax = axes[0,1])\naxes[0,1].set_title('Middle mile lead-time: from retailers to carriers (days)')\n\ndf['lastmile_duration'].plot.hist(bins=30, alpha = 1,ax = axes[1,1])\naxes[1,1].set_title('Last mile lead-time: from carriers to customers (days)')","279a2d6f":"#drop outliers to make the histograms clearer\ndf_quality_chart_1 = df[df.expected_duration < 50] #drop any expected duration more than 60 days from purchase date\ndf_quality_chart_2 = df[df.ship_duration < 50] #drop any end-to-end ship duration more than 60 days from purchase date\ndf_quality_chart_3 = df[(df['tocarrier_duration'] < 30) & (df['tocarrier_duration'] > 0)] #drop any end-to-end ship duration more than 10 days from purchase date\ndf_quality_chart_4 = df[(df['lastmile_duration'] < 30) & (df['lastmile_duration'] > 0)] #drop any end-to-end ship duration more than 60 days from purchase date\ndf_quality_chart_5 = df[(df['expected_vs_shipdate'] < 30) & (df['expected_vs_shipdate'] > -30)] #drop any difference beyond 50 days btw expected ship date and actual ship date\n\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(20,10),dpi=120)\n\ndf_quality_chart_1['expected_duration'].plot.hist(bins=30, alpha = 1,ax = axes[0,0])\naxes[0,0].set_title('Expected Ship Duration 2016-2018 (days)')\n\ndf_quality_chart_2['ship_duration'].plot.hist(bins=30, alpha = 1,ax = axes[1,0])\naxes[1,0].set_title('End-to-End Ship Duration 2016-2018 (days)')\n\ndf_quality_chart_3['tocarrier_duration'].plot.hist(bins=20, alpha = 0.5,ax = axes[0,1])\naxes[0,1].set_title('Middle mile lead-time: from retailers to carriers 2016-2018 (days)')\n\ndf_quality_chart_4['lastmile_duration'].plot.hist(bins=20, alpha = 0.5,ax = axes[1,1])\naxes[1,1].set_title('Last mile lead-time: from carriers to customers 2016-2018 (days)')\n\n#df_quality_chart['lastmile_duration'].plot.hist(bins=30, alpha = 1)\n","b926c479":"df_quality_chart_5['expected_vs_shipdate'].plot.hist(bins=15, alpha = 1)\nplt.title(\"Difference between expected ship date and delivered date\")","6fc6c595":"df['review_score'].plot.hist(bins=10, alpha = 1)\nplt.title(\"Review Score 2016-2018\")","f0d1dcf0":"# Sellers\nThe number of sellers is still increasing MoM, despite a reduced in order volume","53ee2152":"# Churn Analysis","8b43dd67":"# Rootcause Analysis\nWhy 96% of customers shop with us only once? Key factors include\n* Price\n* Customer Experience - proxy by Review\n* Delivery Duration \n\n****Since we have review scores and order delivery time, we will focus here first. \n","7833b970":"\n    1. Analyze total customers by month-year: apart from seasonal factors, is there any problem?\n    2. Analyze churn by states (geo)","a057cd8a":"All other top 4 states suffer from the same decline as SP.\nSince the sale decline happened in 2018 across all states, there could be only two reasons: \n* Competitors launch something in Brazil, attracting customers\/sales to their sites. The top 3 states are all trending down in the past 3 to 4 months. \n* There are some serious bugs\/business strategy changes\n\nSince the case assumed no major bugs, the first hypothesis is the most reasonable one.\nThis hypothesis is further confirmed here \"The company [Amazon] made its first big move into merchandise in October 2017, when it began offering the use of its Brazilian website to third-party merchants to sell electronics.\" Source: https:\/\/www.reuters.com\/article\/us-amazon-com-brazil\/amazon-com-starts-direct-sales-of-merchandise-in-brazil-after-delays-idUSKCN1PG0AG","80014161":"# Orders Volume and Sales Analysis\nObservations: Order purchase was on a rise throughout 2017, and suddenly came to a plateau in 2018 and has been on a downward trend. Both order's volume and order's value have reduced in 2018 \n\nThis reduction on order volume and sales happened very sudden at the start of 2018, across all geos.","fc028d1d":"# Time Series Analysis\n\n*** Context:** We observed that new user growth has gradually slowed over the last year. In the past few months, customer churn is up to 10% from last year. No obvious change in product or major bug. \n\n*** Question:** why are retailers churning?\n\n*** Analysis Direction:** We will discover the reasons for retailer churn by analyzing three dimensions: \n1. Customers Analysis: New User, Retention (repeated purchases) - Any trends YoY? Anythings standout by Geo?\n2. Order Analysis: Order volume (take into account seasonality) & value\n3. Review Analysis: Any significant degrade in CSAT","1737f60f":"Although our review score is not too bad, we have a very long end-to-end ship duration. The review score is high because our expected delivery date is almost a month, so we beat it everytime!","fb527f15":"Based on the above table, the biggest five states: SP, RJ, MG, RS, and PR\nTheir sale patterns are similar, on the decline. SP dominates the overall sale figure, so let's isolate it out.****","0cfc7a88":"96% of customers only buy with Olist once, which is a big problem. ","4a04e5cd":"This delivery performance won't keep any customers. Average duration to ship is between 15-30 days!"}}