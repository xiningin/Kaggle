{"cell_type":{"821460ea":"code","8e9cf5de":"code","95e31dd7":"code","3cc90c84":"code","f1a23f8e":"code","11b8ce25":"code","738f33ad":"code","dab0fafe":"code","d4ef5196":"code","f04fb144":"code","22e2c555":"code","6d9e4c77":"code","43faaf94":"code","f3ea3bb8":"code","eb2a4d75":"code","dcb3f1e8":"code","dae1d3b5":"code","ed368cd7":"code","0acac288":"code","512868d3":"code","7f12a6dc":"code","90fa9cab":"code","ff7fc389":"code","11dff603":"code","9dce82b5":"code","3a33a544":"code","6551f334":"code","4feefeb7":"code","608076fd":"code","6fd258e3":"code","c145c524":"code","bb8d6b2d":"code","a4f0a07b":"code","56be9e42":"code","1373c170":"code","728279dc":"code","0760190d":"code","fcbdc3e8":"code","95b09d71":"code","27cfe97e":"code","95cdd89a":"markdown","c81f46fb":"markdown","5076f357":"markdown","25ad5020":"markdown","1bdf8377":"markdown","c14c6de1":"markdown","dc475dda":"markdown","3bb0ef2c":"markdown","cad05750":"markdown","dbb0365c":"markdown","c6d05c64":"markdown","2581b940":"markdown","0f89a0bd":"markdown","c04bb56a":"markdown","7c9ed584":"markdown","dce97ae0":"markdown","92dd3b1d":"markdown","8907a28e":"markdown","972d35de":"markdown","7b4d4416":"markdown","f79d2504":"markdown","3c2b527f":"markdown","886e538c":"markdown","4d0589c6":"markdown","49b2723d":"markdown","5f639212":"markdown","a96786af":"markdown","0cab591c":"markdown","74c0e147":"markdown","3c5a4a57":"markdown","76fe890a":"markdown","18e2cb42":"markdown","0f7a4666":"markdown","543f277c":"markdown","9ad206c8":"markdown","381aa0c3":"markdown","f7012a28":"markdown","c0b9e5af":"markdown","bf4e2b71":"markdown","d4c3d7bc":"markdown","0f1c2d67":"markdown","5629242c":"markdown"},"source":{"821460ea":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\n# Standard plotly imports\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\n\n# Using plotly + cufflinks in offline mode\ninit_notebook_mode(connected=True)\ncufflinks.go_offline(connected=True)\n\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8e9cf5de":"def knowningData(df, limit=5): #seting the function with df, \n    print(f\"Dataset Shape: {df.shape}\")\n    print('Unique values per column: ')\n    print(df.nunique())\n    print(\"################\")\n    print(\"\")    \n    for column in df.columns: #initializing the loop\n        print(\"Column Name: \", column )\n        entropy = round(stats.entropy(df[column].value_counts(normalize=True), base=2),2)\n        print(\"Entropy \", entropy, \n              \" | Total nulls: \", (round(df[column].isnull().sum() \/ len(df[column]) * 100,2)),\n              \" | Total unique values: \", df.nunique()[column], #print the data and % of nulls\n              \" | Missing: \", df[column].isna().sum())\n        print(\"Top 5 most frequent values: \")\n        print(round(df[column].value_counts(normalize=True)[:5],2))\n        print(\"\")\n        print(\"####################################\")\n\ndef object_cols(df, cols):\n    for col in cols:\n        df[col] = df[col].astype(object)\n    return df\n\ndef quantiles(df, columns):\n    for name in columns:\n        print(name + \" quantiles\")\n        print(df[name].quantile([.01,.25,.5,.75,.99]))\n        print(\"\")\n        \ndef plotly_plots(df, column, plot_type='bar', title=None, xTitle=None, yTitle=None):\n    temp = df[column].value_counts()\n    temp.iplot(kind=plot_type, title=title, xTitle=xTitle, yTitle=yTitle)\n    \ndef quantile_plot(x, **kwargs):\n    qntls, xr = stats.probplot(x, fit=False)\n    plt.scatter(xr, qntls, **kwargs)\n\n# This function is to extract date features\ndef date_process(df, cols, form=None):\n    for col in cols:\n\n        df[col] = pd.to_datetime(df[col]) # seting the column as pandas datetime\n        df['_weekdayName_'+str(col)] = df[col].dt.weekday_name #extracting week day\n        df['_weekday_'+str(col)] = df[col].dt.weekday #extracting week day        \n        df['_day_'+str(col)] = df[col].dt.day # extracting day\n        df['_month_'+str(col)] = df[col].dt.month # extracting month\n        if col == 'ScheduledDay':\n            df['_hour_'+str(col)] = df[col].dt.hour # extracting hour\n            df['_minute_'+str(col)] = df[col].dt.minute # extracting minute\n        # df[col] = df[col].dt.date.astype('datetime64[ns]')\n        \n    return df #returning the df after the transformations\n\ndef dummies(df, list_cols):\n    for col in list_cols:\n        df_dummies = pd.get_dummies(df[col], drop_first=True, \n                                    prefix=(str(col)))\n        df = pd.concat([df, df_dummies], axis=1)\n        df.drop(col, axis=1, inplace=True)\n        \n    return df","95e31dd7":"df_train = pd.read_csv(\"..\/input\/KaggleV2-May-2016.csv\")","3cc90c84":"knowningData(df_train.drop(['PatientId', 'AppointmentID'], axis=1))","f1a23f8e":"binary_features = ['Scholarship', 'Hipertension', 'Diabetes',\n                   'Alcoholism', 'SMS_received', 'Gender']\n\ntarget = ['No-show']\n\ncategorical = ['Neighbourhood', 'Handcap']\n\nnumerical = ['Age']\n\ndates = ['AppointmentDay', 'ScheduledDay']\n\nIds = ['PatientId', 'AppointmentID']","11b8ce25":"df_train.head()","738f33ad":"## Transforming dates to datetime\ndf_train = date_process(df_train, dates)","dab0fafe":"print(f\"Total of Unique Patients is {df_train.PatientId.nunique()} and Appointments is {df_train.AppointmentID.nunique()}\")","d4ef5196":"plotly_plots(df_train, 'No-show', title='Show and No-Show Distribution',\n             xTitle='No-Show Feature - Target Feature <br>Yes or Not', \n             yTitle='Count')","f04fb144":"plt.figure(figsize=(16,12))\n\nplt.subplot(221)\ng = sns.distplot(df_train['Age'])\ng.set_title(\"Age Count Distribuition\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=12)\n\nplt.subplot(222)\ng1 = plt.scatter(range(df_train.shape[0]), np.sort(df_train.Age.values))\ng1= plt.title(\"Age ECDF Distribuition\", fontsize=18)\ng1 = plt.xlabel(\"Index\")\ng1 = plt.ylabel(\"Age Distribution\", fontsize=15)\n\nplt.suptitle('Patient Age Distribution', fontsize=22)\n\nplt.show()","22e2c555":"print(f\"The min Age in our data is {df_train.Age.min()} and the max Age is {df_train.Age.max()}\")\nprint(f\"Total of Patients with 0 years: {len(df_train[df_train.Age == 0])}\")","6d9e4c77":"quantiles(df_train, ['Age'])","43faaf94":"df_train = df_train[(df_train.Age >= 0 ) & (df_train.Age <= 100)]\nprint(f\"Shape after filtering Data: {df_train.shape}\")","f3ea3bb8":"bin_ranges = [-1, 2, 8, 16, 18, 25, 40, 50, 60, 75]\nbin_names = [\"Baby\", \"Children\", \"Teenager\", 'Young', 'Young-Adult', 'Adult', 'Adult-II', 'Senior', 'Old']\n\ndf_train['age_bin'] = pd.cut(np.array(df_train['Age']),\n                               bins=bin_ranges, labels=bin_names)","eb2a4d75":"# now stack and reset\nshow_prob_age = pd.crosstab(df_train['age_bin'], df_train['No-show'], normalize='index')\nstacked = show_prob_age.unstack().reset_index().rename(columns={0:'value'})\n\nplt.figure(figsize=(16,12))\nplt.subplot(211)\nax1 = sns.countplot(x=\"age_bin\", data=df_train)\nax1.set_title(\"Age Bins Count\", fontsize=22)\nax1.set_xlabel(\"Age Categories\", fontsize=18)\nax1.set_ylabel(\"Count\", fontsize=18)\n\nplt.subplot(212)\nax2 = sns.barplot(x=stacked.age_bin, y=stacked.value, hue=stacked['No-show'])\nax2.set_title(\"Age Bins by Show and No-show Patients\", fontsize=22)\nax2.set_xlabel(\"Age Categories\", fontsize=18)\nax2.set_ylabel(\"Count\", fontsize=18)\nax2.legend(loc='out')\n\nplt.subplots_adjust(hspace = 0.4)\n\nplt.show()","dcb3f1e8":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20,15))\nfig.subplots_adjust(hspace=0.3)\nfig.suptitle('BINARY FEATURES by the TARGET feature', fontsize=22)\n\nfor ax, catplot in zip(axes.flatten(), df_train[binary_features].columns):\n    sns.countplot(x=catplot, data=df_train, hue='No-show', ax=ax)\n    ax.set_title(catplot.upper(), fontsize=18)\n    ax.set_ylabel('Count', fontsize=16)\n    ax.set_xlabel(f'{catplot.upper()} Binary Options', fontsize=15)\n    ax.legend(title='No-show', fontsize=12, )","dae1d3b5":"sms_received = df_train.groupby([df_train['AppointmentDay'].dt.date,\n                                 \"SMS_received\", \"No-show\"])['PatientId'].count().reset_index().rename(columns={'PatientId': \"Total\"})\n","ed368cd7":"\nplt.figure(figsize=(18,16))\n\nplt.subplot(3,1,1)\ng = sns.barplot(x='AppointmentDay', y= 'Total', hue='No-show', data=sms_received[sms_received['SMS_received'] == 0])\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Count of Patients that No Received SMS by No-show feature\", fontsize=22)\ng.set_xlabel(\"Dates\", fontsize=18)\ng.set_ylabel(\"Count\", fontsize=18)\n\nplt.subplot(3,1,2)\ng1 = sns.barplot(x='AppointmentDay', y= 'Total', hue='No-show', data=sms_received[sms_received['SMS_received'] == 1])\ng1.set_xticklabels(g.get_xticklabels(),rotation=45)\ng1.set_title(\"Count of Patients that Received SMS by No-show feature\", fontsize=22)\ng1.set_xlabel(\"Dates\", fontsize=18)\ng1.set_ylabel(\"Count\", fontsize=18)\n\nplt.subplot(3,1,3)\ng2 = sns.boxplot(x='SMS_received', y= 'Age', hue='No-show', data=df_train)\ng2.set_xticklabels(g2.get_xticklabels(),rotation=0)\ng2.set_title(\"Received SMS or Not with Age Distribution by No-show feature\", fontsize=22)\ng2.set_xlabel(\"Receive SMS or NOT\", fontsize=18)\ng2.set_ylabel(\"Age Distribution\", fontsize=18)\n\nplt.subplots_adjust(hspace = 0.6)\n\nplt.show()","0acac288":"less_than_100 = ['MORADA DE CAMBURI', 'PONTAL DE CAMBURI', 'ILHA DO BOI', 'ILHA DO FRADE', \n                 'AEROPORTO', 'ILHAS OCE\u00c2NICAS DE TRINDADE', 'PARQUE INDUSTRIAL']\n\ndf_train.loc[df_train.Neighbourhood.isin(less_than_100), 'Neighbourhood'] = \"OTHERS\"\n\ng = sns.FacetGrid(df_train, col=\"Neighbourhood\", \n                  col_wrap=4, height=3, \n                  hue='No-show')\n\ng.map(quantile_plot, \"Age\").add_legend();\ng.set_titles('{col_name}')\nplt.show()","512868d3":"## Creating a feature that is the difference between the schedule and the appointment \ndf_train['waiting_days'] = (df_train['AppointmentDay'] - df_train['ScheduledDay']).dt.days","7f12a6dc":"print(quantiles(df_train, ['waiting_days']))","90fa9cab":"Schedules = (df_train['ScheduledDay'].dt.date.max() - df_train['ScheduledDay'].dt.date.min()).days\nAppointments = (df_train['AppointmentDay'].dt.date.max() - df_train['AppointmentDay'].dt.date.min()).days\ndiff_days = df_train['waiting_days'].max() - df_train['waiting_days'].min() \n\nprint(f\"Total date window of SCHEDULES is {Schedules} days. \\n\\\n        Min date: {df_train['ScheduledDay'].dt.date.min()} \\n\\\n        Max date: {df_train['ScheduledDay'].dt.date.max()} \\n\")\nprint(\"#\"*50, \"\\n\")\nprint(f\"Total date window of APPOINTMENTS is {Appointments} days. \\n\\\n        Min date: {df_train['AppointmentDay'].dt.date.min()} \\n\\\n        Max date: {df_train['AppointmentDay'].dt.date.max()}\")\nprint(\"#\"*50, \"\\n\")\nprint(f\"Total date window of APPOINTMENTS is {diff_days} days. \\n\\\n        Min date: {df_train['waiting_days'].min()} \\n\\\n        Max date: {df_train['waiting_days'].max()}\")","ff7fc389":"group_temp = df_train[(df_train['waiting_days'] < 70) &\n                      (df_train['waiting_days'] >= -1)].groupby(['waiting_days', 'No-show'])['PatientId'].count() \\\n                        \/ df_train[(df_train['waiting_days'] < 70) & \n                                   (df_train['waiting_days'] >= -1)].groupby(['waiting_days'])['PatientId'].count() \n\n# plt.figure(figsize=(14,6))\n\n# sns.countplot(x='waiting_days', hue='No-show', data=df_train[(df_train['waiting_days'] < 10) & (df_train['waiting_days'] >= -1)]) \nfig = group_temp.unstack().iplot(kind='bar', barmode='stack', asFigure=True,\n                           title='Percent of Show and No-show Patients by Days to Appointment',\n                           xTitle='Days to Appointment', yTitle='Percent Show and No-Show')\n\nfig.layout.xaxis.type = 'category'\niplot(fig)","11dff603":"df_train = df_train[(df_train['waiting_days'] >= -1) & (df_train['waiting_days'] <=100)]","9dce82b5":"df_train.groupby([df_train.ScheduledDay.dt.date, \n                  'No-show' ])['PatientId'].count().unstack().fillna(0).iplot(kind='bar', \n                                                                              barmode='stack',\n                                                                              title='Appointments Dates and the distribution \\\n                                                                              of Show and No-show Patients',\n                                                                              xTitle='Dates',\n                                                                              yTitle='Count '\n                                                                             )","3a33a544":"df_train.Gender = df_train['Gender'].map({\"F\":0, \"M\":1})\ndf_train['No-show'] = df_train['No-show'].map({\"No\":0, \"Yes\":1})\ndf_train = dummies(df_train, categorical)\n\ndf_train.drop(['_weekdayName_AppointmentDay', 'AppointmentID', 'PatientId', 'age_bin',\n                         'ScheduledDay', 'AppointmentDay', '_weekdayName_AppointmentDay',\n                         '_weekdayName_ScheduledDay'], axis=1, inplace=True)","6551f334":"df_train.astype(float).corr()['No-show'].sort_values(ascending=False).head(10)","4feefeb7":"#Finallt, lets look the correlation of df_train\nplt.figure(figsize=(20,15))\nplt.title('Correlation of Features for Train Set')\nsns.heatmap(df_train.astype(float).corr(), vmax=1.0 )\nplt.show()","608076fd":"y_train = df_train['No-show']\nX_train = df_train.drop('No-show', axis=1)","6fd258e3":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.25)","c145c524":"#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding","bb8d6b2d":"clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, \n                                                                       n_estimators=600))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, \n                                 cv=kfold, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+\/- %f)\" % (name, cv_results.mean(),  \n                               cv_results.std())\n    print(msg)\n    \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,6))\nfig.suptitle('Classifier Algorithm Comparison', fontsize=22)\nax = fig.add_subplot(111)\nsns.boxplot(x=names, y=results)\nax.set_xticklabels(names)\nax.set_xlabel(\"Algorithmn\", fontsize=20)\nax.set_ylabel(\"Accuracy of Models\", fontsize=18)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45)\nplt.show()","a4f0a07b":"import scipy as sp \nfrom sklearn.model_selection import RandomizedSearchCV\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial\nfrom sklearn.metrics import confusion_matrix","56be9e42":"from sklearn.model_selection import StratifiedKFold\n\ndef objective(params):\n    params = {\n        'max_depth': int(params['max_depth']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n    }\n    \n    clf = XGBClassifier(\n        n_estimators=600,\n        n_jobs=-1,\n        **params\n    )\n\n    score = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=StratifiedKFold()).mean()\n    print(\"Accuracy {:.8f} params {}\".format(-score, params))\n    return -score\n\nspace = {\n    'max_depth': hp.quniform('max_depth', 2, 8, 1),\n    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n    'reg_lambda': hp.uniform('reg_lambda', 0.7, 1.0),\n    'learning_rate': hp.uniform('learning_rate', 0.05, 0.2),\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n    'gamma': hp.uniform('gamma', 0.0, 0.5),\n}\n\nbest = fmin(fn=objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=50)\n","1373c170":"best['max_depth'] = int(best['max_depth'])\n\nprint(\"BEST PARAMS: \", best)","728279dc":"clf = XGBClassifier(\n    n_estimators=5000,\n    n_jobs=-1,\n    **best\n)","0760190d":"clf.fit(X_train, y_train)","fcbdc3e8":"from sklearn.utils.multiclass import unique_labels\nfrom sklearn.metrics import accuracy_score\n\npred = clf.predict(X_val)","95b09d71":"print(f'Accuracy of our Classifier with best Hyper Parameeters: {round(accuracy_score(y_val, pred, normalize=True),4)}')","27cfe97e":"class_names = df_train['No-show'].unique()\n\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix: \")\n    else:\n        print('Confusion matrix, without normalization: ')\n\n    print(cm)\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\n\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplot_confusion_matrix(y_val, pred, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(y_val, pred, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()\n","95cdd89a":"In fact, the distribution is ","c81f46fb":"Cool!!! My hypothesis is that the many people that received SMS could be to reschedule or cancel the appointment.  <br>\nAlso, we can see that people that no-show in appointments has a slightly different Age mean, that is what we saw in the other chart;\n\nI will explore the binary features below.","5076f357":"## Correlation matrix of all features","25ad5020":"## Ploting the waiting days by percent of Show and No-show Patients\n- As the 99 quantile of our data is 65, I will consider the data between -1 to 70 and show the ratio of the target to each schedule time difference","1bdf8377":"## Knowing our target and their distribution","c14c6de1":"- Cool, we have droped almost 50 rows. <br>\nNow, let's create the age bins","dc475dda":"## Unique Patients and Unique Appointments Total","3bb0ef2c":"## Pipelining the models and ploting the cross validation results","cad05750":"Considering the percentiles I will consider only the Ages between 0 to 100 and set the Age to categories to better analize it","dbb0365c":"Maybe will be interesting to get the data highest than march 2016","c6d05c64":"## Exploring SMS_received","2581b940":"## Seting ages to categories\n- I will use the pd.cut function to binarize our data and create categories to Ages","0f89a0bd":"I Think that -1 could be emergence. ","c04bb56a":"We can't see a great difference between the categories, altough the we can see that teenager to young-adult has a slightly higher ratio 25% of no-show, against the 22 to 14% of another categories. <br>\nThe lower ratios of no-show Patients are the old people and Babys. That make a lot of sense.<br>\nI will explore it further and try to cross this Age categories by some Binary features to see if we can get some insights about the no-show Patients;","7c9ed584":"## Date Columns\n- Cleaning\n- Extracting time features\n- Counting Appointments by date\n- Date Distribution","dce97ae0":"## Age features","92dd3b1d":"## I will keep this analysis and I also will build a classification model. \n## Stay Tuned and votes up the kernel =) ","8907a28e":"## Seting X and y to train the model and spliting into validation set ","972d35de":"# Understanding the No-show Patterns \n\n### Welcome to this kernel. <br>\n\nFirst of all, english isn't my first language, so sorry for any mistake.\n___________________\n## Objectives and Questions: \n\nI will try to understand this data and after some EDA and Data Mining I will build a model to predict the No-show Patients\n\nBased on the dataset description, I will start with some questions that will guide my exploration.<br>\nQuestions like: \n- The data have missing values? \n- How many unique values for each column?\n- What are the principal categories for each column?\n- What's the distribution of the target?\n- Whats the distribution of Ages? \n- We have the same No-show pattern for all age patterns?\n- The Neighbourhood has the same ratio of No-show pattern?\n- What's the range of dates and the distribution of Appointments?\n- And a lot of other questions\n\n\n## NOTE: This kernel is not finished, I am working on it.\nIf you think this kernel is usefull, please <b>votesup<\/b> the kernel ","7b4d4416":"## Importing datasets","f79d2504":"many_appointments_patients = df_train.groupby(['PatientId'])['AppointmentID'].count().sort_values(ascending=False).head(10)\ndf_train[df_train.PatientId.isin(many_appointments_patients.index)]['No-show'].value_counts(normalize=True).plot(kind='bar')","3c2b527f":"- Nice! Apparently the Neighbourhood don't have some influence in Appointments No-show. ","886e538c":"Nice. We can see that in average we have almost 2 visits by each patient, that is exactly what we want understand. We will explore it further later","4d0589c6":"## Range of Dates and the differences between Scheduled and Appointment dates","49b2723d":"## Age Bins by No-show (target) feature","5f639212":"## Getting the model optimization of XGBclassifier to predict No-show Patients\n- Now we will use the hyperopt model optimization to automatize our search and get the optimal parameters","a96786af":"## Semantic lists to better work with each type of cats","0cab591c":"Nice. We can see that we have a high ratio of No-Show patients. It will be very useful to better understand the dataset.<br>\nI will explore the other variables and try to understand the relation between independents and the dependent features\n","74c0e147":"- We can see that just KNN and DecisionTrees hasn't 79%+ of score... <br>\n- I think that 79% of accuracy using the 10 kfold is an excellent baseline. ","3c5a4a57":"## Predicting No-show Patients with the best parameters we found in hyperopt","76fe890a":"Cool. I will explore the date columns and try get some insight about the No-show patterns <br>\n<br>\nBased on the quantiles and the range of days to the appointment, I will filter the data and get the range -1 to 100.\n\nI think that -1 don't make any sense, but I think that it could be emergence appointments and zero is when the Patient Schedule in the same day.","18e2cb42":"We can see that our data has 110527 rows and 14 columns. <br>\nThe data has some category features and we will explore it further later. <br>\n\nThis first view give us a good understanding of the dataset and we can set the name columns to new features, to better filtering ","0f7a4666":"# First look at our data","543f277c":"## Neighbourhood No-show by Age distribution\n- Now we will see the distributions of Age for each Neighbourhood by No-show feature\n- The Neighbourhood with less than 100 entries I will se to \"Others\"","9ad206c8":"## Functions\n- If you want to see all functions that I used in this notebook, click in \"Show Input\" or Fork the Kernel.\n- I will put all functions in the cell below to get a clean notebook.","381aa0c3":"# Start Modelling\n## Preprocessing","f7012a28":"Interesting values. It shows that we have many values in -1... We will explore it further later and maybe filter the data that are outliers or any typo.","c0b9e5af":"## Understanding the date \n- If you want see the code, look on cells above or fork this Kernel ","bf4e2b71":"## Importing librarys","d4c3d7bc":"## Filtering and replacing the data \n- Getting the values with range difference into -1 to 100","0f1c2d67":"Interesting patterns... We can see that almost all binary's features has the same ratio in the True and False groups. <br>\nIn the SMS_Received we can see that the ratio of the True group is very different of the False Group. <br>\nAs ","5629242c":"## Knowing our binary features"}}