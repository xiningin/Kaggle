{"cell_type":{"fdfe64f0":"code","ef154818":"code","932f4f01":"code","a689bc8c":"code","36ee3248":"code","9c64e24e":"code","a9abb4e4":"code","bc1419c8":"code","412b497a":"code","d25b287d":"code","d96a66b1":"code","746ffe58":"code","77a416d7":"code","7dec49a0":"code","77f397f0":"code","db7e75bb":"code","634404e8":"code","d1d30359":"code","72a9b645":"code","e63ddeed":"code","7e07b0e8":"markdown","74c1b84f":"markdown","10dd9ab1":"markdown","27afa74e":"markdown"},"source":{"fdfe64f0":"import numpy as np\nimport pandas as pd","ef154818":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","932f4f01":"train_data[:10]","a689bc8c":"train_data.describe(include='all')","36ee3248":"C1mean = train_data[train_data['Pclass']==1].Fare.mean()\ncls1 = train_data[train_data['Pclass']==1][train_data.Fare > C1mean]['Survived']\nrate_fare = sum(cls1)\/len(cls1)\nprint('% of C1 people who paid less than C1 mean and survived:', rate_fare)","9c64e24e":"C2mean = train_data[train_data['Pclass']==2].Fare.mean()\ncls1 = train_data[train_data['Pclass']==2][train_data.Fare > C2mean]['Survived']\nrate_fare = sum(cls1)\/len(cls1)\nprint('% of C2 people who paid less than C2 mean and survived:', rate_fare)","a9abb4e4":"C3mean = train_data[train_data['Pclass']==3].Fare.mean()\ncls1 = train_data[train_data['Pclass']==3][train_data.Fare > C3mean]['Survived']\nrate_fare = sum(cls1)\/len(cls1)\nprint('% of C3 people who paid less than C3 mean and survived:', rate_fare)","bc1419c8":"women = train_data[train_data['Sex'] == 'female']['Survived']\nrate_women = sum(women)\/len(women)\nprint('% of women who survived:', rate_women)","412b497a":"men = train_data[train_data.Sex == 'male']['Survived']\nrate_men = sum(men)\/len(men)\nprint('% of men who survived:', rate_men)","d25b287d":"fare = train_data[train_data.Fare < 32.204208]['Survived']\nrate_fare = sum(fare)\/len(fare)\nprint('% of people who paid less than 32 and survived:', rate_fare)","d96a66b1":"train_data[['Sex', 'Survived']].groupby(['Sex']).mean()","746ffe58":"train_data[['Pclass', 'Survived']].groupby(['Pclass']).mean()","77a416d7":"# generate correlation data (larger values signify a clear positive\/negative correlation between row\/column labels)\ntrain_data[train_data.Sex == 'male'].corr().Survived.Pclass","7dec49a0":"women_count = 0\nwomen_survived_count = 0\nfor idx, row in train_data.iterrows():\n    if row['Sex'] == 'female':\n        women_count += 1\n        if row['Survived'] == 1:\n            women_survived_count += 1\nwomen_survived_count \/ women_count","77f397f0":"train_data[train_data.Sex == 'male'].corr().Survived.Pclass","db7e75bb":"train_data[train_data.Pclass == 1].Fare.mean()","634404e8":"predictions = []\nfor idx, row in test_data.iterrows():\n    if row['Sex'] == 'female' or (row['Pclass'] == 1 and row['Fare'] > 85):\n        predictions.append(1)\n    else:\n        predictions.append(0)","d1d30359":"assert len(predictions) == len(test_data), 'Number of predictions must match number of test data rows!'","72a9b645":"test_data['Survived'] = predictions","e63ddeed":"test_data[['PassengerId', 'Survived']].to_csv('submission.csv', index=False)","7e07b0e8":"# Basic analysis","74c1b84f":"# Making predictions","10dd9ab1":"# Working with rows manually","27afa74e":"# Loading and examining data"}}