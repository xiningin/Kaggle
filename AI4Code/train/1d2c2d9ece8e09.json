{"cell_type":{"0789c7bb":"code","df64e18b":"code","52b528e7":"code","2d2c087e":"code","42994d71":"code","3c825162":"code","93e17270":"code","a25da316":"code","eb259582":"code","424dbe42":"markdown"},"source":{"0789c7bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","df64e18b":"BATCH_SIZE = 16 \nIMAGE_SIZE=[224, 224]\nAUTO = tf.data.experimental.AUTOTUNE\nNUM_TESTING=7382","52b528e7":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\n\ndef get_test_dataset(ordered=True):\n    dataset = load_dataset(tf.io.gfile.glob('..\/input\/tpu-getting-started' + '\/tfrecords-jpeg-224x224\/test\/*.tfrec'), labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ntesting_dataset=get_test_dataset()","2d2c087e":"# Reading the Sample Submission File\nsub=pd.read_csv(\"..\/input\/tpu-getting-started\/sample_submission.csv\")","42994d71":"testing_ds=testing_dataset.map(lambda image,label:image)","3c825162":"# Loading the Model\nmodel=tf.keras.models.load_model(\"..\/input\/best2model\/model.h5\")","93e17270":"# Computing Predictions\npredictions=model.predict(testing_ds)","a25da316":"predictions=np.argmax(predictions,axis=-1)","eb259582":"# Submitting the Predictions\n# Get image ids from test set and convert to integers\ntest_ds=get_test_dataset()\ntest_ids_ds = test_ds.map(lambda image,label:label).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TESTING))).numpy().astype('U')\nsub['id']=test_ids\nsub['label']=predictions\nsub.to_csv(\"submission.csv\",index=False)","424dbe42":"Preparing Test Data for Inference"}}