{"cell_type":{"906ca156":"code","b889c4db":"code","4acf87bf":"code","ecc47184":"code","dd03c2da":"code","70b2d668":"code","ccbe9c63":"code","93d76101":"code","0006efc4":"code","0fd99cbc":"code","38942ac3":"code","7a18df4e":"code","3105edcd":"code","c219bcbc":"code","4096bac6":"code","d073bcf1":"code","7877e0a1":"code","e10d398d":"code","31052a3d":"code","165c9fe3":"code","388ac3b4":"code","1344b3fc":"code","b2deba4c":"markdown","6cffd356":"markdown","c9cf06e3":"markdown","5ad48199":"markdown","9a5833dd":"markdown","ba6877e5":"markdown","163ade66":"markdown","41870de8":"markdown","1c0448b6":"markdown","25447508":"markdown","d03fd1b5":"markdown","7fd73092":"markdown","7b57c34a":"markdown","3e313b9f":"markdown","195de4b5":"markdown","51c5a76c":"markdown","277fc53c":"markdown","09a2f69a":"markdown","f415f5f4":"markdown","5a77ea6e":"markdown","795a1d41":"markdown","d97a1b81":"markdown","0c594455":"markdown","f36194fb":"markdown","2ae732d2":"markdown","b13569b9":"markdown","ec03befe":"markdown","c9841f38":"markdown","d2beb692":"markdown","e4329eab":"markdown"},"source":{"906ca156":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.arima_process import arma_generate_sample, ArmaProcess\nsns.set_palette([ \"#30a2da\", \"#fc4f30\", \"#e5ae38\", \"#6d904f\", \"#8b8b8b\"])\n\ndf = pd.read_csv('..\/input\/crime.csv')\n%matplotlib inline\ndf.head()","b889c4db":"df.info()","4acf87bf":"df.describe()","ecc47184":"df['Dispatch_Date_Time'] = pd.to_datetime(df['Dispatch_Date_Time'])\ndf.set_index('Dispatch_Date_Time', inplace=True)\ndf.sort_index(inplace=True)","dd03c2da":"df['month'] = df.index.month\ndf['year'] = df.index.year\ndf['day'] = df.index.day\ndf['crimes'] = 1","70b2d668":"# trim the data \ndf = df[df.index < '2016-10-01']","ccbe9c63":"sns.set_style(\"whitegrid\", {'axes.grid' : False})\nfig = plt.figure(figsize=(10,10))\nfig.subplots_adjust(hspace=.5)\nax1 = fig.add_subplot(3,1,1)\nax1.plot(df['crimes'].resample('D').count(),linewidth=1)\nax1.set_title('Total Crimes by Day', fontsize=16)\nax1.set_ylabel('# of Crimes', fontsize=14)\nax1.set_xlabel('Day of Crime', fontsize=14)\nax1.tick_params(axis='both', which='major', labelsize=14)\n\nax2 = fig.add_subplot(3,1,2, sharex=ax1)\nax2.plot(df['crimes'].resample('M').count(),linewidth=1)\nax2.set_title('Total Crimes by Month', fontsize=16)\nax2.set_ylabel('# of Crimes', fontsize=14)\nax2.set_xlabel('Month of Crime', fontsize=14)\nax2.tick_params(axis='both', which='major', labelsize=14)\n\nax3  = fig.add_subplot(3,1,3, sharex=ax1)\nax3.plot(df['crimes'].resample('A').count(),linewidth=1)\nax3.set_title('Total Crimes by Year', fontsize=16)\nax3.set_ylabel('# of Crimes', fontsize=14)\nax3.set_xlabel('Year of Crime', fontsize=14)\nax3.tick_params(axis='both', which='major', labelsize=14)","93d76101":"non_violent_df = df[df['UCR_General'] > 800]\n\nfig = plt.figure(figsize=(10,10))\nfig.subplots_adjust(hspace=.5)\nax1 = fig.add_subplot(3,1,1)\nax1.plot(non_violent_df['crimes'].resample('D').count(),linewidth=1)\nax1.set_title('Non-Violent Crimes by Day', fontsize=16)\nax1.set_ylabel('# of Crimes', fontsize=14)\nax1.set_xlabel('Day of Crime', fontsize=14)\nax1.tick_params(axis='both', which='major', labelsize=14)\n\nax2 = fig.add_subplot(3,1,2, sharex=ax1)\nax2.plot(non_violent_df['crimes'].resample('M').count(),linewidth=1)\nax2.set_title('Non-Violent Crimes by Month', fontsize=16)\nax2.set_ylabel('# of Crimes', fontsize=14)\nax2.set_xlabel('Month of Crime', fontsize=14)\nax2.tick_params(axis='both', which='major', labelsize=14)\n\nax3  = fig.add_subplot(3,1,3, sharex=ax1)\nax3.plot(non_violent_df['crimes'].resample('A').count(),linewidth=1)\nax3.set_title('Non-Violent Crimes by Year', fontsize=16)\nax3.set_ylabel('# of Crimes', fontsize=14)\nax3.set_xlabel('Year of Crime', fontsize=14)","0006efc4":"violent_df = df[df['UCR_General'] < 800]\n\nfig = plt.figure(figsize=(10,10))\nfig.subplots_adjust(hspace=.5)\nax1 = fig.add_subplot(3,1,1)\nax1.plot(violent_df['crimes'].resample('D').count(),linewidth=1)\nax1.set_title('Violent Crimes by Day', fontsize=16)\nax1.set_ylabel('# of Crimes', fontsize=14)\nax1.set_xlabel('Day of Crime', fontsize=14)\nax1.tick_params(axis='both', which='major', labelsize=14)\n\nax2 = fig.add_subplot(3,1,2, sharex=ax1)\nax2.plot(violent_df['crimes'].resample('M').count(),linewidth=1)\nax2.set_title('Violent Crimes by Month', fontsize=16)\nax2.set_ylabel('# of Crimes', fontsize=14)\nax2.set_xlabel('Month of Crime', fontsize=14)\nax2.tick_params(axis='both', which='major', labelsize=14)\n\nax3  = fig.add_subplot(3,1,3, sharex=ax1)\nax3.plot(violent_df['crimes'].resample('A').count(),linewidth=1)\nax3.set_title('Violent Crimes by Year', fontsize=16)\nax3.set_ylabel('# of Crimes', fontsize=14)\nax3.set_xlabel('Year of Crime', fontsize=14)","0fd99cbc":"monthly_violent_df = violent_df['crimes'].resample('M').count().to_frame()","38942ac3":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(monthly_violent_df)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nfig = plt.figure(figsize=(10,10))\nfig.subplots_adjust(hspace=.5)\nax1 = fig.add_subplot(4,1,1)\nax1.plot(monthly_violent_df,linewidth=1)\nax1.set_title('Original', fontsize=14)\n\nax2 = fig.add_subplot(4,1,2, sharex=ax1)\nax2.plot(trend,linewidth=1)\nax2.set_title('Trend', fontsize=14)\n\nax3  = fig.add_subplot(4,1,3, sharex=ax1)\nax3.plot(seasonal,linewidth=1)\nax3.set_title('Seasonal', fontsize=14)\n\nax4  = fig.add_subplot(4,1,4, sharex=ax1)\nax4.plot(residual,linewidth=1)\nax4.set_title('Residual', fontsize=14)","7a18df4e":"from statsmodels.tsa.stattools import adfuller\ndef is_stationary(series):\n    \n    \n    #Determing rolling statistics\n    rolmean = series.rolling(window=12, center = False).mean()\n    rolstd = series.rolling(window=12, center = False).std()\n\n    #Plot rolling statistics:\n    fig = plt.figure(figsize=(10,5))\n    orig = plt.plot(series,label='Original')\n    mean = plt.plot(rolmean, label= 'Rolling Mean')\n    std = plt.plot(rolstd, label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(series, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,crimes in dftest[4].items():\n        dfoutput['Critical value (%s)'%key] = crimes\n    print (dfoutput)","3105edcd":"monthly_violent_df['log_crimes'] = np.log(monthly_violent_df.crimes)\nmonthly_violent_df['seasonal'] = seasonal\nmonthly_violent_df['seasonal_decomp'] = monthly_violent_df['crimes'] - monthly_violent_df['seasonal']\nmonthly_violent_df['seasonal_decomp_diff'] = monthly_violent_df.seasonal_decomp.diff(1)\nmonthly_violent_df['monthly_diff'] = monthly_violent_df.crimes.diff(1)\nmonthly_violent_df['seasonal_diff'] = monthly_violent_df.crimes.diff(12)\nmonthly_violent_df['seasonal_monthly_diff'] = monthly_violent_df.monthly_diff - monthly_violent_df.monthly_diff.diff(12)","c219bcbc":"is_stationary(monthly_violent_df.crimes)","4096bac6":"is_stationary(monthly_violent_df.monthly_diff.dropna())","d073bcf1":"is_stationary(monthly_violent_df.seasonal_diff.dropna())","7877e0a1":"is_stationary(monthly_violent_df.seasonal_monthly_diff.dropna())","e10d398d":"is_stationary(monthly_violent_df.seasonal_decomp_diff.dropna())","31052a3d":"fig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(monthly_violent_df.seasonal_decomp_diff.dropna().iloc[13:], lags=100, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(monthly_violent_df.seasonal_decomp_diff.dropna().iloc[13:], lags=100, ax=ax2)","165c9fe3":"model = ARIMA(monthly_violent_df.seasonal_decomp_diff.dropna(),order=(0,0,1))\nresults = model.fit()\n\nprint (results.summary())\n\nmonthly_violent_df['forecast'] = pd.Series(monthly_violent_df.crimes.ix[0], index = monthly_violent_df.index) \\\n                                .add(results.fittedvalues.cumsum()).add(monthly_violent_df.seasonal)\nfig = plt.figure(figsize=(10,5))\nplt.plot(monthly_violent_df.crimes, label = 'Actual')\nplt.plot(monthly_violent_df.forecast,linestyle=\"--\", label='Fitted')\nplt.legend(loc='best')\nplt.title('MAPE: %f' % (100*np.mean(np.abs(monthly_violent_df.forecast-monthly_violent_df.crimes)\/monthly_violent_df.crimes)), fontsize=16)\nplt.ylabel('# of Crimes', fontsize=14)\nplt.xlabel('Year of Crime', fontsize=14)","388ac3b4":"from statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(monthly_violent_df.seasonal_decomp_diff.dropna(),order=(1,0,0))\nresults = model.fit()\n\nprint (results.summary())\n\nmonthly_violent_df['forecast'] = pd.Series(monthly_violent_df.crimes.ix[0], index = monthly_violent_df.index) \\\n                                .add(results.fittedvalues.cumsum()).add(monthly_violent_df.seasonal)\nfig = plt.figure(figsize=(10,5))\nplt.plot(monthly_violent_df.crimes, label = 'Actual')\nplt.plot(monthly_violent_df.forecast,linestyle=\"--\", label='Fitted')\nplt.legend(loc='best')\nplt.title('MAPE: %f' % (100*np.mean(np.abs(monthly_violent_df.forecast-monthly_violent_df.crimes)\/monthly_violent_df.crimes)), fontsize=16)\nplt.ylabel('# of Crimes', fontsize=14)\nplt.xlabel('Year of Crime', fontsize=14)","1344b3fc":"model = ARIMA(monthly_violent_df.seasonal_decomp_diff.dropna(),order=(1,0,1))\n\nresults = model.fit(dips=-1)\n\nprint (results.summary())\n\nmonthly_violent_df['forecast'] = pd.Series(monthly_violent_df.crimes.ix[0], index = monthly_violent_df.index) \\\n                                .add(results.fittedvalues.cumsum()).add(monthly_violent_df.seasonal)\n    \nfig = plt.figure(figsize=(10,5))\nplt.plot(monthly_violent_df.crimes, label = 'Actual')\nplt.plot(monthly_violent_df.forecast,linestyle=\"--\", label='Fitted')\nplt.legend(loc='best')\nplt.title('MAPE: %f' % (100*np.mean(np.abs(monthly_violent_df.forecast-monthly_violent_df.crimes)\/monthly_violent_df.crimes)), fontsize=16)\nplt.ylabel('# of Crimes', fontsize=14)\nplt.xlabel('Year of Crime', fontsize=14)","b2deba4c":"### Let's account for seasonality from our seasonal decompisition and use a difference in time of 1","6cffd356":"# Exploratory Data Analysis\n### Look at all crimes by day,month,year","c9cf06e3":"### First lets test the original data","5ad48199":"### Look at violent crimes by day, month, year","9a5833dd":"# Step 2: Make the Data Stationary\n##### SOURCE: https:\/\/www.analyticsvidhya.com\/blog\/2015\/12\/complete-tutorial-time-series-modeling\/\n\n#####  There are three basic criterion for a series to be classified as stationary series :\n\n1. The mean of the series should not be a function of time rather should be a constant. The image below has the left hand graph satisfying the condition whereas the graph in red has a time dependent mean.\n\n2. The variance of the series should not a be a function of time. This property is known as homoscedasticity. Following graph depicts what is and what is not a stationary series. (Notice the varying spread of distribution in the right hand graph)\n\n3. The covariance of the i th term and the (i + m) th term should not be a function of time. In the following graph, you will notice the spread becomes closer as the time increases. Hence, the covariance is not constant with time for the \u2018red series\u2019.\n\n### Augmented Dickey-Fuller Test  of Stationarity\nWe can use this statistical test to determine if the data is stationary\n### Null hypothesis - a unit root is present in a time series sample\n### Alternative hypothesis - the data is stationary","ba6877e5":"### Lets combine a seasonal lag with a monthly lag","163ade66":"- MAPE = 5.56%  This fit looks great. Let's see if a combined model can beat it","41870de8":"## AR(1) Model","1c0448b6":"#### This looks good, but worse than just a monthly lag","25447508":"#### This looks much better! Our data is now below our 1% critical value. Let's see if we can further improve","d03fd1b5":"# Problem statement: \nUsing the open source Philidelphia Crime dataset, use historical data from 2006-2016 to make predictions for the number of monthly violent crimes that will occur in future months. We will use exploratory data analysis techniques to answer questions and make assumptions about the data. Then we will use different time series models such as Autoregressive Integrated Moving Average (ARIMA) to make predictions on future data.\n## Assumptions\n    \u2022 There are significant trends in the data\n    \u2022 Seasonality largely effects the data\n    \u2022 The data is not stationary\n    \u2022 Potentail outliers will need to be investigated\/removed\n    \n## Hypothesis\nSeasonality and overall trends greatly effect the number of violent crimes in Philidelphia. In order to make accurate predictions, we will need to transform the data to make it stationary.\n\n## Success Metrics\nWe will evalutate our model with the metrics Mean Absolute Percentage Error(MAPE)\n\nLets aim for a model with a MAPE < 10%\n\n   - Outcome Variable: number of violent crimes\n   -   Predictors: Time\n   - Relevant Timeframe: January 2006 - Present\n","7fd73092":"## Look at Data Types & get Summary Statistics","7b57c34a":"## MA(1) Model","3e313b9f":"### The ACF and PACF graphs look great and show that we did a nice job of making the data stationary. Let's use these results to fit our ARIMA model","195de4b5":"### Violent crimes seem to have to most notible time series. Let focus on this subset for now","51c5a76c":"- p \u2013 The lag value where the PACF chart crosses the upper confidence interval for the first time.  p=1.\n- q \u2013 The lag value where the ACF chart crosses the upper confidence interval for the first time.  q=1.","277fc53c":"## Combined Model- AR(1) & MA(1)","09a2f69a":"### Trends - An almost linear decline in the number of monthly violent crimes\n### Seasonality - It looks like there correlation with seasons with a peak in the summer months and a trough in the winter months\n### Residuals - This mostly looks like noise, however we can improve on this,","f415f5f4":"# Step 3: Find optimal parameters for ARIMA\n### Goal: Determine optimal number or AR terms (p), MA terms (q), and Differences (d)\n### Plot Autocorrelation Function (ACF) and Partial Autocorrelation Functio (PACF)","5a77ea6e":"### Lets account for seasonality by using a difference in time of 12","795a1d41":"#### The Dickey-Fuller test statistic is significantly lower than the 1% critical value.  (-9.567 < -3.48)\n#### This data is very close to stationary. Time for some modeling!","d97a1b81":"### Lets try the data with a difference in time of 1","0c594455":"- Much worse than our previous 2 models. Lets scratch this one","f36194fb":"# Step 1: Visualize the time series\n## Seasonal Decompisition\n### Trends - What is the overall trend in the data?\n### Seasonality - How does crimes fluctuate between seasons?\n### Residuals - When removing trends and seasonaility what does the data look like?","2ae732d2":"- MAPE = 8.96% Lets see if we can improve","b13569b9":"#### Still worse than just a monthly lag.","ec03befe":"## Get DateTime index","c9841f38":"### Look at non-violent crimes by day, month, year","d2beb692":"# Step 4: Fit an ARIMA model\n### Goal: Using the results from our ACF\/PACF plots, fit an ARIMA model. Determine the optimal model by measuring Mean Absolue Percentage Error","e4329eab":"#### Unsurprisingly the original data fails the augmeneted Dickey-Fuller Test (T-Statistic > Critical value 1% )"}}