{"cell_type":{"6f5c802b":"code","7f39a8db":"code","479fc5a0":"code","17a5dfbe":"code","0f9c979d":"code","479c55c9":"code","5c5fd64d":"code","2192deb5":"code","11a77f0c":"code","7a57b2ee":"code","c883cf05":"code","5e737536":"code","bc7a9e7c":"markdown","c6278c67":"markdown"},"source":{"6f5c802b":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb","7f39a8db":"train = pd.read_csv(\"..\/input\/lish-moa\/train_features.csv\")\ntest = pd.read_csv(\"..\/input\/lish-moa\/test_features.csv\")\ntrain_targets_scored = pd.read_csv(\"..\/input\/lish-moa\/train_targets_scored.csv\")\ntrain_targets_nonscored = pd.read_csv(\"..\/input\/lish-moa\/train_targets_nonscored.csv\")\nsub = pd.read_csv(\"..\/input\/lish-moa\/sample_submission.csv\")","479fc5a0":"def label_encoding(train: pd.DataFrame, test: pd.DataFrame, encode_cols):\n    n_train = len(train)\n    train = pd.concat([train, test], sort=False).reset_index(drop=True)\n    for f in encode_cols:\n        try:\n            lbl = preprocessing.LabelEncoder()\n            train[f] = lbl.fit_transform(list(train[f].values))\n        except:\n            print(f)\n    test = train[n_train:].reset_index(drop=True)\n    train = train[:n_train]\n    return train, test","17a5dfbe":"def run_lgbm(target_col: str):\n    \n    X_train = train.drop([\"sig_id\"], axis=1)\n    y_train = train_targets_scored[target_col]\n    X_test = test.drop([\"sig_id\"], axis=1)\n\n    y_preds = []\n    models = []\n    oof_train = np.zeros((len(X_train),))\n\n    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n        X_tr = X_train.loc[train_index, :]\n        X_val = X_train.loc[valid_index, :]\n        y_tr = y_train[train_index]\n        y_val = y_train[valid_index]\n\n        lgb_train = lgb.Dataset(X_tr,\n                                y_tr,\n                                categorical_feature=categorical_cols)\n\n        lgb_eval = lgb.Dataset(X_val,\n                               y_val,\n                               reference=lgb_train,\n                               categorical_feature=categorical_cols)\n\n        model = lgb.train(params,\n                          lgb_train,\n                          valid_sets=[lgb_train, lgb_eval],\n                          verbose_eval=10,\n                          num_boost_round=1000,\n                          early_stopping_rounds=10)\n\n\n        oof_train[valid_index] = model.predict(X_val,\n                                               num_iteration=model.best_iteration)\n        y_pred = model.predict(X_test,\n                               num_iteration=model.best_iteration)\n\n        y_preds.append(y_pred)\n        models.append(model)\n\n    return oof_train, sum(y_preds) \/ len(y_preds)","0f9c979d":"train.head()","479c55c9":"train.select_dtypes(include=['object']).columns","5c5fd64d":"train, test = label_encoding(train, test, ['cp_type', 'cp_dose'])","2192deb5":"train.head()","11a77f0c":"cv = KFold(n_splits=5, shuffle=True, random_state=0)\n\nparams = {\n    'num_leaves': 24,\n    'max_depth': 5,\n    'objective': 'binary',\n    'learning_rate': 0.01\n}\n\ncategorical_cols = ['cp_type', 'cp_dose']\noof = train_targets_scored.copy()","7a57b2ee":"for target_col in train_targets_scored.columns:\n    if target_col != \"sig_id\":\n        _oof, _preds = run_lgbm(target_col)\n        oof[target_col] = _oof\n        sub[target_col] = _preds","c883cf05":"scores = []\nfor target_col in train_targets_scored.columns:\n    if target_col != \"sig_id\":\n        scores.append(log_loss(train_targets_scored[target_col], oof[target_col]))\nprint(np.mean(scores))","5e737536":"sub.to_csv('submission.csv', index=False)","bc7a9e7c":"# Modeling","c6278c67":"# Preprocessing\n\nWe have to convert some categorical features into numbers in train and test. We can identify categorical features by `pd.DataFrame.select_dtypes`."}}