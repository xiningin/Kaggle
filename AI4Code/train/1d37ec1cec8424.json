{"cell_type":{"53e27174":"code","dcee759f":"code","03cfd82b":"code","5e42f01a":"code","69ec383f":"code","e04b7e73":"code","1615fbb3":"code","df2d528b":"code","d268f6a0":"code","1ab5f9af":"markdown","1280d2eb":"markdown","6718fb48":"markdown","037dd15e":"markdown","d3e65f39":"markdown","3461200a":"markdown","c230ff24":"markdown","392a6e17":"markdown","3d9ba5fb":"markdown"},"source":{"53e27174":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pylab import savefig\nfrom sklearn.ensemble import IsolationForest\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Generating data ----\nimport numpy as np, pandas as pd, os\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.svm import NuSVC\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm_notebook\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import KMeans","dcee759f":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","03cfd82b":"from sklearn.covariance import GraphicalLasso\nfrom sklearn.cluster import KMeans\nfrom sklearn.covariance import ShrunkCovariance,EmpiricalCovariance,LedoitWolf\ndef get_mean_cov(x,y):\n    model =  LedoitWolf()\n    ones = (y==1).astype(bool)\n    x2 = x[ones]\n    #K=4\n    kmeans = KMeans(4, random_state=125,n_jobs=4).fit(x2)\n    kmeans_predictions = (kmeans.predict(x2))\n    #Calculating the precision and the location of cluster 0 of the 1 labels.\n    onesb = (kmeans_predictions==0).astype(bool)\n    x21 = x2[onesb]\n    model.fit(x21)\n    p1 = model.precision_\n    m1 = model.location_\n    #Calculating the precision and the location of cluster 1 of the 1 labels.\n    onesb = (kmeans_predictions==1).astype(bool)\n    x22 = x2[onesb]\n    model.fit(x22)\n    p2 = model.precision_\n    m2 = model.location_\n    #Calculating the precision and the location of cluster 2 of the 1 labels.\n    onesb = (kmeans_predictions==2).astype(bool)\n    x23 = x2[onesb]\n    model.fit(x23)\n    p3 = model.precision_\n    m3 = model.location_\n    #Calculating the precision and the location of cluster 3 of the 1 labels.\n    onesb = (kmeans_predictions==3).astype(bool)\n    x24 = x2[onesb]\n    model.fit(x24)\n    p4 = model.precision_\n    m4 = model.location_\n    \n  \n    \n    onesb = (y==0).astype(bool)\n    x2b = x[onesb]\n    #K for labels 0 is 4 too\n    kmeans = KMeans(4, random_state=125,n_jobs=4).fit(x2b)\n    kmeans_predictions = (kmeans.predict(x2b))\n    #Calculating the precision and the location of cluster 0 of the 0 labels.\n    onesb = (kmeans_predictions==0).astype(bool)\n    x2b1 = x2b[onesb]\n    model.fit(x2b1)\n    p5 = model.precision_\n    m5 = model.location_\n    #Calculating the precision and the location of cluster 1 of the 0 labels.    \n    onesb = (kmeans_predictions==1).astype(bool)\n    x2b2 = x2b[onesb]\n    model.fit(x2b2)\n    p6 = model.precision_\n    m6 = model.location_\n    #Calculating the precision and the location of cluster 2 of the 0 labels.\n    onesb = (kmeans_predictions==2).astype(bool)\n    x2b3 = x2b[onesb]\n    model.fit(x2b3)\n    p7 = model.precision_\n    m7 = model.location_\n    #Calculating the precision and the location of cluster 3 of the 0 labels.\n    onesb = (kmeans_predictions==3).astype(bool)\n    x2b4 = x2b[onesb]\n    model.fit(x2b4)\n    p8 = model.precision_\n    m8 = model.location_\n\n    #Stacking of all the means and covariances  \n    ms = np.stack([m1,m2,m3,m4,m5,m6,m7,m8])\n    ps = np.stack([p1,p2,p3,p4,p5,p6,p7,p8])\n    return ms,ps","5e42f01a":"#SELECTING COLUMNS\ncols = [c for c in train.columns if c not in ['id', 'target']]\ncols.remove('wheezy-copper-turtle-magic')\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor i in tqdm_notebook(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=2).fit(train2[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n    \n    # STRATIFIED K-FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3, train2['target']):\n        \n\n        #Initialization of the mean and covariance of each cluster within labels 0 and 1 (4clusters for labels 1 and 4clusters for labels 0 )\n        ms, ps = get_mean_cov(train3[train_index,:],train2.loc[train_index]['target'].values)\n        #Gaussian Mixture Modelling \n        gm = GaussianMixture(n_components=8, init_params='random', covariance_type='full', tol=0.001,reg_covar=1, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n        #Since learning with GMM is unsupervised we will fit the train+validation+test \n        gm.fit(np.concatenate([train3,test3],axis = 0))\n        #The predict_proba will return (n_clusters=4+4=8 ,  num_samples)\n        #We will predict the probabilty of being the class 1 and that represent the sum of the probabilities of the 4 first columns and that explains the [:,:4].sum(axis=1)\n        oof[idx1[test_index]] = gm.predict_proba(train3[test_index,:])[:,:4].sum(axis=1)\n        preds[idx2] += gm.predict_proba(test3)[:,:4].sum(axis=1) \/ skf.n_splits\n    auc = roc_auc_score(train2['target'],oof[idx1])\n    print('GMM scores CV =',round(auc,5))\n        \n\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof)\nprint('GMM scores CV =',round(auc,5))","69ec383f":"test['target'] = preds\noof_final6 = np.zeros(len(train))\nfinal_preds = np.zeros(len(test))\n\n# BUILD 512 SEPARATE MODELS\nfor k in tqdm_notebook(range(512)):\n    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==k] \n    train2p = train2.copy(); idx1 = train2.index \n    test2 = test[test['wheezy-copper-turtle-magic']==k]\n    \n    # ADD PSEUDO LABELED DATA\n    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n    train2p = pd.concat([train2p,test2p],axis=0)\n    train2p.reset_index(drop=True,inplace=True)\n    \n    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n    sel = VarianceThreshold(threshold=2).fit(train2p[cols])     \n    train3p = sel.transform(train2p[cols])\n    train3 = sel.transform(train2[cols])\n    test3 = sel.transform(test2[cols])\n        \n    # STRATIFIED K FOLD\n    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n    for train_index, test_index in skf.split(train3p, train2p['target']):\n        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n        \n        # MODEL AND PREDICT WITH GMM\n        ms, ps = get_mean_cov(train3p[train_index,:],train2p.loc[train_index]['target'].values)\n        \n        gm = GaussianMixture(n_components=8, init_params='random', covariance_type='full', \n                             tol=0.001,reg_covar=1, max_iter=100, n_init=1,means_init=ms, precisions_init=ps)\n        \n        gm.fit(np.concatenate([train3p,test3],axis = 0))\n        oof_final6[idx1[test_index3]] = gm.predict_proba(train3[test_index3,:])[:,:4].sum(axis=1)\n        final_preds[test2.index] += gm.predict_proba(test3)[:,:4].sum(axis=1) \/ skf.n_splits\n       \n    #if k%64==0: print(k)\n        \n# PRINT CV AUC\nauc = roc_auc_score(train['target'],oof_final6)\nprint('Pseudo Labeled GMM scores CV =',round(auc,5))","e04b7e73":"auc = roc_auc_score(train['target'],oof_final6+oof)\nprint('Pseudo Labeled GMM scores CV =',round(auc,5))","1615fbb3":"sample = pd.read_csv(\"..\/input\/sample_submission.csv\")","df2d528b":"sample.target = (final_preds+preds)\/2\nsample.to_csv(\"submission.csv\",index=False)","d268f6a0":"sample.head()","1ab5f9af":"We averaged the prediction with  a simple GMM and the prediction with GMM using pseudo labeling ","1280d2eb":"# Ensembling ","6718fb48":"We used the pseudo labeling  proposed by [chris](https:\/\/www.kaggle.com\/cdeotte) in [this](https:\/\/www.kaggle.com\/cdeotte\/pseudo-labeling-qda-0-969) link","037dd15e":"## pseudolabeling","d3e65f39":"Since the target are divided into 2 labels 0 and 1 and made from n gaussians. We tried to cluster each label (0 and 1) to k clusters and we tuned this param k depending on the validation score. We calculate the precision and location for each cluster to initialize gaussian mixture model.\nThe k we used here is 4.","3461200a":"## Gaussian mixture model","c230ff24":"# The model","392a6e17":"## Kmeans to initialize gaussian mixture model","3d9ba5fb":"# PRIIVATE LB 0.97564 33th place"}}