{"cell_type":{"3f968e76":"code","9768ff1f":"code","2e002246":"code","438d269f":"code","faffa137":"code","447ec876":"code","c65cb1f2":"code","9dc631ec":"code","9ee4e9d5":"code","63b24b08":"code","cf110817":"code","b3d828cf":"code","070bd4ac":"code","c39dccfd":"code","d76ad605":"code","722869a5":"code","d7e326fc":"code","c10e477c":"code","ee8d3125":"code","90fb91de":"code","09b2aeb1":"code","dd8e5e07":"code","7789d0a0":"code","a582ce59":"code","a4d96339":"code","2cabefcf":"code","76e59299":"code","2f274822":"code","a0f91eb2":"code","bee4fb06":"code","f4a2ccc9":"code","a20fe4f2":"code","7c1d5693":"code","a5762024":"code","8b94ea32":"code","f58465d1":"code","048644b6":"code","cde8dd18":"code","b59ef4f0":"markdown","dde97161":"markdown","e6a1fe5f":"markdown","9eb43e10":"markdown","1d9cb361":"markdown","505c4ae6":"markdown","893e3568":"markdown","f7077905":"markdown"},"source":{"3f968e76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9768ff1f":"import warnings\nwarnings.filterwarnings(\"ignore\")\n#Visualisation\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#nlp\nimport nltk\nimport re\nfrom nltk.corpus import stopwords \nstop_words =set (stopwords.words('english'))\nfrom textblob import TextBlob\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\n#ml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score, classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold","2e002246":"def text_process(data):\n    str1=str(data)\n    str1 = re.sub(\" \\d+\", \"number\", str1) #Digits Replacement\n    str1 = re.sub('[^\\w\\s]','', str1)  # Punctuation Removal\n    words = re.split(\"\\n|,|;| \",str1) \n    words = [item.lower() for item in words]\n    Keys=[word_text for word_text in words if word_text not in stop_words] \n    Keys = ' '.join(Keys).lower()\n    return Keys","438d269f":"def wordcloud(text):\n    stopwords = set(STOPWORDS)\n    #stopwords.update(['NaN'])\n    wordcloud = WordCloud(\n                              background_color='black',\n                              stopwords=stopwords,\n                              max_words=300,\n                              max_font_size=30, \n                              random_state=42\n                             ).generate(\" \".join(text))\n\n    print(wordcloud)\n    fig = plt.figure(1)\n    plt.rcParams['figure.figsize']=(20,20)\n    plt.imshow(wordcloud)\n    plt.axis('off')","faffa137":"def lemmatize_text(text):\n    # Instantiate the Word tokenizer & Word lemmatizer\n    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n    lemmatizer = nltk.stem.WordNetLemmatizer()\n    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]","447ec876":"def sentiment_analyser(text):\n    return text.apply(lambda Text: pd.Series(TextBlob(Text).sentiment.polarity))\n\n","c65cb1f2":"train = pd.read_csv(\"\/kaggle\/input\/nikkiai-np-challenge\/train (3) (1) (3) (2).csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nikkiai-np-challenge\/test (3) (1) (3) (2).csv\")","9dc631ec":"train.head().T","9ee4e9d5":"train.info()","63b24b08":"train['review']=train['Review Text'].combine_first(train['Review Title'])\ntrain['review']","cf110817":"train.sample(10).T","b3d828cf":"train['review']=train['review'].apply(text_process)\nplt.rcParams['figure.figsize']=(20,20)\nwordcloud(train['review'])\ntrain['lem_review']=train['review'].apply(lemmatize_text)","070bd4ac":"# Applying function to reviews\ntrain['Polarity'] = sentiment_analyser(train['review'])","c39dccfd":"train[\"review_len\"]= train['review'].apply(len)","d76ad605":"g = sns.FacetGrid(train,col='Star Rating')\ng.map(plt.hist,'review_len')","722869a5":"plt.rcParams['figure.figsize']=(10,10)\nsns.boxplot(y='review_len', data=train, x='Star Rating')","d7e326fc":"g = sns.FacetGrid(train,col='Star Rating')\ng.map(plt.hist,'Polarity')","c10e477c":"train['Star Rating'].value_counts()","ee8d3125":"rating_df=train.groupby('Star Rating')","90fb91de":"rating_df['review_len'].describe()","09b2aeb1":"sns.heatmap(train.corr(), cmap='coolwarm', annot=True)","dd8e5e07":"train.drop(labels='App Version Name',axis=1,inplace=True)","7789d0a0":"train.sample(10).T # data preview brfore vectorization","a582ce59":"cvec = CountVectorizer(min_df=.005, max_df=.9, ngram_range=(1,2), tokenizer=lambda doc: doc, lowercase=False)\ncvec.fit(train['lem_review'])","a4d96339":"pd.DataFrame(cvec.vocabulary_.items(),\n             cvec.vocabulary_.values(),columns=['Word','Occurrence']).sort_values(by='Occurrence', ascending=False).head(25)","2cabefcf":"tfidf = TfidfVectorizer(token_pattern='(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2),max_features=200)\n\nfeatures = tfidf.fit_transform(train['review']).toarray()\nprint(features.shape)\ndf2 = pd.DataFrame(features, columns=tfidf.get_feature_names())\n\n","76e59299":"\"\"\"Col_sum=df2.apply(lambda r: df2.sum()[r.name]) #Text Feature\nCol_Max=Col_sum.sort_values().tail(500)\nText_Features=Col_Max.index\nprint(Text_Features)\"\"\"","2f274822":"df_Model = pd.concat([train,df2], axis=1)","a0f91eb2":"drop_col=['id', 'Review Text', 'Review Title', 'Star Rating',\n       'review', 'lem_review']\nX=df_Model.drop(labels=drop_col,axis=1,inplace=False)\ny=df_Model['Star Rating']\nX['App Version Code'][X[\"App Version Code\"].isna()]=0","bee4fb06":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42,stratify=y)","f4a2ccc9":"clf = RandomForestClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [25], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy'],\n              'max_depth': [15], \n              #'min_samples_split': [5,10,15],\n              #'min_samples_leaf': [20,100],\n              'random_state' : [25]\n             }\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X_train, y_train)","a20fe4f2":"\npredictions = clf.predict(X_test)\nprint(predictions)\nprint(classification_report(y_test, predictions))","7c1d5693":"from sklearn.model_selection import cross_val_score\ncross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')","a5762024":"#Quick Check Model\ndef Model(Model,train_x=X_train,val_x=X_test,train_y=y_train,val_y=y_test):\n    clf= Model()\n    clf.fit(train_x,train_y)\n    print(\"Model:\",Model,\"\\n\",classification_report(val_y,clf.predict(val_x)))","8b94ea32":"test.head().T","f58465d1":"test['review']=test['Review Text'].combine_first(test['Review Title'])\ntest['review']=test['review'].apply(text_process)\ntest['lem_review']=test['review'].apply(lemmatize_text)\ntest['Polarity'] = sentiment_analyser(test['review'])\ntest[\"review_len\"]= test['review'].apply(len)","048644b6":"features1 = tfidf.transform(test['review']).toarray()\ntest_tfidf = pd.DataFrame(features1, columns=tfidf.get_feature_names())\ndf_test = pd.concat([test,test_tfidf], axis=1)\ndf_test['App Version Code'][df_test[\"App Version Code\"].isna()] = 0\nScore_X=df_test.drop(['id', 'Review Text', 'Review Title','review', 'lem_review','App Version Name'],axis=1)\nScore_X['App Version Code'][Score_X['App Version Code'].isna()] = 0","cde8dd18":"prediction= pd.DataFrame(clf.predict(Score_X))\nresult=pd.concat([test['id'],prediction],axis=1)\nresult.to_csv(\"predictions.csv\",index=False)\n","b59ef4f0":"* Not of quality as observed in wordcloud. TF-IDF would be better option.","dde97161":"* App Version code and Name are interrelated, droping App Version Name.\n* Secondly,Polarity has strong correlation with Rating. \n* With the quality of data in hand, App Version Code column can be dropped.But there's a high probabily that a particular version have bugs, because of which customers displayed dissatisfaction. 10 percent seems to justify the hypothesis.","e6a1fe5f":"Hypothesis: Higher the dissatisfaction, more people like to express. Conclusion- True.","9eb43e10":"* Rating 5 and 1 in 5:3 ratio, not a case of imbalanced dataset. Rating 2,3,4 volume is comparititavly low.","1d9cb361":"* Strong Association with polarity. Rating 1 with Polarity less than 0, Rating 2 and 3 seems neutral sentiment and Rating 4,5 being pretty positive.","505c4ae6":"Seems effective, no further cleaning required.","893e3568":"* TF-IDF Transform","f7077905":"* Machine Learning"}}