{"cell_type":{"098a5fb4":"code","7e632171":"code","356e26b3":"code","91cdb9a0":"code","e2bf3f42":"code","58b39fed":"code","c751222c":"markdown","41f3caca":"markdown","0f15ef22":"markdown","b2db7353":"markdown","0f494183":"markdown","9dc8d26b":"markdown"},"source":{"098a5fb4":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\n\nRANDOM_STATE = 2021\n\nimport numpy as np\nimport pandas as pd\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.cluster import DBSCAN","7e632171":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","356e26b3":"# get train row size \ntrain_len = len(train)\n# concat train + test \ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n# empty data => np.nan\ndataset = dataset.fillna(np.nan)","91cdb9a0":"# column encoding and create new features\n# 1.Fare\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n# dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n\n# 2.Embarked\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(dataset[\"Fare\"].mode()[0])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\n\n# 3.Sex\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n# dataset = pd.get_dummies(dataset, columns = [\"Sex\"])\n\n# 4.Age\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].mean()\n    dataset['Age'].iloc[i] = age_med\n\n# 5.SibSp(Number of Siblings\/Spouses Aboard) + Parch(Number of Parents\/Children Aboard) =>Fsize\ndataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['IsSingle'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n# dataset['IsSmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n# dataset['IsMedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# dataset['IsLargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n# 6.Cabin\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\n\n# 7.Ticket \nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# 8.Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# 9.PassengerId\ndataset.drop(labels = [\"Name\",\"PassengerId\"], axis = 1, inplace = True)","e2bf3f42":"# devide train test \ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","58b39fed":"def removeAutoOutlier(df,minPercent,maxPercent):\n    begin_size = len(df)\n\n    outlier_cols = []\n    for colname, colvalue in df.iteritems():\n        if type(colvalue[1]) != str and colvalue.nunique() >= 10: # continuous column \n            outlier_cols.append(colname)\n\n    def drop_outliers(df, field_name):\n        iqr = 1.5 * (np.percentile(df[field_name], maxPercent) - np.percentile(df[field_name], minPercent))\n        df.drop(df[df[field_name] > (iqr + np.percentile(df[field_name],maxPercent))].index, inplace=True)\n        df.drop(df[df[field_name] < (np.percentile(df[field_name], minPercent) - iqr)].index, inplace=True)\n\n    for col in outlier_cols:\n        drop_outliers(df,col)\n\n    after_size = len(df)\n\n    print(\"begin size=\",begin_size)\n    print(\"after size=\",after_size)\n    print(\"outler size=\",after_size - begin_size)\n    \n    \nremoveAutoOutlier(train,25,75)","c751222c":"##### 3. devide data ","41f3caca":"# preprocess data","0f15ef22":"##### 1.concat data","b2db7353":"# load data ","0f494183":"##### 2. feature engineering","9dc8d26b":"# outlier"}}