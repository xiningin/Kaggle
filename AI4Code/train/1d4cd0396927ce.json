{"cell_type":{"4d696993":"code","8b757149":"code","ab2d4a2b":"code","c0c89654":"code","bf6cfef5":"code","939ff89e":"code","f32d0311":"code","d9f23cc1":"code","b5721613":"code","3ff73662":"code","64cda483":"code","e97daa09":"code","ee675e85":"code","2a4f30d4":"code","8ff1d31d":"code","418dc5a4":"code","b32e2748":"code","a9e84c1b":"code","c1e09cf4":"code","4ceafdf1":"code","6f87de25":"code","f2c86d9b":"code","1d00fe9a":"code","994cf65e":"markdown"},"source":{"4d696993":"import numpy as np\nimport pandas as pd\nimport time\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval\nfrom hyperopt.pyll import scope as ho_scope\nfrom hyperopt.pyll.stochastic import sample as ho_sample\nfrom functools import partial\n\nfrom lightgbm import LGBMClassifier\n\nfrom imblearn.pipeline import Pipeline\n#from imblearn.over_sampling import ADASYN\n#from imblearn.under_sampling import OneSidedSelection, NeighbourhoodCleaningRule, TomekLinks\nfrom imblearn.under_sampling import RandomUnderSampler","8b757149":"def evalue_model(model, y_test, X_test, model_name):\n    \n    yhat_prob = [x[1] for x in model.predict_proba(X_test)]\n    \n    results = {'model': model_name,\n               'auc': roc_auc_score(y_true = y_test, y_score = yhat_prob),\n               'aucpr': average_precision_score(y_true = y_test, y_score = yhat_prob),\n               'logloss': log_loss(y_test, yhat_prob)}\n    \n    return results","ab2d4a2b":"submission = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nX_test = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\ntrain = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')","c0c89654":"train.drop(columns = \"id\", inplace = True)\nX_test.drop(columns = \"id\", inplace = True)","bf6cfef5":"for col in train.columns[train.dtypes == \"object\"].tolist():\n    train[col] = train[col].astype('category')\n    \nfor col in X_test.columns[X_test.dtypes == \"object\"].tolist():\n    X_test[col] = X_test[col].astype('category')","939ff89e":"X = train.drop('target', axis=1)\ny = train['target']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","f32d0311":"lgbm=LGBMClassifier(random_state = 42, \n                    #device = \"gpu\", \n                    learning_rate = 0.1,\n                    n_estimators = 20000)\n\nlgbm.fit(X_train, y_train, \n         eval_set=(X_val,y_val),\n         early_stopping_rounds=200,\n         verbose=False)\n\npredictions=lgbm.predict_proba(X_val)[:,1]\n\nauc_baseline=roc_auc_score(y_val,predictions)\n\nprint(f'Baseline: {auc_baseline}')","d9f23cc1":"submission_baseline = submission.copy()\nsubmission_baseline.loc[:, 'target'] = lgbm.predict_proba(X_test)[:,1]\nsubmission_baseline.to_csv('submission_baseline.csv', index = False)","b5721613":"hp_space = {\n    'undersample': hp.choice(label = 'undersample', options = [True, False]),\n    'clf': {\n        'boosting_type': hp.choice(label = 'boosting_type', options = ['gbdt', 'goss']),\n        \n        'num_leaves': hp.choice(label = 'num_leaves', options = [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]), \n        #'max_depth': ho_scope.int(hp.quniform('max_depth',1,32,1)), # default 'max_depth': -1\n        'min_child_weight': ho_scope.int(hp.quniform('min_child_weight', 0, 0.01,0.001)),\n        'min_child_samples': ho_scope.int(hp.quniform('min_child_samples',1,300,1)),\n        \n        'max_bin': ho_scope.int(hp.quniform('max_bin',128,1024,128)), # Typical: 255\n        'max_delta_step': ho_scope.int(hp.quniform('max_delta_step',1,10,1)),\n        \n        'subsample_freq': ho_scope.int(hp.quniform('subsample_freq',0,10, 1)),\n       # 'subsample': hp.uniform('subsample',0.2,1),\n        'colsample_bytree': hp.uniform('colsample_bytree',0.2,1),\n        \n        'reg_lambda': hp.loguniform('reg_lambda',np.log(1e-4),np.log(3)),\n        'reg_alpha': hp.loguniform('reg_alpha',np.log(1e-4),np.log(3)),\n        \n        'min_data_per_group': ho_scope.int(hp.quniform('min_data_per_group',50,200,1)),\n        'cat_smooth':  ho_scope.int(hp.quniform('cat_smooth',5,100,1)),\n        'cat_l2': ho_scope.int(hp.quniform('cat_l2',1,20,1))\n    }\n}\n\n#ho_sample(hp_space)","3ff73662":"iteracoes = Trials()","64cda483":"def instancia_modelo(hiperparametros):\n    \n    clf = LGBMClassifier(**hiperparametros['clf'],\n                         random_state = 42, \n                         #device = \"gpu\", \n                         learning_rate = 0.1,\n                         n_estimators = 20000)\n\n    if hiperparametros['undersample'] == True:\n        undersample = RandomUnderSampler(sampling_strategy='majority')\n    else:\n        undersample = None\n\n    pipe = Pipeline([('undersample', undersample),\n                     ('clf', clf) ])\n\n    return pipe","e97daa09":"def funcao_para_minimizar(hiperparametros, features, target):\n    \n    pipe = instancia_modelo(hiperparametros)\n    \n    eval_set=(X_val,y_val)\n    \n    fit_params={'clf__early_stopping_rounds': 200, \n                'clf__eval_metric': 'auc', # logloss\n                'clf__verbose': False,\n                'clf__eval_set': eval_set}\n    \n    cv = StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n    \n    resultado = cross_val_score(estimator = pipe, \n                                X = features, \n                                y = target, \n                                scoring = \"roc_auc\",\n                                cv = cv, \n                                error_score = \"raise\",\n                                fit_params = fit_params,\n                                n_jobs = -1)\n\n    return -resultado.mean()","ee675e85":"%%time\n\notimizacao = fmin(fn = partial(funcao_para_minimizar, features = X_train, target = y_train),\n                  space = hp_space, \n                  algo = tpe.suggest,\n                  trials = iteracoes,\n                  max_evals = int(180), \n                  rstate = np.random.RandomState(42))","2a4f30d4":"def extrai_space_eval(hp_space, trial):\n\n    desempacota_trial = space_eval(space = hp_space, \n                                   hp_assignment = {k: v[0] for (k, v) in trial['misc']['vals'].items() if len(v) > 0})\n    \n    return desempacota_trial","8ff1d31d":"def desempacota_dicionario(dicionario):\n    desempacotado = {}\n    for (chave, valor) in dicionario.items():\n        if isinstance(valor, dict):\n            desempacotado = {**desempacotado, **desempacota_dicionario(valor)}\n        else:\n            desempacotado[chave] = valor\n            \n    return desempacotado","418dc5a4":"historico = pd.DataFrame([desempacota_dicionario(extrai_space_eval(hp_space, x)) for x in iteracoes.trials])\n\nhistorico['auc'] = [-x['loss'] for x in iteracoes.results]","b32e2748":"hiperparametros_selecionados = space_eval(space = hp_space, hp_assignment = otimizacao)\nprint('Selected hyperparameters:\\n%s' % hiperparametros_selecionados)","a9e84c1b":"import plotly.express as px\n\nhistorico.loc[:,'undersample'] = historico.loc[:,'undersample']*1\n\nfig = px.parallel_coordinates(historico, color=\"auc\", width = 1200)\nfig.show()","c1e09cf4":"if hiperparametros_selecionados['undersample'] == True:\n    undersample = RandomUnderSampler(sampling_strategy='majority')\nelse:\n    undersample = None","4ceafdf1":"clf = LGBMClassifier(**hiperparametros_selecionados['clf'],\n                     random_state = 42, \n                     #device = \"gpu\", \n                     learning_rate = 0.05,\n                     n_estimators = 20000)\n\npipe = Pipeline([('undersample', undersample),\n                 ('clf', clf) ])\n\neval_set=(X_val,y_val)","6f87de25":"%%time\n\nfinal_fit = pipe.fit(X_train, y_train,\n                     clf__early_stopping_rounds=200,\n                     clf__eval_metric='auc', # logloss\n                     clf__verbose=False,\n                     clf__eval_set=eval_set\n                    )","f2c86d9b":"predictions=final_fit.predict_proba(X_val)[:,1]\n\nauc=roc_auc_score(y_val,predictions)\n\nprint(f'Baseline: {auc_baseline}')\nprint(f'Tunning: {auc}')","1d00fe9a":"submission.loc[:, 'target'] = final_fit.predict_proba(X_test)[:,1]\nsubmission.to_csv('submission.csv', index = False)","994cf65e":"high_cardinality = [\"cat5\", \"cat7\", \"cat8\", \"cat10\"]\n\ncategorical_cols = X.columns[X.dtypes == \"category\"].tolist()\n\ncategorical_cols = list(set(categorical_cols) - set(high_cardinality))\n\ncat_columns_position = [X.columns.tolist().index(x) for x in categorical_cols + high_cardinality]"}}