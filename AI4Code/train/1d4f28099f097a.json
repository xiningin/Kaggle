{"cell_type":{"b4c18f1c":"code","f1897c7e":"code","6b2097ae":"code","7d6c4959":"code","65d43a98":"code","b19a70e6":"code","4ceeb118":"code","fbe741a2":"code","5f86fe6d":"code","19817691":"code","4d262af6":"code","a4275cb3":"code","44416bca":"code","ef830a98":"code","0b8579ce":"code","afc75ff3":"code","9d72b409":"code","d9add003":"code","e91fdb13":"markdown","3a87b7d1":"markdown","b1d70d0a":"markdown","27b4dc5f":"markdown","cc47d88c":"markdown","750d099c":"markdown","f8cf9260":"markdown","8f83a66d":"markdown","8e1e73f5":"markdown","33a75731":"markdown","4c76af14":"markdown"},"source":{"b4c18f1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1897c7e":"import pandas as pd\nimport numpy as np","6b2097ae":"train = pd.read_csv(\"\/kaggle\/input\/bri-data-hackathon-people-analytic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/bri-data-hackathon-people-analytic\/test.csv\")","7d6c4959":"train = train[train.Employee_status != \"Contract\"]\ntrain = train.drop('Employee_status', axis=1)\ntest = test.drop('Employee_status', axis=1)","65d43a98":"train['achievement_target_1'] = train['achievement_target_1'].replace(['achiev_50%-100%'], 'Pencapaian 50-100')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['achiev_100%-150%'], 'Pencapaian 100-150')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['achiev_< 50%'], 'Pencapaian 50')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['achiev_> 1.5'], 'Pencapaian 15')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['Pencapaian 50%-100%'], 'Pencapaian 50-100')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['Pencapaian 100%-150%'], 'Pencapaian 100-150')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['Pencapaian < 50%'], 'Pencapaian 50')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(['Pencapaian > 1.5'], 'Pencapaian 15')\ntrain['achievement_target_1'] = train['achievement_target_1'].replace(np.nan, 'Tidak diberikan target')\n\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['achiev_50%-100%'], 'Pencapaian 50-100')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['achiev_100%-150%'], 'Pencapaian 100-150')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['achiev_< 50%'], 'Pencapaian 50')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['achiev_> 1.5'], 'Pencapaian 15')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['Pencapaian 50%-100%'], 'Pencapaian 50-100')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['Pencapaian 100%-150%'], 'Pencapaian 100-150')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['Pencapaian < 50%'], 'Pencapaian 50')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(['Pencapaian > 1.5'], 'Pencapaian 15')\ntrain['achievement_target_2'] = train['achievement_target_2'].replace(np.nan, 'Tidak diberikan target')\n\ntrain['achievement_target_3'] = train['achievement_target_3'].replace(['not reached'], 'not_reached')\ntrain['achievement_target_3'] = train['achievement_target_3'].replace(np.nan, 'NONE')\n\n\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['achiev_50%-100%'], 'Pencapaian 50-100')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['achiev_100%-150%'], 'Pencapaian 100-150')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['achiev_< 50%'], 'Pencapaian 50')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['achiev_> 1.5'], 'Pencapaian 15')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['Pencapaian 50%-100%'], 'Pencapaian 50-100')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['Pencapaian 100%-150%'], 'Pencapaian 100-150')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['Pencapaian < 50%'], 'Pencapaian 50')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(['Pencapaian > 1.5'], 'Pencapaian 15')\ntest['achievement_target_1'] = test['achievement_target_1'].replace(np.nan, 'Tidak diberikan target')\n\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['achiev_50%-100%'], 'Pencapaian 50-100')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['achiev_100%-150%'], 'Pencapaian 100-150')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['achiev_< 50%'], 'Pencapaian 50')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['achiev_> 1.5'], 'Pencapaian 15')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['Pencapaian 50%-100%'], 'Pencapaian 50-100')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['Pencapaian 100%-150%'], 'Pencapaian 100-150')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['Pencapaian < 50%'], 'Pencapaian 50')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(['Pencapaian > 1.5'], 'Pencapaian 15')\ntest['achievement_target_2'] = test['achievement_target_2'].replace(np.nan, 'Tidak diberikan target')\n\ntest['achievement_target_3'] = test['achievement_target_3'].replace(['not reached'], 'not_reached')\ntest['achievement_target_3'] = test['achievement_target_3'].replace(np.nan, 'NONE')","b19a70e6":"train['achievement_target_3'].value_counts()","4ceeb118":"test['achievement_target_3'].value_counts()","fbe741a2":"train = train[train['achievement_target_3'] != \"NONE\"]","5f86fe6d":"train['Achievement_above_100%_during3quartal'].hist(density=True, alpha=0.8);\ntest['Achievement_above_100%_during3quartal'].hist(density=True, alpha=0.8);","19817691":"train['job_duration_in_current_person_level'].hist(density=True, alpha=0.8);\ntest['job_duration_in_current_person_level'].hist(density=True, alpha=0.8);","4d262af6":"train['job_duration_as_permanent_worker'].hist(density=True, alpha=0.9);\ntest['job_duration_as_permanent_worker'].hist(density=True, alpha=0.9);","a4275cb3":"train['job_duration_in_current_branch'].hist(density=True, alpha=0.9);\ntest['job_duration_in_current_branch'].hist(density=True, alpha=0.9);","44416bca":"col_subset = [\"number_of_dependences\", \n              \"job_duration_in_current_person_level\", \n              \"Achievement_above_100%_during3quartal\", \n              \"annual leave\"]\n\ntrain_subset = train[col_subset]\ntest_subset = test[col_subset]","ef830a98":"sum(train_subset[col_subset].duplicated())","0b8579ce":"sum(test_subset[col_subset].duplicated())","afc75ff3":"col_subset = [\"number_of_dependences\", \n              \"job_duration_in_current_person_level\", \n              \"Achievement_above_100%_during3quartal\", \n              \"annual leave\",\n              \"job_duration_as_permanent_worker\"]\n\ntrain_subset = train[col_subset]\ntest_subset = test[col_subset]","9d72b409":"sum(train_subset[col_subset].duplicated())","d9add003":"sum(test_subset[col_subset].duplicated())","e91fdb13":"#### By taking 5 variables, we have ~8000 duplicated data in the train set and ~2400 duplicated data in the test set. Solid evidence? You are the judge ;) ","3a87b7d1":"**Fix typo in both train and test dataset.**","b1d70d0a":"**Drop the achievement_target = NONE**","27b4dc5f":"### Evidence 3: Duplicated data\n\n#### If we only take some subset of the data, we can see clearly if the data is duplicated. One can exploit this to get a perfect AUC score.","cc47d88c":"**Employee_status = contract does not exist in test set. So, I will drop it.**","750d099c":"**Here we see that the test dataset only has either reached or not_reached for the achievement_target_3.**\n\n**I suspect the NONE (which I imputed before) randomly added to the train set.**","f8cf9260":"#### By taking 4 variables, we have ~12000 duplicated data in the train set and ~4000 duplicated data in the test set. Is it pure chance? I don't think so. ","8f83a66d":"### **This notebook shows evidence that the data is synthetic or random and does not represent real data.**\n\n#### With a little bit of data cleansing (noise), one can see that the data has an almost perfect correlation between train and test set. I suspect the creator added the noise later after data randomly \/ synthetically created.","8e1e73f5":"### Evidence 2: Look like some variables are shifted a bit on purpose after randomly generated to create a noise.","33a75731":"## Here now comes the fun part. \n\n### Pay attention to the data distribution between train and test set. It is almost impossible to see this kind of data in the real setting.\n#### Also see there is duplicated data in both train and test set.","4c76af14":"### Evidence 1: The distribution of some variables in the train set and data set almost (>95%) perfectly matched."}}