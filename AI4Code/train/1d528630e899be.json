{"cell_type":{"64fd3487":"code","19eeced6":"code","07e4f1cc":"code","d787cddc":"code","f1e1480e":"code","b36bdc78":"code","356704c7":"code","efaad39e":"code","2cd97853":"code","e071a18c":"code","995299d6":"code","9bf841f6":"code","9f74a3de":"code","48e1e8c4":"code","5597d592":"code","bfc12a57":"code","f7da2f3a":"code","8de3e680":"code","201baca3":"code","31eadab3":"code","ec64b073":"code","09c65246":"code","feb28c3d":"code","4c2c3ebe":"code","e82b6a93":"code","13f07efb":"code","266c9108":"code","9a726563":"code","decf500d":"markdown","6e438592":"markdown","b3a88840":"markdown","9910b4dd":"markdown","cbb145bc":"markdown","03d1ee94":"markdown","99fa3458":"markdown","49ced467":"markdown","9adf22dc":"markdown","04b13243":"markdown","481985fc":"markdown","11ddbbd5":"markdown"},"source":{"64fd3487":"import pandas as pd # for data analyse and data manupulation\nimport matplotlib.pyplot as plt # visualization\nimport numpy as np  \nimport folium # visualization\nimport seaborn as sns # visualization","19eeced6":"data = pd.read_csv(\"..\/input\/housesalesprediction\/kc_house_data.csv\")\ndata.head()\n","07e4f1cc":"data.describe()\n","d787cddc":"groups = data.groupby(['grade'])['price'].mean()\nplt.figure(figsize=(10, 5))\nplt.xlabel('price')\ngroups.plot.barh()\n","f1e1480e":"groups = data.groupby(['bedrooms'])['price'].mean()\nplt.figure(figsize=(10, 5))\nplt.xlabel('price')\ngroups.plot.barh()","b36bdc78":"groups = data.groupby(['bathrooms'])['price'].mean()\nplt.figure(figsize=(10, 10))\ngroups.plot.barh()","356704c7":"sns.countplot(data.bathrooms, order = data['bathrooms'].value_counts().index)\n","efaad39e":"sns.countplot(data.bedrooms, order = data['bedrooms'].value_counts().index)\n","2cd97853":"sns.countplot(data.grade, order = data['grade'].value_counts().index)\n","e071a18c":"sns.countplot(data.condition, order = data['condition'].value_counts().index)\n","995299d6":"def generateBaseMap(map_location=[47.5,-122.161], zoom=9):\n    base_map = folium.Map(location=map_location, control_scale=True, zoom_start=zoom)\n    return base_map\n","9bf841f6":"from folium.plugins import HeatMap\ndf_copy = data[np.logical_and(data.yr_built<=1980,data.yr_built >= 1970)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map\n","9f74a3de":"df_copy = data[np.logical_and(data.yr_built<=1990,data.yr_built >= 1980)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map","48e1e8c4":"df_copy = data[np.logical_and(data.yr_built<=2000,data.yr_built >= 1990)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map","5597d592":"df_copy = data[np.logical_and(data.yr_built<=2010,data.yr_built >= 2000)] \ndf_copy['count'] = 1\nbase_map = generateBaseMap()\nHeatMap(data=df_copy[['lat', 'long', 'count']].groupby(['lat', 'long']).sum().reset_index().values.tolist(), radius=8, max_zoom=15).add_to(base_map)\nbase_map","bfc12a57":"neededCols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront',\n            'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n            'yr_renovated', 'sqft_living15', 'sqft_lot15']\n\n\ncorr = data[neededCols].corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","f7da2f3a":"dataForRegression = data[neededCols]","8de3e680":"dataForRegression.head()","201baca3":"from sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm","31eadab3":"X=dataForRegression.drop('price',axis=1)\ny=dataForRegression['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=42)\nlm = linear_model.LinearRegression() \nmodel = lm.fit(X_train[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n       'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15',\n       'sqft_lot15']], y_train)\n\nlm = sm.OLS(y_train, X_train)\nmodel1 = lm.fit()\nmodel1.summary()","ec64b073":"\n\nprint('model accuracy is : ',model.score(X_test,y_test))","09c65246":"from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\n","feb28c3d":"np.sqrt(mean_squared_error(y_train, model.predict(X_train)))","4c2c3ebe":"np.sqrt(mean_squared_error(y_test, model.predict(X_test)))","e82b6a93":"cross_val_score(model, X_train, y_train, cv = 100, scoring = \"r2\").mean()\n\n","13f07efb":"predictedDatas=[]\nfor  row in range(0,len(dataForRegression)):\n    a=(model.predict([[dataForRegression['bedrooms'].values[row],dataForRegression['bathrooms'].values[row],dataForRegression['sqft_living'].values[row],dataForRegression['sqft_lot'].values[row],dataForRegression['floors'].values[row],\n        dataForRegression['waterfront'].values[row],dataForRegression['view'].values[row],dataForRegression['condition'].values[row],dataForRegression['grade'].values[row],dataForRegression['sqft_above'].values[row],\n        dataForRegression['sqft_basement'].values[row],dataForRegression['yr_built'].values[row],dataForRegression['yr_renovated'].values[row],dataForRegression['sqft_living15'].values[row],dataForRegression['sqft_lot15'].values[row]\n        ]]))\n    a=round(a[0],0)\n    predictedDatas.append(a)\n\n","266c9108":"final_df = dataForRegression.price.values\nfinal_df = pd.DataFrame(final_df,columns=['Real_price'])\nfinal_df['predicted_prices'] = predictedDatas\nfinal_df['difference'] = abs(final_df['Real_price'] - final_df['predicted_prices'])\nfinal_df.tail(20)","9a726563":"prediction= model.predict([[2,0,1180,6000,1,0,0,4,7,1180,0,1995,2010,1340,6000]]) \nprediction=round(prediction [0],0)\nprediction","decf500d":"## Now , we will examine  house sales  from 1970 to 2010   with geographical heat map\n###  I will  separate dataset ;\n### from 1970 to 1980 ,\n### 1980 to 1990,\n### 1990 to 2000,\n### and 2000 to 2010\n\n###  I created a  function to generate map graph ","6e438592":"# Analysing House Sales in King County, USA\n## This kernel we will examine house sales from 1970 to 2010 for King county  and we will try to predict house price using multiple linear regression ","b3a88840":"### Importing libs\n","9910b4dd":"# As a result , \n### Popular areas from 1970 to 2010   are map valley, sammammish\n###  Most sales house type  has 3 bedroom, 2.5 bathroom , 7 grade level  and 3 Condition level \n### Also , we learnt how to make prediction with Multiple linear regression","cbb145bc":"### If we want to predict a house price  except from this  dataset , we can predict this way;\n#### we write our 15 criteria  to predict method ","03d1ee94":"## Understanding data ","99fa3458":"### the model have %65 accuracy but ;we will check cross validation score for better  verification ","49ced467":"### r2 is 0.881 \n### our dataset is good for regression ","9adf22dc":"### Stats model  provide us some significant values like r2  \n","04b13243":"### Prepare regression data for prediction\n#### we will create a corralation table ","481985fc":"### Now, we will try to find our model's prediction on the dataset and what is differece between real prices and predicted price ","11ddbbd5":"## Visualize  data to  understand some important variable "}}