{"cell_type":{"4da59d2f":"code","2765fbb8":"code","7843fab9":"code","adcb8e93":"code","4bebad1b":"code","7fa1be5d":"code","4f2274ae":"code","b370ac4d":"code","cd7efe11":"code","2214bd60":"code","54dffd96":"code","b4eb2f54":"code","2b7ab7e7":"code","99ae416f":"code","4e728a85":"code","466c4cef":"code","069066d4":"code","4d6a25d7":"code","38d633c3":"code","0f769a33":"code","737b6a40":"code","ac8649fa":"code","87ca4e61":"code","de101ffb":"code","19113281":"code","536afe68":"code","51293c00":"code","df2de8b9":"code","30b18674":"markdown","3f12cffe":"markdown","d4c68607":"markdown","498127df":"markdown","4896b7b8":"markdown","58a6e218":"markdown","c3822592":"markdown","de189285":"markdown","c9a579d2":"markdown","89ba0b74":"markdown","d5c9cc5d":"markdown","aedf9396":"markdown","5b84e8db":"markdown","9ccd03b3":"markdown"},"source":{"4da59d2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2765fbb8":"# Core data science\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\n\n# Load dataset\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Statistics\nimport scipy\nfrom sklearn import metrics\n\n# KMeans \nfrom sklearn.cluster import KMeans\n\n# Hierachy clustering\nfrom scipy.spatial.distance import cdist\n\n#GMM\nfrom sklearn.mixture import GaussianMixture","7843fab9":"data = pd.read_excel('\/kaggle\/input\/swedish-total-income-from-2018-cleaned\/Swedish total income from employment and business 2018 - cleaned ver2.0.xlsx')\ndata.head()","adcb8e93":"def show_df_info(df):\n    pd.set_option(\"display.max.columns\", None)\n\n    print('Shape: ') \n    print(df.shape)\n    print('-'*50)\n\n    print('Info: ') \n    print(df.info())\n    print('-'*50)\n\n    print('Describe: ')\n    print(df.describe())\n    print('-'*50)\n    \n    print('Head: ') \n    print(df.head())\n    print('-'*50)\n\n    print('Tail: ')\n    print(df.tail())\n    print('-'*50)\n\n    print('Check null: ')\n    print(df.isnull().any())\n    print('-'*50)\n    \n    print('Check null data: ')\n    print(df.isnull().values.any())","4bebad1b":"show_df_info(data)","7fa1be5d":"def show_continuous_info(columns, df):\n    for column in columns:\n        print('Attribute: ', column)\n        print('# Central Tendency:\\n', df[column].describe(include='all'))\n        print('-'*50)\n\n        print('Median: ', df[column].median())\n        print('-'*50)\n\n        print('Mode: ', df[column].mode())\n        print('-'*50)\n\n        print('Measure of dispersion: ',np.ptp(df[column]))\n        print('-'*50)\n\n        print('Q1: ', np.percentile(df[column], 25))\n        print('-'*50)\n\n        print('Q3: ', np.percentile(df[column], 75))\n        print('-'*50)\n\n        print('IQR: ', scipy.stats.iqr(df[column]))\n        print('-'*50)\n\n        print('Variance: ', df[column].var())\n        print('-'*50)\n\n        print('Standard deviation', df[column].std())\n        print('-'*50)\n\n        print('Skewness: ', df[column].skew())\n        if df[column].skew() > 0:\n            print('the data are positively skewed or skewed right, meaning that the right tail of the distribution is longer than the left')\n        elif df[column].skew() < 0:\n            print('the data are negatively skewed or skewed left, meaning that the left tail is longer')\n        else:\n            print('the data are perfectly symmetrical')\n        print('-'*50)\n\n        print('Kurtosis: ', df[column].kurtosis())\n        if df[column].kurtosis() > 0:\n            print('the dataset has heavier tails than a normal distribution (more in the tails)')\n        elif df[column].kurtosis() < 0:\n            print('the dataset has lighter tails than a normal distribution (less in the tails)')\n        else:\n            print('the kurtosis is equal to the normal distribution')\n        print('-'*50)\n\n        # Visualization\n        # Histogram\n        print('Visualization - Histogram')\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        sns.distplot(df[column])\n        plt.subplot(1, 2, 2)\n        plt.hist(df[column])\n        plt.show()\n        print('-'*50)\n\n        # Boxplot\n        print('Visualization - Boxplot')\n        plt.figure(figsize=(4, 8))\n        plt.boxplot(df[column])\n        plt.show()\n        print('-'*50)\n\n        # Number of upper outlier\n        n_upper_out = df[df[column] > (np.percentile(df[column], 75) + 1.5*scipy.stats.iqr(df[column]))].shape[0]\n        print('Number of upper outlier: ', n_upper_out)\n        print('-'*50)\n\n        # Number of lower outlier\n        n_lower_out = df[df[column] < (np.percentile(df[column], 25) - 1.5*scipy.stats.iqr(df[column]))].shape[0]\n        print('Number of lower outlier: ',  n_lower_out)\n        print('-'*50)\n\n        # Percentage of outliers\n        print('Percentage of outlier: ', ((n_lower_out + n_upper_out) \/ df.shape[0])*100, '%')\n        print('-'*50)\n\n        # Check if remove outlier or not\n        df_now = df[(df[column] >= (np.percentile(df[column], 25) - 1.5*scipy.stats.iqr(df[column]))) & (df[column] <= (np.percentile(df[column], 75) + 1.5*scipy.stats.iqr(df[column])))]\n        print('Mean before remove outlier: ', df[column].mean())\n        print('Mean after remove outlier: ', df_now[column].mean())\n        print('-'*50)","4f2274ae":"show_continuous_info(['Number of persons', 'Age bracket', 'Thousand SEK'], data)","b370ac4d":"def encoding_categorical_columns(df):\n    # Categorical boolean mask\n    categorical_feature_mask = df.dtypes==object\n\n    # filter categorical columns using mask and turn it into a list\n    categorical_cols = df.columns[categorical_feature_mask].tolist()\n    print('List of categorical columns: ', categorical_cols)\n    print('*'*50)\n\n    df_now = pd.get_dummies(data=df, columns=categorical_cols, drop_first=True)\n    print('DataFrame after encoding: ')\n    print(df_now.head())\n    print('*'*50)\n\n    print(df_now.isnull().any())\n\n    return df_now","cd7efe11":"data_processed = encoding_categorical_columns(data)\ndata_processed","2214bd60":"# TODO: visualization later","54dffd96":"X = data_processed[['Thousand SEK', 'Number of persons']]\nX.head()","b4eb2f54":"# k means determine k\ndistortions = []\nK = range (1,10)\nfor k in K:\n    kmeanModel = KMeans(n_clusters=k).fit(X)\n    kmeanModel.fit(X)\n    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_,\n                                        'euclidean'), axis=1)) \/ X.shape[0])","2b7ab7e7":"# Plot the elbow\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","99ae416f":"# k = 4\nkmeans = KMeans(n_clusters=4)\nkmeans.fit(X)","4e728a85":"centroids = kmeans.cluster_centers_\nlabels = kmeans.labels_","466c4cef":"print(centroids)\nprint(labels)","069066d4":"X['group'] = pd.Series(labels)\nX.head()","4d6a25d7":"plt.figure(figsize=(8,8))\n#plt.scatter(centroids[:, 1], centroids[:, 0], marker='x', s=150, color='r')\nplt.scatter(X['Number of persons'], X['Thousand SEK'], c=X.group)\nplt.xlabel('Number of persons')\nplt.ylabel('Thousand SEK')\nplt.title('K-Means Cluster', color='red')\nplt.show()","38d633c3":"X = data_processed[['Thousand SEK', 'Number of persons']]\nX.head()","0f769a33":"def find_k_gmm(df):\n    print('Visualize to find k: ')\n    list_sil = [] # chua danh sach cac gia tri sil\n    K = range(4,9) # chua danh sach so cum co the\n    for k in K:\n        gmm = GaussianMixture(n_components=k) # 4,5,6,7,8\n        gmm.fit(df)\n        labels = gmm.predict(df)\n        # k = 2 => 0,1\n        # k = 3 => 0,1,2\n        sil = metrics.silhouette_score(df, labels, metric='euclidean')\n        list_sil.append(sil)\n    # Plot\n    plt.plot(K, list_sil, 'bx-')\n    plt.xlabel('k')\n    plt.ylabel('sil_score')\n    plt.title('The silhouette_score & k')\n    plt.show()","737b6a40":"find_k_gmm(X)","ac8649fa":"def gmm(df, k, chart_title, col1, col2, col3=None):\n    print('Gaussian Mixture Model: ')\n    # fit model\n    gmm = GaussianMixture(n_components=k)\n    gmm.fit(df)\n    print('weights: ', gmm.weights_)\n    print('means: ', gmm.means_)\n    print('covariances: ', gmm.covariances_)\n    print('*'*50)\n\n    print('After predict: ')\n    types = gmm.predict(df)\n    df['group'] = types\n    print(df.head())\n    print('*'*50)\n\n    if col3 is not None:\n        print('Visualize 3D: ')\n        fig = plt.figure(figsize=(10,10))\n        ax = fig.add_subplot(1, 1, 1, projection='3d')\n        ax.scatter(df[col1], df[col2], df[col3],\n                c=df.group, cmap=plt.cm.Spectral)\n        ax.set_xlabel(col1, fontsize=18)\n        ax.set_ylabel(col2, fontsize=18)\n        ax.set_zlabel(col3, fontsize=18)\n        ax.set_title(chart_title, fontsize=22)\n        plt.show()\n        print('*'*50)\n\n    print('Visualize 2D: ')\n    df.groupby('group').count()\n    plt.figure(figsize=(6,6))\n    sns.scatterplot(data=df, x=col1, y=col2, hue='group', palette='tab10',\n                    legend='full', markers='Group')\n    plt.show()\n    print('*'*50)\n\n    #print('New value prediction: ')\n    #new_pred = gmm.predict(new_value_pred)\n    #print(new_pred)","87ca4e61":"gmm(X, k=8, chart_title='GMM clustering', col1='Thousand SEK', col2='Number of persons', col3=None)","de101ffb":"X = data_processed[['Thousand SEK', 'Number of persons', 'Is female_Yes']]\nX.head()","19113281":"def find_k_gmm(df):\n    print('Visualize to find k: ')\n    list_sil = [] # chua danh sach cac gia tri sil\n    K = range(4,9) # chua danh sach so cum co the\n    for k in K:\n        gmm = GaussianMixture(n_components=k) # 4,5,6,7,8\n        gmm.fit(df)\n        labels = gmm.predict(df)\n        # k = 2 => 0,1\n        # k = 3 => 0,1,2\n        sil = metrics.silhouette_score(df, labels, metric='euclidean')\n        list_sil.append(sil)\n    # Plot\n    plt.plot(K, list_sil, 'bx-')\n    plt.xlabel('k')\n    plt.ylabel('sil_score')\n    plt.title('The silhouette_score & k')\n    plt.show()","536afe68":"find_k_gmm(X)","51293c00":"# Choose k = 5 because it is highest\ndef gmm(df, k, chart_title, col1, col2, col3=None):\n    print('Gaussian Mixture Model: ')\n    # fit model\n    gmm = GaussianMixture(n_components=k)\n    gmm.fit(df)\n    print('weights: ', gmm.weights_)\n    print('means: ', gmm.means_)\n    print('covariances: ', gmm.covariances_)\n    print('*'*50)\n\n    print('After predict: ')\n    types = gmm.predict(df)\n    df['group'] = types\n    print(df.head())\n    print('*'*50)\n\n    if col3 is not None:\n        print('Visualize 3D: ')\n        fig = plt.figure(figsize=(10,10))\n        ax = fig.add_subplot(1, 1, 1, projection='3d')\n        ax.scatter(df[col1], df[col2], df[col3],\n                c=df.group, cmap=plt.cm.Spectral)\n        ax.set_xlabel(col1, fontsize=18)\n        ax.set_ylabel(col2, fontsize=18)\n        ax.set_zlabel(col3, fontsize=18)\n        ax.set_title(chart_title, fontsize=22)\n        plt.show()\n        print('*'*50)\n\n    print('Visualize 2D: ')\n    df.groupby('group').count()\n    plt.figure(figsize=(6,6))\n    sns.scatterplot(data=df, x=col1, y=col2, hue='group', palette='rainbow',\n                    legend='full', markers='Group')\n    plt.show()\n    print('*'*50)","df2de8b9":"gmm(X, k=4, chart_title='GMM clustering with 3 features', col1='Thousand SEK', col2='Number of persons', col3='Is female_Yes')","30b18674":"# Apply GMM with 3 features","3f12cffe":"# Visualization","d4c68607":"# Univariate analysis","498127df":"# Load dataset","4896b7b8":"We can see that Gender does not play a role in this dataset. The 4 groups is clustered as follow:\n* Group 1: Only small amount of people (~100) with income from 500 to larger than 3000 thousand SEK\n* Group 2: Around 1-5000 people has income from 750-1250 thousand SEK\n* Group 3: Around 10000 ~ 50000 people have income from 0~750 thousand SEK\n* Group 4: Majority of people have income from 0 to 1000 thousand SEK","58a6e218":"- Data does not have any null item.\n- Is female column should later be switched to boolean type","c3822592":"Choose k=4","de189285":"Choose k=4","c9a579d2":"# K-Means","89ba0b74":"# Load library","d5c9cc5d":"The number of persons are divided into 4 groups, we will investigate with age and gender later\n* Group 1: ","aedf9396":"# GMM\n","5b84e8db":"k = 8 is the highest","9ccd03b3":"# Data standardization"}}