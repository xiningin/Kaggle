{"cell_type":{"4bcf6971":"code","d8454efc":"code","690b7b95":"code","258ef247":"code","0b4dd09c":"code","19297411":"code","ac343634":"code","efca7f2f":"code","57c3641a":"code","adb5fa80":"code","7f386238":"code","c7792678":"code","9dcbebfd":"code","b1b04ae0":"code","7f5a45f2":"code","951502bd":"code","ef818b92":"code","68d56da0":"code","876e0a06":"code","e0c26e38":"code","f7fc6048":"code","7581c71c":"code","3f7ee997":"code","336f6ed0":"code","1e9cbb07":"code","5a6a16bc":"code","362ab394":"code","590757d3":"code","f56d6e65":"code","6072dee0":"code","ed66f218":"code","69e56af1":"code","64acdc0a":"code","601a1e21":"code","748ebbd5":"code","b279a15d":"code","bf965418":"code","50d6e403":"code","89243360":"code","f8a07502":"code","041805fd":"code","ac393514":"code","5321edac":"code","22610761":"code","ab937284":"code","42f08a7a":"code","3662e34b":"code","45800159":"code","e2c7d6ad":"code","dd470d11":"code","65f44b6d":"code","c029c758":"code","3d6dc0b7":"code","0bae3edf":"code","3be722fa":"code","3ff13f5b":"code","e39d8ed3":"code","ea4bda62":"code","990eae6a":"code","12475cd3":"code","d107c577":"code","409ef04c":"markdown","6cb0302a":"markdown","d9a5a826":"markdown","06d269e1":"markdown","b4bd9ec1":"markdown","3966ca01":"markdown","9cd5a3df":"markdown","eea629e4":"markdown","bd613e2e":"markdown","260470b6":"markdown","797005e7":"markdown","e27e4f90":"markdown","9c76c568":"markdown","4142ab21":"markdown","f335fca2":"markdown","4903c45d":"markdown","39fc5d23":"markdown","7db19d10":"markdown","60244a5a":"markdown","0410e761":"markdown","bfb3d6d3":"markdown"},"source":{"4bcf6971":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8454efc":"# Read the sample file from given path.\ndf = pd.read_csv('\/kaggle\/input\/Training_Dataset_v2.csv')\n","690b7b95":"df.head()","258ef247":"df.info()","0b4dd09c":"df['went_on_backorder'].unique()","19297411":"df.groupby('went_on_backorder').count() ","ac343634":"df.went_on_backorder.value_counts(normalize=True)","efca7f2f":"df.count() ","57c3641a":"# The last 5 rows  \ndf.tail()","adb5fa80":"# Some columns are not shown, so showing first 5 rows them here.\ndf.loc[0:4,'sales_9_month':'potential_issue']","7f386238":"# Some columns are not shown, so showing first 5 rows them here.\ndf.loc[1687856:1687860,'sales_9_month':'potential_issue']","c7792678":"# Summarise the non-numerical data in df\ndf.describe(include=['O'])","9dcbebfd":"# Summarise the numerical data in df\ndf.describe()","b1b04ae0":"# Lets get the % of each null values.\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent_1 = df.isnull().sum()\/df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'], sort=False)\nmissing_data.head()","7f5a45f2":"missing_data","951502bd":"# Drop the sku column\ndf = df.drop('sku', axis=1)","ef818b92":"# Drop the last row\ndf = df[:-1]","68d56da0":"df.tail()","876e0a06":"# encoding categorical columns\ncategorical_columns = ['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk','stop_auto_buy', 'rev_stop', 'went_on_backorder']\n\nfor col in categorical_columns:\n    df[col] = df[col].map({'No':0, 'Yes':1})","e0c26e38":"df.info()","f7fc6048":"# Look at replacing NaNs\n\n# Look at histogram of lead_time\ndf.lead_time.plot.hist()","7581c71c":"# lead_time\ndf.lead_time = df.lead_time.fillna(df.lead_time.median())","3f7ee997":"# Re-check for missing values.\n# Lets get the % of each null values.\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent_1 = df.isnull().sum()\/df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'], sort=False)\nmissing_data.head()","336f6ed0":"import matplotlib.pyplot as plt  \nimport seaborn as sns","1e9cbb07":"df.corr().round(2)","5a6a16bc":"## Visiualize it on Heat Map\n##Using Pearson Correlation\nplt.figure(figsize=(20,20))\ncor = df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","362ab394":"df[df.columns[1:]].corr()['went_on_backorder'][:]","590757d3":"# df[['in_transit_qty', 'forecast_3_month', 'forecast_6_month']].corr()['went_on_backorder'][:]","f56d6e65":"# df.corrwith(df['went_on_backorder'])","6072dee0":"# #Correlation with output variable\n# cor_target = abs(cor[\"went_on_backorder\"])\n\n# #Selecting highly correlated features\n# relevant_features = cor_target[cor_target>0.005]\n# relevant_features","ed66f218":"# Take a closer look at correlations with scatter plots.\n\n# Forecast columns\nforecasts = ['forecast_3_month','forecast_6_month', 'forecast_9_month']\n\n# Pair-wise scatter plot for the forecasts\nsns.pairplot(df, vars=forecasts, hue='went_on_backorder', height=3)\n\n# Show the plot\nplt.show()","69e56af1":"# Do a pair-wise scatter plot for sales\nsales = ['sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month']\nsns.pairplot(df, vars=sales, hue='went_on_backorder', height=3)\nplt.show()","64acdc0a":"# Similarly, lets check for in_transit_qty;min_bank along with the latest forecast and sales data, and visualize it in a pair-wise scatter plot.\n# Why I select latest? As a general thumn rule.. Latest past past sales is measured.\n\n# feature_set_1 = ['forecast_3_month', 'sales_1_month', 'in_transit_qty', 'min_bank']\n# sns.pairplot(df, vars=feature_set_1, hue='went_on_backorder', height=3)\n# plt.show()","601a1e21":"# df[df['in_transit_qty'] == 'scott']","748ebbd5":"# df[df['min_bank'] == 'scott']","b279a15d":"# Features chosen\nfeatures = ['national_inv', 'lead_time', 'sales_1_month', 'pieces_past_due', 'perf_6_month_avg',\n            'local_bo_qty', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop']","bf965418":"X = df[features]","50d6e403":"y = df['went_on_backorder']","89243360":"display(X.shape, y.shape)","f8a07502":"from sklearn.preprocessing import MinMaxScaler ","041805fd":"# Use MinMaxScaler to convert features to range 0-1\n\nscaler = MinMaxScaler()\nscaler.fit(X)\n\nX = scaler.transform(X)\nX = pd.DataFrame(X, columns=features) ","ac393514":"X.head()","5321edac":"X.tail()","22610761":"# split the X and y into 2 DF's aka X_train, X_valid, y_train, y_valid.\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n\nprint (X_train.shape, y_train.shape)\nprint (X_valid.shape, y_valid.shape)\n# print (df.shape)","ab937284":"# machine learning algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Model Performance matrix\nfrom sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score, classification_report","42f08a7a":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","3662e34b":"# Predict the model\n\nY_valid_pred_lr = logreg.predict(X_valid)","45800159":"# Model Performance\nprint(\"LogisticRegression Performance --> \")\nprint(\"Score : \", round(logreg.score(X_train, y_train) * 100, 2) )\n\nprint(\"Accuracy Score : \", round(accuracy_score(y_valid, Y_valid_pred_lr) * 100, 2) )\n\nprint(\"Confusion Matrix : \" )\ndisplay( confusion_matrix(y_valid, Y_valid_pred_lr) )\n\nprint(\"ROC AUC Score : \", roc_auc_score(y_valid, Y_valid_pred_lr) )","e2c7d6ad":"acc_lm = round(logreg.score(X_train, y_train) * 100, 2) ","dd470d11":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred_dt = decision_tree.predict(X_valid)\nacc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)","65f44b6d":"acc_decision_tree","c029c758":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=10)\nrandom_forest.fit(X_train, y_train)\nY_pred_rf = random_forest.predict(X_valid)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n","3d6dc0b7":"acc_random_forest","0bae3edf":"modelling_score = pd.DataFrame({\n    'Model': ['Linear Regression','Random Forest','Decision Tree'],\n    'Score': [acc_lm, acc_random_forest, acc_decision_tree]})","3be722fa":"modelling_score.sort_values(by='Score', ascending=False)","3ff13f5b":"cm_lr = confusion_matrix(y_valid, Y_valid_pred_lr)","e39d8ed3":"sns.set(font_scale=1.4) # for label size\nsns.heatmap(cm_lr, annot=True, annot_kws={\"size\": 12}) # font size\n\nplt.show()","ea4bda62":"cm_rf = confusion_matrix(y_valid, Y_pred_rf)\ncm_dt = confusion_matrix(y_valid, Y_pred_dt)","990eae6a":"fig, (ax1, ax2, ax3) = plt.subplots(figsize=(20,5), ncols=3, nrows=1)\nsns.heatmap(cm_lr, ax=ax1, annot=True, annot_kws={\"size\": 12})\nsns.heatmap(cm_rf, ax=ax2, annot=True, annot_kws={\"size\": 12})\nsns.heatmap(cm_dt, ax=ax3, annot=True, annot_kws={\"size\": 12})\nplt.show()","12475cd3":"# from sklearn.metrics import precision_recall_curve\n# from sklearn.metrics import plot_precision_recall_curve","d107c577":"# # draw precison recall curves\n# classifiers = [(decision_tree,'DecisionTreeClassifier'),\n#                (random_forest,'RandomForestClassifier'),\n#                (logreg,'LogisticRegression')\n#                 ]\n# # plt.precision_recall_curve(X_train,y_train,X_valid,y_valid,classifiers)\n# disp = plot_precision_recall_curve(classifiers, X_valid, y_valid)\n# disp.ax_.set_title('2-class Precision-Recall curve: '\n#                    'AP={0:0.2f}'.format(average_precision))","409ef04c":"**Split the Dataset**","6cb0302a":"Seems the last row of the dataset is invalid row \/ record and should be removed. We should check whether the same problem is in the other records, and if so fix it too.","d9a5a826":"Look at correlations between features and the label","06d269e1":"The distribution of lead times is right skewed. Most lead times fall in the range 0-20. It should be OK to assume that samples with missing lead times will have lead times close to the median lead time.","b4bd9ec1":"# My Observations:\n* Very last record is inavlid.. need to delete.\n* The numerical features have different scales, which may be a problem for some machine learning algorithms. The features should be rescaled to have similar scale.\n* The `sku` has a unique value for each row, so we can it as the index column or drop it and use the existing index.\n* The features with string values, except `sku`, are categorical features that has 'yes' and 'no'. We can change it to 1 & 0.\n* There are missing values in `lead_time`. Option 1 : Replace the missing value with mean or 0 or any other value using some technique. Option 2: The records with missing values need to be removed \/delete.\n* lead_time has 100894 i.e. 6% missing values.\n* Out of 1687861, only 11293 i.e., 0.6% of data is Out of Stock (Flag as Yes... as product did go on backorder), and more than 99% is in Stock (Flag as No.. ie product did not go on backorder).","3966ca01":"Though we do have a good score which is above 90%... but if we check the Confusion Matrix... which depicts that mostly the data \/ predicting falls as True Positive (0,0) ie in actual the Product was not placed Back-Order, and model predicted correctly. Next is False Positive (1,0), yes again its similar in all 3 models, in actual the product was placed on Back-Order and model predicted as No Back-Order which is very less.\nNext is False Negative (0,1), for Linear Regression it was zero, where as for Decision Tree and Random Forest, there are few values in it. Seems in actual the product was not Back-Order, but model predicted it as Back-Order.\nand finally True Negative (1,1), where for DT and RF model predicted as Back Order and Product was really in Back-Order.","9cd5a3df":"The correlation matrix shows that the `in_transit_qty`, `forecast_3_month`, `forecast_6_month`, `forecast_9_month`,  `sales_1_month`, `sales_3_month`, `sales_6_month`, `sales_9_month`, and `min_bank` are highly correlated.\nCheck the Reddish color in Heat Map.","eea629e4":"Looks like too many values... lets minimize it, and get only those which are interested to ours.","bd613e2e":"Cool... none of them are missing now","260470b6":"Out of 1687861, only 11293 i.e., 0.6% of data is Out of Stock (Flag as Yes... as it went to BackOrder), and more than 99% is in Stock (Flag as No). So its result bias.","797005e7":"As mentioned in documentation... The data has 23 columns including 22 features and one target column. went_on_backorder is out Target.","e27e4f90":"**Model Performance**","9c76c568":"# Data cleaning","4142ab21":"This is a ML Competation from Hackathon - iNeroun.\n\nhttps:\/\/challenge-ineuron.in\/mlchallenge.php#\n\n    sku \u2013 \t\t \tRandom ID for the product\n    national_inv \u2013   \tCurrent inventory level for the part\n    lead_time \u2013 \t \tTransit time for product (if available)\n    in_transit_qty \u2013 \tAmount of product in transit from source\n    forecast_3_month \u2013 \tForecast sales for the next 3 months\n    forecast_6_month \u2013 \tForecast sales for the next 6 months\n    forecast_9_month \u2013 \tForecast sales for the next 9 months\n    sales_1_month \u2013 \tSales quantity for the prior 1 month time period\n    sales_3_month \u2013 \tSales quantity for the prior 3 month time period\n    sales_6_month \u2013 \tSales quantity for the prior 6 month time period\n    sales_9_month \u2013 \tSales quantity for the prior 9 month time period\n    min_bank \u2013 \t\tMinimum recommend amount to stock\n    potential_issue \u2013 \tSource issue for part identified\n    pieces_past_due \u2013 \tParts overdue from source\n    perf_6_month_avg \u2013 \tSource performance for prior 6 month period\n    perf_12_month_avg \u2013 \tSource performance for prior 12 month period\n    local_bo_qty \u2013 \t\tAmount of stock orders overdue\n    deck_risk \u2013 \t\tPart risk flag\n    oe_constraint \u2013 \tPart risk flag\n    ppap_risk \u2013 \t\tPart risk flag\n    stop_auto_buy \u2013 \tPart risk flag\n    rev_stop \u2013 \t\tPart risk flag\n    went_on_backorder \u2013 \tProduct actually went on backorder. This is the target value.","f335fca2":"Cool.. all are now integer or float.","4903c45d":"# Data visualisation","39fc5d23":"It looks like these sales_x_month are making a liner correlation with each other with some here-&-there.\n\nAnd also if we focus on the Back Order went_on_backorder as Yes (or 1), it seems backorder occurs only when the sales values are low.","7db19d10":"It looks like these forecasts are making a liner correlation with each other.\n\nAnd also if we focus on the Back Order `went_on_backorder` as Yes (or 1), it seems backorder occurs only when the forecast values are low.","60244a5a":"# Models","0410e761":"# Checking for Missing Values","bfb3d6d3":"# Change scale of data"}}