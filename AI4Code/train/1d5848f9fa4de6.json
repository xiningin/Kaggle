{"cell_type":{"c0245073":"code","b5c0a686":"code","2413ecf4":"code","fe978c99":"code","fabfa4cb":"code","387ccfa8":"code","34859413":"code","0c3b3d12":"code","5acf7c92":"code","e1f27b5f":"code","59d900dc":"code","521be616":"code","68a3067b":"code","983bd2e8":"code","5a0d3f32":"code","bdff0cce":"code","07289403":"markdown","f82663c1":"markdown","99afa09d":"markdown","244f0f43":"markdown","44d0a624":"markdown","167df3ed":"markdown","61c56d61":"markdown","a12ec800":"markdown","f6cd31a0":"markdown","e1a32901":"markdown"},"source":{"c0245073":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","b5c0a686":"df = pd.read_csv('..\/input\/classified-dataset\/Classified Data', index_col = 0)\ndf.head()","2413ecf4":"# Logistic Model training and Predicting\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nX = df[['WTT', 'PTI', 'EQW', 'SBI', 'LQE', 'QWG', 'FDJ', 'PJF', 'HQE', 'NXJ']]\ny = df['TARGET CLASS']\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 100)\n\nmodel = LogisticRegression()\nmodel.fit(train_X, train_y)\n\nprediction = model.predict(test_X)","fe978c99":"# Finding Accuracy\n\nprint(confusion_matrix(test_y, prediction))\nprint('\\n')\nprint(classification_report(test_y, prediction))","fabfa4cb":"df.head()","387ccfa8":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(df.drop(['TARGET CLASS'], axis = 1))\n\nscaled_feat = scaler.transform(df.drop(['TARGET CLASS'],axis = 1))\n\n#Final Standardised Data\ndf_feat = pd.DataFrame(scaled_feat, columns = df.columns[:-1])\ndf_feat.head()","34859413":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\ntrain_X,test_X, train_y, test_y = train_test_split(df_feat, df['TARGET CLASS'], test_size = 0.4, random_state = 100)\n\n\n# Model training\nmodel = KNeighborsClassifier(n_neighbors= 1) # Taking k value equals to 1\nmodel.fit(train_X, train_y)\n\npred = model.predict(test_X)","0c3b3d12":"# Finding Accuracy\n\nprint(confusion_matrix(test_y, pred))\nprint('\\n')\nprint(classification_report(test_y, pred))","5acf7c92":"# Using elbow method\n\nerror_rate = []\nfor i in range(1, 60):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_X, train_y)\n    pred_i = knn.predict(test_X)\n    error_rate.append(np.mean(pred_i != test_y))","e1f27b5f":"# Plotting various K values with respect to the error_rate, to find perfect K value\n\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.plot(range(1,60), error_rate, color = 'blue', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red',markersize = 10)\nplt.title('Error rate vs K value')\nplt.xlabel('K')\nplt.ylabel('Error rate')","59d900dc":"# Prediction with K=35\n\nmodel = KNeighborsClassifier(n_neighbors=35)\nmodel.fit(train_X, train_y)\n\npredict = model.predict(test_X)","521be616":"# Finding Accuracy\n\nprint(confusion_matrix(test_y, predict))\nprint('\\n')\nprint(classification_report(test_y, predict))","68a3067b":"# Importing SVM model and Predicting \n\nfrom sklearn.svm import SVC\n\nsvm_model = SVC()\nsvm_model.fit(train_X, train_y)\n\npredict = svm_model.predict(test_X)","983bd2e8":"# Accuracy \n\nprint(confusion_matrix(test_y, predict))\nprint('\\n')\nprint(classification_report(test_y, predict))","5a0d3f32":"# Importing the Grid Search model and predicting\n\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {'C':[0.1, 1, 10, 100, 1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001]}\n\ngrid = GridSearchCV(SVC(), param_grid=parameters)\n\n# Model Training\n\ngrid.fit(train_X, train_y)","bdff0cce":"predict = grid.predict(test_X)\n\n# Finding Accuracy\n\nprint(confusion_matrix(test_y, predict))\nprint('\\n')\nprint(classification_report(test_y, predict))","07289403":"Ooooooo....Now see, We got highest Accuracy with Grid Search... That's pretty good to see,,,haha","f82663c1":"# Prediction with SVM model","99afa09d":"# Choosing K value","244f0f43":"# Predicting using KNN model","44d0a624":"# Prediction with Logistic Regression","167df3ed":"Yeah.. Now we got 93%, in between Logistic and KNN... Ok let's go into the deeper with Grid Search by changing the C and gamma values...\n","61c56d61":"We got 92% accuracy with K=1, let's find the perfect value for K to get more accuracy..","a12ec800":"Let's take 35 is for K value to minimize the error rate","f6cd31a0":"We got 94% accuracy with K=35...Actually we got same percent accuracy with Logistic Regression.\nSo we can minimise the error rate by choosing the K value...which implies increase in accuracy percentage...","e1a32901":"We got 94% here with Logistic Regression...Let's go and check with other models accuracy.."}}