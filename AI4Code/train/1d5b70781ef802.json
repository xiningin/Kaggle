{"cell_type":{"bb90eed2":"code","e6b8faaf":"code","e6cbff5b":"code","455feb0e":"code","0af1db4c":"code","03e6e059":"code","3dfeffba":"code","948dc152":"code","94d589ba":"code","63767576":"code","bcdf3677":"code","58a41522":"code","38e0f49d":"code","b83f2b98":"code","5eb41a79":"code","0380af87":"code","dd49d18e":"code","1963d488":"code","f84c70d8":"code","88272a50":"code","bac97c73":"code","0477d592":"code","25d347ec":"code","11c966b4":"code","793e9546":"code","e566a9da":"code","fdbb95fe":"code","65513475":"code","437486b2":"code","224d7849":"code","151375b3":"code","3cc5e181":"code","70483a48":"code","6ccad8ae":"markdown","6bf96f24":"markdown","a1795b59":"markdown","fb3b60b8":"markdown","fe7469da":"markdown","d5b386de":"markdown","a8909eaf":"markdown","4c834571":"markdown","81b3c003":"markdown"},"source":{"bb90eed2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e6b8faaf":"heart_data = pd.read_csv('\/kaggle\/input\/heart-disease-data\/heart_disease_uci.csv')\nheart_data.head()","e6cbff5b":"# Drop the id and dataset columns\n\nheart_data.drop(['id','dataset'], axis=1, inplace=True)\nheart_data.info()","455feb0e":"# Display descriptive statistics\nheart_data.describe()","0af1db4c":"# Separate numeric and categorical variables for visualization purposes\nCATEGORICAL_COLS = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'ca']\nNUMERICAL_COLS = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n\nheart_cat = heart_data[CATEGORICAL_COLS]\nheart_num = heart_data[NUMERICAL_COLS]\n\nheart_cat.nunique()","03e6e059":"# Visualize the distribution of categorical variables \nfig, axes = plt.subplots(2, 4, figsize=(20,10))\n\nsns.countplot(x='sex', data=heart_cat, ax=axes[0,0])\naxes[0,0].set_title('Gender Distribution')\n\nsns.countplot(x='cp', data=heart_cat, ax=axes[0,1])\naxes[0,1].tick_params(axis='x', rotation=45)\naxes[0,1].set_title('Chest Pain Types')\n\nsns.countplot(x='fbs', data=heart_cat, ax=axes[0,2])\naxes[0,2].set_title('Fasting Blood Sugar > 120 mg\/dl')\n\nsns.countplot(x='restecg', data=heart_cat, ax=axes[0,3])\naxes[0,3].set_title('Resting Electrocardiographic Results')\n\nsns.countplot(x='exang', data=heart_cat, ax=axes[1,0])\naxes[1,0].set_title('Exercise Induced Angina')\n\nsns.countplot(x='slope', data=heart_cat, ax=axes[1,1])\naxes[1,1].set_title('Slope of the Peak Exercise ST Segment')\n\nsns.countplot(x='thal', data=heart_cat, ax=axes[1,2])\naxes[1,2].set_title('Defects')\n\nsns.countplot(x='ca', data=heart_cat, ax=axes[1,3])\naxes[1,3].set_title('Number of Major Vessels colored by Fluoroscopy')\nplt.tight_layout()\nplt.show()","3dfeffba":"# Use scatterplots to visualize key relationships in numerical data\nfig, axes = plt.subplots(2, 2, figsize=(10,10))\n\nheart_num.plot('age', 'chol', kind='scatter', ax=axes[0,0])\naxes[0,0].set_title('Age Against Cholesterol Levels')\n\nheart_num.plot('age', 'trestbps', kind='scatter', ax=axes[0,1])\naxes[0,1].set_title('Age Against Resting Blood Pressure')\n\nheart_num.plot('age', 'thalch', kind='scatter', ax=axes[1,0])\naxes[1,0].set_title('Age Against Maximum Heart Rate Achieved')\n\nheart_num.plot('age', 'oldpeak', kind='scatter', ax=axes[1,1])\naxes[1,1].set_title('Age Against ST Depression')\n\nplt.tight_layout()\nplt.show()","948dc152":"fig, axes = plt.subplots(3, figsize=(7,10))\n\nsns.scatterplot(x='chol', y='thalch', hue='num', data=heart_data, ax=axes[0])\naxes[0].set_title('Affect of Cholesterol on Maximum Heart Rate')\n\nsns.scatterplot(x='chol', y='thalch', hue='sex', data=heart_data, ax=axes[1])\n\nsns.scatterplot(x='chol', y='thalch', hue='restecg', data=heart_data, ax=axes[2])\nplt.show()","94d589ba":"sns.scatterplot(x='trestbps', y='thalch', hue='restecg', data=heart_data)\nplt.show()","63767576":"fig, axes = plt.subplots(3, figsize=(7,10))\n\naxes[0].set_title('Affect of Cholesterol on Resting Blood Pressure')\nsns.scatterplot(x='chol', y='trestbps', hue='num', data=heart_data, ax=axes[0])\nsns.scatterplot(x='chol', y='trestbps', hue='sex', data=heart_data, ax=axes[1])\nsns.scatterplot(x='chol', y='trestbps', hue='restecg', data=heart_data, ax=axes[2])\n\nplt.tight_layout()\nplt.show()","bcdf3677":"heart_data.groupby('num').mean()","58a41522":"print('Average Cholesterol Level Based on Target Variable and Chest Pain Type')\nprint(pd.crosstab(index=heart_data.num, columns=heart_data.cp, values=heart_data.chol, aggfunc=np.mean))\nprint('\\n')\n\nprint('Average Cholesterol Level Based on Target Variable and Patient Gender')\nprint(pd.crosstab(index=heart_data.num, columns=heart_data.sex, values=heart_data.chol, aggfunc=np.mean))\nprint('\\n')\n\nprint('Average Cholesterol Level Based on Target Variable and Cardiographic Results')\nprint(pd.crosstab(index=heart_data.num, columns=heart_data.restecg, values=heart_data.chol, aggfunc=np.mean))","38e0f49d":"# Display correlation matrix and heatmap\ncorr = heart_data.corr()\nprint(corr)\n\nsns.heatmap(corr)\nplt.show()","b83f2b98":"# Display boxplot to visualize outliers in the data\n\nheart_data.boxplot()\nplt.show()","5eb41a79":"heart_data.loc[heart_data['chol']==0,:]","0380af87":"heart_df.info()","dd49d18e":"# Cholesterol Levels\n\nmedian_chol = heart_data.loc[heart_data['chol']!=0, 'chol'].median()\nheart_df = heart_data.fillna(value={'chol': median_chol})\nheart_df.loc[heart_df['chol']==0, 'chol'] = median_chol ","1963d488":"# Resting Blood Pressure\n\nmean_bp = heart_df.loc[heart_df['trestbps']!=0,'trestbps'].mean()\nheart_df = heart_df.fillna(value={'trestbps': mean_bp})\nheart_df.loc[heart_df['trestbps']==0, 'trestbps'] = mean_bp ","f84c70d8":"# Maximum Heart Rate\n\nmean_hr = heart_df.loc[heart_df['thalch']!=0,'thalch'].mean()\nheart_df = heart_df.fillna(value={'thalch': mean_hr})\nheart_df.loc[heart_df['thalch']==0, 'thalch'] = mean_hr","88272a50":"# Old Peak\n\nmean_peak = heart_df.oldpeak.mean()\nheart_df = heart_df.fillna(value={'oldpeak': mean_peak})\nheart_df.loc[heart_df['oldpeak']==0, 'oldpeak'] = mean_peak","bac97c73":"# Drop columns with a great number of missing values and reassign datatypes\n\nheart_df.drop(labels=['ca','thal','slope'], axis=1, inplace=True)\nheart_df = heart_df.astype({'sex':'category', 'cp':'category', 'fbs':'bool', 'restecg':'category', 'exang':'bool'})\n\n# Drop remaining rows with missing values and display distribution for target variables\n\nheart_df.dropna(inplace=True)\nsns.countplot('num', data=heart_df)\nplt.show()","0477d592":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","25d347ec":"# One hot encode the categorical variables and split the target and independent variables\nheart_onehot = pd.get_dummies(heart_df, columns=['sex','cp', 'fbs', 'restecg', 'exang'])\n\nX = heart_onehot.drop('num', axis=1)\ny = heart_onehot.num\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ny_train.value_counts()","11c966b4":"heart_onehot.info()","793e9546":"from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier","e566a9da":"weights = {0:1, 1:0.5, 2:0.5, 3:0.5, 4:0.5}\n\nclf = DecisionTreeClassifier(criterion='entropy', max_depth=5)\nclf = clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","fdbb95fe":"# Perform Decision Tree model with class weighting\nweights = {0:1, 1:0.5, 2:0.5, 3:0.5, 4:0.5}\n\nclf = DecisionTreeClassifier(criterion='entropy', max_depth=5, class_weight='balanced')\nclf = clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","65513475":"gradient_booster = GradientBoostingClassifier(learning_rate=0.02, max_depth=3, n_estimators=150)\ngradient_booster.fit(X_train, y_train)\ny_pred = gradient_booster.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","437486b2":"clf = RandomForestClassifier(n_estimators=150)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","224d7849":"clf = RandomForestClassifier(n_estimators=150, class_weight='balanced_subsample')\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","151375b3":"from imblearn.over_sampling import SMOTE","3cc5e181":"smt = SMOTE(sampling_strategy='not majority')\n\nprint('Before', y_train.value_counts())\n\nX_train_SM, y_train_SM = smt.fit_resample(X_train, y_train)\n\nval, counter = np.unique(y_train_SM, return_counts=True)\nprint('After', (val, counter))","70483a48":"clf = DecisionTreeClassifier(criterion='entropy', max_depth=6)\nclf.fit(X_train_SM, y_train_SM)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","6ccad8ae":"# Exploratory Data Analysis","6bf96f24":"## Gradient Boosting","a1795b59":"# Conclusion\nImbalanced multi-class classification problems can prove to be a challenge for data scientists looking to provide accurate models for real-world problems. Using accuracy is misleading in this case as it does not describe the performance of our model across each of the target variables. The f1 score is a more reliable metric as it calculates the percentage of positive predictions that are correct for each target variable.\n\nThe two techniques used for our models (SMOTE and Class-Weighting) did not show major improvements to our results. We note that the Decision Tree with SMOTE performed worse than the original model. Class-Weighting did not raise the accuracy of our model, however we notice a slight improvement in the f1 score of the minority classes. \n\n***Moving Forward***\\\nAfter running these models, there are several steps we can take to improve our performance. I would love to use hyperparameter tuning methods such as GridSearch or Bayesian Optimization to fine tune the models. I believe that class weighting is a powerful tool and I plan on conducting a survey centered around classification models for various weights. While the results for SMOTE were disappointing, I believe it was due to the lack of original data for the minority classes (there were roughly 20 patients identified with a type 4 heart disease). Lack of data on such a scale would surely diminish the effectiveness of SMOTE. I am curious to see how SMOTE performs on a slightly larger dataset. I would also like to see how the model would performs with oversampling + cross validation.\n\nAs a parting notion, I believe that reworking this dataset into a binary classification problem would yield more promising results and is an exercise that I wish to tackle in the near future. If you've made it to this point, thanks for joining me on my data science journey. Feel free to leave any criticisms or suggestions as all feedback is welcome!","fb3b60b8":"## Preparing the Data for Model Training","fe7469da":"## Random Forest Classifier","d5b386de":"## Decision Tree With SMOTE","a8909eaf":"# Data Cleaning\n\nIn this section we will drop columns with a considerable amount of missing data as well as impute data where necessary. We do not wish to drop any outliers beyond logical reason. For example, we may not drop or impute values for patients with cholesterol levels ~500 since such high values make sense for the given data set. However, patients with cholesterol levels at 0 may be erroneous entries.","4c834571":"As we can see, our dataset is greatly imbalanced. We must be mindful that the accuracy of the models we implement will be misleading. We will explore several methods for dealing with imbalanced data including SMOTE oversampling and the adjusting of Class Weights to tackle this issue","81b3c003":"## Decision Tree Classifier"}}