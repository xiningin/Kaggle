{"cell_type":{"498a99bd":"code","1d726ad2":"code","974fc3ce":"code","3f856748":"code","4113e98a":"code","f6c70b9d":"code","8e3a183f":"code","a0f6282a":"code","6cfb0265":"code","31e2bd7c":"code","1afd7a2a":"code","a8c7d9c3":"code","9c1f22cd":"markdown","969799b3":"markdown","857de0a1":"markdown","e4682f92":"markdown"},"source":{"498a99bd":"import pandas as pd  # data analysis library\nimport numpy as np  # comprehensive mathematical functions, random number generators, linear algebra routines, Fourier transforms, and more\n\n#nlp\nimport string  # working with string constants\nimport re  # regular expressions\nimport nltk  # Natural Language Toolkit\n# NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, \n# along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, \n# and an active discussion forum.\nfrom nltk.corpus import stopwords  # In natural language processing, useless words (data), are referred to as stop words. \n\n\n# import matplotlib.pyplot as plt  # provides an implicit way of plotting\n# import seaborn as sns  # for visualization\n# from tqdm import tqdm  # progressbar decorator for iterators\n# import os  # for operating system\n\n# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator  # word cloud building library\n\n# import warnings  # error processing\n# warnings.filterwarnings(\"ignore\")\n\n# from collections import defaultdict  # if the key is not found in the method, then a new entry is created instead of KeyError. The type of this new entry is specified by the defaultdict argument.\n\n# from itertools import cycle  # contains some inbuilt functions for generating sequences using iterators\n# plt.style.use('ggplot')\n# color_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\n# color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n\n\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)\npd.set_option('max_rows', None)","1d726ad2":"# Look at the data names and size\n!ls -Flash --color ..\/input\/jigsaw-toxic-severity-rating\/","974fc3ce":"val = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')\nprint(f'Validation Data csv is of shape: {val.shape}')","3f856748":"val.head(20)","4113e98a":"import nltk\nfrom nltk.corpus import stopwords\n# stop = stopwords.words('english')\n\n\ndef clean_text(text):\n    text = text.lower()  # convert to lower case\n    \n    # remove unnecessary characters and words\n    text = text.replace('\\n', ' ')\n    text = text.replace('(\\xa0)', ' ')\n    text = text.replace('(&lt)', '')\n    text = text.replace('(&gt)', '')\n    text = text.replace(\"\\\\\", \"\")\n    \n    # process links to sites\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)  # with or without(http),:\/\/, one or more non-white space character, OR www, .,one or more non-white space character\n    text = text.replace(\"http:\/\/\", \"\")\n    text = text.replace(\"www.\", \"\")\n    text = text.replace(\"https:\/\/\", \"\")\n    text = text.replace(\"wikipedia.org\", \"\")\n    \n    # Replace symbols\n    text = text.replace(\"$\", \"s\") \n    text = text.replace(\"@\", \"a\")    \n    text = text.replace(\"!\", \" ! \")\n    text = text.replace(\"?\", \" ? \")    \n    \n\n    # Replace character combinations\n    text = re.sub(r'<[^<]+?>', '', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'<[^<]+?>', '', text) \n\n#     text = re.sub(\"[0-9]\", '', text)  # remove all numbers\n# a lot of uncensored words are written using numbers, simply deleting which we will lose important information\n# '4r5e':'arse', 'ar5e':'arse', '5h1t':'shit', '5hit': 'shit', 'a55':'ass', b!tch, 'c0ck' d1ck f_u_c_k, l3i+ch, l3itch, ma5terb8 #OFC - Of fuckin course\n    # text = re.sub('\\d', ' ', text)  # remove all numbers\n    # text = re.sub(\"\\D\", '', text)  # delete everything except the number\n    text = text.replace(\"4\", \"a\") \n    text = text.replace(\"5\", \"s\") \n    text = text.replace(\"1\", \"i\") \n    text = text.replace(\"!\", \"i\") \n    text = text.replace(\"|\", \"i\") \n    text = text.replace(\"0\", \"o\") \n    text = text.replace(\"l3\", \"b\") \n    text = text.replace(\"7\", \"t\") \n    text = text.replace(\"7\", \"+\") \n    text = text.replace(\"8\", \"ate\") \n    text = text.replace(\"3\", \"e\") \n    text = text.replace(\"9\", \"g\")\n    text = text.replace(\"6\", \"g\")\n    \n    \n    \n    \n    text = re.sub(r'\\b[uU]\\b', 'you', text)\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n    \n\n    # text = re.sub('\\W', ' ', text)  # will remove any character except Latin, numbers or underscore;\n    # text = re.sub('\\w', ' ', text) # this entry will remove all letters - it will help you see how many punctuation marks and other symbols are used\n    text = re.sub('\\s+', ' ', text)  # will remove more than one whitespace character\n    # text = re.sub('\\S+', ' ', text)  # will remove everything except the whitespace character.\n    \n    text = re.sub(r'\\b([^\\W\\d_]+)(\\s+\\1)+\\b', r'\\1', re.sub(r'\\W+', ' ', text).strip(), flags=re.I)  # remove repeating words coming immediately one after another\n    # text = re.sub(r'([a-z])\\2+', r'\\1', text)  # remove all repeating characters going one by (more than two letters)\n\n#     text = re.sub(r'(.)\\1+', r'\\1', text)  # remove all repeated characters one by one (more than two characters)\n#     text = re.sub(r'(\\w)\\1(\\1+)',r'\\1',text)\n#     text = re.sub(r\"(\\w)\\1{2,}\", r\"(\\w)\\1{2}\", text) \n    text = re.sub(r'(.)\\1+', r'\\1\\1', text) # 2 or more characters are replaced by 2 characters\n    \n    text = re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', text, flags = re.I)\n    \n    # Regular expression        r '((\\ b \\ w + \\ b. {1,2} \\ w + \\ b) +). + \\ 1'\n    # finds each occurrence of multiple sequences of alphanumeric characters separated by one or two [any characters] \n    # (to cover the case where words are separated not only by a space, but possibly a period or comma and a space), \n    # and then repeats after doing some [any character ] of indeterminate length. Then\n    \n    # re.sub(r '((\\ b \\ w + \\ b. {1,2} \\ w + \\ b) +). + \\ 1', r '\\ 1', s, flags = re.I)\n    # replaces such occurrences with the first multiple set of alphanumeric characters, separated by one or two [any character], \n    # be sure to ignore case (since a repeated phrase can sometimes appear at the beginning of a sentence).\n\n    \n    text = re.sub(\"[:|\u2663|'|\u00a7|\u2660|*|\/|?|=|%|&|-|#|\u2022|~|^|>|<|\u25ba|_]\", '', text)\n    text = text.strip(' ')  # will remove spaces at the beginning and end of the line\n\n    \n#     print(stopwords.words('english'))  # view all stop words\n    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')  # formula\n    text = pattern.sub('', text)  # dell oll stop words\n        \n    \n    return text\n\n    \n#     in process","f6c70b9d":"val['less_toxic'] = val['less_toxic'].apply(clean_text)\nval['more_toxic'] = val['more_toxic'].apply(clean_text)\n","8e3a183f":"val[0:10]","a0f6282a":"# import modules Lemmatizer\nfrom nltk.stem import WordNetLemmatizer\n \nlemmatizer = WordNetLemmatizer()\n \n# print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n# print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n \n# # a denotes adjective in \"pos\"\n# print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n\n\n# lemmatizer = nltk.stem.WordNetLemmatizer()  # Lemmatize using WordNet\u2019s built-in morphy function. Returns the input word unchanged if it cannot be found in WordNet.\n# Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context\n# to the words. So it links words with similar meanings to one word. \n#Text preprocessing includes both Stemming as well as Lemmatization. Many times people find these two terms confusing. Some treat these two as the same. Actually, lemmatization is preferred over\n# Stemming because lemmatization does morphological analysis of the words.\n\n\ndef lemmatize_text(text):\n    return lemmatizer.lemmatize(text)\n\n","6cfb0265":"val['less_toxic'] = val['less_toxic'].apply(lemmatize_text)\nval['more_toxic'] = val['more_toxic'].apply(lemmatize_text)\nval.head(10)\n\n# output list","31e2bd7c":"\n# import these modules\nfrom nltk.stem import PorterStemmer  \n# Stemming is the process of producing morphological variants of a root \/ base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. \n# A stemming algorithm reduces the words \u201cchocolates\u201d, \u201cchocolatey\u201d, \u201cchoco\u201d to the root word, \u201cchocolate\u201d and \u201cretrieval\u201d, \u201cretrieved\u201d, \u201cretrieves\u201d reduce to the stem \u201cretrieve\u201d.\n\n  \nps = PorterStemmer()\n     \n    \ndef stemmerize_text(text):   \n    return ps.stem(text)\n","1afd7a2a":"val['less_toxic'] = val['less_toxic'].apply(stemmerize_text)\nval['more_toxic'] = val['more_toxic'].apply(stemmerize_text)\nval.head(10)","a8c7d9c3":"def clean_text(text):\n    text = text.lower()  # convert to lower case\n    \n    # remove unnecessary characters and words\n    text = text.replace(' wo wo', ' woo woo ')\n    text = text.replace('numbskul', ' numbskull ')\n    \n    \n       \n    \n    return text\n\n","9c1f22cd":"### Clean Text\n\n-  \\ d - matches any one digit and replaces the expression [0-9];\n-  \\ D - excludes all digits and replaces [^ 0-9];\n-  \\ w - replaces any number, letter, or underscore;\n-  \\ W - any character except Latin, numbers or underscore;\n-  \\ s - matches any whitespace character;\n-  \\ S - describes any non-whitespace character.\n\n-  \".\"    \u0430ny single character except newline \\ n.\n-  \"?\"    0 or 1 occurrence of the pattern to the left\n-  \"+\"    1 or more occurrences of the pattern on the left\n-  \"*\"    0 or more occurrences of the pattern on the left\n-  \"\\w\"   Any number or letter (\\ W - everything except letter or number)\n-  \"\\d\"   Any digit [0-9] (\\ D - everything except a digit)\n-  \"\\s\"   Any whitespace character (\\ S is any non-whitespace character)\n-  \"\\b\"   Word boundary\n-  \"[..]\" One of the characters in brackets ([^ ..] - any character except those in brackets)\n-  \"\\\"    Escaping special characters (\\. Stands for period or \\ + for plus sign)\n-  \"^ and $\"      Beginning and end of line respectively\n-  \"{n, m}\"       n to m occurrences ({, m} - 0 to m)\n-  \"a | b\"        Matches a or b\n-  \"()\"           Groups the expression and returns the found text\n-  \"\\t, \\n, \\r\"    Tab, newline, and carriage return characters respectively","969799b3":"### Jigsaw pre-processing\nThe process of converting data to something a computer can understand is referred to as pre-processing. One of the major forms of pre-processing is to filter out useless data.","857de0a1":"### step2","e4682f92":"- by visualizing the data  https:\/\/www.kaggle.com\/andrej0marinchenko\/jigsaw-data-vizualization-for-beginnersv\n- analyzed the result https:\/\/www.kaggle.com\/c\/jigsaw-toxic-severity-rating\/discussion\/294164\n- concluded that it was necessary to pre-process the text before toxicity analysis"}}