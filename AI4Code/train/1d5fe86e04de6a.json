{"cell_type":{"e0a954c6":"code","8fa57920":"code","4dc14543":"code","ad04510a":"code","9946a142":"code","43964415":"code","77230bb1":"code","5c147cef":"code","1f5f63e3":"code","fb3170bf":"code","3114935f":"code","3f1c87e4":"code","93e78151":"code","16523ffc":"code","9530553d":"code","c94888cf":"code","2827104b":"code","0e74d9c2":"code","01047c02":"code","8a587eb9":"code","9694ea93":"code","32a7c6a7":"code","f67d681d":"code","735fa470":"code","fdaf9182":"code","64c28d1e":"code","4faaccd7":"code","f9b18f58":"code","3346e7bc":"code","61eae51c":"code","5af4ef5a":"code","7924e20c":"code","faf56a3a":"code","828f8c4f":"code","39f6c07f":"code","e55f4669":"code","9253fcb3":"code","4c62b687":"code","a6e7fad8":"code","16fdac57":"code","f0f88a3f":"code","8e32a818":"code","c3f80b7c":"code","bd045bb5":"code","7206d835":"code","8408e450":"code","2a974dbc":"code","8d066c82":"code","540e8558":"code","d5e7204e":"code","b0ba6d39":"code","0c7bd76f":"code","fcd54ca6":"code","470da373":"code","bd324bae":"code","c7b4d877":"code","360ddbf0":"code","7b87f87d":"code","de18a6b5":"code","e00f984a":"code","6353b464":"code","73d02bdc":"code","8e19281f":"code","671cd98d":"code","87c52a48":"code","2170bbef":"code","9047d112":"code","d942b124":"code","df022a2e":"code","a5010ef8":"code","5b815d5a":"code","47663c90":"code","b5fbec8f":"code","bb52d0c0":"code","a16de852":"code","8fcf9a7d":"code","44d8aa32":"code","17c0b106":"code","39540f49":"code","64d88d79":"code","6e27cbe9":"code","2f6f1e11":"code","2a0aff3a":"code","a8956871":"code","d5926530":"code","5dd93156":"code","832dae0a":"code","832dd271":"code","d429a966":"code","d79a50aa":"code","57d13e40":"code","645a9ad4":"code","5df7ddef":"code","849afccd":"code","e4480b89":"markdown","2860671f":"markdown","b3939fc6":"markdown","c6b1bd2c":"markdown","bd5b7249":"markdown"},"source":{"e0a954c6":"# Python \u22653.5 is required\nimport sys\nassert sys.version_info >= (3, 5)\n\n# Scikit-Learn \u22650.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# Common imports\nimport numpy as np\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n# Where to save the figures\nPROJECT_ROOT_DIR = \".\"\nCHAPTER_ID = \"end_to_end_project\"\nIMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\nos.makedirs(IMAGES_PATH, exist_ok=True)\n\ndef save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n    print(\"Saving figure\", fig_id)\n    if tight_layout:\n        plt.tight_layout()\n    plt.savefig(path, format=fig_extension, dpi=resolution)\n\n# Ignore useless warnings (see SciPy issue #5998)\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")","8fa57920":"import os\nimport tarfile\nfrom six.moves import urllib\n\nDOWNLOAD_ROOT = \"https:\/\/raw.githubusercontent.com\/ageron\/handson-ml2\/master\/\"\nHOUSING_PATH = os.path.join(\"datasets\", \"housing\")\nHOUSING_URL = DOWNLOAD_ROOT + \"datasets\/housing\/housing.tgz\"\n\ndef fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n    if not os.path.isdir(housing_path):\n        os.makedirs(housing_path)\n    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n    urllib.request.urlretrieve(housing_url, tgz_path)\n    housing_tgz = tarfile.open(tgz_path)\n    housing_tgz.extractall(path=housing_path)\n    housing_tgz.close()","4dc14543":"fetch_housing_data()","ad04510a":"import pandas as pd\n\ndef load_housing_data(housing_path=HOUSING_PATH):\n    csv_path = os.path.join(housing_path, \"housing.csv\")\n    return pd.read_csv(csv_path)","9946a142":"housing = load_housing_data()\nhousing.head()","43964415":"housing.info()","77230bb1":"housing[\"ocean_proximity\"].value_counts()","5c147cef":"housing.describe()","1f5f63e3":"%matplotlib inline\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50, figsize=(20,15))\nsave_fig(\"attribute_histogram_plots\")\nplt.show()","fb3170bf":"# to make this notebook's output identical at every run\nnp.random.seed(42)","3114935f":"import numpy as np\n\n# For illustration only. Sklearn has train_test_split()\ndef split_train_test(data, test_ratio):\n    shuffled_indices = np.random.permutation(len(data))\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffled_indices[:test_set_size]\n    train_indices = shuffled_indices[test_set_size:]\n    return data.iloc[train_indices], data.iloc[test_indices]","3f1c87e4":"train_set, test_set = split_train_test(housing, 0.2)\nlen(train_set)","93e78151":"len(test_set)","16523ffc":"from zlib import crc32\n\ndef test_set_check(identifier, test_ratio):\n    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n\ndef split_train_test_by_id(data, test_ratio, id_column):\n    ids = data[id_column]\n    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n    return data.loc[~in_test_set], data.loc[in_test_set]","9530553d":"import hashlib\n\ndef test_set_check(identifier, test_ratio, hash=hashlib.md5):\n    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio","c94888cf":"def test_set_check(identifier, test_ratio, hash=hashlib.md5):\n    return bytearray(hash(np.int64(identifier)).digest())[-1] < 256 * test_ratio","2827104b":"housing_with_id = housing.reset_index()   # adds an `index` column\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")","0e74d9c2":"housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")","01047c02":"test_set.head()","8a587eb9":"from sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","9694ea93":"test_set.head()","32a7c6a7":"housing[\"median_income\"].hist()","f67d681d":"housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n                               labels=[1, 2, 3, 4, 5])","735fa470":"housing[\"income_cat\"].value_counts()","fdaf9182":"housing[\"income_cat\"].hist()","64c28d1e":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","4faaccd7":"strat_test_set[\"income_cat\"].value_counts() \/ len(strat_test_set)","f9b18f58":"housing[\"income_cat\"].value_counts() \/ len(housing)","3346e7bc":"def income_cat_proportions(data):\n    return data[\"income_cat\"].value_counts() \/ len(data)\n\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n\ncompare_props = pd.DataFrame({\n    \"Overall\": income_cat_proportions(housing),\n    \"Stratified\": income_cat_proportions(strat_test_set),\n    \"Random\": income_cat_proportions(test_set),\n}).sort_index()\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] \/ compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] \/ compare_props[\"Overall\"] - 100","61eae51c":"compare_props","5af4ef5a":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)","7924e20c":"housing = strat_train_set.copy()","faf56a3a":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\nsave_fig(\"bad_visualization_plot\")","828f8c4f":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\nsave_fig(\"better_visualization_plot\")","39f6c07f":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n    s=housing[\"population\"]\/100, label=\"population\", figsize=(10,7),\n    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()\nsave_fig(\"housing_prices_scatterplot\")","e55f4669":"corr_matrix = housing.corr()","9253fcb3":"corr_matrix[\"median_house_value\"].sort_values(ascending=False)","4c62b687":"# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\nfrom pandas.plotting import scatter_matrix\n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_matrix(housing[attributes], figsize=(12, 8))\nsave_fig(\"scatter_matrix_plot\")","a6e7fad8":"housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n             alpha=0.1)\nplt.axis([0, 16, 0, 550000])\nsave_fig(\"income_vs_house_value_scatterplot\")","16fdac57":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"]\/housing[\"households\"]\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]\/housing[\"total_rooms\"]\nhousing[\"population_per_household\"]=housing[\"population\"]\/housing[\"households\"]","f0f88a3f":"corr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","8e32a818":"housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\nhousing_labels = strat_train_set[\"median_house_value\"].copy()","c3f80b7c":"sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nsample_incomplete_rows","bd045bb5":"median = housing[\"total_bedrooms\"].median()\nsample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3","7206d835":"sample_incomplete_rows","8408e450":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")","2a974dbc":"housing_num = housing.drop(\"ocean_proximity\", axis=1)\n# alternatively: housing_num = housing.select_dtypes(include=[np.number])","8d066c82":"imputer.fit(housing_num)","540e8558":"imputer.statistics_","d5e7204e":"housing_num.median().values","b0ba6d39":"X = imputer.transform(housing_num)","0c7bd76f":"housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index = list(housing.index.values))","fcd54ca6":"housing_tr.loc[sample_incomplete_rows.index.values]","470da373":"imputer.strategy","bd324bae":"housing_tr = pd.DataFrame(X, columns=housing_num.columns)","c7b4d877":"housing_tr.head()","360ddbf0":"housing_cat = housing[[\"ocean_proximity\"]]\nhousing_cat.head(10)","7b87f87d":"from sklearn.preprocessing import OrdinalEncoder\n\nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\nhousing_cat_encoded[:10]","de18a6b5":"ordinal_encoder.categories_","e00f984a":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1hot","6353b464":"housing_cat_1hot.toarray()","73d02bdc":"cat_encoder.categories_","8e19281f":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# column index\nrooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] \/ X[:, households_ix]\n        population_per_household = X[:, population_ix] \/ X[:, households_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)\n            ","671cd98d":"housing_extra_attribs = pd.DataFrame(\n    housing_extra_attribs,\n    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"])\nhousing_extra_attribs.head()","87c52a48":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('attribs_adder', CombinedAttributesAdder()),\n        ('std_scaler', StandardScaler()),\n    ])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","2170bbef":"housing_num_tr","9047d112":"from sklearn.compose import ColumnTransformer\n\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", OneHotEncoder(), cat_attribs),\n])\nhousing_prepared = full_pipeline.fit_transform(housing)","d942b124":"housing_prepared","df022a2e":"housing_prepared.shape","a5010ef8":"#select and train a model\n","5b815d5a":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","47663c90":"some_data= housing.iloc[:5]\nsome_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)\n\nprint(\"Predictions:\", lin_reg.predict(some_data_prepared))","b5fbec8f":"print(\"Labels:\", list(some_labels))","bb52d0c0":"from sklearn.metrics import mean_squared_error\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","a16de852":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(housing_prepared, housing_labels)","8fcf9a7d":"housing_predictions = tree_reg.predict(housing_prepared)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","44d8aa32":"#fine tune model","17c0b106":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","39540f49":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","64d88d79":"display_scores(tree_rmse_scores)","6e27cbe9":"lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring = \"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","2f6f1e11":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\nforest_reg.fit(housing_prepared, housing_labels)","2a0aff3a":"housing_predictions = forest_reg.predict(housing_prepared)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","a8956871":"from sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)","d5926530":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators':[3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2, 3, 4]},\n]\nforest_reg = RandomForestRegressor()\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search.fit(housing_prepared, housing_labels)","5dd93156":"grid_search.best_params_","832dae0a":"grid_search.best_estimator_","832dd271":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","d429a966":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","d79a50aa":"extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","57d13e40":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)","645a9ad4":"final_rmse","5df7ddef":"#We can compute a 95% confidence interval for the test RMSE:","849afccd":"from scipy import stats\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test)**2\nnp.sqrt(stats.t.interval(confidence, len(squared_errors) - 1, loc = squared_errors.mean(), scale=stats.sem(squared_errors)))\n                                   ","e4480b89":"Transform the training set:","2860671f":"By default, the `OneHotEncoder` class returns a sparse array, but we can convert it to a dense array if needed by calling the `toarray()` method:","b3939fc6":"Check that this is the same as manually computing the median of each attribute:","c6b1bd2c":"Now let's preprocess the categorical input feature, `ocean_proximity`:","bd5b7249":"Remove the text attribute because median can only be calculated on numerical attributes:"}}