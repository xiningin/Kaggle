{"cell_type":{"c7c0555a":"code","f91e1cfb":"code","51bd1bb5":"code","0c970ed8":"code","84e5bf3c":"code","5db2184f":"code","8d7da736":"code","8c035625":"code","3938890f":"code","610d93bf":"code","62a299a4":"code","8ba57473":"code","d84f67f9":"code","4a9f6d90":"code","2e2768ee":"code","0089de81":"code","e2d80147":"code","144fd449":"code","1a48af3c":"code","14e5ab4a":"code","f9a2e658":"code","23f10cd8":"code","6d4144df":"code","f3e3895a":"code","a320c321":"code","396778e4":"code","4787b913":"markdown","ee1a4b90":"markdown","ae34c8f5":"markdown","b6e6d3d4":"markdown","bf5a3805":"markdown"},"source":{"c7c0555a":"!pip install git+https:\/\/github.com\/qubvel\/efficientnet","f91e1cfb":"import pandas as pd\nimport os","51bd1bb5":"# directory list\ntrain_path = '..\/input\/kue-indonesia\/train\/'\ntest_path = '..\/input\/kue-indonesia\/test\/'\nvalidation_path = '..\/input\/kue-indonesia\/validation\/'\nitems = os.listdir(train_path)\nitems","0c970ed8":"# create items path\ntrain_dir = []\ntest_dir = []\nvalidation_dir = []\nfor item in items :\n    train_dir.append(train_path + item + '\/')\n    test_dir.append(test_path + item + '\/')\n    validation_dir.append(validation_path + item + '\/')","84e5bf3c":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\n\nlabels = [(\" \").join(x.split('_')) for x in items]\n\nfig = plt.figure(figsize=(10,10))\nfig.suptitle(\"Some examples of the dataset\", fontsize=16)\ni = 1\nfor path in train_dir :\n    for j in range(2) :\n        img = mpimg.imread(path+os.listdir(path)[j])\n        size = min(img.shape[0], img.shape[1])\n        img = cv2.resize(img, (size,size))\n        \n        plt.subplot(4,4,i)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(img, cmap=plt.cm.binary)\n        plt.xlabel(labels[int((i-1)\/2)])\n        i += 1\nplt.show()","5db2184f":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAINING_DIR = train_path\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. ,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=16,\n                                                    class_mode='categorical',\n                                                    target_size=(150, 150))\n\nVALIDATION_DIR = validation_path\nvalidation_datagen = ImageDataGenerator( rescale = 1.0\/255. ,\n                                  rotation_range=40,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\nvalidation_generator = train_datagen.flow_from_directory(VALIDATION_DIR,\n                                                    batch_size=16,\n                                                    class_mode='categorical',\n                                                    target_size=(150, 150))\n\n\n","8d7da736":"TEST_DIR = test_path\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_directory(\n    TEST_DIR,\n    target_size=(150,150),\n    class_mode='categorical',\n    batch_size=10)","8c035625":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n\ndef callbacks(model_name):\n    cb = []\n\n    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n                                       factor=0.5, patience=1, \n                                       verbose=1, mode='min', \n                                       epsilon=0.0001, min_lr=0,\n                                       restore_best_weights=True)\n    cb.append(reduceLROnPlat)\n    \n    log = CSVLogger('log_{}.csv'.format(model_name))\n    cb.append(log)\n    \n    es = EarlyStopping(monitor='val_loss', patience=4, verbose=0,\n                       mode='min', restore_best_weights=True)\n    \n    cb.append(es)\n    \n    return cb","3938890f":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import RMSprop\nfrom efficientnet.tfkeras import EfficientNetB7\n\npre_trained_model = EfficientNetB7(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(150, 150, 3),\n    pooling='avg',\n)\n","610d93bf":"for layer in pre_trained_model.layers:\n    layer.trainable = False\n\n\nlast_layer = pre_trained_model.get_layer('avg_pool')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (8, activation='softmax')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = 'adam', \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","62a299a4":"history = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            epochs = 200,\n            verbose = 1,\n            callbacks = callbacks('model_efficientnetb7'))","8ba57473":"results = model.evaluate(test_generator)","d84f67f9":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc)) # Get number of epochs\n\nplt.figure()\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, label='Training accuracy')\nplt.plot(epochs, val_acc, label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss, label='Training loss' )\nplt.plot  ( epochs, val_loss, label='Validation loss' )\nplt.title ('Training and validation loss')\nplt.legend(loc=0)\n\nplt.show()","4a9f6d90":"model.save_weights('model_efficientnetb7.h5')","2e2768ee":"from efficientnet.tfkeras import EfficientNetB5\n\npre_trained_model = EfficientNetB5(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(150, 150, 3),\n    pooling='avg',\n)","0089de81":"for layer in pre_trained_model.layers:\n    layer.trainable = False\n\n\nlast_layer = pre_trained_model.get_layer('avg_pool')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (8, activation='softmax')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = 'adam', \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","e2d80147":"history = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            epochs = 200,\n            verbose = 1,\n            callbacks = callbacks('model_efficientnetb5'))","144fd449":"results = model.evaluate(test_generator)","1a48af3c":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc)) # Get number of epochs\n\nplt.figure()\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, label='Training accuracy')\nplt.plot(epochs, val_acc, label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss, label='Training loss' )\nplt.plot  ( epochs, val_loss, label='Validation loss' )\nplt.title ('Training and validation loss')\nplt.legend(loc=0)\n\nplt.show()","14e5ab4a":"model.save(\"model_efficientnetb5.h5\")","f9a2e658":"from efficientnet.tfkeras import EfficientNetB3\n\npre_trained_model = EfficientNetB3(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(150, 150, 3),\n    pooling='avg',\n)","23f10cd8":"for layer in pre_trained_model.layers:\n    layer.trainable = False\n\n\nlast_layer = pre_trained_model.get_layer('avg_pool')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (8, activation='softmax')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = 'adam', \n              loss = 'categorical_crossentropy', \n              metrics = ['accuracy'])","6d4144df":"history = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            epochs = 200,\n            verbose = 1,\n            callbacks = callbacks('model_efficientnetb3'))","f3e3895a":"results = model.evaluate(test_generator)","a320c321":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc)) # Get number of epochs\n\nplt.figure()\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, label='Training accuracy')\nplt.plot(epochs, val_acc, label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss, label='Training loss' )\nplt.plot  ( epochs, val_loss, label='Validation loss' )\nplt.title ('Training and validation loss')\nplt.legend(loc=0)\n\nplt.show()","396778e4":"model.save_weights('model_efficientnetb3.h5')","4787b913":"# Define Callbacks","ee1a4b90":"# EfficientNet B5","ae34c8f5":"# EfficientNetB3","b6e6d3d4":"# EfficientNet B7","bf5a3805":"# CNN Transfer Learning [Efficient Net]"}}