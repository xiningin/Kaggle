{"cell_type":{"3b1586ad":"code","66575794":"code","ff574545":"code","024fdb59":"code","65653af7":"code","f770c5b9":"code","bd85d195":"code","a2374c51":"code","d75604d9":"code","5de8cd3e":"code","b9c6eb43":"code","3d646e06":"code","564eaad2":"code","f1fa08cb":"code","f6325f06":"code","485f29ac":"code","e6cba208":"code","acf23c02":"code","5eb40db0":"code","e1a7a8ce":"code","5daddc89":"code","a53d7dac":"code","a2485cb5":"code","9648a0cd":"markdown","c6922c13":"markdown","2dc8f255":"markdown","2f4cb7e8":"markdown","70355eec":"markdown","f674b2e4":"markdown","5500df81":"markdown","56186973":"markdown","28d2db10":"markdown","c3abb622":"markdown","65bad5f2":"markdown","e3c944b9":"markdown","77ac7ce1":"markdown","345cb2f9":"markdown","83b763fe":"markdown","9736ed43":"markdown","a3509930":"markdown","d04c57bb":"markdown","20bfe1ec":"markdown","4733b5df":"markdown","1c3abb23":"markdown","791bbf85":"markdown","fed98442":"markdown","61627c9e":"markdown"},"source":{"3b1586ad":"import bq_helper \n\n# create a helper object for our bigquery dataset\nhacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n                                       dataset_name = \"hacker_news\")","66575794":"# print a list of all the tables in the hacker_news dataset\nhacker_news.list_tables()","ff574545":"# print information on all the columns in the \"full\" table\n# in the hacker_news dataset\nhacker_news.table_schema(\"full\")","024fdb59":"# preview the first couple lines of the \"full\" table\nhacker_news.head(\"full\")","65653af7":"# preview the first ten entries in the by column of the full table\nhacker_news.head(\"full\", selected_columns=\"by\", num_rows=10)","f770c5b9":"# this query looks in the full table in the hacker_news\n# dataset, then gets the score column from every row where \n# the type column has \"job\" in it.\nquery = \"\"\"SELECT score \n            FROM `bigquery-public-data.hacker_news.full`\n            WHERE type = \"job\" \"\"\"\n\n# check how big this query will be (in GB)\nhacker_news.estimate_query_size(query)","bd85d195":"# check out the scores of job postings (if the query is smaller than 1 gig)\njob_post_scores = hacker_news.query_to_pandas_safe(query)\njob_post_scores.head()","a2374c51":"# average score for job posts\njob_post_scores.score.mean()","d75604d9":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\nopen_aq = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                   dataset_name=\"openaq\")\n\n# print all the tables in this dataset (there's only one!)\nopen_aq.list_tables()","5de8cd3e":"# print the first couple rows of the \"global_air_quality\" dataset\nopen_aq.head(\"global_air_quality\")","b9c6eb43":"# query to select all the items from the \"city\" column where the\n# \"country\" column is \"us\"\nquery = \"\"\"SELECT city\n            FROM `bigquery-public-data.openaq.global_air_quality`\n            WHERE country = 'US'\n        \"\"\"\n\n# the query_to_pandas_safe will only return a result if it's less\n# than one gigabyte (by default)\nus_cities = open_aq.query_to_pandas_safe(query)","3d646e06":"# What five cities have the most measurements taken there?\nus_cities.city.value_counts().head()","564eaad2":"# Your code goes here :)\n\n","f1fa08cb":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\nhacker_news = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                   dataset_name=\"hacker_news\")\n\n# print the first couple rows of the \"comments\" table\nhacker_news.head(\"comments\")","f6325f06":"# query to pass to \nquery = \"\"\"SELECT parent, COUNT(id) as count\n            FROM `bigquery-public-data.hacker_news.comments`\n            GROUP BY parent\n            HAVING COUNT(id) > 10\n        \"\"\"\n\n# the query_to_pandas_safe method will cancel the query if\n# it would use too much of your quota, with the limit set \n# to 1 GB by default\npopular_stories = hacker_news.query_to_pandas_safe(query)\n\npopular_stories.head()","485f29ac":"# Your code goes here:\n","e6cba208":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\naccidents = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                   dataset_name=\"nhtsa_traffic_fatalities\")\n\n# query to find out the number of accidents which \n# happen on each day of the week\nquery = \"\"\"SELECT COUNT(consecutive_number) AS num_of_accidents, \n                  EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n            FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n            GROUP BY day_of_week\n            ORDER BY num_of_accidents DESC\n        \"\"\"\n\n# the query_to_pandas_safe method will cancel the query if\n# it would use too much of your quota, with the limit set \n# to 1 GB by default\naccidents_by_day = accidents.query_to_pandas_safe(query)","acf23c02":"# library for plotting\nimport matplotlib.pyplot as plt\n\n# make a plot to show that our data is, actually, sorted:\nplt.plot(accidents_by_day.num_of_accidents)\nplt.title(\"Number of Accidents by Rank of Day \\n (Most to least dangerous)\")\n\nprint(accidents_by_day)","5eb40db0":"# Your code goes here :)\n","e1a7a8ce":"# import package with helper functions \nimport bq_helper\n\n# create a helper object for this dataset\ngithub = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n                                              dataset_name=\"github_repos\")\n\n# You can use two dashes (--) to add comments in SQL\nquery = (\"\"\"\n        SELECT L.license, COUNT(sf.path) AS number_of_files\n        FROM `bigquery-public-data.github_repos.sample_files` as sf\n        INNER JOIN `bigquery-public-data.github_repos.licenses` as L \n            ON sf.repo_name = L.repo_name\n        GROUP BY L.license\n        ORDER BY number_of_files DESC\n        \"\"\")\n\nfile_count_by_license = github.query_to_pandas_safe(query, max_gb_scanned=6)\n\n# print out all the returned results\nprint(file_count_by_license)","5daddc89":"# Your code goes here :)\n","a53d7dac":"from google.cloud import bigquery\nimport pandas as pd\nimport bq_helper \nimport numpy as np\n%matplotlib inline\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nimport spacy\nnlp = spacy.load('en')\n\n# create a helper object for our bigquery dataset\nhacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n                                       dataset_name = \"hacker_news\")\n\n%matplotlib inline","a2485cb5":"hacker_news.head(\"stories\")","9648a0cd":"### Quiz 4\n___\n\nNow it's your turn! Here is the question I would like you to get the data to answer.\n\n*  (10pt) How many commits (recorded in the \"sample_commits\" table) have been made in repos written in the Python programming language? I'm looking for the number of commits per repo for all the repos written in Python.\n    * You'll want to JOIN the sample_files and sample_commits questions to answer this.\n    * **Hint:** You can figure out which files are written in Python by filtering results from the \"sample_files\" table using `WHERE path LIKE '%.py'`. This will return results where the \"path\" column ends in the text \".py\", which is one way to identify which files have Python code.","c6922c13":"## Get set up\nUse BigQuery client to acess public datasets hosted on Cloud.\n\n![](https:\/\/i.imgur.com\/biYqbUB.png)","2dc8f255":"### Check out the structure of your dataset\n____\n\nThe first thing you're going to want to do, like with any new dataset, is check out the way that data is structured. We're going to do that by looking at the schema.\n\n> **Schema**: A description of how data is organized within a dataset.","2f4cb7e8":"### Actually run a query\n___\n\nNow that we know how to check the size of the query (and make sure we're not scanning several terabytes of data!) we're ready to actually run our first query. You have two methods available to help you do this:\n\n* *`BigQueryHelper.query_to_pandas(query)`*: This method takes a query and returns a Pandas dataframe.\n* *`BigQueryHelper.query_to_pandas_safe(query, max_gb_scanned=1)`*: This method takes a query and returns a Pandas dataframe only if the size of the query is less than the upperSizeLimit (1 gigabyte by default). \n\nHere's an example of a query that is larger than the specified upper limit.","70355eec":"### Example: Which day of the week do the most fatal motor accidents happen on?\n___\n\nWe're going to be using the US Traffic Fatality Records database, which contains information on traffic accidents in the US where at least one person died. (It's definitely a sad topic, but if we can understand this data and the trends in it we can use that information to help prevent additional accidents.)","f674b2e4":"### Check the size of your query before you run it\n____\n\nOne way to help avoid running over quota is to estimate how big your query will be before you actually execute it. You can do this with the `BigQueryHelper.estimate_query_size()` method.","5500df81":"# What are SQL & BigQuery and why you should learn them?\n____\n\nSQL (short for \u201cStructured Query Language\u201d) is a programming language that allows you to interact with databases. For many databases out there, SQL is the *only* way to access the information in them and, as a result, it's an important skill for any data scientist or aspiring data scientist.\n\n> **Why learn SQL?**: If you're currently looking for a data science job, being able to show that you're comfortable with SQL will open up more job opportunities for you. If you're currently *doing* data science, brushing up on your SQL skills will help you access more data sources and make it easier to get a subset of a database to work with locally. Plus, it's fun! :)\n\n[BigQuery](https:\/\/cloud.google.com\/bigquery\/) is a Google Cloud product for storing and accessing very large databases very quickly. We've recently started making [some BigQuery datasets](https:\/\/www.kaggle.com\/datasets?filetype=bigQuery) accessible via Kaggle. Since SQL is the easiest way to access these data in these datasets they make the perfect playground to help you get comfortable with this language.\n\n>  Because the datasets on BigQuery can be very large, there are some restrictions on how much data you can access. The good news is that **each Kaggle user can scan 5TB every 30 days for free.** The bad news is that If you go over your quota you're going to have to wait for it to reset. ","56186973":"## JOIN\n___\n\nLet's keep working with our imaginary Pets dataset, but this time let's add a second table. The first table, \"Pets\", has three columns, with information on the ID number of each pet, the pet's name and the type of animal it is. The new table, \"Owners\", has three columns, with the ID number of each owner, the name of the owner and the ID number of their pet. \n\n![](https:\/\/i.imgur.com\/W4gYoNg.png)\n\nWe can join the two tables to have a new table. For example, we might want to have a single table with just two columns: one with the name of the pet and one with the name of the owner. This would look something like this: \n\n![](https:\/\/i.imgur.com\/zqQdJTI.png)\n\nThe syntax to create that table looks like this:\n\n    SELECT p.Name AS Pet_Name, o.Name as Owner_Name\n    FROM `bigquery-public-data.pet_records.pets` as p\n    INNER JOIN `bigquery-public-data.pet_records.owners` as o ON p.ID = o.Pet_ID\n\nThe type of JOIN we're using today is called an INNER JOIN. That just means that a row will only be put in the final output table if the value in the column you're using to combine them shows up in both the tables you're joining. For example, if Tom's ID code of 4 didn't exist in the `Pets` table, we would only get 3 rows back from this query. There are other types of JOIN, but an INNER JOIN won't give you an output that's larger than your input tables, so it's a good one to start with.   \n\n> **What does \"ON\" do?** It says which column in each table to look at to combine the tables. Here were using the \"ID\" column from the Pets table and the \"Pet_ID\" table from the Owners table.","28d2db10":"Now that we know what tables are in this dataset, we can get information on the columns in a specific table. In this example, we're looking at the information on the \"full\" table. \n\nEach SchemaField tells us about a specific column. In order, the information is:\n\n* The name of the column\n* The datatype in the column\n* [The mode of the column](https:\/\/cloud.google.com\/bigquery\/docs\/reference\/rest\/v2\/tables#schema.fields.mode) (NULLABLE means that a column allows NULL values, and is the default)\n* A description of the data in that column","c3abb622":"### Example: Which Hacker News comments generated the most discussion?\n___\n\nNow we're ready to work through an example on a real dataset. We're going to be using the Hacker News dataset, which contains information on stories & comments from the Hacker News social networking site. I want to know which comments on the site generated the most replies.","65bad5f2":"### Quiz 2\n___\n\nNow it's your turn! Here's the questions I would like you to get the data to answer:\n\n* (5pt) How many stories (use the \"id\" column) are there of each type (in the \"type\" column) in the full table?\n* (5pt) How many comments have been deleted?\n    * hint: use comments table and column 'deleted' (True if deleted empty if not).\n* (5pt) **Optional extra credit**: read about [aggregate functions other than COUNT()](https:\/\/cloud.google.com\/bigquery\/docs\/reference\/standard-sql\/functions-and-operators#aggregate-functions) and modify one of the queries you wrote above to use a different aggregate function.","e3c944b9":"## ORDER BY\n\n___\n\nORDER BY is usually the last clause you'll put in your query, since you're going to want to use it to sort the results returned by the rest of your query.\n\n![](https:\/\/i.imgur.com\/QRgb4iL.png). \n\n** Ordering by a numeric column**\n\nWhen you ORDER BY a numeric column, by default the column will be sorted from the lowest to highest number. So this query will return the ID, Name and Animal columns, all sorted by the number in the ID column. The row with the lowest number in the ID column will be returned first.\n\n    SELECT ID, Name, Animal\n    FROM `bigquery-public-data.pet_records.pets`\n    ORDER BY ID\nVisually, this looks something like this:\n\n![](https:\/\/i.imgur.com\/zEXDTKS.png)\n\n    \n** Ordering by a text column**\n\nYou can also order by columns that have text in them. By default, the column you sort on will be sorted alphabetically from the beginning to the end of the alphabet.\n\n    SELECT ID, Name, Animal\n    FROM `bigquery-public-data.pet_records.pets`\n    ORDER BY Animal\n![](https:\/\/i.imgur.com\/E7qjnf9.png)\n\n** Reversing the order**\n\nYou can reverse the sort order (reverse alphabetical order for text columns or high to low for numeric columns) using the DESC argument. \n\nSo this query will sort the selected columns by the Animal column, but the values that are last in alphabetic order will be returned first.\n\n    SELECT ID, Name, Animal\n    FROM `bigquery-public-data.pet_records.pets`\n    ORDER BY Animal DESC\n![](https:\/\/i.imgur.com\/DREYNFF.png)","77ac7ce1":"### Quiz 1\n___\n\nNow it's your turn! Here's the questions I would like you to get the data to answer:\n\n* (5pt) Which countries use a unit other than \"ppm\" to measure any type of pollution? \n    * Hint: use \"!=\" to filter where the value *isn't* something\n    * Hint: you can use \"SELECT DISTINCT column\" to check unique values\n* (5pt) Which pollutants have a value of exactly 0?\n","345cb2f9":"### Quiz 3\n___\n\n* (5pt) Which hours of the day do the most accidents occur during?\n    * Return a table that has information on how many accidents occurred in each hour of the day in 2015, sorted by the the number of accidents which occurred each hour. Use either the accident_2015 or accident_2016 table for this, and the timestamp_of_crash column. (Yes, there is an hour_of_crash column, but if you use that one you won't get a chance to practice with dates. :P)\n    * **Hint:** You will probably want to use the [EXTRACT() function](https:\/\/cloud.google.com\/bigquery\/docs\/reference\/standard-sql\/functions-and-operators#extract_1) for this, i.e., EXTRACT(HOUR FROM timestamp_of_crash)\n* (5pt) Which state has the most hit and runs?\n    * Return a table with the number of vehicles registered in each state that were involved in hit-and-run accidents, sorted by the number of hit and runs. Use either the vehicle_2015 or vehicle_2016 table for this, especially the registration_state_name and hit_and_run columns.","83b763fe":"Taking the results from returned [Pandas dataframe](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.html).","9736ed43":"## SELECT, FROM & WHERE\n\nFirst, we're going to learn how to use SELECT, FROM and WHERE to get data from a specific column based on the value of another column. For the purposes of this explanation, we'll be using this imaginary database, `pet_records` which has just one table in it, called `pets`, which looks like this:\n\n![](https:\/\/i.imgur.com\/Ef4Puo3.png)\n\n### SELECT ... FROM\n___\n\nThe most basic SQL query is to select a single column from a specific table. To do this, you need to tell SELECT which column to select and then specify what table that column is from using from. \n\nSo, if we wanted to select the \"Name\" column from the pets table of the pet_records database, we would do this:\n\n    SELECT Name\n    FROM `bigquery-public-data.pet_records.pets`\n\nWhich would return the highlighted data from this figure.\n\n![](https:\/\/i.imgur.com\/8FdVyFP.png)\n\n### WHERE ...\n___\n\nWhen you're working with BigQuery datasets, you're almost always going to want to return only certain rows, usually based on the value of a different column. You can do this using the WHERE clause, which will only return the rows where the WHERE clause evaluates to true.\n\nLet's look at an example:\n\n    SELECT Name\n    FROM `bigquery-public-data.pet_records.pets`\n    WHERE Animal = \"Cat\"\n\nThis query will only return the entries from the \"Name\" column that are in rows where the \"Animal\" column has the text \"Cat\" in it. Those are the cells highlighted in blue in this figure:\n\n![](https:\/\/i.imgur.com\/Va52Qdl.png)\n","a3509930":"## (30pt) Option 2: Hacker News Analysis\n\n**Hacker news**\n\nHacker News is a social news website focusing on computer science and entrepreneurship. It is run by Paul Graham's investment fund and startup incubator, Y Combinator. In general, content that can be submitted is defined as \"anything that gratifies one's intellectual curiosity\"[[1](https:\/\/en.wikipedia.org\/wiki\/Hacker_News)]\n\n**Y Combinator**\nY Combinator is an American seed accelerator, started in March 2005. Y Combinator has launched various successful companies and there are total of 1058 active companies in [YCList](http:\/\/yclist.com\/) website.\n\nThis kernel attempts to answer some of questions stated in Hacker news [dataset](https:\/\/www.kaggle.com\/hacker-news\/hacker-news) inspirations section. These are listed below.\n\n* (10pt) Hacker News has received complaints that the site is biased towards Y Combinator startups. Do the data support this?\n    * hint: use WHERE REGEXP_CONTAINS(title, r\"Y Combinator|YCombinator\") to select \"Y Combinator\" related stories.\n* (10pt) Recent studies have found that many forums tend to be dominated by a very small fraction of users. Is this true of Hacker News?\n* (10pt) Create visualizations to support your answers.","d04c57bb":"# Challenge: Chose one of the two options below","20bfe1ec":"The `BigQueryHelper.head()` method will also let us look at just the information in a specific column. If we want to see the first ten entries in the \"by\" column, for example, we can do that!","4733b5df":"## More on data visualization\n\n[Examples of data visualizations](https:\/\/www.kaggle.com\/residentmario\/welcome-to-data-visualization)","1c3abb23":"## (30pt) Option 1: Work on your own problem.\n\n1. (5pt) Pick a dataset from the BigQuery public datasets (or others), and raise a question that you want to answer from the data.\n2. (5pt) Identify the tables, columns, and joins you need to answer your question.\n2. (10pt) Write SQL and code to extract evidences for your answer.\n4. (10pt) Create some visualizations to support your answer","791bbf85":"### Example: What are all the U.S. cities in the OpenAQ dataset?\n___\n\nNow that you've got the basics down, let's work through an example with a real dataset. We're going to be working with the OpenAQ dataset, which has information on air quality around the world.","fed98442":"### Example: How many files are covered by each license?\n____\n\nToday we're going to be using the GitHub Repos dataset. GitHub is an place for people to store & collaborate on different versions of their computer code. A \"repo\" is a collection of code associated with a specific project. \n\nMost public code on Github is shared under a specific license, which determines how it can be used and by who. For our example, we're going to look at how many different files have been released under each licenses. ","61627c9e":"## GROUP BY... HAVING and COUNT\n\nNow we're ready to learn how to group your data and count things within those groups. This can help you answer questions like: \n\n* How many of each kind of fruit has our store sold?\n* How many species of animal has the vet office treated?\n\nTo do this, we're going to learn about three new techniques: GROUP BY, HAVING and COUNT. Once again, we're going to use this 100% made up table of information on various pets, which has three columns: one with the unique ID number for each pet, one with the name of the pet and one with the species of the animal (rabbit, cat or dog). \n\n![](https:\/\/i.imgur.com\/Ef4Puo3.png)\n\n### COUNT\n___\n\nCOUNT(), as you may have guessed from the name, returns a count of things. If you pass it the name of a column, it will return the number of entries in that column. So if we SELECT the COUNT() of the ID column, it will return the number of ID's in that column.\n\n    SELECT COUNT(ID)\n    FROM `bigquery-public-data.pet_records.pets`\n    \nThis query, based on the table above, will return 4 because there are 4 ID's in this table.\n \n### GROUP BY\n___\n\nGROUP BY takes the name of one or more column and tells SQL that we want to treat rows that have the same value in that column as a single group when we apply aggregate functions like COUNT().\n\n> An **aggregate function** takes in many values and returns one. Here, we're learning about COUNT() but there are other aggregate functions like SUM() and AVERAGE().\n\nLet's look at an example. We want to know how many of each type of animal we have in our table. You can see the general idea in this image:\n\n![](https:\/\/i.imgur.com\/MFRhycu.png)\n\nThe query that will get us this information looks like this:\n\n    SELECT Animal, COUNT(ID)\n    FROM `bigquery-public-data.pet_records.pets`\n    GROUP BY Animal\n\nThis query will return a table with two columns (Animal & COUNT(ID)) three rows (one for each distinct Animal). \n\nOne thing to note is that if you SELECT a column that you don't pass to 1) GROUP BY or 2) use as input to an aggregate function, you'll get an error. So this query won't work, because the Name column isn't either passed to either an aggregate function or a GROUP BY clause:\n\n    # NOT A VALID QUERY! \"Name\" isn't passed to GROUP BY\n    # or an aggregate function\n    SELECT Name, Animal, COUNT(ID)\n    FROM `bigquery-public-data.pet_records.pets`\n    GROUP BY Animal\n    \nIf make this error, you'll get the error message `SELECT list expression references column (column's name) which is neither grouped nor aggregated at`.\n\n### GROUP BY ... HAVING\n___\n\nAnother option you have when using GROUP BY is to specify that you want to ignore groups that don't meet certain criteria. So this query, for example, will only include groups that have more than one ID in them:\n\n    SELECT Animal, COUNT(ID)\n    FROM `bigquery-public-data.pet_records.pets`\n    GROUP BY Animal\n    HAVING COUNT(ID) > 1\n\nThe only group that this query will return information on is the one in the cells highlighted in blue in this figure:\n\n![](https:\/\/i.imgur.com\/8xutHzn.png)\n\nAs a result, this query will return a table with only one row, since this there only one group remaining. It will have two columns: one for \"Animal\", which will have \"Cat\" in it, and one for COUNT(ID), which will have 2 in it. "}}