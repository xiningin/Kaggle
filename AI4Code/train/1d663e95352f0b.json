{"cell_type":{"e4fcecb6":"code","0d3ade87":"code","48e07d12":"code","f3b3b6e8":"code","26684fc9":"code","9fa9b2b5":"code","ade278a6":"code","295fb5a5":"code","5c303777":"code","46ac8d44":"code","f94da8fd":"code","1705c6eb":"code","80643cc8":"code","7b254f5a":"code","80cfc1fc":"code","bb26ced1":"code","24f85cbe":"code","45887749":"code","8144fe66":"code","b81cd989":"code","f0a698ac":"code","a50e13c5":"code","ecdcd2f1":"code","be329a34":"code","7a074ac2":"code","c50a63e7":"code","0068aa00":"code","48d1fc36":"code","5e7753b0":"code","72869f04":"code","ff95e6d6":"code","2225a16b":"code","95e8a45b":"code","d5460331":"code","04c2dd4c":"code","b7e7e8f6":"code","b6cfffc2":"code","4086c9a4":"code","f6e9b955":"code","04fd6059":"code","2b3d9775":"code","9421a828":"code","baeb659c":"code","cabd6ad1":"code","4861bb69":"code","dc4e8d17":"code","a8ac80d4":"code","631c1ce3":"code","30b9c0ee":"code","becd37ce":"code","30a972e1":"code","f593c809":"code","2d901a78":"code","3cfd79f4":"code","147508d7":"code","ec1b30f7":"code","ea1637a9":"code","b31958c0":"code","19f456d9":"code","3e084f16":"code","2099b9c0":"code","1e1b632a":"code","aff8f2e4":"code","c2b10872":"code","058b0756":"code","4826146d":"code","b6dc06cf":"code","ce29bb54":"code","606e76c2":"code","4023ec77":"code","67fc14a0":"code","f5cfbbbc":"code","0c19b5ce":"code","e4401577":"code","8eb0c8e9":"code","c8b68881":"markdown","0aafef93":"markdown","c99aa64e":"markdown","4c9de5de":"markdown","8320e5b8":"markdown","16d2e66b":"markdown","7b4d5e10":"markdown","4b1671a4":"markdown","90b3665e":"markdown","0690dc8e":"markdown","e1d4997f":"markdown","d6d85160":"markdown","3689ae24":"markdown","f21aa403":"markdown","7653d2ea":"markdown","86ddbc2d":"markdown","9ad0b68a":"markdown"},"source":{"e4fcecb6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d3ade87":"import pandas as pd\nimport random\nfrom matplotlib import pyplot as plt\n\n# Pandas options\npd.set_option('display.max_colwidth', 1000, 'display.max_rows', None, 'display.max_columns', None)\n\nimport seaborn as sns\nimport numpy as np # linear algebra\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nimport pandas as pd","48e07d12":"from matplotlib import pyplot as plt\n%matplotlib inline\nfrom matplotlib import pyplot as plt\ndef countplot(indipendent_features):\n  plt.figure(figsize=(25, 25))\n  for loc, feature in enumerate(indipendent_features):\n    ax = plt.subplot(3, 4, loc+1)\n    ax.set_xlabel('{}'.format(feature), fontsize=10)\n    chart = sns.countplot(loans[feature])\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n  return None","f3b3b6e8":"import seaborn as sns\n\ndef countplot(indipendent_features):\n  plt.figure(figsize=(25, 25))\n  for loc, feature in enumerate(indipendent_features):\n    ax = plt.subplot(3, 4, loc+1)\n    ax.set_xlabel('{}'.format(feature), fontsize=10)\n    chart = sns.countplot(loans3[feature])\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n  return None","26684fc9":"#loansr is a raw dataset containing 2 million of rows\nloan = pd.read_csv('..\/input\/lending-club\/accepted_2007_to_2018Q4.csv.gz', compression='gzip', low_memory=True)","9fa9b2b5":"loan.info()","ade278a6":"loans = loan[['loan_amnt', 'term','int_rate', 'sub_grade','emp_title',\n                  'emp_length','home_ownership', 'annual_inc', 'loan_status', 'addr_state',\n                  'dti','mths_since_recent_inq', 'revol_util', 'bc_open_to_buy', 'bc_util', 'num_op_rev_tl']]","295fb5a5":"loans.head()","5c303777":"pd.set_option('display.float_format', lambda x: '%.0f' % x)","46ac8d44":"loans.describe()","f94da8fd":"loans.isnull().sum()","1705c6eb":"missing_data = pd.DataFrame({'total_missing': loans.isnull().sum(), '%_missing': \n(loans.isnull().sum()\/2260701)*100})\nmissing_data","80643cc8":"loans = loans.dropna()\nloans.info()","7b254f5a":"missing_data = pd.DataFrame({'total_missing': loans.isnull().sum()})\nmissing_data","80cfc1fc":"loans.hist(bins = 10, figsize = (20,10), color = 'b')","bb26ced1":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nnum_cols = ['loan_amnt', 'term','int_rate', 'sub_grade',\n                  'emp_length','home_ownership', 'annual_inc', 'loan_status', 'addr_state',\n                  'dti','mths_since_recent_inq', 'revol_util', 'bc_open_to_buy', 'bc_util', 'num_op_rev_tl' ]\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.title(\"Lending club dataset\", fontsize=20)\nplt.show()","24f85cbe":"loans.annual_inc.describe()","45887749":"loans.annual_inc.unique()","8144fe66":"num_cols = ['annual_inc']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.title(\"Numerical variable\", fontsize=20)\nplt.show()","b81cd989":"#remove outlier \"annual income\"\nq_low = loans[\"annual_inc\"].quantile(0.08)\nq_hi  = loans[\"annual_inc\"].quantile(0.92)\n\nloans = loans[(loans[\"annual_inc\"] < q_hi) & (loans[\"annual_inc\"] > q_low)]\n\n","f0a698ac":"# plot a chart to view to what extend outliers are removed\nnum_cols = ['annual_inc']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.title(\"Numerical variable\", fontsize=20)\nplt.show()","a50e13c5":"num_cols = ['dti']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","ecdcd2f1":"#remove outlier \n\nloans = loans[(loans['dti'] <=45)]","be329a34":"num_cols = ['dti']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","7a074ac2":"loans.hist(bins = 30, figsize = (20,10), color = 'b')","c50a63e7":"num_cols = ['bc_open_to_buy']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","0068aa00":"#remove outlier \nq_hi  = loans['bc_open_to_buy'].quantile(0.95)\nloans = loans[(loans['bc_open_to_buy'] < q_hi)]","48d1fc36":"num_cols = ['bc_open_to_buy']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","5e7753b0":"loans.hist(bins = 30, figsize = (20,10), color = 'b')","72869f04":"num_cols = ['bc_util']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","ff95e6d6":"#remove outlier \n\nloans = loans[(loans['bc_util'] <=160)]","2225a16b":"num_cols = ['bc_util']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","95e8a45b":"num_cols = ['revol_util']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","d5460331":"#remove outlier \nloans = loans[(loans['revol_util'] <=150)]","04c2dd4c":"num_cols = ['revol_util']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","b7e7e8f6":"num_cols = ['num_op_rev_tl']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","b6cfffc2":"#remove outlier\nloans = loans[(loans['num_op_rev_tl'] <=35)]","4086c9a4":"num_cols = ['num_op_rev_tl']\nplt.figure(figsize=(18,9))\nloans[num_cols].boxplot()\nplt.show()","f6e9b955":"loans.hist(bins = 10, figsize = (20,10), color = 'b')","04fd6059":"#from pandas_profiling import ProfileReport\n#profile = ProfileReport (loans, title = 'Loans Defaults Prediction', html = {'style': {'full_width': True }})\n#profile","2b3d9775":"# dropping passed columns\nloans.drop([\"bc_util\", \"bc_open_to_buy\",\"int_rate\"], axis = 1, inplace = True)\nloans.head()","9421a828":"cleaner_app_type = {\"term\": {\" 36 months\": 1.0, \" 60 months\": 2.0},\n                    \"sub_grade\": {\"A1\": 1.0, \"A2\": 2.0, \"A3\": 3.0, \"A4\": 4.0, \"A5\": 5.0,\n                                  \"B1\": 11.0, \"B2\": 12.0, \"B3\": 13.0, \"B4\": 14.0, \"B5\": 15.0,\n                                  \"C1\": 21.0, \"C2\": 22.0, \"C3\": 23.0, \"C4\": 24.0, \"C5\": 25.0,\n                                  \"D1\": 31.0, \"D2\": 32.0, \"D3\": 33.0, \"D4\": 34.0, \"D5\": 35.0,\n                                  \"E1\": 41.0, \"E2\": 42.0, \"E3\": 43.0, \"E4\": 44.0, \"E5\": 45.0,\n                                  \"F1\": 51.0, \"F2\": 52.0, \"F3\": 53.0, \"F4\": 54.0, \"F5\": 55.0,\n                                  \"G1\": 61.0, \"G2\": 62.0, \"G3\": 63.0, \"G4\": 64.0, \"G5\": 65.0,\n                                    },\n                     \"emp_length\": {\"< 1 year\": 0.0, '1 year': 1.0, '2 years': 2.0, '3 years': 3.0, '4 years': 4.0, \n                                   '5 years': 5.0, '6 years': 6.0, '7 years': 7.0, '8 years': 8.0, '9 years': 9.0,\n                                   '10+ years': 10.0 }\n                   }\nloans = loans.replace(cleaner_app_type)\nloans.info()","baeb659c":"loans['loan_status'].value_counts()","cabd6ad1":"array = ['Charged Off', 'Fully Paid']\nloans = loans.loc[loans['loan_status'].isin(array)]\nloans.head()","4861bb69":"cleaner_app_type1 = {\"loan_status\": { \"Fully Paid\": 1.0, \"Charged Off\": 0.0}}\nloans = loans.replace(cleaner_app_type1)\nloans.info()","dc4e8d17":"loans['loan_status'].value_counts()","a8ac80d4":"plt.subplot(2, 1, 1)\nsns.countplot(x='home_ownership', data=loans, hue='loan_status')","631c1ce3":"analyse_home_ownership = loans.groupby(['home_ownership','loan_status'])['loan_status'].count()\nanalyse_home_ownership = analyse_home_ownership.groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))\n\nanalyse_home_ownership","30b9c0ee":"loans['emp_title'].nunique()","becd37ce":"emp_title_data = loan['emp_title'].value_counts()[:20]","30a972e1":"loan_emp_title = loan.loc[loan['loan_status'] =='Fully Paid'] \nloan_emp_title.head()","f593c809":"plt.figure(figsize=(15, 12))\nplt.subplot(2, 2, 2)\nplt.barh(loan_emp_title.emp_title.value_counts()[:10].index, loan.emp_title.value_counts()[:10])\nplt.title(\"The most 10 jobs title applied for a loan\")\nplt.tight_layout()","2d901a78":"#convert annual_inc to integer data type\n\nloans = loans.astype({\"home_ownership\":'category', \"addr_state\":'category'})\nloans.dtypes","3cfd79f4":"\ncat_columns = [\"home_ownership\", \"addr_state\"]\n#create a new DataFrame for our processed data\nloans = pd.get_dummies(loans, prefix_sep=\"__\",\n                              columns=cat_columns)\nloans.head()","147508d7":"pip install hvplot","ec1b30f7":"analyse_sub_grade = loans.groupby(['sub_grade','loan_status'])['loan_status'].count()\nanalyse_sub_grade = analyse_sub_grade.groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))\nanalyse_sub_grade","ea1637a9":"analyse_sub_grade = analyse_sub_grade.unstack()\n","b31958c0":"analyse_sub_grade.plot.area()","19f456d9":"bins = [30000, 50000, 70000, 90000, 110000, 130000, 150000]\nlabels = ['30-50k', '50-70k', '70-90k', '90-110k','110-130k','130-150k']\nloans['binned'] = pd.cut(loans['annual_inc'], bins=bins, labels=labels)\nloans.head()","3e084f16":"analyse_income = loans.groupby(['binned','loan_status'])['loan_status'].count()\nanalyse_income","2099b9c0":"analyse_income = analyse_income.groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))\n\nanalyse_income","1e1b632a":"analyse_income = analyse_income.unstack()\nanalyse_income","aff8f2e4":"analyse_income.plot.area()","c2b10872":"analyse_emp_length = loans.groupby(['emp_length','loan_status'])['loan_status'].count()\nanalyse_emp_length = analyse_emp_length.groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))\n\nanalyse_emp_length","058b0756":"analyse_emp_length = analyse_emp_length.unstack()\nanalyse_emp_length.plot.area()","4826146d":"analyse_dti = loans.groupby(['dti','loan_status'])['loan_status'].count()\nloans['dti'].unique()","b6dc06cf":"binsdti = [1, 10, 20, 30, 40, 50]\nlabelsdti = ['1-10', '10-20', '20-30','30-40','40-50']\nloans['binneddti'] = pd.cut(loans['dti'], bins=binsdti, labels=labelsdti)\n\n\nanalyse_dti = loans.groupby(['binneddti','loan_status'])['loan_status'].count()\nanalyse_dti = analyse_dti.groupby(level=0).apply(lambda x:\n                                                 100 * x \/ float(x.sum()))\n\nanalyse_dti","ce29bb54":"analyse_dti = analyse_dti.unstack()\nanalyse_dti.plot.area()","606e76c2":"loans.drop([\"emp_title\", \"binned\",\"binneddti\"], axis = 1, inplace = True)","4023ec77":"X = loans.drop('loan_status', axis=1)\ny = loans[['loan_status']]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n","67fc14a0":"loans.head()","f5cfbbbc":"loans.to_csv('mycsvfile.csv',index=False)","0c19b5ce":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","e4401577":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","8eb0c8e9":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)\n\nax = sns.heatmap(confusion_matrix, cmap='viridis_r', annot=True, fmt='d', square=True)","c8b68881":"'sub_grade' and 'loan_status'","0aafef93":"# Logistic Regression Model","c99aa64e":"# Load Dataset","4c9de5de":"# Save DataFrame in CSV file","8320e5b8":"# Libraries","16d2e66b":"'emp_length' vs 'loan_status'","7b4d5e10":"# Introduction\nThis series of articles walks you through end to end process to build a data science project based on a real business problem. The business problem along with its scientific solution is focused around Fintech Industry, which is erupting these days, expect a lot of fun! \ud83d\ude42\nRefer this url for the full meduim article:\nhttps:\/\/medium.com\/@mariia.gusarova\/learn-to-build-an-end-to-end-data-science-project-for-fintech-part-i-e84bc542e92f","4b1671a4":"# Train\/Test Split","90b3665e":"'annual_inc' vs 'loan_status'","0690dc8e":"# One hot encoding","e1d4997f":"# Categorcal features","d6d85160":"# Missing data","3689ae24":"'dti' vs 'loan_status'","f21aa403":"# Bi-Variate Analysis","7653d2ea":"# Dealing with outliers","86ddbc2d":"# Ordinal transofmraiton","9ad0b68a":"# Panda Profiling"}}