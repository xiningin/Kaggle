{"cell_type":{"db5221c5":"code","35df4303":"code","dab02fc5":"code","36980dc8":"code","072207f9":"code","df765b35":"code","fcaf88a0":"code","daff64b5":"code","c050b41a":"code","c9552b3e":"code","5b846b80":"code","f53828c7":"code","04c7cdd5":"code","660ef944":"code","c15ba74f":"code","239e98b1":"code","fe36bcca":"code","a8360242":"code","9d64af06":"code","b63942e2":"markdown","daf6f8ae":"markdown","d5d440af":"markdown","b592baf6":"markdown","239a3745":"markdown","75d9aac8":"markdown","cb3f2416":"markdown","7c522005":"markdown","af8b750e":"markdown"},"source":{"db5221c5":"import torch\nimport torchvision","35df4303":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","dab02fc5":"from torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\ntrain_data = datasets.MNIST(root='data', train=True,  transform = ToTensor(), download=True)\ntest_data  = datasets.MNIST(root='data', train=False, transform = ToTensor())","36980dc8":"print(train_data)\nprint(test_data)","072207f9":"print(train_data.data.size())","df765b35":"from torch.utils.data import DataLoader\n\nbatch_size = 100\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1)\ntestloader  = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=1)","fcaf88a0":"import matplotlib.pyplot as plt","daff64b5":"# plot one train_data\nplt.imshow(train_data.data[0], cmap='gray')\nplt.title('%i' % train_data.targets[0])\nplt.show()","c050b41a":"# plot multiple train_data\nfigure = plt.figure(figsize=(10, 8))\ncols, rows = 5, 5\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n    img, label = train_data[sample_idx]\n    figure.add_subplot(rows, cols, i)\n    plt.title(label)\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze(), cmap=\"gray\")\nplt.show()","c9552b3e":"from torch import nn","5b846b80":"class CNN(nn.Module):    \n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Sequential(         \n            nn.Conv2d(\n                in_channels=1,              \n                out_channels=16,            \n                kernel_size=5,              \n                stride=1,                   \n                padding=2,                  \n            ),                              \n            nn.ReLU(),                      \n            nn.MaxPool2d(kernel_size=2),    \n        )\n        self.conv2 = nn.Sequential(         \n            nn.Conv2d(16, 32, 5, 1, 2),     \n            nn.ReLU(),                      \n            nn.MaxPool2d(2),                \n        )\n        #self.conv2_drop = nn.Dropout2d()        \n        self.fc = nn.Linear(32 * 7 * 7, 10) # fully connected layer, output 10 classes\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n        x = x.view(x.size(0), -1)       \n        x = self.fc(x)\n        return x    # return x for visualization","f53828c7":"net = CNN()\nloss_func = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=1e-3)","04c7cdd5":"import tqdm","660ef944":"num_epochs = 10\n\nnet.train() # set to training model\nfor epoch in range(num_epochs):\n    for images, labels in tqdm.notebook.tqdm(trainloader):\n        outputs = net(images)\n        loss = loss_func(outputs, labels)        \n        optimizer.zero_grad()  # clear gradients for this training step        \n        loss.backward()        # backpropagation, compute gradients\n        optimizer.step()       # apply graidents\n        # accuracy\n        pred_y = torch.max(outputs, 1)[1].data.squeeze()\n        accuracy = (pred_y == labels).sum().item() \/ float(labels.size(0))\n    print(\"Epoch {}\/{}, Loss: {:.4f}, Accuracy: {:.3f}\".format(epoch+1, num_epochs, loss.item(), accuracy))","c15ba74f":"torch.save(net.state_dict(), 'mnist_cnn.pt')","239e98b1":"net.eval() # set to evaluate model\nwith torch.no_grad():\n    for images, labels in testloader:\n        outputs = net(images)\n        pred_y = torch.max(outputs, 1)[1].data.squeeze()\n        accuracy = (pred_y == labels).sum().item() \/ float(labels.size(0))\n    print('Test Accuracy of the model on the 10000 test images: %.3f' % accuracy)","fe36bcca":"sample = next(iter(testloader))\nimgs, lbls = sample","a8360242":"# first 10 predictions\nactual_y = lbls[:10].numpy()\nprint(actual_y)","9d64af06":"test_output = net(imgs[:10])\npred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\nprint(f'Predict: {pred_y}')\nprint(f'Actual : {actual_y}')","b63942e2":"## Visualization of MNIST dataset","daf6f8ae":"## Test Model","d5d440af":"## Download Dataset","b592baf6":"## Save Model","239a3745":"# MNIST Handwritten Digit Recognition in PyTorch","75d9aac8":"## Build Network","cb3f2416":"### test first 10 samples","7c522005":"## Prepare DataLoader","af8b750e":"## Train Model"}}