{"cell_type":{"4abf81cf":"code","4571ff8e":"code","938dda49":"code","62192458":"code","b14ff332":"code","2b3ae0ff":"code","7bdbb8d7":"code","cf2a0497":"code","d64e76b8":"code","3c2cb466":"code","f14ccabd":"code","1b426971":"code","4d6c0317":"code","49e8e56b":"code","3bbad506":"code","472071e8":"code","5bceb395":"code","51166dc1":"code","92372e3b":"code","5431ac71":"code","d75a7ad7":"code","3e606df3":"code","c80959fc":"code","8d8659ec":"code","95fa07e7":"code","5eaf6a29":"code","22cbadbe":"code","8654f3ff":"code","3add4065":"code","2729743a":"code","b22a4087":"code","375c63d7":"code","b4fb2546":"code","9bad69a6":"code","7bd3e937":"code","81a09d3c":"code","9fccf51a":"code","7d614bd9":"code","ee908e62":"code","6f4a64ba":"code","3494f266":"code","42f4170a":"code","e479658e":"code","8398d5f8":"code","0bbe60da":"code","76cb679f":"code","50d40106":"code","5d26a4f0":"code","84133d02":"code","c6695c0b":"code","fe9751c2":"code","29bbb277":"code","863f4eaa":"code","9ae5565c":"code","6f4299ce":"code","274ae712":"code","dcb7ba67":"code","84779dea":"markdown","0535a9ee":"markdown","6e46e9a4":"markdown","5d181e41":"markdown","8dbf0c3a":"markdown","fdef44ac":"markdown","0c6bd991":"markdown","9f5a3b15":"markdown","8481f244":"markdown","e5571683":"markdown","2aeaa146":"markdown","dc3d16c6":"markdown","20cca697":"markdown","b95dc2ec":"markdown","79fe6649":"markdown","3c984397":"markdown","d510e93b":"markdown","1346d55f":"markdown","a1bfee71":"markdown"},"source":{"4abf81cf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npd.pandas.set_option('display.max_columns', None)","4571ff8e":"df = pd.read_csv('\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')","938dda49":"df.head()","62192458":"df.shape","b14ff332":"df.drop(columns=['EmployeeCount', 'EmployeeNumber', 'StandardHours'], axis=1, inplace=True)","2b3ae0ff":"target = 'Attrition'","7bdbb8d7":"sns.countplot(x=target, data=df)","cf2a0497":"df.info()","d64e76b8":"df.isnull().sum()","3c2cb466":"# Categorical Variables\n\ncat_vars = [var for var in df.columns if df[var].dtype == 'O' and var != target]\n\n# There are few other categorical features which are not by default\n# We will analyze those variables also\nxtra_vars = ['Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel' ,'JobSatisfaction',\n             'PerformanceRating', 'RelationshipSatisfaction', 'WorkLifeBalance', 'NumCompaniesWorked',\n             'StockOptionLevel', 'PercentSalaryHike', 'TrainingTimesLastYear']\n\n\ncat_vars = cat_vars + xtra_vars","f14ccabd":"cat_vars","1b426971":"def plot_cat(var, dataframe):\n    plt.figure(figsize=(16, 4))\n    sns.countplot(x=var, hue=target, data=dataframe)\n    plt.show()","4d6c0317":"for i in cat_vars:\n    plot_cat(i, df)","49e8e56b":"def plot_cat_percent(var, dataframe):\n    plt.figure(figsize=(16, 4))\n    ys_df = df[df[target] == 'Yes'].groupby(var).count()[target]\n    no_df = df[df[target] == 'No'].groupby(var).count()[target]\n    rat = ys_df \/ (ys_df + no_df) * 100\n    rat.plot(kind='bar')\n    plt.show()","3bbad506":"for i in cat_vars:\n    plot_cat_percent(i, df)","472071e8":"num_vars = [var for var in df.columns if var not in cat_vars and var!=target]","5bceb395":"num_vars","51166dc1":"df[num_vars].hist(bins=30, figsize=(15,15))\nplt.show()","92372e3b":"for i in num_vars:\n    sns.boxplot(x=target, y=i, data=df)\n    plt.show()\n","5431ac71":"df[num_vars + [target]].groupby(target).describe()","d75a7ad7":"num_vars.remove('HourlyRate')\nnum_vars.remove('MonthlyRate')\nnum_vars.remove('YearsSinceLastPromotion')","3e606df3":"plt.figure(figsize=(12,6))\nsns.heatmap(df[num_vars].corr(), annot=True)","c80959fc":"sns.scatterplot(x=df['TotalWorkingYears'], y=df['MonthlyIncome'])","8d8659ec":"sns.scatterplot(y=df['TotalWorkingYears'], x=df['Age'])","95fa07e7":"sns.scatterplot(x=df['YearsAtCompany'], y=df['TotalWorkingYears'])","5eaf6a29":"sns.scatterplot(y=df['YearsInCurrentRole'], x=df['TotalWorkingYears'])","22cbadbe":"sns.scatterplot(y=df['YearsWithCurrManager'], x=df['TotalWorkingYears'])","8654f3ff":"num_vars.remove('Age')","3add4065":"cat_vars.remove('Gender')\ncat_vars.remove('Over18')\ncat_vars.remove('PerformanceRating')","2729743a":"num_vars","b22a4087":"# selected features\nfqs = num_vars + cat_vars + [target]","375c63d7":"print(len(fqs), len(df.columns))","b4fb2546":"df = df[fqs]","9bad69a6":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder","7bd3e937":"enc = OrdinalEncoder()\noc_data = enc.fit_transform(df[['OverTime','Attrition']].values)","81a09d3c":"# DRop those mentioned columns and replace them with oc_data\nord_cols = ['OverTime','Attrition']\noc_df = pd.DataFrame(oc_data, columns=ord_cols)\ndf = df.drop(columns=ord_cols)\ndf = pd.concat([df, oc_df], axis=1)","9fccf51a":"ohc = OneHotEncoder(sparse=False, drop='first')\n\nohc_cols = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']\nohc_data = ohc.fit_transform(df[ohc_cols].values)\n\nohc_df = pd.DataFrame(ohc_data, columns=ohc.get_feature_names())\ndf = df.drop(columns=ohc_cols, axis=1)\ndf = pd.concat([df, ohc_df], axis=1)","7d614bd9":"df.dtypes","ee908e62":"df.head()","6f4a64ba":"X = df.drop('Attrition', axis=1)\ny = df['Attrition'].values","3494f266":"y.shape","42f4170a":"from imblearn.over_sampling import SMOTE\n\noversample = SMOTE()\nXo, yo = oversample.fit_resample(X, y)","e479658e":"yo.shape","8398d5f8":"sns.countplot(x=yo)","0bbe60da":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(Xo, yo, test_size=0.2, random_state=41)","76cb679f":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_sc = scaler.fit_transform(X_train)\nX_test_sc = scaler.transform(X_test)","50d40106":"print(X_train_sc.shape, X_test_sc.shape)","5d26a4f0":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential()\n\nmodel.add(Dense(38, input_shape=(38,), activation='relu'))\nmodel.add(Dense(19, activation='relu'))\nmodel.add(Dense(9, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","84133d02":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","c6695c0b":"model.fit(x=X_train_sc, y=y_train, epochs=50, validation_data=(X_test_sc, y_test))","fe9751c2":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","29bbb277":"pred = model.predict(X_test_sc)\npred = np.where(pred>0.5, 1, 0)\nfrom sklearn.metrics import confusion_matrix, classification_report\nc_m = confusion_matrix(y_test, pred)\nprint(c_m)\nprint(classification_report(y_test, pred))","863f4eaa":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)","9ae5565c":"model_e = Sequential()\n\nmodel_e.add(Dense(38, input_shape=(38,), activation='relu'))\nmodel_e.add(Dense(19, activation='relu'))\nmodel_e.add(Dense(9, activation='relu'))\nmodel_e.add(Dense(1, activation='sigmoid'))\n\nmodel_e.summary()\n\nmodel_e.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","6f4299ce":"model_e.fit(x=X_train_sc, y=y_train, \n          epochs=50, validation_data=(X_test_sc, y_test), callbacks=[early_stop])","274ae712":"model_loss = pd.DataFrame(model_e.history.history)\nmodel_loss.plot()","dcb7ba67":"pred = model_e.predict(X_test_sc)\npred = np.where(pred>0.5, 1, 0)\nfrom sklearn.metrics import confusion_matrix, classification_report\nc_m = confusion_matrix(y_test, pred)\nprint(c_m)\nprint(classification_report(y_test, pred))","84779dea":"**Attrition** is the `target` column\n\nObtain a count plot of the column","0535a9ee":"So from the above series it can be concluded that there are no missing values","6e46e9a4":"From the heatmap it can be observed that there are some mutually correlated features","5d181e41":"Now it's time to use SMOTE method to balance the output classes, This is a simple implementation you can finetune this later","8dbf0c3a":"### Now it's time to do some data vizs\nWe will start with category variables","fdef44ac":"### That's it from my end, This notebook was a part of deep learning journey\n\n### PLzzzzzzz like \/ star if it's good","0c6bd991":"Now we will encode various categories\n\nWe will encode **OverTime**, **Attrition** with OrdinalEncoder, and remaining with One Hot Encoder","9f5a3b15":"**HourlyRate**, **MonthlyRate**, **YearsSinceLastPromotion** are not significant features here  ","8481f244":"We can drop these column, as they are just some indicators\n* EmployeeCount\n* EmployeeNumber\n* StandardHours","e5571683":"## First Model\n\n## Simple ann model","2aeaa146":"From the countplot it can be observed that the target is imbalanced.\n\nLater in this notebook, we will alter it.","dc3d16c6":"## Model 2\n\n## For this model, we are adding an earlystopping (it's not required, I am doing it for learning purpose)","20cca697":"Same inference as above","b95dc2ec":"## Numerical Variables","79fe6649":"We can remove `age` from the features set, because age is correlated with working years.\n","3c984397":"Now check if any features contains null values","d510e93b":"## Let's plot a percentage plot to check what percent of employees\n## left at each features","1346d55f":"Its predictable, since more the experience more the salary","a1bfee71":"These columns are not thatmuch contributing to the attrition rate\n\n**`Gender, Over18, PerformanceRating`**\n\nIn those features ratio of employees leaving are almost the same, So we can drop those columns"}}