{"cell_type":{"d73bce8c":"code","ea36b7d9":"code","64b1d3aa":"code","5e59cf62":"code","dd27859c":"code","2b46680b":"code","d639dabc":"code","9e75fba6":"code","f752b27f":"code","3a2f08fd":"code","52a1722a":"code","bfea1b2c":"code","57a8863a":"markdown"},"source":{"d73bce8c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea36b7d9":"######################################################\n# Sales Prediction with Linear Regression\n######################################################\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score","64b1d3aa":"##########################\n# Linear Regression S\u00fcrecini Anlamak\n##########################\n\n# Rastgele b ve w olu\u015fturmak\nbs = np.random.randint(100, 300, 10)\nws = np.random.randint(1, 10, 10)\n\nb = np.random.choice(bs)\nw = np.random.choice(ws)\n\n\n# ba\u011f\u0131ml\u0131 de\u011fi\u015fken\ny = pd.Series([300, 310, 310, 330, 340, 350, 350, 400, 420, 450, 450, 470])\n\n# ba\u011f\u0131ms\u0131z de\u011fi\u015fken\nx = pd.Series([70, 73, 75, 80, 80, 80, 82, 83, 85, 90, 92, 94])\n\n# b ve w kullanarak tahmin edilen de\u011ferler\ny_pred = b + x * w\n\n# 70 metrekare evin fiyat\u0131\nprint(b, w)\nb + w*70\n\n# gercek ve tahmin edilen de\u011ferlerin bir araya getirilmesi\ndf = pd.DataFrame({\"x\": x, \"y\": y, \"y_pred\": y_pred})\n\n\n# hata metriklerine g\u00f6re hatalar.\n\ndef mse(actual, predicted):\n    return np.mean((actual - predicted)**2)\n\ndef rmse(actual, predicted):\n    return np.sqrt(np.mean((actual - predicted)**2))\n\ndef mae(actual, predicted):\n    return np.mean(np.abs(actual - predicted))\n\n\n# mse\nmse(df[\"y\"], df[\"y_pred\"])\n\n# rmse\nrmse(df[\"y\"], df[\"y_pred\"])\n\n# mae\nmae(df[\"y\"], df[\"y_pred\"])","5e59cf62":"# mse\nmse(df[\"y\"], df[\"y_pred\"])","dd27859c":"# rmse\nrmse(df[\"y\"], df[\"y_pred\"])","2b46680b":"# mae\nmae(df[\"y\"], df[\"y_pred\"])","d639dabc":"##########################\n# Simple Linear Regression with OLS Using Scikit-Learn\n##########################\n\ndf = pd.read_csv(\"\/kaggle\/input\/advertising\/Advertising.csv\", index_col=0)\ndf.shape\ndf.head()","9e75fba6":"X = df[[\"TV\"]]\ny = df[[\"sales\"]]\n\nreg_model = LinearRegression().fit(X, y)\nreg_model.intercept_[0], reg_model.coef_[0][0]\n# (7.032593549127693, 0.047536640433019764)\ny_pred = reg_model.predict(X)\nmean_squared_error(y, y_pred)\n# 10.512652915656757\n\nreg_model.intercept_[0] + reg_model.coef_[0][0]*150\n\nreg_model.intercept_[0] + reg_model.coef_[0][0]*500\n\ng = sns.regplot(x=X, y=y, scatter_kws={'color': 'b', 's': 9},\n                ci=False, color=\"r\")\ng.set_title(f\"Model Denklemi: Sales = {round(reg_model.intercept_[0], 2)} + TV*{round(reg_model.coef_[0][0], 2)}\")\ng.set_ylabel(\"Sat\u0131\u015f Say\u0131s\u0131\")\ng.set_xlabel(\"TV Harcamalar\u0131\")\nplt.xlim(-10, 310)\nplt.ylim(bottom=0)\nplt.show()","f752b27f":"##########################\n# Simple Linear Regression with OLS From Scratch\n##########################\n\ndf = pd.read_csv(\"\/kaggle\/input\/advertising\/Advertising.csv\", index_col=0)\n\nX = df[[\"TV\"]]\ny = df[[\"sales\"]]\n\n\n# b1\nb1 = ((np.array(X) - np.array(df[\"TV\"]).mean()) * (np.array(y) - np.array(df[\"sales\"]).mean())).sum() \\\n     \/ (((np.array(X) - np.array(df[\"TV\"]).mean()) ** 2).sum())\n\nb0 = np.array(df[\"sales\"]).mean() - b1 * np.array(df[\"TV\"]).mean()\n\n\nb0 + b1 * 150","3a2f08fd":"##########################\n# Simple Linear Regression with Gradient Descent from Scratch\n##########################\n\n# Cost function\ndef cost_function(Y, b, w, X):\n    m = len(Y)\n    sse = 0\n    for i in range(0, m):\n        y_hat = b + w * X[i]\n        y = Y[i]\n        sse += (y_hat - y) ** 2\n    mse = sse \/ m\n    return mse\n\n# update_weights\ndef update_weights(Y, b, w, X, learning_rate):\n    m = len(Y)\n    b_deriv_sum = 0\n    w_deriv_sum = 0\n    for i in range(0, m):\n        y_hat = b + w * X[i]\n        y = Y[i]\n        b_deriv_sum += (y_hat - y)\n        w_deriv_sum += (y_hat - y) * X[i]\n    new_b = b - (learning_rate * 1 \/ m * b_deriv_sum)\n    new_w = w - (learning_rate * 1 \/ m * w_deriv_sum)\n    return new_b, new_w\n\n\n# train fonksiyonu\ndef train(Y, initial_b, initial_w, X, learning_rate, num_iters):\n    print(\"Starting gradient descent at b = {0}, w = {1}, mse = {2}\".format(initial_b, initial_w,\n                                                                   cost_function(Y, initial_b, initial_w, X)))\n    b = initial_b\n    w = initial_w\n    cost_history = []\n    for i in range(num_iters):\n        b, w = update_weights(Y, b, w, X, learning_rate)\n        mse = cost_function(Y, b, w, X)\n        cost_history.append(mse)\n        if i % 100 == 0:\n            print(\"iter={:d}    b={:.2f}    w={:.4f}    mse={:.4}\".format(i, b, w, mse))\n    print(\"After {0} iterations b = {1}, w = {2}, mse = {3}\".format(num_iters, b, w, cost_function(Y, b, w, X)))\n    return b, w\n\n\ndf = pd.read_csv(\"\/kaggle\/input\/advertising\/Advertising.csv\")\n\nX = df[\"radio\"]\nY = df[\"sales\"]\n\n# hyperparameters\nlearning_rate = 0.001\ninitial_b = 0.001\ninitial_w = 0.001\nnum_iters = 10000\n\n\ntrain(Y, initial_b, initial_w, X, learning_rate, num_iters)\n\n\n\n# Scikit-learn ile:\nX = df[[\"radio\"]]\nY = df[[\"sales\"]]\nreg_model = LinearRegression().fit(X, Y)\nreg_model.intercept_[0], reg_model.coef_[0][0]\ny_pred = reg_model.predict(X)\nmean_squared_error(y, y_pred)","52a1722a":"##########################\n# Model Validation (Holdout, Cross Validation)\n##########################\n\ndf = pd.read_csv(\"\/kaggle\/input\/advertising\/Advertising.csv\", index_col=0)\ndf.head()\ndf.info()\ndf.shape\n\nX = df[[\"TV\"]]\ny = df[[\"sales\"]]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n\n##########################\n# Model\n##########################\n\nreg_model = LinearRegression()\nreg_model.fit(X_train, y_train)\n\nreg_model.intercept_\nreg_model.coef_\nreg_model.score(X_train, y_train)\n\ng = sns.regplot(x=X_train, y=y_train, scatter_kws={'color': 'b', 's': 9},\n                ci=False, color=\"r\")\ng.set_title(f\"Model Denklemi: Sales = {round(reg_model.intercept_[0], 2)} + TV*{round(reg_model.coef_[0][0], 2)}\")\ng.set_ylabel(\"Sat\u0131\u015f Say\u0131s\u0131\")\ng.set_xlabel(\"TV Harcamalar\u0131\")\nplt.xlim(-10, 310)\nplt.ylim(bottom=0)\nplt.show()","bfea1b2c":"##########################\n# Tahmin & Tahmin Ba\u015far\u0131s\u0131n\u0131 De\u011ferlendirme\n##########################\n\n# y_hat = b + wX\n# y_hat = 6.8 + 0.05*TV\n\n\n# Tahmin ba\u015far\u0131s\u0131n\u0131 de\u011ferlendirmek i\u00e7in 4 yol var.\n# 1. T\u00fcm veri ile model kur t\u00fcm veri ile hataya bak.\n# 2. train seti ile model kur test seti ile hataya bak. (holdout)\n# 3. K Fold CV ile t\u00fcm veri \u00fczerinden hataya bak.\n# 4. Veriyi en ba\u015ftan train test \u015feklinde ay\u0131r.\n# Train setine CV uygula validasyon hatas\u0131na bak test seti i\u00e7in de test hatana bak.\n\n# train hatas\u0131\ny_pred = reg_model.predict(X_train)\nnp.sqrt(mean_squared_error(y_train, y_pred))\n\n# test hatas\u0131\ny_pred = reg_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\n# 10 Katl\u0131 CV RMSE\nnp.mean(np.sqrt(-cross_val_score(reg_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n\n##########################\n# Multiple Linear Regression\n##########################\n\ndf = pd.read_csv(\"\/kaggle\/input\/advertising\/Advertising.csv\", index_col=0)\n\nX = df.drop('sales', axis=1)\ny = df[[\"sales\"]]\n\n##########################\n# Model\n##########################\n\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.20, random_state=1)\n\nreg_model = LinearRegression()\nreg_model.fit(X_train, y_train)\n\nreg_model.intercept_\nreg_model.coef_\nreg_model.score(X_train, y_train)\n\n##########################\n# Tahmin & Tahmin Ba\u015far\u0131s\u0131n\u0131 De\u011ferlendirme\n##########################\n\n# Sales = 2.90  + TV * 0.04 + radio * 0.17 + newspaper * 0.002\n# 30 birim TV, 10 birim radio, 40 birim gazeteye harcan\u0131rsa sat\u0131\u015flar ne olur?\n2.90 + 30 * 0.04 + 10 * 0.17 + 40 * 0.002\n\nyeni_veri = [[30], [10], [40]]\nyeni_veri = pd.DataFrame(yeni_veri).T\nreg_model.predict(yeni_veri)\n\ny.head()\n\n# train hatas\u0131\ny_pred = reg_model.predict(X_train)\nnp.sqrt(mean_squared_error(y_train, y_pred))\n\n# test hatas\u0131\ny_pred = reg_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\n# 10 Katl\u0131 CV RMSE\nnp.mean(np.sqrt(-cross_val_score(reg_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))","57a8863a":"##########################\n# Linear Regression S\u00fcrecini Anlamak\n##########################"}}