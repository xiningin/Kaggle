{"cell_type":{"888c8ba5":"code","5c7b09a5":"code","caba3481":"code","975ea54b":"code","b8de1398":"code","c994bab7":"code","3b322bb8":"code","49b22991":"code","cbb3b200":"code","eb264d4a":"code","000623ca":"code","7ef3697a":"code","35aa0de4":"code","645aea37":"code","690e8163":"code","8c69a957":"code","d890cac2":"code","94f77310":"code","1876d714":"code","0990d8a7":"code","b1b282b8":"code","83f194be":"code","2504e832":"code","00179efb":"code","0f1e88cd":"code","6b00c7b4":"code","92ffb497":"code","572b92a8":"code","646526e5":"code","05c2f00d":"code","3ce1e31f":"code","cdf8e607":"code","390ab451":"code","3da6bb54":"code","a8633263":"code","030b4cf4":"code","bcfe6120":"code","09cab9a4":"code","52caa538":"code","ac7cc205":"code","8a9b3846":"markdown","bc3413f7":"markdown","59e099ad":"markdown","bbc20e7e":"markdown","0fa45ccc":"markdown","1b58cdda":"markdown","1d289c6f":"markdown","4c1eda93":"markdown","a3d66152":"markdown","40a3261e":"markdown","b54b7fa2":"markdown","32a88360":"markdown","c0feea80":"markdown","51ff7fe8":"markdown","7f189cf0":"markdown","50eb5d93":"markdown","8e617774":"markdown","c978eb48":"markdown","493dd8dc":"markdown","420d566c":"markdown","4fe6d52c":"markdown","b2a7398a":"markdown","a726a275":"markdown","9cc859fb":"markdown","f92462e3":"markdown","9fa1254b":"markdown","be476d07":"markdown"},"source":{"888c8ba5":"! pip install keras.applications","5c7b09a5":"# Basic library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Dir check\nimport os","caba3481":"# OpenCV\nimport cv2 # Open cv\n\n# Data preprocessing\nfrom sklearn.model_selection import train_test_split # ML preprocessing\n\n# Karas\nfrom keras.applications import DenseNet121 # RestNet number 101\nfrom keras.preprocessing.image import ImageDataGenerator # data augmentation\nfrom keras.models import Model # Define model\nfrom keras.models import Sequential # For define simple neural network\nfrom keras.models import Input # Define Input\nfrom keras.models import load_model\nfrom keras.layers import Dense # Define neural network layer\nfrom keras.layers import Conv2D # Define convolution layer\nfrom keras.layers import Flatten # multidimensional lists into one dimension\nfrom keras.layers import MaxPool2D # Define max pooling layer\nfrom keras.layers import Dropout # Dropout method\nfrom keras.layers import BatchNormalization # BatchNormalization method\nfrom keras.layers import Activation # Define activation\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.optimizers import Adam # Optimizer\nfrom keras.callbacks import ModelCheckpoint # call back\nfrom keras.callbacks import EarlyStopping\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Validation\nfrom sklearn.metrics import roc_auc_score","975ea54b":"sample_submission = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/train.csv\")","b8de1398":"sample_submission.head()","c994bab7":"train.head()","3b322bb8":"test.head()","49b22991":"# image loading\nimg_size=256\ntrain_image = []\n\nfor name in train[\"image_id\"]:\n    path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg' # difine path\n    img=cv2.imread(path) # reading the image\n    image = cv2.resize(img, (img_size,img_size), interpolation=cv2.INTER_AREA) # Resize the image (100,100), decreasing size:cv2.INTER_AREA\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Change to color array\n    train_image.append(image) # listing tha datas","cbb3b200":"train[\"img_data\"] = train_image","eb264d4a":"# Visualization some sample\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nfig, ax = plt.subplots(4,4, figsize=(15,15))\nfor c in col:\n    for i in range(4):\n        if c == col[0]:\n            sample = train[train[c]==1]\n            ax[0,i].set_axis_off()\n            ax[0,i].imshow(sample[\"img_data\"].values[i])\n            ax[0,i].set_title(\"{}\".format(c))\n        elif c == col[1]:\n            sample = train[train[c]==1]\n            ax[1,i].set_axis_off()\n            ax[1,i].imshow(sample[\"img_data\"].values[i])\n            ax[1,i].set_title(\"{}\".format(c))\n        elif c == col[2]:\n            sample = train[train[c]==1]\n            ax[2,i].set_axis_off()\n            ax[2,i].imshow(sample[\"img_data\"].values[i])\n            ax[2,i].set_title(\"{}\".format(c))\n        else:\n            sample = train[train[c]==1]\n            ax[3,i].set_axis_off()\n            ax[3,i].imshow(sample[\"img_data\"].values[i])\n            ax[3,i].set_title(\"{}\".format(c))","000623ca":"# image loading\nimg_size=256\ntest_image = []\n\nfor name in test[\"image_id\"]:\n    path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg'\n    img = cv2.imread(path)\n    image = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_AREA)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    test_image.append(image)","7ef3697a":"fig, ax = plt.subplots(1,4, figsize=(15,6))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(test_image[i])","35aa0de4":"gblur_img = [cv2.GaussianBlur(img, (3,3),0) for img in train_image]\n\ntrain[\"gblur\"] = gblur_img","645aea37":"# Visualization some sample\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nfig, ax = plt.subplots(4,4, figsize=(15,15))\nfor c in col:\n    for i in range(4):\n        if c == col[0]:\n            sample = train[train[c]==1]\n            ax[0,i].set_axis_off()\n            ax[0,i].imshow(sample[\"gblur\"].values[i])\n            ax[0,i].set_title(\"{}\".format(c))\n        elif c == col[1]:\n            sample = train[train[c]==1]\n            ax[1,i].set_axis_off()\n            ax[1,i].imshow(sample[\"gblur\"].values[i])\n            ax[1,i].set_title(\"{}\".format(c))\n        elif c == col[2]:\n            sample = train[train[c]==1]\n            ax[2,i].set_axis_off()\n            ax[2,i].imshow(sample[\"gblur\"].values[i])\n            ax[2,i].set_title(\"{}\".format(c))\n        else:\n            sample = train[train[c]==1]\n            ax[3,i].set_axis_off()\n            ax[3,i].imshow(sample[\"gblur\"].values[i])\n            ax[3,i].set_title(\"{}\".format(c))","690e8163":"edete_img = [cv2.Canny(img, 100, 200) for img in train_image]\n\ntrain[\"edete\"] = edete_img","8c69a957":"# Visualization some sample\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nfig, ax = plt.subplots(4,4, figsize=(15,15))\nfor c in col:\n    for i in range(4):\n        if c == col[0]:\n            sample = train[train[c]==1]\n            ax[0,i].set_axis_off()\n            ax[0,i].imshow(sample[\"edete\"].values[i])\n            ax[0,i].set_title(\"{}\".format(c))\n        elif c == col[1]:\n            sample = train[train[c]==1]\n            ax[1,i].set_axis_off()\n            ax[1,i].imshow(sample[\"edete\"].values[i])\n            ax[1,i].set_title(\"{}\".format(c))\n        elif c == col[2]:\n            sample = train[train[c]==1]\n            ax[2,i].set_axis_off()\n            ax[2,i].imshow(sample[\"edete\"].values[i])\n            ax[2,i].set_title(\"{}\".format(c))\n        else:\n            sample = train[train[c]==1]\n            ax[3,i].set_axis_off()\n            ax[3,i].imshow(sample[\"edete\"].values[i])\n            ax[3,i].set_title(\"{}\".format(c))","d890cac2":"eqhist_img = []\nfor img in train_image:\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    h,s,v = cv2.split(img)\n    h = cv2.equalizeHist(h)\n    s = cv2.equalizeHist(s)\n    v = cv2.equalizeHist(v)\n    hsv = cv2.merge((h,s,v))\n    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    eqhist_img.append(img)\n\ntrain[\"eqhist\"] = eqhist_img","94f77310":"# Visualization some sample\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nfig, ax = plt.subplots(4,4, figsize=(15,15))\nfor c in col:\n    for i in range(4):\n        if c == col[0]:\n            sample = train[train[c]==1]\n            ax[0,i].set_axis_off()\n            ax[0,i].imshow(sample[\"eqhist\"].values[i])\n            ax[0,i].set_title(\"{}\".format(c))\n        elif c == col[1]:\n            sample = train[train[c]==1]\n            ax[1,i].set_axis_off()\n            ax[1,i].imshow(sample[\"eqhist\"].values[i])\n            ax[1,i].set_title(\"{}\".format(c))\n        elif c == col[2]:\n            sample = train[train[c]==1]\n            ax[2,i].set_axis_off()\n            ax[2,i].imshow(sample[\"eqhist\"].values[i])\n            ax[2,i].set_title(\"{}\".format(c))\n        else:\n            sample = train[train[c]==1]\n            ax[3,i].set_axis_off()\n            ax[3,i].imshow(sample[\"eqhist\"].values[i])\n            ax[3,i].set_title(\"{}\".format(c))","1876d714":"clahe_img = []\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(3, 3))\nfor img in train_image:\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    h,s,v = cv2.split(img)\n    h = clahe.apply(h)\n    s = clahe.apply(s)\n    v = clahe.apply(v)\n    hsv = cv2.merge((h,s,v))\n    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n    clahe_img.append(img)\n\ntrain[\"clahe\"] = clahe_img","0990d8a7":"# Visualization some sample\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nfig, ax = plt.subplots(4,4, figsize=(15,15))\nfor c in col:\n    for i in range(4):\n        if c == col[0]:\n            sample = train[train[c]==1]\n            ax[0,i].set_axis_off()\n            ax[0,i].imshow(sample[\"clahe\"].values[i])\n            ax[0,i].set_title(\"{}\".format(c))\n        elif c == col[1]:\n            sample = train[train[c]==1]\n            ax[1,i].set_axis_off()\n            ax[1,i].imshow(sample[\"clahe\"].values[i])\n            ax[1,i].set_title(\"{}\".format(c))\n        elif c == col[2]:\n            sample = train[train[c]==1]\n            ax[2,i].set_axis_off()\n            ax[2,i].imshow(sample[\"clahe\"].values[i])\n            ax[2,i].set_title(\"{}\".format(c))\n        else:\n            sample = train[train[c]==1]\n            ax[3,i].set_axis_off()\n            ax[3,i].imshow(sample[\"clahe\"].values[i])\n            ax[3,i].set_title(\"{}\".format(c))","b1b282b8":"# Difine function\ndef create_rgb_df(sample_df):\n    create_df = pd.DataFrame({})\n    # Create each list\n    red_mean = []\n    red_std = []\n    green_mean = []\n    green_std = []\n    blue_mean = []\n    blue_std = []\n    \n    for i in range(len(sample_df)):\n        red_m = sample_df.values[i][:,:,0].mean()\n        red_s = sample_df.values[i][:,:,0].std()\n        green_m = sample_df.values[i][:,:,1].mean()\n        green_s = sample_df.values[i][:,:,1].std()\n        blue_m = sample_df.values[i][:,:,2].mean()\n        blue_s = sample_df.values[i][:,:,2].std()\n        # Append to list\n        red_mean.append(red_m)\n        red_std.append(red_s)\n        green_mean.append(green_m)\n        green_std.append(green_s)\n        blue_mean.append(blue_m)\n        blue_std.append(blue_s)\n\n    create_df[\"red_mean\"] = red_mean\n    create_df[\"red_std\"] = red_std\n    create_df[\"green_mean\"] = green_mean\n    create_df[\"green_std\"] = green_std\n    create_df[\"blue_mean\"] = blue_mean\n    create_df[\"blue_std\"] = blue_std\n    \n    return create_df","83f194be":"col = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\n\n# healthy\nsampling_1 = train[train[col[0]]==1][\"img_data\"]\nsampling_2 = train[train[col[0]]==1][\"clahe\"]\nhealthy_df_base = create_rgb_df(sampling_1)\nhealthy_df_clahe = create_rgb_df(sampling_2)\n\n# multiple_diseases\nsampling_1 = train[train[col[1]]==1][\"img_data\"]\nsampling_2 = train[train[col[1]]==1][\"clahe\"]\nmulti_df_base = create_rgb_df(sampling_1)\nmulti_df_clahe = create_rgb_df(sampling_2)\n\n# rust\nsampling_1 = train[train[col[2]]==1][\"img_data\"]\nsampling_2 = train[train[col[2]]==1][\"clahe\"]\nrust_df_base = create_rgb_df(sampling_1)\nrust_df_clahe = create_rgb_df(sampling_2)\n\n# scab\nsampling_1 = train[train[col[3]]==1][\"img_data\"]\nsampling_2 = train[train[col[3]]==1][\"clahe\"]\nscab_df_base = create_rgb_df(sampling_1)\nscab_df_clahe = create_rgb_df(sampling_2)","2504e832":"# Visualization of Red std distribution\nfig, ax = plt.subplots(2,2, figsize=(20, 12))\n# healthy\nsns.distplot(healthy_df_base[\"red_std\"], label=\"base\", ax=ax[0,0])\nsns.distplot(healthy_df_clahe[\"red_std\"], label=\"clahe\", ax=ax[0,0])\nax[0,0].set_title(\"Red color distribution, for healthy\")\nax[0,0].legend()\n\n# multi\nsns.distplot(multi_df_base[\"red_std\"], label=\"base\", ax=ax[0,1])\nsns.distplot(multi_df_clahe[\"red_std\"], label=\"clahe\", ax=ax[0,1])\nax[0,1].set_title(\"Red color distribution, for multilple desease\")\nax[0,1].legend()\n\n# rust\nsns.distplot(rust_df_base[\"red_std\"], label=\"base\", ax=ax[1,0])\nsns.distplot(rust_df_clahe[\"red_std\"], label=\"clahe\", ax=ax[1,0])\nax[1,0].set_title(\"Red color distribution, for rust\")\nax[1,0].legend()\n\n# scab\nsns.distplot(scab_df_base[\"red_std\"], label=\"base\", ax=ax[1,1])\nsns.distplot(scab_df_clahe[\"red_std\"], label=\"clahe\", ax=ax[1,1])\nax[1,1].set_title(\"Red color distribution, for scab\")\nax[1,1].legend()","00179efb":"# Visualization of Blue std distribution\nfig, ax = plt.subplots(2,2, figsize=(20, 12))\n# healthy\nsns.distplot(healthy_df_base[\"blue_std\"], label=\"base\", ax=ax[0,0])\nsns.distplot(healthy_df_clahe[\"blue_std\"], label=\"clahe\", ax=ax[0,0])\nax[0,0].set_title(\"Blue color distribution, for healthy\")\nax[0,0].legend()\n\n# multi\nsns.distplot(multi_df_base[\"blue_std\"], label=\"base\", ax=ax[0,1])\nsns.distplot(multi_df_clahe[\"blue_std\"], label=\"clahe\", ax=ax[0,1])\nax[0,1].set_title(\"Blue color distribution, for multilple desease\")\nax[0,1].legend()\n\n# rust\nsns.distplot(rust_df_base[\"blue_std\"], label=\"base\", ax=ax[1,0])\nsns.distplot(rust_df_clahe[\"blue_std\"], label=\"clahe\", ax=ax[1,0])\nax[1,0].set_title(\"Blue color distribution, for rust\")\nax[1,0].legend()\n\n# scab\nsns.distplot(scab_df_base[\"blue_std\"], label=\"base\", ax=ax[1,1])\nsns.distplot(scab_df_clahe[\"blue_std\"], label=\"clahe\", ax=ax[1,1])\nax[1,1].set_title(\"Blue color distribution, for scab\")\nax[1,1].legend()","0f1e88cd":"# Visualization of Red mean distribution\nfig, ax = plt.subplots(2,2, figsize=(20, 12))\n# healthy\nsns.distplot(healthy_df_base[\"green_std\"], label=\"base\", ax=ax[0,0])\nsns.distplot(healthy_df_clahe[\"green_std\"], label=\"clahe\", ax=ax[0,0])\nax[0,0].set_title(\"Green color distribution, for healthy\")\nax[0,0].legend()\n\n# multi\nsns.distplot(multi_df_base[\"green_std\"], label=\"base\", ax=ax[0,1])\nsns.distplot(multi_df_clahe[\"green_std\"], label=\"clahe\", ax=ax[0,1])\nax[0,1].set_title(\"Green color distribution, for multilple desease\")\nax[0,1].legend()\n\n# rust\nsns.distplot(rust_df_base[\"green_std\"], label=\"base\", ax=ax[1,0])\nsns.distplot(rust_df_clahe[\"green_std\"], label=\"clahe\", ax=ax[1,0])\nax[1,0].set_title(\"Green color distribution, for rust\")\nax[1,0].legend()\n\n# scab\nsns.distplot(scab_df_base[\"green_std\"], label=\"base\", ax=ax[1,1])\nsns.distplot(scab_df_clahe[\"green_std\"], label=\"clahe\", ax=ax[1,1])\nax[1,1].set_title(\"Green color distribution, for scab\")\nax[1,1].legend()","6b00c7b4":"class prepro_DenseNet():\n    # image data:Series data, target:target data dateframe, size:image size\n    def __init__(self, image_data, target, size):\n        self.image = image_data\n        self.target = target\n        self.size = size\n        pass\n    \n    # Dimension change and create train and val data\n    # test_size:split size\n    def preprocessing(self, test_size, random_state):   \n        self.test_size = test_size\n        self.random_state = random_state\n        \n        # Data dimension\n        X_Train = np.ndarray(shape=(len(self.image), self.size, self.size, 3), dtype=np.float32)\n        # Change to np.ndarray\n        for i in range(len(self.image)):\n            X_Train[i]=self.image[i]\n            i=i+1\n    \n        # Scaling\n        X_Train = X_Train\/255\n\n        # change to np.array\n        self.target = np.array(self.target.values)\n        \n        # split train and val data\n        X_train, X_val, y_train, y_val = train_test_split(X_Train, self.target, test_size=self.test_size, random_state=self.random_state)\n        self.X_train = X_train\n        self.X_val = X_val\n        self.y_train = y_train\n        self.y_val = y_val \n            \n    def define_DenseNet121(self):\n        densenet = DenseNet121(include_top=False, weights=\"imagenet\")\n        \n        inputs = Input(shape=(self.size, self.size, 3))\n        x = densenet(inputs)\n        x = GlobalAveragePooling2D()(x)\n        x = Dense(1024, activation='relu')(x)\n        x = Dropout(0.3)(x)\n        x = Dense(512, activation='relu')(x)\n        output = Dense(4, activation=\"softmax\", name=\"root\")(x)\n        \n        model = Model(inputs, output)\n        \n        optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.0001, decay=0.0001)\n        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n        self.model = model\n        \n        return self.model, self.model.summary()\n        \n    def exe_DenseNet121(self, batch_size, epochs, save_file):\n        self.save_file = str(save_file)\n        self.batch_size = batch_size\n        self.epochs = epochs\n        # Datagen\n        datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)\n        datagen.fit(self.X_train)\n        # early stopping and model checkpoint\n        es_cb = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n        cp_cb = ModelCheckpoint(\"{}\".format(self.save_file), monitor=\"val_loss\", verbose=1, save_best_only=True)\n        \n        history_ = self.model.fit_generator(datagen.flow(self.X_train, self.y_train, batch_size=self.batch_size),\n                                                         steps_per_epoch=len(self.X_train) \/ self.batch_size, \n                                                         epochs=self.epochs, \n                                                         validation_data=datagen.flow(self.X_val, self.y_val, batch_size=self.batch_size), \n                                                         callbacks=[es_cb, cp_cb])\n        self.history_ = history_\n        \n    def roc_auc_score(self):\n        # prediction\n        y_pred = load_model(\"{}\".format(self.save_file)).predict(self.X_val)\n        # print roc_auc score\n        print(\"roc_auc score:{}\".format(roc_auc_score(y_true=self.y_val, y_score=y_pred, average=\"weighted\").round(3)))\n        \n    def visualization(self):\n        # loss and accuracy \n        train_loss = self.history_.history[\"loss\"]\n        val_loss = self.history_.history[\"val_loss\"]\n\n        train_acc = self.history_.history[\"accuracy\"]\n        val_acc = self.history_.history[\"val_accuracy\"]\n\n        # Visualization\n        fig, ax = plt.subplots(1,2,figsize=(20,6))\n        ax[0].plot(range(len(train_loss)), train_loss, label=\"train_loss\")\n        ax[0].plot(range(len(val_loss)), val_loss, label=\"val_loss\")\n        ax[0].set_xlabel(\"epoch\")\n        ax[0].set_ylabel(\"loss\")\n        ax[0].legend()\n\n        ax[1].plot(range(len(train_acc)), train_acc, label=\"train_acc\")\n        ax[1].plot(range(len(val_acc)), val_acc, label=\"val_acc\")\n        ax[1].set_xlabel(\"epoch\")\n        ax[1].set_ylabel(\"accuracy\")\n        ax[1].legend()","92ffb497":"# data\nimage_data = train[\"img_data\"]\ntarget = train[['healthy', 'multiple_diseases', 'rust', 'scab']]\nsize = img_size\n\n# preprocessing\ntest_size=0.2\nrandom_state=20\nsave_file = \"dense121_v1\"\n\n# Densenet\nbatch_size = 32\nepochs = 100","572b92a8":"# Execution\nbase = prepro_DenseNet(image_data, target, size)\nbase.preprocessing(test_size, random_state)\nbase.define_DenseNet121()","646526e5":"base.exe_DenseNet121(batch_size, epochs, save_file)","05c2f00d":"# roc_auc score\nbase.roc_auc_score()","3ce1e31f":"# visualization\nbase.visualization()","cdf8e607":"# data\nimage_data = train[\"clahe\"]\ntarget = train[['healthy', 'multiple_diseases', 'rust', 'scab']]\nsize = img_size\n\n# preprocessing\ntest_size=0.2\nrandom_state=20\nsave_file = \"dense121_v2\"\n\n# Densenet\nbatch_size = 32\nepochs = 100\n\n# Execution\neqhist = prepro_DenseNet(image_data, target, size)\neqhist.preprocessing(test_size, random_state)\neqhist.define_DenseNet121()","390ab451":"eqhist.exe_DenseNet121(batch_size, epochs, save_file)","3da6bb54":"# roc_auc score\neqhist.roc_auc_score()","a8633263":"# visualization\neqhist.visualization()","030b4cf4":"# Data dimension\nX_Test = np.ndarray(shape=(len(test_image), 256, 256, 3), dtype=np.float32)\n# Change to np.ndarray\nfor i in range(len(test_image)):\n    X_Test[i]=test_image[i]\n    i=i+1\n# Scaling\nX_Test = X_Test\/255","bcfe6120":"Y_pred = load_model(\"dense121_v1\").predict(X_Test)\nY_pred.shape","09cab9a4":"Y_pred = pd.DataFrame(Y_pred, columns=col)\ntest[col] = Y_pred\nsubmit = test\nsubmit.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","52caa538":"Y_pred = load_model(\"dense121_v2\").predict(X_Test)\nY_pred.shape","ac7cc205":"Y_pred = pd.DataFrame(Y_pred, columns=col)\ntest[col] = Y_pred\nsubmit = test\nsubmit.to_csv('my_submission2.csv', index=False)\nprint(\"Your submission was successfully saved!\")","8a9b3846":"## Base data","bc3413f7":"## Define model","59e099ad":"It seems that human vision can expect a sufficient effect, but if this is learned by deep learning, will the expected effect be obtained? Actually calculated and confirmed","bbc20e7e":"## GaussianBlur","0fa45ccc":"## Edge detection","1b58cdda":"## createCLAHE","1d289c6f":"## Data loading","4c1eda93":"The model used DenseNet121.","a3d66152":"### Test data loading","40a3261e":"## Filter","b54b7fa2":"## Contrast enhancement","32a88360":"### Training data loading","c0feea80":"The result of the Gaussian Bluer filter blurred the whole image. However, it can be said that the link remains firmly due to the characteristics of the leaf of the subject, and the characteristics themselves can be made clear from other noises.<br>\nThe purpose of this classification is to extract features other than large contours such as scab. In that case it may be inappropriate.","51ff7fe8":"# Image pre processing and DenseNet","7f189cf0":"## This analysis and prediction tried the following:\n- Visually check the effects of image processing using Open CV.\n- Contrast processing, which is easy to visually classify, is performed, and the prediction results are compared with the base model.\n- DenseNet is used for prediction, and the effect is confirmed by the roc auc score.\n- Since it is effective, we also preprocessed the test data, made prediction results, and submitted it.","50eb5d93":"Canny's result is a fairly characteristic image, but it makes the contours of the leaves more clearly and easily understandable. In addition, the veins of the leaves are also captured, and although they are simple pictures, the features can be captured sufficiently. <br>\nHowever, it can be seen that the contours are mixed depending on the background. It may be effective to adjust the filter thresholds one by one, but it is difficult to add filter conditions uniformly.","8e617774":"### Perform various pre-processing using Open cv, check images and evaluate classification performance","c978eb48":"Can Equalizes the histogram be more characteristic of scab? And carried out to emphasize the contrast. The result was esoteric. Although some features are captured by rust etc., they are also affected by noise such as shadows and non-targets, which may be unsuitable for identification.","493dd8dc":"## Libraries","420d566c":"## createCLAHE data","4fe6d52c":"## Equalizes the histogram","b2a7398a":"## Color distribution\nTo confirm the effect of contrast, we confirmed the color deviation of each image","a726a275":"The contrast enhancement by createCLAHE is fairly easy to understand visually. The outline of the leaves, the state of rust, and the spread of the scab are easy to understand.<Br>","9cc859fb":"## Canny","f92462e3":"## Test data prediction","9fa1254b":"It can be seen that the deviation is large for each color, and the strength of the color is clear. This makes the image visually clear.","be476d07":"The results of image contrast enhancement and the classification performance of the original data were compared by DenseNEt.<br>\nAs a result, it was found that the prediction performance is almost equal, did not improve.<br>\n\nImage processing was carried out aiming at the visual effect, but it did not go as expected. Is it really effective? Can only be understood by actually performing the analysis."}}