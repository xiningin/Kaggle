{"cell_type":{"27f97b29":"code","01f6b862":"code","ac7d1add":"code","0c1de833":"code","53045b42":"code","83d8f038":"code","de260845":"code","a00773da":"code","2bcf020e":"code","e94f294e":"code","14d03c1b":"code","cd4e6c9c":"code","f2f7bf76":"code","03f85405":"code","b5a1b7b6":"code","c08af39c":"code","6e915efe":"markdown"},"source":{"27f97b29":"import os\nimport numpy as np\nimport pandas as pd\n\nimport albumentations as A\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.optim as optim\n\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\n__print__ = print\n\ndef print(string):\n    os.system(f'echo \\\"{string}\\\"')\n    __print__(string)","01f6b862":"DIR_INPUT = '\/kaggle\/input\/plant-pathology-2020-fgvc7'\n\nSEED = 42\nN_FOLDS = 5\nN_EPOCHS = 10\nBATCH_SIZE = 64\nSIZE = 512","ac7d1add":"class PlantDataset(Dataset):\n    \n    def __init__(self, df, transforms=None):\n    \n        self.df = df\n        self.transforms=transforms\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_src = DIR_INPUT + '\/images\/' + self.df.loc[idx, 'image_id'] + '.jpg'\n        # print(image_src)\n        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        labels = self.df.loc[idx, ['healthy', 'multiple_diseases', 'rust', 'scab']].values\n        labels = torch.from_numpy(labels.astype(np.int8))\n        labels = labels.unsqueeze(-1)\n        \n        if self.transforms:\n            transformed = self.transforms(image=image)\n            image = transformed['image']\n\n        return image, labels","0c1de833":"class PlantModel(nn.Module):\n    \n    def __init__(self, num_classes=4):\n        super().__init__()\n        \n        self.backbone = torchvision.models.resnet18(pretrained=True)\n        \n        in_features = self.backbone.fc.in_features\n\n        self.logit = nn.Linear(in_features, num_classes)\n        \n    def forward(self, x):\n        batch_size, C, H, W = x.shape\n        \n        x = self.backbone.conv1(x)\n        x = self.backbone.bn1(x)\n        x = self.backbone.relu(x)\n        x = self.backbone.maxpool(x)\n\n        x = self.backbone.layer1(x)\n        x = self.backbone.layer2(x)\n        x = self.backbone.layer3(x)\n        x = self.backbone.layer4(x)\n        \n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        x = F.dropout(x, 0.25, self.training)\n\n        x = self.logit(x)\n\n        return x","53045b42":"transforms_train = A.Compose([\n    A.RandomResizedCrop(height=SIZE, width=SIZE, p=1.0),\n    A.Flip(),\n    A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n\n    # Pixels\n    A.OneOf([\n        A.IAAEmboss(p=1.0),\n        A.IAASharpen(p=1.0),\n        A.Blur(p=1.0),\n    ], p=0.5),\n\n    # Affine\n    A.OneOf([\n        A.ElasticTransform(p=1.0),\n        A.IAAPiecewiseAffine(p=1.0)\n    ], p=0.5),\n\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n])\n\ntransforms_valid = A.Compose([\n    A.Resize(height=SIZE, width=SIZE, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n])","83d8f038":"submission_df = pd.read_csv(DIR_INPUT + '\/sample_submission.csv')\nsubmission_df.iloc[:, 1:] = 0\n\nsubmission_df.head()","de260845":"dataset_test = PlantDataset(df=submission_df, transforms=transforms_valid)\ndataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)","a00773da":"train_df = pd.read_csv(DIR_INPUT + '\/train.csv')\n\n# For debugging.\n# train_df = train_df.sample(n=100)\n# train_df.reset_index(drop=True, inplace=True)\n\ntrain_labels = train_df.iloc[:, 1:].values\n\n# Need for the StratifiedKFold split\ntrain_y = train_labels[:, 2] + train_labels[:, 3] * 2 + train_labels[:, 1] * 3\n\ntrain_df.head()","2bcf020e":"folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\noof_preds = np.zeros((train_df.shape[0], 4))","e94f294e":"# Download pretrained weights.\nmodel = PlantModel(num_classes=4)","14d03c1b":"class DenseCrossEntropy(nn.Module):\n\n    def __init__(self):\n        super(DenseCrossEntropy, self).__init__()\n        \n        \n    def forward(self, logits, labels):\n        logits = logits.float()\n        labels = labels.float()\n        \n        logprobs = F.log_softmax(logits, dim=-1)\n        \n        loss = -labels * logprobs\n        loss = loss.sum(-1)\n\n        return loss.mean()\n    ","cd4e6c9c":"def train_one_fold(i_fold, model, criterion, optimizer, dataloader_train, dataloader_valid):\n    \n    train_fold_results = []\n\n    for epoch in range(N_EPOCHS):\n\n        # print('  Epoch {}\/{}'.format(epoch + 1, N_EPOCHS))\n        # print('  ' + ('-' * 20))\n        os.system(f'echo \\\"  Epoch {epoch}\\\"')\n\n        model.train()\n        tr_loss = 0\n\n        for step, batch in enumerate(dataloader_train):\n\n            images = batch[0]\n            labels = batch[1]\n\n            images = images.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.float)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels.squeeze(-1))                \n            loss.backward()\n\n            tr_loss += loss.item()\n\n            optimizer.step()\n            optimizer.zero_grad()\n\n        # Validate\n        model.eval()\n        val_loss = 0\n        val_preds = None\n        val_labels = None\n\n        for step, batch in enumerate(dataloader_valid):\n\n            images = batch[0]\n            labels = batch[1]\n\n            if val_labels is None:\n                val_labels = labels.clone().squeeze(-1)\n            else:\n                val_labels = torch.cat((val_labels, labels.squeeze(-1)), dim=0)\n\n            images = images.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.float)\n\n            with torch.no_grad():\n                outputs = model(images)\n\n                loss = criterion(outputs, labels.squeeze(-1))\n                val_loss += loss.item()\n\n                preds = torch.softmax(outputs, dim=1).data.cpu()\n\n                if val_preds is None:\n                    val_preds = preds\n                else:\n                    val_preds = torch.cat((val_preds, preds), dim=0)\n\n\n        train_fold_results.append({\n            'fold': i_fold,\n            'epoch': epoch,\n            'train_loss': tr_loss \/ len(dataloader_train),\n            'valid_loss': val_loss \/ len(dataloader_valid),\n            'valid_score': roc_auc_score(val_labels, val_preds, average='macro'),\n        })\n\n    return val_preds, train_fold_results","f2f7bf76":"submissions = None\ntrain_results = []\n\nfor i_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, train_y)):\n    print(\"Fold {}\/{}\".format(i_fold + 1, N_FOLDS))\n\n    valid = train_df.iloc[valid_idx]\n    valid.reset_index(drop=True, inplace=True)\n\n    train = train_df.iloc[train_idx]\n    train.reset_index(drop=True, inplace=True)    \n\n    dataset_train = PlantDataset(df=train, transforms=transforms_train)\n    dataset_valid = PlantDataset(df=valid, transforms=transforms_valid)\n\n    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)\n    dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n\n    device = torch.device(\"cuda:0\")\n\n    model = PlantModel(num_classes=4)\n    model.to(device)\n\n    criterion = DenseCrossEntropy()\n    plist = [{'params': model.parameters(), 'lr': 5e-5}]\n    optimizer = optim.Adam(plist, lr=5e-5)\n    \n    val_preds, train_fold_results = train_one_fold(i_fold, model, criterion, optimizer, dataloader_train, dataloader_valid)\n    oof_preds[valid_idx, :] = val_preds.numpy()\n    \n    train_results = train_results + train_fold_results\n\n    model.eval()\n    test_preds = None\n\n    for step, batch in enumerate(dataloader_test):\n\n        images = batch[0]\n        images = images.to(device, dtype=torch.float)\n\n        with torch.no_grad():\n            outputs = model(images)\n\n            if test_preds is None:\n                test_preds = outputs.data.cpu()\n            else:\n                test_preds = torch.cat((test_preds, outputs.data.cpu()), dim=0)\n    \n    \n    # Save predictions per fold\n    submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(test_preds, dim=1)\n    submission_df.to_csv('submission_fold_{}.csv'.format(i_fold), index=False)\n\n    # logits avg\n    if submissions is None:\n        submissions = test_preds \/ N_FOLDS\n    else:\n        submissions += test_preds \/ N_FOLDS\n\nprint(\"5-Folds CV score: {:.4f}\".format(roc_auc_score(train_labels, oof_preds, average='macro')))","03f85405":"train_results = pd.DataFrame(train_results)\ntrain_results.head(10)","b5a1b7b6":"submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(submissions, dim=1)\nsubmission_df.to_csv('submission.csv', index=False)","c08af39c":"submission_df.head(10)","6e915efe":"Plant Pathology 2020\nImplemented \/ planned\n[\u2714] - Starter code\n[\u2714] - 5-Folds CV\n[\u2714] - Albumentations\n[\u2714] - Visualize training history\n[-] - Schedulers\n[-] - Train longer (without overfitting)\n[-] - Experimenting with ResNets\n[-] - Experimenting with EfficientNets\n[-] - Experimenting with SEResNeXts\n[-] - Experimenting with different input image size\n[-] - TTA\n[-] - OHEM\n[-] - Pseudo labelling\n[-] - Mixup\n[-] - Cutmix\n[-] - Cutout\nNotebook Versions\nv1: Starter code\nv4: 5-Folds CV. The gap between local and public score seems a bit high, probably because of the small number of validation samples. I added 5-folds (for now, simple k-fold) CV to see whether it reduces the difference.\nv5: More augmentations. I try to train for more epochs. To prevent overfitting, I added more augmentations.\nv6: Changed to softmax + cross entropy. I used Sigmoid+BCE, not sure why. Note: There was no overfit during training (v5), but the CV-LB gap is still high.\nv8: According to my EDA the classes are not balanced (multiple_deseases is only 5%). I replace KFold to StratifiedKFold.\nv9: Input image size: 256px -> 512px"}}