{"cell_type":{"47209691":"code","b7cf8085":"code","b5bbba2f":"code","49bb1e1c":"code","4146fa89":"code","d7f52172":"code","1e959b5f":"code","95871159":"code","163ddbae":"code","edf4f03e":"code","43ee9d2a":"code","839ff74e":"code","8826f58f":"code","4a3b9de0":"markdown","1665b9d6":"markdown","acae307b":"markdown","cde3c822":"markdown","3334fbbe":"markdown","d6b60a5f":"markdown","12257724":"markdown","ae960581":"markdown","4ea1c91d":"markdown","eb408492":"markdown","dd1b2f7e":"markdown","6c42cbee":"markdown","e2513fef":"markdown","c6d6b28f":"markdown"},"source":{"47209691":"from fastai import *\nfrom fastai.vision import *\n\npath = untar_data(URLs.PETS)\npath_anno = path\/'annotations'\npath_img = path\/'images'\nfnames = get_image_files(path_img)\nnp.random.seed(2)\npat = r'\/([^\/]+)_\\d+.jpg$'","b7cf8085":"bs = 16*5","b5bbba2f":"data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs).normalize(imagenet_stats)\nlearn = cnn_learner(data, models.resnet101, metrics=error_rate)","49bb1e1c":"learn.model","4146fa89":"from fastai.utils.mem import GPUMemTrace\nwith GPUMemTrace():\n  learn.fit_one_cycle(4)","d7f52172":"########################################\n## Defaults\n########################################\nimport torch\nimport torch.nn as nn\nfrom torch.utils.checkpoint import checkpoint, checkpoint_sequential\n\nfrom fastai.callbacks.hooks import *\n\ndef cnn_config(arch):\n    \"Get the metadata associated with `arch`.\"\n    torch.backends.cudnn.benchmark = True\n    return model_meta.get(arch, _default_meta)\n\ndef _default_split(m:nn.Module): return (m[1],)\ndef _resnet_split(m:nn.Module): return (m[0][6],m[1])\n\n_default_meta    = {'cut':None, 'split':_default_split}\n_resnet_meta     = {'cut':-2, 'split':_resnet_split }\n\nmodel_meta = {\n    models.resnet18 :{**_resnet_meta}, models.resnet34: {**_resnet_meta},\n    models.resnet50 :{**_resnet_meta}, models.resnet101:{**_resnet_meta},\n    models.resnet152:{**_resnet_meta}}\n","1e959b5f":"########################################\n## Custom Checkpoint\n########################################\nclass CheckpointModule(nn.Module):\n    def __init__(self, module, num_segments=1):\n        super(CheckpointModule, self).__init__()\n        assert num_segments == 1 or isinstance(module, nn.Sequential)\n        self.module = module\n        self.num_segments = num_segments\n\n    def forward(self, *inputs):\n        if self.num_segments > 1:\n            return checkpoint_sequential(self.module, self.num_segments, *inputs)\n        else:\n            return checkpoint(self.module, *inputs)\n\n########################################\n# Extract the sequential layers for resnet\n########################################\ndef layer_config(arch):\n    \"Get the layers associated with `arch`.\"\n    return model_layers.get(arch)\n\nmodel_layers = {\n    models.resnet18 :[2, 2, 2, 2], models.resnet34: [3, 4, 6, 3],\n    models.resnet50 :[3, 4, 6, 3], models.resnet101:[3, 4, 23, 3],\n    models.resnet152:[3, 8, 36, 3]}","95871159":"########################################\n## Send sequential layers in custom_body to Checkpoint\n########################################\ndef create_body1(arch:Callable, pretrained:bool=True, cut:Optional[Union[int, Callable]]=None):\n    \"Cut off the body of a typically pretrained `model` at `cut` (int) or cut the model as specified by `cut(model)` (function).\"\n    model = arch(pretrained)\n    cut = ifnone(cut, cnn_config(arch)['cut'])\n    dummy_tensor = torch.ones(1, dtype=torch.float32, requires_grad=True)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if   isinstance(cut, int):\n    #Checkpoint - Changes Start\n      if (arch.__name__).find(\"resnet\")==0:       # Check if the Model is resnet                                                        \n        n = 4                                     # Initial 4 Layers didn't have sequential and were not applicable with Checkpoint\n        layers = layer_config(arch)               # Fetch the sequential layer split\n        out = nn.Sequential(*list(model.children())[:cut][:n],\n                            *[CheckpointModule(x, min(checkpoint_segments, layers[i])) for i, x in enumerate(list(model.children())[:cut][n:])])\n        # Join the Initial 4 layers with Checkpointed sequential layers\n      else:\n        out = nn.Sequential(*list(model.children())[:cut])\n      return out\n    #Checkpoint - Changes End\n    elif isinstance(cut, Callable): return cut(model)\n    else:                           raise NamedError(\"cut must be either integer or a function\")\n","163ddbae":"## From base - function renamed\ndef create_head1(nf:int, nc:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n                concat_pool:bool=True, bn_final:bool=False):\n    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n    ps = listify(ps)\n    if len(ps) == 1: ps = [ps[0]\/2] * (len(lin_ftrs)-2) + ps\n    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n    layers = [pool, Flatten()]\n    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n        layers += bn_drop_lin(ni, no, True, p, actn)\n    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n    return nn.Sequential(*layers)\n\n## From base - function renamed\ndef create_cnn1_model1(base_arch:Callable, nc:int, cut:Union[int,Callable]=None, pretrained:bool=True,\n                     lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[nn.Module]=None,\n                     bn_final:bool=False, concat_pool:bool=True):\n    \"Create custom convnet architecture\"\n    body = create_body1(base_arch, pretrained, cut)\n    if custom_head is None:\n        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n        head = create_head1(nf, nc, lin_ftrs, ps=ps, concat_pool=concat_pool, bn_final=bn_final)\n    else: head = custom_head\n    return nn.Sequential(body, head)\n\n## From base - function renamed\ndef cnn_learner1(data:DataBunch, base_arch:Callable, cut:Union[int,Callable]=None, pretrained:bool=True,\n                lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[nn.Module]=None,\n                split_on:Optional[SplitFuncOrIdxList]=None, bn_final:bool=False, init=nn.init.kaiming_normal_,\n                concat_pool:bool=True, **kwargs:Any)->Learner:\n    \"Build convnet style learner.\"\n    meta = cnn_config(base_arch)\n    model = create_cnn1_model1(base_arch, data.c, cut, pretrained, lin_ftrs, ps=ps, custom_head=custom_head,\n        bn_final=bn_final, concat_pool=concat_pool)\n    learn = Learner(data, model, **kwargs)\n    learn.split(split_on or meta['split'])\n    if pretrained: learn.freeze()\n    if init: apply_init(model[1], init)\n    return learn","edf4f03e":"## Clear redundant Memory\ngc.collect()\nimport torch\ntorch.cuda.empty_cache()\nlearn.purge()\ndel data\ndel learn","43ee9d2a":"bs = bs * 2\ncheckpoint_segments = 4\ndata = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs).normalize(imagenet_stats)\nlearn = cnn_learner1(data, models.resnet101, metrics=error_rate)","839ff74e":"learn.model","8826f58f":"from fastai.utils.mem import GPUMemTrace\nwith GPUMemTrace():\n  learn.fit_one_cycle(4)","4a3b9de0":"Now to the code, the usual workflow for classifiying dogs, from lesson 1","1665b9d6":"**Logic of the Process**\n\nThe original optimized code [for resnet](https:\/\/github.com\/prigoyal\/pytorch_memonger\/blob\/master\/models\/optimized\/resnet_new.py) from *Priya Goyal* had only implementations for 'resnet1001'. The reason assumed is that the layers is not defined in the forward block, unlike reset 18 through 152.\n\nHowever, this [implementation](https:\/\/github.com\/eladhoffer\/convNet.pytorch\/blob\/master\/models\/resnet.py) from *Elad Hoffer* overcame this by defining model at a feature method of class 'Resnet' module, and then inheriting this in class 'ResNet_imagenet' where layers are defined and checkpointed.\n\nWith FastAI, you have infinitesimal customization options, where one does not has to go to that level of code changes from the base.\n\nWe've used the [CheckpointModule](https:\/\/github.com\/eladhoffer\/convNet.pytorch\/blob\/master\/models\/modules\/checkpoint.py) from the repository and repurposed to fit with FastAI code.","acae307b":"The Sequential layers starting from 5th position (containing multiple Basic Blocks) are the ones we are interested in.","cde3c822":"**Memory Optimization with Checkpoints**\n\nWith DeepLearning, GPU memory has always been the handicap when it ccomes to handling larger sized images with deeper networks.\nUnless you have access to V100 GPU, you wouldn't need to be worrying about your model in a constrained batch size.\n\nA typical flow of a backprogogation computiational graph can be represented by this figure.\n\n![](https:\/\/miro.medium.com\/max\/676\/0*NARheCDvdoPc4A8z.)\n\n\nTo optimize the memory usage, the idea is to free up the memory, by storing away the computations. This will enable reusage of the saved computation, rather than recalculating it everytime.\n\n![](https:\/\/miro.medium.com\/max\/676\/0*udMSiPD0kZHum-sZ.)\n\n\nThis is where the concept of checkpointing compes into play. Rather store or forget all the computations, we identify strategic nodes, to save, such that the memory usage is optimized.\n\n![](https:\/\/miro.medium.com\/max\/1355\/0*VEYowymIqvNc2HzB.)","3334fbbe":"Notice all the Sequential layer after 4th Layer - MaxPool2d are now of type CheckPoint Module. And since we are not changing the architecture as such, pre-trained weights can be used as we usually do.","d6b60a5f":"At times the kernel was able to execute 64 x 12. But to be at safer side, it was decided to place the batchsize 64 x 10 to prevent Kernel OOM","12257724":"**Training: resnet101 - with Checkpoint**","ae960581":"**References:**\n* https:\/\/medium.com\/tensorflow\/fitting-larger-networks-into-memory-583e3c758ff9 - Fitting Larger Networks in Memory\n* https:\/\/github.com\/prigoyal\/pytorch_memonger\/blob\/master\/tutorial\/Checkpointing_for_PyTorch_models.ipynb - Original source depiciting benefits and usage of checkpointing\n* https:\/\/github.com\/eladhoffer\/convNet.pytorch\/blob\/master\/models\/modules\/checkpoint.py - Code for checkpoint module\n* https:\/\/github.com\/eladhoffer\/convNet.pytorch\/blob\/master\/models\/resnet.py - Variation of base Resnet Model to enable Checkpointing\n* https:\/\/github.com\/pnvijay\/fastaiv3\/blob\/master\/ConvLearner_Lesson1_Fastaiv3.ipynb - Nice explanation on internals of FastAI CNN Learner\n* https:\/\/discuss.pytorch.org\/t\/checkpoint-with-no-grad-requiring-inputs-problem\/19117\/11 - To overcome \"UserWarning: None of the inputs have requires_grad=True. Gradients will be None\"","4ea1c91d":"The only change done with respect to the base code is on 'create_body1' where in instead returning the default **nn.Sequential(*list(model.children())[:cut]) ** , we are refactoring the sequential layers with **CheckpointModule**.\n\nEverything else is same from current FastAI code repo.","eb408492":"*Note*: With bs = 16 * 6,  Kernel would fail with OOM on default workflow. \n","dd1b2f7e":"**Training: resnet101 - No Checkpoint**","6c42cbee":"There is still a warning with regards to the checkpoint usage -*UserWarning: None of the inputs have requires_grad=True. Gradients will be None*, which is discussed [here](https:\/\/discuss.pytorch.org\/t\/checkpoint-with-no-grad-requiring-inputs-problem\/19117\/7). This will be updated in forth coming version.","e2513fef":"If you are constrained on only using Google Colab\/Kaggle\/in-house-limited memory for your experiments, this little trick might just help you.\n\n**Please Upvote if you liked the kernel**","c6d6b28f":"**Visual Flow of a Computational Graph with checkpoint**\n\n![](https:\/\/miro.medium.com\/max\/676\/0*s7U1QDfSXuVd1LrF.)"}}