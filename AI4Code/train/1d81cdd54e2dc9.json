{"cell_type":{"5a6a143d":"code","b8cd72ba":"code","c93dba3e":"code","4522addf":"code","55486654":"code","656886e3":"code","04bf2631":"code","ed1235fa":"code","f069a3fd":"code","b8abcd6a":"code","e493b93d":"code","dc17dbd3":"code","63bf3ce9":"code","77e193dc":"code","e0a29491":"code","49820e49":"code","8afea52c":"code","e6766eeb":"code","4facc201":"code","c6ea5abb":"code","fb29a3b7":"code","cfe10bd6":"code","d2742727":"code","09f31a8f":"code","ac4fd74f":"code","c8b2a6a2":"code","35f2e476":"code","6fa7bebd":"code","93716841":"code","bf83e824":"code","b1384200":"code","086ebe24":"code","e97330f2":"code","135ab40d":"code","fbfe8ef2":"markdown","93a469f6":"markdown","0f2f2269":"markdown","5ac6ee34":"markdown","d870a8b1":"markdown","42f454e3":"markdown","816df4bb":"markdown","d7a47238":"markdown","1b0d55ad":"markdown","d49153ea":"markdown","6c35f61c":"markdown","3a012375":"markdown","9f828237":"markdown","3d6e57a0":"markdown","4d69f01a":"markdown","abe47e74":"markdown","de020132":"markdown","e984e134":"markdown","f334f69a":"markdown","a9f159a1":"markdown","47222aac":"markdown","7b0b1d57":"markdown","0cd1cb95":"markdown","29048b14":"markdown","5cfa34f6":"markdown"},"source":{"5a6a143d":"# import packages\nimport os\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport warnings\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nimport seaborn as sns\n\n# setting up options\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')\n\nimport warnings as wr\nwr.filterwarnings(\"ignore\") #to ignore the warnings\n\n","b8cd72ba":"#Reading the csv file heart.csv in variable \ndf=pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","c93dba3e":"# looking at the first 5 rows of our data\ndf.head()","4522addf":"df.tail()","55486654":"print('Number of rows are :-',df.shape[0], ',and number of columns are :-',df.shape[1])","656886e3":"df.info()","04bf2631":"df.isnull().sum()","ed1235fa":"df.columns","f069a3fd":"#counting duplicate \ndf.duplicated().sum()","b8abcd6a":"df.drop_duplicates(inplace=True)\nprint('Number of rows are :',df.shape[0], ',and number of columns are :',df.shape[1])","e493b93d":"df.describe().T","dc17dbd3":"#This is to look at what all unique values have . Just trying to use python\nlist_col=['sex','chol','trtbps','cp','thall','exng']\n\nfor col in list_col: \n    print('{} :{} ' . format(col.upper(),df[col].unique()))","63bf3ce9":"print(f'Number of people having sex as 0 are {df.sex.value_counts()[0]} and Number of people having sex as 1 are {df.sex.value_counts()[1]}')\nplt.figure(figsize=(12,6))\nax=plt.axes()\nax.set_facecolor(\"green\")\np = sns.countplot(data=df, x=\"sex\", palette='pastel')\n","77e193dc":"ax=plt.axis()\nsns.countplot(x='cp', data=df, palette='pastel')","e0a29491":"sns.countplot(x='fbs', data=df, palette='pastel')","49820e49":"sns.countplot(x='thall', data=df, palette='pastel')","8afea52c":"sns.countplot(x='restecg', data=df, palette='pastel')","e6766eeb":"plt.figure(figsize = (10,10))\nsns.violinplot(x='caa',y='age',data=df)\nsns.swarmplot(x=df['caa'],y=df['age'],hue=df['output'], palette='pastel')","4facc201":"integer_features = ['age','chol','trtbps','cp','thall','exng']\nunique_values_train = pd.DataFrame(df[integer_features].nunique())\nunique_values_train = unique_values_train.reset_index(drop=False)\nunique_values_train.columns = ['Features', 'Count']\n\nunique_values_percent_train = pd.DataFrame(df[integer_features].nunique()\/df.shape[0])\nunique_values_percent_train = unique_values_percent_train.reset_index(drop=False)\nunique_values_percent_train.columns = ['Features', 'Count']\n","c6ea5abb":"plt.rcParams['figure.dpi'] = 400\nfig = plt.figure(figsize=(6, 4), facecolor='#f6f5f5')\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.4, hspace=0.5)\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#ffd514']*6)\n\nax0 = fig.add_subplot(gs[0, 0])\nfor s in [\"right\", \"top\"]:\n    ax0.spines[s].set_visible(False)\nax0.set_facecolor(background_color)\nax0_sns = sns.barplot(ax=ax0, y=unique_values_train['Features'], x=unique_values_train['Count'], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1)\nax0_sns.set_xlabel(\"Unique Values\",fontsize=4, weight='bold')\nax0_sns.set_ylabel(\"Features\",fontsize=4, weight='bold')\nax0_sns.tick_params(labelsize=4, width=0.5, length=1.5)\nax0_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax0_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax0.text(0, -1.5, 'Unique Values - Train Dataset', fontsize=6, ha='left', va='top', weight='bold')\nax0.text(0, -1, 'can be considered as classification features', fontsize=4, ha='left', va='top')\nax0.get_xaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n# data label\nfor p in ax0.patches:\n    value = f'{p.get_width():,.0f}'\n    x = p.get_x() + p.get_width() + 200\n    y = p.get_y() + p.get_height() \/ 2 \n    ax0.text(x, y, value, ha='left', va='center', fontsize=4, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\n    \nax1 = fig.add_subplot(gs[0, 1])\nfor s in [\"right\", \"top\"]:\n    ax1.spines[s].set_visible(False)\nax1.set_facecolor(background_color)\nax1_sns = sns.barplot(ax=ax1, y=unique_values_percent_train['Features'], x=unique_values_percent_train['Count'], \n                      zorder=2, linewidth=0, orient='h', saturation=1, alpha=1)\nax1_sns.set_xlabel(\"Percentage Unique Values\",fontsize=4, weight='bold')\nax1_sns.set_ylabel(\"Features\",fontsize=4, weight='bold')\nax1_sns.tick_params(labelsize=4, width=0.5, length=1.5)\nax1_sns.grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\nax1_sns.grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\nax1.text(0, -1.5, 'Percentage Unique Values - Train Dataset', fontsize=6, ha='left', va='top', weight='bold')\nax1.text(0, -1, 'can be considered as classification features', fontsize=4, ha='left', va='top')\n# data label\nfor p in ax1.patches:\n    value = f'{p.get_width():.2f}'\n    x = p.get_x() + p.get_width() + 0.03\n    y = p.get_y() + p.get_height() \/ 2 \n    ax1.text(x, y, value, ha='left', va='center', fontsize=4, \n            bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', linewidth=0.3))\n\nbackground_color = \"#f6f5f5\"\nsns.set_palette(['#ff355d']*6)\n    \n\n","fb29a3b7":"sns.color_palette(\"pastel\")\nplt.title('Checking Outliers with distplot()')\nsns.distplot(df.trtbps, label='trtbps', kde=True, bins=10, color='green')\nplt.legend()","cfe10bd6":"plt.title('Checking Outliers with distplot()')\nsns.distplot(df.chol, label='chol', kde=True, color='red')\nplt.legend()","d2742727":"plt.title('Checking Outliers with distplot()')\nsns.distplot(df['thalachh'],label='thalachh', kde=True )\nplt.legend()","09f31a8f":"sns.pairplot(df,kind=\"kde\",hue=\"output\")","ac4fd74f":"#spliting data into X and y\n\nX=df.drop([\"output\"],axis=1)\ny=df[\"output\"]","c8b2a6a2":"\nfrom sklearn.preprocessing import MinMaxScaler\nscalerX = MinMaxScaler(feature_range=(0, 1))\nX[X.columns] = scalerX.fit_transform(X[X.columns])\n\n","35f2e476":"#for model building\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost as xgb","6fa7bebd":"# Spliting the data\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 30)\n","93716841":"from sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier()\nada.fit(X_train,y_train)\nada_pre=ada.predict(X_test)\nacc_ada = accuracy_score(y_test,ada_pre)\nacc_ada\n\n","bf83e824":"key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier','XGBClassifier']\nvalue = [LogisticRegression(random_state=9), KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(), xgb.XGBClassifier()]\nmodels = dict(zip(key,value))","b1384200":"predicted =[]","086ebe24":"for name,algo in models.items():\n    model=algo\n    model.fit(X_train,y_train)\n    predict = model.predict(X_test)\n    acc = accuracy_score(y_test, predict)\n    predicted.append(acc)\n    print(name,acc)","e97330f2":"#confusion matrix\ncnn=KNeighborsClassifier()\ncnn.fit(X_train,y_train)\ncnn_predict = cnn.predict(X_test)\ncf_matrix=confusion_matrix(y_test,cnn_predict)\nplt.figure(figsize=(7,6))\nsns.heatmap(cf_matrix,annot=True,fmt='d')","135ab40d":"plt.figure(figsize = (10,5))\nsns.barplot(x = predicted, y = key, palette='pastel')","fbfe8ef2":"**Observation:**\n\n* cp : Chest Pain type chest pain type\n\n    * Value 0: typical angina\n    * Value 1: atypical angina\n    * Value 2: non-anginal pain\n    * Value 3: asymptomatic\n    \n* People of chest pain category '0' have the highest count, whereas of count of chest pain '3' is the lowest","93a469f6":"**using minmax Scaler for scaling the data in same Scale**\n\n**we scal the aal data between 0 to 1**","0f2f2269":"# Conclusion: \n\n\n* Numeric Variables - No outliers were found!\n\n* High Blood Pressure, High Cholestrol and High Heart Rate leads to high chance of heart attack.\n\n* In the count of target showed up that we have more chance of heart attack details.\n\n* Age from 40-60 years have the high chance of heart attack.\n\n* Male gender has more chance of heart attack compared to female ones.\n\n* Highly Correlated factors in this dataset are :\n    * Age and trtbps (blood pressure rate)\n    * Age and chol (cholestrol level)","5ac6ee34":"**By the pair plot we can see data destribution and identfy outlier**","d870a8b1":"**Observation:**\n\n* you can see that there are no missing rows in the entire dataset. so we do not need to fil\/drop any value\n* All the columns except oldpeak (float) are of int data type.","42f454e3":"# model building","816df4bb":"# If you like please do a Up vote\n**Thanks**","d7a47238":"There is 1 duplicate row. Let's drop it!","1b0d55ad":"# Welcome\n# Hear Attack Analysis and Prediction Dataset\n\nThis dataset contains information about people and there chances of having a heart stroke.\n\n\n **Dataset Information:**\n\n\n\n\n\n* Age : Age of the patient\n* Sex : Sex of the patient\n* exang: exercise induced angina (1 = yes; 0 = no)\n* ca: number of major vessels (0-3)\n* cp : Chest Pain type chest pain type\n    * Value 1: typical angina\n    * Value 2: atypical angina\n    * Value 3: non-anginal pain\n    * Value 4: asymptomatic\n* trtbps : resting blood pressure (in mm Hg)\n* chol : cholestoral in mg\/dl fetched via BMI sensor\n* fbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n* rest_ecg : resting electrocardiographic results\n    * Value 0: normal\n    * Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n* thalach : maximum heart rate achieved\n* target : \n    * 0 = less chance of heart attack \n    * 1 = more chance of heart attack\n    \n    \n\n**Objective:**\n\n\n\n\n* With the dataset provided for heart analysis, we have to analyse the possibilities of heart attack on the basis of various features, and then the prediction from the analysis will tell us that whether an individual is prone to heart attack or not. \n* The detailed analysis can proceed with the exploratory data analysis (EDA). \n* The classification for predication can be done using various machine learning model algorithms, choose the best suited model for heart attack analysis and finally save the model in the pickle (.pkl) file.\n\n\n**Questions to be answered:**\n\n\n\n\n\n* Does the age of a person contribute towards heart attack?\n* Are different types of chest pain related to each other or the possibility of getting a heart attack?\n* Does high blood pressure increase the risk of heart attack?\n* Does the choestrol level eventually contribute as a risk factor towards heart attack?\n\n","d49153ea":"### Observations:\n\nIt seems num feature can be treated as classification features as the unique numbers is small compared with the total observation which can be seen on the percentage to the total observations.\n","6c35f61c":"**Observation:** \n\n* The number of people belonging to sex category 0 are 96 whereas 1 are 206.\n* The number of people in one category are more than double than the zero.","3a012375":"**Observation:**\n\n* This swarmplot gives us a lot of information.\n* Accoring to the figure, people belonging to caa category '0' , irrespective of their age are highly prone to getting a heart attack.\n* While there are very few people belonging to caa category '4' , but it seems that around 75% of those get heart attacks.\n* People belonging to category '1' , '2' and '3' are more or less at similar risk.","9f828237":"**Observation:** There are no missing values.","3d6e57a0":"# EDA","4d69f01a":"**Observations:**\n\n* trtbps and chol looks like they are normally distributed, with some outliers highly skewed towards right.\n* In case of thalachh the data is highly skewed towards right!","abe47e74":"**Observation:**  \nFrom the above figure we can see that **KNeighborsClassifier** model give an accuracy greater than 90%.","de020132":"**Observation:**\n \n * You can see know all the columns are already in int or float data types.\n * here output is outcome feature to predict","e984e134":"**Observation:** Thall count is maximum for type 2 ( 165 ) and min for type 0 ( 2 ) .\n","f334f69a":"**Observation:** People of fbs category 1 are less than 25% of people of fbs category 0.","a9f159a1":"### Distribution\nShowing distribution on each feature that are available in train dataset. ","47222aac":"### Unique values\n*Counting number of unique value and it's relative with their respective observations between train & test dataset.*","7b0b1d57":"Now we are going to get all feature for forther uses","0cd1cb95":"**Observation:**\n\n* The average blood pressure of an individual is 130 whereas the maximun value goes upto 200.\n* The average heart rate of the group is 152, whereas overall it ranges between 133 to 202\n* Age of the group varies from 29 to 77 and the mean age is 55.5","29048b14":"**Observation:** \n\n* ECG count is almost the same for type 0 and 1. \n* Also, its almost negligible for type 2 in comparision to type 0 and 1.","5cfa34f6":"**Observation:**\n\n* There are two sex : 0 and 1\n* The highest cholestrol level is 564 and the lowest is 126.\n* Resting Blood Pressure of individuals vary between 94 to 200.\n* There are 4 types of chest pain.\n* exercise induced angina has 2 types (1 = yes; 0 = no)"}}