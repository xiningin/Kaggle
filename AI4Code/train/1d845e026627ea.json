{"cell_type":{"08bfab28":"code","022913d5":"code","50e39d18":"code","f3e70fdb":"code","69cd5fba":"code","46a3e928":"code","7993e6cf":"code","62969c63":"markdown","d7bc2afb":"markdown","7fe26da6":"markdown","cd754053":"markdown","1d330d61":"markdown","b0ecbb4b":"markdown"},"source":{"08bfab28":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch import FloatTensor\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport torchvision.utils as vutils\nfrom torch.utils import data\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom PIL import Image\nimport os\nimport sys\nimport time\nimport numpy as np\nimport random\nimport imageio\nfrom pathlib import Path","022913d5":"dataroot = \"..\/input\/pokemon-mugshots-from-super-mystery-dungeon\/smd\/\"\ncheckpoint_file = \"..\/output\/checkpoint.pt\"\nimage_path = '..\/working\/'\ndataset_name = 'Pokemons'\nnc = 3                    # number of channel\nimg_size = (64,64,nc)\nbatch_size = 64 \nlr = 2e-4\nbetas = (.5, .99)\nepochs = 250\nngpu = 1\nweights_backup = False  #Save weights during training\nweights_restore = False #Set to False if want to restart training from zero\n\nnz = 128 #size of latent z vector\nngf = 64 #number of generator filters\nndf = 64 #number of discriminator filters\n\nreal_label = 1\nfake_label = 0","50e39d18":"dataset = datasets.ImageFolder(root=dataroot,\n                           transform=transforms.Compose([\n                               transforms.Resize(img_size[0]),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\n# Create the dataloader\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                         shuffle=True, num_workers=2)\n\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n\n# Plot some images\nreal_batch = next(iter(dataloader))\nplt.figure(figsize=(10,10))\nplt.axis(\"off\")\nplt.title(\"Images of {}\".format(dataset_name))\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n\nprint('Dataset {} contains {} images'.format(dataset_name, len(dataset)))","f3e70fdb":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\n\"\"\" GENERATOR\"\"\"\nclass Generator(nn.Module):\n    def __init__(self, nz, ngf, nc):\n        super(Generator, self).__init__()\n        self.nz = nz \n        self.layer1 = nn.Sequential(\n            # Input size : input latent vector 'z' with dimension (nz)*1*1\n            # Output size: output feature vector with (ngf*8)*4*4\n            nn.ConvTranspose2d(in_channels = nz, out_channels = ngf*8, kernel_size = 4, stride = 1, padding = 0, bias = False),\n            nn.BatchNorm2d(ngf*8),\n            nn.ReLU(True)\n        )\n\n        self.layer2 = nn.Sequential(\n            # Input size : input feature vector with (ngf*8)*4*4\n            # Output size: output feature vector with (ngf*4)*8*8\n            nn.ConvTranspose2d(in_channels = ngf*8, out_channels = ngf*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ngf*4),\n            nn.ReLU(True)\n        )\n\n        self.layer3 = nn.Sequential(\n            # Input size : input feature vector with (ngf*4)*8*8\n            # Output size: output feature vector with (ngf*2)*16*16\n            nn.ConvTranspose2d(in_channels = ngf*4, out_channels = ngf*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ngf*2),\n            nn.ReLU(True)\n        )\n\n        self.layer4 = nn.Sequential(\n            # Input size : input feature vector with (ngf*2)*16*16\n            # Output size: output feature vector with (ngf)*32*32\n            nn.ConvTranspose2d(in_channels = ngf*2, out_channels = ngf, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True)\n        )\n\n        self.layer5 = nn.Sequential(\n            # Input size : input feature vector with (ngf)*32*32\n            # Output size: output image with (nChannels)*(image width)*(image height)\n            nn.ConvTranspose2d(in_channels = ngf, out_channels = nc, kernel_size =4, stride = 2, padding = 1, bias = False),\n            nn.Tanh() # To restrict each pixels of the fake image to 0~1\n        )\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        return out\n\n    def sample_latent(self, num_samples):\n        return Variable(torch.randn(num_samples, self.nz, 1, 1, device=device))\n\n\"\"\" DISCRIMINATOR\"\"\"\n\nclass Discriminator(nn.Module):\n    def __init__(self, ndf, nc):\n        super(Discriminator, self).__init__()\n        # input : (batch * nChannels * image width * image height)\n        self.layer1 = nn.Sequential(\n            # Input size : input image with dimension (nChannels)*64*64\n            # Output size: output feature vector with (ndf)*32*32\n            nn.Conv2d(in_channels = nc, out_channels = ndf, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ndf),\n            nn.LeakyReLU(0.2, inplace=True))\n\n        self.layer2 = nn.Sequential(\n            # Input size : input feature vector with (ndf)*32*32\n            # Output size: output feature vector with (ndf*2)*16*16\n            nn.Conv2d(in_channels = ndf, out_channels = ndf*2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ndf*2),\n            nn.LeakyReLU(0.2, inplace=True))\n\n        self.layer3 = nn.Sequential(\n            # Input size : input feature vector with (ndf*2)*16*16\n            # Output size: output feature vector with (ndf*4)*8*8\n            nn.Conv2d(in_channels = ndf*2, out_channels = ndf*4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ndf*4),\n            nn.LeakyReLU(0.2, inplace=True))\n\n        self.layer4 = nn.Sequential(\n            # Input size : input feature vector with (ndf*4)*8*8\n            # Output size: output feature vector with (ndf*8)*4*4\n            nn.Conv2d(in_channels = ndf*4, out_channels = ndf*8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n            nn.BatchNorm2d(ndf*8),\n            nn.LeakyReLU(0.2, inplace=True))\n\n        self.layer5 = nn.Sequential(\n            # Input size : input feature vector with (ndf*8)*4*4\n            # Output size: output probability of fake\/real image\n            nn.Conv2d(in_channels = ndf*8, out_channels = 1, kernel_size = 4, stride = 1, padding = 0, bias = False),\n            # nn.Sigmoid() -- Replaced with Least Square Loss\n            )\n\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n\n        return out.view(-1,1)","69cd5fba":"class GAN():\n    def __init__(self, generator, discriminator, gen_optimizer, dis_optimizer, g_scheduler, d_scheduler,\n                 critic_iterations=2):\n      \n        self.G = generator\n        self.G_opt = gen_optimizer\n        self.D = discriminator\n        self.D_opt = dis_optimizer\n        self.losses = {'G': [], 'D': []}\n        self.start_epoch = 0\n        self.critic_iterations = critic_iterations\n        self.training_progress_images = []\n        self.D_scheduler = d_scheduler\n        self.G_scheduler = g_scheduler\n        self.fixed_z =  self.G.sample_latent(batch_size)\n\n    def _critic_train_iteration(self, data):\n\n        #Loss on real data\n        self.D.zero_grad()\n        data = data.to(device)\n        batch_size = data.size(0)      \n        label = torch.full((batch_size,), real_label, device=device) \n        out_real = self.D(data)\n        d_real = 0.5 * torch.mean((out_real-label)**2) # criterion(output, label)\n        d_real.backward()\n        # Loss on generated data\n        generated_data = self.sample_generator(batch_size)\n        label.fill_(fake_label)\n        out_generated = self.D(generated_data)\n        d_fake = 0.5 * torch.mean((out_generated-label)**2) # criterion(output, label)        \n        d_fake.backward()\n        # Create total loss and optimize\n        d_loss = d_fake + d_real\n        self.D_opt.step()\n        # Record loss\n        self.losses['D'].append(d_loss.data.item())\n    \n    def _generator_train_iteration(self, data):\n        \n        self.G.zero_grad()\n        # Get generated data\n        batch_size = data.to(device).size(0)\n        generated_data = self.sample_generator(batch_size)\n        label = torch.full((batch_size,), real_label, device=device)\n        # Calculate loss and optimize\n        out_generated = self.D(generated_data)\n        g_loss = 0.5 * torch.mean((out_generated - label)**2) # criterion(output, label)\n        g_loss.backward()\n        self.G_opt.step()\n        # Record loss\n        self.losses['G'].append(g_loss.data.item())\n\n    def train_epoch(self,dataloader, epoch):\n\n        for i, (data, _) in enumerate(dataloader):\n            #Train first Discriminator for n iteration\n            for _ in range(self.critic_iterations):\n                self._critic_train_iteration(data)\n            #Train generator\n            self._generator_train_iteration(data)\n\n        #self.D_scheduler.step()\n        #self.G_scheduler.step()\n\n        print(\"Epoch[%d\/%d]\\tD_loss: %.2f,\\tG_loss: %.2f\" % (epoch, epochs, self.losses['D'][-1], self.losses['G'][-1]) )\n        \n    def train(self, dataloader, epochs, checkpoint_file):\n      \n        if weights_restore:\n            self.restore_checkpoint(checkpoint_file)\n         \n        print('###########   TRAINING STARTED  ############')\n        start = time.time()\n\n        for epoch in range(epochs-self.start_epoch):\n            epoch+=self.start_epoch\n\n            self.train_epoch(dataloader, epoch)    \n            \n            if weights_backup and epoch % 2 == 0:\n                self.store_checkpoint(epoch, checkpoint_file)\n\n            #Save a checkpoint also at half of the training\n            if weights_backup and epoch == (int(epochs\/2)):\n                self.store_checkpoint(epoch, checkpoint_file)\n            \n            if epoch % 20 == 0:\n                self.evaluate(epoch)\n                \n        end = time.time()\n        print('Total training time: {} min, {} sec '.format(int((end - start) \/ 60), int((end - start) % 60)))\n      \n        #Save and Plot final results\n        imageio.mimsave(image_path+'_GIF_{}epochs.gif'.format(epochs),self.training_progress_images) #Save GIF\n        self.plot_save_generated(epoch, save=True)\n        self.plot_save_losses()\n    \n    def sample_generator(self, num_samples):\n        z_samples = self.G.sample_latent(num_samples)\n        generated_data = self.G(z_samples)\n        return generated_data\n\n    def evaluate(self, epoch):\n        img_grid = make_grid(self.G(self.fixed_z).cpu().data, normalize=True).numpy()   # Generate batch of images and convert to grid\n        img_grid = img_grid.transpose((1, 2, 0))     # Convert to numpy and transpose axes to fit imageio convention i.e. (width, height, channels)\n        self.training_progress_images.append(img_grid)                  # Add image grid to training progress        \n        plt.figure(figsize=(7,7))\n        plt.imshow(img_grid)\n        plt.axis('off')\n        plt.title('Generated images after epoch {}'.format((epoch+1)))\n        plt.show()\n\n    def plot_save_generated(self, epoch=epochs, save=False):\n        img = make_grid(self.sample_generator(64).cpu().data,normalize=True).numpy() \n        img = img.transpose((1, 2, 0)) \n        plt.figure(figsize=(10,10))\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title('Generated images after {} epochs'.format((epoch+1)))\n        if save:\n            plt.savefig(image_path + '_generated_%d.png' % (epoch+1))\n        plt.show()\n     \n    def generate_pokemons(self, n=64):\n        img = make_grid(self.sample_generator(n).cpu().data,normalize=True).numpy() \n        img = img.transpose((1, 2, 0)) \n        plt.figure(figsize=(15,15))\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title('Generated Pok\u00e8mons')\n        plt.show()\n    \n    def plot_save_losses(self):\n        plt.figure(figsize=(10,5))\n        plt.title(\"Generator and Discriminator Losses During Training\")\n        plt.plot(self.losses['G'],label=\"G\")\n        plt.plot(self.losses['D'],label=\"D\")\n        plt.xlabel(\"iterations\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.savefig(image_path + '_losses.png')\n        plt.show()\n\n    def store_checkpoint(self, epoch, checkpoint_file):\n        torch.save({'epoch': epoch,\n                  'generator': self.G.state_dict(),\n                  'discriminator': self.D.state_dict(),\n                  'optimizerG': self.G_opt.state_dict(),\n                  'optimizerD': self.D_opt.state_dict(),\n                  'loss': self.losses,\n                  'fixed_z': self.fixed_z,\n                  'images_gen': self.training_progress_images\n                  }, checkpoint_file)\n        print('Saved checkpoint at epoch: ', epoch)\n\n    def restore_checkpoint(self,checkpoint_file):\n        if Path(checkpoint_file).exists():\n            checkpoint = torch.load(checkpoint_file)\n            self.G.load_state_dict(checkpoint['generator'])\n            self.D.load_state_dict(checkpoint['discriminator'])\n            self.G_opt.load_state_dict(checkpoint['optimizerG'])\n            self.D_opt.load_state_dict(checkpoint['optimizerD'])\n            self.losses = checkpoint['loss']\n            self.fixed_z = checkpoint['fixed_z']\n            self.training_progress_images = checkpoint['images_gen']\n            self.start_epoch = checkpoint['epoch']\n            print('Checkpoint found and restored at epoch {}'.format(self.start_epoch))\n        else: \n            print('Checkpoint not used or not exist\\n')","46a3e928":"######################### Define Models\ndiscriminator = Discriminator(ndf, nc).apply(weights_init).to(device)\ngenerator = Generator(nz, ngf, nc).apply(weights_init).to(device)\n\n######################### Loss & Optimizer\noptimizerD = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)\noptimizerG = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\nschedulerD = optim.lr_scheduler.ExponentialLR(optimizerD, gamma=0.99)\nschedulerG = optim.lr_scheduler.ExponentialLR(optimizerG, gamma=0.99)\n\n######################### Train GAN\nmodel = GAN(generator, discriminator, optimizerG, optimizerD, schedulerG, schedulerD)\nmodel.train(dataloader, epochs, checkpoint_file)","7993e6cf":"model.generate_pokemons(64)","62969c63":"# DATALOADER","d7bc2afb":"# GAN","7fe26da6":"# MAIN","cd754053":"# MODELS","1d330d61":"# Least Squared GAN for Pok\u00e8mon generation","b0ecbb4b":"# PARAMS"}}