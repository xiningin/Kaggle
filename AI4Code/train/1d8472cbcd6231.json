{"cell_type":{"c88eab21":"code","6acfbdd5":"code","50b47fab":"code","8a30e78e":"code","f2cf92a1":"markdown","4f0c6265":"markdown","0e5d79ac":"markdown"},"source":{"c88eab21":"df= pd.read_csv('..\/input\/wikipedia-image-caption\/image_data_test\/image_pixels\/test_image_pixels_part-00000.csv', sep='\\t', names=['image_url', 'b64_bytes', 'metadata_url'])\ndf","6acfbdd5":"df.iloc[0][1]","50b47fab":"import base64 \nbase64.b64decode(df.iloc[0][1])","8a30e78e":"captions = pd.read_csv('..\/input\/wikipedia-image-caption\/test_caption_list.csv')\nprint(len(captions))\ncaptions.head()","f2cf92a1":"## What is Byte Data \n\nThe images are stored in this competition based on base64 encoded bytes of the image file at a 300px resolution. We will be using this data to ","4f0c6265":"# Beginniner Wikipedia Captioning Competition (English Only) \n\nIn this notebook, we will run our starter understanding notebook for the Wikipedia Captioning competition. We have decided to work on a smaller dataset containing english captions only, just for our first phase of modeling. In this notebook, we go over the data types, EDA of our data, model decisions, modeling, and evaluation. ","0e5d79ac":"## Competition Data \n\nThe data for this competition contains both caption and image data. The images are stored in this competition based on base64 encoded bytes of the image file at a 300px resolution. "}}