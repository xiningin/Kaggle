{"cell_type":{"ab2f7c79":"code","952470ea":"code","003eb859":"code","553ea12f":"code","c63fd756":"code","66bfd5a2":"code","83c044a3":"code","9b171cfe":"code","538f56f5":"code","be2e7819":"code","7575d7ff":"code","a285edc6":"code","49225a04":"code","1d2a3d77":"code","ce6cc4a3":"code","90c35be7":"code","9357a581":"code","8d89e84b":"code","b4538590":"code","a256ac48":"code","4ee86d14":"code","b69f2fe1":"code","2ba1b6da":"code","89fb7b37":"code","9e9ff545":"code","4438a8d3":"code","dfea0603":"code","811cccf0":"code","1cc3f2d0":"code","1c948df0":"markdown","82d95c0f":"markdown","be26a7c2":"markdown"},"source":{"ab2f7c79":"# Libraries\nimport numpy as np\nimport pandas as pd\nimport os, time, re\nimport pickle, gzip\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nimport matplotlib as mpl\n\n%matplotlib inline\n\n\nfrom sklearn import preprocessing as pp\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\n\nimport lightgbm as lgb\n\n\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Dense, Dropout\nfrom keras.layers import BatchNormalization, Input, Lambda\nfrom keras import regularizers\nfrom keras.losses import mse, binary_crossentropy","952470ea":"df = pd.read_pickle('..\/input\/searching-for-bad-loan-data-preprocessing\/df_pp.pkl')","003eb859":"df['Loan_status'].value_counts()","553ea12f":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndf['Loan_status'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Loan_status')\nax[0].set_ylabel('')\nsns.countplot('Loan_status',data=df,ax=ax[1])\nax[1].set_title('Loan_status')\nplt.show()","c63fd756":"X = df.drop('Loan_status', axis=1)\ny = df['Loan_status']\n\nfrom sklearn import preprocessing as pp\nfeaturesToScale = X.columns\nsX = pp.StandardScaler(copy=True)\nX.loc[:,featuresToScale] = sX.fit_transform(X[featuresToScale])\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)","66bfd5a2":"# toDrop = y_train[y_train==1].sample(frac=0.90,random_state=2018)\n# X_train.drop(labels=toDrop.index,inplace=True)\n# y_train.drop(labels=toDrop.index,inplace=True)","83c044a3":"def anomalyScores(originalDF, reducedDF):\n    loss = np.sum((np.array(originalDF) - \\\n                   np.array(reducedDF))**2, axis=1)\n    loss = pd.Series(data=loss,index=originalDF.index)\n    loss = (loss-np.min(loss))\/(np.max(loss)-np.min(loss))\n    return loss","9b171cfe":"def plotResults(trueLabels, anomalyScores, returnPreds = False):\n    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n    preds.columns = ['trueLabel', 'anomalyScore']\n    precision, recall, thresholds = \\\n        precision_recall_curve(preds['trueLabel'], \\\n                               preds['anomalyScore'])\n    average_precision = average_precision_score( \\\n                        preds['trueLabel'], preds['anomalyScore'])\n    \n    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.ylim([0.0, 1.05])\n    plt.xlim([0.0, 1.0])\n    \n    plt.title('Precision-Recall curve: Average Precision = \\\n        {0:0.2f}'.format(average_precision))\n\n    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \\\n                                     preds['anomalyScore'])\n    areaUnderROC = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic: Area under the \\\n        curve = {0:0.2f}'.format(areaUnderROC))\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    if returnPreds==True:\n        return preds, average_precision","538f56f5":"def precisionAnalysis(df, column, threshold):\n    df.sort_values(by=column, ascending=False, inplace=True)\n    threshold_value = threshold*df.trueLabel.sum()\n    i = 0\n    j = 0\n    while i < threshold_value+1:\n        if df.iloc[j][\"trueLabel\"]==1:\n            i += 1\n        j += 1\n    return df, i\/j","be2e7819":"k_fold = StratifiedKFold(n_splits=5,shuffle=True,random_state=2020)","7575d7ff":"params_lightGB = {\n    'task': 'train',\n    'application':'binary',\n    'num_class':1,\n    'boosting': 'gbdt',\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'metric_freq':50,\n    'is_training_metric':False,\n    'max_depth':4,\n    'num_leaves': 31,\n    'learning_rate': 0.01,\n    'feature_fraction': 1.0,\n    'bagging_fraction': 1.0,\n    'bagging_freq': 0,\n    'bagging_seed': 2020,\n    'verbose': 0,\n    'num_threads':16\n}","a285edc6":"trainingScores = []\ncvScores = []\npredictionsBasedOnKFolds = pd.DataFrame(data=[], index=y_train.index, \\\n                                        columns=['prediction'])\n\nfor train_index, cv_index in k_fold.split(np.zeros(len(X_train)), \\\n                                          y_train.ravel()):\n    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n        X_train.iloc[cv_index,:]\n    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n        y_train.iloc[cv_index]\n    \n    lgb_train = lgb.Dataset(X_train_fold, y_train_fold)\n    lgb_eval = lgb.Dataset(X_cv_fold, y_cv_fold, reference=lgb_train)\n    gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=2000,\n                   valid_sets=lgb_eval, early_stopping_rounds=200,verbose_eval = 200)\n    \n    loglossTraining = log_loss(y_train_fold, gbm.predict(X_train_fold, \\\n                                num_iteration=gbm.best_iteration))\n    trainingScores.append(loglossTraining)\n    \n    predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'] = \\\n        gbm.predict(X_cv_fold, num_iteration=gbm.best_iteration) \n    loglossCV = log_loss(y_cv_fold, \\\n        predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'])\n    cvScores.append(loglossCV)\n    \n    print('Training Log Loss: ', loglossTraining)\n    print('CV Log Loss: ', loglossCV)\n    \nloglossLightGBMGradientBoosting = log_loss(y_train, \\\n        predictionsBasedOnKFolds.loc[:,'prediction'])\nprint('LightGBM Gradient Boosting Log Loss: ', \\\n        loglossLightGBMGradientBoosting)","49225a04":"preds, average_precision = plotResults(y_train, \\\n                        predictionsBasedOnKFolds.loc[:,'prediction'], True)","1d2a3d77":"predictions = pd.Series(data=gbm.predict(X_test, \\\n                num_iteration=gbm.best_iteration), index=X_test.index)\npreds, average_precision = plotResults(y_test, predictions, True)","ce6cc4a3":"preds, precision = precisionAnalysis(preds, \"anomalyScore\", 0.75)\nprint(\"Precision at 75% recall\", precision)","90c35be7":"# oversample_multiplier = 10\n\n# X_train_original = X_train.copy()\n# y_train_original = y_train.copy()\n# X_test_original = X_test.copy()\n# y_test_original = y_test.copy()\n\n# X_train_oversampled = X_train.copy()\n# y_train_oversampled = y_train.copy()\n# X_train_oversampled = X_train_oversampled.append( \\\n#         [X_train_oversampled[y_train==1]]*oversample_multiplier, \\\n#         ignore_index=False)\n# y_train_oversampled = y_train_oversampled.append( \\\n#         [y_train_oversampled[y_train==1]]*oversample_multiplier, \\\n#         ignore_index=False)\n\n# X_train = X_train_oversampled.copy()\n# y_train = y_train_oversampled.copy()","9357a581":"model = Sequential()\nmodel.add(Dense(units=40, activation='linear', \\\n                activity_regularizer=regularizers.l1(10e-5), \\\n                input_dim=31,name='hidden_layer'))\nmodel.add(Dropout(0.02))\nmodel.add(Dense(units=31, activation='linear'))","8d89e84b":"model.compile(optimizer='adam',\n              loss='mean_squared_error',\n              metrics=['accuracy'])","b4538590":"num_epochs = 5\nbatch_size = 32\n\nhistory = model.fit(x=X_train, y=X_train,\n                    epochs=num_epochs,\n                    batch_size=batch_size,\n                    shuffle=True,\n                    validation_split=0.20,\n                    verbose=1)","a256ac48":"predictionsTrain = model.predict(X_train, verbose=1)\nanomalyScoresAETrain = anomalyScores(X_train, predictionsTrain)\npreds, average_precision = plotResults(y_train, \\\n                                      anomalyScoresAETrain, True)","4ee86d14":"predictions = model.predict(X_test, verbose=1)\nanomalyScoresAE = anomalyScores(X_test, predictions)\npreds, average_precision = plotResults(y_test, anomalyScoresAE, True)","b69f2fe1":"preds, precision = precisionAnalysis(preds, \"anomalyScore\", 0.75)\nprint(\"Precision at 75% recall\", precision)","2ba1b6da":"layer_name = 'hidden_layer'\n\nintermediate_layer_model = Model(inputs=model.input, \\\n                                 outputs=model.get_layer(layer_name).output)\nintermediate_output_train = intermediate_layer_model.predict(X_train)\nintermediate_output_test = intermediate_layer_model.predict(X_test)","89fb7b37":"intermediate_output_trainDF = \\\n    pd.DataFrame(data=intermediate_output_train,index=X_train.index)\nintermediate_output_testDF = \\\n    pd.DataFrame(data=intermediate_output_test,index=X_test.index)","9e9ff545":"X_train = X_train.merge(intermediate_output_trainDF, \\\n                                 left_index=True,right_index=True)\nX_test = X_test.merge(intermediate_output_testDF, \\\n                               left_index=True,right_index=True)\ny_train = y_train.copy()","4438a8d3":"trainingScores = []\ncvScores = []\npredictionsBasedOnKFolds = pd.DataFrame(data=[],index=y_train.index, \\\n                                        columns=['prediction'])\n\nfor train_index, cv_index in k_fold.split(np.zeros(len(X_train)), \\\n                                          y_train.ravel()):\n    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \\\n        X_train.iloc[cv_index,:]\n    y_train_fold, y_cv_fold = y_train.iloc[train_index], \\\n        y_train.iloc[cv_index]\n    \n    lgb_train = lgb.Dataset(X_train_fold, y_train_fold)\n    lgb_eval = lgb.Dataset(X_cv_fold, y_cv_fold, reference=lgb_train)\n    gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=5000,\n                   valid_sets=lgb_eval, early_stopping_rounds=200 ,verbose_eval = 200)\n    \n    loglossTraining = log_loss(y_train_fold, \n                                gbm.predict(X_train_fold, \\\n                                num_iteration=gbm.best_iteration))\n    trainingScores.append(loglossTraining)\n    \n    predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'] = \\\n        gbm.predict(X_cv_fold, num_iteration=gbm.best_iteration) \n    loglossCV = log_loss(y_cv_fold, \\\n            predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'])\n    cvScores.append(loglossCV)\n    \n    print('Training Log Loss: ', loglossTraining)\n    print('CV Log Loss: ', loglossCV)\n    \nloglossLightGBMGradientBoosting = log_loss(y_train, \\\n                        predictionsBasedOnKFolds.loc[:,'prediction'])\nprint('LightGBM Gradient Boosting Log Loss: ', \\\n                        loglossLightGBMGradientBoosting)","dfea0603":"preds, average_precision = plotResults(y_train, \\\n                        predictionsBasedOnKFolds.loc[:,'prediction'], True)","811cccf0":"predictions = pd.Series(data=gbm.predict(X_test, \\\n                    num_iteration=gbm.best_iteration),index=X_test.index)\npreds, average_precision = plotResults(y_test, predictions, True)","1cc3f2d0":"preds, precision = precisionAnalysis(preds, \"anomalyScore\", 0.75)\nprint(precision)","1c948df0":"### Semi-Supervised Learning","82d95c0f":"### Unsupervised Learning","be26a7c2":"#### apply methods learned from \"Hands on Unsupervised Learning \" Author - Ankur A. Patel"}}