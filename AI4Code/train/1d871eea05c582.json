{"cell_type":{"81d51ae3":"code","0b21487e":"code","b53ddb7f":"code","92443a66":"code","f28efa93":"code","6ea97605":"code","c4ae01ba":"code","fa3888b3":"code","f9e82508":"code","ba9b7d92":"code","45948933":"code","211769a4":"code","baf51dc9":"code","d9bdc04b":"code","91f81364":"code","eac388fc":"markdown","d83f8625":"markdown","9eb89666":"markdown","07030bca":"markdown"},"source":{"81d51ae3":"%cd \/content\/drive\/MyDrive\/2021_2_AI\/Term_Project","0b21487e":"# \uac01 \uc2dc\ub4dc \uace0\uc815\nimport torch\nimport random\n\n# GPU \uc0ac\uc6a9 \uac00\ub2a5\ud560 \uacbd\uc6b0, 'cuda' \uadf8\ub807\uc9c0 \uc54a\uc744 \uacbd\uc6b0, 'cpu'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# \uc2dc\ub4dc \uace0\uc815\nrandom.seed(1)\ntorch.manual_seed(1)\nif device == 'cuda':\n    torch.cuda.manual_seed_all(1)","b53ddb7f":"# \ub370\uc774\ud130 \ud504\ub808\uc784 \ud615\ud0dc\ub85c \ub370\uc774\ud130 \uc77d\uae30\nimport pandas as pd\n\n# \ud55c\uae00\uc774 \ud3ec\ud568\ub418\uc5b4 \uc788\uae30 \ub584\ubb38\uc5d0 'CP949'\ub85c encoding\ntrain_df = pd.DataFrame(pd.read_csv('train.csv', encoding='CP949'))\ntest_df = pd.DataFrame(pd.read_csv('x_test.csv', encoding='CP949'))\ny_test_df = pd.DataFrame(pd.read_csv('y_test.csv', encoding='CP949'))\n\n# \ud655\uc778\nprint(train_df.shape)\nprint(test_df.shape)\nprint(y_test_df.shape)","92443a66":"# \uc815\ub2f5\uac12 \uac00\uacf5 (5,4,3,2,1 -> 1)\ntrain_df.loc[train_df['\ucd5c\uc885\ud310\uc815\uacb0\uacfc']>=1,'\ucd5c\uc885\ud310\uc815\uacb0\uacfc'] = 1\ntrain_df['\ucd5c\uc885\ud310\uc815\uacb0\uacfc'].value_counts()","f28efa93":"# \uc9c1\uad00\uc801\uc73c\ub85c \uc801\ud569 \ud310\uc815\uc5d0 \ubd88\ud544\uc694\ud55c \uc5f4 \uc81c\uac70\nremove_list = ['Unnamed: 0','\uc815\uc218\uc7a5\uba85','\uad00\ub9ac\uae30\uad00\uba85','\uad00\ub9ac\uae30\uad00\uc804\ud654\ubc88\ud638','\ucc44\uc218\uc77c\uc790','\uac80\uc0ac\uae30\uad00\uba85','\ub370\uc774\ud130\uae30\uc900\uc77c\uc790',\n               '\uc81c\uacf5\uae30\uad00\ucf54\ub4dc','\uc81c\uacf5\uae30\uad00\uba85']\ntrain_df.drop(remove_list, axis=1, inplace=True)\ntest_df.drop(remove_list, axis=1, inplace=True)","6ea97605":"# \ubb38\uc790\uc5f4 noise, \uc5f4 \uc81c\uac70 in train data\nfor element in train_df['\uc77c\ubc18\uc138\uade0'].unique():\n    if element.isnumeric() != True:\n        train_df = train_df[train_df['\uc77c\ubc18\uc138\uade0'] != element]\n\ntrain_df = train_df[train_df['\uc54c\ub8e8\ubbf8\ub284'] != '\uc774\ucc9c\uc2ed\uad6c\ub144-\uacf5']\ntrain_df = train_df[train_df['\uc2dc\uc548'] != '\uacbd\uc0c1\ubd81\ub3c4 \uc601']","c4ae01ba":"## '\ud574\ub2f9\uc5c6\uc74c' \ubc0f \uacb0\uce21\uce58 \uc804\ucc98\ub9ac\nfor col in test_df.columns:\n    train_df[col] = train_df[col].replace('-',0)\n    train_df[col] = train_df[col].replace('?',0)\n\n    test_df[col] = test_df[col].replace('-',0)\n    test_df[col] = test_df[col].replace('?',0)","fa3888b3":"# \uc2e4\uc218\ud654 \ud6c4 \uacb0\uce21\uce58 \ucc44\uc6b0\uae30\ntrain_df = train_df.astype('float64')\ntest_df = test_df.astype('float64')\nfor col in test_df.columns:\n    train_df[col] = train_df[col].fillna(0.0)\n    test_df[col] = test_df[col].fillna(0.0)  ","f9e82508":"x_train_np = train_df.iloc[:,1:].to_numpy()\ny_train_np = train_df.iloc[:,0].to_numpy()\ntest_np = test_df.iloc[:,:].to_numpy()\n\nprint(x_train_np.shape)\nprint(y_train_np.shape)\nprint(test_np.shape)","ba9b7d92":"# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n# scaler = StandardScaler()\n# # scaler = MinMaxScaler()\n\n# x_train_np = scaler.fit_transform(x_train_np)\n# test_np = scaler.transform(test_np)","45948933":"# \ud150\uc11c \ud615\ud0dc\ub85c \ubcc0\ud658 \ubc0f GPU\uc5d0 \uc62c\ub9ac\uae30\nx_train = torch.FloatTensor(x_train_np).to(device)\ny_train = torch.FloatTensor(y_train_np).to(device)\ntest = torch.FloatTensor(test_np).to(device)\n\n# \ud655\uc778\nprint(x_train.shape)\nprint(y_train.shape)\nprint(test.shape)","211769a4":"# \uac01 \ub79c\ub364 \uc2dc\ub4dc \uace0\uc815\nrandom.seed(1)\ntorch.manual_seed(1)\nif device == 'cuda':\n    torch.cuda.manual_seed_all(1)\n\n# \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlr = 1e-3# learning rate\ntotal_epoch = 100 # epoch\n# n_classes = 6 # class \uac1c\uc218\n\n# model\nlinear1 = torch.nn.Linear(58, 128, bias=True) # \ubaa8\ub378\uc5d0 \ud65c\uc6a9\ud560 \uce35\nlinear2 = torch.nn.Linear(128, 256, bias=True)\nlinear3 = torch.nn.Linear(256, 512, bias=True)\nlinear4 = torch.nn.Linear(512, 256, bias=True)\nlinear5 = torch.nn.Linear(256, 1, bias=True)\n\ntorch.nn.init.xavier_normal_(linear1.weight) # \uac00\uc911\uce58 \ucd08\uae30\ud654\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)\ntorch.nn.init.xavier_normal_(linear4.weight)\ntorch.nn.init.xavier_normal_(linear5.weight)\n\nrelu = torch.nn.ReLU() # \ud65c\uc131\ud654 \ud568\uc218 \uc815\uc758\n# dropout = torch.nn.Dropout(p=0.3) # \uacfc\uc801\ud569 \ub9c9\uae30 \uc704\ud568\nsigmoid = torch.nn.Sigmoid() # \uc774\uc9c4 \ubd84\ub958 \ubb38\uc81c\uc5d0\uc11c\ub294 \ub9c8\uc9c0\ub9c9\uc5d0 sigmoid \ud568\uc218\ub97c \ub123\uc5b4\uc8fc\uc5b4\uc57c \ud568\n\nmodel = torch.nn.Sequential(linear1, relu,\n                            linear2, relu,\n                            linear3, relu,\n                            linear4, relu,\n                            linear5, sigmoid).to(device)\n\n# loss & optimizer\nloss = torch.nn.BCELoss().to(device) # \uc190\uc2e4 \ud568\uc218 \uc815\uc758\noptimizer = torch.optim.Adam(model.parameters(), lr=lr) # \uc635\ud2f0\ub9c8\uc774\uc800 \uc815\uc758\n# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9) # \uc635\ud2f0\ub9c8\uc774\uc800 \uc815\uc758\n","baf51dc9":"# train\nmodel.train() # \ubaa8\ub378 \ud559\uc2b5 \uc120\uc5b8\nfor epoch in range(total_epoch + 1):\n\n    hypothesis = model(x_train)\n    cost = loss(hypothesis, y_train.view(-1,1))\n\n    optimizer.zero_grad() # \ucd08\uae30\ud654\n    cost.backward()\n    optimizer.step() # \uac31\uc2e0\n\n    if epoch % 100 == 0: # \uc911\uac04 \ud655\uc778\n        print(epoch, cost.item())\n        ","d9bdc04b":"y_test = torch.FloatTensor(y_test_df.iloc[:,1].values)","91f81364":"# eval\nmodel.eval() # \ubaa8\ub378 \ud3c9\uac00 \uc120\uc5b8\nwith torch.no_grad(): # \uac00\uc911\uce58 \uac31\uc2e0\uc774 \ud544\uc694\uc5c6\ub294 \uc0c1\ud669\n      \n      hypothesis = model(test)\n      prediction = hypothesis.cpu() >= torch.FloatTensor([0.5])\n\n      # \uc815\ub2f5\uacfc \ube44\uad50\n      correct_pred = prediction == y_test.unsqueeze(1)\n      accuracy = correct_pred.sum().item() \/ len(correct_pred) # \ud3c9\uac00 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc815\ud655\ub3c4\n\n      print(accuracy * 100) # \uc815\ud655\ub3c4 \ucd9c\ub825","eac388fc":"### data","d83f8625":"##### -----","9eb89666":"### eval","07030bca":"### train"}}