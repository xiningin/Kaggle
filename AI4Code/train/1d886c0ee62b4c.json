{"cell_type":{"e62521fc":"code","518d5f66":"code","c896df3a":"code","9f3510ee":"code","3bdc916f":"code","c768a402":"code","8bacf343":"code","a1714c9d":"code","a995ba0d":"code","d20da5c9":"code","981c6dbf":"code","12faf8c4":"markdown","6ea9e8b4":"markdown","592f7e40":"markdown","8e07280b":"markdown","97b3078d":"markdown","6316804c":"markdown","06297bf8":"markdown"},"source":{"e62521fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","518d5f66":"df = pd.read_csv(\"..\/input\/column_2C_weka.csv\")","c896df3a":"# Do it first df.info() because we dont know is there any NaN value or length of data\ndf.info()","9f3510ee":"# to know about features an target variable\ndf.head()","3bdc916f":"x = df.loc[:,df.columns != 'class']\n#x  = df.drop(['class'],axis =1 )\n\ny = df.loc[:,df.columns == 'class']\n\n#x = pd.DataFrame(df.iloc[:,:-1].values)\n#y = pd.DataFrame(df.iloc[:,6].values)\n\nNormal = df.loc[df['class'] == 'Normal']\nAbnormal = df.loc[df['class'] == 'Abnormal']","c768a402":"# Scatter Plot\nplt.scatter(Normal.pelvic_radius,Normal.pelvic_incidence,color='r',label=\"Normal\",alpha=0.3)\nplt.scatter(Abnormal.pelvic_radius,Abnormal.pelvic_incidence,color='g',label=\"Abnormal\",alpha=0.3)\nplt.xlabel(\"pelvic_radius\")\nplt.ylabel(\"pelvic_incidence\")\nplt.legend()\nplt.show()","8bacf343":"#from sklearn.preprocessing import LabelEncoder\n#labelencoder_y=LabelEncoder()\n#y=pd.DataFrame(labelencoder_y.fit_transform(y).reshape(-1,1))\n\n# Categorical Data without sklearn liblary\n\ndf['class'] = [ 1 if each == \"Normal\" else 0 for each in df['class']]\ny = df['class'].values","a1714c9d":"x = ((x-np.min(x)) \/ ( np.max(x)-np.min(x)))","a995ba0d":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state=1)","d20da5c9":"from sklearn.neighbors import KNeighborsClassifier\nknn= KNeighborsClassifier()\nknn.fit(x,y)\nprediction = knn.predict(x_test)\n\nprint(\"{} nn score : {}\".format(3,knn.score(x_test,y_test)))","981c6dbf":"neig = np.arange(1, 25)\ntrain_accuracy = []\ntest_accuracy = []\n# Loop over different values of k\nfor i, k in enumerate(neig):\n    # k from 1 to 25(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # Fit with knn\n    knn.fit(x_train,y_train)\n    #train accuracy\n    train_accuracy.append(knn.score(x_train, y_train))\n    # test accuracy\n    test_accuracy.append(knn.score(x_test, y_test))\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(neig, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neig, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.title('Value VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(neig)\nplt.savefig('graph.png')\nplt.show()\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy)))) ","12faf8c4":"###  Normalization\n\n","6ea9e8b4":"### Categorical Data\n","592f7e40":"### Model complexity\n","8e07280b":"##  K-NEAREST NEIGHBORS (KNN)\n* x = features \n* y = target variables(normal,abnormal)\n","97b3078d":"# Introduction\n\nThis kernel we will use sklearn for KNN algorithm\n","6316804c":"### Train Test Split","06297bf8":"### KNN Model"}}