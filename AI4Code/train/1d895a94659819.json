{"cell_type":{"4f0fe4ce":"code","2dc6ff01":"code","fe4a6de3":"code","dd26eae7":"code","0f063ba5":"code","85c875ef":"code","a4ad5e39":"code","3dc5b614":"code","dd1bf9a2":"code","7576df20":"code","8cbb89ed":"code","64d245b7":"code","8688c40b":"code","aab53801":"code","ee261504":"code","a305bdc7":"code","7e6dd554":"code","77001c97":"code","e93d0c85":"code","245b2ad7":"code","08dc02d7":"code","db61e4e4":"code","01aa2130":"code","f5ddf4d8":"code","fdd82f6a":"code","ee667bc9":"code","d04b3b0b":"code","051f3558":"code","cd789d71":"code","7ca7ad4f":"code","6add5464":"code","77252019":"markdown","80bb796c":"markdown","f1516af2":"markdown","c9ab16fe":"markdown","0e77baff":"markdown","ff191ee2":"markdown","63a45eff":"markdown","3026cd5f":"markdown","0d6c734a":"markdown","4f4b4dd6":"markdown","0d9f303c":"markdown","ba9d726e":"markdown","773bd535":"markdown","4be8bb1b":"markdown","71a762ff":"markdown","404b5191":"markdown","2b11c157":"markdown","3f5978d5":"markdown","e7af4e8b":"markdown","84ba9a9f":"markdown","83ff3016":"markdown","623d31e9":"markdown","3835edc9":"markdown","b6febe95":"markdown"},"source":{"4f0fe4ce":"# Input data files are available in the read-only \"..\/input\/\" directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","2dc6ff01":"# Import necessary packages\n# Create any reusable methods to use later\n\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","fe4a6de3":"def screen_data(df):\n    print('-'*40)\n    print('list of Columns : ',df.columns.to_list())\n    print('-'*40)\n    print('Missing Values in the columns : \\n')\n    print(df.isnull().sum())\n    print('-'*40)\n    print('Unique Value Counts : \\n')\n    print(df.nunique())\n    print('-'*40)","dd26eae7":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\nscreen_data(df_train)\n","0f063ba5":"# Random sampling in the data\ndf_train.sample(3)","85c875ef":"df_test = pd.read_csv(  '..\/input\/titanic\/test.csv'  )\nscreen_data(df_test)","a4ad5e39":"fig, (ax1, ax2) = plt.subplots(1,2, figsize=(18,6))\ncolors = ['lightyellow' , 'red']\n\nf1 = sns.heatmap(df_train[['Age','Cabin','Embarked','Fare']].sort_values('Age').isnull(), cmap=sns.color_palette(colors), ax=ax1)\nf1.set_title('Missing Values - Train Data')\n\nf2 = sns.heatmap(df_test[['Age','Cabin','Embarked','Fare']].sort_values('Age').isnull(), cmap=sns.color_palette(colors), ax=ax2)\nf2.set_title('Missing Values - Test Data')\n\nplt.show()","3dc5b614":"df_train.head(3)","dd1bf9a2":"df_train[['PassengerId','Age']].groupby('Age').count().reset_index().rename(columns={'PassengerId' : 'Cnt'}).sort_values('Cnt', ascending=False).head(5)","7576df20":"df_train['Age_range'] = pd.cut(df_train['Age'], 10, precision=0)\n\nfig , ax = plt.subplots(1,1, figsize=(14,5))\n\nz = sns.barplot(data = df_train[['Survived','Age_range']] , x='Age_range' , y='Survived',  ax = ax, palette=sns.color_palette('pastel'))\nz.set_title('Age comparison for Survival')\nplt.show()\n\ndf_train.drop('Age_range', axis = 1, inplace  = True)\n","8cbb89ed":"\ns1 = sns.barplot(data = df_train, y='Survived' ,  hue='Sex' , x='Sex')\ns1.set_title('Male-Female Survival Comparison')\nplt.show()","64d245b7":"# Finding Titles in the names\n\nimport re\nfrom collections import Counter\n\n\ndef check_title(x) : \n    return re.search(' ([A-Za-z]+)\\.', x).group(1)\n\nCounter(df_train['Name'].map(check_title).to_list())","8688c40b":"df_train['Title'] = df_train['Name'].map(check_title)\n\nfig , ax = plt.subplots(1,1, figsize=(16,6))\nbar = sns.barplot(data = df_train[['Survived' , 'Title']] , y='Title' , x='Survived',  orient='h', ax=ax, palette=sns.color_palette('Blues'))\n# bar = sns.swarmplot(data = df_train[['Survived' , 'Title']] , x='Title' , y='Survived', ax=ax)\nbar.set_title ('Survival Comparison for Passengers with Titles')\nplt.show()\n\ndf_train.drop('Title', axis=1, inplace=True)","aab53801":"# df_train['Fare_range'] = pd.cut(df_train['Fare'], 10, precision=0)\n\nfig , ax = plt.subplots(1,1, figsize=(16,4))\nbar = sns.violinplot(data = df_train[['Survived' , 'Fare']] , y='Fare' , x='Survived', ax=ax)\nbar.set_title ('Survival based on Fare')\nplt.show()","ee261504":"sns.pairplot(df_train, hue='Survived')","a305bdc7":"grid = sns.FacetGrid(df_train, row='Survived', col='Embarked', height=2, aspect=2, palette=sns.color_palette('ocean'))\ngrid.map(plt.hist, 'Embarked', alpha=.5, bins=50)\ngrid.add_legend()\nplt.show()","7e6dd554":"def feature_process(df):\n    df['Embarked'].fillna(df['Embarked'].mode(), inplace=True)  # Fix missing values in Embarked if any\n    df['Fare'].fillna(df['Fare'].mean() , inplace=True)  # Fix missing values in Fare\n    df['Age'].fillna(df['Age'].median() , inplace=True)  # Put median value for Age\n    \n    if 'Cabin' in df.columns:\n        df.drop('Cabin', axis = 1, inplace = True)  # drop Cabin Column\n    \n    if 'Ticket' in df.columns:\n        df.drop('Ticket', axis = 1, inplace = True)  # drop Ticket Column , being a ticket number it has no relevance\n    \n    df['Age_cd'] = pd.cut(df_train['Age'], 10, precision=0).astype('category').cat.codes  # new Column to bucket the age ranges and putting code for it\n    \n\n#     df['Fare_range'] = pd.cut(df_train['Fare'], 10, precision=0)  # new Column\n    \n    df['Embarked_cd'] = df['Embarked'].astype('category').cat.codes # new Column\n    \n    df['Title_cd'] = df['Name'].map(check_title).astype('category').cat.codes # new Column\n    \n    df['Sex_cd'] = df['Sex'].astype('category').cat.codes  # Change sex to codes\n           \n    print(\"Preprocessing on the data complete ..\")","77001c97":"feature_process(df_train)","e93d0c85":"feature_process(df_test)","245b2ad7":"df_train.head(3)","08dc02d7":"df_train.columns","db61e4e4":"h = sns.heatmap(pd.get_dummies(df_train[['Survived', 'Pclass', 'Sex', 'Age_cd']], \n               columns=['Survived', 'Pclass', 'Sex', 'Age_cd']).corr(),\n           annot=True,cmap='RdYlGn_r',linewidths=0.2)\n\nfig=plt.gcf()\n\nh.set_title('Correlation on Various key Features in consideration')\n\nfig.set_size_inches([18,10])\n\nplt.show()\n","01aa2130":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","f5ddf4d8":"# identified features to be used\nfeatures = ['Pclass', 'SibSp', 'Parch', 'Fare',  'Age_cd', 'Sex_cd', 'Embarked_cd', 'Title_cd']\n\n\nX_train, X_test, y_train, y_test = train_test_split(df_train[features],  df_train['Survived'], test_size=0.3 , random_state=25)\n\n# Check basic setup of train and test\nfor x , y in enumerate([X_train, X_test, y_train, y_test]):\n    print(f'{x+1} :  {y.shape}')  \n\n","fdd82f6a":"# Logistic regression\nlr = LogisticRegression(max_iter=2000)\nlr.fit(X_train, y_train)","ee667bc9":"# SVM \nsvm = SVC(kernel='rbf', C=100 , random_state=1)\nsvm.fit(X_train, y_train)","d04b3b0b":"def evaluate_model(model_name) : \n    print(\"-\"*40,'\\n')\n    print(\"Evaluation for Model : \", model_name)\n    print('\\n',\"-\"*40,'\\n')\n    y_predict = model_name.predict(X_test)\n    acc = accuracy_score(y_test , y_predict)\n    print(f'Accuracy score of the model : {acc*100} %')\n    cmat = confusion_matrix(y_test , y_predict)\n    scores = cmat.diagonal() \/ cmat.sum(axis=1)\n    for x in zip(['Not Survived' , 'Survived' ], scores) :\n        print(f'Accuracy Scores for - {x[0]} : {x[1]*100} %')\n    print('\\n',\"-\"*40,'\\n')\n    sns.heatmap(cmat, cmap='Set3' , annot=True , fmt = '4.0f')\n    title = f'Confusion_matrix : {model_name}'\n    plt.title(f'{title}', y=1.1, size=20)\n    plt.show()\n\n    ","051f3558":"evaluate_model(lr)","cd789d71":"evaluate_model(svm)","7ca7ad4f":"prediction = svm.predict(df_test[features])\nfinal = pd.DataFrame ({'PassengerId' : df_test['PassengerId'], 'Survived': prediction})\nfinal.to_csv('.\/submission_svm.csv', index=False)\n\nfinal.head()\n","6add5464":"df_result = final.groupby('Survived').count().reset_index().rename(columns = {'PassengerId': 'Passenger Count'})\nres = sns.barplot(data=df_result, x = 'Survived' , y='Passenger Count', hue='Survived', palette='cool_r')\nres.set_title('Final Results from Prediction')\nplt.show()\n","77252019":"# Prediction of the Test Set","80bb796c":"# Objective Definition\n\n\n**1. Data Acquisition of the Titanic Data set  :** We will read, understand available data , validate high level data quality in the source.\n\n**2. Data Wrangling :** Clean data where applicable. Handle any missing values. Build Integrated views based on associations. Build Summaries if needed.\n\n**3. Exploratory Analysis :** Here we will perform detailed analysis to explore hiddent patterns , co-relations etc. Use Visualize where needed.\n\n**4. Feature Engineering :** This is where we will identify Features to develop the model, check and prepare if any Derived Features are needed.\n\n**5. Model Preparation :** Building the model using defined features. Based on nature of problem definition, we are having a Classification Problem at hand. At the same time, Regression pattern can also be applicable on the data. We will restrict our Model Algorithms to use (SVM) Classification and (Logistict Regression) Regression.\n\n**6. Model Evaluation :** We will build evaluation around both the model we will prepare and evaluate the accuracy score that can be obtained from both. Where applicable , we will use Visualization to compare the accuracy scores. Through evaluation , we will pick the better scoring prediction model.\n\n**7. Predict :** Final stage, we will run our final model to execute predictions.","f1516af2":"#### We will try to explore if the Title have any co-relation with survival","c9ab16fe":"### To understand the missing values and percentages better, we will run a heat map on the dataframes","0e77baff":"The red area in the above heat maps shows distribution of missing values in respective datasets.\n    \n   - It is seens tha we have large amount of missing data for `Cabin` column,\n   \n   - Missing data for `Age` is also considerable , but we can work around the same.\n   \n   - Column `Embarked` and `Fare` does not have any significant missing data.\n   ","ff191ee2":"## Introduction :\n<p style=\"color: indigo\">\nThe Kernel is trying to follow through a typical data science workflow to bulid a prediction model for survival of passenger onboard on Titanic. If you like the work here , please upvote. If you have suggestions to make this better , will love to read them in the comments. Thanks.\n    \n<\/p>\n\n","63a45eff":"#### Age data is working better when put into range bins.\n\n#### Ticket data is basically ticket identifiers, so they can simply be removed from analysis as Ticket Id may not have any significance to survival rate.","3026cd5f":"# <p style=\"font-family:Papyrus;color:Orange;font-size:1.em\"> Titanic Disaster EDA , Visualization and Survival Prediction using SVM <\/p>","0d6c734a":"#### Running the preprocessing on Train and Test Data set","4f4b4dd6":"### Checking Correlation of various Features","0d9f303c":"#### Overall accuracy scores received for both the models are close by. However, SVM score of individual category of prediction shows that it is slightly better when  predicting 'Survived'. We will use SVM for final prediction.","ba9d726e":"# Model Evaluation\n\n","773bd535":"#### Female passengers had higher Survival rate compared to Male passengers.","4be8bb1b":"# Feature Engineering","71a762ff":"### Checking Embarked for Survival","404b5191":"# Data Exploration and  Data Wrangling","2b11c157":"### Exploring mutliple features together","3f5978d5":"### Building a Reusable Function to apply on both Train and Test Data set","e7af4e8b":"#### There is a definite inclination to survival for some Titles like Lady, Sir, Countess etc. To capture this in our prediction, we will want to add a new Derived Feature for 'Title' in our Data set. ","84ba9a9f":"Here we see that both `train.csv` and `test.csv` has common behavior of **missing values in columns Age and Cabin.**","83ff3016":"We can observe in above visuals that survival rate is :\n    \n   1. better on certain Pclass values.\n   2. better on certain Age ranges\n   3. not so focussed on Parch Values.\n   4. better to for very high Fare rate.\n   \nFor other Features such as PassengerId, the survival rate is not having any centralized inclination on the feature at individual values level. ","623d31e9":"# Building the Model\n\n\nIn this stage we will be building our models. As already identified in the objective section above, we will be looking to build 2 type of models.\n\n1. SVM model\n\n2. Logistic Regression model","3835edc9":"Since exploring the data and accordingly wrangle it further the next exploration is an iterative process, we will combine the two stages together. \n\nAs part of Data Exploration stage, we would want to explore possible relationships of the avaialble features by looking at the `Survived` fact for the passengers.\n\nWe will also want to identify if there are new features we want to derive , that can be a better indicator for the survival chances.\n\nDuring the Wrangling , our goal is to identify and create a reusable function for the necessary pre-processing operations that needs to go on both train and test data sets so that they remain in unison standards when applied to model in later stages.","b6febe95":"# Data Acuisition"}}