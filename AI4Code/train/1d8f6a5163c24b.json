{"cell_type":{"1a28443e":"code","5ff2d1f3":"code","12736abd":"code","499a3bb3":"code","64c60259":"code","1c4851f9":"code","02f7a7c4":"code","a58676a3":"code","a5267619":"code","e0f823ba":"code","83413d34":"code","55a212d7":"code","ba2dc867":"code","d268e91d":"markdown","5225714a":"markdown","b18e9651":"markdown","494c576d":"markdown","5cac0b0e":"markdown"},"source":{"1a28443e":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\npd.options.display.max_colwidth = 100\n\nimport random\nimport os\n\nfrom numpy.random import seed\nseed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport glob\nimport cv2\n\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","5ff2d1f3":"IMG_SIZE = 150\nBATCH = 64\nSEED = 42\n","12736abd":"main_path = \"..\/input\/labeled-chest-xray-images\/chest_xray\"\n\n\ntrain_path = os.path.join(main_path,\"train\")\ntest_path=os.path.join(main_path,\"test\")\n\ntrain_normal = glob.glob(train_path+\"\/NORMAL\/*.jpeg\")\ntrain_pneumonia = glob.glob(train_path+\"\/PNEUMONIA\/*.jpeg\")\n\ntest_normal = glob.glob(test_path+\"\/NORMAL\/*.jpeg\")\ntest_pneumonia = glob.glob(test_path+\"\/PNEUMONIA\/*.jpeg\")\n\ntrain_list = [x for x in train_normal]\ntrain_list.extend([x for x in train_pneumonia])\n\ndf_train = pd.DataFrame(np.concatenate([['Normal']*len(train_normal) , ['Pneumonia']*len(train_pneumonia)]), columns = ['class'])\ndf_train['image'] = [x for x in train_list]\n\ntest_list = [x for x in test_normal]\ntest_list.extend([x for x in test_pneumonia])\n\ndf_test = pd.DataFrame(np.concatenate([['Normal']*len(test_normal) , ['Pneumonia']*len(test_pneumonia)]), columns = ['class'])\ndf_test['image'] = [x for x in test_list]\n\ntrain_df, val_df = train_test_split(df_train, test_size = 0.20, random_state = SEED, stratify = df_train['class'])","499a3bb3":"df_train","64c60259":"df_test","1c4851f9":"train_df, val_df = train_test_split(df_train, test_size = 0.20, random_state = SEED, stratify = df_train['class'])\n\ntrain_datagen = ImageDataGenerator(rescale=1\/255.,\n                                  zoom_range = 0.1,\n                                  #rotation_range = 0.1,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1)\n\nval_datagen = ImageDataGenerator(rescale=1\/255.)\n\nds_train = train_datagen.flow_from_dataframe(train_df,\n                                             #directory=train_path, #dataframe contains the full paths\n                                             x_col = 'image',\n                                             y_col = 'class',\n                                             target_size = (IMG_SIZE, IMG_SIZE),\n                                             class_mode = 'binary',\n                                             batch_size = BATCH,\n                                             seed = SEED)\n\nds_val = val_datagen.flow_from_dataframe(val_df,\n                                            #directory=train_path,\n                                            x_col = 'image',\n                                            y_col = 'class',\n                                            target_size = (IMG_SIZE, IMG_SIZE),\n                                            class_mode = 'binary',\n                                            batch_size = BATCH,\n                                            seed = SEED)\n\nds_test = val_datagen.flow_from_dataframe(df_test,\n                                            #directory=test_path,\n                                            x_col = 'image',\n                                            y_col = 'class',\n                                            target_size = (IMG_SIZE, IMG_SIZE),\n                                            class_mode = 'binary',\n                                            batch_size = 1,\n                                            shuffle = False)","02f7a7c4":"early_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\nplateau = callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor = 0.2,                                     \n    patience = 2,                                   \n    min_delt = 0.0000001,                                \n    cooldown = 0,                               \n    verbose = 1\n) \n","a58676a3":"def get_model():\n    \n    #Input shape = [width, height, color channels]\n    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    \n    # Convolu\u00e7\u00e3o inicial\n    x = layers.Conv2D(filters=1, kernel_size=3, padding='same')(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.2)(x)\n\n    #for n in range(47):\n    x = layers.Conv2D(filters=3, kernel_size=5, padding='same', dilation_rate=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.MaxPool2D()(x)\n    x = layers.Dropout(0.2)(x)\n    \n    \n    # Convolu\u00e7\u00e3o final\n    x = layers.Conv2D(filters=64, kernel_size=3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    \n\n    # Head\n    #x = layers.BatchNormalization()(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    \n    #Final Layer (Output)\n    output = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = keras.Model(inputs=[inputs], outputs=output)\n    \n    return model","a5267619":"%env KERAS_BACKEND=theano","e0f823ba":"model = get_model()\nmodel.compile(loss='binary_crossentropy',optimizer= keras.optimizers.Adam(learning_rate=0.00003), metrics='binary_accuracy')\n\nmodel.summary()\n\n","83413d34":"history = model.fit(ds_train,\n          batch_size = BATCH, epochs = 50,\n          validation_data=ds_val,\n          callbacks=[early_stopping, plateau],\n          steps_per_epoch=(len(train_df)\/BATCH),\n          validation_steps=(len(val_df)\/BATCH))","55a212d7":"score = model.evaluate(ds_val, steps = len(val_df)\/BATCH, verbose = 0)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])\n\nscore = model.evaluate(ds_test, steps = len(df_test), verbose = 0)\n\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","ba2dc867":"\nX_test, y_test = next(ds_test)\n\ny_pred = model.predict(X_test)\n\nprint('F1 score: ', metrics.f1_score(y_test, y_pred, average=\"macro\"))\nprint('Precision Score: ', metrics.precision_score(y_test, y_pred, average=\"macro\"))\nprint('Recall Score: ', metrics.recall_score(y_test, y_pred, average=\"macro\")) \nprint('Confusion Metrics: ', metrics.confusion_matrix(y_test, y_pred))","d268e91d":"**Projeto 3 - Redes Neuronal Convolucional**\nIntrodu\u00e7\u00e3o a Intelig\u00eancia Artificial CIC0135\nUnB - Departamento de Ci\u00eancia da Computa\u00e7\u00e3o\n2021- 1, Turma A\n\n\nNome: Marcus Vin\u00edcius Oliveira de Abrantes\nMatr\u00edcula: 19\/0034084\n\nBase de dados: https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/3","5225714a":"Tamanho da imagem e quantidade de lotes","b18e9651":"Compara\u00e7\u00e3o:","494c576d":"Importa\u00e7\u00f5es:","5cac0b0e":"![CNN de Liang e Zheng](https:\/\/i.imgur.com\/DNGctTz.png)"}}