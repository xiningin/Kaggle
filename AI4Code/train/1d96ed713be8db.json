{"cell_type":{"58147c28":"code","280034c4":"code","e87151a7":"code","517971bb":"code","8cae9e79":"code","1e92a939":"code","01e852a2":"code","dcf66af8":"code","17f14ed0":"code","ee28c442":"code","f433b484":"code","143cb18e":"code","d12b53bf":"code","2827fcbb":"code","133c5bb5":"code","cdb8a4f6":"code","2b74ec63":"markdown","6142b218":"markdown","8dcb767a":"markdown"},"source":{"58147c28":"#Disclaimer: most of following code was gathered from all over the internet.\nimport os\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nimport torchvision.datasets as datasets\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nimport pickle\nimport pandas as pd\n\nprint(os.listdir(\"..\/input\/\"))\n\n\n\n\n# Any results you write to the current directory are saved as output.","280034c4":"!ls ..\/input\/colorectal-histology-mnist\/kather_texture_2016_image_tiles_5000\/","e87151a7":"dataset_folder = \"\/input\"\ndataset_path = os.path.join(\"..\/input\/colorectal-histology-mnist\/kather_texture_2016_image_tiles_5000\", 'Kather_texture_2016_image_tiles_5000')\n\n# Load the dataset file names\noriginal_dataset = datasets.ImageFolder(dataset_path)\n# Extract the actual file names and labels as entries\nfileNames = np.asarray([item[0] for item in original_dataset.imgs])\nlabels = np.asarray([item[1] for item in original_dataset.imgs])\n# Split the data into two sets\nX_train, X_val, y_train, y_val = train_test_split(fileNames, labels,\n#                                                   test_size=200,\n                                                  random_state=42,\n                                                  stratify=labels)\n\nfor c in original_dataset.classes:\n    print(\"labels ({}) {}\".format(c, np.size(np.where(y_train == original_dataset.class_to_idx[c]))))\nfor c in original_dataset.classes:\n    print(\"split_train ({}) {}\".format(c, np.size(np.where(y_train == original_dataset.class_to_idx[c]))))\nfor c in original_dataset.classes:\n    print(\"split_val ({}) {}\".format(c, np.size(np.where(y_val == original_dataset.class_to_idx[c]))))\n\n# Create folders for new data\nsplit_train_dir = os.path.join(dataset_folder, \"train\")\nif os.path.exists(split_train_dir):\n    shutil.rmtree(split_train_dir)\nos.makedirs(split_train_dir)\n\nfor class_label in original_dataset.classes:\n    path = os.path.join(split_train_dir, class_label)\n    if os.path.exists(path):\n        shutil.rmtree(path)\n    os.makedirs(path)\n\nsplit_val_dir = os.path.join(dataset_folder, \"val\")\nif os.path.exists(split_val_dir):\n    shutil.rmtree(split_val_dir)\nos.makedirs(split_val_dir)\n\nfor class_label in original_dataset.classes:\n    path = os.path.join(split_val_dir, class_label)\n    if os.path.exists(path):\n        shutil.rmtree(path)\n    os.makedirs(path)\n\n# Copying the splits into their folders\nfor X, y in zip(X_train, y_train):\n    src = X\n    file_name = os.path.basename(src)\n    dest = os.path.join(split_train_dir, original_dataset.classes[y], file_name)\n    shutil.copy(X, dest)\n\nfor X, y in zip(X_val, y_val):\n    src = X\n    file_name = os.path.basename(src)\n    dest = os.path.join(split_val_dir, original_dataset.classes[y], file_name)\n    shutil.copy(X, dest)","517971bb":"# I need this small tweek to ImageFolder class to be able to get paths to images. I need path to use it in the tool I developed, to analyse output of the network\n# https:\/\/gist.github.com\/andrewjong\/6b02ff237533b3b2c554701fb53d5c4d\nclass ImageFolderWithPaths(datasets.ImageFolder):\n    \"\"\"Custom dataset that includes image file paths. Extends\n    torchvision.datasets.ImageFolder\n    \"\"\"\n\n    # override the __getitem__ method. this is the method dataloader calls\n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","8cae9e79":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = dataset_folder\n\ntrainData = ImageFolderWithPaths(root=os.path.join(data_dir, 'train'),transform=data_transforms['train'])\ntrainDataLoader = torch.utils.data.DataLoader(trainData,batch_size=4,shuffle=True,num_workers=4)\n\nvalData = ImageFolderWithPaths(root=os.path.join(data_dir, 'val'),transform=data_transforms['val'])\nvalDataLoader = torch.utils.data.DataLoader(valData,batch_size=4,shuffle=False,num_workers=4)\n\ndataset_sizes = {'train': len(trainData), 'val':len(valData)}\nprint(\"dataset_sizes: \",dataset_sizes)\nclass_names = trainData.classes\nprint(class_names)\nval_class_names = valData.classes\nprint(val_class_names)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"device: \", device)","1e92a939":"label = [str.strip(x) for x in list(trainDataLoader.dataset.classes)]\nlabel","01e852a2":"#Different visualization for train and test Data\nvalCnt = []\ntrainCnt = []\n\ndef countSamples(loader):\n    temp = []\n    for cls in range(len(label)):\n        tempCnt = 0\n        for x in loader:\n            if(cls == x[1]):\n                tempCnt+=1\n\n        temp.append(tempCnt)\n    return temp    \n\ntrainCnt = countSamples(trainDataLoader.dataset.imgs)\nvalCnt = countSamples(valDataLoader.dataset.imgs)\n\n#DATAFRAME\ndf = pd.DataFrame(data={'Class':label,'Train samples':trainCnt,'Val samples':valCnt})\n\nprint(df)","dcf66af8":"#Line bars\n#Train set\nfig0, ax0 = plt.subplots()\nax0.barh(label,trainCnt)\nax0.set_title('Training Data')\nax0.set_xlabel('Training Samples')\nax0.set_ylabel('Cancer categories')\n\n#Validation set\nfig1, ax1 = plt.subplots()\nax1.barh(label,valCnt)\nax1.set_title('Validation data')\nax1.set_xlabel('Validation samples')\nax1.set_ylabel('Cancer categories')","17f14ed0":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes, _ = next(iter(trainDataLoader))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","ee28c442":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n\n#     best_model_wts = copy.deepcopy(model.state_dict())\n#     best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        results, targets, features, predictions, filenames = [], [], [], [], []\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n                dataloaders = trainDataLoader\n            else:\n                model.eval()   # Set model to evaluate mode\n                dataloaders = valDataLoader\n                \n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels, paths in dataloaders:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                    if phase == 'val':\n                        for i in range(len(labels.cpu().numpy())):\n                            target = labels.cpu().numpy()[i]\n                            pred = preds.cpu().numpy()[i]\n                            output_feature = outputs.cpu().detach().numpy()[i]\n                            features.append(output_feature)\n                            targets.append(target)\n                            predictions.append(pred)\n                            filenames.append(paths[i])\n                    \n                \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            if phase == 'val':\n                results.append(features)\n                results.append(predictions)\n                results.append(targets)\n                results.append(filenames)\n\n                model_info = {\n                        \"model_expected_input_size\": \"224,224\",\n                        \"output_channels\": model.fc.out_features,\n                        \"model_name\": model.name,\n                        \"lr\": optimizer.state_dict()[\"param_groups\"][0]['lr'],\n                        \"batch_size\": 4,\n                        \"optimizer_name\": optimizer_ft.__class__.__name__,\n                        \"epoch\": format(epoch) }\n\n                results = {\"results\": results,\n                       \"model_info\": model_info}\n                results_dir = 'results'\n                if not exists(results_dir):\n                    makedirs(results_dir)\n                with open(os.path.join(results_dir, 'results_HIS'+ model.name +\"_\"+ format(epoch) + '.pkl'), 'wb') as f:\n                        pickle.dump(results, f, protocol=2)\n            \n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n#             if phase == 'val' and epoch_acc > best_acc:\n#                 best_acc = epoch_acc\n#                 best_model_wts = copy.deepcopy(model.state_dict())\n\n        \n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n#     print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n#     model.load_state_dict(best_model_wts)\n    return model","f433b484":"!ls ..\/input\/\ncache_dir = expanduser(join('~', '.torch'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models\/resnet34')\nif not exists(models_dir):\n    makedirs(models_dir)\n","143cb18e":"!cp ..\/input\/resnet34\/* ~\/.torch\/models\/","d12b53bf":"!ls ~\/.torch\/models","2827fcbb":"mv ~\/.torch\/models\/resnet34.pth ~\/.torch\/models\/resnet34-333f7ec4.pth ","133c5bb5":"model_ft = models.resnet34(pretrained=True)\nmodel_ft.name = \"ResNet34\"\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, len(trainDataLoader.dataset.classes))\n\n# found it on internet. not sure if it helps. Got same error but in another part of a code.\n# torch.backends.cudnn.enabled=False\n\n\nmodel_ft = model_ft.cuda()\n\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","cdb8a4f6":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=8)","2b74ec63":"All images are 150*150 pxls but we need to resize them to 224 to use pretrained network.","6142b218":"Let's first split dataset into train and val folders","8dcb767a":"Training the model\n------------------"}}