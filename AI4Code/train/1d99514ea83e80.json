{"cell_type":{"ef046e19":"code","557dea44":"code","ad7a5369":"code","fb1a41ee":"code","363c5d32":"code","cab185d1":"code","9fee4ac7":"code","6fcc2dee":"code","4a1d39d4":"code","aa1a4d20":"code","88c638b9":"code","a99b59f8":"code","83de0042":"code","70a925f5":"code","511ae953":"code","f6299d8f":"code","64126497":"code","5bbdfd4a":"code","25b7faed":"code","288aa31a":"code","cb22b59b":"code","313bd836":"code","71974bea":"code","b2c09434":"code","80e19b3c":"code","c843165c":"code","008ae96b":"code","ce28c804":"code","38d191d7":"code","ded13755":"code","8588ea66":"code","d7ed8595":"code","6e626ac9":"markdown","0b9b4b83":"markdown","32e1012e":"markdown","83605043":"markdown","19552c6a":"markdown","d448817d":"markdown","c5cda256":"markdown","25bb3e67":"markdown","39888b05":"markdown","af7c4aa9":"markdown","ac705631":"markdown","a3d2b526":"markdown","617d3d1e":"markdown","45f8d09b":"markdown","8f843546":"markdown","75f495ef":"markdown","ab7305de":"markdown","66962b69":"markdown","58639df5":"markdown","7229ca74":"markdown","9601c524":"markdown","b4523f5f":"markdown","da1d20c3":"markdown","dd3a499b":"markdown","8b4283fa":"markdown","1f668315":"markdown","b39cb052":"markdown","176ea108":"markdown","1936ca92":"markdown","c085d027":"markdown","c35daaf2":"markdown","3a559fde":"markdown","e674ea43":"markdown"},"source":{"ef046e19":"import time\nstart = time.time()","557dea44":"import numpy as np \nimport pandas as pd \nimport os\nfrom keras.layers import Dense, Flatten, Dropout, Lambda, Input, Concatenate, concatenate\nfrom keras.models import Model\nfrom keras.applications import *\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import regularizers","ad7a5369":"for dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fb1a41ee":"!unzip ..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip -d train\n!unzip ..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip -d test","363c5d32":"print(os.listdir('..\/'))","cab185d1":"filenames = os.listdir(\"..\/working\/train\/train\")\n\nlabels = []\nfor file in filenames:\n    category = file.split('.')[0]\n    if category == 'cat':\n        labels.append('cat')\n    else:\n        labels.append('dog')","9fee4ac7":"df = pd.DataFrame({\n    'filename': filenames,\n    'label': labels\n})","6fcc2dee":"df.head(10)","4a1d39d4":"def get_class_counts(df):\n    grp = df.groupby(['label']).nunique()\n    return {key: grp[key] for key in list(grp.keys())}\n\ndef get_class_proportions(df):\n    class_counts = get_class_counts(df)\n    return {val[0]: round(val[1]\/df.shape[0],4) for val in class_counts.items()}","aa1a4d20":"print(\"Dataset class counts\", get_class_counts(df))","88c638b9":"print(\"Dataset class proportions\", get_class_proportions(df))","a99b59f8":"train_df, validation_df = train_test_split(df, \n                                           test_size=0.1, \n                                           stratify=df['label'],\n                                           random_state = 42)","83de0042":"print(\"Train data class proportions : \", get_class_proportions(train_df))\nprint(\"Validation data class proportions : \", get_class_proportions(validation_df))","70a925f5":"train_df.head(10)","511ae953":"train_df = train_df.reset_index(drop=True)\n\nvalidation_df = validation_df.reset_index(drop=True)","f6299d8f":"train_df.head(10)","64126497":"batch_size = 64\ntrain_num = len(train_df)\nvalidation_num = len(validation_df)\n\nprint(\"The number of training set is {}\".format(train_num))\nprint(\"The number of validation set is {}\".format(validation_num))","5bbdfd4a":"def two_image_generator(generator, df, directory, batch_size,\n                        x_col = 'filename', y_col = None, model = None, shuffle = False,\n                        img_size1 = (224, 224), img_size2 = (299,299)):\n    gen1 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size1,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    gen2 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size2,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    \n    while True:\n        X1i = gen1.next()\n        X2i = gen2.next()\n        \n        if y_col:\n            yield [X1i[0], X2i[0]], X1i[1]  #X1i[1] is the label\n        else:\n            yield [X1i, X2i]\n        ","25b7faed":"ex_df = pd.DataFrame()\nex_df['filename'] = filenames[:5]\nex_df['label'] = labels[:5]\nex_df.head()\n\ntrain_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ne1 = two_image_generator(train_aug_datagen, ex_df, '..\/working\/train\/train\/',\n                                      batch_size = 2, y_col = 'label',\n                                      model = 'binary', shuffle = True)\n\nfig = plt.figure(figsize = (10,10))\nbatches = 0\nrows = 5\ncols = 5\ni = 0\nj = 0\nindices_a = [1, 2, 3, 4, 5, 11, 12, 13, 14, 15]\nindices_b = [6, 7, 8, 9, 10, 16, 17, 18, 19, 20]\nfor [x_batch, x_batch2], y_batch in e1:\n    for image in x_batch:\n        fig.add_subplot(rows, cols, indices_a[i])\n        i += 1\n        plt.imshow(image.astype('uint8'))\n        \n    for image in x_batch2:\n        fig.add_subplot(rows, cols, indices_b[j])\n        j += 1\n        plt.imshow(image.astype('uint8'))\n    \n    batches += 1\n    if batches >= 6:\n        break\nplt.show()\n\n","288aa31a":"train_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ntrain_generator = two_image_generator(train_aug_datagen, train_df, '..\/working\/train\/train\/',\n                                      batch_size = batch_size, y_col = 'label',\n                                      model = 'binary', shuffle = True)","cb22b59b":"validation_datagen = ImageDataGenerator()\n\nvalidation_generator = two_image_generator(validation_datagen, validation_df,\n                                           '..\/working\/train\/train\/', batch_size = batch_size,\n                                           y_col = 'label',model = 'binary', shuffle = True)","313bd836":"def create_base_model(MODEL, img_size, lambda_fun = None):\n    inp = Input(shape = (img_size[0], img_size[1], 3))\n    x = inp\n    if lambda_fun:\n        x = Lambda(lambda_fun)(x)\n    \n    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n        \n    model = Model(inp, base_model.output)\n    return model","71974bea":"#define vgg + resnet50 + densenet\nmodel1 = create_base_model(nasnet.NASNetLarge, (224, 224), nasnet.preprocess_input)\nmodel2 = create_base_model(inception_resnet_v2.InceptionResNetV2, (299, 299), inception_resnet_v2.preprocess_input)\nmodel3 = create_base_model(xception.Xception, (299, 299), xception.preprocess_input)\nmodel1.trainable = False\nmodel2.trainable = False\nmodel3.trainable = False\n\ninpA = Input(shape = (224, 224, 3))\ninpB = Input(shape = (299, 299, 3))\nout1 = model1(inpA)\nout2 = model2(inpA)\nout3 = model3(inpB)\n\nx = Concatenate()([out1, out2, out3])                \nx = Dropout(0.6)(x)\nx = Dense(1, activation='sigmoid')(x)\nmultiple_pretained_model = Model([inpA, inpB], x)\n\nmultiple_pretained_model.compile(loss = 'binary_crossentropy',\n                          optimizer = 'rmsprop',\n                          metrics = ['accuracy'])\n\nmultiple_pretained_model.summary()","b2c09434":"checkpointer = ModelCheckpoint(filepath='dogcat.weights.best.hdf5', verbose=1, \n                               save_best_only=True, save_weights_only=True)","80e19b3c":"%%time\nmultiple_pretained_model.fit_generator(\n    train_generator,\n    epochs = 3,\n    steps_per_epoch = train_num \/\/ batch_size,\n    validation_data = validation_generator,\n    validation_steps = validation_num \/\/ batch_size,\n    verbose = 1,\n    callbacks = [checkpointer]\n)","c843165c":"multiple_pretained_model.load_weights('dogcat.weights.best.hdf5')","008ae96b":"test_filenames = os.listdir(\"..\/working\/test\/test\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\n\nnum_test = len(test_df)\n\ntest_datagen = ImageDataGenerator()\n\ntest_generator = two_image_generator(test_datagen, test_df, '..\/working\/test\/test\/', batch_size = batch_size)","ce28c804":"prediction = multiple_pretained_model.predict_generator(test_generator, \n                                         steps=np.ceil(num_test\/batch_size))","38d191d7":"prediction = prediction.clip(min = 0.005, max = 0.995)","ded13755":"submission_df = pd.read_csv('..\/input\/dogs-vs-cats-redux-kernels-edition\/sample_submission.csv')\n\nfor i, fname in enumerate(test_filenames):\n    index = int(fname[fname.rfind('\/')+1:fname.rfind('.')])\n    submission_df.at[index-1, 'label'] = prediction[i]\nsubmission_df.to_csv('Cats&DogsSubmission.csv', index=False)","8588ea66":"submission_df.head()","d7ed8595":"## print run time\nend = time.time()\nprint(round((end-start),2), \"seconds\")","6e626ac9":"* We can see the classes are divided equally into 0.5.","0b9b4b83":"# Manually labelling 2 different datasets and save them into labels\n\nfile.split('.')[0] means - \n* the particular filename is a String separated by dots.\n* line.split(\".\")[0] returns the 1st item of the array. (the actual file looks like \"cat.100.jpg\")","32e1012e":"# Unzip the zip files","83605043":"# Check out where my output files reside","19552c6a":"* Confirm that the labels of both training and validation sets are equally divided.","d448817d":"* Divide the labels according to \"label\" stratification.","c5cda256":"* best weight will be stored in dogcat.weights.best.hdf5","25bb3e67":"* values smaller than 0.005 become 0.005, and values larger than 0.995 become 0.995.","39888b05":"# Prediction","af7c4aa9":"# Make sure that the labels are proportionately equal before and after the train_test_split","ac705631":"# [<center>Dogs Vs Cats<\/center>](https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition)","a3d2b526":"# Preprocessing\n\n1. Augmentation\n2. Flow_from_dataframe","617d3d1e":"# Preprocessing test data","45f8d09b":"* Public and private score : 0.04758\n* I've already been tried with resnet, vgg16 and inception. I'm gonna try something different with nasnet, inception resnet and exception. \n* This time my accuracy is almost 99%. Essential tips are included at the top of the code.","8f843546":"# Modeling\n\n1. Create model architecture\n2. Compile\n3. callbacks\n4. fit_generator","75f495ef":"* calculate the total time spent at the end of this notebook","ab7305de":"I'm gonna label the data, so that in train test split I won't have to use stratification.","66962b69":"# Submission","58639df5":"# Train Test Splitting","7229ca74":"> You can get the idea of different models from here : https:\/\/keras.io\/api\/applications\/","9601c524":"# See which directories have you got","b4523f5f":"* Test if the generator generates same images with two different sizes(225 & 300)","da1d20c3":"* In case of train_test_split, allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes. I'm using pandas dataframes. \n* Our dependent variable will be label and filename will act as an independent variable.","dd3a499b":"# Add data augmentation","8b4283fa":"# Clipping predicted result","1f668315":"* Since we're gonna use two different types of multi input model with flow from directory, I'm using two generator.\n* In case of generator, \"yield\" is used instead of \"return\". Cz, we need to generate image on the fly, which iterates over the loop once.","b39cb052":"* Adding augmented data will not improve the accuracy of the validation. Which is why, augmetation on validation dataset is kind of superfluous","176ea108":"# Import Packages","1936ca92":"# Model generation","c085d027":"* We can see, there is no need of indexing, so I'm dropping it.","c35daaf2":"# Specify DataFrame or Directory ","3a559fde":"# Fit model","e674ea43":"# Callback"}}