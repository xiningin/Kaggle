{"cell_type":{"4c2b0aac":"code","0aa48ff5":"code","cda9d1e5":"code","3f6004e0":"code","ce0e221b":"code","da89d328":"code","ef5d61a7":"code","e9d1cd14":"code","67ee093d":"code","5d174f9e":"code","ebdb2e9d":"code","73bcbcb0":"code","77d3e8d3":"code","707fa73b":"code","7d95169b":"code","9018c317":"code","30e35fdd":"code","3ec552d6":"code","b7d61551":"code","8ed009c0":"code","866958ea":"code","e0dc3000":"code","b949596a":"markdown","aac27bda":"markdown","a0b78fc8":"markdown","ae873c8c":"markdown","03ffe072":"markdown","35a9ffab":"markdown","c6eec0de":"markdown","8802c886":"markdown","3c2cca85":"markdown","a681eaf8":"markdown","124fc7ed":"markdown"},"source":{"4c2b0aac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0aa48ff5":"X = np.load('..\/input\/Sign-language-digits-dataset\/X.npy')\nY = np.load('..\/input\/Sign-language-digits-dataset\/Y.npy')","cda9d1e5":"img_size = 64\nplt.subplot(1, 2, 1)\nplt.imshow(X[260].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(X[900].reshape(img_size, img_size))\nplt.axis('off')","3f6004e0":"print(X.shape)\nprint(Y.shape)","ce0e221b":"# Y Values in [0, 1] range\nprint(Y.max())\nprint(Y.min())\n\n# X Values in [0, 1] range\nprint(X.max())\nprint(X.min())","da89d328":"# Then lets create x_train, y_train, x_test, y_test arrays\nfrom sklearn.model_selection import train_test_split\nxTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n\nxTrain = xTrain.reshape(-1,64,64,1)\nxTest = xTest.reshape(-1,64,64,1)\n\nprint(xTrain.shape)\nprint(yTrain.shape)\nprint(xTest.shape)\nprint(yTest.shape)","ef5d61a7":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import LearningRateScheduler\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation = 'relu', input_shape = (64,64,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (4,4),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","e9d1cd14":"optimizer = Adam(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999)","67ee093d":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","5d174f9e":"epochs = 30 # 1 epoch means 1 forward and 1 backward pass.\nbatch_size = 20 # Number of training samples for one forward\/backward pass.","ebdb2e9d":"datagen = ImageDataGenerator(\n        featurewise_center = False,  # set input mean to 0 over the dataset\n        samplewise_center = False,  # set each sample mean to 0\n        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n        samplewise_std_normalization = False,  # divide each input by its std\n        zca_whitening = False,  # dimesion reduction\n        rotation_range = 10,  # randomly rotate images in the range 10 degrees\n        zoom_range = 0.1, # Randomly zoom image 1%\n        width_shift_range = 0.1,  # randomly shift images horizontally 1%\n        height_shift_range = 0.1,  # randomly shift images vertically 1%\n        horizontal_flip = False,  # randomly flip images\n        vertical_flip = False)  # randomly flip images\n\ndatagen.fit(xTrain)","73bcbcb0":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)","77d3e8d3":"# fit the model\nhistory = model.fit_generator(datagen.flow(xTrain,\n                                           yTrain, \n                                           batch_size = batch_size), \n                              epochs = epochs, \n                              validation_data = (xTest, yTest), \n                              steps_per_epoch = xTrain.shape[0] \/\/ batch_size,\n                              callbacks = [annealer])","707fa73b":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color = 'b', label = \"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","7d95169b":"print(history.history.keys())","9018c317":"accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nlr = history.history['lr']\nepochs = range(len(accuracy))","30e35fdd":"plt.plot(epochs, accuracy, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()","3ec552d6":"plt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","b7d61551":"type(accuracy)\nnewLr = [x * 100 for x in lr]","8ed009c0":"plt.plot(epochs, accuracy, 'bo', label = 'Training accuracy')\nplt.plot(epochs, newLr, 'b', label = 'Learning Rate')\nplt.title('Learning Rate and Accuracy')\nplt.legend()\nplt.show()","866958ea":"final_loss, final_acc = model.evaluate(xTest, yTest, verbose = 0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","e0dc3000":"# Predict the values from the validation dataset\nY_pred = model.predict(xTest)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(yTest,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","b949596a":"**Training loss against validation loss**","aac27bda":"**Learning rate variation with epochs**","a0b78fc8":"<a id=\"1\"><\/a> \n## **Introduction**\n\n* We will use CNN for detact sign language digits. \n* Keras library will be used for building Convolutional Neural Networks (CNN)","ae873c8c":"# **Sign Language Digit Recognizer with Convolutional Neural Networks (CNN)**\n\n### **Content**\n* [Introduction](#1)\n* [Data Preparation](#2)\n    * [Train - Test Split and Reshape](#3)      \n* [CNN](#4)    \n* [Conclusion](#5)","03ffe072":"**Below plot shows loss values against epochs.**","35a9ffab":"<a id=\"5\"><\/a> \n## **Conclusion**\n* We used Keras for building Convolutional Neural Network model. We got approximately %99 accuracy.\n* *If you have a suggestion, I'd be happy to read it.*","c6eec0de":"<a id=\"4\"><\/a> \n# **CNN**\n\n* We'll use Keras library for building convolutional neural networks.","8802c886":"**Below plot shows training accuracy values against validation accuracy.**","3c2cca85":"<a id=\"2\"><\/a> \n### **Data Preparation**","a681eaf8":"<a id=\"3\"><\/a> \n## **Train - Test Split and Reshape**","124fc7ed":"**Evaluate the Model**"}}