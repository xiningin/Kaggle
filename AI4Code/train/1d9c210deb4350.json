{"cell_type":{"897a3f48":"code","a34ae77d":"code","1157a8b4":"code","0e92da7d":"code","564584db":"code","1b992f54":"code","c98197ae":"code","8580feb4":"code","c98c654f":"code","d72210a8":"code","289d9bfb":"code","a944905a":"code","e1d85e47":"code","7d571089":"code","b0b9c9ca":"code","d08af121":"code","a6bfb440":"code","4a79c32a":"code","ed7d1a2c":"code","f04b4410":"code","bf0e11b7":"code","efdebe3c":"code","8d4ec01c":"code","b9543899":"code","fd078197":"code","8ac7cf2a":"code","e3d173ab":"code","fab3c14b":"code","e8d36f80":"code","017bec21":"code","d265edad":"code","7cb546ec":"code","e10058b7":"code","0b246828":"code","ecaf8ef4":"code","bb3932c7":"code","13aa5d22":"code","3029a3f2":"code","a1614978":"code","a0f9d08d":"code","1babdc11":"code","303fdcb3":"code","42b283b4":"code","286b6e6a":"code","b774ead5":"code","b0061374":"code","424cc65b":"code","abbdac2b":"code","b2595f37":"code","b4bb9218":"code","e0c6e635":"code","f97a2cc9":"code","1068b450":"code","9d2200b0":"code","10316c49":"code","86848a37":"code","61786645":"code","6fdd70cf":"markdown","42fff4db":"markdown","026882f3":"markdown","75d2f738":"markdown","d574f97e":"markdown","f2417a02":"markdown","aa15f8b5":"markdown","025cc598":"markdown"},"source":{"897a3f48":"# Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","a34ae77d":"# Importing Netflix Dataset\n\ndf=df = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")\ndf.head()","1157a8b4":"df.shape","0e92da7d":"df.columns","564584db":"df.dtypes","1b992f54":"#As we can see 'release_year' is string type, we need to convert this column into date type\ndf.date_added=pd.to_datetime(df.date_added )\ndf.head()","c98197ae":"df.dtypes","8580feb4":"print(df.show_id.isnull().value_counts())\nprint(df.type.isnull().value_counts())\nprint(df.title.isnull().value_counts())\nprint(df.director.isnull().value_counts())\nprint(df.cast.isnull().value_counts())\nprint(df.country.isnull().value_counts())\nprint(df.date_added.isnull().value_counts())\nprint(df.release_year.isnull().value_counts())\nprint(df.rating.isnull().value_counts())\nprint(df.duration.isnull().value_counts())\nprint(df.listed_in.isnull().value_counts())\nprint(df.description.isnull().value_counts())","c98c654f":"df.isnull().sum()","d72210a8":"#Visualize the null values through heat map\n!pip install missingno\n","289d9bfb":"import seaborn as sns\nimport missingno as ms","a944905a":"heatmap_null_values=ms.heatmap(df, figsize=(10,7), cmap='PuBuGn')","e1d85e47":"#count of unique values\nunique_val=df.nunique()\nunique_val","7d571089":"#Null values of corresponding rows\ndf[df.rating.isna()]","b0b9c9ca":"#Fill 'ratings' NaN values with specific ratings\nuser_rating={67:'TV-MA', 2359:'R',3660:'R', 3736:'PG-13', 3737:'TV-MA', 3738:'R', 4323:'PG-13'}","d08af121":"df.rating=df.rating.fillna(user_rating)","a6bfb440":"df.rating.isnull().value_counts()","4a79c32a":"df[df.rating.isna()] # No null values are present in rating column","ed7d1a2c":"#Replacing country null value with maximum number of country\ncountry=df.loc[df.country.notnull(), 'country'].astype('str').apply(lambda t: t.split(', '))\n\ncountry=list(country)\nlen(country)","f04b4410":"!pip install mlxtend","bf0e11b7":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.preprocessing import TransactionEncoder","efdebe3c":"#Initiating encoder and fit and transform the encoder\nencoder_model=TransactionEncoder().fit(country)\n\nencode_country=encoder_model.transform(country)","8d4ec01c":"#Creating new dataframe with encoded counties\ndf_encode=pd.DataFrame(encode_country, columns=encoder_model.columns_, index=df.loc[df.country.notnull(), 'show_id'])\ndf_encode.head()","b9543899":"country_share=df_encode.mean().sort_values(ascending=False)\n\ncountry_share=country_share * 100\ncountry_share","fd078197":"\nimport matplotlib as mpl\n\nmpl.style.use('ggplot') # optional: for ggplot-like style\n\n# check for latest version of Matplotlib\nprint('Matplotlib version: ', mpl.__version__) # >= 2.0.0","8ac7cf2a":"#Visualiztion of country share in pie chart\n\n# take countries that share more than 1%\ncountry_share=country_share[country_share > 1 ]\nlabels=country_share.round(3).astype('str') + '%'\n#explode_list = [0.1, 0, 0, 0, 0.1, 0.1]\ncountry_share.plot(kind='pie', figsize=(10,10), labels=labels, shadow=True)\n\nplt.title('Percent of produced Movies\/TV Show by Country', fontsize=20)\nplt.legend(labels=country_share.index, loc='upper left')\nplt.show()","e3d173ab":"#Another method\n# take countries that share more than 2%\ncountry_share_1 = country_share[country_share > 2]\nlabels = country_share_1.round(3).astype('str') + ' %'\n\nfig1, ax1 = plt.subplots(figsize=(10,10), facecolor='white')\nax1.pie(country_share_1, labels=labels, labeldistance=1.05,\n        shadow=True)\nplt.title('Percent of produced Movies\/TV Show by Country', fontsize=20)\nplt.legend(labels=country_share_1.index, loc='upper right')\nplt.show()\n","fab3c14b":"df['country']=df['country'].fillna('United States')\ndf.isna().sum()","e8d36f80":"#Drop all the null values from cast column\ndf=df.dropna(subset=['cast'], how='all')","017bec21":"df.cast.isnull().value_counts() ","d265edad":"df.isnull().sum()","7cb546ec":"country_share","e10058b7":"#Formation of dataframe from 'country_share' series. \ndf_country_share=country_share.to_frame().reset_index()\ndf_country_share.head()","0b246828":"df_country_share=df_country_share.rename(columns={'index':'Country', 0:'Frequency'})","ecaf8ef4":"df_country_share.head()","bb3932c7":"# Visualise data in World Map\nimport folium\nprint('Folium installed and imported')","13aa5d22":"world_map = folium.Map()\nworld_map","3029a3f2":"!pip install xlrd","a1614978":"# download countries geojson file\n!wget --quiet https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-DV0101EN-SkillsNetwork\/Data%20Files\/world_countries.json\n    \nprint('GeoJSON file downloaded!')","a0f9d08d":"world_json= '\/kaggle\/input\/jsonfile\/world_countries.json.1'\nworld_json","1babdc11":"# generate choropleth map using Percent of produced Movies\/TV Show of each country\nworld_map.choropleth(\n    geo_data=world_json,\n    data=df_country_share,\n    columns=['Country', 'Frequency'],\n    key_on='feature.properties.name',\n    fill_color='RdBu',\n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Percent of produced Movies\/TV Show by Country'\n)\n\n# display map\nworld_map","303fdcb3":"df.isnull().sum()","42b283b4":"df.head()","286b6e6a":"#Extraction of genre fron 'listed_in' column\ngenre=df['listed_in'].apply(lambda x:x.strip() )\ngenre=genre.str.split(', ')\n#another method:\n#genre=df['listed_in'].apply(lambda x:x.split(', ') )\ngenre\ngenre_list=list(genre)\nprint(genre_list[5])\nprint(len(genre_list))\n\n","b774ead5":"#Initiate encoder\ngenre_encoder=TransactionEncoder().fit(genre)\ntransform=genre_encoder.transform(genre)\n","b0061374":"df_genre=pd.DataFrame(transform, columns=genre_encoder.columns_, index=df['show_id'])","424cc65b":"df_genre.shape","abbdac2b":"#Total number of counts of each genre type\ngenre_count=df_genre.sum().sort_values(ascending=False)\ngenre_count.head(10)","b2595f37":"#creating Bar plot for genres\n\ngenre_count.plot(kind='bar', figsize=(15,7), color='b')\n\nplt.xlabel('Genre Type')\nplt.ylabel('Count of Contents')\nplt.title('Plot between Genre Type vs Count of Contents')\nplt.show()","b4bb9218":"movies=df[df['type']=='Movie']['release_year'].value_counts().rename('Movies').reset_index()\nTV_shows=df[df['type']=='TV Show']['release_year'].value_counts().rename('TV Shows').reset_index()\n\n#Sorting value counts by years\nmovies=movies.sort_values(by='index')\nTV_shows=TV_shows.sort_values(by='index')\n\nmovies_plot=movies.plot(kind='line', x='index', y='Movies', legend='Movies', color='r')\n\nTV_Show_plot=TV_shows.plot(kind='line', x='index', y='TV Shows', legend='TV Shows', color='g')","e0c6e635":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import sigmoid_kernel\nmodel=TfidfVectorizer(max_df=2, min_df=1, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', max_features=None, stop_words='english', ngram_range=(1, 4))","f97a2cc9":"df['combination']= df['description'] + df['cast'] + df['director']\ndf.head(2)","1068b450":"df['combination']=df['combination'].fillna(' ')","9d2200b0":"# Utilising fit and transform method on model object\ntf_matrix=model.fit_transform(df['combination'])\n\nsigmoid=sigmoid_kernel(tf_matrix, tf_matrix)\nsigmoid[1]","10316c49":"indices=pd.Series(df.index, index=df['title'].drop_duplicates())\nindices","86848a37":"def recommend(title,sig=sigmoid):\n    idx = indices[title]\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores,key = lambda x:x[1], reverse = True)\n    sig_scores = sig_scores[1:11]\n    movies_indices = [i[0] for i in sig_scores]\n    return df['title'].iloc[movies_indices]","61786645":"recommend(\"Inside Man: Most Wanted\")","6fdd70cf":"Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. As we can see in 'country' cloumn frequent names are given, thats'y I have used apriori algorithm for finding frequency distribution","42fff4db":"## Netflix Data Visualisation and recomendation system ##\n$\n\\\\Netflix\n$","026882f3":"## Recomendation System ##","75d2f738":"No missing value is present in 'cast' column","d574f97e":"'Unites States' has the maximum frequency. I will fill 'NaN' value in country column with 'United States'","f2417a02":" According to above description 'director':2389, 'cast':718, 'country':507, 'date_added':10, 'rating':7 has null value. We need to remove this null value or fill with corresponding values. ","aa15f8b5":"Initiate encoder for finding count of unique items","025cc598":"## Please drop your suggetions here for any kind of modification. Your suggestion will be appreciated toward more learning ##"}}