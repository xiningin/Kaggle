{"cell_type":{"fb9962b5":"code","c2ad2e77":"code","4fcd6e1e":"code","dc2e2e22":"code","182575e0":"code","885c0e0e":"code","9122545b":"code","bc13a855":"code","1f1c75f8":"code","af586185":"code","95cd2702":"code","bcde3de7":"code","f67b1af7":"code","23711471":"code","4941f183":"code","c2bc2a30":"code","dfc382c5":"code","ee6590a6":"code","6e83510b":"code","cf5b8687":"code","40020f5a":"code","19e21f8f":"code","98bb480d":"code","fba0ef2f":"code","b9bc6780":"markdown","5756e72c":"markdown","92da5372":"markdown","3a2665ce":"markdown","7d1bbbc2":"markdown","517d717d":"markdown","da3bb735":"markdown","e753cd6d":"markdown","bd80e432":"markdown"},"source":{"fb9962b5":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style('whitegrid')\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score,confusion_matrix,recall_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\nfrom xgboost import XGBClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c2ad2e77":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\nprint(df.shape)\ndf.head()","4fcd6e1e":"df['ca'].value_counts()","dc2e2e22":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True,cmap='YlGnBu',fmt='.2f',linewidths=2)\n#No much of correlation","182575e0":"df['target'].value_counts()","885c0e0e":"sns.distplot(df['age'],color='Red',hist_kws={'alpha':1,\"linewidth\": 2},\n             kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE\"})\n#Most people age is from 40 to 60","9122545b":"fig,ax=plt.subplots(figsize=(24,12))\nplt.subplot(1, 3, 1)\nage_bins = [10,20,30,40,50,70,80]\ndf['age_bins'] = pd.cut(df['age'],bins = age_bins, duplicates='drop')\ng1 = sns.countplot(data= df, x= 'age_bins',hue='target',palette='plasma',linewidth=3)\ng1.set_title(\"Age vs Heart Disease\")\n\n\nplt.subplot(1, 3, 2)\ncho_bins = [100,150,200,250,300,350,400,450]\ndf['bin_chol']=pd.cut(df['chol'], bins=cho_bins)\ng2=sns.countplot(x='bin_chol',data=df,hue='target',palette='plasma',linewidth=3)\ng2.set_title(\"Cholestoral vs Heart Disease\")\n\n\nplt.subplot(1, 3, 3)\nthal_bins = [60,80,100,120,140,160,180,200,220]\ndf['bin_thal']=pd.cut(df['thalach'], bins=thal_bins)\ng3=sns.countplot(x='bin_thal',data=df,hue='target',palette='plasma',linewidth=3)\ng3.set_title(\"Thal vs Heart Disease\")","bc13a855":"sns.distplot(df['target'],kde= True)\ndf['target'].value_counts()","1f1c75f8":"df.columns","af586185":"df.info()","95cd2702":"#Conversion to categorical variables\ndf['sex']=df['sex'].astype('category')\ndf['cp']=df['cp'].astype('category')\ndf['fbs']=df['fbs'].astype('category')\ndf['restecg']=df['restecg'].astype('category')\ndf['exang']=df['exang'].astype('category')\ndf['slope']=df['slope'].astype('category')\ndf['ca']=df['ca'].astype('category')\ndf['thal']=df['thal'].astype('category')\ndf['target']=df['target'].astype('category')\ndf.dtypes\n","bcde3de7":"correlation = df.corr()\nplt.figure(figsize=(12,10))\nsns.heatmap(correlation,annot=True,cmap = 'Blues')","f67b1af7":"y = df['target']","23711471":"df = pd.get_dummies(df, drop_first = True) ## Converting the categorical features so that the model learns in a better way\ndf.head()","4941f183":"X = df.drop('target_1', axis = 1)\nX.head()","c2bc2a30":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = 100)","dfc382c5":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix","ee6590a6":"lr = LogisticRegression()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\naccuracy = accuracy_score(y_test,pred)\nclassification = classification_report(y_test,pred)\nconfusion_ = confusion_matrix(y_test,pred)\nprint(accuracy, classification,confusion_)","6e83510b":"from sklearn.model_selection import GridSearchCV\npenalty = ['l1','l2']\nC = np.logspace(0, 4, 10)\nhyperparameters = dict(C=C, penalty=penalty)\nh_logmodel = GridSearchCV(lr, hyperparameters, cv=6, verbose=0)\nbest_logmodel=h_logmodel.fit(x_train,y_train)\nprint('Best Penalty:', best_logmodel.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_logmodel.best_estimator_.get_params()['C'])","cf5b8687":"lr1 = LogisticRegression(penalty='l2',C = 1.0)\nlr1.fit(x_train,y_train)\npred = lr1.predict(x_test)\naccuracy = accuracy_score(y_test,pred)\nclassification = classification_report(y_test,pred)\nconfusion_ = confusion_matrix(y_test,pred)\nprint(accuracy)\nprint(confusion_)\nprint(classification)","40020f5a":"import pickle\npickle.dump(lr1,open('heart.pkl','wb'))","19e21f8f":"def predict_price(age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldspeak,slope,ca,thal):    \n\n    x = np.zeros(40)\n    x[0] = age\n    x[1] = sex\n    x[2] = cp\n    x[3] = trestbps\n    x[4] = chol\n    x[5] = fbs\n    x[6] = restecg\n    x[7] = thalach\n    x[8] = exang\n    x[9] = oldspeak\n    x[10] = slope\n    x[11] = ca\n    x[12] = thal\n\n    #if loc_index >= 0:\n        #   x[loc_index] = 1\n\n    return lr.predict([x])[0]\n\npredict_price(54,0,2,108,267,0,0,167,0,0.0,2,0,2)\n","98bb480d":"pickle_in = open('heart.pkl','rb')\nclf = pickle.load(pickle_in)","fba0ef2f":"clf.predict(x_train)","b9bc6780":"## we can see that our independent variable is Balanced.","5756e72c":"## Exploratory Data Analysis","92da5372":"# Data Cleaning and Exploration","3a2665ce":"## Model Deployment using Streamlit on Heroku\n\n### Want to build an End-to-End project using Machine Learning, this Notebook will help you do so!\n\n[Link to GitHub Repo](https:\/\/github.com\/Lokeshrathi\/Deploying-a-Machine-Learning-Model)\n\n[Link to My WebPage](https:\/\/heart-disease-ml-app.herokuapp.com\/)","7d1bbbc2":"## Prediction","517d717d":"# Visit this [GitHub Link](https:\/\/github.com\/Lokeshrathi\/Deploying-a-Machine-Learning-Model) for Deployment of the Model on Heroku\n\n### Also pin down your doubts, if you have any!","da3bb735":"### Use Pickle to save your model!","e753cd6d":"# Model Training","bd80e432":"- age- in years\n- sex-(1 = male; 0 = female)\n- cp- chest pain type\n- trestbps- resting blood pressure (in mm Hg on admission to the hospital)\n- chol- serum cholestoral in mg\/dl\n- fbs-(fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n- restecg-resting electrocardiographic results\n- thalach-maximum heart rate achieved\n- exang-exercise induced angina (1 = yes; 0 = no)\n- oldpeak-ST depression induced by exercise relative to rest\n- slope-the slope of the peak exercise ST segment\n- ca-number of major vessels (0-3) colored by flourosopy\n- thal- 3 = normal; 6 = fixed defect; 7 = reversable defect\n- target- 1 or 0"}}