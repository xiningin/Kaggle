{"cell_type":{"33e7ac09":"code","8e2250bd":"code","0c1d926f":"code","850e8df2":"code","98706d36":"code","174d9248":"code","18f4bcb3":"code","f6d87ff1":"code","80999e8e":"code","f88318fc":"code","e63a199a":"code","026f2891":"code","9c7d6569":"code","09297475":"code","ec3907ca":"code","ee0f8cd8":"code","81ff1c7f":"code","41f103c0":"code","61ec75f0":"code","16061c75":"code","d08da950":"markdown","e5d631fb":"markdown","738d42d0":"markdown","3bcb2511":"markdown","eee93029":"markdown","592474dc":"markdown","bb3f3109":"markdown","c12e1f69":"markdown","c684fc95":"markdown","0ff2b556":"markdown","cb5ea186":"markdown","8c72b01f":"markdown","50fdb556":"markdown","4cb8807e":"markdown","47be34ce":"markdown","a4d8d804":"markdown"},"source":{"33e7ac09":"# kaggle competitions download -c tabular-playground-series-dec-2021\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler , LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import mode\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.utils import to_categorical\n\nfrom matplotlib import ticker\nimport time\nimport warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('float_format', '{:f}'.format)\nwarnings.filterwarnings('ignore')","8e2250bd":"# folder_path = \"\/content\/drive\/MyDrive\/input\/tabular-playground-series-dec-2021\"\nfolder_path = \"..\/input\/tabular-playground-series-dec-2021\"\n\ntrain = pd.read_csv(folder_path+\"\/train.csv\")\ntest = pd.read_csv(folder_path+\"\/test.csv\")\nsubmission = pd.read_csv(folder_path+\"\/sample_submission.csv\")\n\n\ntrain.drop([\"Id\"] , axis = 1 , inplace = True)\ntest.drop([\"Id\"] , axis = 1 , inplace = True)\nTARGET = 'Cover_Type'\nFEATURES = [col for col in train.columns if col not in ['id', TARGET]]\nRANDOM_STATE = 12 ","0c1d926f":"train.head()","850e8df2":"print(f'Number of rows in train data: {train.shape[0]}')\nprint(f'Number of columns in train data: {train.shape[1]}')\nprint(f'No of missing values in train data: {sum(train.isna().sum())}')","98706d36":"train.describe()","174d9248":"test.head()","18f4bcb3":"print(f'Number of rows in test data: {test.shape[0]}')\nprint(f'Number of columns in test data: {test.shape[1]}')\nprint(f'No of missing values in test data: {sum(test.isna().sum())}')","f6d87ff1":"test.describe()","80999e8e":"# Submission File\nsubmission.head()","f88318fc":"train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","e63a199a":"df = pd.concat([train[FEATURES], test[FEATURES]], axis=0)\n\ncat_features = [col for col in FEATURES if df[col].nunique() < 25]\ncont_features = [col for col in FEATURES if df[col].nunique() >= 25]\n\ndel df\nprint(f'Total number of features: {len(FEATURES)}')\nprint(f'Number of categorical features: {len(cat_features)}')\nprint(f'Number of continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#76D7C4', '#F5B7B1'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\nplt.show()","026f2891":"ncols = 5\nnrows = int(len(cont_features) \/ ncols + (len(FEATURES) % ncols > 0))-1\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(18, 8), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.kdeplot(x=train[col], ax=axes[r, c], color='#58D68D', label='Train data')\n        sns.kdeplot(x=test[col], ax=axes[r, c], color='#DE3163', label='Test data')\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n        axes[r, c].tick_params(labelsize=5, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(4)\n        axes[r, c].yaxis.offsetText.set_fontsize(4)\nplt.show()","9c7d6569":"if len(cat_features) == 0 :\n    print(\"No Categorical features\")\nelse:\n    ncols = 5\n    nrows = int(len(cat_features) \/ ncols + (len(FEATURES) % ncols > 0)) \n\n    fig, axes = plt.subplots(nrows, ncols, figsize=(18, 45), facecolor='#EAEAF2')\n\n    for r in range(nrows):\n        for c in range(ncols):\n            if r*ncols+c >= len(cat_features):\n                break\n            col = cat_features[r*ncols+c]\n            sns.countplot(x=train[col], ax=axes[r, c], color='#58D68D', label='Train data')\n            sns.countplot(x=test[col], ax=axes[r, c], color='#DE3163', label='Test data')\n            axes[r, c].set_ylabel('')\n            axes[r, c].set_xlabel(col, fontsize=8, fontweight='bold')\n            axes[r, c].tick_params(labelsize=5, width=0.5)\n            axes[r, c].xaxis.offsetText.set_fontsize(4)\n            axes[r, c].yaxis.offsetText.set_fontsize(4)\n    plt.show()","09297475":"target_df = pd.DataFrame(train[TARGET].value_counts()).reset_index()\ntarget_df.columns = [TARGET, 'count']\nfig = px.bar(data_frame =target_df, \n             x = 'Cover_Type',\n             y = 'count' , \n             color = \"count\",\n             color_continuous_scale=\"Emrld\") \nfig.show()\ntarget_df.sort_values(by =TARGET , ignore_index = True)","ec3907ca":"train = train.drop(index = int(np.where(train[\"Cover_Type\"] == 5 )[0]))\ntrain = train.drop(labels = [\"Soil_Type7\" , \"Soil_Type15\"] ,axis = 1)\nFEATURES.remove('Soil_Type7')\nFEATURES.remove('Soil_Type15')","ee0f8cd8":"train[\"mean\"] = train[FEATURES].mean(axis=1)\ntrain[\"std\"] = train[FEATURES].std(axis=1)\ntrain[\"min\"] = train[FEATURES].min(axis=1)\ntrain[\"max\"] = train[FEATURES].max(axis=1)\n\ntest[\"mean\"] = test[FEATURES].mean(axis=1)\ntest[\"std\"] = test[FEATURES].std(axis=1)\ntest[\"min\"] = test[FEATURES].min(axis=1)\ntest[\"max\"] = test[FEATURES].max(axis=1)\n\nFEATURES.extend(['mean', 'std', 'min', 'max'])","81ff1c7f":"scaler = StandardScaler()\nfor col in FEATURES:\n    train[col] = scaler.fit_transform(train[col].to_numpy().reshape(-1,1))\n    test[col] = scaler.transform(test[col].to_numpy().reshape(-1,1))\n    \nX = train[FEATURES].to_numpy().astype(np.float32)\ny = train[TARGET].to_numpy().astype(np.float32)\nX_test = test[FEATURES].to_numpy().astype(np.float32)\n\ndel train, test","41f103c0":"LEARNING_RATE = 0.0001\nBATCH_SIZE = 2048\nEPOCHS = 100\nVALIDATION_RATIO = 0.05\n\nLE = LabelEncoder()\ny = to_categorical(LE.fit_transform(y))\nX_train , X_valid ,y_train ,y_valid  = train_test_split(X,y , test_size = VALIDATION_RATIO , random_state=RANDOM_STATE)\n\n\ndef load_model(): \n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(2048, activation = 'swish', input_shape = [X.shape[1]]),\n        tf.keras.layers.Dense(1024, activation ='swish'),\n        tf.keras.layers.Dense(512, activation ='swish'),\n        tf.keras.layers.Dense(6, activation='softmax'),\n    ])\n    model.compile(\n        optimizer= tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n        loss='categorical_crossentropy',\n        metrics=['acc'],\n    )\n    return model\n    \n    \nearly_stopping = callbacks.EarlyStopping(\n        patience=10,\n        min_delta=0,\n        monitor='val_loss',\n        restore_best_weights=True,\n        verbose=0,\n        mode='min', \n        baseline=None,\n    )\nplateau = callbacks.ReduceLROnPlateau(\n            monitor='val_loss', \n            factor=0.2, \n            patience=4, \n            verbose=0,\n            mode='min')\n\nnn_model = load_model()\nhistory = nn_model.fit(  X_train , y_train,\n                validation_data = (X_valid , y_valid),\n                batch_size = BATCH_SIZE, \n                epochs = EPOCHS,\n                callbacks = [early_stopping , plateau],\n              )\nnn_preds = nn_model.predict(X_test , batch_size=BATCH_SIZE)","61ec75f0":"nn_submission = submission.copy()\nnn_submission[\"Cover_Type\"] = LE.inverse_transform(np.argmax((nn_preds), axis=1)).astype(int)\nnn_submission.to_csv(\"nn-sub.csv\" , index= False)\nnn_submission.head()","16061c75":"# download submission\n# from google.colab import files\n# files.download('nn-sub.csv')","d08da950":"## Neural Network","e5d631fb":"# Tabular Playground Series - Dec 2021\n\nSimple EDA and Practice ML on kaggle\n\n- Data based on [Forest Cover Type Prediction](https:\/\/www.kaggle.com\/c\/forest-cover-type-prediction\/overview)\n\n","738d42d0":"# Basic Statistics","3bcb2511":"## Feature Distribution of Categorical Features","eee93029":"## Feature Engineering","592474dc":"# Modeling","bb3f3109":"# Imports","c12e1f69":"# EDA","c684fc95":"## Target Distribution","0ff2b556":"## Basic statistics of test data","cb5ea186":"## Removing Unwanted Rows and columns","8c72b01f":"## Continuos and Categorical Data Distribution","50fdb556":"# Submission","4cb8807e":"## Feature Distribution of Continous Features","47be34ce":"# Data Loading and Preperation","a4d8d804":"## Basic statistics of train data"}}