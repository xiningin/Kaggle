{"cell_type":{"0e444f48":"code","9c0333b2":"code","ddb74515":"code","e8ec8c7b":"code","2cf74fce":"code","8d4485b5":"code","c41f9f61":"code","4c381155":"code","25b14f5b":"code","82e54c19":"code","f8bd4b0c":"code","9dea2d83":"code","5b550d82":"code","bd090eb7":"code","963c0ee9":"code","5d6f49be":"code","985f483b":"code","6ee1ffc6":"code","0c72bf6d":"code","d7bb6f9b":"code","220372ad":"code","0e6b0687":"code","d486fa41":"markdown","109d035f":"markdown","8041a815":"markdown","2124fb26":"markdown","86ea6893":"markdown","0ddccd3a":"markdown","90bc9318":"markdown","6f4c4365":"markdown","61264d45":"markdown","b95c0c13":"markdown","8b88d593":"markdown","67d7e6e4":"markdown","9cf57115":"markdown","6c082081":"markdown","53d56d4b":"markdown","5716898a":"markdown"},"source":{"0e444f48":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom PIL import Image\nimport cv2\n\nfrom glob import glob\nimport time\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom skimage.feature import hog\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix\n","9c0333b2":"labels_csv = pd.read_csv('..\/input\/traffic-signs-classification\/labels.csv')\nlabels_csv.head()","ddb74515":"labels_dict = {labels_csv.iloc[i][\"ClassId\"]:labels_csv.iloc[i][\"Name\"] for i in range(len(labels_csv))}\nlabels_dict","e8ec8c7b":"image_paths = []\ny = []\n\nfor class_path in glob(\"..\/input\/traffic-signs-classification\/myData\/*\"):\n    \n    cpath_replaced = class_path.replace(\"..\/input\/traffic-signs-classification\/myData\/\",\"\")\n    \n    i = cpath_replaced[0]\n    if len(cpath_replaced)>1:\n        if cpath_replaced[1] in (\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"):\n            i = int(i+cpath_replaced[1])\n        \n    for image_path in glob(class_path+\"\/*\"):\n        image_paths.append(image_path)\n        y.append(i)\n        \nfor sample_label,sample_path in zip(y[:5],image_paths[:5]):\n    print(\"Label: {} Path: {}\".format(sample_label,sample_path))","2cf74fce":"print(\"There are {} classes in the dataset\".format(len(set(y))))","8d4485b5":"IMAGE_SIZE = (32,32)\n# Our dataset is already resized so resize parameter's value is false default.\ndef read_image(img_path,resize=False):\n    img = Image.open(img_path)\n    \n    if resize:\n        img.resize(IMAGE_SIZE)\n    \n    return np.asarray(img)","c41f9f61":"sample_image = read_image(\"..\/input\/traffic-signs-classification\/myData\/0\/00000_00000 - Copie.jpg\")\nsample_image.shape","4c381155":"plt.imshow(sample_image)\nplt.axis(\"off\")\nplt.show()","25b14f5b":"x = np.asarray([read_image(image_path) for image_path in image_paths])\nx.shape","82e54c19":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)","f8bd4b0c":"y_train = np.asarray(y_train)\ny_test = np.asarray(y_test)","9dea2d83":"print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","5b550d82":"model = keras.Sequential()\n\nmodel.add(layers.Conv2D(32,kernel_size=(4,4),strides=1,padding=\"same\",input_shape=[32,32,3]))\nmodel.add(layers.Conv2D(64,kernel_size=(4,4),strides=1,padding=\"same\"))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\n\nmodel.add(layers.Conv2D(128,kernel_size=(4,4),strides=1,padding=\"same\"))\nmodel.add(layers.Conv2D(256,kernel_size=(4,4),strides=1,padding=\"same\"))\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(len(set(y)),activation=\"softmax\"))\n\nmodel.summary()\n","bd090eb7":"model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","963c0ee9":"y_train_encoded = np.asarray(pd.get_dummies(pd.DataFrame(y_train),columns=[0]))\ny_test_encoded = np.asarray(pd.get_dummies(pd.DataFrame(y_test),columns=[0]))\n\nprint(y_train_encoded.shape)\nprint(y_test_encoded.shape)","5d6f49be":"history = model.fit(x_train,y_train_encoded,batch_size=128,epochs=2)","985f483b":"model.evaluate(x_test,y_test_encoded)","6ee1ffc6":"\"\"\"\nFirst we'll do an example to show you how the hog features look like.\n\"\"\"\n\nfd, hog_image = hog(sample_image, orientations=8, pixels_per_cell=(4, 4),\n                    cells_per_block=(1, 1), visualize=True)\n\nplt.imshow(hog_image)\nplt.axis(\"off\")\nplt.show()","0c72bf6d":"x_train_fd = []\nx_test_fd = []\n\nfor image in x_train:\n    x_train_fd.append(hog(image, orientations=8, pixels_per_cell=(4, 4),\n                    cells_per_block=(1, 1), visualize=False))\n    \nfor image in x_test:\n    x_test_fd.append(hog(image, orientations=8, pixels_per_cell=(4, 4),\n                    cells_per_block=(1, 1), visualize=False))\n\n\nx_train_fd = np.asarray(x_train_fd)\nx_test_fd = np.asarray(x_test_fd)","d7bb6f9b":"print(x_train_fd.shape)\nprint(x_test_fd.shape)","220372ad":"clf = SVC()\nclf.fit(x_train_fd,y_train)","0e6b0687":"print(\"Accuracy of the SVM Classifier is: {}%\".format(round(clf.score(x_test_fd,y_test),2)))","d486fa41":"* Accuracy is good and loss shows that model did not overfit, everything seems okay, our CNN has done well in this mission.\n","109d035f":"\n* Now we'll get the paths of the images by label and read them","8041a815":"* Our paths are ready, now we can read the entire dataset. First we'll define a function to ease the process, then we'll read them all.","2124fb26":"* As we can see here, accuracy of the Support Vector Machine classifier is almost the same with the convolutional neural network.\n\n### So we could use a SVM classifier instead of a complex neural network in this mission.\n\n# Conclusion\nIn this kernel we've seen that we can use traditional machine learning algorithms instead of deep learning in some missions and this way we can reduce the computation power we need. \n\nI hope this kernel gave you a new way of thinking about how to choose algorithms for various missions. I'd be glad if you give me an upvote :)\n\nHave a good day.\n","86ea6893":"And the last thing we need to do is splitting our dataset for training and evaluating.","0ddccd3a":"* Now we'll extract the features of all images and stack them on a numpy array.","90bc9318":"* Now let's check the accuracy in the test set.","6f4c4365":"* We've successfully extracted the features and we can fit the SVM","61264d45":"# Training CNN\n\nIn this section we're going to build a small Convolutional Neural Network using Keras Sequential API and train it.","b95c0c13":"* In order to make it more useful, I'm going to make it a dictionary.","8b88d593":"* First we'll read the labels from the csv file","67d7e6e4":"# Introduction\n\nHello kagglers! It's been a lot since I could not find time to write kernels here because of my school but finally today I could create some free time to write one.\n\nWe use several deep learning methods in the field of computer vision. We use Convolutional Neural Networks (CNNs) to classify images; YOLO, SSD to detect objects, GAN variants to create images and so forth.\n\nBut in some missions, like classification, **it may be better to use traditional machine learning instead of deep learning** and here is why:\n\n### Why is traditional ML just better than deep learning sometimes:\n* As you know, training a deep learning model costs a lot, it needs a huge computational power and time. However traditional machine learning algorithms takes less computational power and time for training and **if your dataset is not as huge as that wouldn't be possible to handle with machine learning** ML algorithms may give similar results.\n\n### So giving a chance to machine learning before deciding on the deep learning may be lucrative at a point.\n\n* And in this kernel we're going to classify traffic signs with two algorithms. First we'll train a **Convolutional Neural Network**, then we'll fit a **Support Vector Machine Classifier** after extracting the HOG (Histogram Of Gradients, which is a way to extract features from the images.) features of the images.\n","9cf57115":"# Importing Libraries and The Data","6c082081":"# Fitting The Support Vector Machine With The HOG Features\nIn the previous section we've built a CNN with one million parameters, which is not that much for a neural network, and got an accuracy score 97% in the test set.\n\nIn this section we're going to go with Support Vector Machine Classifier, which is one of the best traditional machine learning algorithms for classifying images.\n\nWhen we use deep learning to classify images, convolution operators extracts the features of the images and they learn **what they should extract**, and the dense layers of our neural network learn **to interpret those features** \n\nOn the other hand, when we use traditional machine learning we need to use external statistics based feature extractors to extract the features of the images and in this kernel I'm going to use Histogram Of Gradients, which is one of the most populars.\n\nIn order not to stay off topic I'm not going to go into the details of HOG but it's a dazzling method to extract features, you should check it.","53d56d4b":"* Awesome, we've trained our CNN and it's ready for the test, let's test it and see the results.","5716898a":"* Now there's just one more step before training our model, one hot encoding the labels."}}