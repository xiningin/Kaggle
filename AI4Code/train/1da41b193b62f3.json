{"cell_type":{"4138c1d6":"code","2616b953":"code","641f13d1":"code","60d06b94":"code","cc3bd997":"code","6a0145f6":"code","e1f7218b":"code","8e3508e7":"code","996a4a05":"code","d274bf31":"code","51781eaf":"code","490b6c1c":"code","02172ed7":"code","8f56521d":"code","67cef684":"code","49d71972":"markdown","06f71cf0":"markdown","749f808d":"markdown","d00ed2d0":"markdown","2efbc0d0":"markdown","3f5c3361":"markdown","0e9d4c6f":"markdown"},"source":{"4138c1d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2616b953":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline\nimport matplotlib.pyplot as plt\n","641f13d1":"train_path = \"\/kaggle\/input\/cat-and-dog\/training_set\/training_set\"\ntest_path = \"\/kaggle\/input\/cat-and-dog\/test_set\/test_set\"\n","60d06b94":"IMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)","cc3bd997":"train_batches = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n                train_path ,target_size=(IMG_SIZE,IMG_SIZE),batch_size=24,class_mode='categorical')\n\ntest_batches = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(\n                test_path ,target_size=(IMG_SIZE,IMG_SIZE),batch_size=24,class_mode='categorical')","6a0145f6":"base_model = keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\nbase_model.trainable = False","e1f7218b":"feature_batch = base_model.output\n\nglobal_average_layer = keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\n\nprediction_layer = keras.layers.Dense(2)\nprediction_batch = prediction_layer(feature_batch_average)","8e3508e7":"model = keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer\n])","996a4a05":"model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","d274bf31":"history = model.fit_generator(train_batches,\n                         steps_per_epoch=24,\n                         epochs=10,\n                         validation_data=test_batches,\n                         validation_steps=200)","51781eaf":"loss0,accuracy0 = model.evaluate(test_batches, steps = 20)","490b6c1c":"accuracy0","02172ed7":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","8f56521d":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\nplt.show()\n","67cef684":"plt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n","49d71972":"I used **MobileNetV2** pre-trained model.You can find another models in https:\/\/keras.io\/applications\/","06f71cf0":"Transfer learning is one of the most important things in computer vision. Since, model training on the large dataset is spend most of the time and it depends on your hardware to create a strong-robust model.The significant things is that we use pre-trained models for transfer learning and we just cut the last layer of the pre-trained model and we add our prediction layer.","749f808d":"**Transfer Learning**","d00ed2d0":"Here is the all library I used","2efbc0d0":"For instance, if a model contains 1000 categories , there 1000 neurons at the end of the layers responsible for classifier ,altough you have 2 categories at the your dataset , you can simply use transfer learning and add the Dense layers at the end of the pre-trained model.","3f5c3361":"I should say that the dataset structure is well for our transfer-learning model. Because at the next cell I used \"ImageDataGenerator\" class for the Data Augmentation also used \"flow_from_directory\" method. Due to this method , we simply flow through  the directory where the dataset placed to obtain categories.","0e9d4c6f":"while I was writing the above paragraph , I speak of the \"end of the pre-trained model layer\" but sometimes this might be confused because it's also refer to the \"top of the pre-trained model layer\". So, it depends on the way you look"}}