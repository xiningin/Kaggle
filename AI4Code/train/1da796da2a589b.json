{"cell_type":{"0255367d":"code","9a545152":"code","86aaa707":"code","719b9198":"code","d910f1a2":"code","a97ee980":"code","796b0ca5":"markdown","e3049950":"markdown","0adc4923":"markdown","6a11a27c":"markdown","3b081f10":"markdown"},"source":{"0255367d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a545152":"df=pd.read_csv('..\/input\/iris\/Iris.csv')\ndf","86aaa707":"df.describe()","719b9198":"#Set species as the predicted variable\n\ny=df.Species\n\n#Set the other variables as features\n\nX=df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\nX.describe()","d910f1a2":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\n\niris_model = LogisticRegression()\nscores=cross_val_score(iris_model, X, y, cv=10, scoring='accuracy')\nscores.mean()","a97ee980":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nscores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\nk_range = list(range(1, 31))\nk_scores = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n    k_scores.append(scores.mean())\n    \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\n\nknn = KNeighborsClassifier(n_neighbors=20)\nprint(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())\n","796b0ca5":"# 2-Set the Features and the Response Variable\n\nDefine species as the reponse variable as it is the variable that we want to predict. I will set ghe remaining variables in the dataset as features.","e3049950":"# 5-Conclusion\n\nBy using the best method to measure the accuracy (K-Fold Cross Validation), we can notice that the KNN model (number of neighbors=20) has a better accuracy than the logistic regression model.","0adc4923":"# 3- Logistic Regression Model\n\nI will build the logistic regression model with all the features and the response mentioned before. I will thereafter measure the accuracy of the model by using the K-Fold Cross Validation method.","6a11a27c":"# 1-Import the data","3b081f10":"# 4-KNN model\n\nI will build the KNN model by first determining the best number of neighbors. On the graph, we can see that 12,18 and 20 have the best accuracy. However, I will choose 20 for my model because I prefer to overfit a model than to underfit it. Thereafter, I will evaluate the accuracy of the model with the K-Fold Cross Validation method."}}