{"cell_type":{"dc1db364":"code","115917d3":"code","e2651917":"code","1af814c2":"code","af20acde":"code","09114403":"code","682d78f8":"code","93048c3d":"code","a6f50b42":"code","b3162ccb":"code","52379cde":"code","bc1e9e0f":"code","c6fe46b5":"code","bff70de5":"code","6c9f8670":"code","c6a51254":"code","7b07b397":"code","306fb22f":"code","f5cf3ad4":"markdown","53a7511c":"markdown","d30d8643":"markdown","82bf6d67":"markdown","846643ec":"markdown","204913c0":"markdown","36469fb2":"markdown","baba7724":"markdown","74d8c40a":"markdown","b34e2beb":"markdown","ec354b48":"markdown","f8baa5ff":"markdown","7abef599":"markdown","34b7d036":"markdown","bda90fbf":"markdown","3a721126":"markdown"},"source":{"dc1db364":"import copy\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import KFold #,RepeatedKFold\nfrom sklearn.metrics import mean_squared_error\n\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 18})\nplt.style.use('ggplot')\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\nSEED = 42","115917d3":"train = pd.read_csv(\"..\/input\/widsdatathon2022\/train.csv\")\ntest = pd.read_csv(\"..\/input\/widsdatathon2022\/test.csv\")\n\n# Shuffle train data\ntrain = train.sample(frac = 1, random_state = SEED).reset_index(drop = True)","e2651917":"target = train[\"site_eui\"]\ntrain = train.drop([\"site_eui\",\"id\"],axis =1)\ntest = test.drop([\"id\"],axis =1)","1af814c2":"# code copied from https:\/\/www.kaggle.com\/shrutisaxena\/wids2022-starter-code\n\n# year_built: replace with current year.\ntrain['year_built'] = train['year_built'].fillna(2022)\n#replacing rest of the values with mean\ntrain['energy_star_rating'] = train['energy_star_rating'].fillna(train['energy_star_rating'].mean())\ntrain['direction_max_wind_speed'] = train['direction_max_wind_speed'].fillna(train['direction_max_wind_speed'].mean())\ntrain['direction_peak_wind_speed'] = train['direction_peak_wind_speed'].fillna(train['direction_peak_wind_speed'].mean())\ntrain['max_wind_speed'] = train['max_wind_speed'].fillna(train['max_wind_speed'].mean())\ntrain['days_with_fog'] = train['days_with_fog'].fillna(train['days_with_fog'].mean())\n\n##for testdata\n\n# year_built: replace with current year.\ntest['year_built'] = test['year_built'].fillna(2022)\n#replacing rest of the values with mean\ntest['energy_star_rating'] = test['energy_star_rating'].fillna(test['energy_star_rating'].mean())\ntest['direction_max_wind_speed'] = test['direction_max_wind_speed'].fillna(test['direction_max_wind_speed'].mean())\ntest['direction_peak_wind_speed'] = test['direction_peak_wind_speed'].fillna(test['direction_peak_wind_speed'].mean())\ntest['max_wind_speed'] = test['max_wind_speed'].fillna(test['max_wind_speed'].mean())\ntest['days_with_fog'] = test['days_with_fog'].fillna(test['days_with_fog'].mean())","af20acde":"le = LabelEncoder()\n\ntrain['State_Factor']= le.fit_transform(train['State_Factor']).astype(\"uint8\")\ntest['State_Factor']= le.transform(test['State_Factor']).astype(\"uint8\")\n\ntrain['building_class']= le.fit_transform(train['building_class']).astype(\"uint8\")\ntest['building_class']= le.transform(test['building_class']).astype(\"uint8\")\n\ntrain['facility_type']= le.fit_transform(train['facility_type']).astype(\"uint8\")\ntest['facility_type']= le.transform(test['facility_type']).astype(\"uint8\")","09114403":"scaler = StandardScaler()\nX_train = pd.DataFrame(data=scaler.fit_transform(train), columns=train.columns)\nX_test = pd.DataFrame(data=scaler.transform(test), columns=test.columns)\n\nX_train.head()","682d78f8":"num_folds = 5\nkf = KFold(n_splits = num_folds, random_state = SEED)\nerror = 0\n\nfor i, (train_index, val_index) in enumerate(kf.split(X_train)):\n    train_X = X_train.loc[train_index]\n    val_X = X_train.loc[val_index]\n    train_y = target[train_index]\n    val_y = target[val_index]\n    \n    lgb_train = lgb.Dataset(train_X, train_y)\n    lgb_eval = lgb.Dataset(val_X , val_y)\n    \n    params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression',\n        'metric': {'rmse'},\n        'learning_rate': 0.1,\n        'feature_fraction': 0.8,\n        'bagging_fraction': 1.0,\n        'bagging_freq' : 0, \n        'force_row_wise' : True\n                         }\n    \n    model = lgb.train(params,\n                      lgb_train,\n                      num_boost_round = 2000,\n                      valid_sets = (lgb_train, lgb_eval),\n                      early_stopping_rounds = 20,\n                      verbose_eval = 50)\n\n    y_pred = (model.predict(val_X, num_iteration = model.best_iteration))\n    error += np.sqrt(mean_squared_error(y_pred, (val_y)))\/num_folds\n    print(f\"Fold {i+1} Validation RMSE: {np.sqrt(mean_squared_error(y_pred, (val_y)))}\")\n\nprint(f\"Mean Validation RMSE: {error}\")","93048c3d":"import shap","a6f50b42":"# Create Explainer and get shap_values\nexplainer = shap.TreeExplainer(model)\n#explainer = shap.Explainer(model, X_train)\nshap_values = explainer(X_train)\n\n#shap_values_2 = shap.TreeExplainer(model).shap_values(X_train)","b3162ccb":"print(f\"Shape of shap_values: {shap_values.shape}\\n\")\n\n# The shap_values object is the same shape as X_train\nprint(f\"The shap_values object is the same shape as X_train: {shap_values.shape == X_train.shape}\\n\")\n\nprint(f\"shap_values:\\n{shap_values}\\n\")\n\n# shap_values.data is the original X_train data\nprint(f\"shap_values.base_values ({pd.Series(shap_values.base_values).unique()}) is the average prediction for our model.\\nThe average prediction for X_train is: {model.predict(X_train).mean()}\\n\")\n\n# shap_values.data is the original X_train data\nprint(f\"shap_values.data is the original X_train data: {(shap_values.data == X_train.values).all()}\")","52379cde":"shap.summary_plot(shap_values, X_train)\n#shap.summary_plot(shap_values, X, plot_type=\"bar\")","bc1e9e0f":"display(X_train.loc[[0]])\nshap.plots.waterfall(shap_values[0])","c6fe46b5":"display(X_train.loc[[1]])\nshap.plots.waterfall(shap_values[1])","bff70de5":"# Init JS on Jupyter Notebook to display force_plot()\nshap.initjs()\n\nshap.force_plot(shap_values[0])#, X_train.iloc[0])\n","6c9f8670":"shap.plots.bar(shap_values)","c6a51254":"feature_imp = pd.DataFrame(sorted(zip(model.feature_importance(), train.columns),reverse = True), columns=['Value','Feature'])\nfeature_imp = feature_imp[feature_imp.Value != 0]\nplt.figure(figsize=(8, 8))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).head(10), color='salmon')\nplt.title('LightGBM Feature Importance')\nplt.tight_layout()\nplt.show()","7b07b397":"#shap.dependence_plot(\"energy_star_rating\", shap_values, X_train)","306fb22f":"sub = pd.read_csv(\"..\/input\/widsdatathon2022\/sample_solution.csv\")\nsub[\"site_eui\"] = model.predict(X_test)\nsub.to_csv(\"submission.csv\", index = False)\n\nsub","f5cf3ad4":"## Waterfall Plot\n\nWaterfall plots show how the SHAP values move the model prediction from the expected value E[f(X)] (`.base_values`; the average prediction for our model) to the predicted value f(x).\n\nLet's look at the first data point. The **expected value E[f(X)] is 79.761 (`.base_values` )** as shown on the x-axis. The **predicted value f(x) is 238.703** as shown in the top right corner.\nThe original `X_train` data point (`shap_values.data`) indicates the features and their corresponding values on the y-axis. E.g. `facility_type` = -1.11.\nFinally, SHAP values (`shap_values.values`) are displayed as red or blue arrows depending on whether they increase or decrease the predicted value. \n\nWe can see that `facility_type`, `energy_star_rating` and `building_class` have the biggest impacts. ","53a7511c":"The `shap_values` object is the same shape as `X_train`. It contains:\n* `.values`: the SHAP values themselves\n* `.base_values`: the average prediction for our model\n* `.data`: the original `X_train` data\n","d30d8643":"## Preprocessing","82bf6d67":"# Prediction and Submission","846643ec":"## Bar Plot","204913c0":"First, we need to create an `Explainer` object to get the SHAP values. In this case we will use the `TreeExplainer` object because we are using an LightGBM model.","36469fb2":"## Forceplot","baba7724":"# Introduction\n\nI recently came across this blog article [Shapley Values \u2013 A Gentle Introduction](https:\/\/www.h2o.ai\/blog\/shapley-values-a-gentle-introduction\/) on the \nH2O.ai blog, so I wanted to write a notebook to play around with Shapley values.\n","74d8c40a":"## Dependence Plot","b34e2beb":"## Work in progress...","ec354b48":"# References\n\n* [\ud83d\udd25\ud83d\udd25WiDS2022 LGBM Starter[W & B]\ud83d\udd25\ud83d\udd25](https:\/\/www.kaggle.com\/usharengaraju\/wids2022-lgbm-starter-w-b)\n* https:\/\/www.kaggle.com\/shrutisaxena\/wids2022-starter-code\n* [Shapley Values \u2013 A Gentle Introduction](https:\/\/www.h2o.ai\/blog\/shapley-values-a-gentle-introduction\/)\n* [SHAP documentation](https:\/\/shap.readthedocs.io\/en\/latest\/index.html)\n* https:\/\/towardsdatascience.com\/shap-shapley-additive-explanations-5a2a271ed9c3\n* https:\/\/towardsdatascience.com\/explain-your-model-with-the-shap-values-bc36aac4de3d","f8baa5ff":"# Baseline\n\nThe baseline for this notebook is forked from Usha's ([Tensor Girl](https:\/\/www.kaggle.com\/usharengaraju)) notebook [\ud83d\udd25\ud83d\udd25WiDS2022 LGBM Starter[W & B]\ud83d\udd25\ud83d\udd25](https:\/\/www.kaggle.com\/usharengaraju\/wids2022-lgbm-starter-w-b). \n\n## Load Data","7abef599":"## Model, Training and Validation","34b7d036":"## Summary Plot","bda90fbf":"# SHAP Values\n\n- Interpretability of AI models\n- > **SHAP (SHapley Additive exPlanations)** is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations). - [SHAP documentation](https:\/\/shap.readthedocs.io\/en\/latest\/index.html)\n- > The Shapley value tells us how much impact each element has on the prediction, or (more precisely) how much each feature moves the prediction away from the average prediction. - [Shapley Values \u2013 A Gentle Introduction](https:\/\/www.h2o.ai\/blog\/shapley-values-a-gentle-introduction\/)\n\nWe will use the `shap` library for this purpose.","3a721126":"SHAP bar plot vs. feature importance"}}