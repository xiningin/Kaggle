{"cell_type":{"6f387b5d":"code","a0ef068a":"code","04434cf3":"code","a9bd110f":"code","b7f5bd1f":"code","fc05d9cd":"code","17492276":"code","bfcad426":"code","a578a7c9":"code","4e955137":"code","8b712ad5":"code","1cc32d3a":"code","15a584ba":"code","f83f6622":"code","8c8d9838":"code","f25177df":"code","a16e994d":"code","4f562299":"code","9403713e":"code","72238f50":"code","992c2496":"markdown","0fd83d1b":"markdown","56a435ff":"markdown","335e3fef":"markdown","e77d04e8":"markdown","6fe4e2b9":"markdown","38051d47":"markdown","1b597bbf":"markdown","f189389f":"markdown"},"source":{"6f387b5d":"#Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\nimport time","a0ef068a":"#To ignore warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","04434cf3":"#Pulling the dataset\ndf = pd.read_csv(\"\/kaggle\/input\/spooky-author-identification\/train.zip\")","a9bd110f":"#To display the full text column instead of truncating one\npd.set_option('display.max_colwidth', -1)\n#To display a maximum of 100 columns\npd.set_option('display.max_columns',100)","b7f5bd1f":"df.head()","fc05d9cd":"df.shape","17492276":"#Retaining just first 100 records\ndf = df[:100]","bfcad426":"#Python provides a constant called string.punctuation that provides a great list of punctuation characters. \nprint(string.punctuation)","a578a7c9":"def remove_punctuations(input_col):\n    \"\"\"To remove all the punctuations present in the text.Input the text column\"\"\"\n    table = str.maketrans('','',string.punctuation)\n    return input_col.translate(table)","4e955137":"#Applying the remove_punctuation function\ndf['text'] = df['text'].apply(remove_punctuations)","8b712ad5":"!pip install git+https:\/\/github.com\/neomatrix369\/nlp_profiler.git@master","1cc32d3a":"#Importing the apply_text_profiling\nfrom nlp_profiler.core import apply_text_profiling","15a584ba":"#Applying on the text column of the dataframe\n#Official git mentions Pandas dataframe series as input param to be passed\nstart = time.time()\nprofiled_df = apply_text_profiling(df,'text')\nend = time.time()\ntotal_time = end - start \/ 60*60\nprint(\"Time taken(in secs) for the apply_text_profiling to run on 100 records: \",total_time)","f83f6622":"profiled_df.head(2)","8c8d9838":"profiled_df.columns","f25177df":"#Hist plot for the sentiment polarity for the first 100 sentences\nprofiled_df['sentiment_polarity'].hist()\nplt.title(\"Sentiment Polarity\")\nplt.show()","a16e994d":"#Subjective or Objective sentence\nprofiled_df['sentiment_subjectivity_summarised'].hist()\nplt.title(\"Sentiment Subjectivity\")\nplt.show()","4f562299":"#Histogram on the words_count\nprofiled_df['words_count'].hist()\nplt.title(\"Word Count Distribution with NLP_Profiler\")\nplt.show()","9403713e":"#Average stop word count with the sentences\nprofiled_df['stop_words_count'].mean()","72238f50":"sns.heatmap(profiled_df[['sentiment_polarity_score','sentiment_subjectivity_score']].corr(),annot=True,cmap='Blues')\nplt.title(\"Correlation Between Sentiment Polarity and Sentiment Subjectivity\")\nplt.xticks(rotation=45)\nplt.show()","992c2496":"Just a few minutes back, came across `Philip Vollet's` post on NLP Profiler who describes it has \n> **Simple NLP library that allows profiling datasets with one or more text columns. When given a dataset and a column name containing text data, NLP Profiler will return either high-level insights or low-level \/granular statistical information about the text in that column.**","0fd83d1b":"We can observe now what all features `apply_text_profiling` function as got!","56a435ff":"Pretty Much Subjective sentences!!!","335e3fef":"Sentiment Polarity, Subjectivity and spelling quality would be some great features to check on top of our text data.","e77d04e8":"We are having 19579 records in hand. We will try to cut short and go with just 100 records for our easiness.","6fe4e2b9":"I am yet to explore more on this and this is a very basic notebook that follows pretty much similar approach to the starter notebooks shared in the developer's page! <br>\n\nDo check out the Repo and the starter notebook here - [nlp_profiler](https:\/\/github.com\/neomatrix369\/nlp_profiler) and\n[Notebook](https:\/\/github.com\/neomatrix369\/nlp_profiler\/blob\/master\/notebooks\/google-colab\/nlp_profiler.ipynb)","38051d47":"#### Pip installing the NLP Profiler directly from the GitHub repo\n !pip install git+https:\/\/github.com\/neomatrix369\/nlp_profiler.git@master","1b597bbf":"OK! So apply_text_profiling is saying most of the sentences by spooky authors are pretty positive sentences! BTW dont forget we are running this just on 100 sentences, not the entire train set!! <b>\nI feel sentiment Polarity will surely help in getting a gist on the underlying data!","f189389f":"As per the developer repo, `NLP PROFILER` would be the describe() function for text data and pretty much more! <br>\nNLP Profiler will return either high-level insights or low-level\/granular statistical information about the dataframe text column. Ok thats cool!"}}