{"cell_type":{"1000ccb4":"code","22f5619f":"code","352ce456":"code","9b7dc491":"code","4c4f7d67":"code","9b1e1630":"code","1308be18":"code","ad10c66e":"code","61b2deb4":"code","8d269950":"code","4f730c96":"code","4cad487e":"code","f4dbc028":"code","e8fa991c":"code","626031e1":"code","0e3733a9":"code","db30c5ea":"code","2e50b818":"code","e4138d9e":"code","05e590be":"code","040b975f":"code","d041f931":"code","88066c2e":"markdown","d68fc8e1":"markdown","3af3db10":"markdown","898a4ed7":"markdown","9ca0f697":"markdown","59156db0":"markdown"},"source":{"1000ccb4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","22f5619f":"main_file_path1 = '..\/input\/application_train.csv' # this is the path to the training data that you will use\nATRdata = pd.read_csv(main_file_path1)\nATRdata.dtypes #shows the columns in the application_train.csv table with their corresponding data types\n","352ce456":"#selecting multiple columns from the applicaton_training dataframe\nATRcolumns_of_interest = ['NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE' ]\nATRcolumns_of_data = ATRdata[ATRcolumns_of_interest]\nprint(ATRcolumns_of_data)\nATRcolumns_of_data.describe() #displays the count, unique, top value and frequency for the columns of interest in the application_training.csv","9b7dc491":"main_file_path2 = '..\/input\/application_test.csv' # this is the path to the test data that you will use\nATdata = pd.read_csv(main_file_path2)\nATdata.dtypes #shows the columns in the application_test.csv table with their corresponding data types","4c4f7d67":"#selecting multiple columns from the applicaton_test dataframe\nATcolumns_of_interest = ['NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_HOUSING_TYPE' ]\nATcolumns_of_data = ATdata[ATcolumns_of_interest]\nprint(ATcolumns_of_data)\nATcolumns_of_data.describe() #displays the count, unique, top value and frequency for the columns of interest in the application_est.csv","9b1e1630":"import seaborn as sns #for seaborn plotting\nsns.jointplot(x='TARGET', y='DAYS_REGISTRATION', data=ATRdata[ATRdata['TARGET'] < 100000]) #jointplot for TARGET (dependent variable) and DAYS_REGISTRATION  (independent variable) for scatter graph and histogram","1308be18":"import seaborn as sns #for seaborn plotting\nBx = ATRdata[ATRdata.NAME_EDUCATION_TYPE.isin(ATRdata.NAME_EDUCATION_TYPE.value_counts().head(3).index)]\n\nsns.boxplot(\n    x='NAME_EDUCATION_TYPE',\n    y='DAYS_REGISTRATION',\n    data=Bx\n) #box plot for education type and days of registration","ad10c66e":"ATRdata.head(5)","61b2deb4":"from sklearn.tree import DecisionTreeRegressor # used to make predictions from certain data\n#factors that will predict the TARGET\ndesired_factors = ['DAYS_REGISTRATION','AMT_INCOME_TOTAL', 'CNT_CHILDREN', 'DAYS_ID_PUBLISH','DAYS_EMPLOYED','DAYS_BIRTH']\n\n#set my model to DecisionTree\nmodel1 = DecisionTreeRegressor()\n\n#set prediction data to factors that will predict, and set target to TARGET\ntrain_data = ATRdata[desired_factors]\ntest_data = ATdata[desired_factors]\ntarget = ATRdata.TARGET\n\n#fitting model with prediction data and telling it my target for the application_test.csv data\nmodel1.fit(train_data, target)\n\nmodel1.predict(test_data)","8d269950":"submission1 = pd.DataFrame({'SK_ID_CURR': ATdata.SK_ID_CURR ,'TARGET': model1.predict(test_data)})\n\nsubmission1.to_csv('submission1.csv', index=False)","4f730c96":"main_file_path3 = '..\/input\/bureau.csv' # this is the path to the test data that you will use\nBdata = pd.read_csv(main_file_path3)\nBdata.head() #shows the first 5 rows of the dataset bureau.csv","4cad487e":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go #for plotly graphs\ndtt = Bdata.head(800).assign(n=0).groupby(['DAYS_CREDIT_UPDATE', 'DAYS_CREDIT'])['n'].count().reset_index()\ndtt = dtt[dtt[\"DAYS_CREDIT\"] < 2000]\nver = dtt.pivot(index='DAYS_CREDIT', columns='DAYS_CREDIT_UPDATE', values='n').fillna(0).values.tolist()\niplot([go.Surface(z=ver)])\n#plotly Surface (the most impressive feature)\n#shows the distribution of days of credit against daus of credit update","f4dbc028":"from plotnine import * #plotline graphs\n\n#shows the most common credit types according to the days of credit\n(ggplot(Bdata.head(50))\n         + aes('DAYS_CREDIT', 'CREDIT_TYPE')\n         + geom_bin2d(bins=20)\n         + ggtitle(\"common credit types according to the days of credit\")\n)\n#The plotnine equivalent of a hexplot, a two-dimensional histogram, is geom_bin2d","e8fa991c":"x_train = ATRdata['NAME_EDUCATION_TYPE']\nx_test = ATdata['NAME_EDUCATION_TYPE']\ny=ATRdata['TARGET']\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntext_clf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,10), max_features=10000, lowercase=True, use_idf=True, smooth_idf=True, sublinear_tf=False, tokenizer=TweetTokenizer().tokenize, stop_words='english')),\n                         ('clf', LogisticRegression(random_state=17, C=1.8))])\nfrom sklearn.model_selection import RandomizedSearchCV\nparameters = {\n               'clf__C': np.logspace(.1,1,10),\n }\ngs = RandomizedSearchCV(text_clf, parameters, n_jobs=-1, verbose=3)\ntext_clf.fit(x_train, y)\npredicted = text_clf.predict(x_test)\nATdata['TARGET'] = predicted","626031e1":"submission2 = ATdata[[\"SK_ID_CURR\",\"TARGET\"]]\nsubmission2.to_csv(\"submission2.csv\", index = False)","0e3733a9":"from plotnine import * #plotline graphs\ndta5 = ATRdata.head(1000)\n\n(ggplot(dta5)\n     + aes('TARGET', 'DAYS_REGISTRATION')\n     + aes(color='TARGET')\n     + geom_point()\n     + stat_smooth()\n     + facet_wrap('NAME_EDUCATION_TYPE')\n)\n#applying faceting with the categorical variable NAME_EDUCATION_TYPE","db30c5ea":"from plotnine import * #plotline graphs\ndta4 = ATRdata.head(1000)\n\n(\n    ggplot(dta4)\n        + aes('DAYS_REGISTRATION', 'DAYS_ID_PUBLISH')\n        + geom_point()\n        + aes(color='DAYS_REGISTRATION')\n        + stat_smooth()\n)\n#plots a line of best fit (logistic regression) along the scatter graph with coloured points","2e50b818":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go #for plotly graphs\n\niplot([go.Scatter(x=ATRdata.head(1000)['DAYS_REGISTRATION'], y=ATRdata.head(1000)['DAYS_ID_PUBLISH'], mode='markers')])\n#basic plotly scatter graph","e4138d9e":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go #for plotly graphs\n\niplot([go.Histogram2dContour(x=ATRdata.head(500)['DAYS_REGISTRATION'], \n                             y=ATRdata.head(500)['DAYS_ID_PUBLISH'], \n                             contours=go.Contours(coloring='heatmap')),\n       go.Scatter(x=ATRdata.head(1000)['DAYS_REGISTRATION'], y=ATRdata.head(1000)['DAYS_ID_PUBLISH'], mode='markers')])\n# KDE plot (what plotly refers to as a Histogram2dContour) and scatter plot of the same data.","05e590be":"import seaborn as sns\n\nsns.lmplot(x='DAYS_REGISTRATION', y='DAYS_ID_PUBLISH',  markers=['o', 'x', '*'], hue='NAME_EDUCATION_TYPE', \n           data=ATRdata.loc[ATRdata['NAME_EDUCATION_TYPE'].isin(['Higher education', 'Lower secondary', 'Incomplete higher'])], \n           fit_reg=False)\n#multivariate scatter plot with markers","040b975f":"model1.predict(test_data)","d041f931":"submission3 = pd.DataFrame({'SK_ID_CURR': ATdata.SK_ID_CURR ,'TARGET': model1.predict(test_data)})\n\nsubmission3.to_csv('submission3.csv', index=False)","88066c2e":"**second part**\n\nIn this section, the categorical variable NAME_EDUCATION_TYPE is used to predict the TARGET using encoding. Likewise, the 3D correlation between DAYS_CREDIT_UPDATE and DAYS_CREDIT is revealed through the plotly surface.\n\nSimilarly, this section also reveals the common credit types according to the days of credit using plotnine.","d68fc8e1":"**third part**\n\nContains even more data visualisations and predictions","3af3db10":"box plot shows that on average, higher DAYS_REGISTRATION is due to the the fact that the customer could possibly have a higher education","898a4ed7":"seaborn plot shows that for a target, days of DAYS_REGISTRATION must be greater that- 20000","9ca0f697":"**Introduction**\nThis notebook is divided into 3 parts:\n\nfirst part \n\nsecond part\n\nthird part\n\n","59156db0":"**first part**\n\nIn this section, predictions based on the target for the application_test file will be made, based on predictors from the application_test file. Descriptions of each of the 2 files will also be executes. Likewise, the correlation between target and days of registration will be shown along with relationship between education type and days of registration. "}}