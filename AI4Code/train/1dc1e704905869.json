{"cell_type":{"b7f5244d":"code","ce5400b3":"code","4043217b":"code","b1661b3a":"code","20162347":"code","e7965afa":"code","32bf236d":"code","c1817690":"code","14ea26e0":"code","7ee77dca":"code","6e1ba3a7":"code","d1736f56":"code","facaeb9e":"code","0bd1e400":"code","b34befef":"code","6be219d6":"code","ecdd2ce7":"code","ca05ffec":"code","8076c6bd":"code","0a69e472":"code","285eb81e":"code","146c3768":"code","89becf08":"code","2a19aa16":"code","a8132d4d":"code","b3548dcc":"code","19c64727":"code","6fd57be4":"code","3729d202":"code","0ecc0df6":"code","792c084c":"code","5cabd2bf":"code","6def289c":"code","d43d1c25":"code","e648e186":"code","6609684f":"code","02e1f16b":"code","a60e16f0":"code","bb4aaf96":"code","bc581dd4":"code","0924a876":"code","c1255d97":"code","f15deb18":"code","43a420f3":"code","0f48a233":"code","af42d5aa":"code","60cb2b01":"code","fd176ba7":"code","076af716":"code","17262032":"code","2a00e743":"code","96d2307e":"code","46bac563":"code","025ca444":"code","20f9314b":"code","8f8853cd":"code","0941514b":"code","35055518":"code","34de11d3":"code","ff792c5f":"code","8313857d":"code","dc48bc3d":"code","df5c4c31":"code","bfd7f6cf":"code","617ffa26":"code","8c61cddf":"code","6c722e55":"code","c837cb14":"code","a3b53242":"code","bf82c1d7":"code","29547fcb":"code","141769d5":"code","259b087e":"markdown","2879ddbe":"markdown","ff852f0f":"markdown","e610894c":"markdown","16d201e8":"markdown","6048899c":"markdown","44b9e6db":"markdown","84e26cba":"markdown","79d495dc":"markdown","d7be954a":"markdown","0877e67e":"markdown","6d3054aa":"markdown","f311b7de":"markdown","4d5bf7ae":"markdown","987f1010":"markdown","b065227a":"markdown","3fd7b6d8":"markdown","70ceb4e6":"markdown","06aeb24a":"markdown","276683fd":"markdown","599a3122":"markdown","e633f9c7":"markdown","bf915e57":"markdown","f6d84eb3":"markdown","e7dc0051":"markdown","5e9e0bde":"markdown","a8d14d12":"markdown","2b4fb823":"markdown","f787a2f4":"markdown","127fb3f6":"markdown","40520348":"markdown","083272c8":"markdown","c42fbe4b":"markdown","0d726c1c":"markdown","e44a5978":"markdown","dfb31e44":"markdown","d132745c":"markdown","f5b4bc5a":"markdown","f688b8e9":"markdown","d09415e2":"markdown","1dd8336f":"markdown"},"source":{"b7f5244d":"from IPython.utils import io\nwith io.capture_output() as captured:\n    !pip install scispacy\n    !pip install https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_lg-0.2.4.tar.gz\n    !pip install pyvis","ce5400b3":"import numpy as np \nimport pandas as pd\n\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nimport scispacy\nimport spacy\nimport en_core_sci_lg\n\nfrom scipy.spatial.distance import jensenshannon\n\nimport joblib\n\nfrom IPython.display import HTML, display\n\nfrom ipywidgets import interact, Layout, HBox, VBox, Box\nimport ipywidgets as widgets\nfrom IPython.display import clear_output\n\nfrom tqdm import tqdm\nfrom os.path import isfile\n\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\nplt.style.use(\"dark_background\")\n\n\nfrom pyvis import network as net\nimport networkx as nx\n\nimport textwrap\n","4043217b":"df = pd.read_csv('..\/input\/cord-19-create-dataframe\/cord19_df.csv')","b1661b3a":"df.head()","20162347":"df.dtypes","e7965afa":"df['source'].value_counts()","32bf236d":"df.dtypes","c1817690":"citation_df = pd.read_csv('..\/input\/covid19-for-citation-networks\/network_all_datasets.csv')\ncitation_df.dropna(inplace = True)\ncitation_df.drop_duplicates(inplace = True)\ndel citation_df['Unnamed: 0']","14ea26e0":"citation_df.sample(10)","7ee77dca":"citation_df['cited_article'].describe()","6e1ba3a7":"citation_df['cited_article'].describe().top","d1736f56":"mers_articles = citation_df[citation_df['cited_article'] == 'Isolation of a novel coronavirus from a man with pneumonia in Saudi Arabia'].copy()\n","facaeb9e":"mers_articles","0bd1e400":"to_graph_mers = mers_articles[mers_articles['cited_article'] == 'Isolation of a novel coronavirus from a man with pneumonia in Saudi Arabia']","b34befef":"#mean = mers_articles['cited_article'].value_counts().describe()['mean']\n#to_graph_mers = mers_articles[mers_articles.groupby('cited_article')['cited_article'].transform('size') > (mean)]\n#to_graph_mers = to_graph_mers[to_graph_mers['source_article'].isin(list(to_graph_mers['cited_article']))]","6be219d6":"#to_graph_mers","ecdd2ce7":"covid_articles = list(df[df['is_covid19'] == True]['title'])\ncovid_hop = citation_df[citation_df['source_article'].isin(covid_articles)]\n\nall_relevant_mers_articles = list(to_graph_mers['source_article']) + list(to_graph_mers['cited_article'])\n\n\ncovid_hop = covid_hop[covid_hop['cited_article'].isin(all_relevant_mers_articles)]","ca05ffec":"covid_hop","8076c6bd":"saudi_arabia_g = net.Network(height = 1000, width = 1000, directed = True, notebook = True)\n\n\nfor item in to_graph_mers.iterrows():\n    data = item[1]\n\n    saudi_arabia_g.add_node(data['source_article'], label = item[0], title = data['source_article'],color = 'orange') \n\n    \n    saudi_arabia_g.add_node(data['cited_article'], label = item[0], title = data['cited_article'],color = 'orangered') \n   \n    saudi_arabia_g.add_edge(data['source_article'], data['cited_article'])\n        \nfor item in covid_hop.iterrows():\n    data = item[1]\n\n    saudi_arabia_g.add_node(data['source_article'], label = item[0], title = data['source_article'],color = 'orchid') \n\n    \n    saudi_arabia_g.add_node(data['cited_article'], label = item[0], title = data['cited_article'],color = 'violet') \n   \n    saudi_arabia_g.add_edge(data['source_article'], data['cited_article'])\nsaudi_arabia_g.barnes_hut(gravity=-5000, central_gravity=0, spring_length=200, spring_strength=0.009, damping=0.025, overlap=0)\n    ","0a69e472":"saudi_arabia_g.show('MERS_COVID19_Connections_Graph.html')","285eb81e":"saudi_arabia_html_g = net.Network(height = 1000, width = 1000, directed = True)\n\n\nfor item in to_graph_mers.iterrows():\n    data = item[1]\n\n    saudi_arabia_html_g.add_node(data['source_article'], label = item[0], title = data['source_article'],color = 'orange') \n\n    \n    saudi_arabia_html_g.add_node(data['cited_article'], label = item[0], title = data['cited_article'],color = 'orangered') \n   \n    saudi_arabia_html_g.add_edge(data['source_article'], data['cited_article'])\n        \nfor item in covid_hop.iterrows():\n    data = item[1]\n\n    saudi_arabia_html_g.add_node(data['source_article'], label = item[0], title = data['source_article'],color = 'orchid') \n\n    \n    saudi_arabia_html_g.add_node(data['cited_article'], label = item[0], title = data['cited_article'],color = 'violet') \n   \n    saudi_arabia_html_g.add_edge(data['source_article'], data['cited_article'])\n    \n\nsaudi_arabia_html_g.show_buttons(filter_=['nodes','edges', 'physics'])\nsaudi_arabia_html_g.show('HTML_MERS_COVID19_Connections_Graph.html')\n","146c3768":"#filter citation data to only use citations for available articles in the metadata\ncitation_df = citation_df[citation_df['source_article'].isin(df['title'])]","89becf08":"citation_df.reset_index(inplace = True)","2a19aa16":"del citation_df['index']","a8132d4d":"citation_df.head()","b3548dcc":"#create a separate, smaller dataframe containing both source and cited articles in the covid19_df. \nin_metadata_citation_df = citation_df[citation_df['cited_article'].isin(df['title'])].copy()","19c64727":"in_metadata_citation_df.reset_index(inplace = True)","6fd57be4":"del in_metadata_citation_df['index']","3729d202":"in_metadata_citation_df","0ecc0df6":"#add the pre-publication articles (many of which will be more recent as COVID19 articles are being rapidly submitted to journals)\n#recent_covid_articles = df[df['source']['biorxiv', 'medrxiv']]['title']\n\n\n\nrecent_covid_articles = df[df['publish_year'].isin([2019, 2020])]['title']\n\n\n\n#add any articles that have been published from 2019-present\nrecent_covid_articles.append(df[df['publish_year'].isin([2019, 2020])]['title'])\n\n\nrecent_covid_df = in_metadata_citation_df[in_metadata_citation_df['cited_article'].isin(recent_covid_articles)].copy()\n\n\nrecent_covid_df = recent_covid_df.append(in_metadata_citation_df[in_metadata_citation_df['source_article'].isin(recent_covid_articles)].copy())\nrecent_covid_df.drop_duplicates(inplace = True)\nrecent_covid_df.dropna(inplace = True)","792c084c":"recent_covid_df.reset_index(inplace = True)","5cabd2bf":"del recent_covid_df['index']","6def289c":"recent_covid_df","d43d1c25":"recent_covid_df['cited_article'].describe(), recent_covid_df['source_article'].describe() ","e648e186":"recent_covid_df['cited_article'].value_counts().describe()","6609684f":"mean = recent_covid_df['cited_article'].value_counts().describe()['mean']\ngraph_to_plot = recent_covid_df[recent_covid_df.groupby('cited_article')['cited_article'].transform('size') > (mean)]\ngraph_to_plot","02e1f16b":"graph_to_plot['title'] = graph_to_plot['source_article']\nmerged_graph_to_plot = pd.merge(graph_to_plot, df, on = 'title')\nmerged_graph_to_plot.drop_duplicates(inplace = True)","a60e16f0":"merged_graph_to_plot.cited_article_year.replace('None', np.nan, inplace=True)\nmerged_graph_to_plot.cited_article_year.fillna(value = 2020, inplace=True)\nmerged_graph_to_plot.publish_year.fillna(value = 2020, inplace=True)","bb4aaf96":"merged_graph_to_plot.head()","bc581dd4":"notebook_display_g = net.Network(height = 1000, width = 1000, directed = True,notebook = True)\nhtml_link_g = net.Network(height = 1000, width = 1000, directed = True)\n\n\nfor item in merged_graph_to_plot.iterrows():\n\n    data = item[1]\n    \n    \n    #color code nodes according to whether or not they are a paper about the COVID-19\n    if data['is_covid19']:\n        sourceNodeColor = \"lightcoral\"\n    else:\n        sourceNodeColor = \"lightskyblue\"\n    \n    #create node with an HTML-formatted \"Title\" containing information about each node (citing an article)\n    source_html_title = '<a href=\"' + data['url'] + '\" target=\"_blank\">'+ data['source_article'] + '<\/a>' + \"<p><b>Year Published or Submitted:<\/b><\/p> {0}<p><b>Authors:<\/b><\/p>{1}<p><b>Abstract:<\/b><\/p>{2}\".format(data['publish_year'], data['authors'], data['abstract'])   \n    notebook_display_g.add_node(data['source_article'], label = item[0], title = data['source_article'],color = sourceNodeColor) \n    \n    html_link_g.add_node(data['source_article'], label = item[0], title = source_html_title,color = sourceNodeColor)\n    \n\n    \n    cited_color = df[df['title'] == data['cited_article']].iloc[0]['is_covid19']\n    \n    if cited_color:\n        citeNodeColor = \"darkred\"\n    else:\n        citeNodeColor = \"darkblue\"\n        \n    cited_url = df[df['title'] == data['cited_article']].iloc[0]['url']\n    cited_date = df[df['title'] == data['cited_article']].iloc[0]['publish_year']\n    cited_authors = df[df['title'] == data['cited_article']].iloc[0]['authors']\n    cited_abstract = df[df['title'] == data['cited_article']].iloc[0]['abstract']\n    \n    \n    #create node with an HTML-formatted \"Title\" containing information about each node (an article being cited)\n    cited_html_title = '<a href=\"' + cited_url + '\" target=\"_blank\">'+ data['cited_article'] + '<\/a>' + \"<p><b>Year Published or Submitted:<\/b><\/p> {0}<p><b>Authors:<\/b><\/p>{1}<p><b>Abstract:<\/b><\/p>{2}\".format(cited_date, cited_authors, cited_abstract)\n    notebook_display_g.add_node(data['cited_article'], label = item[0], title = data['cited_article'], color = citeNodeColor)\n    html_link_g.add_node(data['cited_article'], label = item[0], title = cited_html_title, color = citeNodeColor)\n    \n    \n    \n    \n    notebook_display_g.add_edge(data['source_article'], data['cited_article'])\n    html_link_g.add_edge(data['source_article'], data['cited_article'])\n    \n   \n\n    \n    \nnotebook_display_g.barnes_hut(gravity=-5000, central_gravity=0, spring_length=200, spring_strength=0.009, damping=0.025, overlap=0)\nhtml_link_g.barnes_hut(gravity=-5000, central_gravity=0, spring_length=200, spring_strength=0.009, damping=0.025, overlap=0)\nhtml_link_g.show_buttons(filter_=['nodes','edges', 'physics'])\n\nhtml_link_g.show('COVID19_Graph_Interactive.html')","0924a876":"notebook_display_g.show('COVID19_Notebook_Graph.html')","c1255d97":"all_texts = df.body_text","f15deb18":"# example snippet\nall_texts[0][:500]","43a420f3":"# medium model\nnlp = en_core_sci_lg.load(disable=[\"tagger\", \"parser\", \"ner\"])\nnlp.max_length = 2000000","0f48a233":"def spacy_tokenizer(sentence):\n    return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)]","af42d5aa":"# New stop words list \ncustomize_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', 'al.', 'Elsevier', 'PMC', 'CZI',\n    '-PRON-'\n]\n\n# Mark them as stop words\nfor w in customize_stop_words:\n    nlp.vocab[w].is_stop = True","60cb2b01":"filepath = '..\/input\/topic-modeling-finding-related-articles\/'","fd176ba7":"#vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, min_df=2)\n#data_vectorized = vectorizer.fit_transform(tqdm(all_texts))","076af716":"#data_vectorized.shape","17262032":"# vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, max_features=800000)\n# data_vectorized = vectorizer.fit_transform(tqdm(all_texts))","2a00e743":"# data_vectorized.shape # with bigrams: 6428134\n\n# data_vectorized.shape # all 1.2 mio?","96d2307e":"# most frequent words\n#word_count = pd.DataFrame({'word': vectorizer.get_feature_names(), 'count': np.asarray(data_vectorized.sum(axis=0))[0]})\n\n#word_count.sort_values('count', ascending=False).set_index('word')[:20].sort_values('count', ascending=True).plot(kind='barh')","46bac563":"#joblib.dump(vectorizer, 'vectorizer.csv')\n#joblib.dump(data_vectorized, 'data_vectorized.csv')","025ca444":"if not (isfile(filepath + 'vectorizer.csv') & isfile(filepath + 'data_vectorized.csv')):\n    print('Files not there: generating')\n    vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, max_features=800000)\n    data_vectorized = vectorizer.fit_transform(tqdm(all_texts))\n    joblib.dump(vectorizer, 'vectorizer.csv')\n    joblib.dump(data_vectorized, 'data_vectorized.csv')\n\nelse:\n    vectorizer = joblib.load(filepath + 'vectorizer.csv')\n    data_vectorized = joblib.load(filepath + 'data_vectorized.csv')","20f9314b":"#lda = LatentDirichletAllocation(n_components=50, random_state=0)\n#lda.fit(data_vectorized)\n#joblib.dump(lda, 'lda.csv')","8f8853cd":"# # Train\/Load Model\nif not (isfile(filepath + 'lda.csv')):\n    print('File not there: generating')\n    lda = LatentDirichletAllocation(n_components=50, random_state=0)\n    lda.fit(data_vectorized)\n\n    joblib.dump(lda, 'lda.csv')\n\nelse:\n    lda = joblib.load(filepath + 'lda.csv') ","0941514b":"def print_top_words(model, vectorizer, n_top_words):\n    feature_names = vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        message = \"\\nTopic #%d: \" % topic_idx\n        message += \" \".join([feature_names[i]\n                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n        print(message)\n    print()","35055518":"print_top_words(lda, vectorizer, n_top_words=25)","34de11d3":"#doc_topic_dist = pd.DataFrame(lda.transform(data_vectorized))\n#doc_topic_dist.to_csv('doc_topic_dist.csv', index=False)","ff792c5f":"if not (isfile(filepath + 'doc_topic_dist.csv')):\n    print('File not there: generating')\n    doc_topic_dist = pd.DataFrame(lda.transform(data_vectorized))\n    doc_topic_dist.to_csv('doc_topic_dist.csv', index=False)\nelse:\n    doc_topic_dist = pd.read_csv(filepath + 'doc_topic_dist.csv')  ","8313857d":"doc_topic_dist[df.paper_id == '90b5ecf991032f3918ad43b252e17d1171b4ea63']\n","dc48bc3d":"is_covid19_article = df.body_text.str.contains('COVID-19|SARS-CoV-2|2019-nCov|SARS Coronavirus 2|2019 Novel Coronavirus')","df5c4c31":"def get_k_nearest_docs(doc_dist, k=5, lower=1950, upper=2020, only_covid19=False, get_dist=False):\n    '''\n    doc_dist: topic distribution (sums to 1) of one article\n    \n    Returns the index of the k nearest articles (as by Jensen\u2013Shannon divergence in topic space). \n    '''\n    \n    relevant_time = df.publish_year.between(lower, upper)\n    \n    if only_covid19:\n        temp = doc_topic_dist[relevant_time & is_covid19_article]\n        \n        #print(temp)\n        \n    else:\n        temp = doc_topic_dist[relevant_time]\n        #print(temp)\n         \n    distances = temp.apply(lambda x: jensenshannon(x, doc_dist), axis=1)\n    k_nearest = distances[distances != 0].nsmallest(n=k).index\n    #print(k_nearest)\n    \n    if get_dist:\n        k_distances = distances[distances != 0].nsmallest(n=k)\n        return k_nearest, k_distances\n    else:\n        return k_nearest","bfd7f6cf":"d = get_k_nearest_docs(doc_topic_dist[df.paper_id == '90b5ecf991032f3918ad43b252e17d1171b4ea63'].iloc[0])\n\n#sb.kdeplot(d)","617ffa26":"def plot_article_dna(paper_id, width=20):\n    t = df[df.paper_id == paper_id].title.values[0]\n    doc_topic_dist[df.paper_id == paper_id].T.plot(kind='bar', legend=None, title=t, figsize=(width, 4))\n    plt.xlabel('Topic')\n\ndef compare_dnas(paper_id, recommendation_id, width=20):\n    t = df[df.paper_id == recommendation_id].title.values[0]\n    temp = doc_topic_dist[df.paper_id == paper_id]\n    ymax = temp.max(axis=1).values[0]*1.25\n    temp = pd.concat([temp, doc_topic_dist[df.paper_id == recommendation_id]])\n    temp.T.plot(kind='bar', title=t, figsize=(width, 4), ylim= [0, ymax])\n    plt.xlabel('Topic')\n    plt.legend(['Selection', 'Recommendation'])\n\n# compare_dnas('90b5ecf991032f3918ad43b252e17d1171b4ea63', 'a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a')\n\ndef dna_tabs(paper_ids):\n    k = len(paper_ids)\n    outs = [widgets.Output() for i in range(k)]\n\n    tab = widgets.Tab(children = outs)\n    tab_titles = ['Paper ' + str(i+1) for i in range(k)]\n    for i, t in enumerate(tab_titles):\n        tab.set_title(i, t)\n    display(tab)\n\n    for i, t in enumerate(tab_titles):\n        with outs[i]:\n            ax = plot_article_dna(paper_ids[i])\n            plt.show(ax)\n\ndef compare_tabs(paper_id, recommendation_ids):\n    k = len(recommendation_ids)\n    outs = [widgets.Output() for i in range(k)]\n\n    tab = widgets.Tab(children = outs)\n    tab_titles = ['Paper ' + str(i+1) for i in range(k)]\n    for i, t in enumerate(tab_titles):\n        tab.set_title(i, t)\n    display(tab)\n\n    for i, t in enumerate(tab_titles):\n        with outs[i]:\n            ax = compare_dnas(paper_id, recommendation_ids[i])\n            plt.show(ax)","8c61cddf":"def recommendation(paper_id, k=5, lower=1950, upper=2020, only_covid19=False, plot_dna=False):\n    '''\n    Returns the title of the k papers that are closest (topic-wise) to the paper given by paper_id.\n    '''\n    \n    #print(df.title[df.paper_id == paper_id].values[0])\n\n    recommended, dist = get_k_nearest_docs(doc_topic_dist[df.paper_id == paper_id].iloc[0], k, lower, upper, only_covid19, get_dist=True)\n    recommended = df.iloc[recommended].copy()\n    recommended['similarity'] = 1 - dist\n    \n    h = '<br\/>'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n + '<\/a>' +' (Similarity: ' + \"{:.2f}\".format(s) + ')' for l, n, s in recommended[['url','title', 'similarity']].values])\n    display(HTML(h))\n    \n  \n    if plot_dna:\n        compare_tabs(paper_id, recommended.paper_id.values)\n \n    return recommended","6c722e55":"\"\"\"\nGiven a dataframe of recommended articles (including their metadata),\nretrieve citations associated with these papers and build and return a dataframe of citations\n\"\"\"\n\n\ndef recommended_paper_citation_network(df_recommended):\n    #get all of the articles cited by the recommended papers\n    recommended_citations = in_metadata_citation_df[in_metadata_citation_df['source_article'].isin(df_recommended['title'])]\n    \n    # who is citing the same papers as the recommended papers?\n    other_source_papers = in_metadata_citation_df[in_metadata_citation_df['cited_article'].isin(recommended_citations['cited_article'])]\n  \n\n    #who are the cited papers citing?\n    second_network_hop = in_metadata_citation_df[in_metadata_citation_df['cited_article'].isin(recommended_citations['source_article'])]\n\n\n    #who is citing the recommended papers themselves?\n    citing_the_recommended = in_metadata_citation_df[in_metadata_citation_df['cited_article'].isin(df_recommended['title'])]\n\n\n    #append all of the dataframes together\n    recommended_citations = recommended_citations.append(other_source_papers)\n    recommended_citations = recommended_citations.append(second_network_hop)\n    recommended_citations = recommended_citations.append(citing_the_recommended)\n    recommended_citations.drop_duplicates(inplace = True)\n    recommended_citations.dropna(inplace = True)\n    \n    return recommended_citations\n\n","c837cb14":"\"\"\"\nGiven the title of the paper, use the covid_df to assign both source and cited nodes a color\nNodes that have been recommended should be given a separate color\nOther nodes are color-coded according to whether or not they mention the Covid19\n\n\"\"\"\n\ndef assign_source_node_color(source_node_name, master_metadata_df, recommended_df):\n    #print(\"Node name: \", source_node_name)\n    #print(master_metadata_df[master_metadata_df['title'] == source_node_name])\n    covid_node = master_metadata_df[master_metadata_df['title'] == source_node_name].iloc[0]['is_covid19']\n    #covid_node = master_metadata_df[master_metadata_df['title'] == source_node_name].loc['is_covid19']\n    if source_node_name in list(recommended_df['title']):\n        #print('NODE SHOULD BE GREEN')\n        #print(source_node_name)\n        sourceNodeColor = \"palegreen\"    \n    elif covid_node:\n        sourceNodeColor = \"lightcoral\"\n    else:\n        sourceNodeColor = \"lightskyblue\"\n    return sourceNodeColor\n        \n        \ndef assign_cited_node_color(cited_node_name, master_metadata_df, recommended_df):\n    \n    #print(\"Node name: \", cited_node_name)\n    #print(master_metadata_df[master_metadata_df['title'] == cited_node_name])\n    covid_node = master_metadata_df[master_metadata_df['title'] == cited_node_name].iloc[0]['is_covid19']\n    #covid_node = master_metadata_df[master_metadata_df['title'] == cited_node_name].loc['is_covid19']    \n    \n    if cited_node_name in list(recommended_df['title']):\n        #print('NODE SHOULD BE GREEN')\n        #print(cited_node_name)\n        citedNodeColor = \"palegreen\"    \n    elif covid_node:\n        citedNodeColor = \"darkred\"\n    else:\n        citedNodeColor = \"darkblue\"\n    \n    return citedNodeColor","a3b53242":"\"\"\"\nGiven the title of the paper, use the covid_df to create an HTML 'title', such that,\nwhen a user uploads a network graph as an HTML file, they can click on nodes and see\nbasic information about the papers, as well as a link to click on and read the full paper\n\n\"\"\"\n\ndef create_HTML_Title(node_name, master_metadata_df, recommended_df):\n    \n    #get all of the paper needed to make the HTML element\n    url = master_metadata_df[master_metadata_df['title'] == node_name].iloc[0]['url']\n    date = master_metadata_df[master_metadata_df['title'] == node_name].iloc[0]['publish_year']\n    authors = master_metadata_df[master_metadata_df['title'] == node_name].iloc[0]['authors']\n    abstract = master_metadata_df[master_metadata_df['title'] == node_name].iloc[0]['abstract']\n    \n    if node_name in list(recommended_df['title']):\n        similarity_value = recommended_df[recommended_df['title'] == node_name].iloc[0]['similarity']\n        html_title = '<a href=\"' + url + '\" target=\"_blank\">'+ node_name + '<\/a>' + \"<p><b>Similarity:<\/b><\/p> {0}<p><b>Year Published or Submitted:<\/b><\/p> {1}<p><b>Authors:<\/b><\/p>{2}<p><b>Abstract:<\/b><\/p>{3}\".format(similarity_value, date, authors, abstract) \n        \n    else:\n        html_title = '<a href=\"' + url + '\" target=\"_blank\">'+ node_name + '<\/a>' + \"<p><b>Year Published or Submitted:<\/b><\/p> {0}<p><b>Authors:<\/b><\/p>{1}<p><b>Abstract:<\/b><\/p>{2}\".format(date, authors, abstract)\n        \n    return html_title","bf82c1d7":"def create_network_graph(citation_df, covid_df, recommended_by_function):\n    \n    #citation_df: the small df of every cited\/citing article that will be graphed\n    #covid_df: the covid19 df\n    #recommended_by_function: the df returned by the \"recommendation(...)\" function\n    \n    \n    function_recc_notebook_display_g = net.Network(height = 1000, width = 1000, directed = True,notebook = True)\n    function_recc_html_link_g = net.Network(height = 1000, width = 1000, directed = True)\n    \n    \n    for item in citation_df.iterrows():\n        data = item[1]\n        \n        #define source_node_color\n        color_source = assign_source_node_color(data['source_article'], covid_df, recommended_by_function)\n        #print(data['source_article'], color_source)]    \n        \n        #create HTML 'title' for source node\n        source_html = create_HTML_Title(data['source_article'], covid_df, recommended_by_function)  \n        \n        #add source nodes\n        function_recc_notebook_display_g.add_node(data['source_article'], label = item[0], title = data['source_article'],color = color_source) \n        function_recc_html_link_g.add_node(data['source_article'], label = item[0], title = source_html,color = color_source)\n    \n\n        #define cited_node_color\n        color_cited = assign_cited_node_color(data['cited_article'], covid_df, recommended_by_function)\n        #print(data['cited_article'], color_cited)\n        \n        #define create HTML 'title' for cited node\n        cited_html = create_HTML_Title(data['cited_article'], covid_df, recommended_by_function)\n        \n        \n        #add cited node\n        function_recc_notebook_display_g.add_node(data['cited_article'], label = item[0], title = data['cited_article'],color = color_cited) \n        function_recc_html_link_g.add_node(data['cited_article'], label = item[0], title = cited_html,color = color_cited)\n        \n        \n        \n        \n        #add the edge\n        function_recc_notebook_display_g.add_edge(data['source_article'], data['cited_article'])\n        function_recc_html_link_g.add_edge(data['source_article'], data['cited_article'])\n        \n       \n    \n        #save the graph\n        function_recc_notebook_display_g.show('Recommended_Notebook_Graph.html')\n        \n        function_recc_html_link_g.show_buttons(filter_=['nodes','edges', 'physics'])\n        function_recc_html_link_g.show('Recommended_HTML_Interactive_Graph.html')\n       \n        \n    #return the graph so it can be run in the following jupyter cell\n    return function_recc_notebook_display_g\n        \n        \n ","29547fcb":"recommended = recommendation('a137eb51461b4a4ed3980aa5b9cb2f2c1cf0292a', k=20, plot_dna=False)\n\n\nnetwork_graph_df = recommended_paper_citation_network(recommended)\n\n\ngraph = create_network_graph(network_graph_df , df, recommended)","141769d5":"graph.show('Recommended_Notebook_Graph_1.html')","259b087e":"How many COVID19 articles a hop away from this core network?","2879ddbe":"# Applying citation networks to Topic Modelling ","ff852f0f":"### Load in the citation data","e610894c":"All of the recommended nodes (and their scores) are in green.  Like for the other graphs, check your output folder for the html graph file.","16d201e8":"### Text-mining techniques are effective for helping to answer a specific research question and for identifying similar articles.  However, the quality of the answer given is just as important as having an answer:\n\nIf asking \"What conditions make someone more susceptible to contracting COVID-19?\", you might be recommended this article via text-mining: [Relationship between the ABO Blood Group and the COVID-19 Susceptibility](http:\/\/www.medrxiv.org\/content\/10.1101\/2020.03.11.20031096v2)\n\nA confirmed relationship between blood type and susceptibility to COVID19 might greatly impact how COVID19 tests are given and distributed.  I've already seen this article being shared on social media sites.  However, this study did not utilize a large sample size, and there work has not been replicated.  A researcher might be able to make a more informed decision if they viewed similar papers on the MERS coronavirus.\n\nAdditionally, to fully understand the papers recommended, you might need to look at some articles for background knowledge.  However, articles discussing similar topics might cite different background papers, some of which could be out of date, while others rapidly gain popularity with researchers.  With the way COVID19 research is rapidly growing and changing, background knowledge may become out of date quickly.  Therefore, it would be useful to visualize which background papers are the highest-cited by a set of recommended articles.\n\n\nHow do you address these issues?  Article metadata, specifically, an analysis of article citations.  Commonly, the relationship between (source) articles and the ones they cite is visualized in the form of a directed graph, where sources \"point\" to their citations:\n\n\n![](https:\/\/3spxpi1radr22mzge33bla91-wpengine.netdna-ssl.com\/wp-content\/uploads\/2016\/09\/citation-cartel-closeup.png)\n\n\n\n\n\n\n\nIn this notebook, I'll demonstrate how to make citation networks utilizing the COVID19 articles, as well as how to incorporate the graphs into text mining results. All of these graphs are created with pyvis: https:\/\/pyvis.readthedocs.io\/en\/latest\/tutorial.html  Feel free to repurpose\/copy the notebook code in whatever way suits your needs and project.  \n","6048899c":"# Creating an interactive citation graph using additional metadata","44b9e6db":"### Load in the metadata for all of the articles (dataset already part of Wollfram's notebook)","84e26cba":"# A (brief) user guide to pyvis graphs","79d495dc":"## Prepare the subset of data to graph","d7be954a":"I hope this is informative.  There are definitely improvements that can be made to make the code more universal to any type of input, particularly when color-coding the nodes. \n\nPlease use and modify this for your own project if you are interested!","0877e67e":"# Create the Graph!","6d3054aa":"# Given a list of recommended papers, create a citation network","f311b7de":"All right!  Now that we have the ability to look for similar articles, let's use some helper functions to create the graph.  The code is mostly similary to that used for the COVID19 graph, but broken down into functions for easier use.\n\nAs mentioned previously, displaying citation networks could be a part of any text-mining widget.  For example, you could repurpose the functions below to intake a dataframe of articles in the cluster (or clusters) and label and color code nodes according to their cluster number.\n\nWith these functions, we are working with 3 dataframes:\n\n* A dataframe of recommended articles (a subsection of 'df', or all of the metadata retrieved using Wolffram's method) \n* The dataframe of article citations (where both source\/cited articles have available metadata) \n* The dataframe of metadata for all of the articles ","4d5bf7ae":"## Discovered Topics (Wolffram)","987f1010":"# Get Nearest Papers (in Topic Space) (Wolffram)","b065227a":"# Search related papers to a chosen one (Wolffram)","3fd7b6d8":"That....looks a little chaotic. Once you get past ~ 1000 nodes, things can be a little out of hand.  In the example above, the graph is displayed as a notebook output. However, if your user can download\/view html files, you can create graphs that, when downloaded, can include tools to alter node color, the 'physics,' or movement\/arrangements of the codes, and edges.  Importantly, by disabling 'physics' you can get the modes to remain in place.","70ceb4e6":"As a similarity measure we use 1 - Jensen-Shannon distance.","06aeb24a":"Generate files\/models if they are not there yet.","276683fd":"## In this example, let's explore the network graph of all new(dated 2019-2020)\/prepublished articles, as many of those will be discussing COVID-19.","599a3122":"# Install\/Load Packages\n### Use of scispacy is for Wolffram's LDA model","e633f9c7":"Although pyvis graphs can be engaging, *how* exactly you move around nodes or zoom in and out might not be all that intuitive if you have never used Gephi or related network visualization tools.  Here are the basics:\n\n\n**General guide**\n* To see the name\/article name represented by the node: Hover over it with your cursor or click on the node \n\n* To zoom in and out on parts of the network: Use the scroll wheel\/scroll bar, use two fingers to scroll up\/down to zoom in\/out\n\n* To pan left\/right\/up\/down: click on the background (white space behind the graph) and drag up\/down\/left\/right as needed\n\n**Graphs uploaded as HTML Files versus Displayed in Jupyter Notebook**\n\n* HTML graph files are key for making graphs with HTML elements, which can allow you to link nodes to the url for their corresponding papers.  Notebook outputs cannot show HTML elements and have very few formatting options for text.  However, for smaller graphs and testing purposes, they are great.\n\n* As you can see by the first notebook output, large graphs have trouble conforming to a layout, making it difficult to click on nodes.  Once you open your html graph, scroll down the section that says 'physics' in large bold letters and, underneath it, uncheck the box that says 'enabled'\n\n\n","bf915e57":"# Load in the datasets","f6d84eb3":"We consider the text body, but the approach could also be applied to the abstracts only.","e7dc0051":"Check your output folder again to download the HTML version of this graph.  Looking over the graph (without any details besides the article names) you can identify some highly-cited COVID19 papers, and explore their relationship to non-COVID19 research","5e9e0bde":"A while back, I mentioned that network graphs can help users identify highly\/cited or regarded sources.  Let's just start by identifying articles cited at a count greater than the mean (2 or more citations)","a8d14d12":"Using a basic network graph, you can explore the different types of articles citing 'Isolation of a novel coronavirus from a man with pneumonia in Saudi Arabia.' The paper discusses the MERS coronavirus.\n\nWhen combined with citation data for recently-published coronavirus articles, you can quickly see how the MERS and COVID19 research communities are connected. What aspects of MERS are COVID19 researchers focusing on?","2b4fb823":"Each article is a mixture of topics \/ a distribution over topics","f787a2f4":"Check your output folder for the graph!  Download the graph and, when clicked on, it will display as a new tab","127fb3f6":"For preprocessing we use [scispaCy](https:\/\/allenai.github.io\/scispacy\/), which is a Python package containing [spaCy](https:\/\/spacy.io) models for processing biomedical, scientific or clinical text.","40520348":"*Internet access needs to be switched on for this to work!*","083272c8":"However, for the graph to be fully interactive, you would only look at cited articles with available metadata","c42fbe4b":"## Prepare data","0d726c1c":"Now, this dataframe contained every article that's cited '', as well as any Because so many studies have cited this article (and have likely cited many other articles as well), let's only look at articles cited 2 or more times (all articles)","e44a5978":"Finally, let's go over an example of how to incorporate citation graphs into a text-mining approach.  ","dfb31e44":"How many articles have researchers cited in this dataset?  What is the highest cited article?","d132745c":"## Back to Topic Modelling! (Code by Daniel Wolffram)","f5b4bc5a":"Who is citing this popular article?","f688b8e9":"# Latend Dirichlet Allocation (Wolffram)","d09415e2":"# Creating a citation network graph","1dd8336f":"**Pros to this approach:**\n* Citation graphs can be incorporated into any approach.  If your method of choice is clustering, you could create a feature to generate a pyvis graph for a cluster or clusters selected by a user\n\n* Reduces the amount of time researchers\/users have to spend hunting for the most established article or background paper on a topic\n\n* If made interactive, users can identify \"missing links,\" or articles between several topics that could answer multiple questions at once\n\n* This could save users of a tool time and help them decide which articles are the most credible, or, at least, most frequently acknowledged\/regarded within the COVID19 research community\n\n\n**Cons to this approach:**\n* Citation data has to be updated every time new articles are added to the collection.  \n* Graphs are (computationally) expensive.  Although the graphs in this demo can be Jupyter Notebook outputs, if you wanted to create citation networks for a couple thousand nodes (or, say, a half of the 50k corpus), you would have to move this feature to a website.\n* The JSON files, not the cleaner metadata, contained all the citations.  There are far more cited articles than cited articles with metadata.  This poses limitations when creating interactive graphs that display a url, abstract, etc.\n\n* The citation graph is only as useful as the text mining technique recommending\/filtering articles. With that in mind...\n### ***Important Note*: The code to perform LDA \/ recommend articles is the work of Daniel Wolffram.  His complete notebook (with interactive widgets) is [here](https:\/\/www.kaggle.com\/danielwolffram\/topic-modeling-finding-related-articles) and this is the link to his team's website: https:\/\/discovid.ai\/search.  I've also cited each of the sections of functions he wrote below, as I do not want to take credit for his work**  "}}