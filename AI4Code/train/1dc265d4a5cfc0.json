{"cell_type":{"8b78e3bd":"code","93c2155e":"code","b1fe3379":"code","fb0ae79c":"code","b4f28fa6":"code","fc0c997c":"code","a056a19a":"code","bd8ed6a5":"code","aed78dc4":"code","26863212":"code","eab59e58":"code","d61a8b87":"code","dd3b34ef":"code","ae828031":"code","ded0d21c":"code","015f0cc4":"markdown","2aa88af3":"markdown","356e7a29":"markdown","29174474":"markdown","eb93c453":"markdown","f6c2c006":"markdown","aee0ab9b":"markdown","84b1b030":"markdown","0ae55d7f":"markdown"},"source":{"8b78e3bd":"import pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt","93c2155e":"#import train data in Pandas DataFrame\ndf_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv').astype(float)\n\n#import test data in Pandas DataFrame\ndf_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv').astype(float)\n","b1fe3379":"#DataFrame df_train: Show first 5 entries\ndf_train.head()","fb0ae79c":"#Split DataFrame df_train in 2 parts: X (inputs) & y (labels)\n#Split & Scale (X_train_flat)\nX_train_flat = preprocessing.scale(df_train[df_train.columns[1:]])\n\n#Scale (X_test_flat)\nX_test_flat = preprocessing.scale(df_test)\n\n#One-Hot Encoding labels\ny_train = to_categorical(df_train[df_train.columns[0]])\n","b4f28fa6":"#Show first 5 rows of training labels (before One-Hot Enconding)\npd.DataFrame(df_train[df_train.columns[0]]).head()","fc0c997c":"#Show first 5 rows of training labels (after One-Hot Enconding)\npd.DataFrame(y_train).head()","a056a19a":"#Plot one example picture\n#Convert flattend data in to 2D array for each image with size of 28 x 28\nX_train_2d = X_train_flat.reshape(42000, 28,28)\n#Plot image #100\nplt.imshow(X_train_2d[100])","bd8ed6a5":"#Very simple fully-connected (dense) layer model\nmodel = Sequential()\n#First layer with 64 units expects input of 784 (28 x 28)\nmodel.add(Dense(units=64, activation='relu', input_dim=784))\n#Second layer with 32 units\nmodel.add(Dense(units=32, activation='relu'))\n#Output layer with 10 units (for '0' to '9') \nmodel.add(Dense(units=10, activation='softmax'))\n\n#Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n#Fit Model (15 epochs, batch-size 64 and validation split of 30%)\nhistory = model.fit(x=X_train_flat, y=y_train, batch_size=64, epochs=15, validation_split=0.3)","aed78dc4":"#Max validation accuracy during training\nnp.max(history.history['val_acc'])","26863212":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label = 'Training')\nplt.plot(epochs, val_acc, 'b', label = 'Validierung')\nplt.title('Correct Classification Rate training\/validation')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Loss training')\nplt.plot(epochs, val_loss, 'b', label='Loss Validation')\nplt.title('Value of Loss Function training\/validation')\nplt.legend()\n","eab59e58":"from keras.layers import Dropout\n\n#Very simple fully-connected (dense) layer model\nmodel = Sequential()\n#add dropout\nmodel.add(Dropout(0.2, input_shape=(784,)))\n#First layer with 64 units expects input of 784 (28 x 28)\nmodel.add(Dense(units=64, activation='relu'))\n#add dropout\nmodel.add(Dropout(0.2))\n#Second layer with 32 units\nmodel.add(Dense(units=32, activation='relu'))\n#Output layer with 10 units (for '0' to '9') \nmodel.add(Dense(units=10, activation='softmax'))\n\n#Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n#Fit Model (15 epochs, batch-size 64 and validation split of 30%)\nhistory = model.fit(x=X_train_flat, y=y_train, batch_size=64, epochs=25, validation_split=0.3)","d61a8b87":"#Max validation accuracy during training\nnp.max(history.history['val_acc'])","dd3b34ef":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label = 'Training')\nplt.plot(epochs, val_acc, 'b', label = 'Validierung')\nplt.title('Correct Classification Rate training\/validation')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Loss training')\nplt.plot(epochs, val_loss, 'b', label='Loss Validation')\nplt.title('Value of Loss Function training\/validation')\nplt.legend()","ae828031":"#use trained model predict label (one hot encoded) for test data\ny_hat_one_hot = model.predict(X_test_flat)\n\n#convert one-hot encoded values into label values\ny_hat = np.argmax(y_hat_one_hot, axis=1)\n#write prediction into Pandas DataFrame\ny_hat = pd.DataFrame(y_hat, columns=['Label'])\ny_hat.index += 1 \ny_hat.index.name = 'ImageId'\n","ded0d21c":"#Show first 5 rows of prediction table\ny_hat.head()","015f0cc4":"**Figure below shows an overfitting during training**\n\n(there is still bigger potential for improvements)","2aa88af3":"**2.2) Create & Train Model**","356e7a29":"**2.4) Predict Labels for test data**","29174474":"**2.) Simple Fully-Connected Neural Network (96.33%)**\n\n![](https:\/\/storage.googleapis.com\/kaggle-datasets\/98112\/230269\/FC.jpg?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1546422464&Signature=aXTRq0bJC4aRnPqG614J9gMRw8D9PA8tmpD7WNISUEM%2FGIZ8Hw%2FLdO5oJKcbA2V7AYFEareLLIy%2BpipKC0pP3XnLKfZP19fWA7HBwjMhGmRjwNF%2F5P7%2BhizHLGdvDc%2FaXjw04BzEjIa%2FZEAeqNwX%2FZ3xPxa38geoDt%2BibDGJGD8lFCEcDkIMtKkhwWkapM7X02MLNwRnImMIiIRf4OuBjx6Ku9C6B7pPNtuy%2FP9QoyPeiSrdMboyNpYC72a0hLZZ7wY%2FiT6Pezju7UCaXNFOiYsa4sw8KDhm8ftCM0R82gGaSofgdXhVKAVsPD%2F%2FUZiW00anv2mCGlFdXkcC%2F%2FIICQ%3D%3D)\n\n\nIn this example we start already with flattend data.\n","eb93c453":"**2.2) Create & Train Model with Dropout**","f6c2c006":"**2.1) Data Preprocessing**","aee0ab9b":"As it is my first Kernel, I focus on a simple approach with a fully-connected model in keras. \nOf course, there are many other ways to achieve better results (e.g. CNN), but for beginners (like I am) this could be an easy example.\nYour feedback is highly appreciated!\n\n\n**1.) General Imports**\n\n**1.1) Import Modules**","84b1b030":"**1.2) Import Data**","0ae55d7f":"With dropout I could already improve the result (overfitting is reduced & max validation accuracy increased). But a significant higher accuracy (>99%) I could only achieve by different model architecutre (in my case CNN)."}}