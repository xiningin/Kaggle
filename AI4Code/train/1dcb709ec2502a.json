{"cell_type":{"3f221458":"code","9eaf0542":"code","788aefc6":"code","9a30f360":"code","1520dac0":"code","af168d34":"code","d573bfe3":"code","c1faa84f":"code","18fa5285":"code","3eff67d5":"code","6c3be9c5":"code","e11af1be":"code","07e0724c":"code","fee56090":"code","02a790d8":"code","3f675c38":"code","2d16287c":"code","5d52daa1":"code","fec4d005":"code","bd8b7e8b":"code","7c1f9c7b":"code","b34e4986":"code","bc0dc5c3":"code","52157656":"code","678943d4":"code","08bcedbb":"code","337943c6":"code","ace7b279":"code","84116c7b":"code","8867dc49":"code","f15fc9c4":"code","2ef7102b":"code","8b2db0da":"code","d35a4556":"code","53d8ba9b":"code","e5c59a5d":"markdown","27124c2e":"markdown","c8952e5b":"markdown","1763af37":"markdown"},"source":{"3f221458":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9eaf0542":"data=pd.read_csv('\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')\ndata.head()","788aefc6":"#Lets do some visualizations to see how have things worked out\ndata['ssc_b'].value_counts(normalize=True).plot(kind='bar')","9a30f360":"data['hsc_b'].value_counts(normalize=True).plot(kind='bar')","1520dac0":"data['workex'].value_counts(normalize=True)","af168d34":"import seaborn as sns\npd.crosstab(data[\"status\"],data[(\"specialisation\")]).apply(lambda r: (r\/r.sum())*100, axis=0)\n\n# Mkt&HR is not a field where its easy to get a job","d573bfe3":"#see the relationship of predictor with the outcome variable\n\nsns.countplot(x=\"specialisation\",hue=\"workex\",data=data)\n\n##It is visible that candidates with workex in Mkt&Fin had an advantage","c1faa84f":"data.head()","18fa5285":"data=data.drop(['sl_no'],axis=1)","3eff67d5":"data.shape","6c3be9c5":"numerical_cols=pd.DataFrame(data.describe()).columns\nnumerical_cols\noutput_col='salary' #toggle between salary and status","e11af1be":"cat_data=data.drop(numerical_cols,axis=1)\ncat_data.head()","07e0724c":"num_data=data[numerical_cols]\nnum_data.head()","fee56090":"#dealing with num data first\nnum_data['salary']=num_data['salary'].fillna(0)\n#print(num_data.isna().sum())\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(num_data)\nscaled_num_data=pd.DataFrame(scaler.transform(num_data),columns=numerical_cols)\n    ","02a790d8":"\n#keeping an eye for data leakage\n#scaled_num_data_wo_sal=scaled_num_data.drop('salary',axis=1)\ncat_data=cat_data.drop('status',axis=1)","3f675c38":"#dealing with categorical data\ncat_data.head()","2d16287c":"cat_data_dummy=pd.get_dummies(cat_data,drop_first=True)","5d52daa1":"cat_data_dummy.shape","fec4d005":"cat_data_dummy.head()","bd8b7e8b":"final_data=pd.concat([cat_data_dummy,scaled_num_data],axis=1)\n#scaled_num_data_wo_sal","7c1f9c7b":"output=final_data[['salary']]\ntrain_final=final_data.drop(['salary'],axis=1)","b34e4986":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_final, output, test_size=0.30, random_state=1)","bc0dc5c3":"y_test.head()","52157656":"#from sklearn.ensemble import RandomForestClassifier\n#model=RandomForestClassifier(n_estimators=100, random_state=0)\n#model.fit(X_train,y_train)\n\nfrom sklearn.ensemble import RandomForestRegressor\nmodel=RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(X_train,y_train)","678943d4":"preds=model.predict(X_test)\n#from sklearn.metrics import confusion_matrix\n#from sklearn.metrics import accuracy_score\n#confusion_matrix(y_test, preds)\n#print(\"The Accuracy score is: \",accuracy_score(y_test,preds)*100)\nfrom sklearn.metrics import r2_score\nr2_score(y_test, preds)","08bcedbb":"importance=model.feature_importances_\nnames=X_train.columns","337943c6":"feature_importance = np.array(importance)\nfeature_names = np.array(names)\ndata={'feature_names':feature_names,'feature_importance':feature_importance}\nfi_df = pd.DataFrame(data)\n\n#Sort the DataFrame in order decreasing feature importance\nfi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)","ace7b279":"fi_df","84116c7b":"#fucking shit, my life was a lie!","8867dc49":"#Uncomment for categorical problem\n# import shap\n# explainer = shap.TreeExplainer(model)\n# X_train.loc[[10]]\n# choosen_instance = X_train.loc[[10]]\n# shap_values = explainer.shap_values(choosen_instance)\n# shap.initjs()\n# shap.force_plot(explainer.expected_value[1], shap_values[1], choosen_instance)\n# shap.initjs()\n# shap.summary_plot(shap_values, features=X_train, feature_names=X_train.columns)","f15fc9c4":"from time import time\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.neural_network import MLPRegressor\ntic = time()\nest = make_pipeline(QuantileTransformer(),\n                    MLPRegressor(hidden_layer_sizes=(50, 50),\n                                 learning_rate_init=0.01,\n                                 early_stopping=True))\nest.fit(X_train, y_train)\nprint(f\"done in {time() - tic:.3f}s\")\nprint(f\"Test R2 score: {est.score(X_test, y_test):.2f}\")","2ef7102b":"import matplotlib.pyplot as plt\nfrom sklearn.inspection import partial_dependence\nfrom sklearn.inspection import plot_partial_dependence\n","8b2db0da":"numerical_cols_wo_salary=[x for x in numerical_cols if x!='salary']\nnumerical_cols_wo_salary","d35a4556":"\nprint('Computing partial dependence plots...')\ntic = time()\nfeatures = numerical_cols_wo_salary\ndisplay = plot_partial_dependence(\n       est, X_train, features, kind=\"both\", subsample=50,\n       n_jobs=3, grid_resolution=20, random_state=0\n)\nprint(f\"done in {time() - tic:.3f}s\")\n\ndisplay.figure_.subplots_adjust(hspace=0.3)","53d8ba9b":"\nprint('Computing partial dependence plots...')\ntic = time()\nfeatures = X_train.columns\ndisplay = plot_partial_dependence(\n       est, X_train, features, kind=\"both\", subsample=50,\n       n_jobs=3, grid_resolution=20, random_state=0\n)\nprint(f\"done in {time() - tic:.3f}s\")\n\ndisplay.figure_.subplots_adjust(hspace=0.3)","e5c59a5d":"# **Exploratory Data Analysis**","27124c2e":"# **Feature Engineering**","c8952e5b":"# **Model Fitting**","1763af37":"# **Inspecting for Salary**"}}