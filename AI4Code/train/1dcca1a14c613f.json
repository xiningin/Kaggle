{"cell_type":{"ae0a79c2":"code","055189dc":"code","27ae218d":"code","15003bc6":"code","54e52915":"code","03d0c73a":"code","d239640f":"code","f9bee6a9":"code","1ecf957a":"code","9703aacf":"code","e60410dc":"code","757a21d4":"code","5e1dcaf5":"markdown","b9937a27":"markdown","efaf84ed":"markdown"},"source":{"ae0a79c2":"!pip -q install tensorflow-gpu==2.0.0-beta1\n!pip -q install tensorflow-addons","055189dc":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import (\n    BatchNormalization,\n    Dense,\n    Dropout,\n    Flatten,\n    Conv2D,\n    MaxPool2D,\n)\n\nimport matplotlib.pyplot as plt\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","27ae218d":"IMG_HEIGHT = 28\nIMG_WIDTH = 28\nBATCH_SIZE = 128\nBUFFER_SIZE = 1000","15003bc6":"def reshape(image):\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, 1])\n    return image\n\ndef normalize(image):\n    image = tf.cast(image, tf.float32)\n    image = (image \/ 127.5) - 1\n    return image\n\ndef random_crop(image):\n    cropped_image = tf.image.random_crop(\n        image, size=[IMG_HEIGHT, IMG_WIDTH, 1])\n    return cropped_image\n\ndef random_rotate(image):\n    rotate_angles = tf.random.normal([], stddev=0.2)\n    image = tfa.image.rotate(image, rotate_angles)\n    return image\n\ndef random_jitter(image):\n    # resizing to 30 x 30 x 1\n    image = tf.image.resize(image, [30, 30],\n                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n    # randomly cropping to 28 x 28 x 1\n    image = random_crop(image)\n    return image\n\ndef preprocess_train(*features):\n    label = features[0]\n    image = tf.stack(features[1:], axis=-1)\n    \n    image = reshape(image)\n    image = random_rotate(image)\n    image = random_jitter(image)\n    image = normalize(image)\n    return image, label\n\ndef preprocess_eval(*features):\n    label = features[0]\n    image = tf.stack(features[1:], axis=-1)\n    \n    image = reshape(image)\n    image = normalize(image)\n    return image, label\n\ndef preprocess_test(*features):\n    image = tf.stack(features, axis=-1)\n\n    image = reshape(image)\n    image = normalize(image)\n    return image","54e52915":"ds = tf.data.experimental.CsvDataset(\n    \"..\/input\/train.csv\",\n    [tf.int64] * 785,\n    header=True,\n)\n\nds_test = tf.data.experimental.CsvDataset(\n    \"..\/input\/test.csv\",\n    [tf.int64] * 784,\n    header=True,\n)\n\nnum_eval = int(42000 * 0.1)\nds_eval = ds.take(num_eval)\nds_train = ds.skip(num_eval)\n\nds_train = ds_train.map(preprocess_train, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nds_eval = ds_eval.map(preprocess_eval, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nds_test = ds_test.map(preprocess_test, num_parallel_calls=AUTOTUNE).batch(32)","03d0c73a":"NUM_SAMPLES = 6\n\ndef preprocess_sample(*features):\n    image = tf.stack(features[1:], axis=-1)\n    image = reshape(image)\n    return image\n\nsample_images = next(iter(ds.map(preprocess_sample).batch(NUM_SAMPLES)))\n\nfig=plt.figure(figsize=(10, 10))\nfig.tight_layout()\n\nfor i, sample_image in enumerate(sample_images, start=1):\n    fig.add_subplot(3, NUM_SAMPLES, i)\n    plt.imshow(sample_image[:, :, 0], cmap='gray_r')\n\n    fig.add_subplot(3, NUM_SAMPLES, NUM_SAMPLES + i)\n    plt.imshow(random_jitter(sample_image)[:, :, 0], cmap='gray_r')\n\n    fig.add_subplot(3, NUM_SAMPLES, 2 * NUM_SAMPLES + i)\n    plt.imshow(random_rotate(sample_image)[:, :, 0], cmap='gray_r')\nplt.show()","d239640f":"model = tf.keras.models.Sequential(\n    [\n        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n        BatchNormalization(),\n        Conv2D(32, (3, 3), activation=\"relu\"),\n        BatchNormalization(),\n        Conv2D(32, (5, 5), activation=\"relu\", strides=2, padding=\"same\"),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Conv2D(64, (3, 3), activation=\"relu\"),\n        BatchNormalization(),\n        Conv2D(64, (3, 3), activation=\"relu\"),\n        BatchNormalization(),\n        Conv2D(64, (5, 5), activation=\"relu\", strides=2, padding=\"same\"),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Conv2D(128, (4, 4), activation=\"relu\"),\n        BatchNormalization(),\n        Flatten(),\n        Dropout(0.4),\n        Dense(10, activation=\"softmax\"),\n    ]\n)","f9bee6a9":"model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"sparse_categorical_accuracy\"])","1ecf957a":"lr_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience=3, verbose=1, factor=0.5, min_lr=1e-5)\n\nhistory = model.fit(ds_train, epochs=30, validation_data=ds_eval, callbacks=[lr_reduction])","9703aacf":"predictions = model.predict(ds_test)","e60410dc":"results = np.argmax(predictions, axis=1)\nresults = pd.Series(results, name=\"Label\")","757a21d4":"submission = pd.concat([pd.Series(range(1,28001), name=\"ImageId\"), results], axis=1)\nsubmission.to_csv(\"cnn_submission.csv\", index=False)","5e1dcaf5":"## Load Data\n\nSure, `tf.data` is overkill for small datasets, but we are learning here... Also, let's add some data augmentation to the training images in order to avoid overfitting.","b9937a27":"## Build CNN model","efaf84ed":"Visualize the data augmentation"}}