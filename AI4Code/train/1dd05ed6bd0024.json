{"cell_type":{"2757d2b0":"code","853858af":"code","02582144":"code","c8d6f236":"code","dc3b6822":"code","64ee3b35":"code","39c64af1":"code","574c97c3":"code","b0739391":"code","ab3e7094":"code","13374919":"code","a2374c1b":"code","52d06511":"code","e1e584b6":"code","ac678a63":"code","c2013713":"code","3a34915f":"code","58130185":"code","cdae95c3":"code","0cce53ea":"code","96993dae":"code","380c9bfd":"code","d8b2f44f":"code","0e0cea15":"code","4b63ced2":"code","d57c789f":"markdown","e72f3279":"markdown"},"source":{"2757d2b0":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras","853858af":"print(tf.__version__)","02582144":"model = tf.keras.Sequential([keras.layers.Dense(units = 1,input_shape=[1])])","c8d6f236":"model.compile(optimizer = 'sgd', loss = \"mean_squared_error\", metrics = ['accuracy'])","dc3b6822":"xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\nys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)","64ee3b35":"model.fit(xs,ys,epochs = 100)","39c64af1":"print(model.predict([10.0]))","574c97c3":"mnist = tf.keras.datasets.fashion_mnist","b0739391":"(training_images, training_labels),(test_images, test_labels) = mnist.load_data()","ab3e7094":"print(training_images.shape)\nprint(test_images.shape)\nprint(training_labels.shape)\nprint(test_labels.shape)","13374919":"np.set_printoptions(linewidth = 300)\nimport matplotlib.pyplot as plt\nplt.imshow(training_images[0])\nprint(training_labels[0])\nprint(training_images[0])\n","a2374c1b":"training_images = training_images\/255\ntest_images = test_images\/255","52d06511":"model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n                            tf.keras.layers.Dense(128,activation = tf.nn.relu),\n                            tf.keras.layers.Dense(10,activation = tf.nn.softmax)])","e1e584b6":"model.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])","ac678a63":"model.fit(training_images,training_labels,epochs = 10)","c2013713":"model.evaluate(test_images,test_labels)","3a34915f":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,logs={}):\n        if(logs.get('accuracy')>0.9):\n            print(\"\\n Reached desired accuracy(90%) so cancelling training\")\n            self.model.stop_training = True\n            \ncallbacks = myCallback()\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])","58130185":"mnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()","cdae95c3":"training_images = training_images.reshape(60000,28,28,1)\ntest_images.reshape(10000,28,28,1)\ntraining_images = training_images\/255\ntest_images = test_images\/255","0cce53ea":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu',input_shape = (28,28,1)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3),activation ='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128,activation = 'relu'),\n    tf.keras.layers.Dense(10,activation = 'softmax')\n])","96993dae":"model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","380c9bfd":"model.fit(training_images, training_labels, epochs=5)","d8b2f44f":"test_images = test_images.reshape(10000,28,28,1)\ntest_images.shape","0e0cea15":"model.summary()","4b63ced2":"import matplotlib.pyplot as plt\nf, axarr = plt.subplots(3,4)\nFIRST_IMAGE=0\nSECOND_IMAGE=7\nTHIRD_IMAGE=26\nCONVOLUTION_NUMBER = 1\nfrom tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\nfor x in range(0,4):\n  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[0,x].grid(False)\n  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[1,x].grid(False)\n  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n  axarr[2,x].grid(False)","d57c789f":"# Building a convolutional neural network","e72f3279":"# callbacks"}}