{"cell_type":{"905621c4":"code","38a93de5":"code","374df9ce":"code","81d45531":"code","95448a1e":"code","4c1e29c7":"code","0a6c87bb":"code","ec5c3d01":"code","58d6d565":"code","7b48ca7e":"code","3f9bc351":"code","58c6f6e0":"code","24080ca9":"code","450de90e":"code","95997abe":"code","70d4828a":"code","fb1cae74":"code","bb1a499d":"code","94559cb0":"code","035f600e":"code","7052abf5":"code","7cdf22a4":"code","b156a375":"markdown","ae568d6b":"markdown","3906f5fe":"markdown","9df29364":"markdown","b5fde0a6":"markdown"},"source":{"905621c4":"!pip install imutils","38a93de5":"import os\nimport cv2\nimport numpy as np\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory \n\nplt.style.use('ggplot')","374df9ce":"os.listdir(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\")","81d45531":"image_size = (224,224)\nbatch_size = 32\ndata_path = \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\"\n\ntrain_set = image_dataset_from_directory(data_path, \n                                         label_mode ='categorical',\n                                         validation_split=0.2,\n                                         subset=\"training\",\n                                         seed=1337,\n                                         image_size=image_size,\n                                         batch_size=batch_size)\n\nvalidation_set = image_dataset_from_directory(data_path,\n                                   label_mode ='categorical',\n                                   validation_split=0.2,\n                                   subset=\"validation\",\n                                   seed=1337,\n                                   image_size=image_size,\n                                   batch_size=batch_size)\n\nm_train_set = train_set.map(lambda x, y: (preprocess_input(x), y))\nm_validation_set = validation_set.map(lambda x, y: (preprocess_input(x), y))","95448a1e":"INIT_LR = 3e-5\nEPOCHS = 20","4c1e29c7":"baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(128, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(64, activation=\"relu\")(headModel)\nheadModel = Dropout(0.2)(headModel)\nheadModel = Dense(2, activation=\"softmax\")(headModel)\n\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\nfor layer in baseModel.layers:\n\tlayer.trainable = True\n\n\nmetrics = ['accuracy',metrics.Precision(name='precision'),metrics.Recall(name='recall')]    \nopt = Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=metrics)","0a6c87bb":"model.summary()","ec5c3d01":"plot_model(model,dpi=300)","58d6d565":"HR2 = model.fit_generator(m_train_set, steps_per_epoch=16, validation_data = m_validation_set, validation_steps=8, epochs=EPOCHS)","7b48ca7e":"N = EPOCHS\n\nplt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"loss\"], label=\"Training Loss\")\nplt.plot(np.arange(0, N), HR2.history[\"val_loss\"], label=\"Validation Loss\")\nplt.title(\"Training Loss and Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"upper right\")","3f9bc351":"plt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"accuracy\"], label=\"Training Accuracy\")\nplt.plot(np.arange(0, N), HR2.history[\"val_accuracy\"], label=\"Validation Accuracy\")\nplt.title(\"Training Accuracy and Validation Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(loc=\"lower right\")","58c6f6e0":"plt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"precision\"], label=\"Training Precision\")\nplt.plot(np.arange(0, N), HR2.history[\"val_precision\"], label=\"Validation Precision\")\nplt.title(\"Training Precision and Validation Precision\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Precision\")\nplt.legend(loc=\"lower right\")","24080ca9":"plt.figure()\nplt.plot(np.arange(0, N), HR2.history[\"recall\"], label=\"Training Recall\")\nplt.plot(np.arange(0, N), HR2.history[\"val_recall\"], label=\"Validation Recall\")\nplt.title(\"Training Recall and Validation Recall\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Recall\")\nplt.legend(loc=\"lower right\")","450de90e":"parasitized_path = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/'\nuninfected_path = '\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/'","95997abe":"def mapper(val):\n    if val==0:\n        return 'Parasitized'\n    elif val ==1:\n        return 'Uninfected'","70d4828a":"def genPred(PATH,image):\n    o_test_image = cv2.imread(os.path.join(PATH, image))\n    o_test_image = cv2.cvtColor(o_test_image, cv2.COLOR_BGR2RGB)\n\n    test_image = cv2.resize(o_test_image, image_size)\n    test_image = preprocess_input(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n\n    y_hat = model.predict(test_image)\n    y_hat = np.argmax(y_hat, axis=1)\n    pred_lab = mapper(y_hat)\n\n    print(\"ORIGINAL LABEL: \"+PATH.split('\/')[-2])\n    print(\"PREDICTED LABEL: \"+pred_lab)\n    print(\"------------------------------------------------------------------------\")\n    print(\"\")\n\n    plt.imshow(o_test_image)","fb1cae74":"genPred(parasitized_path, 'C101P62ThinF_IMG_20150918_151239_cell_74.png')","bb1a499d":"genPred(parasitized_path, 'C100P61ThinF_IMG_20150918_145422_cell_163.png')","94559cb0":"genPred(parasitized_path, 'C101P62ThinF_IMG_20150918_151239_cell_87.png')","035f600e":"genPred(uninfected_path, 'C100P61ThinF_IMG_20150918_145042_cell_161.png')","7052abf5":"genPred(uninfected_path, 'C100P61ThinF_IMG_20150918_144348_cell_108.png')","7cdf22a4":"genPred(uninfected_path, 'C100P61ThinF_IMG_20150918_144104_cell_128.png')","b156a375":"## ***Model Construction***","ae568d6b":"## ***Model Training***","3906f5fe":"## ***Load Dataset***","9df29364":"## ***Performance Analysis***","b5fde0a6":"## ***Predictions on Random Images***"}}