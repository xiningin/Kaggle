{"cell_type":{"5756ad14":"code","5e7b0d3d":"code","80a4b4f2":"code","8c424219":"code","fb7b1296":"code","ec159284":"code","36da16c0":"code","04067db9":"code","bd779d5f":"code","744b8a20":"code","35397380":"code","8dbcaaa0":"code","d8aab6bd":"code","d893a7e2":"code","92f9ef2c":"code","3575764d":"code","91c3f0b3":"code","beb9e5a4":"code","33366032":"code","9e815bad":"code","00766d58":"code","88af6a79":"code","9b7c867e":"code","c44cc75d":"code","e278ef30":"code","bd00dbf0":"code","a6bb2b66":"code","9e7e829b":"code","3f789347":"code","2d70a73d":"code","422470f7":"markdown","f69184b1":"markdown","da0e2af9":"markdown","a8a35ccc":"markdown","abcec2b7":"markdown","15d5bae6":"markdown","6abf603e":"markdown","cf815264":"markdown"},"source":{"5756ad14":"import numpy as np \nimport pandas as pd \nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e7b0d3d":"pd.set_option('display.max_columns',None)\npd.set_option('display.expand_frame_repr',False)","80a4b4f2":"data = pd.read_csv(\"..\/input\/sms-spam-collection-dataset\/spam.csv\")\ndata.tail()","8c424219":"data.info()","fb7b1296":"data[\"Unnamed: 4\"].unique()","ec159284":"data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\ncolumn_name = [\"Spam\",\"Text\"]\ndata.columns = column_name","36da16c0":"data.head()","04067db9":"data[\"Spam\"].loc[data[\"Spam\"] == \"ham\"] = 1\ndata[\"Spam\"].loc[data[\"Spam\"] == \"spam\"] = 0","bd779d5f":"data[\"Spam\"].unique()","744b8a20":"Spam = [liste for liste in data[\"Spam\"]]","35397380":"Spam = pd.DataFrame(Spam)\ntype(Spam)","8dbcaaa0":"df = pd.concat([Spam,data[\"Text\"]],axis=1)\ndf.head()","d8aab6bd":"column_name = [\"Spam\",\"Text\"]\ndf.columns = column_name","d893a7e2":"df.head()","92f9ef2c":"type(df[\"Spam\"])","3575764d":"df.shape","91c3f0b3":"df.columns","beb9e5a4":"df.isnull().any()","33366032":"nltk.download('stopwords')","9e815bad":"def process(text):\n    punc = [c for c in text if c not in string.punctuation]\n    punc = ''.join(punc)\n    stopw = [w for w in punc.split() if w.lower() not in stopwords.words('english') ]\n    return stopw","00766d58":"df['Text'].head().apply(process)","88af6a79":"from sklearn.feature_extraction.text import CountVectorizer\nmessage = CountVectorizer(analyzer=process).fit_transform(df['Text'])","9b7c867e":"message.shape","c44cc75d":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(message, df['Spam'],test_size=0.2, random_state=0)","e278ef30":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB().fit(x_train,y_train)","bd00dbf0":"#prediction\nclassifier.predict(x_train)","a6bb2b66":"#Actual\ny_train.values","9e7e829b":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","3f789347":"def report(y_train, x_train):\n    pred = classifier.predict(x_train)\n    print('Report: \\n',classification_report(y_train, pred))\n    print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n    print('\\n')\n    print('Accuracy: \\n', accuracy_score(y_train, pred))","2d70a73d":"report(y_train, x_train)","422470f7":"Read the data","f69184b1":"Remove Punctuation and Stopwords","da0e2af9":"Update label names","a8a35ccc":"Stopwords package","abcec2b7":"Naive Bayes Classifier","15d5bae6":"Convert the text to a matrix of special word counts","6abf603e":"Columns 2,3,4 contain no important data and can be deleted.\nAlso, we rename column v1 as \"label\" and v2 as \"text\"","cf815264":"This program detects if an e-mail is spam(1) or not (0)"}}