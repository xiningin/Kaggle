{"cell_type":{"7b33edc5":"code","34208784":"code","50e77c27":"code","1c9fe614":"code","913c9cd0":"code","d7b8444c":"code","9239705c":"code","c9dfb3e0":"code","62a62c92":"code","074517f7":"code","97d55435":"code","2fd4111f":"code","e5198af5":"code","fa7ebb73":"code","184b28f6":"code","11fe6fb8":"markdown","4eb9f0fe":"markdown","1bc0c342":"markdown","2a7c1b21":"markdown","81f42608":"markdown","9f27db45":"markdown","de28d211":"markdown","739c4da9":"markdown","b475cbbd":"markdown","a3445655":"markdown"},"source":{"7b33edc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","34208784":"# Other  \nimport librosa\nimport librosa.display\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport seaborn as sns\nimport glob \nimport os\nfrom tqdm import tqdm\nimport pickle\nimport IPython.display as ipd  # To play sound in the notebook","50e77c27":"# Use one audio file in previous parts again\nfname = '\/kaggle\/input\/demand\/TCAR_48k\/TCAR\/ch13.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Paly it again to refresh our memory\nipd.Audio(data, rate=sampling_rate)","1c9fe614":"def noise(data):\n    \"\"\"\n    Adding White Noise.\n    \"\"\"\n    # you can take any distribution from https:\/\/docs.scipy.org\/doc\/numpy-1.13.0\/reference\/routines.random.html\n    noise_amp = 0.05*np.random.uniform()*np.amax(data)   # more noise reduce the value to 0.5\n    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n    return data","913c9cd0":"x = noise(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","d7b8444c":"def shift(data):\n    \"\"\"\n    Random Shifting.\n    \"\"\"\n    s_range = int(np.random.uniform(low=-5, high = 5)*1000)  #default at 500\n    return np.roll(data, s_range)","9239705c":"x = shift(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","c9dfb3e0":"def stretch(data, rate=0.8):\n    \"\"\"\n    Streching the Sound. Note that this expands the dataset slightly\n    \"\"\"\n    data = librosa.effects.time_stretch(data, rate)\n    return data","62a62c92":"x = stretch(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","074517f7":"def pitch(data, sample_rate):\n    \"\"\"\n    Pitch Tuning.\n    \"\"\"\n    bins_per_octave = 12\n    pitch_pm = 2\n    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n    data = librosa.effects.pitch_shift(data.astype('float64'), \n                                      sample_rate, n_steps=pitch_change, \n                                      bins_per_octave=bins_per_octave)\n    return data","97d55435":"x = pitch(data, sampling_rate)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","2fd4111f":"def dyn_change(data):\n    \"\"\"\n    Random Value Change.\n    \"\"\"\n    dyn_change = np.random.uniform(low=-0.5 ,high=7)  # default low = 1.5, high = 3\n    return (data * dyn_change)","e5198af5":"x = dyn_change(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","fa7ebb73":"def speedNpitch(data):\n    \"\"\"\n    peed and Pitch Tuning.\n    \"\"\"\n    # you can change low and high here\n    length_change = np.random.uniform(low=0.8, high = 1)\n    speed_fac = 1.2  \/ length_change # try changing 1.0 to 2.0 ... =D\n    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n    minlen = min(data.shape[0], tmp.shape[0])\n    data *= 0\n    data[0:minlen] = tmp[0:minlen]\n    return data","184b28f6":"x = speedNpitch(data)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(x, sr=sampling_rate)\nipd.Audio(x, rate=sampling_rate)","11fe6fb8":"Dynamic change","4eb9f0fe":"Shift Method","1bc0c342":"#Codes from Eu Jin Lok https:\/\/www.kaggle.com\/ejlok1\/audio-emotion-part-5-data-augmentation\/notebook","2a7c1b21":"Take one audio file and run it through all the different types to get a feel for how they work. From there we'll then take a few forward for our model training ","81f42608":"Kaggle Notebook Runner: Mar\u00edlia Prata @mpwolke","9f27db45":"Add static noise in the background.","de28d211":"We go to stretch, Eu Jin Lok @ejlok1 most favourite augmentation method","739c4da9":"#Augmentation methods","b475cbbd":"Pitch, this method accentuates the high pitch notes.","a3445655":"#This work was created by Joachim Thiemann (IRISA-CNRS), Nobutaka Ito (University of Tokyo), and Emmanuel Vincent (Inria Rennes - #Bretagne Atlantique). It was supported by Inria under the Associate Team Program VERSAMUS.****"}}