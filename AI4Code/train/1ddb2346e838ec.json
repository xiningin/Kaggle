{"cell_type":{"44509db0":"code","b98dd8fc":"code","1d850322":"code","bf7f22ac":"code","4812e195":"code","e8828884":"code","c8ab2b7d":"code","dfb682d1":"code","a14a0389":"code","a6054b04":"code","9e05eefd":"code","8ad618e1":"code","e00a27be":"code","79f670dc":"code","a4ddc3d8":"code","8f230c9c":"code","3d63955b":"code","37e88194":"code","eda231d7":"code","2491a8f8":"code","55d28fe8":"code","d194bf24":"code","5fbb2ca2":"code","0089a48e":"code","89ba1d90":"code","efc60526":"markdown","62b7fac4":"markdown","488ea9b3":"markdown","aaac8ce9":"markdown","43d328bd":"markdown","daaf1e29":"markdown","7fae336d":"markdown","951bd5dc":"markdown","32496547":"markdown","3e3d7b62":"markdown","8acafb55":"markdown","0a345fa2":"markdown","81f25d60":"markdown","cc218e90":"markdown","75571b75":"markdown","32834259":"markdown"},"source":{"44509db0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline ","b98dd8fc":"df = pd.read_csv(\"..\/input\/sonaralldata\/sonar.all-data.csv\")","1d850322":"# Data overview\n\ndf.info()","bf7f22ac":"df[\"Label\"].value_counts()","4812e195":"plt.figure(figsize=(4,4),  dpi=200)\nsns.countplot(data=df,x=\"Label\")","e8828884":"X= df.drop('Label', axis=1)\ny= df['Label']","c8ab2b7d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","dfb682d1":"from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaler.fit(X_train)\nscaled_X_train= scaler.transform(X_train)\nscaled_X_test= scaler.transform(X_test)","a14a0389":"from sklearn.neighbors import KNeighborsClassifier\nknn_model= KNeighborsClassifier(n_neighbors=1)\nknn_model.fit(scaled_X_train, y_train)","a6054b04":"y_pred= knn_model.predict(scaled_X_test)","9e05eefd":"#A comparison between predicted Value vs Actual Values\n\npd.DataFrame({'Y_Test':y_test, 'Y_Pred': y_pred})","8ad618e1":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\naccuracy_score(y_test, y_pred)","e00a27be":"confusion_matrix(y_test, y_pred)","79f670dc":"print(classification_report(y_test, y_pred))","a4ddc3d8":"test_error_rate= []\n\n\nfor k in range (1, 30):\n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(scaled_X_train, y_train)\n    \n    y_pred_test = knn_model.predict(scaled_X_test)\n    \n    test_error=1- accuracy_score(y_test, y_pred_test)\n    test_error_rate.append(test_error)","8f230c9c":"test_error_rate","3d63955b":"plt.figure(figsize=(6, 4), dpi = 200)\nplt.plot(range(1, 30), test_error_rate, label='Test Error')\nplt.legend()\nplt.ylabel('Error Rate')\nplt.xlabel('K Value')","37e88194":"scaler= StandardScaler()\nknn= KNeighborsClassifier()\nknn.get_params().keys()","eda231d7":"operations= [('scaler', scaler), ('knn', knn)]\nfrom sklearn.pipeline import Pipeline\npipe= Pipeline(operations)\nfrom sklearn.model_selection import GridSearchCV\nk_values= list(range(1, 20))\nparam_grid= {'knn__n_neighbors': k_values}\nfull_cv_classifier= GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\nfull_cv_classifier.fit(X_train, y_train)","2491a8f8":"full_cv_classifier.best_estimator_.get_params()","55d28fe8":"full_cv_classifier.cv_results_.keys()","d194bf24":"scaler= StandardScaler()\nknn1= KNeighborsClassifier(n_neighbors=1)\noperations= [('scaler', scaler), ('knn1', knn1)]","5fbb2ca2":"pipe= Pipeline(operations)\npipe.fit(X_train, y_train)","0089a48e":"pipe_pred= pipe.predict(X_test)","89ba1d90":"print(classification_report(y_test, pipe_pred))","efc60526":"# Step 11: Finilizing the model","62b7fac4":"# Step 3: Exploratory Data Analysis","488ea9b3":"# Step 8: Prediction","aaac8ce9":"# Step 1: Importing required libraries","43d328bd":"## $1^{st}$ Method: Elbow Method","daaf1e29":"# Step 2: Importing the Dataset","7fae336d":"# Step 10: Selecting the best K","951bd5dc":"# Step 6: Feature Scaling\n\n#### It should be mentioned that feature scaling is compulsory in the KNN algorithm.","32496547":"### The sonar dataset\n\nSonar (sound navigation ranging) is a technique that uses sound propagation (usually underwater, as in submarine navigation) to navigate, communicate with or detect objects on or under the surface of the water, such as other vessels. The data set contains the response metrics for 60 separate sonar frequencies sent out against a known mine field (and known rocks). These frequencies are then labeled with the known object they were beaming the sound at (either a rock or a mine).\nOur main goal is to create a machine learning model capable of detecting the difference between a rock or a mine based on the response of the 60 separate sonar frequencies.\n### Data Source:\nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)","3e3d7b62":"# Step 9: Evaluating the Model","8acafb55":"#### As can be seen, there is no missing value.","0a345fa2":"# Step 4: Determining the Features and the Target Variable","81f25d60":"# Step 7: Training the Model\n\n#### K nearset neighbors (KNN) assigns a label to new data according to the distance between the old data and the new data.\n\n$Pr(Y=j|X=x_0) = 1\/K \\times \\sum_{i \\in N_0} I(y_i = j)$","cc218e90":"#### As shown, it is more desirable to set K equal to 1.","75571b75":"# Step 5: Spliting the Data to Train & Test","32834259":"## $2^{nd}$ Method: Grid Search Cross Validation _ A Pipeline application"}}