{"cell_type":{"5e854cf6":"code","687b1ba0":"code","69cb372a":"code","99b082d5":"code","5e1531ab":"code","b31f17d4":"code","c31b0c2f":"code","7f1c4a5d":"code","1fc8c076":"code","480d8934":"code","b4f2733b":"code","cf5f1153":"code","0fb54de8":"code","ad61af0b":"code","4a074dc5":"code","557a6cee":"code","70cdc448":"code","132e38fb":"code","aae96a2d":"code","667121ee":"code","d86f3015":"markdown","92d31229":"markdown","cd96c68a":"markdown","396314bb":"markdown","92619d85":"markdown","4c36442c":"markdown","bd32abba":"markdown","2e18533a":"markdown","fbfd4364":"markdown","e7f544fa":"markdown","ecfcb50a":"markdown","76956d90":"markdown"},"source":{"5e854cf6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","687b1ba0":"dataset = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")","69cb372a":"dataset.head()","99b082d5":"dataset.info()","5e1531ab":"dataset = dataset.drop([\"id\"], axis = 1)","b31f17d4":"dataset = dataset.drop([\"Unnamed: 32\"], axis = 1)","c31b0c2f":"dataset.head(3)","7f1c4a5d":"M = dataset[dataset.diagnosis == \"M\"]","1fc8c076":"M.head(5)","480d8934":"B = dataset[dataset.diagnosis == \"B\"]","b4f2733b":"B.head(5)","cf5f1153":"plt.title(\"Malignant vs Benign Tumor\")\nplt.xlabel(\"Radius Mean\")\nplt.ylabel(\"Texture Mean\")\nplt.scatter(M.radius_mean, M.texture_mean, color = \"red\", label = \"Malignant\", alpha = 0.3)\nplt.scatter(B.radius_mean, B.texture_mean, color = \"lime\", label = \"Benign\", alpha = 0.3)\nplt.legend()\nplt.show()","0fb54de8":"dataset.diagnosis = [1 if i == \"M\" else 0 for i in dataset.diagnosis]","ad61af0b":"x = dataset.drop([\"diagnosis\"], axis = 1)\ny = dataset.diagnosis.values","4a074dc5":"# Normalization:\nx = (x - np.min(x)) \/ (np.max(x) - np.min(x))","557a6cee":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","70cdc448":"from sklearn.tree import DecisionTreeClassifier","132e38fb":"dt = DecisionTreeClassifier()","aae96a2d":"dt.fit(x_train, y_train)","667121ee":"# prediction\ndt.score(x_test, y_test)","d86f3015":"<a id = \"5\"><\/a>\n# 5. Decision Tree with Sklearn","92d31229":"Now, let's get rid of \"id\" and \"Unnamed: 32\" features because we don't need to use them while diagnosing whether the patient has a cancer or not. ","cd96c68a":"![](https:\/\/images.slideplayer.com\/24\/7460347\/slides\/slide_4.jpg)","396314bb":"Column names and meanings:\n* id: ID number\n* diagnosis: The diagnosis of breast tissues (M = malignant, B = benign)\n* radius_mean: mean of distances from center to points on the perimeter\n* texture_mean: standard deviation of gray-scale values\n* perimeter_mean: mean size of the core tumor\n* area_mean: area of the tumor\n* smoothness_mean: mean of local variation in radius lengths\n* compactness_mean: mean of perimeter^2 \/ area - 1.0\n* concavity_mean: mean of severity of concave portions of the contour\n* concave_points_mean: mean for number of concave portions of the contour\n* symmetry_mean\n* fractal_dimension_mean: mean for \"coastline approximation\" - 1\n* radius_se: standard error for the mean of distances from center to points on the perimeter\n* texture_se: standard error for standard deviation of gray-scale values\n* perimeter_se\n* area_se\n* smoothness_se: standard error for local variation in radius lengths\n* compactness_se: standard error for perimeter^2 \/ area - 1.0\n* concavity_se: standard error for severity of concave portions of the contour\n* concave_points_se: standard error for number of concave portions of the contour\n* symmetry_se\n* fractal_dimension_se: standard error for \"coastline approximation\" - 1\n* radius_worst: \"worst\" or largest mean value for mean of distances from center to points on the perimeter\n* texture_worst: \"worst\" or largest mean value for standard deviation of gray-scale values\n* perimeter_worst\n* area_worst\n* smoothness_worst: \"worst\" or largest mean value for local variation in radius lengths\n* compactness_worst: \"worst\" or largest mean value for perimeter^2 \/ area - 1.0\n* concavity_worst: \"worst\" or largest mean value for severity of concave portions of the contour\n* concave_points_worst: \"worst\" or largest mean value for number of concave portions of the contour\n* symmetry_worst\n* fractal_dimension_worst: \"worst\" or largest mean value for \"coastline approximation\" - 1","92619d85":"<a id = \"4\"><\/a>\n# 4. Meaning Of Decision Tree Algorithm","4c36442c":"Dataset information:\n\n* Dataset Characteristics: Multivariate\n* Attribute Characteristics: Real\n* Attribute Characteristics: Classification\n* Number of Instances: 569\n* Number of Attributes: 32\n* Missing Values: No","bd32abba":"## Content:\n\n1. [Importing Dataset](#1)\n1. [Getting Info About Dataset](#2)\n1. [Dataset Visualization](#3)\n1. [Meaning Of Decision Tree Algorithm](#4)\n1. [Decision Tree with Sklearn](#5)","2e18533a":"<a id = \"3\"><\/a>\n# 3. Dataset Visualization ","fbfd4364":"> <a id = \"2\"><\/a>\n# 2. Getting Info About Dataset","e7f544fa":"# Decision Tree Implementation on Cancer Dataset","ecfcb50a":"<a id = \"1\"><\/a>\n\n# 1. Importing Dataset:","76956d90":"* Decision tree models where the target variable uses a discrete set of values are classified as Classification Trees. \n* In these trees, each node, or leaf, represent class labels while the branches represent conjunctions of features leading to class labels.\n* A decision tree where the target variable takes a continuous value, usually numbers, are called Regression Trees.\n* The two types are commonly referred to together at CART (Classification and Regression Tree)."}}