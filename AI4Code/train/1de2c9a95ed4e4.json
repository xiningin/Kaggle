{"cell_type":{"4c36693b":"code","e08f744d":"code","62356d91":"code","1bb6abe0":"code","4d0e6f55":"code","85114429":"code","765427b6":"code","a04edfb0":"code","25489518":"code","d1b6c623":"code","d1eca3f7":"markdown","5adad8e8":"markdown","ec169db2":"markdown","0e91c4cf":"markdown","e045b44f":"markdown","7df1d99c":"markdown","90333d5c":"markdown","73126490":"markdown"},"source":{"4c36693b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e08f744d":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python\n# Any results you write to the current directory are saved as output.\n#Sharpening\n\nimage = cv2.imread('\/kaggle\/input\/shiba-dog\/shiba.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Create our shapening kernel, we don't normalize since the \n# the values in the matrix sum to 1\nkernel_sharpening = np.array([[-1,-1,-1], \n                              [-1,9,-1], \n                              [-1,-1,-1]])\n\n# applying different kernels to the input image\nsharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\n\nplt.subplot(1, 2, 2)\nplt.title(\"Image Sharpening\")\nplt.imshow(sharpened)\n\nplt.show()","62356d91":"# Load our new image\nimage = cv2.imread('\/kaggle\/input\/shiba-dog\/shiba.jpg', 0)\n\nplt.figure(figsize=(30, 30))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Threshold Binary\")\nplt.imshow(thresh1)\n\n# It's good practice to blur images as it removes noise\nimage = cv2.GaussianBlur(image, (3, 3), 0)\n\n# Using adaptiveThreshold\nthresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n\nplt.subplot(3, 2, 3)\nplt.title(\"Adaptive Mean Thresholding\")\nplt.imshow(thresh)\n\n\n\n_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\nplt.subplot(3, 2, 4)\nplt.title(\"Otsu's Thresholding\")\nplt.imshow(th2)\n\n\nplt.subplot(3, 2, 5)\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(image, (5,5), 0)\n_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.title(\"Guassian Otsu's Thresholding\")\nplt.imshow(th3)\nplt.show()","1bb6abe0":"image = cv2.imread('\/kaggle\/input\/shiba-dog\/shiba.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's define our kernel size\nkernel = np.ones((5,5), np.uint8)\n\n# Now we erode\nerosion = cv2.erode(image, kernel, iterations = 1)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Erosion\")\nplt.imshow(erosion)\n\n# \ndilation = cv2.dilate(image, kernel, iterations = 1)\nplt.subplot(3, 2, 3)\nplt.title(\"Dilation\")\nplt.imshow(dilation)\n\n\n# Opening - Good for removing noise\nopening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.subplot(3, 2, 4)\nplt.title(\"Opening\")\nplt.imshow(opening)\n\n# Closing - Good for removing noise\nclosing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.subplot(3, 2, 5)\nplt.title(\"Closing\")\nplt.imshow(closing)","4d0e6f55":"image = cv2.imread('\/kaggle\/input\/shiba-dog\/shiba.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nheight, width,_ = image.shape\n\n# Extract Sobel Edges\nsobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\nsobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Sobel X\")\nplt.imshow(sobel_x)\n\nplt.subplot(3, 2, 3)\nplt.title(\"Sobel Y\")\nplt.imshow(sobel_y)\n\nsobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n\nplt.subplot(3, 2, 4)\nplt.title(\"sobel_OR\")\nplt.imshow(sobel_OR)\n\nlaplacian = cv2.Laplacian(image, cv2.CV_64F)\n\nplt.subplot(3, 2, 5)\nplt.title(\"Laplacian\")\nplt.imshow(laplacian)\n\n# Canny Edge Detection uses gradient values as thresholds\n# The first threshold gradient\ncanny = cv2.Canny(image, 50, 120)\n\nplt.subplot(3, 2, 6)\nplt.title(\"Canny\")\nplt.imshow(canny)","85114429":"image = cv2.imread('\/kaggle\/input\/shiba-dog\/shiba.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n \n# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\n\n\nwarped = cv2.warpPerspective(image, M, (420,594))\n\nplt.subplot(1, 2, 2)\nplt.title(\"warpPerspective\")\nplt.imshow(warped)","765427b6":"# load image\nfrom matplotlib import pyplot\n\nfrom PIL import Image\nimage = Image.open('..\/input\/shiba-dog\/shiba.jpg')\n# horizontal flip\nhoz_flip = image.transpose(Image.FLIP_LEFT_RIGHT)\n# vertical flip\nver_flip = image.transpose(Image.FLIP_TOP_BOTTOM)\n# plot all three images using matplotlib\npyplot.subplot(311)\npyplot.imshow(image)\npyplot.subplot(312)\npyplot.imshow(hoz_flip)\npyplot.subplot(313)\npyplot.imshow(ver_flip)\npyplot.show()","a04edfb0":"# load image\nimage = Image.open('..\/input\/shiba-dog\/shiba.jpg')\n# plot original image\npyplot.subplot(311)\npyplot.imshow(image)\n# rotate 45 degrees\npyplot.subplot(312)\npyplot.imshow(image.rotate(45))\n# rotate 90 degrees\npyplot.subplot(313)\npyplot.imshow(image.rotate(90))\npyplot.show()\n#rotates 270 degrees\npyplot.imshow(image.rotate(270))\npyplot.show()","25489518":"from PIL import Image\n# load image\nimage = Image.open('..\/input\/shiba-dog\/shiba.jpg')\n# create a cropped image\ncropped = image.crop((100, 100, 200, 200))\n# show cropped image\npyplot.imshow(cropped)","d1b6c623":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('@mpwolke Was here' )","d1eca3f7":"#Shiba\n\nThe Shiba Inu (\u67f4\u72ac, Japanese: \u0255iba\u0320 k\u025bn, shiba-ken) is a Japanese breed of hunting dog. A small-to-medium breed, it is the smallest of the six original and distinct spitz breeds of dog native to Japan.\nhttps:\/\/en.wikipedia.org\/wiki\/Shiba_Inu","5adad8e8":"#Perpsective Transform","ec169db2":"#Code from Salman Ibne Eunus https:\/\/www.kaggle.com\/salmaneunus\/mechanical-tools-warehouse-classification","0e91c4cf":"#Dilation, Erosion, Opening and Closing","e045b44f":"#Cropping Images. The cropped image has nothing to do with the Little Shiba (Shibinha).","7df1d99c":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTrexM-QROAlv_eDR6Y8_0QOFsGe-NRrR0wYg&usqp=CAU)www3.livrariacultura.com.br","90333d5c":"#Thresholding, Binarization & Adaptive Thresholding","73126490":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python"}}