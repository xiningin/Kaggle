{"cell_type":{"c0763de3":"code","1b121b86":"code","66dd1839":"code","f166a72b":"code","c10039f0":"code","6f9761d1":"code","4471c3ef":"code","bf0dd4fb":"code","612db63c":"code","f22d5e21":"code","639a3fab":"code","581414f2":"code","eb2da164":"code","186572b4":"code","26368654":"code","862c938e":"code","44f0d76d":"code","36635077":"code","3d74f03e":"code","c10267b2":"code","4c3e7183":"code","39df401a":"code","dc90a784":"code","05c60ce8":"code","370c31a5":"code","6df357f9":"code","10fef70c":"code","ebf94dba":"code","bfb435b3":"markdown","79859b2b":"markdown","9c3ca473":"markdown","35904baa":"markdown","0afb5ac8":"markdown","ac8e6df0":"markdown","c14b3498":"markdown"},"source":{"c0763de3":"!pip install tensorflow==1.15.0\n!pip install keras==2.2.5","1b121b86":"%matplotlib inline\nimport os\nimport gc\nimport sys\nimport json\nimport glob\nimport random \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nimport itertools\nfrom tqdm import tqdm\n\nfrom imgaug import augmenters as iaa\n# Any results you write to the current directory are saved as output.","66dd1839":"!git clone https:\/\/www.github.com\/matterport\/Mask_RCNN.git\n!pip install -q git+https:\/\/github.com\/tensorflow\/examples.git","f166a72b":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c10039f0":"os.chdir('Mask_RCNN')\nDATA_DIR = Path('\/kaggle\/input\/imaterialist-fashion-2019-FGVC6\/')\nROOT_DIR = Path('\/kaggle\/working')","6f9761d1":"sys.path.append(str(ROOT_DIR\/'Mask_RCNN'))\n\nfrom mrcnn.config import Config\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log\n\n!wget --quiet https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n!ls -lh mask_rcnn_coco.h5\n\nCOCO_WEIGHTS_PATH = 'mask_rcnn_coco.h5'","4471c3ef":"# config: either 'resnet50' or 'resnet101' is supported\n\nNUM_CATS = 46\nIMAGE_SIZE = 512\n\nclass Config_(Config):\n    def __init__(self, bbone):\n        super().__init__()\n        self._bone = bbone\n        \n    NAME = \"fashion\"\n    NUM_CLASSES = NUM_CATS + 1 # backgroun\n    \n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 2 \n    \n    BACKBONE = 'resnet50'\n    \n    IMAGE_MIN_DIM = IMAGE_SIZE\n    IMAGE_MAX_DIM = IMAGE_SIZE    \n    IMAGE_RESIZE_MODE = 'none'\n    \n    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n    \n    # STEPS_PER_EPOCH should be the number of instances \n    # divided by (GPU_COUNT*IMAGES_PER_GPU), and so should VALIDATION_STEPS;\n    # however, due to the time limit, I set them so that this kernel can be run in 9 hours\n    STEPS_PER_EPOCH = 1000\n    VALIDATION_STEPS = 200\n    \nconfig = Config_('resnet50')\nconfig.display()","bf0dd4fb":"with open(DATA_DIR\/\"label_descriptions.json\") as f:\n    label_descriptions = json.load(f)\n\nlabel_names = [x['name'] for x in label_descriptions['categories']]\n\nsegment_df = pd.read_csv(DATA_DIR\/\"train.csv\")\nsegment_df['CategoryId'] = segment_df['ClassId'].str.split('_').str[0]\n\nmultilabel_percent = len(segment_df[segment_df['CategoryId'].str.contains('_')])\/len(segment_df)*100","612db63c":"segment_df.head(10)","f22d5e21":"image_df = segment_df.groupby('ImageId')['EncodedPixels', 'CategoryId'].agg(lambda x: list(x))\nsize_df = segment_df.groupby('ImageId')['Height', 'Width'].mean()\nimage_df = image_df.join(size_df, on='ImageId')\n\nprint(\"Total images: \", len(image_df))\nimage_df.head()","639a3fab":"def resize_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)  \n    return img","581414f2":"class Dataset(utils.Dataset):\n\n    def __init__(self, df):\n        super().__init__(self)\n        \n        # Add classes\n        for i, name in enumerate(label_names):\n            self.add_class(\"fashion\", i+1, name)\n        \n        # Add images \n        for i, row in df.iterrows():\n            self.add_image(\"fashion\", \n                           image_id=row.name, \n                           path=str(DATA_DIR\/'train'\/row.name), \n                           labels=row['CategoryId'],\n                           annotations=row['EncodedPixels'], \n                           height=row['Height'], width=row['Width'])\n\n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path'], [label_names[int(x)] for x in info['labels']]\n    \n    def load_image(self, image_id):\n        return resize_image(self.image_info[image_id]['path'])\n\n    def load_mask(self, image_id):\n        info = self.image_info[image_id]\n                \n        mask = np.zeros((IMAGE_SIZE, IMAGE_SIZE, len(info['annotations'])), dtype=np.uint8)\n        labels = []\n        \n        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):\n            sub_mask = np.full(info['height']*info['width'], 0, dtype=np.uint8)\n            annotation = [int(x) for x in annotation.split(' ')]\n            \n            for i, start_pixel in enumerate(annotation[::2]):\n                sub_mask[start_pixel: start_pixel+annotation[2*i+1]] = 1\n\n            sub_mask = sub_mask.reshape((info['height'], info['width']), order='F')\n            sub_mask = cv2.resize(sub_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n            \n            mask[:, :, m] = sub_mask\n            labels.append(int(label)+1)\n            \n        return mask, np.array(labels)","eb2da164":"dataset = Dataset(image_df)\ndataset.prepare()\n\n\nimage_id = random.choice(dataset.image_ids)\nprint(dataset.image_reference(image_id))\n    \nimage = dataset.load_image(image_id)\nmask, class_ids = dataset.load_mask(image_id)\nvisualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=4)","186572b4":"from sklearn.model_selection import KFold\n\nFOLD = 0\nN_FOLDS = 10\n\nkf = KFold(n_splits=N_FOLDS, random_state=42, shuffle=True)\nsplits = kf.split(image_df) # ideally, this should be multilabel stratification\n\ndef get_fold():    \n    for i, (train_index, valid_index) in enumerate(splits):\n        if i == FOLD:\n            return image_df.iloc[train_index], image_df.iloc[valid_index]\n        \ntrain_df, valid_df = get_fold()\n\ntrain_dataset = Dataset(train_df)\ntrain_dataset.prepare()\n\nvalid_dataset = Dataset(valid_df)\nvalid_dataset.prepare()","26368654":"train_segments = np.concatenate(train_df['CategoryId'].values)\nprint(\"Total train images: \", len(train_df))\nprint(\"Total train segments: \", len(train_segments))\n\nplt.figure(figsize=(12, 3))\nvalues, counts = np.unique(train_segments, return_counts=True)\nplt.bar(values, counts)\nplt.xticks(values, label_names, rotation='vertical')\nplt.show()\n\nvalid_segments = np.concatenate(valid_df['CategoryId'].values).astype(int)\nprint(\"Total train images: \", len(valid_df))\nprint(\"Total validation segments: \", len(valid_segments))\n\nplt.figure(figsize=(12, 3))\nvalues, counts = np.unique(valid_segments, return_counts=True)\nplt.bar(values, counts)\nplt.xticks(values, label_names, rotation='vertical')\nplt.show()","862c938e":"LR = 5e-3\nEPOCHS = [2, 6, 8]","44f0d76d":"model_1 = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n\nmodel_1.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    'mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])","36635077":"augmentation = iaa.Sequential([\n    iaa.Fliplr(0.5) \n])","3d74f03e":"model_1.train(train_dataset, valid_dataset,\n            learning_rate=LR*2, # train heads with higher lr to speedup learning\n            epochs=EPOCHS[0],\n            layers='heads',\n            augmentation=None)\n\nhistory = model_1.keras_model.history.history","c10267b2":"model_1.train(train_dataset, valid_dataset,\n            learning_rate=LR,\n            epochs=EPOCHS[1],\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model_1.keras_model.history.history\nfor k in new_history: \n    history[k] = history[k] + new_history[k]","4c3e7183":"epochs = range(EPOCHS[-1])\n\nplt.figure(figsize=(18, 6))\n\nplt.subplot(131)\nplt.plot(epochs, history['loss'], label=\"train loss\")\nplt.plot(epochs, history['val_loss'], label=\"valid loss\")\nplt.legend()\nplt.subplot(132)\nplt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\nplt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\nplt.legend()\nplt.subplot(133)\nplt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\nplt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\nplt.legend()\n\nplt.show()","39df401a":"best_epoch = np.argmin(history[\"val_loss\"]) + 1\nprint(\"Best epoch: \", best_epoch)\nprint(\"Valid loss: \", history[\"val_loss\"][best_epoch-1])","dc90a784":"config = Config_('resnet101')\nconfig.display","05c60ce8":"model_2 = modellib.MaskRCNN(mode='training', config=config, model_dir=ROOT_DIR)\n\nmodel_2.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    'mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])","370c31a5":"model_2.train(train_dataset, valid_dataset,\n            learning_rate=LR*2, # train heads with higher lr to speedup learning\n            epochs=EPOCHS[0],\n            layers='heads',\n            augmentation=None)\n\nhistory = model_2.keras_model.history.history","6df357f9":"model_2.train(train_dataset, valid_dataset,\n            learning_rate=LR,\n            epochs=EPOCHS[1],\n            layers='all',\n            augmentation=augmentation)\n\nnew_history = model_1.keras_model.history.history\nfor k in new_history: \n    history[k] = history[k] + new_history[k]","10fef70c":"epochs = range(EPOCHS[-1])\n\nplt.figure(figsize=(18, 6))\n\nplt.subplot(131)\nplt.plot(epochs, history['loss'], label=\"train loss\")\nplt.plot(epochs, history['val_loss'], label=\"valid loss\")\nplt.legend()\nplt.subplot(132)\nplt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\nplt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\nplt.legend()\nplt.subplot(133)\nplt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\nplt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\nplt.legend()\n\nplt.show()","ebf94dba":"best_epoch = np.argmin(history[\"val_loss\"]) + 1\nprint(\"Best epoch: \", best_epoch)\nprint(\"Valid loss: \", history[\"val_loss\"][best_epoch-1])","bfb435b3":"\u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0443\u043b\u0438 \u0438\u0437 \u0440\u0435\u043f\u043e \u0441\u0435\u0442\u043a\u0438","79859b2b":"\u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u0435\u0440\u0432\u0443\u044e \u0441\u0435\u0442\u043a\u0443 (\u0440\u0435\u0437\u043d\u0435\u0442 50). \u0412\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0447\u0442\u043e\u0431\u044b \u043e\u0442\u043a\u0430\u0442\u0438\u0442\u044c\u0441\u044f \u043f\u043e\u0442\u043e\u043c \u043a \u0442\u0435\u043c \u043d\u0430\u0431\u043e\u0440\u0430\u043c \u0432\u0435\u0441\u043e\u0432","9c3ca473":"\u0423\u0442\u0438\u043b\u0438\u0442\u044b \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u043c. \u041f\u0440\u043e\u0433\u0440\u0443\u0437\u043a\u0430 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f, \u043c\u0430\u0441\u043a\u0438 \u0434\u043b\u044f \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438 \u043f\u0440.","35904baa":"**\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c mask_rcnn \u0438 \u0433\u0443\u0433\u043b\u043e\u0432\u0441\u043a\u0438\u0439 pix2pix \u0434\u043b\u044f \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438**","0afb5ac8":"\u0422\u0443\u0442 \u0431\u0443\u0434\u0435\u0442 \u043a\u0440\u043e\u0441\u0441\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f","ac8e6df0":"\u0422\u0435\u043f\u0435\u0440\u044c \u043f\u0440\u043e\u0434\u0435\u043b\u044b\u0432\u0430\u0435\u043c \u0432\u0441\u0435 \u0442\u043e \u0434\u0435 \u0441 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043e\u0439 \u043d\u0430 101 \u0441\u043b\u043e\u0439","c14b3498":"\u0417\u0430\u0434\u0430\u0435\u043c \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044e \u0441\u0435\u0442\u0438, \u0442\u043e \u0435\u0441\u0442\u044c \u0435\u0435 \u0442\u0438\u043f, \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443, \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u0445\u043e\u0434\u0449\u0435\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u044f, \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432"}}