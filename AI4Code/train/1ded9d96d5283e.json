{"cell_type":{"cda88bd5":"code","30eec8c0":"code","3eb84a96":"code","61c79555":"code","6067a7d5":"code","330ddfc3":"code","8fa64362":"code","bae8a2c5":"code","3d117501":"code","04e81d74":"code","bf3ac170":"code","da3c06c2":"code","ffd748bb":"code","8bb28f2e":"code","46017daa":"code","cdbd7faf":"code","3f184bcf":"code","ce315e71":"code","af6b6e24":"code","8eb45502":"code","58fbec97":"code","17c10329":"code","9e58d4d5":"code","b6f9032e":"code","ae2a6996":"code","51337f4c":"code","235ed486":"markdown","6d40026c":"markdown","c65438ee":"markdown","3efa741f":"markdown","1cb65be3":"markdown","1ac4679d":"markdown","9311af9a":"markdown","bc7f0268":"markdown","a9e8cc70":"markdown","f01e8c80":"markdown","ff9f8320":"markdown","ae0b6e9a":"markdown","14b92c75":"markdown","6973955c":"markdown","61b34402":"markdown","e773e878":"markdown","27ca4b93":"markdown","a79dfa2f":"markdown","8fbfe27b":"markdown","2b8f6ac4":"markdown","f2f7216f":"markdown","3548353b":"markdown","08104c64":"markdown","c51d3110":"markdown","ee0ddc6d":"markdown","266fd689":"markdown","d3fac45c":"markdown","41216728":"markdown"},"source":{"cda88bd5":"import json\nimport math\nimport os\n# import urllib.request\nfrom six.moves import urllib\nimport warnings\nfrom urllib.error import HTTPError\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision\n\n# %matplotlib inline\nfrom IPython.display import set_matplotlib_formats\nfrom torchvision import transforms\nfrom torchvision.datasets import FashionMNIST\nfrom tqdm.notebook import tqdm\n\nset_matplotlib_formats(\"svg\", \"pdf\")  # For export\nsns.set()","30eec8c0":"# \u4e0b\u8f7d\u6587\u4ef6\u7684\u8def\u5f84\nDATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data\/\")\n# \u5b58\u50a8\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u8def\u5f84\nCHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models\/Activation_Functions\/\")\n\n\n# \u8bbe\u7f6e\u968f\u673a\u6570\u79cd\u5b50\ndef set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():  # GPU\u64cd\u4f5c\u7684\u79cd\u5b50\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\n\nset_seed(402) # 402\u662f\u6211\u513f\u5b50\u7684\u751f\u65e5\n\n# \u4e0b\u9762\u7684\u8bbe\u7f6e\u662f\u4e3a\u4e86\u5728GPU\u8bad\u7ec3\u6a21\u578b\u65f6\uff0c\u4fdd\u8bc1\u7ed3\u679c\u7684\u4e00\u81f4\u6027\ntorch.backends.cudnn.determinstic = True\ntorch.backends.cudnn.benchmark = False\n\n# \u6839\u636eCPU\/GPU\u914d\u7f6e\uff0c\u5f97\u5230torch\u7684device\ndevice = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\nprint(\"Using device\", device)","3eb84a96":"# \u672c\u6559\u7a0b\u7684\u6a21\u578b\u4fdd\u5b58\u5730\u5740\nbase_url = \"https:\/\/raw.githubusercontent.com\/phlippe\/saved_models\/main\/tutorial3\/\"\n# \u4e0b\u8f7d\u6a21\u578b\u7684\u6587\u4ef6\npretrained_files = [\n    \"FashionMNIST_elu.config\",\n    \"FashionMNIST_elu.tar\",\n    \"FashionMNIST_leakyrelu.config\",\n    \"FashionMNIST_leakyrelu.tar\",\n    \"FashionMNIST_relu.config\",\n    \"FashionMNIST_relu.tar\",\n    \"FashionMNIST_sigmoid.config\",\n    \"FashionMNIST_sigmoid.tar\",\n    \"FashionMNIST_swish.config\",\n    \"FashionMNIST_swish.tar\",\n    \"FashionMNIST_tanh.config\",\n    \"FashionMNIST_tanh.tar\",\n]\n# \u521b\u5efa\u6a21\u578b\u4fdd\u5b58\u8def\u5f84\nos.makedirs(CHECKPOINT_PATH, exist_ok=True)\n\n# \u4e0b\u8f7d\u6587\u4ef6\nfor file_name in pretrained_files:\n    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n    if not os.path.isfile(file_path):\n        file_url = base_url + file_name\n        print(f\"Downloading {file_url}...\")\n        try:\n            urllib.request.urlretrieve(file_url, file_path)\n        except HTTPError as e:\n            print(\n                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n                e,\n            )","61c79555":"class ActivationFunction(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.name = self.__class__.__name__\n        self.config = {\"name\": self.name}","6067a7d5":"##############################\nclass Sigmoid(ActivationFunction):\n    def forward(self, x):\n        return 1 \/ (1 + torch.exp(-x))\n##############################\nclass Tanh(ActivationFunction):\n    def forward(self, x):\n        x_exp, neg_x_exp = torch.exp(x), torch.exp(-x)\n        return (x_exp - neg_x_exp) \/ (x_exp + neg_x_exp)\n##############################","330ddfc3":"##############################\nclass ReLU(ActivationFunction):\n    def forward(self, x):\n        return x * (x > 0).float()\n##############################\nclass LeakyReLU(ActivationFunction):\n    def __init__(self, alpha=0.1):\n        super().__init__()\n        self.config[\"alpha\"] = alpha\n\n    def forward(self, x):\n        return torch.where(x > 0, x, self.config[\"alpha\"] * x)\n##############################\nclass ELU(ActivationFunction):\n    def forward(self, x):\n        return torch.where(x > 0, x, torch.exp(x)-1)\n##############################\nclass Swish(ActivationFunction):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n##############################\nclass Mish(ActivationFunction):\n    def forward(self, x):\n        return x * torch.tanh(torch.log(1 + torch.exp(x)))\n##############################","8fa64362":"act_fn_by_name = {\n    \"sigmoid\": Sigmoid,\n    \"tanh\": Tanh,\n    \"relu\": ReLU,\n    \"leakyrelu\": LeakyReLU,\n    \"elu\": ELU,\n    \"swish\": Swish,\n    \"mish\": Mish,\n}\n\n# \u53ef\u4ee5\u589e\u52a0\u4e2amish","bae8a2c5":"def get_grads(act_fn, x):\n    \"\"\"\n    Computes the gradients of an activation function at specified positions.\n\n    Inputs:\n        act_fn - An object of the class \"ActivationFunction\" with an implemented forward pass.\n        x - 1D input tensor.\n    Output:\n        A tensor with the same size of x containing the gradients of act_fn at x.\n    \"\"\"\n    x = x.clone().requires_grad_() # Mark the input as tensor for which we want to store gradients\n    out = act_fn(x)\n    out.sum().backward() # Summing results in an equal gradient flow to each element in x\n    return x.grad # Accessing the gradients of x by \"x.grad\"","3d117501":"def vis_act_fn(act_fn, ax, x):\n    # Run activation function\n    y = act_fn(x)\n    y_grads = get_grads(act_fn, x)\n    # Push x, y and gradients back to cpu for plotting\n    x, y, y_grads = x.cpu().numpy(), y.cpu().numpy(), y_grads.cpu().numpy()\n    ## Plotting\n    ax.plot(x, y, linewidth=2, label=\"ActFn\")\n    ax.plot(x, y_grads, linewidth=2, label=\"Gradient\")\n    ax.set_title(act_fn.name)\n    ax.legend()\n    ax.set_ylim(-1.5, 2.5)\n\n# Add activation functions if wanted\nact_fns = [act_fn() for act_fn in act_fn_by_name.values()]\nx = torch.linspace(-5, 5, 1000) # Range on which we want to visualize the activation functions\n## Plotting\nrows = math.ceil(len(act_fns)\/2.0)\nfig, ax = plt.subplots(rows, 2, figsize=(8, rows*4))\nfor i, act_fn in enumerate(act_fns):\n    vis_act_fn(act_fn, ax[divmod(i,2)], x)\nfig.subplots_adjust(hspace=0.3)\nplt.show()","04e81d74":"class BaseNetwork(nn.Module):\n    def __init__(self, act_fn, input_size=784, num_classes=10, hidden_sizes=[512, 256, 256, 128]):\n        \"\"\"\n        Args:\n            act_fn: Object of the activation function that should be used as non-linearity in the network.\n            input_size: Size of the input images in pixels\n            num_classes: Number of classes we want to predict\n            hidden_sizes: A list of integers specifying the hidden layer sizes in the NN\n        \"\"\"\n        super().__init__()\n\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [input_size] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [nn.Linear(layer_size_last, layer_size), act_fn]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], num_classes)]\n        # nn.Sequential summarizes a list of modules into a single module, applying them in sequence\n        self.layers = nn.Sequential(*layers)\n\n        # We store all hyperparameters in a dictionary for saving and loading of the model\n        self.config = {\n            \"act_fn\": act_fn.config,\n            \"input_size\": input_size,\n            \"num_classes\": num_classes,\n            \"hidden_sizes\": hidden_sizes,\n        }\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)  # Reshape images to a flat vector\n        out = self.layers(x)\n        return out","bf3ac170":"def _get_config_file(model_path, model_name):\n    # Name of the file for storing hyperparameter details\n    return os.path.join(model_path, model_name + \".config\")\n\ndef _get_model_file(model_path, model_name):\n    # Name of the file for storing network parameters\n    return os.path.join(model_path, model_name + \".tar\")\n\ndef load_model(model_path, model_name, net=None):\n    \"\"\"Loads a saved model from disk.\n\n    Args:\n        model_path: Path of the checkpoint directory\n        model_name: Name of the model (str)\n        net: (Optional) If given, the state dict is loaded into this model. Otherwise, a new model is created.\n    \"\"\"\n    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n    assert os.path.isfile(\n        config_file\n    ), f'Could not find the config file \"{config_file}\". Are you sure this is the correct path and you have your model config stored here?'\n    assert os.path.isfile(\n        model_file\n    ), f'Could not find the model file \"{model_file}\". Are you sure this is the correct path and you have your model stored here?'\n    with open(config_file) as f:\n        config_dict = json.load(f)\n    if net is None:\n        act_fn_name = config_dict[\"act_fn\"].pop(\"name\").lower()\n        act_fn = act_fn_by_name[act_fn_name](**config_dict.pop(\"act_fn\"))\n        net = BaseNetwork(act_fn=act_fn, **config_dict)\n    net.load_state_dict(torch.load(model_file, map_location=device))\n    return net\n\ndef save_model(model, model_path, model_name):\n    \"\"\"Given a model, we save the state_dict and hyperparameters.\n\n    Args:\n        model: Network object to save parameters from\n        model_path: Path of the checkpoint directory\n        model_name: Name of the model (str)\n    \"\"\"\n    config_dict = model.config\n    os.makedirs(model_path, exist_ok=True)\n    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n    with open(config_file, \"w\") as f:\n        json.dump(config_dict, f)\n    torch.save(model.state_dict(), model_file)","da3c06c2":"# Transformations applied on each image => first make them a tensor, then normalize them in the range -1 to 1\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n\n# Loading the training dataset. We need to split it into a training and validation part\ntrain_dataset = FashionMNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\ntrain_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n\n# Loading the test set\ntest_set = FashionMNIST(root=DATASET_PATH, train=False, transform=transform, download=True)","ffd748bb":"train_loader = data.DataLoader(train_set, batch_size=1024, shuffle=True, drop_last=False)\nval_loader = data.DataLoader(val_set, batch_size=1024, shuffle=False, drop_last=False)\ntest_loader = data.DataLoader(test_set, batch_size=1024, shuffle=False, drop_last=False)","8bb28f2e":"exmp_imgs = [train_set[i][0] for i in range(16)]\n# Organize the images into a grid for nicer visualization\nimg_grid = torchvision.utils.make_grid(torch.stack(exmp_imgs, dim=0), nrow=4, normalize=True, pad_value=0.5)\nimg_grid = img_grid.permute(1, 2, 0)\n\nplt.figure(figsize=(8, 8))\nplt.title(\"FashionMNIST examples\")\nplt.imshow(img_grid)\nplt.axis(\"off\")\nplt.show()\nplt.close()","46017daa":"def visualize_gradients(net, color=\"C0\"):\n    \"\"\"\n    Args:\n        net: Object of class BaseNetwork\n        color: Color in which we want to visualize the histogram (for easier separation of activation functions)\n    \"\"\"\n    net.eval()\n    small_loader = data.DataLoader(train_set, batch_size=256, shuffle=False)\n    imgs, labels = next(iter(small_loader))\n    imgs, labels = imgs.to(device), labels.to(device)\n\n    # Pass one batch through the network, and calculate the gradients for the weights\n    net.zero_grad()\n    preds = net(imgs)\n    loss = F.cross_entropy(preds, labels)\n    loss.backward()\n    # We limit our visualization to the weight parameters and exclude the bias to reduce the number of plots\n    grads = {\n        name: params.grad.data.view(-1).cpu().clone().numpy()\n        for name, params in net.named_parameters()\n        if \"weight\" in name\n    }\n    net.zero_grad()\n\n    # Plotting\n    columns = len(grads)\n    fig, ax = plt.subplots(1, columns, figsize=(columns * 3.5, 2.5))\n    fig_index = 0\n    for key in grads:\n        key_ax = ax[fig_index % columns]\n        sns.histplot(data=grads[key], bins=30, ax=key_ax, color=color, kde=True)\n        key_ax.set_title(str(key))\n        key_ax.set_xlabel(\"Grad magnitude\")\n        fig_index += 1\n    fig.suptitle(\n        f\"Gradient magnitude distribution for activation function {net.config['act_fn']['name']}\", fontsize=14, y=1.05\n    )\n    fig.subplots_adjust(wspace=0.45)\n    plt.show()\n    plt.close()","cdbd7faf":"# Seaborn prints warnings if histogram has small values. We can ignore them for now\nwarnings.filterwarnings(\"ignore\")\n# Create a plot for every activation function\nfor i, act_fn_name in enumerate(act_fn_by_name):\n    # Setting the seed ensures that we have the same weight initialization for each activation function\n    set_seed(42)\n    act_fn = act_fn_by_name[act_fn_name]()\n    net_actfn = BaseNetwork(act_fn=act_fn).to(device)\n    visualize_gradients(net_actfn, color=f\"C{i}\")","3f184bcf":"def train_model(net, model_name, max_epochs=50, patience=7, batch_size=256, overwrite=False):\n    \"\"\"Train a model on the training set of FashionMNIST.\n\n    Args:\n        net: Object of BaseNetwork\n        model_name: (str) Name of the model, used for creating the checkpoint names\n        max_epochs: Number of epochs we want to (maximally) train for\n        patience: If the performance on the validation set has not improved for #patience epochs, we stop training early\n        batch_size: Size of batches used in training\n        overwrite: Determines how to handle the case when there already exists a checkpoint. If True, it will be overwritten. Otherwise, we skip training.\n    \"\"\"\n    file_exists = os.path.isfile(_get_model_file(CHECKPOINT_PATH, model_name))\n    if file_exists and not overwrite:\n        print(\"Model file already exists. Skipping training...\")\n    else:\n        if file_exists:\n            print(\"Model file exists, but will be overwritten...\")\n\n        # Defining optimizer, loss and data loader\n        optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9)  # Default parameters, feel free to change\n        loss_module = nn.CrossEntropyLoss()\n        train_loader_local = data.DataLoader(\n            train_set, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True\n        )\n\n        val_scores = []\n        best_val_epoch = -1\n        for epoch in range(max_epochs):\n            ############\n            # Training #\n            ############\n            net.train()\n            true_preds, count = 0.0, 0\n            for imgs, labels in tqdm(train_loader_local, desc=f\"Epoch {epoch+1}\", leave=False):\n                imgs, labels = imgs.to(device), labels.to(device)  # To GPU\n                optimizer.zero_grad()  # Zero-grad can be placed anywhere before \"loss.backward()\"\n                preds = net(imgs)\n                loss = loss_module(preds, labels)\n                loss.backward()\n                optimizer.step()\n                # Record statistics during training\n                true_preds += (preds.argmax(dim=-1) == labels).sum()\n                count += labels.shape[0]\n            train_acc = true_preds \/ count\n\n            ##############\n            # Validation #\n            ##############\n            val_acc = test_model(net, val_loader)\n            val_scores.append(val_acc)\n            print(\n                f\"[Epoch {epoch+1}] Training accuracy: {train_acc*100.0:05.2f}%, Validation accuracy: {val_acc*100.0:05.2f}%\"\n            )\n\n            if len(val_scores) == 1 or val_acc > val_scores[best_val_epoch]:\n                print(\"\\t   (New best performance, saving model...)\")\n                save_model(net, CHECKPOINT_PATH, model_name)\n                best_val_epoch = epoch\n            elif best_val_epoch <= epoch - patience:\n                print(f\"Early stopping due to no improvement over the last {patience} epochs\")\n                break\n\n        # Plot a curve of the validation accuracy\n        plt.plot([i for i in range(1, len(val_scores) + 1)], val_scores)\n        plt.xlabel(\"Epochs\")\n        plt.ylabel(\"Validation accuracy\")\n        plt.title(f\"Validation performance of {model_name}\")\n        plt.show()\n        plt.close()\n\n    load_model(CHECKPOINT_PATH, model_name, net=net)\n    test_acc = test_model(net, test_loader)\n    print((f\" Test accuracy: {test_acc*100.0:4.2f}% \").center(50, \"=\") + \"\\n\")\n    return test_acc\n\n\ndef test_model(net, data_loader):\n    \"\"\"Test a model on a specified dataset.\n\n    Args:\n        net: Trained model of type BaseNetwork\n        data_loader: DataLoader object of the dataset to test on (validation or test)\n    \"\"\"\n    net.eval()\n    true_preds, count = 0.0, 0\n    for imgs, labels in data_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n        with torch.no_grad():\n            preds = net(imgs).argmax(dim=-1)\n            true_preds += (preds == labels).sum().item()\n            count += labels.shape[0]\n    test_acc = true_preds \/ count\n    return test_acc","ce315e71":"for act_fn_name in act_fn_by_name:\n    print(f\"Training BaseNetwork with {act_fn_name} activation...\")\n    set_seed(42)\n    act_fn = act_fn_by_name[act_fn_name]()\n    net_actfn = BaseNetwork(act_fn=act_fn).to(device)\n    train_model(net_actfn, f\"FashionMNIST_{act_fn_name}\", overwrite=False)","af6b6e24":"def visualize_activations(net, color=\"C0\"):\n    activations = {}\n\n    net.eval()\n    small_loader = data.DataLoader(train_set, batch_size=1024)\n    imgs, labels = next(iter(small_loader))\n    with torch.no_grad():\n        layer_index = 0\n        imgs = imgs.to(device)\n        imgs = imgs.view(imgs.size(0), -1)\n        # We need to manually loop through the layers to save all activations\n        for layer_index, layer in enumerate(net.layers[:-1]):\n            imgs = layer(imgs)\n            activations[layer_index] = imgs.view(-1).cpu().numpy()\n\n    # Plotting\n    columns = 4\n    rows = math.ceil(len(activations) \/ columns)\n    fig, ax = plt.subplots(rows, columns, figsize=(columns * 2.7, rows * 2.5))\n    fig_index = 0\n    for key in activations:\n        key_ax = ax[fig_index \/\/ columns][fig_index % columns]\n        sns.histplot(data=activations[key], bins=50, ax=key_ax, color=color, kde=True, stat=\"density\")\n        key_ax.set_title(f\"Layer {key} - {net.layers[key].__class__.__name__}\")\n        fig_index += 1\n    fig.suptitle(f\"Activation distribution for activation function {net.config['act_fn']['name']}\", fontsize=14)\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n    plt.show()\n    plt.close()","8eb45502":"for i, act_fn_name in enumerate(act_fn_by_name):\n    net_actfn = load_model(model_path=CHECKPOINT_PATH, model_name=f\"FashionMNIST_{act_fn_name}\").to(device)\n    visualize_activations(net_actfn, color=f\"C{i}\")","58fbec97":"@torch.no_grad()\ndef measure_number_dead_neurons(net):\n    \"\"\"Function to measure the number of dead neurons in a trained neural network.\n\n    For each neuron, we create a boolean variable initially set to 1. If it has an activation unequals 0 at any time, we\n    set this variable to 0. After running through the whole training set, only dead neurons will have a 1.\n    \"\"\"\n    neurons_dead = [\n        torch.ones(layer.weight.shape[0], device=device, dtype=torch.bool)\n        for layer in net.layers[:-1]\n        if isinstance(layer, nn.Linear)\n    ]  # Same shapes as hidden size in BaseNetwork\n\n    net.eval()\n    for imgs, labels in tqdm(train_loader, leave=False):  # Run through whole training set\n        layer_index = 0\n        imgs = imgs.to(device)\n        imgs = imgs.view(imgs.size(0), -1)\n        for layer in net.layers[:-1]:\n            imgs = layer(imgs)\n            if isinstance(layer, ActivationFunction):\n                # Are all activations == 0 in the batch, and we did not record the opposite in the last batches?\n                neurons_dead[layer_index] = torch.logical_and(neurons_dead[layer_index], (imgs == 0).all(dim=0))\n                layer_index += 1\n    number_neurons_dead = [t.sum().item() for t in neurons_dead]\n    print(\"Number of dead neurons:\", number_neurons_dead)\n    print(\n        \"In percentage:\",\n        \", \".join(\n            [f\"{(100.0 * num_dead \/ tens.shape[0]):4.2f}%\" for tens, num_dead in zip(neurons_dead, number_neurons_dead)]\n        ),\n    )","17c10329":"# \u9996\u5148\uff0c\u6211\u4eec\u53ef\u4ee5\u6d4b\u91cf\u672a\u7ecf\u8bad\u7ec3\u7684\u7f51\u7edc\u7684\u6b7b\u4ea1\u795e\u7ecf\u5143\u6570\u91cf\uff1a\nset_seed(42)\nnet_relu = BaseNetwork(act_fn=ReLU()).to(device)\nmeasure_number_dead_neurons(net_relu)","9e58d4d5":"net_relu = load_model(model_path=CHECKPOINT_PATH, model_name=\"FashionMNIST_relu\").to(device)\nmeasure_number_dead_neurons(net_relu)","b6f9032e":"set_seed(42)\nnet_relu = BaseNetwork(\n    act_fn=ReLU(),\n    hidden_sizes=[256, 256, 256, 256, 256, 128, 128, 128, 128, 128],\n).to(device)\nmeasure_number_dead_neurons(net_relu)","ae2a6996":"set_seed(42)\nnet_relu = BaseNetwork(\n    act_fn=Swish(),\n    hidden_sizes=[256, 256, 256, 256, 256, 128, 128, 128, 128, 128],\n).to(device)\nmeasure_number_dead_neurons(net_relu)","51337f4c":"set_seed(42)\nnet_relu = BaseNetwork(\n    act_fn=Mish(),\n    hidden_sizes=[256, 256, 256, 256, 256, 128, 128, 128, 128, 128],\n).to(device)\nmeasure_number_dead_neurons(net_relu)","235ed486":"\u6bcf\u4e2a\u6fc0\u6d3b\u51fd\u6570\u90fd\u5c06\u662f\u4e00\u4e2ann.Module\uff0c\u4ee5\u4fbf\u6211\u4eec\u53ef\u4ee5\u5c06\u5b83\u4eec\u5f88\u597d\u5730\u96c6\u6210\u5230\u7f51\u7edc\u4e2d\u3002\u6211\u4eec\u5c06\u4f7f\u7528config\u5b57\u5178\u6765\u5b58\u50a8\u4e00\u4e9b\u6fc0\u6d3b\u51fd\u6570\u7684\u53ef\u8c03\u53c2\u6570\u3002\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86\u4e24\u4e2a\u4ecd\u7136\u5e38\u7528\u4e8e\u5404\u79cd\u4efb\u52a1\u7684\u201c\u6700\u53e4\u8001\u201d\u7684\u6fc0\u6d3b\u51fd\u6570\uff1asigmoid \u548c tanh\u3002sigmoid \u548c tanh \u6fc0\u6d3b\u4e5f\u53ef\u4ee5\u4f5c\u4e3a PyTorch \u51fd\u6570 ( torch.sigmoid, torch.tanh) \u6216\u6a21\u5757 ( nn.Sigmoid, nn.Tanh) \u627e\u5230\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u624b\u52a8\u5b9e\u73b0\u5b83\u4eec\uff1a\n\n- sigmoid\n$$\nf(x) = \\frac{1}{1 + e^{-x}}\n$$\n\n- tanh\n$$\nf(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n$$","6d40026c":"# 2 \u53ef\u89c6\u5316\u6fc0\u6d3b\u51fd\u6570","c65438ee":"sigmoid \u6fc0\u6d3b\u51fd\u6570\u663e\u793a\u51fa\u660e\u663e\u7684\u4e0d\u826f\u884c\u4e3a\u3002\u867d\u7136\u8f93\u51fa\u5c42\u7684\u68af\u5ea6\u975e\u5e38\u5927\uff0c\u9ad8\u8fbe 0.1\uff0c\u4f46\u8f93\u5165\u5c42\u5728\u6240\u6709\u6fc0\u6d3b\u51fd\u6570\u4e2d\u7684\u68af\u5ea6\u8303\u6570\u6700\u4f4e\uff0c\u53ea\u6709 1e-5\u3002\u8fd9\u662f\u7531\u4e8e\u5176 1\/4 \u7684\u6700\u5927\u68af\u5ea6\u5f88\u5c0f\uff0c\u5e76\u4e14\u5728\u6b64\u8bbe\u7f6e\u4e2d\u4e0d\u53ef\u80fd\u5728\u6240\u6709\u5c42\u4e2d\u627e\u5230\u5408\u9002\u7684\u5b66\u4e60\u7387\u3002\u6240\u6709\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\u5728\u6240\u6709\u5c42\u4e2d\u90fd\u663e\u793a\u51fa\u76f8\u4f3c\u7684\u68af\u5ea6\u8303\u6570\u3002\u6709\u8da3\u7684\u662f\uff0cReLU \u6fc0\u6d3b\u5728 0 \u9644\u8fd1\u6709\u4e00\u4e2a\u5c16\u5cf0\uff0c\u8fd9\u662f\u7531\u5de6\u4fa7\u7684\u96f6\u90e8\u5206\u548c\u6b7b\u795e\u7ecf\u5143\u5f15\u8d77\u7684\uff08\u6211\u4eec\u7a0d\u540e\u4f1a\u4ed4\u7ec6\u7814\u7a76\uff09\u3002\n\n\u8bf7\u6ce8\u610f\uff0c\u9664\u4e86\u6fc0\u6d3b\u4e4b\u5916\uff0c\u6743\u91cd\u53c2\u6570\u7684\u521d\u59cb\u5316\u4e5f\u5f88\u5173\u952e\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cPyTorch\u4f7f\u7528\u51ef\u660e\u521d\u59cb\u5316\u4e3a\u53cc\u66f2\u6b63\u5207\u6fc0\u6d3b\u4f18\u5316\u7ebf\u6027\u5c42\u3002","3efa741f":"\u5728\u5b9e\u73b0\u548c\u53ef\u89c6\u5316\u6fc0\u6d3b\u51fd\u6570\u4e4b\u540e\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u6df1\u5165\u4e86\u89e3\u5b83\u4eec\u7684\u6548\u679c\u3002\u6211\u4eec\u901a\u8fc7\u4f7f\u7528\u5728FashionMNIST \u4e0a\u8bad\u7ec3\u7684\u7b80\u5355\u795e\u7ecf\u7f51\u7edc\u6765\u505a\u5230\u8fd9\u4e00\u70b9\uff0c\u5e76\u68c0\u67e5\u6a21\u578b\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5305\u62ec\u6027\u80fd\u548c\u68af\u5ea6\u6d41\u3002\n\n\u9996\u5148\uff0c\u8ba9\u6211\u4eec\u5efa\u7acb\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u3002\u6240\u9009\u62e9\u7684\u7f51\u7edc\u5c06\u56fe\u50cf\u89c6\u4e3a\u4e00\u7ef4\u5f20\u91cf\uff0c\u5e76\u63a8\u52a8\u5b83\u4eec\u901a\u8fc7\u4e00\u7cfb\u5217\u7ebf\u6027\u5c42\u548c\u6307\u5b9a\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u968f\u610f\u5c1d\u8bd5\u5176\u4ed6\u7f51\u7edc\u67b6\u6784\u3002","1cb65be3":"\u4f5c\u4e3a\u7b2c\u4e00\u6b65\uff0c\u6211\u4eec\u5c06\u81ea\u5df1\u5b9e\u73b0\u4e00\u4e9b\u5e38\u89c1\u7684\u6fc0\u6d3b\u51fd\u6570\u3002\u5f53\u7136\uff0c\u5b83\u4eec\u4e2d\u7684\u5927\u90e8\u5206\u4e5f\u53ef\u4ee5\u5728torch.nn\u5305\u4e2d\u627e\u5230\uff08\u8bf7\u53c2\u9605\u6587\u6863\u4ee5\u83b7\u5f97\u6982\u8ff0\uff09\u3002\u4f46\u662f\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u548c\u6d1e\u5bdf\uff0c\u6211\u4eec\u5c06\u5728\u8fd9\u91cc\u7f16\u5199\u81ea\u5df1\u7684\u51fd\u6570\u3002\n\n\u4e3a\u4e86\u66f4\u8f7b\u677e\u5730\u6bd4\u8f83\u5404\u79cd\u6fc0\u6d3b\u51fd\u6570\uff0c\u6211\u4eec\u9996\u5148\u5b9a\u4e49\u4e00\u4e2a\u57fa\u7c7b\uff0c\u6211\u4eec\u672a\u6765\u7684\u6240\u6709\u6a21\u5757\u90fd\u5c06\u4ece\u8be5\u57fa\u7c7b\u7ee7\u627f\uff1a","1ac4679d":"# 7 \u5728 ReLU \u7f51\u7edc\u4e2d\u5bfb\u627e\u6b7b\u795e\u7ecf\u5143\n\nReLU \u6fc0\u6d3b\u7684\u4e00\u4e2a\u5df2\u77e5\u7f3a\u70b9\u662f\u201c\u6b7b\u795e\u7ecf\u5143\u201d\u7684\u51fa\u73b0\uff0c\u5373\u5bf9\u4e8e\u4efb\u4f55\u8bad\u7ec3\u8f93\u5165\u90fd\u6ca1\u6709\u68af\u5ea6\u7684\u795e\u7ecf\u5143\u3002\u6b7b\u795e\u7ecf\u5143\u7684\u95ee\u9898\u5728\u4e8e\uff0c\u7531\u4e8e\u8be5\u5c42\u6ca1\u6709\u63d0\u4f9b\u68af\u5ea6\uff0c\u6211\u4eec\u65e0\u6cd5\u5728\u524d\u4e00\u5c42\u8bad\u7ec3\u8be5\u795e\u7ecf\u5143\u7684\u53c2\u6570\u4ee5\u83b7\u5f97\u9664\u96f6\u4e4b\u5916\u7684\u8f93\u51fa\u503c\u3002\u4e3a\u4e86\u4f7f\u6b7b\u795e\u7ecf\u5143\u53d1\u751f\uff0cReLU \u4e4b\u524d\u7ebf\u6027\u5c42\u7684\u7279\u5b9a\u795e\u7ecf\u5143\u7684\u8f93\u51fa\u503c\u5bf9\u4e8e\u6240\u6709\u8f93\u5165\u56fe\u50cf\u5fc5\u987b\u4e3a\u8d1f\u3002\u8003\u8651\u5230\u6211\u4eec\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u62e5\u6709\u5927\u91cf\u795e\u7ecf\u5143\uff0c\u8fd9\u79cd\u60c5\u51b5\u4e0d\u592a\u53ef\u80fd\u53d1\u751f\u3002\n\n\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u662f\u4e00\u4e2a\u591a\u5927\u7684\u95ee\u9898\uff0c\u5f53\u6211\u4eec\u9700\u8981\u5c0f\u5fc3\u65f6\uff0c\u6211\u4eec\u5c06\u6d4b\u91cf\u4e0d\u540c\u7f51\u7edc\u6709\u591a\u5c11\u6b7b\u795e\u7ecf\u5143\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86\u4e00\u4e2a\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5728\u6574\u4e2a\u8bad\u7ec3\u96c6\u4e0a\u8fd0\u884c\u7f51\u7edc\uff0c\u5e76\u8bb0\u5f55\u6240\u6709\u6570\u636e\u70b9\u7684\u795e\u7ecf\u5143\u662f\u5426\u6070\u597d\u4e3a 0\uff1a","9311af9a":"\u4ee5\u4e0b\u5355\u5143\u683c\u4e0b\u8f7d\u6211\u4eec\u5c06\u5728\u672c\u7b14\u8bb0\u672c\u4e2d\u4f7f\u7528\u7684\u6240\u6709\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u8fd9\u4e9b\u6587\u4ef6\u5b58\u50a8\u5728\u5355\u72ec\u7684\u5b58\u50a8\u5e93\u4e2d\u4ee5\u51cf\u5c11\u7b14\u8bb0\u672c\u5b58\u50a8\u5e93\u7684\u5927\u5c0f\uff0c\u7279\u522b\u662f\u7528\u4e8e\u5728 ReadTheDocs \u4e0a\u6784\u5efa\u6587\u6863\u3002","bc7f0268":"\u6211\u4eec\u8bbe\u7f6e\u4e86\u6570\u636e\u96c6\uff0c\u5373FashionMNIST\u3002FashionMNIST\u662fMNIST\u7684\u66f4\u590d\u6742\u7248\u672c\uff0c\u5305\u542b\u8863\u670d\u7684\u9ed1\u767d\u56fe\u50cf\u800c\u4e0d\u662f\u6570\u5b57\u3002\u8fd910\u4e2a\u7c7b\u5305\u62ec\u88e4\u5b50\u3001\u5916\u5957\u3001\u978b\u5b50\u3001\u5305\u5305\u7b49\u7b49\u3002\u4e3a\u4e86\u52a0\u8f7d\u8fd9\u4e2a\u6570\u636e\u96c6\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u53e6\u4e00\u4e2aPyTorch\u5305\uff0c\u5373torchvision\uff08\u6587\u6863\uff09\u3002\u8be5torchvision\u8f6f\u4ef6\u5305\u7531\u6d41\u884c\u7684\u6570\u636e\u96c6\u3001\u6a21\u578b\u67b6\u6784\u548c\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u5e38\u89c1\u56fe\u50cf\u8f6c\u6362\u7ec4\u6210\u3002\u6211\u4eec\u5c06\u5728\u672c\u8bfe\u7a0b\u4e2d\u7684\u8bb8\u591a\u7b14\u8bb0\u672c\u4e2d\u4f7f\u7528\u8be5\u5305\u6765\u7b80\u5316\u6211\u4eec\u7684\u6570\u636e\u96c6\u5904\u7406\u3002\n\n\u8ba9\u6211\u4eec\u52a0\u8f7d\u4e0b\u9762\u7684\u6570\u636e\u96c6\uff0c\u5e76\u53ef\u89c6\u5316\u4e00\u4e9b\u56fe\u50cf\u4ee5\u4e86\u89e3\u6570\u636e\u3002","a9e8cc70":"\u53e6\u4e00\u4e2a\u5141\u8bb8\u8bad\u7ec3\u66f4\u6df1\u7f51\u7edc\u7684\u6d41\u884c\u6fc0\u6d3b\u51fd\u6570\u662f\u6574\u6d41\u7ebf\u6027\u5355\u5143 (ReLU)\u3002\u5c3d\u7ba1\u5b83\u662f\u5206\u6bb5\u7ebf\u6027\u51fd\u6570\u7684\u7b80\u5355\u6027\uff0c\u4f46\u4e0e sigmoid \u548c tanh \u76f8\u6bd4\uff0cReLU \u6709\u4e00\u4e2a\u4e3b\u8981\u4f18\u70b9\uff1a\u9488\u5bf9\u5927\u8303\u56f4\u503c\u7684\u5f3a\u5927\u3001\u7a33\u5b9a\u7684\u68af\u5ea6\u3002\u57fa\u4e8e\u8fd9\u4e2a\u60f3\u6cd5\uff0c\u4eba\u4eec\u63d0\u51fa\u4e86\u5f88\u591a ReLU \u7684\u53d8\u4f53\uff0c\u5176\u4e2d\u6211\u4eec\u5c06\u5b9e\u73b0\u4ee5\u4e0b\u4e09\u4e2a\uff1aLeakyReLU\u3001ELU \u548c Swish\u3002LeakyReLU \u7528\u8f83\u5c0f\u7684\u659c\u7387\u66ff\u6362\u8d1f\u90e8\u5206\u4e2d\u7684\u96f6\u8bbe\u7f6e\uff0c\u4ee5\u5141\u8bb8\u68af\u5ea6\u5728\u8f93\u5165\u7684\u8fd9\u4e00\u90e8\u5206\u4e2d\u4e5f\u6d41\u52a8\u3002\u7c7b\u4f3c\u5730\uff0cELU \u7528\u6307\u6570\u8870\u51cf\u66ff\u6362\u8d1f\u90e8\u5206\u3002\u7b2c\u4e09\u4e2a\uff0c\u6700\u8fd1\u63d0\u51fa\u7684\u6fc0\u6d3b\u51fd\u6570\u662f Swish\uff0c\u5b83\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u5927\u578b\u5b9e\u9a8c\u7684\u7ed3\u679c\uff0c\u76ee\u7684\u662f\u5bfb\u627e\u201c\u6700\u4f73\u201d\u6fc0\u6d3b\u51fd\u6570\u3002\u4e0e\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\u76f8\u6bd4\uff0cSwish \u65e2\u5e73\u6ed1\u53c8\u975e\u5355\u8c03\uff08\u5373\u5305\u542b\u68af\u5ea6\u4e2d\u7684\u7b26\u53f7\u53d8\u5316\uff09\u3002\u8fd9\u5df2\u88ab\u8bc1\u660e\u53ef\u4ee5\u9632\u6b62\u6807\u51c6 ReLU \u6fc0\u6d3b\u4e2d\u7684\u6b7b\u795e\u7ecf\u5143\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u6df1\u5ea6\u7f51\u7edc\u3002\u5982\u679c\u6709\u5174\u8da3\uff0c\u53ef\u4ee5\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u627e\u5230\u6709\u5173 Swish \u597d\u5904\u7684\u66f4\u8be6\u7ec6\u8ba8\u8bba\u672c\u6587[1]\u3002\n\n\u4e0b\u9762\u6211\u4eec\u6765\u5b9e\u73b0\u56db\u4e2a\u6fc0\u6d3b\u51fd\u6570\uff1a","f01e8c80":"# 4 \u68af\u5ea6\u6d41\u53ef\u89c6\u5316\n\n\u5982\u524d\u6240\u8ff0\uff0c\u6fc0\u6d3b\u51fd\u6570\u7684\u4e00\u4e2a\u91cd\u8981\u65b9\u9762\u662f\u5b83\u4eec\u5982\u4f55\u901a\u8fc7\u7f51\u7edc\u4f20\u64ad\u68af\u5ea6\u3002\u60f3\u8c61\u4e00\u4e0b\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u8d85\u8fc7 50 \u5c42\u7684\u975e\u5e38\u6df1\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u8f93\u5165\u5c42\uff08\u5373\u7b2c\u4e00\u5c42\uff09\u7684\u68af\u5ea6\u5df2\u7ecf\u8d85\u8fc7\u4e86\u6fc0\u6d3b\u51fd\u6570\u7684 50 \u500d\uff0c\u4f46\u6211\u4eec\u4ecd\u7136\u5e0c\u671b\u5b83\u4eec\u5177\u6709\u5408\u7406\u7684\u5927\u5c0f\u3002\u5982\u679c\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u7684\u68af\u5ea6\uff08\u5728\u9884\u671f\u4e2d\uff09\u8fdc\u5c0f\u4e8e 1\uff0c\u6211\u4eec\u7684\u68af\u5ea6\u5c06\u6d88\u5931\uff0c\u76f4\u5230\u5b83\u4eec\u5230\u8fbe\u8f93\u5165\u5c42\u3002\u5982\u679c\u901a\u8fc7\u6fc0\u6d3b\u51fd\u6570\u7684\u68af\u5ea6\u5927\u4e8e 1\uff0c\u5219\u68af\u5ea6\u5448\u6307\u6570\u589e\u957f\u5e76\u53ef\u80fd\u7206\u70b8\u3002\n\n\u4e3a\u4e86\u4e86\u89e3\u6bcf\u4e2a\u6fc0\u6d3b\u51fd\u6570\u5982\u4f55\u5f71\u54cd\u68af\u5ea6\uff0c\u6211\u4eec\u53ef\u4ee5\u67e5\u770b\u4e00\u4e2a\u65b0\u521d\u59cb\u5316\u7684\u7f51\u7edc\u5e76\u6d4b\u91cf\u4e00\u6279 256 \u5f20\u56fe\u50cf\u7684\u6bcf\u4e2a\u53c2\u6570\u7684\u68af\u5ea6\uff1a","ff9f8320":"\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u7ec4\u6570\u636e\u52a0\u8f7d\u5668\uff0c\u7a0d\u540e\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u7528\u4e8e\u5404\u79cd\u76ee\u7684\u3002\u8bf7\u6ce8\u610f\uff0c\u5bf9\u4e8e\u5b9e\u9645\u8bad\u7ec3\u6a21\u578b\uff0c\u6211\u4eec\u5c06\u4f7f\u7528\u5177\u6709\u8f83\u5c0f\u6279\u91cf\u5927\u5c0f\u7684\u4e0d\u540c\u6570\u636e\u52a0\u8f7d\u5668\u3002","ae0b6e9a":"# 3 \u5206\u6790\u6fc0\u6d3b\u51fd\u6570\u7684\u6548\u679c","14b92c75":"\u6beb\u4e0d\u5947\u602a\uff0c\u4f7f\u7528 sigmoid \u6fc0\u6d3b\u51fd\u6570\u7684\u6a21\u578b\u663e\u793a\u5931\u8d25\u5e76\u4e14\u4e0d\u4f1a\u63d0\u9ad8\u968f\u673a\u6027\u80fd\uff0810 \u4e2a\u7c7b => 1\/10 \u968f\u673a\u673a\u4f1a\uff09\u3002\n\n\u6240\u6709\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\u90fd\u83b7\u5f97\u4e86\u76f8\u4f3c\u7684\u6027\u80fd\u3002\u4e3a\u4e86\u5f97\u5230\u66f4\u51c6\u786e\u7684\u7ed3\u8bba\uff0c\u6211\u4eec\u5fc5\u987b\u4e3a\u591a\u4e2a\u79cd\u5b50\u8bad\u7ec3\u6a21\u578b\u5e76\u67e5\u770b\u5e73\u5747\u503c\u3002\u7136\u800c\uff0c\u201c\u6700\u4f73\u201d\u6fc0\u6d3b\u51fd\u6570\u8fd8\u53d6\u51b3\u4e8e\u8bb8\u591a\u5176\u4ed6\u56e0\u7d20\uff08\u9690\u85cf\u5927\u5c0f\u3001\u5c42\u6570\u3001\u5c42\u7c7b\u578b\u3001\u4efb\u52a1\u3001\u6570\u636e\u96c6\u3001\u4f18\u5316\u5668\u3001\u5b66\u4e60\u7387\u7b49\uff09\uff0c\u56e0\u6b64\u5f7b\u5e95\u7684\u7f51\u683c\u641c\u7d22\u5728\u6211\u4eec\u7684\u6848\u4ef6\u3002\u5728\u6587\u732e\u4e2d\uff0c\u5df2\u8bc1\u660e\u4e0e\u6df1\u5ea6\u7f51\u7edc\u914d\u5408\u826f\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u662f\u6211\u4eec\u5728\u8fd9\u91cc\u8bd5\u9a8c\u7684\u6240\u6709\u7c7b\u578b\u7684 ReLU \u51fd\u6570\uff0c\u7279\u5b9a\u7f51\u7edc\u4e2d\u7684\u7279\u5b9a\u6fc0\u6d3b\u51fd\u6570\u7684\u589e\u76ca\u5f88\u5c0f\u3002","6973955c":"\u73b0\u5728\u6211\u4eec\u53ef\u89c6\u5316\u6fc0\u6d3b\u51fd\u6570\uff0c\u5305\u62ec\u5b83\u4eec\u7684\u68af\u5ea6\uff1a","61b34402":"# 6 \u53ef\u89c6\u5316\u6fc0\u6d3b\u5206\u5e03\n\n\u8bad\u7ec3\u6a21\u578b\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u67e5\u770b\u6a21\u578b\u5185\u90e8\u7684\u5b9e\u9645\u6fc0\u6d3b\u503c\u3002\u4f8b\u5982\uff0c\u5728 ReLU \u4e2d\u6709\u591a\u5c11\u795e\u7ecf\u5143\u8bbe\u7f6e\u4e3a\u96f6\uff1f\u6211\u4eec\u5728\u54ea\u91cc\u53ef\u4ee5\u627e\u5230 Tanh \u7684\u5927\u90e8\u5206\u4ef7\u503c\uff1f\u4e3a\u4e86\u56de\u7b54\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u7f16\u5199\u4e00\u4e2a\u7b80\u5355\u7684\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u91c7\u7528\u7ecf\u8fc7\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u6279\u56fe\u50cf\uff0c\u5e76\u7ed8\u5236\u7f51\u7edc\u5185\u90e8\u6fc0\u6d3b\u7684\u76f4\u65b9\u56fe\uff1a","e773e878":"\u6dfb\u52a0\u4e86\u52a0\u8f7d\u548c\u4fdd\u5b58\u6a21\u578b\u7684\u529f\u80fd\u3002\u8d85\u53c2\u6570\u5b58\u50a8\u5728\u914d\u7f6e\u6587\u4ef6\uff08\u7b80\u5355\u7684 json \u6587\u4ef6\uff09\u4e2d\uff1a","27ca4b93":"# \u7ed3\u8bba\n\u5728\u672cnotebook\u4e2d\uff0c\u6211\u4eec\u56de\u987e\u4e86\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4e00\u7ec4\u516d\u4e2a\u6fc0\u6d3b\u51fd\u6570\uff08sigmoid\u3001tanh\u3001ReLU\u3001LeakyReLU\u3001ELU \u548c Swish\uff09\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b83\u4eec\u5982\u4f55\u5f71\u54cd\u8de8\u5c42\u7684\u68af\u5ea6\u5206\u5e03\u3002Sigmoid \u503e\u5411\u4e8e\u4f7f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5931\u8d25\uff0c\u56e0\u4e3a\u5b83\u63d0\u4f9b\u7684\u6700\u9ad8\u68af\u5ea6\u4e3a 0.25\uff0c\u5bfc\u81f4\u65e9\u671f\u5c42\u7684\u68af\u5ea6\u6d88\u5931\u3002\u6240\u6709\u57fa\u4e8e ReLU \u7684\u6fc0\u6d3b\u51fd\u6570\u90fd\u8868\u73b0\u5f97\u5f88\u597d\uff0c\u800c\u4e14\u9664\u4e86\u539f\u59cb\u7684 ReLU \u4e4b\u5916\uff0c\u6ca1\u6709\u795e\u7ecf\u5143\u6b7b\u4ea1\u7684\u95ee\u9898\u3002\u5728\u5b9e\u73b0\u81ea\u5df1\u7684\u795e\u7ecf\u7f51\u7edc\u65f6\uff0c\u5efa\u8bae\u4ece\u57fa\u4e8e ReLU \u7684\u7f51\u7edc\u5165\u624b\uff0c\u6839\u636e\u7f51\u7edc\u7684\u5c5e\u6027\u9009\u62e9\u5177\u4f53\u7684\u6fc0\u6d3b\u51fd\u6570\u3002","a79dfa2f":"\u6b7b\u795e\u7ecf\u5143\u7684\u6570\u91cf\u5728\u540e\u9762\u7684\u5c42\u4e2d\u786e\u5b9e\u51cf\u5c11\u4e86\u3002\u7136\u800c\uff0c\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u6b7b\u795e\u7ecf\u5143\u5728\u8f93\u5165\u5c42\u5c24\u5176\u6210\u95ee\u9898\u3002\u7531\u4e8e\u8f93\u5165\u4e0d\u4f1a\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u800c\u6539\u53d8\uff08\u8bad\u7ec3\u96c6\u4fdd\u6301\u539f\u6837\uff09\uff0c\u56e0\u6b64\u8bad\u7ec3\u7f51\u7edc\u65e0\u6cd5\u4f7f\u8fd9\u4e9b\u795e\u7ecf\u5143\u6062\u590d\u6d3b\u52a8\u72b6\u6001\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u8f93\u5165\u6570\u636e\u901a\u5e38\u5177\u6709\u8db3\u591f\u9ad8\u7684\u6807\u51c6\u504f\u5dee\uff0c\u4ee5\u964d\u4f4e\u795e\u7ecf\u5143\u6b7b\u4ea1\u7684\u98ce\u9669\u3002\n\n\u6700\u540e\uff0c\u6211\u4eec\u68c0\u67e5\u6b7b\u795e\u7ecf\u5143\u7684\u6570\u91cf\u5982\u4f55\u968f\u7740\u5c42\u6df1\u5ea6\u7684\u589e\u52a0\u800c\u53d8\u5316\u3002\u4f8b\u5982\uff0c\u8ba9\u6211\u4eec\u91c7\u7528\u4ee5\u4e0b 10 \u5c42\u795e\u7ecf\u7f51\u7edc\uff1a","8fbfe27b":"# 1 \u5e38\u7528\u6fc0\u6d3b\u51fd\u6570","2b8f6ac4":"\u6211\u4eec\u770b\u5230\u53ea\u6709\u5c11\u91cf\u795e\u7ecf\u5143\u6b7b\u4ea1\uff0c\u4f46\u5b83\u4eec\u968f\u7740\u5c42\u7684\u6df1\u5ea6\u800c\u589e\u52a0\u3002\u7136\u800c\uff0c\u8fd9\u5bf9\u4e8e\u6211\u4eec\u62e5\u6709\u7684\u5c11\u91cf\u6b7b\u795e\u7ecf\u5143\u6765\u8bf4\u4e0d\u662f\u95ee\u9898\uff0c\u56e0\u4e3a\u7531\u4e8e\u524d\u4e00\u5c42\u6743\u91cd\u7684\u66f4\u65b0\u800c\u6539\u53d8\u4e86\u540e\u4e00\u5c42\u7684\u8f93\u5165\u3002\u56e0\u6b64\uff0c\u540e\u9762\u5c42\u4e2d\u7684\u6b7b\u795e\u7ecf\u5143\u53ef\u80fd\u4f1a\u518d\u6b21\u201c\u6d3b\u8dc3\u201d\/\u6d3b\u8dc3\u3002\n\n\u5bf9\u4e8e\u7ecf\u8fc7\u8bad\u7ec3\u7684\u7f51\u7edc\uff08\u5177\u6709\u76f8\u540c\u7684\u521d\u59cb\u5316\uff09\uff0c\u8fd9\u770b\u8d77\u6765\u5982\u4f55\uff1f","f2f7216f":"\u4e3a\u4e86\u4ee5\u540e\u7684\u4f7f\u7528\uff0c\u6211\u4eec\u5c06\u6240\u6709\u6fc0\u6d3b\u51fd\u6570\u603b\u7ed3\u5728\u4e00\u4e2a\u5b57\u5178\u4e2d\uff0c\u5c06\u540d\u79f0\u6620\u5c04\u5230\u7c7b\u5bf9\u8c61\u3002\u5982\u679c\u60a8\u81ea\u5df1\u5b9e\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u8bf7\u5c06\u5176\u6dfb\u52a0\u5230\u6b64\u5904\u4ee5\u5c06\u5176\u5305\u542b\u5728\u672a\u6765\u7684\u6bd4\u8f83\u4e2d\uff1a","3548353b":"# 5 \u8bad\u7ec3\u6a21\u578b\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u60f3\u5728 FashionMNIST \u4e0a\u7528\u4e0d\u540c\u7684\u6fc0\u6d3b\u51fd\u6570\u8bad\u7ec3\u6211\u4eec\u7684\u6a21\u578b\u5e76\u6bd4\u8f83\u83b7\u5f97\u7684\u6027\u80fd\u3002\u603b\u800c\u8a00\u4e4b\uff0c\u6211\u4eec\u7684\u6700\u7ec8\u76ee\u6807\u662f\u5728\u6211\u4eec\u9009\u62e9\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5728\u4e0b\u4e00\u4e2a\u5355\u5143\u683c\u4e2d\u7f16\u5199\u4e86\u4e00\u4e2a\u8bad\u7ec3\u5faa\u73af\uff0c\u5305\u62ec\u6bcf\u4e2a epoch \u4e4b\u540e\u7684\u9a8c\u8bc1\u548c\u5bf9\u6700\u4f73\u6a21\u578b\u7684\u6700\u7ec8\u6d4b\u8bd5\uff1a","08104c64":"- \u6d4b\u8bd5\u6fc0\u6d3b\u51fd\u6570\n\n> \u5728\u672c\u6559\u7a0b\u4e2d\uff0c\u6211\u4eec\u5c06\u7814\u7a76\u6d41\u884c\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e76\u7814\u7a76\u5b83\u4eec\u5bf9\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u5c5e\u6027\u7684\u5f71\u54cd\u3002\u6fc0\u6d3b\u51fd\u6570\u662f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5173\u952e\u90e8\u5206\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e3a\u795e\u7ecf\u7f51\u7edc\u6dfb\u52a0\u4e86\u975e\u7ebf\u6027\u3002\u6587\u732e\u4e2d\u6709\u5404\u79cd\u5404\u6837\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u6709\u4e9b\u6bd4\u5176\u4ed6\u7684\u66f4\u6709\u76ca\u3002\u672c\u6559\u7a0b\u76ee\u7684\u662f\u5c55\u793a\u9009\u62e9\u4e00\u4e2a\u597d\u7684\u6fc0\u6d3b\u51fd\u6570\u7684\u91cd\u8981\u6027\uff08\u4ee5\u53ca\u5982\u4f55\u8fd9\u6837\u505a\uff09\uff0c\u4ee5\u53ca\u5982\u679c\u6211\u4eec\u4e0d\u8fd9\u6837\u505a\u53ef\u80fd\u4f1a\u51fa\u73b0\u4ec0\u4e48\u95ee\u9898\u3002\u8be5\u7b14\u8bb0\u672c\u662f\u963f\u59c6\u65af\u7279\u4e39\u5927\u5b66\u6df1\u5ea6\u5b66\u4e60\u7cfb\u5217\u8bb2\u5ea7\u7684\u4e00\u90e8\u5206\u3002\u5b8c\u6574\u7684\u6559\u7a0b\u5217\u8868\u53ef\u4ee5\u5728https:\/\/uvadlc-notebooks.rtfd.io\u627e\u5230\u3002\u4fb5\u5220\uff01","c51d3110":"\u4e3a\u4e86\u4e86\u89e3\u6bcf\u4e2a\u6fc0\u6d3b\u51fd\u6570\u7684\u5b9e\u9645\u4f5c\u7528\uff0c\u6211\u4eec\u5c06\u5728\u4e0b\u9762\u5c06\u5b83\u4eec\u53ef\u89c6\u5316\u3002\u9664\u4e86\u5b9e\u9645\u6fc0\u6d3b\u503c\u4e4b\u5916\uff0c\u51fd\u6570\u7684\u68af\u5ea6\u662f\u4e00\u4e2a\u91cd\u8981\u65b9\u9762\uff0c\u56e0\u4e3a\u5b83\u5bf9\u4e8e\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u81f3\u5173\u91cd\u8981\u3002PyTorch \u5141\u8bb8\u6211\u4eec\u901a\u8fc7\u8c03\u7528backward\u51fd\u6570\u6765\u7b80\u5355\u5730\u8ba1\u7b97\u68af\u5ea6\uff1a","ee0ddc6d":"\u4e3a\u6bcf\u4e2a\u6fc0\u6d3b\u51fd\u6570\u8bad\u7ec3\u4e00\u4e2a\u6a21\u578b\u3002\u5982\u679c\u60a8\u5728 CPU \u4e0a\u8fd0\u884c\u6b64\u7b14\u8bb0\u672c\uff0c\u6211\u4eec\u5efa\u8bae\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u8282\u7701\u65f6\u95f4\u3002","266fd689":"\u7531\u4e8e\u5177\u6709 sigmoid \u6fc0\u6d3b\u7684\u6a21\u578b\u65e0\u6cd5\u6b63\u786e\u8bad\u7ec3\uff0c\u56e0\u6b64\u6fc0\u6d3b\u7684\u4fe1\u606f\u91cf\u4e5f\u8f83\u5c11\uff0c\u5e76\u4e14\u90fd\u805a\u96c6\u5728 0.5 \u5de6\u53f3\uff08\u8f93\u5165 0 \u5904\u7684\u6fc0\u6d3b\uff09\u3002\n\ntanh \u8868\u73b0\u51fa\u66f4\u591a\u6837\u5316\u7684\u884c\u4e3a\u3002\u867d\u7136\u5bf9\u4e8e\u8f93\u5165\u5c42\uff0c\u6211\u4eec\u9047\u5230\u66f4\u591a\u63a5\u8fd1 -1 \u548c 1 \u7684\u795e\u7ecf\u5143\uff0c\u5176\u4e2d\u68af\u5ea6\u63a5\u8fd1\u4e8e\u96f6\uff0c\u4f46\u4e24\u4e2a\u8fde\u7eed\u5c42\u4e2d\u7684\u6fc0\u6d3b\u66f4\u63a5\u8fd1\u4e8e\u96f6\u3002\u8fd9\u53ef\u80fd\u662f\u56e0\u4e3a\u8f93\u5165\u5c42\u5bfb\u627e\u8f93\u5165\u56fe\u50cf\u4e2d\u7684\u7279\u5b9a\u7279\u5f81\uff0c\u800c\u8fde\u7eed\u7684\u5c42\u5c06\u8fd9\u4e9b\u7279\u5f81\u7ec4\u5408\u5728\u4e00\u8d77\u3002\u6700\u540e\u4e00\u5c42\u7684\u6fc0\u6d3b\u518d\u6b21\u66f4\u504f\u5411\u4e8e\u6781\u503c\u70b9\uff0c\u56e0\u4e3a\u5206\u7c7b\u5c42\u53ef\u4ee5\u88ab\u89c6\u4e3a\u8fd9\u4e9b\u503c\u7684\u52a0\u6743\u5e73\u5747\u503c\uff08\u68af\u5ea6\u5c06\u6fc0\u6d3b\u63a8\u5411\u90a3\u4e9b\u6781\u503c\uff09\u3002\n\n\u6b63\u5982\u6211\u4eec\u6700\u521d\u9884\u671f\u7684\u90a3\u6837\uff0cReLU \u5728 0 \u5904\u6709\u4e00\u4e2a\u5f3a\u5927\u7684\u5cf0\u503c\u3002\u8d1f\u503c\u6ca1\u6709\u68af\u5ea6\u7684\u5f71\u54cd\u662f\u7f51\u7edc\u5728\u7ebf\u6027\u5c42\u4e4b\u540e\u6ca1\u6709\u7c7b\u4f3c\u9ad8\u65af\u7684\u5206\u5e03\uff0c\u800c\u662f\u671d\u7740\u6b63\u503c\u6709\u66f4\u957f\u7684\u5c3e\u5df4\u3002LeakyReLU \u8868\u73b0\u51fa\u975e\u5e38\u76f8\u4f3c\u7684\u884c\u4e3a\uff0c\u800c ELU \u518d\u6b21\u9075\u5faa\u66f4\u7c7b\u4f3c\u9ad8\u65af\u7684\u5206\u5e03\u3002Swish \u6fc0\u6d3b\u4f3c\u4e4e\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\uff0c\u4f46\u503c\u5f97\u6ce8\u610f\u7684\u662f Swish \u4f7f\u7528\u7684\u503c\u660e\u663e\u9ad8\u4e8e\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\uff08\u6700\u591a 20 \u4e2a\uff09\u3002\n\n\u7531\u4e8e\u867d\u7136\u6211\u4eec\u7684\u7b80\u5355\u7f51\u7edc\u83b7\u5f97\u4e86\u76f8\u4f3c\u7684\u6027\u80fd\uff0c\u4f46\u6240\u6709\u6fc0\u6d3b\u51fd\u6570\u90fd\u8868\u73b0\u51fa\u7565\u6709\u4e0d\u540c\u7684\u884c\u4e3a\uff0c\u56e0\u6b64\u5f88\u660e\u663e\uff0c\u201c\u6700\u4f73\u201d\u6fc0\u6d3b\u51fd\u6570\u7684\u9009\u62e9\u786e\u5b9e\u53d6\u51b3\u4e8e\u8bb8\u591a\u56e0\u7d20\uff0c\u5e76\u4e14\u5bf9\u4e8e\u6240\u6709\u53ef\u80fd\u7684\u7f51\u7edc\u5e76\u4e0d\u76f8\u540c\u3002","d3fac45c":"- \u8bbe\u7f6e\u79cd\u5b50\n\n\u6211\u4eec\u5c06\u5b9a\u4e49\u4e00\u4e2a\u51fd\u6570\u6765\u4e3a\u6211\u4eec\u5728\u672c\u6559\u7a0b\u4e2d\u53ef\u80fd\u4e0e\u4e4b\u4ea4\u4e92\u7684\u6240\u6709\u5e93\uff08\u8fd9\u91cc\u662f numpy \u548c torch\uff09\u8bbe\u7f6e\u79cd\u5b50\u3002\u8fd9\u4f7f\u6211\u4eec\u80fd\u591f\u4f7f\u6211\u4eec\u7684\u8bad\u7ec3\u53ef\u91cd\u590d\u3002\u4f46\u662f\uff0c\u8bf7\u6ce8\u610f\uff0c\u4e0e CPU \u76f8\u6bd4\uff0c\u76f8\u540c\u7684\u79cd\u5b50\u5728\u4e0d\u540c\u7684 GPU \u67b6\u6784\u4e0a\u53ef\u80fd\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u7ed3\u679c\u3002\u8fd9\u91cc\u7684\u6240\u6709\u6a21\u578b\u90fd\u5728 NVIDIA GTX1080Ti \u4e0a\u8bad\u7ec3\u8fc7\u3002\n\n\u6b64\u5916\uff0c\u4ee5\u4e0b\u5355\u5143\u683c\u5b9a\u4e49\u4e86\u4e24\u4e2a\u8def\u5f84\uff1aDATASET_PATH\u548cCHECKPOINT_PATH\u3002\u6570\u636e\u96c6\u8def\u5f84\u662f\u6211\u4eec\u5c06\u5728\u5176\u4e2d\u4e0b\u8f7d\u7b14\u8bb0\u672c\u4e2d\u4f7f\u7528\u7684\u6570\u636e\u96c6\u7684\u76ee\u5f55\u3002\u5efa\u8bae\u5c06\u6765\u81ea PyTorch \u7684\u6240\u6709\u6570\u636e\u96c6\u5b58\u50a8\u5728\u4e00\u4e2a\u8fde\u63a5\u76ee\u5f55\u4e2d\uff0c\u4ee5\u9632\u6b62\u91cd\u590d\u4e0b\u8f7d\u3002\u68c0\u67e5\u70b9\u8def\u5f84\u662f\u6211\u4eec\u5c06\u5b58\u50a8\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\u548c\u9644\u52a0\u6587\u4ef6\u7684\u76ee\u5f55\u3002\u9700\u8981\u7684\u6587\u4ef6\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u3002\u5982\u679c\u60a8\u5728 Google Colab \u4e0a\uff0c\u5efa\u8bae\u66f4\u6539\u76ee\u5f55\u4ee5\u4ece\u5f53\u524d\u76ee\u5f55\u5f00\u59cb\uff08\u5373\u5220\u9664..\/\u6570\u636e\u96c6\u548c\u68c0\u67e5\u70b9\u8def\u5f84\uff09\u3002","41216728":"\u6b7b\u4ea1\u795e\u7ecf\u5143\u7684\u6570\u91cf\u660e\u663e\u9ad8\u4e8e\u4e4b\u524d\uff0c\u8fd9\u4f1a\u635f\u5bb3\u68af\u5ea6\u6d41\uff0c\u5c24\u5176\u662f\u5728\u7b2c\u4e00\u6b21\u8fed\u4ee3\u4e2d\u3002\u4f8b\u5982\uff0c\u524d\u6700\u540e\u4e00\u5c42\u4e2d\u8d85\u8fc7 56% \u7684\u795e\u7ecf\u5143\u6b7b\u4ea1\uff0c\u8fd9\u9020\u6210\u4e86\u76f8\u5f53\u5927\u7684\u74f6\u9888\u3002\u56e0\u6b64\uff0c\u5efa\u8bae\u5bf9\u975e\u5e38\u6df1\u7684\u7f51\u7edc\u4f7f\u7528\u5176\u4ed6\u975e\u7ebf\u6027\uff0c\u5982 Swish\u3002"}}