{"cell_type":{"b45d59a6":"code","a025ac37":"code","61534d81":"code","62711232":"code","26683a9d":"code","2fb51a18":"code","01b3a2ac":"code","b79c9c8f":"code","bd83e3cd":"code","59de71eb":"code","8ce1e778":"code","413addee":"code","6aba82b7":"code","bb58f105":"markdown"},"source":{"b45d59a6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\nall_csv_files_loc = []\nall_csv_files_name = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if filename[-3:] != \"txt\" and filename not in all_csv_files_name:\n            all_csv_files_loc.append(os.path.join(dirname, filename))\n            all_csv_files_name.append(filename)\n","a025ac37":"print(\"Total Unique hotels:\", len(all_csv_files_name))\n\ntotal_reviews = 0\nfor file in all_csv_files_loc:\n    df = pd.read_csv(file)\n    total_reviews += df.shape[0]\nprint(\"Total Reviews:\", total_reviews)\n\ntotal_reviews = 0\ncon_df = pd.read_csv(all_csv_files_loc[0]).values\nfor file in all_csv_files_loc[1:]:\n    con_df = np.vstack((con_df, pd.read_csv(file).values))\nprint(\"Stacked Dataframe Shape:\", con_df.shape)","61534d81":"#manipulating data\ncon_df = con_df[:,[1,5]]\ncon_df[:,1] \/= 50\n# con_df[:,1] -= 1","62711232":"# Saving all reviews in a single file\npd.DataFrame(\n    data=con_df,\n    columns = ['review','rating']\n).to_csv(\".\/con_reviews.csv\", index=False)","26683a9d":"from tqdm import tqdm\n\nimport torch\nimport transformers\n\nimport torch.nn as nn\nimport torch.optim as optim","2fb51a18":"class config:\n    MAX_LEN = 64\n    TOKENIZER = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n    PRETRAINED = 'bert-base-uncased'\n    \n    DEVICE = torch.device(\"cuda\")\n    \n    LOSS = nn.MSELoss()\n    OPTIMIZER = None\n    EPOCHS = 5\n    BATCH_SIZE = 32\n        ","01b3a2ac":"def process_data(review, target):\n    tokens = config.TOKENIZER.tokenize(review)\n    tokens = ['[CLS]'] + tokens + ['[SEP]']\n    if len(tokens) < config.MAX_LEN:\n        tokens = tokens + ['[PAD]' for _ in range(config.MAX_LEN - len(tokens))]\n    else:\n        tokens = tokens[:config.MAX_LEN - 1] + ['[SEP]']\n        \n    token_idx = torch.tensor(config.TOKENIZER.convert_tokens_to_ids(tokens))\n    attention_mask = (token_idx != 0).long()\n    \n    return token_idx, attention_mask, target","b79c9c8f":"class ReviewLoader:\n    def __init__(self, review, target):\n        self.review = review\n        self.target = target\n        \n    def __len__(self):\n        return len(self.review)\n    \n    def __getitem__(self, item):\n        return process_data(\n            self.review[item],\n            self.target[item]\n        )","bd83e3cd":"class BertBASE(transformers.BertPreTrainedModel):\n    def __init__(self, conf):\n        super(BertBASE, self).__init__(conf)\n        self.bert = transformers.BertModel.from_pretrained(config.PRETRAINED, config=conf)\n        self.l0 = nn.Linear(768, 1)\n        \n    def forward(self, idx, mask):\n        out = self.bert(\n            idx,\n            attention_mask=mask\n        ) \n        logits = self.l0(out[0][:,0])\n        \n        return logits","59de71eb":"def train_fn(data_loader, model):\n    model.train()\n\n    tk_data = tqdm(data_loader, total=len(data_loader))\n    \n    for it, (idx, mask, target) in enumerate(tk_data):\n\n        idx = idx.to(config.DEVICE, dtype=torch.long)\n        mask = mask.to(config.DEVICE, dtype=torch.long)\n        target = target.to(config.DEVICE, dtype=torch.float)\n        \n        model.zero_grad()\n        logits = model(\n            idx = idx,\n            mask = mask\n        )\n        \n        losses = config.LOSS(logits.float(), target.resize_(config.BATCH_SIZE,1))\n        losses.backward()\n        config.OPTIMIZER.step()\n        \n        if it%200 == 0:\n            print(\"LOSS:\", losses.item())\n    ","8ce1e778":"def run():\n    \n    df = pd.read_csv('.\/con_reviews.csv')\n    train_data_loader = torch.utils.data.DataLoader(\n        ReviewLoader(\n            review = df.review.values,\n            target = df.rating.values\n        ),\n        batch_size = config.BATCH_SIZE,\n        num_workers = 4\n    )\n    \n    model_config = transformers.BertConfig.from_pretrained(config.PRETRAINED)\n    model_config.output_hidden_states = True\n    model = BertBASE(conf = model_config)\n    model.to(config.DEVICE)\n    \n    config.OPTIMIZER = optim.Adam(model.parameters(), lr = 2e-5)\n    \n    for e in range(config.EPOCHS):\n        train_fn(train_data_loader, model)","413addee":"run()","6aba82b7":"torch.cuda.empty_cache()","bb58f105":"## Classification Section"}}