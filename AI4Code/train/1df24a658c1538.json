{"cell_type":{"4f42dad6":"code","3fdf53ac":"code","126af865":"code","f6a046e4":"code","0b813b7b":"code","f1f764d6":"code","2dee38df":"code","74ba2b0c":"code","b8cb8df4":"code","994a89de":"code","5e4f051a":"code","5aba1994":"code","1cfbb7a5":"code","1bf76239":"code","d3029a67":"code","a7ac8d7d":"code","1b60932b":"code","5436ead9":"code","692d07d5":"code","0f509ad3":"code","d4d57381":"code","58aeb245":"code","28d3dac2":"code","776e1860":"code","def8f726":"code","8ce892e9":"code","55e3785c":"code","1bd692ff":"code","3d93c4c4":"code","beefd793":"code","94993ca9":"code","6bdadf95":"code","902ca983":"code","c72505dd":"code","1a7025c8":"code","ec0a56c0":"code","2fcd89ed":"code","a5f42443":"code","ad4420da":"code","3c951d94":"code","58ed76f8":"code","5ec84055":"code","69a627c0":"code","ba37afa9":"code","2cf2c78e":"code","d570c51c":"code","a6af3b55":"code","1dc11d8c":"code","1e3e5139":"code","bf3cce8c":"code","c3363d23":"code","0b70e49e":"code","6252570c":"code","b2a2d5f7":"code","144bd093":"code","8fd8937f":"code","574545ec":"code","c824de74":"code","a7c2eaa2":"code","61ec9574":"code","94fdf738":"code","8cdecb2d":"code","1a5019b0":"code","1257a419":"code","81b0dd9c":"code","a8b8cce9":"code","3483e678":"code","7538e406":"code","28545214":"code","071a3bc1":"code","2509fca4":"code","84063510":"code","7fa56ef8":"code","72bb4282":"code","ba309a12":"code","8863c239":"code","464d0af8":"markdown","1de44e17":"markdown","bf4356bb":"markdown","df5c9609":"markdown","88222990":"markdown","c43d8518":"markdown","1afb08af":"markdown","77fca52e":"markdown","7d0c76e7":"markdown","ac5cc57e":"markdown","b6befebd":"markdown","45c3362c":"markdown","0b07b2a4":"markdown","0b136c23":"markdown"},"source":{"4f42dad6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fdf53ac":"import datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()","126af865":"train_data = pd.read_excel(\"..\/input\/flight-fare-prediction-mh\/Data_Train.xlsx\")","f6a046e4":"train_data.columns, train_data.shape","0b813b7b":"train_data.dtypes","f1f764d6":"train_data.describe()","2dee38df":"# checking if the data has some missing values\ntrain_data.isnull().sum()","74ba2b0c":"# dropping the missing data from the original data\ntrain_data.dropna(inplace = True)\ntrain_data.isnull().sum()","b8cb8df4":"sns.distplot(train_data['Price']);","994a89de":"sns.distplot(np.log(train_data['Price']));","5e4f051a":"np.log(train_data['Price']).describe()","5aba1994":"train_data['Price'].describe()","1cfbb7a5":"train_data['Date_of_Journey'] = pd.to_datetime(train_data['Date_of_Journey'],format= \"%d\/%m\/%Y\")","1bf76239":"# getting the day pf the journey\ntrain_data['Day_of_journey'] = train_data['Date_of_Journey'].dt.day_name()\ntrain_data['Month_of_journey'] = train_data['Date_of_Journey'].dt.month_name()\n\n#removing the date of journey column as all the features are extracted and it's of no use.\ntrain_data.drop(['Date_of_Journey'], axis = 1 , inplace = True)","d3029a67":"train_data.head()","a7ac8d7d":"train_data['Day_of_journey'].value_counts(), train_data['Month_of_journey'].value_counts()","1b60932b":"sns.countplot(x = 'Month_of_journey', data = train_data);\n#it can be seen that the month with the highest number of flights is june and the least one is April.","5436ead9":"sns.countplot(x = 'Day_of_journey', data = train_data);\n#we can see that most of the flights are on thursday and the least are on Sunday.","692d07d5":"train_data.groupby(['Month_of_journey']).mean()\n#it can be seen that the prices are the highest in Januart while the price for a flight in april is the least","0f509ad3":"#Comparing the mean of the price according to the day\n#we can say that the highest prices are on thursday while lowest being on friday.\ntrain_data.groupby(['Day_of_journey']).mean()","d4d57381":"\n#extracting hours and minutes and removing the Dep_Time after feature extraction\n\ntrain_data['departure_hour'] = pd.to_datetime(train_data[\"Dep_Time\"]).dt.hour\ntrain_data['departure_min'] = pd.to_datetime(train_data['Dep_Time']).dt.minute\n\ntrain_data.drop(['Dep_Time'], axis = 1, inplace = True)","58aeb245":"train_data.head()","28d3dac2":"# extracting features from arrival time and then removing it\ntrain_data['arrival_hour'] = pd.to_datetime(train_data['Arrival_Time']).dt.hour\ntrain_data['arrival_min'] = pd.to_datetime(train_data['Arrival_Time']).dt.minute\n#dropping\ntrain_data.drop(['Arrival_Time'], axis = 1, inplace = True)","776e1860":"'h' in '20h'","def8f726":"#using pandas to process the Duration column for further analysis as it is in string format originally\n\ndef get_hr_min(return_h, o):\n    if ('h' in o) and ('m' in o):\n        h, m = o.split()\n        h = int(h.strip('h'))\n        m = int(m.strip('m'))\n    elif 'h' in o:\n        h = int(o.strip('h'))\n        m = 0 \n    else:\n        m = int(o.strip('m'))\n        h = 0 \n        \n    return h if return_h else m","8ce892e9":"from functools import partial \nf = partial(get_hr_min, True)\ntrain_data['duration_hr'] = train_data.Duration.map(f)\nf = partial(get_hr_min, False)\ntrain_data['duration_min'] = train_data.Duration.map(f)","55e3785c":"'2h 50m'.split()","1bd692ff":"train_data.head()","3d93c4c4":"train_data.drop(['Duration'], axis = 1, inplace = True)","beefd793":"train_data.head()","94993ca9":"#Handling Categorical Data\ntrain_data.dtypes","6bdadf95":"train_data[\"Airline\"].value_counts()","902ca983":"sns.catplot(y = 'Price', x = 'Airline',data= train_data.sort_values(\"Price\", ascending = False), kind = \"boxen\",\n            height = 8, aspect = 2)\nplt.tight_layout;\n#we can see that the Jet airways business has the highest price","c72505dd":"#using onehotcoding to change the categorical data into numerical\nAirline = train_data[['Airline']]\n\nAirline = pd.get_dummies(Airline, drop_first= True)\n\nAirline.head()  ","1a7025c8":"#checking source variable\n\ntrain_data.Source.value_counts()","ec0a56c0":"sns.catplot(y = 'Price', x = 'Source', data = train_data.sort_values(\"Price\", ascending= False), kind = \"boxen\", height=4, aspect = 2)\nplt.tight_layout;","2fcd89ed":"#Since Source is also categorical data we will use onehotencoding to change it to numerical\n\nSource = train_data[[\"Source\"]]\n\nSource = pd.get_dummies(Source, drop_first= True)\n\nSource.head()","a5f42443":"train_data.Destination.value_counts()","ad4420da":"#again performing onehotcoding to convert destination into numerical data\nDestination = train_data[['Destination']]\n\nDestination = pd.get_dummies(Destination, drop_first = True)\n\nDestination.head()","3c951d94":"train_data.Additional_Info.value_counts()","58ed76f8":"train_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\ntrain_data.head()","5ec84055":"train_data[:10]","69a627c0":"train_data.Total_Stops.value_counts()","ba37afa9":"#using label encoding for Total Stops\ntrain_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\":3, \"4 stops\": 4}, inplace = True)\ntrain_data","2cf2c78e":"#one hot encoding for journey day and journey month\n\njourney_day = pd.get_dummies(train_data['Day_of_journey'], drop_first = True)\njourney_month = pd.get_dummies(train_data['Month_of_journey'], drop_first = True)\n","d570c51c":"#removing the Airline Source and Destination columns as the information has already been extracted from them\n\ntrain_data.drop([\"Airline\", \"Source\", \"Destination\",\"Day_of_journey\", \"Month_of_journey\"], inplace = True, axis = 1)","a6af3b55":"data_train = pd.concat([train_data, Airline, Source, Destination, journey_day, journey_month], axis = 1)\ndata_train.head(), data_train.shape","1dc11d8c":"data_train.to_excel(\"Flight.xls\")","1e3e5139":"test_data = pd.read_excel(\"..\/input\/flight-fare-prediction-mh\/Test_set.xlsx\")\nprint(test_data.head(), test_data.shape)","bf3cce8c":"test_data.columns, test_data.dtypes","c3363d23":"test_data[\"Date_of_Journey\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format= \"%d\/%m\/%Y\")\n\n#deriving day of journey and month of journey from this\ntest_data[\"Day_of_journey\"] = test_data[\"Date_of_Journey\"].dt.day_name()\ntest_data[\"Month_of_journey\"] = test_data[\"Date_of_Journey\"].dt.month_name()\n\n#Removing date of journey from the test data\ntest_data.drop(['Date_of_Journey'], axis = 1, inplace = True)","0b70e49e":"test_data.head()","6252570c":"#for arrival time\n\n# creating new variables according to the arrival hour and minute\ntest_data['arrival_hour'] = pd.to_datetime(test_data['Arrival_Time']).dt.hour\ntest_data['arrival_min'] = pd.to_datetime(test_data['Arrival_Time']).dt.minute\n\n#dropping the Arrival time column as all the features have already been extracted from it\ntest_data.drop(\"Arrival_Time\",axis = 1, inplace = True)","b2a2d5f7":"#for departure time \n\n# extracting departure hour and minute\ntest_data['departure_hour'] = pd.to_datetime(test_data['Dep_Time']).dt.hour\n\ntest_data['departure_min'] = pd.to_datetime(test_data['Dep_Time']).dt.minute\n\n# removing the departure time column as all the information has been extracted from it \n\ntest_data.drop(\"Dep_Time\", axis = 1, inplace = True)","144bd093":"# extracting hours and minutes from duration column\nduration = list(test_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n        if \"h\" in duration[i]:\n            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n        else:\n            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n\nduration_hr = []\nduration_min = []\n\nfor i in range(len(duration)):\n    duration_hr.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n    duration_min.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n    \n# Adding Duration column to test set\ntest_data[\"Duration_hr\"] = duration_hr\ntest_data[\"Duration_min\"] = duration_min\ntest_data.drop([\"Duration\"], axis = 1, inplace = True)","8fd8937f":"# dropping Route and additional information columns\ntest_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)","574545ec":"#label encoding for total_stops\n\ntest_data.replace({\"non-stop\": 0,\"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n","c824de74":"#one hot encoding for Airline, Source and Destination\nprint(\"Airline\")\nprint(\"-\"*75)\nAirline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n\nprint(\"Source\")\nprint(\"-\"*75)\nSource = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n\nprint(\"Destination\")\nprint(\"-\"*75)\nDestination = pd.get_dummies(test_data[\"Destination\"], drop_first= True)\n\ntest_data.drop([\"Airline\",\"Source\",\"Destination\"], axis = 1, inplace = True)\ntest_data.head()\n","a7c2eaa2":"#one hot encoding for journey day and month for test data\n\njourney_day = pd.get_dummies(test_data[\"Day_of_journey\"], drop_first= True)\njourney_month = pd.get_dummies(test_data[\"Month_of_journey\"], drop_first= True)\n\n#removing the extra columns\ntest_data.drop([\"Day_of_journey\",\"Month_of_journey\"], axis = 1, inplace = True)\n","61ec9574":"print(\"shape of test data\", test_data.shape)","94fdf738":"#joining the data after encoding for further processing\ndata_test = pd.concat([test_data, Airline, Source, Destination, journey_day, journey_month], axis = 1)\nprint(\"shape of test data\", data_test.shape)","8cdecb2d":"data_test.to_excel(\"Flight_test.xls\")","1a5019b0":"data_train.columns","1257a419":"X = data_train.loc[:,['Total_Stops',\n    'departure_hour', 'departure_min',\n       'arrival_hour', 'arrival_min', 'duration_hr', 'duration_min',\n       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n       'Airline_Jet Airways', 'Airline_Jet Airways Business',\n       'Airline_Multiple carriers',\n       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n       'Destination_Cochin', 'Destination_Delhi', 'Destination_Hyderabad',\n       'Destination_Kolkata', 'Destination_New Delhi', 'Monday', 'Saturday',\n       'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'June', 'March', 'May']]\n\nX.head()\n\n","81b0dd9c":"y = data_train.iloc[:,1]\ny.head()","a8b8cce9":"#using heatmap to find the correlation of the variables\n\nplt.figure(figsize = (15,10))\nsns.heatmap(train_data.corr(), annot = True, cmap= \"YlGnBu\")\n\nplt.tight_layout()\n","3483e678":"#Important feature using Extratreesregressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nselection = ExtraTreesRegressor()\nselection.fit(X,y)\n\nprint(selection.feature_importances_)\n\n#plot graph of feature importances for better visualization\n\nplt.figure(figsize = (12,8))\nfeat_importances = pd.Series(selection.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()","7538e406":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\n","28545214":"#fitting the model\nfrom sklearn.ensemble import RandomForestRegressor\nmodel_1 = RandomForestRegressor()\nmodel_1.fit(X_train, y_train)","071a3bc1":"#making prediction on test data\ny_pred = model_1.predict(X_test)","2509fca4":"model_1.score(X_train, y_train)","84063510":"model_1.score(X_test, y_test)","7fa56ef8":"sns.distplot(y_test-y_pred)\nplt.show()","72bb4282":"plt.scatter(y_test, y_pred, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()","ba309a12":"from sklearn import metrics","8863c239":"print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\nprint(\"R-squared score:\", metrics.r2_score(y_test, y_pred))","464d0af8":"# Processing Test data","1de44e17":"If two independent features have a greater correlation then we can drop either of the two.","bf4356bb":"Using Pandas to to analysis of the datetime series.","df5c9609":"Having a look at the descriptive statistics with and without log transformation","88222990":"# Feature selection","c43d8518":"Univariate analysis: let's have look at the price distribution with and without log transformation","1afb08af":"len(\"2h 50m\".split())","77fca52e":"Using log trainsformation on Price variable","7d0c76e7":"# Model Fitting\n\nModel 1: Random Forest will be used","ac5cc57e":"train_data[\"Duration_hours\"] = duration_hours\ntrain_data[\"Duration_mins\"] = duration_mins\ntrain_data.drop(['Duration'], axis = 1, inplace = True)","b6befebd":"THe plot shows that is a gaussian distribution it means that our results are good","45c3362c":"# EDA","0b07b2a4":"*  EDA for train data has been done\n*  Preprocessing for the training data has been done \n*  Performing the similar data preprocessing for the test data below:","0b136c23":"# Credits\n\n* The implementation of Model was adapted and modified from [this](http:\/\/https:\/\/github.com\/Mandal-21\/Flight-Price-Prediction\/blob\/master\/flight_price.ipynb) wonderful notebook on kaggle."}}