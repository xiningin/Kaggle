{"cell_type":{"850e6966":"code","70b0eecd":"code","eeccfc71":"code","8041433e":"code","0952f12c":"code","0266e58a":"code","1433ce56":"code","4683e40d":"code","170b9196":"code","a23e29d8":"code","f9751b69":"code","671d826e":"code","67158bbf":"code","bfc4f1a8":"code","9b4c34ff":"code","49e93ce0":"code","810ab961":"markdown","09989248":"markdown","5dee6015":"markdown","838eef19":"markdown","01be5fa2":"markdown","8cb622f1":"markdown","1697c169":"markdown","9eac29a7":"markdown","16991fcb":"markdown","9e82c915":"markdown","955b4925":"markdown","5094f622":"markdown","78d145e8":"markdown","ff1fc409":"markdown","227d92cf":"markdown","7c104fd4":"markdown","1d6bee6a":"markdown"},"source":{"850e6966":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #advanced plotting\nfrom matplotlib import pyplot as plt #plotting\nfrom scipy import stats #\nfrom statsmodels.stats import weightstats as stests #statistical significance tests\nfrom sklearn.model_selection import train_test_split #split dataset\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree Classifier\nfrom sklearn import tree #\nfrom sklearn.metrics import classification_report,confusion_matrix #confusion matrix\nfrom sklearn.model_selection import GridSearchCV #Grid search tuning algorithm\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","70b0eecd":"cell_data = pd.read_csv('..\/input\/breast-cancer-prediction-dataset\/Breast_cancer_data.csv')\ncell_data.head(10)","eeccfc71":"cell_data.shape","8041433e":"cell_data.info()","0952f12c":"cell_data.isnull().sum()","0266e58a":"cell_data['diagnosis'].value_counts(normalize=True)","1433ce56":"for col in cell_data.columns:\n    print('Unique values in column '+col+' are: '+str(cell_data[col].unique()))","4683e40d":"cell_data.describe()","170b9196":"fig,axs=plt.subplots(2,3,figsize=(20,7))\ncols = 0\nfor i in range(2):\n    for j in range(3):\n        px=sns.boxplot(data=cell_data[cell_data.columns[cols]],ax=axs[i,j]).set(xlabel=cell_data.columns[cols])\n        cols+=1","a23e29d8":"fig,axs=plt.subplots(2,3,figsize=(20,10))\n\ncell_rad = cell_data[['mean_radius','diagnosis']].groupby(['diagnosis']).agg(np.mean).reset_index()\ng=sns.barplot(x='diagnosis',y='mean_radius',data=cell_rad,ax=axs[0,0])\nfor index, row in cell_rad.iterrows():\n    g.text(row.name,row.mean_radius, round(row.mean_radius,2), color='black', ha=\"center\", fontweight='bold')\n    \ncell_text = cell_data[['mean_texture','diagnosis']].groupby(['diagnosis']).agg(np.mean).reset_index()\ng=sns.barplot(x='diagnosis',y='mean_texture',data=cell_text,ax=axs[0,1])\nfor index, row in cell_text.iterrows():\n    g.text(row.name,row.mean_texture, round(row.mean_texture,2), color='black', ha=\"center\", fontweight='bold')    \n    \ncell_per = cell_data[['mean_perimeter','diagnosis']].groupby(['diagnosis']).agg(np.mean).reset_index()\ng=sns.barplot(x='diagnosis',y='mean_perimeter',data=cell_per,ax=axs[0,2])\nfor index, row in cell_per.iterrows():\n    g.text(row.name,row.mean_perimeter, round(row.mean_perimeter,2), color='black', ha=\"center\", fontweight='bold') \n    \ncell_area = cell_data[['mean_area','diagnosis']].groupby(['diagnosis']).agg(np.mean).reset_index()\ng=sns.barplot(x='diagnosis',y='mean_area',data=cell_area,ax=axs[1,0])\nfor index, row in cell_area.iterrows():\n    g.text(row.name,row.mean_area, round(row.mean_area,2), color='black', ha=\"center\", fontweight='bold') \n    \ncell_smooth = cell_data[['mean_smoothness','diagnosis']].groupby(['diagnosis']).agg(np.mean).reset_index()\ng=sns.barplot(x='diagnosis',y='mean_smoothness',data=cell_smooth,ax=axs[1,1])\nfor index, row in cell_smooth.iterrows():\n    g.text(row.name,row.mean_smoothness, round(row.mean_smoothness,2), color='black', ha=\"center\", fontweight='bold')       ","f9751b69":"ztest_rad ,pval_rad = stests.ztest(cell_data['mean_radius'].loc[cell_data['diagnosis']==0], cell_data['mean_radius'].loc[cell_data['diagnosis']==1])\nprint('P-value for mean_radius: '+str(pval_rad))\n\nztest_text ,pval_text = stests.ztest(cell_data['mean_texture'].loc[cell_data['diagnosis']==0], cell_data['mean_texture'].loc[cell_data['diagnosis']==1])\nprint('P-value for mean_texture: '+str(pval_text))\n\nztest_per ,pval_per = stests.ztest(cell_data['mean_perimeter'].loc[cell_data['diagnosis']==0], cell_data['mean_perimeter'].loc[cell_data['diagnosis']==1])\nprint('P-value for mean_perimeter: '+str(pval_per))\n\nztest_area ,pval_area = stests.ztest(cell_data['mean_area'].loc[cell_data['diagnosis']==0], cell_data['mean_area'].loc[cell_data['diagnosis']==1])\nprint('P-value for mean_area: '+str(pval_area))\n\nztest_smooth ,pval_smooth = stests.ztest(cell_data['mean_smoothness'].loc[cell_data['diagnosis']==0], cell_data['mean_smoothness'].loc[cell_data['diagnosis']==1])\nprint('P-value for mean_smoothness: '+str(pval_smooth))","671d826e":"sns.pairplot(cell_data)","67158bbf":"sns.heatmap(cell_data.corr(),annot=True)","bfc4f1a8":"diagnosis = cell_data.pop('diagnosis')\n\nx_train, x_test, y_train, y_test = train_test_split(cell_data, diagnosis, test_size = 0.3, random_state = 0, stratify = diagnosis)","9b4c34ff":"x_train1, x_val, y_train1, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 0)","49e93ce0":"# Run CART model\nparam_grid = {\n    'criterion': ['gini','entropy'],\n    'max_depth': [3,4,5,6,7,8,9,10,15,20],\n    'min_samples_leaf': [50,100,150,200,250], \n    'min_samples_split': [150,200,250,300,350],\n}\n\ndtcl = DecisionTreeClassifier(random_state=0)\n\ngrid_search_dtcl = GridSearchCV(estimator = dtcl, param_grid = param_grid, cv = 10,scoring='f1')\n\ngrid_search_dtcl.fit(x_train, y_train)\ngrid_search_dtcl.best_params_\n\nbest_grid_dtcl = grid_search_dtcl.best_estimator_ #Stores the best estimator parameters in a variable\n#predict\nytrain_predict_dtcl = best_grid_dtcl.predict(x_train1) #predict train data using the best estimator\nytest_predict_dtcl  = best_grid_dtcl.predict(x_test)   #predict test data using the best estimator\nyval_predict_dtcl   = best_grid_dtcl.predict(x_val)    #predict validation data using the best estimator\n\ndtcl_train_acc=best_grid_dtcl.score(x_train1,y_train1)\n\n#confusion matrix parameters for train data\ndtcl_metrics=classification_report(y_train1, ytrain_predict_dtcl,output_dict=True)\ndf=pd.DataFrame(dtcl_metrics).transpose()\ndtcl_train_precision=round(df.loc[\"1\"][0],2)\ndtcl_train_recall=round(df.loc[\"1\"][1],2)\ndtcl_train_f1=round(df.loc[\"1\"][2],2)\nprint ('dtcl_train_precision ',dtcl_train_precision)\nprint ('dtcl_train_recall ',dtcl_train_recall)\nprint ('dtcl_train_f1 ',dtcl_train_f1)\n\n#ROC AUC curve for train data\ndtcl_train_fpr, dtcl_train_tpr,_=roc_curve(y_train1,best_grid_dtcl.predict_proba(x_train1)[:,1])\nplt.plot(dtcl_train_fpr,dtcl_train_tpr,color='green')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend('Train')\ndtcl_train_auc=roc_auc_score(y_train1,best_grid_dtcl.predict_proba(x_train1)[:,1])\nprint('Area under Curve is', dtcl_train_auc)\n\ndtcl_test_acc=best_grid_dtcl.score(x_test,y_test)\n\n#confusion matrix parameters for test data\ndtcl_metrics=classification_report(y_test, ytest_predict_dtcl,output_dict=True)\ndf=pd.DataFrame(dtcl_metrics).transpose()\ndtcl_test_precision=round(df.loc[\"1\"][0],2)\ndtcl_test_recall=round(df.loc[\"1\"][1],2)\ndtcl_test_f1=round(df.loc[\"1\"][2],2)\nprint ('dtcl_test_precision ',dtcl_test_precision)\nprint ('dtcl_test_recall ',dtcl_test_recall)\nprint ('dtcl_test_f1 ',dtcl_test_f1)\n\n#ROC AUC curve for test data\ndtcl_test_fpr, dtcl_test_tpr,_=roc_curve(y_test,best_grid_dtcl.predict_proba(x_test)[:,1])\nplt.plot(dtcl_test_fpr,dtcl_test_tpr,color='red')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend('Test')\ndtcl_test_auc=roc_auc_score(y_test,best_grid_dtcl.predict_proba(x_test)[:,1])\nprint('Area under Curve is', dtcl_test_auc)\n\n#confusion matrix parameters for validation data\ndtcl_metrics=classification_report(y_val, yval_predict_dtcl,output_dict=True)\ndf=pd.DataFrame(dtcl_metrics).transpose()\ndtcl_val_precision=round(df.loc[\"1\"][0],2)\ndtcl_val_recall=round(df.loc[\"1\"][1],2)\ndtcl_val_f1=round(df.loc[\"1\"][2],2)\nprint ('dtcl_val_precision ',dtcl_val_precision)\nprint ('dtcl_val_recall ',dtcl_val_recall)\nprint ('dtcl_val_f1 ',dtcl_val_f1)\n\n#ROC AUC curve for validation data\ndtcl_val_fpr, dtcl_val_tpr,_=roc_curve(y_val,best_grid_dtcl.predict_proba(x_val)[:,1])\nplt.plot(dtcl_val_fpr,dtcl_val_tpr,color='violet')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend('Validation')\ndtcl_val_auc=roc_auc_score(y_val,best_grid_dtcl.predict_proba(x_val)[:,1])\nprint('Area under Curve is', dtcl_val_auc)","810ab961":"<a href='#Read-Input'>1. Read Input dataset <\/a>","09989248":"The pairplot shows that there are some variables which have a linear relationship with each other. The heatmap can quantify this relationship better","5dee6015":"On a cursory look, there are no invalid values in the columns of the dataset","838eef19":"The result above confirms that there are no nulls in the dataset","01be5fa2":"The data from describe table shows that each variable is in a different range\n\nThe Radius variable ranges between 6.98 and 28.11 where as area is between 143.5 and 2501\n\nThe values vary between 0.05 and 2501 across variables indicating there might be a need to standardize the data before applying models that depend on distance measures","8cb622f1":"As can be seen from the plots above, all variables measure significantly less for cells detected with cancer. But we need to find out if they are statistically significant difference<br><br>To achieve this, we will setup z-test for each set of variables<br>**Null Hypothesis:** The mean of column value for non-cancer cells is not different from those of cancer cells<br>**Alternate Hypothesis:**  The mean of column value for non-cancer cells is significantly different from those of cancer","1697c169":"As can be seen in the boxplot, all the variables have extreme values. This need not be handled at the current monent because cancer cells as such have extreme characteristrics. The model we choose on the other hand should be capable of handling the extreme values well","9eac29a7":"## Decision Tree\nDecision tree is a model which generally is immune to extreme values and can handle non-standardized data well. Hence, we will try this first","16991fcb":"In all the cases, the p-value is very less than the significance level of 0.05 indicating that the difference we see in the parameter values is statistically different. Hence all of the variables can influence the prediction of diagnosis column","9e82c915":"63% of the dataset has records with cancer diagnosis and 37% as 'Not Cancer'.\n\nAlthough the dataset will be slightly better at predicting Cancer cases, the dataset is not a biased one. We can expect a reasonbably sound prediction","955b4925":"# Modeling for classification","5094f622":"<a id='Read-Input'><\/a>\n# Read the input dataset\n","78d145e8":"The dataset has 569 rows of data with 6 columns including the target column","ff1fc409":"There is a high correlation between radius, perimeter and area of a cell. This is because all these are related\n\nIf 'r' is the radius, Area = 4 * pi * r^2\n\nPerimeter = 2 * pi * r\n\nFor now, we will let all these variables remain. In future, we can probably replace all these values by a surface area to volume ratio which is a good indicator of cell size.\n\nOtherwise, there is not a lot of linear correlation between the independent variables and diagnosis. This means to say that linear models like logistic regression might not work. ","227d92cf":"All the columns are numeric and do not have null data","7c104fd4":"The dataset is read fine. From an initial look at the data, we see that all columns are numeric. There are 5 independent variables and the 6th, the diagnosis column is the target column\n\n**Exploratory Data Analysis**","1d6bee6a":"Before we do the classification, we need to divide the dataset between training and test. We will divide it into 3 sets - Train, Test and Validation - just so we are sure the unknown data is handled well"}}