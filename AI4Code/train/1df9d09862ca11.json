{"cell_type":{"b21623b3":"code","24180f95":"code","697bccae":"code","9f782ef6":"code","85e1a737":"code","45b0b575":"code","6fe9656b":"code","25fdf888":"code","f393a48e":"code","78263eb1":"code","9fa596d4":"code","fbb93ffa":"code","ef6540c3":"markdown","4ebf33f7":"markdown","35e29e0e":"markdown"},"source":{"b21623b3":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, time, warnings, pickle, psutil, random\n\nfrom math import ceil\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings('ignore')","24180f95":"# Now we have 3 sets of features\ngrid_df = pd.concat([pd.read_pickle('\/kaggle\/input\/m5-simple-fe\/grid_part_1.pkl'),\n                     pd.read_pickle('\/kaggle\/input\/m5-simple-fe\/grid_part_2.pkl').iloc[:,2:],\n                     pd.read_pickle('\/kaggle\/input\/m5-simple-fe\/grid_part_3.pkl').iloc[:,2:]],\n                     axis=1)\ngrid_df.head()","697bccae":"# Lets pick a product with pronounced gaps: 'HOBBIES_1_288_CA_1_validation'\nm = grid_df.id=='HOBBIES_1_288_CA_1_validation'\nsales_ts = grid_df.loc[m,'sales'].values\nsales_ts","9f782ef6":"def gap_finder(ts):\n    \n    # this function finds gaps and calculates their length:\n    ts = (~(ts > 0)).astype(int)\n\n    for i, val in enumerate(ts):\n        if val == 0: \n            continue\n        else: \n            ts[i] += ts[i-1]\n            ts[i-1] = -1\n    return ts\n\ndef gap_counter(ts):\n    \n    # value_counts for gaps lengths\n    \n    counts = np.unique(ts, return_counts=True)\n    return dict(zip(counts[0], counts[1]))\n\nm = grid_df.id=='HOBBIES_1_288_CA_1_validation'\n\nsales_gaps = gap_counter(gap_finder(grid_df.loc[m,'sales'].values))\nsales_gaps","85e1a737":"# Lets try to build a synthetic series with gaps.\n# We assume products have a constant chance of being sold on any particular day.\n# So for every day we will flip an unfair coin with probability of sale equal to 'dates_with sale'\/'all_dates'\n# >>>This might be an oversimplistic assumption, a moving window might be used instead.\n\ndef synth_sales(gaps_dict, min_gap=1000):\n    \n    sum_sale_days = gaps_dict[0] # key '0' gives number of days with sales\n    sum_days = sum(gaps_dict.values()) # sum of all keys - number of all days\n    \n    # Sum of days in gaps longer than minimum gap length:\n    sum_gap_length = sum([k for k in [*sales_gaps.keys()] if k > min_gap])\n    \n    # Exlude all the gaps longer than min_gap_length from probability calculation:\n    p = sum_sale_days\/(sum_days-sum_gap_length)\n    \n    return np.random.binomial(1, p, sum(gaps_dict.values()))\n\nsynth_sales_gaps = gap_counter(gap_finder(synth_sales(sales_gaps)))\nsynth_sales_gaps","45b0b575":"# As you can see we dont have results > 20. \n# To make sure this is a consistent result lets run simulation 1,000 times:\n# >>>> n equal 1,000 might be an overshot for some ids.\n\nn=1000\n\nsym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps))) for i in range(n)])\ngap_length_prob = (sym_df.sum(axis=0)\/n).sort_index()\ngap_length_prob","6fe9656b":"# The shortest gap that has been seen in less than 5% of simulated series:\nmin_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\nmin_gap_length","25fdf888":"# Now we exclude the gaps longer than min_gap_length from 'probability of sale' calculation, \n# because we assume them to be non-random.\n# Run the simulation recursively until the min_gap_length does not decrease:\n\nn=1000\nnew_min_gap_length = 0\n\nwhile new_min_gap_length != min_gap_length:\n    \n    if new_min_gap_length!=0: min_gap_length=new_min_gap_length\n\n    sym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps, min_gap_length))) for i in range(n)])\n    gap_length_prob = (sym_df.sum(axis=0)\/n).sort_index()\n\n    # Lets find the shortes gap that has been seen in les than 5% of simulated series:\n    new_min_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\n\nmin_gap_length","f393a48e":"# Finally we need to make a feature 'out_of_stock' for the product:\nm = grid_df.id=='HOBBIES_1_288_CA_1_validation'\nidx = grid_df.loc[m,'sales'].index\n\ngf = pd.Series(gap_finder(grid_df.loc[m,'sales'].values), index = idx)\ngf = gf.replace(-1,np.nan).fillna(method='backfill') \ngf = gf > min_gap_length\ngf","78263eb1":"# Let calculate 'out-of-stock' for the first 30 ids:\ngrid_df['out_of_stock'] = 0\n\nn=1000\nprods = list(grid_df.id.unique())\ngap_length_list = []\n\nfor prod_id in tqdm(prods[:30]):\n    \n    m = grid_df.id == prod_id\n    idx = grid_df.loc[m,'sales'].index\n\n    sales_gaps = gap_counter(gap_finder(grid_df.loc[m,'sales'].values))\n\n    sym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps))) for i in range(n)])\n    gap_length_prob = (sym_df.sum(axis=0)\/n).sort_index()\n\n    min_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\n    new_min_gap_length = 0\n    \n    while new_min_gap_length < min_gap_length:\n\n        if new_min_gap_length!=0: min_gap_length=new_min_gap_length\n\n        sym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps, min_gap_length))) for i in range(n)])\n        gap_length_prob = (sym_df.sum(axis=0)\/n).sort_index()\n\n        # Lets find the shortes gap that has been seen in les than 5% of simulated series:\n        new_min_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\n\n    gf = pd.Series(gap_finder(grid_df.loc[m,'sales'].values), index = idx)\n    gf = gf.replace(-1,np.nan).fillna(method='backfill') \n    gf = gf > min_gap_length\n    grid_df.loc[m,'out_of_stock'] = gf*1\n    gap_length_list += [min_gap_length]","9fa596d4":"# Let take 'out-of-stock' gap length for different products:\n#from collections import Counter\n#Counter(gap_length_list)\n\ngap_length_list[:15]","fbb93ffa":"# As you can see the out-of-stock gap length vary extremely from product to product.\n# For densily traded products it maybe as short as 8 days, while for rare products it might be over 60 days.\n\n# The current approach to calculating it is SLOW. I will try to refactor it and build the feature in the next notebook.\n# Comments are welcome. Please let me know if you spot inefficiencies or mistakes.","ef6540c3":"# TOO SLOW","4ebf33f7":"### M5 - 'out_of_stock' feature\n\nAs @narsil notes that ***Sales = min (demand, inventory)*** in [this discussion](https:\/\/www.kaggle.com\/c\/m5-forecasting-accuracy\/discussion\/138085#790628). So we need **to distinguish beween zero demand and zero supply**. \n'out_of_stock' feature flags highly improbable long gaps for a given 'id'. \n\nThis notebook describes general approach and logic behind it.\nIt is a bit slow and needs a performance boost to build the feature.","35e29e0e":" [Discussion here.](https:\/\/www.kaggle.com\/c\/m5-forecasting-accuracy\/discussion\/138085#790628)"}}