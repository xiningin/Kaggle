{"cell_type":{"ae227f3e":"code","1ad18141":"code","a62b4ffd":"code","9715e120":"code","c928a87c":"code","7646cb95":"code","fe33ac6b":"code","45017cee":"code","0e5e0e8f":"code","036a3c97":"code","6da4df5c":"code","1377e837":"code","f328818a":"code","76c05437":"code","3b670faa":"code","d5cd3223":"code","620e4e98":"code","67d3c4cf":"code","996d12ed":"code","e0854956":"code","1bee84b8":"code","826e645d":"code","a4a4f131":"code","532a888f":"code","a61422d8":"code","0656a6bc":"code","24faefe4":"code","5a4ce59f":"markdown","a07dcff5":"markdown","ee09d418":"markdown","87b1963e":"markdown","a7f06b76":"markdown","8e34e725":"markdown","e8576c45":"markdown","1bbdaa24":"markdown","4899de6b":"markdown","75f39ed4":"markdown","3b8ee0f8":"markdown","39d46716":"markdown","1ff837b0":"markdown","13ef59b4":"markdown","769911b8":"markdown","d4e66e8d":"markdown","e311a91d":"markdown","cc48f72c":"markdown","5e42548c":"markdown","7e3e2e43":"markdown","67b7a707":"markdown","90e9a993":"markdown","b5d775f7":"markdown","2e953cf7":"markdown","ec7295d5":"markdown"},"source":{"ae227f3e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport os\nimport seaborn as sn\nimport glob as gb\nimport cv2\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","1ad18141":"### for Kaggle\ntrainpath = '..\/input\/covid19-chest-xray-dataset\/training\/'\ntestpath  = '..\/input\/covid19-chest-xray-dataset\/test\/'\npredpath  = '..\/input\/covid19-chest-xray-dataset\/pred\/'\n\n### for Jupyter\n# trainpath = ''\n# testpath = ''\n# predpath = ''","a62b4ffd":"for folder in  os.listdir(trainpath) : \n    files = gb.glob(pathname= str( trainpath + folder + '\/*.jpg'))\n    print(f'For training data , found {len(files)} in folder {folder}')","9715e120":"for folder in  os.listdir(testpath) : \n    files = gb.glob(pathname= str( testpath + folder + '\/*.jpg'))\n    print(f'For testing data , found {len(files)} in folder {folder}')","c928a87c":"files = gb.glob(pathname= str(predpath +'rand\/*.jpg'))\nprint(f'For Prediction data , found {len(files)}')","7646cb95":"code = {'COVID-19':0, 'SARS':1, 'ARDS':2, 'Pneumocystis':3, 'Streptococcus':4, 'Normal':5}\n\ndef getcode(n) : \n    for x , y in code.items() : \n        if n == y : \n            return x    ","fe33ac6b":"size = []\nfor folder in  os.listdir(trainpath) : \n    files = gb.glob(pathname= str( trainpath + folder + '\/*.jpg'))\n    for file in files: \n        image = plt.imread(file)\n        size.append(image.shape)\npd.Series(size).value_counts()","45017cee":"size = []\nfor folder in  os.listdir(testpath) : \n    files = gb.glob(pathname= str( testpath + folder + '\/*.jpg'))\n    for file in files: \n        image = plt.imread(file)\n        size.append(image.shape)\npd.Series(size).value_counts()","0e5e0e8f":"#s = 512\ns = 300","036a3c97":"X_train = []\ny_train = []\nfor folder in  os.listdir(trainpath) : \n    files = gb.glob(pathname= str( trainpath + folder + '\/*.jpg'))\n    for file in files: \n        image = cv2.imread(file)\n        image_array = cv2.resize(image , (s,s))\n        X_train.append(list(image_array))\n        y_train.append(code[folder])","6da4df5c":"print(f'we have {len(X_train)} items in X_train')","1377e837":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_train),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_train[i])   \n    plt.axis('off')\n    plt.title(getcode(y_train[i]))","f328818a":"X_test = []\ny_test = []\nfor folder in  os.listdir(testpath) : \n    files = gb.glob(pathname= str(testpath + folder + '\/*.jpg'))\n    for file in files: \n        image = cv2.imread(file)\n        image_array = cv2.resize(image , (s,s))\n        X_test.append(list(image_array))\n        y_test.append(code[folder])\n        ","76c05437":"print(f'we have {len(X_test)} items in X_test')","3b670faa":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_test),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_test[i])    \n    plt.axis('off')\n    plt.title(getcode(y_test[i]))","d5cd3223":"X_pred = []\nfiles = gb.glob(pathname= str(predpath + 'rand\/*.jpg'))\nfor file in files: \n    image = cv2.imread(file)\n    image_array = cv2.resize(image ,(s,s))\n    X_pred.append(list(image_array))       ","620e4e98":"print(f'we have {len(X_pred)} items in X_pred')","67d3c4cf":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])    \n    plt.axis('off')","996d12ed":"X_train = np.array(X_train)\nX_test = np.array(X_test)\nX_pred_array = np.array(X_pred)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\n\nprint(f'X_train shape  is {X_train.shape}')\nprint(f'X_test shape  is {X_test.shape}')\nprint(f'X_pred shape  is {X_pred_array.shape}')\nprint(f'y_train shape  is {y_train.shape}')\nprint(f'y_test shape  is {y_test.shape}')","e0854956":"KerasModel = keras.models.Sequential([\n        keras.layers.Conv2D(32, border_mode='same', kernel_size=(5,5),activation='relu',input_shape=(s,s,3)),\n        keras.layers.Conv2D(64, border_mode='same', kernel_size=(5,5),activation='relu'),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Conv2D(128, border_mode='same', kernel_size=(3,3),activation='relu'),    \n        keras.layers.Conv2D(256, border_mode='same', kernel_size=(3,3),activation='relu'),    \n        keras.layers.MaxPool2D(2,2),\n        keras.layers.Flatten(),    \n        keras.layers.Dense(300,activation='relu'),\n        keras.layers.Dropout(rate=0.5),\n        keras.layers.Dense(6,activation='softmax'),\n        ])","1bee84b8":"KerasModel.compile(optimizer ='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","826e645d":"print('Model Details are : ')\nprint(KerasModel.summary())","a4a4f131":"epochs = 150\nThisModel = KerasModel.fit(X_train, y_train, epochs=epochs, batch_size=4, verbose=1, validation_split=0.2, shuffle=True)","532a888f":"#  \"Accuracy\"\nplt.plot(ThisModel.history['accuracy'])\nplt.plot(ThisModel.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\n\n# \"Loss\"\nplt.plot(ThisModel.history['loss'])\nplt.plot(ThisModel.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\n\nModelLoss, ModelAccuracy = KerasModel.evaluate(X_test, y_test)\n\n\nprint('Test Loss is {}'.format(ModelLoss))\nprint('Test Accuracy is {}'.format(ModelAccuracy))\n\n\nnp.save(\"CNN_model.npy\",KerasModel)\n# serialize weights to HDF5\nKerasModel.save_weights(\"CNN_model.h5\")\nprint(\"Saved model to disk\")","a61422d8":"y_pred = KerasModel.predict(X_test, verbose=0)\nyhat_probs = KerasModel.predict_classes(X_test, verbose=0)\nprint(y_test)\nprint(yhat_probs)\nprint('=========================================')\n\nf1_score(y_test, yhat_probs, average='weighted')\n# accuracy: (tp + tn) \/ (p + n)\naccuracy = accuracy_score(y_test, yhat_probs)\nprint('Accuracy: %f' % accuracy)\n# precision tp \/ (tp + fp)\nprecision = precision_score(y_test, yhat_probs ,average='weighted')\nprint('Precision: %f' % precision)\n# recall: tp \/ (tp + fn)\nrecall = recall_score(y_test, yhat_probs, average='weighted')\nprint('Recall: %f' % recall)\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1 = f1_score(y_test, yhat_probs, average='weighted')\nprint('F1 score: %f' % f1)\n\nprint('=========================================')\nprint('Prediction Shape is {}'.format(y_pred.shape))\nprint('test Shape is {}'.format(y_test.shape))\n\ncn = confusion_matrix(y_test, yhat_probs)\nsn.heatmap(cn, center = True)\nplt.show()","0656a6bc":"y_result = KerasModel.predict(X_pred_array)\n\nprint('Prediction Shape is {}'.format(y_result.shape))","24faefe4":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])    \n    plt.axis('off')\n    plt.title(getcode(np.argmax(y_result[i])))","5a4ce59f":"now to define the path ( to swtich it between jupyter notebook & kaggle kernel)","a07dcff5":"now to compile the model , using adam optimizer , & sparse categorical crossentropy loss","ee09d418":"great\n\nnow it's time to redict X Predict","87b1963e":"also with Prediction data , without having title of course","a7f06b76":"# COVID-19 Classifier from X-Ray\nImage Classification Using CNN\n\nBy : Ahmed Hamada\n\n________\n\nwe'll build a CNN using Keras to use it classifying thousands of pictures in six different categories\n\nDataset link : https:\/\/www.kaggle.com\/ahmedhamada0\/covid19-chest-xray-dataset\n\nfirst to import libraries\n","8e34e725":"# Reading Images\n\nnow it's time to read all images & convert it into arrays\n\nfirst we'll create a variable s , which refer to size , so we can change it easily \n\nlet's use now size = 512 , so it will be suitable amount to contain accuracy without losing so much time in training","e8576c45":"great , now how many items in X_train ","1bbdaa24":"how is the final loss & accuracy\n","4899de6b":"now how about the images sizes in train folder","75f39ed4":"and to show random redicted pictures & its predicting category\n","3b8ee0f8":"________\n\n# Building The Model \n\nnow we need to build the model to train our data\n\nfirst to convert the data into arrays using numpy","39d46716":"also we have have a look to random pictures in X_train , and to adjust their title using the y value","1ff837b0":"# Open Folders\n\nnow let's first check the Train folder to have a look to its content","13ef59b4":"great , now to repeat same steps exactly in test data","769911b8":"so how the model looks like ? ","d4e66e8d":"now to read all pictues in six categories in training folder, ans use OpenCV to resize it , and not to forget to assign the y value , from the predefined function ","e311a91d":"ok , only 83% accuracy & can be increased by tuning the hyperparameters","cc48f72c":"ok , how about the test folder","5e42548c":"now to build the CNN model by Keras , using Conv2D layers , MaxPooling & Denses","7e3e2e43":"_____\n\n# Checking Images\n\nnow we need to heck the images sizes , to know ow they looks like\n\nsince we have 6 categories , we first need to create a dictionary with their names & indices , also create a function to get the code back","67b7a707":"now to train the model , lets use 64 epochs now","90e9a993":"______\n\nok , almost all sizes are different ^^ , how about test images ? ","b5d775f7":"ok , since almost all of pictures are different .. then i think that is the appropriate size is 512, 512, 3 (that's kaggle GPU limit without error).\n\nwe can feel comfort in using all pictures in our model , after resizing it in a specific amount","2e953cf7":"\n_______\n\nnow to predict X test","ec7295d5":"_____\nnow for prediction folder"}}