{"cell_type":{"66a7a32b":"code","1af9accf":"code","39f58afc":"code","ecc41e37":"code","e60c4dae":"code","30706bb8":"code","3c6e2f2b":"code","1d6aec92":"code","ad78494a":"code","d2657e17":"code","e188f78a":"code","0ca02428":"code","07ed9500":"code","f55abbbb":"code","07eb09e1":"code","cb0dc387":"code","f3f7faab":"code","c0d1e9e5":"code","caa7b24a":"code","82d12ddd":"code","1f810463":"code","e2986b11":"code","97194aa7":"markdown"},"source":{"66a7a32b":"from  datetime import datetime, timedelta\nimport gc\nimport numpy as np, pandas as pd","1af9accf":"CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\nPRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }","39f58afc":"pd.options.display.max_columns = 50","ecc41e37":"h = 28 \nmax_lags = 57\ntr_last = 1913\nfday = datetime(2016,4, 25) \nfday","e60c4dae":"def create_dt(is_train = True, nrows = None, first_day = 1200):\n    prices = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\", dtype = PRICE_DTYPES)\n    for col, col_dtype in PRICE_DTYPES.items():\n        if col_dtype == \"category\":\n            prices[col] = prices[col].cat.codes.astype(\"int16\")\n            prices[col] -= prices[col].min()\n            \n    cal = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\", dtype = CAL_DTYPES)\n    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n    for col, col_dtype in CAL_DTYPES.items():\n        if col_dtype == \"category\":\n            cal[col] = cal[col].cat.codes.astype(\"int16\")\n            cal[col] -= cal[col].min()\n    \n    start_day = max(1 if is_train  else tr_last-max_lags, first_day)\n    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    dtype = {numcol:\"float32\" for numcol in numcols} \n    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n    dt = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\", \n                     nrows = nrows, usecols = catcols + numcols, dtype = dtype)\n    \n    for col in catcols:\n        if col != \"id\":\n            dt[col] = dt[col].cat.codes.astype(\"int16\")\n            dt[col] -= dt[col].min()\n    \n    if not is_train:\n        for day in range(tr_last+1, tr_last+ 28 +1):\n            dt[f\"d_{day}\"] = np.nan\n    \n    dt = pd.melt(dt,\n                  id_vars = catcols,\n                  value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n                  var_name = \"d\",\n                  value_name = \"sales\")\n    \n    dt = dt.merge(cal, on= \"d\", copy = False)\n    dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n    \n    return dt","30706bb8":"def create_fea(dt):\n    lags = [7, 28]\n    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n    for lag, lag_col in zip(lags, lag_cols):\n        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n\n    wins = [7, 28]\n    for win in wins :\n        for lag,lag_col in zip(lags, lag_cols):\n            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n\n    \n    \n    date_features = {\n        \n        \"wday\": \"weekday\",\n        \"week\": \"weekofyear\",\n        \"month\": \"month\",\n        \"quarter\": \"quarter\",\n        \"year\": \"year\",\n        \"mday\": \"day\",\n#         \"ime\": \"is_month_end\",\n#         \"ims\": \"is_month_start\",\n    }\n    \n#     dt.drop([\"d\", \"wm_yr_wk\", \"weekday\"], axis=1, inplace = True)\n    \n    for date_feat_name, date_feat_func in date_features.items():\n        if date_feat_name in dt.columns:\n            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n        else:\n            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")","3c6e2f2b":"FIRST_DAY = 1050","1d6aec92":"%%time\n\ndf = create_dt(is_train=True, first_day= FIRST_DAY)\ndf.shape","ad78494a":"df.head()","d2657e17":"%%time\n\ncreate_fea(df)\ndf.shape","e188f78a":"df.dropna(inplace = True)\ndf.shape","0ca02428":"useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\ntrain_cols = df.columns[~df.columns.isin(useless_cols)]\n\ntrain_cols = list(train_cols)\ntrain_cols.append(\"sales\")\ntrain_cols","07ed9500":"X_train = df[train_cols]","f55abbbb":"X_train.to_csv(\"X_train.csv\", index=False)","07eb09e1":"del df, X_train \ngc.collect()\n","cb0dc387":"test = create_dt(False)","f3f7faab":"test.shape","c0d1e9e5":"create_fea(test)","caa7b24a":"train_cols[:-1]","82d12ddd":"X_test = test[train_cols[:-1]]","1f810463":"X_test.to_csv(\"X_test.csv\", index=False)","e2986b11":"del test, X_test\ngc.collect()","97194aa7":"The purpose of this notebook is to create the best set of features from the following kernel: https:\/\/www.kaggle.com\/kneroma\/m5-first-public-notebook-under-0-50\nThe features will be saved, and further used for exploaration in other kernels."}}