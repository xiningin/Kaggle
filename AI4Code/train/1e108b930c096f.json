{"cell_type":{"da4a55c0":"code","675dbdd7":"code","f48f4b41":"code","fb898e81":"code","50d58252":"code","50b147df":"code","cce5c6a1":"code","c5f5452c":"code","28beb3f8":"code","2bd6e8da":"code","f3e9052a":"code","fdc1ff7f":"code","68508255":"code","9ff48bd7":"code","4c9a02cf":"code","f8e132df":"code","7d3dbb7c":"code","ffa12e28":"code","24541ae1":"code","9bbbf221":"code","ec1cb4d3":"code","2115a916":"code","478f90fc":"code","12d1be09":"code","5924e896":"code","d5f85eda":"code","15506fdb":"code","56953208":"code","fc77b5df":"code","e4898671":"code","0575b012":"code","b8a0b7ca":"code","84583737":"code","1a86d0e2":"code","61f2abf1":"code","78d3b67c":"code","b0dfb446":"code","f0ad0fd3":"code","6348bb00":"code","3c28ed0d":"code","6a01fb4b":"code","64a4c753":"markdown","2ab63dc9":"markdown","aa5b45f4":"markdown","6fe0ac4f":"markdown","f623aab9":"markdown","b9eb9c61":"markdown","575be3a4":"markdown","cc619337":"markdown"},"source":{"da4a55c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","675dbdd7":"# data analysis and wrangling\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rnd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nimport time\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n!pip install py7zr","f48f4b41":"import py7zr\nimport zipfile\n\narchive = py7zr.SevenZipFile('\/kaggle\/input\/mercari-price-suggestion-challenge\/train.tsv.7z', mode='r')\narchive.extractall(path='\/kaggle\/temp\/')\narchive.close()\n\nwith zipfile.ZipFile('\/kaggle\/input\/mercari-price-suggestion-challenge\/test_stg2.tsv.zip', 'r') as zip_ref:\n    zip_ref.extractall('\/kaggle\/temp\/')","fb898e81":"for dirname, _, filenames in os.walk('\/kaggle\/temp'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","50d58252":"train = pd.read_csv('\/kaggle\/temp\/train.tsv', sep='\\t')","50b147df":"train.info()","cce5c6a1":"A = train[['name', 'price']].groupby(['name'], as_index=False).mean().sort_values(by='price', ascending=False)\nB = train[['item_condition_id', 'price']].groupby(['item_condition_id'], as_index=False).mean().sort_values(by='price', ascending=False)\nC = train[['category_name', 'price']].groupby(['category_name'], as_index=False).mean().sort_values(by='price', ascending=False)\nD = train[['brand_name', 'price']].groupby(['brand_name'], as_index=False).mean().sort_values(by='price', ascending=False)\nE = train[['shipping', 'price']].groupby(['shipping'], as_index=False).mean().sort_values(by='price', ascending=False)\nF = train[['category_name', 'price']].groupby(['category_name'], as_index=False).mean().sort_values(by='price', ascending=False)","c5f5452c":"for i in (A, B, C, D, E, F):\n    print(i)","28beb3f8":"X = train.drop(['train_id', 'price'], axis=1)\ny = train['price']\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train = X\ny_train = y","2bd6e8da":"print(X_train.shape)\nprint(X_train.columns.values)\nprint(train.shape)","f3e9052a":"global brand_uniq\nbrand_uniq = X_train.loc[X_train.brand_name.notnull(), ['brand_name']]\nbrand_uniq = brand_uniq['brand_name'].unique()\nprint(brand_uniq)\nbrand_null_index = X_train[X_train.brand_name.isnull()].index\nprint(brand_null_index)","fdc1ff7f":"def add_brandname1(name):\n    global brand_uniq\n    for i in brand_uniq:\n        if i in name:\n            return(i)\n    return('')\n\ndef add_brandname2(df, brand_null_index):\n    df.loc[brand_null_index, 'brand_name'] = df.name[brand_null_index].apply(add_brandname1)\n    return(df)","68508255":"start = time.time()\nX_train = add_brandname2(X_train, brand_null_index)\nX_train.brand_name\nprint(\"brand replace time :\", time.time() - start)","9ff48bd7":"plt.hist(y_train)","4c9a02cf":"y_train = np.log1p(y_train)\nplt.hist(y_train)","f8e132df":"print(sum(X_train.name.isnull())) #0\nprint(sum(X_train.item_condition_id.isnull())) #0\nprint(sum(X_train.category_name.isnull())) #5718\nprint(sum(X_train.brand_name.isnull())) #0\nprint(sum(X_train.shipping.isnull())) #0\nprint(sum(X_train.item_description.isnull())) #3","7d3dbb7c":"X_train.category_name = X_train.category_name.fillna('Others')\nprint(sum(X_train.category_name.isnull()))","ffa12e28":"object_cate = X_train.category_name.value_counts()[X_train.category_name.value_counts() > 5000].index.values\nX_train.category_name[~X_train.category_name.isin(object_cate)] = 'Others'","24541ae1":"X_train.brand_name[X_train.brand_name == ''] = 'Others'","9bbbf221":"object_brand = X_train.brand_name.value_counts()[X_train.brand_name.value_counts() > 5000].index.values\nX_train.brand_name[~X_train.brand_name.isin(object_brand)] = 'Others'","ec1cb4d3":"feature = X_train.drop(['name', 'item_description'], axis = 1)\nprint(feature.info())\nprint(X_train.info())","2115a916":"le1 = preprocessing.LabelEncoder()\nle2 = preprocessing.LabelEncoder()\n\n# Converting string labels into numbers.\nle1.fit(list(feature.brand_name))\nle2.fit(list(feature.category_name))\n\nbrand_name=le1.transform(list(feature.brand_name))\ncategory_name=le2.transform(list(feature.category_name))","478f90fc":"feature_processed = zip(brand_name, category_name, X_train.item_condition_id, X_train.shipping)\nfeature_processed = list(feature_processed)\nprint(feature_processed[:10])","12d1be09":"from sklearn.linear_model import BayesianRidge, LinearRegression\n#from sklearn.svm import SVR\n#training SVR was too slow because of dataset's size\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n#start = time.time()\n#clf = BayesianRidge(compute_score=True)\n#clf.fit(feature_processed, y_train)\n#print(\"clf time :\", time.time() - start)\n\n#start = time.time()\n#ols = LinearRegression()\n#ols.fit(feature_processed, y_train)\n#print(\"ols time :\", time.time() - start)","5924e896":"start = time.time()\nrfr = RandomForestRegressor(n_estimators=100)\nrfr.fit(feature_processed, y_train)\nprint(\"rfr time :\", time.time() - start)","d5f85eda":"#start = time.time()\n#mlp = MLPRegressor(random_state=1, max_iter=500)\n#mlp.fit(feature_processed, y_train)\n#print(\"mlp time :\", time.time() - start)","15506fdb":"#start = time.time()\n#reg = GradientBoostingRegressor(random_state=0)\n#reg.fit(feature_processed, y_train)\n#print(\"reg time :\", time.time() - start)","56953208":"\"\"\"\nMSE_clf = mean_squared_error(np.log1p(y_test), predicted_clf) #1.630\nprint(MSE_clf**0.5)\nMSE_ols = mean_squared_error(np.log1p(y_test), predicted_ols) #1.630\nprint(MSE_ols**0.5)\nMSE_rfr = mean_squared_error(np.log1p(y_test), predicted_rfr) #1.646 n = 10\nprint(MSE_rfr**0.5)\nMSE_mlp = mean_squared_error(np.log1p(y_test), predicted_mlp) #1.510 (iter = 5), 1.576 (iter = 10)\nprint(MSE_mlp**0.5)\n\"\"\"","fc77b5df":"#Same processing to test data\ntest = pd.read_csv('\/kaggle\/temp\/test_stg2.tsv', sep='\\t')\ntest.info()","e4898671":"X_test = test.drop(['test_id'], axis=1)\n\nstart = time.time()\nbrand_null_index = X_test[X_test.brand_name.isnull()].index\nX_test = add_brandname2(X_test, brand_null_index)\nprint(\"brand replace time :\", time.time() - start)","0575b012":"X_test.category_name = X_test.category_name.fillna('Others')\nprint(sum(X_test.category_name.isnull()))","b8a0b7ca":"X_test.category_name[~X_test.category_name.isin(object_cate)] = 'Others'\nX_test.brand_name[X_test.brand_name == ''] = 'Others'\nX_test.brand_name[~X_test.brand_name.isin(object_brand)] = 'Others'","84583737":"feature_test = X_test.drop(['name', 'item_description'], axis = 1)\nprint(feature_test.info())\nprint(X_test.info())","1a86d0e2":"brand_name_test=le1.transform(list(feature_test.brand_name))\ncategory_name_test=le2.transform(list(feature_test.category_name))","61f2abf1":"feature_processed_test = zip(brand_name_test, category_name_test, X_test.item_condition_id, X_test.shipping)\nfeature_processed_test = list(feature_processed_test)\nprint(feature_processed_test[:10])","78d3b67c":"#Predict Output (test_data)\n#predicted_clf = clf.predict(feature_processed_test)\n#predicted_ols = ols.predict(feature_processed_test) \npredicted_rfr = rfr.predict(feature_processed_test)\n#predicted_mlp = mlp.predict(feature_processed_test)\n#predicted_reg = reg.predict(feature_processed_test)","b0dfb446":"Y_pred_rfr = np.expm1(predicted_rfr)\n#Y_pred_mlp = np.expm1(predicted_mlp)\n#Y_pred_reg = np.expm1(predicted_reg)","f0ad0fd3":"#Y_pred_rfr_mlp = (Y_pred_rfr + Y_pred_mlp)\/2","6348bb00":"submission_rfr = pd.DataFrame({\n        \"test_id\": test[\"test_id\"],\n        \"price\": Y_pred_rfr\n    })\n\n#submission_mlp = pd.DataFrame({\n#        \"test_id\": test[\"test_id\"],\n#        \"price\": Y_pred_mlp\n#    })\n\n#submission_rfr_mlp = pd.DataFrame({\n#        \"test_id\": test[\"test_id\"],\n#        \"price\": Y_pred_rfr_mlp\n#    })\n\n#submission_reg = pd.DataFrame({\n#        \"test_id\": test[\"test_id\"],\n#        \"price\": Y_pred_reg\n#    })","3c28ed0d":"#print(submission_rfr_mlp.head())\n#print(submission_reg.head())","6a01fb4b":"#submission_rfr.to_csv('submission.csv', index=False)\n#submission_mlp.to_csv('submission.csv', index=False)\nsubmission_rfr.to_csv('submission.csv', index=False)","64a4c753":"# Feature Engineering 3\n\n#### Null to \"Others\" (category_name)\n#### Sparse item to \"Others\" (category_name, brand_name)\n#### Drop some features (name, item_description)\n#### Nominal variable to int through labelEncoder (category_name, brand_name)\n","2ab63dc9":"# Divide into Train & Test Set\n\n### 1st time: Use train_test_split, and divide train.csv to train\/test data (this part is deactivated now)\n### 2st time: After decided which model to use, use whole data of train.csv to train data","aa5b45f4":"# Feature Engineering 2\n\n#### log processed to price","6fe0ac4f":"# Data Import","f623aab9":"# Model Comparision\n\n#### Naive Bayes, Linear Regression, Random Forest, Multi layer Perceptron\n#### No hyperparameter tuning, because of lack of time","b9eb9c61":"# Feature Engineering 1\n\n#### I've decided not to use name feature, but sometimes \"name\" has information about \"brand_name\".\n#### So I extracted \"brand_name\" information from \"name\" like below:","575be3a4":"# Data Overall","cc619337":"# Prediction for test.csv\n\n#### I've decided to use MLPRegressor, on the basis of comparison of 4 models. (deactivated the source code like below)"}}