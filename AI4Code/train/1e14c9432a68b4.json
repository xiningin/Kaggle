{"cell_type":{"18317a8a":"code","ef5032de":"code","6cd8f5bb":"code","f7f66aff":"code","0489c440":"code","45d6c268":"code","13a06d6c":"code","36639a7f":"code","9d1672ad":"code","b9851dfc":"code","9ead562a":"markdown","3340e9c4":"markdown","9c20f618":"markdown","68c9b420":"markdown","1cad055f":"markdown","cae0986d":"markdown","3e6ba294":"markdown"},"source":{"18317a8a":"import numpy as np\nimport pandas as pd\n\nimport os\nimport json\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nimport pdb","ef5032de":"data_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge\/')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'","6cd8f5bb":"def plot_result(test_input, test_prediction,\n                input_shape):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 2, figsize=(15,15))\n    test_input = test_input.reshape(input_shape[0],input_shape[1])\n    axs[0].imshow(test_input, cmap=cmap, norm=norm)\n    axs[0].axis('off')\n    axs[0].set_title('Actual Target')\n    test_prediction = test_prediction.reshape(input_shape[0],input_shape[1])\n    axs[1].imshow(test_prediction, cmap=cmap, norm=norm)\n    axs[1].axis('off')\n    axs[1].set_title('Model Prediction')\n    plt.tight_layout()\n    plt.show()\n    \ndef plot_test(test_prediction, task_name):\n    \"\"\"\n    Plots the first train and test pairs of a specified task,\n    using same color scheme as the ARC app\n    \"\"\"\n    cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n    norm = colors.Normalize(vmin=0, vmax=9)\n    fig, axs = plt.subplots(1, 1, figsize=(15,15))\n    axs.imshow(test_prediction, cmap=cmap, norm=norm)\n    axs.axis('off')\n    axs.set_title(f'Test Prediction {task_name}')\n    plt.tight_layout()\n    plt.show()","f7f66aff":"# https:\/\/www.kaggle.com\/inversion\/abstraction-and-reasoning-starter-notebook\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","0489c440":"sample_sub = pd.read_csv(data_path\/'sample_submission.csv')\nsample_sub = sample_sub.set_index('output_id')\nsample_sub.head()","45d6c268":"def get_moore_neighbours(color, cur_row, cur_col, nrows, ncols):\n\n    if cur_row<=0: top = -1\n    else: top = color[cur_row-1][cur_col]\n        \n    if cur_row>=nrows-1: bottom = -1\n    else: bottom = color[cur_row+1][cur_col]\n        \n    if cur_col<=0: left = -1\n    else: left = color[cur_row][cur_col-1]\n        \n    if cur_col>=ncols-1: right = -1\n    else: right = color[cur_row][cur_col+1]\n        \n    return top, bottom, left, right\n\ndef get_tl_tr(color, cur_row, cur_col, nrows, ncols):\n        \n    if cur_row==0:\n        top_left = -1\n        top_right = -1\n    else:\n        if cur_col==0: top_left=-1\n        else: top_left = color[cur_row-1][cur_col-1]\n        if cur_col==ncols-1: top_right=-1\n        else: top_right = color[cur_row-1][cur_col+1]   \n        \n    return top_left, top_right","13a06d6c":"def features(task, mode='train'):\n    cur_idx = 0\n    num_train_pairs = len(task[mode])\n    total_inputs = sum([len(task[mode][i]['input'])*len(task[mode][i]['input'][0]) for i in range(num_train_pairs)])\n    feat = np.zeros((total_inputs,nfeat))\n    target = np.zeros((total_inputs,), dtype=np.int)\n    \n    global local_neighb\n    for task_num in range(num_train_pairs):\n        input_color = np.array(task[mode][task_num]['input'])\n        target_color = task[mode][task_num]['output']\n        nrows, ncols = len(task[mode][task_num]['input']), len(task[mode][task_num]['input'][0])\n\n        target_rows, target_cols = len(task[mode][task_num]['output']), len(task[mode][task_num]['output'][0])\n        \n        if (target_rows!=nrows) or (target_cols!=ncols):\n            print('Number of input rows:',nrows,'cols:',ncols)\n            print('Number of target rows:',target_rows,'cols:',target_cols)\n            not_valid=1\n            return None, None, 1\n\n        for i in range(nrows):\n            for j in range(ncols):\n                feat[cur_idx,0] = i\n                feat[cur_idx,1] = j\n                feat[cur_idx,2] = input_color[i][j]\n                feat[cur_idx,3:7] = get_moore_neighbours(input_color, i, j, nrows, ncols)\n                feat[cur_idx,7:9] = get_tl_tr(input_color, i, j, nrows, ncols)\n                feat[cur_idx,9] = len(np.unique(input_color[i,:]))\n                feat[cur_idx,10] = len(np.unique(input_color[:,j]))\n                feat[cur_idx,11] = (i+j)\n                feat[cur_idx,12] = len(np.unique(input_color[i-local_neighb:i+local_neighb,\n                                                             j-local_neighb:j+local_neighb]))\n        \n                target[cur_idx] = target_color[i][j]\n                cur_idx += 1\n            \n    return feat, target, 0","36639a7f":"all_task_ids = sorted(os.listdir(test_path))\n\nnfeat = 13\nlocal_neighb = 5\nvalid_scores = {}\nfor task_id in all_task_ids:\n\n    task_file = str(test_path \/ task_id)\n    with open(task_file, 'r') as f:\n        task = json.load(f)\n\n    feat, target, not_valid = features(task)\n    if not_valid:\n        print('ignoring task', task_file)\n        print()\n        not_valid = 0\n        continue\n\n    nrows, ncols = len(task['train'][-1]['input']\n                       ), len(task['train'][-1]['input'][0])\n    # use the last train sample for validation\n    val_idx = len(feat) - nrows*ncols\n\n    train_feat = feat[:val_idx]\n    val_feat = feat[val_idx:, :]\n\n    train_target = target[:val_idx]\n    val_target = target[val_idx:]\n\n    #     check if validation set has a new color\n    #     if so make the mapping color independant\n    if len(set(val_target) - set(train_target)):\n        print('set(val_target)', set(val_target))\n        print('set(train_target)', set(train_target))\n        print('Number of colors are not same')\n        print('cant handle new colors. skipping')\n        continue\n\n    lgb = LGBMClassifier(n_estimators=50, n_jobs=-1)\n    lgb.fit(feat, target,\n            verbose=-1)\n\n\n#     training on input pairs is done.\n#     test predictions begins here\n\n    num_test_pairs = len(task['test'])\n    for task_num in range(num_test_pairs):\n        cur_idx = 0\n        input_color = np.array(task['test'][task_num]['input'])\n        nrows, ncols = len(task['test'][task_num]['input']), len(\n            task['test'][task_num]['input'][0])\n        feat = np.zeros((nrows*ncols, nfeat))\n        unique_col = {col: i for i, col in enumerate(\n            sorted(np.unique(input_color)))}\n\n        for i in range(nrows):\n            for j in range(ncols):\n                feat[cur_idx, 0] = i\n                feat[cur_idx, 1] = j\n                feat[cur_idx, 2] = input_color[i][j]\n                feat[cur_idx, 3:7] = get_moore_neighbours(\n                    input_color, i, j, nrows, ncols)\n                feat[cur_idx, 7:9] = get_tl_tr(\n                    input_color, i, j, nrows, ncols)\n                feat[cur_idx, 9] = len(np.unique(input_color[i, :]))\n                feat[cur_idx, 10] = len(np.unique(input_color[:, j]))\n                feat[cur_idx, 11] = (i+j)\n                feat[cur_idx, 12] = len(np.unique(input_color[i-local_neighb:i+local_neighb,\n                                                              j-local_neighb:j+local_neighb]))\n\n                cur_idx += 1\n\n        print('Made predictions for ', task_id[:-5])\n        preds = lgb.predict(feat).reshape(nrows, ncols)\n        preds = preds.astype(int).tolist()\n        plot_test(preds, task_id)\n        sample_sub.loc[f'{task_id[:-5]}_{task_num}',\n                       'output'] = flattener(preds)\n","9d1672ad":"sample_sub.head()","b9851dfc":"sample_sub.to_csv('submission.csv')","9ead562a":"# Extract neighbourhood Features","3340e9c4":"# Loading Libraries","9c20f618":"# For flattening 2D numpy arrays","68c9b420":"# Plotting functions","1cad055f":"# Training and Prediction","cae0986d":"# Set Paths","3e6ba294":"# Make features for each train sample"}}