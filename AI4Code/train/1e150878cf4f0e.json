{"cell_type":{"165f5d54":"code","cdd1ad13":"code","c9551788":"code","c25baf49":"code","625cbdfc":"code","39b6ba7d":"code","188e5b24":"code","23614648":"code","b940da71":"code","f8072f48":"code","3a2d27ef":"code","e299d8f1":"code","08f05a74":"code","c215e800":"code","1ae2a130":"code","e2e53d06":"markdown","2d1e275f":"markdown","87e79be2":"markdown","1a15c756":"markdown","c61d9837":"markdown","13df6b47":"markdown","f23c64cc":"markdown","ec2a2191":"markdown","cb6eb6fa":"markdown","54ee3eca":"markdown","35bb9b39":"markdown"},"source":{"165f5d54":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(16,8)})\nsns.set(font_scale=1.3)\nplt.style.use('fivethirtyeight')\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, RepeatVector, TimeDistributed\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimport warnings\nwarnings.filterwarnings('ignore')","cdd1ad13":"df = pd.read_csv('..\/input\/microsoft-stock-time-series-analysis\/Microsoft_Stock.csv',\n                 infer_datetime_format=True, parse_dates=['Date'], index_col=['Date'])\ndf.head()","c9551788":"df.info()","c25baf49":"df.describe()","625cbdfc":"plt.figure(figsize=(16,8))\nplt.plot(df['Close'], label='Close Price history',color='b')\nplt.xlabel('Date',size=20)\nplt.ylabel('Stock Price',size=20)\nplt.title('Stock Price of Microsoft Over the Years',size=25);","39b6ba7d":"# Normalizes the data\ndef to_dataset(data):\n    data = data.astype('float32')\n    #scaler = MinMaxScaler(feature_range=(0,1))\n    #return scaler.fit_transform(data)\n    return data\/255.\n\n# Data train and test\ndef train_test(data):\n    train_size = int(len(data) * 0.75)\n    train, test = data[0:train_size, :], data[train_size:len(data), :]\n    return train, test\n\n# Time windows - use 10 days to forecast the nest 10 days \ndef windows(sequence, step_in, step_out):\n    x, y = [], []\n    for i in range(len(sequence)):\n        end_i = i + step_in\n        out_i = end_i + step_out\n        if out_i > len(sequence):\n            break\n        seq_x, seq_y = sequence[i:end_i, :], sequence[end_i:out_i, :]\n        x.append(seq_x)\n        y.append(seq_y)\n    return np.array(x), np.array(y)\n\n# Model\ndef creat_model(step_in, step_out, features):\n    model = Sequential()\n    model.add(LSTM(50, activation='relu', input_shape=(step_in, features)))\n    model.add(RepeatVector(step_out))\n    model.add(LSTM(200, activation='relu', return_sequences=True))\n    model.add(TimeDistributed(Dense(features)))\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n    return model\n\n# Run all functions\ndef prepare_training(data, step_in, step_out):\n    data = to_dataset(data)\n    train, test = train_test(data)\n    x_train, x_test = windows(train, step_in, step_out)\n    y_train, y_test = windows(test, step_in, step_out)\n    features = 1\n    return x_train, x_test, y_train, y_test, features","188e5b24":"step_in, step_out = 10, 10 \nepochs = 50 \nbatch_size = 32\n\nearly = EarlyStopping(monitor='val_loss',patience=5)\nreduce = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, mil_lr=0.001)","23614648":"data = df['Close'].values\ndata = data.reshape(-1, 1)","b940da71":"x_train, y_train, x_test, y_test, feature = prepare_training(data, step_in, step_out)","f8072f48":"model = creat_model(step_in, step_out, feature)","3a2d27ef":"history = model.fit(x_train, y_train, epochs=epochs, batch_size=144, verbose=1,\n         validation_data=(x_test, y_test), callbacks=[early,reduce])","e299d8f1":"plt.plot(history.history['mean_squared_error'])\nplt.plot(history.history['val_mean_squared_error'])\nplt.xlabel('Epochs')\nplt.ylabel('MSE')\nplt.legend(['Train','Test']);","08f05a74":"pred = model.predict(x_test)","c215e800":"x = x_test[0]*255.0\ny = pred[0]*255.0","1ae2a130":"plt.plot(x)\nplt.plot(y)\nplt.legend(['Real Value','Predicted Value']);","e2e53d06":"<div style=\"color:black; background-color:#f5f7b0; font-size: 120%;border-radius:10px; padding:20px;\">\n<b>Conclusion<\/b><br\/>\n    \nThe model was not perfect but it got a result close to reality.\n<\/div>","2d1e275f":"<a name=\"predictions\">\n\n# <p style=\"background-color:#1c56c9; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  25px; color:#ffffff; padding-top:5px; padding-bottom:5px;\">Prediction<\/p>","87e79be2":"# <p style=\"background-color:#1c56c9; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  25px; color:#ffffff; padding-top:5px; padding-bottom:5px;\">Forecasting the Stock Market with LSTM<\/p>","1a15c756":"<a name=\"eda\">\n    \n# <p style=\"background-color:#1c56c9; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  25px; color:#ffffff; padding-top:5px; padding-bottom:5px;\">EDA<\/p>","c61d9837":"<a name=\"model\">\n\n# <p style=\"background-color:#1c56c9; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  25px; color:#ffffff; padding-top:5px; padding-bottom:5px;\">Model<\/p>","13df6b47":"We have data for ther year 2015 to 2021.","f23c64cc":"## What is Long Short Term Memory (LSTM)\nLSTM is a recurrent neural network (RNN) architecture that \u201cremembers\u201d values \u200b\u200bat arbitrary intervals. LSTM is well suited for classifying, processing and predicting time series with time intervals of unknown duration. We can apply for price prediction, sentiment analysis, text generation.\n\nThe network has 3 gates:\n* Forget Gate: Information that is no longer useful in cell state is removed with forget gate. Two inputs: x_t (point-in-time input) and h_t-1 (previous cell output) are fed to the gate and multiplied by weight matrices, followed by the addition of the bias. The resultant is passed through an activation function that provides a binary output. If for a given cell state the output is 0, the information is forgotten and for output 1, the information is retained for future use.\n\n\n* Input Gate: Adding useful information to the cell state is done by the input gate. First, the information is regulated using the sigmoid function which filters the values \u200b\u200bto be remembered similarly to forget gate using the h_t-1 and x_t inputs. Then, a vector is created using the tanh function that outputs -1 to +1, which contains all possible values \u200b\u200bof h_t-1 and x_t. Vector values \u200b\u200band calibrated values \u200b\u200bare multiplied to obtain useful information.\n\n\n* Output Gate: The task of extracting useful information from the current cell state to be presented as an output is done by the output gate. First, a vector is generated by applying the tanh function to the cell. Then, the information is regulated using the sigmoid function that filters the values \u200b\u200bto be remembered using the inputs h_t-1 and x_t. Vector values \u200b\u200band regulated values \u200b\u200bare multiplied to be sent as an output and input to the next cell. \n\n<img src=\"https:\/\/www.deeplearningbook.com.br\/wp-content\/uploads\/2019\/08\/lstmcell.png\">","ec2a2191":"# Stock Market\n\n<img src=\"https:\/\/blog.clear.com.br\/wp-content\/uploads\/2018\/12\/margem-de-garantia-trader.png\">\n\nThe stock market is a public and organized environment for trading certain securities and real estate (stocks, stock options, real estate funds, etc.). Transactions can take place through stock exchanges or on the so-called over-the-counter markets (markets in which securities not traded on exchanges are traded, within the legal rules provided for by law and regulations, without coordination by private self-regulatory entities).\n\n# Understanding the Problem\n\nIn the stock market, we carry out purchase and sale transactions for profit. In this example, we are going to analyze the LSTM neural network to predict the stock's closing price in 10 days. It's just one example of the power of neural networks.","cb6eb6fa":"<a name=\"import\">\n\n# <p style=\"background-color:#1c56c9; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  25px; color:#ffffff; padding-top:5px; padding-bottom:5px;\">Import<\/p>","54ee3eca":"<a name=\"functions\">\n\n# <p style=\"background-color:#1c56c9; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  25px; color:#ffffff; padding-top:5px; padding-bottom:5px;\">Functions<\/p>\n","35bb9b39":"* <a href=\"#import\">Import<\/a>\n\n* <a href=\"#eda\">EDA<\/a>\n\n* <a href=\"#functions\">Functions<\/a>\n\n* <a href=\"#model\">Model<\/a>\n\n* <a href=\"#predictions\">Predictions<\/a>"}}