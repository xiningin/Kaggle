{"cell_type":{"29a3b7c6":"code","76d33b56":"code","0542334c":"code","535771d9":"code","dffabccd":"code","57851d30":"code","ac2f7b51":"code","445beb88":"code","3f0d122e":"code","d29df6eb":"code","3a8d55b7":"code","a6ded664":"code","4a0e4126":"code","10c7c190":"code","e216d1e5":"code","0366b5f0":"code","19e97c1c":"code","827a6c2d":"code","91b61972":"code","dcfc3cb8":"code","cf36072c":"code","327d5584":"code","2af47a24":"code","5f72b388":"code","ebc94ebf":"code","a83d9baf":"code","e78010ba":"code","edb9dd7d":"code","bd903320":"code","80c89d29":"code","3c419b99":"code","17dcd398":"code","93504d02":"code","0b4e1e79":"code","46573770":"markdown","5e4c2a3f":"markdown","8ae141e0":"markdown","fb743e4c":"markdown","40ba1264":"markdown","248c3be9":"markdown","02777b22":"markdown","c771f127":"markdown","4bf240f5":"markdown","9a256ec5":"markdown","f8b7f727":"markdown","0bfda054":"markdown"},"source":{"29a3b7c6":"# Importing the necessary library\nimport pandas as pd\n\n# Reading the file\nretail = pd.read_csv('..\/input\/learning-data\/OnlineRetail.csv', header=0)\nretail.head()","76d33b56":"# Checking the number of rows and columns\nretail.shape","0542334c":"# Details of the dataframe\nretail.info()","535771d9":"#Missing values count\nretail.isnull().sum()","dffabccd":"# Finding the missing values in percentage\nround(100*retail.isnull().sum()\/len(retail), 2)","57851d30":"# Dropping the rows of missing values\nretail = retail.dropna()\n\n# Getting the number of rows and columns\nprint(\"Shape of retail :\", retail.shape)\n\n# Finding the missing values in percentage\nround(100*retail.isnull().sum()\/len(retail), 2)","ac2f7b51":"# Creating the new column: amount\nretail[\"Amount\"] = retail.Quantity * retail.UnitPrice\nretail.head()","445beb88":"# Change the datatype of 'InvoiceDate' to datetime\nretail.InvoiceDate = pd.to_datetime(retail.InvoiceDate, format='%d-%m-%Y %H:%M')\nretail.info()","3f0d122e":"# Compute the max date\nmax_date = max(retail.InvoiceDate)\nmax_date","d29df6eb":"# Compute the diff\nretail['diff'] = max_date - retail.InvoiceDate\nretail.head()","3a8d55b7":"# Grouping by days\nlatest_purchase = retail.groupby(retail.CustomerID)['diff'].min().reset_index()\nlatest_purchase.head()","a6ded664":"# Grouping by InvoiceNo\ngrouped_frequency = retail.groupby(retail.CustomerID)[\"InvoiceNo\"].count().reset_index()\ngrouped_frequency.head()","4a0e4126":"# Grouping by Amount\ngrouped_retail = retail.groupby(retail.CustomerID)['Amount'].sum().reset_index()\ngrouped_retail.head()","10c7c190":"# Merging the two dataframes\ngrouped_retail = pd.merge(grouped_retail, grouped_frequency, on='CustomerID', how='inner')\ngrouped_retail = pd.merge(grouped_retail, latest_purchase, on='CustomerID', how='inner')\ngrouped_retail.head()","e216d1e5":"# Changing the column name\ngrouped_retail.columns = ['CustomerID','amount', 'frequency', 'recency']\ngrouped_retail.head()","0366b5f0":"# Importing the datetime\nimport datetime as dt\n\n# Number of days only\ngrouped_retail.recency = grouped_retail.recency.dt.days\ngrouped_retail.head()","19e97c1c":"# Importing matplotlib\nimport matplotlib.pyplot as plt\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Plotting graphs for all columns\nplt.figure(figsize=(25,5))\n\nplt.subplot(1,3,1)\nplt.title(\"Amount\")\nplt.boxplot(grouped_retail.amount)\n\nplt.subplot(1,3,2)\nplt.title(\"Frequency\")\nplt.boxplot(grouped_retail.frequency)\n\nplt.subplot(1,3,3)\nplt.title(\"Recency\")\nplt.boxplot(grouped_retail.recency)\n\nplt.show()","827a6c2d":"# Removing the statistical outliers\n# Outlier treatment for 'Amount'\nQ1 = grouped_retail.amount.quantile(0.05)\nQ3 = grouped_retail.amount.quantile(0.95)\nIQR = Q3 - Q1\ngrouped_retail = grouped_retail[(grouped_retail.amount >= Q1 - 1.5*IQR) & (grouped_retail.amount <= Q3 + 1.5*IQR)]\n\n# Outlier treatment for 'Recency'\nQ1 = grouped_retail.recency.quantile(0.05)\nQ3 = grouped_retail.recency.quantile(0.95)\nIQR = Q3 - Q1\ngrouped_retail = grouped_retail[(grouped_retail.recency >= Q1 - 1.5*IQR) & (grouped_retail.recency <= Q3 + 1.5*IQR)]\n\n# Outlier treatment for 'Frequency'\nQ1 = grouped_retail.frequency.quantile(0.05)\nQ3 = grouped_retail.frequency.quantile(0.95)\nIQR = Q3 - Q1\ngrouped_retail = grouped_retail[(grouped_retail.frequency >= Q1 - 1.5*IQR) & (grouped_retail.frequency <= Q3 + 1.5*IQR)]","91b61972":"# Taking columns for RFM\nrfm_df = grouped_retail[['amount', 'frequency', 'recency']]\nrfm_df.head()","dcfc3cb8":"# Importing sklearn\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\n# Instantiate the scaler\nscaler = StandardScaler()\n\n# Fit_transform the values\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nprint(rfm_df_scaled.shape)\nrfm_df_scaled","cf36072c":"# Creating a dataframe\nrfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['amount', 'frequency', 'recency']\nrfm_df_scaled.head()","327d5584":"# Importing the libraries\nfrom sklearn.cluster import KMeans\n\n# K-Means with some arbitrary k\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)","2af47a24":"# Getting the labels\nkmeans.labels_","5f72b388":"# elbow-curve\/SSD\nssd=[]\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(rfm_df_scaled)\n    \n    ssd.append(kmeans.inertia_)\n    \n# Plot the SSDs for each n_clusters\nplt.plot(ssd)\nplt.show()","ebc94ebf":"from sklearn.metrics import silhouette_score\n\n# Calculating\nfor num_clusters in range_n_clusters:\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)\n    kmeans.fit(rfm_df_scaled)\n    \n    silhouette_avg = silhouette_score(rfm_df_scaled, kmeans.labels_)\n    print(\"For n_clusters={0}, the silhoutte score is {1}\".format(num_clusters, silhouette_avg))","a83d9baf":"# Final model with k=3\nkmeans = KMeans(n_clusters=3, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n\nkmeans.labels_","e78010ba":"# Assigning the label\ngrouped_retail['cluster_id'] = kmeans.labels_\ngrouped_retail.head()","edb9dd7d":"import seaborn as sns\n\n#Plotting the graph\nplt.figure(figsize=(25,5))\n\nplt.subplot(1,3,1)\nplt.title(\"Amount\")\nsns.boxplot(x=grouped_retail.cluster_id, y=grouped_retail.amount, data=grouped_retail)\n\nplt.subplot(1,3,2)\nplt.title(\"Frequency\")\nsns.boxplot(x=grouped_retail.cluster_id, y=grouped_retail.frequency, data=grouped_retail)\n\nplt.subplot(1,3,3)\nplt.title(\"Recency\")\nsns.boxplot(x=grouped_retail.cluster_id, y=grouped_retail.recency, data=grouped_retail)\n\nplt.show()","bd903320":"# Importing libraries\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","80c89d29":"# Single Linkage\nmergings = linkage(rfm_df_scaled, method='single', metric='euclidean')\ndendrogram(mergings)\nplt.show()","3c419b99":"# Complete Linkage\nmergings = linkage(rfm_df_scaled, method='complete', metric='euclidean')\ndendrogram(mergings)\nplt.show()","17dcd398":"# 3 Clusters\ncluster_labels = cut_tree(mergings, n_clusters=3).reshape(-1, )\ncluster_labels","93504d02":"# Assigning the cluster lables\ngrouped_retail['cluster_lables'] = cluster_labels\ngrouped_retail.head()","0b4e1e79":"# Plotting the graph\n\nplt.figure(figsize=(25,5))\n\nplt.subplot(1,3,1)\nplt.title(\"Frequency\")\nsns.boxplot(x='cluster_lables', y='frequency', data= grouped_retail)\n\nplt.subplot(1,3,2)\nplt.title(\"Recency\")\nsns.boxplot(x='cluster_lables', y='recency', data= grouped_retail)\n\nplt.subplot(1,3,3)\nplt.title(\"Amount\")\nsns.boxplot(x='cluster_lables', y='amount', data= grouped_retail)\n\nplt.show()","46573770":"### 3.3. Monetary","5e4c2a3f":"### 3.3. Frequency","8ae141e0":"# 2. Clean the Data","fb743e4c":"# 1. Read and Understand the Data","40ba1264":"### 3.1. Recency","248c3be9":"# Introduction\n\nWe have a online customer for which we want to learn clustering. Here we will learn RFM (Recency, Frequency, Monetary Value).\n\n### The steps of the analysis are broadly:\n1. Read and understand the data\n2. Clean the data\n3. Prepare the data for modelling\n4. Modelling\n5. Final analysis and recommendations","02777b22":"### 4.1. Finding the Optimal Numbers of Clusters","c771f127":"# 3. Prepare the Data for Modelling\n* R (Recency)  : Number of days since last purchase\n* F (Frequency): Number of transactions\n* M (Monetary) : Total amount of transactions","4bf240f5":"# 4. Modelling","9a256ec5":"### 4.3. Hierarchical Clustering","f8b7f727":"### 3.4. Preparing the Model","0bfda054":"### 4.2. Silhouette Analysis"}}