{"cell_type":{"c4fc7c42":"code","c4942a2c":"code","65110e28":"code","f44b7e75":"code","c8c136b1":"code","e6cd43d1":"code","e520e90c":"code","0736bdb5":"code","37fa0e20":"code","5566dde9":"code","97a6ab14":"code","8f5118af":"code","72bf5e51":"code","83384500":"code","5c1b10ba":"code","de329338":"markdown","4050875e":"markdown","d92d90fa":"markdown","a3e9c41d":"markdown","91d53d19":"markdown"},"source":{"c4fc7c42":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4942a2c":"#Loading the dataset\ndf = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","65110e28":"#Viewing the first 5 rows of the dataset\ndf.head()","f44b7e75":"df.shape","c8c136b1":"#Columns in the dataset\ndf.columns","e6cd43d1":"df['output'].value_counts()","e520e90c":"#Checking if there are any null values in the dataset\ndf.isnull().sum()","0736bdb5":"#Finding the Statistics of the columns \ndf.describe()","37fa0e20":"X = df.drop(\"output\" , axis =1)\ny = df['output']","5566dde9":"#Standardising the features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler() #It will make the features to have mean = 0 and standard deviation = 1\nX = scaler.fit_transform(X)","97a6ab14":"from sklearn.model_selection import train_test_split\n\nX_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 , random_state=0, stratify=df.output)","8f5118af":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nmodels = [LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier]\nmodel_accuracy = {}\nfor model in models:\n    model = model()\n    model.fit(X_train , y_train)\n    model_accuracy[model.__class__.__name__] = model.score(X_test , y_test)","72bf5e51":"model_accuracy","83384500":"# Lets take Logistic Regression and tune it to get better results\n#This algorithm has C parameter that will affect the models performane\nLogisticRegression_C = [1e-3, 1e-2, 1e-1, 1, 10]\nmodel_accuracy_with_C = {}\nfor c in LogisticRegression_C:\n    model = LogisticRegression(C=c)\n    model.fit(X_train , y_train)\n    y_pred = model.predict(X_test)\n    score = accuracy_score(y_pred , y_test)\n    model_accuracy_with_C[str(c)] = accuracy_score\n    print(f\"The accuracy score for {model.__class__.__name__} and {c} is {score}\")","5c1b10ba":"#Training the LogisticRegression model with parameter C=10\n\nfinal_model = LogisticRegression(C=10)\nfinal_model.fit(X_train ,y_train)\ny_pred = final_model.predict(X_test)\nprint(f\"Accuracy is: {(accuracy_score(y_pred , y_test)*100):.2f}\")","de329338":"# Feature Scaling","4050875e":"we see as we increase the value of C the model performance is increasing and at one point it is plateau","d92d90fa":"# Understanding the Dataset","a3e9c41d":"# Model Training","91d53d19":"If you like the notebook Please UPVOTE :-)"}}