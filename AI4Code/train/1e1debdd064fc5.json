{"cell_type":{"df59517f":"code","ee2b66d4":"code","94a226c2":"code","b4b310dd":"code","7121ee4e":"code","6077a384":"code","e8e2a965":"code","f90ddd11":"code","fc774163":"code","18eab7b2":"code","c8b0c5fe":"code","c792e8f0":"code","d28439a7":"code","04ab3d61":"code","554dafee":"code","a9b3823f":"code","8419963e":"code","cffabde6":"markdown","16a0938c":"markdown"},"source":{"df59517f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee2b66d4":"train_data = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')","94a226c2":"train_data.head()","b4b310dd":"test_data.head()","7121ee4e":"train_data.info()","6077a384":"print(f\"max target value: {max(train_data.target)}\")\nprint(f\"min target value: {min(train_data.target)}\")\nprint(f\"unique target values: {len(train_data.target.unique())}\")","e8e2a965":"# check how many unique values on columns\nfor col in train_data.columns:\n    print(\"Column {c} - {u} values\".format(c=col ,u=len(train_data[col].unique())))","f90ddd11":"s = (train_data.dtypes == 'object')\ncat_cols = list(s[s].index)\n","fc774163":"train_data.index","18eab7b2":"# One-hot-encoder\nEncoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nenc_train = pd.DataFrame(Encoder.fit_transform(train_data[cat_cols]))\nenc_test = pd.DataFrame(Encoder.fit_transform(test_data[cat_cols]))\n\nenc_train.index = train_data.index\nenc_test.index = test_data.index\n\nnum_train = train_data.drop(cat_cols, axis=1)\nnum_test = test_data.drop(cat_cols, axis=1)\n\nencoded_train = pd.concat([num_train, enc_train], axis=1)\nencoded_test = pd.concat([num_test, enc_test], axis=1)","c8b0c5fe":"X = encoded_train.drop('target', axis=1)\ny = encoded_train.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, shuffle=True)","c792e8f0":"models = dict(xgb = XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=1), rfr = RandomForestRegressor(n_estimators=100, random_state=1))\n\ndef test_models(models, X, y):\n    for model in models:\n        print('Model: {m}, NMAE: {score}'.format(m=model, score= cross_val_score(models[model], X, y, cv=5, scoring='neg_mean_absolute_error')))\n\ntest_models(models, X, y)","d28439a7":"# hypers for xgboost \nxgb_params = dict()\n\n# Model: xgb, NMAE: [-0.57557306 -0.58148001 -0.5777023  -0.57897983 -0.57935304]\n# Model: rfr, NMAE: [-0.58764894 -0.5862972  -0.58208449 -0.58353461 -0.58843595]\n    ","04ab3d61":"model_xgb = XGBRegressor(n_estimators=100, learning_rate=0.05, random_state=1)\n\nmodel_xgb.fit(X_train,y_train)\n\npred_xgb = model_xgb.predict(X_test)\n\nmae = mean_absolute_error(pred_xgb, y_test)\nprint(f\"MAE: {mae}\")","554dafee":"prediction = model_xgb.predict(encoded_test)\n","a9b3823f":"pred = pd.DataFrame(dict(Id=encoded_test.id, target=prediction))\npred.to_csv('submission.csv', index=False)","8419963e":"# space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n#         'gamma': hp.uniform ('gamma', 1,9),\n#         'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n#         'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n#         'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n#         'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n#         'n_estimators': 180,\n#         'seed': 0\n#     }","cffabde6":"### Hypers tuning","16a0938c":"### Train Baseline\n* RandomForestRegressor\n* XGBoostRegressor\n"}}