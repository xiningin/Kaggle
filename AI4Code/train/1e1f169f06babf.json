{"cell_type":{"4716d486":"code","42bad50f":"code","61a9b000":"code","63f19578":"code","1bc13af4":"code","93629d59":"code","6cda06a1":"code","096d23bc":"code","f6327fc1":"code","e550344d":"code","37509d97":"code","db17203a":"code","1514aaf4":"code","e14abb0a":"code","10e6f2bc":"code","6ed1bbab":"code","41e33ee4":"code","e37d653f":"code","12aefcdf":"code","45c406a5":"code","75020488":"code","23afd877":"code","d9cebf8e":"code","b1a8b529":"code","2872bd83":"code","35f8cbd8":"code","67a46bdb":"code","bba67c6e":"code","02a7d5cb":"code","c8012f40":"code","8416a806":"code","b5871cc6":"code","fb1a9fbe":"code","5bb729f2":"code","c3a3253f":"code","7b398e48":"code","4cf4d2b0":"code","df5ea6a5":"code","416b2212":"code","b998f764":"code","e3e5ecaf":"code","3875cb57":"code","3d7f4fee":"code","e754707c":"code","93565925":"code","830a7fa7":"code","9e2ed151":"code","c14f7276":"code","7c7af17d":"code","e4a37bea":"code","71313072":"code","19fc61ad":"code","3ac12c11":"code","d92ba3df":"code","b40c3742":"code","bf72a555":"code","bc3d8907":"code","737ca9d3":"code","1dd67fd0":"code","d7910a52":"markdown","06271eaf":"markdown"},"source":{"4716d486":"%env SM_FRAMEWORK=tf.keras\n!pip install tensorflow==2.4.1\n!pip install keras==2.4.3","42bad50f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport random\nimport time\nimport math\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom skimage import data, io, filters\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\nfrom skimage.morphology import convex_hull_image, erosion\nfrom skimage.morphology import square\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom skimage import data, io, filters\nimport skimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import gaussian_filter\nfrom IPython.display import HTML\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom tensorflow.keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16,VGG19,inception_v3\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.datasets import mnist\nimport tensorflow.keras\nfrom tensorflow.keras.models import Model\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","61a9b000":"BAROQUE_PATH = Path(\"..\/input\/architecture-dataset\/arcDataset\/Baroque architecture\")\nBAROQUE_JPG_LIST = list(BAROQUE_PATH.glob(r\"*.JPG\"))\nBAROQUE_jpg_LIST = list(BAROQUE_PATH.glob(r\"*.jpg\"))\n\n\nprint(len(BAROQUE_JPG_LIST))\nprint(len(BAROQUE_jpg_LIST))\n\nfor x_obj in BAROQUE_jpg_LIST:\n    \n    BAROQUE_JPG_LIST.append(x_obj)\n    \nprint(len(BAROQUE_JPG_LIST))","63f19578":"BAROQUE_SERIES = pd.Series(BAROQUE_JPG_LIST,name=\"BAROQUE\").astype(str)","1bc13af4":"BAROQUE_SERIES","93629d59":"figure,axis = plt.subplots(4,4,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = cv2.cvtColor(cv2.imread(BAROQUE_SERIES[x_number]),cv2.COLOR_BGR2RGB)\n    \n    \n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()\n    ","6cda06a1":"IMG_DATA_LIST = []\n\nfor x_values in BAROQUE_SERIES.values:\n    \n    IMG_PICKING = cv2.cvtColor(cv2.imread(x_values),cv2.COLOR_BGR2RGB)\n    RESIZE_IMG = cv2.resize(IMG_PICKING,(180,180))\n    GAUSSIAN_IMG = gaussian_filter(RESIZE_IMG,sigma=0.8)\n    \n    REDUCE_IMG = GAUSSIAN_IMG \/ 255.\n    IMG_DATA_LIST.append(REDUCE_IMG)\n    ","096d23bc":"SINGLE_READING_LIST = []\n\nfor x_values in range(600):\n    \n    IMG_PICKING = cv2.cvtColor(cv2.imread(BAROQUE_SERIES[0]),cv2.COLOR_BGR2RGB)\n    RESIZE_IMG = cv2.resize(IMG_PICKING,(180,180))\n    \n    REDUCE_IMG = RESIZE_IMG \/ 255.\n    SINGLE_READING_LIST.append(REDUCE_IMG)","f6327fc1":"print(len(SINGLE_READING_LIST))","e550344d":"print(len(IMG_DATA_LIST))","37509d97":"print(np.shape(np.array(IMG_DATA_LIST)))","db17203a":"print(np.shape(np.array(SINGLE_READING_LIST)))","1514aaf4":"ARRAY_IMG_PART = np.array(IMG_DATA_LIST,dtype=\"float32\")","e14abb0a":"SINGLE_IMG_PART = np.array(SINGLE_READING_LIST,dtype=\"float32\")","10e6f2bc":"print(ARRAY_IMG_PART.shape)","6ed1bbab":"print(SINGLE_IMG_PART.shape)","41e33ee4":"figure,axis = plt.subplots(4,4,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = SINGLE_IMG_PART[x_number]\n    \n    \n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()","e37d653f":"figure,axis = plt.subplots(4,4,figsize=(15,15))\n\nfor x_number,x_operators in enumerate(axis.flat):\n    \n    EXAMPLE_PICKING = ARRAY_IMG_PART[x_number]\n    \n    \n    x_operators.axis(\"off\")\n    x_operators.imshow(EXAMPLE_PICKING)\n    \nplt.tight_layout()\nplt.show()\n    ","12aefcdf":"ITERATIONS = 75\nVECTOR_NOISE_SHAPE = 180\nCOUNT_EXAMPLE= 2\nBATCH_SIZE = 16\nCOUNT_BUFFER = 60000","45c406a5":"seed = tf.random.normal([COUNT_EXAMPLE,VECTOR_NOISE_SHAPE])","75020488":"print(seed.shape)","23afd877":"TRAIN_SET = tf.data.Dataset.from_tensor_slices(ARRAY_IMG_PART).shuffle(COUNT_BUFFER).batch(BATCH_SIZE)\nSINGLE_SET = tf.data.Dataset.from_tensor_slices(SINGLE_IMG_PART).shuffle(COUNT_BUFFER).batch(BATCH_SIZE)","d9cebf8e":"print(TRAIN_SET.element_spec)","b1a8b529":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*180,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,180)))\n    #\n    Model.add(Conv2DTranspose(128,(2,2),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (2,2), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n\n    #\n    Model.add(Conv2DTranspose(3,(2,2),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","2872bd83":"Generator = Generator_Model()","35f8cbd8":"print(Generator.summary())","67a46bdb":"def Discriminator_Model():\n    \n    Model = Sequential()\n    \n    Model.add(Conv2D(64,(2,2),padding=\"same\",input_shape=[180,180,3]))\n    Model.add(Dropout(0.3))\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2D(128,(2,2),padding=\"same\"))\n    Model.add(Dropout(0.3))\n    Model.add(LeakyReLU())\n\n\n    Model.add(layers.Flatten())\n    Model.add(layers.Dense(1))\n    \n    return Model","bba67c6e":"Discriminator = Discriminator_Model()","02a7d5cb":"print(Discriminator.summary())","c8012f40":"Generator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)","8416a806":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","b5871cc6":"def Discriminator_Loss(real_out,fake_out):\n    \n    Real_Loss_Func = Loss_Function(tf.ones_like(real_out),real_out)\n    Fake_Loss_Func = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    Total_Loss = Real_Loss_Func + Fake_Loss_Func\n    \n    return Total_Loss","fb1a9fbe":"def Generator_Loss(fake_out):\n    \n    return Loss_Function(tf.ones_like(fake_out),fake_out)","5bb729f2":"def display_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(12, 12))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(5, 4, i+1)\n        plt.imshow(predictions[i, :, :, :])\n        plt.axis('off')\n\n    plt.savefig('output_image{:04d}.png'.format(epoch))\n    plt.show()","c3a3253f":"def display_and_save_images_2(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(12, 12))\n    \n    for i in range(predictions.shape[0]):\n        #plt.subplot(5, 4, i+1)\n        plt.imshow(predictions[i, :, :, :])\n        plt.axis('off')\n\n    plt.savefig('output_image_2{:04d}.png'.format(epoch))\n    plt.show()","7b398e48":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([BATCH_SIZE,VECTOR_NOISE_SHAPE])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_Image = Generator(random_noise_vector,training=False)\n        \n        real_output = Discriminator(images,training=True)\n        fake_output = Discriminator(Generator_Fake_Image,training=True)\n        \n        Generator_Loss_Output = Generator_Loss(fake_output)\n        Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n        \n    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n    \n    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))","4cf4d2b0":"def Training(dataset,iterations):\n    \n    for epoch in range(iterations):\n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        display_and_save_images(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    display_and_save_images(Generator,epoch,seed) ","df5ea6a5":"Training(TRAIN_SET,ITERATIONS)","416b2212":"Predict_Generator_Noise = tf.random.normal(shape=[10,VECTOR_NOISE_SHAPE])\n\nGenerator_Predict = Generator(Predict_Generator_Noise)\n\nfigure, axes = plt.subplots(nrows=5,ncols=2,figsize=(18,18))\n\nfor i,ax in enumerate(axes.flat):\n    Prediction_Output = Generator_Predict[i]\n    ax.imshow(Prediction_Output,cmap=\"gray\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","b998f764":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*180,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,180)))\n    #\n    Model.add(Conv2DTranspose(128,(1,1),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (1,1), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n\n    #\n    Model.add(Conv2DTranspose(3,(1,1),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","e3e5ecaf":"def Discriminator_Model():\n    \n    Model = Sequential()\n    \n    Model.add(Conv2D(64,(1,1),padding=\"same\",input_shape=[180,180,3]))\n    Model.add(Dropout(0.3))\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2D(128,(1,1),padding=\"same\"))\n    Model.add(Dropout(0.3))\n    Model.add(LeakyReLU())\n\n\n    Model.add(layers.Flatten())\n    Model.add(layers.Dense(1))\n    \n    return Model","3875cb57":"def Training_2(dataset,iterations):\n    \n    for epoch in range(iterations):\n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        display_and_save_images_2(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    display_and_save_images_2(Generator,epoch,seed) ","3d7f4fee":"Training_2(SINGLE_SET,ITERATIONS)","e754707c":"Predict_Generator_Noise = tf.random.normal(shape=[10,VECTOR_NOISE_SHAPE])","93565925":"Generator_Predict = Generator(Predict_Generator_Noise)","830a7fa7":"figure, axes = plt.subplots(nrows=5,ncols=2,figsize=(18,18))\n\nfor i,ax in enumerate(axes.flat):\n    Prediction_Output = Generator_Predict[i]\n    ax.imshow(Prediction_Output,cmap=\"gray\")\n    ax.axis(\"off\")\nplt.tight_layout()\nplt.show()","9e2ed151":"ALL_PATH_DIC = Path(\".\/\")\nALL_LIST = list(ALL_PATH_DIC.glob(r\"*.png\"))\nprint(len(ALL_LIST))","c14f7276":"ALL_LIST","7c7af17d":"TAR_SERIES = pd.Series(ALL_LIST,name=\"BAROQUE\").astype(str)","e4a37bea":"LIST_PARS = TAR_SERIES[145].split(\"_\")","71313072":"LIST_ADD = TAR_SERIES[1].split(\"_\")","19fc61ad":"LIST_PARS","3ac12c11":"print(len(LIST_PARS))","d92ba3df":"LIST_ADD","b40c3742":"print(len(LIST_ADD))","bf72a555":"TARGET_PATH_READING = []\nADD_PATH_READING = []\n\nfor x_co,x_im in enumerate(TAR_SERIES):\n    \n    LIST_PARS = TAR_SERIES[x_co].split(\"_\")\n    \n    if len(LIST_PARS) >= 3:\n        \n        IMG_TARGET = cv2.cvtColor(cv2.imread(x_im),cv2.COLOR_BGR2RGB)\n        TARGET_PATH_READING.append(IMG_TARGET)\n        \n    else:\n        \n        ADD_TARGET = cv2.cvtColor(cv2.imread(x_im),cv2.COLOR_BGR2RGB)\n        ADD_PATH_READING.append(ADD_TARGET)","bc3d8907":"print(len(TARGET_PATH_READING))\nprint(len(ADD_PATH_READING))","737ca9d3":"def displaying_plot(source):\n    \n    figure = plt.figure(figsize=(14,14))\n    \n    Image_List = []\n    plt.style.use(\"dark_background\")\n    for counting,indexing in enumerate(source):\n        \n        \n        Read_IMG = plt.imshow(indexing, animated=True)\n        plt.axis('off')\n        Image_List.append([Read_IMG])\n\n    Animation_Func = animation.ArtistAnimation(figure, Image_List, interval=144, repeat_delay=10200)\n    \n    plt.close()\n    \n    return Animation_Func","1dd67fd0":"HTML(displaying_plot(TARGET_PATH_READING).to_html5_video())","d7910a52":"# DATA PROCESS AND CONTROLLING","06271eaf":"# DCGAN"}}