{"cell_type":{"fd65597e":"code","a6ed3b0d":"code","484307cc":"code","00c6f82b":"code","a8e6bb48":"code","9dc482c9":"markdown","93ba029a":"markdown","2286430a":"markdown","e318dc23":"markdown","06ffa13d":"markdown"},"source":{"fd65597e":"import sys\nsys.path.append(\"..\/input\/tez-lib\/\")\nfrom collections import Counter\nimport tez \nfrom functools import partial\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nimport gc\ngc.enable()\nimport math\nimport json\nimport time\nimport random\nimport multiprocessing\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm, trange\nfrom sklearn import model_selection\nfrom string import punctuation\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nimport torch.optim as optim\nfrom torch.utils.data import (\n    Dataset, DataLoader,\n    SequentialSampler, RandomSampler\n)\nfrom torch.utils.data.distributed import DistributedSampler\nimport sys \nfrom datasets import Dataset as HFDataset\nfrom transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\nfrom transformers import default_data_collator\n\nimport transformers\nfrom transformers import (\n    WEIGHTS_NAME,\n    AdamW,\n    AutoConfig,\n    AutoModel,\n    AutoTokenizer,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup,\n    logging,\n    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n)","a6ed3b0d":"from Levenshtein import ratio\n\ndef calc_jaccard(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    jac = float(len(c)) \/ (len(a) + len(b) - len(c))\n    print(f'str1: {str1} str2:{str2}, jac:{jac}')\n    return jac\n\ndef check_lev(str1, str2, verbose=False):\n    l_ratio = ratio(str1,str2)\n    if verbose:\n        print(f'str1: {str1} str2:{str2}, lev:{l_ratio}')\n    return l_ratio","484307cc":"def check_similarity(votes, verbose=False):\n    if verbose:\n        print(f'votes {votes}')\n    counter_len = len(votes)\n    adder=0\n    best_pred = votes[0][0]\n    best_vote_count = votes[0][1]\n    # If more than one vote find second best\n    if counter_len > 1:\n        second_best_pred = votes[1][0]\n        second_best_vote_count = votes[1][1]\n    else:\n        second_best_pred = None\n        second_best_vote_count = 0\n    # If more than 2 votes, check 2nd best vs rest\n    if counter_len > 2:\n        for i in range(2, counter_len):\n            score = check_lev(votes[1][0], votes[i][0], verbose=verbose)\n            if score >= 0.3:\n                adder +=1\n    \n    if adder > 0:\n        second_best_vote_count += adder\n        if verbose:\n            print(f'Increasing vote by {adder}: New second best {second_best_vote_count}')\n        if second_best_vote_count > best_vote_count:\n            return second_best_pred\n        else:\n            return best_pred\n    else:\n        return best_pred\n","00c6f82b":"test = pd.read_csv('..\/input\/chaii-hindi-and-tamil-question-answering\/test.csv')","a8e6bb48":"#### Iterate through all predictions and get predictions with max votes\nfinal_predictions = []\nfor i in range(len(test)):\n        # Vote top 1 across all 4 architectures\n        predictions = [all_predictions1[0][i]] + [all_predictions1[1][i]]  + [all_predictions1[2][i]]  + [all_predictions1[3][i]]\n        x = Counter(predictions)\n        print(f'Most common: {x.most_common(1)[0]}')\n        print(f'All predictions {x}')\n        prediction, vote_count = x.most_common(1)[0]\n        # Select majority \n        if vote_count > 1:\n            final_pred = prediction\n        # If no majority \n        else:\n            # Vote top 2\n            predictions = [all_predictions1[0][i]] + [all_predictions1[1][i]]  + [all_predictions1[2][i]]  + [all_predictions1[3][i]] + [all_predictions2[0][i]] + [all_predictions2[1][i]]  + [all_predictions2[2][i]]  + [all_predictions2[3][i]]\n            x = Counter(predictions)\n            print(f'Most common: {x.most_common(1)[0]}')\n            print(f'All predictions {x}')\n            votes = x.most_common()\n            # Max vote\n            prediction, vote_count = votes[0]\n            if len(votes) > 1 :\n                _, vote_count2 = votes[1]\n                if vote_count > vote_count2:\n                    final_pred = prediction\n                else:\n                    if test_shape == 5:\n                        verbose= True\n                    else:\n                        verbose = False\n                    final_pred = check_similarity(votes, verbose=verbose)\n            else:\n                # lb 792 reference\n                final_pred = all_predictions1[1][i]\n            if test_shape == 5:\n                print(f'Max votes for {final_pred} with {vote_count} num votes')\n        final_predictions.append(final_pred)\n\n\nprint(final_predictions)\n","9dc482c9":"## Main Voting Function","93ba029a":"## Vote Similarity Check","2286430a":"`all_predictions1` here are the most confident string predictions for all the test set of 4 different architectures\nSimilarly `all_predictions2` are the second most confident predictions","e318dc23":"## Fine Tune Voting Functions\n\n","06ffa13d":"## Ensemble models using Voting\n\n In this notebook we look at how we can use hard voting based on string predictions from the model to vote on final answers. This is needed because the start\/end logits of different architectures result in outputs of different shapes so ensemble is not possible directly.\n \n This was used for our 13th place solution to give a significant boost to LB. Voting took our scores from 0.792 -> 0.811\n \n The full solution can be found here: https:\/\/www.kaggle.com\/trushk\/qa-ensemble-voter-top-n-votes-similarity\n \n This notebook only covers the voting algorithm itself. \n \n## Main Algorithm at a high level:\n\n**1) Get string predictions from top K confident answers across N different architectures**\n\n**2) First stage involves voting across the N architectures for the most confident prediciton**\n\n--- If we have a winner here return the prediction with most votes as the final prediction\n  \n**3) If the above voting results in a tie, we increase the voter pool by taking top K confident predictions across N architectures**\n\n--- We should most likely get some majority here which can be returned as the final prediction\n \n--- If we still dont have a majority we can also use additional techniques like comparing the similarity of answers to break the deadlock\n\n--- If all voting fails, we can rever to the prediction of the best model"}}