{"cell_type":{"7037b110":"code","a5bcf0b0":"code","3d91921e":"code","273c23d1":"code","a1827269":"code","cda24471":"code","0e080008":"code","18ea446c":"code","5766005e":"code","785136fb":"code","52288ce1":"code","b3328308":"code","b7344297":"code","bbb1aeb1":"code","547f3d7d":"code","93a34da6":"code","07a29760":"code","2f107fdc":"code","afc6cc81":"code","74426ced":"code","43cc2237":"code","c5ae64cc":"code","3807ebbe":"code","369c12cf":"code","f7c65c66":"code","e1275c72":"code","2a3e8595":"code","669658c5":"code","d1d7b5db":"code","bd033c9e":"code","52062e44":"code","d25cd15d":"code","132ea95b":"code","fc047aac":"code","c73d5d59":"code","8d67384a":"code","b4b84fed":"code","128587cc":"code","3c8023e4":"code","cec56478":"code","b8d016c3":"code","975990bc":"code","93c1731c":"code","9aa83357":"code","c7cc1a4b":"code","7247563f":"code","0b5bf5ae":"code","bcc2f2d2":"code","dbd2777c":"code","b4c85b01":"code","cff1b992":"code","c04db513":"code","4fdb5dc5":"markdown","2c6c1cbe":"markdown","a403e94f":"markdown","fdd7ea04":"markdown","b9bc6491":"markdown","24cf2c3b":"markdown","7cc9e4b5":"markdown","ecafe2ae":"markdown","840bbaf8":"markdown","6f54e939":"markdown","ab341c08":"markdown","379f7f12":"markdown","cdc69154":"markdown","17b8be5d":"markdown","3edfe2e6":"markdown","db551cfd":"markdown"},"source":{"7037b110":"!pip install visualkeras","a5bcf0b0":"import plotly.offline as pyo\npyo.init_notebook_mode()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2 \nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing\nimport random\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")","3d91921e":"def Create_Directory_DataFrame():\n    df =pd.DataFrame(columns=['Class','Location'])\n    basedir = '..\/input\/soil-classification-image-data\/Soil_Dataset\/'\n    for folder in os.listdir(basedir):\n        for Class in os.listdir(basedir+folder+'\/'):\n            for location in os.listdir(basedir+folder+'\/'+Class+'\/'):\n                df = df.append({'Class':Class,'Location':basedir+folder+'\/'+Class+'\/'+location},ignore_index=True)\n    df = df.sample(frac = 1) \n    return df\n\ndf = Create_Directory_DataFrame()\nprint(df.shape)\ndf.head()\n","273c23d1":"count = 1\nf = plt.figure(figsize=(50,13))\nfor Class in df['Class'].unique():\n    seg = df[df['Class']==Class]\n    address =  seg.sample().iloc[0]['Location']\n    img = cv2.imread(address,0)\n    ax = f.add_subplot(2, 5,count)\n    ax = plt.imshow(img)\n    ax = plt.title(Class,fontsize= 30)\n    count = count + 1\nplt.suptitle(\"Soil Type\", size = 32)\nplt.show()","a1827269":"img.shape","cda24471":"w , h= 64,64\nfinal_class = 4","0e080008":"from tqdm import tqdm\ntrain_image = []\nfor location in tqdm(df.iloc[:]['Location']):\n    img = cv2.imread(location,0)\n    img = cv2.resize(img, (w,h), interpolation = cv2.INTER_AREA)\n    img = img.reshape(w,h,1)\n    train_image.append(img)\nX = np.array(train_image)","18ea446c":"from sklearn.preprocessing import OneHotEncoder\ny = np.array(df.iloc[:]['Class'])\ny = y.reshape(y.shape[0],1)\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(y)\nprint(enc.categories_)","5766005e":"y = enc.transform(y).toarray()","785136fb":"print(X[0].reshape(w,h))","52288ce1":"plt.figure(figsize=(25,8))\nplt.imshow(X[0].reshape(w,h))\nplt.title(enc.inverse_transform(y[0].reshape(1,final_class))[0][0],size = 20)\nplt.show()","b3328308":"y[0]\n","b7344297":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\nprint('Train data    :'+str(X_train.shape))\nprint('Test data     :'+str(X_test.shape))\nprint('Train Output  :'+str(y_train.shape))\nprint('Test Output   :'+str(y_test.shape))","bbb1aeb1":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    return block\ndef dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    return block\ndef build_model(act , final_class , w , h ):\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(w , h , 1)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation=act, padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation=act, padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(final_class, activation='sigmoid')\n    ])\n    return model\n\ndef wrap(Training_Output_Results , Opt , Act ,  history):\n    epoch  = len(history.history['loss'])\n    epochs = list(np.arange(1,epoch + 1,1))\n    Optimizer = np.repeat(Opt,epoch).tolist()\n    Activation = np.repeat(Act,epoch).tolist()\n    cumiliated_res = {}\n    cumiliated_res['Epochs']=epochs\n    cumiliated_res['Optimizer']=Optimizer\n    cumiliated_res['Activation_Function']=Activation\n    cumiliated_res['Train_Loss']=history.history['loss']\n    cumiliated_res['Train_Accuracy']=history.history['accuracy']\n    cumiliated_res['Train_Precision']=history.history['precision']\n    cumiliated_res['Train_Recall']=history.history['recall']\n    cumiliated_res['Val_Loss']=history.history['val_loss']\n    cumiliated_res['Val_Accuracy']=history.history['val_accuracy']\n    cumiliated_res['Val_Precision']=history.history['val_precision']\n    cumiliated_res['Val_Recall']=history.history['val_recall']\n    convertDictionary = pd.DataFrame(cumiliated_res)\n    Training_Output_Results = Training_Output_Results.append(convertDictionary)\n    return Training_Output_Results","547f3d7d":"Optimisers = ['RMSprop','Adam','Adadelta','Adagrad']\nActivation_function =['relu','sigmoid','softmax','tanh','softsign','selu','elu']","93a34da6":"Training_Output_Results =pd.DataFrame(columns=['Epochs','Optimizer','Activation_Function','Train_Loss','Train_Accuracy','Train_Precision','Train_Recall',                                             'Val_Loss','Val_Accuracy','Val_Precision','Val_Recall'])\ndef Optimise_verify(Training_Output_Results):\n    for opt in Optimisers:\n        model = build_model(Activation_function[0], final_class , w , h)\n        METRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')\n        ]  \n        model.compile(\n                optimizer=opt,\n                loss='categorical_crossentropy',\n                metrics=METRICS\n            )\n        history = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=15,verbose=0,shuffle=True)\n        Training_Output_Results = wrap(Training_Output_Results , opt,Activation_function[0],history)\n        print('---------------------Round for '+opt+' Completed-----------------------------------------')\n    return Training_Output_Results\n    \n    \nTraining_Output_Results = Optimise_verify(Training_Output_Results)","07a29760":"Training_Output_Results=Training_Output_Results.sample(frac = 1) \nprint(Training_Output_Results.shape)\nTraining_Output_Results.to_csv('Optimizer_64*64_data.csv', index = False) \nTraining_Output_Results.head()","2f107fdc":"Training_Output_Results =pd.DataFrame(columns=['Epochs','Optimizer','Activation_Function','Train_Loss','Train_Accuracy','Train_Precision','Train_Recall',\n                                              'Val_Loss','Val_Accuracy','Val_Precision','Val_Recall'])\ndef Activation_verify(Training_Output_Results):\n    for act in Activation_function:\n        model = build_model(act,final_class,w,h)\n        METRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')\n        ]  \n        model.compile(\n                optimizer=Optimisers[0],\n                loss='categorical_crossentropy',\n                metrics=METRICS\n            )\n        history = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=15,verbose=0,shuffle=True)\n        Training_Output_Results = wrap(Training_Output_Results , Optimisers[0],act,history)\n        print('---------------------Round for '+act+' Completed-----------------------------------------')\n    return Training_Output_Results\n    \n    \nTraining_Output_Results = Activation_verify(Training_Output_Results)","afc6cc81":"Training_Output_Results=Training_Output_Results.sample(frac = 1) \nprint(Training_Output_Results.shape)\n\nTraining_Output_Results.to_csv('Activation_64*64_data.csv', index = False)\nTraining_Output_Results.head()","74426ced":"opt = pd.read_csv('.\/Optimizer_64*64_data.csv')\nact = pd.read_csv('.\/Activation_64*64_data.csv')","43cc2237":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Accuracy\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"black\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Accuracy',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\npyo.iplot(scatterplot, filename = 'Opt_train_acc')","c5ae64cc":"scatterplot = px.area(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Loss\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Loss',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_train_loss')","3807ebbe":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Precision\",\n    size='Train_Precision',\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_train_prec')","369c12cf":"scatterplot = px.scatter(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Train_Recall\",\n    size ='Train_Recall',\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Recall',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_train_recall')","f7c65c66":"scatterplot = px.area(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Accuracy\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Accuracy',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_acc')","e1275c72":"scatterplot = px.area(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Precision\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_prec')","2a3e8595":"scatterplot = px.area(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Recall\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Recall',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_recall')\n","669658c5":"scatterplot = px.area(\n    data_frame=opt,\n    x=\"Epochs\",\n    y=\"Val_Loss\",\n    color=\"Optimizer\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Validation Loss',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Opt_val_loss')","d1d7b5db":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Accuracy\",\n    size=\"Train_Accuracy\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Accuracy',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_acc')\n","bd033c9e":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.area(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Loss\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Loss',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_loss')","52062e44":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Precision\",\n    size = \"Train_Precision\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_prec')","d25cd15d":"import plotly.express as px\nimport plotly.io as pio\nimport statsmodels.api as sm\nscatterplot = px.scatter(\n    data_frame=act,\n    x=\"Epochs\",\n    y=\"Train_Recall\",\n    size = \"Train_Recall\",\n    color=\"Activation_Function\",                                              # set opacity of markers\n    color_discrete_sequence=[\"red\",\"orange\",\"blue\",\"green\"],   # set marker colors. When color colum isn't numeric data\n   \n    #facet_col='Optimizer',       # assign marks to subplots in the horizontal direction\n    #facet_col_wrap=2,           # maximum number of subplot columns. Do not set facet_row\n    \n    #log_x=True,                 # x-axis is log-scaled\n    #log_y=True,                 # y-axis is log-scaled\n    \n    title='Train Precision',           # figure title\n    #width=500,                  # figure width in pixels\n    #height=500,                # igure height in pixels\n    template='presentation',     # 'ggplot2', 'seaborn', 'simple_white', 'plotly',\n                                # 'plotly_white', 'plotly_dark', 'presentation',\n                                # 'xgridoff', 'ygridoff', 'gridon', 'none'\n)\n\n# print(scatterplot)\n\npyo.iplot(scatterplot, filename = 'Act_train_prec')","132ea95b":"import plotly.graph_objects as go\ntab_opt = opt[opt['Epochs']==100]\nfinal_col = np.delete(tab_opt.columns[0:], [0,2])\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(final_col),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[tab_opt.Optimizer , tab_opt.Train_Loss,tab_opt.Train_Accuracy,tab_opt.Train_Precision,tab_opt.Train_Recall,tab_opt.Val_Loss,tab_opt.Val_Accuracy,tab_opt.Val_Precision,tab_opt.Val_Recall],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()","fc047aac":"import plotly.graph_objects as go\nty =opt[opt['Epochs']==100].iloc[:,3:]\nnm = ty.columns\nty = ty.values.tolist()\ndata = []\n\nfor j in range(len(nm)):\n        lt = []\n        for i in range(len(Optimisers)):\n            lt.append(ty[i][j])\n            \n        data.append(go.Bar(name = nm[j],x=Optimisers, y=lt))\nfig = go.Figure(data=data)\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","c73d5d59":"import plotly.graph_objects as go\ntab_opt = act[act['Epochs']==100]\nfinal_col = np.delete(tab_opt.columns[0:], [0,1])\nfig = go.Figure(data=[go.Table(\n    header=dict(values=list(final_col),\n                fill_color='paleturquoise',\n                align='left'),\n    cells=dict(values=[tab_opt.Activation_Function , tab_opt.Train_Loss,tab_opt.Train_Accuracy,tab_opt.Train_Precision,tab_opt.Train_Recall,tab_opt.Val_Loss,tab_opt.Val_Accuracy,tab_opt.Val_Precision,tab_opt.Val_Recall],\n               fill_color='lavender',\n               align='left'))\n])\n\nfig.show()","8d67384a":"import plotly.graph_objects as go\nty =act[act['Epochs']==10].iloc[:,3:]\nnm = ty.columns\nty = ty.values.tolist()\ndata = []\n\nfor j in range(len(nm)):\n        lt = []\n        for i in range(len(Activation_function)):\n            lt.append(ty[i][j])\n            \n        data.append(go.Bar(name = nm[j],x=Activation_function, y=lt))\nfig = go.Figure(data=data)\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()\n","b4b84fed":"def Plot(history , name , model):\n    model.save(name+'.h5')\n    epochs = range(1,len(history.history['loss']) + 1)\n    epochs = list(epochs)\n    fig = make_subplots(rows=2, cols=4,subplot_titles=(\"Train Loss\", \"Train Accuracy\" , \"Train Precision\",\"Train Recall\", \"Validation Loss\", \"Validation Accuracy\",\n                                                      \"Validation Precision\",\"Validation Recall\"))\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['loss']), row=1, col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['accuracy']), row=1, col=2)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['precision']), row=1, col=3)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['recall']), row=1, col=4)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_loss']), row=2, col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_accuracy']), row=2, col=2)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_precision']), row=2, col=3)\n    fig.add_trace(go.Scatter(x=epochs, y=history.history['val_recall']), row=2, col=4)\n    fig.update_layout(showlegend=False,height=1000, width=1200, title_text=name)\n    pyo.iplot(fig, filename = 'Act_train_rec')","128587cc":"model = build_model('relu', final_class ,w , h)\nMETRICS = [\n                'accuracy',\n                tf.keras.metrics.Precision(name='precision'),\n                tf.keras.metrics.Recall(name='recall')\n]  \nmodel.compile(\n                optimizer='RMSprop',\n                loss='categorical_crossentropy',\n                metrics=METRICS\n        )\nhistory = model.fit(X_train, y_train, epochs=100, validation_split=0.3, batch_size=15,verbose=1,shuffle=True)","3c8023e4":"Plot(history , 'final_model',model)","cec56478":"import visualkeras\nvisualkeras.layered_view(model)","b8d016c3":"from keras.utils import plot_model\nplot_model(model, to_file='model.png',show_shapes=True)","975990bc":"from matplotlib import pyplot\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(25, 30), dpi=80, facecolor='w', edgecolor='k')\nfilters, biases = model.layers[1].get_weights()\n# normalize filter values to 0-1 so we can visualize them\nf_min, f_max = filters.min(), filters.max()\nfilters = (filters - f_min) \/ (f_max - f_min)\n# plot first few filters\nn_filters, ix = 6, 1\nfor i in range(n_filters):\n\t# get the filter\n\tf = filters[:, :, :, i]\n\t# plot each channel separately\n\tfor j in range(3):\n\t\t# specify subplot and turn of axis\n\t\tax = pyplot.subplot(n_filters,3 , ix)\n\t\tax.set_xticks([])\n\t\tax.set_yticks([])\n\t\t# plot filter channel in grayscale\n\t\tpyplot.imshow(f[:, :, j])\n\t\tix += 1\n# show the figure\npyplot.show()","93c1731c":"from keras.models import Model\nfrom matplotlib.pyplot import figure\nfrom numpy import expand_dims\ndef image_transform_gray(image):\n    img = expand_dims(image, axis=0)\n    model1 = Model(inputs=model.inputs, outputs=model.layers[0].output)\n    feature_maps = model1.predict(img)\n    figure(num=None, figsize=(25, 30), dpi=80, facecolor='w', edgecolor='k')\n    square = 4\n    ix = 1\n    for _ in range(square):\n        for _ in range(square):\n            # specify subplot and turn of axis\n            ax = pyplot.subplot(square, square, ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            # plot filter channel in grayscale\n            pyplot.imshow(feature_maps[0, :, :, ix-1],cmap='gray')\n            ix += 1\n    # show the figure\n    pyplot.show()\ndef image_transform(image):\n    img = expand_dims(image, axis=0)\n    model1 = Model(inputs=model.inputs, outputs=model.layers[0].output)\n    feature_maps = model1.predict(img)\n    figure(num=None, figsize=(25, 30), dpi=80, facecolor='w', edgecolor='k')\n    square = 4\n    ix = 1\n    for _ in range(square):\n        for _ in range(square):\n            # specify subplot and turn of axis\n            ax = pyplot.subplot(square, square, ix)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            # plot filter channel in grayscale\n            pyplot.imshow(feature_maps[0, :, :, ix-1])\n            ix += 1\n    # show the figure\n    pyplot.show()","9aa83357":"plt.figure(figsize=(25,8))\nplt.imshow(X[66].reshape(w,h))\nplt.title(enc.inverse_transform(y[0].reshape(1,final_class))[0][0],size = 20)\nplt.show()","c7cc1a4b":"image_transform(X[66])\nimage_transform_gray(X[66])","7247563f":"y_pred = model.evaluate(X_test , y_test,verbose =1)","0b5bf5ae":"import plotly.graph_objects as go\n\n\nfig = go.Figure(data=[\n    go.Bar(name = 'Accuracy',x=['Training','Validation','Real World Data'], y=[history.history['accuracy'][49] ,history.history['val_accuracy'][49],y_pred[1] ]),\n    go.Bar(name = 'Precision',x=['Training','Validation','Real World Data'], y=[history.history['precision'][49] ,history.history['val_precision'][49],y_pred[2] ]),\n    go.Bar(name = 'Loss',x=['Training','Validation','Real World Data'], y=[history.history['loss'][49] ,history.history['val_loss'][49],y_pred[0] ]),\n\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.update_yaxes(type = \"log\")\npyo.iplot(fig, filename = 'Act_train_rec')","bcc2f2d2":"y_prediction = model.predict(X_test)\ndef binary_classify(y_pred):\n    for inp in y_pred:\n        maximum = 0\n        index = 0\n        for i in range(final_class):\n            if(maximum != max(maximum,inp[i])):\n                maximum = max(maximum,inp[i])\n                index = i\n            inp[i] = 0\n        inp[index]=1\n    return y_pred\ny_prediction  = binary_classify(y_prediction)","dbd2777c":"def create_result(y):\n    y_final = []\n    for i in range(y.shape[0]):\n        y_final.append(enc.inverse_transform(y[i].reshape(1,final_class))[0][0])\n    return y_final \ndef remove_none(y , y_pred):\n    index = []\n    for i in range(len(y)-1,0,-1):\n        if y_pred[i] == None :\n            del y[i]\n            del y_pred[i]\n        \n    return y , y_pred\ndef label_encode(y , y_pred):\n    le = preprocessing.LabelEncoder()\n    le.fit(y_pred)\n    print(le.classes_)\n    y = le.transform(y)\n    y_pred = le.transform(y_pred)\n    return y , y_pred\n\ny_class_result = create_result(y_prediction)\ny_class_desired = create_result(y_test)","b4c85b01":"y_label_desired , y_label_result = label_encode(y_class_desired , y_class_result) ","cff1b992":"from sklearn.metrics import classification_report\ntn = []\nfor cat in enc.categories_[0].reshape(final_class,1):\n    tn.append(cat[0])\ntarget_names = tn\nprint(classification_report(y_label_desired, y_label_result, target_names=target_names))","c04db513":"count = 1\nf = plt.figure(figsize=(20,24))\nfor i in range(20):\n    ind = random.sample(list(y_label_result),1)[0]\n    img = X_test[ind]\n    Class = str(y_class_desired[ind]) + '  vs  '+str(y_class_result[ind])\n    ax = f.add_subplot(5, 4,count)\n    ax = plt.imshow(img.reshape(w,h))\n    ax = plt.title(Class,fontsize= 11)\n    count = count + 1\nplt.suptitle(\"Soil Classes\", size = 32)\nplt.show()","4fdb5dc5":"# Data Creation","2c6c1cbe":"# Activation Analytics","a403e94f":"# Test The Results","fdd7ea04":"# Final Model\n\nOptimizer - RMSprop \nActivation - Relu","b9bc6491":"# Ploting","24cf2c3b":"# Segmentation in Traing and Test Data Sets","7cc9e4b5":"# Predictive Results","ecafe2ae":"# Model Weights","840bbaf8":"# Model\n1. To make our model more modular and easier to understand, let's define some blocks. As we're building a convolution neural network, we'll create a convolution block and a dense layer block.\n2. The following method will define the function to build our model for us. The Dropout layers are important as they \"drop out,\" hence the name, certain nodes to reduce the likelikhood of the model overfitting. We want to end the model with a Dense layer of one node, as this will be the output that determines if an X-ray shows an image of pneumonia. Since there are only two possible labels for the image, we will be using the binary_crossentropy loss. When we fit the model, identify the class weights. Because we are using a TPU, training will be relatively quick.\nFor our metrics, we want to include precision and recall as they will provide use with a more informed picture of how good our model is. Accuracy tells us what fractions are the labels are correct. Since our data is not balanced, accuracy might give a skewed sense of a good model (i.e. a model that always predicts PNEUMONIA will be 74% accurate but is not a good model).\n\nPrecision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\nRecall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","6f54e939":"# Data Loading","ab341c08":"# Define Constraints","379f7f12":"# Visualization of Data","cdc69154":"# Optimization Analytics","17b8be5d":"# Activation Function","3edfe2e6":"# Libraries","db551cfd":"# Samples"}}