{"cell_type":{"0b55f979":"code","bee28fee":"code","76f03aa3":"code","8e8a1912":"code","5373d3cd":"code","f3d3dd8e":"code","a31a579d":"code","64b17b05":"code","951c1375":"code","443c9ad8":"code","5c6419bf":"code","101376ee":"markdown","64c91cb6":"markdown","6880899b":"markdown","9023e90d":"markdown","3fc7f2d4":"markdown"},"source":{"0b55f979":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport os\nfrom tqdm.notebook import tqdm\nimport datetime as dt","bee28fee":"!ls -GFlash --color ..\/input\/chai-time-data-science\/","76f03aa3":"thumb = pd.read_csv('..\/input\/chai-time-data-science\/Anchor Thumbnail Types.csv')\neps = pd.read_csv('..\/input\/chai-time-data-science\/Episodes.csv')","8e8a1912":"cleaned_st_files = os.listdir('..\/input\/chai-time-data-science\/Cleaned Subtitles\/')\n\ndef add_duration(df):\n    df['colon_count'] = df['Time'].str.count(':')\n    df.loc[df['colon_count'] == 1, 'Time'] = '0:' + df.loc[df['colon_count'] == 1]['Time']\n    df['Time_dt'] = df['Time'].apply(lambda x: dt.datetime.strptime(x, \"%H:%M:%S\"))\n    df['Duration'] = (df['Time_dt'] - dt.datetime(1900, 1, 1)) \\\n        .apply(lambda x: x.total_seconds()).astype('int')\n    return df\n\nc_fs = []\nfor f in tqdm(cleaned_st_files):\n    df = pd.read_csv(f'..\/input\/chai-time-data-science\/Cleaned Subtitles\/{f}')\n    df = add_duration(df)\n    df['E'] = f.replace('.csv','')\n    c_fs.append(df)\nall_subs = pd.concat(c_fs)","5373d3cd":"all_subs['Duration'].plot(kind='hist', figsize=(15, 5), bins=20,\n                          title='Duration of Single Subtitle')\nplt.show()","f3d3dd8e":"all_subs.sort_values('Duration')['Text'].values[-1]","a31a579d":"all_subs['first_word'] = all_subs['Text'].str.split(' ', expand=True)[0]\nall_subs['first_word_clean'] = all_subs['first_word'].str.lower().str.replace(',','').str.replace('.','')","64b17b05":"all_subs['first_word_clean'].value_counts().head(20) \\\n    .sort_values().plot(kind='barh', figsize=(15, 8),\n                        title='First word spoken in subtitle section')\nplt.show()","951c1375":"!pip install vaderSentiment > \/dev\/null\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyser = SentimentIntensityAnalyzer()\nall_subs['Polarity_Scores'] = all_subs['Text'].apply(lambda x: analyser.polarity_scores(x))","443c9ad8":"all_subs['neg_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['neg'])\nall_subs['neu_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['neu'])\nall_subs['pos_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['pos'])\nall_subs['compound_score'] = all_subs['Polarity_Scores'].apply(lambda x: x['compound'])","5c6419bf":"fig, ax = plt.subplots(figsize=(15, 5))\nall_subs['neg_score'].plot(kind='hist',\n                           bins=50,\n                           alpha=0.5,\n                           title='Distribution of Sentiment Scores')\nall_subs['pos_score'].plot(kind='hist',\n                           bins=50,\n                           alpha=0.5)\nall_subs['neu_score'].plot(kind='hist',\n                           bins=50,\n                           alpha=0.5)\nplt.legend()\nplt.show()","101376ee":"# First word someone says in subtitle section","64c91cb6":"## Longest subtitle?","6880899b":"## Read in all Cleaned Subtitles and Parse","9023e90d":"# Dirty chai\nAccording to [this website](https:\/\/www.thespruceeats.com\/dirty-chai-definition-765697#:~:text=Dirty%20chai%20is%20a%20popular,and%20a%20chai%20tea%20latte.) Chai with Espresso (aka Dirty chai) \"packs a double whammy of caffeine from the black tea and shot or two of espresso. The average caffeine level of a 12-ounce dirty chai latte is 160 milligrams (versus 50 to 70 milligrams for a chai latte).\"\n\nThat sounds like my kind of Chai! Lets explore this awesome dataset while hyped up on caffene!","3fc7f2d4":"# Simple Sentiment Analysis\nReference: https:\/\/medium.com\/analytics-vidhya\/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f"}}