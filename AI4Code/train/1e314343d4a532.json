{"cell_type":{"386a3ef9":"code","16ccb4d3":"code","e561c78c":"code","39ac3efd":"code","eeea9470":"code","39ca1ca0":"code","4f7df80b":"code","918d4d76":"code","370dec97":"code","cfc10e98":"code","8ccb435f":"code","5bf4d984":"code","8c16948b":"code","b6b8e2b7":"code","84575ff1":"code","2e00ceb7":"code","c8b46a8a":"code","8070f941":"code","f74f1a13":"code","594f31a4":"code","64ac66c1":"code","ed5cfedf":"code","c1f4c21f":"code","e254e827":"code","db8bfa2e":"code","abd16eb7":"code","6fbf1d17":"code","3a1068d3":"code","61b14652":"markdown","590825bf":"markdown","4b3c5607":"markdown","53dcd861":"markdown","1b862d0c":"markdown","6f4e347f":"markdown","74261cc3":"markdown","53bca469":"markdown","4680be49":"markdown","95fc0044":"markdown","a1b2bc1e":"markdown"},"source":{"386a3ef9":"import os\nimport random\nimport warnings\nimport numpy as np\nimport skimage.io\nimport skimage.transform\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras import layers, models\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.preprocessing import image as keras_image\nfrom matplotlib import pyplot as plt\nfrom yellowbrick.target import ClassBalance","16ccb4d3":"# warnings.filterwarnings('ignore')\nnp.random.seed(1337)\nnp.set_printoptions(suppress=True)","e561c78c":"%%html\n<style>\n.output_wrapper, .output {\n    height:auto !important;\n    max-height:100000px;  \/* your desired max-height here *\/\n}\n.output_scroll {\n    box-shadow:none !important;\n    webkit-box-shadow:none !important;\n}\n<\/style>","39ac3efd":"# swaps val and test data because of the number of files\ntrain_dir = '..\/input\/chest_xray\/chest_xray\/train\/'\nval_dir = '..\/input\/chest_xray\/chest_xray\/test\/'\ntest_dir = '..\/input\/chest_xray\/chest_xray\/val\/'","eeea9470":"train_categories = [x for x in os.listdir(train_dir) if x[0] is not '.']\nval_categories = [x for x in os.listdir(val_dir) if x[0] is not '.']\ntest_categories = [x for x in os.listdir(test_dir) if x[0] is not '.']","39ca1ca0":"target_size = (150, 150)","4f7df80b":"def plot_images_per_category(base_dir, categories, size=(150, 150, 3),\n                             images_per_category=1, rows=None):\n    \"\"\"Displays one image from each category.\n\n    :param base_dir: <string> -> The main directory in where the data\n        is stored.\n    :param categories: <list | tuple> -> This must contain all folders\n        (categories) from where the data is to be read.\n    :param images_per_category: <int> -> The images to be displayed by\n        category. Standard is <1>.\n    :parameter rows: int -> number of rows in which the images are to\n        be divided. Standard is <len(categories)>.\n    :param size: list | tuple -> (width, height, channels). Standard is\n        <(150, 150, 3)>.\n    :return: <None>\n    \"\"\"\n\n    if not rows:\n        rows = len(categories)\n\n    images = []\n    categories_list = sorted(\n        [category for category in categories * images_per_category])\n\n    for ix, category in enumerate(categories):\n        directory = os.path.join(base_dir, category)\n        images.extend([os.path.join(directory, x) for x in\n                       os.listdir(directory)[:images_per_category]])\n\n    fig = plt.figure(figsize=(12, 8))\n\n    for ix, image in enumerate(images, start=1):\n        try:\n            image = skimage.io.imread(image)\n        except OSError:\n            continue\n        image = skimage.transform.resize(image, size, mode='reflect')\n        fig.add_subplot(rows, (len(images) \/\/ rows), ix)\n        plt.title(categories_list[ix - 1])\n        plt.axis('off')\n        plt.imshow(image)\n    plt.show()","918d4d76":"plot_images_per_category(train_dir, train_categories, images_per_category=4)","370dec97":"def files_per_directory(base_dir, categories):\n    \"\"\"Counts the files in the directory.\n\n    :param base_dir: <string> -> The main directory in where the images\n        are stored.\n    :param categories: <list | tuple> -> This must contain all folders\n        (categories) from where the images are to be read.\n    :return: <list> -> files_per_directory\n    \"\"\"\n    files_per_dir = []\n\n    for category in categories:\n        files = os.listdir(os.path.join(base_dir, category))\n        files_per_dir.append(len(files))\n\n    return files_per_dir","cfc10e98":"train_files = files_per_directory(train_dir, train_categories)\nval_files = files_per_directory(val_dir, val_categories)\ntest_files = files_per_directory(test_dir, test_categories)","8ccb435f":"def plot_diversification(files_per_dir, categories, title='diversification'):\n    \"\"\"Plot the diversification of the data in the folders.\n\n    :param files_per_dir: <list | tuple> ->  Number of files in each\n        category.\n    :param categories: <list | tuple> -> This must contain all folders\n        (categories) from where the data is to be read.\n    :param title: <string> -> Title of the plot.\n    :return: <None>\n    \"\"\"\n\n    plt.bar([x for x in range(len(files_per_dir))],\n            files_per_dir, tick_label=categories)\n    plt.title(title)\n    plt.show()","5bf4d984":"plot_diversification(train_files, \n                     train_categories, \n                     title='Train data diversification')","8c16948b":"plot_diversification(val_files, \n                     val_categories, \n                     title='Val data diversification')","b6b8e2b7":"plot_diversification(test_files, \n                     test_categories, \n                     title='Test data diversification')","84575ff1":"epochs= 150\npatience= 5\nbatch_size = 8","2e00ceb7":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    # width_shift_range=0.2,\n    # height_shift_range=0.2,\n    # shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=target_size,\n    class_mode='binary',\n    batch_size=batch_size,\n    seed=1337,\n)\n\nvalidation_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    val_dir,\n    target_size=target_size,\n    class_mode='binary',\n    batch_size=batch_size,\n    seed=1337,\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=target_size,\n    class_mode='binary',\n    batch_size=batch_size,\n    seed=1337,\n)","c8b46a8a":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), \n                        activation='relu', \n                        input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.summary()","8070f941":"def plot_activation_layers(model, image_path, target_size=(150, 150),\n                           images_per_row=16, show_pooling=False):\n    \"\"\"Plot the layer activations for ever convolution layer.\n\n    :param model: <keras model>\n    :param image_path: <string> -> Path to a image file.\n    :param target_size: <list | tuple> -> Standard is <(150, 150)>\n    :param images_per_row: <int> -> Number of images to be shown per row\n    :param show_pooling: <bool> -> Shows the layer. Default is <False>\n    :return: <None>\n    \"\"\"\n\n    img = keras_image.load_img(image_path, target_size=target_size)\n    img_tensor = keras_image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor \/= 255.\n\n    layer_outputs = [layer.output for layer in model.layers]\n    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n    activations = activation_model.predict(img_tensor)\n\n    layer_names = []\n    for layer in model.layers:\n        if 'flatten' in layer.name:\n            break\n        else:\n            layer_names.append(layer.name)\n\n    for layer_name, layer_activation in zip(layer_names, activations):\n        if 'dropout' in layer_name:\n            continue\n        if not show_pooling and 'pooling' in layer_name:\n            continue\n\n        n_features = layer_activation.shape[-1]\n        size = layer_activation.shape[1]\n        n_cols = n_features \/\/ images_per_row\n        display_grid = np.zeros((size * n_cols, images_per_row * size))\n\n        with np.errstate(divide='ignore', invalid='ignore'):\n            for col in range(n_cols):\n                for row in range(images_per_row):\n                    channel_image = layer_activation[\n                                    0, :, :, col * images_per_row + row\n                    ]\n                    channel_image -= channel_image.mean()\n                    channel_image \/= channel_image.std()\n                    channel_image *= 64\n                    channel_image += 128\n                    channel_image = np.clip(\n                        channel_image, 0, 255\n                    ).astype('uint8')\n                    display_grid[\n                        col * size: (col + 1) * size,\n                        row * size: (row + 1) * size\n                    ] = channel_image\n\n            scale = 1. \/ size\n            plt.figure(figsize=(scale * display_grid.shape[1],\n                                scale * display_grid.shape[0]))\n            plt.title(layer_name)\n            plt.grid(False)\n            plt.axis('off')\n            plt.imshow(display_grid, aspect='auto', cmap='viridis')\n\n    plt.show()","f74f1a13":"plot_activation_layers(model, '..\/input\/chest_xray\/chest_xray\/test\/NORMAL\/IM-0001-0001.jpeg', images_per_row=16)","594f31a4":"model.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nresult = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    steps_per_epoch=train_generator.samples \/ train_generator.batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples \/ validation_generator.batch_size,\n    callbacks=[\n        EarlyStopping(\n            monitor='val_loss', \n            mode='auto', \n            verbose=1, \n            patience=patience,\n        ), \n        ModelCheckpoint(\n            'best_model.h5', \n            monitor='val_loss', \n            mode='auto', \n            save_best_only=True, \n            verbose=1\n        )\n    ]\n)","64ac66c1":"def statistic_val_loss_acc(result):\n    \"\"\"Show val_loss | val_acc\n\n    :param result: <keras result> -> Result from a keras model.\n    :return: None\n    \"\"\"\n    val_loss = min(result.history.get('val_loss'))\n    val_acc = max(result.history.get('val_acc'))\n\n    print('val_loss: {} | val_acc: {}'.format(\n        val_loss, val_acc\n    ))\n","ed5cfedf":"statistic_val_loss_acc(result)","c1f4c21f":"def plot_loss_acc(result, linestyle='-', result2=None, linestyle2=':'):\n    \"\"\"Plot the loss | acc and val_loss | val_acc from keras model(s).\n\n    :param result: <keras model>\n    :param linestyle: <string> -> See matplotlib documentation.\n    :param result2: <keras model>\n    :param linestyle2: <string> -> See matplotlib documentation.\n    :return: <None>\n    \"\"\"\n    acc = result.history['acc']\n    val_acc = result.history['val_acc']\n    loss = result.history['loss']\n    val_loss = result.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n\n    if result2:\n        acc2 = result2.history['acc']\n        val_acc2 = result2.history['val_acc']\n        loss2 = result2.history['loss']\n        val_loss2 = result2.history['val_loss']\n        epochs2 = range(1, len(acc2) + 1)\n    else:\n        acc2 = 1\n        val_acc2 = None\n        loss2 = None\n        val_loss2 = None\n        epochs2 = None\n\n    plt.figure(figsize=(12, 4))\n    plt.subplot(121)\n    plt.plot(epochs, loss, color='green', linestyle=linestyle, marker='o',\n             markersize=2, label='Training')\n    plt.plot(epochs, val_loss, color='red', linestyle=linestyle, marker='o',\n             markersize=2, label='Validation')\n    if result2:\n        plt.plot(epochs2, loss2, color='green', linestyle=linestyle2,\n                 marker='o', markersize=2, label='Training')\n        plt.plot(epochs2, val_loss2, color='red', linestyle=linestyle2,\n                 marker='o', markersize=2, label='Validation')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Loss')\n    plt.legend()\n    plt.subplot(122)\n    plt.plot(epochs, acc, color='green', linestyle=linestyle, marker='o',\n             markersize=2, label='Training')\n    plt.plot(epochs, val_acc, color='red', linestyle=linestyle, marker='o',\n             markersize=2, label='Validation')\n    if result2:\n        plt.plot(epochs2, acc2, color='green', linestyle=linestyle2,\n                 marker='o', markersize=2, label='Training')\n        plt.plot(epochs2, val_acc2, color='red', linestyle=linestyle2,\n                 marker='o', markersize=2, label='Validation')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n    plt.show()","e254e827":"plot_loss_acc(result)","db8bfa2e":"model = load_model('best_model.h5')","abd16eb7":"def generator_error(generator):\n    \"\"\"To catch errors when reading in data.\n\n    :param generator: <generator>\n    :return: <None>\n    \"\"\"\n\n    while True:\n        try:\n            x, y = next(generator)\n            yield x, y\n        except OSError:\n            pass","6fbf1d17":"def statistic_test_loss_acc(model, x, y=None, error=False):\n    \"\"\"Displays the result of the test data.\n\n    This does not mean the validation data in Deep Learning! Some say\n    you should have three sets of data: Training data, validation data\n    and test data.\n\n    :param model: model\n    :param x: <array> -> Data\n    :param y: <array> -> Labels\n    :param error: <bool> -> If an error occurs while reading, you should\n    try it with <True>. Maybe the error was already considered in the\n    code and intercepted. Standard is <False>\n\n    :return: <None>\n    \"\"\"\n\n    if y is not None:\n        loss, acc = model.evaluate(x, y)\n        print('test_loss: {} | test_acc: {}'.format(loss, acc))\n    else:\n        steps = x.samples \/\/ x.batch_size\n        if error:\n            loss, acc = model.evaluate_generator(generator_error(x), steps=steps)\n        else:\n            loss, acc = model.evaluate_generator(x, steps)\n\n        print('test_loss: {} | test_acc: {}'.format(loss, acc))","3a1068d3":"statistic_test_loss_acc(model, test_generator)","61b14652":"## validation data","590825bf":"## diversification","4b3c5607":"## show some images","53dcd861":"## model","1b862d0c":"## load best model | evaluate test_set","6f4e347f":"# results","74261cc3":"## preprocessing","53bca469":"# imports","4680be49":"# models","95fc0044":"# data","a1b2bc1e":"## data preparation"}}