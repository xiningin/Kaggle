{"cell_type":{"a557f2e8":"code","806f87ee":"code","28919e28":"code","8be865b2":"code","ceea0c6c":"code","5e514800":"code","62d203a8":"code","fe4d5ed4":"code","2cbac65f":"code","a6584221":"code","0448223e":"code","8d467a43":"code","7acd0ca5":"code","39594649":"code","2bcc2201":"code","492ef0a0":"code","2882ffaf":"code","9e4cae01":"code","29087a85":"code","4365f6f5":"code","164343cb":"code","f1e65a70":"code","ef671893":"code","b94eafed":"code","1650a06a":"code","614768f6":"code","a2cea26b":"code","53e9ede0":"code","6c536f4a":"code","3fd8fd49":"markdown","5cf668cb":"markdown","e45ae543":"markdown","8a91f82c":"markdown","0cef343c":"markdown","c136366e":"markdown","3c02f7c3":"markdown","3563520b":"markdown","1313c7ec":"markdown","c5ba2689":"markdown","b420878d":"markdown","93167940":"markdown","fddb808f":"markdown","020bb9ae":"markdown","4ee9511d":"markdown"},"source":{"a557f2e8":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","806f87ee":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","28919e28":"train.head(5)","8be865b2":"test.head(5)","ceea0c6c":"train.shape","5e514800":"test.shape","62d203a8":"train.isnull().sum()","fe4d5ed4":"test.isnull().sum()","2cbac65f":"sns.heatmap(train.isnull(), cbar= False, cmap = 'YlGnBu')","a6584221":"df = pd.concat([train,test], axis = 0, sort = False)\ndf.shape","0448223e":"# Storing the columns with missing values in a list\nMissing_val_col = [col for col in df.columns if df[col].isnull().sum() > 1]\nMissing_val_col","8d467a43":"# Checking the percentage of missing values. If any feature has more than 40% missing value then drop that feature. \nfor col in Missing_val_col:\n    if (df[col].isnull().sum() > int(0.40 * train.shape[0])):\n        print(col)                   ","7acd0ca5":"train.drop(['Alley', 'FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1, inplace = True)","39594649":"test.drop(['Alley', 'FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1, inplace = True)","2bcc2201":"#Checking the numerical features. \nnumerical_data = [col for col in train.columns if train[col].dtypes != 'O']\ntrain[numerical_data].head()","492ef0a0":"# Missing value features in numerical type column\nnumerical_missing = [col for col in numerical_data if train[col].isnull().sum() > 1 ]\nnumerical_missing","2882ffaf":"# Checking categorical features and treating missing values in that\ncategory_data = [col for col in train.columns if train[col].dtypes == 'O']\ntrain[category_data].head()\n","9e4cae01":"category_missing = [col for col in category_data if train[col].isnull().sum() > 1 ]\ncategory_missing","29087a85":"# Filling missing data\ntrain['LotFrontage'].fillna(train['LotFrontage'].mean(), inplace = True)\ntrain['MasVnrArea'].fillna(train['MasVnrArea'].mode()[0], inplace = True)\ntrain['GarageYrBlt'].fillna(train['GarageYrBlt'].mode()[0], inplace = True)\ntrain['MSZoning'].fillna(train['MSZoning'].mode()[0], inplace = True)\ntrain['Utilities'].fillna(train['Utilities'].mode()[0], inplace = True)\ntrain['BsmtFullBath'].fillna(train['BsmtFullBath'].mode()[0], inplace = True)\ntrain['BsmtHalfBath'].fillna(train['BsmtHalfBath'].mode()[0], inplace = True)\ntrain['Functional'].fillna(train['Functional'].mode()[0], inplace = True)\n\ntest['LotFrontage'].fillna(test['LotFrontage'].mean(), inplace = True)\ntest['MasVnrArea'].fillna(test['MasVnrArea'].mode()[0], inplace = True)\ntest['GarageYrBlt'].fillna(test['GarageYrBlt'].mode()[0], inplace = True)\ntest['MSZoning'].fillna(test['MSZoning'].mode()[0], inplace = True)\ntest['Utilities'].fillna(test['Utilities'].mode()[0], inplace = True)\ntest['BsmtFullBath'].fillna(test['BsmtFullBath'].mode()[0], inplace = True)\ntest['BsmtHalfBath'].fillna(test['BsmtHalfBath'].mode()[0], inplace = True)\ntest['Functional'].fillna(test['Functional'].mode()[0], inplace = True)\n","4365f6f5":"# Replacing categorical data with mode\nfor i in category_missing:\n    train[i].fillna(train[i].mode()[0], inplace = True)\n    test[i].fillna(test[i].mode()[0], inplace = True)","164343cb":"# Rechecking for the missing value\nsns.heatmap(train.isnull(),cbar = False, cmap = 'twilight')","f1e65a70":"train_dummy = pd.get_dummies(train[category_data], columns = category_data)\ntrain_dummy","ef671893":"# We Build a Regression model by splitting the training and test data","b94eafed":"# Here I am considering the relationship of numerical features with saleprice. \ndf_x = train[numerical_data]\ndf_x.drop('SalePrice', axis = 1)\nX = df_x\ny = train['SalePrice']","1650a06a":"# Split the data into train and test with 70% data being used for training\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","614768f6":"import statsmodels.api as sm\nX_add_constant = sm.add_constant(X_train)\nmodel = sm.OLS(y_train, X_add_constant)","a2cea26b":"results = model.fit()\nprint(results.summary())","53e9ede0":"X_test = sm.add_constant(X_test)\ny_pred = results.predict(X_test)\nerror = y_test - y_pred","6c536f4a":"sns.distplot(error)","3fd8fd49":"**Explanation of Assumptions**\n\nWe see a sales prediction problem and the first technique comes into mind is Regression technique. By considering only the numerical feature, there was an attempt to fit a regression model and check the assumptions. \n\nAs per the Gauss Markov Theorem, Ordinary Least Square(OLS) estimate is Best linear Unbiased Estimator. Hence we fit OLS model and print the summary. The coefficient of determination and the skewness of error shows that the model violates the assumption of regression model.\nHence Linear Regression Model is not the suitable model for this particular dataset. \n","5cf668cb":"Before we dive deeper into the model building and prediction, we always check for the missing values in our dataset and it is pretty obvious to have missinhg values. Now a questions comes is whether to drop the missing values or impute them with an appropriate method.\n\nFirst we check how many missing values are there in each column then we find an appropriate method to fill missing values. \n\nHere We Go!!!","e45ae543":"**4. Dealing with missing values**","8a91f82c":"**3. Reading Data**","0cef343c":"# House Price Prediction\n![Invest-in-Property.jpg](attachment:Invest-in-Property.jpg)","c136366e":"## Table of Content\n\n1.Regression Definition and assumption\n\n2.Importing libraries\n\n3.Reading data\n\n4.Dealing with missing values\n\n5.Check assumptions\n\n6.Prediction","3c02f7c3":"**A brief note on how I treated missing values.**\n\nFirst I combined both training and test data and checked the missing value features. Then I deleted the columns having more than 40% missing data. \nAfter that I divided the features into numerical and categorical and found the features with missing observations separately. Finally i filled the numerical data using mean and mode and categorical data with mode. \n\nI am a beginner and this data set have many features  that's Why I adopted to treat the missing values with mean and mode. In future i will surely try identify the relationship and then find the suitable method to impute the missing data\n\n","3563520b":"In order to build a regression model we must satisfy the assumptions of Linear Regression. If there is a linear relationship between explanatory variable then we get a green signal to develop a  Linear Regression Model.\n","1313c7ec":"**2. Importing Libraries**","c5ba2689":"6. Prediction\n\nSince Linear Regression Model is not working, we can further use boosting techniques for the better prediction accuracy. Boosting techniques attempts to build to model from the weak classifiers and hence that can give more accurate predictions. \n\n","b420878d":"Converting category to numerical data by using dummies.","93167940":"**5. Checking Regression assumptions**","fddb808f":"A dataset might comprise of both numerical and ctegorical type. Let us now find the number of numerical and categorical features so as to impute missing values. ","020bb9ae":"In the heatmap, we observe many columns are there which consists of missing values","4ee9511d":"**1. Definition and assumptions**\n\nSince Sales prediction problems can be solved with regression modelling. We will first check the assumptions of Linear regression model then we decide which model to use. \n\n**Regression:** Is a statistical Technique for investigating and modelling the relationship between variables.\n\n**Assumptions**\n\n1. Linear relationship between Explanatory and dependent variable. \n2. The variance of residuals is constant for any value of X. This is known as Homoscedasticity. If this assumption is violated then problem of Heteroscedasticity occur.\n3. Observations are independent of each other. \n4. For any value of X, Y is normally distributed.\n"}}