{"cell_type":{"ef46bc5a":"code","38d23fef":"code","bef1e1e6":"code","a8c303ef":"code","a8c11edf":"code","1f2d922a":"code","86d3f682":"code","dc192964":"code","a4fe2c97":"code","6e06f46c":"code","34f157e9":"code","e11d80fd":"code","05204c4d":"code","1f35fc52":"code","d91cda07":"code","8993bb5a":"code","894a958c":"code","e914df46":"code","2bb73d92":"code","ea9a5578":"code","125d09e4":"code","af183fa5":"code","43da9b2b":"code","14bf1a1b":"code","454d6944":"code","ec06ba37":"code","dc5db963":"code","f40525dd":"code","7930b223":"code","588b83ee":"code","88a46773":"code","eeb9f352":"code","75572b97":"code","d5e7cdcc":"code","75e388e6":"code","40e79028":"code","322557d6":"code","7379772c":"code","a01b1339":"code","f8719bf1":"code","b759c815":"code","8146ca99":"code","228797a3":"code","36f0a90b":"code","ac4f26f8":"code","1715b5ba":"code","9c301914":"code","19c52f81":"code","301f4de7":"code","7ab027e5":"code","e4862bf8":"code","e8619efb":"code","7c40f5c5":"code","311b650b":"code","71b00b28":"code","9cfb6f93":"code","7672980a":"code","9bbf99ed":"code","ceee3228":"code","761554b6":"code","edfe3d67":"code","0f10f21e":"code","f22273fb":"code","6858c4db":"code","8f3395ea":"code","0e2387cd":"code","814470ac":"code","7b64fe38":"code","3016766c":"code","6fc9643e":"code","155bad78":"code","cdaaa98c":"code","e828b27c":"code","c8086d05":"code","6fbb01c7":"code","bbb70b46":"code","78fb233d":"code","649df1b4":"code","1b6eb75c":"markdown","16ddc59b":"markdown","de24564b":"markdown","783989b6":"markdown","29c5a4d3":"markdown","db574ea4":"markdown","f399dda2":"markdown","214c0f68":"markdown","d8476404":"markdown","46796aff":"markdown","6dbdc216":"markdown","50bc3c0a":"markdown","7b5cd7b3":"markdown","ef6e915c":"markdown","0b18aabb":"markdown","0052584c":"markdown","34b679e9":"markdown","bdcf1dc6":"markdown","31336a2f":"markdown","936fab96":"markdown","070cc3a8":"markdown","fedbb4a7":"markdown","9124e7ff":"markdown","af42c020":"markdown","a1f723fb":"markdown","869ba43d":"markdown","b6eecd81":"markdown","1f048ce1":"markdown","26880803":"markdown","efec382a":"markdown","685be8a5":"markdown","b200424f":"markdown","c62d0d82":"markdown","a1062292":"markdown","7cb28e54":"markdown","cc2b6cf9":"markdown","3465d896":"markdown","c8e289b8":"markdown","aa07551f":"markdown","93a2821c":"markdown","84c2224d":"markdown","6bc234ea":"markdown","ff2b0a74":"markdown","1d459712":"markdown","a3a4921b":"markdown","97fc35ed":"markdown","f2594bee":"markdown","024f4618":"markdown","3286e803":"markdown","30bbc561":"markdown","88abda7e":"markdown","870a94e9":"markdown","db311e61":"markdown"},"source":{"ef46bc5a":"import pandas as pd\nimport numpy as np\n%matplotlib inline \n#import standard visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns","38d23fef":"conda install mglearn","bef1e1e6":"pip install mglearn","a8c303ef":"df=pd.read_csv('\/kaggle\/input\/bank-marketing-dataset\/bank.csv')","a8c11edf":"df.isna().count()","1f2d922a":"df.head()","86d3f682":"df1=df.sample(n=1500,random_state=0)","dc192964":"df1=df1.sort_index()\ndf1","a4fe2c97":"np.random.seed(0)\ndf2 = df1.mask(np.random.random(df1.shape) < .10)","6e06f46c":"df2","34f157e9":"missing_values= df2.isna().mean().round(2)\nmissing_values.sum()","e11d80fd":"df3 = df2.dropna(how='all', subset=['deposit'])","05204c4d":"df_cat_imputed=df3.select_dtypes(include='object').fillna(df3.select_dtypes(include='object').mode().iloc[0])\ndf_cat_imputed","1f35fc52":"df_num_imputed=df3.select_dtypes(exclude ='object').fillna(df3.select_dtypes(exclude='object').mean().iloc[0])","d91cda07":"df_imputed = pd.concat([df_cat_imputed, df_num_imputed], axis=1)\ndf_imputed","8993bb5a":"df_imputed.isna().sum()","894a958c":"cat_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','poutcome']\nfig, axs = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(20, 15))\ncounter = 0\nfor cat_column in cat_columns:\n    value_counts = df_imputed[cat_column].value_counts()\n    trace_x = counter \/\/ 3\n    trace_y = counter % 3\n    x_pos = np.arange(0, len(value_counts))\n    \n    axs[trace_x, trace_y].bar(x_pos, value_counts.values, tick_label = value_counts.index)\n    \n    axs[trace_x, trace_y].set_title(cat_column)\n    \n    for tick in axs[trace_x, trace_y].get_xticklabels():\n        tick.set_rotation(90)\n    counter += 1\n\nplt.show()","e914df46":"num_columns = ['age','balance', 'day','duration', 'campaign', 'pdays', 'previous']\ndf3_num=df_imputed[num_columns]\ndf3_num","2bb73d92":"fig = plt.figure(figsize = (8,8))\nax = fig.gca()\ndf3_num.hist(ax=ax)\nplt.show()","ea9a5578":"df3_num.describe()","125d09e4":"df_imputed.groupby('deposit').mean()","af183fa5":"len(df_imputed[df_imputed['pdays'] > 400] ) \/ len(df_imputed) * 100","43da9b2b":"len(df_imputed[df_imputed['pdays'] == -1.0])\/len(df_imputed)*100","14bf1a1b":"plt.boxplot(df_imputed['pdays'])\nplt.show()","454d6944":"print(df_imputed['pdays'].quantile(0.10))\nprint(df_imputed['pdays'].quantile(0.90))","ec06ba37":"df_imputed['pdays'] = np.where(df_imputed['pdays'] >185.0, 185.0,df_imputed['pdays'])","dc5db963":"len (df_imputed[df_imputed['duration'] > 1700] ) \/ len(df_imputed) * 100","f40525dd":"plt.boxplot(df_imputed['duration'])\nplt.show()","7930b223":"print(df_imputed['duration'].quantile(0.10))\nprint(df_imputed['duration'].quantile(0.90))","588b83ee":"df_imputed['duration'] = np.where(df_imputed['duration'] >815.1, 815.1,df_imputed['duration'])","88a46773":"value_counts = df_imputed['deposit'].value_counts()\n\nvalue_counts.plot.bar(title = 'Deposit value counts')","eeb9f352":"df_imputed.describe()","75572b97":"df_imputed.groupby('deposit').mean()","d5e7cdcc":"plt.figure(figsize=(20,10))\nsns.heatmap(data=df_imputed.corr(), annot=True, cmap='viridis')","75e388e6":"# Build correlation matrix\ncorr = df_imputed.corr()\ncorr.style.background_gradient(cmap='PuBu')","40e79028":"print(\"Unique levels in 'job' variable:\", df_imputed.job.nunique())\nprint(\"Unique levels in 'marital' variable:\", df_imputed.marital.nunique())\nprint(\"Unique levels in 'education' variable:\", df_imputed.education.nunique())\nprint(\"Unique levels in 'default' variable:\", df_imputed.default.nunique())\nprint(\"Unique levels in 'housing' variable:\", df_imputed.housing.nunique())\nprint(\"Unique levels in 'loan' variable:\", df_imputed.loan.nunique())\nprint(\"Unique levels in 'contact' variable:\", df_imputed.contact.nunique())\nprint(\"Unique levels in 'month' variable:\", df_imputed.month.nunique())\nprint(\"Unique levels in 'poutcome' variable:\", df_imputed.poutcome.nunique())\nprint(\"Unique levels in 'deposit' variable:\", df_imputed.deposit.nunique())","322557d6":"dummy1= pd.get_dummies(df_imputed, columns=['job', 'marital', 'education','contact', 'month','poutcome'],\n               drop_first=False, prefix=['job', 'mar', 'edu', 'con', 'mon', 'pout'])","7379772c":"dummy2=dummy1.replace(to_replace = ['yes','no'],value = ['1','0'])\n#dummy2.info()\ndf_conv=dummy2.copy()\ndf_conv.head()","a01b1339":"y = df_conv.deposit\nX = df_conv.drop(['deposit'], axis=1)","f8719bf1":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nscaled_features = scaler.transform(X)\nX_sc = pd.DataFrame(scaled_features,columns=X.columns)","b759c815":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nclf = RandomForestClassifier(n_estimators = 50, max_depth = 4,random_state=0)\n\nscores = []\nnum_features = len(X_sc.columns)\nfor i in range(num_features):\n    col = X_sc.columns[i]\n    score = np.mean(cross_val_score(clf, X_sc[col].values.reshape(-1,1), y, cv=10))\n    scores.append((float(score*100), col))\n\nprint(sorted(scores, reverse = True))","8146ca99":"df_final=X[['duration','pdays','pout_success','pout_unknown','previous',\n            'age','con_unknown','job_retired','mar_single','housing', \n            'con_cellular','mon_apr','mon_may','job_student','mon_sep']]\ndf_final.info()","228797a3":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import GridSearchCV","36f0a90b":"from sklearn.model_selection import train_test_split\n\nX_train_org, X_test_org, y_train, y_test = train_test_split(df_final,y, random_state = 0)\n\nprint(\"Size of training set: {}  size of test set:\"\n      \" {}\\n\".format(X_train_org.shape[0],X_test_org.shape[0]))","ac4f26f8":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train2 = pd.DataFrame(scaler.fit_transform(X_train_org))\nX_test2= pd.DataFrame(scaler.transform(X_test_org))\nX_train2.columns = X_train_org.columns.values\nX_test2.columns = X_test_org.columns.values\nX_train2.index = X_train_org.index.values\nX_test2.index = X_test_org.index.values\nX_train = X_train2\nX_test = X_test2","1715b5ba":"print(\"Checking the balance status of y train data set\\n\",y_train.value_counts())","9c301914":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier","19c52f81":"knn = KNeighborsClassifier()\n\nknn_param_grid = {'n_neighbors':[1,2,3,5,7,10,15,25],\n              'leaf_size':[1,3,5],\n              'algorithm':['auto', 'kd_tree'],\n              'n_jobs':[-1]}\n\n#Fit the model 5-fold cross validation\nKNN_grid = GridSearchCV(knn, knn_param_grid, cv=5)\nbest_knn=KNN_grid.fit(X_train, y_train)\ny_pred = best_knn.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_results_knn = pd.DataFrame([['KNN_GridCV', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nResults_all=model_results_knn\n\nprint(\"Best Train Accuracy score: \",KNN_grid.best_score_)\nprint(\"Best parameters:\", KNN_grid.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","301f4de7":"sns.lineplot(x='param_n_neighbors', y='mean_test_score', data=pd.DataFrame(KNN_grid.cv_results_))","7ab027e5":"lreg=LogisticRegression(random_state = 0)\npenalty = ['l1', 'l2']\n# Create regularization hyperparameter space\nC = [0.001,0.01,0.1,0.2,0.8,1.2,1.5]\nhyperparameters = dict(C=C, penalty=penalty)\n\n# Create grid search using 5-fold cross validation\nGS_lreg = GridSearchCV(lreg, hyperparameters, cv=5, verbose=0)\n# Fit grid search\nLR_best_model = GS_lreg.fit(X_train, y_train)\ny_pred = GS_lreg.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_results_lr = pd.DataFrame([['Logistic Regression_GridCV', acc, prec, rec, f1]],columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nResults_all = Results_all.append(model_results_lr, ignore_index = True)\n\nprint(\"Best Train Accuracy score: \",GS_lreg.best_score_)\nprint(\"Best parameters:\", GS_lreg.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","e4862bf8":"sns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(GS_lreg.cv_results_))","e8619efb":"classifier_LinSVM = LinearSVC()\n# Grid serach for hyperparameter tuning\nparam_grid_svm = {'C': [0.001, 0.01, 0.10, 1, 10,100]}  \n \nLinsvm_grid = GridSearchCV(classifier_LinSVM, param_grid_svm, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nLinSVM_best_model= Linsvm_grid.fit(X_train, y_train) \n#Predict test data using best model\ny_pred=LinSVM_best_model.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\n\nmodel_results_Linsvm = pd.DataFrame([['LinearSVM_GridCV', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nResults_all = Results_all.append(model_results_Linsvm, ignore_index = True)\n\nprint(\"Best Train Accuracy score: \",Linsvm_grid.best_score_)\nprint(\"Best parameters:\", Linsvm_grid.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","7c40f5c5":"sns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(Linsvm_grid.cv_results_))","311b650b":"classifier_SVM_lin = SVC()\n# Grid serach for hyperparameter tuning \nparam_grid_svm_lin = {'C': [0.001,0.01,0.1, 1, 10, 50,100],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['linear']}  \nsvm_lin_grid = GridSearchCV(classifier_SVM_lin, param_grid_svm_lin, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nSVMlin_best_model= svm_lin_grid.fit(X_train, y_train) \n#Predict test data using best model\ny_pred = SVMlin_best_model.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_results_svm = pd.DataFrame([['SVM (Linear)_GridCV', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nResults_all = Results_all.append(model_results_svm, ignore_index = True)\n\nprint(\"Best Train Accuracy score: \",svm_lin_grid.best_score_)\nprint(\"Best parameters:\", svm_lin_grid.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","71b00b28":"sns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(svm_lin_grid.cv_results_))\n#pd.DataFrame(svm_lin_grid.cv_results_)","9cfb6f93":"%matplotlib inline \nimport mglearn\nscores = np.array(pd.DataFrame(svm_lin_grid.cv_results_).mean_test_score).reshape(7, 5)\n\n# plot the mean cross-validation scores\nmglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid_svm_lin['gamma'], ylabel='C', yticklabels=param_grid_svm_lin['C'], cmap=\"viridis\")","7672980a":"classifier_SVM_rbf = SVC()\n# Grid search for hyperparameter tuning \nparam_grid_svm_rbf = {'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['rbf']}  \nsvm_rbf_grid = GridSearchCV(classifier_SVM_rbf, param_grid_svm_rbf, refit = True, verbose = 3, cv = 5, scoring='roc_auc') \n  \n# fitting the model for grid search \nSVMrbf_best_model= svm_rbf_grid.fit(X_train, y_train) \n# Predicting test data using best model\ny_pred = SVMrbf_best_model.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_results_SVM_rbf = pd.DataFrame([['SVM(RBF)_GridCV', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nResults_all = Results_all.append(model_results_SVM_rbf, ignore_index = True)\n\nprint(\"Best Train Accuracy score: \",SVMrbf_best_model.best_score_)\nprint(\"Best parameters:\", SVMrbf_best_model.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","9bbf99ed":"sns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(svm_rbf_grid.cv_results_))\n#pd.DataFrame(svm_rbf_grid.cv_results_)","ceee3228":"%matplotlib inline \nimport mglearn\nscores = np.array(pd.DataFrame(svm_rbf_grid.cv_results_).mean_test_score).reshape(5, 5)\n\n# plot the mean cross-validation scores\nmglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid_svm_rbf['gamma'], ylabel='C', yticklabels=param_grid_svm_rbf['C'], cmap=\"viridis\")","761554b6":"classifier_SVM_poly = SVC()\n# Grid search for hyperparameter tuning \nparam_grid_svm_poly = {'C': [0.1, 1, 10, 20, 100], 'degree': [2,3,4],'kernel': ['poly']}  \nsvm_poly_grid = GridSearchCV(classifier_SVM_poly, param_grid_svm_poly, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nSVMpoly_best_model= svm_poly_grid.fit(X_train, y_train) \ny_pred = SVMpoly_best_model.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_results_SVM_poly = pd.DataFrame([['SVM(POLY)_GridCV', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nResults_all = Results_all.append(model_results_SVM_poly, ignore_index = True)\n\nprint(\"Best Train Accuracy score: \",svm_poly_grid.best_score_)\nprint(\"Best parameters:\", svm_poly_grid.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","edfe3d67":"sns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(svm_poly_grid.cv_results_))\n#pd.DataFrame(svm_poly_grid.cv_results_)","0f10f21e":"%matplotlib inline \nimport mglearn\nscores = np.array(pd.DataFrame(svm_poly_grid.cv_results_).mean_test_score).reshape(3, 5)\n\n# plot the mean cross-validation scores\nmglearn.tools.heatmap(scores, xlabel='C', xticklabels=param_grid_svm_poly['C'], ylabel='degree', yticklabels=param_grid_svm_poly['degree'], cmap=\"viridis\")","f22273fb":"classifier_dec = DecisionTreeClassifier(random_state = 0)\nparam_grid_dec = {\"criterion\": [\"gini\", \"entropy\"],\n              \"min_samples_split\": [2, 10],\n              \"max_depth\": [2, 5, 10]\n              }\ndec_grid = GridSearchCV(classifier_dec, param_grid_dec, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \ndec_best_model= dec_grid.fit(X_train, y_train) \n\n# Predicting Test Set\ny_pred = dec_best_model.predict(X_test) \n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_results_dec = pd.DataFrame([['Decision tree_GridCV', acc, prec, rec, f1 ]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nResults_all = Results_all.append(model_results_dec, ignore_index = True)\n  \nprint(\"Best Train Accuracy score: \",dec_grid.best_score_)\nprint(\"Best parameters:\", dec_grid.best_estimator_)\nprint(\"Best Test Accuracy score :\", accuracy_score(y_test, y_pred))","6858c4db":"print(Results_all)\nProj1_results=Results_all.copy()","8f3395ea":"from sklearn.decomposition import PCA\npca_red = PCA(n_components=0.95)\nX_train_red = pd.DataFrame(pca_red.fit_transform(X_train))\nX_test_red = pd.DataFrame(pca_red.transform(X_test))","0e2387cd":"X_train_red.info()","814470ac":"knn = KNeighborsClassifier()\n\nknn_param_grid = {'n_neighbors':[1,2,3,5,7,10,15,25],\n              'leaf_size':[1,3,5],\n              'algorithm':['auto', 'kd_tree'],\n              'n_jobs':[-1]}\n\n#Fit the model 5-fold cross validation\nKNN_grid = GridSearchCV(knn, knn_param_grid, cv=5)\nKNN_grid.fit(X_train_red, y_train)\ny_pred=KNN_grid.predict(X_test_red)\n#print(\"Best Accuracy score: \",KNN_grid.best_score_)\n#print(\"Best parameters:\", KNN_grid.best_estimator_)\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_knn_grid_red = pd.DataFrame([['KNN classifier(GridSearch)_red', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(KNN_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(KNN_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", KNN_grid.best_estimator_)\n\n#plot\nsns.lineplot(x='param_n_neighbors', y='mean_test_score', data=pd.DataFrame(KNN_grid.cv_results_))","7b64fe38":"from sklearn.linear_model import LogisticRegression\nlreg=LogisticRegression(random_state = 0)\npenalty = ['l1', 'l2']\n# Create regularization hyperparameter space\nC = [0.001,0.01,0.1,0.2,0.8,1.2,1.5]\nhyperparameters = dict(C=C, penalty=penalty)\n\n# Create grid search using 2-fold cross validation\nlreg_grid = GridSearchCV(lreg, hyperparameters, cv=5, verbose=0)\n# Fit grid search\nLR_best_grid = lreg_grid.fit(X_train_red, y_train)\ny_pred=LR_best_grid.predict(X_test_red)\n\n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_lreg_grid_red = pd.DataFrame([['LogisticRegression(GridSearch)_red', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(LR_best_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(LR_best_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", lreg_grid.best_estimator_)\n#PLot\nsns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(lreg_grid.cv_results_))","3016766c":"from sklearn.svm import LinearSVC\nclassifier_LinSVM = LinearSVC()\n# Grid search for hyperparameter tuning\nparam_grid_svm = {'C': [0.001, 0.01, 0.10, 1, 10,100]}  \n \nLinsvm_grid = GridSearchCV(classifier_LinSVM, param_grid_svm, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nLinSVM_best_model= Linsvm_grid.fit(X_train_red, y_train) \n#Predicting test dataset\ny_pred = LinSVM_best_model.predict(X_test_red) \nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred,pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_linsvm_grid_red = pd.DataFrame([['LinearSVM(GridSearch)_red', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(Linsvm_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(Linsvm_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", Linsvm_grid.best_estimator_)\n#plot\nsns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(Linsvm_grid.cv_results_))","6fc9643e":"from sklearn.svm import SVC\nclassifier_SVM_lin = SVC(random_state = 0)\n# Grid serach for hyperparameter tuning \nparam_grid_svm_lin = {'C': [0.001,0.01,0.1, 1, 10, 50,100],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['linear']}  \nsvm_lin_grid = GridSearchCV(classifier_SVM_lin, param_grid_svm_lin, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nSVMlin_best_model= svm_lin_grid.fit(X_train_red, y_train) \n#Predicting testset\ny_pred = SVMlin_best_model.predict(X_test_red)  \nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred,pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_svmlin_grid_red = pd.DataFrame([['SVM_lin(GridSearch)_red', acc, prec, rec, f1 ]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(svm_lin_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(svm_lin_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", svm_lin_grid.best_estimator_)\n\n#Plot\nsns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(svm_lin_grid.cv_results_))","155bad78":"# plot the mean cross-validation scores\n%matplotlib inline \nimport mglearn\nscores = np.array(pd.DataFrame(svm_lin_grid.cv_results_).mean_test_score).reshape(7, 5)\nmglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid_svm_lin['gamma'], ylabel='C', yticklabels=param_grid_svm_lin['C'], cmap=\"viridis\")","cdaaa98c":"from sklearn.svm import SVC\nclassifier_SVM_rbf = SVC(random_state = 0)\n# Grid search for hyperparameter tuning \nparam_grid_svm_rbf = {'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['rbf']}  \nsvm_rbf_grid = GridSearchCV(classifier_SVM_rbf, param_grid_svm_rbf, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nSVMrbf_best_model= svm_rbf_grid.fit(X_train_red, y_train) \n# Predicting test set\ny_pred = SVMrbf_best_model.predict(X_test_red) \n\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred,pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_svmrbf_grid_red = pd.DataFrame([['SVM_rbf(GridSearch)_red', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(svm_rbf_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(svm_rbf_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", svm_rbf_grid.best_estimator_)\n\n#plot\nsns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(svm_rbf_grid.cv_results_))","e828b27c":"%matplotlib inline \nimport mglearn\nscores = np.array(pd.DataFrame(svm_rbf_grid.cv_results_).mean_test_score).reshape(5, 5)\n\n# plot the mean cross-validation scores\nmglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid_svm_rbf['gamma'], ylabel='C', yticklabels=param_grid_svm_rbf['C'], cmap=\"viridis\")","c8086d05":"from sklearn.svm import SVC\nclassifier_SVM_poly = SVC(random_state = 0)\n# Grid search for hyperparameter tuning \nparam_grid_svm_poly = {'C': [0.1, 1, 10, 20, 100],   \n              'kernel': ['poly'],\n                'degree' :[2,3,4]}  \nsvm_poly_grid = GridSearchCV(classifier_SVM_poly, param_grid_svm_poly, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \nSVMpoly_best_model= svm_poly_grid.fit(X_train_red, y_train) \ny_pred = svm_poly_grid.predict(X_test_red) \nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred,pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_svmpoly_grid_red = pd.DataFrame([['SVM_poly(GridSearch)_red', acc, prec, rec, f1 ]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(svm_poly_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(svm_poly_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", svm_poly_grid.best_estimator_)\n\n#PLOT\nsns.lineplot(x='param_C', y='mean_test_score', data=pd.DataFrame(svm_poly_grid.cv_results_))\n","6fbb01c7":"%matplotlib inline \nimport mglearn\nscores = np.array(pd.DataFrame(svm_poly_grid.cv_results_).mean_test_score).reshape(3, 5)\n\n# plot the mean cross-validation scores\nmglearn.tools.heatmap(scores, xlabel='C', xticklabels=param_grid_svm_poly['C'], ylabel='degree', yticklabels=param_grid_svm_poly['degree'], cmap=\"viridis\")","bbb70b46":"from sklearn.tree import DecisionTreeClassifier\nclassifier_dec = DecisionTreeClassifier(random_state = 0)\n\nparam_grid_dec = {\"criterion\": [\"gini\", \"entropy\"],\n              \"min_samples_split\": [2,10],\n              \"max_depth\": [2, 5, 10]\n              }\ndec_grid = GridSearchCV(classifier_dec, param_grid_dec, refit = True, verbose = 3, cv = 5) \n  \n# fitting the model for grid search \ndec_best_model= dec_grid.fit(X_train_red, y_train) \n\n# Predicting Test Set\ny_pred = dec_best_model.predict(X_test_red) \n  \nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred,pos_label='1')\nrec = recall_score(y_test, y_pred, pos_label='1')\nf1 = f1_score(y_test, y_pred,pos_label='1')\n\nmodel_dec_grid_red = pd.DataFrame([['DecisionTree(GridSearch)_red', acc, prec, rec, f1 ]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nprint(\"Accuracy on training set: {:.3f}\".format(dec_grid.score(X_train_red, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(dec_grid.score(X_test_red, y_test)))\nprint(\"Best parameters:\", dec_grid.best_estimator_)","78fb233d":"#Project 2 Models results table\nProj2_models= pd.concat([model_knn_grid_red,\n           model_lreg_grid_red,model_linsvm_grid_red,model_svmlin_grid_red,\n           model_svmrbf_grid_red,model_svmpoly_grid_red\n           ,model_dec_grid_red])","649df1b4":"#Comparision table\npd.concat([Proj1_results,Proj2_models],ignore_index=True,sort=False)","1b6eb75c":"* we can see that there is nearly 10% of missing values in the data, hence lets explore data by categorical and numerical column wise.","16ddc59b":"## Creating dummies for categorical variables","de24564b":"## Check for missing values in outcome variable-deposit\n* If the deposit variable has missing values, then it is better to do row deletion.","783989b6":"### Method1: KNN-GridSearchCV on reduced dataset","29c5a4d3":"* Have inserted 10% missing values into the dataset as the dataset is clean","db574ea4":"# About the dataset\n* This dataset gives you information about a marketing campaign of a financial institution, which you will have to analyze in order to find ways to look for future strategies in order to improve future marketing campaigns for the bank.\n## Input variables explained:\n### bank client data:<br> \n1 - age (numeric)<br> \n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')<br> \n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)<br> \n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')<br> \n5 - default: has credit in default? (categorical: 'no','yes','unknown')<br> \n6 - balance: average yearly balance, in euros (numeric)\n7 - housing: has housing loan? (categorical: 'no','yes','unknown')<br> \n8 - loan: has personal loan? (categorical: 'no','yes','unknown')<br> \n### Related with the last contact of the current campaign:\n9 - contact: contact communication type (categorical: 'cellular','telephone')<br> \n10 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')<br> \n11 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')<br> \n12 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.<br> \n### Other attributes:\n13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br> \n14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)<br> \n15 - previous: number of contacts performed before this campaign and for this client (numeric)<br> \n16 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')<br> \n## Output variable (desired target):\n17 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n* Deposite definition: What is a Term Deposit?\nA Term deposit is a deposit that a bank or a financial institurion offers with a fixed rate (often better  than just opening deposit account) in which your money will be returned back at a specific maturity time. ","f399dda2":"## Method1: KNN-Grid search with Cross validation","214c0f68":"# Model Comparision1","d8476404":"## Performance of Classification models on reduced dataset","46796aff":"* From the above heatmap, it seems like there is no correlation between input numerical variables, hence we do not need to drop any variables","6dbdc216":"## Approach\nIn order to optimize marketing campaigns with the help of the dataset, we will have to take the following steps:\n* Import data from dataset and perform initial high-level analysis: look at the number of rows, look at the missing values, look at dataset columns and their values respective to the campaign outcome.\n* Clean the data: remove irrelevant columns, deal with missing and incorrect values, turn categorical columns into dummy variables.\n* Here some categorical columns have values \"unknown\". We are considering it as one category which can influence the deposite status. Hence not removing it.\n* Use machine learning techniques to predict the marketing campaign outcome and to find out factors, which affect the success of the campaign.","50bc3c0a":"# 2. Classification","7b5cd7b3":"Box plot to show outliers in duration","ef6e915c":"* Accuracy can be used when the class distribution is similar while F1-score is a better metric when there are imbalanced classes as in the above case. \n* In most real-life classification problems, imbalanced class distribution exists and thus F1-score is a better metric to evaluate our model on.\n* We can see from the above scores results that, Logistic Regression has better accuracy score and  F1_Score, which is greater than all other models. \n* We can consider this as the best model after applying Grid search and cross validation techniques.","0b18aabb":"Removing Outliers from pdays column","0052584c":"### Method6: SVM_kernel=\"poly\"-GridSearchCV on reduced dataset","34b679e9":"* From the above Cross value scores of the input variables, lets select the top 15 variables with highest scores\n* So the features selected for the classification modeling are: 'duration', 'pdays', 'pout_success', 'pout_unknown', 'previous','age','con_unknown','job_retired','mar_single','housing','con_cellular','mon_apr','mon_may','job_student', 'mon_sep'","bdcf1dc6":"## Split the data into train and test","31336a2f":"## Feature Selection","936fab96":"# Inserting missing values","070cc3a8":"## Classification Models prediction scores comparision on original dataset vs. on reduced data","fedbb4a7":"### Method4: SVM_kernel=\"linear\"-GridSearchCV on reduced dataset","9124e7ff":"## Response column(y)-Deposit\nOn the diagram we see that counts for 'yes' and 'no' values for 'deposit' are close, so we can use accuracy as a metric for a model, which predicts the campaign outcome.","af42c020":"* The models which were developed on full dataset are compared with models developed on PCA reduced dataset.","a1f723fb":"### Method3: LinearSVC-GridSearchCV on reduced dataset","869ba43d":"* We will check how the categorical columns are distributed","b6eecd81":"## Method2: Logistic Regression - Grid search with Cross validation","1f048ce1":"* From the above results table we can see that, the accuracy scores of the models that were developed on PCA reduced datasets are slightly smaller compared to the accuracy scores of the models developed on full datasets.But in most of the models, the accuracy is approximately same. \n\n* The models have predicted with sligtly better precision on reduced dataset.\n\n* Hence we can say that even after reducing the dataset to retain 95% variance, the models are predicting the output variable \"deposite\" with good accuracy.\n\n* We can conclude from this, that PCA indeed helps in getting good results with faster analysis. But it is always accuracy variance tradeoff, as we loose variance and some information in the data further by reducing the data using PCA.","26880803":"* We will look at the numerical columns","efec382a":"## Slicing the dataset instances to 1500","685be8a5":"### Method2: LogisticRegression-GridSearch on reduced dataset","b200424f":"Removing Outliers from duration column","c62d0d82":"## Heatmap to check correlation between variables","a1062292":"## Checking for Missing values","7cb28e54":"# 1. DATA PREPROCESSING","cc2b6cf9":"* From the information above, we will create one-hot encoding for categorical variables with > 2 levels. So, 'job',  'marital', 'education', 'contact', 'month' and 'poutcome' variables have levels >2.\n* For 'default', 'housing', 'loan' and 'deposit' variables, we use create label encoding as they have just 2 unique levels.","3465d896":"## Method3: Linear SVC - Gridsearch with Cross Validation","c8e289b8":"### Fill missing values \n* with most frequent values in categorical columns\n* with mean in numerical columns(as we have only less than 10% of the data is missing, filling with average should not decrease the variance much to deviate our predictions.)","aa07551f":"* Reducing the dataset using PCA to retain 95% variance","93a2821c":"## Method5: SVM_rbf - Grid Search with Cross Validation","84c2224d":"### Method5: SVM_kernel=\"rbf\"-GridSearchCV on reduced dataset","6bc234ea":"## Feature Scaling\n* As we can see from the graphs of the input varibles, it is clear that they do not have normally distributed data, hence we are using MinMaxScaling. This will be suitable option as we have also removed the outliers","ff2b0a74":"### Method7: DecisionTreeClassifier-GridSearchCV on reduced dataset","1d459712":"### Import linear algebra and data manipulation libraries","a3a4921b":"## Grid Search & cross validation applied on classification models","97fc35ed":"## Handling Outliers\nWe can see that duration, pdays have outliers","f2594bee":"* We can see from the above graphs, that balance,campaign, duration, pdays and previous variables have some outliers. lets look at those columns","024f4618":"For selecting feautres we will use random forest method because it is robust, nonlinear","3286e803":"## Method4: SVM_lin - Grid search with Cross Validation","30bbc561":"* From the above counts of 0 and 1 values for target variable, it looks not that imbalanced. Hence we can proceed.","88abda7e":"## Method7: Decision tree classifier - Grid search with cross validation","870a94e9":"Box plot to show outliers in pdays","db311e61":"## Method6: SVM_poly - Grid Search with Cross Validation"}}