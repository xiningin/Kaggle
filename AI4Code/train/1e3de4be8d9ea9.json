{"cell_type":{"a219fc67":"code","0097e24f":"code","22e82004":"code","67ec75ca":"code","3f2c2d32":"code","da556650":"code","6beda1f6":"code","5c0855d8":"code","9338d515":"code","fec898de":"code","e25ffc69":"code","337cce0b":"code","b473e07b":"code","19c9a6da":"code","da46c729":"code","3793d927":"code","2e5f658f":"code","0497b74b":"code","96a411fd":"code","598fa65d":"code","907dc67c":"code","a6ea3267":"code","31c3756b":"code","c0e3d202":"code","e897de5a":"code","3d90ea5a":"code","4a4c57f9":"code","180d5516":"code","08117ca0":"code","d40ad3e8":"code","ee0063be":"code","acf78a7e":"code","a98753f2":"code","b6424ff8":"code","573ed581":"code","769b8852":"code","be264c25":"code","c8959bcb":"code","2d5f58e3":"code","b65f55e9":"code","3faeb405":"markdown","bbe2be87":"markdown","b84a86f9":"markdown","8cd61bca":"markdown","17bcbe21":"markdown","d89b1ac7":"markdown","ce8ab4ee":"markdown","273897d1":"markdown","dee6f9b5":"markdown","1f034ed3":"markdown","d84814c9":"markdown","d76735fc":"markdown","bfc64f31":"markdown","a9535001":"markdown","e2040e6f":"markdown","02086189":"markdown","dde33af8":"markdown","d395631c":"markdown","f34abc76":"markdown","a9ac7de1":"markdown","d169fe97":"markdown","98b67214":"markdown","60ee3123":"markdown","9efd7b31":"markdown","d4896011":"markdown","c1d57f93":"markdown","428fcba3":"markdown","2030ffd4":"markdown","58c3e9f3":"markdown","4a476cdf":"markdown","f234f004":"markdown","5a5f1ea3":"markdown","c3c7c2a8":"markdown","b6fb4d1a":"markdown","edf29972":"markdown","ae2b4699":"markdown","3b4d4a8b":"markdown","6dec4d62":"markdown","ea46c486":"markdown"},"source":{"a219fc67":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Import the necessary libs\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.datasets import mnist\nimport tensorflow as tf\n\nsns.set(style='white', context='notebook', palette='deep')","0097e24f":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsub = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\n\nprint(\"Data are Ready!!\")","22e82004":"print(f\"Training data size is {train.shape}\\nTesting data size is {test.shape}\")","67ec75ca":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"], axis = 1) ","3f2c2d32":"# Load more data sets, if there is no such data, validation accuracy = 0.9964\n# With this batch of data, the validation accuracy can reach 0.9985\n(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n\ntrain1 = np.concatenate([x_train1, x_test1], axis=0)\ny_train1 = np.concatenate([y_train1, y_test1], axis=0)\n\nY_train1 = y_train1\nX_train1 = train1.reshape(-1, 28*28)","da556650":"# Print data histogram\nsns.countplot(Y_train);","6beda1f6":"# Normalize data to make CNN faster\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n\nX_train1 = X_train1 \/ 255.0","5c0855d8":"# Reshape Picture is 3D array (height = 28px, width = 28px , canal = 1)\nX_train = np.concatenate((X_train.values, X_train1))\nY_train = np.concatenate((Y_train, Y_train1))","9338d515":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n# canal = 1 => For gray scale\nX_train = X_train.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","fec898de":"# Convert label to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)","e25ffc69":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","337cce0b":"X_train.shape, X_val.shape, Y_train.shape, Y_val.shape","b473e07b":"# Draw an example of a data set to see\ng = plt.imshow(X_train[189][:,:,0])","19c9a6da":"#Creating CNN model\n\"\"\"\n  [[Conv2D->relu]*2 -> BatchNormalization -> MaxPool2D -> Dropout]*2 -> \n  [Conv2D->relu]*2 -> BatchNormalization -> Dropout -> \n  Flatten -> Dense -> BatchNormalization -> Dropout -> Out\n\"\"\"\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation = \"softmax\"))","da46c729":"# print out model look\nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(\"model.png\")","3793d927":"# Define Optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","2e5f658f":"# Compile model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","0497b74b":"# Audjusting learning rate\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","96a411fd":"#Adjusting epochs and batch_size\nepochs = 50\nbatch_size = 128","598fa65d":"#Data Augmentation \ndatagen = ImageDataGenerator(\n        featurewise_center=False, # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n#datagen.fit(X_train)\ntrain_gen = datagen.flow(X_train,Y_train, batch_size=batch_size)","907dc67c":"#Prediction model\nhistory = model.fit(train_gen,\n                              epochs = epochs,validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction],\n                             validation_steps = X_val.shape[0] \/\/ batch_size)","a6ea3267":"# Draw the loss and accuracy curves of the training set and the validation set.\n# Can judge whether it is under-fitting or over-fitting\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","31c3756b":"# Draw a confusion matrix that can be used to observe high false positives\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label');","c0e3d202":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","e897de5a":"# Show some wrong results, and the difference between the predicted label and the real labe\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]","3d90ea5a":"def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1","4a4c57f9":"# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","180d5516":"# Make predictions about test sets\nresults = model.predict(test)\n\n# Convert one-hot vector to number\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","08117ca0":"# Save the final result in cnn_mnist_submission.csv\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_submission.csv\",index=False)","d40ad3e8":"(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n\nY_train1 = y_train1\nX_train1 = x_train1.reshape(-1, 28*28)","ee0063be":"mnist_image = np.vstack((x_train1,x_test1))\nmnist_image = mnist_image.reshape(-1,784)\nprint(mnist_image.shape)\nmnist_label = np.vstack((y_train1.reshape(-1,1),y_test1.reshape(-1,1)))\nprint(mnist_label.shape)","acf78a7e":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data  = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","a98753f2":"train_images = train_data.copy()\ntrain_images = train_images.values\nX_train = train_images[:,1:]\ny_train = train_images[:,0]\nX_test = test_data.values","b6424ff8":"X_train = X_train.reshape(-1,28,28)\ny_train = y_train.reshape(-1,1)\n\nprint(X_train.shape)\nprint(y_train.shape)","573ed581":"predictions = np.zeros((X_train.shape[0]))","769b8852":"x1=0\nx2=0\nprint(\"Classifying Kaggle's 'test.csv' using KNN where K=1 and MNIST 70k images..\")\nfor i in range(0,28000):\n    for j in range(0,70000):\n        if np.absolute(X_test[i,:]-mnist_image[j,:]).sum()==0:\n            predictions[i]=mnist_label[j]\n            if i%1000==0:\n                print(\"  %d images classified perfectly\"%(i),end=\"\")\n            if j<60000:\n                x1+=1\n            else:\n                x2+=1\n            break\n\nif x1+x2==28000:\n    print(\" 28000 images classified perfectly.\")\n    print(\"All 28000 images are contained in MNIST.npz Dataset.\")\n    print(\"%d images are in MNIST.npz train and %d images are in MNIST.npz test\"%(x1,x2))","be264c25":"final_pred = predictions[0:28000]","c8959bcb":"my_submission = pd.DataFrame({'ImageId':np.arange(28000),'Label':final_pred.squeeze().astype(np.int)})\nmy_submission.head()","2d5f58e3":"my_submission[\"ImageId\"]=my_submission[\"ImageId\"]+1","b65f55e9":"my_submission.to_csv('best_submission.csv', index=False)","3faeb405":"I choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model.","bbe2be87":"# 4. Evaluate the model\n## 4.1 Training and validation curves","b84a86f9":"We perform a grayscale normalization to reduce the effect of illumination's differences. \n\nMoreover the CNN converg faster on [0..1] data than on [0..255].","8cd61bca":"In order to avoid overfitting problem, we need to expand artificially our handwritten digit dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.\n\nFor example, the number is not centered \nThe scale is not the same (some who write with big\/small numbers)\nThe image is rotated...\n\nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more. \n\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.\n\nThe improvement is important : \n   - Without data augmentation i obtained an accuracy of 99.114%\n   - With data augmentation i achieved 99.985% of accuracy","17bcbe21":"# 8. Sklearn Soluation","d89b1ac7":"You can find out anthor soluation using simple model sklearn \"Random Forest Classifier\" with more than 94.5% accuracy here on this link **<a href='https:\/\/www.kaggle.com\/elcaiseri\/mnist-simple-sklearn-model-95-accuracy'>MNIST: Simple Sklearn Model<\/a>**","ce8ab4ee":"## 3.3 Model training","273897d1":"### This model accuracy is 99.87% on public and local kaggle submission","dee6f9b5":"## 4.2 Confusion matrix","1f034ed3":"## 5.1 Prediction validation results","d84814c9":"**Merging all the data we got**","d76735fc":"**Plot CNN model**","bfc64f31":"# 3. CNN\n## 3.1 Define the model","a9535001":"## 2.3 Reshape","e2040e6f":"**One-Hot Encoding**","02086189":"## 2.5 Split training and valdiation set","dde33af8":"# 7. References\n\n1. https:\/\/keras.io\/models\/sequential\/\n2. https:\/\/keras.io\/layers\/core\/\n3. https:\/\/keras.io\/layers\/convolutional\/\n4. https:\/\/keras.io\/layers\/pooling\/\n5. https:\/\/www.kaggle.com\/elcaiseri\/mnist-simple-cnn-keras-accuracy-0-99-top-1\n6. https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\n7. https:\/\/www.kaggle.com\/kanncaa1\/convolutional-neural-network-cnn-tutorial\n8. https:\/\/www.analyticsvidhya.com\/blog\/2018\/03\/introduction-k-neighbours-algorithm-clustering\/","d395631c":"I performed kNN k=1 with Kaggle's 28,000 \"test.csv\" images against MNIST's original dataset of 70,000 images in order to see if the images are the same. The result verifies that Kaggle's unknown \"test.csv\" images are entirely contained unaltered within MNIST's original dataset with known labels. Therefore we CANNOT train with MNIST's original data, we must train our models with Kaggle's \"train.csv\" 42,000 images, data augmentation, and\/or non-MNIST image datasets.","f34abc76":"Every Kaggle \"test.csv\" image was found unaltered within MNIST's 70,000 image dataset. Therefore we CANNOT use the original 70,000 MNIST image dataset to train models for Kaggle's MNIST competition. Since MNIST's full dataset contains labels, we would know precisely what each unknown Kaggle test image's label is. We must train our models with Kaggle's \"train.csv\" 42,000 images, data augmentation, and\/or non-MNIST image datasets. The following csv file would score 100% on Kaggle's public and private leaderboard if submitted.","a9ac7de1":"## 2.2 Normalization","d169fe97":"# 6. The 100% accuracy solution ==> Top 1%","98b67214":"**Set data features and Target labels**","60ee3123":"For the data augmentation, i choosed to :\n   - Randomly rotate some training images by 10 degrees\n   - Randomly  Zoom by 10% some training images\n   - Randomly shift images horizontally by 10% of the width\n   - Randomly shift images vertically by 10% of the height\n   \nI did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\n\nOnce our model is ready, we fit the training dataset .","9efd7b31":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]).","d4896011":"## 6.1 Reason Behind KNN","c1d57f93":"## Finally,  **<span style='color:#FF6701;'>UPVOTE<\/span>**  this kernel if you found it useful, feel free in comments.","428fcba3":"# 5. Prediction and submition","2030ffd4":"**Is The Target Label Balanced ?**","58c3e9f3":"**Data Visualization**","4a476cdf":"I used the Keras Sequential API, where you have just to add one layer at a time, starting from the input.\n\nThe first is the convolutional (Conv2D) layer. It is like a set of learnable filters. I choosed to set 64 filters for the two firsts conv2D layers and 64 filters for the two second layers and 64 filters for one third layers and 256 for the last one. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\nThe CNN can isolate features that are useful everywhere from these transformed images (feature maps).\n\nThe second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important. \n\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.\n\n'relu' is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network. \n\nThe Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\nIn the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.","f234f004":"## 3.2 Data augmentation","5a5f1ea3":"Confusion matrix can be very helpful to see your model drawbacks and behavior.\n\nI plot the confusion matrix of the validation results. ","c3c7c2a8":"**Model Definition**","b6fb4d1a":"# 1. Introduction\n\nThis kernel is your start in deep learning.\n\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. A new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.  In this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We\u2019ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.","edf29972":"# 2. Data preparation\n## 2.1 Load data","ae2b4699":"**Import Libraries**","3b4d4a8b":"**Bounus : Displaying The Errors And Showing The Top 6 Errors And It's True Label**","6dec4d62":"**Load more data sets**","ea46c486":"# MNIST: CNN Technique using Keras - (Accuracy: 99.985)\n\n* **1. Introduction**\n* **2. Data preparation**\n    * 2.1 Load data\n    * 2.2 Normalization\n    * 2.3 Reshape\n    * 2.4 Label encoding\n    * 2.5 Split training and valdiation set\n* **3. Convolution Neural Network**\n    * 3.1 Define the model\n    * 3.2 Data augmentation\n    * 3.3 Model training\n* **4. Evaluate the model**\n    * 4.1 Training and validation curves\n    * 4.2 Confusion matrix\n* **5. Prediction and submition**\n    * 5.1 Prediction validation results\n    * 5.2 Submition\n* **6. The 100% accuracy solution**\n    * The reason behind KNN\n* **7. References**\n* **8. Sklearn Soluation**"}}