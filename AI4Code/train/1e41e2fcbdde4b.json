{"cell_type":{"81df4fc6":"code","d86fa630":"code","ea3a2d1b":"code","9d0f5812":"code","bace7fc7":"code","f469896a":"code","4a99b715":"markdown","5276fd4d":"markdown","787bab97":"markdown","c19d64a2":"markdown","e3985a30":"markdown","219d77e7":"markdown","ae48436c":"markdown"},"source":{"81df4fc6":"!pip install tez\n!pip install efficientnet-pytorch","d86fa630":"import os\nimport albumentations\nimport pandas as pd\n\nimport tez\nfrom tez.datasets import ImageDataset\nfrom tez.callbacks import EarlyStopping\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom efficientnet_pytorch import EfficientNet\nfrom sklearn import metrics, model_selection, preprocessing","ea3a2d1b":"class LeafModel(tez.Model):\n    def __init__(self, num_classes):\n        super().__init__()\n\n        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b4\")\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(1792, num_classes)\n        self.step_scheduler_after = \"epoch\"\n        \n    def monitor_metrics(self, outputs, targets):\n        if targets is None:\n            return {}\n        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        accuracy = metrics.accuracy_score(targets, outputs)\n        return {\"accuracy\": accuracy}\n    \n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n        return opt\n    \n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n\n    def forward(self, image, targets=None):\n        batch_size, _, _, _ = image.shape\n\n        x = self.effnet.extract_features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        outputs = self.out(self.dropout(x))\n        \n        if targets is not None:\n            loss = nn.CrossEntropyLoss()(outputs, targets)\n            metrics = self.monitor_metrics(outputs, targets)\n            return outputs, loss, metrics\n        return outputs, None, None","9d0f5812":" #augmentations taken from: https:\/\/www.kaggle.com\/khyeh0719\/pytorch-efficientnet-baseline-train-amp-aug\ntrain_aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(256, 256),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)], p=1.)\n  \n        \nvalid_aug = albumentations.Compose([\n            albumentations.CenterCrop(256, 256, p=1.),\n            albumentations.Resize(256, 256),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            )], p=1.)","bace7fc7":"dfx = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ndf_train, df_valid = model_selection.train_test_split(dfx, test_size=0.1, random_state=42, stratify=dfx.label.values)\n\ndf_train = df_train.reset_index(drop=True)\ndf_valid = df_valid.reset_index(drop=True)\n\nimage_path = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\ntrain_image_paths = [os.path.join(image_path, x) for x in df_train.image_id.values]\nvalid_image_paths = [os.path.join(image_path, x) for x in df_valid.image_id.values]\ntrain_targets = df_train.label.values\nvalid_targets = df_valid.label.values\n\ntrain_dataset = ImageDataset(\n    image_paths=train_image_paths,\n    targets=train_targets,\n    #resize=None,\n    augmentations=train_aug,\n)\nvalid_dataset = ImageDataset(\n    image_paths=valid_image_paths,\n    targets=valid_targets,\n    #resize=None,\n    augmentations=valid_aug,\n)","f469896a":"model = LeafModel(num_classes=dfx.label.nunique())\nes = EarlyStopping(\n    monitor=\"valid_loss\", model_path=\"model.bin\", patience=3, mode=\"min\"\n)\nmodel.fit(\n    train_dataset,\n    valid_dataset=valid_dataset,\n    train_bs=32,\n    valid_bs=64,\n    device=\"cuda\",\n    epochs=10,\n    callbacks=[es],\n    fp16=True,\n)\nmodel.save(\"model.bin\")","4a99b715":"# **Install Tez**","5276fd4d":"# **What is tez** ?\n# ****tez: a simple pytorch trainer****<br>\n\ntez (\u0924\u0947\u095b \/ \u062a\u06cc\u0632) means sharp, fast & active. This is a simple, to-the-point, library to make your pytorch training easy.<br>\n\nThis library is in very early-stage currently! So, there might be breaking changes.","787bab97":"# **Augmentations**","c19d64a2":"# **Load, Train & Save Model**","e3985a30":"# **Tez.Model**","219d77e7":"# **Read CSV, split & create dataset**","ae48436c":"# **Import Libraries**"}}