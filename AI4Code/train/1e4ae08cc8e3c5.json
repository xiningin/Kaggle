{"cell_type":{"f9d85baf":"code","fd6539ca":"code","8f6721d0":"code","42630aaa":"code","94067e16":"code","112fced9":"code","6c43e9c1":"code","2a44e7a9":"code","e9be4249":"code","af8c39c3":"code","81551b9d":"code","5d992ddc":"code","adb019a9":"code","46c424e9":"code","127d1222":"code","5cecfcb4":"markdown","c579c8f5":"markdown","4ebf5fc4":"markdown","18f8bb52":"markdown","b4d2682c":"markdown"},"source":{"f9d85baf":"from google.colab import drive\nimport os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.layers import Input, Dense, Activation, Flatten, Conv2D\nfrom keras.layers import MaxPooling2D, Dropout, ZeroPadding2D, BatchNormalization\nfrom keras.models import Model, load_model\nfrom keras.preprocessing.image import ImageDataGenerator, image\ntf.test.gpu_device_name()","fd6539ca":"\noriginal_dataset_dir = '\/content\/drive\/My Drive\/FD' \n\nbase_dir = '\/content\/FDF_and_NF'\n#os.mkdir(base_dir)\n\ntrain_dir = os.path.join(base_dir, 'train')\n#os.mkdir(train_dir)\n\ntest_dir = os.path.join(base_dir, 'test') \n#os.mkdir(test_dir)\n\ntrain_flower_dir = os.path.join(train_dir, 'Flower')\n#os.mkdir(train_flower_dir)\n\ntrain_nonflower_dir = os.path.join(train_dir, 'NF')\n#os.mkdir(train_nonflower_dir)\n\ntest_flower_dir = os.path.join(test_dir, 'Flower')\n#os.mkdir(test_flower_dir)\n\ntest_nonflower_dir = os.path.join(test_dir, 'NF')\n#os.mkdir(test_nonflower_dir)\n\n\nfnames = ['FD.{}.jpg'.format(i) for i in range(4700)]\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir, fname)\n  dst = os.path.join(train_flower_dir, fname)\n  shutil.copyfile(src, dst)\n\n\nfnames = ['FD.{}.jpg'.format(i) for i in range(4700, 5262)]\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir, fname)\n  dst = os.path.join(test_flower_dir, fname)\n  shutil.copyfile(src, dst)\n\n  fnames = ['NFD{}.jpg'.format(i) for i in range(4700)]\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir, fname)\n  dst = os.path.join(train_nonflower_dir, fname)\n  shutil.copyfile(src, dst)\n\nfnames = ['NFD{}.jpg'.format(i) for i in range(4700, 5262)]\nfor fname in fnames:\n  src = os.path.join(original_dataset_dir, fname)\n  dst = os.path.join(test_nonflower_dir, fname)\n  shutil.copyfile(src, dst)\n\n","8f6721d0":"print('total training flower images:', len(os.listdir(train_flower_dir)))\nprint('total training non-flower images:', len(os.listdir(train_nonflower_dir)))\nprint('total test flower images:', len(os.listdir(test_flower_dir)))\nprint('total test non-flower images:', len(os.listdir(test_nonflower_dir)))","42630aaa":"\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    class_mode = 'binary',\n    target_size = (200, 200),\n    batch_size = 16)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    class_mode = 'binary',\n    target_size = (200, 200),\n    batch_size = 16)\n","94067e16":"for data_batch, labels_batch in train_generator:\n  print('data batch shape:', data_batch.shape)\n  print('labels batch shape:', labels_batch.shape)\n  break","112fced9":"def f_n(input_shape):\n\n  #Placeholding for the X_input.\n  X_input = Input(input_shape)\n    \n  X = X_input\n\n  X = Conv2D(32, (3, 3), activation = 'relu', input_shape=(200, 200, 3))(X)\n  X = MaxPooling2D((2, 2))(X)\n  X = Conv2D(32, (3, 3), activation = 'relu')(X)\n  X = MaxPooling2D((2, 2))(X)\n  X = Flatten()(X)\n  X = Dropout(0.5)(X)\n\n  #FC\n  X = Dense(16, activation = 'relu')(X)\n  #Sigmoid activation\n  X = Dense(1, activation = 'sigmoid')(X)\n\n  #Model creation\n  model = Model(inputs = X_input, outputs = X, name='f_n')\n\n  return model","6c43e9c1":"F_N = f_n(input_shape = (200, 200, 3)) #Assigning the model","2a44e7a9":"F_N.compile(loss = 'binary_crossentropy', \n              optimizer = 'Adam',\n              metrics = ['acc']) ","e9be4249":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size #Determining the step size == (number of samples)\/(batch size)\n\nF_N.fit_generator(generator=train_generator,                # Model training\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    epochs = 30)","af8c39c3":"STEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size #Determining the step size == (number of samples)\/(batch size)\n\ntest_generator.reset()\n\npred = F_N.predict_generator(test_generator,        # Model Evaluation\nsteps=STEP_SIZE_TEST,\nverbose=1)\n\nprint (\"Loss = \" + str(pred[0]))\nprint (\"Test Accuracy = \" + str(pred[1]))","81551b9d":"F_N.save('F_N_99.9%,h5') #Saving the weights of the model as an h5 file.","5d992ddc":"F_N = load_model('\/content\/drive\/My Drive\/Colab Notebooks\/Flower_Not\/F_N_99%,h5') # Only if there is already a trained model !","adb019a9":"F_N.summary() ","46c424e9":"from google.colab import files        #Test your own images ! \nuploaded = files.upload()             #Upload an image from your dir.\n\nfor name, data in uploaded.items():\n  with open(name, 'wb') as f:\n    f.write(data)\n    print ('saved file', name)","127d1222":"from matplotlib.pyplot import imshow\nfrom keras.applications.imagenet_utils import preprocess_input\n\nimg_path = '\/content\/' + name          #Uncomment if you want to use the image uploded by the previous cell.\n#img_path = '\/content\/' + '350' + '.jpg' #Uncomment if you want to choose the image manually.\n\nimg = image.load_img(img_path, target_size=(200, 200))\n\nimshow(img)\n\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\nif F_N.predict(x) == 0 :\n  print(\"It contains flower !\")\nelse :\n  print(\"It does not contain flower\")","5cecfcb4":"# Model Compileing, Training, and Testing","c579c8f5":"# Data Preparing","4ebf5fc4":"# Model Saving, Loading, and Summrizing.","18f8bb52":"# Model Creation and Assigning.","b4d2682c":"# Test Your Own Images :)"}}