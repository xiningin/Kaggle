{"cell_type":{"426323d3":"code","e19a8d31":"code","3c948b6a":"code","19c705a8":"code","ad2d17d3":"code","8c0dd51c":"code","d2e3671d":"code","ee7b5478":"code","6377c9a9":"code","3cd0b374":"code","4c47f644":"code","e500d33c":"code","cf39ae99":"code","d59e8e8b":"code","b2d6e395":"code","c5137438":"code","1005730e":"code","0a4320a2":"code","d33ecdd7":"code","1f2e9696":"code","e45380cc":"code","3fad54df":"code","7a0029aa":"code","bb64e091":"code","1f038b9d":"code","2820233f":"code","c58bd02f":"code","ca14b57d":"code","d1dfc049":"code","f5ce3be2":"code","60b08073":"code","36de4725":"code","318ee24f":"code","91123917":"code","b49b0a07":"code","494d6665":"code","0226ff43":"code","0c913838":"code","ec38269b":"code","56567f32":"code","e01efa96":"code","34791b14":"code","d22d48ac":"code","a0cf543f":"code","25f6deef":"code","eed6a0b7":"code","62f04123":"code","23b170f9":"code","830da64d":"code","9e4c5122":"code","85b1fc2f":"code","6efa7dd3":"code","0fdd6e60":"code","e4a859e1":"code","cced359a":"code","e64c580a":"code","1655aa62":"code","ee1d9b4e":"code","d4069004":"code","ccdd76c6":"markdown","a96e7371":"markdown","1d9df877":"markdown","a021f439":"markdown","5e3262aa":"markdown","c51f4d20":"markdown","0c8d4501":"markdown","dd797557":"markdown","9878a433":"markdown","a19c9f9a":"markdown","0ec0c9b3":"markdown","835a657b":"markdown","54762db5":"markdown","b5db84b5":"markdown","7e3f52c1":"markdown","c338e3cd":"markdown","d14f9819":"markdown","0b856005":"markdown","a58a04bc":"markdown","ff6b7121":"markdown","0196e9b4":"markdown","af29a4e2":"markdown","5cb46f1f":"markdown","b2126067":"markdown","4962693c":"markdown","3ad18058":"markdown","3bb4fa10":"markdown","b2bd8fbf":"markdown","f05877d2":"markdown","fee852d0":"markdown","f46d39b6":"markdown","7c35d34f":"markdown","3313a5b6":"markdown","4fea0c56":"markdown","6dcb8d55":"markdown","f9dc1634":"markdown","493fef52":"markdown","33ae5307":"markdown","825a161a":"markdown","4f00d205":"markdown","7ce4c78a":"markdown","0420dd65":"markdown","6dffccb6":"markdown","21c5a798":"markdown","962b3783":"markdown","f3ede88e":"markdown","ecf380df":"markdown","915d3b8e":"markdown","43d0739c":"markdown","75a136b7":"markdown","6a1ada3d":"markdown","e9def64f":"markdown","86cdfc5d":"markdown","357bc1bd":"markdown","457bf431":"markdown","d826bc97":"markdown","d614dd3d":"markdown","4a3e64fe":"markdown","7cfa28fb":"markdown","08b77537":"markdown","9c04986a":"markdown","c6af00ac":"markdown","b43f9f59":"markdown","01880c9b":"markdown","4cbbd0b2":"markdown","417cd56a":"markdown","be91fc74":"markdown","c73ce703":"markdown","4a53aa97":"markdown","c97b2c37":"markdown","82cbf4dc":"markdown","1cc74f9c":"markdown","e6d7b09d":"markdown","a24fd847":"markdown","26411942":"markdown","f9261f12":"markdown","497d1d8a":"markdown","e30b0942":"markdown","375c7cd0":"markdown","b6c5d817":"markdown","0dacb310":"markdown","57ad2488":"markdown","fddd3c2d":"markdown","711f310c":"markdown","2e641928":"markdown","310c3a23":"markdown","5e2a5abe":"markdown","6630565d":"markdown","afdcbbf6":"markdown","4369cd67":"markdown","fa78f771":"markdown","0fc474ea":"markdown","97bb0602":"markdown","21d96428":"markdown","08e59e99":"markdown","036a6020":"markdown"},"source":{"426323d3":"%%HTML\n<style type=\"text\/css\">\n\ndiv.h2 {\n    background-color: firebrick; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 24px; \n    max-width: 1500px; \n    margin-top: 50px;\n    margin-bottom:4px;\n}\n\n<\/style>","e19a8d31":"%%HTML\n<style type=\"text\/css\">\n\ndiv.h3 {\n    background-color: dodgerblue; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 20px; \n    max-width: 1500px; \n    margin-top: 50px;\n    margin-bottom:4px;\n}\n\n<\/style>","3c948b6a":"pip install --upgrade pip","19c705a8":"pip install seaborn --upgrade","ad2d17d3":"!pip install pycountry_convert","8c0dd51c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint('Seaborn version', sns.__version__)\nimport os\n%config InlineBackend.figure_format = 'retina'\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pycountry\nimport pycountry_convert as pc\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport textwrap","d2e3671d":"data = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\ndata.head()","ee7b5478":"questions = data.iloc[0, :].T\ndata = data.iloc[1:, :]","6377c9a9":"data['Time from Start to Finish (seconds)'].median()\/60","3cd0b374":"Map=data.Q3.value_counts().to_frame()\ndef alpha3code(column):\n    CODE=[]\n    for country in column:\n      if country !='Other': \n        try:\n            code=pycountry.countries.search_fuzzy(country)[0].alpha_3\n           # .alpha_3 means 3-letter country code \n           # .alpha_2 means 2-letter country code\n            CODE.append(code)\n        except:\n            CODE.append('None')\n      else:\n        CODE.append('Other')\n    return CODE\n# create a column for code \nMap['CODE']=alpha3code(Map.index)\nMap.head()","4c47f644":"import geopandas\nfrom geopandas import GeoDataFrame\nworld = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n# rename the columns so that we can merge with our data\nworld.columns=['pop_est', 'continent', 'name', 'CODE', 'gdp_md_est', 'geometry']\n# then merge with our data \nmerge=pd.merge(Map,world, how='right', on='CODE')\n# merge['Q3'] = merge['Q3'].fillna(0)\nmerge = GeoDataFrame(merge).sort_values(by='Q3',ascending=False)\nlocation=pd.read_csv('https:\/\/raw.githubusercontent.com\/melanieshi0120\/COVID-19_global_time_series_panel_data\/master\/data\/countries_latitude_longitude.csv')\nmerge=merge.merge(location,on='name').reset_index()\nmerge.head()","e500d33c":"x=pd.array(merge[merge.name==\"Egypt\"].latitude)[0]\nmerge['latitude'] = merge['latitude'].replace( x,26.8357675)\nmerge['longitude'] = merge['longitude'].replace([-78.183406],30.7956597)","cf39ae99":"merge.plot(column='Q3', scheme=\"quantiles\",\n           figsize=(30, 25), cmap='Reds',\n           legend=True, missing_kwds={'color': 'grey',\n           \"hatch\": \"\",\n           \"label\": \"Missing values\"} )\nplt.title('2020 Participants',fontsize=30, weight='bold')\n# add countries names and numbers \nfor i in range(0,20):\n    plt.text(float(merge.longitude[i]), float(merge.latitude[i]),\n             \"{}\\n{}\".format(merge.name[i], int(merge.Q3[i])), size=10)","d59e8e8b":"data['Q3'].replace({'United States of America':\n                   'USA', 'Viet Nam': 'Vietnam',\n                   'United Kingdom of Great Britain and Northern Ireland': 'UK',\n                   'Iran, Islamic Republic of...': 'Iran'}, inplace=True)","b2d6e395":"data['Q3'].unique()","c5137438":"data['Q3'].count()","1005730e":"data['Q3'].value_counts()","0a4320a2":"countries = np.asarray(data[\"Q3\"])\n# Continent_code to Continent_names\ncontinents = {\n    'NA': 'North America',\n    'SA': 'South America', \n    'AS': 'Asia',\n    'OC': 'Australia',\n    'AF': 'Africa',\n    'EU' : 'Europe',\n    'na' : 'Others'\n}\n\n# Defininng Function for getting continent code for country.\ndef country_to_continent_code(country):\n    try:\n        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(country))\n    except :\n        return 'na'\n    \n#Collecting Continent Information\ndata.insert(2,\"continent\", [continents[country_to_continent_code(country)] for country in countries[:]])","d33ecdd7":"df_continents = data.groupby([\"continent\"]).sum()","1f2e9696":"continents = data['continent'].value_counts().sort_values(ascending=False)\nplt.figure(figsize=(15,6))\ncolor = ['dodgerblue' if (x < max(continents)) else 'firebrick' for x in continents]\nax = sns.countplot(x=\"continent\", data=data, order=continents.index, palette=color, saturation=1)\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['continent'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","e45380cc":"countries = data['Q3'].value_counts()\nplt.figure(figsize=(10, 30))\ncolor = ['dodgerblue' if (y < max(countries)) else 'firebrick' for y in countries]\nax= sns.countplot(y=\"Q3\", data=data, order=countries.index, palette=color, saturation=1)\nplt.ylabel('country')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q3'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","3fad54df":"colors = ['firebrick', 'dodgerblue', 'black', 'yellow', 'olive'] \ncounts = data['Q2'].value_counts(sort=True)\nlabels = counts.index\nvalues = counts.values\npie = go.Pie(labels=labels, values=values, marker=dict(colors=colors, line=dict(color='#000000', width=1)))\nfig = go.Figure(data=[pie])\npy.iplot(fig)","7a0029aa":"age = data['Q1'].value_counts()\nplt.figure(figsize=(15,6))\ncolor = ['dodgerblue' if (x < max(age)) else 'firebrick' for x in age]\nax= sns.countplot(x=\"Q1\", data=data, order=age.index, palette=color, saturation=1)\nplt.xlabel('age')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q1'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","bb64e091":"education = data['Q4'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(education)) else 'firebrick' for y in education]\nax= sns.countplot(y=\"Q4\", data=data, order=education.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('education')\nplt.yticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q4'])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)","1f038b9d":"job_role = data['Q5'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(job_role)) else 'firebrick' for y in job_role]\nax= sns.countplot(y=\"Q5\", data=data, order=job_role.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('job role')\nplt.yticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q5'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","2820233f":"experience = data['Q6'].value_counts()\nplt.figure(figsize=(15, 6))\ncolor = ['dodgerblue' if (x < max(experience)) else 'firebrick' for x in experience]\nax= sns.countplot(x=\"Q6\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_xticklabels(textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels())\nplt.xlabel('code experience')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q5'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","c58bd02f":"compensation = data['Q24'].value_counts()\nplt.figure(figsize=(10, 15))\ncolor = ['dodgerblue' if (y < max(compensation)) else 'firebrick' for y in compensation]\nax= sns.countplot(y=\"Q24\", data=data, order=compensation.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('compensation')\nplt.yticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q24'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","ca14b57d":"df = data[[i for i in data.columns if 'Q7' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q7' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('programming languages')","d1dfc049":"experience = data['Q8'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(experience)) else 'firebrick' for y in experience]\nax= sns.countplot(y=\"Q8\", data=data, order=experience.index, palette=color, saturation=1)\nplt.ylabel('programming languages')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q8'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","f5ce3be2":"experience = data['Q11'].value_counts()\nplt.figure(figsize=(15,6))\ncolor = ['dodgerblue' if (x < max(experience)) else 'firebrick' for x in experience]\nax= sns.countplot(x=\"Q11\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_xticklabels(textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels())\nplt.xlabel('computing platform')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q11'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","60b08073":"df = data[[i for i in data.columns if 'Q12' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=False)\ncolor = ['dodgerblue' if (x<max(df_all)) else 'firebrick' for x in df_all]\nplt.figure(figsize=(15, 6))\nax = df_all.plot(kind='bar', color=color, alpha=1, width=0.8)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data[[i for i in data.columns if 'Q12' in i]])),\n                (x + width\/2, y + height\/2), ha='center', va='center', fontsize=12)\nplt.xticks(rotation=0, fontsize=15)\nplt.xlabel('hardware accelerators')","36de4725":"experience = data['Q13'].value_counts()\nplt.figure(figsize=(15,6))\ncolor = ['dodgerblue' if (x < max(experience)) else 'firebrick' for x in experience]\nax= sns.countplot(x=\"Q13\", data=data, order=experience.index, palette=color, saturation=1)\nplt.xlabel('number of times')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q13'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","318ee24f":"df = data[[i for i in data.columns if 'Q17' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q17' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('algorithms')","91123917":"df = data[[i for i in data.columns if 'Q9' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q9' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('favorite ides')","b49b0a07":"df = data[[i for i in data.columns if 'Q10' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q10' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('notebooks')","494d6665":"df = data[[i for i in data.columns if 'Q14' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q14' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('visualization tools')","0226ff43":"df = data[[i for i in data.columns if 'Q16' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q16' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('ml frameworks')","0c913838":"ml_experience = data['Q15'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(ml_experience)) else 'firebrick' for y in ml_experience]\nax= sns.countplot(y=\"Q15\", data=data, order=ml_experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('ml experience')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q15'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","ec38269b":"df = data[[i for i in data.columns if 'Q18' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q18' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('cv methods')","56567f32":"df = data[[i for i in data.columns if 'Q19' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q19' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('nlp methods')","e01efa96":"df = data[[i for i in data.columns if 'Q26' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q26' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('cloud computing platforms')","34791b14":"df = data[[i for i in data.columns if 'Q27' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q27' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('cloud computing products')","d22d48ac":"df = data[[i for i in data.columns if 'Q28' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q28' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('ml products')","a0cf543f":"df = data[[i for i in data.columns if 'Q29' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q29' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('big data products')","25f6deef":"experience = data['Q30'].value_counts()\nplt.figure(figsize=(10, 15))\ncolor = ['dodgerblue' if (y < max(experience)) else 'firebrick' for y in experience]\nax= sns.countplot(y=\"Q30\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('big data products')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q30'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","eed6a0b7":"df = data[[i for i in data.columns if 'Q31' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q31' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('business ntelligence tools')","62f04123":"experience = data['Q32'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(experience)) else 'firebrick' for y in experience]\nax= sns.countplot(y=\"Q32\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('visualization software')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q32'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","23b170f9":"df = data[[i for i in data.columns if 'Q33' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q33' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('automated ml tools')","830da64d":"df = data[[i for i in data.columns if 'Q34' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q34' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('automated ml tools')","9e4c5122":"df = data[[i for i in data.columns if 'Q35' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q35' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('tools for ml experiments')","85b1fc2f":"df = data[[i for i in data.columns if 'Q36' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 10))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q36' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('platforms to share apps')","6efa7dd3":"df = data[[i for i in data.columns if 'Q37' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q37' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('platforms for courses')","0fdd6e60":"experience = data['Q38'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(experience)) else 'firebrick' for y in experience]\nax= sns.countplot(y=\"Q38\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('primart tools at work')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q38'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","e4a859e1":"df = data[[i for i in data.columns if 'Q39' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q39' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('favorite media sources')","cced359a":"experience = data['Q20'].value_counts()\nplt.figure(figsize=(15, 6))\ncolor = ['dodgerblue' if (x < max(experience)) else 'firebrick' for x in experience]\nax= sns.countplot(x=\"Q20\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_xticklabels(textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels())\nplt.xlabel('company size')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q20'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","e64c580a":"df = data[[i for i in data.columns if 'Q23' in i]]\ndf_all = pd.Series(dtype='int')\nfor i in df.columns:\n    df_all[df[i].value_counts().index[0]] = df[i].count()\ndf_all = df_all.sort_values(ascending=True)\ncolor = ['dodgerblue' if (y<max(df_all)) else 'firebrick' for y in df_all]\nplt.figure(figsize=(10, 15))\nax = df_all.plot(kind='barh', color=color, alpha=1, width=0.8)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x,y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data[[i for i in data.columns if 'Q23' in i]])),\n                (x + width\/2, y + height\/2), ha='left', va='center', fontsize=12)\nplt.yticks(fontsize=15)\nplt.ylabel('activities')","1655aa62":"experience = data['Q21'].value_counts()\nplt.figure(figsize=(15,6))\ncolor = ['dodgerblue' if (x < max(experience)) else 'firebrick' for x in experience]\nax= sns.countplot(x=\"Q21\", data=data, order=experience.index, palette=color, saturation=1)\nplt.xlabel('people responsible for ds')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q21'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","ee1d9b4e":"experience = data['Q22'].value_counts()\nplt.figure(figsize=(10, 10))\ncolor = ['dodgerblue' if (y < max(experience)) else 'firebrick' for y in experience]\nax= sns.countplot(y=\"Q22\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_yticklabels(textwrap.fill(y.get_text(), max_width) for y in ax.get_yticklabels())\nplt.ylabel('ml incorporation')\nplt.yticks(fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_width())*100\/len(data['Q22'])),\n                (x + width\/2, y + height\/2), ha='left', va='center',fontsize=12)","d4069004":"experience = data['Q25'].value_counts()\nplt.figure(figsize=(15,6))\ncolor = ['dodgerblue' if (x < max(experience)) else 'firebrick' for x in experience]\nax= sns.countplot(x=\"Q25\", data=data, order=experience.index, palette=color, saturation=1)\nmax_width = 20\nax.set_xticklabels(textwrap.fill(x.get_text(), max_width) for x in ax.get_xticklabels())\nplt.xlabel('money spent on ml')\nplt.xticks(rotation=0, fontsize=15)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(\"{:.2f}%\".format((p.get_height())*100\/len(data['Q25'])),\n                (x + width\/2, y + height\/2), ha='center', va='center',fontsize=12)","ccdd76c6":"<div class=h3>Automated Machine Learning Tools Used on a Regular Basis<\/div>","a96e7371":"<div class=h3>Tools to Help Machine Learning Experiments<\/div>","1d9df877":"MySQL is the most commonly used database. PostgreSQL has taken the second spot, edging ahead of Microsoft SQL Server.","a021f439":"<div class=h3>Continents<\/div>","5e3262aa":"About three-fourths of the people who took the survey are younger than 35.","c51f4d20":"<div class=h3>Machine Learning Frameworks<\/div>","0c8d4501":"Over 60% of respondents have less than five years of professional coding experience.","dd797557":"<div class=h3>Favorite Data Science Media Sources<\/div>","9878a433":"<div class=h3>Education<\/div>","a19c9f9a":"<div class=h2>Technology<\/div>","0ec0c9b3":"<div class=h3>Machine Learning Experience<\/div>","835a657b":"Respondents were asked about their compensation, and the majority of people who answered this question, makes less than 1000 USD a year.","54762db5":"<div class=h2>Kagglers Profile<\/div>","b5db84b5":"# Kaggle DS and ML Survey 2020","7e3f52c1":"<div class=h2>Overview<\/div>","c338e3cd":"<div class=h3>Money Spent on Machine Learning<\/div>","d14f9819":"Worldwide, more than three-fourths of respondents have the equivalent of a bachelor's degree or higher. However, it is not that rare to find accomplished professionals who have not completed a degree.","0b856005":"Kagglers work in companies of all sizes, from small to large enterprise organizations. About 30% work at small companies and more than 20% work at large companies.","a58a04bc":"<div class=h3>Programming Languages Used on a Regular Basis<\/div>","ff6b7121":"The most common cloud computing platforms for respondents are Amazon Web Services, Google Cloud Platform and Microsoft Azure.","0196e9b4":"<div class=h3>Company Size<\/div>","af29a4e2":"<div class=h3>Business Intelligence Tools Used Most Often<\/div>","5cb46f1f":"Most respondents on the survey say they are not using any automated machine learning tools, and the most common used are Automated model selection and Automation of full ML pipelines.","b2126067":"<div class=h2>Geography<\/div>","4962693c":"More than 29% of Kagglers are from India, and more than 11% of Kagglers are from the USA. Countries like Belarus, Ireland and Ghana are the least represented among kagglers.","3ad18058":"About 50% of respondents currently reside in Asia, and about 15% of respondents currently reside in Europe. These are the continents with the highest number of respondents.","3bb4fa10":"Different types of organizations apply different sets of activities when considering work. Over 30% of respondents analyze and understand data to influence product or business decisions.","b2bd8fbf":"Over 40% of respondents say that there are less than 10 people responsible for Data Science at their organization.","f05877d2":"This year, 20,036 Kaggle users told us how they learn and level up, which tools they\u2019re using, and what they recommend. The results include raw numbers about who is working with data, what\u2019s happening with machine learning in different industries, and the best ways for new data scientists to break into the field.","fee852d0":"When it comes to machine learning algorithms, more than half of respondents use Linear or Logistic Regression, and around 45% use Decision Trees or Random Forests.","f46d39b6":"<div class=h3>Machine Learning Incorporation at the Company<\/div>","7c35d34f":"<div class=h3>Business Intelligence Tools Used on a Regular Basis<\/div>","3313a5b6":"Python is the most commonly used programming language. This year, Python was used on a regular basis by almost 80% of respondents. Python is the fastest-growing major programming language today. SQL was used by almost 38% of respondents, and it is the second most commonly used programming language. R is the third most commonly used programming language, and it is preferred by over 20% of respondents. Swift and Julia are the least used programming languages.","4fea0c56":"<div class=h3>Hardware Accelerators<\/div>","6dcb8d55":"<div class=h2>Key Results<\/div>","f9dc1634":"<div class=h3>Compensation<\/div>","493fef52":"Word embeddings\/vectors are the most popular NLP methods.","33ae5307":"Respondents were asked about their gender identity, and it turned out that globally about 80% of respondents are men. This year more than 19% of survey respondents are women, a little bit up from on last year's survey. This represents improvement in this area, but the continued low proportion points to problems with inclusion in the tech industry in general and on Kaggle in particular.","825a161a":"When asked how about using hardware accelerators such as GPU or TPU, about 40% of respondents say they are not using any such technology today. Those who are using hardware accelerators most commonly prefer GPUs, and only about 5% of respondents use TPUs.","4f00d205":"* Python, the fastest-growing major programming language, is the most used programming language on the survey, followed by SQL, which is standing as the second most used language.\n* The overwhelming majority of respondents are still men, although this situation is slowly changing.\n* Around half of respondents reside in Asia. This fact makes Asia the continent with the highest number of Kaggle users.\n* The most prevailing occupation role is student and the most common degrees respondents have are master's and bachelor's degrees.\n* India is on top of the countries on the survey, followed by the USA, while countries like Ghana and Ireland are among the ones that have the lowest number of respondents.\n* When thinking about work experience, we can see that more than half of respondents have experience of less than 5 years.\n* Respondents were asked about their age. The data indicates that Kaggle users are mostly people in the age from 18 to 30.","7ce4c78a":"About 40% of respondents do not use any tools to help ML experiments.","0420dd65":"Tableau and Microsoft Power BI are business iintelligence tools that are also used most often.","6dffccb6":"Jupiter is the most loved integrated environment for development, with both Visual Studio Code and Pycharm also highly loved this year. Vim\/Emacs and MATLAB are the least loved IDEs.","21c5a798":"Over half of respondents use local development environment and basic statistical software as primary tools at work.","962b3783":"<div class=h3>Code Experience<\/div>","f3ede88e":"<div class=h3>Primary Tools at Work<\/div>","ecf380df":"Respondents were asked what computing platforms they use for work. Over 60% say they mainly use a personal computer or laptop, about 12% use a cloud computing platform, and over 4% use a deep learning work station.","915d3b8e":"<div class=h3>Usage of TPUs<\/div>","43d0739c":"Auto-Sklearn, Google Cloud AutoML and Auto-Keras are the most commonly used automated ML tools.","75a136b7":"<div class=h3>Computer Vision Methods<\/div>","6a1ada3d":"<div class=h3>Favorite Integrated Development Environments (IDEs)<\/div>","e9def64f":"<div class=h3>Natural Language Processing (NLP) Methods<\/div>","86cdfc5d":"Colab Notebooks are the most commonly used notebooks. However, the difference between the number of respondents who use Colab Notebooks and the number of respondents who use Kaggle Notebooks is less than 2%, and a good amount of people use none.","357bc1bd":"Respondents were asked what computer vision methods they use the most, and Image classification and General purpose image\/video tools were the most common answers.","457bf431":"MySQL is the most popular database used on a regular basis. MongoDB has taken the second spot.","d826bc97":"<div class=h3>Platforms to Share Applications<\/div>","d614dd3d":"<div class=h3>Machine Learning Products<\/div>","4a3e64fe":"<div class=h3>Programming Languages Recommended for Aspiring Data Scientists<\/div>","7cfa28fb":"# Thanks for reading! \u263a","08b77537":"Most respondents on the survey say their organizations are not spending any money on ML.","9c04986a":"About half of respondents have less than two years of machine learning experience.","c6af00ac":"<div class=h3>Machine Learning Algorithms<\/div>","b43f9f59":"There are many online platforms people use to learn Data Science. The most common choices this year for respondents were Coursera, Kaggle Learn Courses and Udemy.","01880c9b":"Respondents were asked what social platforms they use to share or deploy their data analysis or machine learning applications, and Github was the most common answer.","4cbbd0b2":"Matplotlib is the number one visualization library kagglers use for work, followed by Seaborn. The third spot is about evenly split between Plotly and Ggplot. Altair is the least popular visualization library on the survey.","417cd56a":"<div class=h3>Computing Platforms<\/div>","be91fc74":"![](https:\/\/www.gammanalytics.com\/assets\/img\/services\/DataScience.png)","c73ce703":"<div class=h3>Gender<\/div>","4a53aa97":"<div class=h3>Age<\/div>","c97b2c37":"<div class=h3>Platforms for Data Science Courses<\/div>","82cbf4dc":"Almost 26% of all respondents are Students. Among professionals, more than 13% of respondents are Data Scientists, and about 10% of respondents are Software Engineers.","1cc74f9c":"<div class=h3>Visualization Libraries<\/div>","e6d7b09d":"Image: https:\/\/www.gammanalytics.com","a24fd847":"<div class=h3>Cloud Computing Products<\/div>","26411942":"<div class=h2>Company Information<\/div>","f9261f12":"<div class=h2>Demographics<\/div>","497d1d8a":"Scikit-learn is a dominant player among machine learning frameworks this year, followed by Tensorflow and Keras.","e30b0942":"### What we know about Kaggle users","375c7cd0":"Over 60% of respondents never use TPUs.","b6c5d817":"<div class=h3>Big Data Products Used Most Often<\/div>","0dacb310":"<div class=h3>Current Job Role<\/div>","57ad2488":"<div class=h3>Activities at Work<\/div>","fddd3c2d":"The median time spent on the survey for qualified responses was 10.43 minutes. Unfortunately, the survey data contains missing values. This unanticipated limitation should be kept in mind when interpreting survey results.","711f310c":"<div class=h3>Big Data Products Used on a Regular Basis<\/div>","2e641928":"Google Cloud AI Platform\/Google Cloud ML Engine is the most broadly used of the machine learning products.","310c3a23":"<div class=h3>Countries<\/div>","5e2a5abe":"### Here are a few of the top takeaways from this year\u2019s results.","6630565d":"Kaggle is the most loved Data Science media source among respondents, followed close behind by Youtube and blogs. Podcasts and Slack communities are the the least loved Data Science media sources.","afdcbbf6":"<div class=h3>Cloud Computing Platforms<\/div>","4369cd67":"About 19% of respondents use Tableau on a regular basis, and about 16% use Microsoft Power BI.","fa78f771":"<div class=h3>People Responsible for Data Science at Work<\/div>","0fc474ea":"Less than 20% of respondents say that their companies are using ML methods (including putting models into production), and over 20% say their companies are not using ML methods.","97bb0602":"Globally, over 70% of respondents recommend Python for aspiring Data Scientists, while over 6% of respondents recommend R. SQL is recommended by less than 5% of respondents.","21d96428":"<div class=h3>Most Hosted Notebooks<\/div>","08e59e99":"Google Cloud Compute Engine is the most used cloud computing product.","036a6020":"<div class=h3>Atomated Machine Learning Tools<\/div>"}}