{"cell_type":{"cc48edd5":"code","a6291ec1":"code","35360120":"code","b800c0ff":"code","d8e92c97":"code","b5b89818":"code","767b8c97":"code","052fa421":"code","bd3f0d4e":"code","413a68e4":"code","55981423":"code","cb2c9514":"code","2cd54055":"code","c0181d38":"code","24e64ec4":"code","5bfbfcf8":"code","d6502163":"code","3102598c":"code","b6685f0a":"code","738086ea":"code","60fc7590":"code","924c09f5":"code","0389a5c7":"code","1b79e327":"code","2b2b37ba":"code","cc317cc9":"code","84dff98d":"code","a0d05966":"markdown","9e0fdc0b":"markdown","e6ed122a":"markdown","23b643ba":"markdown","ceecc0b8":"markdown","b25a8d06":"markdown","104a835c":"markdown"},"source":{"cc48edd5":"# Import necessary packages\nimport numpy as np \nimport pandas as pd \nimport seaborn as sb\nimport matplotlib.pyplot as plt\n% matplotlib inline\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost\nfrom sklearn.metrics import explained_variance_score\nfrom xgboost import XGBClassifier","a6291ec1":"# Load train dataset\ntrain=pd.read_csv('..\/input\/train.csv')\ntrain.head()","35360120":"# Load test dataset\ntest=pd.read_csv('..\/input\/test.csv')\ntest.head()","b800c0ff":"train.info()","d8e92c97":"# Drop uneccessary columns\ntrain.drop(columns=['PassengerId','Name','Cabin','Ticket','Fare'],inplace=True)\ntest.drop(columns=['Name','Ticket','Cabin','Fare'],inplace=True)","b5b89818":"# Get index with null values in train dataset\nindex_list=train[train['Age'].isnull()].index\nindex_list","767b8c97":"# Fill those null values with appropiate mean values\nfor index in index_list:\n    if train.loc[index,'Pclass']==1 and train.loc[index,'Sex']=='female':\n        train.loc[index,'Age']=np.ceil(train.groupby(['Pclass','Sex'])['Age'].mean()[1][0])\n    elif train.loc[index,'Pclass']==1 and train.loc[index,'Sex']=='male':\n        train.loc[index,'Age']=np.ceil(train.groupby(['Pclass','Sex'])['Age'].mean()[1][1])\n    elif train.loc[index,'Pclass']==2 and train.loc[index,'Sex']=='female':\n        train.loc[index,'Age']=np.ceil(train.groupby(['Pclass','Sex'])['Age'].mean()[2][0])\n    elif train.loc[index,'Pclass']==2 and train.loc[index,'Sex']=='male':\n        train.loc[index,'Age']=np.ceil(train.groupby(['Pclass','Sex'])['Age'].mean()[2][1])\n    elif train.loc[index,'Pclass']==3 and train.loc[index,'Sex']=='female':\n        train.loc[index,'Age']=np.ceil(train.groupby(['Pclass','Sex'])['Age'].mean()[3][0])\n    else:\n        train.loc[index,'Age']=np.ceil(train.groupby(['Pclass','Sex'])['Age'].mean()[3][1])","052fa421":"# Fill Embarked with mode of the column\ntrain['Embarked'].fillna(train['Embarked'][0],inplace=True)","bd3f0d4e":"# Get index with null values in test dataset\nindex_list=test[test['Age'].isnull()].index\nindex_list","413a68e4":"# Fill those null values with appropiate mean values\nfor index in index_list:\n    if test.loc[index,'Pclass']==1 and test.loc[index,'Sex']=='female':\n        test.loc[index,'Age']=np.ceil(test.groupby(['Pclass','Sex'])['Age'].mean()[1][0])\n    elif test.loc[index,'Pclass']==1 and test.loc[index,'Sex']=='male':\n        test.loc[index,'Age']=np.ceil(test.groupby(['Pclass','Sex'])['Age'].mean()[1][1])\n    elif test.loc[index,'Pclass']==2 and test.loc[index,'Sex']=='female':\n        test.loc[index,'Age']=np.ceil(test.groupby(['Pclass','Sex'])['Age'].mean()[2][0])\n    elif test.loc[index,'Pclass']==2 and test.loc[index,'Sex']=='male':\n        test.loc[index,'Age']=np.ceil(test.groupby(['Pclass','Sex'])['Age'].mean()[2][1])\n    elif test.loc[index,'Pclass']==3 and test.loc[index,'Sex']=='female':\n        test.loc[index,'Age']=np.ceil(test.groupby(['Pclass','Sex'])['Age'].mean()[3][0])\n    else:\n        test.loc[index,'Age']=np.ceil(test.groupby(['Pclass','Sex'])['Age'].mean()[3][1])","55981423":"# Check if the above operations worked correctly\ntrain.isnull().sum().max(),test.isnull().sum().max()","cb2c9514":"base_color=sb.color_palette()[0]","2cd54055":"# Bivariate plot of Survived vs. Age\nsb.distplot(train[train['Survived']==1]['Age'],label='Survived');\nsb.distplot(train[train['Survived']==0]['Age'],label='Not Survived');\nplt.legend();\nplt.title('Survived vs. Age');","c0181d38":"# Multi-variate plot of Survived vs Age by Gender\nsb.pointplot(data=train,x='Survived',y='Age',hue='Sex',linestyles=\"\",dodge=0.3);\nxticks=[0,1]\nxlabel=['No','Yes']\nplt.xticks(xticks,xlabel);\nplt.title('Survived vs Age by Gender');","24e64ec4":"# Multi-variate plot of Survived vs Age by Class\nsb.pointplot(data=train,x='Survived',y='Age',hue='Pclass',linestyles=\"\",dodge=0.3,palette='viridis_r');\nxticks=[0,1]\nxlabel=['No','Yes']\nplt.xticks(xticks,xlabel);\nplt.title('Survived vs Age by Class');","5bfbfcf8":"'''\nsingle=[train,test]\n# Map columns to numerical values\nfor data in single:\n    data['Sex']=data['Sex'].map({'female':1,'male':0}).astype(int)\n    data['Embarked']=data['Embarked'].map({'S':1,'C':2,'Q':3}).astype(int)\n'''","d6502163":"# Merge the two datasets\nntrain = train.shape[0]\nntest = test.shape[0]\nall_data = pd.concat((train, test))","3102598c":"# Get dummy variables\nall_data=pd.get_dummies(all_data)","b6685f0a":"# Seperate the combined dataset into test and train data\ntest=all_data[all_data['Survived'].isnull()]\ntrain=all_data[all_data['PassengerId'].isnull()]","738086ea":"# Check if the new and old sizes are equal\nassert train.shape[0]==ntrain\nassert test.shape[0]==ntest","60fc7590":"# Drop extra columns\ntest.drop(columns='Survived',inplace=True)\ntrain.drop(columns='PassengerId',inplace=True)\ntest['PassengerId']=test['PassengerId'].astype(int)","924c09f5":"# Divide the data into test and train\nX_train=train.drop('Survived',axis=1)\nY_train=train['Survived']\nX_test=test.drop('PassengerId',axis=1)","0389a5c7":"'''\n# Fit the model using Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest\n'''","1b79e327":"# Fit the model using XGBClassifier\nxgb = xgboost.XGBClassifier(learning_rate= 0.01, max_depth= 4, n_estimators= 300, seed= 0)\nxgb.fit(X_train,Y_train)\nY_pred = xgb.predict(X_test)","2b2b37ba":"final_df = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","cc317cc9":"final_df['Survived']=final_df['Survived'].astype(int)","84dff98d":"# Save the dataframe to a csv file\nfinal_df.to_csv('submission.csv',index=False)","a0d05966":"For filling the missing values of the age dataset lets get the mean of each class furthur divided by sex. Then we will fill these mean values in the coressponding class and sex.","9e0fdc0b":"Since Embarked ghas only two values missing we can fill it with the most common value","e6ed122a":"## Model and Predict","23b643ba":"From the above plot we can see that mostly middle aged women and men survived. The large error bars mean that the number of data for that point is less. Hence more females survived than men. ","ceecc0b8":"## **Titanic Dataset solution**\n\n**Question-Problem Statement**\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this solution we will predict whether a person survives or not based on various factors like social class, gender and age.","b25a8d06":"## **Data Wrangling**\nFirst we will deal with missing and incorrect data.\nFirst lets drop the columns we will not be needing from both datasets.\nAfter analysis we can see that Age has missing data in both train and test data.\nIn tain dataset Embarked has some missing values.\n","104a835c":"## **Visualizations**"}}