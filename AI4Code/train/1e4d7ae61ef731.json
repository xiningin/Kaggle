{"cell_type":{"b0e47b50":"code","b05d9c6a":"code","b6b5ee6c":"code","e1693231":"code","cee01314":"code","332a14f5":"code","8a8915d2":"code","b143b35c":"code","445a3115":"code","47d93b58":"code","75fe3b30":"code","a6efce6c":"code","fd5edd49":"code","22ea8502":"code","c07ff3ab":"code","33d5b729":"code","9f381039":"code","0e84a252":"code","b7bcc8c0":"code","564fb212":"code","2d331679":"code","588c6dcd":"code","1ae68839":"code","247c261c":"markdown","0a431170":"markdown","11806de1":"markdown","2587f1df":"markdown","6a82c32f":"markdown","c0a5a66d":"markdown","0c1a2809":"markdown","394ebb7e":"markdown","bf3cbfa2":"markdown","b5a681bb":"markdown","3d4f688a":"markdown","c940cc00":"markdown","05df7c6e":"markdown","d9358143":"markdown","0a4005fc":"markdown","ea96d982":"markdown"},"source":{"b0e47b50":"import tensorflow as tf\nimport numpy as np\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow.random import set_seed\nset_seed(2)\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport time\nimport PIL\nimport glob\nimport random\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport skimage\nfrom skimage import io\nimport cv2\nimport shutil","b05d9c6a":"base_path = '..\/input\/foodydudy\/kaggle\/train'\nclasses = os.listdir(base_path)\nfilepaths = []\nlabels = []\nfor c in classes:\n    flist = os.listdir(base_path + '\/' + c)\n    for f in flist:\n        fpath = os.path.join(base_path, c, f)\n        filepaths.append(fpath)\n        labels.append(c)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","b6b5ee6c":"Fseries=pd.Series(filepaths, name='file_paths')\nLseries=pd.Series(labels, name='labels')\ntrain_df=pd.concat([Fseries,Lseries], axis=1)\ntrain_df=pd.DataFrame(train_df, columns = ['file_paths', 'labels'])\nprint(train_df['labels'].value_counts())","e1693231":"base_path = '..\/input\/foodydudy\/kaggle\/valid'\nclasses = os.listdir(base_path)\nfilepaths = []\nlabels = []\nfor c in classes:\n    flist = os.listdir(base_path + '\/' + c)\n    for f in flist:\n        fpath = os.path.join(base_path, c, f)\n        filepaths.append(fpath)\n        labels.append(c)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","cee01314":"Fseries=pd.Series(filepaths, name='file_paths')\nLseries=pd.Series(labels, name='labels')\nvalid_df=pd.concat([Fseries,Lseries], axis=1)\nvalid_df=pd.DataFrame(valid_df, columns = ['file_paths', 'labels'])\nprint(valid_df['labels'].value_counts())","332a14f5":"base_path = '..\/input\/foodydudy\/kaggle\/test'\nclasses = os.listdir(base_path)\nfilepaths = []\nlabels = []\nfor c in classes:\n    flist = os.listdir(base_path + '\/' + c)\n    for f in flist:\n        fpath = os.path.join(base_path, c, f)\n        filepaths.append(fpath)\n        labels.append(c)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","8a8915d2":"Fseries=pd.Series(filepaths, name='file_paths')\nLseries=pd.Series(labels, name='labels')\ntest_df=pd.concat([Fseries,Lseries], axis=1)\ntest_df=pd.DataFrame(test_df, columns = ['file_paths', 'labels'])\nprint(test_df['labels'].value_counts())","b143b35c":"img = plt.imread('..\/input\/foodydudy\/kaggle\/train\/00\/0003.jpg')\nimg.shape","445a3115":"plt.figure(figsize=(14,10))\nfor i in range(20):\n    random = np.random.randint(1,len(train_df))\n    plt.subplot(4,5,i+1)\n    img = train_df.loc[random,\"file_paths\"]\n    plt.imshow(plt.imread(img))\n    plt.title(train_df.loc[random, \"labels\"], size = 10, color = \"black\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","47d93b58":"target_size=(224,224)\nbatch_size=64","75fe3b30":"train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input, zoom_range=0.2, horizontal_flip=True)\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntrain_gen = train_datagen.flow_from_dataframe(train_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='categorical')\nvalid_gen = test_datagen.flow_from_dataframe(valid_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='categorical')\ntest_gen = test_datagen.flow_from_dataframe(test_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='categorical')","a6efce6c":"base_model = tf.keras.applications.EfficientNetB0(include_top=False, input_shape=(224,224,3), weights='imagenet')\nmodel = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(48, activation='softmax')\n])","fd5edd49":"lr=0.001\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])","22ea8502":"patience = 2\nstop_patience = 5\nfactor = 0.5\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"classify_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1, restore_best_weights=True),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)\n]","c07ff3ab":"epochs = 30\nhistory = model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=callbacks, verbose=1)","33d5b729":"plt.plot(history.history['loss'], label='Loss (training data)')\nplt.plot(history.history['val_loss'], label='Loss (validation data)')\nplt.title('Loss for Training')\nplt.ylabel('Loss')\nplt.xlabel('No. epoch')\nplt.legend(['train', 'validation'], loc=\"upper left\")\nplt.show()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","9f381039":"best_model = model\nbest_model.load_weights('.\/classify_model.h5')\nbest_model.evaluate(test_gen)","0e84a252":"labels_dict = test_gen.class_indices\nkey_list = list(labels_dict.keys())\nval_list = list(labels_dict.values())","b7bcc8c0":"def predict_image(img_url):\n    img=io.imread(img_url)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    resized_img = cv2.resize(img, (224, 224))\n    img_tensor = tf.convert_to_tensor(resized_img, dtype=tf.float32)\n    img_tensor = tf.expand_dims(img_tensor, 0)\n    prediction = best_model.predict(img_tensor, use_multiprocessing=True)\n    prediction = prediction.argmax()\n    position = val_list.index(prediction)\n    label = key_list[position]\n    plt.figure(figsize=(14,10)) \n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.title(label, size = 10, color = \"black\")\n    plt.xticks([])\n    plt.yticks([])\n    plt.show","564fb212":"predict_image('https:\/\/www.thespruceeats.com\/thmb\/m7lyKJKk2x7ezOnDM_oHncbP1xg=\/1776x1332\/smart\/filters:no_upscale()\/thai-green-curry-recipe-p3-3217442-hero-1-a3fcdfbc551849718c7750fa63ec8c6a.jpg')","2d331679":"predict_image('https:\/\/3.bp.blogspot.com\/_Liz-VpvKDvo\/TLusgS1s_QI\/AAAAAAAAFDA\/NqurYE8r5wI\/s1600\/khaijiao+cover.jpg')","588c6dcd":"predict_image('https:\/\/www.thespruceeats.com\/thmb\/Agleg-0qGlXWpgnHEGQUmVJoSlg=\/4160x3120\/smart\/filters:no_upscale()\/som-tam-thai-green-papaya-salad-3217407-hero-01-9e4281d9e4a64b0e8bb4930debcef3a3.jpg')","1ae68839":"predict_image('https:\/\/c8.alamy.com\/comp\/S0X6JP\/grilled-giant-river-prawn-S0X6JP.jpg')","247c261c":"Predicted chicken green curry as desired.","0a431170":"# **Predictions on Random Google Images**","11806de1":"Thanks for reading this notebook! Make sure to leave an upvote if this helped you out \ud83d\ude00 .","2587f1df":"# **Visualize Images**","6a82c32f":"Predicted fried fish-paste balls instead of omelet.","c0a5a66d":"# **Create Dataframes from Images**","0c1a2809":"Predicted mango sticky rice instead of grilled river prawn.","394ebb7e":"# **EfficientNetB0-based model**","bf3cbfa2":"# **Callbacks**","b5a681bb":"# **Import Libraries**","3d4f688a":"# **Training**","c940cc00":"# **ImageDataGenerator**","05df7c6e":"Looks like we can perform some zooming and horizontal flips with ImageDataGenerator.","d9358143":"Predicted stir-fried chinese morning glory instead of green papaya salad.","0a4005fc":"Balanced dataset so no need to augment or remove images. ","ea96d982":"# **Predictions on Test Set**"}}