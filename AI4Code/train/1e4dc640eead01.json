{"cell_type":{"1d5dd31e":"code","6448e687":"code","6c42b1a0":"code","03123c7f":"code","65f75d62":"code","b78e22ba":"code","2de86506":"code","6e913df6":"code","5fbcb0e4":"code","53af7d73":"code","bdcf33bd":"code","498e1b1a":"code","1b8e2715":"code","7483e7f7":"code","9e90893c":"code","159453b6":"code","745c5dcd":"code","6248604e":"code","53d14610":"code","d8eadc9c":"code","bed530c6":"code","7cff6051":"code","d0b75ef7":"code","d59a51ae":"code","35f7044e":"code","af0cca6a":"code","f5cb1954":"code","04ee8e0e":"code","56b98c2a":"code","194b429f":"code","c4049849":"code","ac64a5a1":"code","f5efc6fa":"code","9967019e":"code","d3fd2a32":"code","42ead5cb":"code","7e5bcf49":"code","176a3d62":"code","53d57ee1":"code","dc5a58f7":"code","ea584881":"code","a2e02bd9":"code","225f59c3":"code","ca5a333f":"code","f77a9bff":"code","360d4448":"code","31a6f166":"code","148a9015":"markdown","1ee4181c":"markdown","bcaa22b6":"markdown","7a5678e8":"markdown","068c1012":"markdown","8c62b6c0":"markdown","b1375b91":"markdown","92ba771e":"markdown","87fca385":"markdown","5f4bf838":"markdown","e95e8622":"markdown","1b2e4939":"markdown","dfb511ed":"markdown","c9f14549":"markdown","ab1fa038":"markdown","a865da16":"markdown","9bc90309":"markdown","1349ee76":"markdown","b3375a02":"markdown","3a89698f":"markdown","f509b135":"markdown","a7d4456f":"markdown","057200d4":"markdown"},"source":{"1d5dd31e":"!nvidia-smi","6448e687":"# \u041e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u0438\u0435 tensorflow\n# !pip install tensorflow --upgrade\n# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 efficientnet\n!pip install -q efficientnet\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043e\u0431\u0432\u044f\u0437\u043a\u0443 \u043f\u043e\u0434 keras \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, albuminations\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor update tensorflow","6c42b1a0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\n# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint,EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\n\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, EfficientNetB5, EfficientNetB3\nfrom tensorflow.keras.layers import *\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n                                   \n# import efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline","03123c7f":"print('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","65f75d62":"print(os.listdir(\"..\/input\/sf-dl-car-classification\"))","b78e22ba":"!pip freeze > requirements.txt","2de86506":"# \u0412 setup \u0432\u044b\u043d\u043e\u0441\u0438\u043c \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438: \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0435 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c.\n\nEPOCHS               = 8 # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 8 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 15%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nH_IMG_SIZE           = 420 # \u0413\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0440\u0438\u0441\u0443\u043d\u043a\u0430\nV_IMG_SIZE           = 320  # \u0412\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u0431\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0440\u0438\u0441\u0443\u043d\u043a\u0430\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (V_IMG_SIZE, H_IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/sf-dl-car-classification\/'\nPATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f","6e913df6":"# \u0423\u0441\u0442\u0430\u043d\u0430\u043b\u0438\u0432\u0430\u0435\u043c \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 random seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\nos.makedirs(PATH,exist_ok=True)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","5fbcb0e4":"class_names = [\n  '\u041f\u0440\u0438\u043e\u0440\u0430', #0\n  'Ford Focus', #1\n  '\u0421\u0430\u043c\u0430\u0440\u0430', #2\n  '\u0412\u0410\u0417-2110', #3\n  '\u0416\u0438\u0433\u0443\u043b\u0438', #4\n  '\u041d\u0438\u0432\u0430', #5\n  '\u041a\u0430\u043b\u0438\u043d\u0430', #6\n  '\u0412\u0410\u0417-2109', #7\n  'Volkswagen Passat', #8\n  '\u0412\u0410\u0417-21099' #9\n]","53af7d73":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"..\/input\/sf-dl-car-classification\/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","bdcf33bd":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")","498e1b1a":"train_df.head()","1b8e2715":"train_df.info()","7483e7f7":"train_df.Category.value_counts()\n# \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0435 - \u044d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e","9e90893c":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index])+'  '+class_names[random_image_cat[index]])\n    plt.axis('off')\nplt.show()","159453b6":"image = PIL.Image.open(PATH+'\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","745c5dcd":"# \u0414\u043b\u044f \u0432\u044b\u0432\u043e\u0434\u0430 \u043a\u0440\u0438\u0432\u044b\u0445 training_acc \u0438 vol_accuracy,  training_loss \u0438 vol_loss\ndef learning_graphic(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n \n    epochs = range(len(acc))\n \n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n \n    plt.figure()\n \n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    \n    return plt\n# learning_graphic(history).show()","6248604e":"import albumentations as a\nfrom ImageDataAugmentor.image_data_augmentor import *","53d14610":"augmentations = a.Compose([\n# \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0440\u0430\u0437\u043c\u044b\u0442\u0438\u0435 \u043f\u043e \u0413\u0430\u0443\u0441\u0441\u0443 \u0438 \u0448\u0443\u043c \u0441 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c\u044e 50%\n      a.Blur(p=0.05), \n      a.GaussNoise(p=0.05),\n    #  \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u0441\u0434\u0432\u0438\u0433\u0430, \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u043f\u043e\u0432\u043e\u0440\u043e\u0442\u0430, \u0442.\u043a. \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \u0438\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043d\u0438\u0437\u043a\u0438\u0435. \n    a.ShiftScaleRotate(shift_limit=0.0625, \n                       scale_limit=0.01, \n                       interpolation=1, \n                       border_mode=4, \n                       rotate_limit=20, \n                       p=.75), \n\n    a.RandomBrightness(limit=0.2, p=0.5),\n    \n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0435\u0449\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e \n# \u043c\u043e\u0434\u0435\u043b\u044c \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u044f \u043c\u043e\u0436\u0435\u0442 \u043e\u0442\u043b\u0438\u0447\u0430\u0442\u044c\u0441\u044f \u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0437\u0435\u0440\u043a\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f,\n# \u043c\u044b \u043c\u043e\u0436\u0435\u043c \u0432\u043a\u043b\u044e\u0447\u0438\u0442\u044c  NO VERTICAL FLIP,  \u0442.\u043a. \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0438 \u0432\u0441\u0435\u0433\u0434\u0430 \u043d\u0430\u0445\u043e\u0434\u044f\u0442\u0441\u044f \u0432 \u0433\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u044c\u043d\u043e\u043c \u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u0438\n    \n    a.HorizontalFlip(),\n    a.HueSaturationValue(), # \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u043e\u0442\u0442\u0435\u043d\u043e\u043a \u0438 \u043d\u0430\u0441\u044b\u0449\u0435\u043d\u043d\u043e\u0441\u0442\u044c\n    a.RGBShift(),\n    a.FancyPCA(alpha=0.1,  always_apply=False,  p=0.5),\n    a.Resize(V_IMG_SIZE, H_IMG_SIZE),\n    \n#  \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c OneOfs \u0441 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c\u044e \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e 50% \u0434\u043b\u044f \u044f\u0440\u043a\u043e\u0441\u0442\u043d\u043e\u0433\u043e \u043a\u043e\u043d\u0442\u0440\u0430\u0441\u0442\u0430\n    a.OneOf([\n        a.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        a.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)],\n        p=0.5)\n ])","d8eadc9c":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445:\ndatagen = ImageDataAugmentor(\n                        rescale=1.\/255,\n                        augment=augmentations, \n                        seed=RANDOM_SEED,\n                        validation_split=VAL_SPLIT)\n\n# \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445:\n\ntrain_datagen = datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0439\n    target_size=(V_IMG_SIZE, H_IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='training') # \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\n\ntest_datagen = datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(V_IMG_SIZE, H_IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    subset='validation') # \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445  Test Time Augmentation (TTA)\ntest_gen = ImageDataAugmentor(rescale=1.\/255) # rescale=1.\/255 \ntest_sub_generator = test_gen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=PATH+'test_upload\/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(V_IMG_SIZE, H_IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","bed530c6":"x,y = train_datagen.next()\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438\u0437 train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,8):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    plt.title('Class: '+str(y[i]))\n    plt.axis('off')\nplt.show()","7cff6051":"x,y = test_datagen.next()\nprint('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438\u0437 test_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    plt.title('Class: '+str(y[i]))\n    plt.axis('off')\nplt.show()","d0b75ef7":"base_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape=input_shape)\nbase_model.trainable = True","d59a51ae":"# Set new head\nmodel = Sequential()\nmodel.add(base_model)\n\n# Add pooling layer\nmodel.add(GlobalAveragePooling2D())\n\n# Add a fully-connected layer\nmodel.add(Dense(256, \n                      activation='relu', \n                      bias_regularizer=l2(1e-4),\n                      activity_regularizer=l2(1e-5)))\n\n# Add batch normalization\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25)) # and dropout\n# model.add(BatchNormalization())\n# model.add(Dropout(0.25))\n\n# And a final layer for 10 classes\nmodel.add(Dense(CLASS_NUM, activation='softmax'))\n\n# This is the model we will train\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), metrics=[\"accuracy\"])","35f7044e":"len(model.trainable_variables)","af0cca6a":"# Add \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044c\u043d\u043e\u0439 \u0442\u043e\u0447\u043a\u0438, \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c\ncheckpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor = ['val_accuracy'], \n                             verbose = 1,\n                             mode = 'max')\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c lr_scheduler (\u044d\u043a\u0441\u043f\u043e\u043d\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0442\u044c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0447\u0435\u0440\u0435\u0437 2 \u044d\u043f\u043e\u0445\u0438)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2, # \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043c lr \u0432 5 \u0440\u0430\u0437\n                              patience=3, # \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u0447\u0435\u0440\u0435\u0437 2 \u044d\u043f\u043e\u0445\u0438 - \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c lr\n\n                              min_lr=0.0000001,\n                              verbose=1,\n                              mode='auto')\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0440\u0430\u043d\u043d\u044e\u044e \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0443\nearlystop = EarlyStopping(monitor = 'val_accuracy',\n                          patience = 4,\n                          restore_best_weights = True)\n\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","f5cb1954":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = len(train_datagen),\n        validation_data = test_datagen, \n        validation_steps = len(test_datagen),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","04ee8e0e":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u0441\u0435\u0442\u044c \u0438 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044e \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (best_model)\n# model.save('..\/working\/model_step_1.hdf5')\nmodel.load_weights('best_model.hdf5')","56b98c2a":"scores = model.evaluate_generator(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","194b429f":"learning_graphic(history).show()","c4049849":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","ac64a5a1":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_step_1.csv', index=False)\nprint('Save submit')\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d Test Time Augmentation (TTA)\n# https:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","f5efc6fa":"submission.head()","9967019e":"EPOCHS               = 9   # \u044d\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u043c \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 2    # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-5\nVAL_SPLIT            = 0.15 # \nH_IMG_SIZE           = 512  # \u0413\u043e\u0440\u0438\u0437\u043e\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0440\u0438\u0441\u0443\u043d\u043a\u0430\nV_IMG_SIZE           = 512  # \u0412\u0435\u0440\u0442\u0438\u043a\u0430\u043b\u0431\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0440\u0438\u0441\u0443\u043d\u043a\u0430\nIMG_CHANNELS         = 3\ninput_shape          = (V_IMG_SIZE, H_IMG_SIZE, IMG_CHANNELS)","d3fd2a32":"# \u0414\u0432\u0443\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\u0430\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 (\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u043b\u0438 \u0442\u0430\u043a \u043d\u0430\u0437\u0432\u0430\u0442\u044c?)\naugmentations = a.Compose([\n     a.ShiftScaleRotate(shift_limit=0.0625, \n                       scale_limit=0.01, \n                       interpolation=1, \n                       border_mode=4, \n                       rotate_limit=20, \n                       p=.75),\n    a.HorizontalFlip(p=0.5)\n])","42ead5cb":" # \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445:\ndatagen = ImageDataAugmentor(                       \n                        # rescale=1.\/255,\n                        augment=augmentations, \n                        seed=RANDOM_SEED,\n                        validation_split=VAL_SPLIT)\n\n# \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445:\n\ntrain_datagen = datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0439\n    target_size=(V_IMG_SIZE, H_IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='training') # \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435\n\ntest_datagen = datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(V_IMG_SIZE, H_IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    subset='validation') # \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438\n\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445  Test Time Augmentation (TTA) (datagen(augmentations))\ntest_sub_generator = datagen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=PATH+'test_upload\/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(V_IMG_SIZE, H_IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","7e5bcf49":"# Set new head\nmodel = Sequential()\nmodel.add(base_model)\n\n# Add pooling layer\nmodel.add(GlobalAveragePooling2D())\n\n# Add a fully-connected layer\nmodel.add(Dense(256, \n                      activation='relu', \n                      bias_regularizer=l2(1e-4),\n                      activity_regularizer=l2(1e-5)))\n\n# Add batch normalization\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25)) # and dropout\n# model.add(BatchNormalization())\n# model.add(Dropout(0.25))\n\n# And a final layer for 10 classes\nmodel.add(Dense(CLASS_NUM, activation='softmax'))\n\n# This is the model we will train\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=LR), \n              metrics=[\"accuracy\"])","176a3d62":"model.load_weights('best_model.hdf5')","53d57ee1":"# Add \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044c\u043d\u043e\u0439 \u0442\u043e\u0447\u043a\u0438, \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c\ncheckpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor = ['val_accuracy'], \n                             verbose = 1,\n                             mode = 'max')\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c lr_scheduler (\u044d\u043a\u0441\u043f\u043e\u043d\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0442\u044c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0447\u0435\u0440\u0435\u0437 3 \u044d\u043f\u043e\u0445\u0438)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2, # \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u043c lr \u0432 5 \u0440\u0430\u0437\n                              patience=3, # \u0435\u0441\u043b\u0438 \u043d\u0435\u0442 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u0447\u0435\u0440\u0435\u0437 2 \u044d\u043f\u043e\u0445\u0438 - \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c lr\n\n                              min_lr=0.0000001,\n                              verbose=1,\n                              mode='auto')\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c \u0440\u0430\u043d\u043d\u044e\u044e \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0443\nearlystop = EarlyStopping(monitor = 'val_accuracy',\n                          patience = 4,\n                          restore_best_weights = True)\n\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","dc5a58f7":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = len(train_datagen),\n        validation_data = test_datagen, \n        validation_steps = len(test_datagen),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","ea584881":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u0441\u0435\u0442\u044c \u0438 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044e \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (best_model)\nmodel.save('..\/working\/model_last_Effi.hdf5')\nmodel.load_weights('best_model.hdf5')","a2e02bd9":"scores = model.evaluate_generator(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","225f59c3":"learning_graphic(history).show()","ca5a333f":"test_sub_generator.samples","f77a9bff":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","360d4448":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_Effi.csv', index=False)\nprint('Save submit')\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c Test Time Augmentation (TTA)\n# https:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","31a6f166":"submission.head()","148a9015":"### \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","1ee4181c":"### \u041a\u043e\u043d\u0435\u0446 Step 1","bcaa22b6":"predictions = 0.6*model_1.predict(sub_generator) \\\n    + 0.25*model_2.predict(sub_generator) \\\n    + 0.15*model_3.predict(sub_generator)\npredictions = predictions.argmax(axis=1)\npredictions","7a5678e8":"### \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","068c1012":"### \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445: Step 1","8c62b6c0":"from skimage import io \ndef imshow(image_RGB): \n    io.imshow(image_RGB) \n    io.show()","b1375b91":"### \u0414\u043b\u044f \u0432\u044b\u0432\u043e\u0434\u0430 \u043a\u0440\u0438\u0432\u044b\u0445 training_acc \u0438 vol_accuracy,  training_loss \u0438 vol_loss","92ba771e":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445:  Step 2","87fca385":"# \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438","5f4bf838":"from keras.models import load_model\nmodel = load_model('model.h5')","e95e8622":"## \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e Albumentations ","1b2e4939":"## Step 2","dfb511ed":"## \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0445 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432\n\u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442 \u043f\u0440\u043e\u0432\u043e\u0434\u0438\u043b\u0441\u044f \u043d\u0430 \u0434\u0432\u0443\u0445 \u043c\u043e\u0434\u0435\u043b\u044f\u0445: \u0444\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u0438 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439.\n\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438  \u043f\u0440\u0438 (transfer learning) \u0431\u0435\u0437 \u0438 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0434\u0430\u043b\u0438 \u043d\u0435 \u0445\u043e\u0440\u043e\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b.\n\u0421 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u0430 image_shape \u0443\u043b\u0443\u0447\u0438\u043b\u0438\u0441\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0430.\n\n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u044b transfer learning \u0441 fine-tuning, \u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432\u043a\u043b\u044e\u0447\u0435\u043d Batch Normalization \u0441\u043b\u043e\u0439, \u043f\u0440\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 image_shape. \u041f\u0440\u0438\u043c\u0435\u043d\u0438\u043b\u0438 \u0440\u0430\u0437\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback Keras.\n\n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u044b \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 Albumentations \u0434\u043b\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 TTA (Test Time Augmentation).  \n\n\u0412 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0432\u043e\u0434\u0438\u043b\u043e\u0441\u044c \u0432 5 \u044d\u043f\u043e\u0445, \u0437\u0430 \u0438\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435\u043c  \u043e\u0434\u043d\u043e\u0433\u043e \u0441\u043b\u0443\u0447\u0430\u044f \u0434\u043b\u044f Xception (12 \u044d\u043f\u043e\u0445).\n\u041f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c Xception \u0434\u043b\u044f \u0424\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u041c\u043e\u0434\u0435\u043b\u0438 \u0431\u0435\u0437 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439.\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b:\n* \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 \u043e\u043a\u043e\u043b\u043e 39% \u043f\u0440\u0438 image_shape = (90,120);\n* \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 \u043e\u043a\u043e\u043b\u043e 50% \u043f\u0440\u0438 image_shape = (150,150);\n* \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 \u043e\u043a\u043e\u043b\u043e 60% \u043f\u0440\u0438 image_shape = (224,224):\n* \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 \u043e\u043a\u043e\u043b\u043e 70% \u043f\u0440\u0438 image_shape = (320,320);\n\n\u041f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c Xception \u0434\u043b\u044f \u0424\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u041c\u043e\u0434\u0435\u043b\u0438 \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439:\n* \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 \u043e\u043a\u043e\u043b\u043e 94,76% \u043f\u0440\u0438 image_shape = (224,224);\n* \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043c\u043e\u0434\u0435\u043b\u0438  \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 95,88%  \u043f\u0440\u0438 image_shape = (320,320) \u0437\u0430 12 \u044d\u043f\u043e\u0445.\n\n\u041f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c EfficientNetB0 \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c  \u0424\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u041c\u043e\u0434\u0435\u043b\u0438 25.59% \u043f\u0440\u0438 image_shape = (320,320)\n\n\u041f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c EfficientNetB3 \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 11.94% \u043f\u0440\u0438 image_shape = (320,320). \u0411\u043e\u043b\u044c\u0448\u0430\u044f \u0430\u043c\u043f\u043b\u0438\u0442\u0443\u0434\u0430 \u0437\u0438\u0433-\u0437\u0430\u0433\u0430 Accuracy \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u044d\u043f\u043e\u0445\u0438.\n\n\u041f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c EfficientNetB5 \u0434\u043b\u044f \u0424\u0443\u043d\u043a\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0439 \u041c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u0438 image_shape = (320,320) \u0437\u0430 5 \u044d\u043f\u043e\u0445:\n* \u0431\u0435\u0437 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 92.92%.\n* \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 94,89%. \u041f\u043e\u0447\u0435\u043c\u0443-\u0442\u043e Accuracy \u0437\u0438\u0433-\u0437\u0430\u0433 \u043f\u043e \u044d\u043f\u043e\u0445\u0430\u043c, \u043d\u0435 \u043f\u043e\u043d\u044f\u0442\u043d\u043e?!\n    \n\n#### \u041f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043d\u044b\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u0438, \u0447\u0442\u043e \u0438\u0437 \u0432\u0441\u0435\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0431\u043e\u043b\u0435\u0435 \u043f\u0435\u0440\u0441\u043f\u0435\u043a\u0442\u0438\u0432\u043d\u044b\u043c\u0438 \u043e\u043a\u0430\u0437\u0430\u043b\u0438\u0441\u044c \u0434\u0432\u0435 \u0431\u0430\u0437\u043e\u0432\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438: EfficientNetB5 \u0438 Xception \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439.\n\n\u041f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0437\u0430 5 \u044d\u043f\u043e\u0445:\n*  \u0441 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e EfficientNetB5 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0434\u043e\u0441\u0442\u0438\u0433\u043b\u0438  94.93%. \u041d\u0430\u0431\u043b\u044e\u0434\u0430\u0435\u0442\u0441\u044f \u043d\u0435 \u0443\u0441\u0442\u043e\u0439\u0447\u0447\u0438\u0432\u043e\u0441\u0442\u044c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f.\n*  \u0441 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e Xception \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0434\u043e\u0441\u0442\u0438\u0433\u043b\u0438 93.09%.\n\n\u041f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0437\u0430 9 \u044d\u043f\u043e\u0445 \u0441 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e Xception:\n* \u0441 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e Xception \u043f\u0440\u0438 image_shape = (320,320): Accuracy: 96.69%.\n\n\u041f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439 \u0437\u0430 9 \u044d\u043f\u043e\u0445 \u0441 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e EfficientNetB5:\n* \u043f\u0440\u0438 image_shape = (320,320): Accuracy: 96.87%; 96.57%;\n* \u043f\u0440\u0438 image_shape = (240,240): Accuracy:  95.84%.\n\n\n\n#### \u0414\u043b\u044f \u043e\u043a\u043e\u043d\u0447\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u0447\u0435\u0442\u0430 \u0432\u044b\u0431\u0440\u0430\u043d\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0441 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e EfficientNetB5 \u0441 \u0442\u043e\u043d\u043a\u043e\u0439 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u043e\u0439.\n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0430 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u044f \u0441 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435\u043c image_shape \u0438 \u044d\u043f\u043e\u0445:\n* \u0432 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u0441\u043b\u043e\u0439 Batch Normalization;\n* \u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0438\u0437\u043c\u0435\u043d\u0438\u043b\u0438: \n     image_shape = (320,320); \n     image_shape = (320,420); \n     image_shape = (512,512);\n* \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 LR, optimizer, loss;\n* \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback:  *\u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0438 lr_scheduler (\u044d\u043a\u0441\u043f\u043e\u043d\u0435\u043d\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0442\u044c \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0447\u0435\u0440\u0435\u0437 2 \u044d\u043f\u043e\u0445\u0438);  *\u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0438 \u0440\u0430\u043d\u043d\u044e\u044e \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0443; *\u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044c\u043d\u043e\u0439 \u0442\u043e\u0447\u043a\u0438, \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0442\u044c \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c;\n* \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e Albumentations (\u0434\u0432\u0430 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430)\n* \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u043e TTA (Test Time Augmentation) \u0434\u043b\u044f \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0430.\n\n\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0438\u0437\u0432\u0435\u0434\u0435\u043d\u043e \u0432 \u0434\u0432\u0443\u0445 \u0448\u0430\u0433\u0430\u0445 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c:\n* \u043e\u0431\u0443\u0447\u0430\u0435\u043c  \u0441 image_shape = (320,420) \u0438 \u0441 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0435\u0439 \u0448\u0438\u0440\u043e\u043a\u0438\u043c \u043d\u0430\u0431\u043e\u0440\u043e\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432; \n* \u0432\u044b\u0431\u0435\u0440\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438, \u0442.\u0435. best_model.hdf5 ;\n* \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u043c \u0448\u0430\u0433\u043e\u043c \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043c \u0432 \u043c\u043e\u0434\u0435\u043b\u044c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043b\u0443\u0447\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0433\u043e \u0448\u0430\u0433\u0430 \u0438 \u043e\u0431\u0443\u0447\u0430\u0435\u043c  \u043c\u043e\u0434\u0435\u043b\u0438 \u0441 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435\u043c \u0434\u043e image_shape = (512,512) \u0441 \u0432\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435\u043c  \u0434\u0432\u0443\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432\u043e\u0439 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0435\u0439 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.","c9f14549":"## \u0418\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e, \u043a \u043a\u0430\u043a\u043e\u043c\u0443 \u043a\u043b\u0430\u0441\u0441\u0443 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0442\u043d\u0435\u0441\u0435\u0442 \u0432\u043e\u0442 \u044d\u0442\u0438 \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0438?","ab1fa038":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438 \u0438\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u0438\u043c\u0430\u0442\u044c \u043a\u0430\u043a \u0438\u0445 \u043b\u0443\u0447\u0448\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0438 \u0441\u0436\u0438\u043c\u0430\u0442\u044c.","a865da16":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","9bc90309":"Clean PATH\nimport shutil\nshutil.rmtree(PATH)","1349ee76":"### \u041a\u043e\u043d\u0435\u0446 Step 2 ","b3375a02":"## \u041a\u043e\u043d\u0435\u0446 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445","3a89698f":"## Step 1","f509b135":"### \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 train_generator, test_generator","a7d4456f":"\u0421\u043e\u0432\u0435\u0442\u044b:\n* \u041f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u0435 transfer learning \u0441 fine-tuning\n* \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u0442\u0435 LR, optimizer, loss\n* \u041f\u043e\u0434\u0431\u0435\u0440\u0438\u0442\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 (\u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438, \u0431\u0430\u0442\u0447 \u0438 \u0442.\u0434.)\n* \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0435\u0442\u0435\u0439 (\u0430 \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e Xception) \u0438\u043b\u0438 \u0438\u0445 \u0430\u043d\u0441\u0430\u043c\u0431\u043b\u0438. \u041f\u0440\u0438\u043c\u0435\u0440\u044b SOTA \u043d\u0430 ImageNet\n* \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 Batch Normalization \u0438 \u043f\u043e\u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0439\u0442\u0435 \u0441 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u043e\u0439 \u201c\u0433\u043e\u043b\u043e\u0432\u044b\u201d\n* \u041f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback Keras https:\/\/keras.io\/callbacks\/\n* \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 TTA (Test Time Augmentation)\n* \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e*: \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate (https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http:\/\/teleported.in\/posts\/cyclic-learning-rate\/ (eng))\n* \u0414\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e*: \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 \u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, Albumentations )\n\n### \u0423\u0434\u0430\u0447\u0438 \u0432 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0438!","057200d4":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445"}}