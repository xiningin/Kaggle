{"cell_type":{"5079fc27":"code","4b3ae262":"code","f0aaec46":"code","20a2f0c1":"code","83aa0384":"code","5f00f635":"code","3cf849bd":"code","90ed78ea":"code","12b674ec":"code","9aba361f":"code","ddc171b9":"code","3907705e":"code","951970fb":"code","66ece62a":"code","037e8bd1":"code","6686606b":"code","98af0ee3":"code","0d20b01d":"code","c6ec5f74":"code","ad9f8a5c":"code","9a12c42b":"code","38e7412b":"code","157c43af":"code","d0c54e4a":"code","79c01933":"code","eff3dd33":"code","47ed5d35":"code","ac657012":"code","a08b9654":"code","8654bb75":"code","42895573":"code","bf55afc5":"code","4976fd91":"code","933eb1aa":"code","2bb61b87":"code","afe2f845":"code","0692df92":"code","3fd90fdf":"code","4dbfe02f":"code","8f47da03":"code","a9cf5751":"code","05358c83":"code","ef63fd79":"code","e1fda53a":"code","9485a585":"code","4af04ae9":"code","d562ab3e":"code","59ee103d":"code","ac5bea71":"code","f1b13aa3":"code","c768368b":"code","8a4c6d85":"code","5211527d":"code","6c4c9f39":"code","dcf44b04":"code","7dc1089d":"code","58ec582c":"code","170d932a":"code","3453f18d":"code","4e07d10e":"code","820c6ead":"code","183f5b64":"code","695fd035":"code","8b3e2abc":"code","154972cc":"code","993d0284":"code","8671a67a":"code","fc5fe5e4":"code","7352b62b":"code","70add62e":"code","ec83d2a0":"code","264dc9d8":"code","da2b3ba4":"code","3a860b9e":"code","006c4765":"code","c6c46487":"code","d65dba46":"code","e7b4b189":"code","0a0bea4b":"code","4513c0b2":"code","c0b11ae4":"code","ab5765db":"code","2b931c38":"code","ff78d75f":"code","c1c134ed":"code","af702671":"code","ed6968ed":"code","68ef6ad6":"code","9f347a6b":"code","b38df47c":"code","c673775c":"code","427c2d69":"code","b043128c":"code","9f63a2fd":"code","6b821557":"code","fb802704":"markdown","d0541e07":"markdown","4fbcf448":"markdown","2948be6c":"markdown","0aac7493":"markdown","0561036f":"markdown","1dac0a77":"markdown","47d21a36":"markdown","b864b7bd":"markdown","7386df08":"markdown","1e0546aa":"markdown","b0747009":"markdown","db8082fa":"markdown","b9983e4c":"markdown","688c449f":"markdown","dec26756":"markdown","2345f33f":"markdown","b8661f39":"markdown","ff01e6e3":"markdown","e78eb572":"markdown","743e34ff":"markdown","460b67df":"markdown","f3c09870":"markdown","d2f2de3c":"markdown","c4f472da":"markdown","f38b58af":"markdown"},"source":{"5079fc27":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4b3ae262":"data = pd.read_csv(\"..\/input\/data.csv\")","f0aaec46":"data.info()","20a2f0c1":"data.shape","83aa0384":"data.head()","5f00f635":"data.tail()","3cf849bd":"def tuple_overall():\n    '''print top 5 players' overall'''\n    oa = tuple(data[:5]['Overall'])\n    return oa\nprint(tuple_overall())","90ed78ea":"name = 'Messi'\ndef player():\n    name = 'Neymar'\n    return name\nprint(name)    # global scope\nprint(player())    # local scope\n","12b674ec":"# what if there is no local scope\nx = 5\ndef f():\n    y = 2*x  # there is no local scope for x\n    return y\nprint(f())\n#First local scopesearched, then global scope searched, \n#if two of them cannot be found lastly built in scope searched.","9aba361f":"# how to learn builtins\nimport builtins\ndir(builtins)","ddc171b9":"def average_age():\n    '''return the average of top 100 players'''\n    def total_age():\n        '''return the total age of top 100 players'''\n        t = sum(data[:100]['Age'])\n        return t\n    return total_age()\/100\nprint(average_age())","3907705e":"DEFAULT AND FLEXIBLE ARGUMENTS","951970fb":"# Default Arguments\ndef f(a, b=1, c=2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we change default arguments\nprint(f(5,10,5))","66ece62a":"# flexible arguments\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint('')\nf(5,6,7,8)\n\n#flexible arguments for dictionary\ndef f(**kwargs):\n    '''print key and value for dictionary'''\n    for key,value in kwargs.items():\n        print(key, ' ', value)\nf(Name = 'Messi', nationality = 'Argentine', overall = 94 )\n        ","037e8bd1":"tot = lambda x,y,z : x + y + z\nprint(tot(5,6,8))","6686606b":"number_list = [3,4,5]\ny = map(lambda x:x**3, number_list)\nprint(list(y))","98af0ee3":"ITERATORS","0d20b01d":"name = \"pele\"\nit = iter(name)\nprint(next(it))    #print next iteration\nprint(*it)    # print remaining iteration\n","c6ec5f74":"ZIP - UNZIP","ad9f8a5c":"list1 = data[0:5]['Name']\nlist2 = data[0:5]['Overall']\nz = zip(list1,list2)\nz_list = list(z)\nprint(z_list)","9a12c42b":"unzip = zip(*z_list)\nunlist1, unlist2 = list(unzip)    # unlist return tuble\nprint(unlist1)\nprint(unlist2)\nprint(type(unlist2))","38e7412b":"# example of list comprehension\np = data[:5]['Potential']\nmiss = [100-i for i in p]\nprint(miss)","157c43af":"# conditionals on iterable\nage1 = data[:10]['Age']\nage2 = ['young' if i<26 else 'middle' if 30>i>26 else 'old' for i in age1]\nprint(age2)","d0c54e4a":"avg = sum(data.Overall)\/len(data.Overall)\ndata['level'] = ['high' if i>avg else 'low' for i in data.Overall]\ndata.loc[0:10,['Overall','level']]","79c01933":"# lets have a look at the frequency of positions of players\nprint(data['Position'].value_counts(dropna=False))    # nan values will be counted","eff3dd33":"# for statistics of the dataframe\ndata.describe()    # ignore null entries","47ed5d35":"# For example: compare potential of players that are with real face or nor\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# no outliers with real face\ndata.boxplot(column='Potential',by = 'Real Face')","ac657012":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","a08b9654":"# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new, id_vars='Name', value_vars=['Nationality','Position'])\nmelted","8654bb75":"melted.pivot(index='Name', columns = 'variable', values = 'value')","42895573":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd. concat([data1,data2], axis=0, ignore_index=True)   #axis=0 adds dataframes in row\nconc_data_row","bf55afc5":"data1 = data['Nationality'].head()\ndata2 = data['Position'].head()\nconc_data_col = pd.concat([data1,data2],axis=1)    # axis = 0 adds dataframes in columns\nconc_data_col","4976fd91":"data.dtypes","933eb1aa":"# lets convert object(str) to categorical and int to float.\ndata['Preferred Foot'] = data['Preferred Foot'].astype('category')\ndata['Potential'] = data['Potential'].astype('float')\ndata.dtypes","2bb61b87":"data['Potential'] = data['Potential'].astype('int')\n","afe2f845":"data.info()","0692df92":"data.Position.value_counts(dropna=False)\nwe have 60 nan values for position of players","3fd90fdf":"data['Position'].dropna(inplace=True)    # inplace = True means we do not assign it to new variable. Changes automatically assigned to data","4dbfe02f":"# to check we use assert\nassert 1==2    # returns error","8f47da03":"assert 1==1 # returns nothing","a9cf5751":"# we check with assert\nassert data['Position'].notnull().all() # returns nothing because we dropped nan values","05358c83":"data.Position.value_counts(dropna=False)\n# we can not see NAN values anymore","ef63fd79":"data['Weak Foot'].value_counts(dropna=False)\n# we have 48 NAN values","e1fda53a":"data['Weak Foot'].fillna('empty', inplace=True)","9485a585":"assert data['Weak Foot'].notnull().all() # returns nothing","4af04ae9":"data['Weak Foot'].value_counts(dropna=False)\n# we can not see NAN values anymore","d562ab3e":"# data frames from dictionary\ncountry = [\"Italy\",\"Germany\"]\npopulation = [\"60\",\"70\"]\nlist_label = [\"country\", \"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","59ee103d":"# add new columns\ndf[\"capital\"] = [\"rome\", \"berlin\"]\ndf","ac5bea71":"# broadcasting\ndf[\"income\"] = 0    # broadcasting entire column\ndf","f1b13aa3":"VISUAL EXPLORATORY DATA ANALYSIS","c768368b":"# plotting all data\ndata1 = data.loc[0:1000,[\"Crossing\",\"Finishing\",\"BallControl\"]]\ndata1.plot()","8a4c6d85":"#subplots\ndata1.plot(subplots = True)\nplt.show()","5211527d":"# scatter plot  \ndata1.plot(kind=\"scatter\", x = \"Crossing\", y = \"Finishing\")\nplt.show()","6c4c9f39":"# hist plot\ndata1.plot(kind=\"hist\", y = \"Crossing\", bins = 50, range = (0,100), normed = True)\nplt.show()","dcf44b04":"# histogram subplot with cumulative and non-cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Crossing\",bins = 30,range= (0,100),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Crossing\",bins = 30,range= (0,100),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","7dc1089d":"data.describe()","58ec582c":"INDEXING PANDAS TIME SERIES","170d932a":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1]))    #string\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","3453f18d":"data2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","4e07d10e":"# Now we can select according to our date index\nprint(data2.loc[\"1993.03.16\"])\nprint(data2.loc[\"1992.03.10\":\"1993.03.16\"])","820c6ead":"data2.resample(\"A\").mean()","183f5b64":"data2.resample(\"M\").mean()","695fd035":"# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","8b3e2abc":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","154972cc":"# read data\ndata = pd.read_csv('..\/input\/data.csv')\n#data= data.set_index(\"index\")\ndata.head()","993d0284":"# indexing using square brackets\ndata[\"Overall\"][1]","8671a67a":"# using column attribute and row label\ndata.Overall[1]","fc5fe5e4":"# using loc accessor\ndata.loc[1,['Overall']]","7352b62b":"# selecting only some columns\ndata[[\"Overall\",\"Potential\"]]","70add62e":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"Overall\"]))    # series\nprint(type(data[['Overall']]))    # data frame","ec83d2a0":"# slicing and indexing series\ndata.loc[0:10,\"Overall\":\"Value\"]    # 10 and Value are inclusive","264dc9d8":"# reverse slicing\ndata.loc[10:0:-1,\"Overall\":\"Name\":-1]","da2b3ba4":"# from something to end\ndata.loc[0:10,\"Value\":]","3a860b9e":"# creating boolean series\nboolean = data.Overall > 93\ndata[boolean]","006c4765":"# combining filters \nfirst_filter = data.Overall > 90\nsecond_filter = data.Potential > 90\ndata[first_filter & second_filter]","c6c46487":"# filtering column based others\ndata.Overall[data.Potential>90]","d65dba46":"# plain python functions\ndef div(n):\n    return n\/2\ndata.Overall.apply(div)","e7b4b189":"# Or we can use lambda function\ndata.Overall.apply(lambda n: n\/2)","0a0bea4b":"# defining columns using other columns\ndata[\"Strike_Power\"] = (data.Crossing + data.Finishing) \/ 2\ndata.head()","4513c0b2":"# our index name is this:\nprint(data.index.name)\n#lets change it\ndata.index.name = \"index name\"\ndata.head()","c0b11ae4":"# Overwrite index\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,18307,1)\ndata3.head()","ab5765db":"HIERARCHICAL INDEXING","2b931c38":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Nationality\",\"Club\"])\ndata1.head(100)","ff78d75f":"PIVOTING DATA FRAMES","c1c134ed":"dic = {\"nationality\":[\"TR\",\"TR\",\"UK\",\"UK\"],\"position\":[\"RF\",\"ST\",\"RF\",\"ST\"],\"skill\":[70,45,75,90],\"age\":[25,40,32,27]}\ndf = pd.DataFrame(dic)\ndf","af702671":"# pivoting\ndf.pivot(index = \"nationality\", columns = \"position\", values = \"skill\")","ed6968ed":"df1 = df.set_index([\"nationality\",\"position\"])\ndf1","68ef6ad6":"# level determines indexes\ndf1.unstack(level=0)","9f347a6b":"df1.unstack(level=1)","b38df47c":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","c673775c":"df","427c2d69":"pd.melt(df,id_vars = \"nationality\", value_vars = [\"age\",\"skill\"])","b043128c":"df.groupby(\"nationality\").mean()","9f63a2fd":"df.groupby(\"nationality\").age.max()","6b821557":"df.groupby(\"nationality\")[[\"age\",\"skill\"]].min()","fb802704":"STATISTICAL EXPLORATORY DATA ANALYSIS","d0541e07":"TIDY DATA","4fbcf448":"\nCATEGORICALS AND GROUPBY","2948be6c":"In this kernel we use F\u0130FA19 dataset yo explore python data science toolbox and data cleaning. This kernel has been prepared for only learning and practice purposes","0aac7493":"LIST COMPREHENSION","0561036f":"USER DEFINED FUNCTION","1dac0a77":"MELTING DATA FRAMES\n* reverse of pivoting","47d21a36":"PIVOTING DATA\n\nreverse of melting","b864b7bd":"VISUAL EXPLORATORY DATA ANALYSIS\n\nBox plots: visualize basic statistics like outliers, min\/max or quantiles","7386df08":"ANONYMOUS FUNCT\u0130ON\n\nLike lambda function but it can take more than one arguments.\n\nmap(func,seq) : applies a function to all the items in a list\n\n","1e0546aa":"MANIPULATING DATA FRAMES WITH PANDAS","b0747009":"CONCATENATING DATA","db8082fa":"BUILDING DATA FRAMES FROM SCRATCH","b9983e4c":"SCOPE","688c449f":"DATA TYPES","dec26756":"**CLEANING DATA**","2345f33f":"LAMBDA FUNCTION","b8661f39":"EXPLORATORY DATA ANALYSIS\n\nvalue_counts(): Frequency counts \noutliers: the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR \n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","ff01e6e3":"MISSING DATA and TESTING WITH ASSERT","e78eb572":"NESTED FUNCTION","743e34ff":"TRANSFORMING DATA","460b67df":"SLICING DATA FRAMES","f3c09870":"INDEX OBJECTS AND LABELED DATA","d2f2de3c":"RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n* Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019","c4f472da":"FILTERING DATA FRAMES","f38b58af":"STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"}}