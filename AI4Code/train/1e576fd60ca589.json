{"cell_type":{"71efa31e":"code","eaedd728":"code","cf1b240e":"code","018e6881":"code","32e74a86":"code","64b568e9":"code","3b464006":"code","282477f5":"code","011019a5":"code","7de3e885":"code","ca241bdc":"code","4b60ed65":"code","d030c9d1":"code","10a95cfd":"code","453f7a88":"code","5ec90da6":"code","ebd3f691":"code","40798c8b":"code","a1854a45":"code","9a0f666b":"code","0477a68a":"code","99d86d7a":"code","57ef7883":"code","f5b01a1c":"code","cbf44292":"code","70deaaf6":"code","43c02c4e":"code","61964d07":"code","fe16701e":"code","bd94a9cf":"code","7cddf97a":"code","6fc4711a":"code","cae0c739":"code","8e1d8b3a":"code","0c0e4211":"code","10053c2d":"code","fe89db55":"code","c2dcdace":"code","4741743c":"code","70e6df9f":"code","066f9b3f":"code","15d83fe4":"code","1f3d9c87":"code","029de553":"code","ff27efe5":"code","e06e4f84":"code","429ae36f":"code","384a7c04":"code","bf209617":"code","e453b533":"code","5389a695":"code","9185967b":"code","60b6f2dc":"code","d35aa326":"code","5f605982":"code","58ed5de2":"code","294090c3":"code","b73c79de":"code","849d526f":"code","b76f98a3":"code","70be705e":"code","691404b6":"code","1bf486e8":"code","5c944287":"code","b59eaad1":"code","b9b9fec2":"code","b1ea6abb":"code","dde799e5":"code","ed785891":"code","976509d0":"code","8df39376":"code","64640ed0":"code","80772785":"code","d707192a":"code","e68f0789":"code","37ace450":"code","f491aba9":"code","e23d8bf0":"code","220edfea":"code","09696dee":"code","56904d6e":"code","8807136e":"code","1a46824a":"code","2a2b1c68":"code","cdb1ee14":"code","6ab77edd":"code","7039a1d4":"code","33ef09e1":"code","4c07608c":"code","bd4c7341":"code","6c2d1708":"code","cfb6fc94":"code","b9b5e938":"code","8a35716b":"markdown","9fd1ed1b":"markdown","3b0c8719":"markdown","c248bf34":"markdown"},"source":{"71efa31e":"from IPython.display import display\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('display.max_columns', None)","eaedd728":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","cf1b240e":"train.head()","018e6881":"data1 = [train, test]","32e74a86":"train.describe()","64b568e9":"test.describe()","3b464006":"train.isnull().sum()","282477f5":"test.isnull().sum()","011019a5":"sns.countplot(train['Survived'])","7de3e885":"# Making Column 'FamilySize'\nfor dataset in data1:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","ca241bdc":"train.corrwith(train['FamilySize'])","4b60ed65":"sns.heatmap(train.corr(), annot=True)","d030c9d1":"sns.boxplot(x='Pclass', y='Fare', data=train)","10a95cfd":"sns.countplot(x='Pclass', hue='FamilySize', data=train)","453f7a88":"train['FamilySize'].value_counts()","5ec90da6":"for dataset in data1:\n    display(dataset['Cabin'].isnull().sum() \/ len(dataset['Cabin']))","ebd3f691":"train['Cabin']","40798c8b":"for dataset in data1:\n    #dataset['TravellingAlone'] = np.nan\n    dataset.loc[dataset['FamilySize'] == 1 ,'TravellingAlone'] = 1\n    dataset.loc[dataset['FamilySize'] != 1 ,'TravellingAlone'] = 0","a1854a45":"train.head()","9a0f666b":"for dataset in data1:\n    dataset['TravellingAlone'] = dataset['TravellingAlone'].astype('int64')","0477a68a":"train.head()","99d86d7a":"train.corrwith(train['TravellingAlone'])","57ef7883":"for dataset in data1:\n    print(dataset.isnull().sum())\n    print('-'*19)","f5b01a1c":"train.corrwith(train['Age'])","cbf44292":"sns.boxplot(x='Pclass', y='Age', data=train)","70deaaf6":"sns.distplot(train['Age'])","43c02c4e":"train.loc[(train['Pclass'] == 1) ,'Age'].isnull().sum()","61964d07":"train.loc[(train['Pclass'] == 2) ,'Age'].isnull().sum()","fe16701e":"train.loc[(train['Pclass'] == 3) ,'Age'].isnull().sum()","bd94a9cf":"train['Age'].isnull().sum()","7cddf97a":"for dataset in data1:\n    dataset.loc[(dataset['Pclass'] == 1), 'Age'] = dataset.loc[(dataset['Pclass'] == 1), 'Age'].fillna(dataset.loc[(dataset['Pclass'] == 1), 'Age'].median())\n    dataset.loc[(dataset['Pclass'] == 2), 'Age'] = dataset.loc[(dataset['Pclass'] == 2), 'Age'].fillna(dataset.loc[(dataset['Pclass'] == 2), 'Age'].median())\n    dataset.loc[(dataset['Pclass'] == 3), 'Age'] = dataset.loc[(dataset['Pclass'] == 3), 'Age'].fillna(dataset.loc[(dataset['Pclass'] == 3), 'Age'].median())","6fc4711a":"train['Age'].isnull().sum()","cae0c739":"for dataset in data1:\n    print(dataset.isnull().sum())\n    print('#'*100)","8e1d8b3a":"sns.distplot(train['Fare'])","0c0e4211":"sns.boxplot(x='Survived', y='Fare', data=train)","10053c2d":"train.corrwith(train['Fare'])","fe89db55":"for dataset in data1:\n    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())","c2dcdace":"test['Fare'].isnull().sum()","4741743c":"type(train['Embarked'].mode().values[0])","70e6df9f":"for dataset in data1:\n    dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode().values[0])","066f9b3f":"passenger_id = test['PassengerId']\nfor dataset in data1:\n    dataset.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize'], axis=1, inplace=True)","15d83fe4":"train.head()","1f3d9c87":"train['Age'].hist()","029de553":"for dataset in data1:\n    dataset['Age'] = dataset['Age'].astype('int64')\ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 3)","ff27efe5":"train['CategoricalAge'].value_counts()","e06e4f84":"train['CategoricalFare'].value_counts()","429ae36f":"for dataset in data1:\n    dataset.loc[(dataset['Age'] < 16), 'Age'] = 0\n    dataset.loc[(dataset['Age'] >= 16) & (dataset['Age'] < 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] >= 32) & (dataset['Age'] < 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] >= 48) & (dataset['Age'] < 64), 'Age'] = 3\n    dataset.loc[(dataset['Age'] >= 64), 'Age'] = 4\n    dataset.loc[(dataset['Fare'] < 9.00), 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] >=9.00 ) & (dataset['Fare'] < 26.00), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] >= 26.00), 'Fare'] = 2","384a7c04":"train.drop(['CategoricalAge', 'CategoricalFare'] ,axis=1, inplace=True)","bf209617":"sns.countplot(x='Survived', hue='Sex', data=train)","e453b533":"train.head()","5389a695":"test.head()","9185967b":"from sklearn.preprocessing import LabelEncoder\nlabelEnc = LabelEncoder()\nfor dataset in data1:\n    dataset['Sex_En'] = labelEnc.fit_transform(dataset['Sex'])\n    dataset['Embarked_En'] = labelEnc.fit_transform(dataset['Embarked'])\n    dataset['Pclass_En'] = labelEnc.fit_transform(dataset['Pclass'])\n    dataset.drop(['Sex', 'Embarked', 'Pclass'], axis=1, inplace=True)","60b6f2dc":"train.head()","d35aa326":"test.head()","5f605982":"X = train.drop('Survived', axis=1)\ny = y_train = train['Survived']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","58ed5de2":"from sklearn.linear_model import LogisticRegression\nlr_model = LogisticRegression()\nlr_model.fit(X_train,y_train)\ny_pred = lr_model.predict(X_test)","294090c3":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score","b73c79de":"cm = confusion_matrix(y_test,y_pred)\ncm","849d526f":"ac = accuracy_score(y_test,y_pred)\nac","b76f98a3":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier()\nrf_model.fit(X_train,y_train)\ny_pred_rf = rf_model.predict(X_test)","70be705e":"ac = accuracy_score(y_test,y_pred_rf)\nac","691404b6":"cm = confusion_matrix(y_test,y_pred_rf)\ncm","1bf486e8":"from sklearn.tree import DecisionTreeClassifier\ndt_model = DecisionTreeClassifier()\ndt_model.fit(X_train,y_train)\ny_pred_dt = dt_model.predict(X_test)","5c944287":"cm = confusion_matrix(y_test,y_pred_dt)\ncm","b59eaad1":"ac = accuracy_score(y_test,y_pred_dt)\nac","b9b9fec2":"from sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(3)\nknn_model.fit(X_train,y_train)\ny_pred_knn = knn_model.predict(X_test)","b1ea6abb":"cm = confusion_matrix(y_test,y_pred_knn)\ncm","dde799e5":"ac = accuracy_score(y_test,y_pred_knn)\nac","ed785891":"y_pred_test = lr_model.predict(test)","976509d0":"from sklearn.svm import SVC\nsvc_model = SVC(probability=True)\nsvc_model.fit(X_train,y_train)\ny_pred_svc = svc_model.predict(X_test)","8df39376":"ac = accuracy_score(y_test,y_pred_svc)\nac","64640ed0":"y_pred_svc_test = svc_model.predict(test)","80772785":"from sklearn.metrics import confusion_matrix, classification_report","d707192a":"def evaluate_models(models):\n    for model in models:\n        print(\"Evaluation for {}\".format(type(model).__name__))\n        print(\"----\"*20)\n        y_pred = model.predict(X_test)\n        cm = confusion_matrix(y_test,y_pred)\n        print(\"\\nConfusion Matrix:\\n\",cm)\n        ac = accuracy_score(y_test,y_pred)\n        print(\"\\nAccuracy:\\n\",ac)\n        print(\"\\nClassification Report:\\n\")\n        print(classification_report(y_test,y_pred))","e68f0789":"models = [lr_model,rf_model,dt_model, knn_model, svc_model]","37ace450":"evaluate_models(models)","f491aba9":"from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV","e23d8bf0":"def cross_validate_models(models, splits):\n    kf = KFold(n_splits=splits,shuffle=True)\n    for model in models:\n        scores = cross_val_score(model,\n                                 X_train,\n                                 y_train,\n                                 cv=kf,\n                                 n_jobs=12,\n                                 scoring=\"accuracy\")\n        print(\"Cross-Validation for {}:\\n\".format(type(model).__name__))\n        print(\"Mean score: \", np.mean(scores))\n        print(\"Variance of score: \", np.std(scores)**2)\n        fig = plt.figure(figsize = (10,5))\n        ax = fig.add_subplot(111)\n        ax = sns.distplot(scores)\n        ax.set_xlabel(\"Cross-Validated Accuracy scores\")\n        ax.set_ylabel(\"Frequency\")\n        ax.set_title('Frequency Distribution of Cross-Validated Accuracy scores for {}'.format(type(model).__name__), fontsize = 15)","220edfea":"cross_validate_models(models,100)","09696dee":"lr_params = {\"penalty\" : [\"l1\", \"l2\"],\n             \"C\" : np.logspace(0, 4, 10),\n             \"solver\" : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}","56904d6e":"dt_params = {\"criterion\":[\"gini\",\"entropy\"],\n             \"splitter\":[\"best\",\"random\"],\n             \"max_depth\":[3,9,81,200],\n             \"min_samples_split\":[25,30,35,50]}","8807136e":"knn_params = {\"n_neighbors\" : [1,3,5,7,9,11,13,15,17,19,21],\n              \"metric\" :  ['euclidean', 'manhattan', 'minkowski'],\n              \"weights\" : ['uniform', 'distance']}             ","1a46824a":"rf_params = {'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n","2a2b1c68":"svc_params = {'kernel' : ['linear', 'rbf', 'poly'],\n'gamma' : [0.1, 1, 10, 100],\n'C' : [0.1, 1, 10, 100, 1000],\n'degree' : [0, 1, 2, 3, 4, 5, 6]}\n","cdb1ee14":"models = [lr_model,rf_model,dt_model, knn_model, svc_model]\nparams = [lr_params,rf_params,dt_params, knn_params, svc_params]","6ab77edd":"tuned_models = []","7039a1d4":"import time","33ef09e1":"def hyper_param_tuning(models,params,splits,scorer):\n    for i in range(len(models)):\n        gsearch = RandomizedSearchCV(estimator=models[i],\n                               param_distributions=params[i],\n                               scoring=scorer,\n                               verbose=2,\n                               n_jobs=-1,\n                               cv=5)\n        start = time.time()\n        gsearch.fit(X_train,y_train)\n        end = time.time()\n        \n        print(\"Grid Search Results for {}:\\n\".format(type(models[i]).__name__))\n        print(\"Time taken for tuning (in secs): \\n\", end-start)\n        print(\"Best parameters: \\n\",gsearch.best_params_)\n        print(\"Best score: \\n\",gsearch.best_score_)\n        tuned_models.append(gsearch.best_estimator_)\n        print(\"\\n\\n\")","4c07608c":"hyper_param_tuning(models,params,100,\"accuracy\")","bd4c7341":"tuned_models","6c2d1708":"dt_model_updated =  DecisionTreeClassifier(criterion='entropy', max_depth=81, min_samples_split=25,\n                        splitter='random')\ndt_model_updated.fit(X_train,y_train)\ny_pred_dt_updated = dt_model_updated.predict(test)","cfb6fc94":"submission1 = pd.DataFrame({\n        \"PassengerId\": passenger_id,\n        \"Survived\": y_pred_dt_updated\n    })","b9b5e938":"submission1.to_csv('mysubmission7.csv', index=False)","8a35716b":"### Model Evaluation","9fd1ed1b":"#### Decision Tree seems to be the most efficient classifier in predicting whether the passenger survived or not with accuracy of 0.78229 on a dataset which our model has never seen before.","3b0c8719":"### Hyperparameter Tuning","c248bf34":"### Cross Validation"}}