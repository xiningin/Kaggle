{"cell_type":{"fb1c1ba3":"code","d48709f9":"code","3a5560e9":"code","fb3e5385":"code","bc871ad7":"code","a376e31b":"code","b5ac1e6a":"code","26e1026b":"code","e1982178":"code","a5b7e483":"code","3ef8d22b":"code","f53d66a4":"code","318e81fc":"code","9ebc9eba":"code","1d210564":"code","6db1baa2":"markdown","60f2df9e":"markdown","f0d67c58":"markdown","31aae091":"markdown","fcff3573":"markdown","3dd0f448":"markdown","13154e71":"markdown","1a7d14aa":"markdown","ffa3ff47":"markdown"},"source":{"fb1c1ba3":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nr_recipes = pd.read_csv('..\/input\/food-com-recipes-and-user-interactions\/RAW_recipes.csv')\ntest = pd.read_csv('..\/input\/food-com-recipes-and-user-interactions\/interactions_test.csv')\ntrain = pd.read_csv('..\/input\/food-com-recipes-and-user-interactions\/interactions_train.csv')\nvalidation = pd.read_csv('..\/input\/food-com-recipes-and-user-interactions\/interactions_validation.csv')","d48709f9":"r_recipes = r_recipes[['id', 'ingredients', 'nutrition', 'n_steps', 'n_ingredients']]\nr_recipes.columns = ['recipe_id', 'ingredients', 'nutrition', 'n_steps', 'n_ingredients']\nr_recipes = r_recipes.set_index('recipe_id')\n\ntrain = pd.concat([train[['user_id', 'recipe_id', 'rating']], validation[['user_id', 'recipe_id', 'rating']]], axis = 0)\n\ntrain_rating = pd.DataFrame(train.groupby(['recipe_id']).mean()['rating'])\ntest_rating = pd.DataFrame(test.groupby(['recipe_id']).mean()['rating'])\n\nrecipes_rating_train = r_recipes.join(train_rating, how = 'inner')\nrecipes_rating_test = r_recipes.join(test_rating, how = 'inner')\n\nrecipes_rating_train['rating'] = recipes_rating_train['rating'].apply(lambda x: round(x))\nrecipes_rating_test['rating'] = recipes_rating_test['rating'].apply(lambda x: round(x))\n\ntrain_test = pd.concat([recipes_rating_train[0:round(recipes_rating_train.shape[0]*0.3)], recipes_rating_test[0:round(recipes_rating_test.shape[0]*0.3)]])","3a5560e9":"def avoidRowsWithMissValues(df):\n  if(df.isnull().values.any()): \n    columns = df.columns\n    for column in columns: \n      df[df[column].isnull()] = \"\"\n      df[df[column]=='NaN'] = \"\"\n      df[pd.isna(df[column])] = \"\"\n  return df\n\nrecipes_rating_train = avoidRowsWithMissValues(recipes_rating_train)\nrecipes_rating_test = avoidRowsWithMissValues(recipes_rating_test)\n\n\nrecipes_rating_train.drop_duplicates()\nrecipes_rating_test.drop_duplicates()\n\n","fb3e5385":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_train['rating'])\nax.set_xticks(np.arange(0,6))\nax.set_xlabel('Ratings in train set')\nplt.show()","bc871ad7":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_test['rating'])\nax.set_xticks(np.arange(0,6))\nax.set_xlabel('Ratings in test set')\nplt.show()","a376e31b":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_train['n_ingredients'])\nax.set_xticks(np.arange(0,20))\nax.set_xlabel('Number of ingredients per recipe in train set')\nplt.show()","b5ac1e6a":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_test['n_ingredients'])\nax.set_xticks(np.arange(0,20))\nax.set_xlabel('Number of ingredients per recipe in test set')\nplt.show()","26e1026b":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_train['n_steps'])\nax.set_xticks(np.arange(0,40, 2))\nax.set_xlabel('Number of steps per recipe')\nplt.show()","e1982178":"sns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = recipes_rating_test['n_steps'])\nax.set_xticks(np.arange(0,40, 2))\nax.set_xlabel('Number of steps per recipe')\nplt.show()","a5b7e483":"recipes_rating_train[recipes_rating_train['n_steps'] > 22]['rating'].value_counts()","3ef8d22b":"recipes_rating_test[recipes_rating_test['n_steps'] > 22]['rating'].value_counts()","f53d66a4":"from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef strToList(list_l, splitSymbol):\n    list_l = list_l.split(splitSymbol)\n    temp = list()\n    for l in list_l: \n        l = l.replace(\"[\",'').replace(\"]\",'').replace(\"'\", '').replace(\" \", '')\n        temp.append(l)\n    return temp\n\nclass ingredientsToList(BaseEstimator, TransformerMixin): \n    def __init__(self, columns = []):\n        self.columns = columns\n    def fit(self, X):\n        return self\n    def transform(self, X): \n      for column in self.columns:\n        X[column] = X[column].apply(lambda x : strToList(x, ','))\n      return X\n    \nclass ingredientsToOneHot(BaseEstimator, TransformerMixin): \n    def __init__(self, columns = []):\n        self.columns = columns\n    def fit(self, X):\n        return self\n    def transform(self, X): \n        cv = CountVectorizer(analyzer=lambda x: x)\n        for column in self.columns:\n            test = cv.fit_transform(X[column].to_list())\n            test_columns = [x for x in cv.get_feature_names()]\n            X = X.join(pd.DataFrame(test.toarray(), columns = test_columns, index = X.index))\n            #X = X.join(pd.DataFrame(test.toarray(), index = X.index))\n        return X\n\nclass nutritionDataIntoCol(BaseEstimator, TransformerMixin): \n    def fit(self, X):\n        return self\n\n    def transform(self, X): \n      nutrition_X = pd.DataFrame(X['nutrition'].to_list(), columns = ['calories', 'total fat', 'sugar_nutrition', 'sodium', 'protein', 'saturated fat', 'carbohydrates'], index = X.index)\n      \n      nutrition_X_col = nutrition_X.columns\n      for col in nutrition_X_col: \n        nutrition_X[col] = nutrition_X[col].apply(lambda x: float(x))\n\n      X = X.join(nutrition_X)\n      return X\n\nclass getFeatureColumns(BaseEstimator, TransformerMixin): \n    def fit(self, X):\n        return self\n    def transform(self, X):\n        col = list(X.columns)\n        for c in ['ingredients', 'nutrition', 'n_steps', 'n_ingredients']:\n            col.remove(c)\n        return X[col]","318e81fc":"from sklearn.pipeline import Pipeline\n\npip = Pipeline([\n    ('ingredientsToList', ingredientsToList(columns = ['ingredients', 'nutrition'])), \n    ('ingredientToOneHotColumns', ingredientsToOneHot(columns = ['ingredients'])),\n    ('nutritionData', nutritionDataIntoCol()), \n    ('getFeatureColumns', getFeatureColumns())\n])\nall_withFeatures = pip.transform(train_test)\nall_withFeatures.head()","9ebc9eba":"del r_recipes\ndel train\ndel train_rating\ndel train_test\ndel recipes_rating_train\ndel recipes_rating_test","1d210564":"col = list(all_withFeatures.columns)\nfor column in ['rating', 'calories', 'total fat', 'sugar_nutrition', 'sodium', 'protein',\n       'saturated fat', 'carbohydrates']:\n    col.remove(column)\nsum_ingredients = pd.DataFrame(all_withFeatures[col].sum(axis = 0)\/all_withFeatures.shape[0])\n\nsns.set(style = \"whitegrid\")\nax = sns.boxenplot(x = sum_ingredients.values*100)\nax.set_xticks(np.arange(0,10, 2))\nax.set_xlabel('Number of time an ingredient was used')\nplt.show()\n\nsum_freq_ingred_index = list(sum_ingredients[sum_ingredients[0]>0.01].index)","6db1baa2":"In the following I will get required data about recipes and interactions, merge train and validation data sets as we use later cross-validation, calculate the average rating per recipe in train\/test\/validate, and join recipes data with rating data. ","60f2df9e":"# Feature engineering\n\nFollowing I will choose a bunch of features to be ready to run classification algorithms. Firstly I check correlations and transform ingredients and nutrition values into a suitable format. With the help of CountVectorizer all ingredients are added to a vocabulary. So each recipe ingredients will be represented by onehot-encodings. Nutrition data will be as well separated into different columns. \n\nFor deployment it is better when all the transformations with the input data are done in a pipeline. For this purpose i created Scikit Learn -designed transformers that will transform the current and future input data. But the input data is expected to be in particular format like includes *recipe_id* and other required columns.","f0d67c58":"# Some data exploration\n\nTo continue with prediction of ratings I will check for missing values, dublicates, look for outliers and imbalances. ","31aae091":"#### Ratings distribution \n\nMost of recipes are rated with 5 in both set. So we need later to take care about imbalanced classes. Class 4 appears more often in test class. \n","fcff3573":"# Data exploration + pipeline for ingredients one hot encodings\n\n# Import data\n \nCurently I'm considering only *ingredients*, *nutrition* and free features like *n_ingredients* and *n_steps* for exploration and one hot encodings. ","3dd0f448":"## Clean RAM\nHere I remove some of variables that are not required any more. It allows to conduct further memory-consuming experiments.","13154e71":"## Avoid rare ingredients\nThe idea here is to avoid ingredients that appear rarely in recipes. Since they can disturb models while looking for the fit. So I consider further ingredients that appear at least in 1% of recipes. ","1a7d14aa":"#### Number of ingredients\nIs similarly distributed in train and test sets and do not include critical outliers.\n","ffa3ff47":"#### Number of steps per recipe \nThe distribution of steps in train and test sets are similar. Some of recipes in both sets have unsualy many steps (> 22). The number of such recipes are similarly distributed in test and train sets and the rating disctribution of outliers corresponds to general rating distribution.  "}}