{"cell_type":{"7a8c154d":"code","c2045002":"code","8686b9b5":"code","a9adc90b":"code","e6ebdf6b":"code","6583c43b":"code","d17578e7":"code","2c4cde01":"code","47587d81":"code","66cad95e":"code","81423df4":"code","06d07ea1":"code","bc98c554":"code","d5ddad1f":"code","9883baee":"code","ed6e77a6":"code","d1f7b724":"code","ee0b6667":"code","00c08ec4":"code","dd84b828":"code","5df5f8e2":"code","488637c6":"markdown","b362ac0f":"markdown","7140076e":"markdown","960fbb7a":"markdown","043fd193":"markdown","1060fdc6":"markdown","12c0fe51":"markdown","7a7383ff":"markdown","ea1a847d":"markdown","a9178cf3":"markdown","6c844a4e":"markdown","7266f5c1":"markdown","79bd82f7":"markdown"},"source":{"7a8c154d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport altair as alt\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix, plot_roc_curve, accuracy_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\ntrain_folder = \"\/kaggle\/input\/healthcare-analytics\/Train\/\"","c2045002":"# take a glance at data\ntrain = pd.read_csv(train_folder+\"Train.csv\")\ntrain.head()\nprint(train.describe())\nprint(train.head())","8686b9b5":"# plot\ntrain.hist()\nplt.tight_layout()","a9adc90b":"# take a glance at data\ntest = pd.read_csv(train_folder+\"test.csv\")\nprint(test.describe())\nprint(test.head())","e6ebdf6b":"# plot\ntest.hist()\nplt.tight_layout()","6583c43b":"# look if duplicate patient_id health_camp_ID combos\n\n# read in the datasets\nhealth_camp_detail = pd.read_csv(train_folder+\"Health_Camp_Detail.csv\") # join on camp_ID\npatient_profile = pd.read_csv(train_folder+\"Patient_Profile.csv\")# join on Patient_ID\n","d17578e7":"# Health Outcomes\nfirst_healthcamp = pd.read_csv(train_folder+\"First_Health_Camp_Attended.csv\")\nsecond_healthcamp = pd.read_csv(train_folder+\"Second_Health_Camp_Attended.csv\")\nthird_healthcamp = pd.read_csv(train_folder+\"Third_Health_Camp_Attended.csv\")\n","2c4cde01":"print(\"first_healthcamp\")\nprint(first_healthcamp.head())\nprint(first_healthcamp.describe())","47587d81":"print(\"second_healthcamp\")\nprint(second_healthcamp.head())\nprint(second_healthcamp.describe())","66cad95e":"print(\"third_healthcamp\")\nprint(third_healthcamp.head())\nprint(third_healthcamp.describe())","81423df4":"# rename column to match other datasets\nsecond_healthcamp.rename(columns={'Health Score': 'Health_Score'}, inplace=True)\n\n# Create a healthscore based on if the patient visited a stall or not\nthird_healthcamp[['Health_Score']] = third_healthcamp[['Number_of_stall_visited']].where(third_healthcamp[['Number_of_stall_visited']] <= 1, 1) \n","06d07ea1":"# Pick only columns we want to use in the first model\ncolumns = ['Patient_ID',  'Health_Camp_ID',  'Health_Score']\nhealth_scores = pd.concat([first_healthcamp[columns],\n                           second_healthcamp[columns],\n                           third_healthcamp[columns]])\nhealth_scores","bc98c554":"health_scores[['Health_Score']].hist()\nplt.tight_layout()","d5ddad1f":"patient_profile = pd.read_csv(train_folder+\"Patient_Profile.csv\")\n\nprint(\"patient_profile\")\nprint(patient_profile.head())\nprint(patient_profile.describe())\n\n#plot\npatient_profile.hist()\nplt.tight_layout()","9883baee":"patient_profile['online_activity'] = patient_profile[['Online_Follower' , 'LinkedIn_Shared',  'Twitter_Shared', 'Facebook_Shared']].max(axis=1)\n\nprint(patient_profile[['online_activity']].describe())","ed6e77a6":"# now just remove the columns\npatient_profile2 = patient_profile.drop(['Online_Follower' , 'LinkedIn_Shared',  'Twitter_Shared', 'Facebook_Shared'], axis=1)","d1f7b724":"health_camp_detail = pd.read_csv(train_folder+\"Health_Camp_Detail.csv\")\nprint(\"health_camp_detail\")\nprint(health_camp_detail.tail())\nprint(health_camp_detail.describe())","ee0b6667":"# health outcomes\ntrain2 = pd.merge(train, health_scores,  how='inner', left_on=['Patient_ID',  'Health_Camp_ID'], right_on = ['Patient_ID',  'Health_Camp_ID'])\n#test2 = pd.merge(test, health_scores,  how='inner', left_on=['Patient_ID',  'Health_Camp_ID'], right_on = ['Patient_ID',  'Health_Camp_ID'])\ntest2 = test\n\n# patient\ntrain2 = pd.merge(train2, patient_profile2,  how='inner', on=['Patient_ID'])\ntest2 = pd.merge(test2, patient_profile2,  how='inner', on=['Patient_ID'])\n\n# health camp\ntrain2 = pd.merge(train2, health_camp_detail,  how='inner', on=['Health_Camp_ID'])\ntest2 = pd.merge(test2, health_camp_detail,  how='inner', on=['Health_Camp_ID'])\n\ny_train = train2[['Health_Score']].round()\nX_train = train2.drop(['Patient_ID', 'Health_Camp_ID', 'Health_Score'], axis=1)\n\n# Use this to predict health results\ntest_final = test2.drop(['Patient_ID', 'Health_Camp_ID'], axis=1)\n\n# replace \"none\" with nan\nX_train[['Income','Education_Score','Age']] = X_train[['Income','Education_Score','Age']].replace(\"None\", np.nan)\ntest_final[['Income','Education_Score','Age']] = X_train[['Income','Education_Score','Age']].replace(\"None\", np.nan)\n\n# get rid of dates, come back to this later and extract some information out of them\ndatecols = ['Registration_Date','First_Interaction', 'Camp_Start_Date','Camp_End_Date']\nX_train = X_train.drop(datecols, axis=1)\ntest_final = test_final.drop(datecols, axis=1)\n\n# Factorise categorical variables\ncat_columns = X_train.dtypes.pipe(lambda x: x[x == 'object']).index\n\nfor c in cat_columns:\n    X_train[c] = pd.factorize(X_train[c])[0]\n    test_final[c] = pd.factorize(test_final[c])[0]\n\n# print what the datasets look like\nprint(\"Columns in Train set\")\nprint(X_train.columns)\nprint(\"\\nColumns in Test set\")\nprint(test_final.columns)\nprint(f\"\\n\\nTrain X dimensions: {X_train.shape}\")\nprint(f\"Train y dimensions: {y_train.shape}\")\nprint(f\"Test X dimensions: {test_final.shape}\")\nprint(\"\\n\\nRoughly 2\/3 of y values represent positive health outcomes\")\nprint(y_train.astype(int).sum() \/ len(y_train))\nprint(y_test.astype(int).sum() \/ len(y_test))","00c08ec4":"X_train_NB = X_train\ny_train_NB = y_train\nX_train, X_test, y_train, y_test = train_test_split(X_train_NB, y_train_NB, test_size=0.1, random_state=0)\ngnb = GaussianNB()\ngnb.fit(X_train, y_train.values.ravel())\n# predict values\ny_hat = gnb.predict(X_test)\n# accuracy:\nprint(f\"Accuracy is: {sum(y_hat == y_test.values.ravel()) \/ len(y_hat)}, which is not great, since 67% of health outcomes are positive anyway\")\nplot_roc_curve(gnb, X_test, y_test)\nplt.show()","dd84b828":"# pick probability for positive outcome\ny_hat_submission = gnb.predict_proba(test_final)[:,1]\ny_hat_submission\n#create a submission dataset\nsubmission = test[['Patient_ID', 'Health_Camp_ID']]\nsubmission[\"Outcome\"] = y_hat_submission\nsubmission[\"Outcome\"].hist()","5df5f8e2":"# save submission dataset\nsubmission.to_csv('submission.csv', index=False)","488637c6":"### 4.3 Random Forest","b362ac0f":"# Healthcare Analytics Quick Exercise\n\n    WORK IN PROGRESS\n\nGoal of this exercise is to:\n\n- [x] become familiar with Kaggle environment\n- [x] create a table of contents using [this tutorial](https:\/\/www.kaggle.com\/getting-started\/107641)\n- [x] get my first ever submission done\n- [ ] try couple of interactive plots introduced in [this tutorial](https:\/\/www.kaggle.com\/raenish\/cheatsheet-100-altair-plots-part-1-basic)\n\n\n\n## Table of Contents\n\n- [1. Context](#section-context)\n- [2. Summary](#section-summary)\n- [3. Data](#section-data)\n    - [3.1 Health Outcomes](#health_outcomes)\n    - [3.2 Patient Profile](#patient_profile)\n    - [3.3 Camp Details](#camp_details)\n    - [3.4 Join Data](#join_data)\n- [4. Modelling](#section-modelling)    \n- [5. Submission](#section-submission)","7140076e":"<a id=\"patient_profile\"><\/a>\n## 3.2 Patient Profile\n","960fbb7a":"The ratio of Online_Follower, LinkedIn_Shared, Twitter_Shared, Facebook_Shared value is roughly 98\/2. This data is very biased.\n\nNow let's combine these values in one column and call it `online_activity`, it gives us value for 4.5% of patients. I assume we don't lose much information by doing that.\n\nLet's select","043fd193":"<a id=\"join_data\"><\/a>\n## 3.4 Join Data\n\nWe join health outcomes, patient information and health camp details to train and test sets. We'll use numerical vairables only for this exercise.","1060fdc6":"<a id=\"camp_details\"><\/a>\n## 3.3 Camp Details","12c0fe51":"<a id=\"section-context\"><\/a>\n## 1. Context\n\nContext copy-pasted from [here](https:\/\/www.kaggle.com\/shivan118\/healthcare-analytics).\n\nMedCamp organizes health camps in several cities with low work-life balance. They reach out to working people and ask them to register for these health camps. For those who attend, MedCamp provides them the facility to undergo health checks or increase awareness by visiting various stalls (depending on the format of the camp).\n\nMedCamp has conducted 65 such events over a period of 4 years and they see a high drop off between \u201cRegistration\u201d and the Number of people taking tests at the Camps. In the last 4 years, they have stored data of ~110,000 registrations they have done.\n\nOne of the huge costs in arranging these camps is the amount of inventory you need to carry. If you carry more than the required inventory, you incur unnecessarily high costs. On the other hand, if you carry less than the required inventory for conducting these medical checks, people end up having bab experience.\n\nThe Process:\nMedCamp employees\/volunteers reach out to people and drive registrations.\nDuring the camp, People who \u201cShowUp\u201d either undergo the medical tests or visit stalls depending on the format of the health camp.","7a7383ff":"<a id=\"section-submission\"><\/a>\n## 5. Submission\n\nPick Naive Bayes results for now and submit.","ea1a847d":"### 4.2 Logistic Regression","a9178cf3":"<a id=\"section-summary\"><\/a>\n## 2. Summary\n\n- Training set has initially ~110k rows and test set ~ 30k rows.\n- There indeed is a big dropout rate. Out of ~110k registrations, roughly 20k has a health outcome. Therefore training set ends up being smaller than the test set.\n- Whereas health scores from camp 1 and 2 are nearly uniformly distributed between 0 and 1, health scores from Camp 3 are just binary (0 or 1).\n\n- Naive Bayes on all numerical variables (train-test split using 20% test) yields 66.6% accuracy, while AUC was 0.72. The result is not great result since 67% of health outcomes are positive in the original dataset.\n\n- Some next steps could be feature engineering on dates, maybe using this [example](https:\/\/towardsdatascience.com\/machine-learning-with-datetime-feature-engineering-predicting-healthcare-appointment-no-shows-5e4ca3a85f96) and just trying more models.","6c844a4e":"<a id=\"health_outcomes\"><\/a>\n### 3.1 Health Outcomes","7266f5c1":"<a id=\"section-data\"><\/a>\n## 3. Data\n- Train set has 75k observations and test set 35k.\n- These datasets have main keys `Patient_ID` and `Health_Camp_ID` along with some anonymised variables captured at the time of registration\n- According to the summary stats and histograms plotted below, I'm afraid there's not much predictive power in these variables\n","79bd82f7":"<a id=\"section-modelling\"><\/a>\n## 4. Modelling\n\n\n### 4.1 Naive Bayes\n\nNaive Bayes likes only numerical variables but doesn't mind too much about missing values in the data. Let's do a test run and first submission using that one.\n"}}