{"cell_type":{"dbf97083":"code","098a65df":"code","fb231999":"code","75c141a3":"code","5b3f5d8f":"code","530da6c1":"code","7158c441":"code","e171e860":"code","7958dcba":"code","1bb570bb":"code","1796f44f":"code","7e0caed0":"code","58bf4bd0":"code","fb61fa19":"code","cb7e7423":"code","8880aae3":"markdown","5aa206ef":"markdown","0bef2ea9":"markdown","5524b02c":"markdown","2d9d3735":"markdown","b587e61d":"markdown","633e2a58":"markdown","4f990803":"markdown"},"source":{"dbf97083":"import numpy as np\nimport pandas as pd \nimport os \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\nimport seaborn as sns \n\n%matplotlib inline \nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom PIL import Image \nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport glob\nimport time \n\n\n\n# seed \ntf.random.set_seed(42)\nnp.random.seed(42)","098a65df":"# dataset\ndataset = '..\/input\/covid-19-x-ray-10000-images\/dataset'","fb231999":"# spliting images \nnormal_images = []\n\nfor img_path in glob.glob(dataset + '\/normal\/*'):\n  normal_images.append(mpimg.imread(img_path))\n\n\n\nplt.figure(figsize=(10,5))\n\n\nplt.subplot(1,2,1)\nplt.title('Normal')\nplt.imshow(normal_images[0], cmap='gray')\n\n\n\n\ncovid_images = []\n\nfor img_path in glob.glob(dataset + '\/covid\/*'):\n  covid_images.append(mpimg.imread(img_path))\n\nplt.subplot(1,2,2)\nplt.title('Covid-19')\nplt.imshow(covid_images[0], cmap='gray')\nplt.tight_layout()","75c141a3":"# size of class images  \nprint('Normal: ', len(normal_images))\nprint('Covid: ', len(covid_images))","5b3f5d8f":"# define shape \nimage_height = 150\nimage_width = 150\nchannels = 3 \n\n\n# parameters \ninput_shape = (image_height, image_width, channels)\nnumber_classe = 2 \nbatch_size = 6\nepochs = 40\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)","530da6c1":"plt.imshow(normal_images[10], cmap='gray')\nplt.title('Normal')","7158c441":"plt.imshow(normal_images[7], cmap='hot')\nplt.axis('off')\nplt.colorbar()","e171e860":"# Convolutional Neural Network \n\nmodel = tf.keras.Sequential([tf.keras.layers.InputLayer(input_shape=input_shape),\n                                    tf.keras.layers.Conv2D(32, (3,3), (1,1), padding='same', activation='relu'),\n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.LayerNormalization(axis=-1),\n                                    tf.keras.layers.Conv2D(64, (3,3), (1,1), padding='same', activation='relu'),                                   \n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.SpatialDropout2D(0.20),\n                                    tf.keras.layers.Conv2D(128, (3,3), (1,1), padding='same', activation='relu'),                                   \n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.LayerNormalization(axis=-1),\n                                    tf.keras.layers.Conv2D(256, (3,3), (1,1), padding='same', activation='relu'),                                   \n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.SpatialDropout2D(0.20),                                  \n                                    tf.keras.layers.Conv2D(512, (3,3), (1,1), padding='same', activation='relu'),\n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.LayerNormalization(axis=-1),\n                                    tf.keras.layers.GlobalMaxPool2D(),\n                                    tf.keras.layers.Dense(units=128, activation='relu'),\n                                    tf.keras.layers.Dense(units=1, activation='sigmoid')\n                                    ])\n\n\nmodel.compile(optimizer=optimizer,\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","7958dcba":"# Data Augmentation \ndata_generator = ImageDataGenerator(featurewise_center=False,\n                                    featurewise_std_normalization=False,\n                                    rotation_range=10,\n                                    zoom_range=0.10,\n                                    rescale = 1.\/255,\n                                    validation_split=0.30)\n\n\n# Train \ntrain_generator = data_generator.flow_from_directory(dataset,\n                                                     target_size=(image_height, image_width),\n                                                     batch_size=batch_size,\n                                                     class_mode='binary',\n                                                     subset='training')\n\n\n# Validation \nvalidation_generator = data_generator.flow_from_directory(dataset,\n                                                     target_size=(image_height, image_width),\n                                                     batch_size=batch_size,\n                                                     class_mode='binary',\n                                                     shuffle=False,\n                                                     subset='validation')\n\n\n\n# CNN \nhistory = model.fit(train_generator, validation_data=validation_generator, epochs=epochs)","1bb570bb":"print(\"Accuracy Test -  \", model.evaluate(validation_generator)[1]*100, '%')","1796f44f":"epochs = [i for i in range(40)]\nloss_train = history.history['loss']\nacc_train = history.history['accuracy']\nloss_test = history.history['val_loss']\nacc_test = history.history['val_accuracy']\n\n\nfig, ax = plt.subplots(1,2, figsize=(14,5))\n\nax[0].plot(epochs, loss_train, color='blue', label='Loss Train')\nax[0].plot(epochs, loss_test, color='orange', label='Loss Test')\nax[0].set_title('Train and test Loss', fontsize=14)\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].legend()\n\n\n\nax[1].plot(epochs, acc_train, color='blue', label='Loss Train')\nax[1].plot(epochs, acc_test, color='orange',  label='Loss Test')\nax[1].set_title('Train and test Accuracy', fontsize=13)\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Accuracy')\nax[1].legend()\nplt.show()","7e0caed0":"# true class\ny_test = validation_generator.classes","58bf4bd0":"y_pred = model.predict(validation_generator)\ny_pred = np.around(y_pred, decimals=0)","fb61fa19":"print(classification_report(y_test, y_pred, target_names=['Covid-19','Normal']))","cb7e7423":"fig, axs = plt.subplots(5, 5, figsize=(12,12))\naxs=axs.ravel()\n\nfor i in range(0,25):  \n    axs[i].imshow(covid_images[i], cmap='gray')\n    axs[i].set_title(\"Prediction Class = {} \\n Original Class = {}\".format(y_pred[i], y_test[i]))\n    axs[i].axis('off')\nplt.subplots_adjust(wspace=0.5)","8880aae3":"<br>\n<br>\n<hr>\n<br>","5aa206ef":"<hr>\n<br>\n<br>\n\n\n### 3. Data Augmentation \n\n\nData Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation.\n\n\n\n<br>\n\n\n\n","0bef2ea9":"<br>\n<br>\n\n\n### 2. Convolutional Neural Network \n\nI decided choose for Convolutional Neural Networks, who are one  architecture who have best performance results when works on images.Beyond consistent and default in problems of images classification.\n\n\nI will explain a little about the architecture that I set up and explain the use of the main layers of the network and why I chose to use it.\n\n\n#### <b> Architecture <\/b>\n\n\n* Input layer is responsible for receiving images (150x150x3) \n* Conv2D with 32 filters, kernel_size=(3,3) and padding='same'\n* MaxPool2D with pool_size=(2,2)\n* <b> LayerNormalization <\/b> This is one technique of normalization, substitute the BatchNormalization, in addition to being faster in calculating gradients and optimizing, it gets good results with it its specificity is pixel normalization done by channel and not by mini-batch.\n* Conv2D with 64 filters, kernel_size=(3,3) and padding='same'\n* MaxPool2D with pool_size=(2,2)\n* <b> SpartialDropout2D <\/b> This layer was necessary for control Overfitting, by terms little images, the risk of overfitting it was biggest, SpartialDropout2D is one variant of dropout, but Spartial is very better for Feature maps, because he drops pixels after MaxPooling.\n* Conv2D with 128 filters, kernel_size=(3,3) and padding='same'\n* MaxPool2D with pool_size=(2,2)\n* LayerNormalization again other normalization\n* Conv2D with 256 filters, kernel_size=(3,3) and padding='same'\n* MaxPool2D with pool_size=(2,2)\n* SpartialDropout2D again other dropout\n* Conv2D with 512 filters, kernel_size=(3,3) and padding='same'\n* MaxPool2D with pool_size=(2,2)\n* LayerNormalization again other normalization\n* <b> GlobalMaxPool2D <\/b> I used layer GlobalMaxPool for decrease a number of parameters of network, different of Flatten this layer reduce Feature maps in Global scale, making a summary by channel of images, very good layer.\n* Dense layer with 128 neurons and relu activation \n* Dense layer again for the output layer in architecture \n\n\n<br>\n<br>\n\n\n \n\n\n\n\n\n\n\n\n\n","5524b02c":"### Summary \n<br>\n\nThe network at the end proved to be very unstable because it had few images, but after the data increase the convolutional network showed <b> 86% accuracy <\/b> in the test data with a Precision of <b> 95% <\/b> > what is a great result, but the detail is in the variance and instability that the model has.\n\n<br>\n\n\nThe reason for I develop this project, was for apply techniques of Computer Vision with Data Augmentation and also experiment diverses layers as LayerNormalization, SpartialDropout2D and GlobalMaxPool2D. \n\n<br>\n\nThis projetc allied with a doctor and health specialist, have big potential to be one Images Detector of Covid-19  apply a Healthcare.\n\nThe biggest problem I encountered was the small dataset of images of x-rays classified with covid-19, only 70 images is very little for this problem \n\n","2d9d3735":"<br>\n\n\n### 1. Frameworks \n\n<br>","b587e61d":"<br>\n<br>\n\n\n#### LayerNormalization \n\nLink for studies abourt LayerNormalization: https:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fdifferent-types-of-normalization-in-tensorflow-dac60396efb0&psig=AOvVaw3K-OwOMngUODmIosDMWdsk&ust=1596501817145000&source=images&cd=vfe&ved=0CA0QjhxqFwoTCMCIwPHm_eoCFQAAAAAdAAAAABAD\n\n<br>\n\n\n#### GlobalMaxPool2D \n\n\nReferences for studies: https:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2Fpeltarion.com%2Fknowledge-center%2Fdocumentation%2Fmodeling-view%2Fbuild-an-ai-model%2Fblocks%2F2d-global-max-pooling&psig=AOvVaw1Vgi5x1VUzND0QBdBDu9Qy&ust=1596501451109000&source=images&cd=vfe&ved=2ahUKEwi0n6TA5f3qAhXyMLkGHYsSDdIQr4kDegUIARCRAQ\n\n<br>\n\n<p align=center>\n<img src=\"https:\/\/alexisbcook.github.io\/assets\/global_average_pooling.png\" width=\"50%\"><\/p>\n\n\n\n\n<br>\n<br>\n\n\n","633e2a58":"<br>\n<hr>\n<br>\n\n\n### 4. Evaluation CNN \n\n\n\n<br>\n<br>","4f990803":"### Detecting Covid-19 Images \n\n<br>\n\nThis project We will build Deep learning system for Detection Covid-19 in X-rays images. \n\nWith the intensive increase in ICU beds, the demand for immediate exam results is more likely than in this pandemic,The goal is to create a Deep learning system that can identify X-ray images and classify the patient as Normal or if they have Covid-19.\n\n\n<br>\n\n\n\n#### <b>WARNING<\/b>: This project was developed by a Machine learning engineer with technical knowledge in Deep learning, I also emphasize that I made this system for technical and intuitive demonstration of a Deep learning application in the Computer Vision area, which it does not qualify as a job of scientific rigor because it would need a business specialist in this case a doctor or health professional to collaborate on a solution that fits scientific standards.\n\n\n<br>\n<br>\n\n<p align=center>\n<img src=\"https:\/\/miro.medium.com\/max\/3840\/1*6TPePg_wW6MZ7rkwFVJGyw.png\" width=\"80%\"><\/p>\n\n\n\n\n<br>\n<br>\n<hr>"}}