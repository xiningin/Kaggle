{"cell_type":{"6d08b3a4":"code","2d37aae7":"code","50fb4b00":"code","39bff378":"code","6abe3484":"code","3ab8e30d":"code","f2c388f3":"code","400e7613":"code","be01c841":"code","92325ec8":"code","35f20aab":"code","0a00c969":"code","f61f57a3":"code","1677b8b3":"code","157feddc":"code","c1c61637":"code","dc65f10b":"code","db5a630e":"code","ebbbe693":"code","74725cd0":"code","52d9b797":"code","51d92991":"code","1ed4e0b4":"code","490bf76d":"code","f01d087c":"markdown","7966e2df":"markdown","2624a2ed":"markdown","03f934d0":"markdown","8c127acc":"markdown","8ddf87a6":"markdown","e725536f":"markdown","50acc34d":"markdown","a6ce8a11":"markdown","46c55a2d":"markdown","c6e0b977":"markdown","e6d17bfd":"markdown","8dc6ab8e":"markdown","c99bfe0d":"markdown","1e933a12":"markdown","8a6f92ab":"markdown","a9581352":"markdown","a453e107":"markdown","a11eb34f":"markdown"},"source":{"6d08b3a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d37aae7":"import numpy as np\nimport os\n\n# visualization libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.image import imread\n\n# tensorflow libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential,  Model, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras import optimizers\nfrom keras.applications.inception_v3 import InceptionV3\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n\n# model evaluation libraries\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix","50fb4b00":"base_dir= \"\/kaggle\/input\/files1\/Malaria Cells\"\ntraining_dir= \"\/kaggle\/input\/files1\/Malaria Cells\/training_set\"\ntesting_dir= \"\/kaggle\/input\/files1\/Malaria Cells\/testing_set\"\n\nprint(\"inside base dir :\", os.listdir(base_dir))\nprint(\"\\ntraining_set :\", os.listdir(training_dir))\nprint(\"\\ntesting_set :\", os.listdir(testing_dir))","39bff378":"train_Uninfected= \"\/kaggle\/input\/files1\/Malaria Cells\/training_set\/Uninfected\"\ntrain_Parasitized= \"\/kaggle\/input\/files1\/Malaria Cells\/training_set\/Parasitized\"\n\ntest_Uninfected= \"\/kaggle\/input\/files1\/Malaria Cells\/testing_set\/Uninfected\"\ntest_Parasitized= \"\/kaggle\/input\/files1\/Malaria Cells\/testing_set\/Parasitized\"\n\nprint(\"train_Uninfected:\", os.listdir(train_Uninfected)[:5])\nprint(\"\\ntrain_Parasitized:\", os.listdir(train_Parasitized)[:5])\nprint(\"\\ntest_Uninfected:\", os.listdir(test_Uninfected)[:5])\nprint(\"\\ntest_Parasitized:\", os.listdir(test_Parasitized)[:5])","6abe3484":"print(\"Total train Uninfected cell images :\", len(os.listdir(train_Uninfected)))\nprint(\"Total train Parasitized cell images :\", len(os.listdir(train_Parasitized)))\nprint(\"\\nTotal test Uninfected cell images :\", len(os.listdir(test_Uninfected)))\nprint(\"Total test Parasitized cell images :\", len(os.listdir(test_Parasitized)))","3ab8e30d":"nrows = 4\nncols = 4\n\npic_index = 0 \n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nparasitized_cell = [os.path.join(train_Parasitized, image) for image in os.listdir(train_Parasitized)[pic_index-8:pic_index]]\n\nuninfected_cell = [os.path.join(train_Uninfected, image) for image in os.listdir(train_Uninfected)[pic_index-8:pic_index]]\n\nfor i, image_path in enumerate(parasitized_cell+uninfected_cell):\n\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') \n\n  img = mpimg.imread(image_path)\n  plt.imshow(img)\n\nplt.show()","f2c388f3":"parasitized_image= imread(\"\/kaggle\/input\/files1\/Malaria Cells\/training_set\/Parasitized\/C99P60ThinF_IMG_20150918_141001_cell_93.png\")\nparasitized_image.shape","400e7613":"# generating training set\nprint(\"training data :\")\ntrain_datagen= ImageDataGenerator(rescale=1\/255, zoom_range=0.3, rotation_range=50,\n                                   width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest')\n\ntrain_data= train_datagen.flow_from_directory(training_dir,\n                                              target_size= (100,100),\n                                              batch_size=20,\n                                              class_mode= \"binary\",\n                                              shuffle= True)\n\n\n# generating validation set\nprint(\"\\nvalidation data :\")\nval_datagen= ImageDataGenerator(rescale=1\/255) # data augmentation is applied only to training data not to validation & test data\n\nval_data= val_datagen.flow_from_directory(testing_dir,\n                                          target_size= (100,100),\n                                          batch_size=20,\n                                          class_mode= \"binary\",\n                                          shuffle= False)\n\n# generating test set\nprint(\"\\ntest data :\")\ntest_datagen= ImageDataGenerator(rescale=1\/255)\n\ntest_data= test_datagen.flow_from_directory(testing_dir,\n                                            target_size= (100,100),\n                                            batch_size=20,\n                                            class_mode= \"binary\",\n                                            shuffle= False)","be01c841":"train_data.class_indices","92325ec8":"model_1= Sequential()\n\nmodel_1.add(Conv2D(filters= 16, kernel_size=(3,3), activation=\"relu\", input_shape=(100, 100, 3)))\nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_1.add(Conv2D(filters= 32, kernel_size=(3,3), activation=\"relu\"))\nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_1.add(Conv2D(filters= 64, kernel_size=(3,3), activation=\"relu\"))\nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_1.add(Conv2D(filters= 128, kernel_size=(3,3), activation=\"relu\"))\nmodel_1.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel_1.add(Flatten())\nmodel_1.add(Dense(units= 512, activation='relu'))\nmodel_1.add(Dropout(0.2))\n\nmodel_1.add(Dense(units=1, activation=\"sigmoid\"))\n\nmodel_1.summary()","35f20aab":"# model compiling\nmodel_1.compile(loss= \"binary_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"accuracy\"])\n\n# model fitting\nhistory= model_1.fit_generator(train_data,\n                               steps_per_epoch= train_data.samples\/\/train_data.batch_size,\n                               validation_data= val_data,\n                               validation_steps= val_data.samples\/\/val_data.batch_size,\n                               epochs=20, verbose= 2)","0a00c969":"history.history.keys()","f61f57a3":"epochs= range(len(history.history[\"accuracy\"]))\n# accuracy plot\nplt.plot(epochs, history.history[\"accuracy\"])\nplt.plot(epochs, history.history[\"val_accuracy\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.title(\"CNN Model Accuracy\")\nplt.legend([\"train\", \"validation\"])\nplt.show()\n\n# loss plot\nplt.plot(epochs, history.history[\"loss\"])\nplt.plot(epochs, history.history[\"val_loss\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"CNN Model Loss\")\nplt.legend([\"train\", \"validation\"])\nplt.show()","1677b8b3":"# inceptionV3 model, with include_top= False we are not using fully connected layer of the inceptionV3 model, instead we\n#  will create our own Fully Connected and Output Layer according to our training data\ninception= InceptionV3(input_shape= (100, 100,3), include_top= False, weights=\"imagenet\")\n\n# Since we are creating our own fully connected layer we need output of the last inception model layer and flatten them \nlast_output= inception.layers[-1].output\n\n# Flattening the last output\nlast_output= Flatten()(last_output)\n\n# Our pretrained model\ninception_model= Model(inception.input, last_output)","157feddc":"# layer 1\nx= Dense(units=512, activation=\"relu\")(last_output)\nx=Dropout(0.2)(x)\n\n# layer 2\nx= Dense(units=128, activation=\"relu\")(x)\nx=Dropout(0.2)(x)\n\n# output layer\nx= Dense(units=1, activation=\"sigmoid\")(x)\n\n# final model\nmodel= Model(inception_model.input, x)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"accuracy\"])\nmodel.summary()","c1c61637":"# Since the layers of InceptionV3 model are already trained, we don't want them to be trained again. \n# So we will freeze these layers\nfor layer in inception_model.layers:\n    layer.trainable= False\n\n# fitting only Fully Connected layers    \nhistory= model.fit(train_data, \n                   steps_per_epoch= train_data.samples\/\/train_data.batch_size,\n                   validation_data= val_data,\n                   validation_steps= val_data.samples\/\/val_data.batch_size,\n                   epochs=20, verbose= 2)","dc65f10b":"epochs= range(len(history.history[\"accuracy\"]))\n# accuracy plot\nplt.plot(epochs, history.history[\"accuracy\"])\nplt.plot(epochs, history.history[\"val_accuracy\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.title(\"InceptionV3 Model Accuracy\")\nplt.legend([\"train\", \"validation\"])\nplt.show()\n\n# loss plot\nplt.plot(epochs, history.history[\"loss\"])\nplt.plot(epochs, history.history[\"val_loss\"])\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.title(\"InceptionV3 Model Loss\")\nplt.legend([\"train\", \"validation\"])\nplt.show()","db5a630e":"prediction= model.predict_generator(test_data, steps=np.ceil(val_data.samples\/val_data.batch_size), verbose=2)\nprediction= prediction > 0.5\nprediction","ebbbe693":"cm= confusion_matrix(test_data.classes, prediction)\nplot_confusion_matrix(cm, figsize=(5,5))\n\nprint(accuracy_score(test_data.classes, prediction))\nprint(classification_report(test_data.classes, prediction))","74725cd0":"test_image= \"\/kaggle\/input\/files1\/Malaria Cells\/single_prediction\/Parasitised.png\"\ntest_image= load_img(test_image,target_size=(100, 100))\nprint(\"The following test image is of Parasitised Cell with label '0'\")\ntest_image","52d9b797":"test_image= img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis=0)\nprint(test_image.shape)","51d92991":"model.predict(test_image)","1ed4e0b4":"model.save(\"malaria2.h5\") ","490bf76d":"# saving 1st model\nmodel_1.save(\"malaria_cnn.h5\")","f01d087c":"### <span style=\"font-family:serif; color:blue\"> Now let's take a look at a few pictures of what the uninfected and parasitized cells look like.<\/span>","7966e2df":"### *Checking model performance through test data*","2624a2ed":"### Saving Model","03f934d0":"image from RCP Journals","8c127acc":"# <span style=\"font-family:serif; color:blue\"> Model Evaluation<\/span>","8ddf87a6":"# <span style=\"font-family:serif; color:blue\"> Using Transfer Learning- InceptionV3 Model<\/span>","e725536f":"### <span style=\"font-family:serif; color:blue\"> Let's find out the total number of Uninfected and Parasitized images in the train and test directories:<\/span>","50acc34d":"### <span style=\"font-family:serif; color:blue\"> Let's define each directories<\/span>","a6ce8a11":"# <span style=\"font-family:serif; color:blue\"> Model Building - CNN<\/span>","46c55a2d":"### *Finally let's predict the image present in the single_prediction directory with our second model*","c6e0b977":"# <span style=\"font-family:serif; color:blue\"> Import Libraries<\/span>","e6d17bfd":"<center>\n<span style=\"font-size:30px; color:coral; font-family:ui-rounded; text-decoration:underline\"> CNN + InceptionV3  <\/span>\n<\/center> ","8dc6ab8e":"### <span style=\"font-family:serif; color:blue\"> Lets's see what labels are assigned to each class<\/span>","c99bfe0d":"![F1.large.jpg](attachment:b8348d29-917b-49ac-9b57-cfe3ad92cea2.jpg)","1e933a12":"### *Model fitting*","8a6f92ab":"## <span style=\"font-family:serif; color:blue\"> Generating Data using augmentation<\/span>","a9581352":"## Model Evaluation","a453e107":"<center>\n<span style=\"font-size:55px; color:purple; font-family:cursive\"> Detection of Malaria Cell <\/span>\n<\/center>    ","a11eb34f":"### *Creating Fully Connected Layer*"}}