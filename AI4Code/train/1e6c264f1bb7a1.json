{"cell_type":{"a6af2f30":"code","c22e9d17":"code","3d6988c2":"code","4e94c59d":"code","8f13ef74":"code","be349aed":"code","4cbf290f":"code","ca9d9bbd":"code","124d21da":"code","edcfc2cf":"code","4aedb02f":"code","458bafcf":"code","2bf4e38a":"code","93985147":"code","19834062":"code","6d411be1":"code","e85554c3":"markdown","7f3b62da":"markdown","ff7d2893":"markdown","fa5374f9":"markdown","26e9a688":"markdown","d1a5ec50":"markdown","79b3f835":"markdown","9d6389fc":"markdown","325d7cc8":"markdown","1d7102af":"markdown","a5418dc8":"markdown","02a6d42a":"markdown","4c899162":"markdown","30b15089":"markdown"},"source":{"a6af2f30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import sigmoid_kernel\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c22e9d17":"credits = pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv')\nmovies_df = pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')","3d6988c2":"credits.head()","4e94c59d":"movies_df.head()","8f13ef74":"credits_column_renamed = credits.rename(columns = {\"movie_id\": \"id\"})\nmovies_df_merged = movies_df.merge(credits_column_renamed, on= 'id')\nmovies_df_merged.head()","be349aed":"movies_cleaned_df = movies_df_merged[['id','original_title', 'overview']]\nmovies_cleaned_df.head()","4cbf290f":"movies_cleaned_df.head(1)['overview'][0]","ca9d9bbd":"tfv = TfidfVectorizer(min_df = 3, max_features=None, strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,3))\n\n# filling NaNs with empty strings\nmovies_cleaned_df.overview = movies_cleaned_df.overview.fillna('')","124d21da":"# Sparse matrix\ntfv_matrix = tfv.fit_transform(movies_cleaned_df.overview)\ntfv_matrix.shape","edcfc2cf":"# Transforms the matrix value range to [0,1]\nsig = sigmoid_kernel(tfv_matrix, tfv_matrix)","4aedb02f":"sig[0]","458bafcf":"indices = pd.Series(movies_cleaned_df.index, index = movies_cleaned_df.original_title).drop_duplicates()\nindices","2bf4e38a":"def give_rec(title, sig = sig):\n    # get index corresponding to the original_title\n    idx = indices[title]\n    \n    # Get the list of ids along with pairwise similarity scores of the provided idx with other ids\n    # Sort the movies\n    # Selecting top 10 movies for recommendation\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores,key = lambda x: x[1], reverse=True)\n    sig_scores = sig_scores[1:11]\n    \n    # Movie indices \n    movies_indices = [i[0] for i in sig_scores]\n    \n    # Top 10 similar movies\n    return movies_cleaned_df.original_title.iloc[movies_indices]","93985147":"give_rec(\"Toy Story 3\")","19834062":"give_rec(\"Spectre\")","6d411be1":"give_rec(\"Newlyweds\")","e85554c3":"## Imports","7f3b62da":"## Reversing mapping of indices and movie titles","ff7d2893":"Example overview","fa5374f9":"## Advantages \n\n1. This recommendation doesn't require user data to train on. \n2. It requires only the item data\n3. The core concept is Natural Language Processing. Hence there is a ready made preprocessing pipeline to be followed which works for any domain.\n4. This acts more like a script which can be run after some amount of item data is available. Best usecase for early stage start-ups.\n5. Requires less resources (training time, processing power) as the algorithm used is standard and has a very high explainability.\n\n***\n\n## Disadvantages\n\n1. The item **must** have item name and item description\n2. Since we run the code as a script, there are chances that the recommendation might be skewed. Solution, more the amount of data, better the recommendation\n3. There must be some naming conventions for the item name and item description so that they are interpretable to the algorithm\n4. The regex filtering changes domain to domain","26e9a688":"## Transforming range of tfv_matrix using sigmoid kernel","d1a5ec50":"In this type of recommendation system, we try to find similarity between items. There are two ways to do it :\n\n- Statistical approach -> Weighted hybrid technique, requires item data + generic data (total ratings, popularity)\n- NLP approach -> Requires item data only, Standard preprocessing steps. Can be used as a script","79b3f835":"## Kids Recommendation (Animated)","9d6389fc":"## Merging both dataframes and keeping only required columns","325d7cc8":"![](https:\/\/qph.fs.quoracdn.net\/main-qimg-6ab7369356c16f17ac39fbb83d5d56c1)","1d7102af":"***The only thing we need to take care is that regex differes for different usecases***","a5418dc8":"![](https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2018\/06\/Screenshot-from-2018-06-21-10-57-38.png)","02a6d42a":"## Action movie recommendation (James Bond)","4c899162":"## Romance recommendation","30b15089":"# Content based recommendation system | *Domain: Movie Recommendation*"}}