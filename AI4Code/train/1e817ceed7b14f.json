{"cell_type":{"0151a0c3":"code","7ada9f0b":"code","f95ffc11":"code","0d5626d3":"code","94e17c37":"code","7e16c4bb":"code","25f128b8":"code","13b23d8a":"code","0dea9585":"code","ffc53096":"markdown","d1dd308f":"markdown","fdcd8906":"markdown","17992ee5":"markdown","c364bcb7":"markdown","06925dbb":"markdown","9608f0c5":"markdown","a046e920":"markdown","3cbc6ce3":"markdown"},"source":{"0151a0c3":"# import\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport os\nimport re\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score,precision_score, recall_score,f1_score\n\ndef print_metrics(y_train,y_pred):\n    conf_mx = confusion_matrix(y_train,y_pred)\n    print(conf_mx)\n    print (\"------------------------------------------\")\n    print (\" Accuracy    : \", accuracy_score(y_train,y_pred))\n    print (\" Precision   : \", precision_score(y_train,y_pred))\n    print (\" Sensitivity : \", recall_score(y_train,y_pred))\n    print (\"------------------------------------------\")","7ada9f0b":"# load data\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsubmit_df = pd.read_csv('..\/input\/gender_submission.csv')\ntarget = train_df[\"Survived\"]","f95ffc11":"print('_'*80)\nprint(\"Value counts in 'Survived' in train data (0 = No; 1 = Yes) : \\n\")\nprint(train_df[\"Survived\"].value_counts())\nprint('_'*80)","0d5626d3":"# Concat TEST and TRAIN data into df\n###########################################\ndel train_df[\"Survived\"]\ntrain_df[\"Train\"]=1\ntest_df[\"Train\"]=0\ndf = pd.concat([train_df,test_df])\ndf.reset_index()\n\n\n# Feature engineering\n###########################################\n\n# Ticket Count\ntemp = df['Ticket'].value_counts()\nTicketCount = pd.DataFrame(temp.values,columns=['TicketCount'])\nTicketCount['Ticket']=temp.index\ndf = pd.merge(df,TicketCount,on='Ticket', how='left')\ndf['TicketCount'].fillna(0)\n\n# Name Length\ndf['NameLength'] = df['Name'].apply(lambda x : len(x))\ndf['NameLength'] = ((df.NameLength)\/15).astype(np.int64)+1\n\n# Ticket Letter\ndf['TicketLetter'] = df['Ticket'].apply(lambda x : str(x)[0]) \ndf['TicketLetter'] = df['TicketLetter'].apply(lambda x : re.sub('[0-9]','N',x))\n#df['TicketLetter'] = df['TicketLetter'].map({'A':0, 'W':1, 'L':2, 'S':3, 'C':4, 'N':5, 'F':6, 'P':7}).astype(int)\n\n# Extract Title from Name\ndf['Title'] = df.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())\nnormalized_titles = {\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n}\ndf['Title'] = df['Title'].map(normalized_titles)\n\n# Family Size\ndf[\"FamilySize\"] = df['SibSp'] + df['Parch'] + 1\nbins = [-1,1, 2, 3,4, np.inf]\nlabels = ['ONE','TWO', 'THREE', 'FOUR','BIG']\ndf['FamilyGroup'] = pd.cut(df[\"FamilySize\"], bins, labels = labels)\n\n# Embarked\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n\n# Group By Age\ndf[\"Age\"] = df.groupby(['Sex','Pclass','Title'])[\"Age\"].transform(lambda x: x.fillna(x.median()))\nbins = [-1, 14,20, 30, 50, np.inf]\nlabels = ['Child','Young','YoungAdult', 'Adult', 'Senior']\ndf['AgeGroup'] = pd.cut(df[\"Age\"], bins, labels = labels)\n\n# Letter of the cabin\ndf[\"Cabin\"] = df[\"Cabin\"].str[0:1]\ndf[\"Cabin\"] = df[\"Cabin\"].fillna('T')\n#df['Cabin'] = df['Cabin'].map({'T':0, 'A':1, 'G':2, 'C':3, 'F':4, 'B':5, 'E':6, 'D':7}).astype(int)\n\n# Group Fare\ndf['Fare'] = df['Fare'].fillna(-1)\nbins = [-1,0,8, 32, 50, np.inf]\nlabels = ['Unknown','Low', 'Medium', 'High','Elite']\ndf['FareGroup'] = pd.cut(df[\"Fare\"], bins, labels = labels)\n\n# Filter Columns\nfilterCol = ['Pclass',  'Sex', 'AgeGroup', 'SibSp', 'Parch','FareGroup', 'Embarked','Title','Cabin', 'FamilyGroup','NameLength','TicketLetter','TicketCount']\n# OneHotEncoder\ndf_f = pd.get_dummies(df[filterCol])\ncolumns = df_f.columns\n\n# split between train and test\nfeatures = df_f[df[\"Train\"]==1].copy()\nfeatures_test = df_f[df[\"Train\"]==0].copy()\n# Original train data\ntrain_df = pd.concat([df[df[\"Train\"]==1].copy(),target],axis=1)","94e17c37":"\nsns.set(style=\"darkgrid\")\ng2 = sns.FacetGrid(train_df, col='Survived',height=4,aspect=1)\nbins = np.linspace(0, 60, 13)\ng2.map(plt.hist, 'Age',color=\"steelblue\", bins=bins,lw=0);\n\ng2 = sns.FacetGrid(train_df, col='Survived',height=4,aspect=1)\nbins = np.linspace(0, 60, 13)\ng2.map(plt.hist, 'Fare',color=\"steelblue\", bins=bins,lw=0);\n\nsns.catplot(x='Sex', col='Survived', kind='count', data=train_df);\nsns.catplot(x='Pclass', col='Survived', kind='count', data=train_df);\nsns.catplot(x='Parch', col='Survived', kind='count', data=train_df);\nsns.catplot(x='Embarked', col='Survived', kind='count', data=train_df);\nsns.catplot(x='SibSp', col='Survived', kind='count', data=train_df);\nsns.catplot(x='FamilySize', col='Survived', kind='count', data=train_df);\nsns.catplot(x='Title', col='Survived', kind='count', data=train_df);\nsns.catplot(x='Cabin', col='Survived', kind='count', data=train_df);","7e16c4bb":"######################################################\n# Train random forest with a GridSearchCV\n######################################################\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparam1={'max_depth' : [10,11,13,15],'n_estimators' : [100,500,1000]}\nparam = dict(     \n    max_depth = [n for n in range(5, 15)],     \n    min_samples_split = [n for n in range(2, 6)], \n    min_samples_leaf = [n for n in range(2, 5)],     \n    n_estimators = [50,100],\n    #criterion = ['gini','entropy']    \n)\ngrid_search = GridSearchCV(RandomForestClassifier(), param, cv=7)\ngrid_search.fit(features, target)\nprint(\"Best parameters {}\".format(grid_search.best_params_))\nprint(\"Best score {:.4f}\".format(grid_search.best_score_))\nresult = grid_search.predict(features)\nprint_metrics(target,result)","25f128b8":"forest = RandomForestClassifier(random_state = 1)\nrandom_forest = forest.fit(features, target)\nprint('Score = ',random_forest.score(features, target))\nprint_metrics(target,random_forest.predict(features))","13b23d8a":"columns = df_f.columns\nimportances = list(zip(grid_search.best_estimator_.feature_importances_,columns))\nimportances.sort(reverse=True)\npd.DataFrame(importances, index=[x for (_,x) in importances]).plot(kind = 'bar');","0dea9585":"y_sub= grid_search.predict(features_test)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": y_sub\n    })\nsubmission.to_csv('titanic.csv', index=False)\n","ffc53096":"### Importation of the libraries","d1dd308f":"### Feature engineering","fdcd8906":"### Balance between survived people and not survived\nCheck if the dataset is unbalanced - and no, it is not.\n","17992ee5":"## Titanic - Train random forest with a GridSearchCV\n> The titanic was sinking,\n> the gigangic ship had hit an iceberg.\n> Land war far, far away.\n\nI Survived the Sinking of the Titanic, 1912 - Lauren Tarshis\n\n### Description of the features\n\n* Survived : (0 = No; 1 = Yes) \n* pclass : Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd) \n* sex : {'female': 1, 'male': 0}\n* age : Passager age\n* sibsp : Number of Siblings\/Spouses Aboard \n* parch : Number of Parents\/Children Aboard \n* ticket : Ticket Number \n* fare : Passenger Fare \n* cabin : Cabin \n* embarked : Port of Embarkation {'S': 0, 'C': 1, 'Q': 2}  (C = Cherbourg; Q = Queenstown; S = Southampton) ","c364bcb7":"### Histograms of characteristics according to the survived property\nSurvived : 0 = No    1 = Yes\n\nThis is a visual exploration of the data - it is more likely to perish with these features :\n* male\n* age ","06925dbb":"## Importances : find the feature that best separates the outcomes\n","9608f0c5":"## Prediction on test data ","a046e920":"## Train a random forest with default parameters\nOverfitting ?\n","3cbc6ce3":"## Train random forest with a grid search\nA grid search is computed in order to optimize the values of the parameters.\n\nThe cross validation is performed with cv Folds\n"}}