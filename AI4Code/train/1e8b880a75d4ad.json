{"cell_type":{"c0b18720":"code","4801d8fd":"code","c4460553":"code","8cdee4c8":"code","35161d58":"code","2cdc72c4":"code","0b6980a7":"code","35462156":"code","418ef3cc":"code","22cfe945":"code","86a7fa8b":"code","0d55a1db":"code","8f90a892":"code","c0a53d72":"code","c0ccf763":"code","543a78a8":"code","5d026479":"code","424ff718":"code","ce0fb44d":"code","5ac77369":"code","8d180c84":"code","097ef5fa":"code","25e5fb69":"code","9f26a899":"code","42689905":"markdown","d25a981b":"markdown","ddbaf468":"markdown","8f789252":"markdown","1f4ab8b2":"markdown","4105b52f":"markdown","5ac6aae1":"markdown","d91afd3a":"markdown","54fef154":"markdown","44a63c81":"markdown","402549c8":"markdown","f735ce48":"markdown"},"source":{"c0b18720":"from IPython.display import YouTubeVideo      \nYouTubeVideo('o9IxCpl7U54')","4801d8fd":"import numpy as np\nimport pandas as pd","c4460553":"!unzip ..\/input\/word2vec-nlp-tutorial\/unlabeledTrainData.tsv.zip","8cdee4c8":"df = pd.read_csv(\".\/unlabeledTrainData.tsv\",delimiter=\"\\t\",quoting=3,header=0)","35161d58":"df.head(10)","2cdc72c4":"import re,string","0b6980a7":"def clean_string(string):                                                         # The entire document is cleaned defining clean_string\n  try:\n    string=re.sub(r'^https?:\\\/\\\/<>.*[\\r\\n]*','',string,flags=re.MULTILINE)\n    string=re.sub(r\"[^A-Za-z]\",\" \",string)\n    words=string.strip().lower().split()\n    return \" \".join(words)\n  except:\n    return \" \"","35462156":"df['clean_review']=df.review.apply(clean_string)                                  # Finally cleaned format is applied on the reviews\n","418ef3cc":"print (\"No.of samples \\n:\",(len(df)))\ndf.head()","22cfe945":"!pip install gensim --quiet  ","86a7fa8b":"import gensim","0d55a1db":"Document=[]\nfor doc in df['clean_review']:\n  Document.append(doc.split(' '))    ","8f90a892":"len(Document)","c0a53d72":"print(len(Document[10]))                                                          # Lenth of the 10th document ,  It has 524 words in it\nprint(Document[10])","c0ccf763":"# Training the Word 2 Vec model\nmodel=gensim.models.Word2Vec(Document,                                           # List of reviews\n                          min_count=10,                                          # we want words appearing atleast 10 times in the vocab otherwise ignore \n                          workers=4,                                             # Use these many worker threads to train the model (=faster training with multicore machines\n                           size=50,                                              # it means aword is represented by 50 numbers,in other words the number of neorons in hidden layer is 50 \n                          window=5)                                              # 5 neighbors on the either side of a word","543a78a8":"print(len(model.wv.vocab))   # Now the vocab contains 28322 uinque words","5d026479":"print(model.wv.vector_size) # It means each vector has 50 numbers in it or in other words each word is vector of 5o numbers that we predefined","424ff718":"model.wv.vectors.shape  # Dimension of the the entire corpus  ","ce0fb44d":"model.wv.most_similar(\"beautiful\")                                                # 10 similar words beautiful,the maximum similarity is 1,minimum is 0.When they are completely similar the \n                                                                                  # Value will be 1 , when completely dissimilar,the value will be 0.","5ac77369":"model.wv.most_similar(\"princess\")                                                  # 10 similar words returned with numbers","8d180c84":"model.wv.doesnt_match(\"she talked to me in the evening publicly\".split())         # publicly does not match in the sentence given","097ef5fa":"model.wv[\"right\"]                                                                  # right word is represented by 50 numbers in other words the word \"right\" is vector of 50 numbers\n                                                                                   # 50 numbers are summarized weights because these numbers are obtained in the hidden layer of predefined 50 neurons","25e5fb69":"model.wv['great']","9f26a899":"model.save(\"word2vec movie-50.model\")                                                    # We save this model for further use.\n                                                                                   # Google has such many pre-trained models","42689905":"**Let us explore split reviews**","d25a981b":"**Since we are going to work with words, so we are required to split the each review so that we can have word tokens.**","ddbaf468":"**Let's check the dimension of a vector i.e. the number of words that represent a word**","8f789252":"Above we defined a function called **clean_string** & this function we have applied on the raw review column and created a new column(**clean_review**) to save the cleaned reviews.","1f4ab8b2":"# The data\n## About the data\nThe analysis seeks to establish transformation of word into vectors on any text. We are not concerned about whether the text data has label or not. The data set supplied consists of 50000 IMDB reviews with review ID on a certain movie with no labels.We'll use this unlabelled data to train a model. which can be applied on test data.","4105b52f":"Hello,\n\nAre you ready to build your own word2vec,\nWhy we want to build our own Word2Vec , when we work on #domain specific like Cancer Research article, sport article.... own w2v helps a lot.\n\nPlease let me know your input\/comments\ud83d\udc4e\ud83d\udc4d\nThank you","5ac6aae1":"Below the word **right** is represented by a dense 50 dimensional vector","d91afd3a":"#  Word2Vec with Gensim(The Word2Vec toolkit)\n\nGensim is an open source Python library for natural language processing, with a focus on topic modeling.Gensim was developed and is maintained by the Czech natural language processing researcher **Radim \u0158eh\u016f\u0159ek** and his company RaRe Technologies.\n\nIt is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling. Most notably for this tutorial, it supports an implementation of the** Word2Vec word embedding** for learning new word vectors from text.\n\nIt also provides tools for loading pre-trained word embeddings in a few formats and for making use and querying a loaded embedding.\n\n\n### Objective\n\nIn this tutorial, we dig a little \"deeper\" into sentiment analysis. Google's Word2Vec is a deep-learning inspired method that focuses on the meaning of words. Word2Vec attempts to understand meaning and **semantic relationships** among words. It works in a way that is similar to deep approaches, such as recurrent neural nets or deep neural nets, but is computationally more efficient. This tutorial focuses on Word2Vec for sentiment analysis.","54fef154":"## Saving the model","44a63c81":"If we look at the data now, we'll not notice any punctuations in the **clean_review** column.","402549c8":"##  Data Cleaning\nWe've gone through the reviews & detected punctuations in many reviews.The punctuations don't contribute anything to our analysis & moreover they are considered as unique word & distort the meaning of other words.This is why the data needs to be cleaned before we jump into core analysis.","f735ce48":"### Let's explore some interesting results of word2vec experiment\n"}}