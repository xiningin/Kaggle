{"cell_type":{"0089be8c":"code","0f7df50e":"code","89e0cfb3":"code","e31407f9":"code","7fe6f889":"code","ca737dcf":"code","b3207c7b":"code","4c69f838":"code","0ac139c6":"code","ae71cc5c":"code","029d38d9":"code","67be69d8":"code","793bdb75":"code","f7ffd306":"markdown","e2643098":"markdown","e891a686":"markdown","22db280d":"markdown","c9e8fe50":"markdown","2a73d104":"markdown","98e1c876":"markdown","32ca4265":"markdown","83159556":"markdown","820fac63":"markdown","5d6862f1":"markdown","fa4da7f0":"markdown","5c7a4dfd":"markdown","bc43a21d":"markdown"},"source":{"0089be8c":"##################################################\n# Imports\n##################################################\n\nimport numpy as np\nimport cv2\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n##################################################\n# Custom imports\n##################################################\n\nimport tensorflow as tf\n# from keras.callbacks import ReduceLROnPlateau\nfrom sklearn import preprocessing\nimport datetime\n\n##################################################\n# Params\n##################################################\n\nDATA_BASE_FOLDER = '\/kaggle\/input\/image-classification-fashion-mnist'","0f7df50e":"##################################################\n# Load dataset\n##################################################\n\nx_train = np.load(os.path.join(DATA_BASE_FOLDER, 'train.npy'))\nx_valid = np.load(os.path.join(DATA_BASE_FOLDER, 'validation.npy'))\nx_test = np.load(os.path.join(DATA_BASE_FOLDER, 'test.npy'))\ny_train = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'train.csv'))['class'].values\ny_valid = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'validation.csv'))['class'].values\ny_labels = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n# Plot random images of different classes\nplt.figure(figsize=(25, 5))\nfor idx in range(20):\n    plt.subplot(1, 20, idx + 1)\n    img = x_train[idx].reshape(28, 28)\n    plt.title(f'{y_labels[y_train[idx]]}')\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\nplt.show()","89e0cfb3":"##################################################\n# Normalization of the input data\n##################################################\n\nx_train = preprocessing.normalize(x_train)\nx_valid = preprocessing.normalize(x_valid)\nx_test = preprocessing.normalize(x_test)","e31407f9":"##################################################\n# Process the data here, if needed\n##################################################\n\nprint(\"### Initial shape ###\")\nprint(\"x_train\",x_train.shape)\nprint(\"x_valid\",x_valid.shape)\nprint(\"x_test\",x_test.shape)\n\nx_train = x_train.reshape(x_train.shape[0],28,28,1)\nx_valid = x_valid.reshape(x_valid.shape[0],28,28,1)\nx_test = x_test.reshape(x_test.shape[0],28,28,1)\n\nprint(\"### Final shape ###\")\nprint(\"x_train\",x_train.shape)\nprint(\"x_valid\",x_valid.shape)\nprint(\"x_test\",x_test.shape)","7fe6f889":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256,activation='relu'),\n    tf.keras.layers.Dropout(0.35),\n    tf.keras.layers.Dense(10,activation='softmax')\n])\n\nmodel.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=0.0001)\n\nhistory = model.fit(x_train,y_train,epochs=20,validation_data=(x_valid,y_valid),verbose=1,callbacks=[reduce_lr])","ca737dcf":"# Model\nmodel = tf.keras.models.Sequential([\n    # Add convolution 2D\ntf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 padding='same',\n                 input_shape=(28, 28, 1)),\ntf.keras.layers.Conv2D(64, \n                 kernel_size=(3, 3), \n                 activation='relu',padding='same'),\ntf.keras.layers.BatchNormalization(),\ntf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\ntf.keras.layers.Dropout(0.3),\ntf.keras.layers.Conv2D(128, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 padding='same',\n                 input_shape=(28, 28, 1)),\ntf.keras.layers.Conv2D(128, \n                 kernel_size=(3, 3), \n                 padding='same',\n                 activation='relu'),\ntf.keras.layers.BatchNormalization(),\ntf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\ntf.keras.layers.Dropout(0.3),\ntf.keras.layers.Conv2D(256, kernel_size=(3, 3),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 padding='same',\n                 input_shape=(28, 28, 1)),\ntf.keras.layers.Conv2D(256, \n                 kernel_size=(3, 3), \n                 padding='same',\n                 activation='relu'),\ntf.keras.layers.Conv2D(256, \n                 kernel_size=(3, 3), \n                 padding='same',\n                 activation='relu'),\ntf.keras.layers.BatchNormalization(),\ntf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\ntf.keras.layers.Dropout(0.3),\n\n#model.add(Conv2D(128, (3, 3), activation='relu'))\ntf.keras.layers.Flatten(),\ntf.keras.layers.Dense(2048, activation='relu'),\ntf.keras.layers.Dropout(0.3),\ntf.keras.layers.Dense(512, activation='relu'),\ntf.keras.layers.Dense(10, activation='softmax')\n])\n\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=\"Adam\",\n              metrics=['accuracy'])\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=3, min_lr=0.0001)\n\nhistory = model.fit(x_train,y_train,epochs=100,validation_data=(x_valid,y_valid),verbose=1,callbacks=[reduce_lr])","b3207c7b":"##################################################\n# Plot\n##################################################\n\nfig, (p1,p2,p3) = plt.subplots(1, 3,figsize=(25,5))\np1.plot(history.history['accuracy'])\np1.plot(history.history['val_accuracy'])\np1.set_title(\"model accuracy\")\np1.set(xlabel='epoch',ylabel=\"accuracy\")\np1.legend(['train', 'validation'], loc='upper left')\n\np2.plot(history.history['loss'])\np2.plot(history.history['val_loss'])\np2.set_title(\"model loss\")\np2.set(xlabel='epoch',ylabel=\"model loss\")\np2.legend(['train', 'valid'], loc='upper left')\n\np3.plot(history.history['lr'])\np3.set_title('LR')\np3.set(xlabel=\"epoch\",ylabel='lr')","4c69f838":"from sklearn import neighbors\nstart = datetime.datetime.now()\nprint(\"fitting\")\nclf = neighbors.KNeighborsClassifier()\nprint(clf)\nclf.fit(x_train,y_train)\nprint(\"evaluating\")\naccuracy = clf.score(x_valid[:100],y_valid[:100])\nprint(\"accuracy\", accuracy)\nend = datetime.datetime.now()\ndifference = end-start\nprint(difference.seconds)","0ac139c6":"from sklearn import svm\nstart = datetime.datetime.now()\nclf = svm.SVC(kernel=\"poly\",degree=6)\nprint(clf)\nprint(\"# training\")\n# clf.fit(x_train[:10000],y_train[:10000])\nclf.fit(x_train,y_train)\ntraining_difference = datetime.datetime.now()-start\nprint(\"trained in \",training_difference.seconds,\"seconds\")\nprint(\"# evaluating\")\naccuracy = clf.score(x_valid,y_valid)\nprint(\"accuracy\", accuracy)\ntest_difference = datetime.datetime.now()-start-training_difference\nprint(\"tested in\",test_difference.seconds,\"seconds\")\ndifference = datetime.datetime.now()-start\nprint(\"total time\",difference.seconds,\"seconds\")","ae71cc5c":"from sklearn.ensemble import RandomForestClassifier\nstart = datetime.datetime.now()\nclf = RandomForestClassifier()\n# clf = RandomForestClassifier(max_depth=2, random_state=0)\nprint(clf)\nprint(\"# training\")\n# clf.fit(x_train[:100],y_train[:100])\n# clf.fit(x_train[:1000],y_train[:1000])\n# clf.fit(x_train[:10000],y_train[:10000])\nclf.fit(x_train,y_train)\ntraining_difference = datetime.datetime.now()-start\nprint(\"trained in \",training_difference.seconds,\"seconds\")\nprint(\"# evaluating\")\n# accuracy = clf.score(x_valid[:100],y_valid[:100])\n# accuracy = clf.score(x_valid[:1000],y_valid[:1000])\naccuracy = clf.score(x_valid,y_valid)\nprint(\"accuracy\", accuracy)\ntest_difference = datetime.datetime.now()-start-training_difference\nprint(\"tested in\",test_difference.seconds,\"seconds\")\ndifference = datetime.datetime.now()-start\nprint(\"total time\",difference.seconds,\"seconds\")","029d38d9":"from sklearn.linear_model import LogisticRegression\nstart = datetime.datetime.now()\nclf = LogisticRegression(random_state=0, max_iter = 10000)\nprint(clf)\nprint(\"# training\")\n# clf.fit(x_train[:100],y_train[:100])\n# clf.fit(x_train[:1000],y_train[:1000])\n# clf.fit(x_train[:10000],y_train[:10000])\nclf.fit(x_train,y_train)\ntraining_difference = datetime.datetime.now()-start\nprint(\"trained in \",training_difference.seconds,\"seconds\")\nprint(\"# evaluating\")\n# accuracy = clf.score(x_valid[:100],y_valid[:100])\n# accuracy = clf.score(x_valid[:1000],y_valid[:1000])\naccuracy = clf.score(x_valid,y_valid)\nprint(\"accuracy\", accuracy)\ntest_difference = datetime.datetime.now()-start-training_difference\nprint(\"tested in\",test_difference.seconds,\"seconds\")\ndifference = datetime.datetime.now()-start\nprint(\"total time\",difference.seconds,\"seconds\")","67be69d8":"##################################################\n# Evaluate the model here\n##################################################\n\n# Use this function to evaluate your model\ndef accuracy(y_pred, y_true):\n    '''\n    input y_pred: ndarray of shape (N,)\n    input y_true: ndarray of shape (N,)\n    '''\n    return (1.0 * (y_pred == y_true)).mean()\n\n# Report the accuracy in the train and validation sets.\n\ntrain_predict = model.predict_classes(x_train)\nvalid_predict = model.predict_classes(x_valid)\n\ntrain_acc = accuracy(train_predict,y_train)\nvalid_acc = accuracy(valid_predict,y_valid)\nprint(\"train accurancy: \",train_acc)\nprint(\"valid accurancy: \",valid_acc)","793bdb75":"##################################################\n# Save your test prediction in y_test_pred\n##################################################\n\ny_test_pred = model.predict_classes(x_test)\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\nsubmission.to_csv('my_submission.csv', index=False)","f7ffd306":"# Very heavy CNN (do not start this unless you have 2 hours to waste)","e2643098":"# Random forest model test","e891a686":"# Plot accuracy and loss\nHere we compare the accuracy and the loss over the epochs for both **training data** and **validation data**.","22db280d":"# Logistic regression model test","c9e8fe50":"# Normalization\nHere we normalize the data in order to eliminate small differences between inputs.","2a73d104":"# Model\n\nHere you have to implement a model (or more models, for finding the most accurate) for classification.\n\nYou can use the [`sklearn`](https:\/\/scikit-learn.org\/stable\/) (or optionally other more advanced frameworks such as [`pytorch`](https:\/\/pytorch.org\/) or [`tensorflow`](https:\/\/www.tensorflow.org\/)) package that contains a pool of models already implemented that perform classification. (SVMs, NNs, LR, kNN, ...)","98e1c876":"# Send the submission for the challenge","32ca4265":"# Welcome to the Fashion-MNIST Challenge!\n\nWebsite reference: https:\/\/github.com\/zalandoresearch\/fashion-mnist","83159556":"# Reshaping\nHere we reshape the data in order to feed it to the algorithm in the correct format.","820fac63":"# Best model (CNN)\nThis is the best CNN model we could build with only 2 layers: one **convolutional** layer and one **dense** (_fully connected_) layer.","5d6862f1":"# SVM model test","fa4da7f0":"# Evaluation","5c7a4dfd":"# Dataset\n\nThe dataset contains 50k train + 10k validation images of 10 different categories ('T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot').\n\nEach image is a 28x28 grayscale, and for simplicity here is flattened into a 784 dimensional vector.","bc43a21d":"# KNN model test"}}