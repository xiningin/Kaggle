{"cell_type":{"2ed88d5d":"code","dab145cb":"code","24947fdf":"code","eaa1ff03":"code","4b5726cb":"code","7e958364":"code","975e9e29":"code","94afc033":"code","812a4d03":"code","2e247e34":"code","3a1811e2":"code","a1e8ca0b":"code","3a243fa3":"code","974ae3cb":"code","67b3095c":"code","7c35f938":"code","bcf6063d":"code","064e3203":"code","99799f8a":"code","e93cc80a":"code","8410880b":"code","d46badef":"code","35ac1771":"code","c84388a2":"code","4298d706":"code","5acff278":"code","c61ab95f":"code","04175a86":"code","abead9ad":"code","29dc778a":"code","66286cc3":"code","041a1601":"code","8d333eef":"code","76198858":"code","de1765ad":"code","66566e4c":"code","8603a69d":"code","f79aa812":"code","51c07dc0":"code","e7140b26":"code","6377e4c4":"code","c543d451":"code","3032182c":"code","7d3f52fa":"code","20214181":"code","d3b57618":"code","38dcfb11":"code","d05ab4cd":"code","cc0dc60e":"code","166f689e":"code","e6e05787":"code","ff6c0ec9":"code","e07fa792":"code","dacdb549":"code","7cd3bf52":"code","73459adc":"code","25d9c8ec":"code","97d708f1":"code","b7211066":"markdown","10aaa076":"markdown","f3f77a89":"markdown","1a4dc073":"markdown","2c9bea5f":"markdown","8054f176":"markdown","3c00e148":"markdown","84bba756":"markdown","83a46aaf":"markdown","e1adab33":"markdown","24ab1e69":"markdown","32d40cb9":"markdown","3dfc8727":"markdown","4ef8ef25":"markdown","acc02fa8":"markdown","7ce24380":"markdown","2efbd7e4":"markdown","9b9dc59a":"markdown","72d1d963":"markdown","043dcbaf":"markdown","891b7a5c":"markdown","b6303974":"markdown","dade4f56":"markdown","00c0efec":"markdown","0e2e6bd9":"markdown","c7cb33ec":"markdown","f699c0b0":"markdown","d6e11508":"markdown","fa13c894":"markdown","1ed2ef51":"markdown","ec156675":"markdown","6f5a377c":"markdown","f527750a":"markdown","712658b8":"markdown","862c5991":"markdown","67f08cf9":"markdown","396a263a":"markdown","d86cf44f":"markdown","6520135c":"markdown","58cad1b6":"markdown","c0c35f54":"markdown","4fa392df":"markdown","f0c6ae73":"markdown","c972643b":"markdown","d5fcf73a":"markdown","279a70d6":"markdown","187f78c6":"markdown","55f026c2":"markdown","2f861072":"markdown","413d8cfc":"markdown","aa3d4952":"markdown","a714db11":"markdown","be1ab4d2":"markdown","65930113":"markdown","51aabecf":"markdown","181d6610":"markdown","982e1833":"markdown","2b62519b":"markdown","525be36e":"markdown"},"source":{"2ed88d5d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.float_format', lambda x: '%.4f' % x)","dab145cb":"# Loading two years of data in two different dataframes...\ndf_18=pd.read_csv(\"..\/input\/2021-kaggle-machine-learning-challenge\/2018_multipleChoiceResponses.csv\",header=1,low_memory=False)\ndf_21=pd.read_csv(\"..\/input\/2021-kaggle-machine-learning-challenge-dataset\/2021_kaggle_survey_responses.csv\",header=1,low_memory=False)\n\n\n# Insert a year column to each dataframe...\ndf_18.insert(0,'Year',2018)\ndf_21.insert(0,'Year',2021)\n\nprint(df_18.shape)\nprint(df_21.shape)","24947fdf":"# Dropping extra gender column in 2018 dataset..\ndf1=df_18.drop(['What is your gender? - Prefer to self-describe - Text','Which best describes your undergraduate major? - Selected Choice'],axis=1)\n\ndf1,df2=df1[df1.columns[0:7]],df_21[df_21.columns[0:7]]\n\ndf=df1.append([df2])\n\n# Adding a dummy variable....\ndf.insert(7,'Dummy',1)\n\ndf.columns=['Year',\"Duration(sec)\",'Gender','Age','Country',\"Highest level of education(till next two years)\",'Recent title','Dummy']\n\ndf.head()","eaa1ff03":"df.Gender.value_counts()","4b5726cb":"df['Gender']=df['Gender'].apply(lambda x:\"Male\" if x=='Man' else \"Female\" if x==\"Woman\" else x)\ndf.Gender.value_counts()","7e958364":"g1=df.groupby(['Year',\"Gender\"]).size().unstack(fill_value=0).stack().reset_index(name='count')\ng1.head(6)","975e9e29":"plt.figure(figsize=[15,8])\nsns.set_theme(style=\"darkgrid\")\np=sns.barplot(x='Gender',y='count',hue='Year',data=g1)\nfor i in p.patches:\n    p.annotate('{:.0f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()+1),ha='center',color='black',fontsize=11)\nplt.show()","94afc033":"df['Highest level of education(till next two years)'].value_counts()","812a4d03":"ed_dict={'Doctoral degree':['Doctoral degree','Professional degree','Professional doctorate'],\n        'College dropout':'Some college\/university study without earning a bachelor\u2019s degree',\n         'High school':'No formal education past high school'}\n\n\ndef ed_map(x):\n    for i in ed_dict:\n        if str(x) in ed_dict[i]:\n            return i\n    else:\n        return x\n\n\n        \ndf.insert(7,'Education level',df['Highest level of education(till next two years)'].apply(ed_map))\ndf.drop('Highest level of education(till next two years)',axis=1,inplace=True)\n\ndf['Education level'].value_counts()","2e247e34":"g2=df.pivot_table(index=['Year',\"Gender\"],columns='Education level'\n               ,values='Dummy',aggfunc=sum,\n                 fill_value=0).stack().reset_index(name='Count')\ng2.head()","3a1811e2":"plt.figure(figsize=[15,10])\nsns.set_theme(style=\"darkgrid\")\np=sns.barplot(x='Education level',y='Count',hue='Year',data=g2,ci=None)\nplt.legend(loc='upper left',shadow=True,fontsize=15,title='Year',title_fontsize=15)\nplt.xticks(size=12)\nplt.yticks(size=12)\nfor i in p.patches:\n    p.annotate('{:.0f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()+1),ha='center',color='black',fontsize=14)\nplt.show()","a1e8ca0b":"df.Age.value_counts()","3a243fa3":"df.Age=df.Age.apply(lambda x: '70-79' if x=='70+' else x)\ndf.Age.value_counts()","974ae3cb":"g3=df.pivot_table(index=['Year'],columns='Age'\n               ,values='Dummy',aggfunc=sum,\n                 fill_value=0).stack().reset_index(name='Count')\ng3.head()","67b3095c":"plt.figure(figsize=[18,12])\np=sns.barplot(data=g3,x='Age',y='Count',hue='Year',ci=None)\nplt.legend(loc='upper right',shadow=True,fontsize=20)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nfor i in p.patches:\n    p.annotate('{:.0f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()+1),ha='center',color='black',fontsize=14)\nplt.show()","7c35f938":"g4=df[(df.Gender=='Male')|(df.Gender=='Female')].groupby(['Gender','Age'])['Dummy'].sum()\ng4=g4.unstack(fill_value=0).stack().reset_index(name='Count')\ng4.head()","bcf6063d":"plt.figure(figsize=[20,12])\np=sns.barplot(data=g4,x='Age',y='Count',hue='Gender',hue_order=['Male','Female'])\nplt.legend(loc='upper right',shadow=True,fontsize=15)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nfor i in p.patches:\n    p.annotate('{:.0f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()),ha='center',color='black',fontsize=14)\nplt.show()","064e3203":"g5=df[(df.Gender=='Male')|(df.Gender=='Female')].groupby(['Gender','Age'])['Dummy'].sum().unstack(fill_value=0).stack().reset_index(name='Count')\n\ng5['Percent']=1\nsum_male=g5['Count'][g5['Gender']=='Male'].sum()\nsum_female=g5['Count'][g5['Gender']=='Female'].sum()\n\ng5['Percent'][g5['Gender']=='Male']=round(g5['Count']\/sum_male,2)*100\ng5['Percent'][g5['Gender']=='Female']=round(g5['Count']\/sum_female,2)*100\n\ng5.head()","99799f8a":"plt.figure(figsize=[20,9])\np=sns.barplot(data=g5,x='Age',y='Percent',hue='Gender',hue_order=['Male','Female'])\nplt.legend(loc='upper right',shadow=True,fontsize=15)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nfor i in p.patches:\n    p.annotate('{:.1f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()),ha='center',color='black',fontsize=14)\nplt.show()","e93cc80a":"g6=df[(df.Gender=='Male')|(df.Gender=='Female')].groupby(['Year','Age',\"Gender\"]).size().unstack(fill_value=0).stack().reset_index(name='Count')\ng6=g6.pivot_table(index=[\"Year\",\"Age\"],columns='Gender',values='Count').assign(Ratio=lambda r: round(r.Female \/ r.Male,2)).reset_index()\ncol=['Year','Age','Female','Male','Ratio']\ng6.columns=col\ng6.head()","8410880b":"plt.figure(figsize=[15,8])\nplt.legend(loc='upper right',title='Year',shadow=True,fontsize=20)\ng = sns.lineplot(data = g6, y  = 'Ratio', x = 'Age',hue='Year',palette=['Red','Green'])\nplt.show()","d46badef":"len(df['Recent title'].value_counts())","35ac1771":"# Map them into following groups:\njob_dict={'Data Analyst':['Data Analyst','Business Analyst','Marketing Analyst'],\n           'Student':['Student'],\n           'Others':['Data journalist','Salesperson','Other','Consultant','Developer Advocate','Principal Investigator'],\n           'Data Scientist':['Data Scientist','Research Scientist','Research Assistant'],\n            'Manager':['Product\/Project Manager','Program\/Project Manager','Manager','Cheif Officer','Product Manager'],\n            'Data Engineer':['Data Engineer','Software Engineer','DBA\/Database Engineer'],\n            'ML Engineer':['Machine Learning Engineer','Statistician'],\n             'Not employed':['Currently not employed','Not employed']}\n\n\ndef job_map(x):\n    for i in job_dict:\n        if x in job_dict[i]:\n            return i\n        \ndf.insert(7,'Job title',df['Recent title'].apply(job_map))\ndf.drop('Recent title',axis=1,inplace=True)\ndf.head()","c84388a2":"job=df['Job title'].value_counts().reset_index(name='Count')\njob=job.rename({'index':'Job'},axis=1)\njob","4298d706":"plt.figure(figsize=[20,10])\np=sns.countplot(data=df,x='Job title',hue='Year')\nplt.legend(loc='upper right',shadow=True,title='Year',fontsize=15)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nfor i in p.patches:\n    p.annotate('{:.0f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()+1),ha='center',color='black',fontsize=14)\nplt.show()","5acff278":"g7=df[(df.Gender=='Male')|(df.Gender==\"Female\")].groupby(['Gender','Job title'])['Dummy'].sum().unstack(fill_value=0).stack().reset_index(name='Count')\n\ng7['Percent']=1\n\nsum_male=g7['Count'][g7['Gender']=='Male'].sum()\nsum_female=g7['Count'][g7['Gender']=='Female'].sum()\n\ng7['Percent'][g7['Gender']=='Male']=round(g7['Count']\/sum_male,2)*100\ng7['Percent'][g7['Gender']=='Female']=round(g7['Count']\/sum_female,2)*100\n\ng7.head()","c61ab95f":"plt.figure(figsize=[20,10])\np=sns.barplot(data=g7,x='Job title',y='Percent',hue='Gender',ci=None)\nplt.legend(loc='upper left',shadow=True,title='Gender',fontsize=18)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nfor i in p.patches:\n    p.annotate('{:.4}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()),ha='center',color='black',fontsize=14)\nplt.show()","04175a86":"g8=df[(df.Gender=='Male')|(df.Gender==\"Female\")].groupby(['Year','Gender','Job title'])['Dummy'].sum().unstack(fill_value=0).stack().reset_index(name='Count')\ng8=g8.pivot_table(index=['Year','Job title'],columns='Gender',values='Count').assign(Ratio=lambda r:round(r.Female \/ r.Male,2)).rename_axis(columns=None).reset_index()\ng8.head()","abead9ad":"plt.figure(figsize=[25,15])\ng=sns.lineplot(data=g8,x='Job title',y='Ratio',hue='Year',ci=None,palette=['Red','Green'])\nplt.legend([\"2018\", \"2021\"], loc =\"upper left\",title='Year',fontsize=20,title_fontsize=20)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nplt.show()","29dc778a":"len(df.Country.value_counts())","66286cc3":"country_dict={'South_Asia_other_than_India':['China','Pakistan','Viet Nam','Taiwan','Indonesia','Bangladesh','Singapore','Malaysia','Thailand','Philipines','Hong Kong (S.A.R.)','Sri Lanka','Nepal'],\n 'Rest_of_Asia':['Japan','Russia','Turkey','South Korea','Iran, Islamic Republic of...','Israel','Republic of Korea','Saudi Arabia','United Arab Emirates','kazakhstan','Iraq'],\n'Europian Union(EU)':['Germany','France','Spain','Italy','Poland','Netherlands','Portugal','Greece','Sweden','Ireland','Belgium','Romania','Denmark','Czech Republic','Austria','Hungary','Finland','Belarus','Ukraine','Switzerland','Norway'],\n 'Africa':['Nigeria','Egypt','Kenya','South Africa','Morocco','Tunisia','Ghana','Algeria','Uganda','Ethiopia'],\n'American_Continent_other_than_USA':['Canada','Mexico','Colombia','Argentina','Peru','Chile','Ecuador','Brazil'],\n'Others':['Other','I do not wish to disclose my location'],\n\"India\":'India','USA':'United States of America',\n             \"Ocenia\":['Australlia','New Zealand']}\n\n\ndef country_map(x):\n    for i in country_dict:\n        if x in country_dict[i]:\n            return i\n        \n        \ndf.insert(5,\"Region\",df.Country.apply(country_map))\ndf.drop('Country',axis=1,inplace=True)\n\ndf.head()","041a1601":"df.Region.value_counts()","8d333eef":"plt.figure(figsize=[22,10])\np=sns.countplot(data=df,x='Region',hue='Year')\np.set_xticklabels(p.get_xticklabels(),rotation=90)\nplt.legend(loc='upper right',title='Year',shadow=True,fontsize=15,title_fontsize=15)\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nfor i in p.patches:\n    p.annotate('{:.0f}'.format(i.get_height()),(i.get_x()+0.2,i.get_height()+1),ha='center',color='black',fontsize=15)\nplt.show()","76198858":"g9=df.groupby(['Year','Gender','Region'])['Dummy'].sum().unstack(fill_value=0).stack().reset_index(name='Count')\ng9=g9[(g9.Gender=='Male')|(g9.Gender=='Female')]\ng9.reset_index(drop=True, inplace=True)","de1765ad":"g9=g9.pivot_table(index=['Year','Region'],columns='Gender',values='Count').assign(Ratio=lambda r:round(r.Female \/ r.Male,2)).rename_axis(columns=None).reset_index()\ng9.head()","66566e4c":"plt.figure(figsize=[40,20])\ng=sns.lineplot(data=g9,x='Region',y='Ratio',ci=None)\nplt.xlabel('Region',size=18)\nplt.ylabel('Ratio',size=18)\nplt.xticks(size = 18)\nplt.yticks(size = 18)\np.set_xticklabels(p.get_xticklabels(),rotation=90)\nplt.show()","8603a69d":"plt.figure(figsize=[25,12])\ng=sns.barplot(data=g9,x='Region',y='Ratio',hue='Year')\ng.set_xticklabels(g.get_xticklabels(),rotation=90)\nplt.legend(loc='upper left',title='Year',shadow=True,fontsize=15,title_fontsize=15)\nplt.xlabel('Region',size=20)\nplt.ylabel('Ratio',size=20)\nplt.xticks(size = 18)\nplt.yticks(size = 18)\nfor p in g.patches:\n    g.annotate('{:.2f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=14)\nplt.show()","f79aa812":"# Get all the languages columns from both datasets and arrange them in proper order.\n\nlang_18=df_18.iloc[:,66:80]\ncol_18=['Python','R',\"SQL\",'Bash','Java','Javascript','VBA','C','MATLAB','Scala','Julia','Go','C#\/.net','PHP']\nlang_18.columns=col_18\nlang_18.drop(['VBA','Scala','Go','C#\/.net','PHP'],axis=1,inplace=True)\nlang_18=lang_18.reindex(columns=['Python','R',\"SQL\",'C','Java','Javascript','Julia','Bash','MATLAB'])\n\nlang_21=df_21.iloc[:,8:19]\ncol_names=['Python','R',\"SQL\",'C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB']\nlang_21.columns=col_names\n\n# Append the above two datasets.\n\nlang=lang_18.append([lang_21])\nlang['C++'][lang['C']=='C\/C++']='C++'\nlang['Javascript'][lang['Javascript']=='Javascript\/Typescript']='Javascript'\nlang.drop(['Swift'],axis=1,inplace=True)\n\n# Handle Null values. Here null value indicates person is not familiar with the languages. so, we fill it using 0.\n\nlang.fillna(0,inplace=True)\nlang=lang.applymap(lambda x:0 if x == 0 else 1)\nlang['Total_languages_known']=lang.sum(axis=1)\n\n\n# Get the column of most recommended language for freshers from both datasets.\n\ncol_name='What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'\nlang['language_recommended_for_freshers']=df_18[col_name].append([df_21[col_name]])\n\n\n# Append all the columns to the dataset obtained from the previous section and arrange the order properly.\ndf=pd.concat([df,lang],axis=1)\n\ncol=df.columns.tolist()\ncol=[i for i in col if i != 'Dummy']+['Dummy']\n\ndf=df.reindex(columns=col)\n\ndf.head()","51c07dc0":"plt.figure(figsize=[20,12])\ng=sns.countplot(data=df,x='Total_languages_known')\nplt.xticks(size = 18)\nplt.yticks(size = 18)\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+0.4,p.get_height()),ha='center',va='bottom',color='black',fontsize=16)\nplt.show()","e7140b26":"plt.figure(figsize=[20,12])\ng=sns.countplot(data=df,x='Total_languages_known',hue='Year')\nplt.legend(loc='upper right',title='Year',shadow=True,fontsize=15,title_fontsize=15)\nplt.xticks(size = 18)\nplt.yticks(size = 18)\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=16)\nplt.show()","6377e4c4":"languages=['Python','SQL','R','C++','C', 'Java', 'MATLAB']\n\ndf_lang=df.pivot_table(index=[\"Year\",'Gender',\"Age\",'Region','Education level','Job title'],values=languages,aggfunc=sum,fill_value=0).stack().reset_index(name='Count')\n\ndf_lang.rename({'level_6':'Programming_language'},axis=1,inplace=True)\n\ndf_lang.head()","c543d451":"g10=df_lang.groupby('Programming_language')['Count'].sum().sort_values().reset_index(name='Count')\nplt.figure(figsize=[25,15])\ng=sns.barplot(x='Programming_language',y='Count',data=g10,ci=None,order=languages)\nplt.xticks(size = 15)\nplt.yticks(size = 18)\nplt.xlabel('Programming languages',size=18)\nplt.ylabel('Percent',size=18)\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+0.4,p.get_height()),ha='center',va='bottom',color='black',fontsize=18)\nplt.show()","3032182c":"g11=df_lang.groupby(['Year','Programming_language'])['Count'].sum().unstack().stack().reset_index(name='Count')\ng11['Percent']=1\ng11['Percent'][g11['Year']==2018]=round(g11['Count']\/23859,4)*100\ng11['Percent'][g11['Year']==2021]=round(g11['Count']\/25973,4)*100\ng11.head()","7d3f52fa":"plt.figure(figsize=[25,15])\ng=sns.barplot(x='Programming_language',y='Percent',hue='Year',data=g11,ci=None,order=languages)\nplt.xticks(size = 15)\nplt.yticks(size = 18)\nplt.xlabel('Programming languages',size=18)\nplt.ylabel('Percent',size=18)\nfor p in g.patches:\n    g.annotate('{:.2f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=14)\nplt.show()","20214181":"import itertools as it\ncol=df.columns.tolist()[7:17]\n\n# creating two empty dictionaries for two years.\n\nlang_combo18={}\nlang_combo21={}\n\n\n# Parsing through all possible unique duos of languages.\n\nfor i in it.combinations(col, 2):\n   lang_combo18[i]=len(df[(df[i[0]]==1)&(df[i[1]]==1)&(df['Year']==2018)])\n   lang_combo21[i]=len(df[(df[i[0]]==1)&(df[i[1]]==1)&(df['Year']==2021)])\n    \n\n# Creating datasframes from the above dictionaries and tidying them...\n\nd1=pd.DataFrame(lang_combo18.items())\nd2=pd.DataFrame(lang_combo21.items())\n\nd1.insert(0,\"Year\",2018)\nd2.insert(0,\"Year\",2021)\n\nd1.rename(columns={0:'Combination',1:'Count'},inplace=True)\nd2.rename(columns={0:'Combination',1:'Count'},inplace=True)\n\nd1=d1.sort_values(by='Count',ascending=False).head(10)\nd2=d2.sort_values(by='Count',ascending=False).head(10)\n\n# Appending the dataframes and finding percentages for each duo as Percentage variable.\n\nd1=d1.append(d2)\n\nd1=d1.reset_index()\n\nd1.drop('index',axis=1,inplace=True)\n\nd1['Percent']=1\nd1['Percent'][d1['Year']==2018]=round(d1['Count']\/23859,4)*100\nd1['Percent'][d1['Year']==2021]=round(d1['Count']\/25973,4)*100\n\nd1.head()","d3b57618":"plt.figure(figsize=[40,25])\ng=sns.barplot(x='Combination',y='Percent',hue='Year',data=d1,ci=None)\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.xlabel('language Combination',size=25)\nplt.ylabel('Percent',size=25)\nfor p in g.patches:\n    g.annotate('{:.2f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=28)\nplt.show()","38dcfb11":"# Fetching the required columns and append them...\n\nsal_18=df_18[['Year','How long have you been writing code to analyze data?','What is your current yearly compensation (approximate $USD)?']]\nsal_21=df_21[['Year','For how many years have you been writing code and\/or programming?','What is your current yearly compensation (approximate $USD)?']]\n\nsal_18.rename({'How long have you been writing code to analyze data?':'Coding experience(years)','What is your current yearly compensation (approximate $USD)?':'Current yearly compensation(USD)'},axis=1,inplace=True)\nsal_21.rename({'For how many years have you been writing code and\/or programming?':'Coding experience(years)','What is your current yearly compensation (approximate $USD)?':'Current yearly compensation(USD)'},axis=1,inplace=True)\n\nsal=sal_18.append(sal_21)\n\n\nsal.head()","d05ab4cd":"# Some heavy mapping work in progress....\n\nexp_dict={'0-1':['< 1 year','< 1 years'],'1-3':['1-2 years','1-3 years'],\n         '3-5':'3-5 years','5-10':'5-10 years','10-20':'10-20 years',\n         '20+':['20-30 years','30-40 years','40+ years','20+ years'],\n         'No experience':['I have never written code but I want to learn','I have never written code and I do not want to learn','I have never written code'],\n         'Not Available':['Not Available']\n         }\n\n\n        \nsal_dict={'0-50,000':['$0-999','1000-1,999','2,000-2,999','3,000-3,999','4,000-4,999','5,000-7,499','7,500-9,999','0-10,000','10,000-14,999','10-20,000','15,000-19,999','20,000-24,999','20-30,000','25,000-29,999','30,000-39,999','30-40,000','40,000-49,999','40-50,000'],\n          '50,001-100,000':['50,000-59,999','50-60,000','60,000-69,999','60-70,000','70,000-79,999','70-80,000','80,000-89,999','80-90,000','90,000-99,999','90-100,000'],\n          '1,00,001-2,00,000':['100,000-124,999','100-125,000','125,000-149,999','125-150,000','150,000-199,999','150-200,000'],\n          '200,001-300,000':['200,000-249,999','200-250,000','250,000-299,999','250-300,000'],\n          '300,001-500,000':['300,000-499,999','300-400,000','400-500,000'],\n          '500,000+':['500,000-999,999','500,000+','>$1,000,000'],\n          \"Do not wish to disclose\":['I do not wish to disclose my approximate yearly compensation','Do not wish to disclose']\n        }\n\ndef exp_map(x):\n    for i in exp_dict:\n        if str(x) in exp_dict[i]:\n            return i\n        \n\ndef sal_map(x):\n    for i in sal_dict:\n        if str(x) in sal_dict[i]:\n            return i\n\n        \n# Handling null values and tidying up the data...\n\nsal['Current yearly compensation(USD)'].fillna('Do not wish to disclose',inplace=True)\nsal['Coding experience(years)'].fillna('Not Available',inplace=True)\n\nsal.insert(2,\"Current yearly compensation (USD)\",sal['Current yearly compensation(USD)'].apply(sal_map))\nsal.insert(1,\"Coding experience(in years)\",sal['Coding experience(years)'].apply(exp_map))\n\nsal.drop('Current yearly compensation(USD)',axis=1,inplace=True)\nsal.drop('Coding experience(years)',axis=1,inplace=True)\n\nsal1=sal.drop(['Year'],axis=1)\n\n# Finally, concating this dataframe with the one obtained from previous section....\n\ndf=pd.concat([df,sal1],axis=1)\n\ncol=df.columns.tolist()\ncol=[i for i in col if i != 'Dummy']+['Dummy']\n\ndf=df.reindex(columns=col)\n\ndf.head()","cc0dc60e":"sal['Dummy']=1\nh21=sal.groupby(['Year','Coding experience(in years)'])['Dummy'].count().reset_index(name='Count')\n\nsum_18=h21['Count'][h21['Year']==2018].sum()\nsum_21=h21['Count'][h21['Year']==2021].sum()\n\nh21['Percent']=1\nh21['Percent'][h21['Year']==2018]=round(h21['Count']\/sum_18,2)*100\nh21['Percent'][h21['Year']==2021]=round(h21['Count']\/sum_21,2)*100\n\nh21.head()","166f689e":"plt.figure(figsize=[20,12])\ng=sns.barplot(data=h21,x='Coding experience(in years)',y='Percent',hue=\"Year\")\nplt.legend(loc='upper right',title='Year',shadow=True,fontsize=15,title_fontsize=15)\nplt.xticks(size = 18)\nplt.yticks(size = 18)\nfor p in g.patches:\n    g.annotate('{:.2f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=16)\nplt.show()","e6e05787":"df1=df[(df.Gender=='Male')|(df.Gender=='Female')]\n\nh22=df1.groupby(['Gender','Coding experience(in years)'])['Dummy'].count().reset_index(name='Count')\n\nsum_male=h22['Count'][h22['Gender']==\"Male\"].sum()\nsum_female=h22['Count'][h22['Gender']=='Female'].sum()\n\nh22['Percent']=1\nh22['Percent'][h22['Gender']=='Male']=round(h22['Count']\/sum_male,3)*100\nh22['Percent'][h22['Gender']=='Female']=round(h22['Count']\/sum_female,3)*100\n\nh22.head()","ff6c0ec9":"plt.figure(figsize=[20,12])\ng=sns.barplot(data=h22,x='Coding experience(in years)',y='Percent',hue=\"Gender\",ci=None)\nplt.xticks(size = 18)\nplt.yticks(size = 18)\nfor p in g.patches:\n    g.annotate('{:.2f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=16)\nplt.show()","e07fa792":"gender=df[(df['Gender']=='Male')|(df['Gender']==\"Female\")]\n\nh23=gender.pivot_table(index=['Current yearly compensation (USD)','Gender'],values='Dummy',aggfunc=sum,\n                 fill_value=0).stack().reset_index(name='Count').drop('level_2',axis=1)\n\nh23['Percent']=1\nh23['Percent'][h23['Gender']=='Male']=(h23['Count']\/40000)*100\nh23['Percent'][h23['Gender']=='Female']=(h23['Count']\/8900)*100\n\nh23.head()","dacdb549":"plt.figure(figsize=[25,15])\ng=sns.barplot(data=h23,x='Current yearly compensation (USD)',y='Percent',hue='Gender',ci=None)\nplt.legend(loc='upper center',title='Year',shadow=True,fontsize=15,title_fontsize=15)\nplt.xticks(size = 14)\nplt.yticks(size = 14)\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()),(p.get_x()+0.2,p.get_height()),ha='center',va='bottom',color='black',fontsize=16)\nplt.show()","7cd3bf52":"gender=df[(df['Gender']=='Male')|(df['Gender']==\"Female\")]\n\nh24=gender.groupby(['Current yearly compensation (USD)','Gender','Job title'])['Dummy'].sum().unstack(fill_value=0).stack().reset_index(name='Count')\n\nh24.rename({'Dummy':'Count'},axis=1,inplace=True)\n\nh25=h24.pivot_table(index=['Job title','Gender'],columns='Current yearly compensation (USD)',values='Count',aggfunc=sum)\n\nh25.head()","73459adc":"plt.figure(figsize=[18,10])\np=sns.heatmap(h25,annot=True,cmap='Greens',fmt='d',linecolor='Black',robust=True)\np.set_xticklabels(p.get_xticklabels(),rotation=90)\nplt.xticks(size = 15)\nplt.yticks(size = 15)\nplt.show()","25d9c8ec":"df.head()","97d708f1":"compression_opts = dict(method='zip',archive_name='out.csv') \n\ndf.to_csv('output.zip', index=False,\n          compression=compression_opts)  ","b7211066":"> Exploratory Data Analysis is a process in which we analyze data to identify the primary features of data and get the targets ready for modeling.\n\n> The primary goal of EDA is to aid in the examination of data before making any assumptions. It can help understand patterns in data and discover interesting relationships between variables. \n\n> EDA includes steps such as Data Understanding, Data Cleaning, and Data visualization, which we will demonstrate in this notebook.  ","10aaa076":"## Novelty:","f3f77a89":"# Importing necessary packages:","1a4dc073":"> Overall, USA has the highest Female:Male ratio and the region 'American_Continent_other_than_USA' has the least value for the   ratio. (Contrasting values for the neighbouring regions...... )","2c9bea5f":"> Python has became far more famous over the years by 81% of people knowing it in 2021.\n\n> Popularity of SQL and C++ increased over the years and R has suffered decline in its popularity.\n\n> All the remaining languages remained constant over the years.","8054f176":"> The above heatmap shows the distribution of salaries over different jobs and gender.\n\n> We can say that for almost all jobs, distribution of salary among male and female remained same.\n\n> We can say that disparities in salary ranges by gender are absent. But, the female:male ratio is less among various jobs and   salary ranges.\n\n> All the not employed members refused to disclose their salaries.\n\n> There are around 26 students(23 male and 3 female) earning more than 100,000 USD annualy.","3c00e148":"> Adding a dummy variable will be helpful in Aggregation using group by and pivot\/pivot_table functions.","84bba756":"### Job title:","83a46aaf":"### Age group:","e1adab33":"## Bonus:","24ab1e69":"> Around, 37 % of all women are not employed (30 % student + 7% not employed).  \n\n> Around, 29 % of all men are not employed. (24 % student + 5% not employed).\n\n> Women are more in the data analyst job in terms of percentage.","32d40cb9":"> We have 40 plus questions and 360+ columns in each dataset, so we start by selecting a group of variables, performing data cleaning and analysis, and moving on to the next.","3dfc8727":"> People with coding experience of 1-3 years have surged from 22% to 30%.\n\n> People with coding experience of 20+ years increased from 2% to 7% (genuinely surprised here...)\n\n> People with no coding experience remained same which is surprising because with the advent of advanced no-code tools, this     number was supposed to go up.","4ef8ef25":"> In addition to the visualization and inferences, we have combined and cleaned survey data of 2018 and 2021.\n\n> Now, we convert it to a csv file, so that it can help increase the efficiency of performing EDA in the future.","acc02fa8":"> This plot may trick people into believing that more number of people knows 0 languages.\n\n> But, if we can get a clear picture only once if we move on to more granular level data. ","7ce24380":"# Subset - II","2efbd7e4":"### Gender:","9b9dc59a":"> (Python,SQL) is the best duo in both the years(2018 and 2021) and also increased its percentage by 8% over the period.\n\n>  Python features 8 times in the top ten 10 duos (not surprising though!!!)","72d1d963":"> The above cell creates a csv file, zips it and download it to your local machine or cloud storage.","043dcbaf":"> For the starters, the above plot shows the distrubtion of Gender variable for the two years 2018 and 2021.","891b7a5c":"## About this Notebook:","b6303974":"> Used the same custom function logic from the above.","dade4f56":"> We have around 70 countries in this variable which will not be easy for visualizing the data. So, we will map them into         regions for the convenience of visualization.","00c0efec":"## Subset - 3 ","0e2e6bd9":"## Country:","c7cb33ec":"## Education:","f699c0b0":"> Female:Male has the least value in the Manager level jobs. Although, the value increased from 2018 to 2021, It is still not     significant enough.","d6e11508":"> I think the basic visualization libraries like Matplotlib and seaborn are more than enough for creating the best visualizations.\n\n> I believe that Data cleaning should be the foremost step in any EDA and should take a lot of our focus.\n\n> As the title suggests, this notebook tries to find the things that have changed or remained unchanged from 2018 to 2021.","fa13c894":"> Around 36% of men refused to disclose salary and 41% of them belongs to 0-50,000 USD range.\n\n> Around 45% of men refused to disclose salary and 38% of them belongs to 0-50,000 USD range.\n\n> Less than 2 % of people are having salaries greater than 200,000 USD.","1ed2ef51":"### Languages known by people (count):","ec156675":"### Male:Female across age groups:","6f5a377c":"> This subset deals with the questions regarding the programming experience of people in years and their annual compensation in   USD.\n\n> We will get the data ready with some heavy cleaning and then proceed   with the analysis.","f527750a":"> No surprises here as Python leads the chart with huge margins followed by SQL and R.\n\n> But, these numbers are not the best way to represent this section. So, we will try another method.","712658b8":"> 26 different job titles are difficult to analyze so, we will use our custom map function to club similar jobs.","862c5991":"> I will be mapping some repetitive variables into one and also change their names to make them more meaningful.","67f08cf9":"> Now we can see that the number of people with no programming knowledge has declined rapildy over the years.\n\n> Also, Bulk number of people are having experience in 1-3 languages.","396a263a":"> In this, we will be group the variables such as Gender, Age, Country, Education levels, and Job title.\n\n> We will start with data cleaning steps and make a suitable dataset from scratch.\n \n> The Analysis in this section will focus on the Female: Male ratio across all the remaining variables of the group. ","d86cf44f":"> We can see that ML Engineer is emerging as the hot-shot job over the years while other vital roles such as Data Scientist and   Data Engineer are seeing a slight decline in the numbers.","6520135c":"> This particular plot is not helpful because the variable, Gender, is highly imbalanced ( with a ratio of 4:1 for male:female)\n\n> So, to combat the data imbalance problem, we will use the percentage of Gender in age groups instead of counts.","58cad1b6":"# Data Loading:","c0c35f54":"> We see that there are few overlaps such as 70-79 and 70+ so, we will correct it in the next cell.","4fa392df":"# Introduction:","f0c6ae73":"> This plot indicates that the ratio improved in the 18-24 age group, showing that more women are focusing on higher studies     and jobs.","c972643b":"> This is a custom function written to map the values with the help of a manually written dictionary. Further, this function is   used in the notebook for mapping missions.","d5fcf73a":"### Female:Male ratio by job:","279a70d6":"### Best Combo Award:","187f78c6":"> Gender wise, Females dominated the groups 0-1 years, 1-3 years and No experience.\n\n> As the experience increases, percentage of men started to increase while compared to women.","55f026c2":"> People from Third world country regions increased significantly from 2018 to 2021 whereas regions such as US and EU suffered   a sharp decline over the same period.","2f861072":"> From the above plot, we can see that woman occupies more % than men in the age group 18-29.\n\n> This may be the result of many woman leaving work after a certain age for reasons like taking care of family.","413d8cfc":"> In this subset, we will isolate the question, which indicates the programming languages known by the person.\n\n> We also have the question most recommended programming language for freshers in this section.\n\n> As usual, we will start with tidying up the data, followed by analysis.","aa3d4952":"> There are some repetitions such as Man\/Male and Female\/Woman, so we shall re-assign them.","a714db11":"> Percent variable indicates that 'x percent of people from that year knows a particular programming language'","be1ab4d2":"> Creating user-friendly visualizations using only Matplotlib and Seaborn libraries(Line plot, Count plot, Bar plot, Heat map).\n\n> Simple and concise code without complex classes and functions and only using Numpy and Pandas libraries.\n\n> Create a thoroughly cleaned and transformed dataset by the end, which will help increase the efficiency of EDA in the future.","65930113":"# Subset 1:","51aabecf":"> Data Sources:\n\n         . For this research, we will be using the datasets of the 2021 Kaggle Machine Learning & Data Science Survey\n           and 2018 Kaggle Machine Learning & Data Science Survey available in the following links:\n\n         . 2018 - https:\/\/www.kaggle.com\/kaggle\/kaggle-survey-2018\n\n         . 2021 - https:\/\/www.kaggle.com\/c\/kaggle-survey-2021\/data","181d6610":"> Major thing to notice here is that the count of people aged 22-34 decreased from 2018 to 2021.\n\n> Also, people of the age group 18-21 increased, indicating that the survey is attracting more students to participate.","982e1833":"## Programming languages:","2b62519b":"> India has registered the highest increase in Female:Male ratio from 2018 to 2021.","525be36e":"> Master's Degree and the Doctoral degree took the biggest hit where as students with Bachelor's degree and college dropouts     increased.\n\n> Now a days, more companies are starting to hire freshers straight out of the college for the jobs in data analysis field.       This can be a reason for rise in Bachelor's degree and slump in higher studies."}}