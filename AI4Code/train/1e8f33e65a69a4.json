{"cell_type":{"beac74fd":"code","d97e98be":"code","b5da66a1":"code","b25d3983":"code","2d35b074":"code","2bed866d":"code","f110dc25":"code","380d7e84":"code","4ab5c1c2":"code","0c3adfb3":"code","ec43fd99":"code","4abf3eb3":"code","a835f0d0":"code","a9de0668":"code","d7705bdb":"code","cbc9c6cc":"code","b69c619b":"code","f144fa57":"code","7e0a3066":"code","e21a8767":"code","b43c64ea":"code","a46f9c1b":"code","44232ff7":"code","35487df9":"markdown","aaaf16e4":"markdown","4e937f21":"markdown","d8d2f9e5":"markdown"},"source":{"beac74fd":"import numpy as np # linear algebra\nimport tensorflow as tf\nimport keras\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n%matplotlib inline","d97e98be":"!apt-get install tree --quiet\n# !rm -rf .\/train\n# !rm -rf .\/test\n# !rm -rf .\/val\n!mkdir train test val train\/yes train\/no test\/yes test\/no val\/yes val\/no\n!tree -d","b5da66a1":"img_path = '..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset\/'\n\nfor class1 in os.listdir(img_path):\n    num_images = len(os.listdir(os.path.join(img_path,class1)))\n    for (n,filename) in enumerate(os.listdir(os.path.join(img_path,class1))):\n        img = os.path.join(img_path,class1,filename)\n        if n < int(0.1 * num_images):\n            shutil.copy(img,'test\/'+class1+'\/'+filename)\n        elif n < int(0.8 * num_images):\n            shutil.copy(img,'train\/'+class1+'\/'+filename)\n        else:\n            shutil.copy(img,'val\/'+class1+'\/'+filename)","b25d3983":"def load_data(image_dir):\n    images = []\n    y = []\n    classNum = 0\n    for class1 in tqdm(os.listdir(image_dir)):\n        for file_name in os.listdir(os.path.join(image_dir,class1)):\n            images.append(cv2.imread(os.path.join(image_dir,class1,file_name)))\n            y.append(classNum)\n        classNum += 1\n    print(f'Loaded {len(images)} images from {image_dir} directory')\n    images = np.array(images)\n    y = np.array(y)\n    return images,y","2d35b074":"def show_samples(X,y,label_dict={0:'no',1:'yes'},n=30):\n    for class1 in label_dict.keys():\n        imgs = X[y == class1][:n]\n        j = 10\n        i = n \/\/ 10\n        plt.figure(figsize=(15,6))\n        for (c,img) in enumerate(imgs,1):\n            plt.subplot(i,j,c)\n            plt.imshow(img)\n            plt.xticks([])\n            plt.yticks([])\n        plt.suptitle(f'Tumor: {label_dict[class1]}')","2bed866d":"train_images, train_labels = load_data('train\/')\nval_images, val_labels = load_data('val\/')\ntest_images, test_labels = load_data('test\/')\n\ntrain_images[0].shape","f110dc25":"show_samples(train_images,train_labels)","380d7e84":"data = [[(train_labels == 0).sum(),(val_labels == 0).sum(),(test_labels == 0).sum()],\n        [(train_labels == 1).sum(),(val_labels == 1).sum(),(test_labels == 1).sum()]]\n\nlabels = ['Train', 'Test', 'Validation']\nX = np.arange(3)\n\n# fig = plt.figure()\nwidth = 0.35\nplt.bar(X - width\/2,data[0],width,label='no')\nplt.bar(X + width\/2,data[1],width,label='yes')\nplt.legend(loc='best')\nplt.xticks(X,labels=labels)\n","4ab5c1c2":"demo_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    rescale=1.\/255,\n    shear_range=0.05,\n    brightness_range=[0.5, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='constant',\n    cval=0\n)","0c3adfb3":"batch1 = demo_datagen.flow_from_directory('train\/').next()\nshow_samples(batch1[0], batch1[1].argmax(axis=1))","ec43fd99":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping","4abf3eb3":"datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    rescale=1.\/255,\n    shear_range=0.05,\n    brightness_range=[0.5, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='constant',\n    cval=0\n)\nRANDOM_SEED = 0\nIMG_SIZE = (224,224)\ntrain_gen = datagen.flow_from_directory(\n        'train\/',\n        color_mode='rgb',\n        target_size=IMG_SIZE,\n        batch_size=32,\n        class_mode='binary',\n        seed=RANDOM_SEED\n)\n\nvalid_gen = datagen.flow_from_directory(\n        'val\/',\n        color_mode='rgb',\n        target_size=IMG_SIZE,\n        batch_size=16,\n        class_mode='binary',\n        seed=RANDOM_SEED\n)","a835f0d0":"base_model = VGG16(include_top=False,weights='imagenet',input_shape=(224,224,3))\nbase_model.summary()","a9de0668":"model = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(300,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.005)))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.layers[0].trainable = False\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.01,\n    decay_steps=500,\n    decay_rate=0.0001)\nopt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\nmodel.summary()","d7705bdb":"train_step_size = train_gen.n\/\/train_gen.batch_size\nval_step_size = valid_gen.n\/\/valid_gen.batch_size\nes = EarlyStopping(\n    monitor='val_accuracy', \n    mode='max',\n    patience=6\n)\n\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch=train_step_size,\n    epochs=10,\n    validation_data=valid_gen,\n    validation_steps=val_step_size,\n    callbacks=[es]\n)","cbc9c6cc":"model.layers[0].trainable = True\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt,\n    metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch=train_step_size,\n    epochs=30,\n    validation_data=valid_gen,\n    validation_steps=val_step_size,\n    callbacks=[es]\n)","b69c619b":"# plot model performance\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","f144fa57":"test_gen = datagen.flow_from_directory(\n        'test\/',\n        color_mode='rgb',\n        target_size=IMG_SIZE,\n        batch_size=16,\n        class_mode='binary',\n        seed=RANDOM_SEED\n)","7e0a3066":"model.evaluate_generator(valid_gen)","e21a8767":"[1 if x > 0.5 else 0 for x in model.predict_generator(test_gen)]","b43c64ea":"from sklearn.metrics import confusion_matrix","a46f9c1b":"confusion_matrix(preds)","44232ff7":"model.save('brain-mri-vgg16-27 May 20.h5')","35487df9":"# ResNet","aaaf16e4":"Check the images flowed through Keras ImageDataGenerator","4e937f21":"Now, let's see our training dataset for both the classes","d8d2f9e5":"Next, to confirm and reassure ourselves, we check the distribution of classes across our datasets"}}