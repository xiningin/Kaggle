{"cell_type":{"b6dde3d3":"code","af5abffe":"code","f76fc725":"code","10287a0b":"code","fc2d3df2":"code","12d73316":"code","ead2ceb2":"code","458a8490":"code","22c251ef":"code","35d35b3a":"code","9f50051a":"code","d674fa03":"code","e87267fc":"code","ba9a9b67":"code","84a7e1b9":"code","784f2b5a":"code","3cebc314":"markdown","b2b76ab1":"markdown"},"source":{"b6dde3d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af5abffe":"import matplotlib.pyplot as plt, seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans, AgglomerativeClustering\nfrom sklearn.metrics import silhouette_score\n\nfrom scipy.cluster.hierarchy import linkage,dendrogram,cut_tree","f76fc725":"wine = pd.read_csv('\/kaggle\/input\/wine-dataset-for-clustering\/wine-clustering.csv')\nwine.head()","10287a0b":"wine.info()","fc2d3df2":"plt.figure(figsize=(15,10))\nmask = np.triu(wine.iloc[:,:-2].corr(),1)\nsns.heatmap(wine.iloc[:,:-2].corr(), annot=True, mask=mask, cmap=\"YlGnBu\")\nplt.show()","12d73316":"wine.plot(kind='box', subplots=True, layout=(4,4), figsize=(15,15), title='Outlier Visualization')\nplt.show()","ead2ceb2":"scaler = StandardScaler()\ndf = scaler.fit_transform(wine)\ndf = pd.DataFrame(df, columns=wine.columns)\ndf.head()","458a8490":"def hopkins(X):\n    \n    from sklearn.neighbors import NearestNeighbors\n    from random import sample\n    from numpy.random import uniform\n    import numpy as np\n    from math import isnan\n    \n    d = X.shape[1]\n    #d = len(vars) # columns\n    n = len(X) # rows\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    H = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(H):\n        print(ujd, wjd)\n        H = 0\n \n    return H","22c251ef":"hopkins_score = np.array([hopkins(df) for i in range(10)]).mean()\nprint('Hopkins score =',hopkins_score)","35d35b3a":"inertia = []\nnum_of_clusters = np.arange(2,8)\nfor i in num_of_clusters:\n    km = KMeans(n_clusters=i, max_iter=100, random_state=100)\n    km.fit(df)    \n    inertia.append(km.inertia_)\n    \nplt.plot(num_of_clusters, inertia)\nplt.grid(alpha=0.6)\nplt.show()","9f50051a":"sil = []\nnum_of_clusters = np.arange(2,8)\nfor i in num_of_clusters:\n    km = KMeans(n_clusters=i, max_iter=100, random_state=100)\n    km.fit(df)    \n    sil.append(silhouette_score(df, km.labels_))\n    \nplt.plot(num_of_clusters, sil)\nplt.grid(alpha=0.6)\nplt.show()","d674fa03":"## 3 clusters seem to be fairly a good choice\n\nkm = KMeans(n_clusters=3, max_iter=100, random_state=100)\nkm.fit(df)\n\nwine['km_cluster_id'] = km.labels_\nwine.head()","e87267fc":"plt.figure(figsize=(20,15))\nfor i in enumerate(wine.columns[:-1]):\n    plt.subplot(4,4,i[0]+1)\n    sns.boxplot(x=wine.km_cluster_id, y=wine[i[1]])\n    plt.xlabel('km_cluster_id',fontsize=15)\n    plt.ylabel(i[1],fontsize=15)\nplt.show()","ba9a9b67":"links = linkage(df, method='complete')\ndendrogram(links)\nplt.show()","84a7e1b9":"ag = AgglomerativeClustering(n_clusters=5, linkage='complete')\nag.fit_predict(df)\n\nwine['ag_cluster_id'] = ag.labels_\nwine.head()","784f2b5a":"plt.figure(figsize=(20,15))\nfor i in enumerate(wine.columns[:-2]):\n    plt.subplot(4,4,i[0]+1)\n    sns.boxplot(x=wine.ag_cluster_id, y=wine[i[1]])\n    plt.xlabel('ag_cluster_id',fontsize=15)\n    plt.ylabel(i[1],fontsize=15)\nplt.show()","3cebc314":"## K-Means","b2b76ab1":"## Agglomerative Clustering"}}