{"cell_type":{"b4f8dcde":"code","dc1d41b9":"code","fd2df7fd":"code","ee235db7":"code","53e5bceb":"code","9749dc78":"code","9fb4eeb3":"code","4c7b17d0":"code","cb446678":"code","f0e914e5":"code","4d6b102a":"code","3e73bacf":"code","5a976974":"code","cdd207c5":"code","691b3e05":"code","a1c7fc02":"code","4c4a47e7":"code","8649a41a":"code","5296b86e":"code","c7b3d4a7":"code","783b7781":"code","3aec206f":"code","89a19a12":"code","19c39dd5":"code","186cdab9":"code","934b5718":"code","0fe69ef1":"code","f8d21831":"code","111b99ff":"code","c2dd1f03":"code","ffb8fa2b":"code","bd8d21e0":"code","f64708b4":"code","cbfe1292":"code","6b0ec15a":"code","5f578d5e":"code","cf35210d":"code","f0fab5b4":"code","39c4542b":"code","548ca521":"code","71489754":"code","5fe3c09e":"code","a34c826e":"code","519f2aec":"code","00ef92a3":"code","dc09761a":"code","2060243c":"code","3f67447c":"code","da889e3a":"code","41eda37e":"code","728f6be2":"code","9e7b8db6":"code","790db920":"code","13b12e90":"code","126e84da":"code","92d26ecd":"code","3b57a7bf":"code","f57a5ca5":"code","31bae304":"code","91c6e748":"code","f61d0bf4":"code","a958692f":"code","99c40200":"code","be197782":"code","045ad6e9":"code","0b115451":"code","834ead0e":"markdown","09918f83":"markdown","6109b54a":"markdown","be6f1198":"markdown","f7280d54":"markdown","7bbabf8c":"markdown","f41b80b6":"markdown","676af5f9":"markdown","d9373993":"markdown","61169f86":"markdown","2e9cf2f8":"markdown","f3e49804":"markdown","130ea61e":"markdown","009fe6bb":"markdown","81fbd7e2":"markdown","0d906278":"markdown","af37a583":"markdown","3bbc1e69":"markdown","4f9f757d":"markdown","9510acdf":"markdown","f818a7f4":"markdown","cf80bc55":"markdown","6e0e6e2a":"markdown","6b3bac27":"markdown","d7f9ae95":"markdown","13eb13c2":"markdown","b44f7e0f":"markdown","365657e5":"markdown","28148475":"markdown","bd7df50f":"markdown","4bad3d87":"markdown","c962f25c":"markdown","a8d10233":"markdown","2dd29b2d":"markdown","a33a7ccf":"markdown","d5077d5b":"markdown","b29daf76":"markdown","6f75ca35":"markdown","8d3bedda":"markdown","166268ab":"markdown","82f59c34":"markdown","bb600dc0":"markdown","93d2fe20":"markdown","3e6c5579":"markdown"},"source":{"b4f8dcde":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#pip install plotly==4.14.1","dc1d41b9":"df = pd.read_csv (\"..\/input\/video-games-sales-2019\/vgsales-12-4-2019.csv\")\ndf.head(5)","fd2df7fd":"df.info()","ee235db7":"df1 = df.loc[:,[\"Name\",\"Genre\",\"Platform\",\"Publisher\",\"Developer\",\"Total_Shipped\",\"Global_Sales\",\"NA_Sales\",\"PAL_Sales\",\"JP_Sales\",\"Other_Sales\",\"Year\"]]\ndf1.tail(5)","53e5bceb":"df2 = df1.loc[:,:]\ndf2.shape","9749dc78":"for i in range(len(df2)):\n    if not pd.isna(df2.loc[i,'Global_Sales']):\n        df2.loc[i,'Total_Sales']  = df2.loc[i,'Global_Sales']\n    elif not pd.isna(df2.loc[i,'Total_Shipped']):\n        df2.loc[i,'Total_Sales']  = df2.loc[i,'Total_Shipped']\n    else:\n        df2.loc[i,'Total_Sales']  = df2.loc[i,'NA_Sales'] + df2.loc[i,'PAL_Sales'] + df2.loc[i,'JP_Sales'] + df2.loc[i,'Other_Sales']","9fb4eeb3":"df2.head()","4c7b17d0":"df2.info()","cb446678":"df2.isnull().sum()","f0e914e5":"#df2 = df2[df2['Year'].notna()]\ndf2.dropna(subset=['Year'],inplace=True)\ndf2 = df2.reset_index(drop=True)","4d6b102a":"df2.isnull().sum()","3e73bacf":"#coerce will convert error values to NaN\ndf2['Year'] = pd.to_numeric(df2['Year'], downcast='integer', errors='coerce')\ndf2.info()","5a976974":"df2 = df2[df2['Year'] < 2019]\ndf2 = df2.reset_index(drop=True)","cdd207c5":"#plot heat map\nimport seaborn as sns\ncorrmat=df2.corr()\ntop_corr_features=corrmat.index\nplt.figure(figsize=(7,7))\ng=sns.heatmap(df2[top_corr_features].corr(),annot=True)","691b3e05":"top_games = df2[['Name','Total_Sales']]\ntop_games1 = top_games.groupby(\"Name\",as_index=False).sum()\ntop_games1 = top_games1.sort_values(by=['Total_Sales'],ascending=False)\ntop_5 = top_games1.head()\nimport plotly.express as px\nfig = px.bar(top_5, x=\"Name\", y=\"Total_Sales\", color=\"Total_Sales\", title=\"Top 5 games sold (millions of units sold)\")\nfig.show()","a1c7fc02":"asd = pd.DataFrame(df2['Genre'].value_counts())\nimport plotly.express as px\nfig = px.pie(asd, values='Genre', names=asd.index, title='Number of Games in each Genre')\nfig.show()","4c4a47e7":"years = df2['Year'].unique()\nprint(years)","8649a41a":"df2['Platform'].value_counts().plot(kind='bar',figsize=(15,5))","5296b86e":"data = df2.dropna(subset=['Global_Sales','NA_Sales','PAL_Sales','JP_Sales','Other_Sales','Year'])\ndata = data.drop(columns=['Total_Shipped','Total_Sales'])\ndata.head()","c7b3d4a7":"xy = data.loc[data['Platform'].isin([\"PS3\", \"X360\"])]\nxy = xy.groupby(\"Name\").filter(lambda x: len(x) == 2)\nxy = xy[['Name','Platform','Global_Sales']]\nxy","783b7781":"ps3 = xy.loc[xy['Platform'] == \"PS3\"]\nps3 = ps3.sort_values(by=['Name'])\nps3 = ps3.reset_index(drop=True)\nps3.tail()","3aec206f":"x360 = xy.loc[xy['Platform'] == \"X360\"]\nx360 = x360.sort_values(by=['Name'])\nx360 = x360.reset_index(drop=True)\nx360.tail()","89a19a12":"import seaborn as sns\nps3['Global_Sales'].hist(histtype='stepfilled', alpha=.5, bins=20)  \nx360['Global_Sales'].hist(histtype='stepfilled', alpha=.5, color=sns.desaturate(\"yellow\", .75), bins=10)\nplt.xlabel('Console',fontsize=15)\nplt.ylabel('Game Sales',fontsize=15)\nplt.show()","19c39dd5":"import matplotlib.pyplot as plt\n%matplotlib inline","186cdab9":"xy.hist(by ='Platform')","934b5718":"console  = ['PS3','X360']\nmeans_c = [ps3[['Global_Sales']].mean().values[0],x360[['Global_Sales']].mean().values[0]]\nmeans_dict = {'Console':console, 'Original Mean':means_c}\nmeans_df =  pd.DataFrame(means_dict) \nmeans_df","0fe69ef1":"observed_difference = ps3[['Global_Sales']].mean().values[0] - x360[['Global_Sales']].mean().values[0]\nprint(observed_difference)","f8d21831":"shuffled = xy['Global_Sales'].sample(510,replace = False)\nshuffled","111b99ff":"original_and_shuffled= xy.assign(Shuffled_sales=shuffled.values)\noriginal_and_shuffled","c2dd1f03":"all_group_means= original_and_shuffled.groupby('Platform',as_index=False).mean()\nall_group_means","ffb8fa2b":"difference = all_group_means['Shuffled_sales'][0]- all_group_means['Shuffled_sales'][1]\ndifference","bd8d21e0":"import array\ndifferences = np.zeros(5000)\nfor i in np.arange(5000):\n    consoles = xy[['Platform', 'Global_Sales']]\n    shuffled = consoles.sample(510,replace = False)\n    Shuffled_sales = shuffled['Global_Sales']\n    original_and_shuffled = consoles.assign(Shuffled_sales=Shuffled_sales.values)\n    all_group_means= original_and_shuffled.groupby('Platform').mean()\n    difference = all_group_means['Shuffled_sales'][0]- all_group_means['Shuffled_sales'][1]\n    differences[i] = difference\noriginal_and_shuffled","f64708b4":"differences_df = pd.DataFrame(differences)\ndifferences_df","cbfe1292":"differences_df.hist()\nplt.title('Prediction Under Null Hypotheses');\nplt.xlabel('Differences between Sales Averages',fontsize=15)\nplt.ylabel('Units',fontsize=15)\nplt.scatter(observed_difference, -1, color='red', s=100)\nprint('Observed Difference:', observed_difference)","6b0ec15a":"empirical_P = np.count_nonzero(differences <= observed_difference)\/5000\nempirical_P","5f578d5e":"#############################","cf35210d":"#plot heat map\nimport seaborn as sns\ncorrmat=data.corr()\ntop_corr_features=corrmat.index\nplt.figure(figsize=(7,7))\ng=sns.heatmap(df2[top_corr_features].corr(),annot=True)","f0fab5b4":"X = data.PAL_Sales\nx = np.array(X).reshape(-1,1)\ny = data.Other_Sales\ny = np.array(y).reshape(-1,1)\nprint(\"X:\",x.shape)\nprint(\"Y:\",y.shape)","39c4542b":"from sklearn.model_selection import  train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state=8)\nprint(\"x Train:\",x_train.shape)\nprint(\"x Test:\",x_test.shape)\nprint(\"y Train:\",y_train.shape)\nprint(\"y Test:\",y_test.shape)","548ca521":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(x_train,y_train)\npred = lr.predict(x_test)\nfrom sklearn.metrics import r2_score\nprint(\"R2 score:\",r2_score(y_test,pred)*100,\"%\")","71489754":"from sklearn import model_selection\nfrom sklearn.model_selection import KFold\nlr_kfold = LinearRegression()\nkfold = model_selection.KFold(n_splits=10)\nresults_kfold = model_selection.cross_val_score(lr_kfold, x_train, y_train, cv=kfold)\nprint(\"10-fold cv\",results_kfold*100)\nprint(\"--------------------------------------------------------------------\")\nprint(\"10-fold accuracy mean:\",results_kfold.mean()*100,\"%\") ","5fe3c09e":"plt.scatter(x=x_test,y=y_test)\nplt.plot(x,lr.predict(x), color='red')\nplt.title('Linear Regression')\nplt.xlabel(\"PAL Sales\")\nplt.ylabel(\"Other Region Sales\")","a34c826e":"# model evaluation for training set\nfrom sklearn.metrics import mean_squared_error\ny_train_predict = lr.predict(x_train)\ny_test_predict = lr.predict(x_test)\nprint(\"Root MSE of training set:\",mean_squared_error(y_train, y_train_predict, squared=False))\nprint(\"Root MSE of testing set:\",mean_squared_error(y_test, y_test_predict, squared=False))\nprint(\"MSE of training set:\",mean_squared_error(y_train, y_train_predict))\nprint(\"MSE of testing set:\",mean_squared_error(y_test, y_test_predict))","519f2aec":"import statsmodels.api as sm\nz1 = sm.OLS(x_train,y_train)\nz2 = z1.fit()\nz2.summary()","00ef92a3":"from sklearn.preprocessing import PolynomialFeatures\npoly=PolynomialFeatures(degree=2)\nx_poly=poly.fit_transform(x_train)\npol_reg=LinearRegression()\nl=pol_reg.fit(x_poly,y_train)\nprediction = pol_reg.predict(poly.fit_transform(x_test))\nfrom sklearn.metrics import r2_score\nprint(\"R2 score:\",r2_score(y_test,prediction)*100,\"%\")","dc09761a":"plt.scatter(x, y) \nplt.plot(x, l.predict(poly.fit_transform(x)), color = 'red')\nplt.title('Polynomial Regression')\nplt.xlabel(\"PAL Region\")\nplt.ylabel(\"Other Region\")\nplt.show()","2060243c":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\ncrossvalidation = KFold(n_splits=10, shuffle=False)\npoly = PolynomialFeatures(2)\nx_poly = poly.fit_transform(x_train)\nmodel = pol_reg.fit(x_poly, y_train)\nscores = cross_val_score(model, x_poly, y_train, scoring=\"r2\", cv=crossvalidation,n_jobs=1)\nprint(np.array(scores))\nfinal_score = np.array(scores).mean()\nprint(\"R2 score:\",final_score)","3f67447c":"ttest = data.loc[(data['Publisher'] == \"2K Games\")]\nttest = ttest[['Name','NA_Sales', 'JP_Sales']]\nttest.shape","da889e3a":"ttest.head()","41eda37e":"import seaborn as sns\ncorrmat=ttest[['NA_Sales','JP_Sales']].corr()\ntop_corr_features=corrmat.index\nplt.figure()\ng=sns.heatmap(data[top_corr_features].corr(),annot=True)","728f6be2":"na = ttest[['NA_Sales']]\njp = ttest[['JP_Sales']]\nprint(\"NA mean:\",na.mean().values[0])\nprint(\"JP mean:\",jp.mean().values[0])","9e7b8db6":"import scipy.stats as stats\nx,p_value=stats.ttest_ind(na,jp)\nif p_value[0] < 0.05:\n    print(\"We are rejecting null hypothesis\")\nelse:\n    print(\"We are accepting null hypothesis\")","790db920":"df_c = data.loc[:,:]\ndf_c = df_c.loc[df_c['Genre'].isin([\"Sports\", \"Music\", \"Visual Novel\", \"Party\"])]","13b12e90":"df_c = df_c.drop(columns=['Name','Platform','Publisher','Developer'])\ndf_c = df_c.reset_index(drop=True)\ndf_c.tail()","126e84da":"for i in range(len(df_c)):\n    if df_c.loc[i,\"Genre\"]  == \"Sports\":\n        df_c.loc[i,\"Genre\"]  = 0\n    else:\n        df_c.loc[i,\"Genre\"]  = 1","92d26ecd":"df_c['Genre'] = pd.to_numeric(df_c['Genre'], downcast='integer', errors='coerce')\nX = df_c.drop(columns=['Genre'],axis=1)\ny = df_c['Genre'].values","3b57a7bf":"from sklearn.model_selection import  train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.33, random_state=1)","f57a5ca5":"from sklearn.metrics import roc_curve,accuracy_score,plot_confusion_matrix,precision_score,recall_score,f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","31bae304":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(train_X, train_y)\ny_pred=gnb.predict(test_X)\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nprint(\"The accuracy is:\",accuracy_score(test_y,y_pred)*100,\"%\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(test_y,y_pred))","91c6e748":"from sklearn import model_selection\nfrom sklearn.model_selection import KFold\nkfold = model_selection.KFold(n_splits=10)\nresults_kfold = model_selection.cross_val_score(gnb, train_X, train_y, cv=kfold)\nprint(\"10-fold cv\",results_kfold*100)\nprint(\"--------------------------------------------------------------------\")\nprint(\"10-fold accuracy mean:\",results_kfold.mean()*100,\"%\") ","f61d0bf4":"plot_confusion_matrix(gnb,test_X,test_y)","a958692f":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(test_y, y_pred)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='DT')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\nfrom sklearn.metrics import roc_auc_score\nprint(\"ROC Score:\", roc_auc_score(test_y, y_pred))","99c40200":"from sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(train_X, train_y)\ny_pred_clf = clf.predict(test_X)\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nprint(\"The accuracy is:\",accuracy_score(test_y,y_pred_clf)*100,\"%\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(test_y,y_pred_clf))","be197782":"from sklearn import model_selection\nfrom sklearn.model_selection import KFold\nkfold = model_selection.KFold(n_splits=10)\nresults_kfold = model_selection.cross_val_score(clf, train_X, train_y, cv=kfold)\nprint(\"10-fold cv\",results_kfold*100)\nprint(\"--------------------------------------------------------------------\")\nprint(\"10-fold accuracy mean:\",results_kfold.mean()*100,\"%\") ","045ad6e9":"plot_confusion_matrix(clf,test_X,test_y)","0b115451":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(test_y, y_pred_clf)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='DT')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\nfrom sklearn.metrics import roc_auc_score\nprint(\"ROC Score:\", roc_auc_score(test_y, y_pred_clf))","834ead0e":"To see how the statistic should vary under the null hypothesis, we have to figure out how to simulate the statistic under that hypothesis. A clever method based on random permutations does just that.","09918f83":"Deleting data in 2019 since the data seems to be scrubbed in 12-4-2019 and does not contain games released in rest of the year.","6109b54a":"## Number of Games available in each platform","be6f1198":"## Visualization","f7280d54":"Modifying data based on above mentioned condition","7bbabf8c":"# Regression: PAL-Sales vs Other Sales","f41b80b6":"Based on T-test, we are rejecting the null hypothesis. Therefore we can conclude that games published by 2k Games have independent sales in North America and Japan.","676af5f9":"# Student T-Test","d9373993":"Playstation 3 and XBox 360 are two of the consoles which are in same generation. As per reports Playstation 3 has more number of units sold when compared with XBox 360 (87.4  million  units vs 84  million units). However in 2015, both Microsoft and Sony stopped disclosing the sales figure. So by now,their sales figure might be almost equal. Source: [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/List_of_best-selling_game_consoles), [EscapistMagazine](https:\/\/www.escapistmagazine.com\/v2\/who-finally-won-ps3-or-xbox-360\/). \n\nSince the number of units of each unit might be comparable now, let's hypothesis that, for a game, which is available in both platforms,  PS3 will have same game sales when compared with X360.","61169f86":"Dropping null values and resetting index","2e9cf2f8":"Therefore for classifying the games in Sports genre, the Naive Bayes is the better model since it gave a better AUC score of 0.95","f3e49804":"### Checking for null values\n- Name and Platform cannot be null since they are the candidate key\n- Also removing rows with year as null since they are also small in number\n- Rest of the null values are leaving as it is. These maybe useful for later","130ea61e":"Most of the video game sales are in North American Region and Japan. Only the popular games perform well in other areas. In the correalation matrix below, we can see that there is a relation between sales in PAL region and Other regions. Therefore using regression models, we might be able to predict sales of a game in these regions.","009fe6bb":"The observed difference lies close to the centre of the distribution.The p-value we got is 0.63 which is greater than 0.05. Therefore we fail to reject the null-hypothesis.\n\nBased on this results, we can conclude that PS3 and X360 may have comparable sales for game which is available in both platform.","81fbd7e2":"**2K Games** is an American video game publisher. Although video games published in Japan are mostly popular in North America, the vice versa may not be true. Therefore let's check the dependency of Game sales in Japan and North America.","0d906278":"## Polynomial Regression with Degree 2","af37a583":"Manually encoding Genres. \n- 0 for sports \n- 1: for other genres","3bbc1e69":"Data Cleaning\n- Selecting only columns needed for our use","4f9f757d":"### Original Dataset Link: [Kaggle](https:\/\/www.kaggle.com\/ashaheedq\/video-games-sales-2019)\n\nVideo Game Industry is one of the largest industry in the world. Video Game Industry is a big moneymaker when compared with Hollywood and North American sports industry combined. [reference](https:\/\/www.marketwatch.com\/story\/videogames-are-a-bigger-industry-than-sports-and-movies-combined-thanks-to-the-pandemic-11608654990)\n\nIn this case study, we are doing about the analysis of video games sales, Genres, platforms etc.\n\n**Note: Plotly is required**","9510acdf":"#### Linear Regression with 10-fold cross validation","f818a7f4":"## Naive Bayes model","cf80bc55":"## Hypothesis Testing","6e0e6e2a":"## Decision Tree model","6b3bac27":"In the correlation matrix also, we can see that the columns does not have much dependency. Let's confirm this by checking whether the sales of Games published by 2K Games are dependent in North America and Japan.\n\n- **Null Hypothesis**: Sales of same games by 2K Games are dependent.\n- **Alternate Hypothesis**: Sales are independent\n\n**Since the total number of Games are only 24, we can do an independent Student's T-test.**","d7f9ae95":"Splitting columns for training and testing","13eb13c2":"Filtering all the games which are in both PS3 and X360","b44f7e0f":"- **Null Hypothesis**: A game which is available in both platforms, PS3 and X360 will have comparable sales.\n- **Alternate Hypothesis**: Sales would not be equal and will be independent.","365657e5":"Downcasting from object to integer since Genre was of object datatype","28148475":"# Case Study: Video Game Sales","bd7df50f":"## Top 5 selling game of all time across all platforms","4bad3d87":"The difference in the accuracy scores with and without k-fold cross validation is due to the class imbalance (81:7).","c962f25c":"Therefore based on the scores, for the problem, both regression models are equally good. However the difference in the k-fold scores is due to the presence of outliers.\n\nTherefore based on the above models, we can predict the sales.","a8d10233":"Extracting games in PS3","2dd29b2d":"### Linear Regression Model","a33a7ccf":"Creating dataframe where all the regional sales information are available.","d5077d5b":"## Number of Games in each Genre","b29daf76":"### Information about dataset\n\nAll the numerical sales data values are number of units sold in millions.\n\nInformation about Regional Sales data\n- NA_Sales: North America\n- JP_Sales: Japan\n- PAL_Sales: India, China, European Countries (except France), Australia etc. (PAL countries)\n- Other Sales: All other countries not included above\n\nWe can see that most of the sales data cells are empty and either Total_Shipped and Global_Sales are present in the dataset. So we need to combine them into a new column i.e. Total_Sales\n\n### Creating Total Sales Data  based on following condition\n- 'Global_Sales' should be equal to sum of all region sales i.e. NA_Sales + PAL_Sales + JP_Sales + Other_Sales\n- Either 'Total_Shipped' or 'Global_Sales' needs to be present\n- Creating Total Sales = Global Sales or Total Shipped or sum of all region sales","6f75ca35":"## Data Cleaning","8d3bedda":"# Classification: Classifying whether game belongs to Sports Genre or not.\n\nSome of the  video game genres are highly popular(eg: Action, Sports etc). Therefore based on given sales data, we are classifying whether given game belongs to Sports or Other Less popular category. We are taking a subset of dataset. Therefore the categories included are Sports, Music, Visual Novel, Party.","166268ab":"**Degree of Freedom** = 24 + 24 - 2 = 46","82f59c34":"## Correlation matrix of all features","bb600dc0":"Anomaly in Total_Shipped vs other sales is because either one of them is present in the table","93d2fe20":"Extracting Games in X360","3e6c5579":"The distributions seems to be almost equal and XBox 360 seems to have higher sales."}}