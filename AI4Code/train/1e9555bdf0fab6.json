{"cell_type":{"2402a6ee":"code","c0270c54":"code","21d79a60":"code","a13635b5":"code","69d8fec8":"code","ba5abb6b":"code","f9f6694d":"code","09ddc363":"code","855aed2a":"code","558ec6ab":"code","629b8285":"code","a2a4fa03":"code","4401dffb":"code","96a7ba96":"code","740d40ac":"code","cdc4135a":"code","5f0edb54":"code","43b61168":"code","4a632362":"code","3be8ea4d":"code","ff1c96d5":"code","548693c4":"markdown","91e0d503":"markdown","05f6e1a0":"markdown","e24e3a7f":"markdown","7a25fc35":"markdown","6266e520":"markdown","8d351a47":"markdown","685ee59a":"markdown","cde1021e":"markdown","852f15ac":"markdown","8d972d3e":"markdown","92074a3e":"markdown","dfa24b28":"markdown","889c9a13":"markdown","564541b8":"markdown","42191fe3":"markdown","4cf9da9c":"markdown","969e8172":"markdown","8174f917":"markdown","cd3005cc":"markdown","91b14de2":"markdown","328ce9bb":"markdown"},"source":{"2402a6ee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\nfrom PIL import Image\nimport cv2","c0270c54":"df_train = pd.read_csv('..\/input\/tensorflow-great-barrier-reef\/train.csv')","21d79a60":"df_train[15:20]","a13635b5":"df_train.tail()","69d8fec8":"img_0 = plt.imread(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\/0.jpg\")\nplt.imshow(img_0)\nplt.show()","ba5abb6b":"image_0 = Image.open(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\/0.jpg\")\nprint(image_0.mode)","f9f6694d":"print(type(img_0))\nprint(img_0.dtype)\nprint(img_0.shape)","09ddc363":"print(img_0)","855aed2a":"plt.hist(img_0.ravel(), 256, [0, 256])\nplt.show()","558ec6ab":"blue, green, red = cv2.split(img_0)","629b8285":"plt.figure(figsize=(20,5))\nplt.subplot(131)\nplt.hist(blue.ravel(), 256, [0, 256])\nplt.title('Blue histogram')\n\nplt.subplot(132)\nplt.hist(green.ravel(), 256, [0, 256])\nplt.title('Green histogram')\n\nplt.subplot(133)\nplt.hist(red.ravel(), 256, [0, 256])\nplt.title('Red histogram')\n\nplt.show()","a2a4fa03":"image_0_gray = cv2.imread(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\/0.jpg\", 0)\nimage_0_eq_hist = cv2.equalizeHist(image_0_gray)","4401dffb":"plt.figure(figsize=(20,5))\n\nplt.subplot(131)\nplt.imshow(img_0)\nplt.title('Original image')\n\nplt.subplot(132)\nplt.imshow(image_0_gray, cmap=plt.cm.gray)\nplt.title('Grayscale image')\n\nplt.subplot(133)\nplt.imshow(image_0_eq_hist, cmap=plt.cm.gray)\nplt.title('Image with the equalizer function')\n\nplt.show()","96a7ba96":"plt.figure(figsize=(20, 5))\n\nplt.subplot(121)\nplt.hist(image_0_gray.ravel(), 256, [0, 256])\nplt.title('Grayscale histogram')\n\nplt.subplot(122)\nplt.hist(image_0_eq_hist.ravel(), 256, [0, 256])\nplt.title('Equalized image histogram')\n\nplt.show()","740d40ac":"filtered_image = cv2.blur(img_0, (3, 3))","cdc4135a":"plt.figure(figsize=(20,5))\n\nplt.subplot(121)\nplt.imshow(img_0)\nplt.title('Original image')\n\nplt.subplot(122)\nplt.imshow(filtered_image)\nplt.title('Filtered image')\n\nplt.show()","5f0edb54":"filtered_image_gaus = cv2.GaussianBlur(img_0, (5, 5), 2)","43b61168":"plt.figure(figsize=(20,5))\n\nplt.subplot(121)\nplt.imshow(img_0)\nplt.title('Original image')\n\nplt.subplot(122)\nplt.imshow(filtered_image_gaus)\nplt.title('Filtered image')\n\nplt.show()","4a632362":"row, column, canal = img_0.shape\n\nrotation_matrix = cv2.getRotationMatrix2D((row\/2, column\/2), 10, 1)\n\nrotated_image = cv2.warpAffine(img_0, rotation_matrix,(column, row))\n\nfig = plt.figure(figsize=(10,8))\nplt.imshow(rotated_image)\nplt.show()","3be8ea4d":"image_16 = plt.imread(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\/1011.jpg\")","ff1c96d5":"red = (0, 0, 255) #'x': 559, 'y': 213, 'width': 50, 'height': 32\ncv2.rectangle(image_16, (559, 213), (559 + 50, 213 + 32), red, 2)\nfig = plt.figure(figsize=(10,8))\nplt.imshow(image_16)\nplt.show()","548693c4":"### Import packages","91e0d503":"In the case of the Gaussian filter, we have to pass a third parameter, which defines that the number of neighboring pixels to be considered must be equal on the x and y axis.\nBelow we can see the original image and the filter image. We can see that it has a lower quality compared to when the blur function is used.","05f6e1a0":"Color system","e24e3a7f":"### The structure of an image\n\nWhen we look at an image, its smallest unit is called a pixel. The pixel is represented by three 8 bits numbers associated with the Red, Green and Blue (RGB) colors, where each color is a channel ranging from 0 to 255. Therefore, the color of a pixel corresponds to a combination of that range of channels.\nThe lowest value in this range (0) corresponds to the black color, the highest (255) represents the white color.","7a25fc35":"### Histogram equalization\n\nA common treatment when using images is their equalization from the interpretation of their histograms, thus ensuring an adequate pre-processing of the image.","6266e520":"### Dataframe description\nMetadata for each image in the training set indexed by the unique image ids, comprising both sequence and bounding box information.\n* video_id - ID number of the video the image was part of. The video ids are not meaningfully ordered.\n* video_frame - The frame number of the image within the video. Expect to see occasional gaps in the frame number from when the diver surfaced.\n* sequence - ID of a gap-free subset of a given video. The sequence ids are not meaningfully ordered.\n* sequence_frame - The frame number within a given sequence.\n* image_id - ID code for the image, in the format '{video_id}-{video_frame}'\n* annotations - The bounding boxes of any starfish detections in a string format that can be evaluated directly with Python. Does not use the same format as the predictions you will submit. Not available in test.csv. A bounding box is described by the pixel coordinate (x_min, y_min) of its upper left corner within the image together with its width and height in pixels.","8d351a47":"Now we have the distribution of light, medium and dark gray tones that make up the image.","685ee59a":"Final part of data.","cde1021e":"#### Gaussian filter\n\nAnother widely used filter is the Gaussian.","852f15ac":"### Image Rotation\n\nRotating the image is also a very common technique used in image recognition models.\nRotating the image by 10 degrees.","8d972d3e":"This histogram represents the colors in pixels within a given range representing the three color channels.","92074a3e":"Data type and dimension (width, height, canal)","dfa24b28":"Now, let's see how the histograms are divided into the blue, green and red channels. With this separation we can better understand the composition and distribution of colors.","889c9a13":"Showing the first image.","564541b8":"It is possible to see that for each line in the matrix above there are 3 values, and these values correspond to the hue of the RGB colors, and that each line represents a pixel.","42191fe3":"Initial parte of data.","4cf9da9c":"### Loading data train.csv","969e8172":"The above function of opencv is responsible for applying a filter on the original image, the command (3, 3) generates a blur based on a pixel in relation to its neighbors. Below we can see the original image, which has a certain level of noise and is smoothed without losing its sharpness and image detail.","8174f917":"### Converting color scale\n\nFor some image classification algorithms, transforming the image to a gray scale is often one of the first steps. Below we can see the original image, in grayscale and its equalized form.","cd3005cc":"### Image treatment","91b14de2":"#### Blur smoothing filter\n\nOne of the most common treatments when working with images is the use of smoothing filters, in order to try to reduce unwanted graininess in the image.\nThe appearance of noise in the image is very common when it is obtained, for example, in low light environments.","328ce9bb":"As seen in the cell above, an image is nothing more than arrays <class 'numpy.ndarray'>, and we can observe this using the numpy library."}}