{"cell_type":{"4201d3a9":"code","6d823d16":"code","b96ed074":"code","4ee0bc9d":"code","4ff65d1d":"code","c85c8f5a":"code","b5e46550":"code","35d23993":"code","ec232144":"code","8747468e":"code","4ff6f8f9":"code","5b21a259":"code","88c02c2e":"code","4ee83674":"code","cad400c6":"code","ecc92588":"code","12ca8232":"code","dcb4dddc":"code","6204f4f7":"code","9cb80cb9":"code","d0606bf2":"code","2805311c":"code","4fdeede4":"code","47c27f5f":"code","34d39eea":"code","f0ccaa26":"code","07766925":"code","f476373e":"code","3d636b69":"code","ef4ae6b2":"code","0dcc10f4":"code","40443e18":"code","e61830a0":"code","4e0eb915":"code","af4294d7":"code","c775c5e8":"code","fa5dcd52":"code","3fce1efd":"code","3577b3ae":"code","0d5ca104":"code","00ebca78":"code","fe14b34f":"code","8cef0e2e":"code","03f39d14":"code","9649c8ff":"code","a69ad0cf":"code","7f2d6e21":"code","2eba05cf":"code","4de1690e":"code","4bff17a1":"code","0b47b983":"code","11a62266":"code","612a557e":"code","a512d7f7":"code","cc12ef72":"code","feb9d684":"code","3a5aebc8":"code","6bc2e3f4":"code","2030bdbc":"code","a711c8f5":"code","10a996e4":"code","32d2f4f1":"code","8ed73424":"code","414eda06":"code","5fab6b21":"code","c6051956":"code","34cfa57e":"code","de7b0536":"code","f508dc58":"code","a9d9b2ba":"code","959c2f54":"code","a3f26486":"code","6e89cafe":"code","7b2e75bc":"code","71fc4572":"code","f7632153":"code","4fdda0cb":"code","b6e27221":"code","5f5e6afe":"code","ff0a3584":"code","1581b852":"code","e8e86cd4":"code","7dc3a73b":"code","5db446a2":"code","1a032cf2":"code","11bd6d83":"code","b550aa2a":"code","ae90b984":"code","1a21051c":"code","1b7affdb":"code","4bf230c6":"code","7208f7e2":"code","44f72016":"code","ac6e31ea":"code","15f38ac3":"code","f730eea6":"code","d22dd340":"code","4054a892":"code","f29e52fc":"code","f7a94d2c":"code","896b5da4":"code","f391d8ca":"code","69bbfd39":"code","965cde73":"code","e31f3fc4":"code","12dd300d":"code","9042ccb1":"code","3a60b174":"code","070cfa90":"code","fe969832":"code","f334168c":"code","2311c811":"code","3a755cd9":"code","6ddad1b4":"code","5022e352":"code","7091c364":"code","599c8d4f":"code","e8d7b487":"code","e8a496b7":"code","698ff466":"code","e8ca925c":"code","e7282b92":"code","c02a8000":"code","e09fc251":"code","e9450b47":"code","52cc2791":"code","6d19e045":"code","0654fb8c":"code","96c00ed7":"code","370826eb":"code","dd2f1ebd":"code","56ae7e46":"code","3c695233":"code","e2a74f99":"code","c9c8a078":"code","b8698d4f":"code","b468a2fa":"code","ce2c34a6":"code","27a99cf4":"code","f3e959ba":"code","9d2c9b24":"code","40593a8f":"code","0280498b":"code","06549d85":"code","278deb49":"code","df8dcf75":"code","52783412":"code","bbc269ca":"code","ef2804f3":"code","682da3ef":"code","0b5b64d8":"code","b9300807":"code","25726e70":"code","4ec2775d":"code","e46d92fb":"code","dd55f3a5":"code","6a0764de":"code","7e05cb64":"code","f969955a":"code","00cadfe6":"code","52bee70c":"code","2fe49e13":"code","65a2b12b":"code","9c5d3cc6":"code","804856f2":"code","b85ca9c5":"code","4da5d4e2":"markdown","e048d20f":"markdown","6cedbcc2":"markdown","53ce2b9a":"markdown","3f61ddf8":"markdown","2d69e994":"markdown","ff5415d1":"markdown","10ff333b":"markdown","ed07ef95":"markdown","099acbbc":"markdown","d2b0f5c6":"markdown","030ee623":"markdown","4b2269b5":"markdown","c2ad9f50":"markdown","8db59221":"markdown","2633fe6d":"markdown","1eeb1bec":"markdown","b4c360a3":"markdown","ab8e21d6":"markdown","066ea0fa":"markdown","22377d99":"markdown","b8bd0d62":"markdown","58c0f852":"markdown","019bc94c":"markdown","058db255":"markdown","de375ff6":"markdown","7d44d49c":"markdown","a00c73c5":"markdown","e32a6905":"markdown","d7e10271":"markdown","0c0ff8f7":"markdown","501d42aa":"markdown","9d78a01e":"markdown","ca667f77":"markdown","3c485cae":"markdown","ace2793c":"markdown","98ab9908":"markdown","467c1c5c":"markdown","d591acca":"markdown","28f98f2c":"markdown","608c1cf2":"markdown","98f1f43a":"markdown","93d1069a":"markdown","dabd6927":"markdown","66996955":"markdown","92311d99":"markdown","b80e3189":"markdown","5171304f":"markdown","2cc9e6ce":"markdown","136af38d":"markdown","be3190d7":"markdown","4a154328":"markdown","9fa02302":"markdown","6f54c2e2":"markdown","068c126c":"markdown","d86ab0b4":"markdown","08ac297f":"markdown","58ae9841":"markdown","90f2732c":"markdown","7198c60c":"markdown","bf0cce1d":"markdown","0d225f97":"markdown","66f4fcb6":"markdown","c56a9c1d":"markdown","0e6ac0bd":"markdown","38976103":"markdown","ec8223d4":"markdown","0b1a57cc":"markdown","cace1e7e":"markdown","179c8490":"markdown","a4e9d276":"markdown","3a24f82c":"markdown","20bd8368":"markdown","0d25e4a3":"markdown","32d4e9d7":"markdown","eb63764c":"markdown","5315d135":"markdown","c45ce326":"markdown","d28724d1":"markdown","aa58da89":"markdown","7cf600a2":"markdown","84896753":"markdown","97fe15a5":"markdown","240ce378":"markdown","cb47cd3a":"markdown","ee91907f":"markdown","3a6b10f9":"markdown","caad79a4":"markdown","693c9f8d":"markdown","03a121de":"markdown","9efb062d":"markdown","f5a8caea":"markdown","e75d9847":"markdown","63ff08f3":"markdown","b1608d51":"markdown","6ba918b0":"markdown","8b2e4bd9":"markdown","d03ca4a9":"markdown","e0a00860":"markdown","c81d50c8":"markdown","ef207627":"markdown","35b6f9fa":"markdown","a62b09a1":"markdown","39632d7d":"markdown","28087ce9":"markdown","1081cd96":"markdown","a41f9623":"markdown","0c572457":"markdown","08bf9e7a":"markdown","a1156a06":"markdown","2492efc0":"markdown","2161a85b":"markdown","953604c5":"markdown","e39c1fbf":"markdown","4f47d591":"markdown","5e6462cc":"markdown","078fa0c6":"markdown","7499752a":"markdown","d10c813a":"markdown","9e2a879c":"markdown","99f447e1":"markdown","6805dcff":"markdown","fb339aff":"markdown","690e78bb":"markdown","cb85adbf":"markdown","bfc15b33":"markdown","2f006a8d":"markdown","56742d8a":"markdown","1dfbf7ef":"markdown","dd0c8288":"markdown","af81d5a6":"markdown","285197cb":"markdown","2cb7084a":"markdown","66dff50e":"markdown","002d6b52":"markdown","49b75607":"markdown","463c9ef5":"markdown","35d03190":"markdown","54908d4f":"markdown","2e4e09d5":"markdown","c318ad7c":"markdown","f781e17b":"markdown","a211d65c":"markdown","c4809d89":"markdown","652c2d23":"markdown","9d8ced21":"markdown","d52598c1":"markdown","8b4a2100":"markdown","24e57308":"markdown","c7b5a882":"markdown","62c807f5":"markdown","1e8be125":"markdown","57dfb589":"markdown","67a0a331":"markdown","5eef0633":"markdown","488eb8a4":"markdown","d16daed4":"markdown","d57dc2c0":"markdown","1e986bac":"markdown","d7569955":"markdown","0032c5fa":"markdown","68c74dab":"markdown","923d220b":"markdown","bfbc132e":"markdown","9af0f992":"markdown","a48a3fae":"markdown","e5bc6ae5":"markdown","9c3635a2":"markdown","362f0756":"markdown","5c69a92b":"markdown","00d27e55":"markdown","1c3aa77a":"markdown","24192639":"markdown","9ff0a1e6":"markdown","0ddb65cb":"markdown","e0c6b914":"markdown","79d616e6":"markdown","5c04999f":"markdown","276092b4":"markdown","c9bfac24":"markdown","637d4708":"markdown","42e9eb44":"markdown","d4f4e64d":"markdown","fc96c292":"markdown","46466af1":"markdown","76091998":"markdown","3efed8f3":"markdown","f6ce4ebd":"markdown","137d8a2f":"markdown","3d26dbad":"markdown"},"source":{"4201d3a9":"# Importing the necessary libraries\nimport numpy                            as np                        # importing numpy library\nimport pandas                           as pd                        # importing pandas library\nimport seaborn                          as sns                       # For Data Visualization \nimport matplotlib.pyplot                as plt                       # Necessary module for plotting purpose\nimport warnings                                                      # importing warning library\n\n# add graphs into jupiter notebook\n%matplotlib inline                             \nwarnings.filterwarnings('ignore')                                    # for ignoring warnings in notebook\n\nimport statsmodels.api                  as sm                        # importing statsmodel api\nfrom sklearn import model_selection                                  # For model_selection\nfrom sklearn.model_selection            import train_test_split      # For train-test split\n\n# getting methods for confusion matrix, F1 score, Accuracy Score\nfrom sklearn import metrics                                          \nfrom sklearn.metrics                    import confusion_matrix,f1_score,accuracy_score,classification_report,roc_curve,auc,average_precision_score\nfrom sklearn.linear_model               import LogisticRegression    # For logistic Regression\nfrom sklearn.naive_bayes                import GaussianNB            # For Naive Bayes classifier\nfrom sklearn.neighbors                  import KNeighborsClassifier  # For K-NN Classifier\nfrom sklearn.svm                        import SVC                   # For support vector machine based classifier\n\n## Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6d823d16":"pdDataOrg = pd.read_csv(\"..\/input\/parkinson-disease-detection\/Parkinsson disease.csv\")        # using pandas read_csv function to load dataset into pdData variable\npdDataOrg.head()                                    # fetching and showing top 5 rows of the pdData variable","b96ed074":"'''\nTo use columns of pdDataOrg df more conveniently following are some changes I have done\n    a. pushing target column i.e 'status' to last column\n    b. converting all column names in lower case\n    c. replacing spaces in column names with '_'\n    d. replacing ':' in column names with '_'\n    e. replacing '(' in column names with '_'\n    f. replacing ')' in column names with '' i.e blank\n    g. replacing '%' in column names with 'in_percent'\n'''\n\npdData = pdDataOrg.copy()                                               # creating a copy of loanDataOrg into loanData\n\ntargetCol = 'status'                                                    # defining target column\ntargetColDf = pdData.pop(targetCol)                                     # popping target column from loanData df\npdData.insert(len(pdData.columns),targetCol, targetColDf)               # inserting target column to last column\n\n# deleting variables that were used for changing column position of target column\ndel targetCol \ndel targetColDf\n\n# converting column names into lower case\npdData.columns = [c.lower() for c in pdData.columns]\n# replacing spaces in column names with '_'\npdData.columns = [c.replace(' ', '_') for c in pdData.columns]\n# replacing ':' in column names with '_'\npdData.columns = [c.replace(':', '_') for c in pdData.columns]\n# replacing '(' in column names with '_'\npdData.columns = [c.replace('(', '_') for c in pdData.columns]\n# replacing ')' in column names with '' i.e blank\npdData.columns = [c.replace(')', '') for c in pdData.columns]\n# replacing '%' in column names with 'in_percent'\npdData.columns = [c.replace('%', 'in_percent') for c in pdData.columns]\n\n# to check the above printing top 5 rows\npdData.head()","4ee0bc9d":"print('\\033[1mThe Parkinson\\'s disease dataset having \"{0}\" rows and \"{1}\" columns\\033[0m.'.format(pdData.shape[0],pdData.shape[1]))","4ff65d1d":"pdData.info()","c85c8f5a":"# setting name column as index column\npdData.set_index('name',inplace=True)","b5e46550":"# after setting column 'name' as index now we have less columns to confirm that printing number of rows and column once again\nprint('\\033[1mAfter setting \\'name\\' column as index of the Dataset,\\033[0m now there are \\033[1m\"{0}\"\\033[0m Rows and \\033[1m\"{1}\"\\033[0m Columns in the given Dataset.'.format(pdData.shape[0],pdData.shape[1]))","35d23993":"# printing top 5 rows once again to check\npd.options.display.max_columns = None\npdData.head()","ec232144":"# printing datatypes of each columns of the dataset\n\nprint(\"\\033[1m*\"*100)\nprint(\"a.\\nColumn_Names        Data_Types\")\nprint(\"*\"*30)\nprint(\"\\033[0m{0}\\033[1m\".format(pdData.dtypes))\nprint(\"*\"*30)\nprint()\n\n# printing No of Columns having different Types of Datatype\n\nprint(\"*\"*100)\nprint(\"b.\\nNumber of Columns with each DataTypes as follows :\")\nprint(\"*\"*50)\nprint(\"Column_Names     No_of_Columns\\033[0m\")\nprint(\"*\"*30)\nprint(pdData.dtypes.value_counts())\nprint(\"\\033[1m*\"*30)\nprint(\"\\033[0m\")\n\n# printing Different Column Names of the dataset\n\nprint(\"\\033[1m*\"*100)\nprint(\"c.\\nEach Column Names of the dataset\")\nprint(\"*\"*80)\nprint(\"\\033[0m{0}\\033[1m\".format(pdData.columns))\nprint(\"*\"*80)\nprint(\"\\033[0m\")","8747468e":"# checking missing values in dataset for each attributes \/ columns \n\nprint(\"\\033[1m*\"*100)\nprint(\"Column_Name       No_of_Missing_Values\")\nprint(\"*\"*50)\nprint(\"\\033[0m{0}\".format(pdData.isnull().sum()))\nprint(\"\\033[1m*\"*50)\nprint()\n\n# checking if any duplicate rows available in the dataset\n\nprint(\"*\"*100)\nprint(\"Showing Duplicate rows if any in the dataset: \")\nprint(\"*\"*50)\nprint(\"\\033[0m{0}\".format(pdData[pdData.duplicated()]))\nprint(\"\\033[1m*\"*100)\nprint(\"\\033[0m\")","4ff6f8f9":"# Five point summary of each attribute\npdData.describe().T","5b21a259":"# checking skewness of the data\npdData.skew().sort_values(ascending=False)","88c02c2e":"feature = 'mdvp_fo_hz'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),4))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","4ee83674":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","cad400c6":"bins = [50,100,150,200,250,300]                                         # defining mdvp_fo_hz bins,\n# defining labels of mdvp_fo_hz groups as per bins defined as above\nmdvp_fo_hz_group = ['mdvp_fo_hz : 50-100', 'mdvp_fo_hz : 100-150', 'mdvp_fo_hz : 150-200', 'mdvp_fo_hz : 200-250', 'mdvp_fo_hz : 250-300']\npdData_mdvp_fo_hz_bin = pd.cut(pdData.mdvp_fo_hz,bins,labels=mdvp_fo_hz_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_fo_hz_group_col variable\nmdvp_fo_hz_group_col = pd.crosstab(pdData_mdvp_fo_hz_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_fo_hz_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_fo_hz_group_col.div(mdvp_fo_hz_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_fo_hz group\")                     # setting title of the figure","ecc92588":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","12ca8232":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","dcb4dddc":"feature = 'mdvp_fhi_hz'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),4))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","6204f4f7":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","9cb80cb9":"bins = [100,200,300,400,500,600]                                         # defining mdvp_fhi_hz bins,\n# defining labels of mdvp_fhi_hz groups as per bins defined as above\nmdvp_fhi_hz_group = ['mdvp_fhi_hz : 100-200', 'mdvp_fhi_hz : 200-300', 'mdvp_fhi_hz : 300-400', 'mdvp_fhi_hz : 400-500',\n                     'mdvp_fhi_hz : 500-600']\npdData_mdvp_fhi_hz_bin = pd.cut(pdData[feature],bins,labels=mdvp_fhi_hz_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_fhi_hz_group_col variable\nmdvp_fhi_hz_group_col = pd.crosstab(pdData_mdvp_fhi_hz_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_fhi_hz_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_fhi_hz_group_col.div(mdvp_fhi_hz_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_fhi_hz group\")                     # setting title of the figure","d0606bf2":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","2805311c":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),3),round(np.median(pdData[feature]),3),round(IQR,3))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","4fdeede4":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","47c27f5f":"feature = 'mdvp_flo_hz'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),4))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","34d39eea":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","f0ccaa26":"bins = [50,100,150,200,250]                                         # defining mdvp_flo_hz bins,\n# defining labels of mdvp_flo_hz groups as per bins defined as above\nmdvp_flo_hz_group = ['mdvp_flo_hz : 50-100', 'mdvp_flo_hz : 100-150', 'mdvp_flo_hz : 150-200', 'mdvp_flo_hz : 200-250']\npdData_mdvp_flo_hz_bin = pd.cut(pdData[feature],bins,labels=mdvp_flo_hz_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_flo_hz_group_col variable\nmdvp_flo_hz_group_col = pd.crosstab(pdData_mdvp_flo_hz_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_flo_hz_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_flo_hz_group_col.div(mdvp_flo_hz_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_flo_hz group\")                     # setting title of the figure","07766925":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","f476373e":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),3),round(np.median(pdData[feature]),3),round(IQR,3))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","3d636b69":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","ef4ae6b2":"feature = 'mdvp_jitter_in_percent'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),4))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","0dcc10f4":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","40443e18":"bins = [0.001,0.005,0.010,0.015,0.020,0.025,0.030,0.035]                                         # defining mdvp_jitter_in_percent bins,\n# defining labels of mdvp_jitter_in_percent groups as per bins defined as above\nmdvp_jitter_in_percent_group = ['0.001-0.005', '0.005-0.010', '0.010-0.015', '0.015-0.020', '0.020-0.025', '0.025-0.030',\n                                '0.030-0.035']\npdData_mdvp_jitter_in_percent_bin = pd.cut(pdData[feature],bins,labels=mdvp_jitter_in_percent_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_jitter_in_percent_group_col variable\nmdvp_jitter_in_percent_group_col = pd.crosstab(pdData_mdvp_jitter_in_percent_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_jitter_in_percent_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_jitter_in_percent_group_col.div(mdvp_jitter_in_percent_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_jitter_in_percent group\")                     # setting title of the figure","e61830a0":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","4e0eb915":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),3),round(np.median(pdData[feature]),3),round(IQR,3))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","af4294d7":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","c775c5e8":"feature = 'mdvp_jitter_abs'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","fa5dcd52":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","3fce1efd":"bins = [0.00004,0.00010,0.00015,0.00020,0.00026]                                         # defining mdvp_jitter_abs bins,\n# defining labels of mdvp_jitter_abs groups as per bins defined as above\nmdvp_jitter_abs_group = ['0.00004-0.00010', '0.00010-0.00015', '0.00015-0.00020', '0.00020-0.00026']\npdData_mdvp_jitter_abs_bin = pd.cut(pdData[feature],bins,labels=mdvp_jitter_abs_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_jitter_abs_group_col variable\nmdvp_jitter_abs_group_col = pd.crosstab(pdData_mdvp_jitter_abs_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_jitter_abs_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_jitter_abs_group_col.div(mdvp_jitter_abs_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_jitter_abs group\")                     # setting title of the figure","3577b3ae":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","0d5ca104":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","00ebca78":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","fe14b34f":"feature = 'mdvp_rap'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","8cef0e2e":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","03f39d14":"bins = [0.000,0.005,0.010,0.015,0.020,0.025]                                         # defining mdvp_rap bins,\n# defining labels of mdvp_rap groups as per bins defined as above\nmdvp_rap_group = ['0.000-0.005', '0.005-.010', '0.010-0.015', '0.015-0.020', '0.020-0.025']\npdData_mdvp_rap_bin = pd.cut(pdData[feature],bins,labels=mdvp_rap_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_rap_group_col variable\nmdvp_rap_group_col = pd.crosstab(pdData_mdvp_rap_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_rap_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_rap_group_col.div(mdvp_rap_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_rap group\")                     # setting title of the figure","9649c8ff":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","a69ad0cf":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","7f2d6e21":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","2eba05cf":"feature = 'mdvp_ppq'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","4de1690e":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","4bff17a1":"bins = [0.000,0.005,0.010,0.015,0.020]                                         # defining mdvp_ppq bins,\n# defining labels of mdvp_ppq groups as per bins defined as above\nmdvp_ppq_group = ['0.000-0.005', '0.005-.010', '0.010-0.015', '0.015-0.020']\npdData_mdvp_ppq_bin = pd.cut(pdData[feature],bins,labels=mdvp_ppq_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_ppq_group_col variable\nmdvp_ppq_group_col = pd.crosstab(pdData_mdvp_ppq_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_ppq_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_ppq_group_col.div(mdvp_ppq_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_ppq group\")                     # setting title of the figure","0b47b983":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","11a62266":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","612a557e":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","a512d7f7":"feature = 'jitter_ddp'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","cc12ef72":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","feb9d684":"bins = [0.00,0.02,0.04,0.06,0.80]                                         # defining jitter_ddp bins,\n# defining labels of jitter_ddp groups as per bins defined as above\njitter_ddp_group = ['0.00-0.02', '0.02-0.04', '0.04-0.06', '0.06-0.08']\npdData_jitter_ddp_bin = pd.cut(pdData[feature],bins,labels=jitter_ddp_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to jitter_ddp_group_col variable\njitter_ddp_group_col = pd.crosstab(pdData_jitter_ddp_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(jitter_ddp_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\njitter_ddp_group_col.div(jitter_ddp_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different jitter_ddp group\")                     # setting title of the figure","3a5aebc8":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","6bc2e3f4":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","2030bdbc":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","a711c8f5":"feature = 'mdvp_shimmer'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","10a996e4":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","32d2f4f1":"bins = [0.00,0.02,0.04,0.06,0.08,0.10,0.12]                                         # defining mdvp_shimmer bins,\n# defining labels of mdvp_shimmer groups as per bins defined as above\nmdvp_shimmer_group = ['0.00-0.02', '0.02-0.04', '0.04-0.06', '0.06-0.08', '0.08-0.10', '0.10-0.12']\npdData_mdvp_shimmer_bin = pd.cut(pdData[feature],bins,labels=mdvp_shimmer_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_shimmer_group_col variable\nmdvp_shimmer_group_col = pd.crosstab(pdData_mdvp_shimmer_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_shimmer_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_shimmer_group_col.div(mdvp_shimmer_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_shimmer group\")                     # setting title of the figure","8ed73424":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","414eda06":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","5fab6b21":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","c6051956":"feature = 'mdvp_shimmer_db'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","34cfa57e":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","de7b0536":"bins = [0.00, 0.25, 0.50, 0.75, 1.00, 1.25, 1.50]                                         # defining mdvp_shimmer_db bins,\n# defining labels of mdvp_shimmer_db groups as per bins defined as above\nmdvp_shimmer_db_group = ['0.00-0.25', '0.25-0.50', '0.50-0.75', '0.75-1.00', '1.00-1.25', '1.25-1.50']\npdData_mdvp_shimmer_db_bin = pd.cut(pdData[feature],bins,labels=mdvp_shimmer_db_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_shimmer_db_group_col variable\nmdvp_shimmer_db_group_col = pd.crosstab(pdData_mdvp_shimmer_db_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_shimmer_db_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_shimmer_db_group_col.div(mdvp_shimmer_db_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_shimmer_db group\")                     # setting title of the figure","f508dc58":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","a9d9b2ba":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","959c2f54":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","a3f26486":"feature = 'shimmer_apq3'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","6e89cafe":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","7b2e75bc":"bins = [0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06]                                         # defining shimmer_apq3 bins,\n# defining labels of shimmer_apq3 groups as per bins defined as above\nshimmer_apq3_group = ['0.00-0.01', '0.01-0.02', '0.02-0.03', '0.03-0.04', '0.04-0.05', '0.05-0.06']\npdData_shimmer_apq3_bin = pd.cut(pdData[feature],bins,labels=shimmer_apq3_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to shimmer_apq3_group_col variable\nshimmer_apq3_group_col = pd.crosstab(pdData_shimmer_apq3_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(shimmer_apq3_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nshimmer_apq3_group_col.div(shimmer_apq3_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different shimmer_apq3 group\")                     # setting title of the figure","71fc4572":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","f7632153":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","4fdda0cb":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","b6e27221":"feature = 'shimmer_apq5'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","5f5e6afe":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","ff0a3584":"bins = [0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08]                                         # defining shimmer_apq5 bins,\n# defining labels of shimmer_apq5 groups as per bins defined as above\nshimmer_apq5_group = ['0.00-0.01', '0.01-0.02', '0.02-0.03', '0.03-0.04', '0.04-0.05', '0.05-0.06', '0.06-0.08']\npdData_shimmer_apq5_bin = pd.cut(pdData[feature],bins,labels=shimmer_apq5_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to shimmer_apq5_group_col variable\nshimmer_apq5_group_col = pd.crosstab(pdData_shimmer_apq5_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(shimmer_apq5_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nshimmer_apq5_group_col.div(shimmer_apq5_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different shimmer_apq5 group\")                     # setting title of the figure","1581b852":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","e8e86cd4":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","7dc3a73b":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","5db446a2":"feature = 'mdvp_apq'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","1a032cf2":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","11bd6d83":"bins = [0.00, 0.02, 0.04, 0.06, 0.08, 0.10, 0.14]                                         # defining mdvp_apq bins,\n# defining labels of mdvp_apq groups as per bins defined as above\nmdvp_apq_group = ['0.00-0.02', '0.02-0.04', '0.04-0.06', '0.06-0.08', '0.08-0.10', '0.10-0.14']\npdData_mdvp_apq_bin = pd.cut(pdData[feature],bins,labels=mdvp_apq_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to mdvp_apq_group_col variable\nmdvp_apq_group_col = pd.crosstab(pdData_mdvp_apq_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(mdvp_apq_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nmdvp_apq_group_col.div(mdvp_apq_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different mdvp_apq group\")                     # setting title of the figure","b550aa2a":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","ae90b984":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","1a21051c":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","1b7affdb":"feature = 'shimmer_dda'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","4bf230c6":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","7208f7e2":"bins = [0.010, 0.025, 0.050, 0.075, 0.100, 0.125, 0.150]                                         # defining shimmer_dda bins,\n# defining labels of shimmer_dda groups as per bins defined as above\nshimmer_dda_group = ['0.010-0.025', '0.025-0.050', '0.050-0.075', '0.075-0.100', '0.100-0.125', '0.125-0.150']\npdData_shimmer_dda_bin = pd.cut(pdData[feature],bins,labels=shimmer_dda_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to shimmer_dda_group_col variable\nshimmer_dda_group_col = pd.crosstab(pdData_shimmer_dda_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(shimmer_dda_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nshimmer_dda_group_col.div(shimmer_dda_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different shimmer_dda group\")                     # setting title of the figure","44f72016":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","ac6e31ea":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","15f38ac3":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","f730eea6":"feature = 'nhr'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","d22dd340":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","4054a892":"bins = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.32]                                         # defining nhr bins,\n# defining labels of nhr groups as per bins defined as above\nnhr_group = ['0.00-0.05', '0.05-0.10', '0.10-0.15', '0.15-0.20', '0.20-0.25', '0.25-0.32']\npdData_nhr_bin = pd.cut(pdData[feature],bins,labels=nhr_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to nhr_group_col variable\nnhr_group_col = pd.crosstab(pdData_nhr_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(nhr_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nnhr_group_col.div(nhr_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different nhr group\")                     # setting title of the figure","f29e52fc":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","f7a94d2c":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","896b5da4":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","f391d8ca":"feature = 'hnr'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","69bbfd39":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","965cde73":"bins = [8, 10, 15, 20, 25 , 30, 34]                                         # defining hnr bins,\n# defining labels of hnr groups as per bins defined as above\nhnr_group = ['8-10', '10-15', '15-20', '20-25', '25-30', '30-34']\npdData_hnr_bin = pd.cut(pdData[feature],bins,labels=hnr_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to hnr_group_col variable\nhnr_group_col = pd.crosstab(pdData_hnr_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(hnr_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nhnr_group_col.div(hnr_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different hnr group\")                     # setting title of the figure","e31f3fc4":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","12dd300d":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","9042ccb1":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","3a60b174":"feature = 'rpde'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","070cfa90":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","fe969832":"bins = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]                                         # defining rpde bins,\n# defining labels of rpde groups as per bins defined as above\nrpde_group = ['0.25-0.35', '0.35-0.45', '0.45-0.55', '0.55-0.65', '0.65-0.75']\npdData_rpde_bin = pd.cut(pdData[feature],bins,labels=rpde_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to rpde_group_col variable\nrpde_group_col = pd.crosstab(pdData_rpde_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(rpde_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nrpde_group_col.div(rpde_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different rpde group\")                     # setting title of the figure","f334168c":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","2311c811":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","3a755cd9":"feature = 'd2'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","6ddad1b4":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","5022e352":"bins = [1.0, 1.5, 2.0, 2.5, 3.0, 3.7]                                         # defining d2 bins,\n# defining labels of d2 groups as per bins defined as above\nd2_group = ['1.0-1.5', '1.5-2.0', '2.0-2.5', '2.5-3.0', '3.0-3.7']\npdData_d2_bin = pd.cut(pdData[feature],bins,labels=d2_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to d2_group_col variable\nd2_group_col = pd.crosstab(pdData_d2_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(d2_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nd2_group_col.div(d2_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different d2 group\")                     # setting title of the figure","7091c364":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","599c8d4f":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","e8d7b487":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","e8a496b7":"feature = 'dfa'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","698ff466":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","e8ca925c":"bins = [0.5, 0.6, 0.7, 0.8, 0.9]                                         # defining dfa bins,\n# defining labels of dfa groups as per bins defined as above\ndfa_group = ['0.5-0.6', '0.6-0.7', '0.7-0.8', '0.8-0.9']\npdData_dfa_bin = pd.cut(pdData[feature],bins,labels=dfa_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to dfa_group_col variable\ndfa_group_col = pd.crosstab(pdData_dfa_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(dfa_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\ndfa_group_col.div(dfa_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different dfa group\")                     # setting title of the figure","e7282b92":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","c02a8000":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","e09fc251":"feature = 'spread1'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","e9450b47":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","52cc2791":"bins = [-8,-6,-4,-2]                                         # defining spread1 bins,\n# defining labels of spread1 groups as per bins defined as above\nspread1_group = ['-8 : -6', '-6 : -4', '-4 : -2']\npdData_spread1_bin = pd.cut(pdData[feature],bins,labels=spread1_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to spread1_group_col variable\nspread1_group_col = pd.crosstab(pdData_spread1_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(spread1_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nspread1_group_col.div(spread1_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different spread1 group\")                     # setting title of the figure","6d19e045":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","0654fb8c":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","96c00ed7":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","370826eb":"feature = 'spread2'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","dd2f1ebd":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","56ae7e46":"bins = [0.0, 0.1, 0.2, 0.3, 0.4,0.5]                                         # defining spread2 bins,\n# defining labels of spread2 groups as per bins defined as above\nspread2_group = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4', '0.4-0.5']\npdData_spread2_bin = pd.cut(pdData[feature],bins,labels=spread2_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to spread2_group_col variable\nspread2_group_col = pd.crosstab(pdData_spread2_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(spread2_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nspread2_group_col.div(spread2_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different spread2 group\")                     # setting title of the figure","3c695233":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","e2a74f99":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","c9c8a078":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","b8698d4f":"feature = 'ppe'\nmeanData = 'Mean : ' + str(round(pdData[feature].mean(),6))        # variable to contain mean of the attribute\nskewData = 'Skewness : ' + str(round(pdData[feature].skew(),4))    # variable to contain skewness of the attribute\nplt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\nfig = sns.distplot(pdData[feature], bins=30, kde=True)             # seaborn distplot to examine distribution of the feature\nplt.title(\"Distribution of feature : \"+feature+\" having \"+meanData+\" and \"+skewData)   # setting title of the figure\nplt.show()","b468a2fa":"plt.figure(figsize=(10,5))                                         # setting figure size with width = 10 and height = 5\n# seaborn distplot to examine distribution of the feature of healthy patient\nfig = sns.distplot(pdData[pdData['status'] == 0][feature], bins=30, kde=True, label='Healthy')\n# seaborn distplot to examine distribution of the feature of Parkinson's patient\nfig = sns.distplot(pdData[pdData['status'] == 1][feature], bins=30, kde=True, label='Parkinson\\'s')\nplt.legend()\nplt.title(\"Distribution of feature : \"+feature)                    # setting title of the figure\nplt.show()","ce2c34a6":"bins = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]                                         # defining ppe bins,\n# defining labels of ppe groups as per bins defined as above\nppe_group = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4', '0.4-0.5']\npdData_ppe_bin = pd.cut(pdData[feature],bins,labels=ppe_group)  # segmenting data as per bins defined\n\n# putting into pandas crosstab and applying lambda function to take percentage and assigning to ppe_group_col variable\nppe_group_col = pd.crosstab(pdData_ppe_bin,pdData.status).apply(lambda r: r\/r.sum()*100, axis=1)\nprint(ppe_group_col)                                                    # printing above crosstab\n\n# plotting a stacked bar chart to show PD status for different mdvp_fo_hz group\nppe_group_col.div(ppe_group_col.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True)\nplt.title(\"PD status with different ppe group\")                     # setting title of the figure","27a99cf4":"ax = sns.boxplot(x=pdData[feature])        # seaborn boxplot to examine outliers of the feature","f3e959ba":"Q1 = pdData[feature].quantile(0.25)        # evaluating lower \/ first quartile\nQ3 = pdData[feature].quantile(0.75)        # evaluating upper \/ third quartile\nIQR = Q3 - Q1                              # evaluating Inter Quartile Range i.e IQR\n'''\nfinding outliers which are mild outliers (Lower quartile - 1.5 times IQR) or\nextreme outliers (Upper quartile + 1.5 times IQR)\n'''\noutliers = pdData[((pdData[feature] < (Q1 - 1.5 * IQR)) |(pdData[feature] > (Q3 + 1.5 * IQR)))][feature]\n\nprint(\"*\"*125)\n# printing mean, median and IQR for the feature\nprint(\"\\033[1mFeature {0} : Mean = {1}, Median = {2} and Inter-Quartile-Range (IQR) = {3}\\033[0m\"\n      .format(feature,round(np.mean(pdData[feature]),6),round(np.median(pdData[feature]),6),round(IQR,6))\n     )\nprint()\nprint(\"*\"*125)\n# printing No of outliers, percentage of the data points are outliers and the values of the outliers\nprint(\"There are \\033[1m{0} outliers\\033[0m ({1} % of the data points) in \\033[1m{2}\\033[0m feature and the values are \\033[1m{3}\\033[0m\"\n.format(outliers.shape[0],round(((outliers.shape[0]\/pdData[feature].shape[0])*100),3),feature,outliers.tolist()))\nprint(\"*\"*125)","9d2c9b24":"sns.boxplot(x=pdData['status'],y=pdData[feature]) ","40593a8f":"plt.figure(figsize=(10,5))                                 # setting figure size with width = 10 and height = 5\n# seaborn count catplot to examine distribution of the status\nax = sns.catplot(x='status', kind=\"count\", data=pdData)\nplt.title(\"Distribution of column : 'Status'\")      # setting title of the figure\ny = []                                                     # creating a null or empty array\nfor val in range(pdData.status.nunique()):        # looping for number of unique values in the status\n    # appending count of each unique values from status to array y\n    y.append(pdData.groupby(pdData.status,sort=False)['status'].count()[val])\nfor i, v in enumerate(y):                                  # looping count of each unique value in the status\n    # including count of each unique values in the plot \n    plt.annotate(str(v), xy=(i,float(v)), xytext=(i-0.1, v+3), color='black', fontweight='bold')","0280498b":"plt.figure(figsize=(5,5))                               # setting figure size with width = 10 and height = 5\n# seaborn pie chart to examine distribution of the status\npdData.groupby(['status']).status.count().plot(kind='pie',labels=['Healthy : 0','Parkinson\\'s : 1'],\n                                                               startangle=90, autopct='%1.1f%%')\nplt.title(\"Distribution of column : 'status'\")   # setting title of the figure","06549d85":"sns.pairplot(pdData,hue='status',diag_kind='hist')","278deb49":"plt.figure(figsize=(20,7))\n# create a mask so we only see the correlation values once\nmask = np.zeros_like(pdData.corr())\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(pdData.corr(),mask=mask, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)","df8dcf75":"#Split the data into training and test set in the ratio of 70:30 respectively\nX = pdData.drop(['status'],axis=1)\ny = pdData['status']\n\n# split data into train subset and test subset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=47)\n\n# checking the dimensions of the train & test subset\n# printing dimension of train set\nprint(X_train.shape)\n# printing dimension of test set\nprint(X_test.shape)","52783412":"X_train.drop(['mdvp_jitter_in_percent'],axis=1,inplace=True)\nX_test.drop(['mdvp_jitter_in_percent'],axis=1,inplace=True)","bbc269ca":"X_train.drop(['mdvp_shimmer'],axis=1,inplace=True)\nX_test.drop(['mdvp_shimmer'],axis=1,inplace=True)","ef2804f3":"X_train.drop(['hnr'],axis=1,inplace=True)\nX_test.drop(['hnr'],axis=1,inplace=True)","682da3ef":"# re checking the dimensions of the train & test subset after dropping several columns from the subsets\n# printing dimension of train set\nprint(X_train.shape)\n# printing dimension of test set\nprint(X_test.shape)","0b5b64d8":"# Let us scale train as well as test data using StandardScaler\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)","b9300807":"# Train and Fit model\nlr = LogisticRegression(random_state=0)\nlr.fit(X_train_scaled, y_train)\n\n#predict status for X_test_scaled dataset \nlr_y_pred = lr.predict(X_test_scaled)\n\n# Confusion Matrix for the Logistic Regression Model\nprint(\"Confusion Matrix : Logistic Regression\")\nprint(confusion_matrix(y_test,lr_y_pred))\n\n# Classification Report for the Logistic Regression Model\nclassRep = classification_report(y_test, lr_y_pred, digits=2)\nprint(classRep)","25726e70":"# creating odd list of K for KNN\nmyList = list(range(3,40,2))\n\n# creating empty list for F1 scores od different value of K\nf1ScoreList = []\n\n# perform accuracy metrics for values from 3,5....29\nfor k in myList:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train_scaled, y_train)\n    # predict the response\n    y_pred = knn.predict(X_test_scaled)\n    # evaluate F1 Score\n    f1Score = f1_score(y_test, y_pred)\n    f1ScoreList.append(f1Score)\n\n# changing to misclassification error\nMSE = [1 - x for x in f1ScoreList]\n\n# determining best k\nbestk = myList[MSE.index(min(MSE))]\nprint(\"The optimal number of neighbors is %d\" % bestk)","4ec2775d":"# instantiate learning model (k = 29)\nknn = KNeighborsClassifier(n_neighbors = 29, weights = 'uniform', metric='euclidean')\n\n# fitting the model\nknn.fit(X_train_scaled, y_train)\n\n# predict the response\nknn_y_pred = knn.predict(X_test_scaled)\n\n# Confusion Matrix for the K-nearest neighbors Model\nprint(\"Confusion Matrix : K-nearest neighbors\")\nprint(confusion_matrix(y_test,knn_y_pred))\n\n# Classification Report for the K-nearest neighbors Model\nclassRep = classification_report(y_test, knn_y_pred, digits=2)\nprint(classRep)","e46d92fb":"svm = SVC(gamma=0.05, C=70,random_state=47)\nsvm.fit(X_train_scaled , y_train)\n\n# predict the response\nsvm_y_pred = svm.predict(X_test_scaled)\n\n# Confusion Matrix for the Support Vector Machine Model\nprint(\"Confusion Matrix : Support Vector Machine\")\nprint(confusion_matrix(y_test,svm_y_pred))\n\n# Classification Report for the Support Vector Machine Model\nclassRep = classification_report(y_test, svm_y_pred, digits=2)\nprint(classRep)","dd55f3a5":"#Using K fold to check how the above algorighms varies throughout the dataset with 10 different subset of equal bins\nmodels = []\nmodels.append(('Logistic Regression', LogisticRegression(random_state=47)))\nmodels.append(('K-NN', KNeighborsClassifier(n_neighbors = 29, weights = 'uniform', metric='euclidean')))\nmodels.append(('SVM', SVC(gamma=0.05, C=70,random_state=47)))\n\n# evaluate each model\nresults = []\nnames = []\nscoring = 'f1'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=47)\n    cv_results = model_selection.cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print(\"\\033[1m{0}\\033[0m model have \\033[1mmean F1-Score\\033[0m of {1} and \\033[1mSD F1-Score\\033[0m of {2}\".format(name, cv_results.mean(), cv_results.std()))","6a0764de":"plt.title('Algorithm Comparison')\nplt.plot(results[0],label='Logistic')\nplt.plot(results[1],label='KNN')\nplt.plot(results[2],label='SVM')\nplt.legend()","7e05cb64":"# defining level hetrogenious model\nlevel0 = list()\nlevel0.append(('lr', LogisticRegression(random_state=47)))\nlevel0.append(('knn', KNeighborsClassifier(n_neighbors = 29, weights = 'uniform', metric='euclidean')))\nlevel0.append(('cart', DecisionTreeClassifier()))\nlevel0.append(('svm', SVC(gamma=0.05, C=70,random_state=47)))\nlevel0.append(('bayes', GaussianNB()))\n\n# define meta learner model\nlevel1 = SVC(gamma=0.05, C=3,random_state=47)\n\n# define the stacking ensemble with cross validation of 5\nStack_model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n\n# predict the response\nStack_model.fit(X_train_scaled, y_train)\nprediction_Stack = Stack_model.predict(X_test_scaled)\n\n# Confusion Matrix for the Stacking Model\nprint(\"Confusion Matrix : Stacking\")\nprint(confusion_matrix(y_test,prediction_Stack))\n\n# Classification Report for the Stacking Model\nprint(classification_report(y_test, prediction_Stack, digits=2))","f969955a":"#determining false positive rate and True positive rate, threshold\nfpr, tpr, threshold = metrics.roc_curve(y_test, prediction_Stack)\nroc_auc_stack = metrics.auc(fpr, tpr)\n\n#plotting ROC curve\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_stack)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","00cadfe6":"#creating model of Random Forest\nRandomForest = RandomForestClassifier(n_estimators = 100,criterion='entropy',max_features=10,random_state=47)\nRandomForest = RandomForest.fit(X_train_scaled, y_train)\n\n# predict the response\nRandomForest_pred = RandomForest.predict(X_test_scaled)\n\n# Confusion Matrix for the Random Forest Model\nprint(\"Confusion Matrix : Random Forest\")\nprint(confusion_matrix(y_test,RandomForest_pred))\n\n# Classification Report for the Randome Forest Model\nprint(classification_report(y_test, RandomForest_pred, digits=2))","52bee70c":"#determining false positive rate and True positive rate, threshold\nfpr, tpr, threshold = metrics.roc_curve(y_test, RandomForest_pred)\nroc_auc_rf = metrics.auc(fpr, tpr)\n\n#plotting ROC curve\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_rf)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","2fe49e13":"# Lets check features importance\nfeature_imp = pd.Series(RandomForest.feature_importances_,index=X_train.columns).sort_values(ascending=False)\nfeature_imp","65a2b12b":"# Creating a bar plot\nsns.barplot(x=feature_imp, y=feature_imp.index)\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')","9c5d3cc6":"#creating model of Adaptive Boosting\nAdBs = AdaBoostClassifier( n_estimators= 50)\nAdBs  = AdBs.fit(X_train_scaled, y_train)\n\n# predict the response\nAdBs_y_pred = AdBs.predict(X_test_scaled)\n\n# Confusion Matrix for the Adaptive Boosting Model\nprint(\"Confusion Matrix : Adaptive Boosting\")\nprint(confusion_matrix(y_test,AdBs_y_pred))\n\n# Classification Report for the Adaptive Boosting Model\nprint(classification_report(y_test, AdBs_y_pred, digits=2))","804856f2":"#determining false positive rate and True positive rate, threshold\nfpr, tpr, threshold = metrics.roc_curve(y_test, AdBs_y_pred)\nroc_auc_ada = metrics.auc(fpr, tpr)\n\n#plotting ROC curve\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_ada)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","b85ca9c5":"#Using K fold to check how the various algorighms varies throughout the dataset with 10 different subset of equal bins\nmodels = []\nmodels.append(('Logistic Regression', LogisticRegression(random_state=47)))\nmodels.append(('K-NN', KNeighborsClassifier(n_neighbors = 29, weights = 'uniform', metric='euclidean')))\nmodels.append(('SVM', SVC(gamma=0.05, C=70,random_state=47)))\nmodels.append(('Stacking', StackingClassifier(estimators=level0, final_estimator=level1, cv=5)))\nmodels.append(('Random Forest', RandomForestClassifier(n_estimators = 100,criterion='entropy',max_features=10,random_state=47)))\nmodels.append(('Adaptive Boosting', AdaBoostClassifier( n_estimators= 50)))\n\n# evaluate each model with scoring method accuracy\nprint(\"*\"*125)\nprint(\"Accuracy scoring of the Models\")\nprint(\"*\"*125)\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=47)\n    cv_results = model_selection.cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print(\"\\033[1m{0}\\033[0m model have \\033[1mmean Accuracy\\033[0m of {1} and \\033[1mSD Accuracy\\033[0m of {2}\"\n          .format(name, round(cv_results.mean(),2), round(cv_results.std(),2))) \n\n\nprint()\nprint(\"*\"*125)\nprint(\"F1 scoring of the Models\")\nprint(\"*\"*125)\n\n# evaluate each model with scoring method f1\nresults = []\nnames = []\nscoring = 'f1'\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state=47)\n    cv_results = model_selection.cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print(\"\\033[1m{0}\\033[0m model have \\033[1mmean F1-Score\\033[0m of {1} and \\033[1mSD F1-Score\\033[0m of {2}\"\n          .format(name, round(cv_results.mean(),2), round(cv_results.std(),2)))    ","4da5d4e2":"* Now will check if any outliers present for different target attributes i.e 'status'","e048d20f":"* Now will check if any outliers present for different target attributes i.e 'status'","6cedbcc2":"**From the above we can observe that, patients with spread2 values greater than 0.21 are more likly to have Parkinson's disease.**\n* Lets bucket spread2 and check w.r.t the different status i.e Healthy or Parkinson's:","53ce2b9a":"**In the 'mdvp_flo_hz' attribute some outliers are present, let's check for the same :**","3f61ddf8":"**In the 'mdvp_jitter_in_percent' attribute some outliers are present, let's check for the same :**","2d69e994":"**From above, it is observed that for 'hnr' attribute with Parkinson's disease have outliers present below lower quartile range whereas for healthy patients outliers present both lower and upper quartile range..**","ff5415d1":"**From above, it is observed that for 'mdvp_fhi_hz' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","10ff333b":"- We can find out the following from the above crosstab:\n    * **All patient with d2 (D2) group with value more than 3.0 are having Parkinson's disease.**\n    * **d2 (D2) group between 2.5-3.0 having Parkinson's patient with percentage of 90.385 followed by d2 (D2) group between 2.0-2.5 having Parkinson's patient with percentage of 70.588 .**\n    * **All patient with d2 (D2) group with value less than 1.5 are healthy patients.**\n    <br><br>\n- Let's check outliers for the attribute :","ed07ef95":"**From above we can understand the following about nhr (NHR) attribute of the dataset:**\n* Mean value of the attribute is 0.0248 with skewness of 4.2207, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.00 to 0.030 .","099acbbc":"**From the above comparision of different algorithms (Logistic Regression, K-nearest neighbors and Support Vector Machine) we can conclude that SVM (Support Vector Machine) performed slightly better than other algorithms.**\n","d2b0f5c6":"* **Also from the earlier correlation heatmap of different attributes we found that mdvp_shimmer (MDVP:Shimmer) have high correlation with mdvp_shimmer_db (MDVP:Shimmer(dB)), shimmer_apq3 (Shimmer:APQ3), shimmer_apq5 (Shimmer:APQ5), mdvp_apq (MDVP:APQ), shimmer_dda (Shimmer:DDA). So, in this case we will drop mdvp_shimmer (MDVP:Shimmer).**","030ee623":"#### L. 'shimmer_apq5' attribute : (Shimmer:APQ5) - One of the measure of variation in amplitude )","4b2269b5":"**From above we can understand the following about jitter_ddp (Jitter:DDP) attribute of the dataset:**\n* Mean value of the attribute is 0.0099 with skewness of 3.3621, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.002 to 0.012.","c2ad9f50":"* **STACKING:**","8db59221":"### 8.Train at least one standard Ensemble model - Random forest, Bagging, Boosting etc, and note the accuracy (10 points)\n**A. Random Forest**","2633fe6d":"- We can find out the following from the above crosstab:\n    * **All the patients under jitter_ddp (Jitter:DDP) groups ranging more than 0.02 have Parkinson's disease.**\n    * **jitter_ddp (Jitter:DDP) group between 0.00-0.02 having Parkinson's patient with percentage of 73.480 .**\n<br><br>\n- Let's check outliers for the attribute :","1eeb1bec":"### B. K-nearest neighbors:","b4c360a3":"**From above we can see out of 195 patients, 48 patients (24.6 %) are healthy and 147 patients (75.4%) patients are having Parkinson's disease.**","ab8e21d6":"**Setting 'name' attribute as index of the pdData dataframe as the attribute \/ column does not have an significance towards identifying patients have Parkinson's disease or not i.e 'status' column [Health status of the subject (one) - Parkinson's, (zero) - healthy]**","066ea0fa":"**From above we can understand the following about mdvp_rap (MDVP:RAP) attribute of the dataset:**\n* Mean value of the attribute is 0.0033 with skewness of 3.3607, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.001 to 0.004.","22377d99":"- We can find out the following from the above crosstab:\n    * **All the patients under shimmer_dda (Shimmer:DDA) groups ranging more than 0.075 have Parkinson's disease.**\n    * **shimmer_dda (Shimmer:DDA) group between 0.050-0.075 having Parkinson's patient with percentage of 96.970 followed by shimmer_dda (Shimmer:DDA) group between 0.025-0.050 having Parkinson's patient with percentage of 65.000 .**\n    * **shimmer_dda (Shimmer:DDA) group between 0.010-0.025 having Parkinson's patient with percentage of 62.745 **\n<br><br>\n- Let's check outliers for the attribute :","b8bd0d62":"**From above, it is observed there are no outliers present in mdvp_fo_hz attribute for different 'status' attributes.**","58c0f852":"**In the 'spread1' attribute some outliers are present, let's check for the same :**","019bc94c":"**From above, it is observed there are no outliers present in mdvp_fo_hz attribute for different 'status' attributes.**","058db255":"**In the 'mdvp_jitter_abs' attribute some outliers are present, let's check for the same :**","de375ff6":"**From the above we can observe that, patients with dfa (DFA) values greater than 0.68 are more likly to have Parkinson's disease.**\n* Lets bucket dfa (DFA) and check w.r.t the different status i.e Healthy or Parkinson's:","7d44d49c":"**In the 'mdvp_ppq' attribute some outliers are present, let's check for the same :**","a00c73c5":"**From the above we can observe that, patients with mdvp_apq (MDVP:APQ) values greater than 0.02 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_apq (MDVP:APQ) and check w.r.t the different status i.e Healthy or Parkinson's:","e32a6905":"### 1. Load the dataset","d7e10271":"**From the above Stacked meta classifier Model, we can find out the following details:**\n* **Accuracy of the model:- 95%**\n* **Re-call of the model:- 100%**\n* **Precision of the model:- 94%**\n* **F1-Score of the model:- 97%**\n* **ROC-AUC : 88%**\n","0c0ff8f7":"**From above, it is observed that for 'shimmer_apq3' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","501d42aa":"### 7. Train a meta-classifier and note the accuracy on test data (10 points)","9d78a01e":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_rap (MDVP:RAP) groups ranging more than 0.01 have Parkinson's disease.**\n    * **mdvp_rap (MDVP:RAP) group between 0.005-0.010 having Parkinson's patient with percentage of 94.444 followed by mdvp_rap (MDVP:RAP) group between 0.000-0.005 having Parkinson's patient with percentage of 72.353  .**\n<br><br>\n- Let's check outliers for the attribute :","ca667f77":"**In the 'mdvp_apq' attribute some outliers are present, let's check for the same :**","3c485cae":"**From the above we can observe that, patients with nhr (NHR) values greater than 0.02 are more likly to have Parkinson's disease.**\n* Lets bucket nhr (NHR) and check w.r.t the different status i.e Healthy or Parkinson's:","ace2793c":"## Ensemble Techniques Project\n\n### Steps and tasks:\n1. Load the dataset\n2. It is always a good practice to eye-ball raw data to get a feel of the data in terms of number of records, structure of the file, number of attributes, types of attributes and a general idea of likely challenges in the dataset. Mention a few comments in this regard (5 points)\n3. Using univariate & bivariate analysis to check the individual attributes for their basic statistics such as central values, spread, tails, relationships between variables etc. mention your observations (15 points)\n4. Split the dataset into training and test set in the ratio of 70:30 (Training:Test) (5 points)\n5. Prepare the data for training - Scale the data if necessary, get rid of missing values (if any) etc (5 points)\n6. Train at least 3 standard classification algorithms - Logistic Regression, Naive Bayes\u2019, SVM, k-NN etc, and note down their accuracies on the test data (10 points)\n7. Train a meta-classifier and note the accuracy on test data (10 points)\n8. Train at least one standard Ensemble model - Random forest, Bagging, Boosting etc, and note the accuracy (10 points)\n9. Compare all the models (minimum 5) and pick the best one among them (10 points)\n","98ab9908":"### 3. Using univariate & bivariate analysis to check the individual attributes for their basic statistics such as central values, spread, tails, relationships between variables etc. mention your observations (15 points)","467c1c5c":"**From the above we can observe that, patients with shimmer_apq5 (Shimmer:APQ5) values greater than 0.015 are more likly to have Parkinson's disease.**\n* Lets bucket shimmer_apq5 (Shimmer:APQ5) and check w.r.t the different status i.e Healthy or Parkinson's:","d591acca":"#### V. 'ppe' attribute : (PPE - Nonlinear measures of fundamental frequency variation ) ","28f98f2c":"* Now will check if any outliers present for different target attributes i.e 'status'","608c1cf2":"**there are no outliers presnt in the 'dfa' feature \/ attribute as we can see from above boxplot.**\n* Now will check if any outliers present for different target attributes i.e 'status'","98f1f43a":"#### F. 'mdvp_rap' attribute : (MDVP:RAP - One of the measure of variation in fundamental frequency )","93d1069a":"### 2. It is always a good practice to eye-ball raw data to get a feel of the data in terms of number of records, structure of the file, number of attributes, types of attributes and a general idea of likely challenges in the dataset. Mention a few comments in this regard (5 points)","dabd6927":"- We can find out the following from the above crosstab:\n    * **Minimum vocal fundamental frequency (mdvp_flo_hz) group between 50-100 are having highest Parkinson's patients with percentage of 83.146 .**\n    * **Minimum vocal fundamental frequency (mdvp_flo_hz) group between 100-150 having second higest Parkinson's patient with percentage of 80.000, followed by Minimum vocal fundamental frequency (mdvp_flo_hz) group between 150-200 having Parkinson's patient with percentage of 70.833 .**\n    * **All the patient from Minimum vocal fundamental frequency (mdvp_flo_hz) group between 200-250 are Healthy patient.**\n<br><br>\n- Let's check outliers for the attribute :","66996955":"**From above we can understand the following about rpde (RPDE) attribute of the dataset:**\n* Mean value of the attribute is 0.4985 with skewness of -0.1434, which shows that the skewness of the attribute is negligible.\n* Maximum datapoints are ranging from 0.4 to 0.68 .","92311d99":"#### T. 'spread1' attribute : (Nonlinear measures of fundamental frequency variation ) ","b80e3189":"**From above we can understand the following about Average vocal fundamental frequency (mdvp_fo_hz) attribute of the dataset:**\n* Mean value of the attribute is 154.2286 with skewness of 0.5917, which shows that the datapoints of the attribute is slightly right \/ positive skewed.\n* Maximum datapoints are ranging from 110 to 130 Hz.","5171304f":"**In the 'mdvp_fhi_hz' attribute some outliers are present, let's check for the same :**","2cc9e6ce":"**From above we can understand the following about spread1 attribute of the dataset:**\n* Mean value of the attribute is -5.6843 with skewness of 0.4321, which shows that the skewness of the attribute is negligible.","136af38d":"**From the above we can observe that, patients with jitter_ddp (Jitter:DDP) values greater than 0.008 are more likly to have Parkinson's disease.**\n* Lets bucket jitter_ddp (Jitter:DDP) and check w.r.t the different status i.e Healthy or Parkinson's:","be3190d7":"* Now will check if any outliers present for different target attributes i.e 'status'","4a154328":"**From the above Adaptive Boosting Model, we can find out the following details:**\n* **Accuracy of the model:- 90%**\n* **Re-call of the model:- 96%**\n* **Precision of the model:- 92%**\n* **F1-Score of the model:- 94%**\n* **ROC-AUC : 82%**\n","9fa02302":"**From above, it is observed that for 'shimmer_apq5' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","6f54c2e2":"- We can find out the following from the above crosstab:\n    * **rpde (RPDE) group between 0.65-0.75 having Parkinson's patient with highest percentage of 91.667 .**\n    * **rpde (RPDE) group between 0.55-0.65 having Parkinson's patient with percentage of 88.135 followed by rpde (RPDE) group between 0.45-0.55 having Parkinson's patient with percentage of 78.571 .**\n    * **Both rpde (RPDE) group between 0.25-0.35 and 0.35-0.45 having Parkinson's patient with percentage of 58.824 .**\n    <br><br>\n- Let's check outliers for the attribute :","068c126c":"**Attribute Information:**\n1. **name** - ASCII subject name and recording number\n2. **mdvp_fo_hz** - Average vocal fundamental frequency (Actualy column name MDVP:Fo(Hz) )\n3. **mdvp_fhi_hz** - Maximum vocal fundamental frequency (Actualy column name MDVP:Fhi(Hz) )\n4. **mdvp_flo_hz** - Minimum vocal fundamental frequency (Actualy column name MDVP:Flo(Hz) )\n5. **mdvp_jitter_in_percent, mdvp_jitter_abs, mdvp_rap, mdvp_ppq, jitter_ddp** - Several measures of variation in fundamental frequency (Actualy column names MDVP:Jitter(%), MDVP:Jitter(Abs), MDVP:RAP, MDVP:PPQ, Jitter:DDP respectively)\n6. **mdvp_shimmer, mdvp_shimmer_db, shimmer_apq3, shimmer_apq5, mdvp_apq, shimmer_dda** - Several measures of variation in amplitude (Actualy column names MDVP:Shimmer, MDVP:Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, MDVP:APQ, Shimmer:DDA respectively)\n7. **nhr, hnr** - Two measures of ratio of noise to tonal components in the voice (Actualy column names NHR, HNR respectively)\n8. **rpde, d2** - Two nonlinear dynamical complexity measures (Actualy column names RPDE, D2 respectively)\n9. **dfa** - Signal fractal scaling exponent (Actualy column name DFA )\n10. **spread1, spread2, ppe** - Three nonlinear measures of fundamental frequency variation (Actualy column names spread1, spread2, PPE respectively)\n11. **status** - Health status of the subject (one) - Parkinson's, (zero) - healthy (**Target Varibale \/ attribute**)","d86ab0b4":"#### U. 'spread2' attribute : (Nonlinear measures of fundamental frequency variation  ","08ac297f":"**In the 'mdvp_shimmer' attribute some outliers are present, let's check for the same :**","58ae9841":"#### M. 'mdvp_apq' attribute : (MDVP:APQ) - One of the measure of variation in amplitude )","90f2732c":"**From the above Random Forest Model, we can find out the following details:**\n* **Accuracy of the model:- 92%**\n* **Re-call of the model:- 98%**\n* **Precision of the model:- 92%**\n* **F1-Score of the model:- 95%**\n* **ROC-AUC : 84%**\n","7198c60c":"* Now will check if any outliers present for different target attributes i.e 'status'","bf0cce1d":"**From the above we can observe that, patients with shimmer_dda (Shimmer:DDA) values greater than 0.04 are more likly to have Parkinson's disease.**\n* Lets bucket shimmer_dda (Shimmer:DDA) and check w.r.t the different status i.e Healthy or Parkinson's:","0d225f97":"**From the above we can observe that, patients with rpde (RPDE) values less than 0.49 are more likly to have Parkinson's disease.**\n* Lets bucket rpde (RPDE) and check w.r.t the different status i.e Healthy or Parkinson's:","66f4fcb6":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_shimmer_db (MDVP:Shimmer(dB)) groups ranging more than 0.50 have Parkinson's disease.**\n    * **mdvp_shimmer_db (MDVP:Shimmer(dB)) group between 0.25-0.50 having Parkinson's patient with percentage of 93.220 followed by mdvp_shimmer_db (MDVP:Shimmer(dB)) group between 0.00-0.25 having Parkinson's patient with percentage of 61.404 .**\n<br><br>\n- Let's check outliers for the attribute :","c56a9c1d":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_shimmer (MDVP:Shimmer) groups ranging more than 0.06 have Parkinson's disease.**\n    * **mdvp_shimmer (MDVP:Shimmer) group between 0.04-0.06 having Parkinson's patient with percentage of 96.296 followed by mdvp_shimmer (MDVP:Shimmer) group between 0.02-0.04 having Parkinson's patient with percentage of 83.562.**\n    * **mdvp_shimmer (MDVP:Shimmer) group between 0.00-0.02 having Parkinson's patient with percentage of 55.128 .**\n<br><br>\n- Let's check outliers for the attribute :","0e6ac0bd":"- We can find out the following from the above crosstab:\n    * **All patient with spread1 group with value more than -4.0 are having Parkinson's disease.**\n    * **spread1 group between -6.0 to -4.0 having Parkinson's patient with percentage of 93.070 followed by spread1 group between -8.0 to -6.0 having Parkinson's patient with percentage of 49.383 .**\n    <br><br>\n- Let's check outliers for the attribute :","38976103":"### A. Logistic Regression:","ec8223d4":"**From the above we can observe that, most of the patients with Parkinson's disease have Minimum vocal fundamental frequency (mdvp_flo_hz) between 60 to 110 hz.**\n* Lets bucket Minimum vocal fundamental frequency (mdvp_flo_hz) and check w.r.t the different status i.e Healthy or Parkinson's:","0b1a57cc":"- We can find out the following from the above crosstab:\n    * **All the patients under hnr (HNR) groups ranging less than 15 have Parkinson's disease.**\n    * **hnr (HNR) group between 15-20 having Parkinson's patient with percentage of 86.957 followed by hnr (HNR) group between 20-25 having Parkinson's patient with percentage of 77.778 .**\n    * **hnr (HNR) group between 25-30 having Parkinson's patient with percentage of 60.417 .**\n    * **All patient having hnr (HNR) more than 30 are healthy.**\n<br><br>\n- Let's check outliers for the attribute :","cace1e7e":"#### D. 'mdvp_jitter_in_percent' attribute : (MDVP:Jitter(%) - One of the measure of variation in fundamental frequency )","179c8490":"**there are no outliers presnt in the 'rpde' feature \/ attribute as we can see from above boxplot.**\n* Now will check if any outliers present for different target attributes i.e 'status'","a4e9d276":"**In the 'shimmer_apq3' attribute some outliers are present, let's check for the same :**","3a24f82c":"- We can find out the following from the above crosstab:\n    * **All the patients under nhr (NHR) groups ranging more than 0.15 have Parkinson's disease.**\n    * **nhr (NHR) group between 0.05-0.10 having Parkinson's patient with percentage of 90.000 followed by nhr (NHR) group between 0.010-0.15 having Parkinson's patient with percentage of 80.000 .**\n    * **nhr (NHR) group between 0.00-0.05 having Parkinson's patient with percentage of 73.714 **\n<br><br>\n- Let's check outliers for the attribute :","20bd8368":"#### AUC-ROC for AdaBoost","0d25e4a3":"#### AUC-ROC for Random Forest","32d4e9d7":"**From above, it is observed that for 'mdvp_jitter_abs' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","eb63764c":"**From the above we can observe that, patients with shimmer_apq3 (Shimmer:APQ3) values greater than 0.015 are more likly to have Parkinson's disease.**\n* Lets bucket shimmer_apq3 (Shimmer:APQ3) and check w.r.t the different status i.e Healthy or Parkinson's:","5315d135":"**From above we can understand the following about dfa (DFA) attribute of the dataset:**\n* Mean value of the attribute is 0.7180 with skewness of -0.0332, which shows that the skewness of the attribute is negligible.","c45ce326":"#### N. 'shimmer_dda' attribute : (Shimmer:DDA) - One of the measure of variation in amplitude )","d28724d1":"**From the above Logistic Regression Model, we can find out the following details:**\n* **Accuracy of the model:- 86%**\n* **Re-call of the model:- 91%**\n* **Precision of the model:- 91%**\n* **F1-Score of the model:- 91%**","aa58da89":"**We can conclude from the above Accuracy and F1 scoring method that, Stacking Model performs better than other models.**\n* **Stacking Model have mean Accuracy of 93% with standard deviation of 5% .**\n* **And, Stacking Model have mean F1-Score of 94% with standard deviation of 5% .**","7cf600a2":"**From the above K-nearest neighbors Model, we can find out the following details:**\n* **Accuracy of the model:- 92%**\n* **Re-call of the model:- 100%**\n* **Precision of the model:- 90%**\n* **F1-Score of the model:- 95%**","84896753":"#### B. 'mdvp_fhi_hz' attribute : (MDVP:Fhi(Hz) - Maximum vocal fundamental frequency )","97fe15a5":"**From the above we can observe that, patients with mdvp_rap (MDVP:RAP) values greater than 0.002 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_rap (MDVP:RAP) and check w.r.t the different status i.e Healthy or Parkinson's:","240ce378":"#### H. 'jitter_ddp' attribute : (Jitter:DDP - One of the measure of variation in fundamental frequency )","cb47cd3a":"**In the 'jitter_ddp' attribute some outliers are present, let's check for the same :**","ee91907f":"- We can find out the following from the above crosstab:\n    * **All the patient with Average vocal fundamental frequency (mdvp_fo_hz) group between 50-100 are having Parkinson's disease.**\n    * **Average vocal fundamental frequency (mdvp_fo_hz) group between 150-200 having second higest Parkinson's patient with percentage of 88.525, followed by Average vocal fundamental frequency (mdvp_fo_hz) group between 100-150 having Parkinson's patient with percentage of 80.435 .**\n    * **Average vocal fundamental frequency (mdvp_fo_hz) group between 200-250 having Healthy patient with percentage of 65.625 .**\n    * **All the patient with Average vocal fundamental frequency (mdvp_fo_hz) group between 250-300 are Healthy.**\n<br><br>\n- Let's check outliers for the attribute :","3a6b10f9":"- We can find out the following from the above crosstab:\n    * **All patient with dfa (DFA) group with value more than 0.8 and value less than 0.6 are having Parkinson's disease.**\n    * **dfa (DFA) group between 0.7-0.8 having Parkinson's patient with percentage of 81.731 followed by dfa (DFA) group between 0.6-0.7 having Parkinson's patient with percentage of 60.811 .**\n    <br><br>\n- Let's check outliers for the attribute :","caad79a4":"**In the 'd2' attribute some outliers are present, let's check for the same :**","693c9f8d":"#### G. 'mdvp_ppq' attribute : (MDVP:PPQ - One of the measure of variation in fundamental frequency )","03a121de":"### 5. Prepare the data for training - Scale the data if necessary, get rid of missing values (if any) etc (5 points)\n\n* **As we have seen earlier, there are no missing values in the dataset**\n* **As from the earlier correlation heatmap of different attributes we found that mdvp_jitter_in_percent (MDVP:Jitter(%)) have high correlation with mdvp_jitter_abs (MDVP:Jitter(Abs) ), mdvp_rap (MDVP:RAP), mdvp_ppq (MDVP:PPQ), jitter_ddq (Jitter:DDQ) and nhr (NHR). So, in this case we will drop mdvp_jitter_in_percent (MDVP:Jitter(%)).**","9efb062d":"**From above, it is observed that for 'mdvp_shimmer' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","f5a8caea":"#### AUC-ROC for stacking","e75d9847":"- We can find out the following from the above crosstab:\n    * **All the patients under shimmer_apq3 (Shimmer:APQ3) groups ranging more than 0.03 have Parkinson's disease.**\n    * **shimmer_apq3 (Shimmer:APQ3) group between 0.02-0.03 having Parkinson's patient with percentage of 96.667 followed by shimmer_apq3 (Shimmer:APQ3) group between 0.01-0.02 having Parkinson's patient with percentage of 76.389 .**\n    * **shimmer_apq3 (Shimmer:APQ3) group between 0.00-0.01 having Parkinson's patient with percentage of 58.904 .**\n<br><br>\n- Let's check outliers for the attribute :","63ff08f3":"**From the above Support Vector Machine Model, we can find out the following details:**\n* **Accuracy of the model:- 95%**\n* **Re-call of the model:- 100%**\n* **Precision of the model:- 94%**\n* **F1-Score of the model:- 97%**","b1608d51":"* Now will check if any outliers present for different target attributes i.e 'status'","6ba918b0":"**From above, it is observed that for 'mdvp_flo_hz' attribute w.r.t different target attribute status i.e Healthy or Parkinson's there are no outliers but combining datapoints are having outliers. Reason for this is patients with Parkinson's disease have lower Minimum vocal fundamental frequency whereas Healthy patients have higher Minimum vocal fundamental frequency as we can deduce from the above boxplot.**","8b2e4bd9":"* Now will check if any outliers present for different target attributes i.e 'status'","d03ca4a9":"#### S. 'dfa' attribute : (DFA - Signal fractal scaling exponent) ","e0a00860":"**From the above we can observe that, patients with mdvp_shimmer (MDVP:Shimmer) values greater than 0.025 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_shimmer (MDVP:Shimmer) and check w.r.t the different status i.e Healthy or Parkinson's:","c81d50c8":"**From the above we can observe that, patients with mdvp_jitter_in_percent (MDVP:Jitter(%)) values greater than 0.005 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_jitter_in_percent (MDVP:Jitter(%)) and check w.r.t the different status i.e Healthy or Parkinson's:","ef207627":"- We can find out the following from the above crosstab:\n    * **All patient with spread2 group with value more than 0.3 are having Parkinson's disease.**\n    * **spread2 group between 0.2-0.3 having Parkinson's patient with percentage of 86.585 followed by spread2 group between 0.1-0.2 having Parkinson's patient with percentage of 53.333 .**\n    * **spread2 group between 0.0-0.1 having Parkinson's patient with percentage of 35.714 .**\n    <br><br>\n- Let's check outliers for the attribute :","35b6f9fa":"* Now will check if any outliers present for different target attributes i.e 'status'","a62b09a1":"**From above, it is observed that for 'spread1' attribute with Parkinson's disease have outliers present on above upper quartile range whereas for healthy patients have no outliers.**","39632d7d":"**From above, it is observed that for 'nhr' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","28087ce9":"**As shown above, <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(a.) There are no missing values<br>and (b.) No duplicate rows in the given dataset**\n","1081cd96":"**From above we can understand the following about hnr (HNR) attribute of the dataset:**\n* Mean value of the attribute is 21.8860 with skewness of -0.5143, which shows that the datapoints of the attribute is slightly left \/ negative skewed.\n* Maximum datapoints are ranging from 18 to 27 .","a41f9623":"**From above, it is observed that for 'mdvp_jitter_in_percent' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","0c572457":"**From above, it is observed that for 'd2' attribute with Parkinson's disease have outliers present above upper quartile range whereas for healthy patients outliers present below lower quartile range.**","08bf9e7a":"**From the above we can observe that, most of the patients with Parkinson's disease have Maximum vocal fundamental frequency (mdvp_fhi_hz) between 100 to 210 hz.**\n* Lets bucket Maximum vocal fundamental frequency (mdvp_fhi_hz) and check w.r.t the different status i.e Healthy or Parkinson's:","a1156a06":"- We can find out the following from the above crosstab:\n    * **All patient with ppe (PPE) (DFA) group with value more than 0.3 are having Parkinson's disease.**\n    * **ppe (PPE) group between 0.2-0.3 having Parkinson's patient with percentage of 93.750 followed by ppe (PPE) group between 0.1-0.2 having Parkinson's patient with percentage of 67.470 .**\n    * **ppe (PPE) group between 0.0-0.1 having very less Parkinson's patient with percentage of 5.556 .**\n    <br><br>\n- Let's check outliers for the attribute :","2492efc0":"**From the above we can observe that, most of the patients with Parkinson's disease have Average vocal fundamental frequency (mdvp_fo_hz) between 90 to 190 hz. Even though some of healthy patients have Average vocal fundamental frequency between 110-130 Hz and 170-180 Hz.**\n* Lets bucket Average vocal fundamental frequency (mdvp_fo_hz) and check w.r.t the different status i.e Healthy or Parkinson's:","2161a85b":"**In the 'spread2' attribute some outliers are present, let's check for the same :**","953604c5":"#### Determining which standard model performed better","e39c1fbf":"**From the above we can observe that, patients with ppe (PPE) values greater than 0.16 are more likly to have Parkinson's disease.**\n* Lets bucket ppe (PPE) and check w.r.t the different status i.e Healthy or Parkinson's:","4f47d591":"* **Also we will drop hnr (HNR).**","5e6462cc":"**From above, it is observed that for 'mdvp_rap' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","078fa0c6":"#### C. 'mdvp_flo_hz' attribute : (MDVP:Flo(Hz) - Minimum vocal fundamental frequency )","7499752a":"**From above we can understand the following about mdvp_ppq (MDVP:PPQ) attribute of the dataset:**\n* Mean value of the attribute is 0.0034 with skewness of 3.0739, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.0010 to 0.0025.","d10c813a":"**From above we can understand the following about shimmer_apq5 (Shimmer:APQ5) attribute of the dataset:**\n* Mean value of the attribute is 0.0179 with skewness of 1.7987, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.004 to 0.02 .","9e2a879c":"**From above, it is observed that for 'spread2' attribute for healthy patients have outliers.**","99f447e1":"**From above we can understand the following about mdvp_shimmer_db (MDVP:Shimmer(dB)) attribute of the dataset:**\n* Mean value of the attribute is 0.2823 with skewness of 1.9994, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.008 to 0.35 .","6805dcff":"**From above we can understand the following about spread2 attribute of the dataset:**\n* Mean value of the attribute is 0.2265 with skewness of 0.1444, which shows that the skewness of the attribute is negligible.","fb339aff":"#### I. 'mdvp_shimmer' attribute : (MDVP:Shimmer - One of the measure of variation in amplitude )","690e78bb":"#### Q. 'rpde' attribute : (RPDE - Nonlinear dynamical complexity measure) ","cb85adbf":"* Now will check if any outliers present for different target attributes i.e 'status'","bfc15b33":"### 4. Split the dataset into training and test set in the ratio of 70:30 (Training:Test) (5 points)","2f006a8d":"**B. Adaptive Boosting**","56742d8a":"**In the 'ppe' attribute some outliers are present, let's check for the same :**","1dfbf7ef":"* Now will check if any outliers present for different target attributes i.e 'status'","dd0c8288":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_jitter_abs (MDVP:Jitter(Abs)) groups ranging more than 0.0001 have Parkinson's disease.**\n    * **mdvp_jitter_abs (MDVP:Jitter(Abs)) group between 0.00004-0.00010 having Parkinson's patient with percentage of 96.552 .**\n<br><br>\n- Let's check outliers for the attribute :","af81d5a6":"**After observing the dataset and column description given we can conclude the followings:**\n* **Columns having only two datatypes, int64, float64. (column 'name' was object datatype which was set as index of the dataframe)**\n* **Column 'status' is only having int64 datatype, remaining all columns datatype is float64.** \n* **All columns except 'status' are Numeric column.**\n* **Columns 'status' is Nominal Categorical column with binary response.**","285197cb":"**From the above we can observe that, patients with mdvp_shimmer_db (MDVP:Shimmer(dB)) values greater than 0.25 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_shimmer_db (MDVP:Shimmer(dB)) and check w.r.t the different status i.e Healthy or Parkinson's:","2cb7084a":"* Now we will check if any outliers present for different target attributes i.e 'status'","66dff50e":"**In the 'nhr' attribute some outliers are present, let's check for the same :**","002d6b52":"**From above, it is observed that for 'mdvp_shimmer_db' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","49b75607":"**In the 'hnr' attribute some outliers are present, let's check for the same :**","463c9ef5":"**From above, it is observed that for 'jitter_ddp' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","35d03190":"* Now will check if any outliers present for different target attributes i.e 'status'","54908d4f":"**From above we can understand the following about mdvp_jitter_abs (MDVP:Jitter(Abs)) attribute of the dataset:**\n* Mean value of the attribute is 0.000044 with skewness of 2.6491, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.00001 to 0.00004.","2e4e09d5":"**In the 'mdvp_rap' attribute some outliers are present, let's check for the same :**","c318ad7c":"* Now will check if any outliers present for different target attributes i.e 'status'","f781e17b":"**From above, it is observed there are no outliers present in dfa attribute for different 'status' attributes.**","a211d65c":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_apq (MDVP:APQ) groups ranging more than 0.04 have Parkinson's disease.**\n    * **mdvp_apq (MDVP:APQ) group between 0.02-0.04 having Parkinson's patient with percentage of 98.246 followed by mdvp_apq (MDVP:APQ) group between 0.00-0.02 having Parkinson's patient with percentage of 57.273 .**\n<br><br>\n- Let's check outliers for the attribute :","c4809d89":"#### A. 'mdvp_fo_hz' attribute : (MDVP:Fo(Hz) - Average vocal fundamental frequency )","652c2d23":"**From the above we can observe that, patients with d2 (D2) values greater than 2.4 are more likly to have Parkinson's disease.**\n* Lets bucket d2 (D2) and check w.r.t the different status i.e Healthy or Parkinson's:","9d8ced21":"### C. SVM (Support Vector Machine):","d52598c1":"### 6. Train at least 3 standard classification algorithms - Logistic Regression, Naive Bayes\u2019, SVM, k-NN etc, and note down their accuracies on the test data (10 points)","8b4a2100":"**From the above we can observe that, patients with mdvp_ppq (MDVP:PPQ) values greater than 0.0025 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_ppq (MDVP:PPQ) and check w.r.t the different status i.e Healthy or Parkinson's:","24e57308":"**From above we can understand the following about mdvp_jitter_in_percent (MDVP:Jitter(%)) attribute of the dataset:**\n* Mean value of the attribute is 0.0062 with skewness of 3.0849, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.001 to 0.007.","c7b5a882":"* Lets check the percentage and plot a pie chart to show :","62c807f5":"**From the above we can observe that, patients with mdvp_jitter_abs (MDVP:Jitter(Abs)) values greater than 0.00002 are more likly to have Parkinson's disease.**\n* Lets bucket mdvp_jitter_abs (MDVP:Jitter(Abs)) and check w.r.t the different status i.e Healthy or Parkinson's:","1e8be125":"* Now will check if any outliers present for different target attributes i.e 'status'","57dfb589":"#### P. 'hnr' attribute : (HNR) - Measures of ratio of noise to tonal components in the voice )","67a0a331":"#### J. 'mdvp_shimmer_db' attribute : (MDVP:Shimmer(dB) - One of the measure of variation in amplitude )","5eef0633":"#### R. 'd2' attribute : (D2 - Nonlinear dynamical complexity measure) ","488eb8a4":"**From the above we can observe that, patients with hnr (HNR) values less than 22.5 are more likly to have Parkinson's disease.**\n* Lets bucket hnr (HNR) and check w.r.t the different status i.e Healthy or Parkinson's:","d16daed4":"**From above, it is observed that for 'ppe' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","d57dc2c0":"**From above we can understand the following about Maximum vocal fundamental frequency (mdvp_fhi_hz) attribute of the dataset:**\n* Mean value of the attribute is 197.1049 with skewness of 2.5421, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 100 to 260 Hz.","1e986bac":"**From the above we can observe that, patients with spread1 values greater than -6.2 are more likly to have Parkinson's disease.**\n* Lets bucket spread1 and check w.r.t the different status i.e Healthy or Parkinson's:","d7569955":"* Now will check if any outliers present for different target attributes i.e 'status'","0032c5fa":"**As from above we understand the following:**\n* Independent variables are measured in different units e.g. Hz, dB, % and absoulute etc i.e variation in units of data exists and gap between feature values extreamly high. Requires data scalling techniques to scale different quantities of measurements.\n* Symmetrical distribution : Values close to 0\n    MDVP:Fo(Hz)\n    spread1\n    spread2\n    PPE\n* Negative skewness and Tail is larger towards the left hand side of the distribution\n    HNR\n    status\n    RPDE\n    DFA\n* Positive skewness and Tail is larger towards the Right hand side of the distribution All other attributes have a very high distribution towards right of the median","68c74dab":"**In the 'mdvp_shimmer_db' attribute some outliers are present, let's check for the same :**","923d220b":"#### K. 'shimmer_apq3' attribute : (Shimmer:APQ3) - One of the measure of variation in amplitude )","bfbc132e":"* Now will check if any outliers present for different target attributes i.e 'status'","9af0f992":"**There are no outliers presnt in the 'mdvp_fo_hz' feature \/ attribute as we can see from above boxplot.**\n* Now will check if any outliers present for different target attributes i.e 'status'","a48a3fae":"**From above we can understand the following about Minimum vocal fundamental frequency (mdvp_flo_hz) attribute of the dataset:**\n* Mean value of the attribute is 116.3246 with skewness of 1.2174, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 65 to 120 Hz.","e5bc6ae5":"**In the 'shimmer_apq5' attribute some outliers are present, let's check for the same :**","9c3635a2":"**From above, it is observed that for 'mdvp_apq' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","362f0756":"* Now will check if any outliers present for different target attributes i.e 'status'","5c69a92b":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_ppq (MDVP:PPQ) groups ranging more than 0.01 have Parkinson's disease.**\n    * **mdvp_ppq (MDVP:PPQ) group between 0.005-0.010 having Parkinson's patient with percentage of 94.737 followed by mdvp_ppq (MDVP:PPQ) group between 0.000-0.005 having Parkinson's patient with percentage of 72.353, suprisingly which is exactly same for the same group of mdvp_rap (MDVP:RAP) attribute.**\n<br><br>\n- Let's check outliers for the attribute :","00d27e55":"- We can find out the following from the above crosstab:\n    * **All the patients under shimmer_apq5 (Shimmer:APQ5) groups ranging more than 0.03 have Parkinson's disease.**\n    * **shimmer_apq5 (Shimmer:APQ5) group between 0.02-0.03 having Parkinson's patient with percentage of 96.154 followed by shimmer_apq3 (Shimmer:APQ3) group between 0.01-0.02 having Parkinson's patient with percentage of 72.093 .**\n    * **shimmer_apq5 (Shimmer:APQ5) group between 0.00-0.01 having Parkinson's patient with percentage of 58.182 .**\n<br><br>\n- Let's check outliers for the attribute :","1c3aa77a":"#### O. 'nhr' attribute : (NHR) - Measures of ratio of noise to tonal components in the voice )","24192639":"**From above, it is observed that for 'mdvp_ppq' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","9ff0a1e6":"**From above we can understand the following about shimmer_dda (Shimmer:DDA) attribute of the dataset:**\n* Mean value of the attribute is 0.0470 with skewness of 1.5806, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.013 to 0.06 .","0ddb65cb":"**From above we can understand the following about mdvp_shimmer (MDVP:Shimmer) attribute of the dataset:**\n* Mean value of the attribute is 0.0297 with skewness of 1.6665, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.009 to 0.02.","e0c6b914":"**From above we can understand the following about mdvp_apq (MDVP:APQ) attribute of the dataset:**\n* Mean value of the attribute is 0.0241 with skewness of 2.618, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.007 to 0.03 .","79d616e6":"**We can observe from the above pairplot and heatmap of correlation of different attributes:**\n* **mdvp_jitter_in_percent (MDVP:Jitter(%)) have high correlation with mdvp_jitter_abs (MDVP:Jitter(Abs) ), mdvp_rap (MDVP:RAP), mdvp_ppq (MDVP:PPQ), jitter_ddp (Jitter:DDP) and nhr (NHR).**\n* **mdvp_jitter_abs (MDVP:Jitter(Abs) have high correlation with mdvp_rap (MDVP:RAP), mdvp_ppq (MDVP:PPQ), jitter_ddp (Jitter:DDP).**\n* **mdvp_rap (MDVP:RAP) have high correlation with mdvp_ppq (MDVP:PPQ), jitter_ddp (Jitter:DDP), nhr (NHR).**\n* **mdvp_ppq (MDVP:PPQ) have high correlation with jitter_ddp (Jitter:DDP).**\n* **jitter_ddp (Jitter:DDP) have high correlation with nhr (NHR).**\n* **mdvp_shimmer (MDVP:Shimmer) have high correlation with mdvp_shimmer_db (MDVP:Shimmer(dB)), shimmer_apq3 (Shimmer:APQ3), shimmer_apq5 (Shimmer:APQ5), mdvp_apq (MDVP:APQ), shimmer_dda (Shimmer:DDA).**\n* **mdvp_shimmer_db (MDVP:Shimmer(dB)) have high correlation with shimmer_apq3 (Shimmer:APQ3), shimmer_apq5 (Shimmer:APQ5), mdvp_apq (MDVP:APQ), shimmer_dda (Shimmer:DDA).**\n* **shimmer_apq3 (Shimmer:APQ3) have high correlation with shimmer_apq5 (Shimmer:APQ5), mdvp_apq (MDVP:APQ), shimmer_dda (Shimmer:DDA).**\n* **shimmer_apq5 (Shimmer:APQ5) have high correlation with mdvp_apq (MDVP:APQ), shimmer_dda (Shimmer:DDA).**\n* **mdvp_apq (MDVP:APQ) have high correlation with shimmer_dda (Shimmer:DDA).**\n* **spread1 have high correlation with ppe (PPE).**","5c04999f":"- We can find out the following from the above crosstab:\n    * **All the patients under mdvp_jitter_in_percent (MDVP:Jitter(%)) groups ranging from 0.015 have Parkinson's disease.**\n    * **mdvp_jitter_in_percent (MDVP:Jitter(%)) group between 0.005-0.010 having second higest Parkinson's patient with percentage of 89.189, followed by mdvp_jitter_in_percent (MDVP:Jitter(%)) group between 0.010-0.015 having Parkinson's patient with percentage of 87.500 .**\n    * **mdvp_jitter_in_percent (MDVP:Jitter(%)) group between 0.001-0.005 having Parkinson's patient with percentage of 61.765 .**\n<br><br>\n- Let's check outliers for the attribute :","276092b4":"**From above we can understand the following about ppe (PPE) attribute of the dataset:**\n* Mean value of the attribute is 0.2066 with skewness of 0.7975, which shows that the datapoints of the attribute is slightly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.1 to 0.27 .","c9bfac24":"* Now will check if any outliers present for different target attributes i.e 'status'","637d4708":"**In the 'shimmer_dda' attribute some outliers are present, let's check for the same :**","42e9eb44":"**First let's find out the value of neighbors.**","d4f4e64d":"**From above, it is observed that for 'shimmer_dda' attribute patients with Parkinson's disease have more outliers than Healthy patients.**","fc96c292":"#### E. 'mdvp_jitter_abs' attribute : (MDVP:Jitter(Abs) - One of the measure of variation in fundamental frequency )","46466af1":"### 9. Compare all the models (minimum 5) and pick the best one among them (10 points)","76091998":"#### W. 'status' attribute : (Health status of the subject (one) - Parkinson's, (zero) - healthy) ","3efed8f3":"* Now will check if any outliers present for different target attributes i.e 'status'","f6ce4ebd":"- We can find out the following from the above crosstab:\n    * **All the patients with Maximum vocal fundamental frequency (mdvp_fhi_hz) group between 400-500 are having Parkinson's disease.**\n    * **Maximum vocal fundamental frequency (mdvp_fhi_hz) group between 100-200 having second highest Parkinson's patient with percentage of 87.069, followed by Maximum vocal fundamental frequency (mdvp_fhi_hz) group between 500-600 having Parkinson's patient with percentage of 60.000 .**\n    * **Maximum vocal fundamental frequency (mdvp_fhi_hz) group between 200-300 having Parkinson's patient with percentage of 55.224 .**\n    * **Exactly half of the patients are from Maximum vocal fundamental frequency (mdvp_fhi_hz) group between 300-400 are Healthy.**\n<br><br>\n- Let's check outliers for the attribute :","137d8a2f":"**From above we can understand the following about d2 (D2) attribute of the dataset:**\n* Mean value of the attribute is 2.382 with skewness of 0.4304, which shows that the skewness of the attribute is negligible.\n* Maximum datapoints are ranging from 2.0 to 2.75 .","3d26dbad":"**From above we can understand the following about shimmer_apq3 (Shimmer:APQ3) attribute of the dataset:**\n* Mean value of the attribute is 0.0157 with skewness of 1.5806, which shows that the datapoints of the attribute is highly right \/ positive skewed.\n* Maximum datapoints are ranging from 0.004 to 0.0175 ."}}