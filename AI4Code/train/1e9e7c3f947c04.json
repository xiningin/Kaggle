{"cell_type":{"0c3c4946":"code","f5c6bf73":"code","6a537da4":"code","ad7463be":"code","7907f26c":"code","6dd51f71":"code","5328bcb4":"code","94cc15d4":"code","c8abef24":"code","8c5c884b":"code","079259de":"code","30419b1a":"markdown","c7b8e1b9":"markdown","3255bfb3":"markdown","247b0363":"markdown","20d452d6":"markdown","de6650b6":"markdown","72015c5a":"markdown","4e5a8180":"markdown","1280f178":"markdown","1fd10a91":"markdown","4b86ada3":"markdown","c0bc1737":"markdown","737d0bdb":"markdown"},"source":{"0c3c4946":"!pip install torchio==0.18.57","f5c6bf73":"import warnings\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\nimport torch\nimport torchio as tio","6a537da4":"NUM_IMAGES = 64\nPROCESSED_DATA_DIR = Path(\"..\/input\/rsna-miccai-preprocessed-by-torchio\/rsna-preprocessed\")\nANIMATION_OUT_DIR = Path(\".\/animation\")\nMRI_TYPES = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]","ad7463be":"def extract_img(img: torch.Tensor) -> torch.Tensor:\n    middle_idx = img.shape[-1] \/\/ 2\n    num_half_imgs = NUM_IMAGES \/\/ 2\n    start_idx = max(0, middle_idx - num_half_imgs)\n    end_idx = min(img.shape[-1], middle_idx + num_half_imgs)\n    return img.data.transpose(0, 3)[start_idx: end_idx].transpose(0, 3)","7907f26c":"def make_animation(subject: tio.data.image.Image, save_path: str, *, skip_if_exists=False):\n    if skip_if_exists and save_path.exists():\n        return\n    \n    fig = plt.figure()\n\n    ims = []\n    for sub_2d in extract_img(subject.data).transpose(0, 3):\n        im = plt.imshow(sub_2d, animated=True)\n        ims.append([im])\n    \n    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n    ani.save(save_path, writer='pillow', fps=30)\n    plt.close()","6dd51f71":"ANIMATION_OUT_DIR.mkdir(exist_ok=True, parents=True)","5328bcb4":"warnings.simplefilter('ignore')","94cc15d4":"id_ = 0\nfor mri_type in MRI_TYPES:\n    sub = tio.Image(PROCESSED_DATA_DIR.joinpath(f\"train\/{str(id_).zfill(5)}\/{mri_type}\/{mri_type}.nii\"))\n    make_animation(sub, ANIMATION_OUT_DIR.joinpath(f\"sub_{id_}_{mri_type}.gif\"), skip_if_exists=True)","c8abef24":"id_ = 2\nfor mri_type in MRI_TYPES:\n    sub = tio.Image(PROCESSED_DATA_DIR.joinpath(f\"train\/{str(id_).zfill(5)}\/{mri_type}\/{mri_type}.nii\"))\n    make_animation(sub, ANIMATION_OUT_DIR.joinpath(f\"sub_{id_}_{mri_type}.gif\"), skip_if_exists=True)","8c5c884b":"id_ = 3\nfor mri_type in MRI_TYPES:\n    sub = tio.Image(PROCESSED_DATA_DIR.joinpath(f\"train\/{str(id_).zfill(5)}\/{mri_type}\/{mri_type}.nii\"))\n    make_animation(sub, ANIMATION_OUT_DIR.joinpath(f\"sub_{id_}_{mri_type}.gif\"), skip_if_exists=True)","079259de":"id_ = 9\nfor mri_type in MRI_TYPES:\n    sub = tio.Image(PROCESSED_DATA_DIR.joinpath(f\"train\/{str(id_).zfill(5)}\/{mri_type}\/{mri_type}.nii\"))\n    make_animation(sub, ANIMATION_OUT_DIR.joinpath(f\"sub_{id_}_{mri_type}.gif\"), skip_if_exists=True)","30419b1a":"- FLAIR\n\n![](.\/animation\/sub_9_FLAIR.gif)\n\n- T1w\n\n![](.\/animation\/sub_9_T1w.gif)\n\n- T1wCE\n\n![](.\/animation\/sub_9_T1wCE.gif)\n\n- T2w\n\n![](.\/animation\/sub_9_T2w.gif)","c7b8e1b9":"## Implementation","3255bfb3":"# RSNA-MICCAI Brain Tumor Radiogenomic Classification: Show animation results of preprocessing the dataset by TorchIO with animation","247b0363":"### Example: BraTS21ID-00003\n\nAnd we show first sample whose MGMT_value is 0.","20d452d6":"### Example: BraTS21ID-00000\n\nLet's show first sample whose MGMT_value is 1.","de6650b6":"- FLAIR\n\n![](.\/animation\/sub_0_FLAIR.gif)\n\n- T1w\n\n![](.\/animation\/sub_0_T1w.gif)\n\n- T1wCE\n\n![](.\/animation\/sub_0_T1wCE.gif)\n\n- T2w\n\n![](.\/animation\/sub_0_T2w.gif)","72015c5a":"### Import modules and define consts and functions","4e5a8180":"### Example: BraTS21ID-00002\n\nNext, we show second sample whose MGMT_value is 1.","1280f178":"## Summary\n\nIn this notebook, we will show results of preprocessing the dataset by TorchIO with animation.\n\nThe work uses some ideas from great work below:\n\n- https:\/\/www.kaggle.com\/fepegar\/preprocessing-mri-with-torchio\n- https:\/\/torchio.readthedocs.io\/datasets.html?highlight=rsnamiccai#id4","1fd10a91":"## Conclusion\n\nIn this notebook, we confirmed below;\n\n- Each sample is in same voxel space.\n- There are some differences between MGMT_value 1 and 0 after preprocessing.\n- In view of the above, the preprocess is working well!","4b86ada3":"- FLAIR\n\n![](.\/animation\/sub_2_FLAIR.gif)\n\n- T1w\n\n![](.\/animation\/sub_2_T1w.gif)\n\n- T1wCE\n\n![](.\/animation\/sub_2_T1wCE.gif)\n\n- T2w\n\n![](.\/animation\/sub_2_T2w.gif)","c0bc1737":"### Example: BraTS21ID-00009\n\nFinally, we show second sample whose MGMT_value is 0.","737d0bdb":"- FLAIR\n\n![](.\/animation\/sub_3_FLAIR.gif)\n\n- T1w\n\n![](.\/animation\/sub_3_T1w.gif)\n\n- T1wCE\n\n![](.\/animation\/sub_3_T1wCE.gif)\n\n- T2w\n\n![](.\/animation\/sub_3_T2w.gif)"}}