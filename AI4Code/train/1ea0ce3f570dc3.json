{"cell_type":{"e8881697":"code","a294fec2":"code","116fced8":"code","2c3f47a4":"code","4580052c":"code","cc70df81":"code","8032e795":"code","7a547807":"code","09df0b21":"code","27b2cb0c":"code","7eda79a9":"code","1e09a016":"markdown","327eb408":"markdown"},"source":{"e8881697":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n\n!pip install tensorlayer\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a294fec2":"# train = pd.read_csv('\/kaggle\/input\/mnist-70000-original\/MNIST_data.csv')\n# target = pd.read_csv('\/kaggle\/input\/mnist-70000-original\/MNIST_target.csv')\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nY = train['label']\nX = train.drop('label', axis=1)\n# Y=target\n# X=train\n\n# xx = np.array(train.drop(\"label\", axis=1)).astype('float32')\n# yy = np.array(train['label']).astype('float32')\n# for i in range(9):\n#     plt.subplot(3,3,i+1)\n#     plt.xticks([])\n#     plt.yticks([])\n#     plt.grid(False)\n#     plt.imshow(xx[i].reshape(28, 28), cmap=plt.cm.binary)\n#     plt.xlabel(yy[i])\n# plt.show()","116fced8":"X = X\/255.\ntest_X = test\/255.","2c3f47a4":"# Using Data augmentation to prevent overfitting\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = False, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\nX = X.values.reshape(-1,28,28,1)\ntest_X = test_X.values.reshape(-1,28,28,1)\ndatagen.fit(X)","4580052c":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\nY = label_binarizer.fit_transform(Y)","cc70df81":"from sklearn.model_selection import train_test_split\n\nX_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n# X_train=X\n# y_train=Y","8032e795":"import tensorflow as tf\nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout,BatchNormalization, GlobalAveragePooling2D\n\ndef create_model():\n    model = models.Sequential()\n    model.add(Conv2D(100 , (5,5) , strides = 2 , padding = 'same', activation = 'relu' , input_shape = (28,28,1)))\n    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(75 , (5,5) , strides = 1 , padding = 'same' , activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(50 , (5,5) , strides = 1 , padding = 'same' , activation = 'relu'))\n    model.add(Dropout(0.2))\n    model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n    model.add(BatchNormalization())\n    model.add(Flatten())\n    model.add(Dense(units = 256 , activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    model.add(Dense(units = 10 , activation = 'softmax')) \n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n    return model","7a547807":"from sklearn.metrics import mean_squared_error\n\n# early = tf.keras.callbacks.EarlyStopping(patience=3)\n\nmodel = create_model()\n# history = model.fit(X,Y, epochs=20, validation_data=(x_test, y_test), verbose=1)\nhistory = model.fit_generator(datagen.flow(X, Y, batch_size = 128), epochs=20, validation_data=(x_test, y_test), verbose=1)\npred_y = model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, pred_y))","09df0b21":"# test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n# p = model.predict_classes(x_test)\n# pp = y_test.argmax(axis=1)\n# print((pp!=p).sum())\n# j=0\n# figure = plt.figure(figsize=(5, 5))\n# for i in range(len(p)):\n#     if(p[i] != pp[i]):\n#         plt.subplot(5,5,j+1)\n#         plt.xticks([])\n#         plt.yticks([])\n#         plt.grid(False)\n#         plt.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.binary)\n#         plt.xlabel(\"Real: %d, Predicted: %d\" % (pp[i], p[i]))\n#         j += 1\n#     if(j==25):\n#         break\n# plt.tight_layout()\n# plt.show()","27b2cb0c":"# from sklearn.model_selection import KFold\n \n# n_split=2\n\n# best = None\n# best_eval = None\n\n# early = tf.keras.callbacks.EarlyStopping(patience=3)\n\n# for train_index,test_index in KFold(n_split).split(X):\n#     x_train,x_test=X[train_index],X[test_index]\n#     y_train,y_test=Y[train_index],Y[test_index]\n\n#     model=create_model()\n#     model.fit(datagen.flow(X, Y, batch_size = 256), callback=[early], epochs=30)\n#     evaluate=model.evaluate(x_test,y_test)\n#     if not best or evaluate > best_eval:\n#         best = model\n#         best_eval = evaluate\n#         print('Model evaluation ', evaluate)\n\n# print('Best ', best_eval)\n","7eda79a9":"predictions = model.predict_classes(test_X)\n# predictions = label_binarizer.inverse_transform(predictions)\nsubmission = pd.DataFrame({'ImageId': range(1,len(predictions)+1), 'Label': predictions})\nsubmission.to_csv('digit_cnn.csv', index=False)\nsubmission.head()\n# predictions","1e09a016":"Pre-processing","327eb408":"CNN"}}