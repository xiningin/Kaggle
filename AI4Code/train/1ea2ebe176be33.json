{"cell_type":{"b97af549":"code","92652b37":"code","5b79e26e":"code","34250fe3":"code","1ef1b42e":"code","3ad8b071":"code","77b15023":"code","109857be":"code","4af2cb3a":"code","ae5e7385":"code","dd27d01d":"code","ce627359":"code","5d423320":"code","179dfc0b":"code","a2f1100f":"code","a9901faf":"code","cc9b9633":"code","7c552f44":"markdown","cb721d14":"markdown","78a6ab55":"markdown","9cf1852e":"markdown","b8023af7":"markdown","62d8504f":"markdown","bdf704f5":"markdown","b218aa6a":"markdown","3be71202":"markdown","78532448":"markdown","3e9423a4":"markdown"},"source":{"b97af549":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","92652b37":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom pandas import Series,DataFrame\nimport scipy\nfrom pylab import rcParams\nimport urllib\nimport sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import neighbors\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')\nprint ('Setup Complete')","5b79e26e":"df = pd.read_csv(\"\/kaggle\/input\/iris-flower-dataset\/IRIS.csv\")","34250fe3":"df.shape","1ef1b42e":"df.head(5)","3ad8b071":"df.dtypes","77b15023":"df.isnull().sum()","109857be":"df.info()","4af2cb3a":"df.describe()","ae5e7385":"plt.figure(figsize=(12,12))\nsns.heatmap(df.drop('species',axis=1).corr(),annot=True)","dd27d01d":"sns.set(style=\"ticks\")\nsns.pairplot(df, hue=\"species\")","ce627359":"X_prime=df.ix[:,(0,1,2,3)].values\ny=df.ix[:,4].values\nX= preprocessing.scale(X_prime)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3, random_state  = 5)","5d423320":"#K-Nearest Neighbours\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('Accuracy is:',accuracy_score(y_pred,y_test))","179dfc0b":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","a2f1100f":"scores=[]\nfor n in range(1,15):\n    model=KNeighborsClassifier(n_neighbors=n)\n    model.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    scores.append(accuracy_score(y_pred,y_test))\n    \nplt.plot(range(1,15),scores)\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Accuracy\")\nplt.show()","a9901faf":"model = KNeighborsClassifier(n_neighbors=6)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('Accuracy is:',accuracy_score(y_pred,y_test))","cc9b9633":"pd.crosstab(y_test, y_pred, rownames=['variety'], colnames=['predicted'])","7c552f44":"In **X_prime** variable, we will store independent columns values and in **y** variable, we will store dependent column values.\n\nWe will split the data into train and test data. Here test data is 30% and remaining 70% is train data.","cb721d14":"This dataset consists of 150 samples of species of iris flower. There are 50 samples for each, Iris setosa, Iris virginica and Iris versicolor.For each such sample there are four features,  the length and the width of the sepals and petals, in centimeters.","78a6ab55":"crosstab is used to get information about where our model predicted wrong values.","9cf1852e":"Above, we have set our model for n=3 neighbors, now we will check that if we can increase the accuracy of our model by giving different values of **n**.","b8023af7":"Accuracy is much greater at n=6 neighbors as compared to n=3 neighbors, therefore we will build our model at n=6 neighbors.","62d8504f":"Accuracy of our model is much better than the previous model.\n\n\n\n\n\n\nThank You.","bdf704f5":"There are no missing values.","b218aa6a":"Now, we will use K-Nearest Neighbor Algorithm.\n","3be71202":"Here, **y_pred** variable is used to store all the predicted values of test data.","78532448":"We can also analyze the correlation using pairplots given below. ","3e9423a4":"From above heatmap we can see that there is good correlation between petal_width and petal_lenth, sepal_lenth and petal_length and also between sepal_length and petal_width (written in decreasing order of correlation)."}}