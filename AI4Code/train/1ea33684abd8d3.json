{"cell_type":{"c2eb7fe8":"code","7998e1de":"code","9ff5e07e":"code","7d196376":"code","63caa1f0":"code","0d862e6e":"code","fd5144ca":"code","ae33ce8f":"code","9b815644":"code","d5b6c6d1":"code","94c3a7d4":"code","ce79d820":"code","9a0ee722":"code","befd687b":"code","60335c4b":"code","7427f44f":"code","47fdfedc":"code","fb5b0aa4":"code","b07c36d0":"code","f13f0d30":"code","5e1eeba2":"code","f7963c0e":"code","5cbf20e2":"code","dd65a53c":"markdown","4406723d":"markdown","66b33854":"markdown","8c46d359":"markdown","2a1c3b2f":"markdown","0e393840":"markdown","fd375e40":"markdown","f59ffe7c":"markdown","5198d234":"markdown","7faea137":"markdown","c83d8084":"markdown","3533241b":"markdown","e7a4bcb2":"markdown","c2ead054":"markdown","d78de724":"markdown","e8f4750c":"markdown"},"source":{"c2eb7fe8":"import pandas as pd\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport glob\n\nfrom random import sample, randint\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Dropout\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2\n\nimport easyocr\n\nfrom lxml import etree","7998e1de":"for dirName, _, fileNames in os.walk('\/kaggle\/input'):\n    for fileName in fileNames:\n        print(os.path.join(dirName, fileName))","9ff5e07e":"# Set Image Size\nIMAGE_SIZE = 200\n\nimg_dir = \"..\/input\/car-plate-detection\/images\"\ndata_path = os.path.join(img_dir,'*g')\n\nfiles = glob.glob(data_path)\nfiles.sort()\n\nX=[]\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    X.append(np.array(img))","7d196376":"def resizeannotation(f):\n    tree = etree.parse(f)\n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n    for dim in tree.xpath(\"object\/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text) \/ (width \/ IMAGE_SIZE)\n        ymin = int(dim.xpath(\"ymin\")[0].text) \/ (height \/ IMAGE_SIZE)\n        xmax = int(dim.xpath(\"xmax\")[0].text) \/ (width \/ IMAGE_SIZE)\n        ymax = int(dim.xpath(\"ymax\")[0].text) \/ (height \/ IMAGE_SIZE)\n    return [int(xmax), int(ymax), int(xmin), int(ymin)]","63caa1f0":"path = '..\/input\/car-plate-detection\/annotations'\ntext_files = ['..\/input\/car-plate-detection\/annotations\/'+f for f in sorted(os.listdir(path))]\n\ny=[]\nfor i in text_files:\n    y.append(resizeannotation(i))","0d862e6e":"sample_index = []\n\nfor i in range(9):\n    sample_index.append(randint(0, len(X)))\n\nplt.figure(figsize=(15, 15))\nfor index, i in enumerate(sample_index):\n    plt.subplot(3, 3, index + 1)\n    plt.axis('off')\n    plt.imshow(cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB))","fd5144ca":"print(f\"X Shape : {np.array(X).shape}\")\nprint(f\"y Shape : {np.array(y).shape}\")","ae33ce8f":"plt.figure(figsize=(15, 15))\nfor index, i in enumerate(sample_index):\n    plt.subplot(3, 3, index + 1)\n    image = cv2.rectangle(cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB),(y[i][0],y[i][1]),(y[i][2],y[i][3]),(0, 255, 0), 2)\n    plt.imshow(image)\n    plt.axis(\"off\")\n\nplt.show()","9b815644":"for i in range(9):\n    print(y[i])","d5b6c6d1":"X = np.array(X)\ny = np.array(y)\n\nX = X \/ 255\ny = y \/ 255","94c3a7d4":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1)","ce79d820":"model = Sequential()\nmodel.add(VGG19(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"sigmoid\"))\n\nmodel.layers[-7].trainable = False\n\nmodel.summary()","9a0ee722":"model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, verbose=1)","befd687b":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training and validation loss curves (VGG19)')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","60335c4b":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Training and validation accuracy curves (VGG19)')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","7427f44f":"test_loss, test_accuracy = model.evaluate(X_test, y_test,steps=int(100))\ny_cnn = model.predict(X_test)\n\nprint(\"\")\nprint(f\"Loss : {test_loss * 100}%\")\nprint(f\"Accuracy : {test_accuracy * 100}%\")","47fdfedc":"sample_index = []\n\nfor i in range(9):\n    sample_index.append(randint(0, len(X_test)))\n\ntext = easyocr.Reader(['en'])\nplt.figure(figsize=(15, 15))\nfor index, i in enumerate(sample_index):\n    plt.subplot(3, 3, index + 1)\n    plt.axis('off')\n    ny = np.copy(y_cnn[i])\n    ny = ny * 255\n    \n    rgb_img = cv2.cvtColor(np.copy(X_test[i]).astype('float32'), cv2.COLOR_BGR2RGB)\n    image = cv2.rectangle(rgb_img,(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    plt.imshow(image)\n    \nplt.show()","fb5b0aa4":"model2 = Sequential()\nmodel2.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel2.add(Flatten())\nmodel2.add(Dropout(0.4))\nmodel2.add(Dense(256, activation=\"relu\"))\nmodel2.add(Dense(128, activation=\"relu\"))\nmodel2.add(Dense(64, activation=\"relu\"))\nmodel2.add(Dense(4, activation=\"sigmoid\"))\n\nmodel2.layers[-7].trainable = False\n\nmodel2.summary()","b07c36d0":"model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n\nhistory2 = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, verbose=1)","f13f0d30":"plt.plot(history2.history['loss'])\nplt.plot(history2.history['val_loss'])\nplt.title('Training and validation loss curves (VGG16)')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","5e1eeba2":"plt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.title('Training and validation accuracy curves (VGG16)')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","f7963c0e":"test_loss2, test_accuracy2 = model2.evaluate(X_test, y_test,steps=int(100))\ny_cnn2 = model2.predict(X_test)\n\nprint(\"\")\nprint(f\"Loss : {test_loss2 * 100}%\")\nprint(f\"Accuracy : {test_accuracy2 * 100}%\")","5cbf20e2":"plt.figure(figsize=(15, 15))\nfor index, i in enumerate(sample_index):\n    plt.subplot(3, 3, index + 1)\n    plt.axis('off')\n    ny = np.copy(y_cnn2[i])\n    ny = ny * 255\n    \n    rgb_img = cv2.cvtColor(np.copy(X_test[i]).astype('float32'), cv2.COLOR_BGR2RGB)\n    image = cv2.rectangle(rgb_img, (int(ny[0]), int(ny[1])), (int(ny[2]), int(ny[3])), (0, 255, 0))\n    plt.imshow(image)\n    \nplt.show()","dd65a53c":"## Data Preprocessing","4406723d":"## Model Evaluation (VGG16)","66b33854":"<font size=\"3\">Data Splitting (70% Training, 10% Validation, 20% Testing)<\/font>","8c46d359":"## Model Training (VGG19)","2a1c3b2f":"## Load Dataset","0e393840":"## Model Creation (VGG19)","fd375e40":"## Model Creation (VGG16)","f59ffe7c":"## Model Testing (VGG19)","5198d234":"## Data Samples","7faea137":"## Import Libaries","c83d8084":"## Model Training (VGG16)","3533241b":"## Model Testing (VGG16)","e7a4bcb2":"## Feature & Target Extraction","c2ead054":"## Model Evaluation (VGG19)","d78de724":"## Display Image Dataset","e8f4750c":"## Check Image Size"}}