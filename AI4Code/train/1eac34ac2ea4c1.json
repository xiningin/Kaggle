{"cell_type":{"ccb40a56":"code","6d4a4973":"code","2025af9f":"code","b166f591":"code","f1203784":"code","1711e960":"code","ed51a2fe":"code","491b9ccd":"code","7d6d056d":"code","265feb6e":"code","30259c57":"code","f759eb68":"code","d02ea90b":"code","c864a360":"code","d0fef67c":"code","c95bd962":"code","969032d7":"code","f22bbbd0":"code","8a116ac9":"code","88e387a7":"code","07d961c6":"code","2d133158":"code","08ea01f8":"code","55cf4a33":"code","b4238d92":"code","117f460f":"code","77d05a69":"code","0573b477":"code","02a9275b":"code","ec807138":"code","24cdeefb":"code","695b54d3":"code","b79597fc":"code","f92eac8c":"code","9b043442":"code","dfaa2d2b":"code","651138aa":"code","5ec4090a":"code","0125b8f1":"code","06a38502":"code","cf32c55e":"code","91350aed":"code","31c96b64":"code","8be7ae5f":"markdown","a1de3b78":"markdown","bc72fdd4":"markdown","0e653a8d":"markdown","f5afa112":"markdown","f512f808":"markdown","b24c03f5":"markdown","3cde1f03":"markdown","6f19633f":"markdown","02e4d198":"markdown","a3393c72":"markdown","2247f730":"markdown","e86ce450":"markdown","32e76cd9":"markdown"},"source":{"ccb40a56":"# Disabling warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")","6d4a4973":"# Import Main libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Import Visualization lib.\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","2025af9f":"import os\nprint(os.listdir('..\/input'))","b166f591":"# set our Dataframe\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/gender_submission.csv')","f1203784":"# Show first 5 rows of train data\ntrain_df.head()","1711e960":"# data size\nprint(\"Train Data Size: \", train_df.shape)\nprint(\"Test Data Size:  \", test_df.shape)","ed51a2fe":"# Show if any NAN data\ntrain_df.isnull().sum()","491b9ccd":"test_df.isnull().sum()","7d6d056d":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(np.nan, \"mean\")\n\ntrain_df['Age'] = imputer.fit_transform(np.array(train_df['Age']).reshape(891, 1)) # 1st\ntrain_df.Embarked.fillna(method='ffill', inplace=True) # 2nd\ntrain_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True) # 3rd\n\ntest_df['Age'] = imputer.fit_transform(np.array(test_df['Age']).reshape(418, 1))\ntest_df.Embarked.fillna(method='ffill', inplace=True)\ntest_df.Fare.fillna(method='ffill', inplace=True)\ntest_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)","265feb6e":"\"\"\"trn_mid = train_df.Age.median() # set median value\n\n# fill NAN data\ntrain_df.Age.fillna(trn_mid, inplace=True)\ntrain_df.Embarked.fillna(method='ffill', inplace=True)\ntrain_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)\n\ntst_mid = test_df.Age.median() # set median value\n\n# fill NAN data\ntest_df.Age.fillna(tst_mid, inplace=True)\ntest_df.drop(['PassengerId', 'Name', 'Cabin'], axis=1, inplace=True)\"\"\"","30259c57":"sns.countplot(x='Survived', hue='Sex', data=train_df)","f759eb68":"sns.countplot(x='Embarked', hue='Survived', data=train_df)","d02ea90b":"sns.countplot(x='SibSp', hue='Survived', data=train_df)","c864a360":"sns.countplot(x='Pclass', hue='Survived', data=train_df)","d0fef67c":"plt.figure(figsize=(10,5))\nsns.distplot(train_df['Age'], bins=24, color='b')","c95bd962":"train_df.info()","969032d7":"objects_cols = train_df.select_dtypes(\"object\").columns\nobjects_cols","f22bbbd0":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ntrain_df[objects_cols] = train_df[objects_cols].apply(le.fit_transform)\ntest_df[objects_cols] = test_df[objects_cols].apply(le.fit_transform)\ntrain_df[objects_cols].head()","8a116ac9":"train_df.head()","88e387a7":"plt.figure(figsize=(12, 8))\nplt.title('Titanic Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_df.corr(), linewidths=0.1, vmax=1.0, \n            square=True, linecolor='white', annot=True)","07d961c6":"from sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import accuracy_score","2d133158":"# Machine Learning \nX = train_df.drop(['Survived'], 1).values\ny = train_df['Survived'].values","08ea01f8":"scale = StandardScaler()\nscale.fit(X)\n\nX = scale.transform(X)","55cf4a33":"# Split data to 80% training data and 20% of test to check the accuracy of our model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1\/3, random_state=0)","b4238d92":"class Model:\n    def __init__(self, model):\n        self.model = model\n        self.X, self.y = X, y\n        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n        \n        self.train()\n    \n    def model_name(self):\n        model_name = type(self.model).__name__\n        return model_name\n        \n    def cross_validation(self, cv=5):\n        print(f\"Evaluate {self.model_name()} score by cross-validation...\")\n        CVS = cross_val_score(self.model, self.X, self.y, scoring='accuracy', cv=cv)\n        print(CVS)\n        print(\"=\"*60, \"\\nMean accuracy of cross-validation: \", CVS.mean())\n    \n    def train(self):\n        print(f\"Training {self.model_name()} Model...\")\n        self.model.fit(X_train, y_train)\n        print(\"Model Trained.\")\n        \n    def prediction(self, test_x=None, test=False):\n        if test == False:\n            y_pred = self.model.predict(self.X_test)\n        else:\n            y_pred = self.model.predict(test_x)\n            \n        return y_pred\n    \n    def accuracy(self):\n        y_pred = self.prediction()\n        y_test = self.y_test\n        \n        acc = accuracy_score(y_pred, y_test)\n        print(f\"{self.model_name()} Model Accuracy: \", acc)","117f460f":"xgb = XGBClassifier()\nxgb = Model(xgb)","77d05a69":"xgb.cross_validation()","0573b477":"xgb.accuracy()","02a9275b":"gnb = GaussianNB()\ngnb = Model(gnb)","ec807138":"gnb.cross_validation()","24cdeefb":"gnb.accuracy()","695b54d3":"svc = SVC()\nsvc = Model(svc)","b79597fc":"svc.cross_validation()","f92eac8c":"svc.accuracy()","9b043442":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc = Model(rfc)\nrfc.cross_validation()\nrfc.accuracy()","dfaa2d2b":"test_df.head()","651138aa":"# Predict our file test\ntest_X = test_df.values\ntest_X = scale.transform(test_X)","5ec4090a":"xgb_pred = xgb.prediction(test_x=test_X, test=True)\ngnb_pred = gnb.prediction(test_x=test_X, test=True)\nsvc_pred = svc.prediction(test_x=test_X, test=True)\nrfc_pred = rfc.prediction(test_x=test_X, test=True)","0125b8f1":"sub.head()\nsub.to_csv('submission.csv', index=False)\nsub.head()","06a38502":"sub['Survived'] = xgb_pred # Best Submission (Top 5% LB)\nsub.to_csv('xgb_submission.csv', index=False)\nsub.head(10)","cf32c55e":"sub['Survived'] = gnb_pred\nsub.to_csv('gnb_submission.csv', index=False)\nsub.head(10)","91350aed":"sub['Survived'] = svc_pred\nsub.to_csv('svc_submission.csv', index=False)\nsub.head(10)","31c96b64":"sub['Survived'] = rfc_pred\nsub.to_csv('rfc_submission.csv', index=False)\nsub.head(10)","8be7ae5f":"Start modeling.\n\nClass Model Idea from \"Heart Disease - Classifications\" kernel here:\nhttps:\/\/www.kaggle.com\/elcaiseri\/heart-disease-classifications","a1de3b78":"**<h2 style='color:red'>Titanic: Simple Models For Beginners With EDA<\/h2>**\n* ** 1- Introduction **\n* ** 2- Data Preparation **\n* ** 3- Data Visualization **\n* ** 4- Preprocessing data for machine learning **\n* ** 5- Machine Learning **\n* ** 6- Submitting **\n<hr>","bc72fdd4":"# Preprocessing data for machine learning","0e653a8d":"<h3>Thanks For Being Here.  <span style='color:red'>UPVOTE<\/span>  If Interested .. Feel Free In Comments<\/h3>","f5afa112":"# Machine Learing","f512f808":"As you see 3 columns have \"object\" data type. So we must convert it to numbers.","b24c03f5":"# Data Visualization","3cde1f03":"# Submitting","6f19633f":"Fix Data using 3 various methods. ","02e4d198":"# Data Preparation","a3393c72":"Encode target labels with value between 0 and (n_classes - 1).","2247f730":"1- Thier is more NAN value in \"Cabin\", \"Age\" columns.\n2- we did not need \"PassengerId\" columns.\n\nSo we need to fix that","e86ce450":"**Introduction**<br>\nThis is the legendary Titanic ML competition \u2013 the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.<br>\n**Goal**\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","32e76cd9":"SimpleImputer is sklearn library for Imputation of missing values\nYou Can find all of them here:\nhttps:\/\/scikit-learn.org\/stable\/modules\/impute.html#univariate-feature-imputation"}}