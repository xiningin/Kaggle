{"cell_type":{"1cfb9b92":"code","7f0e114f":"code","54947d80":"code","a25bdfde":"code","20a4edf6":"code","c32f4ed7":"code","c4b99eb1":"code","19523092":"code","301325f2":"code","18f06f6d":"code","a38d8256":"code","1af2d85d":"code","06b332f8":"code","9e70edeb":"code","36b6a9f1":"code","13fc159c":"code","a6bf6dd0":"markdown","65954fe6":"markdown","49400835":"markdown","6c8205e0":"markdown","00505b32":"markdown"},"source":{"1cfb9b92":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7f0e114f":"data = pd.read_csv(\"..\/input\/column_2C_weka.csv\")\ndata.head()","54947d80":"data[\"class\"].unique()","a25bdfde":"data[\"class\"].value_counts()","20a4edf6":"data.info()","c32f4ed7":"Normal_data = data[data[\"class\"] == \"Normal\"]\nAbnormal_data = data[data[\"class\"] == \"Abnormal\"]\nplt.scatter(\"pelvic_radius\",\"lumbar_lordosis_angle\", data = Normal_data, color= \"green\",label=\"Normal\", alpha= 0.6  )\nplt.scatter(\"pelvic_radius\",\"lumbar_lordosis_angle\", data = Abnormal_data, color= \"red\" ,label = \"Abnormal\", alpha= 0.7 )\nplt.xlabel(\"pelvic_radius\")\nplt.ylabel(\"lumbar_lordosis_angle\")\nplt.legend()\nplt.show()","c4b99eb1":"color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\npd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n                                       c=color_list,\n                                       figsize= [15,15],\n                                       diagonal='hist',\n                                       alpha=0.5,\n                                       s = 200,\n                                       edgecolor= \"black\")\nplt.show()","19523092":"data[\"class\"] = [1 if row == \"Normal\" else 0 for row in data[\"class\"]]\ny_data = data[\"class\"].values\nx_data = data.drop([\"class\"], axis = 1)\n\n#normalization\nx = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data))","301325f2":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y_data, test_size = 0.3, random_state = 1)","18f06f6d":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train, y_train)\nprint(\"Score\", knn.score(x_test, y_test))","a38d8256":"knn_acc_list = []\nfor neighbour in range(1,30):\n    knn2 = KNeighborsClassifier(n_neighbors=neighbour)\n    knn2.fit(x_train, y_train)\n    knn_acc_list.append(knn2.score(x_test, y_test))\nplt.figure(figsize=(12,8))\nplt.plot(range(1,30), knn_acc_list )\nplt.xlabel(\"Neighbour\")\nplt.ylabel(\"Accuracy\")\nplt.show()","1af2d85d":"from sklearn.svm import SVC\nsvm = SVC(random_state = 42)\nsvm.fit(x_train, y_train)\nsvm_score = svm.score(x_test,y_test)\nprint(\"Accuracy of svm: \",svm_score)","06b332f8":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)\nnb_score = nb.score(x_test,y_test)\nprint(\"Naive bayes score: \", nb_score)","9e70edeb":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(x_train, y_train)\ndt_score = dt.score(x_test, y_test)\nprint(\"Decision tree socore: \", dt_score)","36b6a9f1":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 100)\nrf.fit(x_train, y_train)\nrf_score = rf.score(x_test, y_test)\nprint(\"Random forest score :\", rf_score)","13fc159c":"rf_acc_list = []\nestimator_list = range(10, 200, 10)\nfor i in estimator_list:\n    rf2 = RandomForestClassifier(n_estimators= i)\n    rf2.fit(x_train, y_train)\n    rf_acc_list.append(rf2.score(x_test, y_test))\nplt.figure(figsize=(12,8))\nplt.plot(estimator_list, rf_acc_list)\nplt.xlabel(\"Tree count\")\nplt.ylabel(\"Accuracy\")\nplt.show()","a6bf6dd0":"# SVM","65954fe6":"# KNN ","49400835":"# Naive Bayes","6c8205e0":"# Decision Tree","00505b32":"# Data Analyze"}}