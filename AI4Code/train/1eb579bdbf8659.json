{"cell_type":{"0836cad3":"code","5d0fef99":"code","beea59f3":"code","e80e14b2":"code","caec4753":"code","293a67a4":"code","25a119c5":"code","d8b339c6":"code","74fd42b1":"code","b437a2e8":"code","cfedb66b":"code","f350a8a2":"code","10c58f13":"code","3b126704":"code","06a59aa2":"markdown"},"source":{"0836cad3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# Define path to the data directory\ndata_dir = Path('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray')\n\n# Path to train directory (Fancy pathlib...no more os.path!!)\ntr_dir = data_dir \/ 'train'\n\n# Path to validation directory\nval_dir = data_dir \/ 'val'\n\n# Path to test directory\nte_dir = data_dir \/ 'test'\n\n# Any results you write to the current directory are saved as output.","5d0fef99":"NormalCases_dir = tr_dir\/'NORMAL'\nPneumoniaCases_dir = tr_dir\/'PNEUMONIA'\n\n#Get the list of all images\nNormalCases = NormalCases_dir.glob('*.jpeg')\nPneumoniaCases = PneumoniaCases_dir.glob('*.jpeg')\n\n# An empty list. We will insert the data into this list in (img_path, label) format\ntrain_data = []\n\nfor img in NormalCases:\n    train_data.append((img, 0))\n    \nfor img in PneumoniaCases:\n    train_data.append((img, 1))\n    \ntrain_data = pd.DataFrame(train_data, columns = ['image', 'label'], index = None)\n\n# Shuffle the data\ntrain_data = train_data.sample(frac = 1).reset_index(drop = True)\n# https:\/\/stackoverflow.com\/questions\/29576430\/shuffle-dataframe-rows\n# The frac keyword argument specifies the fraction of rows to return in the random sample, so frac=1 means return all rows (in random order).\n# If you wish to shuffle your dataframe in-place and reset the index, you could do\n# Here, specifying drop=True prevents .reset_index from creating a column containing the old index entries.\n\ntrain_data.head(5)","beea59f3":"cases = train_data['label'].value_counts()\nprint(cases)","e80e14b2":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# https:\/\/seaborn.pydata.org\/generated\/seaborn.barplot.html\nplt.figure(figsize = (10, 8))\nsns.barplot(x = cases.index, y = cases.values)\nplt.title('Number of Cases', fontsize = 15)\nplt.xlabel('Case type', fontsize = 12)\nplt.ylabel('Count', fontsize = 12)\nplt.xticks(range(len(cases.index)), ['Normal - 0', 'Pneumonia -1 '])\nplt.show()\n","caec4753":"from skimage.io import imread\npneumonia_samples = (train_data[train_data['label'] == 1]['image'].iloc[:4]).tolist()\nnormal_samples = (train_data[train_data['label'] == 0]['image'].iloc[:4]).tolist()\n\nsamples = pneumonia_samples + normal_samples\ndel pneumonia_samples, normal_samples\n\nf, ax = plt.subplots(2, 4, figsize = (20, 10))\nfor i in range(8):\n    img = imread(samples[i])\n    ax[i\/\/4, i%4].imshow(img, cmap='gray')\n    if i<4:\n        ax[i\/\/4, i%4].set_title(\"Pneumonia\")\n    else:\n        ax[i\/\/4, i%4].set_title(\"Normal\")\n    ax[i\/\/4, i%4].axis('off')\n    ax[i\/\/4, i%4].set_aspect('auto')\nplt.show()","293a67a4":"import cv2\nfrom keras.utils import to_categorical\n\nNormalCasesDir = val_dir\/'NORMAL'\nPneumoniaCasesDir = val_dir\/'PNEUMONIA'\n\nNormalCases = NormalCasesDir.glob('*.jpeg')\nPneumoniaCases = PneumoniaCasesDir.glob('*.jpeg')\n\nvalidation_data = []\nvalidation_labels = []\n\n# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n# We will normalize the pixel values and resizing all the images to 224x224 \n\n# Normal cases\nfor img in NormalCases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(0, num_classes=2)\n    validation_data.append(img)\n    validation_labels.append(label)\n                      \n# Pneumonia cases        \nfor img in PneumoniaCases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(1, num_classes=2)\n    validation_data.append(img)\n    validation_labels.append(label)\n    \n# Convert the list into numpy arrays\nvalidation_data = np.array(validation_data)\nvalidation_labels = np.array(validation_labels)\n\nprint(\"Total number of validation examples: \", validation_data.shape)\nprint(\"Total number of labels:\", validation_labels.shape)","25a119c5":"from keras.preprocessing.image import ImageDataGenerator\naug = ImageDataGenerator()\n\naug = ImageDataGenerator(\n    rotation_range=20,\n\tzoom_range=0.15,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.15,\n\thorizontal_flip=True,\n\tfill_mode=\"nearest\")","d8b339c6":"def data_gen(data, batch_size):\n    # Get total number of samples in the data\n    n = len(data)\n    steps = n\/\/batch_size\n    \n    # Define two numpy arrays for containing batch data and labels\n    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n\n    # Get a numpy array of all the indices of the input data\n    indices = np.arange(n)\n    \n    # Initialize a counter\n    i =0\n    while True:\n        np.random.shuffle(indices)\n        # Get the next batch \n        count = 0\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n        for j, idx in enumerate(next_batch):\n            img_name = data.iloc[idx]['image']\n            label = data.iloc[idx]['label']\n            \n              # one hot encoding\n            encoded_label = to_categorical(label, num_classes=2)\n            # read the image and resize\n            img = cv2.imread(str(img_name))\n            img = cv2.resize(img, (224,224))\n            \n            # check if it's grayscale\n            if img.shape[2]==1:\n                img = np.dstack([img, img, img])\n            \n            # cv2 reads in BGR mode by default\n            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            # normalize the image pixels\n            orig_img = img.astype(np.float32)\/255.\n            \n            batch_data[count] = orig_img\n            batch_labels[count] = encoded_label\n            \n            # generating more samples of the undersampled class\n            if label==0 and count < batch_size-2:\n                aug_img1 = aug.augment_image(img)\n                aug_img2 = aug.augment_image(img)\n                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n                aug_img1 = aug_img1.astype(np.float32)\/255.\n                aug_img2 = aug_img2.astype(np.float32)\/255.\n                \n                batch_data[count+1] = aug_img1\n                batch_labels[count+1] = encoded_label\n                batch_data[count+2] = aug_img2\n                batch_labels[count+2] = encoded_label\n                count +=2\n            \n            else:\n                count+=1\n            \n            if count==batch_size-1:\n                break\n            \n        i+=1\n        yield batch_data, batch_labels\n            \n        if i>=steps:\n            i=0","74fd42b1":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nimport numpy as np\nnp.random.seed(1000)\n#Instantiate an empty model\nmodel = Sequential()\n\n# 1st Convolutional Layer\nmodel.add(Conv2D(filters = 96, input_shape = (224,224,3), kernel_size=(11,11), strides=(4,4), activation = 'relu'))\n# Max Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n# 2nd Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), activation = 'relu'))\n# Max Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n# 3rd Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation = 'relu'))\n\n# 4th Convolutional Layer\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation = 'relu'))\n\n# 5th Convolutional Layer\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation = 'relu'))\n# Max Pooling\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n\n# Passing it to a Fully Connected layer\nmodel.add(Flatten())\n# 1st Fully Connected Layer\nmodel.add(Dense(4096, input_shape=(224*224*3,), activation = 'relu'))\n# Add Dropout to prevent overfitting\nmodel.add(Dropout(0.4))\n\n# 2nd Fully Connected Layer\nmodel.add(Dense(4096, activation = 'relu'))\n\n# Add Dropout\nmodel.add(Dropout(0.4))\n\n# 3rd Fully Connected Layer\nmodel.add(Dense(1000, activation = 'relu'))\n\n# Add Dropout\nmodel.add(Dropout(0.4))\n\n# Output Layer\nmodel.add(Dense(2, activation = 'softmax'))\n\nmodel.summary()\n\n# Compile the model\nmodel.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])","b437a2e8":"batch_size = 16\nepochs = 20\n\n# Get a train data generator\ntrain_data_gen = data_gen(data = train_data, batch_size = batch_size)\n\n# Define the number of training steps\ntrain_steps = train_data.shape[0]\/\/batch_size","cfedb66b":"import cv2\nfrom keras.utils import to_categorical\n\nNormalCasesDir = te_dir\/'NORMAL'\nPneumoniaCasesDir = te_dir\/'PNEUMONIA'\n\nNormalCases = NormalCasesDir.glob('*.jpeg')\nPneumoniaCases = PneumoniaCasesDir.glob('*.jpeg')\n\ntest_data = []\ntest_labels = []\n\n# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n# We will normalize the pixel values and resizing all the images to 224x224 \n\n# Normal cases\nfor img in NormalCases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(0, num_classes=2)\n    test_data.append(img)\n    test_labels.append(label)\n                      \n# Pneumonia cases        \nfor img in PneumoniaCases:\n    img = cv2.imread(str(img))\n    img = cv2.resize(img, (224,224))\n    if img.shape[2] ==1:\n        img = np.dstack([img, img, img])\n    else:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = img.astype(np.float32)\/255.\n    label = to_categorical(1, num_classes=2)\n    test_data.append(img)\n    test_labels.append(label)\n    \n# Convert the list into numpy arrays\ntest_data = np.array(test_data)\ntest_labels = np.array(test_labels)\n\nprint(\"Total number of test examples: \", test_data.shape)\nprint(\"Total number of labels:\", test_labels.shape)","f350a8a2":"# Evaluation on test dataset\ntest_loss, test_score = model.evaluate(test_data, test_labels, batch_size = 16)\nprint(\"Loss on test set: \", test_loss)\nprint(\"Accuracy on test set: \", test_score)","10c58f13":"# Get predictions\npreds = model.predict(test_data, batch_size=16)\npreds = np.argmax(preds, axis=-1)\n\n# Original labels\norig_test_labels = np.argmax(test_labels, axis=-1)\n\nprint(orig_test_labels.shape)\nprint(preds.shape)","3b126704":"# Calculate Precision and Recall\ntn, fp, fn, tp = cm.ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","06a59aa2":"APPLYING ALEXNET"}}