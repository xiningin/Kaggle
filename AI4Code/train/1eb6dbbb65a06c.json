{"cell_type":{"ae484b86":"code","938a7c27":"code","a5c47cbf":"code","1a6ebae0":"code","2c9e1c64":"code","8dc1ad72":"code","e8fae0f6":"code","d0b26b69":"code","1420c058":"code","9a567505":"code","437b0b94":"code","9d0967c0":"code","7c639287":"code","996acec1":"code","ab3671ac":"code","8c08cf50":"code","7d5544b7":"code","3adf5000":"code","22816d58":"code","573fb45e":"code","0d031915":"code","a7f54952":"code","e65e8547":"code","95746f8e":"code","03e9cfbd":"code","69b998b3":"code","fd45a159":"code","9f444135":"code","3968df8f":"code","5de9bf3c":"code","f8b5597a":"code","3f5821a1":"code","d6b0bf5c":"code","6f8b0478":"code","70b73682":"code","71729e01":"code","cce16d5a":"code","dde34ca7":"code","5f651fd3":"code","55d2f4eb":"code","59a801a8":"code","ed8ca80f":"code","eea8789b":"code","094fd687":"code","6e16bf6f":"code","0983587e":"code","4dbd026b":"code","43ae199b":"code","93c90272":"code","a3f7f1e8":"code","6ae4c4c0":"code","fee1af91":"code","9e8a1a48":"code","5398dec9":"code","55c186e3":"code","1db3bd11":"code","f24518b6":"code","c940db72":"code","1d8abe19":"code","7fc08a94":"code","2acb60ad":"code","ab2323d4":"code","93902782":"code","836bdfa2":"code","340aabf0":"code","e0e5c100":"code","e756f605":"code","d883df95":"code","44f0b718":"code","94293a5c":"code","98f5e05f":"code","d0edc8b5":"code","dc666b21":"code","e6f3086a":"code","f9f893f6":"code","2c3803f4":"code","dd3cc2a4":"code","57e49c8e":"code","310de05b":"code","a58c41a1":"code","ae74e8ef":"code","89fddafe":"code","e11ce883":"code","7b66e6bd":"code","bcc03d2d":"code","3ea8808b":"code","9f02c91b":"code","e4c50614":"code","64721e26":"code","3d2f0ab3":"markdown","8ed4b94a":"markdown","46c48a12":"markdown","e42c9c48":"markdown","54ebe59f":"markdown","63eb4cba":"markdown","2beb5612":"markdown","ad3b59c1":"markdown","5da8786a":"markdown","4502982d":"markdown","fa511287":"markdown","31f465f4":"markdown","c9cfa8e3":"markdown","8ff13e54":"markdown","4751f23c":"markdown","98e72af3":"markdown","af008bd7":"markdown","d23ae26e":"markdown"},"source":{"ae484b86":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","938a7c27":"# from IPython.display import Image\n# Image(url= \"https:\/\/static1.squarespace.com\/static\/5006453fe4b09ef2252ba068\/5095eabce4b06cb305058603\/5095eabce4b02d37bef4c24c\/1352002236895\/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")","a5c47cbf":"# # !pip install autoviz\n# # !pip install xlrd\n\n# from autoviz.AutoViz_Class import AutoViz_Class#Instantiate the AutoViz class\n# AV = AutoViz_Class()\n# from IPython.display import clear_output\n# clear_output()","1a6ebae0":"# ff = AV.AutoViz(\"\/kaggle\/input\/titanic\/train.csv\")","2c9e1c64":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.head()","8dc1ad72":"test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest.head()","e8fae0f6":"# women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\n# rate_women = sum(women)\/len(women)\n\n# print(\"% of women who survived:\", rate_women)","d0b26b69":"# men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\n# rate_men = sum(men)\/len(men)\n\n# print(\"% of men who survived:\", rate_men)","1420c058":"train.info()\ntest.info()\ntrain.shape\n","9a567505":"test.shape","437b0b94":"train.isnull().sum()\n","9d0967c0":"test.isnull().sum()","7c639287":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","996acec1":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","ab3671ac":"bar_chart('Sex')","8c08cf50":"bar_chart('Pclass')","7d5544b7":"bar_chart('SibSp')","3adf5000":"bar_chart('Parch')","22816d58":"bar_chart('Embarked')","573fb45e":"# Image(url= \"https:\/\/static1.squarespace.com\/static\/5006453fe4b09ef2252ba068\/t\/5090b249e4b047ba54dfd258\/1351660113175\/TItanic-Survival-Infographic.jpg?format=1500w\")","0d031915":"train_test_data = [train, test] # combining train and test dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","a7f54952":"train['Title'].value_counts()","e65e8547":"test['Title'].value_counts()","95746f8e":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","03e9cfbd":"train.head()","69b998b3":"test.head()","fd45a159":"bar_chart('Title')","9f444135":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","3968df8f":"train.head()","5de9bf3c":"test.head()","f8b5597a":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","3f5821a1":"bar_chart('Sex')","d6b0bf5c":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","6f8b0478":"train.head()\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","70b73682":"train.head(30)\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","71729e01":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show() ","cce16d5a":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","dde34ca7":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","5f651fd3":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","55d2f4eb":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","59a801a8":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","ed8ca80f":"train.info()","eea8789b":"test.info()","094fd687":"temp_data = test[['Age']]\ntemp_data.head()","6e16bf6f":"for dataset in train_test_data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6","0983587e":"train.head()","4dbd026b":"bar_chart('Age')","43ae199b":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","93c90272":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","a3f7f1e8":"train.head()","6ae4c4c0":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","fee1af91":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head()","9e8a1a48":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()  ","5398dec9":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","55c186e3":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","1db3bd11":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","f24518b6":"for dataset in train_test_data:\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","c940db72":"train.head()","1d8abe19":"train.Cabin.value_counts()","7fc08a94":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","2acb60ad":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","ab2323d4":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","93902782":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","836bdfa2":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","340aabf0":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","e0e5c100":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","e756f605":"train.head()","d883df95":"train.head()","44f0b718":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","94293a5c":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","98f5e05f":"train_data.head(10)","d0edc8b5":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","dc666b21":"train.info()","e6f3086a":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","f9f893f6":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","2c3803f4":"# kNN Score\nround(np.mean(score)*100, 2)","dd3cc2a4":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","57e49c8e":"# decision tree Score\nround(np.mean(score)*100, 2)","310de05b":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","a58c41a1":"# Random Forest Score\nround(np.mean(score)*100, 2)","ae74e8ef":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","89fddafe":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","e11ce883":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","7b66e6bd":"round(np.mean(score)*100,2)","bcc03d2d":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","3ea8808b":"# submission = pd.DataFrame({\n#         \"PassengerId\": test[\"PassengerId\"],\n#         \"Survived\": prediction\n#     })\n\n# submission.to_csv('submission.csv', index=False)","9f02c91b":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': prediction})\noutput.to_csv('my_submission.csv', index=False)\n","e4c50614":"submission = pd.read_csv('my_submission.csv')\nsubmission.head()","64721e26":"# help(RandomForestClassifier)\n# help(pd.DataFrame)","3d2f0ab3":"Sex","8ed4b94a":"Ramdon Forest","46c48a12":" FamilySize","e42c9c48":"Decision Tree","54ebe59f":"References\nThis notebook is created by learning from the following notebooks:\n\nMukesh ChapagainTitanic Solution: A Beginner's Guide\nHow to score 0.8134 in Titanic Kaggle Challenge\nTitanic: factors to survive\nTitanic Survivors Dataset and Data Wrangling","63eb4cba":"Age to catagory\n\nfeature vector map:\nchild: 0\nyoung: 1\nadult: 2\nmid-age: 3\nsenior: 4","2beb5612":"Modelling","ad3b59c1":"Age","5da8786a":"Bar Chart for Categorical Features\nPclass\nSex\nSibSp ( # of siblings and spouse)\nParch ( # of parents and children)\nEmbarked\nCabin","4502982d":"Cross Validation (K-fold)","fa511287":"KNN","31f465f4":"Feature engineering\nFeature engineering is the process of using domain knowledge of the data\nto create features (feature vectors) that make machine learning algorithms work.\n\nfeature vector is an n-dimensional vector of numerical features that represent some object.\nMany algorithms in machine learning require a numerical representation of objects,\nsince such representations facilitate processing and statistical analysis.","c9cfa8e3":"Naive Bayes","8ff13e54":"SVM","4751f23c":"Fare","98e72af3":"Embarked","af008bd7":"Cabin","d23ae26e":"Testing"}}