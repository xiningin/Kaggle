{"cell_type":{"738583b0":"code","530d3e5b":"code","f8c35267":"code","585828bf":"code","16b41c33":"code","cc904037":"code","3be3b647":"code","b3cb8b60":"code","a7600a0a":"code","9f4dd426":"code","7b17eb72":"code","f5d8dcd6":"code","65d6d9e4":"code","9b4fb7cc":"code","1d238865":"code","a142aa9b":"code","fc725cc8":"code","61927eae":"code","4d9af103":"code","5fa51307":"code","6c963f28":"code","53ac0af6":"code","0d865989":"code","7f7ab416":"markdown","c4d5c9f1":"markdown","2e6a42b7":"markdown","03706879":"markdown","cd8b843f":"markdown","73771dc3":"markdown","c48da0aa":"markdown","283665e8":"markdown","042b836d":"markdown","c0495eac":"markdown"},"source":{"738583b0":"import tensorflow as tf\nimport IPython.display as display\nimport PIL\nimport PIL.Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pathlib\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.models import load_model","530d3e5b":"dir1 = '..\/input\/Mango\/train'\ndir2 = '..\/input\/Mango\/test'\n\ndata_dir = pathlib.Path(dir1)\ntest_dir = pathlib.Path(dir2)\n\nprint(data_dir)\nprint(test_dir)","f8c35267":"train_count = len(list(data_dir.glob('*\/*.JPG')))\ntest_count = len(list(test_dir.glob('*\/*.JPG')))\nprint(train_count)\nprint(test_count)","585828bf":"healthy_train = list(data_dir.glob('healthy\/*'))\nPIL.Image.open(str(healthy_train[0]))","16b41c33":"batch_size = 32\nimg_height = 180\nimg_width = 180","cc904037":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_gen_train = ImageDataGenerator(rescale = 1.\/255,\n                                     validation_split=0.2,\n                                     rotation_range = 45,\n                                     width_shift_range=.15,\n                                     height_shift_range =.15,\n                                     horizontal_flip=True,\n                                     zoom_range=0.5)","3be3b647":"train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n                                              subset = 'training',  \n                                              directory= data_dir,       \n                                              shuffle=True,\n                                              target_size=(img_height, img_width)\n                                              )    ","b3cb8b60":"#image_gen_val = ImageDataGenerator(rescale = 1.\/255)","a7600a0a":"validation_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n                                              subset = 'validation',  \n                                              directory= data_dir,       \n                                              shuffle=True,\n                                              target_size=(img_height, img_width)\n                                              )  ","9f4dd426":"CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\nCLASS_NAMES","7b17eb72":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(25):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n        plt.axis('off')","f5d8dcd6":"image_batch, label_batch = next(train_data_gen)\nshow_batch(image_batch, label_batch)","65d6d9e4":"for image_batch, labels_batch in train_data_gen:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","9b4fb7cc":"from tensorflow.keras import layers\nnum_classes = 2\nmodel_mango = Sequential([\n  Conv2D(16, 3, padding='same', activation='relu',\n        input_shape=(img_height, img_width ,3)),\n  MaxPooling2D(),\n  Conv2D(32, 3, padding='same', activation='relu'),\n  MaxPooling2D(),\n  Conv2D(64, 3, padding='same', activation='relu'),\n  MaxPooling2D(),\n  Dropout(0.2),\n  Flatten(),\n  Dense(128, activation='relu'),\n  Dense(num_classes)\n])","1d238865":"model_mango.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","a142aa9b":"model_mango.summary()","fc725cc8":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nrlr = ReduceLROnPlateau(patience=10, verbose=1)\nes = EarlyStopping(patience=24, restore_best_weights=True, verbose=1)\nmc = ModelCheckpoint('model_mango.hdf5', save_best_only=True, verbose=1)","61927eae":"epochs = 15\nhistory = model_mango.fit(\n  train_data_gen,\n  callbacks=[rlr, es, mc],  \n  validation_data=validation_data_gen,\n  epochs=epochs\n)","4d9af103":"model_mango = load_model('model_mango.hdf5')\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","5fa51307":"image_gen_test = ImageDataGenerator(rescale = 1.\/255)\ntest_data_gen = image_gen_test.flow_from_directory(batch_size=32,\n                                              directory= test_dir,\n                                              shuffle=True,\n                                              target_size=(img_height, img_width)\n                                              )  ","6c963f28":"predictions = model_mango.predict(test_data_gen)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(CLASS_NAMES[np.argmax(score)], 100 * np.max(score))\n)","53ac0af6":"predictions.shape","0d865989":"score2 = tf.nn.softmax(predictions)\nscore2","7f7ab416":"# **Class labels**","c4d5c9f1":"### Convolution network","2e6a42b7":"### Larning rate reducing by 0.1  every 10 epochs on plateau\n### Early stopping to stop learning after 24 epochs on plateau (with restoring best model)\n### Model checkpoint to save best model to file","03706879":"### Image Generator","cd8b843f":"### Fit the created model","73771dc3":"#  **Import libraries**","c48da0aa":"### Plot loss and accuracy","283665e8":"# **Number of Images**","042b836d":"# **Load image data**","c0495eac":"# **show test image**"}}