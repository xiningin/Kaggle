{"cell_type":{"f0b45429":"code","e91dc573":"code","9849132f":"code","9ef833b7":"code","83439ef1":"code","bca755b1":"code","4d515f71":"code","33184475":"code","354936dc":"code","ba555661":"markdown","35be6498":"markdown","f90c7b73":"markdown","f6835500":"markdown","e69464a7":"markdown","915a5090":"markdown","2f5034de":"markdown","73b490ac":"markdown","b814ab8a":"markdown","6f3e29c9":"markdown","c0675d7c":"markdown","0f6fb530":"markdown"},"source":{"f0b45429":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pylab as plt\nimport os\nimport PIL","e91dc573":"print('TensorFlow version: {}'.format(tf.__version__))\ndevice_name = tf.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n    print('GPU device not found - On for CPU time!')\nelse:\n    print('Found GPU at {}'.format(device_name))","9849132f":"#path = '..\/input\/petfinder-pawpularity-score\/train\/'\n#training_img = os.listdir(path) # list all training images names\n#print('There are {} images in the training directory'.format(len(training_img)))\n\n#img_sz = {'width': list(),\n#          'height': list()} # store image attributes for further analysis\n\n#for im in training_img:\n#    img = PIL.Image.open(path+im)\n#    w, h = img.size\n#    img_sz['width'].append(w)\n#    img_sz['height'].append(h)\n\n#IMG_WIDTH = tf.math.reduce_mean(img_sz['width'])\n#IMG_HEIGHT = tf.math.reduce_mean(img_sz['height'])\n#IMG_CHANNELS = 3\n\n#print('Average training image width: {} px'.format(IMG_WIDTH))\n#print('Average training image height: {} px'.format(IMG_HEIGHT))","9ef833b7":"# Let's define some helpers\n\nIMG_HEIGHT = 150 # Let's try to arbitrarily set 150px x 150px images\nIMG_WIDTH = 150\nIMG_CHANNELS = 3\n\ndef read_and_decode(filename, reshape_dims):\n    # Read an image file to a tensor as a sequence of bytes\n    img = tf.io.read_file(filename)\n    # Convert the tensor to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n    # Convert 3D uint8 tensor \n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # Resize the image to the desired size\n    return tf.image.resize(img, reshape_dims)\n\ndef show_image(filename):\n    img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    plt.imshow(img.numpy());\n    plt.axis('off');\n    \ndef decode_csv(csv_row):\n    record_defaults = ['Id', 'Pawpularity']\n    filename, pawpularity = tf.io.decode_csv(csv_row, record_defaults)\n    pawpularity = tf.convert_to_tensor(np.float(pawpularity), dtype=tf.float32)\n    img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n    return img, pawpularity","83439ef1":"data_path = '..\/input\/petfinder-pawpularity-score\/'\ndata = pd.read_csv(data_path+'train.csv')\n\n# Use stratified sampling\nsssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\nfor train_index, test_index in sssplit.split(data, data['Pawpularity']):\n    training_set = data.iloc[train_index]\n    eval_set = data.iloc[test_index]\n    \n# Visually check distribution of pawpularity score in training and test sets\ntraining_set['Pawpularity'].hist(label='Training set')\neval_set['Pawpularity'].hist(label='Eval set')\nplt.title('Pawpularity score distribution in training and test set')\nplt.xlabel('Pawpularity score')\nplt.ylabel('Count')\nplt.legend(loc='upper right')\nplt.show()\n\n# Export training and test sets as .csv files\ntraining_set['Id'] = training_set['Id'].apply(lambda x: '..\/input\/petfinder-pawpularity-score\/train\/'+x+'.jpg')\ntraining_set[['Id', 'Pawpularity']].to_csv('\/kaggle\/working\/training_set.csv', header=False, index=False)\neval_set['Id'] = eval_set['Id'].apply(lambda x: '..\/input\/petfinder-pawpularity-score\/train\/'+x+'.jpg')\neval_set[['Id', 'Pawpularity']].to_csv('\/kaggle\/working\/eval_set.csv', header=False, index=False)","bca755b1":"BATCH_SIZE = 32\nIMG_HEIGHT = 150 # Let's try to arbitrarily set 150px x 150px images\nIMG_WIDTH = 150\nIMG_CHANNELS = 3\n\ntrain_dataset = tf.data.TextLineDataset(\n    '\/kaggle\/working\/training_set.csv'\n).map(decode_csv).batch(BATCH_SIZE)\n\neval_dataset = tf.data.TextLineDataset(\n    '\/kaggle\/working\/eval_set.csv'\n).map(decode_csv).batch(BATCH_SIZE)\n\n# Our neural network is built as a Sequential model with a single hidden layer\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n    tf.keras.layers.Dense(units=128, activation='relu'), # The hidden layer adds nonlinearity with the ReLU activation function\n    tf.keras.layers.Dense(units=1, activation=None)\n])\n\n# Let's compile it with Adam, a well-suited optimiser for CV problems\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.MeanSquaredError(),\n              metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\n# And let's now train our model with the training and evaluation data\nhistory = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)","4d515f71":"# Let's plot our neural network to see how data is passed through\ntf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=False)","33184475":"sample_submission = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\nsample_submission['Id'] = sample_submission['Id'].apply(lambda x: '..\/input\/petfinder-pawpularity-score\/test\/'+x+'.jpg')\nsample_submission.to_csv('\/kaggle\/working\/sample_submission.csv', index=False, header=False)\nsample_submission = tf.data.TextLineDataset(\n    '.\/sample_submission.csv'\n).map(decode_csv).batch(BATCH_SIZE)\n\n# Make predictions with our model\nsample_prediction = model.predict(sample_submission)","354936dc":"# Format predictions to output for submission\nsubmission_output = pd.concat(\n    [pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv').drop('Pawpularity', axis=1),\n    pd.DataFrame(sample_prediction)],\n    axis=1\n)\nsubmission_output.columns = [['Id', 'Pawpularity']]\n\n# Output submission file to csv\nsubmission_output.to_csv('submission.csv', index=False)","ba555661":"Here we'll ensure that training and test sets are built from the same distribution by using stratified sampling instead of random sampling.","35be6498":"First neural network is built with a single hidden layer and no further optimisation or hyperparameter tuning","f90c7b73":"### Training and test sets","f6835500":"### Image attributes analysis","e69464a7":"## Neural network using Keras","915a5090":"## ETL: load data and prepare it for feeding a Keras model","2f5034de":"## Compute predictions and build submission process","73b490ac":"First of all, we must properly handle the material our model will have to deal with for training. Training images are located in `'..\/input\/petfinder-pawpularity-score\/train\/'`. Let's check some attributes of the images, such as their count, and their size.","b814ab8a":"This second notebook goes further and explores neural networks with Keras. This time I'll use image data only.\n\n**Objectives**\n\n1. Import image data\n2. Prepare data for feeding a neural network\n3. Build, train and evaluate a Keras neural network\n4. Submit results for ranking","6f3e29c9":"### Data handlers","c0675d7c":"# A First Neural Network Using Keras","0f6fb530":"## Enable GPU"}}