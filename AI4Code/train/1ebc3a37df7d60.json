{"cell_type":{"5139204a":"code","004b50c7":"code","57288ad6":"code","e50229da":"code","d4ecebd8":"code","27259d5a":"code","ef116b4e":"code","8963962b":"code","9d354d40":"code","771432ef":"code","18c588d5":"code","7882e357":"code","e53463ae":"code","b27561be":"markdown","fb9ef1cc":"markdown","05a681c2":"markdown","21610832":"markdown","d4eb3428":"markdown","2afb1ed4":"markdown","d82cd659":"markdown","df7f667a":"markdown","c9e85fd4":"markdown","96a5f43d":"markdown"},"source":{"5139204a":"import pandas as pd\nfrom scipy.stats import rankdata\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nimport numpy as np\nimport sklearn \nimport os\nfrom sklearn import model_selection\nfrom sklearn import metrics","004b50c7":"class Config:\n    vocab_size = 20000\n    batch_size = 256\n    epochs = 50\n    labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n       'identity_hate']\n    label_weights = [1, 2, 2, 5, 1, 2]\n    ouput_dataset_path = \"..\/input\/tfidf-vectorization-with-keras-output\"\n    best_acc_path = \"model_best_acc.tf\"\n    best_auc_path = \"model_best_auc.tf\"\n    best_loss_path = \"model_best_loss.tf\"\n    latest_path = \"model_latest.tf\"\n    model_paths = [best_acc_path, best_auc_path, latest_path, best_loss_path]\n    modes = [\"training\", \"inference\"]\n    mode = modes[0]\nconfig = Config()","57288ad6":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\ndf = df.rename(columns={'comment_text': 'text'})\ndf.head()","e50229da":"X = df[\"text\"]\ntext_vectorizer = layers.TextVectorization(max_tokens=config.vocab_size, output_mode=\"tf-idf\", ngrams=2)\n# Index the bigrams and learn the TF-IDF weights via `adapt()`\nwith tf.device(\"CPU\"):\n    # A bug that prevents this from running on GPU for now.\n    text_vectorizer.adapt(X)","d4ecebd8":"y = df[config.labels]\ny.describe()","27259d5a":"sample = text_vectorizer(X[0:config.batch_size])\nsample.shape","ef116b4e":"model = keras.Sequential([\n        keras.Input(shape=(None, ), dtype=\"string\"),\n        text_vectorizer,\n        layers.Dense(256, activation=\"relu\", kernel_regularizer=\"l2\"),\n        layers.Dense(32, activation=\"relu\", kernel_regularizer=\"l2\"),\n        layers.Dense(len(config.labels), activation=\"sigmoid\")\n    ])\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"categorical_accuracy\", keras.metrics.AUC()])\nmodel.summary()","8963962b":"keras.utils.plot_model(model)","9d354d40":"X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","771432ef":"if config.mode == config.modes[0]:\n    model_best_acc_checkpoint = keras.callbacks.ModelCheckpoint(config.best_acc_path, save_best_only=True, save_weights_only=True, monitor=\"val_categorical_accuracy\")\n    model_best_auc_checkpoint = keras.callbacks.ModelCheckpoint(config.best_auc_path, save_best_only=True, save_weights_only=True, monitor=\"val_auc\")\n    model_best_loss_checkpoint = keras.callbacks.ModelCheckpoint(config.best_loss_path, save_best_only=True, save_weights_only=True, monitor=\"val_loss\")\n    reduce_lr = keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n    model.fit(X_train, y_train, epochs=config.epochs, batch_size=config.batch_size, validation_data=(X_val, y_val), callbacks=[model_best_acc_checkpoint, model_best_auc_checkpoint, model_best_loss_checkpoint, reduce_lr])\n    model.save_weights(config.latest_path)","18c588d5":"def evaluate(model, model_path, X_val, y_val):\n    print(\"Evaluation of %s\"%(model_path))\n    path = model_path\n    if config.mode == config.modes[1]:\n        path = os.path.join(config.ouput_dataset_path, path)\n    model.load_weights(path)\n    result = np.array(model.predict(X_val) > 0.5, dtype=int)\n    for i in range(len(config.labels)):\n        cls_report = metrics.classification_report(y_val[config.labels[i]], result[:, i])\n        print(\"Classification Report of %s\"%config.labels[i])\n        print(cls_report)","7882e357":"for path in config.model_paths:\n    evaluate(model, path, X_val, y_val)","e53463ae":"scores = []\ndf_sub = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\nfor path in [config.best_acc_path, config.best_auc_path, config.latest_path, config.best_loss_path]:\n    if config.mode == config.modes[1]:\n        path = os.path.join(config.ouput_dataset_path, path)\n    model.load_weights(path)\n    score = model.predict(df_sub[\"text\"], batch_size=config.batch_size)\n    score = np.sum(score * np.array(config.label_weights), axis=1)\n    scores.append(score)\nscore = np.mean(scores, axis=0)\ndf_sub['score'] = rankdata(score, method='ordinal')\ndf_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)\ndf_sub.head()","b27561be":"## TF-IDF vectorization","fb9ef1cc":"# Submission","05a681c2":"## Model Development","21610832":"## Prepare the data\n","d4eb3428":"The output of the vectorizer:","2afb1ed4":"# TF-IDF Vectorization with Keras\n\n\nThanks for the notebook from \n- https:\/\/www.kaggle.com\/julian3833\/jigsaw-incredibly-simple-naive-bayes-0-768 \n- https:\/\/www.kaggle.com\/steubk\/jrsotc-ridgeregression\n\n[julian3833](https:\/\/www.kaggle.com\/julian3833) and [steubk](https:\/\/www.kaggle.com\/steubk) both show a good way of TF-IDF Vectorization with SKLearn Models such as Ridge Regression and Naive Bayes. Recently I was thinking of a way to use TF-IDF vectorization with Keras, so that we can work with different kinds of Neural Network,  luckily I find a way to do it with keras `TextVectorization` layer.\n\nI will also build a multi-label classification Model and train with all labels from [Toxic Comment Classification Challenge](https:\/\/www.kaggle.com\/c\/jigsaw-toxic-comment-classification-challenge). After training, I will use the Model to predict probability of all labels and multiply them with weights to generate a final result for calcuate ranking of toxicity.\n\nI am also keeping several models and use their final results to calcuate final score.","d82cd659":"## Train Validation Split","df7f667a":"## Model Evluation\n","c9e85fd4":"\n<font color=\"red\" size=\"5\">If you found it useful and would like to back me up, just upvote.<\/font>\n\n","96a5f43d":"## Model Training"}}