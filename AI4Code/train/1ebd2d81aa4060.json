{"cell_type":{"b57dc498":"code","082430b2":"code","d8ee73a3":"code","f628aa19":"code","cad7da80":"code","14076f4d":"code","84f614a4":"code","d462aa8a":"code","f428a5fa":"code","a51bc626":"code","3429e3e8":"code","90d8f910":"code","b96dea17":"code","c6fa35db":"code","28525961":"code","4882a7eb":"code","94caaf46":"code","e7e5efd7":"code","50064a4f":"code","b1b1fbeb":"code","d47e5b2d":"code","eb2b85ac":"code","87d20718":"code","19502630":"code","a4a743d3":"code","74724a15":"code","8f11f1c0":"code","9d0955e1":"code","e345c5f7":"code","629e4707":"code","f8c9f147":"code","09357e54":"code","eca6beda":"code","cecafd13":"code","71d8b66c":"code","336e2326":"code","bda14503":"code","6b25781c":"code","b93327d8":"markdown","4c837609":"markdown","4b8bdbdd":"markdown","42fcb6ae":"markdown","504d2bfc":"markdown"},"source":{"b57dc498":"import os\nimport random\nfrom shutil import copyfile\n\nimport pathlib\nimport PIL\nimport PIL.Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow_hub as hub","082430b2":"# path of all bricks images\ndataset_path = '\/kaggle\/input\/lego-brick-images\/dataset\/'\n\nworking_dataset_path = '\/kaggle\/working\/dataset\/'\nif not os.path.exists(working_dataset_path):\n    os.mkdir(working_dataset_path)\n    print(\"Created the working directory at: \", working_dataset_path)\nelse:\n    print(\"working path already existing\")\n\nTOT_IMAGES = 40000\nNUM_CLASSES = 50","d8ee73a3":"data_dir = pathlib.Path(dataset_path)\n\n# counting the total images\nimage_count = len(list(data_dir.glob('*.png')))\nprint(\"total image found: \", image_count)\nif image_count != TOT_IMAGES:\n    print(\"Warning: some images may be missing, n. of images found are: \", image_count)\n\n# printing a random image\nbricks = list(data_dir.glob('*.png'))\nrand_num = random.randint(1, TOT_IMAGES - 1)\nPIL.Image.open(str(bricks[7]))","f628aa19":"# get the code of a brick given the file name\n# TL;DR the code is always the first string in the splitted name of the file \n\ndef get_code(file_name):\n    words = file_name.split()\n    code = words[0]\n    if code.isnumeric():\n        return code\n    return None","cad7da80":"# creating a list of unique brick codes\n\nbrick_codes = set()\nfor file_name in os.listdir(dataset_path):\n    file_path = os.path.join(dataset_path, file_name)\n    if not os.path.isfile(file_path):\n        continue\n    code = get_code(file_name)\n    if code is not None:\n        brick_codes.add(code)\n        \n#brick_codes\n","14076f4d":"# check that the number of codes found is the number of classes indicated by the author\nif len(brick_codes) != NUM_CLASSES:\n    print(\"Warning: brick codes count is less than the number of\" +\n          \" classes indicated by the author\")\nelse:\n    print(\"Brick codes count correspond to the\" +\n          \" number of classes indicated by the author\")","84f614a4":"# Create a directory for every brick code, aka every class, aka every lego type\n\nfor code in brick_codes:\n    if not os.path.exists(working_dataset_path + code):\n        os.mkdir(working_dataset_path + code)\n    \n# check if directories are created    \nworking_dirs = []\nfor file_name in os.listdir(working_dataset_path):\n    file_path = os.path.join(working_dataset_path, file_name)\n    if os.path.isdir(file_path):\n        working_dirs.append(file_path)\n\nif len(working_dirs) != NUM_CLASSES:\n    print(\"Warning: there are less directories than classes\")\nelse:\n    print(\"Directories and classes match\")\n    \n#working_dirs","d462aa8a":"# adding every brick to the corresponding directory\n\nfor file_name in os.listdir(dataset_path):\n    file_path = os.path.join(dataset_path, file_name)\n\n    if os.path.isdir(file_path):\n        continue\n        \n    code = get_code(file_name)\n    if code is None:\n        continue\n    if code not in brick_codes:\n        print(\"found an unexisting code\")\n        continue\n    # create the file in the working directory with the same name\n    new_file_path = working_dataset_path + code + \"\/\" + file_name\n    with open(new_file_path, 'w') as f:\n        pass\n    # copy the file into working directory\n    copyfile(file_path, new_file_path)\n    \n# check if working directories have files\nrandom_code = '14719'\nrandom_dir = os.listdir(working_dataset_path + random_code)\n#print(random_dir)","f428a5fa":"batch_size = 32\nimg_height = 224\nimg_width = 224\n\nval_split = 0.2","a51bc626":"# training dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    working_dataset_path,\n    validation_split=val_split,\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)","3429e3e8":"# validation dataset\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    working_dataset_path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)","90d8f910":"from tensorflow.keras import layers\n\nnormalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\n\ntrain_normalized = train_ds.map(lambda x, y: (normalization_layer(x), y))\nval_normalized = val_ds.map(lambda x, y: (normalization_layer(x), y))","b96dea17":"# check that normalization went well\nimage_batch, labels_batch = next(iter(train_normalized))\nfirst_image = image_batch[0]\nprint(np.min(first_image), np.max(first_image))\n\nimage_batch, labels_batch = next(iter(val_normalized))\nfirst_image = image_batch[0]\nprint(np.min(first_image), np.max(first_image))","c6fa35db":"NUM_ITER = 9\nclass_names = train_ds.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(NUM_ITER):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","28525961":"URL = \"https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b0\/feature-vector\/1\"\n\nfeature_extractor = hub.KerasLayer(\n    URL, \n    input_shape=(img_height, img_width, 3), \n    trainable=False\n)\n\nb0_model = tf.keras.Sequential([\n  feature_extractor,\n  tf.keras.layers.Dense(NUM_CLASSES)\n])\n\nb0_model.summary()","4882a7eb":"b0_model.compile(\n  optimizer='adam', \n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\nEPOCHS = 10\n\nb0_history = b0_model.fit(train_normalized,\n                    epochs=EPOCHS,\n                    validation_data=val_normalized )","94caaf46":"batch_size = 32\nimg_height = 380\nimg_width = 380\n\nval_split = 0.2","e7e5efd7":"# training dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    working_dataset_path,\n    validation_split=val_split,\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)","50064a4f":"# validation dataset\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    working_dataset_path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size\n)","b1b1fbeb":"from tensorflow.keras import layers\n\nnormalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\n\ntrain_normalized = train_ds.map(lambda x, y: (normalization_layer(x), y))\nval_normalized = val_ds.map(lambda x, y: (normalization_layer(x), y))","d47e5b2d":"# check that normalization went well\nimage_batch, labels_batch = next(iter(train_normalized))\nfirst_image = image_batch[0]\nprint(np.min(first_image), np.max(first_image))\n\nimage_batch, labels_batch = next(iter(val_normalized))\nfirst_image = image_batch[0]\nprint(np.min(first_image), np.max(first_image))","eb2b85ac":"URL = \"https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b4\/feature-vector\/1\"\n\nfeature_extractor = hub.KerasLayer(\n    URL, \n    input_shape=(img_height, img_width, 3), \n    trainable=False\n)\n\nb4_model = tf.keras.Sequential([\n  feature_extractor,\n  tf.keras.layers.Dense(NUM_CLASSES)\n])\n\nb4_model.summary()","87d20718":"b4_model.compile(\n  optimizer='adam', \n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n\nEPOCHS = 10\n\nb4_history = b4_model.fit(\n    train_normalized,\n    epochs=EPOCHS,\n    validation_data=val_normalized\n)","19502630":"val_labels = []\n\nfor images, labels in val_ds.take(-1):\n    for i in range(32):\n        val_labels.append(labels[i])\n        \nprint(len(val_labels))\n#print(val_labels)","a4a743d3":"print(type(val_labels[0]))","74724a15":"predicted_batch = b0_model.predict(val_ds)\npredicted_batch = tf.squeeze(predicted_batch).numpy()\npredicted_ids = np.argmax(predicted_batch, axis=-1)","8f11f1c0":"print(\"lunghezza delle predizioni\", len(predicted_ids))\nprint(\"lunghezza delle labels\", len(val_labels))\n\nif len(predicted_ids) != len(val_labels):\n  print(\"WARNING: labels and images does not correpsond in length\")","9d0955e1":"epochs_range = range(EPOCHS)","e345c5f7":"def plot_accuracy(accuracy, validation_accuracy, epochs_range):\n    plt.figure(figsize=(8, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, accuracy, label='Training Accuracy')\n    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n    plt.show()","629e4707":"def plot_loss(loss, validation_loss, epochs_range):\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()","f8c9f147":"import seaborn as sns\ndef plot_confusion_matrix(model):\n    confusion_mtx = tf.math.confusion_matrix(val_labels, predicted_ids) \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(confusion_mtx, annot=True, fmt='g')\n    plt.xlabel('Prediction')\n    plt.ylabel('Label')\n    plt.show()","09357e54":"accuracy = b0_history.history['accuracy']\nvalidation_accuracy = b0_history.history['val_accuracy']\n\nplot_accuracy(accuracy, validation_accuracy, epochs_range)","eca6beda":"loss = b0_history.history['loss']\nvalidation_loss = b0_history.history['val_loss']\n\nplot_loss(loss, validation_loss, epochs_range)","cecafd13":"plot_confusion_matrix(b0_model)","71d8b66c":"accuracy = b4_history.history['accuracy']\nvalidation_accuracy = b4_history.history['val_accuracy']\n\nplot_accuracy(accuracy, validation_accuracy, epochs_range)","336e2326":"loss = b4_history.history['loss']\nvalidation_loss = b4_history.history['val_loss']\n\nplot_loss(loss, validation_loss, epochs_range)","bda14503":"print(len(validation_loss))\nprint(validation_loss[5:])","6b25781c":"plot_confusion_matrix(b4_model)","b93327d8":"# EFFICIENTNET B0","4c837609":"# B0 accuracy measures","4b8bdbdd":"# B4 accuracy measures","42fcb6ae":"# EFFICIENTNET B4","504d2bfc":"## From the loss figure\nYou can note that the validation loss is decreasing rapidly in the last stages. Maybe with more hours of training we can gain better results"}}