{"cell_type":{"7220c8d1":"code","bfea92fb":"code","3b8fa8af":"code","59b33a64":"code","d7acd6b0":"code","358b6644":"code","20b9d337":"code","463f69cc":"code","cfd33d45":"code","8a321e61":"code","879be0d9":"code","1b7a3cd8":"code","9022809d":"code","df3d7634":"code","c9942589":"code","8c67cec6":"code","567f0fef":"code","91e6e12b":"code","b01741a3":"code","63e28401":"code","8fe4712d":"code","0fdf9ff0":"code","c146c30e":"code","5ebab907":"code","a34d29cd":"code","e5151326":"code","2fae6c8b":"code","975e4f9b":"code","65881dd3":"markdown","10e6274b":"markdown","d17e4ede":"markdown","438479e9":"markdown","ad780841":"markdown","bb36e38d":"markdown","b7470839":"markdown","189be18e":"markdown","50ec5547":"markdown","b21ab084":"markdown","b8377180":"markdown","106dac96":"markdown","3d120b23":"markdown","35f79532":"markdown","2439c6f8":"markdown","97522261":"markdown","8660a123":"markdown","9d9df8a0":"markdown","b3f9aae8":"markdown","b001bd83":"markdown","fcb9c7ce":"markdown","ff0cbd00":"markdown","266b0029":"markdown","a31f0f7f":"markdown","ff2b1c9b":"markdown","6de4d928":"markdown","206afa2a":"markdown","d54af095":"markdown","3aad4055":"markdown","4ebbb5a4":"markdown","f45b21db":"markdown","bb2eab37":"markdown","f03a21a5":"markdown","88ea338e":"markdown","955aa41d":"markdown","89ab683d":"markdown","2866729a":"markdown","9568c3c0":"markdown","d904a118":"markdown","3b449748":"markdown","fd55fb4a":"markdown","edb1a931":"markdown"},"source":{"7220c8d1":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder","bfea92fb":"data1 = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv') [:500]","3b8fa8af":"X1 = data1.drop(['Outcome'], axis=1)\n\ny1 = data1['Outcome']","59b33a64":"from sklearn.model_selection import train_test_split\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.3, random_state = 0)","d7acd6b0":"X_train1.shape, X_test1.shape","358b6644":"cols1 = X_train1.columns","20b9d337":"scaler = StandardScaler()\n\nX_train1 = scaler.fit_transform(X_train1)\n\nX_test1 = scaler.fit_transform(X_test1)","463f69cc":"X_train1 = pd.DataFrame(X_train1, columns=[cols1])","cfd33d45":"X_train1.head()","8a321e61":"X_test1 = pd.DataFrame(X_test1, columns=[cols1])","879be0d9":"X_test1.head()","1b7a3cd8":"# Regresi Logistik\nlogreg = LogisticRegression()\n# SVM\nsvm = SVC(probability=True)\n# Naive Bayes\nnb = GaussianNB()","9022809d":"logreg.fit(X_train1, y_train1)\nsvm.fit(X_train1, y_train1)\nnb.fit(X_train1, y_train1)","df3d7634":"y_pred1_logreg = logreg.predict(X_test1)\ny_pred1_svm = svm.predict(X_test1)\ny_pred1_nb = nb.predict(X_test1)","c9942589":"print('---------------  Regresi Logistik  -------------------')\nprint(classification_report(y_test1, y_pred1_logreg))\nprint('--------------------- SVM ----------------------------')\nprint(classification_report(y_test1, y_pred1_svm))\nprint('--------------------- NB  ----------------------------')\nprint(classification_report(y_test1, y_pred1_nb))","8c67cec6":"data2 = pd.read_excel('..\/input\/datasettbml\/tb1MLBank.xlsx')[:200]","567f0fef":"le = LabelEncoder()\ndata2['job'] = le.fit_transform(data2['job'])\ndata2['marital'] = le.fit_transform(data2['marital'])\ndata2['y'] = le.fit_transform(data2['y'])","91e6e12b":"X2 = data2[['age', 'balance', 'day', 'duration', 'campaign', 'job', 'marital']]\n\ny2 = data2['y']","b01741a3":"from sklearn.model_selection import train_test_split\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.3, random_state = 0)","63e28401":"X_train2.shape, X_test2.shape","8fe4712d":"scaler = StandardScaler()\n\nX_train2 = scaler.fit_transform(X_train2)\n\nX_test2 = scaler.fit_transform(X_test2)","0fdf9ff0":"X_train2 = pd.DataFrame(X_train2, columns=[cols2])","c146c30e":"X_train2.head()","5ebab907":"X_test2 = pd.DataFrame(X_test2, columns=[cols2])","a34d29cd":"X_test2.head()","e5151326":"logreg.fit(X_train2, y_train2)\nsvm.fit(X_train2, y_train2)\nnb.fit(X_train2, y_train2)","2fae6c8b":"y_pred2_logreg = logreg.predict(X_test2)\ny_pred2_svm = svm.predict(X_test2)\ny_pred2_nb = nb.predict(X_test2)","975e4f9b":"print('---------------  Regresi Logistik  -------------------')\nprint(classification_report(y_test2, y_pred2_logreg))\nprint('--------------------- SVM ----------------------------')\nprint(classification_report(y_test2, y_pred2_svm))\nprint('--------------------- NB  ----------------------------')\nprint(classification_report(y_test2, y_pred2_nb))","65881dd3":"# Predict Dataset","10e6274b":"# Deklarasi data \/ Memilih Parameter","d17e4ede":"# Fitting Model","438479e9":"# DATASET 1","ad780841":"# Normalisasi","bb36e38d":"Cek bentuk data fitur dataset 1. Didapatkan data pada data latih atau X_train sebanyak 350 row data dan pada data uji atau X_test sebanyak 150 row data dengan jumlah kolom atau parameter variable fitur yang sama yaitu 8.","b7470839":"# Split Data","189be18e":"**fitting dataset 2 dengan model**","50ec5547":"Deklarasi variable fitur dan target dataset ke 1. Dimana saya menghapus kolom Outcome pada variable fitur dan memasukkan kolom Outcome pada variable target.","b21ab084":"# DATASET 2","b8377180":"# Prediksi data test","106dac96":"**Import library yang dibutuhkan**","3d120b23":"# Report Hasil AKurasi","35f79532":"**split data training dan testing dataset 1**\n\nPada proses membagi data latih dan data uji ini saya menggunakan persentase untuk data uji sebesar 30% dari keseluruhan dataset","2439c6f8":"**Klasifikasi report dataset 2**","97522261":"**fitting dataset 1 dengan model**","8660a123":"Normalisasi data menggunaka Scaler dataset 1","9d9df8a0":"deklarasi variable fitur dan target dataset ke 2. Dimana saya memilih 7 kolom yaitu kolom age, balance, day, duration, campaign, job dan marital pada variable fitur dan memasukkan kolom y pada variable target.","b3f9aae8":"Pada proses ini saya melakukan melatih model Machine Learning yang akan digunakan yaitu Regresi Logistik yang disimpan pada variable logreg, Support Vector Machine yang disimpan pada variable svm dan Naive Bayes yang disimpan pada variable nb dengan cara memanggil proses yang sebelumnya sudah di import menggunakan sklearn.","b001bd83":"Pada proses ini melakukan proses prediksi yang kemudian hasilnya disimpan pada variable y_pred2","fcb9c7ce":"**Normalisasi data menggunaka Scaler datastet 2**","ff0cbd00":"**Baca data**\n\nPada proses ini saya menggunakan pandas untuk membaca dataset ke-2 yaitu dataset bank-marketing yang selanjutnya disimpan pada variable data1 dan saya hanya menggunakan 200 data teratas.","266b0029":"# Melatih Model","a31f0f7f":"# Deklarasi \/ Memilih Parameter 2","ff2b1c9b":"Dari ke-2 Dataset diatas dan pengujian menggunakan 3 model algoritma didapatkan hasil akurasi terbaik yaitu dengan menggunakan model algortima Regresi Logistik.","6de4d928":"# Split data","206afa2a":"Pada proses ini saya melakukan percobaan membandingkan 3 Model Algoritma Machine Learning yaitu Regresi Logistik, Support Vector Machine dan Naive Bayes dimana dalam proses pengujian ini juga saya menggunakan 2 dataset yaitu dataset pima indian diabetse dan bank marketing. ","d54af095":"Normalisasi data menggunaka Scaler dataset 1","3aad4055":"**Predicting dataset 2 dengan memasukkan X_test2**","4ebbb5a4":"> Didapatkan hasil akurasi terbaik yaitu dengan menggunakan model algoritma Regresi Logistik yaitu sebesar 80%","f45b21db":"Cek bentuk data fitur dataset 1. Didapatkan data pada data latih atau X_train sebanyak 140 row data dan pada data uji atau X_test sebanyak 60 row data dengan jumlah kolom atau parameter variable fitur yang sama yaitu 7.","bb2eab37":"**Cek bentuk data fitur dataset 2**","f03a21a5":"Pada proses ini melakukan proses prediksi yang kemudian hasilnya disimpan pada variable y_pred1","88ea338e":"**Baca data**\n\nPada proses ini saya menggunakan pandas untuk membaca dataset ke-1 yaitu dataset pima indian diabestes yang selanjutnya disimpan pada variable data1 dan saya hanya menggunakan 500 data teratas.","955aa41d":"# Report Hasil Akurasi","89ab683d":"Pada proses ini dilakukan encode pada data object\/string menjadi integer.","2866729a":"**Encode data menjadi numerik**","9568c3c0":"Pada proses membagi data latih dan data uji ini saya menggunakan persentase untuk data uji sebesar 30% dari keseluruhan dataset","d904a118":"> Didapatkan hasil akurasi terbaik yaitu dengan menggunakan model algoritma Regresi Logistik yaitu sebesar 85%","3b449748":"# Fitting Model 2","fd55fb4a":"**Klasifikasi report dataset 1**","edb1a931":"**Split data training dan testing dataset 2**"}}