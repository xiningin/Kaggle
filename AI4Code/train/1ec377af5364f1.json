{"cell_type":{"4d788752":"code","0c418371":"code","575aead4":"code","a20ec6f8":"code","e92eac05":"code","7132b57b":"code","1d002b0b":"code","7c137fca":"code","919ecb3d":"code","8191118d":"code","0c279952":"code","d6a9c05b":"code","40248f63":"code","7d741338":"code","9f783198":"code","61f39e6b":"code","201fd996":"code","3be28e6e":"code","13d131c5":"code","ee2c589e":"code","95d43a5d":"code","f997478f":"code","c00ee533":"code","5322e0b4":"code","8579ea4b":"code","562943a5":"code","2f734269":"code","2151c94e":"code","e7b8b9e4":"code","037c64b3":"code","563a0aea":"code","59c0848f":"code","44ce7e29":"code","1eeb7a8e":"code","9abcd9ac":"code","eba6b9dd":"code","b50e021a":"code","a0f21a76":"code","f9f954a2":"code","69911a84":"code","c62f8f1b":"code","5f1f726e":"code","55c27713":"code","cfce1baf":"code","b56235fc":"markdown","e4fe9578":"markdown","50b26912":"markdown","197a43b6":"markdown","34e6d306":"markdown","0b9b3081":"markdown","63105005":"markdown","9f929e8d":"markdown","8c7b5041":"markdown","605b3ccf":"markdown","0f74601a":"markdown","5f27b2d9":"markdown","54c5cd23":"markdown","35677b7d":"markdown","2f5fc149":"markdown","dab96615":"markdown","3b9e782a":"markdown","2448e7ee":"markdown","fc33bb0a":"markdown","e8c16b5b":"markdown","ebd63ea0":"markdown","8e0f7550":"markdown","0e164307":"markdown","c0f3c0b8":"markdown","1bbbf617":"markdown","4b2320a8":"markdown","e6401363":"markdown","b6bec606":"markdown","61f22184":"markdown","855bfea5":"markdown","6d8a4e58":"markdown","a1a111b5":"markdown","f9532996":"markdown","b8737e8c":"markdown","e96c1bbe":"markdown","9b2e0f06":"markdown","4cc82e38":"markdown","a9b28acf":"markdown","7cb65e36":"markdown","e4a885d6":"markdown","373b1cde":"markdown","75beeb21":"markdown","c8c82d15":"markdown","ad42c2dd":"markdown","2fba5ec8":"markdown","57482427":"markdown","b56eb870":"markdown","8d5f9d18":"markdown","290e81e0":"markdown","cf2203f7":"markdown","81af8f0c":"markdown","e158c2e4":"markdown","1fbd9700":"markdown","220a6f6d":"markdown","059c62a3":"markdown","933bfb92":"markdown","733ab56a":"markdown","51bc4286":"markdown","44952678":"markdown","87fd3466":"markdown","3ffe9802":"markdown","3e1f6a50":"markdown","effefc54":"markdown","e42927bc":"markdown","b4d47724":"markdown","372d941a":"markdown","55efe4a3":"markdown","cfcbfe52":"markdown","70f1cc46":"markdown","6f02a23c":"markdown","91a40b21":"markdown","d35aebc9":"markdown","989249e9":"markdown","d9046410":"markdown","5fe77c6a":"markdown","daaaba83":"markdown","96723a9c":"markdown","35b6762d":"markdown","0f66b846":"markdown","3ec3ec04":"markdown","f4f1c699":"markdown","74dfe7b7":"markdown","d5ced6a3":"markdown","7cf63067":"markdown","05eddf6f":"markdown","37478976":"markdown","2d188943":"markdown","0fb16d9f":"markdown","296a7952":"markdown","feb5e034":"markdown","c0292af2":"markdown","d810b992":"markdown","db0c5037":"markdown","f5ceadc6":"markdown","a3cb396c":"markdown","47e4ba6f":"markdown","a1617dc1":"markdown","a0df082a":"markdown","03a6d85c":"markdown","dc6ff820":"markdown","557712e1":"markdown","84009aec":"markdown","413cb1c1":"markdown","35a2e1ee":"markdown","eed6cac1":"markdown"},"source":{"4d788752":"#Import packages\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = 20, 15\nplt.style.use('seaborn')\n%matplotlib inline\nsns.set()","0c418371":"# Draw 1,000 samples from uniform & plot results\nx = np.random.rand(1000)\nplt.hist(x);","575aead4":"# Computed how many people click\nclicks = x <= 0.5\nn_clicks = sum(clicks)\nf\"Number of clicks = {n_clicks}\"","a20ec6f8":"# Computed proportion of people who clicked\nf\"Proportion who clicked = {n_clicks\/len(clicks)}\"","e92eac05":"# Solution\nclicks = x <= 0.7\nn_clicks = sum(clicks)\nprint(f\"Number of clicks = {n_clicks}\")\nprint(f\"Proportion who clicked = {n_clicks\/len(clicks)}\")","7132b57b":"# Import and view head of data\ndf_12 = pd.read_csv('..\/input\/darwin-scandens-finches-beaks\/finch_beaks_2012.csv')\ndf_12.head()","1d002b0b":"# Store lengths in a pandas series\nlengths = df_12['blength']","7c137fca":"p = (sum(lengths > 10))\/len(lengths)\np","919ecb3d":"df_12.info()","8191118d":"n_samples = 10000\nsum(np.random.choice(lengths, n_samples, replace=True) > 10)\/n_samples","0c279952":"# Set seed\nnp.random.seed(seed=16071982)\n\n# Simulate one run of flipping the biased coin 10 times\nnp.random.binomial(10, 0.7)","d6a9c05b":"# Simulate 1,000 run of flipping the biased coin 10 times\nx = np.random.binomial(10, 0.3, 10000)\n\n# Plot normalized histogram of results\nplt.hist(x, density=True, bins=10);","40248f63":"np.unique(x[:10000],return_counts=True)","7d741338":"# Solution\nsum(np.random.binomial(20, 0.3, 10000) >= 5)\/10000","9f783198":"sum(np.random.binomial(20,0.5,10000) >= 5)\/10000","61f39e6b":"# Plot histogram \nx = np.random.binomial(10, 0.5, 10000)\nplt.hist(x, density=True, bins=10);","201fd996":"def ecdf(data):\n    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n    # Number of data points\n    n = len(data)\n\n    # x-data for the ECDF\n    x = np.sort(data)\n\n    # y-data for the ECDF\n    y = np.arange(1, n+1) \/ n\n\n    return x, y","3be28e6e":"# Generate x- and y-data for the ECDF\nx_flips, y_flips = ecdf(x)\n\n# Plot the ECDF\nplt.plot(x_flips, y_flips, marker='.', linestyle='none');","13d131c5":"N = 10**3 #number of points\n\n# Generate x, y coordinates\nx = np.random.uniform(-1,1, N)\ny = np.random.uniform(-1,1, N)\n\n# Calculate pi\n4*sum(x**2 + y**2 <= 1)\/N\n","ee2c589e":"a = x**2 + y**2 <= 1\na.shape, x.shape, y.shape","95d43a5d":"df = pd.DataFrame({'x': x, 'y': y})\ndf.plot.scatter(x='x', y='y');","f997478f":"df_sub = df[df.x**2 + df.y**2 <= 1]\ndf_sub.plot.scatter(x='x', y='y');","c00ee533":"for _ in range(0, 10000):\n    x = np.random.binomial(1, 0.5, 1000) - 0.5\n    t = np.cumsum(x)\n    if (t > 0).all():\n        plt.plot(t, alpha=0.1)","5322e0b4":"# Generate Poisson-distributed data\nsamples  =  np.random.poisson(6, size=10**6)\n\n# Plot histogram\nplt.hist(samples, bins=21);","8579ea4b":"# Generate x- and y-data for the ECDF\nx_p, y_p = ecdf(samples)\n\n# Plot the ECDF\nplt.plot(x_p, y_p, marker='.', linestyle='none');","562943a5":"fga = [19, 16, 15, 20, 20, 11, 15, 22, 34, 17, 20, 24, 14, 14, \n       24, 26, 14, 17, 20, 23, 16, 11, 22, 15, 18, 22, 23, 13, \n       18, 15, 23, 22, 23, 18, 17, 22, 17, 15, 23, 8, 16, 25, \n       18, 16, 17, 23, 17, 15, 20, 21, 10, 17, 22, 20, 20, 23, \n       17, 18, 16, 25, 25, 24, 19, 17, 25, 20, 20, 14, 25, 26, \n       29, 19, 16, 19, 18, 26, 24, 21, 14, 20, 29, 16, 9]","2f734269":"# Generate x & y data for ECDF\nx_ecdf, y_ecdf = ecdf(fga)","2151c94e":"# Number of times we simulate the model\nn_reps = 1000\n\n# Plot ECDF of data\nplt.plot(x_ecdf, y_ecdf, '.', color='black');\n\n# Plot ECDF of model\nfor _ in range(n_reps):\n    samples = np.random.poisson(np.mean(fga), size=len(fga))\n    x_theor, y_theor = ecdf(samples)\n    plt.plot(x_theor, y_theor, '.', alpha=0.01, color='lightgray');\n\n\n# Label your axes\nplt.xlabel('field goal attempts')\nplt.ylabel('ECDF')","e7b8b9e4":"# Load nuclear power accidents data & create array of inter-incident times\ndf = pd.read_csv('..\/input\/scipy-for-beginners-data\/data\/nuclear_power_accidents.csv')\ndf.Date = pd.to_datetime(df.Date)\ndf = df[df.Date >= pd.to_datetime('1974-01-01')]\ninter_times = np.diff(np.sort(df.Date)).astype(float) \/ 1e9 \/ 3600 \/ 24","037c64b3":"# Compute mean and sample from exponential\nmean = np.mean(inter_times)\nsamples = np.random.exponential(mean, size=10**6)\n\n# Compute ECDFs for sample & model\nx, y = ecdf(inter_times)\nx_theor, y_theor = ecdf(samples)","563a0aea":"# Plot sample & model ECDFs\nplt.plot(x_theor, y_theor);\nplt.plot(x, y, marker='.', linestyle='none');","59c0848f":"# Load data, plot histogram \nimport scipy.stats as st\ndf = pd.read_csv('..\/input\/scipy-for-beginners-data\/data\/michelson_speed_of_light.csv')\ndf = df.rename(columns={'velocity of light in air (km\/s)': 'c'})\nc = df.c.values\nx_s = np.linspace(299.6, 300.1, 400) * 1000\nplt.plot(x_s, st.norm.pdf(x_s, c.mean(), c.std(ddof=1)))\nplt.hist(c, bins=9, density=True)\nplt.xlabel('speed of light (km\/s)')\nplt.ylabel('PDF')","44ce7e29":"# Get speed of light measurement + mean & standard deviation\nmichelson_speed_of_light = df.c.values\nmean = np.mean(michelson_speed_of_light)\nstd = np.std(michelson_speed_of_light, ddof=1)\n\n# Generate normal samples w\/ mean,  std of data\nsamples = np.random.normal(mean, std, size=10000)\n\n# Generate data ECDF & model CDF\nx, y = ecdf(michelson_speed_of_light)\nx_theor, y_theor = ecdf(samples)\n\n# Plot data & model (E)CDFs\n_ = plt.plot(x_theor, y_theor)\n_ = plt.plot(x, y, marker='.', linestyle='none')\n_ = plt.xlabel('speed of light (km\/s)')\n_ = plt.ylabel('CDF')","1eeb7a8e":"# Solution: Calculate P(A,B)\nx_0 = np.random.binomial(2, 0.5, 10000)\np_ab = sum(x_0==2)\/len(x_0)\nplt.hist(x_0);\nprint(p_ab)","9abcd9ac":"# Solution: Calculate P(A)P(B)\nx_1 = np.random.binomial(1, 0.5, 10000)\nx_2 = np.random.binomial(1, 0.5, 10000)\np_a = sum(x_1 == 1)\/len(x_1)\np_b = sum(x_2 == 1)\/len(x_2)\np_a*p_b","eba6b9dd":"# Calculate P(A)P(B) of two birds having beak lengths > 10\np_a = (sum(lengths > 10))\/len(lengths)\np_b = (sum(lengths > 10))\/len(lengths)\np_a*p_b","b50e021a":"# Calculate P(A)P(B) using resampling methods\nn_samples = 100000\np_a = sum(np.random.choice(lengths, n_samples, replace=True) > 10)\/n_samples\np_b = sum(np.random.choice(lengths, n_samples, replace=True) > 10)\/n_samples\np_a*p_b","a0f21a76":"# Calculate P(A,B) using resampling methods\nn_samples = 100000\nsamples = np.random.choice(lengths, (n_samples,2), replace=True)\n_ = samples > (10, 10)\np_ab = sum(np.prod(_, axis=1))\/n_samples\np_ab","f9f954a2":"sum(df_12.blength > 10)\/len(df_12)","69911a84":"df_fortis = df_12.loc[df_12['species'] == 'fortis']\nsum(df_fortis.blength > 10)\/len(df_fortis)","c62f8f1b":"df_scandens = df_12.loc[df_12['species'] == 'scandens']\nsum(df_scandens.blength > 10)\/len(df_scandens)","5f1f726e":"# Take 10,000 subjects\nn = 100000\n# Sample for number of users, non-users\nusers = np.random.binomial(n, 0.005, 1) \nnon_users = n - users","55c27713":"# How many of these users tested +ve ?\nu_pos = np.random.binomial(users, 0.99)\n# How many of these non-users tested +ve ?\nnon_pos = np.random.binomial(non_users, 0.01)","cfce1baf":"# how many of those +ve tests were for users?\nu_pos\/(u_pos+non_pos)","b56235fc":"From Bayes Theorem, \n\n$$P(user|+) = \\frac{P(+|user)P(user)}{P(+)}$$\n\n","e4fe9578":"You can also calculate such proportions with real-world data. Here we import a dataset of Finch beak measurements from the Gal\u00e1pagos islands. You can find the data [here](https:\/\/datadryad.org\/resource\/doi:10.5061\/dryad.9gh90).","50b26912":"### Hands on example: drug testing","197a43b6":"**Homework exercise for the avid learner:** verify the above relationship using simulation\/resampling techniques in one of the cases above.","34e6d306":"## Learning Objectives of Part 1","0b9b3081":"You can see from the ECDF that LeBron's field goal attempts per game are ~ Poisson distributed.","63105005":"#### Example: conditional probability for birds","9f929e8d":"## Hands-on","8c7b5041":"## 2. Simulating probabilities","605b3ccf":"The proportion of people who clicked can be calculated as the total number of clicks over the number of people:","0f74601a":"### Empirical cumulative distribution functions (ECDFs)","5f27b2d9":"What type of random phenomena are we talking about here? One example is:\n\n- Knowing that a website has a click-through rate (CTR) of 10%, we can calculate the probability of having 10 people, 9 people, 8 people ... and so on click through, upon drawing 10 people randomly from the population;\n- But given the data of how many people click through, how can we calculate the CTR? And how certain can we be of this CTR? Or how likely is a particular CTR?\n\nScience mostly asks questions of the second form above & Bayesian thinking provides a wonderful framework for answering such questions. Essentially Bayes' Theorem gives us a way of moving from the probability of the data given the model (written as $P(data|model)$) to the probability of the model given the data ($P(model|data)$).\n\nWe'll first explore questions of the 1st type using simulation: knowing the model, what is the probability of seeing certain data?","54c5cd23":"### Bayes Theorem solves the above drug testing problem\n\nBayes Theorem can be used to analytically derive the solution to the 'drug testing' example above as follows.","35677b7d":"**Discussion**: Did you get the same answer as your neighbour? If you did, why? If not, why not?","2f5fc149":"* What proportion of birds have a beak length > 10 ?","dab96615":"- If I flip a biased coin ($P(H)=0.3$) 20 times, what is the probability of 5 or more heads?","3b9e782a":"### Conditional Probability","2448e7ee":"In fact, the Poisson distribution is the limit of the Binomial distribution for low probability of success and large number of trials, that is, for rare events. ","fc33bb0a":"**Task:** Interpret the results of your simulations.","e8c16b5b":"## Exponential distribution","ebd63ea0":"### Example 2: Investors, coincidences, and survivorship bias","8e0f7550":"### A proxy for probability\n\nAs stated above, we have calculated a proportion, not a probability. As a proxy for the probability, we can simulate drawing random samples (with replacement) from the data seeing how many lengths are > 10 and calculating the proportion (commonly referred to as [hacker statistics](https:\/\/speakerdeck.com\/jakevdp\/statistics-for-hackers)):","0e164307":"**Note:** In order to use such simulation and _hacker statistics_ approaches to \"prove\" results such as the above, we're gliding over several coupled and deep technicalities. This is in the interests of the pedagogical nature of this introduction. For the sake of completeness, we'll mention that we're essentially\n- Using the proportion in our simulations as a proxy for the probability (which, although Frequentist, is useful to allow you to start getting your hands dirty with probability via simluation).\n\nHaving stated this, for ease of instruction, we'll continue to do so when thinking about joint & conditional probabilities of both simulated and real data. ","c0f3c0b8":"Enter the ECDF.","1bbbf617":"### Joint Probability","4b2320a8":"**Question:** \n* Looking at the histogram, can you tell me the probability of seeing 4 or more heads?","e6401363":"- Plot the normalized histogram of number of heads of the following experiment: flipping a fair coin 10 times.","b6bec606":"### Poisson processes and the Poisson distribution","61f22184":"___\n\nIn the above, we saw that we could match data-generating processes with binary outcomes to the story of the binomial distribution.\n\n> The Binomial distribution's story is as follows: the number $r$ of successes in $n$ Bernoulli trials with probability $p$ of success, is Binomially distributed. \n\nThere are many other distributions with stories also!","855bfea5":"Plot the ECDF for the previous hands-on  exercise. Read the answer to the following question off the ECDF: the probability of seeing 4 or more heads?","6d8a4e58":"The number of arrivals of a Poisson process in a given amount of time is Poisson distributed. The Poisson distribution has one parameter, the average number of arrivals in a given length of time. So, to match the story, we could consider the number of hits on a website in an hour with an average of six hits per hour. This is Poisson distributed.","a1a111b5":"This section is explicitly taken from the great work of Justin Bois. You can find more [here](https:\/\/github.com\/justinbois\/dataframed-plot-examples\/blob\/master\/lebron_field_goals.ipynb).","f9532996":"We see that the data is close to being Exponentially distributed, which means that we can model the nuclear incidents as a Poisson process.","b8737e8c":"Generate the x and y values for the ECDF of LeBron's field attempt goals.","e96c1bbe":"## An Aside on Monte Carlo Simulations!","9b2e0f06":"### HANDS-ON: joint probability for birds","4cc82e38":"To then simulate the sampling from the population, we check whether each float was greater or less than 0.5. If less than or equal to 0.5, we say the person clicked.","a9b28acf":"> Monte Carlo methods, or Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. -- [Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Monte_Carlo_method)","7cb65e36":"### Another way to simulate coin-flips","e4a885d6":"### Galapagos finch beaks","373b1cde":"## 1. Probability","75beeb21":"Plot the ECDF of the Poisson-distributed data that you generated above.","c8c82d15":"### HANDS-ON: JOINT PROBABILITY COIN FLIPPING","ad42c2dd":"* Calculate the joint probability using the resampling method, that is, by drawing random samples (with replacement) from the data. First calculate $P(A)P(B)$:","2fba5ec8":"Verify that $P(A,B)=P(A)P(B)$ in the two fair coin-flip case (A=heads, B=heads) by \n- first simulating two coins being flipped together and calculating the proportion of occurences with two heads;\n- then simulating one coin flip and calculating the proportion of heads and then doing that again and multiplying the two proportions.\n\nYour two calculations should give \"pretty close\" results and not the same results due to the (in)accuracy of simulation. ","57482427":"**Question:** Does this look like anything to you?","b56eb870":"Calculating this explicitly yields\n\n$$P(user|+) = \\frac{0.99\\times 0.005}{0.99\\times 0.005 + 0.01\\times 0.995} = 0.332 $$","8d5f9d18":"### Hands-on: more clicking","290e81e0":"1. What is the probability of a finch beak having depth > 10 ?\n2. What if we know the finch is of species 'fortis'?\n3. What if we know the finch is of species 'scandens'?","cf2203f7":"To show that this LeBron's attempts are ~ Poisson distributed, you're now going to plot the ECDF and compare it with the the ECDF of the Poisson distribution that has the mean of the data (technically, this is the maximum likelihood estimate).","81af8f0c":"An ECDF is, as an alternative to a histogram, a way to visualize univariate data that is rich in information. It allows you to visualize all of your data and, by doing so, avoids the very real problem of binning.\n- can plot control plus experiment\n- data plus model!\n- many populations\n- can see multimodality (though less pronounced) -- a mode becomes a point of inflexion!\n- can read off so much: e.g. percentiles.\n\nSee Eric Ma's great post on ECDFS [here](https:\/\/ericmjl.github.io\/blog\/2018\/7\/14\/ecdfs\/) AND [this twitter thread](https:\/\/twitter.com\/allendowney\/status\/1019171696572583936) (thanks, Allen Downey!).\n\nSo what is  this ECDF? \n\n**Definition:** In an ECDF, the x-axis is the range of possible values for the data & for any given x-value, the corresponding y-value is the proportion of data points less than or equal to that x-value.","e158c2e4":"To see this, think about the stories. Picture this: you're doing a Bernoulli trial once a  minute for an hour, each with a success probability of 0.05. We would do 60 trials, and the number of successes is Binomially distributed, and we would expect to get about 3 successes. This is just like the Poisson story of seeing 3 buses on average arrive in a given interval of time. Thus the Poisson distribution with arrival rate equal to np approximates a Binomial distribution for n Bernoulli trials with probability p of success (with n large and p small). This is useful because the Poisson distribution can be simpler to work with as it has only one parameter instead of two for the Binomial distribution.","1fbd9700":"Consider two shapes: (1) a circle with radius 1 and centre the origin and (2) a square with the same diameter around the circle. Notice two things:\n- The area of the circle is $\\pi$\n- The area of the square is $4$\nThis means that the $\\pi$ is equal to 4 times the area of the circle divided by the area of the circle. \n\nSo: if we randomly populate the square with points and then count what fraction of them are in the circle (and multiply the result by 4), we'll be able to approximate $\\pi$. So let's do it!","220a6f6d":"Let's define a handy ECDF function that takes in data and outputs $x$ and $y$ data for the ECDF.","059c62a3":"_Discussion point_: This model is known as the bias coin flip. \n- Can you see why?\n- Can it be used to model other phenomena?","933bfb92":"## 3. PROBABILITY DISTRIBUTIONS AND THEIR STORIES","733ab56a":"**Note:** These proportions are definitely different. We can't say much more currently but we'll soon see how to use hypothesis testing to see what else we can say about the differences between the species of finches.","51bc4286":"Coming up: from Bayes Theorem to Bayesian Inference!","44952678":"**Note:** you may have noticed that the _binomial distribution_ can take on only  a finite number of values, whereas the _uniform distribution_ above can take on any number between $0$ and $1$. These are different enough cases to warrant special mention of this & two different names: the former is called a _probability mass function_ (PMF) and the latter a _probability distribution function_ (PDF). Time permitting, we may discuss some of the subtleties here. If not, all good texts will cover this. I like (Sivia & Skilling, 2006), among many others.\n","87fd3466":"In the book [Information Theory, Inference and Learning Algorithms](https:\/\/www.amazon.com\/Information-Theory-Inference-Learning-Algorithms\/dp\/0521642981) David MacKay tells the tale of a town called Poissonville, in which the buses have an odd schedule. Standing at a bus stop in Poissonville, the amount of time you have to wait for a bus is totally independent of when the previous bus arrived. This means you could watch a bus drive off and another arrive almost instantaneously, or you could be waiting for hours.\n\nArrival of buses in Poissonville is what we call a Poisson process. The timing of the next event is completely independent of when the previous event happened. Many real-life processes behave in this way. \n\n* natural births in a given hospital (there is a well-defined average number of natural births per year, and the timing of one birth is independent of the timing of the previous one);\n* Landings on a website;\n* Meteor strikes;\n* Molecular collisions in a gas;\n* Aviation incidents.\n\nAny process that matches the buses in Poissonville **story** is a Poisson process.\n\n    ","3ffe9802":"* Let's say that a website has a CTR of 50%, i.e. that 50% of people click through. If we picked 1000 people at random from the population, how likely would it be to find that a certain number of people click?\n\nWe can simulate this using `numpy`'s random number generator.\n\nTo do so, first note we can use `np.random.rand()` to randomly select floats between 0 and 1 (known as the _uniform distribution_). Below, we do so and plot a histogram:","3e1f6a50":"In the spirit of this workshop, it's now time to harness your computational power and the intuition of simulation to solve this drug testing example. \n\n* Before doing so, what do you think the answer to the question _\"What is the probability that a randomly selected individual with a positive test is a drug user?\"_ is? Write down your guess.","effefc54":"Let's first remind ourselves of the story behind the Poisson distribution.\n> The number of arrivals of a Poisson processes in a given set time interval is Poisson distributed.\n\nTo quote Justin Bois:\n\n> We could model field goal attempts in a basketball game using a Poisson distribution. When a player takes a shot is a largely stochastic process, being influenced by the myriad ebbs and flows of a basketball game. Some players shoot more than others, though, so there is a well-defined rate of shooting. Let's consider LeBron James's field goal attempts for the 2017-2018 NBA season.","e42927bc":"The normal distribution, also known as the Gaussian or Bell Curve, appears everywhere. There are many reasons for this. One is the following:\n\n> When doing repeated measurements, we expect them to be normally distributed, owing to the many subprocesses that contribute to a measurement. This is because (a formulation of the Central Limit Theorem) **any quantity that emerges as the sum of a large number of subprocesses tends to be Normally distributed** provided none of the subprocesses is very broadly distributed.\n\nNow it's time to see if this holds for the measurements of the speed of light in the famous Michelson\u2013Morley experiment:","b4d47724":"**One of the coolest things:** Bayes Theorem can be proved with a few lines of mathematics. Your instructor will do this on the chalk\/white-board now.","372d941a":"**Credit:** Thank you to [Justin Bois](http:\/\/bois.caltech.edu\/) for countless hours of discussion, work and collaboration on thinking about probability distributions and their stories. All of the following is inspired by Justin & his work, if not explicitly drawn from.","55efe4a3":"Some of you may ask but is the data really normal? I urge you to check out Allen Downey's post [_Are your data normal? Hint: no._ ](http:\/\/allendowney.blogspot.com\/2013\/08\/are-my-data-normal.html)","cfcbfe52":"## Hands-on","70f1cc46":"**Discussion**: What you have been able to do here is to solve the following problem: you knew $P(+|user)=0.99$, but you were trying to figure out $P(user|+)$. Is the answer what you expected? If not, why not? \n\nIf you were surprised at the answer, that's not too surprising: you've experienced the [base rate fallacy](https:\/\/en.wikipedia.org\/wiki\/Base_rate_fallacy). The base rate of 99% true positive may lead one to think that most positive tests will be of users, however the vast majority of the overall population are non-users, which means that there will be more that test positive incorrectly than one would otherwise expect.\n\n**Key note:** This is related to the serious scientific challenge posed at the beginning here: if you know the underlying parameters\/model, you can figure out the distribution and the result, but often we have only the experimental result and we're trying to figure out the most appropriate model and parameters.\n\nIt is Bayes' Theorem that lets us move between these.","6f02a23c":"We have already encountered joint probabilities above, perhaps without knowing it: $P(A,B)$ is the probability two events $A$ and $B$ _both_ occurring.\n* For example, getting two heads in a row.\n\nIf $A$ and $B$ are independent, then $P(A,B)=P(A)P(B)$ but be warned: this is not always (or often) the case.\n\nOne way to think of this is considering \"AND\" as multiplication: the probability of A **and** B is the probability of A **multiplied** by the probability of B.","91a40b21":"This means that if an individual tests positive, there is still only a 33.2% chance that they are a user! This is because the number of non-users is so high compared to the number of users.","d35aebc9":"**Question:** Suppose that a test for using a particular drug has 99% sensitivity (true positive rate) and 99% specificity (true negative rate), that is, a 1% false positive rate and 1% false negative rate. Suppose that 0.5% (5 in 1,000) of people are users of the drug. What is the probability that a randomly selected individual with a positive test is a drug user?\n\n**If we can answer this, it will be really cool as it shows how we can move from knowing $P(+|user)$ to $P(user|+)$, a MVP for being able to move from $P(data|model)$ to $P(model|data)$.**","989249e9":"**Note:** Although, in the above, we have described _probability_ in two ways, we have not described it mathematically. We're not going to do so rigorously here, but we will say that _probability_ defines a function from the space of possibilities (in the above, the interval $[0,1]$) that describes how likely it is to get a particular point or region in that space. Mike Betancourt has an elegant [Introduction to Probability Theory (For Scientists and Engineers)](https:\/\/betanalpha.github.io\/assets\/case_studies\/probability_theory.html) that I can recommend.","d9046410":"Any process that matches the coin flip story is a Binomial process (note that you'll see such coin flips also referred to as Bernoulli trials in the literature).  So we can also formulate the story of the Binomial distribution as\n\n> the number $r$ of successes in $n$ Bernoulli trials with probability $p$ of success, is Binomially distributed. ","5fe77c6a":"## 4. Joint Probability & Conditional Probability","daaaba83":"As you may have guessed, it is Bayes' Theorem that will allow us to move back and forth between $P(data|model)$ and $P(model|data)$. As we have seen, $P(model|data)$ is usually what we're interested in as data scientists yet $P(data|model)$ is what we can easily compute, either by simulating our model or using analytic equations.","96723a9c":"In the above, you have used the uniform distribution to sample from a series of biased coin flips. I want to introduce you to another distribution that you can also use to do so: the **binomial distribution**.\n\nThe **binomial distribution** with parameters $n$ and $p$ is defined as the probability distribution of\n\n> the number of heads seen when flipping a coin $n$ times when  with $p(heads)=p$.","35b6762d":"We've encountered a variety of named _discrete distributions_. There are also named _continuous distributions_, such as the exponential distribution and the normal (or Gaussian) distribution. To see what the story of the exponential distribution is, let's return to Poissonville, in which the number of buses that will arrive per hour are Poisson distributed.\nHowever, the waiting time between arrivals of a Poisson process are exponentially distributed.\n\nSo: the exponential distribution has the following story: the waiting time between arrivals of a Poisson process are exponentially distributed. It has a single parameter, the mean waiting time. This distribution is not peaked, as we can see from its PDF.\n\nFor an illustrative example, lets check out the time between all incidents involving nuclear power since 1974. It's a reasonable first approximation to expect incidents to be well-modeled by a Poisson process, which means the timing of one incident is independent of all others. If this is the case, the time between incidents should be exponentially distributed.\n\n\nTo see if this story is credible, we can plot the ECDF of the data with the CDF that we'd get from an exponential distribution with the sole parameter, the mean, given by the mean inter-incident time of the data.\n","0f66b846":"## Example Poisson distribution: field goals attempted per game","3ec3ec04":"- If I flip a fair coin 20 times, what is the probability of 5 or more heads?","f4f1c699":"### Example 1: Estimating $\\pi$\n\n","74dfe7b7":"**Note** that this distribution essentially tells the **story** of a general model in the following sense: if we believe that they underlying process generating the observed data has a binary outcome (affected by disease or not, head or not, 0 or 1, clicked through or not), and that one the of the two outcomes occurs with probability $p$, then the probability of seeing a particular outcome is given by the **binomial distribution** with parameters $n$ and $p$.","d5ced6a3":"# What is probability? A simulated introduction","7cf63067":"What is the probability that two randomly selected birds have beak depths over 10 ?","05eddf6f":"* Group chat: what do you see in the above?","37478976":"**Note:** This is the proportion of birds that have beak length $>10$ in your empirical data, not the probability that any bird drawn from the population will have beak length $>10$.","2d188943":"### Joint and conditional probabilities\n\nConditional and joint probabilites are related by the following:\n$$ P(A,B) = P(A|B)P(B)$$","0fb16d9f":"We can expand the denominator here into \n\n$$P(+)  = P(+,user) + P(+,non-user) $$\n\nso that\n\n$$ P(+)=P(+|user)P(user) + P(+|non-user)P(non-user)$$\n\nand \n\n$$P(user|+) = \\frac{P(+|user)P(user)}{P(+|user)P(user) + P(+|non-user)P(non-user)}$$.","296a7952":"Use random sampling to simulate how many people click when the CTR is 0.7. How many click? What proportion?","feb5e034":"## HANDS ON","c0292af2":"> Let us use the Monte Carlo \ngenerator introduced earlier and construct a population of 10,000 \nfictional investment managers... Assume that they each have a perfectly fair \ngame; each one has a 50% probability of making 10,000 at the end of \nthe year, and a 50% probability of losing 10,000. Let us introduce an \nadditional restriction; once a manager has a single bad year, he is \nthrown out of the sample, good-bye and have a nice life. The Monte Carlo generator will toss a coin; heads and the manager will make 10,000 over the year, tails and he will lose 10,000. We run it for the first year. At the end of the year, we expect 5,000 managers to \nbe up 10,000 each, and 5,000 to be down 10,000. Now we run the game a second year. Again, we can expect 2,500 managers to be up two years in a row; another year, 1,250; a fourth one, 625; a fifth, 313. \nWe have now, simply in a fair game, 313 managers who made money for five years in a row. Out of pure luck. -- [Fooled by Randomness](https:\/\/en.wikipedia.org\/wiki\/Fooled_by_Randomness), Nassim Nicholas Taleb","d810b992":"### Normal distribution","db0c5037":"Below, I'll plot the histogram with a Gaussian curve fitted to it. Even if that looks good, though, that could be due to binning bias. SO then you'll plot the ECDF of the data and the CDF of the model!","f5ceadc6":"- To have an understanding of what \"probability\" means, in both Bayesian and Frequentist terms;\n- To be able to simulate probability distributions that model real-world phenomena;\n- To understand how probability distributions relate to data-generating **stories**;\n- To understand and be able to simulate joint probabilities and conditional probabilities;\n- To understand Bayes' Theorem and its utility.","a3cb396c":"### Simulating many times to get the distribution\n\nIn the above, we have simulated the scenario once. But this only tells us one potential outcome. To see how likely it is to get $n$ heads, for example, we need to simulate it a lot of times and check what proportion ended up with $n$ heads.","47e4ba6f":"**Up for discussion:** Let's say that all you had was this data and you wanted to figure out the CTR (probability of clicking). \n\n* What would your estimate be?\n* Bonus points: how confident would you be of your estimate?","a1617dc1":"Now we'll draw samples out of a Poisson distribution to get the theoretical ECDF (that is, simulating the model), plot it with the ECDF of the data and see how they look.","a0df082a":"> To the pioneers such as Bernoulli, Bayes and Laplace, a probability represented a _degree-of-belief_ or plausibility; how much they thought that something was true, based on the evidence at hand. To the 19th century scholars, however, this seemed too vague and subjective an idea to be the basis of a rigorous mathematical theory. So they redefined probability as the _long-run relative frequency_ with which an event occurred, given (infinitely) many repeated (experimental) trials. Since frequencies can be measured, probability was now seen as an objective tool for dealing with _random_ phenomena.\n\n-- _Data Analysis, A Bayesian Tutorial_, Sivia & Skilling (p. 9)","03a6d85c":"Now calculate $P(A,B)$:","dc6ff820":"First thing's first, the data ([from here](https:\/\/www.basketball-reference.com\/players\/j\/jamesle01\/gamelog\/2018)):","557712e1":"Now that we have a grasp on joint probabilities, lets consider conditional probabilities, that is, the probability of some $A$, knowing that some other $B$ is true. We use the notation $P(A|B)$ to denote this. For example, you can ask the question \"What is the probability of a finch beak having depth $<10$, knowing that the finch is of species 'fortis'?\"","84009aec":"## HANDS ON","413cb1c1":"## Hands-on","35a2e1ee":"We'll now use the binomial distribution to answer the same question as above:\n* If P(heads) = 0.7 and you flip the coin ten times, how many heads will come up?\n\nWe'll also set the seed to ensure reproducible results.","eed6cac1":"## 5. Bayes' Theorem\n\n$$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$$"}}