{"cell_type":{"be740c9d":"code","5afb1717":"code","48e5494a":"code","e7a1f0a0":"code","2097c5ac":"code","5a168341":"code","8bb4ffb2":"code","f3ceb67d":"code","97981a59":"code","96298d66":"code","e434853a":"code","b904ffa9":"code","27a982ea":"code","3a7df9e7":"code","a0a83dfe":"code","fd8ff342":"code","7d99ce35":"code","d3e6ebe1":"code","98c1b005":"code","4975124e":"code","f6b61486":"code","a4e58d1d":"code","f6740def":"code","70798750":"code","8fe770dc":"code","d9b874d0":"code","a403b3eb":"code","44a0f9ba":"code","b9fec6d8":"code","743ab877":"code","8a2ccdd4":"code","16bc3537":"code","9c23ab21":"code","c624e0ef":"code","d9ffae08":"code","623bfcdc":"code","f4008c4a":"code","4718a7fe":"code","deebb3c7":"code","705fc64e":"code","b498152e":"code","d4a3ef05":"code","406307c5":"code","99160ea8":"code","198bc90a":"code","1d00efeb":"code","e3a61b4f":"code","fca7b923":"code","aed22d58":"code","2e1c4439":"code","cf1e5e24":"code","4bd7efd9":"code","59027020":"code","efee0336":"code","321ec5ee":"code","15c1977d":"code","3d6f752b":"code","e09ef9ff":"code","5a9cd7e5":"code","1a480b87":"code","840288ba":"code","20eac910":"code","eace9761":"code","53dcd795":"code","996dec0f":"code","dea4fc3c":"code","862a2227":"code","2b098abd":"code","719de654":"code","2506d9a8":"code","47997e87":"markdown","5e8f0ac0":"markdown","f9a2aa05":"markdown","2576ab5d":"markdown","1a9fdb59":"markdown","14b6d42c":"markdown","500cf9b2":"markdown","693d9a91":"markdown","e7406c93":"markdown","12eae46e":"markdown","c44bce51":"markdown","8680f78b":"markdown","236341c8":"markdown","2bdaab0a":"markdown","914a2c56":"markdown","a7a8235b":"markdown","49c0c1f0":"markdown","6755e2cc":"markdown","dbb63572":"markdown","40c8dea7":"markdown","e38176c4":"markdown","5fd2514a":"markdown","009e3f23":"markdown","60b4f949":"markdown","11718c51":"markdown","6918322a":"markdown","1782d09b":"markdown","b1203348":"markdown","973b510c":"markdown","1aacb2b1":"markdown","9231efe6":"markdown","9704c860":"markdown","9faa6885":"markdown","9e8601d6":"markdown","4f350b11":"markdown","ecd9e886":"markdown","c2f03f56":"markdown","37438e34":"markdown","0c93d046":"markdown","78d466f3":"markdown","7dadcb50":"markdown","11029208":"markdown","2a4dd1d8":"markdown","f813e5cd":"markdown","e722b609":"markdown","d9dfb3b7":"markdown","810554ba":"markdown","febe37cc":"markdown","36ee75bb":"markdown","d0181146":"markdown"},"source":{"be740c9d":"#Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport chardet\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","5afb1717":"# Check the character encoding of the file might be.\nwith open('..\/input\/bike-sharing-dataset\/day.csv', 'rb') as rawdata:\n    result = chardet.detect(rawdata.read())\n    \nprint(result)","48e5494a":"#reading loan.csv in loan dataframe\nday_df =  pd.read_csv('..\/input\/bike-sharing-dataset\/day.csv', encoding = 'ascii')","e7a1f0a0":"# Check the head of the dataset\nday_df.head()","2097c5ac":"#Inspect the various aspects of the housing dataframe\nday_df.info()","5a168341":"day_df.describe()","8bb4ffb2":"#Dropping the 'instant' column\nday_df = day_df.drop(['instant', 'casual', 'registered','dteday'], axis = 1)","f3ceb67d":"#Converting season from continuous variable to categorical variable.\nday_df['season'] = day_df['season'].map({1:'spring', 2:'summer', 3:'fall', 4:'winter'})","97981a59":"#converting 'weathersit' from continuous variable to categorical variable.\nday_df['weathersit'] = day_df['weathersit'].map({1:'clear', 2:'mist', 3:'light_snow', 4:'heavy_rain'})","96298d66":"#converting 'mnth' from continuous variable to categorical variable.\nday_df['mnth'] = day_df['mnth'].map({1:'January', 2:'February', 3:'March', 4:'April', 5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'})","e434853a":"#Plotting pair plots aganist cnt for all numerical variables\nplt.figure(figsize=(15,10))\nsns.pairplot(day_df, x_vars = ['yr','holiday', 'weekday', 'workingday'], y_vars = 'cnt')\nsns.pairplot(day_df, x_vars = ['temp','atemp','hum','windspeed'], y_vars = 'cnt')\nplt.show()","b904ffa9":"#plotting box plot for each of the Categorical variables\nplt.figure(figsize=(20, 15))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'season', y = 'cnt', data = day_df)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = day_df)\nplt.subplot(3,3,3)\nsns.boxplot(x = 'yr', y = 'cnt', data = day_df)\nplt.subplot(3,3,4)\nsns.boxplot(x = 'mnth', y = 'cnt', data = day_df)\nplt.subplot(3,3,5)\nsns.boxplot(x = 'holiday', y = 'cnt', data = day_df)\nplt.subplot(3,3,6)\nsns.boxplot(x = 'weekday', y = 'cnt', data = day_df)\nplt.subplot(3,3,7)\nsns.boxplot(x = 'workingday', y = 'cnt', data = day_df)\nplt.show()","27a982ea":"#visualising 'season' and 'holiday' columns parallely\nplt.figure(figsize = (10, 5))\nsns.boxplot(x = 'season', y = 'cnt', hue = 'holiday', data = day_df)\nplt.show()","3a7df9e7":"#dropping 'weekday' column\nday_df = day_df.drop('weekday', axis = 1)","a0a83dfe":"day_df.head()","fd8ff342":"# Get the dummy variables for the feature 'season' and store it in a new variable - 'status'\nstatus = pd.get_dummies(day_df['season'])","7d99ce35":"# Check what the dataset 'status' looks like\nstatus.value_counts()","d3e6ebe1":"# Let's drop the first column from status df using 'drop_first = True'\nstatus = pd.get_dummies(day_df['season'], drop_first = True)","98c1b005":"# Add the results to the original day_df dataframe\nday_df = pd.concat([day_df, status], axis = 1)","4975124e":"# Drop 'season' as we have created the dummies for it\nday_df.drop(['season'], axis = 1, inplace = True)","f6b61486":"# Get the dummy variables for the feature 'weathersit' and store it in a new variable - 'status'\nstatus = pd.get_dummies(day_df['weathersit'])","a4e58d1d":"# Check what the dataset 'status' looks like\nstatus.value_counts()","f6740def":"# Let's drop the first column from status df using 'drop_first = True'\nstatus = pd.get_dummies(day_df['weathersit'], drop_first = True)","70798750":"# Add the results to the original day_df dataframe\nday_df = pd.concat([day_df, status], axis = 1)","8fe770dc":"# Drop 'weathersit' as we have created the dummies for it\nday_df.drop(['weathersit'], axis = 1, inplace = True)","d9b874d0":"day_df","a403b3eb":"# Get the dummy variables for the feature 'mnth' and store it in a new variable - 'status'\nstatus = pd.get_dummies(day_df['mnth'])\n#reordering the columns according to the months\nstatus = status[['January','February','March','April','May','June','July','August','September','October','November','December']]","44a0f9ba":"# Check what the dataset 'status' looks like\nstatus.value_counts()","b9fec6d8":"# Let's drop the first column from status i.e. January column\nstatus = status.drop(['January'], axis =1)","743ab877":"# Add the results to the original day_df dataframe\nday_df = pd.concat([day_df, status], axis = 1)","8a2ccdd4":"# Drop 'mnth' as we have created the dummies for it\nday_df.drop(['mnth'], axis = 1, inplace = True)","16bc3537":"day_df.info()","9c23ab21":"# specifying this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\nday_train, day_test = train_test_split(day_df, train_size = 0.7, test_size = 0.3, random_state = 100)","c624e0ef":"#shape of training data\nday_train.shape","d9ffae08":"#shape of test data\nday_test.shape","623bfcdc":"scaler = MinMaxScaler()","f4008c4a":"# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\nnum_vars = ['temp', 'atemp', 'hum', 'windspeed']\n\nday_train[num_vars] = scaler.fit_transform(day_train[num_vars])","4718a7fe":"day_train.head()","deebb3c7":"day_train.describe()","705fc64e":"# Let's check the correlation coefficients to see which variables are highly correlated\nplt.figure(figsize = (16, 10))\nsns.heatmap(day_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","b498152e":"#Splitting X and y for training data\ny_train = day_train.pop('cnt')\nX_train = day_train","d4a3ef05":"# Running RFE with the output number of the variable equal to 18\nlm = LinearRegression()\n\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 18)             # running RFE\nrfe = rfe.fit(X_train, y_train)","406307c5":"#checking the rank of each variables\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","99160ea8":"#selected cloumns for model building\ncol = X_train.columns[rfe.support_]\ncol","198bc90a":"#rejected columns for model building\nX_train.columns[~rfe.support_]","1d00efeb":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","e3a61b4f":"# Adding a constant variable  \nX_train_rfe = sm.add_constant(X_train_rfe)","fca7b923":"# Running the linear model\nlm = sm.OLS(y_train,X_train_rfe).fit()   ","aed22d58":"#Summary of the linear model\nprint(lm.summary())","2e1c4439":"#dropping 'atemp' and remining months column.\nX_train_new = X_train_rfe.drop(['atemp',  'March', 'April','May', 'June', 'October','August', 'September'], axis = 1)","cf1e5e24":"# Adding a constant variable \nX_train_lm = sm.add_constant(X_train_new)","4bd7efd9":"# Running the linear model again\nlm1 = sm.OLS(y_train,X_train_lm).fit()   ","59027020":"#Summary of the new linear model\nprint(lm1.summary())","efee0336":"#dropping 'const' column, to calculate VIF\nX_train_new = X_train_new.drop(['const'], axis=1)","321ec5ee":"# Calculate the VIFs for the new model\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","15c1977d":"#dropping 'hum' column\nX_train_new2 = X_train_new.drop(['hum'], axis = 1)","3d6f752b":"# Adding a constant variable \nX_train_lm2 = sm.add_constant(X_train_new2)","e09ef9ff":"# Running the linear model\nlm2 = sm.OLS(y_train,X_train_lm2).fit()   ","5a9cd7e5":"#Let's see the summary of our linear model\nprint(lm2.summary())","1a480b87":"# Calculate the VIFs for the new model\nvif = pd.DataFrame()\nX = X_train_new2\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","840288ba":"#dropping 'hum' column\nX_train_new3 = X_train_new2.drop(['summer'], axis = 1)\n\n# Adding a constant variable \nX_train_lm3 = sm.add_constant(X_train_new3)\n\n# Running the linear model\nlm3 = sm.OLS(y_train,X_train_lm3).fit()  \n\n#Let's see the summary of our linear model\nprint(lm3.summary())","20eac910":"# Calculate the VIFs for the new model\nvif = pd.DataFrame()\nX = X_train_new3\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","eace9761":"y_train_pred = lm3.predict(X_train_lm3)","53dcd795":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_pred), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)                         # X-label","996dec0f":"#Applying the scaling on the test sets\nnum_vars = ['temp', 'atemp', 'hum', 'windspeed']\n\nday_test[num_vars] = scaler.transform(day_test[num_vars])","dea4fc3c":"#Splitting X and y for test data\ny_test = day_test.pop('cnt')\nX_test = day_test","862a2227":"# Now let's use our model to make predictions.\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new3.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","2b098abd":"# Making predictions\ny_pred = lm3.predict(X_test_new)","719de654":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)  ","2506d9a8":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","47997e87":"Here, we can observe linear pattern in the above scatter plot.\n\nThe equation of our best fitted line is:\n\n$ cnt =  2355+ 2041 \\times yr - 775 \\times holiday + 3662 \\times temp - 1262 \\times windspeed - 1034 \\times spring + 407 \\times winter - 2452 \\times lightsnow - 659 \\times mist.$","5e8f0ac0":"Converting 'season' from continuous variable to categorical variable.\n\n1 = spring,\n\n2 = summer,\n\n3 = fall, \n\n4 = winter","f9a2aa05":"## Step 1:  Reading, Understanding and visualising the Data","2576ab5d":"### Observations from the Final Multilinear Regression Model:","1a9fdb59":"Checking the encoding for the day.csv file.","14b6d42c":"## Step 3: Building a linear model","500cf9b2":"Again there is no significant change in R-squared (0.823) and Adj. R-squared (0.820) from previous model's R-squared (0.827) and Adj. R-squared (0.824).","693d9a91":"Dropping first column, as we can identify seasons based on below columns:\n\n- `000` will correspond to `fall`\n- `010` will correspond to `summer`\n- `100` will correspond to `spring`\n- `001` will correspond to `winter`","e7406c93":"Here, we can observe that the error terms are normally distributed and centre of the normal distribution is 0. We can conclude that the assumption of linear regression are respected.\n\nSo, this model fit looks well. Now we can move ahead and make predictions on the test set.","12eae46e":"Dropping 'weekday' column as I have not observed any sigificant pattern in it.","c44bce51":"Applying the scaling on the test sets","8680f78b":"### Visualising Categorical Variables\n\n Let's make a boxplot for some of these variables.","236341c8":"Converting 'weathersit' from continuous variable to categorical variable.\n\n        - 1 : Clear, Few clouds, Partly cloudy, Partly cloudy\n\t\t- 2 : Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\t\t- 3 : Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n\t\t- 4 : Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n        \nMapping these to below values: (Just of convenience purpose, cutting short the values)\n\n        1 = clear\n\t\t2 = mist\n\t\t3 = light_snow\n\t\t4 = heavy_rain","2bdaab0a":"### Rescaling the Features ","914a2c56":"#### RFE\nI am using RFE (Recursive feature elimination) for feature selection.","a7a8235b":"Dropping first column, as we can identify 'weathersit' based on below columns:\n\n- `00` will correspond to `clear`\n- `01` will correspond to `mist  `\n- `10` will correspond to `light_snow `","49c0c1f0":"#### Importing libraries and reading csv files","6755e2cc":"Again, there is no significant change in R-squared (0.820) and Adj. R-squared (0.817) from previous model's R-squared (0.823) and Adj. R-squared (0.820).","dbb63572":"Now, all VIF all the available features are less than 5. But 'summer' has P-value of '0.008', so decided to drop the 'summer' column.","40c8dea7":"### Splitting the Data into Training and Testing Sets","e38176c4":"Now, all VIF all the available features are less than 5 and P-values for all features are fine.\n\nSo considering $lm3$ and final model with R-squared value of 0.820 for training data set.","5fd2514a":"Based on the above heat map, 'cnt' is highly correlated with 'temp', 'atemp' and 'yr'.","009e3f23":"### Building model using statsmodel, for the detailed statistics","60b4f949":"### Observations from Univariate and Bivariate analysis.\n\n1.\tThere are more user\u2019s uses the shared bicycle during fall and summer seasons and less users in spring and winter seasons. \n\n2.\tEven users tend to use more bicycles are used during \u201cClear, Few clouds, partly cloudy, partly cloudy\u201d weather, obviously people avoid using bicycle during rainy and snowy weather. \n\n3.\tThere is noticeable increase in the users in 2019 compared to 2018, we can say that the citizens are getting used to sharing bicycle service and business has increased. \n\n4.\tWe can observe that the shared bicycles are more likely to be used in July, August and September months as the Fall season comes during these months.  \n\n5.\tFrom \u2018holiday\u2019 plot we can say that the, people uses shared bicycle slightly more during non-holiday days, as people uses shared bicycle for office commuting. ","11718c51":"## Shared Bikes Dataset - Analysing Demand using Linear Regression\n\n### Problem Statement:\n\nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. \n\nEssentially, the company wants \u2014\n\n - Which variables are significant in predicting the demand for shared bikes.\n - How well those variables describe the bike demands\n \n \n The steps we are following in this assignments are as follows:\n\n \n    1. Reading, Understanding and visualising the Data\n    2. Preparing the data for modelling (train - test split, rescaling etc.)\n    3. Building a linear model\n    4. Residual Analysis of the train data\n    5. Predictions and evaluation on the test set ","6918322a":"### Visualising the Data\n\nLet'sVisualize and - **understanding the data**.\n- If there is some obvious multicollinearity going on, this is the first place to catch it\n- Here's where you'll also identify if some predictors directly have a strong association with the outcome variable","1782d09b":"We can observe that there are no outliers in the most of the feature, so using \u2018MinMaxScaler\u2019 for scaling the independent variables. ","b1203348":"There is not much change in R-squared (0.827) and Adj. R-squared (0.824) from previous model's R-squared (0.847) and Adj. R-squared (0.841).\n\nBased on the P-value, above features are okay to proceed. Let us calculate the VIF for these.","973b510c":"The R-squared value for test data set is '0.8015' which is good, by taking reference as R-squared value (0.820) of finally built model (lm3) using training data set. ","1aacb2b1":"### Dividing into X and Y sets for the model building","9231efe6":"1.\tThe R-squared value of final model is `0.820`. (training data set)\n\n2.\tThe R-squared value on is test data is `0.8015`.\n\n3.\t`Temperature(temp)` plays a vital role in customers opting shared bikes on that specific day with coefficient \u20183662\u2019.\n\n4.\tThe coefficient of `weathersit` - \u2018Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\u2019  is \u2018-2452\u2019, the usage of shared bike decreases during this time. Based on final model and bivariate analysis we can infer that the \u2018weathersit\u2019 - \u2018Clear, Few clouds, Partly cloudy, Partly cloudy\u2019 is suitable weather where customers prefer shared bike commuting. \n\n5.\tThe business has increased in the `year(yr)` 2019 compared to 2018 with coefficient \u20182041\u2019.\n\n6.\tThe coefficient of feature \u2018spring\u2019 is \u2018-1034\u2019. So spring `season` is not favourable to use shared bicycle service. Based on season \u2018count vs season\u2019 plot Fall and Summer are favourable seasons for shared bike service.\n","9704c860":"#### Reading loan csv file in a dataframe","9faa6885":"Rebuilding the model without 'atemp' and months columns","9e8601d6":"## Step 2: Preparing the data for modelling (train - test split, rescaling etc.)\n\n#### Dummy Variables","4f350b11":"Visualising the Numeric Variables\n\nLet's make a pairplot of all the numeric variables","ecd9e886":"Dropping first column, as we can identify 'mnth' based on below columns:\n\n- `00000000000`  will correspond to `January`\n- `10000000000`  will correspond to `February`\n- `01000000000`  will correspond to `March`\n- `00100000000`  will correspond to `April`\n- `00010000000` will correspond to `May`\n- `00001000000`  will correspond to `June`\n- `00000100000`  will correspond to `July`\n- `00000010000`  will correspond to `August`\n- `00000001000`  will correspond to `September`\n- `00000000100` will correspond to `October`\n- `00000000010` will correspond to `November`\n- `00000000001` will correspond to `December`","c2f03f56":"Here we can observe a linear relationship between \u2018temp\u2019(temperature) and count of shared bicycle usage. This will be helpful in our further model building process. ","37438e34":"The variable 'mnth' has 12 categories. Converting these into integer using dummy variables.","0c93d046":"No missing values.\n\nTarget variable (dependant variable) - 'cnt'.        ","78d466f3":"Converting 'mnth' from continuous variable to categorical variable.\n\n    1  = January\n    2  = February\n    3  = March\n    4  = April\n    5  = May\n    6  = June\n    7  = July\n    8  = August\n    9  = September\n    10 = October\n    11 = November\n    12 = December","7dadcb50":"#### Observations:\n\nHere, we can observe the that the\n\n1.\tThere are more user\u2019s uses the shared bicycle during fall and summer seasons and less users in spring and winter seasons.\n\n2.\tEven users tend to use more bicycles are used during \u201cClear, Few clouds, partly cloudy, partly cloudy\u201d weather, obviously people avoid using bicycle during rainy and snowy weather.\n\n3.\tThere is noticeable increase in the users in 2019 compared to 2018, we can say that the citizens are getting used to sharing bicycle service and business has increased. \n\n4.\tWe can observe that the shared bicycles are more likely to be used in July, August and September months as the Fall season comes during these months.\n\n5.\tFrom \u2018holiday\u2019 plot we can say that the, people uses shared bicycle slightly more during non-holiday days, as people uses shared bicycle for office commuting. \n","11029208":"### Checking VIF","2a4dd1d8":"The variable 'season' has 4 categories. Converting these into integer using dummy variables.","f813e5cd":"Here, 'hum'(27.02) and 'temp'(14.79) have the highest VIF which are greater than 5.\n\nSo, let us drop 'hum' first and build the model again.","e722b609":"## Step 5: Predictions and evaluation on the test set ","d9dfb3b7":"## Step 4: Residual Analysis of the train data","810554ba":"The variable 'weathersit' has 4 categories. Converting these into integer using dummy variables.","febe37cc":"Observed that column 'atemp' has 0.821 P-value which is pretty high, so dropping it.\n\nMost of the months are dropped by RFE, I think dropping remaining months will not make much difference for the model.","36ee75bb":"Found that the file is encoded in 'ascii' with 1.0 confidence","d0181146":"Dropping the 'instant' column as it is a index column.\n\nAlso dropping 'casual'  and 'registered' columns as these are sum of target variable 'cnt'."}}