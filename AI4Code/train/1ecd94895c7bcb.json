{"cell_type":{"e5b7ae06":"code","48f822a8":"code","68a39927":"code","07a5b96f":"code","9eba77ee":"code","3536ae01":"code","bf2a5872":"code","3f3a8ed8":"code","8197eec2":"code","407f7bcf":"code","a4c86be6":"code","fc7dd466":"code","2bc2c4be":"code","cbaaa46d":"code","5222a2bb":"code","9279f273":"code","cbbb76dc":"code","7d39fb80":"code","b2f2369f":"code","4c034bd3":"code","6365a4ec":"code","d2686871":"code","9e4b11a5":"code","2a1e26e0":"code","b80a7618":"code","6008e3c2":"code","c59f1ac0":"code","adab6b94":"code","421f8d88":"code","ff02b559":"markdown"},"source":{"e5b7ae06":"# Import libraries\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2","48f822a8":"IMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_CHANNELS=3\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nBATCH_SIZE = 6\nEPOCHS = 15\n\n# Root path\nROOT_PATH = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\n\n# 'train' path\nTRAIN = ROOT_PATH + 'train\/'\n\n# 'test' path\nTEST = ROOT_PATH + 'test\/'\n\n# 'validation' path\nVAL = ROOT_PATH + 'VAL\/'\nVAL_NORMAL = ROOT_PATH + \"val\/NORMAL\/\"\nVAL_SICK = ROOT_PATH + \"val\/PNEUMONIA\/\"","68a39927":"# Creating 'labels'\n\nlabel_names = ['NORMAL', 'PNEUMONIA']\nlabel_names_ = {label_names:i for i, label_names in enumerate(label_names)}\nlabel_names_","07a5b96f":"import cv2\nfrom skimage import io\n\n# .DS_Store is added due to certain reading problems while working with MacOS\n\n\ndef load_data():\n    \n    datasets = [TRAIN,\n               TEST]\n    \n    output = []\n    \n    for dataset in datasets:\n        print(\"Loading:\", dataset)\n        \n        images = []\n        labels = []\n        \n        for folder in os.listdir(dataset):\n            \n            if folder != '.DS_Store':\n\n\n                print(\"Folder:\", folder)\n                label = label_names_[folder]\n\n                for file in os.listdir(dataset + '\/' + folder):\n\n\n                        try:\n\n                            img_path = dataset + '\/' + folder + '\/' + file\n\n                            image = cv2.imread(img_path)\n                            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                            image = cv2.resize(image, IMAGE_SIZE)\n\n                            images.append(image)\n                            labels.append(label)\n\n\n\n                        except Exception as e:\n                            print(e, file)\n                \n            else:\n                continue\n               \n                \n        images = np.array(images, dtype='float32')\n        labels = np.array(labels, dtype='int32')\n        \n        output.append((images, labels))\n        \n    return output         \n","9eba77ee":"# Reading images: 'train' and 'test' \n\n(X_train, y_train), (X_test, y_test) = load_data()","3536ae01":"# Shuffle data\n\nfrom sklearn.utils import shuffle           \n\nX_train, y_train = shuffle(X_train, y_train, random_state=42)","bf2a5872":"# Let's see how the data looks\n\nprint(\"X_train:\", X_train.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_test:\", y_test.shape)","3f3a8ed8":"# How many labels of each kind are there in 'train'?\n\nprint(np.unique(y_train))\nprint(y_train.tolist().count(0))\nprint(y_train.tolist().count(1))","8197eec2":"# How many labels of each kind are there in 'test'?\n\nprint(np.unique(y_test))\nprint(y_test.tolist().count(0))\nprint(y_test.tolist().count(1))","407f7bcf":"# Images for each kind, train\/test\n\n_, train_counts = np.unique(y_train, return_counts=True)\n_, test_counts = np.unique(y_test, return_counts=True)\n\npd.DataFrame({'train': train_counts,\n             'test': test_counts},\n            index=label_names).plot.bar();","a4c86be6":"# What's the proportion?\n\nplt.pie(train_counts,\n        explode=(0, 0) , \n        labels=label_names,\n        autopct='%1.1f%%')\n\nplt.axis('equal')\nplt.title('Proportion of each observed category')\nplt.show()","fc7dd466":"# Reading 'validation' images \n\nfrom skimage.io import imread\nimport cv2\n\n\ndef read_data(path, category):\n    X = []\n    Y = []\n    \n    for file in os.listdir(path):\n\n        if file != '.DS_Store':\n\n            try:\n\n                image = cv2.imread(path + file)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE)\n\n                X.append(image)\n\n                Y.append(label_names_[category])\n\n            except Exception as e:\n                    print(e, file)\n                    \n        else:\n            continue\n    \n    return np.array(X), np.array(Y)\n\n\nX_val1, y_val1 = read_data(VAL_NORMAL, 'NORMAL')\nX_val2, y_val2 = read_data(VAL_SICK, 'PNEUMONIA')\n\nprint(X_val1.shape)\nprint(y_val1.shape)\nprint(X_val2.shape)\nprint(y_val2.shape)\n\n# Concatenating\n\nX_val = [X_val1, X_val2]\nX_val = np.concatenate(X_val)\n\ny_val = [y_val1, y_val2]\ny_val = np.concatenate(y_val)\n\nprint(\"Shape final 'X_val':\", X_val.shape)\nprint(\"Shape final 'y_val':\", y_val.shape)","2bc2c4be":"# Normalization\n\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0\nX_val = X_val \/ 255.0","cbaaa46d":"# Checking images\n\ndef display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + label_names[labels[index]])\n    plt.show()\n    \ndisplay_random_image(label_names, X_train, y_train)","5222a2bb":"# Checking 25 images\n\ndef display_examples(class_names, images, labels):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[255+i], cmap=plt.cm.binary)\n        plt.xlabel(label_names[labels[255+i]])\n    plt.show()\n    \ndisplay_examples(label_names, X_train, y_train)","9279f273":"# Import libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Reshape, GlobalAveragePooling2D\nfrom keras.applications.vgg16 import VGG16","cbbb76dc":"# Using 'ImageDataGenerator'\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # establece la media del dataset a 0\n        samplewise_center=False,  # media de cada entrada a 0\n        featurewise_std_normalization=False,  # divide cada input por la std del dataset\n        samplewise_std_normalization=False,  # divide cada entrada por su std\n        zca_whitening=False,  # espec\u00edfico para im\u00e1genes y gesti\u00f3n de sus colores\n        rotation_range = 30,  \n        zoom_range = 0.2,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip = True,  \n        vertical_flip=False) \n\nvalidation_datagen = ImageDataGenerator()\n\ndatagen.fit(X_train)","7d39fb80":"# Model\n\nexpert_conv = VGG16(weights = 'imagenet', include_top = False,input_shape=(128,128,3))\n\nfor layer in expert_conv.layers:\n      trainable = True\n      layer.trainable = trainable\n\ntweaked_model = Sequential()\ntweaked_model.add(Reshape((128,128,3)))\ntweaked_model.add(expert_conv)\ntweaked_model.add(GlobalAveragePooling2D())\n\ntweaked_model.add(Dense(128, activation = 'relu'))\ntweaked_model.add(Dropout(0.3))\ntweaked_model.add(Dense(4096, activation = 'relu'))\ntweaked_model.add(Dense(1, activation = \"sigmoid\"))\n\nopt = keras.optimizers.SGD(lr=1e-4, momentum=0.8)\n\ntweaked_model.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics=['accuracy'])","b2f2369f":"history = tweaked_model.fit(datagen.flow(X_train,y_train, batch_size = 32) ,epochs = 25, \n                           validation_data = validation_datagen.flow(X_val, y_val))","4c034bd3":"test_eval = tweaked_model.evaluate(X_test, y_test)","6365a4ec":"history_datagen = pd.DataFrame(history.history)\nhistory_datagen","d2686871":"\ndef plot_acc(history, ax = None, xlabel = 'Epoch #'):\n    history = history.history\n    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n    history = pd.DataFrame.from_dict(history)\n    best_epoch = history.sort_values(by = 'val_accuracy', \\\n                                     ascending = False).iloc[0]['epoch']\n    if not ax:\n      f, ax = plt.subplots(1,1)\n    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n    ax.legend(loc = 'best')    \n    ax.set_ylim([0.4, 1])\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel('Accuracy (Fraction)')\n    plt.show()\n    print(\"The highest validation accuracy was\",history.sort_values\\\n          (by = 'val_accuracy', ascending = False).iloc[0]['val_accuracy'])\n    print(\"The lowest validation accuracy was\",history.sort_values\\\n          (by = 'val_accuracy', ascending = True).iloc[0]['val_accuracy'])\n    \n    \ndef plot_loss(history, ax = None, xlabel = 'Epoch #'):\n    history = history.history\n    history.update({'epoch':list(range(len(history['val_loss'])))})\n    history = pd.DataFrame.from_dict(history)\n    best_epoch = history.sort_values(by = 'val_loss', ascending = True).iloc[0]['epoch']\n    if not ax:\n      f, ax = plt.subplots(1,1)\n    sns.lineplot(x = 'epoch', y = 'val_loss', data = history, label = 'Validation', ax = ax)\n    sns.lineplot(x = 'epoch', y = 'loss', data = history, label = 'Training', ax = ax)\n    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n    ax.legend(loc = 1)    \n    ax.set_ylim([0.1, 1])\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel('Loss (Fraction)')\n    plt.show()\n    print(\"The lowest validation loss was\",history.sort_values\\\n          (by = 'val_loss', ascending = True).iloc[0]['val_loss'])\n    print(\"The highest validation loss was\",history.sort_values\\\n          (by = 'val_loss', ascending = False).iloc[0]['val_loss'])","9e4b11a5":"plot_acc(history)\nplot_loss(history)","2a1e26e0":"predictions = tweaked_model.predict(X_test).round(3)\n\n# Getting all predicted values and saving in a list \n\npreds1 = []\n\nfor i in range(len(predictions)):\n    preds1.append(predictions[i].round(3))\n    \ndf_predictions = pd.DataFrame({'y_test' : y_test, 'Predictions' : preds1})\n\ndf_predictions","b80a7618":"'''\n\nIn order to see the confusion matrix:\n\n- every value < 0.5 will be 0\n- every value >= 0.5 will be 1\n\n\n''' \n\ndf_predictions['preds_for_cm'] = np.where(df_predictions['Predictions'] > 0.5, 1, 0)\n\ndf_predictions","6008e3c2":"from sklearn.metrics import confusion_matrix\n\nCM = confusion_matrix(y_test, df_predictions['preds_for_cm'])\n\nsns.heatmap(CM,\n           annot=True,\n            annot_kws={\"size\":10},\n            cmap=\"Blues\",\n           xticklabels=label_names,\n           yticklabels=label_names,\n            fmt = 'd');   \n","c59f1ac0":"import scikitplot as skplt\n\nskplt.metrics.plot_confusion_matrix(y_test, df_predictions['preds_for_cm'], normalize = True);","adab6b94":"# Calculate Precision and Recall\ntn, fp, fn, tp = CM.ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","421f8d88":"# What are the probabilities of those 8 mistakes?\n\ndf_predictions['Acierto'] = np.where(df_predictions['y_test'] == df_predictions['preds_for_cm'], True, False)\n\n# Filtering those 0 values which are FALSE \n\ndf_predictions[(df_predictions['Acierto'] == False) & (df_predictions['preds_for_cm'] == 0)]","ff02b559":"High accuracy model using Machine Learning and neural networks to diagnose pneumonia reading chest X-ray images.\n\n* CNN \n* VGG16\n* ImageDataGenerator\n\n> \n> * Accuracy: 93,91 %\n> * Recall: 0.98"}}