{"cell_type":{"6ec27014":"code","8d12e566":"code","2d1744a1":"code","142cd18a":"code","01198848":"code","ce23baea":"code","ee94ff79":"code","b9b0946c":"code","31f05bbe":"code","284b4e18":"code","865f5944":"code","3ae70c46":"markdown","b866e9cb":"markdown","a490d2b0":"markdown","780ef755":"markdown","e967b663":"markdown","4781315c":"markdown","57ee967e":"markdown","24b1480e":"markdown","3a99bb96":"markdown","3a9d5813":"markdown","2561c41b":"markdown","e0ed8967":"markdown","66ac5e59":"markdown","e5adc09e":"markdown"},"source":{"6ec27014":"import os\nimport sys\n\nimport pandas as pd\nimport pandas_datareader.data as web\nimport numpy as np\n\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\np = print\n","8d12e566":"MSFT = pd.read_csv('..\/input\/Microsoft.csv', header=None)\nAMZN =  pd.read_csv('..\/input\/Amazon.csv',header=None)\nMSFT['AdjClose'] =  pd.read_csv('..\/input\/Microsoft.csv', header=None)\nAMZN['AdjClose'] =  pd.read_csv('..\/input\/Amazon.csv', header=None)","2d1744a1":"def tsplot(y, lags=None, figsize=(15, 15), style='bmh'):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title('Time Series Analysis Plots')\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.7)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.7)\n        plt.tight_layout()\n    return ","142cd18a":"np.random.seed(1)\n\n# plot of discrete white noise\nwhnoise = np.random.normal(size=1000)\ntsplot(whnoise, lags=30)","01198848":"p(\"Outputs\\n-------------\\nMean: {:.3f}\\nVariance: {:.3f}\\nStandard Deviation: {:.3f}\"\n.format(whnoise.mean(), whnoise.var(), whnoise.std()))","ce23baea":"np.random.seed(1)\nn_samples = 1000\n\nx = w = np.random.normal(size=n_samples)\nfor t in range(n_samples):\n    x[t] = x[t-1] + w[t]\n\ntsplot(x, lags=30)","ee94ff79":"tsplot(np.diff(x), lags=30)","b9b0946c":"tsplot(MSFT.AdjClose, lags=30)","31f05bbe":"tsplot(np.diff(MSFT.AdjClose), lags=30)","284b4e18":"tsplot(AMZN.AdjClose, lags=30)","865f5944":"tsplot(np.diff(AMZN.AdjClose), lags=30)","3ae70c46":"### Importing Relevant Libraries","b866e9cb":"#### AMAZON","a490d2b0":"#### MICROSOFT\n\nViewing raw data","780ef755":"In reality, however, the data for time series is never so easy. Often the data is non-stationary. Working with non-stationary data is difficult. To model, we need to convert a non-stationary process to stationary. There are some tests which help us understand this better for eg. the Dickey-Fuller test for the stationarity of time series (presence of a unit root).\n\nLet's look at how we can convert a non-stationary process to stationary using the Dickey-Fuller test.","e967b663":"### White Noise\nWe know, that for modelling a time series dataset, the data should be stationary. In other words, the plot of the data given should resemble a white noise plot. White Noise is when the mean is 0 and the standard deviation is 1. \n\nLets look at how a white noise plot to get a better understanding -","4781315c":"Here is a non-stationary process. The data clearly isnt centered around mean. This happens because after reaching the critical value the series x(t)=\u03c1x(t\u22121)+w(t) does not return to its mean value. If we subtract x(t\u22121) from the left and the right side we will get x(t)\u2212x(t\u22121)=(\u03c1\u22121)x(t\u22121)+w(t), where the expression on the left is called the first difference. If \u03c1=1 then the first difference gives us stationary white noise w(t) - which is the idea of Dickey-Fuller Test. Since we can get stationary series from non-stationary using the first difference we call those series integrated of order 1.","57ee967e":"Now that we've converted the non-stationary processes into stationary, lets look at how will we identify if the p,q of the model AR or MA.\n\nAR(p) \u2014 autoregression model, i.e., regression of the time series onto itself. Basic assumption \u2014 current series values depend on its previous values with some lag (or several lags). The maximum lag in the model is referred to as p. To determine the initial p you need to have a look at *PACF plot* \u2014 find the biggest significant lag, after which most other lags are becoming not significant.\n\n\nMA(q) \u2014 moving average model. Without going into detail it models the error of the time series, again the assumption is \u2014 current error depends on the previous with some lag, which is referred to as q. Initial value can be found on *ACF plot* - find the biggest significant lag, after which most other lags are becoming not significant.\n\nGiven this background, lets identify the p and q for MSFT and AMZN - \n\nFor MSFT, from the PACF, we see that after lag 2, the significant lags are decreasing. Thus, p =2. In ACF also, we see the significant lags decreasing after lag 2.Thus, q=2. Hence, for **MSFT -> AR(2), MA(2)**\n\nFor AMZN, from the PACF, we see that after lag 8, the significant lags are decreasing. Thus, p =8. In ACF also, we see the significant lags decreasing after lag 2. Thus, q=8. Hence, for **AMZN -> AR(8), MA(8)**\n\n\n                                                                    -------This completes the kernel-------","24b1480e":"## Introduction\nMost of us are aware and worked on various time series data and know how important it is to visualize our data before we conclude on the model that we will be using to predict. The intent of this kernel is the same - visulize data, and then based on our learnings from the texts available, apply the theories and then see if our data is in the correct form to be modelled on. I wanted to put this out is because, the below process help me understand these concepts clearly. Hope these help you'l too. :)\n\nData is picked from Yahoo Finance using the pandas_datareader and will be looking at the data for time period - 01-01-2018 till 31-07-2019. I am looking at adjusted close prices only for this experiment. For convience, I have created the respective csv files and reading them. ","3a99bb96":"We can use the \"np.diff()\" function for this","3a9d5813":"Our series looks stationary and resembles white noise. Now, that we know these basics, lets apply the same to our stock data for Mircosoft and Amazon. ","2561c41b":"Viewing data post applying first difference","e0ed8967":"### Plots\nLets create a function which will create three basic plots for us. \n\n    *1) TS Plot\n    *2) Autocorrelation (ACF)\n    *3) Partial Autocorrelation (PACF) \n\nrefer - http:\/\/www.blackarbs.com\/blog\/time-series-analysis-in-python-linear-models-to-garch\/11\/1\/2016","66ac5e59":"First difference for Amazon","e5adc09e":"### Model Identification"}}