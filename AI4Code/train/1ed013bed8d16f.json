{"cell_type":{"619aa06e":"code","c75447d4":"code","833e480b":"code","21abee26":"code","913766a6":"code","e318b91d":"code","86ed8c12":"code","7a0c1d3c":"code","8ed01437":"code","740cb626":"code","89a0b34f":"code","99f95d95":"code","ebf09c40":"code","22630978":"code","5a4bca53":"code","66818aad":"code","43d9da75":"code","0179fd4e":"code","919e4719":"code","f7c4d19e":"code","f4aba266":"code","d4339f1d":"code","47fa6383":"code","f1a2868c":"code","c8c9af62":"markdown","4dbf52f2":"markdown","8e05560f":"markdown","de00c707":"markdown","f2ddb394":"markdown","5c40fe0f":"markdown","5034ce7f":"markdown","e58880d2":"markdown","3a820908":"markdown"},"source":{"619aa06e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt","c75447d4":"pd.set_option('display.max_columns',50)","833e480b":"dat = pd.read_csv(r'..\/input\/melbourne-housing-snapshot\/melb_data.csv')\ndat_orig = dat.copy()","21abee26":"import plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)  \n\n# fig = px.scatter_mapbox(dat, lat=\"Lattitude\", lon=\"Longtitude\", color=\"Price\", size=\"Bedroom2\",\n#                   color_continuous_scale=px.colors.cyclical.IceFire, size_max=15, zoom=10)\nfig = px.density_mapbox(dat, lat='Lattitude', lon='Longtitude', z='Price', radius=5,\n                        center=dict(lat=-37.8, lon=145), zoom=10,\n                        mapbox_style=\"stamen-terrain\", opacity = 1, title = 'Price map')\nfig.show()","913766a6":"dat_orig.head(5)","e318b91d":"dat.info()","86ed8c12":"dat.Postcode = dat.Postcode.astype(\"int64\")\ndat.Bedroom2 = dat.Bedroom2.astype(\"int64\")\ndat.Bathroom = dat.Bathroom.astype(\"int64\")\ndat.Propertycount = dat.Propertycount.astype(\"int64\")\ndat.Car.fillna(\"0\", inplace=True)\ndat.Car = dat.Car.astype(\"int64\")\ndat = dat.drop(columns=[\"BuildingArea\",\"YearBuilt\",\"CouncilArea\"])\ndat.Date = pd.to_datetime(dat.Date,infer_datetime_format=True)","7a0c1d3c":"dat.info()","8ed01437":"dat_unique = {}\nfor col in dat.columns:\n    if dat[col].dtype == 'O':\n        dat_unique[col] = dat[col].unique()","740cb626":"dat.sample(5)","89a0b34f":"dat.describe()","99f95d95":"dat.groupby([\"Regionname\"]).Price.agg([np.mean, np.median, np.max, np.min, np.std]).sort_values(by=[\"mean\"])","ebf09c40":"# Prediction target\ny = dat.Price\nX = dat[[\"Lattitude\",\"Longtitude\" ,'Rooms']]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\ndtr = DecisionTreeRegressor(random_state=0, max_depth=12, min_samples_split=128)\n\ndtr.fit(X_train,y_train)\nypred = dtr.predict(X_test)\n\nplt.plot(y_test,ypred,'o')\nplt.title(\"R2 = \"+str(round(dtr.score(X_test,y_test)*100,1))+\"%\")\nplt.show()\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test, ypred)","22630978":"fig, ax = plt.subplots(1,1,figsize=(30,10))\nplot_tree(dtr, max_depth=2);\nplt.show()","5a4bca53":"# Prediction target\ny = dat.Price\nnum_cols = [\"Lattitude\",\"Longtitude\" ,'Rooms','Car','Landsize',\"Distance\",'Bedroom2']\nX = dat[num_cols]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nnlist = [i for i in range(50,300,100)]\nerrlist = []\nfor i in nlist:\n    rf = RandomForestRegressor(n_estimators=i,random_state=0)\n    rf.fit(X_train,y_train)\n    ypred = rf.predict(X_test)\n    errlist.append(mean_absolute_error(y_test, ypred))\n    print(i,mean_absolute_error(y_test, ypred))\n    \n","66818aad":"n = nlist[errlist.index(min(errlist))]\n\nrf = RandomForestRegressor(n_estimators=n, random_state=0)\n\nrf.fit(X_train,y_train)\nypred = rf.predict(X_test)\n\nplt.plot(y_test,ypred,'o')\nplt.title(\"R2 = \"+str(round(rf.score(X_test,y_test)*100,1))+\"%\")\nplt.show()\n\nmean_absolute_error(y_test, ypred)","43d9da75":"cat_col = [c for c in dat.columns if ((dat[c].dtype == 'O') and (len(dat[c].unique())<8))]\nprint(cat_col)\n\ny = dat.Price\nnum_col = [\"Lattitude\",\"Longtitude\" ,'Rooms','Car','Landsize',\"Distance\",'Bedroom2']\nall_col = num_col.copy()\nall_col.extend(cat_col)\nprint(all_col)\nX = dat[all_col]","0179fd4e":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n\nOH = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\nOH_X_train = pd.DataFrame(OH.fit_transform(X_train[cat_col]))\nOH_X_test = pd.DataFrame(OH.transform(X_test[cat_col]))\n\nOH_X_train.index = X_train.index\nOH_X_test.index = X_test.index\n\nnew_X_train = pd.concat([X_train[num_col], OH_X_train], axis=1)\nnew_X_test = pd.concat([X_test[num_col], OH_X_test], axis=1)\n\n\nrf = RandomForestRegressor(n_estimators=200, random_state=0)\nrf.fit(new_X_train, y_train)\nypred = rf.predict(new_X_test)\n\nplt.plot(y_test,ypred,'o')\nplt.title(\"R2 = \"+str(round(rf.score(new_X_test,y_test)*100,1))+\"%\")\nplt.show()\n\nmean_absolute_error(y_test, ypred)","919e4719":"from sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","f7c4d19e":"num_trans = SimpleImputer(strategy=\"median\")\ncat_trans = Pipeline(steps=[('imp',SimpleImputer(strategy=\"most_frequent\")),\n                          ('oh', OneHotEncoder(handle_unknown=\"ignore\"))])\n\npreproc = ColumnTransformer(transformers=[('num',num_trans, num_col),\n                                         ('cat', cat_trans, cat_col)])\n\nrf = RandomForestRegressor(n_estimators=200, random_state=0)\npp = Pipeline(steps=[('preproc',preproc),\n                    ('model', rf)])\n\npp.fit(X_train, y_train)\nypred = pp.predict(X_test)\n\nplt.plot(y_test,ypred,'o')\nplt.title(\"R2 = \"+str(round(pp.score(X_test,y_test)*100,1))+\"%\")\nplt.show()\n\nmean_absolute_error(y_test, ypred)\n","f4aba266":"from sklearn.model_selection import cross_val_score\n\ndef calc_score(n):\n    num_trans = SimpleImputer(strategy=\"median\")\n    cat_trans = Pipeline(steps=[('imp',SimpleImputer(strategy=\"most_frequent\")),\n                          ('oh', OneHotEncoder(handle_unknown=\"ignore\"))])\n\n    preproc = ColumnTransformer(transformers=[('num',num_trans, num_col),\n                                         ('cat', cat_trans, cat_col)])\n\n    rf = RandomForestRegressor(n_estimators=n, random_state=0)\n    lpp = Pipeline(steps=[('preproc',preproc), ('model', rf)]) \n    sc = -1* cross_val_score(lpp, X,y, cv=4, scoring=\"neg_mean_absolute_error\")\n    return sc.mean()","d4339f1d":"for i in range(50,600,150):\n    print(i,calc_score(i))","47fa6383":"num_trans = SimpleImputer(strategy=\"median\")\ncat_trans = Pipeline(steps=[('imp',SimpleImputer(strategy=\"most_frequent\")),\n                          ('oh', OneHotEncoder(handle_unknown=\"ignore\"))])\n\npreproc = ColumnTransformer(transformers=[('num',num_trans, num_col),\n                                         ('cat', cat_trans, cat_col)])\n\nrf = RandomForestRegressor(n_estimators=500, random_state=0)\npp = Pipeline(steps=[('preproc',preproc),\n                    ('model', rf)])\n\npp.fit(X_train, y_train)\nypred = pp.predict(X_test)\n\nplt.plot(y_test,ypred,'o')\nplt.title(\"R2 = \"+str(round(pp.score(X_test,y_test)*100,1))+\"%\")\nplt.show()\n\nmean_absolute_error(y_test, ypred)","f1a2868c":"from xgboost import XGBRegressor\n\n\ncat_col = [c for c in dat.columns if ((dat[c].dtype == 'O') and (len(dat[c].unique())<8))]\nprint(cat_col)\n\ny = dat.Price\nnum_col = [\"Lattitude\",\"Longtitude\" ,'Rooms','Car','Landsize',\"Distance\",'Bedroom2']\nall_col = num_col.copy()\nall_col.extend(cat_col)\nprint(all_col)\nX = dat[all_col]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n\nnum_trans = SimpleImputer(strategy=\"median\")\ncat_trans = Pipeline(steps=[('imp',SimpleImputer(strategy=\"most_frequent\")),\n                          ('oh', OneHotEncoder(handle_unknown=\"ignore\"))])\n\npreproc = ColumnTransformer(transformers=[('num',num_trans, num_col),\n                                         ('cat', cat_trans, cat_col)])\n\nxgb = XGBRegressor(n_estimators=400, learning_rate=0.1, random_state=0)\npp = Pipeline(steps=[('preproc',preproc),\n                    ('model', xgb)])\n\npp.fit(X_train, y_train) #, model__early_stopping_rounds = 5, model__eval_set=[(X_test, y_test)])\nypred = pp.predict(X_test)\n\nplt.plot(y_test,ypred,'o')\nplt.title(\"R2 = \"+str(round(pp.score(X_test,y_test)*100,1))+\"%\")\nplt.show()\n\nmean_absolute_error(y_test, ypred)","c8c9af62":"**Random Forest Regressor**","4dbf52f2":"# Modeling","8e05560f":"**With encoding on categorical variables**","de00c707":"**Using cross validation**","f2ddb394":"**XGBoost**","5c40fe0f":"# Interrogate the data : descriptive analytics","5034ce7f":"**With Pipelines**","e58880d2":"# Visualize on a map","3a820908":"**Decision Tree Regressor**"}}