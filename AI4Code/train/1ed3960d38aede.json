{"cell_type":{"cdeeee71":"code","a03767d2":"code","6cbd5eb7":"code","a7c1b0da":"code","2291eba8":"code","9ede0304":"code","cdce435e":"code","ea4971b6":"code","098ad55d":"code","3c534981":"code","9e90a1b4":"code","2efc56d2":"code","dfbb6140":"code","f3267706":"code","64ec0cf8":"code","7685230a":"code","8e5a2d35":"code","99e8d88a":"code","7ee62785":"code","80478625":"code","55de92a8":"code","a63c1dec":"code","b6ef66f9":"code","f80c6d9f":"code","d1897bdd":"code","3253482a":"code","f4965a6b":"code","9a9c819e":"code","d503e199":"code","9edcbd84":"code","20f4fe2b":"code","74d82661":"code","66c5ecb0":"code","1662e639":"code","c18cb6e2":"code","8923f435":"code","cea063b1":"code","e58eddd0":"code","a1b9b93a":"code","043be841":"markdown","43e41bae":"markdown","012f8671":"markdown","20d69d73":"markdown","499e11f7":"markdown","ae74aa31":"markdown","216a959b":"markdown","beca5cfc":"markdown","5adb57b5":"markdown","eeda87a3":"markdown","5a34cf33":"markdown"},"source":{"cdeeee71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a03767d2":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt","6cbd5eb7":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')","a7c1b0da":"df.head()","2291eba8":"df.shape","9ede0304":"df.info()","cdce435e":"df.describe()","ea4971b6":"df['target'].value_counts()","098ad55d":"df.duplicated()","3c534981":"df.isnull().sum()","9e90a1b4":"plt.hist(df)","2efc56d2":"sns.boxplot(data=df)","dfbb6140":"df.corr()","f3267706":"plt.figure(figsize=[10,6])\nsns.heatmap(df.corr(),annot=True)","64ec0cf8":"x = df.drop(columns='target', axis=1)\ny = df['target']","7685230a":"print(x)\nprint(y)","8e5a2d35":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2)","99e8d88a":"print(x.shape, xtrain.shape, xtest.shape)","7ee62785":"from sklearn.linear_model import LogisticRegression","80478625":"model = LogisticRegression(solver='liblinear')","55de92a8":"model.fit(xtrain,ytrain)","a63c1dec":"ypred = model.predict(xtest)","b6ef66f9":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\ncm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","f80c6d9f":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","d1897bdd":"cm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","3253482a":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(xtrain,ytrain)","f4965a6b":"ypred=model.predict(xtest)","9a9c819e":"cm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","d503e199":"from sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","9edcbd84":"cm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","20f4fe2b":"from sklearn.naive_bayes import GaussianNB\nmodel=GaussianNB()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","74d82661":"cm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","66c5ecb0":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()\nmodel.fit(xtrain,ytrain)\nypred=model.predict(xtest)","1662e639":"cm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","c18cb6e2":"from sklearn.ensemble import GradientBoostingClassifier\nmodel=GradientBoostingClassifier()\nmodel.fit(xtrain,ytrain)","8923f435":"ypred=model.predict(xtest)","cea063b1":"cm=confusion_matrix(ytest,ypred)\nsns.heatmap(cm,annot=True)\nprint(\"accuracy is:\",accuracy_score(ytest,ypred))\nprint(classification_report(ytest,ypred))","e58eddd0":"model = [\"LogisticRegression\", \"Decision Tree\", \"Random Forest\", \"Support Vector Machine\", \"Gaussian Naive Bayes\", \"Multinomial Naive Bayes\", \"GradientBoostingClassifier\"]\naccuracy = [0.8032786885245902*100, 0.7868852459016393*100, 0.7540983606557377*100, 0.6229508196721312*100, 0.819672131147541*100, 0.6885245901639344*100, 0.7377049180327869*100]","a1b9b93a":"pd.DataFrame({\"model\":model,\"Accuracy\":accuracy})","043be841":"**We get the highest accuracy score using Gaussian Naive Bayes**","43e41bae":"Splitting into test and train set","012f8671":"**Gradient Boosting Classifier**","20d69d73":"The Dataset","499e11f7":"**Random Forest**","ae74aa31":"**Multinomial Naive Bayes**","216a959b":"**Support Vector Machine**","beca5cfc":"**Decision Tree**","5adb57b5":"**Gaussian Naive Bayes**","eeda87a3":"**Logistic Regression**","5a34cf33":"Importing Dependencies"}}