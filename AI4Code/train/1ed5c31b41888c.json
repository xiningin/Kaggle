{"cell_type":{"8994025e":"code","50e3305a":"code","15b94c40":"code","ae844803":"code","dc00ba67":"code","a6658b47":"code","95234d5c":"code","443006b0":"code","ea4965e6":"code","9a5c6911":"code","e9d0be9e":"code","5181dcf5":"code","146948a4":"code","d3f5cb6a":"code","89bd04d5":"code","546d54f4":"code","703c4665":"code","640cb9d4":"code","652a8ee9":"code","bda6c8dd":"code","534b62da":"code","f0cb7cd3":"code","d8f91a45":"code","2db2448a":"code","6b3513dc":"code","b130b9dc":"code","ba1eb791":"code","b7963e99":"code","6ab4ef4f":"code","480815bb":"code","1e2d34f2":"code","771f6d15":"code","d5166c83":"code","f021efae":"code","971de598":"code","c8f1e7ce":"code","f4b4a3d3":"code","4b22d632":"code","ea0f3ec9":"code","c8e6ab7c":"code","e96049e5":"code","647d92f0":"markdown","a85b2888":"markdown","bc04ba6b":"markdown","f7ca5212":"markdown","536e8318":"markdown","b549507f":"markdown","ab630554":"markdown","229b134f":"markdown","fc785fa8":"markdown","f48a3f8a":"markdown","1148696c":"markdown","6228f637":"markdown","39630507":"markdown","999d3905":"markdown","94d1f00e":"markdown","871d1d56":"markdown","6f7059d5":"markdown","dd4491aa":"markdown"},"source":{"8994025e":"import os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_validate\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nfrom sklearn.feature_selection import RFECV, RFE\n\nsns.set(style=\"white\") \nsns.set(style=\"whitegrid\", color_codes=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')","50e3305a":"files = os.listdir(\"..\/input\")\ntrain_data = pd.read_csv(\"..\/input\/\"+files[1])","15b94c40":"train_data.head(5)","ae844803":"print(\"Tha Dataset Titanic is described with %d features and %d examples\" %(train_data.shape[1] ,train_data.shape[0]))","dc00ba67":"print(\"% of missing values in each columns\")\nprint(round(100*train_data.isna().sum()\/train_data.shape[0],2))","a6658b47":"import re\ndef extractTitle(name):\n    p = re.compile(', (.*)\\.')\n    #p = re.compile('(.*, )|(\\\\..*)')\n    return p.findall(name)","95234d5c":"train_data['title'] = train_data.Name.apply(lambda name:extractTitle(name)[0])","443006b0":"rare_title = ['Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']","ea4965e6":"train_data.title.replace(to_replace=['Mlle', 'Ms'], value='Miss', inplace= True)\ntrain_data.title.replace(to_replace=['Mme'], value='Mrs', inplace= True)\ntrain_data.title.replace(to_replace=train_data.title.where(train_data.title.isin(rare_title)), value='rare_tite', inplace= True)\ntrain_data.title.replace(to_replace='Mrs. Martin (Elizabeth L', value='Mrs', inplace= True)","9a5c6911":"pd.crosstab(index=train_data.Sex,columns=train_data.title)","e9d0be9e":"missing_embarked = train_data.Fare[train_data.Embarked.isna()]\nprint(\"The passengers wirth missing embarked value have paied %.2f $ and %.2f $\" \n      %(missing_embarked.iloc[0], missing_embarked.iloc[1]))","5181dcf5":"plt.figure(figsize=(17,20))\nplt.axhline(y=80, color='red')\nsns.boxplot(x='Embarked', y='Fare', data=train_data, hue='Pclass')","146948a4":"train_df = train_data.copy()","d3f5cb6a":"train_data.Embarked.fillna(value='C', inplace = True)","89bd04d5":"print(\"Percentage of missing values in Age column = \"\\\n+ str(round(100 * train_data[train_data.Age.isna()].shape[0] \/ train_data.shape[0],2)) +\"%\")","546d54f4":"plt.figure(figsize=(20,10))\nsns.distplot(train_data.Age.dropna(), color='teal')","703c4665":"print('The mean of the \"Age\" is %.2f' %(train_data.Age.mean(skipna=True)))\nprint('The media of the \"Age\" is %.2f' %(train_data.Age.median(skipna=True)))","640cb9d4":"train_data.Age.fillna(train_data.Age.median(skipna = True), inplace = True)","652a8ee9":"plt.figure(figsize=(20,10))\nsns.distplot(train_data.Age, color='teal', bins=15)\nsns.distplot(train_df.Age.dropna(), color = 'red', bins = 15)\nsns.distplot(train_df.Age.fillna(train_data.Age.mean(skipna = True)), color = 'blue', bins = 15)\nplt.legend(['Adjusted Age', 'Raw Age'])","bda6c8dd":"train_data.drop(['Cabin'], axis=1, inplace = True)","534b62da":"train_data['TravelAlone']=np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\ntrain_data.drop('SibSp', axis=1, inplace=True)\ntrain_data.drop('Parch', axis=1, inplace=True)","f0cb7cd3":"training=pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\",\"title\"])\ntraining.drop('Sex_female', axis=1, inplace=True)\ntraining.drop('PassengerId', axis=1, inplace=True)\ntraining.drop('Name', axis=1, inplace=True)\ntraining.drop('Ticket', axis=1, inplace=True)","d8f91a45":"plt.figure(figsize=(15,7))\nsns.kdeplot(training.Age[training.Survived == 1], color = 'blue', shade = \"True\")\nsns.kdeplot(training.Age[training.Survived == 0], color = 'red', shade = \"True\")\nplt.legend(['Survived', 'Died'])","2db2448a":"plt.figure(figsize=(20,10))\nsurvival_byage = training[[\"Age\",\"Survived\"]].groupby(['Age'], as_index = False).mean()\nsns.barplot(x='Age', y='Survived', data=survival_byage, color = 'green')","6b3513dc":"training['IsMinor']=np.where(training['Age']<=16, 1, 0)\ntraining['IsMinor']=np.where(training['Age']<=16, 1, 0)","b130b9dc":"plt.figure(figsize=(15,8))\nsns.kdeplot(training[\"Fare\"][training.Survived == 1], color = 'black', shade=True)\nsns.kdeplot(training[\"Fare\"][training.Survived == 0], color = 'orange', shade=True)\nplt.legend(['Survived', 'Died'])","ba1eb791":"sns.barplot(x='Pclass', y='Survived', data=train_df, color=\"darkturquoise\")\n","b7963e99":"sns.barplot('Embarked', 'Survived', data=train_df, color=\"teal\")","6ab4ef4f":"training.columns","480815bb":"sns.barplot('TravelAlone', 'Survived', data=training, color=\"mediumturquoise\")","1e2d34f2":"sns.barplot('Sex', 'Survived', data=train_df, color=\"aquamarine\")","771f6d15":"cols = ['Age', 'Fare', 'TravelAlone', 'Pclass_1', 'Pclass_2',\n       'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Sex_male',\n       'title_Master', 'title_Miss', 'title_Mr', 'title_Mrs',\n       'title_rare_tite', 'IsMinor']\nX = training[cols]\ny = training['Survived']\n# Build a logreg and compute the feature importances\nmodel = LogisticRegression()\n# create the RFE model and select 8 attributes\nrfe = RFE(model, 8)\nrfe = rfe.fit(X, y)\n# summarize the selection of the attributes\nprint('Selected features: %s' % list(X.columns[rfe.support_]))","d5166c83":"# Create the RFE object and compute a cross-validated score.\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nrfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\nrfecv.fit(X, y)\n\nprint(\"Optimal number of features: %d\" % rfecv.n_features_)\nprint('Selected features: %s' % list(X.columns[rfecv.support_]))\n\n# Plot number of features VS. cross-validation scores\nplt.figure(figsize=(10,6))\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","f021efae":"Selected_features = ['Age', 'TravelAlone', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q',\n                     'Embarked_S', 'Sex_male', 'title_Master', 'title_Miss', 'title_Mr', 'title_Mrs',\n                     'title_rare_tite', 'IsMinor']\nX = training[Selected_features]\nplt.subplots(figsize=(10, 8))\nsns.heatmap(X.corr(), annot=True)\nplt.show()","971de598":"plt.subplots(figsize=(12, 8))\nsns.heatmap(training.corr(), annot=True)\nplt.show()","c8f1e7ce":"# create X (features) and y (response)\nX = training[Selected_features]\ny = training['Survived']\n\n# use train\/test split with different random_state values\n# we can change the random_state values that changes the accuracy scores\n# the scores change a lot, this is why testing scores is a high-variance estimate\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n\n# check classification scores of logistic regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_test)","f4b4a3d3":"print('Train\/Test split results:')\nprint(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))","4b22d632":"logreg = LogisticRegression()\nscores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')","ea0f3ec9":"print('K-fold cross-validation results:')\nprint(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())","c8e6ab7c":"scoring = {'accuracy': 'accuracy'}\n\nmodelCV = LogisticRegression()\n\nresults = cross_validate(modelCV, X, y, cv=10, scoring=list(scoring.values()), \n                         return_train_score=False)","e96049e5":"print('K-fold cross-validation results:')\nprint(logreg.__class__.__name__+\" average accuracy is %2.3f\" % results['test_accuracy'].mean())","647d92f0":"People embarked from \"S\" are the ones with lot of outliers !!. As a Data scientists we should ask WHY ?<br>\nFrom some research in wikepidia, the boat started the journey from Southampton, so we can say that people coming last and were excited to live the american dream paid much more to get a ticket.\n","a85b2888":"# Data preprocessing","bc04ba6b":"#### Age feature","f7ca5212":"The line of 80$ cross the median of the first class of Embarekment C, which means we can replace safely the missing values with \"C\"","536e8318":"Is there any relation between the price, OF COURSE !!<br>\nwe will use the boxplot to describe the Embarked stations by the price and per class ","b549507f":"Library and Data loading","ab630554":"PassengerId : type should be integers<br>\nSurvived : 1 = Survived, 0 = Not<br>\nPclass : Class of Travel = {1,2,3}<br>\nName : Name of Passenger<br>\nSex : Gender = {male, female}<br>\nAge : Age of Passengers<br>\nSibSp : Number of Sibling\/Spouse aboard<br>\nParch : Number of Parent\/Child aboard<br>\nTicket : Ticket number<br>\nFare : Ticket price<br>\nCabin : Cabin number<br>\nEmbarked : The port in which a passenger has embarked = {C - Cherbourg, S - Southampton, Q - Queenstown} ","229b134f":"The DF is scewed left, which means using the mean to fill the missing values will change the distribution, that is to say that the best value to use is the median","fc785fa8":"There is some missing sell calling for our help !!! <br>\nFor the both columns \"Age\" and \"Embarked\" we can use some statistical technics to fill theme, but for you \"Cabin\" I am sorry I can't do it I will just drop you SORRY!:(<br>","f48a3f8a":"#### Embarked feature","1148696c":"## Missing values ","6228f637":"## Feature engineering ","39630507":"# Data discovery","999d3905":"#### let's Some Fun","94d1f00e":"train test split","871d1d56":"To fill the missing values in the \"Age\" column we can use the imputers technics. For the first version of this notebook, I will just use the median, mean values for this task","6f7059d5":"Model evaluation based on K-fold cross-validation using cross_val_score() function","dd4491aa":"Fortunatly both passengers paied some price => not much wor to do :D <br>"}}