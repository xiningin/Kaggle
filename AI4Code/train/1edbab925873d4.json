{"cell_type":{"32469ec4":"code","3db7e636":"code","6d36a9b8":"code","ce9ef44b":"code","6de54550":"code","0feaec12":"code","794a6471":"code","9ef1c194":"code","bcc2f697":"code","e0ebe163":"code","ee32f2b6":"code","2722a0d9":"code","32dc6fd4":"code","f0662deb":"code","47e3450b":"code","9d39e263":"code","4cd046c4":"code","9bade7d1":"code","3331dc39":"code","d71d71c2":"code","66a014db":"code","5c18ec43":"code","dd4be72e":"code","deaddf58":"code","0bc6072f":"code","d86b3d55":"code","aa0a95b2":"code","63495210":"code","54d6de0a":"code","9de7bb84":"code","738cb902":"code","e3abd657":"code","fb27f317":"code","bcbec2df":"code","19683641":"code","1a2e8f69":"code","2edde975":"code","8360f303":"code","f6b26c44":"code","ddd1ca0e":"code","49dead27":"code","8b1756fa":"code","87b391e3":"code","5dfe2ce7":"code","80663b3c":"code","2e099426":"code","d5ec1525":"code","c54947f7":"code","4ed543ee":"code","f0e7ca8d":"code","36f09c5a":"code","70f4332d":"code","9c87a881":"code","60d9832c":"code","df5704cd":"code","e8078749":"code","313390ad":"code","f55aaf9a":"code","f053f45f":"code","a759434a":"code","2c4dc8e2":"code","e10ddda8":"code","dbd1d249":"code","6505ccac":"code","6c69c615":"code","0d2a02c0":"code","0884c966":"code","00d3a737":"code","82465aaa":"code","8805079d":"code","5a9c1c16":"code","6bd34936":"code","d02a286c":"code","92c88c4d":"markdown","b28240e0":"markdown","2a954302":"markdown","8ca51fda":"markdown","c8956804":"markdown","d83ce65f":"markdown","91330615":"markdown","f769ec6a":"markdown","a43635f7":"markdown","0e861b6e":"markdown","364533cc":"markdown","93c3a175":"markdown","02800f98":"markdown","62f93342":"markdown","b50f2849":"markdown","39c00712":"markdown","797c4581":"markdown","bf8c192b":"markdown","2fd1e0ca":"markdown","a3a3c9c0":"markdown","4466b964":"markdown","f53c4fea":"markdown","0d2029ad":"markdown","6ad03270":"markdown","abc9696f":"markdown","b6015b9a":"markdown","f99def0c":"markdown","07079fcb":"markdown","569ee8a5":"markdown","75ee1ab1":"markdown","b1e451f6":"markdown","e4d9f271":"markdown","32ad8d85":"markdown","d871959c":"markdown","b90b5ee4":"markdown","7555455c":"markdown","c504b3b8":"markdown","2a8f950f":"markdown","77eb8801":"markdown","e6797ca9":"markdown","d0b1881b":"markdown","3ef6c9f2":"markdown"},"source":{"32469ec4":"import IPython.display as ipd\n\n#Air Conditioner\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold9\/101729-0-0-18.wav')","3db7e636":"#Car Horn\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold10\/100648-1-3-0.wav')","6d36a9b8":"#Children Playing\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold10\/101382-2-0-20.wav')","ce9ef44b":"#Dog bark\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold1\/101415-3-0-2.wav')","6de54550":"#Drilling\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold3\/103199-4-0-3.wav')","0feaec12":"#Engine Idling\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold10\/102857-5-0-12.wav')","794a6471":"#Gun Shot\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold1\/102305-6-0-0.wav')","9ef1c194":"#Jackhammer\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold1\/103074-7-0-1.wav')","bcc2f697":"#Siren\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold2\/102871-8-0-12.wav')","e0ebe163":"#Street Music\nipd.Audio('..\/input\/urbansounds\/UrbanSound8K\/audio\/fold7\/101848-9-0-2.wav')","ee32f2b6":"import IPython.display as ipd\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt","2722a0d9":"# Class: Air Conditioner\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold9\/101729-0-0-40.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","32dc6fd4":"# Class: Car horn \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold8\/107090-1-1-0.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","f0662deb":"# Class: Children playing \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold10\/101382-2-0-20.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","47e3450b":"\n# Class: Dog bark\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold6\/105319-3-0-29.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","9d39e263":"# Class: Drilling\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold6\/107842-4-2-0.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","4cd046c4":"# Class: Engine Idling \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold6\/106486-5-0-2.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","9bade7d1":"# Class: Gunshot\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold1\/102305-6-0-0.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","3331dc39":"\n# Class: Jackhammer\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold1\/103074-7-3-1.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","d71d71c2":"\n# Class: Siren\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold7\/102853-8-0-1.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","66a014db":"\n# Class: Street music\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold4\/107653-9-0-18.wav'\nplt.figure(figsize=(12,4))\ndata,sample_rate = librosa.load(filename)\n_ = librosa.display.waveplot(data,sr=sample_rate)\nipd.Audio(filename)","5c18ec43":"import pandas as pd\nmetadata = pd.read_csv('..\/input\/urbansounds\/UrbanSound8K\/metadata\/UrbanSound8K.csv')\nmetadata = metadata.rename(columns={'class': 'class_name'})\nmetadata.head(10)","dd4be72e":"print(metadata.class_name.value_counts())","deaddf58":"import struct\n\nclass WavFileHelper():\n    \n    def read_file_properties(self, filename):\n\n        wave_file = open(filename,\"rb\")\n        \n        riff = wave_file.read(12)\n        fmt = wave_file.read(36)\n        \n        num_channels_string = fmt[10:12]\n        num_channels = struct.unpack('<H', num_channels_string)[0]\n\n        sample_rate_string = fmt[12:16]\n        sample_rate = struct.unpack(\"<I\",sample_rate_string)[0]\n        \n        bit_depth_string = fmt[22:24]\n        bit_depth = struct.unpack(\"<H\",bit_depth_string)[0]\n\n        return (num_channels, sample_rate, bit_depth)","0bc6072f":"# Load various imports \nimport pandas as pd\nimport os\nimport librosa\nimport librosa.display\n\nwavfilehelper = WavFileHelper()\n\naudiodata = []\nfor index, row in metadata.iterrows():\n    \n    file_name = os.path.join(os.path.abspath('..\/input\/urbansounds\/UrbanSound8K\/audio\/'),'fold'+str(row[\"fold\"])+'\/',str(row[\"slice_file_name\"]))\n    data = wavfilehelper.read_file_properties(file_name)\n    audiodata.append(data)\n\n# Convert into a Panda dataframe\naudiodf = pd.DataFrame(audiodata, columns=['num_channels','sample_rate','bit_depth'])","d86b3d55":"# num of channels \n\nprint(audiodf.num_channels.value_counts(normalize=True))","aa0a95b2":"# sample rates \n\nprint(audiodf.sample_rate.value_counts(normalize=True))","63495210":"\n# bit depth\n\nprint(audiodf.bit_depth.value_counts(normalize=True))","54d6de0a":"import librosa \nfrom scipy.io import wavfile as wav\nimport numpy as np\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold7\/101848-9-0-3.wav' \n\nlibrosa_audio, librosa_sample_rate = librosa.load(filename) \nscipy_sample_rate, scipy_audio = wav.read(filename) \n\nprint('Original sample rate:', scipy_sample_rate) \nprint('Librosa sample rate:', librosa_sample_rate)\nipd.Audio(filename)","9de7bb84":"print('Original audio file min~max range:', np.min(scipy_audio), 'to', np.max(scipy_audio))\nprint('Librosa audio file min~max range:', np.min(librosa_audio), 'to', np.max(librosa_audio))","738cb902":"import matplotlib.pyplot as plt\n\n# Original audio with 2 channels \nplt.figure(figsize=(12, 4))\nplt.plot(scipy_audio)","e3abd657":"# Librosa audio with channels merged \nplt.figure(figsize=(12, 4))\nplt.plot(librosa_audio)","fb27f317":"mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc=40)\nprint(mfccs.shape)","bcbec2df":"import librosa.display\nlibrosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')","19683641":"\ndef extract_features(file_name):\n   \n    try:\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        mfccsscaled = np.mean(mfccs.T,axis=0)\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file)\n        return None \n     \n    return mfccsscaled","1a2e8f69":"# Load various imports \nimport pandas as pd\nimport os\nimport librosa\nfrom tqdm import tqdm\n\n# Set the path to the full UrbanSound dataset \nfulldatasetpath = '..\/input\/urbansounds\/UrbanSound8K\/audio'\n\nmetadata = pd.read_csv('..\/input\/urbansounds\/UrbanSound8K\/metadata\/UrbanSound8K.csv')\nmetadata = metadata.rename(columns={'class': 'class_name'})\nfeatures = []\n\n# Iterate through each sound file and extract the features \nfor index, row in tqdm(metadata.iterrows()):\n    \n    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'\/',str(row[\"slice_file_name\"]))\n    \n    class_label = row[\"class_name\"]\n    data = extract_features(file_name)\n    \n    features.append([data, class_label])\n\n# Convert into a Panda dataframe \nfeaturesdf = pd.DataFrame(features, columns=['feature','class_label'])\n\nprint('Finished feature extraction from ', len(featuresdf), ' files')","2edde975":"featuresdf.head()","8360f303":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\n# Convert features and corresponding classification labels into numpy arrays\nX = np.array(featuresdf.feature.tolist())\ny = np.array(featuresdf.class_label.tolist())\n\n# Encode the classification labels\nle = LabelEncoder()\nyy = to_categorical(le.fit_transform(y))","f6b26c44":"\n# split the dataset \nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)","ddd1ca0e":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom sklearn import metrics \n\nnum_labels = yy.shape[1]\nfilter_size = 2\n\n# Construct model \nmodel = Sequential()\n\nmodel.add(Dense(256, input_shape=(40,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))","49dead27":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","8b1756fa":"# Display model architecture summary \nmodel.summary()\n\n# Calculate pre-training accuracy \nscore = model.evaluate(x_test, y_test, verbose=0)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)","87b391e3":"\nfrom keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \n\nnum_epochs = 100\nnum_batch_size = 32\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.basic_mlp.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\n\nmodel.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","5dfe2ce7":"# Evaluating the model on the training and testing set\nscore = model.evaluate(x_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","80663b3c":"import librosa \nimport numpy as np \n\ndef extract_feature(file_name):\n   \n    try:\n        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n        mfccsscaled = np.mean(mfccs.T,axis=0)\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file)\n        return None, None\n\n    return np.array([mfccsscaled])","2e099426":"def print_prediction(file_name):\n    prediction_feature = extract_feature(file_name) \n\n    predicted_vector = model.predict_classes(prediction_feature)\n    predicted_class = le.inverse_transform(predicted_vector) \n    print(\"The predicted class is:\", predicted_class[0], '\\n') \n\n    predicted_proba_vector = model.predict_proba(prediction_feature) \n    predicted_proba = predicted_proba_vector[0]\n    for i in range(len(predicted_proba)): \n        category = le.inverse_transform(np.array([i]))\n        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )","d5ec1525":"\n# Class: Air Conditioner\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold9\/101729-0-0-11.wav' \nprint_prediction(filename)\nipd.Audio(filename)","c54947f7":"# Class: Drilling\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold2\/104817-4-0-10.wav'\nprint_prediction(filename)\nipd.Audio(filename)","4ed543ee":"# Class: Street music \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold7\/101848-9-0-9.wav'\nprint_prediction(filename)\nipd.Audio(filename)","f0e7ca8d":"\n# Class: Car Horn \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold8\/107090-1-1-0.wav'\nprint_prediction(filename)\nipd.Audio(filename)","36f09c5a":"\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold9\/103249-5-0-0.wav'\nprint_prediction(filename)\nipd.Audio(filename)","70f4332d":"filename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold10\/100795-3-1-2.wav'\n\nprint_prediction(filename)\nipd.Audio(filename)","9c87a881":"\nimport numpy as np\nmax_pad_len = 174\n\ndef extract_features(file_name):\n   \n    try:\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n        pad_width = max_pad_len - mfccs.shape[1]\n        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n        \n    except Exception as e:\n        print(\"Error encountered while parsing file: \", file_name)\n        return None \n     \n    return mfccs","60d9832c":"# Load various imports \nimport pandas as pd\nimport os\nimport librosa\n\n# Set the path to the full UrbanSound dataset \nfulldatasetpath = '..\/input\/urbansounds\/UrbanSound8K\/audio'\n\nmetadata = pd.read_csv('..\/input\/urbansounds\/UrbanSound8K\/metadata\/UrbanSound8K.csv')\nmetadata = metadata.rename(columns={'class': 'class_name'})\nfeatures = []\n\n# Iterate through each sound file and extract the features \nfor index, row in metadata.iterrows():\n    \n    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'\/',str(row[\"slice_file_name\"]))\n    \n    class_label = row[\"class_name\"]\n    data = extract_features(file_name)\n    \n    features.append([data, class_label])\n\n# Convert into a Panda dataframe \nfeaturesdf = pd.DataFrame(features, columns=['feature','class_label'])\n\nprint('Finished feature extraction from ', len(featuresdf), ' files')","df5704cd":"\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\n# Convert features and corresponding classification labels into numpy arrays\nX = np.array(featuresdf.feature.tolist())\ny = np.array(featuresdf.class_label.tolist())\n\n# Encode the classification labels\nle = LabelEncoder()\nyy = to_categorical(le.fit_transform(y)) \n\n# split the dataset \nfrom sklearn.model_selection import train_test_split \n\nx_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)","e8078749":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils\nfrom sklearn import metrics \n\nnum_rows = 40\nnum_columns = 174\nnum_channels = 1\n\nx_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\nx_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n\nnum_labels = yy.shape[1]\nfilter_size = 2\n\n# Construct model \nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(num_labels, activation='softmax'))","313390ad":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","f55aaf9a":"\n# Display model architecture summary \nmodel.summary()\n\n# Calculate pre-training accuracy \nscore = model.evaluate(x_test, y_test, verbose=1)\naccuracy = 100*score[1]\n\nprint(\"Pre-training accuracy: %.4f%%\" % accuracy)","f053f45f":"from keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \n\n#num_epochs = 12\n#num_batch_size = 128\n\nnum_epochs = 72\nnum_batch_size = 256\n\ncheckpointer = ModelCheckpoint(filepath='saved_models\/weights.best.basic_cnn.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\n\nmodel.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n\n\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","a759434a":"\n# Evaluating the model on the training and testing set\nscore = model.evaluate(x_train, y_train, verbose=0)\nprint(\"Training Accuracy: \", score[1])\n\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Testing Accuracy: \", score[1])","2c4dc8e2":"def print_prediction(file_name):\n    prediction_feature = extract_features(file_name) \n    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n\n    predicted_vector = model.predict_classes(prediction_feature)\n    predicted_class = le.inverse_transform(predicted_vector) \n    print(\"The predicted class is:\", predicted_class[0], '\\n') \n\n    predicted_proba_vector = model.predict_proba(prediction_feature) \n    predicted_proba = predicted_proba_vector[0]\n    for i in range(len(predicted_proba)): \n        category = le.inverse_transform(np.array([i]))\n        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )","e10ddda8":"# Class: Air Conditioner\n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold9\/101729-0-0-14.wav' \nprint_prediction(filename)","dbd1d249":"# Class: Car Horn \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold8\/107090-1-1-0.wav'\nprint_prediction(filename)","6505ccac":"# Class: Street music \n\nfilename = '..\/input\/urbansounds\/UrbanSound8K\/audio\/fold7\/101848-9-0-9.wav'\nprint_prediction(filename)","6c69c615":"actual_class_list=[]\npredicted_class_list=[]\nmetadata = pd.read_csv('..\/input\/urbansounds\/UrbanSound8K\/metadata\/UrbanSound8K.csv')\n\nfor index, row in tqdm(metadata.iterrows()):\n    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'\/',str(row[\"slice_file_name\"]))\n    class_id = row[\"classID\"]\n    #print(file_name)\n    #sleep(2)\n    prediction_feature = extract_features(file_name) \n    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n\n    predicted_vector = model.predict_classes(prediction_feature)\n    predicted_class = le.inverse_transform(predicted_vector) \n   # print(\"The predicted class is:\", predicted_class[0], '\\n') \n\n    predicted_proba_vector = model.predict_proba(prediction_feature) \n    predicted_proba = predicted_proba_vector[0]\n    predicted_class=np.argmax(predicted_proba) \n    predicted_class_list.append(predicted_class)\n    actual_class_list.append(class_id)\n    #print(\"pred--\",predicted_class_list)\n    #print(\"actual--\",actual_class_list)","0d2a02c0":"import pandas as pd\ny_actu = pd.Series(actual_class_list, name='Actual')\ny_pred = pd.Series(predicted_class_list, name='Predicted')\ndf_confusion = pd.crosstab(y_actu, y_pred)","0884c966":"df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\ndf_confusion","00d3a737":"unique_labels=['air_conditioner','car_horn','children_playing','dog_bark','drilling','engine_idling','gun_shot','jackhammer','siren','street_music']","82465aaa":"y_pred.shape[0]","8805079d":"y_pred_class=[]\ny_actu_class=[]\nfor i in range(y_pred.shape[0]):\n    y_pred_class.append(unique_labels[y_pred[i]])\n    y_actu_class.append(unique_labels[y_actu[i]])","5a9c1c16":"import seaborn as sns","6bd34936":"from sklearn.metrics import confusion_matrix","d02a286c":"conf_mat = confusion_matrix(y_actu_class, y_pred_class, labels=unique_labels)\ndf_cm = pd.DataFrame(conf_mat, index = unique_labels,\n                     columns = unique_labels)\nplt.figure(figsize = (10,8))\nhm = sns.heatmap(df_cm,annot=True,fmt ='n')\nplt.title('Confusion Matrix')\n#sns.heatmap(df_cm, annot=True, cmap='viridis')\nhm.tick_params(labeltop=True,labelbottom=False,top=True,bottom=False)\nhm.set_xlabel('Model tahmini')\nhm.xaxis.set_label_position('top')\nhm.set_ylabel('ger\u00e7ek etiketi')\nplt.show()","92c88c4d":"# Dataset Metadata\nBurada UrbanSound meta veri .csv dosyas\u0131n\u0131 Panda veri \u00e7er\u00e7evesine y\u00fckleyece\u011fiz.","b28240e0":"**x(data)** \u2192 ses zaman serisi\n\n**sr(sample rate)** \u2192ses frekans\u0131(Hz)\n\nAyn\u0131 zamanda sesi y\u00fcklerken ses frekans\u0131n\u0131 de\u011fi\u015ftirerek y\u00fckleyebilirsiniz.","2a954302":"# Class distributions\n","8ca51fda":"Her s\u0131n\u0131ftan bir \u00f6rnek y\u00fckleyece\u011fiz ve verileri herhangi bir kal\u0131p i\u00e7in g\u00f6rsel olarak inceleyece\u011fiz. Ses dosyas\u0131n\u0131 bir diziye y\u00fcklemek i\u00e7in librosa'y\u0131 daha sonra dalga bi\u00e7imini g\u00f6r\u00fcnt\u00fclemek i\u00e7in librosa.display ve matplotlib'i kullanaca\u011f\u0131z.","c8956804":"Bu ses al\u0131nt\u0131lar\u0131, `.wav` format\u0131ndaki dijital ses dosyalar\u0131d\u0131r.\n","d83ce65f":"# Bit-depth\n\nAyr\u0131ca \u00e7ok \u00e7e\u015fitli bit derinlikleri vard\u0131r. Belirli bir bit derinli\u011fi i\u00e7in maksimum ve minimum genlik de\u011ferlerini alarak bunlar\u0131 normalle\u015ftirmemiz gerekebilir.","91330615":"# Audio channels\n\u00d6rneklerin \u00e7o\u011fu iki ses kanal\u0131na (stereo anlam\u0131nda) sahiptir ve birka\u00e7\u0131 sadece tek kanall\u0131 (mono).\n\nOnlar\u0131 tekd\u00fcze hale getirmenin en kolay yolu, iki kanal\u0131n de\u011ferlerinin ortalamas\u0131n\u0131 alarak, steroid \u00f6rneklerindeki iki kanal\u0131 bir kanalda birle\u015ftirmek olacakt\u0131r.","f769ec6a":"**Her dosya i\u00e7in MFCC'lerin \u00e7\u0131kar\u0131lmas\u0131**\n\n\u015eimdi veri k\u00fcmesindeki her ses dosyas\u0131 i\u00e7in bir MFCC \u00e7\u0131karaca\u011f\u0131z ve s\u0131n\u0131fland\u0131rma etiketiyle birlikte bir Panda Veri \u00c7er\u00e7evesinde saklayaca\u011f\u0131z.","a43635f7":"# 1. Data Exploration and Visualisation","0e861b6e":"**Normalle\u015ftirme gerektiren ses \u00f6zellikleri**\n* Audio Channels\n* Sample rate\n* Bit-depth\n\n\u00d6n i\u015fleme ve \u00f6zellik \u00e7\u0131karma i\u00e7in faydal\u0131 olacak Librosa'y\u0131 kullanmaya devam edece\u011fiz.","364533cc":"# 2. Data Preprocessing and Data Splitting","93c3a175":"# Feature Extraction refinement\n* \u00d6nceki \u00f6zellik \u00e7\u0131karma a\u015famas\u0131nda, MFCC vekt\u00f6rleri farkl\u0131 ses dosyalar\u0131 i\u00e7in boyut olarak de\u011fi\u015fecektir (\u00f6rneklerin s\u00fcresine ba\u011fl\u0131 olarak).\n* Ancak, CNN'ler t\u00fcm giri\u015fler i\u00e7in sabit bir boyut gerektirir. Bunun \u00fcstesinden gelmek i\u00e7in \u00e7\u0131kt\u0131 vekt\u00f6rlerini s\u0131f\u0131rlayarak hepsini ayn\u0131 boyutta yapaca\u011f\u0131z.","02800f98":"# 3. Model Training and Evaluation","62f93342":"# Audio sample file properties\nses \u00f6rnek dosyalar\u0131n\u0131n her birini yineleyip, ses kanallar\u0131n\u0131n say\u0131s\u0131n\u0131, \u00f6rnekleme h\u0131z\u0131n\u0131 ve bit derinli\u011fini \u00e7\u0131karaca\u011f\u0131z.","b50f2849":"### Initial model architecture - MLP\n* Keras ve Tensorflow arka u\u00e7 kullanarak \u00c7ok Katmanl\u0131 Alg\u0131lay\u0131c\u0131 (MLP) Sinir A\u011f\u0131 olu\u015fturmaya ba\u015flayaca\u011f\u0131z.\n* \u00dc\u00e7 katman, bir giri\u015f katman\u0131, bir gizli katman ve bir \u00e7\u0131kt\u0131 katman\u0131ndan olu\u015fan basit bir model mimarisiyle ba\u015flayaca\u011f\u0131z.\u00dc\u00e7 katman\u0131n tamam\u0131, \u00e7o\u011fu durumda sinir a\u011flar\u0131 i\u00e7in kullan\u0131lan standart bir katman t\u00fcr\u00fc olan yo\u011fun katman t\u00fcr\u00fcnde olacakt\u0131r.\n* \u0130lk katman giri\u015f \u015feklini alacakt\u0131r. Her \u00f6rnek 40 MFCC (veya s\u00fctun) i\u00e7erdi\u011finden (1x40) \u015feklinde bir \u015fekle sahibiz, bu da 40 giri\u015f \u015fekli ile ba\u015flayaca\u011f\u0131m\u0131z anlam\u0131na gelir.\n* \u0130lk iki katman 256 d\u00fc\u011f\u00fcme sahip olacakt\u0131r. \u0130lk 2 katman\u0131m\u0131z i\u00e7in kullanaca\u011f\u0131m\u0131z aktivasyon fonksiyonu ReLU veya Do\u011frultulmu\u015f Do\u011frusal Aktivasyondur. Bu aktivasyon i\u015flevinin sinir a\u011flar\u0131nda iyi \u00e7al\u0131\u015ft\u0131\u011f\u0131 kan\u0131tlanm\u0131\u015ft\u0131r.\n* Ayr\u0131ca ilk iki katman\u0131m\u0131za% 50'lik bir B\u0131rakma de\u011feri uygulayaca\u011f\u0131z. Bu, d\u00fc\u011f\u00fcmleri her g\u00fcncelleme d\u00f6ng\u00fcs\u00fcnden rasgele hari\u00e7 tutacak ve bu da, daha iyi genelleme yapabilen ve e\u011fitim verilerini daha d\u00fc\u015f\u00fck olas\u0131l\u0131kla daha az genelle\u015ftirebilen bir a\u011f ile sonu\u00e7lanacakt\u0131r.\n* \u00c7\u0131kt\u0131 katman\u0131m\u0131z, olas\u0131 s\u0131n\u0131fland\u0131rmalar\u0131n say\u0131s\u0131yla e\u015fle\u015fen 10 d\u00fc\u011f\u00fcme (say\u0131_etiketler) sahip olacakt\u0131r.Aktivasyon, \u00e7\u0131kt\u0131 katman\u0131m\u0131z\u0131n softmax olmas\u0131 i\u00e7indir. Softmax, \u00e7\u0131kt\u0131 toplam\u0131n\u0131 1'e \u00e7\u0131kar\u0131r, b\u00f6ylece \u00e7\u0131kt\u0131 olas\u0131l\u0131k olarak yorumlanabilir. Model daha sonra tahminini hangi se\u00e7ene\u011fin en y\u00fcksek olas\u0131l\u0131\u011fa sahip oldu\u011funa g\u00f6re yapacakt\u0131r.","39c00712":"**Bit-depth**\n\nLibrosa\u2019n\u0131n y\u00fckleme i\u015flevi de verileri normalle\u015ftirerek de\u011ferleri -1 ile 1 aras\u0131nda de\u011fi\u015fir. Bu, \u00e7ok \u00e7e\u015fitli bit derinliklerine sahip veri k\u00fcmesinin karma\u015f\u0131kl\u0131\u011f\u0131n\u0131 ortadan kald\u0131r\u0131r.","797c4581":"### Predictions","bf8c192b":"# Test the model\nBurada hem e\u011fitim hem de test veri setlerinde modelin do\u011frulu\u011funu g\u00f6zden ge\u00e7irece\u011fiz.","2fd1e0ca":"**Dikkate al\u0131nacak di\u011fer ses \u00f6zellikleri**\n\nBu a\u015famada, numune s\u00fcresi uzunlu\u011fu ve hacim seviyeleri gibi ba\u015fka fakt\u00f6rlerin de hesaba kat\u0131lmas\u0131 gerekip gerekmedi\u011fi hen\u00fcz net de\u011fildir.\n\nBu arada oldu\u011fu gibi devam edece\u011fiz ve hedef \u00f6l\u00e7\u00fcmlerimizin ge\u00e7erlili\u011fini etkiledi\u011fi d\u00fc\u015f\u00fcn\u00fcl\u00fcrse bunlar\u0131 daha sonra ele almak i\u00e7in geri gelece\u011fiz.","a3a3c9c0":"# Test the model\nBurada hem e\u011fitim hem de test veri setlerinde modelin do\u011frulu\u011funu g\u00f6zden ge\u00e7irece\u011fiz.","4466b964":"# Training\nBurada modeli e\u011fitece\u011fiz. Bir CNN e\u011fitimi \u00f6nemli miktarda zaman alabilece\u011finden, d\u00fc\u015f\u00fck say\u0131da d\u00f6nem ve d\u00fc\u015f\u00fck bir parti boyutu ile ba\u015flayaca\u011f\u0131z. Modelin yak\u0131nsad\u0131\u011f\u0131n\u0131 \u00e7\u0131kt\u0131dan g\u00f6rebilirsek, her iki say\u0131y\u0131 da art\u0131raca\u011f\u0131z.","f53c4fea":"# 4. Model Refinement\n\n\u0130lk denememizde, a\u015fa\u011f\u0131daki gibi bir S\u0131n\u0131fland\u0131rma Do\u011frulu\u011fu puan\u0131 elde etmeyi ba\u015fard\u0131k:\n\nE\u011fitim verileri Do\u011frulu\u011fu:% 92,3\n\nTest Verisi Do\u011frulu\u011fu:% 87 \n\n\u015eimdi bir Convolutional Neural Network (CNN) kullanarak bu puan\u0131 geli\u015ftirip geli\u015ftiremeyece\u011fimizi g\u00f6rece\u011fiz.","0d2029ad":"# Confusion Matrix","6ad03270":"# Predictions","abc9696f":"# Training","b6015b9a":"# **UrbanSound dataset**\n* Air Conditioner\n* Car Horn\n* Children Playing\n* Dog bark\n* Drilling\n* Engine Idling\n* Gun Shot\n* Jackhammer\n* Siren\n* Street Music","f99def0c":"****Sample rate conversion****\n\nVarsay\u0131lan olarak, Librosa\u2019n\u0131n y\u00fck i\u015flevi, \u00f6rnekleme oran\u0131n\u0131 kar\u015f\u0131la\u015ft\u0131rma d\u00fczeyimiz olarak kullanabilece\u011fimiz 22,05 KHz\u2019e d\u00f6n\u00fc\u015ft\u00fcr\u00fcr.","07079fcb":"**Merge audio channels**\n\nLibrosa ayr\u0131ca sinyali monoya d\u00f6n\u00fc\u015ft\u00fcrecektir, yani kanal say\u0131s\u0131 her zaman 1 olacakt\u0131r.","569ee8a5":"Ses analizi i\u00e7in a\u015fa\u011f\u0131daki kitapl\u0131klar\u0131 kullanaca\u011f\u0131z:\n\n1. **IPython.display.Audio**\n\n    Bu, sesi do\u011frudan Jupyter Not Defterinde \u00e7almam\u0131z\u0131 sa\u011flar.\n    \n2. **Librosa**\n\n    librosa, Brian McFee taraf\u0131ndan m\u00fczik ve ses i\u015fleme i\u00e7in bir Python paketidir ve not defterimize analiz ve manip\u00fclasyon i\u00e7in uyu\u015fmu\u015f bir dizi olarak ses y\u00fcklememizi sa\u011flar.","75ee1ab1":"Ses dosyalar\u0131n\u0131 \u00e7almak i\u00e7in ``IPython.display.Audio`` kullanaca\u011f\u0131z, b\u00f6ylece i\u015fitsel olarak inceleyebiliriz.","b1e451f6":"[Original notebook](https:\/\/github.com\/mikesmales\/Udacity-ML-Capstone) bu notebooktan yard\u0131m al\u0131narak haz\u0131rlanm\u0131\u015ft\u0131r.","e4d9f271":"# Extract Features\n\nMFCC, pencere boyutu boyunca frekans da\u011f\u0131l\u0131m\u0131n\u0131 \u00f6zetler, b\u00f6ylece sesin hem frekans hem de zaman \u00f6zelliklerini analiz etmek m\u00fcmk\u00fcnd\u00fcr. Bu sesli temsiller, s\u0131n\u0131fland\u0131rma i\u00e7in \u00f6zellikleri belirlememize izin verecektir.\n\nBunun i\u00e7in, zaman serisi ses verilerinden bir MFCC olu\u015fturan ``Librosa'n\u0131n mfcc ()`` i\u015flevini kullanaca\u011f\u0131z.","32ad8d85":"Bu, librosa'n\u0131n 173 \u00e7er\u00e7eve \u00fczerinde bir dizi 40 MFCC hesaplad\u0131\u011f\u0131n\u0131 g\u00f6stermektedir.","d871959c":"# Convolutional Neural Network (CNN) model architecture\n* Modelimizi yine Keras ve Tensorflow arka u\u00e7 kullanarak Evri\u015fimli Sinir A\u011f\u0131 (CNN) olacak \u015fekilde de\u011fi\u015ftirece\u011fiz.\n* Evri\u015fim katmanlar\u0131, \u00f6zellik tespiti i\u00e7in tasarlanm\u0131\u015ft\u0131r. Giri\u015fin \u00fczerinde bir filtre penceresi kayd\u0131rarak ve bir matris \u00e7arp\u0131m\u0131 ger\u00e7ekle\u015ftirerek ve sonucu bir \u00f6zellik haritas\u0131nda depolayarak \u00e7al\u0131\u015f\u0131r. Bu i\u015flem, evri\u015fim olarak bilinir.\n* Filter parametresi, her katmandaki d\u00fc\u011f\u00fcm say\u0131s\u0131n\u0131 belirtir. Her katman\u0131n boyutu 16, 32, 64'ten 128'e artarken, kernel_size parametresi \u00e7ekirdek penceresinin boyutunu belirtir ve bu durumda 2x2 filtre matrisiyle sonu\u00e7lan\u0131r.\n* Birinci katman, (40, 174, 1) giri\u015f \u015feklini alacakt\u0131r, burada 40, MFCC'lerin say\u0131s\u0131d\u0131r. 174, doldurmay\u0131 hesaba katan \u00e7er\u00e7eve say\u0131s\u0131d\u0131r ve 1, sesin mono oldu\u011funu belirtir.\n* Evri\u015fimli katmanlar\u0131m\u0131z i\u00e7in kullanaca\u011f\u0131m\u0131z aktivasyon fonksiyonu, \u00f6nceki modelimizle ayn\u0131 olan ReLU'dur. Evri\u015fimli katmanlar\u0131m\u0131zda% 20'lik daha k\u00fc\u00e7\u00fck bir B\u0131rakma de\u011feri kullanaca\u011f\u0131z.\n* Her evri\u015fimli katman, bir GlobalAveragePooling2D t\u00fcr\u00fcne sahip olan son evri\u015fimli katmanla birlikte MaxPooling2D t\u00fcr\u00fcnde ili\u015fkili bir havuz katman\u0131na sahiptir. Havuzlama katman\u0131, e\u011fitim s\u00fcresini k\u0131saltmaya ve a\u015f\u0131r\u0131 uyumu azaltmaya hizmet eden modelin boyutlulu\u011funu (parametreleri ve ilgili hesaplama gereksinimlerini azaltarak) azalt\u0131r. Maksimum Havuzlama t\u00fcr\u00fc, her pencere i\u00e7in maksimum boyutu al\u0131r ve Genel Ortalama Havuzlama t\u00fcr\u00fc, yo\u011fun \u00e7\u0131kt\u0131 katman\u0131m\u0131za beslemek i\u00e7in uygun olan ortalamay\u0131 al\u0131r.\n* \u00c7\u0131kt\u0131 katman\u0131m\u0131z, olas\u0131 s\u0131n\u0131fland\u0131rmalar\u0131n say\u0131s\u0131yla e\u015fle\u015fen 10 d\u00fc\u011f\u00fcme (say\u0131_etiketler) sahip olacakt\u0131r. Aktivasyon, \u00e7\u0131kt\u0131 katman\u0131m\u0131z\u0131n softmax olmas\u0131 i\u00e7indir. Softmax, \u00e7\u0131kt\u0131 toplam\u0131n\u0131 1'e \u00e7\u0131kar\u0131r, b\u00f6ylece \u00e7\u0131kt\u0131 olas\u0131l\u0131k olarak yorumlanabilir. Model daha sonra tahminini hangi se\u00e7ene\u011fin en y\u00fcksek olas\u0131l\u0131\u011fa sahip oldu\u011funa g\u00f6re yapacakt\u0131r.","b90b5ee4":"# Split the dataset\nBurada veri setini e\u011fitim ve test setlerine ay\u0131rmak i\u00e7in sklearn.model_selection.train_test_split kullanaca\u011f\u0131z. Test seti boyutu% 20 olacak ve rastgele bir durum belirleyece\u011fiz.","7555455c":"# Sample rate\n\nEndi\u015fe verici olan t\u00fcm numunelerde kullan\u0131lan \u00e7ok \u00e7e\u015fitli Numune oranlar\u0131 vard\u0131r (96k ila 8k aras\u0131nda de\u011fi\u015fen).\n\nBu benzer \u015fekilde, bir \u00f6rnekleme oran\u0131 d\u00f6n\u00fc\u015ft\u00fcrme tekni\u011fi (yukar\u0131 d\u00f6n\u00fc\u015ft\u00fcrme veya a\u015fa\u011f\u0131 d\u00f6n\u00fc\u015ft\u00fcrme) uygulamam\u0131z gerekti\u011fi anlam\u0131na gelir, b\u00f6ylece adil bir kar\u015f\u0131la\u015ft\u0131rma yapmam\u0131za olanak sa\u011flayacak dalga bi\u00e7imlerinin agnostik bir temsilini g\u00f6rebiliriz.","c504b3b8":"Ses dalgalar\u0131, \u00f6rnekleme h\u0131z\u0131 olarak bilinen ayr\u0131 aral\u0131klarla \u00f6rneklenerek say\u0131salla\u015ft\u0131r\u0131l\u0131r (tipik olarak CD kalitesinde ses i\u00e7in 44.1 kHz, yani \u00f6rnekler saniyede 44.100 kez al\u0131n\u0131r).\n\nHer \u00f6rnek, belirli bir zaman aral\u0131\u011f\u0131ndaki dalgan\u0131n genli\u011fidir; burada bit derinli\u011fi, \u00f6rne\u011fin sinyalin dinamik aral\u0131\u011f\u0131 olarak da bilinen ne kadar ayr\u0131nt\u0131l\u0131 olaca\u011f\u0131n\u0131 belirler (tipik olarak 16 bit, bu, bir \u00f6rne\u011fin 65,536 genlik de\u011ferlerinden de\u011fi\u015febilece\u011fi anlam\u0131na gelir).","2a8f950f":"**Convert the data and labels**\n\nKategorik metin verilerini model taraf\u0131ndan anla\u015f\u0131labilir say\u0131sal verilere kodlamak i\u00e7in ``sklearn.preprocessing.LabelEncoder``'\u0131 kullanaca\u011f\u0131z.","77eb8801":"# Compiling the model\n\nModelimizi derlemek i\u00e7in a\u015fa\u011f\u0131daki \u00fc\u00e7 parametreyi kullanaca\u011f\u0131z:\n* Kay\u0131p i\u015flevi - categorical_crossentropy kullanaca\u011f\u0131z. Bu, s\u0131n\u0131fland\u0131rma i\u00e7in en yayg\u0131n se\u00e7imdir. Daha d\u00fc\u015f\u00fck bir puan, modelin daha iyi performans g\u00f6sterdi\u011fini g\u00f6sterir.\n* Metrikler - Modeli e\u011fitirken do\u011frulama verilerindeki do\u011fruluk puan\u0131n\u0131 g\u00f6r\u00fcnt\u00fclememizi sa\u011flayacak do\u011fruluk \u00f6l\u00e7\u00fcs\u00fcn\u00fc kullanaca\u011f\u0131z.\n* Optimizer - burada bir\u00e7ok kullan\u0131m durumu i\u00e7in genellikle iyi bir optimize edici olan Adam'\u0131 kullanaca\u011f\u0131z.","e6797ca9":"## Compiling the model\n\nModelimizi derlemek i\u00e7in, \u00f6nceki modelle ayn\u0131 \u00fc\u00e7 parametreyi kullanaca\u011f\u0131z:","d0b1881b":"Burada S\u0131n\u0131f etiketlerinin dengesiz oldu\u011funu g\u00f6rebiliriz. 10 s\u0131n\u0131ftan 7'sinin tam olarak 1000 \u00f6rne\u011fi olmas\u0131na ve siren 929 ile \u00e7ok uzakta olmamas\u0131na ra\u011fmen, geri kalan iki tanesi (car_horn, gun_shot) s\u0131ras\u0131yla% 43 ve% 37 ile \u00f6nemli \u00f6l\u00e7\u00fcde daha az \u00f6rne\u011fe sahiptir.","3ef6c9f2":"# **G\u00f6zlemler**\n* G\u00f6rsel bir incelemeden, baz\u0131 s\u0131n\u0131flar aras\u0131ndaki fark\u0131 g\u00f6rselle\u015ftirmenin zor oldu\u011funu g\u00f6rebiliriz.\n* \u00d6zellikle klima, delme, motor r\u00f6lantisi ve k\u0131r\u0131c\u0131 i\u00e7in tekrarlanan sesler i\u00e7in dalga formlar\u0131 benzer \u015fekildedir.\n* Benzer \u015fekilde, k\u00f6pek havlama \u00f6rne\u011findeki pik, \u015fekil olarak silahla vurulan \u00f6rne\u011fe benzerdir (\u00f6rnekler, bir k\u00f6pek havlamas\u0131 i\u00e7in bir pik ile kar\u015f\u0131la\u015ft\u0131r\u0131ld\u0131\u011f\u0131nda iki silah at\u0131\u015f\u0131 i\u00e7in iki pik olmas\u0131 bak\u0131m\u0131ndan farkl\u0131l\u0131k g\u00f6sterse de). Ayr\u0131ca, araba kornas\u0131 da benzerdir.\n* Sokak m\u00fczi\u011fi ile oynayan \u00e7ocuklar aras\u0131nda da benzerlikler vard\u0131r.\n* \u0130nsan kula\u011f\u0131, harmonikler aras\u0131ndaki fark\u0131 do\u011fal olarak alg\u0131layabilir, bir derin \u00f6\u011frenme modelinin bu s\u0131n\u0131flar\u0131 birbirinden ay\u0131rmak i\u00e7in gerekli \u00f6zellikleri ne kadar iyi \u00e7\u0131karabilece\u011fini g\u00f6rmek ilgin\u00e7 olacakt\u0131r.\n* Bununla birlikte, dalga \u015fekli \u015feklinden, k\u00f6pek havlamas\u0131 ve k\u0131r\u0131c\u0131 gibi belirli s\u0131n\u0131flar aras\u0131ndaki fark\u0131 ay\u0131rt etmek kolayd\u0131r."}}