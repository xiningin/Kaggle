{"cell_type":{"dc627a62":"code","7bc98d24":"code","5fbedec6":"code","3c43530f":"code","81c4ad22":"code","4dcb5796":"code","0aa85120":"code","78ac6b76":"code","fb8f9b82":"code","3272e885":"code","06e58084":"code","e424aa8f":"code","ec53f0b6":"code","392f1f8e":"code","c2ab8e47":"code","7a9f37e4":"code","54b51513":"code","339adaaf":"code","c4cfdf42":"code","3fc542ef":"code","a600f343":"code","c5ae99ac":"code","b6b82fdb":"code","919ca7ed":"markdown","dfcd0b49":"markdown","cc6e06f5":"markdown","e1ee3f1c":"markdown","038e40b1":"markdown","2302a177":"markdown","058fd18f":"markdown","b0dd9d59":"markdown","971219d1":"markdown","c3e32e68":"markdown","a7359387":"markdown","f70f3461":"markdown","892bf2ad":"markdown","6ec150f6":"markdown"},"source":{"dc627a62":"import numpy as np\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Some styling choices for graphs\nsns.set_style('darkgrid')\nsns.set_palette('deep')","7bc98d24":"# Read the .csv file into a pandas df\nfilename = '\/kaggle\/input\/80-cereals\/cereal.csv'\ncereal_df = pd.read_csv(filename)\ncereal_df","5fbedec6":"# Check for NaN values \nprint('NaN values:', cereal_df.isnull().values.any())\n# get general information on each column\ncereal_df.info()","3c43530f":"# Get the basic statsistics of the columns\ncereal_df.describe()","81c4ad22":"# convert -1 values to NaN\ncereal_df = cereal_df.applymap(lambda x: np.nan if x == -1 else x)\n# use panda's .dropna() with the default values to drop any row with NaN values\ncereal_df = cereal_df.dropna(axis='index', how='any')\ncereal_df","4dcb5796":"cereal_df = cereal_df.drop(['shelf','rating'],axis=1)","0aa85120":"print('weight \\n', cereal_df['weight'].value_counts(), '\\n')\n\nprint('cups \\n', cereal_df['cups'].value_counts())","78ac6b76":"# copy the dataset so far for further consideration\nnon_normal_df = cereal_df.copy()\n\n# create a new dataset from only the numerical columns\nnum_df = cereal_df.select_dtypes(include=[np.number])\n# normalize each row by its corresponding weight to 1.0 ounce\nweight_norm_df = num_df.div(num_df['weight'], axis='rows')\n# check that our normalization worked, all weights should be 1.0\nprint('weight \\n', weight_norm_df['weight'].value_counts())","fb8f9b82":"# replace the original numerical columns with the weight normalized values\ncereal_df[weight_norm_df.columns] = weight_norm_df\n# We can drop the weight and cups columns now. All weight values are 1.0 and cups are irrelevant\ncereal_df.drop(columns=['weight','cups'], axis=1, inplace=True)","3272e885":"sns.set_context('talk', font_scale = 1.6) \n\nceral_g = sns.PairGrid(cereal_df, corner=True)\n# different plot to use on the diagonal\nceral_g.map_diag(plt.hist)\n# type of plot for lower half of the grid\nceral_g.map_lower(plt.scatter)","06e58084":"# As mentioned, normalizing by weight caused some new vitamin values to be created\n# we should round up the values to be readable.\ncereal_df['vitamins'] = cereal_df['vitamins'].round(1)\n\n# seaborn size setting\nsns.set_context('paper',font_scale = 1.8)\n\n# It's good practice to wrap graphs in functions\n# but the PairGrid is already a streamlined graph cal\ncereal_g = sns.PairGrid(cereal_df, hue='vitamins',\n                       x_vars=['fiber','protein'],\n                       y_vars=['potass'],\n                       height=6, aspect=1,\n                       palette='hls',\n                       )\n# use scatter plots for our grid\ncereal_g.map(plt.scatter,**{'edgecolor':'k', 's':80, 'linewidth':1.6}) # changing symbols on plot\ncereal_g.add_legend(title='Vitamins (% of Daily)')\n\n# nice labels\ncereal_g.axes[0,0].set_xlabel('Fiber (grams)')\ncereal_g.axes[0,1].set_xlabel('Protein (grams)')\ncereal_g.axes[0,0].set_ylabel('Potassium (miligrams)')\nplt.savefig('Good_variables.png')","e424aa8f":"# Use for loop to apply a simple lambda function conversion to \n# each column.\ncol_list = ['fat','sugars']\ncal_conv = [9,4]\nfor col,val in zip(col_list, cal_conv):\n    cereal_df[col] = cereal_df[col].apply(lambda x: x*val)","ec53f0b6":"# Create a new column so we can mark those samples \n# which meet the sugar limit and those that don't.\ncereal_df['sugars_criteria'] = cereal_df.apply(lambda row: 1 if row.sugars\/row.calories < 0.1 else 0, axis=1)","392f1f8e":"# The recommended intake of salt is 2300 mg\n# While daily caloric intake is more varied, let's use 2000 calories as our estimator.\ndaily_cal = 2000\ndaily_salt = 2300\n\n\n### This function has very little generality \n#   but it is good practice to keep all these functions in one place\n#   so that calling them is clean. ###\ndef cal_compare_df(input_df, col='sugars'):\n    \n    \n    \"\"\"\n    Removes rows from a DataFrame that are selected by a given variable criteria.\n    For fats and sugars, that is more than 10% of total calories.\n    For vitamins and sodium it is the proportion of daily intake compared to percentage of daily \n    calorie intake.\n\n    Parameters\n    ----------\n    input_df: pd.DataFrame\n        The DataFrame for manipulation.\n    col: str\n        The desired variable by which to limit the dataset. \n        \n    Returns\n    -------\n    output_df: pd.DataFrame\n        The rows from the input DataFrame which satisfy a given variable criteria.\n    \n    \"\"\"\n    \n    \n    ### input handling ###\n    if type(col) != str:\n        raise TypeError('Please input a column name as a str.')\n        \n    output_df = input_df.copy()\n    \n    ### Amount of sodium intake in proportion to amount of daily calorie intake\n    if col == 'sodium':\n        output_df[col] = output_df.apply(lambda row: row[col] if (row.sodium\/daily_salt) < (row.calories\/daily_cal) else np.NaN, axis=1)\n\n        \n    ### Amount of vitamins in proportion to amount of daily calorie intake\n    elif col == 'vitamins':\n        output_df[col] = output_df.apply(lambda row: row[col] if (row.calories\/daily_cal) < row[col] else np.NaN, axis=1)\n    ### fats and sugars, selected to be less than 10 percent of total calories \n    else:\n        output_df[col] = output_df.apply(lambda row: row[col] if row[col]\/row.calories < 0.1 else np.NaN, axis=1)\n        \n    return output_df.dropna(axis='index', how='any')","c2ab8e47":"# Defining a simple linear line that is the selection limit of fat and sugars\n# x is 1\/10 of y.\nx_line_10 = np.linspace(-0,70)\ny_line_10 = x_line_10*10\n\ndef cal_compare_plot(df, title=None, col='sugars', ylabel=False, legend=False):\n    \n    \"\"\"\n    Scatter plot for given input column versus calories.\n    \n    Parameters\n    ----------\n    df: pd.DataFrame\n        Input DataFrame with a '_criteria' column with 0\/1 values. 0 are 'bad' samples while 1 are 'good'.\n    title: str\n        Include a title of input str, or None for no title.\n    col: str\n        The x axis, also selects the correct '_criteria' to use.\n    ylabel: bool\n        Include a ylabel or not.   \n    legend: bool\n        Include a legend or not.\n\n    \"\"\"\n    \n\n    ### This simple method uses c vector to plot \n    # the different criteria samples so class\n    # but it makes a legend difficult.\n    \n#     plt.scatter(df[col], df['calories'],c=df[col+'_criteria'], cmap='Set1_r',s=60,\n#            edgecolor='k',linewidth=1.8)\n\n    ### Instead split the '_criteria' 0 and 1 values into different samples for cleaner plotting. \n\n    # Plot the decision boundary\/ criteria limit\n    plt.plot(x_line_10, y_line_10, linewidth=4, linestyle='--', color='k')\n\n    # get those samples which satisfy the criteria\n    x1 = df[col].loc[df[col+'_criteria'] == 1]\n    y1 = df['calories'].loc[df[col+'_criteria'] == 1]\n    \n    # plot them as green\n    # zorder is so that the point are ontop of the linear line\n    plt.scatter(x1, y1, color='g',s=70,\n           edgecolor='k',linewidth=1.8, label='Good',zorder=20)\n    \n    # get those samples which do not satisfy the criteria\n\n    x0 = df[col].loc[df[col+'_criteria'] == 0]\n    y0 = df['calories'].loc[df[col+'_criteria'] == 0]\n    # plot them as red\n    plt.scatter(x0, y0, color='r', s=70,\n           edgecolor='k', linewidth=1.8, label='Bad', zorder=20)\n\n    plt.ylim(40,160)\n    plt.xlim(-5,65)\n    plt.title(title)\n    \n    plt.xlabel('Sugars (calories)')\n    if ylabel:\n        plt.ylabel('Calories (per serving)')\n    else:\n        plt.gca().set(yticklabels=[])\n        \n    if legend:\n        plt.legend(loc='lower right')\n","7a9f37e4":"sns.set_context('paper', font_scale = 1.6)\n\n# plot the first plot seperate from a for loop to include ylabel and legend\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))\nplt.sca(axes[0])\ncal_compare_plot(cereal_df, title='All Samples', ylabel=True, legend=True)\n\n# use a for loop to quickly plot the three additional selected samples\nselect_list = ['fat','sodium','vitamins']\ntitle_list = ['Fat Selected', 'Sodium Selected', 'Vitamins Selected']\n\nfor i, (col, title) in enumerate(zip(select_list, title_list)):\n    \n    plt.sca(axes[i+1])\n    select_df = cal_compare_df(cereal_df, col=col)\n    cal_compare_plot(select_df)\n    plt.title(title)\n\nplt.savefig('Bad_variables_selected.png')\n# plt.tight_layout()","54b51513":"def cereal_ranker(input_df, bins=8):\n    \n    \n    \"\"\"\n    Assigns a metric score for the binned variable columns. \n    Columns are currently hard coded, but can be easily changed in this function.\n    A higher rank score is 'healthier'.\n\n    Parameters\n    ----------\n    input_df: pd.DataFrame\n        The DataFrame for manipulation.\n    bins: int\n        How many bins to separate column values into.\n        \n    Returns\n    -------\n    work_df: pd.DataFrame\n        The DataFrame will have a 'rank' column. Rank column is the summed columned scores for the \n        variable columns. A higher rank score is 'healthier'.\n\n    \n    \"\"\"\n    \n    \n    cols = ['vitamins','protein', 'potass', 'fiber', 'fat', 'sodium', 'sugars']\n    # max if higher value is healthier, min if higher value is unhealthier. \n    order_method = ['max','max','max','max','min','min','min']\n        \n    work_df = input_df.copy()\n    work_df['rank'] = 0 # add the rank column as zeros first\n    \n    # The vitamins column bins poorly, recall most values are 25, with values also at 0 and 100.\n    # Instead convert vitamins scores into integers on the range of 1 to len(unique(vitamins))\n    # this allows for better results when binning.\n    \n    conv_array = np.unique(work_df['vitamins'])\n    # create a dict to filter vitamins values with a lambda function\n    conv_dict = dict(zip(conv_array,np.arange(1, len(conv_array)+1))) \n    work_df['vitamins'] = work_df.apply(lambda row: conv_dict[row.vitamins], axis=1 )\n    \n    # loop over columns\n    for name, selector in zip(cols, order_method):\n        # the bin scores which will be applyed to samples\n        labels = np.arange(1, bins+1)\n\n        if selector == 'min':\n            # reverse if min, high values should give low score\n            labels = labels[::-1]\n        \n        # pd.cut is used for binning. It out puts a categorical Series. So convert to \n        # numpy for easy summation. \n        work_df['rank'] += pd.cut(work_df[name], bins, labels=labels).to_numpy()\n\n    return work_df","339adaaf":"ranked_df = cereal_ranker(cereal_df, bins=8).sort_values('rank', ascending=False)\nranked_df.head(8)","c4cfdf42":"ranked_df","3fc542ef":"def rank_scatter(input_df,x,y, colorbar=False):\n    \"\"\"\n    Scatter plot for input x and y columns. Colored by metric scores.\n    \n    Parameters\n    ----------\n    df: pd.DataFrame\n        Input DataFrame with a 'rank' column\n    x: str\n        Column from input_df to use for x-axis.\n    y: str\n        Column from input_df to use for y-axis\n    colobar: bool\n        Include a colorbar or not.\n\n    \"\"\"\n    x_vals = input_df[x]\n    y_vals = input_df[y]\n    c_vec = input_df['rank']\n    plt.scatter(x_vals, y_vals, c=c_vec, cmap='jet_r',s=80, edgecolor='k', linewidth=2.5)\n    \n    if colorbar:\n        cbar = plt.colorbar()\n        cbar.set_label('Metric Score', labelpad=10)","a600f343":"fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n\nplt.sca(axes[0])\nrank_scatter(ranked_df,'sugars','calories')\nplt.xlabel('Sugars (calories)')\nplt.ylabel('Calories (per serving)')\n\nplt.sca(axes[1])\nrank_scatter(ranked_df,'protein','fiber', colorbar=True)\nplt.xlabel('Fiber (grams)')\nplt.ylabel('Protein (grams)')\n\nplt.tight_layout()\nplt.savefig('Metric_plot.png')","c5ae99ac":"cup_norm_df = non_normal_df.copy() # call down our non-normalized dataset \nnum_df = cup_norm_df.select_dtypes(include=[np.number]) # grab numeric cols\nweight_norm_df = num_df.div(num_df['cups'], axis='rows') # normalize by cup size\ncup_norm_df[weight_norm_df.columns] = weight_norm_df # add back into df \ncup_norm_df.drop(columns=['weight','cups'], axis=1, inplace=True) # drop weight and cups col\n\n# We have to redo fat and sugar conversion to calories\ncol_list = ['fat','sugars']\ncal_conv = [9,4]\nfor col,val in zip(col_list,cal_conv):\n    cup_norm_df[col] = cup_norm_df[col].apply(lambda x: x*val)\n    \n# again round the vitamins col\ncup_norm_df['vitamins'] = cup_norm_df['vitamins'].round(1)\n\ncup_scored_df = cereal_ranker(cup_norm_df, bins=8).sort_values('rank', ascending=False)\ncup_scored_df","b6b82fdb":"fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n\nplt.sca(axes[0])\nrank_scatter(cup_scored_df,'sugars','calories')\nplt.xlabel('Sugars (calories)')\nplt.ylabel('Calories')\n\nplt.sca(axes[1])\nrank_scatter(cup_scored_df,'protein','fiber', colorbar=True)\nplt.xlabel('Fiber (grams)')\nplt.ylabel('Protein (grams)')\n\nplt.tight_layout()","919ca7ed":"# Introduction\nLet's find the best 5 cerals among the dataset using the guildelines outlined in the US Governments Dietary\nGuidelines\u2019 Executive Summary: https:\/\/health.gov\/sites\/default\/files\/2019-10\/DGA_Executive-Summary.pdf\n\nFields in the dataset:\n\n    Name: Name of cereal\n    mfr: Manufacturer of cereal\n        A = American Home Food Products;\n        G = General Mills\n        K = Kelloggs\n        N = Nabisco\n        P = Post\n        Q = Quaker Oats\n        R = Ralston Purina \n    type:\n        cold\n        hot \n    calories: calories per serving\n    protein: grams of protein\n    fat: grams of fat\n    sodium: milligrams of sodium\n    fiber: grams of dietary fiber\n    carbo: grams of complex carbohydrates\n    sugars: grams of sugars\n    potass: milligrams of potassium\n    vitamins: vitamins and minerals - 0, 25, or 100, indicating the typical percentage of FDA recommended\n    shelf: display shelf (1, 2, or 3, counting from the floor)\n    weight: weight in ounces of one serving\n    cups: number of cups in one serving\n    rating: a rating of the cereals (Possibly from Consumer Reports?)\n\n\nThe following curl command will download the dataset to the current folder. I have turned this cell into a markdown cell as running unknown curl commands are a security hazard. Please make sure the `cereal.csv` file is present in the current working folder. \n","dfcd0b49":"# Libraries\nLet's use only pandas and numpy for this analysis. ","cc6e06f5":"The dashed line represents the threshold of 10% of the calories being sugar. The green dots are those with samples with <10% while the red dots are those with >10%. \nUnfortunately, one can see when we remove those samples which do not fit other criteria (e.g., sodium above the recommended amount) there are no 5 cereals which satisfy all guidelines. \n\nSo there are no obvious, healthy cereals which stand above the others.\nInstead let's select the best ones we can. <b> We can define a metric <\/b> by giving a score for each sample calculated from a sum of its rank in each variable column. To ensure good scoring, instead of using the position of each sample in a sorted column for a score value, we can bin the column value ranges and give each sample a value in that column based on which bin it falls into. \n\nTo clarify, the vitamins column has ~50 samples with a value of 25. Those 50 values are tied, but would have a different score based on how they would appear in the sorted column despite having the same value. Instead, if we bin the data and give each of the 50 mentioned samples a score value of (for example) 5 this would give much better results. \n\nFinally, let's calculate it so that <b>a higher metric score is 'healthier'.<\/b>","e1ee3f1c":"There doesn't seem to be a strong selection for our 'good' variables, the values with the best protein do not have the highest vitamin percentage, or potassium. The higher values of fiber do not have a strong presence of vitamins as well. The 'best' cereals do not clearly standout.\n\nLet us consider the limits the guidelines emphasize for our 'bad' variables.\n\nTo consider fat and sugars as a percentage of calories, convert them to calories based on the FDA given conversion of each. 1 gram of fat is 9 calories, 1 gram of sugar is 4 calories. ","038e40b1":"# First Look","2302a177":"Now we can finally give <b>5 best cereals<\/b>. There are 4 samples tied for the 5th cereal but I use the one that appears first in the sort.\nThe 5 best cereals are:\n\n- <b>3 All-Bran with Extra Fiber<\/b>\n- <b>0 100% Bran<\/b>\n- <b>2 All-Bran<\/b>\n- <b>64 Shredded Wheat 'n'Bran<\/b>\n- <b>26 Frosted Mini-Wheats <\/b>\n\nAnd we can see that our metric score works well because the bottom scores are sugary, clearly unhealthy cereals. And as the metric score decreases the cereals become generally more unhealthy (increased sugars, fats, decreased protein, etc.)\n","058fd18f":"We can see that while no column has NaN values, several columns use -1 as a value to represent missing information. For machine learning problems we could use different methods to replace the missing values such as using the column or manufacturer mean or simply replacing the value with zero. \n\nHowever, for consideration of which cereals best fit the dietary guidelines we will disregard cereals with any missing values as there is a large amount on uncertainty for replacement in this dataset.","b0dd9d59":"The top 3 cereals are the same in both normalizations with the bottom cereals being roughly the same as well. However, when we plot the cup normalized dataset we do not see the gradient of scores we see in the weight normalized dataset, with clearly higher scores towards healthier metrics. Thus I am happy to use the weight normalized dataset to give our top 5 cereals.","971219d1":"# Selection\n\nThey key recommendations from the Dietary Guidelines are: \n1. Focus on nutrient density, variety, and amount. \n2. Limit calories from added sugars and saturated fats and reduce sodium intake\n\nVariety and amount refer to food selection in general and are not relevant to our cereal selection.<b> Nutrient Dense <\/b> foods, are those that are high in natural minerals, vitamins, and other naturally occurring substances such as fiber. Therefore we should have a preference for cereals high in protein, fiber, potassium, and 'vitamins'. \n\nMore strict guidelines are given for sugars, saturated fats, and sodium.\n\n- Consume less than 10 percent of calories per day from added sugars\n- Consume less than 10 percent of calories per day from saturated fats\n- Consume less than 2,300 milligrams (mg) per day of sodium\n\n\nTo get started, let's first take a look at our \"good\" variables: protein, fiber, potassium,  and 'vitamins'.\nVitamins appear to be more categorical (there were only 3 values before our weight normalization created a few more). As fiber and potassium see strongly correlated, we can plot protein against potassium and it will give us a general sense of the relation to fiber.","c3e32e68":"Another benefit we get from using a metric score to rank our cereals is that it allows us to clearly plot the distribution. We can see that metric scores tend to increase towards lower 'bad' variables like sugar, and increase towards higher 'good' variables like fiber and protein. So <b>the metric score gives us an indicator of how healthy a cereal is in relation to all variables<\/b>.","a7359387":"Finally, we should consider that the cereals listed are defined as <b>one serving<\/b>. However, there is no uniform definition to serving size by cups or weight. We note though that the majority of samples have weight 1.0, while amount of cups per serving is more varied. Based on this, let's normalize the sample information to 1.0 ounce of weight. It is important that we normalize the sample values to a weight or volume metric for impartial comparison. ","f70f3461":"There is still a lot of information to process. Let's throw all the columns into a large `seaborn PairGrid` and see if there are any correlations that stick out. \n\nWhat is most clear is that Potassium and Fiber are strongly correlated. And it seems that Vitamins is poorly distributed. \nCarbohydrates are related to sugars, but carbohydrates are not a consideration in our current guidelines (more details soon).","892bf2ad":"We can see that one row with a -1 value `iloc[4]: Almond Delight` has been dropped, as well as 3 rows in total (77 rows to 74 now). Great.\n\nNext, we should drop the columns for `shelf` and `rating` since they are irrelevant to our consideration. (`rating` is a none defined rating from possibly some consumer report. Let's not use metrics that we don't understand and are not cited).","6ec150f6":"_________________________________________________________________________________________________\n------\n# Bonus\n\nOne decision we made was to normalize our dataset by weight. Would we get different results if we normalized by cup size? Normalizing by cup size seems to have preference towards denser, heavy cereals which possibly include things such as dried fruits. "}}