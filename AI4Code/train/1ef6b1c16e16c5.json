{"cell_type":{"5ac877f0":"code","cc69b469":"code","39fc7aa1":"code","730895c2":"code","d8d96b07":"code","6b0b8559":"code","fb7c5b0b":"code","2237e0c7":"code","dcc47f4b":"code","fcf91a0f":"code","4e8fd28e":"code","e0398a3a":"code","48187f4e":"code","03d7018e":"code","3f6a92a4":"code","c0b7e90d":"code","e4985c1e":"code","6463f15b":"code","a671e540":"code","967724dd":"code","053a8f21":"code","11ea3355":"code","350c1e10":"code","7a345521":"code","b480a7d2":"code","4cf036ae":"code","b87fc4cb":"code","3159d3ee":"code","2d8d3408":"code","6ca72dd4":"code","2530e1f9":"code","6d4c3f41":"code","98b82b37":"code","864a1717":"code","fc90b32a":"code","b90fd57c":"code","eab21479":"code","232193d5":"code","921fe0af":"code","4c2e9219":"markdown","07f35270":"markdown","62422003":"markdown","72c94a4c":"markdown","affacfe0":"markdown","0097038f":"markdown","b33028dd":"markdown","4b3f477b":"markdown","df374db3":"markdown","f6849513":"markdown","dcdf5fdc":"markdown","a44945bd":"markdown","4eff44c6":"markdown","b8dd2bcc":"markdown","5e0e635c":"markdown","6184affc":"markdown","d3c053e2":"markdown","d7faa52d":"markdown","e5d83971":"markdown","5b2b36db":"markdown","09466d73":"markdown","fdb6cf07":"markdown","fd524d7f":"markdown","fb7898f5":"markdown","f8d7b23a":"markdown","578f2161":"markdown","9f95f272":"markdown","5a4de439":"markdown","84ca1e4d":"markdown","f4ddbff8":"markdown"},"source":{"5ac877f0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\ntrain_set = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_set = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","cc69b469":"train_set.head()","39fc7aa1":"print(f'train shape is: {train_set.shape}')\nprint(f'test shape is: {test_set.shape}')","730895c2":"X = train_set.drop('label', axis=1)\nlabels = train_set['label']","d8d96b07":"y = pd.get_dummies(labels)","6b0b8559":"print(y.iloc[:6,:])\nprint(f\"y shape:{y.shape}\")","fb7c5b0b":"X = X \/ 255.0\ntest_set = test_set \/ 255.0","2237e0c7":"X = X.values.reshape(-1,28,28,1)\ntest_set = test_set.values.reshape(-1,28,28,1)","dcc47f4b":"print(f\"X:{X.shape} y:{y.shape}\")","fcf91a0f":"from sklearn.model_selection import train_test_split\n\nX_train,X_val, y_train, y_val = train_test_split(X,y,test_size=0.2, random_state=42)","4e8fd28e":"batch_size = 32\nepochs=50","e0398a3a":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nsimple_NN = keras.Sequential([\n    layers.Dense(100, activation='relu', input_shape=(28,28,1)),\n    layers.Dropout(0.3),\n    layers.Flatten(),\n    layers.Dense(units=100, activation='relu'),\n    layers.Dense(units=10, activation='softmax')\n])\n\n","48187f4e":"simple_NN.summary()","03d7018e":"\nsimple_NN.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nsimple_NN.optimizer.lr=0.001\n","3f6a92a4":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","c0b7e90d":"lrr = ReduceLROnPlateau(monitor='val_loss',patience=3,verbose=1,factor=0.5, min_lr=0.00001)","e4985c1e":"\nhistory_simple_NN = simple_NN.fit(\n    x=X_train,\n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=batch_size,\n    epochs=epochs,\n    shuffle=True,\n    verbose=2,\n    callbacks=[early_stopping, lrr]\n)\n","6463f15b":"def plot_loss_and_accuracy(history):\n    history_df = pd.DataFrame(history)\n    history_df.loc[0:, ['loss', 'val_loss']].plot()\n    history_df.loc[0:, ['accuracy', 'val_accuracy']].plot()","a671e540":"plot_loss_and_accuracy(history_simple_NN.history)","967724dd":"\nimport keras\nfrom tensorflow.keras import layers\n\n\nCNN = keras.Sequential([\n    layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n    layers.Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.Flatten(),\n    layers.Dense(10, activation='softmax')\n])\n\n","053a8f21":"CNN.summary()","11ea3355":"CNN.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nCNN.optimizer.lr=0.001","350c1e10":"history_CNN = CNN.fit(\n    x=X_train, \n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=batch_size,\n    epochs=epochs,\n    shuffle= True,\n    verbose=2,\n    callbacks=[early_stopping, lrr]\n)","7a345521":"plot_loss_and_accuracy(history_CNN.history)","b480a7d2":"import keras\nfrom tensorflow.keras import layers\n\nCNN_2 = keras.Sequential([\n    layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Flatten(),\n    layers.Dropout(0.4),\n    layers.Dense(10, activation='softmax')\n])","4cf036ae":"CNN_2.summary()","b87fc4cb":"CNN_2.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nCNN.optimizer.lr=0.001","3159d3ee":"history_CNN_2 = CNN_2.fit(\n    x=X_train, \n    y=y_train,\n    validation_data=(X_val, y_val),\n    batch_size=batch_size,\n    epochs=epochs,\n    shuffle= True,\n    verbose=2,\n    callbacks=[early_stopping, lrr]\n)","2d8d3408":"plot_loss_and_accuracy(history_CNN_2.history)","6ca72dd4":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False,\n    validation_split=0.2\n)\n\ndatagen.fit(X_train)\n","2530e1f9":"data_size = len(X_train) \nsteps_per_epoch = int(data_size \/ batch_size)\nprint(steps_per_epoch)","6d4c3f41":"history_CNN_2_datagen = CNN_2.fit(\n    datagen.flow(X_train,y_train,batch_size=batch_size),\n    epochs=epochs,\n    shuffle=True,\n    validation_data=(X_val,y_val),\n    verbose=2,\n    callbacks=[early_stopping, lrr],\n    steps_per_epoch=steps_per_epoch\n)","98b82b37":"plot_loss_and_accuracy(history_CNN_2_datagen.history)","864a1717":"val_predictions = CNN_2.predict(X_val)\ny_pred = val_predictions.argmax(axis=-1)","fc90b32a":"cm_plot_labels = [x for x in range(10)]\nprint(cm_plot_labels)","b90fd57c":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_val.idxmax(axis=1), y_pred)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=cm_plot_labels)\n\ndisp = disp.plot(include_values=True,\n                 cmap=plt.cm.Blues, ax=None, xticks_rotation='horizontal')\n\nplt.show()","eab21479":"import matplotlib.pyplot as plt\n\nrows = 5\ncols = 9\n\nf = plt.figure(figsize=(2*cols,2*rows))\nsub_plot = 1\n#y_val_array = y_val.values\ny_val_array = y_val.idxmax(axis=1).values\n\n\nfor i in range(X_val.shape[0]):\n    if y_val_array[i] != y_pred[i]:\n        f.add_subplot(rows,cols,sub_plot) \n        sub_plot += 1\n        plt.imshow(X_val[i].reshape([28,28]),cmap=\"Blues\")\n        plt.axis(\"off\")\n        plt.title(f\"True: {str(y_val_array[i])} Pred: {str(y_pred[i])}\", y=-0.15,color=\"Red\")\n        if sub_plot >= (rows * cols) +1:\n            break\nplt.savefig(\"error_plots.png\")\nplt.show()","232193d5":"predictions = CNN_2.predict(test_set)\nresults = predictions.argmax(axis=-1)","921fe0af":"\nresult = pd.DataFrame()\nresult['ImageId'] = list(range(1,28001))\nresult['Label'] = results\nresult.to_csv(\"output.csv\", index = False)\n\n","4c2e9219":"# Digit Recognizer using the MNIST dataset","07f35270":"We can see that the model converges at around ~0.98 `val_accuracy` score.\n\nLet's also take a look at the `loss` and `accuracy` values at each epoch:","62422003":"# Buliding a simple Neural Network (NN) using Keras\n\nAs a naive first approach, we will build a simple clasifier NN, with a single hidden layer.\n\nTo avoid [overfitting](https:\/\/elitedatascience.com\/overfitting-in-machine-learning), we also add a `Dropout` layer (which randomly removes 30% of the neuron connections between the input layer and the hidden layer).\n\nWe use a `Flatten` layer to convert the data shape to 1d instead of 2d.","72c94a4c":"Note that using the CNN architecture, we now have only ~560K parameters to train, compared to 7.8M parameters in the previous architecture. This is over **90% less** parameters to train!\n","affacfe0":"We can see that the model converges at around ~0.992 `val_accuracy` score, which is an improvement to the previous scores.\n\nAdding the differnt layers to deal with the over-fitting has another advantage which is decreasing the running time of each epoch from `~16 seconds` to `~4 seconds`.\n\nLet's again take a look at the `loss` and `accuracy` values at each epoch:","0097038f":"### Reshaping the data\nSince we are planning to use convolutional NNs, we need to convert the 1D representation of the image into 2D representation.","b33028dd":"# Writing the output to a file ","4b3f477b":"These plots also ilustrate a situation of overfitting, but weaker than before. There are a few solutions in this case; the simplest solution is to **decrease the complexity** of the model by removing layers (shallower newtork) or reducing the number of neurons in each layer (narrower network). However, our model is pretty shallow and narrow as it is, and therefore we don't have much to reduce. The solution, counterintuitively is by adding more layers, but of a special kind: \n\n1. [`Dropout`](https:\/\/keras.io\/api\/layers\/regularization_layers\/dropout\/): This layer randomly sets a given fraction of the input units 0.\n2. [`MaxPooling`](https:\/\/keras.io\/api\/layers\/pooling_layers\/max_pooling2d\/): Applies a moving window over the  input and changing each value to the maximum value of the window.\n\nAnother solution is to add more data, by collecting new examples or by data augmantation, which we will discuss below.  ","df374db3":"# Confusion Matrix\n[`Confusion matrix`](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.confusion_matrix.html) is a tool to evaluate the accuracy of a classification process. \nThe horizontal axis shows the labels that the model predicted and the vertical axis shows the real labels. The number in each cell indicates the number of images that match the selected combination. The diagonal shows the number of images in which the model correctly predicted reality.","f6849513":"We now have only 61K parameters to train - another reduction of ~90% compared to our previous network.","dcdf5fdc":"# Exploring the wrong predictions of the model ","a44945bd":"We can see that the model converges at around ~0.96 `val_accuracy` score (different results may occur at each run, due to the randomization of the initial parameters).\n\nLet's also take a look at the `loss` and `accuracy` values at each epoch. However, since we will do the same for each model in the notebook, we will first create a helper function for it.","4eff44c6":"## Preparing the data\nThe training and test data consist of 42,000 and 28,000 pictures respectively, with a size of 28 x 28. i.e. 784 pixels per image. \n\nThe first column in the train data is the label.\n\nWe will seperate it into X and y variables:","b8dd2bcc":"## Early Stopping \nBefore training the network, we define an early stopping criterion, to avoid redundent epochs once the model has already converged.\n","5e0e635c":"Now we can use the data generator as an input to our `fit` function, and re-train our CNN model with the generated data.","6184affc":"## Reduce Learning Rate On Plateau\nWe define a [`ReduceLROnPlateau`](https:\/\/keras.io\/api\/callbacks\/reduce_lr_on_plateau\/) callback to reduce the learning rate when the metric we chose (`val_loss`) has stopped improving.","d3c053e2":"Note that using the fully-connected architecture, we end up with **7.8M parameters** to train.","d7faa52d":"### Normalizing the data\nWe will normalize the data by transforming all the data points to a scale of [0 , 1]:\n","e5d83971":"# Buliding a Convolutional Neural Network (CNN) using Keras\nCNN is an artificial neural network that has so far been most popularly used for analyzing images for computer vision tasks.\nThe basis of a CNN are the convolutional layers, which are able to pick out or detect patterns in the data.\n\nFor a quick intro to the theory behind CNNs, I recommend [this video](https:\/\/www.youtube.com\/watch?v=nmnaO6esC7c&list=PLWKotBjTDoLj3rXBL-EIPRN9V3a9Cx07&index=1).\n\nNotice that we are using 3 layers of convolution, which are considered the feature extraction layers, and a final `Dense` (fully-connected) layer, which acts as the classifier.\n ","5b2b36db":"We will split the original training set into train and validation sets using [`train_test_split`](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html) function from scikit-learn:","09466d73":"We can see that both metrics converge much faster on the validation data than the training data. This is usually a sign of over-fitting. This may be the result of the high number of trainable parameters in this architecture.\n\nTo reduce this number, we will turn to a different method - Convolutional Neural Network.","fdb6cf07":"Let's take a look at the data ","fd524d7f":"We can now fit our simple network to the data and examine the results.","fb7898f5":"Now we will convert the labels into`One-Hot` representation:","f8d7b23a":"# Reading the data","578f2161":"# Image augmantation to increase the accuracy\n\nTo further enhance our model, we would like to add more data to train on. Since we do not have more data, we will use data augmantation to artificially create more data samples. \n\nTo do that, we will use the Keras [`ImageDataGenerator`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator). This tool allows us to create new trainning images by manipulating the exiting ones (scaling, rotating, flipping, etc.). However, since not all manipulations make sense in the context of handwritten digits, i.e. flipping the number 7 vertically is not a valid digit, we will only use a small subset of the possible manipulations.","9f95f272":"Since we are going to use different models, we would like to define a few parameters that will be consistent across all of them.","5a4de439":"Again, we can fit our network to the data and examine the results.","84ca1e4d":"This notebook aims at identifying digits from the MNIST (\"Modified National Institute of Standards and Technology\") dataset, consisting of 42,000 handwritten images.  \nIt is divided into 3 parts, while each part illustrates a more complex model. The models are compared with respect to their running time, accuracy and number of parameters to train. \nAt the end, image augmentation had been applied to the model with the best score.  \n","f4ddbff8":"We can see that the validation and training data seem to converge together this time, which implies that we have solved the main causes of overfitting."}}