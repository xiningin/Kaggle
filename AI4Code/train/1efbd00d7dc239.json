{"cell_type":{"348b65ce":"code","719d4927":"code","3173967d":"code","144f11d2":"code","419682e4":"code","2f0537af":"code","abb47360":"code","8d123b5d":"code","104cc950":"code","efed2f7d":"code","576290f6":"code","68025c69":"code","36addff2":"code","0a882cb5":"code","7a579c34":"code","ec9b3cd2":"code","98be4936":"code","18031952":"code","4e9a3a0e":"code","6bc217ad":"code","b8f6daea":"code","01aed3da":"code","190d4deb":"code","39076798":"code","ee64964b":"code","628f126a":"code","5dafff98":"code","8abb4469":"code","12e2a50c":"code","b1b72a55":"code","acc4432c":"code","f611b537":"code","50ba173d":"code","582ecf4b":"code","bdeb3bd5":"code","d736454d":"code","cefb8c77":"code","14d44c36":"code","aabee391":"code","264fdf9d":"code","637779c4":"code","09b734ac":"code","de4c8ad8":"code","d14e9657":"code","dd6a4803":"code","de7c78e0":"markdown","b8dc9e2d":"markdown","96475ca7":"markdown","69216e1a":"markdown","15c77dda":"markdown","e3fb1ad8":"markdown","627fcd59":"markdown","fa2e2c5a":"markdown","f596ae09":"markdown","8f464589":"markdown","66fed037":"markdown","f9c27097":"markdown","bae527bf":"markdown","d3d66f40":"markdown","0ed728b8":"markdown","23b7faf0":"markdown","049a067c":"markdown","1a936735":"markdown","3284026f":"markdown","4b71129e":"markdown","4846a5c0":"markdown","b35a2d6e":"markdown","fe7aaabc":"markdown","1689d8a8":"markdown"},"source":{"348b65ce":"import numpy as np                                     # linear algebra\nimport pandas as pd                                    # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport copy                                            #to copy list\nfrom sklearn.model_selection import train_test_split   #to split dataset into train and test set\nfrom sklearn.svm import SVC                            #to create svc instance\nfrom sklearn.metrics import classification_report      #to create report for precision,recall,f1-score,accuracy\nfrom sklearn import metrics                            #to get accuracy\nfrom sklearn.model_selection import GridSearchCV       #to optimise the hyper-parameter\nimport math\n\n","719d4927":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3173967d":"#dataset 1\n#df = pd.read_csv('\/kaggle\/input\/protein-secondary-structure\/2018-06-06-ss.cleaned.csv')\n#dataset 2\n#df = pd.read_csv('\/kaggle\/input\/protein-secondary-sequence\/PDB_31-12-2012.csv')\n#dataset 3\n#df = pd.read_csv('\/kaggle\/input\/protein-secondary-sequence\/PDB_31-12-2012.csv')\n#dataset 4\ndf = pd.read_csv('..\/input\/protein-secondary-structure-casp12-cb513-ts115\/training_secondary_structure_train.csv')\n#casp12\ndf_test1 = pd.read_csv('..\/input\/protein-secondary-structure-casp12-cb513-ts115\/test_secondary_structure_casp12.csv')","144f11d2":"#dataset 1\n'''\ndf=df.head(5001)\ndf.head()\n#print(df.info())\n'''","419682e4":"#dataset 2\n#df=df.head()\ndf.head()","2f0537af":"#dataset 3\n'''\ndf=df.head(50)\ndf.head()\n'''","abb47360":"#dataset 1\n'''\nmaxlen_seq = 128\ninput_seqs, target_seqs = df[['seq', 'sst8']][(df.len <= maxlen_seq) & (~df.has_nonstd_aa)].values.T\ninput_seqs, target_seqs = df[['seq', 'sst8']][(~df.has_nonstd_aa)].values.T\ninput_grams = seq2ngrams(input_seqs)\nprint(input_seqs[0:5])\n'''","8d123b5d":"#dataset 2 & 3\n'''\n#maxlen_seq = 550\n#input_seqs, target_seqs = df[['seq', 'sst8']][(df['sst8'].apply(lambda x: len(x))<= maxlen_seq)].values.T\ninput_seqs, target_seqs = df[['seq', 'sst8']].values.T\nprint(input_seqs[0:8])\n'''","104cc950":"#dataset 4\ninput_seqs, target_seqs = df[['seq', 'sst8']].values.T\ninput_seqs_test1, target_seqs_test1 = df_test1[['seq', 'sst8']].values.T\n\nprint(input_seqs[0:8])\nprint(input_seqs_test1[0:8])","efed2f7d":"print(target_seqs[0:8])\nprint(target_seqs.size)","576290f6":"inputSeqs=[]\ntargetSeqs=[]\nfor i in range(input_seqs.size):\n    j=0\n    while(j<len(input_seqs[i])\/128):\n        start = j*128\n        end = start+128\n        inputSeqs.append(input_seqs[i][start:end])\n        targetSeqs.append(target_seqs[i][start:end])\n        j+=1\n        \nprint(len(targetSeqs))\nprint(len(inputSeqs))","68025c69":"inputSeqs_test1=[]\ntargetSeqs_test1=[]\nfor i in range(input_seqs_test1.size):\n    j=0\n    while(j<len(input_seqs_test1[i])\/128):\n        start = j*128\n        end = start+128\n        inputSeqs_test1.append(input_seqs_test1[i][start:end])\n        targetSeqs_test1.append(target_seqs_test1[i][start:end])\n        j+=1\n        \nprint(len(targetSeqs_test1))\nprint(len(inputSeqs_test1))","36addff2":"#for test data\nfor row in range(len(targetSeqs_test1)):\n    secondary_lenth1 = len(targetSeqs_test1[row])\n    primary_lenth1 = len(inputSeqs_test1[row])\n    \n    if(secondary_lenth1 != primary_lenth1):\n        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs_test1[row],\" Primary_Structure -> \",inputSeqs_test1[row])\n    \nprint(len(inputSeqs_test1))","0a882cb5":"for row in range(len(targetSeqs)):\n    secondary_lenth = len(targetSeqs[row])\n    primary_lenth = len(inputSeqs[row])\n    \n    if(secondary_lenth != primary_lenth):\n        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs[row],\" Primary_Structure -> \",inputSeqs[row])\n    \nprint(len(inputSeqs))","7a579c34":"secondary_count = 0\nprimary_count = 0\ndataCheck = \"ACEDGFIHKMLNQPSRTWVY\"\nindex=[]\nfor row in range(len(targetSeqs)):\n    secondary_lenth = len(targetSeqs[row])\n    primary_lenth = len(inputSeqs[row])\n    secondary_count = secondary_count + secondary_lenth\n    primary_count = primary_count + primary_lenth\n    if(secondary_lenth != primary_lenth):\n        print(\"(\",row,\") Secondary_Structure ->\", targetSeqs[row],\" Primary_Structure -> \",inputSeqs[row])\n    for col in range(len(inputSeqs[row])):\n        #print(\"before :\",inputSeqs[row][col])\n        if len(inputSeqs[row])<2:\n            index.append(row)\n        if dataCheck.find(inputSeqs[row][col])==-1:\n            #print(\"after :\",inputSeqs[row][col])\n            index.append(row)\n           # print(\"Row : \"+str(row)+\"have been deleted for having unknown data\")\n            break\n            \n\ninputSeqs =np.delete(inputSeqs,index)\ntargetSeqs =np.delete(targetSeqs,index)\n        \nprint(\"count of secondary structure : \",secondary_count)\nprint(\"count of primary structure : \",primary_count)\nprint(\"size of primary structure : \",len(inputSeqs))","ec9b3cd2":"def split(sequence): \n    return [char for char in sequence]","98be4936":"primary_split = []\nsecondary_split = []\nfor row in range(int(len(targetSeqs)\/1)):\n    primary_split.append(split(inputSeqs[row]))\n    secondary_split.append(split(targetSeqs[row]))\n    \nprint(len(primary_split))","18031952":"primary_split_test1 = []\nsecondary_split_test1 = []\nfor row in range(int(len(targetSeqs_test1)\/1)):\n    primary_split_test1.append(split(inputSeqs_test1[row]))\n    secondary_split_test1.append(split(targetSeqs_test1[row]))\n    \nprint(len(primary_split_test1))","4e9a3a0e":"def orthogonal_primary(arg):\n    switch = {\n        'A' : np.array([1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),  # 20 amino acids\n        'C' : np.array([0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'E' : np.array([0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'D' : np.array([0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'G' : np.array([0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'F' : np.array([0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'I' : np.array([0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'H' : np.array([0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]),\n        'K' : np.array([0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]),\n        'M' : np.array([0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]),\n        'L' : np.array([0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]),\n        'N' : np.array([0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]),\n        'Q' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]),\n        'P' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]),\n        'S' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]),\n        'R' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]),\n        'T' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]),\n        'W' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]),\n        'V' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]),\n        'Y' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]),\n        'X' : np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n    }\n    \n    return switch.get(arg)\n\ndef orthogonal_secondary(arg):\n    switch = {\n        'H' : 0,                    # H= \u03b1-helix\n        'C' : 1,                    # C= Loops and irregular elements\n        'E' : 2,                    # E= \u03b2-strand\n        'B' : 3,                    # B= \u03b2-bridge\n        'G' : 4,                    # G= 3-helix\n        'I' : 5,                    # I= \u03c0-helix\n        'T' : 6,                    # T= Turn\n        'S' : 7                     # S= Bend\n    }\n    \n    return switch.get(arg)","6bc217ad":"for row in range(len(primary_split)):  \n    sequence = primary_split[row]\n    for col in range(len(sequence)):\n        #print(sequence[col])\n        sequence[col] = orthogonal_primary(sequence[col])\n        #print(sequence[col])","b8f6daea":"#for test data\nfor row in range(len(primary_split_test1)):  \n    sequence1 = primary_split_test1[row]\n    for col in range(len(sequence1)):\n        #print(sequence[col])\n        sequence1[col] = orthogonal_primary(sequence1[col])\n        #print(sequence[col])","01aed3da":"for row in range(len(secondary_split)):  \n    sequenceS = secondary_split[row]\n    for col in range(len(sequenceS)):\n        sequenceS[col] = orthogonal_secondary(sequenceS[col])","190d4deb":"#for test data\nfor row in range(len(secondary_split_test1)):  \n    sequenceS1 = secondary_split_test1[row]\n    for col in range(len(sequenceS1)):\n        sequenceS1[col] = orthogonal_secondary(sequenceS1[col])","39076798":"primary_split_test1[0:2]","ee64964b":"#secondary_split[0:5]","628f126a":"def graph_sum2(seq1,seq2):\n    result=[None]*len(seq1)\n    for col in range(len(seq1)):\n        result[col] =  seq1[col]+seq2[col]\n    return result\n\n\ndef graph_sum3(seq1,seq2,seq3):\n    result=[None]*len(seq1)\n    for col in range(len(seq1)):\n        result[col] =  seq1[col]+seq2[col]+seq3[col]\n    return result","5dafff98":"graph_input = copy.deepcopy(primary_split)\nfor row in range(len(primary_split)):\n    sequence = primary_split[row]\n    graph_input[row][0]=graph_sum2(sequence[0],sequence[1])\n    graph_input[row][len(sequence)-1]=graph_sum2(sequence[len(sequence)-1],sequence[len(sequence)-2])\n    for col in range(1,len(sequence)-1):\n        graph_input[row][col] = graph_sum3(sequence[col-1],sequence[col],sequence[col+1])\n        \ngraph_input[0:5]","8abb4469":"#for test data\ngraph_input_test1 = copy.deepcopy(primary_split_test1)\ntemp = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\nfor row in range(len(primary_split_test1)):\n    sequence1 = primary_split_test1[row]\n    if len(sequence1)>1:\n        graph_input_test1[row][0]=graph_sum2(sequence1[0],sequence1[1])\n        graph_input_test1[row][len(sequence1)-1]=graph_sum2(sequence1[len(sequence1)-1],sequence1[len(sequence1)-2])\n        for col in range(1,len(sequence1)-1):\n            graph_input_test1[row][col] = graph_sum3(sequence1[col-1],sequence1[col],sequence1[col+1])\n    else:\n        graph_input_test1[row][0]=graph_sum2(sequence1[0],temp)\n        \ngraph_input_test1[0:5]","12e2a50c":"def targetY(data_list):\n    Y = []\n    for i in range(len(data_list)):\n        for j  in range(len(data_list[i])):\n            Y.append(data_list[i][j])\n    return Y","b1b72a55":"y_label = targetY(secondary_split)\ny_label_test1 = targetY(secondary_split_test1)","acc4432c":"print(len(y_label))\nprint(y_label[0:5])","f611b537":"print(len(y_label_test1))\nprint(y_label_test1[0:5])","50ba173d":"def window_padding_data(size, sequence):\n    num = int(size\/2)\n    #print(\"initial :\",sequence[0])\n    #print(\"\")\n    zeros = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    for i in range(len(sequence)):\n        for j in range(num):\n            sequence[i].append(zeros)\n            sequence[i].insert(0, zeros)\n            #print(sequence[i])\n            #print(\"\")\n            \n    X = []\n    temp = []\n\n    for k in range(len(sequence)):\n        #print(sequence[k])\n        for l in range(len(sequence[k])-(size-1)):\n            temp = sequence[k][l:l+size]\n           # print(temp)\n            X.append(temp)\n            temp = []\n\n    return X","582ecf4b":"X = window_padding_data(11,graph_input)\nprint(len(X))\nX[0:5]","bdeb3bd5":"X_test1 = window_padding_data(11,graph_input_test1)\nprint(len(X_test1))\nX_test1[0:5]","d736454d":"np.set_printoptions(threshold=np.inf)\nX = np.array(X)\ny_label = np.array(y_label)\nX = X.reshape(len(X),11*20)\nprint(X[0:5])\nprint(\"X_train length :\",len(X))\nprint(\"y_label length :\",len(y_label))","cefb8c77":"X_test1 = np.array(X_test1)\ny_label_test1 = np.array(y_label_test1)\nX_test1 = X_test1.reshape(len(X_test1),11*20)\nprint(X_test1[0:5])\nprint(\"X_train length :\",len(X_test1))\nprint(\"y_label length :\",len(y_label_test1))","14d44c36":"#split the dataset into train set and test set\n#X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size = 0.20,random_state=54)","aabee391":"X_train = X\ny_train = y_label\nX_test = X_test1\ny_test = y_label_test1","264fdf9d":"# defining parameter range \n#param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n#              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n#              'kernel': ['rbf','linear','poly','sigmoid']}  \n#  \n#grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n# \n# fitting the model for grid search \n#grid.fit(X_train, y_train) ","637779c4":"# print best parameter after tuning \n#print(grid.best_params_) \n# \n# print how our model looks after hyper-parameter tuning \n#print(grid.best_estimator_)","09b734ac":"#grid_predictions = grid.predict(X_test) \n#  \n# print classification report \n#print(classification_report(y_test, grid_predictions)) ","de4c8ad8":"dictp = {'C':0,'gamma':0,'kernel':\"none\",'accuracy':0,'i':0}","d14e9657":"#for i in range(101):\n#    X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size = 0.20,random_state=i)\n# defining parameter range \n#param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n#              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n#              'kernel': ['rbf','linear','poly','sigmoid']}  \n\n#grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n\n# fitting the model for grid search \n#grid.fit(X_train, y_train) \n\n# print best parameter after tuning \n#print(grid.best_params_) \n# \n# print how our model looks after hyper-parameter tuning \n#print(grid.best_estimator_)\n\n#grid_predictions = grid.predict(X_test) \n#  \n# print classification report \n#print(classification_report(y_test, grid_predictions)) \n    #acu = accuracy_score(y_test,grid_predictions)*100\n    #if dictp['accuracy']<acu:\n        #dictp['accuracy']=acu\n        #dictp['kernel']=grid.best_estimator['kernel']\n        #dictp['gamma']=grid.best_estimator_['gamma']\n        #dictp['C']=grid.best_estimator_['C']\n        #dictp['i']=i\n        \n#print(\"i : \",dictp['i'],\" C : \",dictp['C'],\" gamma : \",dictp['gamma'],\" kernel : \",dictp['kernel'],\" accuracy : \",dictp['accuracy'])","dd6a4803":"#for i in range(1,101):\n#    X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size = 0.20,random_state=i)\n#svc = SVC(kernel='rbf', gamma = 0.1, C=1.5)\n#svc.fit(X_train, y_train)\n#y_pred = svc.predict(X_test)\n#y_true = y_test\n#    print(\"i = \",i,\"acc = \",metrics.accuracy_score(y_test, y_pred))\n#print(\"Accuracy = \",metrics.accuracy_score(y_test, y_pred)*100)\n#print(classification_report(y_true,y_pred))","de7c78e0":"# **Looking for incomplete data**\n\nCheck the data whether there are differences in the number of characters of the primary structure and secondary structure (because the prediction of the secondary structure of the protein is included in the sequence labeling problem, it is certain that the number of characters of the primary structure and secondary structure is always the same)","b8dc9e2d":"# **Import the Library**","96475ca7":"The data feature is formed using the window_padding_data function. This function will accept the size of the sliding window and sequence of the primary structure of the protein. In this function features will be processed such as adding padding 0 at the beginning and end and taking the features of the results of windowing so that the output data can be directly trained on the SVM model","69216e1a":"**graph_sum2**<br>\nthis function take input 2 node (amino acid character's onehot key) and return the sum of 2 node .<br>\n**graph_sum3**<br>\nthis function take input 3 node (amino acid character's onehot key) and return the sum of 3 node .","15c77dda":"# Load the dataset","e3fb1ad8":"Before being entered into the Scikit-Learn SVM model, the data is reshape to follow the input size of the model. The data is reshaped to the length of X(primary structure) times multiplied by 220 (x window size and 20 orthogonal encoding sizes.)","627fcd59":"**Split function**<br>\nsplit the string sequence into character array .<br>\ninput -> string <br>\noutput -> array of character ","fa2e2c5a":"**Graph of primary structure**<br>\nThe primary structure is a linear string of character\/amino acid(node) .<br>\nExample : ***ABBA***<br>\nIn Graph Neural Network , we take each node and sum the information value of it's adjacent node. As a result we find a new value for each node which is dependable for it's adjacent nodes .<br>\n![Untitled%20Diagram.jpg](attachment:Untitled%20Diagram.jpg)\nthe border node will use graph_sum2 function as it has only 1 adjacent node and the rest will use graph_sum3 function .","f596ae09":"Proteins are chains of amino acids joined together by peptide bonds . Each amino acid in the chain is polar, i.e. it has separated positive and negative charged regions with a free carbonyl group, which can act as hydrogen bond acceptor and an NH group, which can act as hydrogen bond donor. These groups can therefore interact in the protein structure. The 20 amino acids can be classified according to the chemistry of the side chain which also plays an important structural role.\n\nThe protein structure can be considered as a sequence of secondary structure elements, such as \u03b1 helices, \u03b2 sheets and coils, which together constitute the overall three-dimensional configuration of the protein chain.","8f464589":"# Directory of Dataset\nfind the directory of dataset","66fed037":"Data is split into training and testing data. Next will be calculated with SVM and see the Classification Report","f9c27097":"input_seqs is 2D array which has string in each row. Make it character array in each row .<br>\nprimary structure from input_seqs go to primary_split .<br>\nsecondary structure from target_seqs go to secondary_split .","bae527bf":"**PDB Dataset**<br>\nLoad the .csv file into dataframe and see if it is load properly .","d3d66f40":"see the target sequence(secondary structure) and it's size . ","0ed728b8":"Find the total sequence of primary structure and secondary structure to find out if there is no anomaly .","23b7faf0":"# Make the Graph","049a067c":"# **Protein Secondary Structure Prediction using Graph Neural Network**","1a936735":"# **Orthogonal Encoding - Target Labeling**\n\nEvery primary and secondary structure data is split so that it can be encoded into orthogonal form","3284026f":"For each character of primary structure and secondary structure use onehot key in the 20 amino acid .<br>\nIn secondary structure encode the 8 classification using 0-7 integer .","4b71129e":"# Use the SVM to find the classification","4846a5c0":"The results of the split primary and secondary structure of the protein are then converted into orthogonal encoding and target labeling. A switch case snippet for each amino acid in the primary structure of a protein as follows .<br>\nSecondary structure character represent ->\n1. H= \u03b1-helix\n2. C= Loops and irregular elements\n3. E= \u03b2-strand\n4. B= \u03b2-bridge\n5. G= 3-helix\n6. I= \u03c0-helix\n7. T= Turn\n8. S= Bend","b35a2d6e":"# **Data processing** \n\nThe PDB dataset is opened and processed using the python programming language. The 'seq' column has the primary sequence of protein and the 'sst8' has the seconday sequence of protein . The max length of any sequence set to 128 . \nhasnonstdaa: whether the peptide contains nonstandard amino acids (B, O, U, X, or Z).\nSo those sequences are only taken which don't have nonstandard amino acids .","fe7aaabc":"# Optimise the Hyper parameter","1689d8a8":"Make the secondary structure in a array of data using targetY function ."}}