{"cell_type":{"ea1e7ddb":"code","5bad05e3":"code","5760c210":"code","fbfddff2":"code","c71ba609":"code","6f3dcd2c":"code","3c1924a1":"code","6d2880af":"code","e94e8ae2":"code","60ab7b12":"code","6c37f7a5":"code","15c3e265":"markdown","6c8fad9b":"markdown","f0239a47":"markdown","a86ca1b2":"markdown","4f7bffe4":"markdown","f7473393":"markdown"},"source":{"ea1e7ddb":"!pip install -U lightautoml","5bad05e3":"import pandas as pd\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task","5760c210":"train_data = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\nsub = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\ntrain_data.shape, test_data.shape, sub.shape","fbfddff2":"%%writefile nn_code.py\n\n# Ref.: https:\/\/www.kaggle.com\/chaudharypriyanshu\/tps-nov-nn-starter-keras\n# ================================================================================\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\nfrom keras.backend import sigmoid\nfrom sklearn.metrics import roc_auc_score\nimport joblib\n\ntrain_data = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\n\n#https:\/\/bignerdranch.com\/blog\/implementing-swish-activation-function-in-keras\/\ndef swish(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nget_custom_objects().update({'swish': Activation(swish)})\n\ndef base_model(hidden_units):\n    num_input = keras.Input(shape=(100,), name='num_data')#input layer\n    out = keras.layers.Concatenate()([num_input])\n    for n_hidden in hidden_units:\n        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n        out = keras.layers.Dropout(0.3)(out)\n    out = keras.layers.Dense(1, activation='sigmoid', name='prediction')(out)\n    model = keras.Model(inputs = [num_input],outputs = out)\n    return model\n\ndef create_nn_preds(train_data, test_data, n_folds = 3):\n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=2020)\n\n    X = train_data.drop(['id', 'target'], axis = 1).values\n    y = train_data['target'].values\n    X_test = test_data.drop(['id'], axis = 1).values\n\n    nn_oof_pred = np.array([0.0] * len(train_data))\n    nn_test_pred = np.array([0.0] * len(test_data))\n    \n    es = keras.callbacks.EarlyStopping(\n        monitor='val_auc', patience=20, verbose=0,\n        mode='max',restore_best_weights=True)\n\n    plateau = keras.callbacks.ReduceLROnPlateau(\n        monitor='val_auc', factor=0.2, patience=7, verbose=0,\n        mode='max')\n    \n    hidden_units = (128, 128, 128, 64) \n\n    for fold, (trn_ind, val_ind) in enumerate(skf.split(y, y)):\n        print(f'Training fold {fold + 1}')\n        X_train, X_val = X[trn_ind, :], X[val_ind, :]\n        y_train, y_val = y[trn_ind], y[val_ind]\n        print('CV {}\/{}'.format(fold + 1, n_folds)) \n\n        model = base_model(hidden_units)\n        model.compile(\n            keras.optimizers.Adam(learning_rate=0.001),\n            loss='binary_crossentropy',\n            metrics = ['AUC']\n        )\n\n        scaler = MinMaxScaler(feature_range=(0, 1))         \n        X_tr = scaler.fit_transform(X_train)    \n        X_v = scaler.transform(X_val)\n        X_t = scaler.transform(X_test)\n\n        model.fit(X_tr, \n                  y_train,               \n                  batch_size=2048,\n                  epochs=1000,\n                  validation_data=(X_v, y_val),\n                  callbacks=[es, plateau],\n                  validation_batch_size = 2048,\n                  shuffle=True,\n                  verbose = 1)\n\n        preds = model.predict(X_v).reshape(-1, 1)[:, 0]\n        nn_oof_pred[val_ind] = preds\n        score = roc_auc_score(y_val, preds)\n        print('Fold {}: {:.7f}'.format(fold + 1, score))\n\n        nn_test_pred += model.predict(X_t).reshape(-1, 1)[:, 0] \/ n_folds     \n\n    K.clear_session()\n    return nn_oof_pred, nn_test_pred\n\nnn_oof_pred, nn_test_pred = create_nn_preds(train_data, test_data, 5)\njoblib.dump((nn_oof_pred, nn_test_pred), 'nn_preds.pkl')","c71ba609":"!python nn_code.py","6f3dcd2c":"# Ref.: https:\/\/www.kaggle.com\/ambrosm\/tpsnov21-001-support-vector-classification\n# ================================================================================\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nauc_list = []\nsvm_oof_pred = np.array([0.0] * len(train_data))\nsvm_test_pred = np.array([0.0] * len(test_data))\n\nN_folds = 10\nkf = StratifiedKFold(n_splits=N_folds, shuffle=True, random_state=13)\nfor fold, (train_idx, val_idx) in enumerate(kf.split(train_data, train_data.target)):\n    print(f\"Fold {fold}\")\n    X_tr = train_data.iloc[train_idx]\n    X_va = train_data.iloc[val_idx]\n    y_tr = X_tr.target\n    y_va = X_va.target\n    X_tr = X_tr.drop(columns=['id', 'target'])\n    X_va = X_va.drop(columns=['id', 'target'])\n\n    # Train\n    model = make_pipeline(StandardScaler(), LinearSVC(tol=1e-7, penalty='l2', dual=False, max_iter=2000))\n    model.fit(X_tr, y_tr)\n    \n    # Validate\n    y_pred = model.decision_function(X_va)\n    svm_oof_pred[val_idx] = y_pred\n    score = roc_auc_score(y_va, y_pred)\n    print(score)\n    auc_list.append(score)\n    \n    # Predict for the submission\n    svm_test_pred += model.decision_function(test_data.drop(columns=['id'])) \/ N_folds\n\navg_auc = sum(auc_list) \/ len(auc_list)\nprint(f\"Average AUC: {avg_auc:.5f}\")","3c1924a1":"import joblib\nnn_oof_pred, nn_test_pred = joblib.load('nn_preds.pkl')","6d2880af":"train_data['NN_pred'] = nn_oof_pred\ntest_data['NN_pred'] = nn_test_pred\n\ntrain_data['SVM_pred'] = svm_oof_pred\ntest_data['SVM_pred'] = svm_test_pred\n\nfor data in [train_data, test_data]:\n    data['SVM_mul_NN'] = data['SVM_pred'] * data['NN_pred']\n    data['SVM_div_NN'] = data['SVM_pred'] \/ (data['NN_pred'] + 1e-6)\n    \nprint('OOF score NN: {:.7f}'.format(roc_auc_score(train_data['target'], train_data['NN_pred'])))\nprint('OOF score SVM: {:.7f}'.format(roc_auc_score(train_data['target'], train_data['SVM_pred'])))\nprint('OOF score MUL: {:.7f}'.format(roc_auc_score(train_data['target'], train_data['SVM_mul_NN'])))\nprint('OOF score DIV: {:.7f}'.format(roc_auc_score(train_data['target'], train_data['SVM_div_NN'])))","e94e8ae2":"task = Task('binary')\nautoml = TabularAutoML(task = task, timeout = 8 * 3600, cpu_limit = 4, \n                       general_params = {'use_algos': [['cb', 'cb_tuned']]}, \n                       selection_params = {'mode': 0})\noof_pred = automl.fit_predict(train_data, roles = {'target': 'target', 'drop': ['id']}, verbose = 2)\nsub['target'] = automl.predict(test_data).data[:, 0]","60ab7b12":"print('OOF score LightAutoML: {:.7f}'.format(roc_auc_score(train_data['target'], oof_pred.data[:, 0])))","6c37f7a5":"sub.to_csv('submission.csv', index = False)","15c3e265":"# Add calculated predictions to datasets","6c8fad9b":"# Create Keras NN oof and test predictions","f0239a47":"# LightAutoML installation\n\n### [Official Github repo](https:\/\/github.com\/sberbank-ai-lab\/LightAutoML)","a86ca1b2":"# Reading data","4f7bffe4":"# LightAutoML model training","f7473393":"# Create SVM oof and test predictions"}}