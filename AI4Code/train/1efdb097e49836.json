{"cell_type":{"a31b8c1c":"code","504d060d":"code","74d1a62e":"code","3f5c4fc7":"code","2b087889":"code","b6e57674":"code","c2ded362":"code","a3a4c00b":"code","5cef9f8c":"code","a4451655":"markdown","acfdd378":"markdown","27bee830":"markdown","0e0f6c81":"markdown","9d7af802":"markdown","aa0908b4":"markdown","35774958":"markdown","151f164f":"markdown","1a4eccf1":"markdown","5b2bf32d":"markdown","55c01fd6":"markdown","ece936d0":"markdown","9501ab46":"markdown","462ea768":"markdown","a8653812":"markdown"},"source":{"a31b8c1c":"import tensorflow as tf\nimport keras \nfrom keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Input\nfrom keras.preprocessing.image import img_to_array\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm import tqdm \nimport numpy as np\nimport os\nimport re\n","504d060d":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n\n\n# defining the size of image \nSIZE = 256\n\nmask_path = '..\/input\/face-mask-lite-dataset\/with_mask'\nmask_array = []\n\nimage_path = '..\/input\/face-mask-lite-dataset\/without_mask'\nimg_array = []\n\nimage_file = sorted_alphanumeric(os.listdir(image_path))\nmask_file = sorted_alphanumeric(os.listdir(mask_path))\nfor i in tqdm(mask_file):\n    #here i have only load 2500 images.\n    if i == 'with-mask-default-mask-seed2500.png':\n        break\n    else:    \n        image = cv2.imread(mask_path + '\/' + i,1)\n\n          # as opencv load image in bgr format converting it to rgb\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # resizing images \n        image = cv2.resize(image, (SIZE, SIZE))\n\n        # normalizing image \n        image = image.astype('float32') \/ 255.0\n\n        #appending normal normal image    \n        mask_array.append(img_to_array(image))\n\n  \n    \nfor i in tqdm(image_file):\n \n    if i == 'seed2500.png':\n        break\n    \n    else:\n        image = cv2.imread(image_path + '\/' + i,1)\n\n        # as opencv load image in bgr format converting it to rgb\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        # resizing images \n        image = cv2.resize(image, (SIZE, SIZE))\n\n        # normalizing image \n        image = image.astype('float32') \/ 255.0\n        # appending normal sketch image\n        img_array.append(img_to_array(image))\n\n   \n    ","74d1a62e":"def plot_image_pair(images = 5):\n    for i in range(images):\n        plt.figure(figsize = (7,7))\n        plt.subplot(1,2,1)\n        plt.title(\"No Mask\", fontsize = 15)\n        plt.imshow(img_array[i].reshape(SIZE, SIZE, 3))\n        plt.subplot(1,2,2)\n        plt.title(\"Mask\", fontsize = 15)\n        plt.imshow(mask_array[i].reshape(SIZE, SIZE, 3))\n        \n        \n        \nplot_image_pair(5)\n        \n        ","3f5c4fc7":"train_mask_image = mask_array[:2300]\ntrain_image = img_array[:2300]\ntest_mask_image = mask_array[2300:]\ntest_image = img_array[2300:]\n# reshaping\ntrain_mask_image = np.reshape(train_mask_image,(len(train_mask_image),SIZE,SIZE,3))\ntrain_image = np.reshape(train_image, (len(train_image),SIZE,SIZE,3))\nprint('Train no mask image shape:',train_image.shape)\ntest_mask_image = np.reshape(test_mask_image,(len(test_mask_image),SIZE,SIZE,3))\ntest_image = np.reshape(test_image, (len(test_image),SIZE,SIZE,3))\nprint('Test no mask image shape',test_image.shape)","2b087889":"encoder_input = keras.Input(shape=(SIZE,SIZE, 3), name=\"img\")\nx = Conv2D(filters = 16, kernel_size = (3,3), activation = 'relu', padding = 'same')(encoder_input)\nx = MaxPool2D(pool_size = (2,2))(x)\nx = Conv2D(filters = 32,kernel_size = (3,3),strides = (2,2), padding = 'valid')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.LeakyReLU()(x)\nx = Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), activation = 'relu', padding = 'same')(x)\nx = MaxPool2D(pool_size = (2,2))(x)\nx = Conv2D(filters = 64, kernel_size = (3,3), padding = 'same')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.LeakyReLU()(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), padding = 'same')(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.LeakyReLU()(x)\nx = Conv2D(filters = 128 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nx = Conv2D(filters = 256 , kernel_size = (3,3), padding = 'same')(x) \nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.LeakyReLU()(x)\nencoder_output = Conv2D(filters = 512 , kernel_size = (3,3), activation = 'relu', padding = 'same')(x) \nencoder = tf.keras.Model(encoder_input, encoder_output)\n\n\n\ndecoder_input = Conv2D(filters = 512 ,kernel_size = (3,3), activation = 'relu', padding = 'same')(encoder_output)\nx = UpSampling2D(size = (2,2))(decoder_input)\nx = Conv2D(filters = 256, kernel_size = (3,3),  padding = 'same')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.LeakyReLU()(x)\nx = Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = Conv2D(filters = 128, kernel_size = (3,3),  padding = 'same')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.LeakyReLU()(x)\nx = Conv2D(filters = 164, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\n\nx = Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\nx = UpSampling2D(size = (2,2) )(x)\nx = Conv2D(filters = 32 , kernel_size = (3,3),  padding = 'same')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.LeakyReLU()(x)\nx = UpSampling2D(size = (2,2) )(x) \nx = Conv2D(filters = 16  , kernel_size = (3,3), activation = 'relu', padding = 'same')(x)\ndecoder_output = Conv2D(filters = 3, kernel_size = (3,3), padding = 'same')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.LeakyReLU()(x)\n\n# final model\nmodel = keras.Model(encoder_input, decoder_output)\nmodel.summary()","b6e57674":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])\n\nmodel.fit(train_mask_image, train_image, epochs = 100, verbose = 0)","c2ded362":"loss_acc= model.evaluate(test_mask_image, test_image)\nprint(\"Loss: \",loss_acc[0])\nprint('Accuracy: ', np.round(loss_acc[1],2) * 100)","a3a4c00b":"def plot_images(start = 0, end = 5):\n    for i in range(start, end, 1):\n        plt.figure(figsize = (10,10))\n        plt.subplot(1,3,1)\n        plt.title(\"No Mask\", fontsize = 12)\n        plt.imshow(test_image[i])\n        plt.subplot(1,3,2)\n        plt.title(\"Mask\", fontsize = 12)\n        plt.imshow(test_mask_image[i])\n        plt.subplot(1,3,3)\n        plt.title(\"Predicted\", fontsize = 12)\n        prediction = model.predict(test_mask_image[i].reshape(1,SIZE, SIZE, 3)).reshape(SIZE, SIZE, 3)\n        plt.imshow(prediction)\n        plt.show()\n        ","5cef9f8c":"plot_images(20,30)","a4451655":"## Model evaluation","acfdd378":"<img src = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTOkFwIF09DEVcgunZk_3EPp6FMWcxx8AUDRA&usqp=CAU' height = '600px' width = '600px'>","27bee830":"## Plot image pair","0e0f6c81":"## Load data\nHere I am going to load only 2500 images each with mask and no mask. These images are converted to an array and are appended in empty array. Here I also have defind function to load data serially. ","9d7af802":"## Compiling our model","aa0908b4":"# Introduction","35774958":"Here I have used Conv2D and MaxPool2D in encoder network for downsampling. Latent vector is of shape (16,16,64). This latent vector is input for decoder network, decoder network tries to reconstruct images and tries to reduce reconstruction loss by upsampling this latent vector.","151f164f":"## Defining our model","1a4eccf1":"# Thanks for your visit","5b2bf32d":"## plotting images","55c01fd6":"Here, I am going to remove face mask of a person using autoencoder. To get better understanding of autoencoder and how it works you can visit my another notebook https:\/\/www.kaggle.com\/theblackmamba31\/autoencoder-removing-noise-from-mnist-digits, also I have some other notebook showing application of autoencoder, So you can visit my profile if you are really intrested in autoencoder. Here, I have defined the architecture of autoencoder it's application.\nLet's Start","ece936d0":"## Slicing and reshaping\nHere i have used 2300 images for training and remaining 200 for testing.","9501ab46":"## Any Suggestion to improve this model is highly appreciated. \n# Feel free to comment ","462ea768":"## Import Necessary Libraries","a8653812":"## Objective: Main aim of this notebook is to find face behind the mask using autoencoder."}}