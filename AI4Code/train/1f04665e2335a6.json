{"cell_type":{"c342b0e5":"code","8ff4b9d8":"code","3386cc41":"code","b6afa642":"code","3fa268e1":"code","ccd6c1bf":"code","dde08d8f":"code","7ef98ad3":"code","7d4f3f98":"code","e8894177":"code","33416a66":"code","1ee1feea":"code","c9fc86ae":"code","54ddf354":"code","d58dbb35":"code","7c297040":"code","9aa8a4be":"code","6e1a8ccc":"code","bb382db8":"markdown","5023f956":"markdown","f9154544":"markdown","4a36bfe9":"markdown","94743ba0":"markdown","c2f190ac":"markdown","dec10c55":"markdown","d241d863":"markdown","6b556fb9":"markdown"},"source":{"c342b0e5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","8ff4b9d8":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3386cc41":"from subprocess import check_output\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nimport time #helper libraries\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt","b6afa642":"prices =  pd.read_csv('\/kaggle\/input\/nyse\/prices.csv', header=0)\nprices","3fa268e1":"google_stocks = prices[prices.symbol == 'GOOG']\ngoogle_stocks.dtypes","ccd6c1bf":"google_stocks_prices = google_stocks.close.values.astype('float64').reshape(1762, 1)\ngoogle_stocks_prices","dde08d8f":"plt.plot(google_stocks_prices)\nplt.show()","7ef98ad3":"# rescale data\nscaler = MinMaxScaler(feature_range=(0, 1))\ngoogle_stocks_prices = scaler.fit_transform(google_stocks_prices)","7d4f3f98":"plt.plot(google_stocks_prices)\nplt.show()","e8894177":"train_size = int(len(google_stocks_prices) * 0.75)\ntest_size = len(google_stocks_prices) - train_size\ntrain, test = google_stocks_prices[0:train_size,:], google_stocks_prices[train_size:len(google_stocks_prices),:]\nprint('train: ',len(train))\nprint('test: ',  len(test))","33416a66":"# convert an array of values into a dataset matrix\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","1ee1feea":"# convert train and test data to datasets\nlook_back = 1\ntrain_X, train_y = create_dataset(train, look_back)\ntest_X, test_Y = create_dataset(test, look_back)","c9fc86ae":"# reshape into X = t and Y = t+1\ntrain_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\ntest_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))","54ddf354":"#LSTM architecture\nmodel = Sequential()\n\n# First LSTM layer with Dropout regularisation\nmodel.add(LSTM(units=50, \n               return_sequences=True, \n               input_shape=(train_X.shape[1],1)))\nmodel.add(Dropout(0.2))\n\n# Second LSTM layer\nmodel.add(LSTM(units=50,return_sequences=True))\nmodel.add(Dropout(0.2))\n\n# Third LSTM layer\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\n# Fourth LSTM layer\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.5))\n\n# The output layer\nmodel.add(Dense(units=50, kernel_initializer='uniform', activation='tanh'))\nmodel.add(Dense(units=1, kernel_initializer='uniform', activation='linear'))","d58dbb35":"# Compiling the RNN\nmodel.compile(optimizer='adam',loss='mean_squared_error')\n# Fitting to the training set\nstart = time.time()\nhistory = model.fit(train_X,\n                  train_y,\n                  epochs=200,\n                  batch_size=35, \n                  validation_split=0.05, \n                  verbose=1)\nprint ('compilation time : ', time.time() - start)","7c297040":"history_dict = history.history\nhistory_dict.keys()\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\n# \"bo\" is for \"blue dot\"\nplt.plot(epochs, loss, 'r', label='Training loss')\n# b is for \"solid blue line\"\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","9aa8a4be":"test_X = np.array(test_X)\ntest_X = np.reshape(test_X, (test_X.shape[0],test_X.shape[1],1))\n\ntest_Y = np.array(test_Y)\ntest_Y = np.reshape(test_Y, (-1,1))\n\n\npredicted_stock_price = model.predict(test_X)\n# Inverse transform is to denormalize the predicted_stock_price\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\ngoogle_stocks_prices = scaler.inverse_transform(test_Y)\npredicted_stock_price.shape","6e1a8ccc":"plt.figure(figsize=(8,6))\nplt.subplot(1,1,1)\nplt.plot(predicted_stock_price, linewidth=1.2, color='darkred', label='Predicted Google Stock price')\nplt.plot(google_stocks_prices, linewidth=1.2, color='green', label='Real Google Stock price')\nplt.xlabel('Days', fontsize=8)\nplt.ylabel('Google Stock Price', fontsize=8)\nplt.legend(loc='best', fontsize=10)\nplt.show()","bb382db8":"### Data\n* Volume is the number of shares of the stock that were traded that given day.\n* Date First Added represents the date when this company was added to the market index S&P 500.\n* Open: At what price did the stock open on that day, 9:00 am ET.\n* High: Highest stock price during the day.\n* Low: Lowest stock price during the day.\n* Close: This is the closing price of the stock at the end of the day (5 in the afternoon ET)","5023f956":"## plot the data ","f9154544":"## Learning Curve","4a36bfe9":"Manually split the data whithout shuffling as our main point of focus here is the data sequence","94743ba0":"## LSTM Model","c2f190ac":"Get the close price for Google trasactions","dec10c55":"## Predictions","d241d863":"##### Training and Validation loss","6b556fb9":"### Split data"}}