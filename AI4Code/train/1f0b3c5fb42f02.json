{"cell_type":{"ef54c61e":"code","94061e23":"code","b858f21d":"code","8831fe11":"code","10de97fc":"code","3c8fa74c":"code","a7a2d5bc":"code","86826d72":"code","d9eb1179":"code","f10210b3":"code","2846b1a6":"code","3e4dbdaa":"code","7134732e":"code","b2f5adac":"code","9788bd21":"code","45313fe7":"code","d1abd20f":"code","438e3937":"code","ba357d0e":"code","a741e65e":"code","0acd808e":"code","0307cc56":"code","c335d8db":"code","802caef8":"code","5fe3a231":"code","b6f6aebf":"code","1fb14e89":"code","d1279b3e":"code","686f05a1":"code","90a82d36":"code","f75af3a3":"code","714ea83c":"code","7db96773":"code","6db16792":"code","badf4bca":"code","a0a787ac":"code","f374f79b":"code","f4ab653b":"code","6495abc9":"code","662e8616":"code","c1bb4b10":"code","29aa5649":"code","f4a2d444":"code","870c86ba":"code","e8d330a6":"code","f598c14e":"code","2d3da189":"code","b718a8d2":"code","92a91856":"code","2746a21f":"code","4e2d63b6":"code","8c81a43d":"code","eaaac265":"code","b27b74ae":"code","ff3e9d2c":"code","e8edf831":"code","307386a2":"code","c720c1be":"code","fd1aec51":"code","e55f42d1":"code","916f949d":"code","3e41d796":"code","29312509":"code","3e622d07":"code","7feb984b":"code","30b935e5":"code","860dae4c":"code","172475e7":"code","28421281":"code","6c0bfb62":"code","a21c9f25":"code","f419b319":"markdown","739be512":"markdown","cb1768f3":"markdown","069c6c52":"markdown","c6078449":"markdown","5dbf8767":"markdown","207846e8":"markdown","24533f62":"markdown","d7d3892d":"markdown","57064de8":"markdown","4d59584f":"markdown","1b325e3f":"markdown","cdad51c9":"markdown"},"source":{"ef54c61e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94061e23":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows',None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef,f1_score\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score,roc_curve\nfrom sklearn.model_selection import cross_val_score,KFold,cross_val_score,cross_validate\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.tree import plot_tree\nfrom xgboost import plot_tree,plot_importance\nfrom sklearn import tree\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom yellowbrick.classifier import ClassificationReport, confusion_matrix,precision_recall_curve,PrecisionRecallCurve,ConfusionMatrix,ROCAUC,DiscriminationThreshold\nfrom yellowbrick.model_selection import FeatureImportances,learning_curve,LearningCurve\nfrom yellowbrick.target import class_balance\nimport itertools\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.experimental import enable_hist_gradient_boosting  \nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier,GradientBoostingClassifier,AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\nfrom lightgbm import LGBMClassifier\nfrom scipy.stats import boxcox\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom catboost import CatBoostClassifier\nfrom imblearn.over_sampling import SMOTE,BorderlineSMOTE,KMeansSMOTE\nfrom imblearn.under_sampling import NearMiss,RandomUnderSampler\nimport h2o\nfrom h2o.automl import H2OAutoML\n!pip install researchpy\nimport researchpy","b858f21d":"data=pd.read_csv(\"\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf=data.copy()\ndf.head()","8831fe11":"print(\"Number of Columns :{0} \\nNumber of Rows : {1}\".format(df.shape[0],df.shape[1]))","10de97fc":"df.dtypes","3c8fa74c":"df.loc[df.TotalCharges==\" \",\"TotalCharges\"]=np.nan","a7a2d5bc":"df.TotalCharges=df.TotalCharges.astype(float)","86826d72":"df.describe().T","d9eb1179":"df.SeniorCitizen=df[\"SeniorCitizen\"].replace({0:\"No\",1:\"Yes\"})","f10210b3":"df.describe(include=[\"object\"]).T","2846b1a6":"def diagnostic_plots(df, variable):\n    \n    plt.figure(figsize=(20, 9))\n\n    plt.subplot(1, 3, 1)\n    sns.distplot(df[variable], bins=30,kde_kws={'bw': 1.5})\n    plt.title('Histogram')\n    \n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('RM quantiles')\n\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n    \n    plt.show()","3e4dbdaa":"num_columns=df.select_dtypes(exclude=[\"object\"]).columns\nfor i in num_columns:\n    diagnostic_plots(df,i)\n","7134732e":"plt.figure(figsize=(12,5))\ncorr=df.corr().abs()\nmask=np.zeros_like(corr,dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True\nsns.heatmap(corr,annot=True,cmap=\"coolwarm\",mask=mask);","b2f5adac":"researchpy.correlation.corr_pair(df.select_dtypes(exclude=\"object\"))","9788bd21":"for i in df.select_dtypes(include=\"object\").columns[1:]:\n    print(str(i) + \" and \" + \"Churn\")\n    crosstab, res = researchpy.crosstab(df[i], df[\"Churn\"], test= \"chi-square\")\n    print(res);","45313fe7":"sns.pairplot(df,hue=\"Churn\",aspect=3);","d1abd20f":"sns.FacetGrid(df,hue=\"Churn\",height=5,aspect=2).map(sns.kdeplot,\"TotalCharges\",shade=False).add_legend();","438e3937":"sns.FacetGrid(df,hue=\"Churn\",height=5,aspect=2).map(sns.kdeplot,\"tenure\",shade=False).add_legend();","ba357d0e":"sns.FacetGrid(df,hue=\"Churn\",height=5,aspect=2).map(sns.kdeplot,\"MonthlyCharges\",shade=False).add_legend();","a741e65e":"cat_columns=df.select_dtypes(include=\"object\").columns[1:]\nfor i in cat_columns[:-1]:\n    sns.catplot(x=i,y=\"TotalCharges\",hue=\"Churn\",data=df,kind=\"box\",aspect=2);","0acd808e":"df.info()","0307cc56":"class_balance(df.iloc[:,-1]);","c335d8db":"\nfor i in cat_columns:\n    plt.figure(figsize=(12,5));\n    sns.countplot(df[i],hue=\"Churn\",data=df)\n    plt.show()","802caef8":"df.isnull().sum()\/(len(df))","5fe3a231":"df[pd.isnull(df[\"TotalCharges\"])]","b6f6aebf":"df.TotalCharges.fillna(df.TotalCharges.median(),inplace=True)","1fb14e89":"df.isnull().sum()","d1279b3e":"df=df.drop(columns=[\"customerID\"],axis=1)","686f05a1":"df_coded=pd.get_dummies(df,drop_first=True)","90a82d36":"X=df_coded.iloc[:,:-1]\ny=df_coded.iloc[:,-1]","f75af3a3":"X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","714ea83c":"X_train.shape,y_train.shape,X_test.shape,y_test.shape","7db96773":"\nclass_balance(y_train);\nclass_balance(y_test);","6db16792":"models = []\nmodels.append(('LR', LogisticRegression(random_state = 12345)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state = 12345)))\nmodels.append(('RF', RandomForestClassifier(random_state = 12345)))\n#models.append(('SVC', SVC(gamma='auto', random_state = 12345)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345)))\nmodels.append((\"XGBoost\", XGBClassifier(random_state = 12345)))\nmodels.append((\"GBM\", GradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"HGBoost\", HistGradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"Adaboost\", AdaBoostClassifier(random_state = 12345)))\nmodels.append((\"Gaussian\", GaussianNB()))\n#models.append((\"Discriminant\", QuadraticDiscriminantAnalysis()))\n#models.append((\"Catboost\", CatBoostClassifier(random_state=12345)))","badf4bca":"results = []\nnames = []","a0a787ac":"for name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n        \n","f374f79b":"\n\ndef visualize_result(model):\n    print(\"*\"*5 + str(model) + \"*\"*5)\n    fig, axes = plt.subplots(2, 2,figsize=(20,10))\n\n    model = model;\n    model.fit(X_train,y_train)\n    y_pred=model.predict(X_test)\n    print(\"Accuracy Score :\",accuracy_score(y_test,y_pred))\n    print(\"Matthews_Corr :\",matthews_corrcoef(y_test,y_pred))\n    print(\"F1_Score :\",f1_score(y_test,y_pred))\n    \n    visualgrid = [\n        ConfusionMatrix(model, ax=axes[0][0],cmap=\"YlGn\"),\n        PrecisionRecallCurve(model,ax=axes[0][1]),  \n        #FeatureImportances(model,ax=axes[0][0]),        \n        ClassificationReport(model, ax=axes[1][0]),\n        ROCAUC(model, ax=axes[1][1])\n    ]\n\n    for viz in visualgrid:\n        \n        viz.fit(X_train, y_train)\n        viz.score(X_test, y_test)\n        viz.finalize()\n\n\n    plt.show()\n    ","f4ab653b":"for i in range(len(models)):    \n    visualize_result(models[i][1])","6495abc9":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=42)\nnm = NearMiss()\nX_train, y_train = nm.fit_sample(X_train, y_train)\ny_train = y_train.astype(int)","662e8616":"class_balance(y_train);\nclass_balance(y_test);","c1bb4b10":"for i in range(len(models)):    \n    visualize_result(models[i][1])","29aa5649":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=42)\nrus = RandomUnderSampler(random_state=42)\nX_train,y_train = rus.fit_resample(X_train, y_train)\n\nfor i in range(len(models)):    \n    visualize_result(models[i][1])","f4a2d444":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=42)\nsmt = SMOTE()\nX_train, y_train = smt.fit_sample(X_train, y_train)\ny_train = y_train.astype(int)","870c86ba":"class_balance(y_train);\nclass_balance(y_test);","e8d330a6":"for i in range(len(models)):    \n    visualize_result(models[i][1])","f598c14e":"for i in df.select_dtypes(include=[\"object\"]).columns:  \n    print(\"-\"*5 + str(i) + \"-\"*5)\n    print(df[i].value_counts())  ","2d3da189":"#MultipleLines ,OnlineSecurity,OnlineBackup,DeviceProtection,TechSupport,StreamigTV\n\ndf_new=df.replace({\"No internet service\" : \"No\",\"No phone service\":\"No\"})\ndf_new=pd.get_dummies(df_new,drop_first=True)\n","b718a8d2":"df_new.head()","92a91856":"plt.subplot(121)\nsns.distplot(np.array(stats.boxcox(df_new.TotalCharges))[0]);\nplt.title(\"Box Cox Transformation\");\nplt.subplot(122)\nsns.distplot(np.log(df_new.TotalCharges));\nplt.title(\"Log Transformation\");","2746a21f":"df_scaled=df_new.copy()\ndf_scaled.TotalCharges=np.array(stats.boxcox(df_new.TotalCharges))[0]","4e2d63b6":"scaler=MinMaxScaler()\ndf_scaled=scaler.fit_transform(df_new)\ndf_scaled=pd.DataFrame(df_scaled,columns=df_new.columns,index=df_new.index)","8c81a43d":"df_scaled.head()","eaaac265":"X=df_scaled.iloc[:,:-1]\ny=df_scaled.iloc[:,-1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=42)","b27b74ae":"for i in range(len(models)):    \n    visualize_result(models[i][1])","ff3e9d2c":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=42)\nrus = RandomUnderSampler()\nX_train, y_train = rus.fit_sample(X_train, y_train)\ny_train = y_train.astype(int)\n\nfor i in range(len(models)):    \n    visualize_result(models[i][1])","e8edf831":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20,random_state=42)\nsmt = SMOTE()\nX_train, y_train = smt.fit_sample(X_train, y_train)\ny_train = y_train.astype(int)","307386a2":"for i in range(len(models)):    \n    visualize_result(models[i][1])","c720c1be":"h2o.init()","fd1aec51":"df_h2o=data.copy()\ndf_h2o.loc[df_h2o.TotalCharges==\" \",\"TotalCharges\"]=np.nan\ndf_h2o.TotalCharges=df_h2o.TotalCharges.astype(float)\ndf_h2o.SeniorCitizen=df_h2o[\"SeniorCitizen\"].replace({0:\"No\",1:\"Yes\"})","e55f42d1":"df_h2o=h2o.H2OFrame(df_h2o)\ndf_h2o.head()","916f949d":"df_h2o[\"Churn\"].table()","3e41d796":"split=df_h2o.split_frame(ratios=[0.8],seed=12345)\ntrain=split[0]\ntest=split[1]\ntrain.shape,test.shape","29312509":"train[\"Churn\"].table()","3e622d07":"test[\"Churn\"].table()","7feb984b":"x = train.columns\ny = \"Churn\"\nx.remove(y)","30b935e5":"aml = H2OAutoML(max_models=25, seed=1,balance_classes=True)\naml.train(x=x, y=y, training_frame=train)","860dae4c":"lb = aml.leaderboard\nlb.head(rows=lb.nrows)","172475e7":"aml.leader","28421281":"preds = aml.predict(test)\n#preds = aml.leader.predict(test)","6c0bfb62":"lb = h2o.automl.get_leaderboard(aml, extra_columns = 'ALL')\nlb","a21c9f25":"perf = aml.leader.model_performance(test)\nperf.auc()","f419b319":"# OVERSAMPLING","739be512":"## RandomUnderSampler","cb1768f3":"# IMPORT THE LIBRARIES","069c6c52":"# MODELLING","c6078449":"# UNDERSAMPLING ON NEW MODEL","5dbf8767":"# EXPLORATORY DATA ANALYSIS (EDA)","207846e8":"## SMOTE","24533f62":"# OVERSAMPLING ON NEW MODEL","d7d3892d":"# NEW MODEL","57064de8":"# UNDERSAMPLING","4d59584f":"# TRAIN TEST SPLIT","1b325e3f":"## NearMiss","cdad51c9":"# H2O AUTO ML"}}