{"cell_type":{"672dae39":"code","348b980b":"code","cf8fd269":"code","465405f5":"code","ec2825ee":"code","861161f3":"code","1512f1cd":"code","e5583ba1":"code","10374fc5":"code","11db43ac":"code","7b2a6f55":"code","dc7ff976":"markdown"},"source":{"672dae39":"import pandas as pd\nimport numpy as np\nimport keras\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.layers import Dense, Activation, Flatten, merge,Input\nfrom keras.models import Model, Sequential\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras.layers import *\nfrom keras.callbacks import *\nimport os\nimport glob\nimport tensorflow as tf","348b980b":"\ntrain = pd.read_csv('\/kaggle\/input\/image-classification-dataset-in-the-gala-event\/image_auto_tagging\/train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/image-classification-dataset-in-the-gala-event\/image_auto_tagging\/test.csv')\n\ns = train['Class'].tolist()\n\nfrom collections import Counter\n\nprint(Counter(s).keys()) # equals to list(set(words))\nprint(Counter(s).values()) # counts the elements' frequency\nprint(len(Counter(s).keys()))\n\ntg_dict = {\"Food\":0, \"misc\": 1, \"Attire\": 2,\"Decorationandsignage\":3}\ndef label_encode(x):\n    return tg_dict[x]\n\ntrain['Class'] = train['Class'].apply(label_encode)\n\nimages = train['Image'].tolist()\nclasses = train['Class'].tolist()\n\nfeatures=[]\nlabels=[]\npath = '\/kaggle\/input\/image-classification-dataset-in-the-gala-event\/image_auto_tagging\/Train_Images\/'\nfor i in range(0,5983):\n  if os.path.isfile(path+str(images[i])):\n    pic = image.load_img(path+str(images[i]), target_size=(224, 224))\n    #print(path+str(images[i]))\n    x = image.img_to_array(pic)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    features.append(x)\n    labels.append(classes[i])\n  else:\n    print(path+str(images[i]), 'not present')\n    \nnpfeatures = np.array(features)\nprint(npfeatures.shape)\nimg_dt = np.rollaxis(npfeatures, 1, 0)\nprint(img_dt.shape)\nX = img_dt[0]\nprint(X.shape)\nlabels = np.array(labels)\nY = np_utils.to_categorical(labels,4)\nprint(Y.shape)\n\n\ndef recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))\n\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n","cf8fd269":"#import efficientnet.tfkeras as efn\n\nIMAGE_SIZE=[224,224]\npretrained_model = MobileNet(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\npretrained_model.trainable = False # tramsfer learning\n    #enet = efn.EfficientNetB7(input_shape=(512, 512, 3),weights='imagenet',include_top=False)\n    \nmodel = Sequential([\n        pretrained_model,\n        GlobalAveragePooling2D(),\n        Dense(220, activation='relu'),\n        Dense(220, activation='relu'),\n        \n        Dense(4, activation='softmax')\n    ])\nes = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n\nmodel.compile(optimizer = 'adamax', loss='categorical_crossentropy', metrics=[f1_m])    \nmodel.fit(X, Y, batch_size=32, epochs=10, validation_split=.1,callbacks=[es])\n","465405f5":"images_test = test['Image'].tolist()\ntest_features=[]\npath_test = '\/kaggle\/input\/image-classification-dataset-in-the-gala-event\/image_auto_tagging\/Test_Images\/'\nfor i in range(0,3219):\n  if os.path.isfile(path_test+str(images_test[i])):\n    pic = image.load_img(path_test+str(images_test[i]), target_size=(224, 224))\n    #print(path+str(images[i]))\n    x = image.img_to_array(pic)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    test_features.append(x)\n  else:\n    print(path_test+str(images[i]), 'not present')","ec2825ee":"test_features = np.array(test_features)\nprint(test_features.shape)\ntest_features = np.rollaxis(test_features, 1, 0)\nprint(test_features.shape)\nX_test = test_features[0]\nprint(X_test.shape)","861161f3":"preds = model.predict(X_test)","1512f1cd":"predictions=[]\nfor i in preds:\n    predictions.append(np.argmax(i))","e5583ba1":"test['Class'] = predictions","10374fc5":"gt_dict = dict((v,k) for k,v in tg_dict.items())\n\ndef inverse_encode(x):\n    return gt_dict[x]\n\ntest['Class'] = test['Class'].apply(inverse_encode)","11db43ac":"test.head(1)","7b2a6f55":"test.to_csv('Submission.csv',header=True,index = None)","dc7ff976":"image_input = Input(shape = (224,224,3))\nmodel = MobileNet(input_tensor = image_input, weights = 'imagenet')\nprint(model.summary())\nlast_layer = model.get_layer('fc2').output\nx = Dense(220,activation='relu')(last_layer)\nx = Dense(220,activation='relu')(x)\nout = Dense(4, activation='softmax')(x)\nclassifier = Model(image_input,out)\nprint(classifier.summary())\nfor Layer in classifier.layers[:-3]:\n    Layer.trainable = False\nes = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n\nclassifier.compile(optimizer = 'adamax', loss='categorical_crossentropy', metrics=[f1_m])    \nclassifier.fit(X, Y, batch_size=32, epochs=10, validation_split=.1,callbacks=[es])"}}