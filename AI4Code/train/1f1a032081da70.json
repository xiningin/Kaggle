{"cell_type":{"628ab5a8":"code","6e83a2e3":"code","32f9dc86":"code","71cdb785":"code","8848abb8":"code","260a8ab5":"code","c4b2a6ae":"code","80f4e5d3":"code","7042ca7a":"code","340f6c52":"code","b4652b30":"code","77d776f6":"code","8091f435":"code","3909c07d":"code","399f1f31":"code","fcb304b5":"code","e77fca29":"code","eb53b63f":"code","84669361":"code","ca28d2ec":"code","85ada17e":"code","3be10760":"code","6f123184":"code","0786241d":"code","70cb7ae6":"code","07e958d0":"code","d0380c2e":"code","4b5236a6":"code","ccb49332":"code","a322e49b":"code","9c4b841c":"code","15518674":"code","69575f27":"code","fb6961e4":"code","0c273aea":"code","8d88a4e9":"code","aea1372f":"code","7efe5fa6":"code","5dd213f2":"code","3fb8f7b9":"code","a88358c7":"code","60e94200":"code","f5f6c92e":"code","67500287":"code","9884496f":"code","4a46298a":"code","8dc9cf0d":"code","b90eb252":"code","7cf7b567":"code","61189a04":"code","daaadf42":"code","51e2919c":"code","964f373a":"code","7242ac53":"code","67f6e877":"code","f866f3fb":"code","e4a90d72":"code","dd13c53c":"code","fb107375":"code","acb99042":"code","3ca22330":"code","43f3817f":"code","56cd0b67":"code","741a8c8d":"code","ec78df25":"code","d053a6d1":"code","ac01407f":"code","c193b333":"code","7b99d334":"code","c134a0b3":"code","2ae52a82":"code","e41def2f":"code","bbae6f95":"markdown","9e9c2332":"markdown","3e056a09":"markdown","5c3e2283":"markdown","c7e8a42c":"markdown","5b7169e0":"markdown","3aae2c4f":"markdown","38c96cbb":"markdown","700e9478":"markdown","be6370cc":"markdown","39214604":"markdown","06371d71":"markdown","2ff15f57":"markdown","bd4f4f30":"markdown"},"source":{"628ab5a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e83a2e3":"import gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\nimport seaborn as sns\n\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, RandomForestRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, mean_squared_log_error, log_loss, roc_curve, confusion_matrix, plot_roc_curve\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,PowerTransformer,QuantileTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom category_encoders import OrdinalEncoder\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","32f9dc86":"#\u73fe\u5728\u306e\u6700\u5927\u8868\u793a\u5217\u6570\u306e\u51fa\u529b\npd.get_option(\"display.max_columns\")\n\n#\u6700\u5927\u8868\u793a\u5217\u6570\u306e\u6307\u5b9a\uff08\u3053\u3053\u3067\u306f50\u5217\u3092\u6307\u5b9a\uff09\npd.set_option('display.max_columns',40)\n\npd.set_option('display.max_rows',100)","71cdb785":"df_train = pd.read_csv('..\/input\/sales-prediction-of-clothes-in-e-commerce\/train.csv', index_col=0)\n\nX_test = pd.read_csv('..\/input\/sales-prediction-of-clothes-in-e-commerce\/test.csv', index_col=0)","8848abb8":"df_train.head()","260a8ab5":"df_train.tail()","c4b2a6ae":"X_test.head()","80f4e5d3":"X_test.tail()","7042ca7a":"#DataFrame\u306e\u884c\u6570\u5217\u6570\u3092\u78ba\u8a8d\u3059\u308b\ndf_train.shape, X_test.shape","340f6c52":"#\u5404\u5217\u306e\u30c7\u30fc\u30bf\u578b\u30fb\u6b20\u640d\u30c7\u30fc\u30bf\u306e\u500b\u6570\u3092\u78ba\u8a8d\ndf_train.info()\nprint('_'*60)\nX_test.info()","b4652b30":"# #\u6b20\u640d\u5024\u3092\u9664\u304f\n# X_train = X_train[y_train.isnull()==False]\n# y_train = y_train[y_train.isnull()==False]","77d776f6":"#\u57fa\u672c\u7d71\u8a08\u91cf\u306e\u78ba\u8a8d\ndf_train.describe()","8091f435":"#\u57fa\u672c\u7d71\u8a08\u91cf\u306e\u78ba\u8a8d\ndf_train.describe(include=['O'])","3909c07d":"df_nan_drop_0 = df_train.dropna()\nplt.figure(figsize=(14,12))\ncor = df_nan_drop_0.corr()\nsns.heatmap(cor, cmap= sns.color_palette('seismic', 10), annot=True,fmt='.2f', vmin = -1, vmax = 1)","399f1f31":"# # seaborn\u3067\u6570\u5024\u30c7\u30fc\u30bf\u306e\u307f\u884c\u5217\u6563\u5e03\u56f3\uff08\u30da\u30a2\u30d7\u30ed\u30c3\u30c8\uff09\u3092\u63cf\u304f\n# #g = sns.pairplot(df_nan_drop,vars=['age','ln_isop','bmi','smkgrp_bmi'],hue ='smkgrp_dummy')\n# plt.figure(figsize=(14,12))\n# #g = sns.pairplot(df_nan_drop_0,vars=[\"price\",])\n# g = sns.pairplot(df_nan_drop_0)\n# #g = sns.pairplot(df_nan_drop)","fcb304b5":"#\u4fa1\u683c\u304c30\u4ee5\u4e0a\/\u4ee5\u4e0b\u3067\u30d5\u30e9\u30b0\u5316\ndf_train.loc[df_train['price'] >= 10, 'price_10'] = \"True\"\ndf_train.loc[df_train['price'] < 10, 'price_10'] = \"False\"\n\nX_test.loc[X_test['price'] >= 10, 'price_10'] = \"True\"\nX_test.loc[X_test['price'] < 10, 'price_10'] = \"False\"","e77fca29":"df_train[[\"price_10\", \"units_sold\"]].groupby(['price_10'], as_index=False).mean().sort_values(by='units_sold', ascending=False).head(24)","eb53b63f":"#\u5c0f\u58f2\u308a\u5e0c\u671b\u4fa1\u683c\u3068\u5b9f\u58f2\u4fa1\u683c\u306e\u5dee\u3092\u307f\u308b\n#\u5b89\u58f2\u308a\u3057\u3066\u3044\u308c\u3070\u305f\u304f\u3055\u3093\u8cb7\u308f\u308c\u308b\u306e\u3067\u306f\uff1f\ndf_train['gap_price'] = df_train['retail_price'] - df_train['price']\ndf_train.head()","84669361":"#\u5c0f\u58f2\u308a\u5e0c\u671b\u4fa1\u683c\u3068\u5b9f\u58f2\u4fa1\u683c\u306e\u5dee\u3092\u307f\u308b\n#\u5b89\u58f2\u308a\u3057\u3066\u3044\u308c\u3070\u305f\u304f\u3055\u3093\u8cb7\u308f\u308c\u308b\u306e\u3067\u306f\uff1f\nX_test['gap_price'] = X_test['retail_price'] - X_test['price']\nX_test.head()","ca28d2ec":"#\u8a55\u4fa1\u306a\u3057\u306e\u5546\u54c1\u3092\u30d5\u30e9\u30b0\u5316\ndf_train.loc[(df_train['rating_five_count'].isnull()) &\n             (df_train['rating_four_count'].isnull()) & \n             (df_train['rating_three_count'].isnull())&\n             (df_train['rating_two_count'].isnull())&\n             (df_train['rating_one_count'].isnull()),\n             'no_Evaluation']='True'\n\ndf_train = df_train.fillna({'no_Evaluation':'False'})","85ada17e":"df_train[[\"no_Evaluation\", \"units_sold\"]].groupby(['no_Evaluation'], as_index=False).mean().sort_values(by='units_sold', ascending=False).head(24)","3be10760":"#\u8a55\u4fa1\u306a\u3057\u306e\u5546\u54c1\u3092\u30d5\u30e9\u30b0\u5316\nX_test.loc[(X_test['rating_five_count'].isnull()) &\n             (X_test['rating_four_count'].isnull()) & \n             (X_test['rating_three_count'].isnull())&\n             (X_test['rating_two_count'].isnull())&\n             (X_test['rating_one_count'].isnull()),\n             'no_Evaluation']='True'\n\nX_test = X_test.fillna({'no_Evaluation':'False'})","6f123184":"#no_Evaluation\u306b\u95a2\u3057\u3066\u306fTarget\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u306f\u5c11\u3057\u308f\u3051\u304c\u9055\u3046\u6c17\u304c\u3059\u308b\u306e\u3067\u30ab\u30a6\u30f3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\n\nsummary = df_train['merchant_id'].value_counts()\ndf_train['merchant_id'] = df_train['merchant_id'].map(summary)\nX_test['merchant_id'] = X_test['merchant_id'].map(summary)\n    \ndf_train.head()","0786241d":"#count\u306b\u95a2\u3057\u3066\u306fnan\u30920\u3067\u57cb\u3081\u3066\u3057\u307e\u3046\n\neva_rate = ['rating_five_count','rating_four_count','rating_three_count','rating_two_count','rating_one_count']\n\n#\u6b20\u640d\u5024\u51e6\u7406\nfor col in eva_rate:\n    df_train[[col]] = df_train[[col]].fillna(0)\n    X_test[[col]] = X_test[[col]].fillna(0)","70cb7ae6":"#\u7dcf\u8a55\u4fa1\u6570\u304c\u58f2\u308a\u4e0a\u3052\u6570\u306b\u52b9\u3044\u3066\u304f\u308b\u306f\u305a\ndf_train['sum_Evaluation']= df_train['rating_five_count'] + df_train['rating_four_count'] + df_train['rating_three_count'] + df_train['rating_two_count'] + df_train['rating_one_count']\nX_test['sum_Evaluation']= X_test['rating_five_count'] + X_test['rating_four_count'] + X_test['rating_three_count'] + X_test['rating_two_count'] + X_test['rating_one_count']","07e958d0":"#\u8a55\u4fa1\u5168\u6570\u306b\u5bfe\u3059\u308b\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u6570\u306e\u5272\u5408\ndf_train[\"rating_five_rate\"] = df_train['rating_five_count']\/df_train['sum_Evaluation']\ndf_train[\"rating_four_rate\"] = df_train['rating_four_count']\/df_train['sum_Evaluation']\ndf_train[\"rating_three_rate\"] = df_train['rating_three_count']\/df_train['sum_Evaluation']\ndf_train[\"rating_two_rate\"] = df_train['rating_two_count']\/df_train['sum_Evaluation']\ndf_train[\"rating_one_rate\"] = df_train['rating_one_count']\/df_train['sum_Evaluation']\n\nX_test[\"rating_five_rate\"] = X_test['rating_five_count']\/X_test['sum_Evaluation']\nX_test[\"rating_four_rate\"] = X_test['rating_four_count']\/X_test['sum_Evaluation']\nX_test[\"rating_three_rate\"] = X_test['rating_three_count']\/X_test['sum_Evaluation']\nX_test[\"rating_two_rate\"] = X_test['rating_two_count']\/X_test['sum_Evaluation']\nX_test[\"rating_one_rate\"] = X_test['rating_one_count']\/X_test['sum_Evaluation']\n\n#bin\u3092\u5c11\u3057\u5909\u3048\u3066\u307f\u308b\n# df_train[\"rating_five_four_rate\"] = (df_train['rating_five_count']+df_train['rating_four_count'])\/df_train['sum_Evaluation']\n# df_train[\"rating_three_rate\"] = df_train['rating_three_count']\/df_train['sum_Evaluation']\n# df_train[\"rating_two_one_rate\"] = (df_train['rating_two_count']+df_train['rating_one_count'])\/df_train['sum_Evaluation']\n\n# X_test[\"rating_five_four_rate\"] = (X_test['rating_five_count']+X_test['rating_four_count'])\/X_test['sum_Evaluation']\n# X_test[\"rating_three_rate\"] = X_test['rating_three_count']\/X_test['sum_Evaluation']\n# X_test[\"rating_two_one_rate\"] = (X_test['rating_two_count']+X_test['rating_one_count'])\/X_test['sum_Evaluation']","d0380c2e":"#\u6d88\u8cbb\u8005\u306e\u5e73\u5747\u8a55\u4fa1\u70b9\u6570\ndf_train[\"ave_rating\"] = (df_train['rating_five_count']*5 + df_train['rating_four_count']*4 + df_train['rating_three_count']*3 + df_train['rating_two_count']*2 + df_train['rating_one_count'])\/df_train['sum_Evaluation']\nX_test[\"ave_rating\"] = (X_test['rating_five_count']*5 + X_test['rating_four_count']*4 + X_test['rating_three_count']*3 + X_test['rating_two_count']*2 + X_test['rating_one_count'])\/X_test['sum_Evaluation']","4b5236a6":"#\u5e97\u8217\u306e\u8a55\u4fa1\u3068\u6d88\u8cbb\u8005\u306e\u8a55\u4fa1\u3092\u91cd\u307f\u3065\u3051\u308b\ndf_train[\"cust_shop_rating\"] = df_train[\"ave_rating\"]*df_train[\"merchant_rating\"]\nX_test[\"cust_shop_rating\"] = X_test[\"ave_rating\"]*X_test[\"merchant_rating\"]","ccb49332":"df_train.head()","a322e49b":"X_test.head()","9c4b841c":"#\u518d\u5ea6\u57fa\u672c\u7d71\u8a08\u91cf\u306e\u78ba\u8a8d\ndf_train.describe()","15518674":"#\u518d\u5ea6\u57fa\u672c\u7d71\u8a08\u91cf\u306e\u78ba\u8a8d\ndf_train.describe(include=['O'])","69575f27":"df_nan_drop_0 = df_train.dropna()\nplt.figure(figsize=(14,12))\ncor = df_nan_drop_0.corr()\nsns.heatmap(cor, cmap= sns.color_palette('seismic', 10), annot=True,fmt='.2f', vmin = -1, vmax = 1)","fb6961e4":"y_train = df_train.units_sold\nX_train = df_train.drop(['units_sold'], axis=1)","0c273aea":"X_test_fix = X_test.copy()\n\ndrop_list=[\"merchant_has_profile_picture\",\n           \"no_Evaluation\",\n           \"shipping_option_price\",\n           \"uses_ad_boosts\",\n           \"merchant_title\",\n           \"merchant_id\",\n           \"price_10\"\n           ]\n\nX_train=X_train.drop(drop_list,axis=1)\nX_test_fix=X_test_fix.drop(drop_list,axis=1)","8d88a4e9":"X_test_fix.head()","aea1372f":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['title','tags'], axis=1, inplace=True)\nX_test_fix.drop(['title','tags'], axis=1, inplace=True)","7efe5fa6":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        if col != 'emp_title':\n            cats.append(col)\ncats","5dd213f2":"#cats.remove(\"price_10\")","3fb8f7b9":"nums = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype != 'object':\n        nums.append(col)\n\nnums","a88358c7":"# #price_10\u306f\u5225\u3067\u30a8\u30f3\u30b3\u30fc\u30c9\n# summary = X_train['price_10'].value_counts()\n# X_train['price_10'] = X_train['price_10'].map(summary)\n# X_test_fix['price_10'] = X_test_fix['price_10'].map(summary)","60e94200":"X_test_fix.head()","f5f6c92e":"target = 'units_sold'\nX_temp = pd.concat([X_train, y_train], axis=1)\n\nfor col in cats:\n    \n    # X_test\u306fX_train\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    summary = X_temp.groupby([col])[target].mean()\n    enc_test = X_test_fix[col].map(summary)\n    X_test_fix[col] = enc_test\n   \n    # X_train\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092oof\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    # \u3053\u3053\u3067\u306f\u7406\u89e3\u306e\u305f\u3081\u306b\u81ea\u5206\u3067\u4ea4\u5dee\u691c\u5b9a\u7684\u306b\u5b9f\u65bd\u3059\u308b\u304c\u3001xfeat\u306a\u3069\u3092\u7528\u3044\u3066\u3082\u826f\u3044\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True) # \u4ea4\u5dee\u691c\u5b9a\u306e\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30cb\u30f3\u30b0\u3092\u5b9a\u7fa9\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index) # encoding\u7d50\u679c\u3092\u683c\u7d0d\u3059\u308b\u914d\u5217\u3092\u7528\u610f\u3057\u3066\u3044\u308b\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix] # encoding\u5bfe\u8c61\u3068\u305d\u308c\u4ee5\u5916\u306e\u96c6\u8a08\u5bfe\u8c61\u3092\u5206\u96e2\u3057\u3066\u3044\u308b\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([col])[target].mean() # encodinig\u5bfe\u8c61\u306e\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3\u4ee5\u5916\u3067\u5e73\u5747\u30bf\u30fc\u30b2\u30c3\u30c8\u7387\u3092\u96c6\u8a08\u3059\u308b\n        enc_train.iloc[val_ix] = X_val[col].map(summary) # encoding\u5bfe\u8c61\u306e\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30f3\u306bmap\u3059\u308b\uff08leak\u9632\u6b62\uff09\n    \n    X_train[col] = enc_train","67500287":"X_train.shape,X_test_fix.shape","9884496f":"# #\u6b20\u640d\u5024\u51e6\u7406\nfor col in nums:\n    X_train[[col]] = X_train[[col]].fillna(X_train[[col]].median())\n    X_test_fix[[col]] = X_test_fix[[col]].fillna(X_test_fix[[col]].median())\n    \nfor col in cats:\n    X_train[[col]] = X_train[[col]].fillna(X_train[[col]].median())\n    X_test_fix[[col]] = X_test_fix[[col]].fillna(X_test_fix[[col]].median())\n    \n# X_train[\"price_10\"] = X_train[\"price_10\"].fillna(X_train[\"price_10\"].median())\n# X_test_fix[\"price_10\"] = X_test_fix[\"price_10\"].fillna(X_test_fix[\"price_10\"].median())","4a46298a":"X_train.info()\nprint('_'*60)\nX_test_fix.info()\nprint('_'*60)\nlen(y_train)","8dc9cf0d":"for num_col in nums:\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u8907\u6570\u30ab\u30e9\u30e0\u306eRankGauss\u306b\u3088\u308b\u5909\u63db\u3092\u5b9a\u7fa9\n    pt = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution='normal')\n    pt.fit(X_train[[num_col]]) \n\n    # \u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u3067\u5404\u5217\u3092\u7f6e\u63db \n    X_train[[num_col]] = pt.transform(X_train[[num_col]]) \n    X_test_fix[[num_col]] = pt.transform(X_test_fix[[num_col]])\n\nX_train['price'].hist(density=True, alpha=0.5, bins=50)\nX_test_fix['price'].hist(density=True, alpha=0.5, bins=50)","b90eb252":"X_test_fix.head()","7cf7b567":"X_train.head()","61189a04":"#\u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf\u306ftf-idf\u5909\u63db\u3059\u308b\nTXT_train = df_train.tags.copy()\nTXT_test = X_test.tags.copy()\n\n# TXT_train = TXT_train.str.lower()\n# TXT_test = TXT_test.str.lower()\n\n#\u6b20\u640d\u5024\u306f\"#\"\u3067\u57cb\u3081\u3066\u304a\u304f\"\nTXT_train.fillna('#', inplace=True)\nTXT_test.fillna('#', inplace=True)\n\nTXT_train","daaadf42":"tfidf = TfidfVectorizer(max_features=1000, use_idf=True)\ntfidf.fit(TXT_train)\n\nTXT_train_enc = tfidf.fit_transform(TXT_train)\nTXT_test_enc = tfidf.transform(TXT_test)\n\nTXT_train_fix = TXT_train_enc.toarray()\nTXT_test_fix = TXT_test_enc.toarray()\n\nTXT_train_fix","51e2919c":"df_text_train = pd.DataFrame(TXT_train_fix)\nX_train = pd.concat([X_train,df_text_train],axis=1)\n\ndf_text_test = pd.DataFrame(TXT_test_fix)\nX_test_fix = pd.concat([X_test_fix,df_text_test],axis=1)","964f373a":"X_train","7242ac53":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n#\u4eca\u56de\u306fKFold\u3068\u3059\u308b\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    hyper_params = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'mape',\n    }\n    gbm = lgb.LGBMRegressor(**hyper_params)\n    gbm.fit(X_train_, y_train_,\n        eval_set=[(X_val, y_val)],\n        eval_metric='mape',\n        early_stopping_rounds=1000)\n    \n    y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration_)\n    \n    #MAPE\n    score = np.mean(np.abs((y_pred - y_val) \/ y_val)) * 100\n    \n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","67f6e877":"X_test_fix","f866f3fb":"cat_train = df_train[cats]\nnum_train = X_train[nums]\n\ncat_test = X_test[cats]\nnum_test = X_test_fix[nums]\n\n# # \u30d0\u30e9\u3057\u3066\u30ea\u30b9\u30c8\u306b\u3059\u308b\n# cat_train = [cat_train.values[:, k].reshape(-1,1) for k in range(len(cats))]\n# cat_test = [cat_test.values[:, k].reshape(-1,1) for k in range(len(cats))]","e4a90d72":"cat_train","dd13c53c":"#\u6b21\u306bcategorical\u3092Ordinal Encoding\nfor col in tqdm(cats):\n    oe = OrdinalEncoder(return_df=False)\n    \n    cat_train[[col]] = oe.fit_transform(cat_train[[col]])\n    cat_test[[col]] = oe.transform(cat_test[[col]]) \n    \n## \u3082\u3057category_eoncoders\u306eOrdinalEncoder\u3092\u4f7f\u3046\u3068-1\u3092\u4f5c\u3063\u3066\u3057\u307e\u3046\u306e\u3067\u3001\u5bfe\u51e6\u7642\u6cd5\u3060\u304c\u51e6\u7406\u3057\u3066\u304a\u304f\ncat_train.replace({-1:0}, inplace=True)\ncat_test.replace({-1:0}, inplace=True)","fb107375":"# \u30d0\u30e9\u3057\u3066\u30ea\u30b9\u30c8\u306b\u3059\u308b\ncat_train = [cat_train.values[:, k].reshape(-1,1) for k in range(len(cats))]\ncat_test = [cat_test.values[:, k].reshape(-1,1) for k in range(len(cats))]","acb99042":"num_train_fix = num_train.values\nnum_test_fix = num_test.values","3ca22330":"# numeric\u3068categorical\u3092\u7d50\u5408\u3057\u3066\u4e00\u3064\u306e\u30ea\u30b9\u30c8\u306b\u3059\u308b\nX_train_NN = [num_train_fix] + [TXT_train_fix]  + cat_train\nX_test_NN = [num_test_fix] + [TXT_test_fix] +   cat_test ","43f3817f":"X_train_NN","56cd0b67":"from tensorflow.keras.layers import Dense ,Dropout, BatchNormalization, Input, Embedding, SpatialDropout1D, Reshape, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.metrics import AUC","741a8c8d":"# # \u30b7\u30f3\u30d7\u30eb\u306aNN\n# def create_model():\n#     #\u6570\u5024\u30c7\u30fc\u30bf\u3092\u51e6\u7406\n#     num= Input(shape=(num_train_fix.shape[1],))\n#     out_num = Dense(194, activation='relu')(num)\n#     #out_num = Dense(194, activation='relu',input_shape=(num_train.shape[1],))\n#     out_num = BatchNormalization()(out_num)\n#     out_num = Dropout(0.5)(out_num)\n    \n#     inputs = [num]\n#     outputs = [out_num]\n    \n#     #\u30c6\u30ad\u30b9\u30c8\u3082\u540c\u69d8\u306b\u51e6\u7406\n#     num1= Input(shape=(TXT_train_fix.shape[1],))\n#     out_num1 = Dense(194, activation='relu')(num1)\n#     #out_num = Dense(194, activation='relu',input_shape=(num_train.shape[1],))\n#     out_num1 = BatchNormalization()(out_num1)\n#     out_num1 = Dropout(0.5)(out_num1)\n    \n#     inputs.append(num1)\n#     outputs.append(out_num1)\n    \n#     # \u30ab\u30c6\u30b4\u30ea\u30ab\u30eb\u5909\u6570\u306fembedding\u3059\u308b\n#     for c in cats:\n#         num_unique_values = int(df_train[c].nunique())       \n#         emb_dim = int(min(np.ceil((num_unique_values)\/2),50))\n#         inp = Input(shape=(1,))\n#         inputs.append(inp)\n        \n#         out = Embedding(num_unique_values+2, emb_dim, name=c)(inp)\n#         out = SpatialDropout1D(0.3)(out)\n#         out = Reshape((emb_dim, ))(out)\n#         outputs.append(out)\n    \n#     x = Concatenate()(outputs)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n#     x = Dense(64, activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n#     x = Dense(64, activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Dropout(0.5)(x)\n#     outp = Dense(1, activation='sigmoid')(x)\n#     model = Model(inputs=inputs, outputs=outp)\n#     model.compile(loss='mse',optimizer=\"adam\",metrics=['mae', 'mse'])\n    \n#     return model","ec78df25":"# model = create_model()\n\n# es = EarlyStopping(monitor='val_loss', patience=0)\n\n# model.fit(X_train_NN, y_train, batch_size=32, epochs=999, validation_split=0.2, callbacks=[es])\n# #model.fit(X_train, y_train, batch_size=128, epochs=999, validation_split=0.2, callbacks=[es])","d053a6d1":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n#\u4eca\u56de\u306fKFold\u3068\u3059\u308b\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf2 = RandomForestRegressor() \n    \n    clf2.fit(X_train_, y_train_)\n    y_pred = clf2.predict(X_val)\n    \n    #MAPE\n    score = np.mean(np.abs((y_pred - y_val) \/ y_val)) * 100\n    \n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","ac01407f":"# %%time\n# # CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# # \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n# #\u4eca\u56de\u306fKFold\u3068\u3059\u308b\n# scores = []\n\n# skf = KFold(n_splits=5, random_state=71, shuffle=True)\n\n# for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n#     X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n#     X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n#     clf3 = RandomForestRegressor() \n    \n#     clf3.fit(X_train_, y_train_)\n#     y_pred = clf3.predict(X_val)\n    \n#     #MAPE\n#     score = np.mean(np.abs((y_pred - y_val) \/ y_val)) * 100\n    \n#     scores.append(score)\n    \n#     print('CV Score of Fold_%d is %f' % (i, score))","c193b333":"# fti = clf2.feature_importances_   \n\n# print('Feature Importances:')\n# for i, feat in enumerate(X_train.columns):\n#     print('\\t{0:20s} : {1:>.6f}'.format(feat, fti[i]))","7b99d334":"from sklearn.ensemble import StackingRegressor\nfrom sklearn import model_selection \n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    estimators=[('gbm', gbm), ('clf2', clf2)]\n    stk_clf=StackingRegressor(estimators=estimators, final_estimator=GradientBoostingRegressor())\n    stk_clf.fit(X_train_, y_train_)\n    \n    y_pred = stk_clf.predict(X_val)\n    #MAPE\n    score = np.mean(np.abs((y_pred - y_val) \/ y_val)) * 100\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","c134a0b3":"y_pred_fix = stk_clf.predict(X_test_fix) ","2ae52a82":"sub = pd.DataFrame(X_test.index)\nsub['units_sold'] = list(map(int, y_pred_fix))\nsub = sub.rename(columns={\"0\":\"row_id\"})\n\nsub","e41def2f":"sub.to_csv(\".\/sample_submission_9.csv\", index = False)","bbae6f95":"## \u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u7528\u30b3\u30fc\u30c9","9e9c2332":"## RankGauss\u3067\u6b63\u898f\u5316","3e056a09":"## submit\u30c7\u30fc\u30bf\u306e\u4f5c\u6210","5c3e2283":"\u25cf\u6570\u5024\n* price\u304c30\u3092\u5883\u306b\u5207\u308c\u3066\u3044\u308b\u306e\u304c\u6c17\u306b\u306a\u308b\n* \u2606\u8a55\u4fa1\u306f\u305d\u308c\u305e\u308c\u3067\u5f37\u3044\u76f8\u95a2\u3092\u6709\u3059\u308b\u304b\u3064\u5024\u6bb5\u306b\u3082\u305d\u308c\u305e\u308c\u76f8\u95a2\u3092\u6709\u3059\u308b\n    * \u2192\u3082\u3057\u304b\u3059\u308b\u3068\u610f\u5473\u306e\u306a\u3044\u6307\u6a19\uff1f\u661f\u304c\u4f4e\u3044\u304b\u3089\u3068\u8a00\u3063\u3066\u58f2\u308a\u4e0a\u3052\u6570\u306b\u8ca0\u306e\u76f8\u95a2\u3092\u304d\u305f\u3057\u3066\u3044\u306a\u3044\u305f\u3081\n    *\u2606\u8a55\u4fa1\u306e\u306a\u3044\u5546\u54c1\u3082\u5b58\u5728\u3059\u308b\u306e\u3067\u7279\u5fb4\u91cf\u5316\u3057\u3066\u307f\u308b\u306e\u3082\u3044\u3044\u304b\u3082\n    \n* \u91d1\u984d\u306e\u5358\u4f4d\u306f\u4e38\u3081\u3089\u308c\u3066\u3044\u308b\u3063\u307d\u3044\u3002\u5358\u4f4d\u304c\u30c9\u30eb\uff1f\u5c11\u306a\u304f\u3068\u3082\u30aa\u30fc\u30c0\u30fc\u304c10\u5358\u4f4d\u306a\u306e\u304c\u6c17\u306b\u306a\u308b\n* \u8f38\u5165\u56fd\u304c\u591a\u3044\u56fd\u306e\u65b9\u304c\u3042\u307e\u308a\u58f2\u308c\u3066\u3044\u306a\u3044(\u3088\u3046\u306b\u898b\u3048\u308b)\n* retail_price\u3068price\u306e\u5358\u4f4d\u304a\u304b\u3057\u304f\u306a\u3044\uff1f\u30aa\u30fc\u30c0\u30fc\u304c\u7d50\u69cb\u9055\u3046\n\n\u25cf\u30ab\u30c6\u30b4\u30ea\n* \u30e6\u30cb\u30fc\u30af\u6570\u304c\u591a\u3044\n* \u30bf\u30a4\u30c8\u30eb\u306b\u306f\u30d5\u30e9\u30f3\u30b9\u8a9e\u3063\u307d\u3044\u8a18\u8ff0\u3042\u308a\n* \u5546\u54c1\u30bf\u30b0\u306f\u7279\u5fb4\u91cf\u306b\u306a\u308a\u305d\u3046\uff1f","c7e8a42c":"## train\u30c7\u30fc\u30bf\u3092\u76ee\u7684\u5909\u6570\u30fb\u8aac\u660e\u5909\u6570\u306b\u5206\u5272\u3059\u308b","5b7169e0":"## Target\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3092\u5b9f\u65bd","3aae2c4f":"## \u3053\u3053\u304b\u3089\u5fc5\u8981\u306b\u5fdc\u3058\u3066EDA","38c96cbb":"## \u30c7\u30fc\u30bf\u6982\u8981\u628a\u63e1","700e9478":"## \u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u7528\u306e\u30c7\u30a3\u30fc\u30d7\u30e9\u30fc\u30cb\u30f3\u30b0","be6370cc":"## \u4e0d\u8981\u305d\u3046\u306a\u7279\u5fb4\u91cf\u3092\u524a\u9664\u3059\u308b","39214604":"## \u307e\u305a\u306f\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u2192\u30e2\u30c7\u30eb\u3092\u6539\u826f\u3059\u308b","06371d71":"## \u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf","2ff15f57":"## \u30e9\u30a4\u30d6\u30e9\u30ea\u30a4\u30f3\u30dd\u30fc\u30c8","bd4f4f30":"## \u73fe\u6642\u70b9\u3067\u30c7\u30fc\u30bf\u3092\u773a\u3081\u3066\u307f\u3066\u306e\u4eee\u8aac\u3092\u8a18\u8ff0\u3059\u308b\u3068\u2026"}}