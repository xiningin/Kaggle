{"cell_type":{"e55e6ded":"code","724ea7c4":"code","488ff135":"code","f35bc68e":"code","49f1b891":"code","c47a0204":"code","94be8dc4":"code","c55225ef":"code","e4461ac7":"code","b581c082":"code","e1e1f4aa":"code","f459a57d":"code","c38c049f":"code","60fe758d":"code","bdca9079":"code","f26caff8":"code","12ec630b":"code","292ded58":"code","214fcb55":"code","4dc0f0d1":"code","a8dac40a":"code","e0d526ec":"code","17ed1bb1":"code","fa88fb7b":"code","78927280":"code","f3847de9":"code","7c7e548b":"code","14d106ea":"code","e28a7112":"code","1017ad87":"code","4007b236":"code","87a059f1":"code","01183638":"code","e9963b63":"code","d33bf007":"code","61c17113":"code","fb8b76e8":"code","390c547c":"code","c2c9d6f1":"code","3c24101d":"code","7d3425fa":"code","d592004b":"code","acb27586":"code","f5513b0f":"code","11a90aba":"code","4c28db40":"code","f4f59f88":"code","31be21a3":"code","e9f6bcee":"code","d697a83d":"code","c26f7960":"code","0401a229":"code","cb900079":"code","9194364f":"code","8c932782":"code","bc621cac":"code","dfd90cdf":"code","1b74a399":"code","0d924f75":"code","0324bb56":"code","fe9d5a30":"code","f063d452":"code","e23a31c0":"code","b26469d3":"code","357a4ade":"code","44a0b880":"code","ce366144":"code","6200c777":"code","8f8a47cb":"code","aec98bab":"code","c6d07a15":"code","9306b1b9":"code","f2b314f7":"code","892e11e6":"code","ff9ab4f3":"code","77abfcc1":"code","9de27d47":"code","c4db537e":"code","0d6cc1fe":"code","88800981":"code","aa2de404":"code","dfcda680":"markdown","84217897":"markdown","ced39b59":"markdown","ba43f93d":"markdown","f64c08c7":"markdown","d99ad374":"markdown","03d7eda7":"markdown","16699ae3":"markdown","e3e6304b":"markdown","9382eb10":"markdown","6c2d81f4":"markdown","eef37b56":"markdown","4ba94a7a":"markdown","19161292":"markdown","23102fc8":"markdown","903366b5":"markdown","2bf23638":"markdown","02b743fa":"markdown","aee8a490":"markdown","1222dfce":"markdown","0445254b":"markdown","e85fb465":"markdown","1986a2ae":"markdown","42864f6f":"markdown","6a592b4a":"markdown","d72687b7":"markdown","1f1a1487":"markdown","c30ed61b":"markdown","1982383e":"markdown","9df9168e":"markdown","03124b3f":"markdown"},"source":{"e55e6ded":"# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","724ea7c4":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","488ff135":"import cudf\n\ntrain = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = cudf.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\nsample_submission = cudf.read_csv('..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')","f35bc68e":"train.tail(3)","49f1b891":"test.tail(3)","c47a0204":"sample_submission.tail(3)","94be8dc4":"type(train)","c55225ef":"type(train.to_pandas())","e4461ac7":"train.to_pandas()","b581c082":"train[['id', 'cat0', 'cat8', 'cont7']].to_pandas()","e1e1f4aa":"type(train.to_pandas())","f459a57d":"y = train.target\n\ny.to_pandas()","c38c049f":"type(y.to_pandas())","60fe758d":"train.shape","bdca9079":"train.info()","f26caff8":"train.describe()","12ec630b":"sns.pairplot(train.to_pandas().sample(100), hue='target');","292ded58":"train.to_pandas().corr().style.background_gradient(cmap='Blues')","214fcb55":"sns.displot(train.to_pandas().target).set(title='Distripution of Target');","4dc0f0d1":"train.columns","a8dac40a":"col_name = train[['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12',\n       'cont13', 'target']]\n\nfor i in col_name:\n    train[i] = train[i].astype(np.float32)","e0d526ec":"train.info()","17ed1bb1":"train_encode = cudf.get_dummies(train)\n\ntest_encode = cudf.get_dummies(test)","fa88fb7b":"train_encode.info()","78927280":"train_encode.columns","f3847de9":"# convert encode data to float32\ncol_name = ['id','cat0_A', 'cat0_B', 'cat1_A', 'cat1_B', 'cat2_A', 'cat2_B',\n       'cat3_A', 'cat3_B', 'cat3_C', 'cat3_D', 'cat4_A', 'cat4_B', 'cat4_C',\n       'cat4_D', 'cat5_A', 'cat5_B', 'cat5_C', 'cat5_D', 'cat6_A', 'cat6_B',\n       'cat6_C', 'cat6_D', 'cat6_E', 'cat6_G', 'cat6_H', 'cat6_I', 'cat7_A',\n       'cat7_B', 'cat7_C', 'cat7_D', 'cat7_E', 'cat7_F', 'cat7_G', 'cat7_I',\n       'cat8_A', 'cat8_B', 'cat8_C', 'cat8_D', 'cat8_E', 'cat8_F', 'cat8_G',\n       'cat9_A', 'cat9_B', 'cat9_C', 'cat9_D', 'cat9_E', 'cat9_F', 'cat9_G',\n       'cat9_H', 'cat9_I', 'cat9_J', 'cat9_K', 'cat9_L', 'cat9_M', 'cat9_N',\n       'cat9_O']\n\nfor i in col_name:\n    train_encode[i] = train_encode[i].astype(np.float32)","7c7e548b":"from cuml.preprocessing import train_test_split\n\nX = train_encode.drop('target', axis=1)\ny = train_encode.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","14d106ea":"\n\n\n\n\nfrom cuml.experimental.preprocessing import StandardScaler\n# scale the X data ONLY\nscaler = StandardScaler()\n# better save it to new var \nX_train_features_scale=X_train.copy()\nX_test_features_scale=X_test.copy()\n\n\nX_train_features_scale[['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']]=scaler.fit_transform(X_train_features_scale[['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']])\nX_test_features_scale[['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']]=scaler.transform(X_test_features_scale[['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6','cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']])\n\n\nX_train_scale = X_train_features_scale # Scale have to be after split data & on train only, .fit_transform() is only for train data\nX_test_scale  = X_test_features_scale      # Scale have to be after split data & on test only,  .transform() is only for test data","e28a7112":"from cuml.ensemble import RandomForestRegressor\n\nrfr1 = RandomForestRegressor()\n\nrfr1.fit(X_train_scale, y_train)","1017ad87":"rfr1_preds = rfr1.predict(X_test_scale)\n\nrfr1_preds.tail()","4007b236":"from cuml.metrics import mean_squared_error\n\ncuml_model_1_mse = mean_squared_error(y_true=y_test,\n                   y_pred=rfr1_preds,\n                   squared=False)\ncuml_model_1_mse","87a059f1":"\nrfr2 = RandomForestRegressor()\n\nrfr2.fit(X_train, y_train)","01183638":"rfr2_preds = rfr2.predict(X_test)\n\nrfr2_preds.tail()","e9963b63":"from cuml.metrics import mean_squared_error\n\ncuml_model_2_mse = mean_squared_error(y_true=y_test,\n                   y_pred=rfr2_preds,\n                   squared=False)\ncuml_model_2_mse","d33bf007":"def baseline_model(n_preds, pred):\n    # just predict the average\n    return cudf.Series([pred for n in range(n_preds)])\n\n# make baseline preds\nbaseline_preds = baseline_model(len(y_test), np.mean(y_train))","61c17113":"# change preds type to float32\nbaseline_preds = baseline_preds.astype(np.float32)","fb8b76e8":"from cuml.metrics import mean_squared_error\n\nbaseline_mse=mean_squared_error(y_true=y_test,\n                   y_pred=baseline_preds,\n                   squared=False)\nbaseline_mse","390c547c":"# download 'dask-ml'\n!pip -q install 'dask-ml'","c2c9d6f1":"import dask_ml.model_selection as dcv","3c24101d":"\n\n\ndask_parameters = {\n    'n_estimators': [100, 200, 500],\n    'max_depth' : [5, 10 , 16, 20, 50],\n    'split_criterion' :[2, 3]\n    }\n\n\nrfr_grid = dcv.GridSearchCV(\n                    rfr2,\n                    dask_parameters,cv=7\n                    )","7d3425fa":"# show Error: AttributeError: 'NoneType' object has no attribute 'fit'\n# rfr_grid.fit(X_train_scale,y_train)","d592004b":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-feb-2021\/test.csv\")\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv')","acb27586":"train.head()","f5513b0f":"# Encode data\nimport category_encoders as ce\n\n# Ordinally Encoded DF \nencoder = ce.OrdinalEncoder()\ntrain_encode = encoder.fit_transform(train)\n\n# Ordinally Encoded DF \nencoder = ce.OrdinalEncoder()\ntest_encode = encoder.fit_transform(test)","11a90aba":"# Split Data\nfrom sklearn.model_selection import train_test_split\n\nX = train_encode.drop('target', axis=1)\ny = train_encode.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","4c28db40":"train_encode.head()","f4f59f88":"# Random forest model\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor()\n\nrfr.fit(X_train, y_train)","31be21a3":"preds = rfr.predict(X_test)\n\npreds[-5: ]","e9f6bcee":"# MSE for model\nfrom sklearn.metrics import mean_squared_error\n\nskl_model_1_mse = mean_squared_error(y_test, preds,squared=False)\nskl_model_1_mse","d697a83d":"# MAE for model\nfrom sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(y_test, preds)","c26f7960":"\n# grid search with sklearn\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = { \n    'n_estimators': [100, 200, 500],\n    'bootstrap': [True],\n    'max_depth' : [5, 10 , 16, 20, 50]\n}\n\n\ngrid = GridSearchCV(rfr,param_grid,cv=3)\ngrid\n","0401a229":"# grid.fit(X_train, y_train)","cb900079":"# best_c=grid.best_params_\n# best_c","9194364f":"\n# ## Change Model Parameters\n# improved_rfr_c = RandomForestRegressor(n_estimators=best_c['n_estimators'],\n#                                       bootstrap=best_c['bootstrap'],\n#                                       max_depth =best_c['max_depth'])\n\n# improved_rfr_c.fit(X_train, y_train)\n","8c932782":"# improved_preds_c = improved_rfr_c.predict(X_test)","bc621cac":"\n# # MSE for model\n# from sklearn.metrics import mean_squared_error\n\n# sk_rf_c=mean_squared_error(y_test, improved_preds_c,squared=False)\n# sk_rf_c\n","dfd90cdf":"train_dum=pd.get_dummies(train)\ntest_dum=pd.get_dummies(test)","1b74a399":"train_dum.head()","0d924f75":"X_d = train_dum.drop('target', axis=1)\ny_d = train_dum.target\n\ndX_train, dX_test, dy_train, dy_test = train_test_split(X_d, y_d, test_size=0.2)","0324bb56":"# Random forest model\nfrom sklearn.ensemble import RandomForestRegressor\n\nrfr_d = RandomForestRegressor()\n\nrfr_d.fit(dX_train, dy_train)","fe9d5a30":"preds_d = rfr_d.predict(dX_test)\n\npreds_d[-5: ]","f063d452":"# MSE for model\nfrom sklearn.metrics import mean_squared_error\n\nskl_model_d_mse = mean_squared_error(dy_test, preds_d,squared=False)\nskl_model_d_mse","e23a31c0":"# MAE for model\nfrom sklearn.metrics import mean_absolute_error\n\nskl_model_d_mae=mean_absolute_error(dy_test, preds_d)\nskl_model_d_mae","b26469d3":"\n\n# grid search with sklearn\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = { \n    'n_estimators': [100, 200, 500],\n    'bootstrap': [True],\n    'max_depth' : [5, 10 , 16, 20, 50]\n}\n\n\ngrid_d = GridSearchCV(rfr_d,param_grid,cv=3)\ngrid_d","357a4ade":"# grid_d.fit(dX_train, dy_train)","44a0b880":"# best_d=grid_d.best_params_\n# best_d","ce366144":"# grid_d.best_score_","6200c777":"# ## Change Model Parameters\n# improved_rfr_d = RandomForestRegressor(n_estimators=best_d['n_estimators'],\n#                                      bootstrap=best_d['bootstrap'],\n#                                      max_depth =best_d['max_depth'])\n\n# improved_rfr_d.fit(dX_train, dy_train)","8f8a47cb":"# improved_preds_d = improved_rfr_d.predict(dX_test)","aec98bab":"# improved_d_mse=mean_squared_error(dy_test, improved_preds_d,squared=False)\n# improved_d_mse","c6d07a15":"\n\nbest_score= {'Baseline Model':baseline_mse,\n                 'RAPIDS Random Forest Regressor Model with Scaled Variables':cuml_model_1_mse,\n                 'RAPIDS Random Forest Regressor Model with No Scaled Variables':cuml_model_2_mse,\n                 'SKlearn Random Forest Regressor Model with Ordinal Encoder':skl_model_1_mse,\n                # 'SKlearn Random Forest Regressor Model with Ordinal Encoder After Optimization':sk_rf_c,\n                 'SKlearn Random Forest Regressor Model with Get Dummies':skl_model_d_mse#,\n                # 'SKlearn Random Forest Regressor Model with Get Dummies After Optimization':improved_d_mse\n                 \n                 }\n\n","9306b1b9":"min_key = min(best_score, key=best_score.get)\nmin_value =best_score[min_key]","f2b314f7":"\n\nprint(f'As seen in the above scores tests, we select {min_key} with a root mean squared error score:{min_value}')\n\n","892e11e6":"# Best Model\nmodels= {'rfr1':cuml_model_1_mse,\n                 'rfr2':cuml_model_2_mse,\n                 'rfr':skl_model_1_mse,\n                 #'improved_rfr_c':sk_rf_c,\n                 'rfr_d':skl_model_d_mse#,\n                 #'improved_rfr_d':improved_d_mse\n                 \n                 }\n\n","ff9ab4f3":"best_model_name = min(models, key=models.get)\nbest_model=models[best_model_name]","77abfcc1":"\nmodels_names_conventer= {'rfr1':rfr1,\n                 'rfr2':rfr2,\n                 'rfr':rfr,\n                 #'improved_rfr_c':improved_rfr_c,\n                 'rfr_d':rfr_d#,\n                 #'improved_rfr_d':improved_rfr_d\n                 \n                 }","9de27d47":"x=models_names_conventer[best_model_name]","c4db537e":"ordinal_encoder=['rfr','improved_rfr_c']\nget_dum=['rfr1','rfr2','rfr_d','improved_rfr_d']","0d6cc1fe":"if best_model_name in ordinal_encoder:\n    test=test_encode\n\n    \nelif best_model_name in get_dum:\n    test=test_dum\n    test['cat6_G']=0","88800981":"\nthe_best_predict=x.predict(test)\nsample_submission['target'] = the_best_predict\n\nsample_submission","aa2de404":"sample_submission.to_csv('submission.csv', index=False)","dfcda680":"[Reference](https:\/\/ml.dask.org\/modules\/generated\/dask_ml.model_selection.GridSearchCV.html)\n","84217897":"Model Optimization\n","ced39b59":"# Improvement Model [Random Forest Regressor]\n\n## We will use gridsearch to find best parameters for the model.\n### But first Need to have Sklearn model ","ba43f93d":"## Second: Get Dummies","f64c08c7":"# EDA","d99ad374":"### Notes\n1. To use sklearn with cudf... convert `cudf.Series` \/ `cudf.DataFrame` `.to_pandas()`..\n2. Using cudf is the same as using pandas but `cudf` instead of `pd`..","03d7eda7":"## Split Data","16699ae3":"## Simple Model Evaluation","e3e6304b":"# The Best Model","9382eb10":"## Simple Model Evaluation","6c2d81f4":"## Spliting the dataset","eef37b56":"## Using the First method: Scaling continuos variables\n[Why to not scale categorical variables](https:\/\/stats.stackexchange.com\/questions\/169350\/centering-and-scaling-dummy-variables\/169358)","4ba94a7a":"# Prepar Data to modling\n","19161292":"## Encode Data","23102fc8":"# submit to kaggle","903366b5":"# RAPIDS Bonus [We solve assignment in both ways Rapids\/Sklearn]","2bf23638":"## We will examin two methods:\n* First: one-hot encoding using Ordinal Encoder\n* Second: one-hot encoding using Get Dummies","02b743fa":"# RAPIDS Random Forest Model\n","aee8a490":"## Using the Second Method: Not Scaling\n[When could you use scale?](https:\/\/medium.com\/greyatom\/why-how-and-when-to-scale-your-features-4b30ab09db5e)","1222dfce":"## Change Float Type to Float32","0445254b":"# Improvement Model [Random Forest Regressor]\n\n \n# Dask GridSearchCV on GPU\n\n### Note: try to do it but failed \n","e85fb465":"# Sklearn Random Forest Model\n","1986a2ae":"## Scale Data","42864f6f":"# Simple Model [Random Forest Regressor]","6a592b4a":"# TPS Feb 2021\nStarter Notebook\n\n## Deleverables\n1. EDA\n    - What's going on?\n    - Show me the data...\n2. Model\n    - Baseline...\n    - Simple...\n    - Evaluation...\n    - Improvement...\n3. RAPIDS Bonus\n    - Apply RAPIDS ([Starter Notebook](https:\/\/www.kaggle.com\/tunguz\/tps-feb-2021-rapids-starter))\n    - Replace pandas with cuDF & sklearn with cuML\n    \n    \n#### Troubleshooting\n- [Data](https:\/\/www.kaggle.com\/c\/tabular-playground-series-feb-2021\/data)\n- [Overview](https:\/\/www.kaggle.com\/c\/tabular-playground-series-feb-2021\/overview)\n- [RF Starter Notebook](https:\/\/www.kaggle.com\/warobson\/tps-feb-2021-rf-starter)\n- [ML repo on GitHub](https:\/\/github.com\/gumdropsteve\/intro_to_machine_learning)\n- [Most simple RAPIDS Notebook submission](https:\/\/www.kaggle.com\/warobson\/simple-rapids-live) (Has stuff like `train_test_split()` with cuml..)\n    \n#### Load Data","d72687b7":"Tried to optimize the model but an error keep showing!","1f1a1487":"### Here we will use two methods:\n\n* First: We will scale continuos variables only \n\n* Second: We do not use scaling at all","c30ed61b":"# Baseline Model","1982383e":"# Simple Model [Random Forest Regressor]","9df9168e":"### Model Optimazition","03124b3f":"## First: Ordinal Encoder"}}