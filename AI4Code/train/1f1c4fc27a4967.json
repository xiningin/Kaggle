{"cell_type":{"6c51fccc":"code","63b58624":"code","17c7aa32":"code","2a886602":"code","9b6706e3":"code","b45ca6f9":"code","58ea7c0a":"code","2894bec6":"code","d062ac42":"code","af1c362e":"code","c8d2898d":"code","36c72261":"code","d2b1c954":"code","d7f7d722":"code","6a0128b1":"code","fb4dfc5c":"code","aaa816c7":"code","a74417c5":"code","775af403":"code","921e7326":"code","4efefbef":"code","747583b4":"code","7d3c9dc0":"code","fa516f5e":"code","2c7b1b4c":"code","9471c8fc":"code","493ab5cc":"code","f4203921":"code","03a9796b":"code","a898f611":"code","4f605f77":"code","7cb60447":"code","d8a940f0":"code","39549c35":"code","b1f47c82":"code","9fbdf641":"code","ac28e643":"code","b54fce83":"code","fad2fe0a":"code","5f2d40e6":"code","8016d964":"code","af012579":"code","141984c8":"code","6e5f8635":"code","4b944ff8":"code","55bd7ed1":"code","b3cf8412":"code","54598da6":"code","bdbe51c0":"code","ba8dd866":"code","7fc42f91":"code","30c39056":"code","626ce7c2":"code","76ebc4e1":"code","0ccbbeea":"code","cae83ba3":"code","c8bf7ea4":"code","78e99946":"code","2cb5ca50":"code","e4602bf5":"code","91c3c92a":"code","88b0b0d2":"code","7e2a656b":"code","36b71f4e":"code","29957093":"code","94376926":"code","f99ce74a":"code","c8341f2d":"code","0bf21f07":"code","245283af":"code","9d1f657e":"code","fdc42341":"code","6fbe48ad":"code","103aafac":"code","a5edee29":"code","1b9207ab":"code","449aff45":"code","634c36ce":"code","8baa0638":"code","50483893":"code","b0075222":"markdown","dae2a089":"markdown","dc42d2a4":"markdown","d0a7ab37":"markdown","15cb2f0a":"markdown","931d008c":"markdown","f07ce1f4":"markdown","3b0a35a3":"markdown","5dae7cf3":"markdown","ab82e96b":"markdown","63ed5c90":"markdown","b2418158":"markdown","d3c699bd":"markdown","2f3c20ff":"markdown","18e42e14":"markdown","57fd6fa8":"markdown","20af4054":"markdown","03458dc6":"markdown","ff734862":"markdown","9b4b4152":"markdown","b4072791":"markdown"},"source":{"6c51fccc":"# import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')","63b58624":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","17c7aa32":"print(train.info())\nprint('#'*30)\nprint(test.info())","2a886602":"# variable for test set 'PassengerId' needed for submission\npassengerId = test['PassengerId']\n\n# combine train and test set\ntitanic = train.append(test, ignore_index=True, sort=False )\n\n# indexes for train and test set for modeling\ntrain_idx = len(train)\ntest_idx = len(titanic) - len(test)","9b6706e3":"# stats summary\ntrain.describe()","b45ca6f9":"# for correlation heatmap reassign female: 1 and male: 0\ntrain['Sex'] = train['Sex'].map({'female': 1, 'male': 0})\n\n# heatmap correlation to 'Survived'\ncorr = train.corr()\nidx = corr.abs().sort_values(by='Survived', ascending=False).index\ncorr_idx = train.loc[:,idx]\ntrain_corr = corr_idx.corr()\nmask = np.zeros_like(train_corr)\nmask[np.triu_indices_from(mask)]=True\nplt.figure(figsize=(8,4))\nsns.heatmap(train_corr, mask=mask, annot=True, cmap='seismic')","58ea7c0a":"plt.figure(figsize=(4,4))\ntrain['Survived'].value_counts().plot.pie(autopct= '%1.1f%%', cmap='Pastel1')","2894bec6":"train['Sex'] = train['Sex'].map({1:'female', 0:'male'})\ntitanic.groupby(['Pclass', 'Sex'])['Survived'].mean()","d062ac42":"# countplot for 'Survived'\nsns.catplot(x='Survived', hue='Sex', data=titanic, col='Pclass', kind='count', palette='seismic', height=4)","af1c362e":"# swarmplot for 'Age'\nsns.catplot(x='Survived', y='Age', hue='Sex', data=titanic, col='Pclass', kind='swarm', height=4, palette='seismic')","c8d2898d":"# swarmplot for 'Fare'\nsns.catplot(x='Survived', y='Fare', hue='Sex', data=titanic, col='Pclass', kind='swarm', height=4, palette='seismic')","36c72261":"# swarmplot for 'SibSp'\nsns.catplot(x='Survived', y='SibSp', hue='Sex', data=titanic, col='Pclass', kind='swarm', height=4, palette='seismic')","d2b1c954":"# swarmplot for 'Parch'\nsns.catplot(x='Survived', y='Parch', hue='Sex', data=titanic, col='Pclass', kind='swarm', height=4, palette='seismic')","d7f7d722":"# missing values\nmissing = titanic.isnull().sum().sort_values(ascending=False)\npct = (titanic.isnull().sum()\/titanic.isnull().count()).sort_values(ascending=False)*100\ntotal_missing = pd.concat([missing, pct], axis=1, keys=['total','percent'])\ntotal_missing[total_missing['total']>0]","6a0128b1":"# 'Fare' NaN value\ntitanic[titanic['Fare'].isnull()]","fb4dfc5c":"# stats summary of 'Fare with 'Pclass and Embarked' groupby\ntitanic.groupby(['Pclass', 'Embarked'])['Fare'].describe()","aaa816c7":"# replace with median fare from 'Pclass' 3\ntitanic.iloc[1043,9] = 8.05","a74417c5":"# 'Embarked' NaN value\ntitanic[titanic['Embarked'].isnull()]","775af403":"# replace with 'C' as passengers' fare is closest to first class median price from 'Embarked' C\ntitanic.iloc[61,11] = 'C'\ntitanic.iloc[829, 11] = 'C'","921e7326":"# deeper look at 'Age' NaN values\n#titanic[titanic['Age'].isnull()].sort_values(by='Name', ascending=True)","4efefbef":"# deeper look at $0.00 fare\ntitanic[titanic['Fare'] == 0]","747583b4":"# median age for passengers with fare $0.00\nwork_median_age = titanic[(titanic['Fare'] == 0) & (titanic['Ticket'] != 'LINE')]['Age'].median()\nwork_median_age","7d3c9dc0":"# function to replace 'Age' NaN values for passengers with $0.00 fare\ndef workers_age(col):\n    Age = col[0]\n    Fare = col[1]\n    if pd.isnull(Age):\n        if Fare == 0:\n            return work_median_age\n    else:\n        return Age","fa516f5e":"# apply function \ntitanic['Age'] = titanic[['Age', 'Fare']].apply(workers_age, axis=1)","2c7b1b4c":"# to replace 'Age' NaN value for the remaining passengers, need to extract social class title from 'Name'\ntitanic['Title'] = titanic['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())","9471c8fc":"# new 'Title' column\ntitanic['Title'].value_counts()","493ab5cc":"# title dictionary to combine similar and rare titles together\nTitle_Dictionary = {\n                    \"Capt\":       \"Officer\",\n                    \"Col\":        \"Officer\",\n                    \"Major\":      \"Officer\",\n                    \"Jonkheer\":   \"Royalty\",\n                    \"Don\":        \"Royalty\",\n                    \"Sir\" :       \"Royalty\",\n                    \"Dr\":         \"Officer\",\n                    \"Rev\":        \"Officer\",\n                    \"the Countess\":\"Royalty\",\n                    \"Dona\":       \"Royalty\",\n                    \"Mme\":        \"Mrs\",\n                    \"Mlle\":       \"Miss\",\n                    \"Ms\":         \"Mrs\",\n                    \"Mr\" :        \"Mr\",\n                    \"Mrs\" :       \"Mrs\",\n                    \"Miss\" :      \"Miss\",\n                    \"Master\" :    \"Master\",\n                    \"Lady\" :      \"Royalty\"\n                    }","f4203921":"# map title dictionary\ntitanic['Title'] = titanic['Title'].map(Title_Dictionary)","03a9796b":"# groupby 'Pclass, Sex, and Title' to get age stats summary\ntitanic.groupby(['Pclass', 'Sex', 'Title'])['Age'].describe()","a898f611":"# deeper look at under 18 passengers\nu_18 = titanic[titanic['Age']<=18]\n#u_18","4f605f77":"# 'Master' median age\nmaster_median_age = u_18[u_18['Title'] == 'Master']['Age'].median()","7cb60447":"# function to replace 'Master' median age\ndef master_age(col):\n    Age = col[0]\n    Title = col[1]\n    if pd.isnull(Age):\n        if Title == 'Master':\n            return master_median_age\n    else:\n        return Age","d8a940f0":"# apply 'master_age' function\ntitanic['Age'] = titanic[['Age', 'Title']].apply(master_age, axis=1)","39549c35":"# deeper look at under 18 female passengers\n#u_18[u_18['Sex'] == 'female']","b1f47c82":"# function to rename 'Miss' to 'Missy' to represent girls under 15\ndef girls_title(df):\n    if df['Title'] == 'Miss':\n        if df['Age'] < 15:\n            return 'Missy'\n        else:\n            return df['Title']\n    else:\n        return df['Title']","9fbdf641":"# apply function 'girls_title'\ntitanic['Title'] = titanic[['Title', 'Age']].apply(girls_title, axis=1)\n\n# groupby 'Pclass, Sex, and Title' updated stats summary for 'Age'\nmedian_pclass_age = titanic.groupby(['Pclass', 'Sex', 'Title'])\n#median_pclass_age['Age'].describe()","ac28e643":"# lambda function to fill in remaining NaN values based on median age from 'median_pclass_age'\ntitanic['Age'] = median_pclass_age['Age'].apply(lambda x: x.fillna(x.median()))","b54fce83":"# fill in 'Cabin' NaN values with 'U' for unknown\ntitanic['Cabin'] = titanic['Cabin'].fillna('U')","fad2fe0a":"# verify missing values, only 'Survived' should have missing values\ntitanic.isnull().sum().sort_values(ascending=False)","5f2d40e6":"# plots for continuous 'Age' and 'Fare'\nfig, axes = plt.subplots(1,2, figsize=(10,4))\nsns.distplot(titanic['Age'], ax=axes[0])\nsns.distplot(titanic['Fare'], ax=axes[1])","8016d964":"# groupby ticket and count passengers traveling on same ticket\ntitanic['Same_Ticket'] = titanic.groupby('Ticket')['PassengerId'].transform('count')\n\n# count the number of passengers traveling in a group\ntitanic[titanic['Same_Ticket'] >1]['Same_Ticket'].count()","af012579":"# divide 'Fare' by 'Same_Ticket'\ntitanic['Fare'] = titanic['Fare'] \/ titanic['Same_Ticket']\n\n# np.log1p 'Fare' to normalize\ntitanic['Fare_log1p'] = np.log1p(titanic['Fare'])\n\n# updated distribution plots for fare\nfig, axes = plt.subplots(1,2, figsize=(10,4))\nsns.distplot(titanic['Fare'], ax=axes[0])\nsns.distplot(titanic['Fare_log1p'], ax=axes[1])","141984c8":"# new 'Family' to represent passengers traveling with family or not\ntitanic['Family'] = titanic['SibSp'] + titanic['Parch']\n\n# new 'Family_size' to represent total number of family members, if equal 1, passenger is traveling alone or with non family group\ntitanic['Family_size'] = titanic['Parch'] + titanic['SibSp'] + 1\n#titanic['Family_size'].value_counts()","6e5f8635":"# deeper look at passengers with no family\nno_family = titanic[(titanic['SibSp'] == 0) & (titanic['Parch'] ==0)]\n\n# groupby to count number of passengers with same ticket and no family members\nno_family['Friends_group'] = no_family.groupby('Ticket')['PassengerId'].transform('count')\n\n# add 'Family' and 'Friends_group' to get group size\nno_family['Group_size'] = no_family['Family'] + no_family['Friends_group']","4b944ff8":"# update titanic dataset with 'no_family'\nnf = no_family[['PassengerId', 'Group_size']]\n\n# create 'Group_size' from 'Family_size'\ntitanic['Group_size'] = titanic['Family_size']\n\n# update titanic with 'no_family' data\nnew_df = titanic[['PassengerId', 'Group_size']].set_index('PassengerId')\nnew_df.update(no_family.set_index('PassengerId'))\ntitanic['Group_size'] = new_df.values\ntitanic['Group_size'] = titanic['Group_size'].astype(int)","55bd7ed1":"# clean 'Ticket' by extracting letters and converting digit only tickets to 'xxx'\ntickets = titanic['Ticket'].apply(lambda t: t.split('.')[0].split()[0].replace('\/','').replace('.',''))\n\n# convert to list\ntickets = tickets.tolist()","b3cf8412":"# function to convert digit only tickets to 'xxx'\ndef ticket_digits(t):\n    v = []\n    for i in t:\n        if i.isnumeric():\n            i == 'xxx'\n            v.append(i)\n        else:\n            v.append(i)\n    return v","54598da6":"# call 'ticket_digits' function\ntickets = ticket_digits(tickets)\n\n# assign to titanic dataset\ntitanic['Ticks'] = pd.DataFrame(tickets)\n\n# number of clean tickets \nticket_count = dict(titanic['Ticks'].value_counts())\ntitanic['Ticket_count'] = titanic['Ticks'].apply(lambda t: ticket_count[t])","bdbe51c0":"# extract surnames from 'Name'\ntitanic['Surname'] = titanic['Name'].apply(lambda x: x.split(',')[0].strip())\n\n# create 'SurnameId' to group same surname\ntitanic['SurnameId'] = titanic.groupby('Surname').ngroup().add(1)\n\n# groupby 'Ticket' and 'Surname' to represent groups with same ticket or family\ntitanic['GroupId'] = titanic.groupby(['Ticket', 'Surname']).ngroup().add(1)\n","ba8dd866":"# extract 'Cabin' letters to group\ntitanic['Cabin_group'] = titanic['Cabin'].apply(lambda x: x[0])","7fc42f91":"# separate dataframe to calculate confidence\ngroup_survival = titanic[['Pclass', 'Survived', 'Surname', 'SurnameId', 'Group_size', 'GroupId', 'Family_size', 'Ticket']]\n\n# sum the number of survivors in a group\ngroup_survival['group_survived'] = group_survival.groupby('GroupId')['Survived'].transform('sum')\n\n# adjust the number of survivors in a group\ngroup_survival['adj_survived'] = group_survival['group_survived'] - group_survival['Survived'].apply(lambda x: 1 if x == 1 else 0)\n\n# sum the number of dead in a group\ngroup_survival['group_dead'] = group_survival.groupby('GroupId')['Survived'].transform('count') - group_survival.groupby('GroupId')['Survived'].transform('sum')\n\n# adjust the number of dead in a group\ngroup_survival['adj_dead'] = group_survival['group_dead'] - group_survival['Survived'].apply(lambda x: 1 if x == 0 else 0)\n\n# confidence of survival on single group of passengers\nno_data = (group_survival['Group_size'] - group_survival['adj_survived'] - group_survival['adj_dead'])\/(group_survival['Group_size'])\n\n# calculate confidence\nconfidence = 1 - no_data\ngroup_survival['confidence'] = confidence * ((1\/group_survival['Group_size']) * (group_survival['adj_survived'] - group_survival['adj_dead']))\n\n# assign back to titanic\ntitanic['confidence'] = group_survival['confidence']","30c39056":"# plot for 'Ticks'\nplt.figure(figsize=(10,4))\nsns.barplot(x= 'Ticks', y='Survived', data=titanic[titanic['Ticket_count']>10])\nplt.axhline(y = np.mean(titanic.groupby('Ticks')['Survived'].mean()), linestyle='-.')","626ce7c2":"# plots for 'Family_size', 'Group_size', and 'Cabin_group'\nfig, axes = plt.subplots(1,3, figsize=(16,4))\nsns.barplot(x='Family_size', y='Survived', data=titanic, ax=axes[0])\naxes[0].axhline(y=np.mean(titanic.groupby('Family_size')['Survived'].mean()), linestyle='-.')\nsns.barplot(x='Group_size', y='Survived', data=titanic, ax=axes[1])\naxes[1].axhline(y=np.mean(titanic.groupby('Group_size')['Survived'].mean()), linestyle='-.')\nsns.barplot(x='Cabin_group', y='Survived', data=titanic, ax=axes[2])\naxes[2].axhline(y=np.mean(titanic.groupby('Cabin_group')['Survived'].mean()), linestyle='-.')","76ebc4e1":"# add column for 'Kid'\ntitanic['Kid'] = (titanic['Age'] < 15).astype(int)","0ccbbeea":"# function to categorize 'Family_size'\ndef family_2_cat(df):\n    if df <= 2:\n        return 'single'\n    elif (df > 2) & (df < 5):\n        return 'small'\n    elif df >= 5:\n        return 'large'     ","cae83ba3":"# apply function on 'Family_size'\ntitanic['Family_cat'] = titanic['Family_size'].apply(family_2_cat)","c8bf7ea4":"# bin 'Age' to range\npd.cut(titanic['Age'], 5).value_counts()","78e99946":"# function to categorize 'Age'\ndef age_2_cat(df):\n    if df < 15:\n        return 'kid'\n    elif (df >= 15) & (df <= 32):\n        return 'young adult'\n    elif (df > 32) & (df <= 64):\n        return 'adult'\n    elif (df > 64):\n        return 'senior'","2cb5ca50":"# apply function 'age_2_cat'\ntitanic['Age_range'] = titanic['Age'].apply(age_2_cat)","e4602bf5":"# bin 'Fare' to a range\ntitanic['Fare_range'] = pd.qcut(titanic['Fare'],3, labels=False)","91c3c92a":"# select best and worst survival chance from 'Ticks'\ntitanic['PC'] = (titanic['Ticks'] == 'PC').astype(int)\ntitanic['CA'] = (titanic['Ticks'] == 'CA').astype(int)\n\n# select best and worst survival chance from 'Cabin_group'\ntitanic['D'] = (titanic['Cabin_group'] == 'D').astype(int)\ntitanic['U'] = (titanic['Cabin_group'] == 'U').astype(int)","88b0b0d2":"# Feature correlation heatmap sorted by most correlated to \"Survived\"\ncorr = titanic.corr()\nidx = corr.abs().sort_values(by='Survived', ascending=False).index\ntrain_corr_idx = titanic.loc[:, idx]\ntrain_corr = train_corr_idx.corr()\nmask = np.zeros_like(train_corr)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize=(20,10))\nsns.heatmap(train_corr, mask=mask, annot =True, cmap = 'seismic')","7e2a656b":"# select \nfeatures = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Title','Group_size', 'CA', 'PC','Kid','confidence', 'Fare_log1p']\n\ntitanic_full = titanic[features]\n\n# map female to 0, male to 1\ntitanic_full['Sex'] = titanic_full['Sex'].map({'female': 0, 'male': 1})\n\n# get dummy variables\ntitanic_feats = pd.get_dummies(titanic_full)","36b71f4e":"# assign to train and test set\ndf_train = titanic_feats[:train_idx]\ndf_test = titanic_feats[test_idx:]\n\n# assign for train test split\nX = df_train\ny = train['Survived']\ntest_X = df_test","29957093":"# import necessary modeling libraries\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier","94376926":"# scale continuous data\nscaler = MinMaxScaler()\n\n# fit, tranform on X and transform on test_X\nX[['Fare_log1p','Group_size']] = scaler.fit_transform(X[['Fare_log1p', 'Group_size']])\ntest_X[['Fare_log1p', 'Group_size']] = scaler.transform(test_X[['Fare_log1p','Group_size']])","f99ce74a":"# train split test\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 8)","c8341f2d":"# models\nrfc = RandomForestClassifier()\nsvc = SVC()\nknn = KNeighborsClassifier()\ngboost = GradientBoostingClassifier()\nlogreg = LogisticRegressionCV()\n\nmodels = [rfc, svc, knn, gboost, logreg]","0bf21f07":"for model in models:\n    print('cross validation of: {0}'.format(model.__class__))\n    score = cross_val_score(model, x_train, y_train, cv= 5, scoring = 'accuracy')\n    print('cv score: {0}'.format(np.mean(score)))\n    print('#'*50)","245283af":"# RFC\nrfc = RandomForestClassifier(oob_score=True)\n\n# fit\nrfc.fit(x_train, y_train)\n\n# oob_score_\nprint(rfc.oob_score_)\n\n# model score\nprint(rfc.score(x_train,y_train))\n\n# prediction on x_test\ny_pred = rfc.predict(x_test)\n\n# classification report\nprint(classification_report(y_test, y_pred))\n\n# confusion matrix\nprint(confusion_matrix(y_test, y_pred))\n\n# accuracy score\nprint('model accuracy: ',accuracy_score(y_test,y_pred))\n\n# train error by RMSE\nprint('train error rmse: ',np.sqrt(mean_squared_error(y_train, rfc.predict(x_train))))","9d1f657e":"# features of importance plot\nfeats = pd.DataFrame()\nfeats['feats'] = x_train.columns\nfeats['importance'] = rfc.feature_importances_\nfeats.sort_values(by='importance', ascending=True, inplace=True)\nfeats.set_index('feats', inplace=True)","fdc42341":"feats.plot(kind='barh')","6fbe48ad":"rfc_submit = pd.DataFrame({'PassengerId': passengerId, 'Survived': rfc.predict(test_X)})\nrfc_submit.to_csv('rfc_submit.csv', index=False)","103aafac":"# Optimize RFC parameters with GridSearchCV\nmodel = RandomForestClassifier()\n\n# parameters \nparameters = {\n    \"n_estimators\": [50,100,200,300,400,500],\n    \"max_depth\": [i for i in range(2,8)], \n    \"min_samples_leaf\": [i for i in range(2,8)],\n    \"max_leaf_nodes\": [i for i in range(6,12)],\n    \"bootstrap\": [True],\n    'oob_score': [True],\n    'max_features': [1,2,3]\n}\n\n# GridSearchCV (kaggle notebook reason will comment out)\n#grid = GridSearchCV(estimator=model, param_grid=parameters, scoring='accuracy', n_jobs=-1, verbose=1, cv=5)","a5edee29":"# fit x_train, y_train, for \n# grid.fit(x_train,y_train)","1b9207ab":"# print('best estimator: ', grid.best_estimator_)\n# print('best params: ', grid.best_params_)","449aff45":"best_estimator = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=6, max_features=3, max_leaf_nodes=7,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=2, min_samples_split=2,\n            min_weight_fraction_leaf='deprecated', n_estimators=50,\n            n_jobs=None, oob_score=True, random_state=None, verbose=0,\n            warm_start=False)\n\nbest_params = {'bootstrap': True, 'max_depth': 6, 'max_features': 3, 'max_leaf_nodes': 7, 'min_samples_leaf': 2, 'n_estimators': 50, 'oob_score': True}\n    ","634c36ce":"rfc_grid = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=6, max_features=3, max_leaf_nodes=7,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=2, min_samples_split=2,\n            min_weight_fraction_leaf='deprecated', n_estimators=50,\n            n_jobs=None, oob_score=True, random_state=None, verbose=0,\n            warm_start=False)","8baa0638":"warnings.filterwarnings('ignore')\nrfc_grid.fit(x_train, y_train)\nprint('oob score: ', rfc_grid.oob_score_)\nprint('accuracy score on x_test: ',accuracy_score(y_test, rfc_grid.predict(x_test)))","50483893":"# optimized RFC prediction\ngrid_prediction = pd.DataFrame({'PassengerId': passengerId, 'Survived': rfc_grid.predict(test_X)})\ngrid_prediction.to_csv('prediction.csv', index=False)","b0075222":"#### EDA","dae2a089":"- The title 'Miss' is to classify all single female passenger regardless of age. To create a group similar to 'Master' title, will classify girls under 15 as 'Missy' title.\n- By creating another 'Title' group, a more accurate age of passengers can be calculated to see if correlation has improved.\n- Filling in median age for female passengers should be more accurate based on title.\n","dc42d2a4":"- Optimized RFC prediction: 0.80382\n- Thoughts to improve Kaggle score: better model optimization, feature engineering on passengers traveling as groups,  married couple only,  and parents with children only.\n- Thanks for taking a look!","d0a7ab37":"- The title 'Masters' only represent boys under 15 years old.\n- Adults are age 15 and above.","15cb2f0a":"- A mix of English, French, royalty, and rare social titles aboard the Titanic","931d008c":"- Passengers with the ticket LINE are crew.\n- The rest all had a working relationship with the Titanic.","f07ce1f4":"#### Data Cleaning and Feature Engineering","3b0a35a3":"#### Data Preprocessing","5dae7cf3":"- got 0.75119 score\n- now to optimize model","ab82e96b":"- The highest numerical correlation is 'Fare,' one can assume that a passenger who bought a more expensive ticket such first class ticket can get to a life boat quicker then a passenger who bought a cheaper ticket, as first class was above deck. \n- Categorical 'Pclass' has a negative correlation meaning that depending on which 'Pclass' a passenger is in, that passenger has a less chance of survival.\n- Logically 'Sex' is highest correlated as 'Women and Children first' code have priority evacuation to emergency lifeboats.\n- Surprisingly 'Age' correlation to survival is quite low.","63ed5c90":"- 'Age' is slightly positive skewed, will leave as is, however 'Fare' is positively skewed and not normal distribution. \n- 'Fare' will be unskew and normalize if to use in prediction.\n- To unskew and normalize 'Fare', first find passengers that are traveling on same ticket, passengers that travel in a group their 'Fare' represents the total price paid for the ticket. ","b2418158":"- In each class, females had the highest percentage of survival.\n- 50% of female passengers in third class survived the lowest amount for females.\n- 36% of male passengers survived in first class the highest amount for males.\n- A total of 38.4% passengers survived from the dataset.","d3c699bd":"#### Feature Selection and Modeling","2f3c20ff":"- Some passengers incorrectly grouped, such as same family but bought different ticket.","18e42e14":"- There 596 passengers that are traveling in groups.\n- To find individual ticket price, divide 'Fare' by 'Same_Ticket'","57fd6fa8":"- For train and test set, majority of missing data are in 'Age' and 'Cabin'. \n-  'Pclass' and 'Survived' are ordinal features. 'Age' and 'Fare' are continous features. 'Ticket' and 'Cabin' contains alphanumeric values. 'PassengerId' is an index.","20af4054":"### Titanic: Machine Learning from Disaster\n- This Titanic dataset is a classic Machine Learning tutorial.\n- I will perform data cleaning, EDA, feature engineering and use classifcation models to predict survivors on the Titanic.\n- Analysis of this dataset was done during a bootcamp. Improved my original score from 0.65 before bootcamp to  0.79 during bootcamp.\n- Credit to [Geoffrey Wong](https:\/\/www.kaggle.com\/csw4192) for helping me get over the damn hump that is 0.80 prediction score with his 'Survivor Confidence'.","03458dc6":"- missing data from 'Survived' is for model prediction.","ff734862":"#### Calculating group survival confidence ","9b4b4152":"- some passengers have $0.00 fare.\n- some passengers have same ticket.\n- some passengers have same surname but with different ticket.","b4072791":"- For passengers under 18 years old, it seems boys survived more than girls. \n- For passengers over 18 years old, as expected females survived more than males because of \"Women and Children first\" code. \n- In first and second class, passengers with family on board has a higher chance of surviving than without. Higher fares had more survivors than lower fares.\n- First class as expected has more survivors than other classes because first class is above deck and is in closer proximity to lifeboats. \n- Females from third class survived more than males from first class."}}