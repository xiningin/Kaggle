{"cell_type":{"8c09be18":"code","9104cd25":"code","3bc84c54":"code","f35e0c11":"code","a87eb7d5":"code","4dbf7ffe":"code","7f173159":"code","dee0dbd9":"code","46eb5ba0":"code","6c8e1217":"code","a13e9685":"code","98463ddd":"code","31214df2":"code","40d8193f":"code","812de6ed":"code","fbb07a7b":"code","836ae346":"code","5e2e4fe6":"code","52af8b02":"code","864b31b2":"code","cdbcd2d8":"code","e035723e":"code","a3dc268a":"code","b4124f69":"code","0faca11f":"code","2100ce0c":"markdown","39238c22":"markdown","adbe02f7":"markdown","0204c57f":"markdown","f10ea917":"markdown","11b90911":"markdown","5196b7f0":"markdown","17eb8c26":"markdown","64f7139b":"markdown","c0bf2101":"markdown","87639105":"markdown","1d8cd00f":"markdown","cad267c7":"markdown","e81006bc":"markdown","75244406":"markdown","f72732b2":"markdown","7a390dc8":"markdown"},"source":{"8c09be18":"## Most Important\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n## less Important\nfrom functools import partial\nfrom scipy import stats\nimport missingno as msno\nfrom pathlib import Path\nfrom PIL import Image\nimport joblib\nimport tarfile\nimport shutil\nimport urllib\nimport os\n\n## Sklearn\nfrom sklearn import datasets\n## Preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n## Metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\n## tensorflow & Keras\nimport tensorflow as tf    ## i will use tf for every thing and for keras using tf.keras\nfrom keras import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","9104cd25":"train_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ntrain_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/train')\n\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntrain_images_paths.head()","3bc84c54":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img)\n        plt.axis('off')\n        i+=1","f35e0c11":"print('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\nprint(\"=\"*40)\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)","a87eb7d5":"train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((13440, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(train_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint(\"=\"*40)\nprint('train_full_labels.shape =>', train_full_labels.shape)","4dbf7ffe":"sns.set()\nplt.figure(figsize=(12,7))\nplt.title('Letters vs Count in Label', fontsize=18, y=1.02)\n\nax = sns.barplot(x=[*range(1,29)],\n                 y=pd.Series(train_full_labels).value_counts().sort_index(),\n                 color='#255db8')\n\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_height())),\n                    (p.get_x()+0.2, p.get_height()+50))\n\nplt.show()","7f173159":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint(\"=\"*40)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","dee0dbd9":"def create_model2(use_activation='relu', use_optimizer='adam', use_initializer='uniform'):\n    model = Sequential()\n\n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', \n                     activation=use_activation, input_shape=(32,32,3)))\n    \n    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation=use_activation))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation= use_activation))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation= use_activation))\n    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(256, activation=use_activation))\n    model.add(Dense(256, activation=use_activation))\n    model.add(Dropout(0.5))\n    model.add(Dense(29, activation=\"softmax\"))\n    \n    model.compile(optimizer=use_optimizer, \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy']\n                 )\n    \n    return model\n","46eb5ba0":"model = create_model2(use_initializer='he_uniform', use_activation='relu', use_optimizer='Nadam')","6c8e1217":"model.summary()","a13e9685":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nearly_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",\n                                                 monitor='val_accuracy',\n                                                 verbose=1,\n                                                 save_best_only=True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                                  factor=0.5,\n                                                  patience=4,\n                                                  min_lr=0.00005,\n                                                  verbose=1)","98463ddd":"aug = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1)\n\ngen_train = aug.flow(X_train, y_train, batch_size=64)\n\ngen_val = aug.flow(X_valid, y_valid, batch_size=64)","31214df2":"history = model.fit(gen_train, validation_data=gen_val, \n                    epochs=100, batch_size=512, callbacks=[checkpoint, reduce_lr])","40d8193f":"model.load_weights(\"weights.hdf5\")","812de6ed":"# plot loss function for train and validation.\nplt.figure(figsize=(10,7))\nplt.title('loss and validation loss with epochs', \n          fontsize=16)\n\nplt.plot(history.history['loss'],\n         marker='o',\n         color=\"green\",\n         label=\"loss\")\n\nplt.plot(history.history['val_loss'],\n         marker='o',\n         color=\"orange\", \n         label=\"val_loss\")\n\nplt.legend()\n\nplt.show()","fbb07a7b":"# plot accuracy for train and validation data.\nplt.figure(figsize=(10,7))\nplt.title('accuracy and validation accuracy with epochs',\n          fontsize=16)\n\nplt.plot(history.history['accuracy'],\n         marker='o',\n         color=\"green\",\n         label=\"accuracy\")\n\nplt.plot(history.history['val_accuracy'],\n         marker='o',\n         color=\"orange\",\n         label=\"val_accuracy\")\n\nplt.legend()\nplt.show()","836ae346":"loss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint(\"=\"*40)\nprint('acc_all_data =>', acc_all_data)","5e2e4fe6":"classes = np.argmax(model.predict(train_full_set), axis=-1)\ncm = confusion_matrix(train_full_labels, classes)\n\nplt.figure(figsize=(10,10))\nplt.title(\"Confusion Matrix\",fontsize=16)\nsns.heatmap(cm, fmt='d', cmap='viridis', annot = True, square=True, cbar=False)\nplt.show()","52af8b02":"test_labels = pd.read_csv('..\/input\/arabic-hwr-ai-pro-intake1\/test.csv')\ntest_images = Path(r'..\/input\/arabic-hwr-ai-pro-intake1\/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()","864b31b2":"print('Number of Instances in test_set is', len(test_images_paths))","cdbcd2d8":"test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_paths):\n    img = plt.imread(path)\n    img = img[:,:,:3]\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)","e035723e":"y_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)","a3dc268a":"test_labels['label'] = y_preds_classes","b4124f69":"test_labels[['id', 'label']].to_csv('\/kaggle\/working\/submission.csv', index=False)","0faca11f":"test_labels.set_index('id').head(8)","2100ce0c":"**The notebook is structured in the following way:**\n\n> Explore the Data.\n\n> Data Preprocessing.\n\n> Model Training.\n\n> Evaluation on Testing DataSet.","39238c22":"### Arabic Handwriting Recognizer | \u270d\ufe0f","adbe02f7":"### Split the Data","0204c57f":"### Loading the Train Data","f10ea917":"**Generate Image Train Data**","11b90911":"## Data Preprocessing","5196b7f0":"## Model Training","17eb8c26":"#### CNN for Arabic Handwritten Characters dataset classification","64f7139b":"**Import Necessary Librariess**","c0bf2101":"**Save Prediction**","87639105":"### Thanks For Read My Notebook :)","1d8cd00f":"## Model Analysis","cad267c7":"**Predict Test label**","e81006bc":"**Read Test Data**","75244406":"**Train Model**","f72732b2":"## Explore the Data","7a390dc8":"## Evaluation on Testing DataSet"}}