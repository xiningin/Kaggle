{"cell_type":{"b940eccc":"code","4b8fabae":"code","1e6a37ed":"code","2ccd3460":"code","b5acb5d2":"code","d0aef4de":"code","d02bc979":"code","2118f175":"code","3c2bb396":"code","6cecd935":"code","82352e60":"code","0d537598":"code","87395715":"code","c0d957df":"code","74041e8b":"code","b41e70f7":"code","1d611385":"code","d38a22f2":"code","18c2328e":"code","76ba9525":"code","d2eeb8e0":"code","62c87e66":"code","4d82b627":"code","9323a4a4":"code","2c05fd39":"code","f0fd26fe":"code","a83e595d":"code","f3a3e7e6":"code","fba2183c":"code","4cf6653c":"code","9d7953f4":"code","5d2a5fb2":"code","128621f7":"code","eedadf61":"code","37a8cfa5":"code","3da88ebe":"code","449a08ed":"code","767082fc":"code","f4e14a51":"code","00399874":"code","fa1fa2be":"code","7e445c6c":"code","70788d3f":"code","d336a3ee":"code","491094fa":"code","154df442":"code","e41ec97e":"code","7b0619cd":"code","08c699d0":"code","8234c455":"code","2343500a":"code","8d1030e0":"markdown","1b8e9d74":"markdown","0ea57eec":"markdown","de047000":"markdown","098a2ab8":"markdown","17a521e3":"markdown","51e16059":"markdown","fe121b48":"markdown","ade0989f":"markdown","9d68d4ca":"markdown","46b8bc71":"markdown","53f5a6d0":"markdown","45b779c1":"markdown","1720b0c0":"markdown","9c76d8ea":"markdown","11946edd":"markdown","29a39505":"markdown","c14c6613":"markdown","75103317":"markdown","eea78221":"markdown","e6781480":"markdown","b553f310":"markdown","4a6ca637":"markdown","f6158683":"markdown","c6c787f3":"markdown","2eb98f14":"markdown","bb22b834":"markdown","7e956a49":"markdown","e660eddb":"markdown","d253b096":"markdown","3f68716d":"markdown","dc89aa02":"markdown"},"source":{"b940eccc":"# Biblioteca para manipula\u00e7\u00e3o de Dados\nimport pandas as pd\n\n# Biblioteca para plotar os gr\u00e1ficos\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Biblioteca para opera\u00e7\u00e3o matem\u00e1ticas de matrizes e arrays\nimport numpy as np\n\n# Biblioteca para filtrar warnings e n\u00e3o apresentar na tela\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Biblioteca utilizada durante as opera\u00e7\u00f5es de Feature Selection e Treinamento do Modelo\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.linear_model import LogisticRegression\n\n# Biblioteca utilizada durante a padroniza\u00e7\u00e3o dos dados\nfrom sklearn.preprocessing import StandardScaler\n\n# Biblioteca utilizada para realizar o balanceamento dos dados\n#!pip install imblearn (instala\u00e7\u00e3o do pacote caso n\u00e3o exista)\nfrom imblearn.over_sampling import SMOTE\n\n# Bibilioteca utilizada durante o split dos dados em treino e teste\nfrom sklearn.model_selection import train_test_split\n\n# Biblioteca utilizada para avalia\u00e7\u00e3o do modelo criado\nfrom sklearn import metrics\n\n# Biblioteca utilizada para realizar o cross-validation com os dados teste\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# Biblioteca utilizada para otimiza\u00e7\u00e3o de hyper-parametros\nfrom sklearn.model_selection import GridSearchCV","4b8fabae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1e6a37ed":"# Carregando o dataset de treino utilizando Pandas\nds_train = pd.read_csv(\"\/kaggle\/input\/projeto4_telecom_treino.csv\", sep = \",\")","2ccd3460":"# Visualizando os primeiros 15 registros do Dataset.\nds_train.head(15)","b5acb5d2":"# Visualizando as informa\u00e7\u00f5es do Dataset\nds_train.info()","d0aef4de":"# Removendo a Coluna {Unnamed: 0} que est\u00e1 caracterizando a sequ\u00eancia de registros do Dataset.\nds_train = ds_train.drop('Unnamed: 0', axis=1)","d02bc979":"# Verificando os valores distintos de cada coluna do dataset\nfor i in ds_train.columns:\n    x = ds_train[i].unique()\n    print(x)","2118f175":"# Fun\u00e7\u00e3o que ser\u00e1 utilizada para transforma algumas vari\u00e1veis string em Num\u00e9ricas atrav\u00e9s de um mapeamento de dict.\ndef transformColumns(dataset):\n    \n    # Transforma as strings de valores Yes\/No em 1\/0 e atribui em um nvo campo, exceto a vari\u00e1vel target Churn\n    dictmapYesNo = {\"yes\": 1, \"no\": 0}\n    \n    dataset['international_plan_num'] = dataset['international_plan'].map(dictmapYesNo)\n    dataset['voice_mail_plan_num'] = dataset['voice_mail_plan'].map(dictmapYesNo)    \n    dataset['churn'] = dataset['churn'].map(dictmapYesNo)\n        \n    # Remove as strings dos c\u00f3digos de Area, preservando somente o c\u00f3digo em um novo campo\n    dictmapAreaCode = {\"area_code_415\": 0, \"area_code_408\": 1, \"area_code_510\": 2}\n\n    dataset['area_code_num'] = dataset['area_code'].map(dictmapAreaCode)\n    \n    # Transforma o valor dos status em Numeros em um novo campo\n    dictmapState = {'KS': 1000, 'OH': 1001, 'NJ': 1002, 'OK': 1003, 'AL': 1004, 'MA': 1005, \n                    'MO': 1006, 'LA': 1007, 'WV': 1008, 'IN': 1009, 'RI': 1010, \n                    'IA': 1011, 'MT': 1012, 'NY': 1013, 'ID': 1014, 'VT': 1015, \n                    'VA': 1016, 'TX': 1017, 'FL': 1018, 'CO': 1019, 'AZ': 1020, \n                    'SC': 1021, 'NE': 1022, 'WY': 1023, 'HI': 1024, 'IL': 1025, \n                    'NH': 1026, 'GA': 1027, 'AK': 1028, 'MD': 1029, 'AR': 1030, \n                    'WI': 1031, 'OR': 1032, 'MI': 1033, 'DE': 1034, 'UT': 1035, \n                    'CA': 1036, 'MN': 1037, 'SD': 1038, 'NC': 1039, 'WA': 1040, \n                    'NM': 1041, 'NV': 1042, 'DC': 1043, 'KY': 1044, 'ME': 1045, \n                    'MS': 1046, 'TN': 1047, 'PA': 1048, 'CT': 1049, 'ND': 1050\n                   }\n    \n    dataset['state_num'] = dataset['state'].map(dictmapState)\n  \n\n    # Transforma as vari\u00e1veis que eram strings e foram manipuladas em Categ\u00f3ricas\n    dataset['international_plan'] = dataset['international_plan'].astype('category')\n    dataset['voice_mail_plan']    = dataset['voice_mail_plan'].astype('category')    \n    dataset['area_code']          = dataset['area_code'].astype('category')\n    dataset['state']              = dataset['state'].astype('category')\n\n    # Reordenando as colunas para que a coluna TARGET (churn) seja a \u00faltima coluna do Dataframe\n    dataset = dataset[[col for col in dataset if col not in ['churn']] + ['churn']]    \n    \n    return dataset","3c2bb396":"ds_train = transformColumns(ds_train)","6cecd935":"ds_train.info()","82352e60":"ds_train.head(10)","0d537598":"ds_train.describe()","87395715":"# Verificando se existem valores NULL\nds_train.isnull().values.any()","c0d957df":"# Analisando como est\u00e1 a distribui\u00e7\u00e3o dos Dados na vari\u00e1vel churn (nossa TARGET). \n# 0 -> N\u00e3o 1 -> Sim\nds_train.groupby('churn').size()","74041e8b":"Count_No = len(ds_train[ds_train['churn']==0])\nCount_Yes = len(ds_train[ds_train['churn']==1])\n\nprint (\"Percentual de Clientes que Cancelaram: \", round((Count_Yes \/ (Count_Yes+Count_No))*100,2))\nprint (\"Percentual de Clientes que N\u00e3o Cancelaram: \", round((Count_No \/ (Count_Yes+Count_No))*100,2))","b41e70f7":"columns = ds_train.select_dtypes(exclude='category').columns\n\nfor i in columns:\n    #ds_train[i].plot(kind = 'hist')\n    sns.distplot(ds_train[i], rug=True)\n    plt.title('Histograma Vari\u00e1vel: ' + i)\n    plt.xlabel(i)    \n    plt.show()","1d611385":"cols = [col for col in ds_train.columns if col not in ['international_plan_num','voice_mail_plan_num','area_code_num','state_num','churn']]\nfor i in cols:\n    pd.crosstab(ds_train[i], ds_train.churn).plot(kind = 'bar')\n    plt.show()","d38a22f2":"# Removendo os dados categ\u00f3ricos\ncolumns = ds_train.select_dtypes(exclude='category').columns\n\nfor i in columns:\n    #ds_train[i].plot(kind = 'box')\n    sns.boxplot(ds_train[i])\n    plt.title('BoxPlots Vari\u00e1vel: ' + i)  \n    plt.show()","18c2328e":"ds_train.corr()","76ba9525":"correlations = ds_train.corr()\n\nfig = plt.figure() # Cria uma figura em branco\nax = fig.add_subplot(111)\ncax = ax.matshow(correlations, vmin = -1, vmax = 1) #Mostrar as correla\u00e7\u00f5es\nfig.colorbar(cax)\n# Definir o tamanho do array. Tamanho escolhido com base no # de variaveis\nticks = np.arange(1, 20, 1) \nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(ds_train.columns)\nax.set_yticklabels(ds_train.columns)\nplt.show()","d2eeb8e0":"ds_train.corr()['churn']","62c87e66":"# Remove as colunas Categ\u00f3ricas.\nds_train_FeatureSelect = ds_train.drop(['voice_mail_plan','area_code','state','international_plan'], axis=1)\n\n# Transforma o Dataframe do Pandas em um Array Numpy (Array \u00e9 um formato esperado para utiliza\u00e7\u00e3o do RFE)\nds_train_array = ds_train_FeatureSelect.values\n\n# Separando os dados em inputs(features) e outputs (target)\nfeatures_x = ds_train_array[:,:-1] # selecionando todas as colunas exceto a ultima (que \u00e9 a TARGET)\ntarget_y = ds_train_array[:,19:] # selecionando somente a ultima coluna Target\n\n# Criando o modelo utilizando Regress\u00e3o Logistica\nLogReg = LogisticRegression()\n\n# Aplicando o modelo RFE\nrfe = RFECV(LogReg, cv=4, scoring='accuracy')\nfit = rfe.fit(features_x, target_y)\n\nplt.figure()\nplt.xlabel(\"Numero de Features Seleciondas\")\nplt.ylabel(\"Cross validation score (# de classifica\u00e7\u00f5es corretas)\")\nplt.plot(range(1, len(rfe.grid_scores_) + 1), rfe.grid_scores_)\nplt.show()\n\n# Print dos resultados\nprint(\"Vari\u00e1veis Preditoras:\", ds_train_FeatureSelect.columns[:-1])\nprint(\"Vari\u00e1veis Selecionadas: %s\" % fit.support_)\nprint(\"Ranking dos Atributos: %s\" % fit.ranking_)\nprint(\"N\u00famero de Melhores Atributos: %d\" % fit.n_features_)\n\ndel ds_train_FeatureSelect\ndel features_x\ndel target_y\ndel ds_train_array","4d82b627":"# Selecionando somente as colunas escolhidas pelo algoritmo RFECV como mais relevantes e melhor acur\u00e1cia para treinamento.\ndef SelectVariablesRFECV(dataset):\n    datasetReturn = dataset[['total_intl_calls', 'total_intl_charge','number_customer_service_calls', 'international_plan_num',\n                                                       'voice_mail_plan_num', 'churn']]\n    \n    return datasetReturn","9323a4a4":"ds_train_Selected = SelectVariablesRFECV(ds_train)","2c05fd39":"ds_train_Selected.describe()","f0fd26fe":"columns = [col for col in ds_train_Selected.columns if col not in ['churn']]\nfor i in columns:\n    #ds_train_Selected[i].plot(kind = 'hist')\n    sns.distplot(ds_train_Selected[i], rug=True)\n    plt.title('Histograma Vari\u00e1vel: ' + i)\n    plt.xlabel(i)    \n    plt.show()","a83e595d":"columns = [col for col in ds_train_Selected.columns if col not in ['churn']]\n\nfor i in columns:\n    #ds_train_Selected[i].plot(kind = 'box')\n    sns.boxplot(data=ds_train_Selected[i])\n    plt.title('BoxPlots Vari\u00e1vel: ' + i)  \n    plt.show()","f3a3e7e6":"def standardizationData(dataset):\n    # Transforma o Dataframe do Pandas em um Array Numpy (Array \u00e9 um formato esperado para utiliza\u00e7\u00e3o do StandardScale)\n    ds_train_array = dataset.values\n\n    # Separando os dados em inputs(features) e outputs (target)\n    features_x = ds_train_array[:,:-1] # selecionando todas as colunas exceto a ultima (que \u00e9 a TARGET)\n    target_y = ds_train_array[:,5:] # selecionando somente a ultima coluna Target\n\n    # Gerando os novos dados Padronizados\n    StScaler = StandardScaler(with_mean=False, with_std=False).fit(features_x)\n    ds_train_return = StScaler.transform(features_x) # Transformamos somente as vari\u00e1veis preditoras.\n\n    # Nomeia as colunas\n    df_features = pd.DataFrame(ds_train_return, columns= ['total_intl_calls', 'total_intl_charge','number_customer_service_calls', 'international_plan_num',\n                                                           'voice_mail_plan_num'])\n    df_target = pd.DataFrame(target_y, columns=['churn'])\n\n    # Junta os 2 dataframes por coluna\n    ds_train_return = pd.concat([df_features,df_target],axis=1) \n\n    del (ds_train_array)\n    del (features_x)\n    del (target_y)\n    del (StScaler)\n    del (df_features)\n    del (df_target)\n\n    return ds_train_return","fba2183c":"ds_train_standard = standardizationData(ds_train_Selected)\nds_train_standard.head(5)","4cf6653c":"ds_train_standard.describe()","9d7953f4":"columns = [col for col in ds_train_Selected.columns if col not in ['churn']]\nfor i in columns:\n    #ds_train_Selected[i].plot(kind = 'hist')\n    sns.distplot(ds_train_Selected[i], rug=True)\n    plt.title('Histograma Vari\u00e1vel (After Standard): ' + i)\n    plt.xlabel(i)    \n    plt.show()","5d2a5fb2":"columns = [col for col in ds_train_standard.columns if col not in ['churn']]\n\nfor i in columns:\n    #ds_train_standard[i].plot(kind = 'box')\n    sns.boxplot(data=ds_train_standard[i])\n    plt.title('BoxPlots Vari\u00e1vel: ' + i)  \n    plt.show()","128621f7":"def BalancingData(dataset, var_target):\n    \n    # Split da variavel target e variaveis preditoras\n    x_train = dataset.drop([var_target], axis=1)\n    y_train = dataset[var_target]\n    \n    smt = SMOTE()\n    \n    # Separando os dados em features e target\n    features_train, target_train = smt.fit_sample(x_train, y_train)\n    \n    target_train_DF = pd.DataFrame(target_train)\n    # atribuindo o nome da coluna\n    target_train_DF.columns = ['churn']\n    \n    features_train_DF = pd.DataFrame(features_train)\n    features_train_DF.columns = x_train.columns\n    \n    return pd.concat([features_train_DF, target_train_DF], axis=1)","eedadf61":"ds_train_final = BalancingData(ds_train_standard, 'churn')\n\nCount_No = len(ds_train_final[ds_train_final['churn']==0])\nCount_Yes = len(ds_train_final[ds_train_final['churn']==1])\n\nprint (\"Percentual de Clientes que Cancelou Depois do Balanceamento: \", round((Count_Yes \/ (Count_Yes+Count_No))*100,2))\nprint (\"Percentual de Clientes que N\u00e3o Cancelou Depois do Balanceamento: \", round((Count_No \/ (Count_Yes+Count_No))*100,2))","37a8cfa5":"ds_train_array = ds_train_final.values\n\n# Separando os dados em inputs(features) e outputs (target)\nfeatures_x = ds_train_array[:,:-1] # selecionando todas as colunas exceto a ultima (que \u00e9 a TARGET)\ntarget_y = ds_train_array[:,5:] # selecionando somente a ultima coluna Target\n\n# Definindo o tamanho da amonstra\ndata_size_test = 0.30 # 30%\n\n# Criando os conjuntos de dados de treino e de teste\nX_treino, X_teste, Y_treino, Y_teste = train_test_split(features_x, target_y, test_size = data_size_test)\n\ndel (features_x)\ndel (target_y)\ndel (data_size_test)\ndel (ds_train_array)","3da88ebe":"# Cria\u00e7\u00e3o do modelo\nmodelo = LogisticRegression()\n\n# Treinamento do modelo com os dados de treino\nmodelo.fit(X_treino, Y_treino)\n\n# Acur\u00e1cia do modelo nos dados de teste\n# Utilizado \nmodelo.score(X_teste, Y_teste)","449a08ed":"def CrossValidation(model, x_test, y_test, metric_scoring, kfold):\n    \n    cv_result = cross_val_score(model, X= x_test, y= y_test, cv=kfold, scoring= metric_scoring)\n\n    return print(\"Cross-Validation mean:\",cv_result.mean())","767082fc":"kfold = KFold(n_splits= 10, shuffle=True)\n\nCrossValidation(modelo, X_teste, Y_teste, 'accuracy', kfold)","f4e14a51":"# Prevendo o resultado do modelo informando as vari\u00e1veis preditoras de teste, para depois realizar a classifica\u00e7\u00e3o e taxa\n# de acerto obtido pelo modelo.\ntarget_predicted = modelo.predict(X_teste)\ntarget_proba     = modelo.predict_proba(X_teste)\n\nprint(\"Accuracy (TP\/Total):\",metrics.accuracy_score(Y_teste, target_predicted))\nprint(\"Precision (TP\/TP+FP):\",metrics.precision_score(Y_teste, target_predicted))\nprint(\"Recall (TP\/TP+FN):\",metrics.recall_score(Y_teste, target_predicted))\nprint(\"Classification Report:\")\nprint(metrics.classification_report(Y_teste, target_predicted))\nprint(target_proba)","00399874":"cnf_matrix = metrics.confusion_matrix(Y_teste, target_predicted)\n\nclass_names = [1,0]\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"viridis\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","fa1fa2be":"valores_grid = {'C': [0.001,0.01,0.1,1,10,100,1000,1000000]}\n\nrsearch = GridSearchCV(estimator = modelo, param_grid = valores_grid)\n\nrsearch.fit(X_treino, Y_treino)\n\nrsearch.best_score_\n","7e445c6c":"# Carregando o dataset de treino utilizando Pandas\nds_test = pd.read_csv(\"\/kaggle\/input\/projeto4_telecom_teste.csv\", sep = \",\")\nds_test.head(5)","70788d3f":"# Remove a coluna \nds_test = ds_test.drop('Unnamed: 0', axis=1)","d336a3ee":"# Verificando se existe valores missing\nds_test.isnull().values.any()","491094fa":"ds_test = transformColumns(ds_test)\nds_test.head(5)","154df442":"# Aplica a sele\u00e7\u00e3o de Vari\u00e1veis \nds_test_Selected = SelectVariablesRFECV(ds_test)","e41ec97e":"# Aplica a padroniza\u00e7\u00e3o dos dados e remover a coluna Churn\nds_test_standard = standardizationData(ds_test_Selected)\n\nds_test_standard = ds_test_standard.drop('churn', axis=1)\n\nds_test_standard.head(5)","7b0619cd":"# Transforma as vari\u00e1veis target em array\nfeatures_x = ds_test_standard.values","08c699d0":"predicted_value = modelo.predict(features_x)\npredicted_proba = modelo.predict_proba(features_x)\n\npredict_value_df = pd.DataFrame(predicted_value, columns=['A\u00e7\u00e3o Prevista'])\npredict_proba_df = pd.DataFrame(predicted_proba, columns=['Prob. N\u00e3o Cancelamento','Prob. Cancelamento'])","8234c455":"result_final = pd.concat([ds_test_standard, predict_value_df, predict_proba_df],axis=1)\nresult_final.head(10)","2343500a":"result_final.groupby('A\u00e7\u00e3o Prevista').size()","8d1030e0":"### A - Pr\u00e9-Processamento: 5. Padroniza\u00e7\u00e3o das vari\u00e1veis\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html\n\nAssim como o algoritmo RFECV utilizado na etapa de feature Selection, o algoritmo StandardScaler esperar que os dados sejam em formato de Array.","1b8e9d74":"### B - Aprendizado e Avalia\u00e7\u00e3o: 5. Otimiza\u00e7\u00e3o do modelo (Ajuste de Hiper-parametros)","0ea57eec":"Com base nos dados observados na c\u00e9lula acima, \u00e9 poss\u00edvel notar que algumas vari\u00e1veis podem ter seu tipo transformado de \"object\" vari\u00e1veis num\u00e9ricas.","de047000":"\u00c9 poss\u00edvel verificar que as vari\u00e1veis: {total_eve_calls}, {total_night_calls} e {area_code_num} s\u00e3o as vari\u00e1veis que menos possuem correla\u00e7\u00e3o com a vari\u00e1vel TARGET (churn), podendo ser candidatas a serem removidas durante o treinamento do modelo.","098a2ab8":"\u00c9 poss\u00edvel notal que os dados n\u00e3o est\u00e3o balanceados. Deve-se utilizar t\u00e9cnicas de balanceamento para que o modelo criado n\u00e3o fique t\u00eandencioso por aprender mais sobre uma classifica\u00e7\u00e3o que outra.","17a521e3":"### A - Pr\u00e9-Processamento: 2. Tratamento de dados","51e16059":"# Prevendo Customer Churn de Operadoras Telecom\n\nO objetivo do projeto \u00e9 conseguir prever se os clientes ir\u00e3o encerrar o relacionamento comercial (Sim ou N\u00e3o) e a probabilidade de cada op\u00e7\u00e3o de ocorrer.\n\nIrei utilizar um modelo de Regress\u00e3o Log\u00edstica para extrair as informa\u00e7\u00f5es necess\u00e1rias e previs\u00f5es.","fe121b48":"### BoxPlots","ade0989f":"### Gerando Histogramas para compreender a distribui\u00e7\u00e3o dos Dados","9d68d4ca":"### Importa\u00e7\u00e3o de Bibliotecas e pacotes necess\u00e1rios","46b8bc71":"### Gerando BoxPlots para compreender a dispers\u00e3o dos dados","53f5a6d0":"### C - Previs\u00e3o: 2. Previs\u00e3o de novos dados","45b779c1":"### A - Pr\u00e9-Processamento: 1. Carregar os Dados","1720b0c0":"### Verificando qual a rela\u00e7\u00e3o de var\u00edaveis categ\u00f3ricas em rela\u00e7\u00e3o a vari\u00e1vel TARGET (churn)","9c76d8ea":"### B - Aprendizado e Avalia\u00e7\u00e3o: 2. Escolha do Modelo a ser utilizado\nComo determinado nas especifica\u00e7\u00f5es do projeto, o modelo a ser utilizado ser\u00e1 o de Regress\u00e3o Logist\u00edca","11946edd":"### B - Aprendizado e Avalia\u00e7\u00e3o: 3. Cross-Validation\nAplicando Cross-Validation para encontrar a m\u00e9dia das previs\u00f5es do modelo com dados de teste.","29a39505":"### A - Pr\u00e9-Processamento: 4. Feature Selection\nSer\u00e1 utilizado a t\u00e9cnica RFE (Recursive Feature Elimination) que \u00e9 baseado na id\u00e9ia de construir repetidamente um modelo e escolher a que obtiver melhor ou pior desempenho at\u00e9 que os recursos sejam esgotados.\n\nO objetivo do RFE \u00e9 selecionar recursos considerando recursivamente os conjuntos de recursos cada vez menor.\n\nhttps:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_selection.RFE.html","c14c6613":"### Resumo das vari\u00e1veis escolhidas pelo RFECV como mais relevantes para utiliza\u00e7\u00e3o","75103317":"\u00c9 poss\u00edvel verificar que as vari\u00e1veis escolhidas durante o Feature Selection possuem muitos outliers (os quais n\u00e3o ser\u00e3o removidos da an\u00e1lise) e portanto, aplicar a t\u00e9cnica de Normaliza\u00e7\u00e3o dos dados pode n\u00e3o ser a melhor. A partir dessa observa\u00e7\u00e3o, a decis\u00e3o escolhida ser\u00e1 aplicar a t\u00e9cnica de Padroniza\u00e7\u00e3o que ir\u00e1 ajustar os dados para m\u00e9dia = 0 e desvio padr\u00e3o = 1.","eea78221":"O resultado obtido ap\u00f3s a otimiza\u00e7\u00e3o utilizando GridSearchCV n\u00e3o foi relevante para o modelo.","e6781480":"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n### Improvement - to DO:\n\nRealizar o tratamento dos outliers das vari\u00e1veis como forma de otimizar a acur\u00e1cia do modelo final.","b553f310":"### C - Previs\u00e3o: 1. Tratamento dos Dados\nRemover a vari\u00e1vel Target, Selecionar as vari\u00e1veis obtidas durante a Feature Selection e Realizar a padroniza\u00e7\u00e3o de dados.","4a6ca637":"### B - Aprendizado e Avalia\u00e7\u00e3o: 4. Confusion Matrix\nUsado para descrever a performance da classifica\u00e7\u00e3o de um modelo em um conjunto de dados de teste cujo os valores reais s\u00e3o conhecidos.","f6158683":"### A - Pr\u00e9-Processamento: 3. Realizando An\u00e1lises Explorat\u00f3rias dos Dados para compreend\u00ea-los","c6c787f3":"## Etapas a serem executadas:\n\nA - Pr\u00e9-Processamento\n\n    OK 1. Carregar os Dados;\n    OK 2. Tratamento dos Dados;\n    OK 3. Realizar an\u00e1lise explorat\u00f3ria das vari\u00e1veis para entender como os dados est\u00e3o distribu\u00eddos e relacionados;\n    OK 4. Feature Selection (Escolha das vari\u00e1veis mais relevantes para serem utilizadas no modelo);\n    OK 5. Padroniza\u00e7\u00e3o das vari\u00e1veis;\n    5.5 Remover os registros que possuem valores outliers, (Regress\u00e3o Log\u00edstica tem dificuldade com dados outliers);\n    OK 6. Balanceamento dos Dados (Caso exista mais dados de uma classifica\u00e7\u00e3o que outra);\n        \n    Obs: Quando os dados de Treino e Teste veem em Dataset separados, a opera\u00e7\u00e3o deve ser realizada nos dados de Treino\n    e tamb\u00e9m nos dados de Teste.\n\nB - Aprendizado e Avalia\u00e7\u00e3o\n\n    OK 1. Split do dataset Treino em Treino\/Teste (Para ser poss\u00edvel avaliar a taxa de aprendizagem do modelo);\n    OK 2. Escolha do Modelo a ser utilizado;\n    OK 3. Cross-Validation;\n    OK 4. Confusion Matrix dos dados originais x previstos;\n    OK 5. Otimiza\u00e7\u00e3o do modelo (Ajuste de Hiper-parametros);\n    \nC - Previs\u00e3o\n\n    OK 1. Tratamento dos Dados (Realizar as opera\u00e7\u00f5es realizadas no Ds Treino no Ds Teste e remover a Target caso exista);\n    OK 2. Previs\u00e3o de novos dados;\n    3. Apresenta\u00e7\u00e3o Final dos Dados;","2eb98f14":"### Histogramas","bb22b834":"Dos dados utilizados para realizar previs\u00f5es, \u00e9 poss\u00edvel notar que das 1667 Operadoras-Telecom, 539 ir\u00e3o cancelar.","7e956a49":"### B - Aprendizado e Avalia\u00e7\u00e3o: 1. Split do dataset Treino em Treino\/Teste","e660eddb":"### A - Pr\u00e9-Processamento: 6. Balanceamento dos Dados\nComo Verificado durante a etapa 3, os dados est\u00e3o desbalanceados e para que o modelo n\u00e3o fique tend\u00eancioso, ser\u00e1 utilizado a t\u00e9cnica SMOTTE para incluir novos dados e balancear a quantidade de cada classe.","d253b096":"\u00c9 poss\u00edvel visualizar que o melhor resultado obtido atrav\u00e9s do Cross Validation considerando a Acur\u00e1cia \u00e9 quando utilizamos 5 vari\u00e1veis, por\u00e9m por escolha pessoal, podemos realizar o treinamento utilizando quantas e quais vari\u00e1veis for desejado.\n\nVari\u00e1veis consideradas: {total_intl_calls, \n                         total_intl_charge, \n                         number_customer_service_calls, \n                         international_plan_num, \n                         voice_mail_plan_num\n                        }","3f68716d":"### Descri\u00e7\u00f5es das Vari\u00e1veis obtidas no Kaggle\n\n    1.\"state\", string. 2-letter code of the US state of customer residence\n    2.\"account_length\", numerical. Number of months the customer has been with the current telco provider\n    3.\"area_code\", string=\"area_code_AAA\" where AAA = 3 digit area code.\n    4.\"international_plan\", (yes\/no). The customer has international plan.\n    5.\"voice_mail_plan\", (yes\/no). The customer has voice mail plan.\n    6.\"number_vmail_messages\", numerical. Number of voice-mail messages.\n    7.\"total_day_minutes\", numerical. Total minutes of day calls.\n    8.\"total_day_calls\", numerical. Total minutes of day calls.\n    9.\"total_day_charge\", numerical. Total charge of day calls.\n    10.\"total_eve_minutes\", numerical. Total minutes of evening calls.\n    11.\"total_eve_calls\", numerical. Total number of evening calls.\n    12.\"total_eve_charge\", numerical. Total charge of evening calls.\n    13.\"total_night_minutes\", numerical. Total minutes of night calls.\n    14.\"total_night_calls\", numerical. Total number of night calls.\n    15.\"total_night_charge\", numerical. Total charge of night calls.\n    16.\"total_intl_minutes\", numerical. Total minutes of international calls.\n    17.\"total_intl_calls\", numerical. Total number of international calls.\n    18.\"total_intl_charge\", numerical. Total charge of international calls\n    19.\"number_customer_service_calls\", numerical. Number of calls to customer service\n    20.\"churn\", (yes\/no). Customer churn - target variable.","dc89aa02":"### Verificando a correla\u00e7\u00e3o entre as vari\u00e1veis "}}