{"cell_type":{"46ebb8cf":"code","6d698712":"code","3a1b637f":"code","d12a8adb":"code","e2836ca5":"code","35559f37":"code","e3be1653":"code","f7238bfb":"code","6cec2146":"code","c7cca1df":"code","3f1813b0":"code","9351e211":"code","b811e824":"code","7b0b7e1c":"code","9cfc9996":"code","d47c0ad6":"code","38fbfe7f":"code","4607b1d5":"code","71c60e47":"code","012a29e2":"code","f3929a1c":"code","07202be9":"code","1507f271":"code","cdf93b73":"code","a75083fc":"code","a6afd3f0":"code","561e0556":"code","2254df38":"code","aff2b69e":"code","9d319463":"code","ed553478":"code","8a7a6784":"code","a70b97a3":"code","60857560":"code","d5d0e69a":"code","944960b2":"code","4857bfb1":"code","540a6cb5":"code","464cda36":"code","7a0666d3":"code","cdbafa3d":"code","a4277a82":"code","724b6543":"code","a3c1a7d7":"code","d51e5c88":"code","1c0f7b74":"code","98b53b2c":"code","628d13aa":"markdown","1583f71f":"markdown","b9051ad5":"markdown","04143523":"markdown","4fb0f3e8":"markdown","ac0942df":"markdown","10595b9e":"markdown","a9839661":"markdown","da7c8e74":"markdown","242d2f71":"markdown"},"source":{"46ebb8cf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport scipy \nimport matplotlib.pyplot as plt\nfrom scipy import stats","6d698712":"data = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')","3a1b637f":"data","d12a8adb":"data.info()\n# :) Happy There Is No Null-Value","e2836ca5":"data.columns","35559f37":"data.describe()","e3be1653":"data['Serial No.'].nunique()","f7238bfb":"data.duplicated().sum()","6cec2146":"plt.figure(figsize=(15, 13))\nplt.grid(True)\nplt.title('Distribution' )\n\nplt.subplot(441)\nsns.distplot(data['GRE Score'], bins=50)\nplt.legend(loc=1)\n\nplt.subplot(442)\nsns.distplot(data['TOEFL Score'], bins=50)\nplt.legend(loc=1)\n\nplt.subplot(443)\nsns.distplot(data['University Rating'], bins=50)\nplt.legend(loc=1)\n\nplt.subplot(444)\nsns.distplot(data['SOP'], bins=50)\nplt.legend(loc=1)\n\nplt.subplot(445)\nsns.distplot(data['CGPA'], bins=50)\nplt.legend(loc=1)\n\nplt.subplot(446)\nsns.distplot(data['LOR '], bins=50)\nplt.legend(loc=1)\n\nplt.subplot(447)\nsns.distplot(data['Research'], bins=50)\nplt.legend(loc=1)\n\n\nplt.subplot(448)\nsns.distplot(data['Chance of Admit '], bins=50)\nplt.legend(loc=1)\nplt.show()","c7cca1df":"p_cha = stats.norm.pdf(data['Chance of Admit '].values, 0.72174, 0.14114)\nc, d = np.histogram(data['Chance of Admit '], bins = 50)\n# ideal:\nideal = stats.norm.rvs(size=len(data['Chance of Admit ']), loc=0.72174, scale=0.14114)\niC, iD = np.histogram(ideal, bins=50)","3f1813b0":"# kullback_leibler_divergence:\ndef kl(p, q):\n    result = np.sum(np.where(np.logical_and(p!=0, q!=0), p * np.log(p\/q), 0))\n    return result","9351e211":"c = c\/500\niC = iC\/500\nkl(c, iC)","b811e824":"sns.distplot(ideal, bins=50, color='y')\nsns.distplot(data['Chance of Admit '], bins=50, color='black')","7b0b7e1c":"from scipy.stats import binom\nfrom scipy import stats\n\nc, d = np.histogram(data['TOEFL Score'], bins=50)\nic, idd = np.histogram(data['GRE Score'], bins=50)\n\nstats.kstest(c, 'norm')","9cfc9996":"sns.heatmap(data.corr(), annot=True)","d47c0ad6":"data.groupby('TOEFL Score')['Chance of Admit '].size().sort_values(ascending=False)[:10].plot(kind='pie', autopct='%.2f')","38fbfe7f":"data.groupby('TOEFL Score')['Chance of Admit '].mean().plot(kind='bar', figsize=(10, 5), ylabel='chance agree')","4607b1d5":"data[data['TOEFL Score'] == 120]['Chance of Admit ']","71c60e47":"data.groupby(['TOEFL Score', 'Research'])['Chance of Admit '].mean().plot(kind='bar', figsize=(15, 8), ylabel='chance agree', grid=True)","012a29e2":"from sklearn.feature_selection import SelectKBest, chi2","f3929a1c":"data.drop('Serial No.', axis='columns', inplace=True)","07202be9":"x = data.iloc[:, :-1]\ny =  data.iloc[:, -1].values * 100\ny = y.astype('int')","1507f271":"from sklearn.feature_selection import SelectKBest, chi2\n\nbestfeatures = SelectKBest(score_func=chi2, k=4)\n\nfit = bestfeatures.fit(abs(x), y)\nscore = pd.DataFrame(fit.scores_)\n\ncolumns = pd.DataFrame(x.columns)\n\nfeatureScores = pd.concat([columns,score],axis=1)\nfeatureScores.columns = ['columns','Score']\n\nfeatureScores","cdf93b73":"data.groupby(['TOEFL Score', 'GRE Score', 'University Rating'])['Chance of Admit '].mean().sort_values(ascending=False)[:100].plot(kind='bar', figsize=(20, 15))","a75083fc":"data['University Rating'].value_counts()","a6afd3f0":"data.describe()","561e0556":"def convert_bin(x):\n    if x < 92:\n        return 'bad'\n    elif  x >= 92 and x < 103:\n        return 'not bad'\n    elif x >= 103 and x < 107:\n        return 'normal'\n    elif x >= 107 and x < 112:\n        return 'good'\n    else:\n        return 'great'","2254df38":"data['TOEFL Score'] = data['TOEFL Score'].map(convert_bin)","aff2b69e":"data_index = data.set_index('Chance of Admit ')","9d319463":"above_85 = data_index[data_index.index > 0.85]","ed553478":"above_85.describe()","8a7a6784":"plt.figure(figsize=(15, 13))\nplt.grid(True)\nplt.title('Distribution' )\n\nplt.subplot(441)\nsns.distplot(above_85['GRE Score'], bins=20)\nplt.legend(loc=1)\n\n\n\nplt.subplot(443)\nsns.distplot(above_85['University Rating'], bins=20)\nplt.legend(loc=1)\n\nplt.subplot(444)\nsns.distplot(above_85['SOP'], bins=20)\nplt.legend(loc=1)\n\nplt.subplot(445)\nsns.distplot(above_85['CGPA'], bins=20)\nplt.legend(loc=1)\n\nplt.subplot(446)\nsns.distplot(above_85['LOR '], bins=20)\nplt.legend(loc=1)\n\nplt.subplot(447)\nsns.distplot(above_85['Research'], bins=20)\nplt.legend(loc=1)\n\n","a70b97a3":"x_train = x.iloc[:400, :]\nx_test = x.iloc[400:, :]\ny_train = y[:400]\ny_test = y[400:]","60857560":"x_train['GRE Score'] = x_train['GRE Score'] \/ max(x_train['GRE Score'])\nx_train['TOEFL Score'] = x_train['TOEFL Score'] \/ max(x_train['TOEFL Score'])","d5d0e69a":"x_train.describe()","944960b2":"from sklearn.linear_model import LinearRegression\nreg = LinearRegression().fit(x_train, y_train)\nreg.score(x_train, y_train)","4857bfb1":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import cross_val_score\nregressor = DecisionTreeRegressor(max_depth=8).fit(x_train, y_train)\n#cross_val_score(regressor, x_train, y_train, cv=10)\nregressor.score(x_train, y_train)\n","540a6cb5":"predict_r = regressor.predict(x_test)","464cda36":"from sklearn.preprocessing import StandardScaler\nstn = StandardScaler()\nx_train = stn.fit_transform(x_train)\nx_test = stn.fit_transform(x_test)","7a0666d3":"from sklearn.svm import SVC\nsvm = SVC(kernel='poly', C=100, gamma='auto')\nsvm.fit(x_train, y_train)\nprint(svm.score(x_train, y_train))\ny_predict = svm.predict(x_test)","cdbafa3d":"print(y_predict)\nprint(y_test)","a4277a82":"def check(y_predict, y_test):\n    same = []\n    diff = []\n    for i in range(len(y_predict)):\n        #print(i)\n        if y_predict[i] == y_test[i]:\n            same.append(y_predict[i])\n        else:\n            diff.append(y_test[i])\n    return same, diff","724b6543":"result_same, result_diff = check(y_predict, y_test)","a3c1a7d7":"print(len(result_same))\nprint(len(result_diff))","d51e5c88":"predict_r = predict_r.astype('int')","1c0f7b74":"print(predict_r)\nprint(y_test)","98b53b2c":"plt.title('True Label')\nplt.scatter(y_test, y_test, color='red')\nplt.figure()\nplt.title('decissionTree predict')\nplt.scatter(predict_r, predict_r)\nplt.figure()\nplt.title('svm predict')\nplt.scatter(y_predict, y_predict, color='green')","628d13aa":"# Tree","1583f71f":"# Statistic:","b9051ad5":"# SVM","04143523":"# Best Features:","4fb0f3e8":"## Not Complete:","ac0942df":"## Now Let's Deep On How People Has Chance To Be Top %0.85: ","10595b9e":"# LinearRegression","a9839661":"# Create Model:\n","da7c8e74":"## Let's Undrestand The Distribution Of Each Columns:","242d2f71":"## No Duplicated Value In Serial No"}}