{"cell_type":{"43d16b9d":"code","91ddf05f":"code","5794a405":"code","f4962c26":"code","b33b13eb":"code","9b36d943":"code","e78d3b81":"code","198091d4":"code","9229ffa4":"code","ecc2852d":"code","8a4806cf":"code","4c82ddd8":"markdown"},"source":{"43d16b9d":"# What this is doing? please refer to my above linked kernel\n#!pip install ..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4\/ > \/dev\/null\npackage_path = '..\/input\/underscripts\/'\nimport sys\nsys.path.append(package_path)","91ddf05f":"import pdb\nimport os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\nfrom albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\nfrom albumentations.torch import ToTensor\nimport torch.utils.data as data\nfrom model import Unet","5794a405":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","f4962c26":"class TestDataset(Dataset):\n    '''Dataset for test prediction'''\n    def __init__(self, root, df, mean, std,TTA=False):\n        self.root = root\n        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n        self.fnames = df['ImageId'].unique().tolist()\n        self.num_samples = len(self.fnames)\n        if TTA==True:\n            self.transform = Compose(\n                [\n                    HorizontalFlip(),\n                    Normalize(mean=mean,std=std,p=1),\n                    ToTensor(),\n                ]\n            )\n        else:\n            self.transform = Compose(\n                [\n                    Normalize(mean=mean, std=std, p=1),\n                    ToTensor(),\n                ]\n            )\n\n    def __getitem__(self, idx):\n        fname = self.fnames[idx]\n        path = os.path.join(self.root, fname)\n        image = cv2.imread(path)\n        images = self.transform(image=image)[\"image\"]\n        return fname, images\n\n    def __len__(self):\n        return self.num_samples","b33b13eb":"def post_process(probability, threshold, min_size):\n    '''Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored'''\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros((256, 1600), np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num","9b36d943":"!ls ..\/input\/ures184fold\/","e78d3b81":"sample_submission_path = '..\/input\/severstal-steel-defect-detection\/sample_submission.csv'\ntest_data_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"","198091d4":"# initialize test dataloader\nbest_threshold = 0.5\nnum_workers = 2\nbatch_size = 1\nprint('best_threshold', best_threshold)\nmin_size = 3500\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\ndf = pd.read_csv(sample_submission_path)\ntestset = DataLoader(\n    TestDataset(test_data_folder, df, mean, std),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)\n\ntestset_TTA = DataLoader(\n    TestDataset(test_data_folder,df,mean,std,TTA=True),\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True\n)","9229ffa4":"# Initialize mode and load trained weights\npredictions = []\nmodel_name = \"resnet18\"\nmodels = []\nfor i in range(4):\n    #ckpt_path = \"..\/input\/uresnet\/u-resnet18_fold_{}.pth\".format(i)\n    ckpt_path = \"..\/input\/ures184fold\/u-resnet18_fold_{}.pth\".format(i)\n    device = torch.device(\"cuda\")\n    model = Unet(encoder_type=\"resnet\",encoder_name=\"resnet18\",classes=4,activation=None)\n    model.to(device)\n    model.eval()\n    state = torch.load(ckpt_path,map_location=lambda storage,loc:storage)\n    model.load_state_dict(state[\"state_dict\"])\n    models.append(model)","ecc2852d":"# start prediction\npredictions = []\nfor i, (batch,batch_TTA) in enumerate(tqdm(zip(testset,testset_TTA))):\n    fnames, images = batch\n    fnames, images_TTA = batch\n    batch_preds = 0\n    for model in models:\n        pred = torch.sigmoid(model(images.to(device))).detach().cpu().numpy()\n        pred_TTA = torch.sigmoid(model(images_TTA.to(device))).detach().cpu().numpy()\n        batch_preds += (pred+pred_TTA[:,:,:,::-1])\/2\n        batch_preds+=pred\n    batch_preds\/= len(models)\n    #batch_preds = batch_preds.detach().cpu().numpy()\n    for fname, preds in zip(fnames, batch_preds):\n        for cls, pred in enumerate(preds):\n            pred, num = post_process(pred, best_threshold, min_size)\n            rle = mask2rle(pred)\n            name = fname + f\"_{cls+1}\"\n            predictions.append([name, rle])\n\n# save predictions to submission.csv\ndf = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\ndf.to_csv(\"submission.csv\", index=False)","8a4806cf":"df.head(50)","4c82ddd8":"### UNet Inference kernel\n\nThis kernel is an inference kernel of my [UNet starter kernel](https:\/\/www.kaggle.com\/rishabhiitbhu\/unet-starter-kernel-pytorch-lb-0-888). \nDon't forget to add the `model.pth` file generated from the starter kernel as dataset to predict on the test set."}}