{"cell_type":{"9e40df21":"code","e40d7156":"code","83eaf0d2":"code","81bd2a35":"code","3c31d0b3":"code","cb031a6c":"code","cded6e5c":"code","d6f87672":"code","82b0f224":"code","bb30d462":"code","ebe88a59":"code","91bdf4eb":"code","65310206":"markdown","82a7d7f3":"markdown","4373c307":"markdown","90406665":"markdown","f3459c56":"markdown","b625c304":"markdown","17cd9390":"markdown","27fed0a6":"markdown"},"source":{"9e40df21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e40d7156":"train_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nsample = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\n","83eaf0d2":"from sklearn.model_selection import train_test_split\n\ny = train_data[\"SalePrice\"]\n\nfeatures = [\"OverallQual\", \"OverallCond\", \"MSSubClass\",\"LotArea\",\"LotFrontage\",\"YearBuilt\",'TotalBsmtSF',\n            'GrLivArea','TotRmsAbvGrd','Fireplaces','GarageArea', 'GarageCars', \n            'PoolArea', 'WoodDeckSF','OpenPorchSF','ScreenPorch','MSZoning',\n          'Street', 'Alley', 'LotShape','LandContour', 'Utilities', 'LandSlope', 'Neighborhood'\n           ,'Condition1', 'Condition2', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'MasVnrType', 'ExterQual', 'ExterCond'\n           ,'Foundation', 'BsmtQual', 'BsmtCond', 'Heating', 'HeatingQC', 'CentralAir',\n           'Electrical','1stFlrSF','2ndFlrSF', 'FullBath', 'HalfBath', 'KitchenQual'\n           ,'Functional', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageQual', 'GarageCond', 'PavedDrive'\n           ,'PoolQC', 'Fence']\n\nX = pd.get_dummies(train_data)\nX_test = pd.get_dummies(test_data)\n\nX = train_data[features]\nX_test = test_data[features]\n\nX_train, X_cv, y_train, y_cv = train_test_split(X, y, train_size = 0.8, test_size = 0.2)\n\n","81bd2a35":"from sklearn.preprocessing import OneHotEncoder\n\n\n\nnull_cols_test = [col for col in X_test.columns \n            if X_test[col].isnull().any()]\nnull_cols_train = [col for col in X_train.columns\n                if X_train[col].isnull().any()]\nnull_cols_cv = [col for col in X_cv.columns\n                if X_cv[col].isnull().any()]\n\nnull_cols = null_cols_train + null_cols_test + null_cols_cv\n\nreduced_X_train = X_train.drop(null_cols, axis = 1)\nreduced_X_cv = X_cv.drop(null_cols, axis = 1)\n\n\n#Select all columns that do not already have int\/float values\ns = (reduced_X_train.dtypes == 'object')\n#These are all catagorical vars\nobject_cols = list(s[s].index)","3c31d0b3":"OH_encoder = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(reduced_X_train[object_cols]))\nOH_cols_train.index = X_train.index\nnum_X_train = reduced_X_train.drop(object_cols, axis = 1)\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis = 1)\n\nOH_cols_cv = pd.DataFrame(OH_encoder.transform(reduced_X_cv[object_cols]))#!!!!!!!!!!!!\nOH_cols_cv.index = X_cv.index\nnum_X_cv = reduced_X_cv.drop(object_cols, axis = 1)\nOH_X_cv = pd.concat([num_X_cv, OH_cols_cv], axis = 1)","cb031a6c":"from sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer(strategy = \"mean\")\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\nimputed_X_cv = pd.DataFrame(my_imputer.transform(OH_X_cv))\n\n\n\nimputed_X_train.columns = OH_X_train.columns\nimputed_X_cv.columns = OH_X_cv.columns\n\n\n","cded6e5c":"#from sklearn.metrics import mean_absolute_error\n#predictions_cv = model.predict(imputed_X_cv)\n\n#print(mean_absolute_error(predictions_cv, y_cv))","d6f87672":"#def score(X_cv, y_cv, X_train, y_train):\n#    maes = []\n#    for i in range(1,30):\n#        model = RandomForestRegressor(n_estimators = i*10, random_state = 1)\n#        model.fit(X_train, y_train)\n#        preds = model.predict(X_cv)\n#        \n#        maes.append(mean_absolute_error(preds, y_cv))\n#    return 10*maes.index(min(maes))\n\n#score(imputed_X_cv, y_cv, imputed_X_train, y_train)","82b0f224":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=10, random_state=1)\nmodel.fit(imputed_X_train, y_train)","bb30d462":"reduced_X_test = X_test.drop(null_cols, axis = 1)\n\nOH_cols_test = pd.DataFrame(OH_encoder.transform(reduced_X_test[object_cols]))\nOH_cols_test.index = X_test.index\nnum_X_test = reduced_X_test.drop(object_cols, axis = 1)\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis = 1)\n\nimputed_X_test = pd.DataFrame(my_imputer.transform(OH_X_test))\nimputed_X_test.columns = OH_X_test.columns","ebe88a59":"predictions = model.predict(imputed_X_test)","91bdf4eb":"output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","65310206":"Submit","82a7d7f3":"Read the data","4373c307":"Removing bad tests","90406665":"Drop rows with missing variables","f3459c56":"Version 4 mae = 17711.011547945207","b625c304":"One-Hot-Encoder","17cd9390":"Test On CV","27fed0a6":"Create A basic model"}}