{"cell_type":{"bfc9abd2":"code","73daa31e":"code","ac3ae7d1":"code","5e5bb445":"code","24546c48":"code","4658cc29":"code","d0f72754":"code","e688c5f5":"code","07561d89":"code","b56d447b":"code","124c5b1a":"code","1fae1e40":"code","065c5331":"code","b3b1eecf":"code","0d587e21":"code","0d15e4af":"code","4bed9798":"code","74693247":"code","c5afa192":"code","7989952b":"code","8cdd3130":"code","a8fac632":"code","44b7ff92":"code","b8717b2f":"code","849c52af":"code","eb332aad":"code","a85b5bc8":"code","522e9da0":"code","bfbcc076":"code","8f0bbf0b":"code","e326a229":"code","fd276040":"code","e0697ccf":"code","af73183a":"code","a268b22c":"code","5b5f344e":"code","e8d91d52":"markdown"},"source":{"bfc9abd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73daa31e":"import seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n","ac3ae7d1":"heart=pd.read_csv(\"..\/input\/heart-disease-cleveland-uci\/heart_cleveland_upload.csv\") #heart isimli bir de\u011fi\u015fken tan\u0131mlay\u0131p csv dosyam\u0131z\u0131 dahil ettik.\ndf = heart.copy()","5e5bb445":"df.head()  # ilk 5 g\u00f6zlem","24546c48":"df.tail()  # son 5 g\u00f6zlem","4658cc29":"matrix = np.triu(df.corr(method='kendall'))\nsns.set_style(\"white\")\nf,ax=plt.subplots(figsize = (10,8),dpi=100)\nsns.heatmap(df.corr(method='kendall'),annot= True,fmt = \".0%\",ax=ax,\n            vmin = -1,\n            vmax = 1, mask = matrix,cmap = \"coolwarm\",\n            linewidth = 0.2,linecolor = \"white\")\nplt.xticks(rotation=70)\nplt.yticks(rotation=0)\nplt.title('Kendall Correlation ', size = 30)\nplt.show()","d0f72754":"df.sample(5) #rastgele 5 g\u00f6zlem","e688c5f5":"df.shape # veri setinin ka\u00e7a ka\u00e7l\u0131k oldu\u011fu ---> 297 sample 14 feature","07561d89":"df.info() # veri seti hakk\u0131nda genel bir info","b56d447b":"plt.figure(figsize=(10,5),dpi=350)\nsns.kdeplot(df[df['sex']==0]['sex'], label='male')\nsns.kdeplot(df[df['sex']==1]['sex'], label='female')\nplt.legend()\nplt.title('sex')\nplt.show()","124c5b1a":"df.isnull().sum().sum() # Veri setindeki eksik de\u011ferlerin say\u0131s\u0131","1fae1e40":"df.describe().T   # temel istatistik de\u011ferleri","065c5331":"df.nunique()  # her bir attribute i\u00e7in unique de\u011ferlerin say\u0131s\u0131","b3b1eecf":"corr = df.corr()\ncorr                  #korelasyon matrisi","0d587e21":"sns.set(font_scale=1.1)\ncorrelation_train = heart.corr()\nmask = np.triu(correlation_train.corr())\nplt.figure(figsize=(20, 12))\nsns.heatmap(correlation_train,\n            annot=True,\n            fmt='.3f',\n            cmap='Wistia',\n            linewidths=1,\n            cbar=True)\n\nplt.show()","0d15e4af":"sns.scatterplot(x=\"oldpeak\",y=\"slope\",data=df);  #en g\u00fc\u00e7l\u00fc ili\u015fki oldpeak ve slope aras\u0131nda\n","4bed9798":"df.condition.value_counts()    #hasta olan ve olmayanlar\u0131n say\u0131s\u0131","74693247":"sns.countplot(x=\"condition\", data=df, palette=\"bwr\")  #grafi\u011fi\nplt.show()","c5afa192":"countNoDisease = len(df[df.condition == 0])    #y\u00fczdelerini yazd\u0131rma\ncountHaveDisease = len(df[df.condition == 1])\nprint(\"Percentage of Patients Haven't Heart Disease: {:.2f}%\".format((countNoDisease \/ (len(df.condition))*100)))\nprint(\"Percentage of Patients Have Heart Disease: {:.2f}%\".format((countHaveDisease \/ (len(df.condition))*100)))","7989952b":"sns.countplot(x='sex', data=df, palette=\"mako_r\")  #kad\u0131n erkek say\u0131s\u0131\nplt.xlabel(\"Sex (0 = female, 1= male)\")\nplt.show()","8cdd3130":"len(df.sex=)","a8fac632":"countFemale = len(df[df.sex == 0])   #kad\u0131n erkek y\u00fczdesi\ncountMale = len(df[df.sex == 1])\nprint(\"Percentage of Female Patients: {:.2f}%\".format((countFemale \/ (len(df.sex))*100)))\nprint(\"Percentage of Male Patients: {:.2f}%\".format((countMale \/ (len(df.sex))*100)))","44b7ff92":"pd.crosstab(df.age,df.condition).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.savefig('heartDiseaseAndAges.png')\nplt.show()","b8717b2f":"df.groupby(['sex'])['condition'].value_counts()","849c52af":"pd.crosstab(df.sex,df.condition).plot(kind=\"bar\",figsize=(15,6),color=['#1CA53B','#AA1111' ])\nplt.title('Heart Disease Frequency for Sex')\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","eb332aad":"y = df.condition.values\nx_data = df.drop(['condition'], axis = 1)","a85b5bc8":"x = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data)).values ","522e9da0":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.15,random_state=0)","bfbcc076":"x_train = x_train.T\ny_train = y_train.T\nx_test = x_test.T\ny_test = y_test.T","8f0bbf0b":"def initialize_weights_and_bias(dimension):\n    w = np.full((dimension,1),0.01)\n    b = 0.0\n    return w, b","e326a229":"def sigmoid(z):\n    y_head = 1 \/ (1+ np.exp(-z)) \n    return y_head","fd276040":"def forwardBackward(weight,bias,x_train,y_train):\n    # Forward\n    \n    y_head = sigmoid(np.dot(weight.T,x_train) + bias)\n    loss = -(y_train*np.log(y_head) + (1-y_train)*np.log(1-y_head))\n    cost = np.sum(loss) \/ x_train.shape[1]\n    \n    derivative_weight = np.dot(x_train,((y_head-y_train).T))\/x_train.shape[1]\n    derivative_bias = np.sum(y_head-y_train)\/x_train.shape[1]\n    gradients = {\"Derivative Weight\" : derivative_weight, \"Derivative Bias\" : derivative_bias}\n    \n    return cost,gradients","e0697ccf":"def update(weight,bias,x_train,y_train,learningRate,iteration) :\n    costList = []\n    index = []\n    \n    #her iterasyonda weightleri ve bias'\u0131 g\u00fcncelle\n    for i in range(iteration):\n        cost,gradients = forwardBackward(weight,bias,x_train,y_train)\n        weight = weight - learningRate * gradients[\"Derivative Weight\"]\n        bias = bias - learningRate * gradients[\"Derivative Bias\"]\n        \n        costList.append(cost)\n        index.append(i)\n\n    parameters = {\"weight\": weight,\"bias\": bias}\n    \n    print(\"iteration:\",iteration)\n    print(\"cost:\",cost)\n\n    plt.plot(index,costList)\n    plt.xlabel(\"Number of Iteration\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n\n    return parameters, gradients","af73183a":"def predict(weight,bias,x_test):\n    z = np.dot(weight.T,x_test) + bias\n    y_head = sigmoid(z)\n\n    y_prediction = np.zeros(1,x_test.shape[1])\n    \n    for i in range(y_head.shape[1]):\n        if y_head[0,i] <= 0.5:\n            y_prediction[0,i] = 0\n        else:\n            y_prediction[0,i] = 1\n    return y_prediction\n","a268b22c":"def logistic_regression(x_train,y_train,x_test,y_test,learningRate,iteration):\n    dimension = x_train.shape[0]\n    weight,bias = initialize_weights_and_bias(dimension)\n    \n    parameters, gradients = update(weight,bias,x_train,y_train,learningRate,iteration)\n\n    y_prediction = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n    \n    print(\"Manuel Test Accuracy: {:.2f}%\".format((100 - np.mean(np.abs(y_prediction - y_test))*100)))\n    print(\"Tahmin de\u011ferleri: \", y_prediction)\n   ","5b5f344e":"logistic_regression(x_train,y_train,x_test,y_test,1,100)","e8d91d52":"__Content__\nThere are 13 attributes and our target variable as condition;\n1. __age__: age in years\n1. __sex__: sex (1 = male; 0 = female)\n1. __cp__: chest pain type\n    - Value 0: typical angina\n    - Value 1: atypical angina\n    - Value 2: non-anginal pain\n    - Value 3: asymptomatic\n1. __trestbps__: resting blood pressure (in mm Hg on admission to the hospital)\n1. __chol__: serum cholesterol in mg\/dl\n1. __fbs__: (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n1. __restecg__: resting electrocardiographic results\n    - Value 0: normal\n    - Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n1. __thalach__: maximum heart rate achieved\n1. __exang__: exercise induced angina (1 = yes; 0 = no)\n1. __oldpeak__ = ST depression induced by exercise relative to rest\n1. __slope__: the slope of the peak exercise ST segment\n    - Value 0: upsloping\n    - Value 1: flat\n    - Value 2: downsloping\n1. __ca__: number of major vessels (0-3) colored by flourosopy\n1. __thal__: 0 = normal; 1 = fixed defect; 2 = reversable defect\n1. __condition__: 0 = no disease, 1 = disease"}}