{"cell_type":{"08cdf4e7":"code","3890777a":"code","5d006562":"code","cbc5430f":"code","bdd6e99b":"code","a58a43bf":"code","0e9c8ef8":"code","33a101b8":"code","06e429fc":"code","1b457fa1":"code","2bccea96":"code","6c529231":"code","d92f88da":"code","7b775542":"markdown"},"source":{"08cdf4e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3890777a":"from math import sqrt\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.models import load_model\nimport types\nimport os\nfrom contextlib import suppress","5d006562":"# convert series to supervised learning\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n\tn_vars = 1 if type(data) is list else data.shape[1]\n\tdf = DataFrame(data)\n\tcols, names = list(), list()\n    \n\t# input sequence (t-n, ... t-1)\n\tfor i in range(n_in, 0, -1):\n\t\tcols.append(df.shift(i))\n\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n        \n\t# forecast sequence (t, t+1, ... t+n)\n\tfor i in range(0, n_out):\n\t\tcols.append(df.shift(-i))\n\t\tif i == 0:\n\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n\t\telse:\n\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n            \n\t# put it all together\n\tagg = concat(cols, axis=1)\n\tagg.columns = names\n    \n\t# drop rows with NaN values\n\tif dropnan:\n\t\tagg.dropna(inplace=True)\n\treturn agg","cbc5430f":"df = pd.read_csv('..\/input\/wind-turbine-scada-dataset\/T1.csv', header=0, index_col=0)\ncolumnsTitles=['LV ActivePower (kW)','Wind Speed (m\/s)',\"Wind Direction (\u00b0)\",\"Theoretical_Power_Curve (KWh)\"]\ndf=df.reindex(columns=columnsTitles)\ndf.head()","bdd6e99b":"# load dataset\ndf['LV ActivePower (kW)']=df['LV ActivePower (kW)'].div(5000)\ndf['Wind Speed (m\/s)']=df['Wind Speed (m\/s)'].div(30)\ndf['Theoretical_Power_Curve (KWh)']=df['Theoretical_Power_Curve (KWh)'].div(5000)\ndf['Wind Direction (\u00b0)']=df['Wind Direction (\u00b0)'].div(360)\ndataset = df\nvalues = dataset.values\n#print(values)\n\n# specify the number of lag and ahead hours\nn_hours = 24\nn_ahead = 1\nn_features = 4\n\n# integer encode direction\n#encoder = LabelEncoder()\n#values[:,n_features-1] = encoder.fit_transform(values[:,n_features-1])\n\n# ensure all data is float\nvalues = values.astype('float32')\n#print(df)\n\n# normalize features\n#scaler = MinMaxScaler(feature_range=(0, 1))\n#scaled = scaler.fit_transform(values)\n#print(scaled[0:30])\n\n# frame as supervised learning\nreframed = series_to_supervised(values, n_hours,n_ahead, 1)\n#print(reframed[0:24])\nprint(reframed.shape)","a58a43bf":"# split into train and test sets\nvalues = reframed.values\nn_train_hours = (int)(len(dataset)*0.999)\ntrain = values[:n_train_hours, :]\ntest = values[n_train_hours:, :]\n\n#print(train)\n\n# split into input and outputs\nn_obs = n_hours * n_features\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features]\ntest_X, test_y = test[:, :n_obs], test[:, -n_features]\nprint(train_X.shape, len(train_X), train_y.shape)\n\n#print(train_X)\n#print(train_y)\n\n# reshape input to be 3D [samples, timesteps, features]\ntrain_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\ntest_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","0e9c8ef8":"model = Sequential()\nmodel.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam')","33a101b8":"# fit network\nhistory = model.fit(train_X, train_y, epochs=150, batch_size=24, validation_data=(test_X, test_y), verbose=2, shuffle=False)\nmodel.save(\"WindBot.h5\")","06e429fc":"filename = 'WindBot'\n# Delete a duplicate file if exists.\nwith suppress(OSError):\n    os.remove(filename)\nmodel.save(filename+\".h5\",overwrite=True)\n\n#compress keras model\ntar_filename = filename + '.tgz'\ncmdstring = 'tar -zcvf ' + tar_filename + ' ' + filename+\".h5\"\nprint(cmdstring)\nos.system(cmdstring)","1b457fa1":"model = load_model('WindBot.h5')","2bccea96":"# plot history\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()\n\n#Copying test data\ntest_C=test_X\n","6c529231":"test_X=test_C\n#yhat = model.predict(test_X)\n#test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n#print(test_X)\n\n# invert scaling for forecast\n#inv_yhat = concatenate((yhat, test_X[:, -(n_features-1):]), axis=1)\n#inv_yhat = scaler.inverse_transform(inv_yhat)\n#inv_yhat = inv_yhat[:,0]\n\ninv_yhat=model.predict(test_X)\nfor i in range(len(inv_yhat)):\n    inv_yhat[i]=inv_yhat[i]*5000\n#print(inv_yhat)\n\n# invert scaling for actual\n#test_y = test_y.reshape((len(test_y), 1))\n#inv_y = concatenate((test_y, test_X[:, -(n_features-1):]), axis=1)\n#inv_y = scaler.inverse_transform(inv_y)\n#inv_y = inv_y[:,0]\n\ninv_y=test_y\nfor i in range(len(inv_y)):\n    inv_y[i]=inv_y[i]*5000\n#print(inv_y)\n\n# calculate RMSE\nrmse = sqrt(mean_squared_error(inv_y, inv_yhat))\nprint('Test RMSE: %.3f' % rmse)","d92f88da":"# plot history\npyplot.plot(inv_yhat, label='predicted')\npyplot.plot(inv_y, label='true')\npyplot.legend()\npyplot.show()","7b775542":"This Notebook uses LSTM model to predict energy output for next hours"}}