{"cell_type":{"a853d726":"code","8e78ef8e":"code","d3ac17e0":"code","7e527692":"code","9832127a":"code","4d1a3556":"code","ecf7d24d":"code","71aee6ca":"code","a2097d3e":"code","96a41ff7":"code","55d459dc":"code","bc1d28ea":"markdown","dd9f6ae8":"markdown","c178a645":"markdown","0004c6df":"markdown","eeb23f4c":"markdown","14a34455":"markdown","d43196a0":"markdown","3f836317":"markdown"},"source":{"a853d726":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport math, re, os, random\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom collections import Counter\n\nimport cv2\nimport PIL\nimport tensorflow as tf\nimport gc\nimport skimage.io\n\nimport tensorflow_addons as tfa\nfrom tqdm import tqdm\n\nimport dask.array as da\nimport dask","8e78ef8e":"IMAGE_SIZE  = 512\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nFOLDS = 5\nBATCH_SIZE = 128","d3ac17e0":"train_df = pd.read_csv('..\/input\/deeplearningchallengeholidays\/dataset\/train.csv')","7e527692":"\nfull_datagen = ImageDataGenerator(rescale=1.\/255)\n\n\nfull_datagenerator=full_datagen.flow_from_dataframe(dataframe=train_df,\n                                            directory=\"..\/input\/deeplearningchallengeholidays\/dataset\/train\",\n                                            x_col=\"Image\",\n                                            y_col=\"Class\",\n                                            subset=\"training\",\n                                            batch_size=BATCH_SIZE ,\n                                            seed=42,\n                                            shuffle=False,\n                                            class_mode=\"categorical\",\n                                            target_size=(IMAGE_SIZE,IMAGE_SIZE))","9832127a":"get_next_data = dask.delayed(full_datagenerator.next, pure=True) # Lazy version of full_datagenerator.next","4d1a3556":"Total_Batches = len(full_datagenerator.filenames) \/\/ BATCH_SIZE","ecf7d24d":"lazy_image_data = [get_next_data()[0] for filename in full_datagenerator.filenames]\nsample_image = lazy_image_data[0].compute()  # load the first data (assume rest are same shape\/dtype)\n\n\nlazy_class_data = [get_next_data()[1] for filename in full_datagenerator.filenames]\nsample_class = lazy_class_data[0].compute()  # load the first data (assume rest are same shape\/dtype)","71aee6ca":"X_chunk = [da.from_delayed(lazy_image,           # Construct a small Dask array\n                          dtype=sample_image.dtype,   # for every lazy value\n                          shape=sample_image.shape)\n          for lazy_image in lazy_image_data]\n\ny_chunk= [da.from_delayed(lazy_class,           # Construct a small Dask array\n                          dtype=sample_class.dtype,   # for every lazy value\n                          shape=sample_class.shape)\n          for lazy_class in lazy_class_data]","a2097d3e":"X =  da.stack(X_chunk, axis=0) \ny = da.stack(y_chunk, axis=0) ","96a41ff7":"X.shape,y.shape","55d459dc":"type(X),type(y)","bc1d28ea":"# Imports","dd9f6ae8":"# Dask Lazy dataGenerator","c178a645":"# Image Generator","0004c6df":"# Tensor Slices","eeb23f4c":"[Dask](https:\/\/docs.dask.org\/en\/latest\/)\n====\n\n> Dask is a flexible library for parallel computing in Python.\n\n> Dask is composed of two parts:\n> \n> 1. Dynamic task scheduling optimized for computation. This is similar to Airflow, Luigi, Celery, or Make, but optimized for interactive computational workloads.\n> 2. \u201cBig Data\u201d collections like parallel arrays, dataframes, and lists that extend common interfaces like NumPy, Pandas, or Python iterators to larger-than-memory or distributed environments. These parallel collections run on top of dynamic task schedulers.","14a34455":"# Config","d43196a0":"# Dask Array","3f836317":"Here X and Y are Dask arrays \n\n> Dask Array implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays. This lets us compute on arrays larger than memory using all of our cores. We coordinate these blocked algorithms using Dask graphs."}}