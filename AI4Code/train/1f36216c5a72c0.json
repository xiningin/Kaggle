{"cell_type":{"488f9452":"code","9fbd77af":"code","58898eff":"code","228dcee7":"code","887e2976":"code","d04576d6":"code","4dea8c39":"code","6ea857cc":"code","c54e956b":"code","e6e36947":"code","8eb180da":"code","4f1f464d":"code","ffc47c49":"code","e9a357fd":"code","51d33e1c":"code","ca109b57":"code","188c782e":"code","97dc7c6a":"code","85dd3e9a":"code","c79c24a0":"code","20122fc3":"code","d850a8f9":"code","283edd90":"code","9ea12820":"code","b22f05b4":"code","538e7b6a":"code","d7818d60":"code","845e257b":"code","331804ee":"code","92db4197":"code","939fa6d9":"code","9778119d":"code","37aa3145":"code","06bdb888":"code","a2c61992":"code","09d5d109":"code","c51af343":"code","cd4b32e1":"code","8f2690f8":"code","45a14215":"code","f1001092":"code","d86013b1":"code","d096381e":"code","f29adb9b":"code","32b92bfd":"code","16b76ec3":"code","b5146823":"code","3678602d":"code","f78e5ed1":"code","f11c2e23":"code","464b041f":"code","ad56f58b":"code","fa568182":"code","7aa8548c":"code","de5788d6":"markdown","1e9af266":"markdown","49d07ec9":"markdown","2847da11":"markdown","08379f19":"markdown","6caa0032":"markdown","b48f879d":"markdown","f328c72f":"markdown","e6843a2d":"markdown"},"source":{"488f9452":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport altair as alt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9fbd77af":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport datetime\nimport tensorflow as tf\nimport itertools\nimport matplotlib\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import class_weight\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import StratifiedKFold\nimport math\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import clear_output\nfrom sklearn.metrics import log_loss\nimport xgboost as xgb\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom catboost import CatBoostClassifier","58898eff":"df=pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df=pd.read_csv('..\/input\/titanic\/test.csv')","228dcee7":"titles1=[]\ntitles2=[]\nmarital1=[]\nmarital2=[]\nfor i in df['Name']:\n    titles1.append(i.split(',')[0])\n    marital1.append(i.split('.')[0].split(',')[1])\nfor i in test_df['Name']:\n    titles2.append(i.split(',')[0])\n    marital2.append(i.split('.')[0].split(',')[1])","887e2976":"df['Titles']=titles1\ndf['marital_status']=marital1\ntest_df['Titles']=titles2\ntest_df['marital_status']=marital2\na=df['marital_status'].value_counts()\nb=test_df['marital_status'].value_counts()\ncleanup_nums = {\"marital_status\":     {\" Mr\": 1, \" Mrs\":1, \" Lady\": 1, \" Miss\":0, \" Master\":0}\n               }\ndf = df.replace(cleanup_nums)\ntest_df = test_df.replace(cleanup_nums)\ndf.loc[(df.marital_status.isin([\" Dr\", \" Rev\", \" Mlle\", \" Major\", \" Col\", \" Mme\", \" Don\", \" Capt\", \" Jonkheer\", \" Ms\", \" the Countess\", \" Sir\"])) & (df['SibSp']>0) , 'marital_status'] = 1\ndf.loc[(df.marital_status.isin([\" Dr\", \" Rev\", \" Mlle\", \" Major\", \" Col\", \" Mme\", \" Don\", \" Capt\", \" Jonkheer\", \" Ms\", \" the Countess\", \" Sir\"])) & (df['SibSp']==0) , 'marital_status'] = 0\ntest_df.loc[(test_df.marital_status.isin([\" Dr\", \" Rev\", \" Mlle\", \" Major\", \" Col\", \" Mme\", \" Don\", \" Capt\", \" Jonkheer\", \" Ms\", \" the Countess\", \" Sir\", \" Dona\"])) & (test_df['SibSp']>0) , 'marital_status'] = 1\ntest_df.loc[(test_df.marital_status.isin([\" Dr\", \" Rev\", \" Mlle\", \" Major\", \" Col\", \" Mme\", \" Don\", \" Capt\", \" Jonkheer\", \" Ms\", \" the Countess\", \" Sir\", \" Dona\"])) & (test_df['SibSp']==0) , 'marital_status'] = 0","d04576d6":"test_df['marital_status'].unique()","4dea8c39":"df['marital_status']=df['marital_status'].astype(int)\ntest_df['marital_status']=test_df['marital_status'].astype(int)","6ea857cc":"df['marital_status'].unique()","c54e956b":"df.head()","e6e36947":"%%capture\ndf['survived']=df['Sex']\nmask=(df['Survived']==1)\ndf['survived'][mask]='survived'\nmask=(df['Survived']==0)\ndf['survived'][mask]='died'","8eb180da":"df['relatives']=df['SibSp']+df['Parch']","4f1f464d":"import missingno as msno\n\nmsno.bar(df)\nplt.show()","ffc47c49":"plt.figure(figsize = (12, 7))\n\nsns.countplot(x = 'survived', data = df, hue='Sex')\nplt.show()","e9a357fd":"\nfig=px.scatter(df.loc[df['Sex'] == 'male'],\n                 x=\"PassengerId\", y=\"Age\", color=\"Survived\",\n                 log_x=True, size_max=20,\n                 template='plotly', title=\"Which Ages of males Survived?\",opacity=1)\nfig.show()      ","51d33e1c":"fig=px.scatter(df.loc[df['Sex'] == 'female'],\n                 x=\"PassengerId\", y=\"Age\", color=\"Survived\",\n                 log_x=True, size_max=20,\n                 template='plotly', title=\"Which Age of females Survived?\", opacity=1)\nfig.show() ","ca109b57":"fig, ax=plt.subplots(figsize=(9,3))\nsns.histplot(df['Age'],kde=True)\nax.set_title('Which age-group was more on the ship')\nplt.show()","188c782e":"sns.catplot(x = 'Parch', y = 'Survived', data = df, kind = 'bar', col = 'Pclass', hue='Sex')","97dc7c6a":"sns.barplot(x='Embarked', y='Survived', data=df);","85dd3e9a":"sns.barplot(x='relatives', y='Survived', data=df);","c79c24a0":"sns.kdeplot(x='SibSp', y='Survived', data=df, shade=True)","20122fc3":"sns.pairplot(data=df, diag_kind='kde', hue='Sex')","d850a8f9":"df['married']=df['Sex']\nmask=(df['marital_status']==1)\ndf['married'][mask]='married'\nmask=(df['marital_status']==0)\ndf['married'][mask]='unmarried'\ndf['use']=df['married']+' '+df['Sex']+' '+df['survived']\nfig=px.scatter(df,\n                 x=\"PassengerId\", y=\"Age\", color=\"use\",\n                 log_x=True, size_max=20,\n                 template='plotly', title=\"which age married vs unmarried who survived?\", opacity=1)\ndf=df.drop(['use','married'], axis=1)\nfig.show()","283edd90":"corrmatrix=df.corr()\nfig, ax=plt.subplots(figsize=(10,10))\nsns.heatmap(corrmatrix, vmax=8, square=True, annot=True, fmt='.2f')\nplt.show()","9ea12820":"#sns.catplot(x = 'Sex', y = 'Age', kind = 'box', data = df, height = 5, aspect = 2,col='survived',contor='h')\n#plt.show()\nfig, ax=plt.subplots(figsize=(15,5))\nax.tick_params(axis='x', rotation=90)\nsns.boxplot(data=df, orient='h')","b22f05b4":"fig, ax=plt.subplots(figsize=(25,10))\nsns.histplot(df['Fare'],kde=True)\nax.set_title('Distribution of Fare for passengers')\nplt.show()","538e7b6a":"#result dataframe\nresult=pd.DataFrame(df['Sex'])\nresult['model']=df['Sex']\nresult['accuracy']=df['Survived']\nresult=result.drop('Sex', axis=1)\nresult=result.iloc[len(result):,:]","d7818d60":"#dropping unnecesary columns NOTE survived was a column created to aid visualization\ndf=df.drop(['PassengerId', 'Name', 'survived', 'Ticket','relatives'], axis=1)\n#filling Embarked with most frequent in the column\ndf['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().index[0])\n#replacing manually the categorical variable other encoders could be used\ncleanup_nums = {\"Embarked\":     {\"Q\": 1, \"C\":2, \"S\":3},\n                \"Sex\": {\"male\": 0, \"female\": 1}\n               }\ndf = df.replace(cleanup_nums)\n#total no of relatives for a person on the ship\ndf['family']=df['SibSp']+df['Parch']+1\n\n#its not realistic for fare to be zero which is special case so let us replace with mean\ndf['Fare'] = df['Fare'].replace(0, df['Fare'].mean())\n#if has a cabin then 1 else 0\ndf['Cabin']=df['Cabin'].fillna(\"0\")\ndf.loc[df.Cabin != \"0\", 'Cabin'] = \"1\"\ndf['Cabin']=df['Cabin'].astype(int)\n\n#if has no relative then 0 else 1\ndf['isAlone']=np.zeros(len(df))\ndf.loc[df.family == 1, 'isAlone'] = 1\ndp=df.dropna()\n#we will not use survived as a feature to predict the age to fill the missing ages as it will not be available in test dataset\nX=dp.drop(['Age', 'Titles','Survived'], axis=1)\ny=dp.Age","845e257b":"%%capture\ntest_df=test_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n\ntest_df['family']=test_df['SibSp']+test_df['Parch']+1\n\ntest_df['Embarked']=test_df['Embarked'].fillna('G')\ntest_df = test_df.replace(cleanup_nums)\ntest_df['Fare'] = test_df['Fare'].replace(0, test_df['Fare'].mean())\ntest_df['Fare']=test_df['Fare'].fillna(test_df['Fare'].mean())\ntest_df['Cabin']=test_df['Cabin'].fillna(\"0\")\ntest_df.loc[df.Cabin != \"0\", 'Cabin'] = \"1\"\ntest_df['Cabin']=test_df['Cabin'].astype(int)\ntest_df['isAlone']=np.zeros(len(test_df))\ntest_df.loc[test_df.family == 1, 'isAlone'] = 1\ndp=test_df.dropna()\nx=dp.drop(['Age','Titles'], axis=1)\nY=dp.Age","331804ee":"X=pd.concat([X, x])\ny=pd.concat([y,Y])\nX.reset_index()\ny.reset_index()","92db4197":"df.head()","939fa6d9":"X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.15)\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier","9778119d":"def checking(train_X, train_y, val_X, val_y, min_child_weight, n_estimators, max_depth):\n    score=1000000\n    n_emi=0\n    min_chi=0\n    model=XGBRegressor()\n    max_de=0\n    for i in n_estimators:\n        for j in min_child_weight:\n            for k in max_depth:\n                xgb_m = XGBRegressor(min_child_weight=j, n_estimators=i, max_depth=k, random_state=0, tree_method='gpu_hist', gpu_id=0)\n                xgb_m.fit(train_X,train_y)\n                preds=xgb_m.predict(val_X)\n                r=mean_squared_error(val_y, preds, multioutput='raw_values')\n                r=math.sqrt(r)\n                if(r<score):\n                    score=r\n                    n_emi=i\n                    min_chi=j\n                    model=xgb_m\n                    max_de=k\n                print(\"n_estimators = \"+str(i)+\" and min_child_weight = \"+str(j)+\" and max_detph = \"+str(k)+\" gives accuracy of \"+str(r))\n    return [model,score, n_emi, min_chi]  ","37aa3145":"min_child_weight=[1,2,3,4,5]\nmax_depth=[2,3,4,5,6,7]\nn_estimators=[50,70,60,80,100,120,140,160,180,200,300]\nxt=checking(X_train, y_train, X_validation, y_validation, min_child_weight, n_estimators, max_depth)\nprint(xt)","06bdb888":"df.head()","a2c61992":"%%capture\n#now we predict age for the entire train dataset\npreds=xt[0].predict(df.drop(['Age','Survived','Titles'], axis=1))\ndf['Age_d']=preds\n#we replace fill only the empty spots by the predicted ages array\ndf['Age']=df['Age'].fillna(df['Age_d'])\ndf=df.drop('Age_d', axis=1)\ndf['Age'][df['Age'] <= 1] = 1","09d5d109":"test_df.head()","c51af343":"%%capture\n#now we predict age for the entire train dataset\npreds=xt[0].predict(test_df.drop(['Age','Titles'], axis=1))\ntest_df['Age_d']=preds\n#we replace fill only the empty spots by the predicted ages array\ntest_df['Age']=test_df['Age'].fillna(test_df['Age_d'])\ntest_df=test_df.drop('Age_d', axis=1)\ntest_df['Age'][test_df['Age'] <= 1] = 1","cd4b32e1":"title=titles1+titles2\nres = []\n[res.append(x) for x in title if x not in res]\nfamily=pd.DataFrame(res,columns =['Names'])\nbelow_10_male=[]\nbelow_20_male=[]\nbelow_25_male=[]\nbelow_10_female=[]\nbelow_20_female=[]\nbelow_25_female=[]\nbelow_50_female=[]\nbelow_50_male=[]\nabove_50_female=[]\nabove_50_male=[]\n\nfor i in res:\n    below_10_male.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=10) & (df['Sex']==1)]))\n    below_10_female.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=10) & (df['Sex']==0)]))\n    below_20_male.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=20) & (df['Sex']==0) & (df['Age']>10)]))\n    below_20_female.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=20) & (df['Sex']==1) & (df['Age']>10)]))\n    below_25_male.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=25) & (df['Sex']==0) & (df['Age']>20)]))\n    below_25_female.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=25) & (df['Sex']==1) & (df['Age']>20)]))\n    below_50_male.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=50) & (df['Sex']==0) & (df['Age']>25)]))\n    below_50_female.append(len(df[((df['Titles']==i) | (test_df['Titles']==i)) & (df['Age']<=50) & (df['Sex']==1) & (df['Age']>25)]))\n    above_50_male.append(len(df[((df['Titles']==i) | (test_df['Titles']==i))  & (df['Sex']==0) & (df['Age']>50)]))\n    above_50_female.append(len(df[((df['Titles']==i) | (test_df['Titles']==i))  & (df['Sex']==1) & (df['Age']>50)]))","8f2690f8":"family['b_10_m']=below_10_male\nfamily['b_10_fm']=below_10_female\nfamily['b_20_m']=below_20_male\nfamily['b_20_fm']=below_20_female\nfamily['b_25_m']=below_25_male\nfamily['b_25_fm']=below_25_female\nfamily['b_50_m']=below_50_male\nfamily['b_50_fm']=below_50_female\nfamily['a_50_m']=above_50_male\nfamily['a_50_fm']=above_50_female\nfamily.head()","45a14215":"df['b_10_m']=np.zeros(len(df))\ndf['b_10_fm']=np.zeros(len(df))\ndf['b_20_m']=np.zeros(len(df))\ndf['b_20_fm']=np.zeros(len(df))\ndf['b_25_m']=np.zeros(len(df))\ndf['b_25_fm']=np.zeros(len(df))\ndf['b_50_m']=np.zeros(len(df))\ndf['b_50_fm']=np.zeros(len(df))\ndf['a_50_m']=np.zeros(len(df))\ndf['a_50_fm']=np.zeros(len(df))\n\ntest_df['b_10_m']=np.zeros(len(test_df))\ntest_df['b_10_fm']=np.zeros(len(test_df))\ntest_df['b_20_m']=np.zeros(len(test_df))\ntest_df['b_20_fm']=np.zeros(len(test_df))\ntest_df['b_25_m']=np.zeros(len(test_df))\ntest_df['b_25_fm']=np.zeros(len(test_df))\ntest_df['b_50_m']=np.zeros(len(test_df))\ntest_df['b_50_fm']=np.zeros(len(test_df))\ntest_df['a_50_m']=np.zeros(len(test_df))\ntest_df['a_50_fm']=np.zeros(len(test_df))","f1001092":"for i in res:\n    dp=family.loc[family['Names']==i]\n    df.loc[df.Titles==i, 'b_10_m']=dp['b_10_m']\n    df.loc[df.Titles==i, 'b_20_m']=dp['b_20_m']\n    df.loc[df.Titles==i, 'b_25_m']=dp['b_25_m']\n    df.loc[df.Titles==i, 'b_50_m']=dp['b_50_m']\n    df.loc[df.Titles==i, 'a_50_m']=dp['a_50_m']\n    df.loc[df.Titles==i, 'b_10_fm']=dp['b_10_fm']\n    df.loc[df.Titles==i, 'b_10_fm']=dp['b_10_fm']\n    df.loc[df.Titles==i, 'b_20_fm']=dp['b_20_fm']\n    df.loc[df.Titles==i, 'b_25_fm']=dp['b_25_fm']\n    df.loc[df.Titles==i, 'b_50_fm']=dp['b_50_fm']\n    df.loc[df.Titles==i, 'a_50_m']=dp['a_50_fm']\n    test_df.loc[df.Titles==i, 'b_10_m']=dp['b_10_m']\n    test_df.loc[df.Titles==i, 'b_20_m']=dp['b_20_m']\n    test_df.loc[df.Titles==i, 'b_25_m']=dp['b_25_m']\n    test_df.loc[df.Titles==i, 'b_50_m']=dp['b_50_m']\n    test_df.loc[df.Titles==i, 'a_50_m']=dp['a_50_m']\n    test_df.loc[df.Titles==i, 'b_10_fm']=dp['b_10_fm']\n    test_df.loc[df.Titles==i, 'b_10_fm']=dp['b_10_fm']\n    test_df.loc[df.Titles==i, 'b_20_fm']=dp['b_20_fm']\n    test_df.loc[df.Titles==i, 'b_25_fm']=dp['b_25_fm']\n    test_df.loc[df.Titles==i, 'b_50_fm']=dp['b_50_fm']\n    test_df.loc[df.Titles==i, 'a_50_m']=dp['a_50_fm']","d86013b1":"df=df.fillna(0)\ntest_df=test_df.fillna(0)","d096381e":"df=df.drop('Titles', axis=1)\ntest_df=test_df.drop('Titles', axis=1)\ndf.head()","f29adb9b":"corrmatrix=df.corr()\nplt.figure(figsize=(20,20))\nplt.title('Let us Again see the final correlation')\nsns.heatmap(corrmatrix,vmax=2.0, \n            square=True, annot=True)","32b92bfd":"# the following two columns have high variance\ndf['Age'] = np.log(df['Age'])\ndf['Fare'] = np.log(df['Fare'])\nX=df.drop('Survived', axis=1)\ny=df.Survived\n#split for training and validation\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.15)","16b76ec3":"accu=[]\nmodels=[]","b5146823":"def checking(train_X, train_y, val_X, val_y, min_child_weight, n_estimators, max_depth):\n    score=0\n    n_emi=0\n    min_chi=0\n    model=XGBClassifier()\n    max_de=0\n    for i in n_estimators:\n        for j in min_child_weight:\n            for k in max_depth:\n                xgb_m = XGBClassifier(min_child_weight=j, n_estimators=i, max_depth=k, random_state=0, tree_method='gpu_hist', gpu_id=0)\n                xgb_m.fit(train_X,train_y)\n                acc=xgb_m.score(X_validation,y_validation)\n                if(acc>score):\n                    score=acc\n                    n_emi=i\n                    min_chi=j\n                    model=xgb_m\n                    max_de=k\n                print(\"n_estimators = \"+str(i)+\" and min_child_weight = \"+str(j)+\" and max_detph = \"+str(k)+\" gives accuracy of \"+str(acc))\n    return [model,score, n_emi, min_chi] ","3678602d":"min_child_weight=[1,2,3,4,5,6]\nmax_depth=[2,3,4,5,6,7,8]\nn_estimators=[50,70,60,80,100,120,140,160,180,200,300]\nxt=checking(X_train, y_train, X_validation, y_validation, min_child_weight, n_estimators, max_depth)\nprint(xt)","f78e5ed1":"pyplot.bar(range(len(xt[0].feature_importances_)), xt[0].feature_importances_)\npyplot.show()","f11c2e23":"from sklearn.ensemble import RandomForestClassifier\ndef checking(train_X, train_y, val_X, val_y, n_estimators, max_depth):\n    score=0\n    n_emi=0\n    model=RandomForestClassifier()\n    max_de=0\n    for i in n_estimators:\n        for k in max_depth:\n            xgb_m = RandomForestClassifier(n_estimators=i, max_depth=k, random_state=0)\n            xgb_m.fit(train_X,train_y)\n            acc=xgb_m.score(X_validation,y_validation)\n            if(acc>score):\n                score=acc\n                n_emi=i\n                model=xgb_m\n                max_de=k\n            print(\"n_estimators = \"+str(i)+\" and max_detph = \"+str(k)+\" gives accuracy of \"+str(acc))\n    return [model,score, n_emi, max_de] ","464b041f":"max_depth=[2,3,4,5,6,7]\nn_estimators=[50,70,60,80,100,120,140,160,180,200,300]\nrt=checking(X_train, y_train, X_validation, y_validation, n_estimators, max_depth)\nprint(rt)","ad56f58b":"pyplot.bar(range(len(rt[0].feature_importances_)), rt[0].feature_importances_)\npyplot.show()","fa568182":"t_df=pd.read_csv('..\/input\/titanic\/gender_submission.csv')\npreds=rt[0].predict(test_df)\nt_df['Survived']=preds\nt_df['Survived']=t_df['Survived'].round()\nt_df['Survived']=t_df['Survived'].astype(int)\nimport gzip\nt_df.to_csv('sub.gz', index=False, compression='gzip')\nt_df.head(10)","7aa8548c":"t_df=pd.read_csv('..\/input\/titanic\/gender_submission.csv')\npreds=xt[0].predict(test_df)\nt_df['Survived']=preds\nt_df['Survived']=t_df['Survived'].round()\nt_df['Survived']=t_df['Survived'].astype(int)\nimport gzip\nt_df.to_csv('subm.gz', index=False, compression='gzip')\nt_df.head(10)","de5788d6":"# Random Forest","1e9af266":"**data is not highly correlated**","49d07ec9":"**From this it is clear that children being with or without parents(with Nanny) doesn't have strong influence on survival**","2847da11":"# if you like this then please upvote \ud83d\udc4d","08379f19":"**Clearly female survived more**","6caa0032":"**We can see the Age and Fare columns has very high variance**","b48f879d":"# IF you like this notebook then please give an upvote \ud83d\udc4d\n**and also give suggestions in comment \ud83d\ude4c**","f328c72f":"# XGBoost","e6843a2d":"**Let us see how our data looks now**"}}