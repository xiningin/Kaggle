{"cell_type":{"950a41ab":"code","d3f5cc22":"code","04d659b5":"code","f8c629ff":"code","98699827":"code","a8060a1c":"code","f9f5d1c0":"code","106226b8":"code","6ab41c00":"code","3dac7f1b":"code","dae382c0":"code","1d1c997b":"code","f41d5e0d":"code","2e09f72d":"code","633288b5":"code","051d4ef1":"code","2b0036fe":"code","a9124eb9":"code","55b843ab":"code","c923d323":"code","fbbd41b8":"code","b2dd5a27":"code","60a331ee":"code","3929c0b7":"code","7520143d":"code","2fc395ef":"code","4fb047b1":"code","543adec2":"code","69706b9b":"code","b497468f":"code","3577104c":"code","70ad73eb":"code","03c4db21":"code","b0e3f512":"code","db16d36b":"code","e59eed9d":"code","302c773c":"code","0c965191":"code","9eb7a261":"code","aa4f1ff6":"markdown","be8bec20":"markdown","ce1dc16d":"markdown","3aeb0e35":"markdown","401d396a":"markdown","74fa32d1":"markdown","8210f101":"markdown","fbea4ec8":"markdown","04845ac0":"markdown","daeb78ce":"markdown","ef917ee8":"markdown"},"source":{"950a41ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3f5cc22":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","04d659b5":"## Loading all the important functions\n\ndef master_dataframe(dataframe):\n    df_metadata = pd.DataFrame({'Datatype': dataframe.dtypes,\n                                \"Null Values\": dataframe.isna().sum(),  \n                                \"Null %\": round(dataframe.isna().sum()\/len(dataframe)*100, 2),\n                                \"No: Of Unique Values\": dataframe.nunique()})\n    \n    df_describe = dataframe.describe(include='all').T\n    \n    df_metadata = df_metadata.join(df_describe)  \n    \n    corr = dataframe.corr()\n    \n    fig, ax = plt.subplots(figsize = (15, 15))    \n    sns.heatmap(ax=ax,\n                data=corr, \n                annot=True,\n                cmap='flare',\n                robust=True)\n    ax.set_title('Correlation Matrix', fontsize = 16)\n    plt.show()\n    \n    return df_metadata\n\n## New function to add a new column Family Member is created below.\ndef family_members(dataframe):\n    dataframe[\"FamilyMembers\"] = dataframe['SibSp'] + dataframe['Parch']\n    dataframe.drop(columns=['SibSp', 'Parch'], axis=1, inplace=True)\n    \n    return \"New column FamilyMembers added and SipSb & Parch dropped from the dataframe.\"\n\n## Functions to replace null values.\ndef handle_null_Age(dataframe):\n\n    # To replace null values from Age.\n    dataframe['Age'] = dataframe['Age'].fillna(raw_data.groupby(by=['Sex', 'FamilyMembers'])['Age'].transform('mean'))\n    dataframe['Age'] = dataframe['Age'].fillna(raw_data.groupby(by=['Sex'])['Age'].transform('mean'))\n\n    return \"Null values handled for Age\"\n\ndef handle_null_Cabin(dataframe):\n    ## To replace null values from Cabin.\n    dataframe['Cabin'] = dataframe['Cabin'].fillna('UNK')\n    dataframe['Cabin'] = dataframe['Cabin'].apply(lambda x: 'UKN' if x =='UNK' else x[0])\n    \n    return \"Null Values handled for Cabin\"\n\ndef handle_null_Embarked(dataframe):\n\n    dataframe['Embarked'] = dataframe['Embarked'].fillna(dataframe['Embarked'].mode()[0])\n    \n    return \"Null values in column Embarked are replaced with it's mode.\"\n\ndef handle_null_Fare(dataframe):\n\n    dataframe['Fare'] = dataframe['Fare'].fillna(dataframe['Fare'].mean())\n    \n    return \"Null values in column Fare are replaced with it's mean.\"\n\n\ndef standardize_data(dataframe):\n    scaler = StandardScaler()\n    dataframe[['Age', 'Fare', 'Pclass']] = scaler.fit_transform(dataframe[['Age', 'Fare', 'Pclass']])\n    \n    return dataframe\n\n\ndef check_vif_data(dataframe):\n    variables = dataframe[['Age','Fare', 'FamilyMembers', 'Sex_male', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E',\n             'Cabin_F', 'Cabin_G', 'Cabin_UKN', 'Embarked_Q', 'Embarked_S', 'Pclass']]\n    vif_data = pd.DataFrame()\n    vif_data['Features'] = variables.columns\n    vif_data['VIF'] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n\n    return vif_data","f8c629ff":"raw_data = pd.read_csv('..\/input\/titanic\/train.csv')\nraw_data_test = pd.read_csv('..\/input\/titanic\/test.csv')\nraw_data.head()","98699827":"master_dataframe(raw_data)","a8060a1c":"master_dataframe(raw_data_test)","f9f5d1c0":"family_members(raw_data)","106226b8":"handle_null_Age(raw_data)","6ab41c00":"handle_null_Cabin(raw_data)","3dac7f1b":"handle_null_Embarked(raw_data)","dae382c0":"master_dataframe(raw_data)","1d1c997b":"fig = px.scatter_matrix(raw_data, width=1000, height=1000, \n                        dimensions=[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"FamilyMembers\", \"Embarked\"], \n                        color='Survived')\nfig.update_traces(diagonal_visible=False)\n#fig.show()\niplot(fig)\n#sns.pairplot(raw_data)\n\n#plt.show()","f41d5e0d":"fig, ax = plt.subplots(nrows=1, ncols=3, figsize = (20, 7))\n\n\nsns.scatterplot(ax=ax[0], data=raw_data, \n                x='Fare', \n                y='Age', \n                hue='Survived')\n\nsns.scatterplot(ax=ax[1], data=raw_data, \n                x='FamilyMembers', \n                y='Age', \n                hue='Survived')\n\nsns.scatterplot(ax=ax[2], data=raw_data, \n                x='Sex', \n                y='Age', \n                hue='Survived')\n\nplt.show()","2e09f72d":"percent_sur_Sex = pd.DataFrame(data=raw_data.groupby(by='Sex').Survived.sum()).reset_index()\npercent_sur_Sex['Survive%'] = round(percent_sur_Sex['Survived']\/len(raw_data)*100, 2)\n\npercent_sur_Embarked = pd.DataFrame(data=raw_data.groupby(by='Embarked').Survived.sum()).reset_index()\npercent_sur_Embarked['Survive%'] = round(percent_sur_Embarked['Survived']\/len(raw_data)*100, 2)\n\npercent_sur_TFM = pd.DataFrame(data=raw_data.groupby(by='FamilyMembers').Survived.sum()).reset_index()\npercent_sur_TFM['Survive%'] = round(percent_sur_TFM['Survived']\/len(raw_data)*100, 2)\n\npercent_sur_Pclass = pd.DataFrame(data=raw_data.groupby(by='Pclass').Survived.sum()).reset_index()\npercent_sur_Pclass['Survive%'] = round(percent_sur_Pclass['Survived']\/len(raw_data)*100, 2)\n","633288b5":"fig = make_subplots(rows = 2, cols=2)\n\nfig.add_trace(go.Scatter(x=percent_sur_Sex['Sex'], y=percent_sur_Sex['Survive%']), row=1, col=1)\n\nfig.add_trace(go.Scatter(x=percent_sur_Embarked['Embarked'], y=percent_sur_Embarked['Survive%']), row=1, col=2)\n\nfig.add_trace(go.Scatter(x=percent_sur_TFM['FamilyMembers'], y=percent_sur_TFM['Survive%']), row=2, col=1)\n\nfig.add_trace(go.Scatter(x=percent_sur_Pclass['Pclass'], y=percent_sur_Pclass['Survive%']), row=2, col=2)\n\nfig.update_xaxes(title_text = \"Gender\", row=1, col=1)\nfig.update_xaxes(title_text = \"Embarked Point\", row=1, col=2)\nfig.update_xaxes(title_text = \"Family Members\", row=2, col=1)\nfig.update_xaxes(title_text = \"Pclass\", row=2, col=2)\n\nfig.update_layout(showlegend= False, title = {'text': 'Percentage of Survivors', 'x': 0.5})\n\niplot(fig)","051d4ef1":"data_with_dummies = pd.get_dummies(raw_data[['Sex', 'Cabin', 'Embarked']], drop_first=True)\ndata_with_dummies = pd.concat([raw_data, data_with_dummies], axis=1)\ndata_with_dummies.drop(columns=['Sex', 'Cabin', 'Embarked', 'Cabin_T'], axis=1, inplace=True)\ndata_with_dummies\n","2b0036fe":"standardize_data(data_with_dummies)","a9124eb9":"check_vif_data(data_with_dummies)","55b843ab":"master_dataframe(data_with_dummies)","c923d323":"y = data_with_dummies['Survived']\nX = data_with_dummies.drop(columns=['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","fbbd41b8":"print('Shape of X_train training dataset : ', X_train.shape)\nprint('Shape of y_train training dataset : ', y_train.shape)\nprint('Shape of X_test training dataset : ', X_test.shape)\nprint('Shape of y_test training dataset : ', y_test.shape)","b2dd5a27":"model = LogisticRegression()\nmodel.fit(X_train, y_train)","60a331ee":"y_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)","3929c0b7":"cm = confusion_matrix(y_train, y_pred_train)\npred_corr = cm[0,0]+cm[1,1]\npred_incorr = cm[1,0]+cm[0,1]\ntotal = cm.sum()\naccuracy_train_data = pred_corr\/total*100\nprint('Accuracy of the model measured on train data set is %f:' %(accuracy_train_data))","7520143d":"cm_test_data = confusion_matrix(y_test, y_pred_test)\npred_corr_test = cm_test_data[0,0]+cm_test_data[1,1]\npred_incorr_test = cm_test_data[1,0]+cm_test_data[0,1]\ntotal = cm_test_data.sum()\naccuracy_test_data = pred_corr_test\/total*100\nprint('Accuracy of the model measured on test data set is %f:' %(accuracy_test_data))","2fc395ef":"family_members(raw_data_test)","4fb047b1":"handle_null_Age(raw_data_test)","543adec2":"handle_null_Cabin(raw_data_test)","69706b9b":"handle_null_Embarked(raw_data_test)","b497468f":"handle_null_Fare(raw_data_test)","3577104c":"master_dataframe(raw_data_test)","70ad73eb":"data_with_dummies_test = pd.get_dummies(raw_data_test[['Sex', 'Cabin', 'Embarked']], drop_first=True)\ndata_with_dummies_test = pd.concat([raw_data_test, data_with_dummies_test], axis=1)\ndata_with_dummies_test.drop(columns=['Sex', 'Cabin', 'Embarked'], axis=1, inplace=True)\ndata_with_dummies_test\n","03c4db21":"standardize_data(data_with_dummies_test)","b0e3f512":"check_vif_data(data_with_dummies_test)","db16d36b":"data_with_dummies_test.reset_index(drop=True)","e59eed9d":"x_test = data_with_dummies_test.drop(columns=['PassengerId', 'Name', 'Ticket'], axis=1)","302c773c":"y_pred_submission = model.predict(x_test)","0c965191":"df_predicted = pd.DataFrame()\ndf_predicted['PassengerId'] = data_with_dummies_test['PassengerId']\ndf_predicted['Survived'] = y_pred_submission\ndf_predicted","9eb7a261":"df_predicted.to_csv('Titanic_Survivors_Prediction_2nd_Attempt.csv', index=False)","aa4f1ff6":"### Standardized the Age & fare","be8bec20":"### Importing necessary packages","ce1dc16d":"# Check percentage of survivors","3aeb0e35":"# Check the relationship between variables","401d396a":"### Loading Data","74fa32d1":"# Getting data prepared for submission","8210f101":"### Check metadata for Test Dataset","fbea4ec8":"### Checkinf features for multi-colliniarity","04845ac0":"### Checking the metadata post data cleaning","daeb78ce":"### Descriptive Analysis","ef917ee8":"### Created dummies for columns : 'Sex', 'Cabin', 'Embarked', 'Pclass'"}}