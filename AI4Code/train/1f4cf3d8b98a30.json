{"cell_type":{"206376e8":"code","9319c598":"code","e7772c05":"code","b278babb":"code","22812568":"code","3f2af489":"code","b72dab5b":"code","49542d17":"code","e673b2e6":"code","a9d2936f":"code","ffdc0144":"code","fedccf56":"code","d38c6293":"code","902db90c":"code","9c468604":"code","e1e9302e":"code","cc2cba0e":"code","23a253e8":"code","f1f4aab4":"markdown","27c1518b":"markdown","006a93e1":"markdown","4c68fa6e":"markdown","e151f056":"markdown","642d01ec":"markdown","dafc9be8":"markdown","23b5435d":"markdown","91d8a97a":"markdown","5a2c20e0":"markdown","9003f829":"markdown","1205de6e":"markdown","b833d1b6":"markdown","bb8d5393":"markdown"},"source":{"206376e8":"pwd = !pwd # ['\/kaggle\/working']\npwd = pwd[0] + '\/'\npwd","9319c598":"posenet_path = pwd + 'posenet-pytorch\/'\nposenet_path","e7772c05":"!rm -rf {pwd}\/*\n!git clone https:\/\/github.com\/rwightman\/posenet-pytorch > \/dev\/null 2>&1\n!ls {posenet_path}","b278babb":"!python3 {posenet_path}get_test_images.py > \/dev\/null 2>&1\n!ls {pwd}\/images","22812568":"import os\n\nimage_path = pwd + 'images\/'\nimage_list = [image for image in sorted(os.listdir(image_path)) if os.path.isfile(os.path.join(image_path, image))]\nimage_list","3f2af489":"import random\n\nsample_count = 5\nimage_samples = random.sample(image_list, 5)\nimage_samples","b72dab5b":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\nrow = sample_count\ncol = 1\nfigure = plt.figure(figsize = (10 * sample_count, 50 * col))\n\nfor r in range(row):\n    for c in range(col):\n        ax = figure.add_subplot(row, col, r * col + c + 1)\n        ax.axis(\"off\")\n        ax.imshow(mpimg.imread(image_path + image_samples[r]))\n        ax.set_title(image_samples[r].split('.')[0], fontsize = 20)\nplt.show()","49542d17":"output_path = pwd + 'output\/'\nif os.path.isdir(output_path):\n    !rm -rf {output_path}\n!mkdir {output_path}\n\n!python3 {posenet_path}image_demo.py --model 101 --notxt --image_dir {image_path} --output_dir {output_path} > \/dev\/null 2>&1\n\n!ls {output_path}","e673b2e6":"import matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\nrow = sample_count\ncol = 2\nfigure = plt.figure(figsize = (10 * sample_count, 50 * col))\n\nfor r in range(row):\n    for c in range(col):\n        ax = figure.add_subplot(row, col, r * col + c + 1)\n        ax.axis(\"off\")\n        if c == 0:   # original image\n            ax.imshow(mpimg.imread(image_path + image_samples[r]))\n            ax.set_title('(Before) ' + image_samples[r].split('.')[0], fontsize = 20)\n        elif c == 1: # append PoseNet image\n            ax.imshow(mpimg.imread(output_path + image_samples[r]))\n            ax.set_title('(After) ' + image_samples[r].split('.')[0], fontsize = 20)\nplt.show()","a9d2936f":"!curl -L https:\/\/yt-dl.org\/downloads\/latest\/youtube-dl -o \/usr\/local\/bin\/youtube-dl\n!chmod a+rx \/usr\/local\/bin\/youtube-dl","ffdc0144":"video_link = 'https:\/\/www.youtube.com\/watch?v=x3_OS6asKeM'\noriginal_video_name = 'video.mp4'\n!youtube-dl -o {original_video_name} {video_link}","fedccf56":"size = !ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=s=x:p=0 {pwd}{original_video_name}\nsize = size[0]\nvideo_width, video_height = map(int, size.split('x'))\nvideo_width, video_height","d38c6293":"from IPython.display import HTML\nfrom base64 import b64encode\n\nsrc = 'data:video\/mp4;base64,' + b64encode(open(pwd + original_video_name, 'rb').read()).decode()\nHTML('<video width=\"%d\" height=\"%d\" controls autoplay loof><source src=\"%s\" type=\"video\/mp4\"><\/video>' % (video_width \/ 2, video_height \/ 2, src))","902db90c":"%%writefile {posenet_path}video_demo.py\n\nimport torch\nimport cv2\nimport time\nimport argparse\nfrom tqdm.auto import tqdm\n\nimport posenet\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--model', type=int, default = 101)\nparser.add_argument('--cam_id', type=str, default = 0)\nparser.add_argument('--cam_width', type=int, default = 1920)\nparser.add_argument('--cam_height', type=int, default = 1080)\nparser.add_argument('--scale_factor', type=float, default = 0.7125)\nparser.add_argument('--output', type=str, default = 'output.mp4')\nparser.add_argument('--codec', type=str, default = 'vp90')\nparser.add_argument('--fps', type=float, default = 25.0)\nargs = parser.parse_args()\n\n\ndef main():\n    model = posenet.load_model(args.model)\n    model = model.cuda()\n    output_stride = model.output_stride\n\n    cap = cv2.VideoCapture(args.cam_id)\n    cap.set(3, args.cam_width)\n    cap.set(4, args.cam_height)\n\n    out = cv2.VideoWriter(args.output, cv2.VideoWriter_fourcc(*args.codec), args.fps, (args.cam_width, args.cam_height))\n    start = time.time()\n    frame_count = 0\n    for _ in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))), position = 0):\n        try:\n            input_image, display_image, output_scale = posenet.read_cap(\n                cap, scale_factor = args.scale_factor, output_stride = output_stride)\n        except IOError:\n            break\n        with torch.no_grad():\n            input_image = torch.Tensor(input_image).cuda()\n\n            heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = model(input_image)\n\n            pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multiple_poses(\n                heatmaps_result.squeeze(0),\n                offsets_result.squeeze(0),\n                displacement_fwd_result.squeeze(0),\n                displacement_bwd_result.squeeze(0),\n                output_stride = output_stride,\n                max_pose_detections = 10,\n                min_pose_score = 0.15)\n\n        keypoint_coords *= output_scale\n\n        overlay_image = posenet.draw_skel_and_kp(\n            display_image, pose_scores, keypoint_scores, keypoint_coords,\n            min_pose_score = 0.15, min_part_score = 0.1)\n        \n        frame_count += 1\n        out.write(overlay_image)\n\n    cap.release()\n    out.release()\n    print('Average FPS: ', frame_count \/ (time.time() - start))\n    \n\nif __name__ == \"__main__\":\n    main()","9c468604":"!ffmpeg -i {original_video_name}","e1e9302e":"posenet_video_name = 'output.mp4'\ncodec = 'vp90'\nfps = 25.0\n!python3 {posenet_path}video_demo.py --model 101 --cam_width {video_width} --cam_height {video_height} \\\n                                    --cam_id {pwd}{original_video_name} --output {pwd}{posenet_video_name} \\\n                                    --codec {codec} --fps {fps} > \/dev\/null\n!ls {pwd}","cc2cba0e":"!ffmpeg -i {posenet_video_name}","23a253e8":"src = 'data:video\/mp4;base64,' + b64encode(open(pwd + posenet_video_name, 'rb').read()).decode()\nHTML('<video width=\"%d\" height=\"%d\" controls autoplay loof><source src=\"%s\" type=\"video\/mp4\"><\/video>' % (video_width \/ 2, video_height \/ 2, src))","f1f4aab4":"## Choose samples","27c1518b":"## 8. Display PoseNet video","006a93e1":"# 2. Clone PoseNet repository","4c68fa6e":"# 5. Compare images","e151f056":"# 0. What is PoseNet?\n\n#### **Refernce**: https:\/\/www.tensorflow.org\/lite\/examples\/pose_estimation\/overview\n\n![posenet process](https:\/\/www.tensorflow.org\/images\/lite\/models\/pose_estimation.gif)","642d01ec":"# 1. Set path variables","dafc9be8":"## Show samples","23b5435d":"# PoseNet Example\n\n#### **Reference**: https:\/\/github.com\/rwightman\/posenet-pytorch","91d8a97a":"# 6. Download a video","5a2c20e0":"## Chrome can supports the vp90 codec.\n\n**Reference** : https:\/\/github.com\/jupyter-widgets\/ipywidgets\/issues\/2559#issuecomment-536536553","9003f829":"## Display original video","1205de6e":"# 4. Run PoseNet for image\n\n## **GPU is required**","b833d1b6":"# 7. Run PoseNet for video","bb8d5393":"# 3. Download sample images"}}