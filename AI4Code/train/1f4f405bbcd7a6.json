{"cell_type":{"1f29989a":"code","51897193":"code","9db8464a":"code","19777df7":"code","c2125ad6":"code","8884b6ed":"code","e657b00b":"code","eb97f736":"code","9c93eea4":"code","3a8ebe7d":"code","7ec8f6e7":"code","bef7b66d":"markdown","dac4ad44":"markdown","a698726d":"markdown","f0b47e63":"markdown"},"source":{"1f29989a":"import re\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nfrom tqdm.notebook import tqdm\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (12, 5);\nsns.set_style('whitegrid')\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","51897193":"train_df = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ntest_df = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")","9db8464a":"train_df.tail(3)\ntest_df.tail(3)","19777df7":"train_df.duplicated([\"less_toxic\", \"more_toxic\"]).sum()\n(train_df.duplicated([\"less_toxic\", \"more_toxic\"]).sum())\/train_df.shape[0]","c2125ad6":"train_df = train_df.drop_duplicates([\"less_toxic\", \"more_toxic\"]).reset_index()\ntrain_df.shape","8884b6ed":"letter_patterns = {\n    \"3\": \"e\",\n    \"4\": \"for\",\n    \" u \": \" you \",\n    \"n't\": \" not\"\n}\n\ndef remove_unprintables(text):\n    for symbol in [\"\\n\", \"\\r\", \"\\t\"]:\n        text = text.replace(symbol, \" \")\n    return re.sub(\" +\", \" \", text)\n\ndef fix_words(text, patterns=letter_patterns):\n    for key in patterns.keys():\n        text = text.replace(key, patterns[key])\n    return text\n\ndef tokenize(text, lower=True):\n    for char in \",.~!@#$%^&*()_=-[]{}\\\"'\":\n        text = text.replace(char, \" \")\n    text = remove_unprintables(text)\n    tokens = [x for x in text.split(\" \") if len(x) != 0]\n    tokens = tokens if not lower else [x.lower() for x in tokens]\n    return tokens\n\ndef count_caps_words(text):\n    tokens = tokenize(text, lower=False)\n    count = [1 for x in tokens if t.isupper()]\n    return count.sum()\n\ndef count_sticky_keys(text):\n    count, mem_char = 0, None\n    for i in range(2, len(text)-2):\n        if text[i] == mem_char:\n            continue\n        if text[i] == text[i-1] == text[i-2] and text[i] == text[i+1] == text[i+2]:\n            count += 1\n            mem_char = text[i]\n    return count","e657b00b":"c = 0\nfor i in range(train_df.shape[0]):\n    if train_df[\"less_toxic\"][i] in train_df[\"more_toxic\"].tolist():\n        c += 1\nc","eb97f736":"def find_least_toxic():\n    start_idxes = []\n    for i in tqdm(range(train_df.shape[0]), total=train_df.shape[0]):\n        text = train_df[\"less_toxic\"][i]\n        if text in train_df[\"more_toxic\"].tolist() and text not in train_df.drop(\n            i)[\"less_toxic\"].tolist():\n            start_idxes.append(i)\n            \n    return start_idxes\n\ndef find_more_toxic(idx):\n    text = train_df.loc[idx, \"more_toxic\"]\n#     print(text)\n    candidates = train_df[train_df.less_toxic == text]\n    return candidates.index.tolist()\n\ndef find_all_chains():\n    chains = []\n    least_toxic_idx = find_least_toxic()\n    \n    for idx in tqdm(least_toxic_idx):\n        df = train_df.copy()\n#         df = train_df.drop(idx)\n        chain = [idx]\n        \n        while df.shape[0] > 0:\n#             print(idx)\n            next_idx = find_more_toxic(idx)\n            df = df.drop(idx)\n            if len(next_idx) > 0:\n                chain.append(next_idx[0])\n                try:\n                    idx = [x for x in next_idx if x in df.index.tolist()][0]\n                except Exception as e:\n                    break\n            else:\n                break\n            \n        if len(chain) > 1:\n            chains.append(list(dict.fromkeys(chain)))\n            \n    return list(set(tuple(x) for x in chains))","9c93eea4":"chains = find_all_chains()","3a8ebe7d":"len(chains)","7ec8f6e7":"for i in range(15):\n    chain = chains[-i]\n#     print(chain)\n    string = train_df.loc[chain[0], \"less_toxic\"]\n    for idx in chain:\n        string += \"\\n{more toxic} \" + train_df.loc[idx, \"more_toxic\"].replace(\"\\n\", \" \")\n    string\n    \"-\"*30","bef7b66d":"#### *Let's look at some relative ratings. We might encounter some inconsistancies due to, well, some subjectivety of the task*","dac4ad44":"*Work in progress*","a698726d":"#### *Incredible, almost half of all comment pairs are duplicates! Let's use this fact to shorten our dataset.*","f0b47e63":"## Disclamer:\n### Explicit content and rude language is present in the dataset"}}