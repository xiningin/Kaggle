{"cell_type":{"3d545504":"code","fff98885":"code","4b2c35c3":"code","09d706a1":"code","b798db12":"code","27a2c644":"code","44b412b2":"code","29967a2c":"code","6406bff3":"code","fe85346a":"code","e8a7965e":"code","e3e6ae8c":"code","71212baf":"code","4f4d7a3c":"code","e57606c4":"code","2c2ded9d":"code","9df57165":"code","9edd2822":"code","fedbab96":"code","fee5ea1c":"code","63c83f24":"code","8068df23":"code","d2c68038":"code","352d846e":"code","d45eefea":"code","49216de2":"code","147c4639":"code","5dcc5e06":"code","620bec04":"code","a2167958":"code","e307bb75":"code","5561105c":"code","b38c3c59":"code","cf82f07c":"code","797b6bd1":"code","b8dab995":"code","79eaa4fc":"code","4b581b99":"code","abf6f6e0":"code","31eb1466":"code","0eb05f34":"code","b1a7d809":"code","45e55b4f":"code","58f301e3":"code","91260478":"code","ae69e29c":"code","5ec290c3":"code","a64c634a":"code","f35c7030":"code","e2e6b804":"code","1b890c85":"code","f3f6e742":"markdown","c885fe85":"markdown","f4065d82":"markdown","fc84af1c":"markdown","ca868bfc":"markdown","28dc792c":"markdown","d12945c3":"markdown","d2f49d7e":"markdown","935d4dfd":"markdown","f4cf6846":"markdown","5e9305c8":"markdown","30e5cfed":"markdown","d5d9fc2d":"markdown","a9741fa5":"markdown","e29fc180":"markdown","cf397d0f":"markdown","a2c9b01b":"markdown","445cfc6c":"markdown","21acb778":"markdown","e7916ba0":"markdown","0f56224c":"markdown","22d81a68":"markdown","2f5e5a90":"markdown","57e67738":"markdown","6f4a60aa":"markdown","d34470dc":"markdown","af6e11e8":"markdown","012cc1e2":"markdown","f4e6446b":"markdown"},"source":{"3d545504":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nsns.set()\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fff98885":"df = pd.read_csv('\/kaggle\/input\/star-type-classification\/Stars.csv')\n\nprint(df.shape)\ndf.head()","4b2c35c3":"df.describe()","09d706a1":"target = 'Type'","b798db12":"df.groupby(target)['L'].count().plot.bar()\n\nplt.ylabel('Count')\nplt.show()","27a2c644":"df.isnull().sum()","44b412b2":"num_features = [feature for feature in df.columns if df[feature].dtype != 'O' and feature != target]\n\ndf[num_features].head()","29967a2c":"for feature in num_features:\n    iqr = stats.iqr(df[feature], interpolation = 'midpoint')\n    h = (2 * iqr) \/ (len(df[feature]) ** (1\/3))\n    bins = round((max(df[feature]) - min(df[feature])) \/ h)\n    \n    df[feature].hist(bins = bins)\n    plt.xlabel(feature)\n    plt.ylabel('Count')\n    plt.show()","6406bff3":"for feature in num_features:\n    df.boxplot(column = feature)\n    plt.ylabel('Value')\n    plt.show()","fe85346a":"extreme = df['R'].median() + 0.5 * df['R'].std()\n\nprint('values to replace: {}%'.format(len(df.loc[df['R'] > extreme]) * 100 \/ len(df)))","e8a7965e":"df['R'] = np.where(df['R'] > extreme, extreme, df['R'])","e3e6ae8c":"for feature in num_features:\n    plt.scatter(df[feature], df[target])\n    plt.xlabel(feature)\n    plt.ylabel(target)\n    plt.show()","71212baf":"for feature in num_features[:-1]:\n    df[feature] = np.log(df[feature])\n    \n    iqr = stats.iqr(df[feature], interpolation = 'midpoint')\n    h = (2 * iqr) \/ (len(df[feature]) ** (1\/3))\n    bins = round((max(df[feature]) - min(df[feature])) \/ h)\n    \n    df[feature].hist(bins = bins)\n    plt.xlabel(feature)\n    plt.ylabel('Count')\n    plt.show()","4f4d7a3c":"cat_features = [feature for feature in df.columns if feature not in num_features and feature != target]\n\ndf[cat_features].head()","e57606c4":"for feature in cat_features:\n    print('{}: {} categories'.format(feature, len(df[feature].unique())))\n    print(df[feature].unique())","2c2ded9d":"idx = df.loc[(df['Color'] == 'Blue white') | (df['Color'] == 'Blue-white') | (df['Color'] == 'Blue-White')].index\ndf.loc[idx, 'Color'] = 'Blue White'\n\nidx = df.loc[df['Color'] == 'white'].index\ndf.loc[idx, 'Color'] = 'White'\n\nidx = df.loc[(df['Color'] == 'yellowish') | (df['Color'] == 'Yellowish')].index\ndf.loc[idx, 'Color'] = 'Yellow'\n\nidx = df.loc[df['Color'] == 'Yellowish White'].index\ndf.loc[idx, 'Color'] = 'White-Yellow'","9df57165":"for feature in cat_features:\n    df.groupby(feature)[target].count().plot.bar()\n    plt.ylabel('count')\n    plt.show()","9edd2822":"for feature in cat_features:\n    df.groupby([feature, target])['L'].count().plot.bar()\n    plt.ylabel('count')\n    plt.show()","fedbab96":"idx = df.loc[(df['Color'] == 'yellow-white') | (df['Color'] == 'Yellow') | (df['Color'] == 'Whitish') | (df['Color'] == 'Orange-Red')].index\ndf.loc[idx, 'Color'] = 'cat_3_only'\n\nidx = df.loc[(df['Color'] == 'Pale yellow orange') | (df['Color'] == 'White-Yellow')].index\ndf.loc[idx, 'Color'] = 'cat_2_only'","fee5ea1c":"for feature in cat_features:\n    print('{}: {} categories'.format(feature, len(df[feature].unique())))\n    print(df[feature].unique())","63c83f24":"for feature in cat_features:\n    df.groupby([feature, target])['L'].count().plot.bar()\n    plt.ylabel('count')\n    plt.show()","8068df23":"df = pd.read_csv('\/kaggle\/input\/star-type-classification\/Stars.csv')\n\nprint(df.shape)\ndf.head()","d2c68038":"extreme = df['R'].median() + 0.5 * df['R'].std()\n\ndf['R'] = np.where(df['R'] > extreme, extreme, df['R'])","352d846e":"for feature in num_features[:-1]:\n    df[feature] = np.log(df[feature])","d45eefea":"idx = df.loc[(df['Color'] == 'Blue white') | (df['Color'] == 'Blue-white') | (df['Color'] == 'Blue-White')].index\ndf.loc[idx, 'Color'] = 'Blue White'\n\nidx = df.loc[df['Color'] == 'white'].index\ndf.loc[idx, 'Color'] = 'White'\n\nidx = df.loc[(df['Color'] == 'yellowish') | (df['Color'] == 'Yellowish')].index\ndf.loc[idx, 'Color'] = 'Yellow'\n\nidx = df.loc[df['Color'] == 'Yellowish White'].index\ndf.loc[idx, 'Color'] = 'White-Yellow'","49216de2":"idx = df.loc[(df['Color'] == 'yellow-white') | (df['Color'] == 'Yellow') | (df['Color'] == 'Whitish') | (df['Color'] == 'Orange-Red')].index\ndf.loc[idx, 'Color'] = 'cat_3_only'\n\nidx = df.loc[(df['Color'] == 'Pale yellow orange') | (df['Color'] == 'White-Yellow')].index\ndf.loc[idx, 'Color'] = 'cat_2_only'","147c4639":"dummy_df = pd.get_dummies(df, drop_first = True)\ndummy_df.head()","5dcc5e06":"X = dummy_df.drop(target, axis = 1)\ny = dummy_df[target]","620bec04":"cor = X[num_features].corr()\n\nsns.heatmap(cor, annot = True, cmap = plt.cm.CMRmap_r)\nplt.show()","a2167958":"X.drop(['R'], axis = 1, inplace = True)","e307bb75":"scores = {}","5561105c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","b38c3c59":"model = RandomForestClassifier()\n\nmodel.fit(X_train, y_train)","cf82f07c":"y_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","797b6bd1":"scores['RandomForest Classifier'] = model.score(X_test, y_test)","b8dab995":"model = XGBClassifier(use_label_encoder = False)\n\nmodel.fit(X_train, y_train)","79eaa4fc":"y_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","4b581b99":"scores['XGBoost Classifier'] = model.score(X_test, y_test)","abf6f6e0":"scaler = MinMaxScaler()\n\nscaler.fit(X_train)","31eb1466":"X_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)","0eb05f34":"model = LogisticRegression()\n\nmodel.fit(X_train_scaled, y_train)","b1a7d809":"y_pred = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","45e55b4f":"scores['Logistic Regression'] = model.score(X_test_scaled, y_test)","58f301e3":"n_score = []\nn_neighbors = [3, 4, 5, 6, 7, 8, 9, 10]\n\nfor n in n_neighbors:\n    model = KNeighborsClassifier(n_neighbors = n)\n    model.fit(X_train_scaled, y_train)\n    n_score.append(model.score(X_test_scaled, y_test))\n    \nbest_neighbors = n_neighbors[n_score.index(max(n_score))]\nprint('Best Neighbors = {}'.format(best_neighbors))","91260478":"model = KNeighborsClassifier(n_neighbors = best_neighbors)\n\nmodel.fit(X_train_scaled, y_train)","ae69e29c":"y_pred = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","5ec290c3":"scores['KNN'] = model.score(X_test_scaled, y_test)","a64c634a":"model = SVC(kernel = 'poly')\n\nmodel.fit(X_train_scaled, y_train)","f35c7030":"y_pred = model.predict(X_test_scaled)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","e2e6b804":"scores['SVM'] = model.score(X_test_scaled, y_test)","1b890c85":"for model in scores:\n    print('{}: {}% accuracy'.format(model, scores[model] * 100))","f3f6e742":"## SVM","c885fe85":"# Feature Engineering","f4065d82":"There are several repetitions in the Color column which we can fix","fc84af1c":"# Models","ca868bfc":"## Categorical Features","28dc792c":"### Inferences\n\n1. If a star has the color Pale yellow orange or White-Yellow it will definitely belong to Type 2\n2. If a star has th color yellow-white, Yellow, Whitish or Orange-Red it will definitely belong to Type 3\n3. If a star has the color Orange it will definitely belong to Type 5\n4. If a star has the spectral type 'G' then it will definitely belong to Type 5:","d12945c3":"## RandomForest Classifier","d2f49d7e":"### Transformation","935d4dfd":"### Distribution","f4cf6846":"### vs Target Variable","5e9305c8":"Several Colors correspond to a single category which can be grouped together as they denote a fixed type of star","30e5cfed":"### Distribution","d5d9fc2d":"### Distribution","a9741fa5":"### Inferences\n\n1. If temperature is less than 5000 then star will definitely belong to Type 0 or Type 1: \n  \n2. If L value = 0 then star will definitely belong to Type 0, Type 1 or Type 2\n        \n3.  - If R value = 0 then star will definitely belong to Type 0, Type 1 or Type 2\n    - If R value > 250 then star will definitely belong to Type 5\n  \n4.  - If A_M value > 15 then star will definitely belong to Type 0\n    - If A_M value >= 10 or A_M value <= 15 then star will definitely belong to Type 1 or Type 2\n    - If A_M value > -5 or A_M value < 10 then star will definitely belong to Type 3","e29fc180":"### vs Target","cf397d0f":"# EDA","a2c9b01b":"# Feature Selection","445cfc6c":"## Numerical Features","21acb778":"## Scaling","e7916ba0":"## Numerical Features","0f56224c":"Dataset is balanced","22d81a68":"## Target","2f5e5a90":"## Logistic Regression","57e67738":"### Outliers","6f4a60aa":"## KNN","d34470dc":"## XGBoost","af6e11e8":"## Missing Values","012cc1e2":"## Final Scores","f4e6446b":"## Categorical Features"}}