{"cell_type":{"86a4f9f8":"code","7fd85fe8":"code","8dcb86bb":"code","3aed23ce":"code","36576964":"code","b082984f":"code","1e95c1c2":"code","d7610dd9":"code","720c8356":"code","ead2995b":"code","e4f38f4a":"code","0a1e868c":"code","63eec85b":"code","92dc4540":"code","1ce334f1":"code","b7bdce7e":"code","a085080f":"code","b8883c05":"code","de389c45":"code","3f92a328":"code","abf34376":"markdown","4e3743f7":"markdown","9158e3db":"markdown","03f689af":"markdown","c76de8a6":"markdown","5eb57fa1":"markdown","c4e83c3b":"markdown","d331bce2":"markdown","0d6298cb":"markdown","92eac194":"markdown"},"source":{"86a4f9f8":"#import numpy for number array handling and represent rgb image pixel values\nimport numpy as np\n\n#import tensorflow to use any tools needed for deep learning\nimport tensorflow as tf\n\n#import keras api needed to implement deep learning techiques\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#import libraries for visualization of data\nimport matplotlib.pyplot as plt\n\n#Allow charts and graphics to display right below the page of browser setup\n%matplotlib inline","7fd85fe8":"#paths to the train, validation and test image datasets \ntrain_path = '..\/input\/garbage-classification\/garbage classification\/Garbage classification'\nvalid_path = '..\/input\/garbage-classification\/garbage classification\/Garbage classification'","8dcb86bb":"train_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.1).flow_from_directory(\n    directory=train_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='training')","3aed23ce":"valid_batches = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n    validation_split=0.1).flow_from_directory(\n    directory=valid_path, target_size=(224,224), classes=['cardboard', 'glass', 'metal', \n                                                         'paper', 'plastic', 'trash'], batch_size=16, subset='validation')","36576964":"def plotImages(images):\n    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images, axes):\n        ax.imshow(img.astype(np.uint8))\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","b082984f":"imgs, labels = next(train_batches)\nplotImages(imgs)","1e95c1c2":"#\u8f93\u5165\u56fe\u50cf\u5927\u5c0f\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n#\u5bfc\u5165\u5e26\u6709\u9884\u8bad\u7ec3\u6743\u91cd\u7684VGG\u57fa\u672c\u6a21\u578b\nbase_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, \n                                        include_top=False,\n                                        weights='imagenet')","d7610dd9":"base_model.summary()","720c8356":"\nmodel = Sequential()\n\nbase_model.trainable=False\n\n#\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\nmodel.add(base_model)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(units=512, activation='relu'))  \nmodel.add(BatchNormalization())                 \nmodel.add(Dropout(0.2))                         \n\nmodel.add(Dense(units=128, activation='relu')) \nmodel.add(BatchNormalization())                \nmodel.add(Dropout(0.2))                        \n\nmodel.add(Dense(units=6, activation='softmax')) \nmodel.summary()","ead2995b":"model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","e4f38f4a":"model_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=30, verbose=2)","0a1e868c":"loss = model_details.history['loss']\nvalidation_loss = model_details.history['val_loss']","63eec85b":"accuracy = model_details.history['accuracy']\nvalidation_accuracy = model_details.history['val_accuracy']","92dc4540":"base_model.trainable=True","1ce334f1":"model.summary()","b7bdce7e":"model_details = model.fit(x=train_batches, validation_data=valid_batches, epochs=8, verbose=2)","a085080f":"model.save('vgg16.h5')","b8883c05":"loss.extend(model_details.history['loss'])\nvalidation_loss.extend(model_details.history['val_loss'])\naccuracy.extend(model_details.history['accuracy'])\nvalidation_accuracy.extend(model_details.history['val_accuracy'])","de389c45":"epochs = range(1, len(loss)+1)\n\nfig1 = plt.figure(figsize=(10,6))\nplt.plot(epochs,loss,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_loss,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(epochs)\nplt.legend()","3f92a328":"epochs = range(1, len(accuracy)+1)\n\nfig2 = plt.figure(figsize=(10,6))\nplt.plot(epochs,accuracy,c=\"red\",label=\"Training\")\nplt.plot(epochs,validation_accuracy,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(epochs)\nplt.legend()","abf34376":"**\u751f\u6210\u9a8c\u8bc1\u96c6\u6570\u636e**","4e3743f7":"**\u67e5\u770bVGG\u5404\u5c42\u7684\u53c2\u6570**","9158e3db":"**\u67e5\u770b\u8bad\u7ec3\u7ed3\u679c**","03f689af":"**\u8bbe\u7f6e\u635f\u5931\u51fd\u6570\u3001metrics\u3001adam\uff08\u521d\u59cb\u5b66\u4e60\u7387\u4e3a0.0001\uff09**","c76de8a6":"**\u5efa\u7acb\u5377\u79ef\u795e\u7ecf\u7f51\u7edc**","5eb57fa1":"**\u751f\u6210\u8bad\u7ec3\u96c6\u6570\u636e**","c4e83c3b":"**\u5fae\u8c03\u6a21\u578b**","d331bce2":"**\u7ed9\u6a21\u578b\u6dfb\u52a0\u5c42\uff0c\u6784\u5efa\u7f51\u7edc**","0d6298cb":"**\u67e5\u770b\u9884\u5904\u7406\u540e\u7684\u56fe\u7247**","92eac194":"**\u52a0\u8f7d\u6570\u636e**"}}