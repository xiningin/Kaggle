{"cell_type":{"57fa87ce":"code","ef78788a":"code","2a6851e1":"code","4464f486":"code","caf41b9c":"code","39c61860":"code","e2c7d317":"code","cf80e473":"code","cc21fd7d":"code","1bd4ae4f":"code","f3c0de69":"code","817b8ac2":"code","b95881d1":"code","919c74bb":"code","ba05b908":"code","697567e8":"code","d69fb41d":"code","794432f6":"code","644d9f51":"code","28285e2f":"code","63011a11":"code","3d5eabc3":"code","fe4c1b4b":"markdown","806791f1":"markdown","1d9aaab9":"markdown","329ab417":"markdown","f0641be0":"markdown","b9f59582":"markdown","c2238e02":"markdown","28dba13d":"markdown","1f1bb198":"markdown","28b7ab7c":"markdown","e84d79a8":"markdown","5765c7b2":"markdown","b48f8c5c":"markdown","517b363b":"markdown","7caf2cc0":"markdown","2be5a23e":"markdown","d440ea13":"markdown","26b76dc6":"markdown"},"source":{"57fa87ce":"! pip install distance #Make sure you have Internet(ON) in the Kaggle notebook settings","ef78788a":"import pandas as pd\nimport numpy as np\nimport json\nimport os.path\nimport re\nimport distance\nimport matplotlib.pyplot as plt","2a6851e1":"metadata=pd.read_csv(\"\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv\")\nmetadata=metadata[metadata[\"sha\"]==metadata[\"sha\"]] #filters out entries having sha=NaN\nmetadata=metadata[metadata[\"has_full_text\"]] #filters out entries for which the full text is not available","4464f486":"def path(shaid): #returns path of .json file\n    for dirname, _, files in os.walk('\/kaggle\/input'):\n        if shaid+'.json' in files:\n            return os.path.join(dirname,shaid+\".json\")","caf41b9c":"metadata[\"Path\"]=metadata.apply(lambda x: path(x[\"sha\"]),axis=1) #this takes a while unfotunately\nmetadata=metadata[metadata[\"Path\"]==metadata[\"Path\"]]\nmetadata.shape","39c61860":"STRING='vir ' #note the space at the end\nKEY='corona' #filter for keywords such as corona, covid, sars, mers, etc.","e2c7d317":"Texts={} #dictionary: {id: \"Text\"}; adapted from cristian's notebook (https:\/\/www.kaggle.com\/crprpr\/vaccine-data-filter)\nAbs_and_concl_w_punct={}\nvalid_id=[]\nfor shaid,file in zip(metadata[\"sha\"],metadata[\"Path\"]):\n    with open(file, 'r') as f:\n        doc=json.load(f)\n    MainText=''\n    A_C_w_p=''\n    for item in doc[\"body_text\"]:\n        MainText=MainText+(re.sub('[^a-zA-Z0-9]', ' ', item[\"text\"].lower()))\n        if (item[\"section\"]==\"Discussion\") or (item[\"section\"]==\"Abstract\") or (item[\"section\"]==\"Conclusion\"):\n            A_C_w_p=A_C_w_p+item[\"text\"].lower()\n    if (STRING in MainText) and (KEY in MainText):\n        Texts[shaid]=MainText\n        Abs_and_concl_w_punct[shaid]=A_C_w_p\n        valid_id.append(shaid)","cf80e473":"metadata=metadata[metadata[\"sha\"].isin(valid_id)] #filter only articles that contain names of antivirals","cc21fd7d":"MIN_LENGTH=6 #most likely names of antivirals are longer than 4 letters + 2 spaces; shorter words are probably acronyms \ndrugs=[]\nfor shaid in valid_id:\n    iterator=re.finditer(STRING,Texts[shaid])\n    for m in iterator:\n        drugs.append(Texts[shaid][Texts[shaid].rfind(' ',0, m.end()-2):m.end()])\ndrugs=[i for i in drugs if len(i)>MIN_LENGTH]\ndrugs_set=list(set(drugs))\ncount=[]\nfor d in drugs_set:\n    count.append(-drugs.count(d))\ndrugs_set=list(np.array(drugs_set)[np.array(count).argsort()])  # thanks Julian for the suggestion","1bd4ae4f":"len(drugs_set)","f3c0de69":"THRESH=2 #Threshold for the Levenshtein distance\nincorrects=[]\ncorrects=[]\nfrom itertools import combinations\nfor str1,str2 in combinations(drugs_set,2):\n    if (distance.levenshtein(str1, str2)<THRESH) and (drugs.count(str1)>10 or drugs.count(str2)>10):\n            if drugs.count(str1)>=drugs.count(str2):\n                incorrect=str2\n                correct=str1\n            else:\n                incorrect=str1\n                correct=str2\n            print(str1, \"(\",drugs.count(str1),\")\", \"and\", str2, \"(\",drugs.count(str2),\")\", \"look very similar.\")\n            if incorrect not in incorrects:\n                print(\"I will substitute\", incorrect, \"with\", correct,\".\")\n                incorrects.append(incorrect)\n                corrects.append(correct)","817b8ac2":"for item in incorrects:\n    drugs_set.remove(item)","b95881d1":"len(drugs_set)","919c74bb":"for shaid in valid_id:\n    for inc in range(0,len(incorrects)):\n        Texts[shaid]=re.sub(incorrects[inc],corrects[inc], Texts[shaid])","ba05b908":"antivirals=pd.DataFrame(drugs_set,columns=[\"Drug\"])\n\ndef count1(drug,druglist):\n    return druglist.count(drug)\n\ndef count2(drug):\n    n=0\n    for shaid in valid_id:\n        iterator=re.finditer(drug,Abs_and_concl_w_punct[shaid])\n        for m in iterator:\n            n+=1 \n    return n\n        \nantivirals['Count_text'] = antivirals.apply(lambda x: count1(x[\"Drug\"],drugs),axis=1) #counts occurences in the whole text\nantivirals['Count_abs_concl'] = antivirals.apply(lambda x: count2(x[\"Drug\"]),axis=1) #counts occurences in abstract + conclusions","697567e8":"MAXPLOT=20 #plot the MAXPLOT most mentioned antivirals\nplt.figure(figsize=(20,5))\nplt.bar(antivirals[\"Drug\"][(-antivirals[\"Count_text\"].to_numpy()).argsort()[:MAXPLOT]], antivirals[\"Count_text\"][(-antivirals[\"Count_text\"].to_numpy()).argsort()[:MAXPLOT]])\nplt.xticks(rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\nplt.ylabel(\"Counts\",fontsize=15)\nplt.show()","d69fb41d":"from textblob import TextBlob\nimport nltk\nhisto=[]\nnltk.download('punkt')","794432f6":"def Sentiment(drug): #looks for the drug name in the abstract or conclusions and measures the sentiment\n    s=0\n    smax=-1\n    for shaid in valid_id:\n            iterator=re.finditer(drug,Abs_and_concl_w_punct[shaid])\n            for m in iterator:\n                beg_comma=Abs_and_concl_w_punct[shaid].rfind(',',0, m.start())+1\n                end_comma=Abs_and_concl_w_punct[shaid].find(',',m.end()-1,len(Texts[shaid]))\n                beg_dot=Abs_and_concl_w_punct[shaid].rfind('.',0, m.start())+1\n                end_dot=Abs_and_concl_w_punct[shaid].find('.',m.end()-1,len(Texts[shaid]))\n                beg=max(beg_comma,beg_dot)\n                end=min(end_comma,end_dot)\n                blob = TextBlob(Abs_and_concl_w_punct[shaid][beg:end])\n                s+=blob.sentiment.polarity\n    return s\n\nTHRESH=0.3\ndef Sentence(drug): #records positive senctences, with the doi for reference\n    nice_sentence=[]\n    for shaid in valid_id:\n            iterator=re.finditer(drug,Abs_and_concl_w_punct[shaid])\n            for m in iterator:\n                beg_comma=Abs_and_concl_w_punct[shaid].rfind(',',0, m.start())+1\n                end_comma=Abs_and_concl_w_punct[shaid].find(',',m.end()-1,len(Texts[shaid]))\n                beg_dot=Abs_and_concl_w_punct[shaid].rfind('.',0, m.start())+1\n                end_dot=Abs_and_concl_w_punct[shaid].find('.',m.end()-1,len(Texts[shaid]))\n                beg=max(beg_comma,beg_dot)\n                end=min(end_comma,end_dot)\n                blob = TextBlob(Abs_and_concl_w_punct[shaid][beg:end])\n                if blob.sentiment.polarity > THRESH:\n                    for doi in metadata[metadata[\"sha\"]==shaid][\"doi\"]:\n                        nice_sentence.append(str(blob)+\" [ \"+doi+\" ]\")\n    if len(nice_sentence)==0:\n        nice_sentence=\"Nothing found\"\n    return nice_sentence","644d9f51":"antivirals['Sentiment'] = antivirals.apply(lambda x: Sentiment(x[\"Drug\"]),axis=1)\nantivirals[\"Nice_sentence\"] = antivirals.apply(lambda x: Sentence(x[\"Drug\"]),axis=1)\n#antivirals['Sentiment_norm']=antivirals[\"Sentiment\"]\/antivirals[\"Count_abs_concl\"]","28285e2f":"MAXPLOT=20\nplt.figure(figsize=(20,5))\nplt.bar(antivirals[\"Drug\"][(-antivirals[\"Sentiment\"].to_numpy()).argsort()[:MAXPLOT]], antivirals[\"Sentiment\"][(-antivirals[\"Sentiment\"].to_numpy()).argsort()[:MAXPLOT]])\nplt.xticks(rotation=90)\nplt.xticks(rotation=90,fontsize=12)\nplt.yticks(fontsize=12)\nplt.ylabel(\"Total Sentiment\",fontsize=15)\nplt.show()","63011a11":"for sentences in antivirals[antivirals[\"Drug\"]==\" oseltamivir \"][\"Nice_sentence\"]:\n    for s in sentences:\n        print(s)","3d5eabc3":"for sentences in antivirals[antivirals[\"Drug\"]==\" favipiravir \"][\"Nice_sentence\"]:\n    for s in sentences:\n        print(s)","fe4c1b4b":"As medical doctors are busy saving lives, data scientists can help them navigate through the mole of recent literature on COVID-19 to access quickly and efficiently new approaches and new therapies. This simple notebook presents the most mentioned names of antivirals in the CORD-19 database.","806791f1":"Curiously, some names look very similar to each other, and are most likely typos or different spellings. Here I look for the similarity between pairs of words via the Levenshtein distance ( https:\/\/en.wikipedia.org\/wiki\/Levenshtein_distance ). If the distance is smaller than THRESH, I regard the names as equivalent and retain the spelling with most entries.","1d9aaab9":"At least 214 different antivirals are mentioned in the CORD-19 database.","329ab417":"# Sentiment analysis","f0641be0":"At the time of writing Favipiravir (Avigan) is regarded by a few research groups as a possible effective treatment against COVID-19 and experimental therapies have begun in Italy ( https:\/\/www.repubblica.it\/salute\/medicina-e-ricerca\/2020\/03\/23\/news\/covid-19_speranza_aifa_procede_su_sperimentazione_avigan_-252090636\/?refresh_ce , in Italian). However, the literature about this antiviral is scarce and the only positive sentence recorded by the sentiment analysis is referred to another virus (the Chikungunya virus):","b9f59582":"This demonstrates that the current literature on COVID-19 is still in its infancy.","c2238e02":"Oseltamivir (Tamiflu) and Zanamivir (Relenza) were both recommended by the World Health Organization (WHO) against the 2009 H1N1 pandemics (swine flu), see https:\/\/www.who.int\/csr\/resources\/publications\/swineflu\/h1n1_guidelines_pharmaceutical_mngt.pdf . Here are some sentences classified as \"positive\" by the sentiment analysis that involve Oseltamivir:","28dba13d":"Now drugs_set contains the set of antiviral names.","1f1bb198":"# Most mentioned antivirals","28b7ab7c":"Even if antivirals are strongly virus-specific, recycling medications that are already in use to treat similar diseases is the most efficient way to face an emergency.","e84d79a8":"This substitutes the correct spellings in the bodies of text:","5765c7b2":"In the scientific literature, \"hot\" topics and popular methods are often proper approaches, otherwise lot of experts (the scientists) would not bother writing about them. However, the contrary is not true: there may be very effective drugs taken into consideration only by few research groups. ","b48f8c5c":"# Data preparation","517b363b":"Here I apply sentiment analysis \"off-the-shelf\". I don't think this approach is optimal for scientific papers, which often involve neutral language, but it may be a good starting point.\nThe function \"Sentiment\" looks for the name of the antiviral in the abstract and conclusions sections, cuts the sentence around the found word by looking for the nearest dots or commas, and then assigns a sentiment between -1 and +1.","7caf2cc0":"According to the standard drug nomenclature ( https:\/\/en.wikipedia.org\/wiki\/Drug_nomenclature ), the names for antivirals have the suffix *-vir*. ","2be5a23e":"# Looking for antivirals","d440ea13":"Here I set up a dataframe (\"antivirals\") that contains useful information for each drug.","26b76dc6":"# Looking for misspellings"}}