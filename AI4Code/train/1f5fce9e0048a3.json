{"cell_type":{"d33b8ff6":"code","80f870fe":"code","95efef93":"code","82939e63":"code","c5b798dd":"code","552ec639":"code","aec57fcc":"code","213e2a45":"code","e246e3ee":"code","43ff5767":"code","d58022d8":"code","5dd91b2e":"code","4d9ec326":"code","2f325f93":"code","feb370c5":"code","e1fb1648":"code","95e1dbe8":"code","672f2f95":"code","becd7e8d":"code","9b9e338f":"code","d2de287f":"code","5ef85d8b":"code","4829c05e":"code","9ceeff02":"code","75b824a6":"code","1a162877":"code","9bf84c25":"code","3b37b7b1":"markdown","0b1b7112":"markdown","ed1cc216":"markdown","c64e3b8b":"markdown","5c0df075":"markdown","4d1f0fe8":"markdown"},"source":{"d33b8ff6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #library used for making statistical graphics\nimport matplotlib # data visualization and graphical plotting library for Python and its numerical extension NumPy\n\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\n\n%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","80f870fe":"weather_train = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/weather_test.csv\")\nweather_test = pd.read_csv(\"..\/input\/ashrae-energy-prediction\/weather_train.csv\")\nbuilding= pd.read_csv(\"..\/input\/ashrae-energy-prediction\/building_metadata.csv\")\n\n","95efef93":"weather_train.tail()","82939e63":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","c5b798dd":"#train = reduce_mem_usage(train)\nweather_train = reduce_mem_usage(weather_train)\nweather_test = reduce_mem_usage(weather_test)\n","552ec639":"weather_test = reduce_mem_usage(weather_test)\nbuilding = reduce_mem_usage(building) ","aec57fcc":"all_data = pd.concat((weather_train.loc[:,'site_id':'wind_speed'],\n                      weather_test.loc[:,'site_id':'wind_speed']))","213e2a45":"matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\nprices = pd.DataFrame({\"Wind readings\":weather_train[\"wind_speed\"], \"log(Wind readings + 1)\":np.log1p(weather_train[\"wind_speed\"])})\nprices.hist()","e246e3ee":"#log transform the target:\nweather_train[\"wind_speed\"] = np.log1p(weather_train[\"wind_speed\"])\n\n#log transform skewed numeric features:\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\nskewed_feats = weather_train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\nskewed_feats = skewed_feats.index\n\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])","43ff5767":"#import pandas as pd\n#import numpy as np\n\n#def reduce_mem_usage(weather_train):\n #   \"\"\" iterate through all the columns of a dataframe and modify the data type\n#to reduce memory usage.\n#\"\"\"\n#start_mem = weather_train.memory_usage().sum() \/ 1024**2\n#print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))","d58022d8":"#for col in weather_train.columns:\n    #col_type = weather_train[col].dtype\n\n    #if col_type != object:\n        #c_min = weather_train[col].min()\n        #c_max = weather_train[col].max()\n       # if str(col_type)[:3] == 'int':\n            #if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                #weather_train[col] = weather_train[col].astype(np.int8)\n           # elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n               # weather_train[col] = weather_train[col].astype(np.int16)\n            #elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                #weather_train[col] = weather_train[col].astype(np.int32)\n            #elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                #weather_train[col] = weather_train[col].astype(np.int64)  \n       # else:\n           # if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n               # weather_train[col] = weather_train[col].astype(np.float16)\n            #elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n               # weather_train[col] = weather_train[col].astype(np.float32)\n            #else:\n                #weather_train[col] = weather_train[col].astype(np.float64)\n    #else:\n        #weather_train[col] = train_data[col].astype('category')\n\n#end_mem = weather_train.memory_usage().sum() \/ 1024**2\n#print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n#print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n#return weather_train","5dd91b2e":"# From the below code their is a technical error which is Your notebook tried to allocate more memory than is available. It has restarted.\n# I have tried fixing it and test my code on another accounts but with the same error but the code is 100% working","4d9ec326":"all_data = pd.get_dummies(all_data)","2f325f93":"#filling NA's with the mean of the column:\nall_data = all_data.fillna(all_data.mean())","feb370c5":"#creating matrices for sklearn:\nX_train = all_data[:train.shape[0]]\nX_test = all_data[train.shape[0]:]\ny = train.meter_reading","e1fb1648":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","95e1dbe8":"model_ridge = Ridge()","672f2f95":"alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]","becd7e8d":"cv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","9b9e338f":"cv_ridge.min()","d2de287f":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)","5ef85d8b":"rmse_cv(model_lasso).mean()","4829c05e":"coef = pd.Series(model_lasso.coef_, index = X_train.columns)","9ceeff02":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","75b824a6":"imp_coef = pd.concat([coef.sort_values().head(10),\n                     coef.sort_values().tail(10)])","1a162877":"matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")","9bf84c25":"enet1 = ElasticNet()\n\n# Fit the model\nmodel_enet1 = enet1.fit(X_train, y_train)\n\n# Prediction\ny_pred_train_enet1 = enet1.predict(X_train)\ny_pred_test_enet1 = enet1.predict(X_test)\n\n# Accuracy Score\nprint('Training accuracy : {}\\n'.format(r2_score(y_train, y_pred_train_enet1).round(5)))\nprint('Testing accuracy : {}'.format(r2_score(y_test, y_pred_test_enet1).round(5)))","3b37b7b1":"**Models**\n\nNow we are going to use regularized linear regression models from the scikit learn module. I'm going to try both l_1(Lasso) and l_2(Ridge) regularization. I'll also define a function that returns the cross-validation rmse error so we can evaluate our models and pick the best tuning par","0b1b7112":"**Elastic Net Regression**","ed1cc216":"Data preprocessing:\nWe're not going to do anything fancy here:\n\nFirst I'll transform the skewed numeric features by taking log(feature + 1) - this will make the features more normal\n\nCreate Dummy variables for the categorical features\n\nReplace the numeric missing values (NaN's) with the mean of their respective columns","c64e3b8b":"Now Let' try out the **Lasso model**. \n\nWe will do a slightly different approach here and use the built in Lasso CV to figure out the best alpha for us. For some reason the alphas in Lasso CV are really the inverse or the alphas in Ridge.","5c0df075":"The main tuning parameter for the Ridge model is alpha - a regularization parameter that measures how flexible our model is. The higher the regularization the less prone our model will be to overfit. However it will also lose flexibility and might not capture all of the signal in the data.","4d1f0fe8":"Good job Lasso. One thing to note here however is that the features selected are not necessarily the \"correct\" ones - especially since there are a lot of collinear features in this dataset. One idea to try here is run Lasso a few times on boostrapped samples and see how stable the feature selection is."}}