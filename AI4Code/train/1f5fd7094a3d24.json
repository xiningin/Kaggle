{"cell_type":{"c4e64b11":"code","2a621002":"code","ef61616b":"code","78bc5e53":"code","eb2c2724":"code","07c6a8bc":"code","6ef958f4":"code","93117678":"code","c2ff53a6":"code","3f14e75a":"code","442b5a60":"code","a38814d8":"code","be5d3ea0":"code","c0c7a1e9":"markdown","f1de4e4d":"markdown","f53f5709":"markdown","e82a8e16":"markdown","e4a1d709":"markdown","751ef58c":"markdown"},"source":{"c4e64b11":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a621002":"## Install NeMo\nBRANCH = 'main'\n!python -m pip install git+https:\/\/github.com\/NVIDIA\/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\nprint(\"Finished installing nemo !\")","ef61616b":"from nemo.collections.asr.metrics.wer import word_error_rate\ndef evaluate_model(ground_truth,model_transcript):\n    with open(ground_truth, 'r') as f:\n        ground_truth_txt = f.readlines()\n        ground_truth_txt = [text.replace(\"\\n\", \"\") for text in ground_truth_txt]\n\n    with open(model_transcript, 'r') as f:\n        transcription_txt = f.readlines()\n        transcription_txt = [text.replace(\"\\n\", \"\") for text in transcription_txt]\n    cer = word_error_rate(transcription_txt, ground_truth_txt, use_cer=True)\n    wer = word_error_rate(transcription_txt, ground_truth_txt, use_cer=False)\n    print(\"Finished computing metrics !\")\n    print(f\"CER : {cer * 100:0.4f}%\")\n    print(f\"WER : {wer * 100:0.4f}%\")","78bc5e53":"# Helper function\nimport contextlib\nimport torch\nimport os\nimport nemo.collections.asr as nemo_asr\n# Helper for torch amp autocast\nif torch.cuda.is_available():\n    autocast = torch.cuda.amp.autocast\nelse:\n    @contextlib.contextmanager\n    def autocast():\n        print(\"AMP was not available, using FP32!\")\n        yield\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","eb2c2724":"%%time\ncitrinet_256_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\"stt_en_citrinet_256\", map_location=device)\ncitrinet_256_model = citrinet_256_model.to(device)\naudio_path = \"\/kaggle\/input\/podcastdata\/raw_audio_processed.wav\"\ntranscribed_filepath = f\"\/kaggle\/working\/citrinet256.txt\"\nif os.path.exists(transcribed_filepath):\n  print(f\"File already exists, delete {transcribed_filepath} manually before re-transcribing the audio !\")\n\nelse:\n    with autocast():\n        transcript = citrinet_256_model.transcribe([audio_path], batch_size=1)[0]\nwith open(transcribed_filepath, 'w', encoding='utf-8') as f:\n    f.write(f\"{transcript}\\n\")","07c6a8bc":"evaluate_model('\/kaggle\/input\/podcastdata\/ground_truth.txt','\/kaggle\/working\/citrinet256.txt')","6ef958f4":"\ncitrinet_512_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\"stt_en_citrinet_512\", map_location=device)\ncitrinet_512_model = citrinet_512_model.to(device)\naudio_path = \"\/kaggle\/input\/podcastdata\/raw_audio_processed.wav\"\ntranscribed_filepath = f\"\/kaggle\/working\/citrinet512.txt\"\nif os.path.exists(transcribed_filepath):\n  print(f\"File already exists, delete {transcribed_filepath} manually before re-transcribing the audio !\")\n\nelse:\n    with autocast():\n        transcript = citrinet_512_model.transcribe([audio_path], batch_size=1)[0]\nwith open(transcribed_filepath, 'w', encoding='utf-8') as f:\n    f.write(f\"{transcript}\\n\")","93117678":"evaluate_model('\/kaggle\/input\/podcastdata\/ground_truth.txt','\/kaggle\/working\/citrinet512.txt')","c2ff53a6":"\ncitrinet_1024_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\"stt_en_citrinet_1024\", map_location=device)\ncitrinet_1024_model = citrinet_1024_model.to(device)\naudio_path = \"\/kaggle\/input\/podcastdata\/raw_audio_processed.wav\"\ntranscribed_filepath = f\"\/kaggle\/working\/citrinet1024.txt\"\nif os.path.exists(transcribed_filepath):\n  print(f\"File already exists, delete {transcribed_filepath} manually before re-transcribing the audio !\")\n\nelse:\n    with autocast():\n        transcript = citrinet_1024_model.transcribe([audio_path], batch_size=1)[0]\nwith open(transcribed_filepath, 'w', encoding='utf-8') as f:\n    f.write(f\"{transcript}\\n\")","3f14e75a":"evaluate_model('\/kaggle\/input\/podcastdata\/ground_truth.txt','\/kaggle\/working\/citrinet1024.txt')","442b5a60":"! pip install -q transformers\nimport librosa\nimport torch\nfrom transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n!git clone https:\/\/huggingface.co\/facebook\/wav2vec2-large-960h-lv60-self","a38814d8":"#load model and tokenizer\ntokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook\/wav2vec2-base-960h\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook\/wav2vec2-base-960h\")","be5d3ea0":"#load any audio file of your choice\nspeech, rate = librosa.load(\"\/kaggle\/input\/podcastdata\/raw_audio_processed.wav\",sr=16000)\n\ninput_values = tokenizer(speech, return_tensors = 'pt').input_values\n#Store logits (non-normalized predictions)\nlogits = model(input_values).logits\n\n\n#Store predicted id's\npredicted_ids = torch.argmax(logits, dim =-1)\n#decode the audio to generate text\ntranscriptions = tokenizer.decode(predicted_ids[0])\nprint(transcriptions)","c0c7a1e9":"In this notebook we will comapre the performance of different Automatic Speech Recognition models on large audio files on the basis of character error rate(CER) and word error rate(WER). The data for evluation is obtained from https:\/\/colab.research.google.com\/gist\/titu1994\/a44fffd459236988ee52079ff8be1d2e\/long-audio-transcription-citrinet.ipynb?pli=1#scrollTo=rZITgro3DC_v  \nData contents:\na) raw_audio_processed.wav\nb) ground_truth.txt","f1de4e4d":"# **1. Citrinet 256 (9.8 M parameters)**","f53f5709":"# **Citrinet 1024 (142 M parameters)**","e82a8e16":"# **2. Citrinet 512 (38 M parameters)**","e4a1d709":"**Evaluation function**","751ef58c":"# **Transformers (Not Working)**"}}