{"cell_type":{"15429c73":"code","3d5e37a1":"code","789a3200":"code","3bd19be3":"code","ba164a9b":"code","fb764f92":"code","8ac70c68":"code","515c7bcc":"code","44392ff8":"code","dba97a4d":"code","4e0dbe67":"code","156d76ae":"code","6977463d":"code","27195eac":"code","c6d53dbd":"code","3c5837b0":"code","7ded9b82":"code","325752b9":"code","9e7d41f3":"code","7b0d0165":"code","4c92e68b":"code","0f4e6ab9":"code","cfbecffc":"code","f27516aa":"code","9f3e4b71":"code","0b3561ec":"markdown","105ebe5a":"markdown","d25cab5f":"markdown","ace09049":"markdown","92b1ca64":"markdown"},"source":{"15429c73":"#import\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport torch.utils.data","3d5e37a1":"# device configration\n\ndevice= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nprint( \"Device :\", device)","789a3200":"# read images\n# load to array\n\ndef read_images (path, num_img):\n    array= np.zeros([num_img,64*32])\n    \n    i=0\n    for img in os.listdir(path):\n        img_path= path + \"\/\" + img\n        img= Image.open(img_path, mode=\"r\") #fotograf\u0131 \"r\" oku\n        data= np.asarray(img, dtype= \"uint8\") # fotograf\u0131 uint8 \u00e7evirmek i\u00e7in\n        data= data.flatten()\n        array[i,:]= data  #t\u00fcm sutunlara \"i\" yi yazd\u0131r\n        i +=1\n    return array","3bd19be3":"#read train negative image\n\ntrain_negative_path= r\"..\/input\/lsi-far-infrared-pedestrian-dataset\/LSIFIR\/Classification\/Train\/neg\"\nnum_train_negative_img= 43390\ntrain_negative_array= read_images(train_negative_path, num_train_negative_img)","ba164a9b":"#from numpy array to torch array\n\nx_train_negative_tensor= torch.from_numpy(train_negative_array)\nprint(\"x_train_negative_tensor size :\", x_train_negative_tensor.size())","fb764f92":"# y_train_neg_tensor\ny_train_negative_tensor= torch.zeros(num_train_negative_img, dtype=torch.long)  # \"0\" ile etiketliyoruz\nprint(\"y_train_neg_tensor size :\", y_train_negative_tensor.size())","8ac70c68":"#read train pozitive image\n\ntrain_positive_path= r\"..\/input\/lsi-far-infrared-pedestrian-dataset\/LSIFIR\/Classification\/Train\/pos\"\nnum_train_positive_img= 10208\ntrain_positive_array= read_images(train_positive_path, num_train_positive_img)","515c7bcc":"#from numpy array to torch array\n\nx_train_positive_tensor= torch.from_numpy(train_positive_array)\nprint(\"x_train_positive_tensor size :\", x_train_positive_tensor.size())\n","44392ff8":"# y_train_neg_tensor\ny_train_positive_tensor= torch.ones(num_train_positive_img, dtype=torch.long) # \"1\" ile etiketliyoruz\nprint(\"y_train_pos_tensor size :\", y_train_positive_tensor.size())","dba97a4d":"#Concat Train\n\n# x_train ve y_train verilerini birle\u015ftir.\n\nx_train= torch.cat((x_train_negative_tensor,x_train_positive_tensor),0)\ny_train= torch.cat((y_train_negative_tensor,y_train_positive_tensor),0)\n\nprint(\"x_train:\",x_train.size() )\nprint(\"y_train:\",y_train.size() )","4e0dbe67":"#read test negative image\n\ntest_negative_path= r\"..\/input\/lsi-far-infrared-pedestrian-dataset\/LSIFIR\/Classification\/Test\/neg\"\nnum_test_negative_img= 22050\ntest_negative_array= read_images(test_negative_path, num_test_negative_img)","156d76ae":"#from numpy array to torch array\n\nx_test_negative_tensor= torch.from_numpy(test_negative_array)\nprint(\"x_test_negative_tensor size :\", x_test_negative_tensor.size())","6977463d":"# y_test_neg_tensor\ny_test_negative_tensor= torch.zeros(num_test_negative_img, dtype=torch.long)\nprint(\"y_test_negative_tensor size :\", y_test_negative_tensor.size())","27195eac":"#read test pozitive image\n\ntest_positive_path= r\"..\/input\/lsi-far-infrared-pedestrian-dataset\/LSIFIR\/Classification\/Test\/pos\"\nnum_test_positive_img= 5944\ntest_positive_array= read_images(test_positive_path, num_test_positive_img)","c6d53dbd":"#from numpy array to torch array\n\nx_test_positive_tensor= torch.from_numpy(test_positive_array)\nprint(\"x_test_positive_tensor size :\", x_test_positive_tensor.size())","3c5837b0":"# y_test_neg_tensor\ny_test_positive_tensor= torch.ones(num_test_positive_img, dtype=torch.long)\nprint(\"y_test_positive_tensor size :\", y_test_positive_tensor.size())","7ded9b82":"#Concat Test\nx_test= torch.cat((x_test_negative_tensor,x_test_positive_tensor),0)\ny_test= torch.cat((y_test_negative_tensor,y_test_positive_tensor),0)\n\nprint(\"x_test:\",x_test.size() )\nprint(\"y_test:\",y_test.size() )","325752b9":"#visualize\nplt.subplot(1,2,1)\nplt.imshow(x_train[35000,:].reshape(64,32))\n\nplt.subplot(1,2,2)\nplt.imshow(x_train[5000,:].reshape(64,32), cmap=\"gray\")","9e7d41f3":"#CNN\n#hyperparameter\n\nnum_epochs= 100\nnum_classes= 2\nbatch_size= 8933\nlearning_rate=0.0001\n","7b0d0165":"# CNN artitecture\n\nclass Net(nn.Module):\n    \n    def __init__(self):\n        \n        super(Net,self).__init__()\n        self.conv1= nn.Conv2d(1,10,5)  # 1-input, 10-output, 5-conv boyutu 5x5\n        self.pool= nn.MaxPool2d(2,2) # max pooling (2x2)\n        self.conv2= nn.Conv2d(10,16,5) # 10-input, 16-output, 5-conv boyutu 5x5\n        self.fc1=nn.Linear(16*13*5,520)   #full connected layers (input, output)\n        self.fc2=nn.Linear(520,130)          \n        self.fc3=nn.Linear(130,num_classes)\n        \n    \n    def forward(self,x):\n        \n        x= self.pool(F.relu(self.conv1(x))) #convolutional Layer (i\u00e7erde convolutional layer, relu aktivasyon fonksiyonu, pooling)\n        x= self.pool(F.relu(self.conv2(x))) #convolutional Layer\n        \n        x= x.view(-1,16*13*5)  #flatten \"-1\"\n         \n        x= F.relu(self.fc1(x))\n        x= F.relu(self.fc2(x))\n        x= self.fc3(x)\n        \n        return x       \n        \n        pass\n    ","4c92e68b":"# x_train ve y_train'i birle\u015ftir\n\ntrain= torch.utils.data.TensorDataset(x_train, y_train) #train datasetlerini birle\u015ftir \ntrainloader= torch.utils.data.DataLoader(train, batch_size= batch_size, shuffle= True)  # tensor\u00fc dataya \u00e7evir.\n\n# x_test ve y_test'i birle\u015ftir\n\ntest= torch.utils.data.TensorDataset(x_test, y_test) #test datasetlerini birle\u015ftir \ntestloader= torch.utils.data.DataLoader(test, batch_size= batch_size, shuffle= False) # tensor\u00fc dataya \u00e7evir.","0f4e6ab9":"#CNN \n\nnet= Net()  # GPU varsa ve GPU ile \u00e7al\u0131\u015ft\u0131rmak isteniyorsa \"net= Net().to(device)\"","cfbecffc":"#Loss and optimizer\n\ncriterion= nn.CrossEntropyLoss()\n\nimport torch.optim as optim\n\noptimizer= optim.SGD(net.parameters(), lr=learning_rate, momentum=0.8) # SGD Stochastic Gradient Descent,  momentum SGD h\u0131zlanma parametresi\n\n","f27516aa":"# training\n\nstart= time.time()\n\ntrain_acc= []\ntest_acc= []\nloss_list= []\nepochs= []\n\nfor epoch in range(num_epochs):\n    epochs.append(epoch)\n    for i, data in enumerate(trainloader,0):\n        \n        inputs, labels= data\n        inputs= inputs.view(batch_size, 1,64, 32) #reshaping\n        inputs= inputs.float() #float\n        \n        \n        # zero gradient\n        \n        optimizer.zero_grad()\n        \n        #forward\n        outputs= net(inputs)\n        \n        #loss\n        loss= criterion(outputs, labels)\n        \n        # back_propagation\n        loss.backward()\n        \n        #uptade weight\n        optimizer.step()\n        \n    #test\n    \n    correct = 0\n    total= 0\n    with torch.no_grad():    # gradient descenti durdur, e\u011fitme\n        for data in testloader:\n            images, labels= data\n            #images= torch.utils.data.TensorDataset(images)\n            images = images.view(images.size(0), 1, 64, 32)\n            images= images.float()\n            \n            outputs = net(images)\n            _, predicted= torch.max(outputs.data,1)\n            \n            total += labels.size(0)\n            correct += (predicted== labels).sum().item()  #integer e \u00e7evirebilmek i\u00e7in \"item()\" metodu\"\n    \n    acc1= 100*correct\/total\n    test_acc.append(acc1)\n\n    #train\n    \n    correct = 0\n    total= 0\n    with torch.no_grad():\n        for data in trainloader:\n            images, labels= data\n            \n            \n            images = images.view(images.size(0), 1, 64, 32)\n            images= images.float()\n            \n            outputs = net(images)\n            _, predicted= torch.max(outputs.data,1)\n            \n            total += labels.size(0)\n            correct += (predicted== labels).sum().item()\n    \n    acc2= 100*correct\/total\n    train_acc.append(acc2)\n    print(epoch,\"accurcy train :\", acc2)\n    print(epoch,\"accurcy test :\", acc1)\n\nprint(\"train is done\")\n\n\n\n\nend= time.time()\n\nprocess_time= (end-start)\/60\n\nprint(\"Process time :\", process_time)","9f3e4b71":"epochs= []\nfor i in range(num_epochs):\n    epochs.append(i)\n    \nplt.plot(epochs,train_acc, label=\"Train\")\nplt.plot(epochs,test_acc, label=\"Test\")\nplt.title(\"Train-Test Accuracy\")\nplt.xlabel(\"Number of Epochs\")\nplt.xlabel(\"Accuracy\")\nplt.legend()\nplt.show","0b3561ec":"# Train - Test\n\n**Visualize**","105ebe5a":"**TRAIN Dataset**","d25cab5f":"# Loading IR Pedestrian dataset","ace09049":"**TEST dataset**","92b1ca64":"# Convolutional Neural Network "}}