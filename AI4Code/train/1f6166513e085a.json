{"cell_type":{"d9b65e44":"code","254f89c8":"code","c47d2654":"code","e216eec8":"code","a42b1df9":"code","c8aed076":"code","6b27dc27":"code","6e87e792":"code","55ed9cfe":"code","78e1ac4c":"code","916f53b4":"markdown"},"source":{"d9b65e44":"import numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport glob\n\nimport os\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm_notebook","254f89c8":"def show_cadence(filename: str) -> None:\n    plt.figure(figsize=(16, 10))\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(6, 1, i + 1)\n#         if i == 0:\n#             plt.title(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n        plt.imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        plt.xticks([])\n    plt.show()","c47d2654":"y = pd.read_csv('\/kaggle\/input\/seti-breakthrough-listen\/train_labels.csv')","e216eec8":"y.shape","a42b1df9":"y.sort_values(by = 'id')","c8aed076":"train_paths = sorted(glob.glob('\/kaggle\/input\/seti-breakthrough-listen\/train\/*\/*'),key = lambda x:x.split('\/')[-1])","6b27dc27":"# Check if the paths and df match\n# pd.Series(train_paths).apply(lambda x : x.split('\/')[-1].split('.')[0]) == y['id']","6e87e792":"y['paths'] = train_paths","55ed9cfe":"show_cadence(train_paths[0])","78e1ac4c":"# you'll run out of ram after 40% of the total data is loaded,so it would be best to load batches in torch or tf\ntrain = [Parallel(n_jobs=-1)(delayed(np.load)(filename) for filename in tqdm_notebook(train_paths))]","916f53b4":"* My reccomendation for this data is finetuning of transfer learning, particulary EfficientNet.\n* EfficientNet can be imported from tf and for torch can be gotten from the module timm. \n* Weights for models in either framework can be added using the \"Add data\" button, they can be custom (ones you've generated) or preexisting. "}}