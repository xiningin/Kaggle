{"cell_type":{"723406dc":"code","eae97bdf":"code","e6b10612":"code","e4c0e83c":"code","86067e8f":"code","e761c987":"code","0877e1ca":"code","fe661011":"code","bd1413d8":"code","dd5da171":"code","d1af04ed":"code","231ee14e":"code","00778808":"code","063c4e37":"code","193cc54d":"code","66f5b372":"code","6679af5a":"code","17e422e8":"code","b1f51569":"code","8a52a096":"code","95ca841e":"code","e9ccdb3a":"code","e125edcb":"code","94b5bef7":"markdown","75a5bd30":"markdown","db842cf5":"markdown","5de9bcf0":"markdown","62f45da4":"markdown","27f0e18d":"markdown"},"source":{"723406dc":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","eae97bdf":"df= pd.read_csv('..\/input\/train.csv')\ndf.head()","e6b10612":"df.columns","e4c0e83c":"sns.distplot(df['SalePrice'])","86067e8f":"print(\"Skewness: %f\" % df['SalePrice'].skew())\nprint(\"mean: %f\" % df['SalePrice'].mean())\nprint(\"median: %f\" % df['SalePrice'].median())","e761c987":"#saleprice correlation matrix\n#number of variables for heatmap\nk = 6\ncorrmat = df.corr()\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","0877e1ca":"data = pd.concat([df['SalePrice'], df['OverallQual']], axis=1)\nsns.boxenplot(x='OverallQual', y='SalePrice',data=data)","fe661011":"data = pd.concat([df['SalePrice'], df['GrLivArea']], axis=1)\nsns.regplot(x='GrLivArea', y='SalePrice',data=data);","bd1413d8":"data = pd.concat([df['SalePrice'], df['GarageCars']], axis=1)\nsns.boxenplot(x='GarageCars', y='SalePrice',data=data)","dd5da171":"data = pd.concat([df['SalePrice'], df['TotalBsmtSF']], axis=1)\nsns.regplot(x='TotalBsmtSF', y='SalePrice', data=data);","d1af04ed":"df_final=df[['OverallQual','GrLivArea','GarageCars','TotalBsmtSF','SalePrice']]\ndf_final","231ee14e":"#df_final_2=df[['LotArea','OverallQual','OverallCond','TotalBsmtSF','FullBath','HalfBath','BedroomAbvGr','TotRmsAbvGrd','Fireplaces','GarageArea','SalePrice']]\n","00778808":"missing_data = df_final.isnull().sum().sort_values(ascending=False)\nmissing_data","063c4e37":"dataset=df_final.values\ndataset","193cc54d":"X=df_final.iloc[:,0:4]\ny=dataset[:,4]\ny","66f5b372":"from sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler()\nX_scale = min_max_scaler.fit_transform(X)\nX_scale","6679af5a":"test=pd.read_csv('..\/input\/test.csv')\ntest.head()","17e422e8":"test_final=test[['OverallQual','GrLivArea','GarageCars','TotalBsmtSF']]\ntest_final.head()","b1f51569":"test_scale = min_max_scaler.fit_transform(test_final)\ntest_scale","8a52a096":"print(X_scale.shape, y.shape,test_final.shape)","95ca841e":"from xgboost import XGBRegressor\n\nmy_model = XGBRegressor()\n# Add silent=True to avoid printing out updates with each cycle\nmy_model.fit(X_scale, y, verbose=False)","e9ccdb3a":"predictions = my_model.predict(test_scale)\nmy_model.score(X_scale,y)","e125edcb":"my_submission = pd.DataFrame({'Id':test.Id, 'SalePrice': predictions})\nmy_submission.to_csv('submission.csv',index = False)","94b5bef7":"#### build and fit a model ","75a5bd30":"These are the variables most correlated with 'SalePrice'. My thoughts on this:\n\n- 'OverallQual', 'GrLivArea' and 'TotalBsmtSF' are strongly correlated with 'SalePrice'. Check!\n- 'GarageCars' and 'GarageArea' are also some of the most strongly correlated variables. we just need one of these variables in our analysis (we can keep 'GarageCars' since its correlation with 'SalePrice' is higher).","db842cf5":"# Missing data\n\nImportant questions when thinking about missing data:\n\n* How prevalent is the missing data?\n* Is missing data random or does it have a pattern?\n\nThe answer to these questions is important for practical reasons because missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis. Moreover, from a substantive perspective, we need to ensure that the missing data process is not biased and hidding an inconvenient truth.","5de9bcf0":"#### Split the data into independent (X) and dependent(Y) data sets. The independent data set contains the features to train on and the dependent data set contains the target.","62f45da4":"#### In the curve of a distribution,it has a longer tail so the sale's price has positive Skewness and The mean of positively skewed data will be greater than the median.","27f0e18d":"### we have no missing Data"}}