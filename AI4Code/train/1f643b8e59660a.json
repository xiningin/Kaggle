{"cell_type":{"fb3a025d":"code","917ad906":"code","6a75afa9":"code","2659b94b":"code","2686c93d":"code","db5fc1ca":"code","8c66ece7":"code","d0428ffd":"code","fce62641":"code","e6b6a0d9":"code","33e775d2":"code","fc846634":"code","e6bbed2a":"code","b476904a":"code","165e7a74":"code","990a614f":"code","27a330f5":"code","a1031755":"code","344c425f":"code","8e483bc5":"code","e1802d1b":"code","96f227b4":"code","0264d149":"code","df30d98d":"code","7f56264a":"code","871d6cb3":"code","df321f21":"code","7b44488f":"code","0ee89191":"code","a1522762":"code","bbd095ec":"markdown","f453f3e5":"markdown","04f7f9fe":"markdown","de4623bc":"markdown","5fa846e2":"markdown","9865be9b":"markdown","f894ce05":"markdown","42e6facc":"markdown","3c96c32e":"markdown","c5581f64":"markdown","550359a4":"markdown","fe90ef85":"markdown","557eac09":"markdown","0c018504":"markdown","2cf98e89":"markdown","2025fcd2":"markdown","e6541e6d":"markdown","1f6ae4b8":"markdown","e56f5916":"markdown","859ee53d":"markdown","e391df0f":"markdown","9425ac3c":"markdown","db222410":"markdown","277e90c7":"markdown","a18bb08a":"markdown","6a24d496":"markdown","43cba987":"markdown","0f0502a6":"markdown","9343d694":"markdown","25131507":"markdown","f47dad41":"markdown","a2aafd53":"markdown","37b88183":"markdown","3fd63ad3":"markdown","868d1f75":"markdown","de05ab45":"markdown","5e5437b0":"markdown","cdb86755":"markdown","1acc7ae3":"markdown","ac197433":"markdown","552fd841":"markdown","47373ddc":"markdown","54319847":"markdown","56868cbb":"markdown"},"source":{"fb3a025d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","917ad906":"#Importing  the  dataset using pandas \ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","6a75afa9":"#Checking the first 5 columns in the train dataset\nprint(train.head())\nprint('Shape of the train is {}'.format(train.shape))\nprint('Shape of the test is {}'.format(test.shape))","2659b94b":"# Visualising the label using the  bar plot to get the  idea of the  distribution of the target feature\nimport seaborn as sns\nsns.countplot(train['label'])","2686c93d":"#Breaking the training dataset into matrix of independent features and dependent feature vector\nX = train.drop('label',axis = 1)\ny = train.label","db5fc1ca":"# Let's check the shape \nprint('Shape of the X is {}'.format(X.shape))\nprint(f'Shape of y is {y.shape}')","8c66ece7":"#Using the matplotlib to display the image and the  label of the  image \nimport matplotlib.pyplot as plt\nplt.imshow(X.values.reshape(-1,28,28)[3],cmap = 'gray')\nplt.show()\nprint(y[3])","d0428ffd":"#Reshaping the size of the image to 28 x 28 pixels\nX = X.values.reshape(-1,28,28,1)","fce62641":"#Rechecking the shape of the image\nprint('Shape of the X is {}'.format(X.shape))","e6b6a0d9":"#Converting the dependent feature vector into one hot  encoding \nfrom keras.utils import to_categorical\ny = to_categorical(y)","33e775d2":"#Dividing the dataset into training and validation set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state = 123)","fc846634":"#Model building using keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten,MaxPooling2D,Dropout\nfrom keras.layers.convolutional  import Conv2D\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32,kernel_size = (3,3),activation = 'relu',input_shape = (28,28,1)))\nmodel.add(Conv2D(64,kernel_size = (3,3),activation = 'relu'))\nmodel.add(Flatten())\nmodel.add(Dense(10,activation = 'softmax'))\n","e6bbed2a":"#Compiling  the  model\nmodel.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])","b476904a":"#Training\nhistory = model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs = 20)","165e7a74":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs   = range(len(acc)) \n\n# Plotting training and validation accuracy per epoch\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\n# Plotting training and validation loss per epoch\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.legend()\nplt.title('Training and validation loss')","990a614f":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","27a330f5":"# Compile the model\n#from keras.optimizers import RMSprop\n#optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = 'Adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","a1031755":"#Data agumentation to preventing the overfitting\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.1,  \n        width_shift_range=0.1, \n        height_shift_range=0.1,  \n        horizontal_flip=False,  \n        vertical_flip=False)  \n\n\ndatagen.fit(X_train)","344c425f":"# Set a learning rate annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nbatch_size = 256\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = 30, validation_data = (X_test,y_test),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","8e483bc5":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs   = range(len(acc)) \n\n# Diffining Figure\nfig = plt.figure(figsize=(20,7))\n\n#Subplot 1 (For Accuracy)\nfig.add_subplot(121)\n\nplt.plot(epochs, acc,label = 'Accuracy')\nplt.plot(epochs, val_acc,label = 'Validation Accuracy')\nplt.title(\"Accuracy Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Accuracy\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n#Subplot 2 (For Loss)\nfig.add_subplot(122)\nplt.plot(epochs, loss,label = 'Loss')\nplt.plot(epochs, val_loss,label = 'Validation Loss')\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\nplt.show()","e1802d1b":"#Reshaping the test dataset\ntest = test.values.reshape(-1,28,28,1)","96f227b4":"#Predicting the test using our model\npredictions = model.predict_classes(test, verbose=1)","0264d149":"predictions","df30d98d":"#Converting our predictions into dataframe\nprediction = pd.DataFrame({\"ImageId\":list(range(1,len(predictions)+1)),\"Label\":predictions})","7f56264a":"#Finally exporting to the csv file as the output\nprediction.to_csv('kaggle_submission.csv',index=False,header=True)\nprediction","871d6cb3":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten,MaxPooling2D,Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.layers.convolutional  import Conv2D\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(10,activation='softmax'))\n\n","df321f21":"#Compiling the model\nmodel.compile(RMSprop(lr=0.001,rho=0.9),loss='categorical_crossentropy',metrics=['accuracy'])","7b44488f":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=False,\n                                   fill_mode='nearest')\ntrain_datagen.fit(X_train)\ntrain_generator = train_datagen.flow(X_train,y_train,batch_size=128)\n","0ee89191":"from keras.callbacks import ReduceLROnPlateau,EarlyStopping\n\nearlystop = EarlyStopping(monitor='val_loss',patience=2,verbose=1)\nlearning_reduce = ReduceLROnPlateau(patience=2,monitor=\"val_acc\",verbose=1,min_lr=0.00001,factor=0.5)\n#callbacks = [earlystop,learning_reduce]\ncallbacks = [learning_reduce]\nhistory = model.fit_generator(train_generator,epochs=30,verbose=1,validation_data=(X_test,y_test),callbacks=callbacks)","a1522762":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs   = range(len(acc)) \n\n# Diffining Figure\nfig = plt.figure(figsize=(20,7))\n\n#Subplot 1 (For Accuracy)\nfig.add_subplot(121)\n\nplt.plot(epochs, acc,label = 'Accuracy')\nplt.plot(epochs, val_acc,label = 'Validation Accuracy')\nplt.title(\"Accuracy Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Accuracy\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\n#Subplot 2 (For Loss)\nfig.add_subplot(122)\nplt.plot(epochs, loss,label = 'Loss')\nplt.plot(epochs, val_loss,label = 'Validation Loss')\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\n\nplt.show()","bbd095ec":"<a id = 'conclude'><\/a>\n## Conclusion\n* That's all Folks\n* I highly encourage you all to try building your own model with the intution you have developed with the notebook\n* All the best","f453f3e5":"<p>We will let our model learn on the training set and validate it's performance with the validation set<\/p>\nWe are spliting the train set in two parts : (20%) of the train dataset as the validation set which the model is evaluated and the rest (80%) is used to train the model.","04f7f9fe":"Clearly, this image of '4' and it is labelled as 4","de4623bc":"One hot encoding is needed as the model expects each of the labels to be in array of 10 elements in which only one of the elements = 1 and rest of the elements = 0<br>\nLabels are 10 digits numbers from 0 to 9. It is  encoded to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]","5fa846e2":"<a id = 'compile3'><\/a>\n## Compiling the Model","9865be9b":"<a id = 'agument3'><\/a>\n## Data Agumentation","f894ce05":"<a id= 'predict'><\/a>\n## Predicting the test data","42e6facc":"* <p>Here the distribution of the dependent variable seems balanced which  is good for  our model<\/p>\n* <p>It's not always the  case when  you  will get balanced dataset<\/p>\n* <p>In case of unbalanced dataset, we will have to use the sampling techniques but that's not the case with the dataset<\/p>","3c96c32e":"<a id='compile1'><\/a>\n## Compiling Model","c5581f64":"<H1 align = 'center'>Digit Recognization - CNN by using Keras<\/H1>\n<img src = 'https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/02\/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png' alt = 'Digit Recognization'><\/img>","550359a4":"<a id = 'perform3'><\/a>\n# Model performance\n* Here the accuracy is 99.11% which is not bad, but this way we understand we always don't need a very complex and deep neural network\n* The neural network architechture is always based on the intution of the dataset it is always important to learn the dataset throughly before creating a model","fe90ef85":"In order to make the optimizer converge faster and closest to the global minimum of the loss function, we will use an annealing method of the learning rate (LR).\n\nThe LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima.\n\nIts better to have a decreasing learning rate during the training to reach efficiently the global minimum of the loss function.\n\nTo keep the advantage of the fast computation time with a high LR, i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).\n\nWith the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs.","557eac09":"<a id = 'prepare'><\/a>\n# Data preparation","0c018504":"<a id ='visualise'><\/a>\n## Visualisation","2cf98e89":"<a id=\"library\"><\/a>\n<H2>Importing Libraries<\/H2>\n<H3>In this notebook the main libraries we will import are<\/H3>\n<ol>\n    <li><B>Pandas<\/B>:For handling the CSV files<\/li>\n    <li><B>Numpy<\/B>:Numerical calculations<\/li>\n    <li><B>Matplotlib\/Seaborn<\/B>:Visualisation<\/li>\n    <li><B>Keras<\/B>: Building  the CNN model and prediction<\/li>\n<\/ol>\n<p>I will import the libraries as it is used rather than just importing  in the  start , this will help you understand where the specific module is used in the notebook<\/p>","2025fcd2":"<a id = 'model1'><\/a>\n# Model I","e6541e6d":"<a id = 'Bmodel2'><\/a>\n## Building the Model","1f6ae4b8":"* The model type that we are using is sequential. \n* It is one of the easiest way to build a CNN model in keras. It helps to build the in successive layers  with the add() function.\n* The first layer is the input of the shape which is 28 x 28 x 1, in this case\n* Model is started with Conv2D layers. This will enable the convulation layers to deal with our input images which are seen as 2D matrices\n* The nodes used in the layers are 32 and 64, these numbers are choosen  arbitarily  and can be adjusted according to the size of the dataset\n* Kernel size is 3, which is 3x3 filter matrix for extracting the information from the image\n* Activation function used here is Relu in between the layers, this activation function is widely used in the neural network and is known for the speed and output in the neural nets. \n* Next there is flatten layer which is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n* In the end  there is dense layer which  is used for output layer, the activation used in the last layer is softmax, softmax returns the prediction with the maximum probablity of the dependent feature\n* Once our layers are added to the model, we need to set up a score function, a loss function and an optimisation algorithm.\n* We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. \n* The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n* The metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).\n* <b>Optimizer<\/b> \u2014 It controls the learning rate. We will be using \u2018adam\u2019 optimizer. It is a very good optimizer as it utilises the perks of both Stochastic gradient and RMSprop optimizers.\n* <b>Loss function<\/b> \u2014 We will be using \u2018categorical_crossentropy\u2019 loss function. It is the most common choice for classification. A lower score corresponds to better performance.\n* <b>Metrics<\/b> \u2014 To make things easier to interpret, we will be using \u2018accuracy\u2019 metrix to see the accuracy score on the validation set while training the model.","e56f5916":"<a id = 'train3'><\/a>\n## Training the Model","859ee53d":"<a id = 'model3'><\/a>\n# Model III\nlet's go one step further and add some more add on in the model and see how it perform","e391df0f":"<a id = 'perform2'><\/a>\n##  Training performance\n* This model has definetly performed better than the previous model \n* The accuracy achived here  is 99.50%\n* Also the training and validaiton loss both are minimised which implies there is no overfitting and underfitting\n* Remember we always want just fit model, we don't need extremely perfect model","9425ac3c":"<a id=\"MNIST\"><\/a>\n## MNIST Dataset\n<p>The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n<br>\nIt is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n<\/p>","db222410":"* **Optimizer** \u2014 It controls the learning rate. We will be using \u2018adam\u2019 optimizer. It is a very good optimizer as it utilises the perks of both Stochastic gradient and RMSprop optimizers.\n* **Loss function** \u2014 We will be using \u2018categorical_crossentropy\u2019 loss function. It is the most common choice for classification. A lower score corresponds to better performance.\n* **Metrics** \u2014 To make things easier to interpret, we will be using \u2018accuracy\u2019 metrix to see the accuracy score on the validation set while training the model.","277e90c7":"<a id ='agument2'><\/a>\n## Data Agumentation","a18bb08a":"* Now we make a new sequential model for better fit to our data\n\n* The first is the convolutional (Conv2D) layer. It is like a set of learnable filters. \n* Here we are setting 32 filters for the two firsts conv2D layers and 64 filters for the two last ones. \n* Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\n* The CNN isolates the features that are useful everywhere from these transformed images (feature maps).\n\n* The second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n\n* Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n\n* 'relu' is the rectifier. The rectifier activation function is used to add non linearity to the network.\n\n* The Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\n* In the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.","6a24d496":"* The idea behind data augmentation is that we can artificially enlarge our training dataset (thus reducing overfitting) by its augmentation.\n* The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.\n<img src = 'https:\/\/cdn-images-1.medium.com\/max\/1000\/1*dJNlEc7yf93K4pjRJL55PA.png' alt = 'Image agumentation'>\n<h3>Parameters in the  data agumentation<\/h3>\n1. **rotation_range**: randomly rotate images in the range (degrees, 0 to 180) \n2. **zoom_range**: Randomly zoom image\n3. **width_shift_range**: randomly shift images horizontally (fraction of total width)\n4. **height_shift_range**: randomly shift images vertically (fraction of total height)\n5. **horizontal_flip**: randomly flip images (Can't be used in this case as it changes the digit)\n6. **vertical_flip**: randomly flip images (Can't be used in this case as it changes the digit","43cba987":"Seperating the indendent feature from the dependent feature","0f0502a6":"\n* <strong>If you liked the worked, an upvote will be nice!<\/strong>\n* <strong>Any suggestions and feedback are always welcome<\/strong>\n* <strong>If you have any doubt, let's dicuss in the comments<\/strong>","9343d694":"<a id= 'Bmodel3'><\/a>\n## Building  the Model","25131507":"<a id = 'Bmodel1'><\/a>\n## Building Model","f47dad41":"<a id=\"Introduction\"><\/a>\n## Introduction\n\n* In this dataset, I will solve the digit recognization problem\n* We will solve the problem by using CNN, I highly suggest to read as much as you can and make an intutive understanding of CNN before solving this problem\n* No matter where you look, you will find complex neural networks architechture which can be very confusing\n* Sometimes you don't need a very complex model a simple model can also do the work. \n* Our aim should be to make a better model not complex model\n* I will start with a very simple architechture and further make it complex to get better accuracy and better fitted model\n* I will explain each and everything as to why I added the component to the model and how why I took the decision to do so","a2aafd53":"# Table of Contents\n\n# Content:\n\n* [Introduction](#Introduction)\n* [MNIST Dataset](#MNIST)\n* [Importing  Libraries](#library)\n* [Loading the Dataset](#load)\n* [Visualisation](#visualise)\n* [Data Preperation](#prepare)\n* **[Model I](#model1)**\n    * [Model building](#Bmodel1)\n    * [Compiling Model](#compile1)\n    * [Training the Model](#train1)\n    * [Training Performance](#perform1)\n* **[Model II](#model2)**\n    * [Model building](#Bmodel2)\n    * [Compiling Model](#compile2)\n    * [Data Agumentation](#agument2)\n    * [Training the Model](#train2)\n    * [Training Performance](#perform2)\n    * [Predicting the test data](#predict)\n* **[Model III](#model3)**\n    * [Model building](#Bmodel3)\n    * [Compiling Model](#compile3)\n    * [Data Agumentation](#agument3)\n    * [Training the Model](#train3)\n    * [Training Performance](#perform3)\n* [Conclusion](#conclude)","37b88183":"<a id = 'compile2'><\/a>\n## Compiling the Model","3fd63ad3":"# Feedback\n* <strong>If you liked the worked, an upvote will be nice!<\/strong>\n* <strong>Any suggestions and feedback are always welcome<\/strong>\n* <strong>If you have any doubt, let's dicuss in the comments<\/strong>","868d1f75":"* Now we make a new sequential model for better fit to our data\n\n* The first is the convolutional (Conv2D) layer. It is like a set of learnable filters. \n* Here we are setting 64 filters for the two firsts conv2D layers and 28 filters for the two last ones. \n* Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters can be seen as a transformation of the image.\n\n* The CNN isolates the features that are useful everywhere from these transformed images (feature maps).\n\n* The second important layer in CNN is the pooling (MaxPool2D) layer. This layer simply acts as a downsampling filter. It looks at the 2 neighboring pixels and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. We have to choose the pooling size (i.e the area size pooled each time) more the pooling dimension is high, more the downsampling is important.\n\n* Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting.\n\n* Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n\n* 'relu' is the rectifier. The rectifier activation function is used to add non linearity to the network.\n\n* The Flatten layer is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional\/maxpool layers. It combines all the found local features of the previous convolutional layers.\n\n* In the end i used the features in two fully-connected (Dense) layers which is just artificial an neural networks (ANN) classifier. In the last layer(Dense(10,activation=\"softmax\")) the net outputs distribution of probability of each class.\n\n* We define the loss function to measure how poorly our model performs on images with known labels. It is the error rate between the oberved labels and the predicted ones. We use a specific form for categorical classifications (>2 classes) called the \"categorical_crossentropy\".\n\n* The most important function is the optimizer. This function will iteratively improve parameters (filters kernel values, weights and bias of neurons ...) in order to minimise the loss.\n\n* we have choosen the RMSprop (with default values), it is a very effective optimizer. The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. We could also have used Stochastic Gradient Descent ('sgd') optimizer, but it is slower than RMSprop.\n\n* The metric function \"accuracy\" is used is to evaluate the performance our model. This metric function is similar to the loss function, except that the results from the metric evaluation are not used when training the model (only for evaluation).","de05ab45":"* Now will fit the model to the training data and will be validated against the  validated data\n* epochs = 20\n* 1 epoch -> One iteration\/cycle of the dataset throughout the Neural Network","5e5437b0":"<a id = 'perform1'><\/a>\n## Training Performance.\n\n* Plotting the accuracy and loss of both training and validation set with each epoch to check the training performance. \n* In the accuracy graphs, there is clearly a difference in the training and validation set. \n* The model is more accurate on the training set. \n* Even though you see the model is not complex it has done a fairly well job\n* Also while  evaluating the performace of the  model also check the training and validation loss, both the loss should be as low as possible for better model\n* Let's try to max a bit more complex model by doing some add ons.","cdb86755":"<p>First, we will start with visualising the  dependent varaible distribution with the countplot<\/p>\n","1acc7ae3":"<a id = 'load'><\/a>\n## Loading the Dataset","ac197433":"<a id = 'train1'><\/a>\n## Training the model","552fd841":"<a id = 'train2'><\/a>\n## Training the Model","47373ddc":"* Dataset size 70k samples of handwritten images of which 42k is in train with the label and rest 28k is in test dataset\n* The dataset is dataframe with 784 columns which is  square of 28 this implies the size of each image is 28x28 pixels.\n* Each image has only 1 color channel, i.e., grayscale image.\n* Each pixel has value in the range of [0,255] where 0 represents black, and 255 represents white.\n* Each image has labeled from 0-9.","54319847":"Train and test images (28px x 28px) has been represented as dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n<br>\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.","56868cbb":"<a id = 'model2'><\/a>\n# Model II"}}