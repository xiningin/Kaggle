{"cell_type":{"c1c6f534":"code","dccf6152":"code","2e6aeb38":"code","8265d2f5":"code","38742679":"code","03ee4095":"code","46f02ae9":"code","8b4a272a":"code","30522581":"code","deba4d06":"code","8fdc08db":"code","fd4a57f4":"code","e621469f":"code","b425d4f3":"code","faa6db3a":"code","f9f65cbe":"code","07d632a0":"code","7c139d55":"code","7335f8d9":"code","24626874":"markdown","1b3d3b8e":"markdown","d679ca74":"markdown"},"source":{"c1c6f534":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","dccf6152":"from sklearn.feature_extraction.text import CountVectorizer\nimport collections","2e6aeb38":"data = pd.read_csv('\/kaggle\/input\/trump-tweets\/trumptweets.csv')","8265d2f5":"data.head()","38742679":"trump_tweets = data['content']","03ee4095":"string_trump = \"\"\nfor string in trump_tweets.values:\n    string_trump += string + \".\"\n ","46f02ae9":"import nltk\n\nwords = set(nltk.corpus.words.words())\n\nstring_trump = \" \".join(w for w in nltk.wordpunct_tokenize(string_trump) if w.lower() in words or not w.isalpha())","8b4a272a":"import re\nstring_trump = re.sub(r'\\W+', ' ', string_trump)","30522581":"vectorizer = CountVectorizer(min_df=0, lowercase=True)\nvectorizer.fit(trump_tweets)\ntrump_voc = vectorizer.vocabulary_","deba4d06":"for index,row in data.iterrows():\n    for word in nltk.word_tokenize(row['content']):\n        if word in trump_voc:\n            trump_voc[word] += trump_voc[word] * (row['favorites'] + 0.01)\n        ","8fdc08db":"df_trump = pd.DataFrame.from_dict(trump_voc,orient = 'index',columns=['count'])","fd4a57f4":"df_trump = df_trump.reset_index()\ndf_trump.columns = ['word','count']","e621469f":"df_trump = df_trump.sort_values('count',ascending = False)","b425d4f3":"trump_most_val_str = \"\"\nfor index,row in df_trump.iterrows():\n    if row['count'] == float(\"inf\") or row['count'] > 10**24:\n        trump_most_val_str += \" \" + row['word']","faa6db3a":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nwordcloud = WordCloud(width = 1000, height = 500).generate(trump_most_val_str)\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.savefig(\"your_file_name\"+\".png\", bbox_inches='tight')\nplt.show()\nplt.close()","f9f65cbe":"import markovify","07d632a0":"fav_tweets = \"\"\nfor index,row in data.sort_values('favorites',ascending = False).head(100).iterrows():\n    fav_tweets += row['content'] + \".\"\n    ","7c139d55":"text_model = markovify.Text(fav_tweets)","7335f8d9":"for i in range(5):\n    x = text_model.make_short_sentence(200,tries = 100)\n    print(x)","24626874":"# Generate tweets from Most liked words","1b3d3b8e":"So these are the words that are mostly used and getting likes. We see that political and economic parameters that are put into process are valuable","d679ca74":"Using favorite numbers we will asses authority value."}}