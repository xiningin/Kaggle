{"cell_type":{"a5ccb593":"code","78bc6970":"code","af13434b":"code","f20b145e":"code","8901ad36":"code","0737305a":"code","6f15a920":"code","16737131":"code","d3cbe8b3":"code","7b5517dd":"code","bccc3894":"code","cdc76a51":"code","39a515cc":"code","3af0df45":"code","695e5a68":"code","f5e9a694":"code","a3e72056":"code","036764ab":"code","e9a58123":"code","d9b6b277":"code","0e9540f3":"code","ff313b43":"code","07d1536a":"code","c36c7e20":"code","7f4817b4":"markdown","a56a4f0e":"markdown","44388110":"markdown"},"source":{"a5ccb593":"import pandas as pd\nimport numpy as np","78bc6970":"NBA = pd.read_csv(\"\/content\/all_seasons.csv\")","af13434b":"NBA.head()","f20b145e":"NBA.isnull()","8901ad36":"NBA.info()","0737305a":"#ambil colom sesuai syarat\ndf = NBA[[\"age\",\"player_height\",\"player_weight\",\"pts\",\"gp\"]]","6f15a920":"df.head()","16737131":"#membuat dataset sesuai dengan syarat diatas\ndef dataset(x):\n  if x['age']>=25 and x['player_height']>=200 and x['player_weight']>=90 and x['pts']>=10 and x['gp']>=50:\n    return 1\n  else:\n    return 0\n\ndf['keterangan']=df.apply(dataset,axis=1)","d3cbe8b3":"df.head(30)","7b5517dd":"df[df['keterangan']==1].head(100)","bccc3894":"from sklearn.preprocessing import StandardScaler\n","cdc76a51":"sc = StandardScaler()\nval= sc.fit_transform(df)","39a515cc":"#membagi dataset ke dalam training set dan test set (untuk kasus ini diambil 30% untuk test)\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df, df['keterangan'], test_size= .30)\nlen(x_train)","3af0df45":"#load machine learning\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.naive_bayes import GaussianNB","695e5a68":"sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\nsgd.fit(x_train, y_train)\ny_pred = sgd.predict(x_test)\n\nsgd.score(x_train, y_train)\n\nacc_sgd = round(sgd.score(x_train, y_train) * 100, 2)","f5e9a694":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(x_train,y_train)\ny_pred=random_forest.predict(x_test)\n\nrandom_forest.score(x_train,y_train)\nacc_random_forest=round(random_forest.score(x_train,y_train)*100,2)","a3e72056":"logreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\n\ny_pred = logreg.predict(x_test)\n\nacc_log = round(logreg.score(x_train, y_train) * 100, 2)","036764ab":"KNN = KNeighborsClassifier(n_neighbors=3)\nKNN.fit(x_train,y_train)\ny_pred = KNN.predict(x_test)\nacc_KNN = round(KNN.score(x_train,y_train)*100,2)","e9a58123":"perceptron = Perceptron()\nperceptron.fit(x_train, y_train)\n\ny_pred = perceptron.predict(x_test)\n\nacc_perceptron = round(perceptron.score(x_train, y_train) * 100, 2)","d9b6b277":"linear_svc =LinearSVC()\nlinear_svc.fit(x_train,y_train)\n\ny_pred = linear_svc.predict(x_test)\n\nacc_linear_svc = round(linear_svc.score(x_train,y_train)*100,2)","0e9540f3":"gaussian = GaussianNB() \ngaussian.fit(x_train, y_train)  \ny_pred = gaussian.predict(x_test)  \nacc_gaussian = round(gaussian.score(x_train, y_train) * 100, 2)","ff313b43":"decision_tree = DecisionTreeClassifier() \ndecision_tree.fit(x_train, y_train)  \nY_pred = decision_tree.predict(x_test)  \nacc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)","07d1536a":"results = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', \n              'Decision Tree'],\n    'Score': [acc_linear_svc, acc_KNN, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_decision_tree]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(9)","c36c7e20":"random_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 10,   \n                                       n_estimators=100, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\n\nrandom_forest.fit(x_train, y_train)\nY_prediction = random_forest.predict(x_test)\n\nrandom_forest.score(x_train, y_train)\n\nprint(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")","7f4817b4":"Disini akan mencari machine learning dengan hyperparameter untuk menentukan klasifikasi yang terbaik\n\nsumber data didapatkan dari https:\/\/www.kaggle.com\/justinas\/nba-players-data","a56a4f0e":"Ambil data dengan syarat:\n1. Umur >= 25\n2. Tinggi badan >=200\n3. Berat badan >= 90\n4. Point >= 10\n5. Gp >=50","44388110":"Standardscaler digunakan untuk menghilangkan mean dan menskalakan ke variasi. biasanya standardscaler digunakan untuk membagi data menjadi train dan test.\n\nrujukan:\n1. https:\/\/prasetyadi.name\/2019\/data-preprocessing-menggunakan-modul-python\/\n2. https:\/\/qastack.id\/datascience\/38395standardscaler-before-and-after-splitting-data"}}