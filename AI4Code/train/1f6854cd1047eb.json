{"cell_type":{"2f698e5f":"code","20f5ce29":"code","d06ad00b":"code","7f5fdba1":"code","0e383d81":"code","c7fedee0":"code","e31f0bfe":"code","79664a3f":"code","3315fcd5":"code","3e390c39":"code","e6bea32a":"code","96c013f0":"code","32f86a94":"code","f685ab62":"code","cb062e61":"code","63a4eff0":"code","7424b4c1":"code","047ed3e9":"code","47d605a8":"code","0dc95f32":"code","a493c542":"code","95f172c6":"code","9ceaef39":"code","44be6ca0":"code","a3ccc724":"code","841989e4":"code","3b18d01a":"code","b35e6ba4":"markdown","b32e1750":"markdown","d9ae8b14":"markdown","4525f695":"markdown","3e2e0a27":"markdown","89a22777":"markdown","80896c0a":"markdown","233ce0ae":"markdown"},"source":{"2f698e5f":"# load data libraries\nimport numpy as np # linear algebra library\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport zipfile # to read zip files\nfrom sklearn.model_selection import train_test_split\n\n\n# data understanding libraries\nimport matplotlib.pyplot as plt # ploting library\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\n\n\n# data preparation\nimport re\nfrom nltk.stem import PorterStemmer\n\n\n# ADS Creation\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.preprocessing import StandardScaler\n\n# Modeling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Evaluation and Model Selection\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV","20f5ce29":"pd.set_option('display.max_rows', 10000)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', -1)  # or 199\npd.set_option('display.precision',150)\npd.options.display.float_format = '{:,.3f}'.format","d06ad00b":"#unzip the files\narchive_train = zipfile.ZipFile('\/kaggle\/input\/whats-cooking\/train.json.zip')\n\n#read training json file \ntrain = pd.read_json(archive_train.read('train.json'))\n\n#output the frist 5 rows\ntrain.head()","7f5fdba1":"train_data, test_data = train_test_split(train, test_size=0.4, random_state=1)\n\ntrain_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","0e383d81":"print(\"Train set size is \",len(train_data))\nprint(\"Test set size is \",len(test_data))","c7fedee0":"train_data['ingredients_txt'] = pd.Series([' , '.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])","e31f0bfe":"ingredients = pd.Series((','.join([','.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])).split(','))\nwords = pd.Series(' '.join(ingredients).split())","79664a3f":"len(set(words))","3315fcd5":"train_data['ingredients_txt'].sample(150)","3e390c39":"ingredients = pd.Series((' '.join([','.join(row[\"ingredients\"]) for ind,row in train_data.iterrows()])).split(','))","e6bea32a":"pd.Series([s for s in ingredients if \"-\" in s]).unique()","96c013f0":"pd.Series([s for s in ingredients if any(char.isdigit() for char in s)]).unique()","32f86a94":"pd.Series([s for s in ingredients if \"\u00ae\" in s]).unique()","f685ab62":"pd.Series([s for s in ingredients if \"'\" in s]).unique()","cb062e61":"pd.Series([s for s in words if re.findall('[^a-zA-Z]',re.sub(r'[^\\w\\s]','',s))]).unique()","63a4eff0":"pd.Series([s for s in ingredients if \" oz\" in s]).unique()","7424b4c1":"stopwords = set([\"Campbell's\",\"hellmann\",\"oz\",\"M&M\",\"Paso\u00e2\u201e\u00a2\",\"I Can't Believe It's Not Butter!\u00ae\"])\nporter = PorterStemmer()\n# lancaster=LancasterStemmer()\n\ndef ret_words(ingredients):\n    ingredients_text = ' '.join(ingredients)\n    ingredients_text = ingredients_text.lower()\n    ingredients_text = ingredients_text.replace('-', '')\n    ingredients_text = ingredients_text.replace(',', ' ')\n    ingredients_text = ingredients_text.replace('\\'', '')\n    words = []\n    for word in ingredients_text.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) <= 2: continue\n        if '\u00ae' in word: continue\n        if word in stopwords: continue\n        if re.findall('[^a-zA-Z]',re.sub(r'[^\\w\\s]','',word)): continue\n        if len(word) > 0: words.append(porter.stem(re.sub(r'[^\\w\\s]','',word)))\n    return ' '.join(words)\n\ndef preprocess(df,flag):\n    # add column\n    df[\"ingredients_num\"]=df[\"ingredients\"].apply(len)\n    \n    # Remove recipes with only one Ingredient\n    if flag == 0 :\n        df = df.drop(df[df[\"ingredients_num\"]<=1].index)\n    \n    # Convert list of ingredients to string\n    df['ingredients_txt'] = df[\"ingredients\"].apply(ret_words)\n    \n    return df","047ed3e9":"train_preprocessed = preprocess(train_data,0)\ntest_preprocessed = preprocess(test_data,1)","47d605a8":"train_preprocessed.head(10)","0dc95f32":"len(set(pd.Series(' '.join([row[\"ingredients_txt\"] for ind,row in train_preprocessed.iterrows()]).split(' '))))","a493c542":"id_train, X_train, y_train = train_preprocessed['id'], train_preprocessed['ingredients_txt'], train_preprocessed['cuisine']\nid_test, X_test, y_test = test_preprocessed['id'], test_preprocessed['ingredients_txt'], test_preprocessed['cuisine']","95f172c6":"# BoW\nBoW = CountVectorizer()\n\nBoW.fit(X_train)\nCount_data = BoW.transform(X_train)\n\nBoW_X_train = pd.DataFrame(Count_data.toarray(),columns=BoW.get_feature_names())\n\nBoW_X_train","9ceaef39":"X_train.head()","44be6ca0":"BoW.fit(X_train.head())\nCount_data = BoW.transform(X_train.head())\nBoW_X_train = pd.DataFrame(Count_data.toarray(),columns=BoW.get_feature_names())\nBoW_X_train","a3ccc724":"# TFIDF\nTFIDF = TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.25, norm='l2', encoding='latin-1',\\\n                ngram_range=(1, 2), stop_words='english')\n\nTFIDF.fit(X_train)\nCount_data = TFIDF.transform(X_train)\nTFIDF_X_train = pd.DataFrame(Count_data.toarray(),columns=TFIDF.get_feature_names())\n\n\nTFIDF_X_train","841989e4":"X_train.head(5)","3b18d01a":"TFIDF = TfidfVectorizer()\nTFIDF.fit(X_train.head(5))\nCount_data = TFIDF.transform(X_train.head(5))\nTFIDF_X_train = pd.DataFrame(Count_data.toarray(),columns=TFIDF.get_feature_names())\n\n\nTFIDF_X_train","b35e6ba4":"# What's Cooking?\n\n#### before we start with the problem itself there are some questions we need to answer:\n1. What is the business question?\n2. What each row represent?\n3. What is the evaluation method?\n\n#### for this problem (and all kaggle problems) the answers to these questions is always in the problem's overview page.\n1. What is the category of a dish's cuisine given a list of its ingredients? (Supervised ML Problem)\n2. Each row represent a recipe.\n3. Submissions are evaluated on the categorization accuracy (the percent of dishes that you correctly classify).","b32e1750":"> There are only 3 columns: id, cuisine and ingredients","d9ae8b14":"What is need to be cleaned?\n- lower and upper case data.\n- punctuation\n- dashed data\n- numbers\n- non-english char","4525f695":"## ADS Creation","3e2e0a27":"### Sperate the data","89a22777":"# 2. Data Preparation\n\n## 2.1 Data Cleansing\n### First let's have another look on the ingredients text.","80896c0a":"# 1. Important imports\n### let's start by importing needed libraries.","233ce0ae":"# 2. Load Data\n### Let's load the data and have a look on it.\n1. data is provieded in a zip file, so we need to unzip it first using zipfile library.\n2. the traning\/ testing files available in json file format, to read it we use pd.read_json function.\n        we read the data into pandas dataframes which is a 2-dimensional labeled data structure with columns of\n        potentially different types. You can think of it like a spreadsheet or SQL table.\n3. to view some rows of the dataframe we use df_name.head() method which output the first 5 rows of the dataframe."}}