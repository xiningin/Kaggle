{"cell_type":{"ef56ed5a":"code","249869d4":"code","4f12f378":"code","c0a63b23":"code","4482f25f":"code","dfdd4cb4":"code","dbda4800":"code","48275ff0":"code","18a74a1f":"code","dc02d30e":"code","4731e3c6":"code","3434fbe5":"code","ce7b4c24":"code","549ad361":"code","7a59912c":"code","c9a147fb":"markdown"},"source":{"ef56ed5a":"import tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","249869d4":"## Tomato name dictionary \nnames = {'0' : 'Kumato' , '1' : 'Beefsteak'  , '2' : 'Tigerella' , '3' :'Roma' , '4' : 'Japanese black trifella' , '5' : 'yellow pear' , '6' : 'sun gold', '7' : 'green zebra' , '8' : 'Cherokee purple' , '9' : 'Oxheart' , '10' : 'blue berries' , '11' : 'San Marzano' , '12' : 'Banana legs' , '13' : 'German orange strawberry' , '14' : 'Super sweet 100'}","4f12f378":"import cv2\nimport os\n\ndef load_images_from_folder(folder):\n    images = []\n    img_class = []\n    for filename in os.listdir(folder):\n        img_class.append(int(filename[:2]) -1)\n        img = cv2.imread(os.path.join(folder,filename))\n        img = cv2.resize(img , (224,224))\n        if img is not None:\n            images.append(img)\n    return images, img_class\n\nimages , image_class = load_images_from_folder(\"..\/input\/tomato-cultivars\")","c0a63b23":"type(images) , type(image_class)","4482f25f":"images = np.array(images)\nimages.shape","dfdd4cb4":"image_class = np.array(image_class)\nimage_class.shape","dbda4800":"## Using sklearn train_test_split \ntrain, x_val_test, y_train, y_val_test = train_test_split(images, image_class , stratify = image_class, test_size = 0.25 , random_state = 12)\nval, test, y_val, y_test = train_test_split(x_val_test, y_val_test , stratify = y_val_test, test_size = 0.4)\n\nprint(\"train size :{}\".format(train.shape))\nprint(\"y_train size :{}\".format(y_train.shape))\n##\nprint(\"val size :{}\".format(val.shape))\nprint(\"y_val size :{}\".format(y_val.shape))\n##\nprint(\"test size :{}\".format(test.shape))\nprint(\"y_test size :{}\".format(y_test.shape))","48275ff0":"## number of classes in train data \npd.Series(y_train).value_counts()","18a74a1f":"## no of classes in validation data \npd.Series(y_val).value_counts()","dc02d30e":"## no of classes in test data \npd.Series(y_test).value_counts()","4731e3c6":"## visualize train set images\n\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    ## in order for the image to be displayed in its real color \n    rgb = cv2.cvtColor(train[i], cv2.COLOR_BGR2RGB)\n    plt.imshow(rgb, cmap = plt.cm.Spectral)\n    #\n    label = y_train[i]\n    name = names[str(label)]\n    plt.title(name)\n    plt.axis(\"off\")","3434fbe5":"## visualize validation set images\n\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    ## in order for the image to be displayed in its real color \n    rgb = cv2.cvtColor(val[i], cv2.COLOR_BGR2RGB)\n    plt.imshow(rgb, cmap = plt.cm.Spectral)\n    #\n    label = y_val[i]\n    name = names[str(label)]\n    plt.title(name)\n    plt.axis(\"off\")","ce7b4c24":"## visualize test set images\n\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    ## in order for the image to be displayed in its real color \n    rgb = cv2.cvtColor(test[i], cv2.COLOR_BGR2RGB)\n    plt.imshow(rgb, cmap = plt.cm.Spectral)\n    #\n    label = y_test[i]\n    name = names[str(label)]\n    plt.title(name)\n    plt.axis(\"off\")","549ad361":"## pre process the input images as required for the model \ntrain_processed = tf.keras.applications.resnet.preprocess_input(train)\n#\nval_processed = tf.keras.applications.resnet.preprocess_input(val)\n#\ntest_processed = tf.keras.applications.resnet.preprocess_input(test)","7a59912c":"# Transfer learning with ResNet . \nbase_Net = tf.keras.applications.ResNet50(include_top = False, \n                         weights ='imagenet', \n                         input_shape = (224,224,3), \n                         pooling='avg',\n                         )\n\nbase_Net.trainable = False\n#Adding the final layers to the above base models where the actual classification is done in the dense layers\nmodel_Net = tf.keras.models.Sequential()\nmodel_Net.add(base_Net)\nmodel_Net.add(tf.keras.layers.Dense(1024 , activation = 'relu'))\nmodel_Net.add(tf.keras.layers.Dense(15, activation=tf.nn.softmax))\n\nmodel_Net.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\nmodel_Net.summary()\n\n# Training the CNN on the Train data and evaluating it on the val data\n%time history = model_Net.fit(train_processed , y_train, validation_data = (val_processed , y_val), epochs = 50, verbose = 0 )\n\n##\ntest_loss, test_acc = model_Net.evaluate(test_processed , y_test)\nprint(\"Test image accuracy :{}\".format(test_acc))\n##\nplt.plot(history.history['accuracy'], '-o' ,label='accuracy')\nplt.plot(history.history['val_accuracy'], '-o', label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n##\nmodel_Net.save('ResNet_tomato_classifier')\n##\ntest_predicted = model_Net.predict(test_processed)\n##\npredicted_label = []\nfor i in test_predicted:\n    label =  np.argmax(i, axis = -1)\n    predicted_label.append(label)\n    \n## classification report \nprint(classification_report(y_test, predicted_label, target_names = [v for k,v in names.items()]))","c9a147fb":"In this notebook, Tomato classification is performed using transfer learning from a pretrained model - ResNet50.  "}}