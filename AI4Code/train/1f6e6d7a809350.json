{"cell_type":{"f9c2e3e0":"code","3975d4c7":"code","01b14807":"code","7478beda":"code","821bf733":"code","2a091591":"code","14380da0":"code","38eb226a":"code","326d9e30":"code","53365326":"code","3c034ae1":"code","b2bae6f3":"code","985801cb":"code","b3d6812c":"code","2a306546":"code","09322437":"code","83a4371f":"code","3abfc81b":"code","1cc8e4bd":"code","72c7db3b":"code","2844b93e":"code","db4d6799":"code","2e5697e5":"code","60bdd2ec":"code","2a806815":"code","0c259e6d":"code","5b97da44":"code","1d8f0766":"code","4bacc677":"code","746e3d5c":"code","59f8cf96":"code","85277135":"code","ec490559":"code","f330a5db":"markdown","d9af9c60":"markdown","8c1032f7":"markdown","e33b3f97":"markdown","76b7bbc5":"markdown","05e700ce":"markdown","49a19ec4":"markdown","1b0c1efe":"markdown","1da98795":"markdown","6ba977a7":"markdown","f8b3dfa6":"markdown","8940a50a":"markdown"},"source":{"f9c2e3e0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import LSTM ,Dense, Dropout\nfrom keras.optimizers import SGD, Adam\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","3975d4c7":"train_path = \"..\/input\/human-activity-recognition\/uci_har_dataset\/UCI_HAR_Dataset\/train\/\"\ntest_path = \"..\/input\/human-activity-recognition\/uci_har_dataset\/UCI_HAR_Dataset\/test\/\"\nfeatures_path = \"..\/input\/human-activity-recognition\/uci_har_dataset\/UCI_HAR_Dataset\/features.txt\"","01b14807":"features = []\nwith open(features_path) as f:\n    features = [line.split()[1] for line in f.readlines()]\nprint('No of Features: {}'.format(len(features)))\nprint(\"No. of unique features:{}\".format(len(set(features))))","7478beda":"#LABELS\nlabels = {1: 'WALKING', \n          2:'WALKING_UPSTAIRS',\n          3:'WALKING_DOWNSTAIRS',\n          4:'SITTING',\n          5:'STANDING',\n          6:'LAYING'}","821bf733":"re=[]\nfor i , f in enumerate(features):\n    for j in range(i+1 , len(features)):\n        if features[i]==features[j] and features[i] not in re:\n            re.append(features[i])","2a091591":"for i , f in enumerate(features):\n    features[i] = ''.join(e for e in f if e not in ['(',')' , '-' , ',']) ","14380da0":"train = pd.read_csv(train_path + \"X_train.txt\" , delim_whitespace=True ,header=None)\ntrain.columns = features\ntrain['subject'] = pd.read_csv(train_path + 'subject_train.txt' , header=None , squeeze=True)\ntest = pd.read_csv(test_path + \"X_test.txt\" , delim_whitespace=True ,header=None)\ntest.columns = features\ntest['subject'] = pd.read_csv(test_path + 'subject_test.txt' , header=None , squeeze=True)","38eb226a":"train.head()","326d9e30":"test.head()","53365326":"y_train = pd.read_csv(train_path + 'y_train.txt' , names=['Activity'] , squeeze=True)\ny_test = pd.read_csv(test_path + 'y_test.txt' , names=['Activity'] , squeeze=True)","3c034ae1":"train['Activity']= y_train\ntest['Activity'] = y_test\ntrain['ActivityName'] = y_train.map(labels)\ntest['ActivityName']  = y_test.map(labels)","b2bae6f3":"print(\"The number of missing values in Training Data:\" , train.isnull().values.sum())\nprint(\"The number of missing values in Testing Data:\" , test.isnull().values.sum())","985801cb":"print(\"The number of duplicate values in Training Data:\" , train.duplicated().sum())\nprint(\"The number of duplicate values in Testing Data:\" , test.duplicated().sum())","b3d6812c":"plt.figure(figsize=(10,5))\nplt.title('Subject Wise Data Distribution')\nsns.countplot(x='subject' , data=train )\nplt.show()","2a306546":"plt.figure(figsize=(25,10))\nplt.title('Activity based Subject Distribution')\nsns.countplot(x='subject' , hue='ActivityName', data=train )\nplt.show()","09322437":"accFeat=[]\nfor feat in features:\n    if feat.find('BodyAcc') != -1 and feat.find('Magmean') !=-1 and feat.find('Freq')==-1:\n        accFeat.append(feat)","83a4371f":"def plotFacetGrid(feature, height):\n    \n    plt.figure(figsize=(10,10))\n    facetgrid=sns.FacetGrid(train , hue='ActivityName',height=height,aspect=3)\n    facetgrid.map(sns.distplot ,feature, hist=False).add_legend()\n    plt.show()","3abfc81b":"for f in accFeat:\n    plotFacetGrid(f,3) ","1cc8e4bd":"def boxplot(feature , ylabel):\n    \n    plt.figure(figsize=(5,5))\n    sns.boxplot(x='ActivityName', y=feature, data=train , showfliers=False )\n    plt.ylabel(ylabel)\n    plt.axhline(y=-0.8, xmin=0.1, xmax=0.9,dashes=(5,5), c='g') #line separating both type of activities\n    plt.xticks(rotation=90)","72c7db3b":"for f in accFeat:\n    boxplot(f , f[5:])","2844b93e":"from sklearn.manifold import TSNE","db4d6799":"def plotTsne(X,y,perplexity):\n    \n    #performing dim reduction\n    X_reduce = TSNE(verbose=2, perplexity=perplexity).fit_transform(X)\n    \n    print('Creating plot for this t-sne visualization..')\n    data={'x':X_reduce[:,0],\n          'y':X_reduce[:,1],\n         'label':y}\n    #preparing dataframe from reduced data\n    df = pd.DataFrame(data)\n    \n    #draw the plot\n    sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, height=8,\\\n                   palette=\"Set1\",markers=['^','v','s','o', '1','2'])\n    \n    plt.title(\"perplexity : {}\".format(perplexity))\n    img_name = 'TSNE_perp_{}.png'.format(perplexity)\n    print('saving this plot as image in present working directory...')\n    plt.savefig(img_name)\n    plt.show()\n    print('Done')\n    ","2e5697e5":"X= train.drop(['ActivityName'],axis=1)\ny= train['ActivityName']\nperplexity=[2,5,10]","60bdd2ec":"for p in perplexity:\n    plotTsne(X,y,perplexity=p)","2a806815":"# Activities are the class labels\n# It is a 6 class classification\nACTIVITIES = {\n    0: 'WALKING',\n    1: 'WALKING_UPSTAIRS',\n    2: 'WALKING_DOWNSTAIRS',\n    3: 'SITTING',\n    4: 'STANDING',\n    5: 'LAYING',\n}\n\n\"-----------------------RAW DATA--------------------------------------\"\n\n# Raw data signals\n# Signals are from Accelerometer and Gyroscope\n# The signals are in x,y,z directions\n# Sensor signals are filtered to have only body acceleration\n# excluding the acceleration due to gravity\n# Triaxial acceleration from the accelerometer is total acceleration\nSIGNALS = [\n    \"body_acc_x\",\n    \"body_acc_y\",\n    \"body_acc_z\",\n    \"body_gyro_x\",\n    \"body_gyro_y\",\n    \"body_gyro_z\",\n    \"total_acc_x\",\n    \"total_acc_y\",\n    \"total_acc_z\"\n]","0c259e6d":"path= \"..\/input\/human-activity-recognition\/uci_har_dataset\/UCI_HAR_Dataset\/\"","5b97da44":"# Utility function to read the data from csv file\ndef _read_csv(filename):\n    return pd.read_csv(filename, delim_whitespace=True, header=None)\n\n\"----------------------------LOAD SIGNAL---------------------------------------------\"\n\n# Utility function to load the load\ndef load_signals(subset):\n    signals_data = []\n\n    for signal in SIGNALS:\n        filename = path+subset+'\/Inertial Signals\/'+signal+'_'+subset+'.txt'\n        signals_data.append(\n            _read_csv(filename).values\n        ) \n\n    # Transpose is used to change the dimensionality of the output,\n    # aggregating the signals by combination of sample\/timestep.\n    # Resultant shape is (7352 train\/2947 test samples, 128 timesteps, 9 signals)\n    return np.transpose(signals_data, (1, 2, 0))\n\n\"-------------------------CONFUSION MATRIX----------------------------------------------\"\n\n# Utility function to print the confusion matrix\ndef confusion_matrix(Y_true, Y_pred):\n    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n\n    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n\n\n\"----------------------------LOAD Y-------------------------------------------------------\"\n\n\n\ndef load_y(subset):\n    \"\"\"\n    The objective that we are trying to predict is a integer, from 1 to 6,\n    that represents a human activity. We return a binary representation of \n    every sample objective as a 6 bits vector using One Hot Encoding\n    (https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.get_dummies.html)\n    \"\"\"\n    filename = path+subset+'\/y_'+subset+'.txt'\n    y = _read_csv(filename)[0]\n\n    return pd.get_dummies(y).values\n\n\n\n\"---------------------------------LOAD DATA---------------------------------------------\"\n\n\ndef load_data():\n    \"\"\"\n    Obtain the dataset from multiple files.\n    Returns: X_train, X_test, y_train, y_test\n    \"\"\"\n    X_train, X_test = load_signals('train'), load_signals('test')\n    y_train, y_test = load_y('train'), load_y('test')\n\n    return X_train, X_test, y_train, y_test\n\n\n\"---------------------------------COUNT CLASSES--------------------------------------------\"\n\n# Utility function to count the number of classes\ndef _count_classes(y):\n    return len(set([tuple(category) for category in y]))","1d8f0766":"# Initializing parameters\nepochs = 30\nbatch_size = 16\nn_hidden = 32","4bacc677":"# Loading the train and test data\nX_train, X_test, Y_train, Y_test = load_data()","746e3d5c":"timesteps = len(X_train[0])\ninput_dim = len(X_train[0][0])\nn_classes = _count_classes(Y_train)\n\nprint(timesteps)\nprint(input_dim)\nprint(len(X_train))","59f8cf96":"# Initiliazing the sequential model\nmodel = Sequential()\n# Configuring the parameters\nmodel.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n# Adding a dropout layer\nmodel.add(Dropout(0.5))\n# Adding a dense output layer with sigmoid activation\nmodel.add(Dense(n_classes, activation='sigmoid'))\nmodel.summary()","85277135":"# Compiling the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","ec490559":"# Training the model\nmodel.fit(X_train,\n          Y_train,\n          batch_size=batch_size,\n          validation_data=(X_test, Y_test),\n          epochs=epochs)","f330a5db":"## **[NOTE]**\npandas doesnt handle duplicate column names so its better you defined `header=NONE` and later set `DataframeName.columns=[columnNames]`","d9af9c60":"**[OBSERVATION]** \nWe can see that all the activities are well separated. But only Sitting and Standing are non separable.","8c1032f7":"**[Remember]** \nAcceleration is not so important in activities like Standing, Sitting, Laying","e33b3f97":"3. Data Imbalance","76b7bbc5":"The names of features need to be processed. We need to replace `() , \"-\"` from their names.","05e700ce":"# LSTM MODEL","49a19ec4":"# Human Activity Recognition\n\nThis project is to build a model that predicts the human activities such as Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing or Laying.\n\nThis dataset is collected from 30 persons(referred as subjects in this dataset), performing different activities with a smartphone to their waists. The data is recorded with the help of sensors (accelerometer and Gyroscope) in that smartphone. This experiment was video recorded to label the data manually.","1b0c1efe":"**[Observation]**\nYou can separate low accelaration activity from high accelaration activities easily from the plot. Box plot will give you better intuitions.","1da98795":"# Dimentionality Reduction using T-SNE","6ba977a7":"This shows that there are duplicate feature names","f8b3dfa6":"# Data Analysis\n\n1. Check for missing Values\n2. Duplicate Values","8940a50a":"# Features \n\nWe need to extract features names from file `features.txt`"}}