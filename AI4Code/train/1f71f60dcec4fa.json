{"cell_type":{"3884e11b":"code","0e6cf096":"code","415bf293":"code","4c3c215e":"code","b6cfed5a":"code","446f3bab":"code","a40e3729":"code","2d561f34":"code","0fa4b7a4":"code","c986f44a":"code","7b8deb5c":"code","34bbad9f":"code","8b70e2e6":"code","6a21cb2a":"code","5205e980":"code","d45d249e":"code","f53f4177":"code","c074a449":"code","8ac3e59d":"code","9b85746e":"code","b3f10458":"code","4e45e121":"code","c156f5b6":"code","4495772b":"code","33c15bd8":"code","cc11bde5":"code","7212b262":"markdown","731b7333":"markdown","3ad1b2df":"markdown","81e433eb":"markdown","9bc28686":"markdown","0b3c27e0":"markdown","44ceb6aa":"markdown","af0c8d40":"markdown","3b6eb49b":"markdown"},"source":{"3884e11b":"import os\nimport glob\nimport tensorflow as tf\nimport h5py\nimport shutil\nimport imgaug as aug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport imgaug.augmenters as iaa\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\n#from pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.layers.core import Dense, Activation\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D, Input, Concatenate, Dropout\nfrom keras.models import Model\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing import image\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.regularizers import l2\nfrom keras.callbacks import ReduceLROnPlateau, Callback\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom glob import glob\nfrom keras import backend as K\ncolor = sns.color_palette()\n%matplotlib inline","0e6cf096":"data_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"\ntrain_dir = os.path.join(data_dir, \"train\/\")\ntest_dir = os.path.join(data_dir, \"test\/\")\nval_dir = os.path.join(data_dir, \"val\/\")","415bf293":"train_data = []\n\nnormal_cases_dir = os.path.join(train_dir,'NORMAL')\npneumonia_cases_dir = os.path.join(train_dir,'PNEUMONIA')\n\n# Get the list of all the images\nnormal_cases = glob(normal_cases_dir+\"\/*.jpeg\")\npneumonia_cases = glob(pneumonia_cases_dir + \"\/*.jpeg\")\n\n# Go through all the normal cases. The label for these cases will be 0\nfor img in normal_cases:\n    train_data.append((img,0))\n\n# Go through all the pneumonia cases. The label for these cases will be 1\nfor img in pneumonia_cases:\n    train_data.append((img, 1))\n\n# Get a pandas dataframe from the data we have in our list \ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n\n# How the dataframe looks like?\ntrain_data.head()","4c3c215e":"cases_count = train_data['label'].value_counts()\nprint(cases_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=cases_count.index, y= cases_count.values)\nplt.title('Number of cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\nplt.show()","b6cfed5a":"val_data = []\n\nnormal_cases_dir = os.path.join(val_dir,'NORMAL')\npneumonia_cases_dir = os.path.join(val_dir,'PNEUMONIA')\n\n# Get the list of all the images\nnormal_cases = glob(normal_cases_dir+\"\/*.jpeg\")\npneumonia_cases = glob(pneumonia_cases_dir + \"\/*.jpeg\")\n\n# Go through all the normal cases. The label for these cases will be 0\nfor img in normal_cases:\n    val_data.append((img,0))\n\n# Go through all the pneumonia cases. The label for these cases will be 1\nfor img in pneumonia_cases:\n    val_data.append((img, 1))\n\n# Get a pandas dataframe from the data we have in our list \nval_data = pd.DataFrame(val_data, columns=['image', 'label'],index=None)\n\n# How the dataframe looks like?\nval_data.head()","446f3bab":"cases_count = val_data['label'].value_counts()\nprint(cases_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=cases_count.index, y= cases_count.values)\nplt.title('Number of cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\nplt.show()","a40e3729":"test_data = []\n\nnormal_cases_dir = os.path.join(test_dir,'NORMAL')\npneumonia_cases_dir = os.path.join(test_dir,'PNEUMONIA')\n\n# Get the list of all the images\nnormal_cases = glob(normal_cases_dir+\"\/*.jpeg\")\npneumonia_cases = glob(pneumonia_cases_dir + \"\/*.jpeg\")\n\n# Go through all the normal cases. The label for these cases will be 0\nfor img in normal_cases:\n    test_data.append((img,0))\n\n# Go through all the pneumonia cases. The label for these cases will be 1\nfor img in pneumonia_cases:\n    test_data.append((img, 1))\n\n# Get a pandas dataframe from the data we have in our list \ntest_data = pd.DataFrame(test_data, columns=['image', 'label'],index=None)\n\n# How the dataframe looks like?\ntest_data.head()","2d561f34":"cases_count = test_data['label'].value_counts()\nprint(cases_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=cases_count.index, y= cases_count.values)\nplt.title('Number of cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\nplt.show()","0fa4b7a4":"pneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\nnormal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n\n# Concat the data in a single list and del the above two list\nsamples = pneumonia_samples + normal_samples\ndel pneumonia_samples, normal_samples\n\n# Plot the data \nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    img = imread(samples[i])\n    ax[i\/\/5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i\/\/5, i%5].set_title(\"Pneumonia\")\n    else:\n        ax[i\/\/5, i%5].set_title(\"Normal\")\n    ax[i\/\/5, i%5].axis('off')\n    ax[i\/\/5, i%5].set_aspect('auto')\nplt.show()","c986f44a":"Normal = glob(train_dir + \"NORMAL\/*\") + glob(test_dir + \"NORMAL\/*\") + glob(val_dir + \"NORMAL\/*\")\nPneumonia = glob(train_dir + \"PNEUMONIA\/*\") + glob(test_dir + \"PNEUMONIA\/*\") + glob(val_dir + \"PNEUMONIA\/*\")\n\nprint(\"We have total {} Normal Images\".format(len(Normal)))\nprint(\"We have total {} Pneumonia Images\".format(len(Pneumonia)))","7b8deb5c":"\n# For all normal images\nTrain_normal = Normal[:1266]\nTest_normal = Normal[1266:1424]\nValidation_normal = Normal[1424:]\n\n# For all pneumonia images\nTrain_pneumonia = Pneumonia[:3418]\nTest_pneumonia = Pneumonia[3418:3845]\nValidation_pneumonia = Pneumonia[3845:]\n\n","34bbad9f":"!mkdir Train\n!mkdir Test\n!mkdir Validation\n!mkdir Train\/Normal\n!mkdir Train\/Pneumonia\n!mkdir Test\/Normal\n!mkdir Test\/Pneumonia\n!mkdir Validation\/Normal\n!mkdir Validation\/Pneumonia","8b70e2e6":"# copy all images from Train_pneumonia to Train\/Pneumonia\nfor i in Train_pneumonia:\n    shutil.copy(i, \"Train\/Pneumonia\/\")\nprint(\"Copied all images from Train_pneumonia to Train\/Pneumonia\")\n    \n# copy all images from Test_pneumonia to Test\/Pneumonia\nfor i in Test_pneumonia:\n    shutil.copy(i, \"Test\/Pneumonia\/\")\nprint(\"Copied all images from Test_pneumonia to Test\/Pneumonia\")\n    \n# copy all images from Validation_pneumonia to Validation\/Pneumonia\nfor i in Validation_pneumonia:\n    shutil.copy(i, \"Validation\/Pneumonia\/\")\nprint(\"Copied all images from Validation_pneumonia to Validation\/Pneumonia\")\n\n# copy all images from Train_normal to Train\/Normal\nfor i in Train_normal:\n    shutil.copy(i, \"Train\/Normal\/\")\nprint(\"Copied all images from Train_normal to Train\/Normal\")\n\n# copy all images from Test_normal to Test\/Normal\nfor i in Test_normal:\n    shutil.copy(i, \"Test\/Normal\/\")\nprint(\"Copied all images from Test_normal to Test\/Normal\")\n    \n# copy all images from Validation_normal to Validation\/Normal\nfor i in Validation_normal:\n    shutil.copy(i, \"Validation\/Normal\/\")\nprint(\"Copied all images from Validation_normal to Validation\/Normal\")","6a21cb2a":"train_dir = \"Train\/\"\ntest_dir = \"Test\/\"\nval_dir = \"Validation\/\"\n# check new data distribution\nprint(\"Number of images in Train is {}\".format(len(glob(train_dir + \"*\/*\"))))\nprint(\"Number of images in Test is {}\".format(len(glob(test_dir + \"*\/*\"))))\nprint(\"Number of images in Validation is {}\".format(len(glob(val_dir + \"*\/*\"))))","5205e980":"filenames = tf.io.gfile.glob(str('Train\/*\/*'))\ntrain_filenames=tf.io.gfile.glob(str('Train\/*\/*'))\nfilenames.extend(tf.io.gfile.glob(str('Validation\/*\/*')))\nval_filenames=tf.io.gfile.glob(str('Validation\/*\/*'))\n\nCOUNT_NORMAL = len([filename for filename in train_filenames if \"Normal\" in filename])\nprint(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n\nCOUNT_PNEUMONIA = len([filename for filename in train_filenames if \"Pneumonia\" in filename])\nprint(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))","d45d249e":"initial_bias = np.log([COUNT_PNEUMONIA\/COUNT_NORMAL])\ninitial_bias\nweight_for_0 = (1 \/ COUNT_NORMAL)*(len(train_filenames))\/2.0 \nweight_for_1 = (1 \/ COUNT_PNEUMONIA)*(len(train_filenames))\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\n","f53f4177":"train_datagen = ImageDataGenerator(rotation_range = 30,\n                                   zoom_range = 0.2,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   horizontal_flip = True,\n                                   rescale = 1.\/255)\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","c074a449":"batch_size = 16\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                 target_size = (224, 224), \n                                                 batch_size = batch_size, \n                                                 class_mode = \"binary\")\nval_set = val_datagen.flow_from_directory(val_dir,\n                                          target_size = (224, 224),\n                                          batch_size = batch_size,\n                                          class_mode = 'binary')\ntest_set = test_datagen.flow_from_directory(test_dir,\n                                            target_size = (224, 224),\n                                            batch_size = batch_size,\n                                            class_mode = 'binary')","8ac3e59d":"def dense_block(x, blocks, name):\n    for i in range(blocks):\n        x = conv_block(x, 32, name=name + '_block' + str(i + 1))\n    return x","9b85746e":"def transition_block(x, reduction, name):\n    bn_axis = 3\n    if K.image_data_format() == \"channels_first\":\n        bn_axis = 1\n    x = BatchNormalization(axis = bn_axis, epsilon=1.001e-5, name = name + '_bn')(x)\n    x = Activation('relu', name = name + '_relu')(x)\n    x = Conv2D(int(K.int_shape(x)[bn_axis] * reduction), 1, use_bias = False, \n               name = name + '_conv')(x)\n    x = AveragePooling2D(2, strides = 2, name = name + '_pool')(x)\n    return x","b3f10458":"def conv_block(x, growth_rate, name):\n    bn_axis = 3\n    if K.image_data_format() == \"channels_first\":\n        bn_axis = 1\n    \n    x1 = BatchNormalization(axis = bn_axis, epsilon = 1.001e-5,\n                            name = name + '_0_bn')(x)\n    x1 = Activation('relu', name = name + '_0_relu')(x1)\n    x1 = Conv2D(4 * growth_rate, 1, use_bias = False,\n                name = name + '_1_conv')(x1)\n    \n    x1 = BatchNormalization(axis = bn_axis, epsilon = 1.001e-5, name = name + '_1_bn')(x1)\n    x1 = Activation('relu', name = name + '_1_relu')(x1)\n    x1 = Conv2D(growth_rate, 3, padding = 'same', use_bias = False,\n                name = name + '_2_conv')(x1)\n    \n    x = Concatenate(axis = bn_axis, name = name + '_concat')([x, x1])\n    return x","4e45e121":"def DenseNet121(blocks, input_shape = (224, 224, 3), classes = 1):\n    \n    # Determine proper input shape\n    img_input = Input(shape=input_shape)\n    bn_axis = 3\n    if K.image_data_format() == \"channels_first\":\n        bn_axis = 1\n\n    x = ZeroPadding2D(padding = ((3, 3), (3, 3)))(img_input)\n    x = Conv2D(64, 7, strides = 2, use_bias = class_weight, name = 'conv1\/conv')(x)\n    x = BatchNormalization(axis = bn_axis, epsilon = 1.001e-5, name = 'conv1\/bn')(x)\n    x = Activation('relu', name = 'conv1\/relu')(x)\n    x = ZeroPadding2D(padding = ((1, 1), (1, 1)))(x)\n    x = MaxPooling2D(3, strides = 2, name = 'pool1')(x)\n\n    x = dense_block(x, blocks[0], name = 'conv2')\n    x = transition_block(x, 0.5, name = 'pool2')\n    x = dense_block(x, blocks[1], name = 'conv3')\n    x = transition_block(x, 0.5, name = 'pool3')\n    x = dense_block(x, blocks[2], name = 'conv4')\n    x = transition_block(x, 0.5, name = 'pool4')\n    x = dense_block(x, blocks[3], name = 'conv5')\n\n    x = BatchNormalization(axis = bn_axis, epsilon = 1.001e-5, name = 'bn')(x)\n    x = Activation('relu', name = 'relu')(x)\n    \n    basemodel = Model(img_input, x, name='basedensenet121')\n    #basemodel.load_weights(weights=\"imagenet\",)\n    \n    x = basemodel.output\n    x = GlobalAveragePooling2D(name = 'avg_pool')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(classes, activation = 'sigmoid', name = 'fc1')(x)\n    \n    model = Model(img_input, x, name='densenet121')\n    return model\n","c156f5b6":"model = DenseNet121(blocks = [6, 12, 24, 16], input_shape = (224, 224, 3), classes = 1)\nmodel.summary()","4495772b":"opt = Adam(lr = 0.001)\nmodel.compile(loss = \"binary_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])\n# this will help in reducing learning rate by factor of 0.1 when accuarcy will not improve\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 2, verbose = 1,\n                                            factor = 0.3, min_lr = 0.000001)\nclass myCallback(Callback):\n\tdef on_epoch_end(self, epoch, logs={}):\n\t\tif(logs.get('val_accuracy') > 0.90):\n\t\t\tprint(\"\\nReached 90% accuracy so cancelling training!\")\n\t\t\tself.model.stop_training = True\n\ncallbacks = myCallback()","33c15bd8":"H = model.fit_generator(training_set,\n                        steps_per_epoch = training_set.samples\/\/batch_size,\n                        validation_data = val_set,\n                        epochs = 20,\n                        validation_steps = val_set.samples\/\/batch_size,\n                        callbacks = [reduce_lr, callbacks])","cc11bde5":"print(\"Loss of the model is - \" , model.evaluate(test_set)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(test_set)[1]*100 , \"%\")","7212b262":"# Visualizing Images","731b7333":"In next some code blocks we will split the data in Train, Validation and Testing in ratio of 80% for Training, 10% for Validation, and 10% for Testing\n","3ad1b2df":"# Preparing Dataset","81e433eb":"# Preparing Balanced dataset","9bc28686":"# **Importing Libraries**","0b3c27e0":"# Make new directory to store our balanced data\n","44ceb6aa":"# ***Result on Testset***","af0c8d40":"# Checking For Unbalanced Data","3b6eb49b":"## **Training**"}}