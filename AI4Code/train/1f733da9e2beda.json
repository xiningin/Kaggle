{"cell_type":{"1db58e44":"code","670e6640":"code","f662923c":"code","4e0e66c0":"code","066cc955":"code","b0a1f519":"code","3345f6c2":"code","351f2a92":"code","150a9178":"code","0163a228":"code","cbfbec62":"code","4f021c3b":"code","352cd742":"code","80b23874":"markdown","ef031835":"markdown","70f42130":"markdown","68f34f86":"markdown","fb68ddf3":"markdown","25f99769":"markdown","fe2bfcf5":"markdown","e3d5a919":"markdown","4bacc6c2":"markdown","dc9e40d8":"markdown","4dd4ad3b":"markdown","b49dcd96":"markdown","fc0b81d0":"markdown","5d180652":"markdown","21a8c170":"markdown","29ac0707":"markdown","3dec46fe":"markdown"},"source":{"1db58e44":"!pip install kneed","670e6640":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport time\n\nimport datetime as datetime\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\nfrom kneed import KneeLocator\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)","f662923c":"def MinMaxScaler(data):\n    return (data-np.min(data))\/(np.max(data)-np.min(data))\n\ndef Kmeans_clustering(df, clusterNum, max_iter=1000, n_jobs=-1):\n    '''\n    Function for doing kmeans clustering.\n    Inputs should include at least the dataframe of variables and cluster number you want.\n    '''\n    # Normalize the dataframe\n    scaler = StandardScaler()\n    scaler.fit(df) \n    df_std = pd.DataFrame(data=scaler.transform(df), columns=df.columns, index=df.index)\n    \n    # Kmeans clustering\n    km_model = KMeans(n_clusters=clusterNum, max_iter=max_iter, random_state=666)\n    km_model = km_model.fit(df_std)\n    \n    clusterdf= pd.DataFrame(data=km_model.labels_, columns=['ClusterNo'])\n    clusterdf.index = df.index\n    \n    return clusterdf\n\ndef Kmeans_bestClusterNum(df, range_min, range_max, max_iter=1000, n_jobs=-1):\n    '''\n    Function for finding optimal number of kmeans clustering.\n    Inputs should include at least the dataframe of variables, and search range of cluster number (min & max cluster number).\n    '''    \n    \n    # Normalize the dataframe\n    scaler = StandardScaler()\n    scaler.fit(df) \n    df_std = pd.DataFrame(data=scaler.transform(df), columns=df.columns, index=df.index)       \n    \n    # Calculate inertia for each cluster number in the research range\n    sum_of_squared_distances = [] #Inertia of all clustering results\n    ks = range(range_min,range_max+1)\n    for k in ks:\n        kmeans_fit = KMeans(n_clusters = k, max_iter=max_iter, random_state=666).fit(df_std)\n        cluster_labels = kmeans_fit.labels_\n        sum_of_squared_distances.append(kmeans_fit.inertia_)\n        \n    # Use kneed package to locate the elbow \/ knee of the curve line\n    kn = KneeLocator(list(ks), sum_of_squared_distances, S=1.0, curve='convex', direction='decreasing')  \n    \n    # Plot the result of finding optimal cluster number\n    plt.xlabel('k')\n    plt.ylabel('sum_of_squared_distances')\n    plt.title('The Elbow Method showing the optimal k')\n    plt.plot(ks, sum_of_squared_distances, 'bx-')\n    plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    plt.show()\n    \n    print('Optimal clustering number:'+str(kn.knee))\n    print('----------------------------')    \n    \n    return kn.knee","4e0e66c0":"path_file = r'\/kaggle\/input\/create-pickle-for-dataset\/'","066cc955":"df_data = pd.read_pickle(os.path.join(path_file, 'df_merged.pickle.gz'))\ndf_data","b0a1f519":"# Leave columns with keyword of 'kW'\ndf_powerMeter = df_data.loc[:, df_data.columns.str.contains('kW')].copy()\n\n# Sum up demands of all power meters\ndf_powerMeter = df_powerMeter.sum(axis=1).rename('total_demand')\ndf_powerMeter = df_powerMeter.resample('H').mean()\ndf_powerMeter","3345f6c2":"df_powerMeter.iplot()","351f2a92":"# Reshape the dataframe\ndf_temp = df_powerMeter.reset_index().copy()\ndf_temp['date'] = df_temp['Date'].dt.date    \ndf_temp['hour'] = df_temp['Date'].dt.hour\ndf_temp_pivot = df_temp.pivot_table(index='hour', columns='date')\ndf_temp_pivot","150a9178":"df_temp_pivot.plot(figsize=(15,5),color='black',alpha=0.1,legend=False)","0163a228":"df_PM_temp = df_temp_pivot.copy()\ndf_PM_temp = df_PM_temp.T\n\nbestClusterNum_dept = Kmeans_bestClusterNum(df=df_PM_temp.fillna(0), range_min=2, range_max=10, max_iter=10000, n_jobs=-1)","cbfbec62":"df_PM_temp['ClusterNo'] = Kmeans_clustering(df=df_PM_temp.fillna(0), clusterNum=bestClusterNum_dept, max_iter=10000, n_jobs=-1)\n\nfor ClusterNo in df_PM_temp['ClusterNo'].sort_values().unique():\n    df_plot = df_PM_temp[df_PM_temp['ClusterNo']==ClusterNo].T.drop('ClusterNo')\n    print('Cluster No.: ' + str(ClusterNo))    \n    print('Amount of meters: ' + str(len(df_plot.T)))\n    df_plot.plot(figsize=(15,5),color='black',alpha=0.1,legend=False, ylim=(0, 1000))\n    plt.show()\n    print('-----------------------------------------------------------------------------------')","4f021c3b":"plt.figure(figsize=(15,6))\nax = sns.lineplot(x=\"hour\", y=\"value\", hue=\"ClusterNo\",\n                  data=df_PM_temp.melt(id_vars='ClusterNo'))","352cd742":"df_temp = df_temp.merge(df_PM_temp.reset_index()[['date', 'ClusterNo']], on='date')\ndf_temp = df_temp.pivot_table(columns='ClusterNo', index='Date', values='total_demand')\ndf_temp.loc['2018'].iplot()","80b23874":"Let's start to find optimal cluster number in search range of 2 to 10.","ef031835":"Let's start with importing packages and installing `kneed` package.","70f42130":"Group0, group3 and group4 seems like `workday groups` with traditional occupant behaviors, while the group1 and group2 are probably `holiday groups` with flat trends.","68f34f86":"# Load dataset","fb68ddf3":"# Preprocess the dataset (power meter data at 15-min interval)","25f99769":"In the module \"BPS5229 Data Science for the Built Environment\",  we've learned how to use Kmeans for clustering daily profiles of power meters.\n\nHowever, cluster number of kmeans should be indicated by user, and user usually needs to manually adjust the number many times to find the optimal one.\n\nSo, this notebook tries to use **knee method (also called elbow method)** based on the **inertia value** of clustering result to find the optimal clustering number.\n\nThe result of this notebook, which is an useful python function, could *help user automatically find an initial optimal number for clustering.*","fe2bfcf5":"Because our goal is to cluster daily load profiles, we need to reshape the dataframe from a single `time series` to an `array` with hour in y-axis and date in x-axis.","e3d5a919":"The result seems nice and reasonable, but it's just one of cases for demonstrating the methodology.\n\nAlthough more conductions and discussions should be made to find the optimal cluster number, this elbow method may provide a nice reference value for initial kmeans clustering","4bacc6c2":"Here's the plot for all daily load profiles, and it's obvious that there are at least two groups: (1) workday group and (2) holiday group.","dc9e40d8":"Let's load the dataset of power meters!","4dd4ad3b":"# Clustering function","b49dcd96":"Here are main functions we'll use in this notebook, which help us find optimal cluster numbers and produce the dataframe with cluster labels.\n\nTo find the optimal cluster number, there are three basic steps:\n1. Normalize all variables in the dataframe (here we use `min-max-scaler`)\n2. Calculate `inertia` for each cluster number in the search range we set\n3. Draw the curve between `inertia` in y-axis and `cluster number` in x-axis, and find the optimal cluster number via **elbow method**\n","fc0b81d0":"Before doing kmeans clustering, let's sum up energy consumptions from all power meters to make this demo much easier.\n\nBesides, we also do resmpling from 1-min interval to 15-min interval to save some memory use.\n","5d180652":"![Elbow mehod for clustering](https:\/\/www.datanovia.com\/en\/wp-content\/uploads\/dn-tutorials\/004-cluster-validation\/figures\/015-determining-the-optimal-number-of-clusters-k-means-optimal-clusters-wss-silhouette-1.png)\nReference: https:\/\/www.datanovia.com\/en\/lessons\/determining-the-optimal-number-of-clusters-3-must-know-methods\/","21a8c170":"# Could we automatically get optimal number for Kmeans clustering?","29ac0707":"### Hooray! We got optimal clustering number of 5 here!\n\nThen we put this optimal number for following Kmeans clustering and see what happened:","3dec46fe":"# Clustering & visualizations"}}