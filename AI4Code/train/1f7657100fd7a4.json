{"cell_type":{"157d4a62":"code","4c7c1257":"code","11015396":"code","fd338484":"code","1ad1158e":"code","e2ea31d4":"code","e59a7569":"code","344e6697":"code","c8c63328":"code","e0284b0f":"code","53dafd62":"code","efc813e9":"code","d49cdd7f":"code","21afbc97":"code","66c2a6b6":"code","3613089d":"markdown","9b7a27d7":"markdown","3b690563":"markdown","9b084f71":"markdown","83e2676f":"markdown","d9ce3ee5":"markdown","09d72374":"markdown","4f2c50a6":"markdown","acac2705":"markdown","d591cbc3":"markdown","054471b7":"markdown","7bda3455":"markdown","b1ece162":"markdown","1c901bee":"markdown","4f1c1c47":"markdown","94c31f6b":"markdown","cb271ce5":"markdown","4ee30bde":"markdown","0d7cd0ad":"markdown"},"source":{"157d4a62":"import numpy as np  # linear algebra\nimport pandas as pd  # data manipulation and processing\nimport matplotlib.pyplot as plt  # data visualization\nimport seaborn as sns  # more attractive visualizations\nimport statsmodels.api as sm  # will help us apply regression model","4c7c1257":"sns.set()  # (optional), will make all matplotlib visualizations appear in seaborn skins","11015396":"raw_data = pd.read_csv(\"..\/input\/real-estate-price\/real_estate_price_size_year_view.csv\")\nraw_data.head()","fd338484":"raw_data.view.value_counts()","1ad1158e":"data = raw_data.copy()  # making a copy so that our original data remains intact","e2ea31d4":"data.view = data.view.map({\"No sea view\": 0, \"Sea view\":1})\ndata.head()","e59a7569":"y = data[\"price\"]  # inferred\nx1 = data[[\"size\", \"view\"]]  # data[\"size\", \"year\", \"view\"] - for all variables available in dataset","344e6697":"plt.scatter(y, data[\"size\"])\nplt.xlabel(\"size\", fontsize = 20)\nplt.ylabel(\"price\", fontsize = 20)\nplt.show()","c8c63328":"x = sm.add_constant(x1)\nresult = sm.OLS(y, x).fit()\nresult.summary()","e0284b0f":"plt.scatter(data[\"size\"], y)\ny_hat_sv = 135040 + (218.7521 * data[\"size\"])\ny_hat_nsv = 7.748e+04 + (218.7521 * data[\"size\"])\nfig = plt.plot(data[\"size\"], y_hat_sv, lw = 2, c = \"orange\")\nfig = plt.plot(data[\"size\"], y_hat_nsv, lw = 2, c = \"green\")\nplt.xlabel(\"size\", fontsize = 20)\nplt.ylabel(\"price\", fontsize = 20)\nplt.show()","53dafd62":"plt.scatter(data[\"size\"], y, c=data['view'],cmap='RdYlGn_r')\ny_hat_sv = 135040 + (218.7521 * data[\"size\"])\ny_hat_nsv = 7.748e+04 + (218.7521 * data[\"size\"])\nfig = plt.plot(data[\"size\"], y_hat_sv, lw = 2, c = \"orange\")\nfig = plt.plot(data[\"size\"], y_hat_nsv, lw = 2, c = \"green\")\nplt.xlabel(\"size\", fontsize = 20)\nplt.ylabel(\"price\", fontsize = 20)\nplt.show()","efc813e9":"x.head(2)  # our regressor and constant that we added before applying sm.OLS()","d49cdd7f":"new_houses = pd.DataFrame({'const': 1,'size': [400, 600, 800, 1000], 'view': [0, 1, 1, 0]}, index = range(4))\nnew_houses","21afbc97":"new_house_prices = result.predict(new_houses)  # syntax to apply model on some new houses (saved in new_houses)\nnew_house_prices.reindex()\nnew_house_prices","66c2a6b6":"new_houses_prices = pd.DataFrame({\"Predicted Prices\": new_house_prices})\nnew_houses.join(new_houses_prices)","3613089d":"## 4. Saving Dependent Variable and Regressors","9b7a27d7":"const is nothing but a coefficient of our b0, does not change anything as 1*b0 = b0.\n\nWe will create a DataFrame of new houses whose prices we want to predict using our model, this new houses' DataFrame should have columns for all regressors and constant as columns. (i.e. 'const', 'size' and 'view')","3b690563":"- result here is the variable we saved sm.OLS().fit() in\n\n- predict() is the function to apply to model to predict dependent variable and takes new df df (having regressors' values) as argument\n\n- and return of the statement is a Series having prices of given houses in corresonding indices\n\n**Next,** we can create a new houses DataFrame containing everything(i.e. all the independent variables and prices of the houses). But for that, we will need to change new_house_prices from a Series to a DataFrame as join() can only be used to join DataFrames.","9b084f71":"## 3. Replacing Categorical Data with Dummy Values\nWe can edit the same 'view' column or add another column for our dummy values. Here, we will be editing same column and use map() function to replace 'No sea view' with a 0 and 'Sea view' with a 1.","83e2676f":"That is how regression is applied on Categorical Data.","d9ce3ee5":"**Foreword:** This notebook was maintained simultaneously when I was learning Linear Regression. This notebook is third part of the three-notebook series, which tend to explain process of applying Linear Regression on a dataset. You can find all parts by clicking given links:\n\n[**1. First Linear Regression Model**](https:\/\/www.kaggle.com\/salmankhi\/my-first-regression-mode)\n\n[**2. Multiple Variable Linear Regression Model**](https:\/\/www.kaggle.com\/salmankhi\/multiple-linear-regression)\n\n[**3. Linear Regression on Categorical Data**](https:\/\/www.kaggle.com\/salmankhi\/regression-on-categorical-data)","09d72374":"## 8. Visualization of Results\n\nWith equation in hand, we can also say that we have two equations for the prediction of house prices, that are given below,\n\n- With Sea View: y_hat = 135040 + (218.7521 * \"size\") (As view = 1 here, and 7.748e+04 + 5.756e+04 = 135040)\n- Without Sea View: y_hat = 7.748e+04 + (218.7521 * \"size\") (As view = 0 here)","4f2c50a6":"## 1. Importing Libraries","acac2705":"- orange line shows regression results for houses with the sea view\n- green line shows regression results for houses without the sea view\n\nboth have the same slopes, but different intercepts.","d591cbc3":"## 7. Substituting values in Multiple Linear Regression Equation\n\nWe can find a price of a house for given 'size' and 'view' by using following equation.\n<center>y_hat = 7.748e+04 + (218.7521 * \"size\") + (5.756e+04 * \"view\")<\/center>\n\nLike for house of size = 500 and no sea view, predicted price is 186856,\n\nfor house of size = 700 and sea view, predicted price is 288166\n\nand for house of size = 300 and sea view, predicted price is 200665.","054471b7":"## Regression Analysis on Categorical Data\nTill now, we have only seen application of regression analysis on numerical data. But regression can also be applied on categorical data. For this purpose we need to substitute dummy values (numerical) in place of categorical data.","7bda3455":"Here we can see that there are only two unique values in 'view' column and we need to replace them with numerical data.","b1ece162":"**For the example,** we will use same real estate data with an additional 'view' column in it. This data will contain prices, sizes, years of construction and view options of the houses.\n\nOf course, we can use and should use all of the variables as regressors in our analysis. But, for the sake that I want to make as much as visualization as possible, I will not be considering 'year' as a regressor in this particular example. However, I will point out how all three independent variables can be used to predict price of the given house.","1c901bee":"**Summary tells us,**\n- b0 = 7.748e+04\n- b1 = 218.7521\n- b2 = 5.756e+04\n- P>|t| for all of the coefficients is 0.000, meaning each regressor is driving the variability of 'y'\n- P-Vale of f-statistics is very small, we can reject the H0 that b1 = b2 = 0\n\nwe would have a b3, if we had considered 'year' as well with these two regressors (i.e. 'size', 'view').","4f1c1c47":"## 2. Loading Data","94c31f6b":"## 9. Making Predictions\nTill now, we were predicting values by manually applying the equation on a given house and solving for it. But we can also use python's predict() function to make predictions based on the regression model we have made.","cb271ce5":"## 5. Price - Size Scatter Plot","4ee30bde":"## 6. Applying Regression","0d7cd0ad":"Houses with and without sea views are seperated by color here and it can be clearly observed that houses having same size are expensive if they have a sea view compared to the houses that do not."}}