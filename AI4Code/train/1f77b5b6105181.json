{"cell_type":{"f3349c24":"code","ae012a75":"code","7009e459":"code","6efdddc7":"code","41b0d2c9":"code","8f2242fa":"code","b73793c3":"code","bd6f6fed":"code","3409a9da":"code","526f7bfb":"code","555c845a":"markdown","70592661":"markdown","8538a877":"markdown","345233b2":"markdown","87ac9a9b":"markdown","f5d982b8":"markdown","c8fbb393":"markdown","723d0307":"markdown","3de7b816":"markdown","bbbc0353":"markdown","813ee618":"markdown","592ab641":"markdown","98449533":"markdown","04b22fef":"markdown","a69fc0e6":"markdown"},"source":{"f3349c24":"#All imports here.\nimport array\nimport time\nfrom multiprocessing import Process\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom math import log\nfrom tqdm import tqdm","ae012a75":"#Byte file count vectors.\n\n\"\"\"\nbyte_count_vectors = open(\".\/byte_count_vectors.csv\", \"w+\") # w+ idicates it will create a file if it does not exist in library.\n\nchar_list = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']\nfinal_string = \"Id,\"\nfor i in char_list:\n    for j in char_list:\n        concat = \"\"\n        concat = concat.join((i,j))\n        final_string = final_string + concat + \",\"\n\nfinal_string = final_string+\"??\"\nbyte_count_vectors.write(final_string)\nbyte_count_vectors.write(\"\\n\")\n\nfiles = os.listdir(\".\/byte_files\") #byte_files is folder in the local machine having all byte files.\nfeature_matrix = np.zeros((len(files), 257), dtype = int)\n\nk=0 #Denotes each row. Rows will be total datapoints,here files.\nprint(\"The code is still running--------------------------------------------------------------------->>>>>>>>>>>\")\nfor file in tqdm(files):\n    f_name = file.split(\".\")[0]\n    byte_count_vectors.write(f_name+\",\") #This goes into byte_fe_results.csv file.\n    with open(\".\/byte_files\/\"+file, \"r\") as each_file:\n        for line in each_file:\n            line = line.rstrip().split(\" \") #At the end of each line there is a new space.\n            line = line[1:] #Ignored the addresses.\n            for hex_word in line:\n                if hex_word == \"??\":\n                    feature_matrix[k][256] += 1\n                else:\n                     feature_matrix[k][int(hex_word, 16)] += 1 #int(hex_word, 16) will return decimal equivalent.\n    string_for_each_file = \"\"\n    for i in feature_matrix[k]:\n        string_for_each_file = string_for_each_file + str(i) + \",\"\n    string_for_each_file = string_for_each_file[:-1]\n    byte_count_vectors.write(string_for_each_file)\n    byte_count_vectors.write(\"\\n\")\n    each_file.close()\n    k += 1\n\nbyte_count_vectors.close()\nprint(\"The code has executed----------------------------------------------------------------------------->>>>>>>>>>>>\")\n\n\"\"\"","7009e459":"#Byte file size.\n\n\"\"\"\n\ndef calculate_byte_file_size(class_labels):\n#It calculate size of each file in MB.\n\n fname = [] #Stores the name of each file.\n fsize = [] #Stores the size of each file respectively.\n flabels = [] #Stores respective labels of malware\n\n for file in tqdm(os.listdir(\".\/byte_files\")):\n  file_name = file.split('.')[0]\n  fname.append(file_name)\n  size_in_mb = (os.stat(\".\/byte_files\/\"+file).st_size)\/(1024.0*1024.0)\n  fsize.append(size_in_mb)\n  flabels.append(int(class_labels[class_labels[\"Id\"] == file_name][\"Class\"]))\n \n file_size_df = pd.DataFrame({\"Class\":flabels, \"Id\": fname, \"fsize\": fsize})\n \n if not os.path.exists(\".\/byte_file_size.csv\"):\n  file_size_df.to_csv(\".\/byte_file_size.csv\", index = False)\n \n print(file_size_df.head())\n\n print(\"size calculated and stored in csv\")\n\n#Call the function.\nclass_labels = pd.read_csv(\".\/trainLabels.csv\")\ncalculate_byte_file_size(class_labels)\n\n\"\"\"\n\n#Finally merge count vectors, file sizes and class labels. Store in a single output file, bye_count_vectors.csv","6efdddc7":"\"\"\"'\ndata = pd.read_csv(\"..\/input\/byte_count_vectors.csv\")\ndata = data.set_index(\"Id\")\ncount_vector_data = data.drop(['Class', 'fsize'], axis=1)\ncount_vector_data['entropy'] = 0.0\nentropies = []\n\n\nfor idx, rows in tqdm(count_vector_data.iterrows()):\n    entropy = 0.0\n    for elem in rows.index:\n        if(rows[elem]):\n            entropy = entropy - ( ((rows[elem]\/rows.sum()) * log(rows[elem]\/rows.sum())))\n    \n    entropies.append(entropy)\n\ncount_vector_data['entropy'] = entropies\n\ndata['entropy'] = count_vector_data['entropy']\n\n#byte_entropy.to_csv(\"byte_entropy.csv\")'\"\"\"","41b0d2c9":"#ASM file count vectors.\n#We will divide asm files in 3 different folders, 'first', 'second', 'third' respectively. \n#It will helpp us in multiprogramming.\n\"\"\"\ndef firstprocess():\n    list_of_dics = []\n    files  = os.listdir(\".\/first\") \n    for file in tqdm(files):\n        filename = file.split('.')[0]\n        prefixes = {'HEADER:': 0, '.text:': 0, '.Pav:': 0, '.idata:': 0, '.data:': 0, '.bss:': 0, '.rdata:': 0, '.edata:': 0, '.rsrc:': 0, '.tls:': 0, '.reloc:': 0, '.BSS:': 0, '.CODE': 0}\n        opcode = {'add': 0, 'al': 0, 'bt': 0, 'call': 0, 'cdq': 0, 'cld': 0, 'cli': 0, 'cmc': 0, 'cmp': 0, 'const': 0, 'cwd': 0, 'daa': 0, 'db': 0, 'dd': 0,\n                 'dec': 0, 'dw': 0, 'endp': 0, 'ends': 0, 'faddp': 0, 'fchs': 0, 'fdiv': 0, 'fdivp': 0, 'fdivr': 0, 'fild': 0, 'fistp': 0, 'fld': 0,\n                  'fstcw': 0, 'fstcwimul': 0, 'fstp': 0, 'fword': 0, 'fxch': 0, 'imul': 0, 'in': 0, 'inc': 0, 'ins': 0, 'int': 0, 'jb': 0, 'je': 0, 'jg': 0,\n                   'jge': 0, 'jl': 0, 'jmp': 0, 'jnb': 0, 'jno': 0, 'jnz': 0, 'jo': 0, 'jz': 0, 'lea': 0, 'loope': 0, 'mov': 0, 'movzx': 0, 'mul': 0,\n                    'near': 0, 'neg': 0, 'not': 0, 'or': 0, 'out': 0, 'outs': 0, 'pop': 0, 'popf': 0, 'proc': 0, 'push': 0, 'pushf': 0, 'rcl': 0, 'rcr': 0,\n                    'rdtsc': 0, 'rep': 0, 'ret': 0, 'retn': 0, 'rol': 0, 'ror': 0, 'sal': 0, 'sar': 0, 'sbb': 0, 'scas': 0, 'setb': 0, 'setle': 0,\n                     'setnle': 0, 'setnz': 0, 'setz': 0, 'shl': 0, 'shld': 0, 'shr': 0, 'sidt': 0, 'stc': 0, 'std': 0, 'sti': 0, 'stos': 0, 'sub': 0,\n                     'test': 0, 'wait': 0, 'xchg': 0, 'xor': 0, 'retf': 0, 'nop': 0, 'rtn': 0}\n        #Opcodes were changed after dchad solution.\n        keywords = {'.dll' : 0, 'std::' : 0, ':dword' : 0}\n        registers = {'edx': 0, 'esi': 0, 'es': 0, 'fs': 0, 'ds': 0, 'ss': 0, 'gs': 0, 'cs': 0, 'ah': 0, 'al': 0, 'ax': 0, 'bh': 0, 'bl': 0, 'bx': 0,\n                    'ch': 0, 'cl': 0, 'cx': 0, 'dh': 0, 'dl': 0, 'dx': 0, 'eax': 0, 'ebp': 0, 'ebx': 0, 'ecx': 0, 'edi': 0, 'esp': 0, 'eip': 0}\n        #Registers were changed after dchad solution.\n        current_file = open(\".\/first\/\"+file, \"r\", encoding =\"cp1252\", errors = \"replace\")\n        for lines in current_file:\n            line = lines.rstrip().split()\n            prefix = line[0]\n            rest_of_line = line[1:]        \n            #Check for prefixes\n            for key in prefixes.keys():\n                if key in prefix:\n                    prefixes[key] += 1\n            #Check for keywords\n            for key in keywords.keys():\n                for word in rest_of_line:\n                    if key in word: #Because we need to match substring.\n                        keywords[key] += 1\n            #Check for opcodes\n            for key in opcode.keys():\n                for word in rest_of_line:\n                    if key==word: #Because we need to match exact string.\n                        opcode[key] += 1\n            #Check for registers\n            if ('text' in prefix or 'CODE' in prefix):\n                for key in registers.keys():\n                    for word in rest_of_line:\n                        if key in word:\n                            registers[key] += 1\n        current_file.close()\n        final_dic = {'Id': filename, }\n        #final_dic['Id'] = filename\n        for key,values in prefixes.items():\n            final_dic[key] = values\n        for key,values in keywords.items():\n            final_dic[key] = values\n        for key,values in opcode.items():\n            final_dic[key] = values\n        for key,values in registers.items():\n            final_dic[key] = values\n        list_of_dics.append(final_dic)\n    first_df = pd.DataFrame(list_of_dics)\n    first_df = first_df.set_index(\"Id\")\n    first_df.to_csv(\".\/first\/firstfile.csv\")\n    \ndef secondprocess():\n    list_of_dics = []\n    files  = os.listdir(\".\/second\")\n    for file in tqdm(files):\n        filename = file.split('.')[0]\n        prefixes = {'HEADER:': 0, '.text:': 0, '.Pav:': 0, '.idata:': 0, '.data:': 0, '.bss:': 0, '.rdata:': 0, '.edata:': 0, '.rsrc:': 0, '.tls:': 0, '.reloc:': 0, '.BSS:': 0, '.CODE': 0}\n        opcode = {'add': 0, 'al': 0, 'bt': 0, 'call': 0, 'cdq': 0, 'cld': 0, 'cli': 0, 'cmc': 0, 'cmp': 0, 'const': 0, 'cwd': 0, 'daa': 0, 'db': 0, 'dd': 0,\n                 'dec': 0, 'dw': 0, 'endp': 0, 'ends': 0, 'faddp': 0, 'fchs': 0, 'fdiv': 0, 'fdivp': 0, 'fdivr': 0, 'fild': 0, 'fistp': 0, 'fld': 0,\n                  'fstcw': 0, 'fstcwimul': 0, 'fstp': 0, 'fword': 0, 'fxch': 0, 'imul': 0, 'in': 0, 'inc': 0, 'ins': 0, 'int': 0, 'jb': 0, 'je': 0, 'jg': 0,\n                   'jge': 0, 'jl': 0, 'jmp': 0, 'jnb': 0, 'jno': 0, 'jnz': 0, 'jo': 0, 'jz': 0, 'lea': 0, 'loope': 0, 'mov': 0, 'movzx': 0, 'mul': 0,\n                    'near': 0, 'neg': 0, 'not': 0, 'or': 0, 'out': 0, 'outs': 0, 'pop': 0, 'popf': 0, 'proc': 0, 'push': 0, 'pushf': 0, 'rcl': 0, 'rcr': 0,\n                    'rdtsc': 0, 'rep': 0, 'ret': 0, 'retn': 0, 'rol': 0, 'ror': 0, 'sal': 0, 'sar': 0, 'sbb': 0, 'scas': 0, 'setb': 0, 'setle': 0,\n                     'setnle': 0, 'setnz': 0, 'setz': 0, 'shl': 0, 'shld': 0, 'shr': 0, 'sidt': 0, 'stc': 0, 'std': 0, 'sti': 0, 'stos': 0, 'sub': 0,\n                     'test': 0, 'wait': 0, 'xchg': 0, 'xor': 0, 'retf': 0, 'nop': 0, 'rtn': 0}\n        #Opcodes were changed after dchad solution.\n        keywords = {'.dll' : 0, 'std::' : 0, ':dword' : 0}\n        registers = {'edx': 0, 'esi': 0, 'es': 0, 'fs': 0, 'ds': 0, 'ss': 0, 'gs': 0, 'cs': 0, 'ah': 0, 'al': 0, 'ax': 0, 'bh': 0, 'bl': 0, 'bx': 0,\n                    'ch': 0, 'cl': 0, 'cx': 0, 'dh': 0, 'dl': 0, 'dx': 0, 'eax': 0, 'ebp': 0, 'ebx': 0, 'ecx': 0, 'edi': 0, 'esp': 0, 'eip': 0}\n        #Registers were changed after dchad solution.\n        current_file = open(\".\/second\/\"+file, \"r\", encoding =\"cp1252\", errors = \"replace\")\n        for lines in current_file:\n            line = lines.rstrip().split()\n            prefix = line[0]\n            rest_of_line = line[1:]    \n            #Check for prefixes\n            for key in prefixes.keys():\n                if key in prefix:\n                    prefixes[key] += 1\n            #Check for keywords\n            for key in keywords.keys():\n                for word in rest_of_line:\n                    if key in word: #Because we need to match substring.\n                        keywords[key] += 1\n            #Check for opcodes\n            for key in opcode.keys():\n                for word in rest_of_line:\n                    if key==word: #Because we need to match exact string.\n                        opcode[key] += 1\n            #Check for registers\n            if ('text' in prefix or 'CODE' in prefix):\n                for key in registers.keys():\n                    for word in rest_of_line:\n                        if key in word:\n                            registers[key] += 1\n        current_file.close()\n        final_dic = {'Id': filename, }\n        #final_dic['Id'] = filename\n        for key,values in prefixes.items():\n            final_dic[key] = values\n        for key,values in keywords.items():\n            final_dic[key] = values\n        for key,values in opcode.items():\n            final_dic[key] = values\n        for key,values in registers.items():\n            final_dic[key] = values\n        list_of_dics.append(final_dic)\n    first_df = pd.DataFrame(list_of_dics)\n    first_df = first_df.set_index(\"Id\")\n    first_df.to_csv(\".\/second\/secondfile.csv\")\n\ndef thirdprocess():\n    list_of_dics = []\n    files  = os.listdir(\".\/third\")\n    for file in tqdm(files):\n        filename = file.split('.')[0]\n        filename = file.split('.')[0]\n        prefixes = {'HEADER:': 0, '.text:': 0, '.Pav:': 0, '.idata:': 0, '.data:': 0, '.bss:': 0, '.rdata:': 0, '.edata:': 0, '.rsrc:': 0, '.tls:': 0, '.reloc:': 0, '.BSS:': 0, '.CODE': 0}\n        opcode = {'add': 0, 'al': 0, 'bt': 0, 'call': 0, 'cdq': 0, 'cld': 0, 'cli': 0, 'cmc': 0, 'cmp': 0, 'const': 0, 'cwd': 0, 'daa': 0, 'db': 0, 'dd': 0,\n                 'dec': 0, 'dw': 0, 'endp': 0, 'ends': 0, 'faddp': 0, 'fchs': 0, 'fdiv': 0, 'fdivp': 0, 'fdivr': 0, 'fild': 0, 'fistp': 0, 'fld': 0,\n                  'fstcw': 0, 'fstcwimul': 0, 'fstp': 0, 'fword': 0, 'fxch': 0, 'imul': 0, 'in': 0, 'inc': 0, 'ins': 0, 'int': 0, 'jb': 0, 'je': 0, 'jg': 0,\n                   'jge': 0, 'jl': 0, 'jmp': 0, 'jnb': 0, 'jno': 0, 'jnz': 0, 'jo': 0, 'jz': 0, 'lea': 0, 'loope': 0, 'mov': 0, 'movzx': 0, 'mul': 0,\n                    'near': 0, 'neg': 0, 'not': 0, 'or': 0, 'out': 0, 'outs': 0, 'pop': 0, 'popf': 0, 'proc': 0, 'push': 0, 'pushf': 0, 'rcl': 0, 'rcr': 0,\n                    'rdtsc': 0, 'rep': 0, 'ret': 0, 'retn': 0, 'rol': 0, 'ror': 0, 'sal': 0, 'sar': 0, 'sbb': 0, 'scas': 0, 'setb': 0, 'setle': 0,\n                     'setnle': 0, 'setnz': 0, 'setz': 0, 'shl': 0, 'shld': 0, 'shr': 0, 'sidt': 0, 'stc': 0, 'std': 0, 'sti': 0, 'stos': 0, 'sub': 0,\n                     'test': 0, 'wait': 0, 'xchg': 0, 'xor': 0, 'retf': 0, 'nop': 0, 'rtn': 0}\n        #Opcodes were changed after dchad solution.\n        keywords = {'.dll' : 0, 'std::' : 0, ':dword' : 0}\n        registers = {'edx': 0, 'esi': 0, 'es': 0, 'fs': 0, 'ds': 0, 'ss': 0, 'gs': 0, 'cs': 0, 'ah': 0, 'al': 0, 'ax': 0, 'bh': 0, 'bl': 0, 'bx': 0,\n                    'ch': 0, 'cl': 0, 'cx': 0, 'dh': 0, 'dl': 0, 'dx': 0, 'eax': 0, 'ebp': 0, 'ebx': 0, 'ecx': 0, 'edi': 0, 'esp': 0, 'eip': 0}\n        #Registers were changed after dchad solution.\n        current_file = open(\".\/third\/\"+file, \"r\", encoding =\"cp1252\", errors = \"replace\")\n        for lines in current_file:\n            line = lines.rstrip().split()\n            prefix = line[0]\n            rest_of_line = line[1:]        \n            #Check for prefixes\n            for key in prefixes.keys():\n                if key in prefix:\n                    prefixes[key] += 1\n            #Check for keywords\n            for key in keywords.keys():\n                for word in rest_of_line:\n                    if key in word: #Because we need to match substring.\n                        keywords[key] += 1\n            #Check for opcodes\n            for key in opcode.keys():\n                for word in rest_of_line:\n                    if key==word: #Because we need to match exact string.\n                        opcode[key] += 1\n            #Check for registers\n            if ('text' in prefix or 'CODE' in prefix):\n                for key in registers.keys():\n                    for word in rest_of_line:\n                        if key in word:\n                            registers[key] += 1\n        current_file.close()\n        final_dic = {'Id': filename, }\n        #final_dic['Id'] = filename\n        for key,values in prefixes.items():\n            final_dic[key] = values\n        for key,values in keywords.items():\n            final_dic[key] = values\n        for key,values in opcode.items():\n            final_dic[key] = values\n        for key,values in registers.items():\n            final_dic[key] = values\n        list_of_dics.append(final_dic)\n    first_df = pd.DataFrame(list_of_dics)\n    first_df = first_df.set_index(\"Id\")\n    first_df.to_csv(\".\/third\/thirdfile.csv\")\n    \ndef main():\n    p1=Process(target=firstprocess)\n    p2=Process(target=secondprocess)\n    p3=Process(target=thirdprocess)\n    #p4=Process(target=fourthprocess)\n    #p5=Process(target=fifthprocess)\n    #p1.start() is used to start the thread execution\n    p1.start()\n    p2.start()\n    p3.start()\n    #p4.start()\n    #p5.start()\n    #After completion all the threads are joined\n    p1.join()\n    p2.join()\n    p3.join()\n    #p4.join()\n    #p5.join()\n\nif __name__==\"__main__\":\n    main()\n\"\"\"","8f2242fa":"\"\"\"\ndef firstprocess():\n    list_of_dics = []\n    files  = os.listdir(\".\/first\")\n    for file in tqdm(files):\n        filename = file.split('.')[0]\n        current_file = open(\".\/first\/\"+file, mode = \"rb\")\n        ln = os.path.getsize(\".\/first\/\"+file)\n        width = int(ln**0.5)\n        rem = ln%width\n        a = (array.array(\"B\"))\n        a.fromfile(current_file, ln-rem)\n        g = np.reshape(a, (len(a)\/\/width, width))\n        g = np.uint8(g)\n        final_image_feature_array = g.flatten()[0:1000]\n        current_file.close()\n        keys = list(\"img_feature_\"+ str(i) for i in range(0,1000))\n        final_dic = {'Id': filename, }\n        for key in keys:\n            final_dic[key] =  final_image_feature_array[int(key.split('_')[2])]\n        list_of_dics.append(final_dic)\n\t\n    first_df = pd.DataFrame(list_of_dics)\n    first_df = first_df.set_index(\"Id\")\n    first_df.to_csv(\".\/first\/image_feature_firstfile.csv\")\n    \ndef secondprocess():\n    list_of_dics = []\n    files  = os.listdir(\".\/second\")\n    for file in tqdm(files):\n        filename = file.split('.')[0]\n        current_file = open(\".\/second\/\"+file, mode = \"rb\")\n        ln = os.path.getsize(\".\/second\/\"+file)\n        width = int(ln**0.5)\n        rem = ln%width\n        a = (array.array(\"B\"))\n        a.fromfile(current_file, ln-rem)\n        g = np.reshape(a, (len(a)\/\/width, width))\n        g = np.uint8(g)\n        final_image_feature_array = g.flatten()[0:1000]\n        current_file.close()\n        keys = list(\"img_feature_\"+ str(i) for i in range(0,1000))\n        final_dic = {'Id': filename, }\n        for key in keys:\n            final_dic[key] =  final_image_feature_array[int(key.split('_')[2])]\n        list_of_dics.append(final_dic)\n\t\n    first_df = pd.DataFrame(list_of_dics)\n    first_df = first_df.set_index(\"Id\")\n    first_df.to_csv(\".\/second\/image_feature_secondfile.csv\")\n\ndef thirdprocess():\n    list_of_dics = []\n    files  = os.listdir(\".\/third\")\n    for file in tqdm(files):\n        filename = file.split('.')[0]\n        current_file = open(\".\/third\/\"+file, mode = \"rb\")\n        ln = os.path.getsize(\".\/third\/\"+file)\n        width = int(ln**0.5)\n        rem = ln%width\n        a = (array.array(\"B\"))\n        a.fromfile(current_file, ln-rem)\n        g = np.reshape(a, (len(a)\/\/width, width))\n        g = np.uint8(g)\n        final_image_feature_array = g.flatten()[0:1000]\n        current_file.close()\n        keys = list(\"img_feature_\"+ str(i) for i in range(0,1000))\n        final_dic = {'Id': filename, }\n        for key in keys:\n            final_dic[key] =  final_image_feature_array[int(key.split('_')[2])]\n        list_of_dics.append(final_dic)\n\t\n    first_df = pd.DataFrame(list_of_dics)\n    first_df = first_df.set_index(\"Id\")\n    first_df.to_csv(\".\/third\/image_feature_thirdfile.csv\")\n    \ndef main():\n    print(time.ctime())\n    p1=Process(target=firstprocess)\n    p2=Process(target=secondprocess)\n    p3=Process(target=thirdprocess)\n    #p4=Process(target=fourthprocess)\n    #p5=Process(target=fifthprocess)\n    #p1.start() is used to start the thread execution\n    p1.start()\n    p2.start()\n    p3.start()\n    #p4.start()\n    #p5.start()\n    #After completion all the threads are joined\n    p1.join()\n    p2.join()\n    p3.join()\n    print(time.ctime())\n    #p4.join()\n    #p5.join()\n\nif __name__==\"__main__\":\n    main()\n\n\"\"\"","b73793c3":"asm_final_features = pd.read_csv(\"..\/input\/asm_final_features.csv\")\nasm_final_features.head()","bd6f6fed":"asm_final_features = asm_final_features.set_index(\"Id\")","3409a9da":"asm_final_features.head()","526f7bfb":"byte_final_features = pd.read_csv(\"..\/input\/byte_final_features.csv\")\nbyte_final_features.head()","555c845a":"## 1.5 Summary on Feature Extraction of byte files","70592661":"**Example data point of .byte file**\n\n<pre>\n00401000 00 00 80 40 40 28 00 1C 02 42 00 C4 00 20 04 20\n00401010 00 00 20 09 2A 02 00 00 00 00 8E 10 41 0A 21 01\n00401020 40 00 02 01 00 90 21 00 32 40 00 1C 01 40 C8 18\n00401030 40 82 02 63 20 00 00 09 10 01 02 21 00 82 00 04\n00401040 82 20 08 83 00 08 00 00 00 00 02 00 60 80 10 80\n00401050 18 00 00 20 A9 00 00 00 00 04 04 78 01 02 70 90\n00401060 00 02 00 08 20 12 00 00 00 40 10 00 80 00 40 19\n00401070 00 00 00 00 11 20 80 04 80 10 00 20 00 00 25 00\n00401080 00 00 01 00 00 04 00 10 02 C1 80 80 00 20 20 00\n00401090 08 A0 01 01 44 28 00 00 08 10 20 00 02 08 00 00\n004010A0 00 40 00 00 00 34 40 40 00 04 00 08 80 08 00 08\n004010B0 10 00 40 00 68 02 40 04 E1 00 28 14 00 08 20 0A\n004010C0 06 01 02 00 40 00 00 00 00 00 00 20 00 02 00 04\n004010D0 80 18 90 00 00 10 A0 00 45 09 00 10 04 40 44 82\n004010E0 90 00 26 10 00 00 04 00 82 00 00 00 20 40 00 00\n004010F0 B4 00 00 40 00 02 20 25 08 00 00 00 00 00 00 00\n00401100 08 00 00 50 00 08 40 50 00 02 06 22 08 85 30 00\n00401110 00 80 00 80 60 00 09 00 04 20 00 00 00 00 00 00\n00401120 00 82 40 02 00 11 46 01 4A 01 8C 01 E6 00 86 10\n00401130 4C 01 22 00 64 00 AE 01 EA 01 2A 11 E8 10 26 11\n00401140 4E 11 8E 11 C2 00 6C 00 0C 11 60 01 CA 00 62 10\n00401150 6C 01 A0 11 CE 10 2C 11 4E 10 8C 00 CE 01 AE 01\n00401160 6C 10 6C 11 A2 01 AE 00 46 11 EE 10 22 00 A8 00\n00401170 EC 01 08 11 A2 01 AE 10 6C 00 6E 00 AC 11 8C 00\n00401180 EC 01 2A 10 2A 01 AE 00 40 00 C8 10 48 01 4E 11\n00401190 0E 00 EC 11 24 10 4A 10 04 01 C8 11 E6 01 C2 00\n\n<\/pre>","8538a877":"## 1.2 Byte file size","345233b2":"## 2.2 ASM files image features","87ac9a9b":"* byte_final_features have all the data extracted from byte files.\n* asm_final_features have all the data extracted from asm files.","f5d982b8":"**Features involve :-**\n* ASM files count vectors.\n* Image features of each file.\n* ASM files size.","c8fbb393":"**Features involve :-**\n* Byte files count vectors.\n* Entropy of every file.\n* Byte files size.","723d0307":"# 1. Byte Files","3de7b816":"# 2. ASM Files","bbbc0353":"1. For byte file cout vectors, we have used simple bag of words to count the appeareance of each hex (eg: f3,f2,ff etc) in a data file.\n1. For byte file size , we have calculated the size of each .byte file.\n1. **'byte_count_vectors.csv'** contains BoW, file size in a dataframe.\n1. **'byte_entropy.csv'** contains entropy of each file. We hvae utilized the idea of the entropy of a file. We already had our count vectors in 'byte_count_vectors.csv', from which we have calculated the entropy of each and every single file.\n1. We could'nt utilized the idea of bi-grams, n-grams since somehow our machine failed in terms of memory.\n1. **'byte_final_features.csv'** consist of all above data combined, i.e count_vectors,file_size,entropy ina  single file.","813ee618":"## 1.3 Byte files entropy","592ab641":" ## 1.1 Byte files count vectors","98449533":"# Final summary","04b22fef":"1. We divided asm files in three different folders 'first', 'second', 'third' to do multiprogramming.\n1. Each will return a different csv files. \n> firstfile.csv, image_feature_firstfile.csv containing count vectors and image features of all thee files of 'first' folder and so on.\n1. **asm_count_vectors.csv** consist of count vectors of all thee asm files.\n1. **asm_file_size.csv** consist of the file sizes of all the asm files.\n1. **asm_final_features.csv** consist of all the count_vectors, image_features and file_sizes commbined. ","a69fc0e6":"## 2.1 ASM files count vectors"}}