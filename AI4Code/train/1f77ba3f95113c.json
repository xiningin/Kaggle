{"cell_type":{"8afa6d4d":"code","0a6f9889":"code","22d2b5c2":"code","fb4820be":"code","739920c0":"code","67547c1e":"code","17adc0d5":"code","72e54cd3":"code","cacda842":"code","6795ccbc":"code","feae4bd7":"code","bdae8cd6":"code","4008919a":"code","aca0985d":"code","7924d004":"code","e2fab5f6":"code","cd3541e5":"code","851d7cb9":"code","81c9b281":"code","858fb0a6":"code","9854a769":"code","d6d469a5":"code","45910db7":"code","969771bb":"code","ab219952":"code","4827e1fa":"code","da5e0e58":"code","9fdf31af":"code","38a2df10":"code","5ee7101f":"code","3f7601ba":"code","1fb29f8f":"code","a39a623c":"code","7ea6adea":"code","87e874db":"code","c72dcf47":"code","e6e7d5c0":"code","e33d77fe":"code","629e450a":"code","97418292":"code","0d4f8356":"code","733061b6":"code","bc75a6b7":"code","995b955f":"markdown","bcc5bade":"markdown","51da137f":"markdown","8761bff3":"markdown","57f8d9b6":"markdown","4a1f5640":"markdown","54b32b77":"markdown","77e7b933":"markdown","fec5b9d1":"markdown","20add2ae":"markdown","f5d9e0a5":"markdown","f0883a23":"markdown","4a528be3":"markdown","8434717c":"markdown","1195f990":"markdown","071ed874":"markdown","15692e7d":"markdown","7bdea044":"markdown"},"source":{"8afa6d4d":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nimport os \nimport cv2\nimport random\n \nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split \n\nimport warnings \nwarnings.filterwarnings(\"ignore\")","0a6f9889":"print(tf.__version__)","22d2b5c2":"os.listdir('..\/input\/petfinder-pawpularity-score')","fb4820be":"data = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nss = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')","739920c0":"data_dir = \"..\/input\/petfinder-pawpularity-score\/train\/\"\ntest_dir = \"..\/input\/petfinder-pawpularity-score\/test\/\"","67547c1e":"data.shape","17adc0d5":"data.head()","72e54cd3":"_, axs = plt.subplots( 2, 2, figsize=(15, 12))\n\naxs = axs.flatten()\ncol = data.columns.tolist() \n\nfor a, ax in zip(data.sample(4).iterrows(), axs):\n    img = cv2.imread(data_dir + f'{a[1][0]}.jpg')\n    img = cv2.resize(img, (600, 600))\n    other_info = [col[i] for i in range(13) if a[1][i] == 1 ]\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img)\n    ax.set_title(f'Id: {a[0]}, Pawpularity : {a[1][13]}, ' + \", \".join(other_info), fontsize= 12, fontweight='bold' )\n    \nplt.show()","cacda842":"data = data[[\"Id\",\"Pawpularity\"] ]  ","6795ccbc":"train,val  = train_test_split( data, test_size=0.2) ## Approx 500 images for validation ","feae4bd7":"train.shape","bdae8cd6":"val.shape","4008919a":"filenames = tf.constant(train.Id.map(lambda x : data_dir + f'{x}.jpg' ).tolist())\nlabels = tf.constant( train.Pawpularity.tolist())\ndataset = tf.data.Dataset.from_tensor_slices((filenames, labels))","aca0985d":"val_filenames = tf.constant(val.Id.map(lambda x : data_dir + f'{x}.jpg' ).tolist())\nval_labels = tf.constant( val.Pawpularity.tolist() )\nval_dataset = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))","7924d004":"list(dataset.as_numpy_iterator())[:5]","e2fab5f6":"### Hyperparams \n\nBATCH_SIZE = 64\nIMG_SIZE = (224, 224) \n","cd3541e5":"def _parse_function(filename, output ):\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string)\n    image_resized = tf.image.resize(image_decoded, IMG_SIZE)\n    return image_resized, output","851d7cb9":"dataset = dataset.map(_parse_function)\nval_dataset = val_dataset.map(_parse_function)","81c9b281":"dataset = dataset.batch(BATCH_SIZE) \nval_dataset = val_dataset.batch(BATCH_SIZE) ","858fb0a6":"normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)","9854a769":"dataset = dataset.map(lambda x, y: (normalization_layer(x), y))\nval_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))","d6d469a5":"AUTOTUNE = tf.data.AUTOTUNE\ndataset = dataset.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)\nval_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE) ## We dont need to shuffel the validation data ","45910db7":"# # Print one key val pair \n\nbatch_data = list(next(dataset.as_numpy_iterator()))\nprint(batch_data[0][0])\nprint(batch_data[1][0])","969771bb":"data_augmentation = tf.keras.Sequential(\n  [\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n                      input_shape=(IMG_SIZE[0],\n                                  IMG_SIZE[1],\n                                  3)),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)","ab219952":"plt.figure(figsize=(10, 10))\n\nfor images, _ in dataset.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        # we are multiplaying the numpy array to 255 because we had normalized the dataset to [ 0, 1] \n        plt.imshow((augmented_images[0].numpy()*255).astype(\"uint8\")) \n        plt.axis(\"off\")","4827e1fa":"# Create the base model from the pre-trained model MobileNet V2\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.ResNet152V2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","da5e0e58":"#Freeze the convolutional base\nbase_model.trainable = False","9fdf31af":"# base_model.summary()","38a2df10":"class ImageModel(tf.keras.Model):\n\n    def __init__(self):\n\n        super(ImageModel, self).__init__()\n\n        self.input_l = tf.keras.layers.InputLayer( input_shape = IMG_SIZE + (3,)  ) \n        \n        self.base_model = base_model\n        self.preprocess_input = tf.keras.applications.resnet_v2.preprocess_input \n        self.data_augmentation = tf.keras.Sequential([\n                                tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n                                tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n                                ])\n        self.gap = tf.keras.layers.GlobalAveragePooling2D() ##  ( batch_size , 2048 )\n\n        self.activation = tf.keras.layers.LeakyReLU( alpha=0.15 )\n        self.activation_final = tf.keras.layers.ReLU(max_value = 100 ) # since the maximum score can be 100 \n        \n        self.dense_1 = tf.keras.layers.Dense(512, activation= self.activation )\n        self.dense_2 = tf.keras.layers.Dense(128, activation= self.activation )\n        self.dense_3 = tf.keras.layers.Dense(32, activation= self.activation  )\n        self.final = tf.keras.layers.Dense(1, activation= self.activation_final )\n\n        \n    def call(self, input_tensor):\n\n        x = self.input_l(input_tensor)\n        x = self.data_augmentation(x)\n        x = self.preprocess_input(x)\n        x = self.base_model(x)\n        x = self.gap(x)\n\n        x = self.dense_1(x)\n        x = self.dense_2(x)\n        x = self.dense_3(x)\n        x = self.final(x)\n \n        return  x","5ee7101f":"def create_model():\n    \n    model = ImageModel()\n    \n    model.compile(\n        optimizer='adam', \n        loss=\"mse\", # Mean squared error \n        metrics=[\"mae\"] # Mean Absolute Error\n      )\n    \n    return model ","3f7601ba":"CNN_regressor = create_model()","1fb29f8f":"epochs = 20\n\ncheckpoint_path = \"cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\nes_callback = tf.keras.callbacks.EarlyStopping(\n                                monitor='val_mae',\n                                patience=3,\n                                verbose=1,\n                                restore_best_weights=True)\n\nhistory = CNN_regressor.fit(\n                    dataset,\n                    validation_data = val_dataset, \n                    epochs=epochs,\n                    callbacks = [cp_callback , es_callback ] ,\n                    )","a39a623c":"saved_checkpoint_path = \"cp.ckpt\"","7ea6adea":"# Create a basic model instance\nmodel = create_model()\n\n# Loads the weights\nmodel.load_weights(saved_checkpoint_path)","87e874db":"def _parse_function_test(filename ):\n    image_string = tf.io.read_file(filename)\n    image_decoded = tf.image.decode_jpeg(image_string)\n    image_resized = tf.image.resize(image_decoded, IMG_SIZE)\n    return image_resized ","c72dcf47":"test_filenames = tf.constant(test.Id.map(lambda x : test_dir + f'{x}.jpg' ).tolist())\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_filenames))\ntest_dataset = test_dataset.map(_parse_function_test)\ntest_dataset = test_dataset.map(lambda x: (normalization_layer(x)))","e6e7d5c0":"test_dataset = test_dataset.batch(len(test))","e33d77fe":"predictions = model.predict(test_dataset)","629e450a":"ss.head()","97418292":"submission = pd.DataFrame()\nsubmission[\"Id\"] = test[\"Id\"]\nsubmission[\"Pawpularity\"]= predictions","0d4f8356":"submission.head()","733061b6":"ss.columns.equals(submission.columns)","bc75a6b7":"submission.to_csv('submission.csv', index=False)","995b955f":"### Visualize the data","bcc5bade":"### Compile and train the model","51da137f":"### Configure the dataset for performance\n* **Dataset.cache** keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n* **Dataset.prefetch** overlaps data preprocessing and model execution while training.\n ","8761bff3":"### Standardize the data\n\nThe RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general we should seek to make your input values small.\n\nHere, we will standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling","57f8d9b6":"### Batching ","4a1f5640":"#### Lets check a datapoint ","54b32b77":"### Load the saved model ","77e7b933":"## Predict on test data","fec5b9d1":"## Data preprocessing\n\n ","20add2ae":"## Model Developement ","f5d9e0a5":"### Data Augmentation \n\n> This helps expose the model to more aspects of the data and generalize better.","f0883a23":"### Imports","4a528be3":"### File names to images","8434717c":" ## Problem description\n\nPetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. \n\nWhile this basic tool is helpful, it's still in an experimental stage and the algorithm could be improved. The participants needs to build an AI model using provided data to help make the tool better.  \n\n**Task** \n\nThe task is to predict engagement with a pet's profile( **Pawpularity** ) based on the photograph for that profile. \n\n**Data** \n\nThe dataset for this competition comprises both images and tabular data(hand-labelled metadata for each photo). \n\nThe train set contains 9912 pet photos \n\nThe test set contains 8 pet photos\n> NOTE: The actual test data comprises about **6800** pet photos similar to the training set photos. \n\n\n####  **Previous Notebooks**: \n1. [*Understanding the problem & EDA*](https:\/\/www.kaggle.com\/vivmankar\/understanding-the-problem-eda) \n2. [*ML RandomForestRegressor*](https:\/\/www.kaggle.com\/vivmankar\/ml-randomforestregressor)","1195f990":"We will use ResNet152V2 as a base model, other opctions for pretrained models can be found [here](https:\/\/keras.io\/api\/applications\/)\n ","071ed874":"## Data ","15692e7d":"## Overview of the Notebook\n\nIn this notebook we will discuss the transfer learning approch to the problem \n\n#### Data preprocessing\n\n>   1. Create the dataset( tf.data.dataset )\n>   2. Batching ( To speedup the treaning ) \n>   2. Standardize the data ( To speedup the treaning )\n>   3. Configure the dataset for performance ( To speedup the treaning )\n>   4. Data augmentation( adding an augmentation to the model ) \n\n#### Model Building \n\n>   1. Load the base model ( ResNet152V2 ) \n>   2. Develope a custom model class ( ImageModel(tf.keras.Model) ) \n>   3. Update last layer activation to ReLU(max_value = 100 ) \/\/ this helps improving performence \n>   4. Compile model and add callbacks ( Save-Checkpoint, Early Stopping ) \n>   5. Train Model ( MAE on validation split : 15.1742 ) \n","7bdea044":"#### Let's visualize what a few augmented examples look like by applying data augmentation to the same image several times"}}