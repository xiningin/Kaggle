{"cell_type":{"68a41c55":"code","4cf309e4":"code","47569819":"code","5d397b85":"code","7e631c22":"code","ea7f8b3d":"code","cf6d88f8":"code","ccfae761":"code","c3d97115":"code","48704988":"code","8d26c4a8":"code","44cd21c7":"code","7c74d11b":"code","88e0a18f":"code","4f7c2b39":"code","3dc6776f":"code","7506c79b":"code","ba0ad95a":"code","d3dceec7":"code","693d9ed2":"code","45a41fb9":"code","2390e891":"code","0e8093b2":"code","486e2150":"code","f29be79e":"code","dad421e2":"code","8e0a0cd8":"code","3b767537":"code","cd9cd6b7":"code","b99d0e2a":"code","87c7a0ca":"code","0e4829e3":"code","d91c1f8d":"code","2c02649d":"code","d097ae96":"code","d55c4dba":"code","11b41547":"code","056103b9":"code","dfff2a1e":"code","5ba95b60":"code","425154a5":"code","f97fc5ee":"code","67044730":"code","390d0afb":"code","d424f192":"code","3b0e92dc":"code","99fcf8a3":"code","c9ddbd20":"code","f485a7bc":"code","50a607d0":"code","d0a8e834":"code","fc5c1c29":"code","74dede4d":"markdown","58915fa1":"markdown","bda93153":"markdown","f78b0088":"markdown","44109bda":"markdown","1c6c84f4":"markdown","7f56f3f5":"markdown","44f14ea2":"markdown","32704466":"markdown"},"source":{"68a41c55":"import shutil\nimport numpy as np\nimport pandas as pd\nfrom random import random\n\n# Image operations and plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n%matplotlib inline\n\n# File, path and directory operations\nimport os\nimport os.path\nimport shutil\n\n\n# Model building\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *\nimport torchvision\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom pathlib import PurePath\n\n# For reproducability\nfrom numpy.random import seed\nseed(108)\n","4cf309e4":"print(os.listdir(\"..\/input\/skin-cancer-mnist-ham10000\"))","47569819":"# Create a new directory\nbase = \"base\"\nos.mkdir(base)","5d397b85":"\n#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n\n# now we create 7 folders inside 'base':\n\n# train\n    # nv\n    # mel\n    # bkl\n    # bcc\n    # akiec\n    # vasc\n    # df\n \n# valid\n    # nv\n    # mel\n    # bkl\n    # bcc\n    # akiec\n    # vasc\n    # df\n\n# create a path to 'base' to which we will join the names of the new folders\n# train\ntrain = os.path.join(base, 'train')\nos.mkdir(train)\n\n# valid\nvalid = os.path.join(base, 'valid')\nos.mkdir(valid)\n\n\n# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside train\nnv = os.path.join(train, 'nv')\nos.mkdir(nv)\nmel = os.path.join(train, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(train, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(train, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(train, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(train, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(train, 'df')\nos.mkdir(df)\n\n\n\n\n\n# test\ntest = os.path.join(base, 'test')\nos.mkdir(test)\n\nnv = os.path.join(test, 'nv')\nos.mkdir(nv)\nmel = os.path.join(test, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(test, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(test, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(test, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(test, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(test, 'df')\nos.mkdir(df)\n","7e631c22":"# create new folders inside valid\nnv = os.path.join(valid, 'nv')\nos.mkdir(nv)\nmel = os.path.join(valid, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(valid, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(valid, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(valid, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(valid, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(valid, 'df')\nos.mkdir(df)","ea7f8b3d":"import pandas as pd\ndf = pd.read_csv(\"..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv\")\n","cf6d88f8":"from numpy.random import seed\nseed(101)\ndf2=df.iloc[:,1:3]\nmsk = np.random.rand(len(df2)) < 0.85\ntrain1_df2 = df2[msk]\ntest_df2 = df2[~msk]\nmsk1 = np.random.rand(len(train1_df2)) < 0.85\ntrain_df2 = train1_df2[msk1]\nvalidation_df2 = train1_df2[~msk1]","ccfae761":"train_df2['dx'].value_counts()","c3d97115":"validation_df2['dx'].value_counts()","48704988":"test_df2['dx'].value_counts()","8d26c4a8":"# Set the image_id as the index in df_data\ndf.set_index('image_id', inplace=True)","44cd21c7":"# Get a list of images in each of the two folders\nfolder_1 = os.listdir('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1')\nfolder_2 = os.listdir('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2')","7c74d11b":"# Get a list of train , val and test images \ntrain_df2_list = list(train_df2['image_id'])\nvalidation_df2_list = list(validation_df2['image_id'])\ntest_df2_list = list(test_df2['image_id'])","88e0a18f":"# Transfer the train images\n\nfor image in train_df2_list:\n    \n    fname = image + '.jpg'\n    label = df.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(train, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(train, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)","4f7c2b39":"# Transfer the val images\n\nfor image in validation_df2_list:\n    \n    fname = image + '.jpg'\n    label = df.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(valid, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(valid, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n   \n        ","3dc6776f":"for image in test_df2_list:\n    \n    fname = image + '.jpg'\n    label = df.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(test, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(test, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)","7506c79b":"# check how many train images we have in each folder\nprint(\"..............................\")\nprint(\"Train folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/train\/nv')))\nprint(len(os.listdir('base\/train\/mel')))\nprint(len(os.listdir('base\/train\/bkl')))\nprint(len(os.listdir('base\/train\/bcc')))\nprint(len(os.listdir('base\/train\/akiec')))\nprint(len(os.listdir('base\/train\/vasc')))\nprint(len(os.listdir('base\/train\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"validation folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/valid\/nv')))\nprint(len(os.listdir('base\/valid\/mel')))\nprint(len(os.listdir('base\/valid\/bkl')))\nprint(len(os.listdir('base\/valid\/bcc')))\nprint(len(os.listdir('base\/valid\/akiec')))\nprint(len(os.listdir('base\/valid\/vasc')))\nprint(len(os.listdir('base\/valid\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"Test folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/test\/nv')))\nprint(len(os.listdir('base\/test\/mel')))\nprint(len(os.listdir('base\/test\/bkl')))\nprint(len(os.listdir('base\/test\/bcc')))\nprint(len(os.listdir('base\/test\/akiec')))\nprint(len(os.listdir('base\/test\/vasc')))\nprint(len(os.listdir('base\/test\/df')))","ba0ad95a":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')\nimg_path = load_img('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2\/ISIC_0029316.jpg',target_size=(224, 224))\n # this is a PIL image\nx = img_to_array(img_path)  # Numpy array with shape (224, 224, 3)\nx = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 224, 224, 3)\n\n# The .flow() command below generates batches of randomly transformed images\n# It will loop indefinitely, so we need to `break` the loop at some point!\ni = 0\nfor batch in datagen.flow(x, batch_size=1):\n  plt.figure(i)\n  imgplot = plt.imshow(array_to_img(batch[0]))\n  i += 1\n  if i % 5 == 0:\n    break","d3dceec7":"# note that we are not augmenting class 'nv'\nclass_list = ['mel','bkl','bcc','akiec','vasc','df']\n\nfor item in class_list:\n    \n    # We are creating temporary directories here because we delete these directories later\n    # create a base\n    aug = 'aug'\n    os.mkdir(aug)\n    # create a dir within the base to store images of the same class\n    img_dir = os.path.join(aug, 'img_dir')\n    os.mkdir(img_dir)\n\n    # Choose a class\n    img_class = item\n\n    # list all images in that directory\n    img_list = os.listdir('base\/train\/' + img_class)\n\n    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n    for fname in img_list:\n            # source path to image\n            src = os.path.join('base\/train\/' + img_class, fname)\n            # destination path to image\n            dst = os.path.join(img_dir, fname)\n            # copy the image from the source to the destination\n            shutil.copyfile(src, dst)\n\n\n    # point to a dir containing the images and not to the images themselves\n    path = aug\n    save_path = 'base\/train\/' + img_class\n\n    # Create a data generator\n    datagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        #brightness_range=(0.9,1.1),\n        fill_mode='nearest')\n\n    batch_size = 50\n\n    aug_datagen = datagen.flow_from_directory(path,\n                                           save_to_dir=save_path,\n                                           save_format='jpg',\n                                                    target_size=(224,224),\n                                                    batch_size=batch_size)\n\n\n\n    # Generate the augmented images and add them to the training folders\n    \n    ###########\n    \n    num_aug_images_wanted = 5000 # total number of images we want to have in each class\n    \n    ###########\n    \n    num_files = len(os.listdir(img_dir))\n    num_batches = int(np.ceil((num_aug_images_wanted-num_files)\/batch_size))\n\n    # run the generator and create about 6000 augmented images\n    for i in range(0,num_batches):\n\n        imgs, labels = next(aug_datagen)\n        \n    # delete temporary directory with the raw image files\n    shutil.rmtree('aug')","693d9ed2":"# check how many train images we have in each folder\nprint(\"..............................\")\nprint(\"Train folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/train\/nv')))\nprint(len(os.listdir('base\/train\/mel')))\nprint(len(os.listdir('base\/train\/bkl')))\nprint(len(os.listdir('base\/train\/bcc')))\nprint(len(os.listdir('base\/train\/akiec')))\nprint(len(os.listdir('base\/train\/vasc')))\nprint(len(os.listdir('base\/train\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"validation folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/valid\/nv')))\nprint(len(os.listdir('base\/valid\/mel')))\nprint(len(os.listdir('base\/valid\/bkl')))\nprint(len(os.listdir('base\/valid\/bcc')))\nprint(len(os.listdir('base\/valid\/akiec')))\nprint(len(os.listdir('base\/valid\/vasc')))\nprint(len(os.listdir('base\/valid\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"Test folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/test\/nv')))\nprint(len(os.listdir('base\/test\/mel')))\nprint(len(os.listdir('base\/test\/bkl')))\nprint(len(os.listdir('base\/test\/bcc')))\nprint(len(os.listdir('base\/test\/akiec')))\nprint(len(os.listdir('base\/test\/vasc')))\nprint(len(os.listdir('base\/test\/df')))","45a41fb9":"# Define transformations for data augmentation\ntfms = get_transforms(do_flip=True,  \n                      max_rotate=10,\n                      max_zoom=1.1,\n                      max_warp=0.2)\n\n# Build dataset by applying transforms to the data from our directory\ndata = (ImageList.from_folder(base)\n        .split_by_folder()          \n        .label_from_folder()\n        .add_test_folder('test')\n        .transform(tfms, size=224)\n        .databunch()\n        .normalize(imagenet_stats))","2390e891":"wd=1e-2\n\nmobilenet_split = lambda m: (m[0][0][10], m[1])\narch  = torchvision.models.mobilenet_v2\nlearn = cnn_learner(data, arch, cut=-1, split_on=mobilenet_split, wd=wd, metrics=[accuracy])","0e8093b2":"learn.lr_find();\nlearn.recorder.plot();","486e2150":"# Set our learning rate to the value where learning is fastest and loss \n# is still decreasing.\n\n# This function uses our input lr as an anchor and sweeps through a range \n# in order to search out the best local minima.\nlearn.fit_one_cycle(5, max_lr=slice(3e-03), pct_start=0.9)","f29be79e":"data.show_batch(rows=3, figsize=(4,4))","dad421e2":"learn.recorder.plot_losses()","8e0a0cd8":"# Exctract predictions and losses to evaluate model\npreds,y,losses = learn.get_preds(with_loss=True)\ninterp = ClassificationInterpretation(learn, preds, y, losses)","3b767537":"def top_k_spread(preds, y, spread):\n  for i in range(spread):\n    print(f\"Top {i+1} accuracy: {top_k_accuracy(preds, y, i+1)}\")","cd9cd6b7":"# Top-1 accuracy of 86% is quite near the best models from the open competition\ntop_k_spread(preds, y, 5)","b99d0e2a":"interp.plot_confusion_matrix()","87c7a0ca":"# probs from log preds\nprobs = np.exp(preds[:,1])\n# Compute ROC curve\nfpr, tpr, thresholds = roc_curve(y, probs, pos_label=1)\n\n# Compute ROC area\nroc_auc = auc(fpr, tpr)\nprint('ROC area is {0}'.format(roc_auc))","0e4829e3":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.01])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")","d91c1f8d":"learn.export()","2c02649d":"learn.path","d097ae96":"learn = load_learner(base,test=ImageList.from_folder('\/kaggle\/working\/base\/test'))","d55c4dba":"preds,y = learn.get_preds(ds_type=DatasetType.Test)\npreds = np.argmax(preds, 1).tolist()","11b41547":"for i in range(0,7):\n    print('The count of element:', i ,'is ', preds.count(i))","056103b9":"y_true=[]\nfor i in list(data.test_ds.items):\n    if PurePath(i).parts[2]==\"akiec\":\n        y_true.append(int(str(0)))\n    elif PurePath(i).parts[2]==\"bcc\":\n        y_true.append(int(str(1)))\n    elif PurePath(i).parts[2]==\"bkl\":\n        y_true.append(int(str(2))) \n    elif PurePath(i).parts[2]==\"df\":\n        y_true.append(int(str(3)))  \n    elif PurePath(i).parts[2]==\"mel\":\n        y_true.append(int(str(4))) \n    elif PurePath(i).parts[2]==\"nv\":\n        y_true.append(int(str(5)))\n    else:\n        y_true.append(int(str(6)))","dfff2a1e":"target_names = ['akiec', 'bcc','bkl','df','mel','nv','vasc']\nprint(classification_report(y_true, preds, target_names=target_names))","5ba95b60":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","425154a5":"cnf_matrix = confusion_matrix(y_true, preds,labels=[0,1,2,3,4,5,6])\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['akiec', 'bcc','bkl','df','mel','nv','vasc'],\n                      title='Confusion matrix, without normalization')","f97fc5ee":"def plot_prediction(learn, index):\n  data = learn.data.test_ds[index][0]\n  pred = learn.predict(data)\n  classes = learn.data.classes\n\n  prediction = pd.DataFrame(to_np(pred[2]*100), columns=['Confidence'])\n  prediction['Classes'] = classes\n  prediction = prediction.sort_values(by='Confidence', ascending=False)\n\n  fig = plt.figure(figsize=(12, 5))\n  ax1 = fig.add_subplot(121)\n  show_image(data, figsize=(5, 5), ax=ax1)\n  ax2 = fig.add_subplot(122)\n  sns.set_color_codes(\"pastel\")\n  sns.barplot(x='Confidence', y='Classes', data=prediction,\n              label=\"Total\", color=\"b\")\n  ax2.set_title(f'Actual: {PurePath(learn.data.test_ds.items[index]).parts[5]}')\n","67044730":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","390d0afb":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","d424f192":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","3b0e92dc":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","99fcf8a3":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","c9ddbd20":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","f485a7bc":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","50a607d0":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","d0a8e834":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","fc5c1c29":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","74dede4d":"**Balancing the unbalanced classes using Data Augmentation technique**","58915fa1":"Using **MobileNet Architecture**","bda93153":"**Analysis report for Test images.**","f78b0088":"**Plot of training and validation loss**","44109bda":"****Loading HAM10000_metadata and splitting into train ,  validation and test**","1c6c84f4":"****Mobilenet Convolutional Architecture****","7f56f3f5":"****Importing all neccessary librarys****","44f14ea2":"**Confusion Matrix Report for validation data**","32704466":"**Predictions"}}