{"cell_type":{"3be5a088":"code","e9cdeb7a":"code","575a289a":"code","4427a243":"code","57283bce":"code","45bdf636":"markdown","8ca86650":"markdown","8d092757":"markdown","0b7503ed":"markdown","c0fdae8b":"markdown"},"source":{"3be5a088":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split","e9cdeb7a":"class SVM:\n    def __init__(self, learning_rate=0.0001, lambda_param=0.001, n_iters=10000):\n        self.weights = None\n        self.bias =  None\n        self.lr = learning_rate\n        self.lambda_param = lambda_param\n        self.n_iters = n_iters\n    def fit(self,X,y):\n        n_samples, n_features = X.shape\n        \n        y1 = np.where(y <= 0, -1, 1)\n        \n        self.weights = np.zeros(n_features)\n        self.bias = 0\n        for i in range(self.n_iters):\n            for idx, x_i in enumerate(X):\n                condition = y1[idx] * (np.dot(x_i, self.weights) - self.bias) >= 1\n                if condition:\n                    self.weights -= self.lr * (2 * self.lambda_param * self.weights)\n                else:\n                    self.weights -= self.lr * (2 * self.lambda_param * self.weights - np.dot(x_i, y1[idx]))\n                    self.bias -= self.lr * y1[idx]\n        \n    def predict(self, X):\n        approx = np.dot(X, self.weights) - self.bias\n        return np.sign(approx)","575a289a":"def accuracy(y_true,y_pred):\n    acc = np.sum(y_true == y_pred)\/len(y_true)\n    return acc","4427a243":"X, y =  datasets.make_blobs(n_samples=50, n_features=2, centers=2, cluster_std=1.05, random_state=40)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\ny = np.where(y == 0, -1, 1)\nclf = SVM()\nclf.fit(X_train,y_train)\npredict = clf.predict(X_test)\nsvm_acc = accuracy(y_test,predict)\nprint('Accuracy:',svm_acc)\nprint(f'''\n     Final Weight:{clf.weights}\n     Final Bias:{clf.bias}\n     ''')","57283bce":"def visualize_svm():\n    def get_hyperplane_value(x, w, b, offset):\n        return (-w[0] * x + b + offset) \/ w[1]\n    fig = plt.figure()\n    ax = fig.add_subplot(1,1,1)\n    plt.scatter(X[:,0], X[:,1], marker='o',c=y)\n\n    x0_1 = np.amin(X[:,0])\n    x0_2 = np.amax(X[:,0])\n\n    x1_1 = get_hyperplane_value(x0_1, clf.weights, clf.bias, 0)\n    x1_2 = get_hyperplane_value(x0_2, clf.weights, clf.bias, 0)\n\n    x1_1_m = get_hyperplane_value(x0_1, clf.weights, clf.bias, -1)\n    x1_2_m = get_hyperplane_value(x0_2, clf.weights, clf.bias, -1)\n\n    x1_1_p = get_hyperplane_value(x0_1, clf.weights, clf.bias, 1)\n    x1_2_p = get_hyperplane_value(x0_2, clf.weights, clf.bias, 1)\n\n    ax.plot([x0_1, x0_2],[x1_1, x1_2], 'b--')\n    ax.plot([x0_1, x0_2],[x1_1_m, x1_2_m], 'k')\n    ax.plot([x0_1, x0_2],[x1_1_p, x1_2_p], 'k')\n\n    x1_min = np.amin(X[:,1])\n    x1_max = np.amax(X[:,1])\n    ax.set_ylim([x1_min-3,x1_max+3])\n\n    plt.show()\n\nvisualize_svm() ","45bdf636":"# Defining the SVM class","8ca86650":"# Method to calculate Accuracy","8d092757":"# Visualizing","0b7503ed":"# Import Libraries","c0fdae8b":"# Implementation"}}