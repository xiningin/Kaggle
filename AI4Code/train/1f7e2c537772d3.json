{"cell_type":{"d2b3ffbb":"code","0a147bd4":"code","b20ada77":"code","e1fd1693":"code","7d2c08f7":"code","6c1f33ad":"code","5405bbe2":"code","726a9880":"code","7f70bdc1":"code","9e809afa":"code","6dc26053":"code","4275b1d7":"code","4f4d68ff":"code","bc2381c2":"code","b7bdeb86":"markdown","5b6f2664":"markdown","d021c17e":"markdown","913bfce4":"markdown","026e5114":"markdown","7bcfc950":"markdown","1f80b7a1":"markdown","ef5ce4c3":"markdown","a63157a0":"markdown"},"source":{"d2b3ffbb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import recall_score\n\nfrom albumentations import Compose\nfrom albumentations.augmentations.geometric.rotate import Rotate\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport os\nimport cv2\nimport datetime\nfrom tqdm import tqdm","0a147bd4":"def save_images_to_csv(file_name, cats_path, dogs_path, size, folds):\n    counts = {cats_path: 0, dogs_path: 0}\n    labels = {cats_path: 0, dogs_path: 1}\n    dataset = list()\n    \n    for label in labels:\n        for f in tqdm(os.listdir(label)):\n            try:\n                path = os.path.join(label, f)\n                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n                img = cv2.resize(img, (size, size))\n                dataset.append(np.append(img, labels[label]))\n                counts[label] += 1\n            except Exception as e:\n                pass\n    \n    print('Saving...')\n    df = pd.DataFrame(np.array(dataset)).rename(columns={size * size: 'label'})\n    \n    df['fold'] = 0\n    kf = KFold(n_splits=folds, shuffle=True, random_state=16)\n    kf.get_n_splits(df)\n    for fold, (_, idx) in enumerate(kf.split(df)):\n        df.loc[idx, 'fold'] = fold\n    \n    df.to_csv(f'{file_name}_size{size}_fold{folds}.csv', index=False)\n    print('Successfully Saved Images To CSV')\n    print(f'Cats: {counts[cats_path]:4d}, Dogs: {counts[dogs_path]:4d}\\n')","b20ada77":"CATS_PATH = '..\/input\/cat-and-dog\/training_set\/training_set\/cats'\nDOGS_PATH = '..\/input\/cat-and-dog\/training_set\/training_set\/dogs'\n\nREBUILD_DATA = False\nSIZE = 80\nFOLD = 4\n\nif REBUILD_DATA:\n    save_images_to_csv('train', CATS_PATH, DOGS_PATH, SIZE, FOLD)","e1fd1693":"# df_train = pd.read_csv('.\/train_size80_fold4.csv')\ndf_train = pd.read_csv('..\/input\/cat-dog\/train_size80_fold4.csv')\ndf_train.head()","7d2c08f7":"plt.imshow(df_train.iloc[0, :-2].to_numpy().reshape((SIZE, SIZE)), cmap='binary_r')\nplt.show()","6c1f33ad":"fold = 3\ntrain_fold = [i for i in range(FOLD) if i not in [fold]]\nvalid_fold = [fold]\ntrain_idx = df_train.loc[df_train['fold'].isin(train_fold)].index\nvalid_idx = df_train.loc[df_train['fold'].isin(valid_fold)].index","5405bbe2":"class CatDogDataset(Dataset):\n    def __init__(self, csv, size, transform):\n        self.csv = csv.reset_index(drop=True)\n        self.size = size\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.csv)\n    \n    def __getitem__(self, index):\n        img = self.csv.iloc[index, :-2].to_numpy().astype(np.uint8).reshape(self.size, self.size)\n        if self.transform is not None:\n            img = self.transform(image=img)['image']\n        return img, self.csv.iloc[index]['label']","726a9880":"train_augmentation = Compose([\n    Rotate(20),\n    ToTensorV2()\n])\n\nvalid_augmentation = Compose([\n    ToTensorV2()\n])","7f70bdc1":"BATCH_SIZE = 16\n\ntrain_dataset = CatDogDataset(df_train.loc[train_idx], SIZE, train_augmentation)\nvalid_dataset = CatDogDataset(df_train.loc[valid_idx], SIZE, valid_augmentation)\n\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\nvalid_loader = DataLoader(valid_dataset, shuffle=True, batch_size=BATCH_SIZE)","9e809afa":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.cbn1 = nn.BatchNorm2d(64)\n        self.cbn2 = nn.BatchNorm2d(128)\n        \n        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n        self.conv3 = nn.Conv2d(128, 128, 3, padding=1)\n        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n        self.conv6 = nn.Conv2d(128, 64, 3)\n        \n        self.fc1 = nn.Linear(64 * 9 * 9, 2048)\n        self.fc2 = nn.Linear(2048, 512)\n        self.fc3 = nn.Linear(512, 128)\n        self.fc4 = nn.Linear(128, 64)\n        self.fc5 = nn.Linear(64, 32)\n        self.fc6 = nn.Linear(32, 2)\n    \n    def forward(self, x):\n        x = self.pool(F.relu(self.cbn1(self.conv1(x))))  # 80x80 to 40x40\n        x = F.relu(self.cbn2(self.conv2(x)))\n        x = F.relu(self.cbn2(self.conv3(x)))\n        x = F.relu(self.cbn2(self.conv4(x)))\n        x = self.pool(F.relu(self.cbn2(self.conv5(x))))  # 40x40 to 20x20\n        x = self.pool(F.relu(self.cbn1(self.conv6(x))))  # 20x20 to 9x9\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = F.relu(self.fc4(x))\n        x = F.relu(self.fc5(x))\n        x = self.fc6(x)\n        return x","6dc26053":"def rand_bbox(shape, lam):\n    W = shape[2]\n    H = shape[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n    \n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n    \n    bbx1 = np.clip(cx - cut_w \/\/ 2, 0, W)\n    bby1 = np.clip(cy - cut_h \/\/ 2, 0, H)\n    bbx2 = np.clip(cx + cut_w \/\/ 2, 0, W)\n    bby2 = np.clip(cy + cut_h \/\/ 2, 0, H)\n    \n    return bbx1, bby1, bbx2, bby2","4275b1d7":"def train(train_loader, valid_loader, model, optimizer, criterion, device, epoch, cutmix_prob=0.5):\n    file_name = f\"model_cutmix{cutmix_prob}_({datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}).pth\"\n    best_score = 0\n    best_epoch = 1\n    train_losses = list()\n    valid_losses = list()\n    \n    for ep in range(epoch):\n        train_loss = list()\n        \n        model.train()\n        for inputs, targets in tqdm(train_loader):\n            inputs = (inputs \/ 255.).to(device)\n            targets = targets.to(device)\n            \n            if np.random.rand() < cutmix_prob:\n                lam = np.random.beta(1.0, 1.0)\n                rand_idx = torch.randperm(inputs.shape[0])\n                shuffled_targets = targets[rand_idx]\n                bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.shape, lam)\n                inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_idx, :, bbx1:bbx2, bby1:bby2]\n                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) \/ (inputs.shape[-1] * inputs.shape[-2]))\n                \n                outputs = model(inputs)\n                optimizer.zero_grad()\n                loss = criterion(outputs, targets) * lam + criterion(outputs, shuffled_targets) * (1. - lam)\n            else:\n                outputs = model(inputs)\n                optimizer.zero_grad()\n                loss = criterion(outputs, targets)\n            \n            loss.backward()\n            optimizer.step()\n            train_loss.append(loss.item())\n        \n        valid_loss = list()\n        valid_true = list()\n        valid_pred = list()\n        \n        model.eval()\n        with torch.no_grad():\n            for inputs, targets in tqdm(valid_loader):\n                inputs = (inputs \/ 255.).to(device)\n                targets = targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                valid_loss.append(loss.item())\n                valid_true.append(targets.cpu().numpy())\n                valid_pred.append(outputs.cpu().argmax(dim=1).numpy())\n        \n        valid_true = np.concatenate(valid_true)\n        valid_pred = np.concatenate(valid_pred)\n        \n        train_loss = np.mean(train_loss)\n        valid_loss = np.mean(valid_loss)\n        \n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        \n        score = recall_score(valid_true, valid_pred, average='macro')        \n        if score > best_score:\n            best_score = score\n            best_epoch = ep + 1\n            torch.save(model.state_dict(), file_name)\n            \n        print(f'Epoch [{ep + 1:3d}\/{epoch}] train_loss: {train_loss:.5f}; valid_loss: {valid_loss:.5f}; score: {score:.5f}; (Best Epoch: {best_epoch})')\n    \n    return train_losses, valid_losses","4f4d68ff":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nnet = Net().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr = 0.001)\n\ntrain_loss, valid_loss = train(train_loader, valid_loader, net, optimizer, criterion, device, epoch=60, cutmix_prob=0.)","bc2381c2":"plt.figure(figsize=(10, 8))\nplt.plot(train_loss, label='train')\nplt.plot(valid_loss, label='valid')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","b7bdeb86":"# Train","5b6f2664":"#### [YouHan Lee's Github](https:\/\/github.com\/kaggler-tv\/codes\/blob\/master\/cutmix\/cutmix.ipynb)\n#### [Sentdex Pytorch Tutorial](https:\/\/youtu.be\/1gQR24B3ISE)","d021c17e":"# Split Data","913bfce4":"# Define Augmentations","026e5114":"# Save Images to CSV","7bcfc950":"# Define Dataset","1f80b7a1":"# Load Data","ef5ce4c3":"# Make Dataloader","a63157a0":"# Make Model"}}