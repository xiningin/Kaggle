{"cell_type":{"b40e81f3":"code","b3ad6958":"code","5907d789":"code","586a47b2":"code","5daa59e9":"code","ea938d62":"code","5e6c9204":"code","e76d2872":"code","775f84f5":"code","8a8c18ae":"code","20ae30a6":"code","c95d0236":"code","3c987395":"code","8788bc1f":"code","7fb4405a":"code","1e593116":"code","8c0a0d9c":"code","84bc4a01":"code","c59dd74c":"code","542a9fc2":"code","82420d19":"code","03573dd5":"code","182bf478":"code","e8957657":"code","c5d33a2c":"code","a86fa410":"markdown","7e822c93":"markdown","384a52e6":"markdown","6d82774f":"markdown","c1ed7bc8":"markdown","94c58335":"markdown","6d68f035":"markdown","7ac95e45":"markdown","27da6c2d":"markdown","ca0f1f06":"markdown","78311298":"markdown","3640fdf1":"markdown","590f0e23":"markdown","bb1dcfc4":"markdown"},"source":{"b40e81f3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b3ad6958":"df = pd.read_csv('..\/input\/cicids2017\/train.csv')\ntest = pd.read_csv('..\/input\/cicids2017\/test.csv')\ndf.head()","5907d789":"df.info()","586a47b2":"#testset number of rows and columns\nprint('number of rows:',test.shape[0])\nprint('number of columns:',test.shape[1])\nprint('')","5daa59e9":"# function to identify which columns are numerical, which categorical, store in two variables\n# print some results\n#input:dataframe, preferably with the label column sliced off\n#returns two lists with names of categorical and numeric features\n\ndef column_types(df):\n    numeric_columns = []\n    categorical_columns = []\n    \n    for column in df.columns:\n        if df[column].dtype != 'object':\n            numeric_columns.append(column)\n        else:\n            categorical_columns.append(column)\n    \n    print('number of numeric columns:',len(numeric_columns))\n    print('column names:')\n    print( numeric_columns)\n    print('')\n    \n    print ('number of categorical columns:', len(categorical_columns))\n    print ('column names:', categorical_columns)\n    print('')\n    print('Number of Unique Values:')\n\n    [print ('{}:'.format(column),df[column].nunique()) \n     for column in categorical_columns]\n\n    [print('\\n\\ncolumn {}:\\n'.format(column),df[column].value_counts()) \n     for column in categorical_columns]\n    \n    return numeric_columns, categorical_columns\n\nnumeric_columns, categorical_columns = column_types(df.iloc[:,:-1])","ea938d62":"# report on labels \n#input:dataframe and name of label column\n#displays class information\n\ndef label_report(df,label_column_name):\n    \n    print ('number of classes:', df[label_column_name].nunique())\n    print('')\n    print ('class names:', np.unique(df[label_column_name]))\n    print('')\n    print('Number of Unique Values:')\n    print(df[label_column_name].value_counts())\n\n\nprint('Train Data')\nprint('__________')\nlabel_report(df,'label')\nprint('')\nprint('__________')\nprint('')\nprint('Test Data')\nprint('__________')\nprint('Number of Unique Values:')\nprint(test['label'].value_counts())","5e6c9204":"#function to resample dataset in balanced form\n#majority classes may be downsampled, minority classes will be upsampled\n#input:pandas dataframe, output:pandas dataframe\n#params:df, name of label column, number of samples each class will have\n\ndef balanced_sampling(df, label_column_name, n_samples):\n    import numpy as np\n    import pandas as pd\n    \n    #identify majority and minority classes\n    minority_classes = []\n    majority_classes = []\n    for value,index in zip(df['label'].value_counts(),df['label'].value_counts().index):\n        if value<n_samples:\n            minority_classes.append(index)\n        else:\n            majority_classes.append(index)\n    \n    #sample each class\n    #oversample minority classes (replace=True)\n    balanced_df_min = df[df[label_column_name].isin(minority_classes)].groupby(by=df[label_column_name]).\\\n    apply(lambda x: x.sample(n_samples, replace=True))\n    #downsample majority classes (replace=False)\n    balanced_df_maj = df[df[label_column_name].isin(majority_classes)].groupby(by=df[label_column_name]).\\\n    apply(lambda x: x.sample(n_samples, replace=False))\n    #combine dataframes\n    balanced_df = pd.concat((balanced_df_min,balanced_df_maj),axis=0)\n    \n    #shuffle new dataframe\n    #(because it's sorted by class)\n    rand_state = np.random.RandomState(seed=33)\n    indices=np.arange(balanced_df.shape[0])\n    rand_state.shuffle(indices)\n       \n    return balanced_df.iloc[indices].reset_index(drop=True)\n\n\n\ndata=balanced_sampling(df,'label', 200000)\n","e76d2872":"# function that displays information about the resampling results\n#input: original dataframe, new dataframe, name of label column\n\ndef sampling_results(df_orig, df_final, label_column_name):\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    \n    print('original dataset rows:', df_orig.shape[0])\n    print('new dataset rows:     ', df_final.shape[0])\n    print ('')\n    print ('original dataset: samples per class')\n    print(df_orig[label_column_name].value_counts())\n    print('')\n    print('new dataset contains:')\n    print('{} values per class'.\\\n          format(df_final[label_column_name].value_counts()[0]))\n    \n    plt.figure(figsize=(12,4));\n    sns.countplot(x=label_column_name, data=df_orig, color='Gray');\n    plt.title('original dataset -- samples per class');\n    plt.figure(figsize=(12,4));\n    sns.countplot(x=label_column_name, data=df_final, color='Gray');\n    plt.title('new dataset -- samples per class');\n    \nsampling_results(df,data,'label')","775f84f5":"#function to prepare input data\n#input:dataframe without labels\n#output1: numpy array of values of dataframe with categorical one-hot encoded\n#                                                        and all data scaled\n#output2: sklearn objects encoder and scaler, to apply .transform on test data, and to use attributes for reference\n\ndef prepare_input_data(df, scaling='minmax'):\n    \n    \n    #scaling\n    if scaling == 'minmax':\n        from sklearn.preprocessing import MinMaxScaler\n        scaler = MinMaxScaler()\n        df = scaler.fit_transform(df)\n    elif scaling == 'standard':\n        from sklearn.preprocessing import StandardScaler\n        scaler == StandardScaler()\n        data = scaler.fit_transform(df)\n\n    return df, scaler\n\n\nx_tr, scaler = prepare_input_data(data.iloc[:,:-1])\n\nx_ts = scaler.transform(test.iloc[:,:-1])","8a8c18ae":"# export scaled samplings\nnp.save('CICIDS2017_mydata_tr.npy',x_tr)\nnp.save('CICIDS2017_mydata_ts.npy',x_ts[:200000,:])\nnp.save('CICIDS2017_mylabels_tr.npy',data.iloc[:,-1])\nnp.save('CICIDS2017_mylabels_ts.npy',test.iloc[:200000,-1])","20ae30a6":"x_tr = np.load('.\/CICIDS2017_mydata_tr.npy')\nx_ts = np.load('.\/CICIDS2017_mydata_ts.npy')\ny_tr = np.load('.\/CICIDS2017_mylabels_tr.npy')\ny_ts = np.load('.\/CICIDS2017_mylabels_ts.npy')\n\nx_tr.shape,y_tr.shape, x_ts.shape,y_ts.shape","c95d0236":"#convert input data to images\n#converts to square matrices, pads with zeros\n\n#the function converts:\n#1d arrays into 2d images\n#2d arrays into sequence of 2d images (an image for each row)\n\ndef to_image(array):\n    \n    if array.ndim == 1:\n        t = array.shape[0]\n        sqr = int(np.round(np.sqrt(t)))\n        \n        if sqr**2 == t:\n            im=np.reshape(array.copy(),(sqr,sqr))\n\n        else:\n            im = np.zeros((sqr+1,sqr+1))\n            dif = (sqr+1)**2-t\n            im = np.ravel(im)\n            im[:-dif] = array.copy()\n            im = np.reshape(im,(sqr+1,sqr+1))\n            \n        return np.array(im)\n     \n        \n    elif array.ndim ==2:\n        t=array.shape[1]\n        sqr=int(np.round(np.sqrt(t)))\n        \n        if sqr**2 ==t:\n            ims = np.zeros((array.shape[0],sqr,sqr))\n            for i, im in enumerate(ims):\n                im = np.reshape(array[i].copy(),(sqr,sqr))\n        else:\n            ims = np.zeros((array.shape[0],sqr+1,sqr+1))\n            dif = (sqr+1)**2 - t\n            for i, im in enumerate(ims):\n                temp = np.ravel(im)\n                temp[:-dif] = array[i].copy()\n                im = np.reshape(temp,(sqr+1,sqr+1))\n        \n        return np.array(ims)\n      \n        \n    else:\n        print('wrong dimensions, 1d or 2d only')\n\n\n\n        \n\n#convert to rgb, keras pretrained need 3 color channels\n#we copy the first channel to the other two\n\ndef to_rgb(array):\n    \n    images = np.empty((array.shape[0],10,10,3))\n    \n    for i,image in enumerate(array):\n        \n        images[i,:,:,1] = np.squeeze(image)\n        images[i,:,:,2] = np.squeeze(image)\n        \n    return images\n\n\n\n\n\n#transform each image to 80x80x3, to make compatible with InceptionV3 pretrained model\n#we repeat the 10x10x3 matrix horizontally and vertically to get 80x80x3\n\ndef expand(array):\n\n\n    \n    expanded = np.repeat(array,8,axis=2)\n    expanded = np.repeat(expanded,8,axis=1)\n        \n    return expanded","3c987395":"#visualize two images for each class\n\nfrom skimage.io import imshow\n\nfor class_ in np.unique(y_tr):\n    indices = np.random.choice \\\n    (np.argwhere(y_tr==class_).flatten(),2)\n    class_ims = to_image(x_tr[indices])\n    class_ims = to_rgb(class_ims)\n    class_ims = expand(class_ims)\n    \n    plt.figure(figsize=(16,4));\n    plt.subplot(1,3,1);\n    imshow(class_ims[0]);\n    plt.title(class_)\n    plt.subplot(1,3,2);\n    imshow(class_ims[1]);\n    plt.title(class_);\n\nprint('image shape:',class_ims[1].shape)","8788bc1f":"import tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras import models\nfrom keras.models import Model, load_model\nfrom keras import layers\nfrom keras.layers import Dense,Conv2D,MaxPooling2D, Flatten, Input\nfrom keras.layers.core import Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","7fb4405a":"#weight and notops from pretrained models\n!mkdir ~\/.keras\n!mkdir ~\/.keras\/models\n!cp ..\/input\/keras-pretrained-models\/*notop* ~\/.keras\/models\/\n!cp ..\/input\/keras-pretrained-models\/imagenet_class_index.json ~\/.keras\/models\/","1e593116":"#we will use an InceptionV3 model\nconv_base = keras.applications.InceptionV3(include_top=False,weights='imagenet',input_shape=(80,80,3))","8c0a0d9c":"conv_base.summary()","84bc4a01":"#complete pipeline\n# coefficient 'pack_size' determines chunks that will be processed at each iteration\n# too large 'pack_size' puts burden on memory, too small adds time complexity\ndef pipeline(array, conv_base):\n    \n    array = to_image (array)\n    pack_size = 10000\n    first_dim_fract = array.shape[0]\/\/pack_size\n    array = to_rgb(array)\n    features = []\n\n    for i in (np.arange(first_dim_fract)+1):\n        \n        first_index = (i-1)*pack_size\n        second_index = i*pack_size\n        print('chunk of index:{}-{}'.format(first_index,second_index))\n        temp = expand(array[first_index:second_index])\n        temp = conv_base.predict(temp)\n        features.append(temp)\n    \n    return np.reshape(features,(first_dim_fract*pack_size,1, 1, 2048))","c59dd74c":"#extract features in chunks to manage memory\ntrain_features = pipeline(x_tr[:100000],conv_base)\ntrain_features = np.append(train_features,pipeline(x_tr[100000:200000],conv_base),axis=0)\ntrain_features = np.append(train_features,pipeline(x_tr[200000:300000],conv_base),axis=0)","542a9fc2":"np.save('CICIDS2017_InceptionV3_train_features.npy',train_features)\n#train_features = np.load('.\/CICIDS2017_InceptionV3_train_features.npy')","82420d19":"test_features = pipeline(x_ts[:100000],conv_base)","03573dd5":"np.save('CICIDS2017_InceptionV3_test_features.npy',test_features)\n#test_features = np.load('')","182bf478":"#reshape to fit classifier\ntrain_features = np.reshape(train_features,(train_features.shape[0],2048))\ntest_features = np.reshape(test_features,(test_features.shape[0],2048))","e8957657":"#train a classifier with the feature maps of the pretrained keras model\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(256,activation='relu',input_dim=train_features.shape[1]))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1,activation='sigmoid'))\n\nstop= EarlyStopping(patience=4, verbose=1)\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\nmodel.fit(train_features,y_tr,epochs=30,batch_size=20,callbacks=stop,validation_split=0.1)","c5d33a2c":"#evaluate performance\n\npred = model.predict(test_features)\npred = np.squeeze((pred>0.5).astype(np.uint8))\nprint('accuracy:',accuracy_score(y_ts[:100000],pred))\nprint('f1-score:',f1_score(y_ts[:100000],pred))\nplt.figure(figsize=(9,7));\nconf=confusion_matrix(y_ts[:100000],pred)\nsns.heatmap(conf, annot=True, fmt='1d');","a86fa410":"The capacity of CNNs to work with cross-tabular, non-image data has been underappreciated, but in this project we've shown that CNNs, arguably the most powerful deep learning models, can be harnessed with great results for tasks other than vision and image recognition.","7e822c93":"Convolutional Neural Networks are some of the strongest deep learning models, with state-of-the-art performance in problems of exceeding complexity, but can't we benefit from them in non-vision tasks? \n\nHere we will take advantage of keras pretrained CNNs for classifying non-image data. We will use a benchmark dataset of network intrusions, convert the data to image format, extract features with a pretrained model, and use these features to train a Dense-layer classifier.","384a52e6":"### Data Preparation","6d82774f":"### CNN Training","c1ed7bc8":"### Data Analysis","94c58335":"## Pretrained Keras Models for Cross-tabular Data","6d68f035":"Now we'll extract features and train a classifier. We will only use a slice of the data, 300k train samples,and 100k test samples.","7ac95e45":"Also, note that for memory management purposes we will not transform the vectors now, but will embedd image generation into the CNN-training pipeline shortly.","27da6c2d":"### Conclusion","ca0f1f06":"### Image Conversion","78311298":"### Train Data Resampling","3640fdf1":"Next, we create a complete pipeline, from image transform to feature extraction. For memory management we will do it by chunks and then use the features to train a classifier.","590f0e23":"To see how this layered transformation looks like,we will visualize two images for each class. Note that duplicating the grayscale channel to generate 3 rgb channels may cause individual pixels to exceed the threshold value. Imshow may occassionally display the images weirdly: there seems to be a bug and imshow may display a image in different ways if you run the command more than once, but the internal numerical representations are constant and normal. We will not apply color normalization, as that would distort our non-image data.","bb1dcfc4":"CICDS2017 dataset from https:\/\/www.kaggle.com\/trystanmortimer\/cicids2017"}}