{"cell_type":{"ac68c533":"code","1f1b820f":"code","a6522b9d":"code","48edd2d4":"code","759976cd":"code","fab67c21":"code","2708882c":"code","d1699259":"code","24f9ddfa":"code","8ac1b938":"code","ab4cce1b":"code","d3e3192b":"code","02790cfe":"code","8d504d1e":"code","31dc232f":"code","0c43bf5b":"code","e370bd1b":"code","4382ab09":"code","cb9eaa67":"markdown","99c7cab5":"markdown","8e8dbae2":"markdown","c815a355":"markdown","989d99b8":"markdown","9fe2c9b0":"markdown","44441201":"markdown","4f6642ef":"markdown","c2027ade":"markdown","4ae060cc":"markdown","289fcfc8":"markdown","f2b1bc9e":"markdown","a632b373":"markdown","fa6f152c":"markdown","f5d8168b":"markdown","a0758ffa":"markdown","065ddb59":"markdown","0150467c":"markdown","443d348e":"markdown"},"source":{"ac68c533":"import warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")","1f1b820f":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nprint('Train set shape:', train.shape)\nprint('Test set shape:', test.shape)\nprint('Train set overview:')\ndisplay(train.head())","a6522b9d":"N_FOLDS = 5","48edd2d4":"# INITIALIZE VARIABLES\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic', 'preds']]\ntest['target_knn'] = 0\ntrain['preds_knn'] = 0\ntest['target_mlp'] = 0\ntrain['preds_mlp'] = 0\ntest['target_svc'] = 0\ntrain['preds_svc'] = 0\ntest['target_nusvc'] = 0\ntrain['preds_nusvc'] = 0\ntest['target_qda'] = 0\ntrain['preds_qda'] = 0\n\n# BUILD 512 MODELS\nfor i in range(512):\n    print('wheezy-copper-turtle-magic {}\\n'.format(i))\n    \n    # EXTRACT SUBSET OF DATASET WHERE WHEEZY-MAGIC EQUALS I\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index\n    idx2 = test2.index\n    train2.reset_index(drop=True, inplace=True)\n    \n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n    train3 = data2[:train2.shape[0]]\n    test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=N_FOLDS, random_state=0)\n    counter = 0\n\n    for train_index, val_index in skf.split(train3, train2['target']):\n        counter += 1\n        print('Fold {}\\n'.format(counter))\n        model_names = ['knn', 'mlp', 'svc', 'nusvc', 'qda']\n        models = [KNeighborsClassifier(n_neighbors=17, p=2.9), \n                  MLPClassifier(random_state=3, activation='relu', solver='lbfgs', tol=1e-06, hidden_layer_sizes=(250, )), \n                  SVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42), \n                  NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.59, coef0=0.053), \n                  QuadraticDiscriminantAnalysis(0.1)]\n        \n        for i in range(len(model_names)):\n            model = models[i]\n            model_name = model_names[i]\n            model.fit(train3[train_index,:], train2.loc[train_index]['target'])\n\n            train_predictions = model.predict(train3[train_index,:])\n            val_predictions = model.predict(train3[val_index,:])\n\n            train_auc = roc_auc_score(train2.loc[train_index]['target'], train_predictions) * 100\n            val_auc = roc_auc_score(train2.loc[val_index]['target'], val_predictions) * 100\n            train_precision = precision_score(train2.loc[train_index]['target'], train_predictions) * 100\n            val_precision = precision_score(train2.loc[val_index]['target'], val_predictions) * 100\n            train_recall = recall_score(train2.loc[train_index]['target'], train_predictions) * 100\n            val_recall = recall_score(train2.loc[val_index]['target'], val_predictions) * 100\n            print('-----%s - Train----------' % model_name)\n            print('AUC: %.2f Precision: %.2f Recall: %.2f \\n' % (train_auc, train_precision, train_recall))\n            print('-----%s - Validation-----' % model_name)\n            print('AUC: %.2f Precision: %.2f Recall: %.2f \\n' % (val_auc, val_precision, val_recall))\n\n            # Make predictions\n            train[('preds_%s' % model_name)].loc[idx1] += model.predict_proba(train3)[:,1] \/ N_FOLDS\n            test[('target_%s' % model_name)].loc[idx2] += model.predict_proba(test3)[:,1] \/ N_FOLDS","759976cd":"train['preds_svcs'] = (train['preds_svc'] * 0.5) + (train['preds_nusvc'] * 0.5)\ntest['target_svcs'] = (test['target_svc'] * 0.5) + (test['target_nusvc'] * 0.5)\n\ntrain['preds_avg'] = (train['preds_knn'] * 0.2) + (train['preds_mlp'] * 0.2) + (train['preds_svc'] * 0.2) + (train['preds_nusvc'] * 0.2) + (train['preds_qda'] * 0.2)\ntest['target_avg'] = (test['target_knn'] * 0.2) + (test['target_mlp'] * 0.2) + (test['target_svc'] * 0.2) + (test['target_nusvc'] * 0.2) + (test['target_qda'] * 0.2)\n\ntrain['preds_avg2'] = (train['preds_knn'] * 0.2) + (train['preds_mlp'] * 0.05) + (train['preds_svc'] * 0.05) + (train['preds_nusvc'] * 0.7)\ntest['target_avg2'] = (test['target_knn'] * 0.2) + (test['target_mlp'] * 0.05) + (test['target_svc'] * 0.05) + (test['target_nusvc'] * 0.7)\n","fab67c21":"f = plt.subplots(1, 1, figsize=(16, 5), sharex=True)\ntrain_cnf_matrix = confusion_matrix(train['target'], [np.round(x) for x in train['preds_avg']])\ntrain_cnf_matrix_norm = train_cnf_matrix \/ train_cnf_matrix.sum(axis=1)[:, np.newaxis]\ntrain_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=[0, 1], columns=[0, 1])\nsns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","2708882c":"f = plt.subplots(1, 1, figsize=(16, 5), sharex=True)\ntrain_cnf_matrix = confusion_matrix(train['target'], [np.round(x) for x in train['preds_knn']])\ntrain_cnf_matrix_norm = train_cnf_matrix \/ train_cnf_matrix.sum(axis=1)[:, np.newaxis]\ntrain_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=[0, 1], columns=[0, 1])\nsns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","d1699259":"f = plt.subplots(1, 1, figsize=(16, 5), sharex=True)\ntrain_cnf_matrix = confusion_matrix(train['target'], [np.round(x) for x in train['preds_svc']])\ntrain_cnf_matrix_norm = train_cnf_matrix \/ train_cnf_matrix.sum(axis=1)[:, np.newaxis]\ntrain_df_cm = pd.DataFrame(train_cnf_matrix_norm, index=[0, 1], columns=[0, 1])\nsns.heatmap(train_df_cm, annot=True, fmt='.2f', cmap=\"Blues\")\nplt.show()","24f9ddfa":"print('KNN AUC %.2f' % roc_auc_score(train['target'], train['preds_knn']))\nprint('MLP AUC %.2f' % roc_auc_score(train['target'], train['preds_mlp']))\nprint('SVC AUC %.2f' % roc_auc_score(train['target'], train['preds_svc']))\nprint('NuSVC AUC %.2f' % roc_auc_score(train['target'], train['preds_nusvc']))\nprint('QDA AUC %.2f' % roc_auc_score(train['target'], train['preds_qda']))\nprint('SVCs AUC %.2f' % roc_auc_score(train['target'], train['preds_svcs']))\nprint('Averaged AUC %.2f' % roc_auc_score(train['target'], train['preds_avg']))\nprint('Averaged 2 AUC %.2f' % roc_auc_score(train['target'], train['preds_avg2']))","8ac1b938":"test[['id', 'target_avg', 'target_avg2', 'target_svcs', 'target_knn', 'target_mlp', 'target_svc', 'target_nusvc', 'target_qda']].head()","ab4cce1b":"submission = test[['id', 'target_avg']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_avg.csv', index=False)\nsubmission.head()","d3e3192b":"submission = test[['id', 'target_avg2']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_avg2.csv', index=False)\nsubmission.head()","02790cfe":"submission = test[['id', 'target_svcs']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_svcs.csv', index=False)\nsubmission.head()","8d504d1e":"submission = test[['id', 'target_knn']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_knn.csv', index=False)\nsubmission.head()","31dc232f":"submission = test[['id', 'target_mlp']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_mlp.csv', index=False)\nsubmission.head()","0c43bf5b":"submission = test[['id', 'target_svc']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_svc.csv', index=False)\nsubmission.head()","e370bd1b":"submission = test[['id', 'target_nusvc']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_nusvc.csv', index=False)\nsubmission.head()","4382ab09":"submission = test[['id', 'target_qda']]\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission_qda.csv', index=False)\nsubmission.head()","cb9eaa67":"# Ensemble models\n\nHere you can ensemble any combination of models, and give the desired weight for each one.","99c7cab5":"#### QDA model submission","8e8dbae2":"#### NuSVC model submission","c815a355":"## Confusion matrix (knn model)","989d99b8":"### Here I'll show how you can build multiple models, ensemble but also evaluate each of them, this may help instead of just train random models and then blindly submit the results.\n\n#### This is another iteration of the amazing work of Chris Deotte [checkout here](https:\/\/www.kaggle.com\/cdeotte\/support-vector-machine-0-925)","9fe2c9b0":"### You can find evaluation metrics for each model on each fold below on this cell output log. (It's hidden to keep the code clean)","44441201":"#### KNN model submission","4f6642ef":"## Metrics ROC AUC","c2027ade":"#### KNN model submission","4ae060cc":"## Confusion matrix (SVC model)","289fcfc8":"### Test set with all models predictions","f2b1bc9e":"# Dependencies","a632b373":"# Model evaluation\n## Confusion matrix (averaged model)","fa6f152c":"#### Averaged 2 models submission","f5d8168b":"#### SVCs models submission","a0758ffa":"# Load data","065ddb59":"# Test predictions\nNow you can output predictions for each individual model and the ensembled models as well.\n\n#### Averaged models submission","0150467c":"#### SVC model submission","443d348e":"# Model\n\n## Model parameters"}}