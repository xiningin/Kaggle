{"cell_type":{"179bdf0a":"code","d8d338e1":"code","25131131":"code","a85cf166":"code","e5040450":"code","a9950d86":"code","033bfa17":"code","40ff8960":"code","1a6e811a":"code","dafd79ac":"code","51a4bb05":"code","158857d5":"code","97467887":"code","b12deda4":"code","b7b87a0f":"code","ff7734a3":"code","add84a8e":"code","81ec510e":"code","e96f2eb9":"code","889e61ef":"code","bd271d99":"code","f485478c":"code","ae908257":"code","d9fd68ad":"markdown","b816d877":"markdown","7bc10613":"markdown","ac01ee47":"markdown","46f4bedd":"markdown"},"source":{"179bdf0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nimport sklearn\nimport sklearn.metrics as metrics\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8d338e1":"email = pd.read_csv('..\/input\/enron-email-dataset\/emails.csv')\nemail","25131131":"import os\nprint(os.listdir(\"..\/input\/dataset\"))","a85cf166":"for i in os.listdir(\"..\/input\/dataset\"):\n    try:\n        df = pd.read_pickle('..\/input\/dataset\/'+i, compression=None)\n        print(i, \", SHAPE:\", df.shape, \", SIZE: {:,} bytes\".format(sys.getsizeof(df)))\n        del df\n    except Exception as e:\n        print(i, \"Error loading file\", repr(e))","e5040450":"\"\"\"\nconvert dos linefeeds (crlf) to unix (lf)\nusage: dos2unix.py \n\"\"\"\noriginal = \"\/kaggle\/input\/dataset\/final_project_dataset.pkl\"\ndestination = \"final_project_dataset_unix.pkl\"\n\ncontent = ''\noutsize = 0\nwith open(original, 'rb') as infile:\n    content = infile.read()\nwith open(destination, 'wb') as output:\n    for line in content.splitlines():\n        outsize += len(line) + 1\n        output.write(line + str.encode('\\n'))","a9950d86":"dataset = pickle.load(open(\"final_project_dataset_unix.pkl\", \"rb\"))\ndata = np.asanyarray(dataset)\ndata","033bfa17":"\"\"\"\" A general tool for converting data from the\n    dictionary format to an (n x k) python list that's \n    ready for training an sklearn algorithm\n\n    n--no. of key-value pairs in dictonary\n    k--no. of features being extracted\n\n    dictionary keys are names of persons in dataset\n    dictionary values are dictionaries, where each\n        key-value pair in the dict is the name\n        of a feature, and its value for that person\n\n    In addition to converting a dictionary to a numpy \n    array, you may want to separate the labels from the\n    features--this is what targetFeatureSplit is for\n\n    so, if you want to have the poi label as the target,\n    and the features you want to use are the person's\n    salary and bonus, here's what you would do:\n\n    feature_list = [\"poi\", \"salary\", \"bonus\"] \n    data_array = featureFormat( data_dictionary, feature_list )\n    label, features = targetFeatureSplit(data_array)\n\n    the line above (targetFeatureSplit) assumes that the\n    label is the _first_ item in feature_list--very important\n    that poi is listed first!\n\"\"\"\"\"\n\ndef featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n    \"\"\" convert dictionary to numpy array of features\n        remove_NaN = True will convert \"NaN\" string to 0.0\n        remove_all_zeroes = True will omit any data points for which\n            all the features you seek are 0.0\n        remove_any_zeroes = True will omit any data points for which\n            any of the features you seek are 0.0\n        sort_keys = True sorts keys by alphabetical order. Setting the value as\n            a string opens the corresponding pickle file with a preset key\n            order (this is used for Python 3 compatibility, and sort_keys\n            should be left as False for the course mini-projects).\n        NOTE: first feature is assumed to be 'poi' and is not checked for\n            removal for zero or missing values.\n    \"\"\"\n\n\n    return_list = []\n\n    # Key order - first branch is for Python 3 compatibility on mini-projects,\n    # second branch is for compatibility on final project.\n    if isinstance(sort_keys, str):\n        import pickle\n        keys = pickle.load(open(sort_keys, \"rb\"))\n    elif sort_keys:\n        keys = sorted(dictionary.keys())\n    else:\n        keys = dictionary.keys()\n\n    for key in keys:\n        tmp_list = []\n        for feature in features:\n            try:\n                dictionary[key][feature]\n            except KeyError:\n                print(\"error: key \", feature, \" not present\")\n                return\n            value = dictionary[key][feature]\n            if value==\"NaN\" and remove_NaN:\n                value = 0\n            tmp_list.append( float(value) )\n\n        # Logic for deciding whether or not to add the data point.\n        append = True\n        # exclude 'poi' class as criteria.\n        if features[0] == 'poi':\n            test_list = tmp_list[1:]\n        else:\n            test_list = tmp_list\n        ### if all features are zero and you want to remove\n        ### data points that are all zero, do that here\n        if remove_all_zeroes:\n            append = False\n            for item in test_list:\n                if item != 0 and item != \"NaN\":\n                    append = True\n                    break\n        ### if any features for a given data point are zero\n        ### and you want to remove data points with any zeroes,\n        ### handle that here\n        if remove_any_zeroes:\n            if 0 in test_list or \"NaN\" in test_list:\n                append = False\n        ### Append the data point if flagged for addition.\n        if append:\n            return_list.append( np.array(tmp_list) )\n\n    return np.array(return_list)\n\n\n\n\n","40ff8960":"def targetFeatureSplit( data ):\n    \"\"\" \n        given a numpy array like the one returned from\n        featureFormat, separate out the first feature\n        and put it into its own list (this should be the \n        quantity you want to predict)\n\n        return targets and features as separate lists\n\n        (sklearn can generally handle both lists and numpy arrays as \n        input formats when training\/predicting)\n    \"\"\"\n\n    target = []\n    features = []\n    for item in data:\n        target.append( item[0] )\n        features.append( item[1:] )\n\n    return target, features","1a6e811a":"xx1 = featureFormat(dataset,['poi','salary','bonus'])\nxx2 = featureFormat(dataset,['poi','salary','total_payments','deferral_payments'])\nxx3 = featureFormat(dataset,['poi','salary','bonus','deferral_payments'])\nxx4 = featureFormat(dataset,['poi','salary','bonus','deferred_income'])\nxx5 = featureFormat(dataset,['poi','salary','total_payments','deferred_income'])\nxx6 = featureFormat(dataset,['poi','salary','expenses'])\nxx2","dafd79ac":"a = plt.figure(figsize = (8,8))\nfor i in range(len(xx1)):\n    if xx1[i][0] == 1:\n        plt.scatter(xx1[i][1],xx1[i][2],color = 'g')\n    else:\n        plt.scatter(xx1[i][1],xx1[i][2],color = 'r')\n        \n            \nplt.xlabel('Salary')\nplt.ylabel('Bonus')\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.ylim(-1000,10000000)\nplt.xlim(-1000,1000000)\n\n\n\n\n\n\n\nplt.show","51a4bb05":"a = plt.figure(figsize = (8,8))\n\nfor i in range(len(xx2)):\n    if xx2[i][0] == 1:\n        if xx2[i][3] == 0:\n            plt.plot(xx2[i][1],xx2[i][2],'g^')\n        else: \n            plt.plot(xx2[i][1],xx2[i][2],'go')\n    else:\n        if xx2[i][3] == 0:\n            plt.plot(xx2[i][1],xx2[i][2],'r^')\n        else:\n            plt.plot(xx2[i][1],xx2[i][2],'ro')\nplt.ylim(-1000,10000000)\nplt.xlim(-1000,1000000)           \nplt.xlabel('Salary')\nplt.ylabel('Total_payments') \nplt.show","158857d5":"a = plt.figure(figsize = (8,8))\nfor i in range(len(xx3)):\n    if xx3[i][0] == 1:\n        if xx3[i][3] == 0:\n            plt.plot(xx3[i][1],xx3[i][2],'g^')\n        else: \n            plt.plot(xx3[i][1],xx3[i][2],'go')\n    else:\n        if xx3[i][3] == 0:\n            plt.plot(xx3[i][1],xx3[i][2],'r^')\n        else:\n            plt.plot(xx3[i][1],xx3[i][2],'ro')\n            \nplt.ylim(-1000,10000000)\nplt.xlim(-1000,1000000)             \nplt.xlabel('Salary')\nplt.ylabel('Bonus')\nplt.show","97467887":"a = plt.figure(figsize = (8,8))\nfor i in range(len(xx4)):\n    if xx4[i][0] == 1:\n        if xx4[i][3] == 0:\n            plt.plot(xx4[i][1],xx4[i][2],'g^')\n        else: \n            plt.plot(xx4[i][1],xx4[i][2],'go')\n    else:\n        if xx4[i][3] == 0:\n            plt.plot(xx4[i][1],xx4[i][2],'r^')\n        else:\n            plt.plot(xx4[i][1],xx4[i][2],'ro')\n            \nplt.ylim(-1000,10000000)\nplt.xlim(-1000,1000000)             \nplt.xlabel('Salary')\nplt.ylabel('Bonus')\nplt.show","b12deda4":"a = plt.figure(figsize = (8,8))\nfor i in range(len(xx5)):\n    if xx5[i][0] == 1:\n        if xx5[i][3] == 0:\n            plt.plot(xx5[i][1],xx5[i][2],'g^')\n        else: \n            plt.plot(xx5[i][1],xx5[i][2],'go')\n    else:\n        if xx5[i][3] == 0:\n            plt.plot(xx5[i][1],xx5[i][2],'r^')\n        else:\n            plt.plot(xx5[i][1],xx5[i][2],'ro')\nplt.ylim(-1000,10000000)\nplt.xlim(-1000,1000000)             \nplt.xlabel('Salary')\nplt.ylabel('Total_payments')\nplt.show","b7b87a0f":"a = plt.figure(figsize = (8,8))\nfor i in range(len(xx6)):\n    if xx6[i][0] == 1:\n        plt.scatter(xx6[i][1],xx6[i][2],color = 'g')\n    else:\n        plt.scatter(xx6[i][1],xx6[i][2],color = 'r')\nplt.xlabel('Salary')\nplt.ylabel('Expenses')         \n        \nplt.ylim(-1000,1000000)\nplt.xlim(-1000,1000000)         \n\n\nplt.show","ff7734a3":"def dict_to_list(key,normalizer):\n    feature_list=[]\n\n    for i in dataset:\n        if dataset[i][key]==\"NaN\" or dataset[i][normalizer]==\"NaN\":\n            feature_list.append(0.)\n        elif dataset[i][key]>=0:\n            feature_list.append(float(dataset[i][key])\/float(dataset[i][normalizer]))\n    return feature_list\n\nfraction_from_poi_email=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\nfraction_to_poi_email=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\np = 0\nfor i in dataset:\n    dataset[i][\"fraction_from_poi_email\"]=fraction_from_poi_email[p]\n    dataset[i][\"fraction_to_poi_email\"]=fraction_to_poi_email[p]\n    p=p+1","add84a8e":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier","81ec510e":"feature_list = ['poi','shared_receipt_with_poi','fraction_from_poi_email','fraction_to_poi_email',\"deferral_payments\"]\ndata_array = featureFormat(dataset, feature_list)\nlabels, features = targetFeatureSplit(data_array)\nX_train, X_test, Y_train, Y_test = train_test_split(features, labels,test_size=0.3,random_state=42)","e96f2eb9":"clf1 = GaussianNB()\nclf1.fit(X_train,Y_train)\npred = clf1.predict(X_test)\nacc = metrics.accuracy_score(pred,Y_test)\nprint(\"Accuracy by GaussianNB classifier: \",acc)","889e61ef":"\nclf2=RandomForestClassifier()\nclf2.fit(X_train,Y_train)\npred2 = clf2.predict(X_test)\nacc2 = metrics.accuracy_score(pred2,Y_test)\nprint(\"Accuracy by RandomForestClassifier:\",acc2)","bd271d99":"clf3 = KNeighborsClassifier(n_neighbors=6)\nclf3.fit(X_train,Y_train)\npred3 = clf3.predict(X_test)\nacc3 = metrics.accuracy_score(pred3, Y_test)\nprint(\"Accuracy by KNN classifier: \",acc3)","f485478c":"clf4 = tree.DecisionTreeClassifier()\nclf4 = clf4.fit(X_train, Y_train)\npred4 = clf4.predict(X_test)\nacc = metrics.accuracy_score(pred4,Y_test)\nprint(\"Accuracy by DecesionTree classifier: \",acc3)","ae908257":"pickle.dump(clf2, open(\"my_classifier.pkl\", \"wb\") )\npickle.dump(dataset, open(\"my_dataset.pkl\", \"wb\") )\npickle.dump(feature_list, open(\"my_feature_list.pkl\", \"wb\") )","d9fd68ad":"# Add new feature","b816d877":"# Output","7bc10613":"## The pickle file has to be using Unix new lines otherwise at least Python 3.4's C pickle parser fails with exception: pickle.UnpicklingError: the STRING opcode argument must be quoted","ac01ee47":"# Now drawing Plots","46f4bedd":"# Now using Algos"}}