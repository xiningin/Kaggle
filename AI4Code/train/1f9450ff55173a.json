{"cell_type":{"efa8d9c2":"code","b1dc58cf":"code","0b9391b5":"code","606b3348":"code","34129372":"code","a5a32d04":"code","166ecb20":"code","0276cdd2":"code","c250fab9":"code","37af3504":"code","e503effd":"code","0d93572b":"code","26ecc6e8":"code","d8577bab":"code","42973d6c":"code","607953f0":"code","29163a7e":"code","2b365017":"code","5e69a9e0":"code","1b4a3c45":"code","a7bbd526":"code","413feed0":"markdown","3e0d6135":"markdown","4732edac":"markdown","1e85fa91":"markdown","95efd315":"markdown","04086d20":"markdown","954eeee5":"markdown","ef8f78df":"markdown","0a888990":"markdown","f52b8c64":"markdown","c944f118":"markdown","7e3f4a4e":"markdown","47340a3d":"markdown","2c2ebc7b":"markdown","cf438f8c":"markdown","b9f5a90c":"markdown","74e6f29e":"markdown","efb6c232":"markdown"},"source":{"efa8d9c2":"pip install -U lightautoml","b1dc58cf":"# Standard python libraries\nimport os\nimport time\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport torch\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.utils.profiler import Profiler","0b9391b5":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 1800 # Time in seconds for automl run\nTARGET = 'loan_default' # Target column name","606b3348":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","34129372":"%%time\npd.set_option('display.max_columns', 100)\ntrain_data = pd.read_csv('..\/input\/ds-masters-math-retake\/default_train.csv')\ntrain_data.head()","a5a32d04":"test_data = pd.read_csv('..\/input\/ds-masters-math-retake\/default_test.csv')\ntest_data.head()","166ecb20":"submission = pd.read_csv('..\/input\/ds-masters-math-retake\/default_sample_submission.csv')\nsubmission.head()","0276cdd2":"def create_extra_features(data):\n    data['DatesDiff'] = (pd.to_datetime(data['DisbursalDate'], format = '%d-%m-%y') - \n                         pd.to_datetime(data['Date.of.Birth'], format = '%d-%m-%y')) \/ np.timedelta64(1, 'D')\n    data.drop(columns = ['DisbursalDate', 'Date.of.Birth'], inplace = True)\n    \n    for col in ['AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH']:\n        data[col + '_years'] = data[col].map(lambda x: x.split(' ')[0][:-3]).astype(int)\n        data[col + '_mons'] = data[col].map(lambda x: x.split(' ')[1][:-3]).astype(int)\n        data[col + '_full_num_mons'] = data[col + '_years'] * 12 + data[col + '_mons']\n        \n    data['diff_in_mons_num'] = data['CREDIT.HISTORY.LENGTH' + '_full_num_mons'] - data['AVERAGE.ACCT.AGE' + '_full_num_mons']\n    \n    data['CNS_score_type'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].map(lambda x: ord(x[0]) - ord('A'))\n    data['CNS_score_type_no_scored'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].map(\n                                            lambda x: x[:10] if x.startswith('Not Scored: ') else x)\n    \n\ncreate_extra_features(train_data)\ncreate_extra_features(test_data)","c250fab9":"train_data","37af3504":"tr_data, te_data = train_test_split(train_data, \n                                     test_size=TEST_SIZE, \n                                     stratify=train_data[TARGET], \n                                     random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: tr_data = {}, te_data = {}'.format(tr_data.shape, te_data.shape))","e503effd":"%%time\ndef acc_score(y_true, y_pred, **kwargs):\n    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ntask = Task('binary', metric = acc_score)","0d93572b":"%%time\n\nroles = {\n    'target': TARGET\n}","26ecc6e8":"%%time \n\nautoml = TabularAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(tr_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","d8577bab":"%%time\n\ntest_pred = automl.predict(te_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(tr_data[TARGET].values, oof_pred.data[:, 0])))\nprint('VALID score: {}'.format(acc_score(te_data[TARGET].values, test_pred.data[:, 0])))","42973d6c":"%%time \n\nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(tr_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","607953f0":"%%time\n\ntest_pred = automl.predict(te_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(tr_data[TARGET].values, oof_pred.data[:, 0])))\nprint('VALID score: {}'.format(acc_score(te_data[TARGET].values, test_pred.data[:, 0])))","29163a7e":"%%time \n\nautoml = TabularAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","2b365017":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(train_data[TARGET].values, oof_pred.data[:, 0])))","5e69a9e0":"submission[TARGET] = (test_pred.data[:, 0] > 0.5).astype(int)\nsubmission.to_csv('automl_utilized.csv', index = False)","1b4a3c45":"submission","a7bbd526":"%%time\n\n# Fast feature importances calculation\nfast_fi = automl.get_feature_scores('fast')\nfast_fi.set_index('Feature')['Importance'].plot.bar(figsize = (20, 10), grid = True)","413feed0":"# ========= AutoML preset usage =========\n\n\n## Step 1. Create Task","3e0d6135":"## Step 8. Predict for test data and check OOF score","4732edac":"## Step 10. Feature importances ","1e85fa91":"# Step 0.4. Data load ","95efd315":"## Step 6. Predict to validation data and check scores for utilized automl","04086d20":"Score for `TabularUtilizedAutoML` is 78.41% accuracy for OOF preds and 78.39% accuracy for validation preds in 23.5 minutes. As the validation score is better for `TabularAutoML` for this case, we choose it for final model retrain on full train dataset.\n\n## Step 7. Train on full data ","954eeee5":"# Step 0.0. Install LightAutoML","ef8f78df":"Below we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible):","0a888990":"# Step 0.1. Import necessary libraries ","f52b8c64":"## Step 9. Prepare submission","c944f118":"## Step 4. Predict to validation data and check scores","7e3f4a4e":"Score for `TabularAutoML` is 78.41% accuracy for OOF preds and 78.39% accuracy for validation preds in 8 minutes time. \n\n## Step 5. Create AutoML with time utilization ","47340a3d":"# Step 0.3. Fix torch number of threads and numpy seed ","2c2ebc7b":"# Step 0.5. Add new features","cf438f8c":"## Step 3. Create AutoML from preset and train on 80% of data","b9f5a90c":"# Step 0.6. Data splitting for train-test ","74e6f29e":"## Step 2. Setup columns roles","efb6c232":"# Step 0.2. Parameters "}}