{"cell_type":{"d8bb3f00":"code","58b312cb":"code","86d77841":"code","6a3ade8e":"code","a30a792c":"code","2a80c724":"code","89a40a27":"code","47ab0393":"code","eab998bd":"code","fc34eef9":"code","4f7c69fb":"code","e2b5b5b8":"code","05b23d87":"code","4b2d14c8":"code","7a34b306":"code","7961280c":"code","545bccf2":"code","08ff0a9a":"code","2c998238":"code","c572313c":"code","6296dd87":"code","fc6e1142":"code","619b1c12":"code","20ef93e2":"code","827fe834":"code","20287515":"code","1aacf4eb":"code","c3e4c988":"code","57b5a5cb":"code","25a8e964":"code","d717ea29":"code","0cf587b7":"code","ca62bcec":"code","cf981d04":"code","0e907f91":"code","9bbe84ff":"code","1d14ab3d":"code","e3687735":"code","dd8f706a":"code","7fb72eba":"code","ffbe3613":"code","6b06ca1c":"code","7bb70497":"code","da7fa2ed":"code","9343064e":"code","895e62bc":"code","6f59bac4":"code","08df5fb5":"code","d298af4d":"code","a331f52f":"code","98e1f623":"code","51fcd9b2":"code","168b561c":"code","21f0ab7b":"code","98243f08":"code","ab4e4d6c":"code","4a8cf258":"code","57935ef3":"code","ee3695bf":"code","db284cf5":"code","c9b6d149":"code","e292ce98":"code","d2a1838a":"code","5e2f32b3":"code","1bdd6147":"code","44cab762":"code","868b4e99":"code","6f3f079f":"code","8948ea2c":"code","50c1b0e0":"code","536f432c":"code","d6f5acff":"code","42ec70b4":"code","b4d38c2c":"code","a57687e2":"code","948c3298":"code","0fa9a9ab":"code","bea9a4be":"code","542d5f7c":"markdown","9304a93e":"markdown","7cd2412d":"markdown","56b22996":"markdown","a5b0e3d6":"markdown","775cef5f":"markdown","0812b363":"markdown","fd8db8f2":"markdown","5175e564":"markdown","b3e00d36":"markdown","c62f2716":"markdown","f288974b":"markdown","f37cf159":"markdown"},"source":{"d8bb3f00":"#making the imports\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nimport seaborn as sns\nsns.set_style('dark')\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","58b312cb":"#print the directory items\nprint(os.listdir('..\/input\/house-prices-advanced-regression-techniques'))","86d77841":"#read the test and train files\ndf_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","6a3ade8e":"print(df_train.head())\nprint('***************************************************\\n')\nprint(df_test.head())","a30a792c":"#checking the shape of train and test set\n\nprint('The shape of training set is: {}'.format(df_train.shape))\nprint('\\n')\nprint('The shape of test set is: {}'.format(df_test.shape))","2a80c724":"#assigning id column to this variable. we will use it later when writing the submission file. \ntest_ID = df_test['Id']\n\n#delete the id column from datasets\ndel df_train['Id']\ndel df_test['Id']","89a40a27":"#making the scatter plot\ndef scater_plot(x,y,x2,y2):\n    plt.figure(figsize = (10,8))\n    sns.scatterplot(x,y)\n    plt.xlabel(x2,fontsize = 15)\n    plt.ylabel(y2,fontsize = 15)\n    plt.show()","47ab0393":"#scatter plot for living area vs sale price\n\nscater_plot(df_train['GrLivArea'], df_train['SalePrice'], 'GrLivArea', 'SalePrice')","eab998bd":"#scatter plot of Total basement vs sale price\n\nscater_plot(df_train['TotalBsmtSF'], df_train['SalePrice'], 'TotalBsmtSF', 'SalePrice')","fc34eef9":"#scatter plot of Garage Area vs sale price\n\nscater_plot(df_train['GarageArea'], df_train['SalePrice'], 'GarageArea', 'SalePrice')","4f7c69fb":"#scatter plot of Lot Area vs sale price\n\nscater_plot(df_train['LotArea'], df_train['SalePrice'], 'LotArea', 'SalePrice')","e2b5b5b8":"#remove the outliers and store data in a temp df to re-visualize the relation between\n#lot area and sales price. Now we see bit of a linear relationship\n\ntemp_df = df_train[df_train['LotArea'] < 40000]\nscater_plot(temp_df['LotArea'], temp_df['SalePrice'], 'LotArea', 'SalePrice')","05b23d87":"#making the box plot for over all quality vs the sale price\n\nplt.figure(figsize = (14,8))\nsns.boxplot(df_train['OverallQual'], df_train['SalePrice'], palette = 'pastel')\nplt.xlabel('OverallQual', fontsize = 15)\nplt.ylabel('SalePrice', fontsize = 15)\nplt.title('Over all Quality vs Sale Price', fontsize = 20)\nplt.show()","4b2d14c8":"#making the box plot for year built vs the sale price\n\nplt.figure(figsize = (22,8))\nsns.boxplot(df_train['YearBuilt'], df_train['SalePrice'], palette = 'pastel')\nplt.xlabel('YearBuilt', fontsize = 15)\nplt.ylabel('SalePrice', fontsize = 15)\nplt.title('Year Built vs Sale Price', fontsize = 20)\nplt.axis(ymin=0, ymax=600000);\nplt.xticks(rotation=90)\nplt.show()","7a34b306":"#correlation matrix for all features in training set\n\nplt.figure(figsize = (22,18))\ncorrmat = df_train.corr()\nsns.heatmap(corrmat, vmax=.8, square=True, cmap= 'viridis')\nplt.show()","7961280c":"#lets visualize the correlation between less variable which are more correlated\n\nplt.figure(figsize = (18,14))\ncorr_matrix = df_train[['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageYrBlt', 'GarageArea', 'TotalBsmtSF',\n                       '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd']].corr()\n\nsns.heatmap(corr_matrix, vmax = 0.8, linewidths= 0.01, square= True, \n           annot= True, cmap= 'viridis', linecolor= 'white')\n\nplt.title('Correlation Matrix')\nplt.show()","545bccf2":"#check the distribution of target variable \n\nprint (\"Skew is:\", df_train.SalePrice.skew())\nprint('\\n')\nplt.figure(figsize = (8,6))\nplt.hist(df_train.SalePrice, color='blue')\nplt.show()","08ff0a9a":"#making the distribution plot for sale price\n\nplt.figure(figsize = (8,6))\nsns.distplot(df_train['SalePrice'])\nplt.xlabel('Sale Price', fontsize = 15)\nplt.show()","2c998238":"#checking for numerical and categorical features\n\nnumerical_feats = df_train.dtypes[df_train.dtypes != 'object'].index\nprint(\"Number of Numerical features: \", len(numerical_feats))\n\ncategorical_feats = df_train.dtypes[df_train.dtypes == 'object'].index\nprint(\"Number of Categorical features: \", len(categorical_feats))","c572313c":"#printing the columns\n\nprint(df_train[numerical_feats].columns)\nprint(\"*\"*80)\nprint(\"*\"*80)\nprint(df_train[categorical_feats].columns)","6296dd87":"#count and percent of missing values\n\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent']>0]","fc6e1142":"# Function for value counts in each columns\n\ndef cat_exploration(column):\n    return df_train[column].value_counts()\n\n# Function for Imputing the missing values\n\ndef cat_imputation(column, value):\n    df_train.loc[df_train[column].isnull(),column] = value","619b1c12":"#A number of values are missing and one possibility would be to just impute the mean. \n#However, there should actually be a correlation with LotArea, which has no missing values.\n#check correlation of LotFrontage with LotArea\n\ndf_train['LotFrontage'].corr(df_train['LotArea'])","20ef93e2":"# we assume that most lots are rectangular, using the square root might be an improvement.\n\ndf_train['SqrtLotArea']=np.sqrt(df_train['LotArea'])\ndf_train['LotFrontage'].corr(df_train['SqrtLotArea'])","827fe834":"#see the pair plot for LotFrontage and SqrtLotArea\n\nsns.pairplot(df_train[['LotFrontage','SqrtLotArea']].dropna())\nplt.show()","20287515":"#imputing the missing values in LotFrontage column\n\ncond = df_train['LotFrontage'].isnull()\ndf_train.LotFrontage[cond]=df_train.SqrtLotArea[cond]","1aacf4eb":"# This column is not needed now. lets delete it. \n\ndel df_train['SqrtLotArea']","c3e4c988":"#value counts for  Alley column\n\ncat_exploration('Alley')","57b5a5cb":"# empty fields just means that there is no alley access so replace it with none\n\ncat_imputation('Alley','None')","25a8e964":"#value counts for MasVnrType\n\ncat_exploration('MasVnrType')","d717ea29":"#fill the missing with None\n\ncat_imputation('MasVnrType', 'None')","0cf587b7":"#value counts MasVnrArea\ncat_exploration('MasVnrArea')","ca62bcec":"#0.0 is the most frequent value\ncat_imputation('MasVnrArea', 0.0)","cf981d04":"#doing the imputation for basement related columns\n\nbasement_cols=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2']\ndf_train[basement_cols][df_train['BsmtQual'].isnull()==True]","0e907f91":"#replace Nan with None\n\nfor cols in basement_cols:\n    if 'FinSF'not in cols:\n        cat_imputation(cols,'None')","9bbe84ff":"#value counts for  Electrical column\ncat_exploration('Electrical')","1d14ab3d":"#impute with the most occuring value\n\ncat_imputation('Electrical', 'SBrkr')","e3687735":"#value counts for  fireplaceQu\ncat_exploration('FireplaceQu')","dd8f706a":"#lets check the count of missing values\n\ndf_train['FireplaceQu'].isnull().sum()","7fb72eba":"#impute with none as these don't have a fireplace\n\ncat_imputation('FireplaceQu','None')","ffbe3613":"#making corsstab with Fireplaces column\n\npd.crosstab(df_train.Fireplaces, df_train.FireplaceQu)","6b06ca1c":"#now lets do it for Garages columns\n\ngarage_cols=['GarageType','GarageQual','GarageCond','GarageYrBlt','GarageFinish','GarageCars','GarageArea']\ndf_train[garage_cols][df_train['GarageType'].isnull()==True]","7bb70497":"#Garage Imputation - zero for numerical and none for categorical columns\n\nfor cols in garage_cols:\n    if df_train[cols].dtype==np.object:\n        cat_imputation(cols,'None')\n    else:\n        cat_imputation(cols, 0)","da7fa2ed":"#value counts for PoolQC\ncat_exploration('PoolQC')","9343064e":"#count of missing values\ndf_train['PoolQC'].isnull().sum()","895e62bc":"#seems like the missing are the ones where there is no pool in the house. lets put none there\n\ncat_imputation('PoolQC', 'None')","6f59bac4":"#value counts for Fence column\ncat_exploration('Fence')","08df5fb5":"#seems like missing ones are the ones with no Fence\ncat_imputation('Fence', 'None')","d298af4d":"#value counts for MiscFeatures\ncat_exploration('MiscFeature')","a331f52f":"#the missing ones are the ones where we don't have these features\ncat_imputation('MiscFeature', 'None')","98e1f623":"#Let's check if we still have missing values in training set\n\ntotal = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()\/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","51fcd9b2":"#we are done imputing the missing values :-)\n\ndf_train.isnull().any()","168b561c":"#count and percent of missing values\n\ntotal = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent']>0]","21f0ab7b":"# We will use the same two functions for value counts of a column and also for imputation. \ndef cat_exploration(column):\n    return df_test[column].value_counts()\n\n# Function for Imputing the missing values\n\ndef cat_imputation(column, value):\n    df_test.loc[df_test[column].isnull(),column] = value","98243f08":"# as we have already imputed missing values in training set\n# lets do it the same way for test set for some columns which are matching \n\ncat_imputation('Alley','None')\ncat_imputation('MasVnrType', 'None')\ncat_imputation('MasVnrArea', 0.0)\ncat_imputation('FireplaceQu','None')\ncat_imputation('PoolQC', 'None')\ncat_imputation('Fence', 'None')\ncat_imputation('MiscFeature', 'None')","ab4e4d6c":"#imputation for basement columns\n\nbasement_cols=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2']\n\n#replace Nan with None\nfor cols in basement_cols:\n    if 'FinSF'not in cols:\n        cat_imputation(cols,'None')","4a8cf258":"#imputation for garage columns\n\ngarage_cols=['GarageType','GarageQual','GarageCond','GarageYrBlt','GarageFinish','GarageCars','GarageArea']\n\n#Garage Imputation - zero for numerical and none for categorical columns\nfor cols in garage_cols:\n    if df_test[cols].dtype==np.object:\n        cat_imputation(cols,'None')\n    else:\n        cat_imputation(cols, 0)","57935ef3":"#count and percent of missing values\n\ntotal = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent']>0]","ee3695bf":"#A number of values are missing and one possibility would be to just impute the mean. \n#However, there should actually be a correlation with LotArea, which has no missing values.\n# check correlation of LotFrontage with LotArea\n\ndf_test['LotFrontage'].corr(df_test['LotArea'])","db284cf5":"# we assume that most lots are rectangular, using the square root might be an improvement.\n\ndf_test['SqrtLotArea']=np.sqrt(df_test['LotArea'])\ndf_test['LotFrontage'].corr(df_test['SqrtLotArea'])\n","c9b6d149":"#see the pair plot for LotFrontage and SqrtLotArea\n\nsns.pairplot(df_test[['LotFrontage','SqrtLotArea']].dropna())\nplt.show()\n","e292ce98":"#imputing the missing values in LotFrontage column\n\ncond = df_test['LotFrontage'].isnull()\ndf_test.LotFrontage[cond]=df_test.SqrtLotArea[cond]\n","d2a1838a":"# This column is not needed now\n\ndel df_test['SqrtLotArea']","5e2f32b3":"#count and percent of missing values\n\ntotal = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent']>0]","1bdd6147":"#value counts for total basement SF column\n\ncat_exploration('TotalBsmtSF')","44cab762":"#imputation for numerical columns\n\nnum_cols = ['BsmtHalfBath','BsmtFullBath', 'BsmtFinSF2', 'BsmtUnfSF', 'BsmtFinSF1', 'TotalBsmtSF']\n\n#replace with most frequent value which is 0.0\n\nfor col in num_cols:\n    cat_imputation(col,'0.0')\n    \n","868b4e99":"#count and percent of missing values\n\ntotal = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent']>0]","6f3f079f":"#imputation for catrgory columns\n\ncat_cols =['MSZoning', 'Functional', 'Utilities', 'Exterior1st', 'SaleType', 'Exterior2nd', 'KitchenQual']\n\n#replace with none\nfor col in cat_cols:\n    cat_imputation(col,'None')","8948ea2c":"#count and percent of missing values\n\ntotal = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df_test.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data[missing_data['Percent']>0]","50c1b0e0":"#we are done imputing the missing values in test set.\n\ndf_test.isnull().any()","536f432c":"#lets put all features other than sale price in a list\n\nfeatures = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n       'MoSold', 'YrSold', 'SaleType', 'SaleCondition']","d6f5acff":"#create X and y to be used for training the model\n\nX = df_train[features]\ny = df_train.SalePrice","42ec70b4":"#divide the training set into train\/validation set with 20% set aside for validation. \n\nfrom sklearn.model_selection import train_test_split\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.20, random_state=101)","b4d38c2c":"#as we know that we can give categorical features to catboost to make best use of its performance. \n#all categorical features will be where data type is not float\n\ncategorical_features_indices = np.where(X_train.dtypes != np.float)[0]","a57687e2":"#importing catboost regressor and define key parameters\n#we can play with some parameters like learning rate etc\n\nfrom catboost import CatBoostRegressor\nmodel=CatBoostRegressor(iterations=1000, \n                        depth=5, \n                        learning_rate=0.1,\n                        loss_function='RMSE',\n                        random_seed=1,\n                        bagging_temperature=22,\n                        od_type='Iter',\n                        metric_period=100,\n                        od_wait=100)","948c3298":"#train the model (1000 iterations)\n\nmodel.fit(X_train, y_train,cat_features=categorical_features_indices,\n          eval_set=(X_validation, y_validation),plot=True)","0fa9a9ab":"#as we can see that the model starts to overfit after 100 iterations\n#so lets train a new model for 100 iterations only\n\nmodel_2=CatBoostRegressor(iterations=100, \n                        depth=5, \n                        learning_rate=0.1,\n                        loss_function='RMSE',\n                        random_seed=1,\n                        bagging_temperature=22,\n                        od_type='Iter',\n                        metric_period=100,\n                        od_wait=100)\n\n#train the model (100 iterations)\n\nmodel_2.fit(X_train, y_train,cat_features=categorical_features_indices,\n          eval_set=(X_validation, y_validation),plot=True)","bea9a4be":"#make the submission file\n\nsubmission_02 = pd.DataFrame()\nsubmission_02['Id'] = test_ID\nsubmission_02['SalePrice'] = model.predict(df_test)\nsubmission_02.to_csv(\"Submission_02.csv\", index=False)","542d5f7c":"Now we can proceed to build our model. ","9304a93e":"The plot seems to be effected by the outliers. ","7cd2412d":"### So this is the end for this project. \n\n### We successfully did EDA, missing values imputation and build a model to make \n### predictions on test set.\n\n### Further options could be to use different models like lightgbm, xgboost etc.","56b22996":"This Submission has a public leaderboard score of 0.16026 (position 3169 out of 4440). ","a5b0e3d6":"# Data Preprocessing","775cef5f":"# Exploratory Data Analysis","0812b363":"## Imputing the missing values in Train Set","fd8db8f2":"# Imputing the missing values in Test Set","5175e564":"So in the cases where the categorical variables are NaN, the numerical ones are 0. Which means there's no Garage, so the categorical ones should also be set to \"None\".","b3e00d36":"# Cat Boost","c62f2716":"So in the cases where the categorical variables are NaN, the numerical ones are 0. Which means there's no basement, so the categorical ones should also be set to \"None\".","f288974b":"# House Price Prediction\n\nIn this kaggle challenge we are required to predict the final price of a house based on a set of different features (like number of bedrooms, garage size, year built, over all quality etc). There are a total of 79 different features for each house. \n\nWe will do Exploratory Data Analysis , Data preprocessing, Feature Engineering and Model building to predict the target variable. \n","f37cf159":"**Now we will follow the above steps for test set as well.**"}}