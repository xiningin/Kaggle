{"cell_type":{"a485f6f6":"code","62eb8fd6":"code","0b6d584f":"code","de398523":"code","405947df":"code","a04627bd":"code","b41869a3":"code","266dd3a6":"code","c486415a":"code","7d19ec8d":"code","4db60335":"code","6e0c5ca3":"code","31b725b7":"markdown","2448ec3e":"markdown","c3bc63d9":"markdown","2b4220f7":"markdown","e5ae29ae":"markdown","de6cad73":"markdown","d6e19825":"markdown"},"source":{"a485f6f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","62eb8fd6":"import pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom tensorflow.keras.models import Model, Sequential\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tqdm import tqdm","0b6d584f":"jane=pd.read_csv(\"..\/input\/jane-street-market-prediction\/train.csv\")\n\njane=jane[jane['weight']!=0]","de398523":"imputer = SimpleImputer(missing_values = np.nan, strategy ='median') \n\njane2= imputer.fit(jane)\njane2= imputer.transform(jane)","405947df":"jane2=pd.DataFrame(jane2)\n\ncols=jane.columns\n\njane2.columns=cols\n\njane2.drop(['resp_1','resp_2','resp_3','resp_4', 'ts_id'], axis=1, inplace=True)\n\naction=jane2['resp']\n\naction=(action>0)*1","a04627bd":"jane2.drop(['resp'], axis=1, inplace=True)\n\nX_train=jane2[jane2['date']>347]\nX_test=jane2[jane2['date']<=347]\n\ny_train=action[1327574:]\ny_test=action[:1327574]","b41869a3":"inp = tf.keras.layers.Input(shape=(132, ))\n\nfirst_units = [316, 316]\nsecond_units = [158, 158, 158]\nthird_units = [76, 76, 76, 76]\n\n#first block\nb1 = tf.keras.layers.BatchNormalization()(inp)\nfor units in first_units:\n    b1 = tf.keras.layers.Dropout(0.2)(b1)\n    b1 = tf.keras.layers.Dense(units)(b1)\n    b1 = tf.keras.layers.Activation(tf.keras.activations.relu)(b1)\n    \n#second block\nb2 = tf.keras.layers.BatchNormalization()(inp)\nfor units in second_units:\n    b2 = tf.keras.layers.Dropout(0.2)(b2)\n    b2 = tf.keras.layers.Dense(units)(b2)\n    b2 = tf.keras.layers.Activation(tf.keras.activations.relu)(b2)\n\n#third block\nb3 = tf.keras.layers.BatchNormalization()(inp)\nfor units in third_units:\n    b3 = tf.keras.layers.Dropout(0.2)(b3)\n    b3 = tf.keras.layers.Dense(units)(b3)\n    b3 = tf.keras.layers.Activation(tf.keras.activations.relu)(b3)\n    \n    \n#concatenate blocks\nblocks = tf.keras.layers.concatenate([b1, b2, b3])\nblocks = tf.keras.layers.Dense(1)(blocks)\nout = tf.keras.layers.Activation('sigmoid')(blocks)\n\nmodel = tf.keras.models.Model(inputs=inp, outputs=out)","266dd3a6":"from keras.utils import plot_model\ndisplay(plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=True))","c486415a":"lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\n\nmodel.compile(\n    optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule),#learning_rate=lr_schedule\n    loss='binary_crossentropy',  \n    metrics=['binary_accuracy'],\n)\n\n\nearly=EarlyStopping(\n    min_delta=0.01,\n    patience=50,\n    restore_best_weights='True',\n)","7d19ec8d":"history= model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=200, \n    batch_size=4096,\n    callbacks=[early], \n    verbose=0, \n)","4db60335":"history_df=pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss','val_loss']].plot()\nhistory_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()","6e0c5ca3":"import janestreet\n#janestreet.competition.make_env.__called__ = False\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set\n\nimport time\nstart_time = time.time()\n\nfor (test_df, pred_df) in tqdm(env.iter_test()):\n    x_tt = test_df.loc[:,].values\n    if np.isnan(x_tt[:, 1:].sum()):\n        pred_df.action = 0\n    else:\n        pred = model(x_tt, training=False)\n        pred_df.action = np.where(pred > 0.5, 1, 0).astype(int)\n    env.predict(pred_df)\n    \n\n\nprint(f\"took: {time.time() - start_time} seconds\")","31b725b7":"# MODEL","2448ec3e":"Impute by mean","c3bc63d9":"**Upload Dataset and first operations..**","2b4220f7":"Keras","e5ae29ae":"**Plotting the model rapresentation:**","de6cad73":"Create train and test set","d6e19825":"**Upload modules**"}}