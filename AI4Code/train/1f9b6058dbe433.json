{"cell_type":{"994b9dbf":"code","aaa2fbb1":"code","c12f3298":"code","fe12d72a":"code","a242e988":"code","aa8e2efc":"code","ed9236d6":"code","42a67a2a":"code","46c8d2c3":"code","913a30f5":"code","0e849391":"code","bca9177d":"markdown","3997bdf9":"markdown","bf030659":"markdown","2e989667":"markdown","62718b63":"markdown","66637e3a":"markdown","4db74b5b":"markdown","64b55768":"markdown","87d57865":"markdown","3d514fa8":"markdown","c0079f2b":"markdown","3592e9fb":"markdown"},"source":{"994b9dbf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n\n# Input data files are available in the \"..\/input\/\" directory.\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.\n\n# This is a bit of magic to make matplotlib figures appear inline in the notebook\n# rather than in a new window.\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n","aaa2fbb1":"from tensorflow.python.keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# Import Data\ntrain = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest= pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")\nprint(\"Train size:{}\\nTest size:{}\".format(train.shape, test.shape))\n\n# Transform Train and Test into images\\labels.\nx_train = train.drop(['label'], axis=1).values.astype('float32') # all pixel values\ny_train = train['label'].values.astype('int32') # only labels i.e targets digits\nx_test = test.drop(['label'], axis=1).values.astype('float32')\nx_train = x_train.reshape(x_train.shape[0], 28, 28) \/ 255.0\nx_test = x_test.reshape(x_test.shape[0], 28, 28) \/ 255.0\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.11, random_state=42)\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(x_test.shape)","c12f3298":"# classes for title\n# num classes for amount of examples\nclasses = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nprint(x_train.shape)\nnum_classes = len(classes)\nsamples_per_class = 7\nplt.figure(0)\nfor y, cls in enumerate(classes):\n    idxs = np.flatnonzero(y_train == y)\n    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n    for i, idx in enumerate(idxs):\n        plt_idx = i * num_classes + y + 1\n        plt.subplot(samples_per_class, num_classes, plt_idx)\n        # plt.imshow(x_train[idx].astype('uint8'))\n        plt.imshow(x_train[idx])\n        plt.axis('off')\n        if i == 0:\n            plt.title(cls)\nplt.show()","fe12d72a":"x_train = x_train.reshape(x_train.shape[0], 28, 28,1)  \nx_val = x_val.reshape(x_val.shape[0], 28, 28,1)  \nx_test = x_test.reshape(x_test.shape[0], 28, 28,1) \nprint(\"Train size:{}\\nvalidation size:{}\\nTest size:{}\".format(x_train.shape,x_val.shape, x_test.shape))\n\nmean_px = x_train.mean().astype(np.float32)\nstd_px = x_train.std().astype(np.float32)\n","a242e988":"from tensorflow.python.keras.layers import Input , Dense , Conv2D , Activation , Add,ReLU,MaxPool2D,Flatten,Dropout,BatchNormalization\nfrom tensorflow.python.keras.models import Model\n\n\n\ninput = Input(shape=[28, 28, 1])\nx = Conv2D(32, (5, 5), strides=1, padding='same')(input)\n# x = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\nx = Activation('relu')(x)\nx = Conv2D(32, (5, 5), strides=1, padding='same')(x)\n# x = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\nx = Activation('relu')(x)\nx = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\nx = Dropout (0.25)(x)\n\nx = Conv2D(64, (3, 3), strides=1, padding='same')(x)\n# x = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\nx = Activation('relu')(x)\n# x = Dropout (0.5)(x)\nx = Conv2D(64, (3, 3), strides=1, padding='same')(x)\n# x = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\nx = Activation('relu')(x)\nx = Conv2D(64, (3, 3), strides=1, padding='same')(x)\n# x = BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\nx = Activation('relu')(x)\n\nx = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\nx = Dropout (0.35)(x)\nx = Flatten()(x)\nx = Dense(200)(x)\nx = Activation('relu')(x)\nx = BatchNormalization()(x)\nx = Dense(10)(x)\nx = Activation('softmax')(x)\n\nmodel = Model(inputs = input, outputs =x)\nprint(model.summary())","aa8e2efc":"class CollectBatchStats(tf.keras.callbacks.Callback):\n    def __init__(self):\n        self.batch_losses = []\n        self.batch_acc = []\n\n    def on_batch_end(self, batch, logs=None):\n        self.batch_losses.append(logs['loss'])\n        self.batch_acc.append(logs['acc'])\n\nbatch_stats = CollectBatchStats()","ed9236d6":"from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.python.keras.optimizers import Adam ,RMSprop\n\n\n# optimizer = RMSprop(lr=0.001, rho=0.95, epsilon=1e-08, decay=0.0)\nepochs = 50\nLearning_rate = 0.001\ndecay= 5 * Learning_rate \/ epochs\n# optimizer = Adam(lr=Learning_rate, decay= 3 * Learning_rate \/ epochs)\noptimizer = RMSprop(lr=Learning_rate, rho=0.9, epsilon=1e-08, decay= 0)\n\n\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n#               loss='sparse_categorical_crossentropy',\n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00005)\n\n# Data augmentation\n\naug_num = 10 \ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range= 0.8,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = aug_num \/ 100, # Randomly zoom image \n        width_shift_range= aug_num \/ 100,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range= aug_num \/ 100,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=0.05,  # randomly flip images horizontally\n        vertical_flip=False)  # randomly flip images vertically\n\n\ndatagen.fit(x_train)\n# batch_size = 64\nbatch_size = 256\n# Max value lr_min = 0.000125\ncheckpoint = ModelCheckpoint(\"best_weights.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size,callbacks=[checkpoint,learning_rate_reduction])\nmodel.load_weights(\"best_weights.hdf5\") \n","42a67a2a":"plt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Complexity Graph:  Training vs. Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\n\nplt.figure(2)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\nplt.show()\n\n","46c8d2c3":"# predicted class\nnum_rows = 6\nnum_cols = 15\nsample_size = num_rows * num_cols\nindices = np.arange(sample_size)\nx_pred = x_test[indices,:,:]\npredictions = model.predict(x_pred)\nx_pred = np.squeeze(x_test[indices,:,:])\ny_pred = np.argmax(predictions,axis=1)\n\nnum_images = num_rows*num_cols\nplt.figure(figsize=(num_cols*2, num_rows*2))\nplt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.6)\nfor i in range(num_images):\n  plt.subplot(num_rows, num_cols, i+1)\n  plt.imshow(x_pred[i])\n  plt.title(classes[y_pred[i]])\n  # plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  # plot_value_array(i, predictions, test_labels)\nplt.show()","913a30f5":"from sklearn.metrics import confusion_matrix\n\ny_vecs = model.predict(x_val)\ny_pred = np.argmax(y_vecs, axis=1)\ny_true = y_val\ncm = confusion_matrix(y_true, y_pred)\n# print(cm)\n\n# plt.imshow(cm, cmap = 'ocean')\n# plt.colorbar\n\nmin_val, max_val = 0, 15\n\n# intersection_matrix = np.random.randint(0, 10, size=(max_val, max_val))\nfig, ax = plt.subplots(figsize=(20,20))\nax.matshow(cm, cmap=plt.cm.Blues)\n# ax.matshow(cm, cmap=plt.cm.magma_r)\nax.xaxis.set_ticklabels(classes); ax.yaxis.set_ticklabels(classes);\n\nfor i in range(10):\n    for j in range(10):\n        c = cm[j,i]\n        ax.text(i, j, str(c), va='center', ha='center')\n\n\nplt.xticks(range(10))\nplt.yticks(range(10))\nplt.suptitle('Confusion matrix',size = 32)\nplt.xlabel('True labeling',size = 32)\nplt.ylabel('Predicted labeling',size = 32)\nplt.rcParams.update({'font.size': 28})\n\n","0e849391":"# Display some error results \n# y_vecs = model.predict(x_test)\n# y_pred = np.argmax(y_vecs, axis=1)\nY_true = y_val\nY_pred_classes =  y_pred\nY_pred = y_vecs\nX_val = x_val\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 8\n    ncols = 8\n#     plt.figure(figsize=(90, 90))\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=(30, 30))\n    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=1)\n\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted  :{}\\nTrue  :{}\".format(classes[pred_errors[error]],classes[obs_errors[error]]), fontsize=14)\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","bca9177d":"## Miss-labeled data","3997bdf9":"## Plotting prediction\nStright forward taking some images and plotting predictions","bf030659":"## Importing the data the data","2e989667":"## Visualize some examples from the dataset.\nShowing some example per class","62718b63":"### Defining a class to get access about information after each update","66637e3a":"# Checking MNIST model on Fashion MNIST data. \nHi!\n\nPerforms 99.971 on Kaggle MNIST <br>\nInspired by https:\/\/github.com\/zalandoresearch\/fashion-mnist <br> \nI decided to check my best MNIST model: https:\/\/www.kaggle.com\/shaygu\/mnist-using-keras-improving-accuracy-13-99-96  97.13 acc top 9% on the more challenging fashion mnist data.","4db74b5b":"## Visualizations","64b55768":"## Defining the architecture\n\n### Option 1:\nLight architecture with approximately 25K parameters. \n<br>Dropout for avoiding overfitting\n<br>BatchNormalization for faster convergence time","87d57865":"## Adding dimensions for keras","3d514fa8":"## Train the model using data augmentation","c0079f2b":"## Confusion matrix","3592e9fb":"## Starting with Kaggle - imporing data \n\nImportant: Switch settings to GPU"}}