{"cell_type":{"e854edc2":"code","07c0a1b5":"code","31055d0f":"code","b65b9931":"code","777e4e6e":"code","2115f1ed":"code","ff41262b":"code","e52e5154":"code","7f4cc891":"code","7fdc5de8":"code","8b78b3fb":"code","cf7731cc":"code","f37b646b":"code","1bc156ae":"code","cd98cfb8":"code","fb5c1238":"code","b829f977":"code","34199621":"code","94988967":"code","f7f25eca":"code","daa5fbda":"code","aba5477c":"code","e505c379":"code","30a7d6a2":"code","fbf3ed07":"code","d4310194":"code","2ae5ae85":"code","e35ff934":"code","2feffee0":"code","82348e6b":"code","e5954006":"code","9317e7b7":"code","55b0e762":"code","0e9ae061":"code","27b08d3a":"code","d4f2336e":"markdown","dbbdcc42":"markdown","04381697":"markdown","cd416881":"markdown","66a0918b":"markdown","2f7fa4e9":"markdown","133122f3":"markdown","0ed551fd":"markdown","eb016feb":"markdown","3d28110a":"markdown","07526e04":"markdown","8f277f81":"markdown","6d90c100":"markdown","25074cf0":"markdown"},"source":{"e854edc2":"# Silence All Tensorflow Warnings\n!pip install -q silence_tensorflow","07c0a1b5":"# Silence Tensorflow\nimport silence_tensorflow.auto","31055d0f":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\n\nimport joblib\nimport imageio\nimport cv2\nimport os\nimport glob\nimport multiprocessing\n\ntqdm.pandas()","b65b9931":"# Set CV2 to run single threaded, speeds up multithreading\ncv2.setNumThreads(1)","777e4e6e":"# Original Train\ntrain_original = pd.read_csv('\/kaggle\/input\/landmark-recognition-2021\/train.csv')","2115f1ed":"display(train_original.head())","ff41262b":"display(train_original.info())","e52e5154":"# Print class value counts, many classes have just 2 samples!\ntrain_original['landmark_id'].value_counts()","7f4cc891":"train_original_landmark_ids = set(train_original['landmark_id'].unique())\nprint(f'There are {len(train_original_landmark_ids)} unique landmarks')","7fdc5de8":"# Landmark ID occurances, we fill them up to 20 images\noriginal_landmark_id2count = train_original.groupby('landmark_id').count().squeeze().to_dict()","8b78b3fb":"# Original image ids to check for duplicates\noriginal_ids = set(train_original['id'])","cf7731cc":"# GitHub Train of complete dataset\n!wget -cq \"https:\/\/s3.amazonaws.com\/google-landmark\/metadata\/train.csv\"\ntrain_github = pd.read_csv('.\/train.csv')","f37b646b":"display(train_github.head())","1bc156ae":"# The complete dataset contains 203094 classes, many more than the Kaggle dataset\ntrain_github['landmark_id'].value_counts()","cd98cfb8":"display(train_github.info())","fb5c1238":"print(f'There are {train_github[\"landmark_id\"].nunique()} unique landmarks')","b829f977":"github_id2landmark_id = train_github[['id', 'landmark_id']].set_index('id').squeeze().to_dict()","34199621":"res = []\nfor n in tqdm(range(101)):\n    potential = 0\n    for k, count in original_landmark_id2count.items():\n        potential += max(0, n - count)\n    res.append(potential)","94988967":"plt.figure(figsize=(12, 6))\npd.Series(res).plot()\nplt.grid()\nplt.title(f'Potential Number of Extra Train Images per Threshold', size=18)\nplt.xlabel('Threshold', size=16)\nplt.ylabel('Potential Number of Extra Train Images', size=16)\nplt.show()","f7f25eca":"pd.DataFrame({ 'Potential Number of Extra Train Images': res[:26] })","daa5fbda":"# Process Extraced Images, beating heart of this notebook\ndef process_download(idx):\n    # Get all paths to the newly downloaded images\n    file_paths = glob.glob('\/kaggle\/working\/temp\/*\/*\/*\/*.jpg')\n    new_train_data = 0\n    for file_path in file_paths:\n        # Get Image ID to check for duplicates\n        image_id = file_path.split('\/')[-1].split('.')[0]\n        landmark_id = github_id2landmark_id[image_id]\n        # Check for duplicates and check if class is under Kaggle dataset\n        if landmark_id in train_original_landmark_ids and image_id not in original_ids:\n            # Only add image if class count is below threshold\n            count = original_landmark_id2count[landmark_id]\n            if count < THRESHOLD:\n                # Increase class count\n                original_landmark_id2count[landmark_id] += 1\n                # Increase newly found images count\n                new_train_data += 1\n                # Continue, do not remove this image\n                continue\n        # Remove image\n        os.remove(file_path)\n\n    # Ratio of images kept\n    keep_ratio = new_train_data \/ len(file_paths) * 100\n    # Count total new training data\n    total_new_files = new_train_data + len(glob.glob('\/kaggle\/working\/train\/*\/*\/*\/*.jpg'))\n    # Print info\n    if idx % 10 == 0:\n        print(\n            f'{idx:03d} | ' +\n            f'{str(new_train_data).rjust(4)}\/{len(file_paths)} ' +\n            f'({keep_ratio:05.2f}%) images kept' +\n            f', total new files: {total_new_files}'\n        )","aba5477c":"def downsize_single_image(fp):\n    img = imageio.imread(fp)\n    h, w, _ = img.shape\n\n    # Check whether image is bigger than IMG_SIZE\n    if min(h,w) > IMG_SIZE:\n        r = IMG_SIZE \/ min(w, h)\n        w_resize = int(w * r)\n        h_resize = int(h * r)\n        # Resize using high quality LANCZOS algorithm\n        img = cv2.resize(img, (w_resize, h_resize), interpolation=cv2.INTER_LANCZOS4)\n        # Save as JPEG with quality set to 70, just as original images\n        img_jpeg = tf.io.encode_jpeg(img, quality=70, optimize_size=True).numpy()\n        # Overwrite image with lower res version\n        with open(fp, 'wb') as f:\n            f.write(img_jpeg)\n\n# Downsize images in parallel, speeds up the whole process\ndef downsize_images_parallel():\n    jobs = [joblib.delayed(downsize_single_image)(fp) for fp in glob.glob('\/kaggle\/working\/temp\/*\/*\/*\/*.jpg')]\n    joblib.Parallel(\n        n_jobs=cpu_count(),\n        verbose=0,\n        require='sharedmem'\n    )(jobs)","e505c379":"!rm -rf *","30a7d6a2":"# Fill Value\nTHRESHOLD = 20\n# Downsize Image Resolution\nIMG_SIZE = 384\n# Number of cores\nN_CORES = cpu_count()","fbf3ed07":"!mkdir train temp","d4310194":"# Install AXEL for multithreading download\n!apt-get -qq install axel","2ae5ae85":"# Process all TAR files\nfor i in tqdm(range(0, 500)):\n    idx = str(i).rjust(3, '0')\n    file = f'images_{idx}.tar'\n\n    # Get tar file, downloaded in parallel for speedup\n    !axel -q -n \"$N_CORES\" \"https:\/\/s3.amazonaws.com\/google-landmark\/train\/$file\" -o \"temp\"\n\n    # Extract tar file\n    !tar -xf \"\/kaggle\/working\/temp\/$file\" -C \"\/kaggle\/working\/temp\"\n\n    # Process Download\n    process_download(i)\n    \n    # Downsize Images in parallel\n    downsize_images_parallel()\n    \n    # Remove tar file\n    !rm -rf \"\/kaggle\/working\/temp\/$file\"\n\n    # Move all accepted images\n    for source in glob.glob('\/kaggle\/working\/temp\/*'):\n        !cp -r \"$source\" \"\/kaggle\/working\/train\"\n        !rm -rf \"$source\"","e35ff934":"# Computes the mean images size in bytes, used for debug purposes\nfile_paths = glob.glob('\/kaggle\/working\/train\/*\/*\/*\/*.jpg')\nmean_img_size = 0\nfor fp in tqdm(file_paths):\n    with open(fp, 'rb') as f:\n        mean_img_size += len(f.read()) \/ len(file_paths)\n        \nprint(f'Mean image size: {mean_img_size \/ 2**10:.2f}KB')\nprint(f'Maximum amount of images in 20GB dataset: {20 * 2**30 \/ mean_img_size \/ 1000:.1f}K')","2feffee0":"train_extra_list = []\n\nfor file_path in glob.glob('\/kaggle\/working\/train\/*\/*\/*\/*.jpg'):\n    image_id = file_path.split('\/')[-1].split('.')[0]\n    landmark_id = github_id2landmark_id[image_id]\n    \n    train_extra_list.append({ 'id': image_id, 'landmark_id': landmark_id })","82348e6b":"train_extra = pd.DataFrame.from_dict(train_extra_list)","e5954006":"display(train_extra.head())","9317e7b7":"display(train_extra.info())","55b0e762":"# Save Train Extra DataFrame with ID and Landmark ID\ntrain_extra.to_pickle('train_extra.pkl.xz')","0e9ae061":"# Sanity check, there should be no duplicate images present in both train and train_extra\nduplicate_landmark_ids = len(set(train_extra['id']).intersection(set(train_original['id'])))\nprint(f'Found {duplicate_landmark_ids} landmark-ids occuring both in the original and extra dataset')","27b08d3a":"for source in tqdm(glob.glob('\/kaggle\/working\/train\/*')):\n    # Ignore files\n    if '.' not in source:\n        print(f'Zipping folder {source}')\n        folder = source.split('\/')[-1]\n        target = f'{folder}.zip'\n        # Zip\n        !cd \"\/kaggle\/working\/train\" ; zip -qr \"$target\" \"$folder\"\n        # Remove original folder\n        !rm -rf \"$source\"","d4f2336e":"# Process Download","dbbdcc42":"Hello Fellow Kagglers,\n\nThis notebook demonstrates how to get extra train images of low occuring classes. The train data is highly unbalanced, with some classes having thousands of samples and others just a handful of sampples. All classes are filled up to a maximum of 20 samples, greatly increasing the training data for low occuring classes. This should result in a lower class inbalance, lower bias towards the majority class and better recognition for low occuring classes.\n\nAll data is crawled from [this](https:\/\/github.com\/cvdfoundation\/google-landmark) GitHub repository. Over 400,000 new images are added. The provided training set in this competition contains 1.5M images, whereas the complete dataset contains over 4M images!\n\nAll 4M images are downloaded, if the Kaggle training set does not contain the image and the image belongs to a class with less than 20 samples the images is kept, it's as simple as that. The complete dataset also contains over 200,000 classes, most of those are not present in the Kaggle dataset. Only classes present in the Kaggle dataset are added.\n\nThe dataset this notebook results in can be found [here](https:\/\/www.kaggle.com\/markwijkhuizen\/google-landmark-recognition-extra-train-data-pub) and [this](https:\/\/www.kaggle.com\/markwijkhuizen\/google-landmark-recognition-extra-data-tfrec-pub) notebook shows how to convert the images to TFRecords, resulting in [this](https:\/\/www.kaggle.com\/markwijkhuizen\/google-landmark-recognition-extra-train-tfrecs-pub) TFRecords dataset.","04381697":"The notebook disk size limit is just 20GB, therefore the images are downsized to have a smaller side of 384 pixels. This allows for more new training data!","cd416881":"# Extra Image Potential","66a0918b":"# Add Extra Training Data","2f7fa4e9":"# Train Original","133122f3":"# Mean Image Size","0ed551fd":"This function computes the maximum number of additional images for a given fill value. To compute this the assumption is made that each class is filled up to the fill value. Thus with a fill value of 20 the assumption is made the number of samples for each class will be filled up to 20. As can be seen, with a fill value of 100 the additional image potential is over 6 million!","eb016feb":"# Downsize Images","3d28110a":"This step is extremely important, all images must be zipped. Otherwise the notebook crashes, it will add all images as output when the notebook result is converted to HTML. It will thus add over 400K images to a HTML file, the notebook will fail. When zipping the images this will not happen. When creating the dataset Kaggle will automatically unzip the files.","07526e04":"# Create Train Extra DataFrame","8f277f81":"# Zip Dataset","6d90c100":"The files are split up in 500 TAR files, they will all be downloaded and processed. Yes, that's processing half a Terabyte, over 4 million images, in about 6 hours.","25074cf0":"# Train GitHub"}}