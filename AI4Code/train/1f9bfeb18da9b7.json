{"cell_type":{"1e2dc9f8":"code","6644f40c":"code","63d7ffcd":"code","3a507693":"code","5f27f408":"code","9e32bc79":"code","1f4ab4c3":"code","211a4c82":"code","8fbcd64a":"code","42056cec":"code","78ea03f2":"code","d96e6079":"code","92971c77":"code","deee89b8":"code","7fffaa9b":"code","248f2ec0":"code","e09ebac9":"code","263fb1ee":"code","2e09301f":"code","fe2ac19a":"code","3dab9d2c":"code","602327be":"code","c80495f5":"code","507cc130":"code","7a84924e":"code","aa5bb6e8":"code","55670362":"code","e75fb93b":"code","7873753e":"code","2facf7ce":"code","2e05109a":"code","e6617a36":"code","a8398f23":"code","16ec6511":"code","c420a0dc":"code","eaa28cc5":"code","03f05f44":"code","7fa64eb9":"code","ba93bf33":"code","601f1525":"code","27897a11":"markdown","c2365306":"markdown","67a86b83":"markdown","ef1c0523":"markdown","684b9233":"markdown","c550b0d0":"markdown","a9ce36e9":"markdown","3525abb0":"markdown","be028b21":"markdown","624085e3":"markdown","2beb8720":"markdown","cb479d3a":"markdown","16de36b0":"markdown","171f9de2":"markdown","67c6d87d":"markdown","ce41c1fc":"markdown","19552e42":"markdown","1bb3b580":"markdown","011ca9c3":"markdown","042f5457":"markdown","fb9bcf5e":"markdown","b15fb06b":"markdown","ed596d08":"markdown","12ab8f45":"markdown","2c4356f3":"markdown","eee59c77":"markdown","5f80c50a":"markdown","e93d137b":"markdown","f66980c0":"markdown","0a0779b1":"markdown"},"source":{"1e2dc9f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6644f40c":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nfrom mpl_toolkits import mplot3d\n\n%matplotlib inline\nsns.set()\npd.options.display.max_columns = 35","63d7ffcd":"main_data = pd.read_csv(\"..\/input\/customer-personality-analysis\/marketing_campaign.csv\", \n                        header = 0, sep='\\t')\nmain_data.set_index('ID', inplace=True)\nmain_data.head(5)","3a507693":"data = main_data.copy()\ndata.info()  ","5f27f408":"data.dropna(inplace = True)\ndata.info()","9e32bc79":"obj_col = [col for col in data.columns if data[col].dtype == 'object']\ndata[obj_col].head(5)","1f4ab4c3":"data['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'],\n                    format= \"%d-%m-%Y\")\ndata['Dt_Customer'] = (data['Dt_Customer'].max() - data['Dt_Customer']).dt.days\/\/30\ndata['Year_Birth'] = 2014 - data['Year_Birth']\ndata[['Dt_Customer', 'Year_Birth']].head(5)","211a4c82":"print(data['Education'].value_counts())\ndata['Education'].replace({'Basic': 'Undergraduate', '2n Cycle': 'Undergraduate'}, \n                          inplace = True)","8fbcd64a":"print(data['Marital_Status'].value_counts())\ndata['Marital_Status'].replace({'Absurd': 'Single', 'YOLO': 'Single',\n        'Alone': 'Single', 'Widow': 'Single', 'Divorced': 'Single', \n        'Together': 'Couple', 'Married': 'Couple' }, inplace = True)\nprint(\"\\nData Marital_Status after replacing values: \")\nprint(data['Marital_Status'].value_counts())","42056cec":"data['Children'] = data['Kidhome'] + data['Teenhome']\ndata['Children'].value_counts()","78ea03f2":"spending_cols = data.columns[8:14]\npurchase_cols = data.columns[14:19]\ncampaign_cols = data.columns[19:24]\ndata['Spending'] = data[spending_cols].sum(axis = 1)\ndata['Spending'].head(5)","d96e6079":"campaign_cols","92971c77":"filt1 = lambda x: x[3:] if not (x.endswith('Products')) else x[3:x.find('Products')]\nfilt2 = lambda x: x[3:] if not (x.endswith('Purchases')) else x[3:x.find('Purchases')]\n\nspending_cols_rename = {cols: filt1(cols) for cols in spending_cols} \npurchase_cols_rename = {cols: filt2(cols) for cols in purchase_cols}\ncampaign_cols_rename = {cols: cols[8:] for cols in campaign_cols}\n\npurchase_cols_rename.update(campaign_cols_rename)\nspending_cols_rename.update(purchase_cols_rename)\nrename_filter = spending_cols_rename\nrename_filter.update({'Year_Birth':'Age','MntGoldProds':'Gold'})\n\ndata.rename(columns = rename_filter, inplace = True)\ndata.head(5)","deee89b8":"spending_cols = data.columns[8:14]\npurchase_cols = data.columns[14:19]\ncampaign_cols = data.columns[19:24]\n\ndel_cols = ['Kidhome','Teenhome','Z_CostContact', 'Z_Revenue']\n\ndata.drop(del_cols, axis = 1, inplace = True)\ndata.head(5)","7fffaa9b":"data.describe()","248f2ec0":"num_cols = ['Age', 'Spending', 'Income']\nplt.figure(figsize = (12, 6))\nfor i, col in enumerate(num_cols):\n    plt.subplot(1, 3, i+1)\n    data[col].plot(kind = 'box')","e09ebac9":"def remove_outlier(df, columns):\n    df = df.copy()\n    for col in columns:\n        q1 = df[col].quantile(q = 0.25)\n        q3 = df[col].quantile(q = 0.75)\n        intr_qr = q3 - q1\n        upper_range = q3 + (1.5*intr_qr)\n        lower_range = q1 - (1.5*intr_qr)\n        df.loc[df[col]> upper_range, col] = np.nan\n        df.loc[df[col]< lower_range, col] = np.nan\n    return df.dropna()\ndata = remove_outlier(data, ['Age', 'Income', 'Spending'])\n\nplt.figure(figsize = (12, 6))\nfor i, col in enumerate(num_cols):\n    plt.subplot(1, 3, i+1)\n    data[col].plot(kind = 'box')","263fb1ee":"def plot_data(plot_type, Data, sub_row, sub_col, figsize, x = None, y = None, Hue = False, \n              estimator = np.median):\n    plt.figure(figsize = figsize)\n    if plot_type == sns.barplot:\n        for i, col in enumerate(y):\n            plt.subplot(sub_row, sub_col, i+1)\n            plot_type(x = x, y = col, data = Data, estimator = estimator)\n            plt.legend(loc = 'upper right', labels = '', title = col)\n            plt.xlabel('')   \n    else:\n        if Hue: \n            for i, col in enumerate(y):\n                plt.subplot(sub_row, sub_col, i+1)\n                plot_type(x = x, data = Data, hue = col)\n                plt.legend(loc = 'upper right', title = col)\n                plt.ylabel('')\n        else:\n            for i, col in enumerate(x):\n                plt.subplot(sub_row, sub_col, i+1)\n                plot_type(x = col, data = Data)\n                plt.legend(loc = 'upper right', title = col)\n                plt.ylabel('')","2e09301f":"plot_data(sns.countplot, data, 1, 2, figsize = (12, 6), \n         x = ['Education' ,'Marital_Status'] )","fe2ac19a":"plot_data(sns.histplot, data, 1, 3, figsize = (12, 6), \n         x = num_cols)","3dab9d2c":"plot_data(sns.histplot, data, 2,3, figsize = (12, 8), x = spending_cols)","602327be":"plot_data(sns.barplot, data, 3,2, x = 'Education', \n          y = spending_cols, figsize = (12,12 ))","c80495f5":"data['cat_income'] = pd.cut(data['Income'], 4, labels = [1, 2, 3, 4])\nplot_data(sns.barplot, data, 2,3, x = 'cat_income', \n          y = spending_cols, figsize = (12, 8))","507cc130":"plot_data(sns.barplot, data, 3,2, x = 'Education', \n          y = purchase_cols, figsize = (12, 8), estimator =np.mean)","7a84924e":"plot_data(sns.barplot, data, 2,3, x = 'cat_income', \n          y = purchase_cols, figsize = (12, 8), estimator =np.mean)","aa5bb6e8":"campaign_cols = list(campaign_cols) + ['Complain', 'Response']\nplot_data(sns.countplot, data, 4,2, x = 'Education', \n          y = campaign_cols, Hue = True, figsize = (12, 16))","55670362":"plot_data(sns.countplot, data, 2,4, x = 'cat_income', \n          y = campaign_cols, Hue = True, figsize = (12, 8))","e75fb93b":"data = data.drop('cat_income', axis = 1).copy()\nnew_data = data.copy()\nnew_data.head(5)","7873753e":"encoder = LabelEncoder()\n\nfor col in new_data.columns:\n    if new_data[col].dtype == 'object':\n        print('\\n')\n        print('Columns Name: %s' %col)\n        print('************')\n        new_data[col] = new_data[[col]].apply(encoder.fit_transform)\n        for i in range(len(encoder.classes_)):\n            print(encoder.classes_[i],':', i)","2facf7ce":"cols = ['Age', 'Income', 'Spending',\n        'Recency', 'Wines', 'Fruits', 'Meat',\n        'Fish', 'Sweet', 'Gold']\n\nX = new_data.copy()\n\nScaler = StandardScaler()\nfor col in cols:\n    X[col] = Scaler.fit_transform(X[[col]])\n\nX.head(5)","2e05109a":"kmeans_per_cluster = []\nfor i in range(2, 12):\n    temp =KMeans(n_clusters = i, random_state = 0).fit(X)\n    kmeans_per_cluster.append(temp)\n    \ninertia = [model.inertia_ for model in kmeans_per_cluster]\n\nplt.figure(figsize = (12, 6))\nplt.plot(range(2, 12), inertia, 'o-', ms = 8, linewidth=3) \nplt.xlabel('Cluster ')\nplt.ylabel('Inertia')\nplt.annotate('Elbow', xy = (4, inertia[2]) ,xytext = (0.4, 0.6), \n             textcoords='figure fraction',fontsize = 14,\n             arrowprops={'facecolor':'black', 'shrink':0.05})","e6617a36":"plt.figure(figsize = (12, 6))   \nslh_score = [silhouette_score(X, model.labels_) for model in kmeans_per_cluster]\nplt.figure(figsize = (12, 6))\nplt.plot(range(2, 12), slh_score, 'o-', ms = 8, linewidth=3) \nplt.xlabel('Cluster ')\nplt.ylabel('Silhouette Score')","a8398f23":"kmeans = KMeans(n_clusters = 4, random_state=0)\nkmeans.fit(X)\nlabeled_data = new_data.copy()\nlabeled_data['Labels'] = kmeans.labels_\nlabeled_data['Labels'].value_counts()","16ec6511":"plt.figure(figsize = (12, 8))\nsns.countplot(x = 'Labels', hue = 'Education', \n              data = labeled_data)","c420a0dc":"columns = ['Income', 'Age','Spending' , 'Dt_Customer',\n       'Recency', 'Wines', 'Fruits', 'Meat', 'Fish', 'Sweet', 'Gold', 'Deals',\n       'Web', 'Catalog', 'Store', 'WebVisitsMonth','Cmp1', 'Cmp2', 'Cmp3', 'Cmp4', \n       'Cmp5','Response','Complain', 'Marital_Status', 'Children',\n       'Education', 'Labels']\n\nlabeled_data = labeled_data.loc[:, columns]\nlabeled_data.head(5)","eaa28cc5":"func = lambda z: np.sum(z)\/z.count()*100\nfunc1 = {x: 'median' for x in labeled_data.columns[:18]}\nfunc2 = {y: func for y in labeled_data.columns[18:-3]}\nfunc1.update(func2)\ngrouped = labeled_data.groupby('Labels').aggregate(func1).sort_index()   \ngrouped.head(5)","03f05f44":"plot_data(sns.barplot, labeled_data, 1, 3, figsize = (14, 6), x = 'Labels', \n         y = ['Income', 'Spending' , 'Dt_Customer'])","7fa64eb9":"segmentation = {0: 'Low Potential', 1: 'Low Value', \n 2: 'High Potential', 3: 'High Value'}\nlabeled_data['Labels'] = labeled_data['Labels'].map(segmentation)\nprint(labeled_data['Labels'].value_counts())\nlabeled_data.head(5)","ba93bf33":"cus_labels = ['Low Potential','Low Value',\n          'High Potential','High Value']\n\nfig = plt.figure(figsize = (10, 8))\nax  = fig.add_subplot(111, projection = '3d')\nfor seg in cus_labels:\n    filt = labeled_data['Labels'] == seg\n    ax.scatter(xs = data['Income'][filt],\n               ys = data['Spending'][filt],\n               zs = data['Dt_Customer'][filt], \n               cmap = 'jet', label = seg)\n    ax.legend()\nax.set_xlabel('Income')\nax.set_ylabel('Spending')\nax.set_zlabel('Dt_Customer')   ","601f1525":"func = lambda z: np.sum(z)\/len(z)*100\nplot_data(sns.barplot, labeled_data, 4, 2, figsize = ((12, 12)), x = 'Labels', \n         y = campaign_cols, estimator = func)\n","27897a11":"The following charts shows the success rate of marketing campaigns on different segments. For example, it is obvious that the success rate for the last campaign was higher almost for all the segments, so probably it is a good strategy. Or for instance, campaign 3 was better for targetting low potential groups, while campaigns 1, 4, 5 are better for targetting high potential and high-value groups. Perhaps it's a good idea to customise the campaigns for different segments.","c2365306":"The only column that has null data is Income. As the number of null data is negligible, we simply drop them.","67a86b83":"These charts show the Education and Marital Status. We see that most of our customers' Education level is Graduate, and most of them are couples.","ef1c0523":"We create three different lists for spending, purchase, and campaign features, including the name of relevant features in the data. We use these columns for grouping and visualisation. Also, a unique spending column is added to reflect the total spending per customer.","684b9233":"Now that we have explored the data, it's time to prepare them for ML algorithms. First, we replace categorical features with numbers by using Label Encoding: ","c550b0d0":"Now that we don't have any null elements let's take a look at the object type columns.","a9ce36e9":"Lets read the data and have a look at its features. ","3525abb0":"The above plot indicates four segments that we can distinguish based on income, spending, and duration each customer has had service with us. We name the segments based on their potential as follows: \n\n1: New customers with Low income and low spending value: **Low potential** group. This means this group needs attention, and they might not be an appropriate target group. \n\n2: Old customers with low income and low spending: **Low Value** group. This means that this group does not add much value to the company and should be excluded from any marketing campaigns. As they have been with the company for a long time, but their spending is very low. \n\n3: New Customers with high income and high spending: **High Potential** group. This group has a very high potential, as their income is high, and although they are relatively new customers, they have had high spending. \n\n4: Old customers with high income and high spending: **High Value** group. This group should be as high value and loyal customers, and the company should consider plans to satisfy its loyal customers. \n","be028b21":"In the following parts, we start visualising the data to understand the data better. To save time and energy, I have defined the following function specifically for the following sections, and it is able to plot barplot, histplot, and countplot with some flexibility. In this function, we can provide the dimensions of the subplot you want as well as the type of the plot, and it draws the desired charts we need.","624085e3":"The following charts show the distribution of Age, income, total spending, and each spending column individually.","2beb8720":"Now our data is prepared for the algorithm. We use Kmeans algorithm (Unsupervised learning) to find segments with similar behaviours. For finding the correct number of clusters or segments, we draw inertia vs number of clusters to detect the elbow in the diagram, which indicates the right number of clusters.","cb479d3a":"The following chart shows these four segments clearly in a 3D environment. ","16de36b0":"In the following section, we group the columns based on the labels(segments) to find out the characteristics of the segments. For the numerical columns, we use median, and for categorical columns, we use the percentage of positive responses to the campaigns to aggregate the data. For this purpose, I have defined a lambda function that calculates this percentage. Then, we use dict comprehension to map the columns with their appropriate aggregate function and feed this dictionary to groupby method. ","171f9de2":"For getting better results, we need to get rid of the outliers. In the following code, I have defined a function to remove the outlier based on IQR method. From the next box plots, we can see that the outliers are successfully removed.","67c6d87d":"The majority of the columns are integer. We only have three columns whose type is object. Two of them (Education and Marital_status) are categorical, which we label them later on. The dt_customer is a string that needs to be converted to date to calculate customers' seniority.","ce41c1fc":"Although the above table clearly shows the segments' characteristics, we need to see the visualisation to better understand those segments. By using the next plot, we are able to distinguish the segments easily.","19552e42":"Now that we have cleaned the data let's have a look at them. ","1bb3b580":"The kidhome and teenhome columns are combined to form a feature called children. ","011ca9c3":"In this chart, the Income column has been divided into four levels of 1, 2, 3 and 4, with a higher number meaning a higher income level. Therefore, this plot shows the effect of income level on spending habits.","042f5457":"The following two charts show the number of positive and negative responses to all the campaigns for Education and different income levels. ","fb9bcf5e":"The next two charts show the relation between Education and income level with purchasing methods.","b15fb06b":"We first convert the date strings to DateTime format. Then subtract it from the maximum and then divide it by 30 to get the length of each customers seniority in months. \nWe also convert date of birth to age. As the data belongs to 2014, we use it to calculate the ages.\n","ed596d08":"Then we scale the continuous data using standard scaler.","12ab8f45":"There are two categorical features. We try to organise them a little more. For Education, we divide it into four groups: Undergarduate, graduation, Master and Phd, and Marital status divided into two overall categories of single and couple. ","2c4356f3":"The following chart clearly shows that some of our features have outliers. Especially Age and Income. ","eee59c77":"We define two lambda functions and use string methods to rename the name of the columns in the data and remove unwanted parts. For this purpose, we create a dictionary to map each column name with a new one using these functions. Then we feed this dictionary to rename method of pandas to change the column names subsequently. In the end, we delete some of the columns which we don't need.","5f80c50a":"In the following code, I change the order of the columns to perform some other operations on the data more easily.","e93d137b":"The above diagram indicates that 4 is the best number of segments. However, we will use Silhouette score to confirm the results. Silhouette score shows that two is a better choice. However, the score for four is also quite good. So, we stick with four as the number of segments.","f66980c0":"Thank you for taking the time. \n**Please Upvote if you liked my work.**\nThanks","0a0779b1":"The following plot shows how education is related to different categories of spending. It provides us with interesting data, and we can see how the level of education might affect spending habits."}}