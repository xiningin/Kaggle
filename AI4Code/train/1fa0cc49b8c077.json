{"cell_type":{"b2769c35":"code","b06784a6":"code","e2b03078":"code","aa88c2b2":"code","94a42abd":"code","87a420da":"code","e6f09cff":"code","6de4190f":"code","91c53fc5":"code","cb551278":"code","d100c494":"code","df90f96d":"code","3ed67e3b":"markdown"},"source":{"b2769c35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b06784a6":"data = pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', encoding = 'latin-1')\ndata.head()","e2b03078":"cols_to_del = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\ndata.drop(cols_to_del, axis = 1, inplace = True)","aa88c2b2":"data.rename(columns = {'v1' : 'type', 'v2' : 'text'}, inplace = True)\ndata.head()","94a42abd":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nstemer = PorterStemmer()\nstop_words = stopwords.words('english')\nclean_text = []\nfor i in range(0, len(data.text)):\n    review = re.sub('[^a-zA-Z]',' ', data.text[i])\n    review = review.lower()\n    review = review.split()\n    review = [stemer.stem(word) for word in review if word not in set(stop_words)]\n    review = ' '. join(review)\n    clean_text.append(review)\n","87a420da":"# create Bag of Words\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(max_features = 5000)\nX = cv.fit_transform(clean_text).toarray()","e6f09cff":"data['spam'] = data['type'].map({'spam' :1, 'ham' : 0})\ndata.head()","6de4190f":"y = data.spam\n","91c53fc5":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 0)\n","cb551278":"from sklearn.naive_bayes import MultinomialNB\nmy_nmb = MultinomialNB()\nmy_nmb.fit(X_train, y_train)\npredictions = my_nmb.predict(X_test)","d100c494":"from sklearn.metrics import accuracy_score\n\nprint (accuracy_score(y_test, predictions))","df90f96d":"from sklearn.metrics import confusion_matrix\nconfusion_m = confusion_matrix(y_test,predictions)\nconfusion_m","3ed67e3b":"Used basic \/ beginner level logic.\n* Import the data\n* Clean the data (removed punctuation marks, lowered the case, split the sentences in words, removed the stop words , PorterStemmer and finally joined it back to sentence)\n* Bag of Words using CountVectorizer\n* Train test split \n* Applied naive_bayes - MultinomialNB\n"}}