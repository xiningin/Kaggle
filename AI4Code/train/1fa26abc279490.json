{"cell_type":{"b9531c1d":"code","107ba50e":"code","4c637f9a":"code","01b68bbf":"code","1a0f7d4e":"code","63411f24":"code","13c7c5bc":"code","10a13201":"code","32764d05":"code","8e3c1b2d":"code","c08baeb8":"markdown","580ee0a7":"markdown","bd357090":"markdown","1c7323e0":"markdown","9b81c6c9":"markdown","d4e30596":"markdown","964f3db1":"markdown","e1676f1a":"markdown","7f1cb753":"markdown","04b80225":"markdown","659763a2":"markdown"},"source":{"b9531c1d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.base import clone\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV, train_test_split, KFold\nfrom xgboost import XGBClassifier\nimport copy\nfrom sklearn import model_selection\nfrom sklearn import ensemble\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()","107ba50e":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","4c637f9a":"train.head()","01b68bbf":"trace = go.Histogram(x=train['Target'].values)\n\nlayout = go.Layout(\n    title=\"Histogram with Frequency Count\"\n)\n\nfig = go.Figure(data=go.Data([trace]), layout=layout)\npy.iplot(fig)","1a0f7d4e":"# train[train.columns[train.isna().sum()!=0]]\ntrain[train.columns[train.isna().sum()!=0]] = train[train.columns[train.isna().sum()!=0]].fillna(0)\nfor df in (train, test):\n    df['RentByRoom'] = df['v2a1']\/df['rooms']\n    df['TabletsByPeople'] = df['v18q1']\/df['r4t3']\n    df['SizeByPeople'] = df['tamhog']\/df['r4t3']\n    df['PhoneByPeople'] = df['qmobilephone']\/df['r4t3']\n    df['PeopleByRoom'] = df['r4t3']\/df['rooms']    ","63411f24":"y = train['Target']\nX = train.drop(['Target', 'Id'], axis=1)\ntest_id = test['Id']\ntest.drop('Id', axis=1, inplace=True)","13c7c5bc":"train_test_df = pd.concat([X, test], axis=0)\ncols = [col for col in train_test_df.columns if train_test_df[col].dtype == 'object']\n\nle = LabelEncoder()\nfor col in cols:\n    le.fit(train_test_df[col])\n    X[col] = le.transform(X[col])\n    test[col] = le.transform(test[col])","10a13201":"def get_lgb_model():\n    lgb_model = lgb.LGBMClassifier(objective='multiclass',num_leaves=144,\n                      learning_rate=0.05, n_estimators=300, max_depth=13,\n                      metric='merror',is_training_metric=True,\n                      max_bin = 55, bagging_fraction = 0.8,verbose=-1,\n                      bagging_freq = 5, feature_fraction = 0.9) \n    return lgb_model","32764d05":"lgb_model = get_lgb_model()\nlgb_model.fit(X, y)\ntarget_hat = lgb_model.predict(test)","8e3c1b2d":"pred = pd.DataFrame({'Id': test_id, 'Target': target_hat})\npred.to_csv('submission.csv', index=False)","c08baeb8":"### The Notebook will continue to improve. Please Stay Tunned!!\n### Thank you!","580ee0a7":"**Complete Training**","bd357090":"**This notebook has built a base model for predicting the class of test data. The notebook will continue to improve. So please stay tunned with the updates.**<br>\n\n### Content\n[1. Loading Libraries](#1)<br>\n[2. Loading Data](#2)<br>\n[3. Check frequency of each class ](#3)<br>\n[4. Build Base Classification Model](#4)<br>","1c7323e0":"### <a id='1'>1. Loading Libraries<\/a>","9b81c6c9":"**Label Transform all the Features of type object**","d4e30596":"**Create LGB Model**","964f3db1":"There are many columns which has null values. For example, **v18q1, rez_esc**","e1676f1a":"We can see that the **data has unbalanced classes with class 4 occuring most of the time**. So we need to build a model which can handle this unbalanced data.","7f1cb753":"### <a id='2'>2. Load Data<\/a>","04b80225":"### <a id='4'> 4. Build Base Classification Model <\/a>\n**Prepare Data**","659763a2":"### <a id='3'> 3. Check feequency of each class <\/a>"}}