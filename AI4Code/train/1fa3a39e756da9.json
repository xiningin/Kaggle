{"cell_type":{"a601270a":"code","9efdf7e2":"code","5e12b67f":"code","89e18211":"code","fbed77e3":"code","4474c65b":"code","4f7672e2":"code","99b5bc9b":"code","2837b979":"code","c432daf1":"code","b4d6aecd":"code","5ec25d35":"code","ec156fa7":"code","f2580ec5":"code","d074f7e0":"code","3ecaf707":"markdown","30bd3d54":"markdown","fd70d461":"markdown","5d774aea":"markdown","8714c02a":"markdown","670d2c78":"markdown","801538e0":"markdown","2fa30656":"markdown","ed8a3a5b":"markdown","4aa991bc":"markdown","97b37367":"markdown","1eebbe07":"markdown","9df2e86b":"markdown","3baf455f":"markdown","c407c21b":"markdown","a52cdf30":"markdown","a019cbaa":"markdown","b98cf982":"markdown"},"source":{"a601270a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9efdf7e2":"import pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","5e12b67f":"from sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","89e18211":"fashion_mnist = keras.datasets.fashion_mnist\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()","fbed77e3":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']","4474c65b":"x_train = x_train \/ 255.0\nx_test = x_test \/ 255.0","4f7672e2":"x_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.2,random_state = 12345)","99b5bc9b":"plt.figure(figsize=(10,10))\nfor i in range(5):\n    plt.subplot(1,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[y_train[i]])\nplt.show()","2837b979":"image_rows = 28\nimage_cols = 28\nbatch_size = 4096\nimage_shape = (image_rows,image_cols,1) ","c432daf1":"x_train = x_train.reshape(x_train.shape[0],*image_shape)\nx_test = x_test.reshape(x_test.shape[0],*image_shape)\nx_validate = x_validate.reshape(x_validate.shape[0],*image_shape)","b4d6aecd":"cnn_model = Sequential()\ncnn_model.add(Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape))\ncnn_model.add(MaxPool2D(pool_size=2)) # down sampling the output instead of 28*28 it is 14*14\ncnn_model.add(Flatten())# flatten out the layers\ncnn_model.add(Dense(32,activation='relu'))\ncnn_model.add(Dense(10,activation = 'softmax'))","5ec25d35":"cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])","ec156fa7":"history = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=4096,\n    epochs=15,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n)","f2580ec5":"plt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","d074f7e0":"#Get the predictions for the test data\npredicted_classes = cnn_model.predict_classes(x_test)\n#Get the indices to be plotted\n#y_true = test_df.iloc[:, 0]\ncorrect = np.nonzero(predicted_classes==y_test)[0]\nincorrect = np.nonzero(predicted_classes!=y_test)[0]\nfrom sklearn.metrics import classification_report\n#target_names = [\"Class {}\".format(i) for i in range(class_names )]\nprint(classification_report(y_test, predicted_classes, target_names=class_names))","3ecaf707":"**tf.keras.layers.MaxPooling2D(\n    pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None, **kwargs\n)**","30bd3d54":"# looking at few input images","fd70d461":"# CNN Architecture","5d774aea":"# Assigning Classnames","8714c02a":"# Plotting the accuracy and loss","670d2c78":"# Pooling Parameters","801538e0":"![image.png](attachment:image.png)","2fa30656":"# Importing dataset","ed8a3a5b":"# Standardization","4aa991bc":"# Importing Libraries","97b37367":"![image.png](attachment:image.png)","1eebbe07":"![image.png](attachment:image.png)","9df2e86b":"# Validation Set","3baf455f":"![image.png](attachment:image.png)","c407c21b":"# Predicting on the testset","a52cdf30":"# Fixing the CNN Image Size","a019cbaa":"**tf.keras.layers.Conv2D(filters,kernel_size,strides=(1, 1),padding=\"valid\",data_format=None, dilation_rate=(1, 1),\n    groups=1,activation=None,use_bias=True,kernel_initializer=\"glorot_uniform\",bias_initializer=\"zeros\",kernel_regularizer=None,\n    bias_regularizer=None,activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs\n)**","b98cf982":"# Convolution Layer paramaters"}}