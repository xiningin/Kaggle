{"cell_type":{"32f5b775":"code","69077841":"code","8ddb592a":"code","1e08496f":"code","6c4482bf":"code","4599b463":"code","69d83427":"code","dbd103fc":"code","e0cabdc8":"code","056470ad":"code","d00abe49":"code","d74df8a7":"code","6a5bfc4a":"code","7f32ab5a":"code","73435a33":"code","8f29ca11":"code","8695b2a9":"code","223a669c":"code","15b6e036":"code","55788565":"code","c0d7829c":"code","313c0a1b":"code","6bfd1078":"code","f7a1db15":"code","d3437d16":"markdown","d5f1aa23":"markdown","f6b39dec":"markdown","284ae8e9":"markdown","80adb5bc":"markdown","f41fee1e":"markdown","b7bb01c2":"markdown","0bc0b938":"markdown","3c99cf00":"markdown","e90df30b":"markdown","3aadc8d1":"markdown","26553f58":"markdown","e3deb4df":"markdown"},"source":{"32f5b775":"! unzip \"..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip\"\n! unzip \"..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip\"","69077841":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","8ddb592a":"IMAGE_HEIGHT = 128\nIMAGE_WIDTH = 128\nIMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\nIMAGE_CHANNELS = 3\nBATCH_SIZE = 256","1e08496f":"filenames = os.listdir(\"train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == \"dog\":\n        categories.append(1)\n    else:\n        categories.append(0)","6c4482bf":"all_data = pd.DataFrame({\n    \"filename\": filenames,\n    \"category\": categories,\n}, dtype = \"str\")","4599b463":"index = 357\nsample_img_filename, sample_img_label = all_data.iloc[index, :]\nsample_img_label = int(sample_img_label)\nsample_img = plt.imread(\"train\/\" + sample_img_filename)\nplt.imshow(sample_img)\nprint(\"Label: {}({})\".format([\"Cat\", \"Dog\"][sample_img_label], sample_img_label))","69d83427":"train_data, validation_data = train_test_split(all_data, test_size = 0.05, shuffle = True, random_state = 2)\n\ntrain_data = train_data.reset_index(drop = True)\nvalidation_data = validation_data.reset_index(drop = True)\n\ntrain_data.shape, validation_data.shape","dbd103fc":"num_train = train_data.shape[0]\nnum_val = validation_data.shape[0]","e0cabdc8":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization, Activation","056470ad":"train_datagen = ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 15,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_data,\n    directory = \"train\/\",\n    x_col = \"filename\",\n    y_col = \"category\",\n    class_mode = \"binary\",\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n)","d00abe49":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validation_data,\n    directory = \"train\/\",\n    x_col = \"filename\",\n    y_col = \"category\",\n    class_mode = \"binary\",\n    target_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n)","d74df8a7":"example_generator = train_datagen.flow_from_dataframe(\n    train_data.sample(n = 1),\n    directory = \"train\/\",\n    x_col = \"filename\",\n    y_col = \"category\",\n    target_size = IMAGE_SIZE,\n    batch_size = 15,\n)","6a5bfc4a":"plt.figure(figsize = (12, 12))\nfor i in range(15):\n    example_data = next(example_generator)\n    plt.subplot(5, 3, i + 1)\n    image = np.squeeze(example_data[0])\n    plt.imshow(image)\n    \nlabel = int(example_data[1])\nprint(\"Label: {}({})\".format([\"Cat\", \"Dog\"][label], label))","7f32ab5a":"pretrained_base = VGG19(\n    include_top = False, \n    weights = \"imagenet\",\n    input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n    pooling = None,\n)\n\nfor layer in pretrained_base.layers[:5]:\n    layer.trainable = True\nfor layer in pretrained_base.layers[5:]:\n    layer.trainable = False\npretrained_base.summary()","73435a33":"model = Sequential([\n    pretrained_base,\n    Flatten(),\n    Dropout(0.2),\n    Dense(512),\n    BatchNormalization(),\n    Activation(\"relu\"),\n    Dropout(0.2),\n    Dense(128),\n    BatchNormalization(),\n    Activation(\"relu\"),\n    Dropout(0.2),\n    Dense(32),\n    BatchNormalization(),\n    Activation(\"relu\"),\n    Dense(1, activation = \"sigmoid\"),\n])\n\nmodel.summary()","8f29ca11":"model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])","8695b2a9":"model.fit(\n    x = train_generator, \n    steps_per_epoch = num_train \/\/ BATCH_SIZE,\n    epochs = 20,\n    validation_data = validation_generator,\n    validation_steps = num_val \/\/ BATCH_SIZE,\n)","223a669c":"filenames = os.listdir(\"test\")\ntest_data = pd.DataFrame({\n    \"filename\": filenames\n}, dtype = \"str\")","15b6e036":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_data,\n    directory = \"test\",\n    x_col = \"filename\",\n    y_col = None,\n    target_size = IMAGE_SIZE,\n    class_mode = None,\n    shuffle = False,\n    batch_size = 1,\n)","55788565":"predictions = model.predict(x = test_generator, batch_size = 1, steps = test_data.shape[0], verbose = 1)\npredictions.shape","c0d7829c":"predictions = np.squeeze(predictions)","313c0a1b":"ids = np.arange(1, test_data.shape[0] + 1, 1)\nids.shape","6bfd1078":"submission = pd.DataFrame({\n    \"id\": ids,\n    \"label\": predictions,\n})","f7a1db15":"submission.to_csv(\"submission.csv\", index = False)","d3437d16":"**IMPORTING LIBRARIES FOR DEFINING THE MODEL**","d5f1aa23":"**TRAIN-VALIDATION SPLIT**","f6b39dec":"**DEFINING HEAD LAYERS**","284ae8e9":"**IMPORTING LIBRARIES**","80adb5bc":"**SAMPLE IMAGE**","f41fee1e":"**LOADING DATA**","b7bb01c2":"**SUBMISSION**","0bc0b938":"**EXAMPLE GENERATOR**","3c99cf00":"**DEFINING CONSTANTS**","e90df30b":"**PREDICTING ON TEST DATASET**","3aadc8d1":"**DEFINING IMAGE GENERATORS**","26553f58":"**DEFINING PRETRAINED VGG19 MODEL**","e3deb4df":"**UNZIPPING THE DATA**"}}