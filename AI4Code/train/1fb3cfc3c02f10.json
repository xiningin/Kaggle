{"cell_type":{"7020648a":"code","ffe148d8":"code","29baf04f":"code","a644ad3a":"code","5048342d":"code","e6a9e0db":"code","f56cc0bb":"code","5cfd28ba":"code","fc384403":"code","ee1cf979":"code","2bdb213e":"code","18e59e0d":"code","1873c0d9":"code","d87eeca1":"code","a5d5c7f4":"code","0c1aa521":"code","2a2630bc":"code","7733f03e":"code","b13431f3":"code","078f5c22":"code","a6475a30":"code","98b5664b":"code","3262b8e4":"code","a258aae7":"code","21294760":"code","ab1db714":"code","f024e94a":"code","85f3e797":"code","d911969a":"code","accb28ce":"code","eb71612e":"code","d3d3a6f3":"code","c787124a":"code","443c7565":"code","12f4cfa6":"code","320a84c1":"code","3d758c61":"code","b5ffd8d9":"code","29eeb4ea":"code","2a324225":"code","6922bc14":"code","deab6f28":"code","ab905cda":"code","ed92fb39":"code","2b8e8684":"code","90041631":"code","ef3f8c4b":"code","28039e81":"code","74f62db7":"code","3c88d97e":"code","40c74b05":"code","5b5c69b6":"markdown","378af518":"markdown","6f10ef16":"markdown","2b6cd37a":"markdown","0a5d4823":"markdown","848b2ad1":"markdown","e011427a":"markdown","571c5874":"markdown","80ef2be9":"markdown","76b5077b":"markdown","1748bb1b":"markdown","1b793e1d":"markdown","ed3bdded":"markdown","8d49ed0b":"markdown","509cd35e":"markdown","1ad0b4ee":"markdown","91e1f51d":"markdown","c2a290fb":"markdown","2bd1c834":"markdown","a6380e34":"markdown","45dd6635":"markdown","163f8c6d":"markdown","594a1437":"markdown","548e14ff":"markdown","fabdb006":"markdown","37f00a94":"markdown","d6b35893":"markdown","306bc806":"markdown","813a00d8":"markdown","5715d700":"markdown","94caa772":"markdown","2881cbd9":"markdown","d0933500":"markdown","373105e6":"markdown","a57e58f7":"markdown","ab37fe39":"markdown","9e32af36":"markdown","47064619":"markdown","233d97a3":"markdown","63580ea3":"markdown","694d2d82":"markdown","5b8fba9a":"markdown","eb288a26":"markdown","d1333ce2":"markdown","c039b615":"markdown","4742aa55":"markdown"},"source":{"7020648a":"pip install plotly","ffe148d8":"import pandas as pd\nimport numpy as np\nimport plotly.express as px","29baf04f":"df = pd.read_csv(\"https:\/\/cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud\/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork\/labs\/FinalModule_Coursera\/data\/loan_train.csv\")\ndf.head()","a644ad3a":"df['effective_date'] = pd.to_datetime(df['effective_date'])","5048342d":"df['due_date'] = pd.to_datetime(df['due_date'])","e6a9e0db":"df['weekday'] = df['effective_date'].dt.dayofweek","f56cc0bb":"df.head()","5cfd28ba":"df['days_of_week'] = df['weekday'].apply(lambda x: 1 if (x>3) else 0)","fc384403":"df.head()","ee1cf979":"df['Gender'] = df['Gender'].apply(lambda x:1 if(x=='male') else '0')","2bdb213e":"df.head()","18e59e0d":"df['loan_status'] = df['loan_status'].apply( lambda x : 1 if(x=='PAIDOFF') else 0)","1873c0d9":"y = df.groupby(['education'])['loan_status'].value_counts(normalize= True)","d87eeca1":"import plotly.express as px","a5d5c7f4":"max, min  = df['weekday'].max(), df['weekday'].min()\nfig = px.bar(df, x='education',color='loan_status', width=500, height =400)\nfig.show()","0c1aa521":"encoded = pd.get_dummies(df['education'])\nencoded = encoded.drop('Master or Above', axis = 1)\nencoded.head()","2a2630bc":"df = pd.concat([df,encoded], axis= 1)","7733f03e":"df.head()","b13431f3":"fig = px.histogram(df, y= 'Principal', color= 'loan_status',width=500, height =400)\nfig.show()","078f5c22":"Features = list(df.columns)\nFeatures = Features[3:]\nFeatures = df[Features]","a6475a30":"label = df['loan_status']\n","98b5664b":"Features.drop(['due_date','effective_date','education','weekday'] ,axis= 1, inplace= True)\nFeatures.head()\n","3262b8e4":"from sklearn import preprocessing\nFeatures = preprocessing.StandardScaler().fit(Features).transform(Features)","a258aae7":"Features.shape","21294760":"from sklearn.model_selection import train_test_split as split\n\ntrain_x, test_x, train_y, test_y = split(Features,label, test_size = 0.1, random_state = 1)","ab1db714":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","f024e94a":"ks =20\nmean_acc = np.zeros((ks-1))\nstd_acc = np.zeros((ks-1))\nfor n in range(1, ks):\n    neigh = KNeighborsClassifier(n_neighbors= n)\n    neigh.fit(train_x, train_y)\n    prediction = neigh.predict(test_x)\n    mean_acc[n-1] = metrics.accuracy_score(test_y, prediction)\n    \nmean_acc = list(mean_acc)\n\nfor i in range(len(mean_acc)):\n    mean_acc[i] = round(mean_acc[i]*100,1) \n    ","85f3e797":"import plotly.express as px\nfig = px.line(x = np.arange(1,20,1), y= mean_acc,title ='Acurracy v\/s K-value',text = mean_acc)\nfig.show()\n\n# fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n# fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n","d911969a":"del mean_acc","accb28ce":"KNN = KNeighborsClassifier(n_neighbors= 5)\nKNN.fit(train_x, train_y)","eb71612e":"predict = KNN.predict(test_x)","d3d3a6f3":"from sklearn.metrics import jaccard_score\nscore = jaccard_score(test_y,predict)\nprint('Jaccard-Score for KNN with [K=10] is {:.2f}%'.format(score*100))","c787124a":"from sklearn.metrics import f1_score\nscore = f1_score(test_y, predict)\nprint('F1-Score for KNN with [K=10] is {:.2f}%'.format(score*100))","443c7565":"from sklearn.tree import DecisionTreeClassifier","12f4cfa6":"n = 6\nmean_acc = np.zeros(n)\nfor i  in range(1,n+1):\n    tree = DecisionTreeClassifier(criterion='entropy')\n    tree.fit(train_x, train_y)\n    prediction = tree.predict(test_x)\n    mean_acc[i-1] = metrics.accuracy_score(test_y, prediction)\n\nmean_acc = list(mean_acc)\nfor i in range(len(mean_acc)):\n    mean_acc[i]  = round(mean_acc[i], 2)","320a84c1":"fig = px.line(x=np.arange(1,n+1,1), y= list(mean_acc), text=list(mean_acc), title='Accuracy v\/s Layer Number')\nfig.show()","3d758c61":"tree = DecisionTreeClassifier(criterion ='entropy')\ntree.fit(train_x, train_y)\nprediction = tree.predict(test_x)","b5ffd8d9":"score = jaccard_score(test_y,prediction)\nprint('Jaccard-Score for Tree is {:.2f}%'.format(score*100))","29eeb4ea":"score = f1_score(test_y, prediction)\nprint('F1-Score for Tree is {:.2f}%'.format(score*100))","2a324225":"from sklearn import svm\nmachine = svm.SVC()\nmachine.fit(train_x, train_y)\nprediction = machine.predict(test_x)","6922bc14":"score = jaccard_score(test_y,prediction)\nprint('Jaccard-Score for SVM is {:.2f}%'.format(score*100))","deab6f28":"score = f1_score(test_y, prediction)\nprint('F1-Score for SVM is {:.2f}%'.format(score*100))","ab905cda":"from sklearn.linear_model import LogisticRegression\nlinearModel = LogisticRegression(C=0.01, solver = 'liblinear')\nlinearModel.fit(train_x, train_y)\nprediction = linearModel.predict(test_x)","ed92fb39":"score = jaccard_score(test_y,prediction)\nprint('Jaccard-Score for Logistics is {:.2f}%'.format(score*100))","2b8e8684":"score = f1_score(test_y, prediction)\nprint('F1-Score for Logistics is {:.2f}%'.format(score*100))","90041631":"from sklearn.metrics import log_loss\n\nscore = log_loss(test_y,prediction)\nprint('LogLoss-Score for Logistics is:',score)","ef3f8c4b":"test_df = pd.read_csv('https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/ML0101ENv3\/labs\/loan_test.csv')\ntest_df.head()","28039e81":"# Removing unwanted first two columns.\nremove = test_df.columns[0:2]\ntest_df = test_df.drop(remove, axis=1)\n\n#Converting Loan status from descriptive classification to binary classification.\ntest_df['loan_status'] = test_df['loan_status'].apply(lambda x: 1 if(x=='PAIDOFF') else 0)\n\n#Converting Date Times in  date columns, so that we could do some feature engineerign on it later.\ntest_df['effective_date'] = pd.to_datetime(df['effective_date'])\n\n#Getting Days of week on every date.\ntest_df['weekday'] = test_df['effective_date'].dt.dayofweek\n#Setting threshold for days of week by 1 for x>3 and 0 for x<4.\ntest_df['days_of_week'] = test_df['weekday'].apply(lambda x: 1 if(x>3) else 0)\n\n\n#Conversion of discriptive classification to binary classififcation.\ntest_df['Gender'] = test_df['Gender'].apply(lambda x: 1 if (x=='Male') else 0)\n\n# One Hot Encoding for eduction columns.\ndummies = pd.get_dummies(test_df['education'])\n\n# Concatenating two dataframe of dummy and test_df.\ntest_df = pd.concat([test_df, dummies], axis = 1)\n\n#Dropping unnecessasry columns.\ntest_df.drop(test_df.iloc[:,[3,4,6,8,12]],axis  = 1, inplace = True)\n\n#Seprating test_y columns for checking accuracy of model.\nlabels = test_df['loan_status']\ntest_df.drop(['loan_status'], axis = 1, inplace = True)\n\n# Normalizing our DataFrame.\nNormalize = preprocessing.StandardScaler()\nNormalize = Normalize.fit(test_df)\ntest_X = Normalize.transform(test_df)\n\n# Our Data Cake is ready to serve to our Hungary Machine Learning Models.","74f62db7":"t1 = \"Jaccard-Score\"\nt2 = 'F1-Score'\nt3 = \"LogLoss\"\nNames = ['KNN','Tree','SVM','Logistics']\n#Listing all models \nmodels = [KNN,tree, machine, linearModel]\n\n# Creating a dictionary for saving Scores as Dataframe.\nresult = {'Name':[], t1:[], t2:[], t3:[]}\n\n# scores.append (jaccard_score(test_y,predict))\n# scores.append (f1_score(test_y, prediction))\n# scores.append( log_loss(test_y,prediction))\nfor i in range(4):\n    prediction = models[i].predict(test_X)\n    Score1 = jaccard_score(labels, prediction)\n    Score1 = \"{:,.2f}%\".format(Score1*100)\n    \n    Score2 = f1_score(labels, prediction)\n    Score2 = \"{:,.2f}%\".format(Score2*100)\n    \n    Score3 = log_loss(labels, prediction)\n    Score3 = \"{:,.2f}\".format(Score3)\n    \n    result['Name'].append(Names[i])\n    result[t1].append(Score1)\n    result[t2].append(Score2)\n    result[t3].append(Score3)\n    ","3c88d97e":"\nTest_Result = pd.DataFrame.from_dict(result)","40c74b05":"Test_Result","5b5c69b6":"### Jaccard-Score","378af518":"# *So if you looked at all above codes then you have known almost everything in data prepration for this project & I just wants to say to you....*  \n","6f10ef16":"### F1-Score","2b6cd37a":"## Testing Model","0a5d4823":"### F1-Score","848b2ad1":"**Here we see max acurracy is with *[Layer = 2]* after that acurracy is in harmonic trend**","e011427a":"<img src=\"https:\/\/www.tibco.com\/sites\/tibco\/files\/media_entity\/2020-09\/logistic-regression-diagram.svg\">","571c5874":"### Jaccard_score","80ef2be9":"### F1-Score","76b5077b":"### Setting a threshold for weekday.  \n*1 for (days>3) and 0 for (days<4)*","1748bb1b":"<img src ='https:\/\/www.testim.io\/wp-content\/uploads\/2019\/11\/Testim-What-is-a-Test-Environment_-A-Guide-to-Managing-Your-Testing-A.png' width= \"400\">","1b793e1d":"** **","ed3bdded":"### LogLoss","8d49ed0b":"# Support Vector Machine","509cd35e":"<img src ='https:\/\/pbs.twimg.com\/media\/Eh9Z5VMWsAUclr3?format=jpg&name=medium' width='800'>","1ad0b4ee":"### Converting the effective_date & due_date columns to date format.","91e1f51d":"# DataSet","c2a290fb":"** ** ","2bd1c834":"# Start Testing ML-Models","a6380e34":"# Testing Models","45dd6635":"###  Converting Gender..... not real gender of human, just variable   \n**male = 1 & female =0**","163f8c6d":"### Plotting Accuracy","594a1437":"### Real Test Score","548e14ff":"# Logistic Regression","fabdb006":"<img src='https:\/\/waste4change.com\/blog\/wp-content\/uploads\/niko-photos-tGTVxeOr_Rs-unsplash-1160x773.jpg' width =1000>","37f00a94":"## Jaccard Score","d6b35893":"# Transforming Data","306bc806":"**Here Master or Above is insignificant**   \n### One Hot Encoding >Eduction","813a00d8":"** ** ","5715d700":"## F1 Score ","94caa772":"## K-Nearest Neighbours","2881cbd9":"<img src='https:\/\/i2.wp.com\/dataaspirant.com\/wp-content\/uploads\/2017\/01\/Support-vector-machine-svm.jpg?resize=768%2C576&ssl=1'>","d0933500":"## Testing Model","373105e6":"# Normalizing the features Bcz we r going to use Euclidian Distance Matrix","a57e58f7":"# Result","ab37fe39":"### Jaccard-Score","9e32af36":"<img src ='https:\/\/charterforcompassion.org\/images\/menus\/communities\/goodneighbor.jpg'>","47064619":"** **","233d97a3":"**Here we note that accuracy incease upto 83.3% with k= 3.**  \n*Therefor we will build model with K = 3*","63580ea3":"** **","694d2d82":"**Getting respected week days from effective dates.**","5b8fba9a":"# Machine Learning Models","eb288a26":"** **","d1333ce2":"## Decision Tree","c039b615":"** **","4742aa55":"### Concat Two dataframe"}}