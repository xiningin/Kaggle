{"cell_type":{"588d00c1":"code","a4b46ec2":"code","dfcda8fa":"code","108a453b":"code","81822eb0":"code","74a7d201":"code","4a197079":"code","f8b5db6a":"code","5432cfc7":"code","920c0cb0":"code","7517d482":"code","3223e53c":"code","938dc5e3":"code","36326aa3":"code","1783c905":"code","12b3b93b":"code","9a4efef9":"code","66d11438":"code","bde9206d":"code","b3b8ade5":"code","d80ad6d2":"code","687ceb07":"code","8f8f978f":"code","3b866bfa":"code","2286215d":"markdown","366369f4":"markdown","0b024857":"markdown","9c09752d":"markdown","5d7aca67":"markdown","0a9ea976":"markdown"},"source":{"588d00c1":"import numpy as np\nimport pandas as pd\nfrom sklearn import datasets","a4b46ec2":"iris = datasets.load_iris()","dfcda8fa":"X_iris = iris.data\ny_iris = iris.target","108a453b":"from sklearn.preprocessing import scale\nX_scaled = pd.DataFrame(scale(X_iris))","81822eb0":"from sklearn.cluster import KMeans","74a7d201":"from sklearn.metrics import silhouette_samples, silhouette_score\nimport matplotlib.pyplot as plt\n\nKs = [2,3,4,5,6,7,8,9]\nssw=[]\nfor k in Ks:\n    kmeans=KMeans(n_clusters=int(k))\n    kmeans.fit(X_scaled)\n    sil_score=silhouette_score(X_scaled,kmeans.labels_)\n    print(\"silhouette score:\",sil_score,\"number of clusters are:\", int(k))\n    ssw.append(kmeans.inertia_)\nplt.plot(Ks,ssw)","4a197079":"k = 3\nkmeans = KMeans(n_clusters=k)\nkmeans.fit(X_scaled)","f8b5db6a":"labels1 = kmeans.labels_\nX_scaled[\"cluster\"]=labels1","5432cfc7":"for i in range(k):\n    ds = X_scaled[X_scaled[\"cluster\"]==i].as_matrix()\n    plt.plot(ds[:,0],ds[:,1],'o')\n\nplt.show()","920c0cb0":"kmeans.inertia_","7517d482":"from scipy.cluster.hierarchy import dendrogram, linkage\nfrom sklearn.cluster import AgglomerativeClustering","3223e53c":"for n_clusters in range(2,10):\n    cluster_model = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean',linkage='single')\n    cluster_labels = cluster_model.fit_predict(X_scaled)\n    silhouette_avg = silhouette_score(X_scaled,cluster_labels,metric='euclidean')\n    print(\"For n_clusters =\", n_clusters, \n          \"The average silhouette_score is:\", silhouette_avg)","938dc5e3":"for n_clusters in range(2,10):\n    cluster_model = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean',linkage='ward')\n    cluster_labels = cluster_model.fit_predict(X_scaled)\n    silhouette_avg = silhouette_score(X_scaled,cluster_labels,metric='euclidean')\n    print(\"For n_clusters =\", n_clusters, \n          \"The average silhouette_score is:\", silhouette_avg)","36326aa3":"s = 3\nhclust = AgglomerativeClustering(n_clusters=s, affinity='euclidean',linkage='single')\nhclust.fit(X_scaled)","1783c905":"hclust1 = AgglomerativeClustering(n_clusters=s, affinity='euclidean',linkage='complete')\nhclust1.fit(X_scaled)","12b3b93b":"hclust2 = AgglomerativeClustering(n_clusters=s, affinity='euclidean',linkage='average')\nhclust2.fit(X_scaled)","9a4efef9":"hclust3 = AgglomerativeClustering(n_clusters=s, affinity='euclidean',linkage='ward')\nhclust3.fit(X_scaled)","66d11438":"labels = hclust.fit_predict(X_scaled)\nX_scaled[\"cluster\"]=labels","bde9206d":"for i in range(s):\n    hc = X_scaled[X_scaled[\"cluster\"]==i].as_matrix()\n    plt.plot(hc[:,0],hc[:,1],'o')\nplt.show()","b3b8ade5":"# SINGLE","d80ad6d2":"Z = linkage(X_scaled, 'single')\nplt.figure(figsize=(10, 10))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('Cluster points')\nplt.ylabel('Distance')\ndendrogram(Z, leaf_rotation=90.,color_threshold = 40, leaf_font_size=8. )\nplt.tight_layout()","687ceb07":"# COMPLETE\n\nZ1 = linkage(X_scaled, 'complete')\nplt.figure(figsize=(10, 10))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('Cluster points')\nplt.ylabel('Distance')\ndendrogram(Z1, leaf_rotation=90.,color_threshold = 40, leaf_font_size=8. )\nplt.tight_layout()","8f8f978f":"# AVERAGE\n\nZ2 = linkage(X_scaled, 'average')\nplt.figure(figsize=(10, 10))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('Cluster points')\nplt.ylabel('Distance')\ndendrogram(Z2, leaf_rotation=90.,color_threshold = 40, leaf_font_size=8. )\nplt.tight_layout()","3b866bfa":"# WARD\n\nZ33 = linkage(X_scaled, 'ward')\nplt.figure(figsize=(10, 10))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('Cluster points')\nplt.ylabel('Distance')\ndendrogram(Z, leaf_rotation=90.,color_threshold = 40, leaf_font_size=8. )\nplt.tight_layout()","2286215d":"SINGLE","366369f4":"3 is the optimum number of clusters for hierarchical clustering as well","0b024857":"The complete and average distance methods seem to be good as the clusters are compact and are separated from one another by maximal distance.","9c09752d":"3.\tPerform Hierarchical clustering using different linkage methods","5d7aca67":"2.\tFind optimal K","0a9ea976":"when k = 2 the inertia > than when k = 3 so optimal number of clusters = 3 as the purpose of k means clustering is to to rduce the inertia.\n\nFrom the elbow curve maximum number of clusters = 3"}}