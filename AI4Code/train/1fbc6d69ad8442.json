{"cell_type":{"cbacaaca":"code","a12928e6":"code","c2b5922e":"code","13640eee":"code","53869d64":"code","93204ed5":"code","37b7028f":"code","a4b0cc6f":"code","8e4f2bcd":"code","30273669":"code","afeca4c6":"code","b74f4afc":"code","5e177723":"code","338d288a":"code","8a686b72":"code","34403f2b":"code","e06b2c0f":"code","ba6d2273":"code","599da058":"code","ebfc01a0":"code","4df6222c":"code","b413781c":"code","9eb4b37c":"code","3ba39198":"code","7b13d4a3":"markdown","c19cfc7f":"markdown","64795856":"markdown","8f6c666f":"markdown","36754222":"markdown","2eb094a2":"markdown","ba7e8db4":"markdown","e455cb59":"markdown","dda4f3e7":"markdown","282dbcbb":"markdown","11a71617":"markdown","f5b7db65":"markdown","3dadb46f":"markdown","d7d7c288":"markdown","108346be":"markdown","20cb304e":"markdown","7d94dc0d":"markdown","08457f21":"markdown","7570eb2b":"markdown","f108eb93":"markdown","2ace132e":"markdown","27735a08":"markdown","946bd56f":"markdown","ab3dc984":"markdown"},"source":{"cbacaaca":"import pandas as pd\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport tensorflow as tf\nimport seaborn as sns\nfrom pylab import rcParams\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dense\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras import regularizers, Sequential\n%matplotlib inline\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\nrcParams['figure.figsize'] = 14, 8\nRANDOM_SEED = 42\nLABELS = [\"Normal\", \"Fraud\"]","a12928e6":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()","c2b5922e":"df.shape","13640eee":"df.isnull().values.any()","53869d64":"count_classes = pd.value_counts(df['Class'], sort = True)\ncount_classes.plot(kind = 'bar', rot=0)\nplt.title(\"Transaction class distribution\")\nplt.xticks(range(2), LABELS)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\");","93204ed5":"frauds = df[df.Class == 1]\nnormal = df[df.Class == 0]\nfrauds.shape","37b7028f":"normal.shape","a4b0cc6f":"# Fraud transactions\nfrauds.Amount.describe()","8e4f2bcd":"# Non-fraud transactions\nnormal.Amount.describe()","30273669":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Amount per transaction by class')\n\nbins = 50\n\nax1.hist(frauds.Amount, bins = bins)\nax1.set_title('Fraud')\n\nax2.hist(normal.Amount, bins = bins)\nax2.set_title('Normal')\n\nplt.xlabel('Amount ($)')\nplt.ylabel('Number of Transactions')\nplt.xlim((0, 20000))\nplt.yscale('log')\nplt.show();","afeca4c6":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Time of transaction vs Amount by class')\n\nax1.scatter(frauds.Time, frauds.Amount)\nax1.set_title('Fraud')\n\nax2.scatter(normal.Time, normal.Amount)\nax2.set_title('Normal')\n\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Amount')\nplt.show()","b74f4afc":"data = df.drop(['Time'], axis=1)","5e177723":"from sklearn.preprocessing import StandardScaler\n\ndata['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))","338d288a":"non_fraud = data[data['Class'] == 0] #.sample(1000)\nfraud = data[data['Class'] == 1]\n\ndf = non_fraud.append(fraud).sample(frac=1).reset_index(drop=True)\nX = df.drop(['Class'], axis = 1).values\nY = df[\"Class\"].values","8a686b72":"# X_train, X_test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n# X_train_fraud = X_train[X_train.Class == 1]\n# X_train = X_train[X_train.Class == 0]\n# X_train = X_train.drop(['Class'], axis=1)\n# y_test = X_test['Class']\n# X_test = X_test.drop(['Class'], axis=1)\n# X_train = X_train.values\n# X_test = X_test.values\n# X_train.shape","34403f2b":"input_layer = Input(shape=(X.shape[1],))\n\n## encoding part\nencoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\nencoded = Dense(50, activation='relu')(encoded)\n\n## decoding part\ndecoded = Dense(50, activation='tanh')(encoded)\ndecoded = Dense(100, activation='tanh')(decoded)\n\n## output layer\noutput_layer = Dense(X.shape[1], activation='relu')(decoded)","e06b2c0f":"autoencoder = Model(input_layer, output_layer)\nautoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")","ba6d2273":"x = data.drop([\"Class\"], axis=1)\ny = data[\"Class\"].values\n\nx_scale = MinMaxScaler().fit_transform(x.values)\nx_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]","599da058":"autoencoder.fit(x_norm[0:2000], x_norm[0:2000], \n                batch_size = 256, epochs = 10, \n                shuffle = True, validation_split = 0.20);","ebfc01a0":"hidden_representation = Sequential()\nhidden_representation.add(autoencoder.layers[0])\nhidden_representation.add(autoencoder.layers[1])\nhidden_representation.add(autoencoder.layers[2])","4df6222c":"norm_hid_rep = hidden_representation.predict(x_norm[:3000])\nfraud_hid_rep = hidden_representation.predict(x_fraud)","b413781c":"rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\ny_n = np.zeros(norm_hid_rep.shape[0])\ny_f = np.ones(fraud_hid_rep.shape[0])\nrep_y = np.append(y_n, y_f)\n","9eb4b37c":"train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)","3ba39198":"clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\npred_y = clf.predict(val_x)\n\nprint (\"\")\nprint (\"Classification Report: \")\nprint (classification_report(val_y, pred_y))\n\nprint (\"\")\nprint (\"Accuracy Score: \", accuracy_score(val_y, pred_y))","7b13d4a3":"The time does not seem to be a crucial feature in distinguishing normal vs fraud cases. Hence, we drop it.","c19cfc7f":"### Obtain the Hidden Representation","64795856":"### Checking the shape of data","8f6c666f":"### Graphical representation of Amount","36754222":"### Importing necessary libraries","2eb094a2":"The numerical amount in fraud and normal cases differ highly, hence we scale them.","ba7e8db4":"### Plotting time of transaction to check for correlations","e455cb59":"### Checking number of records of each kind of transaction class (Fraud and Non-Fraud)","dda4f3e7":"### Getting the representation data","282dbcbb":"### Scaling the values","11a71617":"### Train, test split","f5b7db65":"The dataset is highly imbalanced. Looking at each of the fraud(1) and non-fraud(0) transactions","3dadb46f":"Train, test split","d7d7c288":"Since only 3 of the features (time, amount and Class) are non-anomyzed, let's explore them.","108346be":"### Checking the amount of money involved in each kind of transaction","20cb304e":"### Building the model\n\nWe will be using **autoencoders** for the fraud detection model. Using autoencoders, we train the database only to learn the representation of the non-fraudulent transactions. The reason behind applying this method is to let the model learn the best representation of non-fraudulent cases so that it automatically distinguishes the other case from it.\n","7d94dc0d":"There are no null values in the data.","08457f21":"### Model Prediction","7570eb2b":"### Scaling the Amount using StandardScaler","f108eb93":"### Checking for null values","2ace132e":"### Reading the data\n\nThe [dataset](https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud) we\u2019re going to use contains data about credit card transactions that occurred during a period of two days, with 492 frauds out of 284,807 transactions.\nAll variables in the dataset are numerical. The data has been transformed using PCA transformation(s) due to privacy reasons. The two features that haven\u2019t been changed are Time and Amount. Time contains the seconds elapsed between each transaction and the first transaction in the dataset.","27735a08":"### Training the model","946bd56f":"### Autoencoder model","ab3dc984":"### Classification model"}}