{"cell_type":{"06e022a7":"code","833ebf30":"code","9ca34304":"code","867658a0":"code","49824edc":"code","66fa44a6":"code","126a5382":"code","245db8db":"code","758dd01b":"code","7c2330c1":"code","2e9fcd97":"code","acfcd077":"code","861b4eaf":"code","4cdc3d89":"code","93ff1ffe":"code","3d556ab5":"code","6232f030":"code","f878e0c0":"code","709d4ed4":"code","bd94dfd6":"code","a15f0ab0":"code","f829104a":"code","9e83b419":"code","f3e757c1":"code","ceacc964":"code","6077b54c":"code","27047778":"code","016485c1":"code","27ac8682":"code","ad252966":"code","536b33d5":"code","25cb5b8e":"code","75e3517d":"code","21f0103f":"code","e4c8acea":"code","47dc86eb":"code","7429ef8a":"code","6d390fe3":"code","86bca64c":"code","00dc6e64":"code","62477a9c":"code","a18a4a45":"code","90be7c48":"code","3fe7d547":"code","d45c4d9d":"code","567b4ae1":"code","f3d5c326":"code","1f015df5":"code","5bc84c91":"code","81490f26":"code","3007c8ce":"code","3335fd0a":"code","6e9dbb6e":"code","9c905ca9":"code","419175f1":"code","d3b69b1b":"code","ee4b0fe4":"code","e292ec03":"code","625c77a3":"code","3dd60c2d":"code","8bef8a90":"code","aa6ddde3":"code","91d037bc":"code","6a82898c":"code","1da057b7":"code","73e9a69e":"code","5812245d":"markdown","0368c71d":"markdown","23fc2689":"markdown","45ef3e85":"markdown","f6917e81":"markdown","6b0ddf7d":"markdown","e2b4be33":"markdown","78b9272b":"markdown","b7c8e4e2":"markdown","b3eafac3":"markdown","c0192dd3":"markdown","ccdf7e8e":"markdown","b5bc0146":"markdown"},"source":{"06e022a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","833ebf30":"df = pd.read_csv('..\/input\/beer-consumption-sao-paulo\/Consumo_cerveja.csv')","9ca34304":"df","867658a0":"df.isnull().sum()","49824edc":"df.dropna(inplace=True)","66fa44a6":"df.info()","126a5382":"df['Data'] = pd.to_datetime(df['Data'])","245db8db":"df.columns","758dd01b":"df['Temperatura Media (C)'] = df['Temperatura Media (C)'].str.replace(',', '.').astype('float')\ndf['Temperatura Minima (C)'] = df['Temperatura Minima (C)'].str.replace(',', '.').astype('float')\ndf['Temperatura Maxima (C)'] = df['Temperatura Maxima (C)'].str.replace(',', '.').astype('float')\ndf['Precipitacao (mm)'] = df['Precipitacao (mm)'].str.replace(',', '.').astype('float')","7c2330c1":"df.info()","2e9fcd97":"df.describe()","acfcd077":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","861b4eaf":"sns.pairplot(df)","4cdc3d89":"X = df.drop(columns=['Data', 'Consumo de cerveja (litros)'])\ny = df['Consumo de cerveja (litros)']","93ff1ffe":"from statsmodels.stats.outliers_influence import variance_inflation_factor","3d556ab5":"vif = pd.DataFrame()\nvif['VIF Factor'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['Features'] = X.columns","6232f030":"vif","f878e0c0":"X = X.drop(columns='Temperatura Media (C)')\nvif = pd.DataFrame()\nvif['VIF Factor'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['Features'] = X.columns\nvif","709d4ed4":"X = X.drop(columns='Temperatura Minima (C)')\nvif = pd.DataFrame()\nvif['VIF Factor'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['Features'] = X.columns\nvif","bd94dfd6":"from sklearn.model_selection import train_test_split","a15f0ab0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)","f829104a":"from sklearn.linear_model import LinearRegression","9e83b419":"lin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\nlin_reg_preds = lin_reg.predict(X_test)","f3e757c1":"print('Linear regression intercept is: ', lin_reg.intercept_)\nprint('Linear regression coefs are: ', lin_reg.coef_)\nprint(\"R squared score for the model is : \", lin_reg.score(X_train, y_train))","ceacc964":"sns.scatterplot(y_test, lin_reg_preds)\nplt.title('Test data vs Linear Regression Predictions')","6077b54c":"sns.distplot(y_test-lin_reg_preds)\nplt.title('Residual Distribution')","27047778":"import statsmodels.api as sm","016485c1":"X_train = sm.add_constant(X_train) # Adding constant\n\npoisson_reg = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()","27ac8682":"poisson_reg.summary()","ad252966":"X_test = sm.add_constant(X_test)\npoisson_reg_preds = poisson_reg.get_prediction(X_test)\npoisson_reg_preds.summary_frame()","536b33d5":"sns.scatterplot(y_test, poisson_reg_preds.summary_frame()['mean'])\nplt.title('Test Data vs Poisson Regression Predictions')","25cb5b8e":"sns.distplot(y_test-poisson_reg_preds.summary_frame()['mean'])\nplt.title('Residuals')","75e3517d":"nbm_reg = sm.GLM(y_train, X_train, family=sm.families.NegativeBinomial()).fit()\nnbm_reg.summary()","21f0103f":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR","e4c8acea":"param_grid = {'kernel' : ['linear', 'rbf', 'sigmoid'], 'gamma' : [1, 0.1, 0.01, 0.001], \n              'C' : [1, 10, 100]}","47dc86eb":"reg_svr = GridSearchCV(estimator=SVR(), param_grid=param_grid)","7429ef8a":"reg_svr.fit(X_train, y_train)","6d390fe3":"reg_svr.best_params_","86bca64c":"reg_svr = SVR(kernel='linear', C=1, gamma=1)","00dc6e64":"reg_svr.fit(X_train, y_train)","62477a9c":"preds_svr = reg_svr.predict(X_test)","a18a4a45":"sns.scatterplot(y_test, preds_svr)","90be7c48":"reg_svr.score(X_train, y_train)","3fe7d547":"sns.distplot(y_test - preds_svr)","d45c4d9d":"from sklearn.tree import DecisionTreeRegressor","567b4ae1":"parameters = {'criterion' : ['mse', 'friedman_mse', 'mae'], 'splitter' : ['random', 'best']}","f3d5c326":"reg_dtree = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=parameters)","1f015df5":"reg_dtree.fit(X_train, y_train)","5bc84c91":"reg_dtree.best_params_","81490f26":"reg_dtree = DecisionTreeRegressor(criterion='mae', splitter='best')","3007c8ce":"reg_dtree.fit(X_train, y_train)","3335fd0a":"preds_dtree = reg_dtree.predict(X_test)","6e9dbb6e":"sns.scatterplot(y_test, preds_dtree)","9c905ca9":"reg_dtree.score(X_train, y_train)","419175f1":"sns.distplot(y_test - preds_dtree)","d3b69b1b":"from sklearn.ensemble import RandomForestRegressor","ee4b0fe4":"p_grid = {'n_estimators' : [100, 200, 500, 800, 1000], 'criterion' : ['mse', 'mae'],\n         'min_samples_split' : [3, 4, 5, 6, 7, 8, 9]}","e292ec03":"reg_rf = GridSearchCV(estimator=RandomForestRegressor(), param_grid=p_grid)","625c77a3":"reg_rf.fit(X_train, y_train)","3dd60c2d":"reg_rf.best_params_","8bef8a90":"reg_rf = RandomForestRegressor(criterion='mse', min_samples_split=9, n_estimators=800)","aa6ddde3":"reg_rf.fit(X_train, y_train)","91d037bc":"pred_rf = reg_rf.predict(X_test)","6a82898c":"sns.scatterplot(y_test, pred_rf)","1da057b7":"reg_rf.score(X_train, y_train)","73e9a69e":"sns.distplot(y_test - pred_rf)","5812245d":"**Let's try and see if Negative Binomial Regression gives us any better results than Poisson model**","0368c71d":"**Hmm. We acheived a humble R sq'd score of 0.72, which is reasonable but not hugely impressive. \nAs we have already noticed earlier in the pair plot that our precipitation variable is basically a count variable with a lot of 0 values.\nLet's try and see if Poisson Regression yields any better results**","23fc2689":"**Basic data cleaning and formatting**","45ef3e85":"**Saperating input and output dats into X and y and checking for multicolinearity in the input data, X**","f6917e81":"**Support Vector Regression - Fine tuning with GridsearchCV**","6b0ddf7d":"**Introduction\n\nAbout this file\nBeer is one of the most democratic and consumed drinks in the world. Not without reason, it is perfect for almost every situation, from happy hour to large wedding parties. If you just think about it, you already feel like having a beer, you\u2019re not alone.\n\nThe objective of this work will be to demonstrate the impacts of variables on beer consumption in a given region and the consumption forecast for certain scenarios. The data (sample) were collected in S\u00e3o Paulo\u200a\u2014\u200aBrazil, in a university area, where there are some parties with groups of students from 18 to 28 years of age (average).**","e2b4be33":"As feared, Negatine Bonomial regression does not seem to be a good fit as we see that we are getting very high p-values in the summary table. There is no point to continue with this regression.","78b9272b":"df.isnull().sum()","b7c8e4e2":"**Let's start with Linear Regression**","b3eafac3":"**Well, it looks like Poisson Regression has performed slightly worse. This might be due to the log Link Function. But anyway, it is not too bad given that we are using a small dataset.**","c0192dd3":"All three temperature variables have extremely high level of multicolinearity. Using backward elimination method, we eliminate variables one by one and see how this affecs VIF scores","ccdf7e8e":"**Decesion Tree Regressor - Fine tunes with GridsearchCV**","b5bc0146":"**OK, so now we have acceptable VIF values and now we can split the data into training and testing sets**"}}