{"cell_type":{"5c75fa0a":"code","05a3866c":"code","9cba037e":"code","9ada690f":"code","b88bab76":"code","a5082a61":"code","92cb739c":"code","ae699dd0":"code","90079d86":"code","3578fd7d":"code","5074a87f":"code","148f7ba0":"code","7cb547dd":"code","5d60b604":"code","19c09435":"code","917cf406":"code","ac23bd9b":"code","bc528740":"code","ead8277d":"code","bf7efe2e":"code","405ed242":"code","0751019d":"code","974b48bb":"code","f8a57fcf":"code","0ce6942e":"code","a14ce88f":"code","17075ce4":"markdown"},"source":{"5c75fa0a":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport json\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers, applications\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom keras import backend as K ","05a3866c":"train_df = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/train.csv\")\ntrain_df[\"attribute_ids\"]=train_df[\"attribute_ids\"].apply(lambda x:x.split(\" \"))\ntrain_df[\"id\"]=train_df[\"id\"].apply(lambda x:x+\".png\")\ntrain_df.head()","9cba037e":"label_df = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/labels.csv\")\nprint(label_df.shape)\nlabel_df.head()","9ada690f":"# Example of images with tags\n\ni = 1\nplt.figure(figsize=[30,30])\nfor img_name in os.listdir(\"..\/input\/imet-2019-fgvc6\/train\/\")[5:10]:   \n    img = cv2.imread(\"..\/input\/imet-2019-fgvc6\/train\/%s\" % img_name)[...,[2, 1, 0]]\n    plt.subplot(5, 1, i)\n    plt.imshow(img)\n    ids = train_df[train_df[\"id\"] == img_name][\"attribute_ids\"]\n    title_val = []\n    for tag_id in ids.values[0]:\n        att_name = label_df[label_df['attribute_id'].astype(str) == tag_id]['attribute_name'].values[0]\n        title_val.append(att_name)\n    plt.title(title_val)\n    i += 1\n    \nplt.show()","b88bab76":"nb_classes = 1103\nbatch_size = 300\nimg_size = 75\nnb_epochs = 25","a5082a61":"lbls = list(map(str, range(nb_classes)))","92cb739c":"%%time\n\ntrain_datagen=ImageDataGenerator(\n    rescale=1.\/255, \n    validation_split=0.25,\n    horizontal_flip = True,    \n    zoom_range = 0.3,\n    width_shift_range = 0.3,\n    height_shift_range=0.3\n    )\n\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"..\/input\/imet-2019-fgvc6\/train\",\n    x_col=\"id\",\n    y_col=\"attribute_ids\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    classes=lbls,\n    target_size=(img_size,img_size),\n    subset='training')\n\nvalid_generator=train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"..\/input\/imet-2019-fgvc6\/train\",\n    x_col=\"id\",\n    y_col=\"attribute_ids\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    classes=lbls,\n    target_size=(img_size,img_size),\n    subset='validation')","ae699dd0":"# Loss\n\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","90079d86":"# Metric\n\ndef f2_score(y_true, y_pred):\n    beta = 2\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n    \n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    \n    return K.mean(((1+beta**2)*precision*recall) \/ ((beta**2)*precision+recall+K.epsilon()))","3578fd7d":"model = applications.InceptionResNetV2(weights=None, \n                          include_top=False, \n                          input_shape=(img_size, img_size, 3))\nmodel.load_weights('..\/input\/inceptionresnetv2\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')","5074a87f":"model.trainable = False","148f7ba0":"# Freeze some layers\n# for layer in model.layers[:-4]:\n#     layer.trainable = False","7cb547dd":"#Adding custom layers \nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\npredictions = Dense(nb_classes, activation=\"softmax\")(x)\nmodel_final = Model(input = model.input, output = predictions)\n\nmodel_final.compile(optimizers.rmsprop(lr=0.001, decay=1e-6),loss=focal_loss,metrics=[f2_score])","5d60b604":"# model_final.summary()","19c09435":"# Callbacks\n\ncheckpoint = ModelCheckpoint(\"model_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')","917cf406":"%%time\nhistory = model_final.fit_generator(generator=train_generator,                   \n                                    steps_per_epoch=500,\n                                    validation_data=valid_generator,                    \n                                    validation_steps=200,\n                                    epochs=nb_epochs,\n                                    callbacks = [checkpoint, early],\n                                    max_queue_size=16,\n                                    workers=2,\n                                    use_multiprocessing=True,\n                                    verbose=0)","ac23bd9b":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['f2_score', 'val_f2_score']].plot()","bc528740":"sam_sub_df = pd.read_csv('..\/input\/imet-2019-fgvc6\/sample_submission.csv')\nsam_sub_df[\"id\"]=sam_sub_df[\"id\"].apply(lambda x:x+\".png\")\nprint(sam_sub_df.shape)\nsam_sub_df.head()","ead8277d":"%%time\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(  \n        dataframe=sam_sub_df,\n        directory = \"..\/input\/imet-2019-fgvc6\/test\",    \n        x_col=\"id\",\n        target_size = (img_size,img_size),\n        batch_size = 1,\n        shuffle = False,\n        class_mode = None\n        )","bf7efe2e":"%%time\ntest_generator.reset()\npredict = model_final.predict_generator(test_generator, steps = len(test_generator.filenames))","405ed242":"len(predict)","0751019d":"%%time\nimport operator\npredicted_class_indices_3=[]\nfor i in range(len(predict)):         \n    d = {}\n    for index, value in enumerate(predict[i]):               \n        if value > 0.03:            \n            d[index] = value \n    sorted_d = sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n    \n    # Take only first 10 items\n    predicted_class_indices_3.append([i[0] for i in sorted_d[:10]])","974b48bb":"%%time\npredictions_3=[]\n\nfor i in range(len(predicted_class_indices_3)):\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predictions = [labels[k] for k in predicted_class_indices_3[i]]\n    predictions_3.append(predictions)","f8a57fcf":"predict_3 = []\nfor i in range(len(predictions_3)):\n    str3 = \" \".join(predictions_3[i])\n    predict_3.append(str3)","0ce6942e":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"id\":filenames,\n                      \"attribute_ids\":predict_3})\nresults['id'] = results['id'].map(lambda x: str(x)[:-4])\nresults.to_csv(\"submission.csv\",index=False)","a14ce88f":"results.head()","17075ce4":"**Simple example of transfer learning from pretrained model using Keras.**\n* Loss: Focal loss\n* Metrics: f2_score"}}