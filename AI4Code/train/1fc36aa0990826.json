{"cell_type":{"37b12501":"code","6f8ec61d":"code","cf368cf3":"code","ede02c7b":"code","500fb5e5":"code","67384e76":"code","4ccca25d":"code","1e822213":"code","bd3dc5cb":"code","2fbfab67":"code","c2d9365e":"code","6e7dba7c":"code","1b6bf3be":"code","b4755bc2":"code","1750c3ca":"code","76c18e9d":"code","f87a60d9":"code","08af0c86":"markdown","792e7678":"markdown"},"source":{"37b12501":"import os\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model","6f8ec61d":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/cats_and_dogs_filtered.zip \\\n    -O \/tmp\/cats_and_dogs_filtered.zip","cf368cf3":"import os\nimport zipfile\n\nlocal_zip = '\/tmp\/cats_and_dogs_filtered.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('\/tmp')\nzip_ref.close()\n\n\n# We will use 2000 pics for training and 1000 pics for testing out of 300 \n# pics in total","ede02c7b":"#Let's define each of these directories:\n\nbase_dir = '\/tmp\/cats_and_dogs_filtered'\ntrain_dir = os.path.join(base_dir,'train')\nvalidation_dir = os.path.join(base_dir,'validation')\n\n# Directory with our training cat pictures\ntrain_cats_dir = os.path.join(train_dir,'cats')\n\n# Directory with our training dog pictures\ntrain_dogs_dir = os.path.join(train_dir,'dogs')\n\n# Directory with our validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir,'cats')\n\n#Directory with our validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir,'dogs')","500fb5e5":"train_cat_fnames = os.listdir(train_cats_dir)\nprint(train_cat_fnames[:10])\n\ntrain_dog_fnames = os.listdir(train_dogs_dir)\nprint(train_dog_fnames[:10])","67384e76":"#Let's take a look at few pictures to get a better sense of what the cat and dogs dataset look like.First,configures the matplotlib parameters\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mping\n\n#Parameters for our graph\nnrows = 4\nncols = 4\n\n#Index for iterating over images\npic_index = 0","4ccca25d":"#Import the inception model\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\n\n\npre_trained_model = InceptionV3(input_shape=(150,150,3),\n                                include_top = False,\n                                weights = 'imagenet')\n","1e822213":" # Make all the layers non-trainable(We can retrain some of the lower layers to increase performance.It might lead to overfitting)\n\n for layer in pre_trained_model.layers:\n   layer.trainable = False","bd3dc5cb":"# We can use binary_crossentropy as the loss metric as we have 2 target classes\n\n#Our optimizer is RMSProp with a learning rate of 0.0001\n\nfrom tensorflow.keras.optimizers import RMSprop\n\n#Flatten the output layer to 1 dimension\nx = layers.Flatten()(pre_trained_model.output)\n#Add a fully connected layer with 1024 hidden units abd ReLU activation\nx = layers.Dense(1024,activation='relu')(x)\n#Add a dropout of 0.2\nx = layers.Dropout(0.2)(x)\n#Add a final sigmoid layer for classification\nx = layers.Dense(1,activation='sigmoid')(x)\n\n\nmodel = Model(pre_trained_model.input,x)\n\nmodel.compile(optimizer = RMSprop(lr = 0.0001),\n              loss = 'binary_crossentropy',\n              metrics = ['acc'])","2fbfab67":"\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\n#Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n#Note that validation data should not be augmented!\ntest_datagen = ImageDataGenerator(rescale = 1.0\/255. )\n\n#Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary',\n                                                    target_size = (150,150))\n\n#Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    batch_size = 20,\n    class_mode = 'binary',\n    target_size = (150,150)\n)","c2d9365e":"history = model.fit_generator(\n    train_generator,\n    validation_data = validation_generator,\n    steps_per_epoch = 100,\n    epochs = 100,\n    validation_steps = 50,\n    verbose = 2\n)","6e7dba7c":"# sets for each training epoch\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n#get number of epochs\nepochs = range(len(acc))\n\n#plot training and validation accuaracy per epoch\nplt.plot(epochs,acc)\nplt.plot(epochs,val_acc)\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\n# Plot training and validation loss per epoch\nplt.plot(epochs,loss)\nplt.plot(epochs,val_loss)\nplt.title('Training and validation loss')\nplt.figure()","1b6bf3be":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('acc')>0.959):\n      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n      self.model.stop_training = True","b4755bc2":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","1750c3ca":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc'])\n\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0\/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary', \n                                                    target_size = (150, 150))     \n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator =  test_datagen.flow_from_directory( validation_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary', \n                                                          target_size = (150, 150))\n\ncallbacks = myCallback()\nhistory = model.fit_generator(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2,\n            callbacks=[callbacks])","76c18e9d":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","f87a60d9":"import numpy as np\nfrom google.colab import files\nfrom keras.preprocessing import image\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n \n  # predicting images\n  path = '\/content\/' + fn\n  img = image.load_img(path, target_size=(150, 150))\n  x = image.img_to_array(img)\n  x = np.expand_dims(x, axis=0)\n\n  images = np.vstack([x])\n  classes = model.predict(images, batch_size=10)\n  print(classes[0])\n  if classes[0]>0.5:\n    print(fn + \" is a dog\")\n  else:\n    print(fn + \" is a cat\")","08af0c86":"After rescaling the images, and using Image Augmentation, we flow them in batches of 20 using train_datagen and train_datagen.","792e7678":"**An approach where we do not use all the layers in the pre-trained model**"}}