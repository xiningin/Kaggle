{"cell_type":{"508e50d6":"code","cb4963b8":"code","21fc6bac":"code","d59885d2":"code","d0b8d9c0":"code","249bd245":"code","161cb38e":"code","7daa043e":"code","dea586e3":"code","5eca7986":"code","096e52de":"code","99fb39b3":"code","673c2c38":"code","fae7151f":"code","4ec77d78":"code","1483b89a":"code","ca8e4dc1":"code","21fc2b8c":"markdown","10e0c2c6":"markdown","d2c01ad7":"markdown","5a647658":"markdown","50104a4d":"markdown","b93c7f52":"markdown","afc70147":"markdown"},"source":{"508e50d6":"import pandas as pd\nimport os","cb4963b8":"# General libraries\nimport numpy as np\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Deep learning libraries\n#import keras.backend as K\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\n\n#Util Component 1: Confusion matrix report\/Accuracy measures\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# disabling warnings\nimport logging\nlogging.getLogger('tensorflow').disabled = True #Jordan_note: Disable red warning lines seen at model architecture creation.","21fc6bac":"def renderConfusionMetrics ( ___model, _testData, _testLabels, enableTraining, ___train_gen, ___test_gen, __batch_size, __epochs, hdf5_testSaveFileName ):\n    preds = ___model.predict(_testData)\n\n    acc = accuracy_score(_testLabels, np.round(preds))*100\n    cm = confusion_matrix(_testLabels, np.round(preds))\n    tn, fp, fn, tp = cm.ravel()\n\n\n    print('\\nCONFUSION MATRIX FORMAT ------------------\\n')\n    print(\"[true positives    false positives]\")\n    print(\"[false negatives    true negatives]\\n\\n\")\n\n    print('CONFUSION MATRIX ------------------')\n    print(cm)\n\n    print('\\nTEST METRICS ----------------------')\n    precision = tp\/(tp+fp)*100\n    recall = tp\/(tp+fn)*100\n    specificity = tn\/(tn+fp)*100 #Jordan_note: added specificity calculation \n    print('Accuracy: {}%'.format(acc))\n    print('Precision: {}%'.format(precision))\n    print('Recall\/Sensitivity: {}%'.format(recall)) #Jordan_note: added sensitivity label\n    print('Specificity {}%'.format(specificity)) #Jordan_note: added specificity calculation \n    print('F1-score: {}'.format(2*precision*recall\/(precision+recall)))\n\n\n    if enableTraining:\n        checkpoint = ModelCheckpoint(filepath=hdf5_testSaveFileName, save_best_only=True, save_weights_only=True)\n        lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n        early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n\n\n        hist = ___model.fit_generator(\n                   ___train_gen, steps_per_epoch=___test_gen.samples \/\/ __batch_size, \n                   epochs=__epochs, validation_data=___test_gen, \n                   validation_steps=___test_gen.samples \/\/ __batch_size, callbacks=[checkpoint, lr_reduce])\n\n        print('\\nTRAIN METRIC ----------------------')\n        print('Covid19 Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))\n\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(hist.history[met])\n        ax[i].plot(hist.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['train', 'val'])\n    plt.savefig('train_val_acc_loss.png')","d59885d2":"#Util Component 2:model architecture description\ndef defineModelArchitecture (_img_dims ):\n    # Input layer\n    inputs = Input(shape=(_img_dims, _img_dims, 3))\n\n    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n    x = Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n\n    x = Flatten()(x)\n    x = Dense(units=512, activation='relu')(x)\n    x = Dropout(rate=0.7)(x)\n    x = Dense(units=128, activation='relu')(x)\n    x = Dropout(rate=0.5)(x)\n    x = Dense(units=64, activation='relu')(x)\n    x = Dropout(rate=0.3)(x)\n\n    # Output layer\n    output = Dense(units=1, activation='sigmoid')(x)\n    \n    return inputs, output\n\n\n\n\ndef process_data(___inputPath, img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=___inputPath+'train', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=___inputPath+'test', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n    # I will be making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n        for img in (os.listdir(___inputPath + 'test' + cond)):\n            img = cv2.imread(___inputPath+'test'+cond+img,0) #Replace plt.imread, with  gray scale cv2.imread(path,0), so that ui's image load process doesn't throw a pyimage10 error\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') \/ 255\n            if cond=='\/NORMAL\/':\n                label = 0\n            elif cond=='\/PNEUMONIA\/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels\n    \n\n###########\n#Util Component 4: Report file distributions\n#directoryProcessArray eg, = ['train', 'val', 'test'], in the case that training val and test folders exist in sub-dir for processing.\ndef reportFileDistributions (___inputPath, directoryProcessArray):\n    for _set in directoryProcessArray:\n        n_normal = len(os.listdir(___inputPath + _set + '\/NORMAL'))\n        n_infect = len(os.listdir(___inputPath + _set + '\/PNEUMONIA'))\n        print('Set: {}, normal images: {}, regular pneumonia images: {}'.format(_set, n_normal, n_infect))","d0b8d9c0":"# Setting seeds for reproducibility\nseed = 232\nnp.random.seed(seed)\ntf.random.set_seed(seed)","249bd245":"# Hyperparameters\nimg_dims = 150\nbatch_size = 32","161cb38e":"inputs, output = defineModelArchitecture ( img_dims )","7daa043e":"# Creating model and compiling\nmodel_pneumoniaDetector = Model(inputs=inputs, outputs=output)\nmodel_pneumoniaDetector.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_pneumoniaDetector.summary()","dea586e3":"input_path_b = '..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/'","5eca7986":"# Report file distributions\nreportFileDistributions (input_path_b, ['train', 'val', 'test'] )","096e52de":"# Getting the data\ntrain_gen, test_gen, test_data_b, test_labels_b = process_data(input_path_b, img_dims, batch_size)","99fb39b3":"renderConfusionMetrics(model_pneumoniaDetector, test_data_b, test_labels_b, True, train_gen, test_gen, batch_size, 10, 'model_weights.hdf5')\n","673c2c38":"inputs, output = defineModelArchitecture(img_dims)\n\n# Creating model and compiling\nmodel_covid19PneumoniaDetector = Model(inputs=inputs, outputs=output)\nmodel_covid19PneumoniaDetector.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_covid19PneumoniaDetector.load_weights('model_weights.hdf5')","fae7151f":"input_path_d = '..\/input\/covid19-xray-dataset-train-test-sets\/xray_dataset_covid19\/'","4ec77d78":"reportFileDistributions (input_path_d, ['train', 'test'])","1483b89a":"train_gen_d, test_gen_d, test_data_d, test_labels_d = process_data(input_path_d, img_dims, batch_size)","ca8e4dc1":"renderConfusionMetrics(model_covid19PneumoniaDetector, test_data_d, test_labels_d, True, train_gen_d, test_gen_d, batch_size, 10, 'covid19_model_weights.hdf5')","21fc2b8c":"# Non-COVID-19 Lung Pneumonia Detection","10e0c2c6":"# COVID-19 Lung Pneumonia Detection","d2c01ad7":"# References\n\n[1] Joseph Paul Cohen and Paul Morrison and Lan Dao. COVID-19 image data collection, arXiv, 2020. https:\/\/github.com\/ieee8023\/covid-chestxray-dataset\n\n[2] https:\/\/github.com\/JordanMicahBennett\/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR\/","5a647658":"## Thank you! I'll be updating this kernel from time to time, when new COVID-19 images come in. Stay safe and happy Kaggling everyone! :)","50104a4d":"# Utility Functions","b93c7f52":"# Imports","afc70147":"# Acknowledgements\n\n- Dataset from https:\/\/github.com\/ieee8023\/covid-chestxray-dataset\n- COVID-19 Detector code from https:\/\/github.com\/JordanMicahBennett\/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR\/"}}