{"cell_type":{"31007baf":"code","98448822":"code","85c165db":"code","7abdfe34":"code","80c44b86":"code","d3d088e6":"code","d9f4a82b":"code","08e75a43":"code","2363045f":"code","61897f6b":"code","c06ac1bc":"code","44ca8867":"code","583a6178":"code","df92a4ab":"code","ec370002":"code","af865d89":"code","5fb577ec":"code","d7422e56":"code","caf5eea2":"code","eb10a319":"code","dac6e2e5":"code","49fe0db4":"code","e7d3e12e":"code","64046c6f":"code","e572f3dc":"code","5bbb057d":"code","494a9990":"code","5b676dd0":"code","53b50905":"code","a89e0f3a":"code","7dd909ac":"code","4071b4fe":"code","08f3d4a5":"markdown"},"source":{"31007baf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98448822":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)","85c165db":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ncombine = [train_data, test_data]","7abdfe34":"train_data.describe()","80c44b86":"train_data.describe(include=['O'])","d3d088e6":"nan_percent = train_data.isna().mean()*100\nnan_count = train_data.isna().sum()\npd.concat([nan_count.rename('missing_count'), nan_percent.round().rename('missing_percent')], axis=1)","d9f4a82b":"test_data.isna().sum()","08e75a43":"from sklearn.impute import SimpleImputer\n# Imputation\nimputer = SimpleImputer()\ntrain_data[['Age', 'Fare']] = imputer.fit_transform(train_data[['Age', 'Fare']])\ntest_data[['Age', 'Fare']] = imputer.transform(test_data[['Age', 'Fare']])","2363045f":"train_data[\"Embarked\"].fillna(train_data[\"Embarked\"].value_counts().index[0], inplace=True)\ntest_data[\"Embarked\"].fillna(test_data[\"Embarked\"].value_counts().index[0], inplace=True)","61897f6b":"test_data.isna().sum()","c06ac1bc":"train_data['Sex'] = train_data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\ntest_data['Sex'] = test_data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_data.head()","44ca8867":"sns.barplot(x='Sex', y='Survived', data=train_data)","583a6178":"g = sns.FacetGrid(train_data, col=\"Survived\", margin_titles=True)\ng.map(plt.hist, 'Age', bins=5)","df92a4ab":"train_d = train_data.copy()\ntrain_d['AgeBand'] = pd.cut(train_d['Age'], 5)\ntrain_d[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","ec370002":"train_data[\"Age\"] = pd.cut(train_data[\"Age\"], 5, labels=[1,2,3,4,5])\ntest_data[\"Age\"] = pd.cut(test_data[\"Age\"], 5, labels=[1,2,3,4,5])\ntrain_data.head()","af865d89":"g = sns.FacetGrid(train_data, col=\"Survived\", margin_titles=True)\ng.map(plt.hist, 'Fare', bins=4)","5fb577ec":"train_d['FareBand'] = pd.qcut(train_d['Fare'], 6)\ntrain_d[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","d7422e56":"train_data[\"Fare\"] = pd.qcut(train_data[\"Fare\"], 6, labels=[1,2,3,4,5,6])\ntest_data[\"Fare\"] = pd.qcut(test_data[\"Fare\"], 6, labels=[1,2,3,4,5,6])\ntrain_data.head()","caf5eea2":"train_data['FamilySize'] = train_data['SibSp'] +  train_data['Parch'] + 1\ntest_data['FamilySize'] = test_data['SibSp'] +  test_data['Parch'] + 1\nprint (train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","eb10a319":"sns.barplot(x='FamilySize', y='Survived', data=train_data)","dac6e2e5":"train_data['Isalone'] = train_data['FamilySize'].lt(2)\ntest_data['Isalone'] = test_data['FamilySize'].lt(2)\n\ntrain_data.head()","49fe0db4":"train_data['Title'] = train_data.Name.str.extract(' ([A-Za-z]+)\\.')\ntest_data['Title'] = test_data.Name.str.extract(' ([A-Za-z]+)\\.')","e7d3e12e":"pd.crosstab(train_data['Title'], train_data['Sex'])","64046c6f":"train_data['Title'] = train_data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Major', 'Rev', 'Sir', 'Dr', 'Jonkheer', 'Dona'], 'Other')\ntrain_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Ms', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace('Mme', 'Mrs')\n\ntest_data['Title'] = test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Major', 'Rev', 'Sir', 'Dr', 'Jonkheer', 'Dona'], 'Other')\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Ms', 'Miss')\ntest_data['Title'] = test_data['Title'].replace('Mme', 'Mrs')\n    \ntrain_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","e572f3dc":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\ntrain_data['Title'] = train_data['Title'].map(title_mapping)\ntrain_data['Title'] = train_data['Title'].fillna(0)\ntest_data['Title'] = test_data['Title'].map(title_mapping)\ntest_data['Title'] = test_data['Title'].fillna(0)","5bbb057d":"columns_to_drop = ['Ticket', 'Cabin', 'Name', 'SibSp', 'Parch']\ntrain_data = train_data.drop(columns_to_drop, axis=1)\ntest_data = test_data.drop(columns_to_drop, axis=1)","494a9990":"train_data['Embarked'] = train_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntest_data['Embarked'] = test_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","5b676dd0":"train_data.head()","53b50905":"test_data.head()","a89e0f3a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train_data.drop(['Survived', 'PassengerId'], axis=1), train_data['Survived'], random_state=42)\n\nmodel = RandomForestClassifier(n_estimators=50, max_depth=5)\nmodel.fit(X_train, y_train)\n\nacc_random_forest = round(model.score(X_test, y_test) * 100, 2)\nprint (acc_random_forest)","7dd909ac":"importance = pd.DataFrame({\"feature\":X_train.columns, \"importance\": np.round(model.feature_importances_,3)})\nimportance = importance.sort_values(\"importance\", ascending=False).set_index(\"feature\")\nimportance.plot(kind='bar', rot=0)\nplt.show()","4071b4fe":"X_train = train_data.drop(['PassengerId', 'Survived'], axis=1)\ny_train = train_data['Survived']\nX_test = test_data.drop(['PassengerId'], axis=1)\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5)\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","08f3d4a5":"----------------------------"}}