{"cell_type":{"1ea79abe":"code","74ff1f9b":"code","e9e9cabe":"code","22c98ca2":"code","12eba76e":"code","91015fd4":"code","00befb92":"code","3116a24b":"code","06d5a3ae":"code","dd38e615":"code","d0aa8c08":"code","4dd54421":"code","37efc533":"code","f4744970":"code","01f65dd1":"code","1a43ec0b":"code","84f6d80a":"code","6fdf06e5":"code","3d612057":"code","82b51180":"code","eb99dacc":"code","f5563ec4":"code","9d995885":"code","e3951b0d":"code","4682f17a":"code","02d641e7":"code","2163e74f":"code","195b272f":"code","63828c84":"code","4a5d7117":"markdown","f53c2339":"markdown","7d034874":"markdown","af035a8d":"markdown","cc300575":"markdown","0abb2660":"markdown","04bc8923":"markdown","493bec65":"markdown","70b7dde6":"markdown","28abc9f9":"markdown","6f652473":"markdown","fe111ed4":"markdown","9bc6b471":"markdown","ffc9ed6d":"markdown","ea8047be":"markdown","551dd062":"markdown"},"source":{"1ea79abe":"# Handling Data\nimport pandas as pd\nimport numpy as np\n\n# Visialization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\n# For Text processing \nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\n# nltk.download('punkt')\n# nltk.download('stopwords')\n\n# ML\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n# DL\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, BatchNormalization, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential\n\n#Accuracy Metrics\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n","74ff1f9b":"df = pd.read_csv('\/kaggle\/input\/spam-mails-dataset\/spam_ham_dataset.csv')\n# Removing Unnecessary column\ndf.drop('Unnamed: 0', axis=1, inplace = True)\n# Changing column names\ndf.columns = ['label', 'text', 'class']","e9e9cabe":"df.head()","22c98ca2":"df.shape","12eba76e":"df.info()","91015fd4":"# No NaN in the data\ndf.isna().sum()","00befb92":"# Barplot describes the count of the class labels\nplt.figure(figsize = (12, 6))\nsns.countplot(data = df, x = 'label');","3116a24b":"# Let's see few examples of the data\n\nfor i in df.iterrows():\n    print(\"Class Label: {}\\nMail: \\n{}\\n\\n\".format(i[1][0], i[1][1]))\n    if i[0] == 6: break\n   ","06d5a3ae":"%%time\nstop_words = set(stopwords.words('english')) \n\ndf['text'] = df['text'].apply(lambda x: ' '.join([ word for word in word_tokenize(x)  if not word in stop_words]))","dd38e615":"df.sample(10)","d0aa8c08":"X = df.loc[:, 'text']\ny = df.loc[:, 'class']\n\nprint(f\"Shape of X: {X.shape}\\nshape of y: {y.shape}\")","4dd54421":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)","37efc533":"print(f\"Train Data Shape: {X_train.shape}\\nTest Data Shape: {X_test.shape}\")","f4744970":"cVect = CountVectorizer()\ncVect.fit(X_train)","01f65dd1":"print('NO.of Tokens: ',len(cVect.vocabulary_.keys()))","1a43ec0b":"# document term vector (dtv)\ndtv = cVect.transform(X_train)","84f6d80a":"type(dtv)","6fdf06e5":"dtv = dtv.toarray()","3d612057":"print(f\"Number of Observations: {dtv.shape[0]}\\nTokens\/Features: {dtv.shape[1]}\")","82b51180":"# Let's see an sample that has been preprocessed\ndtv[1]","eb99dacc":"lr = LogisticRegression(verbose=1)\n\ngrid={\"C\":[float(i) for i in range(1, 3)], \"penalty\":[\"l2\"], \"solver\":[ 'lbfgs', 'liblinear']}\nlogreg_cv=GridSearchCV(lr, grid, cv=4)\nlogreg_cv.fit(dtv,y_train)\n\nprint(\"Tuned Hpyerparameters :\",logreg_cv.best_params_)\nprint(\"accuracy :\",logreg_cv.best_score_)","f5563ec4":"%%time\nlr = LogisticRegression(solver='liblinear', penalty ='l2' , C = 1.0)\nlr.fit(dtv, y_train)","9d995885":"# Preprocess the test data\ntest_dtv = cVect.transform(X_test)\ntest_dtv = test_dtv.toarray()\nprint(f\"Number of Observations: {test_dtv.shape[0]}\\nTokens\/Features: {test_dtv.shape[1]}\")","e3951b0d":"%%time\npred = lr.predict(test_dtv)","4682f17a":"print('Accuracy: ', accuracy_score(y_test, pred) * 100)","02d641e7":"# 0 - Not Spam \/ Ham\n# 1 - Spam \nprint(classification_report(y_test, pred))","2163e74f":"cmat = confusion_matrix(y_test, pred)\nplt.figure(figsize = (6, 6))\nsns.heatmap(cmat, annot = True, cmap = 'Paired', cbar = False, fmt=\"d\", xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam']);","195b272f":"# 'You won 1000$ prize money in lottery. Click here to avail'\ndef predict_class(lr):\n    text = input('Enter Text(Subject of the mail): ')\n    text = [' '.join([ word for word in word_tokenize(text)  if not word in stop_words])]\n    t_dtv = cVect.transform(text).toarray()\n    print('Predicted Class:', end = ' ')\n    print('Spam' if lr.predict(t_dtv)[0] else 'Not Spam') \n    prob = lr.predict_proba(t_dtv)*100\n    print(f\"Not Spam: {prob[0][0]}%\\nSpam: {prob[0][1]}%\")\n    plt.figure(figsize=(12, 6))\n    sns.barplot(x =['Not Spam', 'Spam'] , y = [prob[0][0], prob[0][1]])\n    plt.xlabel('Class')\n    plt.ylabel('Probalility')\n    plt.show()\n","63828c84":"predict_class(lr)","4a5d7117":"### Hyperparameter Tuning","f53c2339":"## Import Libraries","7d034874":"## Preprocess text to build the ML mdel","af035a8d":"  Classification Report of the classifier","cc300575":"## Split data into **train** and **test** in 80:20","0abb2660":"# **Spam Mail Classifier**\n\n![alt text](https:\/\/miro.medium.com\/max\/1536\/1*mzIPUxnxbzdjlJusLnkNRQ.jpeg)","04bc8923":"\n\n---\n\n","493bec65":"  Confusion Matrix","70b7dde6":"  Let's see the vocabulary that has extracted by hte count vextorizer","28abc9f9":"## Reading Data","6f652473":"## Evaluate on the Test data","fe111ed4":"### Logistic Regression.\n\n##### **Logistic Regression** could help use predict whether the student passed or failed. Logistic regression predictions are discrete (only specific values or categories are allowed). We can also view probability scores underlying the model\u2019s classifications.","9bc6b471":"## Viewing samples of the data","ffc9ed6d":"## Predict Class label for the unseen data i.e., Spam or Not Spam","ea8047be":"### Do Upvote the Notebook, If you like.","551dd062":"## Remove stopwords from the data"}}