{"cell_type":{"d66ad11c":"code","a685c58f":"code","444f79cb":"code","660b44aa":"code","b0541896":"code","fd5d1b32":"code","727e0ee3":"code","7d539313":"code","87255bc7":"code","35afd297":"code","cd7aa630":"code","33b35b30":"code","7178ea71":"code","ff81cddd":"code","3d3b13fb":"code","d6529f6e":"code","570772b1":"code","c591724a":"code","ac0eed80":"code","f6d43acf":"code","fb229bc1":"code","035d5238":"code","0b12def8":"code","e3d62b23":"code","1e8e61d6":"code","7327c2ba":"code","6c8b8a7f":"markdown","d646b55d":"markdown"},"source":{"d66ad11c":"!pip install ttach","a685c58f":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport ttach as tta\n\nimport pandas as pd\nimport time","444f79cb":"# kaggle confuses my input folder with its input folder. Has to restart and rerun.\nos.chdir(\"..\/input\/cats-and-dogs-bbox\/src\")","660b44aa":"import models\nimport config\nimport transforms\nimport dataset","b0541896":"start = time.time()","fd5d1b32":"# setting seed\ntorch.manual_seed(0)\nnp.random.seed(0)","727e0ee3":"# setting device to cuda if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","7d539313":"# load dataframe\ndf = pd.read_csv(config.DF_PATH, usecols=['fname', 'height', 'width', 'xmin_alb', 'ymin_alb', 'xmax_alb', 'ymax_alb', 'label', 'kfold'])\ndf.shape","87255bc7":"df.head(1)","35afd297":"# change the fnames (file names were created in windows, have to change them for linux)\nfname = [os.path.join(config.DATA, row.split('\\\\')[-1]) for row in df.fname]\ndf.fname = fname","cd7aa630":"df.head(1)","33b35b30":"# create dataframes using folds we have got with \"df_preparation.py\"\ntrain_df = df[df.kfold.isin([0, 1, 2])].reset_index(drop=True)\nvalid_df = df[df.kfold == 3].reset_index(drop=True)\ntest_df = df[df.kfold == 4].reset_index(drop=True)\n\n# create dataset\ntrain_dataset = dataset.localization_dataset(train_df, transforms.train_transform_loc)\nvalid_dataset = dataset.localization_dataset(valid_df, transforms.valid_transform_loc)\ntest_dataset = dataset.localization_dataset(test_df, transforms.test_transform_loc)\n\n# create loaders\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=config.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=config.batch_size, shuffle=True)","7178ea71":"# just a check if all is good with the shapes of the loaders\nprint(f'dataloader test: {next(iter(train_loader))[0].shape}, {next(iter(valid_loader))[0].shape}')","ff81cddd":"# displayig the data (looks this way because of normalization)\nbatch_tensor = next(iter(train_loader))[0][:6,...]\ngrid_img = torchvision.utils.make_grid(batch_tensor, nrow=3)\n\n# grid_img.shape\nplt.figure(figsize=(18,6))\nplt.imshow(grid_img.permute(1, 2, 0));","3d3b13fb":"# setting up a model\nmodel = config.model.to(device)\n# loss\ncriterion = nn.MSELoss()\n# optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n# learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, mode='min')","d6529f6e":"def train_model(n_epochs=1,\n                model=model,\n                train_loader=train_loader,\n                valid_loader=valid_loader,\n                criterion=criterion,\n                optimizer=optimizer,\n                lr_scheduler=lr_scheduler):\n    '''\n    Main function for training.\n    '''\n    # start total time\n    total_time = time.time()\n\n    for epoch in range(n_epochs):\n        # go to train mode\n        model.train()\n        # start epoch time\n        t0 = time.time()\n        # these will be used for metric calculations\n        correct_on_epoch = 0\n        total_num_images = 0\n        epoch_loss = 0\n\n        for batch, (images, labels) in enumerate(train_loader):\n\n            # move images and labels to gpu, if available\n            images = images.to(device, non_blocking=True).float()\n            labels = labels.to(device, non_blocking=True).float()\n\n            # keep track of total images in one epoch\n            total_num_images += images.size(0)\n\n            # clear grads before forward pass\n            optimizer.zero_grad()\n\n            # calculate outputs\n            outputs = model(images)\n\n            # we only need labels from (1,5) size tensor (both outputs and labels tensor), which is last digit\n            preds = outputs[:, -1]\n            preds = torch.clip(preds, 0, 1).round()\n            true = labels[:, -1].round()\n\n            # calculate the batch training loss\n            loss = criterion(outputs, labels)\n\n            # keep track of total epoch loss\n            epoch_loss += loss\n\n            # correct on bacth\n            correct_on_batch = (preds == true).sum().item()\n\n            # debugging\n            # print(f'custom acc: {correct_on_batch\/images.size(0)}')\n            # print(f'preds: {preds[:10]}')\n            # print(f'true: {true[:10]}')\n            \n            # correct on epoch\n            correct_on_epoch += correct_on_batch\n            # backward pass and step\n            loss.backward()\n            optimizer.step()\n\n        # train acc\/loss\n        train_epoch_acc = round((correct_on_epoch\/total_num_images), 4)\n        train_avg_epoch_loss = round(float(epoch_loss\/len(train_loader)), 4)\n        # valid acc\/loss\n        valid_avg_epoch_loss, valid_epoch_accuracy, mean_iou = test_model(model, valid_loader)\n\n        # epoch time\n        epoch_time = round(time.time() - t0)\n        # for reduce on plateau LR\n        lr_scheduler.step(valid_avg_epoch_loss)\n\n        print(f'epoch: [{epoch+1}\/{n_epochs}] | train loss: {train_avg_epoch_loss} | train acc: {train_epoch_acc} | valid loss: {valid_avg_epoch_loss} | valid acc: {valid_epoch_accuracy} | iou: {mean_iou} | time: {epoch_time\/\/60:.0f}m {epoch_time%60:.0f}s')\n\n    return model","570772b1":"def test_model(model, test_loader):\n    '''\n    Main function for testing. Comments are almost identical to the train function.\n    '''\n    model.eval()\n\n    correct_on_epoch = 0\n    total_num_images = 0\n    epoch_loss = 0\n    epoch_iou = []\n\n    all_batch_acc = []\n\n    with torch.no_grad():\n\n        for batch, (images, labels) in enumerate(test_loader):\n\n            images = images.to(device, non_blocking=True).float()\n            labels = labels.to(device, non_blocking=True).float()\n            \n            total_num_images += images.size(0)\n\n            outputs = model(images)\n\n            # preds and true are compared for valid accuracy\n            preds = outputs[:, -1]\n            preds = torch.clip(preds, 0, 1).round()\n            true = labels[:, -1]\n\n            true_bb = labels[:, :-1]\n            pred_bb = outputs[:, :-1]\n\n            loss = criterion(outputs, labels)\n            epoch_loss += loss\n\n            correct_on_epoch += (preds == true).sum().item()\n\n            # batch iou\n            batch_iou = iou(true_bb, pred_bb)\n            epoch_iou.append(batch_iou)\n\n    test_epoch_accuracy = round((correct_on_epoch\/total_num_images), 4)\n    test_avg_epoch_loss = round(float(epoch_loss\/len(test_loader)), 4)\n    mean_iou = np.round(np.mean(epoch_iou), 4)\n\n    return test_avg_epoch_loss, test_epoch_accuracy, mean_iou","c591724a":"def iou(true_bb, pred_bb):\n    '''\n    Main function for calculating Intersection over Union\n    '''\n    batch_iou = []\n\n    for idx, (true, pred) in enumerate(zip(true_bb, pred_bb)):\n\n        # we have to clip our bbox predictions between 0 and 1\n        pred = torch.clip(pred, min=0.0, max=1.0).detach().clone().to('cpu')\n        # clipping true not necessary but I kept it for symmetry\n        true = torch.clip(true, min=0.0, max=1.0).detach().clone().to('cpu')\n\n        # unpacking coordinates\n        xmin_t, ymin_t, xmax_t, ymax_t = true\n        xmin_p, ymin_p, xmax_p, ymax_p = pred\n\n        # here we 4 intersection points\n        xmin_intersect = np.maximum(xmin_t, xmin_p)\n        ymin_intersect = np.maximum(ymin_t, ymin_p)\n        xmax_intersect = np.minimum(xmax_t, xmax_p)\n        ymax_intersect = np.minimum(ymax_t, ymax_p)\n\n        # this condition will check if intersection points are real intersections\n        # if this condition fails, intersection area = 0\n        if xmin_intersect < xmax_intersect and ymin_intersect < ymax_intersect:\n\n            intersection_area = (xmax_intersect - xmin_intersect) * (ymax_intersect - ymin_intersect)\n            union_area = (xmax_t-xmin_t)*(ymax_t-ymin_t)+(xmax_p-xmin_p)*(ymax_p-ymin_p)-intersection_area + 1e-6\n\n            # this is just sanity check\n            assert intersection_area > 0, 'intersection area cant be < 0'\n            assert union_area > 0, 'union area cant be < 0'\n\n            iou = intersection_area \/ union_area\n            batch_iou.append(iou)\n\n        else:\n            batch_iou.append(0.0)\n\n    return np.round(np.mean(batch_iou), 4)","ac0eed80":"# unfreeze all the params for training\ndef unfreeze(model=model):\n    '''\n    This finction will unfreeze previously freezed params of our model so all the model's params will be available for training.\n    '''\n    for param in model.parameters():\n        param.requires_grad = True\n    return model","f6d43acf":"# train for more epochs\ntrain_model(3)\nunfreeze()\ntrain_model(15);","fb229bc1":"%%time\n# testing with train data\n_, train_acc, train_iou = test_model(model, train_loader)\nprint(f'train acc: {train_acc} | train iou: {train_iou}')","035d5238":"%%time\n# testing with test data\n_, test_acc, test_iou = test_model(model, test_loader)\nprint(f'test acc: {test_acc} | test iou: {test_iou}')","0b12def8":"%%time\n# tta with test data\ntta_model = tta.ClassificationTTAWrapper(model, tta.aliases.five_crop_transform(config.tta_crop, config.tta_crop))\n\ntta_dataset = dataset.localization_dataset(valid_df, transform=transforms.test_transform_loc)\ntta_loader = DataLoader(tta_dataset, batch_size=1, shuffle=True)\n\n_, tta_acc, tta_iou = test_model(tta_model, tta_loader)\n\nprint(f'TTA acc: {tta_acc} | tta iou: {tta_iou}')","e3d62b23":"total_time = time.time() - start\nprint(f'Total time: {total_time\/\/60:.0f}m {total_time%60:.0f}s')","1e8e61d6":"%%time\n\n# create dataframe\ninference_df = df.copy()\n\n# create dataset\ninference_dataset = dataset.localization_dataset(inference_df, transforms.test_transform_loc)\n\n# create loader\ninference_loader = torch.utils.data.DataLoader(dataset=inference_dataset, batch_size=config.batch_size, shuffle=True)\n\n# testing with all the data\n_, inference_acc, inference_iou = test_model(model, inference_loader)\nprint(f'inference acc: {inference_acc} | inference iou: {inference_iou}')","7327c2ba":"import cv2\n\nwith torch.no_grad():\n\n    # build dataset\n    temp_dataset = dataset.localization_dataset(df, transforms.test_transform_loc)\n    # take a random picture from a dataset\n    idx = np.random.randint(len(temp_dataset))\n    image, label = temp_dataset[idx]\n    # predict new bbox\n    image = torch.unsqueeze(image, 0)\n    model.to('cpu')\n    outputs = model(image)\n    outputs = outputs.flatten()\n    pred_bb = np.round(outputs[:-1], 4).tolist() # <---- pred bb\n\n    # convert ration bbox to pixels\n    pred_start = (int(pred_bb[0]*config.crop), int(pred_bb[1]*config.crop))\n    pred_end = (int(pred_bb[2]*config.crop), int(pred_bb[3]*config.crop))\n    pred_id = outputs[-1].long().item()\n\n    # need to permute tensor for visualization\n    image = torch.squeeze(image, 0)\n    image = np.array(image.permute(1, 2, 0))\n\n    # bbox = first 4 digits\n    bbox = np.round(label[:-1], 4).tolist() # <---- true bb\n\n    # class = last digit\n    class_id = label[-1].long().item()\n\n    # define 2 points for rectangle\n    start_point = (int(bbox[0]*config.crop), int(bbox[1]*config.crop))\n    end_point = (int(bbox[2]*config.crop), int(bbox[3]*config.crop))\n\n    # define a color and thickness\n    color = (0, 255, 0)\n    color2 = (255, 0, 0)\n\n    thickness = 2\n\n    image = cv2.rectangle(image, start_point, end_point, color, thickness)\n    image = cv2.rectangle(image, pred_start, pred_end, color2, thickness)\n\n    # cv2.imshow('image', image)\n    plt.figure(figsize=(8, 8))\n    plt.imshow(np.array(image));","6c8b8a7f":"## visualize predictions of the model","d646b55d":"## inference run with all the data"}}