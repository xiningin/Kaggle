{"cell_type":{"464fc147":"code","7522b854":"code","66ea3d21":"code","d5b89d3d":"code","3f026ae3":"code","1c7effa9":"code","1837a205":"code","17fcc17c":"markdown","11d5ef79":"markdown"},"source":{"464fc147":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport IPython\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport sklearn\nimport sklearn.utils\nimport scipy\nimport scipy.signal\nimport scipy.io\nimport scipy.io.wavfile as wavfile\nimport glob\nimport itertools\nimport sys\nfiles = glob.glob(\"..\/input\/Training\/*.wav\")\nfiles.sort()\nfiles.pop(0)\nFRAMERATE = 16000\nLENGTH = 16000\nPADDED_LENGTH = 2**14","7522b854":"bird_songs = np.concatenate([wavfile.read(f)[1] for f in files])\nbird_songs = bird_songs \/ np.max(bird_songs)","66ea3d21":"ENCODED_FEATURES = 4096\n\nencoder = tf.keras.models.Sequential()\nencoder.add(tf.keras.layers.InputLayer(input_shape=(LENGTH,)))\nencoder.add(tf.keras.layers.Reshape((LENGTH, 1)))\nencoder.add(tf.keras.layers.ZeroPadding1D((0,PADDED_LENGTH-LENGTH)))\nfor s, k, n in ([4, 25, 16],[4, 25, 32],[4, 15, 64]):\n    encoder.add(tf.keras.layers.Conv1D(n, kernel_size=k, strides=s, padding='same'))\n    encoder.add(tf.keras.layers.LeakyReLU())\n    encoder.add(tf.keras.layers.BatchNormalization())\nencoder.add(tf.keras.layers.Reshape((256, 64, 1)))\nfor s, k, n in ([(4,2), (15,5), 16],[(4,2), (15,5), 16]):\n    encoder.add(tf.keras.layers.Conv2D(n, kernel_size=k, strides=s, padding='same'))\n    encoder.add(tf.keras.layers.LeakyReLU())\n    encoder.add(tf.keras.layers.BatchNormalization())\nencoder.add(tf.keras.layers.Flatten())\nencoder.summary()\n\ndecoder = tf.keras.models.Sequential()\ndecoder.add(tf.keras.layers.InputLayer(input_shape=(ENCODED_FEATURES,)))\ndecoder.add(tf.keras.layers.Reshape((16,16,16)))\nfor s, k, n in reversed(([(4,2), (15,5), 16],[(4,2), (15,5), 16])):\n    decoder.add(tf.keras.layers.Conv2DTranspose(n, kernel_size=k, strides=s, padding='same'))\n    decoder.add(tf.keras.layers.LeakyReLU())\n    decoder.add(tf.keras.layers.BatchNormalization())\ndecoder.add(tf.keras.layers.Conv2DTranspose(1, kernel_size=1, strides=1, padding='same'))\ndecoder.add(tf.keras.layers.Reshape((256, 1, 64)))\nfor s, k, n in reversed(([4, 25, 16],[4, 25, 32],[4, 15, 64])):\n    decoder.add(tf.keras.layers.Conv2DTranspose(n, kernel_size=(k,1), strides=(s,1), padding='same'))\n    decoder.add(tf.keras.layers.LeakyReLU())\n    decoder.add(tf.keras.layers.BatchNormalization())\ndecoder.add(tf.keras.layers.Conv2DTranspose(1, kernel_size=(1,1), strides=(1,1), padding='same'))\ndecoder.add(tf.keras.layers.Reshape((PADDED_LENGTH, 1)))\ndecoder.add(tf.keras.layers.Cropping1D(((0, PADDED_LENGTH-LENGTH))))\ndecoder.add(tf.keras.layers.Reshape((LENGTH, )))\ndecoder.add(tf.keras.layers.Activation('tanh'))\ndecoder.summary()\n\ncae = tf.keras.models.Sequential()\ncae.add(tf.keras.layers.InputLayer(input_shape=(LENGTH,)))\ncae.add(encoder)\ncae.add(decoder)\ncae.summary()\ncae.compile(loss=tf.keras.losses.mean_squared_error,\n            optimizer=tf.keras.optimizers.Adam(0.001)\n           )","d5b89d3d":"def fit_generator(bird_songs, batch_size=64):\n    while True:\n        recorded = np.array([bird_songs[x: x+LENGTH] for x in np.random.randint(0,len(bird_songs)-LENGTH,(batch_size))])\n        noised = np.array([np.random.normal(0, 0.1, LENGTH)+seg for seg in recorded])\n        yield noised, recorded","3f026ae3":"BATCH_SIZE = 32\nSTEPS_PER_EPOCH = 1000\nEPOCHS = 50\ncae.fit_generator(fit_generator(bird_songs),\n                  epochs=EPOCHS, \n                  steps_per_epoch=STEPS_PER_EPOCH,\n                  callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss',\n                              min_delta=0,\n                              patience=0,\n                              verbose=0, mode='auto')\n                      ],\n                  verbose=2)","1c7effa9":"SAMPLE = 5\nsegments = np.stack([np.random.normal(0, 0.1, LENGTH)+bird_songs[x: x+LENGTH] for x in np.random.randint(0,len(bird_songs)-LENGTH,(SAMPLE))])\nreproduced = cae.predict(segments)\n\nplt.figure(figsize=(20,5))\nfor i, s, r in zip(np.arange(5), segments, reproduced):\n    s = s.flatten()\n    r = r.flatten()\n    plt.subplot(SAMPLE,4,i*4+1)\n    plt.plot(s)\n    plt.subplot(SAMPLE,4,i*4+2)\n    plt.specgram(s, NFFT=256, Fs=2, Fc=0, noverlap=128)\n    plt.subplot(SAMPLE,4,i*4+3)\n    plt.plot(r)\n    plt.subplot(SAMPLE,4,i*4+4)\n    plt.specgram(r, NFFT=256, Fs=2, Fc=0, noverlap=128)\n\nfor i, signal in enumerate(reproduced):\n    IPython.display.display(IPython.display.Audio(signal.flatten(), rate=FRAMERATE))","1837a205":"segments = np.stack([np.random.normal(0, 0.1, LENGTH)+bird_songs[x: x+LENGTH] for x in np.random.randint(0,len(bird_songs)-LENGTH,(2))])\nreproduced1,reproduced2 = encoder.predict_on_batch(segments)\nsteps = 10\n\ndelta = (reproduced2 - reproduced1) \/ steps\ninterpolated = np.array([reproduced1+delta*i for i in range(steps+1)])\ngenerated = decoder.predict_on_batch(interpolated)\n\nplt.figure(figsize=(20,5))\nfor i, signal in enumerate(generated):\n    signal =  signal.flatten()\n    plt.subplot(2,steps+1, i+1)\n    plt.plot(signal)\n    plt.subplot(2,steps+1, i+(steps+1)+1)\n    plt.specgram(signal, NFFT=256, Fs=2, Fc=0, noverlap=128)","17fcc17c":"### Interpolating Latent Space","11d5ef79":"### Denoising with DAE"}}