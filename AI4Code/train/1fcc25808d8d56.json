{"cell_type":{"fe0650c2":"code","c8091162":"code","77bca36f":"code","4dcec8e7":"code","0be6d741":"code","6049b31b":"code","feae5b8d":"code","878dece0":"code","b6913d44":"code","128f70e8":"code","2539c18c":"code","e31e33dc":"code","2770211f":"code","f1493e75":"code","eb674c36":"code","ecf0b4d7":"code","33521d08":"code","ddfae45a":"code","20db1d14":"code","f0c3985c":"code","043f2562":"code","bf9ed00a":"code","778986e5":"code","3debb51d":"code","932b07bc":"code","b08dd082":"code","042898b2":"code","c4402d21":"code","141937da":"code","da41ab09":"code","3e73f985":"code","4b06a2bd":"code","9af1f03e":"code","186eb1cb":"code","c1cbbeb5":"code","bf102c7e":"code","4844cc73":"code","7e93d806":"code","9d9c6f19":"code","a811b5f9":"code","5eb4a42a":"code","d6a1bee4":"code","e132736f":"code","c84d1e78":"code","c247b328":"code","ac5fc011":"code","bbf5e1f6":"code","00b92cb5":"code","e23445d3":"code","1d7c5374":"markdown","e3944c64":"markdown","b09b8882":"markdown","43cba590":"markdown","abbe7105":"markdown","77ea130c":"markdown","6621d0e8":"markdown","11791aa9":"markdown","9e6b4496":"markdown","bed7f380":"markdown","009b38e5":"markdown","c2de5c74":"markdown","2b3d5ab8":"markdown","ae37462e":"markdown","13fd52a5":"markdown","5ca3cc36":"markdown","1a17c7b3":"markdown","4eb5240a":"markdown","478011ad":"markdown","4e91437e":"markdown","306967f2":"markdown","b6aa9891":"markdown","fb51c291":"markdown","09fd9a29":"markdown","217b4445":"markdown","5cc07edf":"markdown","81cae1d5":"markdown","3739fc61":"markdown","aa8df427":"markdown","0d88a6d3":"markdown","954d5641":"markdown"},"source":{"fe0650c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8091162":"%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use(style='ggplot')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nimport seaborn as sns","77bca36f":"from sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer","4dcec8e7":"!apt-get install p7zip\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/train.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/test.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission.csv.7z","0be6d741":"!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission_stg2.csv.zip\n!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/test_stg2.tsv.zip","6049b31b":"train = pd.read_csv('train.tsv', sep = '\\t')\ntest = pd.read_csv('test_stg2.tsv', sep='\\t')","feae5b8d":"print (\"Train data shape:\", train.shape)\nprint (\"Test data shape:\", test.shape)","878dece0":"train.head(10)","b6913d44":"train.info()","128f70e8":"train.price.describe().apply(lambda x: format(x, 'f'))","2539c18c":"np.percentile(train.price, 99)","e31e33dc":"print (\"Skew is:\", train.price.skew())\nsns.displot(train.price, kde=True)\nplt.show()","2770211f":"sns.displot(np.log1p(train['price']))","f1493e75":"np.log1p(train['price']).hist()","eb674c36":"train['price'] = np.log1p(train['price'])","ecf0b4d7":"train['shipping'].value_counts()","33521d08":"train['item_description'].value_counts().head()","ddfae45a":"train['item_condition_id'].value_counts()","20db1d14":"train['brand_name'].value_counts().head()","f0c3985c":"train['category_name'].value_counts().head(10)","043f2562":"def category_split(category_name):\n    try:\n        return category_name.split('\/')\n    except:\n        return ['Missing', 'Missing', 'Missing']","bf9ed00a":"train['main_cat'], train['sub_cat'], train['item_cat'] = zip(*train['category_name'].apply(lambda x: category_split(x)))\ntest['main_cat'], test['sub_cat'], test['item_cat'] = zip(*test['category_name'].apply(lambda x: category_split(x)))","778986e5":"train['category_name'] = train['category_name'].fillna(value='Missing')\ntrain['brand_name'] = train['brand_name'].fillna(value='Missing')\ntrain['item_description'] = train['item_description'].fillna(value='Missing')","3debb51d":"test['category_name'] = test['category_name'].fillna(value='Missing')\ntest['brand_name'] = test['brand_name'].fillna(value='Missing')\ntest['item_description'] = test['item_description'].fillna(value='Missing')","932b07bc":"cnt_vec = CountVectorizer()\n\nX_train_name = cnt_vec.fit_transform(train['name'])\nX_test_name = cnt_vec.transform(test['name'])","b08dd082":"print(X_train_name.shape)\nprint(X_test_name.shape)","042898b2":"tfidf_descp = TfidfVectorizer(max_features=50000, ngram_range=(1, 3), stop_words='english')\n\nX_train_descp = tfidf_descp.fit_transform(train['item_description'])\nX_test_descp = tfidf_descp.transform(test['item_description'])","c4402d21":"from sklearn.preprocessing import LabelBinarizer","141937da":"lb_brand_name = LabelBinarizer(sparse_output=True)\nX_train_brand = lb_brand_name.fit_transform(train['brand_name'])\nX_test_brand = lb_brand_name.transform(test['brand_name'])\n\nlb_item_cond_id = LabelBinarizer(sparse_output=True)\nX_train_item_condition_id = lb_item_cond_id.fit_transform(train['item_condition_id'])\nX_test_item_condition_id = lb_item_cond_id.transform(test['item_condition_id'])\n\nlb_shipping = LabelBinarizer(sparse_output=True)\nX_train_shipping = lb_shipping.fit_transform(train['shipping'])\nX_test_shipping = lb_shipping.transform(test['shipping'])","da41ab09":"lb_main_cat = LabelBinarizer(sparse_output=True)\nX_train_main_cat = lb_main_cat.fit_transform(train['main_cat'])\nX_test_main_cat = lb_main_cat.transform(test['main_cat'])\n\nlb_sub_cat = LabelBinarizer(sparse_output=True)\nX_train_sub_cat = lb_sub_cat.fit_transform(train['sub_cat'])\nX_test_sub_cat = lb_sub_cat.transform(test['sub_cat'])\n\nlb_item_cat = LabelBinarizer(sparse_output=True)\nX_train_item_cat = lb_item_cat.fit_transform(train['item_cat'])\nX_test_item_cat = lb_item_cat.transform(test['item_cat'])","3e73f985":"# Full dataframe printing\nprint(type(X_train_brand), type(X_train_item_condition_id), type(X_train_shipping))\nprint(type(X_test_brand), type(X_test_item_condition_id), type(X_test_shipping))","4b06a2bd":"# Train dataframe printing\nprint('X_train_brand shape:', X_train_brand.shape)\nprint('X_train_item_cond_id shape:', X_train_item_condition_id.shape)\nprint('X_train_shipping shape:', X_train_shipping.shape)\nprint('X_train_main_cat shape:', X_train_main_cat.shape)\nprint('X_train_sub_cat shape:', X_train_sub_cat.shape)\nprint('X_train_item_cat shape:', X_train_item_cat.shape)","9af1f03e":"# Test dataframe printing\nprint('X_test_brand shape:', X_test_brand.shape)\nprint('X_test_item_cond_id shape:', X_test_item_condition_id.shape)\nprint('X_test_shipping shape:', X_test_shipping.shape)\nprint('X_test_main_cat shape:', X_test_main_cat.shape)\nprint('X_test_sub_cat shape:', X_test_sub_cat.shape)\nprint('X_test_item_cat shape:', X_test_item_cat.shape)","186eb1cb":"from scipy.sparse import hstack\nimport gc","c1cbbeb5":"sparse_matrix_list = (X_train_name, X_train_descp, X_train_brand, \n                      X_train_item_condition_id, X_train_shipping, \n                      X_train_main_cat, X_train_sub_cat, X_train_item_cat)","bf102c7e":"X_train = hstack(sparse_matrix_list).tocsr()\nprint(type(X_train), X_train.shape)","4844cc73":"del X_train\ngc.collect()","7e93d806":"def rmsle(y, y_pred):\n    return np.sqrt(np.mean(np.power(np.log1p(y) - np.log1p(y_pred), 2)))\n\ndef evaluate_orig_price(y_test, preds):\n    preds_exmpm = np.expm1(preds)\n    y_test_exmpm = np.expm1(y_test)\n    \n    return rmsle(y_test_exmpm, preds_exmpm)","9d9c6f19":"def model_train_predict(model, matrix_list):\n    X = hstack(matrix_list).tocsr()\n    X_train, X_test, y_train, y_test = train_test_split(X, train['price'], test_size=0.2)\n\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    \n    del X, X_train, X_test, y_train\n    gc.collect()\n    \n    return preds, y_test","a811b5f9":"linear_model = Ridge(solver='lsqr', fit_intercept=False)\n\nsparse_matrix_list = (X_train_name, X_train_brand, \n                      X_train_item_condition_id, X_train_shipping, \n                      X_train_main_cat, X_train_sub_cat, X_train_item_cat)\n\nlinear_preds, y_test = model_train_predict(model=linear_model, \n                                           matrix_list=sparse_matrix_list)\n\nprint('Item Description rmsle:', evaluate_orig_price(y_test, linear_preds))\n\nsparse_matrix_list = (X_train_name, X_train_descp, X_train_brand, \n                      X_train_item_condition_id, X_train_shipping, \n                      X_train_main_cat, X_train_sub_cat, X_train_item_cat)\n\n\nlinear_preds, y_test = model_train_predict(model=linear_model, \n                                           matrix_list=sparse_matrix_list)\nprint('Item Description rmsle:', evaluate_orig_price(y_test, linear_preds))","5eb4a42a":"sparse_matrix_list = (X_train_name, X_train_descp, X_train_brand, \n                      X_train_item_condition_id, X_train_shipping, \n                      X_train_main_cat, X_train_sub_cat, X_train_item_cat)\n\nX_train = hstack(sparse_matrix_list).tocsr()\nX_train","d6a1bee4":"sparse_matrix_list = (X_test_name, X_test_descp, X_test_brand, \n                      X_test_item_condition_id, X_test_shipping, \n                      X_test_main_cat, X_test_sub_cat, X_test_item_cat)\nX_test = hstack(sparse_matrix_list).tocsr()","e132736f":"y_train = train['price']\ny_train","c84d1e78":"linear_model.fit(X_train, y_train)","c247b328":"preds = linear_model.predict(X_test)\npreds","ac5fc011":"preds = np.expm1(preds)\npreds","bbf5e1f6":"submission = pd.read_csv('sample_submission_stg2.csv')\nsubmission","00b92cb5":"submission.loc[:, 'price'] = preds\nsubmission","e23445d3":"submission.to_csv('submission.csv', index=False)","1d7c5374":"we may need to split the categories so that we can match the common ones and get better insights from the data","e3944c64":"It doesn't seem to be a good practise if we filled or imputed data in predection, so we will fill all missing with missing.","b09b8882":"Stack X_train dataframe for printing purpose.","43cba590":"## Data Exploration","abbe7105":"## Categories handling","77ea130c":"We are trying to predict the items price, so we will investigate the variable distribution and check if it has skwenwss.","6621d0e8":"### One-hot encoding via LabelBinarizer","11791aa9":"We have some prices that exceed the third quartile range, they may be high price products or outliers. ","9e6b4496":"# Evalutation","bed7f380":"Columns Category_name, brand_name and item_description have nulls","009b38e5":"Convert this matrix to Compressed Sparse Row forma","c2de5c74":"## Stacking X_Train","2b3d5ab8":"### Vectorize Item Description ","ae37462e":"Vectorize Item Description using TF-IDF Model.","13fd52a5":"Print all the columns shape so we know the size of our data after encoding.","5ca3cc36":"# Missing Data ","1a17c7b3":"Apply labelBinarizer on all variables on train and test dataset.","4eb5240a":"# Vectorization","478011ad":"# Modeling","4e91437e":"Take log1p to the price variable","306967f2":"Extract the 7z files on kaggle servers","b6aa9891":"Garbage Collecting","fb51c291":"To handel sparsity in matrix, we will apply One-Hot Encoding on categorical variables.","09fd9a29":"# Data Import","217b4445":"### Vectorize name","5cc07edf":"So our price is skewed, we will apply the log transform on it.","81cae1d5":"# Prediction","3739fc61":"Now we will explore the other variables and thier values","aa8df427":"## Ridge Regression Model","0d88a6d3":"Vectorize name column using BoW Model. ","954d5641":"## Target distribution"}}