{"cell_type":{"05a32dee":"code","b998726a":"code","efa741d8":"code","05875e0b":"code","c8bad460":"code","4a59b59a":"code","17f325b2":"code","347f0658":"code","bc859fae":"code","8936f934":"code","5563e367":"code","f2aade36":"code","054b0c06":"code","662e7a37":"code","3566e475":"code","5af295f4":"code","0cecd377":"code","f5f632fb":"code","f8522afb":"code","7cd197c4":"code","a81ac44a":"code","56cf07e6":"code","cb314c5b":"code","36dd8234":"code","7cddc8fe":"code","5064bd57":"code","f81e6e88":"code","b76d0055":"code","78752fd2":"code","09b42553":"code","d1916e15":"code","b161d756":"code","409bc23f":"code","4f49bdf5":"code","c81b465d":"code","cf7314a1":"code","53fac11c":"code","4263c858":"code","90038559":"code","bd7d8895":"code","1a6aa97c":"code","2c2443db":"code","f20a22a9":"code","58792ff6":"code","f5c5b2f4":"code","746d65dc":"code","2efd1a75":"code","b3333e7c":"code","102139e7":"code","7fbf88f6":"code","35a086aa":"code","5987d2fa":"code","16f43c7d":"code","0a931cf0":"code","190fa9d8":"code","e924d74c":"code","4184b78c":"code","135e2b04":"code","08ecf307":"code","81428edc":"code","c8cacce8":"code","05448e34":"code","23518545":"code","b52e3963":"code","10c42565":"code","005d79f6":"code","5d48a018":"code","e3c9e6c8":"code","3f29ecf2":"code","04224fff":"markdown","c6d7d545":"markdown","bd4870d1":"markdown","620dd659":"markdown","fbad3955":"markdown","f6cc3ccf":"markdown","b65e52d0":"markdown","63d91638":"markdown","7efda5f2":"markdown","67697e03":"markdown","7ad74a83":"markdown","0bfad70f":"markdown","be290b56":"markdown","2e2954b8":"markdown","4fbfe273":"markdown","02e0f76c":"markdown","0a15f355":"markdown","bdc685dd":"markdown","35bf6acf":"markdown","3e47bb3f":"markdown","e6dc756f":"markdown","27b3775f":"markdown","185c135e":"markdown","9546e7aa":"markdown","4fa6d9a3":"markdown","1a5b46c4":"markdown","a49bbe7f":"markdown","dc938c8c":"markdown","04286958":"markdown","e595f7a7":"markdown","3d539558":"markdown","62710f73":"markdown","126c570b":"markdown","42da4822":"markdown","fc1fb380":"markdown","a75ac3d6":"markdown","8f68cd12":"markdown","a0fa5853":"markdown","a9d09575":"markdown","e6f19899":"markdown","69c5d31e":"markdown","fa990ff5":"markdown","7c698888":"markdown","b48c2b1b":"markdown","ae974b7a":"markdown","d47ff5a3":"markdown","efbbdb9e":"markdown","5cd0bb76":"markdown","fd039bf7":"markdown","e64fae28":"markdown","4b31d773":"markdown","b5b33689":"markdown","0a1697fb":"markdown","39c041f8":"markdown","814e67fc":"markdown"},"source":{"05a32dee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b998726a":"import warnings  \nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns","efa741d8":"data = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndata","05875e0b":"data.isnull().sum()","c8bad460":"avg = data['bmi'].mean()\navg","4a59b59a":"data.bmi=(data.bmi.fillna(28.74))","17f325b2":"data.isnull().sum()","347f0658":"data.info() # THIS FUNCTION LETS US KNOW WHAT DATA TYPE VARIABLE ARE PROVIDED IN THE DATASET","bc859fae":"data.describe()","8936f934":"sns.countplot(data['work_type'])","5563e367":"sns.countplot(data['Residence_type'])","f2aade36":"sns.countplot(data['smoking_status'])","054b0c06":"sns.countplot(data['stroke'])","662e7a37":"sns.countplot(data['ever_married'])","3566e475":"min_avg_glucose_level = min(data.avg_glucose_level)\nmax_avg_glucose_level = max(data.avg_glucose_level)\nprint(min_avg_glucose_level)\nprint(max_avg_glucose_level)","5af295f4":"sns.distplot(data['age'])","0cecd377":"sns.distplot(data['avg_glucose_level'])","f5f632fb":"data['work_type'] = data['work_type'].map({'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4})","f8522afb":"data['gender'] = data['gender'].map({'Male':0, 'Female':1})\ndata['Residence_type'] = data['Residence_type'].map({'Urban':0, 'Rural':1})\ndata['smoking_status'] = data['smoking_status'].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})\ndata['ever_married'] = data['ever_married'].map({'Yes':0, 'No':1})","7cd197c4":"data","a81ac44a":"plt.figure(figsize=(16,10))\nsns.heatmap(data.corr(method='pearson'), annot=True)","56cf07e6":"sns.scatterplot(x=data['age'], y=data['avg_glucose_level'])\n","cb314c5b":"sns.catplot(x='heart_disease',y='age', hue=\"work_type\", kind=\"bar\", data=data)","36dd8234":"sns.catplot(x='hypertension',y='age', hue=\"work_type\", kind=\"bar\", data=data)","7cddc8fe":"sns.catplot(x=\"smoking_status\", y=\"stroke\", hue=\"work_type\", kind=\"bar\", data=data)","5064bd57":"sns.catplot(x=\"hypertension\", y=\"stroke\", hue=\"work_type\", kind=\"bar\", data=data)","f81e6e88":"sns.catplot(x=\"Residence_type\", y=\"stroke\", hue=\"work_type\", kind=\"bar\", data=data)","b76d0055":"sns.catplot(x='stroke', y=\"avg_glucose_level\", kind=\"box\", data=data)","78752fd2":"sns.catplot(x='stroke', y=\"age\", hue = 'gender', kind=\"box\", data=data)","09b42553":"sns.catplot(x='stroke', y=\"age\", hue = 'work_type', kind=\"box\", data=data)","d1916e15":"features = ['id','age',\n 'hypertension',\n 'heart_disease',\n 'ever_married',\n 'Residence_type',\n 'avg_glucose_level',\n 'bmi',\n 'gender',\n 'work_type',\n 'smoking_status']\n\nlabel = ['stroke']\n\nX = data[features]\ny = data[label]","b161d756":"X.isnull().sum() #WE STILL HAVE 1 NULL VALUE IN THE GENDER COLUMN","409bc23f":"X.gender=(X.gender.fillna(1))","4f49bdf5":"X.isnull().sum()","c81b465d":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nx_smote, y_smote = smote.fit_resample(X, y)","cf7314a1":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(x_smote,y_smote,test_size=0.33,random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","53fac11c":"testing = X_test['id'] #taking ID column for the purpose of submission\ntesting","4263c858":"X_train = X_train.drop(columns=['id'])\nX_test = X_test.drop(columns=['id'])","90038559":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","bd7d8895":"X_train","1a6aa97c":"X_test","2c2443db":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train,y_train)\n","f20a22a9":"y_pred_log_reg = log_reg.predict(X_test)\ny_pred_log_reg","58792ff6":"from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nclassification_report = classification_report(y_test, y_pred_log_reg)\nprint(classification_report)","f5c5b2f4":"auc = roc_auc_score(y_test, y_pred_log_reg)\nauc","746d65dc":"cm = confusion_matrix(y_test, y_pred_log_reg)\ncm","2efd1a75":"predicted_probab_log = log_reg.predict_proba(X_test)\npredicted_probab_log = predicted_probab_log[:, 1]\nfpr, tpr, _ = roc_curve(y_test, predicted_probab_log)","b3333e7c":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', label='Logistic Regression')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","102139e7":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","7fbf88f6":"rfc_predict = rfc.predict(X_test)\nroc_auc_score(y_test, rfc_predict)","35a086aa":"cm = confusion_matrix(y_test, rfc_predict)\ncm","5987d2fa":"tn = cm[0,0]\nfp = cm[0,1]\ntp = cm[1,1]\nfn = cm[1,0]\naccuracy  = (tp + tn) \/ (tp + fp + tn + fn)\nprecision = tp \/ (tp + fp)\nrecall    = tp \/ (tp + fn)\nf1score  = 2 * precision * recall \/ (precision + recall)\nprint(f1score)","16f43c7d":"predicted_probab = rfc.predict_proba(X_test)","0a931cf0":"predicted_probab = predicted_probab[:, 1]","190fa9d8":"fpr, tpr, _ = roc_curve(y_test, predicted_probab)","e924d74c":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', color='red', label='Random Forest')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","4184b78c":"import xgboost as xgb","135e2b04":"model = xgb.XGBClassifier()\nmodel.fit(X_train,y_train)","08ecf307":"y_pred1 = model.predict(X_test)","81428edc":"roc_auc_score(y_test, y_pred1)","c8cacce8":"cm = confusion_matrix(y_test, y_pred1)\ncm","05448e34":"tn = cm[0,0]\nfp = cm[0,1]\ntp = cm[1,1]\nfn = cm[1,0]\naccuracy  = (tp + tn) \/ (tp + fp + tn + fn)\nprecision = tp \/ (tp + fp)\nrecall    = tp \/ (tp + fn)\nf1score  = 2 * precision * recall \/ (precision + recall)\nprint(f1score)","23518545":"predicted_probab = model.predict_proba(X_test)\npredicted_probab = predicted_probab[:, 1]\nfpr, tpr, _ = roc_curve(y_test, predicted_probab)","b52e3963":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', color='green',label='XGB Classifier')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","10c42565":"\nmy_submission = pd.DataFrame({'Id': testing, 'Stroke': y_pred1})\nmy_submission.to_csv('submission.csv', index=False)\nmy_submission = pd.read_csv('submission.csv')\nmy_submission\n","005d79f6":"params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","5d48a018":"xgb = xgb.XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n                    silent=True, nthread=1)","e3c9e6c8":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfolds = 5\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4,  verbose=3, random_state=1001 )\nrandom_search.fit(X_train, y_train)","3f29ecf2":"print('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\nprint(random_search.best_score_ * 2 - 1)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)\nresults = pd.DataFrame(random_search.cv_results_)\nresults.to_csv('xgb-random-grid-search-results-01.csv', index=False)","04224fff":"AUC SCORE OF AROUND 80% IS QUITE GOOD. MODEL IS ABLE TO CLASSIFY THE CLASSES VERY WELL","c6d7d545":"PEOPLE HAVING HIGHER GLUCOSE LEVEL ARE AT HIGH RISK OF STROKE","bd4870d1":"DATA POINTS AFTER STANDARDIZATION:","620dd659":"ONCE AGAIN CHECK FOR NULL VALUES IN THE DATASET","fbad3955":"CALCULATION OF F1 SCORE","f6cc3ccf":"DIVIDING THE DATASET INTO FEATURES AND LABELE","b65e52d0":"FROM THE ABOVE FIGURE WE CAN SEE THAT-\nWORK_TYPE AND BMI - NEGATIVE CORRELATION\nSTROKE AND AGE HAS A POSITIVE CORRELATION\nSIMILARLY MANY OTHER VARIABLES HAVE SUCH CORRELATION VALUES WE CANNOT REMOVE ANY VARIABLES. WE HAVE TO CONSIDER ALL THE VARIABLES FOR OUR MODEL","63d91638":"IF YOU FIND THIS NOTEBOOK USEFUL THEN PLEASE UPVOTE!!\n\n\n\nTHANK YOU..","7efda5f2":"THE ABOVE MINIMUM AND MAXIMUM VALUES OF AVERAGE GLUCOSE LEVEL SHOWS THAT THE COLUMN NEEDS TO BE STANDARDIZED AS THERE IS VERY HIGH DIFFERENCE BETWEEN THEM","67697e03":"**MAPPING OF CATEGORICAL VARIABLES**","7ad74a83":"**ROC CURVE**","0bfad70f":"**ROC CURVE**","be290b56":"THERE ARE LARGE NUMBER OF PEOPLE WHO WORK ON PRIVATE SECTOR ","2e2954b8":"**RANDOM FOREST**","4fbfe273":"**APPLYING GRID SEARCH**","02e0f76c":"FROM THE ABOVE SCATTER PLOT IT IS QUITE VISIBLE THAT AS THE AGE INCREASE IT LEADS TO INCREASE IN GLUCOSE LEVEL","0a15f355":"**READ DATA**","bdc685dd":"SPLITTING OF DATASET INTO TRAIN AND TEST","35bf6acf":"THERE ARE ALMOST SAME NUMBER OF PEOPLE LIVING IN BOTH URBAN AND RURAL AREAS","3e47bb3f":"SO NOW NO NULL VALUES PRESENT","e6dc756f":"**CONCLUSION**","27b3775f":"**COUNTPLOT TO SEE THE DISTRIBUTION OF WORK_TYPE**","185c135e":"THE ABOVE PLOT SHOWS THAT THERE IS **HIGH IMBALANCE** IN THE BOTH THE TARGET CLASSES AN WE NEED TO RESOLVE THIS ISSUE BEFORE APPLYING ANY ALGORITHM","9546e7aa":"**XGBOOST CLASSIFIER**","4fa6d9a3":"AS ID COLUMN DOES NOT AFFETCT THE MODEL'S PERFORMANCE, WE DROP IT","1a5b46c4":"AMAZING F1 SCORE","a49bbe7f":"GOOD TO SEE THAT MOST NUMBER OF PEOPLE NEVER SMOKED AS \"SMOKING KILLS\"","dc938c8c":"DATASET AFTER MAPPING OF CATEGORICAL VARIABLES","04286958":"PEOPLE WHO ARE SELF EMPLOYED ARE THE ONES WHO HAVE HEART DISEASE AND OBVIOUSLY LEAST NUMBERS ARE OF CHILDREN","e595f7a7":"AUC SCORE HAS INCREASED TO **94%**. AMAZING!!","3d539558":"LET'S SEE IF WE CAN IMPROVE IT FURTHER USING ANOTHER MODEL","62710f73":"IN THE GIVEN DATASET WE FIRT APPLIED GENERAL PREPROCESSING TO REMOVE\/IMPUTE MISSING VALUES. STANDARDIZATION WAS IMPORTANT AS INDEPENDENT FEATURES WERE IN DIFFERENT SCALES.\nWE MUST MAKE SURE THAT RARGET CLASS IS NOT IMBALANCED AND IF IT IS SO THEN WE MUST HANDLE IT USING APPROPRIATE TECHNIQUE.\nAMONG THREE MODELS APPLIED, XGBOOST WAS FOUND TO BE THE MOST SUCCESSFUL WITH F1 SCORE OF AROUND 95%. IN SUCH TYPE OF DATASET LIKE THIS WHERE THERE IS HIGH CLASS IMBALANCE ACCURACY METRIC SHOULD NOT BE RELIED ON. WE MUST SEE CONFUSION MATRIX FOR CLEAR INSIGHT OF HOW THE MODEL IS PERFORMING.\n","126c570b":"WOW!! AUC SCORE INCREASED","42da4822":"AGAIN SELF-EMPLOYED PEOPLE HAVE HIGHER RISK OF STROKE. THIS SHOWS THAT THESE PEOPLE ARE MORE VULNERABLE TO DIFFERENT DISEASES AS THEY CARRY LOT OF TENSION OF EARNINGS AND FAMILY INCOME","fc1fb380":"**APPLY MACHINE LEARNING ALGORITHM FOR PREDICTION**","a75ac3d6":"*AS WE CAN SEE BMI CONTAINS NULL VALUES AND WE NEED TO FIX THIS*","8f68cd12":"VALUES OF F1 SCORE SHOWS THAT THE MODEL IS PERFORMING QUITE WELL","a0fa5853":"STANDARDIZATION OF THE DATA IS REQUIRED AS DATA ARE IN DIFFERENT SCALES","a9d09575":"LOGISTIC REGRESSION IS PERFORMING WELL, BUT CAN WE IMPROVE PERFORMANCE USING ANOTHER MODEL? LET'S APPLY ANOTHER ALGORITHM","e6f19899":"WHILE PLOTTING WE NEED TO KEEP IN MIND THAT AGAINST WHICH TYPE OF VARIABLES WE ARE PLOTTING THEN ONLY WE CAN DRAW INSIGHT FROM IT","69c5d31e":"**CHECK FOR NULL VALUES**","fa990ff5":"SINCE THE TARGET CLASS IS HIGHLY IMBALANCED, WE NEED TO TREAT IT AS IT'S PRESENCE WILL LEAD TO POOR PERFORMANCE OF THE MODEL. HERE I HAVE USED SMOTE (Synthetic Minority Oversampling Technique) TECHNIQUE. SMOTE WORKS BY RANDOMNLY PICKING A POINT FROM MINORITY CLASS AND COMPUTING A K-NEAREST NEIGHBOURS FOR THIS POINT.","7c698888":"So from above statistical description of the dataset we can see that mean age of people is around 43 years and mean bmi is more than normal","b48c2b1b":"*A stroke occurs when the blood supply to part of your brain is interrupted or reduced, preventing brain tissue from getting oxygen and nutrients. Brain cells begin to die in minutes*\n*There can be various factors related to occurence to stroke. So using the data given we try to list out the potential factors by using various visualization techniques. *","ae974b7a":"FOR ADULTS THE NORMAL BMI RANGE IS BETWEEN 18.5 TO 24.9 FOR ADULTS AND AS WE OBSERVE THAT AVERAGE BMI CALCULTION COMES OUT TO BE MORE THAN NORMAL THAT LARGE PROPROTION OF THE POPULATION IN THE GIVEN DATASET IS OVERWEIGHT","d47ff5a3":"**LET'S FIND OUT THE BEST PARAMETERS**","efbbdb9e":"HIGH AGE FEMALES ARE AT THE RISK TO STROKE","5cd0bb76":"LET'S APPLY **LOGISTIC REGRESSION**","fd039bf7":"**ROC CURVE**","e64fae28":"**CONTEXT**\n\nAccording to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\nThis dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.*","4b31d773":"***FILLING THE NULL VALUES WITH AVERAGE OF THE BMI'S***","b5b33689":"**TREATING IMBALANCE CLASS USING SMOTE**","0a1697fb":"CLASSIFICATION REPORT OF LOGISTIC REGRESSION","39c041f8":"**CORRELATION HEATMAP** TO CHECK FOR ANY CORRELATION BETWEEN VARIABLES","814e67fc":"TYPE OF RESIDENCE HARDLY MAKES ANY DIFFERENCE TO DISEASE"}}