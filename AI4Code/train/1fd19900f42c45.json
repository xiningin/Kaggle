{"cell_type":{"97c78f5a":"code","f31f3167":"code","4492c5a5":"code","9ec85f6f":"code","87a03b7f":"code","e59e3a49":"code","63f99024":"code","df2603f1":"code","7d94f381":"code","22b00d42":"code","d724020b":"code","54e33e16":"code","6401530a":"code","9d66e1cf":"code","8369f44d":"code","3b5b5d04":"code","736184e4":"code","578c72dd":"code","25d56742":"markdown","fe7731b1":"markdown","bf53c152":"markdown","cda68915":"markdown"},"source":{"97c78f5a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f31f3167":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nwarnings.simplefilter('ignore')","4492c5a5":"df_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')\n\ndf_train.head()","9ec85f6f":"# \u6570\u5024\u30c7\u30fc\u30bf\u306e\u307f\u6b8b\u3057\u305f\u3044\nprint(len(df_train.dtypes[df_train.dtypes != np.object]))\nprint(len(df_test.dtypes[df_test.dtypes != np.object]))","87a03b7f":"df_train = df_train[df_train.dtypes[df_train.dtypes != np.object].index].fillna(0).astype(np.int64)\ndf_test = df_test[df_test.dtypes[df_test.dtypes != np.object].index].fillna(0).astype(np.int64)\n\ndisplay(df_train.head())\ndisplay(df_test.head())","e59e3a49":"x_train = df_train.drop(\"SalePrice\", axis=1)\ny_train = df_train[[\"SalePrice\"]]\n\ndisplay(x_train.head())\ndisplay(y_train.head())","63f99024":"from sklearn.ensemble import RandomForestRegressor as RFR\nrf = RFR(n_estimators=80, max_features='auto')\nrf.fit(x_train, y_train)\n \n \nf, ax = plt.subplots(figsize=(11, 15))\nsns.barplot(x=rf.feature_importances_, y=x_train.columns.values, orient='h')","df2603f1":"print(df_train.columns)\nprint(df_train.columns[np.argsort(-rf.feature_importances_)])\ndisplay(df_test[df_train.columns[np.argsort(-rf.feature_importances_)]].head())","7d94f381":"# \u91cd\u8981\u5ea6\u306e\u9806\u306b\u4e26\u3073\u66ff\u3048 \norg_sort = np.argsort(-rf.feature_importances_)\n\nx_train = x_train.loc[:, df_train.columns[org_sort[:20]]]\nx_test = df_test.loc[:, df_train.columns[org_sort[:20]]]\n\nx_train.head()","22b00d42":"x_train.shape, y_train.shape","d724020b":"X_train, X_test, y_train, y_test = train_test_split(\n    x_train,\n    y_train,\n    test_size=0.2,\n    random_state=0\n)","54e33e16":"models = []\n\nK_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n\nfor cv_train_index, cv_test_index in K_fold.split(X_train.index, y_train):\n    # \u5b66\u7fd2\u30c7\u30fc\u30bf\n    cv_x_train = X_train.iloc[cv_train_index, :]\n    cv_y_train = y_train.iloc[cv_train_index, :]\n    # \u691c\u8a3c\u30c7\u30fc\u30bf\n    cv_x_test = X_train.iloc[cv_test_index, :]\n    cv_y_test = y_train.iloc[cv_test_index, :]\n\n    # \u5b66\u7fd2\n    model = lgb.LGBMRegressor()\n    model.fit(\n        cv_x_train, \n        cv_y_train,\n        eval_set=[(cv_x_train, cv_y_train), (cv_x_test, cv_y_test)],\n        verbose=-1, # \u5b66\u7fd2\u30ed\u30b0\u3092\u7701\u7565\n        eval_metric=\"rmse\"\n    )\n    \n    lgb.plot_metric(model)\n    plt.show()\n#     # \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u4e88\u6e2c\u3059\u308b\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n\n    # mse \u3092\u8a08\u7b97\u3059\u308b\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    print('rmse:', rmse)\n    \n    # \u5b66\u7fd2\u304c\u7d42\u308f\u3063\u305f\u30e2\u30c7\u30eb\u3092\u30ea\u30b9\u30c8\u306b\u5165\u308c\u3066\u304a\u304f\n    models.append(model) ","6401530a":"models","9d66e1cf":"x_test","8369f44d":"result = []\nfor fold_, model in enumerate(models):\n    pred = model.predict(x_test, num_iteration=model.best_iteration_)\n    result.append(pred)\n\nresult = np.array(result)\n\naverage_result = result.mean(axis=0)\nprint(average_result.shape, average_result)","3b5b5d04":"output = pd.DataFrame({'Id': x_test.index, 'SalePrice': average_result})","736184e4":"output.head()","578c72dd":"output.to_csv('testPrediction.csv',index = False)","25d56742":"k\u5206\u5272\u6cd5 x lightbgm","fe7731b1":"\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u8aad\u307f\u8fbc\u307f","bf53c152":"\u4e88\u6e2c","cda68915":"\u91cd\u8981\u5ea6\u306e\u78ba\u8a8d"}}