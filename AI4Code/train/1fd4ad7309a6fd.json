{"cell_type":{"10a4189b":"code","263cd812":"code","d30020b2":"code","fd9fb5a9":"code","c5b3e666":"code","501d00fb":"code","fce78b3d":"code","1e34abdf":"code","9e21d1c7":"code","18255d08":"code","a9882302":"code","d422f7e5":"code","c932bdba":"code","61648830":"code","159996fd":"code","29643f94":"code","a620ffec":"code","199e255f":"code","745bdf16":"code","a5168933":"markdown","121572b2":"markdown"},"source":{"10a4189b":"import os\nfrom operator import itemgetter    \nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nget_ipython().magic(u'matplotlib inline')\nplt.style.use('ggplot')\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\n#from sklearn.utils.fixes import signature\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nimport tensorflow as tf\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils, to_categorical\n \nfrom keras.datasets import reuters\n\nprint(os.getcwd())\nprint(\"Modules imported \\n\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","263cd812":"(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)","d30020b2":"print(\"train_data \", train_data.shape)\nprint(\"train_labels \", train_labels.shape)\n\nprint(\"test_data \", test_data.shape)\nprint(\"test_labels \", test_labels.shape)","fd9fb5a9":"# Reverse dictionary to see words instead of integers\n# Note that the indices are offset by 3 because 0, 1, and 2 are reserved indices for \u201cpadding,\u201d \u201cstart of sequence,\u201d and \u201cunknown.\u201d\n\nword_index = reuters.get_word_index()\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\ndecoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in\ntrain_data[0]])\n\nprint(decoded_newswire)\nprint(train_labels[0])","c5b3e666":"# VECTORIZE function\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results","501d00fb":"# Vectorize and Normalize train and test to tensors with 10k columns\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\nprint(\"x_train \", x_train.shape)\nprint(\"x_test \", x_test.shape)","fce78b3d":"# ONE HOT ENCODER of the labels\n\none_hot_train_labels = to_categorical(train_labels)\none_hot_test_labels = to_categorical(test_labels)\n\nprint(\"one_hot_train_labels \", one_hot_train_labels.shape)\nprint(\"one_hot_test_labels \", one_hot_test_labels.shape)","1e34abdf":"# Setting aside a VALIDATION set\n\nx_val = x_train[:1000]\npartial_x_train = x_train[1000:]\ny_val = one_hot_train_labels[:1000]\npartial_y_train = one_hot_train_labels[1000:]\n\nprint(\"x_val \", x_val.shape)\nprint(\"y_val \", y_val.shape)\n\nprint(\"partial_x_train \", partial_x_train.shape)\nprint(\"partial_y_train \", partial_y_train.shape)","9e21d1c7":"# MODEL\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.001), activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(256, kernel_regularizer=regularizers.l1(0.001), activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(46, activation='softmax'))\nmodel.summary()\n# REGULARIZERS L1 L2\n#regularizers.l1(0.001)\n#regularizers.l2(0.001)\n#regularizers.l1_l2(l1=0.001, l2=0.001)\n\n# Best results I got with HU=128\/128\/128 or 256\/256 and L1=0.001 and Dropout=0.5 = 77.02%\n# Without Regularizer 72.92%\n# Reg L1 = 76.04, L2 = 76.2, L1_L2 = 76.0\n# Only DropOut (0.5) = 76.85%","18255d08":"# FIT \/ TRAIN model\n\nNumEpochs = 10\nBatchSize = 512\n\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(partial_x_train, partial_y_train, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, y_val))\n\nresults = model.evaluate(x_val, y_val)\nprint(\"_\"*100)\nprint(\"Test Loss and Accuracy\")\nprint(\"results \", results)\n\nhistory_dict = history.history\nhistory_dict.keys()","a9882302":"# VALIDATION LOSS curves\n\nplt.clf()\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","d422f7e5":"## VALIDATION ACCURACY curves\n\nplt.clf()\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","c932bdba":"# PREDICT\n\npredictions = model.predict(x_test)\n# Each entry in predictions is a vector of length 46\nprint(predictions[123].shape)\n\n# The coefficients in this vector sum to 1:\nprint(np.sum(predictions[123]))\n\n# The largest entry is the predicted class \u2014 the class with the highest probability:\nprint(np.argmax(predictions[123]))","61648830":"# Get the top 3 classes\npredictions[21].argsort()[-3:][::-1]","159996fd":"test_labels[21]","29643f94":"SampleNum = 2125\n\nprint(test_labels[SampleNum])\nprint(predictions[SampleNum].argsort()[-3:][::-1])\n\ntest_labels[SampleNum] in predictions[SampleNum].argsort()[-3:][::-1]","a620ffec":"# Create a top 3 matrix\n\nTop3Preds = np.zeros((2246,3), dtype=int)\nprint(Top3Preds.shape)\n\nfor SampleNum in range(predictions.shape[0]):\n    Top3Preds[SampleNum] = predictions[SampleNum].argsort()[-3:][::-1]\n    \nTop3Preds","199e255f":"# Modify the raw final_predictions - prediction probs into 0 and 1 for the confusion matrix\n\nFinalPreds = np.zeros((2246,1), dtype=int)\nprint(FinalPreds.shape)\n\nfor SampleNum in range(Top3Preds.shape[0]):\n    if test_labels[SampleNum] in Top3Preds[SampleNum]:\n        FinalPreds[SampleNum] = 1\n        \nFinalPreds","745bdf16":"FinalPreds = pd.DataFrame(FinalPreds)\nNumTop3 = FinalPreds[0][FinalPreds[0] == 1].count()\npercentTop3 = round(100 *NumTop3 \/ FinalPreds.shape[0], 1)\n\nprint('Percent of one from top 3 being correct ... ', percentTop3, '%')\n","a5168933":"* **This kernel is based on one of the exercises in the excellent book: Deep Learning with Python by Francois Chollet**\n* It is a single-label (mutually exclusive), multi class classification of text problem \n* Solved using Keras - the Deep Learning framework I much appreciate (with TensorFlow as its backend)\n* The kernel imports the Reuters dataset from Keras","121572b2":"# Retrain from scratch for # of epochs per LEARNING curves above - and evaluate with TEST (which was set aside above)\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(46, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(partial_x_train,partial_y_train,epochs= 20, batch_size=512,\nvalidation_data=(x_val, y_val))\n\nresults = model.evaluate(x_test, one_hot_test_labels)\n\nprint(\"_\"*100)\nprint(results)"}}