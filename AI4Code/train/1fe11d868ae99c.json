{"cell_type":{"57394a13":"code","be27a19e":"code","d7ecac10":"code","02747046":"code","e265f8b7":"code","7c62d2ee":"code","252e5bbe":"code","3c477e9e":"code","8bff5e66":"code","2aa0b0b4":"code","217124e2":"code","f7994433":"code","12bb457d":"code","a9d3caec":"code","4557d7a6":"markdown"},"source":{"57394a13":"import numpy as np\nimport pandas as pd\nall_data = pd.read_csv('..\/input\/sbti-companies\/companies-taking-action.csv')","be27a19e":"selected_cols = all_data[['Date','Company Name', 'Target Qualification', 'Country',\n             'Region', 'Sector', 'Status', 'Target', 'Target Classification']]\n\n# Segregating companies with target set\ntarget_set = selected_cols.copy()\ntarget_set = target_set.loc[selected_cols['Status'] == 'Targets Set']\n# NaN date\ntarget_set = target_set.loc[target_set['Company Name'] != \"Legacy Vacation Resorts\"]\ntarget_set.Date = target_set.Date.astype('datetime64[ns]')\ntarget_set = target_set.set_index(target_set['Date'])\ntarget_set = target_set.drop('Date', axis = 1)\ntarget_set = target_set.sort_index()","d7ecac10":"X_original = target_set.reset_index()[['Date','Country', 'Region', 'Sector']]\ny_original = target_set['Target Qualification']\nX_original['year'] = X_original.Date.dt.year\nX_original['month'] = X_original.Date.dt.month\nX_original['quarter'] = X_original.Date.dt.quarter\nX_original['day'] = X_original.Date.dt.day\nX_original['day_of_week'] = X_original.Date.dt.dayofweek\nX_original.drop('Date', axis  = 1)\nX_original.shape, y_original.shape","02747046":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nle = LabelEncoder()\nCountry_label = le.fit_transform(X_original['Country'])\nRegion_label = le.fit_transform(X_original['Region'])\nSector_label = le.fit_transform(X_original['Sector'])","e265f8b7":"X_label = X_original.copy()\ny_label = le.fit_transform(y_original)\nX_label['Target Qualification'] = y_label\nX_label['Country'] = Country_label\nX_label['Region'] = Region_label\nX_label['Sector'] = Sector_label\nX_label = X_label[['year', 'quarter', 'month', 'day_of_week', 'day', 'Country', 'Region', 'Sector']]\nX_train,X_test,y_train,y_test = train_test_split(X_label, y_label, test_size=0.33, random_state=24)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","7c62d2ee":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\ndt.fit(X_train,y_train)\nrf.fit(X_train,y_train)\nprint(\"Training Accuracy of Decision Tree: \", dt.score(X_train,y_train))\nprint(\"Training Accuracy of  Random Forest: \",rf.score(X_train,y_train))\ny_dt = dt.predict(X_test)\ny_rf = rf.predict(X_test)\nprint(\"Testing Accuracy of Decision Tree : \", accuracy_score(y_dt,y_test))\nprint(\"Testing Accuracy Random Forest: \",accuracy_score(y_rf,y_test))","252e5bbe":"# from sklearn.model_selection import KFold\n# from xgboost import XGBRegressor\n# from sklearn.metrics import mean_squared_error\n# df_train = X_label\n# df_train['kfold'] = -1\n# kf = KFold(n_splits = 5, shuffle = True, random_state = 24)\n# for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X = df_train)):\n#     df_train.loc[valid_indicies, \"kfold\"] = fold\n# # df_train\n# from sklearn.model_selection import train_test_split\n# X_train,X_test,y_train,y_test = train_test_split(df_train, y_label, test_size=0.25, random_state=24)\n# print(X_train.shape)\n# print(y_train.shape)\n# print(X_test.shape)\n# print(y_test.shape)","3c477e9e":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nmy_pipeline1 = Pipeline(steps=[('preprocessor', SimpleImputer()),\n                              ('model', RandomForestRegressor(n_estimators=50,\n                                                              random_state=0))\n                             ])\nmy_pipeline2 = Pipeline(steps=[('preprocessor', SimpleImputer()),\n                              ('model', RandomForestClassifier(n_estimators=50,\n                                                              random_state=0))\n                             ])\nfrom sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* MAE\nscores = -1 * cross_val_score(my_pipeline2, X_label, y_label,\n                              cv=5,\n                              scoring='neg_mean_absolute_error')\n\nprint(\"MAE scores:\\n\", scores)\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())","8bff5e66":"from xgboost import XGBRegressor\nX_train, X_valid, y_train, y_valid = train_test_split(X_label, y_label)\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.5, n_jobs=4)\nmy_model.fit(X_train, y_train,\n            early_stopping_rounds=5, \n             eval_set=[(X_valid, y_valid)],\n             verbose=False)\nfrom sklearn.metrics import mean_absolute_error\n\npredictions = my_model.predict(X_valid)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_valid)))","2aa0b0b4":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\nX_lda = lda.fit_transform(X_label, y_label)\nlda.explained_variance_ratio_","217124e2":"from matplotlib import pyplot as plt\nplt.xlabel('LD1')\nplt.ylabel('LD2')\nplt.scatter(\n    X_lda[:,0],\n    X_lda[:,1],\n    c=y_label,\n    cmap='rainbow',\n    alpha=0.7,\n    edgecolors='b'\n)","f7994433":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_label, y_label)\npca.explained_variance_ratio_","12bb457d":"plt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.scatter(\n    X_pca[:,0],\n    X_pca[:,1],\n    c=y_label,\n    cmap='rainbow',\n    alpha=0.7,\n    edgecolors='b'\n)","a9d3caec":"from sklearn.metrics import confusion_matrix\nX_train, X_test, y_train, y_test = train_test_split(X_lda, y_label, random_state=24)\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred = dt.predict(X_test)\nconfusion_matrix(y_test, y_pred)","4557d7a6":"## Modelling\n### Data-type, cardinality and encoding\n\n* __About data type and cardinality__ : The data is <mark>categorical<\/mark> and there are variables <mark>with high cardinality<\/mark>.\n* __About encoding__: \n    * one hot encoding will lead to high number of features, trying <mark>frequency based encoding<\/mark>\n    * <mark>frequency based encoding<\/mark> does not work for Logistic regression and KNN, trying <mark>label encoding<\/mark>"}}