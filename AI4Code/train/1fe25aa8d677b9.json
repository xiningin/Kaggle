{"cell_type":{"3c6a18f9":"code","8b311e35":"code","fb248319":"code","0a01641d":"code","0f93e71f":"code","c35383e0":"code","d2934dc4":"code","c997e432":"markdown","ea53a725":"markdown","f9bd4577":"markdown","fa2e7435":"markdown","f9891bf9":"markdown","665134d2":"markdown","0772cbca":"markdown"},"source":{"3c6a18f9":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import History\nimport matplotlib.pyplot as plt\nimport numpy as np","8b311e35":"datagen = ImageDataGenerator(\n    rescale = 1.0\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip = True,\n    validation_split=0.1\n)\n\nbatch_size = 48\nnum_classes = 2\nimage_size = 64","fb248319":"train_generator = datagen.flow_from_directory(\n    '..\/input\/cell_images\/cell_images',\n    target_size = (image_size, image_size),\n    batch_size = batch_size,\n    class_mode = 'binary',\n    subset='training'\n)\n\ndev_generator = datagen.flow_from_directory(\n    '..\/input\/cell_images\/cell_images',\n    target_size = (image_size, image_size),\n    batch_size = batch_size,\n    class_mode = 'binary',\n    subset='validation'\n)","0a01641d":"sample = train_generator.next();\nplt.imshow(sample[0][0])\ntrain_generator.reset()","0f93e71f":"model = Sequential()\nmodel.add(Conv2D(64,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\n\nmodel.add(Conv2D(64,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128,(3,3)\n        ,input_shape=(image_size,image_size,3)\n        ,activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\nmodel.summary()","c35383e0":"history=model.fit_generator(\n    train_generator,\n    steps_per_epoch=2000 \/\/ batch_size,\n    epochs=60,\n    validation_data=dev_generator,\n    validation_steps=800 \/\/ batch_size)","d2934dc4":"metrics = history.history\n\nplt.subplot(211)\n\nplt.plot(metrics['acc'],color='blue')\nplt.plot(metrics['val_acc'],color='green')\n\nplt.subplot(212)\n\nplt.plot(metrics['loss'],color='yellow')\nplt.plot(metrics['val_loss'],color='red')","c997e432":"# Malaria Cell Image Classification using CNN\n\nThis kernel is a demonstration of using CNN with keras on tensorflow to classify if an image of a cell has Malaria or not.","ea53a725":"### Data Augmentation\nHere, I use `ImageDataGenerator` from keras.","f9bd4577":"### Visualize the results","fa2e7435":"### Visualize\nLet us inspect an image from the dataset.","f9891bf9":"### Define the Model\nThe model is as follows.","665134d2":"### Input Data\nUsing `flow_from_directory` from keras lets us easily import the images into our script. It automatically lables the images according to the folder names.","0772cbca":"### Time to Train!"}}