{"cell_type":{"670bd8fc":"code","8ccc556f":"code","2899d6a8":"code","37fd48bf":"code","5f7445e8":"code","aa66c649":"code","8978dfde":"code","c480b751":"code","8e27b29a":"code","3c4bcb39":"code","4a39c6c2":"code","f891afc4":"code","9943296d":"code","469241cf":"code","1b4d5f79":"code","a2f50d52":"code","8c241068":"code","09a9a48e":"code","e07ff8dd":"code","abe8789f":"code","08b7d989":"code","afce7ccd":"code","55584f60":"code","d758d20a":"code","7ed4f617":"markdown","7f09e0bd":"markdown","a994d10c":"markdown","d1f96581":"markdown","ba8a22a6":"markdown","2da11ae0":"markdown","217fd166":"markdown","829326e8":"markdown","66a5cd4b":"markdown"},"source":{"670bd8fc":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nimport pathlib\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","8ccc556f":"dataset_url = \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz\"\ndata_dir = tf.keras.utils.get_file(\"flower_photos\", origin=dataset_url, untar=True)\ndata_dir = pathlib.Path(data_dir)","2899d6a8":"image_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)","37fd48bf":"roses = list(data_dir.glob('roses\/*'))\nPIL.Image.open(str(roses[23]))","5f7445e8":"tulips = list(data_dir.glob('tulips\/*'))\nPIL.Image.open(str(tulips[4]))","aa66c649":"batch_size = 32\nimg_height = 180\nimg_width = 180\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split = 0.2,\n    subset = \"training\",\n    seed = 123,\n    batch_size = batch_size,\n    image_size = (img_height, img_width) \n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split = 0.2,\n    subset = \"validation\",\n    seed=123,\n    batch_size = batch_size,\n    image_size = (img_height, img_width)\n)","8978dfde":"class_names = train_ds.class_names\nprint(class_names)","c480b751":"plt.figure(figsize=(10,10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3,3, i+1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","8e27b29a":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","3c4bcb39":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","4a39c6c2":"normalization_layer = layers.experimental.preprocessing.Rescaling(1.\/255)\n\nnormalized_ds = train_ds.map(lambda x, y : (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nimage = image_batch[7]\nprint(np.min(image), np.max(image))","f891afc4":"num_classes = 5\n\nmodel = Sequential([\n                    layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(img_height, img_width, 3)),\n                    layers.Conv2D(16,3, padding = 'same', activation='relu'),\n                    layers.MaxPooling2D(),\n                    layers.Conv2D(32,3, padding = 'same', activation='relu'),\n                    layers.MaxPooling2D(),\n                    layers.Conv2D(64,3, padding = 'same', activation='relu'),\n                    layers.Flatten(),\n                    layers.Dense(128, activation='relu'),\n                    layers.Dense(num_classes)\n])","9943296d":"model.compile(optimizer='Adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])","469241cf":"model.summary()","1b4d5f79":"epochs = 10\nhistory = model.fit(train_ds, validation_data = val_ds, epochs = epochs)","a2f50d52":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8,8))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label=\"Training Accuracy\")\nplt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\nplt.legend(loc='lower right')\nplt.title(\"Training and Validation Acuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label=\"Training Loss\")\nplt.plot(epochs_range, val_loss, label=\"Validation Loss\")\nplt.legend(loc='upper right')\nplt.title(\"Training and Validation Loss\")\n\nplt.show()","8c241068":"data_augmentation = keras.Sequential([\n                                      layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n                                      layers.experimental.preprocessing.RandomRotation(0.1),\n                                      layers.experimental.preprocessing.RandomZoom(0.1)\n])","09a9a48e":"plt.figure(figsize=(10,10))\nfor imgaes, _ in train_ds.take(1):\n  for i in range(9):\n    augmentated_images = data_augmentation(images)\n    ax = plt.subplot(3,3, i+1)\n    plt.imshow(augmentated_images[6].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","e07ff8dd":"model = keras.Sequential([\n        data_augmentation,\n        layers.experimental.preprocessing.Rescaling(1.\/255),\n        layers.Conv2D(16,3, padding = 'same', activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(32,3, padding = 'same', activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(64,3, padding = 'same', activation='relu'),\n        layers.MaxPooling2D(),\n        layers.Dropout(0.2),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(num_classes)\n])","abe8789f":"model.compile(optimizer='adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])","08b7d989":"model.summary()","afce7ccd":"epochs = 15\nhistory = model.fit(\n         train_ds,\n         validation_data = val_ds,\n         epochs = epochs\n)","55584f60":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8,8))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label = \"Training Accuracy\")\nplt.plot(epochs_range, val_acc, label = \"Validation Accuracy\")\nplt.legend(loc=\"lower right\")\nplt.title(\"Training and Validation Accuracy\")\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label = \"Training Loss\")\nplt.plot(epochs_range, val_loss, label = \"Validation Loss\")\nplt.legend(loc=\"upper right\")\nplt.title(\"Training and Validation Loss\")\n\nplt.show()","d758d20a":"sunflower_url = \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/592px-Red_sunflower.jpg\"\nsunflower_path = tf.keras.utils.get_file('Red_sunflower', origin = sunflower_url)\n\nimg = keras.preprocessing.image.load_img(sunflower_path, target_size=(img_height, img_width))\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\"This image most likly belongs to {} with a {:.2f} percent of confidence.\" .format(class_names[np.argmax(score)], 100*np.max(score)))","7ed4f617":"**Creating Dataset**\n\n---\n\n---\n\n\n\n","7f09e0bd":"**Train Model**\n\n---\n\n\n\n---\n\n","a994d10c":"**Dropout**\n\n---\n\n\n\n---\n\n","d1f96581":"**Standardizing Data**\n\n---\n\n\n\n---\n\n","ba8a22a6":"**Configuring the dataset for performance**\n\n---\n\n\n\n---\n\n","2da11ae0":"**Compile Model**\n\n---\n\n\n\n---\n\n","217fd166":"**Creat Model**\n\n---\n\n\n\n---\n\n","829326e8":"**Training Results**\n\n---\n\n\n\n---\n\n","66a5cd4b":"**Data Augmentation**\n\n---\n\n\n\n---\n\n"}}