{"cell_type":{"5fd268a1":"code","46b10e8b":"code","6e174b5a":"code","e4ddfbdf":"code","3fb15989":"code","e85f32b2":"code","790f7492":"code","3df8ed61":"code","5be470b9":"code","3c9bd27f":"code","54c87845":"code","0bd3fea6":"code","e6ade321":"code","bfabe3d6":"code","be163b76":"code","756880b5":"code","2d90661d":"code","adb60329":"code","5b828226":"code","62bde4f1":"code","54535dcc":"code","149cd592":"code","6bbf79b6":"code","8a7845b6":"code","665ba96c":"code","f0ac9aca":"code","254e2fc7":"code","aa562bc1":"code","8b455c53":"code","54bc0134":"code","5e2418bc":"code","626b8d92":"code","17da5aa3":"code","e98c64ba":"code","6cb789f2":"code","b079fc42":"code","72188acb":"code","b8749e23":"code","a440a8b2":"code","cbb5e5b9":"code","2ce03b09":"code","8539e388":"code","110f943e":"code","5d1b565f":"code","c5a193d7":"code","b3631eb7":"code","ceaa873b":"code","b9ec7223":"code","d1664bbb":"code","64c42c8d":"code","0b850ca2":"code","5d94e171":"code","c4a4ca15":"code","056e438a":"code","da9c6756":"code","22465c71":"code","dc14d575":"code","2149b9b0":"code","b2384f3a":"code","b0528f2d":"code","4c83cae9":"code","7f35f62b":"code","838bcb47":"code","30128937":"code","0a177716":"code","996c0f3f":"code","ebe795c0":"code","c6d7267f":"code","da0e9bb0":"code","27ee7d4d":"code","721895e0":"markdown","be2719b3":"markdown","dc6ffb6d":"markdown","9910e31d":"markdown","6876bd45":"markdown","159ddf59":"markdown","c0085193":"markdown","75e72b60":"markdown","06622868":"markdown","083141bb":"markdown","f769bbf0":"markdown","7689bf74":"markdown"},"source":{"5fd268a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46b10e8b":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nsns.set_theme(context='notebook', style='darkgrid')\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import plot_confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","6e174b5a":"dataframe_train  = pd.read_csv('..\/input\/titanic\/train.csv')\ndataframe_test  = pd.read_csv('..\/input\/titanic\/test.csv')\ndataframe_pred = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","e4ddfbdf":"dataframe_train.sample(5)","3fb15989":"for i in range(len(dataframe_train.columns)):\n  print(f'{i} -->> {dataframe_train.columns[i]}')","e85f32b2":"print(f'shape of dataframe_train dataset is {dataframe_train.shape[0],dataframe_train.shape[-1]}')","790f7492":"dataframe_test.sample(5)","3df8ed61":"for i in range(len(dataframe_test.columns)):\n  print(f'{i} -->> {dataframe_test.columns[i]}')","5be470b9":"dataframe_train.describe().T.style.bar(subset=['mean'],color='Red').background_gradient(subset='std',cmap='ocean').background_gradient(subset=['50%'],cmap='plasma').background_gradient(subset=['max'],cmap=None)","3c9bd27f":"dataframe_train.hist(bins=50,figsize=(20,18))","54c87845":"dataframe_train.nunique()","0bd3fea6":"dataframe_train.select_dtypes(include=['int64','float64']).columns","e6ade321":"dataframe_train.select_dtypes(include='object').columns\n","bfabe3d6":"plt.figure(figsize=(12,8))\nplt.title('Missing Values Per Feature')\nnans = dataframe_train.isna().sum().sort_values(ascending=False).to_frame()\nsns.heatmap(nans,annot=True,fmt='d',cmap='vlag')","be163b76":"print(dataframe_train['Sex'].value_counts())\nsns.countplot(x='Sex',data= dataframe_train)","756880b5":"print(dataframe_train['Embarked'].value_counts())\nsns.countplot(x='Embarked',data=dataframe_train)","2d90661d":"print(dataframe_train['Pclass'].value_counts())\nsns.countplot(x='Pclass',data=dataframe_train)","adb60329":"print(dataframe_train['Parch'].value_counts())\nsns.countplot(x='Parch',data=dataframe_train)","5b828226":"from pandas.plotting import scatter_matrix\nattributes = ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']\nscatter_matrix(dataframe_train[attributes],figsize=(12,12))","62bde4f1":"sns.pairplot(dataframe_train)","54535dcc":"drop_dataset = ['PassengerId','Name','Ticket','Cabin','Parch','SibSp']\ndataframe_train=dataframe_train.drop(drop_dataset,axis=1,inplace=False)","149cd592":"plt.figure(figsize=(12, 8))\nheatmap = sns.heatmap(dataframe_train.corr()[['Survived']].sort_values(by='Survived', ascending=False), \n                      vmin=-1, \n                      vmax=1, \n                      annot=True, \n                      cmap=sns.diverging_palette(5, 5, as_cmap=True))","6bbf79b6":"dataframe_train.head()","8a7845b6":"dataframe_train.info()","665ba96c":"median_value =dataframe_train['Age'].median()\nmedian_value","f0ac9aca":"dataframe_train['Age']=dataframe_train['Age'].fillna(median_value)","254e2fc7":"dataframe_train.info()","aa562bc1":"empty = pd.isnull(dataframe_train['Embarked']).value_counts()\nempty ","8b455c53":"null_columns=dataframe_train.columns[dataframe_train.isnull().any()]\nprint(dataframe_train[null_columns].isnull().sum())","54bc0134":"print(dataframe_train[dataframe_train.isnull().any(axis=1)][null_columns].head())","5e2418bc":"dataframe_train = dataframe_train.drop(61,axis=0)\ndataframe_train  = dataframe_train.drop(829,axis=0)","626b8d92":"dataframe_train.info()","17da5aa3":"dataframe_train.isnull().sum()","e98c64ba":"dataframe_train =dataframe_train.reset_index()","6cb789f2":"dataframe_train=dataframe_train.iloc[:,1:]","b079fc42":"dataframe_train","72188acb":"\none_hot_encoded_data = pd.get_dummies(dataframe_train, columns = ['Embarked','Sex','Pclass'])\none_hot_encoded_data.head()","b8749e23":"plt.figure(figsize=(24,22))\nsns.heatmap(one_hot_encoded_data.corr().round(2),annot=True)","a440a8b2":"dataframe_test.head()","cbb5e5b9":"dataframe_test = pd.merge(dataframe_test,dataframe_pred,on='PassengerId')","2ce03b09":"dataframe_test.info()","8539e388":"drop_dataset_test = ['PassengerId','Name','Ticket','Cabin','Parch','SibSp']\ndataframe_test=dataframe_test.drop(drop_dataset_test,axis=1,inplace=False)","110f943e":"median_value_test=dataframe_test['Age'].median()\nmedian_value_test","5d1b565f":"dataframe_test['Age']=dataframe_test['Age'].fillna(median_value_test)","c5a193d7":"null_columns_test=dataframe_test.columns[dataframe_test.isnull().any()]\ndataframe_test[null_columns_test].isnull().sum()","b3631eb7":"dataframe_test[dataframe_test.isnull().any(axis=1)][null_columns_test].head()","ceaa873b":"dataframe_test = dataframe_test.drop(152,axis=0)","b9ec7223":"dataframe_test.reset_index()","d1664bbb":"dataframe_test=dataframe_test.iloc[:,0:]","64c42c8d":"dataframe_test.head()","0b850ca2":"\none_hot_encoded_data_test = pd.get_dummies(dataframe_test, columns = ['Embarked','Sex','Pclass'])\none_hot_encoded_data_test.head()","5d94e171":"plt.figure(figsize=(24,22))\nsns.heatmap(one_hot_encoded_data_test.corr().round(2),annot=True)","c4a4ca15":"X_train = one_hot_encoded_data.drop('Survived',axis=1)\ny_train = one_hot_encoded_data['Survived']\nX_test = one_hot_encoded_data_test.drop('Survived',axis=1)\ny_test = one_hot_encoded_data_test['Survived']\n","056e438a":"print(f'shape of X_train is {X_train.shape}\\nshape of X_test is {X_test.shape}\\nshape of y_train is {y_train.shape}\\nshape of y_test is {y_test.shape}')","da9c6756":"X_test.head()","22465c71":"X_train.head()","dc14d575":"logistic_model = LogisticRegression(max_iter=1000)\nlogistic_model.fit(X_train,y_train)\n","2149b9b0":"train_predictions = logistic_model.predict(X_train)\ntest_predictions = logistic_model.predict(X_test)","b2384f3a":"model_performance = pd.DataFrame([['LogisticRegression',round(accuracy_score(y_train,train_predictions)*100,2),round(accuracy_score(y_test,test_predictions)*100,2)]],columns=['Model','Train_Accuracy','Test_Accuracy'])\nprint(model_performance)","b0528f2d":"\ndef dt_score(max_leaf_nodes, X_train, y_train,X_test,y_test):\n    model = DecisionTreeClassifier(max_leaf_nodes= max_leaf_nodes,random_state=1)\n    model.fit(X_train,y_train)\n    train_predict= model.predict(X_train)\n    test_predict = model.predict(X_test)\n    ac_score_train = round(accuracy_score(y_train,train_predict)*100,2)\n    ac_score_test = round(accuracy_score(y_test,test_predict)*100,2)\n    return(ac_score_train,ac_score_test)","4c83cae9":"dt_score_results = pd.DataFrame(columns=['Max_leaf_nodes','Train_Accuracy','Test_Accuracy'])\nfor max_leaf_nodes in [2,3,4,5,10,20,30,40,50]:\n    ac_score_train,ac_score_test = dt_score(max_leaf_nodes,X_train,y_train,X_test,y_test)\n    print(\"Max leaf nodes: %d  \\t Train Accuracy:  %.2f \\t Test Accuracy %.2f\" % (max_leaf_nodes, ac_score_train, ac_score_test))","7f35f62b":"decision_tree_model = DecisionTreeClassifier(max_leaf_nodes=2,random_state=1)\ndecision_tree_model.fit(X_train,y_train)\ntrain_prediction = decision_tree_model.predict(X_train)\ntest_predictions = decision_tree_model.predict(X_test)\nmodel_performance = model_performance.append(pd.DataFrame([['DecisionTreeClassifier',round(accuracy_score(y_train,train_predictions)*100,2),round(accuracy_score(y_test,test_predictions)*100,2)]],columns=['Model','Train_Accuracy','Test_Accuracy']),ignore_index=True)\nprint(model_performance)","838bcb47":"def rf_score(max_leaf_nodes, X_train, y_train,X_test,y_test):\n    model = RandomForestClassifier(max_leaf_nodes= max_leaf_nodes,random_state=1)\n    model.fit(X_train,y_train)\n    train_predict= model.predict(X_train)\n    test_predict = model.predict(X_test)\n    ac_score_train = round(accuracy_score(y_train,train_predict)*100,2)\n    ac_score_test = round(accuracy_score(y_test,test_predict)*100,2)\n    return(ac_score_train,ac_score_test)","30128937":"rf_score_results = pd.DataFrame(columns=['Max_leaf_nodes','Train_Accuracy','Test_Accuracy'])\nfor max_leaf_nodes in [2,3,4,5,10,20,30,40,50]:\n    ac_score_train,ac_score_test = rf_score(max_leaf_nodes,X_train,y_train,X_test,y_test)\n    print(\"Max leaf nodes: %d  \\t Train Accuracy:  %.2f \\t Test Accuracy %.2f\" % (max_leaf_nodes, ac_score_train, ac_score_test))","0a177716":"\nrandom_forest_model = RandomForestClassifier(max_leaf_nodes=4,random_state=1)\nrandom_forest_model.fit(X_train,y_train)\ntrain_prediction = decision_tree_model.predict(X_train)\ntest_predictions = decision_tree_model.predict(X_test)\nmodel_performance = model_performance.append(pd.DataFrame([['RandomForestClassifier',round(accuracy_score(y_train,train_predictions)*100,2),round(accuracy_score(y_test,test_predictions)*100,2)]],columns=['Model','Train_Accuracy','Test_Accuracy']),ignore_index=True)\nprint(model_performance)","996c0f3f":"def svc_score( X_train, y_train,X_test,y_test):\n    model = SVC()\n    model.fit(X_train,y_train)\n    train_predict= model.predict(X_train)\n    test_predict = model.predict(X_test)\n    ac_score_train = round(accuracy_score(y_train,train_predict)*100,2)\n    ac_score_test = round(accuracy_score(y_test,test_predict)*100,2)\n    return(ac_score_train,ac_score_test)","ebe795c0":"svc_model = svc_score(X_train,y_train,X_test,y_test)","c6d7267f":"\nsvc_model = SVC(random_state=1)\nsvc_model.fit(X_train,y_train)\ntrain_prediction =svc_model.predict(X_train)\ntest_predictions = svc_model.predict(X_test)\nmodel_performance = model_performance.append(pd.DataFrame([['SVC',round(accuracy_score(y_train,train_predictions)*100,2),round(accuracy_score(y_test,test_predictions)*100,2)]],columns=['Model','Train_Accuracy','Test_Accuracy']),ignore_index=True)\nprint(model_performance)","da0e9bb0":"full_predictions_svc = svc_model.predict(X_test)\nprint( \"Accuracy Score: %.2f \" % (round(accuracy_score(y_test, full_predictions_svc)*100,2)))\n\n# Plotting confusion matrix\nplot_confusion_matrix(svc_model,\n                      X_test, \n                      y_test,\n                      cmap=plt.cm.Blues,\n                      normalize= 'true')","27ee7d4d":"full_predictions = random_forest_model.predict(X_test)\nprint( \"Accuracy Score: %.2f \" % (round(accuracy_score(y_test, full_predictions)*100,2)))\n\n# Plotting confusion matrix\nplot_confusion_matrix(random_forest_model,\n                      X_test, \n                      y_test,\n                      cmap=plt.cm.Blues,\n                      normalize= 'true')","721895e0":"## Removing NaN rows ","be2719b3":"# Correlation Between features and Target","dc6ffb6d":"## Position of missed value rows in dataset","9910e31d":"# Train Dataset","6876bd45":"# Drop unless columns","159ddf59":"# SVC","c0085193":"# Missing value ","75e72b60":"# MODEL","06622868":"# LogisticRegression","083141bb":"# RandomForestClasifer","f769bbf0":"# Test Dataset","7689bf74":"# DecisionTreeClassifier"}}