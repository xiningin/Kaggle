{"cell_type":{"cba92d6e":"code","cfbc5018":"code","72be2250":"code","646c6067":"code","804f5baa":"code","19a6a20e":"code","2d610408":"code","c3730918":"code","e3261a36":"code","82caa4cc":"code","14476371":"markdown","3815fa41":"markdown","ba0ac748":"markdown","f78edbdf":"markdown"},"source":{"cba92d6e":"# import libs\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport gc\nimport optuna\n\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor","cfbc5018":"# reduce cols for use to save memory capacity\nbasic_cols = ['row_id', 'time_id', 'investment_id', 'target']\nnum_feat = 5\nfeatures = [f'f_{i}' for i in range(num_feat)]\ncols = basic_cols + features\n\n# load data\ntrain_df = pd.read_csv('..\/input\/ubiquant-market-prediction\/train.csv', usecols=cols)\ndisplay(train_df)\n\ngc.collect()","72be2250":"print(train_df.info())\nprint('')\nprint(train_df.describe())","646c6067":"# split train data\ninvestment_ids = train_df['investment_id'].unique()\nnum_ids = len(investment_ids)\ntr_rate = 0.8\n\ntr_ids = investment_ids[:int(num_ids*tr_rate)]\nval_ids = investment_ids[int(num_ids*tr_rate):]\nprint('train: ', len(tr_ids), )\nprint('val: ', len(val_ids),)\n\ntrain = train_df[train_df['investment_id'].isin(tr_ids)]\nvalid = train_df[train_df['investment_id'].isin(val_ids)]\n\ndisplay(train)\ndisplay(valid)","804f5baa":"# prepare for training\ntr_y = train['target'].values\ntr_x = train[features].values\nval_y = valid['target'].values\nval_x = valid[features].values\nlgb_train = lgb.Dataset(tr_x, tr_y)\nlgb_eval = lgb.Dataset(val_x, val_y)\n\ndel train_df, train, valid\ngc.collect()","19a6a20e":"def objective(trial):\n    \n    train_x, test_x, train_y, test_y = tr_x, val_x, tr_y, val_y\n    param = {\n        'metric': 'rmse', \n        'random_state': 2022,\n        'n_estimators': 500,\n        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 10.0),\n        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 10.0),\n        'max_depth': trial.suggest_int(\"max_depth\", 2, 30),\n        'num_leaves' : trial.suggest_int('num_leaves', 2, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),\n    }\n    model = LGBMRegressor(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=10,verbose=-1)\n    \n    preds = model.predict(test_x)\n    \n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","2d610408":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=3)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","c3730918":"gc.collect()","e3261a36":"# training with lgbm\nparams=study.best_params   \nparams['random_state'] = 2022\nparams['n_estimators'] = 1000\nparams['metric'] = 'rmse'\n\nmodel = LGBMRegressor(**params)\n\ntrain_x, test_x, train_y, test_y = tr_x, val_x, tr_y, val_y\n\nmodel.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=-1)","82caa4cc":"# inference\nimport ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    preds = model.predict(test_df[features].values)\n    sample_prediction_df['target'] = preds  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","14476371":"I only use 5 features here as an example. If you want to achieve a better score then perhaps you should use more","3815fa41":"Increase the number of trials (***n_trials***) if you have some time *to waste*","ba0ac748":"You can add more parameters, those are given as an example","f78edbdf":"This notebook is a modified version of the following one:\nhttps:\/\/www.kaggle.com\/yosukeyama\/ubiquant-simple-lgbm-train-infer"}}