{"cell_type":{"d5d48a93":"code","85a08fd2":"code","5edb958f":"code","73a76bfa":"code","35ca9a44":"code","65a503ca":"code","ec87d894":"code","32734a7e":"markdown","c66cc2e1":"markdown","6776ec62":"markdown","c03a62cb":"markdown","07878ec2":"markdown","22cd3760":"markdown","a4ac35b7":"markdown","b9370233":"markdown","602a3a5e":"markdown","b931c24a":"markdown","6c398b77":"markdown","5bb51947":"markdown","3f1ca309":"markdown"},"source":{"d5d48a93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","85a08fd2":"!pip install numpyro","5edb958f":"from jax import ops, random\nfrom jax.scipy.special import expit\n\nimport numpyro\nimport numpyro.distributions as dist\nfrom numpyro.infer import MCMC, NUTS, Predictive","73a76bfa":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nd = train_df.copy()\nd.Embarked.fillna(\"S\", inplace=True)  # filling 2 missing data points with the mode \"S\"\nd[\"Title\"] = d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).apply(\n    lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")\ntitle_cat = pd.CategoricalDtype(categories=[\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\", \"Misc.\"], ordered=True)\nage_mean, age_std = d.Age.mean(), d.Age.std()\nembarked_cat = pd.CategoricalDtype(categories=[\"S\", \"C\", \"Q\"], ordered=True)\ndata = dict(age=d.Age.pipe(lambda x: (x - age_mean) \/ age_std).values,\n            pclass=d.Pclass.values - 1,\n            title=d.Title.astype(title_cat).cat.codes.values,\n            sex=(d.Sex == \"male\").astype(int).values,\n            sibsp=d.SibSp.clip(0, 1).values,\n            parch=d.Parch.clip(0, 2).values,\n            embarked=d.Embarked.astype(embarked_cat).cat.codes.values,\n            survived=d.Survived.values)","35ca9a44":"def model(age, pclass, title, sex, sibsp, parch, embarked, survived=None):\n    # create a variable for each of Pclass, Title, Sex, SibSp, Parch,\n    b_pclass = numpyro.sample(\"b_Pclass\", dist.Normal(0, 1), sample_shape=(3,))\n    b_title = numpyro.sample(\"b_Title\", dist.Normal(0, 1), sample_shape=(5,))\n    b_sex = numpyro.sample(\"b_Sex\", dist.Normal(0, 1), sample_shape=(2,))\n    b_sibsp = numpyro.sample(\"b_SibSp\", dist.Normal(0, 1), sample_shape=(2,))\n    b_parch = numpyro.sample(\"b_Parch\", dist.Normal(0, 1), sample_shape=(3,))\n    b_embarked = numpyro.sample(\"b_Embarked\", dist.Normal(0, 1), sample_shape=(3,))\n\n    # impute Age by Title\n    age_mu = numpyro.sample(\"age_mu\", dist.Normal(0, 1), sample_shape=(5,))\n    age_mu = age_mu[title]\n    age_sigma = numpyro.sample(\"age_sigma\", dist.Normal(0, 1), sample_shape=(5,))\n    age_sigma = age_sigma[title]\n    age_isnan = np.isnan(age)\n    age_nanidx = np.nonzero(age_isnan)[0]\n    if survived is not None:\n        age_impute = numpyro.param(\"age_impute\", np.zeros(age_isnan.sum()))\n    else:  # for prediction, we sample `age_impute` from Normal(age_mu, age_sigma)\n        age_impute = numpyro.sample(\"age_impute\", dist.Normal(age_mu[age_nanidx], age_sigma[age_nanidx]))\n    age = ops.index_update(age, age_nanidx, age_impute)\n    numpyro.sample(\"age\", dist.Normal(age_mu, age_sigma), obs=age)\n\n    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n    b_age = numpyro.sample(\"b_Age\", dist.Normal(0, 1))\n    logits = a + b_age * age\n\n    logits = logits + b_title[title] + b_pclass[pclass] + b_sex[sex] \\\n        + b_sibsp[sibsp] + b_parch[parch] + b_embarked[embarked]\n    # for prediction, we will convert `logits` to `probs` and record that result\n    if survived is None:\n        probs = expit(logits)\n        numpyro.sample(\"probs\", dist.Delta(probs))\n    numpyro.sample(\"survived\", dist.Bernoulli(logits=logits), obs=survived)","65a503ca":"mcmc = MCMC(NUTS(model), 1000, 1000)\nmcmc.run(random.PRNGKey(0), **data)\nmcmc.print_summary()","ec87d894":"test_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nd = test_df.copy()\nd[\"Title\"] = d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).apply(\n    lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")\ntest_data = dict(age=d.Age.pipe(lambda x: (x - age_mean) \/ age_std).values,\n                 pclass=d.Pclass.values - 1,\n                 title=d.Title.astype(title_cat).cat.codes.values,\n                 sex=(d.Sex == \"male\").astype(int).values,\n                 sibsp=d.SibSp.clip(0, 1).values,\n                 parch=d.Parch.clip(0, 2).values,\n                 embarked=d.Embarked.astype(embarked_cat).cat.codes.values)\n\nposterior = mcmc.get_samples().copy()\nposterior.pop(\"age_impute\")\nsurvived_probs = Predictive(model, posterior).get_samples(random.PRNGKey(2), **test_data)[\"probs\"]\nd[\"Survived\"] = (survived_probs.mean(axis=0) >= 0.5).astype(np.uint8)\nd[[\"PassengerId\", \"Survived\"]].to_csv(\"submission.csv\", index=False)","32734a7e":"### make predictions","c66cc2e1":"### modelling","6776ec62":"### sampling","c03a62cb":"### further improvements\n\n+ Using other features such as `Cabin` or `Fare`.\n+ The above model assumes a linear relationship of `Survived` w.r.t. other latent variables. The result is intuitive but is not enough to beat tree-based models. We can build more complicated models or construct a [Bayesian neural network](http:\/\/pyro.ai\/numpyro\/bnn.html) model to capture more complex relationship.","07878ec2":"Note that I don't use other features such as `Fare` or `Cabin` for simplicity. I also don't do much of feature engineering for the same reason.","22cd3760":"In this notebook, we will do logistic regression to predict `Survived` using `Age` variable. For simplicity, I'll skip EAD part (which has been nicely done in many other popular kernels). I'll use [NumPyro](https:\/\/github.com\/pyro-ppl\/numpyro) for modelling, sampling, and making predictions.","a4ac35b7":"To make predictions on the new data, we will maginalize those `age_imput` variables (in other words, removing them from posterior samples) and use the remaining variables for predictions.","b9370233":"Submiting the result gives me the score about 79 (top 16%). It is great for the first attempt. :)","602a3a5e":"As we can see, using Bayesian, we can get uncertainties of our results: e.g. imputing values, coefficients of being male or female,... (and you can make nice plots with them ;)","b931c24a":"### prepare data","6c398b77":"If you are not familiar with NumPyro, you can take a look at [its documentation](https:\/\/github.com\/pyro-ppl\/numpyro#numpyro) which includes some tutorials, examples, and translated code for Statistical Rethinking book (which is a good reference IMO if you are not familiar with Bayesian methods).","5bb51947":"After loading data, I recognize that there are many missing values for `Age` column. We know (by intuition or from other kernels) that `Age` is correlated with the title of the name: e.g. those with `Mrs.` would be older than those with `Miss.`. Let's make a new column `Title` for that purpose.","3f1ca309":"After making a model, sampling is pretty fast in NumPyro."}}