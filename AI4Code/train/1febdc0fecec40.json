{"cell_type":{"bda027f2":"code","1523b3ef":"code","322daf2e":"code","8cfb992a":"code","1812f136":"code","094cebf0":"code","904453a3":"code","9bd8dd07":"code","4e6ed1c0":"code","37d5a608":"code","555bec2c":"code","2c3ea7f6":"code","ae6634d5":"code","8024ca68":"code","7f4df5b5":"code","8495eaec":"code","96bc7f0c":"code","cc461660":"code","fe274912":"code","ae72af39":"code","7a0a9fcc":"code","2a3f999c":"markdown","03365707":"markdown","04041a32":"markdown"},"source":{"bda027f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1523b3ef":"# Reading files from directory\nimport os\nimport pickle\n \n# Data manipulation & analysis\nimport pandas as pd\npd.set_option('display.max_columns',100)\npd.set_option('display.max_rows', 500)\nimport datetime as dt\n \nimport numpy as np\nimport scipy\n\n# Visualisation\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n \n # \u5b9f\u884c\u306b\u95a2\u4fc2\u306a\u3044\u8b66\u544a\u3092\u7121\u8996\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm\nimport gc\nimport json\nimport math\n\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import accuracy_score,roc_auc_score\n\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\n\nfrom lightgbm import LGBMClassifier\nimport lightgbm\n","322daf2e":"#\u5b9f\u884c\u74b0\u5883\u304c\u3069\u3053\u306e\u968e\u5c64\u306b\u3042\u308b\u304b\u3001\u30d1\u30b9\u3092\u691c\u7d22\nimport os\nprint(os.getcwd())","8cfb992a":"train = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")","1812f136":"display(train.head())\ndisplay(train.describe())\ndisplay(train.info())","094cebf0":"train.columns","904453a3":"#--------------------------------\n#\u6570\u5024\u306e\u7279\u5fb4\u91cf\u3000\u203b\u4e0a\u7d1a\u8005\u306f\u3001\u7279\u5fb4\u91cf\u306e\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\u3057\u3066\u3044\u308b\u3002\n#------------------------------\nfeatures_num = ['Age', 'Fare','SibSp','Parch', 'Pclass',]\nfeatures_cat = ['Sex','Embarked' ] \nfeatures_str = ['Name','Ticket','Cabin']\nfeatures_all = features_num + features_cat + features_str\n\n# Update numeric cols as float\ntrain[features_num] = train[features_num].astype(np.float64)\ntest[features_num] = test[features_num].astype(np.float64)\n\n# Update categorical cols as categories\ntrain[features_cat] = train[features_cat].astype('category')\ntest[features_cat] = test[features_cat].astype('category')\n","9bd8dd07":"#\u76f8\u95a2\u4fc2\u6570\u3092\u5b9a\u7fa9\ncorr_pearson = train[features_all].corr(method='pearson')\ncorr_spearman =train[features_num].corr(method='spearman')","4e6ed1c0":"fig = plt.figure(figsize = (12,9))\nsns.heatmap(corr_pearson, annot=True, cmap='coolwarm', vmin=-1, vmax=+1, fmt=\"1.1f\")\nplt.title('Pearson Correlation')\nplt.show()","37d5a608":"#\u7279\u5fb4\u91cf\u4f5c\u6210\u306e\u305f\u3081\u306b\u30c7\u30fc\u30bf\u3092\u7d50\u5408\ndf_data = pd.concat([train, test], sort=False)\ndf_data","555bec2c":"#complete sex with mode\ndf_data['Sex'].fillna(df_data['Sex'].mode()[0], inplace = True)\n\n\n# Age fillna with mean age for each class\ndf_data['Age'] = df_data['Age'].fillna(df_data['Age'].mean())\n\n# Cabin, fillna with 'X' and take first letter \u5148\u982d\u6587\u5b57\u306b\u3059\u308b\u3000NaN\u306fX\u3068\u3059\u308b\ndf_data['Cabin'] = df_data['Cabin'].fillna('X').map(lambda x: x[0].strip())\n\n# Ticket, fillna with 'X', split string and take first split   \u5148\u982d\u6587\u5b57\u306b\u3059\u308b\u3000NaN\u306fX\u3068\u3059\u308b\ndf_data['Ticket'] = df_data['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n# Fare, fillna with mean value\nfare_map = df_data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\ndf_data['Fare'] = df_data['Fare'].fillna(df_data['Pclass'].map(fare_map['Fare']))\ndf_data['Fare'] = np.log1p(df_data['Fare'])\n\n# Embarked, fillna with 'X' value\n\ndf_data['Embarked'].fillna(df_data['Embarked'].mode()[0], inplace = True)##\u6700\u983b\u5024\n\n# Name, take only surnames \u3000NaN\u306fX\u3068\u3059\u308b\ndf_data['Name'] = df_data['Name'].map(lambda x: x.split(',')[0])","2c3ea7f6":"\n##--------------------------------------------\n#\u30ab\u30c6\u30b4\u30eafeature  \u3000\u30e9\u30d9\u30eb\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\n#---------------------------------------------\nfor feature in features_str :\n    le = LabelEncoder()\n    le.fit(df_data[feature])\n    df_data[feature] = le.transform(df_data[feature])\n\n\n##--------------------------------------------\n#\u30ab\u30c6\u30b4\u30eafeature  \u3000one-hot\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\n#---------------------------------------------\n\ndf_data = pd.get_dummies(df_data, columns= features_cat )\n\n\n##--------------------------------------------\n#\u6a19\u6e96\u5316\u30b9\u30b1\u30fc\u30e9\u30fc\n#---------------------------------------------\n\nsc = StandardScaler()\ndf_data[features_num] = sc.fit_transform(df_data[features_num])","ae6634d5":"#\u7279\u5fb4\u91cf\u4f5c\u6210\u5f8c\u306b\u3001train_x  , test_x \u5143\u306b\u30c7\u30fc\u30bf\u5f62\u72b6\u306b\u623b\u3059\n#df_data\u3092df_train\u306e\u9577\u3055\u3067\u5207\u308a\u3001\u305d\u308c\u4ee5\u964d\u3067\u30c7\u30fc\u30bf\u3092\u5206\u3051\u308b\n \ntrain = df_data[:len(train)]\ntest = df_data[len(train):]","8024ca68":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3092\u7279\u5fb4\u91cf\u3068\u76ee\u7684\u5909\u6570\u306b\u5206\u3051\u308b  \u6b63\u89e3\u30e9\u3079\u30eb\u3092\u8a18\u5165\ntrain_x = train.drop(['Survived'], axis=1)\ntrain_y = train['Survived']\n \n# \u7279\u5fb4\u91cf\u3067\u7d50\u5408\u3057\u3066\u6f14\u7b97\u3057\u3066\u3044\u308b\u3068\u6b63\u89e3\u30e9\u30d9\u30eb\u306bNaN\u304c\u5165\u308b\u3053\u3068\u304c\u3042\u308b\u306e\u3067\u524a\u9664\u3059\u308b\n#test_x = test\ntest_x = test.drop(['Survived'], axis=1)","7f4df5b5":"# \u5909\u6570PassengerId\u3092\u9664\u5916\u3059\u308b\ntrain_x = train_x.drop(['PassengerId'], axis=1)\ntest_x = test_x.drop(['PassengerId',], axis=1)\n","8495eaec":"import optuna.integration.lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\ndef build():\n\n    # \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5206\u5272\u65b9\u6cd5\n    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n    # LightGBM\u7528\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u5909\u63db\n    dtrain = lgb.Dataset(train_x, label=train_y)\n\n\n    # \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30b5\u30fc\u30c1&\u30e2\u30c7\u30eb\u69cb\u7bc9\n    params =  {'objective': 'binary',\n              'metric':'binary_logloss',\n              'random_seed':71,\n              } \n\n    # \u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306b\u3088\u308b\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u63a2\u7d22 5fold\n    best_params = {}\n    tuner = lgb.LightGBMTunerCV(params, dtrain,\n                                verbose_eval=False, \n                                num_boost_round=10000,\n                                early_stopping_rounds=100, \n                                folds=folds,\n                               )\n\n\n    # \u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u63a2\u7d22\u306e\u5b9f\u884c\n    tuner.run()\n\n    # \u30b5\u30fc\u30c1\u3057\u305f\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8868\u793a\n    best_score = tuner.best_score\n    best_params = tuner.best_params\n    \n    print(\"  Params: \")\n    for key, value in best_params.items():\n        print(\"   {}: {}\".format(key, value))\n\n    return tuner\ntuner = build()","96bc7f0c":"##############################\n#######     LGBMClassifier by tunner\n################################\n\ntrain_oof_lgbm_0 = np.zeros((train_x.shape[0],))\ntest_preds_lgbm_0 = 0\n\nlgbm_params= tuner.best_params\n#lgbm_params={\n#    'objective': 'binary',\n #   'metric': 'binary_logloss',\n  #  'random_seed': 71,\n   # 'feature_pre_filter': False,\n    #'lambda_l1': 8.365958995688352,\n#    'lambda_l2': 0.03664386468415251,\n #   'num_leaves': 31,\n  #  'feature_fraction': 0.6,\n   # 'bagging_fraction': 1.0,\n#    'bagging_freq': 0,\n #   'min_child_samples': 20,}\n\n\nNUM_FOLDS = 5\nkf =  StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\nevaluation_results = {}  \nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train_x, train_y))):\n        print(f'Fold {f+1}')\n        train_df, val_df = train_x.iloc[train_ind], train_x.iloc[val_ind]\n        train_target, val_target = train_y.iloc[train_ind], train_y.iloc[val_ind]\n                \n        model = LGBMClassifier(**lgbm_params)\n\n\n        model =  model.fit(train_df, train_target,\n                           eval_set=[(val_df,val_target)],\n                           early_stopping_rounds=200,verbose=\"false\" )\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(test_x)[:,1]\n\n        train_oof_lgbm_0[val_ind] = temp_oof\n        test_preds_lgbm_0 += temp_test\/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))\n        \nprint(roc_auc_score(train_y, train_oof_lgbm_0))\nnp.save('train_oof_lgbm_0', train_oof_lgbm_0 ) #for validation\nnp.save('test_preds_lgbm_0',test_preds_lgbm_0 ) #for submission\n","cc461660":"pred_label = test_preds_lgbm_0\npred_label = np.where(pred_label>0.5, 1, 0)\npred_label","fe274912":"##### \u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210 \u30d8\u30c3\u30c0\u30fc\u7121\u8a2d\u306e\u8a2d\u5b9a\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})\nsubmission.to_csv('submission_test.csv', index=False)\n\ndisplay(submission.head(), submission.tail())","ae72af39":"for dirname, _, filenames in os.walk('.\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7a0a9fcc":"# importance\u3092\u8868\u793a\u3059\u308b\nplt.rcParams[\"figure.figsize\"] = (10, 5)\nlightgbm.plot_importance(model,max_num_features = 25,height=.8)","2a3f999c":"![\u30ad\u30e3\u30d7\u30c1\u30e32.PNG](attachment:609aa46b-b91d-42d9-97d3-833250f38800.PNG)","03365707":"![\u30ad\u30e3\u30d7\u30c1\u30e3.PNG](attachment:41cfa1e9-509b-47ad-b8b0-5601406b97c1.PNG)","04041a32":"The first step in kaggle is to get better results in an easy way.\n\nKaggle\u306e\u7b2c\u4e00\u6b69\u306f\u697d\u306f\u65b9\u6cd5\u3067\u3088\u308a\u826f\u3044\u7d50\u679c\u3092\u3048\u308b\u3053\u3068\u304c\u91cd\u8981\u3067\u3059\u3002\n\nLightGBMTunerCV\u3000is a very good tool because everything(LGBM + CV + Quickly optimisation) is one package.\n\nLightGBMTunerCV\u306f\u5168\u3066\u304c\u4e00\u3064\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u306a\u308a\u3068\u3066\u3082\u826f\u3044\u30c4\u30fc\u30eb\u306e\u4e00\u3064\u3067\u3059\u3002\n\nI recommend that you use this Easy-Way study for your next\u3000deep exploration.\n\n\u3053\u306e\u65b9\u6cd5\u3092\u4f7f\u3063\u3066\u6b21\u306e\u6df1\u3044\u63a2\u7d22\u3092\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\n\nDon't forget to vote !!"}}