{"cell_type":{"34a848b4":"code","a48fd104":"code","6ea4e5c0":"code","b1a7e928":"code","a12e07bd":"code","0adf6bc6":"code","ce36221e":"code","dbded150":"code","b060f3e4":"code","d42387b4":"code","c586ff2a":"code","b5f295ea":"code","3b17cb37":"code","42dddc53":"code","6d2bd317":"code","917dfd2a":"code","bbbe55a4":"code","854f0ec3":"code","8fc36a58":"code","74db1715":"code","ea362cb3":"code","579516dc":"code","e2897833":"code","481e6b74":"code","80984718":"code","8d835f10":"code","9cab8ed5":"code","5eef8783":"code","7c59881c":"code","0ae77222":"code","b5429fab":"code","88c5c4b5":"code","704170eb":"code","6e82cbc4":"code","b21d61f8":"code","60736aed":"code","59c4c2b0":"code","eed2584f":"code","02db6e75":"code","6092ed9b":"code","9f9da7d4":"code","48d9c736":"code","dd62383f":"code","488df71d":"code","e56c0acf":"code","9cac4996":"code","b0c30bed":"code","d9fbfa10":"code","38b163c8":"code","195d7562":"code","380c3529":"code","88eaaefd":"code","f5ec32c8":"code","566ab1f1":"code","c4b4c2d3":"code","a0640721":"code","ce29a981":"code","82c87500":"code","932dd35e":"code","29bbc27f":"code","90ca8c70":"code","0c2838a9":"code","13c737e2":"code","78afacf5":"code","ae7f723d":"code","81444020":"code","f0b551db":"code","9b8fd958":"code","4c26ae34":"code","d3e7f596":"code","28de0e35":"code","b3469078":"code","e0f49c7f":"code","391f541b":"code","7cdbc9be":"code","101a5fab":"code","cad42f1a":"markdown","9353077e":"markdown","15e840aa":"markdown","aff99967":"markdown","f903f495":"markdown","5b58442d":"markdown","f98f19b9":"markdown","5a720fae":"markdown","a6afd2e7":"markdown","810e5ee4":"markdown","63170ae2":"markdown","8b43cb45":"markdown","7efe18a2":"markdown","0b518887":"markdown","d2f25fab":"markdown","a30bb2c6":"markdown","c4f409c1":"markdown","8822daa0":"markdown","49e9e821":"markdown","1ac04843":"markdown","d2e897f6":"markdown","7ac48267":"markdown"},"source":{"34a848b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a48fd104":"import pandas as pd\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt","6ea4e5c0":"train_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\n# combined train and test datasets\ntotal_data = pd.concat([train_data,test_data],axis=0)","b1a7e928":"train_data.head()","a12e07bd":"train_data.shape","0adf6bc6":"train_data.info()","ce36221e":"train_dtype = train_data.dtypes\ntrain_dtype.value_counts()","dbded150":"train_data.isnull().sum().sort_values(ascending = False)","b060f3e4":"(train_data.isnull().sum()\/len(train_data)*100).sort_values(ascending = False)\n","d42387b4":"fig, ax = plt.subplots(figsize=(7,7)) \n\nsb.heatmap(train_data.isnull(), yticklabels = False, cbar = False )","c586ff2a":"test_data.head()","b5f295ea":"test_data.shape","3b17cb37":"test_data.info()","42dddc53":"test_dtype = test_data.dtypes\ntest_dtype.value_counts()","6d2bd317":"test_data.isnull().sum().sort_values(ascending = False)","917dfd2a":"(test_data.isnull().sum()\/len(test_data)*100).sort_values(ascending = False)\n\n","bbbe55a4":"fig, ax = plt.subplots(figsize=(7,7)) \n\nsb.heatmap(test_data.isnull(), yticklabels = False, cbar = False )","854f0ec3":"total_data = pd.concat([train_data,test_data],axis=0)","8fc36a58":"## Here we will check the percentage of nan values present in each feature\n## 1 -step make the list of features which has missing values\nfeatures_with_na=[features for features in total_data.columns if total_data[features].isnull().sum()>1]\n## 2- step print the feature name and the percentage of missing values\n\nfor feature in features_with_na:\n    print(feature, np.round(total_data[feature].isnull().mean(), 4),  ' % missing values')","74db1715":"for feature in features_with_na:\n    data = total_data.copy()\n    \n    # let's make a variable that indicates 1 if the observation was missing or zero otherwise\n    data[feature] = np.where(data[feature].isnull(), 1, 0)\n    \n    # let's calculate the mean SalePrice where the information is missing or present\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","ea362cb3":"\ncat_data = total_data.select_dtypes(exclude=np.number)\nnum_data = total_data.select_dtypes(include=np.number)","579516dc":"# list of variables that contain year information\nyear_feature = [feature for feature in num_data if 'Yr' in feature or 'Year' in feature]\n\nyear_feature\n","e2897833":"## Lets analyze the Temporal Datetime Variables\n## We will check whether there is a relation between year the house is sold and the sales price\n\ntotal_data.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Median House Price')\nplt.title(\"House Price vs YearSold\")","481e6b74":"## Here we will compare the difference between All years feature with SalePrice\n\nfor feature in year_feature:\n    if feature!='YrSold':\n        data=total_data.copy()\n        ## We will capture the difference between year variable and year the house was sold for\n        data[feature]=data['YrSold']-data[feature]\n\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()\n","80984718":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature=[feature for feature in num_data if len(total_data[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","8d835f10":"discrete_feature","9cab8ed5":"## Lets Find the realtionship between them and Sale PRice\n\nfor feature in discrete_feature:\n    data=total_data.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","5eef8783":"continuous_feature=[feature for feature in num_data if feature not in discrete_feature+year_feature+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","7c59881c":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\nfor feature in continuous_feature:\n    data=total_data.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","0ae77222":"f, axes = plt.subplots(7,6 , figsize=(30, 30), sharex=False)\nfor i, feature in enumerate(num_data):\n    sb.scatterplot(data=total_data, x = feature, y= \"SalePrice\",ax=axes[i%7, i\/\/7])\n","b5429fab":"total_data.shape","88c5c4b5":"total_data.isnull().sum()\/len(total_data)*100","704170eb":"total_data = total_data.drop(columns = ['PoolQC','MiscFeature','Alley','Fence',\"LotFrontage\", \"FireplaceQu\",'Id'])","6e82cbc4":"total_data.shape","b21d61f8":"total_data","60736aed":"cat_data = total_data.select_dtypes(exclude=np.number)\nnum_data = total_data.select_dtypes(include=np.number)","59c4c2b0":"num_data.isnull().sum()","eed2584f":"total_data['MSZoning'] = total_data['MSZoning'].fillna(total_data['MSZoning'].mode()[0])","02db6e75":"total_data['Utilities'] = total_data['Utilities'].fillna(total_data['Utilities'].mode()[0])\ntotal_data['Exterior1st'] = total_data['Exterior1st'].fillna(total_data['Exterior1st'].mode()[0])\ntotal_data['Exterior2nd'] = total_data['Exterior2nd'].fillna(total_data['Exterior2nd'].mode()[0])\ntotal_data['MasVnrType'] = total_data['MasVnrType'].fillna(total_data['MasVnrType'].mode()[0])\ntotal_data['BsmtQual'] = total_data['BsmtQual'].fillna(total_data['BsmtQual'].mode()[0])\ntotal_data['BsmtCond'] = total_data['BsmtCond'].fillna(total_data['BsmtCond'].mode()[0])\ntotal_data['BsmtExposure'] = total_data['BsmtExposure'].fillna(total_data['BsmtExposure'].mode()[0])\ntotal_data['BsmtFinType1'] = total_data['BsmtFinType1'].fillna(total_data['BsmtFinType1'].mode()[0])\ntotal_data['BsmtFinType2'] = total_data['BsmtFinType2'].fillna(total_data['BsmtFinType2'].mode()[0])\ntotal_data['Electrical'] = total_data['Electrical'].fillna(total_data['Electrical'].mode()[0])\ntotal_data['KitchenQual'] = total_data['KitchenQual'].fillna(total_data['KitchenQual'].mode()[0])\ntotal_data['Functional'] = total_data['Functional'].fillna(total_data['Functional'].mode()[0])\ntotal_data['GarageType'] = total_data['GarageType'].fillna(total_data['GarageType'].mode()[0])\ntotal_data['GarageFinish'] = total_data['GarageFinish'].fillna(total_data['GarageFinish'].mode()[0])\ntotal_data['GarageQual'] = total_data['GarageQual'].fillna(total_data['GarageQual'].mode()[0])\ntotal_data['GarageCond'] = total_data['GarageCond'].fillna(total_data['GarageCond'].mode()[0])\ntotal_data['SaleType'] = total_data['SaleType'].fillna(total_data['SaleType'].mode()[0])\n\n","6092ed9b":"total_data['MasVnrArea'] = total_data['MasVnrArea'].fillna(total_data['MasVnrArea'].mean())\ntotal_data['MBsmtFinSF1'] = total_data['BsmtFinSF1'].fillna(total_data['BsmtFinSF1'].mean())\ntotal_data['BsmtFinSF2'] = total_data['BsmtFinSF2'].fillna(total_data['BsmtFinSF2'].mean())\ntotal_data['BsmtUnfSF'] = total_data['BsmtUnfSF'].fillna(total_data['BsmtUnfSF'].mean())\ntotal_data['TotalBsmtSF'] = total_data['TotalBsmtSF'].fillna(total_data['TotalBsmtSF'].mean())\ntotal_data['BsmtFullBath'] = total_data['BsmtFullBath'].fillna(total_data['BsmtFullBath'].mean())\ntotal_data['BsmtHalfBath'] = total_data['BsmtHalfBath'].fillna(total_data['BsmtHalfBath'].mean())\ntotal_data['GarageYrBlt'] = total_data['GarageYrBlt'].fillna(total_data['GarageYrBlt'].mean())\ntotal_data['GarageCars'] = total_data['GarageCars'].fillna(total_data['GarageCars'].mean())\ntotal_data['GarageArea'] = total_data['GarageArea'].fillna(total_data['GarageArea'].mean())","9f9da7d4":"total_data.shape","48d9c736":"total_data.isnull().sum()","dd62383f":"cat_data = total_data.select_dtypes(exclude=np.number)\nnum_data = total_data.select_dtypes(include=np.number)\nprint(num_data.shape)\nprint(cat_data.shape)","488df71d":"num_data = num_data.drop(['SalePrice'],axis = 1)","e56c0acf":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nnum_data_sc=sc.fit_transform(num_data)\n\nnum_data_sc=pd.DataFrame(num_data_sc,columns=num_data.columns)\nnum_data_sc.head(2)","9cac4996":"num_data_sc.shape","b0c30bed":"for i in cat_data:\n    print(cat_data[i].value_counts())","d9fbfa10":"for feature in cat_data:\n    labels_ordered=total_data.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    cat_data[feature]=total_data[feature].map(labels_ordered)","38b163c8":"cat_data.head(2)","195d7562":"print(cat_data.shape)\nnum_data_sc.shape","380c3529":"num_data_sc = num_data_sc.reset_index()\ncat_data = cat_data.reset_index()\nfinal_data=pd.concat([num_data_sc,cat_data],axis=1)","88eaaefd":"final_data = final_data.drop(['index'],axis = 1)\nfinal_data.head(2)","f5ec32c8":"import seaborn as sb\nimport matplotlib.pyplot as plt\n\nfor i in final_data.columns:\n    sb.boxplot(x=final_data[i])\n    plt.show()","566ab1f1":"for i in final_data.columns:\n    q1=final_data[i].quantile(0.25)\n    q3=final_data[i].quantile(0.75)\n    iqr=q3-q1\n    ub=q3 + 1.5*iqr\n    lb=q1 - 1.5*iqr\n    uc=final_data[i].quantile(0.99)\n    lc=final_data[i].quantile(0.01)\n    for ind1 in final_data[i].index:\n        if final_data.loc[ind1,i]>ub:\n            final_data.loc[ind1,i]=uc\n        if (final_data.loc[ind1,i]<lb):\n            final_data.loc[ind1,i]=lc","c4b4c2d3":"import seaborn as sb\nimport matplotlib.pyplot as plt\nfor i in final_data.columns:\n    sb.boxplot(x=final_data[i])\n    plt.show()","a0640721":"final_data.fillna(-999, inplace=True)\n","ce29a981":"total_data.fillna(-999,inplace=True)","82c87500":"inp_s = final_data\nout_s = total_data['SalePrice']","932dd35e":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\n\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(inp_s, out_s,test_size = 0.5, random_state = 48)\n\nprint(xtrain.shape)\nprint(xtest.shape)","29bbc27f":"from sklearn.linear_model import LinearRegression\nlreg = LinearRegression()\nlreg.fit(xtrain, ytrain)\nypred = lreg.predict(xtest)","90ca8c70":"ypred[0:5]","0c2838a9":"ytest[0:5]","13c737e2":"from sklearn.metrics import r2_score,mean_squared_error\nr2=r2_score(ytest,ypred)\nmse=mean_squared_error(ytest,ypred)\nrmse=np.sqrt(mse)\nprint('The Rsquare : ',r2)\nprint('The RMSE : ',rmse)","78afacf5":"from sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\nrf.fit(xtrain,ytrain)\nypred=rf.predict(xtest)","ae7f723d":"ypred","81444020":"ytest","f0b551db":"from sklearn.ensemble import AdaBoostRegressor\nada=AdaBoostRegressor()\nada.fit(xtrain,ytrain)\nypred=ada.predict(xtest)","9b8fd958":"from sklearn.ensemble import GradientBoostingRegressor\ngrad=GradientBoostingRegressor()\ngrad.fit(xtrain,ytrain)\nypred=grad.predict(xtest)","4c26ae34":"from xgboost import XGBRegressor\nxgb=XGBRegressor()\nxgb.fit(xtrain,ytrain)\nypred=xgb.predict(xtest)","d3e7f596":"ypred","28de0e35":"ytest","b3469078":"clf1=LinearRegression()\nclf2=RandomForestRegressor(random_state=48)\nclf3=AdaBoostRegressor(random_state=48)\nclf4=GradientBoostingRegressor(random_state=48)\nclf5=XGBRegressor(random_state=48)","e0f49c7f":"clf=[clf1,clf2,clf3,clf4,clf5] # Creating list\nname=['LinR','RF','AdaB','Grad','XGB']\nfor i,j in zip(clf,name):\n    x=i\n    x.fit(xtrain,ytrain)\n    ypred=x.predict(xtest)\n    r2=r2_score(ytest,ypred)\n    mse=mean_squared_error(ytest,ypred)\n    rmse=np.sqrt(mse)\n    print(j,r2,rmse)","391f541b":"from sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor()\nrf.fit(xtrain,ytrain)\nypred=rf.predict(xtest)","7cdbc9be":"ypred","101a5fab":"pred = pd.DataFrame(ypred)\nsub_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\ndatasets = pd.concat([sub_df['Id'],pred],axis = 1)\ndatasets.columns = ['Id','SalePrice']\ndatasets.to_csv('sample_submission_csv',index = False)","cad42f1a":"## Here we are performing some EDA techniques ##","9353077e":"### Dividing into train and test ###","15e840aa":"## Droping the columns with % greater than 50% ##","aff99967":"### Applying Standard scalar on Numerical columns ###","f903f495":"### Joining both the num_data and cat_Data ###","5b58442d":"## outliers are removed ##","f98f19b9":"### Filling the missing values with mean(for numerical values) and mode (for categorial values) imputation ###","5a720fae":"### Dropping the SalePrice column as we need not to apply scaling and other transformations on it ###","a6afd2e7":"### If you find this notebook useful,don't forget to \"UPVOTE\"\ud83d\udc4f ###\n","810e5ee4":"## 2. Load Datasets ##\n","63170ae2":"## Temporal Variables(Eg: Datetime Variables) ##","8b43cb45":"## 1. Install & Import Libraries ##","7efe18a2":"### Missing Value Treatment is done ###","0b518887":"## Dividing data into input and output ##","d2f25fab":"#### Using Capping Technique to remove outliers ###","a30bb2c6":"## Checking for outliers ##","c4f409c1":"## Since they are many missing values, we need to find the relationship between missing values and Sales Price ##\n","8822daa0":"### Missing value Treatment ###","49e9e821":"### Applying different regression models to predict the output ###","1ac04843":"## 3. Exploratory Data Analysis ##\n### 3.1. Train Data Exploration ###\n### For both train and test dataset, We'll explore following things ###\n\n ### First 5 rows ###\n### Data shape ###\n### Data information ###\n### Data types ###\n### Null value ###","d2e897f6":"### Diving the data into numerical and categorial ###","7ac48267":"### Applying encoding techniques on the categorial data ###"}}