{"cell_type":{"b5f03b85":"code","7470bce3":"code","cf14a009":"code","17e37440":"code","63a2ee99":"code","878d4a60":"code","dd839f88":"code","018bffbb":"code","cab4bafd":"code","8c131f81":"code","903d35a0":"code","d55c86d2":"code","e3213de6":"code","4d670202":"code","dc9c2273":"code","06308cdd":"code","e63d30a1":"code","b8445377":"code","8f320a86":"code","23a6d9b7":"code","b19c2af6":"code","39ea72cf":"code","b25d2789":"code","8c16879f":"code","fecab66d":"code","27370f28":"code","af3f2130":"code","8971957c":"code","288eccdb":"code","3bc5d8b5":"code","722e7468":"code","41a0f61e":"code","e4703b5a":"code","70496bce":"code","08f2a58b":"code","f6574d58":"code","0db0d689":"code","95018256":"code","f386955c":"code","d530a1c3":"code","c25f6650":"code","7db97132":"code","f824f9bf":"code","bb8e81a2":"code","8d4f9fb4":"code","4ca248c1":"code","1ed2368e":"markdown","c4201c5a":"markdown","073feb3a":"markdown"},"source":{"b5f03b85":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7470bce3":"# Import train & test Data\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ngender_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","cf14a009":"train.head()","17e37440":"train.info()","63a2ee99":"test.info()","878d4a60":"dataset=[train,test]","dd839f88":"train['Cabin'].unique()","018bffbb":"len(train['Ticket'].unique())","cab4bafd":"for data in dataset:\n    data['lastname']=data['Name'].apply(lambda x: x.split(',')[0])","8c131f81":"len(train['lastname'].unique())","903d35a0":"count=0\nlastnamerecorder=[]\nfor i in range(train.shape[0]):\n    if( train['lastname'][i] not in lastnamerecorder):\n        count=count+1+train['SibSp'][i]+train['Parch'][i]\n        lastnamerecorder.append(train['lastname'][i])\nprint(count)","d55c86d2":"lastname_cabin={}\nfor i in range(train.shape[0]):\n    if( train['lastname'][i] not in lastname_cabin.keys() and train['Cabin'][i]==train['Cabin'][i] ):\n        lastname_cabin[train['lastname'][i]]=[train['Cabin'][i]]\n    elif(train['lastname'][i] in lastname_cabin.keys() and train['Cabin'][i]==train['Cabin'][i] ):\n        if(train['Cabin'][i] not in lastname_cabin[train['lastname'][i]] ):\n            lastname_cabin[train['lastname'][i]].append(train['Cabin'][i])","e3213de6":"len(lastname_cabin.keys())","4d670202":"class_cabin={}\nfor i in range(train.shape[0]):\n    if( train['Pclass'][i] not in class_cabin.keys() and train['Cabin'][i]==train['Cabin'][i] ):\n        class_cabin[train['Pclass'][i]]=[train['Cabin'][i]]\n    elif(train['Pclass'][i] in class_cabin.keys() and train['Cabin'][i]==train['Cabin'][i] ):\n        if(train['Cabin'][i] not in class_cabin[train['Pclass'][i]] ):\n            class_cabin[train['Pclass'][i]].append(train['Cabin'][i])\nclass_cabin","dc9c2273":"train.groupby(['Pclass']).count()","06308cdd":"for data in dataset:\n    data[\"cabin\"]=data['Cabin'].apply(lambda x: x[0] if x==x else x)","e63d30a1":"train['cabin']","b8445377":"d=['X','A','B','C','D','E','F','G']\n","8f320a86":"for data in dataset:\n    for i in range(data.shape[0]):\n        if(data['Pclass'][i]==1 and data[\"cabin\"][i]!=data[\"cabin\"][i]):\n            data['cabin'][i]=d[np.random.choice(np.arange(1, 6), p=[0.3,0.3,0.2,0.15,0.05])]\n        elif(data['Pclass'][i]==2 and data[\"cabin\"][i]!=data[\"cabin\"][i]):\n            data['cabin'][i]=d[np.random.choice(np.arange(4, 7), p=[0.4,0.3,0.3])]\n        elif(data['Pclass'][i]==3 and data[\"cabin\"][i]!=data[\"cabin\"][i]):\n            data['cabin'][i]=d[np.random.choice(np.arange(5, 8), p=[0.3,0.4,0.3])]","23a6d9b7":"train['cabin']","b19c2af6":"sns.countplot(x='cabin',hue='Survived' ,data=train)","39ea72cf":"sns.countplot(x='Pclass',hue='Survived' ,data=train)","b25d2789":"for data in dataset:\n    data['Age']=data['Age'].fillna(data['Age'].mean())","8c16879f":"train","fecab66d":"test=test.drop([\"Cabin\"], axis=1)\ntrain=train.drop([\"Cabin\"], axis=1)","27370f28":"test.info()","af3f2130":"for data in dataset:\n    data['family']=data['Parch']+data['SibSp']","8971957c":"train.info()","288eccdb":"columns=['PassengerId','Name','Ticket','lastname']\ntrain=train.drop(columns,axis=1)\ntest1=test.drop(columns, axis=1)","3bc5d8b5":"train.info()","722e7468":"train.info()","41a0f61e":"train=pd.get_dummies(train)\ntest1=pd.get_dummies(test1)","e4703b5a":"train","70496bce":"X=train.drop(['Survived'],axis=1)\n\nY=train['Survived']","08f2a58b":"train.info()","f6574d58":"from sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size = 0.3, random_state = 42)","0db0d689":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\n# Train the model on training data\nrf.fit(train_features, train_labels);","95018256":"predictions = rf.predict(test_features)","f386955c":"predictions","d530a1c3":"from sklearn.metrics import accuracy_score\naccuracy_score(test_labels, predictions)","c25f6650":"test1=test1.fillna(test1['Fare'].mean())","7db97132":"test1.info()","f824f9bf":"test1['cabin_T']=0","bb8e81a2":"predictions = rf.predict(test1)","8d4f9fb4":"test['Survived']=predictions","4ca248c1":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('Titanic_submission.csv', index=False)","1ed2368e":"Lots of empty values in the cabin and age trying to fill the empty values based on lastname as there is a high possibility that family members will stay in the same cabin","c4201c5a":"Based on the above count we can assume that there are 667 different families in the ship but after count siblings and relations in each family we got a count of 973 but the total count is 891 in the ship which means that 81 people out of all the these families have not boarded the ship","073feb3a":"From the above two figures (681,667) we can assume that every family has close to one unique ticket"}}