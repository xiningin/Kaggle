{"cell_type":{"13c72a38":"code","76e0461a":"code","73015393":"code","a422be04":"code","5ee43abf":"code","85828ed1":"code","4806cb74":"code","3794f9fc":"code","814694da":"code","1f9829e3":"code","f1604690":"code","3647a48d":"code","ad1e43fc":"code","af6fcfff":"code","7a556e3c":"code","b0e7a8f2":"code","fe60d70c":"code","1b495da2":"code","05d73d2b":"code","2161bc3f":"code","06d091a0":"code","41dcc934":"code","18272740":"code","12f26853":"code","beba7bbb":"code","50f8684f":"code","1711e901":"code","eef2a43b":"code","70cbf269":"code","50bb8b38":"markdown","8e82ede1":"markdown","417d41d5":"markdown","54e2fca4":"markdown","9f1144f4":"markdown","1b95732e":"markdown","7ccde50c":"markdown","b5e91084":"markdown","b8093a82":"markdown","58987b95":"markdown","5c622f75":"markdown","ba6984a5":"markdown","0bc20d4d":"markdown","ee4ec371":"markdown","51bdc81d":"markdown","b0c56b01":"markdown","cfb3b79b":"markdown","e30d66ca":"markdown","90795663":"markdown"},"source":{"13c72a38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 # opencv\n#from mtcnn.mtcnn import MTCNN\nfrom matplotlib import pyplot as plt\nfrom keras.models import load_model\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","76e0461a":"# extract a single face from a given photograph\ndef extract_face(filename, required_size=(160, 160)):\n    # load image from file\n    image = Image.open(filename)\n    # convert to RGB, if needed\n    image = image.convert('RGB')\n    # convert to array\n    pixels = np.asarray(image)\n# resize pixels to the model size\n    image = Image.fromarray(pixels)\n    image = image.resize(required_size)\n    face_array = np.asarray(image)\n    return face_array","73015393":"img = extract_face('\/kaggle\/input\/masked-facerecognition\/AFDB_face_dataset\/AFDB_face_dataset\/aidai\/1_0_aidai_0003.jpg')\nplt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n#plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\nplt.show()\nprint(img.shape)","a422be04":"def load_face(dir):\n    faces = list()\n    # enumerate files\n    for filename in os.listdir(dir):\n        path = dir + filename\n        face = extract_face(path)\n        faces.append(face)\n    return faces\n\ndef load_dataset(dir):\n    # list for faces and labels\n    X, y = list(), list()\n    for subdir in os.listdir(dir):\n        path = dir + subdir + '\/'\n        faces = load_face(path)\n        labels = [subdir for i in range(len(faces))]\n        # print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n        X.extend(faces)\n        y.extend(labels)\n    return np.asarray(X), np.asarray(y)","5ee43abf":"# load train dataset\ntrainX, trainy = load_dataset('\/kaggle\/input\/masked-facerecognition\/AFDB_face_dataset\/AFDB_face_dataset\/')\nprint(trainX.shape, trainy.shape)","85828ed1":"# load test dataset\ntestX, testy = load_dataset('\/kaggle\/input\/masked-facerecognition\/AFDB_masked_face_dataset\/AFDB_masked_face_dataset\/')\nprint(testX.shape, testy.shape)","4806cb74":"# save and compress the dataset for further use\nnp.savez_compressed('new_maskes_face.npz', trainX, trainy, testX, testy)","3794f9fc":"data = np.load('\/kaggle\/input\/new-masked-face\/extracted_masked_unmasked.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)","814694da":"trainx, valid = train_test_split(trainX, test_size=0.1, random_state=42, shuffle=True)","1f9829e3":"print(\"number of image in train dataset : %s\" %(len(trainx)))\n\nprint(\"number of image in train dataset : %s\" %(len(valid)))","f1604690":"y_train, y_valid = train_test_split(trainy, test_size=0.1, random_state=42, shuffle=True)","3647a48d":"print(\"number of image in train dataset : %s\" %(len(y_train)))\n\nprint(\"number of image in train dataset : %s\" %(len(y_valid)))","ad1e43fc":"# save and compress the dataset for further use\nnp.savez_compressed('extracted_masked_unmasked.npz', trainx, y_train, valid, y_valid,testX, testy)","af6fcfff":"data = np.load('\/kaggle\/input\/new-masked-face\/extracted_masked_unmasked.npz')\ntrainx, y_train, valid, y_valid,testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']\nprint('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)","7a556e3c":"facenet_model = load_model('\/kaggle\/input\/facenet\/keras-facenet\/model\/facenet_keras.h5')\nprint('Loaded Model')","b0e7a8f2":"print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)","fe60d70c":"def get_embedding(model, face):\n    # scale pixel values\n    face = face.astype('float32')\n    # standardization\n    mean, std = face.mean(), face.std()\n    face = (face-mean)\/std\n    # transfer face into one sample (3 dimension to 4 dimension)\n    sample = np.expand_dims(face, axis=0)\n    # make prediction to get embedding\n    yhat = model.predict(sample)\n    return yhat[0]","1b495da2":"emdTrainX = list()\nfor face in trainx:\n    emd = get_embedding(facenet_model, face)\n    emdTrainX.append(emd)\nemdTrainX = np.asarray(emdTrainX)\nprint(emdTrainX.shape)\nembValid = list()\nfor face in valid:\n    emd = get_embedding(facenet_model,face)\n    embValid.append(emd)\nembValid = np.asarray(embValid)\nprint(embValid.shape)","05d73d2b":"emdTestX = list()\nfor face in testX:\n    emd = get_embedding(facenet_model, face)\n    emdTestX.append(emd)\nemdTestX = np.asarray(emdTestX)\nprint(emdTestX.shape)","2161bc3f":"# save arrays to one file in compressed format\nnp.savez_compressed('embeddings_masked.npz', emdTrainX, y_train, embValid, y_valid, emdTestX, testy)","06d091a0":"data = np.load('\/kaggle\/input\/newsst7\/embeddings_masked.npz')\nemdTrainX, y_train, embValid, y_valid, emdTestX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']","41dcc934":"print('Loaded: ', emdTrainX.shape, y_train.shape, embValid.shape, y_valid.shape, emdTestX.shape, testy.shape)","18272740":"from sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\nimport pickle\nprint(\"Dataset: train=%d,validation = %d, test=%d\" % (emdTrainX.shape[0],embValid.shape[0] ,emdTestX.shape[0]))\n# normalize input vectors\nin_encoder = Normalizer(norm='l2')\nemdTrainX_norm = in_encoder.transform(emdTrainX)\nembValid_norm = in_encoder.transform(embValid)\nemdTestX_norm = in_encoder.transform(emdTestX)\n# label encode targets\nout_encoder = LabelEncoder()\nencoder_arr = np.append (y_train, 'wangnan')\nout_encoder.fit(encoder_arr)","12f26853":"trainy_enc = out_encoder.transform(y_train)\ny_valid_enc = out_encoder.transform(y_valid)\ntesty_enc = out_encoder.transform(testy)","beba7bbb":"model = SVC(kernel='linear', probability=True)\n#model = SVC(kernel='poly', probability=True)\n#model = SVC(kernel='rbf', probability=True)\nmodel.fit(emdTrainX_norm, trainy_enc)","50f8684f":"# predict\nyhat_valid = model.predict(embValid_norm)\nyhat_test = model.predict(emdTestX_norm)\n# score\nscore_valid = accuracy_score(y_valid_enc, yhat_valid)\nscore_test = accuracy_score(testy_enc, yhat_test)\n# summarize\nprint('Accuracy: train=%.3f, test=%.3f' % (score_valid*100, score_test*100))","1711e901":"filename = 'linear.sav'\npickle.dump(model, open(filename, 'wb'))\n#filename = 'poly.sav'\n#pickle.dump(model, open(filename, 'wb'))\n#filename = 'rbf.sav'\n#pickle.dump(model, open(filename, 'wb'))","eef2a43b":"loaded_model = pickle.load(open('linear.sav', 'rb'))","70cbf269":"from random import choice\nfor i in range(20):\n    # select a random face from test set\n    selection = choice([i for i in range(testX.shape[0])]) \n    random_face = testX[selection]\n    random_face_emd = emdTestX_norm[selection]\n    random_face_class = testy_enc[selection]\n    random_face_name = out_encoder.inverse_transform([random_face_class])\n    # prediction for the face\n    samples = np.expand_dims(random_face_emd, axis=0)\n    yhat_class = loaded_model.predict(samples)\n    yhat_prob = loaded_model.predict_proba(samples)\n    class_index = yhat_class[0]\n    if class_index <= 460:\n        # get name\n        class_probability = yhat_prob[0,class_index] * 100\n        predict_names = out_encoder.inverse_transform(yhat_class)\n        #print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n        #if random_face_name[0] == predict_names[0]:\n        print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n        print('Expected: %s' % random_face_name[0])\n        # plot face\n        plt.imshow(random_face)\n        title = '%s (%.3f)' % (predict_names[0], class_probability)\n        plt.title(title)\n        plt.show()","50bb8b38":"### Save Model","8e82ede1":"## Face Classification with SVC\n#### > Note 1: In SVC, different kernels can be used for multiclass classification. These kernels are : linear, polynomial,  radial basis function (rbf). The kernel is a method or function which is used for linear classification for nonlinear problems or classification. As a default rbf are used; however, in the model, linear is used to make classification process faster since rbf works more slowly. \n\n#### > Note 2: If you want you can use other kernels, I write their code to use them as comment.","417d41d5":"## Label Encoding","54e2fca4":"### Example","9f1144f4":"# Face Recognition with FaceNet Embedding and Support Vector Classification (SVC) Models\n## Pipeline:\n1. Extract Faces\n2. Face Embeddings with FaceNet\n3. Label Encoding \n4. Face Classification with SVC","1b95732e":"### Compress and Save Train and Test Dataset\n#### > Note: After face extraction process, train and dataset may occupy memory and there might be memorry error. The reason of this process is to deal with this issue . ","7ccde50c":"### Load Model","b5e91084":"### Convert Each Face in the Train Set into Embedding","b8093a82":"### Load Test Dataset","58987b95":"## Result Examples","5c622f75":"### Compress and Save Train and Test Embeddings ","ba6984a5":"### Load saved compressed file","0bc20d4d":"### Convert Each Face in the Test Set into Embedding","ee4ec371":"## Extract Faces","51bdc81d":"### Encoding Trainy and Testy with Fitted Encoder","b0c56b01":"## Face Embeddings with FaceNet\n### Load Model","cfb3b79b":"#### > Note: Normally, In this part of the pipeline, MTCNN library are used; however, faces cannot be detected by MTCNN because of weared mask.","e30d66ca":"### Load Saved Compressed Dataset","90795663":"## Load Train and Test Dataset\n### Load Train Dataset"}}