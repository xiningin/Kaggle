{"cell_type":{"17d2f28b":"code","76c2af38":"code","2a7a9369":"code","851d81b5":"code","e1e7f43a":"code","792c94de":"code","1eec8ade":"code","93e108db":"code","98dd9afd":"code","1c86c8eb":"code","4d43240b":"code","09a88ace":"code","42a97e06":"code","6cf0dc1c":"code","14743770":"code","d9cce8e3":"markdown","edd86d8c":"markdown","4f601fbf":"markdown","8c3623b1":"markdown","b657ca4a":"markdown","a49397bc":"markdown","b863148c":"markdown","fdf50bed":"markdown","0d7469cf":"markdown","e9ec011c":"markdown","c596343d":"markdown"},"source":{"17d2f28b":"import tensorflow as tf\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense, AvgPool2D,MaxPool2D\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras import backend as K\nimport cv2\nimport shutil\nimport glob","76c2af38":"train_data = image_dataset_from_directory('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/',labels='inferred',\n                                       label_mode='binary',interpolation='nearest',image_size=[150,150],batch_size=64,\n                                       shuffle=True)\ntest_data = image_dataset_from_directory('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/',labels='inferred',\n                                       label_mode='binary',interpolation='nearest',image_size=[150,150],batch_size=64,\n                                       shuffle=True)\nvalid_data = image_dataset_from_directory('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/',labels='inferred',\n                                       label_mode='binary',interpolation='nearest',image_size=[150,150],batch_size=64,\n                                       shuffle=True)","2a7a9369":"classes_train = train_data.class_names\nplt.style.use('dark_background')\nplt.figure(figsize=(10,10))\nfor img, label in train_data.take(1):\n    for i in range(25):\n        ax = plt.subplot(5,5,i+1)\n        plt.imshow(img[i].numpy().astype('uint8'))\n        plt.title(classes_train[int(label[i])])\n        plt.axis('off')","851d81b5":"classes_test = test_data.class_names\nplt.style.use('dark_background')\nplt.figure(figsize=(10,10))\nfor img, label in train_data.take(1):\n    for i in range(25):\n        ax = plt.subplot(5,5,i+1)\n        plt.imshow(img[i].numpy().astype('uint8'))\n        plt.title(classes_test[int(label[i])])\n        plt.axis('off')","e1e7f43a":"classes_valid = valid_data.class_names\nplt.style.use('dark_background')\nplt.figure(figsize=(10,10))\nfor img, label in train_data.take(1):\n    for i in range(25):\n        ax = plt.subplot(5,5,i+1)\n        plt.imshow(img[i].numpy().astype('uint8'))\n        plt.title(classes_valid[int(label[i])])\n        plt.axis('off')","792c94de":"train_datagen = ImageDataGenerator(rescale = 1.\/255.,rotation_range = 20, width_shift_range = 0.2, height_shift_range = 0.2, \n                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\ntest_datagen = ImageDataGenerator(rescale = 1.0\/255.)","1eec8ade":"train_gen = train_datagen.flow_from_directory('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train',\n                                              target_size = (200,200), batch_size = 64, \n                                              class_mode = 'binary',  color_mode= 'rgb')\nval_gen = train_datagen.flow_from_directory('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation', \n                                            target_size=(200,200), class_mode='binary', color_mode= 'rgb',\n                                            batch_size= 64)\ntest_gen = test_datagen.flow_from_directory('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test',\n                                            target_size = (200,200), class_mode = 'binary',color_mode= 'rgb',\n                                            batch_size = 64)","93e108db":"base_model = tf.keras.applications.densenet.DenseNet201(weights='imagenet', input_shape = (200,200,3),\n                                                     include_top=False)\n\nfor layer in base_model.layers:\n    layer.trainable = False","98dd9afd":"\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(300, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation=\"sigmoid\"))\nmodel.summary()","1c86c8eb":"from tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n#initial_learning_rate = 1e-2,final_learning_rate = 1e-6,decay_steps = 10000\nlearning_rate = optimizers.schedules.PolynomialDecay(1e-5,10000,1e-6,power=0.4)\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])","4d43240b":"callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=1e-5, patience=10, mode='auto',\n                                              restore_best_weights=False, verbose=1),\n                ModelCheckpoint(filepath='mask_detection_model.h5', monitor='accuracy', save_best_only=True, \n                                save_weights_only=False,\n                                mode='auto', save_freq='epoch', verbose=1)]","09a88ace":"history = model.fit(train_gen, validation_data = val_gen, epochs = 40, steps_per_epoch=len(train_gen),\n                    callbacks = [callbacks], verbose = 1)","42a97e06":"loss, accuracy = model.evaluate(test_gen)","6cf0dc1c":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\nimport keras\nkeras.utils.plot_model(model, show_shapes=True)","14743770":"model.save('mask_detection_model.h5')","d9cce8e3":"# Base Model DenseNet201","edd86d8c":"# Showing the images","4f601fbf":"![](https:\/\/lh3.googleusercontent.com\/proxy\/qx9rRvq4RZNlrCHjS8-5A1esx4ilMw5aGJtadzaX36br-MhQDlFdeHglSvVg4JYFLf79yE9L7y6nNLVxQv6iR15pXt0EIwOVFOUFqQJ4jnTrcYiMsI2ooA)","8c3623b1":"![](https:\/\/medlineplus.gov\/ency\/images\/ency\/fullsize\/24381.jpg)","b657ca4a":"# Model Plotting","a49397bc":"# Model training","b863148c":"# Above 99% accuracy","fdf50bed":"![](https:\/\/i.pinimg.com\/originals\/18\/7c\/f8\/187cf8272755130197bacc8df6267c61.png)","0d7469cf":"# Upvote if you like it or fork it.","e9ec011c":"# Image Data Generator","c596343d":"![](https:\/\/world-heart-federation.org\/wp-content\/uploads\/2020\/07\/WHF_Covid19_Posters_A4_Prevent_Landscape.jpg)"}}