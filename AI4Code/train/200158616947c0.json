{"cell_type":{"fc8d4f5e":"code","6185fbfc":"code","d7e1e212":"code","2f9746ef":"code","0c4c1986":"code","e4ecab9c":"code","dc97357b":"code","f5a30559":"code","ebe974e1":"code","c3b7196c":"code","d60b79d9":"code","595dd35e":"code","5238355e":"code","0df5f1c6":"code","1edf445a":"code","cdee03ce":"code","a35ad9ce":"code","efca47a2":"markdown","3cc61277":"markdown","13d5ebf6":"markdown","09ba1004":"markdown","14b73ee5":"markdown","b0a5ad2d":"markdown","02bbccdf":"markdown","c6ecbbd3":"markdown"},"source":{"fc8d4f5e":"import numpy as np\nimport pandas as pd\nimport os\nimport PIL\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report","6185fbfc":"# we added the separation and header because the data is not organized, one can run without sep and header\n#to understand the difference\n\ntrain_df = pd.read_csv('..\/input\/covidx-cxr2\/train.txt', sep=\" \", header=None)\n\n#Columns are added because it was seen that column names were 0,1,2,3, so new column names are added\n#which are given in descriptions\ntrain_df.columns=['patient id', 'filename', 'class', 'data source']\n\n# Since we are doing image classification, patient id and data source is of no importance to us, so\n#we cn drop them\ntrain_df=train_df.drop(['patient id', 'data source'], axis=1 )","d7e1e212":"\n#same as train\ntest_df = pd.read_csv('..\/input\/covidx-cxr2\/test.txt', sep=\" \", header=None)\ntest_df.columns=['id', 'filename', 'class', 'data source' ]\ntest_df=test_df.drop(['id', 'data source'], axis=1 )","2f9746ef":"train_df.head() # see the first 5 rows and columns of train","0c4c1986":"test_df.head()#see the first 5 columns for test","e4ecab9c":"train_path = '..\/input\/covidx-cxr2\/train\/'  #directory path\ntest_path = '..\/input\/covidx-cxr2\/test\/'","dc97357b":"train_df['class'].value_counts()","f5a30559":"negative  = train_df[train_df['class']=='negative']   #negative values in class column\npositive = train_df[train_df['class']=='positive']  #positive values in class column\nfrom sklearn.utils import resample\n#majority class that  is negative, we need to downsample\/decrease that class so that there is no bias\n#n_samples = 2158 means we want 2158 sample of class negative, since there are 2158 samples of class positive\ndf_majority_downsampled = resample(negative, replace = True, n_samples = 2158) \n#concatenate\ntrain_df = pd.concat([positive, df_majority_downsampled])\n\nfrom sklearn.utils import shuffle\ntrain_df = shuffle(train_df) # shuffling so that there is particular sequence","ebe974e1":"train_df['class'].value_counts()","c3b7196c":"train_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)","d60b79d9":"#Let's see how many images for training and validation and testing\n\nprint(f\"Negative and positive values of train: {train_df['class'].value_counts()}\")\nprint(f\"Negative and positive values of validation: {valid_df['class'].value_counts()}\")\nprint(f\"Negative and positive values of test: {test_df['class'].value_counts()}\")","595dd35e":"#Let's start the modelling task\n# The ImageDataGenerator for keras is awesome.\n#It lets you augment your images in real-time while your model is still training! \n#You can apply any random transformations on each training image as it is passed to the model. \n#This will not only make your model robust but will also save up on the overhead memory!\n\n\n#We will apply the Image Data Generator on training with various parameters, but we won't apply \n#the same parameters on testin. Why?\n# Because we want the test iamges as it is, we don't want biasedness,\n#also if we fit it we will be applying\n# the model only on these test images only, it can't predict new images if fed into model\n#Because new images will not be augmented this way\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, \n                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\ntest_datagen = ImageDataGenerator(rescale = 1.0\/255.)\n\n#Now fit the them to get the images from directory (name of the images are given in dataframe) with augmentation\n\n\ntrain_gen = train_datagen.flow_from_dataframe(dataframe = train_df, directory=train_path, x_col='filename', \n                                              y_col='class', target_size=(200,200), batch_size=64, \n                                               class_mode='binary')\nvalid_gen = test_datagen.flow_from_dataframe(dataframe = valid_df, directory=train_path, x_col='filename',\n                                             y_col='class', target_size=(200,200), batch_size=64, \n                                            class_mode='binary')\ntest_gen = test_datagen.flow_from_dataframe(dataframe = test_df, directory=test_path, x_col='filename', \n                                            y_col='class', target_size=(200,200), batch_size=64,\n                                             class_mode='binary')\n#class mode binary because we want the classifier to predict covid or not\n#target size (200,200) means we want the images to resized to 200*200","5238355e":"import tensorflow as tf\n#Our base model is InceptionResNetV2, new readers are encouraged to see the architecture of this particular model\n\nbase_model = tf.keras.applications.ResNet50V2(weights='imagenet', input_shape = (200,200,3),\n                                                     include_top=False)\nfor layer in base_model.layers:\n    layer.trainable = False","0df5f1c6":"#Now we will add some more layers to the base model for our requirements\n\nmodel = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"covid_classifier_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', verbose=1),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n]\n\nmodel.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001),\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])\n","1edf445a":"history = model.fit(train_gen, \n                    validation_data=valid_gen, epochs=20, \n                    callbacks=[callbacks])","cdee03ce":"model.load_weights('.\/covid_classifier_model.h5')\nmodel.evaluate(test_gen)","a35ad9ce":"preds = (model.predict(test_gen)>0.5).astype(\"int32\")\n\npreds","efca47a2":"# Model evaluation and predictions","3cc61277":"## If you like it ot fork it, then upvote it! This gives us motivation to produce more notebooks for the community!","13d5ebf6":"# Model building","09ba1004":"Now we will split the train data into train(for training the model) and valid(for validation) and then after training and validation we will use the model to predict on test set. Simple.","14b73ee5":"Now start the transfer learning!","b0a5ad2d":"And the negative values are 13793 and positive values are 2158.\n\nWe need to balance them, else the model we create will be more biased towards negative and thereby wrong predictions.","02bbccdf":"Awesome! Now no imbalanced data! Proceed!","c6ecbbd3":"Let's do the same for test set!\n\nI highly encourage beginners to read the data without sep and header parameters to understand the difference!"}}