{"cell_type":{"f7044de9":"code","2c768a4c":"code","ce74d200":"code","65a584b7":"code","01e642eb":"code","b76e68d3":"code","e5ee333e":"code","b7ee763c":"code","da6c13dd":"code","e5381805":"code","20273bbc":"code","33be3ec9":"code","9021ff60":"markdown","6a7e0d03":"markdown","3908d02d":"markdown","6ecb5ff1":"markdown","f72ad9c9":"markdown","032c49aa":"markdown","8424f349":"markdown","f110db3b":"markdown","766cb930":"markdown"},"source":{"f7044de9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam # - Works\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport tensorflow as tf\nimport cv2\nimport os\nimport numpy as np\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2c768a4c":"labels = ['arson', 'home_intrusion', 'robbery']\nimg_size = 224 # Resize all the image to this size\ndef get_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","ce74d200":"train = get_data('..\/input\/crime-dataset\/COTM\/COTM\/TRAIN') # Uploading image\nval = get_data('..\/input\/crime-dataset\/COTM\/COTM\/TEST') # Uploading image","65a584b7":"l = []\nfor i in train:\n    if(i[1] == 0):\n        l.append(\"arson\")\n    elif(i[1] == 1):\n        l.append(\"home_intrusion\")\n    else:\n        l.append(\"robbery\")\nsns.set_style('darkgrid')\nsns.countplot(l)","01e642eb":"plt.figure(figsize = (5,5))\nplt.imshow(train[1][0])\nplt.title(labels[train[0][1]])","b76e68d3":"plt.figure(figsize = (5,5))\nplt.imshow(train[-1][0])\nplt.title(labels[train[-1][1]])","e5ee333e":"x_train = []\ny_train = []\nx_val = []\ny_val = []\n\nfor feature, label in train:\n  x_train.append(feature)\n  y_train.append(label)\n\nfor feature, label in val:\n  x_val.append(feature)\n  y_val.append(label)\n\n# Normalize the data\nx_train = np.array(x_train) \/ 255\nx_val = np.array(x_val) \/ 255\n\nx_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)","b7ee763c":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","da6c13dd":"model = Sequential()\nmodel.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dense(3, activation=\"softmax\"))\n\nmodel.summary()","e5381805":"opt = Adam(lr=0.000001)\nmodel.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])","20273bbc":"history = model.fit(x_train,y_train,epochs = 500 , validation_data = (x_val, y_val))","33be3ec9":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(500)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","9021ff60":"### Checking file size","6a7e0d03":"## TRAIN\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTu9x3kF897hnyfd7aRaCoQEuj9fX1_UoMY1Q&usqp=CAU)","3908d02d":"## Thank you","6ecb5ff1":"The acuraccy in this case is very less it is just 6, due to less and diverse data. We can use more data to make it better.","f72ad9c9":"## Sample file image","032c49aa":"Link to dataset: https:\/\/www.kaggle.com\/keagle\/crime-dataset","8424f349":"## Shifiting data","f110db3b":"## Data generator\nBasically it flisps the imge, changes brightness and more to make AI more better.","766cb930":"## Graphs"}}