{"cell_type":{"011fbc21":"code","82d81572":"code","b01c6717":"code","f7498864":"code","ff3756be":"code","9f304c5d":"code","48767536":"code","09196bdf":"code","de598aa3":"code","a20ae15e":"code","f1af73c0":"code","273db0ac":"code","904e6d98":"code","20941109":"code","254678ae":"code","b7a087aa":"code","525edaef":"code","f2199fe3":"code","e13e3eb1":"code","30069c0b":"code","e23f967c":"code","98b15e19":"code","c0369265":"code","d891f79b":"code","7444651f":"code","94eab6d8":"code","0c463ceb":"code","0cbffa65":"code","130c16cd":"code","1e8c88ad":"code","ce101d6f":"code","2c16224b":"code","75997f84":"code","b9929fb0":"code","165e4667":"code","a621632e":"code","7585a926":"code","2fcff612":"code","b0cf4424":"code","81c3fd99":"code","dff752f2":"code","1c0169fc":"markdown","2280320e":"markdown","f46d56a7":"markdown","ef7e7735":"markdown","031f12ff":"markdown","c6a05fcd":"markdown","448aa736":"markdown","caf38353":"markdown","c1e15f4d":"markdown","51e0afff":"markdown","0f6a5466":"markdown","dc8cf98d":"markdown","d394040b":"markdown","19613a9b":"markdown","801c56b8":"markdown","a29fb551":"markdown","91cdfa1b":"markdown","338f1a2f":"markdown","4a7ed14b":"markdown","a2f402e4":"markdown","98c40d16":"markdown","c0722cc4":"markdown","38bf4a1a":"markdown","419480cb":"markdown","02a8cdae":"markdown","c15bc42b":"markdown","8d33b3ab":"markdown","1a6e270b":"markdown","4fd4a686":"markdown","9f68b187":"markdown","7c58722e":"markdown","7c8a4ccb":"markdown","d462b792":"markdown","361588c5":"markdown","9df71f44":"markdown","62a703cf":"markdown","e0055f51":"markdown","cd48f2a2":"markdown","8ed99d8c":"markdown","e2524beb":"markdown","cef1aab5":"markdown"},"source":{"011fbc21":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","82d81572":"data = pd.read_csv('..\/input\/world-happiness-report-2019.csv')","b01c6717":"data.head(10)","f7498864":"data = data.drop(['Ladder', 'SD of Ladder'], axis=1)\n\ndata = data.rename(columns={\n    'Country (region)':'Country',\n    'Positive affect':'Pos',\n    'Negative affect':'Neg',\n    'Log of GDP\\nper capita':'GDP',\n    'Healthy life\\nexpectancy':'Life expectancy'\n})","ff3756be":"data.shape","9f304c5d":"data.info()","48767536":"data.isnull().sum()","09196bdf":"data = data[~data.isnull().any(axis=1)]\ndata.shape","de598aa3":"data.describe()","a20ae15e":"fig, ax = plt.subplots(2, 4, figsize=(16, 8))\nplt.tight_layout()\n\nfor i, feature in enumerate(list(data)[1:]):\n    sns.boxplot(x=feature, data=data, orient='v', ax=ax[int(i-4>=0)][i%4]);","f1af73c0":"plt.figure(figsize=(8,8))\nsns.heatmap(data.corr(), cmap=\"Blues\");","273db0ac":"data.corr()","904e6d98":"size = int(data.shape[0]\/3)\nsize","20941109":"data['Class'] = 0\ndata.iloc[size:2*size]['Class'] = 1\ndata.iloc[2*size:]['Class'] = 2","254678ae":"# Happiest countries among each group\n\ndata.iloc[[0, size, 2*size], :]","b7a087aa":"def distplot(col, bins=10):\n    \n    fig, ax = plt.subplots(1,3,figsize=(16, 4))\n\n    sns.distplot(data[data['Class']==0][col], bins=10, ax=ax[0])\n    ax[0].set_title('Class 0')\n\n    sns.distplot(data[data['Class']==1][col], bins=10, ax=ax[1])\n    ax[1].set_title('Class 1')\n\n    sns.distplot(data[data['Class']==2][col], bins=10, ax=ax[2])\n    ax[2].set_title('Class 2')\n\n    plt.show();","525edaef":"distplot('Freedom')","f2199fe3":"distplot('Corruption')","e13e3eb1":"distplot('Social support')","30069c0b":"distplot('GDP')","e23f967c":"distplot('Life expectancy')","98b15e19":"def scatterplot(x, y):\n    \n    fig, ax = plt.subplots(1, 3, figsize=(16, 6))\n\n    sns.regplot(x, y, data=data[data['Class']==0], ax=ax[0])\n    ax[0].set_title('Class 0', size=15)\n    ax[0].set_xlabel(x, size=15)\n    ax[0].set_ylabel(y, size=15)\n    \n    sns.regplot(x, y, data=data[data['Class']==1], ax=ax[1])\n    ax[1].set_title('Class 1')\n    ax[1].set_title('Class 1', size=15)\n    ax[1].set_xlabel(x, size=15)\n    ax[1].set_ylabel(y, size=15)\n    \n    sns.regplot(x, y, data=data[data['Class']==2], ax=ax[2])\n    ax[2].set_title('Class 2')\n    ax[2].set_title('Class 2', size=15)\n    ax[2].set_xlabel(x, size=15)\n    ax[2].set_ylabel(y, size=15)\n    \n    plt.show();","c0369265":"x = 'Social support'\ny = 'GDP'\nz = 'Life expectancy'","d891f79b":"scatterplot(x, y)","7444651f":"scatterplot(y, z)","94eab6d8":"scatterplot(x, z)","0c463ceb":"fig = sns.pairplot(data=data[['GDP', 'Social support', 'Life expectancy']])\n\nfig.fig.set_size_inches(12, 12);","0cbffa65":"from sklearn.tree import DecisionTreeClassifier","130c16cd":"# Reset index since some samples were dropped before that a few numbers skip\ndata.index = np.arange(data.shape[0])","1e8c88ad":"# Randomly choose testing samples\nhappy_idx = np.random.choice(np.arange(size), size=5, replace=False)\nneutral_idx = np.random.choice(np.arange(size, 2*size), size=5, replace=False)\nsad_idx = np.random.choice(np.arange(2*size, data.shape[0]), size=5, replace=False)\n\ntest_idx = list(happy_idx) + list(neutral_idx) + list(sad_idx)","ce101d6f":"test = data.iloc[test_idx]\ntest","2c16224b":"train = data[~data.index.isin(test_idx)]\n\ntrain.shape, test.shape","75997f84":"def split_data(dat):\n    \n    X = dat.loc[:, ['Social support', 'GDP', 'Life expectancy']]\n    y = dat.loc[:, 'Class']\n    \n    return X, y","b9929fb0":"# Only use three features\nX_train, y_train = split_data(train)\nX_test, y_test = split_data(test)","165e4667":"# Set random_state for reproducibility\nclf = DecisionTreeClassifier(random_state=123)\n\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)","a621632e":"X_train, y_train = train.drop(['Class', 'Country'], axis=1), train.loc[:, 'Class']\nX_test, y_test = test.drop(['Class', 'Country'], axis=1), test.loc[:, 'Class']","7585a926":"clf2 = DecisionTreeClassifier(random_state=123)\n\nclf2.fit(X_train, y_train)\nclf2.score(X_test, y_test)","2fcff612":"feature_importances = np.stack((clf2.feature_importances_, list(X_train)), axis=1)\nfeature_importances = feature_importances[feature_importances.argsort(axis=0)[:, 0]][::-1]\nfeature_importances","b0cf4424":"scores = []\n\nfor i in range(1, len(feature_importances)+1):\n    \n    features = feature_importances[:i, 1]\n\n    clf = DecisionTreeClassifier(random_state=123)\n    \n    clf.fit(X_train.loc[:, features], y_train)\n    \n    scores.append(clf.score(X_test.loc[:, features], y_test))","81c3fd99":"plt.figure(figsize=(8, 6))\nplt.plot(scores)\nplt.xlabel('Numer of Features', size=15)\nplt.ylabel('Scores', size=15)\nplt.show();","dff752f2":"feature_importances","1c0169fc":"## Cleaning","2280320e":"Let's see how many rows are null.","f46d56a7":"The data looks quite weird because we can see that all features' descriptions are almost the same. Additionally, the max value of Life expectancy is 150!","ef7e7735":"With the above graph, we could use 3, 4, 5, or 6 features and still have the same score. ","031f12ff":"We can do the same thing as above but this time, using all Class.","c6a05fcd":"It seems GDP and Life expectancy are the most correlated with the value of 0.847850, among others.","448aa736":"After cleaning up the data a bit, we could try if any of features are correlated.","caf38353":"Ladder is just another word for ranking so I removed it together with SD of ladder and renamed others. ","c1e15f4d":"Since we've added Class feature, we could build a model which predicts based on other features.","51e0afff":"Note that scores will vary as well as the number of features because training and validation set for models are chosen randomly and since our data is not big, random selection will affect the performance quite much.","0f6a5466":"Let's do the same with Corruption.","dc8cf98d":"Next we see the general numeric description of each feature.","d394040b":"## Overview of Data","19613a9b":"I chose three features <b>Social support<\/b>, <b>GDP<\/b>, and <b>Life expectancy<\/b> that are highly correlated to <b>Class<\/b> from the heatmap plot for better information gain.","801c56b8":"After adding the feature, I found a few things I could try and the first thing I did was to see how much Freedome behaves when classifying the Class.","a29fb551":"It seems that the lower the freedom value is, the happier a country is. What?","91cdfa1b":"There are a few ways when dealing with null samples. \n1. Drop Rows\n2. Fill with mean values or similar computation (e.g. forward fill)\n3. Use K-Nearest Neighbors\n\nBecause the whole data is small anyway, I chose to just drop them.","338f1a2f":"Based on the plot, Corruption affects less to the happiness of a country than the Freedom because the line plots are less indicative that Class 1 and Class 2 looks quite similar.","4a7ed14b":"I'm not sure how the data is computed exactly because when I checked out the original data from the original site, the features were different so I think this data was aggregated in some way I have no idea.","a2f402e4":"# Classification","98c40d16":"1. <b>Country (region)<\/b> Name of the country.\n2. <b>Ladder<\/b> is a measure of life satisfaction.\n3. <b>SD of Ladder<\/b> Standard deviation of the ladder.\n4. <b>Positive affect<\/b> Measure of positive emotion.\n5. <b>Negative affect<\/b> Measure of negative emotion.\n6. <b>Social support<\/b> The extent to which Social support contributed to the calculation of the Happiness Score.\n7. <b>Freedom<\/b> The extent to which Freedom contributed to the calculation of the Happiness Score.\n8. <b>Corruption<\/b> The extent to which Perception of Corruption contributes to Happiness Score.\n9. <b>Generosity<\/b> The extent to which Generosity contributed to the calculation of the Happiness Score.\n10. <b>Log of GDP per capita<\/b> The extent to which GDP contributes to the calculation of the Happiness Score.\n11. <b>Healthy life expectancy<\/b> The extent to which Life expectancy contributed to the calculation of the Happiness Score.","c0722cc4":"It still quite works poorly but the score increased a little.","38bf4a1a":"Now that we've found out they are correlated to Class, we explore if they are correlated themselves.","419480cb":"## Exploration","02a8cdae":"This is a kernel to show how to do basic EDA and classification for custom labels.","c15bc42b":"<b>0<\/b> shows a country is <b>happy<\/b>, <b>1<\/b> is <b>neutral<\/b> and <b>2<\/b> is <b>sad<\/b> (or unhappy). The smaller the value, the happier. This way, I can see which other features are correlated to it.","8d33b3ab":"Data is sorted in a way the country on top of the dataframe is the happiest while the last is the opposite.","1a6e270b":"We only have 140 samples so it may not work very well. So I held out 5 samples from each class for validation set.","4fd4a686":"All of the above plots show one common thing. The countires with Class 0 have right-skewed distribution while Class 2 have left-skewed distribution. And of course, Class 1 countries show more symmetric distribution than others.","9f68b187":"It does not seem like there exists any outliers so we don't have to drop any samples.","7c58722e":"---","7c8a4ccb":"If you find any errors and\/or typos or have any suggestion, please let me know!","d462b792":"Using the top 3 correlated features show poor result so I used all features again.","361588c5":"If we sort the features by descending order based on its importance to Class, we have the following result.","9df71f44":"Each column of data has the next description.","62a703cf":"I though for a while what I could do with the data above. What I did was to evenly distribute samples and add a new feature <b>Class<\/b> which each sample will have either 0, 1, or 2.","e0055f51":"In many cases, 8 features for a machine learning model aren't considered too much dimension and not really necessary to reduce them. However, let's see how many we can eliminate and still maintain the score.","cd48f2a2":"One of many things to do at the beginning of EDA is checking if any outliers exist among samples.","8ed99d8c":"# Simple Exploratory Data Analysis","e2524beb":"Because we are short in the number of samples and data is not time-series data, there are not much we can do to explore. But still, we could try something like visualizing proportions of Social support (or other features) by different classes. ","cef1aab5":"But EDA continues."}}