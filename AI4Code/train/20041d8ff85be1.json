{"cell_type":{"3f5f8534":"code","aea49680":"code","aad7efab":"code","c66ec0e6":"code","6f232af7":"code","d4780f0a":"code","213478f1":"code","38bf8186":"code","baffef73":"code","ae25fbcc":"code","5cffa7ac":"markdown","1d94c400":"markdown","ffcf12cc":"markdown","6ddfaebe":"markdown","5171a828":"markdown"},"source":{"3f5f8534":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/image1\"))\n\n# Any results you write to the current directory are saved as output.","aea49680":"\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D,BatchNormalization\nfrom keras.layers import MaxPooling2D,Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nimport cv2\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n","aad7efab":"# Initialising the CNN\nclassifier = Sequential()\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, (3, 3), input_shape = (50, 50,1), activation = 'relu',padding='same'))\n# Adding a second convolutional layer\n#classifier.add(BatchNormalization(axis=1))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(0.25))\n\n\nclassifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(64, (3, 3), activation = 'relu',padding='same'))\n#classifier.add(BatchNormalization(axis=1))\n\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(0.25))\n\n\nclassifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(128, (3, 3), activation = 'relu',padding='same'))\n#classifier.add(BatchNormalization(axis=1))\n\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\nclassifier.add(Dropout(0.25))\n# Step 3 - Flattening\nclassifier.add(Flatten())\nclassifier.add(Dense(512,activation='relu'))\nclassifier.add(BatchNormalization())\nclassifier.add(Dropout(0.5))\n\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 62, activation = 'softmax'))\n\n# Compiling the CNN\n\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\n\nclassifier.summary()\n","c66ec0e6":"\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   zoom_range = 0.2,\n                                   shear_range=0.2,\n\n                                  )\n\ntraining_set = train_datagen.flow_from_directory('..\/input\/images\/bmp\/Bmp',\n                                                target_size = (50,50),\n                                               batch_size = 128,\n                                                 color_mode= \"grayscale\",\n                                              class_mode = 'categorical')\n\n\nclassifier.fit_generator(training_set,\n                         epochs = 50,\n                         steps_per_epoch=40,\n                         )\n","6f232af7":"import cv2\nfrom keras.preprocessing.image import img_to_array\nimport numpy as np\nimg=cv2.imread('..\/input\/quotes\/down.jpeg')\nimagee=img.copy()\nimg=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n\nret,img=cv2.threshold(img,180,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\nk=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n\nimg = cv2.morphologyEx(img, cv2.MORPH_OPEN, k)\nk1=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\nimg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, k)\n\nimg1=cv2.Canny(img,0,255,2)\n\ncontours, hierarchy = cv2.findContours(img1,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\nimg2=cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\nfont = cv2.FONT_HERSHEY_SIMPLEX\n\nimg3=cv2.drawContours(img2, contours, -1, (0,255,255), 1)\nimage=[]\np=[]\nlist=['0','1','2','3','4','5','6','7','8','9']\nfor i in range(65,91):\n    list.append(chr(i))\nfor i in range(97,123):\n    list.append(chr(i))\nprint(list)\nfor c in contours:\n    x,y,w,h=cv2.boundingRect(c)\n    if w>5 and h>5:\n        \n        img4=cv2.rectangle(img3,(x,y),(x+w,y+h),(255,255,0),1)     \n        \n        i=img3[y:y+h,x:x+w]\n        i=cv2.resize(i,(50,50))\n        i=cv2.cvtColor(i,cv2.COLOR_BGR2GRAY)\n        i = i.astype(\"float\") \/ 255.0\n        \n        ima = img_to_array(i)\n        ima = np.expand_dims(ima, axis=0)\n        pred = classifier.predict(ima)[0]\n        #print(list[pred.argmax()],pred.max())\n        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h+20), font, 0.8 ,(255,255,255),2,cv2.LINE_AA)   \n        p.append(list[pred.argmax()])\n'''for c in contours:\n    x,y,w,h=cv2.boundingRect(c)\n    if w>5 and h>5:\n        img5=cv2.putText(img4,list[pred.argmax()],(x,y+h-35), font, 0.5,(255,255,255),2,cv2.LINE_AA)        \nfrom PIL import Image, ImageTk \n#img5.show()'''\nimport matplotlib.pyplot as plt\nplt.imshow(img5)\n   ","d4780f0a":"plt.imshow(img)\n","213478f1":"'''from keras.preprocessing.image import img_to_array\nimport numpy as np \nlist=['s1','s2']\nimage = cv2.imread('..\/input\/picture\/main-qimg-03de963368e748a6fb7e399772b09c48-c')\nprint(type(image))\n# pre-process the image for classification\nimage = cv2.resize(image, (50,50))\nima=image\n\nimage = image.astype(\"float\") \/ 255.0\nimage = img_to_array(image)\nimage = np.expand_dims(image, axis=0)\nprint(image.shape)\n\npred = classifier.predict(image)[0]\nfor i in range(2):\n    if pred[i]>0.5:\n        print(list[i],(pred[i]).astype('float32'))\n    \n\nprint(pred)\n\n#classifier.save('..\/input\/model.h5')'''","38bf8186":"'''import cv2\nprint((ima.shape))\n\ngray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\nface_cascade = cv2.CascadeClassifier('..\/input\/repository\/informramiz-opencv-face-recognition-python-0edc6e0\/opencv-files\/haarcascade_frontalface_alt.xml')\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n(x,y,w,h)=faces[0]\nimm=gray[y:y+w, x:x+h]\nprint((gray.shape))\nimport matplotlib.pyplot as mat\nmat.plot(imm)\ncv2.waitKey()'''","baffef73":"'''import cv2\nf=[]\nl=[]\ndir=sorted(list(os.listdir('..\/input\/repository\/informramiz-opencv-face-recognition-python-0edc6e0\/training-data')))\nfor i in dir:\n    s=sorted(list(os.listdir('..\/input\/repository\/informramiz-opencv-face-recognition-python-0edc6e0\/training-data\/'+i)))\n    for j in s:\n        print(i)\n        k=cv2.imread('..\/input\/repository\/informramiz-opencv-face-recognition-python-0edc6e0\/training-data\/'+i+'\/'+j)\n        gray=cv2.cvtColor(k,cv2.COLOR_BGR2GRAY)\n        face_cascade=cv2.CascadeClassifier('..\/input\/repository\/informramiz-opencv-face-recognition-python-0edc6e0\/opencv-files\/lbpcascade_frontalface.xml')\n        faces=face_cascade.detectMultiScale(gray,1.2,9)\n        if len(faces)>0:\n            (x,y,w,h)=faces[0]\n            face=gray[y:y+h,x:x+w]\n            f.append(face)\n            label=i\n            if label=='s1':\n                l.append(1)\n            else:\n                l.append(0)'''","ae25fbcc":"'''face_rec=cv2.face.LBPHFaceRecognizer_create()\nface_rec.train(f,np.array(l))\ntestimg='..\/input\/repository\/informramiz-opencv-face-recognition-python-0edc6e0\/test-data\/test1.jpg'\nlab,conf=face_rec.predict(testimg)'''","5cffa7ac":"# Model Building","1d94c400":"                          - - - - - - - - - - - - -- - - - - - - - - END- - - - - - - - - - - - - - - -- - - - - - - - - - - ","ffcf12cc":"# Preprocessing the text doc","6ddfaebe":"# Fitting Image dataset","5171a828":"**We can see that it matches most of the words but sometimes give error in diiferentiation of capital and small letters.**"}}