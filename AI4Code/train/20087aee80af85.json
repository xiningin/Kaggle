{"cell_type":{"3ae1b7d1":"code","1b3c1d31":"code","5e4255cc":"code","6d4f62ee":"code","d7807af6":"code","427e5e96":"code","d72c9ba9":"code","d200bc20":"code","9a835be0":"code","7225a9cf":"code","3a3ffc4d":"code","d8afa4b6":"code","e7072109":"code","11eda9ae":"code","507378f0":"code","33586e18":"code","36e29a27":"code","feaff235":"code","6f96dd1b":"markdown","48815a02":"markdown","434e3ecc":"markdown","76fc7966":"markdown","55f68fd5":"markdown","1ee7d2b7":"markdown","2e4dbef8":"markdown","f3dd32e2":"markdown","a635015a":"markdown","a28d4793":"markdown","4f9cff36":"markdown","f4139d7f":"markdown","d6763c99":"markdown","9d036007":"markdown","468886e9":"markdown","46fb2363":"markdown","88ebba28":"markdown"},"source":{"3ae1b7d1":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,AveragePooling2D,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adagrad,Adadelta,Adam,RMSprop\nfrom tensorflow.keras.losses import categorical_crossentropy,binary_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator","1b3c1d31":"# load the dataset into train and test sets\n(x_train,y_train), (x_test,y_test)= mnist.load_data()","5e4255cc":"print('Training data size:')\nprint(x_train.shape)\nprint(y_train.shape)\nprint('Testing data size:')\nprint(x_test.shape)\nprint(y_test.shape)","6d4f62ee":"# classes distribution \nsns.countplot(y_train)","d7807af6":"# visualisations\nfig, axes= plt.subplots(6,5, figsize=(18,18))\naxes= axes.flatten()\nidx= np.random.randint(0,60000,size=30)\nfor i in range(30):\n    axes[i].imshow(x_train[idx[i],:].reshape(28,28))\n    axes[i].axis('off') #hide the axis ticks\n    axes[i].set_title(str(int(y_train[idx[i]])), color='k',fontsize=25)\n    \nplt.show()","427e5e96":"# Specify input dimension of each image\nimg_rows, img_cols= 28,28\ninput_shape = (img_rows, img_cols,1)\n# Specifying batch size, number of classes, epoch\nbatch_size=128\nnum_classes=10\nepochs = 50","d72c9ba9":"x_train.shape","d200bc20":"# Reshaping x_train and x_test\nx_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\nx_test= x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\nprint(x_train.shape)\nprint(x_test.shape)","9a835be0":"# convert class labels (from digits) to one hot encoded vectore\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=num_classes)\ny_test= tf.keras.utils.to_categorical(y_test,num_classes)\nprint(y_train.shape)\nprint(y_test.shape)","7225a9cf":"# originally, the pixels are stored as ints\nx_train.dtype","3a3ffc4d":"# convert into float\nx_train=x_train.astype('float32')\nx_test= x_test.astype('float32')\n\n# Normalised train and test data\nx_train\/=255\nx_test\/=255","d8afa4b6":"# early stopping in case of no improvement or overfitting\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)","e7072109":"'''\nLet's apply some data augmentation.\n\nData augmentation is a set of techniques used to generate new training samples from the original ones\nby applying jitters and perturbations such that the classes labels are not changed.\nIn the context of computer vision, these random transformations can be translating,\nrotating, scaling, shearing, flipping etc.\n\nData augmentation is a form of regularization because the training algorithm is being\nconstantly presented with new training samples,\nallowing it to learn more robust and discriminative patterns\nand reducing overfitting.\n'''\n\ndata_aug= ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=10,\n    zoom_range = 0.1, \n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False\n)","11eda9ae":"# model\nmodel=Sequential()\n# note that the first layer needs to be told the input shape explicitly\n\n# first conv layer\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu', input_shape=input_shape)) # input shape=(img_rows,img_cols,1)\nmodel.add(BatchNormalization())\n# second conv layer\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\n#third conv layer\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#fourth conv layer\nmodel.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#flatten and put a fully connected layer\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu')) # fully connected\nmodel.add(Dropout(0.5))\n\n#softmax layer\nmodel.add(Dense(num_classes, activation='softmax')) #multiclass classification problem\n\n# model summary\nmodel.summary()","507378f0":"# cross entropy loss\n# choose any optimiser such as adam, rmsprop, adagrad, adadelta\n# metric is accuracy\n# configures the model for training\nmodel.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['accuracy'])","33586e18":"# fit model \nhistory = model.fit_generator(data_aug.flow(x_train,y_train, batch_size=batch_size),epochs=epochs, verbose=1, validation_data=(x_test,y_test),\\\n         callbacks=[callback],steps_per_epoch=x_train.shape[0] \/\/ batch_size)","36e29a27":"# evaluate the model on test data\nmodel.evaluate(x_test, y_test)","feaff235":"# loss and accuracy curves of the training set and the validation set.\nfig, ax = plt.subplots(2,1,figsize=(8,8))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","6f96dd1b":"The final loss (on test data) is about 0.02 and the accuracy is 99.4%.","48815a02":"The final loss (on test data) is about 0.02 and the accuracy is 99.4%.","434e3ecc":"Finally, let's convert the data type of `x_train` and `x_test` from int to float and normalise the images.","76fc7966":"`We are using Mnist kaggle training set as our training dataset. It consists of 28px by 28px grayscale images of handwritten digits (0 to 9), along with labels for each image indicating which digit it represents. Here are some sample images from the dataset:`\n\n![mnist-sample](https:\/\/i.imgur.com\/CAYnuo1.jpg)\n\n`Our goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.`","55f68fd5":"## 2. Data Preparation\n\nLet's prepare the dataset for feeding to the network. We will do the following three main steps:<br>\n\n#### 2.1 Reshape the Data\nFirst, let's understand the shape in which the network expects the training data. \nSince we have 60,000 training samples each of size (28, 28, 1), the training data (`x_train`) needs to be of the shape `(60000, 28, 28, 1)`. If the images were coloured, the shape would have been `(60000, 28, 28, 3)`.\n\nFurther, each of the 60,000 images have a 0-9 label, so `y_train` needs to be of the shape `(60000, 10)` where each image's label is represented as a 10-d **one-hot encoded vector**.\n\nThe shapes of `x_test` and `y_test` will be the same as that of `x_train` and `y_train` respectively.\n\n#### 2.2 Rescaling (Normalisation)\nThe value of each pixel is between 0-255, so we will **rescale each pixel** by dividing by 255 so that the range becomes 0-1. Recollect <a href=\"https:\/\/stats.stackexchange.com\/questions\/185853\/why-do-we-need-to-normalize-the-images-before-we-put-them-into-cnn\">why normalisation is important for training NNs<\/a>.\n\n#### 2.3 Converting Input Data Type: Int to Float\nThe pixels are originally stored as type `int`, but it is advisable to feed the data as `float`. This is not really compulsory, but advisable. You can read <a href=\"https:\/\/datascience.stackexchange.com\/questions\/13636\/neural-network-data-type-conversion-float-from-int\">why conversion from int to float is helpful here<\/a>.\n","1ee7d2b7":"So we have 60,000 training and 10,000 test images each of size 28 x 28. Note that the images are grayscale and thus are stored as 2D arrays.<br> \n\nAlso, let's sample only 20k images for training (just to speed up the training a bit).","2e4dbef8":"Now let's reshape `y_train` from `(20000,)` to `(20000, 10)`, one hot encoded vector for 10 classes. This can be conveniently done using the keras' `utils` module.","f3dd32e2":"## 3. Building the Model","a635015a":"Let's now reshape the array `x_train` from shape `(60000, 28, 28)`to `(60000, 28, 28, 1)`. Analogously for `x_test`.","a28d4793":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:red' role=\"tab\" aria-controls=\"home\"><center>If you found this notebook helpful , some upvotes would be very much appreciated - That will keep me motivated \ud83d\ude0a<\/center><\/h2>\n","4f9cff36":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:red' role=\"tab\" aria-controls=\"home\"><center>MNIST Tensorflow: Convoluton Neural Networks<\/center><\/h2>\n","f4139d7f":"# Building a Basic Custom CNN: The MNIST Dataset\n\nIn this notebook, we will build a simple CNN-based architecture to classify the 10 digits (0-9) of the MNIST dataset.\nThe objective of this notebook is to become familiar with the process of building CNNs in Keras.\n\nWe will go through the following steps:\n1. Importing libraries and the dataset\n2. Data preparation: Train-test split, specifying the shape of the input data etc.\n3. Building and understanding the CNN architecture \n4. Fitting and evaluating the model\n","d6763c99":"## 4. Fitting and Evaluating the Model\n\nLet's now compile and train the model.","9d036007":"## 1. Importing Libraries and the Dataset\n\nLet's load the required libraries. From Keras, we need to import two main components:\n1. `Sequential` from `keras.models`: `Sequential` is the keras abstraction for creating models with a stack of layers (MLP has multiple hidden layers, CNNs have convolutional layers, etc.). \n2. Various types of layers from `keras.layers`: These layers are added (one after the other) to the `Sequential` model\n\nThe keras `backend` is needed for keras to know that you are using tensorflow (not Theano) at the backend (the backend is <a href=\"https:\/\/keras.io\/backend\/\">specified in a JSON file<\/a>). \n","468886e9":"Let's load the MNIST dataset from `keras.datasets`. The download may take a few minutes.","46fb2363":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:red' role=\"tab\" aria-controls=\"home\"><center>Thank You \ud83d\ude0a\ud83d\ude4f<\/center><\/h2>\n","88ebba28":"Let's now build the CNN architecture. For the MNIST dataset, we do not need to build a very sophisticated CNN - a simple shallow-ish CNN would suffice. \n\nWe will build a network with:\n- two convolutional layers having 32 and 64 filters respectively, \n- followed by a max pooling layer, \n- and then `Flatten` the output of the pooling layer to give us a long vector, \n- then add a fully connected `Dense` layer with 128 neurons, and finally\n- add a `softmax` layer with 10 neurons\n\nThe generic way to build a model in Keras is to instantiate a `Sequential` model and keep adding `keras.layers` to it. We will also use some dropouts."}}