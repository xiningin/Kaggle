{"cell_type":{"9f08f4f8":"code","4e421172":"code","bd41c880":"code","8f8f3e2d":"code","299cfdaa":"code","ecbd1345":"code","e456f6f6":"code","a40cba46":"code","e4e9a866":"code","9ea9bef3":"code","8288906e":"code","54e93ecb":"code","629afc53":"code","cb5c07bc":"code","fcff8d75":"code","67645e06":"code","6d92d4a4":"code","cf819817":"code","2a8428bb":"code","cd9b6cd9":"code","e93016d2":"code","a478d483":"code","adea523b":"code","2b3f216e":"code","da3ae5d7":"code","f7520732":"code","f2d68b5e":"code","1a7a8df1":"code","60cffae8":"code","b337f061":"code","d9ea0570":"code","bd15f1ff":"code","fa0c26e3":"code","bd557e2c":"code","8d1cbe18":"code","b12c3323":"code","211c4984":"code","03b8ae5e":"code","c1db048d":"code","a82c59bd":"code","a4dd19b3":"code","5ae9ef0c":"code","7fd06c32":"code","71c35068":"code","b2f7ac25":"code","0a43e3db":"code","e9ea033d":"code","d0a7fdc6":"code","314f5a15":"markdown","f973e65f":"markdown","d6bf2f56":"markdown","1069ab28":"markdown","578b73d0":"markdown","9272a314":"markdown","20e61127":"markdown","dfa037ce":"markdown","feca7926":"markdown","38d61fcc":"markdown","7a67df06":"markdown","21bf1776":"markdown","7c1a0ee0":"markdown","311e69db":"markdown","30b3b7b7":"markdown","064f3bf6":"markdown","9bf2c543":"markdown","46ddcfd3":"markdown","7884b4a4":"markdown"},"source":{"9f08f4f8":"import os\nimport cv2\nimport numpy as np \nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \nfrom random import shuffle , seed\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications   import EfficientNetB3\nfrom tensorflow.keras.applications.densenet import DenseNet201 \nfrom tensorflow.keras.layers import Input ,concatenate, Dense,Flatten ,Conv2D ,Dropout ,MaxPool2D , GlobalAveragePooling2D ","4e421172":"#read\ndata_path=\"..\/input\/brain-tumor-classification-mri\/Training\"\nfolders=os.listdir(data_path)\nprint (\"classes : \", folders)\n\n\n# configration lists for read in it\nglioma_tumor_scans=[]\nglioma_tumor_labels=[]\n\nmeningioma_tumor_scans=[]\nmeningioma_tumor_labels=[]\n\npituitary_tumor_scans=[]\npituitary_tumor_labels=[]\n\n\nnon_tumor_scans=[]\nnon_tumor_labels=[]","bd41c880":"# read brain glioma tumor scans\nglioma_tumor_scans,glioma_tumor_labels=[cv2.imread(data_path+\"\/glioma_tumor\/\"+image) for image in tqdm(os.listdir(data_path+\"\/glioma_tumor\"))],[\"Glioma Tumor\" for image in tqdm(os.listdir(data_path+\"\/glioma_tumor\"))]\nprint(\"brain glioma tumor scans number : \", len(glioma_tumor_scans))\nprint(\"brain glioma tumor labels number : \", len(glioma_tumor_labels))\n \n","8f8f3e2d":"# read brain meningioma tumor scans\nmeningioma_tumor_scans,meningioma_tumor_labels=[cv2.imread(data_path+\"\/meningioma_tumor\/\"+image) for image in tqdm(os.listdir(data_path+\"\/meningioma_tumor\"))],[\"Meningioma Tumor\" for image in tqdm(os.listdir(data_path+\"\/meningioma_tumor\"))]\nprint(\"brain meningioma tumor scans number : \", len(meningioma_tumor_scans))\nprint(\"brain meningioma tumor labels number : \", len(meningioma_tumor_labels))\n","299cfdaa":"# read brain tumor scans\npituitary_tumor_scans,pituitary_tumor_labels=[cv2.imread(data_path+\"\/pituitary_tumor\/\"+image) for image in tqdm(os.listdir(data_path+\"\/pituitary_tumor\"))],[\"Pituitary Tumor\" for image in tqdm(os.listdir(data_path+\"\/pituitary_tumor\"))]\nprint(\"brain pituitary tumor scans number : \", len(pituitary_tumor_scans))\nprint(\"brain pituitary tumor labels number : \", len(pituitary_tumor_labels))\n","ecbd1345":"# read non tumor scans\nnon_tumor_scans , non_tumor_labels=[cv2.imread(data_path+\"\/no_tumor\/\"+image) for image in tqdm(os.listdir(data_path+\"\/no_tumor\"))], [\"Non Tumor\" for image in tqdm(os.listdir(data_path+\"\/no_tumor\"))]\nprint(\"non tumor scans number : \", len(non_tumor_scans))\nprint(\"non tumor labels number : \", len(non_tumor_labels))\n","e456f6f6":"plt.imshow(glioma_tumor_scans[0])\nplt.title(pituitary_tumor_labels[0])","a40cba46":"#function to show images\ndef image_show(data, labels , number_of_image ):\n    #to generate a random numbers\n    numbers=np.random.randint(0,len(data),number_of_image)\n    plt.figure(figsize=(30,20))\n    j = number_of_image\/10\n    for _,i in enumerate(numbers):\n        plt.subplot(j,10,_+1)\n        plt.imshow(data[i])\n        plt.title(labels[i]+\"\\n\"+f\"size {data[i].shape}\")\n        #to remove the number that appear around image\n        plt.xticks([]),plt.yticks([])\n    plt.show()\n\n","e4e9a866":"# show sample for  glioma_tumor_scans\nimage_show(glioma_tumor_scans,glioma_tumor_labels ,10)","9ea9bef3":"# show sample for non tumor scan\nimage_show(pituitary_tumor_scans,pituitary_tumor_labels ,10)","8288906e":"# show sample for  glioma_tumor_scans\nimage_show(meningioma_tumor_scans,meningioma_tumor_labels ,10)","54e93ecb":"# show sample for non tumor scan\nimage_show(non_tumor_scans,non_tumor_labels ,10)","629afc53":"# global image size\nImageSize=300\n\n#resize tumor scans\nglioma_tumor_scans=[cv2.resize(image, (ImageSize,ImageSize)) for image in glioma_tumor_scans]\n\n\n#resize tumor scans\nmeningioma_tumor_scans=[cv2.resize(image, (ImageSize,ImageSize)) for image in meningioma_tumor_scans]\n\n\n#resize tumor scans\npituitary_tumor_scans=[cv2.resize(image, (ImageSize,ImageSize)) for image in pituitary_tumor_scans]\n\n\n#resize non tumor scans\nnon_tumor_scans=[cv2.resize(image, (ImageSize,ImageSize)) for image in non_tumor_scans]","cb5c07bc":"#prepare Dataset\n\nScans=[]\nLabels=[]\n\n\n#combine scans\nScans.extend(glioma_tumor_scans)\nScans.extend(meningioma_tumor_scans)\nScans.extend(pituitary_tumor_scans)\nScans.extend(non_tumor_scans)\n\n#combine labels\nLabels.extend(glioma_tumor_labels)\nLabels.extend(meningioma_tumor_labels)\nLabels.extend(pituitary_tumor_labels)\nLabels.extend(non_tumor_labels)\n\n#converte to array \nScans=np.array(Scans)\nLabels=np.array(Labels)\n\n\nprint(\"Scans shape: \", Scans.shape)\nprint(\"Labels shape: \", Labels.shape)\n","fcff8d75":"#### show scans after resized\n# show sample for  tumor scan\nimage_show(Scans,Labels ,40)\n\n","67645e06":"classes={0:\"Non Tumor\" , 1:\"Glioma Tumor\" , 2:\"Meningioma Tumor\" , 3:\"Pituitary Tumor\"}\n#function to get code by name \ndef get_code(name):\n    for key , value in classes.items():\n        if value ==name:\n            break\n    return key\n\n#function to get name by code\ndef get_class(key):\n    return classes[key]\n\n\n#test\nprint(\"Non Tumor :\", get_code(\"Non Tumor\"))\nprint(\"0 :\" ,get_class(0))\n\nprint(\"Tumor :\", get_code(\"Tumor\"))\nprint(\"1 :\" ,get_class(1))\n\n","6d92d4a4":"#labels configuration\n\nLabels=[get_code(label) for label in Labels]\nLabels","cf819817":"import seaborn as sns\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(9,5))\nsns.countplot(Labels)\nplt.show()","2a8428bb":"# read other non tumor scans\nother_non_tumor_scans , other_non_tumor_labels=[cv2.resize(cv2.imread(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/\"+image),(ImageSize,ImageSize)) for image in tqdm(os.listdir(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\"))], [\"Non Tumor\" for image in tqdm(os.listdir(\"..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/\"))]\nprint(\"other non tumor scans number : \", len(other_non_tumor_scans))\nprint(\"other non tumor labels number : \", len(other_non_tumor_labels))","cd9b6cd9":"# show sample for  other tumor scan\nimage_show(other_non_tumor_scans,other_non_tumor_labels ,10)","e93016d2":"Scans=list(Scans) +other_non_tumor_scans\nScans=np.array(Scans)\n\n# add labels and converte other non tumor labels to categroical\nLabels=list(Labels)+ [get_code(label) for label in other_non_tumor_labels]\n\nLabels=np.array(Labels)\n\n\nprint(\"Scans shape: \", Scans.shape)\nprint(\"Labels shape: \", Labels.shape)","a478d483":"import seaborn as sns\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(9,5))\nsns.countplot(Labels)\nplt.show()","adea523b":"import tensorflow as tf\nLabels=tf.keras.utils.to_categorical(Labels, num_classes=4, dtype='float32')\nLabels","2b3f216e":"#split all data to train and test\nx_train, x_val, y_train  , y_val=train_test_split(Scans, Labels,test_size=0.05 , shuffle=True , stratify=Labels)\n\nprint(\"x train shape: \", x_train.shape)\nprint(\"y train shape: \", y_train.shape)\n\n\nprint(\"x val shape: \", x_val.shape)\nprint(\"y val shape: \", y_val.shape)","da3ae5d7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ngenerator=ImageDataGenerator(\n        samplewise_std_normalization=True,\n        samplewise_center=True,\n        rotation_range=90\n,fill_mode='nearest')\n\nbatch_size=8                                               \ntrain_generator=generator.flow(x_train,y_train ,batch_size=batch_size)\nval_generator=generator.flow(x_val,y_val)","f7520732":"#get data for generator\ntrain_scans=train_generator.__getitem__(0)[0]\ntrain_labels=train_generator.__getitem__(0)[1]","f2d68b5e":"train_labels","1a7a8df1":"#converte labels to plot images\nlabels=[get_class(np.argmax(i)) for i in train_labels]\n\n#show train generator\nimage_show(train_scans,labels,40)","60cffae8":"denenet_model=DenseNet201(weights=\"imagenet\", include_top=False , input_shape=(ImageSize,ImageSize,3) )\n\n\nfor layer in denenet_model.layers[:150]:\n    layer.trainable=False\n    \n    \ndenenet_model.summary()","b337f061":"denenet_model=DenseNet201(weights=\"imagenet\", include_top=False , input_shape=(ImageSize,ImageSize,3) )\n\n\nfor layer in denenet_model.layers[:150]:\n    layer.trainable=False\n    \n    \n# denenet_model.summary()\n\n\n\nc=Conv2D(1024 , (5,5), padding=\"same\" , activation=\"relu\")(denenet_model.output)\nc=Conv2D(512 , (5,5), padding=\"same\" , activation=\"relu\")(c)\nc=Conv2D(64 , (5,5), padding=\"same\" , activation=\"relu\")(c)\n\np=GlobalAveragePooling2D()(c)\n\n# Fine tuning  dense net model model\n\nx=Dense(1024, activation=\"relu\")(p)\nx=Dense(1024, activation=\"relu\")(x)\n\nx=Dense(512, activation=\"relu\")(x)\nx=Dense(512, activation=\"relu\")(x)\n\nx=Dense(256, activation=\"relu\")(x)\nx=Dense(256, activation=\"relu\")(x)\n\nx=Dense(128, activation=\"relu\")(x)\n\nx=Dense(64, activation=\"relu\")(x)\n\noutput=Dense(4, activation=\"softmax\")(x)\n\nmodel=Model(inputs=denenet_model.input , outputs=output)\nmodel.summary()\n\n#plot model\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True , to_file=\"model.png\")","d9ea0570":"#callbacks\ncallbacks_denseNet=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\" , patience=5 , verbose=1),\n    tf.keras.callbacks.ModelCheckpoint(\"denseNetModel.h5\" , save_best_only=True ,verbose=1),\n#     lr_rate\n    \n    ]","bd15f1ff":"#training Densenet Model\n\n# check t batch size is 8\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001 ,  epsilon=1e-07) , \n              loss=tf.keras.losses.categorical_crossentropy , \n              metrics=[\"accuracy\"])\n\nDenseNet_history=model.fit_generator(train_generator, \n          epochs= 20, \n          steps_per_epoch=x_train.shape[0]\/batch_size ,\n          validation_data=val_generator ,callbacks=callbacks_denseNet,\n          verbose=1)\n\n","fa0c26e3":"#evaluate \nprint('evaluate')\nmodel.evaluate(train_generator),model.evaluate(val_generator)","bd557e2c":"print(\"- the Accuracy and Loss for DenseNet Model With 20 Epochs\")\nplt.figure(figsize=(40,20))\n\n\n\n# summarize history for accuracy \nplt.subplot(5,5,1)\nplt.plot(DenseNet_history.history['accuracy'])\nplt.plot(DenseNet_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','validation'], loc='upper left')\n\n\n\n# summarize history for loss\nplt.subplot(5,5,2)\nplt.plot(DenseNet_history.history['loss'])\nplt.plot(DenseNet_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','loss'], loc='upper left')\nplt.show()","8d1cbe18":"val_generator.__getitem__(0)[0][image_index].reshape(1,300,300,3)","b12c3323":"import scipy as sp\nimage_index=6\n#class activation map\ncam_model=Model(inputs=model.inputs,outputs=(model.layers[-11].output , model.layers[-1].output))\n# cam_model.summary()\n# get weights\nget_weights=cam_model.layers[-1].get_weights()[0]\n\nprint(get_weights.shape)\n\nfeatures , results=cam_model.predict(val_generator.__getitem__(0)[0][image_index].reshape(1,300,300,3))\npredication=np.argmax(results)\nclass_activation_weights=get_weights[:,predication]\nfeatures.shape\n\n#zoom image \nclass_activation_features=sp.ndimage.zoom(features.reshape(9, 9, 64), (300\/9, 300\/9, 1), order=2)\n\nprint(class_activation_features.shape, class_activation_weights.shape)\n\ncam_output=np.dot(class_activation_features ,class_activation_weights)\n\n\nplt.imshow(cam_output ,  cmap='jet', alpha=0.5)\nplt.imshow(val_generator.__getitem__(0)[0][image_index], alpha=0.5)\ntitle=classes[predication]+\" <=> \"+ classes[np.argmax(val_generator.__getitem__(0)[1][image_index])]\nplt.title(title)\nplt.show()","211c4984":"#New model\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import MaxPooling2D\nmodel = Sequential()\nmodel.add(Conv2D(16,input_shape=(300,300,3),kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128,kernel_size=(3,3),activation='relu',padding='same'))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(4, activation=\"softmax\"))\n\nmodel.summary()","03b8ae5e":"\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001 ,  epsilon=1e-07) , \n              loss=tf.keras.losses.categorical_crossentropy , \n              metrics=[\"accuracy\"])\n\nmodel_history=model.fit_generator(train_generator, \n          epochs= 20, \n          steps_per_epoch=x_train.shape[0]\/batch_size ,\n          validation_data=val_generator ,callbacks=callbacks_denseNet,\n          verbose=1)","c1db048d":"image_index=0\n#class activation map\ncam_model=Model(inputs=model.inputs,outputs=(model.layers[-3].output , model.layers[-1].output))\n# cam_model.summary()\n# get weights\nget_weights=cam_model.layers[-1].get_weights()[0]\n\nprint(get_weights.shape)\n\nfeatures , results=cam_model.predict(x_val[image_index:image_index+1])\npredication=np.argmax(results)\nclass_activation_weights=get_weights[:,predication]\n\n#zoom image \nclass_activation_features=sp.ndimage.zoom(features.reshape(37,37,128), (300\/37, 300\/37, 1), order=2)\n\nprint(class_activation_features.shape, class_activation_weights.shape)\n\ncam_output=np.dot(class_activation_features ,class_activation_weights)\n\n\nplt.imshow(cam_output ,  cmap='jet', alpha=0.5)\nplt.imshow(x_val[image_index], alpha=0.5)\ntitle=classes[predication]+\" vs \"+ classes[np.argmax(y_val[image_index])]\nplt.title(title)\nplt.show()","a82c59bd":"# call EfficientNetB3  model\n\nEfficientNetB3_model=EfficientNetB3(weights=\"imagenet\", include_top=False , input_shape=(ImageSize,ImageSize,3) )\n\n\nfor layer in EfficientNetB3_model.layers[:10]: \n    layer.trainable=False\n    \n    \n# EfficientNetB3_model.summary()\n\nx=Flatten()(EfficientNetB3_model.output)\nx=Dense(1024, activation=\"relu\")(x)\nx=Dense(1024, activation=\"relu\")(x)\n# x=Dense(1024, activation=\"relu\")(x)\n# x=Dense(1024, activation=\"relu\")(x)\n\nx=Dropout(0.3)(x)\nx=Dense(512, activation=\"relu\")(x)\n# x=Dense(512, activation=\"relu\")(x)\n# x=Dense(512, activation=\"relu\")(x)\nx=Dropout(0.2)(x)\nx=Dense(256, activation=\"relu\")(x)\n# x=Dense(256, activation=\"relu\")(x)\nx=Dense(128, activation=\"relu\")(x)\nx=Dense(64, activation=\"relu\")(x)\noutput=Dense(4, activation=\"softmax\")(x)\n\nEfficientNetB3_model=Model(inputs=EfficientNetB3_model.input , outputs=output)\nEfficientNetB3_model.summary()\n\n#plot model\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\nplot_model(EfficientNetB3_model, show_shapes=True, show_layer_names=True , to_file=\"model.png\")\n","a4dd19b3":"len(EfficientNetB3_model.layers)","5ae9ef0c":"# cam_model=EfficientNetB3_model(inputs=EfficientNetB3_model.input , outputs=(EfficientNetB3_model.))","7fd06c32":"#callbacks\ncallbacks_EfficientNetB3=[\n    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\" , patience=5 , verbose=1),\n    tf.keras.callbacks.ModelCheckpoint(\"EfficientNetB3.h5\" , save_best_only=True),\n#     lr_rate\n    ]","71c35068":"# training EfficientNetB3 model\nEfficientNetB3_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001 ,  epsilon=1e-07) , \n              loss=tf.keras.losses.categorical_crossentropy , \n              metrics=[\"accuracy\"])\n\n\nEfficientNetB3_history=EfficientNetB3_model.fit(\n          train_generator, \n          epochs=20  , \n          steps_per_epoch=x_train.shape[0]\/batch_size ,\n          validation_data=val_generator ,callbacks=callbacks_EfficientNetB3,\n          verbose=1)","b2f7ac25":"print(\"- the Accuracy and Loss for EfficientNetB3 Model With 20 Epochs\")\nplt.figure(figsize=(40,20))\n\n# summarize history for accuracy\nplt.subplot(5,5,1)\nplt.plot(EfficientNetB3_history.history['accuracy'])\nplt.plot(EfficientNetB3_history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','validation'], loc='upper left')\n\n\n# summarize history for loss\nplt.subplot(5,5,2)\nplt.plot(EfficientNetB3_history.history['loss'])\nplt.plot(EfficientNetB3_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','loss'], loc='upper left')\nplt.show()","0a43e3db":"# EfficientNetB3_model.evaluate(train_generator),\nEfficientNetB3_model.evaluate(val_generator),EfficientNetB3_model.evaluate(train_generator)","e9ea033d":"#to download output files \nimport os\nos.chdir(r'..\/working')\nfrom IPython.display import FileLink\nFileLink(r'.\/EfficientNetB3.h5')                                                                ","d0a7fdc6":"#to download output files \nimport os\nos.chdir(r'..\/working')\nfrom IPython.display import FileLink\nFileLink(r'.\/denseNetModel.h5')  ","314f5a15":"# Class Activation Map","f973e65f":"# class activation map","d6bf2f56":"# denenet_model","1069ab28":"# combine scans","578b73d0":"EfficientNetB3 and densenet169\n","9272a314":"\u0628\u0639\u062f \u0645\u0627 \u0634\u0641\u062a \u0639\u062f\u0645 \u062a\u0648\u0627\u0632\u0646 \u0641\u064a \u0639\u064a\u0646\u0627\u062a \u0627\u0644\u0637\u0628\u064a\u0639\u064a\u0647 , \u0627\u0646\u0627 \u0647\u0636\u064a\u0641 \u062f\u0627\u062a\u0627 \u0633\u064a\u062a \u062a\u0627\u0646\u064a\u0647 \u0639\u0634\u0627\u0646 \u064a\u062d\u0635\u0644 \u0639\u0646\u062f\u064a \u062a\u0648\u0627\u0632\u0646 \u0628\u0634\u0643\u0644 \u0639\u0638\u064a\u0645 ","20e61127":"# Read data And Explore data","dfa037ce":"**all is done data prepareation and data preprocessing  on scans and labels**","feca7926":"add other non tumor to original non tumor scans","38d61fcc":"# Split dataset","7a67df06":"# EfficientNetB3_model","21bf1776":"should converte this labels to Categorical","7c1a0ee0":"# Let's see graph if there is balance in the data or not","311e69db":"# **Preprocessing on the images**","30b3b7b7":"* versions \n>version 1 with fixed lr densenet  val =98 , efficient val=97 with batch size 16 better result<br\/>\n> version 2 strat with LearningRateScheduler with 20 and 30 with batch size 16<br\/>\n> version 3 with LearningRateScheduler 50 epochs and scans size is 300 x 300 with batch size 16<br\/>\n>version 4 with LearningRateScheduler 20 epochs and scans size is 300 x 300 with batch size 8 eith efficient 20layer<br\/>","064f3bf6":"first after show these images , we can resize the all of these image in the same size","9bf2c543":"# resize images","46ddcfd3":"# import libraries\n","7884b4a4":"# Build Models"}}