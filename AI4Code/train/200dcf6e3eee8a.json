{"cell_type":{"6b687a81":"code","8e56a143":"code","9ef8d13c":"code","f8948971":"code","53a8ff79":"code","c7c7dd14":"code","f48e70b1":"code","c2756309":"code","6554936f":"code","be7da3e5":"code","aa824d4f":"markdown"},"source":{"6b687a81":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\n    '..\/input\/train.csv',\n    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})","8e56a143":"def fft_analysis(x: np.array, n=None, k=128, order=False) -> np.array:\n    \"\"\"\n    Perform an FFT op on a block of data.\n\n    Returns a tensor with shape (k, 3) where\n      0 - frequency\n      1 - amplitude\n      2 - phase\n    \"\"\"\n    if x.ndim > 1:\n        x = x.reshape(-1)\n    if n is None:\n        n = x.size\n    yf = np.fft.fft(x, n) * 1\/n\n    yf = yf[:n\/\/2]\n    if order:\n        sig = np.argsort(np.abs(yf))[-k:][::-1]\n    else:\n        sig = np.argpartition(np.abs(yf), -k)[-k:]\n    Y = np.empty((k, 3))\n    Y[:, 0] = sig # frequencies\n    yf_sig = yf[sig]\n    Y[:, 1] = 2.0 * np.abs(yf_sig) # amplitude\n    Y[:, 2] = np.angle(yf_sig) # phase\n    return Y\n\ndef feature_gen(x: np.array, strides=512, k=128) -> np.array:\n  \"\"\"\n  Given data block of 150_000 values, generate a set of 4k windows over the\n  data and get its FFT data.\n  \"\"\"\n  WINDOW = 4 * 1024\n  data = []\n  for i in range(x.shape[0] \/\/ strides):\n    begin = i * strides\n    end = begin + WINDOW\n    data.append(fft_analysis(x[begin:end], k=k))\n  return np.stack(data)","9ef8d13c":"from tensorflow import keras\n\nclass DataTrainTestSplit(object):\n    def __init__(self, df, sample_size, split=0.1):\n        n_samples = df.shape[0] \/\/ sample_size\n        perm = np.random.permutation(n_samples)\n        test_samples = int(np.floor(n_samples * split))\n        self.train_slice = perm[:-test_samples]\n        self.test_slice = perm[-test_samples:]\n    def train(self):\n        return self.train_slice\n    def test(self):\n        return self.test_slice\n        \nclass Generator(keras.utils.Sequence):\n  sample_size = 150_000\n  STRIDES = 2 * 1024\n  NDIMS = 128\n  STEPS = sample_size \/\/ STRIDES\n\n  def __init__(self, df, indices, batch_size=32):\n    self.dataframe = df\n    self.indices = indices\n    self.batch_size = batch_size\n\n  def __len__(self):\n    return int((self.indices.shape[0] - 1) \/ self.batch_size) + 1\n  \n  def __getitem__(self, index: int):\n    s_begin = index * self.batch_size\n    s_end = min(s_begin + self.batch_size, self.indices.shape[0])\n\n    X_list = []\n    y = np.empty((s_end - s_begin))\n    for m in range(s_begin, s_end):\n        begin = self.indices[m] * self.sample_size\n        end = begin + self.sample_size\n        X_list.append(\n            feature_gen(self.dataframe['acoustic_data'].values[begin:end],\n                        strides=Generator.STRIDES, k=Generator.NDIMS)\n        )\n        y[m - s_begin] = self.dataframe['time_to_failure'].iloc[end - 1]\n\n    X = np.stack(X_list)\n    return X, y","f8948971":"slices = DataTrainTestSplit(df, Generator.sample_size)","53a8ff79":"from tensorflow import keras\nimport tensorflow.keras.backend as K\n\nclass Decision(keras.layers.Layer):\n    \"\"\"\n    input_shape: (samples, channels)\n    output_shape: (samples, output_dim)\n    \"\"\"\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        self.activation = keras.activations.get('relu')\n        super(Decision, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.bias = self.add_weight(\n            shape=(self.output_dim,),\n            name='bias',\n            trainable=True)\n\n        self.u = self.add_weight(\n            shape=(int(input_shape[-1]), self.output_dim,),\n            name='u',\n            trainable=True)\n\n        self.v = self.add_weight(\n            shape=(self.output_dim, self.output_dim,),\n            name='v',\n            trainable=True)\n        super(Decision, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, x):\n        m = K.dot(self.activation(K.dot(x, self.u)), self.v)\n        output = K.bias_add(m, self.bias, data_format='channels_last')\n        pos = self.activation(output)\n        neg = output - pos\n        return [neg, pos]\n\n\n    def compute_output_shape(self, input_shape):\n        shape = input_shape\n        shape[-1] = self.output_dim\n        return [shape, shape]\n\n","c7c7dd14":"import tensorflow as tf\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, Sequential\n\ndef make_model():\n    inp = Input(shape=(Generator.STEPS, Generator.NDIMS, 3))\n\n    h1_outs = Decision(64)(inp)\n    h2_outs = []\n    for h1 in h1_outs:\n        h2_outs.extend(Decision(16)(h1))\n\n    h2_out = Concatenate(axis=3)(h2_outs)\n\n    h2_mix = Dense(32)(h2_out)\n\n    h3_out = MaxPooling2D((1, Generator.NDIMS))(h2_mix)\n    h3_out = Reshape((Generator.STEPS, 32,))(h3_out)\n\n    common = LSTM(128)(h3_out)\n    outp = Dense(1)(common)\n\n    return Model(inp, outp)\n\nmodel = make_model()\nmodel.compile(optimizer='adam', loss='mse', metrics=['mae'])\nmodel.summary()","f48e70b1":"filepath=\"model.ckpt.hdf5\"\ncb_checkpoint = keras.callbacks.ModelCheckpoint(\n    filepath, monitor='val_mean_absolute_error',\n    save_best_only=True, mode='min')\n\ncb_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nhistory = model.fit_generator(Generator(df, slices.train(), batch_size=64),\n                              validation_data=Generator(df, slices.test()),\n                              callbacks=[cb_stop, cb_checkpoint],\n                              epochs=100)\n\n","c2756309":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend()\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.plot()\n\nplt.figure()\nplt.plot(history.history['mean_absolute_error'], label='mae')\nplt.plot(history.history['val_mean_absolute_error'], label='val_mae')\nplt.legend()\nplt.title('Mean Absolute Error')\nplt.ylabel('Error')\nplt.xlabel('Epoch')\nplt.plot()\n\n","6554936f":"model.load_weights('model.ckpt.hdf5')","be7da3e5":"from tqdm import tqdm_notebook\n\nsubmission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id', dtype={'time_to_failure': np.float32})\n\nfor seg_id in tqdm_notebook(submission.index):\n    seg = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    X = feature_gen(seg['acoustic_data'].values, strides=Generator.STRIDES, k=Generator.NDIMS)\n    y = model.predict(X[np.newaxis, :])\n    submission.loc[seg_id]['time_to_failure'] = y\nsubmission.to_csv('submission.csv')","aa824d4f":"According to the dataset description, the acoustic data is sampled in blocks of 4k samples. A test data block is 150_000 samples long and doesn't necessarily start \/ end at a 4k sample threshold."}}