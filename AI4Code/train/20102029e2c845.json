{"cell_type":{"3dea6e2f":"code","3334d8d0":"code","a8c8e845":"code","6d45eb8d":"code","58fa6eba":"code","8b1223a5":"code","f7ded8f1":"code","cf2aab01":"code","c10f28ac":"code","6488f09b":"code","ca87df4c":"code","18b96fda":"code","fe935b1f":"code","a62750fd":"code","370d6d9b":"code","70ddbb4a":"code","84169ff2":"code","ceea2284":"code","194b345d":"code","3d433daf":"code","879c47a3":"code","9b33b242":"code","03d77f14":"code","89ddfd19":"code","683f31d7":"code","2a07b178":"code","b407b725":"code","4b42a9b6":"code","75fa9075":"code","cc1599a7":"code","6eb5564b":"code","c79e52ad":"code","de7ddbc7":"code","fb9fe810":"code","db855c77":"code","45a363d3":"code","05e00a83":"code","2e0d35de":"code","ceedb1a8":"code","69a4eccf":"code","18b4db71":"code","ff568a38":"code","9f6cad7c":"code","1fad2327":"code","4e9659e4":"code","2546a217":"code","5892bed6":"code","53806892":"code","a9eadd7e":"code","da13eb14":"code","2d088346":"code","3af13728":"code","d5d29abe":"code","d7c15b91":"code","00cffff1":"code","30dfd643":"code","0f2d3069":"code","8e7ab18d":"code","74a2d23f":"code","7518d415":"code","74e5597b":"code","8ec71299":"code","c6b813a2":"code","c89a3b0f":"code","3f851c80":"code","f712978d":"code","2832c54e":"code","19dfc1ef":"markdown","be710706":"markdown","050d23fc":"markdown","c4da3052":"markdown","c83df6ae":"markdown","6c94715a":"markdown","b75980f7":"markdown","1ccfee23":"markdown","fdc21ca3":"markdown","6f4feb42":"markdown","63c7417c":"markdown","187c1aa7":"markdown","b6c7f69c":"markdown","1b4bc27e":"markdown","fc301fc3":"markdown","c542a55b":"markdown","369b7bd3":"markdown","f57b332d":"markdown","711d8c4f":"markdown","876feb6e":"markdown","2ac0bf89":"markdown","bfd506bc":"markdown","cfd43809":"markdown","20f3235d":"markdown","12f71d5b":"markdown","53da0943":"markdown","12ba5ac7":"markdown","28a5a800":"markdown","3fc1ab7a":"markdown","32907aff":"markdown","a09995e7":"markdown","dd0b7b13":"markdown","b8d0aff5":"markdown","a0becbe1":"markdown"},"source":{"3dea6e2f":"#!pip install pmdarima","3334d8d0":"import pandas as pd\nimport numpy as np\nfrom pandas import datetime\nfrom matplotlib import pyplot as plt\nimport os\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom matplotlib import pyplot\nfrom pandas.tools.plotting import autocorrelation_plot\n\n#from pyramid.arima import auto_arima\n#from pmdarima.arima import auto_arima\nimport pyflux as pf\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport statsmodels.api as sm\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\nimport math\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\n","a8c8e845":"# Combining all blocks\nfor num in range(0,112):\n    df = pd.read_csv(\"..\/input\/daily_dataset\/daily_dataset\/block_\"+str(num)+\".csv\")\n    df = df[['day','LCLid','energy_sum']]\n    df.reset_index()\n    df.to_csv(\"hc_\"+str(num)+\".csv\")\n\nfout= open(\"energy.csv\",\"a\")\n# first file:\nfor line in open(\"hc_0.csv\"):\n    fout.write(line)\n# now the rest:    \nfor num in range(0,112):\n    f = open(\"hc_\"+str(num)+\".csv\")\n    f.readline() # skip the header\n    for line in f:\n         fout.write(line)\n    f.close()\nfout.close()","6d45eb8d":"energy = pd.read_csv('energy.csv')\nlen(energy)","58fa6eba":"housecount = energy.groupby('day')[['LCLid']].nunique()\nhousecount.head(4)","8b1223a5":"housecount.plot(figsize=(25,5))","f7ded8f1":"energy = energy.groupby('day')[['energy_sum']].sum()\nenergy = energy.merge(housecount, on = ['day'])\nenergy = energy.reset_index()","cf2aab01":"energy.count()","c10f28ac":"energy.day = pd.to_datetime(energy.day,format='%Y-%m-%d').dt.date","6488f09b":"energy['avg_energy'] =  energy['energy_sum']\/energy['LCLid']\nprint(\"Starting Point of Data at Day Level\",min(energy.day))\nprint(\"Ending Point of Data at Day Level\",max(energy.day))","ca87df4c":"energy.describe()","18b96fda":"weather = pd.read_csv('..\/input\/weather_daily_darksky.csv')\nweather.head(4)","fe935b1f":"weather.describe()","a62750fd":"weather['day']=  pd.to_datetime(weather['time']) # day is given as timestamp\nweather['day']=  pd.to_datetime(weather['day'],format='%Y%m%d').dt.date\n# selecting numeric variables\nweather = weather[['temperatureMax', 'windBearing', 'dewPoint', 'cloudCover', 'windSpeed',\n       'pressure', 'apparentTemperatureHigh', 'visibility', 'humidity',\n       'apparentTemperatureLow', 'apparentTemperatureMax', 'uvIndex',\n       'temperatureLow', 'temperatureMin', 'temperatureHigh',\n       'apparentTemperatureMin', 'moonPhase','day']]\nweather = weather.dropna()","370d6d9b":"weather_energy =  energy.merge(weather,on='day')\nweather_energy.head(2)","70ddbb4a":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.temperatureMax, color = 'tab:orange')\nax1.plot(weather_energy.day, weather_energy.temperatureMin, color = 'tab:pink')\nax1.set_ylabel('Temperature')\nax1.legend()\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nax2.legend(bbox_to_anchor=(0.0, 1.02, 1.0, 0.102))\nplt.title('Energy Consumption and Temperature')\nfig.tight_layout()\nplt.show()\n","84169ff2":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.humidity, color = 'tab:orange')\nax1.set_ylabel('Humidity',color = 'tab:orange')\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nplt.title('Energy Consumption and Humidity')\nfig.tight_layout()\nplt.show()","ceea2284":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.cloudCover, color = 'tab:orange')\nax1.set_ylabel('Cloud Cover',color = 'tab:orange')\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nplt.title('Energy Consumption and Cloud Cover')\nfig.tight_layout()\nplt.show()","194b345d":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.visibility, color = 'tab:orange')\nax1.set_ylabel('Visibility',color = 'tab:orange')\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nplt.title('Energy Consumption and Visibility')\nfig.tight_layout()\nplt.show()","3d433daf":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.windSpeed, color = 'tab:orange')\nax1.set_ylabel('Wind Speed',color = 'tab:orange')\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nplt.title('Energy Consumption and Wind Speed')\nfig.tight_layout()\nplt.show()","879c47a3":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.uvIndex, color = 'tab:orange')\nax1.set_ylabel('UV Index',color = 'tab:orange')\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nplt.title('Energy Consumption and UV Index')\nfig.tight_layout()\nplt.show()","9b33b242":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(weather_energy.day, weather_energy.dewPoint, color = 'tab:orange')\nax1.set_ylabel('Dew Point',color = 'tab:orange')\nax2 = ax1.twinx()\nax2.plot(weather_energy.day,weather_energy.avg_energy,color = 'tab:blue')\nax2.set_ylabel('Average Energy\/Household',color = 'tab:blue')\nplt.title('Energy Consumption and Dew Point')\nfig.tight_layout()\nplt.show()","03d77f14":"cor_matrix = weather_energy[['avg_energy','temperatureMax','dewPoint', 'cloudCover', 'windSpeed','pressure', 'visibility', 'humidity','uvIndex', 'moonPhase']].corr()\ncor_matrix","89ddfd19":"#scaling\nscaler = MinMaxScaler()\nweather_scaled = scaler.fit_transform(weather_energy[['temperatureMax','humidity','windSpeed']])","683f31d7":"# optimum K\nNc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in Nc]\nkmeans\n\nscore = [kmeans[i].fit(weather_scaled).score(weather_scaled) for i in range(len(kmeans))]\nscore\nplt.plot(Nc,score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve')\nplt.show()","2a07b178":"kmeans = KMeans(n_clusters=3, max_iter=600, algorithm = 'auto')\nkmeans.fit(weather_scaled)\nweather_energy['weather_cluster'] = kmeans.labels_","b407b725":"# Cluster Relationships with weather variables\nplt.figure(figsize=(20,5))\nplt.subplot(1, 3, 1)\nplt.scatter(weather_energy.weather_cluster,weather_energy.temperatureMax)\nplt.title('Weather Cluster vs. Temperature')\nplt.subplot(1, 3, 2)\nplt.scatter(weather_energy.weather_cluster,weather_energy.humidity)\nplt.title('Weather Cluster vs. Humidity')\nplt.subplot(1, 3, 3)\nplt.scatter(weather_energy.weather_cluster,weather_energy.windSpeed)\nplt.title('Weather Cluster vs. WindSpeed')\n\nplt.show()\n# put this in a loop","4b42a9b6":"fig, ax1 = plt.subplots(figsize = (10,7))\nax1.scatter(weather_energy.temperatureMax, \n            weather_energy.humidity, \n            s = weather_energy.windSpeed*10,\n            c = weather_energy.weather_cluster)\nax1.set_xlabel('Temperature')\nax1.set_ylabel('Humidity')\nplt.show()","75fa9075":"holiday = pd.read_csv('..\/input\/uk_bank_holidays.csv')\nholiday['Bank holidays'] = pd.to_datetime(holiday['Bank holidays'],format='%Y-%m-%d').dt.date\nholiday.head(4)","cc1599a7":"weather_energy = weather_energy.merge(holiday, left_on = 'day',right_on = 'Bank holidays',how = 'left')\nweather_energy['holiday_ind'] = np.where(weather_energy['Bank holidays'].isna(),0,1)","6eb5564b":"weather_energy['Year'] = pd.DatetimeIndex(weather_energy['day']).year  \nweather_energy['Month'] = pd.DatetimeIndex(weather_energy['day']).month\nweather_energy.set_index(['day'],inplace=True)","c79e52ad":"model_data = weather_energy[['avg_energy','weather_cluster','holiday_ind']]\n# train = model_data.iloc[0:round(len(model_data)*0.90)]\n# test = model_data.iloc[len(train)-1:]\ntrain = model_data.iloc[0:(len(model_data)-30)]\ntest = model_data.iloc[len(train):(len(model_data)-1)]","de7ddbc7":"train['avg_energy'].plot(figsize=(25,4))\ntest['avg_energy'].plot(figsize=(25,4))\n","fb9fe810":"test.head(1)","db855c77":"plot_acf(train.avg_energy,lags=100)\nplt.show()","45a363d3":"plot_pacf(train.avg_energy,lags=50)\nplt.show()","05e00a83":"t = sm.tsa.adfuller(train.avg_energy, autolag='AIC')\npd.Series(t[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])","2e0d35de":"# function for differencing\ndef difference(dataset, interval):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset.iloc[i] - dataset.iloc[i - interval]\n        diff.append(value)\n    return diff","ceedb1a8":"t  = sm.tsa.adfuller(difference(train.avg_energy,1), autolag='AIC')\npd.Series(t[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])","69a4eccf":"s = sm.tsa.seasonal_decompose(train.avg_energy,freq=12)","18b4db71":"s.seasonal.plot(figsize=(20,5))","ff568a38":"s.trend.plot(figsize=(20,5))","9f6cad7c":"s.resid.plot(figsize=(20,5))","1fad2327":"endog = train['avg_energy']\nexog = sm.add_constant(train[['weather_cluster','holiday_ind']])\n\nmod = sm.tsa.statespace.SARIMAX(endog=endog, exog=exog, order=(7,1,1),seasonal_order=(1,1, 0, 12),trend='c')\nmodel_fit = mod.fit()\nmodel_fit.summary()","4e9659e4":"train['avg_energy'].plot(figsize=(25,10))\nmodel_fit.fittedvalues.plot()\nplt.show()","2546a217":"predict = model_fit.predict(start = len(train),end = len(train)+len(test)-1,exog = sm.add_constant(test[['weather_cluster','holiday_ind']]))\ntest['predicted'] = predict.values\ntest.tail(5)","5892bed6":"test['residual'] = abs(test['avg_energy']-test['predicted'])\nMAE = test['residual'].sum()\/len(test)\nMAPE = (abs(test['residual'])\/test['avg_energy']).sum()*100\/len(test)\nprint(\"MAE:\", MAE)\nprint(\"MAPE:\", MAPE)","53806892":"test['avg_energy'].plot(figsize=(25,10),color = 'red')\ntest['predicted'].plot()\nplt.show()","a9eadd7e":"model_fit.resid.plot(figsize= (30,5))","da13eb14":"model_fit.fittedvalues.plot(figsize = (30,5))\ntest.predicted.plot()","2d088346":"test['predicted'].tail(5)","3af13728":"np.random.seed(11)\ndataframe = weather_energy.loc[:,'avg_energy']\ndataset = dataframe.values\ndataset = dataset.astype('float32')","d5d29abe":"# convert series to supervised learning\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg","d7c15b91":"reframed = series_to_supervised(dataset, 7,1)\nreframed.head(3)","00cffff1":"reframed['weather_cluster'] = weather_energy.weather_cluster.values[7:]\nreframed['holiday_ind']= weather_energy.holiday_ind.values[7:]","30dfd643":"reframed = reframed.reindex(['weather_cluster', 'holiday_ind','var1(t-7)', 'var1(t-6)', 'var1(t-5)', 'var1(t-4)', 'var1(t-3)','var1(t-2)', 'var1(t-1)', 'var1(t)'], axis=1)\nreframed = reframed.values","0f2d3069":"scaler = MinMaxScaler(feature_range=(0, 1))\nreframed = scaler.fit_transform(reframed)","8e7ab18d":"# split into train and test sets\ntrain = reframed[:(len(reframed)-30), :]\ntest = reframed[(len(reframed)-30):len(reframed), :]","74a2d23f":"train_X, train_y = train[:, :-1], train[:, -1]\ntest_X, test_y = test[:, :-1], test[:, -1]","7518d415":"# reshape input to be 3D [samples, timesteps, features]\ntrain_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\ntest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)","74e5597b":"# design network\nmodel = Sequential()\nmodel.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam')\n# fit network\nhistory = model.fit(train_X, train_y, epochs=50, batch_size=72, verbose=2, shuffle=False)\n# plot history\npyplot.plot(history.history['loss'], label='train')\npyplot.legend()\npyplot.show()","8ec71299":"# make a prediction\nyhat = model.predict(test_X)","c6b813a2":"test_X = test_X.reshape(test_X.shape[0], test_X.shape[2])","c89a3b0f":"# invert scaling for forecast\ninv_yhat = np.concatenate((yhat, test_X), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)","3f851c80":"# invert scaling for actual\ntest_y = test_y.reshape((len(test_y), 1))\ninv_y = np.concatenate((test_y, test_X), axis=1)\ninv_y = scaler.inverse_transform(inv_y)","f712978d":"act = [i[9] for i in inv_y] # last element is the predicted average energy\npred = [i[9] for i in inv_yhat] # last element is the actual average energy\n\n# calculate RMSE\nimport math\nrmse = math.sqrt(mean_squared_error(act, pred))\nprint('Test RMSE: %.3f' % rmse)","2832c54e":"predicted_lstm = pd.DataFrame({'predicted':pred,'avg_energy':act})\npredicted_lstm['avg_energy'].plot(figsize=(25,10),color = 'red')\npredicted_lstm['predicted'].plot(color = 'blue')\nplt.show()","19dfc1ef":"# Energy Consumption\nTo better follow the energy consumption, the government wants energy suppliers to install smart meters in every home in England, Wales and Scotland. There are more than 26 million homes for the energy suppliers to get to, with the goal of every home having a smart meter by 2020.\n\nThis roll out of meter is lead by the European Union who asked all member governments to look at smart meters as part of measures to upgrade our energy supply and tackle climate change. After an initial study, the British government decided to adopt smart meters as part of their plan to update our ageing energy system.\n\nIn this dataset, you will find a refactorised version of the data from the London data store, that contains the energy consumption readings for a sample of 5,567 London Households that took part in the UK Power Networks led Low Carbon London project between November 2011 and February 2014. The data from the smart meters seems associated only to the electrical consumption.\n\n**Approach : **\n\n1.  Combine all blocks into a single dataframe- keeping on relevant columns.\n2. Use day-level energy consumption data per household to normalize data for inconsistent household count\n3. Explore relationships between weather conditions and energy consumptions. Create clusters for the weather data- using which we can add weather identifiers to day-level data\n4. Add UK holidays data to the day level data as an indicator.\n5. Fit an ARIMA model\n        i) ACF, PACF\n        ii) Explore Seasonal Decomposition\n        iii) Modelling \n7. Fit an LSTM model","be710706":"**Prediction**","050d23fc":"**Creating a holiday indicator on weather data**","c4da3052":"### Correlation between Weather Variables and Energy Consumption\n* Energy has high positive correlation with humidity and high negative correlation with temperature.\n* Dew Point, UV Index display multicollinearity with Temperature, hence discarded\n* Cloud Cover and Visibility display multicollinearity with Humidity, hence discarded\n* Pressure and Moon Phase have minimal correlation with Energy, hence discarded\n* Wind Speed has low correlation with energy but does not show multicollinearity\n","c83df6ae":"***4. Visibility***\n> The visibility factor does not seem to affect energy consumption at all- since visibility is most likely an outdoors factor, it is unlikely that it's increase or decrease affects energy consumption within a household.","6c94715a":"***3. Cloud Cover***\n> The cloud cover value seems to be following the same pattern as the energy consumption.","b75980f7":" *** 1. Temperature ***\n> We can see that energy and temperature have an inverse relationship-we can see the peaks in one appearing with troughs in the other. This confirms the business intuition that during low temperature, it is likely that the energy consumption through heaters etc. increases. ","1ccfee23":"***7. dewPoint***\n> Dew Point- is a function of humidity and temperature therefore it displays similar relation to energy consumption.","fdc21ca3":"### Energy Data\n\n> We are predicting for energy demand in the future- therefore we are taking only energy sum i.e. total energy use per day for a given household.","6f4feb42":"**Normalization**","63c7417c":"**House Count**\n> In the dataset we see that the number of households for which energy data was collected across different days are different. This is probably due to the gradually increasing adoption of smart meters in London.  This could lead to false interpretation that the energy for a particular day might be high when it could be that the data was only collected for more number of houses. We will look at the house count for each day.  ","187c1aa7":"### ARIMAX","b6c7f69c":"**Modelling**","1b4bc27e":"**Importing Libraries **","fc301fc3":"### LSTM","c542a55b":"***5.  Wind Speed***\n>  Like visibility, wind speed seems to be an outdoors factor which does not affect in the energy consumption as such.","369b7bd3":"# Daily Energy Data Preparation","f57b332d":"***6.  UV Index***\n> The UV index has an inverse relationship with energy consumption- why?","711d8c4f":"### Creating Weather Clusters \n> The weather information has a lot of variables- which might not all be useful. We will attempt to create weather clusters to see if we can define a weather of the day based on the granular weather data like temperature, precipitation etc. ","876feb6e":"**ACF PACF **","2ac0bf89":"***2.  Humidity ***\n\n>  Humidity and the average consumption of energy seems to have the same trend.\n","bfd506bc":"### Relationship of weather conditions with electricity consumption","cfd43809":"** Energy at Day Level **","20f3235d":"**Prediction**","12f71d5b":"**Dickey Fuller's Test**\n> p is greater than 0.05 therefore the data is not stationary. After differencing, p < 0.05.","53da0943":"** Subset for required columns and 70-30 train-test split**","12ba5ac7":"## Weather Information\nDaily level weather information is taken using darksky api in the dataset[](http:\/\/)","28a5a800":"**Seasonal Decomposition**\n> The seasonal component is quite low while the trend is quite strong with obvious dips in electricity consumption during summers i.e. April to September. This may be attributed to longer days during summer.","3fc1ab7a":"**Model Fit**","32907aff":"Autocorrelation plot shows gradual decay while Partial AutoCorrelation shows that there is a sharp drop after 1st lag. This means that most of the higher-order autocorrelations are effectively explained by the k = 1 lag. Therefore, the series displays AR 'signature' ","a09995e7":"### UK Bank Holidays","dd0b7b13":"Using lags of upto 7 days we are going to convert this into a supervised problem. I have taken the function to create lags from this [tutorial](http:\/\/machinelearningmastery.com\/convert-time-series-supervised-learning-problem-python\/) by Jason Brownlee. He has also applied the same to convert multivariate data to a supervised dataframe which he has in turn applied LSTM on.","b8d0aff5":"**Normalization across households**\n> The data collection across households are inconsistent- therefore we will be using *energy per household* as the target to predict rather than energy alone. This is an optional step as we can also predict for energy sum as whole for each household. However there are quite a lot of unique households for which we have to repeat the exercise and our ultimate goal is to predict overall consumption forecast and not at household level.  \nThis also means that since household level is removed, we are not looking into the ACORN details which is available at household level","a0becbe1":"**Performance**"}}