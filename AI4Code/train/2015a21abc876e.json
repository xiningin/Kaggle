{"cell_type":{"d6f19622":"code","42c0700e":"code","fda153c0":"code","48330581":"code","4a158b2e":"code","d3f00b6c":"code","863fd846":"code","ee8f9447":"code","c8c5a860":"code","b1e94bae":"code","a427e402":"code","273c7ceb":"code","583f2414":"code","e78ea4bc":"code","546e08b7":"code","725febe0":"code","98f57314":"code","94f5d52b":"code","e7dce873":"code","f1c71ee9":"code","b031980c":"code","2def4e02":"code","9a8a4c52":"code","1802d0dc":"code","36a69aa5":"code","51c1f859":"code","1c7c86e9":"code","d8330f81":"code","a131523f":"code","296152ff":"markdown","734c5b59":"markdown","6b8898c6":"markdown","a4785bb2":"markdown","07e1e24b":"markdown","de3743e8":"markdown","72a35e89":"markdown","68960acf":"markdown","65a86c37":"markdown"},"source":{"d6f19622":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, plot_roc_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import plot_importance\nimport xgboost as xg\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set_theme(style =  \"whitegrid\")","42c0700e":"PATH = \"\/kaggle\/input\/blog-or-not-dataset\/blogOrNotDataset.csv\"\ndata = pd.read_csv(PATH)","fda153c0":"data.shape","48330581":"data.head()","4a158b2e":"def plotTargetCounts(data,\n                     target):\n    ###\n    ### Plots value counts of target feature as bar plot for better analysis\n    ### @params = {data: dataset to examine, target: target feature for plotting}\n    ###\n    target = data[target].value_counts()\n    plt.figure(figsize = (12,8))\n    sns.barplot(x = target.keys(),\n                y = target.values)\n    plt.show()\n\nplotTargetCounts(data, \"is_blog\")","d3f00b6c":"data = data[data[\"is_blog\"] != \"is_blog\"]\ndata[\"is_blog\"] = data[\"is_blog\"].astype(int)\nplotTargetCounts(data, \"is_blog\")","863fd846":"data[\"is_blog\"].value_counts()","ee8f9447":"data.drop(data[data[\"is_blog\"] == 1].index.tolist()[-42000:],\n         axis = 0,\n         inplace = True)","c8c5a860":"plotTargetCounts(data, \"is_blog\")","b1e94bae":"data[\"is_blog\"].value_counts()","a427e402":"data.isna().sum()","273c7ceb":"pd.DataFrame(data.isna().sum() ,\n             columns=[\"naCount\"]).\\\n             reset_index().\\\n             rename(columns = {\"index\" : \"columnName\" }).\\\n             sort_values(by = \"naCount\")","583f2414":"colsForOutlierAnalyze = [col for col in data.columns if len(data[col].value_counts().keys()) > 100]\ncolsForOutlierAnalyze","e78ea4bc":"def boxPlot(data, colsForOutlierAnalyze):\n## \n## Boxplots for detect outlier values\n## @params = {data: dataset for analyze, colsForOutlierAnalyze: Numeric columns in dataset}\n##\n    plt.subplots(nrows = 3,\n              ncols = 1,\n              figsize = (15,15))\n    for i in range(len(colsForOutlierAnalyze)):\n        plt.subplot(3,1,i+1)\n        sns.boxplot(x = \"is_blog\", y = colsForOutlierAnalyze[i], data = data)\n  #plt.title(colsForOutlierAnalyze[i])\n#boxPlot(data, colsForOutlierAnalyze)","546e08b7":"data.dtypes","725febe0":"for column in data.columns[1:]:\n    data[column] = data[column].astype(int)","98f57314":"data = data.sample(frac=1).reset_index(drop=True) ## Need to shuffle dataset","94f5d52b":"def trainTestSplitData(data, trainLen, valLen):\n##\n## Splits data for train (Model Training) and test (Model Evaluating)\n## @params = {data: data for split, testLen: train data ratio}\n## @returns = {x_train, x_test, y_train, y_test, x_val, y_val : base and target data for model}\n##\n    X = data.drop([\"is_blog\", \"url\"], \n                  axis = 1)\n    y = data[\"is_blog\"]\n    urls = data[\"url\"]\n    trainLen = int(data.shape[0] * trainLen)\n    valLen = trainLen - int(trainLen * valLen)  \n    x_train, x_test, y_train, y_test, test_urls = X[:trainLen], X[trainLen:], y[:trainLen], y[trainLen:], urls[trainLen:]\n    x_train, x_val, y_train, y_val = x_train[:valLen], x_train[valLen:], y_train[:valLen], y_train[valLen:]\n    del X\n    del y\n    return x_train, x_test, x_val, y_train, y_test, y_val, test_urls","e7dce873":"x_train, x_test, x_val, y_train, y_test, y_val, test_urls = trainTestSplitData(data, 0.8, 0.15)","f1c71ee9":"print(f\"Train Data Shape: {x_train.shape} Train Target Shape: {y_train.shape}\")\nprint(f\"Validation Data Shape: {x_val.shape} Validation Target Shape: {y_val.shape}\")\nprint(f\"Test Data Shape: {x_test.shape} Test Target Shape: {y_test.shape}\")","b031980c":"def gridSearchCrossValidation(tunedParams,\n                              scores,\n                              x_train,\n                              x_val,\n                              y_train,\n                              y_val,\n                              modelType = \"KNN\"\n                              ):\n    ###\n    ### Cross Validation for test model metric and hyper-parameter tuning\n    ### @params = {tunedParams: hyper-parameters for dataset, scores: accuracy metrics, x_train\/y_train\/x_val\/y_val: datasets, modelType: algorithm type (KNN, RF, XGB)}\n    ###\n    for score in scores:\n        print(f\"Hyper-Parameter Tuning for {score}\")\n        if modelType == \"KNN\":\n            model = GridSearchCV(KNeighborsClassifier(),\n                       tunedParams,\n                       scoring = f\"{score}_macro\")\n        elif modelType == \"RF\":\n            model = GridSearchCV((RandomForestClassifier()),\n                       tunedParams,\n                       scoring = f\"{score}_macro\")\n        elif modelType == \"XGB\":\n            model = GridSearchCV(xg.XGBClassifier(),\n                       tunedParams,\n                       scoring = f\"{score}_macro\")\n        \n        model.fit(x_train, y_train)\n        print(\"Best parameters set found on development set:\")\n        print(model.best_params_)\n        print(\"Grid scores on development set:\")\n        means = model.cv_results_['mean_test_score']\n        stds = model.cv_results_['std_test_score']\n        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n            print(\"%0.3f (+\/-%0.03f) for %r\"\n                  % (mean, std * 2, params))\n        print(\"Detailed classification report:\")\n        y_true, y_pred = y_val, model.predict(x_val)\n        print(classification_report(y_true, y_pred))","2def4e02":"tunedParams = [{\"n_neighbors\": [3,5,7],\n                \"weights\": [\"uniform\", \"distance\"],\n                \"p\": [1,2]}]\nscores = [\"precision\", \"recall\"]\ngridSearchCrossValidation(tunedParams,\n                          scores,\n                          x_train,\n                          x_val,\n                          y_train,\n                          y_val,\n                          modelType = \"KNN\")","9a8a4c52":"tunedParams = [{\"n_estimators\": [10, 50, 100],\n                \"criterion\": [\"gini\", \"entropy\"],\n                \"max_features\": [\"auto\", \"sqrt\", \"log2\"]}]\nscores = [\"precision\", \"recall\"]\ngridSearchCrossValidation(tunedParams,\n                          scores,\n                          x_train,\n                          x_val,\n                          y_train,\n                          y_val,\n                          modelType = \"RF\")","1802d0dc":"tunedParams = [{\"min_child_weight\": [5, 10],\n                \"colsample_bytree\": [0.6, 0.8]}]\nscores = [\"precision\", \"recall\"]\ngridSearchCrossValidation(tunedParams,\n                          scores,\n                          x_train,\n                          x_val,\n                          y_train,\n                          y_val,\n                          modelType = \"XGB\")","36a69aa5":"model = xg.XGBClassifier(colsample_bytree =  0.6, \n                         min_child_weight = 5)\nmodel.fit(x_train, y_train)","51c1f859":"plt.figure(figsize= (20,20))\nplot_roc_curve(model, x_test, y_test)\nplt.title(\"Roc Curve\")\nplt.show()","1c7c86e9":"plot_importance(model, max_num_features=10) # top 10 most important features\nplt.show()","d8330f81":"predicts = model.predict(x_test)\npredictionData = {\"Index\": test_urls,\n                      \"Actual\": y_test,\n                      \"Prediction\": predicts}\npredictionData = pd.DataFrame(predictionData)\npredictionData","a131523f":"def getClassAccuracies(predictionData):\n    ###\n    ### Gets accuracies of model for all unique classes\n    ### @params = {predictionaData: Preproccessed data cols = [\"Index\", \"Actual\", \"Prediction\"]}\n    ###\n    positives = predictionData[predictionData[\"Actual\"] == 1]\n    posRatio = ((positives[\"Actual\"] == positives[\"Prediction\"]).sum() \/ positives.shape[0]) * 100\n    negatives = predictionData[predictionData[\"Actual\"] == 0]\n    negRatio = ((negatives[\"Actual\"] == negatives[\"Prediction\"]).sum() \/ negatives.shape[0]) * 100\n    print(f\"Model Accuracy for predict blogs: {posRatio}\\nModel Accuracy for predict non-blogs: {negRatio}\")\ngetClassAccuracies(predictionData)","296152ff":"## Missing Values","734c5b59":"# Import Libraries \/ Load Data","6b8898c6":"# Data Analysis","a4785bb2":"# Model Evaluation","07e1e24b":"## Target Analysis","de3743e8":"# Model Selection","72a35e89":"# Train-Test Split","68960acf":"## Dtypes","65a86c37":"## Outlier Analysis"}}