{"cell_type":{"bd80cb88":"code","66fc0369":"code","fa720b6c":"code","2badbd13":"code","ce652cd1":"code","32ab9a1c":"code","eec20d5e":"code","74f9d2fe":"code","b3929422":"code","7fcf42d7":"code","05b31202":"code","d89db074":"code","9aa1e5e1":"code","edfcb79b":"code","34cfc175":"code","bc692e97":"code","486d84ac":"code","c63601f9":"code","5520bc03":"code","edc624af":"code","d9a3f555":"code","b24da62d":"code","b8897644":"code","9a0354e9":"code","68e3e472":"code","a97ec2f3":"code","b2399202":"code","b638be77":"code","ad93a456":"code","e964803f":"code","3472a559":"code","3c7f093e":"code","1473352f":"code","7516cd21":"code","4c6d3cc2":"code","c0e391b1":"code","7930d328":"code","be6daad3":"code","c72500a3":"code","8a9eef1d":"code","9ade9d54":"code","7f102a97":"code","6b31821c":"code","b2d0eb50":"code","6a038af7":"code","1160318b":"code","3a90a32e":"code","3de12c8a":"code","615e241f":"code","6defaf05":"code","83fd87d3":"code","a615cb4c":"code","55ca21c2":"code","0a4c2801":"code","739e35c1":"code","5b7e6c8c":"code","a5a12d42":"code","72fcccf2":"code","b1f77b24":"code","7ed71cd4":"code","b2b0c0c1":"code","d30379c3":"markdown","0c794f12":"markdown","4c601476":"markdown","b6a55f28":"markdown","070dcc3b":"markdown","0a4cdb94":"markdown","0c58b7ab":"markdown","d67e5a11":"markdown","d9ad4af8":"markdown","607db3c1":"markdown","b782d588":"markdown","5c526355":"markdown","54519d85":"markdown","d78e7aa3":"markdown","7059ef27":"markdown","6fbc1f03":"markdown","15215d6b":"markdown","1d30b351":"markdown","22ce4d26":"markdown","8a681ab1":"markdown","b0f70531":"markdown","3ba6ec85":"markdown","5ee56cda":"markdown","dfe9a531":"markdown","9b218662":"markdown","0938bc63":"markdown","6a5ea726":"markdown","9c3f3bb4":"markdown","51fc1921":"markdown","64e8f3d3":"markdown","4f21a054":"markdown","19e8b023":"markdown","48aca970":"markdown","c9569d1c":"markdown","2e24581b":"markdown","7934fbb2":"markdown","1bd4ee16":"markdown","99a04152":"markdown"},"source":{"bd80cb88":"from IPython.display import Image\nImage(\"..\/input\/databaseschema\/DataBase_schema.png\")","66fc0369":"import os\nprint(os.listdir('..\/input\/open-university-learning-analytics-dataset'))","fa720b6c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport seaborn as sns\n\n\nassessments = pd.read_csv('..\/input\/open-university-learning-analytics-dataset\/assessments.csv')\nstudent_assessment = pd.read_csv('..\/input\/open-university-learning-analytics-dataset\/studentAssessment.csv')\nstudent_info = pd.read_csv('..\/input\/open-university-learning-analytics-dataset\/studentInfo.csv')\nvle_activity = pd.read_csv('..\/input\/open-university-learning-analytics-dataset\/studentVle.csv')\n\n#we only need code_module so that we can perform a join with studenAssessment and then studentInfo tables\nassessments.drop(['code_presentation','assessment_type','date','weight'], axis = 1, inplace = True)\n#assessments.code_module.value_counts()","2badbd13":"#merge individual assessments data with assessment data, so that we know which module each assessment belongs to\ncomb_assess = pd.merge(student_assessment,assessments,on='id_assessment')\ncomb_assess.drop(['is_banked','date_submitted'],axis = 1,inplace=True)\ncomb_assess.dtypes","ce652cd1":"#clean some of the data - we don't want score as a string, we want it as an integer. So let's remove the ?\n#comb_assess.drop(comb_assess[comb_assess.score == '?'].index, inplace = True);\n#comb_assess.score = comb_assess.score.astype(int);\n#comb_assess.dtypes","32ab9a1c":"#how much data do we have?\ncomb_assess.shape","eec20d5e":"#group by student and then subgroup by module, so that we retain ability to evaluate different module predictability\ngrouped = comb_assess.groupby(['id_student','code_module']).mean()\ngrouped.sort_values('id_student')\n#we can't keep id_assessment, because we have just grouped by module. We have to group by module, as our vle interaction data is \n#only grouped by module\ngrouped.drop(['id_assessment'],axis=1,inplace = True)\ngrouped.head()","74f9d2fe":"student_info.shape","b3929422":"#put it all together\nstudent_all_info = pd.merge(student_info,grouped,on='id_student')\n#just getting a feel for it - how many modules is each student enrolled in?\nfig1 = student_all_info.groupby(['id_student']).code_module.count().sort_values().hist()\nfig1.set_title('Number of modules by student')\nfig1.set_xlabel('Number of modules')\nfig1.set_ylabel('Number of students')","7fcf42d7":"#total number of clicks per student by module\nvle_grouped = vle_activity.groupby(['id_student','code_module']).sum()\n#we have to drop the columns below as we have grouped by student and subgrouped by module, so they are meaningless\nvle_grouped.drop(['id_site','date'],axis=1,inplace=True)\nvle_grouped.head()\n","05b31202":"student_all_info.shape","d89db074":"#left join as we want to keep student info where no clicks were made\ndf = pd.merge(student_all_info,vle_grouped,on = ['id_student','code_module'],how='left')","9aa1e5e1":"df.shape","edfcb79b":"#remove rows where there are null values for sum_click. There are only 201 so it won't have a huge impact\ndf.dropna(inplace=True)","34cfc175":"#save the new table\ndf.to_csv('joinedData.csv',index=False)","bc692e97":"df.dtypes","486d84ac":"df.code_module = pd.Categorical(df.code_module)\ndf.code_presentation = pd.Categorical(df.code_presentation)\ndf.gender = pd.Categorical(df.gender)\ndf.region = pd.Categorical(df.region)\ndf.highest_education = pd.Categorical(df.highest_education)\ndf.imd_band = pd.Categorical(df.imd_band)\ndf.age_band = pd.Categorical(df.age_band)\ndf.disability = pd.Categorical(df.disability)\ndf.final_result = pd.Categorical(df.final_result)","c63601f9":"df.dtypes","5520bc03":"df.head()","edc624af":"import plotly.express as px\ndata = df\nfig = px.box(data, x=\"code_module\", y=\"score\",title='Student average scores by Module')\n\nfig.show()","d9a3f555":"data = df\nfig = px.box(data, x=\"region\", y=\"score\",title='Student average scores by Region')\n\nfig.show()","b24da62d":"highest_ed = df.highest_education.value_counts()\nf, ax = plt.subplots(figsize=(18,5))\nax.bar(highest_ed.index,highest_ed)\nax.set_ylabel('number of students')\ndf.highest_education.cat.categories","b8897644":"for_bar = df.pivot_table(index = 'highest_education', columns='gender', values = 'score')\nfor_bar.plot(kind='bar')","9a0354e9":"df.head()","68e3e472":"interaction_by_module = df.sum_click\nfig2, ax2 = plt.subplots(figsize=(5,5));\nax2.hist(interaction_by_module,bins=50);\nax2.set_xlabel('Number of Clicks by module');\nax2.set_title('Number of clicks by module for each student');\nax2.set_ylabel('Number of occurences');\n","a97ec2f3":"interaction_by_module = df.sum_click\nfig2, ax2 = plt.subplots(figsize=(5,5));\nax2.boxplot(interaction_by_module);\nax2.set_xlabel('Number of Clicks by module');\nax2.set_title('Number of clicks by module for each student');\nax2.set_ylabel('Number of occurences');","b2399202":"plt.scatter((df.sum_click),(df.score))","b638be77":"plt.scatter((df.studied_credits),(df.score))","ad93a456":"bins = [0,50,100,150,200,250,300,350,400,450,500,550,600]\ndf['studied_credits'] = pd.cut(df['studied_credits'], bins=bins)","e964803f":"df2 = df.groupby(['gender','code_module']).score.mean()","3472a559":"df3 = df.groupby(['gender','code_module']).sum_click.mean()\ncodes =  df2.index.get_level_values(1)\ncodes\nsns.scatterplot(df3,df3.index.get_level_values(1), hue = df2.index.get_level_values(0), legend='full');","3c7f093e":"import seaborn as sns\ncodes =  df2.index.get_level_values(1)\ncodes\nsns.scatterplot(df2,df2.index.get_level_values(1), hue = df2.index.get_level_values(0), legend='full');","1473352f":"df.groupby('final_result').sum_click.mean().sort_values().plot(kind='bar',)","7516cd21":"data = df\nfig = px.box(data, x=\"final_result\", y=\"sum_click\",title='Student final score by the total clicks on the vle')\n\nfig.show()","4c6d3cc2":"df.groupby('final_result').score.mean().sort_values().plot(kind='bar',)","c0e391b1":"plt.scatter((df.sum_click[df.sum_click < 700]),(df.score[df.sum_click < 700]))","7930d328":"#Let's check the datatypes\ndf.dtypes","be6daad3":"df.isnull().sum()\ndf.dropna(inplace=True)","c72500a3":"df.describe()","8a9eef1d":"df_target = df.score\ndf.drop(['score'],axis=1,inplace=True)\ndf.drop(['id_student'],axis=1,inplace=True)","9ade9d54":"df.head()\ndf.dtypes","7f102a97":"#Check multicollinearity\ncorr = df.corr()\ncorr","6b31821c":"df.hist()","b2d0eb50":"df.num_of_prev_attempts = (df.num_of_prev_attempts - df.num_of_prev_attempts.mean())\/df.num_of_prev_attempts.std()\ndf.sum_click = (df.sum_click - df.sum_click.mean())\/df.sum_click.std()\ndf_target = (df_target - df_target.mean())\/df_target.std()","6a038af7":"df.hist();","1160318b":"df_target.hist();","3a90a32e":"#test skew and kurtosis\nprint(\"Kurtosis\",df.kurtosis(axis=0))\nprint(\"Skew\",df.skew(axis=0))\nprint(\"Target Kurtosis\",df_target.kurtosis(axis=0))\nprint(\"Target Skew\",df_target.skew(axis=0))\n","3de12c8a":"df.num_of_prev_attempts.value_counts()","615e241f":"df_trans = df\ndf_trans.head()\n#df_trans['num_of_prev_attempts'] = np.log(df.num_of_prev_attempts)\n#df_trans['studied_credits'] = np.log(df.studied_credits)\n#df_trans['sum_click'] = np.log(df.sum_click)\n#df_trans_target = np.log(df_target)","6defaf05":"df_target.hist()\ndf_trans.hist()","83fd87d3":"df_trans = pd.get_dummies(df_trans)\ndf_trans.shape\ndf_trans.dtypes\nfor i in df_trans.columns[2:]:\n    df_trans[i] = df_trans[i].astype('category')","a615cb4c":"df_trans.dtypes\ndf_trans['score']=df_target\n","55ca21c2":"plt.scatter(df_trans['sum_click'],df_target)\ndf_trans.sum_click.isnull().sum()\ndf_trans.shape","0a4c2801":"#replace spaces in strings with _ for modelling purposes\ndf_trans.columns = df_trans.columns.str.replace(' ', '_')\ndf_trans.columns = df_trans.columns.str.replace('-', '_')\ndf_trans.columns = df_trans.columns.str.replace('%', '')\ndf_trans.columns = df_trans.columns.str.replace('?', '')\ndf_trans.columns = df_trans.columns.str.replace('<', '')\ndf_trans.columns = df_trans.columns.str.replace('=', '')\ndf_trans.columns = df_trans.columns.str.replace(']', ')')\ndf_trans.columns = df_trans.columns.str.replace('(', '')\ndf_trans.columns = df_trans.columns.str.replace(')', '')\ndf_trans.columns = df_trans.columns.str.replace(',', '')\n\ndf_trans.head()","739e35c1":"import statsmodels.formula.api as smf\n\ndfcol = ['num_of_prev_attempts','sum_click']\nresult = []\nfor count, i in enumerate(dfcol):\n    formula = 'score ~' + ' ' + i\n    model = smf.ols(formula, data = df_trans).fit()\n    #print(model.params[0],model.params[1],model.pvalues[1])\n    result.append([i, model.rsquared, model.params[0],model.params[1],model.pvalues[1]])\nresult","5b7e6c8c":"df_trans.columns","a5a12d42":"cols_module= df_trans.columns[2:9]\ncols_pres= df_trans.columns[9:13]\ncols_gender = df_trans.columns[13:15]\ncols_region = df_trans.columns[13:28]\ncols_ed = df_trans.columns[28:33]\ncols_imd = df_trans.columns[33:44]\ncols_age = df_trans.columns[44:47]\ncols_cred = df_trans.columns[47:59]\ncols_dis = df_trans.columns[59:61]\ncols_result = df_trans.columns[61:65]\n\nprint(cols_result)\n","72fcccf2":"cols = [cols_module, cols_pres , cols_gender, cols_region,cols_ed,cols_imd,cols_age,cols_cred,cols_dis,cols_result]\nfor col in cols:\n    sum_cols = \"+\".join(col)\n    form = \"score ~\" + sum_cols\n    model = smf.ols(formula= form, data= df_trans).fit()\n    #model = smf.ols(formula, data = df).fit()\n    print(model.summary())","b1f77b24":"df_final = df_trans.drop([\"num_of_prev_attempts\",\"code_module_AAA\",\"code_presentation_2013B\",\"gender_F\",\"region_East_Anglian_Region\",\"highest_education_No_Formal_quals\",\"imd_band_0_10\",\"studied_credits_550_600\",\"disability_Y\",\"final_result_Fail\"], axis=1)\ny = df_final[[\"score\"]]\nX = df_final.drop([\"score\"], axis=1)","7ed71cd4":"df_final.shape","b2b0c0c1":"import statsmodels.formula.api as smf\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\n\n\n\nr_list = []\nadj_r_list = []\nlist_n = list(range(1,56,2))\nfor n in list_n: \n    linreg = LinearRegression()\n    select_n = RFE(linreg, n_features_to_select = n)\n    select_n = select_n.fit(X, np.ravel(y))\n    selected_columns = X.columns[select_n.support_ ]\n    linreg.fit(X[selected_columns],y)\n    yhat = linreg.predict(X[selected_columns])\n    SS_Residual = np.sum((y-yhat)**2)\n    SS_Total = np.sum((y-np.mean(y))**2)\n    r_squared = 1 - (float(SS_Residual))\/SS_Total\n    print(r_squared)\n    adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)\/(len(y)-X.shape[1]-1)\n    print(adjusted_r_squared)\nr_list.append(r_squared)\nadj_r_list.append(adjusted_r_squared)","d30379c3":"### What this tells us:\nWe need to be careful about generalising for the two categories Post Grad and No prior quals as they only have small numbers  \n\nAnd below, we can see there isn't much variation by gender","0c794f12":"So there does seem to be some pattern between final score and engagement on the vle","4c601476":"Let's drop some of the less predictive columns, and one from each category","b6a55f28":"### Question: Does this higher engagement for women translate to better scores? ","070dcc3b":"## Initial Question: \nCan we use what we know about students, and their engagement on the VLE to predict assessment outcomes?  \n\nWe will use:  \naverage number of clicks per module  \naverage score on assessments per module","0a4cdb94":"### How normal are these independent variables?","0c58b7ab":"### What this shows us\nMost students perform under 1000 clicks per module. There is a long tail of keen students though!  \nThere isn't a clear linear relationship between number of clicks and average assessment score by module","d67e5a11":"Data Source: https:\/\/www.kaggle.com\/rocki37\/open-university-learning-analytics-dataset\nData description: https:\/\/analyse.kmi.open.ac.uk\/open_dataset#description\n\nIn this investigation, I am looking at whether student data such as gender and age, as well as interaction in the VLE can be a predictor of assessment scores by module. ","d9ad4af8":"## Check for Linearity between each independent variable and the target variable","607db3c1":"# Modelling","b782d588":"### What this tells us:\nAll modules have a lower tail, and 6 out of 7 have zero scores included  \nScores by region are fairly consistent  \n\nLet's look at numbers of each students' highest achieved education level, and see if that tells us anything","5c526355":"So not great. Let's try the categorical variables","54519d85":"## We need to create the categorical variables","d78e7aa3":"### Next question: Let's look just at those people\/modules that have less than 700 clicks, and see if it's more predictive","7059ef27":"## Feature selection\nWe will use recursive feature selection to find the best combination of features. ","6fbc1f03":"All variables have positive skewness and kurtosis nowhere near zero. However we can't log transform with the data we have, as there are lots of invalid values including 0s. ","15215d6b":"## Let's look at linear regression by variable","1d30b351":"Database Schema:\n","22ce4d26":"### What this shows us\nWe should put the studied_credits data in bins, as it would make more sense as categorical data - it only appears as certain value.","8a681ab1":"Check for multicollinearity","b0f70531":"So it looks like there are some keen beans skewing our conclusion a bit, but there is still some difference in clicks by result  \n\nAnd how about final score and average score for that module? There should be a relationship no?","3ba6ec85":"# Learning Analytics - Multiple Linear Regression","5ee56cda":"### What this shows us\nThere aren't huge differences in performance by gender for each module","dfe9a531":"So we now have a dataframe with student info, average assessment score for that module and average number of clicks for that module. We will now inspect the data for missing data, and ensure it's clean. ","9b218662":"## Does the total number of clicks impact the final result?","0938bc63":"## Initial exploration of the data","6a5ea726":"## One hot encoding","9c3f3bb4":"### Perform log transformation on the variables - apart from date which has negative values","51fc1921":"So num_of_prev_attempts is heavily positively skewed. studied_credits might have significant outliers. There is a large variation in sum_click, with std larger than mean. ","64e8f3d3":"There is no significant multicollinearity between independent variables  \n\nNext, let's normalise the continuous variables - num_of_prev_attempts, studied_credits,score,date, sum_clicks, plus the target variable score","4f21a054":"## Conclusion:\nThis regression didn't yield much. However we can look further into the relationship between final score and vle engagement using logarithmic regression. ","19e8b023":"### Scaling the continuous features","48aca970":"Note: The plot above shows most students are enrolled in one module. ","c9569d1c":"### What this shows us:\nIt looks as though the number of clicks above 700 isn't that predictive, but below 700 could be. Particularly of withdrawal and failure. There also seems to be a link between final_result and number of clicks","2e24581b":"Let's look at the range now","7934fbb2":"### What this shows us\nWomen tend to be more engaged with the VLE","1bd4ee16":"## Loading the Data","99a04152":"## Overall conclusion so far\nWe have seen that number there is a relationship between number of clicks and final result, and particularly that it might be possible at the lower end of engagement to predict withdrawal or failure from VLE engagement. However our independent variables by themselves don't seem to be predictive of mean assessment score.  \n\nLet's continue anyway, to see if we get any results from a multiple linear regression"}}