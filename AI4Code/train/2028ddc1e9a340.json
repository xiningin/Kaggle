{"cell_type":{"ca411782":"code","4aab7ddb":"code","707ffa77":"code","0145a5a1":"code","78258b8f":"code","4b992213":"code","2c33973c":"code","f2e4e17b":"code","9e6a87e0":"code","9cc8de47":"code","5899e79c":"code","7913f09e":"code","59870fbb":"code","59ed2bc5":"code","be95f279":"code","62997bc9":"code","39c629f4":"code","c7104e77":"code","93b9b385":"code","73762c2e":"code","2b3347d9":"code","fc4430c7":"code","8ebb8df3":"code","2bdda64f":"code","2cf69efc":"code","b377005e":"code","ed62b8d1":"code","8e8a5ba4":"code","7ddf33e0":"code","9c0bbedf":"code","3271f6b2":"code","a5691cd7":"code","630a6b08":"code","dbbac51e":"code","10a26191":"code","ef08d0ba":"code","a67d2747":"code","c5b9f445":"code","b7e084c5":"code","1675d3c5":"code","9daad507":"code","17cd8532":"code","7b8cfc36":"code","11f9111b":"markdown","14490adb":"markdown","4b489754":"markdown","4f85aa9a":"markdown","7710f770":"markdown","6c8b701a":"markdown","38dedeae":"markdown","e50037de":"markdown","aef813fa":"markdown","848411cf":"markdown","7bc3e69f":"markdown","c2464cd5":"markdown","9fb5aa90":"markdown","de95137b":"markdown","d5d2de07":"markdown","22ec2b2b":"markdown","7f044b1f":"markdown","bce22afc":"markdown","b467454d":"markdown"},"source":{"ca411782":"import pandas as pd \nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime as dt\n\nimport warnings\nwarnings.simplefilter(action = 'ignore')","4aab7ddb":"pd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);  # to display all columns and rows\npd.set_option('display.float_format', lambda x: '%.2f' % x) # The number of numbers that will be shown after the comma.\n\nonret = pd.read_excel('..\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx', \n                      sheet_name = 'Year 2010-2011', sep=';')\nonret.head()","707ffa77":"onret.info()","0145a5a1":"df = onret.dropna() # Deleting missing values\ndf.info()","78258b8f":"df.head(2)","4b992213":"df[\"Customer ID\"] = df[\"Customer ID\"].astype(int) # Values of float are converted to integer.\ndf[\"TotalPrice\"] = df[\"Quantity\"] * df[\"Price\"]  # it is necessary to create a new variable by multiplying two variables\ndf.head()","2c33973c":"df[df['Invoice'].str.startswith(\"C\", na = False)]  # Values starting with 'c' in the invoice variable indicate the returned products.","f2e4e17b":"df[\"InvoiceDate\"].max()","9e6a87e0":"today = df[\"InvoiceDate\"].max()\ntoday","9cc8de47":"temp_df = (today - df.groupby(\"Customer ID\").agg({\"InvoiceDate\":\"max\"})) # Show the last shopping dates of each customer.\ntemp_df.head()","5899e79c":"temp_df.rename(columns={\"InvoiceDate\":\"Recency\"},inplace=True)\nrecency_df = temp_df[\"Recency\"].apply(lambda x: x.days)\nrecency_df.head()","7913f09e":"recency_df = pd.DataFrame(recency_df)\nrecency_df.head()","59870fbb":"temp_df = df.groupby([\"Customer ID\", \"Invoice\"]).agg({\"Invoice\": \"count\"})\nfreq_df = temp_df.groupby(\"Customer ID\").agg({\"Invoice\":\"count\"})\nfreq_df.rename(columns={\"Invoice\":\"Frequency\"},inplace = True)\nfreq_df.head()","59ed2bc5":"monetary_df = df.groupby(\"Customer ID\").agg({\"TotalPrice\": \"sum\"})\nmonetary_df.rename(columns={\"TotalPrice\":\"Monetary\"},inplace=True)\nmonetary_df.head()","be95f279":"rfm_df = pd.concat([recency_df, freq_df, monetary_df], axis = 1)\nrfm_df.head()","62997bc9":"# Outlier Analysis of Amount Frequency and Recency\n\nattributes = ['Monetary','Frequency','Recency']\nplt.rcParams['figure.figsize'] = [10,8]\nsns.boxplot(data = rfm_df[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"Attributes\", fontweight = 'bold')","39c629f4":"# Removing (statistical) outliers for Monetary\nQ1 = rfm_df.Monetary.quantile(0.05)\nQ3 = rfm_df.Monetary.quantile(0.95)\nIQR = Q3 - Q1\nrfm_df = rfm_df[(rfm_df.Monetary >= Q1 - 1.5*IQR) & (rfm_df.Monetary <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Recency\nQ1 = rfm_df.Recency.quantile(0.05)\nQ3 = rfm_df.Recency.quantile(0.95)\nIQR = Q3 - Q1\nrfm_df = rfm_df[(rfm_df.Recency >= Q1 - 1.5*IQR) & (rfm_df.Recency <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Frequency\nQ1 = rfm_df.Frequency.quantile(0.05)\nQ3 = rfm_df.Frequency.quantile(0.95)\nIQR = Q3 - Q1\nrfm_df = rfm_df[(rfm_df.Frequency >= Q1 - 1.5*IQR) & (rfm_df.Frequency <= Q3 + 1.5*IQR)]","c7104e77":"rfm_1 = rfm_df.copy()","93b9b385":"rfm_df.head()","73762c2e":"rfm_df[\"RecencyScore\"] = pd.qcut(rfm_df['Recency'], 5, labels = [5, 4, 3, 2, 1])\nrfm_df[\"FrequencyScore\"] = pd.qcut(rfm_df['Frequency'].rank(method=\"first\"), 5, labels = [1, 2, 3, 4, 5])\nrfm_df[\"MonetaryScore\"] = pd.qcut(rfm_df['Monetary'], 5, labels = [1, 2, 3, 4, 5])\nrfm_df[\"RFM_SCORE\"] = (rfm_df['RecencyScore'].astype(str) \n                                + rfm_df['FrequencyScore'].astype(str) \n                                + rfm_df['MonetaryScore'].astype(str))\nrfm_df.head()","2b3347d9":"seg_map = {r'[1-2][1-2]': 'Hibernating',\n            r'[1-2][3-4]': 'At Risk',\n            r'[1-2]5': 'Can\\'t Loose',\n            r'3[1-2]': 'About to Sleep',\n            r'33': 'Need Attention',\n            r'[3-4][4-5]': 'Loyal Customers',\n            r'41': 'Promising',\n            r'51': 'New Customers',\n            r'[4-5][2-3]': 'Potential Loyalists',\n            r'5[4-5]': 'Champions'}\n    \nrfm_df['Segment'] = rfm_df['RecencyScore'].astype(str) + rfm_df['FrequencyScore'].astype(str)\nrfm_df['Segment'] = rfm_df['Segment'].replace(seg_map, regex=True)\nrfm_df.head()","fc4430c7":"rfm = rfm_1\nrfm.head()","8ebb8df3":"from sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler((0,1))\ncols = rfm.columns\nindex = rfm.index\nscaled_rfm = mms.fit_transform(rfm)\nscaled_rfm = pd.DataFrame(scaled_rfm, columns=cols, index = index)\nscaled_rfm.head()","2bdda64f":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 4)\nkmeans = kmeans.fit(scaled_rfm)\nkmeans","2cf69efc":"kmeans.cluster_centers_","b377005e":"kmeans.labels_","ed62b8d1":"ssd = []\n\nK = range(1,30)\n\nfor k in K:\n    kmeans = KMeans(n_clusters = k).fit(rfm)\n    ssd.append(kmeans.inertia_)\n    \nplt.plot(K, ssd, \"bx-\")\nplt.xlabel(\"Distance Residual Sums Versus Different k Values\")\nplt.title(\"Elbow method for Optimum number of clusters\")","8e8a5ba4":"from yellowbrick.cluster import KElbowVisualizer\n\nkmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k = (2,20))\nvisu.fit(rfm)\nvisu.poof();","7ddf33e0":"# Final model with k=6\nkmeans = KMeans(n_clusters = 5, max_iter=50).fit(rfm)\nkmeans.labels_","9c0bbedf":"# assign the label\nrfm['Cluster_Id'] = kmeans.labels_","3271f6b2":"# Box plot to visualize Cluster Id vs Monetary\nsns.boxplot(x = 'Cluster_Id', y = 'Monetary', data = rfm);","a5691cd7":"# Box plot to visualize Cluster Id vs Frequency\nsns.boxplot(x='Cluster_Id', y='Frequency', data = rfm);","630a6b08":"# Box plot to visualize Cluster Id vs Recency\nsns.boxplot(x='Cluster_Id', y='Recency', data = rfm);","dbbac51e":"rfm.groupby(\"Cluster_Id\").agg({\"Cluster_Id\":\"count\"})","10a26191":"rfm.groupby(\"Cluster_Id\").agg(np.mean)","ef08d0ba":"from scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nhc_complete = linkage(rfm, \"complete\") #Complete Linkage\nhc_average = linkage(rfm, \"average\") # Average Linkage\n","a67d2747":"plt.figure(figsize = (15,10))\nplt.title(\"Hierarchical Cluster Dendrogram\")\nplt.xlabel(\"Observation Unit\")\nplt.ylabel(\"Distance\")\ndendrogram(hc_complete,\n           truncate_mode = \"lastp\",\n           p = 10,\n           show_contracted = True,\n          leaf_font_size = 10);","c5b9f445":"# Cutting the Dendrogram based on K\ncluster_labels = cut_tree(hc_complete, n_clusters = 5).reshape(-1, )\ncluster_labels","b7e084c5":"# Assign cluster labels\nrfm['Cluster_Labels'] = cluster_labels\nrfm['Cluster_Labels'] = rfm['Cluster_Labels'] + 1\nrfm.head()","1675d3c5":"rfm.groupby(\"Cluster_Labels\").agg(np.mean)","9daad507":"# Plot Cluster Id vs Monetary\nsns.boxplot(x = 'Cluster_Labels', y = 'Monetary', data = rfm);","17cd8532":"# Plot Cluster Id vs Frequency\nsns.boxplot(x = 'Cluster_Labels', y = 'Frequency', data = rfm);","7b8cfc36":"# Plot Cluster Id vs Recency\nsns.boxplot(x='Cluster_Labels', y='Recency', data=rfm);","11f9111b":"\n## Scoring for RFM\n\n- Let's start with the last 5 here. Let's use the 'qcut' method to score.","14490adb":"# KMeans:","4b489754":"## Recency\n\n\n\n\nWhat is today? Now if we take today's date, then there will be a very serious difference.\n\nFor this reason, let us determine ourselves a \"today\" according to the structure of this data set.\n\nWe can set this day as the maximum day of the data set.\n\nWe can segmentation according to the day of the last recording.","4f85aa9a":"### Let's do regex segmentation. With the help of regex, we will set rfm aside and consider r and f.\n\n### Example: If you see 1-2 in r and 1-2 in f, write 'Hibernating'","7710f770":"### For each customer, we need to deduce the customers' last purchase date from today's date.\n\n### Then we have singularized customer deadlines.","6c8b701a":"### MODEL OPTIMIZATION","38dedeae":"### Now, we need to score according to the most recent (Recency), the cyclic (Frequency) and the monetary expenditure (Monetary).\n","e50037de":"**","aef813fa":"## Frequency","848411cf":"## Monetary","7bc3e69f":"## OPTIMAL NUMBER OF CLUSTER\n\n\nElbow Curve to get the right number of Clusters\nA fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","c2464cd5":"## Data Understanding","9fb5aa90":"## Final Analysis\nAccording to K-Means Clustering with optimized 5 Cluster Ids;\n\nCustomers belong to Cluster Id 4 are the ones having the highest amount of transactions as compared to other cluster Ids.\\\nCustomers in Cluster Id 1 are the ones bring us the least amount of money and not recent buyers.\n\nFor the Hierarchical Clustering Model, customers in cluster_label 4 has the highest amount of transactions.\\\nCustomers in cluster_label 1 are the ones having the least transaction frequency.\n","de95137b":"## Data Set Story:\n### https:\/\/www.kaggle.com\/mathchi\/online-retail-ii-data-set-from-ml-repository\n\n### This Online Retail II data set contains all the transactions occurring for a UK-based and registered, non-store online retail between 01\/12\/2009 and 09\/12\/2011.\n\n### The company mainly sells unique all-occasion gift-ware.\n\n### Many customers of the company are wholesalers.\n\n## Features Information:\n\n### InvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation.\n### StockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product.\n### Description: Product (item) name. Nominal.\n### Quantity: The quantities of each product (item) per transaction. Numeric.\n### InvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated.\n### UnitPrice: Unit price. Numeric. Product price per unit in sterling (\u00c2\u00a3).\n### CustomerID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer.\n### Country: Country name. Nominal. The name of the country where a customer resides.","d5d2de07":"## HIERARCHICAL CLUSTERING\n\nHierarchical clustering involves creating clusters that have a predetermined ordering from top to bottom. For example, all files and folders on the hard disk are organized in a hierarchy. There are two types of hierarchical clustering,\n\nDivisive\nAgglomerative.\n\n\nComplete Linkage\n\nIn complete linkage hierarchical clustering, the distance between two clusters is defined as the longest distance between two points in each cluster. For example, the distance between clusters \u201cr\u201d and \u201cs\u201d to the left is equal to the length of the arrow between their two furthest points.\n\nhttps:\/\/www.saedsayad.com\/images\/Clustering_complete.png\n\n\nAverage Linkage:\n\nIn average linkage hierarchical clustering, the distance between two clusters is defined as the average distance between each point in one cluster to every point in the other cluster. For example, the distance between clusters \u201cr\u201d and \u201cs\u201d to the left is equal to the average length each arrow between connecting the points of one cluster to the other.\n\nhttps:\/\/www.saedsayad.com\/images\/Clustering_average.png\n\n","22ec2b2b":"# Business Problem with Customer Segmentation \n\n### An e-commerce company wants to segment its customers and determine marketing strategies according to these segments.  For this purpose, we will define the behavior of customers and we will form groups according to clustering.  In other words, we will take those who exhibit common behaviors into the same groups and we will try to develop sales and marketing techniques specific to these groups.","7f044b1f":"## Building the Model\n\n\n### K-Means Clustering\u00b6\n\nK-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n\n### The algorithm works as follows:\n\nFirst we initialize k points, called means, randomly.\nWe categorize each item to its closest mean and we update the mean\u2019s coordinates, which are the averages of the items categorized in that mean so far.\nWe repeat the process for a given number of iterations and at the end, we have our clusters.","bce22afc":"## Customer Segmentation with RFM Scores\n\n### Consists of initials of **Recency**, **Frequency**, **Monetary** expressions.\n\n### It is a technique that helps determine marketing and sales strategies based on customers' buying habits.\n\n### - *Recency (innovation)*: Time since customer last purchased\n\n###      -- In other words, it is the \u201ctime since the last contact of the customer\u201d.\n\n###      -- Today's date - Last purchase\n\n###      -- To give an example, if we are doing this analysis today, today's date is the last product purchase date.\n\n###      -- This can be for example 20 or 100. We know that 20 customers are hotter. He has been in contact with us recently.\n\n### - *Frequency*: Total number of purchases.\n\n### - *Monetary* (Monetary Value): Total spending by the customer.\n","b467454d":"## Rescaling the Attributes\n\n### It is extremely important to rescale the variables so that they have a comparable scale.| There are two common ways of rescaling:\n\n### Min-Max scaling\n### Standardisation (mean-0, sigma-1)\n### Here, we will use Min-Max scaling."}}