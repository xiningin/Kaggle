{"cell_type":{"62c83fb1":"code","cd56e02a":"code","2bd9534c":"code","0c04f82e":"code","7d6531f1":"code","8800ab72":"code","fe5017d8":"code","30f46d49":"code","44519709":"code","1bcd00e6":"code","b177e0ce":"code","9288ce64":"markdown","c2c52785":"markdown","a5f06f92":"markdown","408e8f34":"markdown","53ef25cd":"markdown","3c775925":"markdown","812a8171":"markdown"},"source":{"62c83fb1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\ntrain = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","cd56e02a":"discrete_features = []\n\nfor col in train.columns:\n    if np.array_equal(train[col].values, train[col].values.astype(int)):\n        discrete_features.append(col)\n\nprint(f'Total {len(discrete_features)} : ')\nprint(discrete_features)","2bd9534c":"f1_loss = train.groupby(['f1'])['loss'].mean().sort_values()\nf16_loss = train.groupby(['f16'])['loss'].mean().sort_values()\nf27_loss = train.groupby(['f27'])['loss'].mean().sort_values()\nf55_loss = train.groupby(['f55'])['loss'].mean().sort_values()\nf60_loss = train.groupby(['f60'])['loss'].mean().sort_values()\nf86_loss = train.groupby(['f86'])['loss'].mean().sort_values()\nprint((f1_loss==0).sum())\nprint((f16_loss==0).sum())\nprint((f27_loss==0).sum())\nprint((f55_loss==0).sum())\nprint((f60_loss==0).sum())\nprint((f86_loss==0).sum())","0c04f82e":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f16_loss)), f16_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f16', loc='left', fontweight='bold')\nax.legend()\nplt.show()","7d6531f1":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f27_loss)), f27_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f27', loc='left', fontweight='bold')\nax.legend()\nplt.show()","8800ab72":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f55_loss)), f55_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f55', loc='left', fontweight='bold')\nax.legend()\nplt.show()","fe5017d8":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n\nax.bar(range(len(f60_loss)), f60_loss, alpha=0.7, color='lightgray', label='Test Dataset')\nax.set_yticks(range(0, 20, 3))\nax.margins(0.01)\nax.grid(axis='y', linestyle='--', zorder=5)\nax.set_title('Average of loss grouped by f60', loc='left', fontweight='bold')\nax.legend()\nplt.show()","30f46d49":"train2 = train[train<0]\ntrain3 = abs(train2)\ntrain3.sum()","44519709":"train4 = train3.sum()\n\nx = np.arange(6)\nids = ['f1', 'f16', 'f27', 'f55', 'f60', 'f86']\nvalues = [530, train4.loc['f16'], train4.loc['f27'], train4.loc['f55'], train4.loc['f60'], train4.loc['f86']]\n\nplt.bar(x, values)\nplt.xticks(x, ids)\nplt.show()","1bcd00e6":"x = np.arange(4)\nids = ['f1', 'f27', 'f55', 'f86']\nvalues = [530, train4.loc['f27'], train4.loc['f55'], train4.loc['f86']]\n\nplt.bar(x, values)\nplt.xticks(x, ids)\nplt.show()","b177e0ce":"x = np.arange(3)\nids = ['f1', 'f55', 'f86']\nvalues = [530, train4.loc['f55'], train4.loc['f86']]\n\nplt.bar(x, values)\nplt.xticks(x, ids)\nplt.show()","9288ce64":"**To be contine**","c2c52785":"**f16 and f60 are big.**","a5f06f92":"**f55 is big.**","408e8f34":"**f27 is big.**","53ef25cd":"**I decided to consider the loss value.**","3c775925":"**Reference : https:\/\/www.kaggle.com\/subinium\/tps-aug-simple-eda**","812a8171":"\n\nA total of 6 features have no decimal point.\n\n*     f1\n*     f16\n*     f27\n*     f55\n*     f60\n*     f86\n\n"}}