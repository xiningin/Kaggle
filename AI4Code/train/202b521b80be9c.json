{"cell_type":{"15c59fc7":"code","54c73c14":"code","3e733f37":"code","d3e493d1":"code","bdfc9f1e":"code","3229b783":"code","30f09b64":"code","5d620041":"code","7848aa42":"code","46aaab31":"code","da13ae8a":"code","2957094b":"code","629c63fb":"code","6ba9e33e":"code","eee6040e":"code","427181e1":"code","5f5455cf":"code","19b090a0":"code","d0160ad8":"code","795a54db":"code","01db5645":"code","6fe19122":"code","9613455f":"code","5970b09c":"code","7cb7016c":"code","1851f182":"code","83664ec1":"code","eebf5fa3":"code","96cc9b7b":"code","5b3eb2bc":"code","88d27ebe":"code","38a7d4d7":"code","a9e5bcf6":"code","db733942":"code","b2a8a7ce":"code","19331f24":"code","61a74339":"markdown","7a9481c3":"markdown","698aa475":"markdown","367ca2c5":"markdown","99c2b56e":"markdown","4cb6b1b8":"markdown","7b3dc396":"markdown","3abd1f0c":"markdown","81c67cc2":"markdown","ba2c55c3":"markdown","030b53ed":"markdown","82846740":"markdown","3712eca1":"markdown","16d2d61b":"markdown","e7d23abb":"markdown","31093c35":"markdown","121afc3b":"markdown","c0281d22":"markdown","cf023bbb":"markdown","b07b31fe":"markdown","ba202701":"markdown","f252069d":"markdown","0f0c873e":"markdown","8decddab":"markdown","5bd79ece":"markdown","c3d7a2a0":"markdown","89792c9d":"markdown","3322cf18":"markdown","37f67ee7":"markdown"},"source":{"15c59fc7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","54c73c14":"dataset = pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")\nprint(dataset.shape)","3e733f37":"# Overview of the first 5 rows\ndataset.head(5)","d3e493d1":"dataset.describe()","bdfc9f1e":"dataset.drop(columns=['Serial No.'], axis=1, inplace=True)","3229b783":"dataset.apply(lambda x: sum(x.isnull()))","30f09b64":"dataset.columns = dataset.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\nlist(dataset)","5d620041":"sns.distplot(dataset['chance_of_admit'].dropna(), hist=True, kde=True, \n             bins=int(350\/50), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})","7848aa42":"dataset['university_rating']= dataset.university_rating.astype(object)\ndataset['research']= dataset.research.astype(object)","46aaab31":"dataset.dtypes","da13ae8a":"pd.DataFrame(dataset.corr()['chance_of_admit'])","2957094b":"sns.pairplot(data=dataset,\n                  y_vars=['chance_of_admit'],\n                  x_vars=['gre_score','toefl_score','university_rating','sop','lor','cgpa','research'])","629c63fb":"corr = dataset.corr()\ncorr.style.background_gradient(cmap='coolwarm')","6ba9e33e":"fig, axs = plt.subplots(2, 3)\n# gre_score plot\naxs[0, 0].boxplot(dataset['gre_score'])\naxs[0, 0].set_title('gre_score')\n\n# toefl_score plot\naxs[0, 1].boxplot(dataset['toefl_score'])\naxs[0, 1].set_title('toefl_score')\n\n# sop plot\naxs[0, 2].boxplot(dataset['sop'])\naxs[0, 2].set_title(\"sop\")\n\n# lor plot\naxs[1, 0].boxplot(dataset['lor'])\naxs[1, 0].set_title('lor')\n\n# cgpa plot\naxs[1, 1].boxplot(dataset['cgpa'])\naxs[1, 1].set_title('cgpa')\n\n# chance of admission plot\naxs[1, 2].boxplot(dataset['chance_of_admit'])\naxs[1, 2].set_title('chance_of_admit')\n\nfig.subplots_adjust(left=0.15, right=1.98, bottom=0.09, top=0.95,\n                    hspace=0.5, wspace=0.5)\n\nplt.show()\n","eee6040e":"sns.boxplot(data = dataset['lor'], orient=\"v\", palette=\"Set2\")\n","427181e1":"X = dataset[['toefl_score','university_rating','sop','lor','cgpa','research']]\nY = dataset['chance_of_admit']\nX = pd.get_dummies(data=X, drop_first=True)","5f5455cf":"#Treatment of the outlier\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)","19b090a0":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","d0160ad8":"from sklearn import linear_model\nlm = linear_model.LinearRegression()\nmodel = lm.fit(X_train, y_train)","795a54db":"coef_dframe = pd.DataFrame(lm.coef_,X.columns, columns=['Coefficients'])\ncoef_dframe","01db5645":"lm_pred = model.predict(X_test)","6fe19122":"fig = plt.figure()\nc = [i for i in range(1,101,1)]\nplt.plot(c,y_test, color = 'grey', linewidth = 2.5, label='Test')\nplt.plot(c,lm_pred, color = 'blue', linewidth = 2.5, label='Predicted')\nplt.grid(alpha = 0.3)\nplt.legend()\nfig.suptitle('Actual vs Predicted')","9613455f":"from sklearn import metrics\nnp.sqrt(metrics.mean_squared_error(y_test,lm_pred))","5970b09c":"metrics.mean_absolute_error(y_test,lm_pred)","7cb7016c":"SS_Residual = sum((y_test-lm_pred)**2)\nSS_Total = sum((y_test-np.mean(y_test))**2)\nR_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_R_squared = 1 - (1-R_squared)*(len(y_test)-1)\/(len(y_test)-X.shape[1]-1)\n\nprint (R_squared, adjusted_R_squared)","1851f182":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n","83664ec1":"# Train the model on training data\nrf_model = rf.fit(X_train, y_train);\nrf_model","eebf5fa3":"# Use the forest's predict method on the test data\nrf_pred = rf.predict(X_test)","96cc9b7b":"# Calculate the absolute errors\nerrors_rf = abs(rf_pred - y_test)\n\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors_rf), 2))","5b3eb2bc":"rmse = np.sqrt(metrics.mean_squared_error(y_test,rf_pred))\n\nprint('Root Mean Squared Error:', round(rmse,2))","88d27ebe":"SS_Residual = sum((y_test-rf_pred)**2)\nSS_Total = sum((y_test-np.mean(y_test))**2)\nR_squared = 1 - (float(SS_Residual))\/SS_Total\nadjusted_R_squared = 1 - (1-R_squared)*(len(y_test)-1)\/(len(y_test)-X.shape[1]-1)\n\nprint (R_squared, adjusted_R_squared)","38a7d4d7":"feature_importances = pd.DataFrame(rf.feature_importances_,\n                                   index = X.columns,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nfeature_importances","a9e5bcf6":"X_test","db733942":"Predictions = model.predict(X_test)\nPredictions","b2a8a7ce":"#Create a  DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame(Predictions,columns=['Predictions'])\n\n#Visualize the first 5 rows\nsubmission.head()","19331f24":"#Convert DataFrame to a csv file that can be uploaded\n#This is saved in the same directory as your notebook\nfilename = 'Predictions 1.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","61a74339":"**Mean Absolute Error**","7a9481c3":"The correlation matrix above suggest that there are strong presence of multicollinearity within the dataset. gre_score for an instance has got 0.83 correlation coefficient with toefl_score. This means they are both giving the same explanation to the reason why a student should be admitted or not. Hence, keeping both of them will skew our model as it will violate the assumption of no or little multicollinearity.","698aa475":"**Checking for Multicollinearity between the variables**\n\nMutlicollineairty is a situation where each of the predictors (independent variables) have got strong correlation with one another.","367ca2c5":"**Mean Absolute Error(MAE)**","99c2b56e":"**Checking for Missing Data**","4cb6b1b8":"**Checking that the variables are in the right format**\n\nSince Research and University Rating are categorical variable, it is not right to have them as integer. Hence, we change the data type to object.","7b3dc396":"lor looks like it has got an outlier from the bottom. So let's inspect that. From the diagram below we can clearly observe that there is an outlier.","3abd1f0c":"**Root Mean Squared Error(RMSE)**","81c67cc2":"**2. Data Preparation**","ba2c55c3":"**The distribution of Chance of Admit**\nChecking the distribution of the response variable enables one to determine if the variable is skewed; either to the right or left; or is normallly distributed.\n\nSince, chance of Admit is normally distributed and hence, it is fit for use. ","030b53ed":"**Importing the Dataset**","82846740":"From the result above, we can authoritatively conclude that all of the chosen variables are highly correlated with the dependent variable 'chance_of_admit' while research has got the lowest correlation coefficient.","3712eca1":"**4. Model building**","16d2d61b":"**Summary of the dataset**\n\nThis gives a brief overview of how the dataset is distributed. A critical look suggests that both University rating and Research are categorical in nature as they are both within 1 - 5 and 0 - 1 respectively.","e7d23abb":"**1. Project Overview**\n\nThe objective of this project is to understand which of the given variables will be useful in determining the chance of a student being admitted as this afford us the opportunity to be able to predict if a student will be admitted with the minimum possible error. \n\nThe dataset consists of 500 observations and 9 variables. 8 independent variables and 1 dependent variable which makes this project a supervised learning task.","31093c35":"**R Squared and Adjusted R Squared**","121afc3b":"**Random Forest for Regression**","c0281d22":"**Linear Regression**","cf023bbb":"**Checking for Outliers**\n\nOutliers are numbers or observation that are outside the range of the rest of the data. Hence, an outlier is a data point whose value is higher that 1.5(75% - 25%) or lower than 1.5(75% - 25%).","b07b31fe":"**Model Evaluation for Random Forest**","ba202701":"**Checking for Correlations**\n\nCorrelation coefficient is a statistical measure that helps in understanding the nature and degree of relationship existing between variable. It shows how strongly pairs of variables are related. If a variable X has a correlation coefficient that is more than 0.5 with variable Y, it is generally regarded as both variable are highly correlated.\n\n","f252069d":"**Conclusion**\n\nFrom this analysis, it is obvious that score from CGPA is most important factor in deciding if a student will be admitted. What this means is that, a student with a high CGPA score has got a high chance of being admitted irrespective of if the school his coming from has got a high or low rating.\n\nAgain there are so significant amount of difference between the results obtained from linear regression model and Random forest model despite training the model on 1000 trees. Hence, a linear regression model will be preferred for a task like this.\n\nSo a good model, will be  a model with the lowest number of variables being used and with a significant high level of accuracy.","0f0c873e":"**Refining variables to avoid computation difficulties**","8decddab":"**The required Libraries**","5bd79ece":"**R Squared and Adjusted R Squared**","c3d7a2a0":"**Dropping the flat variable**","89792c9d":"**3. Data Splitting**","3322cf18":"**Model Evaluation for Regression**","37f67ee7":"**Root Mean Squared Error(RMSE)**"}}