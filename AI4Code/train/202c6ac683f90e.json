{"cell_type":{"bba99e43":"code","08c891cb":"code","472cb438":"code","7eb46053":"code","4e3bdf7e":"code","e22d499c":"code","8fdb6ce2":"code","d3f0003c":"code","c15dd344":"code","598a7f57":"code","e9a219d2":"code","480e63b2":"code","862d89da":"code","435169ce":"code","12afa2ba":"code","ad67efd8":"code","2097bec0":"code","c5d1bd19":"code","57f26df4":"code","d4dca887":"code","00303d6f":"code","5a5c6790":"code","704a49b8":"code","e6ea9d97":"code","dd0c743a":"code","63a34bf0":"code","653b159d":"code","ab28393a":"code","87395d56":"code","140f7b06":"code","39acb186":"code","43701fff":"code","89708295":"code","ff2322da":"markdown","0ffb7ead":"markdown","fe0db8fd":"markdown","94af9e8b":"markdown","0d2fb7fd":"markdown","7c5625df":"markdown","321d7374":"markdown","0cf6cecc":"markdown","06294116":"markdown","e690c053":"markdown"},"source":{"bba99e43":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08c891cb":"import tensorflow as tf\ntf.test.is_gpu_available()","472cb438":"device_name = tf.test.gpu_device_name()\nif device_name != '\/device:GPU:0':\n    raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","7eb46053":"tf.device('\/device:GPU:0')","4e3bdf7e":"import matplotlib.pyplot as plt\nimport datetime\nimport matplotlib.dates as mdates\nfrom datetime import datetime, timedelta\nimport seaborn as sns\nfrom pandas.plotting import register_matplotlib_converters\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\nimport keras_tuner as kt","e22d499c":"register_matplotlib_converters()\nsns.set(font_scale=1.5, style=\"whitegrid\")","8fdb6ce2":"df = pd.read_csv('..\/input\/nvidia-stock-data-latest-and-updated\/NVidia_stock_history.csv')\ndf['Date'] = pd.to_datetime(df[\"Date\"], format='%Y-%m-%d')\ndf.head()","d3f0003c":"null_columns=df.columns[df.isnull().any()]\ndf[null_columns].isnull().sum()","c15dd344":"df.dropna(inplace=True)","598a7f57":"df.plot(subplots = True, figsize = (10,12))\nplt.title('NVidia Stock Attributes')\nplt.show()","e9a219d2":"df.describe()","480e63b2":"df.dtypes","862d89da":"df[['Volume']].plot()","435169ce":"ma_day = [50, 200]\n\nfor ma in ma_day:\n    column_name = f\"MA for {ma} days\"\n    df[column_name] = df['Close'].rolling(ma).mean()","12afa2ba":"plt.style.use(\"fivethirtyeight\")\nplt.plot(df['Date'],df[['Close', 'MA for 50 days', 'MA for 200 days']])\nplt.legend(['Price', 'MA for 50 days', 'MA for 200 days'])","ad67efd8":"df = df.set_index('Date')","2097bec0":"df['Daily Return'] = df['Close'].pct_change()\ndf['Daily Return'].plot(legend=True, linestyle='--', marker='o')","c5d1bd19":"plt.figure(figsize=(16,6))\nplt.title('Close Price History')\nplt.plot(df['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.show()","57f26df4":"df.drop([\"MA for 50 days\",\"MA for 200 days\",\"Daily Return\"],axis=1,inplace=True)","d4dca887":"X_train0, X_test0, y_train0, y_test0 = train_test_split(df[[\"Open\",\"High\",\"Low\",\"Volume\",\"Dividends\",\"Stock Splits\"]], df['Close'], test_size=0.05, random_state=42,shuffle=False)","00303d6f":"scaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(df[[\"Open\",\"High\",\"Low\",\"Volume\",\"Dividends\",\"Stock Splits\"]])\n\n\nscaler_y = MinMaxScaler()\nscaled_data_y = scaler_y.fit_transform(df[[\"Close\"]])","5a5c6790":"X_train, X_test, y_train, y_test = train_test_split(scaled_data, scaled_data_y, test_size=0.05, random_state=42,shuffle=False)","704a49b8":"X_train, X_test, y_train, y_test = np.array(X_train),np.array(X_test), np.array(y_train), np.array(y_test)","e6ea9d97":"X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\nX_train.shape","dd0c743a":"y_train = np.reshape(y_train, (y_train.shape[0], 1))\ny_test = np.reshape(y_test, (y_test.shape[0],1))\ny_train.shape","63a34bf0":"def model_builder(hp):\n    model = Sequential()\n    model.add(LSTM(hp.Int('input_unit',min_value=32,max_value=512,step=32), return_sequences=True, input_shape= ( X_train.shape[1],X_train.shape[2])))\n    for i in range(hp.Int('n_layers', 1, 4)):\n        model.add(LSTM(hp.Int(f'lstm_{i}_units',min_value=32,max_value=512,step=32),return_sequences=True))\n    model.add(LSTM(hp.Int('layer_2_neurons',min_value=32,max_value=512,step=32)))\n    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n    model.add(Dense(30, activation=hp.Choice('dense_activation',values=['relu', 'sigmoid'],default='relu')))\n    model.add(Dense(1, activation=hp.Choice('dense_activation',values=['relu', 'sigmoid'],default='relu')))\n   \n    model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mse'])\n    \n    return model\n    \ntuner = kt.RandomSearch(model_builder, objective=\"mse\", max_trials = 4, executions_per_trial =2,directory = \".\/\")\n\ntuner.search(x=X_train, y=y_train, epochs = 10, batch_size =256, validation_data=(X_test, y_test))","653b159d":"best_model = tuner.get_best_models(num_models=1)[0]","ab28393a":"tuner.results_summary()","87395d56":"y_pred = best_model.predict(X_test)","140f7b06":"y_pred.shape","39acb186":"y_pred = scaler_y.inverse_transform(y_pred)","43701fff":"valid = pd.DataFrame(y_test0)\nvalid['Predicted'] = y_pred","89708295":"plt.figure(figsize=(16,6))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.plot(y_train0)\nplt.plot(valid[['Close', 'Predicted']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","ff2322da":"### Plotting the Closing price History","0ffb7ead":"# \ud83d\udcaf Validating model results on test data and plotting results","fe0db8fd":"# \u2696\ufe0f Scaling data\n\nMin-max normalization is one of the most common ways to normalize data. For every feature, the minimum value of that feature gets transformed into a 0, the maximum value gets transformed into a 1, and every other value gets transformed into a decimal between 0 and 1.","94af9e8b":"# \ud83d\udcc8 Plotting various charts","0d2fb7fd":"# \ud83d\udcc2 Loading dataset","7c5625df":"<h1><center style=\"color: navy\"> NVidia Price Prediction - LSTM using Keras Tuner <\/center><\/h1>\n\n## Objective\nThe aim of this kernal is to train an LSTM model to predict the future price of NVidia Shares based on past time series data. This kernel will use LSTM model from the Keras Library\n\n## What is LSTM?\n\nLSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems. LSTM has feedback connections, i.e., it is capable of processing the entire sequence of data, apart from single data points such as images. This finds application in speech recognition, machine translation, etc. LSTM is a special kind of RNN, which shows outstanding performance on a large variety of problems.\n\n<center><img src = \"https:\/\/miro.medium.com\/max\/1400\/1*goJVQs-p9kgLODFNyhl9zA.gif\" alt=\"LSTM aniamtion\" width=700px><\/center>\n\n","321d7374":"### Plotting Moving Average (MA) for 50 and 200 days\n\nMoving Average (MA) is the average of closing price for a specified time period. This gives traders a clear view of the trend of the share or market.","0cf6cecc":"# \ud83d\udce5 Importing needed libraries","06294116":"### Plotting daily returns","e690c053":"# \ud83c\udfd7\ufe0f Building and Training Model\n\n### What is Kears Tuner?\n\nThe Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called hyperparameter tuning or hypertuning."}}