{"cell_type":{"f37cd2f1":"code","ede4b8e3":"code","0f731de5":"code","da7f5e04":"code","777c7bc5":"code","3da0cafa":"code","1bf056e7":"code","7feaaca8":"code","3c1307f7":"code","85ae281f":"code","017df71a":"code","ebc7dc6e":"code","04106b2b":"code","61481d45":"code","3e37c42c":"code","6bb6c3e2":"code","82f04f5a":"code","38bcfe41":"code","a2721fd9":"code","6c4774f9":"code","0022e369":"markdown","c1360932":"markdown"},"source":{"f37cd2f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\"\"\"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\"\"\"\n\n# Any results you write to the current directory are saved as output.","ede4b8e3":"os.chdir('\/kaggle\/input\/histopathologic-cancer-detection')\nos.listdir()\ntest_files=os.listdir('test') # Name of the images of the test dataset","0f731de5":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.applications.resnet import ResNet50\nfrom keras.layers import Dense,Conv2D,MaxPool2D,BatchNormalization,Dropout,Flatten,AvgPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD,RMSprop,Adam\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA,LatentDirichletAllocation\nimport eli5","da7f5e04":"import pandas as pd\nsample_submission = pd.read_csv(\"sample_submission.csv\")\ntrain_labels = pd.read_csv(\"train_labels.csv\")\ntrain_labels['label']=train_labels['label'].apply(lambda x:str(x))\ntrain_labels['id']=train_labels['id'].apply(lambda x:str(x)+'.tif')","777c7bc5":"train_labels['label'].value_counts().plot(kind='bar')\nprint(train_labels['label'].value_counts())\nplt.yticks(color='yellow')\nplt.xticks(color='yellow')","3da0cafa":"# The dataset is imbalanced. So we will check ADASYN or SMOTE","1bf056e7":"%%time\ntrain_datagen=ImageDataGenerator(rescale=1.\/255,validation_split=0.15)\ntest_datagen=ImageDataGenerator(rescale=1.\/255)\ntraindir='train'\ntestdir='test'\ntrain=train_datagen.flow_from_dataframe(train_labels,directory=traindir,\n                                        x_col='id',y_col='label',\n                                        subset='training',\n                                        target_size=(96,96),\n                                        batch_size=64,class_mode='binary')\n\nvalidation=train_datagen.flow_from_dataframe(train_labels,directory=traindir,\n                                        x_col='id',y_col='label',\n                                        subset='validation',\n                                        target_size=(96,96),\n                                        batch_size=64,class_mode='binary')","7feaaca8":"print(f\"Length of the training dataset is {len(train)*64} ,validation {len(validation)*64} ,test {len(test_files)}\")","3c1307f7":"# Visualizing some examples\ntemp_img,temp_label=next(iter(train))\nj=0\nfig=plt.figure(figsize=(10,10))\nfor idx, img in enumerate(temp_img):\n    if j==16:\n        break\n    j+=1\n    ax = fig.add_subplot(4,4, idx+1)\n    plt.imshow(img)\n    lab = temp_label[idx]\n    ax.set_title('Label: %s'%lab,color='yellow')","85ae281f":"tsne=TSNE(n_components=2,init='pca')","017df71a":"%time\nims=[] # For Images\nlbs=[] # For labels\nfor idx,batch in enumerate(train):\n    image,label=batch\n    image=[i.reshape(-1) for i in image]\n    ims+=image\n    for i in label:\n        lbs.append(i)\n    if len(ims)>1000:\n        print(len(ims))\n        break","ebc7dc6e":"%%time\nplt.figure(figsize=(10,10))\nims=tsne.fit_transform(ims)\nplt.scatter(ims[:,0],ims[:,1],c=lbs)\nplt.legend([\"Not a Cancer Cell\",\"Cancer Cell\"])","04106b2b":"# So we can see how the classes are clustered and how one class actually","61481d45":"classifier=Sequential()\n\n# Conv1 Layer\nclassifier.add(Conv2D(16,(3,3),strides=(1,1),input_shape=(96,96,3),activation='relu'))\nclassifier.add(Conv2D(16,(3,3),activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n# Conv2 Layer\nclassifier.add(Conv2D(32,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(32,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(32,(3,3),strides=1,activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n\n# Conv3 Layer\nclassifier.add(Conv2D(64,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(64,(3,3),strides=1,activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n\n# Conv4 Layer\nclassifier.add(Conv2D(128,(3,3),strides=1,activation='relu'))\nclassifier.add(Conv2D(128,(3,3),strides=1,activation='relu'))\nclassifier.add(MaxPool2D(2))\nclassifier.add(BatchNormalization())\n\n\n# Dense Layer\nclassifier.add(Flatten())\nclassifier.add(Dense(units=128,activation='relu'))\nclassifier.add(Dense(units=64,activation='relu'))\nclassifier.add(Dense(units=32,activation='relu'))\nclassifier.add(Dense(units=1,activation='sigmoid'))\n\nclassifier.compile(optimizer=Adam(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy'])","3e37c42c":"classifier.summary()","6bb6c3e2":"history=classifier.fit_generator(train,epochs=9,validation_data=validation)","82f04f5a":"def occlusion_analysis(image,label,occluding_size,occluding_pixel,occluding_stride):\n    \"\"\" Convnet Visualization \"\"\"\n    \n    \n    height,width,_=image.shape\n    image=np.expand_dims(image,axis=0)\n    out=classifier.predict(image)\n    \n    # Setting up output height and output width\n    \n    output_height=int(np.floor((height-occluding_size)\/occluding_stride+1))\n    output_width=int(np.floor((width-occluding_size)\/occluding_stride+1))\n    heatmap=np.zeros((output_height,output_width))\n    \n    for h in range(output_height):\n        for w in range(output_width):\n            # Occluder region\n            \n            h_start=h*occluding_stride\n            h_end=min(height,h_start+occluding_size)\n            \n            w_start=w*occluding_stride\n            w_end=min(width,w_start+occluding_size)\n            \n            input_image=image.copy()\n            \n            input_image[:,h_start:h_end,w_start:w_end,:]=occluding_pixel\n            \n            predict=classifier.predict(input_image)\n            \n            heatmap[h,w]=predict\n            \n    f=plt.figure(figsize=(10,10))\n    f.add_subplot(2,2,1)\n    sns.heatmap(heatmap,xticklabels=True)\n    f.add_subplot(2,2,3\"]))\n    plt.imshow(image[0])\n    plt.title(label)\n    plt.show()","38bcfe41":"#y1,l1=next(iter(train))","a2721fd9":"#%%time\n#occlusion_analysis(y1[2],l1[2],occluding_size=40,occluding_pixel=2,occluding_stride=1)","6c4774f9":"#plt.imshow(y1[2])","0022e369":"# Dataset Generator","c1360932":"# Visualizing with T-Stochastic Neighbour Embedding"}}