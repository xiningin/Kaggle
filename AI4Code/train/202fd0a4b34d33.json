{"cell_type":{"5fb2ba49":"code","817bf00b":"code","8d48f911":"code","980179aa":"code","b12e78f5":"code","f5ed6610":"code","dc868e32":"code","2591bb28":"code","b7357dd3":"code","dffa9813":"code","6f7b685a":"code","49d2c60f":"code","d1cee32c":"code","859ef62a":"code","a6cf0618":"code","8cf39df3":"code","abe576db":"code","a6ac8112":"code","c363061c":"code","98dbd2f4":"code","b03fbf6e":"code","9e96d3d0":"code","f5c6a5f6":"code","cb9b4dca":"code","c7668625":"markdown","612bc53a":"markdown","c2df543f":"markdown","98cc8201":"markdown","99feba4e":"markdown","ab100732":"markdown","3be8078a":"markdown","66456843":"markdown","c0f21674":"markdown","4e7c02bb":"markdown"},"source":{"5fb2ba49":"import numpy as np \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nimport cv2\nimport os \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport random","817bf00b":"os.listdir('\/kaggle\/input\/watermarked-not-watermarked-images\/wm-nowm') # directory with the images (root)","8d48f911":"# directory paths \ntrain_path = '\/kaggle\/input\/watermarked-not-watermarked-images\/wm-nowm\/train' # training directory\nvalid_path = '\/kaggle\/input\/watermarked-not-watermarked-images\/wm-nowm\/valid' # validation directory","980179aa":"def takeFileName(filedir): # remove just file name from directory and return\n    # filename = np.array(filedir.split('\/'))[-1].split('.')[0] # take out the name, isolate the jpeg, then return the name\n    filename = np.array(filedir.split('\/'))[-1] # take out the name, then return the name\n    # print(filename)\n    return filename","b12e78f5":"def matchFileNames(watermarkedarr, nonwatermarkedarr, dname_wm, dname_nwm):\n    sortedwmarr = np.array([])\n    sortednwmarr = np.array([])\n    \n    wmarr = list(watermarkedarr)\n    nwmarr = list(nonwatermarkedarr)\n    \n    length = len(watermarkedarr) if len(watermarkedarr) >= len(nonwatermarkedarr) else len(nonwatermarkedarr)\n    \n    for pos in range(length):\n        try:\n            if length == len(watermarkedarr): # more images in watermarked array\n                exist_nwm = nwmarr.index(wmarr[pos])\n                sortedwmarr = np.append(sortedwmarr, dname_wm + watermarkedarr[pos]) # this is the iterable\n                sortednwmarr = np.append(sortednwmarr, dname_nwm + nonwatermarkedarr[exist_nwm]) # this is the match\n            elif length == len(nonwatermarkedarr): # more images in nonwatermarked array\n                exist_wm = wmarr.index(nwmarr[pos])\n                sortedwmarr = np.append(sortedwmarr, dname_wm + watermarkedarr[exist_wm]) # this is the match\n                sortednwmarr = np.append(sortednwmarr, dname_nwm + nonwatermarkedarr[pos]) # this is the iterable\n        except ValueError: \n            continue\n    return sortedwmarr, sortednwmarr","f5ed6610":"# Sort the watermarked and non watermarked images into parallel arrays so NN will use it better\n\ntrain_path_watermarked_images = '..\/input\/watermarked-not-watermarked-images\/wm-nowm\/train\/watermark\/'\ntrain_path_nonwatermarked_images = '..\/input\/watermarked-not-watermarked-images\/wm-nowm\/train\/no-watermark\/'\n\ntp_watermarked = np.array([]) # array with watermarked image names\ntp_nonwatermarked = np.array([]) # array with nonwatermarked image names\n\nfor root, dirs, files in os.walk(train_path_watermarked_images, topdown=True): # data length = 12510\n    for file in files:\n        tp_watermarked = np.append(tp_watermarked, takeFileName(file)) # append just the name of the file into array\n    \nfor root, dirs, files in os.walk(train_path_nonwatermarked_images, topdown=True): # data length = 12477\n    for file in files:\n        tp_nonwatermarked = np.append(tp_nonwatermarked, takeFileName(file)) # append just the name of the file into array\n        \ntp_watermarked_sorted, tp_nonwatermarked_sorted = matchFileNames(tp_watermarked, tp_nonwatermarked, train_path_watermarked_images, train_path_nonwatermarked_images)\n\n\nvalid_path_watermarked_images = '..\/input\/watermarked-not-watermarked-images\/wm-nowm\/valid\/watermark\/'\nvalid_path_nonwatermarked_images = '..\/input\/watermarked-not-watermarked-images\/wm-nowm\/valid\/no-watermark\/'\n\nvp_watermarked = np.array([]) # array with watermarked image names\nvp_nonwatermarked = np.array([]) # array with nonwatermarked image names\n\nfor root, dirs, files in os.walk(valid_path_watermarked_images, topdown=True): # data length = 3299\n    for file in files:\n        vp_watermarked = np.append(vp_watermarked, takeFileName(file)) # append just the name of the file into array\n    \nfor root, dirs, files in os.walk(valid_path_nonwatermarked_images, topdown=True): # data length = 3289\n    for file in files:\n        vp_nonwatermarked = np.append(vp_nonwatermarked, takeFileName(file)) # append just the name of the file into array\n        \nvp_watermarked_sorted, vp_nonwatermarked_sorted = matchFileNames(vp_watermarked, vp_nonwatermarked, valid_path_watermarked_images, valid_path_nonwatermarked_images)","dc868e32":"# dimension to resize to \nwidth = 196 # only certain dimensions work due to UpSampling (196x196 works, 148x148 works)\nheight = 196\ndim = (width, height) # set the dimensions\n\ndef createPixelArr(files):\n    data = []\n    for image in files:\n        try: # take each image and use imread to get the pixel values in a matrix \n            img_arr = cv2.imread(image, cv2.IMREAD_COLOR)\n            resized_arr = cv2.resize(img_arr, (width, height)) # rescale the image so every image is of the same dimension\n            data.append(resized_arr) # add the matrix of pixel values \n        except Exception as e:\n            print(e) # some error thrown in imread or resize\n    return np.array(data)\n\ntrain_wms_pixVals = createPixelArr(tp_watermarked_sorted)\ntrain_nwms_pixVals = createPixelArr(tp_nonwatermarked_sorted)\n\nval_wms_pixVals = createPixelArr(vp_watermarked_sorted)\nval_nwms_pixVals = createPixelArr(vp_nonwatermarked_sorted) # make ndarrays","2591bb28":"# TODO check if watermark and non-watermark pictures are read in correctly - (quality control) \n# make sure you create a function to make the process more efficient ","b7357dd3":"# TODO use sklearn to split tp_wms_pixVals, tp_nwms_pixVals into training and testing sets\n# use variables names: X_train, y_train, X_test, y_test\n# 80% training, 20% testing, amount of shuffling applied\nX_train, X_test, y_train, y_test = train_test_split(train_wms_pixVals, train_nwms_pixVals, train_size=0.8, random_state=1) ","dffa9813":"train_wms_pixVals = 0 \ntrain_nwms_pixVals = 0 \nval_wms_pixVals = 0 \nval_nwms_pixVals = 0 ","6f7b685a":"plt.figure(figsize=(25,25))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(X_test[i], cv2.COLOR_BGR2RGB))\nplt.show()","49d2c60f":"# Functions to data augment images \n\ndef data_augmentation(inputImage): # run image through all augmentation methods\n    return randomContrast(randomBrightness(inputImage)).numpy()\n    # return randomCrop(randomFlip(inputImage)) # use augmentation methods without messing with colour \n\ndef randomFlip(pic): # flips the image up and down before left and right at random\n    return tf.image.random_flip_up_down(tf.image.random_flip_left_right(pic, 1), 1)\n\n# def randomCrop(pic): # crops the image from a randomly defined width and height, that are under the intial image width and height\n#     return tf.image.random_crop(pic, size=[random.randint(75,width), random.randint(75,height), 3], seed=None)\n\ndef randomBrightness(pic): # makes the image a random brightness from 1% to 20%\n    return tf.image.random_brightness(pic, random.uniform(0.01, 0.2), 1)\n\ndef randomContrast(pic): # contrasts the image from 5% to 50%\n    return tf.image.random_contrast(pic, 0.2, 0.7, 1)","d1cee32c":"# Output Tensorflow data augmented images\nplt.figure(figsize=(25,25))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    augmented_image = data_augmentation(X_train[random.randint(1, len(X_train))]) # send 25 images into data augmentation\n    plt.imshow(cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB)) # not using cv2 as it messed up the code\nplt.show()","859ef62a":"#apply data augmentation to the X_train and y_train\n\ndata_augmented_X = [] \ndata_augmented_y = []\n\nfor image in X_train:\n    data_augmented_X.append(data_augmentation(image))\n    \nfor image in y_train:\n    data_augmented_y.append(data_augmentation(image))","a6cf0618":"plt.figure(figsize=(25,25))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(data_augmented_X[i], cv2.COLOR_BGR2RGB))\nplt.show()","8cf39df3":"plt.figure(figsize=(25,25))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(data_augmented_y[i], cv2.COLOR_BGR2RGB))\nplt.show()","abe576db":"X_train = np.append(X_train, data_augmented_X, axis=0)\ny_train = np.append(y_train, data_augmented_y, axis=0)","a6ac8112":"# normalize \nX_train = X_train \/ 255\ny_train = y_train \/ 255\nX_test = X_test \/ 255\ny_test = y_test \/ 255","c363061c":"# base model for removing \n\ndef create_model(img_x, img_y):\n    x = Input(shape=(img_x, img_y, 3))\n    \n    # Think this process as function composition in algebra \n    \n    # Encoder - compresses the input into a latent representation\n    e_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    pool1 = MaxPooling2D((2, 2), padding='same')(e_conv1)\n    batchnorm_1 = BatchNormalization()(pool1)\n    \n    e_conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(batchnorm_1)\n    pool2 = MaxPooling2D((2, 2), padding='same')(e_conv2)\n    batchnorm_2 = BatchNormalization()(pool2)\n    \n    e_conv3 = Conv2D(16, (3, 3), activation='relu', padding='same')(batchnorm_2)\n    h = MaxPooling2D((2, 2), padding='same')(e_conv3)\n    \n    # Decoder - reconstructs the input from a latent representation \n    d_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n    up1 = UpSampling2D((2, 2))(d_conv1)\n    \n    d_conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1)\n    up2 = UpSampling2D((2, 2))(d_conv2)\n    \n    d_conv3 = Conv2D(16, (3, 3), activation='relu')(up2)\n    up3 = UpSampling2D((2, 2))(d_conv3)\n    \n    r = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n    \n    model = Model(x, r)\n    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n    return model","98dbd2f4":"watermark_auto_encoder = create_model(width, height)\nearly_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\nhistory = watermark_auto_encoder.fit(X_train, y_train, batch_size=20, epochs=100, callbacks=[early_stop])","b03fbf6e":"result = watermark_auto_encoder.predict(X_test)\nwatermark_auto_encoder.evaluate(X_test, result)","9e96d3d0":"plt.imshow(cv2.cvtColor(result[5], cv2.COLOR_BGR2RGB))","f5c6a5f6":"plt.figure(figsize=(25,25))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(X_test[i].astype('float32'), cv2.COLOR_BGR2RGB))\nplt.show()","cb9b4dca":"plt.figure(figsize=(25,25))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(cv2.cvtColor(result[i], cv2.COLOR_BGR2RGB))\nplt.show()","c7668625":"Normalizet the values between 0 and 1","612bc53a":"# Methods for data augmentation","c2df543f":"Combine the augmented images with the training sets","98cc8201":"# Watermark removal using convolutional autoencoder\n\nThe goal of this project is to remove watermarks from pictures using a convolutional autoencoder network. We want the model to generalize well with different pictures, that is one the reasons we chose to use this dataset. \n\nLibraries utilized: tensorflow, sklearn, matplotlib, numpy\n\nCollabed with Arjun Viswanthan et al\n\n![](https:\/\/external-content.duckduckgo.com\/iu\/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F3632%2F1*2zID-391yWcI0y4ZGw1FyA.jpeg&f=1&nofb=1)\nPicture credits: https:\/\/phototips.medium.com\/how-to-remove-watermark-from-photos-in-3-fast-best-ways-9573924c08","99feba4e":"Garbage collection - free up RAM","ab100732":"# Data Processing\nWe want to make sure that the images in the non-watermarked and watermarked sets are the same. This can be achieved by checking if they have the same file name. ","3be8078a":"# Base convolutional autoencoder ","66456843":"# Data Augmentation Pictures","c0f21674":"# Results of the convolutional autoencoder model","4e7c02bb":"# Actual vs Predictions "}}