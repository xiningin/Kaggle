{"cell_type":{"6e0d779b":"code","954bac79":"code","9bd0f986":"code","4ade0ccb":"code","613d7c2b":"code","686c1e06":"code","ed827e1e":"code","5220abcd":"code","e089bb96":"code","38dc6a06":"code","b9936938":"code","a7c29085":"code","5de93e35":"code","15681f1e":"code","fb7dacb9":"code","fefe81f3":"code","adfb4bbd":"code","76744351":"code","fead16d9":"code","a26c31a0":"code","58bf9839":"code","8db2ce2e":"code","faf59aca":"code","00a121ad":"code","aeb4a128":"code","a038ae58":"code","984989df":"code","604e93c7":"code","dea539dc":"code","83e36f9b":"code","377a3fdf":"code","50ca1e51":"code","44df9866":"code","07493d95":"code","4222ff07":"code","b381e5de":"code","87ca3c09":"code","eb59fa25":"code","c6d279d0":"code","a11a38f7":"code","3b967a29":"code","1bc38d17":"code","af3a0e9b":"code","77b3940e":"markdown","5f138ca3":"markdown","91c065cb":"markdown","135cb5aa":"markdown","d9bec2b9":"markdown","5ba70d86":"markdown","4b273b9e":"markdown","e1907d11":"markdown","e7e8e4af":"markdown","1cce23fd":"markdown","d665471b":"markdown","788200c3":"markdown","81c6959d":"markdown","0dda02f0":"markdown","c41d9c96":"markdown","2d1e1af3":"markdown","9931cbe8":"markdown"},"source":{"6e0d779b":"import os\nfrom fastai.vision.all import *\nimport SimpleITK as sitk\nimport shutil","954bac79":"path = Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train')","9bd0f986":"!mkdir t1w_nifti\n!mkdir t1wce_nifti\n!mkdir t2w_nifti\n!mkdir flair_nifti","4ade0ccb":"samples = [Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00002'),\n           Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00194'),\n           Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00094'),\n           Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00734'),\n           Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00526')]","613d7c2b":"path_train_t2w, path_train_t1wce,path_train_t1w,path_train_flair = [],[],[],[]\nfor each in samples:\n    path_train_t2w.append(each.ls()[0])\n    path_train_t1wce.append(each.ls()[1])\n    path_train_t1w.append(each.ls()[2])\n    path_train_flair.append(each.ls()[3])","686c1e06":"def dicom2nifti(image_dir, out_dir, save=True):\n    \"given a dicom directory, loads them into single file and can save it as .nii file\"\n    reader = sitk.ImageSeriesReader()\n    reader.LoadPrivateTagsOn()\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(str(image_dir))\n    reader.SetFileNames(filenamesDICOM)\n    img = reader.Execute()\n    img = sitk.Cast(img, sitk.sitkFloat32)\n    \n    if save:\n        sitk.WriteImage(img, f'{out_dir}\/{image_dir.parent.name}.nii')\n    else:\n        return img","ed827e1e":"for fn in path_train_t1w: dicom2nifti(fn, \"\/kaggle\/working\/t1w_nifti\/\")\nfor fn in path_train_t1wce: dicom2nifti(fn, \"\/kaggle\/working\/t1wce_nifti\/\")\nfor fn in path_train_t2w: dicom2nifti(fn, \"\/kaggle\/working\/t2w_nifti\/\")\nfor fn in path_train_flair: dicom2nifti(fn, \"\/kaggle\/working\/flair_nifti\/\")","5220abcd":"def get_array(fn):\n    \"opens .nii file and return the array\"\n    img = sitk.ReadImage(str(fn))\n    imgd = sitk.GetArrayFromImage(img)\n    return imgd\n\ndef plot_slice(imgd, sli):\n    \"given an image of shape slices x height x width, plots a slice\"\n    plt.imshow(imgd[sli], cmap='gray')\n    plt.axis('off')\n    \ndef get_array_plot(fn, sli):\n    imgd = get_array(fn)\n    plot_slice(imgd, sli)","e089bb96":"samp_pat = '00094'","38dc6a06":"get_array_plot(Path(f'.\/t1w_nifti\/{samp_pat}.nii'), 20)","b9936938":"get_array_plot(Path(f'.\/t1wce_nifti\/{samp_pat}.nii'), 45)","a7c29085":"get_array_plot(Path(f'.\/t2w_nifti\/{samp_pat}'), 120)","5de93e35":"get_array_plot(Path(f'.\/flair_nifti\/{samp_pat}'), 80)","15681f1e":"def resample_nifti(image_dir, ref_image, fn, save=True):\n    \"resample using a reference image\"\n\n    image = sitk.ReadImage(str(image_dir), sitk.sitkFloat32)\n    \n    initial_transform = sitk.CenteredTransformInitializer(ref_image, \n                                                          image, \n                                                          sitk.Euler3DTransform(), \n                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear)\n    resampler.SetTransform(initial_transform)\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n    resampler.SetSize((ref_image.GetSize()))\n    resampler.SetOutputDirection(ref_image.GetDirection())\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n    resamped_image = resampler.Execute(image)\n    \n    if save:\n        sitk.WriteImage(resamped_image, fn)\n\n    return resamped_image","fb7dacb9":"ref_image = sitk.ReadImage('..\/input\/sri24-dataset\/sri24\/spgr.nii', sitk.sitkFloat32)","fefe81f3":"!mkdir t1w_resample\n!mkdir t1wce_resample\n!mkdir t2w_resample\n!mkdir flair_resample","adfb4bbd":"for fn in Path(\".\/t1w_nifti\").ls():\n    pat_id = str(fn).split('\/')[-1].split('.')[0]\n    final_fn = f\"\/kaggle\/working\/t1w_resample\/{pat_id}_0001.nii.gz\"\n    resample_nifti(fn, ref_image, final_fn, True)\n    os.remove(str(fn))","76744351":"for fn in Path(\".\/t1wce_nifti\").ls():\n    pat_id = str(fn).split('\/')[-1].split('.')[0]\n    final_fn = f\"\/kaggle\/working\/t1wce_resample\/{pat_id}_0002.nii.gz\"\n    resample_nifti(fn, ref_image, final_fn, True)\n    os.remove(str(fn))","fead16d9":"for fn in Path(\".\/t2w_nifti\").ls():\n    pat_id = str(fn).split('\/')[-1].split('.')[0]\n    final_fn = f\"\/kaggle\/working\/t2w_resample\/{pat_id}_0003.nii.gz\"\n    resample_nifti(fn, ref_image, final_fn, True)\n    os.remove(str(fn))","a26c31a0":"for fn in Path(\".\/flair_nifti\").ls():\n    pat_id = str(fn).split('\/')[-1].split('.')[0]\n    final_fn = f\"\/kaggle\/working\/flair_resample\/{pat_id}_0000.nii.gz\"\n    resample_nifti(fn, ref_image, final_fn, True)\n    os.remove(str(fn))","58bf9839":"get_array_plot(Path(f'\/kaggle\/working\/t1w_resample\/{samp_pat}_0001.nii.gz'), 85)","8db2ce2e":"get_array_plot(Path(f'\/kaggle\/working\/t1wce_resample\/{samp_pat}_0002.nii.gz'), 85)","faf59aca":"get_array_plot(Path(f'\/kaggle\/working\/t2w_resample\/{samp_pat}_0003.nii.gz'), 85)","00a121ad":"get_array_plot(Path(f'\/kaggle\/working\/flair_resample\/{samp_pat}_0000.nii.gz'), 85)","aeb4a128":"!rm -rf t1w_nifti\n!rm -rf t1wce_nifti\n!rm -rf t2w_nifti\n!rm -rf flair_nifti","a038ae58":"import os\nbase_dir = '\/kaggle\/working\/'\nos.chdir(base_dir)","984989df":"!git clone https:\/\/github.com\/MIC-DKFZ\/nnUNet.git \n!git clone https:\/\/github.com\/NVIDIA\/apex","604e93c7":"respository_dir = os.path.join(base_dir,'nnUNet')\nos.chdir(respository_dir)\n\n!pip install -e .\n#(optional installation)\n!pip install --upgrade git+https:\/\/github.com\/nanohanno\/hiddenlayer.git@bugfix\/get_trace_graph#egg=hiddenlayer\n\nos.chdir(base_dir)","dea539dc":"#import IPython\n#IPython.Application.instance().kernel.do_shutdown(True)","83e36f9b":"import os\nfrom fastai.vision.all import *\nimport SimpleITK as sitk\nimport shutil\n\nbase_dir = '\/kaggle\/working\/'\nos.chdir(base_dir)","377a3fdf":"def make_if_dont_exist(folder_path,overwrite=False):\n    \"\"\"\n    creates a folder if it does not exists\n    input: \n    folder_path : relative path of the folder which needs to be created\n    over_write :(default: False) if True overwrite the existing folder \n    \"\"\"\n    if os.path.exists(folder_path):\n        \n        if not overwrite:\n            print(f'{folder_path} exists.')\n        else:\n            print(f\"{folder_path} overwritten\")\n            shutil.rmtree(folder_path)\n            os.makedirs(folder_path)\n\n    else:\n        os.makedirs(folder_path)\n        print(f\"{folder_path} created!\")","50ca1e51":"task_name = 'Task001_BrainTumour' #change here for different task name\nnnunet_dir = \"nnUNet\/nnunet\/nnUNet_raw_data_base\/nnUNet_raw_data\"\ntask_folder_name = os.path.join(nnunet_dir,task_name)\ntrain_image_dir = os.path.join(task_folder_name,'imagesTr')\ntrain_label_dir = os.path.join(task_folder_name,'labelsTr')\ntest_dir = os.path.join(task_folder_name,'imagesTs')\nmain_dir = os.path.join(base_dir,'nnUNet\/nnunet')","44df9866":"make_if_dont_exist(task_folder_name,overwrite = False)\nmake_if_dont_exist(train_image_dir)\nmake_if_dont_exist(train_label_dir)\nmake_if_dont_exist(test_dir,overwrite= False)\nmake_if_dont_exist(os.path.join(main_dir,'nnunet_trained_models'))","07493d95":"os.environ['nnUNet_raw_data_base'] = os.path.join(main_dir,'nnUNet_raw_data_base')\nos.environ['nnUNet_preprocessed'] = os.path.join(main_dir,'preprocessed')\nos.environ['RESULTS_FOLDER'] = os.path.join(main_dir,'nnUNet_trained_models')","4222ff07":"#!nnUNet_print_available_pretrained_models\n!nnUNet_download_pretrained_model Task001_BrainTumour","b381e5de":"path_ts = '\/kaggle\/working\/nnUNet\/nnunet\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task001_BrainTumour\/imagesTs'","87ca3c09":"for fn in Path(\".\/t1w_resample\").ls(): \n    pat_id = fn.name.split('.')[0].split('_')[0]\n    shutil.copy(f'\/kaggle\/working\/t1w_resample\/{pat_id}_0001.nii.gz', f'{path_ts}')\n    shutil.copy(f'\/kaggle\/working\/t1wce_resample\/{pat_id}_0002.nii.gz', f'{path_ts}\/{pat_id}_0002.nii.gz')\n    shutil.copy(f'\/kaggle\/working\/t2w_resample\/{pat_id}_0003.nii.gz', f'{path_ts}\/{pat_id}_0003.nii.gz')\n    shutil.copy(f'\/kaggle\/working\/flair_resample\/{pat_id}_0000.nii.gz', f'{path_ts}\/{pat_id}_0000.nii.gz')\n    \n    os.remove(f'\/kaggle\/working\/t1w_resample\/{pat_id}_0001.nii.gz')\n    os.remove(f'\/kaggle\/working\/t1wce_resample\/{pat_id}_0002.nii.gz')\n    os.remove(f'\/kaggle\/working\/t2w_resample\/{pat_id}_0003.nii.gz')\n    os.remove(f'\/kaggle\/working\/flair_resample\/{pat_id}_0000.nii.gz')","eb59fa25":"result_dir = os.path.join(main_dir,'nnUNet_Prediction_Results',task_name)\nmake_if_dont_exist(result_dir)\n\nteam_name = 'arshath'\n\n#location where you want save your results, will be created if dont exist\nos.chdir(main_dir)\n!nnUNet_predict -i nnUNet_raw_data_base\/nnUNet_raw_data\/Task001_BrainTumour\/imagesTs -o nnUNet_Prediction_Results\/Task001_BrainTumour -t 001 -tr nnUNetTrainerV2 -m 3d_fullres --disable_tta \nos.chdir(base_dir)","c6d279d0":"import os\nfrom fastai.vision.all import *\nimport SimpleITK as sitk\nimport shutil","a11a38f7":"path_ts = '\/kaggle\/working\/nnUNet\/nnunet\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task001_BrainTumour\/imagesTs'\npath_lbl = '\/kaggle\/working\/nnUNet\/nnunet\/nnUNet_Prediction_Results\/Task001_BrainTumour'\nsamp_pat = '00094'","3b967a29":"def get_array(fn):\n    \"opens .nii file and return the array\"\n    img = sitk.ReadImage(str(fn))\n    imgd = sitk.GetArrayFromImage(img)\n    return imgd\n\ndef plot_slice(imgd, sli):\n    \"given an image of shape slices x height x width, plots a slice\"\n    plt.imshow(imgd[sli], cmap='gray')\n    plt.axis('off')\n    \ndef get_array_plot(fn, sli):\n    imgd = get_array(fn)\n    plot_slice(imgd, sli)","1bc38d17":"get_array_plot(f'{path_ts}\/{samp_pat}_0003.nii.gz', 85)","af3a0e9b":"get_array_plot(f'{path_lbl}\/{samp_pat}.nii.gz', 85)","77b3940e":"# 5. Inference - Make Masks","5f138ca3":"## Environment Veriables","91c065cb":"# 3. Git clone and set up nnUnet","135cb5aa":"In this notebook, we will see how we can make use nnUnet to make masks for this competition. \n\nWhat is [nnUnet](https:\/\/github.com\/MIC-DKFZ\/nnUNet)?\n>nnU-Net is the first segmentation method that is designed to deal with the dataset diversity found in the domain (medical). It condenses and automates the key decisions for designing a successful segmentation pipeline for any given dataset. \nnnUnet was published in [Nature](https:\/\/www.nature.com\/articles\/s41592-020-01008-z)\n\nAbstract from nature:\n>Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training.\n\nnnUnet lead the [Medical Decathlon competition](http:\/\/medicaldecathlon.com\/results\/).  \n\nWe will make use of nnUnet's Task01-Brain Tumouur Segmentation pretrained model to generate masks. \n\nWe will follow the following steps\n1. Select 5 random patients\n2. Resample the images using SimpleITK and SIR24 dataset - I have a [notebook](https:\/\/www.kaggle.com\/marshath\/btrg-dicom-to-nifti-using-sri24-to-resample) completely for this\n3. Git clone and set up nnUnet - This [notebook](https:\/\/github.com\/prateekgupta891\/nnUNet\/blob\/master\/nnunetmec2020.ipynb) here was my light\n4. Prepare the data as per nnUnet's requirement\n5. Make masks!","d9bec2b9":"Looks like we have resampled them. If you noticed, we added four digits to the file names. This is because nnUnet (Task01 - Brain Tumour) requires all four modalities \n\n`0000 - flair, 0001 - T1w, 0002 - T1wce, 0003 - T2w`","5ba70d86":"## Download the pretrained model","4b273b9e":"`labels: {'0': 'background',  '1': 'edema', '2': 'non-enhancing tumor', '3': 'enhancing tumour'}` - following is the labels ","e1907d11":"Let's take a look at the images","e7e8e4af":"### 2. Resample the images using SimpleITK and SIR24 dataset","1cce23fd":"# 1. Select 5 random patients ","d665471b":"**Note** Restart the notebook","788200c3":"# 0. Imports and paths","81c6959d":"As we can see, for orientations are different across the different modalities. Let's resample using SRI24 as the template. ","0dda02f0":"## Dataset Folder Structure","c41d9c96":"# 4. Prepare the data as per nnUnet's requirement","2d1e1af3":"Let's convert the images into nifti","9931cbe8":"## Finally let's check the masks"}}