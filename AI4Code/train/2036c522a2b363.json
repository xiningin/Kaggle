{"cell_type":{"5a4ac6d9":"code","1aa62c26":"code","54700a6b":"code","25627fff":"code","75ae2753":"code","6306d34b":"code","6e5674f1":"code","4a58738e":"code","522175c9":"code","4fb77b2e":"code","9c2e428d":"code","2fbe709c":"code","fe63636a":"code","66a02aad":"code","321697b9":"code","ecc7d28f":"code","1e66747f":"code","4ca5ecd9":"code","4671e91d":"code","a2a973c6":"code","bd50a011":"code","0364dfec":"code","4129a57e":"code","14ef3119":"code","2e79ce36":"code","4eabfc1d":"code","99dcf12a":"code","5781ada5":"code","e6d2cf27":"code","fc7d30a8":"code","f9922eda":"code","6e49b60b":"code","cfb99310":"code","b9b57f8c":"code","57338be3":"code","e1b4d9fe":"code","b4c5b67b":"code","7612eca4":"code","18d55e58":"code","afb6cb8a":"code","d1806a62":"code","2fb40679":"code","b891e28b":"code","9309147f":"code","7f70534f":"code","83f624e8":"code","ac147f62":"code","b94ae91f":"code","41dc4fe7":"code","0d4a5b95":"code","7c393f8f":"code","68308371":"code","9bd3f205":"code","fbb848d5":"code","1b42ebac":"code","a6d65c7b":"code","b35991ea":"code","c0e6b972":"code","e5c16df2":"code","4715019e":"code","d3252c70":"code","47c63d88":"code","ee29cce8":"code","2b28fb3a":"code","37aab31a":"code","ba32e6d1":"code","aa9fe9ce":"code","b800bc5d":"code","d1ac5426":"code","5debfab3":"code","4c83394c":"code","70ecf100":"code","7c613b2e":"code","9f277209":"code","79bf130b":"code","87c1cd75":"code","c6883b15":"code","54027309":"code","1e306cdb":"code","d0a6b9d9":"code","602bea0f":"code","3e926c36":"code","cf7f9ba1":"code","d45efd55":"code","b5d96922":"code","3d6b7f43":"code","5321c120":"code","7ac60ff4":"code","90f04f74":"code","310dfbe1":"code","23be9a8b":"code","2911a34f":"code","0cf6476a":"code","00b3556e":"code","3d77b5af":"code","54973315":"code","355d93db":"markdown","fe77cdd2":"markdown","d119af2d":"markdown","0aa98b55":"markdown","ffd07b5b":"markdown","6e32c09a":"markdown","986ed819":"markdown","ef2b31bf":"markdown","7989ce22":"markdown"},"source":{"5a4ac6d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1aa62c26":"import pandas as pd            # Data Analytical library\nimport numpy as np             # Fast Linear Alegbra\nimport matplotlib.pyplot as plt# Visulisation\nimport seaborn as sns          # Statisitical Viz","54700a6b":"#Loading the training and test dataset\ndf_test=pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/Test_SJC.csv\")\ndf_train=pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/train_SJC.csv\")\n# viewing first six columns of test dataset\ndf_test.head(7)","25627fff":"#viewing first six columns of train data\ndf_train=df_train.rename(columns={\"Unnamed: 0\":\"ClaimNumber\",\"Unnamed: 1\":\"DateTimeOfAccident\",\"Unnamed: 3\":\"Age\",\"Unnamed: 4\":\"Gender\",\"Unnamed: 5\":\"MaritalStatus\",\"Unnamed: 6\":\"DependentChildren\",\"Unnamed: 8\":\"WeeklyWages\",\"Unnamed: 9\":\"PartTimeFullTime\",\"Unnamed: 10\":\"HoursWorkedPerWeek\",\"Unnamed: 12\":\"ClaimDescription\",\"Unnamed: 13\":\"InitialIncurredCalimsCost\",\"Unnamed: 14\":'UltimateIncurredClaimCost'},inplace=False)\ndf_train.head(7)","75ae2753":"print (\"Train data shape:\", df_train.shape)\nprint (\"Test data shape:\", df_test.shape)","6306d34b":"df_test.info()  #dataframe summary of test data","6e5674f1":"df_train.info()  #dataframe summary of train dataset","4a58738e":"df_train.describe() # statistical inference about test dataset","522175c9":"df_test.describe()  # statistical inference about test dataset","4fb77b2e":"df_test.select_dtypes(include=[int,float]).describe() #numerical variables in test data","9c2e428d":"df_test.select_dtypes(include='object').describe() #categorical variables in test data","2fbe709c":"# CHECK FOR MISSING VAUE IN TRAIN DATA:\ndf_train.isnull().sum()   # column vise report of the missing value","fe63636a":"# CHECK FOR MISSING VAUE IN TEST DATA:\ndf_test.isnull().sum()   # column vise report of the missing value","66a02aad":"df_test['ClaimDescription'].value_counts() #counting total number of different types of claim description present","321697b9":"df_test['PartTimeFullTime'].value_counts() #counting how many people worked part time and how many full time","ecc7d28f":"df_test['PartTimeFullTime'].value_counts().plot.bar() #visualising count of number of people who did full time and part time","1e66747f":"df_test['MaritalStatus'].value_counts() # counting total number of married and unmaried people","4ca5ecd9":"df_test['MaritalStatus'].value_counts().plot.bar() #visualising the number of married and unmarried people","4671e91d":"df_test['Gender'].value_counts() #counting totalnumber of male and female present","a2a973c6":"df_test['Gender'].value_counts().plot.bar() #visualising the total number of male and female present","bd50a011":"df_test['MaritalStatus']=df_test['MaritalStatus'].fillna(df_test['MaritalStatus'].mode()[0])","0364dfec":"df_train['DateReported']=df_train['DateReported'].fillna(df_train['DateReported'].mode()[0])","4129a57e":"df_train['Age']=df_train['Age'].fillna(df_train['Age'].mode()[0])","14ef3119":"df_train['MaritalStatus']=df_train['MaritalStatus'].fillna(df_train['MaritalStatus'].mode()[0])","2e79ce36":"df_train['WeeklyWages']=df_train['WeeklyWages'].fillna(df_train['WeeklyWages'].mode()[0])","4eabfc1d":"df_train['HoursWorkedPerWeek']=df_train['HoursWorkedPerWeek'].fillna(df_train['HoursWorkedPerWeek'].mode()[0])","99dcf12a":"df_train['DependentsOther']=df_train['DependentsOther'].fillna(df_train['DependentsOther'].mode()[0])","5781ada5":"df_train['DaysWorkedPerWeek']=df_train['DaysWorkedPerWeek'].fillna(df_train['DaysWorkedPerWeek'].mode()[0])","e6d2cf27":"df_train.apply(pd.Series.nunique)  # number of unique elements in each object","fc7d30a8":"df_train.plot.box(figsize=(35,15))\n","f9922eda":"df = pd.DataFrame(df_train)\n\nprint (df.dtypes)\n  ","6e49b60b":"df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n\ndf['UltimateIncurredClaimCost'] = pd.to_numeric(df['UltimateIncurredClaimCost'], errors='coerce')\n\n\n","cfb99310":"sns.catplot(data=df_train,x='MaritalStatus',kind='count')","b9b57f8c":"sns.catplot(data=df_train,x='Gender',kind='count')","57338be3":"sns.catplot(data=df_train,x='PartTimeFullTime',kind='count')","e1b4d9fe":"plt.figure(figsize=(15,10))\nsns.barplot(x='Age',y='UltimateIncurredClaimCost',data=df_train)\nplt.xticks(rotation=90)\nplt.show()","b4c5b67b":"plt.figure(figsize=(15,10))\nsns.barplot(x='DependentChildren',y='UltimateIncurredClaimCost',data=df_train)\nplt.xticks(rotation=90)\nplt.show()","7612eca4":"plt.figure(figsize=(12,10))\nsns.barplot(x='DaysWorkedPerWeek',y='UltimateIncurredClaimCost',data=df_train)\nplt.show()","18d55e58":"df_train['WeeklyWages'].hist()","afb6cb8a":"df_train['DependentChildren'].hist()","d1806a62":"df_train['HoursWorkedPerWeek'].hist()","2fb40679":"fig, ax = plt.subplots(figsize=(20,10)) \nsns.heatmap(df_train.corr()*10,vmin=-1,vmax=10,linewidths=1,annot=True,annot_kws={\"size\": 10},fmt=\"g\",ax=ax,cmap=\"RdYlGn\")","b891e28b":"df_test.columns","9309147f":"df_train['InitialIncurredCalimsCost'] = pd.to_numeric(df_train['InitialIncurredCalimsCost'], errors='coerce')\n","7f70534f":"df_train['InitialIncurredCalimsCost'].describe()","83f624e8":"\ndf_train['InitialIncurredCalimsCost'].min()","ac147f62":"df_train['InitialIncurredCalimsCost']=(df_train['InitialIncurredCalimsCost'] - df_train['InitialIncurredCalimsCost'].min())\/(df_train['InitialIncurredCalimsCost'].max()-df_train['InitialIncurredCalimsCost'].min())\n","b94ae91f":"df_train['WeeklyWages'] = pd.to_numeric(df_train['WeeklyWages'], errors='coerce')","41dc4fe7":"df_train['WeeklyWages']=(df_train['WeeklyWages'] - df_train['WeeklyWages'].min())\/(df_train['WeeklyWages'].max()-df_train['WeeklyWages'].min())\n","0d4a5b95":"df_train['WeeklyWages'].describe()","7c393f8f":"import sklearn.preprocessing as pre","68308371":"le=pre.LabelEncoder()","9bd3f205":"le.fit(df['Gender'])","fbb848d5":"le.transform(df['Gender']) # Encoding categorical variable gender ","1b42ebac":"#le.fit(df['ClaimDescription'])","a6d65c7b":"#le.transform(df['ClaimDescription'])","b35991ea":"df_train.columns","c0e6b972":"list_df=['Gender',\n       'MaritalStatus', 'DependentChildren', 'DependentsOther', 'WeeklyWages',\n       'PartTimeFullTime', 'HoursWorkedPerWeek', 'DaysWorkedPerWeek',\n       'InitialIncurredCalimsCost',\n       'UltimateIncurredClaimCost']","e5c16df2":"for x in list_df:\n    df_train[x]=le.fit_transform(df_train[x])","4715019e":"df_train.head()","d3252c70":"df_ML=df_train[list_df]\ndf_test_data=df_ML.copy","47c63d88":"df_test_data=pre.minmax_scale(df_ML.values)\n","ee29cce8":"df_test_data","2b28fb3a":"df_test_data=df_test\ndf_train_data=df_test_data.drop(['ClaimNumber', 'DateTimeOfAccident','DateReported'], axis = 1)\n","37aab31a":"df_train_data.head()","ba32e6d1":"df_train_data.columns","aa9fe9ce":"#Splitting the train into X (Independent variable) and Y (Dependent Variable)\nX = df_train.drop('UltimateIncurredClaimCost', axis=1)\ny = df_train['UltimateIncurredClaimCost']","b800bc5d":"#Splitting the test into X (Independent variable) and Y (Dependent Variable)\n#X1 = df_train_data.drop('UltimateIncurredClaimCost', axis=1)\n#y1 = df_train_data['UltimateIncurredClaimCost']","d1ac5426":"import sklearn.model_selection as ms","5debfab3":"#Splitting the train data into 70% as training data and 30% as testing data to check the accuracy of the model\nX_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.40, random_state=100)","4c83394c":"# summarize train dataset\nprint('Train', X_train.shape, y_train.shape)\nprint('Test', X_test.shape, y_test.shape)","70ecf100":"#from sklearn.preprocessing import StandardScaler\n# creating a standard scaler\n#sc = StandardScaler()\n# feeding independents sets into the standard scaler\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.fit_transform(X_test)\n","7c613b2e":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n","9f277209":"from sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.feature_selection import f_regression","79bf130b":"import matplotlib.pyplot as plt","87c1cd75":"from sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom matplotlib import pyplot\n \n# feature selection\ndef select_features(X_train, y_train, X_test):\n\t# configure to select all features\n\tfs = SelectKBest(score_func=f_regression, k='all')\n\t# learn relationship from training data\n\tfs.fit(X_train, y_train)\n\t# transform train input data\n\tX_train_fs = fs.transform(X_train)\n\t# transform test input data\n\tX_test_fs = fs.transform(X_test)\n\treturn X_train_fs, X_test_fs, fs\n \n# load the dataset\nX, y = make_regression(n_samples=3000, n_features=15, n_informative=10, noise=0.1, random_state=1)\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n# feature selection\nX_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n# what are scores for the features\nfor i in range(len(fs.scores_)):\n\tprint('Feature %d: %f' % (i, fs.scores_[i]))\n# plot the scores\nplt.bar([i for i in range(len(fs.scores_))], fs.scores_)\nplt.show()","c6883b15":"# evaluation of a model using all input features\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n# load the dataset\nX, y = make_regression(n_samples=3000, n_features=15, n_informative=10, noise=0.1, random_state=1)\n\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n\n# fit the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# evaluate the model\nyhat = model.predict(X_test)\n\n# evaluate predictions\nmae = mean_absolute_error(y_test, yhat)\nprint('MAE: %.3f' % mae)","54027309":"# evaluation of a model using 10 features chosen with correlation\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n \n# feature selection\ndef select_features(X_train, y_train, X_test):\n\t# configure to select a subset of features\n\tfs = SelectKBest(score_func=f_regression, k='all')\n\t# learn relationship from training data\n\tfs.fit(X_train, y_train)\n\t# transform train input data\n\tX_train_fs = fs.transform(X_train)\n\t# transform test input data\n\tX_test_fs = fs.transform(X_test)\n\treturn X_train_fs, X_test_fs, fs\n \n# load the dataset\nX, y = make_regression(n_samples=3000, n_features=15, n_informative=10, noise=0.1, random_state=1)\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n# feature selection\nX_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n# fit the model\nmodel = LinearRegression()\nmodel.fit(X_train_fs, y_train)\n# evaluate the model\nyhat = model.predict(X_test_fs)\n\n\n\nprint(yhat)\n\n","1e306cdb":"#Obtaining regression coefficient\nnew_model = LinearRegression().fit(X, y.reshape((-1, 1)))\nprint('intercept:', new_model.intercept_)\nprint('slope:', new_model.coef_)","d0a6b9d9":"from sklearn.metrics import mean_squared_error\n# evaluate predictions\nmae = mean_squared_error(y_test, yhat)\nprint('Mean squared error: %.3f' % mae)\nrmse=np.sqrt(mae)\nprint(\"Root Mean Squared Error\")\nprint(rmse)\n","602bea0f":"df_test.columns","3e926c36":"import datetime as dt\ndf_test['DateTimeOfAccident']=pd.to_datetime(df_test['DateTimeOfAccident'],format=\"%Y-%m-%dT%H:%M:%S\")\ndf_test[\"yearofAccident\"] =df_test[\"DateTimeOfAccident\"].dt.year\ndf_test[\"dayofweekAccident\"] = df_test[\"DateTimeOfAccident\"].dt.weekday\ndf_test['monthOfAccident'] =df_test['DateTimeOfAccident'].dt.month","cf7f9ba1":"df_test['WeeklyWages']=df_test['WeeklyWages'].astype(np.float64)\ndf_test['WeeklyWages']=df_test['WeeklyWages'].astype(np.int64)","d45efd55":"# importing label encoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# creating a label encoder\nle = LabelEncoder()\n\n# label encoding for Gender\n# 0 for females, 1 for males\ndf_test['Gender'] = le.fit_transform(df_test['Gender'])\n\n# label encoding for MaritalStatus\n# 0 for Married  1 for Single ,2 for unknown.\ndf_test['MaritalStatus'] = le.fit_transform(df_test['MaritalStatus'])\n\n# lebel encoding for PartTimeFullTime\n# 0 for FullTime and 1 for partTime                                      \ndf_test['PartTimeFullTime']=le.fit_transform(df_test['PartTimeFullTime'])  ","b5d96922":"x1=df_test['Age']\nx2=df_test['Gender']\nx3=df_test['MaritalStatus']\nx4=df_test['DependentChildren']\nx5=df_test['WeeklyWages']\nx6=df_test['PartTimeFullTime']\nx7=df_test['InitialIncurredCalimsCost']\n","3d6b7f43":"UltimateIncurredClaimCost=0.24*x1+0.04*x2+0.046*x3+0.02*x4+0.24*x5+0.03*x6+0.33*x7","5321c120":"UltimateIncurredClaimCost","7ac60ff4":"\nUltimateIncurredClaimCost.mean()\n\n\n","90f04f74":"df=pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")\n","310dfbe1":"df.shape","23be9a8b":"df['UltimateIncurredClaimCost']=UltimateIncurredClaimCost","2911a34f":"df.head()","0cf6476a":"df['UltimateIncurredClaimCost']=df['UltimateIncurredClaimCost'].fillna(2761)","00b3556e":"df.to_csv('sample_submission.csv',index=False)","3d77b5af":"df1=pd.read_csv('sample_submission.csv')\ndf1.head()","54973315":"csv=pd.read_csv(\"..\/input\/machine-learning-24-hrs-hackathon\/sample_submission.csv\")\ncsv[\"UltimateIncurredClaimCost\"]=df['UltimateIncurredClaimCost']\ncsv.to_csv(\".\/sample_submission.csv\",index=False)","355d93db":"**DATA TRANSFORMATION**","fe77cdd2":"**EXPLORATORY DATA ANALYSIS**","d119af2d":"**EVALUATING THE MODEL: OBTAINING RMSE**","0aa98b55":"**MISSING VALUE IMPUTATION USING MODE**","ffd07b5b":"**Outlier Analysis**","6e32c09a":"**CREATING FEATURES AND OUTCOME**","986ed819":"**DATA NORMALIZATION**","ef2b31bf":"**I have used linear regression with stochastic gradient descent. The UltimateCostIncurred is taken as the dependent variable and remaining variables are independent variables. The train and test set have been divided in 7:3 ratio.The accuracy of the model is 0.82 and the RMSE obtained is 0.1**","7989ce22":"**UltimateIncurredClaimCost=0.24*x1+0.04*x2+0.046*x3+0.02*x4+0.24*x5+0.03*x6+0.33*x7+0.04*x8***"}}