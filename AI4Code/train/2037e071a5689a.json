{"cell_type":{"e6a452de":"code","063adfd8":"code","a5dd7af5":"code","298b30c0":"code","ad3fda66":"code","438df561":"code","06336bcf":"code","b3dcfd94":"code","9f4a39db":"code","13881447":"code","c6c00a40":"code","946b4c82":"code","902f11e2":"code","373e4144":"code","177be982":"code","25d56786":"code","6c210b2f":"code","3d0cf82a":"code","1710814d":"code","9cc5c56c":"code","7e7bdb85":"code","afaf0676":"code","243a03e2":"code","3ec1161b":"code","e95cfe8f":"code","26eabedc":"code","33567c77":"code","f066930b":"code","ba4fdf51":"code","b2a3e5cb":"code","ed572051":"code","4552aa16":"code","3efed8da":"code","ac5b047c":"code","935e683d":"code","855a5b51":"code","82b5effe":"code","5e644143":"code","0d19e18c":"code","251b013d":"code","f96a2048":"code","3f9c90f7":"code","3989fd7b":"code","5dbe439e":"code","7423cc73":"code","6545ef2e":"code","44c859e5":"code","d40d2221":"code","6911c93b":"code","931ccaa9":"code","d30cde7e":"code","7b21c13a":"code","cdadffbd":"code","89923477":"code","b3c17ab5":"code","71e01eec":"code","65803225":"code","2e2e2fb5":"code","2a9e401d":"code","2dde7b38":"code","e302aa52":"code","868a9702":"code","c88bc5ee":"code","5d0991e3":"code","65e662f4":"markdown","39b02558":"markdown","5a1acbee":"markdown","778f33f3":"markdown","1189b76c":"markdown","78690067":"markdown","1e3f82fe":"markdown","70e574b0":"markdown","09b70d55":"markdown","4232a0f5":"markdown","5525624c":"markdown","393fd678":"markdown","a395b635":"markdown","13a8529f":"markdown","36da1327":"markdown","08104be2":"markdown","22666b43":"markdown","1b4ecef8":"markdown","44c83586":"markdown","d41cadc8":"markdown","12992329":"markdown","a827f966":"markdown","2aff3787":"markdown","7cea08d9":"markdown","3cbe2403":"markdown","2d166536":"markdown","c502351f":"markdown","674e883d":"markdown","e6883795":"markdown","f21f412f":"markdown","eed7a422":"markdown","192dbb93":"markdown","40ba23d2":"markdown","01ec4134":"markdown","fae4a7ec":"markdown","e317b96d":"markdown","01cd5a5c":"markdown","b5c4a1aa":"markdown","1a45340d":"markdown","11106b9b":"markdown","b0b29930":"markdown","627540ed":"markdown","b1f1927c":"markdown","b1dbe13d":"markdown","e51ebb70":"markdown","0eef338e":"markdown","be0d8e33":"markdown","75999c37":"markdown","f77f5ed2":"markdown","08e61ba0":"markdown","4f9d4dd1":"markdown","df74c1c4":"markdown","d10c77d9":"markdown","42e19225":"markdown","cd4d0d91":"markdown","c1292fb6":"markdown","ca90ff1e":"markdown","5c34b30c":"markdown","5b2a8bc8":"markdown","36fd858c":"markdown","fa3b3b12":"markdown","6c94e1b2":"markdown","345b46a4":"markdown","123609d4":"markdown","2e26cf1e":"markdown","83cb0113":"markdown","6490394b":"markdown","2060436d":"markdown","ad717fc2":"markdown","9c775250":"markdown"},"source":{"e6a452de":"!pip install comet_ml","063adfd8":"# Loading in the comet_ml tool\n#from comet_ml import Experiment\n    \n# Setting the API key, saved as environment variable\n# experiment = Experiment(api_key=\"9gsTl4Wv73PDkYEoX8PUt5RSX\",\n#                       project_name=\"nlp-predict-first-class\", workspace=\"ms-noxolo\")\n# experiment.display()","a5dd7af5":"# Importing modules for data science and visualization\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi'] = 180\n# NLP Libraries\nimport re\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import SnowballStemmer\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n# ML Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk import pos_tag\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","298b30c0":"!pip install nlppreprocess","ad3fda66":"# Loading in the datasets\ntrain = pd.read_csv(\"\/kaggle\/input\/climate-change-belief-analysis\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/climate-change-belief-analysis\/test.csv\")\nsample_submission = pd.read_csv('\/kaggle\/input\/climate-change-belief-analysis\/sample_submission.csv')","438df561":"# Looking at the first few entries in the dataset\ntrain.head()","06336bcf":"# Shape of the dataset\ntrain.shape","b3dcfd94":"# dataframe information\ntrain.info()","9f4a39db":"# Looking at the numbers of possible classes in our sentiment\ntrain['sentiment'].unique()","13881447":"# Looking at the how the messages are distributed across the sentiment\ntrain.describe()","c6c00a40":"# Checking for missing values\ntrain.isnull().sum()","946b4c82":"# Checking whether a character is white-space character or not\nprint(len(train['message']))\nprint(sum(train['message'].apply(lambda x: x.isspace())))","902f11e2":"# Sample tweet\ntweet = train.iloc[6,1]\nprint(tweet)","373e4144":"# Visualizing the distribution of the target \nplt.hist(train['sentiment'], label='data');\nplt.legend();\nplt.title('Distribution of target labels')","177be982":"# Distribution plots for the label\nfig,(ax1,ax2,ax3,ax4) = plt.subplots(1,4,figsize=(16,8))\n\n#For Positive \nsns.distplot(train[train['sentiment']==1]['message'].str.len(), hist=True, kde=True,\n             bins=int(200\/25), color = 'blue', \n             ax = ax1,\n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax1.set_title('Positive')\nax1.set_xlabel('message_Length')\nax1.set_ylabel('Density')\n\n#For Negative \nsns.distplot(train[train['sentiment']==-1]['message'].str.len(), hist=True, kde=True,\n             bins=int(200\/25), color = 'lightblue', \n             ax = ax2,\n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax2.set_title('Negative ')\nax2.set_xlabel('message_Length')\nax2.set_ylabel('Density')\n\n#For Neutral \nsns.distplot(train[train['sentiment']==0]['message'].str.len(), hist=True, kde=True,\n             bins=int(200\/25), color = 'purple',  \n             ax = ax3,\n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax3.set_title('Neutral ')\nax3.set_xlabel('message_Length')\nax3.set_ylabel('Density')\n\n#For Neews\nsns.distplot(train[train['sentiment']==2]['message'].str.len(), hist=True, kde=True,\n             bins=int(200\/25), color = 'green', \n             ax = ax4,\n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax4.set_title('News')\nax4.set_xlabel('message_Length')\nax4.set_ylabel('Density')","25d56786":"working_df = train.copy()\n# Labeling the target\nworking_df['sentiment'] = [['Negative', 'Neutral', 'Positive', 'News'][x+1] for x in working_df['sentiment']]","6c210b2f":"# checking the numerical distribution\nvalues = working_df['sentiment'].value_counts()\/working_df.shape[0]\nlabels = (working_df['sentiment'].value_counts()\/working_df.shape[0]).index\ncolors = ['lightgreen', 'blue', 'purple', 'lightsteelblue']\nplt.pie(x=values, labels=labels, autopct='%1.1f%%', startangle=90, explode= (0.04, 0, 0, 0), colors=colors)\nplt.show()","3d0cf82a":"sns.countplot(x='sentiment' ,data = working_df, palette='PRGn')\nplt.ylabel('Count')\nplt.xlabel('Sentiment')\nplt.title('Number of Messages Per Sentiment')\nplt.show()","1710814d":"# Visualizing text lengths for each sentiment\nsns.barplot(x='sentiment', y=working_df['message'].apply(len) ,data = working_df, palette='PRGn')\nplt.ylabel('Length')\nplt.xlabel('Sentiment')\nplt.title('Average Length of Message by Sentiment')\nplt.show()","9cc5c56c":"# Extracting Users in a column\nworking_df['users'] = [''.join(re.findall(r'@\\w{,}', line)) \n                       if '@' in line else np.nan for line in working_df.message]","7e7bdb85":"# Generating Counts of users\ncounts = working_df[['message', 'users']].groupby('users', as_index=False).count().sort_values(by='message', ascending=False)","afaf0676":"# Top 5 most popular\ncounts.head()","243a03e2":"# checking the numerical distribution\nvalues = [sum(np.array(counts['message']) == 1)\/len(counts['message']), sum(np.array(counts['message']) != 1)\/len(counts['message'])]\nlabels = ['First Time Tags', 'Repeated Tags']\ncolors = ['lightsteelblue', \"purple\"]\nplt.pie(x=values, labels=labels, autopct='%1.1f%%', startangle=90, explode= (0.04, 0), colors=colors)\nplt.show()","3ec1161b":"# Analysis of most popular tags, sorted by populariy\nsns.countplot(y=\"users\", hue=\"sentiment\", data=working_df, palette='PRGn',\n              order=working_df.users.value_counts().iloc[:20].index) \n\nplt.ylabel('User')\nplt.xlabel('Number of Tags')\nplt.title('Top 20 Most Popular Tags')\nplt.show()\n#plt.xticks(rotation=90)","e95cfe8f":"# Analysis of most popular tags, sorted by populariy\nsns.countplot(x=\"users\", data=working_df[working_df['sentiment'] == 'Positive'],\n              order=working_df[working_df['sentiment'] == 'Positive'].users.value_counts().iloc[:20].index) \n\nplt.xlabel('User')\nplt.ylabel('Number of Tags')\nplt.title('Top 20 Positive Tags')\nplt.xticks(rotation=85)\nplt.show()","26eabedc":"# Analysis of most popular tags, sorted by populariy\nsns.countplot(x=\"users\", data=working_df[working_df['sentiment'] == 'Negative'],\n              order=working_df[working_df['sentiment'] == 'Negative'].users.value_counts().iloc[:20].index) \n\nplt.xlabel('User')\nplt.ylabel('Number of Tags')\nplt.title('Top 20 Negative Tags')\nplt.xticks(rotation=85)\nplt.show()","33567c77":"# Analysis of most popular tags, sorted by populariy\nsns.countplot(x=\"users\", data=working_df[working_df['sentiment'] == 'News'],\n              order=working_df[working_df['sentiment'] == 'News'].users.value_counts().iloc[:20].index) \n\nplt.xlabel('User')\nplt.ylabel('Number of Tags')\nplt.title('Top 20 News Tags')\nplt.xticks(rotation=85)\nplt.show()","f066930b":"# Testing the PorterStemmer \nstemmer = PorterStemmer()\nprint(\"The stemmed form of typing is: {}\".format(stemmer.stem(\"typing\")))\nprint(\"The stemmed form of types is: {}\".format(stemmer.stem(\"types\")))\nprint(\"The stemmed form of type is: {}\".format(stemmer.stem(\"type\")))","ba4fdf51":"# Testing Lemmatization\nlemm = WordNetLemmatizer()\nprint(\"In  case of Lemmatization, typing is: {}\".format(lemm.lemmatize(\"typing\")))\nprint(\"In  case of Lemmatization, types is: {}\".format(lemm.lemmatize(\"types\")))\nprint(\"In  case of Lemmatization, type is: {}\".format(lemm.lemmatize(\"type\")))","b2a3e5cb":"from nlppreprocess import NLP\nnlp = NLP()\nnlp.process('shouldnt')","ed572051":"nlp.process('There is no good here')","4552aa16":"# Data cleaning for furthur sentiment analysis\n\ndef cleaner(line):\n    '''\n    For preprocessing the data, we regularize, transform each upper case into lower case, tokenize,\n    normalize and remove stopwords. Normalization transforms a token to its root word i.e. \n    These words would be transformed from \"love loving loved\" to \"love love love.\"\n    \n    '''\n\n    # Removes RT, url and trailing white spaces\n    line = re.sub(r'^RT ','', re.sub(r'https:\/\/t.co\/\\w+', '', line).strip()) \n    emojis = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # removes emoticons,\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n\n    line = emojis.sub(r'', line)\n\n    # Removes puctuation\n    punctuation = re.compile(\"[.;:!\\'\u2019\u2018\u201c\u201d?,\\\"()\\[\\]]\")\n    tweet = punctuation.sub(\"\", line.lower()) \n    # Removes stopwords\n    nlp_for_stopwords = NLP(replace_words=True, remove_stopwords=True, \n                            remove_numbers=True, remove_punctuations=False) \n    tweet = nlp_for_stopwords.process(tweet) # This will remove stops words that are not necessary. The idea is to keep words like [is, not, was]\n    # https:\/\/towardsdatascience.com\/why-you-should-avoid-removing-stopwords-aa7a353d2a52\n\n    # tokenisation\n    # We used the split method instead of the word_tokenise library because our tweet is already clean at this point\n    # and the twitter data is not complicated\n    tweet = tweet.split() \n    # POS \n    # Part of Speech tagging is essential for Lemmatization to perform well\n    pos = pos_tag(tweet)\n    \n    # Lemmatization\n    lemmatizer = WordNetLemmatizer()\n    tweet = ' '.join([lemmatizer.lemmatize(word, po[0].lower()) \n                      if (po[0].lower() in ['n', 'r', 'v', 'a'] and word[0] != '@') else word for word, po in pos])\n    return tweet","3efed8da":"text1 = cleaner(tweet)\nprint('BEFORE')\nprint(tweet, '\\n'*2)\nprint('AFTER')\nprint(text1)\n# In the tweet below, you can see that \"not\" was added and kept, because the word is significant","ac5b047c":"cleaned = train['message'].apply(cleaner)","935e683d":"cleaned.head()","855a5b51":"working_df['clean'] = cleaned","82b5effe":"# Combining all the messages\ntext_before_cleaning = \" \".join(tweet for tweet in train['message'])\ntext_after_cleaning = \" \".join(tweet for tweet in cleaned)","5e644143":"# Numbers of characters\nsns.barplot(x=['Before Cleaning', 'After Cleaning'], y=[len(text_before_cleaning), len(text_after_cleaning)], palette='PRGn')\n# sns.countplot(x=[] ,data = working_df, palette='PRGn')\nplt.ylabel('Number of Characters')\n# plt.xlabel('Sentiment')\nplt.title('Number of Characters')\nplt.show()","0d19e18c":"# Generating the word cloud image from all the messages\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(text_after_cleaning)\n\n# Displaying the word cloud image:\n# using matplotlib way:\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","251b013d":"# Wordcloud for the cleaned data:Positive sentiment\ncorpus = re.sub(\"climate change\", '',\" \".join(tweet.strip() for tweet in working_df['clean'][working_df['sentiment'] == 'Positive']))\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(corpus)\n\n# Displaying the word cloud using matplotlib:\n# plt.title(\"General Word Cloud\")\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","f96a2048":"# Wordcloud for the cleaned data:Negative sentiment\ncorpus = re.sub(\"climate change\", '',\" \".join(tweet.strip() for tweet in working_df['clean'][working_df['sentiment'] == 'Negative']))\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(corpus)\n\n# Displaying the word cloud image:\n# plt.title(\"General Word Cloud\")\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","3f9c90f7":"# Wordcloud for the cleaned data:News\ncorpus = re.sub(\"climate change\", '',\" \".join(tweet.strip() for tweet in working_df['clean'][working_df['sentiment'] == 'News']))\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(corpus)\n\n# Displaying the word cloud image:\n# plt.title(\"General Word Cloud\")\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","3989fd7b":"# Creating a column of hastags\nworking_df['hashtags'] = [' '.join(re.findall(r'#\\w{,}', line)) \n                       if '#' in line else np.nan for line in working_df.message]","5dbe439e":"# A sneak peak of these tweets plus hashtags\nworking_df.head()","7423cc73":"# Creating a wordcloud of the hashtags: Positive sentiment\ncorpus = re.sub(\"climate change\", '',\" \".join(tweet.strip() for tweet in working_df['hashtags'][working_df['sentiment'] == 'Positive'] if type(tweet) == str))\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(corpus)\n\n# Displaying the word cloud image:\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","6545ef2e":"# Wordcloud for the hashtags:Negtive sentiment\ncorpus = re.sub(\"climate change\", '',\" \".join(tweet.strip() for tweet in working_df['hashtags'][working_df['sentiment'] == 'Negative'] if type(tweet) == str))\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(corpus)\n\n# Displaying the word cloud image:\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","44c859e5":"# Wordcloud for the hashtags:News\ncorpus = re.sub(\"climate change\", '',\" \".join(tweet.strip() for tweet in working_df['hashtags'][working_df['sentiment'] == 'News'] if type(tweet) == str))\nwordcloud = WordCloud(font_path='..\/input\/droidsansmonottf\/droidsansmono.ttf', background_color=\"white\",\n                      width = 1920, height = 1080, colormap=\"viridis\").generate(corpus)\n\n# Displaying the word cloud image:\n# plt.title(\"General Word Cloud\")\nplt.figure(dpi=260)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","d40d2221":"# Converting the collection of clean messages to a matrix of token counts\ncorpus = working_df['clean']\n\nvectorizer = CountVectorizer()\ncount_vectorized = vectorizer.fit_transform(corpus)\n#print(vectorizer.get_feature_names())\n#print(X.toarray())","6911c93b":"# Converting the collection of clean messages to a matrix of TF-IDF features\ndata = working_df['clean']\n\nvectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\nvectorized = vectorizer.fit_transform(data)\n#print(vectorizer.get_feature_names())\n#print(X.toarray())","931ccaa9":"# Using sparse to train the model using both representations.\nimport scipy.sparse\n\n# Defining the features as well as the label\nX = scipy.sparse.hstack([vectorized, count_vectorized])\ny = working_df['sentiment']","d30cde7e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics","7b21c13a":"from sklearn.model_selection import train_test_split\n\n# Splitting the previously defined features and label of your dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","cdadffbd":"# Creating a list of all the models to train\nalgs = [LogisticRegression(random_state = 5), SVC(kernel = 'linear', random_state = 5), SVC(kernel = 'rbf', random_state = 5)\n        ,MultinomialNB(), KNeighborsClassifier(), DecisionTreeClassifier(max_depth=6),RandomForestClassifier()]","89923477":"# Fitting models onto the training data and predicting.\nfor i in range(0, len(algs)):\n    text_clf = Pipeline([('clf', algs[i])])\n    ##lowercase = True,stop_words='english', ngram_range=(1, 2), analyzer='word',max_df = 0.8\n    text_clf.fit(X_train, y_train)  \n    predictions = text_clf.predict(X_test)\n    \n    \n    print(algs[i])\n    print(metrics.confusion_matrix(y_test,predictions))\n    print(metrics.classification_report(y_test,predictions))\n    print('F1_score: ',round(metrics.f1_score(y_test,predictions, average = 'weighted'),3))\n    print('-------------------------------------------------------')","b3c17ab5":"data = train.copy()","71e01eec":"# importing the module and creating a resampling variable\nfrom sklearn.utils import resample\nclass_size = int(len(data[data['sentiment']==1])\/2)","65803225":"# seperating the four classes\nclass_1 = data[data['sentiment']==-1]\nclass_2 = data[data['sentiment']==0]\nclass_3 = data[data['sentiment']==1]\nclass_4 = data[data['sentiment']==2]","2e2e2fb5":"# upsampling classes 1, 2, and 4 & downsampling class 3\nclass_1_up = resample(class_1,replace=True,n_samples=class_size, random_state=27)\nclass_2_up = resample(class_2,replace=True,n_samples=class_size, random_state=27)\nclass_4_up = resample(class_4,replace=True,n_samples=class_size, random_state=27)\nclass_3_down = resample(class_3,replace=False,n_samples=class_size, random_state=27)","2a9e401d":"# Creating a new DataFrame out of the balanced bata\nres_df = pd.concat([class_1_up, class_2_up, class_4_up,class_3_down])","2dde7b38":"# Checking if data has been well-balanced\nsns.countplot(x = res_df['sentiment'], data = data, palette='PRGn')\nplt.show()","e302aa52":"# Defining the features as well as the label\nX1 = res_df['message']\nX_res = X1.apply(cleaner)\ny_res = res_df['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.25, random_state=42)","868a9702":"# Fitting models onto the training data and predicting.\nfor i in range(0, len(algs)):\n    text_clf = Pipeline([('count_vec', CountVectorizer(lowercase = True, ngram_range=(1, 2), analyzer='word')),\n                         ('clf', algs[i]),])\n    text_clf.fit(X_train, y_train)  \n    predictions = text_clf.predict(X_test)\n    \n    \n    print(algs[i])\n    print(metrics.confusion_matrix(y_test,predictions))\n    print(metrics.classification_report(y_test,predictions))\n    print('F1_score: ',round(metrics.f1_score(y_test,predictions, average = 'weighted'),3))\n    print('-------------------------------------------------------')","c88bc5ee":"# Extracting a confusion matrix from the results of balanced data\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_test, predictions))","5d0991e3":"# Extracting a classification report from the balanced data\nprint(metrics.classification_report(y_test, predictions))","65e662f4":"# What Hashtags were Trending?","39b02558":"##### Best perfoming models\n\nMost of the models scored F1_score above 0.80 \n\n-LogisticRegression()\n\n-SVC()\n\n-MultinomialNB()\n\n-RandomForestClassifier()\n\nwhile KNN and DecisonTreeClassifier were *0.52 and 0.393* repectively which is not an improved of the score from models trained with unbalanced data.","5a1acbee":"# Common Words in News","778f33f3":"We see that in the negative sentiment tweets, the common words beside \"Global Warming\" are \"Science\", \"man made\", \"Fraud\", \"Lie\", \"Hoax\" and \"Fake\" amongst others. Words some of which ARE actually associated with negative sentiment in general. ","1189b76c":"The following function is an important step in the data mining process. In our case of classification, preprocessing data means; Data cleaning, Fill in missing values, smoothing noisy data and resolving any existing inconsistencies. Success in the steps will then make it possible and some-what easy for us to perform Data integration, Data transformation, Normalization and aggregation as well as Data reduction.","78690067":"# Introduction \nSeveral companies are built around lessening one\u2019s environmental impact or carbon footprint. This is because they offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product\/service may be received.\n\nWith this context, we have created a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data. This model together will the accompanying app will help Geo-Environmental Consultation companies who are turning to social media to obtain valuable information about job applicants and to monitor the activities of their employees in relation to the values they have towards the company's projects and beliefs surrounding the ever changing global environment.\n\nProviding an accurate and robust solution to this task will provide access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies. The app launched on **streamlit** is also an intuitive, easy to use, simple and the customer can rely on the product it.","1e3f82fe":"## Missing values","70e574b0":"The equal distribution of classes as shown on the count plot, confirms that classes are now balanced.","09b70d55":"For our *Feature Extraction*, we use CV and TF-IDF. These are tools which will help encode the words as integers or floating point values for use as input to a machine learning algorithm.\n\nCountVectorizer counts the word frequencies, while the TFIDFVectorizer (The term frequency-inverse document frequency) is a weight whose value increases proportionally to count, but is inversely proportional to frequency of the word in the corpus. The TF-IDF weight is a weight often used in information retrieval and text mining. Tf-idf can be successfully used for stop-words filtering in various subject fields including text summarization and classification.","4232a0f5":"# Common Words in Negative Tweets","5525624c":"In perspective, there are more than 8000 Positive tweets, and the news, being the second largest, has less than 4000 tweets. \nNegative tweets account for less than 20% of the Positive tweets. ","393fd678":"## Training with balanced data","a395b635":"Having Cleaned the data, we can now explore which words are most common from which sentiment of tweets. \nWe will do this using WordClouds.","13a8529f":"It is notable that there is an imbalance of classes in the daset  and these tend to be a common problem in machine learning classification where there are a disproportionate ratio of observations in each class. This is can cause problems as most algorithms are designed to maximize accuracy and reduce error. Therefore we ill address and take care of the class imbalance in our EDA","36da1327":"# Importing Libraries","08104be2":"In reality, @SenSanders and @BernieSanders are the same person, this therefore means that tags associated with this tag are the most, in the positive sentiment repeated tags. \nIt is no surprise to see NationalGeo and \"ClimateCentral\" of course... Climate Change. ","22666b43":"# References","1b4ecef8":"In some problems the countsvec is better suited for model training in others the tfidf representation is the best choice. We have decided to try them both. Although the two representations are very similar and therefore carry approximately the same information, it could be the case that you will get better precision by using the full set of features(tfidf+counts).","44c83586":"It makes sense why the most popular name in the news is Donald Trump as this was election year. Much of the words in the news are politically associated with climate change. \n\n\"The Paris Agreement is a landmark environmental accord that was adopted by nearly every nation in 2015 to address climate change and its negative impacts. The deal aims to substantially reduce global greenhouse gas emissions in an effort to limit the global temperature increase in this century to 2 degrees Celsius above preindustrial levels, while pursuing means to limit the increase to 1.5 degrees.\" - NRDC","d41cadc8":"Resampling is a process which involves changing the frequency of the observations. Below we apply it to assess whether or not it will improve our training. This process also serves as model tuning as we will be using a define resampling strategy while taking note of performance measure.\n","12992329":"We will also need to also transform some of the messages into a more digestible form and keeping words and items that ar otherwise discarded. We will carry out this process using the nlp tool below.","a827f966":"# Model Selection","2aff3787":"The are possibilities of obtaining better results using parameter tuning and better preprocessing techninques. We commit to continue conducting research into discovering and training models that would yiled optimal results. The insights garned from the EDA as well as model evaluation will be useful in providing stakeholders that are interested in climate change and related policies understand the distribution of sentiments around the issue.","7cea08d9":"In lemmatisation, the part of speech of a word should be first determined and the normalisation rules will be different for different part of speech, while the stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech.","3cbe2403":" We need to perform investigative and detective analysis on our data to see if we can unearth any useful insights. We have data being generated from tweets, digital media platforms, blogs, and a whole host of other sources, in this case, tweets, and s a data scientists and NLP enthusiasts, it\u2019s important to utilize Exploratory Data Analysis to analyze all this text data, with the aid of Visuals to help organizations make data-driven decisions.","2d166536":"Now that we've had a look at the tweets themselves as well as the users, we now analyse the hastags:","c502351f":" Here we increase the frequency of the samples.","674e883d":"## Data Cleaning","e6883795":"Accuracy is not always the best metric to use when evaluating imbalanced datasets as it can be very misleading. Metrics that can provide better insight include:","f21f412f":"# Climate Change Belief Analysis\n#### by Team_SS4_JHB_First_Class on {29\/06}","eed7a422":"### Balancing the classes","192dbb93":"14.6% of the tweets are certain users tagged more than once. Considering that we are dealing with highly imbalanced data, 14.6% is significant. Depending on how influential the tagged users are, they may account for more a further portion of the data. \nKnowing who is tagged on a tweet may increase the chance of the model predict the correct sentiment of the tweet.","40ba23d2":"The Pie-Chart Above shows that more than 50% of the tweet sample has positive sentiments about Climate Change. Tweets with negative Sentiments are the least. \nThe news are also actively engaged on Climate Change as well, as we can see that they are the second popular.","01ec4134":"The average length of messages for all sentiments is not suprising as a tweet is only limited to 140 characters. However, the density contrast between positive and negative sentiments is interesting and will make for more unpacking later in the EDA. Now that we have explored our dataset, we can begin perfoming some analyses on it.","fae4a7ec":"A stemmer will return the stem of a word, which needn't be identical to the morphological root of the word. It usually sufficient that related words map to the same stem,even if the stem is not in itself a valid root, while in lemmatisation, it will return the dictionary form of a word, which must be a valid word.","e317b96d":"1. Comet Starter Notebook: \nhttps:\/\/athena.explore-datascience.net\/student\/content\/pre-processing-view\/38\/100\/1772\n\n2. Building a Twitter Sentiment-Analysis App Using Streamlit\nhttps:\/\/medium.com\/analytics-vidhya\/building-a-twitter-sentiment-analysis-app-using-streamlit-d16e9f5591f8\n\n3. Comprehensive Hands on Guide to Twitter Sentiment Analysis with dataset and code\nhttps:\/\/www.analyticsvidhya.com\/blog\/2018\/07\/hands-on-sentiment-analysis-dataset-python\/\n\n4. 10 OF THE BEST TWEETS ON CLIMATE CHANGE | AUGUST 08, 2018 | 5:21 AM\nhttps:\/\/www.climaterealityproject.org\/blog\/10-best-tweets-climate-change\n\n5. Media Bias Detection using Deep Learning Libraries in Python\nhttps:\/\/towardsdatascience.com\/media-bias-detection-using-deep-learning-libraries-in-python-44efef4918d1\n\n6. Does it make sense to use both countvectorizer and tfidfvectorizer as feature vectors for text clustering with KMeans?\nhttps:\/\/stackoverflow.com\/questions\/27496014\/does-it-make-sense-to-use-both-countvectorizer-and-tfidfvectorizer-as-feature-ve\n\n7. Reccurent Neural Networks (RNN), the following video from MIT is an excellent resource:\nhttps:\/\/www.youtube.com\/watch?v=SEnXr6v2ifU\n\n8. Cross Validation and Grid Search for Model Selection in Python\nhttps:\/\/stackabuse.com\/cross-validation-and-grid-search-for-model-selection-in-python\/\n\n9. Tuning Hyperparameters\nhttps:\/\/mlr.mlr-org.com\/articles\/tutorial\/tune.html\n\n10. Resampling\nhttps:\/\/mlr.mlr-org.com\/articles\/tutorial\/resample.html","01cd5a5c":"A visual represenation of the hashtags using word clouds","b5c4a1aa":"**Recommendations for fututre Machine Learning:**\nThe objective of parameter tuning is to find the optimum value for each parameter to improve the accuracy of the model. Tuning the these parameters requires a good understanding of these meaning and their individual impact on model which can be unpacked through a thorough EDA.\n\nBelow are some other approaches that can be considered for model tuning:\n- Grid Search method: an exhaustive search (blind search\/unguided search) over a manually specified subset of the hyperparameter space. This method is a computationally expensive option but guaranteed to find the best combination in your specified grid.\n\n- Informed Search method: In informed search, each iteration learns from the last, the results of one model helps creating the next model.\n\n- Random Search method: a simple alternative and similar to the grid search method but the grid is randomly selected. This method (also blind search\/unguided search) is faster at getting reasonable model but will not get the best in your grid.","1a45340d":"It seems that positive sentiments may be trying to convince often with the use of words like \"believe\" in and \"not believe\". \nSomeone's husband is strangely very popular. The president elect at this time, was Donald Trump, whom we have seen his popularity in negative tweets. ","11106b9b":"This clear imbalance of classes in the daset can lead to a disproportionate ratio of observations in each class, causing problems as most algorithms are designed to maximize accuracy and reduce error. As a result, those models may perform best at predicting Positive sentiments, but poorly at predicting Negative sentiments, for example, because of the high imbalance.\nWe therefore continue to analyse and evaluate for more insights to be derived from the dataset as we prepared to balance later on in the analysis.","b0b29930":"# Conclusion","627540ed":"There is also a Classification report which is used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report as shown below.","b1f1927c":"# Importing dataset","b1dbe13d":"Comet is a great tool for model versioning and experimentation as it records the parameters and conditions from each of the experiements- allowing for reproducing of results, or going back to a previous version of the experiment.","e51ebb70":"# Data Preprocessing","0eef338e":"All these metrices were included and accounted for in the reports of our models fitted. Additionally, resampling as an approach to model tuning really improved the accuary of our models.","be0d8e33":"Below we import some of the models that we will be training:","75999c37":"Now we will whether a tagged user has any relation to the sentiment, and which users are most popular in each sentiment","f77f5ed2":"# Model Evaluation","08e61ba0":"1. Confusion Matrix: table shows correct predictions and types of incorrect predictions.\n2. Precision: the number of true positives divided by all positive predictions. \n3. Recall: the number of true positives divided by the number of positive values in the test data. \n4. F1: Score: the weighted average of precision and recall.\n","4f9d4dd1":"##### Best perfoming models\n\n-LogisticRegression()\n\n-SVC()\n\n-N.B: From previous and initial notebook: We have noted that using both represenations improved the KNN perfomance score from *0.328 to 0.559* while the DecisionTreeClassifier score went from *0.559 to 0.488*.","df74c1c4":"Here we see that both negative postive tweets have roughly the highest average length of tweets, with Positive having a slightly higher average","d10c77d9":"Of course, the most popular words in all the tweets are, \"Climate Change\" and \"Global Warming\". \nWe see also, the phases \"believe in\" and  \"not believe\". And these two phrases capture the reason of this project. \nThe efficiency and relevance of our preprocessing function is now shining in being able to keep what may normally be stop words in English, that is, 'not' and 'in'. ","42e19225":"#### Up-sampling","cd4d0d91":"# Feature Engineering and Selection","c1292fb6":"# Exploratory Data Analysis","ca90ff1e":"Cleaning is the process of detecting and correcting corrupt or inaccurate records from the dataset and identifying incomplete, incorrect, inaccurate or irrelevant parts of the data. We also apply database normalization which is the process of structuring a relational database in accordance with a series of normal forms in order to reduce data redundancy. Applying it will aslo help improve data integrity as it entails organizing the attributes of a dataset to ensure that their dependencies are properly enforced by database integrity constraints. Stemming and Lemmatization are techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.\n\n","5c34b30c":"Without surprise, we are able to notice certain tags are commonly associated with a specific sentiment. \nThere are some tags which are mojorly strongly associated with one sentiment. \nKeeping these users will aid the machine learning process. We also notice well known american politicians strongly associated with either side. An interesting thing is that one was Liberal and the other, conservative as of the time of the tweets and now. \nWe notice also that some of the news platforms have positive sentiments concerning Climate Change. ","5b2a8bc8":"Fortunately, there are no missing values in our dataset.","36fd858c":"## Comet","fa3b3b12":"#### Class size to up\/down sample","6c94e1b2":"# Table of Contents\n\n1. Intro to Comet\n2. Importing Libraries\n3. Importing Dataset\n4. Data Preprocessing\n5. Exploratory Data Analysis\n6. Feature Engineering and Selection\n7. Model Selection \n8. Model Evaluation\n9. References","345b46a4":"Word clouds are a simple visualization of data, in which words are shown in varying sizes depending on how often they appear. The kind of insight they provide even without much analysis being done helps in data normalization and in also what to expect as we dive deeper into data analysis. In our case, it is no surprise that both \"climate change\" and \"global warming\" as the biggest words in the could. Some other big words include \"https\" and \"RT\" which can be easily categorized as potential stopwords.","123609d4":"## Summary Statistics","2e26cf1e":"## Training with imbalanced data","83cb0113":"In perspective, we have rid the data of more than 1.5 million unnecessary characters. This will certainly have a positive effect on the efficiency of our model.","6490394b":"The count of negative sentiments by a single tag is much less that that of the positive sentiments. \nOn the positive sentiments, the threshhold count, was above 300, while on the negative, it is less than 60. \nHowever, we can see that the most popular tag associated with negative tweets at this time, was the President(now) of the U.S.A. ","2060436d":"# Common Words in Positive Tweets","ad717fc2":"#### Feature Extraction","9c775250":"# Common Words in All the Tweets"}}