{"cell_type":{"f6c48287":"code","77b533da":"code","5c1a79ff":"code","75d18658":"code","d4a04e1a":"code","57b3ae5c":"code","dace7a6a":"code","39f46d0b":"code","340263bd":"code","3aa613b0":"code","d9f94ed2":"code","19c14b59":"code","a1527e7b":"code","5aadb5a6":"code","0f531bcc":"code","046a795a":"code","5ebdbb5a":"code","484cd2bc":"code","9cad7353":"code","e1949150":"code","d2f42103":"code","210b86a6":"code","9ac2e5dd":"code","d54384fd":"code","dbf24fed":"code","d77f4d95":"code","9bc9583d":"code","87a719fa":"code","f639a19c":"code","3cda1e04":"code","9ebb3da5":"code","c59c8bba":"code","acf35d4c":"code","0a8c0e8e":"code","cd90cdda":"code","2c7d296f":"code","eed2a61d":"code","be1e6851":"code","b9fb3df8":"code","ada75065":"code","0f6f511e":"code","32451fe1":"code","457bfe02":"code","30cfe7c4":"code","5d397900":"code","ce497398":"code","2dcff517":"code","5721fef6":"code","2d0c7548":"code","004f6a8c":"code","8c5a20a3":"code","898c5417":"code","61ff6aaa":"code","906ae47e":"code","c23dc354":"code","82494979":"code","660b5239":"code","67733561":"code","3745eed9":"code","22f548f6":"code","d3cbc53f":"code","16181e60":"code","3ab52371":"code","f8f44593":"code","3ea1708e":"code","0f44e46e":"code","e86f8df4":"code","a55b58fe":"code","6b21e1ad":"code","986a9842":"code","491b8716":"code","4509848d":"code","01cd0f8e":"code","61ad30c6":"code","9e7ac55e":"code","50212575":"code","ebea0549":"code","1242581d":"code","45a27039":"code","ca5e6c26":"code","cc18ab25":"code","df302a20":"code","04dbeec6":"code","6659aa23":"code","06c1adab":"code","1b39ab64":"code","49247ab6":"code","ded2aee1":"code","352cc85a":"code","9f63ec12":"code","17a5f992":"code","3ff1c7bc":"code","e79afd91":"code","1df95717":"code","74a0ea19":"code","75c5649a":"code","6c169dd0":"code","8618e7a1":"code","7349e607":"code","c73a7282":"code","163c44ae":"code","1c4b02f4":"code","5bc56eb9":"code","d93dceb9":"code","1a84ea0d":"code","05293c5a":"code","e711d937":"markdown","af99a325":"markdown","d5d4b319":"markdown","be879ba4":"markdown","8b783f3f":"markdown","d311c78b":"markdown","bf66d126":"markdown","dae3530d":"markdown","0687438a":"markdown","744344a6":"markdown","3d9b8b7e":"markdown","b0bf955a":"markdown","a0871d10":"markdown","f53b6e38":"markdown","bdb7e05d":"markdown","a1300141":"markdown","7cb60665":"markdown","8bbc76bc":"markdown","839f0818":"markdown","176e1305":"markdown","975c5571":"markdown","7cc6f220":"markdown","19879b0c":"markdown","60b59c31":"markdown","2d2508cb":"markdown","4a28d725":"markdown","8ce756d6":"markdown","220dd6aa":"markdown","c26c3f7e":"markdown","2a0be525":"markdown","b217529a":"markdown","fed45276":"markdown","93c51477":"markdown","a1a549b0":"markdown","fe6bdb2d":"markdown","3f73a1f8":"markdown","92a07a51":"markdown","b168f7be":"markdown","57979e71":"markdown","7ff7590a":"markdown","63fb6cd7":"markdown","ed4702a0":"markdown","6e91c951":"markdown","ade2bd19":"markdown","6b7d5816":"markdown","469bb1cd":"markdown","ffa58bdc":"markdown","c6e7ae8d":"markdown","ee1d5cb3":"markdown","c0400313":"markdown","cba33aa1":"markdown","fa234414":"markdown","04dca787":"markdown","7136ced7":"markdown","352a8d1a":"markdown","9f012e97":"markdown","a1d0123f":"markdown","92ea3b07":"markdown","f48de36f":"markdown","c751e26d":"markdown","6c1c0de3":"markdown","c98e1830":"markdown","ef7f42d3":"markdown","94032062":"markdown","a3dc82b8":"markdown","b7317f71":"markdown","abc65187":"markdown","19f3bc04":"markdown","7d0b34ba":"markdown","dca960e4":"markdown","5df4a85d":"markdown","f5289dc3":"markdown","565d38d1":"markdown","2d971f69":"markdown","2786bff0":"markdown","3873ec22":"markdown","a7df8985":"markdown","572975e5":"markdown","fc89ac17":"markdown","c9f7df85":"markdown","0f839d9c":"markdown","351cf4c0":"markdown","39424db9":"markdown","13292a8d":"markdown","44be67b5":"markdown","41838dce":"markdown","7b6229f5":"markdown","927252bf":"markdown","533c2a79":"markdown","53627e1c":"markdown","373fe30c":"markdown","7dadc2ea":"markdown","de3670f4":"markdown","0a4c4dfe":"markdown","26151cf2":"markdown","2c461596":"markdown","0d90e300":"markdown","f4896538":"markdown","b82ef2bf":"markdown","46a7b5f6":"markdown","70d6be77":"markdown","647045f9":"markdown","70cb4552":"markdown","0ec3014a":"markdown","6d00df9f":"markdown","74afcbf1":"markdown","2cca8f51":"markdown","05cb9e20":"markdown","65ee8769":"markdown","2c35b54a":"markdown","fb9a4d96":"markdown","a59447e1":"markdown","1e72ca38":"markdown","74f8e442":"markdown","68240f26":"markdown","b0189a85":"markdown","3b3e9f75":"markdown","6fbdabb3":"markdown","0cad74e8":"markdown","fa301015":"markdown","4a546a86":"markdown"},"source":{"f6c48287":"import pandas as pd\nimport numpy as np\n\nimport datetime\nfrom IPython.display import Markdown,display,HTML\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\n# configuration\nnp.set_printoptions(suppress=True)\n%matplotlib inline\nsns.set_context(\"paper\")\nsns.set_style(\"whitegrid\")\n\npd.set_option('display.float_format', lambda x: '%.4f' % x)\n\nimport warnings\nwarnings.filterwarnings('ignore')","77b533da":"# setting up root for data files\ndata_location_root =  '..\/input\/store-sale\/'","5c1a79ff":"stores = pd.read_csv(f'{data_location_root}store.csv')\n\n# peek five records \nstores.head(5)","75d18658":"Markdown(f\"There are `{stores['Store'].shape[0]}` stores data with `{stores.shape[1]}` variables.\")","d4a04e1a":"sales = pd.read_csv(f'{data_location_root}train.csv', parse_dates=[\"Date\"], index_col= 'Date')\nsales.sort_index(inplace=True)\nsales.head(5)","57b3ae5c":"Markdown(f\"There are `{len(sales)}` sales records present from `{sales.index.min().strftime('%x')}` to `{sales.index.max().strftime('%x')}`.\")","dace7a6a":"stores.info()","39f46d0b":"stores = stores.astype({\n    'CompetitionOpenSinceMonth': pd.Int8Dtype(),\n    'CompetitionOpenSinceYear': pd.Int16Dtype(),\n    'Promo2SinceWeek': pd.Int8Dtype(),\n    'Promo2SinceYear': pd.Int16Dtype()\n})","340263bd":"sales.info()","3aa613b0":"def list_variables(df):\n    \"\"\" List each variable name and its missing data count \"\"\"\n    columns_data = []\n    for column in df.columns:\n        columns_data.append([column, df[column].isnull().sum()])\n        \n    return pd.DataFrame(columns_data, columns=[\"Variable\", \"Missing Observations\"])","d9f94ed2":"list_variables(stores)","19c14b59":"def stores_analysis(variable, type=\"count\"):\n    \"\"\"utility method to univariate study of stores' categorical variable \n    \n       - describes its number of store count\n       - plots  counts of categorical value\n       - reports  missing value count if any\n    \"\"\"\n    \n    column_name = f\"Store {type}\"\n    description = stores.groupby(variable)['Store'].aggregate(type).to_frame(name=column_name).sort_values(by=column_name, ascending=False).reset_index()\n    \n    \n    fig = plt.figure(figsize=(9, 4))\n    fig.suptitle(f\"Store {type} vs. {variable}\")\n    gs=fig.add_gridspec(ncols=1, nrows=1)\n    sns.barplot(variable, column_name, data=description, ax=fig.add_subplot(gs[0,0]))\n    fig.tight_layout()\n    plt.show()\n    \n\n    # report\n    nullValues = stores[variable].isnull().sum()\n    if nullValues > 0: \n        display(Markdown(f\"**`{stores[variable].isnull().sum()}` observations are missing.**\"))\n    return description","a1527e7b":"stores_analysis('StoreType', 'count')","5aadb5a6":"stores_analysis('Assortment', 'count')","0f531bcc":"stores_analysis('Promo2', 'count')","046a795a":"stores_analysis('Promo2SinceWeek', 'count')","5ebdbb5a":"stores['Promo2SinceWeek'] = stores['Promo2SinceWeek'].fillna(-1)","484cd2bc":"stores_analysis('Promo2SinceYear', 'count')","9cad7353":"stores['Promo2SinceYear'] = stores['Promo2SinceYear'].fillna(-1)","e1949150":"sns.distplot(stores['CompetitionDistance'])\nplt.show()","d2f42103":"Markdown(f\"`{stores['CompetitionDistance'].isnull().sum()}` stores with missing competition distance. \")","210b86a6":"# getting records of missing `CompetitionDistance`\nstores[stores['CompetitionDistance'].isnull()]","9ac2e5dd":"#  Filling missing data\nstores['CompetitionDistance'] = stores['CompetitionDistance'].fillna(-1)","d54384fd":"stores_analysis('CompetitionOpenSinceMonth', 'count')","dbf24fed":"\n# filling -1 where store does not have competition\nstores.loc[stores['CompetitionDistance'] == -1, 'CompetitionOpenSinceMonth'] = -1\n\n# rest with mode\nstores['CompetitionOpenSinceMonth'] = stores['CompetitionOpenSinceMonth'].fillna(method=\"ffill\")","d77f4d95":"stores['CompetitionOpenSinceMonth'].isnull().sum()","9bc9583d":"stores_analysis('CompetitionOpenSinceYear', 'count')","87a719fa":"\n# filling -1 where store does not have competition\nstores.loc[stores['CompetitionDistance'] == -1, 'CompetitionOpenSinceYear'] = -1\n\n# rest with mode\nstores['CompetitionOpenSinceYear'] = stores['CompetitionOpenSinceYear'].fillna(method=\"ffill\")","f639a19c":"list_variables(sales)","3cda1e04":"sales['Sales'].describe([0, .25, .5, .75, .9, .95, .99]).to_frame()","9ebb3da5":"sns.distplot(sales['Sales'])\nplt.show()","c59c8bba":"# removing outliers: having value more than 99 percentile.\ncount_before_operation = sales.shape[0]\nsales = sales[sales['Sales'] <= sales['Sales'].quantile(.99)]","acf35d4c":"Markdown(f\"The sales count has been reduce to `{sales.shape[0]}` from `{count_before_operation}` after deleting sales outliers. \")","0a8c0e8e":"sales['Customers'].describe([0, .25, .5, .75, .9, .95, .99]).to_frame()","cd90cdda":"sns.distplot(sales['Customers'])\nplt.show()","2c7d296f":"count_before_operation = sales.shape[0]\nsales = sales[sales['Customers'] <= sales['Customers'].quantile(.99)]","eed2a61d":"Markdown(f\"The sales count has been reduce to `{sales.shape[0]}` from `{count_before_operation}` after deleting customers outliers. \")","be1e6851":"def sales_analysis(variable, scale=1):\n    \"\"\"\n    method to analyze variable:\n    \n    - describe its  value counts\n    - plot counts\n    \"\"\"\n    \n    \n    variable_value_counts = sales[variable].value_counts()\n    \n    # plot\n    plt.title(f\"{variable} Count Plot\")\n    sns.barplot(variable_value_counts.index, variable_value_counts.values)\n    \n    variable_value_counts = variable_value_counts.to_frame(name=\"Records Count\")\n    variable_value_counts.index.name = variable\n    return variable_value_counts","b9fb3df8":"sales_analysis('DayOfWeek', scale=10000)","ada75065":"sales_analysis('Open')","0f6f511e":"sales_analysis('Promo')","32451fe1":"sales_analysis('StateHoliday')","457bfe02":"sales_analysis('StateHoliday')","30cfe7c4":"sales['StateHoliday']=sales['StateHoliday'].apply(lambda value: 0 if value == '0' else value )","5d397900":"sales_analysis('StateHoliday')","ce497398":"sales_analysis('SchoolHoliday')","2dcff517":"\n# creating a new dataset combining data of sales and stores\nsales_stores = sales.merge(stores)","5721fef6":"# find number of days stores are closed\nsales[sales['Open'] == 0].shape[0]","2d0c7548":"# find number of days stores are closed and there is no sales\nsales[( sales['Open'] == 0) & (sales['Sales'] != 0)].shape[0]","004f6a8c":"# deleting transactions records\ncount_before_operation = sales.shape[0]\nsales = sales[sales['Open'] != 0]","8c5a20a3":"Markdown(f\"The sales observation has been reduce to `{sales.shape[0]}` from `{count_before_operation}` after deleting records where store is closed. \")","898c5417":"sales.drop(columns=['Open'], inplace=True)\nsales.head()","61ff6aaa":"sns.scatterplot(sales['Customers'], sales['Sales'])\nplt.show()","906ae47e":"display(Markdown(f\"Pearson cofficient is `{'%.2f' % sales[['Sales', 'Customers']].corr().iloc[0,1]}`\"))","c23dc354":"avg_sales__avg_customers = sales.groupby('Store').mean()[['Sales', 'Customers']]\nsns.scatterplot('Customers', 'Sales', data=avg_sales__avg_customers)\nplt.show()","82494979":"display(Markdown(f\"Pearson cofficient is `{'%.2f' % avg_sales__avg_customers[['Sales', 'Customers']].corr().iloc[0,1]}`\"))","660b5239":"sales_customers = sales[['Sales', 'Customers']].resample('M').mean()\nsns.scatterplot('Customers', 'Sales', data=sales_customers)\nplt.show()","67733561":"display(Markdown(f\"Pearson cofficient is `{'%.2f' % sales_customers.corr().iloc[0,1]}`\"))","3745eed9":"average_sales_per_store = sales.groupby('Store')['Sales'].mean().to_frame(\"Average Sales\").reset_index()\n\n# combine it with stores data\naverage_sales_stores = average_sales_per_store.merge(stores)\n\nsns.scatterplot('CompetitionDistance', 'Average Sales', data=average_sales_stores)\nplt.show()","22f548f6":"def sales_with_variable(df, variable):\n    group_by_var = df.groupby(variable)\n\n    # getting average and total sales\n    sales_var = pd.concat([group_by_var['Sales'].sum().to_frame(\"Total Sales\"), group_by_var['Sales'].mean().to_frame(name=\"Average Sales\")], axis=1)\n\n\n    # Visual analysis\n    fig = plt.figure(figsize=(6, 6))\n    gs = fig.add_gridspec(ncols=1, nrows=2, hspace=0.05)\n    fig.suptitle(f'Sales and {variable}')\n    sns.barplot(sales_var.index, sales_var['Total Sales'], ax = fig.add_subplot(gs[0,0]))\n    sns.barplot(sales_var.index, sales_var['Average Sales'], ax= fig.add_subplot(gs[1,0]))\n    plt.show()\n    \n    return sales_var","d3cbc53f":"sales_with_variable(sales, 'Promo')","16181e60":"sales_with_variable(sales_stores, 'Promo2')","3ab52371":"average_sale = sales['Sales'].mean()","f8f44593":"\n# getting previous day sales\nsales['SalesP1'] = sales['Sales'].shift(1)\n\n#  promo if sales is less average sales\nsales['Promo2.1'] = np.where(sales['SalesP1'] <  average_sale, 1, 0)","3ea1708e":"sales_with_variable(sales, 'Promo2.1')","0f44e46e":"sales_with_variable(sales_stores, 'Assortment')","e86f8df4":"sales_with_variable(sales_stores, 'StoreType')","a55b58fe":"sales['Month'] = sales.index.map(lambda date:  date.month)\nsales['Year'] = sales.index.map(lambda date:  date.year)\nsales['WeekInYear'] = sales.index.map(lambda date:  date.weekofyear)\n\nsales_stores = sales.merge(stores)","6b21e1ad":"fig=plt.figure(figsize=(40, 8))\nsns.lineplot(sales['Sales'].index, sales['Sales'], label=\"Sales\")\nsns.lineplot(sales['Sales'].index, sales['Sales'].rolling('7D').mean(), label=\"Moving Average 7D\")\nplt.show()","986a9842":"fig=plt.figure(figsize=(12, 4))\nsales_yearly = sales.groupby([\"Year\", \"Month\"])['Sales'].mean().reset_index()\n# for year in sales_yearly['Year'].unique():\nplt.title(\"Sales over months\")\nsns.lineplot(x=\"Month\", y=\"Sales\", data=sales_yearly, style=\"Year\")\nplt.show()","491b8716":"weekly_sales_per_store = sales.groupby(['Store', 'Year',  'WeekInYear']).aggregate({\"Sales\": \"mean\"})\nweekly_sales_per_store = weekly_sales_per_store.reset_index()\n\nplt.figure(figsize=(20, 4))\nsns.lineplot(x=\"WeekInYear\", y=\"Sales\", style=\"Year\", data=weekly_sales_per_store[weekly_sales_per_store['Store'] ==1] )\nplt.show()","4509848d":"operation_display = {'mean': \"Average\", 'sum': \"Total\"}\nONE_MILLION = 1_000_000\n\ndef timewise_sales_study(df, period, operation, variable = None, million_scale = False, visual=True): \n\n    \n    \"\"\" Breaks and crunch the given dataset into period and aggregate operation \n        - plot the trend of operated Sales (average\/total ) with respect to preriods \n    \"\"\"\n    groupby = [period, variable] if variable else [period]\n    column_name = f\"{operation_display[operation]} Sales{' (m)' if million_scale else ''}\"\n    \n    analyzed_sales = df.groupby(groupby)['Sales'].aggregate(operation).to_frame(name=column_name)\n    analyzed_sales = analyzed_sales \/ ONE_MILLION if million_scale else analyzed_sales\n    analyzed_sales.reset_index(inplace=True)\n    \n\n\n    # visual display \n    if visual: \n        fig = plt.figure(figsize=(15, 4))\n        fig.suptitle(f\"{operation_display[operation]} Sales over {period}\")\n        \n        gs = fig.add_gridspec(ncols=1, nrows=1)\n        sns.barplot(period,column_name, data = analyzed_sales, hue=variable, ax=fig.add_subplot(gs[0,0]))\n        plt.show()\n    \n    return analyzed_sales","01cd0f8e":"timewise_sales_study(sales, 'WeekInYear', 'mean')","61ad30c6":"timewise_sales_study(sales, 'Month', 'mean')","9e7ac55e":"timewise_sales_study(sales, 'Year', 'mean')","50212575":"timewise_sales_study(sales, 'Year', 'sum', million_scale = True)","ebea0549":"timewise_sales_study(sales_stores, 'Year', 'mean', variable='Assortment')","1242581d":"timewise_sales_study(sales_stores, 'Year', 'mean', variable='StoreType')","45a27039":"timewise_sales_study(sales, 'Year', 'mean', variable='Promo')","ca5e6c26":"sales_analysis = timewise_sales_study(sales, 'Store', 'sum', visual=False)\n\n#select bottom 5\nsales_analysis.nlargest(5, 'Total Sales').merge(stores, on=\"Store\", how=\"left\")","cc18ab25":"sales_analysis.nsmallest(5, 'Total Sales').merge(stores, on=\"Store\", how=\"left\")","df302a20":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nseasonal_data = []\nfor period in [7, 30, 90, 180, 270, 365]:\n    result = seasonal_decompose(sales['Sales'], period=period, model=\"additive\", extrapolate_trend = \"freq\")\n    seasonal_data.append([period, result.resid.mean(), result.trend.mean(), result.seasonal.mean()])\n    \nseasonal_df = pd.DataFrame(seasonal_data, columns=[\"period\", \"Residual Mean\", \"Trend Mean\", \"Seasonal\" ]);\nseasonal_df","04dbeec6":"result = seasonal_decompose(sales.loc[ sales['Year'] == 2015, 'Sales'], period=7, model=\"additive\", extrapolate_trend = \"freq\")\nfig = result.plot()\nfig.set_figwidth(20)\nfig.set_figheight(10)\nplt.show()","6659aa23":"sales_df = sales.reset_index().merge(stores, how=\"left\").drop(columns=['PromoInterval', 'Promo2.1', 'SalesP1']).set_index(\"Date\")\nsales_df.head()","06c1adab":"encoder_mapper = {'a': 1, 'b': 2, 'c': 3,'d': 4, 0: 0}\n\nsales_df['StateHoliday'] = sales_df['StateHoliday'].map(encoder_mapper)\nsales_df['Assortment'] = sales_df['Assortment'].map(encoder_mapper)\nsales_df['StoreType'] = sales_df['StoreType'].map(encoder_mapper)","1b39ab64":"sales_df.info()","49247ab6":"sales_df = sales_df.astype(float)","ded2aee1":"from datetime import timedelta\n\n\n# finding the split point\n## Go back 6 weeks (42 days) from the last transaction\nsplit_point = sales_df.index[-1] - timedelta(days=42)\n\n# train data\nsales_df_train = sales_df.loc[sales_df.index <= split_point, :]\n\n# test data\nsales_df_test = sales_df.loc[sales_df.index > split_point, :]","352cc85a":"Markdown(f\"\"\"\n- Numbers of observations in Training Data is `{sales_df_train.shape[0]}`.\n- Numbers of observations in Test Data is `{sales_df_test.shape[0]}`.\n\"\"\")","9f63ec12":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(sales_df_train[['Sales', 'Customers', 'CompetitionDistance']])\nsales_df_train[['Sales', 'Customers', 'CompetitionDistance']]=scaler.transform(sales_df_train[['Sales', 'Customers', 'CompetitionDistance']])\nsales_df_test[['Sales', 'Customers', 'CompetitionDistance']]=scaler.transform(sales_df_test[['Sales', 'Customers', 'CompetitionDistance']])","17a5f992":"sales_df_train.corr()","3ff1c7bc":"plt.figure(figsize=(12, 10))\nsns.heatmap(sales_df_train.corr())\nplt.show()","e79afd91":"from statsmodels.tsa.stattools import adfuller\ndef test_stationary(series, maxlag=12, cuttoff=0.05):\n    \"\"\"Tests the series for stationary using Augmented Dickey Fuller Test\"\"\"\n    results = adfuller(series, autolag='AIC', maxlag=maxlag)\n    if results[1] < cuttoff: \n        display(Markdown(f\"Since p-value is `{'%.4f' % results[1]}` which is less than `0.05`.   \\n=> Rejecting null hypothesis.\"))","1df95717":"test_stationary(sales_df['Sales'])","74a0ea19":"test_stationary(sales_df['Customers'])","75c5649a":"from statsmodels.tsa.stattools import grangercausalitytests\n\ndef causality_tests(data, X,  Y = ['Sales', 'Customers'], ):    \n    \"\"\"Tests X Variables whether they cause Y variable using  Granger\u2019s causality, \n    - Returns p-value matrix  \"\"\"\n    \n    maxlag = 12\n    p_values = []\n    for y in Y:\n        p_values_yx = []\n        for x in X:\n            test_result = grangercausalitytests(data[[y, x]], maxlag=maxlag, verbose=False)\n            p_values_yx.append(np.min([test_result[i+1][0]['ssr_chi2test'][1] for i in range(maxlag)]))\n        p_values.append(p_values_yx)\n    \n    return pd.DataFrame( p_values, columns=X, index=Y)","6c169dd0":"results = causality_tests(sales_df_train, X=['Sales', 'Customers'])  \nresults.style.applymap(lambda value : 'background-color: red' if value > 0.05 else '')","8618e7a1":"from statsmodels.tsa.vector_ar.vecm import coint_johansen\n\n\ndef cointegration_test(df, maxlag=12): \n    \"\"\"Cointegration Test using Johansen\"\"\"\n    out = coint_johansen(df,1,maxlag)\n    \n    \n    # get statis\n    traces = out.lr1\n    \n    #  get 95% Critical value\n    cvts = out.cvt[:, 1]  \n    \n    \n    # Collecting Report and Statistics Value\n    report = []\n    for col, trace, cvt in zip(df.columns, traces, cvts):\n        report.append([col, trace, cvt, trace > cvt])\n\n    return pd.DataFrame(report, columns=[\"Variable\", \"Statistics\", \"Critical Value 95%\", \"Cointegrated?\"])\n\ncointegration_test(sales_df_train)","7349e607":"from statsmodels.tsa.api import VAR\nmodel = VAR(endog=sales_df_train[['Sales', 'Customers']], exog=sales_df_train.drop(columns=['Sales', 'Customers']))","c73a7282":"selector_model = model.select_order(maxlags=12)\nselector_model.summary()","163c44ae":"selected_model = model.fit(12)\nselected_model.summary()","1c4b02f4":"selected_model.plot_acorr()\nplt.show()","5bc56eb9":"irf = selected_model.irf(42)\nirf.plot(orth=False)\nplt.show()","d93dceb9":"# forecasting\nforecast_results = selected_model.forecast(y=sales_df_train[['Sales', 'Customers']].values[-12:], steps=sales_df_test.shape[0], exog_future=sales_df_test.drop(columns=['Sales', 'Customers']))\npredicted_sales = forecast_results[ :, 0]","1a84ea0d":"fig=plt.figure(figsize=(40, 8))\nsns.lineplot(sales_df_test.index, predicted_sales, legend='brief', label=\"Predicted\")\nsns.lineplot(sales_df_test.index, sales_df_test['Sales'], legend='brief', label=\"Actual\")\nplt.show()","05293c5a":"mape = np.mean(abs(sales_df_test['Sales'] - predicted_sales \/ sales_df_test['Sales']))\ndisplay(Markdown(f\"Mean absolute percentage error (MAPE) is `{'%.2f' % mape}%`.\"))","e711d937":"### Sales and Customers","af99a325":"####  Average Customer vs Average Sales per month\nScatter plot of Average Customers Count with Average Sales wrt per month","d5d4b319":"## Sales Dataset\nLoading and peeking Sales data which is in `train.csv`.","be879ba4":"### Seasonal & Trend Analysis\n\nComparing Seasonal & trend for various period & selecting with minimum residual","8b783f3f":"### Impluse Response Function","d311c78b":"> Period 7 has lowest residual mean \n\n","bf66d126":"> There is consistent pattern. With Promo, there is more sale.","dae3530d":"> There are variability in Seasonal & Residual; Howerver these follow consistent pattern.","0687438a":"> `Sales` data almost follows _skewed Normal Distribution_ (leaving zeros sales).","744344a6":"> None of variable has missing values.","3d9b8b7e":"### CompetitionOpenSinceYear","b0bf955a":"Sales Forecasting\n===\n\n# Problem Context\n\nRossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality.\n\nWith thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column. ","a0871d10":"- mean ~ median => the distribution is almost normal.\n- Difference of `99 percentile` and `100 percentile` is very large; which indicates presence of **outliers**.\n\nConfirming distribution visually:","f53b6e38":"### Customer\n`Customer` is another important variable which would be studied.\n\n\n#### Descriptive analysis of Customer Variable","bdb7e05d":"### Promo2SinceWeek\ncalendar week when the store started participating in Promoting activities","a1300141":"- Sales is Strongly corelated to Customers\n- Sales is weakly corelated to Storetype, Assortmen","7cb60665":"### Promo\nPromo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating","8bbc76bc":"> Data is skewed","839f0818":"## Conclusion \n\n\n* Sales, Customer series are stationary \n* StoreType, Assortment, Promo 2 and Competition has long term effect; Promo, StateHoliday has short term effect (no co-integration)\n* With increasing customers, sales are increasing (Strong Correlation).\n* if promo2 was introduced on previous day sales performance sales would have improved.\n* 6 Weeks Sales prediction having `4.5%` mean absolute percentage error (mape) when validated. ","176e1305":"### CompetitionDistance\ndistance in meters to the nearest competitor store","975c5571":"> Most of columns are categorial","7cc6f220":"## Sales over Time\nIn this section, sales would be analyzed with respect to time.\n\n### Time Characterstics based feature engineering\nTo better analyzed Sales with Time, additional Time Characterstics based variables would be introduced\nSales dataset already have `Day of Week`.\n\nThe details of Additional Variables: \n* `Month` : Month in which transaction took placed.\n* `Year` : Year in which transaction took placed.\n* `WeekInYear` : Week of years in which transaction took placed.","19879b0c":"## Encoding data\n\n`StateHoliday`, `Assortment` and `StoreType` contain alphanumeric values which needed to be encoded to numbers.","60b59c31":"> Sales and Customer follow same fluctuations. ","2d2508cb":"> In 14th week, the highest number of activities \n\n\nAlso, `544` values of `Promo2SinceWeek` are missing which is aligned with `Promo2=0` (store is not prompting).  \n\n\n\n#### Filling missing data\nfilling `-1` as week for missing data; `-1` means store is not participating in promo","4a28d725":"### Sales and Assortment","8ce756d6":"### Forecast & Validation","220dd6aa":"=> This confirms that there is **no sale** when stores are closed; there is no data anomaly in this context.\n\n---\nAlso, there is no point to keep these records for further analysis. We can safely delete these records. ","c26c3f7e":"> There is consistent pattern. Assortment typed `c` outperfroms\n","2a0be525":"> Selecting the model with `lag=12` with best `FPE`","b217529a":"> Again, with increasing customers, sales is increasing","fed45276":"- `StoreType`, `Assortment`, `Promo 2` and `Competition` has long term effect\n-  `Promo`, `StateHoliday` has short term effect","93c51477":"> p-values for Customers on Sales and Sales on Customer both are less than `0.05` (cuttoff)   \n=> Rejecting the null hypothesis","a1a549b0":"## Sales with other variables (Bivariate Analysis)","fe6bdb2d":"### Sale\n`Sales` is our targeted variable. It is important to study its trends and relationship with other variables.   \nIn this section sales would be analyzed univariatly.\n\n\n#### Descriptive analysis of `Sales` variable with subjected to various percentile","3f73a1f8":"#### Visual Comparison of Predicted Values with Actual Value","92a07a51":"####  Average Customers Count vs Average Sales per store\n\nSince, it is established that customers and sales both series follows \"Gausian Distribution\"    \n=> it is fair to use their mean values as representives of these series.  \n\n\nScatter plot of Average Customers Count with Average Sales wrt per store","b168f7be":"Also, there is no point of keeping `Open` variable as all the value would be `1` (no variation).   \nRemoving `Open` variable...","57979e71":"### Assortment\nDescribes an assortment level: a = basic, b = extra, c = extended","7ff7590a":"### Promo2SinceYear\ncalendar year when the store started participating in Promoting activities","63fb6cd7":"### Stationary test\n\nusing Augmented Dickey-Fuller which hypothesize that non-stationary series has unit root.\n* Null Hypothesis: Series has unit root; Series is non stationary\n* Alternate Hypothesis: Series does not have unit; Series is stationary","ed4702a0":"> Sales has downward trend; **For year `2015`, it can't be said conclusively as there is no full year data available.** \n\n","6e91c951":"### p-value matrix\nVariable in column causes variable in index ","ade2bd19":"> Almost half of stores are participating in promo","6b7d5816":"> `354` observations are missing\n\n#### Filling missing data\n\n- 3 stores are not having competition which can be filled with `-1` meaning absence of competition\n- rest stores can be filled with mode or highest frequency.","469bb1cd":"> Most of stores has basic facilities","ffa58bdc":"Let's break the above long series in years and then analyze in year's months","c6e7ae8d":"\n> The shape of plot follows skewed Gausian Distribution which confirms presence of outliers","ee1d5cb3":"### Monthly Analysis of Sales","c0400313":"- No data is missing.\n- `Open` (categorical), `Promo` (categorical), `SchoolHoliday` (categorical), `DayOfWeek` (ordinal) are already encoded to integer\n- StateHoliday can be encoded to integer\n","cba33aa1":"#### Removing Sales outliers\n\nKeeping the Sales data below `99 percentile` and removing rest. ","fa234414":"#### Ploting Seasonal \/ Trend with period 7\n\nSince there is 3 years data avaiable; it would not be clean to plot all the data, \nSo 2015 ","04dca787":"# Data Exploration\n","7136ced7":"> Customer Series is **stationary.**","352a8d1a":"`544` values of `Promo2SinceYear` are missing which is aligned with `Promo2=0` (store is not prompting).   ","9f012e97":"##### Deleting transactions when store is closed","a1d0123f":"> Almost half of transactions are with promo","92ea3b07":"### Corelation Analysis\n\n#### Descriptive Analysis","f48de36f":"#### Filling missing data\nfilling `-1` as week for missing data; `-1` means store is not participating in promo\n","c751e26d":"* The data type of `CompetitionDistance`,  `CompetitionOpenSinceYear` should be `int`.\n* `Promo2SinceWeek`, `Promo2SinceYear` should be `int`.\n* Competition data is unavailable for most of stores\n* `Promo2` (categorical) is already encoded to `integer`.\n* Promo data (`Promo2SinceWeek`,`Promo2SinceYear`, `PromoInterval`) seem to be unavailable for most of stores. Howerver, `Promo2` is present which for all. Missing data count should be same as `Promo2=0`.","6c1c0de3":"### What if Promo was decided on previous day sale\n\nFor this analysis, we can compare the previous day sales with Average Sales \n\nif previous day sales is less than Average Sales, then promo would be applied   \nelse not\n","c98e1830":"### CompetitionOpenSinceMonth","ef7f42d3":"> `354` observations are missing\n\n#### Filling missing data\n\n- 3 stores are not having competition which can be filled with `-1` meaning absence of competition\n- rest stores can be filled with previous value","94032062":"## Store Dataset Exploration (Univariate)\n\nIn this section, store dataset variables would be explored in isolation (univariately).    \nLater these would be combined with sales data for more meaning analysis.\n\n\nAlso, missing value would be handled in this section\n\n\nThe stores has following columns for analysis:","a3dc82b8":"### Weekly Analysis of Overall Sales","b7317f71":"## Data Modeling\nusing VAR model; ","abc65187":"### Day of Week","19f3bc04":"### Sales and Competition\nIn this section, competition impact sales would be analyzed. \n\n\n***Intuition 2: Sales amount should indirectly proportional to competitor closeness***     \nMore Close the Competitor, Lesser is the sales\n\n\n---\nThe sales data would be crunched per store, then combined with `Competition Distance`\n","7d0b34ba":"### Open\nAn indicator for whether the store was open: 0 = closed, 1 = open","dca960e4":"#### One - One Plot\nIn this, Scatterplot would be drawn without applying any aggregate operation","5df4a85d":"- `a` typed stores are hightest in numbers\n- `b` typed stores are lowest in numbers.","f5289dc3":"#### Removing outliers\nRemoving values above `99 percentile`.","565d38d1":"> CounterIntuitively, sales' is decresing with increase in competition distance.    \n***It is opposite of Intution 2.***","2d971f69":"### Bottom 5 Stores\nby sales revenue  ","2786bff0":"### Correcting data type of `CompetitionDistance`,  `CompetitionOpenSinceYear` in Stores dataset","3873ec22":"> Note: 2015 sales line is abruptly finished in July as data is not available after july","a7df8985":"## Sales Dataset Exploration (Univariate)\nIn this section sales dataset variables are explored in isolation (univariate analysis).\n\nThe sales dataset has the following variables:","572975e5":"# Data Loading\nIn this section, The data would be loaded from given datasets .     \nThere are two datasets:\n* `store.csv` containing information regarding stores.\n* `sales.csv` containing sales transaction records.","fc89ac17":"#### Visual Analysis of `Sales` variable","c9f7df85":"### StateHoliday\nIndicates if the (Store, Date) was affected by the closure of public schools","0f839d9c":"### Weekly sales of Stores\nIt would be overwheleming to plot all stores data and also, computationally intensive. \nSo limiting the analysis to store 1.","351cf4c0":"## Basic Check\n\nIn section, datatype of variables, missing information would be detected.    \nAlso, The correction would be applied if needed\n\nMissing data treatment would be done in later section.","39424db9":"### Promo\nIndicates whether a store is running a promo on that day","13292a8d":"#### Forecast Evaluation\n\nUsing Mean absolute percentage error (MAPE)","44be67b5":"### Sales and StoreType","41838dce":"Autocorrelated Plot","7b6229f5":"> With increasing Customers, Sales is increasing","927252bf":"#### Reploting `StateHoliday` after correction","533c2a79":"### Long Term Effect \/ Cointegration Analysis\n\nusing Johansen' Cointegration test:    \n=> A variable is cointegrated if statistics output > Critical Value\n","53627e1c":"### Overall Sales and 7D moving average with Time \nOverall Sales means stores are not taken into account while crunching the sales data","373fe30c":"> There is slow rising of Average Sales ","7dadc2ea":"> There are data anomaly    \nvalues: `0` and `'0' (string)` meant same thing\n\n#### Correcting Value of `StateHoliday`","de3670f4":"#### Treating `CompetitionDistance` missing data\nThe Missing data can be filled it with `-1` (absence of competition)  or `mean` if other competition data is available.","0a4c4dfe":"#### Total Sales (In million) analysis","26151cf2":"> Both Average sale and total sale is lesser for store with regular Promo ","2c461596":"### Causality Test\n\n\nusing Granger\u2019s causality test which hypothesize as:\n- Null Hypothesis: x does not Granger cause y \n\n\nif p value is less `0.05`; null hypothesis is rejected","0d90e300":"> `a` typed stores earns the most However the average sales `b` typed stores outperform","f4896538":"### Train-Test Split\n\nIt is required to predict the sales of 6 weeks,   \nTo measure the Performance of Model, data would be split into two parts as \n\n1. Last 6 Weeks data from validation purpose\n2. rest for training purpose","b82ef2bf":"## Data Preparation\nIn this section, would be prepared for modeling\n- required variables would be encoded, \n- unnecessary variables would be dropped.\n- required variables would be standarized","46a7b5f6":"* mean ~ median => The distribution follows Gausian Distribution\n* There is huge difference between 99 percentile and 100 percentile which indicates the presence of outliers.","70d6be77":"### Sales and Promotional\nIn this section, the impact of promotional with sales would be analyzed.\n\n***Intuition 3: Sales with promo should be more than sales with no promo***  \n","647045f9":"## Stores Dataset\nLoading and peeking Stores data which is in `store.csv`.","70cb4552":"> Sales Series is **stationary.**","0ec3014a":"### Sales and closed store \n\n***Intuition 1: There should not be `no sale` if store was closed***    \nThis is quite obvious hypothesis. Tesing this is useful for catching data anomaly if present. ","6d00df9f":"> `a` typed Assortment level stores earns the most ","74afcbf1":"> `End of Year` sales is better than rest of year sales.","2cca8f51":"> Overall Sales would have improved if Promo was applied using previous day sale","05cb9e20":"> `End of Year` sales is better than rest of year sales.","65ee8769":"- 2 years and 7 months of data is presented","2c35b54a":"> All variables are in `Number` and there is no missing data\n\nHowever there are mixed number types; which might trouble in modelling.   \nStandardizing all types to `float`","fb9a4d96":"### Store Type\n4 different store models: a, b, c, d","a59447e1":"#### Yearly Average sales with Promo","1e72ca38":"Since there is no Competition data available for all these records. It can be assumed that competition does not exist for these stores.   \nFilling these stores' `CompetitionDistance` with `-1` (Competition does not exist)","74f8e442":"### Yearly Analysis of Sales\n\n#### Average Sale analysis","68240f26":"#### Visual analysis","b0189a85":"> Time Series is almost stationary except end of year it is upward moving","3b3e9f75":"### Standarising data","6fbdabb3":"#### Yearly Average Sales with StoreType","0cad74e8":"### Top 5 Stores\nby sales revenue  ","fa301015":"> There is little inconsistency in pattern.","4a546a86":"#### Yearly Average Sales with Assortment"}}