{"cell_type":{"04ab2e7c":"code","d2f68089":"code","31f86c1c":"code","f719074d":"code","17590cd6":"code","83f5d4d1":"code","54e8ee76":"code","d6acf0f5":"code","ed4d8e1c":"code","679ef148":"code","f6ad8346":"code","1ff8265d":"code","19d2f64b":"code","01677d1b":"code","e141139b":"code","1aa993ba":"code","c31ebf1d":"code","a7b553d1":"code","2a80804e":"code","64e72563":"code","63eb2d62":"code","0904a189":"code","a8247cf4":"code","7f6a88a9":"code","9d978e4a":"code","82f8eb82":"code","38fdca7a":"markdown","553176dd":"markdown","40532bd5":"markdown","daaa7832":"markdown","50b5750c":"markdown","f724f40f":"markdown","9f12d37b":"markdown","cbeeb859":"markdown","3081aa02":"markdown","25b29f20":"markdown","2ef4aa28":"markdown","54deaae0":"markdown","77a21dd7":"markdown","5d4e4fa7":"markdown","dfe6fa58":"markdown","41224539":"markdown","630bf09e":"markdown","b9d0da5c":"markdown","129f759e":"markdown","28b5b684":"markdown","b94ca317":"markdown","41bd84b3":"markdown","d86ea4fe":"markdown","0a76d632":"markdown","c4206d0d":"markdown"},"source":{"04ab2e7c":"import tensorflow as tf\nprint(tf.__version__)","d2f68089":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport urllib.request\n\nimport os\nimport zipfile\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator,load_img\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense,Conv2D, MaxPooling2D,GlobalMaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras import optimizers","31f86c1c":"urllib.request.urlretrieve(\"https:\/\/download.microsoft.com\/download\/3\/E\/1\/3E1C3F21-ECDB-4869-8368-6DEBA77B919F\/kagglecatsanddogs_3367a.zip\", \"cat_dog.zip\")\n#zip = ZipFile('cat_dog.zip')\n#zip.extractall()","f719074d":"import zipfile\nzip_ref = zipfile.ZipFile('cat_dog.zip', 'r')\nzip_ref.extractall('..\/output\/')\nzip_ref.close()\n\nimport os\nos.listdir('..\/output\/PetImages')\n\nprint('total  dog images :', len(os.listdir('..\/output\/PetImages\/Dog') ))\nprint('total  cat images :', len(os.listdir('..\/output\/PetImages\/Cat') ))\n\nos.remove('..\/output\/PetImages\/Cat\/666.jpg')\nos.remove('..\/output\/PetImages\/Dog\/11702.jpg')","17590cd6":"os.listdir('..\/output\/PetImages\/Dog')[1:10]","83f5d4d1":"image = load_img('..\/output\/PetImages\/Dog\/4644.jpg')\nplt.imshow(image)","54e8ee76":"os.listdir('..\/output\/PetImages\/Cat')[1:10]","d6acf0f5":"image = load_img('..\/output\/PetImages\/Cat\/8962.jpg')\nplt.imshow(image)","ed4d8e1c":"img_width=150\nimg_height=150\nbatch_size=20\ninput_shape = (img_width, img_height, 3)","679ef148":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1.\/255.\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.3,\n    zoom_range=[0.6,1.0],\n    brightness_range=[0.6,1.0],\n    rotation_range=90,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\n# --------------------\n# Flow training images in batches of 20 using train_datagen generator\n# --------------------\ntrain_generator = train_datagen.flow_from_directory(\n    '..\/output\/PetImages',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical',\n    seed = 42,\n    subset='training'\n    \n)\nvalid_generator = train_datagen.flow_from_directory(\n    '..\/output\/PetImages',\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    #class_mode='binary',\n    class_mode='categorical',\n    seed = 42,\n    subset='validation'\n    \n)\n#X, y = next(train_generator)","f6ad8346":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in train_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","1ff8265d":"####################### VGG16\nfrom keras.applications import VGG16\npre_trained_model = VGG16(input_shape=(150, 150, 3), include_top=False, weights=\"imagenet\")\n\nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\n\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output","19d2f64b":"pre_trained_model.summary()","01677d1b":"# Flatten the output layer to 1 dimension\nx = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\n#x = Dense(1, activation='sigmoid')(x)\nx = Dense(2, activation='softmax')(x)\nmodel = Model(pre_trained_model.input, x)","e141139b":"model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['acc'])","1aa993ba":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n#earlystop = EarlyStopping(patience=5)\nearlystop=EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20, verbose=0, mode='auto')\ncallbacks = [earlystop]","c31ebf1d":"history = model.fit_generator(\n            train_generator,\n            validation_data = valid_generator,\n            steps_per_epoch = 100,\n            epochs = 50,\n            validation_steps = 50,\n            verbose = 1\n            ,callbacks=callbacks\n)","a7b553d1":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\nacc      = history.history[     'acc' ]\nval_acc  = history.history[ 'val_acc' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\n#plt.plot  ( epochs,     loss )\n#plt.plot  ( epochs, val_loss )\n#plt.title ('Training and validation loss'   )","2a80804e":"!pip install -q pyyaml h5py","64e72563":"# save model\nfrom keras.models import load_model\nmodel.save('VGG16_dog_cat_cnn_model.h5')","63eb2d62":"from IPython.display import FileLink\nFileLink(r'VGG16_dog_cat_cnn_model.h5')","0904a189":"import keras\nnew_model = keras.models.load_model('VGG16_dog_cat_cnn_model.h5')","a8247cf4":"val_loss, val_acc = model.evaluate(valid_generator)  # evaluate the out of sample data with model\n#print(val_loss)  # model's loss (error)\n","7f6a88a9":"print(val_acc)  # model's accuracy","9d978e4a":"urllib.request.urlretrieve('https:\/\/dcist.com\/wp-content\/uploads\/sites\/3\/2019\/04\/Gem2-768x689.jpg', \"image.jpg\")","82f8eb82":"import numpy as np\nimport pandas as pd\n#from keras_preprocessing import image\n#import PIL.Image as Image\nimport tensorflow as tf\n#import cv2\nimport PIL.Image as Image\nx = Image.open('image.jpg').resize((150, 150))\nx = np.array(x)\/255.0\nnew_model = tf.keras.models.load_model ('VGG16_dog_cat_cnn_model.h5')\nresult = new_model.predict(x[np.newaxis, ...])\ndf = pd.DataFrame(data =result,columns=['cat','dog'])\ndf","38fdca7a":"# 1.load package","553176dd":"### download cat and dog picture from microsoft","40532bd5":"### make prediction on one image","daaa7832":"### compile model with SGD optimizer ","50b5750c":"## Dog picture","f724f40f":"### load the saved model","9f12d37b":"# 2.download cat dog data","cbeeb859":"# 3.load data with ImageDataGenerator","3081aa02":"# 6.model result","25b29f20":"\n<img src=\"https:\/\/www.pyimagesearch.com\/wp-content\/uploads\/2019\/07\/keras_data_augmentation_in_place.png\" width=\"600\">","2ef4aa28":"<img src=\"https:\/\/pythonprogramming.net\/static\/images\/machine-learning\/convolution-new-featuremap.png\" width=\"600\">","54deaae0":"# 5.trainning model","77a21dd7":"## show picture after augmentation","5d4e4fa7":"<img src=\"https:\/\/dcist.com\/wp-content\/uploads\/sites\/3\/2019\/04\/Gem2-768x689.jpg\" width=\"400\">","dfe6fa58":"# 7.save model and load model","41224539":"### train model with 50 epochs","630bf09e":"### import all other pakcage","b9d0da5c":"### make prediction on test data","129f759e":"### import tensorflow package and check tensorflow version","28b5b684":"# 4.define model","b94ca317":"## Cat picture","41bd84b3":"### set up callbacks with earlystop","d86ea4fe":"\n<img src=\"https:\/\/pythonprogramming.net\/static\/images\/machine-learning\/artificial-neural-network-model.png\" width=\"600\">","0a76d632":"### This is a notebook for transfer learning (VGG16)Cat dog image classfication with tensorflow CNN model with data augmentation, drop out.\n\n### 1.load package - > 2.download data -> 3.data augmentation -> 4.define model -> 5.train model -> 6.model performance - > 7.save model","c4206d0d":"### unzip the file"}}