{"cell_type":{"450c5db0":"code","1600ff77":"code","b61e6bad":"code","a24cfbdb":"code","6ac92f8b":"code","9f31b89c":"code","4756f7ec":"code","91185816":"code","9593c3b8":"code","567fe1c2":"code","b1d38c0a":"code","5ffe633d":"code","acbb9e31":"code","52666d32":"code","a760e21a":"code","ed80328b":"code","1e85813d":"code","d8eb8dfc":"code","5065588b":"code","0af7e7c4":"code","cdc0164b":"code","6a6af6de":"code","da7a9b7a":"code","a21d6fa6":"code","f68f6aa1":"code","025c01c6":"code","8890550c":"code","79e2251f":"code","b67c9acd":"code","ff5d0c43":"code","674b29a4":"code","9648aa4f":"code","a1396a16":"code","1baac425":"code","182e3550":"code","3d2cc057":"code","3b806e5c":"code","0cc009f3":"code","39af19ab":"markdown","a4445f18":"markdown","9c6d8eca":"markdown","9e856abd":"markdown","86d9a60e":"markdown","50580d45":"markdown","7882f663":"markdown","56b480d3":"markdown","8c56339d":"markdown","4a8b66bf":"markdown","70578290":"markdown","faaa0e7b":"markdown","ca8b71c0":"markdown","1d7f6d53":"markdown","40edb095":"markdown","2035fd90":"markdown","1d7e2b98":"markdown","825e6978":"markdown","abd45bc2":"markdown"},"source":{"450c5db0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.cluster import KMeans\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1600ff77":"data_path = '..\/input\/credit-card-data.csv' # Path to data file\ndata = pd.read_csv(data_path)\ndata.head(15)","b61e6bad":"data.columns","a24cfbdb":"data.describe()\n","6ac92f8b":"#can be used to convey results of box plot but easier to visualize and interpret\nfor col in data.columns[2:]:\n    data[col].plot(kind='hist')\n    plt.title('histogram plot for '+col)\n    plt.show()","9f31b89c":" data.installments_purchases[data.installments_purchases>5000].plot(kind='hist')","4756f7ec":"\nlen(data.purchases[data.purchases < 3000])","91185816":"from scipy.stats import kurtosis, skew","9593c3b8":"result_array = np.array([])\n\nfor col in data.columns[1:]:\n    result = format( skew(data[col]) )\n    result_array = np.append(result_array, result)\n","567fe1c2":"label = ['balance', 'balance_frequency', 'purchases',\n       'oneoff_purchases', 'installments_purchases', 'cash_advance',\n       'purchases_frequency', 'oneoff_purchases_frequency',\n       'purchases_installments_frequency', 'cash_advance_frequency',\n       'cash_advance_trx', 'purchases_trx', 'credit_limit', 'payments',\n       'minimum_payments', 'prc_full_payment', 'tenure']","b1d38c0a":"index = np.arange(len(label))\nindex","5ffe633d":"    # this is for plotting purpose\nplt.bar(index,result_array)\nplt.xlabel('Columns in dataset', fontsize=15)\nplt.ylabel('Skewness', fontsize=15)\nplt.xticks(index, label, fontsize=10, rotation=90)\nplt.title('Displaying skewness distribution Columns')\nplt.show()\n   ","acbb9e31":"for col in data.columns[2:]:\n    data[col].plot(kind='density')\n    plt.title('Density Plot for '+col)\n    plt.show()","52666d32":"cluster_data = data[['purchases','payments']]\ncluster_data.head()","a760e21a":"cluster_data.plot(kind='scatter',x='purchases',y='payments')","ed80328b":"\n# Is there any missing data\nmissing_data_results = cluster_data.isnull().sum()\nprint(missing_data_results)\n\n# perform imputation with median values\n# not require since none missing\n#cluster_data = cluster_data.fillna( data.median() )","1e85813d":"\n#retrieve just the values for all columns except customer id\ndata_values = cluster_data.iloc[ :, :].values\ndata_values","d8eb8dfc":"\n# Use the Elbow method to find a good number of clusters using WCSS (within-cluster sums of squares)\nwcss = []\nfor i in range( 1, 15 ):\n    kmeans = KMeans(n_clusters=i, init=\"k-means++\", n_init=10, max_iter=300) \n    kmeans.fit_predict( data_values )\n    wcss.append( kmeans.inertia_ )\n    \nplt.plot( wcss, 'ro-', label=\"WCSS\")\nplt.title(\"Computing WCSS for KMeans++\")\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()","5065588b":"kmeans = KMeans(n_clusters=5, init=\"k-means++\", n_init=10, max_iter=300) \ncluster_data[\"cluster\"] = kmeans.fit_predict( data_values )\ncluster_data","0af7e7c4":"\ncluster_data['cluster'].value_counts()","cdc0164b":"cluster_data['cluster'].value_counts().plot(kind='pie',title='Numerical Portion each groups')\nfig = plt.gcf()\nfig.set_size_inches(7,4)\nplt.show()","6a6af6de":"cluster_data['cluster'].value_counts().plot(kind='bar',title='Distribution of Customers across groups')\nfig = plt.gcf()\nfig.set_size_inches(7,4)\nplt.show()","da7a9b7a":"cluster_data1 = data[['payments','oneoff_purchases']]\ncluster_data1.head()","a21d6fa6":"\nmissing_data_results = cluster_data1.isnull().sum()\nprint(missing_data_results)","f68f6aa1":"cluster_data1.plot(kind='scatter',x='payments',y='oneoff_purchases')","025c01c6":"#retrieving just the values for purchases and oneoff_purchases\ndata_values = cluster_data1.iloc[ :, :].values\ndata_values","8890550c":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans","79e2251f":"mms = MinMaxScaler()\nmms.fit(data_values)\ndata_transformed = mms.transform(data_values)","b67c9acd":"Sum_of_squared_distances = []\nK = range(1,15)\nfor i in K:\n    km = KMeans(n_clusters=i)\n    km = km.fit(data_transformed)\n    Sum_of_squared_distances.append(km.inertia_)","ff5d0c43":"plt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","674b29a4":"kmeans = KMeans(n_clusters=4, init=\"k-means++\", n_init=10, max_iter=300)\ncluster_data1[\"cluster\"] = kmeans.fit_predict( data_values )\ncluster_data1","9648aa4f":"#viewing amount of elements in clusters\ncluster_data1['cluster'].value_counts()","a1396a16":"import seaborn as sns\nsns.set(color_codes=True)","1baac425":"cluster_data1['cluster'].value_counts().plot(kind='bar',title='Distribution of Customers')","182e3550":"sns.pairplot( cluster_data1, hue=\"cluster\")","3d2cc057":"grouped_cluster_data = cluster_data1.groupby('cluster')\ngrouped_cluster_data","3b806e5c":"grouped_cluster_data.describe()","0cc009f3":"grouped_cluster_data.plot(subplots=True)","39af19ab":"In the plot above the elbow is at k=4 indicating the optimal k for this dataset is 4","a4445f18":"Aim: Can we identify groups based on purchases and payments?\nIf that is the case, we could offer different payment plans based on different purchases.","9c6d8eca":"Illustrating the numerical proportion of each groups using pie chart. When lookking at the graph we can see where group1 is rather close to group three but this is because their numerical portion is of close value and the scale of the chart.","9e856abd":"For each k value, we will initialise k-means and use the inertia attribute to identify the sum of squared distances of samples to the nearest cluster centre.","86d9a60e":"Determining how best i can price products so that customers to purchase with one payment using k-means.","50580d45":"Determining how best i can price products so that customers to purchase with one payment. \nFrom the scatter plot below,we can see that customers normally make one-off payments for products just below 10000","7882f663":"Group four only has 31 customers but probably 31 is a significant number\nfor customers of that type and could help marketing department to make better decisions","56b480d3":"I did not understand the code in the lab to find the best number of clusters so i resarched another way that i could understand","8c56339d":"To give equal importance to all features, we need to scale the continuous features. We will be using scikit-learn\u2019s MinMaxScaler as the feature matrix is a mix of binary and continuous features . Other alternatives includes StandardScaler.","4a8b66bf":"**checking for missing data **\n\nComplete case analysis, Complete case analysis followed by nearest-neighbor assignment for partial data, Partial data cluster analysis, Replacing missing values or incomplete data with means Imputation are all ways to deals with missing data.","70578290":"Plot 3","faaa0e7b":"**3. Repeat the clustering activity on different columns in an attempt to provide additional mar-\nketing insight. If the results are not insightful state why**","ca8b71c0":" A Density Plot visualises the distribution of data over a continuous interval or time period. This chart is a **variation of a Histogram** that uses kernel smoothing to plot values, allowing for **smoother distributions by smoothing out the noise**.","1d7f6d53":"**1. Provide three(3) plots of the data to assist in describing the initial data set**","40edb095":"Second Plot","2035fd90":"**2. Plot the differences between the groups above using at least two (2) charts.**","1d7e2b98":"The mean is measures of the center of a set of data.","825e6978":"Plots below showing us an estimate of how much \"Payments\" and \"oneoff_purchases\" were \nmade in each groups. Looking at group 4(last graph below) we can see that there are\nless payments and one-off purchases from these customers so probably marketing should ignore them.","abd45bc2":"As k increases, the sum of squared distance tends to zero."}}