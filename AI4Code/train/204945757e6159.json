{"cell_type":{"444d1212":"code","0d0efc27":"code","eb72de62":"code","7f3894fe":"code","d613aacb":"code","a3ccc151":"code","83c4d4f7":"code","5db02fad":"code","39ed3a45":"code","cf5f5599":"code","242b5512":"code","785ba2bb":"markdown","747b3962":"markdown","ad3341b4":"markdown","d09c6e02":"markdown","6cb24af7":"markdown","fb5a12e8":"markdown","b063d270":"markdown","b252c4ef":"markdown","a626ff12":"markdown","d26c57d4":"markdown"},"source":{"444d1212":"!pip install mtcnn","0d0efc27":"import mtcnn\n# print version\nprint(mtcnn.__version__)","eb72de62":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 # opencv\nfrom mtcnn.mtcnn import MTCNN\nfrom matplotlib import pyplot as plt\nfrom keras.models import load_model\nfrom PIL import Image\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7f3894fe":"img = cv2.imread('..\/input\/5-celebrity-faces-dataset\/data\/train\/ben_afflek\/httpcsvkmeuaeccjpg.jpg')\nplt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n#plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\nplt.show()\nprint(img.shape)","d613aacb":"# extract a single face from a given photograph\ndef extract_face(filename, required_size=(160, 160)):\n    # load image from file\n    image = Image.open(filename)\n    # convert to RGB, if needed\n    image = image.convert('RGB')\n    # convert to array\n    pixels = np.asarray(image)\n    # create the detector, using default weights\n    detector = MTCNN()\n    # detect faces in the image\n    results = detector.detect_faces(pixels)\n    # extract the bounding box from the first face\n    x1, y1, width, height = results[0]['box']\n    # deal with negative pixel index\n    x1, y1 = abs(x1), abs(y1)\n    x2, y2 = x1 + width, y1 + height\n    # extract the face\n    face = pixels[y1:y2, x1:x2]\n    # resize pixels to the model size\n    image = Image.fromarray(face)\n    image = image.resize(required_size)\n    face_array = np.asarray(image)\n    return face_array\n\n# load the photo and extract the face\npixels = extract_face('..\/input\/5-celebrity-faces-dataset\/data\/train\/ben_afflek\/httpcsvkmeuaeccjpg.jpg')\nplt.imshow(pixels)\nplt.show()\nprint(pixels.shape)","a3ccc151":"def load_face(dir):\n    faces = list()\n    # enumerate files\n    for filename in os.listdir(dir):\n        path = dir + filename\n        face = extract_face(path)\n        faces.append(face)\n    return faces\n\ndef load_dataset(dir):\n    # list for faces and labels\n    X, y = list(), list()\n    for subdir in os.listdir(dir):\n        path = dir + subdir + '\/'\n        faces = load_face(path)\n        labels = [subdir for i in range(len(faces))]\n        print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n        X.extend(faces)\n        y.extend(labels)\n    return np.asarray(X), np.asarray(y)\n\n\n# load train dataset\ntrainX, trainy = load_dataset('..\/input\/5-celebrity-faces-dataset\/data\/train\/')\nprint(trainX.shape, trainy.shape)\n# load test dataset\ntestX, testy = load_dataset('..\/input\/5-celebrity-faces-dataset\/data\/val\/')\nprint(testX.shape, testy.shape)\n\n# save and compress the dataset for further use\nnp.savez_compressed('5-celebrity-faces-dataset.npz', trainX, trainy, testX, testy)\n        ","83c4d4f7":"# load the face dataset\ndata = np.load('5-celebrity-faces-dataset.npz')\ntrainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\nprint('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)","5db02fad":"# load the facenet model\nfacenet_model = load_model('..\/input\/facenet-keras\/facenet_keras.h5')\nprint('Loaded Model')","39ed3a45":"def get_embedding(model, face):\n    # scale pixel values\n    face = face.astype('float32')\n    # standardization\n    mean, std = face.mean(), face.std()\n    face = (face-mean)\/std\n    # transfer face into one sample (3 dimension to 4 dimension)\n    sample = np.expand_dims(face, axis=0)\n    # make prediction to get embedding\n    yhat = model.predict(sample)\n    return yhat[0]\n    \n# convert each face in the train set into embedding\nemdTrainX = list()\nfor face in trainX:\n    emd = get_embedding(facenet_model, face)\n    emdTrainX.append(emd)\n    \nemdTrainX = np.asarray(emdTrainX)\nprint(emdTrainX.shape)\n\n# convert each face in the test set into embedding\nemdTestX = list()\nfor face in testX:\n    emd = get_embedding(facenet_model, face)\n    emdTestX.append(emd)\nemdTestX = np.asarray(emdTestX)\nprint(emdTestX.shape)\n\n# save arrays to one file in compressed format\nnp.savez_compressed('5-celebrity-faces-embeddings.npz', emdTrainX, trainy, emdTestX, testy)","cf5f5599":"from sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.svm import SVC\n\nprint(\"Dataset: train=%d, test=%d\" % (emdTrainX.shape[0], emdTestX.shape[0]))\n# normalize input vectors\nin_encoder = Normalizer()\nemdTrainX_norm = in_encoder.transform(emdTrainX)\nemdTestX_norm = in_encoder.transform(emdTestX)\n# label encode targets\nout_encoder = LabelEncoder()\nout_encoder.fit(trainy)\ntrainy_enc = out_encoder.transform(trainy)\ntesty_enc = out_encoder.transform(testy)\n# fit model\nmodel = SVC(kernel='linear', probability=True)\nmodel.fit(emdTrainX_norm, trainy_enc)\n# predict\nyhat_train = model.predict(emdTrainX_norm)\nyhat_test = model.predict(emdTestX_norm)\n# score\nscore_train = accuracy_score(trainy_enc, yhat_train)\nscore_test = accuracy_score(testy_enc, yhat_test)\n# summarize\nprint('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))","242b5512":"from random import choice\n# select a random face from test set\nselection = choice([i for i in range(testX.shape[0])])\nrandom_face = testX[selection]\nrandom_face_emd = emdTestX_norm[selection]\nrandom_face_class = testy_enc[selection]\nrandom_face_name = out_encoder.inverse_transform([random_face_class])\n\n# prediction for the face\nsamples = np.expand_dims(random_face_emd, axis=0)\nyhat_class = model.predict(samples)\nyhat_prob = model.predict_proba(samples)\n# get name\nclass_index = yhat_class[0]\nclass_probability = yhat_prob[0,class_index] * 100\npredict_names = out_encoder.inverse_transform(yhat_class)\nall_names = out_encoder.inverse_transform([0,1,2,3,4])\n#print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\nprint('Predicted: \\n%s \\n%s' % (all_names, yhat_prob[0]*100))\nprint('Expected: %s' % random_face_name[0])\n# plot face\nplt.imshow(random_face)\ntitle = '%s (%.3f)' % (predict_names[0], class_probability)\nplt.title(title)\nplt.show()\n","785ba2bb":"See a sample image","747b3962":"Randomly select a face from test set for prediction. Calculate confidence","ad3341b4":"The extract_face function load a image file and return the extracted face in 160 * 160 pixels shape as needed for trained FaceNet model","d09c6e02":"Import libraries","6cb24af7":"First of all, You will need to install a face detector library. Before installing, turn on the Internet at Kaggle Kernal Settings","fb5a12e8":"To confirm that library is installed correctly","b063d270":"Try the extract_face() on the sample image. Works nicely","b252c4ef":"Next step is standardizing the faces and extracting a embedding vector using the model","a626ff12":"This project aims to test FaceNet system for face recognition. FaceNet is proposed by [Florian Schroff](http:\/\/www.florian-schroff.de) in the 2015 paper [FaceNet: A Unified Embedding for Face Recognition and Clustering](https:\/\/arxiv.org\/abs\/1503.03832)\n\nA pretrained FaceNet model by [Hiroki Taniai](https:\/\/drive.google.com\/drive\/folders\/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn) is used here.\n\nThis project is inspired by [Machine Learning Mastery](https:\/\/machinelearningmastery.com\/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier\/)","d26c57d4":"Apply extract_face() for all faces in the dataset"}}