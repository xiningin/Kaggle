{"cell_type":{"1cbc4c16":"code","631b944c":"code","601e63fb":"code","ed1a52ae":"code","07b32696":"code","36430285":"code","30ea76b4":"code","0d031c5f":"code","956214fb":"code","9a2a3891":"code","00937712":"code","a4866cf3":"code","5cb8b99c":"code","53b3ba1a":"markdown","7f9c9c5d":"markdown","17b1f8cd":"markdown"},"source":{"1cbc4c16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","631b944c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\nfrom sklearn.preprocessing import StandardScaler , Binarizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport time\nimport os, sys, gc, warnings, random, datetime\nimport math\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nwarnings.filterwarnings('ignore')","601e63fb":"df = pd.read_pickle(\"\/kaggle\/input\/handling-imbalanced-data-eda-small-fe\/df_for_use.pkl\")","ed1a52ae":"plt.figure(figsize = (9,9))\ncorr = df.corr()\nsns.heatmap(corr, cmap='RdBu')","07b32696":"X = df.drop('loan_condition_cat', axis=1)\ny = df['loan_condition_cat']\n\n\nX_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)","36430285":"### LightGBM without Outlier Elimination\n\n\nstart = time.time()\n\nlgbm_clf = LGBMClassifier(n_estimators = 3000, random_state = 2020)\nevals = [(X_test, y_test)]\nlgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric = 'auc' , eval_set = evals, verbose = 50)\nlgbm_cpu_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1], average = 'macro')\n\nlgbm_cpu_runtime = time.time() - start\n\nprint( 'LightGBM_cpu_ROC_AUC : {0:.4f} , Runtime : {1:.4f}'.format(lgbm_cpu_roc_score ,lgbm_cpu_runtime ))","30ea76b4":"def get_outlier(df= None, column = None, weight = 5.0):\n    #Extract column data with Bad Loan only, get 1\/4 percentile and 3\/4 percentile through np.percentile\n    \n    bad_loan = df[df['loan_condition_cat']==1][column]\n    quantile_25 = np.percentile(bad_loan.values,25)\n    quantile_75 = np.percentile(bad_loan.values,75)\n    \n    #calculate IQR, multiply with 3, get min,max value\n    \n    iqr = quantile_75  - quantile_25\n    iqr_weight = iqr*weight\n    lowest_val = quantile_25 - iqr_weight\n    highest_val = quantile_25 + iqr_weight\n    \n    #fix outlier which is bigger than max, smaller than min\n    \n    outlier_index = bad_loan[(bad_loan < lowest_val) | (bad_loan > highest_val)].index\n    return outlier_index","0d031c5f":"outlier_index = get_outlier (df = df , column = 'recoveries', weight = 5.0)\nprint ( \"Outlier index :\", outlier_index)","956214fb":"def get_preprocessed_df(df=None):\n    df_copy = df.copy()\n    amount_n = np.log1p(df['loan_amount'])\n    df_copy.insert(0, 'Amount_Scaled', amount_n)\n    df_copy.drop(['loan_amount'], axis=1, inplace=True)\n    # \uc774\uc0c1\uce58 \ub370\uc774\ud130 \uc0ad\uc81c\ud558\ub294 \ub85c\uc9c1 \ucd94\uac00\n    outlier_index = get_outlier(df=df_copy, column='recoveries', weight=5.0)\n    df_copy.drop(outlier_index, axis=0, inplace=True)\n    return df_copy\n","9a2a3891":"df_copy = get_preprocessed_df(df)","00937712":"X = df_copy.drop('loan_condition_cat', axis=1)\ny = df_copy['loan_condition_cat']\n\n\nX_train, X_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)","a4866cf3":"\nstart = time.time()\n\nlgbm_clf = LGBMClassifier(n_estimators = 3000, random_state = 2020)\nevals = [(X_test, y_test)]\nlgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric = 'auc' , eval_set = evals, verbose = 50)\nlgbm_outlier_eliminated_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1], average = 'macro')\n\nlgbm_outlier_eliminated_runtime = time.time() - start\n\nprint( 'LightGBM_outlier_eliminated_ROC_AUC : {0:.4f} , Runtime : {1:.4f}'.format(lgbm_outlier_eliminated_roc_score ,lgbm_outlier_eliminated_runtime ))","5cb8b99c":"print( 'LightGBM_cpu_ROC_AUC : {0:.4f} , Runtime : {1:.4f}'.format(lgbm_cpu_roc_score ,lgbm_cpu_runtime ))\nprint( 'LightGBM_outlier_eliminated_ROC_AUC : {0:.4f} , Runtime : {1:.4f}'.format(lgbm_outlier_eliminated_roc_score ,lgbm_outlier_eliminated_runtime ))\n\n\n### Negative Effect on Model\n#### Opinion : Since DATA is not so skewed, so many columns are designated as outlier and removed","53b3ba1a":"## LightGBM (Apply Outlier Elimination)","7f9c9c5d":"## Libraries","17b1f8cd":"## LightGBM Without Outlier Elimination"}}