{"cell_type":{"2d414c43":"code","0fba6ebe":"code","5ef68375":"code","783d3d8b":"code","9b6846cd":"code","e70dc506":"code","733574c8":"code","ba87ab06":"code","8f89cbcc":"code","947d8ba6":"code","25c4826a":"code","ee5112ef":"code","e55cdfa0":"code","f44b01aa":"code","32cb520b":"code","817b778f":"code","8aea3c9b":"code","317264b6":"code","c4486b5f":"code","3db806d2":"code","9ab6381f":"code","9de18f2c":"markdown","4a19f5da":"markdown","7afaab01":"markdown","1e9fb7ba":"markdown","dede1d11":"markdown","803a0f7b":"markdown","df5bca03":"markdown","e81f6f5f":"markdown","f86c3635":"markdown","d4157943":"markdown","865b5021":"markdown","69708e3f":"markdown","46505a6d":"markdown","7505299b":"markdown","eb094d72":"markdown","1c435065":"markdown","53e11f2c":"markdown","fb436dcc":"markdown","581451eb":"markdown","5adcb3e3":"markdown","0f214176":"markdown","62c44c79":"markdown","461131a0":"markdown","e71ddb2e":"markdown","2da4ab41":"markdown","5ce7162e":"markdown","64e986a3":"markdown","c6b3e644":"markdown"},"source":{"2d414c43":"import os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport pydicom as dicom\nimport cv2\nimport ast\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0fba6ebe":"path = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/'\nos.listdir(path)","5ef68375":"train_data = pd.read_csv(path+'train_labels.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","783d3d8b":"print('Samples train:', len(train_data))\nprint('Samples test:', len(samp_subm))","9b6846cd":"train_data.head()","e70dc506":"train_data[\"MGMT_value\"].value_counts().head(2).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","733574c8":"train_data[\"MGMT_value\"].value_counts()","ba87ab06":"samp_subm.head()","8f89cbcc":"folder = str(train_data.loc[0, 'BraTS21ID']).zfill(5)\nfolder","947d8ba6":"os.listdir(path+'train\/'+folder)","25c4826a":"print('Number of FLAIR images:', len(os.listdir(path+'train\/'+folder+'\/'+'FLAIR')))\nprint('Number of T1w images:', len(os.listdir(path+'train\/'+folder+'\/'+'T1w')))\nprint('Number of T1wCE images:', len(os.listdir(path+'train\/'+folder+'\/'+'T1wCE')))\nprint('Number of T2w images:', len(os.listdir(path+'train\/'+folder+'\/'+'T2w')))","ee5112ef":"path_file = ''.join([path, 'train\/', folder, '\/', 'FLAIR\/'])\nimage = os.listdir(path_file)[0]\ndata_file = dicom.dcmread(path_file+image)\nimg = data_file.pixel_array","e55cdfa0":"print('Image shape:', img.shape)","f44b01aa":"def plot_examples(row = 0, cat = 'FLAIR'): \n    folder = str(train_data.loc[row, 'BraTS21ID']).zfill(5)\n    path_file = ''.join([path, 'train\/', folder, '\/', cat, '\/'])\n    images = os.listdir(path_file)\n    \n    fig, axs = plt.subplots(1, 5, figsize=(30, 30))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    \n    for num in range(5):\n        data_file = dicom.dcmread(path_file+images[num])\n        img = data_file.pixel_array\n        axs[num].imshow(img, cmap='gray')\n        axs[num].set_title(cat+' '+images[num])\n        axs[num].set_xticklabels([])\n        axs[num].set_yticklabels([])\n        \nrow = 0\nplot_examples(row = row, cat = 'FLAIR')","32cb520b":"plot_examples(row = row, cat = 'T1w')","817b778f":"plot_examples(row = row, cat = 'T1wCE')","8aea3c9b":"plot_examples(row = row, cat = 'T2w')","317264b6":"VGG_types = {\n    'VGG11' : [64, 'M', 128, 'M', 256, 256, 'M', 512,512, 'M',512,512,'M'],\n    'VGG13' : [64,64, 'M', 128, 128, 'M', 256, 256, 'M', 512,512, 'M', 512,512,'M'],\n    'VGG16' : [64,64, 'M', 128, 128, 'M', 256, 256,256, 'M', 512,512,512, 'M',512,512,512,'M'],\n    'VGG19' : [64,64, 'M', 128, 128, 'M', 256, 256,256,256, 'M', 512,512,512,512, 'M',512,512,512,512,'M']\n}\nclass VGGnet(nn.Module):\n    def __init__(self, model, in_channels=3, num_classes=10, init_weights=True):\n        super(VGGnet,self).__init__()\n        self.in_channels = in_channels\n\n        # create conv_layers corresponding to VGG type\n        self.conv_layers = self.create_conv_laters(VGG_types[model])\n\n        self.fcs = nn.Sequential(\n            nn.Linear(1536, 1536\/\/2),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(1536\/\/2, 1536\/\/2),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(1536\/\/2, num_classes),\n        )\n\n        # weight initialization\n        if init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.fcs(x)\n        return x\n\n    # defint weight initialization function\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm3d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    # define a function to create conv layer taken the key of VGG_type dict \n    def create_conv_laters(self, architecture):\n        layers = []\n        in_channels = self.in_channels # 3\n\n        for x in architecture:\n            if type(x) == int: # int means conv layer\n                out_channels = x\n\n                layers += [nn.Conv3d(in_channels=in_channels, out_channels=out_channels,\n                                     kernel_size=(3,2,3), stride=(1,1,1), padding=(1,1,1)),\n                           nn.BatchNorm3d(x),\n                           nn.ReLU()]\n                in_channels = x\n            elif x == 'M':\n                layers += [nn.MaxPool3d(kernel_size=(2,2,2), stride=(2,2,2))]\n        \n        return nn.Sequential(*layers)","c4486b5f":"# define device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# creat VGGnet object\n# Choose between 'VGG11', 'VGG13', 'VGG16', 'VGG19'\nmodel = VGGnet('VGG16', in_channels=1, num_classes=1, init_weights=True).to(device)\nprint(model)","3db806d2":"samp_subm.head()","9ab6381f":"samp_subm.to_csv('submission.csv', index=False)","9de18f2c":"### Importing Libraries","4a19f5da":"### The exact mpMRI scans included are:\n\n* Fluid Attenuated Inversion Recovery\n* T1-weighted pre-contrast (T1w)\n* T1-weighted post-contrast (T1Gd)\n* T2-weighted (T2)\n","7afaab01":"> # T2w Images ","1e9fb7ba":"![](https:\/\/www.researchgate.net\/profile\/Max_Ferguson\/publication\/322512435\/figure\/fig3\/AS:697390994567179@1543282378794\/Fig-A1-The-standard-VGG-16-network-architecture-as-proposed-in-32-Note-that-only.png)","dede1d11":"# Read Dicom Files\nWe consider the first train sample.\n```\nTraining\/Validation\/Testing\n\u2502\n\u2514\u2500\u2500\u2500 00000\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500 FLAIR\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1wCE\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T2w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 .....\n\u2502   \n\u2514\u2500\u2500\u2500 00001\n\u2502   \u2502 ...\n\u2502   \n\u2502 ...   \n\u2502   \n\u2514\u2500\u2500\u2500 00002\n\u2502   \u2502 ...\n```","803a0f7b":"<div class=\"alert alert-block alert-danger\">  \n<h1>If you like my work, please upvote ^ \ud83d\udc4d my code so that i will be motivated to share more valuable and helpful work on this competition \ud83d\ude0d<\/h1>\n        <\/p>\n<\/div>","df5bca03":"### Path of dataset","e81f6f5f":"### Read the refrence paper for more ideas \n\nU.Baid, et al., \u201cThe RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor Segmentation and Radiogenomic Classification\u201d, arXiv:2107.02314, 2021.\nhttps:\/\/arxiv.org\/abs\/2107.02314","f86c3635":"### MGMT_value counts ","d4157943":"## More code is coming Soon. Please upvote if you like the work and you will get notifications with additions. \n\n<center><img src=\"https:\/\/thumbs.gfycat.com\/AshamedWeightyDachshund-max-1mb.gif\"><\/center>","865b5021":"<div class=\"alert alert-block alert-info\">  \n    <h3><strong>Guideline to submit the results<\/strong><\/h3>\n    <i><\/i>\n<\/div>","69708e3f":"### Extract folder id of the first train sample","46505a6d":"### Overview of dataset","7505299b":"### Take overview of the Competition here \n\nhttps:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/overview","eb094d72":"#### How to submit results ","1c435065":"> **Check the submission.csv file so we will know the format that how can submit the predictions. Before we do so, it's worth reminding ourselves that this is a code-only competition, meaning that your submission file has to be generated in a script\/notebook. The submission.csv file demonstrated what kind of file needs to be produced:**","53e11f2c":"> # T1w Images ","fb436dcc":"> # T1wCE Images ","581451eb":"### Read image","5adcb3e3":"### Folders content","0f214176":"### Files\ntrain\/ - folder containing the training files, with each top-level folder representing a subject\ntrain_labels.csv - file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation)\ntest\/ - the test files, which use the same structure as train\/; your task is to predict the MGMT_value for each subject in the test data. NOTE: the total size of the rerun test set (Public and Private) is ~5x the size of the Public test set\nsample_submission.csv - a sample submission file in the correct format","62c44c79":"> **We submitted the predictions but we will come back soon with model training and a lot more.**","461131a0":"### Image shape","e71ddb2e":"> # Flair Images ","2da4ab41":"![](https:\/\/www.mdpi.com\/jcm\/jcm-10-01411\/article_deploy\/html\/images\/jcm-10-01411-g001.png)","5ce7162e":"<div class=\"alert alert-block alert-success\">  \n    <center><h2><strong>\ud83d\udc68\u200d\ud83d\udcbb Getting Started with RSNA-MICCAI Brain Tumor Radiogenomic Classification<\/strong><\/h2><\/center>\n    <i><\/i>\n<\/div>","64e986a3":"# Transfer Learning for Brain Tumor Radiogenomic Classification\u00b6","c6b3e644":"#### Loading dataset"}}