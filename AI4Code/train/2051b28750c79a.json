{"cell_type":{"aa9ef93a":"code","ac4a28ab":"code","bdd463af":"code","b108ebb7":"code","47fe44ba":"code","3ddafc67":"code","73ca1ef1":"code","e0355aa9":"code","7aeb1bd0":"code","dcef6107":"code","e0f86c49":"code","1fb01221":"code","8b463583":"code","bbedbf49":"markdown","3a58ad6c":"markdown","98a347b5":"markdown"},"source":{"aa9ef93a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n#!pip install -U tensorflow==1.7.0  ##2.0.0-alpha0\n#!pip install Keras==2.2.4\n#!pip install Keras==1.7.0\n#!pip install tensorflow --upgrade\n#!pip install keras --upgrade\n\nimport numpy as np\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom keras.models import  Sequential\nfrom keras.layers.core import Dense, Flatten, Lambda# , , , Dropout\nfrom keras.layers import Convolution2D, MaxPooling2D, BatchNormalization\n#from tensorflow.keras import  backend as K\n\nprint(\"tf.__version__ is\", tf.__version__)\nprint(\"tf.keras.__version__ is:\", tf.keras.__version__)\n\n\n#from tensorflow import keras\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n","ac4a28ab":"#tf.config.experimental_list_devices()\ntf.config.list_logical_devices()","bdd463af":"sample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(\"test.shape\", test.shape)\nprint(\"train.shape\", train.shape)","b108ebb7":"X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')\nprint(\"y_train\", y_train)","47fe44ba":"print(\"Before\")\nprint(\"X_train.shape\", X_train.shape)\nprint(\"X_test.shape\", X_test.shape)\nprint(\"After\")\n#Convert train datset to (num_images, img_rows, img_cols) format \nX_train = X_train.reshape(X_train.shape[0], 28, 28)\n\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])\n    \n#expand 1 more dimention as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nprint(\"X_train.shape\", X_train.shape)\nprint(\"X_test.shape\", X_test.shape)","3ddafc67":"mean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px\n","73ca1ef1":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","e0355aa9":"from sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches=gen.flow(X_val, y_val, batch_size=64)","7aeb1bd0":"gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3, \n                               height_shift_range=0.08, zoom_range=0.08)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches = gen.flow(X_val, y_val, batch_size=64)","dcef6107":"def get_bn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","e0f86c49":"#AttributeError: module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'\n#\n\nmodel= get_bn_model()","1fb01221":"model.optimizer.lr=0.01\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","8b463583":"model.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(X, y, batch_size=64)\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)\n\npredictions = model.predict_classes(X_test, verbose=0)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)","bbedbf49":"**Feature Standardization**\n-------------------------------------\n\nIt is important preprocessing step.\nIt is used to centre the data around zero mean and unit variance.","3a58ad6c":"### This notebook is showing of the error\n*AttributeError: module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'*  \nI found that it is happened in tensorflow_backend.py (line 506)  when creating 'Sequential' model (Dense).  \nIt is happened as i understood beacause of tf.config.experimental_list_devices() is removed in newer version.  \nI am new in python and just open an issue https:\/\/github.com\/keras-team\/keras\/issues\/13684","98a347b5":"## Error here."}}