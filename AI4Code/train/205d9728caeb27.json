{"cell_type":{"4ed51608":"code","435b5659":"code","f2a68876":"code","a34830d5":"code","8e6ba5e4":"code","ef8839ea":"code","2088cc4c":"code","6a3f2bf5":"code","49382809":"code","ac27c11e":"code","87cfc8cd":"code","38ea3a6c":"code","29196f47":"code","ceffa8a1":"code","afdaecfc":"code","e28881c4":"code","6c47dd35":"code","da7e9f8c":"code","8c0005e8":"code","fcd11135":"code","36beed06":"code","7fadb3e6":"code","b3d5829d":"code","16723b9e":"code","59a2bf5d":"code","3b3801de":"code","c9c02fb3":"code","b171fe92":"code","bc224521":"code","e397555b":"code","d3068d8d":"code","6edec054":"code","c43cd0f6":"code","faf4fcc0":"code","1346193d":"code","86935474":"code","f21d2678":"code","726186ad":"code","f9e87690":"code","7c535c55":"code","d2b7b832":"code","03fbda27":"code","84ce3d67":"code","841a223d":"code","ac16e589":"code","ce7d48fb":"code","4c0267f4":"code","413a0732":"code","13c5c663":"markdown","5f2a5b86":"markdown","aee9b241":"markdown","e779975f":"markdown","459acf6b":"markdown","820a2d80":"markdown"},"source":{"4ed51608":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","435b5659":"train=pd.read_csv(r\"..\/input\/fake-news\/train.csv\")\ntest=pd.read_csv(r\"..\/input\/fake-news\/test.csv\")","f2a68876":"train.head(10)","a34830d5":"test.head()","8e6ba5e4":"###Drop Nan Values\ntrain=train.dropna()","ef8839ea":"## Get the Independent Features\n\nX=train.drop('label',axis=1)","2088cc4c":"## Get the Dependent features\ny=train['label']","6a3f2bf5":"X.shape","49382809":"y.shape","ac27c11e":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","87cfc8cd":"### Vocabulary size\nvoc_size=5000","38ea3a6c":"messages=X.copy()","29196f47":"messages['title'][1]","ceffa8a1":"messages.reset_index(inplace=True)","afdaecfc":"import nltk\nimport re\nfrom nltk.corpus import stopwords","e28881c4":"nltk.download('stopwords')","6c47dd35":"### Dataset Preprocessing\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\n\ndef data_preprocessing(messages):\n    corpus = []\n    for i in range(0, len(messages)):\n    \n        review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n        review = review.lower()\n        review = review.split()\n    \n        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n        review = ' '.join(review)\n        corpus.append(review)\n        #corpus\n    return [one_hot(words,voc_size)for words in corpus]\n\n\nonehot_repr=data_preprocessing(messages)","da7e9f8c":"#onehot_repr","8c0005e8":"sent_length=20\ndef embedding_representation(onehot_repr):\n    \n    embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n    return embedded_docs\n\nembedded_docs=embedding_representation(onehot_repr)","fcd11135":"embedded_docs[0]","36beed06":"from tensorflow.keras.layers import Dropout\n\n#create model\n\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","7fadb3e6":"print(model.summary())","b3d5829d":"len(embedded_docs),y.shape","16723b9e":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","59a2bf5d":"X_final.shape,y_final.shape","3b3801de":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","c9c02fb3":"### Finally Training\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","b171fe92":"y_pred=model.predict_classes(X_test)","bc224521":"from sklearn.metrics import confusion_matrix","e397555b":"confusion_matrix(y_test,y_pred)","d3068d8d":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","6edec054":"test.head()","c43cd0f6":"test_messages=test.copy()\ntest_messages = test_messages.fillna(' ')","faf4fcc0":"test_messages['title'].head()","1346193d":"test_messages['title'].isnull().sum()","86935474":"len(test_messages['title'])","f21d2678":"test_messages.reset_index(inplace=True)","726186ad":"test_onehot_repr=data_preprocessing(test_messages)","f9e87690":"test_embedded_docs=embedding_representation(test_onehot_repr)","7c535c55":"test_embedded_docs","d2b7b832":"test_final=np.array(test_embedded_docs)","03fbda27":"test_final","84ce3d67":"model_prediction = model.predict_classes(test_final)","841a223d":"model_prediction=model_prediction.ravel()","ac16e589":"model_prediction","ce7d48fb":"submission = pd.DataFrame({'id':test_messages['id'], 'label':model_prediction})\nsubmission.shape","4c0267f4":"submission.head()","413a0732":"submission.to_csv('submit.csv', index = False)","13c5c663":"# Test Data Prediction","5f2a5b86":"## Model Training","aee9b241":"## Embedding Representation","e779975f":"## Onehot Representation","459acf6b":"## Creating model","820a2d80":"\n# Performance Metrics And Accuracy"}}