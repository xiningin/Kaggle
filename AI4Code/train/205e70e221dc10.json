{"cell_type":{"2e94f50d":"code","f19eeab6":"code","fefe7463":"code","c7b8dedd":"code","7787fa71":"code","2798fc62":"code","d019e8d5":"code","927977b5":"code","05aa74b8":"code","d95e3f30":"code","a1c6b855":"code","10414754":"code","4d857736":"code","06664541":"code","f2866277":"code","07dae289":"code","8385bf98":"code","76917c7d":"code","50d5bc1e":"code","234b887c":"code","86d1c568":"code","2a2075ae":"code","8f0bef28":"code","8875f5f5":"code","36cafee0":"code","df8064b8":"code","83100c69":"code","04fb7398":"code","ddd22929":"code","ef0854f3":"code","cf09a79f":"code","1cf2062a":"code","6f45345d":"code","13442139":"code","fdc28de6":"code","250d8af6":"code","d5fab20e":"code","18769a8c":"code","2e4affd9":"code","096a555d":"code","aad0eee8":"code","65b788a4":"code","6455814c":"code","66189972":"code","bd4c48ea":"code","6ce15a41":"code","2170a88a":"code","0b627fd1":"code","29e72222":"code","29bcf61d":"code","9c40c1e0":"code","eb5414ca":"code","9c6b07ae":"code","b06aff6b":"code","f1b337e5":"code","58385bd1":"code","6a602758":"code","989324b9":"code","1fbab8a5":"code","4e217437":"markdown","f649526b":"markdown","53433f4f":"markdown","d22783d2":"markdown","c0e9f4d9":"markdown","c420b68f":"markdown","dafe8628":"markdown","0d5a5596":"markdown","eda03aa6":"markdown","1f91b99d":"markdown","f62c8401":"markdown"},"source":{"2e94f50d":"!pip install -U segmentation_models_pytorch","f19eeab6":"!pip install catalyst","fefe7463":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset as BaseDataset\n\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\n\nfrom catalyst.data import Augmentor\nfrom catalyst.dl import utils\nfrom catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\nfrom catalyst.dl.runner import SupervisedRunner\nfrom catalyst.contrib.models.segmentation import Unet\nfrom catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback\n\nimport segmentation_models_pytorch as smp\n\nfrom skimage.transform import resize","c7b8dedd":"path = \"..\/input\/seebirds\/\"\nseebirds_data = pd.read_csv(f'{path}\/All_Birds_format2.csv')","7787fa71":"seebirds_data.head()","2798fc62":"def convert_to_int(series):\n    series = series.apply(lambda x: round(float(x)))\n    return(series)","d019e8d5":"seebirds_data[\"Leftcoords\"] = seebirds_data[\"Leftcoords\"].apply( lambda x : x.replace(\"(\",\"\"))\nseebirds_data[\"Leftcoords\"] = seebirds_data[\"Leftcoords\"].apply( lambda x : x.replace(\")\",\"\"))\nseebirds_data[\"XLeft\"] = seebirds_data[\"Leftcoords\"].apply( lambda x : x.split(\",\")[0].strip())\nseebirds_data[\"YLeft\"] = seebirds_data[\"Leftcoords\"].apply( lambda x : float(x.split(\",\")[1].strip()))\n\nseebirds_data[\"XLeft\"] = convert_to_int(seebirds_data[\"XLeft\"])\nseebirds_data[\"YLeft\"] = convert_to_int(seebirds_data[\"YLeft\"])","927977b5":"seebirds_data[\"Rightcoords\"] = seebirds_data[\"Rightcoords\"].apply( lambda x : x.replace(\"(\",\"\"))\nseebirds_data[\"Rightcoords\"] = seebirds_data[\"Rightcoords\"].apply( lambda x : x.replace(\")\",\"\"))\nseebirds_data[\"XRight\"] = seebirds_data[\"Rightcoords\"].apply( lambda x : x.split(\",\")[0].strip())\nseebirds_data[\"YRight\"] = seebirds_data[\"Rightcoords\"].apply( lambda x : x.split(\",\")[1].strip())\n\nseebirds_data[\"XRight\"] = convert_to_int(seebirds_data[\"XRight\"])\nseebirds_data[\"YRight\"] = convert_to_int(seebirds_data[\"YRight\"])\n","05aa74b8":"seebirds_data[\"Topcoords\"] = seebirds_data[\"Topcoords\"].apply( lambda x : x.replace(\"(\",\"\"))\nseebirds_data[\"Topcoords\"] = seebirds_data[\"Topcoords\"].apply( lambda x : x.replace(\")\",\"\"))\nseebirds_data[\"XTop\"] = seebirds_data[\"Topcoords\"].apply( lambda x : x.split(\",\")[0].strip())\nseebirds_data[\"YTop\"] = seebirds_data[\"Topcoords\"].apply( lambda x : float(x.split(\",\")[1].strip()))\n\nseebirds_data[\"XTop\"] = convert_to_int(seebirds_data[\"XTop\"])\nseebirds_data[\"YTop\"] = convert_to_int(seebirds_data[\"YTop\"])","d95e3f30":"seebirds_data[\"Bottomcoords\"] = seebirds_data[\"Bottomcoords\"].apply( lambda x : x.replace(\"(\",\"\"))\nseebirds_data[\"Bottomcoords\"] = seebirds_data[\"Bottomcoords\"].apply( lambda x : x.replace(\")\",\"\"))\nseebirds_data[\"XBottom\"] = seebirds_data[\"Bottomcoords\"].apply( lambda x : x.split(\",\")[0].strip())\nseebirds_data[\"YBottom\"] = seebirds_data[\"Bottomcoords\"].apply( lambda x : float(x.split(\",\")[1].strip()))\n\nseebirds_data[\"XBottom\"] = convert_to_int(seebirds_data[\"XBottom\"])\nseebirds_data[\"YBottom\"] = convert_to_int(seebirds_data[\"YBottom\"])","a1c6b855":"seebirds_data.head()","10414754":"seebirds_data.to_csv(\"seebirds_data.csv\",index = False)","4d857736":"import cv2\nimport matplotlib.pyplot as plt\n\npath = \"..\/input\/seebirds\/Seebirds\/Seebirds\/\"\n\nimage_file = path + seebirds_data.Image[0]\n\nimage = cv2.imread(image_file)","06664541":"image.shape","f2866277":"mask = np.zeros((image.shape[0],image.shape[1]))","07dae289":"mask.shape","8385bf98":"total_rows = seebirds_data.shape[0]","76917c7d":"total_rows","50d5bc1e":"files_present = []\nfiles_absent = []","234b887c":"for i in range(total_rows):\n    image_file = path + seebirds_data.Image[i]\n    isExist = os.path.exists(image_file) \n    if (isExist):\n        files_present.append(image_file)\n    else:\n        files_absent.append(image_file)","86d1c568":"len(files_present)","2a2075ae":"len(files_absent)","8f0bef28":"x = np.unique(files_present)","8875f5f5":"len(x)","36cafee0":"im_width = 128\nim_height = 128\nim_chan = 1","df8064b8":"images_tot = len(np.unique(files_present))","83100c69":"unique_files = np.unique(files_present)\nlen_unique_files = len(unique_files)","04fb7398":"unique_files[:10]","ddd22929":"seebirds_data[\"Image_full_path\"] = \"..\/input\/seebirds\/Seebirds\/Seebirds\/\" + seebirds_data[\"Image\"]","ef0854f3":"seebirds_data.head()","cf09a79f":"image.shape","1cf2062a":"a = unique_files[0]\ndf = seebirds_data[ (seebirds_data.Image_full_path == a) & (seebirds_data.Annotation == \"AdultBird\")] \nfor index, row in df.iterrows():\n        X1 = row.XLeft\n        X2 = row.XRight\n        Y1 = row.YBottom\n        Y2 = row.YTop\n\n        mask[Y1:Y2,X1:X2] = 1\n        \nmask2 = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)","6f45345d":"plt.imshow(np.squeeze(mask2))","13442139":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()\n    \n# helper function for data visualization    \ndef denormalize(x):\n    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n    x_max = np.percentile(x, 98)\n    x_min = np.percentile(x, 2)    \n    x = (x - x_min) \/ (x_max - x_min)\n    x = x.clip(0, 1)\n    return x","fdc28de6":"def to_tensor(x, **kwargs):\n    \"\"\"\n    Convert image or mask.\n    \"\"\"\n    return x.transpose(2, 0, 1).astype('float32')","250d8af6":"# classes for data loading and preprocessing\nclass Dataset(BaseDataset):\n    \n    \"\"\"Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        images_path (str): path of images\n        \n        class_values (list): values of classes to extract from segmentation mask\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    \n    CLASSES = ['AdultBird']\n    \n    def __init__(\n            self, \n            images_path, \n            classes=None, \n            augmentation=None, \n            preprocessing=None,\n    ):\n        self.images_fps = images_path\n                     \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n        \n    def __len__(self):\n        return(len(self.images_fps))\n    \n    def get_ith_element(self ,i):\n        return(self.images_fps[i])\n    \n    def __getitem__(self, i):\n\n        # read data\n        image = cv2.imread(self.images_fps[i])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image,(128,128))\n            \n        \n        \n        #create mask\n              \n        df = seebirds_data[ (seebirds_data.Image_full_path == self.images_fps[i]) & \n                            (seebirds_data.Annotation == \"AdultBird\")] \n        \n        mask = np.zeros((1080, 1920),dtype=np.int) \n        \n        for index, row in df.iterrows():\n            X1 = row.XLeft\n            X2 = row.XRight\n            Y1 = row.YBottom\n            Y2 = row.YTop\n\n            mask[Y1:Y2,X1:X2] = 1\n        \n        mask = resize(mask, (128, 128,1), mode='constant', preserve_range=True)\n        \n        \n       \n        \n        # apply augmentations\n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n\n        # apply preprocessing\n        if self.preprocessing:\n            sample = self.preprocessing(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n\n        return image, mask\n","d5fab20e":"dataset = Dataset(unique_files)","18769a8c":"len(dataset)","2e4affd9":"image, mask = dataset[0] # get some sample","096a555d":"visualize(\n    image=image, \n    adult_birds = mask.squeeze()\n)","aad0eee8":"print(image.shape, mask.shape)","65b788a4":"import albumentations as A","6455814c":"def round_clip_0_1(x, **kwargs):\n    return x.round().clip(0, 1)\n\n# define heavy augmentations\ndef get_training_augmentation():\n    train_transform = [\n\n        A.HorizontalFlip(p=0.5),\n\n        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n\n        A.PadIfNeeded(min_height=128, min_width=128, always_apply=True, border_mode=0),\n        A.RandomCrop(height=128, width=128, always_apply=True),\n\n        A.IAAAdditiveGaussianNoise(p=0.2),\n        A.IAAPerspective(p=0.5),\n\n        A.OneOf(\n            [\n                A.CLAHE(p=1),\n                A.RandomBrightness(p=1),\n                A.RandomGamma(p=1),\n            ],\n            p=0.9,\n        ),\n\n        A.OneOf(\n            [\n                A.IAASharpen(p=1),\n                A.Blur(blur_limit=3, p=1),\n                A.MotionBlur(blur_limit=3, p=1),\n            ],\n            p=0.9,\n        ),\n\n        A.OneOf(\n            [\n                A.RandomContrast(p=1),\n                A.HueSaturationValue(p=1),\n            ],\n            p=0.9,\n        ),\n        A.Lambda(mask=round_clip_0_1)\n    ]\n    return A.Compose(train_transform)\n\n\ndef get_validation_augmentation():\n    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n    test_transform = [\n        A.PadIfNeeded(128, 128)\n    ]\n    return A.Compose(test_transform)\n\ndef get_preprocessing(preprocessing_fn):\n    \"\"\"Construct preprocessing transform\n    \n    Args:\n        preprocessing_fn (callbale): data normalization function \n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n    \n    \"\"\"\n    \n    _transform = [\n        A.Lambda(image=preprocessing_fn),\n        A.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return A.Compose(_transform)","66189972":"dataset = Dataset(seebirds_data[\"Image_full_path\"],augmentation=get_training_augmentation())","bd4c48ea":"image, mask = dataset[12] # get some sample","6ce15a41":"visualize(\n    image=image, \n    adult_birds = mask.squeeze()\n)","2170a88a":"X_train, X_test = train_test_split(unique_files,test_size=0.2)","0b627fd1":"len(X_train),len(X_test)","29e72222":"X_train[:3]","29bcf61d":"ENCODER = 'se_resnext50_32x4d'\nENCODER_WEIGHTS = 'imagenet'\nDEVICE = 'cuda'\nCLASSES = ['AdultBird']\nACTIVATION = 'sigmoid'","9c40c1e0":"# create segmentation model with pretrained encoder\nmodel = smp.Unet(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    classes=1, \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","eb5414ca":"train_dataset = Dataset(\n    X_train, \n    preprocessing=get_preprocessing(preprocessing_fn),\n    classes=CLASSES,\n)\n\nvalid_dataset = Dataset(\n    X_test, \n    preprocessing=get_preprocessing(preprocessing_fn),\n    classes=CLASSES,\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=12)\nvalid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)","9c6b07ae":"loaders = {\n    \"train\": train_loader,\n    \"valid\": valid_loader\n}","b06aff6b":"num_epochs = 2\nlogdir = \".\/logs\/segmentation\"\n\n# model, criterion, optimizer\noptimizer = torch.optim.Adam([\n    {'params': model.decoder.parameters(), 'lr': 1e-2}, \n    {'params': model.encoder.parameters(), 'lr': 1e-3},  \n])\nscheduler = ReduceLROnPlateau(optimizer, factor=0.15, patience=2)\ncriterion = smp.utils.losses.BCEDiceLoss(eps=1.)\nrunner = SupervisedRunner()","f1b337e5":"runner.train(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loaders=loaders,\n    callbacks=[DiceCallback(), EarlyStoppingCallback(patience=5, min_delta=0.001)],\n    logdir=logdir,\n    num_epochs=num_epochs,\n    verbose=True\n)","58385bd1":"# this get predictions for the whole loader\npredictions = runner.predict_loader(\n    model=model,\n    loader=valid_loader,\n    resume=f\"{logdir}\/checkpoints\/best.pth\",\n    verbose=True,\n)","6a602758":"print(type(predictions))\nprint(predictions.shape)","989324b9":"def show_examples(name: str, image: np.ndarray, mask: np.ndarray):\n    plt.figure(figsize=(10, 14))\n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title(f\"Image: {name}\")\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(mask)\n    plt.title(f\"Mask: {name}\")","1fbab8a5":"threshold = 0.5\nmax_count = 5\n\n\ndef detach(tensor: torch.Tensor) -> np.ndarray:\n    return tensor.detach().cpu().numpy()\n\nfor i, (features, logits) in enumerate(zip(valid_dataset, predictions)):\n    image = features[0]\n    \n    \n    image = image.transpose(1, 2, 0)\n    mask_ = torch.from_numpy(logits[0]).sigmoid()\n    mask = detach(mask_ > threshold).astype(\"uint8\")\n        \n    show_examples(name=\"\", image=image, mask=mask)\n    \n    if i >= max_count:\n        break","4e217437":"# Create the Dataset class","f649526b":"# Segmentation Model Training","53433f4f":"# Read a Image","d22783d2":"# Import Libraries","c0e9f4d9":"# Create masks","c420b68f":"# Utility Functions","dafe8628":"# Get the Unique File Names in the CSV","0d5a5596":"# Inference ","eda03aa6":"# Augmentation Code","1f91b99d":"# Read the Bounding Box File","f62c8401":"## Viz Augmented Data"}}