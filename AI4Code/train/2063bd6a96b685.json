{"cell_type":{"4c9a302a":"code","eaf4860f":"code","2e09b0fc":"code","d5d1ccee":"code","c9d7da14":"code","6cbdace9":"code","a783cbdf":"code","8a21598f":"code","d0540b38":"markdown","349e8b6c":"markdown","bc42a392":"markdown","9029139d":"markdown","b559c43a":"markdown","511059db":"markdown","f55c2ec3":"markdown","6c800c59":"markdown"},"source":{"4c9a302a":"# 1. Enable Internet in the Kernel (Settings side pane)\n\n# 2. Curl cache may need purged if v0.1.4 cannot be found (uncomment if needed). \n# !curl -X PURGE https:\/\/pypi.org\/simple\/kaggle-environments\n\n# ConnectX environment was defined in v0.1.4\n!pip install 'kaggle-environments>=0.1.4'","eaf4860f":"from kaggle_environments import evaluate, make\n\nenv = make(\"connectx\", debug=True)\nenv.render()","2e09b0fc":"def my_agent(observation, configuration):\n    import numpy as np\n    max_depth = 4\n    def check_win(bord):\n        for y in range(bord.shape[0]):\n            for x in range(bord.shape[1]):\n                if x+3 < bord.shape[1] and bord[y,x] != 0:\n                    if bord[y,x] == bord[y,x+1] and \\\n                       bord[y,x+1] == bord[y,x+2] and \\\n                       bord[y,x+2] == bord[y,x+3]:\n                        return bord[y,x]\n                if y+3 < bord.shape[0] and bord[y,x] != 0:\n                    if bord[y,x] == bord[y+1,x] and \\\n                       bord[y+1,x] == bord[y+2,x] and \\\n                       bord[y+2,x] == bord[y+3,x]:\n                        return bord[y,x]\n                if x+3 < bord.shape[1] and y+3 < bord.shape[0] and bord[y,x] != 0:\n                    if bord[y,x] == bord[y+1,x+1] and \\\n                       bord[y+1,x+1] == bord[y+2,x+2] and \\\n                       bord[y+2,x+2] == bord[y+3,x+3]:\n                        return bord[y,x]\n                if x+3 < bord.shape[1] and y+3 < bord.shape[0] and bord[y+3,x] != 0:\n                    if bord[y+3,x] == bord[y+2,x+1] and \\\n                       bord[y+2,x+1] == bord[y+1,x+2] and \\\n                       bord[y+1,x+2] == bord[y,x+3]:\n                        return bord[y+3,x]\n        return 0\n    def make_score(bord):\n        \"\"\"\n        If the game does not advance to the conclusion even after calculating up to max_depth, \n        a score is obtained from the board. Here, the score is simply set to be advantageous \n        to the side where the stones are gathered.\n        \"\"\"\n        d = np.where(bord == 1)\n        s = -np.std(d[1])\n        if d[0].shape[0] > 0:\n            mx, my = np.mean(d[0]), np.mean(d[1])\n            s -= np.std([np.sqrt(((x-mx)*(x-mx))+((y-my)*(y-my))) for x,y in zip(d[0],d[1])])\n        d = np.where(bord == 2)\n        s += np.std(d[1])\n        if d[0].shape[0] > 0:\n            mx, my = np.mean(d[0]), np.mean(d[1])\n            s += np.std([np.sqrt(((x-mx)*(x-mx))+((y-my)*(y-my))) for x,y in zip(d[0],d[1])])\n        return s\n    def drop_one(c, b, stack_bord):\n        nonlocal configuration\n        bord = stack_bord.copy()\n        d = np.where(bord[:,c] != 0)[0]\n        p = bord.shape[0] if d.shape[0] == 0 else min(d)\n        if p == 0:\n            return None\n        else:\n            bord[p-1,c] = b\n            return bord\n    def grow_tree(selection, tree, depth, current_bord, b):\n        nonlocal configuration, max_depth\n        if depth >= max_depth:\n            return\n        w = check_win(current_bord)\n        if w != 0:\n            s = np.inf if b == 2 else -np.inf\n        else:\n            s = make_score(current_bord)\n        leaf = {'root':tree,'selection':selection,'bord':current_bord,'score':s,'next':[]}\n        tree['next'].append(leaf)\n        if w != 0:\n            return\n        k = 1 if b==2 else 2\n        for i in range(configuration.columns):\n            t = drop_one(i, b, current_bord)\n            if t is not None:\n                grow_tree(i, leaf, depth+1, t, k)\n    \n    game_tree = {'next':[]}\n    current_bord = np.array(observation['board'], dtype=np.uint8).reshape((6,7))\n    if observation.mark == 2:\n        # Decide that I am 1\n        current_bord[current_bord==2] = 255\n        current_bord[current_bord==1] = 2\n        current_bord[current_bord==255] = 1\n    grow_tree(0, game_tree, 0, current_bord, 1)\n    game_tree = game_tree['next'][0]\n    def minmax(b, tree):\n        nonlocal configuration, max_depth\n        if len(tree['next']) == 0:\n            return tree\n        if b == 2:\n            return sorted(tree['next'], key=lambda x: minmax(1, x)['score'])[0]\n        else:\n            return sorted(tree['next'], key=lambda x: -(minmax(2, x)['score']))[0]\n    r = minmax(1, game_tree)\n    while r['root'] != game_tree:\n        r = r['root']    \n    return r['selection']","d5d1ccee":"env.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([my_agent, \"random\"])\nenv.render(mode=\"ipython\", width=500, height=450)","c9d7da14":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"My Action\", my_action)\n    observation, reward, done, info = trainer.step(my_action)\n    # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","6cbdace9":"def mean_reward(rewards):\n    return sum(r[0] for r in rewards) \/ sum(r[0] + r[1] for r in rewards)\n\n# Run multiple episodes to estimate it's performance.\nprint(\"My Agent vs Random Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"random\"], num_episodes=10)))\nprint(\"My Agent vs Negamax Agent:\", mean_reward(evaluate(\"connectx\", [my_agent, \"negamax\"], num_episodes=10)))\nprint(\"Random Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"random\", my_agent], num_episodes=10)))\nprint(\"Negamax Agent vs My Agent:\", mean_reward(evaluate(\"connectx\", [\"negamax\", my_agent], num_episodes=10)))","a783cbdf":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","8a21598f":"!cat submission.py","d0540b38":"# Test your Agent","349e8b6c":"# Create ConnectX Environment","bc42a392":"# Debug\/Train your Agent","9029139d":"# Write Submission File\n\n","b559c43a":"# Submit to Competition\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https:\/\/kaggle.com\/c\/connectx\/submissions) to view your score and episodes being played.","511059db":"# Evaluate your Agent","f55c2ec3":"# Install kaggle-environments","6c800c59":"# Create an Agent\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy (more may be added later). "}}