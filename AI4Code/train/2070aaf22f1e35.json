{"cell_type":{"01a12ee9":"code","06cfe736":"code","91f06ff8":"code","2516f359":"code","afd01818":"code","034ea79a":"code","b6e06f5b":"code","558cef87":"code","6c37dc24":"code","f3738c79":"code","e3482deb":"code","09875022":"markdown","59575c46":"markdown","53b6f8ea":"markdown","58aec42c":"markdown","bc100ce0":"markdown","cad8b590":"markdown","1f202d09":"markdown"},"source":{"01a12ee9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06cfe736":"training_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntraining_data.head()","91f06ff8":"one_sib_sp = training_data.loc[training_data.SibSp == 1][\"Survived\"]\ntwo_sib_sp = training_data.loc[training_data.SibSp == 2][\"Survived\"]\nthree_sib_sp = training_data.loc[training_data.SibSp == 3][\"Survived\"]\nfour_sib_sp = training_data.loc[training_data.SibSp == 4][\"Survived\"]\n\nprint(\"% of 1 SibSp who survived: \", sum(one_sib_sp)\/len(one_sib_sp))\nprint(\"% of 2 SibSp who survived: \", sum(two_sib_sp)\/len(two_sib_sp))\nprint(\"% of 3 SibSp who survived: \", sum(three_sib_sp)\/len(three_sib_sp))\nprint(\"% of 4 SibSp who survived: \", sum(four_sib_sp)\/len(four_sib_sp))","2516f359":"age = 11\nchildren = training_data.loc[training_data.Age < age][\"Survived\"]\nadults = training_data.loc[training_data.Age >= age][\"Survived\"]\n\nprint(\"% of children who survived: \", sum(children)\/len(children))\nprint(\"% of adults who survived: \", sum(adults)\/len(adults))\n\nmask = (training_data.Age.notnull())\nmean_age = training_data.loc[mask, 'Age'].mean()\n\ntraining_data.loc[training_data.Age.isnull(), 'Age'] = mean_age","afd01818":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","034ea79a":"women = training_data.loc[training_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","b6e06f5b":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\"]\n\nt_y = training_data[\"Survived\"]\nt_X = training_data[features]\n\ntrain_X, val_X, train_y, val_y = train_test_split(t_X, t_y, random_state=1)\n\ntrain_X_D = pd.get_dummies(train_X)\nval_X_D = pd.get_dummies(val_X)","558cef87":"def mae_with_depth(depth):\n    mae_model = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=1)\n    mae_model.fit(train_X_D, train_y)\n    return mean_absolute_error(mae_model.predict(val_X_D), val_y)\n\nprint(\"Max depth of 5, MAE: \", mae_with_depth(5))\nprint(\"Max depth of 3, MAE: \", mae_with_depth(3))\nprint(\"Max depth of 1, MAE: \", mae_with_depth(1))\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=1)\nmodel.fit(train_X_D, train_y)","6c37dc24":"mask = (test_data.Age.notnull())\nmean_age = test_data.loc[mask, 'Age'].mean()\n\ntest_data.loc[test_data.Age.isnull(), 'Age'] = mean_age","f3738c79":"test_X = pd.get_dummies(test_data[features])\n\npredictions = model.predict(test_X)\n\noutput = pd.DataFrame({ 'PassengerId': test_data.PassengerId, 'Survived': predictions })\noutput.head()","e3482deb":"output.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","09875022":"Now we generate our final predictions from the test data.","59575c46":"**Calculating optimal max depth**\n\nUsing a max depth of 5 results in an MAE of about 21%.\n\nThe optimal max depth seems to be 3, with an MAE of about 20%.","53b6f8ea":"We can't remove rows from the test data as per the rules of the competition, so instead we'll replace the null Age values with the mean age across the dataset.","58aec42c":"Finally we save the output to a CSV file.","bc100ce0":"The likelihood of surviving seems to increase as age decreases. The increase begins to be more dramatic at about 11.","cad8b590":"Here we leave out some of the training data to use for **validation**.\n\nWe then create our model and calculate the **mean absolute error**. Closer to 0 is better.","1f202d09":"**SibSp** is the number of siblings\/spouse the passenger had on board with them.\n\nWe can see that having a higher SibSp is inversely proportional to likelihood of surviving. So we'll add SibSp to the list of features used in the model."}}