{"cell_type":{"156e5189":"code","bf99a629":"code","43e27135":"code","be34c9b7":"code","2c8760d9":"code","546b2a17":"code","032e9a46":"code","c364bcd7":"code","5da31009":"code","b50c6083":"code","6e6bc7b9":"code","15c58eed":"code","89295a33":"code","69210896":"code","045fec81":"code","33281d29":"code","536c0539":"code","52fb5206":"code","e1e32a5f":"code","9f70efeb":"code","cc1ee916":"code","8d542aa7":"code","2712b111":"code","62c58061":"code","454dafe8":"code","2aa92e61":"code","a5c6d633":"code","35b17b76":"code","9b56ead1":"code","c46adf36":"code","7b41644a":"code","92210fbc":"code","4f154b21":"code","f7ec929f":"code","09e3ac4c":"code","1d7f05f1":"code","8867b93c":"code","4f81df82":"code","9c9091c5":"code","b3590418":"code","bb973851":"code","eb060c60":"code","09d48dc9":"code","d2ae5352":"code","029e227e":"code","93797e61":"code","5d73db60":"code","e173653b":"code","a65cc1e9":"code","87c12b5b":"code","60321cf5":"code","469cedde":"code","8bb472b9":"code","7413b338":"code","fb67b7f8":"code","723b831e":"code","ec8d2fca":"code","e707ed8e":"code","a5430c41":"code","95d0c7d8":"code","10c740bd":"code","ca6d5420":"code","d18a0522":"code","913bc82e":"code","48d5aa50":"code","9d76db34":"code","27a56fcf":"code","493ced66":"code","bb4fb5b2":"code","a01e30d7":"code","2af0533b":"code","7f37dae8":"markdown","a92b8f5d":"markdown","b8a84251":"markdown","d6e18d7a":"markdown","1487c96b":"markdown","7302057c":"markdown","3faf7f24":"markdown","46a3845a":"markdown","992b7b88":"markdown","ffdce1f0":"markdown","0f1fcb32":"markdown"},"source":{"156e5189":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bf99a629":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime \n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","43e27135":"data = pd.read_csv('..\/input\/analytics-vidya-ltfs-finhack-3\/ltfs3_train.csv')","be34c9b7":"data.shape","2c8760d9":"data['target'] = np.where(data['Top-up Month']=='No Top-up Service', 0, 1)\ndata['target'].value_counts(normalize = True)","546b2a17":"print('Loan frequency')\ndata.groupby(by='Frequency')['target'].agg(['count','mean']).reset_index()\\\n         .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\\\n         .sort_values(by=['Frequency Count'], ascending=False)","032e9a46":"print('Installment Mode')\ndata.groupby(by='InstlmentMode')['target'].agg(['count','mean']).reset_index()\\\n         .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})","c364bcd7":"print('Loan Status')\ndata.groupby(by='LoanStatus')['target'].agg(['count','mean']).reset_index()\\\n         .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})","5da31009":"print('Payment Mode')\ndata.groupby(by='PaymentMode')['target'].agg(['count','mean']).reset_index()\\\n    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\\\n    .sort_values(by=['Frequency Count'], ascending=False)","b50c6083":"print('Branch ID')\ndata.groupby(by='BranchID')['target'].agg(['count','mean']).reset_index()\\\n    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\\\n    .sort_values(by=['Frequency Count'], ascending=False).head(10)","6e6bc7b9":"print('Area')\ndata.groupby(by='Area')['target'].agg(['count','mean']).reset_index()\\\n    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\\\n    .sort_values(by=['Frequency Count'], ascending=False).head(10)","15c58eed":"print('Tenure')\nf, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\nsns.kdeplot(data=data, x='Tenure' ,ax=axes[0], hue='target')\nsns.kdeplot(data=data[data['Tenure']<=100], x='Tenure' ,ax=axes[1], hue='target')\nsns.boxplot(data=data, x='Tenure' ,ax=axes[2]);","89295a33":"print('Asset Cost')\nf, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\nsns.kdeplot(data=data, x='AssetCost' ,ax=axes[0], hue='target')\nsns.kdeplot(data=data[data['AssetCost']<=1000000], x='AssetCost' ,ax=axes[1], hue='target')\nsns.boxplot(data=data, x='AssetCost' ,ax=axes[2]);","69210896":"f, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\nsns.kdeplot(data=data, x='AmountFinance' ,ax=axes[0], hue='target')\nsns.kdeplot(data=data[data['AmountFinance']<=700000], x='AmountFinance' ,ax=axes[1], hue='target')\nsns.boxplot(data=data, x='AmountFinance' ,ax=axes[2]);","045fec81":"f, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\nsns.kdeplot(data=data, x='DisbursalAmount' ,ax=axes[0], hue='target')\nsns.kdeplot(data=data[data['DisbursalAmount']<=700000], x='DisbursalAmount' ,ax=axes[1], hue='target')\nsns.boxplot(data=data, x='DisbursalAmount' ,ax=axes[2]);","33281d29":"f, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\nsns.kdeplot(data=data, x='EMI' ,ax=axes[0], hue='target')\nsns.kdeplot(data=data[data['EMI']<=100000], x='EMI' ,ax=axes[1], hue='target')\nsns.boxplot(data=data, x='EMI' ,ax=axes[2]);","536c0539":"f, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\nsns.kdeplot(data=data, x='AGE' ,ax=axes[0], hue='target')\nsns.boxplot(data=data, x='AGE' ,ax=axes[1]);","52fb5206":"f, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\nsns.kdeplot(data=data, x='LTV' ,ax=axes[0], hue='target')\nsns.boxplot(data=data, x='LTV' ,ax=axes[1]);","e1e32a5f":"f, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\nsns.kdeplot(data=data, x='MonthlyIncome' ,ax=axes[0], hue='target')\nsns.kdeplot(data=data[data['MonthlyIncome']<=50000], x='MonthlyIncome' ,ax=axes[1], hue='target')\nsns.boxplot(data=data, x='MonthlyIncome' ,ax=axes[2]);","9f70efeb":"data.head(3)","cc1ee916":"data.groupby(by='SEX')['target'].agg(['count','mean']).reset_index()\\\n    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\\\n    .sort_values(by=['Frequency Count'], ascending=False)","8d542aa7":"data['target'] = np.where(data['Top-up Month']=='No Top-up Service', 0, 1)\ndata['target'].value_counts(normalize = True)","2712b111":"state = ['HIMACHAL PRADESH','JHARKHAND','UTTARAKHAND','ASSAM','DELHI','CHANDIGARH','TAMIL NADU','DADRA AND NAGAR HAVELI']\npay_mode = ['SI Reject','Auto Debit','Cheque','ECS Reject','Escrow','PDC Reject']\n\ndata['new_state'] = data['State'].map(lambda x:'Other' if x in state else x)\ndata['new_payment_mode'] = data['PaymentMode'].map(lambda x:'Other' if x in state else x)","62c58061":"data['AGE'].fillna(data['AGE'].mean(), inplace=True)\ndata['SEX'].fillna('M', inplace=True)\ndata['MonthlyIncome'].fillna(data['MonthlyIncome'].median(), inplace=True)\ndata['Area'].fillna('NA', inplace=True)\ndata['state_area'] = data['new_state'] + '_' + data['Area']\ndata['ZiPCODE'].fillna('NA', inplace=True)\ndata['DisbursalDate'] = pd.to_datetime(data['DisbursalDate'], errors='coerce')\ndata['MaturityDAte'] = pd.to_datetime(data['MaturityDAte'], errors='coerce')\n\ndata['loan_tenure'] = (data['MaturityDAte'] - data['DisbursalDate'])\/np.timedelta64(1,'M')\n\ndata['loan_tenure'].fillna(data['loan_tenure'].mean(), inplace=True)\nmanu = [2608,2733,3473]\ndata['ManufacturerID'] = data['ManufacturerID'].map(lambda x:99999 if x in manu else x)","454dafe8":"def cat_bin(vec):\n    cnt, res_rate = vec[0], vec[1]\n    if cnt>10:\n        if res_rate <0.07:\n            return 'a'\n        elif res_rate <0.14:\n            return 'b'\n        elif res_rate <0.2:\n            return 'c'\n        elif res_rate <0.3:\n            return 'd'\n        else:\n            return 'e'\n    else:\n        return 'c'","2aa92e61":"ZIPCODE_ratio =  data.groupby(by='ZiPCODE')['target'].agg(['count','mean']).reset_index()\\\n                    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\n\nZIPCODE_ratio['zip_bin'] = ZIPCODE_ratio[['Frequency Count','Top-up Ratio']].apply(cat_bin, axis=1)","a5c6d633":"SupplierID_ratio =  data.groupby(by='SupplierID')['target'].agg(['count','mean']).reset_index()\\\n                    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\n\nSupplierID_ratio['supplier_bin'] = SupplierID_ratio[['Frequency Count','Top-up Ratio']].apply(cat_bin, axis=1)","35b17b76":"branch_ratio =  data.groupby(by='BranchID')['target'].agg(['count','mean']).reset_index()\\\n                    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\n\nbranch_ratio['branch_bin'] = branch_ratio['Top-up Ratio']\\\n                             .map(lambda x: 'Low' if x<=0.14 else ('Moderate' if x<=.2 else 'High'))","9b56ead1":"data = pd.merge(left=data, right=ZIPCODE_ratio[['ZiPCODE','zip_bin']], how = 'left', on='ZiPCODE')\ndata = pd.merge(left=data, right=SupplierID_ratio[['SupplierID','supplier_bin']], how = 'left', on='SupplierID')\ndata = pd.merge(left=data, right=branch_ratio[['BranchID','branch_bin']], how = 'left', on='BranchID')","c46adf36":"data['disbursal_cost'] = data['DisbursalAmount']\/data['AssetCost']\ndata['emi_disbursal'] = data['EMI']\/data['DisbursalAmount']\ndata['emi_income'] = data['EMI']\/(data['MonthlyIncome']+.01)","7b41644a":"data.drop(columns=['City', 'Area', 'Top-up Month', 'State','PaymentMode','DisbursalDate', 'MaturityDAte', \n                   'AuthDate', 'AssetID', 'ZiPCODE', 'SupplierID','BranchID','AmountFinance'], \n          axis=1, inplace=True)","92210fbc":"bureau = pd.read_csv('..\/input\/analytics-vidya-ltfs-finhack-3\/ltfs3_train_bureau.csv')","4f154b21":"bureau.groupby(by='ID')['ACCT-TYPE'].agg(['count']).reset_index()\n\nno_act = bureau[['ID','ACCT-TYPE']].drop_duplicates().groupby(by='ID')['ACCT-TYPE']\\\n                                   .agg(['count']).reset_index().rename(columns={'count':'No_of_trade'})\ndata = pd.merge(left=data, right=no_act, how = 'left', on='ID')\n\ndata.groupby(by='No_of_trade')['target'].agg(['count','mean']).reset_index()\\\n    .rename(columns={'count':'Frequency Count', 'mean':'Top-up Ratio'})\\\n    .sort_values(by=['Frequency Count'], ascending=False)","f7ec929f":"data['No_of_trade'] = data['No_of_trade'].map(lambda x:5 if x >=5 else x)","09e3ac4c":"bureau['DISBURSED-AMT\/HIGH CREDIT'] = bureau['DISBURSED-AMT\/HIGH CREDIT'].str.replace(',', '')\nbureau['CURRENT-BAL'] = bureau['CURRENT-BAL'].str.replace(',', '')","1d7f05f1":"bureau['CURRENT-BAL']= bureau['CURRENT-BAL'].astype(float)","8867b93c":"c_bal = bureau.groupby('ID')[['CURRENT-BAL']].sum().reset_index()\ndata = pd.merge(left=data, right=c_bal, how = 'left', on='ID')","4f81df82":"bureau['Acct_status_combined'] = np.where(bureau['ACCOUNT-STATUS']=='Settled', 'Active', \\\n                                          np.where(bureau['ACCOUNT-STATUS']=='Written Off', 'Closed', \\\n                                                   np.where(bureau['ACCOUNT-STATUS']=='Suit Filed', 'Delinquent',\\\n                                                            np.where(bureau['ACCOUNT-STATUS']=='Restructured', 'Active', \\\n                                                                     np.where(bureau['ACCOUNT-STATUS']=='SUIT FILED (WILFUL DEFAULT)','Delinquent', \\\n                                                                             np.where(bureau['ACCOUNT-STATUS']=='WILFUL DEFAULT', 'Delinquent',\\\n                                                                                      np.where(bureau['ACCOUNT-STATUS']=='Cancelled', 'Closed', \\\n                                                                                               np.where(bureau['ACCOUNT-STATUS']=='Sold\/Purchased', 'Closed', bureau['ACCOUNT-STATUS']))))))))","9c9091c5":"bureau['Acct_status_combined'].value_counts()","b3590418":"table = pd.pivot_table(bureau, values='ACCT-TYPE', index=['ID'],\n                       columns=['Acct_status_combined'], aggfunc='nunique').reset_index()\ndata = pd.merge(left=data, right=table, how = 'left', on='ID')","bb973851":"data.head(1)","eb060c60":"data.fillna(0, inplace=True)","09d48dc9":"data.groupby(by='Active')['target'].agg(['count','mean']).reset_index()","d2ae5352":"data.groupby(by='Closed')['target'].agg(['count','mean']).reset_index()","029e227e":"data['Active'] = data['Active'].map(lambda x:3 if x >=3 else x)\ndata['Closed'] = data['Closed'].map(lambda x:4 if x >=4 else x)\ndata['Delinquent'] = data['Delinquent'].map(lambda x:1 if x >=1 else 0)","93797e61":"data['Active'].value_counts()","5d73db60":"test = pd.read_csv('..\/input\/analytics-vidya-ltfs-finhack-3\/ltfs3_test.csv')\ntest_bureau = pd.read_csv('..\/input\/analytics-vidya-ltfs-finhack-3\/ltfs3_test_bureau.csv')\nprint(test.shape, test_bureau.shape)","e173653b":"def cat_enc(df, col, target):\n    dd = df.groupby(by=col)[target].agg(['mean']).reset_index()\n    return dict(zip(dd.iloc[:,0].values, dd.iloc[:,-1].values))","a65cc1e9":"data.columns","87c12b5b":"Frequency_cat = cat_enc(data, 'Frequency', 'target')\nInstlmentMode_cat = cat_enc(data, 'InstlmentMode', 'target')\nLoanStatus_cat = cat_enc(data, 'LoanStatus', 'target')\nManufacturerID_cat = cat_enc(data, 'ManufacturerID', 'target')\nSEX_cat = cat_enc(data, 'SEX', 'target')\nnew_state_cat = cat_enc(data, 'new_state', 'target')\nnew_payment_mode_cat = cat_enc(data, 'new_payment_mode', 'target')\nstate_area_cat = cat_enc(data, 'state_area', 'target')\nzip_bin_cat = cat_enc(data, 'zip_bin', 'target')\nsupplier_bin_cat = cat_enc(data, 'supplier_bin', 'target')\nbranch_bin_cat = cat_enc(data, 'branch_bin', 'target')","60321cf5":"data['Frequency'] = data['Frequency'].map(Frequency_cat)\ndata['InstlmentMode'] = data['InstlmentMode'].map(InstlmentMode_cat)\ndata['LoanStatus'] = data['LoanStatus'].map(LoanStatus_cat)\ndata['ManufacturerID'] = data['ManufacturerID'].map(ManufacturerID_cat)\ndata['SEX'] = data['SEX'].map(SEX_cat)\ndata['new_state'] = data['new_state'].map(new_state_cat)\ndata['new_payment_mode'] = data['new_payment_mode'].map(new_payment_mode_cat)\ndata['state_area'] = data['state_area'].map(state_area_cat)\ndata['zip_bin'] = data['zip_bin'].map(zip_bin_cat)\ndata['supplier_bin'] = data['supplier_bin'].map(supplier_bin_cat)\ndata['branch_bin'] = data['branch_bin'].map(branch_bin_cat)","469cedde":"Active_cat = cat_enc(data, 'Active', 'target')\nClosed_cat = cat_enc(data, 'Closed', 'target')\n\ndata['Active'] = data['Active'].map(Active_cat)\ndata['Closed'] = data['Closed'].map(Closed_cat)","8bb472b9":"Active_cat","7413b338":"data.isnull().sum()","fb67b7f8":"from sklearn.model_selection import train_test_split","723b831e":"x, y = data.drop(columns=['ID','target'], axis=1).copy(), data['target'].copy()\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","ec8d2fca":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import cross_validate, RandomizedSearchCV\nfrom sklearn.metrics import precision_recall_curve, auc, make_scorer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\n\nfrom sklearn import metrics\nfrom sklearn.metrics import auc,accuracy_score,classification_report,confusion_matrix,f1_score,precision_score,roc_auc_score\nfrom sklearn.metrics import roc_curve,recall_score ","e707ed8e":"lg = LogisticRegression(random_state=0)\nlg.fit(x_train, y_train)\ny_pred = lg.predict(x_test)\nlg_fpr, lg_tpr, lg_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lg_fpr,lg_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","a5430c41":"lg = DecisionTreeClassifier(random_state=0)\nlg.fit(x_train, y_train)\ny_pred = lg.predict(x_test)\nlg_fpr, lg_tpr, lg_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lg_fpr,lg_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","95d0c7d8":"lg = RandomForestClassifier(random_state=0)\nlg.fit(x_train, y_train)\ny_pred = lg.predict(x_test)\nlg_fpr, lg_tpr, lg_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lg_fpr,lg_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","10c740bd":"lg = XGBClassifier(random_state=0)\nlg.fit(x_train, y_train)\ny_pred = lg.predict(x_test)\nlg_fpr, lg_tpr, lg_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lg_fpr,lg_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","ca6d5420":"lg = LGBMClassifier(random_state=0, objective='binary', is_unbalance=True)\nlg.fit(x_train, y_train)\ny_pred = lg.predict(x_test)\nlg_fpr, lg_tpr, lg_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lg_fpr,lg_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","d18a0522":"lgbm = LGBMClassifier(random_state=0, n_jobs=-1, boosting='gbdt', objective='binary', is_unbalance=True)\nparams = {'learning_rate': [0.01, .02, 0.05],\n          'max_depth': [5, 6, 7, 8],\n          'num_leaves':[32, 64, 128, 256],\n          'feature_fraction':[.35, .5, .65],\n          'sample_pos_weight':[.05, .1, .2, .3, ],\n          'n_estimators': [350, 400, 500, 550],\n          'lambda_l1':[1, 3, 9, 19,],\n          'min_data_in_leaf': [15, 20, 50, 100]}\n\ngrid = RandomizedSearchCV(lgbm, params, scoring='f1', cv=5, return_train_score=True )\ngrid.fit(x_train, y_train)\n\nprint('Best Params', grid.best_params_)\nprint('Best score', grid.best_score_)\n\ntuned_lgbm = LGBMClassifier(random_state=0, n_jobs=-1, boosting='gbdt', objective='binary', is_unbalance=True,\n                                learning_rate =grid.best_params_['learning_rate'],\n                                max_depth =grid.best_params_['max_depth'],\n                                num_leaves = grid.best_params_['num_leaves'],\n                                feature_fraction = grid.best_params_['feature_fraction'],\n                                sample_pos_weight = grid.best_params_['sample_pos_weight'],\n                                lambda_l1 = grid.best_params_['lambda_l1'],\n                                n_estimators =grid.best_params_['n_estimators'],\n                                min_data_in_leaf =grid.best_params_['min_data_in_leaf'])\n\ntuned_lgbm.fit(x_train, y_train)\ny_pred = tuned_lgbm.predict(x_test)\nlgb_fpr, lgb_tpr, lgb_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lgb_fpr,lgb_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","913bc82e":"tuned_lgbm = LGBMClassifier(random_state=0, n_jobs=-1, objective='binary', is_unbalance=True,\n                            learning_rate =  0.07, max_depth = 7, num_leaves = 128,  n_estimators = 350)\n\ntuned_lgbm.fit(x_train, y_train)\ny_pred = tuned_lgbm.predict(x_test)\nlgb_fpr, lgb_tpr, lgb_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lgb_fpr,lgb_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","48d5aa50":"ax = lgb.plot_importance(tuned_lgbm, max_num_features=50, figsize=(15,15))\nplt.show()","9d76db34":"plt.figure()\nplt.plot(lgb_fpr, lgb_tpr, label='Light GBM (area = %0.2f)' % accuracy_score(y_test, y_pred))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","27a56fcf":"x_train.columns","493ced66":"cols = ['InstlmentMode', 'SEX', 'branch_bin', 'Delinquent', 'Frequency', 'LoanStatus']\nx_train.drop(columns=cols, axis=1, inplace=True)\nx_test.drop(columns=cols, axis=1, inplace=True)","bb4fb5b2":"tuned_lgbm = LGBMClassifier(random_state=0, n_jobs=-1, objective='binary', is_unbalance=True,\n                            learning_rate =  0.07, max_depth = 7, num_leaves = 128,  n_estimators = 350)\n\ntuned_lgbm.fit(x_train, y_train)\ny_pred = tuned_lgbm.predict(x_test)\nlgb_fpr, lgb_tpr, lgb_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lgb_fpr,lgb_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))","a01e30d7":"plt.figure()\nplt.plot(lgb_fpr, lgb_tpr, label='Light GBM (area = %0.2f)' % accuracy_score(y_test, y_pred))\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\nimport shap\n\nshap.initjs()\nexplainer = shap.Explainer(tuned_lgbm, x_test)\nshap_values = explainer(x_test, check_additivity=False)\n\nshap.plots.bar(shap_values)\n\nshap.plots.beeswarm(shap_values)\n\nshap.plots.waterfall(shap_values[0])","2af0533b":"shap.plots.scatter(shap_values[:,'CURRENT-BAL'], color=shap_values)\n\nshap.plots.scatter(shap_values[:,'loan_tenure'], color=shap_values)\n\nshap.plots.scatter(shap_values[:,'MonthlyIncome'], color=shap_values)\n\nshap.plots.scatter(shap_values[:,'AGE'], color=shap_values)\n\n# Over Sampling\n\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=0, n_jobs=-1)\nx_res, y_res = smote.fit_resample(x_train, y_train)\n\ntuned_lgbm = LGBMClassifier(random_state=0, n_jobs=-1, objective='binary', is_unbalance=True,\n                            learning_rate =  0.05, max_depth = 7, num_leaves = 128,  n_estimators = 400)\n\ntuned_lgbm.fit(x_res, y_res)\ny_pred = tuned_lgbm.predict(x_test)\nlgb_fpr, lgb_tpr, lgb_thresholds = roc_curve(y_test, y_pred)\n\nprint('Accuracy : ',accuracy_score(y_test, y_pred))\nprint('Precision : ',precision_score(y_test, y_pred))\nprint('Recall : ',recall_score(y_test, y_pred))    \nprint('ROC_AUC :',auc(lgb_fpr,lgb_tpr))\nprint('F1 :',f1_score(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n","7f37dae8":"## Bureau Data","a92b8f5d":"### We create bins for some of the categories liek Zip Code etc","b8a84251":"### Analysing how different parameters look like across the different classes","d6e18d7a":"## Categorical data Encoding","1487c96b":"# Transforming Test Data","7302057c":"# EDA","3faf7f24":"## Checking for Class Imbalance","46a3845a":"### Logistic regression","992b7b88":"# Feature Engineering","ffdce1f0":"## Model training","0f1fcb32":"### We club together different categories where the no. of loans are less"}}