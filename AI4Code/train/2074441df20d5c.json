{"cell_type":{"108a47f5":"code","667c206c":"code","c95663ac":"code","22e13a86":"code","54234cb8":"code","25c5102c":"code","d7df726b":"code","07ca3467":"code","eb4002f2":"code","885e686b":"code","bc25364d":"code","a0ca8a7d":"code","2e259f61":"code","8a445e84":"code","1bd84348":"code","c68685ec":"code","6d57308d":"code","fa94f077":"code","79f30dc9":"code","8f87cd4c":"code","2f15c4f0":"code","e13cc613":"code","ba223c07":"code","aa7428ef":"markdown","011d1ad0":"markdown","9e2bd78d":"markdown","ea257178":"markdown","1fdaec14":"markdown","99235b6e":"markdown","cd843258":"markdown","c929b543":"markdown","17b0695c":"markdown","68abf8df":"markdown","3edb0b91":"markdown","b1324f48":"markdown","591599d0":"markdown","6441b3ee":"markdown","64f3c040":"markdown","0434f203":"markdown","74bfbbfa":"markdown","777200cc":"markdown"},"source":{"108a47f5":"import numpy as np\nfrom numpy import random\nfrom numpy import vstack\nimport pandas as pd\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom numpy import expand_dims","667c206c":"from keras import backend\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam\nfrom keras.optimizers import RMSprop\nfrom keras.layers import BatchNormalization\nfrom keras.initializers import RandomNormal\nfrom keras.constraints import Constraint\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import load_model","c95663ac":"train_df = pd.read_csv('..\/input\/train.csv')\ntrain_df_7 = train_df[train_df['label']==7]\nX = train_df_7.drop(['label'], axis=1).values\nX = (X - 127.5) \/ 127.5 # scale from [0,255] to [-1,1]\nprint(X.shape)","22e13a86":"# reshape flattened data into tensors\nn_x = 28     # size of image n_x by n_x\nn_c = 1      # number of channels\nX = X.reshape((-1, n_x, n_x, n_c))\nprint(X.shape)","54234cb8":"# pick some random digits from the dataset X and look at them\nplt.figure(figsize=(10,6))\nn_digits = 60\nselect = random.randint(low=0,high=X.shape[0],size=n_digits)\nfor i, index in enumerate(select):  \n    plt.subplot(5, 12, i+1)\n    plt.imshow(X[index].reshape((28, 28)), cmap=plt.cm.binary)\n    plt.axis('off')\nplt.subplots_adjust(wspace=0.3, hspace=-0.1)\nplt.show()","25c5102c":"class ClipConstraint(Constraint):\n    \"\"\"\n    clip model weights to a given hypercube\n    \"\"\"\n    def __init__(self, clip_value):\n        self.clip_value = clip_value\n    def __call__(self, weights):\n        return backend.clip(weights, -self.clip_value, self.clip_value)\n    def get_config(self):\n        return {'clip_value': self.clip_value}","d7df726b":"def wasserstein_loss(y_true, y_pred):\n    \"\"\"\n    Wasserstein loss function\n    \"\"\"\n    return backend.mean(y_true * y_pred)","07ca3467":"def define_critic(in_shape=(n_x,n_x,n_c)):\n    \"\"\"\n    Define the conv net for the critic\n    \"\"\"\n    init = RandomNormal(stddev=0.02)    # weight initialization\n    const = ClipConstraint(0.01)    # weight constraint\n    model = Sequential()\n    model.add(Conv2D(64,kernel_size=4,strides=2,padding='same',kernel_initializer=init,kernel_constraint=const,input_shape=in_shape))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(64,kernel_size=4,strides=2,padding='same',kernel_initializer=init,kernel_constraint=const))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Flatten())\n    model.add(Dense(1,activation='linear'))\n    opt = RMSprop(lr=0.00005)    # define optimizer\n    model.compile(loss=wasserstein_loss,optimizer=opt)\n    return model","eb4002f2":"critic = define_critic()\ncritic.summary()","885e686b":"def generate_real_samples(data, n_samples):\n    \"\"\"\n    Pick 'n_samples' randomly from 'data'\n    \"\"\"\n    idx = random.randint(low=0,high=data.shape[0],size=n_samples)\n    X = data[idx]\n    Y = -np.ones((n_samples,1))\n    return X, Y","bc25364d":"def define_generator(latent_dim):\n    \"\"\"\n    Define the conv net for the generator\n    \"\"\"\n    init = RandomNormal(stddev=0.02)    # weight initialization\n    n_nodes = 128*7*7\n    model = Sequential()\n    model.add(Dense(n_nodes,kernel_initializer=init,input_dim=latent_dim)) # foundation for 7*7 image\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((7,7,128)))\n    model.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same')) # up-sample to 14*14 image\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2DTranspose(128,kernel_size=4,strides=2,padding='same',kernel_initializer=init)) # up-sample to 28*28 image\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(1,kernel_size=7,activation='tanh',padding='same',kernel_initializer=init))\n    return model","a0ca8a7d":"latent_dim = 100 # define size of latent space\ngenerator = define_generator(latent_dim)\ngenerator.summary()","2e259f61":"def generate_latent_points(latent_dim, n_samples):\n    \"\"\"\n    This generates points in the latent space as input for the generator\n    \"\"\"\n    x_input = random.randn(latent_dim * n_samples)\n    x_input = x_input.reshape(n_samples, latent_dim)     # reshape into a batch of inputs for the network\n    return x_input","8a445e84":"def generate_fake_samples(g_model, latent_dim, n_samples):\n    \"\"\"\n    Generate 'n_samples' of fake samples from the generator\n    \"\"\"\n    X_input = generate_latent_points(latent_dim, n_samples)\n    X = g_model.predict(X_input)    # generator predicts output\n    Y = np.ones((n_samples,1))     # create class labels '1' for fake sample\n    return X, Y","1bd84348":"def define_gan(g_model, c_model):\n    \"\"\"\n    This takes as arguments the generator and critic and creates the GAN subsuming these two models. \n    The weights in the critic are marked as not trainable, \n    which only affects the weights as seen by the GAN and not the standalone discriminator model.\n    \"\"\"\n    c_model.trainable = False     # make weights in the critic not trainable\n    model = Sequential()\n    model.add(g_model)\n    model.add(c_model)\n    opt = RMSprop(lr=0.00005)\n    model.compile(loss=wasserstein_loss, optimizer=opt)\n    return model","c68685ec":"gan = define_gan(generator, critic)\ngan.summary()","6d57308d":"def save_plot(examples, step, n=10):\n    \"\"\"\n    This creates and save a plot of generated images\n    \"\"\"\n    for i in range(n * n):\n        plt.subplot(n, n, 1 + i)\n        plt.axis('off')\n        plt.imshow(examples[i, :, :, 0], cmap=plt.cm.binary)\n    filename = 'generated_plot_e%04d.png' % (step+1)\n    plt.savefig(filename)\n    plt.close()","fa94f077":"def summarize_performance(step, g_model, latent_dim, n_samples=100):\n    \"\"\"\n    This plots generated images, save generator model\n    \"\"\"\n    X_fake, Y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n    X_fake = (X_fake+1)\/2.0\n    save_plot(X_fake, step)\n    filename = 'generator_model_%04d.h5' % (step+1)\n    g_model.save(filename)","79f30dc9":"def train(g_model, c_model, gan_model, data, latent_dim, n_epochs=100, batch_size=64, n_critic=5):\n    \"\"\"\n    This trains the combined generator and critic models in the GAN\n    \"\"\"\n    batch_per_epoch = data.shape[0] \/\/ batch_size\n    n_steps = batch_per_epoch * n_epochs\n    half_batch = batch_size \/\/ 2\n    for i in range(n_steps):\n        for j in range(n_critic):\n            X_real, Y_real = generate_real_samples(data, half_batch)   # randomly select real samples\n            c_loss1 = c_model.train_on_batch(X_real, Y_real)\n            X_fake, Y_fake = generate_fake_samples(g_model, latent_dim, half_batch)   # generate fake samples\n            c_loss2 = c_model.train_on_batch(X_fake, Y_fake)\n        X_gan = generate_latent_points(latent_dim, batch_size)   # as input for generator\n        Y_gan = -np.ones((batch_size, 1))\n        g_loss = gan_model.train_on_batch(X_gan, Y_gan)   # update generator via the discriminator's error\n        print('>%d, c1=%.3f, c2=%.3f, g=%.3f' % (i+1, c_loss1, c_loss2, g_loss)) # summarize loss for batch        \n        # evaluate the model performance, after some epochs\n        if (i+1) % batch_per_epoch == 0: \n            summarize_performance(i, g_model, latent_dim)","8f87cd4c":"latent_dim = 50\nc_model = define_critic()\ng_model = define_generator(latent_dim)\ngan_model = define_gan(g_model, c_model)\ndata = X\ntrain(g_model, c_model, gan_model, data, latent_dim)","2f15c4f0":"img = Image.open('generated_plot_e6800.png')\nplt.figure(figsize = (10,10))\nplt.imshow(img)","e13cc613":"def show_plot(examples, n):\n    \"\"\"\n    This shows the plots from the GAN\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    for i in range(n * n):\n        plt.subplot(n, n, 1 + i)\n        plt.axis('off')\n        plt.imshow(examples[i, :, :, 0], cmap=plt.cm.binary)\n    plt.show()","ba223c07":"latent_points = generate_latent_points(50, 64)\nnew_digits = g_model.predict(latent_points)\nshow_plot(new_digits, 8)","aa7428ef":"# Train the GAN","011d1ad0":"# Using the final Generator model to generate images","9e2bd78d":"### Training of the Critic","ea257178":"The Generator creates new, fake but plausible images. It works by taking a point from a latent space as input and output an image.\n\n**Inputs:** Point in latent space, e.g. a 100-element vector of Gaussian random numbers.\n\n**Outputs:** 2D image of 28x28 pixels with pixel values in [-1, 1].","1fdaec14":"The generation of each image requires a point in the latent space as input.","99235b6e":"# Introduction","cd843258":"All \"digit\" samples will be labelled '-1' (real). Need to create fake samples labelled as '1'. The fake samples will be created by the Generator. The real and fake samples will be fed into the Critic by batches.","c929b543":"# The Critic","17b0695c":"### Define the Critic","68abf8df":"Using WGAN to generate handwritten digits (see tutorials in [Reference 1][1] & [Reference 2][2].) \n\n[1]: https:\/\/machinelearningmastery.com\/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras\/\n[2]: https:\/\/machinelearningmastery.com\/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch\/","3edb0b91":"# Combining the Discriminator & Generator as a GAN","b1324f48":"# Functions to evaluate performance of GAN","591599d0":"# The Generator","6441b3ee":"### Wasserstein loss","64f3c040":"The critic takes a sample \"digit\" from our dataset and says how real or fake it is.\n\n**Inputs:** \"digit\" 28x28 pixels in size; one channel.\n\n**Outputs:** linear regression, degree the sample is real.","0434f203":"### Critic weight clipping","74bfbbfa":"Started on 5 July 2019\n\n**References:**\n1. https:\/\/machinelearningmastery.com\/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras\/\n2. https:\/\/machinelearningmastery.com\/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch\/\n3. https:\/\/www.kaggle.com\/rhodiumbeng\/digit-recognizer-convolutional-neural-network","777200cc":"# Load & prepare MNIST digit dataset"}}