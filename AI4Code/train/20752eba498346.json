{"cell_type":{"29453a1b":"code","e635046b":"code","9d7f11d0":"code","58d25e6c":"code","c58ae704":"code","2087a2af":"code","e809643b":"code","f3872dbf":"code","dd802aa6":"code","2aa7d75d":"code","e51f0879":"code","8fb0f28c":"code","c9295942":"code","6dba572d":"code","6245c48d":"code","39bc75fc":"code","b8ef268a":"code","ccf3d42c":"code","89ef2794":"code","41c2080d":"code","6673aa82":"code","a04d7805":"code","58024b75":"code","431ab4a0":"code","fefe2c1e":"code","c10f9eb0":"code","ed08f94e":"code","5b6f875d":"code","344a5d36":"code","56d82524":"code","28bd2f1d":"code","d9c01a80":"code","38920dbc":"code","3d33d28b":"code","574282ab":"code","262762d7":"code","98077c49":"code","09838893":"code","b1cbbe2e":"code","9ce20cec":"code","0413b9ce":"code","6d75e171":"code","38edb68c":"code","25233392":"code","8f17903f":"code","1fc6862b":"code","22c82a13":"code","5b12846a":"code","f79769e1":"code","a9fc5e9d":"code","439b66c5":"code","d996389d":"code","4e2c3315":"code","30e2ccb2":"code","279205f5":"code","7dba7162":"code","589efa84":"code","62f2d9eb":"code","04278ed6":"code","429929b6":"markdown","e704617e":"markdown","5342f99b":"markdown","fe051b0c":"markdown","c89a8c47":"markdown","e01fe52d":"markdown","62216b09":"markdown","8e564353":"markdown","6cdd9762":"markdown","c409b2fa":"markdown","7fed33c0":"markdown","3e069301":"markdown","3122b3a1":"markdown","8c6139bf":"markdown","ddcf5844":"markdown","c7f2cbee":"markdown","9d9bd7cc":"markdown","f1bd9da5":"markdown"},"source":{"29453a1b":"# Importing Libraries\n\nimport pandas as pd","e635046b":"# To view all columns\npd.set_option('max_columns', None)\n\n# Reading Data\nData = pd.read_csv('..\/input\/melbourne-housing-market\/Melbourne_housing_FULL.csv')\nData.head()","9d7f11d0":"# Analysing all categorical and numerical data\nData.info()","58d25e6c":"# Analysing Numerical data only\n\nData.describe()","c58ae704":"# Shortcut to get numerical columns \n\nData.describe().columns","2087a2af":"# Counts of missing Values in each columns\nData.isnull().sum()","e809643b":"# Percentage of Missings in each columns\nData.isnull().sum()\/len(Data)*100","f3872dbf":"# Getting list of columns with missing values \ncols_with_missing = [col for col in Data.columns \n                    if Data[col].isnull().any()\n                    ]\ncols_with_missing","dd802aa6":"# Dropping Clounms with missing values\n# reduced_Data = Data.drop(cols_with_missing, axis=1)\n\n# Dropping Rows with missing values\n# reduced_Data = Data.drop(cols_with_missing, axis=0)","2aa7d75d":"from sklearn.impute import SimpleImputer\nData_imputer = SimpleImputer(strategy='most_frequent')","e51f0879":"imputed_Data = pd.DataFrame(Data_imputer.fit_transform(Data))","8fb0f28c":"# Imputation renoved column names so puting them back\nimputed_Data.columns = Data.columns","c9295942":"# Checking for missing values in the Data.\nimputed_Data.isnull().sum()","6dba572d":"imputed_Data.info()","6245c48d":"# As we can see above all columns is of object type, so befor moving ahead i should fix it.\n# Next line of code will help to get all columns so that we can classify the dtype of columns \n\npd.set_option('max_columns', None)\nimputed_Data.head()","39bc75fc":"# Converting the dtypes of columns into right dtypes\n#Converting into Categorical dtypes\ncat_col = ['Suburb', 'Address', 'Type', 'Method', 'SellerG', 'CouncilArea','Regionname']\nfor colname in cat_col:\n    imputed_Data[colname] = imputed_Data[colname].astype('object') \n\n#Converting into Numerical dtypes\nint_col = ['Rooms', 'Price', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea',\n           'YearBuilt', 'Propertycount']\nflt_col = ['Distance', 'Lattitude', 'Longtitude']\nfor colname in int_col:\n    imputed_Data[colname] = imputed_Data[colname].astype('int64')\nfor colname in flt_col:\n    imputed_Data[colname] = imputed_Data[colname].astype('float64')   \n\n# Converting to date object\nimputed_Data['Date'] = pd.to_datetime(imputed_Data['Date'])","b8ef268a":"# Rechecking the dtypes\nimputed_Data.info()","ccf3d42c":"# As we are done with Missing values and dtypes so we can move next which is Outliers\n# For this I'm going to use Univariate and Bivariate analysis.","89ef2794":"pd.set_option('display.max_columns', None)\nimputed_Data.head()","41c2080d":"num_col = imputed_Data.select_dtypes(exclude=['object', 'datetime64[ns]'])\nnum_col","6673aa82":"# Ploting Box Plot for each numerical columns\nimport matplotlib.pyplot as plt\nfor i in num_col:\n    plt.hist(num_col[i])\n    plt.title(i)\n    plt.show()","a04d7805":"# Defining a function to get the Ranges\ndef minmax(val_list):\n    min_val = min(val_list)\n    max_val = max(val_list)\n\n    return (min_val, max_val)\nprint('The Range of Number of Room ',minmax(imputed_Data['Rooms']))\nprint('The Range of Price ',minmax(imputed_Data['Price']))\nprint('The Range of Distance ',minmax(imputed_Data['Distance']))\nprint('The Range of Landsize ',minmax(imputed_Data['Landsize']))\nprint('The Range of YearBuilt ',minmax(imputed_Data['YearBuilt']))\n","58024b75":"# Getting entries for building having more than 4 and 10 rooms\nimputed_Data[imputed_Data['Rooms']>4].head()","431ab4a0":"pd.set_option('display.max_columns', None)\nimputed_Data[imputed_Data['Rooms']>10].head()","fefe2c1e":"# As we can see from previous two cells, its not possible to build more than 6 rooms within 120Sq.Mtr (~1200Sq.Mtr).\n# So it might be wrong entry. Hence we can drop those entries (Rows) as its only few Rows (Entries).\ncleaned_Data_R = imputed_Data[imputed_Data['Rooms']<=8]","c10f9eb0":"cleaned_Data_R.shape","ed08f94e":"# Now we are left with entries with only less than 8 rooms\nprint('The Range of Number of Room ',minmax(cleaned_Data_R['Rooms']))","5b6f875d":"# Analysing Bathroom\nprint('The Range of Bathroom ',minmax(imputed_Data['Bathroom']))\nprint(imputed_Data[imputed_Data['Bathroom']==0].shape)\nimputed_Data[imputed_Data['Bathroom']==0]","344a5d36":"# Previous cell shows that 46 houses does not have Bathroom but the Price of that rooms is high.\n# So we can drop that too\ncleaned_Data_R_B = cleaned_Data_R[cleaned_Data_R['Bathroom']>0]","56d82524":"cleaned_Data_R_B.shape","28bd2f1d":"# Again, Building Area cannot be 0, if it is, then Price for that Building cannot be in thousands of Australian dollars\n# So just remove it\ncleaned_Data_R_B_A = cleaned_Data_R_B[cleaned_Data_R_B['BuildingArea']>0]","d9c01a80":"# Analysing BuildingArea\nprint('The Range of Landsize ',minmax(cleaned_Data_R_B_A['Landsize']))\nprint(cleaned_Data_R_B_A[cleaned_Data_R_B_A['Landsize']<=50].shape)\ncleaned_Data_R_B_A[cleaned_Data_R_B_A['Landsize']<50]","38920dbc":"# Analysing BuildingArea\nprint('The Range of BuildingArea ',minmax(imputed_Data['BuildingArea']))\nprint('Shape of BbildingArea is ',cleaned_Data_R_B[cleaned_Data_R_B['BuildingArea']==0].shape)\ncleaned_Data_R_B[cleaned_Data_R_B['BuildingArea']==0]","3d33d28b":"cleaned_Data_R_B_A","574282ab":"# Now try to find is there any which not justify with BuildingArea\ncleaned_Data_R_B_A[cleaned_Data_R_B_A['BuildingArea']<50]","262762d7":"# Its not Possible to cunstruct 3 rooms in 3 Sq.Mtr Area.....And so on\n# So I'm going to move forward with Area more than 50Sq.Mtr only\ncleaned_Data_R_B_BA = cleaned_Data_R_B_A[cleaned_Data_R_B_A['BuildingArea']>50]","98077c49":"# Analysing Landsize\nprint('The Range of Landsize ',minmax(imputed_Data['Landsize']))\nprint('The Range of BuildingArea ',minmax(imputed_Data['BuildingArea']))\n\ncleaned_Data_R_B_BA[['Landsize','BuildingArea', 'Price','Rooms']].head(20)","09838893":"# As we can see in previous cell The Range of Landsize has a wide range (0, 433014). \n#So I'm trying to get only genuine size of land for the BuildingArea\n\ncleaned_Data_R_B_BA_L = cleaned_Data_R_B_BA[cleaned_Data_R_B_BA['Landsize']>50]\ncleaned_Data_R_B_BA_L.head()","b1cbbe2e":"# Still data has something which is not acceptable, for instance index 5 has Landsize=94 and BuildingArea is 120 which seems impossible.\n# Hence, selecting only those data which has Landsize more than or equal to BuildingArea\n\ncleaned_Data_R_B_BA_LS = cleaned_Data_R_B_BA[cleaned_Data_R_B_BA['Landsize'] >= cleaned_Data_R_B_BA['BuildingArea']]\nprint(cleaned_Data_R_B_BA_LS.shape)\ncleaned_Data_R_B_BA_LS.head()","9ce20cec":"# Now I thing we have almost a good Data to move further \ncleaned_Data_R_B_BA_LS.info()","0413b9ce":"# Ploting Box Plot for each numerical columns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfor i in cleaned_Data_R_B_BA_LS.select_dtypes(exclude=['object','datetime64[ns]']):\n    plt.hist(num_col[i])\n    plt.title(i)\n    plt.show()","6d75e171":"# Copying the cleaned to avoid loosing Data\ncleaned_Data = cleaned_Data_R_B_BA_LS.copy()","38edb68c":"cleaned_Data.head()","25233392":"# Here, I want to add one column which will show the Age of the building,\n# as Age of the building is one of the most considering factor for Price of building \ncleaned_Data['Age'] = 2020 - cleaned_Data['YearBuilt']\ncleaned_Data.head()","8f17903f":"# The easiest approach to dealing with categorical variables is to simply remove them from the dataset. \n# But this approach will only work well if the columns did not contain useful information.\n# therefore I'm gonna use Categorical columns as well for modeling, So....\n# I'm going to choose those Columns which has less Cardinality.\n\nlow_Cardi_cols = [ccol for ccol in cleaned_Data.columns \n                  if cleaned_Data[ccol].nunique() < 10 \n                 and cleaned_Data[ccol].dtype == 'object']\nprint('So I got only 3 columns which is ', low_Cardi_cols)","1fc6862b":"cols = ['Type', 'Method', 'Regionname']","22c82a13":"'''\nFor this excersice I'll use One-hot encoding which creates new columns indicating \nthe presence (or absence) of each possible value in the original data.\nOne-hot encoding generally does not perform well if the categorical variable takes \non a large number of values (i.e., you generally won't use it for variables taking more than 15 different values).\n'''\n\nfrom sklearn.preprocessing import OneHotEncoder\nOHE = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOHE_Data = pd.DataFrame(OHE.fit_transform(cleaned_Data[cols]))","5b12846a":"# OneHotEncoder removed index so put them back\nOHE_Data.index = cleaned_Data.index","f79769e1":"# Remove categorical columns\nOHE_num = cleaned_Data.drop(cols, axis=1)","a9fc5e9d":"# Add OHE columns to numerical feature\nOHE_Cleaned_Data = pd.concat([OHE_num, OHE_Data], axis=1)\nOHE_Cleaned_Data.head()","439b66c5":"# Now Its time to choose those columns which will help me to make a accurate model\nSelected_Col_Data = OHE_Cleaned_Data.drop(['Suburb', 'Address', 'Price', 'SellerG', 'Date', \n                                           'Postcode', 'YearBuilt', 'CouncilArea','Lattitude', 'Longtitude', 'Propertycount'],\n                                          axis=1)","d996389d":"print('Shape of the Data is ', Selected_Col_Data.shape)\nSelected_Col_Data.head()","4e2c3315":"# Now I'm ready to use this Data for Modeling","30e2ccb2":"# Splitting data into Train and Test data\nfrom sklearn.model_selection import train_test_split\n\nX = Selected_Col_Data.copy()\ny = OHE_Cleaned_Data.Price\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","279205f5":"print('training data and validating data has shape of ', X.shape, \"and\", y.shape, 'respectively')","7dba7162":"# Imporrting Gradient Boosting (Regressor)\nfrom xgboost import XGBRegressor\n\n# Defining Regressor\nmy_model = XGBRegressor(n_estimators=500,\n                        learning_rate=0.05,\n                        n_jobs=2)\n# Fitting Model\nmy_model.fit(X_train, y_train, early_stopping_rounds=5,\n             eval_set=[(X_valid, y_valid)], \n             verbose=False)","589efa84":"# Predicting and Validating  Model\nfrom sklearn.metrics import mean_absolute_error\nmy_preds = my_model.predict(X_valid)\nprint('Mean Absolute Value for this Prediction is ', mean_absolute_error(y_valid, my_preds))","62f2d9eb":"# Setting Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nmy_pipeline = Pipeline(steps=[\n    ('preprocessor', SimpleImputer()),\n    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n])","04278ed6":"# Cross Validation\nfrom sklearn.model_selection import cross_val_score\n \nscore = -1 * cross_val_score(my_pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\nprint('Mean Absolute Score for this Prediction is ', score)\nprint(score.mean())","429929b6":"# Removing Outliers","e704617e":"Unless most values in the dropped columns are missing, the model loses access to a lot of (potentially useful!) information with this approach. So,\nI'm not going to drop any columns or any rows as it can make worse to my model's accuracy. \n\n\nOn other hand, Imputation fills in the missing values with some number. For instance, we can fill in the mean value along each column.\n","5342f99b":"### Univariate Analysis","fe051b0c":"### Using Extreme Gradient Boosting","c89a8c47":"Hello Kagglers,\n>My name is **Muqesh** and this is my very first model that i created. Hope you will support my work. If there is any other method to enhance my model then you are most welcome.","e01fe52d":"### Some Key Details\nSuburb: Suburb\n\nAddress: Address\n\nRooms: Number of rooms\n\nPrice: Price in Australian dollars\n\n### Method:\nS - property sold;\n\nSP - property sold prior;\n\nPI - property passed in;\n\nPN - sold prior not disclosed;\n\nSN - sold not disclosed;\n\nNB - no bid;\n\nVB - vendor bid;\n\nW - withdrawn prior to auction;\n\nSA - sold after auction;\n\nSS - sold after auction price not disclosed.\n\nN\/A - price or highest bid not available.\n\n### Type:\nbr - bedroom(s);\n\nh - house,cottage,villa, semi,terrace;\n\nu - unit, duplex;\n\nt - townhouse;\n\ndev site - development site;\n\no res - other residential.\n\n### Description\nSellerG: Real Estate Agent\n\nDate: Date sold\n\nDistance: Distance from CBD in Kilometres\n\nRegionname: General Region (West, North West, North, North east \u2026etc)\n\nPropertycount: Number of properties that exist in the suburb.\n\nBedroom2 : Scraped # of Bedrooms (from different source)\n\nBathroom: Number of Bathrooms\n\nCar: Number of carspots\n\nLandsize: Land Size in Metres\n\nBuildingArea: Building Size in Metres\n\nYearBuilt: Year the house was built\n\nCouncilArea: Governing council for the area\n\nLattitude: Self explanitory\n\nLongtitude: Self explanitory","62216b09":"# Modeling","8e564353":"From above, we can see that there are so many Missing values. We can observe the categorical (object) and numerical columns seperately.","6cdd9762":"# Feature Engineering ","c409b2fa":"Similarly in case of 'Price' columns, we can see that Prices is fluctuating so much for Number of Rooms. Some time 3 & 4 Room's cost is almost eqal to 2 Room's Prices.\n","7fed33c0":"# Feature Selection","3e069301":"# Understanding the Data","3122b3a1":"### Dealing with Missing Values","8c6139bf":"# Removing Missing Values","ddcf5844":"# Before Start","c7f2cbee":"### Checking for dtypes","9d9bd7cc":"Before starting the modeling and other stuff we should analyse the data, and prepare some question and their answer related to the data. For instance, in this data so many abbreviation are used which must be known before start.","f1bd9da5":"### Cross Validation"}}