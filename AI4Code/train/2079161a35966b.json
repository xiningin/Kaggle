{"cell_type":{"0362cd4a":"code","7945994c":"code","ce2e16c1":"code","4138f86f":"code","88db997b":"code","7291d1a5":"code","c389bd90":"code","dc58e2d0":"code","2543b01d":"code","2103faa1":"code","730daadd":"code","0350054f":"code","ded0deaa":"code","b33c90a8":"code","8740e978":"code","85ca4971":"code","4bc1fce2":"code","3c5ca3ab":"code","28a5437b":"code","3298a805":"code","58e75989":"markdown","ca47c7fa":"markdown","cfb060c2":"markdown"},"source":{"0362cd4a":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nimport sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.stem.snowball import SnowballStemmer\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom sklearn.cluster import KMeans","7945994c":"if torch.cuda.is_available():\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')\nprint(device)","ce2e16c1":"# \u0421\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445","4138f86f":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntrain_df = pd.DataFrame(train)\ncopy_train = train_df.copy()\ntrain_df.head()","88db997b":"train_df['label_group'].shape","7291d1a5":"test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\ntest_df = pd.DataFrame(test)\ntest_df.head()","c389bd90":"#32412\npics_train = 34250\npics_test = 3\nsize = 28\ntrain_images = np.empty(shape=(pics_train, size ** 2))\ntest_images = np.empty(shape=(pics_test, size ** 2))\nprint(train_images.shape, test_images.shape)","dc58e2d0":"names = train_df['image']\ndirname = '..\/input\/shopee-product-matching\/train_images\/'\nprint(len(names))\nfor i in range(len(names)):\n    img = cv2.resize(cv2.cvtColor(cv2.imread(os.path.join(dirname, names[i])), cv2.COLOR_BGR2GRAY) \/ 255., (size, size)).flatten()\n    print(os.path.join(dirname, names[i]), img.shape)\n    train_images[i] = img","2543b01d":"'''train_images = np.unique(train_images)\ntrain_df.drop_duplicates(subset=['image'], ignore_index=True, inplace=True)'''","2103faa1":"print(train_df.shape, train_images.shape)\nprint(test_df.shape, test_images.shape)","730daadd":"for dirname, _, filenames in os.walk('..\/input\/shopee-product-matching\/test_images\/'):\n    for filename in filenames:\n        img = cv2.resize(cv2.cvtColor(cv2.imread(os.path.join(dirname, filename)), cv2.COLOR_BGR2GRAY) \/ 255., (size, size)).flatten()\n        print(os.path.join(dirname, filename), img.shape)\n        test_images[filename.index(filename)] = img","0350054f":"train_data = torch.from_numpy(train_images).float()\ntrain_data = train_data.to(device)\nunique = train_df['label_group'].unique()\nids = np.array([i for i in range(len(unique))])\nid_dict = dict(zip(unique, ids))\nid_labels = np.array([id_dict[i] for i in train_df['label_group'].values])\nid_labels = torch.from_numpy(id_labels).long()\nid_labels = id_labels.to(device)\nprint(max(id_labels))","ded0deaa":"test_data = torch.from_numpy(test_images).float()\ntest_data = test_data.to(device)","b33c90a8":"num_features = train_data.shape[1]\nhidden_units = 192\nnum_classes = train_df['label_group'].nunique()\nmodel = nn.Sequential(\nnn.Linear(num_features, hidden_units, bias=True),\nnn.LeakyReLU(),\nnn.Linear(hidden_units, hidden_units, bias=True),\nnn.LeakyReLU(),\nnn.Linear(hidden_units, num_classes)\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nmodel.to(device)","8740e978":"cost = []\ncriterion = nn.CrossEntropyLoss()","85ca4971":"def fit(X, Y, epochs):\n    for i in range(epochs):\n        preds = model(X)\n        loss = criterion(preds, Y)\n        cost.append(loss)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        print(f'loss on iter {i} is {cost[-1]}')","4bc1fce2":"def predict(X):\n    preds = nn.Softmax(model(X))\n    return preds","3c5ca3ab":"fit(train_data, id_labels, 430)","28a5437b":"plt.plot(cost)","3298a805":"predict(test_data)","58e75989":"\u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043a \u043d\u0435\u0439\u0431\u043e\u0440\u0441 \u0441 50 \u0441\u043e\u0441\u0435\u0434\u044f\u043c\u0438","ca47c7fa":"\u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0438\u0434\u0442\u0438 \u043f\u043e \u0442\u0440\u0435\u0439\u043d \u0434\u0444 \u0438 \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0442\u044c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u043f\u043e \u0438\u043c\u0435\u043d\u0430\u043c \u0438\u0437 \u043a\u043e\u043b\u043e\u043d\u043a\u0438, \u043f\u043e\u0444\u0438\u0433 \u043d\u0430 \u043f\u043e\u0432\u0442\u043e\u0440\u0435\u043d\u0438\u044f. \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0434\u0443\u0431\u043b\u0438\u043a\u0430\u0442\u044b \u0438\u0437 \u0442\u0440\u0435\u0439\u043d \u0434\u0444 \u0438 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u0447\u043d\u043e\u0433\u043e \u043c\u0430\u0441\u0441\u0438\u0432\u0430","cfb060c2":"# \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a"}}