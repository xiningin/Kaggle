{"cell_type":{"b2a5c416":"code","e0048742":"code","246c7dc1":"code","3a42123c":"code","082defa8":"code","13c34218":"code","c6379471":"code","e9c1492f":"code","a8c941e2":"code","d43bcf8c":"code","68e15d58":"code","a3be9887":"code","152571c4":"code","81377efa":"code","ae38c8d2":"code","b613af37":"code","6a0e2052":"markdown"},"source":{"b2a5c416":"!pip install soundfile librosa","e0048742":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom librosa import core, onset, feature, display\nimport soundfile as sf\nimport umap\nfrom IPython.display import Audio\nimport sklearn","246c7dc1":"df = pd.read_csv(\"..\/input\/birdsong_metadata.csv\")\ndf.head()","3a42123c":"def load_audio(file_id):\n    data, samplerate = sf.read(\"..\/input\/songs\/songs\/xc\"+str(file_id)+\".flac\")\n    s = len(data)\/samplerate\n    sg = feature.melspectrogram(data, sr=samplerate, hop_length=512)\n    \n    # Take mean amplitude M from frame with highest energy\n    centerpoint = np.argmax(sg.mean(axis=0))\n    M = sg[:,centerpoint].mean()\n    \n    # Filter out all frames with energy less than 5% of M\n    mask = sg.mean(axis=0)>=M\/20\n\n    audio_mask = np.zeros(len(data), dtype=bool)\n    for i in range(0,len(mask)):\n        audio_mask[i*512:] = mask[i]\n    return sg, mask, data, audio_mask, samplerate","082defa8":"df['length'] = np.zeros(len(df))\n\nwaves = {}\n\n\nfor file_id in df['file_id']:\n    sg, mask, data, audio_mask, sample_rate = load_audio(file_id)\n    waves[file_id] = data[audio_mask]\n    df.loc[df['file_id'] == file_id,'length'] = len(data[audio_mask])\n    #print(len(data[audio_mask])\/sample_rate)","13c34218":"df['length'].hist()\nplt.show()\ndf['length'].describe()","c6379471":"# We set window to 6.144000e+03 frames as it's the minimum length among our audio files\ndf['windows'] = df['length'].apply(lambda x: int(x\/6.144000e+03))\ndf.head()","e9c1492f":"# To relax the problem we'll consider the genus as the label instead of the species\n# We use 23 windows per genus to have a balanced data set\n\nn_windows = df.groupby('species')['windows'].sum().min()\nn_windows","a8c941e2":"# First we create all windows for each file and partition them by species\n\nwindows = {}\n\nfor file_id in df['file_id']:\n    wave = waves[file_id]\n    species = df[df['file_id']==file_id]['genus'].values[0] + \"_\" + df[df['file_id']==file_id]['species'].values[0]\n    if species not in windows:\n        windows[species] = []\n    for i in range(0, int(len(wave)\/6.144000e+03)):\n        windows[species].append(wave[i:int(i+6.144000e+03)])\n        ","d43bcf8c":"# We randomly pick 20 windows for each species\n\n# Save other samples for testing\n\nwindows_fixed = {}\nwindows_fixed_test = {}\n\nfor species in windows.keys():\n    windows_fixed[species] = []\n    windows_fixed_test[species] = []\n    ws = windows[species]\n    index = np.random.choice(len(ws), n_windows, replace=False)\n    for i in range(0, len(ws)):\n        if i in index:\n            windows_fixed[species].append(ws[i])\n        else:\n            windows_fixed_test[species].append(ws[i])","68e15d58":"# Extract Features from Window\nnew_dataset = pd.DataFrame()\n\nfor species in windows_fixed.keys():\n    for i in range(0,n_windows):\n        data_point = {'species':species.split('_')[1], 'genus':species.split('_')[0]}\n        spec_centroid = feature.spectral_centroid(windows_fixed[species][i])[0]\n        chroma = feature.chroma_stft(windows_fixed[species][i], sample_rate)\n        for j in range(0,13):\n            data_point['spec_centr_'+str(j)] = spec_centroid[j]\n            for k in range(0,12):\n                data_point['chromogram_'+str(k)+\"_\"+str(j)] = chroma[k,j]\n        new_dataset = new_dataset.append(data_point,ignore_index=True)\n\nnew_dataset.head()","a3be9887":"# Extract Features from Window for test\nnew_dataset_test = pd.DataFrame()\n\nfor species in windows_fixed_test.keys():\n    for i in range(0,len(windows_fixed_test[species])):\n        data_point = {'species':species.split('_')[1], 'genus':species.split('_')[0]}\n        spec_centroid = feature.spectral_centroid(windows_fixed_test[species][i])[0]\n        chroma = feature.chroma_stft(windows_fixed_test[species][i], sample_rate)\n        for j in range(0,13):\n            data_point['spec_centr_'+str(j)] = spec_centroid[j]\n            for k in range(0,12):\n                data_point['chromogram_'+str(k)+\"_\"+str(j)] = chroma[k,j]\n        new_dataset_test = new_dataset_test.append(data_point,ignore_index=True)\n\nnew_dataset_test.head()","152571c4":"# Prepare dataset to fit a simple model\n\nfeatures= list(new_dataset.columns)\nfeatures.remove('species')\nfeatures.remove('genus')\n\nX = new_dataset[features].values\ny = new_dataset['species'].values\n\nX_test = new_dataset_test[features].values\ny_test = new_dataset_test['species'].values","81377efa":"# Use Naive Bayes as benchmark \n\nfrom sklearn import naive_bayes\nNB = naive_bayes.GaussianNB()\n\nSSS = sklearn.model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n\naccs = [] \n\nfor train_index, val_index in SSS.split(X, y):\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n    \n    NB.fit(X_train, y_train)\n    \n    y_pred = NB.predict(X_val)\n    \n    accs.append(sklearn.metrics.accuracy_score(y_pred=y_pred, y_true=y_val))\n    \nprint(accs)","ae38c8d2":"y_pred = NB.predict(X_test)\nsklearn.metrics.accuracy_score(y_pred=y_pred, y_true=y_test)","b613af37":"# The data can be used to predict, let's export the newly created datasets\n\nnew_dataset.to_csv(\"train.csv\")\nnew_dataset_test.to_csv(\"test.csv\")","6a0e2052":"You can find the dataset using the extracted features [here](https:\/\/www.kaggle.com\/fleanend\/birds-songs-numeric-dataset)."}}