{"cell_type":{"1a37bf7c":"code","c5840375":"code","05b35393":"code","2709e218":"code","68d64425":"code","afcbfb03":"code","1b4acc44":"code","46178ee5":"code","cdbf6fe0":"code","acbf4e50":"code","70431232":"code","d1161990":"code","a037c0c2":"code","c2461d84":"code","4207a14f":"code","c48cb82b":"code","298f07c6":"code","3f75bd01":"code","ee0b758e":"code","c3a4b841":"code","77eccfcc":"code","0c9de427":"code","64ddcc10":"code","86eca91f":"code","821b67bf":"code","f997c257":"code","76524d16":"code","8abb7fcf":"code","5dec69b7":"code","fecb8fb0":"code","3dc1eed2":"code","0912b18c":"code","a24dbe83":"markdown","d8265563":"markdown","d0a46216":"markdown","052844d1":"markdown","72e31c7c":"markdown","4a0aaade":"markdown"},"source":{"1a37bf7c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c5840375":"from PIL import Image","05b35393":"image = Image.open('..\/input\/mspec-data\/spectr_data\/test\/classical\/classical00030.png')","2709e218":"print(image.format)","68d64425":"print(image.size)","afcbfb03":"print(image.mode)","1b4acc44":"data = np.asarray(image)","46178ee5":"print(data)","cdbf6fe0":"plt.imshow(data)","acbf4e50":"data.shape","70431232":"data_gen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255.)\ntrain_datagen= data_gen.flow_from_directory(\"..\/input\/mspec-data\/spectr_data\/train\",target_size=(256,256),batch_size=32,class_mode='categorical')\ntest_datagen= data_gen.flow_from_directory(\"..\/input\/mspec-data\/spectr_data\/test\",target_size=(256,256),class_mode='categorical')","d1161990":"from tensorflow.keras.applications import VGG19","a037c0c2":"model=VGG19(include_top=False,input_shape=(256,256,3))","c2461d84":"for layer in model.layers:\n    layer.trainable=False","4207a14f":"output=model.layers[-1].output\nmodel_final=tf.keras.layers.Flatten()(output)\nmodel_final=tf.keras.layers.Dense(4096,activation='relu')(model_final)\nmodel_final=tf.keras.layers.Dropout(0.2)(model_final)\nmodel_final=tf.keras.layers.Dense(1024,activation='relu')(model_final)\nmodel_final=tf.keras.layers.Dense(10,activation='softmax')(model_final)","c48cb82b":"model=tf.keras.models.Model(model.input,model_final)","298f07c6":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc','AUC'])","3f75bd01":"y = model.fit_generator(generator=train_datagen,validation_data=test_datagen,epochs=8)","ee0b758e":"plt.plot(y.history[\"acc\"])\nplt.plot(y.history['val_acc'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\"])\nplt.show()","c3a4b841":"plt.plot(y.history[\"loss\"])\nplt.plot(y.history['val_loss'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train_loss\",\"Validation_Loss\"])\nplt.show()","77eccfcc":"model.summary()\n","0c9de427":"tf.keras.utils.plot_model(model,show_shapes=True,to_file=\"model.png\",\n    show_dtype=False,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=50,)","64ddcc10":"model.save(\"Musgenre.h5\")","86eca91f":"Imggpath = '..\/input\/mspec-data\/spectr_data\/test\/pop\/pop00029.png'\nimagee = Image.open(Imggpath)","821b67bf":"da = np.asarray(imagee)\nprint(da.size)\nplt.imshow(da)","f997c257":"image = tf.keras.preprocessing.image.load_img(Imggpath,color_mode=\"rgb\",target_size=(256,256))","76524d16":"input_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])","8abb7fcf":"input_arr.size","5dec69b7":"def scale_range (input, min, max):\n    input += -(np.min(input))\n    input \/= np.max(input) \/ (max - min)\n    input += min\n    return input","fecb8fb0":"input_arr = scale_range(input_arr,0,1)","3dc1eed2":"res = model.predict(input_arr)\nprint(res)","0912b18c":"if(np.argmax(res) == 0):\n    print('Blues')\nelif(np.argmax(res) == 1):\n    print('Classical')\nelif(np.argmax(res) == 2):\n    print('Country')\nelif(np.argmax(res) == 3):\n    print('Disco')\nelif(np.argmax(res) == 4):\n    print('Hiphop')\nelif(np.argmax(res) == 5):\n    print('Jazz')\nelif(np.argmax(res) == 6):\n    print('Metal')\nelif(np.argmax(res) == 7):\n    print('Pop')\nelif(np.argmax(res) == 8):\n    print('Reggae')\nelif(np.argmax(res) == 9):\n    print('Rock')","a24dbe83":"# Deep Neural Network Part> ****","d8265563":"# Prediction****","d0a46216":"# Image Preprocessing****","052844d1":"# Graphs****","72e31c7c":"# Saving****","4a0aaade":"# Visualization****"}}