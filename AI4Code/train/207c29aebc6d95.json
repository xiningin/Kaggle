{"cell_type":{"e3d45005":"code","43967281":"code","12629793":"code","883729eb":"code","a414a167":"code","510ad1a2":"code","cf57196f":"code","04119f73":"code","343a10f6":"code","bf4574c0":"code","4c84f2cf":"code","351e1566":"code","35213982":"code","4afc3e9e":"code","62020d75":"code","85ff27ea":"code","3e0878e8":"code","8aae46a3":"code","f6081cba":"code","503ff0ac":"code","2020d0eb":"code","286f3f33":"code","f3e357ac":"code","e73be66e":"code","8cddbbbb":"code","9f21b729":"code","f04cd3d3":"code","e92abf5d":"code","172896c5":"code","7a884671":"code","2676c9c6":"code","a97d340f":"code","c95b08c1":"code","e905870d":"code","03c76e5f":"code","70e74f19":"code","05f4c1a8":"code","bccbba5d":"code","4e761e3d":"code","f4225ce8":"code","5ccc1e20":"code","400bba17":"code","f43920b3":"code","25d3faf4":"code","50ef2981":"code","01ae81f9":"code","556f3b43":"code","c99dab3b":"code","e94707bf":"code","da00ce83":"code","c19f9ff7":"code","ba38608c":"code","b89d3085":"code","f9c7e6c1":"code","ad31bc18":"code","60d61cba":"code","f5bcbdbd":"code","f78f7ada":"code","a6d67040":"markdown","a7f00c51":"markdown","efeb4d89":"markdown","9fa3b020":"markdown","458c9b09":"markdown","7e915714":"markdown","bd6b5282":"markdown","79bbcf84":"markdown","c927905b":"markdown","8e79195e":"markdown","f22582f0":"markdown","d3b2dceb":"markdown","8d5fdeed":"markdown","c854a851":"markdown","254ab13b":"markdown","541c988c":"markdown","bed0264e":"markdown","0b66b00b":"markdown","0b90a6f0":"markdown","15778cee":"markdown","bf1ddd9b":"markdown","29530bde":"markdown","4531eefb":"markdown"},"source":{"e3d45005":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","43967281":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.preprocessing import LabelEncoder\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\n#timer\nimport time\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} done in {:.0f}s\".format(title, time.time() - t0))\n\n# Importing modelling libraries\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold\nfrom sklearn.preprocessing import StandardScaler  \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.calibration import CalibratedClassifierCV","12629793":"df = pd.read_csv('\/kaggle\/input\/predicting-churn-for-bank-customers\/Churn_Modelling.csv')","883729eb":"df.info()","a414a167":"df = df.astype({\"Age\": float})\ndf.head()","510ad1a2":"df = df.astype({\"Age\": float})","cf57196f":"df.shape","04119f73":"df['Exited'].value_counts()","343a10f6":"df['Gender'].value_counts()","bf4574c0":"df['Geography'].value_counts()","4c84f2cf":"df['NumOfProducts'].value_counts()","351e1566":"df['HasCrCard'].value_counts()","35213982":"df['IsActiveMember'].value_counts()","4afc3e9e":"df.groupby('IsActiveMember')['Exited'].value_counts()","62020d75":"print('The ratio of retention of active members',end=\": \")\nprint(round(4416\/5151*100,2))\nprint('The ratio of retention of passive members',end=\": \")\nprint(round(3547\/4849*100,2))","85ff27ea":"df['Gender'].value_counts()","3e0878e8":"df.groupby('Gender')['Exited'].value_counts()","8aae46a3":"print('The ratio of retention of men',end=\": \")\nprint(round(4559\/5457*100,2))\nprint('The ratio of retention of women',end=\": \")\nprint(round(3404\/4543*100,2))","f6081cba":"df['Geography'].value_counts()","503ff0ac":"df.groupby('Geography')['Exited'].value_counts()","2020d0eb":"print('The ratio of retention of customers from France',end=\": \") \nprint(round(4204\/5014*100,2))\nprint('The ratio of retention of  customers from Spain',end=\": \")\nprint(round(2064\/2477*100,2))\nprint('The ratio of retention of customers from Germany',end=\": \")\nprint(round(1695\/2509*100,2))","286f3f33":"df['NumOfProducts'].value_counts()","f3e357ac":"df.groupby('NumOfProducts')['Exited'].value_counts()","e73be66e":"print('The ratio of retention of customers with 2 products',end=\": \") \nprint(round(4242\/4590*100,2))\nprint('The ratio of retention of  customers with 1 product',end=\": \")\nprint(round(3675\/5084*100,2))","8cddbbbb":"df['HasCrCard'].value_counts()","9f21b729":"df.groupby('HasCrCard')['Exited'].value_counts()","f04cd3d3":"print('The ratio of retention of customers with credit card',end=\": \") \nprint(round(2332\/2945*100,2))\nprint('The ratio of retention of  customers without credit card',end=\": \")\nprint(round(5631\/7055*100,2))","e92abf5d":"df.describe().T","172896c5":"g = sns.FacetGrid(df, col = \"Exited\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","7a884671":"g = sns.FacetGrid(df, col = \"Exited\")\ng.map(sns.distplot, \"CreditScore\", bins = 25)\nplt.show()","2676c9c6":"g = sns.FacetGrid(df, col = \"Exited\")\ng.map(sns.distplot, \"Tenure\", bins = 25)\nplt.show()","a97d340f":"g = sns.FacetGrid(df, col = \"Exited\")\ng.map(sns.distplot, \"Balance\", bins = 25)\nplt.show()","c95b08c1":"g = sns.FacetGrid(df, col = \"Exited\")\ng.map(sns.distplot, \"EstimatedSalary\", bins = 25)\nplt.show()","e905870d":"# Let's visualize the correlations between numerical features of data.\nfig, ax = plt.subplots(figsize=(12,6)) \nsns.heatmap(df.iloc[:,1:len(df)].corr(), annot = True, fmt = \".2f\", linewidths=0.5, ax=ax) \nplt.show()","03c76e5f":"df.drop(['RowNumber'], axis = 1, inplace = True)\ndf.drop(['Surname'], axis = 1, inplace = True)\ndf.drop(['CustomerId'], axis = 1, inplace = True)","70e74f19":"df.head()","05f4c1a8":"for d in [df]:\n    d[\"Gender\"]=d[\"Gender\"].map(lambda x: 0 if x=='Female' else 1)","bccbba5d":"df.head()","4e761e3d":"df = pd.get_dummies(df, columns=[\"Tenure\"])","f4225ce8":"df = pd.get_dummies(df, columns=[\"NumOfProducts\"])","5ccc1e20":"df = pd.get_dummies(df, columns=[\"Geography\"])","400bba17":"df.head()","f43920b3":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = df.drop(['Exited'], axis=1)\ntarget = df[\"Exited\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","25d3faf4":"x_train.shape","50ef2981":"y_train.shape","01ae81f9":"y_train.head()","556f3b43":"x_val.shape","c99dab3b":"r=1309\nmodels = [LogisticRegression(random_state=r),GaussianNB(), KNeighborsClassifier(),\n          SVC(random_state=r,probability=True),DecisionTreeClassifier(random_state=r),\n          RandomForestClassifier(random_state=r), GradientBoostingClassifier(random_state=r),\n          XGBClassifier(random_state=r), MLPClassifier(random_state=r),\n          CatBoostClassifier(random_state=r,verbose = False)]\nnames = [\"LogisticRegression\",\"GaussianNB\",\"KNN\",\"SVC\",\n             \"DecisionTree\",\"Random_Forest\",\"GBM\",\"XGBoost\",\"Art.Neural_Network\",\"CatBoost\"]","e94707bf":"print('Default model validation accuracies for the train data:', end = \"\\n\\n\")\nfor name, model in zip(names, models):\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_val) \n    print(name,':',\"%.3f\" % accuracy_score(y_pred, y_val))","da00ce83":"results = []\nprint('10 fold cross validation accuracy scores of the default models:', end = \"\\n\\n\")\nfor name, model in zip(names, models):\n    kfold = KFold(n_splits=10, random_state=1001)\n    cv_results = cross_val_score(model, predictors, target, cv = kfold, scoring = \"accuracy\")\n    results.append(cv_results)\n    print(\"{}: {} ({})\".format(name, \"%.3f\" % cv_results.mean() ,\"%.3f\" %  cv_results.std()))","c19f9ff7":"# Tuning by Cross Validation  \nrf_params = {\"max_features\": [\"log2\",\"Auto\",\"None\"],\n                \"min_samples_split\":[2,3,5],\n                \"min_samples_leaf\":[1,3,5],\n                \"bootstrap\":[True,False],\n                \"n_estimators\":[50,100,150],\n                \"criterion\":[\"gini\",\"entropy\"]}\nrf = RandomForestClassifier()\nrf_cv_model = GridSearchCV(rf, rf_params, cv = 5, n_jobs = -1, verbose = 2)\nrf_cv_model.fit(x_train, y_train)\nrf_cv_model.best_params_","ba38608c":"rf = RandomForestClassifier(bootstrap = True, criterion = 'entropy' , max_features = 'log2', min_samples_leaf = 3, min_samples_split = 3,\n n_estimators = 100)\nrf_tuned = rf.fit(x_train,y_train)\ny_pred = rf_tuned.predict(x_val) \nacc_rf = round(accuracy_score(y_pred, y_val) * 100, 2) \nprint(acc_rf)","b89d3085":"predictions = y_pred","f9c7e6c1":"output = pd.DataFrame({ 'Exited': predictions }) \noutput.to_csv('submission.csv', index=False)\noutput.head()","ad31bc18":"output.describe().T","60d61cba":"output[\"Exited\"].value_counts()","f5bcbdbd":"Retention_Rate = 1734\/2000*100","f78f7ada":"print(str(Retention_Rate)+'%')","a6d67040":"It is interesting to see that there seems to be no relationship between credit score and exiting the company.","a7f00c51":"Data Preparation\n\nDropping Certain Variables: RowNumber, Surname, CustomerId","efeb4d89":"There is no significant difference between the customers who hold credit cards or not in terms of retention with the bank.","9fa3b020":"One hot encoding of Tenure, Geography and NumOfProducts","458c9b09":"Importing Data","7e915714":"Model tuning using crossvalidation","bd6b5282":"A higher part of the active members seems to stay with the company, compared to the non active members. ","79bbcf84":"It seems younger customers tend to stick with the company more compared to older customers.","c927905b":"It is interesting to see that there seems to be no relationship between estimated salary and exiting the company.","8e79195e":"A higher part of men seems to stay with the company, compared to women. ","f22582f0":"Accuracy Scores for the Default models","d3b2dceb":"It is interesting to see that there seems to be no relationship between balance and exiting the company.","8d5fdeed":"Label encoding of the variable Gender to a dummy variable (0-1)","c854a851":" Modeling, Evaluation and Model Tuning","254ab13b":"Explarotary Data Analysis","541c988c":"A higher part of customers from France and Spain seems to stay with the company, compared to Germany.","bed0264e":"CATEGORICAL VARIABLES","0b66b00b":"Splitting the data as train and test","0b90a6f0":"A higher part of customers with 2 products seems to stay with the company, compared to customers with 1 product.","15778cee":"It is interesting to see that there seems to be no relationship between tenure and exiting the company.","bf1ddd9b":"As it can be seen from the figure there is no significant correlation among numerical variables. It seems that only the variable of Age has some kind of correlation with the variable of Exited.","29530bde":"Cross Validation Accuracy Scores of the Default Models","4531eefb":"NUMERICAL VARIABLES"}}