{"cell_type":{"68e66079":"code","2774ba8c":"code","19dc98a4":"code","97758d03":"code","fafb4f71":"code","b0782c6a":"code","5968ec8a":"code","7f129caf":"code","2880637d":"markdown","68a20ee3":"markdown","ca0740e1":"markdown","41c8fcb0":"markdown","86eeff00":"markdown","f5eb9ff3":"markdown","1c9e262b":"markdown","3c1837d7":"markdown"},"source":{"68e66079":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sys\nimport scipy\nimport matplotlib\nimport sklearn\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2774ba8c":"#matplotlib for plotting various graphs\n#sklearn for accessing different algorithms\n\nimport pandas\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt \n","19dc98a4":"\n#Load data from the Iris Dataset as a Pandas Dataframe into 'data'\ndata = pd.read_csv(\"..\/input\/Iris.csv\")\n\n#Dimensions of the dataset\nprint(\"Dimensions =\",data.shape)         \nprint('\\nIris Data\\n')\nprint(data.head(10))      #Displaying the First 10 rows of the Iris Dataset\n\n#Removing the first column as it is redundant\ndel data['Id']\n\n#Renaming the column names with something more accesible\ndata.columns=['Sepal-Length', 'Sepal-Width', 'Petal-Length', 'Petal-Width', 'Class']\nprint(data.head(5))\nprint('\\n')\n\n#Class Distribution of the Dataset\nprint(\"Class Distribution\\n\")\nprint(data.groupby('Class').size())  \n\n#Statistical Summary of the Dataset\nprint(\"\\n\\nStatistical Summary\\n\")\nprint(data.describe())               \nprint('\\n')\n","97758d03":"#Histogram\n\ndata.hist(edgecolor='black', linewidth=1.2)\nplt.show()\n\n#Box and Whisper Plots\ndata.plot(kind='box',subplots=True,layout=(2,2), sharex=False,sharey=False,title=\"Boxplot(Class vs cm)\")\nplt.show()\n\n#Multivariate Plot \ndata.plot(kind=\"scatter\", x=\"Sepal-Length\", y=\"Sepal-Width\")\nplt.title(\"Sepal Length(cm) vs Sepal Width(cm)\")\nplt.show()\n\ndata.plot(kind=\"scatter\", x=\"Petal-Length\", y=\"Petal-Width\")\nplt.title(\"Petal Length(cm) vs Petal Width(cm)\")\nplt.show()\n\n","fafb4f71":"#Create a Validation Dataset by splitting the original dataset into separate Test and Train datasets\narray=data.values\nX = array[:,0:4]\nY = array[:,4]\nprint(\"Training set for both X and Y is about 80% of the original dataset\")\nvalidation_size = 0.20\nprint(\"Validation Size=\",validation_size)\nseed = 7 #Setting up randomness\n#With model_selection.train_test_split imported from sklearn, we can split data into test and train sets\nX_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\nprint(X_train[5])\n","b0782c6a":"#Use K Fold cross validation to estimate accuracy, k =10\n#Meaning that the dataset will be split into 10 parts, which will train on 9 and test on 1 for every combination\nseed=7\nscoring='accuracy'\n#We will be using the scoring variable to compare the accuracy of every model tested\n\nprint(\"Evaluate every Algorithm\\n\")\n# pot Check Different Algorithms\n#Linear(LR, LDA) & Non Linear (KNN, CART, NB, SVM)\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n#Evaluate each model in turn\nresults = []\nnames = []\nprint(\"Model\\t\",\"Mean\\t\\t\",\"Std\")\nfor name, model in models: \n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s:\\t %f\\t (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n\n\n","5968ec8a":"#From the above values, we can see that Support Vector Machines (SVM) has the largest estimated accuracy score.\n#Compare mean acccuracy of Algorithms with each other\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","7f129caf":"from sklearn.svm import SVC\nmodel=SVC()\nmodel.fit(X_train, Y_train)\npredictions = model.predict(X_validation)\nprint(\"Accuracy=\",accuracy_score(Y_validation, predictions),\"%\\n\")\nprint(\"Confusion Matrix=\\n\",confusion_matrix(Y_validation, predictions),\"\\n\")\nprint(\"Classification Report=\\n\",classification_report(Y_validation, predictions))","2880637d":"**Make predictions on Validation dataset**","68a20ee3":"**Create Validation dataset**","ca0740e1":"I'd like to thank https:\/\/machinelearningmastery.com\/ for helping me out with my first notebook (especially with applying different algorithms on the training dataset)","41c8fcb0":"**Import Libraries**","86eeff00":"**Data Visualization**","f5eb9ff3":"**Load and Summarize the Dataset **","1c9e262b":"**Comparing Algorithms**","3c1837d7":"**Run different algorithms on training dataset**"}}