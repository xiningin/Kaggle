{"cell_type":{"bf3a7824":"code","6735151c":"code","6bc4e4bc":"code","d759e021":"code","f611a1c4":"code","0404b1fb":"code","e4f100e8":"code","9ab647e5":"code","23b80726":"code","b2b09faf":"code","42232fe3":"code","e71179f2":"markdown","f3f4db37":"markdown","88010e50":"markdown","08934595":"markdown","e5113076":"markdown","f57d8857":"markdown","b5225387":"markdown","e92cb8ab":"markdown","024c66c4":"markdown","80a1f2ce":"markdown","5122972a":"markdown","fadf667b":"markdown","cb3f0f65":"markdown","49fed58d":"markdown","21375376":"markdown","f5358b93":"markdown","c30f9365":"markdown","3f018687":"markdown","2894de5a":"markdown","f9676e35":"markdown","e4c92cfe":"markdown","32e59e30":"markdown","7da469e6":"markdown","c44b05c4":"markdown"},"source":{"bf3a7824":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom scipy import stats\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndirectory = \"..\/input\/car-purchase-data\/\"\nfeature_tables = ['Car_Purchasing_Data.csv']\n\ndf_train = directory + feature_tables[0]\n\n# Create dataframes\nprint(f'Reading csv from {df_train}...')\ntrain = pd.read_csv(df_train,encoding='ISO-8859-1')\nprint('...Complete')","6735151c":"train.head()","6bc4e4bc":"train = train.drop(['Customer Name','Customer e-mail', 'Country'],axis=1)","d759e021":"corr = train.corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(20, 18))\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, annot=True, mask=mask, cmap=\"YlGnBu\", center=0,\n            square=True, linewidths=.5)","f611a1c4":"features = ['Age', 'Annual Salary', 'Net Worth']\ntarget = ['Car Purchase Amount']\n\nX = train[features]\ny = train[target]","0404b1fb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","e4f100e8":"regressor = LinearRegression()  \nregressor.fit(X_train, y_train)\ny_pred = regressor.predict(X_test)\nprint(regressor.coef_)\nprint(regressor.intercept_)","9ab647e5":"print(f'Linear Regression equation is Y = {round(regressor.coef_[0][0],3)}*X0 + {round(regressor.coef_[0][1],3)}*X1 + {round(regressor.coef_[0][2],3)}*X2 {round(regressor.intercept_[0],3)}'  )\nprint(f'Y = {target[0]}')\nprint(f'X0 = {features[0]}')\nprint(f'X1 = {features[1]}')\nprint(f'X2 = {features[2]}')","23b80726":"r2 = metrics.r2_score(y_test,y_pred)\nmae = metrics.mean_absolute_error(y_test,y_pred)\nmse = metrics.mean_squared_error(y_test,y_pred)\nprint(f'R2 = {r2}')\nprint(f'MAE = {mae}')\nprint(f'RMSE = {mse}')","b2b09faf":"age = 49\nsalary = 60500\nnet_worth = 173000\ncustomer = [age, salary, net_worth]\nprediction = regressor.predict([customer])","42232fe3":"print('--Customer Information--')\nprint(f'Age: {age}') \nprint(f'Salary: {salary}')\nprint(f'Net Worth: {net_worth}')\nprint()\nprint(f'Predicted Car Purchase Amount: {round(prediction[0][0],2)}')","e71179f2":"### We will drop all of our non-numerical variables first as we won't be using them in numerical regression","f3f4db37":"# Introduction to Multiple Linear Regression\n\n### Linear regression is one the most basic algorithms used for machine learning models. And for certain problems it is the perfect solution, providing an easily interpretible model that can be deployed with minimal effort. Linear regression is approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). Basic linear regression involves one dependent variable and one explanatory variable.","88010e50":"### Now we can deploy our model! We simply need to plug in the age, salary, and net_worth of our customer.","08934595":"### R-Squared: R-squared evaluates the scatter of the data points around the fitted regression line. It is also called the coefficient of determination, or the coefficient of multiple determination for multiple regression. For the same data set, higher R-squared values represent smaller differences between the observed data and the fitted values.\n![image.png](attachment:image.png)","e5113076":"## Deploy","f57d8857":"### Multiple linear regression involves one dependent variable and N number of independent variables.\n\n![image.png](attachment:image.png)\n\n### It allows us to more accurately predict a dependent variable when there exist multiple independent variables that correlate well to our dependent variable. This kernel will walk through how to implement a multiple linear regression model.\n\n### Please UPVOTE this Kernel if you found it useful","b5225387":"### With our data all properly prepared, we can create our linear regression model, fit the model to our training data, and use the model to predict our dependent variable on our validation test set. ","e92cb8ab":"### With all of that explained, how does our model perform?","024c66c4":"### Now, time to look at correlation between all of our variables. We are particularly interest in correlation to our dependent variable: Car Purchase Amount","80a1f2ce":"### Mean Absolute Error (MAE): MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It\u2019s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n![image.png](attachment:image.png)","5122972a":"### From this heatmap we observe that there are three explanatory variables that have a high correlation to our dependent variable: Age, Annual Salary, and Net Worth.\n### These will be the features (explanatory variables) which we will use to create our linear regression model.","fadf667b":"### Root mean squared error (RMSE): RMSE is a quadratic scoring rule that also measures the average magnitude of the error. It\u2019s the square root of the average of squared differences between prediction and actual observation.\n![image.png](attachment:image.png)","cb3f0f65":"### Looking at some example plots, we can see how the R2 is quite intuitive. The first plot shows that, relative to the fit line, the data has much more variance compared to the second plot. Therefore, it has a lower R2 score. If Total Variance goes up, our R2 goes down. Simple!","49fed58d":"### I hope you found this kernel helpful. Please UPVOTE if that is the case!","21375376":"## Data Preparation","f5358b93":"![image.png](attachment:image.png)","c30f9365":"![image.png](attachment:image.png)","3f018687":"### We now have a regression model that predictions our dependent variable 'Car Purchase Amount' using our three explanatory variables 'Age', 'Annual Salary', and 'Net Worth'. We can get the coeffients and interept of our new regression equation from the model.","2894de5a":"### An R2 of greater than 0.99 tells us that the variance of our test dataset to our regression model is incredibly low. In other words, our model is very accurate! The MAE tells us that our model is only off by a little over 1 dollar on average. That's great! Finally, our RMSE tells a very similar story, showing that our variance is low.","f9676e35":"### Now that we have our model, we need to know how good it actually is. Before that, we need to have a good understanding of a few key performance metrics that are good to use for regression problems...","e4c92cfe":"![image.png](attachment:image.png)","32e59e30":"### Time to split our dataset into our test and train datasets. We don't need to do anything too complicated for our validation scheme.","7da469e6":"## Model Training","c44b05c4":"## Model Validation"}}