{"cell_type":{"43123038":"code","03a4ef30":"code","470a6e59":"code","57dd97af":"code","0b2e446b":"code","f00e8042":"code","7b8d5ab9":"code","b8fc2988":"code","6c70b633":"code","f88905e7":"code","82929235":"code","519a28ea":"code","1c3932cd":"code","1c7be071":"code","03dd0db7":"code","bd7c35a4":"code","c85b3018":"code","b2f46f65":"code","1a4e82cc":"code","c961fb34":"code","3a01543e":"code","b393111a":"code","aadfd219":"code","a74eb584":"code","57363692":"code","000c674d":"code","9d3a8c1a":"code","a55e5391":"code","90223a8d":"code","1d96a734":"code","94a6b0d3":"code","43fe3394":"code","d2f56f12":"code","181a93f1":"code","2569f579":"code","8b1c6ddd":"code","6eaf5e32":"code","7c620c42":"code","638c4a20":"code","fb74cb78":"code","6c61436f":"code","9ce944f5":"code","1d599047":"markdown","afce6c9f":"markdown","8801fc99":"markdown","371f26a9":"markdown","5ec1d465":"markdown","16f72ea8":"markdown","d49e2c99":"markdown","4d4b99fa":"markdown","e8524347":"markdown","c8d406ee":"markdown","c4423eb5":"markdown","bf9b8a9c":"markdown","c8bf66f7":"markdown","3dceed8c":"markdown","b96b353c":"markdown"},"source":{"43123038":"# \ud310\ub2e4\uc2a4 \uceec\ub7fc,\ud589\uc744 \ucd5c\ub300\ub85c \ucd9c\ub825\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","03a4ef30":"# \uacbd\uace0\ud45c\uc2dc \ud574\uc81c\nimport warnings\nwarnings.filterwarnings(action='ignore')","470a6e59":"# format\nx = 12.9293939\nprint(format(x, '.2f')) # \uc18c\uc218\uc810 \ub458\uc9f8\uc790\ub9ac\ub85c \ud45c\uae30(\ubc18\uc62c\ub9bc)","57dd97af":"# Matplotlib \ud55c\uae00 \uc124\uc815 \ndef fix_font():\n     # From https:\/\/HC.Dle.pw, By Jinseo Kim\n    # v1.0.0\n    import os\n    import matplotlib as mpl\n    import matplotlib.pyplot as plt\n    os.system(\"apt-get install -y fonts-nanum\")\n    os.system(\"fc-cache -fv\")\n    mpl.font_manager._rebuild()\n    findfont = mpl.font_manager.fontManager.findfont\n    mpl.font_manager.findfont = findfont\n    mpl.backends.backend_agg.findfont = findfont\n    plt.rcParams['font.family'] = \"NanumBarunGothic\"\n    plt.rcParams['axes.unicode_minus'] = False\n           \nfix_font()","0b2e446b":"# \ubd84\uc0b0\nnp.var(x) # \ubd84\uc0b0\nnp.std(x) # \ud45c\uc900\ud3b8\ucc28","f00e8042":"# 4\ubd84\uc704\uc218\nimport numpy as np\nnp.quantile(df['Global_Sales'], 0.75)","7b8d5ab9":"# \ucca8\ub3c4 \uc65c\ub3c4\nfrom scipy.stats import skew, kurtosis\n\nskew(df['numeric']) #\uc65c\ub3c4\nkurtosis(df['numeric']) # \ucca8\ub3c4","b8fc2988":"# \uc0c1\uad00\uacc4\uc2181\ncorr = df.corr(method = 'pearson') #\ub610\ub294 spearman\n\n# \uc0c1\uad00\uacc4\uc218 2\nfrom scipy import stats\nstats.pearsonr(df['1'], df['2']) # \ub610\ub294 spearmanr\n# (\uc0c1\uad00\uacc4\uc218, p-value) \ucd9c\ub825, p-value\uac00 0.05\ubcf4\ub2e4 \uc791\uc73c\uba74 \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd, \uc0c1\uad00 \uc788\uc74c","6c70b633":"# \uc815\uaddc\uc131 \uac80\uc815\nfrom scipy import stats\n\nstats.normaltest(data)\n\nstats.kstest(data, \"norm\") #\ucf5c\ubaa8\uace0\ub85c\ud504-\uc2a4\ubbf8\ub974\ub178\ud504, \ud45c\ubcf8\uc218\uac00 \ub9ce\uc744\ub54c\n# p-value >= 0.05 : \uadc0\ubb34\uac00\uc124 \ucc44\ud0dd - \uc815\uaddc\ubd84\ud3ec\uc640 \ub3d9\uc77c\n# p-value < 0.05 : \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd  - \uc815\uaddc\ubd84\ud3ec\uac00 \uc544\ub2d8\n\nstats.shapiro(data) #\uc0e4\ud53c\ub85c \ud14c\uc2a4\ud2b8, \ud45c\ubcf8\uc218\uac00 \uc801\uc744\ub54c (50\uac1c \ubbf8\ub9cc)\n# p-value >= 0.05 : \uadc0\ubb34\uac00\uc124 \ucc44\ud0dd - \uc815\uaddc\ubd84\ud3ec\uc640 \ub3d9\uc77c\n# p-value < 0.05 : \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd  - \uc815\uaddc\ubd84\ud3ec\uac00 \uc544\ub2d8","f88905e7":"# \ub4f1\ubd84\uc0b0\uc131 \uac80\uc815  - \ub450 \ud45c\ubcf8\uc758 \ud3c9\uade0 \uac80\uc815 \uc804\uc5d0 \uc0ac\uc6a9\ud55c\ub2e4\n# p-value >= 0.05 : \uadc0\ubb34\uac00\uc124 \ucc44\ud0dd - \ub450 \ud45c\ubcf8\uc758 \ubd84\uc0b0\uc774 \ub3d9\uc77c = \ub4f1\ubd84\uc0b0\uc131 \ub9cc\uc871 \n# p-value < 0.05 : \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd  - \ub450 \ud45c\ubcf8\uc758 \ubd84\uc0b0\uc774 \ub2e4\ub984 = \ub4f1\ubd84\uc0b0\uc131 \ubd88\ub9cc\uc871\n\nfrom scipy.stats import bartlett, fligner, levene\n\nbartlett(data1, data2) # \ud45c\ubcf8\uc774 \uc815\uaddc\uc131\uc744 \ub530\ub97c \ub54c \uc0ac\uc6a9 \uac00\ub2a5\ud55c \ub4f1\ubd84\uc0b0 \uac80\uc815\ubc95.\nfligner(data1, data2)\nlevene(data1, data2)  # \uc815\uaddc\uc131 \uad00\uacc4 \uc5c6\uc774 \uc0ac\uc6a9","82929235":"# t-\uac80\uc815, t-test - \uc9d1\ub2e8 \uac04 \ud3c9\uade0 \ucc28\uc774 \uac80\uc815\n# p-value >= 0.05 : \uadc0\ubb34\uac00\uc124 \ucc44\ud0dd - \ud3c9\uade0\uc774 \uac19\ub2e4\n# p-value < 0.05 : \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd  - \ud3c9\uade0\uc774 \uac19\uc9c0 \uc54a\ub2e4\n\nfrom scipy import stats\n\n# 1) \ud55c\uc9d1\ub2e8 \ud3c9\uade0 \uac80\uc815\nstats.ttest_1samp(data, \uc54c\ub824\uc9c4\ud3c9\uade0) # \ud1b5\uacc4\ub7c9, p-value \ucd9c\ub825\n\n# 2) \ub450\uc9d1\ub2e8 \ud3c9\uade0 \uac80\uc815\nstats.ttest_ind(data1, data2)\n\n# 3) \uc9d1\ub2e8\uc758 \uc804\ud6c4\ubcc0\ud654\ub97c \uac80\uc815\nstats.ttest_rel(x,y)","519a28ea":"# \uce74\uc774\uc81c\uacf1 \uac80\uc815 - \ub450\uac1c\uc758 \uc9d1\ub2e8\uc5d0 \ucc28\uc774\uac00 \uc788\ub294\uc9c0 \uac80\uc815 (\ubc94\uc8fc\ud615 \uac12 \uac19\uc740 \uba85\ubaa9\ucc99\ub3c4\uc5d0 \uc0ac\uc6a9)\n# p-value >= 0.05 : \uadc0\ubb34\uac00\uc124 \ucc44\ud0dd - \ub450 \uc9d1\ub2e8\uac04 \ucc28\uc774\uac00 \uc5c6\ub2e4.\n# p-value < 0.05 : \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd  - \ub450 \uc9d1\ub2e8\uac04 \ucc28\uc774\uac00 \uc788\ub2e4.\nfrom scipy import stats\nstats.chisquare(data1, data2) #\ud1b5\uacc4\ub7c9, #p-value\n\n\n#x_train \ub370\uc774\ud130\uc5d0\uc11c \uc720\uc785\uacbd\ub85c\uc640 \uc131\ubcc4\uc774 \uc5f0\uad00\uc131\uc774 \uc788\ub294\uc9c0 \uac00\uc124\uac80\uc815\uc744 \uc2e4\uc2dc \n# \uadc0\ubb34\uac00\uc124 : \uc131\ubcc4\uc5d0 \ub530\ub978 \uc720\uc785\uacbd\ub85c\uc758 \ucc28\uc774\uac00 \uc5c6\ub2e4. (\uc11c\ub85c \ub3c5\ub9bd)\n# \ub300\ub9bd\uac00\uc124 : \uc131\ubcc4\uc5d0 \ub530\ub978 \uc720\uc785\uacbd\ub85c\uc758 \ucc28\uc774\uac00 \uc788\ub2e4. (\uc11c\ub85c \ub3c5\ub9bd\uc774 \uc544\ub2d8)\n\nimport scipy.stats as stats \nx_cotigency = pd.crosstab(x_train['\uc131\ubcc4'],x_train['\uc720\uc785\uacbd\ub85c']) # \uc131\ubcc4\uc5d0 \ub530\ub978 \uc720\uc785\uacbd\ub85c \uce74\uc6b4\ud2b8 \ud45c \uc0dd\uc131 (\uba85\ubaa9\ucc99\ub3c4->\ub4f1\uac04\ucc99\ub3c4)\nprint(stats.chi2_contingency(x_cotigency)[0]) # \ud1b5\uacc4\uac12\nprint(stats.chi2_contingency(x_cotigency)[1]) # P.value \nprint(stats.chi2_contingency(x_cotigency)[2]) # \uc790\uc720\ub3c4 \nprint(stats.chi2_contingency(x_cotigency)[3]) # \uae30\ub313\uac12 \n\n# p.value > 0.05 , \uadc0\ubb34\uac00\uc124\uae30\uac01\uc2e4\ud328 (\uadc0\ubb34\uac00\uc124 \ucc38)\n# \uc131\ubcc4\uc5d0 \ub530\ub978 \uc720\uc785\uacbd\ub85c\uc758 \ucc28\uc774\uac00 \uc5c6\ub2e4. (\uc11c\ub85c \ub3c5\ub9bd)","1c3932cd":"# \ud63c\ub3d9\ud589\ub82c, \uc815\ud655\ub3c4, \uc7ac\ud604\uc728, f1 score\nfrom sklearn.metrics import classification_report\nclassification_report(y, model1.predict(X))","1c7be071":"from scipy import stats\n# 2\uac1c \uc774\uc0c1\uc758 \uc9d1\ub2e8\uc758 \ud3c9\uade0 \ubd84\ud3ec\ub97c \ube44\uad50\n# ANOVA \uc77c\uc6d0\ubc30\uce58 \ubd84\uc0b0\ubd84\uc11d - \ub3c5\ub9bd\ubcc0\uc218 1\uac1c\n# p-value >= 0.05 : \uadc0\ubb34\uac00\uc124 \ucc44\ud0dd - \uadf8\ub8f9\uac04 \ud3c9\uade0\uc774 \ucc28\uc774\uac00 \uc5c6\ub2e4\n# p-value < 0.05 : \ub300\ub9bd\uac00\uc124 \ucc44\ud0dd  - \uadf8\ub8f9\uac04 \ud3c9\uade0\uc774 \ucc28\uc774\uac00 \uc788\ub2e4\nstats.f_oneway(data1, data2, data3)","03dd0db7":"import requests\nfrom bs4 import BeautifulSoup as bs\n\ndata = requests.get(url)  # \uc0ac\uc774\ud2b8 \ub370\uc774\ud130 \uac00\uc838\uc624\uae30\nsoup = bs(data.text)  # \ud14d\uc2a4\ud2b8 \ud30c\uc2f1\ud558\uc5ec soup\uc5d0 \uc800\uc7a5","bd7c35a4":"import pandas as pd\n\ny_train = pd.read_csv('https:\/\/raw.githubusercontent.com\/Datamanim\/dataq\/main\/y_train.csv')\nX_train = pd.read_csv('https:\/\/raw.githubusercontent.com\/Datamanim\/dataq\/main\/X_train.csv', encoding='euc-kr')\ntest  = pd.read_csv('https:\/\/raw.githubusercontent.com\/Datamanim\/dataq\/main\/X_test.csv',encoding='euc-kr')\n\n# \ub370\uc774\ud130 \ubcd1\ud569\ntrain = pd.merge(y_train,X_train)","c85b3018":"# \ub0a0\uc9dc\ubcc0\ud658 datetime\ndf['\uc77c\uc790'] = pd.to_datetime(df['\uc77c\uc790'])\ndf['\ub144\ub3c4'] = df['\uc77c\uc790'].dt.year\ndf['\uc6d4'] = df['\uc77c\uc790'].dt.month\ndf['\uc77c'] = df['\uc77c\uc790'].dt.day\ndf['weekend'] = df['\uc77c\uc790'].dt.weekday","b2f46f65":"# \uc911\ubcf5\uc81c\uac70\ndf.drop_duplicates(subset='item_name', keep='first')","1a4e82cc":"# N\uc73c\ub85c \uc2dc\uc791\ud558\ub294 \ub370\uc774\ud130 \ucd94\ucd9c\ndf[df['item_name'].str.startswith('N')].head()","c961fb34":"# \uacb0\uce21\uac12 \ud655\uc778\nprint('train \uacb0\uce21\uac12 \ud655\uc778\\n', train.isnull().sum())\nprint('\\ntest \uacb0\uce21\uac12 \ud655\uc778\\n', test.isnull().sum())","3a01543e":"# \uacb0\uce21 \uceec\ub7fc \uc815\ubcf4 \ud655\uc778\ntrain['\ud658\ubd88\uae08\uc561'].describe()","b393111a":"# \ud658\ubd88\uae08\uc561 \ucd5c\uc18c\uac12\uc774 0\uc774 \uc544\ub2c8\ubbc0\ub85c \uacb0\uce21\uac12\uc744 0\uc73c\ub85c \ubcc0\ud658\ntrain['\ud658\ubd88\uae08\uc561'] = train['\ud658\ubd88\uae08\uc561'].fillna(0)\ntest['\ud658\ubd88\uae08\uc561'] = test['\ud658\ubd88\uae08\uc561'].fillna(0)\n\n# \uc815\ud615\ub370\uc774\ud130 \uacb0\uce21\uce58 \ud3c9\uade0\uac12 \ub300\uccb4 \uc608\uc2dc\n# train['numeric'].fillna(data['numeric].median(), inplace=True)","aadfd219":"train.describe()","a74eb584":"# \ubc94\uc8fc\ud615 \ub370\uc774\ud130 \ud655\uc778\nprint('\uc8fc\uad6c\ub9e4\uc0c1\ud488 values\\n', train['\uc8fc\uad6c\ub9e4\uc0c1\ud488'].value_counts())\nprint('\\n\uc8fc\uad6c\ub9e4\uc9c0\uc810 values\\n : ', train['\uc8fc\uad6c\ub9e4\uc9c0\uc810'].value_counts())","57363692":"# \uc5f0\uc18d\ud615 \ub370\uc774\ud130 \ubd84\ud3ec \ud655\uc778\nprint('skew() = ', df['\ud658\ubd88\uae08\uc561'].skew())\nprint(pd.cut(df['\ud658\ubd88\uae08\uc561'], bins=15).value_counts(sort=False))","000c674d":"# \uc885\uc18d\ubcc0\uc218\uc640 \uc0c1\uad00\uad00\uacc4 \ud30c\uc545\ntrain.corr()['gender']\n\npd.DataFrame({'feature':list(df.columns), 'importance':model.feature_importance_})","9d3a8c1a":"df.select_dtypes(include=np.number).columns # \uc218\uce58\ud615 \uceec\ub7fc \uc120\ud0dd\ndf.select_dtypes(include=object).columns # \ubc94\uc8fc\ud615 \uceec\ub7fc \uc120\ud0dd","a55e5391":"train['sex'].replace(['male', 'female'], [0,1], inplace=True)","90223a8d":"# \uc6d0\ud56b \uc778\ucf54\ub529\ndata = pd.get_dummies(data)","1d96a734":"# label \uc778\ucf54\ub529\nstore_to_num = dict(zip(train['\uc8fc\uad6c\ub9e4\uc9c0\uc810'].unique(), [0,1,2,3,4,5,6,7,8,9,10,11]))\ntrain['\uc8fc\uad6c\ub9e4\uc9c0\uc810'].map(store_to_num)","94a6b0d3":"label_dic = {'G':7, 'E':6, 'F':5, 'H':4, 'D':3, 'I':2, 'J':1}\ndf['colorLabel'] = df['color'].map(label_dic)","43fe3394":"# \uc74c\uc218 \ub370\uc774\ud130 \uc0ad\uc81c\ntrain = train[train['\ucd1d\uad6c\ub9e4\uc561']>0]","d2f56f12":"# \ud30c\uc0dd\ubcc0\uc218 \uc0dd\uc131\ntrain['\ucd5c\ucd08\uad6c\ub9e4\uc561'] = train['\ucd1d\uad6c\ub9e4\uc561'] + train['\ud658\ubd88\uae08\uc561'] + 1\ntrain['\ucd5c\ub300\uad6c\ub9e4\uc561\ube44\uc728'] = train['\ucd5c\ub300\uad6c\ub9e4\uc561']\/train['\ucd5c\ucd08\uad6c\ub9e4\uc561']\ntrain['\ud658\ubd88\uae08\uc561\ube44\uc728'] = train['\ud658\ubd88\uae08\uc561']\/train['\ucd5c\ucd08\uad6c\ub9e4\uc561']\ntrain['\ucd1d\uad6c\ub9e4\uac74\uc218'] = train['\ub0b4\uc810\uc77c\uc218']*train['\ub0b4\uc810\ub2f9\uad6c\ub9e4\uac74\uc218']\n\n\ntest['\ucd5c\ucd08\uad6c\ub9e4\uc561'] = test['\ucd1d\uad6c\ub9e4\uc561'] + test['\ud658\ubd88\uae08\uc561'] + 1\ntest['\ucd5c\ub300\uad6c\ub9e4\uc561\ube44\uc728'] = test['\ucd5c\ub300\uad6c\ub9e4\uc561']\/test['\ucd5c\ucd08\uad6c\ub9e4\uc561']\ntest['\ud658\ubd88\uae08\uc561\ube44\uc728'] = test['\ud658\ubd88\uae08\uc561']\/test['\ucd5c\ucd08\uad6c\ub9e4\uc561']\ntest['\ucd1d\uad6c\ub9e4\uac74\uc218'] = test['\ub0b4\uc810\uc77c\uc218']*test['\ub0b4\uc810\ub2f9\uad6c\ub9e4\uac74\uc218']","181a93f1":"from sklearn.decomposition import PCA\ntrain_pca = pca.fit_transform(train_scaled) # pca\uc804 Standardscaler \ubcc0\ud658 \ud544\uc694\npca = PCA(n_components=5) # 5\uac1c \uc8fc\uc131\ubd84\uc73c\ub85c \ucc28\uc6d0 \ucd95\uc18c\na = pca.explained_variance_ratio_ # 30\uac1c \uc8fc\uc131\ubd84\uc758 \ubd84\uc0b0\ube44\uc728 (\uc124\uba85\ub825 \ub192\uc740 \uc21c)\na[0] + a[1] + a[2] # \uc138\ubc88\uc9f8 \uc8fc\uc131\ubd84\uae4c\uc9c0\uc758 \ub204\uc801\ubd84\uc0b0 \ube44\uc728","2569f579":"# pca\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=75) \nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","8b1c6ddd":"# \uc8fc\uc131\ubd84\uac04 \uc720\ud074\ub9ac\ub4dc \uac70\ub9ac \uacc4\uc0b0\ndef dist(x,y):\n  return np.sqrt(np.sum((x - y) ** 2))\n\nprint(dist(df3['com1'], df3['com2']))","6eaf5e32":"# PCA \uc8fc\uc131\ubd84 \uad70\uc9d1\ud654\nfrom sklearn.cluster import AgglomerativeClustering\n\ncluster = AgglomerativeClustering(n_clusters = 3, affinity='euclidean', linkage='ward')  # n_clusters \uad70\uc9d1\uc218, affinity \uac70\ub9ac\uce21\uc815\ubc29\ubc95, linkage \uc5f0\uacb0\ubc95\ndf['group'] = cluster.fit_predict(df5)\nprint( df5['group'].value_counts())","7c620c42":"# \uac01\uc885 \uac70\ub9ac\uad6c\ud558\uae30\nfrom sklearn.metrics.pairwise import cosine_distances, euclidean_distances, manhattan_distances","638c4a20":"# test \ub370\uc774\ud130 \ubd84\ub9ac\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =10)\n\n# \uac80\uc99d\nfrom sklearn.metrics import roc_auc_score\nroc = roc_auc_score(y_pred, y_test)","fb74cb78":"# from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.datasets import load_iris\nimport numpy as np\n\niris_data = load_iris()\ndf_clf = DecisionTreeClassifier(random_state=156)\n\ndata = iris_data.data\nlabel = iris_data.target\n\nscores = cross_val_score(df_clf, data, label, scoring='accuracy', cv=5)\nprint('\uad50\ucc28 \uac80\uc99d\ubcc4 \uc815\ud655\ub3c4:', scores)\nprint('\ud3c9\uade0 \uac80\uc99d \uc815\ud655\ub3c4:', mean(scores))","6c61436f":"class_weight='balanced' # \ubd88\uade0\ud615 \ub370\uc774\ud130 \uac00\uc911\uce58 \uc124\uc815\ncriterion='gini' or 'entropy'\nn_estimators= \uc22b\uc790 # \ubd84\ub958\uae30 \uc218\nmax_depth = \uac00\uc9c0 \ucd5c\ub300 \uae4a\uc774","9ce944f5":"model.fit(X_train, y_train)\ny_test = model.predict_proba(X_test)\nsubmission = pd.DataFrame({'custid': test.cust_id, 'gender' : y_test[:,1]})\nsubmission.to_csv('\uc218\ud5d8\ubc88\ud638.csv', index=False)","1d599047":"# EDA","afce6c9f":"# Feature Engineering","8801fc99":"# \ubaa8\ub378 \uac80\uc99d","371f26a9":"# \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd","5ec1d465":"# \uc81c\ucd9c","16f72ea8":"# \ubc94\uc8fc\ud615 \ub370\uc774\ud130 \ucc98\ub9ac\n","d49e2c99":"# \ud06c\ub864\ub9c1","4d4b99fa":"# \ud1b5\uacc4 \uac80\uc815\n\n1. https:\/\/datascienceschool.net\/02%20mathematics\/09.05%20%EC%82%AC%EC%9D%B4%ED%8C%8C%EC%9D%B4%EB%A5%BC%20%EC%82%AC%EC%9A%A9%ED%95%9C%20%EA%B2%80%EC%A0%95.html\n\n2. https:\/\/blog.naver.com\/ostin1038\/222381788634","e8524347":"![image.png](attachment:9a7a594d-eab0-4924-9dcf-a29f4bd8f67a.png)","c8d406ee":"# \ud544\ud130\ub9c1","c4423eb5":"# \uc804\ucc98\ub9ac","bf9b8a9c":"# \uacb0\uce21\uac12 \ucc98\ub9ac","c8bf66f7":"ANOVA\n![image.png](attachment:7a616d08-cff8-43a3-87c9-bc51e39616d0.png)![image.png](attachment:dc0e9d43-7986-4d53-839e-01ef9721c05c.png)","3dceed8c":"# PCA \ubc0f \uad70\uc9d1\ud654","b96b353c":"# \uc14b\uc5c5 \ubc0f \uae30\ud0c0"}}