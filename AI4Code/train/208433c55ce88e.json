{"cell_type":{"6f786d03":"code","3e7faaf2":"code","fe8a6728":"code","2fb3700e":"markdown","4c63ac23":"markdown","fe635d82":"markdown","3d6b1693":"markdown"},"source":{"6f786d03":"from IPython.display import YouTubeVideo\n\nYouTubeVideo('I6UWNzE7XNQ')","3e7faaf2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nimport torch\nimport torch.nn as nn\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe8a6728":"def double_conv(in_c, out_c):\n    conv = nn.Sequential(\n        nn.Conv2d(in_c, out_c, kernel_size=3),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(out_c, out_c, kernel_size=3),\n        nn.ReLU(inplace=True)\n    )\n    return conv\n\ndef crop_tensor(tensor, target_tensor):\n    '''\n    Adjusting the shapes of layers to concatenate\n    \n    '''\n    target_size = target_tensor.size()[2]\n    tensor_size = tensor.size()[2]\n    # Assuming tensor size is larger than target size\n    delta = tensor_size - target_size\n    delta = delta \/\/ 2\n    return tensor[:,:, delta:tensor_size-delta, delta:tensor_size-delta] # adjusting the height and width for concatenation\n\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n    \n        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.down_conv_1 = double_conv(1,64)\n        self.down_conv_2 = double_conv(64,128)\n        self.down_conv_3 = double_conv(128,256)\n        self.down_conv_4 = double_conv(256,512)\n        self.down_conv_5 = double_conv(512,1024)\n    \n        self.up_trans_1 = nn.ConvTranspose2d(in_channels = 1024,\n                                             out_channels = 512,\n                                             kernel_size =2, \n                                             stride=2)\n        \n        self.up_conv_1 = double_conv(1024, 512)\n        \n        \n        self.up_trans_2 = nn.ConvTranspose2d(in_channels = 512,\n                                             out_channels = 256,\n                                             kernel_size =2, \n                                             stride=2)\n        \n        self.up_conv_2 = double_conv(512, 256)\n        \n        \n        self.up_trans_3 = nn.ConvTranspose2d(in_channels = 256,\n                                             out_channels = 128,\n                                             kernel_size =2, \n                                             stride=2)\n        \n        self.up_conv_3 = double_conv(256, 128)\n        \n        \n        self.up_trans_4 = nn.ConvTranspose2d(in_channels = 128,\n                                             out_channels = 64,\n                                             kernel_size =2, \n                                             stride=2)\n        \n        self.up_conv_4 = double_conv(128, 64)\n        \n        self.out = nn.Conv2d(\n            in_channels = 64,\n            out_channels = 2,\n            kernel_size = 1\n        )\n        \n    \n    def forward(self, image):\n        #batch_size, channels, height, width\n        \n        # encoder\n        x1 = self.down_conv_1(image) \n        x2 = self.max_pool_2x2(x1)\n        x3 = self.down_conv_2(x2) \n        x4 = self.max_pool_2x2(x3)\n        x5 = self.down_conv_3(x4) \n        x6 = self.max_pool_2x2(x5)\n        x7 = self.down_conv_4(x6) \n        x8 = self.max_pool_2x2(x7)\n        x9 = self.down_conv_5(x8)\n        \n        #decoder\n        x = self.up_trans_1(x9)\n        #concatenate x with x7, before that we crop x7\n        y = crop_tensor(x7, x)\n        x = self.up_conv_1(torch.cat([x,y],1))\n        \n        x = self.up_trans_2(x)\n        y = crop_tensor(x5, x)\n        x = self.up_conv_2(torch.cat([x,y],1))\n        \n        x = self.up_trans_3(x)\n        y = crop_tensor(x3, x)\n        x = self.up_conv_3(torch.cat([x,y],1))\n        \n        x = self.up_trans_4(x)\n        y = crop_tensor(x1, x)\n        x = self.up_conv_4(torch.cat([x,y],1))\n        \n        x = self.out(x)\n        print(x.size())\n        return x\n        \n        \nif __name__ == \"__main__\":\n    image = torch.rand((1,1,572,572))\n    model = UNet()\n    print(model(image))","2fb3700e":"# Model layout","4c63ac23":"# Introduction\nI have implemented a simple UNet model architecture from a 2015 arxiv paper on [Biomedical Image Segmentation](https:\/\/arxiv.org\/abs\/1505.04597)\nHere is my GitHub repo for the [same](https:\/\/github.com\/digs1998\/UNets-from-Scratch)\n\nIf you like my work please do upvote my notebook!!","fe635d82":"# UNet Architecture\nWe will be working on implementing the below shown architecture which is taken from the arxiv research paper\n\n![model_layout](https:\/\/github.com\/digs1998\/UNets-from-Scratch\/raw\/master\/model_layout.PNG)","3d6b1693":"# UNet Introduction \nBelow I have shared an video which will help you understand few points about UNet"}}