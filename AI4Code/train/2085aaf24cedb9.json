{"cell_type":{"fec2968e":"code","2b787240":"code","01d030b3":"code","ec91531d":"code","a3883e46":"code","1b9e9fcf":"code","0f6df08b":"code","32beb95f":"code","dd9f04fb":"code","69b8b41a":"code","649880d7":"code","273be509":"markdown","7f3c7883":"markdown","8775b7ce":"markdown","2e81bd96":"markdown","34001580":"markdown","9ad9ab7f":"markdown","c3c7a610":"markdown","a38ba4ea":"markdown","921d87c6":"markdown","e50b1b82":"markdown"},"source":{"fec2968e":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom nltk.tokenize import RegexpTokenizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression","2b787240":"df = pd.read_csv(\"\/kaggle\/input\/amazon-alexa-reviews\/amazon_alexa.tsv\",sep=\"\\t\")\ndf.head()","01d030b3":"# Count plot\nsns.countplot(x='feedback', data=df)\n# Set X-axis and Y-axis labels\nplt.xlabel('Sentiment Score')\nplt.ylabel('Number of Records')\n# Show the plot using show() function\nplt.show()","ec91531d":"#Create Regex tokenizer for removing special symbols and numeric values\nregex_tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n# Initialize CountVectorizer object\ncount_vectorizer = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = regex_tokenizer.tokenize)\n# Fit and transform the dataset\ncount_vectors = count_vectorizer.fit_transform(df['verified_reviews'])","a3883e46":"# Partition data into training and testing set\nfeature_train, feature_test, target_train, target_test = train_test_split(count_vectors, df['feedback'],\n                                                                        test_size=0.3, random_state=1)","1b9e9fcf":"# Create logistic regression model object\nlogreg = LogisticRegression(solver='lbfgs')\n# fit the model with data\nlogreg.fit(feature_train,target_train)\n# Forecast the target variable for given test dataset\npredictions = logreg.predict(feature_test)","0f6df08b":"# Assess model performance using accuracy measure\nprint(\"Logistic Regression Model Accuracy: \", accuracy_score(target_test, predictions))\n# Calculate model precision\nprint(\"Logistic Regression Model Precision: \", precision_score(target_test, predictions))\n# Calculate model recall\nprint(\"Logistic Regression Model Recall: \", recall_score(target_test,predictions))\n# Calculate model f1 score\nprint(\"Logistic Regression Model F1-Score: \", f1_score(target_test,predictions))","32beb95f":"# Create Regex tokenizer for removing special symbols and numeric values\nregex_tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n# Initialize TfidfVectorizer object\ntfidf = TfidfVectorizer(lowercase=True, stop_words='english',ngram_range = (1,1),tokenizer = regex_tokenizer.tokenize)\n# Fit and transform the dataset\ntext_tfidf = tfidf.fit_transform(df['verified_reviews'])","dd9f04fb":"# Partition data into training and testing set\nX_train, X_test, y_train, y_test = train_test_split(text_tfidf, df['feedback'],\n                                                                        test_size=0.3, random_state=1)","69b8b41a":"# instantiate the model\nlogreg = LogisticRegression(solver='lbfgs')\n# fit the model with data\nlogreg.fit(X_train,y_train)\n# Forecast the target variable for given test dataset\npredictions = logreg.predict(X_test)","649880d7":"# Assess model performance using accuracy measure\nprint(\"Logistic Regression Model Accuracy:\",accuracy_score(y_test, predictions))\n# Calculate model precision\nprint(\"Logistic Regression Model Precision:\",precision_score(y_test, predictions))\n# Calculate model recall\nprint(\"Logistic Regression Model Recall:\",recall_score(y_test,predictions))\n# Calculate model f1 score\nprint(\"Logistic Regression Model F1-Score:\",f1_score(y_test,predictions))","273be509":"## Feature generation using TfidfVectorizer","7f3c7883":"Let's generate a TF-IDF matrix for the customer reviews using TfidfVectorizer","8775b7ce":"Let's generate a BoW matrix for the customer reviews using CountVectorizer","2e81bd96":"## Generating features using CountVectorizer","34001580":"## Explore the dataset","9ad9ab7f":"All the measures are greater than 94%, so we can say that our model is performing well and classifying both the sentiment levels with a good amount of precision and recall.","c3c7a610":"The accuracy and precision gave lower values than in the previous case, the recall was higher, but in the end the f1-score was similar to the previous one. ","a38ba4ea":"We will build the logistic regression model to classify the review\nsentiments using BoW (or CountVectorizer). ","921d87c6":"In this plot, we can observe that 2,900 reviews are positive and\n250 reviews are negative feedback.","e50b1b82":"We will build the logistic regression model to classify the review sentiments using TF-IDF"}}