{"cell_type":{"6b0e0eab":"code","5655119b":"code","3f739ceb":"code","1f225ca5":"code","e80b28fc":"code","b2d1fc57":"code","d72b000a":"code","a41f2d29":"code","777c1da0":"code","4568a8ee":"code","b1415d59":"code","30626776":"code","5a4a277e":"code","ce1b4934":"code","9d19b8e0":"code","d32d1561":"code","6bdeed9c":"code","4507d194":"code","57f60ea5":"code","5a6b9a78":"code","756089a6":"code","866a6c5a":"code","3a84333d":"code","48e3190f":"code","0b553478":"code","f2237f24":"code","8c5c1db7":"code","93178dcd":"code","ff15eda1":"code","a1dc907f":"code","d46b3193":"code","95e0d1ea":"code","de9fedaa":"code","4469fe0b":"code","00db3304":"markdown"},"source":{"6b0e0eab":"import pandas as pd, numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5655119b":"train = pd.read_csv(r'..\/input\/car-price\/train set.csv')","3f739ceb":"train.head(2)","1f225ca5":"test  = pd.read_csv(r\"..\/input\/car-price\/test set.csv\")","e80b28fc":"test.head(2)","b2d1fc57":"names = [x.split(' ')[0] for x in list(train['name'])]","d72b000a":"train.insert(0,'brand',names)","a41f2d29":"train= train.drop(['name','seller_type','owner','torque','fuel'],axis=1)","777c1da0":"train['engine'] = [int(x.split(' ')[0]) for x in list(train['engine'])];","4568a8ee":"train['mileage'] = [float(x.split(' ')[0]) for x in list(train['mileage'])]\ntrain['max_power'] = [float(x.split(' ')[0]) for x in list(train['max_power'])]","b1415d59":"train.head(2)","30626776":"num_features = [x for x in train.columns if type(train[x][0]) is not str]\ncat_features = [x for x in train.columns if x not in num_features]","5a4a277e":"import seaborn as sns, matplotlib.pyplot as plt\n\nsns.barplot(y=train['brand'], x=train['selling_price'])\nplt.show()","ce1b4934":"import seaborn as sns, matplotlib.pyplot as plt\n\nsns.barplot(x=train['transmission'], y=train['selling_price'])\nplt.show()","9d19b8e0":"train['transmission'] = [0 if x == 'Manual' else 1 for x in train['transmission']]","d32d1561":"train.head(3)","6bdeed9c":"train['brand'] = [0 if x <= 1000000 else 1 if x <= 2000000 else 2 if x <= 4000000 else 3 for x in train['selling_price'] ]","4507d194":"train.head(3)","57f60ea5":"X_train = train.drop('selling_price', axis=1).values[0:6850]\ny_train = train['selling_price'].values[0:6850]","5a6b9a78":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_X_train = scaler.fit_transform(X_train) ","756089a6":"#import multiple regression classes for data modeling\nfrom sklearn.neighbors import KNeighborsRegressor as KNR, RadiusNeighborsRegressor as RNR\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LinearRegression as LR, Perceptron\nfrom sklearn.neural_network import MLPRegressor as MLPR\nfrom sklearn.ensemble import RandomForestRegressor as RFR","866a6c5a":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import *\nfrom math import sqrt\nmcc= make_scorer(mean_absolute_error)","3a84333d":"# create function to evaluate the model\ndef evaluate_model(model):\n    model = model\n    # evaluate the model\n    import sklearn\n    scores = cross_val_score(model, scaled_X_train, y_train,\n                             scoring= mcc,\n                             cv=5, n_jobs=-1)\n    # return scores\n    return scores.mean()","48e3190f":"models = [KNR(),RNR(),LR(), RFR(n_estimators=300),\n         Perceptron(), SVR(),MLPR()]\nmodels_names = ['K_neighbors','radius_neighbors','linear_regression', 'random_forest_regressor',\n               'perceptron', 'SVR', 'MLP_Regression']\n\n# record mean error\n\nscores = list()\n\nfor clf,clf_name in zip(models,models_names):    \n    # evaluate model with k_value=5\n    k_mean = evaluate_model(clf)\n    # report performance\n    print(f'score of {clf_name} :  ', round(k_mean,3))\n    # store mean accuracy\n    scores.append(k_mean)","0b553478":"#select model with best performance on cross validation\n\nmodel = models[3]\nprint(model)","f2237f24":"model.fit(scaled_X_train, y_train)","8c5c1db7":"train_prediction = model.predict(scaled_X_train)\n#convert predicted values to integers\ntrain_pred = [int(x) for x in train_prediction.round()]\ntrain_prediction = np.array(train_pred)","93178dcd":"print('Train R.M.S.E : ', sqrt(mean_squared_error(y_train,train_prediction)))","ff15eda1":"def transform(df):\n    brand = [x.split(' ')[0] for x in list(df['name'])]\n    df.insert(0,'brand',brand)\n    df.drop(['name','seller_type','owner','torque','fuel'],axis=1, inplace=True)\n    df['engine'] = [int(x.split(' ')[0]) for x in list(df['engine'])]\n    df['mileage'] = [float(x.split(' ')[0]) for x in list(df['mileage'])]\n    df['max_power'] = [float(x.split(' ')[0]) for x in list(df['max_power'])]\n    df['transmission'] = [0 if x == 'Manual' else 1 for x in df['transmission']]\n    df['brand'] = [0 if x <= 1000000 else 1 if x <= 2000000 else 2 if x <= 4000000 else 3 for x in df['selling_price']]\n    X = df.drop('selling_price', axis=1).values\n    y = df['selling_price'].values\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X) \n    \n    return X, y ","a1dc907f":"X_test, y_test = transform(test)","d46b3193":"test_prediction = model.predict(X_test)\n#convert predicted values to integers\ntest_pred = [int(x) for x in test_prediction.round()]\ntest_prediction = np.array(test_pred)","95e0d1ea":"print('Test R.M.S.E : ', sqrt(mean_squared_error(y_test,test_prediction)))","de9fedaa":"model = models[3]\ntrees, train_loss, test_loss = [], [], []\n\nfor iter in range(10):\n    model.fit(scaled_X_train, y_train)\n    y_train_predicted = model.predict(scaled_X_train)\n    y_train_predicted = [int(x) for x in y_train_predicted.round()]\n    y_train_predicted = np.array(y_train_predicted)\n    y_test_predicted = model.predict(X_test)\n    y_test_predicted = [int(x) for x in y_test_predicted.round()]\n    y_test_predicted = np.array(y_test_predicted)\n    rmse_train = sqrt(mean_squared_error(y_train, y_train_predicted))\n    rmse_test = sqrt(mean_squared_error(y_test, y_test_predicted))\n    print(\"Iteration: {} Train rmse: {} Test rmse: {}\".format(iter, rmse_train, rmse_test))\n    trees.append(model.n_estimators)\n    train_loss.append(rmse_train)\n    test_loss.append(rmse_test)\n    model.n_estimators += 10","4469fe0b":"#plot how model performs with hyper parameter base estimators number increased\n\nplt.figure(figsize=(8,6))  \nplt.plot(trees, train_loss, color=\"blue\", label=\"MSE on Train data\")\nplt.plot(trees, test_loss, color=\"red\", label=\"MSE on Test data\")\nplt.xlabel(\"# of trees\")\nplt.ylabel(\"Mean Squared Error\");\nplt.legend()","00db3304":"The model is overfitting as seen in the performance on the test results. Let's try to finetune the number of base estimators to see how model performs on test data."}}