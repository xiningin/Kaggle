{"cell_type":{"385bee3e":"code","4b4f9532":"code","4c56d308":"code","1b47c0e8":"code","3e7cfade":"code","8780c34b":"code","f6f956bf":"code","737851fc":"code","ac84123d":"code","7c70f166":"code","a7472082":"code","50728b26":"code","3f408e10":"code","e0b0ec3c":"code","2c00eb9f":"code","174a9362":"code","05f16860":"code","6166df1a":"code","a57bbe27":"code","125eb4d0":"code","7d002bb1":"code","8920983e":"code","5717b9d4":"code","5a75220f":"code","9c81f332":"code","d8e72348":"code","a4c43b57":"code","f1acbdcd":"code","766bf98f":"code","eef7c0e0":"code","aeb16024":"code","2d6005d2":"code","13b06944":"code","d75f75eb":"code","7f13c956":"code","2262b434":"code","0b22698f":"code","25a8db79":"code","d35bf546":"code","667abf24":"code","61026e51":"code","04d98d2c":"code","36d51ad0":"code","deae5a71":"code","c4ace9c0":"code","c47e6c13":"code","5cfa1676":"code","f87fcd68":"code","78c95935":"code","e5916667":"code","83354197":"code","6d133683":"code","ba4ed426":"code","deb4c716":"code","aa2e1be2":"code","6ed41a55":"code","79876519":"code","9ae2e8bd":"code","8616b535":"code","8e160088":"code","e99392e9":"code","601b0ab3":"code","3feb6d74":"code","1f6b7a1a":"code","70e2de10":"code","e63f5203":"markdown","e13f4dc7":"markdown","e1005fa3":"markdown","b99cdd9a":"markdown","5775a200":"markdown","8edc3b57":"markdown","cb8df845":"markdown","de492582":"markdown"},"source":{"385bee3e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b4f9532":"train_data=pd.read_csv(\"..\/input\/titanic\/train.csv\") \ntrain_data.head(10)","4c56d308":"train_data.describe()","1b47c0e8":"train_data.var()","3e7cfade":"train_data.info()","8780c34b":"train_data.isna().sum()","f6f956bf":"train_data.plot.hist()","737851fc":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno","ac84123d":"msno.bar(train_data)\nplt.show()","7c70f166":"sns.countplot(train_data.PassengerId)\nplt.show()","a7472082":"sns.countplot(train_data.Survived)\nplt.show()","50728b26":"sns.countplot(train_data.Pclass)\nplt.show()","3f408e10":"sns.countplot(train_data.Age)\nplt.show()","e0b0ec3c":"sns.countplot(train_data.SibSp)\nplt.show()","2c00eb9f":"sns.countplot(train_data.Parch)\nplt.show()","174a9362":"sns.countplot(train_data.Fare)\nplt.show()","05f16860":"values = train_data['Survived'].value_counts()\nlabels = ['Not Survived', 'Survived']\n\nfig, ax = plt.subplots(figsize = (5, 5), dpi = 100)\nexplode = (0, 0.06)\n\npatches, texts, autotexts = ax.pie(values, labels = labels, autopct = '%1.2f%%', shadow = True,\n                                   startangle = 90, explode = explode)\n\nplt.setp(texts, color = 'grey')\nplt.setp(autotexts, size = 12, color = 'white')\nautotexts[1].set_color('black')\nplt.show()","6166df1a":"train_data.Pclass.value_counts()","a57bbe27":"train_data.groupby(['Pclass', 'Survived'])['Survived'].count()","125eb4d0":"train_data.Name.value_counts()","7d002bb1":"len(train_data.Name.unique()), train_data.shape","8920983e":"train_data.Sex.value_counts()","5717b9d4":"train_data.groupby(['Sex', 'Survived'])['Survived'].count()","5a75220f":"train_data['SibSp'].value_counts()","9c81f332":"train_data.Parch.value_counts()","d8e72348":"train_data.Ticket.value_counts()","a4c43b57":"len(train_data.Ticket.unique())","f1acbdcd":"train_data['Embarked'].value_counts()","766bf98f":"train_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1, inplace = True)","eef7c0e0":"train_data.head()","aeb16024":"train_data.isnull().sum()","2d6005d2":"# replacing Zero values of \"fare\" column with mean of column\n\ntrain_data['Fare'] = train_data['Fare'].replace(0, train_data['Fare'].mean())","13b06944":"#replacing Age value of \"Age\" column with mean of column\n\ntrain_data['Age'].fillna(train_data['Age'].mean(), inplace = True)","d75f75eb":"# filling null values of \"Embarked\" column with mode value of the column\n\ntrain_data['Embarked'].fillna(train_data['Embarked'].mode()[0], inplace = True)","7f13c956":"# checking for null values after filling null values\n\ntrain_data.isna().sum()","2262b434":"train_data.head()","0b22698f":"train_data['Sex'] = train_data['Sex'].apply(lambda val: 1 if val == 'male' else 0)","25a8db79":"train_data['Embarked'] = train_data['Embarked'].map({'S' : 0, 'C': 1, 'Q': 2})","d35bf546":"train_data.head()","667abf24":"train_data.describe()","61026e51":"train_data.var()","04d98d2c":"train_data['Age'] = np.log(train_data['Age'])\ntrain_data['Fare'] = np.log(train_data['Fare'])","36d51ad0":"train_data.head()","deae5a71":"test_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_data.head()","c4ace9c0":"test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1, inplace = True)","c47e6c13":"test_data['Fare'] = test_data['Fare'].replace(0, test_data['Fare'].mean())","5cfa1676":"test_data['Age'].fillna(test_data['Age'].mean(), inplace = True)","f87fcd68":"test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace = True)","78c95935":"test_data.isna().sum()","e5916667":"test_data['Fare'].fillna(test_data['Fare'].mean(), inplace = True)","83354197":"test_data['Sex'] = test_data['Sex'].apply(lambda val: 1 if val == 'male' else 0)","6d133683":"test_data['Embarked'] = test_data['Embarked'].map({'S' : 0, 'C': 1, 'Q': 2})","ba4ed426":"test_data.head()","deb4c716":"test_data['Age'] = np.log(test_data['Age'])\ntest_data['Fare'] = np.log(test_data['Fare'])","aa2e1be2":"test_data.var()","6ed41a55":"test_data.isna().any()","79876519":"test_data.head()","9ae2e8bd":"X = train_data.drop('Survived', axis = 1)\ny = train_data['Survived']","8616b535":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)","8e160088":"from sklearn.linear_model import LogisticRegression","e99392e9":"lr = LogisticRegression()\nlr.fit(X_train, y_train)","601b0ab3":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nlr_acc = accuracy_score(y_test, lr.predict(X_test))\n\nprint(f\"Training Accuracy of Logistic Regression is {accuracy_score(y_train, lr.predict(X_train))}\")\nprint(f\"Test Accuracy of Logistic Regression is {lr_acc}\")\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, lr.predict(X_test))}\")\nprint(f\"Classofocation Report : -\\n {classification_report(y_test, lr.predict(X_test))}\")","3feb6d74":"#hyper parameter tuning \n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_param = {\n    'penalty': ['l1', 'l2'],\n    'C' : [0.001, 0.01, 0.1, 0.005, 0.5, 1, 10]\n}\n\ngrid_search_lr = GridSearchCV(lr, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_lr.fit(X_train, y_train)","1f6b7a1a":"print(grid_search_lr.best_params_)\nprint(grid_search_lr.best_score_)","70e2de10":"lr = grid_search_lr.best_estimator_\n\n# accuracy score, confusion matrix and classification report of logistic regression\n\nlr_acc = accuracy_score(y_test, lr.predict(X_test))\n\nprint(f\"Training Accuracy of Logistic Regression is {accuracy_score(y_train, lr.predict(X_train))}\")\nprint(f\"Test Accuracy of Logistic Regression is {lr_acc}\")\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, lr.predict(X_test))}\")\nprint(f\"Classofocation Report : -\\n {classification_report(y_test, lr.predict(X_test))}\")","e63f5203":"**LOGISTIC REGRESSION**","e13f4dc7":"**Variance in \"Fare\" column is very high so we have to normalize these columns.**","e1005fa3":"**Titanic Test data**","b99cdd9a":"**DATA VISUALIZATION**","5775a200":"**DATA CLEANING IN TRAIN DATA(CSV FILE)**","8edc3b57":"**DATA PRE-PROCESSING**","cb8df845":"**TO PERFORM THE MACHINE LEARNING MODELS**","de492582":"**To cleaning the test data**"}}