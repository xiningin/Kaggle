{"cell_type":{"65a947de":"code","538bf8cf":"code","fa4fd7dd":"code","89fd5d2b":"code","bd34a0c3":"code","4d4c7ba5":"code","76f83f41":"code","eb8d0533":"code","5407f04d":"code","2b85e0b5":"code","add70386":"code","fe6e02ae":"code","d0466d59":"code","a97e13a6":"code","638058fa":"code","7b994910":"code","2c1f3e5d":"code","99aec7a5":"code","50940dc1":"code","20b83811":"code","8e08c235":"code","87df4719":"code","799c9c8e":"code","099cc814":"code","c2a50239":"code","9bda7e20":"code","f64595f2":"code","4dd38f46":"code","8decfca0":"code","22b9d769":"code","bcb51e1a":"code","87145cc5":"code","27e84e09":"code","cea62aab":"code","517a6e3f":"code","edd14ff3":"code","0cca2d58":"code","89cbc708":"code","9669071e":"code","bca5bb37":"code","cddd8ff2":"code","1dccaf22":"code","da12affb":"code","9b22637f":"code","e86d1544":"code","98141dbb":"code","269ff9fa":"code","2d69dcec":"code","23d00981":"code","4f632870":"code","501d9cae":"code","de362019":"code","a71b1b85":"code","a2aabc5f":"code","17a27b06":"code","4d0f27c1":"code","76e1ff80":"code","95f43a8a":"code","bcaf4d9b":"code","8daf054b":"code","325c3e76":"markdown","10117453":"markdown","16e5348c":"markdown","3b0ae37c":"markdown","218e5189":"markdown","e3984639":"markdown","a8b29995":"markdown","f55ae3e9":"markdown","2adb6429":"markdown","3c6022e9":"markdown","63a58148":"markdown","c4155b61":"markdown","a7deb8cc":"markdown","71c289a1":"markdown","00d54016":"markdown","0f59e66b":"markdown","582a803c":"markdown","da5540b4":"markdown","b210730b":"markdown","6ae2e211":"markdown","e8ead5c1":"markdown"},"source":{"65a947de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","538bf8cf":"# usual imports\nimport pandas as pd\nimport numpy as np\n\n# handle os specific\nimport os\n\n# randomization\nimport random\n\n# visualization imports \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n%matplotlib inline\n\n# consistent plot size\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 17,7\nrcParams['axes.labelsize'] = 14\nrcParams['xtick.labelsize'] = 8\nrcParams['ytick.labelsize'] = 8\nrcParams['axes.titlesize'] = 16\n \n# ignore deprecated and future warnings\nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)","fa4fd7dd":"# check the root dir\nos.listdir('\/kaggle\/input')","89fd5d2b":"# set the path\nROOT_DIR = '\/kaggle\/input'\nFILE_PATH = os.path.join(ROOT_DIR,'logical-rythm-2k20-sports-image-classification')","bd34a0c3":"# LIST DIRCTORIES INSIDE THE FILE PATH\nos.listdir(FILE_PATH)","4d4c7ba5":"# SET THE TRAINING AND THE TEST PATH\nTRAIN_PATH = os.path.join(FILE_PATH,'train')\nTEST_PATH = os.path.join(FILE_PATH,'test')","76f83f41":"os.listdir(TRAIN_PATH)","eb8d0533":"os.listdir(TEST_PATH)","5407f04d":"TRAIN_IMAGES = os.path.join(TRAIN_PATH,'train')\nTEST_IMAGES = os.path.join(TEST_PATH,'test')","2b85e0b5":"len(os.listdir(TRAIN_IMAGES))","add70386":"len(os.listdir(TEST_IMAGES))","fe6e02ae":"# READ THE TRAIN csv FILE CONTAINING THE SPORTS LABEL\ntrain_df = pd.read_csv(os.path.join(FILE_PATH,'train_labels.csv'))","d0466d59":"# READ THE test csv FILE\ntest_df = pd.read_csv(os.path.join(FILE_PATH,'test_images_list.csv'))\ntest_df.tail()","a97e13a6":"# LIST THE FIRST FEW ROWS\ntrain_df.head(10)","638058fa":"train_df.info()","7b994910":"len(train_df['sports'].unique())","2c1f3e5d":"# Extract the unique labels\nsports_labels = train_df['sports'].unique()","99aec7a5":"# LIST THE SPORTS NAME INCLUDED IN THE DATASET\nsports_labels","50940dc1":"# CHECK ONE OF THE IMAGES -- > LETS PICK THE FIRST IN THE LIST\nplt.imshow(imread(os.path.join(TRAIN_IMAGES,'0.jpg')));","20b83811":"# CHECK THE CLASS NAME OF THE DISPLAYED SPORT\ntrain_df['sports'][0]","8e08c235":"# IMAGE COUNT PER SPORT\ntrain_df['sports'].value_counts()","87df4719":"# VISUALIZE IMAGE COUNT PER SPORT\nsns.countplot(train_df['sports'],palette='viridis')\nplt.title('Images per Sports',)\nplt.ylabel('Number of images')\nplt.xlabel('Sports Name')\nplt.tight_layout()","799c9c8e":"# PICK A RANDOM SPORTS\nx = random.randint(0,len(train_df['sports'].unique()))\nrandom_sport = sports_labels[x]\n\nsports_show = train_df[train_df['sports']==random_sport]\nprint(f'The selected sport to display various images is {random_sport.upper()}')\nsports_show.head()","099cc814":"# DISPLAY THE SPORTS IMAGES --- > NOTICE THE VARIATION IN THE IMAGES OF THE SAME SPORT\nn_rows = 3\nn_cols = 4\n\nfor row in range(n_rows):\n    for col in range(n_cols):\n        index = n_cols * row + col\n        plt.subplot(n_rows,n_cols,index+1)\n        # PICK RANDOM IMAGES OF THE SELECTED SPORT\n        sport_img = random.randint(0,len(sports_show))\n        image_ = plt.imread(os.path.join(TRAIN_IMAGES,sports_show.iloc[sport_img]['image'][8:]))\n        # DISPLAY THE IMAGE\n        plt.imshow(image_,cmap='binary',interpolation='nearest')\n        #plt.axis('off')\n        rcParams['axes.titlesize']= 12\n        #plt.title(random_sport)  ","c2a50239":"# RETRIEVE THE DIMENSION OF ALL THE TRAINING IMAGES\n#dim1 = []\n#dim2 = []\n\n#for image in os.listdir(TRAIN_IMAGES):\n #   img = imread(os.path.join(TRAIN_IMAGES,image))\n  #  d1,d2 = img.shape[0], img.shape[1]\n   # dim1.append(d1)\n    #dim2.append(d2)  ","9bda7e20":"#print(f'Dimension 1 range is {np.min(dim1)} to {np.max(dim1)} and the range for dimension 2 is {np.min(dim2)} to {np.max(dim2)}')","f64595f2":"# CHECK THE MODE OF THE DIMENSIONS\n#from statistics import mode\n#print (f'The most frequently occuring dimensions are {mode(dim1)} and {mode(dim2)}')","4dd38f46":"# TAKE THE MEAN OF THE DIMENSIONS OF THE IMAGES AND SET IT AS INPUT SHAPE, PLUS ANOTHER DIMENSION FOR COLOR\n#IMAGE_SHAPE = (int(np.mean(dim1)),int(np.mean(dim2)),3)","8decfca0":"IMAGE_SHAPE = (224,224,3)","22b9d769":"# IMPORT THE REQUIRED KERAS LIBRARIES FOR IMAGE AUGMENTATION\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","bcb51e1a":"#help(ImageDataGenerator)","87145cc5":"#from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.applications.xception import preprocess_input","27e84e09":"image_generator = ImageDataGenerator(    \n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    brightness_range=None,\n    shear_range=0.5,\n    zoom_range=[0.5,1.8],\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=True,\n    vertical_flip=False,\n    rescale=1.\/255,\n    preprocessing_function=preprocess_input,\n    data_format=None,\n    validation_split=0.2,\n    dtype= 'float32'\n)","cea62aab":"# DISPLAY THE ORIGINAL AND THE GENERATED IMAGES\nimage = imread(os.path.join(TRAIN_IMAGES,'129.jpg'))\nplt.imshow(image)","517a6e3f":"gen_image = image_generator.random_transform(image)\nplt.imshow(gen_image)","edd14ff3":"# DEFINE THE BATCH SIZE - --- > THIS IS USED AS AN INPUT WHILE FITTING THE MODEL USING GENERATORS\nBATCH_SIZE = 32","0cca2d58":"# CREATE THE TRAINING GENERATOR \ntrain_generator = image_generator.flow_from_dataframe(dataframe=train_df,\n                                                      directory=TRAIN_PATH,\n                                                      x_col='image',\n                                                      y_col='sports',\n                                                      subset='training',\n                                                      color_mode='rgb',\n                                                      batch_size=BATCH_SIZE,\n                                                      seed=42,\n                                                      shuffle=True,\n                                                      class_mode='categorical',\n                                                      target_size=(224,224))\n\ntrain_generator","89cbc708":"# CREATE THE VALIDATION GENERATOR \nvalidation_generator = image_generator.flow_from_dataframe(dataframe=train_df,\n                                                           directory=TRAIN_PATH,\n                                                           x_col='image',\n                                                           y_col='sports',\n                                                           subset='validation',\n                                                           color_mode='rgb',\n                                                           batch_size=BATCH_SIZE,\n                                                           seed=42,\n                                                           shuffle=False,\n                                                           class_mode='categorical',\n                                                           target_size=(224,224))\n\nvalidation_generator","9669071e":"# TEST GENERATOR ... NO SHUFFLE & CLASS MODE SET TO NONE\ntest_generator = image_generator.flow_from_dataframe(dataframe=test_df,\n                                                     directory=TEST_PATH,\n                                                     x_col='image',\n                                                     y_col=None,\n                                                     batch_size=BATCH_SIZE,\n                                                     color_mode='rgb',\n                                                     seed=42,\n                                                     shuffle=False,\n                                                     class_mode=None,\n                                                     target_size=(224,224))\n\ntest_generator","bca5bb37":"## IMPORT THE LIBRARIES\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import SGD,Adam\nfrom tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPool2D,AvgPool2D,GlobalMaxPool2D,Flatten,MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import CSVLogger","cddd8ff2":"trial = 4","1dccaf22":"if trial==1: # Basic Model\n    \n        \n    ## DEFINE THE BASIC MODEL\n    model =  Sequential()\n\n    # ADD CONVOLUTIONAL LAYERS and MaxPooling Layer -- > Typical CNN Model\n    model.add(Conv2D(filters=32,kernel_size=(7,7),input_shape=IMAGE_SHAPE,strides=1,padding='same',activation='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n        \n    model.add(Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n        \n    model.add(Conv2D(filters=128,kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n        \n    model.add(Conv2D(filters=256,kernel_size=(3,3),strides=1,padding='same',activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n        \n    # ADD DENSE LAYERS\n    model.add(Flatten())\n    model.add(Dense(units=512,activation='relu'))\n    model.add(Dense(units=128,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(units=22,activation='softmax'))\n    \n    \n    # COMPILE THE BASIC MODEL \n    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])  \n       \n    # PRINT MODEL SUMMARY\n    print('BASIC MODEL')\n    model.summary()\n    \nelif trial==2: # Batch Normalization plus selu actiovation and lecun-normal kernel initializer\n    model = Sequential()\n    \n    # Add the CNN layers \n    model.add(Conv2D(filters=32,input_shape=IMAGE_SHAPE,padding='same',kernel_size=(3,3),activation='relu'))\n    model.add(MaxPooling2D(2,2))\n    \n    model.add(Conv2D(filters=64,padding='same',kernel_size=(3,3),activation='relu'))\n    model.add(MaxPooling2D(2,2))\n    \n    model.add(Conv2D(filters=128,padding='same',kernel_size=(3,3),activation='relu'))\n    model.add(MaxPooling2D(2,2))\n    \n    # ADD THE DNN LAYERS\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    \n    model.add(Dense(units=256,activation='selu',kernel_initializer='lecun_normal',use_bias=False))\n    model.add(BatchNormalization())\n    \n    model.add(Dense(units=128,activation='selu',kernel_initializer='lecun_normal',use_bias=False))\n    model.add(BatchNormalization())\n    \n    model.add(Dense(units=64,activation='selu',kernel_initializer='lecun_normal',use_bias=False))\n    model.add(BatchNormalization())\n    \n    model.add(Dense(units=32,activation='selu',kernel_initializer='lecun_normal',use_bias=False))\n    model.add(BatchNormalization())\n    \n    model.add(Dense(units=22,activation='softmax'))\n    \n    # COMPILE THE MODEL\n    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    print('Model with Batch Normalization')\n    model.summary()\n    \nelif trial==3:    # VGG16 Pre Trained Model - SGD as well as Adam -- > Adam performs faster and returns better accuracy\n    base_model = VGG16(include_top=False,input_shape=(224,224,3),weights='imagenet')\n    # mark loaded layers as not trainable\n    for layer in base_model.layers:\n        layer.trainable = False\n    # add new classification layers\n    flat1 = Flatten()(base_model.layers[-1].output)\n    class1 = Dense(512,activation='relu',kernel_initializer='he_normal')(flat1)\n    class2 = Dense(256,activation='relu',kernel_initializer='he_normal')(class1)\n    class3 = Dense(128,activation='relu',kernel_initializer='he_normal')(class2)\n    output = Dense(22,activation='softmax')(class3)\n    # define new model\n    model = Model(inputs=base_model.inputs,outputs=output)\n    #compile the model\n    # opt = SGD(lr=0.001,momentum=0.9,nesterov=True)\n    opt = Adam(lr=0.001)\n    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics='accuracy')\n    \n    print('Transfer Learning based on VGG16')\n    model.summary()\n    \nelse:\n    base_model = Xception(include_top=False,input_shape=(224,224,3),weights='imagenet')\n    # mark loaded layers as not trainable\n    for layer in base_model.layers:\n        layer.trainable = False\n    # add new classification layers\n    #avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n    flat1 = Flatten()(base_model.layers[-1].output)\n    class1 = Dense(512,activation='relu',kernel_initializer='he_normal')(flat1)\n    class2 = Dense(256,activation='relu',kernel_initializer='he_normal')(class1)\n    class3 = Dense(128,activation='relu',kernel_initializer='he_normal')(class2)\n    output = Dense(22,activation='softmax')(class3)\n    # define new model\n    model = Model(inputs=base_model.inputs,outputs=output)\n    #compile the model\n    # opt = SGD(lr=0.001,momentum=0.9,nesterov=True)\n    opt = Adam(lr=0.001)\n    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics='accuracy')\n    \n    print('Transfer Learning based on Xception Module')\n    model.summary()  \n","da12affb":"# DEFINE CALLBACKS ---- > EARLY STOP AND REDUCE LEARNING RATE ON PLATEAU\nearly_stop = EarlyStopping(patience=9,monitor='val_loss',restore_best_weights=True)\n#reduce_lr = ReduceLROnPlateau(patience=2,monitor='val_loss',factor=0.1)\ncsv_logger = CSVLogger('epoch_run_transfer_Xception.csv',separator=',',append=True)","9b22637f":"# DEFINE THE STEPS_PER_EPOCH\nSTEP_SIZE_TRAIN = (train_generator.n \/\/ train_generator.batch_size)   \nSTEP_SIZE_VALIDATION = (validation_generator.n \/\/ validation_generator.batch_size)   \nSTEP_SIZE_TEST = (test_generator.n \/\/ test_generator.batch_size) ","e86d1544":"## FIT THE MODEL\nmodel.fit_generator(generator=train_generator,\n                   steps_per_epoch=STEP_SIZE_TRAIN,\n                   validation_data=validation_generator,\n                   validation_steps=STEP_SIZE_VALIDATION,\n                   epochs=30,\n                   callbacks=[early_stop,csv_logger]\n                   )","98141dbb":"base_model.trainable = True\nopt = Adam(lr=0.00001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics='accuracy')\n\n\nmodel.fit_generator(generator=train_generator,\n                   steps_per_epoch=STEP_SIZE_TRAIN,\n                   validation_data=validation_generator,\n                   validation_steps=STEP_SIZE_VALIDATION,\n                   epochs=40,\n                   callbacks=[early_stop,csv_logger]\n                   )\n","269ff9fa":"# EVALUATE THE MODEL ... \nmodel.evaluate_generator(generator=validation_generator)","2d69dcec":"#loss_df = pd.DataFrame(model.history.history)\n#loss_df.plot()","23d00981":"data_generator = ImageDataGenerator(    \n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    brightness_range=None,\n    shear_range=0.5,\n    zoom_range=[0.5,1.8],\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=True,\n    vertical_flip=False,\n    rescale=1.\/255,\n    preprocessing_function=preprocess_input,\n    data_format=None,\n    validation_split=0.0,\n    dtype= 'float32'\n) \n   ","4f632870":"# CREATE THE TRAINING GENERATOR \ntrain_generator_full = data_generator.flow_from_dataframe(dataframe=train_df,\n                                                      directory=TRAIN_PATH,\n                                                      x_col='image',\n                                                      y_col='sports',\n                                                      subset='training',\n                                                      color_mode='rgb',\n                                                      batch_size=BATCH_SIZE,\n                                                      seed=42,\n                                                      shuffle=True,\n                                                      class_mode='categorical',\n                                                      target_size=(224,224))\n\ntrain_generator_full","501d9cae":"model.fit_generator(generator=train_generator_full,\n                   steps_per_epoch=train_generator_full.n\/\/train_generator_full.batch_size,\n                   epochs=35,\n                   callbacks=[early_stop]\n                   )","de362019":"# RESET THE GENERATOR TO GET THE RESULTS IN THE RIGHT ORDER\ntest_generator.reset()\n","a71b1b85":"# GENERATE PREDICTIONS ON THE TEST DATA\npredictions = model.predict_generator(test_generator)","a2aabc5f":"# RETRIEVE THE CLASS INDEX FOR WHICH THE PROBABILITY IS MAXIMUM ...hence np.argmax\npredictions_class_index = np.argmax(predictions,axis=1)","17a27b06":"# CHECK THE PREDICTED CLASS INDICES\npredictions_class_index","4d0f27c1":"# EXTRACT THE PREDICTION LABELS\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nfinal_predictions = [labels[k] for k in predictions_class_index]","76e1ff80":"# LIST THE FINAL PREDICTED LABELS\nfinal_predictions","95f43a8a":"len(final_predictions)","bcaf4d9b":"# PREPARE FOR SUBMISSION\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"image\":filenames,\n                      \"sports\":final_predictions})\nresults.to_csv(\"results.csv\",index=False)","8daf054b":"model.save('sports_xception_final_model_v2.h5')","325c3e76":"## Setting Directory Paths","10117453":"## Library Imports","16e5348c":"## Data Preparation\n\nAll the images cannot be read into the memory at once. Secondly, the number of images per sports can be limited. Data augmentation technique is generally suited for this kind of problem. \n\nI will make use of the ImageDataGenerator class from Keras for this. I particularly liked this post \nhttps:\/\/machinelearningmastery.com\/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks\/","3b0ae37c":"## Prepare for final model","218e5189":"### Check the dimensions of the images\nWe do not know for sure the size\/shape of the images. They all can be same or different. This needs to be determined so that it can be fed as a hyper-parameter in the image data generator. \n\nThis might consume some time. Hence after the first run, better to comment this out. ","e3984639":"### Summary based on data directory organization\n- Images are organized in train and test dir\n- All the train images are in the same directory and not in directories of their respective class. \n- There are 22 sports covered by the various images\n- The dataframe has the full filename with the extension. \n- There are over 11,000 images in the training folder and roughly 2,700 images in the test folder\n\nImportant Consideration\n-  Later I wanted to use the data augmentation using ImageDataGenerator class in Keras. Instead of flowfrom directory, I will need to use flow from dataframe.","a8b29995":"Considering the mean and the mode, the IMAGE_SHAPE appears to be a good choice. ","f55ae3e9":"One of the hyperparatemer while training with the generators is the steps_per_epoch. The steps_per_epoch argument must specify the number of batches of samples comprising one epoch. If the original dataset has 10,000 images and your batch size is 32, then a reasonable value for steps_per_epoch when fitting a model on the augmented data might be ceil(10,000\/32), or 313 batches. \nFor more information, have a look at this article\nhttps:\/\/machinelearningmastery.com\/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks\/","2adb6429":"The hello word of CNN is often the digit recognition in MNIST dataset. That itself has around 70,000 images and all the images are nicely centered. This makes even a fully connected model like ANN to come out with high accuracy. \n\nIn the current situation of sports images, there are only 11,000 images covering 22 sports. Moreover, all the images are very different. Almost all as 3D with chances of grayscale as well (check out the hockey images if interested) and color images but have different colors, zoom ranges, light levels, images where only the equipment is present while others with the player on the field etc. \n\nSo the task is not as easy as it appeared to me in the beginning. ","3c6022e9":"### Generating many manipulated images from the directory\n\nWe need to use flow from dataframe instead of flow from directory as all the training images are in the single folder. ","63a58148":"## Data Exploration\n- Display images and corresponding labels\n- Check whether the data balanced --- > total image representation of various sports \n- Image sizes -- > to determine the input shape later in the model\n- Variation in a particular sport's images","c4155b61":"Wonderful ! As if the image variation was not enough, the dimension of the images are all different. One way to tackle this is feed the mean of the image shape into the model. Other options could be to set it to max values. But this might result in slower training. ","a7deb8cc":"**It would be interesting to see the variation in the images in the dataset for a particular sport. The final model should be agnostic or robust to these variations. \nSame sports images can be provided from innumerable venues, angles, lighting levels, different people playing the sports etc. These variations make this project interesting to explore !!**","71c289a1":"### Step 1: Experiment with a basic model","00d54016":"## Fit the Model","0f59e66b":"### Create the training and validation generators. \n\nThe directory path in the flow_from_dataframe should contain path till the point leading to the 'id' column in the dataframe. In this case, the id column is the column 'image' in the dataframe train_labels. The fields in the image column are labeled .\/train\/img_num.jpg eg .\/train\/0.jpg\n\nSince I used the validation_split to split the dataset, I have to specify which set is to be used for which flow_from_dataframe function. The subset argument is set to \u201ctraining\u201d or \u201cvalidation\u201d accordingly. ","582a803c":"# Image Based Sports Classification","da5540b4":"### Check various images of the same sport\n\nIn the below section, I randomly picked a sport and its corresponding images. Same sport can have different type of images and the trained model should be robust for all the variations. ","b210730b":"**Badminton and Football has the maximum number of images in the dataset. Kabaddi is the least. Broadly, the data does not seem to be biased for a particular sport.**","6ae2e211":"## Build the Model","e8ead5c1":"There are two directories - train and test. Rest are all the csv files. Lets explore the train directory. Data dir indicated there are no sub folders and all images are in the same directory. "}}