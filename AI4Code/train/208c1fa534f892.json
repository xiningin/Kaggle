{"cell_type":{"3492945d":"code","25b4c4e4":"code","74458759":"code","359592bf":"code","e9887880":"code","aa241b72":"code","1b5915bf":"code","361a9c62":"code","6eba4289":"code","82a29f94":"code","1526db77":"code","a1c90ff6":"code","8685211a":"code","a40cb0d5":"code","fd76416f":"code","248f6219":"code","4799397f":"code","06bce58f":"code","624ccd34":"code","909ab30f":"code","bc9c3d45":"code","6ac22805":"code","ce5736e3":"code","e976a1fb":"code","20156aae":"code","f22f8b3e":"code","6449f1a9":"code","a4c5fe51":"code","e52cc5ad":"code","5f2a3a2f":"code","b42407db":"code","71a2201d":"code","3ff6bef1":"code","d1960590":"code","a693a7eb":"code","ce0c2b57":"code","baa98a5d":"code","a67abfe3":"code","6d6daddb":"code","15c4438b":"code","013c6443":"code","05e8c32d":"code","a016852f":"code","8915168e":"code","5157887a":"code","c8daca1a":"code","0182b8f7":"code","3ae68db6":"code","c147e841":"code","b93b823d":"code","140d72b8":"code","366562db":"code","335fe30f":"code","ffad6e50":"code","72f3b874":"code","2474d613":"code","4c9284cb":"code","5ce1fee4":"code","fe2b58e7":"code","30ce9edc":"code","5c349555":"code","ab9cfc92":"code","33f9af4e":"code","ca5ebf36":"code","7ba1debf":"code","d084f648":"code","f79e0f71":"code","ac4cf734":"code","d6e57c95":"code","7b672917":"code","80764e60":"code","3dcebff5":"code","0238c4c1":"code","44a7c46f":"code","48ed1966":"code","80850eee":"code","a2925507":"code","43f1c194":"code","c378e332":"code","e7a764d4":"code","9cb33785":"code","8fe5ad04":"code","0ebc15bb":"code","b71525f9":"code","355b6a36":"code","8077c420":"code","2b7feb1d":"code","7262ee5a":"code","8c4f5956":"code","81fc040c":"code","5dfc1afa":"code","f8676920":"code","d6e890e2":"code","ca46259a":"code","4329b98f":"code","dcdecc69":"code","23cb3173":"code","134e2985":"code","d1675fc7":"code","1b7d208a":"code","834b4cb3":"code","a1e14665":"code","c0747d96":"code","2c3036f1":"code","9a5af8bc":"code","a11bc324":"code","aee1db60":"code","05477303":"code","a3df52e4":"code","60e195f6":"code","13007818":"code","c5fabda2":"code","e3c3d0f6":"code","74246b10":"code","ca1f9d8f":"code","80794326":"code","4be0feb8":"code","284588be":"code","70a3d2c4":"code","eec85c53":"code","fbc75099":"code","de517f82":"code","340ffc05":"code","0a142203":"code","e642e6a4":"code","4426c81a":"code","9bd2745a":"code","ead64157":"code","71de344b":"code","7d490d68":"code","cc6c7709":"code","e93ad67c":"markdown","4f774f20":"markdown","3fefdd92":"markdown","7ddd5aa6":"markdown","f7eab366":"markdown","7f6a4105":"markdown","46784941":"markdown","14df5aa8":"markdown","5a65f430":"markdown","148ed18b":"markdown","adfb26ca":"markdown","ad88009c":"markdown","864dda1c":"markdown","87115ef3":"markdown","badea79c":"markdown","12c4b30b":"markdown","4a40224c":"markdown","973b2766":"markdown","2d691ca3":"markdown","cc8d7280":"markdown","1789b0c4":"markdown","0ad567c2":"markdown","b612489e":"markdown","6738e3d1":"markdown","cd0f9e34":"markdown","cc7ee38e":"markdown","a852cad4":"markdown","30f28b28":"markdown","79f9d639":"markdown","d14b69d8":"markdown","96e1ce4e":"markdown","15a35f72":"markdown","3a5e402e":"markdown","28cfba34":"markdown","3596f537":"markdown","bad6ff40":"markdown","579e645b":"markdown","4e083992":"markdown","2c06b4cf":"markdown","314cfc16":"markdown","3d1fb5cf":"markdown","83d7d888":"markdown","baea95ba":"markdown"},"source":{"3492945d":"# importing libraries\nimport numpy as np\nimport pandas as pd","25b4c4e4":"# importing the dataset\ndf = pd.read_csv(\"..\/input\/mechanical-properties-of-low-alloy-steels\/MatNavi Mechanical properties of low-alloy steels.csv\")","74458759":"# showing first five rows of the dateset\ndf.head()","359592bf":"# showing the column names\nlist(df.columns)","e9887880":"# editing the column names\nnew_list = {' C': 'C',\n            ' Si': 'Si',\n            ' Mn': 'Mn',\n            ' P': 'P',\n            ' S': 'S',\n            ' Ni': 'Ni',\n            ' Cr': 'Cr',\n            ' Mo': 'Mo',\n            ' Cu': 'Cu', \n            ' Al': 'Al',\n            ' N': 'N', \n            ' Temperature (\u00b0C)': 'Temperature (\u00b0C)',\n            ' 0.2% Proof Stress (MPa)': '0.2% Proof Stress (MPa)',\n            ' Tensile Strength (MPa)': 'Tensile Strength (MPa)',\n            ' Elongation (%)': 'Elongation (%)', \n            ' Reduction in Area (%)': 'Reduction in Area (%)'}\ndf.rename(columns=new_list, inplace=True)\nlist(df.columns)","aa241b72":"# showing the column names\nlist(df.columns)","1b5915bf":"# showing statistical information about the dataset\ndf.info()","361a9c62":"# showing statistical data of the dataset\ndf.describe()","6eba4289":"# removeing Alloy code column because it is for information only\ndf.drop('Alloy code', axis='columns', inplace=True)","82a29f94":"df.head()","1526db77":"# plotting C variable\nboxplot = df.boxplot(column=[\"C\"]);","a1c90ff6":"# plotting Si variable\nboxplot = df.boxplot(column=[\"Si\"])","8685211a":"# plotting Mn variable\nboxplot = df.boxplot(column=[\"Mn\"]);","a40cb0d5":"# plotting S variable in descending order\nboxplot = df.boxplot(column=[\"S\"]);","fd76416f":"# plotting P variable in descending order\nboxplot = df.boxplot(column=[\"P\"]);","248f6219":"# plotting Ni variable\nboxplot = df.boxplot(column=[\"Ni\"]);","4799397f":"# plotting non-zero Ni variable\ndf_Ni = df[\"index\" and \"Ni\"]\ndf_Ni_nonzero = df_Ni[df_Ni != 0]\ndf_Ni_nonzero.to_frame().boxplot(column=[\"Ni\"])","06bce58f":"# plotting Cr variable\nboxplot = df.boxplot(column=[\"Cr\"]);","624ccd34":"# plotting Mo variable\nboxplot = df.boxplot(column=[\"Mo\"]);","909ab30f":"# plotting Cu variable\nboxplot = df.boxplot(column=[\"Cu\"]);","bc9c3d45":"# calculating skewness of Al variable\ncu_skewness = df[\"Cu\"].skew()\ncu_skewness","6ac22805":"# trying log transformation to improve the skewness\nlog_cu_skewness = np.log(df[\"Cu\"]).skew()\nlog_cu_skewness","ce5736e3":"# trying root square transformation to improve the skewness\nsqrt_cu_skewness = np.sqrt(df[\"Cu\"]).skew()\nsqrt_cu_skewness","e976a1fb":"# creating sqrt(Cu) column\ndf[\"sqrt(Cu)\"] = np.sqrt(df['Cu'])","20156aae":"# plotting sqrt(Cu) variable\nboxplot = df.boxplot(column=[\"sqrt(Cu)\"]);","f22f8b3e":"# removing Cu column\ndf.drop([\"Cu\"], axis=1, inplace=True)\ndf.head()","6449f1a9":"# plotting V variable\nboxplot = df.boxplot(column=[\"V\"]);","a4c5fe51":"# plotting non-zero V variable\ndf_V = df[\"index\" and \"V\"]\ndf_V_nonzero = df_V[df_V != 0]\ndf_V_nonzero.to_frame().boxplot(column=[\"V\"])","e52cc5ad":"# plotting Al variable\nboxplot = df.boxplot(column=[\"Al\"]);","5f2a3a2f":"# plotting Al variable\ndf[\"Al\"].plot(); # There is no zewroes in Al variable","b42407db":"# calculating skewness of Al variable\nal_skewness = df[\"Al\"].skew()\nal_skewness","71a2201d":"# trying log transformation to improve the skewness\nlog_al_skewness = np.log(df[\"Al\"]).skew()\nlog_al_skewness","3ff6bef1":"# trying root square transformation to improve the skewness\nsqrt_al_skewness = np.sqrt(df[\"Al\"]).skew()\nsqrt_al_skewness","d1960590":"# creating log(Al) column\ndf[\"log(Al)\"] = np.log(df['Al'])","a693a7eb":"# plotting log(Al) variable\nboxplot = df.boxplot(column=[\"log(Al)\"]);","ce0c2b57":"# removing Al column\ndf.drop([\"Al\"], axis=1, inplace=True)\ndf.head()","baa98a5d":"# plotting N variable\nboxplot = df.boxplot(column=[\"N\"]);","a67abfe3":"# plotting Ceq variable\nboxplot = df.boxplot(column=[\"Ceq\"]);","6d6daddb":"# plotting Ceq non-zero variable\ndf_Ceq = df[\"index\" and \"Ceq\"]\ndf_Ceq_nonzero = df_Ceq[df_Ceq != 0]\ndf_Ceq_nonzero.to_frame().boxplot(column=[\"Ceq\"])","15c4438b":"# plotting Nb + Ta variable\nax = df[\"Nb + Ta\"].value_counts().sort_index().plot.bar(xlabel=\"Nb + Ta\", ylabel=\"Frequency\", figsize=(2,6), rot=45);","013c6443":"# plotting Temperature (\u00b0C) variable\nboxplot = df.boxplot(column=[\"Temperature (\u00b0C)\"]);","05e8c32d":"# plotting 0.2% Proof Stress (MPa) variable\nboxplot = df.boxplot(column=[\"0.2% Proof Stress (MPa)\"]);","a016852f":"# plotting Tensile Strength (MPa) variable\nboxplot = df.boxplot(column=[\"Tensile Strength (MPa)\"]);","8915168e":"# detecting the outlier\ndf.loc[df[\"Tensile Strength (MPa)\"] > 1000]","5157887a":"# deleting the outlier\ndf.drop(626, inplace=True)","c8daca1a":"# plotting Tensile Strength (MPa) variable\nboxplot = df.boxplot(column=[\"Tensile Strength (MPa)\"]);","0182b8f7":"# plotting Elongation (%) variable\nboxplot = df.boxplot(column=[\"Elongation (%)\"]);","3ae68db6":"# calculating skewness of Elongation (%) variable\nelongation_skewness = df[\"Elongation (%)\"].skew()\nelongation_skewness","c147e841":"# trying log transformation to improve the skewness\nlog_el_skewness = np.log(df[\"Elongation (%)\"]).skew()\nlog_el_skewness","b93b823d":"# creating log(Elongation (%)) column\ndf[\"log(Elongation (%))\"] = np.log(df['Elongation (%)'])","140d72b8":"# plotting log(Elongation (%)) variable\nboxplot = df.boxplot(column=[\"log(Elongation (%))\"]);","366562db":"# removing Elongation column\ndf.drop([\"Elongation (%)\"], axis=1, inplace=True)\ndf.head()","335fe30f":"# plotting Reduction in Area (%) variable\nboxplot = df.boxplot(column=[\"Reduction in Area (%)\"]);","ffad6e50":"# calculating skewness of Reduction in Area (%) variable\nReduction_skewness = df[\"Reduction in Area (%)\"].skew()\nReduction_skewness","72f3b874":"# reordering the dataframe columns in original order\ndf = df[['C',\n 'Si',\n 'Mn',\n 'P',\n 'S',\n 'Ni',\n 'Cr',\n 'Mo',\n 'sqrt(Cu)',\n 'V',\n 'log(Al)',\n 'N',\n 'Ceq',\n 'Nb + Ta',\n 'Temperature (\u00b0C)',\n '0.2% Proof Stress (MPa)',\n 'Tensile Strength (MPa)',\n 'log(Elongation (%))',\n 'Reduction in Area (%)']]","2474d613":"df.head()","4c9284cb":"# importing libraries for heatmap building \nimport seaborn as sns\nimport matplotlib.pyplot as plt","5ce1fee4":"# calculating a correlation matrix\ncorr_matrix = df.corr()\nprint(corr_matrix)","fe2b58e7":"# drawing a heatmap\nplt.figure(figsize = (20,20))\nax = sns.heatmap(corr_matrix, annot=True, square=True, cmap='Blues')\nplt.show()","30ce9edc":"# defining variables\nX = df.iloc[:, :-4].values\ny = df.iloc[:, -4].values","5c349555":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)","ab9cfc92":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","33f9af4e":"# training the multiple Linear regression model on the training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","ca5ebf36":"# predicting the test set results\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","7ba1debf":"# test scoring\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","d084f648":"# training the decision tree regression model on the training set\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor()\nregressor.fit(X_train, y_train)","f79e0f71":"# predicting the test set results\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","ac4cf734":"# test scoring\nfrom sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","d6e57c95":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, y_train)","7b672917":"# predicting the test set results\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","80764e60":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_1 = r2_score(y_test, y_pred)\nscore_1","3dcebff5":"# defining variables\nX = df.iloc[:, :-4].values\nz = df.iloc[:, -3].values","0238c4c1":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, z_train, z_test = train_test_split(X, z, test_size = 0.20, random_state=42)","44a7c46f":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","48ed1966":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, z_train)","80850eee":"# predicting the test set results\nz_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=0)\nprint(np.concatenate((z_pred.reshape(len(z_pred),1), z_test.reshape(len(z_test),1)),1))","a2925507":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_2 = r2_score(z_test, z_pred)\nscore_2","43f1c194":"# defining variables\nX = df.iloc[:, :-4].values\nv = df.iloc[:, -2].values","c378e332":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, v_train, v_test = train_test_split(X, v, test_size = 0.20, random_state=42)","e7a764d4":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","9cb33785":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, v_train)","8fe5ad04":"# predicting the test set results\nv_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=1)\nprint(np.concatenate((v_pred.reshape(len(v_pred),1), v_test.reshape(len(v_test),1)),1))","0ebc15bb":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_3 = r2_score(v_test, v_pred)\nscore_3","b71525f9":"# defining variables\nX = df.iloc[:, :-4].values\nw = df.iloc[:, -1].values","355b6a36":"# splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, w_train, w_test = train_test_split(X, w, test_size = 0.20, random_state=42)","8077c420":"# feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","2b7feb1d":"# training the random forest regression model on the training set\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()\nregressor.fit(X_train, w_train)","7262ee5a":"# predicting the test set results\nw_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=1)\nprint(np.concatenate((w_pred.reshape(len(w_pred),1), w_test.reshape(len(w_test),1)),1))","8c4f5956":"# test scoring\nfrom sklearn.metrics import r2_score\nscore_4 = r2_score(w_test, w_pred)\nscore_4","81fc040c":"print({\"0.2% Proof Stress (MPa) score is\": \"{:.3f}\".format(score_1)})\nprint({\"Tensile Strength (MPa) score is\": \"{:.3f}\".format(score_2)})\nprint({\"log(Elongation (%)) score is\": \"{:.3f}\".format(score_3)})\nprint({\"Reduction in Area (%) score is\": \"{:.3f}\".format(score_4)})","5dfc1afa":"# importing tensorflow\nimport tensorflow as tf","f8676920":"tf.__version__","d6e890e2":"# initializing the ANN\nann_1 = tf.keras.models.Sequential()","ca46259a":"# showing a shape of X_train array\nX_train.shape","4329b98f":"# adding the input layer and the first hidden layer\nann_1.add(tf.keras.layers.Dense(units=15, activation='relu'))","dcdecc69":"# adding the second hidden layer\nann_1.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","23cb3173":"# adding the third hidden layer\nann_1.add(tf.keras.layers.Dense(units=60, activation='relu'))","134e2985":"# adding the output layer\nann_1.add(tf.keras.layers.Dense(units=1))","d1675fc7":"# compiling the ANN\nann_1.compile(optimizer = 'adam', loss = 'mean_squared_error')","1b7d208a":"# training the ANN model on the Training set\nann_1.fit(X_train, y_train, batch_size = 64, epochs = 600)","834b4cb3":"ann_1.summary()","a1e14665":"y_pred = ann_1.predict(X_test)\nnp.set_printoptions(precision=2)","c0747d96":"# y_test scoring\nfrom sklearn.metrics import r2_score\nann_1_score = r2_score(y_test, y_pred)\nann_1_score","2c3036f1":"# initializing the ANN\nann_2 = tf.keras.models.Sequential()","9a5af8bc":"# adding the input layer and the first hidden layer\nann_2.add(tf.keras.layers.Dense(units=15, activation='relu'))","a11bc324":"# adding the second hidden layer\nann_2.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","aee1db60":"# adding the third hidden layer\nann_2.add(tf.keras.layers.Dense(units=60, activation='relu'))","05477303":"# adding the output layer\nann_2.add(tf.keras.layers.Dense(units=1))","a3df52e4":"# compiling the ANN\nann_2.compile(optimizer = 'adam', loss = 'mean_squared_error')","60e195f6":"# training the ANN model on the Training set\nann_2.fit(X_train, z_train, batch_size = 64, epochs = 750)","13007818":"z_pred = ann_2.predict(X_test)\nnp.set_printoptions(precision=2)","c5fabda2":"# z_test scoring\nfrom sklearn.metrics import r2_score\nann_2_score = r2_score(z_test, z_pred)\nann_2_score","e3c3d0f6":"# initializing the ANN\nann_3 = tf.keras.models.Sequential()","74246b10":"# adding the input layer and the first hidden layer\nann_3.add(tf.keras.layers.Dense(units=15, activation='sigmoid'))","ca1f9d8f":"# adding the second hidden layer\nann_3.add(tf.keras.layers.Dense(units=60, activation='sigmoid'))","80794326":"# adding the third hidden layer\nann_3.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","4be0feb8":"# adding the output layer\nann_3.add(tf.keras.layers.Dense(units=1))","284588be":"# compiling the ANN\nann_3.compile(optimizer = 'adam', loss = 'mean_squared_error')","70a3d2c4":"# training the ANN model on the Training set\nann_3.fit(X_train, v_train, batch_size = 64, epochs = 5000)","eec85c53":"v_pred = ann_3.predict(X_test)\nnp.set_printoptions(precision=3)","fbc75099":"# v_test scoring\nfrom sklearn.metrics import r2_score\nann_3_score = r2_score(v_test, v_pred)\nann_3_score","de517f82":"# initializing the ANN\nann_4 = tf.keras.models.Sequential()","340ffc05":"# adding the input layer and the first hidden layer\nann_4.add(tf.keras.layers.Dense(units=15, activation='sigmoid'))","0a142203":"# adding the second\nann_4.add(tf.keras.layers.Dense(units=15, activation='sigmoid'))","e642e6a4":"# adding the third hidden layer\nann_4.add(tf.keras.layers.Dense(units=240, activation='sigmoid'))","4426c81a":"# adding the output layer\nann_4.add(tf.keras.layers.Dense(units=1))","9bd2745a":"# compiling the ANN\nann_4.compile(optimizer = 'adam', loss = 'mean_squared_error')","ead64157":"# training the ANN model on the Training set\nann_4.fit(X_train, w_train, batch_size = 64, epochs = 1000)","71de344b":"w_pred = ann_4.predict(X_test)\nnp.set_printoptions(precision=2)","7d490d68":"# w_test scoring\nfrom sklearn.metrics import r2_score\nann_4_score = r2_score(w_test, w_pred)\nann_4_score","cc6c7709":"print({\"0.2% Proof Stress (MPa) score is\": \"{:.3f}\".format(ann_1_score)})\nprint({\"Tensile Strength (MPa) score is\": \"{:.3f}\".format(ann_2_score)})\nprint({\"log(Elongation (%)) score is\": \"{:.3f}\".format(ann_3_score)})\nprint({\"Reduction in Area (%) score is\": \"{:.3f}\".format(ann_4_score)})","e93ad67c":"Results discussion: Random forest regression has showed high level of predectibility for the both strengths and reasonably high for geometrical deformations.","4f774f20":"STEP3: Building and optimising deep learning model","3fefdd92":"STEP2: Choosing best performing machine learning model","7ddd5aa6":"Predicting the results of the Test set","f7eab366":"Discussion: Random forest seems suitable model for this type of data.","7f6a4105":"Training the ANN#4","46784941":"Tensile Strength (MPa) column has an outlier. Let's detect and remove it.","14df5aa8":"Random forest regression for Reduction in Area (%)","5a65f430":"Predicting the results of the Test set","148ed18b":"Training the ANN#1","adfb26ca":"Scoring the ANN#2 prediction","ad88009c":"Predicting the results of the Test set","864dda1c":"Predicting the results of the Test set","87115ef3":"Random forest regression for 0.2% Proof Stress (MPa)","badea79c":"Building the ANN #3 for prediction of log(Elongation (%))","12c4b30b":"Scoring the ANN#4 prediction","4a40224c":"STEP 1: Learning the dataset and feature engineering","973b2766":"Link to the dataset:\n\nhttps:\/\/www.kaggle.com\/rohannemade\/mechanical-properties-of-low-alloy-steels","2d691ca3":"Log transformation gave better results then square root transformation","cc8d7280":"Training the ANN#2","1789b0c4":"Let's replace Elongation (%) variable with log(Elongation (%)) to fix the skewness","0ad567c2":"Building the ANN #2 for prediction of Tensile Strength (MPa)","b612489e":"Random forest regression for Tensile Strength (MPa)","6738e3d1":"Training the ANN#3","cd0f9e34":"R squared score for the ANNs:","cc7ee38e":"Scoring the ANN#3 prediction","a852cad4":"Elongation (%) variable is highly skewed","30f28b28":"Building the ANN #4 for prediction of Reduction in Area (%)","79f9d639":"Discussion: ANN performs similarly to Random Forest regression for all the four dependent variables. R square score is about 2% less for the ANN.","d14b69d8":"Building the ANN #1 for prediction of 0.2% Proof Stress (MPa)","96e1ce4e":"Random forest regression for Elongation (%)","15a35f72":"Square root transformation gave low skewness","3a5e402e":"R squared score for random forest with default parametrs:","28cfba34":"Project: prediction of the mechanical properties using the alloy composition and temperature.\n\n","3596f537":"Visualize data columns\n\nExplore distribution, skewness, outliers and other statistical properties","bad6ff40":"Decision tree regression for 0.2% Proof Stress (MPa)","579e645b":"Multiple linear regression for 0.2% Proof Stress (MPa)","4e083992":"Learning the dataset and making feature engineering","2c06b4cf":"Conclusion: random forest regression has showed best performance for this task. Data scaling, outliers removal and skewness amendmend have sensibly improved the performance.","314cfc16":"Reduction in Area (%) variable is reasonably skewed","3d1fb5cf":"Al variable is highly skewed","83d7d888":"Scoring the ANN#1 prediction","baea95ba":"Conclusion: random forest regression has showed best performance for this task. Data scaling, outliers removal and skewness amendmend have sensibly improved the performance.\n\nMethods: machine learning and deep learning\n\nDataset: \"Mechanical properties of low alloy steels\" from Kaggle, Contains alloy composition, temperature and mechanical properties\n\nContext: currently there are no precise theoretical methods to predict mechanical properties of steels. All the methods available are by backed by statistics and extensive physical testing of the materials. Since testing each material with different composition is a highly tedious task (imagine the number of possibilities!), let's apply our knowledge of machine learning and statistics to solve this problem.\n\nContent: this dataset contains compositions by weight percentages of low-alloy steels along with the temperatures at which the steels were tested and the values mechanical properties observed during the tests. The alloy code is a string unique to each alloy. Weight percentages of alloying metals and impurities like Aluminum, copper, manganese, nitrogen, nickel, cobalt, carbon, etc are given in columns. The temperature in celsius for each test is mentioned in a column. Lastly mechanical properties including tensile strength, yield strength, elongation and reduction in area are given in separate columns. The dataset contains 915 rows."}}