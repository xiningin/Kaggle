{"cell_type":{"fe7cbc42":"code","aea6312d":"code","9975966d":"code","b737940f":"code","76c7440c":"code","0547cc7d":"code","b33a3753":"code","86979aeb":"code","8275f7c5":"code","11946f0e":"code","81568ea1":"code","4f3b2b70":"code","fbf4f993":"code","de7e3680":"code","084a81a5":"code","36cd7cad":"code","3b76f3ac":"code","c5c85bcb":"code","aa04707e":"code","005875c1":"code","2f0b7cfd":"code","31872c37":"code","f04d0c4a":"code","a063b885":"code","6b6e6fb2":"code","203b1947":"code","65baa03d":"code","0db4b561":"code","778b7ccf":"code","ca48ccc0":"code","ed31f71c":"code","cfefb995":"code","8b44ccbb":"code","5866b6c8":"code","061b16a6":"code","39b71cc9":"code","6b006c0c":"code","148812e0":"code","1a941ec5":"code","d4ba7862":"code","8822eba8":"code","be1bd936":"code","99c4cc55":"code","8c3a5505":"code","e176c45b":"code","10c9610f":"code","8966072b":"code","85096f4c":"code","ed98f091":"code","d2cc82e7":"code","0dc02e92":"code","5a8d1d86":"code","fa883df5":"code","4dd749f1":"code","fb2d9439":"code","1e854d60":"code","c8075db6":"code","97334dd5":"code","fbac691e":"markdown","019eaa45":"markdown","4141ee6a":"markdown","f76b3700":"markdown","4e323121":"markdown","db388497":"markdown","679d8b96":"markdown","8c5ed71e":"markdown","0e82c9eb":"markdown","fcbac263":"markdown","3e91514a":"markdown","b7beaf3d":"markdown","96260815":"markdown","ffa5b2cd":"markdown","3ea04d07":"markdown","fd6a2f15":"markdown","7648ea87":"markdown","923c6b48":"markdown","ac9975fd":"markdown","1d20af7a":"markdown","550222da":"markdown","1cb775d7":"markdown","d0b01d3f":"markdown","126a5682":"markdown","c22cee8f":"markdown","ffa7db3a":"markdown","01e0caae":"markdown","467d0405":"markdown","497db768":"markdown","2bd1229c":"markdown","5ade10d3":"markdown","858ee0ec":"markdown","5227df3c":"markdown","09489d8c":"markdown","0a6eae53":"markdown"},"source":{"fe7cbc42":"!unzip ..\/input\/home-depot-product-search-relevance\/product_descriptions.csv.zip\n!unzip ..\/input\/home-depot-product-search-relevance\/train.csv.zip\n!unzip ..\/input\/home-depot-product-search-relevance\/test.csv.zip\n!unzip ..\/input\/home-depot-product-search-relevance\/attributes.csv.zip","aea6312d":"from sklearn import pipeline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom subprocess import check_output\nimport os\n# Any results you write to the current directory are saved as output.\nimport json\nimport warnings; warnings.filterwarnings(\"ignore\");\nimport time\nstart_time = time.time()\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import pipeline\nfrom sklearn.model_selection import GridSearchCV\n#from sklearn.feature_extraction import DictVectorizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import TruncatedSVD\n#from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import mean_squared_error, make_scorer\n#from nltk.metrics import edit_distance\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\n#from nltk.stem.snowball import SnowballStemmer #0.003 improvement but takes twice as long as PorterStemmer\nfrom bs4 import BeautifulSoup\nimport re\n#import enchant\nimport random\nrandom.seed(2016)\nfrom scipy.stats import norm  \nimport seaborn as sns # data visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\n","9975966d":"df_train = pd.read_csv('train.csv', encoding=\"ISO-8859-1\") #update here\ndf_test = pd.read_csv('test.csv', encoding=\"ISO-8859-1\") #update here\ndf_pro_desc = pd.read_csv('product_descriptions.csv')[:64000] #update here\ndf_attr = pd.read_csv('attributes.csv')","b737940f":"print(f\"training data has {df_train.isnull().values.sum()} null values:\")\nprint(f\"testing data has {df_test.isnull().values.sum()} null values:\")\nprint(f\"attribute data has {df_attr.isnull().values.sum()} null values:\")\nprint(f\"description data has {df_pro_desc.isnull().values.sum()} null values:\")","76c7440c":"def get_df_info(df):\n    print(\"df columns: \\n\",df.columns)\n    print(f\"df shape: \\n\",df.shape)\n    print(f\"df data types: \\n\",df.dtypes)\n    return df.head(10)","0547cc7d":"get_df_info(df_train)","b33a3753":"print(\"there are in total {} products \".format(len(df_train.product_title.unique())))\nprint(\"there are in total {} search query \".format(len(df_train.search_term.unique())))\nprint(\"there are in total {} product_uid\".format(len(df_train.product_uid.unique())))","86979aeb":"get_df_info(df_test)","8275f7c5":"print(\"there are in total {} products \".format(len(df_test.product_title.unique())))\nprint(\"there are in total {} search query \".format(len(df_test.search_term.unique())))\nprint(\"there are in total {} product_uid\".format(len(df_test.product_uid.unique())))","11946f0e":"get_df_info(df_pro_desc)","81568ea1":"print(\"there are in total {} product_uid \".format(len(df_pro_desc.product_uid.unique())))\nprint(\"there are in total {} product_descriptions \".format(len(df_pro_desc.product_description.unique())))","4f3b2b70":"(df_pro_desc.product_description.str.count('\\d+') + 1).hist(bins=30)\n(df_pro_desc.product_description.str.count('\\W')+1).hist(bins=30)","fbf4f993":"print('Total {} html tags contains in product description'.format(df_pro_desc.product_description.str.count('<br$').values.sum()))","de7e3680":"df_pro_desc[df_pro_desc.product_description.str.contains(\"<br\")].values.tolist()[-2:]","084a81a5":"df_pro_desc.product_description.str.contains(\"Click here to review our return policy for additional information regarding returns\").values.sum()","36cd7cad":"train_merged = pd.merge(df_train, df_pro_desc, on='product_uid')\ntest_merged = pd.merge(df_test, df_pro_desc, on='product_uid')","3b76f3ac":"sns.countplot(train_merged.relevance)","c5c85bcb":"hight_relevance = train_merged.loc[train_merged[\"relevance\"] == 3]\nhight_relevance[['product_title', 'search_term']].head()","aa04707e":"train_merged.relevance.plot(kind='hist', density=True)\n\nmu, std = norm.fit(train_merged.relevance)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'k', linewidth=2)\ntitle = \"Results: mu = %.3f,  std = %.3f\" % (mu, std)\nplt.title(title)\n\nplt.show()","005875c1":"train_merged[train_merged.search_term.str.contains(\"^\\\\d+ . \\\\d+$\")].head(10)","2f0b7cfd":"df_train_distribution = train_merged.search_term.str.split().apply(len).value_counts().sort_index()\ndf_test_distribution = test_merged.search_term.str.split().apply(len).value_counts().sort_index()\nfig, (ax1, ax2) = plt.subplots(2, sharex=False)\nfig.suptitle('Number of word in search term of train and test set')\n\n#ax1.hist(df_train_distribution)\ndf_train_distribution.plot(kind = 'pie', colormap = 'pink', figsize = (10,10), ax = ax1, title = 'in train data')\ndf_test_distribution.plot(kind = 'pie', colormap = 'jet', figsize = (10, 10), ax = ax2, title = 'in test data')","31872c37":"fig, (ax1, ax2) = plt.subplots(2, sharex=False)\nfig.suptitle('Number of word in search term of train and test set')\ndf_train_distribution.plot(kind = 'bar',colormap = 'pink',sharex = True, figsize = (10,5), ax = ax1, title = 'train data')\ndf_test_distribution.plot(kind = 'bar', colormap = 'autumn', figsize = (10,5), ax = ax2, title = 'test data')\n","f04d0c4a":"df_train_pro_desc_distribution = train_merged.product_description.str.split().apply(len).divmod(10)[0].value_counts().nlargest(40).sort_index()\ndf_test_pro_desc_distribution = test_merged.product_description.str.split().apply(len).divmod(10)[0].value_counts().nlargest(40).sort_index()\nfig, (ax1, ax2) = plt.subplots(2)\nfig.suptitle('Number of word in product description of train and test set')\n\ndf_train_pro_desc_distribution.plot(kind = 'bar', colormap = 'pink',sharex = True, figsize = (10,5), ax = ax1, title = 'in train')\ndf_test_pro_desc_distribution.plot(kind = 'bar', colormap = 'autumn', figsize = (10, 5), ax = ax2, title = 'in test')","a063b885":"df_brand = df_attr[df_attr.name == \"MFG Brand Name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})\nnum_train = df_train.shape[0]\ndf_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\ndf_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\ndf_all = pd.merge(df_all, df_brand, how='left', on='product_uid')","6b6e6fb2":"df_all.columns","203b1947":"from nltk.corpus import stopwords # Import the stop word list\n#stop_w = set(stopwords.words('english'))","65baa03d":"# use Beautifulsoup lib to remove html tags in text\ndef remove_html_tag(text):\n    soup = BeautifulSoup(text, 'lxml')\n    text = soup.get_text().replace('Click here to review our return policy for additional information regarding returns', '')\n    return text","0db4b561":"#stopwords are the words contain very little or no imformation. \nstop_w = ['for', 'xbi', 'and', 'in', 'th','on','sku','with','what','from','that','less','er','ing'] #'electr','paint','pipe','light','kitchen','wood','outdoor','door','bathroom'\n\nstrNum = {'zero':0,'one':1,'two':2,'three':3,'four':4,'five':5,'six':6,'seven':7,'eight':8,'nine':9}\nspell_check = json.load(open('..\/input\/spell-check-home-depot\/spell_check.json','r'))\ndef str_stem(s):\n    if isinstance(s, str):\n        s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A\n        s = s.lower()\n        s = s.replace(\"  \",\" \") #remove double space\n        #remove special character and split number\n        s = s.replace(\",\",\"\") #could be number \/ segment later\n        s = s.replace(\"$\",\" \")\n        s = s.replace(\"?\",\" \")\n        s = s.replace(\"-\",\" \")\n        s = s.replace(\"\/\/\",\"\/\")\n        s = s.replace(\"..\",\".\")\n        s = s.replace(\" \/ \",\" \")\n        s = s.replace(\" \\\\ \",\" \")\n        s = s.replace(\".\",\" . \")\n        s = re.sub(r\"(^\\.|\/)\", r\"\", s)\n        s = re.sub(r\"(\\.|\/)$\", r\"\", s)\n        s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n        s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n        s = s.replace(\" x \",\" xbi \")\n        s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n        s = re.sub(r\"([a-z])( *)\/( *)([a-z])\", r\"\\1 \\4\", s)\n        s = s.replace(\"*\",\" xbi \")\n        s = s.replace(\" by \",\" xbi \")\n        #convert mesurement unit to standard form.\n        s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n        s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n        s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n        s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n        s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n        s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n        s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n        s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n        s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n        s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n        s = s.replace(\"\u00b0\",\" degrees \")\n        s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg. \", s)\n        s = s.replace(\" v \",\" volts \")\n        s = re.sub(r\"([0-9]+)( *)(volts|volt)\\.?\", r\"\\1volt. \", s)\n        s = re.sub(r\"([0-9]+)( *)(watts|watt)\\.?\", r\"\\1watt. \", s)\n        s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp. \", s)\n        s = s.replace(\"  \",\" \")\n        s = s.replace(\" . \",\" \")\n        # filter out stop words\n        s = (\" \").join([z for z in s.split(\" \") if z not in stop_w])\n        # convert string number to number\n        s = (\" \").join([str(strNum[z]) if z in strNum else z for z in s.split(\" \")])\n        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n        s = remove_html_tag(s)\n        s = s.lower()\n        #fix the missed spell in text\n        for (k,v) in spell_check.items():\n            s = s.replace(k,v)\n        return s\n    else:\n        return \"null\"","778b7ccf":"df_all['search_term'] = df_all['search_term'].map(lambda x:str_stem(x))\ndf_all['product_title'] = df_all['product_title'].map(lambda x:str_stem(x))\ndf_all['product_description'] = df_all['product_description'].map(lambda x:str_stem(x))\ndf_all['brand'] = df_all['brand'].map(lambda x:str_stem(x))","ca48ccc0":"df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title'] +\"\\t\"+df_all['product_description']","ed31f71c":"df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['len_of_title'] = df_all['product_title'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['len_of_description'] = df_all['product_description'].map(lambda x:len(x.split())).astype(np.int64)\ndf_all['len_of_brand'] = df_all['brand'].map(lambda x:len(x.split())).astype(np.int64)","cfefb995":"def seg_words(str1, str2):\n    '''\n    str1: search_term\n    str2: product_tilte\n    '''\n    str2 = str2.lower()\n    str2 = re.sub(\"[^a-z0-9.\/]\",\" \", str2)\n    str2 = [s for s in set(str2.split()) if len(s)>2]\n    words = str1.lower().split(\" \")\n    s = []\n    for word in words:\n        if len(word)>3:\n            s1 = []\n            s1 += segmentit(word,str2,True)\n            #print(s1)\n            if len(s)>1:\n                s += [z for z in s1 if z not in ['er','ing','s','less'] and len(z)>1]\n            else:\n                s.append(word)\n        else:\n            s.append(word)\n    return (\" \".join(s))","8b44ccbb":"def segmentit(s, txt_arr, t):\n    st = s\n    r = []\n    for j in range(len(s)):\n        for word in txt_arr:\n            if word == s[:-j]:\n                r.append(s[:-j])\n                #print(s[:-j],s[len(s)-j:])\n                s=s[len(s)-j:]\n                r += segmentit(s, txt_arr, False)\n    if t:\n        i = len((\"\").join(r))\n        if not i==len(st):\n            r.append(st[i:])\n    return r\n","5866b6c8":"df_all['search_term'] = df_all['product_info'].map(lambda x:seg_words(x.split('\\t')[0],x.split('\\t')[1]))","061b16a6":"\ndef str_common_word(str1, str2):\n    words, cnt = str1.split(), 0\n    for word in words:\n        if str2.find(word)>=0:\n            cnt+=1\n    return cnt","39b71cc9":"#count number of times the last word in title appear in search term\ndf_all['query_last_word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[1]))\n#count number of times the last word in product_description appear in search term\ndf_all['query_last_word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0].split(\" \")[-1],x.split('\\t')[2]))\n#count number of times each word in product_info appear in search term\ndf_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n#count number of times each word in product_description appear in search term\ndf_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))","6b006c0c":"#count number of time each word in string1 appear in string2\ndef str_whole_word(str1, str2, i_):\n    cnt = 0\n    while i_ < len(str2):\n        i_ = str2.find(str1, i_)\n        if i_ == -1:\n            return cnt\n        else:\n            cnt += 1\n            i_ += len(str1)\n    return cnt","148812e0":"df_all['query_in_title'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[1],0))\ndf_all['query_in_description'] = df_all['product_info'].map(lambda x:str_whole_word(x.split('\\t')[0],x.split('\\t')[2],0))","1a941ec5":"df_all['ratio_title'] = df_all['word_in_title']\/df_all['len_of_query']\ndf_all['ratio_description'] = df_all['word_in_description']\/df_all['len_of_query']\ndf_all['attr'] = df_all['search_term']+\"\\t\"+df_all['brand']\ndf_all['word_in_brand'] = df_all['attr'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\ndf_all['ratio_brand'] = df_all['word_in_brand']\/df_all['len_of_brand']","d4ba7862":"!pip install textdistance","8822eba8":"import textdistance\ndf_all['jaccard_sim_desc'] = df_all['product_info'].map(lambda x:textdistance.jaccard(x.split('\\t')[0],x.split('\\t')[2]))\ndf_all['jaccard_sim_title'] = df_all['product_info'].map(lambda x:textdistance.jaccard(x.split('\\t')[0],x.split('\\t')[1]))","be1bd936":"df_all['levenshtein_sim_desc'] = df_all['product_info'].map(lambda x:textdistance.levenshtein(x.split('\\t')[0],x.split('\\t')[2]))\ndf_all['levenshtein_sim_title'] = df_all['product_info'].map(lambda x:textdistance.levenshtein(x.split('\\t')[0],x.split('\\t')[1]))","99c4cc55":"df_all['mra_sim_desc'] = df_all['product_info'].map(lambda x:textdistance.mra(x.split('\\t')[0],x.split('\\t')[2]))\ndf_all['mra_sim_title'] = df_all['product_info'].map(lambda x:textdistance.mra(x.split('\\t')[0],x.split('\\t')[1]))","8c3a5505":"df_brand = pd.unique(df_all.brand.ravel())\nd={}\ni = 1000\nfor s in df_brand:\n    d[s]=i\n    i+=3\ndf_all['brand_feature'] = df_all['brand'].map(lambda x:d[x])\ndf_all['search_term_feature'] = df_all['search_term'].map(lambda x:len(x))\n","e176c45b":"from nltk.corpus import brown\nimport gensim\nembed_model = gensim.models.Word2Vec(brown.sents())\nembed_model.save('brown.embedding')\nmodel = gensim.models.Word2Vec.load('brown.embedding')","10c9610f":"def embedding_sim_cal(s, t, i):\n    _sum = 0\n    avg = 0\n    if len(s.split()) == 0 :\n        return 0\n    for s_word in s.split():\n        _max = 0\n        for t_word in t.split():\n            if ((s_word in model.wv) and (t_word in model.wv)):\n                _max = max(_max, model.wv.similarity(s_word, t_word))\n        _sum += _max\n    avg = _sum\/ len(s.split())\n    return avg","8966072b":"df_all['word_ebed_similarity'] = df_all['product_info'].map(lambda x:embedding_sim_cal(x.split('\\t')[0],x.split('\\t')[2],0))\ndf_all.to_csv('df_all.csv')","85096f4c":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\ntfidf = TfidfVectorizer(analyzer='char_wb', ngram_range = (3,3), max_features = 1500)\ntfidf_des = tfidf.fit_transform(df_all.product_description).toarray()\ntfidf_search = tfidf.transform(df_all.search_term).toarray()\ntfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')","ed98f091":"def fmean_squared_error(ground_truth, predictions):\n    fmean_squared_error_ = mean_squared_error(ground_truth, predictions)**0.5\n    return fmean_squared_error_\n\nRMSE  = make_scorer(fmean_squared_error, greater_is_better=False)","d2cc82e7":"\nclass custom_regression_vals(BaseEstimator, TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, hd_searches):\n        d_col_drops=['id','relevance','search_term','product_title','product_description','product_info','attr','brand']\n        hd_searches = hd_searches.drop(d_col_drops,axis=1).values\n        return hd_searches\n\nclass custom_txt_col(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n    def fit(self, x, y=None):\n        return self\n    def transform(self, data_dict):\n        return data_dict[self.key].apply(str)","0dc02e92":"df_train = df_all.iloc[:num_train]\ndf_test = df_all.iloc[num_train:]\nid_test = df_test['id']\ny_train = df_train['relevance'].values\nX_train = df_train[:]\nX_test = df_test[:]\nprint(\"--- Features Set: %s minutes ---\" % round(((time.time() - start_time)\/60),2))","5a8d1d86":"rfr = RandomForestRegressor(n_estimators = 530, n_jobs = -1, random_state = 2016, verbose = 1)","fa883df5":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor()\n","4dd749f1":"tsvd = TruncatedSVD(n_components=10, random_state = 2016)","fb2d9439":"clf = pipeline.Pipeline([\n        ('union', FeatureUnion(\n                    transformer_list = [\n                        ('cst',  custom_regression_vals()),  \n                        ('txt1', pipeline.Pipeline([('s1', custom_txt_col(key='search_term')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n                        ('txt2', pipeline.Pipeline([('s2', custom_txt_col(key='product_title')), ('tfidf2', tfidf), ('tsvd2', tsvd)])),\n                        ('txt3', pipeline.Pipeline([('s3', custom_txt_col(key='product_description')), ('tfidf3', tfidf), ('tsvd3', tsvd)])),\n                        ('txt4', pipeline.Pipeline([('s4', custom_txt_col(key='brand')), ('tfidf4', tfidf), ('tsvd4', tsvd)]))\n                        ],\n                    transformer_weights = {\n                        'cst': 1.0,\n                        'txt1': 0.5,\n                        'txt2': 0.25,\n                        'txt3': 0.01,\n                        'txt4': 0.5\n                        },\n                #n_jobs = -1\n                )), \n        ('rfr', rfr)])\nparam_grid = {'rfr__max_features': [8], 'rfr__max_depth': [18]}","1e854d60":"model = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs = -1, cv = 2, verbose = 20, scoring=RMSE)\nmodel.fit(X_train, y_train)","c8075db6":"print(\"Best parameters found by grid search:\")\nprint(model.best_params_)","97334dd5":"pd.DataFrame({\"id\": id_test, \"relevance\": model.predict(X_test)}).to_csv('submission.csv',index=False)\nprint(\"--- Training & Testing: %s minutes ---\" % round(((time.time() - start_time)\/60),2))","fbac691e":"### Clean the data\n\nFirst, remove html tags","019eaa45":"## Take a look at each df\nIn order to understand our data, we can look at each variable and try to understand their meaning and relevance to this problem. This is time-consuming, but it will give us the flavour of our dataset.\n\n**Data fields:**\n- `id` - a unique Id field which represents a (search_term, product_uid) pair\n- `product_uid` - an id for the products\n- `product_title` - the product title\n- `product_description` - the text description of the product (may contain HTML content)\n- `search_term` - the search query\n- `relevance` - the average of the relevance ratings for a given id\n- `name` - an attribute name\n- `value` - the attribute's value\n\n### Get some extra info about our data:\n\nCheck null values in each dataframe","4141ee6a":"The relevancy score is between 1 and 3. Because the density of product whose relevancy score is between 2 and 3 is higher we can conclude that most of search query has been classifield between 2 and 3\n\nThe histogram of relevancy score doesn't follow standard distribution pattern\n\n**`search_term`** \n\n`search_term` is the words that customers use to search for products.","f76b3700":"### Caculating ratio","4e323121":"### Dimensionality reduction using truncated SVD (aka LSA).\n\nThis transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.\n\nHyperparametters used:\n\n`n_components`:Desired dimensionality of output data. Must be strictly less than the number of features. The default value is useful for visualisation. For LSA, a value of 100 is recommended.\n\n`random_stateint`: Used during randomized svd. Pass an int for reproducible results across multiple function calls.\n\n[Details](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.TruncatedSVD.html)","db388497":"Then, we remove special characters which is susposed to contain very few information and standardlize mesurement unit (ex: inches\/inch\/in -> 1in; pounds\/pound\/lbs\/lb -> 1lb ).","679d8b96":"## TF-IDF similarity measure feature at char level\n**What is TF-IDF?**\n\nTF-IDF is an information retrieval and information extraction subtask which aims to express the importance of a word to a document which is part of a colection of documents which we usually name a corpus. It is usually used by some search engines to help them obtain better results which are more relevant to a specific query\n\nTF-IDF stands for Term Frequency \u2014 Inverse Document Frequency and is a statistic that aims to better define how important a word is for a document, while also taking into account the relation to other documents from the same corpus.\nThis is performed by looking at how many times a word appears into a document while also paying attention to how many times the same word appears in other documents in the corpus.\nThe rationale behind this is the following:\na word that frequently appears in a document has more relevancy for that document, meaning that there is higher probability that the document is about or in relation to that specific word\na word that frequently appears in more documents may prevent us from finding the right document in a collection; the word is relevant either for all documents or for none. Either way, it will not help us filter out a single document or a small subset of documents from the whole set.\n\n* N is the number of documents we have in our dataset\n* d is a given document from our dataset\n* D is the collection of all documents\n* w is a given word in a document\n\nFirst step is to calculate the term frequency, our first measure if the score.\n\n![image.png](attachment:c4282087-314b-4a83-90bc-479eeef71331.png)\n\nSecond step is to calculate the inverse term frequency.\n\n![image.png](attachment:df2c1594-00c7-4feb-a9eb-336f2498642d.png)\n\nFinal step is to compute the TF-IDF score by the following formula:\n\n![image.png](attachment:e5417753-6522-4ede-b6e0-705dc9ee5626.png)\n\nBut in here, we will use TfidfVectorizer() which has already implimented in sklearn lib.","8c5ed71e":"## String similarity feature\n### Jaccard similiraty:\nThe Jaccard similarity index (sometimes called the Jaccard similarity coefficient) compares members for two sets to see which members are shared and which are distinct. It\u2019s a measure of similarity for the two sets of data, with a range from 0% to 100%. The higher the percentage, the more similar the two populations\n\n![image.png](https:\/\/neo4j.com\/docs\/graph-data-science\/current\/_images\/jaccard.png)","0e82c9eb":"### Join train, test with product_descriptions by product_uid","fcbac263":"# Result\n\nBecause the competition has closed, we will not see our rank in leaderboard\n\nMy score is about ~rank200\n\n![image.png](attachment:b40e2a79-da42-47b9-8dcb-6fe8bbb2e3c4.png)","3e91514a":"## **Get into details**\n**`relevance`**\n\n> `relevance` is our goal. It's like when we're going to a party. We always have a reason to be there.\n\nThe relevance is a number between 1 (not relevant) to 3 (highly relevant). For example, a search for \"AA battery\" would be considered highly relevant to a pack of size AA batteries (relevance = 3), mildly relevant to a cordless drill battery (relevance = 2), and not relevant to a snow shovel (relevance = 1).","b7beaf3d":"## Import required libraries","96260815":"## GridSearchCV for model selection\nGridSearchCV is a model selection step and this should be done after Data Processing tasks. It is used to train a machine learning model with multiple combinations of training hyper parameters and finds the best combination of parameters which optimizes the evaluation metric. It creates an exhaustive set of hyperparameter combinations and train model on each combination.\n\nIt is always good to compare the performances of Tuned and Untuned Models. This will cost us the time and expense but will surely give us the best results. The scikit-learn API is a great resource in case of any help.\n\nHyperparametters used:\n\n- `estimator`: estimator object being used\n- `param_grid`: dictionary that contains all of the parameters to try\n- `scoring`: evaluation metric to use when ranking results\n- `cv`: cross-validation, the number of cv folds for each combination of parameters\n\n [Details](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html)","ffa5b2cd":"# Preprocessing data\n\n## Transform `dt_attributes`\n- We will transform attributes into new dataframe which contain two columns `product_uid` and `brand` \n\n- Cause not every fields has `product attributes` , when we merge them with `dt_description`, some `NAN` values will show up. Therefor, we need to handle `NAN` values  after that.\n\n\n### Merge them all\n\nIn order to have a general sight to our data, we will merge train and test set.","3ea04d07":"### Analyze train data","fd6a2f15":"Apply preprocessing func to `product_title`, `search_term`, `product_description`, and `brand`","7648ea87":"# Student's information:\n**Ho va ten**: \u0110\u1ed7 Vi\u1ebft \u0110o\u00e0n\n\n**Mssv**: 18020313\n\n**Lop**: K63-K1","923c6b48":"# Feature engineering\n> Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\n\nThe features in your data will directly influence the predictive models you use and the results you can achieve.\n\nYou can say that: the better the features that you prepare and choose, the better the results you will achieve. It is true, but it also misleading.\n\nThe results you achieve are a factor of the model you choose, the data you have available and the features you prepared. Even your framing of the problem and objective measures you\u2019re using to estimate accuracy play a part. Your results are dependent on many inter-dependent properties.\n\nYou need great features that describe the structures inherent in your data.\n### Create new field \nwe can enrich the infomation by constructing of new features from raw data\nFor example, we will have `product_info` if concating `search_term`,`product_title`  with `product_description` separated by `tab`","ac9975fd":"### Analyze test data","1d20af7a":"### Analyze product description data\n\nContain `product_id` and `product_description`\n\n`product_description` seems contain valueable infomation and can be usefull later\n\n","550222da":"Split data into train and test data","1cb775d7":"## Create pipeline","d0b01d3f":"Lets see some of them","126a5682":"### RandomforestRegesssor\n\n**A random forest regressor.**\n\n![image.png](attachment:50a269dc-6d2b-40a5-8ea1-ead92a840cee.png)\n\nA random forest is a meta estimator that fits a number of classifying decision trees on various `sub-samples` of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The `sub-sample` size is controlled with the `max_samples` parameter if `bootstrap`=True (default), otherwise the whole dataset is used to build each tree.\n\nHyperparametters used:\n\n- `n_estimators`: The number of trees in the forest.\n\n- `n_jobs`: The number of jobs to run in parallel.\n\n- `random_state`: Controls both the randomness of the bootstrapping of the samples used when building trees (if `bootstrap`=True) and the sampling of the features to consider when looking for the best split at each node (if `max_features` < n_features)\n\n- `verbose`: Controls the verbosity when fitting and predicting.\n\n[Details](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestRegressor.html)","c22cee8f":"# Make submition","ffa7db3a":"## Word embedding feature\n### Word2vec and gensim\nWord2vec is one of the most popular technique to learn word embeddings using a two-layer neural network. Its input is a text corpus and its output is a set of vectors. Word embedding via word2vec can make natural language computer-readable, then further implementation of mathematical operations on words can be used to detect their similarities. A well-trained set of word vectors will place similar words close to each other in that space. For instance, the words women, men, and human might cluster in one corner, while yellow, red and blue cluster together in another.\n\nGensim is an open source python library for natural language processing and it was developed and is maintained by the Czech natural language processing researcher Radim \u0158eh\u016f\u0159ek. Gensim library will enable us to perform word embeddings simple and effeciently.","01e0caae":"#  Predict the Relevance of Search Results on HomeDepot.com\n> *Shoppers searching through Home Depot's product authority require correct results to their queries on home improvement. Currently human raters gauge search relevance and the impact of potential changes to the search algorithm. Home Depot aims to \"develop a model that can accurately predict the relevance of search results.*\n\nIn this competition, Home Depot is asking Kagglers to help them improve their customers' shopping experience by developing a model that can accurately predict the relevance of search results.\n\nSearch relevancy is an implicit measure Home Depot uses to gauge how quickly they can get customers to the right products. Currently, human raters evaluate the impact of potential changes to their search algorithms, which is a slow and subjective process. By removing or minimizing human input in search relevance evaluation, Home Depot hopes to increase the number of iterations their team can perform on the current search algorithms.\n wh\n## Input:\nA number of products and real customer search terms from Home Depot's website along with the ground truth labels (the relevance) which have been evaluated by at least three human raters .\n## Output: \nA relevance score for the provided combinations of search terms and products","467d0405":"Some query in dataset training are too straight, it's hard to guess exactly what user meant in terms of broad sense\n\nSome of the search query in dataset training has too specific meaning like 8 4616809045 9\n\nNumber of diggits appearence in the product title tends to be greater number of characters for dataset training (and the same is true for search query field)","497db768":"Create num columns based on text columns\n\n* count number of words in `search_term`\n* count number of words in `product_title`\n* count number of words in `product description`\n* count number of words in `brand`\n","2bd1229c":"## Unzip data","5ade10d3":"# Modeling\n## Loss function: RMSE","858ee0ec":"# **Data explore**\n\n## File descriptions\n\n- `train.csv` - the training set, contains products, searches, and relevance scores\n- `test.csv` - the test set, contains products and searches. You must predict the relevance for these pairs.\n- `product_descriptions.csv` - contains a text description of each product. You may join this table to the training or test set via the product_uid.\n- `attributes.csv` -  provides extended information about a subset of the products (typically representing detailed technical specifications). Not every product will have attributes.\n- `sample_submission.csv` - a file showing the correct submission format\n- `relevance_instructions.docx` - the instructions provided to human raters\n\n## Load data from csv file into Pandas DataFrame","5227df3c":"`product_description`","09489d8c":"## Numeric feature: \n### counting","0a6eae53":"### Levenshtein distance\n\nThe Levenshtein distance between two strings is defined as the minimum number of edits needed to transform one string into the other, with the allowable edit operations being insertion, deletion, or substitution of a single character.\n* So a Levenshtein distance of 0 means: both strings are equal\n* The maximum Levenshtein distance (all chars are different) is max(string1.length, string2.length)\n\nFor example, \"Hallo\", \"Hello\" -> Levenstein distance 1 Max Levenstein distance for this two strings is: 5. So the 20% of the characters do not match."}}