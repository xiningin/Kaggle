{"cell_type":{"bdfd176e":"code","b302ad34":"code","3abc69fb":"code","460167e4":"code","ca5db94b":"code","8d8cb4eb":"code","07c1df7c":"code","d461a07a":"code","e63c5dfb":"code","2c6e87cd":"code","081f7286":"code","c69a5194":"code","cdfa5637":"code","1af1ce77":"code","7da2d5f3":"code","56aaf293":"code","9803b70e":"code","adc0df31":"code","01bcb379":"code","45b50a22":"code","eae1aca7":"code","e1ad5660":"code","d3543de9":"code","fd301333":"code","16750029":"code","4ddb54d1":"code","2eeb8110":"code","64fc3374":"code","c32bbcb2":"code","b40d682e":"code","475aa1e3":"code","dc02a4ae":"code","8f52092f":"markdown","8d4ae35b":"markdown","bf6b6253":"markdown","2b39b5cb":"markdown","13873e0b":"markdown","c775dbd1":"markdown","648368e6":"markdown","5f245280":"markdown","59b5504c":"markdown","42b9faab":"markdown","e612caa7":"markdown"},"source":{"bdfd176e":"#some of the codelines are copied from https:\/\/www.kaggle.com\/wspinkaggle\/seti-basic-tensorflow-efficientnet","b302ad34":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport math\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pathlib\nfrom tensorflow.keras.applications import EfficientNetB2\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","3abc69fb":"data_dir = Path('..\/input\/seti-breakthrough-listen\/')\ntrain_data_dir = data_dir \/ 'train'\ntest_data_dir = data_dir \/ 'test'\n\ntrain_label_file = data_dir \/ 'train_labels.csv'\nsample_file = data_dir \/ 'sample_submission.csv'","460167e4":"df_labels = pd.read_csv(train_label_file, index_col='id')\ndf_labels.head()","ca5db94b":"df_labels.query(\"target == 0\").sample(3)","8d8cb4eb":"d_point = np.load('..\/input\/seti-breakthrough-listen\/train\/6\/6759b44dd672.npy')\nd_point = d_point.astype('float')\n\nplt.figure(figsize=(16,10))\nfor i in range(6):\n    plt.subplot(6, 1, i + 1)\n    if i == 0:\n        plt.title('File name: 6759b44dd672  | Target: 0', fontsize=18)\n    plt.imshow(d_point[i].astype(float), interpolation='nearest', aspect='auto')\n    plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n    plt.xticks([])\nplt.show()","07c1df7c":"d_point = np.load('..\/input\/seti-breakthrough-listen\/train\/e\/ee3e7543040a.npy')\nd_point = d_point.astype('float')\n\nplt.figure(figsize=(16,10))\nfor i in range(6):\n    plt.subplot(6, 1, i + 1)\n    if i == 0:\n        plt.title('File name: ee3e7543040a  | Target: 0', fontsize=18)\n    plt.imshow(d_point[i].astype(float), interpolation='nearest', aspect='auto')\n    plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n    plt.xticks([])\nplt.show()","d461a07a":"df_labels.query(\"target == 1\").sample(3)","e63c5dfb":"d_point = np.load('..\/input\/seti-breakthrough-listen\/train\/a\/a5db9a15fb61.npy')\nd_point = d_point.astype('float')\n\nplt.figure(figsize=(16,10))\nfor i in range(6):\n    plt.subplot(6, 1, i + 1)\n    if i == 0:\n        plt.title('File name: 22fa5d1a87de  | Target: 1', fontsize=18)\n    plt.imshow(d_point[i].astype(float), interpolation='nearest', aspect='auto')\n    plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n    plt.xticks([])\nplt.show()","2c6e87cd":"d_point = np.load('..\/input\/seti-breakthrough-listen\/train\/8\/84cd8577baec.npy')\nd_point = d_point.astype('float')\n\nplt.figure(figsize=(16,10))\nfor i in range(6):\n    plt.subplot(6, 1, i + 1)\n    if i == 0:\n        plt.title('File name: b18e4f5d7132  | Target: 1', fontsize=18)\n    plt.imshow(d_point[i].astype(float), interpolation='nearest', aspect='auto')\n    plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n    plt.xticks([])\nplt.show()","081f7286":"#Fourier function\n\ndef fourier_masker_ver(image):\n    dark_image_fourier =np.fft.fftshift(np.fft.fft2(image))\n    dark_image_fourier[:, 124:136] = 1\n    fig, ax = plt.subplots(1,3,figsize=(15,15))\n    ax[0].imshow(np.log(abs(dark_image_fourier)), cmap='gray')\n    ax[0].set_title('Fourier Image', fontsize = 15)\n    ax[1].imshow(image)\n    ax[1].set_title('Original Image', fontsize = 15);\n    ax[2].imshow(abs(np.fft.ifft2(dark_image_fourier)))\n    ax[2].set_title('Transformed  Image', fontsize = 15);","c69a5194":"df_labels.query(\"target == 1\").sample(3)","cdfa5637":"d_point = np.load('..\/input\/seti-breakthrough-listen\/train\/2\/2c407e6d4cce.npy')\nd_point = d_point.astype('float')\/255","1af1ce77":"fourier_masker_ver(d_point[0])","7da2d5f3":"fourier_masker_ver(d_point[1])","56aaf293":"fourier_masker_ver(d_point[2])","9803b70e":"def id_to_path(file_id, train=True):\n    data_dir = train_data_dir if train else test_data_dir\n    return data_dir \/ file_id[0] \/ f'{file_id}.npy'","adc0df31":"class SETISequence(Sequence):\n    \"\"\"\n    Taken from this nice starter notebook https:\/\/www.kaggle.com\/kenjirokiyono\/seti-simple-code-for-beginners-tensorflow and added the fourier transform step\n    \"\"\"\n    def __init__(self, x_set, y_set=None, batch_size=64):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.is_train = False if y_set is None else True\n    \n    def __len__(self):\n        return math.ceil(len(self.x) \/ self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch_ids = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n        \n        # taking channels \n        list_x=[]\n        # below is the fourier transform step\n        for x in batch_ids:\n            new = np.load(id_to_path(x, train=self.is_train))\n            new = new.astype('float')\/255\n            new = np.fft.fftshift(np.fft.fft2(new))\n            new[:, :, 120:136] = 1\n            new = abs(np.fft.ifft2(new))\n            list_x.append(new)\n        batch_x = np.moveaxis(list_x,1,-1)\n        batch_x = batch_x.astype(\"float\")\n        \n        if self.is_train:\n            return batch_x, batch_y\n        else:\n            return batch_x\n        \n# small output test\nSETISequence([\"00047dfc96a9\"], [1], batch_size=2).__getitem__(0)[0].shape","01bcb379":"data_augmentation_1 = tf.keras.layers.experimental.preprocessing.RandomTranslation(\n    height_factor=0.2, width_factor=0.2, fill_mode='wrap',\n    interpolation='bilinear', seed=None, fill_value=0.0\n)\ndata_augmentation_2 = tf.keras.layers.experimental.preprocessing.RandomFlip(\"vertical\")","45b50a22":"lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=0.001, \n    decay_steps=1000, \n    decay_rate=0.9)","eae1aca7":"model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(3,(3,3), strides=(1,1), padding=\"same\", activation='relu', input_shape=(273,256,6)), data_augmentation_1, data_augmentation_2,\n        EfficientNetB2(input_shape=(273, 256, 3), weights='imagenet', include_top=False, drop_connect_rate=0.4),\n        tf.keras.layers.GlobalAveragePooling2D(), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss='binary_crossentropy', metrics=['accuracy'])","e1ad5660":"model.summary()","d3543de9":"train_ids = df_labels.index.values\ntrain_y = df_labels['target'].values","fd301333":"train = SETISequence(train_ids, train_y, batch_size=64)","16750029":"history = model.fit(train, epochs=8)","4ddb54d1":"submission = pd.read_csv(sample_file, index_col='id')\nsubmission.head()","2eeb8110":"test_ids = submission.index.values","64fc3374":"test = SETISequence(test_ids, batch_size=64)","c32bbcb2":"test_prediction = model.predict(test)","b40d682e":"final_pred = np.where(test_prediction > 0.5, 1, 0)","475aa1e3":"final_pred[:10]","dc02a4ae":"submission['target'] = final_pred\nsubmission.to_csv('sub.csv', index=False)\nsubmission.head()","8f52092f":"### The model might not perfom well, but I have only trained the model on limited data and just 5 epochs. \n### But do let me know what you think about the idea to use fourier transform as a preprocessor.","8d4ae35b":"### Datapoint where target is 0","bf6b6253":"# Filtering the signal using Fourier transform.","2b39b5cb":"# Import the required libraries","13873e0b":"## To make it quick, i'll run the model on 2000 data points only.","c775dbd1":"# Visualise the input data","648368e6":"As seen above the horizontal lines are removed by fourier transform. Now lets build a model based on EfficientNetB2.","5f245280":"It can be seen that in the data points where target is 1, there is a vertical or inclined line. The horizontal lines are mostly noise and can be eliminated.\nWe will use fourier tranform to filter out the horizontal lines before the data is feed to the CNN model.\n\nLets look at an example of the fourier tranform.","59b5504c":"# Set the path for input data","42b9faab":"### Datapoint where target is 1","e612caa7":"# Model"}}