{"cell_type":{"0386eae4":"code","b1a11ccf":"code","a67a8d37":"code","66c03767":"code","3c01d03d":"code","76d3f5c4":"code","c5bead7b":"code","6992b6c2":"code","2543d862":"code","4108f6a0":"code","dd9ce741":"code","8f7fcb47":"code","65ad0300":"code","ce9f49db":"code","9dad91c0":"code","a0452b9a":"code","50c7a574":"code","edf6db10":"code","f1ee6fee":"code","65943064":"code","64704b2b":"code","2dcfb525":"code","c8c5a150":"markdown","4538df4f":"markdown","57e7a807":"markdown","80403eae":"markdown","224c6ad9":"markdown","25c1db2e":"markdown","9b9c806a":"markdown","29f59c2f":"markdown","209eeaa0":"markdown","28229c11":"markdown","86fd6f03":"markdown","41ff7a02":"markdown","3eacaaaa":"markdown","871c98cf":"markdown"},"source":{"0386eae4":"!pip uninstall scikit-learn -y\n!pip install scikit-learn==0.23.2 \n!pip install mne==0.24.0 \n!pip install mne_features==0.1 ","b1a11ccf":"%%capture\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport mne\nfrom mne.datasets.sleep_physionet.age import fetch_data\n\n\nfiles = fetch_data(subjects=range(21), \nrecording=[1])","a67a8d37":"%%capture\nmapping = {'rectal': 'misc',\n           'marker': 'misc'}\n\nraw = [mne.io.read_raw_edf(x[0]) for x in files];\nannot = [mne.read_annotations(x[1]) for x in files];\nfor i in range(21):\n  raw[i].set_annotations(annot[i], emit_warning=False);\n  raw[i].set_channel_types(mapping);","66c03767":"%%capture\nannotation_desc_2_event_id = {'Sleep stage W': 1,\n                              'Sleep stage 1': 2,\n                              'Sleep stage 2': 3,\n                              'Sleep stage 3': 4,\n                              'Sleep stage 4': 4,\n                              'Sleep stage R': 5}\n\n# create a new event_id that unifies stages 3 and 4\nevent_id = {'Sleep stage W': 1,\n            'Sleep stage 1': 2,\n            'Sleep stage 2': 3,\n            'Sleep stage 3\/4': 4,\n            'Sleep stage R': 5}\nevents = [0] * len(annot)\n# keep last 30-min wake events before sleep and first 30-min wake events after\n# sleep and redefine annotations on raw data\nfor i in range(len(annot)):\n  annot[i].crop(annot[i][1]['onset'] - 30 * 60,\n                 annot[i][-2]['onset'] + 30 * 60);\n  raw[i].set_annotations(annot[i], emit_warning=False);\n\n  events[i], _ = mne.events_from_annotations(\n    raw[i], event_id=annotation_desc_2_event_id, chunk_duration=30.);\n  # plot events\n  # fig = mne.viz.plot_events(events[i], event_id=event_id,\n  #                         sfreq=raw[i].info['sfreq'],\n  #                         first_samp=events[i][0, 0])\n  # stage_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\n\n\n","3c01d03d":"%%capture\nreject_criteria = dict(eeg=150e-6,       # 150 \u00b5V\n                       eog=250e-6)       # 250 \u00b5V\nepochs = [0] * len(annot)\nfor i in range(len(annot)):\n  tmax = 30. - 1. \/ raw[i].info['sfreq']\n  epochs[i] = mne.Epochs(raw=raw[i], events=events[i],\n                          event_id=event_id, tmin=0., tmax=tmax, baseline=None, reject=reject_criteria);\n","76d3f5c4":"%%capture\nraw_train = np.concatenate([k.get_data()[:,:2,:] for k in epochs[:16]],axis = 0);\ny_train = np.concatenate([k.events[:,2] for k in epochs[:16]],axis = 0);","c5bead7b":"%%capture\nraw_test = np.concatenate([k.get_data()[:,:2,:] for k in epochs[16:]],axis = 0);\ny_test = np.concatenate([k.events[:,2] for k in epochs[16:]],axis = 0);","6992b6c2":"from mne_features.feature_extraction import extract_features\nfrom mne.time_frequency import psd_welch\nimport time\n# import time","2543d862":"def plot_f_dist(feat,title):\n  import seaborn as sns\n  fig, (ax1,ax2) = plt.subplots(ncols=2)\n  stages = sorted(event_id.keys())  \n  for stage in stages:\n    f = feat[y_train==event_id[stage]]\n    sns.kdeplot(f[:,0], label = stage, ax=ax1,shade=True)\n    sns.kdeplot(f[:,1], label = stage, ax=ax2,shade=True)\n  # Plot formatting\n  plt.legend(title = 'Sleep Stages', loc='best',bbox_to_anchor=(1.1, 1.05))\n  plt.title(title)\n  plt.xlabel('V')\n  plt.ylabel('Density')","4108f6a0":"from scipy.stats import kurtosis, skew, entropy\n\ndef feature_extraction(data,epochs):\n\n    features_array = []\n    assert type(data) == np.ndarray, \"Data not an array\"\n\n    funcs = [#{'app_entropy'},             # Entropy\n    {'hjorth_complexity'},       # Hjorth's Complexity\n    {'hjorth_mobility'},         # Hjorth's Mobility\n    #  {'kurtosis'},                # Kurtosis\n    #  {'mean'},                    # Mean\n    #  {'skewness'},                # Skewness\n    #            {'spect_entropy'},           # Spectral Entropy\n    #            {'std'},                     # Standard Deviation\n    {'zero_crossings'},          # Zero Crossing Rate\n    #  {'energy_freq_bands'},\n    {'pow_freq_bands'},\n    ]\n    \n    features_array.append(data.std(axis=2))\n    \n#     features_array.append(entropy(data,axis=2))\n    \n    for i in funcs:\n        if i == {'pow_freq_bands'}:\n            features_array.append(extract_features(data, 100, i,{'pow_freq_bands__freq_bands':np.array([0.5, 4.5, 8.5, 11.5, 15.5, 30.])}))\n        elif i == {'energy_freq_bands'}:\n            features_array.append(extract_features(data, 100, i,{'energy_freq_bands__freq_bands':np.array([0.5, 4.5, 8.5, 11.5, 15.5, 30.])}))\n        else:\n            features_array.append(extract_features(data, 100, i))\n\n    ###\n    # frequency domain\n    psds_l = []\n    freqs_l = []\n    for e in epochs:\n        psds, freqs = psd_welch(e, picks='eeg', fmin=0.5, fmax=30.)\n        psds_l.append(psds)\n#         freqs_l.append(freqs)\n    psds = np.concatenate(psds_l,axis = 0)\n#     freqs = np.concatenate(freqs_l,axis = 0)\n    # spectral mean\n#     features_array.append(psds.mean(axis=2))\n    # Spectral Kurtosis\n    features_array.append(kurtosis(psds, axis=2))\n    # Spectral skewness\n    features_array.append(skew(psds, axis=2))\n    # Spectral Standard Deviation\n#     features_array.append(psds.std(axis=2))\n    # Spectral Entropy\n    features_array.append(entropy(psds,axis=2))\n    ###\n    return np.concatenate(features_array,axis=1)","dd9ce741":"X_train = feature_extraction(raw_train,epochs[:16])\nX_test = feature_extraction(raw_test,epochs[16:])","8f7fcb47":"np.amin(X_train[:,2])","65ad0300":"# funcs = [{'app_entropy'},             # Entropy\n#           #  {'energy_freq_bands'},\n#            {'hjorth_complexity'},       # Hjorth's Complexity\n#            {'hjorth_mobility'},         # Hjorth's Mobility\n#           #  {'kurtosis'},                # Kurtosis\n#           #  {'mean'},                    # Mean\n#           #  {'pow_freq_bands'},\n#           #  {'skewness'},                # Skewness\n#            {'spect_entropy'},           # Spectral Entropy\n#            {'std'},                     # Standard Deviation\n#            {'zero_crossings'},          # Zero Crossing Rate\n#            {'spec_mean'},\n#           #  {'spectral_centroid'},\n#          {'spectral kurtosis'},{'spectral skewness'}\n# ]\n# for i in range(0,12,2):\n#   plot_f_dist(X_train[:,i:i+2],funcs[int(i\/2)])\n# # for i in range(18,28,2):\n# #   plot_f_dist(X_train[:,i:i+2],'energy_freq_bands')\n# for i in range(12,22,2):\n#   plot_f_dist(X_train[:,i:i+2],'pow_freq_bands')\n# for i in range(22,28,2):\n#   plot_f_dist(X_train[:,i:i+2],funcs[int((i-10)\/2)])\n# # for i in range(18,28,2):\n# #   plot_f_dist(X_train[:,i:i+2],'energy_freq_bands')","ce9f49db":"from sklearn.metrics import classification_report\nfrom sklearn.neighbors import KNeighborsClassifier\nimport keras\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn import svm","9dad91c0":"model1 = KNeighborsClassifier(n_neighbors=10)\nmodel1.fit(X_train, y_train-1)\n\ny_pred1 = model1.predict(X_test)\n\nprint(classification_report(y_test-1, y_pred1))","a0452b9a":"model2 = RandomForestClassifier()\nmodel2.fit(X_train,y_train-1)\n\ny_pred2 = model2.predict(X_test)\n\nprint(classification_report(y_test-1, y_pred2))","50c7a574":"# from keras.regularizers import l1,l2,l1_l2\ninput = keras.Input(shape=(24,))\nx = keras.layers.Dense(16,activation='tanh',)(input)\nx = keras.layers.Dense(16,activation='relu',)(x)\nx = keras.layers.Dense(16,activation='tanh',)(x)\nx = keras.layers.Dense(16,activation='relu',)(x)\nx = keras.layers.Dense(16,activation='tanh',)(x)\nx = keras.layers.Dense(16,activation='relu',)(x)\noutput = keras.layers.Dense(5,activation='softmax')(x)\nmodel3 = keras.Model(input,output)\n\nmodel3.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=[keras.metrics.SparseCategoricalAccuracy()])\nmodel3.summary()\n","edf6db10":"%%capture\n# from tensorflow.keras.utils import to_categorical\nmodel3.fit(X_train,y_train-1,\n           batch_size = 128,\n           epochs = 500,\n           validation_data=(X_test,y_test-1)\n           )","f1ee6fee":"y_pred = model3.predict(X_test)\ny_pred_bool = np.argmax(y_pred, axis=1)\n\nprint(classification_report(y_test-1, y_pred_bool))","65943064":"model4 = AdaBoostClassifier(n_estimators=20)\nmodel4.fit(X_train,y_train-1)\n\ny_pred4 = model4.predict(X_test)\n\nprint(classification_report(y_test-1, y_pred4))","64704b2b":"from collections import OrderedDict\nfeat_imp = model2.feature_importances_\nfeat_dict = OrderedDict({'Standard Deviation':0,'Hjorth`s Complexity':0,'Hjorth`s Mobility':0,'Zero Crossing Rate':0,'Power frequency bands':0,'Spectral Kurtosis':0,'Spectral Skewness':0,'Spectral Entropy':0})\nkeys = list(feat_dict.keys())\nfor i in range(8):\n    feat_dict[keys[int(i\/2)]]+=feat_imp[i]\nfor i in range(8,18):\n    feat_dict[keys[4]]+=feat_imp[i]\nfor i in range(18,24):\n    feat_dict[keys[int(i\/2)-4]]+=feat_imp[i]\nfeat_dict","2dcfb525":"features = np.array(list(feat_dict.keys()))\nimportances = np.array(list(feat_dict.values()))\n\nindices = np.argsort(importances)\nplt.figure(figsize=(20,5))\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='green', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","c8c5a150":"## Installing Libraries","4538df4f":"## Feature importance","57e7a807":"### Test","80403eae":"## Feature Extraction","224c6ad9":"### Model 1: KNN","25c1db2e":"## Importing the dataset","9b9c806a":"## Models","29f59c2f":"### Train","209eeaa0":"### Model 2: Random Forest","28229c11":"### Model 4: ADA Boost","86fd6f03":"## Preprocessing","41ff7a02":"### Model 3: Deep Neural Network","3eacaaaa":"## Splitting the data","871c98cf":"# Building 3 models to identify sleep stages in mne dataset"}}