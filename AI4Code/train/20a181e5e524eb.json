{"cell_type":{"e6987d5d":"code","84756f6c":"code","babfa2b3":"code","a8d2173c":"code","21b39608":"code","dc58a56a":"code","6322247a":"code","def1166a":"code","f0da736f":"code","091e8523":"code","34afbdf7":"code","f2006bf4":"code","3becb26e":"code","0f4b8cde":"code","a8a80e3f":"code","1860c186":"code","04d401d0":"code","0b0a13f1":"code","c25ade6d":"code","d0471034":"code","16315189":"code","f5233ef2":"code","9a432a50":"code","c1b5c664":"markdown","005e8abf":"markdown","73484745":"markdown","5b7fe650":"markdown","182cb26e":"markdown","6792d5f6":"markdown","563a7b9a":"markdown","1fbc552f":"markdown","190c69e0":"markdown","8a73aeea":"markdown","79fb6221":"markdown","b3c0c3aa":"markdown","8de074fa":"markdown"},"source":{"e6987d5d":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\n","84756f6c":"path='..\/input\/my-nsfw-dataset\/train\/train\/'","babfa2b3":"Nude=os.listdir(path+'NSFW\/')\nDecent=os.listdir(path+'SFW\/')\ntest_path='..\/input\/my-nsfw-dataset\/test\/test\/'\ntest=os.listdir(test_path)","a8d2173c":"vgg16 = tf.keras.applications.VGG16(include_top=False)\npreprocess_input = tf.keras.applications.vgg16.preprocess_input\nimage = tf.keras.preprocessing.image","21b39608":"batch_size=20","dc58a56a":"def extract_features(img_paths, batch_size=batch_size):\n\n    global vgg16\n    n = len(img_paths)\n    img_array = np.zeros((n, 299, 299, 3))\n    \n    for i, path in enumerate(img_paths):\n        img = image.load_img(path, target_size=(299, 299))\n        img = image.img_to_array(img)\n        img = np.expand_dims(img, axis=0)\n        x = preprocess_input(img)\n        img_array[i] = x\n    \n    X = vgg16.predict(img_array, batch_size=batch_size, verbose=1)\n    X = X.reshape(n, 512, -1)\n    return X\n","6322247a":"X = extract_features(\n    list(map(lambda x: path + 'NSFW\/' + x, Nude)) + list(map(lambda x: path + 'SFW\/' + x, Decent))\n) \ny = np.array([1] * len(Nude) + [0] * len(Decent))","def1166a":"X_test = extract_features(\n    list(map(lambda x: test_path + x, test))\n)\ny_test = np.array([1] * len(Nude) + [0] * len(Decent))","f0da736f":"def train():\n    model = tf.keras.models.Sequential([ \n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(1724, activation=tf.nn.relu),\n\n\n      tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n\n    ])\n    return model","091e8523":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","34afbdf7":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)","f2006bf4":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Dense\nnp.random.seed(42)\n\nepochs = 10\n\nmodel = train()\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train,\n                    validation_data=(X_test,y_test),\n                    batch_size=batch_size,\n                    epochs=epochs)","3becb26e":"plt.plot(range(1,epochs+1), history.history['accuracy'], label='train')\nplt.plot(range(1,epochs+1), history.history['val_accuracy'], label='test')\nplt.legend()","0f4b8cde":"plt.plot(range(1,epochs+1), history.history['loss'], label='train loss')\nplt.plot(range(1,epochs+1), history.history['val_loss'], label='test loss')\nplt.legend()","a8a80e3f":"import cv2","1860c186":"X_test = extract_features(\n    list(map(lambda x: '..\/input\/my-nsfw-dataset\/test\/test\/NSFW (2).jpg' , test))\n)","04d401d0":"y_pred = model.predict(X_test)\nif(y_pred>0.5).all():\n    print(\"This image is not safe to use and it depicts Nudity\")\nelif(y_pred<0.5).all():\n    print(\"Safe to use\")\nelse:\n    print(\"Invalid Image\")","0b0a13f1":"plt.imshow(cv2.imread('..\/input\/safeee\/s1.jpg'))","c25ade6d":"plt.imshow(cv2.imread('..\/input\/safeee\/s2.jpg'))","d0471034":"X_test = extract_features(\n    list(map(lambda x: '..\/input\/safeee\/s1.jpg' , test))\n)","16315189":"y_pred = model.predict(X_test)\nif(y_pred>0.5).all():\n    print(\"This image is not safe to use and it depicts Nudity\")\nelif(y_pred<0.5).all():\n    print(\"Safe to use\")\nelse:\n    print(\"Invalid Image\")","f5233ef2":"X_test = extract_features(\n    list(map(lambda x: '..\/input\/safeee\/s2.jpg' , test))\n)","9a432a50":"y_pred = model.predict(X_test)\nif(y_pred>0.5).all():\n    print(\"This image is not safe to use and it depicts Nudity\")\nelif(y_pred<0.5).all():\n    print(\"Safe to use\")\nelse:\n    print(\"Invalid Image\")","c1b5c664":"# Extracting Features","005e8abf":"# Training and Loss Graph","73484745":"# Importing VGG-16 Pretrained model","5b7fe650":"**Model tells that the above two images are safe images which is precise.**","182cb26e":"# Defining paths","6792d5f6":"# Safe Image","563a7b9a":"**Our model has detected it accurately as Nudity. The image can't be displayed here as it is a sensual content**","1fbc552f":"# Prediction","190c69e0":"# Training the model","8a73aeea":"# Detecting Nude image","79fb6221":"# Importing Packages","b3c0c3aa":"**These are the safe images that we use for testing**","8de074fa":"# Overall our model predicts accurately with an accuracy of around 93%"}}