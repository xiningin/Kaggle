{"cell_type":{"ea065f0d":"code","fe75389e":"code","68d1ce5e":"code","97842255":"code","ae696cbc":"code","6c63bcaf":"code","1ac79916":"code","a4a0d979":"code","2f8a7c2e":"code","a6b38dc5":"code","5fc5254a":"code","92fd9cd7":"code","2344384b":"code","0b64c0d7":"code","e4948acc":"code","37c3cb2c":"code","99998b13":"code","001c8e3c":"code","3f166519":"code","9682a8b1":"code","4e80557c":"code","283c0a01":"code","fe0dddd6":"code","4fa9c022":"code","a0d59320":"code","07e7a5a5":"code","dae36755":"code","0157425b":"code","400c3557":"code","9184b4e3":"code","62b856cc":"code","3fe2b11d":"code","c26adc15":"code","2a12e709":"code","ece16a85":"code","2a720659":"code","ec4fb4fb":"code","88c721e3":"code","d5cf1c91":"code","08aa07c2":"code","4ea78372":"code","bde4c601":"markdown","40984833":"markdown","286a7701":"markdown","e06c4f1e":"markdown","328b44a2":"markdown","83fad978":"markdown","49c63768":"markdown","949fc06a":"markdown","e968c928":"markdown","df6bd515":"markdown","dc0314db":"markdown","bb3600d2":"markdown","b179fb49":"markdown","0a078b31":"markdown","b9520a58":"markdown","960ed291":"markdown","4c66fbe4":"markdown","d2bae797":"markdown","9b35ed60":"markdown","79b25129":"markdown","2e1acf9f":"markdown","9a81796b":"markdown","546e4df0":"markdown","d140abe9":"markdown","d27df037":"markdown","939477d5":"markdown","526dd204":"markdown","4dda5b0f":"markdown","e3828b0a":"markdown"},"source":{"ea065f0d":"# libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, normalize\n# from sklearn.model_selection import GroupKFold\n# from sklearn import metrics\n\n# import time\n# import lightgbm as lgb\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# warnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)","fe75389e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","68d1ce5e":"def plot2_bid(bid, cols=['u_in_lag1','u_in_lag2']):\n    '''\n    Compare contour plots of two columns vs presure at x-axis \n    to illustrate correlation levels:\n    Is the 2nd column (blue) have potentially higher predictive power?    \n    '''\n    \n    tmp = train.loc[(train['breath_id'] == bid) & (train['time_step'] < 1.2)].reset_index(drop=True)\n    \n    fig, (ax1, ax3) = plt.subplots(1, 2, figsize = (12, 4)) \n    ax2 = ax1.twinx()\n#     ax2.plot(tmp['time_step'], tmp['cumsum'], 'b-', label='cumsum', alpha=0.5)    \n    ax2.plot(tmp['time_step'], tmp['u_out'], 'y-', label='u_out', alpha=0.5)    \n    \n    ax1.plot(tmp['time_step'], tmp['pressure'], 'r-', label='pressure', alpha=0.5)\n    ax1.plot(tmp['time_step'], tmp['u_in'], 'g-', label='u_in', alpha=0.5)\n    ax1.plot(tmp['time_step'], tmp[cols[0]], 'k--', label=cols[0], alpha=0.5)\n    ax1.plot(tmp['time_step'], tmp[cols[1]], 'b--', label=cols[1])\n\n    ax1.set_xlabel('Timestep')\n    \n    RC = tmp['RC'][0]\n    ax1.set_title(f'{RC} breath_id:{bid}')\n\n    ax1.legend(loc=(1.1, 0.7))\n    ax2.legend(loc=(1.1, 0.5))\n    \n    ####################################\n    \n    ax3.plot(tmp['pressure'], tmp['u_in'], 'g-', label='u_in', alpha=0.5)\n    ax3.plot(tmp['pressure'], tmp[cols[0]], 'k--', label=cols[0], lw=1.5, alpha=0.4)\n    ax3.plot(tmp['pressure'], tmp[cols[1]], 'b--', label=cols[1], lw=2, alpha=0.8)\n    \n    ax3.set_xlabel('Pressure') \n\n    ax3.legend(loc=(1.1, 0.7))\n    \n    fig.tight_layout()    \n    plt.show()","97842255":"# scaled version for cumulative features\ndef plot2_bid_scaled(bid, cols=['cumsum','u_in_lag2']):\n    '''\n    Plotted columns were scaled except for pressure and time_step.\n    Compare contour plots of two columns vs presure at x-axis \n    to illustrate correlation levels:\n    Is the 2nd column (blue) have potentially higher predictive power?  \n    \n    '''\n    tmp = train.loc[(train['breath_id'] == bid) & (train['time_step'] < 1.2)].reset_index(drop=True)\n    \n    fig, (ax1, ax3) = plt.subplots(1, 2, figsize = (12, 4)) \n    ax2 = ax1.twinx()   \n    \n    ax1.plot(tmp['time_step'], tmp['pressure'], 'r-', label='pressure', alpha=0.5)\n    \n    ax2.plot(tmp['time_step'], tmp['u_out'], 'y-', label='u_out', alpha=0.5)    \n    ax2.plot(tmp['time_step'], tmp['u_in'], 'g-', label='u_in', alpha=0.5)\n    ax2.plot(tmp['time_step'], tmp[cols[0]], 'k--', label=cols[0], alpha=0.5)\n    ax2.plot(tmp['time_step'], tmp[cols[1]], 'b--', label=cols[1])\n    \n    ax1.set_xlabel('Timestep')\n    ax1.set_ylabel('Pressure')\n    \n    RC = tmp['RC'][0]\n    ax1.set_title(f'{RC} breath_id:{bid}')\n    \n    ax1.legend(loc=(1.12, 0.9))\n    ax2.legend(loc=(1.12, 0.4))\n    \n    #################################### \n    ax4 = ax3.twinx()\n    ax4.plot(tmp['pressure'], tmp['u_in'], 'g-', label='u_in', alpha=0.5)\n    \n#     ax3.plot(tmp['pressure'], tmp['u_in'], 'g-', label='u_in', alpha=0.5)\n    ax3.plot(tmp['pressure'], tmp[cols[0]], 'k--', label=cols[0], lw=1.5, alpha=0.4)\n    ax3.plot(tmp['pressure'], tmp[cols[1]], 'b--', label=cols[1], lw=2, alpha=0.8)    \n            \n    ax3.set_xlabel('Pressure') \n\n    ax3.legend(loc=(1.12, 0.8))    \n    ax4.legend(loc=(1.12, 0.4))   \n    \n    fig.tight_layout()    \n    plt.show()","ae696cbc":"path = '..\/input\/ventilator-pressure-prediction'\ntrain_raw = pd.read_csv(os.path.join(path, 'train.csv'))\n# test = pd.read_csv(os.path.join(path, 'test.csv'))\n# sub = pd.read_csv(os.path.join(path, 'sample_submission.csv'))","6c63bcaf":"DEBUG = False\n#DEBUG = True\n\nif DEBUG:\n    train = train_raw.iloc[:8*5000,:]\nelse:\n    train = train_raw","1ac79916":"train.shape","a4a0d979":"train['RC'] = [f'{r}_{c}' for r, c in zip(train['R'], train['C'])]","2f8a7c2e":"RC_order = ['5_10', '5_20', '5_50', '20_10', '20_20', '20_50', '50_10', '50_20', '50_50']\nplt.figure(figsize = (10, 6))\nsns.countplot(x='RC', order=RC_order, data=train)","a6b38dc5":"# Only RC_50_10 subset have negative pressures.\ntrain.groupby('RC')['pressure'].describe().round(2)","5fc5254a":"train['u_in_lag1'] = train.groupby('breath_id')['u_in'].shift(1) \ntrain['u_in_lag2'] = train.groupby('breath_id')['u_in'].shift(2)\ntrain['u_in_lag3'] = train.groupby('breath_id')['u_in'].shift(3)\ntrain['u_in_lag4'] = train.groupby('breath_id')['u_in'].shift(4) \ntrain = train.fillna(0) \n\ntrain['area'] = train['time_step'] * train['u_in']\ntrain['area'] = train.groupby('breath_id')['area'].cumsum()\n\ntrain['cumsum'] = train.groupby('breath_id')['u_in'].cumsum()\ntrain['cumsum'] = train.groupby('breath_id')['u_in'].cumsum()\n\ntrain['step'] = train.groupby('breath_id')['time_step'].cumcount() + 1\ntrain['cummean'] = train['cumsum'] \/ train['step']","92fd9cd7":"train.tail()","2344384b":"bid_list = list(train['breath_id'].unique())","0b64c0d7":"# u_in_lag2 generally has smaller\/narrower inside contour plots along 45 degree, better correlated with pressure  \nfor bid in bid_list[:5]:\n    plot2_bid(bid)","e4948acc":"for bid in bid_list[-5:]:\n    plot2_bid(bid)","37c3cb2c":"# u_in_lag3:  mixed\/cross patterns\nfor bid in bid_list[:5]:\n    plot2_bid(bid, cols =['u_in_lag3','u_in_lag2'])","99998b13":"# u_in_lag4 looks too aggressive?\nfor bid in bid_list[:5]:\n    plot2_bid(bid, cols =['u_in_lag4','u_in_lag2'])","001c8e3c":"cols = ['pressure', 'u_in', 'u_in_lag1', 'u_in_lag2', 'u_in_lag3', 'u_in_lag4']","3f166519":"RC_list = train['RC'].unique()","9682a8b1":"a = train.loc[train['u_out'] == 0,cols]\nfig, ax = plt.subplots(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nsns.heatmap(a.corr(), cmap='coolwarm', annot=True, annot_kws={\"size\":15})\nplt.title('Pearson correlation')\nplt.subplot(1, 2, 2)\nsns.heatmap(a.corr(method=\"spearman\"), cmap='coolwarm', annot=True, annot_kws={\"size\":15}) # decimeal pts: fmt='.2g'\nplt.title('Spearman correlation')\nplt.tight_layout()","4e80557c":"fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(18,18),  sharey=True) # sharex=True,\nfor i, ax in enumerate(axes.flatten()):\n    a = train.loc[(train['u_out'] == 0) & (train['RC'] == RC_order[i]) ,cols]\n    sns.heatmap(data=a.corr(), cmap='coolwarm', annot=True, annot_kws={\"size\":18},\n                ax=ax,\n                vmin=-0.3, vmax=1,\n               ) \n    #plt.yticks(rotation=90)\n    ax.set_title(f'RC: {RC_order[i]}')\n    \nfig.tight_layout()\nplt.show()","283c0a01":"bid_list_lowCorr = list(train.loc[train['RC'] == '5_10', 'breath_id'].unique())\nfor bid in bid_list_lowCorr[-5:]:\n    plot2_bid(bid, cols =['u_in_lag4','u_in_lag2'])","fe0dddd6":"bid_list_highCorr = list(train.loc[train['RC'] == '50_50', 'breath_id'].unique())\nfor bid in bid_list_highCorr[-5:]:\n    plot2_bid(bid, cols =['u_in_lag4','u_in_lag2'])","4fa9c022":"time_step_max0 = round(train.loc[(train['u_out'] == 0), 'time_step'].max(),2)\ntime_step_max0","a0d59320":"fig, axes = plt.subplots(nrows=len(RC_order), ncols=2, figsize=(16, 30),  sharex=True) # sharex=True,\nfor i, ax in enumerate(axes.flatten()):\n    time_step_start = []\n    time_step_end = []\n    if i % 2 == 0:\n        time_step_start = 0\n        time_step_end = 0.5\n    else:\n        time_step_start = 0.5\n        time_step_end = time_step_max0\n    a = train.loc[(train['u_out'] == 0) & \n                  (train['RC'] == RC_order[int(i \/ 2)]) &\n                  (train['time_step'] >= time_step_start) &\n                  (train['time_step'] < time_step_end)\n                  ,cols]\n    sns.heatmap(data=a.corr(), cmap='coolwarm', annot=True, ax=ax, annot_kws={\"size\":14},\n                vmin=-0.3, vmax=1,\n               ) \n    ax.set_title(f'RC: {RC_order[int(i \/ 2)]},  time_step: {time_step_start} to {time_step_end}')\n    \nfig.tight_layout()\nplt.show()\n","07e7a5a5":"train.columns","dae36755":"cols = ['pressure', 'u_in', 'u_in_lag2', 'area', 'cumsum', 'cummean']","0157425b":"fig, axes = plt.subplots(nrows=len(RC_order), ncols=2, figsize=(16, 30),  sharex=True) # sharex=True,\nfor i, ax in enumerate(axes.flatten()):\n    time_step_start = []\n    time_step_end = []\n    if i % 2 == 0:\n        time_step_start = 0\n        time_step_end = 0.5\n    else:\n        time_step_start = 0.5\n        time_step_end = time_step_max0\n    a = train.loc[(train['u_out'] == 0) & \n                  (train['RC'] == RC_order[int(i \/ 2)]) &\n                  (train['time_step'] >= time_step_start) &\n                  (train['time_step'] < time_step_end)\n                  ,cols]\n    sns.heatmap(data=a.corr(), cmap='coolwarm', annot=True, annot_kws={\"size\":14},\n                ax=ax,\n                vmin=-0.3, vmax=1,\n               ) \n    ax.set_title(f'RC: {RC_order[int(i \/ 2)]},  time_step: {time_step_start} to {time_step_end}')\n    \nfig.tight_layout()\nplt.show()","400c3557":"cols_raw = ['u_in', 'u_in_lag2', 'area', 'cumsum', 'cummean']","9184b4e3":"# RobustScale() will produce negative values for most cumsum and different range for cumsum and lag2\n# scaler = RobustScaler()\n# train[cols_raw] = scaler.fit_transform(train[cols_raw])\n# train[cols_raw] = scaler.inverse_transform(train[cols_raw])","62b856cc":"train['pressure'].describe()","3fe2b11d":"# default range max = 1 is too small relative to the magnitude of pressure\nscaler = MinMaxScaler(feature_range=(0, 10))\ntrain[cols_raw] = scaler.fit_transform(train[cols_raw])","c26adc15":"train[cols_raw].describe()","2a12e709":"\ntrain.head()\n","ece16a85":"bid_list_lowCorr = list(train.loc[train['RC'] == '5_10', 'breath_id'].unique())\nprint('Please note y-scale: only target pressue and time_step on the left panel plots are still in raw scales.\\n\\\n        All other features are scaled by MinMaxScaler()')\nfor bid in bid_list_lowCorr[-5:]:\n    plot2_bid_scaled(bid, cols =['cumsum','u_in_lag2'])","2a720659":"bid_list_lowCorr = list(train.loc[train['RC'] == '5_10', 'breath_id'].unique())\nfor bid in bid_list_lowCorr[-5:]:\n    plot2_bid_scaled(bid, cols =['cummean','u_in_lag2'])","ec4fb4fb":"bid_list_lowCorr = list(train.loc[train['RC'] == '5_10', 'breath_id'].unique())\nprint('Note: now the blue curve is not for the default \"u_in_lag2\"  any more')\nfor bid in bid_list_lowCorr[-5:]:\n    plot2_bid_scaled(bid, cols =['cummean','cumsum'])","88c721e3":"bid_list_lowCorr = list(train.loc[train['RC'] == '20_10', 'breath_id'].unique())\nprint('One of two subsets with less instances in train data')\nfor bid in bid_list_lowCorr[-5:]:\n    plot2_bid_scaled(bid, cols =['cummean','cumsum'])","d5cf1c91":"bid_list_lowCorr = list(train.loc[train['RC'] == '20_20', 'breath_id'].unique())\nprint('One of two subsets with less instances in train data')\nfor bid in bid_list_lowCorr[-5:]:\n    plot2_bid_scaled(bid, cols =['cummean','cumsum'])","08aa07c2":"bid_list_highCorr = list(train.loc[train['RC'] == '50_10', 'breath_id'].unique())\nprint('The subset with largest instances in train data')\nfor bid in bid_list_highCorr[-10:]:\n    plot2_bid_scaled(bid, cols =['cummean','cumsum'])","4ea78372":"del a","bde4c601":"### Overall when `u_out == 0`","40984833":"## References\n[Ventilator Pressure Prediction: EDA, FE and models](https:\/\/www.kaggle.com\/artgor\/ventilator-pressure-prediction-eda-fe-and-models)\n\n[Ventilator Pressure: EDA and simple submission](https:\/\/www.kaggle.com\/carlmcbrideellis\/ventilator-pressure-eda-and-simple-submission)\n\n[EDA about time_step and u_out](https:\/\/www.kaggle.com\/marutama\/eda-about-time-step-and-u-out\/notebook)","286a7701":"**Lag2 wins** 6 times out of 9 subsets and is expected to work well at `R` in (20, 50).\n>  Still at medium high corr: 0.45 (5_20) and 0.65 (5_50). lag2 correlats well with lag4 when `C` > 10. So the net benifit may be small if both lag2 and lag 4 in the model.\n\n>  5_10 subset: low or near-zero corr \n\nLag4 wins the remaing 3 subests with `R` = 5. \n>  Low resistence `R` = 5 has very high correlations (>0.8) between neighboring lags.","e06c4f1e":"# Summary\n\nMost EDAs usually and naturally just used `time_step` as x-axis for pressure prediciton.\n\nWhen `pressure` is also used as x-axis, it may provide additinal insights. For example, we can easily illustrate why `u_in_lag2` is a better feature than `u_in_lag1`.\n\nThe correlation heatmaps were shown:\n>  9 R-C combinations\n\n>  before and after 0.5 min for `time_step`.\n\nWe know it is not a simple linear regression or linear correlation. But association pattern illustations may help ask interesting questions: \n* why `R=50, C=20` has the highest subset size? whether this subset implies larger prediction errors?\n* which R\/C combination will not be predicted globally well by a new feature \n* whether stratified splits and conditional lag amounts are needed\n\nFinding:\n* `u_in_lag2` is medium high correlated with `pressure` while`u_in_lag4` maybe not provide additional net benefit. (`cumsum` will take care when `u_in_lag2` is not that good at R=5.)\n* `cumsum` is very highly correlated with `pressure` and can complement `u_in_lag2` (eg. R=5, C=10 subset).\n* `cummean` has relatively higher correlation in the later stage than early ramp stage (say > 0.5 min).\n\nExploring...","328b44a2":"**High correlation (>0.9) between pressure and cumsum when R=5 and C=10!** (straight up line on the right plot (dashed gray) of cumsum ~ pressure).","83fad978":"Finding:\n* Yes,`cumsum` has extremely high correlations for 5_10 subset which u_in_lag2 may fail.\n* `cumsum` correlates very high during the entire 1 min.\n* `cummean` consistently correlates higher during **later stage**, after 0.5 min, even close to last_u_in.","49c63768":"Is it so fun to explore challenging pressure curves which will be predicted better and better by your amazing ML models?\n\nHope these plenty lots with `breath_id` labeled would sometime faciltate your wonderful new idea and modeling!\nThat's what I am learning from kaggle communicty like you.","949fc06a":"# u_in_lag3 vs lag2","e968c928":"# u_in_lag4 vs lag2","df6bd515":"# Function","dc0314db":"There seem similar levels of correlations between parametric pearson and non-parametric spearman methods.","bb3600d2":"### By R and C subsets","b179fb49":"## Motivation: Some subsets (e.g. 5_10) are expected to have hihger correlation with pressure by cumulative features than u_in_lag2","0a078b31":"### Revisit the 3 subsets with min and max instances","b9520a58":"# Corr by R_C subsets","960ed291":"Based on the corr heatmaps, more breath_id plots from two subsets with distinct patterns: top left and bottom right.","4c66fbe4":"## Revisit subset R=5 and C=10.","d2bae797":"# Corr in early <0.5min\nPatterns may be different during ramp and PIP\/plateau stages.","9b35ed60":"# cumsum, cummean, area","79b25129":"### Thank you for your reading!","2e1acf9f":"Is `RC_50_10` a special group?","9a81796b":"### cummean vs cumsum","546e4df0":"## cummean","d140abe9":"As expected,`u_in` features tend to have larger preditive power during the early ramp stage (time_step < 0.5 or earlier).\n\nLag2 is still the winner most of the time. It is OK in the early stage for`5_10` subset, where lag4 seems the best though.\n\n-- Different optimal lag amounts for some subsets?\n\n","d27df037":"## Data loading and overview","939477d5":"Compared to the left shifting plots, the right plots are easier to show the improvement due to lag2: shrunk blue area, eg breath_id 1 and 4.\n\nTry the bottom 5 instances to further checking.","526dd204":"5_10 subset: pressure grows relatively smoothly.\nCumulative **area**, **cumsum**, **cummean** (as already proposed by other teams) may work better than lag2 for this subset?","4dda5b0f":"# u_in_lag2 vs lag1","e3828b0a":"Want to confirm the relative feature importance for the added features in lightGBM,then select good ones applied to LSTM. \n\nHowever, kaggle said too much memory was used during lgbm training. Not sure why simple correlation analysis used so much memory."}}