{"cell_type":{"869a1acb":"code","f873b87b":"code","0777ec2f":"code","1ea2a388":"code","cb3d63b3":"code","8f95b635":"code","5a426010":"code","97e70555":"code","7dc1531e":"code","291e4fa2":"code","23c09ade":"code","64bf7e7c":"code","8f8bedfa":"code","281bbe42":"code","749ec312":"code","0dd9f97b":"code","4300203f":"code","1b212b58":"code","3f4a4a3a":"markdown","e4059735":"markdown","f3449ec8":"markdown","921146b5":"markdown","22aae949":"markdown","25b7cda8":"markdown","b0599b5b":"markdown","91815825":"markdown","34c44d46":"markdown","49bd70aa":"markdown","bf88651d":"markdown","fb4633a8":"markdown","fef78314":"markdown"},"source":{"869a1acb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\npet_data = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\npet_data.head()","f873b87b":"pet_data.columns","0777ec2f":"features =['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\nX = pet_data[features]\ny = pet_data.Pawpularity","1ea2a388":"plt.figure(figsize = (20, 8))\nsns.heatmap(pet_data.corr(), annot = True, cmap = \"YlGnBu\")\nplt.show()","cb3d63b3":"from sklearn.ensemble import ExtraTreesRegressor\nSelection = ExtraTreesRegressor()\nSelection.fit(X,y)","8f95b635":"print(Selection.feature_importances_)","5a426010":"# Plotting the feature importances for better understanding\n\nplt.figure(figsize= (12,8))\nfeat_importances = pd.Series(Selection.feature_importances_, index = X.columns)\nfeat_importances.nlargest(10).plot(kind = 'barh', )\nplt.show()","97e70555":"from sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 0)\n\nmodel = XGBRegressor(n_estimators=6)\n\nmodel.fit(train_X, train_y, \n             eval_set=[(test_X, test_y)],\n             verbose=False)\nprint(\"Training Score: \", model.score(train_X, train_y))\n\npreds_y = model.predict(test_X)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(test_y, preds_y)))\nprint(\"Test Score: \", model.score(test_X, test_y))","7dc1531e":"sns.distplot(test_y-preds_y)\nplt.show()","291e4fa2":"plt.scatter(test_y, preds_y, alpha = 0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_predictions\")\nplt.show()","23c09ade":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nimport time","64bf7e7c":"# A parameter grid for XGBoost\nparams = {\n    'n_estimators':[1,5,6,10,20,50,100,200,500,1000], \n    'objective': ['reg:squarederror', 'reg:tweedie'],\n    'booster': ['gbtree', 'gblinear'],\n    'importance_type': ['gain','weight', 'cover'],\n    'eval_metric': ['rmse'],\n    'n_jobs': [i for i in range(1,100)],\n    'nthread': [i for i in range(-10,10)],\n    'eta': [i\/10.0 for i in range(3,6)],\n}\n\nreg = XGBRegressor(random_state = 11)\n\n# run randomized search\nn_iter_search = 100\nrandom_search = RandomizedSearchCV(reg, param_distributions=params,\n                                   n_iter=n_iter_search, cv=5, iid=False, scoring='neg_mean_squared_error')\n\nstart = time.time()\nrandom_search.fit(train_X, train_y)\nprint(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n      \" parameter settings.\" % ((time.time() - start), n_iter_search))","8f8bedfa":"best_regressor = random_search.best_estimator_\nbest_regressor","281bbe42":"val_predicts = best_regressor.predict(test_X)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(test_y, val_predicts)))","749ec312":"x_ax = range(len(test_y))\nplt.figure(figsize = (20, 5))\nplt.plot(x_ax, test_y, label=\"original\")\nplt.plot(x_ax, val_predicts, label=\"predicted\")\nplt.title(\"Pawpularity test and predicted data\")\nplt.legend()\nplt.show()","0dd9f97b":"pet_test = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\npet_test.head()","4300203f":"X_test= pet_test[features]\npredictions = best_regressor.predict(X_test)","1b212b58":"output = pd.DataFrame({\"Id\": pet_test.Id, \"pawpularity\": predictions})\noutput.to_csv('submission.csv', index = False)","3f4a4a3a":"# EDA, Machine Learning and Hyperparameter Tuning for Pawpularity of Petfinder:\nHere first we explored the data carefully by finding correlation between the features, and also the top 10 important features using ExtraTreeRegressor Model. Then applied the XGBRegressor model to the data and at last did some hyperparameter tuning to improve the prediction.","e4059735":"Using ExtraTreesRegressor Module to find the ranking of the features based on its importance","f3449ec8":"From above it is clear that \n\n1. Occlusion and Human\n2. Face and Eyes\n3. Collage and Info\n\nare the top 3 correlated features","921146b5":"# Hyper Parameter Tuning\nChoose following method for hyperparameter tuning\n*  RandomizedSearchCV --> Fast\n    1. GridSearchCV\n    2. Assign hyperparameters in form of dictionery\n* Fit the model\n* Check best paramters and best score","22aae949":"# The Top 10 Most Important Features","25b7cda8":"# Exploratory Data Analysis (EDA)","b0599b5b":"Importing essential moduls and exploring training data using read_csv method of Pandas","91815825":"# Fitting model using XGBRegressor\n1. Import model\n2. Split dataset into train and test set in order to predict w.r.t test_X\n3. Fit the data using XGBRegressor Model\n4. Predict w.r.t test_X\n5. In regression check RSME Score\n6. Plot graph","34c44d46":"From above figure it is clear that the **Near** feature is the most important while the **subject** focus is the least of 10 features","49bd70aa":"Taking out the Target i.e. Pawpularity from the Data","bf88651d":"# The Top 3 Most Correlated Features","fb4633a8":"**Note:** Suggestions are Highly appreciated for improvement.","fef78314":"Which shows an improvement"}}