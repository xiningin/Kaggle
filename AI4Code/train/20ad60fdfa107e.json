{"cell_type":{"2acb296f":"code","f9f81a50":"code","5d9d7656":"code","536defe7":"code","395c9241":"code","6136be92":"code","a43a25f0":"code","8f04f297":"code","46bc31a1":"code","557478ac":"code","6ca104cd":"code","eefcb434":"code","82c17eae":"code","a0c681fa":"code","71c64839":"code","1db8ef7d":"code","060f9013":"code","b1636037":"code","4cae384b":"code","db0fb49d":"code","0344f5c9":"code","b96567f8":"code","663d8505":"code","a615f566":"code","f219ad24":"code","1b91d11d":"code","c667656d":"code","036691eb":"code","1a8a62e2":"code","7aff10c0":"code","d0382327":"code","97712082":"markdown","61f4ff28":"markdown","f925caec":"markdown","6022f430":"markdown","66b38b6d":"markdown","7c5add4b":"markdown","48be3046":"markdown","249e3b35":"markdown","b1d6053c":"markdown","a899efe7":"markdown","1a01e933":"markdown","f775026c":"markdown","0eb22e3f":"markdown","61f5b2c8":"markdown","680eb1be":"markdown","7876fe87":"markdown","89b1e81a":"markdown","b4c5554c":"markdown","f9f58de6":"markdown","94b1ba43":"markdown","5c7ca185":"markdown","93cd2d4d":"markdown","ea18eb7e":"markdown"},"source":{"2acb296f":"import sqlite3\nimport pandas as pd \nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt ","f9f81a50":"cnx = sqlite3.connect('..\/input\/database.sqlite')\ndata = pd.read_sql_query(\"SELECT * FROM Player_Attributes\", cnx)\ndata.shape","5d9d7656":"data.head()","536defe7":"data.describe()","395c9241":"data.columns","6136be92":"# Let's look for null values \ndata.isnull().sum()\n#data[data.isnull().any(axis = 1)]","a43a25f0":"data = data.dropna()\ndata.shape","8f04f297":"features =list(data.columns[~(data.columns.str.contains('id'))])\nfeatures\n# We also do not need overall_rating as that is our target and date \nfeatures.remove('date')\nfeatures.remove('overall_rating')\nfeatures\ndata[features].head()","46bc31a1":"remove = ['preferred_foot', 'attacking_work_rate', 'defensive_work_rate']\nfor i in remove:\n    features.remove(i)\nfeatures","557478ac":"# Let's loop through all the features \n\nfor feature in features:\n    co = data['overall_rating'].corr(data[feature])\n    dict[feature] = co\ndict","6ca104cd":"%matplotlib inline\nimport matplotlib.pyplot as plt\nx_values = []\ny_values = []\nfor value in dict:\n    x_values.append(value)\n    y_values.append(dict[value])\n\n# Plotting the values using matplotlib.pyplot\nplt.xlabel('Features in the data')\nplt.ylabel('Correlation Coefficient with Overall Rating')\nplt.title('Correlation of Overall Rating with different features')\nplt.yticks([0, 1])\n\n#Adjusting the size of the image \nfrom matplotlib.pyplot import figure\nfigure(num = None, figsize = (30, 6), dpi=80, facecolor='w', edgecolor='k')\n\nplt.plot(x_values, y_values)\nplt.show()\n","eefcb434":"%matplotlib inline\n\n#Plotting a subplot\nfig, axis = plt.subplots(figsize = (40, 8))\n# Grid lines, Xticks, Xlabel, Ylabel\n\naxis.yaxis.grid(True)\naxis.set_title('Overall Player Rating',fontsize=10)\naxis.set_xlabel('Player Features',fontsize=10)   \naxis.set_ylabel('Correlation Values',fontsize=10)\naxis.set_yticks([0,1])\naxis.set_yticklabels(['0', '1'])\n\n# # We can also use this to set figure size \n# f.set_figheight(15)\n# f.set_figwidth(15)\n\naxis.plot(x_values, y_values)\nplt.show()","82c17eae":"# Let's also specifiy the target \ntarget = ['overall_rating']","a0c681fa":"# Obtain the X and y values for regression analysis\nX = data[features]\ny = data[target]","71c64839":"# Let us look at a typical row from our features:\nX.head()\n# X.iloc[2]","1db8ef7d":"y.head() ","060f9013":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 324)","b1636037":"X_train.describe()","4cae384b":"X_test.describe()","db0fb49d":"regressor = LinearRegression()\nregressor.fit(X_train, y_train)","0344f5c9":"y_prediction = regressor.predict(X_test)\ny_prediction","b96567f8":"#Let's explore the predictions. \ny_prediction.mean()","663d8505":"y_test.describe().transpose()","a615f566":"RMSE = sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))","f219ad24":"print(RMSE)","1b91d11d":"from sklearn.metrics import r2_score, accuracy_score","c667656d":"print(r2_score(y_test, y_prediction))","036691eb":"#print(accuracy_score(y_test, y_prediction))","1a8a62e2":"decision_regressor = DecisionTreeRegressor(max_depth = 50)\ndecision_regressor.fit(X_train, y_train)","7aff10c0":"y_prediction = decision_regressor.predict(X_test)\ny_prediction.mean()","d0382327":"RMSE = sqrt(mean_squared_error(y_test, y_prediction))\nprint(RMSE)","97712082":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nDeclare the Columns You Want to Use as Features\n<br><br><\/p>\n","61f4ff28":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\n(1) Linear Regression: Fit a model to the training set\n<br><br><\/p>\n\n","f925caec":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\n(2) Decision Tree Regressor: Fit a new regression model to the training set\n<br><br><\/p>\n","6022f430":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nWhat is the mean of the expected target value in test set ?\n<br><br><\/p>","66b38b6d":"Let's find out the error value","7c5add4b":"Feel free to go through the dataset and explore it as much as you can ","48be3046":"Let's drop the null values ","249e3b35":"Let's get a brief overview of what this data contains. ","b1d6053c":"That is a pretty low error value and that is very good. Let's also find the accuracy and r2 score. ","a899efe7":"## Error\nWe get an error for the above value. To find out why, [click here](http:\/\/https:\/\/www.kaggle.com\/questions-and-answers\/92771****)","1a01e933":"## Data Cleaning ","f775026c":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nEvaluate Linear Regression Accuracy using Root Mean Square Error\n\n<br><br><\/p>\n","0eb22e3f":"### Correlation Plot","61f5b2c8":"Let us also display our target values: ","680eb1be":"We got a surprisingly low error value for this data set compared to Linear Regressor even though the mean of linear regressor was closer to the actual one. We can reduce the error value by increasing the depth of the Decision Tree. We can also increase the accuracy by increasing the size of the training set ( set testsize = 0.1 )","7876fe87":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nSplit the Dataset into Training and Test Datasets\n<br><br><\/p>\n","89b1e81a":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nSpecify the Prediction Target\n<br><br><\/p>\n","b4c5554c":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nPerform Prediction using Decision Tree Regressor\n<br><br><\/p>","f9f58de6":"Let's also plot these values on line plot to get an idea of the dependence of overall rating on r","94b1ba43":"We can see above that there are more non numeric values in this data. Remove those. ","5c7ca185":"In this we can make a dictionay of coorelations of all the features on overall ratings. Let's do that. This is being done to select our features. ","93cd2d4d":"<p style=\"font-family: Arial; font-size:1.75em;color:blue; font-style:bold\"><br>\n\nPerform Prediction using Linear Regression Model\n<br><br><\/p>\n","ea18eb7e":"Let's look at all the columns present in the dataset"}}