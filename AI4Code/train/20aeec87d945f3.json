{"cell_type":{"449f86c2":"code","cde74e76":"code","c6857eae":"code","2c89c143":"code","e5775ca9":"code","9ba0b750":"code","703ab943":"code","8003a8ee":"code","83517955":"code","763ed7b8":"code","d12e9c35":"code","67a90e24":"code","62361574":"code","9f0f34ce":"code","68d4b871":"code","43a1342e":"code","d402bcf5":"code","b14d306d":"code","5c7cbe32":"code","3e0b54ad":"code","188b9e2f":"markdown","a9589499":"markdown","a5db8304":"markdown","8d195205":"markdown","35c98d33":"markdown","c2cbab3a":"markdown","a8777964":"markdown","4ee6835b":"markdown","6eac0cbc":"markdown","a5b25b77":"markdown","109b62da":"markdown","ddf20c3b":"markdown","a2459e09":"markdown","c8ed1adb":"markdown","0719e0c1":"markdown"},"source":{"449f86c2":"import os\nimport h5py\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import KFold","cde74e76":"os.listdir('\/kaggle\/input\/trends-assessment-prediction\/')","c6857eae":"import sys\n!cp ..\/input\/rapids\/rapids.0.13.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path\n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","2c89c143":"def metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)\/np.sum(y_true, axis=0))","e5775ca9":"import cudf\nfrom cuml import SVR","9ba0b750":"fnc_df = cudf.read_csv(\"..\/input\/trends-assessment-prediction\/fnc.csv\")\nloading_df = cudf.read_csv(\"..\/input\/trends-assessment-prediction\/loading.csv\")\n\n\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\ndf = fnc_df.merge(loading_df, on=\"Id\")\n\n\nlabels_df = cudf.read_csv(\"..\/input\/trends-assessment-prediction\/train_scores.csv\")\nlabels_df[\"is_train\"] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n\ndf.shape, test_df.shape","703ab943":"loading_df.shape","8003a8ee":"temp_data =  train_data.drop(['Id'], axis=1)\nplt.figure(figsize = (15, 10))\nsns.heatmap(temp_data.corr(), annot = True, cmap=\"brg\")\nplt.yticks(rotation=0) \nplt.show()","83517955":"fnc_df.head()","763ed7b8":"labels_df.head()","d12e9c35":"labels_df.isnull().sum()\n","67a90e24":"temp_data =  loading_df.drop(['Id'], axis=1)\nplt.figure(figsize = (20, 20))\nsns.heatmap(temp_data.corr(), annot = True, cmap=\"RdYlGn\")\nplt.yticks(rotation=0) \nplt.show()","62361574":"import nilearn as nl\nimport nibabel as nib\nfrom nilearn import image\nfrom nilearn import plotting\nfrom nilearn import datasets\nfrom nilearn import surface\nimport nilearn.plotting as nlplt","9f0f34ce":"fmri_mask = '..\/input\/trends-assessment-prediction\/fMRI_mask.nii'","68d4b871":"smri = 'ch2better.nii'\nmask_img = nl.image.load_img(fmri_mask)\n\ndef load_subject(filename, mask_img):\n    subject_data = None\n    with h5py.File(filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_img = nl.image.new_img_like(mask_img, subject_data, affine=mask_img.affine, copy_header=True)\n\n    return subject_img\n\n\nfiles = random.choices(os.listdir('..\/input\/trends-assessment-prediction\/fMRI_train\/'), k = 3)\nfor file in files:\n    subject = os.path.join('..\/input\/trends-assessment-prediction\/fMRI_train\/', file)\n    subject_img = load_subject(subject, mask_img)\n    print(\"Image shape is %s\" % (str(subject_img.shape)))\n    num_components = subject_img.shape[-1]\n    print(\"Detected {num_components} spatial maps\".format(num_components=num_components))\n    rsn = subject_img\n    #convert to 3d image\n    first_rsn = image.index_img(rsn, 0)\n    print(first_rsn.shape)     \n    plotting.plot_glass_brain(first_rsn,display_mode='lyrz')\n    print(\"-\"*50)","43a1342e":"motor_images = datasets.fetch_neurovault_motor_task()\nstat_img = motor_images.images[0]\nview = plotting.view_img_on_surf(stat_img, threshold='90%')\nview.open_in_browser()\nview","d402bcf5":"FNC_SCALE = 1\/500\n\ndf[fnc_features] *= FNC_SCALE\ntest_df[fnc_features] *= FNC_SCALE","b14d306d":"%%time\n\nNUM_FOLDS = 7\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\n\nfeatures = loading_features + fnc_features\n\noveral_score = 0\nfor target, c, w in [(\"age\", 100, 0.3), (\"domain1_var1\", 10, 0.175), (\"domain1_var2\", 10, 0.175), (\"domain2_var1\", 10, 0.175), (\"domain2_var2\", 10, 0.175)]:    \n    y_oof = np.zeros(df.shape[0])\n    y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n    \n    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n        train_df = train_df[train_df[target].notnull()]\n\n        model = SVR(C=c, cache_size=3000.0)\n        model.fit(train_df[features], train_df[target])\n\n        y_oof[val_ind] = model.predict(val_df[features])\n        y_test[:, f] = model.predict(test_df[features])\n        \n    df[\"pred_{}\".format(target)] = y_oof\n    test_df[target] = y_test.mean(axis=1)\n    \n    score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n    overal_score += w*score\n    print(target, np.round(score, 4))\n    print()\n    \nprint(\"Overal score:\", np.round(overal_score, 4))","5c7cbe32":"sub_df = cudf.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.head(10)","3e0b54ad":"sub_df.to_csv(\"submission.csv\", index=False)","188b9e2f":"# Check dataset list ","a9589499":"# Submission Part","a5db8304":"![image.png](attachment:image.png)","8d195205":"# <span style=\"color:DarkBlue\"> Glass brain visualization\nGlass Brain is a tool that maps the electrical activity of your brain in realtime.The anatomically realistic 3D brain will show realtime data from electroencephalographic (EEG) signals taken from a specially-designed EEG cap.This data is mapped to the source of that electrical activity, i.e. the specific part of the brain. The underlying brain model is generated through MRI scans so that the EEG data is accurately mapped to an individual's brain model.\n\nDifferent colours are given to the different signal frequency bands to create a beautiful interactive artwork that seems to crackle with energy, showing how information is transferred (or at least estimated to do so) between different regions of the brain.","35c98d33":"# <span style='color:Red'> Thanks for reading the notebook \u2764 If you like, please Upvote \ud83d\udc95","c2cbab3a":"# Install RAPID","a8777964":"# Load Dataset","4ee6835b":"# Define Evaluation Metrix","6eac0cbc":"# <span style='color:Red'> Let's Try the Heatmap ","a5b25b77":"# <span style='color:Red'> Brain Image Visualization Library","109b62da":"# <span style='color:DarkOrange'> 3D Plots of statistical maps ","ddf20c3b":"**References :**\n\n* https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC3983169\/\n* https:\/\/www.kaggle.com\/aerdem4\/rapids-svm-on-trends-neuroimaging\n* https:\/\/www.kaggle.com\/aaroha33\/trends-neuroimaging-easy-notebook\n* https:\/\/www.kaggle.com\/saife245\/neuroimaging-in-depth-understanding-eda-model","a2459e09":"# <span style=\"color:Green\"> \u211d\ud835\udd38\u2119\ud835\udd40\ud835\udd3b\ud835\udd4a - \ud835\udd4b\u211d\ud835\udd56\u2115\ud835\udd3b\ud835\udd4a \u2115\ud835\udd56\ud835\udd66\ud835\udd63\ud835\udd60\ud835\udd5a\ud835\udd5e\ud835\udd52\ud835\udd58\ud835\udd5a\ud835\udd5f\ud835\udd58 \u2764\n    \n\n   \nImages of the human brain, in form and function, seem to be everywhere these days - on television, in glossy magazines, and on internet blogs worldwide. This is due, in many respects, to the incredible amount of information these images present and the sheer number of brain imaging research studies being performed to spy on the brain in action or at rest, to examine how it is built and wired, and what happens when things go wrong. Indeed, neuroimagers routinely collect more study data in a few days than was collected in over an entire year just a decade ago. These data are a rich source of information on detailed brain anatomy, the subtle variations in brain activity in response to cognitive stimuli, and complex patterns of inter-regional communication. Taken individually, these various data types would have once formed the basis for entire research programs. Now, with interests not only in multi-modal neuroimaging but the inclusion of co-occurring biological and clinical variable collection requiring linkage between geographically distributed researchers, neuroscience programs are rapidly becoming the brain-focused versions of projects more akin to those involving particle physics. The methods by which these data are obtained are themselves contributing to this growth, involving finer spatial and temporal resolution as MR physicists push the limits of what is possible and as brain scientists then rush to meet those limits. It is safe to say that human neuroimaging is now, officially, a \u201cbig data\u201d science.\n\nSuch examples of large-data, their promise and challenges, have not gone unnoticed. In the US, The National Science Foundation, the National Institutes of Health, the Defense Department, the Energy Department, Homeland Security Department as well as the U.S. Geological Survey have all made commitments toward \u201cbig data\u201d programs. The Obama Administration itself has even gotten in on the act. In response to recommendations from the President\u2019s Council of Advisors on Science and Technology, the White House sponsored a meeting bringing together a cross-agency committee to lay out specific actions agencies should take to coordinate and expand the government\u2019s investment in \u201cbig data\u201d, totaling $200 million in support (see http:\/\/www.whitehouse.gov\/sites\/default\/files\/microsites\/ostp\/big_data_fact_sheet_final.pdf). Among the examples of \u201cbig data\u201d featured at the meeting was \u2013 no surprise - human neuroimaging. Additionally, the recent anouncement of the Brain Research through Advancing Innovative Neurotechnologies (BRAIN) Initiative (http:\/\/nih.gov\/science\/brain\/index.htm) forms part of a new Presidential focus aimed at revolutionizing understanding of the human brain. Initiatives surrounding large-scale brain mapping are also underway in Europe (http:\/\/www.humanbrainproject.eu\/; Frisoni 2010) and examples of large-scale brain data sets have been on full display at recent annual meetings of the Organization for Human Brain Mapping (OHBM; http:\/\/www.humanbrainmapping.org) in Beijing, China in 2012 and Seattle, Washington in June 2013.\n\nHowever, as the richness of brain data sets continues to grow and the push to place it in accessible repositories mounts, there are many issues to be considered on how to handle the data, move it from place to place, how to store it, analyze it, and share it.","c8ed1adb":"# Import Basic Libraries","0719e0c1":"## <span style=\"color:Blue\"> Please upvote this kernel if you like this notebook  \u2763"}}