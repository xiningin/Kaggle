{"cell_type":{"5dc22937":"code","397e9506":"code","3206d3f5":"code","533aee1e":"code","110b2534":"code","0a7e95a5":"code","5c0a8f3b":"code","e4097122":"code","9da5a298":"code","6dab521f":"code","932a5708":"code","53546841":"code","c6d5107a":"code","f984ada7":"code","9fa086b2":"code","0728e389":"code","5dfcba33":"code","1f75ee58":"code","5e2f62ae":"code","cbfb56ef":"markdown","6b49c2c7":"markdown","bcddd88a":"markdown","134b43f1":"markdown","426062fc":"markdown","90dbc814":"markdown","a130b49e":"markdown","50635921":"markdown","a86bbe31":"markdown","a1b811d5":"markdown","d21e1bbc":"markdown","d1178c08":"markdown","956cd1f0":"markdown","2f1b23eb":"markdown"},"source":{"5dc22937":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image \nimport matplotlib.image as mpimg\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom tensorflow.keras.layers import Input, Conv2D,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom IPython.display import clear_output\nimport random, re, math\nimport pandas as pd \nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\n","397e9506":"df=pd.read_csv('..\/input\/landmark-recognition-2021\/train.csv')\ndf.head()","3206d3f5":"%%time\ndf['path']=['..\/input\/landmark-recognition-2021\/train\/'+id[0]+'\/'+id[1]+'\/'+id[2]+'\/'+id+'.jpg' for id in df['id']]\ndf.head()","533aee1e":"df.info()","110b2534":"df['landmark_id'].nunique()","0a7e95a5":"df['landmark_id'].value_counts()","5c0a8f3b":"df['landmark_id'].describe()","e4097122":"\ndf['id_counts'] = df.landmark_id.value_counts().loc[df.landmark_id.values].values\nid_map = df.sort_values(by='id_counts').landmark_id.drop_duplicates().reset_index(drop=True)\nid_dict = {id_map.loc[x]:81312-x for x in range(81313)}\ndf['encode_id'] = df.landmark_id.apply(lambda x: id_dict[x])\ndf.head()","9da5a298":"df['landmark_id'].describe()","6dab521f":"df['encode_id'].describe()","932a5708":"plt.subplots(3, 4, figsize=(160, 120))\nfor i in range(12):\n    sp = plt.subplot(3, 4, i + 1)\n    sp.axis('Off')\n    im = mpimg.imread(df.iloc[i][2])\n    plt.imshow(im)\n    plt.title(f'landmark_id:{df.iloc[i][1]} ', \n                                     fontweight =\"bold\",fontsize=100)\n    ","53546841":"AUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nIMAGE_SIZE = [256, 256]\nEPOCHS = 40\nSEED = 24\nBATCH_SIZE = 32 ","c6d5107a":"def flip(image,label):\n    \n    image = tf.image.flip_left_right(image)\n    \n    return image,label\n\n\n\ndef rotate(image,label):\n\n    rot = 15. * tf.random.normal([1],dtype='float32')\n    rotation = math.pi * rot \/ 180.\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    m = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n    DIM = IMAGE_SIZE[0]\n    XDIM = DIM%2 \n    x = tf.repeat( tf.range(DIM\/\/2,-DIM\/\/2,-1), DIM )\n    y = tf.tile( tf.range(-DIM\/\/2,DIM\/\/2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM\/\/2+XDIM+1,DIM\/\/2)\n    idx3 = tf.stack( [DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n    img=tf.reshape(d,[DIM,DIM,3])\n    return img,label\n#tf.cast(np.array(img), dtype=tf.float32)\n\n\n\ndef read_image_and_label(image_path, label=None,resize=IMAGE_SIZE):\n    \n    image=tf.io.read_file(image_path)\n    image=tf.image.decode_jpeg(image, channels=3)\n    image=tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, dtype=tf.float32)\/255.\n    if not label is None:\n        return image, label\n    return image\n\n\n\n\ndef get_training_dataset(df):\n    \n    training_dataset = tf.data.Dataset.from_tensor_slices((df[\"path\"].values, df[\"encode_id\"].values))\n    training_dataset = training_dataset.map(read_image_and_label,num_parallel_calls=AUTO)\n    training_dataset = training_dataset.map(flip,num_parallel_calls=AUTO)\n    training_dataset = training_dataset.map(rotate,num_parallel_calls=AUTO)\n    training_dataset = training_dataset.shuffle(1000, reshuffle_each_iteration=True)\n    training_dataset = training_dataset.batch(BATCH_SIZE)\n    training_dataset = training_dataset.prefetch(AUTO)\n\n    return training_dataset\n\n\ndef get_validation_dataset(df,batch_size=16):\n  \n  validation_dataset = tf.data.Dataset.from_tensor_slices((df[\"path\"].values, df[\"encode_id\"].values))\n  validation_dataset = validation_dataset.map(read_image_and_label)\n  validation_dataset = validation_dataset.batch(BATCH_SIZE)\n  \n\n  return validation_dataset\n\n\ndef get_test_dataset(images,batch_size=16):\n  \n  test_dataset = tf.data.Dataset.from_tensor_slices((images))\n  test_dataset = test_dataset.map(read_image_and_label)\n  test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n\n  return test_dataset","f984ada7":"tr_dataset = get_training_dataset(train_test_split(df, random_state=SEED, test_size=.25)[0])\nval_dataset = get_validation_dataset(train_test_split(df, random_state=SEED, test_size=.25)[1])","9fa086b2":"row = 2; col = 4;\nall_elements = tr_dataset.unbatch()\none_element = tf.data.Dataset.from_tensors( next(iter(all_elements)) )\naugmented_element = one_element.repeat().map(rotate).batch(row*col)\n\nfor (img,label) in augmented_element:\n    plt.figure(figsize=(15,int(15*row\/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        plt.axis('off')\n        plt.imshow(img[j,])\n        \n    plt.show()\n    break","0728e389":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\ndef conv_block(filters, inputs):\n    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    outputs = layers.MaxPool2D()(x)\n\n    return outputs\n\n\ndef dense_block(units, dropout_rate, inputs):\n    x = layers.Dense(units, activation=\"relu\")(inputs)\n    x = layers.BatchNormalization()(x)\n    outputs = layers.Dropout(dropout_rate)(x)\n\n    return outputs","5dfcba33":"def build_model():\n    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(inputs)\n    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n    x = layers.MaxPool2D()(x)\n\n    x = conv_block(32, x)\n    x = conv_block(64, x)\n\n    x = conv_block(128, x)\n    x = layers.Dropout(0.2)(x)\n\n    x = conv_block(256, x)\n    x = layers.Dropout(0.2)(x)\n\n    x = layers.Flatten()(x)\n    x = dense_block(512, 0.7, x)\n    x = dense_block(128, 0.5, x)\n    x = dense_block(64, 0.3, x)\n\n    outputs = layers.Dense(81313, activation=\"softmax\")(x)\n\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model","1f75ee58":"\nmodel = build_model()\nmodel.summary()","5e2f62ae":"\n# Compile Model. \nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['acc']\n)\n\n# Train the Model\n#history = model.fit_generator( tr_dataset, epochs=2,validation_data=val_dataset)\n\n","cbfb56ef":"## Build a model","6b49c2c7":"## Model training","bcddd88a":"### Since we have a large dataset,a complex model works better than a simple one but as we will have a long runtime I used a simple model with just 2 epochs in this notebook!","134b43f1":"## Configuration","426062fc":"## Making a dataframe of label_train\n","90dbc814":"### ***By adding path to our dataframe we can use this dataframe in Tensorflow directly!***","a130b49e":"## Importing Library\u00b6\n","50635921":"## Label types and null values check\u00b6","a86bbe31":"\n# Google Landmark Recognition 2021 ","a1b811d5":"## Adding path_columns from train images pathes","d21e1bbc":"## Display Example Augmentation\u00b6\u00b6\n","d1178c08":"## label number check","956cd1f0":"## Encoding the landmark_id","2f1b23eb":"## Let's take a look at some image examples and their correponding Landmark_id"}}