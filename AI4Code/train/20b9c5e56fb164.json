{"cell_type":{"c1246749":"code","906c38dd":"code","a88a04bc":"code","08047a52":"code","415f913f":"code","b0939224":"code","fc87f854":"code","459ebebb":"code","05ac9922":"code","5c0babd4":"code","f2ea1baf":"code","afd49994":"code","072b774e":"code","299c6a08":"code","9c9383af":"code","e3e276f7":"code","7f821435":"code","e95d5abf":"code","d209a91a":"code","af38c807":"code","5a300ae5":"code","a8b99718":"code","0e5a776c":"code","af865938":"code","bde92173":"code","9dfe9ca9":"code","69005b84":"code","3b7c693c":"code","c1970e7f":"code","cc23deed":"code","f0f01894":"code","0b9cc041":"code","49441961":"code","fb65a7bc":"code","1fafa859":"markdown","73008edf":"markdown","51900867":"markdown"},"source":{"c1246749":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","906c38dd":"#Import libraries\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew, norm\nfrom scipy.stats.stats import pearsonr\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\n%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n%matplotlib inline","a88a04bc":"#Load data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nprint(train.shape)\ntrain.head()","08047a52":"test.head()","415f913f":"#Check training data for missing values\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nprint(missing_data.head(20))","b0939224":"#DEAL WITH MISSING VALUES\n\n#Delete columns from both training and test data where missing data is more than 1 (all except Electrical)\ntrain = train.drop((missing_data[missing_data['Total'] > 1]).index, 1)\n\n#Delete observation with missing Electrical data from training data\ntrain = train.drop(train.loc[train['Electrical'].isnull()].index)\n\n#Need to redefine SalePrice to account for missing observation\ny = train['SalePrice'];  \n\n#Check all missing values are gone\nprint(train.isnull().sum().max())","fc87f854":"train.shape","459ebebb":"#Drop same columns from test data\ntest = test.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage',\n       'GarageCond', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual',\n       'BsmtExposure', 'BsmtFinType2', 'BsmtFinType1', 'BsmtCond', 'BsmtQual',\n       'MasVnrArea', 'MasVnrType'], 1)","05ac9922":"test.shape","5c0babd4":"#Look for outlier - I know from previous kernel GrLivArea has a couple\nvar = 'GrLivArea'\ndata = pd.concat((train[var], y), axis=1)\ndata.plot.scatter(x=var, y='SalePrice');","f2ea1baf":"#Identify IDs of outliers based on above charts - 2 in GrLivArea, 1 in TotalBsmtSF\nprint(train.sort_values(by = 'GrLivArea', ascending = False)[:2])\nprint(train.sort_values(by = 'TotalBsmtSF', ascending = False)[:1])","afd49994":"#Delete them\ntrain.sort_values(by = 'GrLivArea', ascending = False)[:2]\ntrain = train.drop(train[train['Id'] == 1299].index)\ntrain = train.drop(train[train['Id'] == 524].index)","072b774e":"#Get target variable\ny = train['SalePrice'].copy()\ny.head()","299c6a08":"#Combine Kaggle's train and test data for transformations\nall_data = pd.concat([train, test], sort=False)\nall_data = all_data.drop(['SalePrice'], 1)\nprint(all_data.shape)\nall_data.head()","9c9383af":"#Check target variable for skew\nsns.distplot(y, fit=norm);\nfig = plt.figure()\nres = stats.probplot(y, plot=plt)","e3e276f7":"#Resolve skew in target variable by taking logs\ny = np.log1p(y)\nsns.distplot(y, fit=norm);\nfig = plt.figure()\nres = stats.probplot(y, plot=plt)","7f821435":"#Isolate numeric features\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n#Compute skewness\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())) \n#Set threshold for skewness\nskewed_feats = skewed_feats[skewed_feats > 0.75]\n#Identify skewed numeric features\nskewed_feats = skewed_feats.index\nprint(skewed_feats)\n\n#Log transform combined dataset features\nall_data[skewed_feats] = np.log1p(all_data[skewed_feats])\nall_data.head()","e95d5abf":"#Get dummies for categorial variables - note get_dummies only works on strings\nall_data = pd.get_dummies(all_data)\nall_data.head()","d209a91a":"all_data = all_data.fillna(0)\nall_data = all_data.drop(['Id'], 1)\nall_data.head()","af38c807":"#Refresh Kaggle train and test datasets with log transformed numeric features\nXtrain = all_data[:train.shape[0]]\nXtest = all_data[train.shape[0]:]\nprint(Xtrain.shape)\nprint(Xtest.shape)\nXtrain.head()","5a300ae5":"#Feature Scaling\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\nXtrain_scaled = scaler.fit_transform(Xtrain.values)\nXtrain_scaled_df = pd.DataFrame(Xtrain_scaled, index = Xtrain.index, columns = Xtrain.columns)\nXtest_scaled = scaler.transform(Xtest.values)\nXtest_scaled_df = pd.DataFrame(Xtest_scaled, index = Xtest.index, columns = Xtest.columns)\nXtrain = Xtrain_scaled_df\nXtest = Xtest_scaled_df","a8b99718":"Xtrain.head()","0e5a776c":"#DEFINE ERROR FUNCTION: RMSE\nfrom sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, Xtrain, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","af865938":"model_ridge = Ridge()","bde92173":"#Ridge Regression\n\n#Tune alpha (regularization parameter)\nalphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]","9dfe9ca9":"cv_ridge = pd.Series(cv_ridge, index=alphas)\ncv_ridge.plot(title=\"Validation\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","69005b84":"cv_ridge.min()","3b7c693c":"#Lasso\nmodel_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(Xtrain,y)","c1970e7f":"rmse_cv(model_lasso).mean()","cc23deed":"coef = pd.Series(model_lasso.coef_, index=Xtrain.columns)","f0f01894":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" + str(sum(coef == 0)) + \" variables\")","0b9cc041":"#Make predictions\nlnTestY = model_lasso.predict(Xtest)\nTestY = np.expm1(lnTestY)\nTestY = pd.Series(TestY)\nprint(TestY.shape)\nprint(TestY.head())","49441961":"#Prepare submission file\nsubmission = pd.DataFrame({'Id':test['Id'], 'SalePrice':TestY})\nprint(submission.head())\nprint(submission.shape)","fb65a7bc":"submission.to_csv('hpsubmission.csv', index=False)","1fafa859":"**Data Cleaning**","73008edf":"**Prepare predictions to submit**","51900867":"**Modeling**"}}