{"cell_type":{"0e0e27e0":"code","87a25f32":"code","b011f9ce":"code","0b33306e":"code","5d5adca4":"code","42105302":"code","fe94b2de":"code","1a5b8784":"code","9df12509":"code","45cff5b1":"code","77391767":"code","6cae205d":"code","77c02106":"code","a311e0ad":"code","b200e63f":"code","d4039e92":"code","84595280":"code","082129f3":"code","eccc94a5":"code","84fbbe9e":"code","9b2ebb67":"code","10bd6020":"code","32bd9f30":"code","24ae7d5d":"code","ddb64b45":"code","5d329973":"code","f32a8cf2":"code","8286dbee":"code","3a545d12":"code","09a8b8cb":"code","b8bf84bd":"code","22b1a1fb":"code","5ef9941c":"code","f5893184":"code","9cd9c5a0":"code","46c4bd37":"code","8ee7ebf9":"code","cc9df007":"code","21e7ecb9":"code","c80a51e9":"code","3a10d749":"code","a3a4b81c":"code","554b51a8":"code","aa7dad60":"code","df0aee42":"code","42a9428d":"code","db774c12":"code","ed4f9ade":"code","02d67716":"code","0f3c2036":"code","873eee1f":"code","98d97993":"code","8deca0d4":"code","c004bbdc":"code","db837a6b":"code","051f58d3":"code","e8aca6a5":"code","eceb181f":"code","82d202c6":"code","3d4a7994":"code","1a10d1a7":"code","2058688b":"code","52109c45":"code","0ffdd402":"code","549f1398":"code","6e6529e4":"code","d97b1b88":"code","164f1ede":"markdown","8fb5577b":"markdown","fa594438":"markdown","d5dcbeab":"markdown","fb7db64b":"markdown","0fb0a622":"markdown","231579c1":"markdown","ac6fc3bb":"markdown","b971dd22":"markdown","f2884143":"markdown","2a4e190f":"markdown","f3b2f9c8":"markdown","94f42d9d":"markdown","059b2dd1":"markdown","87c89272":"markdown","a4607211":"markdown","d8616060":"markdown","e194aa9c":"markdown","213e0df7":"markdown","e31360a7":"markdown"},"source":{"0e0e27e0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.basemap import Basemap\n%matplotlib inline\nimport statistics\nimport statsmodels.api as sm\nfrom scipy import stats\nimport seaborn as sns; sns.set(style = \"white\", color_codes = True)\nimport plotly\nplotly.tools.set_credentials_file(username='Olivia_Z', api_key='gQ5vg2hAX5tU6ZSQhFnt')\nimport plotly.plotly as py","87a25f32":"df = pd.read_csv('..\/input\/location-areacode\/directory.csv')","b011f9ce":"##View the dataset columns\ndf.head()","0b33306e":"#rename_columns\ndf.rename(columns={'Store Number':'Store_Number'},inplace = True)\ndf.rename(columns={'Store Name':'Store_Name'},inplace = True)\ndf.rename(columns={'Ownership Type':'Ownership_Type'},inplace = True)\ndf.rename(columns={'Street Address':'Street_Address'},inplace = True)\ndf.rename(columns={'Ownership Type':'Ownership_Type'},inplace = True)\ndf.rename(columns={'State\/Province':'State_Province'},inplace = True)\ndf","5d5adca4":"##Number of records having complete data for each column\ndf.notnull().sum()\ndf.notnull().sum()*100\/df.shape[0]","42105302":"#drop columns in order to imporve efficiency \nto_drop =['Brand','Store_Number','Store_Name','Street_Address','Phone Number','Timezone']\ndf.drop(columns=to_drop,inplace=True)\n#drop duplicate rows\ndf = df.drop_duplicates()\nlen(df)","fe94b2de":"#Which country has the largest number of starbucks stores?\ndf.Country.describe()","1a5b8784":"#Which city has the largest number of starbucks stores?\nprint(df.City.describe())","9df12509":"## The top ten countries with large number of Starbucks\ndf.Country.value_counts().head(10)","45cff5b1":"#count of category occurence in data\ndf.Country.value_counts().head(10).plot(kind = \"pie\")\nplt.xlabel('Countries')\nplt.ylabel('Number of stores')\n#ax = fig.add_subplot(111)\nplt.title(\"Top 10 Countries with Most Number of Starbucks Stores\")","77391767":"#The top ten cities with large number of Starbucks\ndf.City.value_counts().head(10)","6cae205d":"#count of category occurence in data\ndf.City.value_counts().head(10).plot(kind = \"pie\")\n\nplt.xlabel('Cities')\nplt.ylabel('Number of stores')\n#ax = fig.add_subplot(111)\nplt.title(\"Top 10 Cities with Most Number of Starbucks Stores\")","77c02106":"##Creat a new dataset for plot the choropleth Map\ndf1=df.Country.value_counts()\ndf1 = pd.DataFrame(df1)\nwith open('..\/input\/alphacou\/Country alpha_3.csv') as code:\n    table = pd.read_table(code,sep='-',index_col=0,header = None,names=['code'])\ndfc=pd.DataFrame(table)\ndfc=dfc[:73]\ndfc['Number_stores']= np.asarray(df1['Country'])\ndfc['code'] = dfc.index","a311e0ad":"import plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\ndata = dict(type='choropleth',\n            locations = dfc['code'],\n            z = dfc['Number_stores'],\n            text = dfc['code'], colorbar = dict(autotick = False,\n            tickprefix = 'Number of stores',\n            title = 'Number of Starbucks stores'),\n            colorscale=[[0, 'rgb(224,255,255)'],\n                       [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n                       [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n                       [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n                       [1, 'rgb(227,26,28)']], reversescale = False)\n\nlayout = dict(title='Number of Starbucks stores all over the World',\ngeo = dict(showframe = True, projection={'type':'Mercator'}))\n\nchoromap = dict(data = [data], layout = layout)\niplot(choromap, validate=False)","b200e63f":"## The type of Starbucks stores all over the world\ndf_w=df.Ownership_Type.value_counts()\nprint(df_w)","d4039e92":"df_us = df.loc[df['Country']=='US']\ndf_us.Ownership_Type.value_counts()","84595280":"df_cn = df.loc[df['Country']=='CN']\ndf_cn.Ownership_Type.value_counts()","082129f3":"df_ca = df.loc[df['Country']=='CA']\ndf_ca.Ownership_Type.value_counts()","eccc94a5":"df_type = df.Ownership_Type.value_counts()\ndf_fran= df.loc[df[\"Ownership_Type\"] == \"Franchise\"]","84fbbe9e":"import pycountry\ninput_countries = df['Country']\ncountries = {}\nfor country in pycountry.countries:\n    countries[country.alpha_2] = country.alpha_3\n\ncodes = [countries.get(country,'Unknown code') for country in input_countries]\npd.Series(codes)\ndf.loc[:,'Alpha_3'] = pd.Series(codes)","9b2ebb67":"df_ty = df.groupby('Alpha_3').Ownership_Type.value_counts()\ndf_ty = pd.DataFrame(df_ty)\n\ndf_ty.rename(columns={'Ownership_Type':'Number'}, inplace = True) \ndf_ty2 = df_ty.Number.apply(pd.Series)\n\ndf_ty['codes'] = df_ty.index\ndf_ty1 = df_ty.codes.apply(pd.Series)\ndf_ty2 = df_ty2.join(df_ty1, lsuffix='_df_ty2', rsuffix='_df_ty1')\ndf_ty2.columns\ndf_ty2.rename(columns={'0_df_ty2':'Number_of_type'}, inplace = True) \ndf_ty2.rename(columns={'0_df_ty1':'code'}, inplace = True)\ndf_ty2.rename(columns={1:'type'}, inplace = True)\n#\ndf_comowner = df_ty2.loc[df_ty2['type']==\"Company Owned\"]\ndf_com = df_comowner.sort_values(by=['Number_of_type'],ascending=False)\ndf_com[:10].plot(kind=\"bar\")\nplt.show()\n#\ndf_licen = df_ty2.loc[df_ty2['type']==\"Licensed\"]\ndf_licen = df_licen.sort_values(by=['Number_of_type'],ascending=False)\ndf_licen[:10].plot(kind=\"bar\")\n","10bd6020":"df_franch = df_ty2.loc[df_ty2['type']==\"Franchise\"] \ndf_franch = df_franch.sort_values(by=['Number_of_type'],ascending=False)\ndf_franch[:10].plot(kind=\"bar\")\n#\ndf_join = df_ty2.loc[df_ty2['type']==\"Joint Venture\"] \ndf_join = df_join.sort_values(by=['Number_of_type'],ascending=False)\ndf_join[:10].plot(kind=\"bar\")","32bd9f30":"# get the sub-dataset of US\ndf_us = df.loc[df['Country']=='US']\n\n#add new columns to data frame \"How many stores in each states\"\ndf_us.State_Province.value_counts().head(10).plot(kind = \"bar\")\n","24ae7d5d":"## CA dataset\ndf_us_CA = df_us[df_us['State_Province']=='CA']\ndf_us_CA.City.value_counts().head(30).plot(kind=\"bar\")","ddb64b45":"df_us_CA1 = df_us_CA[df_us_CA[\"City\"]=='San Diego']\nto_drop1 =['Country','State_Province','Ownership_Type','Postcode','City','Alpha_3']\nCA = df_us_CA1.drop(columns = to_drop1)\nfrom scipy.spatial import distance\nCA.index.name = 'ID'\nCA = CA.values","5d329973":"##Function of disatnce measurements\nimport math\nfrom math import radians, cos, sin, asin, sqrt\ndef distance_stores(lon1,lat1,lon2,lat2):\n    lon1= math.radians(lon1)\n    lat1= math.radians(lat1)\n    lon2= math.radians(lon2)\n    lat2= math.radians(lat2)\n    dlon = lon2-lon1\n    dlat = lat2-lat1\n    a = sin(dlat\/2)**2+cos(lat1)*cos(lat2)*sin(dlon\/2)**2\n    c = 2 * asin(sqrt(a))\n    km = 6371 * c\n    return km","f32a8cf2":"all = []\nfor i in CA: \n    for j in CA[1:]: \n        all.append(distance_stores(i[0],i[1],j[0],j[1]))","8286dbee":"len(all)\nall = pd.DataFrame(all)\ntest = all[:127]\ntest.loc[:,'p1_Lon'] = pd.DataFrame(CA[:,0])\ntest.loc[:,'p1_Lat'] = pd.DataFrame(CA[:,1])\ntest.loc[:,'p2_Lon'] = pd.DataFrame(CA[1:,0])\ntest.loc[:,'p2_Lat'] = pd.DataFrame(CA[1:,1])\ntest = test[:127]\ntest.columns=['Distance','p1_Lon','p1_Lat','p2_Lon','p2_Lat']","3a545d12":"San = test.sort_values(by=['Distance'])\nsize = (12,12)\nsns.set(rc={'figure.figsize':(8,8)})\nsns.scatterplot(x = 'p1_Lon',y='p1_Lat',data = San) ","09a8b8cb":"test_mean= np.mean(test)\ntest_std = np.std(test)\nplt.hist(San['Distance'])","b8bf84bd":"#coords = distance.cdist(CA, CA,'euclidean')\n#min_dis = np.min(coords[np.nonzero(coords)])\n#itmeindex = np.where(coords==min)\n#itemindex = np.asarray(itmeindex)\n#df_min = pd.DataFrame(itemindex).T\n#df_min.columns = ['ID1','ID2']\n#CA1.index.name = 'ID1'\n#df_min_1 = pd.DataFrame(df_min['ID1'])\n#close = pd.merge(CA1,df_min_1,how='inner',on=['ID1'])\n#close.columns=['ID','Lon','Lat']\n#close_dis = distance.cdist(close,close,'euclidean')\n#pd.DataFrame(close_dis)","22b1a1fb":"## WA dataset\ndf_us_wa = df_us[df_us['State_Province']=='WA']\ndf_us_wa.City.value_counts().head(30).plot(kind=\"bar\")","5ef9941c":"df_us_wa1 = df_us_wa[df_us_wa[\"City\"]=='Seattle']\nto_drop1 =['Country','State_Province','Ownership_Type','Postcode','City','Alpha_3']\nsea = df_us_wa1.drop(columns = to_drop1)\nfrom scipy.spatial import distance\nsea.index.name = 'ID'\nsea = sea.values\nlen(sea)","f5893184":"seattle = []\nfor i in sea: \n    for j in sea[1:]: \n        seattle.append(distance_stores(i[0],i[1],j[0],j[1]))","9cd9c5a0":"len(seattle)\nseattle1 = pd.DataFrame(seattle)\nseattle1 = seattle1[:142]\nseattle1.loc[:,'p1_Lon'] = pd.DataFrame(sea[:,0])\nseattle1.loc[:,'p1_Lat'] = pd.DataFrame(sea[:,1])\nseattle1.loc[:,'p2_Lon'] = pd.DataFrame(sea[1:,0])\nseattle1.loc[:,'p2_Lat'] = pd.DataFrame(sea[1:,1])\nseattle1 =seattle1 [:142]\nseattle1.columns=['Distance','p1_Lon','p1_Lat','p2_Lon','p2_Lat']","46c4bd37":"#seattle_dis = seattle1.sort_values(by=['Distance'])\n#plt.figure(figsize=(10,10))\n#plt.scatter(x = 'p1_Lon',y='p1_Lat',data =seattle_dis )\n#plt.show()","8ee7ebf9":"sea_mean= np.mean(seattle1)\nsea_std = np.std(seattle1)\nplt.hist(seattle1['Distance'])","cc9df007":"## NYC dataset\ndf_us_ny = df_us[df_us['State_Province']=='NY']\ndf_us_ny.City.value_counts().head(30).plot(kind=\"bar\")","21e7ecb9":"df_us_nyc = df_us_ny[df_us_ny[\"City\"]=='New York']\nto_drop1 =['Country','State_Province','Ownership_Type','Postcode','City','Alpha_3']\nnyc = df_us_nyc.drop(columns = to_drop1)\nfrom scipy.spatial import distance\nnyc.index.name = 'ID'\nnyc = nyc.values\nlen(nyc)","c80a51e9":"nyc_list = []\nfor i in nyc: \n    for j in nyc[1:]: \n        nyc_list.append(distance_stores(i[0],i[1],j[0],j[1]))","3a10d749":"len(nyc_list)\nnyc1 = pd.DataFrame(nyc_list)\nnyc1 = nyc1[:207]\nnyc1.loc[:,'p1_Lon'] = pd.DataFrame(nyc[:,0])\nnyc1.loc[:,'p1_Lat'] = pd.DataFrame(nyc[:,1])\nnyc1.loc[:,'p2_Lon'] = pd.DataFrame(nyc[1:,0])\nnyc1.loc[:,'p2_Lat'] = pd.DataFrame(nyc[1:,1])\nnyc1 =nyc1 [:207]\nnyc1.columns=['Distance','p1_Lon','p1_Lat','p2_Lon','p2_Lat']\n","a3a4b81c":"nyc_dis = nyc1.sort_values(by=['Distance'])\nplt.figure(figsize=(10,10))\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data =nyc_dis )\nplt.show()","554b51a8":"nyc_mean= np.mean(nyc1)\nnyc_std = np.std(nyc1)\nplt.hist(nyc1['Distance'])","aa7dad60":"## TX dataset\ndf_us_TX = df_us[df_us['State_Province']=='TX']\ndf_us_TX.City.value_counts().head(30).plot(kind=\"bar\")","df0aee42":"df_us_TX1 = df_us_TX[df_us_TX[\"City\"]=='Houston']\nto_drop1 =['Country','State_Province','Ownership_Type','Postcode','City','Alpha_3']\nHU = df_us_TX1.drop(columns = to_drop1)\nfrom scipy.spatial import distance\nHU.index.name = 'ID'\nHU = HU.values\nlen(HU)","42a9428d":"all_HU = []\nfor i in HU: \n    for j in HU[1:]: \n        all_HU.append(distance_stores(i[0],i[1],j[0],j[1]))","db774c12":"len(all_HU)\nall_HU = pd.DataFrame(all_HU)\nHU_TX = all_HU[:147]\nHU_TX.loc[:,'p1_Lon'] = pd.DataFrame(HU[:,0])\nHU_TX.loc[:,'p1_Lat'] = pd.DataFrame(HU[:,1])\nHU_TX.loc[:,'p2_Lon'] = pd.DataFrame(HU[1:,0])\nHU_TX.loc[:,'p2_Lat'] = pd.DataFrame(HU[1:,1])\nHU_TX = HU_TX[:147]\nHU_TX.columns=['Distance','p1_Lon','p1_Lat','p2_Lon','p2_Lat']","ed4f9ade":"HU1 = HU_TX.sort_values(by=['Distance'])\nsize = (12,12)\nsns.set(rc={'figure.figsize':(8,8)})\nsns.scatterplot(x = 'p1_Lon',y='p1_Lat',data = HU1) ","02d67716":"HU_mean= np.mean(HU_TX)\nHU_std = np.std(HU_TX)\nplt.hist(HU_TX['Distance'])","0f3c2036":"# get the sub-dataset of Canada\ndf_ca = df.loc[df['Country']=='CA']\n#add new columns to data frame \"How many stores in each states\"\ndf_ca.State_Province.value_counts().head(10).plot(kind = \"bar\")","873eee1f":"## ON dataset\ndf_ca_on = df_ca[df_ca['State_Province']=='ON']\ndf_ca_on.City.value_counts().head(30).plot(kind=\"bar\")","98d97993":"df_ca_on1 = df_ca_on[df_ca_on[\"City\"]=='Toronto']\nto_drop1 =['Country','State_Province','Ownership_Type','Postcode','City','Alpha_3']\nON = df_ca_on1.drop(columns = to_drop1)\nfrom scipy.spatial import distance\nON.index.name = 'ID'\nON = ON.values\nlen(ON)","8deca0d4":"all_tor = []\nfor i in ON: \n    for j in ON[1:]: \n        all_tor.append(distance_stores(i[0],i[1],j[0],j[1]))","c004bbdc":"len(all_tor)\nall_tor = pd.DataFrame(all_tor)\ntor = all_tor[:183]\ntor.loc[:,'p1_Lon'] = pd.DataFrame(ON[:,0])\ntor.loc[:,'p1_Lat'] = pd.DataFrame(ON[:,1])\ntor.loc[:,'p2_Lon'] = pd.DataFrame(ON[1:,0])\ntor.loc[:,'p2_Lat'] = pd.DataFrame(ON[1:,1])\ntor = tor[:183]\ntor.columns=['Distance','p1_Lon','p1_Lat','p2_Lon','p2_Lat']\nlen(tor)","db837a6b":"a_tor = tor.sort_values(by=['Distance'])\nplt.figure(figsize=(10,10))\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data = a_tor)\nplt.show()","051f58d3":"tor_mean= np.mean(tor)\ntor_std = np.std(tor)\nplt.hist(a_tor['Distance'])","e8aca6a5":"# get the sub-dataset of China\ndf_cn = df.loc[df['Country']=='CN']\n#add new columns to data frame \"How many stores in each states\"\ndf_cn.State_Province.value_counts().head(10).plot(kind = \"bar\")","eceb181f":"## ON dataset\ndf_cn_sh = df_cn[df_cn['State_Province']== '31']\n#df_cn_sh.City.value_counts().head(10).plot(kind=\"bar\")","82d202c6":"to_drop1 =['Country','State_Province','Ownership_Type','Postcode','City','Alpha_3']\nSH = df_cn_sh.drop(columns = to_drop1)\nfrom scipy.spatial import distance\nSH.index.name = 'ID'\nSH = SH.values\nlen(SH)","3d4a7994":"all_sh = []\nfor i in SH: \n    for j in SH[1:]: \n        all_sh.append(distance_stores(i[0],i[1],j[0],j[1]))","1a10d1a7":"len(all_sh)\nall_sh = pd.DataFrame(all_sh)\nsh = all_sh[:447]\nsh.loc[:,'p1_Lon'] = pd.DataFrame(SH[:,0])\nsh.loc[:,'p1_Lat'] = pd.DataFrame(SH[:,1])\nsh.loc[:,'p2_Lon'] = pd.DataFrame(SH[1:,0])\nsh.loc[:,'p2_Lat'] = pd.DataFrame(SH[1:,1])\nsh = sh[:447]\nsh.columns=['Distance','p1_Lon','p1_Lat','p2_Lon','p2_Lat']\nlen(sh)","2058688b":"a_sh = sh.sort_values(by=['Distance'])\nplt.figure(figsize=(10,10))\nsns.jointplot(x = 'p1_Lon',y='p1_Lat',data = a_sh)\nplt.show()","52109c45":"sh_mean= np.mean(sh)\nsh_std = np.std(sh)\nplt.hist(a_sh['Distance'])\nplt.xlim(xmin=0,xmax=80)","0ffdd402":"\n#San Diego\nplt.subplot(221)\nSan = test.sort_values(by=['Distance'])\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data = San) \nplt.title(\"San Diego\")\n\nplt.ylabel(\"Lontitude\")\n\n# Seattle\nplt.subplot(222)\nseattle_dis = seattle1.sort_values(by=['Distance'])\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data =seattle_dis )\nplt.title(\"Seattle\")\n\n\n\n#new york\nplt.subplot(223)\nnyc_dis = nyc1.sort_values(by=['Distance'])\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data =nyc_dis )\nplt.title(\"New York City\")\nplt.xlabel(\"Latitude\")\nplt.ylabel(\"Lontitude\")\n\n# huston\nplt.subplot(224)\nHU1 = HU_TX.sort_values(by=['Distance'])\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data = HU1) \nplt.title(\"Huston\")\nplt.xlabel(\"Latitude\")","549f1398":"#Toronto\nplt.subplot(1,2,1)\na_tor = tor.sort_values(by=['Distance'])\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data = a_tor)\nplt.title(\"Toronto\")\nplt.xlabel(\"Latitude\")\nplt.ylabel(\"Lontitude\")\n\n#Shanghai\nplt.subplot(1,2,2)\na_sh = sh.sort_values(by=['Distance'])\nplt.scatter(x = 'p1_Lon',y='p1_Lat',data = a_sh)\nplt.title(\"Shanghai\")\nplt.xlabel(\"Latitude\")\n","6e6529e4":"#San Diego\nplt.subplot(221)\ntest_mean= np.mean(test)\ntest_std = np.std(test)\nplt.hist(San['Distance'])\nplt.title(\"San Diego\")\n\nplt.ylabel(\"Number of stores\")\n\n#Seattle\nplt.subplot(222)\nsea_mean= np.mean(seattle1)\nsea_std = np.std(seattle1)\nplt.hist(seattle1['Distance'])\nplt.title(\"Seattle\")\n\n\n#NYC\nplt.subplot(223)\nnyc_mean= np.mean(nyc1)\nnyc_std = np.std(nyc1)\nplt.hist(nyc1['Distance'])\nplt.title(\"New York City\")\nplt.xlabel(\"Distance\")\nplt.ylabel(\"Number of stores\")\n#Houston\nplt.subplot(224)\nHU_mean= np.mean(HU_TX)\nHU_std = np.std(HU_TX)\nplt.hist(HU_TX['Distance'])\nplt.title(\"Huston\")\nplt.xlabel(\"Distance\")\n","d97b1b88":"#Toronto\nplt.subplot(1,2,1)\ntor_mean= np.mean(tor)\ntor_std = np.std(tor)\nplt.hist(a_tor['Distance'])\nplt.title(\"Toroton\")\nplt.xlabel(\"Distance\")\nplt.ylabel(\"Number of stores\")\n#Shanghai\nplt.subplot(1,2,2)\nsh_mean= np.mean(sh)\nsh_std = np.std(sh)\nplt.hist(a_sh.Distance[:280])\nplt.xlim(xmin=0,xmax=15)\nplt.title(\"Shanghai\")\nplt.xlabel(\"Distance\")\n","164f1ede":"writing a summary","8fb5577b":"# Seattle","fa594438":"US has a large number of company owned and licensed Starbucks. Britain is the top one country\nwith franchise, China is the top of joint venture.","d5dcbeab":"The dataset includes Starbucks and subsidiart store locations worldwide that comes from Kaggle and its link: https:\/\/www.kaggle.com\/starbucks\/store-locations. \nThere are a lot of stories about Starbucks. The six most surprsing facts:\n\n1.The most loyal 20% of customers come into the store at least 16 times per month.\n\n2.There are over 87,000 drink combination possibilities.\n\n3.The \u201ctrenta\u201d sized cup holds more liquid than the human stomach.\n\n4.Since 1987, an average of two Starbucks stores have opened each day.\n\n5.The majority of their flavored drinks contain more sugar than one should consume in entire day.\n\n6.A \u201cgrande\u201d sized coffee contains four times the amount of caffeine as Red Bull.","fb7db64b":"# New York City","0fb0a622":"# Canada","231579c1":"1.The pattern of Starbucks stores can shows the city's shape or the most of popular CBD shapes.\n","ac6fc3bb":"# Distacne histrogram","b971dd22":"# Texas","f2884143":"# Quetsions: \n","2a4e190f":"# Shanghai","f3b2f9c8":"# San Diego","94f42d9d":"Future research\n1. Dig into more cities and the ownership_type distributions\n2. connect the sale or customer review to analysis to do some location analysis","059b2dd1":"# Read the dataset ","87c89272":"1. The top ten contries\/cities with largest number of Starbucks stores\n\n2. There are four different type of ownership_type of Starbucks:\n    Company owned, licensed, joint venture, Franchise\n   How those type distrbution all over the world?\n\n3.Find the distance between two Starbucks stores and what is the most frequent distance \n  within a city?","a4607211":"# Type of Ownership","d8616060":"# The distribution of Starbucks stores in six biggest cities","e194aa9c":"2. The larger the cities, the closer the Starbucks stores","213e0df7":"cited from https:\/\/slideplayer.com\/slide\/6129775\/","e31360a7":"# Background and Dataset"}}