{"cell_type":{"3f3df5b1":"code","12f1957f":"code","1fba6f55":"code","3fd17dba":"code","949e742b":"code","f360be65":"code","71a8c038":"code","2725da85":"code","d0d76005":"code","728fdbb8":"code","4f8f1d5e":"code","338e2a45":"code","03d0f837":"code","b1cb9899":"code","2124f68f":"code","04076690":"code","b0c09c70":"code","95feec53":"code","bad4fcaf":"code","13a87735":"code","cbb0361b":"code","77c112ab":"code","59b556cd":"code","de432951":"code","93f4f72d":"code","ae2bc43b":"code","bc58aa5a":"code","bdb01e3b":"code","63921169":"code","cb17b13b":"code","131c76bc":"code","d05d0abd":"code","5c293734":"code","fbf4114c":"code","cc89038e":"code","55259360":"code","50d8c1dc":"code","cfdde31e":"code","8f7c833b":"code","399f6879":"code","bbcffbe6":"code","c82ea7c0":"code","89d18a80":"code","55c29cc2":"code","6ac42d26":"code","470cc61b":"code","18f4b665":"code","7b8fc406":"code","e2f45655":"code","5d9aef96":"markdown","69e31f53":"markdown","39829802":"markdown","00ee704f":"markdown","84f421d2":"markdown","d5eb8705":"markdown","7a3afb04":"markdown","3daf24d8":"markdown","c15d213b":"markdown","8886e1da":"markdown","26ac0574":"markdown","d2e94d6f":"markdown","d6438a0b":"markdown","84ecd0e1":"markdown","0af9d7e4":"markdown","061508d3":"markdown","4b4e7103":"markdown","c60fea98":"markdown","be936c56":"markdown","52828e29":"markdown","55bed246":"markdown","e1412cac":"markdown","51e43284":"markdown","8cafdb29":"markdown","e92ffb1f":"markdown","e5527dfa":"markdown","c23fc8ec":"markdown","5f7a29f7":"markdown","21a36325":"markdown","efc64af4":"markdown","f98cd977":"markdown","c9e3f90e":"markdown","baf6c1ff":"markdown","d30014be":"markdown","bb92d4c6":"markdown","8c81854b":"markdown","6f311ea6":"markdown","2c9a862c":"markdown","8d9e25c7":"markdown"},"source":{"3f3df5b1":"import gc\nimport os\nimport json\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\nwarnings.filterwarnings('ignore')","12f1957f":"IS_LOCAL = False\nif(IS_LOCAL):\n    PATH=\"..\/input\/iwildcam\/\"\nelse:\n    PATH=\"..\/input\/iwildcam-2019-fgvc6\/\"\nos.listdir(PATH)","1fba6f55":"%%time\ntrain_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(PATH, 'test.csv'))","3fd17dba":"x_train = np.load('..\/input\/reducing-image-sizes-to-32x32\/X_train.npy')\nx_test = np.load('..\/input\/reducing-image-sizes-to-32x32\/X_test.npy')\ny_train = np.load('..\/input\/reducing-image-sizes-to-32x32\/y_train.npy')","949e742b":"train_df.head()","f360be65":"test_df.head()","71a8c038":"print(\"Train and test shape: {} {}\".format(train_df.shape, test_df.shape))","2725da85":"classes_wild = {0: 'empty', 1: 'deer', 2: 'moose', 3: 'squirrel', 4: 'rodent', 5: 'small_mammal', \\\n                6: 'elk', 7: 'pronghorn_antelope', 8: 'rabbit', 9: 'bighorn_sheep', 10: 'fox', 11: 'coyote', \\\n                12: 'black_bear', 13: 'raccoon', 14: 'skunk', 15: 'wolf', 16: 'bobcat', 17: 'cat',\\\n                18: 'dog', 19: 'opossum', 20: 'bison', 21: 'mountain_goat', 22: 'mountain_lion'}","d0d76005":"train_df['classes_wild'] = train_df['category_id'].apply(lambda cw: classes_wild[cw])","728fdbb8":"train_df.head()","4f8f1d5e":"train_image_files = list(os.listdir(os.path.join(PATH,'train_images')))\ntest_image_files = list(os.listdir(os.path.join(PATH,'test_images')))\n                         \nprint(\"Number of image files: train:{} test:{}\".format(len(train_image_files), len(test_image_files)))","338e2a45":"%%time\ntrain_file_names = list(train_df['file_name'])\nprint(\"Matching train image names: {}\".format(len(set(train_file_names).intersection(train_image_files))))","03d0f837":"%%time\ntest_file_names = list(test_df['file_name'])\nprint(\"Matching test image names: {}\".format(len(set(test_file_names).intersection(test_image_files))))","b1cb9899":"cnt_classes_images = train_df.classes_wild.nunique()\nprint(\"There are {} classes of images\".format(cnt_classes_images))\npd.DataFrame(train_df.classes_wild.value_counts()).transpose()","2124f68f":"def plot_classes(feature, fs=8, show_percents=True, color_palette='Set3'):\n    f, ax = plt.subplots(1,1, figsize=(2*fs,4))\n    total = float(len(train_df))\n    g = sns.countplot(train_df[feature], order = train_df[feature].value_counts().index, palette=color_palette)\n    g.set_title(\"Number and percentage of labels for each class of {}\".format(feature))\n    if(show_percents):\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(100*height\/total),\n                    ha=\"center\") \n    plt.show()    ","04076690":"plot_classes('classes_wild')","b0c09c70":"plot_classes('seq_num_frames', fs=3)","95feec53":"plot_classes('location', fs=15)","bad4fcaf":"fig, ax = plt.subplots(1,1,figsize=(16,26))\nt = pd.DataFrame(train_df.groupby(['classes_wild', 'location'])['seq_id'].count().reset_index())\nm = t.pivot(index='location', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed per location', size=16)\nplt.show()","13a87735":"fig, ax = plt.subplots(1,1,figsize=(16,26))\ntmp = train_df[train_df['classes_wild'] != 'empty']\nt = pd.DataFrame(tmp.groupby(['classes_wild', 'location'])['seq_id'].count().reset_index())\nm = t.pivot(index='location', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed per location (except `empty`)', size=16)\nplt.show()\ndel t, tmp, m\ngc.collect()","cbb0361b":"plot_classes('rights_holder', fs=3)","77c112ab":"fig, ax = plt.subplots(1,1,figsize=(16,4))\nt = pd.DataFrame(train_df.groupby(['classes_wild', 'rights_holder'])['seq_id'].count().reset_index())\nm = t.pivot(index='rights_holder', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed by each rights holder', size=16)\nplt.show()","59b556cd":"fig, ax = plt.subplots(1,1,figsize=(16,4))\nt = pd.DataFrame(train_df[~(train_df.classes_wild == 'empty')].groupby(['classes_wild', 'rights_holder'])['seq_id'].count().reset_index())\nm = t.pivot(index='rights_holder', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed by each rights holder (empty class removed)', size=16)\nplt.show()","de432951":"try:\n    train_df['date_time'] = pd.to_datetime(train_df['date_captured'], errors='coerce')\n    train_df[\"year\"] = train_df['date_time'].dt.year\n    train_df[\"month\"] = train_df['date_time'].dt.month\n    train_df[\"day\"] = train_df['date_time'].dt.day\n    train_df[\"hour\"] = train_df['date_time'].dt.hour\n    train_df[\"minute\"] = train_df['date_time'].dt.minute\nexcept Exception as ex:\n    print(\"Exception:\".format(ex))   ","93f4f72d":"train_df.head()","ae2bc43b":"plot_classes('year', fs=3)","bc58aa5a":"plot_classes('month', fs=5)","bdb01e3b":"plot_classes('day', fs=10)","63921169":"plot_classes('hour', fs=8)","cb17b13b":"fig, ax = plt.subplots(1,1,figsize=(16,10))\nt = pd.DataFrame(train_df.groupby(['classes_wild', 'hour'])['seq_id'].count().reset_index())\nm = t.pivot(index='hour', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed per hour', size=16)\nplt.show()","131c76bc":"tmp = train_df[train_df['classes_wild'] != 'empty']\nfig, ax = plt.subplots(1,1,figsize=(16,12))\nt = pd.DataFrame(tmp.groupby(['classes_wild', 'hour'])['seq_id'].count().reset_index())\nm = t.pivot(index='hour', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed per hour', size=16)\nplt.show()","d05d0abd":"fig, ax = plt.subplots(1,1,figsize=(16,8))\nt = pd.DataFrame(tmp.groupby(['classes_wild', 'month'])['seq_id'].count().reset_index())\nm = t.pivot(index='month', columns='classes_wild', values='seq_id')\ns = sns.heatmap(m, linewidths=.1, linecolor='black', annot=True, cmap=\"YlGnBu\")\ns.set_title('Number of wild animals observed per month', size=16)\nplt.show()","5c293734":"classes = train_df.classes_wild.unique()\nfig, ax = plt.subplots(7,2,figsize=(20,28))\ni = 0\nfor class_wild in classes:\n    i = i + 1\n    plt.subplot(7,2,i)\n    tmp = train_df[train_df['classes_wild'] == class_wild]\n    t = pd.DataFrame(tmp.groupby(['month', 'hour'])['seq_id'].count().reset_index())\n    m = t.pivot(index='hour', columns='month', values='seq_id')\n    s = sns.heatmap(m, linewidths=.1, linecolor='black', annot=False, cmap=\"Greens\")\n    if(i<13):\n        s.set_xlabel('')    \n    s.set_title(class_wild, size=12)\n\nplt.show()","fbf4114c":"classes = train_df.classes_wild.unique()\nfig, ax = plt.subplots(7,2,figsize=(16,24))\ni = 0\nfor class_wild in classes:\n    i = i + 1\n    plt.subplot(7,2,i)\n    tmp = train_df[train_df['classes_wild'] == class_wild]\n    t = pd.DataFrame(tmp.groupby(['rights_holder', 'month'])['seq_id'].count().reset_index())\n    m = t.pivot(index='rights_holder', columns='month', values='seq_id')\n    s = sns.heatmap(m, linewidths=.1, linecolor='black', annot=False, cmap=\"Blues\")\n    if(i<13):\n        s.set_xlabel('')    \n    s.set_title(class_wild, size=12)\n\nplt.show()","cc89038e":"def draw_category_images(var,cols=5):\n    categories = (train_df.groupby([var])[var].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=cols, figsize=(3*cols,3*len(categories)))\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = train_df[train_df[var]==cat].sample(cols)\n        for j in range(0,cols):\n            file=IMAGE_PATH + sample.iloc[j]['file_name']\n            im = Image.open(file)\n            ax[i, j].imshow(im, resample=True)\n            ax[i, j].set_title(cat, fontsize=9)  \n    plt.tight_layout()\n    plt.show()","55259360":"IMAGE_PATH = os.path.join(PATH,'train_images\/')\ndraw_category_images('classes_wild')","50d8c1dc":"IMAGE_PATH = os.path.join(PATH,'test_images\/')\nf, ax = plt.subplots(nrows=5,ncols=5, figsize=(15,15))\n\nfor i in range(5):\n    sample = test_df.sample(5)\n    for j in range(5):\n        file=IMAGE_PATH + sample.iloc[j]['file_name']\n        im = Image.open(file)\n        ax[i, j].imshow(im, resample=True)\n        ax[i, j].set_title('Not labeled', fontsize=9)  \nplt.tight_layout()\nplt.show()","cfdde31e":"x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train \/= 255.\nx_test \/= 255.","8f7c833b":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        self.val_recalls = []\n        self.val_precisions = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, y_val = self.validation_data[:2]\n        y_pred = self.model.predict(X_val)\n\n        y_pred_cat = keras.utils.to_categorical(\n            y_pred.argmax(axis=1),\n            num_classes=14\n        )\n\n        _val_f1 = f1_score(y_val, y_pred_cat, average='macro')\n        _val_recall = recall_score(y_val, y_pred_cat, average='macro')\n        _val_precision = precision_score(y_val, y_pred_cat, average='macro')\n\n        self.val_f1s.append(_val_f1)\n        self.val_recalls.append(_val_recall)\n        self.val_precisions.append(_val_precision)\n\n        print((f\"val_f1: {_val_f1:.4f}\"\n               f\" \u2014 val_precision: {_val_precision:.4f}\"\n               f\" \u2014 val_recall: {_val_recall:.4f}\"))\n\n        return\n\nf1_metrics = Metrics()","399f6879":"model_densenet = DenseNet121(\n    weights='..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(32,32,3)\n)","bbcffbe6":"model = Sequential()\nmodel.add(model_densenet)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(cnt_classes_images, activation='softmax'))","c82ea7c0":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","89d18a80":"checkpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_acc', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)","55c29cc2":"model.summary()","6ac42d26":"BATCH_SIZE = 64\nEPOCHS = 35\nVALID_SPLIT = 0.1\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[checkpoint, f1_metrics],\n    validation_split=VALID_SPLIT\n)","470cc61b":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\nh_df = pd.DataFrame(history.history)\nh_df['val_f1'] = f1_metrics.val_f1s\nh_df['val_precision'] = f1_metrics.val_precisions\nh_df['val_recall'] = f1_metrics.val_recalls\nepochs = range(len(h_df['val_f1']))\nplt.figure()\nfig, ax = plt.subplots(1,3,figsize=(18,4))\nax[0].plot(epochs,h_df['loss'], label='Training loss')\nax[0].plot(epochs,h_df['val_loss'], label='Validation loss')\nax[0].set_title('Training and validation loss')\nax[0].legend()\nax[1].plot(epochs,h_df['acc'],label='Training accuracy')\nax[1].plot(epochs,h_df['val_acc'], label='Validation accuracy')\nax[1].set_title('Training and validation accuracy')\nax[1].legend()\nax[2].plot(epochs,h_df['val_f1'],label='Validation f1-score')\nax[2].plot(epochs,h_df['val_precision'],label='Validation precision')\nax[2].plot(epochs,h_df['val_recall'],label='Validation recall')\nax[2].set_title('Validation f1-score, precision & recall')\nax[2].legend()\nplt.show()","18f4b665":"model.load_weights('model.h5')\n#prepare prediction\ny_test = model.predict(x_test)","7b8fc406":"#submission\nsubmission_df = pd.read_csv(os.path.join(PATH,'sample_submission.csv'))\nsubmission_df['Predicted'] = y_test.argmax(axis=1)\n\nprint(submission_df.shape)\nsubmission_df.head(3)","e2f45655":"submission_df.to_csv(\"submission.csv\", index=False)","5d9aef96":"## Extract date and time information\n\nWe extract date and time information from the `date_time` column.","69e31f53":"Only two rights holder are registered in `train_df` data.  \n\nLet's check the rights holder and type of images taken by each.\n\n## Rights holder and wild animals class\n\nWe represent the relationship between the rights holder and the animal classes presented in the photo dataset.\n","39829802":"We check again train:","00ee704f":"## Load data   \n\nLet's check what data files are available.","84f421d2":"## Number of sequences frames","d5eb8705":"## Rights holder\n\nThe rights holder is most probably the photo author.","7a3afb04":"We are using the number of images classes inferred before to init the **Dense** layer.","3daf24d8":"## Test images samples\n\nLet's also draw few test images samples.","c15d213b":"## Classes per rights holder and month","8886e1da":"![](http:\/\/)Then, we prepare the submission.","26ac0574":"<h1><center><font size=\"6\">iWildCam 2019 EDA<\/font><\/center><\/h1>\n\n<center><img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/0\/01\/Fauna.jpg\" width=\"800\"><\/img><\/center>\n\n<br>\n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Prepare the data analysis<\/a>  \n- <a href='#3'>Data exploration<\/a>   \n- <a href='#4'>Model<\/a>   \n- <a href='#5'>References<\/a>","d2e94d6f":"## Train images samples   \n\nLet's show a part of the images from train_df set.","d6438a0b":"## Submission\n\nFirst, we load the model and predict.","84ecd0e1":"## Validation","0af9d7e4":"# <a id='1'>Introduction<\/a>  \n\n## Competition\n\nBiologists all over the world use camera traps to monitor biodiversity and population density of animal species. They have recently been making strides towards automating the species classification challenge in camera traps, but as they try to expand the scope of these models from specific regions where they have collected training data to nearby areas we are faced with an interesting probem: how do you classify a species in a new region that you may not have seen in previous training data?\n\n## Data\n\nIn order to tackle this problem, the competition organizers have prepared a challenge where the training data and test data are from different regions, namely The American Southwest and the American Northwest. The species seen in each region overlap, but are not identical, and the challenge is to classify the test species correctly.  \n\n## Kernel\n\nIn this Kernel we perform EDA on the data and create a predictive model, using <a href='#5'>References<\/a> [5]-[9].  The predictive model solution, including the use of pretrained DenseNet weights and reduced image sizes, should be credited to [5].\n\n## References\n\nPlease consult the <a href='#5'>References<\/a> section for the datasets, Kernels and articles used in this Kernel.","061508d3":"## Clases of images\n\nLet's check the classes of images in train_df.","4b4e7103":"## Check images  \nLet's check how many images are in train and test images folders.","c60fea98":"# <a id='3'>Data exploration<\/a>  \n\nLet's define the classes:","be936c56":"## Define the model   \n\nI used the <a href='#7'>References<\/a> [5] (credits should to go to this Kernel mostly), [6], [7], [8], [9], [10] for creation of this model.\n","52828e29":"Majority of records are actually from location 96 and without specifying the wild animal class (`empty`). Also, location 26 (the next one as frequence) is as well for `empty` class. Let's see what we get if we just remove the entries with `empty`.\n","55bed246":"## Classes and hours  \n\nLet's show the number of wild animals observed at different hours.","e1412cac":"A model is saved every training epoch if the validation error improved.","51e43284":"Let's check the files.","8cafdb29":"We write the submission file.","e92ffb1f":"Most of the images are of classe `empty`, followed by `opossum`, `racoon`, `coyote` and `rabbit`.","e5527dfa":"\n# <a id='4'>Model<\/a>  \n\nLet's convert the compact 32x32 images to float and scale to 0 to 1.  \nI used the <a href='#7'>References<\/a> [5] (credits should to go to this Kernel mostly), [6], [7], [8], [9].\n\n\n## Scale the images","c23fc8ec":"Majority of images are from location 96 (18.38%) and 26 (13.95%).\n\n## Locations and classes\n\nLet's show now the locations and classes.","5f7a29f7":"We can observe that majority of racoons and opossums images are captured during night.  \n\nLet's see in what month are each species images mostly captured.","21a36325":"# <a id='2'>Prepare for data analysis<\/a>  \n\n\n## Load packages","efc64af4":"## Metric","f98cd977":"Majority of sequence number frames are 1 (61%), followed by 3 (37%), the rest (1.2%) having 5.\n\n## Locations distribution","c9e3f90e":"Let's check again the data.","baf6c1ff":"All these visualizations suffers from one problem: the distribution of majority classes obscures the distribution of minority classes. We will try to create a heatmap for each species. Let's do this showing month and hour for each species, on a separate histogram.\n\n\n## Classes per hour and month","d30014be":"We remove `empty` class, which is observed mostly around noon, to see better the other classes distribution on hours.\n\n\n## Classes and months\n\nWe show the number of wild animals during different months.\n","bb92d4c6":"## Train the model","8c81854b":"We can observe that the number of images in train folder is smaller that the number of rows in train dataset while the number of images in test folder is equal with the number of rows in test dataset.\n\nLet's check if every row in train and test have a corresponding image in the images folders.","6f311ea6":"Let's check the resulting model.","2c9a862c":"We remove the `empty` class to see better the other classes.","8d9e25c7":"# <a id='5'>References<\/a>\n\n[1] https:\/\/www.kaggle.com\/gpreda\/honey-bee-subspecies-classification   \n[2] https:\/\/www.kaggle.com\/gpreda\/robots-need-help  \n[3] https:\/\/www.kaggle.com\/artgor\/iwildcam-basic-eda  \n[4] https:\/\/www.kaggle.com\/c\/iwildcam-2019-fgvc6\/  \n[5] https:\/\/www.kaggle.com\/xhlulu\/keras-cnn-starter-petfinder\/  \n[6] https:\/\/www.kaggle.com\/xhlulu\/reducing-image-sizes-to-32x32  \n[7] https:\/\/medium.com\/@thongonary\/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2  \n[8] https:\/\/www.kaggle.com\/xhlulu\/cnn-baseline-iwildcam-2019  \n[9] https:\/\/www.kaggle.com\/xhlulu\/densenet-transfer-learning-iwildcam-2019\/  \n[10] https:\/\/www.kaggle.com\/gpreda\/cats-or-dogs-using-cnn-with-transfer-learning\n"}}