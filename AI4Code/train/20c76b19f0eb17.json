{"cell_type":{"047cb6c3":"code","59e2cad1":"code","eda7e522":"code","b192504f":"code","976711a8":"code","512e0dee":"code","34af497b":"code","6218cb5c":"code","33c249cc":"code","244ac11c":"code","4abe6947":"code","0ea0cc49":"code","d29b80ee":"code","6da19a3c":"code","fc27b0fd":"code","0771fc91":"code","4be8fc0d":"code","f664f05a":"code","08dcea65":"code","9d0aa5aa":"code","053a20ed":"code","19330cfe":"code","4a8fd5da":"markdown"},"source":{"047cb6c3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('..\/input'))\ndata = pd.read_csv(\"\/kaggle\/input\/confused-eeg\/EEG_data.csv\")","59e2cad1":"data.head()\n","eda7e522":"data.info()\n","b192504f":"data.plot()\n","976711a8":"data.head().plot()","512e0dee":"data.describe()","34af497b":"df=pd.DataFrame(data)","6218cb5c":"df.columns","33c249cc":"print(data['user-definedlabeln'].unique())","244ac11c":"df['Theta'].plot()","4abe6947":"gr1=df.groupby('Theta')['user-definedlabeln'].mean()\nprint(gr1)\ngrp1=pd.DataFrame(gr1)\nprint(grp1.describe())\ngrp1.head(300).plot()\n","0ea0cc49":"gr2=df.groupby('Alpha1')['user-definedlabeln'].mean()\nprint(gr2)\ngrp2=pd.DataFrame(gr2)\nprint(grp2.describe())\ngrp2.head(300).plot()","d29b80ee":"gr3=df.groupby('Alpha2')['user-definedlabeln'].mean()\nprint(gr3)\ngrp3=pd.DataFrame(gr3)\nprint(grp3.describe())\ngrp3.head(300).plot()","6da19a3c":"###testing the acuuracy for the first timw will do the other preprocessing later ones the accuracy is seen \nX_int=df.drop('user-definedlabeln',axis=1).values\nY_int=df['user-definedlabeln'].values","fc27b0fd":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_int,Y_int, test_size=0.2,random_state=42)","0771fc91":"from sklearn.ensemble import RandomForestClassifier\nfor i in range(1,50):\n    clf=RandomForestClassifier(n_estimators=i,max_depth=2,random_state=13)\n    clf.fit(X_train,y_train)\n    clf.predict(X_test)\n    scr=clf.score(X_test,y_test)\n    print(scr)\n","4be8fc0d":"from sklearn import svm\nclf = svm.SVC()\nclf.fit(X_train,y_train)\npreds = clf.predict(X_test)\nclf.score(X_test, y_test)\n","f664f05a":"pip install xgboost\n","08dcea65":"import xgboost as xgb\n\nxg = xgb.XGBClassifier(objective='binary:logistic', n_estimators=1000, seed=1)\nxg.fit(X_train,y_train)\nprint(xg.predict(X_test))\nxg.score(X_test,y_test)\n","9d0aa5aa":"import xgboost as xgb\n\nxg = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100,seed=1)\nxg.fit(X_train,y_train)\npredict=xg.predict(X_test)\nprint(xg.score(X_test,y_test))","053a20ed":"import xgboost as xgb\nfor i in range(200,300):\n    xg = xgb.XGBClassifier(objective='binary:logistic', n_estimators=i, seed=1)\n    xg.fit(X_train,y_train)\n    predict=xg.predict(X_test)\n    print(xg.score(X_test,y_test))","19330cfe":"# final accuracy \n\nimport xgboost as xgb\n\nxg = xgb.XGBClassifier(objective='binary:logistic', n_estimators=1000, seed=1)\nxg.fit(X_train,y_train)\nprint(xg.predict(X_test))\nxg.score(X_test,y_test)","4a8fd5da":"here is the code and we got an accuracy of 0.99102 way heigher than the proclaimed 67 percent \nAbhishek Parashar and Yukti Mohan"}}