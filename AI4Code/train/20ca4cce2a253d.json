{"cell_type":{"791ee455":"code","23959945":"code","c95b7be8":"code","e8534725":"code","e1312fcd":"code","568f0a9d":"code","e678ad6d":"code","bb4704fd":"code","c568cf6c":"code","118c2ea4":"code","ae1aaf50":"code","17850c05":"code","4e4ba08a":"code","96c82593":"code","59db8fa6":"code","964a2546":"code","777bd12a":"code","564627f5":"code","131da884":"code","fb83f056":"code","842f3cf7":"code","95b37c1f":"code","3083d276":"markdown","a3f93a3f":"markdown","d2bec597":"markdown","edd401a9":"markdown","a88407c6":"markdown","656509e2":"markdown","01085143":"markdown","420d56a5":"markdown","979c085b":"markdown","3f76dba9":"markdown","3a4f44e0":"markdown"},"source":{"791ee455":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","23959945":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nsubmit = pd.read_csv(\"..\/input\/sample_submission.csv\")","c95b7be8":"test.head()","e8534725":"train.head()","e1312fcd":"x_train = train.iloc[:,1:]\ny_train = train.iloc[:,0]","568f0a9d":"plt.subplot(221)\nplt.imshow(np.reshape(np.array(x_train.iloc[0]),(28,28)), cmap=plt.get_cmap('gray'))\nplt.subplot(222)\nplt.imshow(np.reshape(np.array(x_train.iloc[1]),(28,28)), cmap=plt.get_cmap('gray'))\nplt.subplot(223)\nplt.imshow(np.reshape(np.array(x_train.iloc[2]),(28,28)), cmap=plt.get_cmap('gray'))\nplt.subplot(224)\nplt.imshow(np.reshape(np.array(x_train.iloc[3]),(28,28)), cmap=plt.get_cmap('gray'))\nplt.show()","e678ad6d":"sns.catplot(x=\"label\",kind=\"count\", data=train,height=7)","bb4704fd":"x_train=x_train\/255.0\ntest=test\/255.0","c568cf6c":"x_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","118c2ea4":"y_train=to_categorical(y_train,num_classes=10)\nprint(x_train.shape,y_train.shape,test.shape)","ae1aaf50":"num_classes = y_train.shape[1]\nnum_pixels = x_train.shape[1]","17850c05":"seed=7\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.10, random_state=seed)","4e4ba08a":"def cnn_model():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu', input_shape = (28,28,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.20))\n    model.add(Flatten())\n    model.add(Dense(128, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n    model.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\nmodel=cnn_model()","96c82593":"from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\nfilepath1=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\nfilepath2 = \"best_weights.hdf5\"\ncheckpoint1 = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncheckpoint2 = ModelCheckpoint(filepath2, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n                              patience=3, \n                              verbose=1, \n                              factor=0.5, \n                              min_lr=0.00001)\n\ncallbacks_list = [checkpoint1,checkpoint2,reduce_lr]\n\n\nepochs = 1 #increase for better results\nbatch_size = 640","59db8fa6":"datagen = ImageDataGenerator(\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1)  # randomly shift images vertically (fraction of total height)\n\n\ndatagen.fit(x_train)","964a2546":"history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test,y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0], callbacks=callbacks_list)","777bd12a":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","564627f5":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","131da884":"model.load_weights(\"best_weights.hdf5\")\nsubmit.shape","fb83f056":"test.shape","842f3cf7":"submit.Label =model.predict_classes(test)","95b37c1f":"submit.head()\nsubmit.to_csv('submit.csv',index=False)","3083d276":"So the training data is almost balanced.","a3f93a3f":"## Defining CNN Model ","d2bec597":"We see that the data in the train and test dataframes are the pixel values for the images of the digits. The final shape of the digit image is 28X28. So there are 784 columns in test and 785 columns in train, one column for labels.","edd401a9":"# Basic and advanced approach to solve MNIST competition\n\n## About MNIST\nMNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.","a88407c6":"## Data Preprocessing","656509e2":"Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]).","01085143":"NOTE: These plots are more useful when trained for more number of epochs. They don't display much trends in just 1 epoch.","420d56a5":"We can also use Residual Blocks for better results. The current model only after training for 1 epoch was able to produce 99.53% accurate results which is great in my opinion.\n<br>\n<br>\nIf you like my work please do **UPVOTE** as it motivates me to create better notebooks and tutorials for the community. It's a pleasure to give back to the data science community. ","979c085b":"### Basic Plots","3f76dba9":"## Training","3a4f44e0":"### Predicting and saving the output."}}