{"cell_type":{"437b32a1":"code","7329564b":"code","697b5065":"code","e4bbe7ce":"code","18a27589":"code","d32cea79":"code","9645733f":"code","c4aad379":"code","9ea79f56":"code","44ddcb65":"code","d74c3b1f":"code","50457c47":"code","aea15f56":"code","b8c11230":"code","fd44851d":"code","89ccef9d":"code","1cf64fd8":"code","bd777d8b":"code","4350349a":"code","fb79dcd3":"markdown","04013f64":"markdown","f76c6ff2":"markdown","36e438e4":"markdown","0f2052cf":"markdown"},"source":{"437b32a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7329564b":"import random\nimport seaborn as sns\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, RocCurveDisplay, ConfusionMatrixDisplay, confusion_matrix, roc_auc_score, accuracy_score\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn import preprocessing\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","697b5065":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","e4bbe7ce":"y =train['target']","18a27589":"train.head()","d32cea79":"train.info()","9645733f":"train.shape","c4aad379":"train.isnull().sum()","9ea79f56":"train.describe()","44ddcb65":"cols = ['f'+str(i) for i in range(100)]","d74c3b1f":"#plot the first 32 features\ni = 1\nplt.figure()\nfig, ax = plt.subplots(8, 4,figsize=(20, 22))\nfor feature in cols[:32]:\n    plt.subplot(8, 4,i)\n    sns.histplot(train[feature],color=\"blue\", kde=True,bins=100, label='train_'+feature)\n    sns.histplot(test[feature],color=\"olive\", kde=True,bins=100, label='test_'+feature)\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","50457c47":"train.describe()","aea15f56":"sns.catplot(x=\"target\", kind=\"count\",  data=train)","b8c11230":"#apply standart scaler to the data\nscaler = StandardScaler()\ntrain[cols] = scaler.fit_transform(train[cols])\ntest[cols] = scaler.transform(test[cols])","fd44851d":"preds = np.zeros(test.shape[0])\nkf = StratifiedKFold(n_splits=15,random_state=48,shuffle=True)\nauc=[]  # list contains auc for each fold\nacc=[]  # list contains accuracy for each fold\nn=0\nfor trn_idx, test_idx in kf.split(train[cols],y):\n    X_tr,X_val=train[cols].iloc[trn_idx],train[cols].iloc[test_idx]\n    y_tr,y_val=y.iloc[trn_idx],y.iloc[test_idx]\n    \n    model = LogisticRegression(solver='liblinear')\n    model.fit(X_tr,y_tr)\n    preds += model.predict_proba(test[cols])[:,1]\/kf.n_splits\n    \n    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))\n    acc.append(accuracy_score(y_val, model.predict(X_val)))\n\n    print(f\"fold: {n+1} , accuracy: {round(acc[n]*100,3)} , auc: {round(auc[n]*100,3)}\")\n    n+=1","89ccef9d":"print(f\"the mean AUC is : {round(np.mean(auc)*100,2)} while the mean Accuracy is : {round(np.mean(acc)*100,2)} \")","1cf64fd8":"# Plot of confusion matrix for the last fold\ncm = confusion_matrix(model.predict(X_val),y_val)\ncm_display = ConfusionMatrixDisplay(cm).plot()","bd777d8b":"sub['target']=preds\nsub.to_csv('submission.csv', index=False)","4350349a":"sub","fb79dcd3":"# Data Collection","04013f64":"# Final Accuracy","f76c6ff2":"# Hi there ,This notebook is perferct for beginner. It is simple to understand and lot to learn !!","36e438e4":"# Importing dependencies ","0f2052cf":"# Modeling"}}