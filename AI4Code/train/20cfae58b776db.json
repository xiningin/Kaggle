{"cell_type":{"fd9ef404":"code","e7fbba53":"code","6094544c":"code","24844bfd":"code","0107acbd":"code","338862ec":"code","c18c217e":"code","0918dc5a":"code","0cc45c2e":"code","877bee43":"code","692b4d1c":"code","794dc14a":"code","117f3199":"code","6cdbe511":"code","32023e79":"code","8aa5ad58":"code","57a92e7e":"code","e761ddcb":"code","cad1e5a6":"code","37757e3d":"code","6db76e15":"code","a3fc2278":"code","19c3b80d":"code","d6a220ac":"code","14d1195f":"code","316ebc4b":"code","9998f55d":"code","3cee525c":"code","ad6dc8fe":"code","ea9645f5":"code","6b176c58":"code","4bbbf08e":"code","9fea1baa":"code","c026950e":"code","f91c579f":"code","40987355":"code","0d50ea43":"code","4e221ec3":"code","2f3c0e53":"code","0f9a8ec1":"code","7fb3f4cd":"code","07104787":"code","681f3c41":"code","269039e9":"code","a177a058":"code","657f207d":"code","d749f8a8":"code","affff182":"code","ba09f172":"code","20acb7d0":"code","02035bcf":"markdown","e2f5aa1c":"markdown","11fff58c":"markdown","2acaeaf6":"markdown","ced03176":"markdown","dc95be15":"markdown","3bc8a4ec":"markdown","905b7b73":"markdown","84297701":"markdown","3a18d0d9":"markdown","b38d885c":"markdown","16a2c910":"markdown","3957de48":"markdown","999b6833":"markdown","5e8432a7":"markdown","70d06f02":"markdown","7f32bd41":"markdown","ef36ddd8":"markdown","24a59349":"markdown","3ea70724":"markdown","4aec296c":"markdown","c59d262e":"markdown","d5cb8ea4":"markdown","a0a44da5":"markdown","4175ff3d":"markdown","14e8d834":"markdown","0c49c9de":"markdown","3276b6a9":"markdown","ed2f5105":"markdown","ddf9c64a":"markdown","762e61be":"markdown","f389f4e1":"markdown","7f7e5aec":"markdown","c69fd2c2":"markdown","366ee74a":"markdown"},"source":{"fd9ef404":"from keras.layers import Input, Dense\nfrom keras.models import Model, Sequential\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.manifold import TSNE\nfrom sklearn import preprocessing \nimport matplotlib.pyplot as plt\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\n\n%matplotlib inline\nplt.style.use('ggplot')","e7fbba53":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","6094544c":"df.head()","24844bfd":"df.info()","0107acbd":"df.describe()","338862ec":"df.isnull().sum()","c18c217e":"fig, ax = plt.subplots(figsize=(6, 4))\n\nax = sns.countplot(x='Class', data=df)\nplt.tight_layout()","0918dc5a":"print(df['Class'].value_counts())\nprint('\\nPercentage of fraudulent activity: {:.2%}'.format((df[df['Class'] == 1].shape[0] \/ df.shape[0])))","0cc45c2e":"df['Time'].describe()","877bee43":"df_copy = df.copy()\ndf_copy.loc[:,'Time'] = df_copy.Time \/ 3600\ndf_copy['Time'].tail(10)","692b4d1c":"df_copy['Time'].max() \/ 24","794dc14a":"plt.figure(figsize=(12,4), dpi=80)\nsns.distplot(df_copy['Time'], bins=48)\nplt.xlim([0,48])\nplt.xticks(np.arange(0,54,6))\nplt.xlabel('Time After First Transaction (hr)')\nplt.ylabel('Count')\nplt.title('Transaction Times')","117f3199":"df_copy_nofraud = df_copy[df_copy['Class']==0] \nplt.figure(figsize=(12,4), dpi=80)\nsns.distplot(df_copy_nofraud['Time'], bins=48)\nplt.xlim([0,48])\nplt.xticks(np.arange(0,54,6))\nplt.xlabel('Time After First Transaction (hr)')\nplt.ylabel('Count')\nplt.title('Transaction Times')","6cdbe511":"df_copy_fraud = df_copy[df_copy['Class']==1] \nplt.figure(figsize=(12,4), dpi=80)\nsns.distplot(df_copy_fraud['Time'], bins=48)\nplt.xlim([0,48])\nplt.xticks(np.arange(0,54,6))\nplt.xlabel('Time After First Transaction (hr)')\nplt.ylabel('Count')\nplt.title('Transaction Times')","32023e79":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(20,6))\nsns.distplot(df_copy.Amount, ax=ax1)\nsns.boxplot(df_copy.Amount, ax=ax2)","8aa5ad58":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(20,8))\nsns.boxplot(df_copy[df_copy['Class']==1].Amount, ax=ax1)\nsns.boxplot(df_copy[df_copy['Class']==0].Amount, ax=ax2)","57a92e7e":"sns.jointplot(x=df_copy['Time'], y=df_copy['Amount'])","e761ddcb":"from scipy.stats import iqr\nupper_limit = df_copy.Amount.quantile(0.75) + (1.5*iqr(df_copy.Amount))\nprint(upper_limit)\nprint(df_copy[df_copy.Amount>upper_limit]['Class'].value_counts())","cad1e5a6":"df = df[df.Amount<=8000]\nprint(df['Class'].value_counts())\nprint('\\nPercentage of fraudulent activity: {:.2%}'.format((df[df['Class'] == 1].shape[0] \/ df.shape[0])))","37757e3d":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(20,15))\nsns.boxplot(df[df['Class']==1].Amount, ax=ax1)\nax1.set_title('Fraudulent Transactions')\nsns.boxplot(df[df['Class']==0].Amount, ax=ax2)\nax2.set_title('Genuine Transactions')","6db76e15":"corr = df_copy.corr()\nfig, ax = plt.subplots(figsize=(9, 7))\n\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, linewidths=.1, cmap=\"RdBu\", ax=ax)\nplt.tight_layout()","a3fc2278":"non_fraud = df[df['Class'] == 0].sample(2000)\nfraud = df[df['Class'] == 1]\nprint(len(non_fraud), len(fraud))\n\ndf_2 = non_fraud.append(fraud).sample(frac=1).reset_index(drop=True)\nx = df_2.drop(['Class'], axis = 1).values\ny = df_2[\"Class\"].values","19c3b80d":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(20,15))\nsns.boxplot(df_2[df_2['Class']==1].Amount, ax=ax1)\nax1.set_title('Fraudulent Transactions')\nsns.boxplot(df_2[df_2['Class']==0].Amount, ax=ax2)\nax2.set_title('Genuine Transactions')","d6a220ac":"p = TSNE(n_components=2, random_state=24).fit_transform(x)\np","14d1195f":"color_map = {0:'red', 1:'blue'}\nplt.figure()\nfor idx, cl in enumerate(np.unique(y)):\n    plt.scatter(x = p[y==cl,0], \n                y = p[y==cl,1], \n                c = color_map[idx], \n                label = cl)\nplt.xlabel('X in t-SNE')\nplt.ylabel('Y in t-SNE')\nplt.legend(loc='upper left')\nplt.title('t-SNE visualization of test data')\nplt.show()","316ebc4b":"x_scale = preprocessing.MinMaxScaler().fit_transform(x)\nx_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]","9998f55d":"autoencoder = Sequential()","3cee525c":"autoencoder.add(Dense(x.shape[1], activation='tanh'))\nautoencoder.add(Dense(100, activation='tanh'))\nautoencoder.add(Dense(50, activation='relu'))\nautoencoder.add(Dense(50, activation='tanh'))\nautoencoder.add(Dense(100, activation='tanh'))\nautoencoder.add(Dense(x.shape[1], activation='relu'))","ad6dc8fe":"autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")","ea9645f5":"autoencoder.fit(x_norm, x_norm, \n                batch_size = 256, epochs = 10, \n                shuffle = True, validation_split = 0.20);","6b176c58":"autoencoder.layers","4bbbf08e":"hidden_representation = Sequential()\nhidden_representation.add(autoencoder.layers[0])\nhidden_representation.add(autoencoder.layers[1])\nhidden_representation.add(autoencoder.layers[2])","9fea1baa":"norm_hid_rep = hidden_representation.predict(x_norm)\nfraud_hid_rep = hidden_representation.predict(x_fraud)","c026950e":"rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\ny_n = np.zeros(norm_hid_rep.shape[0])\ny_f = np.ones(fraud_hid_rep.shape[0])\nrep_y = np.append(y_n, y_f)","f91c579f":"p = TSNE(n_components=2, random_state=24).fit_transform(rep_x)","40987355":"color_map = {0:'red', 1:'blue'}\nplt.figure()\nfor idx, cl in enumerate(np.unique(y)):\n    plt.scatter(x = p[y==cl,0], \n                y = p[y==cl,1], \n                c = color_map[idx], \n                label = cl)\nplt.xlabel('X in t-SNE')\nplt.ylabel('Y in t-SNE')\nplt.legend(loc='upper left')\nplt.title('t-SNE visualization of test data')\nplt.show()","0d50ea43":"train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\nclf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\npred_y = clf.predict(val_x)\n\n# classification report\nprint(classification_report(val_y, pred_y))\n\n# confusion matrix\nfig, ax = plt.subplots()\nsns.heatmap(confusion_matrix(val_y, pred_y, normalize='true'), annot=True, ax=ax)\n\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real Value\")\nax.set_xlabel(\"Predicted\")\n\nplt.show()","4e221ec3":"model_tree = DecisionTreeClassifier(max_depth=4, criterion=\"entropy\")\n\nmodel_tree.fit(train_x, train_y)\n\ny_pred_tree = model_tree.predict(val_x)\n\n# classification report\nprint(classification_report(val_y, y_pred_tree))\n\n# confusion matrix\nfig, ax = plt.subplots()\nsns.heatmap(confusion_matrix(val_y, y_pred_tree, normalize='true'), annot=True, ax=ax)\n\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real Value\")\nax.set_xlabel(\"Predicted\")\n\nplt.show()","2f3c0e53":"from imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter","0f9a8ec1":"y = df[\"Class\"].values","7fb3f4cd":"from sklearn.preprocessing import StandardScaler\nscaler_df = df.drop('Class',axis=1)\nscaler_df_final = StandardScaler().fit_transform(scaler_df)\nscaler_df_final = pd.DataFrame(scaler_df_final)\nscaler_df_final.head()","07104787":"x = scaler_df_final.values","681f3c41":"train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.25)","269039e9":"df_real = pd.DataFrame(train_x, columns = scaler_df.columns)\ndf_real['Class'] = train_y","a177a058":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(20,15))\nsns.boxplot(df_real[df_real['Class']==1].Amount, ax=ax1)\nax1.set_title('Fraudulent Transactions')\nsns.boxplot(df_real[df_real['Class']==0].Amount, ax=ax2)\nax2.set_title('Genuine Transactions')","657f207d":"over = SMOTE(sampling_strategy=0.5)\n\nsteps = [\n    ('over',over)\n]\nxs, ys = Pipeline(steps=steps).fit_resample(train_x, train_y)\nclass_cnt = dict(Counter(ys))\nprint('The new count of classes:', class_cnt)\n","d749f8a8":"df_oversampler = pd.DataFrame(xs, columns = scaler_df.columns)\ndf_oversampler['Class'] = ys","affff182":"fig, (ax1,ax2) = plt.subplots(2,1,figsize=(20,15))\nsns.boxplot(df_oversampler[df_oversampler['Class']==1].Amount, ax=ax1)\nax1.set_title('Fraudulent Transactions')\nsns.boxplot(df_oversampler[df_oversampler['Class']==0].Amount, ax=ax2)\nax2.set_title('Genuine Transactions')","ba09f172":"reg = LogisticRegression(random_state = 42)\nreg.fit(xs, ys)\ny_test_predict = reg.predict(test_x)\n\n# classification report\nprint(classification_report(test_y, y_test_predict))\n\n# confusion matrix\nfig, ax = plt.subplots()\nsns.heatmap(confusion_matrix(test_y, y_test_predict, normalize='true'), annot=True, ax=ax)\n\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real Value\")\nax.set_xlabel(\"Predicted\")\n\nplt.show()","20acb7d0":"model_tree = DecisionTreeClassifier(max_depth=4, criterion=\"entropy\")\n\nmodel_tree.fit(xs, ys)\n\ny_pred_tree = model_tree.predict(test_x)\n\n# classification report\nprint(classification_report(test_y, y_pred_tree))\n\n# confusion matrix\nfig, ax = plt.subplots()\nsns.heatmap(confusion_matrix(test_y, y_pred_tree, normalize='true'), annot=True, ax=ax)\n\nax.set_title(\"Confusion Matrix\")\nax.set_ylabel(\"Real Value\")\nax.set_xlabel(\"Predicted\")\n\nplt.show()","02035bcf":"### Logistic Regression","e2f5aa1c":"# **Handle Imbalanced Dataset**\n\nThe dataset we are using is heavily imbalanced i.e. the data points that belong to fraudulent transactions are around 0.16% only. Therefore, there are chances that the model may develop certain bias towards the non-fraudulent transactions and miss out on understanding the patterns behind fraudulent transactions due to their less count.\n\nThis will hazardous for our use-case as we cannot afford misclassifying the fraudulent transactions as genuine ones.\n\nTo deal with the problem of imbalanced datasets, we generally take two approaches:\n\n1. **Undersampling** - In this approach, we reduce the count of the majority class and balance it with the minority class. \n2. **Oversampling** - In this approach, we generate synthetic data points for the minority class and try to balance it with the majority class.","11fff58c":"### Oversampling using SMOTE","2acaeaf6":"### Decision Tree Classifier","ced03176":"# Exploratory Data Analysis (EDA)","dc95be15":"Let's convert the time from seconds to hours to ease the interpretation.","3bc8a4ec":"### Latent Representations","905b7b73":"### Logistic Regression","84297701":"### Scaling the data","3a18d0d9":"we can observe that now fraud and non-fraud transactions are pretty visibile and are linearly separable. Even the simpler models can be used to predict the target variable now","b38d885c":"### Visualizing the training data before oversampling","16a2c910":"## **Undersampling**\n\nUndersampling techniques remove examples from the training dataset that belong to the majority class in order to better balance the class distribution.\nThese methods can be used directly on a training dataset that can then, in turn, be used to fit a machine learning model.","3957de48":"### Training the autoencoder","999b6833":"### Decision Tree Classifier","5e8432a7":"### Visualizing the data after oversampling","70d06f02":"### Constructing the autoencoder","7f32bd41":"# Correlation Analysis","ef36ddd8":"### Visualising the encoded distributions","24a59349":"The data is heavily right-skewed.","3ea70724":"## Oversampling","4aec296c":"## Time - Understanding it better","c59d262e":"In regular transactions, we see two major drop in the transactions as given below:\n1. 1 hr to 6 hr mark\n2. 23 hr to 29 hr mark\n\nSince the data spans over two days, we can conclude that the non-fraudulent\/regular transactions drop significantly during the night hours. This makes sense as people sleep during these times and hence, the genuine transactions are very less.\n\n\nHowever, in the fraudulent transactionns, we see no clear patterns in the activity over the hours. But we may observe that there is clearly a hike in the count of fraudulent transactions during night time.","d5cb8ea4":"Let us look at these approaches one by one.","a0a44da5":"### Splitting the data into train and test","4175ff3d":"From the above heatmap, we can observe that the there are no strongly correlated features in the dataset. \n\nWe see some negative correlation between PCA components and Time column of the dataset but it is not so significant that we need to take some action to handle it.\n\nOther than that, all the correlation values lie somewhere in the neutral or zero-range. ","14e8d834":"### Sampling the Data","0c49c9de":"Fraudulent Transactions over the time","3276b6a9":"## Amount - Understanding it better","ed2f5105":"### Visualising the data","ddf9c64a":"So the transactions occur over a two-day period. Next let's plot a histogram of transaction times, with one bin per hour:","762e61be":"# Outlier Analysis","f389f4e1":"Non-Fraudulent Transactions over the time","7f7e5aec":"### Data Scaling","c69fd2c2":"In this use-case, we do not want to remove any outliers as the data is sensitive ","366ee74a":"What is the time of the last transaction, in days?"}}