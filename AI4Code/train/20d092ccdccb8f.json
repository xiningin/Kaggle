{"cell_type":{"ba5bbdbd":"code","0db394fd":"code","038e1cf3":"code","1fb2730b":"code","78e05802":"code","fbbdcbbb":"code","f017cff7":"code","6372f356":"code","ddb31856":"code","4a9c60db":"code","63dcfc99":"code","8ad6460b":"code","ac1249ad":"code","5e4c09f0":"code","33ac3bb0":"code","f53c6296":"markdown","6004d921":"markdown","2609153b":"markdown","e090b709":"markdown","85d6c663":"markdown","fa4fec79":"markdown","603ef7f7":"markdown","e3af1bbe":"markdown","b5774924":"markdown","5acd212d":"markdown","1765a2fe":"markdown","091591c5":"markdown","9125c662":"markdown","a1be20ba":"markdown","e960cc2f":"markdown","da66e4a5":"markdown","f8d806c0":"markdown","2f6e4c56":"markdown"},"source":{"ba5bbdbd":"import os\nimport time\nimport copy\nimport numpy as np\n# from tqdm import tqdm,trange\nimport tqdm\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision import utils\n\n!pip install torchsummary\nfrom torchsummary import summary\n\nimport matplotlib.pyplot as plt","0db394fd":"train_set = datasets.STL10('.\/data',split='train',transform=transforms.ToTensor(),download=True)\nvalid_set = datasets.STL10('.\/data',split='test',transform=transforms.ToTensor(),download=True)\nprint('train : %s \/ test : %s' % (len(train_set),len(valid_set)))","038e1cf3":"# load class_names\nwith open('.\/data\/stl10_binary\/class_names.txt','r') as f:\n    classes = []\n    lines = f.readlines()\n    for i in lines:\n        classes.append(i.strip())\n\nprint('[ classes ]\\n',classes)\n\n\n# display sample images \ndef show(img, y=None, color=True):\n    npimg = img.numpy()\n    npimg_tr = np.transpose(npimg, (1,2,0))\n    plt.imshow(npimg_tr)\n\n    if y is not None:\n        plt.title('labels :' + str(y))\n\nnp.random.seed(1)\ntorch.manual_seed(1)\n\ngrid_size = 4\nrnd_inds = np.random.randint(0, len(train_set), grid_size)\nprint('image indices:',rnd_inds)\n\nx_grid = [train_set[i][0] for i in rnd_inds]\ny_grid = [classes[train_set[i][1]] for i in rnd_inds]\n\nx_grid = utils.make_grid(x_grid, nrow=grid_size, padding=2)\n\nshow(x_grid, y_grid)","1fb2730b":"# To normalize the dataset, calculate the mean and std\ntrain_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_set]\ntrain_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_set]\n\ntrain_meanR = np.mean([m[0] for m in train_meanRGB])\ntrain_meanG = np.mean([m[1] for m in train_meanRGB])\ntrain_meanB = np.mean([m[2] for m in train_meanRGB])\ntrain_stdR = np.mean([s[0] for s in train_stdRGB])\ntrain_stdG = np.mean([s[1] for s in train_stdRGB])\ntrain_stdB = np.mean([s[2] for s in train_stdRGB])\n\n\nval_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in valid_set]\nval_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in valid_set]\n\nval_meanR = np.mean([m[0] for m in val_meanRGB])\nval_meanG = np.mean([m[1] for m in val_meanRGB])\nval_meanB = np.mean([m[2] for m in val_meanRGB])\n\nval_stdR = np.mean([s[0] for s in val_stdRGB])\nval_stdG = np.mean([s[1] for s in val_stdRGB])\nval_stdB = np.mean([s[2] for s in val_stdRGB])\n\nprint('train mean : ',train_meanR, train_meanG, train_meanB)\nprint('train std : ',train_stdR,train_stdG,train_stdB)\nprint('valid mean : ',val_meanR, val_meanG, val_meanB)\nprint('valid std : ',val_stdR,val_stdG,val_stdB)","78e05802":"## [ image transformation ]\ntrain_transformation = transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Resize(224),\n                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n                        transforms.RandomHorizontalFlip(),\n])\n\nval_transformation = transforms.Compose([\n                        transforms.ToTensor(),\n                        transforms.Resize(224),\n                        transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n])\n\n## [ apply transforamtion ] \ntrain_set.transform = train_transformation\nvalid_set.transform = val_transformation\n\n## [ create DataLoader ] \ntrain_dl = DataLoader(train_set, batch_size=32, shuffle=True)\nval_dl = DataLoader(valid_set, batch_size=32, shuffle=True)\n\nprint('train set : ',train_set.data.shape, train_set.labels.shape)\nprint('valid set : ',valid_set.data.shape, valid_set.labels.shape)","fbbdcbbb":"class BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self,in_channels,out_channels,stride=1):\n        super().__init__()\n        \n        # BatchNorm\uc5d0 bias \ud3ec\ud568\ub418\uc5b4\uc788\uc73c\ubbc0\ub85c, conv2d bias=False\n        self.residual_function = nn.Sequential(\n            nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.Conv2d(out_channels,out_channels*BasicBlock.expansion,kernel_size=3,stride=stride,padding=1,bias=False),\n            nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n        )\n        self.shortcut = nn.Sequential()\n        self.relu = nn.ReLU()\n        \n        # projection mapping using 1x1conv\n        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n            )\n    def forward(self,x):\n        x = self.residual_function(x) + self.shortcut(x)\n        x = self.relu(x)\n        return x\n    \nclass BottleNeck(nn.Module):\n    expansion = 4\n    def __init__(self,in_channels,out_channels,stride=1):\n        super().__init__()\n        \n        self.residual_function = nn.Sequential(\n            nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=1,bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.Conv2d(out_channels,out_channels * BottleNeck.expansion, kernel_size=1,stride=1, bias=False),\n            nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n        )\n        \n        self.shortcut = nn.Sequential()\n        self.relu = nn.ReLU()\n        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n            )\n            \n    def forward(self, x):\n        x = self.residual_function(x) + self.shortcut(x)\n        x = self.relu(x)\n        return x\n","f017cff7":"class ResNet(nn.Module):\n    def __init__(self,block,num_block, num_classes=10, init_weights=True):\n        super(ResNet,self).__init__()\n        \n        self.in_channels = 64\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n        )\n        self.conv2 = self._make_layer(block, 64, num_block[0], 1)\n        self.conv3 = self._make_layer(block, 128, num_block[1], 2)\n        self.conv4 = self._make_layer(block, 256, num_block[2], 2)\n        self.conv5 = self._make_layer(block, 512, num_block[3], 2)\n        \n        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n        \n        # weights init\n        if init_weights:\n            self._initialize_weights()\n            \n    def _make_layer(self,block,out_channels, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks-1)\n        layers =[]\n        for stride in strides:\n            layers.append(block(self.in_channels, out_channels,stride))\n            self.in_channels = out_channels *block.expansion\n        return nn.Sequential(*layers)\n    \n    def forward(self,x):\n        output = self.conv1(x)\n        output = self.conv2(output)\n        x = self.conv3(output)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.avg_pool(x)\n        x = x.view(x.size(0),-1)\n        x = self.fc(x)\n        return x\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias,0)\n            elif isinstance(m,nn.BatchNorm2d):\n                nn.init.constant_(m.weight,1)\n                nn.init.constant_(m.bias,0)\n            elif isinstance(m,nn.Linear):\n                nn.init.constant_(m.weight,0.01)\n                nn.init.constant_(m.bias,0)\n                \n            \ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3,4,6,3])\n\ndef ResNet50():\n    return ResNet(BottleNeck, [3,4,6,3])\n\ndef ResNet101():\n    return ResNet(BottleNeck, [3,4,23,3])\n    ","6372f356":"class BottleNeck(nn.Module):\n    expansion = 4\n    Cardinality = 32 # group \uc218\n    Basewidth = 64 # bottleneck \ucc44\ub110\uc774 64\uc774\uba74 group convolution\uc758 \ucc44\ub110\uc740 depth\uac00 \ub429\ub2c8\ub2e4.\n    Depth = 4 # basewidth\uc77c \ub54c, group convolution\uc758 \ucc44\ub110 \uc218\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        C = BottleNeck.Cardinality\n        D = int(BottleNeck.Depth * out_channels \/ BottleNeck.Basewidth)\n\n        self.conv_residual = nn.Sequential(\n            nn.Conv2d(in_channels, C * D, 1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(C*D),\n            nn.ReLU(),\n            nn.Conv2d(C*D, C*D, 3, stride=stride, padding=1, groups=BottleNeck.Cardinality, bias=False),\n            nn.BatchNorm2d(C*D),\n            nn.ReLU(),\n            nn.Conv2d(C*D, out_channels * BottleNeck.expansion, 1, stride=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n        )\n\n        self.conv_shortcut = nn.Sequential()\n\n        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n            self.conv_shortcut = nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, 1, stride=stride, padding=0)\n\n    def forward(self, x):\n        x = self.conv_residual(x) + self.conv_shortcut(x)\n        return x\n\n\n# ResNext\nclass ResNext(nn.Module):\n    def __init__(self, nblocks, num_classes=10, init_weights=True):\n        super().__init__()\n        self.init_weights=init_weights\n        self.in_channels = 64\n\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, 7, stride=2, padding=2, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2, padding=1)\n        )\n\n        self.conv2 = self._make_res_block(nblocks[0], 64, 1)\n        self.conv3 = self._make_res_block(nblocks[1], 128, 2)\n        self.conv4 = self._make_res_block(nblocks[2], 256, 2)\n        self.conv5 = self._make_res_block(nblocks[3], 512, 2)\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n        self.linear = nn.Linear(512 * BottleNeck.expansion, num_classes)\n\n        # weights initialization\n        if self.init_weights:\n            self._initialize_weights()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.avg_pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x\n\n    def _make_res_block(self, nblock, out_channels, stride):\n        strides = [stride] + [1] * (nblock-1)\n        res_block = nn.Sequential()\n        for i, stride in enumerate(strides):\n            res_block.add_module('dens_layer_{}'.format(i), BottleNeck(self.in_channels, out_channels, stride))\n            self.in_channels = out_channels * BottleNeck.expansion\n        return res_block\n\n    # weights initialization function\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n\ndef ResNext50():\n    return ResNext([3, 4, 6, 3])","ddb31856":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n## ======= SELECT MODEL =========\n# model = ResNet50().to(device)\nmodel = ResNext50().to(device)\n## ==============================\n\nx = torch.randn(3, 3, 224, 224).to(device)\noutput = model(x)\nprint(output.size())\n\nsummary(model, (3, 224, 224), device=device.type)","4a9c60db":"loss_func = nn.CrossEntropyLoss(reduction='sum')\nopt = optim.Adam(model.parameters(), lr=0.001)\n\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nlr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)","63dcfc99":"# function to get current lr\ndef get_lr(opt):\n    for param_group in opt.param_groups:\n        return param_group['lr']\n\n# function to calculate metric per mini-batch\ndef metric_batch(output, target):\n    pred = output.argmax(1, keepdim=True)\n    corrects = pred.eq(target.view_as(pred)).sum().item()\n    return corrects\n\n\n# function to calculate loss per mini-batch\ndef loss_batch(loss_func, output, target, opt=None):\n    loss = loss_func(output, target)\n    metric_b = metric_batch(output, target)\n\n    if opt is not None:\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n    return loss.item(), metric_b\n\n# function to calculate loss and metric per epoch\ndef loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n    running_loss = 0.0\n    running_metric = 0.0\n    len_data = len(dataset_dl.dataset)\n\n    for xb, yb in tqdm.notebook.tqdm(dataset_dl):\n        xb = xb.to(device)\n        yb = yb.to(device)\n        output = model(xb)\n\n        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n\n        running_loss += loss_b\n        \n        if metric_b is not None:\n            running_metric += metric_b\n        \n        if sanity_check is True:\n            break\n\n    loss = running_loss \/ len_data\n    metric = running_metric \/ len_data\n\n    return loss, metric","8ad6460b":"# function to start training\ndef train_val(model, params):\n    num_epochs=params['num_epochs']\n    loss_func=params[\"loss_func\"]\n    opt=params[\"optimizer\"]\n    train_dl=params[\"train_dl\"]\n    val_dl=params[\"val_dl\"]\n    sanity_check=params[\"sanity_check\"]\n    lr_scheduler=params[\"lr_scheduler\"]\n    path2weights=params[\"path2weights\"]\n\n    loss_history = {'train': [], 'val': []}\n    metric_history = {'train': [], 'val': []}\n\n    # # GPU out of memoty error\n    # best_model_wts = copy.deepcopy(model.state_dict())\n\n    best_loss = float('inf')\n\n    start_time = time.time()\n\n    for epoch in tqdm.notebook.tqdm(range(num_epochs)):\n        current_lr = get_lr(opt)\n        print('Epoch {}\/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n\n        model.train()\n        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n        loss_history['train'].append(train_loss)\n        metric_history['train'].append(train_metric)\n\n        model.eval()\n        with torch.no_grad():\n            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n        loss_history['val'].append(val_loss)\n        metric_history['val'].append(val_metric)\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            # best_model_wts = copy.deepcopy(model.state_dict())\n\n            # torch.save(model.state_dict(), path2weights)\n            # print('Copied best model weights!')\n            print('Get best val_loss')\n\n        lr_scheduler.step(val_loss)\n\n        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)\/60))\n        print('-'*10)\n\n    # model.load_state_dict(best_model_wts)\n\n    return model, loss_history, metric_history","ac1249ad":"# define the training parameters\nparams_train = {\n    'num_epochs':2,\n    'optimizer':opt,\n    'loss_func':loss_func,\n    'train_dl':train_dl,\n    'val_dl':val_dl,\n    'sanity_check':False,\n    'lr_scheduler':lr_scheduler,\n    'path2weights':'.\/models\/weights.pt',\n}\n\n# create the directory that stores weights.pt\ndef createFolder(directory):\n    try:\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n    except OSerror:\n        print('Error')\ncreateFolder('.\/models')","5e4c09f0":"model, loss_hist, metric_hist = train_val(model, params_train)","33ac3bb0":"# Train-Validation Progress\nnum_epochs=params_train[\"num_epochs\"]\n\n# plot loss progress\nplt.title(\"Train-Val Loss\")\nplt.plot(range(1,num_epochs+1),loss_hist[\"train\"],label=\"train\")\nplt.plot(range(1,num_epochs+1),loss_hist[\"val\"],label=\"val\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Training Epochs\")\nplt.legend()\nplt.show()\n\n# plot accuracy progress\nplt.title(\"Train-Val Accuracy\")\nplt.plot(range(1,num_epochs+1),metric_hist[\"train\"],label=\"train\")\nplt.plot(range(1,num_epochs+1),metric_hist[\"val\"],label=\"val\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Training Epochs\")\nplt.legend()\nplt.show()","f53c6296":"> ---\n> ### 3-2. ResNeXt","6004d921":"---\n# 5. Execute Train","2609153b":"---\n# 6. Visualize Train Result","e090b709":"> ---\n> ### 4-3. Train Function","85d6c663":"> ---\n> ### 4-4. Parameters","fa4fec79":"> ---\n> ### 3-1. ResNet","603ef7f7":"---\n# 3. Model Structure","e3af1bbe":"---\n# 2. Load Dataset","b5774924":"---\n# 4. Train","5acd212d":"> ---\n> ### 3-3. Load Model","1765a2fe":"> ---\n> ### 2-1. Download Dataset & check sample","091591c5":"> ---\n> ### 2-2. Image Explore (mean, std)","9125c662":"# Contents\n - [1. Import Packages](#1.-Import-Packages)\n - [2. Load Datasets](#2.-Load-Datasets)\n   - [2-1. Download Dataset & check sample](#2-1.-Download-Dataset-&-check-sample)\n   - [2-2. Image Explore (mean, std)](#2-2.-Image-Explore-(mean,-std))\n   - [2-3. Define Transforms & DataLoader](#2-3.-Define-Transforms-&-DataLoader)\n - [3. Model Structure](#3.-Model-Structure)\n   - [3-1. ResNet](#3-1.-ResNet)\n   - [3-2. ResNeXt](#3-2.-ResNeXt)\n   - [3-3. Load Model](#3-3.-Load-Model)\n - [4. Train](#4.-Train)\n   - [4-1. Loss & Optimizer & Learning rate](#4-1.-Loss-&-Optimizer-&-Learning-rate)\n   - [4-2. Additional Function](#4-2.-Additional-Function)\n   - [4-3. Train Function](#4-3.-Train-Function)\n   - [4-4. Parameters](#4-4.-Parameters)\n - [5. Execute Train](#5.-Execute-Train)\n - [6. Visualize Train Result](#6.-Visualize-Train-Result)","a1be20ba":"> ---\n> ### 4-2. Additional Function","e960cc2f":"> ---\n> ### 4-1. Loss & Optimizer & Learning rate","da66e4a5":"---\n# 1. Import Packages","f8d806c0":"> ---\n> ### 2-3. Define Transforms & DataLoader","2f6e4c56":"![image.png](attachment:12167507-1112-47bf-b851-cf629046007a.png)\n![image.png](attachment:940f0dac-a0cc-41e8-810d-0a41309b5f88.png)\n![image.png](attachment:f6c44b28-b9d3-4c60-b5fd-1da29d90253f.png)"}}