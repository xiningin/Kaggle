{"cell_type":{"ccdf775b":"code","629d074f":"code","aa1e818a":"code","b4a35642":"code","351e6e00":"code","6fd9560a":"code","ebefde2f":"code","fa0ee35f":"code","b959344d":"code","2e4775ea":"code","dd3ed5e3":"code","0b24c8cd":"code","b52a6296":"code","538af197":"code","930db393":"code","e93a6e87":"code","191ebc1f":"markdown","c98df3a1":"markdown","34323682":"markdown","37cccaec":"markdown","17ba84a4":"markdown","f3628b67":"markdown","959e3344":"markdown","1f84001b":"markdown","2cb43849":"markdown","3a0b9e86":"markdown","111c128c":"markdown","2593533e":"markdown"},"source":{"ccdf775b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport torch\nimport numpy as np\nimport cupy as cp\n\nfrom torchvision import transforms\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","629d074f":"! pip install \"..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\/\"","aa1e818a":"from efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_name('efficientnet-b0')\nmodel.load_state_dict(torch.load(\"..\/input\/efficientnet-pytorch\/efficientnet-b0-08094119.pth\"))\nmodel = model.eval()","b4a35642":"from torch.utils.data import Dataset, DataLoader\nclass ShopeeDataset(Dataset):\n    def __init__(self, anotation, transforms):\n        self.anotation = anotation\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.anotation)\n    \n    def __getitem__(self, idx):\n        \n        post_id, img_id = self.anotation.loc[idx,['posting_id','image']].values\n        img_path = \"..\/input\/shopee-product-matching\/train_images\/\"+img_id\n        img = Image.open(img_path)\n        img = self.transforms(img)\n        return img, post_id","351e6e00":"train = pd.read_csv('\/kaggle\/input\/shopee-product-matching\/train.csv')\n### I only use 20% data to demo this method\ntrain = train[:int(len(train)*0.2)] ","6fd9560a":"tfms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n\ndata = ShopeeDataset(anotation = train, transforms=tfms)\n\nbatch_size=64\ndata_loader = DataLoader(dataset=data, batch_size=batch_size, shuffle=False)","ebefde2f":"device = torch.device(\"cuda\")\nmodel = model.to(device)","fa0ee35f":"data_feature = np.zeros((len(train),1280))\npost_id_list = []\nfor i, (x_input, post_input) in enumerate(tqdm(data_loader)):\n    features = model.extract_features(x_input.to(device))\n    feature_vec = torch.nn.AdaptiveAvgPool2d(1)(features).cpu().view(-1,1280).detach().numpy()\n    data_feature[i * batch_size:(i+1) * batch_size] = feature_vec\n    post_id_list += post_input\n    del x_input, post_input, features","b959344d":"feature_data = pd.DataFrame({\"post_id\":post_id_list,\"feature\":data_feature.tolist()})","2e4775ea":"feature_data.head()","dd3ed5e3":"post_id_sub_list = []\nmatch_id_list = []\nfor i in tqdm(range(len(feature_data))):\n\n    post_id, fea_id = feature_data.loc[i,['post_id','feature']].values\n    #match_temp_id = \"\"\n    #score_np = np.linalg.norm(data_feature - fea_id, ord=2, axis=1.)\n    #score_np = np.dot(fea_id, data_feature.T)\n    score_np = cp.sum((data_feature-fea_id)**2,axis = 1)\n    idx_relate = np.where(score_np<30)\n    \n    temp_str = \" \".join(np.array(post_id_list)[idx_relate[0]].tolist())\n    \n    post_id_sub_list.append(post_id)\n    match_id_list.append(temp_str)","0b24c8cd":"submission1 = pd.DataFrame()\nsubmission1['posting_id'] = post_id_sub_list\nsubmission1['matches'] = match_id_list","b52a6296":"submission1.head()","538af197":"submission1.head()","930db393":"def plot_image_list(img_list, post_id, match_list):\n    \"\"\" Function to display row of image slices \"\"\"\n    fig, axes = plt.subplots(1, len(img_list),figsize=(len(img_list)*5, 5))\n    fig.suptitle('Query Image = [{}], Match Image = [{}]'.format(post_id, \",\".join(match_list)), fontsize=16)\n    for i, img in enumerate(img_list):\n        axes[i].imshow(img)","e93a6e87":"import matplotlib.pyplot as plt\ntrain_path = \"..\/input\/shopee-product-matching\/train_images\/\"\nhave_relate_img = submission1[submission1['posting_id']!=submission1['matches']].reset_index(drop=True)\nfor i in np.random.choice(len(have_relate_img), 20):\n    query_id, match_id = have_relate_img.loc[i,['posting_id','matches']].values\n    match_list = match_id.split(\" \")\n    plt_array=[]\n    for j in match_list:\n        img_name = train[train['posting_id']==j]['image'].values[0]\n        img_path = train_path+img_name\n        img = Image.open(img_path)\n        plt_array.append(img)\n    plot_image_list(plt_array, query_id, match_list)","191ebc1f":"### Define image featrue extract Dataset","c98df3a1":"### Load train files","34323682":"### Install EfficientNet Pytorch offline\n* https:\/\/www.kaggle.com\/hmendonca\/efficientnet-pytorch","37cccaec":"## This is the simple method of feature relation\n### Status update: This method can get LB 0.6 up, if you solve the GPU timeout issue and find the great threshold of distance\n![image.png](attachment:image.png)image reference : https:\/\/github.com\/pochih\/CBIR\n* I use the 20% training data to demo this method \n* Using pre-trained Efficient-B0 model to be feature extractor\n* Extract all image features and using euclidean distance to find the similarity image\n* P.S this notebook can't commit the result, in this competition, GPU limit only 2 hours, if you submit this notebook, it will exceed the time limit","17ba84a4":"### Plot the image to check the model result\n* Let's plot 10 related image to check the model performance","f3628b67":"### Conclusion\n* We need to extract all test image features, so submit need large time to extract\n* This notebook can't submit the test result, because there are about 70000 test image, submit time will exceed the limit (2Hours)\n* This method can get LB 0.6 up, if you solve the GPU timeout issue and find the great threshold of distance (my current score)","959e3344":"### Find the feature distance between base image and related image\n* Using simple euclidean distance\n* Set the distance lower than 14 (you can define by yourself and find the best threshold by CV calculate)","1f84001b":"* We only use 20% training data, if we use full training data, we can find more relate image.","2cb43849":"### Efficient relate result","3a0b9e86":"### Load efficientnet b0 pretrained model by imageNet","111c128c":"### Next step\n* Solve the time limit (using some algorithm to reduce inference time)\n* Using training set to re-train the better feature extractor","2593533e":"### Extract all test image feature\n* First we extract all image feature by pre-train efficient-b0 as our retrival database\n* Set the base image then find the distance to all the image in database"}}