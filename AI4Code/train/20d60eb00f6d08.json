{"cell_type":{"7d57c4e2":"code","22c9c5b1":"code","6dccc5d3":"code","66ac65b9":"code","70057a2d":"code","ace7fceb":"code","f2cfeae8":"code","68097443":"code","a828cc4d":"code","fbaaa30e":"code","6ba22a67":"code","8c3491fb":"code","3b1ac3b4":"code","1c4ce0e5":"code","65c2cbb7":"code","e2bb879c":"markdown","6027773c":"markdown","76b96e95":"markdown","eb6d7b6d":"markdown","178b5b08":"markdown","7c30313b":"markdown","9eefa496":"markdown","3d9cefe1":"markdown"},"source":{"7d57c4e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nprint('Files in this dataset:')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","22c9c5b1":"! pip install dl-cliche torchsummary pytorch-lightning","6dccc5d3":"# public modules\nfrom dlcliche.notebook import *\nfrom dlcliche.utils import (\n    sys, random, Path, np, plt, EasyDict,\n    ensure_folder, deterministic_everything,\n)\nfrom argparse import Namespace\n\n########################################################################\n# setup STD I\/O\n########################################################################\n\"\"\"\nStandard output is logged in \"baseline.log\".\n\"\"\"\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG, filename=\"baseline.log\")\nlogger = logging.getLogger(' ')\nhandler = logging.StreamHandler()\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nhandler.setFormatter(formatter)\nlogger.addHandler(handler)","66ac65b9":"# https:\/\/github.com\/daisukelab\/dcase2020_task2_variants\/blob\/master\/pytorch_common.py\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchsummary\nimport torch\nimport pytorch_lightning as pl\nimport random\nfrom dlcliche.utils import *\n\n\ndef load_weights(model, weight_file):\n    model.load_state_dict(torch.load(weight_file))\n\n\ndef summary(device, model, input_size=(1, 640)):\n    torchsummary.summary(model.to(device), input_size=input_size)\n\n\ndef summarize_weights(model):\n    summary = pd.DataFrame()\n    for k, p in model.state_dict().items():\n        p = p.cpu().numpy()\n        df = pd.Series(p.ravel()).describe()\n        summary.loc[k, 'mean'] = df['mean']\n        summary.loc[k, 'std'] = df['std']\n        summary.loc[k, 'min'] = df['min']\n        summary.loc[k, 'max'] = df['max']\n    return summary\n\n\ndef show_some_predictions(dl, model, start_index, n_samples, image=False):\n    shape = (-1, 64, 64) if image else (-1, 640)\n    x, y = next(iter(dl))\n    with torch.no_grad():\n        yhat = model(x)\n    x = x.cpu().numpy().reshape(shape)\n    yhat = yhat.cpu().numpy().reshape(shape)\n    print(x.shape, yhat.shape)\n    for sample_idx in range(start_index, start_index + n_samples):\n        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n        if image:\n            axs[0].imshow(x[sample_idx])\n            axs[1].imshow(yhat[sample_idx])\n        else:\n            axs[0].plot(x[sample_idx])\n            axs[1].plot(yhat[sample_idx])\n\n\ndef normalize_0to1(X):\n    # Normalize to range from [-90, 24] to [0, 1] based on dataset quick stat check.\n    X = (X + 90.) \/ (24. + 90.)\n    X = np.clip(X, 0., 1.)\n    return X\n\n\nclass ToTensor1ch(object):\n    \"\"\"PyTorch basic transform to convert np array to torch.Tensor.\n    Args:\n        array: (dim,) or (batch, dims) feature array.\n    \"\"\"\n    def __init__(self, device=None, image=False):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.non_batch_shape_len = 2 if image else 1\n\n    def __call__(self, array):\n        # (dims)\n        if len(array.shape) == self.non_batch_shape_len:\n            return torch.Tensor(array).unsqueeze(0).to(self.device)\n        # (batch, dims)\n        return torch.Tensor(array).unsqueeze(1).to(self.device)\n\n    def __repr__(self):\n        return 'to_tensor_1d'\n\n\n########################################################################\n# PyTorch utilities\n########################################################################\n\nclass Task2Dataset(torch.utils.data.Dataset):\n    \"\"\"PyTorch dataset class for task2. Caching to a file supported.\n    Args:\n        n_mels, frames, n_fft, hop_length, power, transform: Audio conversion settings.\n        normalize: Normalize data value range from [-90, 24] to [0, 1] for VAE, False by default.\n        cache_to: Cache filename or None by default, use this for your iterative development.\n    \"\"\"\n\n    def __init__(self, files, n_mels, frames, n_fft, hop_length, power, transform,\n                 normalize=False, cache_to=None):\n        self.transform = transform\n        self.files = files\n        self.n_mels, self.frames, self.n_fft = n_mels, frames, n_fft\n        self.hop_length, self.power = hop_length, power\n        # load cache or convert all the data for the first time\n        if cache_to is not None and Path(cache_to).exists():\n            logger.info(f'Loading cached {Path(cache_to).name}')\n            self.X = np.load(cache_to)\n        else:\n            self.X = com.list_to_vector_array(self.files,\n                             n_mels=self.n_mels,\n                             frames=self.frames,\n                             n_fft=self.n_fft,\n                             hop_length=self.hop_length,\n                             power=self.power)\n            if cache_to is not None:\n                np.save(cache_to, self.X)\n\n        if normalize:\n            self.X = normalize_0to1(self.X)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, index):\n        x = self.X[index]\n        x = self.transform(x)\n        return x, x\n\n\nclass Task2Lightning(pl.LightningModule):\n    \"\"\"Task2 PyTorch Lightning class, for training only.\"\"\"\n\n    def __init__(self, device, model, params, files, normalize=False):\n        super().__init__()\n        self.device = device\n        self.params = params\n        self.normalize = normalize\n        self.model = model\n        self.mseloss = torch.nn.MSELoss()\n        # split data files\n        if files is not None:\n            n_val = int(params.fit.validation_split * len(files))\n            self.val_files = random.sample(files, n_val)\n            self.train_files = [f for f in files if f not in self.val_files]\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.forward(x)\n        loss = self.mseloss(y_hat, y)\n        tensorboard_logs = {'train_loss': loss}\n        return {'loss': loss, 'log': tensorboard_logs}\n\n    def validation_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.forward(x)\n        return {'val_loss': self.mseloss(y_hat, y)}\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        tensorboard_logs = {'val_loss': avg_loss}\n        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.params.fit.lr,\n                                betas=(self.params.fit.b1, self.params.fit.b2),\n                                weight_decay=self.params.fit.weight_decay)\n\n    def _get_dl(self, for_what):\n        files = self.train_files if for_what == 'train' else self.val_files\n        cache_file = f'{self.params.model_directory}\/__cache_{str(files[0]).split(\"\/\")[-3]}_{for_what}.npy'\n        ds = Task2Dataset(files,\n                          n_mels=self.params.feature.n_mels,\n                          frames=self.params.feature.frames,\n                          n_fft=self.params.feature.n_fft,\n                          hop_length=self.params.feature.hop_length,\n                          power=self.params.feature.power,\n                          transform=com.ToTensor1ch(device=self.device),\n                          normalize=self.normalize,\n                          cache_to=cache_file)\n        return torch.utils.data.DataLoader(ds, batch_size=self.params.fit.batch_size,\n                          shuffle=(self.params.fit.shuffle if for_what == 'train' else False))\n\n    def train_dataloader(self):\n        return self._get_dl('train')\n\n    def val_dataloader(self):\n        return self._get_dl('val')","70057a2d":"# https:\/\/github.com\/daisukelab\/dcase2020_task2_variants\/blob\/master\/image_common.py\n\nimport librosa\n\n\ndef get_log_mel_spectrogram(filename,\n                            n_mels=64,\n                            n_fft=1024,\n                            hop_length=512,\n                            power=2.0):\n    wav, sampling_rate = com.file_load(filename)\n    mel_spectrogram = librosa.feature.melspectrogram(y=wav,\n                                                     sr=sampling_rate,\n                                                     n_fft=n_fft,\n                                                     hop_length=hop_length,\n                                                     n_mels=n_mels,\n                                                     power=power)\n    log_mel_spectrogram = 20.0 \/ power * np.log10(mel_spectrogram + sys.float_info.epsilon)\n    return log_mel_spectrogram\n\n\ndef file_to_vector_array_2d(file_name,\n                         n_mels=64,\n                         steps=20,\n                         n_fft=1024,\n                         hop_length=512,\n                         power=2.0):\n    \"\"\"convert file_name to a 2d vector array.\n\n    file_name : str\n        target .wav file\n    return : np.array( np.array( float ) )\n        vector array\n        * dataset.shape = (dataset_size, n_mels, n_mels)\n    \"\"\"\n    # 02 generate melspectrogram using librosa\n    y, sr = com.file_load(file_name)\n    mel_spectrogram = librosa.feature.melspectrogram(y=y,\n                                                     sr=sr,\n                                                     n_fft=n_fft,\n                                                     hop_length=hop_length,\n                                                     n_mels=n_mels,\n                                                     power=power)\n\n    # 03 convert melspectrogram to log mel energy\n    log_mel_spectrogram = 20.0 \/ power * np.log10(mel_spectrogram + sys.float_info.epsilon)\n\n    # 04 calculate total vector size\n    vector_array_size = (log_mel_spectrogram.shape[1] - n_mels + 1) \/\/ steps\n\n    # 06 generate feature vectors by concatenating multiframes\n    vector_array = np.zeros((vector_array_size, n_mels, n_mels))\n    for t in range(vector_array_size):\n        vector_array[t] = log_mel_spectrogram[:, t*steps:t*steps+n_mels]\n\n    return vector_array\n\n\nclass Task2ImageDataset(torch.utils.data.Dataset):\n    \"\"\"Task 2 dataset to handle samples as 1 channel image.\n\n    Unlike other dataset, set `preprocessed_file` as preprocessed dataset filename.\n    For every output, this dataset class crop square image from this original data.\n\n    Number of total samples is `n_sampling` times number of _live data_.\n    _Live data_ is all the original data by default, and filtered by splitting functions.\n\n    - For training use, set `random=True`. This will yield randomly cropped square\n      image (64x64 for example) from the original sample (64x431 for 10s sample).\n    - For validation use, set `random=False`. Image will be cropped from fixed position.\n\n    Augmentation can be flexibly applied to either the output `x` only or `y` only, or both `x` and `y`.\n    `aug_x` and `aug_y` control this behavor.\n\n    Data split for training\/validation can be done by using:\n        `get_index_by_pct()`: generate list of training index.\n        `train_split(train_index)`: set live data as original samples listed on `train_index`.\n        `val_split(train_index)`: set live data as original samples NOT listed on `train_index`.\n    Yields:\n        x: square image expected to be used as source.\n        y: square image expected to be used as reference for evaluating reconstructed image by training model.\n    \"\"\"\n\n    def __init__(self, preprocessed_file, n_sampling=10, transform=None, augment_tfm=None,\n                 normalize=True, random=True, aug_x=True, aug_y=False, debug=False):\n        self.n_sampling = n_sampling\n        self.transform, self.augment_tfm = transform, augment_tfm\n        self.random, self.aug_x, self.aug_y = random, aug_x, aug_y\n\n        self.X = np.load(preprocessed_file)\n        if normalize:\n            self.X = normalize_0to1(self.X)\n\n        if debug:\n            from dlcliche.utils import display\n            from dlcliche.math import np_describe\n            display(np_describe(self.X[0].cpu().numpy()))\n\n        self.orgX = self.X\n  \n    def get_index_by_pct(self, split_pct=0.1):\n        n = len(self.orgX)\n        return random.sample(range(n), k=(n - int(n * split_pct)))\n\n    def train_split(self, train_index):\n        self.train_index = train_index\n        self.X = self.orgX[train_index]\n    \n    def val_split(self, train_index):\n        n = len(self.orgX)\n        self.val_index = [i for i in range(n) if i not in train_index]\n        self.X = self.orgX[self.val_index]\n\n    def __len__(self):\n        return len(self.X) * self.n_sampling\n\n    def __getitem__(self, index):\n        file_index = index \/\/ self.n_sampling\n        part_index = index % self.n_sampling\n        x = self.X[file_index]\n        dim, length = x.shape\n\n        # crop square part of sample\n        if self.random:\n            # random crop\n            start = random.randint(0, length - dim)\n        else:\n            # crop with fixed position\n            start = (length \/\/ self.n_sampling) * part_index\n        start = min(start, length - dim)\n        x = x[:, start:start+dim]\n\n        # augmentation transform\n        y = x\n        if self.augment_tfm is not None:\n            tfm_x = self.augment_tfm(x)\n            if self.aug_x: x = tfm_x\n            if self.aug_y: y = tfm_x\n\n        # transform (convert to tensor here)\n        if self.transform is not None:\n            x = self.transform(x)\n            y = self.transform(y)\n        return x, y","ace7fceb":"config_yaml = '''\ndev_directory : \/kaggle\/input\/dc2020task2prep\neval_directory : \/kaggle\/input\/dc2020task2prep\nmodel_directory: .\/model\nresult_directory: .\/result\nresult_file: result.csv\n# target: ['ToyConveyor']  #  set this when you want to test for specific target only.\n\nmax_fpr : 0.1\n\nfeature:\n  n_mels: 64\n  frames : 5\n  n_fft: 1024\n  hop_length: 512\n  power: 2.0\n\nfit:\n  lr: 0.001\n  b1: 0.9\n  b2: 0.999\n  weight_decay: 0.0\n  epochs : 100\n  batch_size : 256\n  shuffle : True\n  validation_split : 0.1\n  verbose : 1\n'''\n\nimport yaml\nfrom easydict import EasyDict\nparams = EasyDict(yaml.safe_load(config_yaml))\n\nparams","f2cfeae8":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchsummary\nimport torch\nimport pytorch_lightning as pl\nimport random\n\n\nclass CNNAutoEncoder(nn.Module):\n    \"\"\"\n    Thanks to http:\/\/dl-kento.hatenablog.com\/entry\/2018\/02\/22\/200811#Convolutional-AutoEncoder\n    \"\"\"\n\n    def  __init__(self, z_dim=40):\n        super().__init__()\n\n        # define the network\n        # encoder\n        self.conv1 = nn.Sequential(nn.ZeroPad2d((1,2,1,2)),\n                              nn.Conv2d(1, 32, kernel_size=5, stride=2),\n                              nn.ReLU())\n        self.conv2 = nn.Sequential(nn.ZeroPad2d((1,2,1,2)),\n                              nn.Conv2d(32, 64, kernel_size=5, stride=2),\n                              nn.ReLU(), nn.Dropout(0.2))\n        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0),\n                              nn.ReLU(), nn.Dropout(0.3))\n        self.conv4 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0),\n                              nn.ReLU(), nn.Dropout(0.3))\n        self.fc1 = nn.Conv2d(256, z_dim, kernel_size=3)\n\n        # decoder\n        self.fc2 = nn.Sequential(nn.ConvTranspose2d(z_dim, 256, kernel_size=3),\n                            nn.ReLU(), nn.Dropout(0.3))\n        self.conv4d = nn.Sequential(nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=0),\n                               nn.ReLU(), nn.Dropout(0.3))\n        self.conv3d = nn.Sequential(nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=0),\n                               nn.ReLU(), nn.Dropout(0.2))\n        self.conv2d = nn.Sequential(nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2),\n                               nn.ReLU())\n        self.conv1d = nn.ConvTranspose2d(32, 1, kernel_size=5, stride=2)\n\n    def forward(self, x):\n        encoded = self.fc1(self.conv4(self.conv3(self.conv2(self.conv1(x)))))\n\n        decoded = self.fc2(encoded)\n        decoded = self.conv4d(decoded)\n        decoded = self.conv3d(decoded)\n        decoded = self.conv2d(decoded)[:,:,1:-1,1:-1]\n        decoded = self.conv1d(decoded)[:,:,0:-1,0:-1]\n        decoded = nn.Sigmoid()(decoded)\n\n        return decoded","68097443":"# create working directory\nensure_folder(params.model_directory)\n\n# test targets\nif 'target' in params:\n    types = params.target\nelse:\n    types = sorted(set([d.name.split('-')[1] for d in Path(params.dev_directory).glob('*.npy')]))\n\n# dataset\ndata_files = sorted(Path(params.dev_directory).glob('dc2020t2l1*.npy'))\ndata = {t:[f for f in data_files if t in str(f)] for t in types}\n\n# fix random seeds\ndeterministic_everything(2020, pytorch=True)\n\n# PyTorch device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndata, types","a828cc4d":"# This will show you visualization examples of the dataset when augmentation is applied\nif False: # test dataset\n    from albumentations import (\n        HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, RandomCrop,\n        Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n        IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n        IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose,\n        ISONoise, Cutout\n    )\n\n    class MyTfm():\n        def __init__(self):\n            self.album_tfm = Compose([\n                Cutout(num_holes=8, max_h_size=6, max_w_size=6, p=0.6),\n                ShiftScaleRotate(shift_limit=0.3, scale_limit=0.1, rotate_limit=0, p=.5),\n            ], p=1)\n        def __call__(self, x):        \n            data = {\"image\": x}\n            augmented = self.album_tfm(**data)\n            x = augmented[\"image\"]\n            return x\n\n    trn_ds = Task2ImageDataset(data[types[0]][1], augment_tfm=MyTfm(), aug_y=True, random=True)\n    train_index = trn_ds.get_index_by_pct()\n    trn_ds.train_split(train_index)\n    fig, ax = plt.subplots(1, 2)\n    one = trn_ds[0]; ax[0].imshow(one[0]); ax[1].imshow(one[1]);","fbaaa30e":"class Task2ImageLightning(Task2Lightning):\n    \"\"\"Task2 PyTorch Lightning class, for training only.\"\"\"\n\n    def __init__(self, device, model, params, preprocessed_file, normalize=True):\n        super().__init__(device, model, params, files=None, normalize=normalize)\n        self.device = device\n        self.params = params\n        self.normalize = normalize\n        self.model = model\n        self.mseloss = torch.nn.MSELoss()\n\n        to_tensor = ToTensor1ch(device=self.device, image=True)\n        self.trn_ds = Task2ImageDataset(preprocessed_file, transform=to_tensor,\n                                      normalize=normalize)\n        self.val_ds = Task2ImageDataset(preprocessed_file, transform=to_tensor,\n                                      normalize=normalize, random=False)\n        train_index = self.trn_ds.get_index_by_pct()\n        self.trn_ds.train_split(train_index)\n        self.val_ds.val_split(train_index)\n\n    def _get_dl(self, for_what):\n        ds = self.trn_ds if for_what == 'train' else self.val_ds\n        return torch.utils.data.DataLoader(ds, batch_size=self.params.fit.batch_size,\n                          shuffle=(self.params.fit.shuffle if for_what == 'train' else False))\n\n\n# train models\n\nfor target in types:\n    print(f'==== Start training [{target}] with {torch.cuda.device_count()} GPU(s). ====')\n\n    try:\n        del model, task2, trainer\n    except:\n        pass # first time, nothing to delete\n    model = CNNAutoEncoder().to(device)\n    task2 = Task2ImageLightning(device, model, params, preprocessed_file=data[target][1])\n    summary(device, model, input_size=task2.train_dataloader().dataset[0][0].shape)\n    trainer = pl.Trainer(max_epochs=params.fit.epochs, gpus=torch.cuda.device_count())\n    trainer.fit(task2)\n\n    model_file = f'{params.model_directory}\/model_{target}.pth'\n    torch.save(task2.model.state_dict(), model_file)\n    print(f'saved {model_file}.\\n')","6ba22a67":"show_some_predictions(task2.train_dataloader(), task2.model, 0, 3, image=True)","8c3491fb":"show_some_predictions(task2.val_dataloader(), task2.model, 0, 3, image=True)","3b1ac3b4":"# Getting test file information in a data frame\n\n! wget https:\/\/raw.githubusercontent.com\/daisukelab\/dcase2020_task2_variants\/master\/file_info.csv\n\ndf = pd.read_csv('file_info.csv')\ndf.file = df.file.map(lambda f: str(f).replace('\/data\/task2\/dev', '\/kaggle\/input\/dc2020task2'))\ndf['id'] = df.file.map(lambda f: '_'.join(f.split('_')[1:3]))\ndf['class'] = df.file.map(lambda f: f.split('_')[0].split('\/')[-1])\ntypes = df.type.unique()","1c4ce0e5":"import glob\nimport re\nimport csv\nimport itertools\nfrom tqdm import tqdm\nfrom sklearn import metrics\n\n\ndeterministic_everything(2022, pytorch=True)\n\n\ndef save_csv(save_file_path,\n             save_data):\n    with open(save_file_path, \"w\", newline=\"\") as f:\n        writer = csv.writer(f, lineterminator='\\n')\n        writer.writerows(save_data)\n\n\nclass Task2ImageDatasetForTest(Task2ImageDataset):\n    def get_test_batch_x(self, file_index, n_mels=params.feature.n_mels, steps=20):\n        log_mel_spectrogram = self.X[file_index]\n        vector_array_size = (log_mel_spectrogram.shape[1] - n_mels + 1) \/\/ steps\n        vector_array = np.zeros((vector_array_size, n_mels, n_mels))\n        for t in range(vector_array_size):\n            vector_array[t] = log_mel_spectrogram[:, t*steps:t*steps+n_mels]\n        return vector_array\n\n\ndef get_machine_id_list_for_test(df, target):\n    return sorted(set(df[df['type'] == target].id.values))\n\n\ndef test_file_list_generator(df,\n                             target,\n                             id_name,\n                             prefix_normal=\"normal\",\n                             prefix_anomaly=\"anomaly\"):\n    \"\"\"\n    target : str\n        target machine type\n    id_name : str\n        id of wav file in <<test_dir_name>> directory\n    prefix_normal : str (default=\"normal\")\n        normal directory name\n    prefix_anomaly : str (default=\"anomaly\")\n        anomaly directory name\n\n    return :\n        test_files : list [ str ]\n            file list for test\n        test_labels : list [ boolean ]\n            label info. list for test\n            * normal\/anomaly = 0\/1\n    \"\"\"\n    logger.info(\"target_id : {}\".format(target+\"_\"+id_name))\n    df = df[df['type'] == target][df.split == 'test'].reset_index()\n    df = df[df['id'] == id_name]\n\n    indexes = df.index.values\n    files = df.file.values\n    labels = df['class'].map(lambda c: 1 if c == prefix_anomaly else 0)\n    logger.info(\"# of test_files : {num}\".format(num=len(files)))\n    if len(files) == 0:\n        logger.exception(\"no_wav_file!!\")\n    print(\"\\n========================================\")\n\n    return indexes, files, labels\n########################################################################\n\n\n########################################################################\n# main 01_test.py\n########################################################################\ndef do_test():\n    # check mode\n    # \"development\": mode == True\n    # \"evaluation\": mode == False\n    mode =True\n\n    # make output result directory\n    os.makedirs(params.result_directory, exist_ok=True)\n\n    # initialize lines in csv for AUC and pAUC\n    csv_lines = []\n\n    # PyTorch version specific...\n    to_tensor = ToTensor1ch(image=True)\n\n    # loop of the base directory\n    for idx, machine_type in enumerate(types):\n        print(\"\\n===========================\")\n        print(f\"[{idx}\/{len(types)}] {machine_type}\")\n\n        print(\"============== MODEL LOAD ==============\")\n        # set model path\n        model_file = \"{model}\/model_{machine_type}.pth\".format(model=params.model_directory,\n                                                               machine_type=machine_type)\n\n        # load model file\n        if not os.path.exists(model_file):\n            logger.error(\"{} model not found \".format(machine_type))\n            sys.exit(-1)\n        logger.info(\"loading model: {}\".format(model_file))\n        model = CNNAutoEncoder().to(device)\n        load_weights(model, model_file)\n        summary(device, model, input_size=(1, params.feature.n_mels, params.feature.n_mels))\n        model.eval()\n\n        if mode:\n            # results by type\n            csv_lines.append([machine_type])\n            csv_lines.append([\"id\", \"AUC\", \"pAUC\"])\n            performance = []\n\n        machine_id_list = get_machine_id_list_for_test(df, machine_type)\n\n        for id_str in machine_id_list:\n            # load test file\n            indexes, test_files, y_true = test_file_list_generator(df, machine_type, id_str)\n            print(f'test preprocesssed file: {data[machine_type][0]}')\n            ds = Task2ImageDatasetForTest(data[machine_type][0], random=False, normalize=True)\n\n            # setup anomaly score file path\n            anomaly_score_csv = \"{result}\/anomaly_score_{machine_type}_{id_str}.csv\".format(\n                                                                                     result=params.result_directory,\n                                                                                     machine_type=machine_type,\n                                                                                     id_str=id_str)\n            anomaly_score_list = []\n\n            print(\"\\n============== BEGIN TEST FOR A MACHINE ID ==============\")\n            y_pred = [0. for k in test_files]\n            for batch_idx, (file_idx, file_path) in tqdm(enumerate(zip(indexes, test_files)), total=len(test_files)):\n                x = ds.get_test_batch_x(file_idx)\n                with torch.no_grad():\n                    yhat = model(to_tensor(x)).cpu().detach().numpy().reshape(x.shape)\n                    errors = np.mean(np.square(x - yhat), axis=1)\n                    if batch_idx in [0, 500]:\n                        for i in range(2):\n                            fig, axs = plt.subplots(1, 2)\n                            axs[0].imshow(x[i])\n                            axs[1].imshow(yhat[i])\n                            plt.show()\n                y_pred[batch_idx] = np.mean(errors)\n                anomaly_score_list.append([os.path.basename(file_path), y_pred[batch_idx]])\n\n            # save anomaly score\n            save_csv(save_file_path=anomaly_score_csv, save_data=anomaly_score_list)\n            logger.info(\"anomaly score result ->  {}\".format(anomaly_score_csv))\n\n            if mode:\n                # append AUC and pAUC to lists\n                auc = metrics.roc_auc_score(y_true, y_pred)\n                p_auc = metrics.roc_auc_score(y_true, y_pred, max_fpr=params.max_fpr)\n                csv_lines.append([id_str.split(\"_\", 1)[1], auc, p_auc])\n                performance.append([auc, p_auc])\n                logger.info(\"AUC : {}\".format(auc))\n                logger.info(\"pAUC : {}\".format(p_auc))\n\n            print(\"\\n============ END OF TEST FOR A MACHINE ID ============\")\n\n        if mode:\n            # calculate averages for AUCs and pAUCs\n            averaged_performance = np.mean(np.array(performance, dtype=float), axis=0)\n            csv_lines.append([\"Average\"] + list(averaged_performance))\n            csv_lines.append([])\n\n    result_path = \"{result}\/{file_name}\".format(result=params.result_directory, file_name=params.result_file)\n    logger.info(\"AUC and pAUC results -> {}\".format(result_path))\n    save_csv(save_file_path=result_path, save_data=csv_lines)\n    return csv_lines\n\ncsv_lines = do_test()","65c2cbb7":"def print_csv_lines(csv_lines):\n    for l in csv_lines:\n        print('\\t\\t'.join([(a if type(a) == str else f'{a:.6f}') for a in l]))\n        \nprint_csv_lines(csv_lines)","e2bb879c":"## Model","6027773c":"## Class and function definitions","76b96e95":"## Configurations","eb6d7b6d":"## Visualize last model's predictions","178b5b08":"## Train models for each machine types","7c30313b":"# Testing\n\nThis will output test results in `result` folder.","9eefa496":"# DCASE 2020 Task 2 Example - Convolutional Autoencoder\n\nThis notebook will show you convolutional autoencoder example using DCASE 2020 task 2 dataset.\n\n(This is a Kaggle notebook version from [github repository](https:\/\/github.com\/daisukelab\/dcase2020_task2_variants\/blob\/master\/3cnn_ae_pytorch\/00-train-with-visual.ipynb).)","3d9cefe1":"## Prepare to train"}}