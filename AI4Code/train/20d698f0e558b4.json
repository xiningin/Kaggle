{"cell_type":{"104e6d45":"code","28680116":"code","3769398d":"code","344be303":"code","7d82f5f2":"code","2708f2fd":"code","adadd215":"code","6c2864fc":"code","c5062a1c":"code","412f68d5":"code","40efbe6f":"code","ad0d78a2":"code","12b4d95f":"code","2bea37ad":"code","76e544fa":"code","2c7fb30f":"code","614f7030":"code","fac5aed5":"code","2dea11cd":"code","19c1d2c1":"code","027246bd":"code","01dadc9a":"code","e80f8721":"code","e11ae64a":"code","2766c099":"code","e54ca9e1":"code","d59c0023":"code","9913ec10":"code","8f52fefb":"code","e460b6cd":"code","b5d005ad":"code","fd09d457":"code","952aa204":"markdown","046f6a41":"markdown"},"source":{"104e6d45":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder, scale\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, auc, roc_curve, roc_auc_score\nfrom sklearn.model_selection import train_test_split","28680116":"# load the dataset\ntrain = pd.read_csv('\/kaggle\/input\/data-train-competicao-ml-1-titanic\/train.csv')\n\n# create labelencoder\nle = LabelEncoder()\n\ntrain = train.drop(['Name', 'Cabin'], axis=1).fillna(train['Age'].mean())\ncat_columns = train.select_dtypes('object').columns\ntrain[cat_columns] = train[cat_columns].apply(lambda col: le.fit_transform(col.astype(str)))\ntrain.describe()","3769398d":"# separate X and Y\nX = train.drop(['PassengerId', 'Ticket', 'Survived'], axis=1)\ny = train[['Survived']]","344be303":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)","7d82f5f2":"plt.bar(x=[0, 1], height=y.groupby('Survived').size(), color=['red', 'green'])\nplt.xticks([0, 1], ['Died', 'Survied']);","2708f2fd":"plt.hist(X['Age']);","adadd215":"# convert to DMatrix\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)","6c2864fc":"# params to tune\nparams = {\n    'max_depth': 6,\n    'min_child_weight': 1,\n    'eta': .3,\n    'subsample': 1,\n    'colsample_bytree': 1,\n    # Other parameters\n    'objective':'binary:logistic',\n}\n\nparams['eval_metric'] = 'auc'\n\nnum_boost_round = 999","c5062a1c":"model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, 'Test')],\n    early_stopping_rounds=10\n)","412f68d5":"cv_results = xgb.cv(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    seed=42,\n    nfold=5,\n    metrics={'auc'},\n    early_stopping_rounds=10\n)\n\ncv_results","40efbe6f":"cv_results['test-auc-mean'].max()","ad0d78a2":"gridsearch_params = [\n    (max_depth, min_child_weight)\n    for max_depth in range(1, 10)\n    for min_child_weight in range(1, 10)\n]","12b4d95f":"# Define initial best params\nmax_auc = float(0)\nbest_params = None\n\nfor max_depth, min_child_weight in gridsearch_params:\n    print(f'CV with max_depth = {max_depth}, min_child_weight = {min_child_weight}')   # Update our parameters\n    params['max_depth'] = max_depth\n    params['min_child_weight'] = min_child_weight \n          \n    # run CV\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        seed=42,\n        nfold=5,\n        metrics={'auc'},\n        early_stopping_rounds=10\n    )\n          \n    # update best AUC model    \n    mean_auc = cv_results['test-auc-mean'].max()\n    boost_rounds = cv_results['test-auc-mean'].argmax()\n    print(f'\\tAUC {mean_auc} for {boost_rounds} rounds')\n    if mean_auc > max_auc:\n        max_auc = mean_auc\n        best_params = (max_depth, min_child_weight)\n        print(f'Best params: {best_params[0]}, {best_params[1]}, AUC: {max_auc}')\n\nprint('\\nBest params:', best_params)","2bea37ad":"params['max_depth'], params['min_child_weight'] = best_params\nparams","76e544fa":"model2 = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, 'Test')],\n    early_stopping_rounds=10\n)","2c7fb30f":"gridsearch_params = [\n    (subsample, colsample)\n    for subsample in [0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n    for colsample in [0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n]","614f7030":"# Define initial best params\nmax_auc = float(0)\nbest_params = None\n\n# start reversed (max -> min)\nfor subsample, colsample in reversed(gridsearch_params):\n    print(f'CV with subsample = {subsample}, colsample = {colsample}')   # Update our parameters\n    params['subsample'] = subsample\n    params['colsample_bytree'] = colsample \n          \n    # run CV\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        seed=42,\n        nfold=5,\n        metrics={'auc'},\n        early_stopping_rounds=10\n    )\n          \n    # update best AUC model    \n    mean_auc = cv_results['test-auc-mean'].max()\n    boost_rounds = cv_results['test-auc-mean'].argmax()\n    print(f'\\tAUC {mean_auc} for {boost_rounds} rounds')\n    if mean_auc > max_auc:\n        max_auc = mean_auc\n        best_params = (subsample, colsample)\n        print(f'Best params: {best_params[0]}, {best_params[1]}, AUC: {max_auc}')\n\nprint('\\nBest params:', best_params)","fac5aed5":"params['subsample'], params['colsample_bytree'] = best_params\nparams","2dea11cd":"model3 = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, 'Test')],\n    early_stopping_rounds=10\n)","19c1d2c1":"max_auc = float(0)\nbest_params = None\n\n# start reversed (max -> min)\nfor eta in [.31, .309, .308, .307, .306, .305, .304, .303, .302, .301, .3, .299]:\n    print(f'CV with eta = {eta}')   # Update our parameters\n    params['eta'] = eta\n          \n    # run CV\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        seed=42,\n        nfold=5,\n        metrics={'auc'},\n        early_stopping_rounds=10\n    )\n          \n    # update best AUC model    \n    mean_auc = cv_results['test-auc-mean'].max()\n    boost_rounds = cv_results['test-auc-mean'].argmax()\n    print(f'\\tAUC {mean_auc} for {boost_rounds} rounds')\n    if mean_auc > max_auc:\n        max_auc = mean_auc\n        best_params = (eta)\n        print(f'Best params: {best_params}, AUC: {max_auc}')\n\nprint('\\nBest params:', best_params)","027246bd":"params['eta'] = best_params\nparams","01dadc9a":"model4 = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, 'Test')],\n    early_stopping_rounds=10\n)","e80f8721":"num_boost_round = model4.best_iteration + 1\n\nbest_model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, 'Test')]\n)","e11ae64a":"# predict\ny_pred = best_model.predict(dtest)\ny_pred = y_pred.reshape((y_pred.shape[0], 1))\n\nauc = roc_auc_score(y_test, y_pred)\nauc","2766c099":"params","e54ca9e1":"# load test for submission\ntest = pd.read_csv('\/kaggle\/input\/data-train-competicao-ml-1-titanic\/test.csv')","d59c0023":"plt.hist(test['Age']);","9913ec10":"# id\nid_passenger = test[['PassengerId']]\n\n# use only train features\ntest = test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\ntest['Age'] = test['Age'].fillna(test['Age'].mean())\n\ncat_columns = test.select_dtypes('object').columns\ntest[cat_columns] = test[cat_columns].apply(lambda col: LabelEncoder().fit_transform(col.astype(str)))\ntest","8f52fefb":"plt.hist(test['Age']);","e460b6cd":"# generate predictions from submit data\ndtest_submit = xgb.DMatrix(test)\npred_submit = best_model.predict(dtest_submit)\n\ndf_submit = pd.concat([id_passenger, pd.DataFrame(pred_submit, columns=['Survived'])], axis=1)\ndf_submit","b5d005ad":"plt.hist(df_submit['Survived']);","fd09d457":"# df_submit.to_csv(f'auc{auc}.csv', index=False)","952aa204":"Este notebook tamb\u00e9m pode ser visto no meu Github:    \nhttps:\/\/github.com\/igorkf\/DataTrain-DesafioTitanic\/blob\/master\/solucao_DataTrainTitanic.ipynb","046f6a41":"## Porque: Todo aquele que invocar o nome do Senhor ser\u00e1 salvo. Romanos 10:13"}}