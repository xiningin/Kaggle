{"cell_type":{"cbfb2d00":"code","b3a7c000":"code","739c65da":"code","5bfbd93a":"code","84e7a053":"code","4ff7e064":"code","8ea0b9aa":"code","3e6d579f":"code","082f476e":"code","289b6dcc":"code","526f073b":"code","e4037851":"code","6df370a1":"code","67f8daf9":"code","e83954f7":"code","123f370f":"code","d70c2db2":"code","08e18991":"code","b2845c6a":"code","5fad9a3c":"code","c48f1ed9":"code","39805657":"code","2ff19a04":"code","a2ea96ec":"code","e0612f97":"code","442680b9":"code","1edea24c":"code","42f742b7":"code","13247310":"code","f1a69361":"code","4332faab":"code","5a34cc06":"code","5079148c":"code","d7c6e72c":"code","e04e5303":"code","c4e76427":"code","e115b7ec":"code","186326de":"code","a4cb0990":"code","5abaef3f":"code","504a8d23":"code","6bda31a8":"code","fa5710b7":"code","3f744ff4":"code","56e3b1d1":"code","6c2ff136":"code","491d440b":"code","3fe64928":"code","521fb051":"code","3870c665":"code","f128f97c":"code","8f79f0be":"code","2c1253b1":"code","7222ce91":"code","33a32014":"code","10c2ab43":"code","99e984fd":"code","40953808":"code","c2ebcfee":"code","1512e94c":"code","e420888f":"code","f791eae6":"code","a5a61143":"code","c6853ff0":"code","580c4ef0":"code","ce088a83":"code","718d3c6d":"code","1dd62dfd":"code","84695e84":"code","d6a222fa":"code","e1823a78":"code","8fd2d848":"code","256be9d5":"code","354cbe18":"code","b681eac5":"code","d255f6d4":"code","c3457ec4":"markdown","dab205ba":"markdown","c8f5977e":"markdown","19cd27e7":"markdown","c11147a7":"markdown","5a66eafd":"markdown","023805d3":"markdown","5f0e205a":"markdown","d845dfa5":"markdown","71ceb72d":"markdown","73fb8dea":"markdown","b8bfb750":"markdown","ca9db3ea":"markdown","cf4059c7":"markdown","1cca29c1":"markdown","66de1146":"markdown","8ca0f841":"markdown","ce2341b9":"markdown","f0a70b8a":"markdown","9e49ddba":"markdown","4adce4b8":"markdown","445a7437":"markdown","669b64a7":"markdown","055b7daf":"markdown","b352f1f7":"markdown","e0541ef4":"markdown"},"source":{"cbfb2d00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b3a7c000":"file = open(\"\/kaggle\/input\/mnist-in-csv\/mnist_train.csv\")\ndata_train = pd.read_csv(file)\n\ny_train = np.array(data_train.iloc[:, 0])\nx_train = np.array(data_train.iloc[:, 1:])\n\nfile = open(\"\/kaggle\/input\/mnist-in-csv\/mnist_test.csv\")\ndata_test = pd.read_csv(file)\ny_test = np.array(data_test.iloc[:, 0])\nx_test = np.array(data_test.iloc[:, 1:])\n\n","739c65da":"\nsize_img = 28\nthreshold_color = 100 \/ 255\n# show n_images numbers\ndef show_img(x):\n    plt.figure(figsize=(8,7))\n    if x.shape[0] > 100:\n        print(x.shape)\n        n_imgs = 16\n        n_samples = x.shape[0]\n        x = x.reshape(n_samples, size_img, size_img)\n        for i in range(n_imgs):\n            plt.subplot(4, 4, i+1) #devide figure into 4x4 and choose i+1 to draw\n            plt.imshow(x[i])\n        plt.show()\n    else:\n        plt.imshow(x)\n        plt.show()","5bfbd93a":"show_img(x_train)","84e7a053":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=0\nprint(y_train[n])\nplt.imshow(X[n])","4ff7e064":"data= y_train\ncounts, bins = np.histogram(data)\nplt.hist(bins[:-1], bins, weights=counts)","8ea0b9aa":"data_train.head()","3e6d579f":"data= x_train\ncounts, bins = np.histogram(data)\nprint(bins)\nplt.hist(bins[:-1], bins, weights=counts)","082f476e":"x_train = np.array(data_train.iloc[:, 1:])\nx_train01=x_train\nn=200\nx_train01[x_train01<n] = 0\nx_train01[x_train01>=n] = 1\n#print(x_train01[0])\nshow_img(x_train01)\n","289b6dcc":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=0\nprint(y_train[n])\nplt.imshow(X[n])","526f073b":"x_test01=x_test\nn=200\nx_test01[x_test01<n] = 0\nx_test01[x_test01>=n] = 1\n\nX=x_test01.reshape(x_test.shape[0],28,28)\nn=0\nprint(y_test[n])\nplt.imshow(X[n])","e4037851":"print(x_train01[1:5,:])\ndata_train.head()","6df370a1":"from sklearn.decomposition import PCA\nX=x_train01\npca = PCA(n_components=10)\nX_pca = pca.fit_transform(X)\nprint(pca)\nprint('eigenvectors \\n', pca.components_)\nprint('singular values ', pca.singular_values_)\nprint('normalized cumulative sum of eigenvalues \\n', pca.explained_variance_ratio_)\n#print(' mean vector ', pca.mean_)\n\n#print('Projections of class 0 \\n ', X_pca[y_train==0])\n#print('Projections of class 1 \\n ', X_pca[y_train==1])","67f8daf9":"eig_vals=  pca.singular_values_\neig_vecs= pca.components_\n# Make a list of (eigenvalue, eigenvector) tuples\neig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n\n# Sort the (eigenvalue, eigenvector) tuples from high to low\neig_pairs.sort(key=lambda x: x[0], reverse=True)\n\n# Visually confirm that the list is correctly sorted by decreasing eigenvalues\nprint('Eigenvalues in descending order:')\nfor i in eig_pairs:\n    print(i[0])","e83954f7":"tot = sum(eig_vals)\nvar_exp = [(i \/ tot)*100 for i in sorted(eig_vals, reverse=True)]\ncum_var_exp = np.cumsum(var_exp)\nprint(cum_var_exp)","123f370f":"#matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs)\nwith plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(6, 4))\n\n    plt.bar(range(10), var_exp, alpha=0.5, align='center',\n            label='individual explained variance')\n    plt.step(range(10), cum_var_exp, where='mid',\n             label='cumulative explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layout()","d70c2db2":"print(X_pca)\nX_pca.shape","08e18991":"X=x_train01\npca = PCA(n_components=10)\nX_pca = pca.fit_transform(X)\nxtest_pca=pca.fit_transform(x_test01)","b2845c6a":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nX=x_train01\ny=y_train\nlda= LinearDiscriminantAnalysis(n_components=9)\nx_lda=lda.fit(X,y).transform(X)\n\nx_lda","5fad9a3c":"xtest_lda=lda.fit(x_train01,y).transform(x_test01)\nxtest_lda.shape","c48f1ed9":"X_train= pd.DataFrame(data=x_train)\ns=X_train.sum(axis=1)\ns=s\/784\ns","39805657":"import matplotlib.pyplot as plt\nplt.plot(y_train,s, 'o')\nplt.ylabel('ratio of ink used')\nplt.show()","2ff19a04":"X=X_pca\nfrom sklearn import svm\nclf=svm.SVC()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precis\u00e3o SVM = {}\".format(confidence)) \ny1=clf.predict(X)\ny1_test=clf.predict(xtest_pca)","a2ea96ec":"from sklearn.metrics import confusion_matrix\nX=X_pca\nclassifier=clf\ny_tes=y_train\ny_pred=clf.predict(X)\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix","e0612f97":"import seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","442680b9":"y_tes=y_test\nX=X_pca\ny_pred=y1_test\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precis\u00e3o pca_svm = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","1edea24c":"X=x_lda\nfrom sklearn import svm\nclf=svm.SVC()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precis\u00e3o SVM_lda = {}\".format(confidence)) \ny2=clf.predict(X)\ny2_test=clf.predict(xtest_lda)\n\nfrom sklearn.metrics import confusion_matrix\nclassifier=clf\ny_tes=y_train\ny_pred=y2\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","42f742b7":"\nfrom sklearn.metrics import confusion_matrix\nclassifier=clf\ny_tes=y_test\ny_pred=y2_test\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precis\u00e3o SVM_lda = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","13247310":"X=x_lda\nfrom sklearn import tree\nclf= tree.DecisionTreeClassifier()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precis\u00e3o TREE_lda = {}\".format(confidence)) \ny3=clf.predict(X)\ny3_test=clf.predict(xtest_lda)\nX.shape","f1a69361":"x_test.shape","4332faab":"from sklearn.metrics import confusion_matrix\ny_tes=y_test\ny_pred= y3_test\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precis\u00e3o SVM_lda = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","5a34cc06":"X=X_pca\nfrom sklearn import tree\nclf= tree.DecisionTreeClassifier()\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precis\u00e3o TREE_pca = {}\".format(confidence)) \ny4=clf.predict(X)","5079148c":"from sklearn.metrics import confusion_matrix\nclassifier=clf.fit(X_pca, y_train) \ny_tes= y_test\nX=xtest_pca\ny_pred=clf.predict(X)\ny4_test=y_pred\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nconfidence = clf.score(xtest_pca, y_tes) \nprint(\"Precis\u00e3o TREE_pca = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","d7c6e72c":"X=X_pca\nfrom sklearn.ensemble import RandomForestClassifier\nclf= RandomForestClassifier(n_estimators=100)\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precis\u00e3o forest_pca = {}\".format(confidence)) \ny5=clf.predict(X)","e04e5303":"from sklearn.metrics import confusion_matrix\nclassifier=clf.fit(X_pca, y_train) \ny_tes= y_test\nX=xtest_pca\ny_pred=clf.predict(X)\ny5_test=y_pred\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nconfidence = clf.score(xtest_pca, y_tes) \nprint(\"Precis\u00e3o forest_pca = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","c4e76427":"X=x_lda\nfrom sklearn.ensemble import RandomForestClassifier\nclf= RandomForestClassifier(n_estimators=100)\nclf.fit(X, y_train) \nconfidence = clf.score(X, y_train) \nprint(\"Precis\u00e3o forest_lda = {}\".format(confidence)) \ny6=clf.predict(X)","e115b7ec":"from sklearn.metrics import confusion_matrix\nclassifier=clf.fit(x_lda, y_train) \ny_tes= y_test\nX=xtest_lda\ny_pred=clf.predict(X)\ny6_test=y_pred\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nconfidence = clf.score(xtest_lda, y_tes) \nprint(\"Precis\u00e3o forest_lda = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","186326de":"train_results = pd.DataFrame(data = {'ImageId':y_train,'I1':y1,'I2':y2,'I3':y3,'I4':y4,'I5':y5,'I6':y6})","a4cb0990":"train_results","5abaef3f":"train= pd.DataFrame(data = {'I1':y1,'I2':y2,'I3':y3,'I4':y4,'I5':y5,'I6':y6})\nmode= train.mode(axis='columns', numeric_only=True)\nmode","504a8d23":"notsure=mode.dropna()","6bda31a8":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=8468\nprint(y_train[n])\nplt.imshow(X[n])","fa5710b7":"#plot any image (keep in min 1st row n=0)\nX=x_train.reshape(x_train.shape[0],28,28)\nn=19502\nprint(y_train[n])\nprint(train.loc[[19502]])\nplt.imshow(X[n])","3f744ff4":"na_free = mode.dropna()\nonly_na = mode[~mode.index.isin(na_free.index)]\nonly_na.shape\ny_tes = y_train[~mode.index.isin(na_free.index)]","56e3b1d1":"from sklearn.metrics import confusion_matrix\ny_pred=mode\n\ncnf_matrix = confusion_matrix(y_train, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_train, y_pred,average='micro')\nprint(\"Precis\u00e3o combo = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","6c2ff136":"test= pd.DataFrame(data = {'I1':y1_test,'I2':y2_test,'I3':y3_test,'I4':y4_test,'I5':y5_test,'I6':y6_test})\ntest_mode= test.mode(axis='columns', numeric_only=True)\ntest_mode","491d440b":"na_free = test_mode.dropna()\nonly_na = test_mode[~test_mode.index.isin(na_free.index)]\ny_tes = y_test[~test_mode.index.isin(na_free.index)]\nna_free.shape","3fe64928":"from sklearn.metrics import confusion_matrix\ny_pred=only_na[0]\n\ncnf_matrix = confusion_matrix(y_tes, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes, y_pred,average='micro')\nprint(\"Precis\u00e3o combo = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","521fb051":"test_mode.dropna()","3870c665":"#plot any image (keep in min 1st row n=0)\nX=x_test.reshape(x_test.shape[0],28,28)\nn=6569\nprint(y_test[n])\nplt.imshow(X[n])","f128f97c":"#import the libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport numpy as np\nimport tensorflow as tf\nnp.random.seed(1337)","8f79f0be":"#One-Hot Encoding\ny_train_one_hot = to_categorical(y_train)\ny_test_one_hot = to_categorical(y_test)\n\n#Print the new label\nprint(y_train_one_hot[0])","2c1253b1":"# build\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(128, activation = tf.nn.relu, input_shape = (28*28,)))\nmodel.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))","7222ce91":"# compile\nmodel.compile(optimizer = 'adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics = ['accuracy'])","33a32014":"EPOCH = 10\n\nmodel.fit(x_train01, y_train, epochs = EPOCH, verbose = 1, validation_split = 0.3)","10c2ab43":"pred_train = model.predict(x_train01)","99e984fd":"pred_train[0]","40953808":"y7=np.argmax(pred_train, axis = 1)","c2ebcfee":"np.argmax(pred_train[0])","1512e94c":"# true label\ny_train[0]","e420888f":"from sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_train, y7)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_train, y7,average='micro')\nprint(\"Precis\u00e3o NN = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","f791eae6":"pred_test = model.predict(x_test01)","a5a61143":"pred_test.shape","c6853ff0":"pred_test[0]","580c4ef0":"np.argmax(pred_test[0])","ce088a83":"y_test[0]","718d3c6d":"test_id = np.arange(1, x_test.shape[0]+1,1)\ntest_id","1dd62dfd":"predictions = np.argmax(pred_test, axis = 1)\ny7_test=predictions","84695e84":"from sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_test, predictions)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_test, predictions,average='micro')\nprint(\"Precis\u00e3o NN = {}\".format(confidence)) \n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","d6a222fa":"train01= pd.DataFrame(data = {'I1':y1,'I2':y2,'I3':y3,'I4':y4,'I5':y5,'I6':y6,'I7':y7})\nmode01= train.mode(axis='columns', numeric_only=True)\nmode01","e1823a78":"notsure=mode01.dropna()\nnotsure\n#the same as before","8fd2d848":"na_free = mode01.dropna()\nonly_na = mode01[~mode01.index.isin(na_free.index)]\ny_train01 = y_train[~mode01.index.isin(na_free.index)]\n","256be9d5":"from sklearn.metrics import confusion_matrix\ny_pred=mode01\n\ncnf_matrix = confusion_matrix(y_train, y_pred)\ncnf_matrix\n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")\n","354cbe18":"test01= pd.DataFrame(data = {'I1':y1_test,'I2':y2_test,'I3':y3_test,'I4':y4_test,'I5':y5_test,'I6':y6_test,'I7':y7_test })\ntest_mode01= test01.mode(axis='columns', numeric_only=True)\ntest_mode01","b681eac5":"na_free = test_mode01.dropna()\nonly_na = test_mode01[~test_mode01.index.isin(na_free.index)]\ny_tes01 = y_test[~test_mode01.index.isin(na_free.index)]\nna_free.shape","d255f6d4":"from sklearn.metrics import confusion_matrix\ny_pred=only_na[0]\n\ncnf_matrix = confusion_matrix(y_tes01, y_pred)\ncnf_matrix\n\nfrom sklearn.metrics import precision_score\nconfidence=precision_score(y_tes01, y_pred,average='micro')\nprint(\"Precis\u00e3o combo_NN = {}\".format(confidence)) \n\n\nimport seaborn as sns \nplt.title(\"Confusion Matrix\")\nsns.heatmap(cnf_matrix,cbar=False,annot=True,cmap=\"Blues\",fmt=\"d\")","c3457ec4":"LDA test","dab205ba":"## Add the neural network result to the complex system","c8f5977e":"# PRE - PROCESSAMENTO\n>transformar os valores entre 0 e 1 \n","19cd27e7":"# Models\n* Support Vector Machines (SVM)\n* Decision Tree \n* Random Forest","c11147a7":"## Interaction 4: PCA and Decision Trees","5a66eafd":"## Rede neuronal\n\n* https:\/\/www.digitalocean.com\/community\/tutorials\/como-construir-uma-rede-neural-para-reconhecer-digitos-manuscritos-com-o-tensorflow-pt\n* https:\/\/itnext.io\/classify-hand-written-digits-using-python-and-convolutional-neural-networks-26ccfc06b95c\n- https:\/\/www.kaggle.com\/yukikitayama\/neural-network-classification-to-digit-images\n","023805d3":"SHOW IMAGES","5f0e205a":"# Dimension selection\n> originally there are 784 features (#columns) its therefore crutial to reduce the number of dimensions to use on the model\n* PCA (unsupervised)\n* LDA (supervised)\n\n","d845dfa5":"## LDA","71ceb72d":"> This is a classification problem, the aim is to create a model that is able to identify which digit from 0 to 9, based on the images of previous digits. \n\n>https:\/\/medium.com\/@Mandysidana\/machine-learning-types-of-classification-9497bd4f2e14\nHere we have the types of classification algorithms in Machine Learning:\n* Linear Classifiers: Logistic Regression, Naive Bayes Classifier\n* Nearest Neighbor\n* - Support Vector Machines\n* - Decision Trees\n* Boosted Trees\n* - Random Forest\n* - Neural Networks\n\n>Competition https:\/\/www.kaggle.com\/c\/digit-recognizer\/overview","73fb8dea":"transformar dataset de test ","b8bfb750":"## Interaction 5: PCA and random forest","ca9db3ea":"comments: better outcomes by adding the neural network results, what creates a worst system than the neural network","cf4059c7":"## Interaction 6: LDA and Random Forest","1cca29c1":"com precisao de 1 - fazer a matrix de confusao com a info dos dataset de teste\n","66de1146":"## Interaction 1: PCA and SVM","8ca0f841":"## PCA","ce2341b9":"## build extra features","f0a70b8a":"## Interaction 2: LDA and SVM","9e49ddba":"## Interaction 3: Lda and Decision Trees","4adce4b8":"we can observe that the:\nthe model struggles with distingguish 9 and 4 and 3 and 8 the most\n\n\n","445a7437":"Exploratory Data Analysis","669b64a7":"## evaluate the models\n","055b7daf":"PCA test \n","b352f1f7":"### testing","e0541ef4":"## Testing complex model\n\n- get all the 6 results\n- calculate mode\n- remove unsure values (without unique mode)\n- confusion matrix\n"}}