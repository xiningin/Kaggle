{"cell_type":{"28f36717":"code","90d779d1":"code","2949e32d":"code","2e8a472d":"code","28c1e014":"code","6ae65aee":"code","0a26fb1d":"code","8434ab36":"code","a486e173":"code","6afcbc21":"code","57a3f94a":"code","7f45b996":"code","aecb441e":"code","642996b2":"code","463c3299":"code","0527fa4f":"code","d60a3992":"code","89459ced":"code","02654aae":"code","9a64fd47":"code","18ee3ce5":"code","ebf43258":"code","8baf240f":"code","31db3d5e":"code","f43dea54":"code","7a2856e5":"code","33d6b83e":"code","db08b914":"code","addd41c4":"code","53f5bfb7":"code","1e8f878c":"code","4eef76f7":"code","f6c1c4b5":"code","d86ee545":"code","e6f85cd8":"markdown","7e33a968":"markdown","57f60bdd":"markdown","5e6b1e20":"markdown","02ed6ed9":"markdown","cfad394a":"markdown","6bbddadb":"markdown","a299b691":"markdown","2e0f11ec":"markdown","5bcab09d":"markdown","9dc79126":"markdown","b864d068":"markdown","b4a91fac":"markdown","e27b138f":"markdown","1e5845e4":"markdown","a2e19e22":"markdown","bfead79a":"markdown"},"source":{"28f36717":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nimport lightgbm as lgbm\nfrom sklearn.metrics import mean_squared_error\n\npd.set_option(\"display.max_columns\", 25)\npd.set_option(\"display.max_rows\", 25)","90d779d1":"train_df= pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\ntest_df= pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsub_df= pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")","2949e32d":"train_df.info()","2e8a472d":"train_df.columns","28c1e014":"train_df.duplicated().sum()","6ae65aee":"train_df.describe().T","0a26fb1d":"train_df.head()","8434ab36":"cat_cols = [\"cat0\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\",\n\"cat7\",\"cat8\", \"cat9\"]\ncont_cols= [\"cont0\", \"cont1\", \"cont2\", \"cont3\", \"cont4\", \"cont5\",\n\"cont6\", \"cont7\", \"cont8\", \"cont9\", \"cont10\", \"cont11\", \"cont12\",\n\"cont13\"]","a486e173":"# Check unique values\nfor col in cat_cols:\n    print (col,train_df[col].unique())","6afcbc21":"# Check unique values in test\nfor col in cat_cols:\n    print (col,test_df[col].unique())","57a3f94a":"for col in cat_cols:\n    sns.barplot(x=train_df[col].value_counts().index, y=train_df[col].value_counts()).set_title(col)\n    plt.show()","7f45b996":"cont_hm = train_df[cont_cols].corr()\nplt.figure(figsize=(15,15))\nsns.heatmap(cont_hm, annot= True)\nplt.show()","aecb441e":"for col in cont_cols:\n    plt.hist(train_df[col])\n    plt.title(col)\n    plt.show()","642996b2":"# Some custom functions\ndef encode_cat_cols(df,cols):\n    '''\n    encodes categorical columns between 0-n for n+1 unique values\n    df = dataframe to be worked upon\n    cols = list of the columns to be worked upon in the df\n    '''\n    for col in cols:\n        values=df[col].unique()\n        labels_ordered = { k:i for i,k in enumerate(sorted(values),0)}\n        df[col]=df[col].map(labels_ordered)\n        \ndef plot_model_comparison(models,results,title):\n    \"\"\" \n    Compares the results of different models and plots box plots for the algorithms.\n    models: list of names of models\n    results: training results\n    title: title for the graph\n        \n    \"\"\"\n    fig = plt.figure()\n    fig.suptitle(title)\n    ax = fig.add_subplot(111)\n    plt.boxplot(results)\n    ax.set_xticklabels(models)\n    plt.show()\n\ndef timer(start_time=None):\n    \"\"\" \n    Helps  to keep track of time elapsed while training.\n    start time: if none then start time tracking\n                if not none tracks time from start time         \n    \"\"\"\n    if not start_time:\n        print(datetime.now())\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print(\"Time taken: %i hours %i minutes and %s seconds.\" % (thour, tmin, round(tsec, 2)))","463c3299":"train_df.head()","0527fa4f":"encode_cat_cols(train_df,cat_cols)","d60a3992":"train_df.head()","89459ced":"X = train_df.drop(columns=[\"id\",\"target\"]).values\nY = train_df[\"target\"].values","02654aae":"print(X.shape)\nprint(Y.shape)","9a64fd47":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=5)","18ee3ce5":"print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)","ebf43258":"scoring = \"neg_root_mean_squared_error\" \nn_splits = 5\nseed = 5\n\nmodels = []\nmodels.append((\"LR\", LinearRegression()))\nmodels.append((\"LASSO\", Lasso()))\nmodels.append((\"EN\", ElasticNet()))\nmodels.append((\"KNN\", KNeighborsRegressor()))\nmodels.append((\"CART\", DecisionTreeRegressor()))\n","8baf240f":"results = []\nnames = []\nstart_time=timer(None)\nfor name, model in models:\n    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, \\\n                                 scoring=scoring) \n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\ntimer(start_time)","31db3d5e":"graph_title=\"Algorithm Comparison\"\nplot_model_comparison(names,results,graph_title)","f43dea54":"sc = StandardScaler()\nscaled_x_train = sc.fit_transform(x_train)\nscaled_x_test = sc.transform(x_test)","7a2856e5":"models = []\nmodels.append((\"LR\", LinearRegression()))\nmodels.append((\"LASSO\", Lasso()))\nmodels.append((\"EN\", ElasticNet()))\nmodels.append((\"KNN\", KNeighborsRegressor()))\nmodels.append((\"CART\", DecisionTreeRegressor()))","33d6b83e":"results = []\nnames = []\nstart_time=timer(None)\nfor name, model in models:\n    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    cv_results = cross_val_score(model, scaled_x_train, y_train, cv=kfold, \\\n                                 scoring=scoring) \n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\ntimer(start_time)","db08b914":"graph_title=\"Scaled Algorithm Comparison\"\nplot_model_comparison(names,results,graph_title)","addd41c4":"ensembles = []\nensembles.append(('AB', AdaBoostRegressor()))\nensembles.append(('GBM', GradientBoostingRegressor()))\nensembles.append(('RF', RandomForestRegressor()))\nensembles.append(('ET', ExtraTreesRegressor()))\n\nresults = []\nnames = []\nstart_time=timer(None)\nfor name, model in ensembles:\n    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    cv_results = cross_val_score(model, scaled_x_train, y_train,cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\ntimer(start_time)","53f5bfb7":"graph_title=\"Scaled Ensemble Algorithm Comparison\"\nplot_model_comparison(names,results,graph_title)","1e8f878c":"test_df.head()","4eef76f7":"encode_cat_cols(test_df,cat_cols)\ntest_df = test_df.drop(columns=[\"id\"])\nx_test_scaled = sc.transform(test_df)","f6c1c4b5":"#4158\nm1= LinearRegression()\nm1.fit(x_train,y_train)\ntarget_lr = m1.predict(test_df)\nsub_df['target'] = target_lr\nsub_df[['id', 'target']].to_csv('submission1.csv', index=False)\nsub_df.head()","d86ee545":"#2976\nm2= GradientBoostingRegressor()\nm2.fit(scaled_x_train,y_train)\ntarget_gbm = m2.predict(x_test_scaled)\nsub_df['target'] = target_gbm\nsub_df[['id', 'target']].to_csv('submission2.csv', index=False)\nsub_df.head()","e6f85cd8":"# Evaluate Algorithms","7e33a968":"# Summarize Data\n","57f60bdd":"# Fine Tuning","5e6b1e20":"#### The plain old Linear regression wins out!!","02ed6ed9":"#### after encoding","cfad394a":"# Predictions","6bbddadb":"## Linear Regression","a299b691":"#### Lets scale the continuous variables and check again","2e0f11ec":"### GBM has given the best performance so far. In the next submision we will further tune parameters","5bcab09d":"## Split-out validation dataset","9dc79126":"#### We repeate the data transformation on the test set","b864d068":"## Load Dataset","b4a91fac":"# Preparing the data\n## Data Transformation","e27b138f":"# Preparation\n## Load Libraries","1e5845e4":"#### before encoding","a2e19e22":"##  Spot Check Algorithms","bfead79a":"# Gradient Boosting Regressor"}}