{"cell_type":{"d51b9b16":"code","bd762dda":"code","16784622":"code","89dd8426":"code","36bcb1f1":"code","ce79bab3":"code","c97b6a9f":"code","3cf3d2f6":"code","043e3cb3":"code","214361e5":"code","26d69c31":"code","2ec2a126":"code","f00a20e0":"code","1d32130c":"code","d71961ae":"code","274d9cd9":"code","64a24a62":"code","ad53ca2f":"code","29d59229":"code","f28e021f":"code","9b683ca3":"code","382d4686":"code","4183e713":"code","0efd1930":"code","8575ae9a":"code","d7926454":"code","7aaff14d":"code","9fac69cd":"code","8ff9773a":"code","75a9616f":"code","3562fcdb":"code","dd2822b1":"code","f7e918eb":"code","29ae1585":"code","7c80db48":"code","f63b9648":"code","7d4bfc8b":"code","79a503ff":"code","30751863":"code","6814876b":"code","3ff45efa":"code","44a6cc75":"code","fd02ffde":"code","24b84ebf":"code","a6b021e1":"code","f82cb94d":"code","d688e9c6":"code","b0f66a3d":"code","043c416b":"code","a641aef0":"code","29df1ac4":"code","b4f1dd98":"code","d3d84851":"code","2f4e51c7":"code","1884bdde":"code","6c42fc6e":"code","d5547787":"code","806b78f9":"code","6dce630a":"code","95e5154f":"code","89141630":"code","8d0ded93":"code","8e8dfb13":"code","e963e55d":"code","3885253c":"code","f482d200":"code","db08a662":"code","77f58282":"code","982b57d0":"code","4984b95f":"code","ea509f36":"code","853b6445":"markdown","f2d1a6e3":"markdown","10a8bfc7":"markdown","43a99a48":"markdown","b8a35f83":"markdown","29bb4efc":"markdown","308221cb":"markdown","a548d0a9":"markdown","a5bfebb4":"markdown","2f85302d":"markdown","c4b07712":"markdown","98661e18":"markdown","e39c3a97":"markdown","e5e6da27":"markdown","959dcbd3":"markdown","ff98610e":"markdown","4dc56dd3":"markdown","c4db0c3b":"markdown","18cc2712":"markdown","ccf7e66d":"markdown","db41f090":"markdown","4f160071":"markdown","435b6098":"markdown","9b61e2b9":"markdown","d12daec1":"markdown","90f9bfd6":"markdown","a4e478a3":"markdown","5969df01":"markdown","383ef23a":"markdown","49135bd5":"markdown","2d6352e8":"markdown","75713077":"markdown","843525b1":"markdown","76e1c405":"markdown","abb3052c":"markdown","7b075477":"markdown","895fde2a":"markdown","2908c5f2":"markdown","1055335c":"markdown","74a18342":"markdown","15b38693":"markdown","31d0daed":"markdown","3fc5fb5b":"markdown","3ef1dc6b":"markdown","f349f238":"markdown","a62a51f5":"markdown","37197adf":"markdown","6302ac9a":"markdown"},"source":{"d51b9b16":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import load_breast_cancer","bd762dda":"#loading data\ndata = load_breast_cancer()\nX=data.data\ny=data.target","16784622":"#splitting data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y)\n#applying model\nmodel = DecisionTreeClassifier(random_state=1)\n#fitting model\nmodel = model.fit(train_X, train_y)","89dd8426":"pip install eli5","36bcb1f1":"import eli5\nfrom eli5.sklearn import PermutationImportance","ce79bab3":"#calculate the importance of features in model by shuffling\nperm = PermutationImportance(model, random_state=0)\nperm = perm.fit(val_X, val_y)","c97b6a9f":"#show the weights (accuracy \u00b1 variance) for every feature\neli5.show_weights(perm, feature_names = data.feature_names,top=30) \n#since len(data.feature_names)=30 we have assigned it to top to get all the features.","3cf3d2f6":"from sklearn.inspection import partial_dependence\nfrom sklearn.inspection import plot_partial_dependence\nfrom sklearn.ensemble import GradientBoostingClassifier","043e3cb3":"data.feature_names","214361e5":"pdp_model = GradientBoostingClassifier()\npdp_model.fit(X,y)","26d69c31":"plot_partial_dependence(pdp_model, features=[0,1,2,3,4,5,6,7,8,9,10], # first 11 columns\n                                   X=X,            # required data \n                                   feature_names=['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity',\n                                    'mean concave points', 'mean symmetry', 'mean fractal dimension','radius error'], # labels on graphs\n                                   grid_resolution=10) # number of values to plot on x axis","2ec2a126":"pip install pdpbox","f00a20e0":"from pdpbox import pdp, get_dataset, info_plots","1d32130c":"#converting into dataframe\ndf=pd.DataFrame(data.data,columns=data.feature_names)\ndf.head()","d71961ae":"ice = pdp.pdp_isolate(model=pdp_model, dataset=df, model_features=df.columns.tolist(), feature='worst concave points')\npdp.pdp_plot(ice, 'worst concave points', plot_lines=True)\nplt.show()","274d9cd9":"ice = pdp.pdp_isolate(model=pdp_model, dataset=df, model_features=df.columns.tolist(), feature='worst perimeter')\npdp.pdp_plot(ice, 'worst perimeter', plot_lines=True)\nplt.show()","64a24a62":"!conda install -c conda-forge Skater -y\n\nfrom skater.core.explanations import Interpretation\nfrom skater.model import InMemoryModel","ad53ca2f":"#interpreter is an object of interpretation\ninterpreter = Interpretation(training_data=val_X, feature_names=data.feature_names)\n# val_X , val_y are the testing datasets and data.feature_names will return the column names to parameter feature_names \nglobal_model = InMemoryModel(pdp_model.predict_proba, examples=train_X, target_names=['Benign', 'Malignant'])\n#The predicted probabilities of classifier model are passed in the parameter","29d59229":"fig,ax = interpreter.feature_importance.plot_feature_importance(global_model, progressbar=False)#plotting feature importance\nfig.set_figheight(10)#for resizing","f28e021f":"from sklearn.datasets import fetch_20newsgroups","9b683ca3":"# CONSIDER 4 CATEGORIES\ncategories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']","382d4686":"newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\nnewsgroups_test = fetch_20newsgroups(subset='test', categories=categories)","4183e713":"class_names = ['atheism', 'christian','graphics','med']","0efd1930":"import sklearn","8575ae9a":"vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\ntrain_vectors = vectorizer.fit_transform(newsgroups_train.data)\ntest_vectors = vectorizer.transform(newsgroups_test.data)","d7926454":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error","7aaff14d":"rf = RandomForestClassifier(n_estimators=500)\nrf.fit(train_vectors, newsgroups_train.target)","9fac69cd":"pred = rf.predict(test_vectors)\nmean_absolute_error(newsgroups_test.target, pred)","8ff9773a":"pip install lime","75a9616f":"from lime import lime_text\nfrom sklearn.pipeline import make_pipeline\nc = make_pipeline(vectorizer, rf)","3562fcdb":"newsgroups_test.data[0]","dd2822b1":"print(c.predict_proba([newsgroups_test.data[0]]))","f7e918eb":"from lime.lime_text import LimeTextExplainer\nexplainer = LimeTextExplainer(class_names=class_names)","29ae1585":"idx = 83\n#exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6,top_labels=4)#generate an explanation with at most 6 features \nprint('Document id: %d' % idx)\nprint('Probability(atheism) =', c.predict_proba([newsgroups_test.data[idx]])[0,0])\nprint('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\nprint('Probability(graphics) =', c.predict_proba([newsgroups_test.data[idx]])[0,2])\nprint('Probability(med) =', c.predict_proba([newsgroups_test.data[idx]])[0,3])\nprint('True class: %s' % class_names[newsgroups_test.target[idx]])","7c80db48":"#exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6,top_labels=4)#generate an explanation with at most 6 features \n#exp.as_list()#explainer","f63b9648":"print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\ntmp = test_vectors[idx].copy()\ntmp[0,vectorizer.vocabulary_['AVS']] = 0\ntmp[0,vectorizer.vocabulary_['graphics']] = 0\nprint('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\nprint('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])","7d4bfc8b":"#fig = exp.as_pyplot_figure()","79a503ff":"#exp.show_in_notebook(text=False)","30751863":"import skimage.io \nimport skimage.segmentation","6814876b":"print(\"Image to be read\")\nXi = skimage.io.imread(\"https:\/\/www.data-imaginist.com\/assets\/images\/kitten.jpg\") #link for image to be read\nXi = skimage.transform.resize(Xi, (299,299)) # resizing image\nskimage.io.imshow(Xi)# Show image \nXi = (Xi - 0.5)*2 #Inception pre-processing of image","3ff45efa":"import keras","44a6cc75":"inceptionV3_model = keras.applications.inception_v3.InceptionV3() #Load pretrained model","fd02ffde":"import numpy as np\nfrom keras.applications.imagenet_utils import decode_predictions","24b84ebf":"print(\"The top 5 classes of predictions are - \")\npreds = inceptionV3_model.predict(Xi[np.newaxis,:,:,:]) #np.newaxis is used to increase the dimension of the existing array by one. Here,Input should be 4D\nprint(decode_predictions(preds)) #top = 5 by default","a6b021e1":"preds.shape","f82cb94d":"top_pred_classes = preds[0].argsort()[-5:][::-1]\nprint(\"The indices of the top 5 classes \")\ntop_pred_classes               ","d688e9c6":"superpixels = skimage.segmentation.quickshift(Xi, kernel_size=4,max_dist=200, ratio=0.2) #the higher the kernel size,max_dist, the fewer are the clusters\n#Segments image using quickshift clustering\nnum_superpixels = np.unique(superpixels).shape[0]\nprint(\"The number of super pixels generated\")\nnum_superpixels","b0f66a3d":"skimage.io.imshow(skimage.segmentation.mark_boundaries(Xi\/2+0.5, superpixels))","043c416b":"np.random.seed(222)\nnum_perturb = 150 \n#150 perturbations\nperturbations = np.random.binomial(1, 0.5, size=(num_perturb, num_superpixels))# The size corresponds to the (no. of perturbations x no. of superpixels) in the image.\nprint(\" Here, '1' represent ON(active) superpixel and '0' represents OFF.\")\nperturbations[0]","a641aef0":"import copy","29df1ac4":"def perturb_image(img,perturbation,segments): #takes in the parameters : raw image, perturbation vector and superpixels generated\n  active_pixels = np.where(perturbation == 1)[0]\n  mask = np.zeros(segments.shape)\n  for active in active_pixels:\n      mask[segments == active] = 1 \n  perturbed_image = copy.deepcopy(img)\n  perturbed_image = perturbed_image*mask[:,:,np.newaxis]\n  return perturbed_image #returns the perturbed image","b4f1dd98":"print(\"The perturbed image\")\nskimage.io.imshow(perturb_image(Xi\/2+0.5,perturbations[0],superpixels)) ","d3d84851":"predictions = []\nfor pert in perturbations:\n  perturbed_img = perturb_image(Xi,pert,superpixels)\n  pred = inceptionV3_model.predict(perturbed_img[np.newaxis,:,:,:])\n  predictions.append(pred)\n\npredictions = np.array(predictions)","2f4e51c7":"import sklearn.metrics","1884bdde":"original_image = np.ones(num_superpixels)[np.newaxis,:] #Perturbation with all superpixels enabled \n#The distance between each randomly generated perturnation and the image being explained is computed using the cosine distance. \ndistances = sklearn.metrics.pairwise_distances(perturbations,original_image, metric='cosine').ravel()#ravel() function is used to create a contiguous flattened array.\n#distances","6c42fc6e":"kernel_width = 0.25\nweights = np.sqrt(np.exp(-(distances**2)\/kernel_width**2)) #Kernel function\nweights.shape","d5547787":"from sklearn.linear_model import LinearRegression","806b78f9":"simpler_model = LinearRegression()\nsimpler_model.fit(X=perturbations, y=predictions[:,:,top_pred_classes[0]], sample_weight=weights) # the top predicted class is to be explained\ncoeff = simpler_model.coef_[0] \ncoeff.shape # Each coefficient in the linear model corresponds to one superpixel in the segmented image.","6dce630a":"num_top_features = 4\ntop_features = np.argsort(coeff)[-num_top_features:] \n#Now we need to sort the coefficients to figure out which are the superpixels that have larger coefficients (magnitude) for the prediction of egyptian cat. \ntop_features","95e5154f":"mask = np.zeros(num_superpixels) #The less relevant pixels are black and only the top superpixels are activated.\nmask[top_features]= True \nskimage.io.imshow(perturb_image(Xi\/2+0.5,mask,superpixels) )","89141630":"pip install shap","8d0ded93":"import shap","8e8dfb13":"explainer = shap.TreeExplainer(pdp_model)\n#calculate shap values\nshap_values = explainer.shap_values(val_X)","e963e55d":"X_shap = pd.DataFrame(shap_values)\n#display shap values\nX_shap.head()","3885253c":"print('Expected Value\/base value: ', explainer.expected_value)","f482d200":"test_X=pd.DataFrame(val_X,columns=data.feature_names)","db08a662":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[0,:], test_X.iloc[0,:])","77f58282":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[:1000,:], test_X.iloc[:1000,:])","982b57d0":"shap.dependence_plot(\"worst concave points\", shap_values, test_X)","4984b95f":"shap.summary_plot(shap_values, test_X)","ea509f36":"shap.summary_plot(shap_values, test_X, plot_type=\"bar\", color='red')","853b6445":"Step 9 - Use 'perturbations', 'predictions' and 'weights' to fit an explainable (linear) model","f2d1a6e3":"TREE EXPLAINER","10a8bfc7":"INTERPRETATION -\nGlobal Surrogate Model takes the raw data and trains it using interpretable model.\n\nThe feature importance is plotted which shows that the most important feature in this dataset is worst area. mean concave points, worst concave points, worst concavity, worst texture , area error etc. are some other crucial features.\n\nEarlier, we have seen the partial dependence plots of various features and ICE plot of worst concave points and worst parameter, which show in detail their impact on target.","43a99a48":"Step 7 :Lime prediction","b8a35f83":"The expected value of the model output. The su of the rows of matrix shows the difference between actual and expected value .","29bb4efc":"Step 5: Tokenizing the text using Vectoriser","308221cb":"These are the probablities for all 4 categories for the data shown above.","a548d0a9":"Step 1 - Read and pre-process image\nThe image is resized, displayed and pre-processed for Inception V3. The variable 'Xi' contains the image. ","a5bfebb4":"Step 10 - Compute top features (superpixels)","2f85302d":"## ICE(Individual Conditional Expectation) PLOTS","c4b07712":"Step 8 - Compute weights (importance) of each perturbed image using kernel.\nThe distances are then mapped to a value between zero and one (weight). ","98661e18":"Step 3 - Predict class of input image using Inception V3 model.","e39c3a97":"INTERPRETATION -\n\nThe plot sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low). This reveals for example that a high MEAN CONCAVE POINTS indicates BENIGN CANCER.","e5e6da27":"Conclusion -\n\nThis is the area of the image that produced the prediction of Egyptian cat. ","959dcbd3":"INTERPRETATION -\n\nUnlike in PDP plots where the value on y axis is averaged for several records, here all the lines are shown. \n\nThe \"worst perimeter\" plot is decreasing in nature i.e. Lower value(<90) of worst parameter is a factor for higher value of target variable(malignant cases). Between 90 and 100 the graph increases in many cases, then decreases slightly and for higher values (>125) it is constant(has lower y value - benign cases).\n\nOn the yellow line, Negative value means that the y is less than the actual average for that perimeter.","ff98610e":"Step 7 - Compute distances between the original image and each of the perturbed images.","4dc56dd3":"Step 6: Training using RandomForest","c4db0c3b":"The predicted output(preds) is a vector of 1000 proabilities for each class available in Inception V3. ","18cc2712":"Step 2: Text classification - determiming the type of text","ccf7e66d":"## SHAP","db41f090":"Step 3: Splitting into 2","4f160071":"The highest probability was for christian , thus it is predicted right. ","435b6098":"INTERPRETATION -\nThe prediction probability of Christian is the highest.  The other 4 grpahs on right show the respective probabilities of being and not being the category.","9b61e2b9":"Step 4 - Extract super-pixels from image","d12daec1":"The superpixels of the top 4 features are shown.","90f9bfd6":"## LIME ON TEXT","a4e478a3":"Step 2 - InceptionV3 initialization\n\nThe pre-trained InceptionV3 model is available in Keras, which is a widely-used image recognition model and has been shown to have more than 78.1% accuracy on the ImageNet dataset.","5969df01":"INTERPRETATION -\n\nThe mean absolute value of the SHAP values for each feature is shown. Worst area has the maximum followed by mean concave points ,then worst concave points and so on. Smoothness error has the least.","383ef23a":"The \"worst concave points\" plot is decreasing in nature i.e. Lower value(<0.10) of concave points is a factor for higher value of target variable(malignant cases). Between 0.10 and 0.20 the graph decreases and after 0.21 it is constant(has lower y value - benign cases).","49135bd5":"This notebook presents Feature-based model explainability techniques, which denote how much the input features contribute to a model\u2019s output. There are many\nFeature-based methods available such as permutation Feature Importance, Partial Dependence Plots (PDPs), Individual Conditional Expectation (ICE) plots, Global surrogate models, Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP). ","2d6352e8":"INTERPRETATION -\nThe values on y axis is the average value of target variable(banign,malignant) on multiple records of a particular value(say, 0.15,0.30 and so on) of a feature(say radius error).\nHigher value on y axis means malignant breast cancer and lower value implies benign.\n\nFeatures like mean radius and mean symmetry have no impact\/dependence on target variable (which have horizontal straight line).\n\nThe graphs show the increasing \/ decreasing nature with increase in the value of features -\n\nExample : In the plot showing mean concave points, it can be inferred that lower value of mean concave points(below 0.06) mean malignant cancer and vice versa since the graph is decreasing in nature.","75713077":"The generated superpixels are shown in the image below using mark_boundaries.","843525b1":"INTERPRETATION -\n\nThe plot represents the change in predicted worst concave points. Vertical dispersion at a single value represents interaction effects with other features. To find interactions dependence_plot automatically selects another feature for coloring. In this case coloring by area error highlights that worst concave points has high impact on concave points on a high area error and vice versa.","76e1c405":"Step 6 - Predict classes of new generated images ","abb3052c":"INTERPRETATION -\n\nThe above explanation shows features which are contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red and their visual size shows the magnitude of the feature's effect and those pushing the prediction lower are in blue. \n\n\nWe predicted -3.89, whereas the base_value is 1.837. The biggest impact comes from mean concave points being 0.04079. Though the worst area value has high effect(989.5) decreasing the prediction.\n\nIf you subtract the length of the blue bars from the length of the pink bars, it equals the distance from the base value to the output. (Here, 3.89+3.837-5.89 = 1.837)","7b075477":"CONCLUSION -\n\nFrom all the above plots (permutation importance , partial dependence, ice , global surrogate, shap), it can be stated that WORST AREA, MEAN CONCAVE POINTS, WORST CONCAVE POINTS , WORST RADIUS are some of the most important features in the breast cancer dataset.","895fde2a":"## LIME ON IMAGE","2908c5f2":"Step 1: loading the text dataset from sklearn","1055335c":"Step 5 - Random perturbations","74a18342":"INTERPRETATION -\n\nThe permutation importance shuffles the features(independent variables) and performs the classification (according to the model) multiple times. It identifies which of them have the greatest impact on the dependent variable y.\n\nThe most important features are those displayed at the top of the list with the max. accuracy (example - mean concave points).\n\nA large number of features with accuracy 0 are not useful at all.\n\nFeatures at the bottom with negative accuracy are found to be more accurate when shuffled.","15b38693":"Step 4: Defining the class names according to the categories","31d0daed":"The description of these classes is shown and it can be seen that the \"Egyptian cat\" is the top class for the given image with the max probability of 0.465.","3fc5fb5b":"Shapley values calculate the importance of a feature by comparing what a model predicts with and without the feature. However, since the order in which a model sees features can affect its predictions, this is done in every possible order, so that the features are fairly compared.","3ef1dc6b":"INTERPRETATION -\n\nThis is the combined force plot. Here the values on y axis are the values that are shown by the x axis on an individual force plot. By dragging along the graph , the impact of the features can be seen for all the samples in our dataset. \n\nExample, the values from 10 to 91 (the red portion) has the worst area and mean concave points as the ones that  are pushing the prediction higher.","f349f238":"## PERMUTATION IMPORTANCE","a62a51f5":"## GLOBAL SURROGATE","37197adf":"## PARTIAL DEPENDENCE PLOTS","6302ac9a":"Last Step - Show image with top features"}}