{"cell_type":{"1c651193":"code","612c54d8":"code","f96b3d9d":"code","105cdd07":"code","d511a66e":"code","45bda42a":"code","a9e486d7":"code","6fcf9142":"code","39791a0d":"code","74567ff2":"code","23996fd1":"code","db3d69c6":"code","a00c5976":"code","92cf9f84":"code","d01874cf":"code","73496b85":"code","142621ce":"markdown","ce9af044":"markdown","04ee9071":"markdown","d320bad7":"markdown","4721414a":"markdown"},"source":{"1c651193":"import numpy as np\nimport pandas as pd\nimport re\nimport gc\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom gensim.models import Word2Vec, KeyedVectors\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patheffects as PathEffects\n%matplotlib inline\n\nfrom tqdm import tqdm\ntqdm.pandas()","612c54d8":"news_df = pd.read_pickle('..\/input\/data-preparation-memory-optimization\/news_df.pkl')","f96b3d9d":"news_df['date'] = news_df.time.dt.date\ntime_news = news_df.groupby('date').headline.apply(' '.join).reset_index()","105cdd07":"del news_df; gc.collect()","d511a66e":"# The function \"text_to_wordlist\" is from\n# https:\/\/www.kaggle.com\/currie32\/quora-question-pairs\/the-importance-of-cleaning-text\n\ndef text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n    # Clean the text, with the option to remove stopwords and to stem words.\n    \n    # Convert words to lower case and split them\n    text = text.lower().split()\n\n    # Optionally, remove stop words\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))\n        text = [w for w in text if not w in stops]\n    \n    text = \" \".join(text)\n\n    # Clean the text\n    text = re.sub(r\"[^A-Za-z0-9^,!.\\\/'+-=]\", \" \", text)\n    text = re.sub(r\"what's\", \"what is \", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"i'm\", \"i am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\",\", \" \", text)\n    text = re.sub(r\"\\.\", \" \", text)\n    text = re.sub(r\"!\", \" ! \", text)\n    text = re.sub(r\"\\\/\", \" \", text)\n    text = re.sub(r\"\\^\", \" ^ \", text)\n    text = re.sub(r\"\\+\", \" + \", text)\n    text = re.sub(r\"\\-\", \" - \", text)\n    text = re.sub(r\"\\=\", \" = \", text)\n    text = re.sub(r\"'\", \" \", text)\n    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n    text = re.sub(r\":\", \" : \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\" u s \", \" american \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e - mail\", \"email\", text)\n    text = re.sub(r\"j k\", \"jk\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    \n    # Optionally, shorten words to their stems\n    if stem_words:\n        text = text.split()\n        stemmer = SnowballStemmer('english')\n        stemmed_words = [stemmer.stem(word) for word in text]\n        text = \" \".join(stemmed_words)\n    \n    # Return a list of words\n    return(text)","45bda42a":"time_news['words'] = time_news.headline.progress_apply(text_to_wordlist)\ntime_news.head(1).T","a9e486d7":"# Load Google pretrained model\nmodel = KeyedVectors.load_word2vec_format('..\/input\/word2vecnegative300\/GoogleNews-vectors-negative300.bin', binary=True)","6fcf9142":"def text2vec(text):\n    return np.mean([model[x] for x in text.split() if x in model.vocab], axis=0).reshape(1,-1)\n\ntime_news['vectors'] = time_news.words.progress_apply(text2vec)\ntime_news.head().T","39791a0d":"time_news.to_pickle('time_news.pkl')","74567ff2":"X = np.concatenate(time_news['vectors'].values)","23996fd1":"kmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\ntime_news['cluster'] = kmeans.predict(X)","db3d69c6":"pca = PCA(n_components=2)\npca_result = pca.fit_transform(X)\ntime_news['x'] = pca_result[:, 0]\ntime_news['y'] = pca_result[:, 1]","a00c5976":"time_news.head()","92cf9f84":"cluster_colors = pd.np.array(['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000'])\ntime_news['color'] = cluster_colors[time_news.cluster.values]\ntime_news['text'] = time_news.headline.str[:50]\n","d01874cf":"import bokeh.io\nfrom bokeh.io import push_notebook, show, output_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, LabelSet\n\n# from bokeh.charts import Donut, HeatMap, Histogram, Line, Scatter, show, output_notebook, output_file\nbokeh.io.output_notebook()","73496b85":"#visualize the data using bokeh\n#output_file(\"top_artists.html\", title=\"top artists\")\n# TOOLS = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n\nsource = ColumnDataSource.from_df(time_news[['x', 'y', 'color', 'text', 'date']])\nTOOLTIPS = [(\"date\", \"@date\"),(\"text\", \"@text\")]\nTOOLS = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n\nplot = figure(plot_width=800, plot_height=450, tooltips=TOOLTIPS, tools=TOOLS)\n\n#draw circles\nplot.circle(y='y', x='x', source=source, size=15, fill_color='color')\nshow(plot)","142621ce":"# Reading data","ce9af044":"# Processing words using Google model","04ee9071":"This notebook uses the output from https:\/\/www.kaggle.com\/nareyko\/data-preparation-memory-optimization","d320bad7":"Joining all daily texts together","4721414a":"# Clustering and generating scatter"}}