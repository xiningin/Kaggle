{"cell_type":{"60cd32e7":"code","3fbe8bf2":"code","5a03317f":"code","36d665de":"code","93c6172a":"code","22335170":"code","6c26d3c4":"code","92048b78":"code","c93db4f5":"code","1135aff3":"code","dd2d5ade":"code","354fc696":"code","a6857d3d":"markdown","ccb03fb2":"markdown","995d5277":"markdown","73ed4459":"markdown","41259914":"markdown","759f7b86":"markdown","cc975e39":"markdown","913d6c33":"markdown","aa898cd1":"markdown","e46dfe13":"markdown"},"source":{"60cd32e7":"import pandas as pd\nimport numpy as np\nnp.random.seed(0)","3fbe8bf2":"df = pd.read_csv('..\/input\/IRIS.csv')\ndf.head()","5a03317f":"df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\ndf.head(10)","36d665de":"train, test = df[df['is_train'] == True], df[df['is_train'] == False]\nprint(\"Size of training data: \", len(train))\nprint(\"Size of test data: \", len(test))","93c6172a":"y = pd.factorize(train['species'])[0]\ny","22335170":"from sklearn.ensemble import RandomForestClassifier as RFC","6c26d3c4":"features = df.columns[:4]\nfeatures","92048b78":"clf = RFC(n_jobs = 2, random_state = 0)\nclf.fit(train[features], y)","c93db4f5":"clf.predict(test[features])","1135aff3":"clf.predict_proba(test[features])[10:20]","dd2d5ade":"preds = df.species[clf.predict(test[features])]\npreds[:5]","354fc696":"from sklearn.metrics import accuracy_score\naccuracy_score(test['species'], preds)","a6857d3d":"If we check the accuracy of the model we will have a low value due to the small amount of data. Try using this model with a larger dataset. Random Forest Classifier works best for large datasets and for many features.","ccb03fb2":"As you can see we have used the np.random.uniform() to achieve this. (0,1, len(df)) <=75 suggests that we will assign 75% of the data as train and the remaining as test.\nLet's split the data now and check the count for each.","995d5277":"As you can see we have fitted our train dataset to the model. The output shows several attributes you can alter. Check out the Documentaion to understand these values.","73ed4459":"All other features are numbers. So now let's bring in our model.","41259914":"Now let's try to predict the species type using our model. We will use the test data for this.","759f7b86":"Here we are going to see how we can use the Random Forest Classifier on a dataset.\nA Random Forest Classifier is an extension of Decision Tree Classifier. In this model we use several decison trees to create a **forest** or a group of outcomes where the final outcome is taken on vote.\nLook at the below image to visualize the working of the model.\n![](http:\/\/www.globalsoftwaresupport.com\/wp-content\/uploads\/2018\/02\/ggff5544hh.png)\nTry to find out on what are the benefits of using the Random Forest Classifier and where the model suits best.","cc975e39":"In this kernal we will not use the train_test_split(), we will try a different approach to split the dataset into train and test.\nInitially we will add a column to label which rows will be taken as train and the rest as test.","913d6c33":"To understand how the model arrives at these results. Let's take a look at the probabilty for each species type given by the model for each input","aa898cd1":"Here each line shows 3 probabilty values for respective species type given by the model.","e46dfe13":"To train the model we need make sure all values are numerical.\nOur species column contains string, which is also the target(y) we are going to predict.\nLet's replace these values with numercials. We will use the factorize() for this."}}