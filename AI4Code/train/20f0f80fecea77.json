{"cell_type":{"1e4bca5d":"code","1180b54a":"code","21d49166":"code","b9eb8ff2":"code","746b7eee":"code","a09bb269":"code","2116ad6b":"code","ba94ff92":"code","ae3326f7":"code","a612aa61":"code","8ff74117":"code","660c63de":"code","4f372b8c":"code","38de4cb9":"code","808c81f8":"code","80652ac9":"code","ed338008":"code","41688c22":"code","6eb6c865":"code","72d3db79":"code","ebe49afd":"code","f0e43a49":"code","cf43e976":"code","88b69e98":"code","acb25740":"code","b6be0d6a":"code","b60571e4":"code","abbc6d3e":"code","806c3d63":"code","79253d49":"code","f4b7c42e":"code","7d938c0e":"code","4a32c2c4":"code","3c6bacb1":"code","9ddbdfe9":"code","91ff80b6":"code","be20faa7":"code","ea30c033":"code","7c269e82":"code","7f3508a0":"code","656c3b5c":"code","958b2939":"code","fd8f9c22":"markdown","2e49428e":"markdown","9374fa7c":"markdown","65e99a3b":"markdown","81e850a9":"markdown","351a2773":"markdown","ae03a005":"markdown"},"source":{"1e4bca5d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1180b54a":"#-- carregando as libs\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import SMOTE\n\nsns.set(rc={'figure.figsize':(25, 18)})","21d49166":"#-- loading dataset\ndb = pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\ndb.head()","b9eb8ff2":"#-- checking dataset dimensionality\nprint(f'Dimens\u00f5es do dataset - \\n linhas = {db.shape[0]} \\n colunas = {db.shape[1]}')","746b7eee":"#-- checking variables type\ndb.info()","a09bb269":"#-- checking missing values\nmissing_values = pd.DataFrame(db.isnull().sum().sort_values(ascending=False) \/ len(db))\nmissing_values.reset_index(inplace=True)\nmissing_values.columns = ['features', 'porcentagem']\nmissing_values.head()","2116ad6b":"#-- print columns by missing values\nfor i in range(0, len(missing_values)):\n    print(f'{missing_values.iloc[i, 0]} - sua pocentagem \u00e9: {missing_values.iloc[i, 1]}')","ba94ff92":"#-- checking missing values\n_ = sns.heatmap(db.isnull(), cbar=False)","ae3326f7":"#-- creatings a list with columns names\nvar_columns = list(db.columns)","a612aa61":"#-- missing values\n_ = plt.bar(missing_values['features'], missing_values['porcentagem'], width = 0.6)\n_ = plt.xticks(rotation=90, fontsize=6)\n_ = plt.axhline(y=0.8, color='r', linestyle='--', lw=2)","8ff74117":"#-- filtrando colunas com missing values\ncolumns_filt = list(missing_values[missing_values['porcentagem'] <= 0.8]['features'])","660c63de":"#-- dropando as linhas com missing values\ndb_filt = db[columns_filt].dropna()\ndb_filt.reset_index(inplace=True)","4f372b8c":"#-- verificando o tipo dos dados\ndb_filt.info()","38de4cb9":"#-- selecionando os dados num\u00e9ricos\ndb_filt_num = db_filt.select_dtypes(include=['int64'])","808c81f8":"#-- verificando o tipo dos dados\ndb_filt_num.info()","80652ac9":"#-- printando m\u00e9tricas de avalia\u00e7\u00e3o \ndb_filt_num.iloc[:, 1:].describe()","ed338008":"#-- verificando as correla\u00e7\u00f5es entre os dados num\u00e9ricos\n_ = sns.heatmap(db_filt_num.iloc[:, 1:].corr())","41688c22":"#-- printando o pairplot\n_ = sns.pairplot(db_filt_num.iloc[:, 1:], corner=True, height=4)","6eb6c865":"#-- selecionadno os dados categ\u00f3ricos\ndb_filt_cat = db_filt.select_dtypes(include='object')","72d3db79":"#-- printando algumas m\u00e9tricas\ndb_filt_cat.describe()","ebe49afd":"db_filt.columns","f0e43a49":"#-- dropando a coluna resposta\ndb_filt = db_filt.drop(columns=['Patient ID'])","cf43e976":"#-- feature engineering\ndb_filt_dummies = pd.get_dummies(db_filt)","88b69e98":"#-- printando os heads\ndb_filt_dummies.head()","acb25740":"#-- criando as vari\u00e1veis do modelo\nX = db_filt_dummies.drop(columns=['SARS-Cov-2 exam result_negative', 'SARS-Cov-2 exam result_positive'])\ny = db_filt['SARS-Cov-2 exam result']","b6be0d6a":"#-- verificando o balaceamento dos dadso\ny.value_counts()","b60571e4":"#-- alterando nome da coluna\ny.columns = ['SARS-Cov-2 exam result']","abbc6d3e":"for i in range(0, len(y)):\n    if y[i] == 'negative':\n        y[i] = 0\n    else:\n        y[i] = 1","806c3d63":"y[:] = y[:].apply(pd.to_numeric)","79253d49":"#-- criando o balanceamento\nos = SMOTE(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\ncolumns = X_train.columns\nos_data_X, os_data_y = os.fit_sample(X_train, y_train)\nos_data_X = pd.DataFrame(data=os_data_X, columns=columns )\nos_data_y = pd.DataFrame(data=os_data_y)\n\n#-- checando\nprint(\"tamanho do dataset \",len(os_data_X))\nprint(\"n\u00famero de paciente sem covid\",len(os_data_y[os_data_y[:] == 0]))\nprint(\"n\u00famero de paciente com covid\",len(os_data_y[os_data_y[:] == 1]))\nprint(\"propor\u00e7\u00e3o de sem covid \",len(os_data_y[os_data_y[:] == 0])\/len(os_data_X))\nprint(\"propor\u00e7\u00e3o de com covid \",len(os_data_y[os_data_y[:] == 1])\/len(os_data_X))","f4b7c42e":"#-- criando o modelo\nlogistic = LogisticRegression(random_state=0)","7d938c0e":"#-- aplicando o modelo nos dados de treino\nlogistic.fit(os_data_X, os_data_y)","4a32c2c4":"#-- aplicando o modelo nos dados de teste\ny_pred = logistic.predict(X_test)","3c6bacb1":"from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n                             roc_auc_score, log_loss, plot_confusion_matrix, roc_curve, auc, plot_roc_curve)","9ddbdfe9":"#-- calculando a acuracidade do modelo\naccuracy_score(y_test, y_pred)","91ff80b6":"#-- printando a matrix de confus\u00e3o\nconfusion_matrix(y_test, y_pred)","be20faa7":"#-- printando os indicadores de recall\nprint(classification_report(y_test, y_pred))","ea30c033":"#-- plotando a curva roc\n_ = plot_roc_curve(logistic, X_test, y_test)","7c269e82":"#-- calculando a probabilidade\ny_sca_proba = logistic.predict_proba(X_test)\ny_sca_proba[:5]","7f3508a0":"#-- selecionando a coluna de probabilidade ser um bom techlead\ny_sca_proba = y_sca_proba[:, 1]\ny_sca_proba[:5]","656c3b5c":"#-- selecionando a probabilidade maior do que 70%\ny_pred_customizado = y_sca_proba >= 0.80","958b2939":"#-- printando a classifica\u00e7\u00e3o do modelo\nprint(classification_report(y_test, y_pred_customizado))","fd8f9c22":"### CAT DATA","2e49428e":"- Dados com baixa correla\u00e7\u00e3o linear","9374fa7c":"## EDA","65e99a3b":"### NUM DATA","81e850a9":"- Os dados est\u00e3o desbalanceados","351a2773":"- Como existem muitos missing values nas linhas, n\u00e3o irei utilizar nenhuma t\u00e9cnica de preenchimento","ae03a005":"Vi muitas pessoas uilizando deep learning para resolver este problema, e dizendo que tinham uma acuracia de 90%. No entanto, seus modelos tinham uma alta precis\u00e3o para encontrar os casos negativos, e baixo para encontrar os positicos. Este modelo tem o mesmo resultado, sem utilizar deep learning. No entanto, ainda \u00e9 muito ruim, pois tem baixa precis\u00e3o, o modelo precisar ser melhorado para encontrar casos positivos da covid."}}