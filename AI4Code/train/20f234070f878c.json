{"cell_type":{"8a7ef10f":"code","719e8c1a":"code","76667c03":"code","f4004dde":"code","77914f85":"code","1fb5f6f8":"code","12233246":"code","026212ef":"code","0c599d75":"code","1a14edac":"code","c7c7a53a":"code","52e675ea":"code","755d9668":"code","8bf61d81":"code","e0f51d5f":"code","51a28537":"code","8a785712":"code","5972aa38":"code","5beb01bf":"code","ab312b7b":"code","33b864e0":"code","58415d20":"code","a1fcd48a":"code","5a4bdd9a":"code","234ea214":"code","d8638a04":"code","e786f052":"code","fe01497a":"code","2cad509d":"code","0ac1d7ac":"code","72122e97":"code","c40bdd38":"code","03a116a6":"code","a9f3ef78":"code","e0695f31":"code","70a7f2bd":"code","924b1869":"code","6546387e":"code","cccaef66":"code","f4054f3a":"code","ed6d511a":"code","1a1bd6ce":"code","76afa469":"code","16fe3366":"code","1fa1711e":"code","bb74c527":"code","a2ead8c3":"markdown","bf19002e":"markdown","09d9f366":"markdown","4153784c":"markdown","1741cccb":"markdown","f842efee":"markdown","2358aa47":"markdown","89266fb5":"markdown","f8052ecc":"markdown","5cdb26c7":"markdown","596ee579":"markdown","f9d4a345":"markdown","aaf64822":"markdown","627d1863":"markdown","c5777e00":"markdown","b00ffb2a":"markdown","c7eed072":"markdown","618a28e0":"markdown","53ff22c4":"markdown","2fe6eec3":"markdown"},"source":{"8a7ef10f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","719e8c1a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\n","76667c03":"train_data=pd.read_csv('\/kaggle\/input\/human-activity-recognition-with-smartphones\/train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/human-activity-recognition-with-smartphones\/test.csv')\n","f4004dde":"train_data.head()","77914f85":"test_data.head()","1fb5f6f8":"print('train ==> ',train_data.shape)\nprint('test  ==> ',test_data.shape)","12233246":"train_data.describe()","026212ef":"test_data.describe()","0c599d75":"# duplicates ?\n\nprint ('Num of duplicates in train_data ==> ',sum(train_data.duplicated()))\nprint ('Num of duplicates in test_data  ==> ',sum(test_data.duplicated()))","1a14edac":"# null ?\n\nprint('Num of Null values in train_data ==> ',train_data.isnull().values.sum())\nprint('Num of Null values in test_data  ==> ',test_data.isnull().values.sum())","c7c7a53a":"train_data.dtypes","52e675ea":"cat_col = train_data.select_dtypes(include=['object'])\ncat_col","755d9668":"numf_col = train_data.select_dtypes(include=['float64'])\nnumi_col = train_data.select_dtypes(include=['int64'])\n\nlen(numf_col.columns)+len(numi_col.columns)","8bf61d81":"data = pd.concat([train_data , test_data])","e0f51d5f":"data['Activity'].groupby(data['Activity']).count()","51a28537":"data['subject'].unique()","8a785712":"px.histogram(data_frame=data, x=\"subject\", color=\"Activity\",barmode='group')","5972aa38":"df = data\nfig = px.pie(df, names='Activity',width=1200)\nfig.show()","5beb01bf":"fig = px.histogram (df,x=\"Activity\", y=\"subject\",width=1200,color='Activity')\nfig.update_layout(barmode='group')\nfig.show()\n","ab312b7b":"fig = px.box(df, y='subject', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\",)\nfig.show()","33b864e0":"Acc=0\nGyro=0\nother=0\nfor i in data.columns:\n  if'Acc'in i:\n    Acc=Acc+1\n  elif'Gyro'in i:\n    Gyro=Gyro+1\n  else:\n    other=other+1\n\npx.bar(x=['Accelerometer ','Gyroscope ','other'],y=[Acc,Gyro,other],color=[Acc,Gyro,other])        ","58415d20":"px.histogram(data_frame=df,\n             x='tBodyAccMag-mean()',\n             y=\"Activity\",\n             color='Activity', \n             histnorm='probability density',\n             )","a1fcd48a":"fig = px.box(df, y='tBodyAccMag-mean()', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\",)\nfig.show()","5a4bdd9a":"fig = px.box(df, y='angle(X,gravityMean)', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","234ea214":"fig = px.bar(df, x='angle(X,gravityMean)', y=\"Activity\",color=\"Activity\",width=1200,orientation='h',barmode='overlay')\nfig.show()","d8638a04":"fig = px.box(df, y='angle(Y,gravityMean)', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","e786f052":"fig = px.box(df, y='tGravityAcc-energy()-Y', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","fe01497a":"fig = px.bar(df, x='tGravityAcc-energy()-Y', y=\"Activity\",color=\"Activity\",width=1200,orientation='h',barmode='overlay')\nfig.show()","2cad509d":"fig = px.box(df, y='fBodyAcc-bandsEnergy()-1,8', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","0ac1d7ac":"fig = px.bar(df, x='fBodyAcc-bandsEnergy()-1,8', y=\"Activity\",color=\"Activity\",width=1200,orientation='h',barmode='overlay')\nfig.show()","72122e97":"fig = px.box(df, y='fBodyAccJerk-entropy()-X', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","c40bdd38":"fig = px.bar(df, x='fBodyAccJerk-entropy()-X', y=\"Activity\",color=\"Activity\",width=1200,orientation='h',barmode='overlay')\nfig.show()\n","03a116a6":"fig = px.box(df, y='fBodyGyro-entropy()-Z', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","a9f3ef78":"fig = px.bar(df, x='fBodyGyro-entropy()-Z', y=\"Activity\",color=\"Activity\",width=1200,orientation='h',barmode='overlay')\nfig.show()\n","e0695f31":"fig = px.box(df, y='tBodyAcc-max()-X', x=\"Activity\",color=\"Activity\",width=1200,boxmode=\"overlay\")\nfig.show()\n","70a7f2bd":"from sklearn.manifold import TSNE\n\nmm = TSNE(random_state = 42, n_components=2, verbose=1, perplexity=50, n_iter=1000).fit_transform(data.drop('Activity',axis=1))\n\nfig = px.scatter(\n    mm, x=0 ,y=1,\n    color=data.Activity\n)\nfig.show()\n","924b1869":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,accuracy_score\n\nY = data['Activity']\nX = data.drop('Activity',axis=1)\n# x, x_test, y, y_test = train_test_split(X,Y,test_size=0.2,train_size=0.8)\nx_train, x_validation, y_train, y_validation = train_test_split(X,Y,test_size=0.1,random_state=254)\n","6546387e":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nLDA = LinearDiscriminantAnalysis()\nLDA.fit(x_train,y_train)","cccaef66":"predictLDA =  LDA.predict(x_validation)\nprint(classification_report(predictLDA,y_validation))","f4054f3a":"acc_LDA=accuracy_score(predictLDA,y_validation)\nprint(acc_LDA)\n","ed6d511a":"from sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(solver='adam', alpha=1e-08,hidden_layer_sizes=(25,),activation='tanh', random_state=2,batch_size='auto',)\nclf = clf.fit(x_train, y_train)\npredictCLF = clf.predict(x_validation)\n\n","1a1bd6ce":"print(classification_report(predictCLF,y_validation))","76afa469":"acc_CLF=accuracy_score(predictCLF,y_validation)\nprint(acc_CLF)","16fe3366":"from xgboost import XGBClassifier\nxgb_params = {'n_estimators': 100,\n              'learning_rate': 0.2,\n              'subsample': 0.927,\n              'colsample_bytree': 0.88,\n              'max_depth': 5,\n              'booster': 'gbtree', \n              'reg_lambda': 38,\n              'reg_alpha': 32,\n              'random_state': 12}\nmodel = XGBClassifier(**xgb_params)\nmodel.fit(x_train, y_train)","1fa1711e":"predictXGB = model.predict(x_validation)\nprint(classification_report(predictXGB,y_validation))\n","bb74c527":"acc_XGB=accuracy_score(predictXGB, y_validation)\nacc_XGB","a2ead8c3":"``` \nif(tBodyAccMag-mean()<=-0.5):\n    Activity = \"static\"\nelse:\n    Activity = \"dynamic\"\n```\n","bf19002e":"Data is blanced ","09d9f366":"Using boxplot again we can come with conditions to seperate static activities from dynamic activities.\n\n``` \nif(tBodyAccMag-mean()<=-0.8):\n    Activity = \"static\"\nif(tBodyAccMag-mean()>=-0.6):\n    Activity = \"dynamic\"\n``` \n\nAlso, we can easily seperate WALKING_DOWNSTAIRS activity from others using boxplot.\n\n``` \nif(tBodyAccMag-mean()>0.02):\n    Activity = \"WALKING_DOWNSTAIRS\"\nelse:\n    Activity = \"others\"\n```\n\nBut still 25% of WALKING_DOWNSTAIRS observations are below 0.02 which are misclassified as **others** so this condition makes an error of 25% in classification.","4153784c":"```\nif(fBodyAccJerk-entropy()-X>0):\n    Activity = \"static\"\nelse:\n    Activity = \"dynmic\"\n```\n`entropy(): Signal entropy`\n","1741cccb":"The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals","f842efee":"```\nif(ffBodyGyro-entropy()-Z>0):\n    Activity = \"static\"\n```\n`entropy(): Signal entropy`","2358aa47":"From the boxplot and bar we can observe that angle(X,gravityMean) perfectly seperates LAYING from other activities.\n``` \nif(angle(X,gravityMean)>0.01):\n    Activity = \"LAYING\"\nelse:\n    Activity = \"others\"\n```","89266fb5":"**LDA**","f8052ecc":"\n\n1. we have 0 duplicates values\n2. we have 0 null values \n3. we have out layers","5cdb26c7":"## Quick overview ","596ee579":"## Models","f9d4a345":"As we can see We have got almost same number of reading from all the subjects means there are not sygnificant difference in reading then we should not worry about it","aaf64822":"Using the two new components obtained through t-SNE we can visualize and seperate all the six activities in a 2D space.\n","627d1863":" imbalance  ?","c5777e00":"we have 562 numeric and one ","b00ffb2a":"1. In static activities ACC information will not be very useful.\n2. In the dynamic activities  ACC info will be significant.\n\nLet's consider **tBodyAccMag-mean()** feature to differentiate among these two broader set of activities. \nusing **Pdf**","c7eed072":"**neural network**","618a28e0":"From the boxplot and bar we can observe that (fBodyAcc-bandsEnergy()-1,8) perfectly seperates LAYING from other activities.\n``` \nif(fBodyAcc-bandsEnergy()-1,8)>0):\n    Activity = \"Walking_downstairs\"\nelse:\n    Activity = \"others\"\n```\n`bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.`","53ff22c4":"From the boxplot and bar we can observe that (tGravityAcc-energy()-Y) perfectly seperates LAYING from other activities.\n``` \nif(tGravityAcc-energy()-Y)>0):\n    Activity = \"LAYING\"\nelse:\n    Activity = \"others\"\n```\n` energy(): Energy measure. Sum of the squares divided by the number of values. `","2fe6eec3":"1. Acc=345\n2. Geyro=213\n3. other=5\nmost of data in `Accelerometer` so i will start DA with it "}}