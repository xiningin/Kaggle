{"cell_type":{"3b7fb12e":"code","4e152f37":"code","d3fdb4c7":"code","fd15fc31":"code","74e1aacc":"code","3e2f56b6":"code","8a18809e":"code","b1022819":"code","d72d27a7":"code","d2e4beb6":"code","9cb04180":"code","9ff8cb12":"code","b3a3104d":"code","d2bc9e91":"code","780ee3d6":"code","60049631":"code","842abf50":"code","0ccc3b7f":"code","e190a55b":"markdown","2ac8549b":"markdown","77624789":"markdown","01c41010":"markdown"},"source":{"3b7fb12e":"!pip install yacs","4e152f37":"!git clone https:\/\/github.com\/L1aoXingyu\/fcn.pytorch.git","d3fdb4c7":"cd \/kaggle\/working\/fcn.pytorch","fd15fc31":"mkdir output","74e1aacc":"!mv utils utils_fcn","3e2f56b6":"cd \/kaggle\/working\/fcn.pytorch\/modeling\/backbone","8a18809e":"%%writefile vgg.py\n# %load vgg.py\n\"\"\"\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n\"\"\"\nimport torch\nimport torchvision\nfrom torch import nn\n\n\nclass VGG16(nn.Module):\n    def __init__(self):\n        super(VGG16, self).__init__()\n        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n        self.relu1_1 = nn.ReLU(inplace=True)\n        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n        self.relu1_2 = nn.ReLU(inplace=True)\n        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1\/2\n\n        # conv2\n        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n        self.relu2_1 = nn.ReLU(inplace=True)\n        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n        self.relu2_2 = nn.ReLU(inplace=True)\n        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1\/4\n\n        # conv3\n        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n        self.relu3_1 = nn.ReLU(inplace=True)\n        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n        self.relu3_2 = nn.ReLU(inplace=True)\n        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n        self.relu3_3 = nn.ReLU(inplace=True)\n        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1\/8\n\n        # conv4\n        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n        self.relu4_1 = nn.ReLU(inplace=True)\n        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n        self.relu4_2 = nn.ReLU(inplace=True)\n        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n        self.relu4_3 = nn.ReLU(inplace=True)\n        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1\/16\n\n        # conv5\n        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n        self.relu5_1 = nn.ReLU(inplace=True)\n        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n        self.relu5_2 = nn.ReLU(inplace=True)\n        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n        self.relu5_3 = nn.ReLU(inplace=True)\n        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1\/32\n\n    def forward(self, x):\n        x = self.relu1_1(self.conv1_1(x))\n        x = self.relu1_2(self.conv1_2(x))\n        x = self.pool1(x)\n\n        x = self.relu2_1(self.conv2_1(x))\n        x = self.relu2_2(self.conv2_2(x))\n        x = self.pool2(x)\n\n        x = self.relu3_1(self.conv3_1(x))\n        x = self.relu3_2(self.conv3_2(x))\n        x = self.relu3_3(self.conv3_3(x))\n        x = self.pool3(x)\n\n        x = self.relu4_1(self.conv4_1(x))\n        x = self.relu4_2(self.conv4_2(x))\n        x = self.relu4_3(self.conv4_3(x))\n        x = self.pool4(x)\n\n        x = self.relu5_1(self.conv5_1(x))\n        x = self.relu5_2(self.conv5_2(x))\n        x = self.relu5_3(self.conv5_3(x))\n        x = self.pool5(x)\n        return x\n\n\ndef pretrained_vgg(cfg):\n    model = torchvision.models.vgg16(pretrained=True)\n#     model.load_state_dict(torch.load(cfg.MODEL.BACKBONE.WEIGHT))\n    return model\n","b1022819":"cd \/kaggle\/working\/fcn.pytorch\/configs","d72d27a7":"%%writefile train_fcn32s.yml\n# %load train_fcn32s.yml\n\nMODEL:\n  META_ARCHITECTURE: \"fcn32s\"\n\n  BACKBONE:\n    PRETRAINED: True\n    WEIGHT: '\/mnt\/truenas\/scratch\/xingyu.liao\/model_zoo\/vgg16-397923af.pth'\n\n  REFINEMENT:\n    NAME: ''\n\nDATASETS:\n  ROOT: '\/kaggle\/input\/pascal-voc-2012\/VOC2012'\n\nSOLVER:\n  MAX_EPOCHS: 15\n  CHECKPOINT_PERIOD: 15\n\nOUTPUT_DIR: '\/kaggle\/working\/fcn.pytorch\/output'\n","d2e4beb6":"cd \/kaggle\/working\/fcn.pytorch\/engine","9cb04180":"%%writefile trainer.py\n# %load trainer.py\n\"\"\"\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n\"\"\"\n\nimport logging\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.handlers import ModelCheckpoint, Timer\nfrom ignite.metrics import Loss, RunningAverage\nfrom tensorboardX import SummaryWriter\n\nfrom data.transforms import build_untransform\nfrom data.transforms.transforms import COLORMAP\nimport utils_fcn\nimport utils_fcn.metric\n\nplt.switch_backend('agg')\n\n\ndef do_train(\n        cfg,\n        model,\n        train_loader,\n        val_loader,\n        optimizer,\n        loss_fn\n):\n    cm = np.array(COLORMAP).astype(np.uint8)\n    untransform = build_untransform(cfg)\n\n    log_period = cfg.SOLVER.LOG_PERIOD\n    checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD\n    epochs = cfg.SOLVER.MAX_EPOCHS\n    device = cfg.MODEL.DEVICE\n    output_dir = cfg.OUTPUT_DIR\n\n    logger = logging.getLogger(\"FCN_Model.train\")\n    logger.info(\"Start training\")\n    trainer = create_supervised_trainer(model, optimizer, loss_fn, device=device)\n    evaluator = create_supervised_evaluator(model, metrics={'mean_iu': utils_fcn.metric.Label_Accuracy(cfg.MODEL.NUM_CLASSES),\n                                                            'loss': Loss(loss_fn)}, device=device)\n#     checkpointer = ModelCheckpoint(output_dir, 'fcn',n_saved=10, require_empty=False)\n    timer = Timer(average=True)\n    writer = SummaryWriter(output_dir + '\/board')\n\n    # automatically adding handlers via a special `attach` method of `RunningAverage` handler\n    RunningAverage(output_transform=lambda x: x).attach(trainer, 'avg_loss')\n\n    # automatically adding handlers via a special `attach` method of `Checkpointer` handler\n#     trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'model': model.state_dict(),\n#                                                                      'optimizer': optimizer.state_dict()})\n\n    # automatically adding handlers via a special `attach` method of `Timer` handler\n    timer.attach(trainer, start=Events.EPOCH_STARTED, resume=Events.ITERATION_STARTED,\n                 pause=Events.ITERATION_COMPLETED, step=Events.ITERATION_COMPLETED)\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.ITERATION_COMPLETED)\n    def log_training_loss(engine):\n        iter = (engine.state.iteration - 1) % len(train_loader) + 1\n\n        if iter % log_period == 0:\n            logger.info(\"Epoch[{}] Iteration[{}\/{}] Loss: {:.3f}\"\n                        .format(engine.state.epoch, iter, len(train_loader), engine.state.metrics['avg_loss']))\n            writer.add_scalars(\"loss\", {'train': engine.state.metrics['avg_loss']}, engine.state.iteration)\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        evaluator.run(train_loader)\n        metrics = evaluator.state.metrics\n        mean_iu = metrics['mean_iu']\n        avg_loss = metrics['loss']\n        logger.info(\"Training Results - Epoch: {} Mean IU: {:.3f} Avg Loss: {:.3f}\"\n                    .format(engine.state.epoch, mean_iu, avg_loss))\n        writer.add_scalars(\"mean_iu\", {'train': mean_iu}, engine.state.epoch)\n\n    if val_loader is not None:\n        # adding handlers using `trainer.on` decorator API\n        @trainer.on(Events.EPOCH_COMPLETED)\n        def log_validation_results(engine):\n            evaluator.run(val_loader)\n            metrics = evaluator.state.metrics\n            mean_iu = metrics['mean_iu']\n            avg_loss = metrics['loss']\n            logger.info(\"Validation Results - Epoch: {} Mean IU: {:.3f} Avg Loss: {:.3f}\"\n                        .format(engine.state.epoch, mean_iu, avg_loss)\n                        )\n            writer.add_scalars(\"loss\", {'validation': avg_loss}, engine.state.iteration)\n            writer.add_scalars(\"mean_iu\", {'validation': mean_iu}, engine.state.epoch)\n\n    # adding handlers using `trainer.on` decorator API\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def print_times(engine):\n        logger.info('Epoch {} done. Time per batch: {:.3f}[s] Speed: {:.1f}[samples\/s]'\n                    .format(engine.state.epoch, timer.value() * timer.step_count,\n                            train_loader.batch_size \/ timer.value()))\n        timer.reset()\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def plot_output(engine):\n        model.eval()\n        dataset = val_loader.dataset\n        idx = np.random.choice(np.arange(len(dataset)), size=1).item()\n        val_x, val_y = dataset[idx]\n        val_x = val_x.to(device)\n        with torch.no_grad():\n            pred_y = model(val_x.unsqueeze(0))\n\n        orig_img, val_y = untransform(val_x.cpu().data, val_y)\n        pred_y = pred_y.max(1)[1].cpu().data[0].numpy()\n        pred_val = cm[pred_y]\n        seg_val = cm[val_y]\n\n        # matplotlib\n        fig = plt.figure(figsize=(9, 3))\n        plt.subplot(131)\n        plt.imshow(orig_img)\n        plt.axis(\"off\")\n\n        plt.subplot(132)\n        plt.imshow(seg_val)\n        plt.axis(\"off\")\n\n        plt.subplot(133)\n        plt.imshow(pred_val)\n        plt.axis(\"off\")\n        writer.add_figure('show_result', fig, engine.state.iteration)\n\n    trainer.run(train_loader, max_epochs=epochs)\n    writer.close()\n","9ff8cb12":"cd \/kaggle\/working\/fcn.pytorch\/tools","b3a3104d":"%%writefile train_fcn.py\n# %load train_fcn.py\n\"\"\"\n@author:  sherlock\n@contact: sherlockliao01@gmail.com\n\"\"\"\n\nimport argparse\nimport os\nimport sys\nfrom os import mkdir\n\nsys.path.append('.')\nfrom config import cfg\nfrom data import make_data_loader\nfrom engine.trainer import do_train\nfrom modeling import build_fcn_model\nfrom solver import make_optimizer\nimport utils_fcn\nimport utils_fcn.logger\nfrom layers.cross_entropy2d import cross_entropy2d\n\n\ndef train(cfg):\n    model = build_fcn_model(cfg)\n\n    optimizer = make_optimizer(cfg, model)\n\n    arguments = {}\n\n    data_loader = make_data_loader(cfg, is_train=True)\n    val_loader = make_data_loader(cfg, is_train=False)\n\n    do_train(\n        cfg,\n        model,\n        data_loader,\n        val_loader,\n        optimizer,\n        cross_entropy2d,\n    )\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"PyTorch FCN Training\")\n    parser.add_argument(\n        \"--config_file\", default=\"\", help=\"path to config file\", type=str\n    )\n    parser.add_argument(\"opts\", help=\"Modify config options using the command-line\", default=None,\n                        nargs=argparse.REMAINDER)\n\n    args = parser.parse_args()\n\n    num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n\n    if args.config_file != \"\":\n        cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n\n    output_dir = cfg.OUTPUT_DIR\n    if output_dir and not os.path.exists(output_dir):\n        mkdir(output_dir)\n\n    logger = utils_fcn.logger.setup_logger(\"FCN_Model\", output_dir, 0)\n    logger.info(\"Using {} GPUS\".format(num_gpus))\n    logger.info(args)\n\n    if args.config_file != \"\":\n        logger.info(\"Loaded configuration file {}\".format(args.config_file))\n        with open(args.config_file, 'r') as cf:\n            config_str = \"\\n\" + cf.read()\n            logger.info(config_str)\n    logger.info(\"Running with config:\\n{}\".format(cfg))\n\n    train(cfg)\n\n\nif __name__ == '__main__':\n    main()\n","d2bc9e91":"cd \/kaggle\/working\/fcn.pytorch","780ee3d6":"!python tools\/train_fcn.py --config_file='configs\/train_fcn32s.yml'","60049631":"cd  \/kaggle\/working\/fcn.pytorch\/output","842abf50":"def dfs_get_zip_file(input_path,result):\n\n#\n    files = os.listdir(input_path)\n    for file in files:\n        if os.path.isdir(input_path+'\/'+file):\n            dfs_get_zip_file(input_path+'\/'+file,result)\n        else:\n            result.append(input_path+'\/'+file)\n\ndef zip_path(input_path,output_path,output_name):\n\n    f = zipfile.ZipFile(output_path+'\/'+output_name,'w',zipfile.ZIP_DEFLATED)\n    filelists = []\n    dfs_get_zip_file(input_path,filelists)\n    for file in filelists:\n        f.write(file)\n    f.close()\n    return output_path+r\"\/\"+output_name\n# if __name__ == '__main__':\n# \u00a0\u00a0\u00a0\u00a0zip_path(r'\/kaggle\/working\/fcn.pytorch\/output\/board','\/kaggle\/working\/','boa.zip')\n","0ccc3b7f":"import zipfile\nimport os\nzip_path('\/kaggle\/working\/fcn.pytorch\/output\/board','\/kaggle\/working\/','boa.zip')","e190a55b":"kaggle\/working\/fcn.pytorch\/output","2ac8549b":"    import os\n    os.chdir(r'\/kaggle\/working')","77624789":"    from IPython.display import FileLink\n    FileLink('.\/fcn.pytorch\/output')","01c41010":"\/kaggle\/input\/pascal-voc-2012\/VOC2012"}}