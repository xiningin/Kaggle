{"cell_type":{"d1236c92":"code","078890ca":"code","58027c7e":"code","efa2adb3":"code","c0124c76":"code","9b146d6b":"code","6a6f7f02":"code","4d0bd827":"code","9a49f1ed":"code","8ea458db":"code","05a9d38f":"code","41605e49":"code","5e85f2f4":"code","2380dac6":"code","8c1a9f12":"code","c4a17574":"code","d1f566a6":"code","94c84d8a":"code","283c8a3b":"code","ae4c8237":"code","5692554e":"code","11af33c1":"code","682c4699":"code","ae524753":"code","727e9cb9":"code","479bad3a":"code","dcf11144":"code","89f7976c":"code","0cb8553b":"code","9ed679d5":"markdown","4fc56720":"markdown","b56224c1":"markdown","f16d8129":"markdown","c8f3151f":"markdown","d8228427":"markdown","e9f876a5":"markdown","ec5fecea":"markdown","080681b9":"markdown","bababae8":"markdown","f0913860":"markdown","6b9cc346":"markdown","9dbd1d9e":"markdown","760cf636":"markdown","1c9c03cd":"markdown","3cb16712":"markdown","a93dbbe5":"markdown"},"source":{"d1236c92":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline  \n\nimport time\nstart_time = time.time()\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport pandas as pd","078890ca":"tweets = \"..\/input\"\nembedding_path = \"..\/input\/crawl-300d-2M.vec\"  #where word2vector model is \n\ndf_Trump = pd.read_csv(os.path.join(tweets,\"DonaldTrump.csv\"))\ndf_Bernie = pd.read_csv(os.path.join(tweets, \"BernieSanders.csv\"))\ndf_Joe = pd.read_csv(os.path.join(tweets, \"JoeBiden.csv\"))\ndf_Elizabeth = pd.read_csv(os.path.join(tweets, \"ElizabethWarren.csv\"))\ndf_politics = pd.concat((df_Trump, df_Bernie, df_Joe, df_Elizabeth), axis=0)\ndf_politics.head()","58027c7e":"df_politics.shape","efa2adb3":"embed_size = 300\nmax_features = 130000\nmax_len = 220\n\ndf_politics[\"text\"].fillna(\"no comment\")   #if there is any \"None\" text in data, delete the entire row\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]   #Negative feeling lists\nraw_text = df_politics[\"text\"].str.lower()   \n\ntk = Tokenizer(num_words = max_features, lower = True)  #Implement tokenizer model (it helps to divide the text into list of several words. For example, [I love apple] -> ['I', 'love', 'apple'])\ntk.fit_on_texts(raw_text)  # Tokenize tweets \ndf_politics[\"comment_seq\"] = tk.texts_to_sequences(raw_text)   #Then make them into a number. For example, \"I love apple \" -> [[16, 322, 2271]]. Insert the printed number into the 'df_politics' table\n\ntweets_pad_sequences = pad_sequences(df_politics.comment_seq, maxlen = max_len) #each row of the table has different length of \"comment_seq\". Make them into equal length of vector. \nprint(\"The vectorized tweet's shape is: \", tweets_pad_sequences.shape) # Each text has transformed into list of numbers which has length of 84. \n\ndf_politics[['text', 'comment_seq']]","c0124c76":"# def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n# embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path, encoding =\"utf-8\"))   #This code is to open embedding \"Glove model\"","9b146d6b":"# word_list = tk.word_index\n# n_words = min(max_features, len(word_list))\n# print(\"number of used words: {}\".format(len(word_list)))  #Number of the whole words used in tweet data \n# embedding_matrix = np.zeros((n_words+1, embed_size)) \n# for word, i in word_list.items():\n#     if i >= max_features: continue\n#     embedding_vector = embedding_index.get(word)\n#     if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n\n# embedding_matrix[0].shape","6a6f7f02":"model = load_model(\"..\/input\/best_model.hdf5\")","4d0bd827":"model.summary() ","9a49f1ed":"pred = model.predict(tweets_pad_sequences, batch_size = 1024, verbose = 1)","8ea458db":"pred.max()","05a9d38f":"toxic_predictions = pd.DataFrame(columns=list_classes, data=pred)\ntoxic_predictions['id'] = df_politics['date'].values\ntoxic_predictions['text'] = df_politics['text'].values\ntoxic_predictions.head()","41605e49":"toxic_predictions[list_classes].describe()","5e85f2f4":"toxic_predictions['username'] = df_politics['username'].values\ntoxic_predictions['text'] = df_politics['text'].values\ntoxic_predictions.tail()","2380dac6":"for neg_word in ['toxic', 'insult', 'identity_hate']:\n  pd.set_option('display.max_colwidth', -1)\n  temp = toxic_predictions[toxic_predictions[neg_word] == max(toxic_predictions[neg_word])]\n  print('The most {} text: {}'.format(neg_word, temp['text'].values))\n  print(temp['username'])","8c1a9f12":"Trump_predictions = toxic_predictions[toxic_predictions['username'] == 'realDonaldTrump']\nSanders_predictions = toxic_predictions[toxic_predictions['username'] == 'BernieSanders']\nWarren_predictions = toxic_predictions[toxic_predictions['username'] == 'ewarren']\nBiden_predictions = toxic_predictions[toxic_predictions['username'] == 'JoeBiden']","c4a17574":"#Trump Summary\nTrump_predictions[list_classes].describe()","d1f566a6":"#Sanders Summary\nSanders_predictions[list_classes].describe()","94c84d8a":"#Warren Summary\nWarren_predictions[list_classes].describe()","283c8a3b":"#Biden Summary\nBiden_predictions[list_classes].describe()","ae4c8237":"x=toxic_predictions.iloc[:,0:6].sum()\n#plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.index, x.values, alpha=0.8)\nplt.title(\"# per class\")\nplt.ylabel('# of Occurrences', fontsize=12)\nplt.xlabel('Type ', fontsize=12)\n#adding the text labels\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()\/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()","5692554e":"temp_df=toxic_predictions.iloc[:,0:6:]\ncorr=temp_df.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr,\n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values, annot=True)","11af33c1":"melt_df = pd.melt(toxic_predictions, value_vars=list_classes, id_vars='username')\nsns.violinplot(x='variable', y='value', hue='username', data=melt_df)\nplt.show()","682c4699":"print(\"Trump: \" + Trump_predictions.loc[Trump_predictions['toxic'].idxmax()]['text'])","ae524753":"print(Trump_predictions.sort_values(by=['toxic'], ascending=False)['text'].head(10).values)","727e9cb9":"print(Sanders_predictions.sort_values(by=['toxic'], ascending=False)['text'].head(10).values)","479bad3a":"print(Warren_predictions.sort_values(by=['toxic'], ascending=False)['text'].head(10).values)","dcf11144":"print(Biden_predictions.sort_values(by=['toxic'], ascending=False)['text'].head(10).values)","89f7976c":"import re\ntotal = []\nnum = 0\ncandidates = ['Trump', 'Sanders','Biden','Warren']\nfor df_candidate in [df_Trump, df_Bernie, df_Joe, df_Elizabeth]:\n    cd_list = [candidates[num]]\n    for candidate in candidates:\n        count = 0\n        for i in df_candidate['text'].values:\n            if re.search(candidate, i):\n                temp = len(re.findall(candidate, i))\n                count+=temp\n        cd_list.append(count)\n    total.append(cd_list)\n    num+=1\n","0cb8553b":"header = ['','Trump', 'Sanders','Biden','Warren'] \npd.DataFrame(total, columns=header, index= None)","9ed679d5":"WOW! This model has 99.75% accuracy! I really didn't expect that. <br>\nThis means this model can almost 100% distinguish toxic words from the tweets. <br>\nThen let's see the summary of this distinguishment","4fc56720":"### Tokenizer\n\n\n1.   Separe full text into list of words. For example,\n\n> 'I love you' => ['I', 'love', 'you']\n\n2.   Transform list of words into list of numbers. For example,\n\n>['I', 'love', 'you'] => [16, 322, 22]\n\n3. Make each list of numbers into vectorized value. For example,\n```\narray([[    0,     0,     0, ...,    30, 10547,    14],\n       [    0,     0,     0, ...,    97,     2,   759],\n       [    0,     0,     0, ...,   329,   488,   120],\n       ...,\n       [    0,     0,     0, ...,    11,     7, 25414],\n       [    0,     0,     0, ...,    11,     7, 25415],\n       [    0,     0,     0, ...,    11,     7, 25419]], dtype=int32)\n```\n\n","b56224c1":"### How many times did the candidates mention others?","f16d8129":"### Distribution of each candwidate\nvery skewed distribution....Unlike what I expected, candidates show realtively low negative feelings in their tweets. <br>\nHmm...Does this prove that candidates use clean words? Or....Is this Facebook's fault? \n","c8f3151f":"Not all tweets show only one type of feeling. <br>\nSo, I tried to see what feeling comes frequent with which feeling. ","d8228427":"First, I compared the occurence of each negative feelings. <br>\nPolticians showed the greatest feeling of toxic, followed by obscene, and insult.","e9f876a5":"### Number of the data\nThere are total of 11762 tweets. This might seem like a lot of data, but actually relatively small data compared to those which is used in other machine learning projects. <br>\n\n\n\n\n*   Donald Trump: 3929 tweets\n*   Elizabeth Warren: 3645 tweets \n*   Bernie Sanders: 2681 tweets <br>\n* Joe Biden: 1507 tweets <br>\n\n\n\n\n\n\n","ec5fecea":"### Let's check which tweet showed the greatest negative feeling(toxic, insult, identity_hate)\nInteresting! It seems relatively correct ","080681b9":"### Plotting","bababae8":"### Data Preview\nThere are 4 dataset: Trump, and 3 Democrat party Candidates, Joe Biden, Elizabeth Warren and Bernie Sanders <br>\nI collected their tweets from '2019-01-01' to '2019-11-12'. <br>\nI merged individual csv files into one df_tweet file (df_politics), just to make sure every dataset is perfectly arranged","f0913860":"### Machine Learning Model\nI have pre-trained model, so I loaded actual trained model and make the predictions on our data.","6b9cc346":"It shows how the model actually looks like. This model is mixture of 'LSTM' and 'CNN' model. ","9dbd1d9e":"### Compare Politicians' negative Feelings! ","760cf636":"### Embedding Words into Vector space\nNow I need to construct an embedding index, that puts each one of the words into a 300-dimensional vector space.<br>\nI used 'FastText' model which was developed from Facebook in 2017. <br>\nThis is a very revolutionary model, far better than 'GLOVE' or 'Word2Vec'. It calculates the distance between each words in its semantics, and can be redistributed even though there is a new word.\n","1c9c03cd":"Let's train our web-crawled tweets using 'LSTM-CNN' model.","3cb16712":"### Required Library","a93dbbe5":"## Sentiment Analysis on 2020 US presidential Election Candidates using Twitter Data.\n**Data Information**: Tweets from 1 Republican Party candidate(Donald Trump) and 3 Democrat Party candidates(Joe Biden, Elizabeth Warren, Bernie Sanders) <br>\n**Question**: Which Candidate is more negative on which topic? <br>\n**Method**: Word Embedding Model(FastText), LSTM-CNN model (RCNN) "}}