{"cell_type":{"bb74f158":"code","7ff34b75":"code","dac820a6":"code","c9ba39e5":"code","9d7cb885":"code","88ace00a":"code","a4cd7723":"code","56962b55":"code","860cce97":"code","d83d2489":"code","d8a949dc":"code","e747ad8f":"code","abbc7f0d":"code","9c0c8c79":"code","5c353a27":"code","d275a6d1":"code","0750659f":"code","5c536546":"code","518a8101":"code","017242a8":"code","e9b92c9b":"code","7da50dee":"code","64d10f6c":"markdown"},"source":{"bb74f158":"#Importing Libraries\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Input,Lambda\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns","7ff34b75":"#Defining the image size as VGG16 has got trained in image size of (224,224)\nIMAGE_SIZE=[224,224]","dac820a6":"#Saving the data location path in variables\ndf_train='..\/input\/cat-and-dog\/training_set'\ndf_test='...\/input\/cat-and-dog\/test_set'","c9ba39e5":"#Importing the VGG16 model and removing the last layer \"include_top=False\"\n#We have to remove the last layer because we need to predict for 2 classes and VGG16 is 1000 class classification model\nvgg=VGG16(input_shape=IMAGE_SIZE+[3],weights='imagenet',include_top=False)","9d7cb885":"#Setting the weight updation of all layers as False as we will not train them\nfor layers in vgg.layers:\n  layers.trainable=False","88ace00a":"#Flattening the output of VGG16 model\nx=Flatten()(vgg.output)","a4cd7723":"#Adding a dense layer for prediction\nprediction=Dense(2,activation='sigmoid')(x)","56962b55":"#Instantiating a model\nmodel=Model(inputs=vgg.input,outputs=prediction)","860cce97":"#Understanding the parameters of model\nmodel.summary()","d83d2489":"#Compiling the model\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","d8a949dc":"#setting the parameters for train dataset\ntrain_data=ImageDataGenerator(rescale=(1\/255.0),\n                              zoom_range=0.2,\n                              rotation_range=0.2,\n                              horizontal_flip=True,\n                              shear_range=0.1)","e747ad8f":"#setting the parameters for test dataset \ntest_data=ImageDataGenerator(rescale=(1\/255.0))","abbc7f0d":"#Creating more images using ImageDataGenerator class\ntraining=train_data.flow_from_directory(directory='..\/input\/cat-and-dog\/training_set\/training_set', target_size=(224,224), \n                                           classes=['cats', 'dogs'], batch_size=10, shuffle=False)\ntesting=test_data.flow_from_directory(directory= '..\/input\/cat-and-dog\/test_set\/test_set', target_size=(224,224), classes=['cats', 'dogs'], \n                                       batch_size=10, shuffle=False)","9c0c8c79":"#fitting the model\nanswer=model.fit(training,validation_data=testing,epochs=10,steps_per_epoch=len(training),validation_steps=len(testing))","5c353a27":"#Checking the keys stored in the variable answer\nanswer.history.keys","d275a6d1":"#Plotting the training accuracy and validation accuracy graphs\nplt.plot(answer.history['val_accuracy'],label=['Validation Accuracy'])\nplt.plot(answer.history['accuracy'],label=['Training Accuracy'])\nplt.legend()","0750659f":"#plotting the training and validation loss graphs\nplt.plot(answer.history['val_loss'],label=['Validation Loss'])\nplt.plot(answer.history['loss'],label=['Training Loss'])\nplt.legend()","5c536546":"#predicting using the model on the test data\ny_pred=model.predict(testing)","518a8101":"#Storing the true values\ny_test=testing.classes","017242a8":"#Getting the classification report\nreport =classification_report(y_true=testing.classes, y_pred=np.argmax(y_pred, axis=-1))\nprint(report)","e9b92c9b":"#Plotting the confusion matrix\ncm = confusion_matrix(y_true=testing.classes, y_pred=np.argmax(y_pred, axis=-1))\nsns.heatmap(cm,annot=True)\nprint(cm)","7da50dee":"dat = '..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4009.jpg' # For cat images\ndat1 = '..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4006.jpg' # For Dog images\n\nimport numpy as np\nfrom keras.preprocessing import image\ntest1 = image.load_img(dat1, target_size = (224, 224)) # Change when directory change \n\ntest= image.load_img(dat1, target_size = (224, 224)) # Change when directory change \ntest= image.img_to_array(test)\ntest = np.expand_dims(test, axis = 0)\nresult = model.predict(test)\ntraining.class_indices\nif result[0][0] == 1:\n  prediction = 'cat'\nelse:\n  prediction = 'dog'\n\nprint(prediction)\nprint('\\n')\nplt.imshow(test1)","64d10f6c":"**Predicting using the model**"}}