{"cell_type":{"f5d994ea":"code","122d1b34":"code","3c71e2d7":"code","dc9d1c19":"code","9d64295f":"code","fe364fb7":"code","b83b453a":"code","6ce84dcb":"code","4b66892c":"code","274f70fa":"code","bee51fe9":"code","b31023de":"code","883a3770":"code","78a62bdf":"code","5f52d5a4":"code","f86c4a5e":"code","1eb674c1":"code","409aa5d0":"code","a0b2ad73":"code","5749ffa8":"code","39372048":"code","ea1b1a51":"code","49a4a2a4":"code","c9c8ce53":"code","abc2e8cf":"code","024cc85e":"code","025e4eb1":"markdown","78b04e0b":"markdown","807dec86":"markdown","55e31a38":"markdown","fffafe30":"markdown","03fec758":"markdown","71a74a86":"markdown","d0a5dd6d":"markdown","c1e63679":"markdown","78ddad89":"markdown","affccc10":"markdown","3d1e71af":"markdown","f896539d":"markdown","fef73acd":"markdown","e9917ca4":"markdown","2da326eb":"markdown"},"source":{"f5d994ea":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.datasets import load_boston\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.graphics.gofplots import ProbPlot\nfrom patsy import dmatrices","122d1b34":"df = pd.read_csv('..\/input\/world-happiness-report-2019.csv')\ndf.head()","3c71e2d7":"df.shape","dc9d1c19":"df.dtypes","9d64295f":"plt.figure(1, figsize = (30, 40))\nn = 0\nfor x in ['SD of Ladder', 'Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption', 'Generosity', \n          'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']:\n    n += 1\n    plt.subplot(3, 3, n)\n    plt.subplots_adjust(hspace = 0.2, wspace = 0.4)\n    plt.scatter(df['Ladder'], df[x])\n    plt.title('{} plot'.format(x))\nplt.show()","fe364fb7":"df.isnull().sum()\ndf = df.replace([np.inf, -np.inf], np.nan)\ndf = df.dropna()","b83b453a":"plt.style.use('fivethirtyeight')","6ce84dcb":"plt.figure(1, figsize = (30, 40))\nn = 0\nfor x in ['SD of Ladder', 'Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption', 'Generosity', \n          'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']:\n    n += 1\n    plt.subplot(3, 3, n)\n    plt.subplots_adjust(hspace = 0.2, wspace = 0.4)\n    sns.regplot(df['Ladder'], df[x])\n    plt.title('{} plot'.format(x))\nplt.show()","4b66892c":"Xa = pd.DataFrame(df, columns = ['SD of Ladder'])\nXb = pd.DataFrame(df, columns = ['Positive affect'])\nXc = pd.DataFrame(df, columns = ['Negative affect'])\nXd = pd.DataFrame(df, columns = ['Social support'])\nXe = pd.DataFrame(df, columns = ['Freedom'])\nXf = pd.DataFrame(df, columns = ['Corruption'])\nXg = pd.DataFrame(df, columns = ['Generosity'])\nXh = pd.DataFrame(df, columns = ['Log of GDP\\nper capita'])\nXi = pd.DataFrame(df, columns = ['Healthy life\\nexpectancy'])\ny = pd.DataFrame(df.Ladder)\n\nmodel = sm.OLS(y, sm.add_constant(Xi))\nmodel_fit = model.fit()\ndataframe = pd.concat([Xi, y], axis = 1)","274f70fa":"yhat = model_fit.fittedvalues\nresiduals = model_fit.resid\nnormal_residuals = model_fit.get_influence().resid_studentized_internal\nabs_sqrt_residuals = np.sqrt(np.abs(normal_residuals))\nmodel_abs_residuals = np.abs(residuals)\nleverage = model_fit.get_influence().hat_matrix_diag\ncooks_dis = model_fit.get_influence().cooks_distance[0]","bee51fe9":"plot_lm_1 = plt.figure(1, figsize = (15, 15))\nplot_lm_1.axes[0] = sns.residplot(yhat, dataframe.columns[-1], data = dataframe, lowess = True, scatter_kws = {'alpha': 0.8},\n                                 line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n\nn = 0\nfor x in ['SD of Ladder', 'Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption', 'Generosity', \n          'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']:\n    n += 1\n    model = sm.OLS(y, sm.add_constant(pd.DataFrame(df, columns = [x])))\n    model_fit = model.fit()\n    dataframe = pd.concat([df[x], y], axis = 1)\n    yhat = model_fit.fittedvalues\n    residuals = model_fit.resid\n    normal_residuals = model_fit.get_influence().resid_studentized_internal\n    abs_sqrt_residuals = np.sqrt(np.abs(normal_residuals))\n    model_abs_residuals = np.abs(residuals)\n    leverage = model_fit.get_influence().hat_matrix_diag\n    cooks_dis = model_fit.get_influence().cooks_distance[0]\n    plt.subplot(3, 3, n)\n    plt.subplots_adjust(hspace = 0.5, wspace = 1)\n    sns.residplot(yhat, dataframe.columns[-1], data = dataframe, lowess = True, scatter_kws = {'alpha': 0.8},\n                                 line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n    plt.title('{}: yhat vs residuals'.format(x))\n    plt.xlabel('yhat')\n    plt.ylabel('residuals')\nplt.show()","b31023de":"plot_lm_1 = plt.figure(1, figsize = (15, 15))\nplot_lm_1.axes[0] = sns.residplot(yhat, dataframe.columns[-1], data = dataframe, lowess = True, scatter_kws = {'alpha': 0.8},\n                                 line_kws = {'color': 'red', 'lw': 1, 'alpha': 0.8})\n\nn = 0\nfor x in ['SD of Ladder', 'Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption', 'Generosity', \n          'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']:\n    n += 1\n    model = sm.OLS(y, sm.add_constant(pd.DataFrame(df, columns = [x])))\n    model_fit = model.fit()\n    dataframe = pd.concat([df[x], y], axis = 1)\n    yhat = model_fit.fittedvalues\n    residuals = model_fit.resid\n    normal_residuals = model_fit.get_influence().resid_studentized_internal\n    abs_sqrt_residuals = np.sqrt(np.abs(normal_residuals))\n    model_abs_residuals = np.abs(residuals)\n    leverage = model_fit.get_influence().hat_matrix_diag\n    cooks_dis = model_fit.get_influence().cooks_distance[0]\n    plt.subplot(3, 3, n)\n    plt.subplots_adjust(hspace = 0.5, wspace = 1)\n    \n    plt.scatter(yhat, abs_sqrt_residuals, alpha = 0.5)\n    sns.regplot(yhat, abs_sqrt_residuals, scatter = False, ci = False, lowess = True, \n                line_kws = {'color': 'red', 'lw':1, 'alpha': 0.8})\n    plt.title('{}: yhat vs sqrt resids'.format(x))\n    plt.xlabel('yhat')\n    plt.ylabel('$\\sqrt{Standardized Residuals}$')\nplt.show()","883a3770":"plot_lm_4 = plt.figure(1, figsize = (15, 15))\n\nn = 0\nfor x in ['SD of Ladder', 'Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption', 'Generosity', \n          'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']:\n    n += 1\n    model = sm.OLS(y, sm.add_constant(pd.DataFrame(df, columns = [x])))\n    model_fit = model.fit()\n    dataframe = pd.concat([df[x], y], axis = 1)\n    yhat = model_fit.fittedvalues\n    residuals = model_fit.resid\n    normal_residuals = model_fit.get_influence().resid_studentized_internal\n    abs_sqrt_residuals = np.sqrt(np.abs(normal_residuals))\n    model_abs_residuals = np.abs(residuals)\n    leverage = model_fit.get_influence().hat_matrix_diag\n    cooks_dis = model_fit.get_influence().cooks_distance[0]\n    plt.subplot(3, 3, n)\n    plt.subplots_adjust(hspace = 0.5, wspace = 1)\n    \n    plt.scatter(leverage, normal_residuals, alpha = 0.5)\n    sns.regplot(leverage, normal_residuals, scatter = False, ci = False, lowess = True, line_kws = {'color': 'red', 'lw': 1,\n                                                                                               'alpha': 0.8})\n    \n    plt.title('{}: Resids vs Levrg'.format(x))\n    plt.xlabel('Leverage')\n    plt.ylabel('standard residuals')\nplt.show()","78a62bdf":"X1 = df[['Social support', 'Ladder']].iloc[:, :].values\nX2 = df[['Freedom', 'Ladder']].iloc[:, :].values\nX3 = df[['Corruption', 'Ladder']].iloc[:, :].values\nX4 = df[['Generosity', 'Ladder']].iloc[:, :].values\nX5 = df[['Log of GDP\\nper capita', 'Ladder']].iloc[:, :].values\nX6 = df[['Healthy life\\nexpectancy', 'Ladder']].iloc[:, :].values\nalgorithm = (KMeans(n_clusters = 4, init = 'k-means++', n_init = 10, max_iter = 300,\n            tol = 0.0001, random_state = 111, algorithm = 'elkan')\n            )\nalgorithm.fit(X1)\nlabels1 = algorithm.labels_\ncentroids1 = algorithm.cluster_centers_","5f52d5a4":"algorithm = (KMeans(n_clusters = 3, init='k-means++', n_init = 10 , max_iter=300, \n                        tol=0.0001,  random_state= 111, algorithm='elkan') )\nalgorithm.fit(X1)\nlabels1 = algorithm.labels_\ncentroids1 = algorithm.cluster_centers_","f86c4a5e":"h = 0.02\nx_min, x_max = X1[:, 0].min() - 1, X1[:, 0].max() + 1\ny_min, y_max = X1[:, 1].min() - 1, X1[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])","1eb674c1":"plt.figure(1 , figsize = (15 , 7) )\nplt.clf()\nZ = Z.reshape(xx.shape)\nplt.imshow(Z , interpolation='nearest', \n           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n           cmap = plt.cm.Pastel2, aspect = 'auto', origin='lower')\n\nplt.scatter( x = 'Ladder' ,y = 'Social support' , data = df , c = labels1 , \n            s = 200 )\nplt.scatter(x = centroids1[: , 0] , y =  centroids1[: , 1] , s = 300 , c = 'red' , alpha = 0.5)\nplt.ylabel('Social support') , plt.xlabel('Ladder')\nplt.show()","409aa5d0":"m = df[['Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption', 'Generosity',\n        'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']]\ny = df['Ladder']\nmodel = sm.OLS(y,m).fit()\npredictions = model.predict(m)\nmodel.summary()","a0b2ad73":"n = df[['Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Corruption',\n        'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']]\ny = df['Ladder']\nmodel = sm.OLS(y,n).fit()\npredictions = model.predict(n)\nmodel.summary()","5749ffa8":"o = df[['Positive affect', 'Negative affect', 'Social support', 'Freedom',\n        'Log of GDP\\nper capita', 'Healthy life\\nexpectancy']]\ny = df['Ladder']\nmodel = sm.OLS(y,o).fit()\npredictions = model.predict(o)\nmodel.summary()","39372048":"df_cor = o.corr()\npd.DataFrame(np.linalg.inv(o.corr().values), index = df_cor.index, columns=df_cor.columns)","ea1b1a51":"p = df[['Positive affect', 'Negative affect', 'Social support', 'Freedom', 'Healthy life\\nexpectancy']]\ny = df['Ladder']\nmodel = sm.OLS(y, p).fit()\npredictions = model.predict(p)\nmodel.summary()","49a4a2a4":"q = df[['Positive affect', 'Negative affect', 'Social support', 'Healthy life\\nexpectancy']]\ny = df['Ladder']\nmodel = sm.OLS(y, q).fit()\npredictions = model.predict(q)\nmodel.summary()","c9c8ce53":"r = df[['Positive affect', 'Social support', 'Healthy life\\nexpectancy']]\ny = df['Ladder']\nmodel = sm.OLS(y, r).fit()\npredictions = model.predict(r)\nmodel.summary()","abc2e8cf":"df_cor = r.corr()\npd.DataFrame(np.linalg.inv(r.corr().values), index = df_cor.index, columns=df_cor.columns)","024cc85e":"plt.figure(1, figsize = (20, 10))\nn = 0\nfor x in ['Positive affect', 'Social support', 'Healthy life\\nexpectancy']:\n    n += 1\n    plt.subplot(1, 3, n)\n    plt.subplots_adjust(hspace = 1, wspace = 0.4)\n    sns.regplot(df['Ladder'], df[x])\n    plt.title('{} plot'.format(x))\nplt.show()","025e4eb1":"#### VIF are in the diagonals for each predictor. I removed Log GDP as it has VIF > 5","78b04e0b":"#### Removing predictors with P > 0.05 > |t| and removing predictors with VIF > 5.","807dec86":"### Fitting a linear regression model to each variable","55e31a38":"###### Here is a beginner analysis to a dataset. It includes some regression analysis and machine learning algorithms. I'm happy to receive comments on my work. \n","fffafe30":"#### Diagnostic plots","03fec758":"# World Happiness Report 2019 Data Analysis","71a74a86":"#### VIF calculation. Included predictors have VIF < 5","d0a5dd6d":"### Algorithm grouping","c1e63679":"#### I removed Generosity as it was basically insignificant.","78ddad89":"#### Exploring the data","affccc10":"#### Import the data","3d1e71af":"## Final model: 'r' vs. 'Ladder'. Included predictors are considered significant to increase happiness.","f896539d":"#### Remaining predictors are significant","fef73acd":"#### I removed Corruption from the model as it was an insignificant predictor.","e9917ca4":"#### Removing Negative affect and Freedom.","2da326eb":"### T-test and Variance Inflation factor"}}