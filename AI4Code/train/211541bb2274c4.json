{"cell_type":{"100c8285":"code","23f105a1":"code","6f598e95":"code","e559d869":"code","f3aca34e":"code","94caeb64":"code","b5240568":"code","2323acf3":"code","c08a5349":"code","25430089":"code","aaec17cf":"code","cb118d86":"code","65995c1e":"code","ab208324":"code","fc63eca0":"code","0b644f36":"code","4d15a451":"code","a5af0db0":"code","cba6a2bf":"code","50118524":"code","07268ed0":"code","28504fce":"code","4762371f":"markdown","e4db4a25":"markdown","70342479":"markdown","92d4b95b":"markdown","c454dc3f":"markdown"},"source":{"100c8285":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","23f105a1":"import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium","6f598e95":"dataset=pd.read_csv('..\/input\/Advertising.csv')\ndataset.head()","e559d869":"dataset.iloc[:, 1:].describe()","f3aca34e":"plt.style.use('seaborn')\ndataset[['TV','Radio', 'Newspaper']].boxplot()\nplt.show()","94caeb64":"corr_matrix=dataset.iloc[:,1:].corr()\nplt.figure(figsize=(10,8))\n\nplt.subplot2grid((1,1),(0,0))\nsns.heatmap(corr_matrix, cmap='PuOr', annot=True, linewidths=3)\nplt.title('Correlation Matrix including response variable', fontsize=20)\nplt.show()","b5240568":"sns.pairplot(dataset.iloc[:,1:])\nplt.show()","2323acf3":"# Scatter plot TV and Sales\nplt.figure(figsize=(20,8))\nplt.tight_layout\n\nplt.subplot(1,3,1)\nplt.scatter(dataset['TV'], dataset['Sales'], alpha=0.5, color='red')\nplt.title('TV and Sales', fontsize=18, fontweight='bold')\n\nplt.subplot(1,3,2)\nplt.scatter(dataset['Radio'], dataset['Sales'], alpha=0.5, color='green')\nplt.title('Radio and Sales', fontsize=18, fontweight='bold')\n\nplt.subplot(1,3,3)\nplt.scatter(dataset['Newspaper'], dataset['Sales'], alpha=0.5)\nplt.title('Newspaper and Sales', fontsize=18, fontweight='bold')\n\nplt.show()","c08a5349":"# preparation of the data to our purposes\ny=dataset['Sales']\nX=dataset[['TV']]\nX=sm.add_constant(X)","25430089":"model1=sm.regression.linear_model.OLS(y,X)\nlinear_regression=model1.fit()\nlinear_regression.summary()","aaec17cf":"coefficients=np.array(linear_regression.params)\ncoefficients","cb118d86":"y_predicted=linear_regression.predict(X)","65995c1e":"plt.figure(figsize=(15,10))\n\nplt.subplot2grid((2,3),(0,0),colspan=2,rowspan=2)\nplt.scatter(X.iloc[:,1],y, color='gray', label='Observations')\nplt.plot(X.iloc[:,1], y_predicted, color='red', linewidth=3, label=\"y= %.2f + %.2fx\" %(coefficients[0], coefficients[1]))\nplt.legend(fontsize=14)\nplt.title('TV vs Sales', fontsize=18, fontweight='bold')\n\nplt.subplot2grid((2,3),(0,2),colspan=2)\nplt.scatter(X.iloc[:,1],linear_regression.resid_pearson)\nplt.plot(X.iloc[:,1], [3]*len(X.iloc[:,1]), color='red', linestyle='--', alpha=0.5)\nplt.plot(X.iloc[:,1], [-3]*len(X.iloc[:,1]), color='red', linestyle='--',alpha=0.5)\nplt.plot(X.iloc[:,1], [0]*len(X.iloc[:,1]), color='red', linestyle='--', alpha=0.5)\nplt.title('Residuals', fontsize=18)\n\nplt.subplot2grid((2,3),(1,2))\nplt.hist(linear_regression.resid_pearson, alpha=0.6)\nplt.title('Residuals Distributions', fontsize=18)\n\n\nplt.show()","ab208324":"from sklearn import linear_model","fc63eca0":"X=dataset['TV']\nX=np.array(X).reshape(len(X),1)\ny=dataset['Sales']\n\nlinear_regression=linear_model.LinearRegression()\nlinear_regression=linear_regression.fit(X,y)\nprint(linear_regression.coef_,linear_regression.intercept_, sep='   ')","0b644f36":"print('The first 5 predicted values are:', linear_regression.predict(X)[:5])","4d15a451":"import random\n\ndef random_w(p):\n    return np.array([np.random.normal() for j in range(p)])\n\ndef hypothesis(X,w):\n    return np.dot(X,w)\n\ndef loss(X,w,y):\n    return hypothesis(X,w) -y\n\ndef squared_loss(X,w,y):\n    return loss(X,w,y)**2\n\ndef gradient(X,w,y):\n    gradients= list()\n    n=float(len(y))\n    for j in range(len(w)):\n        gradients.append(np.sum(loss(X,w,y)*X[:,j])\/n)\n    return gradients\n\ndef update(X,w,y, alpha = 0.001):\n    return [t - alpha*g for t,g in zip(w,gradient(X,w,y))]\n\ndef optimize(X, y, alpha = 0.001, eta = 10**-12, iterations=1000):\n    w=random_w(X.shape[1])\n    path = list()\n    for k in range(iterations):\n        SSL=np.sum(squared_loss(X,w,y))\n        new_w=update(X,w,y, alpha=alpha)\n        new_SSL=np.sum(squared_loss(X,new_w,y))\n        w=new_w\n        if k >= 5 and (new_SSL - SSL <= eta and new_SSL-SSL > -eta):\n            path.append(new_SSL)\n            return w, path\n        if k % (iterations \/ 20)==0:\n            path.append(new_SSL)\n    return w, path","a5af0db0":"#preparing the variables and standardizing it\nfrom sklearn.preprocessing import StandardScaler\nX=dataset[['TV']]\nobservations = len(dataset)\nstandarddization=StandardScaler()\nXst = standarddization.fit_transform(X)\noriginal_means=standarddization.mean_\noriginal_stds=standarddization.var_**0.5\nXst = np.column_stack((Xst, np.ones(observations)))\ny = dataset['Sales']","cba6a2bf":"#using the gradient descent\nalpha = 0.02\nw, path = optimize(Xst, y, alpha, eta = 10**-12, \\\niterations = 20000)\nprint (\"These are our final standardized coefficients: \" + ', '.join(map(lambda x: \"%0.4f\" % x, w)))","50118524":"unstandardized_betas = w[:-1]\/original_stds\nunstandardized_bias=w[-1]-np.sum(original_means\/original_stds*w[:-1])\nprint(unstandardized_betas)\nprint(unstandardized_bias)","07268ed0":"import ipywidgets as widgets\nfrom IPython.display import Javascript, display\n\na=widgets.Dropdown(\n    options=list(dataset.columns)[1:-1],\n    value=list(dataset.columns)[1:-1][0],\n    description='Predictor:',\n    disabled=False,\n)\ndisplay(a)\n\ndef run_all(ev):\n    display(Javascript('IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.ncells())'))\n\nbutton = widgets.Button(description=\"Run\")\nbutton.on_click(run_all)\ndisplay(button)","28504fce":"y=dataset['Sales']\nX=dataset[[a.value]]\nX=sm.add_constant(X)\n\nmodel1=sm.regression.linear_model.OLS(y,X)\nlinear_regression=model1.fit()\n\ny_predicted=linear_regression.predict(X)\ncoefficients=np.array(linear_regression.params)\n\nplt.figure(figsize=(15,10))\n\nplt.subplot2grid((2,3),(0,0),colspan=2,rowspan=2)\nplt.scatter(X.iloc[:,1],y, color='gray', label='Observations')\nplt.plot(X.iloc[:,1], y_predicted, color='red', linewidth=3, label=\"y= %.2f + %.2fx\" %(coefficients[0], coefficients[1]))\nplt.legend(fontsize=14)\nplt.title(a.value + ' vs Sales', fontsize=18, fontweight='bold')\n\nplt.subplot2grid((2,3),(0,2),colspan=2)\nplt.scatter(X.iloc[:,1],linear_regression.resid_pearson)\nplt.plot(X.iloc[:,1], [3]*len(X.iloc[:,1]), color='red', linestyle='--', alpha=0.5)\nplt.plot(X.iloc[:,1], [-3]*len(X.iloc[:,1]), color='red', linestyle='--',alpha=0.5)\nplt.plot(X.iloc[:,1], [0]*len(X.iloc[:,1]), color='red', linestyle='--', alpha=0.5)\nplt.title('Residuals', fontsize=18)\n\nplt.subplot2grid((2,3),(1,2))\nplt.hist(linear_regression.resid_pearson, alpha=0.6)\nplt.title('Residuals Distributions', fontsize=18)\n\n\nplt.show()","4762371f":"## **Testing any predictor using statmodel**","e4db4a25":"## **Using Gradient Descent**","70342479":"## **Loading the dataset to memory and displaying the first rows**","92d4b95b":"<hr>","c454dc3f":"## **SicKit-Learn Model**"}}