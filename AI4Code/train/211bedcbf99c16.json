{"cell_type":{"772e84db":"code","59d83f46":"code","c78cee46":"code","a86d8c84":"code","56739349":"code","55d93020":"code","4a5671bb":"code","50d048f8":"code","76510f42":"code","741d8618":"code","99058bde":"code","21204d6d":"code","8f6667f4":"code","533374fa":"code","081fa450":"code","f54b43a7":"code","79ff17ca":"code","4e581509":"code","ed66714e":"code","a1fa3cee":"markdown","131ffaa2":"markdown","b532c342":"markdown","3821115a":"markdown","15595f8a":"markdown","0179447f":"markdown","40a035c6":"markdown","d9c3ba92":"markdown","7d8df898":"markdown","fea4e79e":"markdown","9200105d":"markdown"},"source":{"772e84db":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import r2_score","59d83f46":"dataset_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndataset_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c78cee46":"dataset_train.head()","a86d8c84":"dataset_train.shape","56739349":"dataset_test.head()","55d93020":"dataset_test.shape","4a5671bb":"dataset = pd.concat([dataset_train, dataset_test])","50d048f8":"sns.heatmap(dataset.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')","76510f42":"null_value_train = dict(dataset.isnull().sum())\nfor i,j in null_value_train.items():\n    print(i,\"==>\",j)","741d8618":"dataset.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'Id'], axis=1, inplace=True)","99058bde":"dataset['MSZoning'] = dataset['MSZoning'].fillna(dataset['MSZoning'].mode())\ndataset['LotFrontage'] = dataset['LotFrontage'].fillna(dataset['LotFrontage'].mean())\ndataset['Utilities'] = dataset['Utilities'].fillna(dataset['Utilities'].mode())\ndataset['Exterior1st'] = dataset['Exterior1st'].fillna(dataset['Exterior1st'].mode())\ndataset['Exterior2nd'] = dataset['Exterior2nd'].fillna(dataset['Exterior2nd'].mode())\ndataset['MasVnrType'] = dataset['MasVnrType'].fillna(dataset['MasVnrType'].mode())\ndataset['MasVnrArea'] = dataset['MasVnrArea'].fillna(dataset['MasVnrArea'].mean())\ndataset['BsmtQual'] = dataset['BsmtQual'].fillna(dataset['BsmtQual'].mode())\ndataset['BsmtCond'] = dataset['BsmtCond'].fillna(dataset['BsmtCond'].mode())\ndataset['BsmtExposure'] = dataset['BsmtExposure'].fillna(dataset['BsmtExposure'].mode())\ndataset['BsmtFinType1'] = dataset['BsmtFinType1'].fillna(dataset['BsmtFinType1'].mode())\ndataset['BsmtFinSF1'] = dataset['BsmtFinSF1'].fillna(dataset['BsmtFinSF1'].mean())\ndataset['BsmtFinType2'] = dataset['BsmtFinType2'].fillna(dataset['BsmtFinType2'].mode())\ndataset['BsmtFinSF2'] = dataset['BsmtFinSF2'].fillna(dataset['BsmtFinSF2'].mean())\ndataset['BsmtUnfSF'] = dataset['BsmtUnfSF'].fillna(dataset['BsmtUnfSF'].mean())\ndataset['TotalBsmtSF'] = dataset['TotalBsmtSF'].fillna(dataset['TotalBsmtSF'].mean())\ndataset['Electrical'] = dataset['Electrical'].fillna(dataset['Electrical'].mode())\ndataset['BsmtFullBath'] = dataset['BsmtFullBath'].fillna(dataset['BsmtFullBath'].median())\ndataset['BsmtHalfBath'] = dataset['BsmtHalfBath'].fillna(dataset['BsmtHalfBath'].median())\ndataset['KitchenQual'] = dataset['KitchenQual'].fillna(dataset['KitchenQual'].mode())\ndataset['Functional'] = dataset['Functional'].fillna(dataset['Functional'].mode())        \ndataset['GarageType'] = dataset['GarageType'].fillna(dataset['GarageType'].mode())\ndataset['GarageYrBlt'] = dataset['GarageYrBlt'].fillna(dataset['GarageYrBlt'].median())\ndataset['GarageFinish'] = dataset['GarageFinish'].fillna(dataset['GarageFinish'].mode())\ndataset['GarageCars'] = dataset['GarageCars'].fillna(dataset['GarageCars'].median())\ndataset['GarageArea'] = dataset['GarageArea'].fillna(dataset['GarageArea'].mean())\ndataset['GarageQual'] = dataset['GarageQual'].fillna(dataset['GarageQual'].mode())        \ndataset['GarageCond'] = dataset['GarageCond'].fillna(dataset['GarageCond'].mode())\ndataset['FireplaceQu'] = dataset['FireplaceQu'].fillna(dataset['FireplaceQu'].mode())\ndataset['SaleType'] = dataset['SaleType'].fillna(dataset['SaleType'].mode())","21204d6d":"dataset = pd.get_dummies(dataset, drop_first=True)","8f6667f4":"dataset_train_1 = dataset.iloc[:1460, :]\ndataset_test_1 = dataset.iloc[1460:, :]","533374fa":"y_train = dataset_train_1['SalePrice'].values\ndataset_train_1 = dataset_train_1.drop('SalePrice', axis=1)\ndataset_test_1 = dataset_test_1.drop('SalePrice', axis=1)","081fa450":"X_train = dataset_train_1.iloc[:, :].values\nX_test = dataset_test_1.iloc[:, :].values","f54b43a7":"from xgboost import XGBRegressor\nregressor = XGBRegressor()\nregressor.fit(X_train, y_train)","79ff17ca":"y_pred_train = regressor.predict(X_train)\nprint(r2_score(y_train,y_pred_train))","4e581509":"y_pred_test = regressor.predict(X_test)","ed66714e":"output = pd.DataFrame({'Id': dataset_test.Id, 'SalePrice': y_pred_test})\noutput.to_csv('my_submission_house_prediction_3.csv', index=False)\nprint(\"Your submission was successfully saved!\")","a1fa3cee":"# Inserting new Values at the place of missing data in dataset","131ffaa2":"# Encoding categorical Columns using Pandas Library","b532c342":"# Droping Columns Having High Amount of Nan Value For Dataset\n\n**For Train Dataset As We can See PoolQC,Alley,Fence,MiscFeature Have High Amount of Nan Value so Drop Them.**\n**Also I will Drop Id Column As it has no value in determining the Price of Houses.**","3821115a":"# Importing the libraries","15595f8a":"# Combining the Test and Train Dataset\n\n**I am doing so because it will make some easy doing and we will have less data to be treated as both test and train are merged together**","0179447f":"# Traing the train dataset ","40a035c6":"# Prediction for test Set","d9c3ba92":"# Calculating the R^2 for our training set\n**I am calculating the R^2 for my training dataset to see how well my model is adapted to the train dataset to predict housing price.**","7d8df898":"# Checking Null values in dataset\n**First of all we will check is there any null or nan value in our dataset.For This I will use two methods.**\n\nBy using inbuilt method of our data ,i.e., isnull() method\nBy using heatmap function of seaborn library","fea4e79e":"# Importing The The Train And Test Dataset","9200105d":"# Making our dependent and independent features\n\n**Now making our dependent and independent features to test our model and predict for future values.**"}}